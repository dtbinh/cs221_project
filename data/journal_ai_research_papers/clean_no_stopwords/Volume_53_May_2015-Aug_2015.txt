Journal Artificial Intelligence Research 53 (2015) 659-697Submitted 4/15; published 8/15Evolutionary Dynamics Multi-Agent Learning:SurveyDaan BloembergenKarl Tuylsd.bloembergen@liverpool.ac.ukk.tuyls@liverpool.ac.ukDepartment Computer Science, University LiverpoolAshton Building, Ashton Street, Liverpool L69 3BX, UKDaniel Hennesdaniel.hennes@esa.intAdvanced Concepts Team, European Space AgencyKeplerlaan 1, 2201 AZ Noordwijk, NLMichael Kaisersm.kaisers@cwi.nlCentrum Wiskunde & InformaticaScience Park 123, 1098 XG Amsterdam, NLAbstractinteraction multiple autonomous agents gives rise highly dynamic nondeterministic environments, contributing complexity applications automatedfinancial markets, smart grids, robotics. Due sheer number situations mayarise, possible foresee program optimal behaviour agents beforehand. Consequently, becomes essential success system agentslearn optimal behaviour adapt new situations circumstances. pasttwo decades seen emergence reinforcement learning, single multiagent settings, strong, robust adaptive learning paradigm. Progresssubstantial, wide range algorithms available. important challengedomain multi-agent learning gain qualitative insights resulting systemdynamics. past decade, tools methods evolutionary game theorysuccessfully employed study multi-agent learning dynamics formally strategicinteractions. article surveys dynamical models derived variousmulti-agent reinforcement learning algorithms, making possible study comparequalitatively. Furthermore, new learning algorithms introduced using evolutionary game theoretic tools reviewed. evolutionary modelsused study complex strategic interactions. Examples analysis givendomains automated trading stock markets collision avoidance multi-robot systems. paper provides roadmap progress achieved analysingevolutionary dynamics multi-agent learning highlighting main resultsaccomplishments.1. Introductionmulti-agent system, several autonomous agents interact environment.Therefore, multi-agent systems used model many complex problems todayssociety, urban air traffic control (Agogino & Tumer, 2012), multi-robot coordination (Ahmadi & Stone, 2006; Claes, Hennes, Tuyls, & Meeussen, 2012), distributedsensing (Mihaylov, Tuyls, & Nowe, 2014), energy distribution (Pipattanasomporn, Feroze,& Rahman, 2009), load balancing (Schaerf, Shoham, & Tennenholtz, 1995; Verbeeck,c2015AI Access Foundation. rights reserved.fiBloembergen, Tuyls, Hennes, & KaisersNowe, & Tuyls, 2005). fact multiple agents interact leads highly dynamic,non-deterministic environment. environment, defining proper behaviouragent advance non-trivial therefore learning crucial. Recent publicationsagents machine learning conferences, well papers published related mainstreamjournals, make clear number newly proposed multi-agent learning algorithmsconstantly growing. overview well-established multi-agent learning algorithmsvarious purposes attained previous multi-agent learning survey papers(Panait & Luke, 2005; Hoen, Tuyls, Panait, Luke, & Poutre, 2005; Busoniu, Babuska, &De Schutter, 2008; Tuyls & Weiss, 2012), demonstrates need comprehensiveunderstanding qualitative similarities differences. Although single-agent learning particular reinforcement learning extensively studied acquiredstrong theoretical foundation (Kaelbling, Littman, & Moore, 1996; Sutton & Barto, 1998),thorough understanding learning multi-agent settings long remained openproblem (Tuyls, Hoen, & Vanschoenwinkel, 2006).Learning multi-agent systems relevant within field artificial intelligence extensively studied game theory economics well (Shoham,Powers, & Grenager, 2007). surprising then, fields share lot common ground. Indeed, game theory often provides context multi-agent systemsmodelled evaluated. Recently, multi-agent learning research shiftedfocus traditional game theory evolutionary game theory (Tuyls et al., 2006; Tuyls& Parsons, 2007). concepts employed evolutionary game theory prove well suiteddescribe learning multi-agent systems. fields concerned dynamic environments high level uncertainty, characterised fact agents lack completeinformation (Tuyls et al., 2006). Moreover, exists formal relation behaviour one basic reinforcement learning algorithms, Cross learning (Cross,1973), population dynamics evolutionary game theory, described replicator dynamics (Borgers & Sarin, 1997). Although link originally establishedcontext stateless normal-form games only, since extended complexscenarios well (e.g., Hennes, Tuyls, & Rauterberg, 2009; Tuyls & Westra, 2009; Galstyan,2013; Panozzo, Gatti, & Restelli, 2014).Understanding relation sheds light black box reinforcement learningmaking possible analyse learning dynamics multi-agent systems detailcompare behaviour different algorithms principled manner. turnfacilitates important tasks parameter tuning, helps selecting specific learnergiven problem. Tuyls Nowe (2005) Tuyls et al. (2006) first presentoverview evolutionary game theoretic approach multi-agent learning.build connection Cross learning replicator dynamics extendlink learning automata Q-learning well. However, much progressmade past decade, warranting up-to-date overview roadmap researcharea. precisely aim work.believe evolutionary game theory lot offer understandingapplication multi-agent learning. Shoham et al. (2007) call groundedapproach research multi-agent learning, suggesting five agendas researchcould contribute. also caution rely strongly requirementsconvergence Nash equilibrium evaluating learning algorithms multi-agent660fiEvolutionary Dynamics Multi-Agent Learningsetting. response, Tuyls Parsons (2007) argue favour evolutionary game theory,rather classical game theory, preferable framework within study multiagent learning formally. show research evolutionary framework contributesfive agendas research identified Shoham et al. (2007). Moreover, allowsus move away static Nash equilibrium, focus instead transientdynamics learning process.article describe formal relation evolutionary game theorymulti-agent learning detail survey recent advances extensionsmade area.1 end present categorisation related work basednature environment (stateless multi-state games) actions (discretecontinuous) available learning agents. Moreover, provide examplessuccessful application approach relation parameter tuning, design newlearning algorithms, analysis complex strategic interactions automatedtrading multi-robot collision avoidance. evolutionary game theoretic approachoffers promising new paradigm within study multi-agent learning, providesnew insights towards understanding, analysis, design multi-agent reinforcementlearning algorithms.paper proceeds follows. Section 2 provides necessary background (multiagent) reinforcement learning evolutionary game theory. Section 3 introduces linkreplicator dynamics Cross learning outlines methodologysurvey. overview recent advances extensions given Section 4, supportedempirical validation Section 5. Section 6 presents examples applicationevolutionary game theoretic approach. Section 7 concludes article.2. Preliminariessection, outline fundamentals multi-agent learning. Firstly, conciselypresent Markov decision processes (MDPs) standard formal framework singleagent decision making, together well-known reinforcement learning algorithm, Qlearning. proceed present stochastic games, also called Markov games, multiagent extension MDPs, well three approaches learning extended setting:independent learning, joint action learning, gradient based methods. Finally, discussevolutionary game theory used reason multi-agent interactions, pavingway formally relate two fields Section 3.2.1 Reinforcement LearningReinforcement learning based concept trial-and-error learning, underliesmany theories (human) learning intelligence (Sutton & Barto, 1998). reinforcement learning agent continuously interacts environment, perceiving state,taking actions, observing effect actions (see Figure 1). Actions yieldpositive effect higher chance executed future,1. attempt present broad survey multi-agent learning general focus solelyworks explicitly model multi-agent learning using methods evolutionary game theory.excellent survey taxonomy multi-agent learning algorithms general foundwork Busoniu et al. (2008).661fiBloembergen, Tuyls, Hennes, & KaisersAgentstrtrt+1st+1EnvironmentFigure 1: reinforcement learning agent perceives state st environment timet, decides take action , upon environment transitions state st+1agent receives reward rt+1 .say reinforced within agents behaviour. effect, agent receivesreward signal indicates quality actions taken; however, reward maystochastic, delayed, accumulated sequences actions. Therefore, agent needsbalance exploration exploitation, avoid getting stuck local optima. objectivelearning agent discover policy, represented mapping states actions,maximises long-term expected reward.single-agent reinforcement learning setting formalised Markov decisionprocess (MDP) (Puterman, 1994). MDP defined finite state action sets,A, one-step state transition dynamics0Pss0 = P (st+1 = |st = s, = a)(1)describing probability transitioning state s0 taking action states, expected value next rewardRass0 = E(rt+1 |st = s, = a, st+1 = s0 )(2)given previously executed action resulting state transition. state transitionsrewards stochastic, fact learning stochastic models key taskmany reinforcement learning problems. learning goal MDP find policymaps states action selection probabilities, maximising expected reward.following fixed policy define value state policy totalamount reward R agent expects accumulate starting state followingthereafter:XV (s) = E (Rt |st = s) = E (k rt+k+1 |st = s).k=0rewards discounted factor [0, 1) ensure bounded sum infinite horizonMDPs. value function policy calculated iteratively using Bellmanequation (Bellman, 1957). Starting arbitrarily chosen value function V ,iteration state value function updated based immediatereward current estimate V :XX0(s, a)PssV (s)0 [Rss0 + V (s )].aA(s)s0662fiEvolutionary Dynamics Multi-Agent LearningBellman equation expresses recursive relation value statesuccessor states, averages possibilities, weighing probabilityoccurring. setting, finding optimal policy equivalent finding policymaximises value function, i.e.,V (s) = max V (s) S.model environment available, particular P R known,Bellman equation applied compute optimal policy directly, using dynamicprogramming technique value iteration policy iteration (Sutton & Barto, 1998).general, however, model may available. case, reinforcement learning used find optimal mapping states actions. Arguablyfamous example reinforcement learning algorithm model-free temporal differencealgorithm Q-learning (Watkins & Dayan, 1992). Q-learning maintains value functionstate-action pairs, Q(s, a), updates based immediate rewarddiscounted expected future reward according Q:hQ(st , ) Q(st , ) + rt+1 + max Q(st+1 , a) Q(st , ) .(3)Here, discount factor future rewards before, [0, 1] learning ratedetermines quickly Q updated based new reward information. Q-learningproven converge optimal policy, given sufficient updates state-actionpair, decreasing learning rate 0 (Watkins & Dayan, 1992).Choosing action take crucial aspect learning process.agent exploit actions yielded high reward past, explore orderachieve potentially better results future, thereby risking low reward now? Neithertwo sufficient own, dilemma find right balance (Kaelblinget al., 1996; Sutton & Barto, 1998). Two often used action selection mechanisms greedy softmax Boltzmann exploration (Sutton & Barto, 1998). -Greedy selectsbest action (greedy w.r.t. Q) probability 1 , probability selectsaction random. Boltzmann exploration mechanism makes use temperatureparameter controls balance exploration exploitation. Action aichosen state probabilitye Q(s,ai )/pi = X.e Q(s,aj )/(4)jhigh temperature drives mechanism towards exploration, whereas low temperaturepromotes exploitation, favouring actions higher Q-values.2.2 Single-Agent Multi-Agent LearningMDP framework assumes single agent active environment. multipleagents interact learn simultaneously, model needs extended. Stochastic games,Markov games, offer generalisation MDPs multi-agent domain (Littman, 1994).stochastic game, agent set actions, i.e., n agents joint-action663fiBloembergen, Tuyls, Hennes, & Kaisersspace = A1 A2 . . . . state transition reward functions dependjoint action agents:R : A1 . . . 7 RnP : A1 . . . 7 [0, 1].immediate rewards may agents need general.special case stochastic games stateless setting described normal-form games.Normal-form games one-shot interactions, agents simultaneously selectaction receive reward based joint action, game ends.state transition function, reward function represented n-dimensionalpayoff matrix, n agents. agents policy simply probability distributionactions. Repeated normal form games common benchmarks multi-agent learning.scenarios detailed Section 2.3.Learning multi-agent setting inherently complex single-agentcase described previously, agents interact environment potentiallyother. Learning simultaneous, meaning changes policy one agentmay affect rewards hence optimal policy others. Moreover, agents mayconflicting interests, yet cooperation competitors may yield short long termbenefits. makes difficult judge learning process, since myopic maximisationindividual rewards might lead best overall solution. fact rewardfunction depends actions agents leads important characteristicmulti-agent reinforcement learning: environment non-stationary resultagent essentially pursuing moving target (Busoniu et al., 2008). Moreover, factmultiple agents influence environment means that, perspectiveindividual agents, Markov property longer holds. Two different approaches multiagent learning distinguished: independent learning joint-action learning (Claus& Boutilier, 1998). following briefly discuss approaches, list notablealgorithms class. detailed taxonomy multi-agent learning algorithms,refer excellent survey Busoniu et al. (2008).2.2.1 Independent LearningIndependent learners mutually ignore other, thereby effectively reducing multiagent learning problem single-agent one. Interaction agents implicitlyperceived noise stochastic environment. advantage approachsingle-agent learning algorithms straightforwardly applied multi-agent setting,scalability number agents issue.2 However, stochasticityenvironment means convergence guarantees single-agent setting lost.particular, Markov property proofs typically based, longer holds.Moreover, explicit mechanism coordination available agents. Despitedrawbacks, independent learners shown good performance many multi-agent settings (Busoniu et al., 2008).2. Computational complexity increases linearly number agents. Performance may varydepending specific domain algorithm.664fiEvolutionary Dynamics Multi-Agent LearningTraditional single-agent reinforcement learning algorithms, Q-learning (Watkins& Dayan, 1992) (networks of) learning automata (Narendra & Thathachar, 1974;Wheeler Jr & Narendra, 1986; Vrancx, Verbeeck, & Nowe, 2008b), directly appliedsetting. Moreover, various new independent learning algorithms proposedspecifically multi-agent setting mind. example, Bowling Veloso (2001)proposed policy hill climbing win learn fast heuristic (WoLF-PHC), showalgorithm rational convergent multi-agent domains. examplesinclude frequency maximum Q-learning (Kapetanakis & Kudenko, 2002), algorithm tailored coordinate cooperative multi-agent systems, class regret minimisationalgorithms (Blum & Mansour, 2007) guarantee performance close best fixedaction hindsight opponent. Finally, two extensions Q-learningproposed alleviate certain artifacts algorithm non-stationary (e.g. multiagent) environments: frequency-adjusted Q-learning (Kaisers & Tuyls, 2010), repeatedupdate Q-learning (Abdallah & Kaisers, 2013). Frequency-adjusted Q-learningproven converge two-player two-action normal-form games (Kaisers & Tuyls, 2011;Kianercy & Galstyan, 2012).2.2.2 Joint-Action LearningWhereas independent learners completely ignore presence agents, joint-actionlearners explicitly take account. Joint-action learners achieve learningspace joint actions, rather individual action space (Claus &Boutilier, 1998). observe actions agents order estimate policy,act optimally given estimated policies. way, joint action learnersbetter means coordination. drawback agent needs able observeagents actions, assumptions opponents adaptation mechanism necessary derive reasonable predictions opponents future actions. Moreover, complexity algorithm grows exponentially number agents. Examples jointaction learners minimax-Q (Littman, 1994), fictitious play AWESOME (Brown,1951; Conitzer & Sandholm, 2007), hyper-Q (Tesauro, 2003), Nash-Q (Hu & Wellman,2003). Worth mentioning well related stream work Bayesian reinforcement learning (Dearden, Friedman, & Russell, 1998; Strens, 2000). particular interestdiscussion multi-agent learning work Chalkiadakis Boutilier (2003),use Bayesian framework explicitly model agents uncertaintymodel environment strategies agents.2.2.3 Gradient Ascent Optimisationsomewhat separate stream multi-agent learning research revolves around gradient ascent based algorithms. methods often fall independent learningjoint-action learning, worth mentioning separately importantdiscussion Section 4.1. Gradient ascent (or descent) well-known optimisation technique field machine learning. Given well-defined differentiable objective function,learning process follow direction gradient order find local optimum.concept adapted multi-agent learning learning agents policiesfollow gradient individual expected reward.665fiBloembergen, Tuyls, Hennes, & KaisersExamples gradient ascent algorithms infinitesimal gradient ascent (IGA),designed specifically two-player two-action normal-form games (Singh, Kearns, &Mansour, 2000), generalized infinitesimal gradient ascent (GIGA), extends IGAgames arbitrary number actions (Zinkevich, 2003). algorithmscombined win learn fast (WoLF) heuristic order improve convergencestochastic games (Bowling & Veloso, 2002; Bowling, 2005). IGA GIGA assumeagents knowledge (reward) structure game, leastmechanism approximating gradient value function, generallyfeasible practice. However, recent algorithm weighted policy learning (WPL)relaxes assumption (Abdallah & Lesser, 2008).2.3 Game TheoryGame theory (Von Neumann & Morgenstern, 1944; Gibbons, 1992) theory interactivestrategic decision making, therefore utmost importance multi-agent systems.studies decision making form cooperative competitive games.games, player set actions preference joint action outcome,captured numerical payoff signal. games two players playedonce, i.e., one-shot two-player games, payoffs represented bi-matrix(A, B), gives payoff row player A, column player B (seeFigure 2). example, row player chooses one two rows, column playerchooses columns, outcome joint action determines payoffboth. goal player come strategy (a probability distributionactions) maximises expected payoff game. Note games, players,strategies, payoffs game theory map one-to-one environments, agents, policies,rewards multi-agent systems literature.players thought individually rational, sense playerperfectly logical tries maximise payoff, assuming others likewise.assumption, Nash equilibrium (NE) solution concept used studyplayers reasonably choose do. set strategies forms NE single playerbetter unilaterally switching different strategy. words, strategyNE best response strategies equilibrium.game one Nash equilibrium, may preferredequally. Moreover, NE may best outcome social point view.example, consider Prisoners Dilemma (Axelrod & Hamilton, 1981), depicted Figure 3(left). game, two players simultaneously choose either cooperate (C) defect(D). Individually, defection best response opponent strategy, resultmutual defection single Nash equilibrium game. However, players wouldbetter would cooperate hence dilemma.a11 , b11 a12 , b12a21 , b21 a22 , b22Figure 2: General payoff bi-matrix (A, B) two-player two-action normal form game.666fiEvolutionary Dynamics Multi-Agent LearningCC3, 3 0, 55, 0 1, 1HH4, 4 1, 33, 1 3, 3HH1, 0 0, 10, 1 1, 0Figure 3: Payoff matrix Prisoners Dilemma (left), Stag Hunt (center),Matching Pennies (right).second example given Stag Hunt (Skyrms, 2004), shown Figure 3 (center).coordination game, players prefer jointly choose either hunt stag (S)hare (H). Hunting hare provides safe choice, payoff action independentchoice opponent. Hunting stag risky, however players yield higherpayoff manage coordinate. game two pure Nash equilibria, (S, S)(H, H), one mixed Nash equilibrium players randomise playprobability 32 .Finally, Matching Pennies game (Figure 3, right) two players simultaneouslychoose side coin display, either heads (H) tails (T). chooseside, first player gets keep coins. pick opposite sides, secondplayer keeps coins. zero-sum game, single mixed NE playersrandomise uniformly actions.2.4 Evolutionary Game TheoryClassical game theory assumes full knowledge game available players,together assumption individual rationality necessarily reflectdynamic nature real world interactions. Evolutionary game theory relaxes rationality assumption replaces biological concepts natural selectionmutation (Maynard Smith & Price, 1973; Weibull, 1997; Hofbauer & Sigmund, 1998; Gintis, 2009). Central evolutionary game theory replicator dynamics describepopulation individuals evolves time evolutionary pressure. individual certain type, individuals randomly paired interaction.reproductive success determined fitness, results interactions.replicator dynamics dictate population share certain type increaseindividuals type higher fitness population average; otherwisepopulation share decrease. populationdescribed state vectorPx = (x1 , x2 , . . . , xn )>, 0 xi 1 xi = 1, representing fractionspopulation belonging n types. suppose fitness type givenPby fitness function fi (x), average fitness population given f (x) = j xj fj (x).Using xi denote dxdt , population change time writtenxi = xi fi (x) f(x) .(5)replicator dynamics describe change time large population individuals.However, model interpreted alternatively representing strategy singleplayer, population share type represents probabilityplayer selects corresponding pure action, summarised Table 1. replicatordynamics describe players strategy change time repeatedly plays667fiBloembergen, Tuyls, Hennes, & KaisersTable 1: Correspondence terminology domains reinforcement learning,game theory, evolutionary game theory.Reinforcement LearningenvironmentagentactionpolicyrewardGame TheorygameplayeractionstrategypayoffEvolutionary Game Theorygamepopulationtypedistribution typesfitnessgame iteratively updates policy.Evolutionary game theory refines staticNash equilibrium (NE) concept notion evolutionarily stable strategies (ESS).strategy x ESS immune invasion mutant strategies, given mutantsinitially occupy small fraction population. Let f (x, y) (expected) fitnessstrategy x strategy y. Formally then, strategy x ESS iff, mutantstrategy y, following hold:1. f (x, x) f (y, x),2. f (x, x) = f (y, x), f (x, y) > f (y, y).first condition states ESS also NE original game. secondcondition states invading strategy well original strategyoriginal strategy itself, original strategy must betterinvader invader itself. means ESS refinementNE solution concept. Moreover, every ESS asymptotically stable fixed pointreplicator dynamics (Weibull, 1997).two-player game, player described evolving population,every iteration game one individual players population drawn interact.Therefore, fitness type depends population distribution coplayer, i.e., two populations co-evolving. two players populations givenx fitness functions payoff matrices B, writeexpected fitness type population xXfi (x) =aij yj = (Ay)ijsimilarly write average population fitnessX Xf(x) =xiaij yj = x>Ay.jFollowing similar reasoning population y, rewrite Equation 5 twopopulationshxi = xi (Ay)i x>Ayh(6)yi = yi (x>B)i x>By .668fiEvolutionary Dynamics Multi-Agent Learning1110.750.750.75110.50.250010.50.250.250.5x10.751000.50.250.250.5x10.751000.250.5x10.751Figure 4: replicator dynamics, plotted unit simplex, prisoners dilemma(left), stag hunt (center), matching pennies (right).illustrate dynamics Equation 6, analyse three games presented Figure 3.Since players strategy two actions fully defined probability first action(as x2 = 1 x1 ), plot strategy space games two-dimensional unitsimplex tuple (x1 , y1 ). Plugging payoff matrix game replicatordynamics Equation 6, find direction relative speed change pointunit simplex. resulting vector fields three games shown Figure 4.Figure 4 shows players prisoners dilemma drawn (D, D)equilibrium, NE ESS. stag hunt, pure NE, (S, S)(H, H), also ESS, mixed NE not. fixed point, asymptoticallystable. Finally, matching pennies game single mixed NE ( 21 , 12 ),players randomise uniformly actions. However, ESS; insteadtrajectories cycle around fixed point.3. Relating Reinforcement Learning Replicator DynamicsRecent research analysing dynamics multi-agent learning builds seminal workBorgers Sarin (1997), first proved formal relation replicatordynamics evolutionary game theory reinforcement learning. section,first summarise proof. Next, present categorisation recent work, basednature environment actions available agents.3.1 Replicator Dynamics Continuous Time Limit Cross LearningMulti-agent learning evolutionary game theory share substantial part foundation, deal decision making processes boundedly rationalagents, players, uncertain environments. link two fieldsintuitive one, made formal proof continuous time limitCross learning converges replicator dynamics (Borgers & Sarin, 1997).669fiBloembergen, Tuyls, Hennes, & KaisersCross learning (Cross, 1973) one basic stateless reinforcement learningalgorithms, updates policy3 based reward r received taking action jr (i)r = j(i) (i) +.(7)(i)rotherwisevalid policy ensured update rule long rewards normalised, i.e.,0 r 1. Cross learning closely related finite action-set learning automata (Narendra& Thathachar, 1974; Thathachar & Sastry, 2002). particular, equivalent learningautomaton linear reward-inaction (LRI ) update scheme learning step size ()1.estimate expected change policy, E [(i)], induced Equation 7(Borgers & Sarin, 1997). probability (i) action affected selectedanother action j selected. Let Ei [r] expected reward taking action i.writehXhE [(i)] = (i) Ei [r] (i)Ei [r] +(j) Ej [r](i)j6=ih= (i) Ei [r](j)E[r].jjP(8)Assuming learner takes infinitesimally small update steps, continuous time limitEquation 8 takent+ (i) = (i) + (i)lim 0. yields continuous time system expressedpartial differential equationhP(i) = (i) Ei [r] j (j)Ej [r]two-player normal form game, write policy agent simply probabilitydistribution actions, i.e. x. defined, given payoff matrices Bpolicies x two players, respectively, yieldshxi = xi (Ay)i x>Ayh(9)yi = yi (x>B)i x>Byexactly multi-population replicator dynamics Equation 6.link made explicit theoretically also empirically, shownFigure 5. Here, simulate learning process two Cross learners takingsmall policy update steps (by multiplying update term Equation 7 =0.001), starting different initial policies, overlaying resulting policy tracesreplicator dynamics Figure 4. observed, learning traces followreplicator dynamics precisely. similar fashion, dynamical models different (andcomplex) reinforcement learning algorithms derived. discussedfollowing sections.3. dependency policy state dropped stateless environments, dependencetime implied omitted notational convenience.670fiEvolutionary Dynamics Multi-Agent Learning1110.750.750.75110.50.250010.50.250.250.5x10.751000.50.250.250.5x10.751000.250.5x10.751Figure 5: Policy traces Cross learning, plotted unit simplex overlaidreplicator dynamics, prisoners dilemma (left), stag hunt (center), matchingpennies (right).3.2 Categorisation Learning Dynamicsdivide learning algorithms corresponding dynamics presentedwork four categories, based nature environment actions available agent. distinguish stateless normal-form games, games multiplestates probabilistic transitions them, represented stochastic games (seealso Section 2.2). Moreover, differentiate settings agent finite,discrete choice actions, settings offer continuous range choices. Table 2lists four resulting categories, along references work donecategory. focus solely work explicitly relates dynamical models learningmulti-agent systems. large body work available discusses extensionsreplicator dynamics evolutionary game theoretic viewpoint only, however, falloutside scope survey.4Cross learning, detailed previously, belongs first category stateless gamesdiscrete actions. examples category stateless Q-learning relatedfrequency adjusted (FAQ) lenient (LFAQ) versions, regret minimisation, gradientascent algorithms. second category comprises stateless games continuous actionspace. Typically, function approximators used settings (a recent overviewprovided Busoniu, Babuska, De Schutter, & Ernst, 2010), however workcategory far limited single-agent learning. Here, summarise approachesmodel games using continuous action replicator dynamics. third categorystochastic (i.e. multi-state) games discrete actions. Dynamics derivednetworks learning automata, particular piece-wise state-coupled replicatordynamics, variation RESQ-learning incorporates exploration learningprocess.fourth category Table 2, comprising stochastic games continuous actionspaces, strikingly empty. Indeed, domain main interest future work,attempts made far derive learning dynamics setting. Combiningtechniques approaches second third category could fruitful starting4. See e.g. textbooks Weibull (1997) Hofbauer Sigmund (1998) introduction.671fiBloembergen, Tuyls, Hennes, & KaisersTable 2: Categorisation dynamical models multi-agent learning availableliterature.Discrete actionsContinuous actionsQ-learning1Normal formgamesStochasticgames1FAQ-learning2Regret Minimisation3Lenient FAQ-learning4Gradient ascent5Piecewise replicator dynamics8State-coupled replicatordynamics9RESQ-learning10Tuyls et al. (2003)4Kianercy Galstyan (2012)23Continuous action replicatordynamics6Q-learning7Kaisers Tuyls (2010, 2011)5Klos et al. (2010)6Panait et al. (2008)7Galstyan (2013)Bloembergen et al. (2011)8Vrancx et al. (2008a)Kaisers et al. (2012)9Hennes et al. (2009)Tuyls Westra (2009)10Hennes et al. (2010)point endeavour. next section provide overview work listedTable 2, following categorisation.4. Overview Learning Dynamicscategorisation presented Table 2 hand, give overviewdynamics various multi-agent reinforcement learning algorithms. First, learning dynamicsnormal-form games discussed. Next, present replicator dynamics continuousstrategy spaces. Finally, multi-state learning dynamics described.4.1 Learning Dynamics Normal-Form GamesRepeated normal-form games characterised stateless games, agentschoose discrete finite set actions time step. greatly simplifiesanalytical approaches, time still allowing capture interesting strategicinteractions. result, normal-form games frequently used test-bedmulti-agent learning (Busoniu et al., 2008). Several learning algorithms devisedspecifically normal-form games; multi-state algorithms Q-learningstraightforwardly applied removing state dependency learning updaterule. before, remainder define x policies twoagents stateless setting.4.1.1 Independent Reinforcement Learnersdescribed Section 3, Cross learning (CL) first algorithm linkedreplicator dynamics evolutionary game theory (Borgers & Sarin, 1997). particular,infinitesimal time limit Cross learning update rule (Equation 7) converges672fiEvolutionary Dynamics Multi-Agent Learningreplicator dynamics. link simple policy learner Cross learning,dynamical system policy space may seem intuitive. However, linkextended value-based (and complex policy-based) learners well. selectionmutation model Boltzmann Q-learning proposed Tuyls et al. (2003), assumingconstant temperature .5 Tuyls et al. show dynamical system decomposedterms exploitation (selection following replicator dynamics) exploration(mutation randomisation based Boltzmann mechanism):6xi =hPxi h(Ay)i x>Ay xi log xi k xk log xk .|{z}{z}|exploitation(10)explorationAnother way view two terms Equation 10 relation thermodynamicalconcepts energy entropy, selection analogous energy, mutationentropy. entropy term subdividedPin entropy one individual strategy, log xi , entropy entire population, k xk log xk . sense, mutationdetermined difference entropy individual strategy compared entropywhole population (Tuyls et al., 2003).dynamical model Equation 10 assumes actions updated simultaneously, case Cross learning. Q-learning, however, updates Q-valueselected action, causing discrepancies predicted dynamics actual learning behaviour algorithm. variation frequency-adjusted Q-learning (FAQ) (Kaisers& Tuyls, 2010) mimics simultaneous action updates modulating update rule (Equation 3) inversely proportional xi , thereby following dynamical model Equation 10precisely. Dropping state dependency, yields1Q(i) Q(i) + r + max Q(j) Q(i) .jxiUsing replicator dynamics model Equation 10, two independent proofs convergenceFAQ derived two-player two-action normal-form games, showing convergence near Nash equilibria given decreasing exploration temperature (Kaisers & Tuyls,2011; Kianercy & Galstyan, 2012).Lenient FAQ (LFAQ) (Bloembergen et al., 2011) variation aimed overcomingconvergence suboptimal equilibria mis-coordination early phase cooperativelearning processes, mistakes one agent may lead penalties others, irrespectivequality actions. Leniency towards mistakes achieved collectingrewards action, updating Q-value based highest rewards.causes (optimistic) change expected reward actions learningagent, incorporating probability potential reward action highestconsecutive tries (Panait et al., 2008). expected reward action Ay5. model Boltzmann Q-learning dynamics varying temperature, see work Kaisers, Tuyls,Parsons, Thuijsman (2009) Kaisers (2012).6. on, derive dynamics one agent only. dynamics agents followstraightforwardly, similar Equation 9.673fiBloembergen, Tuyls, Hennes, & KaisersEquation 10 replaced utility vector u,hPPX ij jk:aik aij kk:aik <aij kPui =k:aik =aij yk(11)jPk:statement implies summing indices k statement holds.Recently, evolutionary framework also extended polynomial weightsalgorithm, implements regret minimisation (RM) (Blum & Mansour, 2007; Kloset al., 2010). learner calculates loss (or regret) li taking action ratherbest action hindsight li = r r r actual reward received, roptimal reward. learner maintains set weights w actions, updatesweights according perceived loss, derives new policy normalisation:wi wi [1 li ]wixi = P.j wj(12)form regret, computed time step, known external regret, whereasinternal regret computed loss respect policy replaces given actionaction j occurrence (Blum & Monsour, 2007). Despite greatdifference update rule policy generation compared Cross learning Q-learning,Klos et al. (2010) show infinitesimal time limit regret minimisation similarlylinked dynamical system replicator dynamics numerator:xi (Ay)i x>Ayxi =.(13)1 [maxk (Ay)k x>Ay]denominator interpreted learning rate modulation dependent bestactions update, corresponding weighting action probability update expectedloss.4.1.2 Gradient Ascent AlgorithmsGradient ascent (or descent) well known optimisation technique field MachineLearning. Given well-defined differentiable objective function, learning processfollow direction gradient order find local optimum. conceptadapted multi-agent learning learning agents policies follow gradientindividual expected payoff. approach assumes expected payoff functionknown (or accurately learned by) agents, may generally feasiblepractice, since multi-agent settings payoff function usually depends (possiblyfrequently changing) unobservable internal states agents.One algorithm implementing gradient ascent multi-agent learning infinitesimalgradient ascent (IGA) (Singh et al., 2000), learner updates policytaking infinitesimal steps direction gradient expected payoff.proven that, two-player two-action games, IGA either converges Nash equilibrium,asymptotic expected payoff two players converges expected payoffNash equilibrium (Singh et al., 2000). discrete time algorithm using finite decreasing674fiEvolutionary Dynamics Multi-Agent Learningstep size shares properties. Take V (x) : Rn R value function mapspolicy expected payoff. policy update rule IGA definedV (x)xix projection(x + x)xi(14)denotes learning step size. intended change x may take x outsidevalid policy space, case projected back nearest valid policyprojection function.Win learn fast (IGA-WoLF) (Bowling & Veloso, 2002) variation IGAuses variable learning rate. intuition behind scheme agentadapt quickly performing worse expected, whereas cautiouswinning. modified learning rule IGA-WoLFV (x) min V (x) > V (x )xiximax otherwise(15)x projection(x + x)x reference policy, e.g., policy belonging arbitrary Nash equilibrium.weighted policy learner (WPL) (Abdallah & Lesser, 2008) second variationIGA also modulates learning rate, contrast IGA-WoLF requirereference policy. update rule WPL definedV (x) xiVx(x)<0xixi1 xi otherwise(16)x projection(x + x)update weighted either xi 1 xi depending sign gradient.means x driven away boundaries policy space.next section, derive dynamical model gradient ascent algorithms two-player two-action games, show remarkable similaritiesdynamics reinforcement learners discussed Section 4.1.1.4.1.3 Comparative Overview Learning Dynamics 2x2 Gamestwo-agent two-action games, dynamical models presented previous sectionssimplified (Kaisers et al., 2012). Let h = (1, 1), x = (x, 1x) = (y, 1y).learning dynamics completely described pair (x, y), denote probabilitychange first action learners. Cross learning (CL) leadssimplified formx = x (Ay)1 x>Ay= x(1 x) (a11 a12 a21 + a22 ) + a12 a22= x(1 x) yhAh> + a12 a22a12 a22 elements payoff matrix A. shorten notation twoaction games, let= (Ay>)1 (Ay>)2 = yhAh> + a12 a22675fiBloembergen, Tuyls, Hennes, & Kaisersdenote gradient, CL dynamics written x = x(1 x). Then,similarly, simplified FAQ dynamics readxx = x(1 x).log1xdynamics RM slightly complex, denominator dependsaction gives highest reward. derived gradient: first actionmaximal iff > 0. Using insight, dynamics RM two action gameswritten follows:(1 + x)1< 0x = x(1 x)1(1 (1 x))otherwise.IGA, update rule worked similar fashion. main termupdate rule gradient expected reward, two player two-action gameswrittenV (x)=(x, 1 x)A1yxx= y(a11 a12 a21 + a22 ) + a12 a22= yhAh> + a12 a22= .reduces dynamics update rule IGA two-player two-action gamesx = . extension dynamics IGA IGA-WoLF WPL straightforward.Table 3 lists dynamics six discussed algorithms: IGA, IGA-WoLF, WPL,CL, FAQ RM. immediately clear table algorithms sharebasic term dynamics: gradient . Depending algorithm,gradient scaled learning speed modulation. Interestingly, dynamics IGAcompletely independent learners current policy x. words, IGATable 3: table shows overview learning dynamics, rewritten specificcase two-agent two-action games (Kaisers et al., 2012).AlgorithmIGAIGA-WoLFWPLCLFAQRMxmin V (x) > V (x )max otherwisex< 0(1 x) otherwisex(1 x)xx(1 x) 1 log 1x(1 + x)1< 0x(1 x)1(1 (1 x))otherwise676fiEvolutionary Dynamics Multi-Agent Learningoff-policy algorithm assumes actions sampled equally often. contrast,multi-agent learning setting (gradient the) value function known,learners necessarily need on-policy, otherwise cannot learn true valuefunction. light, argued Cross learning implements stochastic onpolicy gradient ascent (Kaisers et al., 2012). Finally, FAQ yields dynamicsadditionally add exploration terms process.analysis shows merits evolutionary game theoretic approach studymulti-agent learning. deriving mathematical models infinitesimal time limitvarious learning algorithms, formally establish underlying differencescommonalities.4.2 Replicator Dynamics Continuous Action Spacesdynamics algorithms discussed previously assume discrete, finite action space.contrast, many real-world settings feature actions rather continuous nature.settings tabular notation Q-functions policies longer feasiblefunction approximators need used. One approach discretise continuous parameters ranges, treat range one instance. However, straightforwardgeneral design good discretisation, details might lost. Another approachmodel continuous actions directly, moving discrete probability vectors actions probability density functions. Examples Q-learning algorithms continuous action spaces fitted Q-iteration (Ernst, Geurts, & Wehenkel, 2005) NEAT+Q-learning(Whiteson & Stone, 2006). Learning automata similarly extended continuous action spaces. instance, Santharam, Sastry, Thathachar (1994) propose continuousaction-set learning automata (CALA) use Gaussian distribution model policy.also possible use nonparametric distribution, employed continuous actionreinforcement learning automata (CARLA), allowing diverse exploration strategyconvergence potentially multi-modal distribution (Howell, Frost, Gordon, & Wu,1997; Rodrguez, Vrancx, Grau, & Nowe, 2012). in-depth discussion learningmethods falls outside scope paper. Instead, focus modellingalgorithms extending replicator dynamics continuous action spaces.7Suppose agents action space described continuous parameters x =(x1 , x2 , . . . , xD ), x RD , allowed action space. two-playersetting, reward playing action x opponent plays given f (x, y).agents policy time given probability density function actionspace, (x, t),Z(x, t)dx = 1.write continuum limit standard replicator dynamics (Equation 5)partial differential equation (Oechssler & Riedel, 2001; Cressman, 2005; Tuyls & Westra,2009):h(x, t)= (x, t) V (x, t) E(t)(17)7. recent extensive overview function approximation methods reinforcement learning providedBusoniu et al. (2010).677fiBloembergen, Tuyls, Hennes, & KaisersZf (x, y)(y, t)dyV (x, t) =ZE(t) =V (x, t)(x, t)dx.Here, V (x) depicts expected reward action x, E overall average reward.context statistical mechanics terms thought local potentialtotal energy, respectively.Similar discrete action dynamics discussed before, add mutation termsEquation 17 model exploration learning agents. straightforwardapproach including diffusion term replicator dynamics,allows mutation strategies slightly different ones nearby. procedureoriginally proposed Hofbauer Sigmund (1998), Ruijgrok Ruijgrok(2005) provided rigorous mathematical foundation subsequent analysis. RuijgrokRuijgrok add diffusion term continuous action replicator dynamicsfind even small mutation rate may greatly alter outcome learning process,leading favourable results in, e.g., ultimatum game. Specifically, addtransition probability per unit time qij spontaneous transfer strategystrategy j. way discrete replicator equations mutation writtenfollows:Xxi = xi (Vi E) +(qij xj qji xi ).jRuijgrok Ruijgrok follow method Van Kampen (1992) derive continuumlimit mutation term. Using approach, arrive continuous replicator equation Hofbauer Sigmund:h(x, t)= (x, t) V (x, t) E(t) + (x, t)2 (x, t).(18)Ruijgrok Ruijgrok study equation number games transformed continuous strategy setting. is, however, reason assume mutations restricted adjacent strategies. Therefore, building work, TuylsWestra (2009) compare three different diffusion-based mutation terms, findtype mutation also significantly influence resulting dynamics. Specifically,replace simple isotropous diffusion term containing mutation rate RuijgrokRuijgrok mimicking effect anisotropous deterministic mutations. startcontinuous time discrete action replicator equations mutation,derive different formulation continuous action space:hh(x, t)= (x, t) V (x, t) E(t) + (x) V (x)(x, t) .new formulation able capture certain aspects evolution driven gametheoretic interactions absent original formulation Hofbauer Sigmund,Ruijgrok Ruijgrok Equation 18. dynamics approach evencomplex different mutation rates provide entirely different stationary solutions. Fulldetails found work Tuyls Westra.678fiEvolutionary Dynamics Multi-Agent LearningAlthough dynamical models Equations 17 18 yet directly linkedspecific learning algorithm, Galstyan (2013) recently proposed dynamical modelcontinuous action version Boltzmann Q-learning. Galstyans model similar selectionterm based local potential V (x) total energy E, mutation termentropy term derived Boltzmann distribution, Equation 10. Galstyanfinds mutation drives learning process away pure Nash equilibria helpsconvergence uniformly mixed equilibria, similar discrete action Q-learning (see Kaisers& Tuyls, 2011; Kianercy & Galstyan, 2012).4.3 State-Coupled Replicator Dynamicsfar, discussion learning dynamics limited stateless games. Althoughmany real-world interactions indeed cast form repeated normal-form games,always case. Therefore, need understand learning dynamicsstatefull environments well. Vrancx et al. (2008a) propose combination replicator dynamics switching dynamics model learning automata stochastic (Markov) games.learning automata definition stateless (see Section 3.1), extension neededmulti-state games. One option agent maintain network learning automata(Wheeler Jr & Narendra, 1986; Vrancx et al., 2008b), one state. gameprogresses, control passed one automaton depending currentstate game. Instead performing policy updates active automaton basedimmediate reward rt , update delayed automaton becomes active again,time updated based average reward received period. Basedmechanism, Vrancx et al. (2008a) partition state-space cells, correspondingdifferent attractors average reward games. cell fixed replicator dynamic,based agents policies updated. update makes system leavecurrent cell, new replicator dynamic takes over. Hennes, Tuyls, Rauterberg (2008)formalise piece-wise replicator dynamics.piece-wise model suffers several shortcomings, however, demonstratedHennes et al. (2009). Firstly, model approximates learning behaviour assuming fixed dynamics cell, secondly, discrete switching cells causesdiscontinuities present real traces learning process. order alleviate shortcomings, Hennes et al. propose state-coupled replicator dynamics(SC-RD) model uses direct state coupling rather piece-wise switching dynamics. direct state coupling eliminates anomalies discontinuities caused linearapproximations discrete cell switching. SC-RDdefined follows. Letset policies n agents, i.e., = 1 , 2 , . . . , n . Moreover, let = a1 , a2 , . . . ,joint action. Assuming game absorbing states (i.e., set statesergodic), exists stationarystates ,P distributionfrequency state sS= 1. calculate limiting averagereward r playing specific joint-action state s, given fixed policiesstates s0 ,ri (s, a) =r (s, a) +Xs0 S{s}6790s0 f(19)fiBloembergen, Tuyls, Hennes, & Kaisersf (s0 ) expected reward (fitness) agent state s0 , calculatedXf (s) =r (s, a)QnAjj=1nkks,!.k=1set system differential equations agent action j, similarEquation 9, payoff matrix substituted limiting average reward r.Furthermore, instead singleopponent policy agents policies= 1 . . . i1 , i+1 . . . n . expected payoff player playing pure action jstate givenXri s, a0fji (s) =k s, a0ka0Ql6=iAlk6=ia0 = a1 . . . ai1 , j, ai . . . . Essentially, enumerate possible joint actionsfixed action j agent i. general, mixed policy , agent receivesexpected payoffri s, a0k s, a0kf (s, ) =Xai AiX(s, ai )a0Ql6=iAlk6=ir limiting average reward given Equation 19. Writing xi (s) (s)probability distribution actions agent j state s, definemulti-population state-coupled replicator dynamics following system differentialequations:xij (s) = xij (s)xs f (s, ej ) f s, xi (s)(20)ej j th -unit vector,policy plays pure action j.P correspondingPtotal system N = sS ni=1 |Ai | replicator equations. Hennes et al. showSC-RD model describes true learning dynamics networks learning automatafar precise piece-wise replicator dynamics.Recently, replicator dynamics extended sequence form representation extensive-form games well (Gatti, Panozzo, & Restelli, 2013; Lanctot, 2014).allows us model even complex games, e.g. sequential moves imperfect information. Panozzo et al. (2014) developed new version Q-learning workssequence form, along dynamical model matches learning process basedsequence-form replicator dynamics mutation term similar Equation 10.show that, although selection mechanism sequence-form normal-formreplicator dynamics realization equivalent (Gatti et al., 2013; Lanctot, 2014), mutation term not. in-depth discussion findings falls outside scopearticle, would require addition much broader background extensive-formgames. However, recent works show promise evolutionary frameworkmulti-agent learning beyond normal-form even stochastic games well.680fiEvolutionary Dynamics Multi-Agent Learning5. Experimental Overviewestablished link multi-agent reinforcement replicator dynamicsevolutionary game theory Section 3, provided overview learning dynamicsnormal-form games, continuous strategy spaces, stochastic (Markov) games Section 4.Here, show set experiments empirically validate models two-player twoaction normal-form games. restrict games simplicity allowseasy visual analysis, preserving explanatory power dynamical models.end section provide overview related empirical work complexinteractions.described earlier, two-player two-action games policy space compactlyrepresented unit simplex completely defined probabilityagents select first action. makes easy plot visually inspectlearning dynamics interactions. Section 3.1, Figure 5, example analysisfound Cross learning, compared standard replicator dynamics. Similaranalysis performed different learning algorithms, plotting policy traceslearning behaviour overlaid vector field corresponding dynamical model (seee.g. Tuyls et al., 2006; Klos et al., 2010; Kaisers & Tuyls, 2010, 2011; Bloembergen et al.,2011). Figure 6 shows standard frequency-adjusted Q-learning (FAQ),lenient counterpart (LFAQ), top two rows. Whereas dynamics differentalgorithms similar convergence behaviour one equilibrium present,case prisoners dilemma matching pennies, stag hunt differencesobserved. notion leniency, introduced overcome convergence suboptimalequilibria, works drive learning process towards optimal outcome game (S,top right corner), easily observed investigating vector field. Interestingly,Cross learning standard replicator dynamics converge matchingpennies game, (L)FAQ sprial inwards towards single Nash equilibrium ( 12 , 21 ),evolutionarily stable classical replicator dynamics model (Section 2.3).additional exploration term makes difference here.far, analysed dynamics two identical learners pittedother. However, replicator dynamics model allows heterogeneous systems well,different agents follow different learning rules. cases, policy changeindividual agent modelled different variation replicator dynamics,corresponding agents learning rule. bottom row Figure 6 showssituation FAQ LFAQ pitted other. games selfplay dynamics learners similar, prisoners dilemma matchingpennies, mixed dynamics change significantly. cases, staghunt, learning process clearly influenced different dynamics mix. LFAQstronger tendency play optimal action S, FAQ persuaded likewise.analysis makes possible compare behaviour learning algorithms heterogeneousenvironments, compare different parameter settings single algorithm.final example, revisit comparison gradient ascent-based reinforcementlearning algorithms Section 4.1.3. Figure 7 shows learning dynamics predictedmodels derived presented Table 3, matching pennies game. Regretminimisation (RM) omitted dynamics visually indistinguishable Cross681fiBloembergen, Tuyls, Hennes, & KaisersFAQ-learning1110.750.750.75y1y10.50.25y10.50.25000.250.5x10.750.250010.50.250.5x10.750010.250.5x10.7510.250.5x10.7510.751Lenient FAQ-learning1110.750.750.75y1y10.50.25y10.50.25000.250.5x10.750.250010.50.250.5x10.75001110.750.750.750.50.2500LFAQ: y11LFAQ: y1LFAQ: y1FAQ vs LFAQ0.50.250.250.5FAQ: x10.75Prisoners Dilemma1000.50.250.250.5FAQ: x1Stag Hunt0.751000.250.5FAQ: x1Matching PenniesFigure 6: Policy traces FAQ LFAQ, plotted unit simplex overlaidrespective dynamical model, prisoners dilemma (left), stag hunt (center),matching pennies (right) (Bloembergen et al., 2011).682fiEvolutionary Dynamics Multi-Agent Learning1110.50010.50.5x00110.50.5x0010.5111CL100IGAWoLFWPLCLFAQ10.50.50.5x1WPL110.5x1IGA-WoLF10011IGA10.5x1FAQ1000.5x11TracesFigure 7: Overview dynamics various gradient ascent reinforcement learning algorithms matching pennies. bottom right panel shows single tracedynamical models, using initial policy (indicated ) (Kaisers et al., 2012).learning (CL). clearly observe similarity CL infinitesimal gradientascent (IGA), cycle around central equilibrium point without converging.Win-or-learn-fast IGA (WoLF) weighted policy learner (WPL) converge duelearning rate modulator; case WoLF, two learning rates used (forwinning loosing), whereas WPL uses continuum learning rates, resulting nonlinear dynamics. difference clearly observed comparing vector fieldsrespective dynamical models. noted before, FAQ spirals inwards towards Nashequilibrium although hard observe vector field alone, factverified following trace dynamics, shown bottom right panel Figure 7different algorithms. traces highlight (subtle) similarities differencesdiverse algorithms.Similar analyses performed investigate learning dynamics complex(e.g., multi-state) games, highlight influence certain parameters learningprocess. instance, Tuyls et al. (2003) first derive selection-mutationdynamics Q-learning discrete-action normal-form games, visually compare traceslearning algorithm predicted dynamics model. Similar derivationsanalyses later provided algorithms learning automata (Tuyls683fiBloembergen, Tuyls, Hennes, & Kaiserset al., 2006) regret minimisation (Klos et al., 2010). Others focused learningdynamics multi-state (stochastic) games, particular deriving dynamics networkslearning automata (Vrancx et al., 2008a; Hennes et al., 2009). others derived newlearning algorithms based desirable dynamical model, leading FAQ-learning (Kaisers& Tuyls, 2010) lenient FAQ (Bloembergen et al., 2011) normal-form games,RESQ-learning stochastic games (Hennes et al., 2010). Finally, several authorsused insights stemming dynamical models compare different algorithms,investigate convergence. example, Bowling Veloso (2002) introducevariable learning rate WoLF heuristic prove used make IGA convergentnormal-form games. Abdallah Lesser (2008) introduce WPL compare IGAIGA-WoLF, show WPL converges normal-form games well, withoutrequiring much information IGA-WoLF. Kaisers Tuyls (2011) use dynamicalmodel FAQ demonstrate near-NE convergence normal-form games, Galstyan(2013) similarly shows continuous-action Q-learning (see also Section 6.1.2).Table 4 presents overview related works, clustered interaction type i.e.,normal form games discrete continuous actions spaces, stochastic gameslists relevant learning algorithms investigated. purposely listworks explicitly focus relation multi-agent learning algorithmsevolutionary dynamical model. works utilises extends connectionorder gain qualitative insights behaviour algorithms varietysettings.Table 4: overview related empirical evaluations learning dynamics. NFG: normalform games; CNFG: continuous action normal-form games; SG: stochastic (Markov) games.TypeAlgorithmReferenceNFGQ-learningTuyls et al. (2003, 2006)NFGregret minimisationKlos et al. (2010)NFGFAQKaisers Tuyls (2010, 2011)NFGlenient FAQBloembergen et al. (2011)Kaisers (2012)NFGWoLFBowling Veloso (2002)NFGIGA, IGA-WoLF, WPLAbdallah Lesser (2008)CNFGQ-learningGalstyan (2013)SGnetworks learningautomataVrancx et al. (2008a)Hennes et al. (2009)SGRESQ-learningHennes et al. (2010)684fiEvolutionary Dynamics Multi-Agent Learning6. Applicationsprevious sections highlighted descriptive power replicator dynamicsmodel multi-agent learning. Here, focus prescriptive power well. example, use dynamical models easy parameter tuning learning algorithms.Moreover, starting desired dynamics, possible reverse-engineer learning algorithm exhibits preferred behaviour. Finally, evolutionary modelsused analyse complex strategic interactions, automated trading. Focusingmeta-strategies rather primitives reduces complexity interactions enoughstudy dynamics analytically.6.1 Parameter TuningParameter tuning traditionally cumbersome task involving many simulation trials, oftenfollowing evolutionary optimisation approach. However, deterministic dynamical model effect various parameters learning process readily observable.following, provide examples lenient learning, balancing explorationexploitation.6.1.1 Degree LeniencyLenient learning introduced way overcome problem suboptimal convergence cooperative multi-agent settings, initial mis-coordination leadsundervaluation optimal action (Panait et al., 2008). problem also knownrelative overgeneralisation (Wiegand, 2003) action shadowing (Fulda & Ventura, 2007).focusing learning update maximal rewards rather average, learner effectively ignores low rewards due suboptimal behaviour others earlyphases learning process. achieved collecting rewards actionperforming update based highest rewards (Panait et al., 2008;Bloembergen et al., 2011). details dynamical model lenient frequency-adjustedQ-learning (LFAQ) given Section 4.1.1, Equation 11.main parameter LFAQ degree leniency, . One main advantagesdynamical model allows studying tuning parameter withoutneed extensive simulations. Instead, directly analyse dynamical model.Figure 8 shows dynamics LFAQ, following Equation 11, stag hunt,{1, 2, 5, 25}. stag hunt two pure Nash equilibria also evolutionarily stablestrategies, agents either play H, (0, 0), S, (1, 1) (see Section 2.3).dilemma game choice safe action H, always givesreward independent agents action, S, optimal,players coordinate. precisely problem leniency aims solve. Figure 8shows degree leniency increases, basin attraction optimaloutcome (1, 1). Depending nature game opponent, balance needsfound leniency one hand, risk exploited, laggingbehind changing environment, other. dynamical model greatly facilitatesgaining quick insight effects.685fi110.750.750.750.750.50.25000.50.250.250.50.75LFAQ: x1=1100LFAQ: y11LFAQ: y11LFAQ: y1LFAQ: y1Bloembergen, Tuyls, Hennes, & Kaisers0.50.250.250.50.75LFAQ: x11=2000.50.250.250.50.75LFAQ: x1=51000.250.50.75LFAQ: x11= 25Figure 8: effect degree leniency convergence stag hunt game.solid line indicates boundary basins attraction two equilibria;global optimum located (1, 1) (Bloembergen et al., 2011).6.1.2 Tuning Exploration Rate FAQ-LearningBalancing exploration exploitation vital importance learning task, particular dynamic environments multiple learning agents interact. (FA)Q-learningBoltzmann exploration (Equation 4), temperature parameter controls levelexploration high temperature promotes exploration, whereas low temperature favoursexploitation. dynamical model FAQ (Equation 10) allows study effectexploration rate behaviour convergence learner multi-agent setting,demonstrated Kaisers Tuyls (2011).Figure 9 shows effect dynamics convergence FAQ battlesexes. game, players need coordinate either one two actions, howeverdifferent preference joint outcomes:BB2, 1 0, 00, 0 1, 2first three frames figure show dynamics computed fixed pointsdifferent temperatures (first frame = , second frame = 0.72877, third frame = 0).fixed points move discrete values indicated paths shownfourth frame. game three Nash equilibria, (0, 0), (1, 1), ( 32 , 13 ). However,high values replicator model yields one attracting fixed point, moves( 12 , 21 ) towards mixed equilibrium ( 23 , 13 ). Kaisers Tuyls show fixedpoint splits supercritical pitchfork bifurcation critical temperature crit 0.72877position (x1 , y1 ) (0.5841, 0.4158). low temperatures < crit , dynamicsyield three fixed points move closer corresponding equilibria decreased.two fixed points moving toward pure equilibria (0, 0) (1, 1) attracting,third one moving toward ( 32 , 13 ) repelling.similar analysis Boltzmann Q-learning performed Kianercy Galstyan (2012). also observe fixed points dynamical model move towardsNash equilibria 0 relate temperature Boltzmann mechanismthermodynamical concept free energy (Galstyan, 2013). Gomes Kowalczyk (2009)propose dynamical model -greedy Q-learning, show model accurately686fiEvolutionary Dynamics Multi-Agent Learning11110.80.80.80.80.60.6y10.60.6y1y1y10.40.40.40.40.20.20.20.2000.20.4x10.60.81000.20.4x10.60.80010.20.4x10.60.80010.20.4x10.60.81Figure 9: Replicator dynamics (arrows) fixed points () = {, 0.72877, 0}(first three frames). Right-most frame shows trajectories fixed points temperaturedecreased (Kaisers & Tuyls, 2011).predicts empirical findings. Similarly, Wunder, Littman, Babes (2010) presentdetailed study -greedy Q-learning various classes normal-form games provideproofs (non-) convergence class, varying rapid convergence stable oscillations. works shows great applicability benefit replicatordynamics model multi-agent learning, investigating effect various parameterslearning process.6.2 Design New Learning Algorithmsfar, taken forward approach: starting learning algorithm deriveddynamical model accurately predicts behaviour algorithm limit.can, however, also take inverse approach starting set desired dynamicsreverse-engineering learning algorithm exhibits dynamical properties (Henneset al., 2010; Tuyls, Heytens, Nowe, & Manderick, 2003).example, consider state-coupled replicator dynamics (SC-RD) introduced Section 4.3. dynamics describe behaviour networks learning automata, essentially exploiting, exploration solely induced stochasticaction-selection process. However, results domain stateless games suggestexploration aids convergence mixed equilibria, purely exploitative learners entercycles (see Section 5, particular Figure 7). Hennes et al. (2010) extend SC-RD model(Equation 20) exploration term FAQ-learning (Equation 10), leadsxij (s)=xij (s)xs"f (s, ej ) f s, xi (s)log xij +Xxik log xik#.kdynamics translated learning algorithm adding similar explorationterm policy update network learning automata. reward remains equalaverage accumulated reward since last visit particular automata,687fiBloembergen, Tuyls, Hennes, & Kaiserspolicy update taking action j computed(Pr (i)r (log (i) + k (k) log (k)) = jP(i) (i) +(i)r (log (i) + k (k) log (k))otherwise.Hennes et al. show RESQ-learning able converge two-state version matchingpennies, standard SC-RD cycle around equilibrium.Another example given work Tuyls et al. (2003), standard replicatordynamics extended ensure stable convergence Nash equilibria classes twoagent two-action normal-form games. Based extended replicator dynamics Tuylset al. derive extended Cross learning algorithm adheres preferred dynamics.6.3 Evolutionary Analysis Complex Strategic Interactionsaddition relatively simple, stylised games, also analyse much complexsystems. accomplished taking high-level view focusing meta-strategies,rather atomic actions, scenarios. example, allows us studyevolutionary dynamics various trading strategies stock markets (Kaisers et al., 2009;Hennes, Bloembergen, Kaisers, Tuyls, & Parsons, 2012; Bloembergen, Hennes, McBurney,& Tuyls, 2015). Similarly, possible compare auction mechanisms (Phelps, Parsons, &McBurney, 2005), strategies game poker (Ponsen, Tuyls, Kaisers, & Ramon, 2009),even collision avoidance methods multi-robot systems (Hennes, Claes, & Tuyls, 2013).Moreover, link replicator dynamics reinforcement learning allows uspredict happen agents learn optimise strategy scenarios.following, present two examples analyses. Firstly, detail heuristicpayoff tables method estimate payoff high-level meta-strategies empirically.Next, present use analysis evaluate trading strategies stock markets(Section 6.3.2), collision avoidance strategies multi-robot systems (Section 6.3.3).6.3.1 Heuristic Payoff Tablesorder analyse evolutionary strength high-level meta-strategies, needestimate expected payoff strategies relative other. evolutionarygame theoretic terms, relative fitness various strategies, dependentcurrent frequencies strategies population. evolutionary model assumesinfinite population. cannot compute payoff population directly,approximate evaluations finite population. possible distributionsk strategies enumerated finite population n individuals. Let Nmatrix,row Ni contains one discrete distribution. matrix yieldn+k1rows. distribution strategies simulated (using appropriatenmodel environment), returning vector expected relative rewards u(Ni ). Let Umatrix captures rewards corresponding rows N , i.e., Ui = u(Ni ).heuristic payoff table H = (N, U ) proposed Walsh, Das, Tesauro, Kephart (2002)capture payoff information possible discrete distributions finite population.example heuristic payoff table given Table 5. example,k = 3 different meta-strategies, distributed population n = 6 individuals.row N specifies exactly many individuals use three strategy types,688fiEvolutionary Dynamics Multi-Agent LearningTable 5: Example heuristic payoff table k = 3 strategies finite populationn = 6 individuals.Ni16530Ni20110Ni300Ui10.50.420.360Ui200.70.50Ui3000.80.9row U specifies estimated payoff. discrete distribution Ni features zeroindividuals type j, payoff naturally cannot measured, set Uij = 0.order approximate payoff arbitrary mix strategies infinite population distributed species according x, n individuals drawn randomlyinfinite distribution. probability selecting specific row Ni computedx NiknNP (Ni |x) =xj ij .Ni1 , Ni2 , . . . , Nikj=1expected payoff strategy i, fi (x), computed weighted combinationpayoffs given rows:Pj P (Nj |x)Ujifi (x) =.1 (1 xi )kexpected payoff function used Equation 5 compute evolutionarypopulation change according replicator dynamics.6.3.2 Value Information Marketsexample, consider market differently informed traders bid certainasset (Bloembergen et al., 2015). Depending information level, traderscertain amount foresight regarding future value stock. information givesbetter approximation real current value asset; however, information comesprice. use replicator dynamics model analyse effect various pricingschemes information, e.g. cost, fixed cost amount information, costfunction linear amount information. Traders also choose acquireadditional information instead rely solely current market price. runningmarket simulations different distributions information levels among traders,compute heuristic payoff table described above, use table basisreplicator model.Figure 10 shows resulting dynamics three types traders (uninformed ZI;averagely informed I3; insiders I9), three different cost functions describedabove. absence costs, best strategy obtain much information689fiBloembergen, Tuyls, Hennes, & KaisersF9ZIF9F3ZIF9F3ZIF3Figure 10: Vector field showing evolutionary dynamics market three information levels different cost functions information: cost (left), fixed cost (center),linear cost (right) (Bloembergen et al., 2015).possible, leading domination I9 traders entire interior simplex. Addingfixed costs gives small boost I0 traders (who pay), allowingsurvive equilibrium alongside insiders. linear cost function gives riseinternal equilibrium types coexist. analysis valuable toolgain insight dynamics stock markets, helps predict effect externalinfluences (such costs, e.g. form taxing schemes) market whole.6.3.3 Collision Avoidance Multi-robot SystemsAutonomous collision avoidance complex task field robotics, especiallypresence dynamic obstacles. task increases complexity dynamicobstacles mobile robots also take actions avoid collisions. However, assumingmutual avoidance (reciprocity) may potentially improve avoidance behaviour sincerobot needs take half responsibility avoiding pairwise collisions. ordertest hypothesis employ meta-strategy approach evaluateevolutionary strength different collision avoidance strategies (Hennes et al., 2013).One approach collision avoidance continuous spaces velocity obstacle (VO)paradigm, first introduced Fiorini Shiller (1998) local collision avoidancenavigation dynamic environments multiple moving objects. VO strategymodified include reciprocity, yielding reciprocal velocity obstacle (RVO); hybridtwo given HRVO. Figure 11 (left) shows evolutionary dynamicsresulting heuristic payoff table three strategies. pure population statesasymptotically stable fixed points replicator dynamics. Although basinattraction RVO considerably smaller, see clearly dominant strategysetting. pairwise comparison two strategies, along faces simplex,strategy inferior; three strategies evolutionarily stable.VO takes obstacles account, independent distance. may greatlyreduce mobility robots highly cluttered environment. order overcomeproblem, VO truncated ignore obstacles farther away. Truncationyields significantly different complex dynamics, shown Figure 11 (right).pairwise comparison (faces simplex), RVO dominated VO well HRVO.690fiEvolutionary Dynamics Multi-Agent LearningVOHRVOVORVOHRVORVOFigure 11: Evolutionary dynamics three strategies multi-robot collision avoidance,without truncation (left) truncation (right) (Hennes et al., 2013).However, reciprocal velocity obstacle robust presence three strategies(interior simplex), explained aggressive,least restricting, strategy.7. Conclusionsarticle surveyed recent advances study evolutionary dynamicsmulti-agent learning. particular, presented formal relation reinforcement learning replicator dynamics evolutionary game theory. modifyingstandard replicator dynamics, behaviour various state-of-the-art reinforcement learning algorithms multi-agent setting modelled accurately. far, linkestablished stateless environments (e.g. normal form games), discretecontinuous action spaces, multi-state environments (e.g. stochastic games)discrete action space. Therefore, important avenue future work extensiontheory stochastic games continuous action spaces.analytical study multi-agent learning dynamics offers several important advantages. particular, sheds light black box reinforcement learning, makingpossible analyse learning dynamics multi-agent systems detail, compare behaviour different algorithms principled manner. turn facilitatesimportant tasks parameter tuning. Furthermore, studying dynamics differentlearning algorithms helps selecting specific learner given problem. Moreover,possible derive new learning algorithms first designing preferred dynamics. Finally, theory applied complex strategic interactions real-world settingsanalysing meta-strategies, demonstrated automated trading multi-robot collisionavoidance.691fiBloembergen, Tuyls, Hennes, & KaisersAcknowledgmentsgrateful editor anonymous reviewers JAIR valuable feedbackhelpful suggestions.ReferencesAbdallah, S., & Kaisers, M. (2013). Addressing policy-bias Q-learning repeatingupdates. Proc. 2013 int. conf. Autonomous Agents Multi-AgentSystems (AAMAS 2013), pp. 10451052. International Foundation AAMAS.Abdallah, S., & Lesser, V. (2008). multiagent reinforcement learning algorithmnon-linear dynamics. Journal Artificial Intelligence Research, 33 (1), 521549.Agogino, A. K., & Tumer, K. (2012). multiagent approach managing air traffic flow.Autonomous Agents Multi-Agent Systems, 24 (1), 125.Ahmadi, M., & Stone, P. (2006). multi-robot system continuous area sweeping tasks.ICRA, pp. 17241729.Axelrod, R., & Hamilton, W. D. (1981). evolution cooperation. Science, 211 (4489),13901396.Bellman, R. (1957). Dynamic Programming. Princeton University Press.Bloembergen, D., Hennes, D., McBurney, P., & Tuyls, K. (2015). Trading marketsnoisy information: evolutionary analysis. Connection Science, appear.Bloembergen, D., Kaisers, M., & Tuyls, K. (2011). Empirical theoretical supportlenient learning. Tumer, Yolum, Sonenberg, & Stone (Eds.), Proc. 10th Intl.Conf. Autonomous Agents Multiagent Systems (AAMAS 2011), pp. 11051106. International Foundation AAMAS.Blum, A., & Mansour, Y. (2007). Learning, regret minimization equilibria. CambridgeUniversity Press.Blum, A., & Monsour, Y. (2007). external internal regret. Journal MachineLearning Research, 8, 13071324.Borgers, T., & Sarin, R. (1997). Learning reinforcement replicator dynamics.Journal Economic Theory, 77 (1).Bowling, M., & Veloso, M. (2002). Multiagent learning using variable learning rate.Artificial Intelligence, 136, 215250.Bowling, M. (2005). Convergence no-regret multiagent learning. Advances neuralinformation processing systems, 17, 209216.Bowling, M., & Veloso, M. (2001). Rational convergent learning stochastic games.Proc. 17th Intl. Joint Conf. Artificial Intelligence, pp. 10211026.Brown, G. W. (1951). Iterative solution games fictitious play. Activity analysisproduction allocation, 13 (1), 374376.692fiEvolutionary Dynamics Multi-Agent LearningBusoniu, L., Babuska, R., & De Schutter, B. (2008). comprehensive survey multiagentreinforcement learning. IEEE Transactions Systems, Man, Cybernetics, PartC: Applications Reviews, 38 (2), 156172.Busoniu, L., Babuska, R., De Schutter, B., & Ernst, D. (2010). Reinforcement learningdynamic programming using function approximators. CRC Press.Chalkiadakis, G., & Boutilier, C. (2003). Coordination multiagent reinforcement learning:Bayesian approach. Proc. 2nd intl. joint conf. Autonomous AgentsMultiAgent Systems, pp. 709716. ACM.Claes, D., Hennes, D., Tuyls, K., & Meeussen, W. (2012). Collision avoidance boundedlocalization uncertainty. IROS, pp. 11921198.Claus, C., & Boutilier, C. (1998). dynamics reinforcement learning cooperativemultiagent systems. AAAI/IAAI, pp. 746752.Conitzer, V., & Sandholm, T. (2007). Awesome: general multiagent learning algorithmconverges self-play learns best response stationary opponents.Machine Learning, 67 (1-2), 2343.Cressman, R. (2005). Stability replicator equation continuous strategy space.Mathematical Social Sciences, 50 (2), 127147.Cross, J. G. (1973). stochastic learning model economic behavior. QuarterlyJournal Economics, 87 (2), 239266.Dearden, R., Friedman, N., & Russell, S. (1998). Bayesian Q-learning. AAAI/IAAI.Ernst, D., Geurts, P., & Wehenkel, L. (2005). Tree-based batch mode reinforcement learning.Journal Machine Learning Research, pp. 503556.Fiorini, P., & Shiller, Z. (1998). Motion planning dynamic environments using velocityobstacles. International Journal Robotics Research, 17, 760772.Fulda, N., & Ventura, D. (2007). Predicting preventing coordination problems cooperative Q-learning systems.. Proceedings International Joint ConferenceArtificial Intelligence (IJCAI-07), Vol. 2007, pp. 780785.Galstyan, A. (2013). Continuous strategy replicator dynamics multi-agent q-learning.Autonomous agents multi-agent systems, 26 (1), 3753.Gatti, N., Panozzo, F., & Restelli, M. (2013). Efficient evolutionary dynamicsextensive-form games. Twenty-Seventh AAAI Conference Artificial Intelligence,pp. 335341.Gibbons, R. (1992). Primer Game Theory. Pearson Education.Gintis, H. (2009). Game Theory Evolving (2nd edition). University Press, Princeton NJ.Gomes, E. R., & Kowalczyk, R. (2009). Dynamic analysis multiagent Q-learning-greedy exploration. Proceedings 26th Annual International ConferenceMachine Learning, pp. 369376. ACM.Hennes, D., Bloembergen, D., Kaisers, M., Tuyls, K., & Parsons, S. (2012). Evolutionaryadvantage foresight markets. Proceedings Genetic EvolutionaryComputation Conference (GECCO 2012), pp. 943950.693fiBloembergen, Tuyls, Hennes, & KaisersHennes, D., Claes, D., & Tuyls, K. (2013). Evolutionary advantage reciprocity collision avoidance. Proc. AAMAS 2013 Workshop Autonomous RobotsMultirobot Systems (ARMS 2013).Hennes, D., Kaisers, M., & Tuyls, K. (2010). RESQ-learning stochastic games.Adaptive Learning Agents Workshop AAMAS 2010, p. 8.Hennes, D., Tuyls, K., & Rauterberg, M. (2008). Formalizing multi-state learning dynamics. Proceedings 2008 IEEE/WIC/ACM International Conference WebIntelligence Intelligent Agent Technology, pp. 266272. IEEE Computer Society.Hennes, D., Tuyls, K., & Rauterberg, M. (2009). State-coupled replicator dynamics. Proceedings 8th International Conference Autonomous Agents MultiagentSystems-Volume 2, pp. 789796. International Foundation Autonomous AgentsMultiagent Systems.Hofbauer, J., & Sigmund, K. (1998). Evolutionary games population dynamics. Cambridge University Press.Howell, M. N., Frost, G. P., Gordon, T. J., & Wu, Q. H. (1997). Continuous action reinforcement learning applied vehicle suspension control. Mechatronics, 7 (3), 263276.Hu, J., & Wellman, M. P. (2003). Nash q-learning general-sum stochastic games.Journal Machine Learning Research, 4, 10391069.Kaelbling, L., Littman, M., & Moore, A. (1996). Reinforcement learning: survey. JournalArtificial Intelligence Research, 4, 237285.Kaisers, M., & Tuyls, K. (2010). Frequency adjusted multi-agent Q-learning. Proc.9th Intl. Conf. Autonomous Agents Multiagent Systems (AAMAS 2010), pp.309315.Kaisers, M. (2012). Learning Learning - Evolutionary Dynamics ReinforcementLearning Algorithms Strategic Interactions. Ph.D. thesis, Maastricht University.Kaisers, M., Bloembergen, D., & Tuyls, K. (2012). common gradient multi-agent reinforcement learning. Proc. 11th Int. Conf. Autonomous Agents MultiagentSystems (AAMAS 2012), pp. 13931394.Kaisers, M., & Tuyls, K. (2011). Faq-learning matrix games: Demonstrating convergencenear nash equilibria, bifurcation attractors battle sexes. WorkshopInteractive Decision Theory Game Theory (IDTGT 2011). Assoc.Advancement Artif. Intel. (AAAI).Kaisers, M., Tuyls, K., Parsons, S., & Thuijsman, F. (2009). evolutionary modelmulti-agent learning varying exploration rate. Proc. 8th Intl. Conf.Autonomous Agents Multiagent Systems (AAMAS 2009), pp. 12551256. International Foundation Autonomous Agents Multiagent Systems.Kapetanakis, S., & Kudenko, D. (2002). Reinforcement learning coordination cooperative multi-agent systems. AAAI/IAAI, 2002, 326331.Kianercy, A., & Galstyan, A. (2012). Dynamics boltzmann Q learning two-playertwo-action games. Phys. Rev. E, 85 (4), 041145.694fiEvolutionary Dynamics Multi-Agent LearningKlos, T., Van Ahee, G. J., & Tuyls, K. (2010). Evolutionary dynamics regret minimization. Machine Learning Knowledge Discovery Databases, pp. 8296.Springer.Lanctot, M. (2014). developments extensive-form replicator dynamics usingsequence-form representation. Proceedings 2014 international conferenceAutonomous agents multi-agent systems, pp. 12571264. International FoundationAutonomous Agents Multiagent Systems.Littman, M. L. (1994). Markov games framework multi-agent reinforcement learning.. ICML, Vol. 94, pp. 157163.Maynard Smith, J., & Price, G. R. (1973). logic animal conflict. Nature, 246 (2),1518.Mihaylov, M., Tuyls, K., & Nowe, A. (2014). decentralized approach conventionemergence multi-agent systems. Autonomous Agents Multi-Agent Systems,28 (5), 749778.Narendra, K. S., & Thathachar, M. A. L. (1974). Learning automata - survey. IEEETransactions Systems, Man, Cybernetics, 4 (4), 323334.Oechssler, J., & Riedel, F. (2001). Evolutionary dynamics infinite strategy spaces. Economic Theory, 17 (1), 141162.Panait, L., Tuyls, K., & Luke, S. (2008). Theoretical advantages lenient learners:evolutionary game theoretic perspective. Journal Machine Learning Research, 9,423457.Panait, L., & Luke, S. (2005). Cooperative multi-agent learning: state art.Autonomous Agents Multi-Agent Systems, 11 (3), 387434.Panozzo, F., Gatti, N., & Restelli, M. (2014). Evolutionary dynamics Q-learningsequence form. Twenty-Eighth AAAI Conference Artificial Intelligence, pp.20342040.Phelps, S., Parsons, S., & McBurney, P. (2005). evolutionary game-theoretic comparisontwo double-auction market designs. Faratin, P., & Rodrguez-Aguilar, J. (Eds.),Agent-Mediated Electronic Commerce VI. Theories Engineering DistributedMechanisms Systems, Vol. 3435 Lecture Notes Computer Science, pp. 101114. Springer Berlin Heidelberg.Pipattanasomporn, M., Feroze, H., & Rahman, S. (2009). Multi-agent systems distributed smart grid: Design implementation. Power Systems ConferenceExposition, pp. 18. IEEE.Ponsen, M., Tuyls, K., Kaisers, M., & Ramon, J. (2009). evolutionary game-theoreticanalysis poker strategies. Entertainment Computing, 1 (1), 3945.Puterman, M. L. (1994). Markov decision processes: Discrete dynamic stochastic programming. John Wiley & Sons, New York.Rodrguez, A., Vrancx, P., Grau, R., & Nowe, A. (2012). RL approach commoninterest continuous action games. Proceedings 11th International Conference695fiBloembergen, Tuyls, Hennes, & KaisersAutonomous Agents Multiagent Systems, pp. 14011402. International Foundation Autonomous Agents Multiagent Systems.Ruijgrok, M., & Ruijgrok, T. W. (2005). Replicator dynamics mutations gamescontinuous strategy space. arXiv preprint nlin/0505032.Santharam, G., Sastry, P. S., & Thathachar, M. A. L. (1994). Continuous action set learningautomata stochastic optimization. Journal Franklin Institute, 331 (5), 607628.Schaerf, A., Shoham, Y., & Tennenholtz, M. (1995). Adaptive load balancing: studymulti-agent learning. J. Artif. Intell. Res. (JAIR), 2, 475500.Shoham, Y., Powers, R., & Grenager, T. (2007). multi-agent learning answer,question?. Artificial Intelligence, 171 (7), 365377.Singh, S., Kearns, M., & Mansour, Y. (2000). Nash convergence gradient dynamicsgeneral-sum games. Proceedings Sixteenth conference Uncertaintyartificial intelligence, pp. 541548. Morgan Kaufmann Publishers Inc.Skyrms, B. (2004). stag hunt evolution social structure. Cambridge UniversityPress.Strens, M. (2000). Bayesian framework reinforcement learning. ICML, pp. 943950.Sutton, R., & Barto, A. (1998). Reinforcement Learning: introduction. MA: MIT Press,Cambridge.Hoen, P. J., Tuyls, K., Panait, L., Luke, S., & Poutre, J. A. L. (2005). overviewcooperative competitive multiagent learning. LAMAS, pp. 146.Tesauro, G. (2003). Extending q-learning general adaptive multi-agent systems..NIPS, Vol. 4.Thathachar, M., & Sastry, P. S. (2002). Varieties learning automata: overview. IEEETransactions Systems, Man, Cybernetics, Part B: Cybernetics, 32 (6), 711722.Tuyls, K., Hoen, P. J., & Vanschoenwinkel, B. (2006). evolutionary dynamical analysis multi-agent learning iterated games. Autonomous Agents Multi-AgentSystems, 12, 115153.Tuyls, K., Heytens, D., Nowe, A., & Manderick, B. (2003). Extended replicator dynamicskey reinforcement learning multi-agent systems. Machine Learning: ECML2003, pp. 421431. Springer.Tuyls, K., & Nowe, A. (2005). Evolutionary game theory multi-agent reinforcementlearning. Knowledge Engineering Review, 20 (01), 6390.Tuyls, K., & Parsons, S. (2007). evolutionary game theory tells us multiagentlearning. Artificial Intelligence, 171 (7), 406416.Tuyls, K., Verbeeck, K., & Lenaerts, T. (2003). selection-mutation model q-learningmulti-agent systems. Proc. 2nd Intl. Conf. Autonomous Agents Multiagent Systems (AAMAS 2003), pp. 693700, New York, NY, USA. ACM.Tuyls, K., & Weiss, G. (2012). Multiagent learning: Basics, challenges, prospects. AIMagazine, 33 (3), 41.696fiEvolutionary Dynamics Multi-Agent LearningTuyls, K., & Westra, R. (2009). Replicator dynamics discrete continuous strategyspaces. Uhrmacher, A. M., & Weyns, D. (Eds.), Multi-Agent Systems: SimulationApplications, pp. 215240. CRC Press.Van Kampen, N. (1992). Stochastic Processes Physics Chemistry. Elsevier SciencePublishers, Amsterdam.Verbeeck, K., Nowe, A., & Tuyls, K. (2005). Coordinated exploration multi-agent reinforcement learning: application load-balancing. AAMAS, pp. 11051106.Von Neumann, J., & Morgenstern, O. (1944). Theory Games Economic Behavior.Princeton University Press.Vrancx, P., Tuyls, K., Westra, R., & Nowe, A. (2008a). Switching dynamics multi-agentlearning. Proc. 7th intl. joint conf. autonomous agents multiagent systems (AAMAS 2008), pp. 307313. International Foundation Autonomous AgentsMultiagent Systems.Vrancx, P., Verbeeck, K., & Nowe, A. (2008b). Decentralized learning markov games.Systems, Man, Cybernetics, Part B: Cybernetics, IEEE Transactions on, 38 (4),976981.Walsh, W., Das, R., Tesauro, G., & Kephart, J. (2002). Analyzing complex strategic interactions multi-agent systems. AAAI-02 Workshop Game-TheoreticDecision-Theoretic Agents.Watkins, C. J. C. H., & Dayan, P. (1992). Q-learning. Machine Learning, 8 (3), 279292.Weibull, J. W. (1997). Evolutionary game theory. MIT press.Wheeler Jr, R., & Narendra, K. S. (1986). Decentralized learning finite markov chains.IEEE Transactions Automatic Control, 31 (6), 519526.Whiteson, S., & Stone, P. (2006). Evolutionary function approximation reinforcementlearning. Journal Machine Learning Research, 7, 877917.Wiegand, R. P. (2003). Analysis Cooperative Coevolutionary Algorithms. Ph.D.thesis, George Mason University.Wunder, M., Littman, M. L., & Babes, M. (2010). Classes multiagent q-learning dynamicsepsilon-greedy exploration. Proceedings 27th International ConferenceMachine Learning (ICML-10), pp. 11671174.Zinkevich, M. (2003). Online convex programming generalized infinitesimal gradientascent. Proc. 20th Intl. Conf. Machine Learning (ICML-2003).697fiJournal Artificial Intelligence Research 53 (2015) 745-778Submitted 02/15; published 08/15AutoFolio:Automatically Configured Algorithm SelectorMarius Lindauerlindauer@cs.uni-freiburg.deUniversity FreiburgHolger H. Hooshoos@cs.ubc.caUniversity British ColumbiaFrank Hutterfh@cs.uni-freiburg.deUniversity FreiburgTorsten Schaubtorsten@cs.uni-potsdam.deUniversity PotsdamINRIA RennesAbstractAlgorithm selection (AS) techniques involve choosing set algorithmsone expected solve given problem instance efficiently substantiallyimproved state art solving many prominent AI problems, SAT, CSP,ASP, MAXSAT QBF. Although several procedures introduced,surprisingly, none dominates others across scenarios. Furthermore,procedures parameters whose optimal values vary across scenarios. holdsspecifically machine learning techniques form core current procedures, hyperparameters. Therefore, successfully apply new problems,algorithms benchmark sets, two questions need answered: (i) selectapproach (ii) set parameters effectively. address problemssimultaneously using automated algorithm configuration. Specifically, demonstrateautomatically configure claspfolio 2, implements large varietydifferent approaches respective parameters single, highly-parameterizedalgorithm framework. approach, dubbed AutoFolio, allows researchers practitioners across broad range applications exploit combined power many differentmethods. demonstrate AutoFolio significantly improve performanceclaspfolio 2 8 13 scenarios Algorithm Selection Library, leadsnew state-of-the-art algorithm selectors 7 scenarios, matches state-ofthe-art performance (statistically) scenarios. Compared best singlealgorithm scenario, AutoFolio achieves average speedup factors 1.315.4.1. Introductionlast decade, tremendous progress Boolean constraint solving technologyachieved several areas within AI, SAT (Biere, 2013), ASP (Gebser, Kaufmann,& Schaub, 2012), CSP (Tamura, Taga, Kitagawa, & Banbara, 2009), Max-SAT (Abrame& Habet, 2014) QBF (Janota, Klieber, Marques-Silva, & Clarke, 2012).areas, multiple algorithms complementary solving strategies exist, none dominates others kinds problem instances. fact exploited algorithm selection (AS) (Rice, 1976) methods, use characteristics individual probc2015AI Access Foundation. rights reserved.fiLindauer, Hoos, Hutter, & Schaublem instances (so-called instance features) choose promising algorithm instance. Algorithm selectors empirically shown improve state artsolving heterogeneous instance sets and, result, many prizes competitions. instance, SATzilla (Xu, Hutter, Hoos, & Leyton-Brown, 2008) severalcategories multiple SAT competitions, claspfolio 1 (Gebser, Kaminski, Kaufmann,Schaub, Schneider, & Ziller, 2011b) NP-track 2011 ASP Competition, CPHydra (OMahony, Hebrard, Holland, Nugent, & OSullivan, 2008) 2008 CSPcompetition, ISAC++ (Ansotegui, Malitsky, & Sellmann, 2014) partial Max-SATCrafted Industrial track 2014 Max-SAT Competition, AQME (Pulina &Tacchella, 2009) first stage main track 2010 QBF Competition.Although many new approaches proposed years (cf. Smith-Miles,2008; Kotthoff, 2014), two flexible frameworks allow re-implementingcomparing existing approaches fair uniform way: LLAMA (Kotthoff, 2013)claspfolio 2 (Hoos, Lindauer, & Schaub, 2014). these, claspfolio 2comprehensive, encompassing strategies algorithm selection systems 3S (Kadioglu,Malitsky, Sabharwal, Samulowitz, & Sellmann, 2011), aspeed (Hoos, Kaminski, Lindauer,& Schaub, 2015), claspfolio 1 (Gebser et al., 2011b), ISAC (Kadioglu, Malitsky, Sellmann, & Tierney, 2010), ME-ASP (Maratea, Pulina, & Ricca, 2014), SNNAP (Collautti,Malitsky, Mehta, & OSullivan, 2013) SATzilla (Xu et al., 2008; Xu, Hutter, Hoos,& Leyton-Brown, 2011).Figure 1 illustrates performance benefits existing selection strategies (as realized claspfolio 2) yield across wide range benchmarks Algorithm Selection Library (Bischl et al., 2015b, 2015a). observe approach strengthsweaknesses different scenarios. SATzilla11-like approach (the defaultclaspfolio 2) performs best overall, achieves better performanceapproaches considered 8 13 scenarios, 3S, aspeed ISAC yieldingbetter performance remaining cases.note selection approaches used fixed default parameterconfiguration might therefore fall short full performance potential. example, imputation missing instance features used approaches considered Figure 1; use improve performance scenarios (e.g.,ASP-POTASSCO), yields improvements others (e.g., SAT12-RAND,SATzilla11-like approach plus mean imputation outperforms single best algorithmfactor 1.2).Generally, well known performance many machine learning techniquesdepends hyper-parameter settings (e.g., case SVM, kernel, kernel hyperparameter soft margin; cf. Bergstra, Bardenet, Bengio, & Kegl, 2011; Snoek, Larochelle,& Adams, 2012; Thornton, Hutter, Hoos, & Leyton-Brown, 2013). However, hyperparameters machine learning models used Figure 1 fixed manually, basedlimited experiments. Therefore, performance algorithm selection systemsconsidered could likely improved using carefully chosen hyper-parametersettings.Facing new algorithm selection problem, thus answer three salient questions: (i) selection approach use; (ii) set parameters selectionapproach (and underlying machine learning model) effectively; (iii) make746filio-1.0-lISAikeC-like-ASP-likeSATzilla'09-likSAeTzilla'11-likAuetoFoliclaspfoaspee3S-likeAutoFolio: Automatically Configured Algorithm SelectorASP-POTASSCOCSP-2010MAXSAT12-PMSPREMARSHALLINGPROTEUS-2014QBF-2011SAT11-HANDSAT11-INDUSAT11-RANDSAT12-ALLSAT12-HANDSAT12-INDUSAT12-RAND4.11.56.52.910.97.72.61.23.91.51.71.20.81.41.02.73.66.34.93.61.14.71.11.80.80.82.82.11.61.23.52.31.11.21.21.21.11.20.63.82.14.91.34.32.81.21.32.51.11.11.20.91.92.62.11.13.12.81.01.21.81.11.01.10.92.92.53.41.54.93.71.91.12.61.41.51.30.94.23.18.62.36.59.82.31.23.81.81.91.30.94.23.28.63.57.810.13.21.515.43.03.21.81.3geo. mean2.62.01.51.91.52.02.83.9Figure 1: Factors selection approach re-implemented claspfolio 2 outperformed single best algorithm 13 ASlib scenarios w.r.t. penalized average runtime(PAR10, counts timeout 10 times given runtime cutoff). results10-fold cross-validation, ignoring test instances solved solver.last row shows geometric mean 13 scenarios.best use techniques augmenting pure AS, pre-solving schedules (Xu et al., 2008;Kadioglu et al., 2011). Instead common, manual trial-and-error approach, propose automatically answer questions using automated algorithm configurationmethods (Hutter, Hoos, Leyton-Brown, & Stutzle, 2009) configure flexible frameworks. manual approach error-prone, potentially biased requires substantial human expert time knowledge, approach introduce fully automatic,unbiased, leverages full power broad range methods. thus facilitateseasier effective use algorithm selection makes techniques accessiblebroader community.Specifically, present AutoFolio, general approach automatically determiningstrong algorithm selection method particular dataset, using algorithm configurationsearch flexible design space algorithm selection methods. also provideopen-source implementation AutoFolio (www.ml4aad.org/autofolio/) basedalgorithm configurator SMAC (Hutter, Hoos, & Leyton-Brown, 2011) algorithmselection framework claspfolio 2 (Hoos et al., 2014). last column Figure 1 previewsresults obtained AutoFolio clearly shows significant improvementsclaspfolio 2 10 13 scenarios ASlib.747fiLindauer, Hoos, Hutter, & SchaubInstanceAlgorithmPortfolioComputeFeaturesSelect AlgorithmSolve InstanceAlgorithmFigure 2: General outline algorithm selection.2. Background: Algorithm Configuration Selectionsection, briefly introduce standard approaches algorithm selection algorithm configuration form basis AutoFolio approach.2.1 Algorithm SelectionFigure 2 shows general outline algorithm selection (Rice, 1976). given probleminstance, first compute cheap instance features; numerical characteristics,including simple ones (such number variables clauses SAT instance)complex ones (such statistics gathered short probing runs actual SATsolver given instance). Based features, appropriate algorithmalgorithm portfolio (Huberman, Lukose, & Hogg, 1997; Gomes & Selman, 2001) selectedsolve given instance. overall workflow subject runtime cutoff.One major challenge algorithm selection find good mapping instancefeatures algorithms. general offline algorithm selection approach consider,done based training data. Specifically, given portfolio algorithms setproblem instances I, use training data performance matrix size #I #Afeature matrix containing fixed-size feature vector I. Based trainingdata, learn mapping instance features algorithms using machine learningtechniques, k-NN (Maratea et al., 2014), g-means (Kadioglu et al., 2010) randomforests (Xu et al., 2011).2.1.1 Related Work Algorithm Selection SystemsRecent successful algorithm selection systems include SATzilla (Xu et al., 2008; Xu, Hutter, Hoos, & Leyton-Brown, 2012a), 3S (Kadioglu et al., 2011; Malitsky, Sabharwal, Samulowitz, & Sellmann, 2012, 2013b), ISAC (Kadioglu et al., 2010; Ansotegui et al., 2014),CSHC (Malitsky, Sabharwal, Samulowitz, & Sellmann, 2013a) claspfolio 1 (Gebseret al., 2011b). recent years, systems showed excellent performance competitionsSAT, MAXSAT ASP. briefly review following.original version pioneering algorithm selection system SATzilla (Xu et al.,2008) learned mapping instance features algorithms training ridge regression models. regression model predicts performance algorithm giveninstance. Based predicted performances, SATzilla selects algorithmbest predicted performance. SATzillas latest version (Xu et al., 2011) uses classificationmodels that, pair algorithms, predict better-performing one, selectsalgorithm run using simple voting predictions thus obtained. modelsalso cost-sensitive, is, training instance pairwise classification models748fiAutoFolio: Automatically Configured Algorithm Selectorweighted performance loss incurred selecting worse two algorithms.Furthermore, SATzilla introduced concept pre-solving schedules, is, shortinstance-independent schedule algorithms running limited amount time. onealgorithm pre-solving schedule solves given instance, SATzilla immediatelyterminate successfully, saving time required compute instance features. Furthermore,pre-solving schedules increase robustness algorithm selectors relyingone selected algorithm also pre-solvers solve given instance. One drawbackSATzilla use grid search possible pre-solving schedules threepre-solvers; schedule considered, SATzilla performs algorithm subset selectiontrains classification models, require substantial amounts time (inexperiments, 4 CPU days).3S (Kadioglu et al., 2011; Malitsky et al., 2012, 2013b) uses k-nearest neighbourapproach select algorithm. given problem instance solved, determinesset similar training instances instance feature space selects algorithmbest performance instance set. performance k-NN approachimproved distance-based weighting (that is, weighting algorithm performanceinstance instances distance new given instance) using clusteringbased adaptive neighbourhood size (to adjust size neighbourhood differentareas feature space). Furthermore, 3S uses mixed integer programming computepre-solving schedules efficiently SATzilla.ISAC (Kadioglu et al., 2010) clusters instances instance feature space usingg-means algorithm stores cluster centre well best-performing algorithmcluster. new problem instance, determines nearest cluster centre(1-NN) selects algorithm associated it.cost-sensitive hierarchical clustering system CSHC (Malitsky et al., 2013a) alsopartitions feature space clusters, instead ISACs unsupervised clusteringapproach, creates partitioning supervised top-down fashion, much like decisionregression tree algorithm. Starting instances (the entire feature space)root tree, recursively splits instances associated node two childnodes, choosing split along single feature value, performancebest-performing algorithm child node optimized. cost-sensitive supervisedapproach based trees closely resembles cost-sensitive random forests SATzilla,difference that, contrast SATzillas pairwise voting approach, buildssingle model.Last least, claspfolio 1 (Gebser et al., 2011b) predecessor claspfolio 2, use (and describe Section 2.1.2). contrast flexible framework claspfolio 2, claspfolio 1 inspired earlier version SATzillauses regression approach, different machine learning method (supportvector regression instead ridge regression).systems algorithm selection combine extend techniques, example, combining regression clustering approaches (Collautti et al., 2013),selecting algorithm portfolios (Yun & Epstein, 2012; Lindauer, Hoos, & Hutter, 2015a)schedules (Amadini, Gabbrielli, & Mauro, 2014) instead single algorithm. additional information, refer interested reader two recent surveys algorithmselection (Smith-Miles, 2008; Kotthoff, 2014).749fiLindauer, Hoos, Hutter, & SchaubFeatureGeneratorTraining InstancesAlgorithmsInstance FeaturesGroupsAlgorithmPerformanceASlib ScenarioFeaturePreprocessingPerformancePreprocessingTrainSelection Model(s)Performance EstimationPre-Solving ScheduleaspeedSelectionSchedulingOffline Training(Test) InstanceCompute FeaturesSelect AlgorithmfailedRun BackupAlgorithmRun Pre-SolvingSchedulesuccessfulRun SelectedAlgorithmOnline SolvingFigure 3: General workflow claspfolio 2. Objects algorithms instancesshown rectangles, activities depicted rectangles rounded corners.Activities related algorithm selection shown red activities related algorithmschedules yellow.2.1.2 Algorithm Selection Framework claspfolio 2explain algorithm selection framework claspfolio 2 (Hoos et al., 2014; Lindauer, Hoos, & Schaub, 2015c) detail, since provides basisconcrete implementation general AutoFolio approach, used experiments.claspfolio 2 framework implements idea algorithm selection flexiblegeneral way. provides general view individual components algorithmselectors, based implements many different selection approaches associatedtechniques. Therefore, claspfolio 2 natural candidate serve basisAutoFolio approach.Figure 3 shows workflow claspfolio 2, divided ASlib Scenarioinput claspfolio 2; Offline Training Selection Scheduling; Online Solvingnew instance:ASlib scenario. input, claspfolio 2 reads algorithm selection scenario, supporting format Algorithm Selection library, ASlib. consistsperformance matrix, instance features, groups instance features1 optional information, cross-validation splits ground truth problem1. note that, according definition ASlib, feature group enables list instance featurescomputed common block feature computation code, jointly incur costrunning code.750fiAutoFolio: Automatically Configured Algorithm Selectorinstances (for example, whether SAT instance satisfiable unsatisfiable).full specification ASlib format, refer interested reader aslib.net.Offline training selection. Based given scenario (training) data, claspfolio 2pre-processes instance features (for example, normalization feature imputation)performance data (for example, log-transformation). Using machine learningtechniques, claspfolio 2 learns selection model maps instance featuresalgorithms.Offline training scheduling. compute efficient pre-solving schedule, claspfolio 2 first estimates performance Selection module using internalcross-validation training data (Arrow I). Based performance estimation,claspfolio 2 computes timeout-minimal pre-solving schedule using Answer SetProgramming aspeed (Hoos et al., 2015), assigning algorithm (potentiallyzero-length) time slice overall runtime budget. estimation Selectionmodule necessary compute runtime budget pre-solving schedule.Selection module performs well, pre-solving schedule may empty,pre-solving schedule cannot perform better perfect predictor (that is, predictor always selects best solver). contrast, prediction performspoorly (for example, result non-informative instance features), pre-solvingschedule may allocated complete time budget, Selection moduleignored.Online solving. Solving workflow follows: feature generator computesinstance features new problem instance solved; computation fails(for example, time memory constraints) feature imputationstrategy selected, backup solver i.e., single best performing solveroffline training run instance; otherwise, previously trained selectionmodel uses instance features select algorithm expected perform well.pre-solving schedule available, schedule runs either instance featurecomputation selection algorithm, depending parameter settingclaspfolio 2 latter version shown Figure 3. formeradvantage time compute instance features saved instancesolved pre-solving. latter advantage algorithm chosenselector removed pre-solving schedule prevent running twice.list techniques implemented modules given Section 3.2.2.2 Algorithm ConfigurationFigure 4 shows general outline algorithm configuration methods. Given parameterized algorithm possible parameter settings C, set training problem instancesI, performance metric : C R, objective algorithm configurationproblem find parameter configuration c C minimizes across instancesI. Prominent examples performance metric optimized runtime,solution quality, misclassification cost target algorithm achieves. configuration751fiLindauer, Hoos, Hutter, & SchaubInstancesAlgorithmConfiguration Space CSelect c CAssess A(c)0ReturnsBest FoundConfiguration cReturn PerformanceConfiguration TaskFigure 4: General outline algorithm configuration.procedure (or short configurator ) iteratively evaluates performance parameter configurations c C (by running one instances I) usesresult decide next configurations evaluate. given budget configuration process exhausted, configurator returns best known parameterconfiguration found then.n parameters p1 , . . . , pn , respective domains D1 , . . . , Dn , parameterconfiguration space C = D1 Dn cross-product domains,parameter configuration c C assigns value parameter. several typesparameters, including real-valued, integer-valued categorical ones (which finite,unordered domain; example, choice different machine learning algorithms).Furthermore, configuration spaces structured; specifically, parameter piconditional another parameter pj , value pi relevant parentparameter pj set specific value. example, case pj categoricalchoice machine learning algorithms, pi sub-parameter onealgorithms; pi active pj chooses algorithm parameterizes further.date, four general configuration procedures: ParamILS (Hutter et al.,2009), GGA (Ansotegui, Sellmann, & Tierney, 2009), irace (Lopez-Ibanez, Dubois-Lacoste,Stutzle, & Birattari, 2011), SMAC (Hutter et al., 2011). principle, could useconfigurator general AutoFolio approach. practice,found SMAC often yield better results ParamILS GGA (Hutter et al., 2011;Hutter, Lindauer, Balint, Bayless, Hoos, & Leyton-Brown, 2015; Lindauer, Hoos, Hutter, &Schaub, 2015b), thus use basis concrete implementation AutoFoliodiscussed following. describe SMAC detail.2.2.1 SMAC: Sequential Model-Based Algorithm Configurationsequential model-based algorithm configuration method SMAC (Hutter et al., 2011;Hutter, Hoos, & Leyton-Brown, 2015a) uses regression models approximate performance metric : C R (Hutter, Xu, Hoos, & Leyton-Brown, 2014). followsgeneral algorithm configuration workflow above, alternating evaluationsparameter configurations instances decision phases, configurator usesdata gathered far select configurations evaluate next instances.SMACs decision phases involve constructing regression model : C R baseddata observed far, using model (as well models uncertaintypredictions) select promising configurations try next. step automatically752fiAutoFolio: Automatically Configured Algorithm Selectortrades exploration (evaluating regions configuration space modeluncertain) exploitation (evaluating configurations predicted perform well).order save time evaluating new configurations cnew C, SMAC first evaluatessingle instance I; additional evaluations carried (using doublingschedule) if, based evaluations date, cnew appears outperform SMACs bestknown configuration c. evaluated number runs cnew c,cnew still performs better, SMAC updates best known configuration c cnew .2.2.2 Previous Applications Algorithm ConfigurationAlgorithm configuration demonstrated effective optimizing algorithms wide range problems, including SAT-based formal verification (Hutter, Babic,Hoos, & Hu, 2007), timetabling (Chiarandini, Fawcett, & Hoos, 2008), multi-objective optimization (Lopez-Ibanez & Stutzle, 2010), mixed integer programming (Hutter, Hoos, &Leyton-Brown, 2010), AI planning (Vallati, Fawcett, Gerevini, Hoos, & Saetti, 2013), generation heuristics (Mascia, Lopez-Ibanez, Dubois-Lacoste, & Stutzle, 2014), occupancyscheduling (Lim, van den Briel, Thiebaux, Backhaus, & Bent, 2015) kidney exchangematching (Dickerson & Sandholm, 2015). important special case algorithm configuration hyperparameter optimization machine learning (Bergstra et al., 2011; Snoeket al., 2012; Eggensperger et al., 2013).previous line work related application configuration algorithmselection Auto-WEKA (Thornton et al., 2013). Auto-WEKA addresses combinedproblem selecting machine learning algorithm WEKA framework (Hall, Frank,Holmes, Pfahringer, Reutemann, & Witten, 2009) optimizing hyperparameters.AutoFolio also needs solve combined algorithm selection hyperparameteroptimization problem, particular needs problem formulationsconsiders: regression, classification clustering. important design choicesAutoFolio pre-solving parameters, well instance features use.AutoFolio applies one meta-solving strategy (algorithm configuration) another one(algorithm selection). previous application meta-solving strategy selfconfiguration ParamILS (Hutter et al., 2009). However, case, self-configurationyielded modest improvement default configuration ParamILS, whereashere, achieve substantial improvements default configuration claspfolio 2.Algorithm configuration algorithm selection previously combineddifferent way, using configuration find good parameter settings highly parameterized algorithm, using selection choose per-instancebasis. Two systems implement approach date: ISAC (Kadioglu et al., 2010)Hydra (Xu, Hoos, & Leyton-Brown, 2010). ISAC first clusters training problem instanceshomogeneous subsets, uses configurator find good solver parameterizationcluster, uses selector choose parameterizations. Hydraiteratively adds new solver parameterizations initially empty portfolio-based selector,step tasking configurator find solver parameterization improvescurrent portfolio.753fiLindauer, Hoos, Hutter, & SchaubTraining DataTest Data10-fold cross-validation = 10 meta instancesFigure 5: Split instance sets algorithm selection scenarios; cross-validation performedinside configuration process, test set withheld evaluating configured selector.3. Configuration Algorithm Selectorspresent AutoFolio approach using algorithm configurators automaticallycustomize flexible algorithm selection (AS) frameworks specific scenarios. applyalgorithm configuration context, need specify parameterized selectorconfiguration space, well performance metric judge performance.3.1 Formal Problem Statementjudge performance algorithm selection (AS) system scenario,crucial partition given set problem instances training test set, usesystem training set train selector s, evaluate testset instances. (If training set instead used evaluate performance, perfectsystem could simply memorize best solver instance without learning anythinguseful new problem instances). standard notion training-test splitmachine learning.scenario includes algorithms A, problem instances I, performance featuredata D, loss function l : R minimized (for example, algorithmsruntime solution cost), data split disjoint sets Dtrain Dtest . LetS(Dtrain ) : denote selector learned system trained dataDtrain . Then, performance S, P (S) average performance algorithmsselects instances test data set Dtest :P (S) =X1l(S(Dtrain ), i).|Dtest |(1)iDtestLikewise, evaluate performance system Sc parameterizedconfiguration c P (Sc ). However, perform algorithm configuration simplyminimizing P (Sc ) respect c C: would amount peeking test setmany times, even though would yield configuration c low P (Sc ), couldexpected perform well instances contained Dtest . Instead, orderobtain unbiased evaluation configured selectors performance end, needhold back test set instances touched configuration process.order still able optimize parameters without access test set, standardsolution machine learning partition training set further, k cross-validationfolds. Overall, use instance set selection scenario illustrated Figure 5:(i) split full set instances training test set (ii) training data754fiAutoFolio: Automatically Configured Algorithm SelectorAlgorithm 1: AutoFolio: Automated configuration algorithm selectorInput : algorithm configurator AC, algorithm selector S, configuration space CS, training data algorithm scenario (with performance featurematrix), number folds k5randomly split D(1) , . . . , D(k)start AC D(1) , . . . , D(k) meta instances, using average loss acrossmeta-instances performance metric m, using target algorithmconfiguration space Cconfiguration budget remainingAC selects configuration c C meta instance n {1 . . . k}train Sc D\D(n) , assess loss D(n) return loss AC6return best configuration c found AC1234partitioned k folds (in experiments, use k = 10), usedfollows.(1)(k)Let Dtrain , . . . , Dtrain random partition training set Dtrain . crossvalidation performance CV (Sc ) Sc training set then:kXX11(j)CV (Sc ) =l(Sc (Dtrain \Dtrain ), i)(2)(j)k|Dtrain |(j)j=1iDtrainend, optimize performance CV (Sc ) determining configuration c Cselector good cross-validation performancec arg min CV (Sc ),(3)cCevaluate c training selector Sc entire training data evaluatingP (Sc ) Dtest , defined Equation 1.(j)Following Thornton et al. (2013), use k folds Dtrain one instance withinconfiguration process. order avoid confusion instancesbase-level problem instances (e.g., SAT instances) solved inside instance,refer instance meta-instance. note many configurators, FocusedILS (Hutter et al., 2009), irace (Lopez-Ibanez et al., 2011) SMAC (Hutter et al.,2011), discard configurations perform poorly subset meta-instancestherefore evaluate k cross-validation folds every configuration.saves time lets us evaluate configurations within configurationbudget. Based considerations, Algorithm 1 outlines process configurealgorithm selector AutoFolio.Since instances scenario could split configuration testing setsmany different ways, one split necessarily yield representative performanceestimate. Therefore, yield confident results evaluation, perform additional outer cross-validation (as given ASlib scenario) instead single training-test755fiLindauer, Hoos, Hutter, & Schaubsplit. is, consider multiple training-test splits, configure selector training set, assess final configurations respective test data sets, average results.note, however, practical application AS, one would single training set (which would still split k cross-validation splits internally) single testset.3.2 Configuration Space Selectorsexisting algorithm selectors implement one specific algorithm selection approach, usingone specific machine learning technique. note, however, selection approaches,least implicitly, admit flexibility, particular could used rangemachine learning techniques. example, SATzilla11 (Xu et al., 2011) uses votingpairwise performance predictions obtained cost-sensitive random forest classifiers, but,principle, could use cost-sensitive binary classifiers instead random forests.Based observation, consider hierarchically structured configuration spacetop-level parameter determines overall algorithm selection approachexample, regression approach, used SATzilla09 (Xu et al., 2008) k-NNapproach, used ME-ASP (Maratea et al., 2014). selection approaches,choose different regression techniques, example, ridge regression, lassoregression, support vector regression random forest regression. machinelearning techniques configured (hyper-)parameters.Besides selection approach, techniques used preprocessing training data (for example, z-score feature normalization feature preprocessing steplog-transformation runtime data performance preprocessing step). Preprocessingtechniques configured independently selection approach, thereforealso handled top-level parameters.use third group parameters control pre-solving schedules (Kadioglu et al.,2011; Xu et al., 2011), including parameters determine time budget pre-solvingnumber pre-solvers considered. Pre-solving techniques freely combinedselection approaches; always needed, added top-level binaryparameter completely activates deactivates use pre-solvers; presolving parameters conditional switch.implemented choices claspfolio 2 system described Section 2.1.2.Figure 6 illustrates complete configuration space thus obtained. current version,use concrete implementation AutoFolio approach, covers sixdifferent algorithm selection approaches:(hierarchical) regression (inspired SATzilla09; Xu et al., 2008) learns regressionmodel algorithm; new instace, selects algorithm bestpredicted performance;multiclass classification (inspired LLAMA; Kotthoff, 2013) learns classificationmodel directly selects algorithm based features new instance;pairwise classification (inspired SATzilla11; Xu et al., 2011) learns (cost-sensitive)classification model pairs algorithms; new instance, evaluates models selects algorithm votes;756fiAutoFolio: Automatically Configured Algorithm Selectortransformationpre-solvingyesinstanceweightingcontributionfilteringnormalizationapproachimputationp : PCAPerformance Preprocessingmax_feature_timeFeature Preprocessing4multi-classclassificationpairwiseclassificationc (SVM)gamma(SVM)(hierarchical)regressionclusteringSNNAPk : k-NNmax cluste rkbest_nrandomforestSVMgradientboostingrandomforestSVMgradientboostingridgelassoSVRrandomforestridgelassoSVRrandomforest32332311321132k-meansGaussianmixturespectralclusteringFigure 6: Configuration space claspfolio 2, including 22 categorial parameters, 15integer valued parameters 17 continous parameters. Parameters double boxestop-level parameters; single boxes represent algorithm selection approaches based classesmachine learning techniques, dashed boxes machine learning techniques dotted boxesindicate number low-level parameters. Parameter boxes used default configuration filled grey.clustering (inspired ISAC; Kadioglu et al., 2010) determines subsets similar traininginstances feature space best algorithm subsets; newinstance, determines nearest cluster center selects associated algorithm;k-NN (inspired 3S; Kadioglu et al., 2011, ME-ASP; Maratea et al., 2014) determines set similar training instances feature space given new instanceselects algorithm best performance instance set;SNNAP (inspired Collautti et al., 2013) predicts performance algorithmregression models uses information k-NN approach predictedperformance space.approaches, claspfolio 2 covers least three different machinelearning techniques (where appropriate). listed Figure 6; example, pairwiseclassification based random forests, SVMs gradient boosting (with 3, 2 3hyper-parameters, respectively). preprocessing strategies, supports:Performance preprocessing:transformation applies log (Xu et al., 2008) z-score normalization (Collauttiet al., 2013) performance data;instance weighting weights instances impact performancealgorithm selector, is, instances get low weight available algorithms perform equally, high weight algorithms differ substantiallyperformance (Kotthoff, Gent, & Miguel, 2012);contribution filtering removes algorithms less specified contribution performance oracle (also known virtual best solver) (Xuet al., 2012a); form algorithm subset selection.757fiLindauer, Hoos, Hutter, & SchaubFeature preprocessing:normalization transforms instance features min-max, z-score, decimalpoint, log scheme application PCA;p:PCA applies principal component analysis features selects top pprincipal components, p parameter (if PCA activated);imputation fills missing feature values median, average frequentvalue feature imputation deactivated feature vector incompletegiven instance, single best solver statically selected;max feature time limits amount time spent collect features ensuresmuch time spent feature computation; however, resultincomplete features missing values (which get imputed imputationactive).chose default configuration claspfolio 2 (used initialize algorithmconfigurator) SATzilla11-like configuration, since shown effectiveSAT (Xu et al., 2012a) ASP (Hoos et al., 2014), since overall high performanceevident results Figure 1. configuration uses pairwise cost-sensitive randomforest classifiers, z-score feature normalization pre-solving schedule threepre-solvers. Since assume prior knowledge algorithm selection scenarios,default configuration uses default instance features defined scenario designers.chose claspfolio 2 basis AutoFolio, designedflexible known perform well.2 note principle, selectors,SATzilla (Xu et al., 2008), ISAC (Kadioglu et al., 2010), SNNAP (Collautti et al.,2013) LLAMA (Kotthoff, 2013), could generalized similar way.addition using claspfolio 2 algorithm selection framework, currentversion AutoFolio employs algorithm configurator SMAC (described Section2.2.1). Like selection framework, configurator also exchangeable: choseSMAC, performed best across algorithm configuration problems studiedfar, principle, configurators could also used, as, GGA (Ansotegui et al.,2009) irace (Lopez-Ibanez et al., 2011). Preliminary results (Lindauer et al., 2015b)showed ParamILS also optimize performance claspfolio 2,inferior SMAC one scenario, performance advantage small.4. Empirical Performance Analysissection, empirically analyze performance AutoFolio approach.experiments, AutoFolio employs claspfolio 2 using well-known machine learning package scikit-learn (Pedregosa et al., 2011) (version 0.14.1) algorithm configurator SMAC (version 2.08.00). ran AutoFolio thirteen algorithm selectionscenarios make Algorithm Selection Library 1.0 (Bischl et al., 2015b).32. Results performance claspfolio 2 compared state-of-the-art algorithm selectorsfound aslib.net.3. note experiments ASlib scenarios, claspfolio 2 algorithm selectorsneed perform actual runs algorithms feature generators, ASlib scenarios already758fiAutoFolio: Automatically Configured Algorithm Selectorshown Table 1, scenarios comprise wide variety hard combinatorialproblems; includes performance data range solvers (between 231) set instances, instance features organized feature groups associatedcosts. scenarios consider here, performance objective runtime minimization.high level, scenarios comprise following data:ASP-POTASSCO: runtimes different parameter configurations ASP solverclasp broad range ASP instances collected Potassco group (Gebser,Kaminski, Kaufmann, Ostrowski, Schaub, & Schneider, 2011a);CSP-2010: runtimes single solver two different configurations (withwithout lazy learning; Gent, Jefferson, Kotthoff, Miguel, Moore, Nightingale, & Petrie,2010) collection CSP instances;MAXSAT12-PMS: runtime data 2012 MaxSAT Evaluation;PREMARSHALLING: runtimes -based IDA -based solvers premarshalling problem, real-world, time-sensitive pre-marshalling problem instancesoperations research literature;PROTEUS-2014: runtimes different CSP SAT solvers range CSPinstances, preprocessed various CSP-to-SAT translation techniques;QBF-2011: runtime data QBF solvers AQME system (Pulina &Tacchella, 2009) QBF instances 2010 QBF Solver Evaluation;SAT11-HAND, SAT11-INDU SAT11-RAND: runtime data respective tracks 2011 SAT Competition;SAT12-ALL, SAT12-HAND, SAT12-INDU SAT12-RAND: runtimes various SAT solvers broad range SAT instances used train algorithmselection system SATzilla (Xu, Hutter, Shen, Hoos, & Leyton-Brown, 2012b)respective tracks 2012 SAT Challenge.refer Bischl et al. (2015b) details scenarios, including baselineexperiments showing algorithm selection applied effectively scenarios. point using common library allows us compare AutoFoliofair uniform way algorithm selection methods. However, price payuniform comparison necessarily consider current state-of-the-artalgorithms solving respective problems, since ASlib data collectedseveral years ago. Furthermore, note current version ASlib consistsdeterministic performance data. expect future versions also consider scenarios stochastic performance data multiple runs per algorithm instance, usingdifferent pseudo-random number seeds. AutoFolio applied stochastic scenarios straightforward manner, optimizing mean performance across runsinstancecontain necessary performance data feature vectors (in order allow fair comparisonalgorithm selectors based data, without confounding factor due hardware platformused run experiments).759fiLindauer, Hoos, Hutter, & SchaubScenarioASP-POTASSCOCSP-2010MAXSAT12-PMSPREMARSHALLINGPROTEUS-2014QBF-2011SAT11-HANDSAT11-INDUSAT11-RANDSAT12-ALLSAT12-HANDSAT12-INDUSAT12-RAND#I1294202487652740211368296300600161476711671362#U #A #f #fg8225312904283147747108202292093221126422515189313131311388637161984611511511511511511511541114110101010101010tc600500021003600360036005000500050001200120012001200Reference(Hoos et al., 2014)(Gent et al., 2010)(Malitsky et al., 2013)(Tierney & Malitsky, 2015)(Hurley et al., 2014)(Pulina & Tacchella, 2009)(Xu et al., 2008)(Xu et al., 2008)(Xu et al., 2008)(Xu et al., 2012b)(Xu et al., 2012b)(Xu et al., 2012b)(Xu et al., 2012b)Table 1: Overview algorithm selection scenarios Algorithm Selection Library,showing number instances #I, number unsolvable instances #U (U I), numberalgorithms #A, number features #f , number feature groups #fg , cutoff time tcliterature reference.4.1 Algorithm Configuration SetupFollowing standard practice (Hutter et al., 2009), performed multiple (in case, 12)independent runs algorithm configurator SMAC scenario selectedconfiguration claspfolio 2 best performance training data. configurator run allocated total time budget 2 CPU days. single run claspfolio 2limited 1 CPU hour, using runsolver tool (Roussel, 2011). performancemetric, used penalized average runtime penalty factor 10 (PAR10), countstimeout 10 times given runtime cutoff (runtime cutoffs differ ASlibscenarios). study optimization PAR10 influenced metrics,number timeouts. time required evaluate single configuration claspfolio 2 varied 10 CPU seconds 1 CPU hour reference machine (seebelow), mostly depending difficulty optimizing pre-solving schedules.obtain robust estimate AutoFolios performance, used 10-fold outer crossvalidation given specific ASlib scenarios, is, configured claspfolio 2 tentimes scenario (with different training-test splits). Therefore, total, performed12 10 = 120 configuration runs 2 CPU days three different configuration spaces(see Section 4.2) thirteen ASlib benchmarks, requiring total 9 360CPU days (25 CPU years). note although thorough evaluation AutoFoliorequired substantial amounts computation, applying single benchmark setgiven training-test split would require 12 independent configuration runs twodays could thus performed weekend modern desktop machine.Furthermore, applying AutoFolio new algorithm selection benchmark set cheapcomparison collecting data new benchmark set. instance, collect760fiAutoFolio: Automatically Configured Algorithm SelectorAutoFoliovoteAutoFolioAutoFolioextcategoricalintegerrealconditionalsconfigurations18 2828 3847 24771515315151444441 106 6 1083 1011 2 10142 1017 2 1077Table 2: Overview configuration spaces number categorical, integer-valuedreal-valued parameters, number conditionals, estimation numberconfigurations ignoring real-valued parameters. number categorical valuesvaries scenarios depending number algorithms, features featuregroups.algorithm performance data ASlib scenarios required 25.7 CPU days(ASP-POTASSCO) 596.7 CPU days (PROTEUS-2014), average 212.3CPU days (9 times much configuration budget AutoFolio).performed experiments bwUniCluster Karlsruhe, whose machinesequipped two Octa-Core Intel Xeon E5-2670 (2.6 GHz, 20 MB cache) CPUs64 GB RAM each, running Hat Enterprise Linux 6.4. note, however, runtimesselected algorithms feature computations part ASlib scenariosdepend hardware used.4.2 Different Configuration Spacesmentioned earlier, AutoFolio used optimize performance single approach algorithm selectors, SATzilla, multi-approach selectors, LLAMAclaspfolio 2, much larger configuration spaces (see Figure 6). Therefore, studied three different parameter spaces AutoFolio based claspfolio 2:AutoFolio considers configuration space described Section 3.2 additionallyadds binary parameters enable disable feature groups4 definedspecific algorithm selection scenario. Algorithm subset selection done usingheuristic based marginal contribution algorithm oracle performance;AutoFoliovote considers subset configuration space AutoFolio,fixes algorithm selection approach pairwise classification voting scheme;AutoFolioext considers configuration space AutoFolio, instead parameters feature group, added binary parameters instance featureselectable algorithm. increases number parameters substantially example, adds 220 additional parameters PROTEUS-2014scenario.4. selected feature groups result empty feature set, claspfolio 2 statically select singlebest algorithm training data.761fiLindauer, Hoos, Hutter, & SchaubScenarioASP-POTASSCOCSP-2010MAXSAT12-PMSPREMARSHALLINGPROTEUS-2014QBF-2011SAT11-HANDSAT11-INDUSAT11-RANDSAT12-ALLSAT12-HANDSAT12-INDUSAT12-RANDDefaultPAR10 #TOs124.8384.7264.02513.83274.21068.47093.27851.23684.02087.02081.21019.8708.2191073332126293734261866952AutoFoliovotePAR10#TOs119.8329.7135.71953.61274.0866.65781.46616.51441.9890.41079.5682.9391.618832411019233112102434429AutoFolioPAR10#TOs125.0355.1246.32005.11379.2910.25552.85932.3967.4979.11212.3774.6440.81997251172122277115495233AutoFolioextPAR10#TOs152.7358.1268.21922.53102.7946.98085.87671.31301.71077.01285.5990.7543.125982428022333610126526741Table 3: Comparing different configuration spaces AutoFolio based test performance. best performance shown bold face; indicate performance significantly better default configuration claspfolio 2 significance levels= 0.05 = 0.1, respectively, according one-sided permutation test 100 000permutations. Performances values that, according permutation test, significantly worse (at = 0.05) best performance given scenario marked.fixed selection approach AutoFoliovote pairwise classificationvoting scheme, since SATzilla11-like promising single approach experiments (see, e.g., Figure 1). hand, extended configuration space,AutoFolioext , obtained adding algorithm subset selection feature selectionconfiguration task. Feature selection well known improve many machine learningmodels, often small subset instance features necessary predict runtimealgorithms (Hutter, Hoos, & Leyton-Brown, 2013).note configuration AutoFoliovote also found AutoFolio,configuration AutoFolio also part AutoFolioext , is, AutoFoliovoteAutoFolio AutoFolioext . Table 2 gives overview configuration space sizes.4.3 Analysis Configuration ProcessTable 3, compare performance default configuration claspfolio 2(namely, SATzilla11-like) configurations optimized AutoFoliovote ,AutoFolio AutoFolioext . selection scenarios, AutoFoliovote improvedperformance test data comparison default configuration claspfolio 2.AutoFolio improved one scenario AutoFolioext three scenarios.Performance improvements test data statistically significant = 0.1 = 0.05ten seven scenarios AutoFoliovote , nine seven AutoFolio,five four AutoFolioext , respectively, according one-sided permutation test100 000 permutations.762fiAutoFolio: Automatically Configured Algorithm Selector11 13 ASlib scenarios, configuration least one configurationspaces considered led statistically significant improvements ( = 0.1); discussremaining two scenarios, ASP-POTASSCO CSP-2010. ASP-POTASSCO,performance improved substantially training data (AutoFolio reduced PAR10score 30%), transfer test data (with none differencestest performances statistically significant). note default configurationclaspfolio 2 manually optimized scenario (Hoos et al., 2014),AutoFolio found similar configurations similar performance. CSP2010, AutoFolio variants improved default, insignificantly so.note hard improve performance substantially benchmark,contains two algorithms.PREMARSHALLING, AutoFolio solved 8 additional problem instances reduced PAR10 25%; nevertheless, performance difference weaklysignificant (at = 0.1). due strong constraints pre-solving scheduledefault configuration claspfolio 2 (at 3 solvers 256 seconds).extensive pre-solving schedules decreased number timeouts PREMARSHALLING, also introduced overhead many instancesscenario, making harder AutoFolio achieve significant performance improvements. scatter plot Figure 7a shows AutoFolio produced fewer timeoutsdefault claspfolio 2, AutoFolio required higher runtime instances (points diagonal). Similarly, AutoFolio solved lot instancesPROTEUS-2014 QBF-2011, AutoFolio higher runtimeinstances (see Figure 7c 7b). However, number timeouts improved much PROTEUS-2014 (from 321 117) performance improvementstatistically significant here. Finally, SAT12-ALL example clear-cutcase: AutoFolio improved performance claspfolio 2 instances alsosubstantially reduced number timeouts (see Figure 7d).Overall, AutoFoliovote performed best experiments, followed AutoFolio,distance, AutoFolioext . respect statistical significance, AutoFoliovote AutoFolio performed quite similarly, former better three timeslatter better once. Based results, suspect added flexibilityAutoFolio compared AutoFoliovote pays configuration budgetlarge enough evaluate enough configurations effectively search larger space.case three SAT11 scenarios, AutoFolio reached bestperformance: scenarios contain relatively problem instances, makingevaluation claspfolio 2 quite fast allowing SMAC evaluate 40 000 configurations within 2 days. contrast, evaluation configuration largest ASlibscenario, PROTEUS-2014, cost hour, SMAC evaluated 600configurations, enough explore design space AutoFolio; accordingly, performance AutoFolioext PROTEUS-2014 improved slightlycomparison default configuration, AutoFoliovote made progress fasterperformed statistically significantly better AutoFolio. Therefore, believeAutoFolio good choice evaluate many configurations,scenario small large configuration budget available. hand,763fiLindauer, Hoos, Hutter, & Schaub100x10x2x100x10x2x2x2x1000100010x10x100100100xConfiguredConfigured100x1010110.10.10.010.010.1110Default1000.010.0110000.1110Default1001000(a) PREMARSHALLING. Number timeouts (b) QBF-2011. Number timeouts reducedreduced 33 (default) 25 (configured).26 (default) 21 (configured).100x10x2x100x10002x10x2x2x100010x10010x10100x100ConfiguredConfigured100x10110.10.10.010.010.1110Default1000.010.0110000.1110Default1001000(c) PROTEUS-2014. Number timeouts(d) SAT12-ALL. Number timeouts reducedreduced 321 (default) 117 (configured). 261 (default) 115 (configured).Figure 7: Scatter plots comparing per-instance performance default claspfolio 2(SATzilla11-like) AutoFolio. Left: PREMARSHALLING, AutoFolio improved penalized average runtime (PAR10) reducing number timeouts,cost increased runtimes many instances. Right: SAT12-ALL, AutoFolioimproved performance instances also reduced number timeouts.AutoFoliovote used larger scenarios configuration budgetquite small.Figure 8 shows progress configuration process terms training performancefunction time SAT11-HAND PROTEUS-2014, scenarios764fiAutoFolio: Automatically Configured Algorithm Selector80003000PerformancePAR10700060005000AutofolioAutofolio_extAutofolio_vote400029210211212213 214Time (s)25002000AutofolioAutofolio_extAutofolio_vote1500100021521621729210(a) SAT11-HAND211212213 214Time (s)215216217(b) PROTEUS-2014Figure 8: training PAR10 performance best configuration time. lineshows median 10 folds outer cross-validation filled area indicatesperformance 25 75-quantile.fewest configuration evaluations performed fixed configuration budget.scenarios, large configuration space AutoFolioext resulted periodstagnation performance improved. PROTEUS-2014, performance startedimprove near end configuration budget. contrast, AutoFolioAutoFoliovote performed quite similarly scenarios, AutoFoliovotesomewhat faster make progress (note logarithmic time axis). Surprisingly us,different selection approaches chosen AutoFolio AutoFoliovote .restricted configuration space, AutoFoliovote choose pairwise classificationvoting scheme, AutoFolio also used approaches outer foldsscenarios: regression (2 times two scenarios), clustering (1 3 times,resp.) SNNAP (3 4 times, resp.).Figure 8, also estimate influence configuration budgetperformance final algorithm selector. example, halve configuration timebudget 1 day, penalized average runtime training set increases8%.4.4 Choices Lead Good Performance?analyze choices important AutoFolio, applied two complementary methods assessing parameter importance algorithm configuration spaces:functional ANOVA (Hutter, Hoos, & Leyton-Brown, 2014, 2015b) global measureparameter importance ablation analysis (Fawcett & Hoos, 2015b, 2015a) localmeasure. high-level overview parameters AutoFolio, refer backSection 3.2; full details, including default values ranges parameters, givenonline appendix available www.ml4aad.org/autofolio.765fiLindauer, Hoos, Hutter, & Schaub4.4.1 Functional ANOVA (fANOVA)Functional ANOVA (fANOVA, see, e.g., Sobol, 1993) general method partitioningvariance function components corresponding subsets arguments. Hutteret al. (2014) demonstrated technique applied efficiently quantifyimportance algorithms parameters. approach re-use performance datacollected configuration process purpose (without requiring new algorithmexecutions) therefore computationally efficient (in experiments, requiredminutes). overall approach fit empirical performance model (Hutter, Xu, Hoos,& Leyton-Brown, 2014) : C R measured performance data,used predict performance arbitrary configurations instances, studyparameter importance model. fitting model, fANOVA marginalizesacross problem instances:1 Xf(c) =m(c, i).(4)|I|iIcomputes variance function f across entire configuration space Cpartitions variance additive components due subset algorithmsparameters. particular interest unary subsets, often explain substantial partvariance tend easiest interpret. important note fANOVApartitions variance f entire configuration space. providesglobal measure parameter importance, takes account many poorly-performingconfigurations.use fANOVA context study, ASlib scenario, mergedperformance data 12 independent SMAC runs removed data points reported timeout5 resulted empty feature set. latter,case claspfolio 2 statically selects single best solver, causing parametersbecome unimportant performance claspfolio 2.brevity, report results scenario SAT12-ALL. Table 4 shows tenimportant parameters AutoFolio AutoFolioext scenario.configuration spaces, maximal time spent compute instance features (max-featuretime) turned important parameter. parameter important,setting small result features (or even none, disablingselection mechanism) setting large lead increased overhead featurecomputation (see Figure 9).second important parameter AutoFolio marginal contributionfiltering heuristic algorithm subset selection. Algorithm subset selection especially important scenarios based SAT solving, include many SATsolvers performance solvers often highly correlated (Xu et al.,2012a). AutoFolioext , contribution filtering heuristic less important,configuration space includes binary parameters individual algorithm, allowingconfigurator (here SMAC) directly perform subset selection. context, including mphaseSATm marchrw special importance. solver mphaseSATmsingle best algorithm SAT12-ALL one highest marginal contributions5. observed timeouts particular configuration larger data sets: clustering approachspectral clustering.766fiAutoFolio: Automatically Configured Algorithm SelectorParameterMain Effectmax-feature-timecontr-filterapproachfeature-step:CGpre-solvingimputeperf:transformationtime-pre-solvingfeature:normalizationpre-solving:max-solverParameter23.43% 2.056.82% 2.306.39% 0.630.76% 0.090.69% 0.090.29% 0.060.26% 0.050.22% 0.060.06% 0.010.05% 0.01Main Effectmax-feature-timeapproachpre-solvingcontr-filteralgorithms:mphaseSATmimputationF:algorithms:marchrwtime-pre-solvingpre-solving:sec modeperf:transformation(a) AutoFolio11.07% 5.325.90% 4.401.29% 1.610.80% 0.920.72% 0.220.69% 0.270.30% 0.180.23% 0.410.11% 0.240.11% 0.04(b) AutoFolioextTable 4: Average main effects ( stdev) outer cross-validation splits tenimportant claspfolio 2 parameters SAT12-ALL according fANOVA.Marginal PAR10 Scores5851447530920100 200 300 400 500 600max-feat-time [sec]Figure 9: Marginal performance predictions parameter max-feature-time dataone outer fold configuration space AutoFolio. blue line indicates meanpredicted marginal performance red area standard deviation.oracle. Similarly, marchrw high marginal contribution algorithmwhose performance highly correlated another solver (see exploratorydata analysis Bischl et al., 2015b).note analysis determines global parameter importancerespect entire parameter space. example, importance maximal featurecomputation time mostly high, crucial change improveperformance claspfolio 2, configuration space contains settingsdrastically worsen performance. gain complementary insights parameters changed improve performance, next performed ablation analysis.66. note fANOVA also used yield local analysis parameter importance partitioning variance performance high-performance regions given configuration space (Hutter767fi20002200180020001600180014001600PAR10PAR10Lindauer, Hoos, Hutter, & Schaub12001000140012008001000600800400ute ime lter lize :sp ans opt :CG eaf aps sic res joisimpture-t ontr-finorma -stepsnce_trspeed--steps ples_pl s:ls_s eps:Ba_featups:lobcure ature n_same-ste ure-st f-max re-ste-fefeatperforfe f-mi atur feat ing:r eatumaxvot fng:r fev600e e e p f r cs:CG put tim -op aliz ran joi sap s:s lea ure filte asitep im ature- speed normance_teps:lobps:ls_re-stepmples_x_featcontr- teps:Bete-sur-feform re-s e-s atu n_s f-m eaturefeatmaxper featu featur fge:rf-mioting:rfvnvoti(a) 2nd outer fold(b) 7th outer foldFigure 10: Ablation paths two outer-folds SAT12-ALL. (a), importantparameter impute feature-step:CG smaller effect. (b), feature-step:CGimportant parameter impute effect performance.4.4.2 Ablation AnalysisAblation analysis provides answer question changes parameter valuesone configuration another caused biggest improvement performance?.iteratively changing parameter value largest impact performancepath two given configurations, e.g., default configuration algorithmoptimized configuration. Unlike fANOVA, ablation analysis attemptsummarize parameter importance across entire configuration space, focusses locallypaths configurations interest. results obtained ablation analysistherefore complementary fANOVA. Unfortunately, ablation costly,since requires new algorithm runs assess performance configurations pathtwo given configurations. AutoFolio experiments SAT12-ALL,allocated time budget 6 days maximum wall-clock time permitted jobscluster ablation 10 outer cross-validation folds, withinbudget, obtained results 6 those.ablation results indicate feature-step:CG Boolean parameter enablesdisables computation clause graph features single important parameterchange claspfolio 2s default. default, feature-step:CG activated,turns clause graph features often expensive compute withintime allow feature computation. Therefore, indeed good decisionconfiguration procedure deactivate optional feature computation step. Accordingablation results, done 5 6 outer cross-validation folds and, average,5 folds, responsible 99% performance improvements achievedet al., 2014); here, this, since used ablation analysis study parameter importancelocally.768fiAutoFolio: Automatically Configured Algorithm Selectorconfiguration (standard deviation 37%7 ). contrast, seen fANOVA results,feature-step:CG quite unimportant globally, main effect 0.76%. secondimportant parameter change activation feature imputation (impute);average, responsible 39% overall performance improvement (standarddeviation 56%) made 6 outer cross-validation folds analyzed.8 However,impute effect performance feature-step:CG deactivatedimpute changed ablation path. case 2 6 ablationpaths (e.g., see Figure 10a) hence, impute impact performance 4paths (e.g., see Figure 10b). two parameters dependent effects, since imputationparticularly important clause graph features computed: features timemany large instances thus require imputation.globally important parameter, according fANOVA, max-feature-time,found rather unimportant change default value. parameterchanged default optimized configuration outer folds SAT12-ALL,since default value already good average 2% overall performance improvement could attributed change. note alongAblation path, max-feature-time never flipped value resulted worse performance default configuration, many poorly-performing valuesexist explain globally high importance parameter.4.5 Comparison Algorithm SelectorsTable 5, compare AutoFolio SATzilla159 (Xu et al., 2011), SNNAP (version 1.4; Collautti et al., 2013) ISAC (implementation SNNAP 1.4; Kadiogluet al., 2010).10 note ISAC SNNAP pure algorithm selectors, whereasSATzilla15 claspfolio 2 additionally use pre-solver schedules. Furthermore,added nave approach, RandSel, simulating uninformed user selects uniformly random SNNAP, ISAC SATzilla15. Overall, AutoFolio performed best 7 13 scenarios statistically indistinguishablebest system scenarios, according one-sided permutation test 100 000permutations significance level = 0.05. Therefore, AutoFolio systemachieves state-of-the-art performance scenarios.SATzilla15 performed second best, yielded statistically significantly worse performance AutoFolio 5 13 scenarios. Even though statistically significant,SATzilla15 performed slightly better AutoFolio 5 scenarios. reason7. large standard deviation arises fact folds, parameter change actuallyresponsible 100% performance difference: folds, change alone wouldsufficed achieve better performance optimized configuration.8. sum relative performance subset parameter improvements limited 100%, sincecomputed relative difference default optimized configuration. 56 ablation paths, parameter changes lead better performance final optimizedconfiguration, parameter changed worsened performance again.9. Alexandre Frechette, current main developer SATzilla, provided internal new implementationSATzilla (version 0.9.1b-count-cheap-feat-12) longer limited SAT.10. state-of-the-art selectors, 3S (Kadioglu et al., 2011) CSHC (Malitsky et al., 2013a),publicly available training procedures, therefore unable trainscenarios.769fiLindauer, Hoos, Hutter, & SchaubASP-POTASSCOCSP-2010MAXSAT12-PMSPREMARSHALLINGPROTEUS-2014QBF-2011SAT11-HANDSAT11-INDUSAT11-RANDSAT12-ALLSAT12-HANDSAT12-INDUSAT12-RANDOracleSBSNNAPISAC21.3107.740.7227.626.395.9478.3419.9227.393.7113.288.146.9534.11087.42111.67002.910756.39172.317815.88985.614938.62967.93944.21360.6568.5203.81087.58959042.14058.77386.29209.36632.648591427.52180.5789593.1291.91027786.45880.833283813.513946.28461.23140.42989.34110.81409.5434.5SATzilla15 RandSel AutoFolio170276166.83179.12050.31245.26211.58048.8877.5876.91031.5839.7485.3221.6796.8615.660343145.64148.397897714.22958.91764.52440.91012.7504.3125355246.32005.11379.29105552.75932.39679791212774.6440Table 5:Performance comparison AutoFolio, SNNAP, ISAC,SATzilla15, well single best solver (SB, selected based PAR10 trainingset) baseline, oracle (also known virtual best solver) bound optimal performance algorithm selector. show PAR10 scores averaged 10 outercross-validation folds, instances solved solver removed test setavoid artificially inflating PAR10-scores. RandSel column shows expectedperformance picking uniformly random one SNNAP, ISAC SATzilla15.best performance shown bold face. performance values statistically significantly better best-performing system given scenario, accordingone-sided permutation test 100 000 permutations significance level = 0.05,marked .might SATzilla15 performs extensive search determine best combination pre-solving schedule (grid search), algorithm subset (iterated local search)trained selection model.note that, order compensate 24 CPU days spent find well-performingconfiguration AutoFolio, compared simply using single best solver, averageacross scenarios AutoFolio would consecutively solve instances 42 CPUdays (standard deviation 23), less two times configuration budget.Although AutoFolio improved substantially single best solver (SB)scenarios (up speedup factor 15.4 SAT11-RAND), still gapOracle performance (also known virtual best solver SAT community).gap could closed least two ways: (i) using larger configuration budgetAutoFolio, (ii) developing better instance features, basisalgorithm selection methods.5. Conclusionspresented AutoFolio best knowledge, first approach automatically configuring algorithm selectors. Using concrete realization approach basedhighly parameterized algorithm selection framework claspfolio 2, showedusing state-of-the-art algorithm configurators, algorithm selectors customized770fiAutoFolio: Automatically Configured Algorithm Selectorrobustly achieve peak performance across range algorithm selection scenarios.resulting approach performs significantly (and sometimes substantially) better manually configured selectors applied out-of-the-box previously unseen algorithmselection scenarios.comprehensive experiments 13 algorithm selection scenarios differentdomains (SAT, Max-SAT, CSP, ASP, QBF, container pre-marshalling) makealgorithm selection library ASlib, concrete realization AutoFolio outperformedbest single solver selection benchmark factors 1.3 15.4 (geometricaverage: 3.9) terms PAR10 scores. Overall, AutoFolio established improved stateof-the-art performance 7 13 scenarios performed par previousstate-of-the-art approaches scenarios; overall, clearly yielded robustperformance across diverse set benchmarks.also studied effect different configuration spaces. Here, showedmedium-size configuration space AutoFolio lead state-of-the-art performanceconfiguration budget allows evaluation sufficiently many configurations.contrast, selection scenario large (in terms number algorithms probleminstances), configuration budget limited, configuration constrainedspace, used AutoFoliovote , typically leads better performance.performance AutoFoliovote independently verified ICON ChallengeAlgorithm Selection (Kotthoff, 2015), evaluated 8 different systemssmall configuration budget 12 CPU hours respect three metrics: PAR10 score,number instances solved misclassification penalty. throughout paper,metric optimized AutoFolio PAR10 score, AutoFolio ranked firstrespect metric. also ranked first respect number instances solvedsecond respect misclassification penalty (leading overall second place).future work, plan investigate potential gains larger configurationspaces (including feature algorithm subset selection) used effectively.end, would like (i) study performance larger configuration budgetsallow configurator assess configurations; (ii) evaluate algorithm configurators, irace (Lopez-Ibanez et al., 2011) GGA (Ansotegui et al., 2009); (iii)extend configuration space AutoFolio implementing algorithm selectionapproaches (e.g., CSHC; Malitsky et al., 2013a); (iv) shrink larger configuration spacebased analysis parameter importance fANOVA (Hutter et al., 2014)Ablation (Fawcett & Hoos, 2015b), allowing configurator focus important parameters; (v) automatically select pre-configured algorithm selectors,based features given algorithm selection scenario, improve performancestarting automatic configuration configurations thus selected (Feurer, Springenberg, & Hutter, 2015). Another promising avenue reducing computational costapproach would pre-select algorithms, features, problem instances basedtechniques proposed Hoos et al. (2013) based collaborative filtering approachMisir Sebag (2013). Finally, plan investigate extent AutoFolioconfigure algorithm selection systems selecting parallel portfolios (Lindauer et al.,2015a) exploit increasing availability parallel computing resources.Overall, believe automated configuration algorithm selection systems improves performance versatility systems across broad range application771fiLindauer, Hoos, Hutter, & Schaubdomains. AutoFolio approach also facilitates future improvements, making easier realize assess performance potential inherent new design choicesvarious components algorithm selection system. open-source implementationAutoFolio available www.ml4aad.org/autofolio/.AcknowledgementsM. Lindauer supported DFG (German Research Foundation) EmmyNoether grant HU 1900/2-1 project SCHA 550/8-3, H. Hoos NSERC DiscoveryGrant, F. Hutter DFG Emmy Noether grant HU 1900/2-1 T. SchaubDFG project SCHA 550/8-3, respectively. work performedcomputational resource bwUniCluster funded Ministry Science, Research Artsuniversities State Baden-Wurttemberg, Germany, within frameworkprogram bwHPC.ReferencesAbrame, A., & Habet, D. (2014). extension learning Max-SAT. Endriss, U.,& Leite, J. (Eds.), Proceedings 7th European Starting AI Researcher Symposium(STAIRS14), Vol. 264 Frontiers Artificial Intelligence Applications, pp. 110. IOS Press.Amadini, R., Gabbrielli, M., & Mauro, J. (2014). SUNNY: lazy portfolio approachconstraint solving. Theory Practice Logic Programming, 14 (4-5), 509524.Ansotegui, C., Malitsky, Y., & Sellmann, M. (2014). Maxsat improved instance-specificalgorithm configuration. Brodley, C., & Stone, P. (Eds.), Proceedings Twentyeighth National Conference Artificial Intelligence (AAAI14), pp. 25942600. AAAIPress.Ansotegui, C., Sellmann, M., & Tierney, K. (2009). gender-based genetic algorithmautomatic configuration algorithms. Gent, I. (Ed.), ProceedingsFifteenth International Conference Principles Practice Constraint Programming (CP09), Vol. 5732 Lecture Notes Computer Science, pp. 142157. SpringerVerlag.Bergstra, J., Bardenet, R., Bengio, Y., & Kegl, B. (2011). Algorithms hyper-parameteroptimization. Shawe-Taylor, J., Zemel, R., Bartlett, P., Pereira, F., & Weinberger,K. (Eds.), Proceedings 25th International Conference Advances NeuralInformation Processing Systems (NIPS11), pp. 25462554.Biere, A. (2013). Lingeling, plingeling treengeling entering sat competition 2013.Balint, A., Belov, A., Heule, M., & Jarvisalo, M. (Eds.), Proceedings SAT Competition 2013: Solver Benchmark Descriptions, Vol. B-2013-1 DepartmentComputer Science Series Publications B, pp. 5152. University Helsinki.Bischl, B., Kerschke, P., Kotthoff, L., Lindauer, M., Malitsky, Y., Frechette, A., Hoos, H.,Hutter, F., Leyton-Brown, K., Tierney, K., & Vanschoren, J. (2015a). www.aslib.net.772fiAutoFolio: Automatically Configured Algorithm SelectorBischl, B., Kerschke, P., Kotthoff, L., Lindauer, M., Malitsky, Y., Frechette, A., Hoos,H., Hutter, F., Leyton-Brown, K., Tierney, K., & Vanschoren, J. (2015b). Aslib:benchmark library algorithm selection. Computing Research Repository (CoRR),abs/1506.02465.Chiarandini, M., Fawcett, C., & Hoos, H. (2008). modular multiphase heuristic solverpost enrolment course timetabling. Proceedings Seventh InternationalConference Practice Theorysy Automated Timetabling (PATAT08, pp.18.Collautti, M., Malitsky, Y., Mehta, D., & OSullivan, B. (2013). SNNAP: Solver-basednearest neighbor algorithm portfolios. Blockeel, H., Kersting, K., Nijssen,S., & Zelezny, F. (Eds.), Machine Learning Knowledge Discovery Databases(ECML/PKDD13), Vol. 8190 Lecture Notes Computer Science, pp. 435450.Springer-Verlag.Dickerson, J., & Sandholm, T. (2015). Futurematch: Combining human value judgmentsmachine learning match dynamic environments. Bonet, B., & Koenig,S. (Eds.), Proceedings Twenty-nineth National Conference Artificial Intelligence (AAAI15), pp. 622628. AAAI Press.Eggensperger, K., Feurer, M., Hutter, F., Bergstra, J., Snoek, J., Hoos, H., & Leyton-Brown,K. (2013). Towards empirical foundation assessing Bayesian optimizationhyperparameters. NIPS Workshop Bayesian Optimization Theory Practice.Fawcett, C., & Hoos, H. (2015a). www.cs.ubc.ca/labs/beta/Projects/Ablation/.Fawcett, C., & Hoos, H. (2015b). Analysing differences algorithm configurationsablation. Journal Heuristics, 128.Feurer, M., Springenberg, T., & Hutter, F. (2015). Initializing Bayesian hyperparameteroptimization via meta-learning. Bonet, B., & Koenig, S. (Eds.), ProceedingsTwenty-nineth National Conference Artificial Intelligence (AAAI15), pp. 11281135. AAAI Press.Gebser, M., Kaminski, R., Kaufmann, B., Ostrowski, M., Schaub, T., & Schneider, M.(2011a). Potassco: Potsdam answer set solving collection. AI Communications,24 (2), 107124.Gebser, M., Kaminski, R., Kaufmann, B., Schaub, T., Schneider, M., & Ziller, S. (2011b).portfolio solver answer set programming: Preliminary report. Delgrande, J.,& Faber, W. (Eds.), Proceedings Eleventh International Conference LogicProgramming Nonmonotonic Reasoning (LPNMR11), Vol. 6645 Lecture NotesComputer Science, pp. 352357. Springer-Verlag.Gebser, M., Kaufmann, B., & Schaub, T. (2012). Conflict-driven answer set solving:theory practice. Artificial Intelligence, 187-188, 5289.Gent, I., Jefferson, C., Kotthoff, L., Miguel, I., Moore, N., Nightingale, P., & Petrie, K.(2010). Learning use lazy learning constraint solving. Coelho, H., Studer,R., & Wooldridge, M. (Eds.), Proceedings Nineteenth European ConferenceArtificial Intelligence (ECAI10), pp. 873878. IOS Press.773fiLindauer, Hoos, Hutter, & SchaubGomes, C., & Selman, B. (2001). Algorithm portfolios. Artificial Intelligence, 126 (1-2),4362.Hall, M., Frank, E., Holmes, G., Pfahringer, B., Reutemann, P., & Witten, I. (2009).WEKA data mining software: update. SIGKDD Explorations, 11 (1), 1018.Hoos, H., Kaminski, R., Lindauer, M., & Schaub, T. (2015). aspeed: Solver scheduling viaanswer set programming. Theory Practice Logic Programming, 15, 117142.Hoos, H., Kaufmann, B., Schaub, T., & Schneider, M. (2013). Robust benchmark set selection boolean constraint solvers. Pardalos, P., & Nicosia, G. (Eds.), ProceedingsSeventh International Conference Learning Intelligent Optimization(LION13), Vol. 7997 Lecture Notes Computer Science, pp. 138152. SpringerVerlag.Hoos, H., Lindauer, M., & Schaub, T. (2014). claspfolio 2: Advances algorithm selectionanswer set programming. Theory Practice Logic Programming, 14, 569585.Huberman, B., Lukose, R., & Hogg, T. (1997). economic approach hard computationalproblems. Science, 275, 5154.Hurley, B., Kotthoff, L., Malitsky, Y., & OSullivan, B. (2014). Proteus: hierarchicalportfolio solvers transformations. Simonis, H. (Ed.), ProceedingsEleventh International Conference Integration AI Techniques Constraint Programming (CPAIOR14), Vol. 8451 Lecture Notes Computer Science,pp. 301317. Springer-Verlag.Hutter, F., Babic, D., Hoos, H., & Hu, A. (2007). Boosting verification automatic tuningdecision procedures. OConner, L. (Ed.), Formal Methods Computer AidedDesign (FMCAD07), pp. 2734. IEEE Computer Society Press.Hutter, F., Hoos, H., & Leyton-Brown, K. (2010). Automated configuration mixed integerprogramming solvers. Lodi, A., Milano, M., & Toth, P. (Eds.), ProceedingsSeventh International Conference Integration AI Techniques Constraint Programming (CPAIOR10), Vol. 6140 Lecture Notes Computer Science,pp. 186202. Springer-Verlag.Hutter, F., Hoos, H., & Leyton-Brown, K. (2011). Sequential model-based optimizationgeneral algorithm configuration. Coello, C. (Ed.), Proceedings FifthInternational Conference Learning Intelligent Optimization (LION11), Vol.6683 Lecture Notes Computer Science, pp. 507523. Springer-Verlag.Hutter, F., Hoos, H., & Leyton-Brown, K. (2014). efficient approach assessinghyperparameter importance. Xing, E., & Jebara, T. (Eds.), Proceedings 31thInternational Conference Machine Learning, (ICML14), Vol. 32, pp. 754762.Omnipress.Hutter, F., Hoos, H., & Leyton-Brown, K. (2015a). www.ml4aad.org/smac.Hutter, F., Hoos, H., & Leyton-Brown, K. (2015b). www.ml4aad.org/fanova.Hutter, F., Hoos, H., Leyton-Brown, K., & Stutzle, T. (2009). ParamILS: automaticalgorithm configuration framework. Journal Artificial Intelligence Research, 36,267306.774fiAutoFolio: Automatically Configured Algorithm SelectorHutter, F., Hoos, H. H., & Leyton-Brown, K. (2013). Identifying key algorithm parametersinstance features using forward selection. Pardalos, P., & Nicosia, G. (Eds.),Proceedings Seventh International Conference Learning Intelligent Optimization (LION13), Vol. 7997 Lecture Notes Computer Science, pp. 364381.Springer-Verlag.Hutter, F., Lindauer, M., Balint, A., Bayless, S., Hoos, H., & Leyton-Brown, K. (2015).Configurable SAT Solver Challenge (CSSC). Artificial Intelligence. review.Hutter, F., Xu, L., Hoos, H., & Leyton-Brown, K. (2014). Algorithm runtime prediction:Methods evaluation. Artificial Intelligence, 206, 79111.Janota, M., Klieber, W., Marques-Silva, J., & Clarke, E. (2012). Solving QBF counterexample guided refinement. Cimatti, A., & Sebastiani, R. (Eds.), ProceedingsFifteenth International Conference Theory Applications Satisfiability Testing (SAT12), Vol. 7317 Lecture Notes Computer Science, pp. 114128.Springer-Verlag.Kadioglu, S., Malitsky, Y., Sabharwal, A., Samulowitz, H., & Sellmann, M. (2011). Algorithm selection scheduling. Lee, J. (Ed.), Proceedings Seventeenth International Conference Principles Practice Constraint Programming (CP11),Vol. 6876 Lecture Notes Computer Science, pp. 454469. Springer-Verlag.Kadioglu, S., Malitsky, Y., Sellmann, M., & Tierney, K. (2010). ISAC - instance-specificalgorithm configuration. Coelho, H., Studer, R., & Wooldridge, M. (Eds.), Proceedings Nineteenth European Conference Artificial Intelligence (ECAI10),pp. 751756. IOS Press.Kotthoff, L. (2013). LLAMA: leveraging learning automatically manage algorithms.Computing Research Repository (CoRR), abs/1306.1031.Kotthoff, L. (2014). Algorithm selection combinatorial search problems: survey. AIMagazine, 4860.Kotthoff, L. (2015). ICON Challenge Algorithm Selection..icon-fet.eu/challengeas.http://challenge.Kotthoff, L., Gent, I., & Miguel, I. (2012). evaluation machine learning algorithmselection search problems. AI Communications, 25 (3), 257270.Lim, B., van den Briel, M., Thiebaux, S., Backhaus, S., & Bent, R. (2015). HVAC-AwareOccupancy Scheduling. Bonet, B., & Koenig, S. (Eds.), Proceedings Twentynineth National Conference Artificial Intelligence (AAAI15), pp. 679686. AAAIPress.Lindauer, M., Hoos, H., & Hutter, F. (2015a). sequential algorithm selection parallelportfolio selection. Dhaenens, C., Jourdan, L., & Marmion, M. (Eds.), Proceedings Nineth International Conference Learning Intelligent Optimization(LION15), Lecture Notes Computer Science, pp. 116. Springer-Verlag.Lindauer, M., Hoos, H., Hutter, F., & Schaub, T. (2015b). Autofolio: Algorithm configuration algorithm selection. Proceedings Workshops Twenty-ninethNational Conference Artificial Intelligence (AAAI15).775fiLindauer, Hoos, Hutter, & SchaubLindauer, M., Hoos, H., & Schaub, T. (2015c). www.cs.uni-potsdam.de/claspfolio/.Lopez-Ibanez, M., Dubois-Lacoste, J., Stutzle, T., & Birattari, M. (2011). irace package,iterated race automatic algorithm configuration. Tech. rep., IRIDIA, UniversiteLibre de Bruxelles, Belgium.Lopez-Ibanez, M., & Stutzle, T. (2010). Automatic configuration multi-objective ACOalgorithms. Dorigo, M., M-Birattari, Caro, G. D., Doursat, R., Engelbrecht,A. P., Floreano, D., Gambardella, L., Gro, R., Sahin, E., Sayama, H., & Stutzle,T. (Eds.), Proceedings Seventh International Conference Swarm Intelligence(ANTS10), Lecture Notes Computer Science, pp. 95106. Springer-Verlag.Malitsky, Y., Mehta, D., & OSullivan, B. (2013). Evolving instance specific algorithmconfiguration. Helmert, M., & Roger, G. (Eds.), Proceedings Sixth AnnualSymposium Combinatorial Search (SOCS14). AAAI Press.Malitsky, Y., Sabharwal, A., Samulowitz, H., & Sellmann, M. (2012). Parallel SAT solverselection scheduling. Milano, M. (Ed.), Proceedings Eighteenth International Conference Principles Practice Constraint Programming (CP12),Vol. 7514 Lecture Notes Computer Science, pp. 512526. Springer-Verlag.Malitsky, Y., Sabharwal, A., Samulowitz, H., & Sellmann, M. (2013a). Algorithm portfoliosbased cost-sensitive hierarchical clustering. Rossi, F. (Ed.), Proceedings23rd International Joint Conference Artificial Intelligence (IJCAI13), pp. 608614.Malitsky, Y., Sabharwal, A., Samulowitz, H., & Sellmann, M. (2013b). Boosting sequential solver portfolios: Knowledge sharing accuracy prediction. Pardalos, P.,& Nicosia, G. (Eds.), Proceedings Seventh International Conference Learning Intelligent Optimization (LION13), Vol. 7997 Lecture Notes ComputerScience, pp. 153167. Springer-Verlag.Maratea, M., Pulina, L., & Ricca, F. (2014). multi-engine approach answer-set programming. Theory Practice Logic Programming, 14, 841868.Mascia, F., Lopez-Ibanez, M., Dubois-Lacoste, J., & Stutzle, T. (2014). Grammar-basedgeneration stochastic local search heuristics automatic algorithm configuration tools. Computers & OR, 51, 190199.Misir, M., & Sebag, M. (2013). Algorithm selection collaborative filtering problem.Tech. rep., INRIA & LRI, Universite Paris Sud XI.OMahony, E., Hebrard, E., Holland, A., Nugent, C., & OSullivan, B. (2008). Using casebased reasoning algorithm portfolio constraint solving. Bridge, D., Brown,K., OSullivan, B., & Sorensen, H. (Eds.), Proceedings Nineteenth Irish Conference Artificial Intelligence Cognitive Science (AICS08).Pedregosa, F., Varoquaux, G., Gramfort, A., Michel, V., Thirion, B., Grisel, O., Blondel,M., Prettenhofer, P., Weiss, R., Dubourg, V., Vanderplas, J., Passos, A., Cournapeau,D., Brucher, M., Perrot, M., & Duchesnay, E. (2011). Scikit-learn: Machine learningPython. Journal Machine Learning Research, 12, 28252830.Pulina, L., & Tacchella, A. (2009). self-adaptive multi-engine solver quantified booleanformulas. Constraints, 14 (1), 80116.776fiAutoFolio: Automatically Configured Algorithm SelectorRice, J. (1976). algorithm selection problem. Advances Computers, 15, 65118.Roussel, O. (2011). Controlling solver execution runsolver tool. JournalSatisfiability, Boolean Modeling Computation, 7, 139144.Smith-Miles, K. (2008). Cross-disciplinary perspectives meta-learning algorithmselection. ACM Computing Surveys, 41 (1).Snoek, J., Larochelle, H., & Adams, R. P. (2012). Practical Bayesian optimization machine learning algorithms. Bartlett, P., Pereira, F., Burges, C., Bottou, L., &Weinberger, K. (Eds.), Proceedings 26th International Conference AdvancesNeural Information Processing Systems (NIPS12), pp. 29602968.Sobol, I. (1993). Sensitivity estimates nonlinear mathematical models. MathematicalModeling Computational Experiment, 1 (4), 407414.Tamura, N., Taga, A., Kitagawa, S., & Banbara, M. (2009). Compiling finite linear CSPSAT. Constraints, 14 (2), 254272.Thornton, C., Hutter, F., Hoos, H., & Leyton-Brown, K. (2013). Auto-WEKA: combinedselection hyperparameter optimization classification algorithms. I.Dhillon,Koren, Y., Ghani, R., Senator, T., Bradley, P., Parekh, R., He, J., Grossman, R., &Uthurusamy, R. (Eds.), 19th ACM SIGKDD International Conference Knowledge Discovery Data Mining (KDD13), pp. 847855. ACM Press.Tierney, K., & Malitsky, Y. (2015). algorithm selection benchmark container premarshalling problem. Dhaenens, C., Jourdan, L., & Marmion, M. (Eds.), Proceedings Nineth International Conference Learning Intelligent Optimization(LION15), Lecture Notes Computer Science, pp. 1722. Springer-Verlag.Vallati, M., Fawcett, C., Gerevini, A., Hoos, H., & Saetti, A. (2013). Automatic generationefficient domain-optimized planners generic parametrized planners. Helmert,M., & Roger, G. (Eds.), Proceedings Sixth Annual Symposium CombinatorialSearch (SOCS14). AAAI Press.Xu, L., Hoos, H., & Leyton-Brown, K. (2010). Hydra: Automatically configuring algorithms portfolio-based selection. Fox, M., & Poole, D. (Eds.), ProceedingsTwenty-fourth National Conference Artificial Intelligence (AAAI10), pp. 210216.AAAI Press.Xu, L., Hutter, F., Hoos, H., & Leyton-Brown, K. (2008). SATzilla: Portfolio-based algorithm selection SAT. Journal Artificial Intelligence Research, 32, 565606.Xu, L., Hutter, F., Hoos, H., & Leyton-Brown, K. (2011). Hydra-MIP: Automated algorithm configuration selection mixed integer programming. RCRA workshopExperimental Evaluation Algorithms Solving Problems CombinatorialExplosion International Joint Conference Artificial Intelligence (IJCAI).Xu, L., Hutter, F., Hoos, H., & Leyton-Brown, K. (2012a). Evaluating component solvercontributions portfolio-based algorithm selectors. Cimatti, A., & Sebastiani,R. (Eds.), Proceedings Fifteenth International Conference Theory Applications Satisfiability Testing (SAT12), Vol. 7317 Lecture Notes ComputerScience, pp. 228241. Springer-Verlag.777fiLindauer, Hoos, Hutter, & SchaubXu, L., Hutter, F., Shen, J., Hoos, H., & Leyton-Brown, K. (2012b). SATzilla2012: improvedalgorithm selection based cost-sensitive classification models. Balint, A., Belov,A., Diepold, D., Gerber, S., Jarvisalo, M., & Sinz, C. (Eds.), Proceedings SATChallenge 2012: Solver Benchmark Descriptions, Vol. B-2012-2 DepartmentComputer Science Series Publications B, pp. 5758. University Helsinki.Yun, X., & Epstein, S. (2012). Learning algorithm portfolios parallel execution.Hamadi, Y., & Schoenauer, M. (Eds.), Proceedings Sixth International Conference Learning Intelligent Optimization (LION12), Vol. 7219 Lecture NotesComputer Science, pp. 323338. Springer-Verlag.778fiJournal Artificial Intelligence Research 53 (2015) 169-222Submitted 11/14; published 06/15Using Machine Translation Provide Target-LanguageEdit Hints Computer Aided Translation BasedTranslation MemoriesMiquel Espla-GomisFelipe Sanchez-MartnezMikel L. Forcadamespla@dlsi.ua.esfsanchez@dlsi.ua.esmlf@dlsi.ua.esDept. de Llenguatges Sistemes InformaticsUniversitat dAlacant, E-03071 Alacant, SpainAbstractpaper explores use general-purpose machine translation (MT) assistingusers computer-aided translation (CAT) systems based translation memory (TM)identify target words translation proposals need changed (eitherreplaced removed) kept unedited, task term word-keeping recommendation.MT used black box align source target sub-segments fly translation units (TUs) suggested user. Source-language (SL) target-language (TL)segments matching TUs segmented overlapping sub-segments variablelength machine-translated TL SL, respectively. bilingual subsegments obtained matching SL segment TU segmenttranslated employed build features used binary classifierdetermine target words changed kept unedited. approach,MT results never presented translator. Two approaches presentedwork: one using word-keeping recommendation system trained TMused CAT system, basic approach require training.Experiments conducted simulating translation texts several languagepairs corpora belonging different domains using three different MT systems.compare performance obtained previous works used statisticalword alignment word-keeping recommendation, show MT-based approachespresented paper accurate scenarios. particular, resultsconfirm MT-based approaches better alignment-based approachusing models trained out-of-domain TMs. Additional experiments also performedcheck dependent MT-based recommender language pair MTsystem used training. experiments confirm high degree reusabilityrecommendation models across various MT systems, low level reusability acrosslanguage pairs.1. IntroductionComputer-aided translation (CAT) systems based translation memory (TM) (Bowker,2002; Somers, 2003) translation technology choice professional translators, especially translation tasks repetitive effective recycling previoustranslations feasible. reasons choice conceptual simplicity fuzzymatch scores (FMS) (Sikes, 2007) ease used determineusefulness translations proposed CAT system estimate remainc2015AI Access Foundation. rights reserved.fiEspla-Gomis, Sanchez-Martnez & ForcadaFigure 1: Procedure followed translate document using TM-based CAT system.ing effort needed turn adequate translations. FMS function measuressimilarity two text segments, usually computing variant word-based editdistance (Levenshtein, 1966), although FMS proprietary tools publiclydescribed.TM-based CAT system used translate new source document, systemfirst segments document, then, source segment 0 , provides translatorsubset translation units (TUs) (S, ) TM FMS 0selected threshold . translator must choose TU (S, )best fits needs post-edit target segment produce 0 , adequatetranslation 0 . Figure 1 illustrates procedure.showing subset matching TUs translator, TM-based CATsystems highlight words differ 0 order ease taskpost-editing . is, however, translator identify specific wordschanged (either replaced removed) order convert 0 ,problem deal paper term word-keeping recommendation.experiments professional translators show TM-based CAT system capableword-keeping recommendation improves productivity 14% ideal caserecommendations indeed correct (see Appendix details).Word-keeping recommendation related translation spotting (Veronis & Langlais,2000; Simard, 2003; Sanchez-Martnez, Carrasco, Martnez-Prieto, & Adiego, 2012),consists solving problem finding parallel sub-segments parallel texts. Translationspotting used, example, bilingual concordancers (Bourdaillet, Huet, Langlais, & Lapalme, 2010), types tools help translator retrieve occurrences sub-segmentparallel corpus corresponding translation. examples commercial bilingual concordancers Webitext,1 Linguee,2 Reverso Context.3 Translation spottingalso particularly relevant example-based machine translation (Somers, 1999), usestechnique build sub-segmental TM used translate new materials. MT qualityestimation (de Gispert, Blackwood, Iglesias, & Byrne, 2013; Specia, Raj, & Turchi, 2010),also shares features task: cases objective discover whether1. http://www.webitext.com [last visit: 15th May 2015]2. http://www.linguee.com [last visit: 15th May 2015]3. http://context.reverso.net/translation/ [last visit: 15th May 2015]170fiTarget-Language Edit Hints CAT Tools Based TM Means MTtranslation proposal 4 valid translation given source language segment 0 .parallelisms become stronger case word-level quality estimation (Ueffing & Ney,2005; Bojar et al., 2014; Espla-Gomis, Sanchez-Martnez, & Forcada, 2015), which,word-keeping recommendation, every word proposal analysed decide whetherlikely belong final translation. critical differencesscenarios quality estimation word-keeping recommendation operate: qualityestimation detects words changed segments likelyinadequately written TL, intended translations 0 ; conversely, wordkeeping recommendation intended work segments usually adequatelywritten TL, translation 0 (unless exact match0 found).Espla, Sanchez-Martnez, Forcada (2011) performed word-keeping recommendation using statistical word-alignment models (Och & Ney, 2003) align sourcelanguage (SL) target-language (TL) words TU TM. TU (S, )suggested translator, pre-computed word alignments used determine target words changed kept unedited. Analogously, Kranias Samiotou(2004) align words TU different sub-segment levels using, amongresources, bilingual dictionary words phrases (Meyers, Kosaka, & Grishman, 1998),suffix lists deal morphological variations, list closed-class wordscategories (Ahrenberg, Andersson, & Merkel, 2000). authors use alignmentsdetect words changed use MT propose translation them.best knowledge, specific details Kranias Samiotou methodworks published. patent published Kuhn, Goutte, Isabelle, Simard(2011) describes similar method also based statistical word alignment orderdetect words changed translation proposal. Unfortunately, patentprovide detailed description actual procedure used.Espla-Gomis, Sanchez-Martnez, Forcada (2011) follow different approachnecessitate computation word alignments. Instead, make useavailable MT system source bilingual information compute set featuresused perceptron classifier estimate probability pK target wordkept unedited. done by: obtaining matching TUs TM using FMSgiven threshold; segmenting SL TL segments TUsoverlapping sub-segments variable length; machine translating sub-segmentsTL SL, respectively, order learn sub-segment alignments; usingsub-segment alignments matching 0 build featuresused classifier. basic idea behind method word likelykept unedited appears translation sub-segments common0 , segment translated. Finally, pK used word-keeping recommendationmarking words pK < 12 change, otherwise keep.Although latter approach requires training procedure run TM, EsplaGomis et al. (2011) show that, translation Spanish texts English, modelused perceptron classifier trained TM domain differentactual TM used text translated. Furthermore,4. case quality estimation, segment evaluated originates MT, wordkeeping recommendation, originates TM-based CAT tool proposal.171fiEspla-Gomis, Sanchez-Martnez & Forcadaresults obtained system similar obtained Espla et al. (2011), basedstatistical word alignments, models trained texts domaintext translated, much better models trained out-of-domain texts, shownSection 7.paper revisit approach Espla-Gomis et al. (2011), propose newfeature sets capture information machine-translated sub-segmentssuccessful way features therein. addition, complex multilayer perceptron binary classifier used work, improves results obtainedsimpler perceptron classifier proposed Espla et al. (2011). improvements binary classification compared previous approach exhaustive evaluationframework, including new domains language pairs (see below). Finally, introducenew method word-keeping recommendation also able use available MTsystem source bilingual information, require training procedurerun advance. training-free method uses sub-segment pairs matchcompute alignment strength (Espla-Gomis, Sanchez-Martnez, & Forcada,2012b) words . alignment strength two words sktj measures amount evidence relates two words givingweight evidence shorter sub-segments, involves sharper picturerelation sk tj . Alignment strengths used similar fashionEspla et al. (2011) determine words changed kept unedited.mentioned above, experiments performed work compare two MTbased approaches (that requires training training-free)alignment-based approach Espla et al. (2011) using ten different language pairs, TMsthree different domains, three different MT systems. experimentscover ideal scenario, trained recommendation models testedconditions language pair, TM domain, MT system used training,also scenarios conditions change order test reusabilitymodels. Namely, experiments carried using recommendation models trained on:TM different domain, different MT system, different language pair.results obtained show MT-based approaches superior alignment-basedapproach regards accuracy scenarios. results additionally confirmMT-based approaches produce recommendation models portable acrossTM domains based word alignment. also provides good reusabilitydifferent MT systems, poor reusability translating different pair languagesused training; fact, training-free MT-based method provides better resultsscenario.remainder paper organised follows. following section reviewsprevious works integration TMs MT. Section 3 reviews statistical wordalignment-based approach defined Espla et al. (2011), used paperreference compare new methods presented. Section 4 tackles problem wordkeeping recommendation using binary classifier several sets features basedcoverage sub-segment pairs obtained machine translating sub-segments differentsizes segments translation proposal, matching source-sideproposal segment translated. Section 5 shows usebilingual sub-segments compute alignment strength SL TL words172fiTarget-Language Edit Hints CAT Tools Based TM Means MTTU, used word-keeping recommendation without training.Section 6 describes experimental framework, Section 7 presents discussesresults obtained. paper ends concluding remarks. Two appendicesincluded paper: one including experiments aimed measuring impact wordkeeping recommendation productivity professional translators, onereporting results filtered-out data set check performance ideal setting.2. Integration Machine Translation Translation Memoriesliterature subject contains several approaches combine benefits MTTMs ways different presented paper, go beyondobvious -combination scenario defined Simard Isabelle (2009), MTused translate new segment matching TU fuzzy-match score thresholdfound TM.Marcu (2001) integrates word-based statistical machine translation (SMT) subsegmental TM. method uses IBM model 4 (Brown, Della Pietra, Della Pietra, &Mercer, 1993) word-based translation model build sub-segmental TM learn wordlevel translation probabilities. done training IBM model 4 TM usedtranslation. source language (SL) segments target language (TL) segmentstranslation unit (TU) TM aligned word level usingViterbi algorithm. Finally, sub-segmental TM built parallel phrasessimilar way occurs modern phrase-based statistical MT systems (Koehn,2010): parallel phrases identified pairs sub-segmentswords SL side aligned word TL side NULL (unaligned),vice versa. translation process carried two stages: first, occurrencesSL phrases sub-segmental TM translated using corresponding TL phrase;second, words covered translated using word-level translation model learnedIBM model 4. similar approach proposed Langlais Simard (2002),also use translation sub-segment level. case, segment translated splitsub-segments, online bilingual concordancer used find translations.word-based SMT decoder Nieen, Vogel, Ney, Tillmann (1998) usedchoose best sub-segments put best order according model.Bicici Dymetman (2008) integrate phrase-based SMT (PBSMT) (Koehn, 2010)system TM-based CAT system using discontinuous bilingual sub-segments.PBSMT system trained TM, new source segment 0translated, segments best matching TU used bias statisticaltranslation 0 towards . done augmenting translation table PBSMTsystem bilingual sub-segments originating fuzzy match (S, )source part common sub-sequence 0 , target part sub-sequencedetected aligned counterpart sub-sequence S. SimardIsabelle (2009) propose similar approach new feature function introducedlinear model combination PBSMT system promote use bilingualsub-segments originating best fuzzy match (S, ). Following similar approach,Laubli, Fishel, Volk, Weibel (2013) use mixture-modeling technique (Foster & Kuhn,2007) learn domain-adapted PBSMT system combining in-domain TM173fiEspla-Gomis, Sanchez-Martnez & Forcadageneral parallel corpora. worth noting none three approaches guaranteesPBSMT system produce translation containing translationsub-segments common 0 . contrast, Zhechev van Genabith (2010)Koehn Senellart (2010), also use PBSMT system, guarantee subsegments detected aligned sub-segments matched0 appear translation.Example-based machine translation (EBMT) (Somers, 1999) also frequentlyused take advantage TMs sub-segment level (Simard & Langlais, 2001). EBMTsystems based partial matches TMs, case TM CAT tools.case, matching TUs aligned detect sub-segment pairs reusedtranslation. sub-segment pairs combined produce suitabletranslation 0 . instance, commercial TM-based CAT tool Deja Vu 5 integratesexample-based MT order suggest candidate translations casesexact match found, partial matches available (Garcia, 2005; Lagoudaki, 2008).example-based-inspired MT system used propose translation putting togethersub-segments partial matchings available. Unfortunately, unable finddetails method works.6 Approaches combine several MT systemsalso available. example, Gough, Way, Hearne (2002) use several online MTsystems enlarge example database EBMT system. authors claimpermits better exploitation parallel information TM new translations.approach differs described two ways. First, aforementionedapproaches use TM improve results MT, use MT translate sub-segmentsTUs, MT-based approaches presented paper use MT improveexperience using TM-based CAT system without actually showing machinetranslated material translator. Second, approaches above, sole exceptionGough et al. (2002), focus specific MT system family MT systems(namely, SMT EBMT), whereas MT-based approaches use MT black box,therefore able use one MT systems once. addition, MTbased approaches need access inner workings MT systems,capable using MT systems available on-line (thus avoiding needlocal installation) even source bilingual information dictionaries,glossaries, terminology databases, sub-segment pairs bilingual concordancers.works cited section, Zhechev van Genabith (2010)Koehn Senellart (2010) use PBSMT, may easily extended orderuse different MT system. approaches share similarities ours:also try detect word phrase alignments source information findparts translation proposal kept unedited. main differenceapproach Zhechev van Genabith Koehn Senellart useMT produce final translation segment translated, comes closerMT TM-based CAT. One aims approach minimally disturbway translators work TM-based CAT system keeping translation proposalsfound TM.5. http://www.atril.com [last visit: 15th May 2015]6. usually called advanced leveraging (Garcia, 2012).174fiTarget-Language Edit Hints CAT Tools Based TM Means MT[keep][edit][?][?]tjtj 0tj 00tj 000?sisi0matched unmatched00si00matched0?000sisi0000AAmatched0unmatched0Figure 2: Example possible word-alignments obtained pair segments (S, ). Target word tj may remain unedited alignedsource word si part matches 0 . Target word tj 0may changed aligned source word si0part match 0 . target word tj 00 alignedsource word S, evidence could used make recommendation it. case word tj 000 special, since aligned twowords, one matching 0 matching 0 , straightforwardrecommendation cannot provided.3. Word-Keeping Recommendation Based Statistical Word Alignmentsection reviews first approach word-keeping recommendation, introduced Espla et al. (2011), used statistical word alignment detect wordskept edited translation proposal. Given segment 0 translated TU(S, ) proposed TM-based CAT system, method first computes matching0 aligns words using word-based statisticaltranslation models implemented GIZA++ (Och & Ney, 2003). Alignments usedfollows: let tj word j-th position aligned word si ,word i-th position S. si part matching 0 , indicatestj might part translation 0 therefore remain unedited,occurs word tj Figure 2. Conversely, si part match0 , indicates tj might translation words 0edited, occurs word tj 0 Figure 2. complex situationsTL word aligned one SL word tackled following voting scheme,explained below. main limitation approach that, word tjunaligned, occurs word tj 00 Figure 2, evidence could usedmake recommendation it. Although might possible decide unalignedwords by, example, using aligned words surrounding them, wrong recommendationcould worse translator making recommendation all. ideabehind claim wrong keep recommendation may lead wrong translation,would clearly undesirable.order determine whether word tj target proposal changedkept unedited, fraction words aligned tj common 0175fiEspla-Gomis, Sanchez-Martnez & ForcadaLasituacinhumanitariapareceserulichudifftheitariansituioap npeardifcilFigure 3: Word alignments TU (la situacion humanitaria parece ser difcil,humanitarian situation appears difficult).computed:XfK (tj , 0 , S, ) =matched(si )si aligned(tj )|aligned(tj )|aligned(tj ) set source words aligned target word tj ,matched(si ) equals 1 word si part match 0 , segmenttranslated, 0 otherwise. Function matched(x) based optimal edit path,7obtained result word-based edit distance (Levenshtein, 1966) 0 .fraction fK (tj , 0 , S, ) may interpreted likelihood keep word tjunedited. mentioned above, tj may aligned several words S,may common 0 others may not, occurs word tj 000 Figure 2.Espla et al. (2011) propose two possible heuristics deal this:unanimity: word tj , recommendation made aligned matchedwords (fK () = 1), unmatched words (fK () = 0) S, recommendation made otherwise;majority: heuristic uses voting scheme, tj alignedmatched words unmatched words (fK () > 21 ), recommendation madekept, vice versa. tj aligned numbermatched unmatched words (fK () = 21 ) recommendation made.Let us suppose TU (S, ) = (la situacion humanitaria parece ser difcil,humanitarian situation appears difficult) proposed order translate newsegment 0 = la situacion poltica parece ser difcil, word-alignment7. may occur one optimal path available align two segments 0 . case,one chosen arbitrarily.176fiTarget-Language Edit Hints CAT Tools Based TM Means MT(S, ) depicted Figure 3. words the, situation, would markedkept, since aligned single word part matching0 , compatible possible translation 0 =the political situation appearsdifficult. word difficult would also marked kept, since, even thoughaligned two words, part matching 0 . However,evidence word humanitarian ambiguous; aligned words lasituacion, part matching, also humanitaria not.unanimity criterion used, recommendation would made it,use majority criterion would result keeping recommendation. Finally,recommendation would made word appears, since aligned word.main disadvantage approach requires word-alignment modeltrained directly TM used translation order maximise coverage,means re-training alignment model every time TM updated new TUs.may also occur TM sufficiently large able obtain recommendationsacceptable quality, signifying necessary use external parallel corporaorder train models. Incremental training (Gao, Lewis, Quirk, & Hwang, 2011)online training (Bertoldi, Farajian, & Federico, 2009) statistical word alignment modelscould means reduce training time TM modified, even adaptgeneral alignment models specific domains, thus improving coverage.case, incremental training would useful regards adapting existing models newTM, on-line training would allow models updated new TUadded TM. However, paper focuses using machine translation sourcebilingual information word-keeping recommendation: therefore keep originalword-alignment-based approach described Espla et al. (2011) usereference comparing new approaches proposed here.4. Word-Keeping Recommendation Binary Classificationwork tackle problem word-keeping recommendation binary classification problem. new segment 0 TU (S, ) suggested translatorTM-based CAT system, set features computed word tj , binaryclassifier used determine whether tj kept unedited changed (eitherreplaced deleted). Henceforth, shall refer approach trained MT-basedrecommender, differentiate training-free MT-based recommender presentedSection 5.features use based assumption MT, sourcebilingual information, provide evidence whether word tjchanged kept unedited. Let sub-segment one matching TUs(S, ), related MT sub-segment . related MT meanmachine translating leads , vice versa. hypothesise that:words matching new segment translated 0 provide evidencewords kept unedited (keeping evidence);words matching new segment translated 0 provide evidencewords changed (changing evidence).177fiEspla-Gomis, Sanchez-Martnez & Forcada(la,the) [keeping evidence],(situacion,situation) [keeping evidence],(humanitaria, humanitarian) [changing evidence],(ser,be) [keeping evidence],(ser,to be) [keeping evidence],(difcil,difficult) [keeping evidence],(situacion humanitaria,humanitarian situation),(ser difcil, difficult) [keeping evidence],(la situacion humanitaria, humanitarian situation).Figure 4: Example collection overlapping machine translated pairs subsegments (S, ) = (la situacion humanitaria parece ser difcil, humanitarian situation appears difficult). Sub-segment pairs (, )matching matching highlighted bold type.continue example proposed Section 3, which: (S, ) = (la situacion humanitaria parece ser difcil, humanitarian situation appears difficult), 0 =la situacion poltica parece ser difcil, segment possible overlappingsub-segments translate MT system obtain collection subsegment pairs (, ) matching (S, ) shown Figure 4. sub-segment pairs,(parece, appear), included list translations subsegment one side match equivalents side. example, parecetranslated English seems, appear translated Spanish aparecer.pairs (, ) list words match 0 provide strong evidencewords corresponding target part kept unedited. example,words the, situation, difficult, compatible possible translation0 =the political situation appears difficult. Conversely, pairs (, )words match 0 provide strong evidence words target partchanged. case, occurs word humanitarian.hand, one word evidence obtained (appears)matched MT system. case, possible provide translatorrecommendations occurs, analogous reasons, alignment-based approachdescribed Section 3. Note pair (, ) =(situacion humanitaria,humanitariansituation) contains source word (situacion) matches 0 another (humanitaria)match 0 . Dealing ambiguous evidence, along combiningevidence different (, ) (which may contradictory) leads additional problem.order deal ambiguous evidence, define three feature sets model combine keeping changing evidence, described Sections 4.1, 4.2,4.3.worth noting pre-processing methods could used order to, hopefully, exploit evidence bilingual sources information efficiently,stemming/lemmatisation, morphological analysis, even integration syntactic features proposed Ma, He, Way, van Genabith (2011). However,178fiTarget-Language Edit Hints CAT Tools Based TM Means MTobjective approach avoid complex processing order obtain fast recommendations translating texts pair languages, domain,re-using already available sources bilingual information, numerous MTsystems available Internet.4.1 Features Based Matching/Mismatching Sub-segmentsUnconstrained Length Relations [MM-U]feature set proposed Espla-Gomis et al. (2011) used referenceremaining feature sets proposed work. feature set considers, given(, ) pair segments, that:common sub-segment new segment translated 0source segment S, likely words changed(keeping evidence);sub-segment 0 , likely wordschanged (changing evidence).seen, rather conservative criterion discards informationmatching words partially matching sub-segment 0 S,8 probablycapable providing high accuracy recommending word kept.flexible approach presented Section 4.2.Based proposed rationale, four sets features computed: two sets keepingfeatures, provide information chances keeping tj , two sets changingfeatures, provide information chances changing tj . Given maximumsub-segment length L, keeping feature set Km defined word tj everyvalue [1, L] follows:Km (j, 0 , S, ) =tcover(j, segm (S) segm (S 0 ), seg (T ), ),tcover(j, segm (S), seg (T ), )segm (X) represents set possible m-word sub-segments segment X,seg (X) similar segm (X) without length constraints, tcover(j, S, , )defined as:tcover(j, S, , ) = |{ : (, ) j span( , )}|,seg (S), seg (T ), function span( , ) returns set word positionsspanned sub-segment segment .9 Function tcover(j, S, , ) thereforecomputes number target sub-segments containing word tj relatedMT sub-segment S.Similarly Km , Kn computed using target sub-segments length n:Kn (j, 0 , S, ) =tcover(j, seg (S) seg (S 0 ), segn (T ), ).tcover(j, seg (S), segn (T ), )8. example, sub-segment 5 words 4 matched one unmatched wouldconsidered changing evidence.9. Note sub-segment may found segment : function span( , ) returnspossible positions spanned.179fiEspla-Gomis, Sanchez-Martnez & ForcadaAnalogously, changing feature sets Cm Cn defined as:Cm (j, 0 , S, ) =tcover(j, segm (S) segm (S 0 ), seg (T ), ),tcover(j, segm (S), seg (T ), )Cn (j, 0 , S, ) =tcover(j, seg (S) seg (S 0 ), segn (T ), ).tcover(j, seg (S), segn (T ), )case four features, numerator denominator happenzero pair (, ) covers tj , value feature set 12 .four features computed every value 1 L 1 n L,L maximum sub-segment length used, resulting 4L features. featurestake values [0, 1] may probabilistic interpretation, 12 means dontknow. feature set termed MM-U features. similar collectionfeatures tried constrained length (m) (n). However,results confirmed improvement obtained adding feature set.running example, show feature set could computed word be,sixth word (t6 ). Please recall (S, ) = (la situacion humanitaria pareceser difcil, humanitarian situation appears difficult). Using collectiontranslated pairs overlapping sub-segments shown Figure 4, three sub-segmentpairs (, ) cover word be:= {(ser, be), (ser, be), (ser difcil, difficult)}.pairs (, ) contain sub-segments [1, 2]. value functiontcover is:tcover(6, seg1 (S), seg (T ), ) = |{be, be}| = 2tcover(6, seg2 (S), seg (T ), ) = |{be difficult}| = 1values m. addition, value tcover sub-segments match0 is:tcover(6, seg1 (S) seg1 (S 0 ), seg (T ), ) = |{be, be}| = 2tcover(6, seg2 (S) seg2 (S 0 ), seg (T ), ) = |{be difficult}| = 1value corresponding features therefore:K1 (6, 0 , S, ) =tcover(6, seg1 (S) seg1 (S 0 ), seg (T ), )2= =1tcover(6, seg1 (S), seg (T ), )2K2 (6, 0 , S, ) =tcover(6, seg2 (S) seg2 (S 0 ), seg (T ), )1= =1tcover(6, seg2 (S), seg (T ), )1Features K1 (6, 0 , S, ) K2 (6, 0 , S, ) computed analogously. caserather simple, since evidence available word indicates kept.However, word situation (t3 ), keeping changing evidence coexistset translated sub-segments pairs:= {(situacion, situation), (situacion humanitaria, humanitarian situation),(la situacion humanitaria, humanitarian situation)}180fiTarget-Language Edit Hints CAT Tools Based TM Means MTcase, sub-segments take lengths [1, 3], produces following valuestcover():tcover(3, seg1 (S), seg (T ), ) = |{situation}| = 1tcover(3, seg2 (S), seg (T ), ) = |{humanitarian situation}| = 1tcover(3, seg3 (S), seg (T ), ) = |{the humanitarian situation}| = 1However, case, match 0 :tcover(3, seg1 (S) seg1 (S 0 ), seg (T ), ) = |{situation}| = 1tcover(3, seg2 (S) seg2 (S 0 ), seg (T ), ) = || = 0tcover(3, seg3 (S) seg3 (S 0 ), seg (T ), ) = || = 0allows us compute following keeping features:K1 (3, 0 , S, ) =1tcover(3, seg1 (S) seg1 (S 0 ), seg (T ), )= =1tcover(3, seg1 (S), seg (T ), )1K2 (3, 0 , S, ) =tcover(3, seg2 (S) seg2 (S 0 ), seg (T ), )0= =0tcover(3, seg2 (S), seg (T ), )1K3 (3, 0 , S, ) =tcover(3, seg3 (S) seg3 (S 0 ), seg (T ), )0= =0tcover(3, seg3 (S), seg (T ), )1Analogously, changing features, have:tcover(3, seg1 (S) seg1 (S 0 ), seg (T ), ) = || = 0tcover(3, seg2 (S) seg2 (S 0 ), seg (T ), ) = |{humanitarian situation}| = 1tcover(3, seg3 (S) seg3 (S 0 ), seg (T ), ) = |{the humanitarian situation}| = 1allow us obtain following features:C1 (3, 0 , S, ) =tcover(3, seg1 (S) seg1 (S 0 ), seg (T ), )0= =0tcover(3, seg1 (S), seg (T ), )1C2 (3, 0 , S, ) =1tcover(3, seg2 (S) seg2 (S 0 ), seg (T ), )= =1tcover(3, seg2 (S), seg (T ), )1C3 (3, 0 , S, ) =tcover(3, seg3 (S) seg3 (S 0 ), seg (T ), )1= =1tcover(3, seg3 (S), seg (T ), )1case, ambiguity features managed binary classifier,determine corresponding weights training.181fiEspla-Gomis, Sanchez-Martnez & Forcada4.2 Features Based Partially Matching Sub-segments ConstrainedLength Relations [PM-C]feature set slightly different previous one regards wayevidence pairs sub-segments (, ) used. case, featuresrepresent fraction words match 0 given word tj relatedmeans sub-segment pairs (, ). worth noting previous feature set,matching sub-segment pairs (, ) evaluated whole sub-segment . However,new feature set, keeping changing features computed usingmatched/unmatched words . objective feature set use positiveevidence partially matching sub-segments efficiently. following equationW :defines new keeping feature KmnWKmn(j, 0 , S, )=|S|Xstcover(j, k, segm (S), segn (T ), ) match(k, 0 , S)k=1j position tj , k position sk S, match(k, 0 , S) 1 skpart match 0 , 0 otherwise,10 function stcover(j, k, S, , )defined as:stcover(j, k, S, , ) = |{(, ) : j span( , ) k span(, S)}|W as:Similarly, define changing feature CmnWCmn(j, 0 , S, ) =|S|Xstcover(j, k, segm (S), segn (T ), ) (1 match(k, 0 , S)).k=1Function stcover(j, k, S, , ) differs tcover(j, S, , ) that, given pair(, ), former takes account latter takes accountWW C W complementary, whereas K. makes Kmnmn Cmn not. KmnmnW may combined single normalised feature term KCW :Cmnmn|S|X0KCWmn (j, , S, ) =stcover(j, k, segm (S), segn (T ), ) match(k, 0 , S)k=1|S|Xstcover(j, k, segm (S), segn (T ), ),(1)k=1feature set described Section 4.1, KCWmn takes values [0, 1], and,case, evidence found tj , value corresponding feature set 21 .feature set results L2 features referred PM-C.10. function match(k, 0 , S) based optimal edit path obtained result word-basededit distance (Levenshtein, 1966) 0 S. Although frequent, may occurone optimal paths available: case, one chosen arbitrarily.182fiTarget-Language Edit Hints CAT Tools Based TM Means MTrunning example, compute PM-C features word situation,occurred Section 4.1. previous example, use collection translatedsub-segments Figure 4. set sub-segments pairs covering word situation is:= {(situacion, situation), (situacion humanitaria, humanitarian situation),(la situacion humanitaria, humanitarian situation)}W (3, 0 , S, ), KC W (3, 0 , S, ), KC W (3, 0 , S, ) comand features KC1,12,23,3puted them. seen stcover() happens different zero k = 1:stcover(3, 1, seg1 (S), seg1 (T ), ) = |{(situacion, situation)}| = 1case, see situacion (s2 ) related situation sub-segment pair(, )=(situacion, situation). case, completely matches 0 , thereforethat:|S|Xstcover(3, k, seg1 (S), seg1 (T ), ) match(k, 0 , S)WKC1,1(3, 0 , S, ) =k=1|S|X=1=11stcover(3, k, seg1 (S), seg1 (T ), )k=1W (3, 0 , S, ) slightly complex. Here, stcover() happenscase KC2,2different zero k [1, 2]:stcover(3, 1, seg2 (S), seg2 (T ), ) =|{(situacion humanitaria, humanitarian situation)}| = 1stcover(3, 2, seg2 (S), seg2 (T ), ) =|{(situacion humanitaria, humanitarian situation)}| = 1observed, words situacion humanitaria related situationpair (, )=(situacion humanitaria,humanitarian situation). Here, onetwo words matches 0 , hence:|S|XWKC2,2(3, 0 , S, ) =stcover(3, k, seg2 (S), seg2 (T ), ) match(k, 0 , S)k=1=|S|X1= 0.52stcover(3, k, seg2 (S), seg2 (T ), )k=1W (3, 0 , S, ), stcover() happens different zeroFinally that, KC3,3k [1, 3]:stcover(3, 1, seg3 (S), seg3 (T ), ) =|{(la situacion humanitaria, humanitarian situation)}| = 1183fiEspla-Gomis, Sanchez-Martnez & Forcadastcover(3, 2, seg3 (S), seg3 (T ), ) =|{(la situacion humanitaria, humanitarian situation)}| = 1stcover(3, 3, seg3 (S), seg3 (T ), ) =|{(la situacion humanitaria, humanitarian situation)}| = 1time, three words related situation, sub-segmentpair (, )=(la situacion humanitaria,the humanitarian situation). case, lasituacion match 0 , humanitaria not. resulting feature therefore:|S|XWKC3,3(3, 0 , S, ) =stcover(3, k, seg3 (S), seg3 (T ), ) match(k, 0 , S)k=1=|S|2' 0.673Xstcover(3, k, seg3 (S), seg3 (T ), )k=1Note feature collection constrains length time.configuration also tried previous feature set (MM-U), improvementsobtained compared constraining lengths separately. featureset possibilities also tried, constraining lengthtime proved lead better results.4.3 Features Combining Partially Matching Sub-segments ConstrainedLength Relations Information Coverage [PM-C+C]Features KCWmn may hide amount keeping/changing evidence, sincetake account fraction keeping evidence total amount evidence.11deal this, propose feature set defined Section 4.2 combinednew feature Emn :Emn (j, S, ) = |{(, ) : segm (S) segn (T ) j span( , )}|(2)feature counts number sub-segment pairs (, ) covering word tj , thus providing measure amount evidence supporting value feature KCWmn .0 , S, ),propose new feature set, 2L2 features, using KCWE(j,mnmnreferred PM-C+C. similar feature set tried, Emn normaliseddividing maximum number pairs (, ) could covered tj (m n).However, set features show improvement therefore discarded.running example, pairs (, ) cover word (t6 ) are:= {(ser, be), (ser, be), (ser difcil, difficult)}.Therefore, features Emn different zero word are:E1,1 (6, S, ) = |{(ser, be)}| = 111. example, would 1 keeping evidence 1 evidence 5 keeping evidences5 evidences; however, second case considered reliable, since evidenceconfirms keeping recommendation.184fiTarget-Language Edit Hints CAT Tools Based TM Means MTE1,2 (6, S, ) = |{(ser, be)}| = 1E2,2 (6, S, ) = |{(ser difcil, difficult)}| = 1Given single pair (, ) covers word n, featuresset 1. However, evidence (, )=(ser,be difficult) could used, valueE1,2 would become higher:E1,2 (6, S, ) = |{(ser, be), (ser, difficult)}| = 25. Word-Keeping Recommendation Based MT Alignment Strengthscollection sub-segment pairs (, ) related MT used wordkeeping recommendation directly, i.e., without run training procedure.propose using training-free MT-based recommender based alignmentstrengths described Espla-Gomis, Sanchez-Martnez, Forcada (2012a) EsplaGomis et al. (2012b). metric determines relatedness association strengthj-th word k-th word defined as:L XLXstcover(j, k, segm (S), segn (T ), )A(j, k, S, ) =mnm=1 n=1alignment strength based idea matched sub-segment pairs apply pressurewords, signifying larger surface covered sub-segment pair, lowerpressure applied individual word. Figure 5 shows words TUcovered bilingual sub-segments (left), result computing alignmentstrengths (right).order perform word-keeping recommendation using alignment strengths,define function G(j, 0 , S, ) computes fraction alignment strengthrelates word tj words sk part matching 0 S,sum alignment strength words S:|S|XG(j, 0 , S, ) =A(j, k, S, ) match(k, 0 , S)k=1|S|XA(j, k, S, )(3)k=1Word keeping recommendation performed following simple manner:G(j, 0 , S, ) 21 , word tj marked changed, otherwise kept.evidence (, ) spanning tj , recommendation provided tj .worth noting A(j, k, S, ) similar particular linear combinationPM-C feature set described Section 4.2, weight feature directly set1mn, rather chosen optimising recommendation accuracy trainingset. results shown Section 6 prove method less accurate trainedMT-based approach, still provides reasonably good results.185fiEspla-Gomis, Sanchez-Martnez & ForcadaLaLa 1.11 0.11 0.11situacinsituacin 0.11 0.36 1.36humanitariahumanitaria 0.11 1.36 0.36ulichudiffulicdiffhu0.25 1.25difcildifciltheitariansituioap npear0.50 1.75 0.25serserparecetheitariansituioap npearpareceFigure 5: Sub-segment pairs covering words TU (la situacion humanitaria pareceser difcil, humanitarian situation appears difficult) (left),alignment strengths obtained (right). weight sub-segmentpair taken 1 divided surface covers computepressure exerted individual word.running example, use scores shown Figure 5; seen, wordsituation related three words: La, score 0.11, situacion, score 1.36,humanitaria, score 0.36. value G(3, 0 , S, ) therefore:G(3, 0 , S, ) =0.11 1 + 1.36 1 + 0.36 01.47=' 0.80.11 + 1.36 + 0.361.83case, G(3, 0 , S, ) > 12 , means word situation must remain unedited.However, humanitarian, related words Spanish, have:G(2, 0 , S, ) =0.470.11 1 + 0.36 1 + 1.36 0=' 0.30.11 + 0.36 + 1.361.83Since G(2, 0 , S, ) 21 , word humanitarian would marked changed.6. Experimental Settingsexperiments conducted consisted simulating translation texts severallanguage pairs text domains. language pairs involved experimentsGermanEnglish (deen), EnglishGerman (ende), EnglishSpanish (enes), SpanishEnglish (esen), EnglishFinnish (enfi), FinnishEnglish (fien), EnglishFrench (enfr),FrenchEnglish (fren), SpanishFrench (esfr), FrenchSpanish (fres). Threethematic TMs created language pair extracting domain-specific TUsDGT-TM (Steinberger, Eisele, Klocek, Pilos, & Schluter, 2012), TM publishedEuropean Commission Directorate-General Translation (European CommissionDirectorate-General Translation, 2009).186fiTarget-Language Edit Hints CAT Tools Based TM Means MTcompared two MT-based approaches described Sections 4 5 navebaseline also based binary classifier, using fuzzy-match score(FMS) 0 feature, (henceforth FMS-only baseline, see Section 6.5),statistical word-alignment-based approach described Section 3, differentscenarios. first evaluated approaches optimal case, models(either word-alignment models classification models) trained TM usedtranslating, and, case MT-based approaches, employing MT systemused translation. evaluation extended evaluate:reusability across domains: word-alignment models classification models trained out-of-domain TMs;reusability across MT systems: models trained TM usedtranslation, using different MT system;reusability across language pairs: models trained TMdomain used translation, different language pair, obviously,using different MT system.reusability across MT systems evidently evaluated case MT-basedapproaches. regards reusability across language pairs, one hand, FMS-onlybaseline language independent, other, statistical word-alignment modelsused alignment-based approach trained pair languagesused translation.extensive evaluation allow us ascertain degree independencerecommendation model regard domain TM, MT system,language pair used training. key point, since high independencepart variables would allow computer-aided translation (CAT) users reuse existingfeature weights obtained without run training procedure changedomain texts translated, MT system use even languagesworking with. case domain independence particularly relevant sincecovers problem using different TM, also case new TUsseen training added TM.regard MT systems, used statistical MT system Google,12Power Translator (Depraetere, 2008) version 15,13 free/open-source, shallow-transferMT system Apertium (Forcada et al., 2011).14 Unfortunately, MT systems mentioned available language pairs. Table 1 shows MT system(s)available language pair included experiments.Even though used large data sets batch mode obtain results reportedpaper, wanted ensure MT-based approaches would able providerecommendations real time translation tasks. main part computationtime MT-based approaches spent segmenting machine-translatingresulting sub-segments. order prove could done real MT-based12. http://translate.google.com [last visit: 15th May 2015]13. http://www.lec.com/power-translator-software.asp [last visit: 15th May 2015]14. http://www.apertium.org [last visit: 15th May 2015]187fiEspla-Gomis, Sanchez-Martnez & ForcadaLanguage pairGermanEnglish (deen)EnglishGerman (ende)EnglishSpanish (enes)SpanishEnglish (esen)EnglishFinnish (enfi)FinnishEnglish (fien)EnglishFrench (enfr)FrenchEnglish (fren)SpanishFrench (esfr)FrenchSpanish (fres)Apertium3333Google TranslatePower Translator333333333333333333Table 1: MT systems available translation direction () used experiments.CAT scenario, prototype15 plug-in implementing training-free approach builtfree/open-source CAT system OmegaT16 and, experiments using on-lineMT systems Apertium Google Translate, confirm recommendationsobtained almost instantaneously.6.1 EvaluationFMS-only baseline, statistical alignment-based approach proposed Section 3,MT-based approaches proposed Sections 4, 5 tested using test set(TS) parallel segments {(Sl0 , Tl0 )}Ndomain. SL segmentl=1 , TM0N0Sl TS, set matching TUs {(Si , Ti )}i=1 TM FMS thresholdobtained. Please recall FMS measures similarity translationproposals segments translated. FMS threshold usually set values60% (Bowker, 2002, p. 100) experiments therefore used several values60% 90%.17 set matching TUs obtained,recommendations every word tj every target-language segment Ti obtainedevaluated using Tl0 , translation Sl0 , gold standard. words Tl0 Timatched using Levenshtein edit distance (Levenshtein, 1966), allows uscheck whether given word tj , j-th word Ti , actually kept finaltranslation. thus possible determine whether recommendation tj successfulif:tj recommended changed Ti match word Tl0 ,tj recommended kept Ti match word Tl0 .15. http://www.dlsi.ua.es/~mespla/edithints.html [last visit: 15th May 2015]16. http://www.omegat.org [last visit: 15th May 2015]17. MT-based approaches require training, different models trained every valueincluded experiments.188fiTarget-Language Edit Hints CAT Tools Based TM Means MTpairs (Sl0 , Tl0 ) TS used obtain corresponding sets0matching TUs {(Si , Ti )}Ni=1 , recommendations obtained checked,several metrics used evaluation. Accuracy (A) computed fraction successful recommendations total number words recommendationmade. worth noting methods proposed provide recommendations words; another interesting metric therefore fractionwords covered (NC) system, is, fraction words recommendation made. combination two metrics helps us understandmethod perform test set. addition accuracy fraction words covered, also compute precision recall regards keepingrecommendations (PK RK , respectively) changing recommendations (PCRC , respectively). latter metrics useful since provide specific informationsuccessful keeping recommendations change recommendations, separately,NC provide information general performance recommender.code used perform experiments freely available license GNU General Public License v3.0 (Free Software Fundation, 2007) downloadedhttp://transducens.dlsi.ua.es/~mespla/resources/wkr/.6.2 Corporacorpus used experiments DGT-TM (Steinberger et al., 2012). translation memory collection documents Official Journal European Union 18aligned segment level several languages (multilingual TUs). Segmentalignment DGT-TM expected high level quality, since part alignments manually checked, actually generated computer-aided translationprofessional translators.TUs DGT-TM contain segments many official languages European Unionlabelled domain codes19 used create three domain-specific TUcollections. done using following domain codes: elimination barrierstrade (code 02.40.10.40), safety work (code 05.20.20.10), general informationpublic contracts (code 06.30.10.00). TUs containing corresponding segmentsfive languages used experiments included TU collections.collection TUs used build bilingual TM test set language pair randomly selecting pairs segments without repetition.20 additionpre-processing already performed creators DGT-TM (European CommissionJoint Research Center, 2007) segments included TMs test set usedexperiments tokenised lowercased. TMs consist 6, 000 TUs each,simulate TM translator may use translating CAT tool. test setconsist 1, 500 TUs whose source language side simulates segments translatedusing TMs (the translators job), target language side may consideredreference translation segment translated.18. http://eur-lex.europa.eu [last visit: 15th May 2015]19. http://old.eur-lex.europa.eu/RECH_repertoire.do [last visit: 15th May 2015]20. TMs test set obtained way downloaded http://transducens.dlsi.ua.es/~mespla/resources/mtacat/ [last visit: 15th May 2015]189fiEspla-Gomis, Sanchez-Martnez & Forcada02.40.10.4002.40.10.4005.20.20.1006.30.10.0005.20.20.10(8o )(76o )0.990.26 (75o )0.24 (76o )0.240.98 (11o )0.23 (76o )06.30.10.000.20 (78o )0.23 (76o )0.97 (14o )Table 2: Cosine similarity (and corresponding angle) English sideEnglishSpanish TMs belonging three domains experiments: elimination barriers trade (code 02.40.10.40), safety work (code 05.20.20.10),general information public contracts (code 06.30.10.00).domains chosen experiments little overlap vocabulary, evidencedcosine similarity measure shown Table 2.21 technique maps text ontovocabulary vector, word dimension number occurrencesword text value dimension. vocabulary vectorsused compare two texts computing cosine angle them. cosinesimilarity computed using English side three EnglishSpanish TMssplitting 6,000 segments two halves. table shows cosine similarityfirst half domain (rows) second half (columns).noted, cosines vocabulary vectors domainclose 1, angles 8o 14o . However, cosinesvocabulary vectors different domains much smaller, angles 75o79o . therefore conclude considerable differences TMsused experiments.regards number TUs matched simulating translation Spanishsegments English test set, Table 3 reports, fuzzy-match scores four differentranges, average number TUs matched per segment translated totalnumber words provide recommendation. data provide idearepetitiveness corpora used carry experiments. seen,corpus domain 02.40.10.40 repetitive two. worth notingdomains 05.20.20.10 06.30.10.00 notable differences low values FMSthreshold , differ much higher values.6.3 Fuzzy-Match Score Functionexperiments, many TM-based CAT systems, chosen fuzzy-matchscore function based word-based Levenshtein edit distance (Levenshtein, 1966):FMS(S 0 , S) = 1D(S 0 , S)max(|S 0 |, |S|)21. cosine similarity computed lowercased corpora, removing punctuation charactersstopwords provided 4.7.2 version Lucene: http://lucene.apache.org/core/ [last visit: 15thMay 2015].190fiTarget-Language Edit Hints CAT Tools Based TM Means MT(%)filteringdomainTUavgNwords6002.40.10.4005.20.20.1006.30.10.003.710.625.6895,8819,71834,3397002.40.10.4005.20.20.1006.30.10.002.360.370.9965,8656,88310,3278002.40.10.4005.20.20.1006.30.10.001.580.140.4546,5193,0154,7269002.40.10.4005.20.20.1006.30.10.000.700.050.0326,6251,5991,268Table 3: Average number matching TUs (TUavg ) per segment total number targetwords (Nwords ) recommendation provided translatingSpanish English three different domains. results obtaineddifferent values FMS threshold ().|x| length (in words) string x D(x, y) refers word-based Levenshteinedit distance x y.226.4 Binary ClassifierEspla-Gomis et al. (2011) used simple perceptron classifier defined, translation source segment 0 , probability keeping j-th word , targetlanguage segment TU (S, ) as:pk (j, 0 , S, ) =11+eg(j,S 0 ,S,T )(4)0g(j, , S, ) = 0 +NFXk fk (j, 0 , S, ).(5)k=1perceptron uses sigmoid function incorporates linear combinationdifferent features fk corresponding weights k learned classifier.22. Many TM-based CAT tools implement variations FMS rank translation proposals regardsedition effort required (for instance, disregarding punctuation signs numbers 0 ,using stemmed versions 0 ). experiments continue use original FMS, sinceranking important experiments. owing fact proposalsthreshold evaluated, highest score.191fiEspla-Gomis, Sanchez-Martnez & Forcadawork, complex multilayer perceptron (Duda, Hart, & Stork, 2000, Section 6) used, namely, implemented Weka 3.7 (Hall et al., 2009). Multilayerperceptrons (also known feedforward neural networks) complex structureincorporates one hidden layers, consisting collection H perceptrons, placedinput classifier (the features) output perceptron. hiddenlayer makes multilayer perceptrons suitable non-linear classification problems (Dudaet al., 2000, Section 6). fact, Hornik, Stinchcombe, White (1989) proved neuralnetworks single hidden layer containing finite number neurons universalapproximators may therefore able perform better simple perceptroncomplex problems. case, output perceptron provides classification takesoutput hl perceptrons H input. Eq. (5) therefore needsupdated follows:0g(j, , S, ) = 0 +|H|Xl hl (j, 0 , S, ).(6)l=1perceptron hl H works similarly perceptron described eq. (4):hl (j, 0 , S, ) =11 + egl (j,S 0 ,S,T ) )gl (j, 0 , S, ) = l0 +NFXlk fk (j, 0 , S, ).k=1seen, besides collection weights main perceptron, differentcollection weights 0l needed perceptron hl hidden layer H.weights obtained using backpropagation algorithm (Duda et al., 2000, Section6.3) training, updates using gradient descent error function.case, used batch training strategy, iteratively updates weights orderminimise error function. training process stops error obtainediteration worse obtained previous 10 iterations.23validation set 10% training examples used training,weights therefore iteratively updated basis error computed90%, decision stop training (usually referred convergence condition)based validation set. usual practice whose objective minimiserisk overfitting.Hyperparameter optimisation carried using grid search (Bergstra, Bardenet,Bengio, & Kegl, 2011) strategy based accuracy obtained EnglishSpanishTM 02.40.10.40 domain. 10-fold cross-validation performed trainingcorpus order choose following hyperparameters:23. usual set number additional iterations error stops improving, case functionlocal minimum, error starts decreasing iterations. errorcontinues worsen 10 iterations, weights used obtained iterationlowest error.192fiTarget-Language Edit Hints CAT Tools Based TM Means MTNumber nodes hidden layer : Weka (Hall et al., 2009) makes possiblechoose among collection predefined network designs; bestperformed training corpus number nodeshidden layer number features.Learning rate: parameter allows dimension weight updates regulated applying factor error function iteration; valuebest performed experiment 0.4.Momentum: updating weights end training iteration, momentummodifies new value, signifying depends current gradientdirection, also previous weight value. objective techniquesmooth training process faster convergence. case experiments,set 0.1.6.5 Reference Resultsmentioned previously, performance two MT-based approaches proposedwork compared two different approaches: nave FMS-only baseline,uses classifier described Section 6.4 employs FMS 0feature, approach reviewed Section 3, uses statistical word alignmentrelate words two segments TU (S, ). nave FMS-only baselinetrained datasets described Section 6.2 different values FMS threshold. worth mentioning resulting models classify target wordskept. consequence fact that, value FMS trainingset, words kept changed.alignments used alignment-based approach obtained meansfree/open-source MGIZA++ toolkit (Gao & Vogel, 2008), implementationGIZA++ toolkit (Och & Ney, 2003) eases task training alignment modelsparallel corpus aligning different one using models learned. wordbased alignment models (Brown et al., 1993; Vogel, Ney, & Tillmann, 1996) separatelytrained TMs defined Section 6.2 JRC-Acquis 3.0 (Steinberger et al.,2006) corpus (a large multilingual parallel corpus includes, among others, textsTMs, given built texts DGT-TM).24 alignmentsused result running MGIZA++ translation directions (source-totarget target-to-source) symmetrising sets alignments meansusual grow-diag-final-and (Koehn et al., 2005) heuristic. symmetrisation techniquefound provided best compromise coverage accuracyword-keeping recommendation (Espla et al., 2011).25Table 4 shows accuracy obtained nave FMS-only baseline. fractionwords covered, is, words recommendation provided,included table since baseline provides recommendation every word24. https://ec.europa.eu/jrc/en/language-technologies/jrc-acquis [last visit: 15th May 2015]25. Symmetrisation necessary MGIZA++ produces alignments source wordaligned many target words, whereas target word aligned one source word.use symmetrisation allows alignments combined directions order obtain Nalignments.193fiEspla-Gomis, Sanchez-Martnez & Forcada(%)A(%)6070809082.69.2488.37.2591.65.2593.98.29Table 4: Accuracy A(%) obtained nave FMS-only baseline translatingenes domain 02.40.10.40. Accuracy obtained different FMS thresholds. language pairs domains behave way.test set. due fact nave FMS-only baseline dependcoverage source information.general, see accuracy obtained nave FMS-only baselinequite high. is, fact, hard-to-beat nave baseline, although resultsreasonable, since relatively high values FMS threshold imply highnumber words kept unedited translation proposals.regard alignment-based approach, several options evaluated orderchoose configuration. one hand, tried two decision criteria describedSection 3 (unanimity majority). hand, tried two alignment models:one trained translation memory used experiments (as occurredtrained MT-based recommender), another trained JRC Acquis parallelcorpus. objective comparing models confirm corpusadequate regards training alignment-based recommender: one reduceddomain focused, one bigger generic, although still containingtext domain. results presented Table 5, accuracypercentage words covered measured four combinations decisioncriteria training corpora. already mentioned Section 3, unanimity criterionfocused accuracy, majority criterion focused coverage.order confirm method better, statistical significance test performedresults obtained using approximate randomisation test.26 free/open-sourcetool SIGF V.2 (Pado, 2006) used statistical significance testing resultsdescribed throughout section. test confirmed cases alignmentmodels trained TM used testing outperform trained JRC Acquiscorpus. approach trained TM used testing used experimentsshown following section, decision criterion used unanimity,reason consider accuracy relevant coverage wordkeeping recommendation, since mentioned above, believe better makerecommendation make wrong one.26. Approximate randomisation compares difference accuracy/coverage two classifierstest set. method randomly interchanges predictions classifiers everyinstance test set. difference accuracy/coverage randomised datasetscompared original set. process iterativelly repeated confirm whether resultsregards randomised predictions consistently worse original results.194fiTarget-Language Edit Hints CAT Tools Based TM Means MT(%)training 02.40.10.40methodtraining JRC Acquis(%)NC (%)(%)NC (%)60unanimitymajority93.90.1692.96.176.09.154.39.1393.14.1793.05.176.29.155.39.1470unanimitymajority94.32.1893.47.195.90.184.45.1693.67.1993.59.196.15.185.42.1780unanimitymajority95.10.2094.49.215.37.214.31.1994.56.2194.52.215.87.215.33.2090unanimitymajority95.34.2695.10.274.93.264.35.2594.97.2794.95.275.48.275.04.26Table 5: Accuracy (A) fraction words covered (NC) obtained alignmentbased approach described Section 3 different FMS thresholds , translating Spanish English domain 02.40.10.40. results show accuracyobtained using model trained TM belonging 02.40.10.40 domain JRC-Acquis corpus, using unanimity majoritydecision criteria. behaviour also observed remaining TMs usedexperiments. Statistically significant differences accuracy approach different values p 0.05 highlighted bold type,also occurs fraction words covered.7. Results Discussionsection present results obtained two approaches proposed papercompare performance nave FMS-only baseline alignment-basedapproach Espla et al. (2011). large amount variables taken consideration(feature sets, language pairs, domains, MT systems, sub-segment length) forced usselect experiments performed. parameters therefore chosen basisresults obtained translation Spanish English, languagepair used Espla et al. (2011) Espla-Gomis et al. (2011). domain chosenpreliminary experiments elimination barriers trade (02.40.10.40), highermatching rates (see Table 3) therefore data obtained.7.1 Parameter Selectionfirst attempted determine optimal sub-segment maximum length L experiments training-free recommender trained recommender. Table6 shows fraction words covered depending value L recommenders together. fraction words covered 16% 19% usingsub-segments one word, percentage diminishes context providedtranslations. seen, fraction words covered starts stabiliseL = 4, since difference L = 5 0.25%.Table 7 shows impact value L accuracy obtained trainingfree recommender trained recommender using different sets features195fiEspla-Gomis, Sanchez-Martnez & Forcada(%)60708090Fraction words without recommendation (%)L=1L=2L=3L=4L=516.42.2416.74.2817.37.3418.18.4610.22.1910.66.2411.25.2911.80.397.24.167.34.207.65.248.05.335.13.145.18.175.53.215.86.284.90.144.94.175.29.205.59.28Table 6: Percentage words covered MT-based approaches enes language pair domain 02.40.10.40 using combination MT systems available.fraction words covered obtained different FMS thresholdsusing different values maximum sub-segment length L.(%)Accuracy (%) classificationMethodL=1L=2L=3L=4L=560MM-UPM-CPM-C+Ctraining-free93.51.1793.62.1793.59.1793.63.1793.40.1794.07.1694.36.1593.78.1693.58.1694.31.1594.57.1593.79.1693.57.1694.18.1595.14.1493.27.1693.77.1694.37.1595.41.1492.90.1770MM-UPM-CPM-C+Ctraining-free94.79.1994.75.1994.81.1994.76.1994.72.1894.89.1895.16.1794.77.1894.77.1895.12.1795.33.1794.77.1894.70.1894.94.1795.63.1694.14.1894.82.1795.05.1795.92.1693.78.1980MM-UPM-CPM-C+Ctraining-free96.09.1996.09.1996.11.1996.05.2096.14.1996.14.1996.24.1895.97.1995.92.1996.11.1896.34.1895.88.1996.00.1896.01.1896.39.1795.29.2096.02.1895.98.1896.58.1794.98.2090MM-UPM-CPM-C+Ctraining-free96.84.2396.84.2396.84.2396.80.2396.85.2296.82.2396.95.2296.72.2396.80.2296.87.2296.95.2296.70.2296.74.2296.85.2296.90.2196.61.2296.75.2296.87.2297.00.2196.42.23Table 7: Accuracy obtained trained MT-based recommender using differentfeature combinations described Section 4 training-free MT-basedrecommender enes language pair. Accuracy obtained differentFMS thresholds using different values maximum sub-segment lengthL. Statistically significant accuracy results L = 4 (the value Lused remaining experiments) p 0.05 highlighted bold type.196fiTarget-Language Edit Hints CAT Tools Based TM Means MTdescribed Section 4. seen, accuracy training-free system dropsslightly longer sub-segments introduced. reasonable since longer subsegments used, higher number words recommendation made (seeTable 6). Words covered long sub-segments difficultclassify, since sub-segments contain evidence regarding words thereforeless precise. interesting observe that, case feature sets,trained recommender behave manner, since able learn reliablelonger sub-segments are. case feature set MM-U, accuracy almostconstant values L, means using longer sub-segmentsimpact accuracy case. event, worth notingresults obtained using training-free recommender quite accurate, confirmssub-segment pairs discovered using MT good source information wordkeeping recommendation. Moreover, results indicate long sub-segments lessinformative short sub-segments. general, small improvements accuracycoverage occur values L higher 4. remaining experimentssection therefore performed L = 4.results Table 7, namely column L = 4, also useddetermine best feature combination trained MT-based recommender.first glance, set features based matching words, namely PM-C (see Section 4.2),PM-C+C (see Section 4.3), perform best. commented Section4.2, MM-U features consider partial matching sub-segments negative evidence,PM-C PM-C+C also attempt extract positive evidence sub-segments,thus using bilingual information efficiently. However, results obtainclose, particularly case high values . statistical significance testconfirmed PM-C+C superior feature combinations valuep 0.05. feature set PM-C+C therefore used trained classifierapproach remaining experiments section.accuracy obtained using approaches presented previoussection lower expected, particularly considering results obtained EsplaGomis et al. (2011) Espla et al. (2011) trained MT-based approachalignment-based approach obtained average accuracy 5% higherobtained experiments. intuition leads us believe dropaccuracy may due fact data sets used previous works mightcleaner used here. confirm this, additional set experiments carriedusing additional cleaning criteria ensure quality datasets usedevaluation. results study presented Appendix B.7.2 General Resultsparameters chosen (maximum sub-segment length L = 4 MT-based approaches,PM-C+C feature set trained MT-based approach, unanimity criterionmodels trained TM used experiments alignment-based approach)used perform several experiments order check performance system.Tables 8 9 show results obtained trained MT-based recommendertranslating Spanish segments English. Table 8, different MT systems available197fiEspla-Gomis, Sanchez-Martnez & Forcada(%)60708090ApertiumGoogle TranslatePower Translator(%)NC (%)(%)NC (%)(%)NC (%)94.61.1795.40.1996.49.2097.25.2327.89.2828.32.3428.39.4128.49.5495.08.1495.54.1696.34.1896.99.216.22.156.38.196.52.226.31.2994.52.1795.47.1996.46.2097.01.2428.99.2929.62.3529.59.4228.50.54Table 8: Accuracy (A) fraction words covered (NC) obtained translatingesen domain 02.40.10.40 trained MT-based approach. resultsobtained separate use MT systems available languagepair: Apertium, Google Translate, Power Translator. every value ,results supersede rest statistically significant margin p 0.05highlighted bold type, accuracy fraction wordscovered.used separately obtain recommendations 02.40.10.40 domain. resultsconfirm that, accuracy remains stable,27 coverage strongly depends MT system.may interpreted follows: MT-based approaches robust bilingual sourcesinformation low coverage. experiments confirmed best coverageobtained Google Translate, whereas Apertium Power Translator produce similarresults. However, Apertium Power Translator produce higher precision changerecommendations, three MT systems perform similarly regards precisionkeep recommendations.Table 9 compares performance alignment-based approach trainedMT-based recommender three MT systems available used timelanguage pair esen. table shows results obtained separatelyalignment-based approach trained MT-based approach regards three domains: 02.40.10.40, 05.20.20.10 06.30.10.00. results quite similarapproaches. MT-based approach slightly outperforms alignment-based approachaccuracy, results alignment-based approach better coverage, particularly case 06.30.10.00 domain. event, leads us believeapproaches obtain comparable results across domains.Tables 10 11 present results regards accuracy fraction wordscovered, respectively, obtained trained MT-based approachalignment-based approach language pairs. case trained MT-basedapproach, MT systems available used (Table 1 lists MT systems availablelanguage pair).results confirm hypothesis alignment-based approach generally obtainsbetter results regards coverage MT-based approach language pairs,reasonable, given alignment models trained TMused translation. Accuracy yet strongest point trained MT27. Although differences accuracy observed, possible state MT systembetter statistical significance p 0.05 case =60% =90%.198fiTarget-Language Edit Hints CAT Tools Based TM Means MT02.40.10.40(%) method(%)trainedalignmenttrained70alignmenttrained80alignmenttrained90alignment6095.14.193.90.295.63.294.32.296.39.295.10.296.90.295.34.305.20.20.10NC (%)5.13.16.09.25.18.25.90.25.53.25.37.25.86.34.93.3(%)06.30.10.00NC (%)95.62.492.97.597.02.494.16.695.78.894.56.895.361.194.261.27.20.56.22.56.44.65.96.610.421.15.51.811.131.55.191.1(%)NC (%)94.87.391.38.394.93.594.57.595.00.795.20.697.65.996.471.111.33.318.31.410.55.67.78.512.8414.80.69.311.66.151.3Table 9: Accuracy (A) fraction words covered (NC) obtained trainedMT-based approach alignment-based approach translating esenthree different domains using MT systems. corpusvalue , statistical significance test performed approachesregards accuracy fraction words covered. resultsshow improvement statistically significant p 0.05highlighted bold type.60(%)lang.pairesenenesdeenendefrenenfrfienenfiesfrfrestrained95.1.190.0.294.2.288.9.295.2.189.7.293.2.289.1.291.2.289.4.270(%)alignmenttrained93.9.288.7.292.6.287.9.293.4.289.4.291.9.287.1.289.4.288.6.295.5.291.5.295.8.291.1.296.3.291.9.294.6.290.2.393.2.292.1.2alignment94.3.289.8.293.8.289.7.295.1.291.3.293.1.288.5.390.7.291.1.280(%)trained96.3.292.3.296.6.293.0.297.0.293.3.294.7.290.3.394.8.293.5.2alignment95.1.290.4.294.7.291.5.296.0.292.1.293.3.388.4.392.8.292.2.290(%)trainedalignment97.0.293.0.297.2.292.8.397.6.295.7.294.8.390.6.496.0.293.6.395.3.391.8.395.5.391.5.396.4.294.3.392.8.488.9.494.3.292.2.3Table 10: Accuracy (A) obtained trained MT-based approachalignment-based approach translating language pairsdomain 02.40.10.40. results obtained several values FMSthreshold using available MT systems language pair.language pair value , statistical significance test performedaccuracy obtained approaches. results showimprovement statistically significant p 0.05 highlightedbold type.199fiEspla-Gomis, Sanchez-Martnez & Forcada60(%)lang.pairtrainedesenenesdeenendefrenenfrfienenfiesfrfres6.2.17.3.110.5.211.6.27.7.27.9.111.2.211.6.217.8.219.5.2alignment6.1.17.7.15.8.15.6.14.3.15.9.19.9.27.2.24.9.110.3.170(%)80(%)trainedalignmenttrained6.4.28.3.210.7.212.4.27.7.28.8.211.3.311.0.318.4.219.4.35.9.28.8.26.2.26.2.24.1.26.0.210.2.27.0.24.9.19.5.26.5.28.6.210.9.313.0.38.1.39.6.211.5.312.0.318.6.320.4.3alignment5.4.29.4.26.0.26.5.24.2.26.0.210.6.37.2.25.0.210.5.290(%)trainedalignment6.3.39.5.312.4.414.5.47.6.39.4.311.6.412.6.421.2.417.6.44.9.310.7.36.0.36.6.33.5.27.8.310.9.48.0.35.6.25.9.2Table 11: Fraction words covered (NC) obtained trained MT-basedapproach alignment-based approach translatinglanguage pairs domain 02.40.10.40. results obtained several values FMS threshold using available MT systems languagepair. language pair value , statistical significancetest performed fraction words covered obtainedapproaches. results show improvement statistically significant p 0.05 highlighted bold type.200fiTarget-Language Edit Hints CAT Tools Based TM Means MTbased recommender. Another interesting detail experiments language pairsEnglish target language obtain better accuracy experimentsinverse language pairs. due fact DGT-TM, usual find freetranslations languages English, original languagedocuments TM.28 particularly frequent find additional informationtechnical English words languages. example, software translatedSpanish, translated segments include text equipo logico (software).translation includes correct translation original word, order keepmeaning original English segment. important issue since, freetranslations used reference evaluate accuracy approaches presentedwork, lead lower accuracy. problem analysed, partially bypassed,additional experiments presented Appendix B. seen, trained MT-basedapproaches provide, general, better accuracy. However, language pairs,coverage obtained alignment-based approach much better. Neverthelessresults still reasonably similar considered comparable.Table 12 shows results obtained different approaches:29 nave FMSonly baseline, alignment-based approach, trained training-freeMT-based approaches, esen language pair 02.40.10.40 domain usingMT systems available simultaneously. table provides detail: additionaccuracy percentage words covered, also includes precision recallkeeping recommendations changing recommendations. table allowsbetter understand differences approaches starting complexcomparison different scenarios. Throughout section provide information regardingprecision recall significant tables presented.Leaving aside nave FMS-only baseline, observed accuracysimilar approaches, trained MT-based recommender obtains slightlybetter results. already mentioned, amount words covered similarMT-based approaches alignment-based approach. regards precision,trained MT-based approach seems outperform others, although approachesobtain comparable scores. results coherent obtained restlanguage pairs: general recall precision keep recommendations similarapproaches, MT-based approach seems precise casechange recommendations, difference much higher, specially higher valuesFMS threshold . conclusions extensible data shown Table 13.results shown Table 12 extended repeating experiment computingrecommendations content words (i.e. ignoring stopwords). done usinglist stopwords provided 4.7.2 version Lucene30 language utilisedexperiments. results experiments found Table 13. seen,results change much, thus confirming approaches perform equallywell content stopwords.28. According Steinberger et al. (2012), English source language 72% documents.29. nave FMS-only baseline recommend word changed, explained Section 6.5,signifying Pc cannot computed approach Rc always 0. Similarly, wordsapproach covered, therefore Rk always 1.30. http://lucene.apache.org/core/ [last visit: 15th May 2015]201fiEspla-Gomis, Sanchez-Martnez & Forcada(%)Method(%)NC (%)Pk (%)Rk (%)Pc (%)Rc (%)60FMS-onlyalignmenttrainedtraining-free82.7.293.9.295.1.193.3.2100%06.1.25.1.15.1.182.7.296.3.196.5.195.2.1100%096.5.197.8.196.8.180.8.387.6.282.2.30%080.2.381.8.374.9.370FMS-onlyalignmenttrainedtraining-free88.4.394.3.295.6.294.1.2100%05.9.25.2.25.2.288.4.396.6.196.8.195.9.2100%097.2.198.4.197.7.173.0.483.7.375.8.30%069.1.471.8.463.6.480FMS-onlyalignmenttrainedtraining-free91.7.395.1.296.4.295.3.2100%05.4.25.5.25.5.291.7.396.8.297.2.296.5.2100%098.0.199.0.198.5.168.4.480.8.471.0.40%057.2.561.1.551.3.590FMS-onlyalignmenttrainedtraining-free94.0.395.3.396.9.296.6.2100%04.9.35.9.35.9.394.0.396.5.297.3.297.4.2100%098.7.199.6.199.2.157.1.672.9.660.2.60%032.4.630.1.632.6.6Table 12: Comparison results obtained using trained MT-based approach,training-free MT-based approach, alignment-based approach naveFMS-only baseline. accuracy (A) fraction words covered (NC)reported, together precision (P ) recall (R) regards keepingrecommendations changing recommendations. results obtainedseveral values FMS threshold translating esen domain02.40.10.40, using MT systems available. Statistically significant resultsp 0.05 highlighted bold type. values two valueshighlighted column; means statisticallysignificant difference results, significantlybetter values.202fiTarget-Language Edit Hints CAT Tools Based TM Means MT(%)Method(%)NC (%)Pk (%)Rk (%)Pc (%)Rc (%)60FMS-onlyalignmenttrainedtraining-free81.2.393.7.295.1.293.3.2100%06.2.25.6.25.6.281.2.396.1.196.5.195.3.2100%096.4.197.6.196.6.182.1.388.1.283.0.30%080.8.383.7.377.9.370FMS-onlyalignmenttrainedtraining-free87.3.394.0.295.6.293.9.2100%05.9.25.7.25.7.287.3.396.3.296.9.295.9.2100%097.0.198.2.197.3.174.0.484.3.376.0.40%069.6.474.9.467.1.480FMS-onlyalignmenttrainedtraining-free90.8.394.9.296.4.295.1.2100%05.2.26.1.26.1.290.8.396.6.297.3.296.5.2100%097.9.198.8.198.2.170.5.581.6.471.5.50%058.7.565.6.555.4.590FMS-onlyalignmenttrainedtraining-free93.4.394.9.396.9.296.5.3100%04.5.36.6.36.6.393.4.396.1.397.3.297.4.2100%098.6.299.5.199.0.158.9.774.0.660.5.70%033.0.734.5.736.9.7Table 13: Comparison results obtained using trained MT-based approach,training-free MT-based approach, alignment-based approach naveFMS-only baseline. accuracy (A) fraction words covered (NC)reported, together precision (P ) recall (R) keepingrecommendations changing recommendations. Unlike Table 12, metricscomputed content words only. results obtained severalvalues FMS threshold translating esen domain 02.40.10.40,using MT systems available. Statistically significant results p 0.05highlighted bold type. values two values highlightedcolumn; means statistically significant differenceresults, significantly bettervalues.203fiEspla-Gomis, Sanchez-Martnez & Forcadatraininglanguage pairesenenesdeenendefrenenfrfienenfiesfrfrestraining-free(%)6070809095.08.1490.84.1992.52.1792.20.1892.65.1790.91.1992.38.1791.05.1992.36.1791.91.1893.36.1695.54.1691.80.2293.46.2093.22.2094.16.1992.23.2193.93.1993.36.2093.40.2092.24.2194.28.1896.34.1893.35.2395.09.2094.31.2295.78.1993.84.2395.30.2095.20.2094.56.2193.16.2495.41.2096.99.2194.94.2796.41.2394.88.2796.67.2295.24.2696.35.2396.47.2396.42.2395.49.2696.72.22Table 14: Accuracy obtained trained MT-based recommender translatingSpanish English domain 02.40.10.40 using recommendation modelstrained language pairs domain. first row, highlightedgrey, corresponds reference results obtained model trainedesen. Google Translate used experiment. Statisticallysignificant results p 0.05 highlighted bold type. valuestwo values highlighted column; meansstatistically significant difference results,significantly better values.experiments carried point confirmed three approachesproposed work perform similarly different scenarios. word-alignmentbased approach provides highest coverage is, therefore, able provide recommendations, MT-based approaches robust obtain higher stableaccuracy independently language pair domain used. results led usbelieve approach clearly stands better, mayuseful different scenarios, depending resources available translationconditions.7.3 Experiments Reusability Across Language PairsTable 14 presents results obtained trained MT-based recommender useddomain different language pair. experiments performeddomain 02.40.10.40 translating Spanish segments English re-using modelstrained language pairs. results obtained model trainedpair languages included table give idea upper-bound,corresponding row filled grey. models used, training testing,source information used Google Translate, since MT systemavailable language pairs used experiments.204fiTarget-Language Edit Hints CAT Tools Based TM Means MTresults show clear decline regards results obtained recommendation model learned esen learned language pairs,particularly low values FMS threshold . cases, accuracy obtainedtraining recommender language pairs different usedtesting worse obtained using training-free approach. exceptionmodel trained fren pair, similar pair esen.statistical significance test confirms that, values , either modeltraining-free approach best ones. difference accuracy obtainedapproaches =70% =90% fact statistically significant.results led us believe trained method highly dependentlanguage pair used training, thus making reasonable conclude betteruse training-free MT-based recommender MT-based recommender traineddifferent language pair.7.4 Experiments Reusability Across DomainsTable 15 presents results experiments concerning domain independence. objective experiments verify dependent trained MT-based recommenderdomain training corpus. case, re-used recommendation modelstrained three domains esen translation translate Spanish segmentsdomain 02.40.10.40 English, using MT systems available.drop accuracy observed re-using models trained out-of-domainTMs rather training TM used translation. However, caseaccuracy closer obtained recommendation model trainedTM used testing (in-domain). regard results obtainedalignment-based approach, difference accuracy MT-based approacheshigher statistically significant p 0.05. say, training-free MT-basedapproach models trained domain 05.20.20.10 perform best,statistically significant difference values . Similarly, coveragealignment-based approach clearly drops using out-of-domain models. duefact that, case alignment-based approach, words seentraining cannot aligned, since translation probabilities learned them.contrast, case MT-based approaches linguistic resources learnedtraining, rather obtained MT systems available: trainingMT-based recommender instead focuses relevance sub-segment lengthsamount sub-segment pairs covering word. general, conclusion drawnexperiment using either training-free approach classification model trainedcorpus different domain valid options perform betteralignment-based approach. closer look data one observebigger differences precision change recommendations, MT-basedapproach outperforms alignment-based approach.7.5 Experiments Reusability Across Machine Translation SystemsTable 16 presents results experiments concerning MT system independence. Threemodels trained three TM belonging domain 02.40.10.40, case205fiEspla-Gomis, Sanchez-Martnez & ForcadaalignmentMT-basedtraining-free(%)(%)training corpus6002.40.10.4005.20.20.1006.30.10.0093.90.16 6.09.1591.77.18 9.63.1990.23.20 11.67.2095.14.1493.34.1692.02.1893.27.165.13.147002.40.10.4005.20.20.1006.30.10.0094.32.18 5.90.1892.68.21 9.71.2391.60.23 11.61.2595.63.1694.03.1992.74.2094.14.185.18.178002.40.10.4005.20.20.1006.30.10.0095.10.20 5.37.2193.82.23 9.20.2693.21.24 11.05.2896.39.1795.56.1994.27.2295.29.205.53.219002.40.10.4005.20.20.1006.30.10.0095.34.26 4.93.2694.61.28 8.90.3494.20.30 10.27.3796.90.2196.53.2396.31.2396.61.225.86.28(%)NC (%)trained(%)NC (%)Table 15: Accuracy (A) fraction words covered (NC) obtained alignmentbased recommender, trainng-free MT-based recommender, trainedMT-based recommender translating Spanish segments English domain 02.40.10.40. results obtained re-using recommendationalignment models learned TMs belonging domains indicatedsecond column. results obtained models trained domain 02.40.10.40included (highlighted gray) reference. MT systems availableused training testing. Statistical significance tests carriedout, separately accuracy fraction words covered. Differencesresults statistically significant p 0.05 highlightedbold type. values , difference accuracyMT-based approaches statistically significant, differencesalignment-based approach statistically significant p 0.05.206fiTarget-Language Edit Hints CAT Tools Based TM Means MT(%) trained(%)60708090ApertiumGoogle Translate92.94.1793.41.2095.57.1996.65.2295.08.1495.54.1696.34.1896.99.21(%) training-freePower Translator91.12.1993.02.2094.78.2196.47.2393.36.1694.28.1895.41.2096.72.22Table 16: Accuracy (A) obtained trained MT-based recommender trainingfree MT-based recommender translating Spanish segments Englishdomain 02.40.10.40 using Google Translate MT system testing.trained approach, results obtained re-using recommendationmodels learned TM language pairs using three differentMT systems. results obtained using model trained Google (columngray) included upper-bound, included comparison.every value highest accuracy, statistically significant differencep 0.05 compared values, highlighted bold type.using one three MT systems available. models used translate segmentsSpanish English within domain using Google Translate MTsystem, order obtain sub-segment translations testing. resultstable similar presented last set experiments, reusabilityacross different domains studied. general terms, would appear dropaccuracy making change recommendations quite similar models trainedApertium Power Translator. addition, observed accuracy obtainedtwo models similar obtained training-free recommender.training-free approach is, fact, performs best 60% 70%difference accuracy statistically significant p 0.05. However, 80%trained approach using model trained Apertium performs best.Finally, difference among results = 90%.general, would appear re-using models trained MT systemdifferent used translation feasible, although using training-free approachprovide better results.7.6 Error Analysisfollowing sample frequent errors made different approachesproposed work word-keeping recommendation. objective error analysispropose strategies deal errors (when possible) future work.7.6.1 Errors Caused Synonyms Equivalent Expressionsincorrect change recommendations experiments resulted usedifferent synonyms translation proposal reference 0 used goldstandard. Let us suppose translation proposal (S, )= (the natural isotopic abundance207fiEspla-Gomis, Sanchez-Martnez & Forcadalithium-6 approximately 6,5 weight per cent (7,5 atom per cent)., la proporcionnatural del isotopo litio-6 es de aproximadamente 6,5% del peso (7,5% de atomos).),sentence 0 = natural isotopic abundance lithium-6 approximately 6,5 weight% (7,5 atom %). whose reference translation 0 = la proporcion natural del isotopo 6en el litio es de aproximadamente 6,5% en peso (7,5% de atomos).. seen,0 semantically equivalent written almost same, although percentagesymbol (%) used 0 , expression per cent used S. Although twooptions equivalent, per cent considered part matching0 occurrences. sub-segment pair (, ) =per cent =%,may led two occurrences symbol % changed, obviouslynecessary. Since symbol % also used reference translation 0 ,fact considered wrong recommendations evaluation.7.6.2 Errors Caused Morphological Differences Languagesproblem respects similar previous one, although problemconcern using different words concept, rather presence wordone languages may different morphologies language.example, found proposal (S, )= (optical equipment follows:,equipo opticosegun se indica:), sentence 0 = optical detectors, follows: whose referencetranslation 0 = detectores opticos segun se indica:. case word opticalmatched 0 , singular plural 0 . Englishforms share orthography, Spanish, plural mark added 0 (opticos),therefore differing singular form (optico). result, word optico wouldprobably recommended kept, although actually final translation(or least inflected way). worth noting would badrecommendation, since difference word kept word neededtranslation same, inflected different way. Whatever case might be,would necessary indicate situations way, order let user knowchange must made.7.6.3 Errors Caused Fertilityrefers fact translation single word one language translatedtwo word language. words form multi-word expressiontranslated properly using sub-segment covering whole expression.Sub-segments covering part expression lead out-of-context translationsproduce wrong evidence. instance, TU (S, )= (wavelength less1400nm, longitud de onda inferior 1400nm), proposed sentence 0 = wavelength equal greater 1400nm whose reference translation 0 = longitud deonda igual superior 1400nm word wavelength English translated longitudde onda Spanish. Since wavelength appears 0 , obvious threewords multi-word expression kept. However, context, word detranslated of, also appears matched 0 . word demay therefore obtaining keeping evidence sub-segments covering wholeexpression longitud de onda, changing evidence sub-segments covering208fiTarget-Language Edit Hints CAT Tools Based TM Means MTpart expression. situation may easily result change recommendation.probably difficult error fix, since motivated specificslanguage may, cases, extremely complex.8. Concluding Remarkspaper presented new approach assist CAT users employ TMsproviding recommendations target-side words translationproposals provided CAT system changed (modified removed) keptunedited. method propose imposes constraints type MT systemused, since used black box. method may use one MT systemtime obtain set features combined using binary classifierdetermine whether target words changed remain unedited.event, MT results never presented translator. version methodrequire training also proposed alternative.experiments carried bear witness feasibility methods proposedcomparing accuracy coverage previous approach based statisticalword alignment word-keeping recommendation. experiments tackle problemdifferent scenarios, comparing results obtained different domains, MT systemslanguage pairs. results obtained confirm viability MT-based methodsproposed work, particularly case trained MT-based approach (seeSection 4), obtains better results regards accuracy obtainedstatistical alignment-based approach (see Section 3). case coverage, resultsobtained MT-based approaches general worse obtained usingalignment-based approach alignment models trained in-domain TMs,better trained out-of-domain TMs. results also show reasonabledegree independence MT-based models respect domain TMMT system(s) used training. results suggest need re-trainclassifier new TM and, even importantly, necessaryevery time new TU added TM.general, models trained MT-based recommender much portableacross domains trained alignment-based approach. approachescompared training-free approach (see Section 5), also uses MT sourceevidence word-keeping recommendation, need training.experiments confirm results obtained training-free MT-based recommenderworse obtained trained recommender trainedTM used translating new texts. However, advisable use training-freeMT-based approach recommendation models TM availabletrained MT-based recommender.summary, MT-based approaches perform better alignment-based approaches accuracy important coverage, trainedout-of-domain TMs. regard MT-based approaches, better use trainedMT-based recommender model available pair languages MT system(s) used translating, use training-free MT-based recommenderotherwise.209fiEspla-Gomis, Sanchez-Martnez & Forcadaprincipal conclusion work three approaches comparableuseful depending needs translator resources available translation.might even possible combine three approaches (trained MT-based, training-freeMT-based, statistical alignment-based) order prove, example, recommendations words covered approaches others.results obtained study also opened new horizons futurework, as: extending method able provide userrecommendations words keep unedited, also actively suggest translationwords change; trying alternative parametric classifiers; using sourcesbilingual knowledge, glossaries, dictionaries, bilingual concordancers, etc.improve results MT-based approaches word-keeping recommendation.Appendix presents study confirms usefulness word-keeping recommendation translators, showing improvement productivity 14% translationtask Spanish English. plan extend experiments explore newways performing word-keeping recommendation. instance, would interestingcompare productivity translators receiving recommendations content words, optionally partial recommendations (on stems), receiving changerecommendations. also believe would interesting evaluate amountminimum recommendations needed segment make tool useful translators, computing productivity translators regards proposals low coverage.One main interests able model cost errors recommendations, i.e.confirm whether wrong keeping recommendation expensive translatorwrong changing recommendation. ideas require new set experimentsprofessional translators order obtain optimal method presentrecommendations, order maximise improvement productivity already shownAppendix A.study impact noise data set used evaluation paper includedAppendix B. study uses heuristic31 filter free wrong translationsdata sets. translated materials obtained experiments described Appendixadditionally used clean data set produced directly professional translators.results appendix show accuracy classification significantlyimproved using clean data sets.Finally, prototype plug-in free/open-source CAT system OmegaT32implements training-free approach described Section 5 proof concept, available downloaded http://www.dlsi.ua.es/~mespla/edithints.html.prototype uses free on-line MT systems perform word-keeping recommendation,thus confirming technical feasibility approach regards making on-the-fly recommendations real-world settings.31. heuristic based distance segment translate 0 source sidetranslation proposal S, distance reference translation 0 used gold standardevaluation target side translation proposal .32. http://www.omegat.org [last visit: 15th May 2015]210fiTarget-Language Edit Hints CAT Tools Based TM Means MTAcknowledgmentswork supported Spanish government projects TIN2009-14009-C02-01TIN2012-32615. would like thank Juan Antonio Perez-Ortiz, Andy WayHarold Somers suggestions. also thank anonymous reviewers helpedimprove original manuscript suggestions.Appendix A. Experiment Concerning Effect Word-KeepingRecommendation Translator ProductivityWord-keeping recommendation relatively new task. based assumptionproviding translators using translation memory (TM) tools hints wordschange keep unedited translation proposal increase productivity. Although might appear obvious assumption, needs empirically confirmed.objective experiment described appendix verify impact wordkeeping recommendation translation productivity, independently approach usedobtain recommendations.A.1 Methodologyexperiment, productivity professional translators measured translating several documents English Spanish using computer-aided translation(CAT) tool OmegaT, first without word-keeping recommendations them.task, five translators previous experience using OmegaT hired.translate three projects: short training project (training), usedfamiliarisation tool kind documents translate; project translated standard version OmegaT (standard ); project translatedmodified version OmegaT provided word-keeping recommendations (recommendation).training project five translators, five different standardprojects created (one translator). standard projects reused recommendation projects rotating translators, thus signifying none translatedproject twice. decision made use translations obtained standard projects reference computing word-keeping recommendationsrecommendation projects; would equivalent perfect classifier.often called oracle setting.Following structure described, experiment driven waytranslations would done time, room, using identicalcomputers. experiment divided two phases: first, training standardprojects translated, break half hour took placerecommendation project translated.A.1.1 CorpusDGT-TM (Steinberger et al., 2012) translation memory published EuropeanCommission Directorate-General Translation used build translation memoriestranslation projects used experiment. 90% document pairs211fiEspla-Gomis, Sanchez-Martnez & Forcadaused TM segment alignment. remaining 10% used build translationprojects: documents selected segments matched least one translationunit (TU) TM fuzzy-match score (FMS) higher equal 50%.Six translation projects created selection: one containing single document127 words (the training project) five containing three different documents1,000 words total.A.1.2 OmegaTexperiment, version 3.1 free/open-source CAT tool OmegaT usedplug-in OmegaT SessionLog 33 version 0.2, silently logs actions performedtranslator. initial version OmegaT modified avoid exact matches(FMS=100%) proposed, since would possible evaluate impact wordkeeping recommendation kind proposals.34 modified version OmegaTcreated also make word-keeping recommendations based former translations.version tool computes, given translation proposal, edit distancereference translation proposal, colours words kept greenwords removed replaced proposal red. meansrecommendations made version OmegaT professionaltranslator would make translating, i.e. perfect recommendations. (oracle setting).A.2 Resultsresults experiment shown Table 17. worth noting containsresults four data sets, given one translators forgot translatepart standard project assigned her, thus invalidating corresponding results.table shows time devoted translating test set, without usingword-keeping recommendation. Translation time measured segment.tool used capture edition information revealed segment usually selected(or visited ) several times whole process, translate review it.order show information clearly, two different measures obtainedsegment: total translation time (columns 2 3), time spentsegment taking account every visit it, edit time (columns 4 5),time spent translating first time using translation proposal.second measure, longest edit visit segment taken account,assuming edits made later visits corresponded review process. lastrow table presents total translation time column. seen,total time devoted translation reduced 14% using word-keepingrecommendation. Moreover, editing time, word-keeping recommendationmain impact, reduced 20%. gain translation time provedstatistically significant p 0.05 performing approximate randomisation test33. https://github.com/mespla/OmegaT-SessionLog [last visit: 15th May 2015]34. assumed exact match provides translation need edited, therefore,possible evaluate advantage word-keeping recommendations.212fiTarget-Language Edit Hints CAT Tools Based TM Means MTtest set1234test setstotal timeedition timewithout WKRWKRwithout WKRWKR3,664s3,613s4,251s3,787s2,611s3,467s3,709s3,315s2,441s3,080s2,674s2,432s1,917s2,293s2,310s1,937s15,315s13,102s10,627s8,457sTable 17: Time spent translation. Columns 2 3 compare total time spent translating test set, respectively, using version OmegaT withoutword-keeping recommendation. Columns 4 5 present comparison,taking account time actually spent reviewing test set.1,000 iterations.35 free/open-source tool SIGF V.2 Pado (2006) usedexperiments.results obtained experiment confirm assumption word-keeping recommendation significantly improve productivity translators use translationmemory tools. Although extensive experiment, including translators documents domains, would needed confirm this, current results encouraging.addition, translators participating experiment agreed word-keepingrecommendation useful translators working TM-based CAT tools.worth noting experimental framework presented appendixspecifically designed measure word-keeping recommendation results obtainedcannot therefore straightforwardly assumed every translation project. example, projects translated experiment used TM, thus ensuring least onetranslation proposal would provided FMS higher 50%, TMtype coverage may available given project. addition, translationsperformed humans used experiment compute word-keeping recommendations, would usually called gold standard. translations wouldobviously available real scenario recommendations would approximate.use gold-standard-based recommendations may also boost confidencetranslators using tool, since experiment correct times.therefore consider results correspond upper bound productivitygain. Nevertheless, results obtained experiment allowed us obtainclearer idea usefulness word-keeping recommendation confirm relevanceproblem obtaining fast accurate word-keeping recommendations.35. Here, approximate randomisation applied time devoted translating segmentwithout word-keeping recommendation concatenated data sets. method first computesdifference time needed translate entire data sets. randomly interchanges time spenttranslating segments sets results recomputes total time.equal higher time gain obtained randomised lists times, means resultsignificant.213fiEspla-Gomis, Sanchez-Martnez & ForcadaAppendix B. Experiments High Quality Gold Standardsappendix tackle problem associated use free translations references evaluation. already mentioned Section 7, pair segments (Sl0 , Tl0 )test set, obtain matching TUs (Si , Ti ), set word-keeping recommendations provided every segment Ti . Tl0 used gold standardrecommendations purpose evaluation. method assumes waySl0 translated Tl0 similar way Si translated Ti , thus enablinguse Tl0 reference.36 However, may case several reasons,wrong segment alignments, errors translations, or, case, free (but still adequate)translations. Following example shown Section 4, illustrate impact freetranslation evaluation method. Let us assume segment 0 translatedla situacion poltica parece ser difcil, matching TU (S, ) retrieved CATtool (la situacion humanitaria parece ser difcil, humanitarian situation appearsdifficult), gold standard 0 test set situation,political point view, appears tortuous, semantically valid translation 0 ,different . checking validity translation occurred Section4, words common 0 the, appears, situation, remainingwords would considered words change order produce correct translation.However, sufficient replace word humanitarian political producevalid translation 0 . therefore obvious 0 good referenceevaluate recommendations performed .consequence free translations test set, fraction recommendations actually correct considered inadequate evaluation sincematch reference test set. accuracy obtained approachespresented work therefore lower expected.Although loss accuracy affects methods work wayconclusions obtained therefore valid, wished see reliable resultsregards performance approaches could attained. therefore performedset additional experiments order bypass problem free translations.one hand, repeated experiments shown Section 7 usingconstrained test set pairs segments likely wrong(or free) translations discarded. hand, performed experimentre-using test set TMs described Appendix A.mentioned previously, first group experiments defined constraintorder attempt evaluate pairs segments test set Section 6.2reliable. done employing filtering based fuzzy-matchscore (FMS) used choose candidate TUs given segment translated.condition relies assumption FMS 0 (FMSS )similar FMS 0 (FMST ), since number words differedpairs segments proportional languages. Based idea,set threshold pairs TUs fulfilling condition |FMSS FMST |36. similar mean matching parts Sl0 Si translated way, thusproducing differences Tl0 Ti parts corresponding differences Sl0Si .214fiTarget-Language Edit Hints CAT Tools Based TM Means MT(%)domainfiltering0.05TUavgNwordsTUavgNwords6002.40.10.4005.20.20.1006.30.10.003.710.625.6895,8819,71834,3391.590.390.5244,2406,1986,9567002.40.10.4005.20.20.1006.30.10.002.360.370.9965,8656,88310,3271.160.260.2631,0224,8624,1948002.40.10.4005.20.20.1006.30.10.001.580.140.4546,5193,0154,7260.970.090.0924,9281,8892,1439002.40.10.4005.20.20.1006.30.10.000.700.050.0326,6251,5991,2680.500.030.0315,154975943Table 18: Average number matching TUs (TUavg ) per segment total numberwords (Nwords ) provide recommendation translating esenthree different domains. results obtained different rangesFMS threshold (), filtering = 0.05 filteringapplied.used training testing. worth mentioning experiments alsoperformed applying filtering test set, difference resultssignificant. experiments, arbitrarily set value 0.05, i.e.divergence 5% permitted FMS source language segmentstarget language segments, since threshold constrains examples usedhighly controlled scenario, reasonable number samples maintainedexperiments, shown Table 18.37B.1 Experiments Constrained Test Setstable shows, esen language pair fuzzy-match scores four differentranges, average number TUs matched per segment translated totalnumber words recommendation provided. results obtainedfiltering threshold filtering applied. worth notingcase domains 05.20.20.10 06.30.10.00 noticeable differencesmatching restriction applied, similar data obtainedfiltering = 0.05. led us believe TUs belonging domain05.20.20.10 regular translation domain 06.30.10.00.37. Note objective experiments compare different approaches (this already done), rather confirm whether improvement accuracy exists using less noisy datasets. statistical significance different approaches therefore re-computed.215fiEspla-Gomis, Sanchez-Martnez & Forcada(%)Method(%)NC (%)Pk (%)Rk (%)Pc (%)Rc (%)60FMS-onlyalignmenttrainedtraining-free84.7.396.4.296.9.295.2.2100%04.8.24.7.24.7.284.7.398.2.197.9.196.5.2100%097.5.298.4.197.9.185.8.390.8.387.3.30%089.4.388.2.379.9.470FMS-onlyalignmenttrainedtraining-free90.5.397.0.297.4.296.1.2100%04.7.24.4.24.4.290.5.398.5.198.3.297.1.2100%098.2.298.8.198.6.181.7.487.3.483.4.40%083.9.482.7.469.8.580FMS-onlyalignmenttrainedtraining-free93.2.397.4.298.0.296.7.2100%04.6.34.6.34.6.393.2.398.7.198.7.297.5.2100%098.5.299.2.198.0.277.1.586.5.479.8.50%079.4.579.5.561.7.690FMS-onlyalignmenttrainedtraining-free96.5.397.9.298.6.298.3.2100%04.1.34.2.34.2.396.5.398.9.299.0.298.9.2100%098.9.299.6.199.4.168.0.881.7.674.0.70%068.0.862.8.860.8.8Table 19: Comparison results obtained using trained MT-based approach,training-free MT-based approach, alignment-based approach naveFMS-only baseline. accuracy (A) fraction words covered (NC)reported, together precision (P ) recall (R) keepingrecommendations changing recommendations. results obtainedseveral values FMS threshold translating esen domain02.40.10.40, using MT systems available filtering = 0.05 (seetext).observed, threshold, approximately half training samples kept domain02.40.10.40 two thirds domain 05.20.20.10. case domain 06.30.10.00different; filtering removes far training samples low values FMS threshold, higher values loss high, similar domain 05.20.20.10.Table 19 equivalent Table 12, contains detailed comparisonapproaches, using filtering described data set. noted,results obtained case clearly better approaches obtainedexperiments filtering.Finally, Table 20 shows accuracy obtained trained MT-based approachalignment-based approach language pairs, occurs Table 10. worthnoting that, although differences results obtained approachessimilar, noticeably better.B.2 Experiment Human-Produced Test Setssecond group experiments used documents described Appendixtest set evaluate word-keeping recommendation. case, original documents216fiTarget-Language Edit Hints CAT Tools Based TM Means MT60(%)70(%)80(%)90(%)lang.pairtrainedalignmenttrainedalignmenttrainedalignmenttrainedalignmentesenenesdeenendefrenenfrfienenfiesfrfres96.9.295.1.296.9.296.3.296.9.295.9.296.0.296.3.295.6.295.2.296.4.293.6.296.3.294.8.296.7.295.5.296.0.294.8.395.3.294.8.297.5.296.4.297.7.297.2.297.9.297.4.297.3.297.2.296.8.296.7.297.0.294.8.296.8.295.7.297.7.296.8.297.1.295.5.396.5.296.3.298.0.297.1.298.3.297.6.298.4.298.1.197.7.297.7.297.7.297.3.297.4.295.5.297.4.296.2.298.0.297.3.297.5.296.0.397.2.297.0.298.5.297.8.298.3.297.9.298.5.298.3.298.0.397.7.398.1.297.4.297.9.296.9.397.5.397.0.398.1.297.5.297.5.397.5.397.4.297.0.3Table 20: Accuracy (A) obtained trained MT-based approachalignment-based approach translating language pairsdomain 02.40.10.40. results obtained several values FMSthreshold using available MT systems language pair.(%)(%)NC (%)(%)(%)NC (%)6070809097.8.198.6.199.0.198.7.210.0.28.5.28.1.37.3.46070809095.6.196.2.196.7.296.4.29.8.28.5.28.1.28.1.3Table 21: Accuracy (A) fraction words covered (NC) obtained translatingtrained MT-based approach reusing data set described Appendix A. left-hand table contains results translating SpanishEnglish, right-hand table contains results translating EnglishSpanish.Spanish translated English professional translators, told translatefaithfully possible. parallel documents therefore expected totallyfit requirements evaluation.experiment, TM used professional translators Appendix usedevaluate translation texts English Spanish vice versa. In-domainmodels also trained TM which, already mentioned above, consists629 TUs. Table 21 presents accuracy fraction words coveredobtained data set, enes esen. Although coverage slightly lowerobtained system data sets, accuracy much better,even better obtained constrained test sets.217fiEspla-Gomis, Sanchez-Martnez & Forcadaresults presented appendix allow us confirm accuracyapproaches presented work may noticeably higher presented Section7, lack valid gold standard experiments allows us approximateresults.ReferencesAhrenberg, L., Andersson, M., & Merkel, M. (2000). Parallel text processing: alignmentuse translation corpora, chap. knowledge-lite approach word alignment.Kluwer Academic Publishers. Edited J. Veronis.Bergstra, J. S., Bardenet, R., Bengio, Y., & Kegl, B. (2011). Algorithms hyper-parameteroptimization. Advances Neural Information Processing Systems 24, pp. 25462554. Curran Associates, Inc.Bertoldi, N., Farajian, A., & Federico, M. (2009). Online word alignment online adaptivemachine translation. Proceedings Workshop Humans Computerassisted Translation, pp. 120127, Gothenburg, Sweden.Bicici, E., & Dymetman, M. (2008). Dynamic translation memory: Using statistical machine translation improve translation memory fuzzy matches. Proceedings9th International Conference Intelligent Text Processing ComputationalLinguistics, Vol. 4919 LNCS, pp. 454465, Haifa, Israel.Bojar, O., Buck, C., Federmann, C., Haddow, B., Koehn, P., Leveling, J., Monz, C., Pecina,P., Post, M., Saint-Amand, H., Soricut, R., Specia, L., & Tamchyna, A. (2014). Findings 2014 Workshop Statistical Machine Translation. ProceedingsNinth Workshop Statistical Machine Translation, pp. 1258, Baltimore, USA.Bourdaillet, J., Huet, S., Langlais, P., & Lapalme, G. (2010). TransSearch: bilingualconcordancer translation finder. Machine Translation, 24 (34), 241271.Bowker, L. (2002). Computer-aided translation technology: practical introduction, chap.Translation-memory systems, pp. 92127. University Ottawa Press.Brown, P. F., Della Pietra, S. A., Della Pietra, V. J., & Mercer, R. L. (1993). mathematics statistical machine translation: Parameter estimation. Computational Linguistics, 19 (2), 263311.de Gispert, A., Blackwood, G., Iglesias, G., & Byrne, W. (2013). N-gram posterior probability confidence measures statistical machine translation: empirical study.Machine Translation, 27 (2), 85114.Depraetere, I. (2008). LEC Power Translator 12. MultiLingual, September 2008, 1822.Duda, R. O., Hart, P. E., & Stork, D. G. (2000). Pattern Classification (second edition).John Wiley Sons Inc.Espla, M., Sanchez-Martnez, F., & Forcada, M. L. (2011). Using word alignmentsassist computer-aided translation users marking target-side words changekeep unedited. Proceedings 15th Annual Conference EuropeanAssocitation Machine Translation, pp. 8189, Leuven, Belgium.218fiTarget-Language Edit Hints CAT Tools Based TM Means MTEspla-Gomis, M., Sanchez-Martnez, F., & Forcada, M. L. (2011). Using machine translation computer-aided translation suggest target-side words change.Proceedings 13th Machine Translation Summit, pp. 172179, Xiamen, China.Espla-Gomis, M., Sanchez-Martnez, F., & Forcada, M. L. (2015). Using on-line availablesources bilingual information word-level machine translation quality estimation. Proceedings 18th Annual Conference European AssocitationMachine Translation, pp. 1926, Antalya, Turkey.Espla-Gomis, M., Sanchez-Martnez, F., & Forcada, M. L. (2012a). Using external sourcesbilingual information on-the-fly word alignment. Tech. rep., Universitat dAlacant.Espla-Gomis, M., Sanchez-Martnez, F., & Forcada, M. L. (2012b). simple approachuse bilingual information sources word alignment. Procesamiento de LenguajeNatural, 49.European Commission Directorate-General Translation (2009). Translation ToolsWorkflow. Directorate-General Translation European Commission.European Commission Joint Research Center (2007). EUR-Lex pre-processing. http://optima.jrc.it/Resources/Documents/DGT-TM_EUR-LEX-preprocessing.pdf.Last retrieved: 15th May 2015.Forcada, M. L., Ginest-Rosell, M., Nordfalk, J., ORegan, J., Ortiz-Rojas, S., Perez-Ortiz,J. A., Sanchez-Martnez, F., Ramrez-Sanchez, G., & Tyers, F. M. (2011). Apertium:free/open-source platform rule-based machine translation. Machine Translation,25 (2), 127144. Special Issue Free/Open-Source Machine Translation.Foster, G., & Kuhn, R. (2007). Mixture-model adaptation SMT. ProceedingsSecond Workshop Statistical Machine Translation, StatMT 07, pp. 128135,Prague, Czech Republic.Free Software Fundation (2007). GNU general public license, version 3. http://www.gnu.org/licenses/gpl.html. Last retrieved: 15th May 2015.Gao, Q., Lewis, W., Quirk, C., & Hwang, M. (2011). Incremental training intentionalover-fitting word alignment. Proceedings 13th Machine Translation Summit, pp. 106113, Xiamen, China.Gao, Q., & Vogel, S. (2008). Parallel implementations word alignment tool. ProceedingsSoftware Engineering, Testing, Quality Assurance Natural LanguageProcessing Workshop, pp. 4957, Columbus, USA.Garcia, I. (2005). Long term memories: Trados TM turn 20. Journal SpecialisedTranslation, 4, 1831.Garcia, I. (2012). Machines, translations memories: language transfer webbrowser. Perspectives, 20 (4), 451461.Gough, N., Way, A., & Hearne, M. (2002). Example-based machine translation via web.Richardson, S. D. (Ed.), Machine Translation: Research Real Users, Vol.2499 Lecture Notes Computer Science, pp. 7483. Springer Berlin Heidelberg.Hall, M., Frank, E., Holmes, G., Pfahringer, B., Reutemann, P., & Witten, I. H. (2009).WEKA Data Mining Software: Update. SIGKDD Explorations, 11 (1), 1018.219fiEspla-Gomis, Sanchez-Martnez & ForcadaHornik, K., Stinchcombe, M., & White, H. (1989). Multilayer feedforward networksuniversal approximators. Neural Networks, 2 (5), 359366.Koehn, P. (2010). Statistical Machine Translation. Cambridge University Press.Koehn, P., & Senellart, J. (2010). Convergence translation memory statistical machine translation. Proceedings 2nd Joint EM+/CNGL, Workshop BringingMT User: Research Integrating MT Translation Industry, pp. 2131,Denver, USA.Koehn, P., Axelrod, A., Mayne, A. B., Callison-Burch, C., Osborne, M., & Talbot, D.(2005). Edinburgh system description 2005 IWSLT speech translation evaluation. Proceedings International Workshop Spoken Language Translation,Pittsburgh, USA.Kranias, L., & Samiotou, A. (2004). Automatic translation memory fuzzy match postediting: step beyond traditional TM/MT integration. Proceedings 4thInternational Conference Language Resources Evaluation, pp. 331334, Lisbon, Portugal.Kuhn, R., Goutte, C., Isabelle, P., & Simard, M. (2011). Method system usingalignment means matching translation. USA patent application: US20110093254A1.Lagoudaki, E. (2008). value machine translation professional translator.Proceedings 8th Conference Association Machine TranslationAmericas, pp. 262269, Waikiki, USA.Langlais, P., & Simard, M. (2002). Merging example-based statistical machine translation: experiment. Richardson, S. (Ed.), Machine Translation: ResearchReal Users, Vol. 2499 Lecture Notes Computer Science, pp. 104113. SpringerBerlin Heidelberg.Laubli, S., Fishel, M., Volk, M., & Weibel, M. (2013). Combining statistical machine translation translation memories domain adaptation. Proceedings 19thNordic Conference Computational Linguistics, pp. 331341, Oslo, Norway.Levenshtein, V. (1966). Binary codes capable correcting deletions, insertions reversals. Soviet Physics Doklady, 10 (8), 707710.Ma, Y., He, Y., Way, A., & van Genabith, J. (2011). Consistent translation using discriminative learning: translation memory-inspired approach. Proceedings 49thAnnual Meeting Association Computational Linguistics: Human LanguageTechnologies - Volume 1, HLT 11, pp. 12391248, Portland, Oregon.Marcu, D. (2001). Towards unified approach memory- statistical-based machinetranslation. Proceedings 39th Annual Meeting Association Computational Linguistics, ACL 01, pp. 386393, Toulouse, France.Meyers, A., Kosaka, M., & Grishman, R. (1998). multilingual procedure dictionarybased sentence alignment. Machine translation information soup: Proceedings third conference Association Machine TranslationAmericas, Vol. 1529 LNCS, pp. 187198, Langhorne, USA.220fiTarget-Language Edit Hints CAT Tools Based TM Means MTNieen, S., Vogel, S., Ney, H., & Tillmann, C. (1998). DP based search algorithmstatistical machine translation. Proceedings 36th Annual Meeting Association Computational Linguistics 17th International Conference Computational Linguistics - Volume 2, ACL 98, pp. 960967, Montreal, Canada.Och, F. J., & Ney, H. (2003). systematic comparison various statistical alignmentmodels. Computational Linguistics, 29 (1), 1951.Pado, S. (2006). Users guide sigf: Significance testing approximate randomisation.Sanchez-Martnez, F., Carrasco, R. C., Martnez-Prieto, M. A., & Adiego, J. (2012). Generalized biwords bitext compression translation spotting. Journal ArtificialIntelligence Research, 43, 389418.Sikes, R. (2007). Fuzzy matching theory practice. MultiLingual, 18 (6), 3943.Simard, M. (2003). Translation spotting translation memories. ProceedingsHLT-NAACL 2003, Workshop Building Using Parallel Texts: Data DrivenMachine Translation Beyond, pp. 6572, Edmonton, Canada.Simard, M., & Isabelle, P. (2009). Phrase-based machine translation computer-assistedtranslation environment. Proceedings 12th Machine Translation Summit, pp.120127, Ottawa, Canada.Simard, M., & Langlais, P. (2001). Sub-sentential exploitation translation memories.Proceedings Machine Translation Summit VIII, pp. 335339, Santiago deCompostela, Spain.Somers, H. (2003). Computers translation: translators guide, chap. Translation memory systems, pp. 3148. John Benjamins Publishing, Amsterdam, Netherlands.Somers, H. (1999). Review article: Example-based machine translation. Machine Translation, 14 (2), 113157.Specia, L., Raj, D., & Turchi, M. (2010). Machine translation evaluation versus qualityestimation. Machine Translation, 24 (1), 3950.Steinberger, R., Pouliquen, B., Widiger, A., Ignat, C., Erjavec, T., & Tufis, D. (2006).JRC-Acquis: multilingual aligned parallel corpus 20+ languages. Proceedings5th International Conference Language Resources Evaluation, pp. 21422147, Genoa, Italy.Steinberger, R., Eisele, A., Klocek, S., Pilos, S., & Schluter, P. (2012). DGT-TM: freelyavailable translation memory 22 languages. Proceedings 8th InternationalConference Language Resources Evaluation, LREC12, pp. 454459, Istambul,Turkey.Ueffing, N., & Ney, H. (2005). Word-level confidence estimation machine translationusing phrase-based translation models. Proceedings Conference HumanLanguage Technology Empirical Methods Natural Language Processing, HLT05, pp. 763770, Vancouver, Canada.Veronis, J., & Langlais, P. (2000). Evaluation parallel text alignment systems. Veronis,J. (Ed.), Parallel Text Processing, Vol. 13 Text, Speech Language Technology,pp. 369388. Springer Netherlands.221fiEspla-Gomis, Sanchez-Martnez & ForcadaVogel, S., Ney, H., & Tillmann, C. (1996). HMM-based word alignment statistical translation. Proceedings 16th International Conference Computational Linguistics, pp. 836841, Copenhagen, Denmark.Zhechev, V., & van Genabith, J. (2010). Seeding statistical machine translation translation memory output tree-based structural alignment. ProceedingsCOLING10, Workshop Syntax Structure Statistical Translation, pp. 4351,Beijing, China.222fiJournal Artificial Intelligence Research 53 (2015) 497-540Submitted 01/15; published 07/15Satisfiability SystematicityMatthew L. GinsbergConnected Signals, Inc.355 Goodpasture Island Road, Suite 200Eugene, Oregon 97401Abstractintroduce new notion systematicity satisfiability algorithms restarts,saying algorithm strongly systematic systematic independent restartpolicy weakly systematic systematic restart policies others.show existing satisfiability engines generally weakly systematic, describeflex, strongly systematic algorithm uses amount memory polynomialsize problem. large number factoring problems, flex appears outperformweakly systematic approaches.1. Introductionupon time, dpll (Davis, Logemann, & Loveland, 1962; Davis & Putnam, 1960)algorithm choice solving Boolean satisfiability problems, sat. threereasons this.First, dpll systematic particular problem solution, dpll wouldeventually find it. problem solution, dpll would identify unsatisfiable.properties essential want simply invoke solver, allow long necessarysolve problem, assured answer always result.Second, dpll used amount memory polynomial size problem.amount time used was, course, exponential given NP-complete nature sat.memory used polynomial, therefore logarithmic running time.finally, dpll worked. success harbinger uses later satengines would put, range problems dpll could practically appliedexceeded previous general-purpose NP algorithm. Today range wider still,including microprocessor verification (Kaivola, Ghughal, Narasimhan, Telfer, Whittemore,Pandav, Slobodov, Taylor, Frolov, Reeber, & Naik, 2009), device driver validation (Moura& Bjrner, 2010) many others (Biere, Heule, van Maaren, & Walsh, 2009).Two changes led significant algorithmic improvements. first recognitiondpll backtrack best thought move tree-like search space,instead resolution-based inference step. idea appeared first StallmanSussmans (1977) work dependency-directed backtracking Doyles subsequent (1979)work truth maintenance. earlier authors, however, described algorithmsmight accumulate exponential number resolution consequences searchproceeded.Ginsbergs (1993) work dynamic backtracking first show systematic nonchronological inference methods could constructed using polynomialamount memory, describing algorithm extension backjumping (Gaschnig,c2015AI Access Foundation. rights reserved.fiGinsberg1979). Bayardo Schrag (1997) continued work approach, renaming (sensibly) relevance-bounded learning. ideas currently known conflict driven clauselearning, cdcl, name introduced Ryan (2002) popularizedMarques-Silva, Lynce Malik (2009).work 1997 involved using scheme retaining learned clauses guaranteed polynomial number clauses would kept particularpoint search. grasp (Marques-Silva & Sakallah, 1999), requirementdropped. Virtually modern sat solvers use cdcl, generally modified wayeither allows unlimited number clauses collected (as tinisat, Huang, 2006;Quest0.5, Lynce, Baptista, & Marques-Silva, 2001) or, commonly, waylonger guarantees systematicity (zChaff, Moskewicz, Madigan, Zhao, Zhang, & Malik,2001; rsat, Pipatsrisawat & Darwiche, 2007; minisat, Sorensson & Een, 2005, manyothers).abandonment systematicity linked inclusion restarts satisfiabilityalgorithms. appears due Gomes, Selman colleagues (1998);basic idea escape areas solver thrashing (searching nearly endlesslywithout ever identifying real source problem) simply restarting scratch. Putsomewhat differently (but equivalently), restarts provide solver makesmistake near root search tree, Harvey (1995) refers early mistake.setting provided dpll, restarting prover inevitably result nonsystematicity. crucial information state search storedposition search tree, restarting search abandons information.work restarts matured two separate directions. First,considerable body work examining theoretical properties search restartscdcl case clauses retained search proceeds. searchobviously systematic, since limited number new clauses learnedeither solution found empty clause derived (proving original problemunsatisfiable).interesting conclusions drawn, however, fact restartsprevent thrashing appears related fact appear allow foxrflexible inference schema previous methods. work begun Beamecolleagues (2004), continued Buss et al. (2008) Hertel et al. (2008), extendedPipatsrisawat Darwiche (2011), showed cdcl restartsequivalent general resolution. Cdcl without restarts known generally ableproduce proofs exponentially shorter tree-based resolution, general resolutionlead exponentially shorter proofs tree-based resolution many instances (BenSasson, Impagliazzo, & Wigderson, 2000).1addition theoretical work, practical work proceeding well, focusinglarge measure development strategies identifying points searchrestarted. realized fairly quickly virtually restart policyimprovement restarting all. Luby et al. (1993) developed restart policyshowed within logarithmic factor optimal wide range problems.1. also known tree-based resolution cant polynomially simulate general resolution (Bonet &Johannsen, 2014).498fiSatisfiability SystematicityLuby restart policy shown outperform variety alternatives sat domainHuang (2007).Luby restart policy involves gradually (but monotonically) increasing number backtracks restarts; roughly speaking, 2kth restart first allows2k backtracks restarting again. refer effort undertakenconsecutive restarts probe; number backtracks restarts calledsize probe.Luby approach two useful consequences. first total numberbacktracks grows quadratically number restarts infrequencyprobes large size.second consequence Luby policy search systematic,assuming original procedure, without restarts, systematic. reasonLuby restart policy eventually involve probes sufficiently large sizesystematicity guaranteed.distinction worth formalizing. Given algorithm involves restartpolicy, say strongly systematic systematic independent restartpolicy chosen. say weakly systematic systematic restartpolicies others, say nonsystematic systematicrestart policy.connection systematicity amount memory used sufficientlyimportant present following classification sat solvers:Exp-spacePolyspaceStronglySystematictinisat?WeaklySystematicminisatNonsystematicwsatexp-space, mean algorithms demonstrably may take amount spaceexponential size problem solved; polyspace algorithmsremove learned clauses thus could, least theory, use polynomial amountsspace result.Memory cheap days; perhaps exp-space much drawbackwas. turns case, following reason.CPU time consumed sat engines spent unit propagation procedure, finds obvious consequences variable assignments made particularpoint search. Although variety engineering improvementsspeed process considerably (Moskewicz et al., 2001), overall time still linearsize accumulated clausal database. database grows exponentiallysize, time needed single inference therefore grow exponentially well.Given tinisats existence upper left, little interest exp-spacesolver weaker systematicity properties. tinisat cannot really consideredproduction solver; difficult problems, number stored clauses grows impracticallysolver essentially grinds halt.previously discussed wsat family algorithms (Selman, Kautz, &Cohen, 1993), shall we. algorithms different spirit onesdescribed thus far, working complete variable assignments using hill499fiGinsbergclimbing attempt gradually convert assignments solutions problemsinvestigated. competitive 1990s, progress systematic algorithmsfundamentally nonsystematic approaches currently given relatively little attention, although recent work shown connectionalgorithms cdcl approach closer one might think (Goultiaeva & Bacchus,2012).modern sat solvers join minisat middle bottom row, weakly systematic using relatively modest amount memory get job done. Removingclauses essential practical solver simply known stronglysystematic algorithm capable so. general view althoughstrongly systematic, systems work exceptionally well practice, including managingproduce proofs unsatisfiability necessary.noted, however, loss systematicity simple theoretical concession. obviously important, example, distinct probes beginsearch distinct locations search space. starting locations closesense, also important corresponding probes overlap little possible.believe experimental results Section 4 support intuition.remarked, work dynamic backtracking introduced first nonchronological, polyspace, weakly systematic sat engine. goal current paper describe new cdcl-based sat engine flex polyspace strongly systematic.outline paper follows. Section 2, introduce necessary notationdescribe standard cdcl algorithm. also describe choices typically madeimplementing algorithms.Section 3 describes flex algorithm; proof systematic polyspacedeferred appendix. discuss additional data structures needed guaranteesystematicity, restrictions must placed standard choices result.Experimental results presented Section 4 concluding remarks Section 5.2. Background, Notation Existing Worksatisfiability problem, mean collection clauses Boolean variablesas:abbbb cclauses disjunction, goal value variablesclause satisfied. particular example, make b true, cfalse.Definition 2.1 variable letter, a, b, c on. literal variablenegation variable. clause disjunction literals; (unsatisfiable) emptyclause denoted . theory conjunction clauses.500fiSatisfiability Systematicityinterpretation bias assignment true false variable theory.interpretation said model theory every clause satisfiedinterpretation.often call theories sat instances satisfiability problems, thinkclauses simply sets literals contain, writing, example, b.similarly think theories sets clauses, think size theorysimply number clauses , denoting |T |.2Modern satisfiability algorithms work manipulating partial assignments valuesvariables; idea either extend partial assignment value variables(and eventually model theory question) show particular partialassignment cannot extended model.Definition 2.2 partial assignment sequence P = hl1 , l2 , . . . , ln literals6= j, li 6= lj li 6= lj . variable v called valued P v Pv P . literal l called satisfied P l P , called falsified Pl P . clause c called falsified P every literal l c falsified P .practice, variables assigned values partial assignment typically annotatedreasons sort. variable value may result choice made searchengine, obvious result previous choices:Definition 2.3 annotated partial assignment sequence h(l1 , c1 ), (l2 , c2 ), . . . , (ln , cn )ipairs, pair contains literal li clause ci . clause ci calledreason li , set {c1 , . . . , cn } {} denoted R(P ) called reasonsannotated partial assignment.Given annotated partial assignment P , ith pair (l, c) P called justifiedeither c = l c every literal c l lj j < i. annotatedpartial assignment P called justified every (l, c) P justified.Note justified partial assignment always contain pairs form (l, ), sincejustification condition trivially satisfied. use indicate l choicemade search algorithm:Definition 2.4 P annotated partial assignment (l, ) P , say lchoice P . set choices P denoted C(P ). set negationschoices P denoted C(P ).Similarly, justified partial assignment always contain pairs form (l, l),use indicate l proven consequence theoryinvestigated.general, partial assignments consider justified.2. complexity perspective, might seem natural think size theory totalnumber literals clauses . choice bit convenient notationally theoryinvolving v variables, total number literals obviously v|T |.501fiGinsbergDefinition 2.5 Let P annotated partial assignment. (l, c) ith elementP , say assertion level l|{j i|cj = }|clause , say assertion level maximum assertionlevels literals .words, assertion level literal number choice variablesprecede P .Definition 2.6 Let P annotated partial assignment theory . clause =l1 ln literal satisfied P , exactly one literal unvaluedP , called unit.single literal l unvalued P unsatisfied clause , extensionP model must include l, P remain justified partial assignmentadd (l, ) end. called unit propagation:Definition 2.7 Unit propagation procedure unit accepts input theoryjustified partial assignment P . returns pair (P 0 , c) P 0 maximal justifiedpartial assignment extends P , P P 0 , either c = true c falsifiedP 0 .unit propagation returns c = true, unit propagation succeeded. returns partialassignment P 0 clause c falsified P 0 , contradiction found creason.Definition 2.8 say backtrack level zero every literalassertion level, second greatest assertion levels literals otherwise.Given annotated partial assignment P clause , define result backtracking , denoted backtrack(P, ), result removing Pliteral assertion level greater backtrack level .clause backtrack level n 6= 0, clearly literal lassertion level l greater n. literal l unique, backtrackingbacktrack level leave every element l unchanged,(which contradiction prior backtrack) unit clause backtrackcomplete.sat implementations spend bulk time unit procedure;consequence fact must search theory unit clauses. Moskewiczet al.s (2001) introduction so-called watched literals zChaff sped process considerably, continues consume bulk computational resources implementedsystems.Eventually, unit propagation either terminates without finding contradiction (presumably unit clauses remain ), returns clause c falsifiedcurrent justified partial assignment P . latter case, satisfiability engine needs502fiSatisfiability Systematicityrespond new information modify P way. Dpll, example, wouldmodify P simply returning recent choice point resuming search.Cdcl implementations work differently. take P c produce new clauseentailed captures, best possible, reason went wrong.example, suppose P gives = b c reason c (so P containsa, b therefore c), = c appears . clause falsifiedP . resolve get new clause b, also falsified Psuggests (correctly) either b source problem even manyvariable choices appear subsequently P itself. may enable much deeper backtracksimply returning recent choice point.Definition 2.9 Let P justified partial assignment, c clause falsified P .(P, c)-conflict mean clause logical consequence c togetherreasons P also falsified P , c R(P ) |= P |= .shown above, unit propagation identifies contradiction, use resolutionderive (P, c)-conflict P current partial assignment c conflictingclause .also sometimes more. Consider following theory:b(1)b e c(2)e(3)f c(4)imagine e f true, choose make true well. unitpropagation allows us conclude b c b (and e), also c(and e f ). single resolution (2) (the reason c) (4) (the reasonc) allow us concludeb e f(5)go further, resolving (5) reason (1) b get e falso resolving reason (3) get simply e f . lastconclusion correctly identifies source problem e ftrue.see example single (P, c) pair may many conflictsgenerally need identify single conflict continue search.general, want select conflict single literal assertion level.allow algorithm redraw conclusion question backtrackingbacktrack level conflict. Continuing example, suppose levelschoice literals involved 1 e f 4 choice literal a. explained,following possible learned clauses case:clauseb e fe fe fassertionlevel444503literalsassertion levelb,a,backtracklevel111fiGinsberglearn last clauses able draw unit conclusion(a) backtracking level one.Definition 2.10 Given justified partial assignment P clause , let n assertion level . called unique implication point, uip, uniqueliteral whose assertion level n.Uips introduced grasp (Marques-Silva & Sakallah, 1999), experienceshown part strategy selecting conflict clause always selectuip. done resolving away reasons multiple literals assertionlevel .describe cdcl-based inference engine. so, recall Definition 2.1 bias complete assignment values variables. B bias vvariable, denote B(v) value specified bias v, B(v) BB(v) = v B(v) = v. also define:Definition 2.11 bias B set literals S, define result restricting BS, denoted B|S , B|S = B {l|l S}.Informally, result restricting bias label literals true, removingnegations appeared bias restriction performed.bias intended capture current guess likely values model. extend partial assignment take value new variable, choosevariable use value suggested bias. specific example ideaintroduced Pipatsrisawat Darwiche (2007) rsat called phase savingwork.33. similar idea introduced slightly earlier Selmann Ansotegul (2006); earlier still, Beck (2005)introduced idea saving preferred values use next portion search.504fiSatisfiability SystematicityProcedure 2.12 (CDCL) Let theory, set clauses |= , Bbias . compute cdcl(T, , B, n), one of: shown unsatisfiable,model P one found, unknown solution found n steps:1 0;2 < n3(P, c) unit(T , P );4c = true5P assigns value every variable return P ;6v variable unvalued P ;// choice7(P, c) unit(T , hP, (B(v), )i);8(P, c)-conflict uip;// choice9{};10B B|P ;11return ;12P backtrack(P, );13discard(, P );// choice14ii+115 return unknownalgorithm hardly original us, let us give explanation event.algorithm proceeds, P justified partial assignment consideredcollection learned clauses.algorithm works extending partial assignment P either solutionfound (line 5) new clause learned (line 7 c 6= true). latter case,identify new conflict-driven uip (line 8), add , backtrack unit,repeat. update bias search proceeds; present line 10 rsat choiceupdating bias every time variable set unit propagation. seeSection 3, choices also possible.4new clause discovered added line 9, discard elements(line 13); potentially shrink relatively small (andpotentially polynomial) number clauses retained. either giveencountered n backtracks, continue searching.Recall annotated partial assignment P , R(P ) set reasons literalsP . (P, c) value returned unit propagation, abuse notationsomewhat use R(P, c) denote simply R(P ). have:Lemma 2.13 Suppose R(unit(T , P )) discard() = ,never discard reasons unit clauses become reasons. throughoutexecution Procedure 2.12, |= P justified partial assignment. addition:4. attentive reader may wonder test line 11 appear addedline 9 bias updated line 10. reason flex may perform additional inferencepoint.505fiGinsberg1. Procedure 2.12 returns , unsatisfiable. Procedure 2.12 returns Ppartial assignment P , literals P model .2. theory v variables n 2v , Procedure 2.12 return unknown,independent nature discard.Proof. first show invariants mentioned above. P justified partial assignment follows fact returned unit; justified partial assignmentobviously remain backtrack appears line 12. |= followsfact entails (P, c)-conflict P justified partial assignmentc T.consider various points Procedure 2.12 returns. line 5, Pmodel . line 11, unit propagation resolution collectively derived(P, c)-conflict, |= unsatisfiable.Procedure 2.12 return unknown bit subtle. see this, supposepartial assignment P . associate P sequence positiveintegers hn0 , n1 , . . . , nk i, nj number literals P assertion level j.call sequence size P denote size(P ).let n = hn0 , n1 , . . . , nk = hm0 , m1 , . . . , ml two sizes. saysmaller n, writing < n, one following two conditions holds:1. j mj 6= nj and, first j, mj > nj .2. mi = ni k, j k < j l mj > 1.Informally, size partial assignment gets smaller, made progressderived consequences earlier search tree, unexploredregion search space therefore gotten smaller. formalize via followingtwo claims:1. Denote Pi partial assignment line 3 Procedure 2.12 given valuei. size(Pi+1 ) < size(Pi ).2. s1 > s2 > > sz properly descending sequence sizes, z 2v , vnumber variables theory question.Note two results suffice complete proof, since followloop Procedure 2.12 repeated 2v times.first claim, note new clause unit backtrack line 12.Since unit, reason unit(T , P ) therefore cannot discardeddiscard. let j assertion level . immediate unitpropagation line 12, least one new variable assigned value level j.suppose size(Pi ) = hn0 , n1 , . . . , nk i, size(Pi+1 ) = hm0 , m1 , . . . , mj i. (Thenumber assertion levels Pi+1 necessarily equal j.) Pi Pi+1 agreepoint backtrack, mk = nk k < j. j k (so backtrack broughtus Pi ), mj > nj size(Pi+1 ) < size(Pi ). If, hand, j > k,506fiSatisfiability Systematicitysizes agree k mj > 1 conclusion unit consequencelevel. proves first claim.second, note first ordering conditionsunchanged appendPend size hn0 , n1 , . . . , nk enough 1s ni = v. essentially pretendsadded values subsequent variables, unit propagationsvariables. write n result extending sequence way,easy see n < n < m.let n size. claim descending sequence length least 2vn0steps beginning n ending size m0 > n0 . proof inductionv n0 .v n0 = 1, n0 = v 1 must n = hv 1, 1i.way make smaller = hvi, m0 > n0 .inductive step, suppose n = hn0 , 1, . . .i. 2vn0 1 steps,gotten hn0 , 2, . . .i inductive hypothesis. 2vn0 2 steps,gotten hn0 , 3, . . .i, on. therefore arrive hn0 , v n0vn0 1X2vn0 = 2vn0 2i=1steps. One step, total 2vn0 1, causes n0 increment. 2vn0 steps thus causen0 increment well. completes induction.imagine add new variable w theory, w appears clausesevaluated first search begins. new theory v + 1 variables, givensize partial assignment must first component incremented2(v+1)1 steps, either learned something w (an impossibility)derived empty clause . Thus second claim follows lemma proved.proof similar spirit proof Theorem 3.10, main theoreticalresult.general, Lemma 2.13 appears common knowledge sat community,although unaware published proof second claimcompletely clear sat community knows true.5point, yet included restarts algorithm,straightforward. define:Definition 2.14 restart policy mapping r : IN, set positiveintegers.restart policy simply gives number backtracks permitted functionprobe.5. similar result, similar proof based assumption clauses ever deleted,appear Section 4.2 Zhangs (2003) Ph.D. thesis.507fiGinsbergProcedure 2.15 (CDCL restarts) Let theory r restart policy.compute sat(T, n), either empty clause unsatisfiable model :1 ;2 B bias ;// choice3 1;4 true5x cdcl(T, , B, r(i));6x 6= unknown return x;7+ 1;2.1 Theoretical Resultsshow following:Proposition 2.16 Let theory involving v variables, r restart policy.Procedure 2.15 returns , unsatisfiable. Procedure 2.15 returns partial assignmentP , literals P model . addition:1. R(unit(T , P )) discard(, P ) = r(i) 2v ,Procedure 2.15 always terminate.2. discard(, P ) = R(unit(T , P )), || v Procedure 2.15 executed.3. discard(, P ) = , size may grow exponential v, independentrestart policy r.Proof. proof Lemma 2.13 also shows Procedure 2.15 correct.Claim 1 Proposition 2.16 follows immediately claim 2 Lemma 2.13. Claim2 follows fact variable one reason R(P ). Claim 3follows fact amount memory used Procedure 2.15 linearrun time clauses ever discarded, known many problemsshortest resolution proof exponential length (Bonet, Pitassi, & Raz, 1997;Haken, 1985, 1995; Krajicek, 1997; Pudlak, 1997; Tseitin, 1970).Corollary 2.17 weakly systematic, polyspace instances Procedure 2.15.strongly systematic, exp-space instances Procedure 2.15.Proof. Take discard(, P ) = R(unit(T , P )) get weakly systematic polyspaceinstance virtue first two claims Proposition 2.16. discard() = ,resulting instance strongly systematic instantiation eventually runnew clauses learn, may use exponential amount memory thirdclaim Proposition 2.16.Tinisat exp-space, strongly systematic instance. Minisat (potentially) polyspace, weakly systematic instance.508fiSatisfiability Systematicity2.2 Practical Concernsaddition selection restart policy, three points explicitchoice must made Procedure 2.12, one choice must made Procedure 2.15. line 6 Procedure 2.12, variable selected addition P . line 8,particular conflict clause selected addition . line 13, set reduced,presumably order conserve memory (and thereby speed unit propagation).line 2 Procedure 2.15, initial bias selected.Given much work sat currently focuses one implementation Procedure 2.15(and therefore Procedure 2.12) another, considerable volume literaturechoices. summarize work here, providing additional detailsareas ideas constrain allowed options.Variable bias selection Variables generally selected cdcl prover usingheuristic called vsids (variable state independent decaying sum) introducedzChaff (Moskewicz et al., 2001). continue use vsids workdescribe here.also need specify initial bias, search choice valuedvariables. real reason prefer one initial bias another, especially givenvalues likely overwritten search moves forward. followminisats example set every variable false initial bias.6Conflict clause selection already remarked particular (P, c) pairmay many associated conflicts, generally wise select one uip.allow algorithm redraw conclusion question backtrackingbacktrack level conflict, central proof Lemma 2.13.sometimes more. Recall running example, derived uipe f . Suppose also actual choice literal level one g, e ffollowing g e g f respectively. continue resolution process,usingglearned clause instead e f . so?Definition 2.18 uip called decision uip, duip, C(P ) |= ,every literal negation choice P .Proposition 2.19 Let P justified partial assignment clause falsified P .(P, ) unique duip.Proof. way construct duip resolve literals away decisionsremain. hard see set decisions obtained independentorder resolutions.always work duip algorithm proceeds? Surprisingly, answerappears no; extra resolutions seem move conflict away realproblem often not. one thing remove literals6. naturally occurring problems, effectiveness biasing every variable false perhaps rootedso-called closed world assumption (Clark, 1978; Reiter, 1978), concern us here.509fiGinsbergsimply unnecessary. running example reason f e f ,obviously wise resolve conflict clause learned, replacing e fproperly stronger e.Zhang et al. define first uip follows.7 basic idea want definefirst uip uip minimal close eventual conflict possible.Definition 2.20 annotated partial assignment P conflict c, (P, c)-conflictuip called reduced proper subset (P, c)-conflict.close eventual conflict, Zhang et al. actually mean uip questionlate conflict graph possible:Definition 2.21 Let P annotated partial assignment suppose 1 2clauses falsified P . write 1 <P 2 every literal 1 either appears 2reason includes least one literal 2 . (P, c)-conflict reducedminimal transitive closure <P called first uip, fuip.remarked above, 1 <P 2 1 closer eventual contradiction (and thereforelater implication graph) 2 .Proposition 2.22 (Zhang, Madigan, & Moskewicz, 2001) Let P justified partialassignment clause falsified P . (P, ) unique fuip.basic idea proof construct fuip resolving enoughensure working uip removing literals subsumedliterals . Additional resolutions needed produce new clausesminimal <P .Cdcl-based provers work uip, performance generally bestfuips used (Zhang et al., 2001).learned clauses interact bias; general, want learn clauseconflict bias (and therefore encourages us adjust bias useful way).Definition 2.23 Given bias B, uip called bias uip B, buip B,B |= . buip minimal transitive closure <p Definition 2.21called first buip, fbuip.case bias B contains negations literals P (as Procedure 2.12 written), uip buip, since literals P always conflictvalues B. case, fuip fbuip well.also have:Definition 2.24 Let P annotated partial assignment B bias. sayP supported B C(P ) B, every choice literal P appears B.7. Zhangs description fuip bit less formal; Definitions 2.20 2.21 simply formalizationideas.510fiSatisfiability Systematicitywords, bias supports annotated partial assignment choices madeP suggested bias.Lemma 2.25 Let P justified partial assignment c clause falsified P ,suppose B bias supports P . duip (P, c) also buip.follows Proposition 2.19 bias supports annotated partialassignment, least one buip, therefore least one fbuip.difficult see fbuip unique (basically, stop resolving soon necessaryconditions met). Fbuips share crucial property modify learned clauseminimally subject restriction contradicts bias uip.Discard strategy Clause reduction generally proceeds estimating likely futurevalue clause subsequent search. least valuable clauses periodicallyremoved search proceeds. free follow identical strategy, althoughmarked essential preserving systematicity. clausesneed retained independent estimated future value. procedure usepolynomial amounts memory, number clauses must guaranteed growpolynomially size problem.3. FLEXConsider search polyspace, strongly systematic satisfiability algorithm.immediately have:Observation 3.1 Strongly systematic, polyspace satisfiability algorithms exist.reason obvious. Imagine implementation cdcl restarts,suppose maintain, one restart another, separate partial assignment PDconstructed dpll. additional data structure requires polynomial memory (atv clauses, size v), simply incorporate clausesPD , resulting algorithm clearly systematic.practice, however, essentially value. systematicity guaranteeddpll completely separate inference going individual probes,unlikely additional clauses much constrain search. addition,restart policies restart relatively infrequently, guarantee2v restarts required satisfying theoretical perspective, may littlevalue practice.3.1 Pure FLEXFar interesting would find instance Procedure 2.15 stronglysystematic. Showing possible main theoretical result paper.basic idea behind method manage set learned clausesretain enough information ensure solver making progress lexicographicsense, identify variables lexicographically earlier others.lexicographic ordering quite weak, weakened possible search511fiGinsbergproceeds. So, example, make progress eliminating one possible valuevariable a, drop restrictions relative ordering variables follow(although need remember indeed follow a).get somewhat better feel this, imagine ordered variablestheory way, variables ordered v1 < v2 < < vm .view progress eliminate value variable vi withoutintroducing new possible values vj j < i. repeatedly this,eventually manage eliminate value v1 , value remain eliminatedsearch proceeds. eventually eliminate one two values v2 , on.say making lexicographic progress happens.fact, dont need maintain complete ordering variables question.make progress eliminating value vi , really need remember variables precede vi ordering (since eliminated values must remaineliminated). Variables following vi ordering reordered subsequent searchsuggests so.formalize this, maintain partial order variables appearing theoryProcedure 2.12 executed.8 learn something new particular variablex, should, described above, free discard information regarding relativeordering variables follow x partial order. Since eliminated valuevariable x, ordering information longer needed. formalizefollows:Definition 3.2 partial order x point, define weakeningx, denoted x , partial order given x z z either= z x 6< y.words, weakened partial order original forgets< z x < < z, z follow x partial order.Proposition 3.3 x partial order.Proof. Reflexivity immediate. transitivity, suppose u x v x w. u = v,u x w since v x w. u 6= v, x 6< u since u x v. also u v wu w. Thus u x w. Anti-symmetry x follows immediately anti-symmetry.specific example, initial partial order < given < b < c < d, weakening partial order b produces <b b, b <b c b <b d. c incomparableb , since followed b original partial order.imagine justified partial assignment P . (l, ) pair P , isWreasonablethink implying l. words, think disjunction = j ljl1 li1 li+1 lk li8. note passing possible, difficulty, modify work dealcase preorder instead partial order. provides additional flexibilitymanipulation bias, obvious additional flexibility practical value.discuss partial order case interest maintaining clarity exposition.512fiSatisfiability Systematicityli = l literal (l, ) pair. retain partial assignmentone search probe another, retain partial ordering use splitantecedent conclusion particular clause. specific example, cfollows b ordering, c b c, clause b c interpretedb c.general, clause partial order, think -maximal elementsconclusion, rest antecedent:Definition 3.4 Let clause partial order variables contains.conclusion , denoted , disjunction= {l | 6 , > l}antecedent , denoted , = ( ).conclusion learned clause disjunction maximal literals ,antecedent negation whats left.Again, example may help. Suppose = b c partial orderc b d. c maximal elements , conclusiondisjunction c d. antecedent= ( )= ({a, b, c, d} {c, d})= {a, b}= (a b)= bone would expect. learned clause effectively rewrittenb ccavalier use notation, switching freely representingdisjunction set.Definition 3.5 set learned clauses partial order, denoteconjunction antecedents . denote conjunctionconclusions .finally position describe procedure add new clause. Procedure 2.12, via simple {} line 9, bitcomplex. addition also modify partial order replacelexicographically stronger clause circumstances:513fiGinsbergProcedure 3.6 compute add(, , ):1 = return (, {}, );2 select l ;// l intended conclusion3 = l4return add(resolve(, ), , )5 add x l x ;6 l ;7 remove c either c {l, l} =6 c {x|l < x} =6|c | > 1;8 return (, {}, )Line 1 handles edge case actually derived contradiction. Line 4calls resolution l l appear conclusions clauses , line 7 saysclauses deleted include either l l antecedent,ambiguous conclusions based variables follow l partial order.keeping overall lexicographic approach: make progressparticular literal l, forget everything following literals partial order,removing relative orderings (as per weakening line 6 Procedure 3.6)clauses contain (as per removal line 7).Proposition 3.7 Suppose contains n clauses involving v variables. Procedure 3.6 executed O(v 3 + nv 2 ) time.Proof. Except recursion, expensive steps line 6, potentiallytake time O(v 2 ) line 7, take time O(nv). assumes determinewhether x < time O(1), whatever data structure used retain partialorder, always compute entire partial order iteration loop,take time O(v 2 ). total time taken without recursion thus boundedO(v 2 + nv).maximum number recursive calls O(v), since variable resolvedupon once.o(v 2 ) unit propagation procedure remains practical problems containingmillions variables, expect add procedure 3.6 well. (And roughlyreasons: Clauses length v, literals generally appear relativehandful clauses, on.)Procedure 3.6 primary difference standard cdcl algorithm flex;replace act adding involved Procedure 3.6.so, note Procedure 3.6 may actually derive empty clause line 4;return theory containing empty clause line 1, leading failure line 11Procedure 2.12. have:514fiSatisfiability SystematicityProcedure 3.8 (Pure FLEX) Let theory, set clauses |= ,partial order variables , B bias . compute flex(T, , , B, n),one of: shown unsatisfiable, model P one found, unknownsolution found n steps:1 0;2 < n3(P, c) unit(T , P );4c = true5P assigns value every variable return P ;6v variable unvalued P ;7(P, c) unit(T , hP, (B(v), )i);8(P, c)-conflict uip B |= ;9(, , ) add(, , );10B B| ;11return ;12P backtrack(P, );13ii+114 return unknownNote require selection buip line 8 Procedure 3.8 (since requireB |= ), adjust bias cater conclusion new clauseline 10. observations important discuss practical implementationmethods.modification needed Procedure 2.15 initialize use partialorder :Procedure 3.9 (Pure FLEX restarts) Let theory r restart policy.compute sat(T, n), either empty clause unsatisfiable model :1 ;2 ;3 B bias ;4 1;5 true6x flex(T, , , B, r(i));7x 6= unknown return x;8+ 1;finally have:Theorem 3.10 Suppose theory n clauses involving v variables. Then:1. loop Procedure 3.8 executed time O(v 3 + nv 2 ),2. || v Procedure 3.9 executed,515fiGinsberg3. nn.Pni=0 r(i)2v , Procedure 3.9 finish completing iterationCorollary 3.11 Procedure 3.9 strongly systematic polyspace.proof Theorem 3.10 lengthy appears appendix.Note contribution show possible ensure systematicityretaining sufficient number learned clauses. Tinisat already shown this,Lecoutre et al. shown (2007) retaining single nogood per restart suffice.work, number restarts grows polynomially numberbacktracks, therefore potentially exponentially problem size. earlierresults thus may require keeping exponential number learned clauses; contributionshow polynomial number nogoods suffice.3.2 Hybrid FLEXProcedures 3.8 3.9 achieve basic theoretical goal set paper, directimplementation procedures written encounters two practical difficulties.First, add procedure expensive. Executing every backtrack introducesoverall computational burden greater unit propagation.Second, search Procedure 3.8 guided bias B, bias modifiedmatch every unit propagation, match conclusions newly learnedclauses. Experimentation shows rsat bias, matching result everyunit propagation, effective practice. cannot value newly selected variablesrsat, since bias doesnt support nogood, may buip line 8Procedure 3.8. fact, experimentation number factoring problems shows approximately 40% time, none clauses learned particular probe resolvedbuip.Nevertheless, straightforward way deal issues still preserveintuition underlying approach. probe, follow bias newclause learned. new clause buip (because bias followedconstructing it), incorporate new clause usual. completeprobe using rsat bias. this, follow rsat bias almost timecall add per probe, eliminating substantial computational overheadprocedure might introduce.refer compound procedure hybrid flex, simply flex. orderimplement it, need maintain two biases, refer B (for flexcomponent) R (for rsat component), two sets learned clauses,refer (for flex component) (for conventional component). finallyhave:516fiSatisfiability SystematicityProcedure 3.12 (FLEX) Let theory, sets clauses |= ,partial order variables , B R biases . computeflex(T, , , B, , R, n), one of: shown unsatisfiable, model P onefound, unknown solution found n steps:1 0;2 < n3(P, c) unit(T , P );4c = true5P assigns value every variable return P ;6v variable unvalued P ;7= 0 l B(v);8else l R(v);9(P, c) unit(T , hP, (l, )i);10= 011(P, c)-conflict uip B |= ;12(, , ) add(, , );13B B|14else(P, c)-conflict uip;15{};16R R|P17return ;18P backtrack(P, );19discard();20ii+121 return unknownProcedure 3.13 (FLEX restarts) Let theory r restart policy.compute sat(T, n), either empty clause unsatisfiable model :1 ;2 ;3 B R bias ;4 1;5 true6x flex(T, , , B, , R, r(i));7x 6= unknown return x;8+ 1;Theorem 3.10 Corollary 3.11, have:Corollary 3.14 Procedure 3.13 strongly systematic polyspace discard procedure ensures polyspace.517fiGinsberg4. Experimental Resultspresent experimental results based methods, let us describe settingexperiments performed.First, expect value results vary problem size. one majoradvantage existing methods, strong systematicity approach causeprobes late search examine areas search space unexplored earlier.advantage also drawback, however. Especially early search,probes small, rsat bias known extremely effective likely seeperformance degradation fact cannot follow bias first setchoices particular probe.easy problems, would expect methods perform worse conventional ones inability begin probes following rsat bias. difficultproblems, would expect methods perform better conventional ones,manage reach new areas search space older methods reexamining previously explored regions. dont know transitiontwo general problem types.order evaluate this, used two separate sets problems experiments.first set 1030 problems sat 2013 benchmarks. problems solved5000 second cutoff order ensure processes terminated.second set problems used number factoring problems (Bebel & Yuen, 2013).Although subexponential algorithms number factoring known exist (Buhler,Lenstra, & Pomerance, 1993, great deal subsequent work), reasonbelieve techniques involved bear significantly sat encodingsproblems.One advantage using number factoring problems gradually increasing difficulty run completion every case, avoiding fact simple timeout lessinformative regarding overall computational efficacy time needed actuallysolve problem. Problems gradually increasing difficulty generated simplyincreasing magnitudes numbers factored.number factoring problems generated using iterated Miller-Rabin testgenerate pairs primes using Purdom/Sabry (2005) sat generator producesat encoding problem factoring product primes. order avoidsituations factoring problem might easy, prime factors selectedsizes binary representations within three bits one another.given problem size (number bits number factored), fifty instancesgenerated randomly.baseline solver, used minisat 2.2 (Sorensson & Een, 2005).fact three separate sets changes needed make produce flex:1. First, converted minisat C C++ changed use C++ standardlibrary many locations instead variety specialized techniques includedminisat. refer solver stlsat.2. Second, flex expected efficient number restarts increases.minisat similar solvers, number backtracks restarting given518fiSatisfiability Systematicity100001.22 x ** 0.9916x1000stlsat1001010.10.010.010.1110minisat100100010000Figure 1: minisat vs. stlsat, sat competition problems (CPU time seconds)specified original Luby policy (Luby et al., 1993), instead multiplyingLuby numbers constant (generally taken 100, first probeinvolves 100 backtracks). order increase number probes, reducedmultiplicative factor four (so first probe involves four backtracks).refer solver stlsat4 .3. Finally, modified stlsat produce flex, also initial probe size four.present results sat 2013 benchmarks first, followed results numberfactoring. compare minisat stlsat, stlsat stlsat4 , stlsat4 flex.experiments run 24-core Intel Xeon machine running 2.2GHz 256KL2 cache per processor, 24GB main memory, 75GB swap space. 24 problemssolved time, swap space needed deal larger satcompetition instances, since many running parallel.9software used experiments available online appendix paper.stlsat.zip contains source stlsat, flex.zip contains source flex. (Stlsatflex various extensions removed.)4.1 Sat Competition ProblemsFigure 1 compares minisat stlsat sat competition problems. solvercloser original minisat always x-axis, modification y-axis,9. evaluate impact use swap running times larger problems, althoughobviously might substantial. practice, however, significant amounts swap used,none systems evaluated able solve problem question. addition, runningproblems serially would simply impractical given available hardware.519fiGinsberg100001.14 x ** 0.9999x1000stlsat_41001010.10.010.010.1110stlsat100100010000Figure 2: stlsat vs. stlsat4 , sat competition problems (CPU time seconds)axes plotted using log scale dashed line giving = x baseline. Onepoint plotted problem solved either two methods. point x =means old solver better; point x = y, new solver better.many cases, also give best polynomial fit form = axb fixedb. Figure 1, stlsat seen 22% worse minisat outset,exponent slightly one indicates disparity shrinking problemsbecome difficult. (Indeed, apparent looking graph itself.)find polynomial fit, use standard technique minimizingsquared vertical distance point line question. reasonflipped axes, would minimizing squared horizontal distanceline, potentially different fit would found. ensure fitfound independent axis selection, minimized sum squares actual(perpendicular) distances data points line question.cases, split data depending whether problem instancessolved satisfiable. interesting distinction here.results one might expect. Without fine-tuned data structures minisat, stlsat performs slightly worse. significant easy problems,two solvers appear virtually identical difficult instances.Figures 2 3 show impact reducing number backtracks per probe. Overall(Figure 2), 14% cost making change, cost nearly independentproblem size. Somewhat curiously, however, cost significantly different satisfiableinstances (a 22% cost, top Figure 3) compared unsatisfiable ones (a 7% savings,bottom Figure 3).520fiSatisfiability Systematicity100001.22 x ** 1.0043xstlsat_4 -- SAT10001001010.10.010.01stlsat_4 -- UNSAT100000.1110stlsat -- SAT1001000100000.93 x ** 0.9999x10001001001000stlsat -- UNSAT10000Figure 3: stlsat vs. stlsat4 , sat competition problems (CPU time seconds)521fiGinsberg1000003.60 x ** 0.9935x100001000flex1001010.10.010.010.1110stlsat_4100100010000Figure 4: stlsat4 vs. flex, sat competition problems (CPU time seconds)Note scatter cases much significant Figure 1.expected stlsat intended essentially unchanged minisatalgorithmic perspective, change restart frequency expectedfairly dramatic effects. Note also collection points either x = 5000 = 5000,indicating problem solved one method timed using other.Finally, Figure 4 compares stlsat4 flex sat competition problems, flexfactor 3.6 slower (4.53 times slower satisfiable instances; 2.01 times slowerunsatisfiable ones).10 Many problems time flex modifiedversion minisat.shown clearly Figure 5, compare number problemssolved stlsat4 flex sat competition problems. specific timecutoff, stlsat4 solves 2.5 times many problems flex.appear case, however, performance gap narrowingproblems become difficult; example, flex solves 36 problems 30005000 seconds; stlsat4 solves 42 problems time. reasonexamined number factoring problems well.1110. graphs satisfiable unsatisfiable instances shown; look basicallyFigure 4.11. Note cannot simply increase timeout limit sat competition problems; causedrelative handful new problems solved. generate interesting numberdifficult problems, want instances known satisfiable, number factoring seemssimplest way go.522fiSatisfiability Systematicity300flexstlsat4250problems solved2001501005000.010.1110CPU time (secs)100100010000Figure 5: stlsat4 vs. flex, sat competition problems (5000 second timeout)1000001.06 x ** 1.0069x100001000100stlsat_41010.10.010.0010.00011e-050.00010.0010.010.1110stlsat (all SAT)100100010000100000Figure 6: stlsat vs. stlsat4 , factoring problems (CPU time seconds)4.2 Number Factoringnumber factoring, generated 50 factoring problems size five 45 bits.problems run stlsat, stlsat4 flex.523fiGinsberg1000001.41 x ** 0.9743x100001000100flex1010.10.010.0010.00011e-051e-050.00010.0010.010.1110stlsat_4 (all SAT)100100010000100000Figure 7: stlsat4 vs. flex, factoring problems (CPU time seconds; 5000 second timeout)(relatively uninteresting) result comparing stlsat stlsat4 shownFigure 6. sat competition problems, reducing size first probe fourbacktracks leads small degradation performance satisfiable problems. includeprimarily ensure change probe size responsible resultsfollowing figures.Flex stlsat4 compared Figure 7. Here, show problems onemethod able solve 5000 seconds less, although exact timessolution used solvers. figure also includes dotted lines indicating 5000second timeout either solver.overall results similar previous section, although flexs performance improved somewhat. sat competition problems, 3.6 times slower overall4.53 times slower satisfiable problems specifically. number factoring problems,flex 41% slower stlsat4 .curve fit dominated large number easy problems case.addition, appears flex actually better stlsat4 problemsbecome difficult; many problems appear timing stlsat4 (pointsright x = 5000 seconds Figure 7) flex (points = 5000figure). suggests instead looking easiest factoring problems, lookhardest ones.done Figure 8, consider problems one two solversrequired least 5000 seconds reach solution. results strikingly different.glance shows flex general solving problems quickly stlsat4 ; fact,524fiSatisfiability Systematicity1000000.24 x ** 1.0010xflex10000100010010101001000stlsat_4 (all SAT)10000100000Figure 8: stlsat4 vs. flex, factoring problems (CPU time seconds; 5000 secondsharder)1000000.13 x ** 1.0101xflex10000100010010100100010000100000stlsat_4 (all SAT)Figure 9: stlsat4 vs. flex, factoring problems (CPU time seconds; 10,000 secondsharder)525fiGinsberg100000stlsatflex10000average CPU time (secs)10001001010.10.010.0010.0001510152025bits30354045Figure 10: stlsat4 vs. flex, average time factor n-bit numberline best fit shows flex four times fast stlsat4 . Restrictingproblems took least 10,000 seconds makes distinction sharper still;(Figure 9) flex eight times faster stlsat4 .Similar results appear Figure 10, shows average running time neededflex stlsat factor number n bits. Flex slower smaller numbersfaster larger ones. unfortunately impractical extend graph much further, sinceaverage runtime stlsat single 45-bit factoring problem already approximatelysix hours.previously, show number difficult problems (40 bits more) solvedsolvers function time Figure 11. cutoff less 1000 seconds, stlsat4performs best; problems get harder, reversed.5. Conclusion Future Workfundamental claim made paper sat communityneed abandon systematicity methods switched dpll-styleprovers cdcl-based ones. showed possible simultaneously guaranteesystematicity, maintain polynomially-sized set learned clauses, restart proverfrequently desired. Furthermore, showed hybrid puresystematic prover typical cdcl engine incurs significant computational costachieving goals, cost recovered run time appears reduceddifficult problems.Looking forward, two obvious ways work extended.526fiSatisfiability Systematicity300flexstlsat4250problems solved2001501005001101001000CPU time (secs)10000100000Figure 11: stlsat4 vs. flex, factoring problems (40 bits larger)First, seen value methods increases number restartsincreases. One principal reasons limit number restarts cdcl-basedprover restarting prover expensive. Recent work Ramos et al. (2011),however, suggests significant part expense avoided. basic ideaparticular probe may well begin search repeating many literalchoices unit propagations previous probe. case, reasonbacktrack past point two probes first diverge. Incorporating ideamethods improve value enabling larger number restartsthus making systematic component offer effective.Second, hope overall approach proposed guaranteeing systematicity retaining partial order appropriate set learned clauses finallyputs rest notion sat engines achieve systematicity careful managementsearch space defined partial assignments. instead learned clausal databaseguarantees systematicity semantic methods.general conclusion lead variety new algorithmic choices.example, values represented bias presumably best thought probabilisticestimates regarding likelihood particular literal appearing modeltheory question. probabilistic approach gives different flavor satisfiabilitygeneral, suggests recent results Monte Carlo Tree Search, mcts (Browne,Powley, Whitehouse, Lucas, Cowling, Rohlfshagen, Tavener, Perez, Samothrakis, & Colton,2012; Kocsis & Szepesvari, 2006, others) may well find place sat well.527fiGinsbergAcknowledgmentswould like thank Connected Signals Time Systems coworkers, especiallyAran Clauson Heidi Dixon, useful technical advice assistance. would alsolike thank anonymous referees many carefully considered commentssuggestions, improved paper enormously. Finally, would like thank DavidMcAllester many contributions work years; work presented drawsgreatly McAllesters original work (1993) partial-order dynamic backtracking.Appendix A. Proof Theorem 3.10proof Theorem 3.10 depend certain invariants maintained Procedure 3.8 executed. begin discussing invariants.A.1 Learned Clausesunderstand them, suppose set learned clauses derivedcourse systematic search. conditions would expect satisfy?answer this, imagine partial assignment P derivednew learned clause add .certainly expect P satisfy existing learned clauses. also assumeP satisfies antecedents learned clauses; keeping idealearned clauses continue relevant portion search spaceexplored.new clause ? First, turn uniqueconclusion partial order . addition, new learned clause newknowledge sense eliminates portion search space still admissible. words, expect conclusion distinct conclusionselements .Formally, have:Definition A.1 say partial order parses learned clause | | = 1.say set learned clauses acceptable partial orderfollowing conditions hold:1. , parses ,2. 1 , 2 , 1 = 2 , 1 = 2 ,3. 6|= .first condition repeats requirement conclusions individualliterals. second condition says contain two distinct learned clausesconclusion. third says least possible find partialassignment P described above, since collection learned clauses consistentantecedents learned clauses.Lemma A.2 acceptable partial order , contains one learnedclause particular variable x conclusion.528fiSatisfiability SystematicityProof. contains clauses x x conclusions, impossible, contradicting requirement acceptability.Proposition A.3 set clauses involving v variables acceptable partialorder , || v.A.2 Search Space Sizeconsidering general way new clause allows us improve bias,way new clause incorporated , let us examine simple specialcase fact total order variables question. meansparticular learned clause always interpreted forcing value single variablecontains occurs latest ordering .given set learned clauses , extend P either solve problemderive new learned clause . Given bias B, assuming B |=learned clause allows us improve bias, already remarked assumeB consistent . follows consistent well. lconclusion , update ?Note first l conclusion. were,would |= l therefore |= also. two cases: maycontain learned clause conclusion l, may contain learned clause.contain learned clause conclusion l, would like simply add. may cause become unacceptable, since may contain learnedclause l antecedent. simply add , result unacceptablerespect impossible satisfy elementssimultaneously satisfying antecedents.example, suppose contains learned clause c d, antecedentc. learn c simply add , includes cc, contradiction.case remove every learned clause lantecedent; call result 0 . take add(, ) 0 {}. parsesobviously continues parse learned clauses remaining 0 . 0 {} thereforeacceptable respect , since l longer appear antecedent learnedclause 0 .Given discarded learned clauses , basisconcluding procedure eventually terminate? do. mentionedmain body text, key observation made lexicographic progresssearch space. true allowed domains variables followingl may gotten bigger replaced 0 , domain l gottensmaller. Since l precedes variables total order, made lexicographicprogress systematicity remains guaranteed.Consider second case, contain learned clause conclusion l.Note first since acceptable, learned clause concluding l must unique.resolve learned clause obtain new learned clause . Every variableprecedes l according ordering , conclusion must precede l well.thus continue make lexicographic progress define add(, ) add(, ),529fiGinsbergessentially chosen incorporate lexicographically powerful resolventinstead original learned clause .ensure ideas clear, suppose original learned clause setgiven following, ordering ranks variables alphabetically:ac(6)cd enew learned clause b f , simply add . learned clauseneed removed conclusion f appear antecedent learnedclause .added b f , suppose learn c. example above,add learned clause remove every learned clause whose antecedent includesc, means original learned clauses removed , althoughb f retained. new set is:ab f(7)cmade lexicographic progress. true, original learned clause set (6)allowed c either true false; new learned clause set (7) forces c false.Reducing number possible values c counts progress, whatever happenspossible values subsequent variables.Suppose instead learning c, learned c f . conflictsb f , resolve two together obtain b c, total ordercauses us interpret b c. add previous paragraph;again, lexicographic progress made.restricted example contains essence ideas use generalcase. general case complex because, must ensure remainsacceptable, would also like ensure partial order remains flexiblepossible. approach total order, would tend force specific interpretationsnewly learned clauses, reducing ability reverse decisions made earlysearch. would mean would relatively little flexibility modifyingbias; would always simply flip bias variable recently valuedeven evidence accumulated variable valued correctly.begin formalizing notion lexicographic progress.Definition A.4 set learned clauses total order, denote||x number elements conclusion either x x. denote|>x| number > x.v number variables considered, define total order sizeXsizet (, ) = 2v2|>x| ||x(8)xProposition A.5 acceptable total order , 2v sizet (, ) > 0.530fiSatisfiability SystematicityProof. first inequality immediate. second, since ||x 1,sizet (, ) 2vX2|>x|xconsider summation isolation, have:X2|>x|xvX2i1 = 2v 1.i=1Thus sizet (, ) > 0.moving on, let us explain intuition underlying Definition A.4. basicidea expression (8) reflect size search space remainingconsidered,X2|>x| ||xxcounts number potential models eliminated learned clauses .fairly clear. unique learned clause ||x eliminates valuex. elimination corresponds removal subtree overall searchspace. size subtree given 2|>x| , since |>x| number variables properlyfollowing x ordering.Proposition A.6 Fix total order , let 0 two sets learned clauses.Assume x ||x < |0 |x ||y = |0 |y < x.0 total order agrees restricted set {y, z|y, z x},sizet (0 , 0 ) < sizet (, ).Proof. simply formalization lexicographic argument made earlier. showsizet (, ) sizet (0 , 0 ) > 0,sizet (, ) sizet (0 , 0 ) =X02|> y| |0 |yXy02|>y| ||y(9)show:1. < x,02|> y| |0 |y = 2|>y| ||y(10)2|> x| |0 |x 2|>x| ||x 2|>x|(11)2. = x,03. > x,X2|>y| ||y < 2|>x|531(12)fiGinsbergCollectively, suffice. terms (10) < x effect difference (9).amount contributed term (11) = x greater amount subtractedterms (12) > x. Thus total sum positive result follows.(10) consequence fact x, |>0 y| = |>y| |0 |y = ||y . (11),since |0 |x > ||x , get2|>x| ||x 2|>x| (|0 |x 1)0= 2|> x| |0 |x 2|>x|(12), sum essentially identical appearing end previousproof.Definition A.7 partial order 0 called refinement partial order xx 0 y. refinement total order called total refinement .Definition A.8 set learned clauses partial order , define size, denoted size(, ), maximum sizet (, 0 ) total refinements0 .following immediate consequence Proposition A.5:Corollary A.9 acceptable partial order , 2v size(, ) > 0.point state desiderata add bit precisely.need:1. Polynomial space: acceptable respect ( 0 , 0 , 0 ) = add(, , ),want 0 acceptable respect 0 . allow us use Proposition A.3 conclude stored polynomial space algorithmproceeds. bias B obviously stored polynomial space well.2. Systematicity: ( 0 , 0 , 0 ) = add(, , ), want size(0 , 0 ) < size(, ).allow us use Corollary A.9 conclude add invoked2v times entire search space eliminated.A.3 SystematicityRecall:Procedure 3.6 compute add(, , ):12345678= return (, {}, );select l ;// l intended conclusion= lreturn add(resolve(, ), , )add x l x ;l ;remove c either c {l, l} =6 c {x|l < x} =6|c | > 1;return (, {}, )532fiSatisfiability SystematicityProposition A.10 Suppose acceptable respect , 6|= .( 0 , 0 , 0 ) = add(, , ), 0 acceptable respect 0 .Proof. Note first procedure terminates. possible source nontermination recursive call line 4, conclusion resolvent necessarily <conclusion . number recursive calls therefore bounded, procedureterminates.show 0 acceptable, consider first nonrecursive caseconclusion l. three conditions Definition A.1, have:1. show 0 parses c c 0 , two cases.c learned clause , know construction 0 includes x everyappearing c.case c , need following lemma:Lemma A.11 Suppose x u x 60 u. l <0 x l < x.Proof. Suppose denote + partial order constructed line 5procedure, additional arcs added original . Since + refinement, clear x u, x + u well.+0+0 =+l , way x u x 6 u l < x,0l < x well.show l < x, note l <0 x, l <+ x arcs removedconstruction <0 <+ . l <+ x must also l < x, since arcsadded construction <+ form z < l.0Returning proof proposition, suppose y, z c zincomparable 0 . either l <0 l <0 z, clause question wouldeliminated line 7 add construction, follows l 6<0l 6<0 z.claim u c < u. u, would00 u virtue lemma, 6 c . Similarly u c z < u.Thus y, z c therefore = z, since parses c.2. show two elements 0 conclusion, note first twoelements 0 conclusion original partial order .true construction two elements . new learned clauseconclusion element , would |= .way conclusion c 0 0 different conclusiony, z c < z z <0 y. lemmamust l < l <0 y. Since l < < z, l < z therefore l <0 z.weakening line 6 causes z incomparable <0 .533fiGinsberg3. Finally, must show 00 6|= 0 , 00 0 consistent.see this, use fact 6|= find complete assignment Pvalues variables satisfies , . Note P must satisfyantecedent include l order falsify .claim P |l satisfies 00 0 . P |l continues satisfy antecedent, since l 6 , P |l satisfies since contains l. therefore need considerc 0 appear well.Since P satisfies c c , way P |l might satisfy c c0P |l fails satisfy c conclusion c longer satisfied, P |l failssatisfy c0 one terms antecedent longer satisfied.first cannot happen P |l differs P l, l cannot csconclusion. second cannot happen l appears antecedent c,c would removed construction 0 .concludes proof remains acceptable nonrecursive path takenadd; see recursive path remains acceptable well, need showfundamental requirement 6|= holds recursive call.words, proof complete show 6|= resolve(, ) line 4.Suppose |= resolve(, ), noteresolve(, ) =, must therefore|=would imply |= , contradicting assumptions proposition.proof complete.Proposition A.12 Suppose acceptable respect , 6|= .( 0 , 0 , 0 ) = add(, , ), size(0 , 0 ) < size(, ).Proof. need following lemma:Lemma A.13 Let partial order x point. Tx total refinementx , total refinement Tx agree restricted{y, z|y, z Tx x}.Proof. Define 0 z following three conditions hold:1. y, z Tx x Tx z,2. x <Tx y, z z,3. Tx x <Tx z.534fiSatisfiability Systematicityclaim 0 partial order satisfying requirements lemma. (Informally,0 partial order matches x Tx x.)0 reflexive clear. transitivity, suppose u 0 v 0 w. x <Tx u,second clause definition one support u 0 v, mustx <Tx v similarly x <Tx w together u v w, u 0 w. w Tx x,analogous argument applicability first clause requires v Tx x similarlyu Tx x; transitivity Tx gives u Tx w u 0 w also. Finally, u Tx x <Tx w,get u 0 w directly.see 0 anti-symmetric, suppose u 0 v 0 u u 6= v. cannotu Tx x Tx v v Tx x Tx u Tx partial order, either firstsecond clause definition 0 must apply. Either way, must u = vTx partial orders.see Tx 0 agree restricted points z y, z Tx x, notefirst clause definition ever asserts 0 x y, clausesays Tx 0 match.remains show 0 refinement , z, 0 z.suppose z. x y, x x therefore x Tx y. Similarly,x Tx z. Thus case 2 definition applies, 0 z.If, hand, x 6 y, x z definition weakening x . ThusTx z well. two cases, depending Tx relationship xy:1. x Tx y, x Tx z well case 2 definition implies 0 z.2. Tx x (recall Tx total), two subcases:(a) x Tx z, case 3 definition applies 0 z.(b) z Tx x, case 1 applies.cases, conclude 0 z z.shows 0 partial order satisfying conditions lemma. Takingtotal refinement 0 completes proof.return proof Proposition A.12. earlier, denote +partial order obtained line 5 add procedure, added new constraintsbased selection l conclusion . showsize(0 , 0 ) < size(, + ) size(, )(13)second inequality easy; since + refinement , fewerrefinements consider Definition A.4 size. first inequality, 1 totalorder used evaluate size(0 , 0 ), must show total order 2 usedevaluate size(, + ) sizet (0 , 1 ) < sizet (, 2 ).Recall lines 5 6 Procedure 3.6 constructed 0 +l . follows 1total refinement +.thereforeknowlemma2ltotal refinement + 1 2 agree {x, y|x, 1 l}. Since 0 ,|0 |l > ||l thus apply Proposition A.6 concludesizet (0 , 1 ) < sizet (, 2 )535fiGinsbergfollows maximum 1 less maximum 2 s,size(0 , 0 ) < size(, + )needed (13). proof complete.Procedure 3.8 Let theory, set clauses |= , partial ordervariables , B bias . compute flex(T, , , B, n), one of:shown unsatisfiable, model P one found, unknown solutionfound n steps:1 0;2 < n3(P, c) unit(T , P );4c = true5P assigns value every variable return P ;6v variable unvalued P ;7(P, c) unit(T , hP, (B(v), )i);8(P, c)-conflict uip B |= ;9(, , ) add(, , );10B B| ;11return ;12P backtrack(P, );13ii+114 return unknownProposition A.14 every iteration loop Procedure 3.8, following conditionshold:1. B |= C(P ).2. 6|= C(P ).3. |= .4. acceptable .Proof. see B |= C(P ), note obviously true start, C(P ) =. three places could fail: line 7 new variable assignmentmade unit propagated, line 3 P extended unit propagation, line 10,B modified incorporate conclusion .Line 7 consistent B construction. Line 3 change C(P ), since newchoices made. line 10, always unit backtrack line 12, addingconclusion B conflict choice survives backtrack.B |= throughout bit subtle; begin showing B |=specifically. Clearly B |= , since bias modified satisfy conclusion .see B |= , note prior adjustment line 10, B |= constructionB |= . Negating conclusion change this.536fiSatisfiability SystematicityNext, must show , B |= line 10 complete.order B stop entailing particular learned clause , conclusion must, since modified line 10. case, resolutionperformed add different returned. Thus B |= .order B stop entailing particular antecedent , must includedantecedent. case, learned clause question removedadd procedure. Thus B |= well. concludes proof first claimProposition A.14.second claim follows this; |= C(P ), B would entail C(P )C(P ) would inconsistent result.see |= , note first |= line 8 construction buip.add procedure 3.6 adds either result resolving existing elements; either way, clause added necessarily entailed . fact variouslearned clauses may removed clearly affect conclusion |= .Finally, 6|= virtue facts B |= B |= . ThusProposition A.10 used conclude remains acceptable .Theorem 3.10 Suppose theory n clauses involving v variables. Then:1. loop Procedure 3.8 executed time O(v 3 + nv 2 ),2. || v Procedure 3.9 executed,P3. n ni=0 r(i) 2v , Procedure 3.9 finish completing iterationn.Proof. Since acceptable respect , second claim follows Proposition A.3. first claim follows Proposition 3.7. third claim followsProposition A.5, bounds size(, ) 0 2v , Proposition A.12,ensures size decreases pass loop Procedure 3.8.ReferencesBayardo, R. J., & Schrag, R. C. (1997). Using CSP look-back techniques solve real-worldSAT instances. Proceedings Fourteenth National Conference ArtificialIntelligence, pp. 203208.Beame, P., Kautz, H., & Sabharwal, A. (2004). Towards understanding harnessingpotential clause learning. Journal Artificial Intelligence Research, 22, 319351.Bebel, J., & Yuen, H. (2013). Hard SAT instances based factoring. ProceedingsSAT Competition 2013: Solver Benchmark Description, p. 102, Helsinki, Finland.Beck, J. C. (2005). Multi-point constructive search. Proc. Eleventh Intl. Conf.Principles Practice Constraint Programming (CP05), pp. 737741.Ben-Sasson, E., Impagliazzo, R., & Wigderson, A. (2000). Near-optimal separation treelike general resolution. Tech. rep., Electronic Colloquium Computation Complexity.537fiGinsbergBiere, A., Heule, M. J. H., van Maaren, H., & Walsh, T. (Eds.). (2009). HandbookSatisfiability, Vol. 185 Frontiers Artificial Intelligence Applications. IOSPress.Bonet, M. L., & Johannsen, J. (2014). Improved separations regular resolution clauselearning proof systems. Journal Artificial Intelligence Research, 49, 669703.Bonet, M. L., Pitassi, T., & Raz, R. (1997). Lower bounds cutting planes proofssmall coefficients. Journal Symbolic Logic, 62 (3), 708728.Browne, C., Powley, E., Whitehouse, D., Lucas, S., Cowling, P. I., Rohlfshagen, P., Tavener,S., Perez, D., Samothrakis, S., & Colton, S. (2012). survey Monte Carlo treesearch methods. IEEE Transactions Computational Intelligence AI Games,4 (1), 149.Buhler, J., Lenstra, H., & Pomerance, C. (1993). Factoring integers number fieldsieve, Vol. 1554 Lecture Notes Mathematics, pp. 5094. Springer-Verlag.Buss, S. R., Hoffmann, J., & Johannsen, J. (2008). Resolution trees lemmas: Resolutionrefinements characterize DLL algorithms clause learning. Logical MethodsComputer Science, 4.Clark, K. L. (1978). Negation failure. Gallaire, H., & Minker, J. (Eds.), LogicData Bases, pp. 293322. Plenum, New York.Davis, M., & Putnam, H. (1960). computing procedure quantification theory. J.Assoc. Comput. Mach., 7, 201215.Davis, M., Logemann, G., & Loveland, D. (1962). machine program theorem-proving.Communications ACM, 5 (7), 394397.Doyle, J. (1979). truth maintenance system. Artificial Intelligence, 12, 231272.Gaschnig, J. (1979). Performance Measurement Analysis Certain Search Algorithms.Ph.D. thesis, Carnegie-Mellon University.Ginsberg, M. L. (1993). Dynamic backtracking. Journal Artificial Intelligence Research,1, 2546.Gomes, C. P., Selman, B., & Kautz, H. (1998). Boosting combinatorial searchrandomization. Proceedings Fifteenth National Conference Artificial Intelligence (AAAI98), pp. 431437, Madison, Wisconsin.Goultiaeva, A., & Bacchus, F. (2012). trail: Re-examining CDCL algorithm.Proceedings 15th International Conference Theory ApplicationsSatisfiability Testing (SAT-2012), pp. 3043.Haken, A. (1985). intractability resolution. Theoretical Computer Science, 39, 297308.Haken, A. (1995). Counting bottlenecks show monotone P 6= N P . Proceedings 36thAnnual IEEE Symp. Foundations Computer Science (FOCS-95), pp. 3640,Milwaukee, MN. IEEE.Harvey, W. D. (1995). Nonsystematic Backtracking Search. Ph.D. thesis, Stanford University, Stanford, CA.538fiSatisfiability SystematicityHertel, P., Bacchus, F., & Pitassi, T. (2008). Clause learning effectively P-simulate general propositional resolution. Proceedings Twenty-Third National ConferenceArtificial Intelligence, pp. 283290.Huang, J. (2006). TINISAT SAT-race 2006..Huang, J. (2007). effect restarts efficiency clause learning. Proceedings20th International Joint Conference Artifical Intelligence, IJCAI07, pp.23182323, San Francisco, CA, USA. Morgan Kaufmann Publishers Inc.Kaivola, R., Ghughal, R., Narasimhan, N., Telfer, A., Whittemore, J., Pandav, S., Slobodov,A., Taylor, C., Frolov, V., Reeber, E., & Naik, A. (2009). Replacing testing formalverification Intelr Core i7 processor execution engine validation. Bouajjani,A., & Maler, O. (Eds.), Computer Aided Verification, Vol. 5643 Lecture NotesComputer Science, pp. 414429. Springer Berlin Heidelberg.Kocsis, L., & Szepesvari, C. (2006). Bandit based Monte-Carlo planning. In: ECML-06.Number 4212 LNCS, pp. 282293. Springer.Krajicek, J. (1997). Interpolation theorems, lower bounds proof systems, independence results bounded arithmetic. J. Symb. Logic, 62 (2), 457486.Lecoutre, C., Sas, L., Tabary, S., & Vidal, V. (2007). Recording minimizing nogoodsrestarts. J. Satisfiability, Boolean Modeling Computation (JSAT), 1,147167.Luby, M., Sinclair, A., & Zuckerman, D. (1993). Optimal speedup Las Vegas algorithms.Information Processing Letters, 47, 173180.Lynce, I., Baptista, L., & Marques-Silva, J. (2001). Stochastic systematic search algorithmssatisfiability. LICS Workshop Theory Applications Satis Testing,pp. 17.Marques-Silva, J. P., & Sakallah, K. A. (1999). GRASP search algorithm propositional satisfiability. Computers, 48 (5), 506521.Marques-Silva, J., Lynce, I., & Malik, S. (2009). Conflict-Driven Clause Learning SATSolvers, Vol. 185 Frontiers Artificial Intelligence Applications, pp. 131153.IOS Press.McAllester, D. A. (1993). Partial order backtracking. Unpublished.Moskewicz, M., Madigan, C., Zhao, Y., Zhang, L., & Malik, S. (2001). Chaff: Engineeringefficient SAT solver. 39th Design Automation Conference.Moura, L., & Bjrner, N. (2010). Bugs, moles skeletons: Symbolic reasoning softwaredevelopment. Giesl, J., & Hahnle, R. (Eds.), Automated Reasoning, Vol. 6173Lecture Notes Computer Science, pp. 400411. Springer Berlin Heidelberg.Pipatsrisawat, K., & Darwiche, A. (2007). lightweight component caching schemesatisfiability solvers. Proceedings 10th International Conference TheoryApplications Satisfiability Testing (SAT), pp. 294299.Pipatsrisawat, K., & Darwiche, A. (2011). power clause-learning SAT solversresolution engines. Artif. Intell., 175 (2), 512525.539fiGinsbergPudlak, P. (1997). Lower bounds resolution cutting planes proofs monotonecomputations. J. Symbolic Logic, 62 (3), 981998.Purdom, P., & Sabry, A. (2005). CNF generator factoring problems.. cgi.cs.indiana.edu/~sabry/cnf.html.Ramos, A., Tak, P., & Heule, M. (2011). restarts backjumps. Sakallah,K., & Simon, L. (Eds.), Theory Applications Satisfiability Testing - SAT 2011,Vol. 6695 Lecture Notes Computer Science, pp. 216229. Springer.Reiter, R. (1978). closed world data bases. Gallaire, H., & Minker, J. (Eds.), LogicData Bases, pp. 119140. Plenum, New York.Ryan, L. (2002). Efficient algorithms clause-learning SAT solvers. Masters thesis, SimonFraser University.Sellmann, M., & Ansotegui, C. (2006). Disco Novo GoGo: Integrating local searchcomplete search restarts. Proceedings Twenty-First National ConferenceArtificial Intelligence, pp. 10511056.Selman, B., Kautz, H. A., & Cohen, B. (1993). Local search strategies satisfiability testing. Proceedings 1993 DIMACS Workshop Maximum Clique, Graph Coloring,Satisfiability.Sorensson, N., & Een, N. (2005). Minisat v1.13 - SAT solver conflict-clause minimization. 2005. SAT-2005 poster. Tech. rep..Stallman, R. M., & Sussman, G. J. (1977). Forward reasoning dependency-directedbacktracking system computer-aided circuit analysis. Artificial Intelligence,9, 135196.Tseitin, G. (1970). complexity derivation propositional calculus. Slisenko,A. (Ed.), Studies Constructive Mathematics Mathematical Logic, Part 2, pp.466483. Consultants Bureau.Zhang, L. (2003). Searching Truth: Techniques Satisfiability Boolean Formulas.Ph.D. thesis, Princeton University, Princeton, NJ.Zhang, L., Madigan, C. F., & Moskewicz, M. H. (2001). Efficient conflict driven learningboolean satisfiability solver. ICCAD, pp. 279285.540fiJournal Artificial Intelligence Research 53 (2015) 699-720Submitted 03/15; published 08/15Tree-Width Computational ComplexityMAP Approximations Bayesian NetworksJohan Kwisthoutj.kwisthout@donders.ru.nlRadboud University NijmegenDonders Institute Brain, Cognition BehaviourMontessorilaan 3, 6525 HR Nijmegen, NetherlandsAbstractproblem finding probable explanation designated set variables given partial evidence (the MAP problem) notoriously intractable problemBayesian networks, compute exactly approximate. known,theoretical considerations practical experience, low tree-width typicallyessential prerequisite efficient exact computations Bayesian networks.paper investigate whether holds approximating MAP. define fournotions approximating MAP (by value, structure, rank, expectation) argueintractable general. prove efficient value-approximations,structure-approximations, rank-approximations MAP instances high tree-widthviolate Exponential Time Hypothesis. contrast, show MAP sometimes efficiently expectation-approximated, even instances high tree-width,probable explanation high probability. introduce complexity classFERT, analogous class FPT, capture notion fixed-parameter expectationapproximability. suggest road-map future research yields fixed-parametertractable results expectation-approximate MAP, even graphs high tree-width.1. IntroductionOne important computational problems Bayesian networks MAP problem, i.e., problem finding joint value assignment designated set variables(the MAP variables) maximum posterior probability, given partial observationremaining variables. MAP problem notably intractable; NPPP -hard,strictly harder (given usual assumptions computational complexity theory)PP-hard inference problem (Park & Darwiche, 2004). sense, seen combiningoptimization problem inference problem, potentially contributeproblems complexity (Park & Darwiche, 2004, p. 113). Even variablesnetwork binary network (very restricted) polytree topology, MAPremains NP-hard (De Campos, 2011). optimization inferencepart problem computed tractably (for example, tree-widthnetwork small, cardinality variables low, probable joint valueassignment high probability) MAP computed tractably (Kwisthout, 2011).known that, arbitrary probability distributions assumptionExponential Time Hypothesis, low tree-width moralized graph Bayesian networknecessary condition Inference problem Bayesian networks tractable2015 AI Access Foundation. rights reserved.fiKwisthout(Kwisthout, Bodlaender, & van der Gaag, 2010); result easily extended MAP,show Section 4.MAP also intractable approximate (Abdelbar & Hedetniemi, 1998; Kwisthout,2011, 2013; Park & Darwiche, 2004). obviously case particular instanceMAP problem approximated efficiently computed exactlyefficiently, yet unclear whether approximate MAP computations renderedtractable different conditions exact MAP computations. Crucialquestion mean statement algorithm approximates MAP problem.Typically, computer science, approximation algorithms guarantee outputalgorithm value within bound value optimal solution.example, canonical approximation algorithm Vertex Cover problem selectsedge random, puts endpoints vertex cover, removes nodesinstance. algorithm guaranteed get solution twicenumber nodes vertex cover optimal vertex set. However, typical Bayesianapproximation algorithms guarantee; contrast, may convergeoptimal value given enough time (such Metropolis-Hastings algorithm), mayfind optimal solution high probability success (such repeated local searchstrategies).paper assess four different notions approximation relevant MAPproblem; particular value-approximation, structure-approximation, rank-approximation,expectation-approximation MAP. introducing notation providingpreliminaries (Section 2), show approximations intractableassumption P 6= NP, respectively NP 6 BPP (Section 3). Building resultKwisthout et al. (2010) show Section 4 bounded tree-width indeednecessary condition efficient value-approximation, structure-approximation, rankapproximation MAP. Section 5 argue need case expectationapproximation. introduce parameterized complexity classes FERT (Fixed ErrorRandomized Tractable) FPERT (Fixed Parameter Error Randomized Tractable)natural extensions class FPT. introduce MAP variant additionalconstraints show Constrained-MAP intractable (PP-hard) general;however, Constrained-MAP FERT parameterized probabilityprobable explanation, even tree-width high. conclude paper Section6.2. Preliminariessection, introduce notational conventions provide preliminariesBayesian networks, graph theory, complexity theory; particular definitionsMAP problem, tree-width, parameterized complexity theory, Exponential TimeHypothesis. thorough discussion concepts, reader referredtextbooks Darwiche (2009), Arora Barak (2009), DowneyFellows (1999).700fiTree-Width MAP Approximations2.1 Bayesian NetworksBayesian network B = (GB , Pr) graphical structure succinctly represents jointprobability distribution set stochastic variables. B includes directed acyclic graphGB = (V, A), V models (in one-to-one mapping) stochastic variablesmodels conditional (in)dependences them, set parameter probabilitiesPr form conditional probability tables (CPTs), capturing strengthsrelationshipsQ variables. network models joint probability distributionPr(V) = ni=1 Pr(Vi | (Vi )) variables; here, (Vi ) denotes parents Vi GB .notational convention use upper case letters denote individual nodesnetwork, upper case bold letters denote sets nodes, lower case letters denote valueassignments nodes, lower case bold letters denote joint value assignments setsnodes. use node variable interchangeably.One key computational problems Bayesian networks problem findprobable explanation set observations, i.e., joint value assignment designated set variables (the explanation set) maximum posterior probability givenobserved variables (the joint value assignment evidence set) network.network bi-partitioned explanation variables evidence variables problemknown Probable Explanation (MPE). general problem,network also includes variables neither observed explained (referredintermediate variables) known (Partial Marginal) MAP. problemtypically defined formally follows:MAPInstance: Bayesian network B = (GB , Pr), V partitioned setevidence nodes E joint value assignment e, set intermediate nodes I,explanation set H.Output: joint value assignment h H joint value assignments h0H, Pr(h | e) Pr(h0 | e).remainder, use following definitions. arbitrary MAP instance{B, H, E, I, e}, let cansol B refer set candidate solutions {B, H, E, I, e},optsol B cansol B denoting optimal solution (or, case draw, one optimalsolutions) MAP instance. cansol B ordered according probabilitycandidate solutions (breaking ties candidate solutions probabilityarbitrarily), optsol 1...mrefers set first elements cansol B , viz.Bprobable solutions MAP instance. particular notion approximation,refer (unspecified) approximate solution approxsol B cansol B .2.2 Tree-Widthimportant structural property Bayesian network B tree-width,defined minimum width tree-decomposition (or equivalently, minimal sizelargest clique triangulation) moralization GMB network. Treewidth plays important role complexity analysis Bayesian networks, manyotherwise intractable computational problems rendered tractable, providedtree-width network small. moralization (or moralized graph) GMB701fiKwisthoutundirected graph obtained GB adding arcs connect pairsparents variable, dropping directions. triangulation GMBchordal graph GT embeds GB subgraph. chordal graph graphinclude loops three variables without pair adjacent.tree-decomposition (Robertson & Seymour, 1986) triangulation GT treeTG node Xi TG bag nodes constitute clique GT ;every i, j, k, Xj lies path Xi Xk TG , Xi Xk Xj .context Bayesian networks, tree-decomposition often referred junctiontree clique tree B. width tree-decomposition TG graph GT definedsize largest bag TG minus 1, i.e., maxi (|Xi | 1). tree-width twBayesian network B minimum width possible tree-decompositionstriangulations GMB .2.3 Complexity Theoryassume reader familiar basic notions complexity theory,intractability proofs, computational complexity classes P NP, polynomialtime reductions. section shortly review additional concepts usethroughout paper, namely complexity classes PP BPP, Exponential TimeHypothesis basic principles parameterized complexity theory.complexity classes PP BPP defined classes decision problemsdecidable probabilistic Turing machine (i.e., Turing machine makes stochasticstate transitions) polynomial time particular (two-sided) probability error.difference two classes bound error probability. Yes-instancesproblems PP accepted probability 1/2 + , may depend exponentiallyinput size (i.e., = 1/cn constant c > 1). Yes-instances problems BPPaccepted probability polynomially bounded away 1/2 (i.e., = 1/nc ).PP-complete problems, problem determining whether majority truthassignments Boolean formula satisfies , considered intractable; indeed,shown NP PP. contrast, problems BPP considered tractable.Informally, decision problem BPP exists efficient randomized (MonteCarlo) algorithm decides high probability correctness. Given errorpolynomially bounded away 1/2, probability answering correctly boostedarbitrarily close 1 still requiring polynomial time. obviouslyBPP PP, reverse unlikely; particular, conjectured BPP = P (Clementi,Rolim, & Trevisan, 1998).Exponential Time Hypothesis (ETH), introduced Impagliazzo Paturi (2001),states exists constant c > 1 deciding 3Sat instance nvariables takes least (cn ) time. Note ETH stronger assumptionassumption P 6= NP. sub-exponentialpolynomial-time algorithm33Sat, algorithm running O(2 n ), would contradict ETH wouldimply P = NP. assume ETH proofs show necessity lowtree-width efficient approximation MAP.Sometimes problems intractable (i.e., NP-hard) general, become tractableparameters problem assumed small. problem called702fiTree-Width MAP Approximationsfixed-parameter tractable parameter (or set {1 , . . . , } parameters)solved time, exponential (or even worse) polynomial input size|x|, i.e., time O(f () |x|c ) constant c > 1 arbitrary computable functionf . practice, means problem instances solved efficiently, evenproblem NP-hard general, known small. contrast, problemNP-hard even small, problem denoted para-NP-hard .parameterized complexity class FPT consists fixed parameter tractable problems .traditionally defined mapping problem instances natural numbers(e.g., Flum & Grohe, 2006, p. 4), one easily enhance theory rational parameters(Kwisthout, 2011). context paper, particular consider rationalparameters range [0, 1], liberally mix integer rational parameters.3. Approximating MAPwidely known, practical experiences theoretical results, smalltree-width often necessary constraint render exact Bayesian inferences tractable.However, often assumed intractable computations efficiently approximated using inexact algorithms; assumption appears warranted observationmany cases approximation algorithms seem reasonable job in, e.g., estimating posterior distributions, even networks high tree-width exact computationsinfeasible (Cheng & Druzdzel, 2000; Sontag, Meltzer, Globerson, Weiss, & Jaakkola,2008). Whether observation firm theoretical basis, i.e., whether approximationalgorithms cannot principle perform well even situations tree-widthgrow large, date known.Crucial answering question make precise efficiently approximated actually pertains to. on-line Merriam-Webster dictionary lists one entriesapproximate similar exactly like (something). computer science,similarity typically defined terms value: approximate solution valueclose value optimal solution. However, notions approximationrelevant. One think approximating value optimal solution,appearance: approximate solution A0 closely resembles optimal solution. Also, onedefine approximate solution one ranks close optimal solution: approximate solution A00 ranks within top-m solutions. Note notions refercompletely different solutions. One situations second-best solutionresemble optimal solution all, whereas solutions look almostlow value compared optimal solution (Van Rooij & Wareham, 2012;Kwisthout, 2013). Similarly, second-best solution may either value almostgood optimal solution, much worse.many practical applications, particular Bayesian inferences, definitionsapproximation (fully) capture actual notion interested in. example, trying approximate MAP explanation using sort randomizedcomputation, guarantee quality solution found, however, maybound likeliness good solution. current state-of-the-art approximatealgorithms MAP (AnnealedMAP, Yuan, Lu, & Druzdzel, 2004; P-Loc, Park & Darwiche, 2001; BP-LS, Park & Darwiche, 2004) employ strategy. added notion703fiKwisthoutapproximation here, induced use randomized computations, allowancebounded amount error.1remainder section elaborate notions approximationapplied MAP problem. give formal definitions approximateproblems show intractable general. MAP-approximationvalue structure interpret known results literature. MAPapproximation rank give formal proof intractability; MAP-approximationusing randomized algorithms give argument complexity theory.3.1 Value-ApproximationValue-approximating MAP problem finding explanation approxsol B cansol Bvalue, close value optimal solution. closeness definedadditive relative manner; additive meaning absolute differenceprobability optimal approximate solution smaller value ;relative ratio probability optimal approximate solutionsmaller value . problems intractable general. AbdelbarHedetniemi (1998) proved NP-hardness relative value-approximation constant1. result holds networks binary variables, three incomingarcs per variable, evidence. addition, Kwisthout (2011) showed NP-hardgeneral find explanation approxsol B Pr(approxsol B , e) > constant> 0, thus Pr(optsol B , e) Pr(approxsol B , e) > Pr(optsol B , e) .latter result holds even networks binary variables, two incomingarcs per variable, single evidence variable, intermediate variables (i.e.,approximate MPE problem).Definition 3.1 (additive value-approximation MAP) Let optsol B optimalsolution MAP problem. explanation approxsol B cansol B defined -additivevalue-approximate optsol B Pr(optsol B , e) Pr(approxsol B , e) .Result 3.2 (Kwisthout, 2011) NP-hard -additive value-approximate MAP> Pr(optsol B , e) constant > 0.Definition 3.3 (relative value-approximation MAP) Let optsol B optimalsolution MAP problem. explanation approxsol B cansol B defined -relativePr(optsol B | e)value-approximate optsol B Pr(approxsol| e) .BResult 3.4 (Abdelbar & Hedetniemi, 1998) NP-hard -relative value-approximatePr(optsol B | e)MAP Pr(approxsol| e) > 1.B1. Observe algorithms always converge optimal solution, may take exponential time(e.g., MCMC-type approaches). However, turn algorithm expectationapproximation algorithm adding clock halts computations time, polynomially inputsize, returning current best solution may may optimal (Gill, 1977).704fiTree-Width MAP Approximations3.2 Structure-ApproximationStructure-approximating MAP problem finding explanation approxsol Bcansol B structurally resembles optimal solution. captured using solutiondistance function, metric associated optimization problem relating candidatesolutions optimal solution (Hamilton, Muller, van Rooij, & Wareham, 2007).MAP, typical structure distance function dH (approxsol B , optsol B ) Hamming distance explanation approxsol B probable explanation optsol B .shown Kwisthout (2013) algorithm calculate value even singlevariable probable explanation polynomial time, unless P = NP; is,NP-hard find explanation dH (approxsol B , optsol B ) |optsol B | 1, evenvariables network bi-partitioned explanation evidence variables,variable three possible values.Definition 3.5 (structure-approximation MAP) Let optsol B optimal solution MAP problem let dH Hamming distance. explanation approxsol Bcansol B defined d-structure-approximate optsol B dH (approxsol B , optsol B ) d.Result 3.6 (Kwisthout, 2013) NP-hard d-structure-approximate MAP|optsol B | 1.3.3 Rank-ApproximationApart allowing explanation resembles, probability close to,probable explanation, also define approximate solution approxsol B explanation one best explanations, constant m, is, approxsol Boptsol 1...mm. Note explanation may resemble probableBexplanation needs relatively high probability, ranked withinprobable explanations. denote approximation rank-approximation.Definition 3.7 (rank-approximation MAP) Let optsol 1...mcansol B setBprobable solutions MAP problem let optsol B optimal solution.explanation approxsol B cansol B defined m-rank-approximate optsol B approxsol Boptsol 1...m.Bprove NP-hard m-rank-approximate MAP constant m.reduction variant LexSat, based reduction Kwisthout, Bodlaender,van der Gaag (2011). LexSat defined follows:LexSATInstance: Boolean formula n variables X1 , . . . , Xn .Output: lexicographically largest truth assignment x X = {X1 , . . . , Xn }satisfies ; output satisfiable.Here, lexicographical order truth assignments maps truth assignment x = x1 , . . . , xnstring {0, 1}n , {0}n (all variables set false) lexicographically smallest,{1}n (all variables set true) lexicographically largest truth assignment. LexSatNP-hard; particular, LexSat proven complete class FPNP (Krentel,705fiKwisthoutVX0X1X2X3X4XFigure 1: Example construction Bex LexSat0 instance ex1988). proofs use following variant always returns truth assignment(rather , case unsatisfiable):LexSAT0Instance: Boolean formula n variables X1 , . . . , Xn .Output: lexicographically largest satisfying truth assignment x = (X0 )satisfies .Note satisfiable, X0 never set false lexicographically largestsatisfying truth assignment , yet X0 necessarily set false satisfiable;hence, unsatisfying truth assignments always ordered satisfying truth assignments lexicographical ordering. Note LexSat trivially reduces LexSat0 usingsimple transformation. claim following.Theorem 3.8 algorithm find approximation approxsol B optsol 1...m,Bconstant m, polynomial time, unless P = NP.proof describe polynomial-time one-Turing reduction2 LexSat0 mrank-approximated-MAP arbitrary constant m. reduction largely followsreduction presented Kwisthout et al. (2011) additions. takefollowing LexSat0 -instance running example proof: ex = X1 (X2 X3 );correspondingly, ex = (X0 ) (X1 (X2 X3 )) example. set = 3example construct. construct Bayesian network B follows (Figure 1).variable Xi , introduce binary root variable Xi B possiblevalues true false. set prior probability distribution variablesi+1 1Pr(Xi = true) = 1/2 22n+2. addition, include uniformly distributed variableXn+1 B values x1n+1 , . . . , xmn+1 . variables X0 , . . . , Xn together form setX. Note prior probability joint value assignment x X higher priorprobability different joint value assignment x0 X, corresponding2. function problem f polynomial-time one-Turing reducible function problem g existpolynomial-time computable functions T1 T2 every x,f (x) = Tl (x, g(T2 (x))) (Toda,1994). One-Turing reductions seen equivalent many-one reductions, appliedfunction problems.706fiTree-Width MAP Approximationstruth assignment x LexSat0 instance lexicographically larger truth assignmentx0 . running example, Pr(X0 = true) = 15/32, Pr(X1 = true) =13/32, Pr(X2 = true) = 9/32, Pr(X3 = true) = 1/32, Pr(X4 = x1 ) = Pr(X4 =4x24 ) = Pr(X4 = x34 ) = 1/3. Observe Pr(X0 ) . . . Pr(Xi1 ) Pr(Xi ) >Pr(X0 ) Pr(Xi1 ) Pr(Xi ) every i, i.e., ordering property statedattained.logical operator , introduce additional binary variable Bpossible values true false, parents sub-formulas (or single subformula, case negation operator) bound operator. conditionalprobability distribution variable matches truth table operator, i.e., Pr(T =true | (T )) = 1 operator evaluates true particular truthvalue sub-formulas bound . top-level operator denoted V . readilyseen Pr(V = true | x) = 1 truth assignment variablesmatches x satisfies , Pr(V = true | x) = 0 otherwise. Observem-valued variable Xn+1 independent every variable B . notenetwork, including prior conditional probabilities, described using numberbits polynomial size . MAP instance constructed , setV evidence set V = true observation set X {Xn+1 } explanationset.Proof. Let instance LexSat0 , let B network constructeddescribed above. joint value assignment x X Pr(X = x | V =true) = Pr(X = x) normalization constant > 0 x corresponds satisfyingtruth assignment , Pr(X = x | V = true) = 0 x corresponds non-satisfyingtruth assignment . Given prior probability distribution variables X,satisfying joint assignments x X ordered posterior probabilityPr(x | V = true) > 0, non-satisfying joint value assignments probabilityPr(x | V = true) = 0 thus ordered satisfying assignments. joint valueassignment highest posterior probability thus lexicographically largestsatisfying truth assignment .take m-th valued variable Xn+1 account, every x,joint value assignments X {Xn+1 } probability since Pr(x, Xn+1 | V =true) = Pr(x | V = true) Pr(Xn+1 ). then, joint value assignments xmX {Xn+1 } correspond lexicographically largest satisfying truth assignment xposterior probability Pr(xm | V = true). Thus, algorithmreturns one m-th ranked joint value assignments explanation set X {Xn+1 }evidence V = true transformed polynomial time algorithmsolves LexSat0 . conclude algorithm m-rank-approximate MAP,constant m, polynomial time, unless P = NP.Note that, technically speaking, result even stronger: LexSat0 FPNP complete reduction described actually one-Turing reduction LexSat0m-rank-approximation-MAP, latter problem FPNP -hard. strengthenresult observing variables (minus V ) mimic operators deterministically depend parents thus added explanation set withoutsubstantially changing proof above. implies m-rank-approximation-MPEalso FPNP -hard. Lastly, strengthen result replacing m-th valued variable707fiKwisthoutXn+1 dlog2 unconnected binary variables Xn+1 Xn+dlog2 uniform probability. Still, algorithm returning one m-th ranked joint value assignmentsX{Xn+1 , . . . , Xn+dlog2 } polynomial time effectively solve LexSat0 polynomialtime.Result 3.9 NP-hard m-rank-approximate MAP constant m.3.4 Expectation-Approximationlast notion MAP approximation discuss returns polynomial timeexplanation approxsol B cansol B likely probable explanation,allows small margin error; i.e., small probability answeroptimal solution, guarantees given quality solution.approximations closely related randomized algorithms run polynomialtime whose output small probability error, viz., Monte Carlo algorithms.notion approximationwhich refer expectation-approximation (Kwisthout &van Rooij, 2013)is particularly relevant typical Bayesian approximation methods,Monte Carlo sampling repeated local search algorithms.Definition 3.10 (expectation-approximation MAP) Let optsol B optimal solution MAP problem let E expectation function (Papoulis, 1984).explanation approxsol B cansol B defined -expectation-approximate optsol BE(Pr(optsol B ) 6= Pr(approxsol B )) < .order practical relevance, want error small, i.e., casteddecision problem, want probability answering correctly bounded away1/2. case, amplify probability answering correctly arbitrarilyclose 1 polynomial time, repeated evocation algorithm. Otherwise, e.g.,error depends exponentially size input, need exponential numberrepetitions achieve result. Problems enjoy polynomial-time Monte Carloalgorithms complexity class BPP; problems may need exponential timereduce probability error arbitrarily close 0 complexity class PP.MAP NP-hard, efficient randomized algorithm solving MAP polynomial timebounded probability error, would imply NP BPP. consideredhighly unlikely, almost every problem enjoys efficient randomized algorithmproven P, i.e., decidable deterministic polynomial time.3 variousgrounds believed BPP = P (Clementi et al., 1998), thus efficient randomized algorithm MAP would (under assumption) establish P = NP. Therefore,algorithm expectation-approximate MAP polynomial time bounded marginerror unless NP BPP. result holds also MPE, already NP-hard,even binary variables in-degree 2 (Kwisthout, 2011).43. dramatic example problem PRIMES: given natural number, decide whetherprime. efficient randomized algorithms PRIMES around quite time(establishing PRIMES BPP), fairly recently proven PRIMES P (Agrawal,Kayal, & Saxena, 2004).4. fact, holds value-approximation, structure-approximation, rank-approximation MAPwell, three problems NP-hard (see also Abdelbar & Hedetniemi, 1998, p. 35).708fiTree-Width MAP ApproximationsResult 3.11 cannot exist randomized algorithm -expectation-approximatesMAP polynomial time < 1/2 1/nc constant c unless NP BPP.3.5 Discussionprevious subsections showed approximation notions establishedfact intractable, various assumptions. results hold MAP general,many cases strengthened hold MPE (i.e., network two-partitionedevidence explanation variables); either case, cardinality c in-degreenodes (and consequently, size CPTs) bounded. results holdempty (or singleton) evidence sets. results summarized Table 1.Approximationvalue, additivevalue, ratiostructurerankexpectationconstraintsc = 2, = 2,|E| = 1, =c = 2, = 3,E=c = 3, = 3,I=c = 2, = 2,|E| = 1, =c = 2, = 2,|E| = 1, =assumptionP 6= NPreference(Kwisthout, 2011, p. 1462)P 6= NP(Abdelbar & Hedetniemi, 1998, p. 24)P 6= NP(Kwisthout, 2013, p. 345)P 6= NPSection 3.3NP 6 BPPSection 3.4Table 1: Summary intractability results MAP approximations4. Necessity Low Tree-Width Efficient Approximation MAPprevious section shown four notions approximating MAP,efficient general approximation algorithm constructed unless either P = NP NPBPP. However, MAP fixed-parameter tractable number problem parameters;example, {tw, c, q}MAP FPT parameters tree-width (tw), cardinalityvariables (c = maxi |(Vi V)|), probability probable solution (q =Pr(optsol B , e)). Surely, compute {1 , . . . , }MAP exactly FPT time,also approximate {1 , . . . , }MAP FPT time. question remains, however, whetherapproximate MAP fixed-parameter tractable different set parametersexact MAP.Tree-width shown necessary parameter efficient exact computation Inference problem (and, trivial adjustment illustrated Section 4.3,also MAP), assumption ETH holds (Kwisthout et al., 2010).section, show low tree-width also necessary parameter efficientapproximate computation value-approximations, structure-approximations, rankapproximations. also argue (in Section 5) necessary parameterefficient expectation-approximation. next sub-section review so-called treewidth-preserving reductions (tw-reductions), special kind polynomial many-one reductions preserve tree-width instances (Kwisthout et al., 2010). Sub-section709fiKwisthout4.2 sketch notion used tw-reduce Constraint SatisfactionInference. Together known result Constraint Satisfaction instanceshigh tree-width cannot sub-exponential algorithms, unless ETH fails (Marx,2007), established Kwisthout et al. cannot (general-purpose) algorithm decides Inference instances high tree-width sub-exponential time,unless ETH fails. Here, Inference problem problem deciding whetherBayesian network B designated sets H E rational number q, casePr(H = h | E = e) > q. precisely, following theorem proved:Theorem 4.1 exists computable function f Inference decidedalgorithm running timef (GMB )o(kBktw(GMB ) )log tw(GM )Barbitrary Inference instances (B, H, h, E, e, q) moralized graph GMB treeMwidth tw(GB ), ETH fails.reader referred Kwisthout et al. (2010) full proof.5 remaindersection, show proof augmented establish similar resultsMAP, value-approximate MAP, structure-approximate MAP, rank-approximate MAP(Sub-sections 4.3 4.4).4.1 Tree-Width-Preserving ReductionsTree-width-preserving reductions defined Kwisthout et al. (2010) means reduceConstraint Satisfaction Inference ensuring tree-width preservedinstances reduction, modulo linear factor.Definition 4.2 (Kwisthout et al., 2010) Let B computational problemstree-width defined instances B. say polynomialtime tree-width-preserving reducible, tw-reducible, B exists polynomial-timecomputable function g linear function l x g(x) Btw(g(x)) = l(tw(x)). pair (g, l) called tw-reduction.use notion show Constraint Satisfaction also tw-reduces MAP,value-approximate MAP, structure-approximate MAP, rank-approximate MAP.4.2 Proof Sketchtw-reduction (binary) Constraint Satisfaction Inference, presentedKwisthout et al. (2010), constructs Bayesian network BI instance = (V, D, C)Constraint Satisfaction, V denotes set variables I, denotes setvalues variables, C denotes set binary constraints defined V V.5. results Kwisthout et al. (2010) rule existence special-case algorithms,assume (and utilize) particular property instance, particular orientation arcsparticular planarity properties graph structure, failing assumption violated.results current paper, built result, inherit constraint.710fiTree-Width MAP ApproximationsR1R4X1X2X4X3R2R3Figure 2: Example construction BI example CSP instanceconstructed network BI includes uniformly distributed variables Xi , correspondingvariables V, binary variables Rj , corresponding constraints C.parents variables Rj variables Xi bound constraints;conditional probability distributions match imposed constraints variables(i.e., Pr(Rj = true | x ((Rj ))) = 1 joint value assignment xvariables bound Rj matches constraints imposed Rj . Figure 2,taken Kwisthout et al., shows result construction far exampleConstraint Satisfaction instance four variables X1 X4 , C contains fourconstraints bind respectively (X1 , X2 ), (X1 , X4 ), (X2 , X3 ), (X3 , X4 ).tree-width thus obtained network equals max(2, tw(GI )), GIprimal graph I; note tree-width BI increases tree-width GI1. order enforce constraints simultaneously enforced, constraint nodesRj need connected extra nodes mimicking operators. crucial aspecttw-reduction topography connection nodes Rj : care must takenblow tree-width arbitrarily connecting nodes, e.g., log-deep binarytree. original proof uses minimal tree-decomposition moralization BIdescribes procedure select nodes need connected tree-widthresulting graph tree-width GI plus 3. conditional probabilitydistribution nodes Ak defined follows.V1 x = V (Ak ) (V = true)Pr(Ak = true | x) =0 otherwisenode Ak without parents, Pr(Ak = true) = 1. graph resultsapplying procedure example given Figure 3 (also taken Kwisthoutet al., 2010). Now, Pr(A1 = true | x) = 1 x corresponds satisfying value assignmentV 0 otherwise; correspondingly, Pr(A1 = true) > 0 ConstraintSatisfaction instance satisfiable.4.3 MAP Resulttw-reduction described previous sub-section easily modified twreduction Constraint Satisfaction MAP. adding binary node711fiKwisthoutR1R4X1X2X4X3A1R2R3A2A3A4A5A6Figure 3: Resulting graph BI adding nodes Ak appropriate arcsVI thus obtained graph, A1 parent conditional probabilityPr(VI = true | A1 = true) = 1 Pr(VI = true | A1 = false) = 1/2 ,number, smaller 1/|D||V| . Consequently, Pr(VI = true) > 1/2satisfiable, Pr(VI = true) < 1/2 satisfiable; hence, MAP queryexplanation set H = {VI } return VI = true satisfiable. addedsingle node BI , A1 parent, thus increasing tree-width BI1. Hence, Constraint Satisfaction tw-reduces MAP.4.4 Approximation Intractability Resultssimilar way modify reduction Sub-section 4.2 show valueapproximations, structure-approximations, rank-approximations tw-reducedConstraint Satisfaction, sketched below.4.4.1 Value-Approximationadd binary node VI , A1 parent, conditional probabilityPr(VI = true | A1 = true) = 1 Pr(VI = true | A1 = false) = 0. observevariable set true. enforces Pr(A1 = true | VI = true)non-zero probability (i.e., solvable) since otherwise conflicting evidencethus constructed network. Thus, value-approximation algorithm explanationset H = {A1 } evidence e = {VI = true} return solution approxsol Bcansol B Pr(approxsol B , e) > constant > 0, (that is, approximates additivelyB)) effectively solves Constraint> Pr(optsol B ) relatively > Pr(optsolSatisfaction: exists solution non-zero probability, construction dictatesmust solvable. Given added single node BI , A1 parent,increases tree-width BI 1. Hence, Constraint Satisfaction twreduces value-approximate MAP.712fiTree-Width MAP Approximations4.4.2 Structure-ApproximationObserve tw-reduction MAP Sub-section 4.3 that, since H consistssingleton binary variable, trivially algorithm find explanationapproxsol B cansol B dH (approxsol B , optsol B ) |optsol B | 1 = 0 since wouldsolve MAP query. extend result hold explanation sets sizek constant k, i.e., structure-approximation algorithm guarantee returncorrect value one k variables H polynomial time instances hightree-width, unless ETH fails.Instead adding single binary node VI tw-reduction MAP, add kbinary nodes VI1 . . . VIk , A1 parent Pr(VIj = true | A1 =true) = 1 Pr(VIj = true | A1 = false) = 1/2 1 j kdescribed Sub-section 4.3. MAP query explanation set H = 1jk VIjreturn 1jk VIk = true satisfiable; satisfiable, MAPquery return 1jk VIk = false probable explanation. Hence, structureapproximation algorithm correctly return value one variables H,effectively solves Constraint Satisfaction. added k nodes BI , A1parent outgoing arcs, tree-width BI increases 1. Hence,Constraint Satisfaction tw-reduces structure-approximate MAP.4.4.3 Rank-Approximationmodify proof Sub-section 4.3 follows. addition adding binary nodeVI specified section, also add dlog2 unconnected binary variables MI =dlog{MI1 . . . MI 2 } uniform probability H; m-rank-approximate MAP queryexplanation set H = {VI } MI return VI = true (and MI set arbitrary value)satisfiable. addition MI increase tree-width, hence,Constraint Satisfaction tw-reduces m-rank-approximate MAP.4.5 Discussionefficient exact computation, value-approximation, structure-approximation, rankapproximation MAP showed bounded tree-width necessary condition, assumption ETH, general-purpose algorithm accepts arbitraryinstances. rule possibility may exist special-purpose algorithms compute approximate MAP explanations specific networksspecial structure distribution (as already concluded Kwisthout et al. (2010)Inference problem Bayesian networks). However, previous sub-sectionshows, approximation problems intractable even extreme lower boundsapproximation quality, nature reductions followseffectively approximate MAP explanations value, structure, rank, decideproblem exactly well. leaves little room efficient approximation algorithmsMAP instances high tree-width approximate value, structure, rank.713fiKwisthout5. Expectation-Approximation Classes FERT FPERTprevious section showed cannot value-approximate, structure-approximate,rank-approximate MAP instances high tree-width, unless ETH fails.expectation-approximation? appears strategy employedprevious subsection cannot used show similar result expectation-approximation. fact, reasons believe efficient expectation-approximation MAPindeed depends different set parameters notions approximationdiscussed above, bounded tree-width necessary particular notionapproximation. notion parameterized approximability well capturedtraditional fixed parameter tractable class FPT; therefore, introduce parameterized complexity classes FERT (Fixed Error Randomized Tractable) FPERT(Fixed Parameter Error Randomized Tractable) characterize notion efficient parameterized expectation-approximation. Intuitively, contrast class FPT,parameterizes running time, classes parameterize error probability (FERT),respectively running time error probability (FPERT).best knowledge, previous work proposes parameterize probability acceptance probabilistic Turing machine. Montoya Muller(2013) define class BPFPT assumes bounded error independentparameterization , amount randomness (operationalized numbercoins used) bounded. Arvind Raman (2002) propose randomized approximationalgorithms counting problems, running time approximation ratioparameterized, error probability constant. authors, however, assumebounded (rather parameterized) error.next section set formal machinery results. introduce natural parameterizations MajSAT, respectively E-MajSAT, FERT,respectively FPERT. show restricted variant MAP indeed FERT, parameterized probability probable explanation, FrugalExplanations problem (Kwisthout, 2015) FPERT number parameterizations.elaborate relation classes classes BPP, PP, FPT,finally, propose road map future research.5.1 Parameterizing Error Bound Randomized Algorithmsformally define complexity class FERT follows:Definition 5.1 Let decision problem let parameterization .FERT exists probabilistic Turing machinehalts time, polynomial size input x, following acceptance criteria.accepts Yes-instances probability 1/2 + min(f (), 1/|x|c ) constant carbitrary function f : R h0, 1/2]; No-instances accepted probability 1/2.Observe definition demand halts time, polynomial inputsize (and independent parameterization ), yet probability acceptanceYes-instances may depend function . Intuitively, class FERT characterizesproblems efficiently computed randomized algorithm (i.e., polynomialtime, error arbitrarily close 0) bounded. canonical parameterized problem714fiTree-Width MAP ApproximationsFERT {r}MajSAT, r denotes fraction satisfying truth assignments (or, equivalently, probability random truth assignment accepts).follows corollary following result Littman, Majercik, Pitassi (2001):Lemma 5.2 (adapted Littman et al., 2001) Let v number acceptingtruth assignments Boolean formula , let v estimate v found via randomsampling using w samples variables . Let > 0 target approximation2error. probability |v v| > less 2e2 w .Note solving MajSAT-instance, target approximation error directlydepends probability r random truth assignment accepts, acceptable error(i.e., error still gives correct answer MajSAT instance) randomsampling algorithm = |r 1/2|. So, probability acceptance random truthassignment polynomially bounded away 1/2, guarantee arbitrarily smallerror using polynomially many samples using straightforward randomized algorithm.Corollary 5.3 {r}MajSAT FERT.allow parameterization running time probability acceptance, get complexity class FPERT defined follows:Definition 5.4 Let decision problem let {1 , 2 } parameterization. {1 , 2 } FPERT exists probabilistic Turingmachine halts time O(f1 (1 ) |x|c1 ), accepts Yes-instancesprobability 1/2 + min(f2 (2 ), 1/|x|c2 ), accepts No-instances probability 1/2.Here, f1 : R R f2 : R h0, 1/2] arbitrary computable functions c1 c2constants.also define canonical problem FPERT, based observation {p}-SATFPT (Flum & Grohe, 2006, parameter p denotes number variablesformula) Corollary 5.3:E-MajSATInstance: Let Boolean formula n variables xi , = 1, . . . , n, n 1,furthermore partition variables sets XE XM .Question: truth assignment XE majority truthassignments XM satisfy ?Parameter: 1 = p; 2 = r; p number variables set XE ; define rfollows. Let rxE denote ratio accepting truth assignments XM givenparticular truth assignment xE XE . define r = minxE (|1/2 rxE |).Informally, r describes minimum absolute distance 1/2 fraction acceptingtruth assignments truth assignment xE XE . Observe try (bruteforce) truth assignments XE and, truth assignment, expectation-approximatewhether truth assignment majority truth assignments XM satisfy. algorithm runs time O(2p nc ) constant c, probability least1/2 + f (r) answering correctly (using polynomial number samples).Corollary 5.5 {p, r}E-MajSAT FPERT.715fiKwisthout5.2 Parameterized Expectation-Approximation MAPProving problem FPT normally done constructively, i.e., givingdeterministic algorithm decides time O(f () |x|c ) constant c > 1. Similarly,proving FERT done giving randomized algorithm6 decidespolynomial time error 1/2 min(f (), 1/|x|c ). succeed givingalgorithm MAP general, however, prove restricted variant MAPFERT parameterized probability probable explanation,despite restricted variant remains PP-complete general bounded treewidth necessary parameter approximate problem value, structure, rank:ConstrainedMAPInstance: MAP. addition, demand E = , H consists singletonnode H outgoing edges, (H) = {true, false}.Question: Pr(H = true) > 1/2?Parameter: q = Pr(H = true).PP-completeness Constrained-MAP follows trivial modification PPcompleteness proof Inference described Kwisthout (2009, Lemma 2.7 Lemma2.9). Furthermore, given reductions Constraint Satisfaction MAP,value-approximate MAP, structure-approximate MAP, rank-approximate MAP respectrestrictions imposed Constrained-MAP, necessity bounded treewidth follows.show {q}Constrained-MAP FERT, parameter q = Pr(H =true), give following approximation algorithm. Observe H binary sinknode (i.e., outgoing edges) B evidence. simple forward samplingstrategy (Henrion, 1986) approximate distribution H sampling valuesvariables network according probability distribution CPTs.thus estimate Pr(H) taking samples; decide upon approxsol B using estimation.Note degree error given particular number samples depends directlyprobability q. precise, using Chernoff bound compute numbersamples N needed degree error lower 1/(q 1/2)2 ln 1/ . givesus fixed-parameter randomized tractable algorithm parameter {q}.Corollary 5.6 {q}Constrained-MAP FERT.Another parameterized problem shown fixed-error, fixed parameterrandomized tractable Frugal Explanations heuristic approach MAP, introduced Kwisthout (2015). heuristic (that either marginalizes samples intermediate variables, based subjective partition intermediate variables (intoset I+ set ) according expected contribution deciding upon MAPexplanation) expectation-approximated tractably tree-width network low, cardinality variables small, set I+ small, probabilitydistribution samples suffice decide upon MFE explanationhigh probability. first three parameters ensure bounded running time, whereas6. refer algorithm fixed-error randomized tractable algorithm.716fiTree-Width MAP Approximationspara-NPPPFPERTpara-PPFERTpara-NPBPPFPTPFigure 4: Inclusion properties complexity classes P, BPP, FERT, FPERT, FPT,para-NP, para-PP, para-NPPPfinal parameter ensures bounded probability error. Hence, {tw, c, |I+ |} {b}MFEFPERT, tw denotes tree-width network, c denotes cardinalityvariables, |I+ | denotes number variables marginalize (not sample) over, bdenotes parameter describing bias towards particular explanation. additionshown {|H|, c, |I+ |} {b}MFE FPERT, |H| denotes sizeexplanation set.Corollary 5.7 {tw, c, |I+ |} {b}MFE FPERT {|H|, c, |I+ |} {b}MFE FPERT.5.3 Relation FERT, FPERT, Complexity Classescomplexity class FERT introduced randomized analog FPT. Ratherparameterizing running time (as arbitrary function polynomiallyinput size), parameterize probability acceptance Yes-instances. BPP, FERT,para-PP form natural analogs P, FPT, para-NP, respectively. class FPERTparameterizes running time probability acceptance, using two parametersets 1 2 . thus BPP FERT PP, FERT FPERT,FPT FPERT. Obviously, FPERT para-NPPP , every slice {1 , 2 }1 NPPP (seeFlum & Grohe, 2006, discussion slices parameterized problems). inclusionrelations depicted Figure 4.conjectured BPP = P (Clementi et al., 1998); however, clear whetherconjecture transposed parameterized world; is, whetherconjectured FERT = FPT. known {q, |I|}MAP {q, tw}MAP fixedparameter tractable (Kwisthout, 2011); Constrained-MAP special case MAP,results also hold Constrained-MAP. However, intractability proofneither |I| tw bounded. best knowledge parameterizedcomplexity result known (in either direction) {q}Constrained-MAP.717fiKwisthout5.4 Efficient MAP Approximation: Road-map Future Researchestablished particular, constrained version MAP efficiently approximated expectation-approximations probability MAP explanationhigh (where tree-width instance may unbounded). next step wouldinvestigate parameterized approximability current state-of-the-art approximationalgorithms MAP show parameterization regimes algorithmsshown FERT FPERT.different perspective, interesting explore parameterizationerror randomized algorithms (for example) establish analog Whierarchy parameterizations. allows us derive fine-grained negativeparameterization results, similar way proving W[1]-hardness leads finegrained negative results proving para-NP-hardness.6. Conclusionpaper analyzed whether low tree-width prerequisite approximating MAPBayesian networks. formalized four distinct notions approximating MAP (by value,structure, rank, expectation) argued approximate MAP intractable generalusing either notions. case value-approximation, structure-approximation,rank-approximation showed MAP cannot approximated using notions(non-trivial) instances high tree-width, ETH holds. However, showedconstrained version MAP, despite PP-hard general, tractablyexpectation-approximated probable explanation high probability.proposed complexity classes FERT FPERT capture parameterizationerror (respectively error running time), rather running time. resultscontributed fuller understanding make state-of-the-artapproximation algorithms MAP feasible practice.7. Acknowledgementsprevious version paper (Kwisthout, 2014) published ProceedingsSeventh European Workshop Probabilistic Graphical Models (PGM 2014). authorwishes thank workshop participants (both sets of) anonymous reviewers stimulating discussion worthwhile suggestions. thanks particular Hans BodlaenderTodd Wareham valuable comments earlier version manuscript.ReferencesAbdelbar, A. M., & Hedetniemi, S. M. (1998). Approximating MAPs belief networksNP-hard theorems. Artificial Intelligence, 102, 2138.Agrawal, M., Kayal, N., & Saxena, N. (2004). PRIMES P. Annals Mathematics,160 (2), 781793.Arora, S., & Barak, B. (2009). Computational Complexity: Modern Approach. CambridgeUniversity Press.718fiTree-Width MAP ApproximationsArvind, V., & Raman, V. (2002). Approximation algorithms parameterized counting problems. Bose, P., & Morin, P. (Eds.), Algorithms Computation, Vol. 2518Lecture Notes Computer Science, pp. 453464. Springer Berlin Heidelberg.Cheng, J., & Druzdzel, M. (2000). AIS-BN: adaptive importance sampling algorithmevidential reasoning large Bayesian networks. Journal Artificial IntelligenceResearch, 13 (1), 155188.Clementi, A., Rolim, J., & Trevisan, L. (1998). Recent advances towards proving P=BPP.Allender, E. (Ed.), Bulletin EATCS, Vol. 64. EATCS.Darwiche, A. (2009). Modeling Reasoning Bayesian Networks. Cambridge University Press.De Campos, C. P. (2011). New complexity results MAP Bayesian networks.Walsh, T. (Ed.), Proceedings Twenty-Second International Joint ConferenceArtificial Intelligence, pp. 21002106.Downey, R. G., & Fellows, M. R. (1999). Parameterized Complexity. Springer Verlag, Berlin.Flum, G., & Grohe, M. (2006). Parameterized Complexity Theory. Springer, Berlin.Gill, J. T. (1977). Computational complexity Probabilistic Turing Machines. SIAMJournal Computing, 6 (4), 675695.Hamilton, M., Muller, M., van Rooij, I., & Wareham, H. (2007). Approximating solutionstructure. Demaine, E., Gutin, G., Marx, D., & Stege, U. (Eds.), Structure TheoryFPT Algorithmics Graphs, Digraphs Hypergraphs, No. 07281 DagstuhlSeminar Proceedings.Henrion, M. (1986). Propagating uncertainty Bayesian networks probabilistic logicsampling. Kanal, L., & Lemmer, J. (Eds.), Proceedings Second AnnualConference Uncertainty Artificial Intelligence, pp. 149164. New York: ElsevierScience.Impagliazzo, R., & Paturi, R. (2001). complexity k-SAT. Journal ComputerSystem Sciences, 62 (2), 367 375.Krentel, M. W. (1988). complexity optimization problems. Journal ComputerSystem Sciences, 36, 490509.Kwisthout, J. (2009). Computational Complexity Probabilistic Networks. Ph.D.thesis, Faculty Science, Utrecht University, Netherlands.Kwisthout, J. (2011). probable explanations Bayesian networks: Complexitytractability. International Journal Approximate Reasoning, 52 (9), 1452 1469.Kwisthout, J. (2013). Structure approximation probable explanations Bayesiannetworks. van der Gaag, L. (Ed.), Proceedings Twelfth European ConferenceSymbolic Quantitative Approaches Reasoning Uncertainty, Vol. 7958LNAI, pp. 340351. Springer-Verlag.Kwisthout, J. (2014). Treewidth computational complexity MAP approximations.van der Gaag, L., & Feelders, A. (Eds.), Proceedings Seventh EuropeanWorkshop Probabilistic Graphical Models, Vol. 8754 Lecture Notes ComputerScience, pp. 271285. Springer International Publishing.719fiKwisthoutKwisthout, J. (2015). frugal explanations Bayesian networks. Artificial Intelligence,218, 56 73.Kwisthout, J., Bodlaender, H. L., & van der Gaag, L. C. (2010). necessity boundedtreewidth efficient inference Bayesian networks. Coelho, H., Studer, R.,& Wooldridge, M. (Eds.), Proceedings 19th European Conference ArtificialIntelligence, pp. 237242. IOS Press.Kwisthout, J., Bodlaender, H. L., & van der Gaag, L. C. (2011). complexity findingkth probable explanations probabilistic networks. Cerna, I., Gyimothy, T.,Hromkovic, J., Jefferey, K., Kralovic, R., Vukolic, M., & Wolf, S. (Eds.), Proceedings37th International Conference Current Trends Theory PracticeComputer Science, Vol. LNCS 6543, pp. 356367. Springer.Kwisthout, J., & van Rooij, I. (2013). Bridging gap theory practiceapproximate Bayesian inference. Cognitive Systems Research, 24, 28.Littman, M. L., Majercik, S. M., & Pitassi, T. (2001). Stochastic boolean satisfiability.Journal Automated Reasoning, 27 (3), 251296.Marx, D. (2007). beat treewidth?. Proceedings 48th Annual IEEESymposium Foundations Computer Science, pp. 169179.Montoya, J.-A., & Muller, M. (2013). Parameterized random complexity.. Theory Computing Systems, 52 (2), 221270.Papoulis, A. (1984). Probability, Random Variables, Stochastic Processes (2nd edition).New York: McGraw-Hill.Park, J. D., & Darwiche, A. (2001). Approximating MAP using local search. Proceedings17th Conference Uncertainty Artificial Intelligence, pp. 403410. MorganKaufmann Publishers, San Francisco, California, 2001.Park, J. D., & Darwiche, A. (2004). Complexity results approximation settingsMAP explanations. Journal Artificial Intelligence Research, 21, 101133.Robertson, N., & Seymour, P. (1986). Graph minors II: Algorithmic aspects tree-width.Journal Algorithms, 7, 309322.Sontag, D., Meltzer, T., Globerson, A., Weiss, Y., & Jaakkola, T. (2008). Tightening LPrelaxations MAP using message-passing. Proceedings 24th ConferenceUncertainty Artificial Intelligence, pp. 503510. AUAI Press.Toda, S. (1994). Simple characterizations P(#P) complete problems. JournalComputer System Sciences, 49, 117.Van Rooij, I., & Wareham, H. (2012). Intractability approximation optimizationtheories cognition. Journal Mathematical Psychology, 56 (4), 232 247.Yuan, C., Lu, T., & Druzdzel, M. J. (2004). Annealed MAP. Chickering, D., & Halpern,J. (Eds.), Proceedings Twentieth Conference Uncertainty Artificial Intelligence, pp. 628635. AUA.720fiJournal Artificial Intelligence Research 53 (2015) 439-496Submitted 12/14; published 07/15Bypassing Combinatorial Protections: Polynomial-TimeAlgorithms Single-Peaked ElectoratesFelix Brandtbrandtf@in.tum.deInstitut fur InformatikTU Munchen85748 Garching, GermanyMarkus Brillbrill@cs.duke.eduDepartment Computer ScienceDuke UniversityDurham, NC 27708, USAEdith Hemaspaandraeh@cs.rit.eduDepartment Computer ScienceRochester Institute TechnologyRochester, NY 14623, USALane A. Hemaspaandralane@cs.rochester.eduDepartment Computer ScienceUniversity RochesterRochester, NY 14627, USAAbstractmany election systems, bribery (and related) attacks shown NP-hard using constructions combinatorially rich structures partitions covers. paper shows voters follow central political-science model electoratessingle-peaked preferencesthose hardness protections vanish. using single-peaked preferences simplify combinatorial covering challenges, first time show NPhard bribery problemsincluding Kemeny Llull electionsfall polynomialtime single-peaked electorates. using single-peaked preferences simplify combinatorial partition challenges, first time show NP-hard partition-of-voters problems fall polynomial time single-peaked electorates. show single-peakedelectorates, winner problems Dodgson Kemeny elections, though p2 -completegeneral case, fall polynomial time. completely classify complexityweighted coalition manipulation scoring protocols single-peaked electorates.1. IntroductionElections perhaps important framework preference aggregation. electionsystem (or election rule) mapping takes input preferences votersrespect set candidates (alternatives) returns set winners,subset candidate set. Elections central preference aggregation among humanseverything political elections selecting good singers popular television shows.Elections rapidly increasing importance electronic settings multiagentsystems, used proposed varied tasks recommender systemscollaborative filtering (Ghosh, Mundhe, Hernandez, & Sen, 1999; Pennock, Horvitz, &c2015AI Access Foundation. rights reserved.fiBrandt, Brill, Hemaspaandra, & HemaspaandraGiles, 2000), web spam reduction improved web-search engines (Dwork, Kumar, Naor,& Sivakumar, 2001), planning (Ephrati & Rosenschein, 1997). electronic settings,elections may huge numbers voters alternatives.One natural worry elections agents may try slant outcome, example, bribing voters. Motivated work economics political science showingreasonable election systems always allow manipulation cases (Gibbard, 1973;Satterthwaite, 1975; Duggan & Schwartz, 2000), starting 1989, Bartholdi, Orlin, Tovey,Trick (Bartholdi, Tovey, & Trick, 1989; Bartholdi & Orlin, 1991; Bartholdi, Tovey,& Trick, 1992) made thrilling suggestion elections protected via complexitytheorynamely, making attackers task NP-hard. line active eversince. resulted NP-hardness protections proven many election systems,attacks bribery (the attacker budget buy altervoters votes, Faliszewski, Hemaspaandra, & Hemaspaandra, 2009), manipulation (a coalition voters wishes set votes make given candidate win, Bartholdi et al.,1989; Bartholdi & Orlin, 1991), control (an agent seeks make given candidate winadding/deleting/partitioning voters candidates, Bartholdi et al., 1992). bookchapter Faliszewski, Hemaspaandra, Hemaspaandra, Rothe (2009b) surveysNP-hardness results, apply many important election systems plurality,single transferable voting, approval voting.past years, flurry papers come asking whether NP-hardnessprotections satisfying. particular, papers explore possibility heuristicalgorithms may well frequently approximation algorithms may exist.papers questioned. example, influential frequency paper (Friedgut, Kalai, & Nisan, 2008, see also journal version, Friedgut, Kalai, Keller,& Nisan, 2011) assumes voter random independent candidate preferenceordering, model seem reflect typical voter behavior. approximations, work showing certain voter-control settings (differentstudied paper) polynomial-time algorithms use, example,log number candidates times many added voters optimal approachwould need (Faliszewski, Hemaspaandra, & Hemaspaandra, 2013). However, campaignmanager might well financial resources motivate many extra peoplecome vote, rather would want know smallest possible number votesadd reach victory.present paper questions NP-hardness results completely different direction. political science, perhaps canonical model electorates unidimensional single-peaked model. model, electorate preferencesone-dimensional spectrum (e.g., liberal conservative) alongcandidates also located, voters preferences (loosely put)peak, affinity declining one moves away peak. brilliant paper Walsh(2007) recently asked whether NP-hardness protections manipulation fall apartelectorates single-peaked. case Walsh looked at, answer proved no;looked particular NP-hardness manipulation protection proved holds evensingle-peaked societies. Faliszewski, Hemaspaandra, Hemaspaandra, Rothe (2011),inspired Walshs work, looked range election systems came sharply dif440fiBypassing Combinatorial ProtectionsProblemGeneral cases complexitySingle-peaked casescomplexityapproval:briberynegative-briberystrongnegative-briberyNP-comp. (Faliszewski et al., 2009)NP-comp. (Thm. 4.3, part 1)NP-comp. (Thm. 4.3, part 1)P (Thm. 4.2)P (Thm. 4.3, part 2)P (Thm. 4.3, part 2)NP-comp.NP-comp.NP-comp.NP-comp.NP-comp.P (Thm. 4.7)P (Thm. 4.7)P (Thm. 4.7)NP-comp. (Thm. 4.7)P (Thm. 5.3)Llull:bribery$briberyweighted-briberyweighted-$briberycontrolvoter partitionKemeny:winnerbribery$briberyweighted-briberyweighted-$bribery(Faliszewski(Faliszewski(Faliszewski(Faliszewski(Faliszewskietetetetetal.,al.,al.,al.,al.,2009)2009)2009)2009)2009a)p2 -comp. (Hemaspaandra et al., 2005)p2 -hard (Thm. 4.8)p2 -hard (Thm. 4.8)p2 -hard (Thm. 4.8)p2 -hard (Thm. 4.8)P (Thm. 3.3)P (Thm. 4.9)P (Thm. 4.9)P (Thm. 4.9)NP-comp. (Thm. 4.9)Table 1: single-peakedness (often) lowers complexity key election problems.fering conclusion many crucial cases, NP-hardness protections manipulationcontrol vanish single-peaked electorates.present paper young line research complexity manipulative actionscontext single-peaked electorates. work seeks take line researchnew directions, improve one existing direction, following contributions:1. (Section 3) show checking winner Dodgson, Young, Kemeny elections, known p2 -complete general case (respectively dueHemaspaandra, Hemaspaandra, & Rothe, 1997, due papers Theorem A.2based adapting proof Rothe, Spakowski, & Vogel, 2003, due Hemaspaandra, Spakowski, & Vogel, 2005), polynomial time single-peaked electorates(Corollary 3.3 Theorem 3.4).algorithm shows Dodgson elections good example generaltechnical theme paper: single-peakedness often precludes combinatorial explosion. particular case, single-peakedness simplify seeminglyexponential-sized search space series exchanges provide upper boundsDodgson scores, allow us instead search polynomial-sized possibility space related particular, simple set exchanges happening limitedtwo voters.2. (Section 4) first time study effect single-peaked electoratescomplexity bribery. show many NP-hardness protections bribery441fiBrandt, Brill, Hemaspaandra, & Hemaspaandrageneral case vanish single-peaked electorates. (Table 1 provides keyexamples examples lowering complexity.) show this,give polynomial-time bribery algorithms single-peaked electorates many settings. polynomial-time algorithms apply approval voting (Theorem 4.2Theorem 4.3) rich range weak-Condorcet consistent election systemseven systems merely known weak-Condorcet consistentelectorate single-peaked (Corollary 4.5), including weakBlack, weakDodgson,Fishburn, Kemeny, Llull, Maximin, Schwartz, Young, two variants Nansondue Fishburn Schwartz.right general interpretation underlies NP-hardness resultsuse (in outputs reductions establishing NP-hardness) sets voter preferencesintricate simply cannot realized single-peaked societies.practical lesson skeptical NP-completeness resultselectorate may limitations (such single-peakedness) ensemblesvotes produces. specific technical reason obtain polynomial-timebribery algorithms NP-hardness proofs based combinatoriallyrich structure covering problems (whose core challenge incomparabilityvoters), (see proof Theorem 4.2) use single-peakedness createdirectional attack covering problems effect locally removingincomparability.3. (Section 5) first time study effect single-peaked electoratescomplexity control partition voters, voters partitionedtwo groups vote candidates primary elections, winnersprimaries compete final election. one seven types controlintroduced seminal control paper Bartholdi et al. (1992), controlpartition voters previously addressed single-peaked case.show known NP-hardness protections control-by-partition vanishsingle-peaked electorates, giving polynomial-time algorithmssingle-peaked control partition (Theorems 5.2 5.6, Corollary 5.3).general interpretation practical lessonmentioned bribery case. However, technical way obtain control-bypartition result differs here. technical challenge exponential numberpartitions, algorithms circumvent using single-peakedness allowus effect structure huge number partitions polynomial numberclasses partitions class look class ratherexplore member partitions.shared technical theme bribery case single-peakednessused tame combinatorial explosion (of partitions covers)general case protected elections attack, particular single-peakedness yieldspolynomial-time attack algorithms.4. final contribution (Section 6) strong extension important resultFaliszewski et al. (2011). broad class election systems known scoringprotocols, Faliszewski et al. gave complete characterization computational442fiBypassing Combinatorial Protectionscomplexity (weighted, coalition) manipulation problem case singlepeaked elections three candidates. characterizations importanttell systems easily manipulable systemsmakes easily manipulable. extend providing, single-peakedelectorates, complete characterization easy manipulability scoring protocols(Theorem 6.2). is, extend three-candidate theorem Faliszewski et al.(2011) result holds number candidates, allows oneimmediately read complexity manipulation scoring protocol,single-peaked electorates.proof organization follows. four result sections contains onespotlight theorem, whose proof give within section itself. proofs seekgive key flavor techniques, text proofs often tryinformally describe proofs ideas approaches. first three four spotlightproofs directly support, fourth spotlight proof part, papers technicaltheme single-peakedness tames combinatorial explosion. appendix contains,completeness, proofs results, definitions omitted maintext.2. Preliminariessection presents preliminaries topics election systems, preferences, notionsrelated Condorcet consistency, single-peakedness.2.1 Election Systems, Preferences, weakCondorcet Consistencyelection system (or election rule) mapping finite set candidates Cfinite collection V voter preferences candidates collection W Ccalled winner set.1 one election systems cover, voterspreference linear order (by always mean strict linear order: irreflexive,antisymmetric, complete, transitive relation) candidates. election systemcalled approval voting, voter votes bit-vector, approving disapprovingcandidate separately. Voters preferences input list ballots (i.e., votes),multiple voters preference, ballot appear separately V .briefly describe election systems central paper. approvalvoting, preferences approval vectors, candidate gets highest numberapprovals among candidates belongs winner set. systems use,voters vote linear orders. candidate said Condorcet winner (respectively,weak Condorcet winner ), candidate preferred candidate strictmajority (respectively, least half) voters. Condorcet voting (or Condorcetelections) winners precisely set Condorcet winners. election system1. social choice theory, called social choice correspondence. Social choice theorists often excludecase allowing function empty set winners, following Bartholdi et al. (1992)many computationally oriented papers, artificially exclude case definitions.However, except elections zero candidates, systems discuss might ever outputempty set winners Condorcet weakCondorcet.443fiBrandt, Brill, Hemaspaandra, & HemaspaandraweakCondorcet, winners precisely set weak Condorcet winners.known two hundred years election instances neither Condorcet winnersweak Condorcet winners (Condorcet, 1785). course, election instanceone Condorcet winner, whereas might several weak Condorcetwinners.Let , 0 1, rational number. Copeland (Copeland, 1951, = 12 ;Faliszewski et al., 2009a, general rational ) election system defined follows.pair distinct candidates, consider one (if any) preferredtwo strict majority voters. one gets one Copeland pointpairwise contest gets zero Copeland points. candidatespair tie pairwise contest (which happen number voterseven), gets points. = 1, Copeland known Llull, system definedmystic Ramon Llull thirteenth century (see Hagele & Pukelsheim, 2001).Llulls election system known remarkably resistant, computationally, briberycontrol attacks (Faliszewski et al., 2009a, although see also Erdelyi, Nowak, & Rothe,2009, Erdelyi & Rothe, 2010, Erdelyi, Piras, & Rothe, 2011, Menton, 2013, differenthighly resistant systems, see Hemaspaandra, Hemaspaandra, & Rothe, 2009, regardingextremely resistant artificial systems constructed).important class elections, focus Section 6, classscoring protocols. scoring protocol fixed number candidates definedscoring vector = (1 , 2 , . . . , ) Nm , 1 2 . Voters voteslinear orders, voter contributes 1 points preferred candidate,2 points next preferred candidate, on. candidate whosetotal number points least great totals candidate winner.example, m-candidate plurality voting scoring protocol defined scoringm1z }| {vector = (1, 0, . . . , 0). m-candidate Borda voting scoring protocol definedscoring vector = (m 1, 2, . . . , 0).Kemeny elections basedP concept Kemeny consensus. linear order > minimum Kemeny score, a,bC, > b k{v V | v prefers b a}k, saidKemeny consensus. usual, kSk denotes cardinality finite set S. candidate cKemeny winner c ranked first Kemeny consensus. Kemeny electionsintroduced Kemeny (1959, see also Kemeny & Snell, 1960).Black elections (respectively, weakBlack elections), Condorcet winner (respectively, weak Condorcet winners), defines winners, otherwise Bordas method used select winners. Black elections introduced Black(1958) weakBlack elections (somewhat confusingly called Black elections there)introduced Fishburn (1977). Dodgson elections (respectively, weakDodgson elections),whichever candidates fewest repeated transpositions adjacent candidatesvoters orders become Condorcet winners (respectively, weak Condorcet winners)winners. Dodgson elections introduced 1800s Dodgson (1876) weakDodgson elections (somewhat confusingly called Dodgson elections there) introducedFishburn (1977) studied McCabe-Dansted, Pritchard, Slinko (2008).Young elections (respectively, strongYoung elections), whichever candidatesdeletion fewest voters become weak Condorcet (respectively, Condorcet) winners444fiBypassing Combinatorial Protectionswinners. Young elections introduced Young (1977) strongYoung elections(somewhat confusingly called Young elections there) introduced Rothe et al. (2003).important notion paper weakCondorcet-consistent. election system said weakCondorcet-consistent (which earlier wrote, equivalently,weak-Condorcet consistent), every input least one weak Condorcet winner, winners election system exactly set weak Condorcet winners.2bribery results hold election systems weakCondorcetconsistent, even election systems restricted single-peaked electoratesweakCondorcet-consistent.Fishburn (1977) noted election systems weakBlack, weakDodgson, Fishburn, Maximin, Young weakCondorcet-consistent. add observationLlull elections easily seen definition weakCondorcet-consistent.also make (new) observation election systems Kemeny, Schwartz,two variants Nanson due Fishburn Schwartz weakCondorcet-consistentrestricted single-peaked electorates. (By Fishburn, 1977, Niou, 1987, systemsknown weakCondorcet-consistent general case.) also noteBlack, Dodgson, original version Nanson, , 0 < 1, Copeland elections weakCondorcet-consistent even restricted single-peaked electorates.seen following universal counterexample. Let two voters preferences b > > c c > b > a. preferences single-peaked respectsocietal ordering L b L c (the notion societal orders explained two paragraphs present one). Candidates b c weak Condorcet winners,mentioned election systems chooses b. Similarly, note strongYoungweakCondorcet-consistent single-peaked electorates election twovoters whose preferences > b > c c > b > a, candidates weak Condorcetwinners, strongYoung yields candidates c. appendix includes definitionselection systems Fishburn, Maximin (a.k.a. Simpson), Nanson, provesnew observations made paragraph.2.2 Single-Peaked Preferencespapers theme combinatorial protections crumble case single-peakedelectorates. briefly define single-peaked preferences motivation is.single-peaked preference model introduced half century ago Black(1948, 1958) influential ever since. model captures caseelectorate polarized single issue dimension, voters utility alongdimension either one peak rises falls. Candidates positions (locations)along dimension. voters preferences (in linear order model) simply ordercandidates utility (except ties allowed). Since utility curves flexible,amounts overall societal ordering L candidates,voter placed location candidates2. nomenclature literature varied here. authors use term weak Condorcetconsistent mean systems always select weak Condorcet winners perhaps additional winners. denote weakCondorcet-consistent precisely Fishburn (1977) calls[obeying the] strict Condorcet principle.445fiBrandt, Brill, Hemaspaandra, & Hemaspaandravotersv1v2v3v4utilityc1liberalc2c3c4candidatesc5conservativeFigure 1: Example single-peaked electorate four voters, utility functionsshown.right preferences drop left, although within framework,right left candidates interspersed other. picture makeclearer. Figure 1 shows electorate four voters five candidates,societys polarization (liberal-to-conservative) axis. picture, seev1 preferences c5 > c4 > c3 > c2 > c1 , v2 preferences c1 > c2 > c3 > c4 > c5 ,v3 preferences (note interleaving) c2 > c3 > c1 > c4 > c5 , v4 preferencesc4 > c5 > c3 > c2 > c1 .Formally, many equivalent ways capture behavior, usefollowing definition. collection V votes (each linear ordering >icandidates) candidate set C said single-peaked exactly exists linear ordering L C triple candidates a, b, c, holds(a L b L c c L b L a) (i) [a >i b b >i c].single-peaked model intensely studied, strengths limitations. positive side, excellent rough model wide range elections.Votes ranging American presidential elections US Supreme Court votes hiringvotes within CS department often shockingly close reflecting single-peaked preferences. certainly vastly reasonable model settings assumingvoters random independent, although latter model receivinghuge amount study recently. fact, wide range scholarly studies arguedvalue single-peaked model (Black, 1948, 1958; Davis, Hinich, & Ordeshook, 1970;Niemi & Wright, 1987; Procaccia & Rosenschein, 2007; Krehbiel, 1998), modelone first taught students positive (i.e., theoretical) political science courses.hand, electorates certainly driven multidimensional concerns,even heavily unidimensional electorate may outside-the-box voters (e.g., voterselection polarized liberal-conservative axis decide votes instead basedon, example, religion race). Simply put, model, speaks simplifiedversion world.446fiBypassing Combinatorial Protectionssingle-peaked model also makes sense approval voting (Faliszewski et al., 2011):There, voter intuitively may thought utility threshold startingapproves candidates. means voters approved candidatesmust contiguous within societys linear order L. Formally, define sayingelection instance (of approval voters) single-peaked exactly exists linearorder L triple candidates a, b, c, L b L c (i) [{a, c}Approvesi b Approvesi ], Approvesi set candidates voter approves.Following suggestion Walshs (2007) seminal work, assume (exceptmake something else clear) societys linear order part input singlepeaked winner, bribery, manipulation, control problems. However, mentionpassing given election instance, one polynomial time tell whether voterssingle-peaked also polynomial time compute societal linear orderinstantiating single-peakedness (by Bartholdi Trick, 1986, Doignon Falmagne,1994, Escoffier, Lang, Ozturk, 2008, linear-order preferences and, pointedTheorem 2.1 Faliszewski et al., 2011, Fulkerson Gross, 1965, BoothLueker, 1976, approval preferences). One course also easily, polynomialtime, check whether given linear order one respect given set votessingle-peaked.want get results quickly possible, define needednotions winner, bribery, control, manipulation start sectionparticular topic.3. WeakCondorcet Elections, Single-Peaked Electorates, BypassingWinner-Problem Complexitymain results sections paper study whether single-peakedness bypassescomplexity-theoretic protections attacks elections. moving sections, quickly present results showing single-peakedness also bypassescomplexity results systems even telling won. Unlike protectionattack complexity-shield bypassings, sense bad news (for security election systems), winner-hardness complexity-shield bypassingsgood newstaming complexity election systems Dodgson Kemenysingle-peaked case, despite fact known NP-hard winner problemsgeneral case.given election system E, winner problem takes input election, (C, V ),candidate p C, asks p winner election whose candidates Cwhose votes V (where V collection votes candidate set C).speak single-peaked case winner problem, input also contain linearorder L relative election single-peaked. (Formally, part winner-problemtask check input indeed single-peaked relative L. However, sincepolynomial-time check caseslinear orders approval vectorsthat dealwith, tacitly view appropriateness L syntactic condition input,although really syntactic.) Note weakCondorcet winner problem Pgeneral case thus certainly single-peaked case. Furthermore, something447fiBrandt, Brill, Hemaspaandra, & Hemaspaandraused often papers proofs following standard fact Condorcet votingmedians.Fact 3.1. Let (C, V ) election votes linear orders C, let Llinear order respect (C, V ) single-peaked. Associate votercandidate top voters preference ordering. Order voters respect Lterms association.kV k odd unique weakCondorcet Condorcet winner winnertop preference median voter. kV k even weakCondorcet winner setset candidates L fall range, inclusively, top preferenceleftmost two median voters top preference rightmost twomedian voters (and two coincide, candidate Condorcet winnerotherwise Condorcet winner).example, ordered-by-L picture candidates voterstop choices are:v3v6v1v2v4v5c1c2c3c4c5c6c2 , c3 , c4 weak Condorcet winners, since candidates preferredcandidates right v1 , v2 , v3 , candidates left v4 , v5 ,v6 . c1 weak Condorcet winner, since voters v1 prefer c2 c1 .c5 c6 weak Condorcet winners, since v1 , v2 , v3 , v4 prefer c4 c5 c6 .Finally, note Condorcet winner, since Condorcet winner uniqueweak Condorcet winner.immediate consequence Fact 3.1 well-known fact single-peakedelections, always least one weak Condorcet winner (we tacitly assumingC 6= ). Since earlier noted winner problem P weakCondorcet elections,following holds.Theorem 3.2. election system E weakCondorcet-consistent restrictedsingle-peaked electorates, winner problem P restricted single-peakedelections.course, many systems winner problem obviously P even general.Yet get interesting consequences Theorem 3.2 following (recallSection 2 Young weakDodgson weakCondorcet-consistent, KemenyweakCondorcet-consistent restricted single-peaked electorates).Corollary 3.3. restricted single-peaked electorates, winner problems Kemeny, Young, weakDodgson elections P.contrast, general-case Kemeny winner problem problem proven Hemaspaandra et al. (2005) p2 -complete.3 prove paper generalcase winner problems Young weakDodgson elections p2 -complete well (see3. p2 class sets solved polynomial-time parallel access NP (Papadimitriou &Zachos, 1983; Hemachandra, 1989). Throughout paper, completeness always refers completenessrespect polynomial-time many-one reductions.448fiBypassing Combinatorial ProtectionsTheorems A.2 A.4 appendix). So, Theorem 3.2 implies sharp complexity simplifications three election systems. mention passing even generalization single-peakedness known bounded single-peaked width (Cornaz, Galand,& Spanjaard, 2012), work Cornaz, Galand, Spanjaard (2013) done subsequent Corollary 3.3 (Brandt, Brill, Hemaspaandra, & Hemaspaandra, 2010) showspolynomial time one find Kemeny winner, find scorewinnerand thus Kemeny winnerswill have. (This necessarily mean onepolynomial-time algorithm testing, generalized setting, whether givencandidate Kemeny winner.)identify weakCondorcet approach worked Young weakDodgson elections apply Dodgson strongYoung elections. However,constructed direct algorithms solve winner problems polynomial timesingle-peaked case. state theorem, prove immediatelyspotlight proof section.Theorem 3.4. restricted single-peaked electorates, winner problems Dodgson strongYoung elections P.Proof. Recall following easy characterization Condorcet winners singlepeaked setting. kV k odd, top choice median voter Condorcet winner.kV k even, two cases: either median voters top choicenot. former case, median voters preferred candidate Condorcet winner,latter case Condorcet winner (since top choices two medians,different, tie other).Given election instance (C, V ) valid single-peaked order L, showcompute strongYoung winners polynomial time. Recall strongYoung winnerscandidates made Condorcet winners fewest voter deletions.mention C = never winners. zero voters, candidatesstrongYoung winners, tie distance , convention.4 (C, V )Condorcet winner, unique strongYoung winner. Otherwise kV k 2 eventwo median voters different top choices, say m` mr . strongYoungwinner set {m` , mr }, two candidates strongYoung score 1, onescore 0, everyone else score least 2.show Algorithm 1, clearly runs polynomial time, computesDodgson winners. Recall Dodgson winners candidates fewestrepeated transpositions adjacent candidates voters orders (so-called switches) becomeCondorcet winners. kCk = 0, winners, kV k = 0, C tieswinners, (C, V ) Condorcet winner, candidate unique Dodgsonwinner. assume kV k 2 even two median voters different top choices,say m` mr , m` L mr , candidate Dodgson score 0. intuition behind4. Regarding line Algorithm 1 handling zero-voter zero-candidate case, one mightwonder dont define election problems allow cases. answer is, first,unattractive simplify proofs altering problems. But, compellingly, control problemsimportant papers, control problems inputs small numbercandidates (respectively, voters) create situations small numbers candidates(respectively, voters). particular, legal partitions within partition-control types leave onecandidates voters.449fiBrandt, Brill, Hemaspaandra, & Hemaspaandraalgorithm follows. show every Dodgson winner weak Condorcet winner.show always turn weak Condorcet winner Condorcet winnerminimum number switches making changes two voters.5 proofcorrectness follows immediately Claims 3.5 3.6 below. Note Fact 3.1,set weak Condorcet winners consists candidates L fall range,inclusively, m` mr . denote set [m` , mr ]L .Claim 3.5. Algorithm 1 find correct Dodgson score candidate p [m` , mr ]L .Claim 3.6. Every Dodgson winner [m` , mr ]L .proofs two claims, use following simple claim.Claim 3.7.1. Let p [m` , mr ]L . (a L b L p p L b L a) ties p, b ties p.2. mr L d, mr beats d. L m` , m` beats d.6Proof Claim 3.7.1. know half voters prefer p half voters prefer p a.voters prefer p also prefer b p. implies p best ties b.Fact 3.1, p weak Condorcet winner. follows p ties b.2. prove first statement. proof second statement analogous. Supposecontradiction mr beat d. Since mr weak Condorcet winner,mr ties d. Let db candidate immediately right mr (with respect L).Using part 1 claim, follows db ties mr .Since db weak Condorcet winner, exists candidate c c beatsb Note c L mr L db mr L db L c. c L mr L d,b every voter prefers cd.b mr beats d,b contradicts fact mr tiesdb also prefers mr d.bbd. mr L L c, every voter prefers c db also prefers db mr . cdb beat mr , contradicts fact mr weak Condorcet winner.q Claim 3.7Proof Claim 3.5. Consider optimal (with respect number switches) wayturn p Condorcet winner. first assume T` 6= Tr 6= . Let c`leftmost candidate T` let cr rightmost candidate Tr . Since p needsgain vote c` , exists voter v` c` >v` p p gets switched beyond c`v` . Since p needs gain vote cr , exists voter vr cr >vr p pgets switched beyond cr vr . Let A` , B` , C` sets candidates v` orderformA` > c` > B` > p > C` .5. One might think turning weak Condorcet winner Condorcet winner would equivalentmaking sure median voters candidate top choice. However, noteelectorate may longer single-peaked switches, footnoted statementsurprising harder prove one might think.6. Note possible candidate weak Condorcet winner tie weak Condorcetwinner. example, universal counterexample end Section A.2, candidate a,weak Condorcet winner, ties weak Condorcet winner c.450fiBypassing Combinatorial ProtectionsAlgorithm 1 Dodgson winners1: kV k = 0 kCk = 02:return C3: else kV k odd (kV k even two median voters top choice)4:return candidate chosen median voter(s)5: else6:Let m` mr , m` L mr , top choices median voters7:p [m` , mr ]L8:DodgsonScore(p)9:Let T` set candidates c c L p c ties p10:Let Tr set candidates c p L c c ties p11:v` , vr V T` >v` p Tr >vr p12:Move p order v` beyond every candidate T`13:Move p order vr beyond every candidate Tr14:Let n number switches used15:n < DodgsonScore(p)16:DodgsonScore(p) n17:return {p C | DodgsonScore(p) DodgsonScore(c) c [m` , mr ]L }Let Ar , Br , Cr sets candidates vr order formAr > cr > Br > p > Cr .Note T` >v` p >v` Tr Tr >vr p >vr T` . Clearly, v` 6= vr takes kB` k + 1switches switch p beyond c` v` takes kBr k + 1 switches switch p beyond crvr . kB` k + kBr k + 2 switches, v` order turned A` > p > c` > B` > C`vr order turned Ar > p > cr > Br > Cr . Since T` Cr , stillensure p gains vote every candidate A` T` since Tr C` , stillensure p gains vote every candidate Ar Tr . So,DodgsonScore(p) kB` k + kBr k + 2 + kA` T` k + kAr Tr k.show Algorithm 1 correctly computes Dodgson score p. First notealgorithm computes upper bound Dodgson score, since p madeCondorcet winner iteration loop (recall Fact 3.1 p alreadyweak Condorcet winner). consider score computed algorithm voters v`vr (since T` >v` p Tr >vr p, algorithm consider two voters).analysis, may help keep mind c` L T` {c` } L p L Tr {cr } L cr .top choice v` c` left c` , A` T` = . case,moving p order v` beyond every candidate T` givesA` > p > c` > B` > C` .top choice v` right c` , every candidate c A` , c` L c L p.follows Claim 3.7.1 A` = A` T` . case, algorithm changes v`p > A` > c` > B` > C` .451fiBrandt, Brill, Hemaspaandra, & Hemaspaandracases, algorithm uses kB` k + 1 + kA` T` k switches v` . argumentshows algorithm uses kBr k + 1 + kAr Tr k switches vr . clearly makes pCondorcet winner using kB` k + kBr k + 2 + kA` T` k + kAr Tr k switches. Sincealso upper bound (see above), followsDodgsonScore(p) = kB` k + kBr k + 2 + kA` T` k + kAr Tr k.still handle case T` = Tr = . Without loss generality,assume Tr = . Since m` mr tie p m` 6= mr , follows T` 6= . Let c`leftmost candidate T` . previous case, exist voter v` setscandidates A` , B` , C` v` order formA` > c` > B` > p > C`DodgsonScore(p) kB` k + 1 + kA` T` k.show Algorithm 1 correctly computes Dodgson score p. Considerscore computed algorithm voter v` letting vr arbitrary voter.Since T` >v` p Tr >vr p (since Tr = ), algorithm consider two voters.previous case, algorithm uses kB` k + 1 + kA` T` k switches v` .since Vr = , algorithm uses zero switches vr . clearly makes p Condorcetwinner using kB` k + 1 + kA` T` k switches. Since also upper bound, followsDodgsonScore(p) = kB` k + 1 + kA` T` k.q Claim 3.5Proof Claim 3.6. Let 6 [m` , mr ]L . Without loss generality, assume mr L d.show DodgsonScore(d) > DodgsonScore(mr ), impliesDodgson winner. Let set candidates C {mr } mr ties with. Note6= , since m` ties mr . every c , c L mr (by Claim 3.7.2) beatc (half voters prefer c mr , since c L mr L d, voters prefer c mr d).Consider optimal (with respect number switches) way turnCondorcet winner. Let c` leftmost candidate . Since half voters prefer c`mr d, exists voter v c` >v mr >v gets switched beyond c`v. Let A, B, C1 , C2 sets candidates vs order form> c` > B > mr > C1 > > C2 .takes kBk + kC1 k + 2 switches switch beyond c` v, switches, vsorder turned> > c` > B > mr > C1 > C2 .still ensure gains vote every candidate . So,DodgsonScore(d) kBk + kC1 k + 2 + kA k.consider mr . Since c` leftmost candidate every c , c L mr ,holds >v mr . Since mr weak Condorcet winner, moving mr order452fiBypassing Combinatorial Protectionsv beyond every candidate makes mr Condorcet winner gives upper boundDodgson score mr .top choice v c` left c` , = . case, movingmr order v beyond every candidate gives> mr > c` > B > C1 > > C2 .top choice v right c` , every candidate c A, c` L c L mr .follows Claim 3.7.1 = . case, moving mr order v beyondevery candidate givesmr > > c` > B > C1 > > C2 .cases, use kBk + 1 + kA k switches v. clearly makes mr Condorcetwinner,DodgsonScore(mr ) kBk + 1 + kA k < DodgsonScore(d).q Claim 3.6follows Dodgson winner.q Theorem 3.4claims Theorem 3.4 contrast directly known p2 -completenessgeneral-case Dodgson (Hemaspaandra et al., 1997) strongYoung (Rothe et al., 2003)winner problems, thus reflect substantial complexity simplification holdselectorates single-peaked. section focused election systemsDodgson, Kemeny, Young, natural, important first three electionsystems proven p2 -complete winner problems (for least one strongweak variants). commend reader issue obtaining, electionsystems hard winner problems, reductions winner complexity single-peakedcase.Although Theorem 3.4 winners rather bribery/manipulation/controlprotections, proof good, simple example papers theme single-peakednesstames combinatorial explosions. Taking Dodgson example: general case (notnecessarily single-peaked votes), set paths potentially implement best Dodgsonscores combinatorially explosive (to best current knowledge). contrast,single-peaked case searching paths implement best Dodgson scores turnsrestrict changing two voters particularly simple way yieldspolynomial-sized set options search space.4. Bribery Single-Peaked Electionssection shows single-peakedness undercuts many, although all, NP-hardnessprotections bribery problems.453fiBrandt, Brill, Hemaspaandra, & Hemaspaandra4.1 Notionsbribery notions presented here, except negative approval bribery, paper started complexity-theoretic study bribery (Faliszewski, Hemaspaandra, &Hemaspaandra, 2009). Given election system E, E-bribery problem takes inputC, V , p C, k {0, 1, 2, . . .}, asks if, changing votes k members V , p made winner election respect E. basicbribery problem. modified combination following items. $means voter price (belonging {1, 2, 3, . . .}) question whetherset voters whose total price k changing votesmake p winner. intuition prices voters swayedeasily others. Weighted means vote weight (belonging {1, 2, 3, . . .}),weight w vote bribed indivisible object, applying E, viewedw identical regular votes. intuition weights electionse.g.,stockholdersvoters differing weights.case V consists linear orders, negative mean bribevoter bribe voter must p top choice unless p alreadytop choice bribe.7 intuition negative bribery one tryingstay radar directly helping ones candidate. voting approvalvectors, give definitions capture analog linear-preference negativenotion defined (negative) one one would get taking Faliszewskiet al. (2009) utterly literally (strong negative)see Footnote 7 background.approval-vector votes, negative mean bribe voter,after-bribe vector approve p before-bribe vector approved p.strongnegative mean bribe voter voter bribed cannotapprove p. notions described occur combination, e.g., speakLlull-negative-weighted-$bribery.speak single-peaked case above, mean electoratesingle-peaked, L relative votes single-peaked partinput. Further, bribes must result votes consistent inputsocietal order L. Taking L part input, binding legal bribes,natural bribery analog manipulation model Walsh (2007) Faliszewski et al.(2011). Binding bribes respect L natural, e.g., L widely known, centralauthority may simply reject (as obviously manipulative votes) votes violate L.although core model, many results carry models flexiblepoints, times point outsee Footnote 8, Footnote 9, finalparagraph Section 5.1.7. Faliszewski et al. (2009) definition negative bribery naturally read quitedifferent semantics bribed voter must, bribe, p top choice.Since paper used negative bribery plurality, issue made difference paper,indeed since look negative bribery linear orders mostly respect weakCondorcetsingle-peaked contexts, key issue either. switched definitioncaptures attractive notion: cannot directly boost preferred candidate p top,votes p already top shift remaining preferences. distinctiontwo approaches negative change proofs case approval voting,give separate definitions capture notion.454fiBypassing Combinatorial Protectionsoften speak bribery (or, later, manipulation control) problemsP (or polynomial time). Although formally asserts P algorithmexists say whether successful bribery (or manipulation control) action exists, factevery instance proof show addition obtain actual, successfulbribery (or manipulation control) action one exists. reason worthmentioning that, even context elections, search plausibly harderdecision (Hemaspaandra, Hemaspaandra, & Menton, 2013).4.2 Approval-Bribery Resultsspotlight result approval-bribery, prove bribery protectioncomplexity gives fails single-peaked electorates.Theorem 4.1 (Faliszewski et al., 2009). Approval-bribery NP-complete.Theorem 4.2. Approval-bribery P single-peaked electorates.8prove Theorem 4.2, informally explain key challenge (namely,incomparability) exists regarding proving proof overcomes challenge(namely, using directionality).So, recall approval bribery single-peaked setting, societal order, L,part input voter approves (possibly empty) set candidatescontiguous respect L. Suppose input linear order L c1 L c2 L c3 L L c100respect society single-peaked. Suppose candidate briber tryingmake win c25 . Suppose input limit number people briberbribe 2009 suppose input election 5000 voters 3000 (call V )initially approve c25 2000 (call V+ ) initially approve c25 . Now,clearly, spend 2009 bribes voters V+ , voters alreadyapprove c25 , bribing voter V+ never better bribing voterV . So, goal seek good set 2009 voters V , exists.key challenge, even given single-peakedness, stated word: incomparability. is, given know number approvals c25 go exactly2009 bribe, given know total number approvals candidategets bribe, candidate ci c25 target number niamong 2009 votes choose bribe V , least ni must initiallyapproved ci (in order c25 beat ci bribe).Now, rub. Consider two voters V , one approves c30c55 approves c40 c80 . Among two votes,former helps us address positive ni values 30 39, latter helps usaddress positive ni values 56 80. Since neither voters approval set containsothers, offer differing advantages, neither is, first glance, obviously oneinclude 2009. fact 3000 voters V thicketincomparabilities. Indeed, trying find subset size 2009 (in particular example,8. result holds model L part input model must findL consistent input relative bribery possible. result also holds evenmodelnot core model prove itin bribed voters need respectsocietal order bribed.455fiBrandt, Brill, Hemaspaandra, & Hemaspaandranumber vary input) feels much like covering problem, factexactly path general case proven NP-hard Faliszewski et al.(2009).However, use single-peakedness tame combinatorial challenge choosinggood subset. particular use single-peakedness induce directional attacklocally make incomparability disappear moment need makedecision choosing 2009. (Although focus bribery,construction arguments tailored that, mention line attackmodeled Faliszewski et al., 2011, call smart greedy algorithmsuse study control attacks.) full proof appendix, key ideaeasily conveyed reader kind visualize along us moment.Consider largest ni > 0, (for purpose example) supposestrictly greater 25let us say 93, suppose n93 = 3.must include 2009 least three members V approve c93 .three? Isnt incomparability still problem? No! Since chose largestni > 0, clearly n94 = = n100 = 0. although among voters V approvec93 may incomparability approval ranges, range differences rightc93 utterly irrelevant, c25 already beating candidates anyway.interesting issue is, among voters V approve c93 , leftmost approvedcandidate isthe leftward better help possible ni deficits.direct comparisons take action: put 2009three voters (among V voters initially approve c93 ) whose approval rangeleftmost. (If V lacks three voters approve c93 , since n93 = 3, successful briberyimpossible.) process continues one would expect: Based threevotes, ni values updated next leftmost ni > 0 satisfying 26 similarlyhandled, ni > 0 26 handled, startingend L analogously handle c1 c24 . neutralize ni > 0 within2009 bribes among V , successful bribery, otherwise none possible.concludes example single-peakedness creates directionality tames richcovering problem caused incomparability.fact, example essentially (if one removes particular integer valuesused) complete proof case k kV k. note k kV k,always make p winner bribing voters V , since bribe voters approvep. following proof Theorem 4.2 gives careful exposition process.However, reader comfortable somewhat informal presentation given maywish least initially simply skip following detailed proof.Proof Theorem 4.2. Let (C, V ) instance single-peaked electionsocietal order L given c1 L c2 L L ckCk let k bribe limit.decide whether designated candidate p C made approval winner bribingk voters. Without loss generality, assume bribe, bribedvoters approve p disapprove candidates.Partition multiset V voters multiset V+ voters approve pmultiset V voters disapprove p. k kV k, obviously make pwinner bribing voters V , since bribe voters approve p. (Thecase need bribe voter V+ everybody approves p (i.e., V = ),456fiBypassing Combinatorial Protectionsexists candidate p also approved every voter, wantmake p unique approval winner; case, bribing one arbitrary voter obviouslysuffices.)assume k < kV k. Without loss generality, assume bribeexactly k voters, successful bribe involves k voterssuccessful bribe involves exactly k voters. also argue bribingvoter V+ never profitable bribing voter V . reasonci C {p}, bribing voter V+ lowers quantity number approvalsci number approvals p 1, whereas bribing voter V lowersquantity least 1. Thus assume without loss generality bribevoters V know bribe, p exactly bk = kV+ k + k approvals.candidate ci C {p}, let Vci multiset voters approve cidefine surplus ni ci ni = kVci k bk. order make p winner, bribeleast ni voters Vci V candidates ci positive surplus.Let us first consider candidates right p, i.e., candidates c p L c. orderavoid incomparability problems, start right end L. Let ci rightmostcandidate positive surplus ni > 0. know bribe least nivoters Vci V , question ones. nj 0 j > i, solelyfocus candidates left ci bribe ni voters Vci V whose approvalrange extends furthest left ci . bribe, voters approve p only.thereby achieved ni = 0 clear choice optimal sensechoice would removed greater number approvals candidatesp (ignoring candidates right ci ).update surplus candidates move next rightmost candidate ci0 right p positive surplus. (Observe i0 < j > i,nj initially nonpositive surplus candidate never grows bribing voterapprove p.) repeat procedure candidates right pnonpositive surplus, point mirror societal order repeat wholeprocess, thereby handling candidates c c L p.exceed bribe limit k process, cannot successful briberyaction: choices made algorithm provably least goodchoice would been. If, hand, bribing k 0 k voters sufficesmake surpluses nonpositive, bribe (k k 0 ) additional voters chosen arbitrarilyV (to ensure p bk approvals) thereby found successful briberyaction.q Theorem 4.2general approach used prove Theorem 4.2using directional attacksingle-peaked setting tame incomparability challenges covering problemsestablish following two additional cases NP-hard bribery problems fallP single-peaked case.Theorem 4.3. following hold:99. claim standard model: nonunique-winner model (i.e., ask preferred candidate pmade winner); societal order L given part input; bribed voters must stillrespect L. However, note passing claim still holds choices one make457fiBrandt, Brill, Hemaspaandra, & Hemaspaandra1. Approval-negative-bribery approval-strongnegative-bribery NP-complete.2. single-peaked electorates, approval-negative-bribery approval-strongnegativebribery P.Faliszewski, Hemaspaandra, Hemaspaandra (2011a, see also Faliszewski, Hemaspaandra, & Hemaspaandra, 2011b) observed constructions proofsTheorem 4.2 Theorem 4.3 (part 2) used show results hold evenflexible model logarithmic number voters violatesocietal linear order.4.3 Llull-Bribery Kemeny-Bribery Results: weakCondorcet Consistencystate following eight-case result. membership-in-P claims Theorem 4.4proven direct algorithmic attacks using connection weakCondorcetmedian voters. theorems NP-completeness claims shown reductionsNP-complete problems Knapsack Partition.Theorem 4.4. single-peaked electorates, weakCondorcet-weighted-$bribery, weakCondorcet-negative-weighted-bribery, weakCondorcet-negative-weighted-$briberyNP-complete, remaining five cases (weakCondorcet-bribery, weakCondorcet$bribery, weakCondorcet-weighted-bribery, weakCondorcet-negative-bribery, weakCondorcetnegative-$bribery) P.Theorem 4.4 interesting says weakCondorcet elections,immediate consequences election systems.Corollary 4.5. Let E election system weakCondorcet-consistentmerely weakCondorcet-consistent single-peaked inputs. three NP-completenessfive P results Theorem 4.4 hold (for single-peaked electorates) E.discussions earlier paper, Corollary 4.5 applies Llull, Kemeny,Young, weakDodgson, Maximin, Schwartz, weakBlack, Fishburn, two variantsNanson due Fishburn Schwartz. light this, Corollary 4.5 quietly establishinglarge number claims NP-hardness shields failing single-peaked electorates.example, following claims.Theorem 4.6 (Faliszewski et al., 2009). Llull-bribery, Llull-$bribery, Llull-weighted-bribery,Llull-weighted-$bribery NP-complete.Theorem 4.7 (follows Corollary 4.5). single-peaked electorates: Llull-bribery,Llull-$bribery, Llull-weighted-bribery P Llull-weighted-$bribery NPcomplete.regarding: nonunique-winner model vs. unique-winner model; L part input vs. askingwhether exists valid L respect successful bribery accomplished;bribed voters respect L model vs. model bribed voters may violate L. Seeingresult holds various alternate models requires natural modifications proof cases(e.g., nonunique vs. unique), requires taking advantage specific properties constructioncases (e.g., regarding allowing bribed voters violate L, constructions actually bribevoters end approving zero one candidate, votes consistent every ordering).458fiBypassing Combinatorial Protectionsbest knowledge, bribery Kemeny elections never studied. Note,however, winner problem election system E many-one reduceseight types bribery problems mentioned Theorem 4.4, except weakCondorcetreplaced E. holds ask whether preferred candidate winsgiven bribe limit 0, captures winner problem. So, knownp2 -completeness winner problem Kemeny elections (Hemaspaandra et al., 2005),following result, gives us eight contrasts hardness (threep2 -hardness NP membership five p2 -hardness P membership).Theorem 4.8. Kemeny elections, eight types bribery mentioned Theorem 4.4p2 -hard.Theorem 4.9 (follows Corollary 4.5). single-peaked electorates, Kemeny-weighted$bribery, Kemeny-negative-weighted-bribery, Kemeny-negative-weighted-$bribery NPcomplete (and particular belongs NP). single-peaked electorates,remaining five types bribery Kemeny elections P.final remark regarding Theorem 4.4, note even within single-peakedcases studies, one twist, changing bribery negative briberychanges complexity, namely, single-peaked electorates, weakCondorcet-weightedbribery P weakCondorcet-negative-weighted-bribery NP-complete. Here, decreasing set bribes available briber actually boosts complexitybribers task. (The explanation is, loosely intuitively speaking,among set bribes negativity removes search space set bribesused P-time nonnegative case bribery attack.)5. Control Partition Single-Peaked Electoratescontrol problems elections ask whether various types changes electionsstructure given candidate made winner. (In papers, seeking makecandidate winner structural changes called constructive control distinguishdestructive case trying preclude candidate winning.However, paper always use control constructive sense, unless explicitlymention otherwise.) types control introduced 1992 Bartholdi, Tovey,Trick, (give take slight refinements) studied subsequentpapers, addition/deletion/partition voters/candidates. However, bestknowledge previous study complexity control single-peaked electorates (suchFaliszewski et al., 2011) focused exclusively additions deletions candidatesvoters.first time study complexity partition problems case singlepeaked electorates. show broad range election systems controlpartition voters problem P single-peaked electorates. Among systemsLlull Condorcet elections, whose control partition voters problemknown NP-complete general electorates. proofs work using singlepeakedness tame combinatorial explosionin case, number partitionsmust examined reduced exponential number partitions polynomialnumber classes partitions checked block.459fiBrandt, Brill, Hemaspaandra, & Hemaspaandra5.1 Notionsdefine key types control study: control partitionvoters, control adding voters, control deleting voters.Partition voters models case partitioned electorate primaries.example Faliszewski et al. (2009a) business group powerful manager studiesissue splitting group two task forces (by voting) recommendalternatives part final vote conducted entire group. (loosely)corresponds control partition. Control adding voters loosely models actionstargeted get-out-the-vote drives. Control deleting voters loosely models actionstargeted attempts voter suppression.partition case, two first-round elections second-roundelection, two different approaches candidates move forwardfirst-round election. One Ties Promote (TP) model, winners firstround election move forward. Ties Eliminate (TE) model, which,first-round election, unique winner moves forward unique winnerotherwise one moves forward first-round election. consistency, controldefinitions adopted, often word-for-word, papers Hemaspaandraet al. (2013), Faliszewski et al. (2009a), Faliszewski, Hemaspaandra, Hemaspaandra(2014).Definition 5.1. Let E election system.1. control partition voters problem E, TP TE tie-handling rulemodel, given election (C, V ) candidate p C. partition10V V1 V2 p winner two-stage election winnerselection (C, V1 ) survive tie-handling rule compete winners(C, V2 ) survive tie-handling rule? two first-round onesecond-round elections conducted using election system E.112. control adding voters problem E given set candidates C,two collections voters, V (often referred collection registered voters)W (often referred collection unregistered voters), preferencesC, candidate p C, nonnegative integer K. ask whethersubcollection W 0 W (a) kW 0 k K, (b) p winner E election(C, V W 0 ).3. control deleting voters problem E given election (C, V ),candidate p C, nonnegative integer K. ask whether collectionV 0 voters obtained V deleting K voters pwinner E election (C, V 0 ).10. partition collection pair collections (A1 , A2 ) A1 A2 = A1 A2 = ;since different voters preferences, multiset operations.11. important note definition draw it, speak election,(C 0 , V 0 ), always implicitly mean vote V 0 passed election systemversion restricted candidates C 0 . particular, relevant second-roundelection here.460fiBypassing Combinatorial Protectionsthree definitions called nonunique-winner model,namely, question is: p made winner final election? Another modelstudied literature called unique-winner model,questions replaced with: p made uniquely win final election?find natural study TP, nonunique-winner model. (TP nonunique-winnerpair naturally, TE unique-winner.) contrast, seminal control paperBartholdi et al. (1992) used unique-winner model. clear broad possiblemodels results hold in, checked results holdfour model combinations (i.e., TP unique-winner, TP nonunique winner, TEunique-winner, TE nonunique-winner).speak control problem single-peaked electorates, meansocietal order L part input. mean single-peakedness must holdentire input (including potentially added candidates voters). However,control, turns just-mentioned model polynomial-time membership holdspolynomial-time membership holds model one given Lpart input rather one asked whether exists linear order L relativeinput (as before, even including potentially added candidates voters)single-peaked goal achieved given control action.claim formalized Theorem A.5 proven appendix. light Theorem A.5,simply assume control results default model (societal order partinput).5.2 Control Results Related weakCondorcet Electionssection present control results, focus control partition voters. see although Llull Condorcet elections NP-hard voter-partitioncontrol problems, problems fall polynomial time single-peaked electorates.spotlight result section states partition-by-voters control weakCondorcetelections P.Theorem 5.2. weakCondorcet elections, control partition voters P singlepeaked electorates, nonunique-winner model unique-winner model,Ties Promote model Ties Eliminate model.giving Theorem 5.2s proof, let us note consequences contrasts.Corollary 5.3. Let E election system weakCondorcet-consistent singlepeaked inputs. election system E, control partition voters P singlepeaked electorates, nonunique-winner model unique-winner model,Ties Promote model Ties Eliminate model. particular, holdselection systems Llull, Kemeny, Young, weakDodgson, Maximin, Schwartz, weakBlack,Fishburn, two variants Nanson due Fishburn Schwartz.Llull elections, provides clear contrast known NP-completenesscontrol type general case.Theorem 5.4 (Faliszewski et al., 2009a). Llull elections, control partition votersNP-complete, nonunique-winner model unique-winner model,Ties Promote model Ties Eliminate model.461fiBrandt, Brill, Hemaspaandra, & HemaspaandraAlgorithm 2 weakCondorcet Control Partition Voters1: a, b, c, C L b, c L d, L c, p weakCondorcet winner(C 0 , V ) C 0 = {e C | L e L b c L e L d}2:k {0, 1, 2, . . . , kV k}3:let r number interesting regionsP4:` = (`1 , `2 , . . . , `r ) Nr ri=1 `i = k5:define P` set partitions (V1 , V2 ) i, `inumber voters V1 whose top choice Ri6:P` 6=7:let (V1 , V2 ) arbitrary partition P`8:set weakCondorcet winners (C, V1 ) equals [a, b]set weakCondorcet winners (C, V2 ) equals [c, d]9:return (V1 , V2 )10: return partition voters makes p weakCondorcet winnerturn proof Theorem 5.2. idea behind proof differs completelyapproach used polynomial-time control proofs Faliszewski et al. (2011),is, think, novel.Proof Theorem 5.2. Let (C, V ) election L linear order C respectelectorate single-peaked. decide whether designated candidatep C made overall winner partitioning set voters appropriateway.algorithm tailored natural Ties Promote, nonunique-winner model,end proof mention adapted models.natural model, want find partition (V1 , V2 ) p weakCondorcet winnerelection (C 0 , V ) C 0 union weakCondorcet winners (C, V1 )(C, V2 ).show Algorithm 2 returns partition property whenever one exists.Algorithm 2 loops 4-tuples a, b, c, candidates tests whether voterspartitioned (V1 , V2 ) way (a) weakCondorcet winners (C, V1 )[a, b] (i.e., candidates {x C | L x L b}, writing L z (y = z L z)),(b) weakCondorcet winners (C, V2 ) [c, d], (c) p weakCondorcet winner([a, b] [c, d], V ).4-tuple a, b, c, d, divide set C candidates disjoint interestingregions. Regions defined follows. candidates a, b, c, constitutesregion itself. Furthermore, contiguous (with respect L) interval twofour candidates region. Finally, two additional regions, namely oneinterval consisting candidates left a, b, c, one interval consistingcandidates right a, b, c, d.Note intervals containing a, b, c, may empty,set {a, b, c, d} may contain adjacent even identical candidates. easy seenumber interesting (i.e., nonempty) regions nine, equal nineadjacent identical candidates among a, b, c, d. Assuming462fiBypassing Combinatorial Protectionscase, three possible situations, depending relation intervals[a, b] [c, d].1. intervals disjoint:R1R2cbR3R4R5R6R7R8R92. intervals nonempty intersection, neither contains other:R1R2cR3R4bR5R6R73. One interval contains other:cR1R2R3R4R5R6R8R9bR7R8R9set {a, b, c, d} contains adjacent identical elements, regions picturedempty identical, less nine interesting regions.r interesting regions, denote R1 , . . . , Rr , left rightrespect L.Associate voter candidate top voters preference order.following observation turns helpful. [a, b] set weakCondorcet winners(C, V1 ), voters V1 top choice x <L x <L b.Similarly, voter V2 top choice strictly c d. is, regionconsists voters whose top choice lies strictly either b c fullydetermined regard question many voters V1 V2 . example,case [c, d] contained [a, b], five nine regions fully determined:voters R3 , R4 , R6 , R7 V2 must votersregion R5 , voters would lie b c d.argument, one see maximum number regions fully determined7 (in case intervals [a, b] [c, d] disjoint). Clearly, numberways kV k divided 7 ordered numbers bounded kV k6 .fact weakCondorcet winners (C, V1 ) (C, V2 ) efficiently checkeddue following key observation. Within region, thing affectswinner set number voters put V1 , voters use achievenumber. is, need check partition individually (thereexponential number them), rather deal large number partitions simultaneously. formally, suppose r interesting regions let ` = (`1 , `2 , . . . , `r )463fiBrandt, Brill, Hemaspaandra, & Hemaspaandrar-dimensional vector natural numbers. define P` set partitions(V1 , V2 ) V i, `i number voters V1 whose top choiceRi .P` 6= , key observation restated follows. [a, b] setweakCondorcet winners election (C, V1 ) (V1 , V2 ) P` [a, b]set weakCondorcet winners every election (C, V1 ) (V1 , V2 ) P` . is,want check whether [a, b] set weakCondorcet winners primaryelections (C, V1 ) induced partitions (V1 , V2 ) P` , suffices check oneobtain answer. check easily done counting. symmetry,statement holds [c, d] weakCondorcet winners elections (C, V2 )(all four combinations).reason true that, given number voters region, easyrecognize region(s) median voter(s) (just counting). Since a, b, c,constitute region own, equally easy tell whether median voterfour candidates top choice.Implementing idea, algorithm loops possible sizes k V1 (line 2)possibilities k divided r numbers `1 , `2 , . . . , `r , checks (line 8)gives partition required. argued last paragraphs, queryefficiently answered.running time Algorithm 2 thus bounded follows. numberiterations loops lines 1, 2, 4, bounded kCk4 , kV k + 1, kV k6 ,respectively. Moreover, shown queries line 8 answeredpolynomial time. Altogether, yields running time obviously polynomialsize input.Correctness Algorithm 2 clear explanations above: findpartition makes p overall weakCondorcet winner partitionexists. particular, observe setting k = 0 line 2 handles case palready weakCondorcet winner original election.12 Note algorithms themeperfectly supports theme paper: algorithm used single-peakedness bypasscombinatorial richness partitions.completes proof TP, nonunique-winner model. TP, uniquewinner model, line 1 Algorithm 2 needs adapted loop choicesa, b, c, make p unique weakCondorcet winner (C 0 , V ). TE, unique-winnermodel dealt Theorem 5.6 page 465. (By Fact 3.1 page 448,unique weakCondorcet winner tantamount Condorcet winner single-peakedelectorates.)true TE, nonunique-winner model. Here, weakCondorcetwinner final election suffices, Algorithm 3 (which found appendix)easily adapted take consideration.q Theorem 5.212. see this, assume p [m` , mr ], [m` , mr ] interval weakCondorcet winners(C, V ). Observe set a, b, c, [a, b] = C [c, d] = [m` , mr ], C 0 = {e C |L e L b c L e L d} = C obviously p weakCondorcet winner (C 0 , V ). Thus,choice a, b, c, considered line 1. setting k 0 uniquely defines ` (0, . . . , 0) P`consists partition (, V ) only. Due choice a, b, c, d, answer query line 8yes (, V ) correctly output partition makes p overall winner.464fiBypassing Combinatorial Protectionsturn weakCondorcet Condorcet elections, state resultquickly give us number additional contrasts general-case control complexitysingle-peaked control complexity.Theorem 5.5. weakCondorcet elections, control adding voters control deleting voters P single-peaked electorates, nonunique-winner modelunique-winner model.usual, immediately follows result applies standard longlist systems (e.g., Kemeny, Young, weakDodgson elections) weakCondorcetconsistent single-peaked electorates. appendix contains similar results Condorcetelections. However, winner problem general case trivially many-one polynomialtime reduces control adding voters (via asking p made win adding 0voters; see Hemaspaandra et al., 2009, Section 2.4). Thus, existing p2 -hardness resultsKemeny winner problem (both nonunique-winner model, Hemaspaandra et al.,2005, unique-winner model, Hemaspaandra et al., 2009), Young winnerproblem (both nonunique-winner model unique-winner model, seepapers Theorem A.2), weakDodgson winner problem (both nonunique-winnermodel unique-winner model, see papers Theorem A.4), implycontrol adding voters p2 -hard Kemeny, Young, weakDodgson elections(in nonunique-winner model unique-winner model). commentshold control deleting voters. Thus single-peaked general cases controladding deleting voters differ Kemeny, Young, weakDodgson elections.5.3 Control Results Related Condorcet ElectionsControl Condorcet elections studied much detail (Bartholdi et al., 1992;Hemaspaandra, Hemaspaandra, & Rothe, 2007), (see Table 1 Hemaspaandra et al.,2007) standard control type known either never change outcomepolynomial-time algorithm, three exceptions. Namely, Bartholdi et al.(1992) proved seminal paper control, control addition voters controldeletion voters NP-complete Condorcet elections; control partitionvoters also NP-complete Condorcet elections (due Bartholdi et al., 1992, nownonstandard partition model, due Faliszewski et al., 2009a, now-standardpartition model).13 However, following results show resistance results vanishsingle-peaked electorates.Theorem 5.6. Condorcet elections, control partition voters P singlepeaked electorates, nonunique-winner model unique-winner model,Ties Promote model Ties Eliminate model (note four casescoincide here).13. entire Bartholdi, Tovey, Trick paper unique-winner model, discussion unique-winner model. thus need establish contrasting polynomial-timeresults unique-winner model want meaningful contrast. address this, ensurecontrasting results hold models. holds trivially prove either model,Condorcet elections, nonunique-winner unique-winner coincide Ties Promote TiesEliminate coincideboth one never two winners.465fiBrandt, Brill, Hemaspaandra, & HemaspaandraTheorem 5.7. Condorcet elections, control adding voters control deletingvoters P single-peaked electorates, nonunique-winner modelunique-winner model.So, standard control cases Condorcet voting known NP-hardgeneral case (Bartholdi et al., 1992; Faliszewski et al., 2009a), shownCondorcet-voting control falls polynomial time single-peaked electorates.146. Manipulation Single-Peaked Electorates: DichotomyConstructive Coalition Weighted ManipulationFaliszewski et al. (2011) completely characterized, three-candidate elections, scoring protocols polynomial-time constructive coalition weighted manipulation problemsNP-complete constructive coalition weighted manipulation problems.achieve far sweeping dichotomy theoremour result applies scoring protocols,regardless number candidates. Scoring protocols arguably importantbroad class election systems.constructive coalition weighted manipulation problem, input candidateset C, nonmanipulative voters (each preference order C weight),manipulative voters (each weight), candidate p C, questionwhether way setting preferences manipulative voters pwinner given election rule manipulative nonmanipulative votersvote weighted election.Theorem 6.1 (Faliszewski et al., 2011). Consider three-candidate scoring protocol,namely, = (1 , 2 , 3 ), 1 2 3 , 1 N, 2 N, 3 N. single-peaked case,constructive coalition weighted manipulation problem (in nonunique-winnermodel unique-winner model) NP-complete 1 3 > 2(2 3 ) > 0polynomial time otherwise.extension three-candidate, single-peaked electorate result casescoring protocol single-peaked electorates somewhat complicated. Yet, sincecomplete characterizationa dichotomization complexities, factitsense simply reflecting subtlety complexity scoring systems. (For generali.e., necessarily single-peakedcase, known characterization simple regardlessnumber candidates: NP-completeness holds kCk 2 2 6= kCkotherwise problem P (Hemaspaandra & Hemaspaandra, 2007, see also Conitzer,Sandholm, Lang, 2007, Procaccia Rosenschein, 2007.) following theoremsections soleand spotlightresult.Theorem 6.2. Consider m-candidate scoring protocol, namely, = (1 , 2 , . . . , )Nm , 1 2 .14. sharp-eyed reader may wonder whether concept possible general-casepolynomial-time results control (e.g., Condorcet control deleting candidates) might suddenly,freakishly get harder single-peaked case. all, Faliszewski et al. (2011) show freakish caselimiting single-peaked case increases manipulation complexity. However, hardseeby reasoning related used prove Theorem A.5that control type polynomialtime general case single-peaked case remains polynomial time.466fiBypassing Combinatorial Protections2 2 > b m1 c+2 exist integers i, j > 1 + j + 12(1 )(1 j ) > (i i+1 )(j j+1 ), constructive coalition weightedmanipulation problem single-peaked case NP-complete.2 2 = b m1 c+2 1 > 2 > (2 > m1 1 >22(2 )), constructive coalition weighted manipulation problemsingle-peaked case NP-complete.cases, constructive coalition weighted manipulation problemsingle-peaked case P.example, constructive coalition weighted manipulation single-peaked casem-candidate plurality m-candidate veto P, m-candidate BordaP 3 NP-complete otherwise.Note Theorem 6.1 follows Theorem 6.2, since 1 3 > 2(2 3 ) equivalent1 2 > 2 3 . also note specific cases more-than-three-candidatescoring protocolssuch four-candidate Borda m-candidate vetothat analyzedsingle-peaked case Faliszewski et al. (2011) yielded results completely consistentTheorem 6.2s characterization. P cases Theorem 6.2s dichotomy aligntheme single-peakedness often foiling combinatorial protections.Proof Theorem 6.2. first give intuition conditions theorem.P cases exactly cases optimal manipulator vote. example,show Lemma 6.6 (1 )(1 j ) (i i+1 )(j j+1 ) i, j > 1+ j + 1, candidates scoring higher p one side p,say left, societal order. case optimal manipulators rankp first, candidates ps right, candidates ps left.contrast, NP-complete cases exists societal orderconstruct elections p two main rivals, say b, two differenttypes optimal votes manipulators different effects scoresb. NP-hardness proofs follow via reductions well-known NP-completeproblem Partition (see, e.g., Garey Johnson, 1979). problem, givennonempty collection (k1 , . . . , kn ) positive integers sum 2K, ask whetherexists subcollection k1 , . . . , kn sums K. cases carefullydefine societal order, weights votes nonmanipulators, weightsmanipulators weights manipulators voting one twooptimal vote types successful manipulation correspond partition vice versa.turn formal proof theorem. 1, problem trivialthus P. So, assume 2. split proof Theorem 6.2 three lemmas:2 > b m1 c+2 NP-complete cases (Lemma 6.4), 2 > b m1 c+2 P cases (follow22Lemma 6.6), 2 = b m1 c+2 cases (Lemma 6.7).2proof, use following notation. V collection voters c candidate,scoreV (c) denotes score c V , i.e., number points c receivesvoters V . V clear context, simply write score(c). section,usually denote collection nonmanipulators collection manipulators.First prove following simple lemma.467fiBrandt, Brill, Hemaspaandra, & HemaspaandraLemma 6.3. constructive coalition weighted manipulation problem singlepeaked case scoring protocols, p made winner, p made winnermanipulation manipulators rank p first.Proof Lemma 6.3. Let > p > b1 > > b` single-peaked vote,set candidates order. exists orderingp > > b1 > > b` also single-peaked. Note new vote, every candidatec, score(p) score(c) decrease. So, p winner election, p stillwinner replace every single-peaked vote form > p > b1 > > b`single-peaked vote form p > > b1 > > b` .q Lemma 6.3Lemma 6.4. Let = (1 , 2 , . . . , ) scoring protocol 2 2 >b m1 c+2 . exist integers i1 , i2 > 1 i1 +i2 m+1 (1 i1 )(1 i2 ) >2(i1 i1 +1 )(i2 i2 +1 ), constructive coalition weighted manipulation problemsingle-peaked case NP-complete.Proof Lemma 6.4. Let i1 , i2 integers fulfill conditions lemmai1 i2 i2 minimal, i.e., 1 < i1 i2 , i1 + i2 + 1, (1 i1 )(1 i2 ) >(i1 i1 +1 )(i2 i2 +1 ), i01 , i02 1 < i01 i02 < i2 i01 + i02 + 1,holds (1 i01 )(1 i02 ) (i01 i01 +1 )(i02 i02 +1 ).reduce Partition constructive coalition weighted manipulationproblem single-peaked electorates. Let (k1 , . . . , kn ) instance Partition, i.e.,(k1 , . . . , kn ) nonempty collection positive integers sum 2K. Let societysorderam1 L L a1 L p L b1 L L bm2 ,m2 = max(d m12 e, i2 1) m1 = m2 1. Note i2 m2 + 1. Sincei1 +i2 m+1, follows immediately i1 m1 +1. Also note 1 m1 m2 m2.make reduction work, also need following claim.Claim 6.5. m1 +2 < 2 .Proof Claim 6.5.m1 = b m12 c, immediate, since 2 > b m1 c+2 . not,2m2 = i2 1 i2 1 > m12 e 2. Since i2 minimal, conditions lemmafulfilled i1 = i2 = 2, (1 2 ) (2 3 ). 2 = m1 +2 ,2 = 3 , follows 1 = 2 thus 1 = m1 +2 . choice i1 , i2fulfill conditions lemma, since 1 i1 = 0.q Claim 6.5Let consist two voters, one voter weight `1 preference ordera1 > > ai1 1 > p > b1 >(the end vote denotes remaining candidates listed arbitrary,single-peaked order) one voter weight `2 preference orderb1 > > bi2 1 > p > a1 > ,468fiBypassing Combinatorial Protectionslet weights k1 , k2 , . . . , kn ,= (1 i1 )(1 i2 ) (i1 i1 +1 )(i2 i2 +1 ),`1 = ((21 2 m2 +2 )(1 i2 ) + (i2 i2 +1 )(21 2 m1 +2 ))K,`2 = ((1 i1 )(21 2 m1 +2 ) + (i1 i1 +1 )(21 2 m2 +2 ))K.values chosen (using Cramers Rule)(1 i1 )`1 (i2 i2 +1 )`2 = (21 2 m2 +2 )K(i1 i1 +1 )`1 + (1 i2 )`2 = (21 2 m1 +2 )K.Note positive, since (1 i1 )(1 i2 ) > (i1 i1 +1 )(i2 i2 +1 ). Note`1 `2 also positive, since (1 i1 ) (1 i2 ) positive,(21 2 m1 +2 ) (21 2 m2 +2 ), Claim 6.5 fact m1 m2 .prove reduction works, first suppose k1 , . . . , kn partition, i.e.,subcollection k1 , . . . , kn sums K. show p made winnerfollows. Let K weight votep > a1 > > am1 > b1 >let K weight votep > b1 > > bm2 > a1 > .Note i, 1 m1 , score(ai ) score(a1 ) i, 1 m2 ,score(bi ) score(b1 ) suffices show score(a1 ) score(p) score(b1 )score(p). Notescore(p) = i1 `1 + i2 `2 + 21 K,score(a1 ) = 1 `1 + i2 +1 `2 + 2 K + m2 +2 K,score(b1 ) = 1 `2 + i1 +1 `1 + 2 K + m1 +2 K.choice , `1 , `2 , follows score(a1 ) = score(p) score(b1 ) = score(p).converse, suppose voters vote p becomes winner. observations above, followsscoreT (a1 ) (2 + m2 +2 )KscoreT (b1 ) (2 + m1 +2 )K.Lemma 6.3 assume p ranked first every voter . impliesevery voter ranks a1 b1 second. Let Wa total weight voters ranka1 second. followsscoreT (a1 ) 2 Wa + m2 +2 (2K Wa )scoreT (b1 ) 2 (2K Wa ) + m1 +2 Wa .observations, fact > 0 2 > m1 +2 (by Claim 6.5) (andthus also 2 > m2 +2 ), follows Wa K (2K Wa ) K. So, exactlyhalf vote weight ranks a1 second. weights voters ranka1 second correspond partition.q Lemma 6.4469fiBrandt, Brill, Hemaspaandra, & HemaspaandraLemma 6.6. Let = (1 , 2 , . . . , ) scoring protocol. i, j > 1+ j + 1, holds(1 )(1 j ) (i i+1 )(j j+1 ),constructive coalition weighted manipulation problem single-peaked caseP.Proof Lemma 6.6. Let am1 L L a1 L p L b1 L L bm2 societys order.immediate scoreS (ai ) scoreS (p) i, 1 m1 , p made winnerp winner every voter votesp > a1 > > am1 > b1 > > bm2 .Similarly, scoreS (bi ) scoreS (p) i, 1 m2 , p made winnerp winner every voter votesp > b1 > > bm2 > a1 > > am1 .show cases occur. immediately impliesLemma 6.6.So, remainder proof, suppose contradiction collectionvoters integers i1 i2 1 i1 m1 , 1 i2 m2 , scoreS (ai1 ) > scoreS (p),scoreS (bi2 ) > scoreS (p).1 < m1 +1, let `i total weight voters rank candidate{a1 , . . . , am1 } first rank p ith place. Note voters rank candidates{b1 , . . . , bm2 } p. 1 < m2 + 1, let `0i total weight votersrank candidate {b1 , . . . , bm2 } first rank p ith place. Notevoters rank candidates {a1 , . . . , am1 } p. follows immediatelyscoreS (ai1 ) scoreS (p)X(1 )`i +1<im1 +1scoreS (bi2 ) scoreS (p)XX(i+1 )`0i1<im2 +1(1)`0i+1<im2 +1X(i+1 )`i .1<im1 +1Since scoreS (ai1 ) > scoreS (p) scoreS (bi2 ) > scoreS (p), followsX1<im1 +1XX(1 )`i >(11<im2 +1(i i+1 )`0i1<im2 +1)`0iX>(i i+1 )`i .1<im1 +1Since sides inequalities nonnegative, followsXX(1 )`i(1 )`0i >1<im1 +11<im2 +1470fiBypassing Combinatorial ProtectionsX(i i+1 )`0i1<im2 +1(i i+1 )`i .1<im1 +1Multiplying out, followsX(1 )(1 j )`i `0j >1<im1 +11<jm2 +1XX(i i+1 )(j j+1 )`i `0j .1<im1 +11<jm2 +1Since = m1 + m2 + 1, contradicts assumption i, j > 1+ j + 1 holds(1 )(1 j ) (i i+1 )(j j+1 ).q Lemma 6.6Lemma 6.6 handles 2 > b m1 c+2 P cases Theorem 6.2. Note lemma2limited use 2 = b m1 c+2 , since case lemma applies = 2 1 = 2 =2b m1 c+2 . 2 = b m1 c+2 cases Theorem 6.2 handled following lemma22combination standard observation scoring protocol (1 , 2 , . . . , )behavior scoring protocol (1 , 2 , . . . , m1 , 0).Lemma 6.7. Let = (1 , 2 , . . . , ) scoring protocol 2, = 0,2 = b m1 c+2 . 2 = 0 1 = 2 (2 = m1 1 22 ) constructive2coalition weighted manipulation problem single-peaked case P; otherwise,NP-complete.Proof Lemma 6.7. 2 = 0, vote form p > optimalmanipulator vote. 1 = 2 , 1 = b m1 c+2 . Let j i, j > 12m1+ j + 1. min(i, j) b m+12 c = b 2 c + 1 (1 )(1 j ) = 0.follows Lemma 6.6 case P.remainder proof, assume 1 > 2 > 0.consider case 2 = m1 1 22 . Consider societys order. pleftmost rightmost candidate, exactly one vote puts p first,optimal manipulator vote. Otherwise, let leftmost candidate societysorder, b rightmost. b candidates occur lastvote. Since 1 22 , follows scoreS (a) + scoreS (b) 2scoreS (p). Without lossgenerality, let scoreS (a) scoreS (b). scoreS (a) scoreS (p) vote formp > > b optimal manipulator vote.concludes P cases. turn NP-complete cases. cases,reduce Partition.First assume 2 = m1 1 > 22 . Let k1 , . . . , kn nonemptycollection positive integers sum 2K. construct following election: Societysorder L p L L b. consists two voters, weight (21 2 )K. Onevoter votes > p > > b voter votes b > > p > a. Notecandidates c 6 {a, b}, scoreS (c) = scoreS (p). weights manipulators(1 22 )k1 , . . . , (1 22 )kn . proof correctness reduction similar471fiBrandt, Brill, Hemaspaandra, & Hemaspaandra(but easier than) corresponding proof Lemma 6.4. First suppose existssubcollection k1 , . . . , kn sums K. set K vote weight p > > > bK vote weight p > > b > a. Note resulting election,score(p) = (22 (21 2 ) + 21 (1 22 ))K = (212 222 )Kscore(a) = score(b) = (1 (21 2 ) + 2 (1 22 ))K = (212 222 )K.converse, suppose p made winner. observations above,immediatescoreT (a) 2 (1 22 )K scoreT (b) 2 (1 22 )K.Let Wa total weight voters rank b last. followsscoreT (a) 2 Wa scoreT (b) (2(1 22 )K Wa )2 .observations, assumption 2 > 0, follows Wa = (1 22 )K.So, exactly half vote weight ranks b last. weights votersrank b last correspond partition.Finally, handle last case, namely, 1 > 2 > m1 . Letb smallest indexm1c+2<b<m.Takesocietysorder2 >.Notebb2ab m1 c L L a1 L p L b1 L L bd m1 e .22reducing Partition. Let k1 , . . . , kn nonempty collection positiveintegers sum 2K. Let consist two voters, weight (21 2b )K,votingab m1 c(mm)b > > a1 > p > b1 > > bd m1 e(mm)b >22bd m1 e(mm)b > > b1 > p > a1 > > ab m1 c(mm)b >22let weights (1 2 )k1 , . . . , (1 2 )kn . Since b m1b =mb2 c (m m)m1m1m1(d m1e+1)m(bbc+2)>0bc(mm)+1+dbe(mm)b=2mmb<m,b2222following scores.scoreS (p) = 22 (21 2b )K,scoreS (ab m1 c(mm)b )K,b ) = (1 + 2 )(21 22scoreS (bd m1 e(mm)b ) = scoreS (ab m1 c(mm)b ).22k1 , . . . , kn partition, set (1 2 )K vote weightp > a1 > > ab m1 c > b1 > > bd m1 e(mm)b >22set (1 2 )K vote weightp > b1 > > bd m1 e > a1 > > ab m1 c(mm)b > .22472fiBypassing Combinatorial ProtectionsNote ab m1 c(mm)b bd m1e(mm)b candidates score higher22p22score(p) = (22 (21 2b ) + 21 (1 2 ))K = (21 + 21 2 22b 22 )K.score(ad m1 e(mm)b ) = score(bd m1 e(mm)b )=2222((1 + 2 )(21 2b ) + (2 +b )(1 2 ))K = (21 + 21 2 22b 22 )K.So, p winner resulting election.converse, suppose p made winner. Assume (using Lemma 6.3)p ranked first every manipulator. observations above, immediatescoreT (ab m1 c(mm)b )(1 2 )b ) (2 +2scoreT (bd m1 e(mm)b )(1 2 ).b ) (2 +2Let Wa total weight voters ab m1 c(mm)b > bd m1e(mm)b .22followsscoreT (ab m1 c(mm)b (2(1 2 )K Wa )b ) 2 Wa +2scoreT (bd m1 e(mm)b Wa + 2 (2(1 2 )K Wa ).b )2observations, fact 2 > , follows Wa = (1 2 )K.weights voters ab m1 c(mm)b > bd m1e(mm)b correspond22partition.q Lemma 6.7qTheorem 6.27. Related Work, Additional Discussion, Open Problemstwo papers related work Walsh (2007) Faliszewski, Hemaspaandra, Hemaspaandra, Rothe (2011). Walshs paper first raised (among manyinteresting issues, possible necessary winners, Konczak & Lang, 2005, singlepeaked settings) issue effect single-peaked electorates manipulation.particular case looked atweighted coalition manipulation single transferable vote electionshe showed manipulation remains hard even single-peaked electorates. Faliszewski et al. showed cases single-peakedness removes complexity shieldsmanipulation, also opened study (nonpartition) control. papercontrast Walshs stresses cases single-peakedness removes combinatorial protections. go beyond Faliszewski et al. (2011) first time studying briberysingle-peaked electorates partition-control single-peaked electorates.new cases, show many election systems (for example Llull elections)polynomial-time algorithms single-peaked electorates, even system knownNP-hard analogous general case. also generalize Faliszewski et al. (2011)473fiBrandt, Brill, Hemaspaandra, & Hemaspaandradichotomy theorem manipulation three-candidate scoring protocols casearbitrary scoring protocols.Although closely related Faliszewski et al. (2011) present paper,came present paper, important mention work Faliszewskiet al. (2011b, 2014) explores interesting issue seeing whether resultsFaliszewski et al. (2011) still hold even electorate merely nearsingle-peaked (see also Cornaz et al., 2012; Bredereck et al., 2013; Erdelyi et al., 2013; Suiet al., 2013, regarding nearness single-peakedness weaker forms single-peakedness).Since large real-world electorates unlikely (perfectly) single-peaked, naturalimportant study weaker forms single-peakedness.Although Walsh (2007) Faliszewski et al. (2011) far related work,work much worth mentioning. Bartholdi Trick (1986), Doignon Falmagne(1994), Escoffier et al. (2008) provided efficient algorithms finding single-peakedorderings. Conitzer (2009) studied effect single-peaked electorates preferenceelicitation. Indeed, single-peakedness much current interest computational settings.example, least four papers IJCAI-2013 conference, including Brederecket al. (2013) paper mentioned related single-peakedness.p2 -completeness winner problems Dodgson, Kemeny, strongYoungelections established, respectively, Hemaspaandra et al. (1997), Hemaspaandra et al.(2005), Rothe et al. (2003). literature contains many papers complexity(when single-peaked preferences assumed) manipulation control (as pointerthose, see Faliszewski et al., 2009b, Faliszewski, Hemaspaandra, & Hemaspaandra, 2010, citations therein), even contains number papersyounger topic complexity bribery (e.g., Faliszewski et al., 2009; Faliszewski, 2008;Faliszewski et al., 2009a). Although nonunique-winner model unique-winnermodel typically complexity results, Faliszewski, Hemaspaandra,Schnoor (2008, drawing also Conitzer et al., 2007) show always case.NP-completeness p2 -completeness worst-case notions. natural wonderwhether problems classes solved frequently heuristic algorithms.much experimental study theme (see, e.g., Walsh, 2009).hand, known (see Hemaspaandra Williams, 2012) polynomial-time deterministic heuristic algorithm NP-complete (or p2 -complete) problem asymptoticallymakes subexponentially many errors, polynomial hierarchy collapses.worry comes immediate minds social choice theorists expressedfollows: Since known that, single-peaked electorates, median voting leaves votersvoting sincerely optimal strategy, single-peaked elections interestingterms election systems, since median voting used. detailed discussionworry would fill paper. briefly mention three reasonsobjection serious might first seem. First, nonmanipulability claimsregarding single-peaked elections median voting manipulability, saynothing about, example, control. Indeed, weakCondorcet effect typemedian voting single-peaked electorates, example partition votersalgorithm makes clear control exercised interesting ways.15 Second, even15. explicit, natural way framing median voting, median voting weakCondorcet (and weakCondorcet-consistent rules) exactly single-peaked electorates.474fiBypassing Combinatorial Protectionsmedian voting nice properties, simple truth real world, societyvirtually elections electorateshas chosen (perhaps due transparency, comfort,tradition) use voting systems clash sharply median voting. prominenceplurality voting dramatic case. since real world userich range election systems, make sense understand behavior. Third, onemust careful terms strategy-proof. paper people commonlymention showing median voting strategy-proof Barbera (2001).papers results social choice functions (election rules kCk 1 alwaysexactly one winner), notas paper isabout election rules select setwinners. one cannot simply assume case median voting (say, weakCondorcetelections) never gives incentive misrepresent preferences.Actually, certain problem settings, one never incentive misrepresent onestop choice (in single-peaked weakCondorcet elections ones top choice affectsoutcome) weakCondorcet elections (which social choice correspondence).example, ones goal Seek make top choice weakCondorcet winner,one never incentive misstate ones top choice. another example, onesgoal (for fixed k) Seek make least one first k choices amongweakCondorcet winners, one never incentive misstate ones topchoice (which thing matters ones vote).16 hand,reasonable problem settings, misstating may make sense. ones goal Maketop choice unique winner failing make second choice unique winner... failing make last choice unique winner failing makemultiple winners, two-candidate single-peaked election voter 1 votes > bvoter 2 prefers b already gives voter 2 incentive vote, insincerely, > b.leaving topic, stress previous paragraphs discussionsmodel manipulators come complete preference orders. However,Bartholdi et al. (1989) model (which paper complexity papers usestudying manipulation), manipulative coalition blank slate goalmake certain candidate p winner.open issue already mentioned paper following. Section 6 providedsingle-peaked electorates manipulation-complexity dichotomy applies scoringrules (and see Hemaspaandra & Hemaspaandra, 2007, holds without singlepeaked restriction). Although broad set rules, theorem connectingspecification system systems complexitya natural connection. However,paper establishes many results regarding bribery control weakCondorcet contextsingle-peaked electorates.16. mention passing two incentive manipulate claims made weakCondorcetelections single-peaked electorates also hold family related election systems single-peakedelectorates. weakCondorcet, sorting voters first choice (under single-peaked orderingcandidates), candidates fall median voter(s) winners. thinkMedianVoting 1 , rational , 0 12 , single-peaked voting2consider rule, MedianVoting , ordering voters first-choice makes winnerscandidates societal order L fall inclusive interval (a) leftmost voter vleftleast kV ke voters first preference vleft left Lvleft , (b) rightmost voter vright least kV ke voters first preferencevright right L vright . rule MedianVoting share incentivemanipulate properties mentioned text.475fiBrandt, Brill, Hemaspaandra, & Hemaspaandraalso natural wonder whether one tightly link social-choice-favored propertiesrule manipulation (or bribery control) complexity. give idea kindtheorem thinking of, mention following known theorem linking social-choiceproperties winner-problem complexity (the statement involves notionsdefine here): Every election system neutral, Condorcet-consistent, consistentp2 -complete winner problem (Hemaspaandra et al., 2005, see also discussionHemaspaandra Hemaspaandra, 2000). However, just-quoted winner resultsomething cheat one system satisfies propertiesKemenyelections. dream case manipulationand bribery controlwould findbroad link social-choice properties complexity single-peaked casegeneral case. true dream case, might completely characterize termsstatement social-choice properties election systems easy manipulation(or bribery control) problems, single-peaked case general case.final open direction find cases partition-of-candidates control shiftsNP-hard polynomial time restricted single-peaked electorates.8. Conclusionstheme paper single-peaked electorates often tame combinatorial explosion.saw first case winner problem. case, taming good.shows single-peaked electorates, election systems Kemeny efficientwinner algorithms, despite p2 -hardness general case. briberycontrol (and part, manipulation), saw many cases NP-hard problems fellpolynomial time single-peaked electorates, via algorithms bypassed generalcase combinatorial explosions covers partitions. Since NP-hardness resultsprotections attacks elections, results serve warningprotections core dependent extreme flexibility voter preferencecollections general case allows. single-peaked electorates, protections vanish.Acknowledgmentswork supported part ARC grant DP1101011792, DFG grants BR-2312/{32,6-1}, NSF grants CCF-{0426761,0915792,1101452,1101479} IIS-0713061, European Science Foundations EUROCORES program LogICCC, Friedrich Wilhelm BesselResearch Awards Edith Hemaspaandra Lane A. Hemaspaandra. work donepart Felix Brandt Ludwig-Maximilians-Universitat Munchen MarkusBrill Ludwig-Maximilians-Universitat Munchen TU Munchen, donepart visits Edith Hemaspaandra Lane A. Hemaspaandra Heinrich-HeineUniversitat Dusseldorf Ludwig-Maximilians-Universitat Munchen. preliminary version paper appeared proceedings 24th AAAI Conference ArtificialIntelligence, July 2010 (Brandt, Brill, Hemaspaandra, & Hemaspaandra, 2010).grateful Steven Brams, Piotr Faliszewski, Felix Fischer, Zack Fitzsimmons,Paul Harrenstein, Jerome Lang, Ariel Procaccia, Jorg Rothe, Hans Georg Seedig, TroelsSrensen, anonymous conference journal referees helpful comments476fiBypassing Combinatorial Protectionsvaluable suggestions. grateful Piotr Faliszewski email exchange ledTheorem A.5 Paul Harrenstein preparing figures.Appendix A. Additional Definitions Proofsappendix provides additional definitions proofs.A.1 Additional DefinitionsLet us define additional election systems mentioned Section 2.Nanson elections runoff methods based Bordas scoring protocol. Nansons(1882) original definition, series Borda elections held candidatesstage average Borda score excluded unless candidatesidentical Borda scores, case candidates declared winnerselection. exist two variants Nanson due Fishburn Schwartz, excludecandidates lowest Borda score candidates whose Borda score lessaverage score, respectively. three versions fail weakCondorcet-consistent (Niou,1987).Maximin (a.k.a. Simpson-Kramer) elections (Simpson, 1969; Kramer, 1977) choosecandidates fare best worst pairwise comparison candidate.remaining three election systems based pairwise majority relation.Schwartz (1972) elections (sometimes also called top cycle), winners definedmaximal elements asymmetric part transitive closure majority relation. winners Fishburn (1977) elections maximal elements Fishburnrelation F , defined letting F b every candidate beats pairwisecomparison also beats b exists candidate beats b a.A.2 Proofs Section 2Theorem A.1. Kemeny, Schwartz, Fishburns Schwartzs versions NansonweakCondorcet-consistent single-peaked electorates.Proof. statements rely observation pairwise majority relation, >m ,single-peaked electorates transitive (Black, 1948, 1958). observe weakCondorcet winners precisely maximal elements pairwise majority relation.follows immediately Schwartz weakCondorcet-consistent.P case Kemeny, note (again writing >m pairwise majority relation){a,b}C,a6=b,am b k{v V | v prefers b a}k lower bound Kemeny scorelinear order. score realized linear order > > consistent >m ,i.e., every a, b C, >m b > b. pairwise majority relation transitivec weak Condorcet winner, c Kemeny winner, evidenced followingKemeny consensus: rank c first greedily keep adding, successive positionsconsensus, maximal (with respect >m ) unranked candidates. Since > consistent>m , > Kemeny consensus. immediate weak Condorcetwinner, ranked first linear order consistent >m .Nanson, prove weak Condorcet winner eliminated stageelection. First let us normalize Borda scores subtracting (kV k (m 1))/2477fiBrandt, Brill, Hemaspaandra, & HemaspaandraBorda score every candidate. ensures average normalized Borda scoreprecisely zero. Now, observe normalized Borda score candidate simply halfsum, candidates b, number voters prefer b minusnumber voters prefer b a. consequence, normalized Borda score everyweak Condorcet winner least zero. Moreover, case single-peaked electorate,due transitivity majority relation, always candidate negativenormalized Borda score unless candidates identical score zero. lattercase, three versions Nanson terminate. former case, neither FishburnsSchwartzs variant exclude weak Condorcet winners score leastlarge average score.qfact Black, Dodgson, original version Nanson, Copeland elections[0, 1) weakCondorcet-consistent single-peaked electorates seenfollowing universal counterexample. Let two voters preferences b > > cc > b > a. preferences single-peaked respect societal orderingL b L c. Candidates b c weak Condorcet winners, mentionedelection systems chooses b. Similarly, strongYoung weakCondorcet-consistentsingle-peaked electorates election two voters whose preferences> b > c c > b > a, candidates weak Condorcet winners, strongYoungyields candidates c.A.3 Additional Proofs Section 3Theorem A.2. winner problem Young elections p2 -complete,nonunique-winner model unique-winner model.Proof. p2 -completeness (nonunique) winner problem strongYoung elections(somewhat confusingly called Young elections there) shown Rothe et al. (2003).proof also establishes p2 -completeness unique winner model (Hemaspaandraet al., 2009). p2 upper bound easy show, argument usedshow p2 upper bound Young winner problem (in nonunique-winnermodel unique-winner model). p2 -hardness winner problem strongYoungelections shown Theorem 2.5 Rothe et al. (2003) via reduction p2 complete problem Maximum Set Packing Compare (MSPC, short): Given two sets, B1B2 , two collections sets S1 S2 , Si nonempty, finitesubset Bi , case (S1 ) (S2 )? Here, (Si ) denotes maximum numberpairwise disjoint sets Si . Rothe et al., assume (Si ) > 2.proofs Theorems 2.3 2.5 Rothe et al. (2003) show constructgiven MSPC instance = (B1 , B2 , S1 , S2 ) election (D, W ) two designatedcandidates, c d, (a) (S1 ) (S2 ) c strongYoung winners(D, W ), (b) (S2 ) > (S1 ) unique strongYoung winner (D, W ).show proof adapted work Young elections. Pleaserefer Rothe et al. (2003) definitions details construction,point differences here. Given MSPC instance = (B1 , B2 , S1 , S2 ), construct478fiBypassing Combinatorial Protectionselection (C 0 , V 0 ) c designated candidates C 0 , holdsYoungScore(C 0 , c, V 0 ) = 2 (S1 ) YoungScore(C 0 , d, V 0 ) = 2 (S2 ).17Let C 0 = C V 0 = V {v(2.4) , v(2.7) }, (C, V ) election constructedproof Theorem 2.3 Rothe et al. (2003), v(2.4) one two voters Vreferred voters form (2.4) Rothe et al. v(2.7) one two votersV referred voters form (2.7) Rothe et al.18 One definesubmultiset V0 voters V 0 V0 = V {v(2.4) }, V defined page 381Rothe et al. kV0 k = 2 (S1 ) c weak Condorcet winner (C 0 , V0 ),implying YoungScore(C 0 , c, V 0 ) 2 (S1 ).show YoungScore(C 0 , c, V 0 ) 2 (S1 ), adapt Lemma 2.4 Rothe et al.(2003) following way. (The proof Lemma A.3 similar proof Lemma 2.4Rothe et al., 2003, omit here.)Lemma A.3. 3 < kS1 k + 1, let V submultiset V 0 Vcontains exactly 1 voters form (2.4) (2.5) c weak Condorcet winner(C 0 , V 0 ). V contains exactly 1 voters form (2.3) voters form(2.6), (2.7), (2.8). Moreover, 1 voters form (2.3) V represent pairwisedisjoint sets S1 .Let V0 V 0 kV0 k 2 (S1 ) c weak Condorcet winnerSuppose exactly 1 voters form (2.4) (2.5) V0 . Since(S1 ) > 2, follows kV0 k 6, thus > 3 order beat c. Also,1 kS1 k, since exactly kS1 k voters form (2.4) (2.5) V 0 . Lemma A.3implies exactly 1 voters form (2.3) V0 , voters representpairwise disjoint sets S1 , V0 contains voters form (2.6), (2.7), (2.8).Hence, kV0 k = 2 ( 1) 2 (S1 ).thus YoungScore(C 0 , c, V 0 ) = 2 (S1 ). Analogously, one showYoungScore(C 0 , d, V 0 ) = 2 (S2 ). Thus(C 0 , V0 ).(S1 ) (S2 )YoungScore(C 0 , c, V 0 ) YoungScore(C 0 , d, V 0 ),proves p2 -hardness comparing Young scores. show winner problemYoung elections p2 -hard, alter election (C 0 , V 0 ) way (C, V )17. Note proof, follow Rothe et al.s (2003) convention Young scores defineYoungScore(C, c, V ) candidate c election (C, V ) size maximal submultisetvoters c weak Condorcet winner. Hence, set Young winners consists candidateswhose YoungScore least large YoungScore candidate.18. completeness, give definition (C 0 , V 0 ). C 0 = B1 B2 {a, b, c, d} V 0 consistsfollowing voters. (For ordered set = {m1 , . . . , mk }, write m1 > > mk .)(2.3) E S1 , one voter preference order E > > c > B1 E > B2 > b > d.(2.4) One voter preference order c > B1 > > B2 > b > d.(2.5) kS1 k 1 voters preference order B1 > c > > B2 > b > d.(2.6) F S2 , one voter vF preference order F > b > > B2 F > B1 > > c.(2.7) One voter preference order > B2 > b > B1 > > c.(2.8) kS2 k 1 voters preference order B2 > > b > B1 > > c.479fiBrandt, Brill, Hemaspaandra, & Hemaspaandraaltered Theorem 2.5 Rothe et al. (2003). Let (D0 , W 0 ) altered election.19 Oneshow Young scores c (D0 , W 0 ) (C 0 , V 0 ),candidates Young score (D0 , W 0 ) 2. Thus, sinceYoung scores c least 6, comparing Young scores c (D0 , W 0 )tantamount deciding c Young winner.Altogether, (a) (S1 ) (S2 ) c Young winner (D0 , W 0 ),(b) (S2 ) > (S1 ) unique Young winner (D0 , W 0 ). followsMSPC-instance MSPC c Young winner (D0 , W 0 ), implyingp2 -hardness Young winner problem nonunique-winner model. uniquewinner model, follow argument proof Theorem 2.3 Hemaspaandraet al. (2009): Observe MSPC unique winner(D0 , W 0 ). Thus complement unique-winner problem Young elections p2 hard. Since p2 closed complement, proves unique-winner problemYoung elections p2 -hard well.qTheorem A.4. winner problem weakDodgson elections p2 -complete,nonunique-winner model unique-winner model.Proof. p2 -completeness (nonunique) winner problem Dodgson electionsshown Hemaspaandra et al. (1997). proof also establishes p2 -completenessunique winner model (Hemaspaandra et al., 2009). p2 upper bound easyshow, argument used show p2 upper bound weakDodgsonwinner problem (in nonunique-winner model unique-winner model). p2 hardness winner problem Dodgson shown reduction p2 -hardproblem Two Election Ranking (2ER, short) (Hemaspaandra et al., 1997): Given twoDodgson triples (C, c, V ) (D, d, W ), kV k kW k odd c 6= d,Dodgson score c (C, V ) less equal Dodgson score (D, W )?Here, Dodgson triple (C, c, V ) election (C, V ) designated candidate c C.reduction 2ER winner problem Dodgson elections works mergingelections E1 = (C, V ) E2 = (D, W ) new election E3 = (C 0 , V 0 )C C 0 following properties satisfied:(i) Dodgson-ScoreE3 (c) = Dodgson-ScoreE1 (c) + 1,(ii) Dodgson-ScoreE3 (d) = Dodgson-ScoreE1 (d) + 1,(iii) Dodgson-ScoreE3 (x) > Dodgson-ScoreE3 (c) x C 0 {c, d}.Here, Dodgson-ScoreE (x) denotes minimal number switches required make candidate x Condorcet winner election E. Thus, immediately c Dodgsonwinner E3 Dodgson-ScoreE1 (c) Dodgson-ScoreE2 (d).2019. completeness, (D0 , W 0 ) defined follows. replace every candidate g C 0 {c, d} kV 0 k0candidates g 0 , . . . , g kV k1 . replace occurrence candidate g ith voter V 00000g mod kV k > g (i+1) mod kV k > > g (i+kV k1) mod kV k .20. noted fixable problem construction Hemaspaandra et al. (1997). problempage 822 end proof Lemma 3.7, proving Dodgson-ScoreE3 (dkDk1 ) >480fiBypassing Combinatorial Protectionsshow approach Hemaspaandra et al. (1997) adaptedwork weakDodgson. First, observe problem Weak Two Election Ranking(w2ER), defined like 2ER except Dodgson score replaced weakDodgsonscore, inherits p2 -hardness 2ER Dodgson scores weakDodgson scorescoincide instances odd number voters. (If number voters odd,weak Condorcet winner tantamount Condorcet winner, sinceties pairwise comparisons.) Also observe, inspection p2 -hardness proofHemaspaandra et al. (1997), 2ER w2ER still p2 -hard restrictDodgson-ScoreE3 (c), claimed argument applies candidate (C D)\{c, d}.Though claim clearly true candidate D{d}, true candidate C {c},since preference orders voter groups (b) (c), candidates C {c} separatedcandidates set separating candidates. consequence, may possible makecandidate C {c} Condorcet winner less kSk/2 switches voter groups.problem avoided changing t1 < < tkT k < c < s1 < < skSk < c1 < <ckCk1 prefix preference orders voters groups (b) (c) c < t1 < < tkT k <c1 < < ckCk1 < s1 < < skSk . gives following set voters. (In footnote use< b < c-notation specifying votes, rather c > b > a-notation used throughout restpaper, order match approach expressing votes used Hemaspaandra et al., 1997.make comparisons paper straightforward possible.)(a) voter e1 < < ekCk V , voter < s1 < < skSk < d1 < < dkDk1 < t1 < <tkT k < e1 < < ekCk .(b) voter e1 < < ekDk W , voter c < t1 < < tkT k < c1 < < ckCk1 < s1 < <skSk < e1 < < ekDk .llk(c) kV2 k kWvoters c < t1 < < tkT k < c1 < < ckCk1 < s1 < < skSk < d1 < <2dkDk1 < d.l(d) kV2 k voters t1 < < tkT k < c1 < < ckCk1 < d1 < < dkDk1 < skSk < < s1 < c < d.lk(e) kWvoters t1 < < tkT k < c1 < < ckCk1 < d1 < < dkDk1 < s1 < < skSk < < c.2Intuitively, changed construction symmetrical original one, preferencesvoter groups (a) (b) defined analogously, roles C (and )interchanged.Using proof Lemma 3.7 Hemaspaandra et al. (1997), easy see threeproperties mentioned hold. particular, c preferred halfvoters, Dodgson score c change. every candidate d0 D, d0 occurprefix preference order changed Dodgson score d0 change.remains show Dodgson-ScoreE3 (x) > Dodgson-ScoreE3 (c) x (C {c}).proof Lemma 3.7, know Dodgson-ScoreE3 (c) < kSk/2 kSk = kT k. orderbecome Condorcet winner, needs gain least one vote d. Note changedpreferences, need kSk switches switch beyond d, change preferenceslower Dodgson score kSk/2. order become Condorcet winner,shown Hemaspaandra et al. needs gain least one vote c needkSk/2 switches that. Since preferred c voters groups (b) (c)original changed election, voters used gain vote c. followschanged election, needs kSk/2 switches become Condorcet winner. Finally, letc0 C {c}. argument Hemaspaandra et al. every d0 {d} needs gain leastone vote c order become Condorcet winner, need kSk/2 switchesused (by symmetry construction) show every c0 C {c} needs gainleast one vote order become Condorcet winner, need kSk/2switches that.481fiBrandt, Brill, Hemaspaandra, & Hemaspaandraproblem Dodgson triples least three voters. Let w2ER0 thus-restrictedversion w2ER.reduction w2ER0 winner problem weakDodgson elections.Given two Dodgson triples (C, c, V ) (D, d, W ), denote corresponding electionsE1 = (C, V ) E2 = (D, W ). convenience, denote v = kV k w = kW k. Recallv w odd least three assume without loss generalityC = v w. Define = v kCk + w kDk observe strictupper bound weakDodgsonE1 E2 : Even worst case (a candidatescoresleast preferred voters), v2 (kCk 1) < switches sufficemake candidateweak Condorcet winner E1 (by making top choice v2 voters), analogousstatement holds E2 .define new election E3 = (C 0 , V 0 ). set C 0 candidates E3 definedC 0 = C U , C candidates elections E1 E2= {s1 , . . . , sm }, = {t1 , . . . , tm }, U = {u1 , . . . , um } 3m new candidates.order define voters E3 , introduce following abbreviations notational convenience. (ordered) set = {m1 , . . . , mk }, > > b shorthand> mk > > m1 > b. Furthermore, let c1 , . . . , ckCk1 d1 , . . . , dkDk1 arbitraryenumerations C = C {c} = {d}, respectively. voters V 0 E3 consistfollowing subgroups:(a) every voter E1 preference order Ci C, one voter preference orderCi > > > > > U.(b) every voter E2 preference order Dj D, one voter preference orderDj > > C > > c > U.(c) v2 w2 voters preference order> > > C > > c > U.(d)v2voters preference order> c > U > > > C > T.(e)w21 voters preference orderc > > U > > > C > T.(f) one voter preference order> > C > > c > > U.Since v odd, total number voters kV 0 k = 2v + w + 1. v w odd,kV 0 k even weak Condorcet winner preferred every candidate0least kV2 k = v + w2 voters. show following three propertiessatisfied:482fiBypassing Combinatorial Protections(i) weakDodgson-ScoreE3 (c) = weakDodgson-ScoreE1 (c),(ii) weakDodgson-ScoreE3 (d) = weakDodgson-ScoreE1 (d),(iii) weakDodgson-ScoreE3 (x) > weakDodgson-ScoreE3 (c) x C 0 {c, d}.0(i), observe c preferred every candidate C 0 C least kV2 kvoters. Thus, computing weakDodgson score c, take carecandidates C = {c1 , . . . , ckCk1 }. Let xi number voters group(a)prefer c ci . number voters V 0 prefer c ci xi + v2 + w2 1.Candidate c weak Condorcet winner E3 number greater0equal kV2 k = v + w2 , case xi v2{1, . . . , kCk 1}. means c Condorcet winner E1 . definition,achieved k switches, k = weakDodgson-ScoreE1 (c). thusshown upper bound weakDodgson-ScoreE3 (c) weakDodgson-ScoreE1 (c). assumeweakDodgson-ScoreE3 (c) < weakDodgson-ScoreE1 (c). Due construction,switches optimal sequence occur voters group (a), making c beatcandidate C would require switches relevant voter groups(b), (c), (f). means way make c weak Condorcet winner E1less weakDodgson-ScoreE1 (c) switches, contradiction. thereby shownweakDodgson-ScoreE3 (c) = weakDodgson-ScoreE1 (c). proof property (ii)analogous.(iii), recall chosen sufficiently large strict upper boundweakDodgson-ScoreE1 (c) thus, (i), weakDodgson-ScoreE3 (c). showcandidates C 0 c weakDodgson score least E3 .Consider candidate S. order become weak Condorcet winner, mustvbeatcontest. preferredc w + 2particularv tiec pairwiseww0 , needs gain least v extra votes c voter+1=+votersV2222groups (a), (d), (e). gaining one extra vote c would requireswitches, separated c least candidates votergroups.similar argument applies candidates: Candidates need w2 extravotes (b), (c), (d), (e), one extravote requires switchesvvoters. Candidates U need 2 extra votes di (a), (b), (c),(f), one extra vote requires switches. Candidates need v2extra votes c (a), (d),(e), one extra vote requires switches.wCandidates C need 2 extra votes (b), (c), (d), (e), one extra voterequires switches. Thus, shown weakDodgson-ScoreE3 (x) > >weakDodgson-ScoreE3 (c) x C 0 {c, d}.easy see (1) weakDodgson-ScoreE1 (c) weakDodgson-ScoreE2 (d),c weakDodgson winner E3 , (2) weakDodgson-ScoreE1 (c) >weakDodgson-ScoreE2 (d), unique weakDodgson winner E3 . Let =((C, c, V ), (D, d, W )) instance w2ER0 . argued w2ER0c weakDodgson winner E3 , immediately implies p2 -hardnessweakDodgson winner problem nonunique-winner model. unique-winnermodel, follow argument proof Theorem 2.3 Hemaspaandra et al.483fiBrandt, Brill, Hemaspaandra, & Hemaspaandra(2009): Observe w2ER0 unique weakDodgson winnerE3 . Thus complement unique-winner problem weakDodgson electionsp2 -hard. Since p2 closed complement, proves unique-winner problemweakDodgson elections also p2 -hard.qA.4 Additional Proofs Section 4Theorem 4.3. following hold (see Footnote 9):1. Approval-negative-bribery approval-strongnegative-bribery NP-complete.2. single-peaked electorates, approval-negative-bribery approval-strongnegativebribery P.Proof. polynomial-time algorithms witnessing P-membership approval-negativebribery approval-strongnegative-bribery flavor algorithmapproval-bribery (Theorem 4.2), present first.Let (C, V ) instance single-peaked approval election L valid single-peakedordering candidates. decide whether designated candidate p Cmade winner bribing k voters. proof Theorem 4.2, define Vcmultiset voters approve candidate c. V+ = Vp multiset votersapproving p V = V V+ multiset voters disapproving p.Approval-strongnegative-bribery like approval-bribery, except bribed votersbribe allowed approve p. Consequently, bribing voter approves palways pointless bribe voters V . Also, without lossgenerality assume bribed voters disapprove candidates bribe,clearly best possible action regard goal make p winner. algorithmsimilar one presented proof Theorem 4.2. Define surplus n(c)candidate c C {p} n(c) = kVc k kVp k consider rightmost candidate c0right p positive surplus. order make p winner, obviouslybribe least n(c0 ) voters Vc0 V . definition, candidates right c0nonpositive surplus, whyin deciding n(c0 ) voters Vc0 Vbribewe solely focus candidates left c0 choose n(c0 ) votersVc0 V whose approval range extends furthest left. mentioned above,bribe voters disapprove everyone, thereby making n(c0 ) = 0. recalculatesurpluses candidates left c0 (note candidates surplus never growsthus ignore candidates right c0 ) repeat processrightmost candidate right p positive surplus.time candidates right p nonpositive surplus,mirror societal order L repeat procedure nonpositive-surplus candidates originally left p respect L. make surplusesnonpositive without exceeding bribe limit k, found successful bribery action. Otherwise, successful bribery action exist, decisions (concerningvoters bribe) provably optimal.case approval-negative-bribery, bribed candidates may approve pbribe approved p bribe. model, sometimes make sense484fiBypassing Combinatorial Protectionsbribe voters V+ . pose problem, following observationshows. approval score p remains unchanged every optimal bribe. Here, optimalbribe defined either bribing voter V+ disapprove everyone except p,bribing voter V disapprove everyone. Again, case strongnegativebribery, without loss generality assume bribes optimal. Thus,observation tells us differentiate bribing voters V+V , cases thing care removal approvalscandidates p. Hence, algorithm strongnegative bribery,except considering positive-surplus candidate c deciding votersVc bribe, consider voters disapprove p also votersapprove p.go show bribery problems NP-complete general (i.e.,necessarily single-peaked) case. Membership NP obvious problems.hardness proof approval-strongnegative-bribery adaptation proofapproval-bribery NP-hard (Faliszewski et al., 2009, Thm. 4.2). Please referproof point differences. reduction NP-hard problemExact Cover 3-sets (X3C), define bribery instance Theorem 4.2 Faliszewskiet al. (2009), except number voters approvep changedinstead m. exists cover kAk = iA Si = B, bribevi approve zero candidates (this slight additional change).candidates tie approvals win. Looking direction, existssuccessful bribe voters, since p approvals 3t candidatesB + 1 approvals, bribe increase number approvals p (innegative strongnegative bribery setting), clearly p still approvalsbribes. So, 3t candidates B (that started + 1 approvals)must lost exactly one approval (if lost one approval, one wouldlost zero approvals would beat p; lost zero approvals, would beat p). So,exact cover 3-sets.Due construction, one use proof show NP-hardness approvalnegative-bribery: voters approving p voters approve p obviously never bribed.qTheorem 4.4. single-peaked electorates, weakCondorcet-weighted-$bribery, weakCondorcet-negative-weighted-bribery, weakCondorcet-negative-weighted-$briberyNP-complete, remaining five cases (weakCondorcet-bribery, weakCondorcet$bribery, weakCondorcet-weighted-bribery, weakCondorcet-negative-bribery, weakCondorcetnegative-$bribery) P.Proof. general setting eight bribery problems describehere. Let (C, V ) election instance let L linear order candidateselectorate single-peaked respect L. question whetherdesignated candidate p C made weakCondorcet winner bribing kvoters.p weakCondorcet winner election (C, V ), successful bribery action obviously possible bribe voter. thus focus case p485fiBrandt, Brill, Hemaspaandra, & HemaspaandraweakCondorcet winner (C, V ). case, definition weakCondorcetimplies p contained median interval (i.e., p/ [m` , mr ]L , m`mr top choices median voters). Assume without loss generality p liesstrictly right median interval, i.e., mr L p (otherwise, mirrorsocietal order L).Identify voter preferred candidate. Define V` = {v V | v L p}multiset voters lying left p respect L Vr = V V` = {vV | v = p p L v} multiset voters lying p right p. settingsvoters weights, mr L p immediately impliesl kV` k >m kVr k that,rkorder make p weakCondorcet winner, need bribe kV` kkVvoters V`2make p top choice (or, negative-bribery settings, make candidaterightptop choice). voters weights, shift total weight leastlw(V` )w(Vr ), w(V 0 ) submultiset V 0 V voters defined natural way2Psum weights voters contained V 0 , i.e., w(V 0 ) = vV 0 w(v).Observe eight bribery problems easily seen NP. proveassertions Theorem 4.4 order mentioned statementtheorem.(i) weakCondorcet-weighted-$bribery NP-complete.Define k weight needs shifted V` p, i.e.,w(V` ) w(Vr )k =.2problem weakCondorcet-weighted-$bribery stated follows.given collection objects (voters), positive integer weightpositive integer price, bounds k k, question whether existssubset whose price k whose weight least k. so, bribefirst-choose p. holds (or p initially wins), succeed, else fail.straightforward show NP-hard problem Knapsack (see, e.g., Garey& Johnson, 1979) reduces directly problem, establishing NP-hardnessweakCondorcet-weighted-$bribery.(ii) weakCondorcet-negative-weighted-bribery NP-complete.give reduction NP-complete problem Partition (see proofTheorem 6.2). Given collection (k1 , k2 , . . . , kn ) positive integers sum2K, define single-peaked election (C, V ) C = {a, p, c}, L p L c,ki one voter vi whose first choice whose weight ki . Setbudget k equal n. easy see p win via negative bribery(k1 , k2 , . . . , kn ) partitioned two equal-sum parts.(iii) weakCondorcet-negative-weighted-$bribery NP-complete.follows (ii).(iv) weakCondorcet-bribery P.486fiBypassing Combinatorial Protectionsalgorithm easy: Bribe k voters chosen arbitrarily V` make p topchoice. If, bribe, p weakCondorcet winner, successful. Otherwise,successful bribery action exists.(v) weakCondorcet-$bribery P.algorithm (iv), except bribe voters orderprice tags, starting cheapest voter.(vi) weakCondorcet-weighted-bribery P.algorithm (iv), except bribe voters orderweights, starting voter highest weight.(vii) weakCondorcet-negative-bribery P.follows (viii).(viii) weakCondorcet-negative-$bribery P.Recall p lies strictly right median interval. case negativebribery, bribed voters must p top choice. Thus, p never madeweakCondorcet winner either (a) voter p first choice kV kodd, (b) p right end societal order L. (Since p lies strictlyright median interval, p cannot left end L.)Otherwise, let p candidate right p respect L. Successfulbribery possible if, greedily bribing voters V` (startingcheapest voter) p top choice, make p weakCondorcet winner.qfinal comment, note easy see problems solvedpseudo-polynomial time dynamic programming, NP-completeness resultsstrengthened strong NP-completeness unless P = NP.A.5 Additional Proofs Section 5Let one 22 control types defined Faliszewski et al. (2009a), i.e., eleventypes (adding/deleting candidates/voters (4 types); unlimited-adding candidates (1type); three partition types TP TE (6 types)), constructive cases (making c win uniquely win) destructive cases (making c winunique winner). Let E election system. following holdsunique-winner model nonunique-winner model. (Recall Section 5.1speak control problem single-peaked, mean single-peakednessholds even including potentially added candidates voters.)Theorem A.5. control problem E P single-peaked electoratesdefault model (in societal order L part input) controlproblem E P single-peaked electorates exists-L model (in askexists order L relative input single-peakedgoal achieved type control action).487fiBrandt, Brill, Hemaspaandra, & HemaspaandraProof. Note control problem instance L0 L00 validsocietal orders relative instance (and crucial notioninstancenot voters/candidates left endmust respect ordervalid), set successful (resp., unsuccessful) control actions L0exactly L00 . Thus, following key observation:(?) exists valid single-peaked order relative control problem instance successfully controlled control problem instancesuccessfully controlled every valid single-peaked order.So, control problem P model L part input via algorithm A,exists-L model, given instance compute valid L (e.g., usingalgorithm Escoffier et al., 2008) hand A. (?) correctness A,know gives correct answer.direction, control problem P exists-L model, thanks(?), simply strip L input model L part inputsafely (knowing answer correct original issue) ask existential questionhypothetical P algorithm exists-L version.qparticular instances Theorem A.5 argued directly particular cases EFaliszewski et al. (2011), Theorem A.5 provides tool removes needcase-specific arguments.Theorem 5.5. weakCondorcet elections, control adding voters control deleting voters P single-peaked electorates, nonunique-winner modelunique-winner model.Proof. give algorithms nonunique-winner model. unique-winnermodel, see proof Theorem 5.7 (by Fact 3.1 page 448, unique weakCondorcetwinner tantamount Condorcet winner single-peaked electorates).Associate voter preferred candidate. goal make pweakCondorcet winner, i.e., want end one following two situations:1. kV k odd median voter p top choice.2. kV k even p lies (inclusive) interval [m` , mr ]L , m` mrmedian voters. (This includes case m` = mr .) following,refer [m` , mr ]L median interval.easy algorithm case control addition voters: Seecurrent median (or median interval) is. p median (or p lies median interval),done. Otherwise, assume without loss generality median (interval) liesleft p. add unregistered voters whose top choice either p candidateright p p weakCondorcet winner hit addition boundadded unregistered voters sort. point succeeded,success impossible.algorithm control-by-deletion-of-voters case similar: See currentmedian (or median interval) is. p median (or p lies median interval),488fiBypassing Combinatorial Protectionsdone. Otherwise, need shift location median voter(s) towards p. Withoutloss generality assume median (interval) lies left p. startdeleting voters left end L make p weakCondorcet winner hitdeletion bound without success.qTheorem 5.6. Condorcet elections, control partition voters P singlepeaked electorates, nonunique-winner model unique-winner model,Ties Promote model Ties Eliminate model (note four casescoincide here).Proof. Let (C, V ) instance Condorcet election let L linear orderrespect electorate single-peaked. Without loss generality assume kCk 2(otherwise, problem trivial). Furthermore, p C designated candidatequestion whether exists partition (V1 , V2 ) p Condorcet winneroverall election. clear case exists partition(V1 , V2 ) p Condorcet winner (C, V1 ) (C, V2 ) Condorcet winner,Condorcet winner p beats pairwise comparison, p Condorcet winner.show Algorithm 3 returns partition property whenever one exists.Algorithm 3 loops candidates c p beats pairwise comparisonpossible sizes V1 (line 2). set C candidates divided five regionsR1 , R2 , . . . , R5 defined follows. Without loss generality assume p <L c,i.e., c lies right p respect societal order L (otherwise, mirroreverything). Region R1 consists candidates left p, i.e., R1 = {x C | x <L p},region R2 consists p only. Similarly, R5 consists candidates right cR4 consists c only. Finally, R3 consists remaining candidates, namely,candidates lie p c respect L. Note regions except R2R4 may empty. following picture:pR1R2cR3R4R5Associate voter candidate top voters preference order.define P` , set partitions V respect regions defined. Let` = (`1 , `2 , . . . , `5 ) five-dimensional vector natural numbers. Define P` setpartitions (V1 , V2 ) V property that, i, `i number votersV1 whose top choice Ri .P` 6= , key observation following: x {p, c} holds xCondorcet winner election (C, V1 ) (V1 , V2 ) P` x Condorcetwinner every election (C, V1 ) (V1 , V2 ) P` . is, want check whether xCondorcet winner primary elections (C, V1 ) induced partitions(V1 , V2 ) P` , suffices check one obtain answer. symmetry,statement holds Condorcet winners elections (C, V2 ).reason true that, given number voters region,easy compute region(s) median voter(s) (just counting). Since p489fiBrandt, Brill, Hemaspaandra, & HemaspaandraAlgorithm 3 Condorcet Control Partition Voters1: candidates c lose p pairwise comparison2:k {1, 2, . . . , kV k}P3:` = (`1 , `2 , . . . , `5 ) N5 5i=1 `i = k4:define P` set partitions (V1 , V2 ) V i, `inumber voters V1 whose top choice Ri5:P` 6=6:let (V1 , V2 ) arbitrary partition P`7:p Condorcet winner (C, V1 )8:either c p Condorcet winner (C, V2 )9:return (V1 , V2 )10:else (V1 , V2 ) P` : (C, V2 ) Condorcet winner11:return (V1 , V2 )12: return partition makes p overall Condorcet winnerc constitute region own, equally easy tell whether Condorcetwinners (using Fact 3.1).shown queries lines 7 8 Algorithm 3 efficientlyanswered. go show query line 10 efficiently answered,i.e., given `, partition (V1 , V2 ) P` (C, V2 ) Condorcet winner.Clearly, cannot happen odd number voters V2 . assume kV2 keven let m1 m2 median voters. region Ri , know numberV2 -voters whose top choice Ri (this number kRi k `i ). Thus knowregions median voters fall (again counting). Now, least one m1 m2 fallR2 R4 (i.e., p c), (C, V2 ) cannot possibly Condorcet winnerp c (there may Condorcet winners). three cases, partitionaction successful21 return arbitrary partition P` .remaining cases m1 m2 fall R1 R3 R5 . m1m2 fall different regions, obviously Condorcet winner done.Assume, therefore, m1 m2 fall Ri {1, 3, 5}. goal assignqi = kRi k `i voters top choice Ri V2 way median pairV2 fall candidate. Let median pair rth (r + 1)stV2 -voter Ri . Here, r (1 r qi 1) known (by numbers V2 -voters leftright Ri ) count left right respect societal order L.try accomplish goal brute force, namely, pair candidates (d` , dr )Ri d` <L dr , let us try ensure rth V2 -voter Ri left fallsleft d` (r + 1)st falls right dr .k{x V | x falls Ri x L d` }k r k{x V | x falls Ri dr L x}k qi r.cost check O(kCk2 ), pair candidates Ri , easycounting.Summing up, running time Algorithm 3 bounded follows. numberiterations loops lines 1, 2, 3, bounded kCk, kV k, kV k5 , respectively.cost one iteration inner loop clearly dominated cost answering21. fact, either p c Condorcet winner (C, V2 ), would already detected line 8.490fiBypassing Combinatorial Protectionsquery line 10. cost bounded O(kCk2 ), argued last paragraph.Altogether, yields running time obviously polynomial size input.Correctness Algorithm 3 clear explanations above,argued find partition makes p overall Condorcet winnerpartition exists. particular, observe never need consider casesk = 0 p never Condorcet winner (C, ). case p alreadyCondorcet winner original election (C, V ) handled setting k kV k line 2(and c arbitrary candidate C {p} line 1).qTheorem 5.7. Condorcet elections, control adding voters control deletingvoters P single-peaked electorates, nonunique-winner modelunique-winner model.Proof. Associate voter preferred candidate. goalmake p Condorcet winner, i.e., want end situation ppreferred candidate median voter(s).easy algorithm case control addition voters: Seecurrent median (or median pair) is. p, done. Otherwise, add unregisteredvoters whose top choice p added succeed hitaddition bound. succeed hit addition bound, done (with withoutsuccess). yet hit addition bound, move follows. p strictlytwo median voters point, success impossible. one two distinctmedian voters (without loss generality say rightmost two median voters)median interval contain p (without loss generality say interval liesleft p), add unregistered voters right p make p Condorcetwinner hit addition bound added unregistered voterssort. point succeeded, success impossible.algorithm control-by-deletion-of-voters case similar: See currentmedian (or median pair) is. p, done. Otherwise, need shift locationmedian voter(s) towards p. Without loss generality assume median (ormedian interval) lies left p. start deleting voters left end Lmake p Condorcet winner hit deletion bound without success. Note pinitially lies two median voters, never made Condorcet winnerdeleting voters.qReferencesBarbera, S. (2001). introduction strategy-proof social choice functions. Social ChoiceWelfare, 18 (4), 619653.Bartholdi, III, J., & Orlin, J. (1991). Single transferable vote resists strategic voting. SocialChoice Welfare, 8 (4), 341354.Bartholdi, III, J., Tovey, C., & Trick, M. (1989). computational difficulty manipulating election. Social Choice Welfare, 6 (3), 227241.491fiBrandt, Brill, Hemaspaandra, & HemaspaandraBartholdi, III, J., Tovey, C., & Trick, M. (1992). hard control election?Mathematical Computer Modeling, 16 (8/9), 2740.Bartholdi, III, J., & Trick, M. (1986). Stable matching preferences derivedpsychological model. Operations Research Letters, 5 (4), 165169.Black, D. (1948). rationale group decision-making. Journal Political Economy,56 (1), 2334.Black, D. (1958). Theory Committees Elections. Cambridge University Press.Booth, K., & Lueker, G. (1976). Testing consecutive ones property, interval graphs,graph planarity using PQ-tree algorithms. Journal Computer SystemSciences, 13 (3), 335379.Brandt, F., Brill, M., Hemaspaandra, E., & Hemaspaandra, L. (2010). Bypassing combinatorial protections: Polynomial-time algorithms single-peaked electorates. Proceedings 24th AAAI Conference Artificial Intelligence, pp. 715722. AAAIPress.Bredereck, R., Chen, J., & Woeginger, G. (2013). nicely structured preferenceprofiles nearby? Proceedings 23rd International Joint Conference ArtificialIntelligence, pp. 6268. AAAI Press.Condorcet, J. (1785). Essai sur lApplication de LAnalyse la Probabilite des DecisionsRendues la Pluralite des Voix. Facsimile reprint original published Paris, 1972,Imprimerie Royale.Conitzer, V. (2009). Eliciting single-peaked preferences using comparison queries. JournalArtificial Intelligence Research, 35, 161191.Conitzer, V., Sandholm, T., & Lang, J. (2007). elections candidateshard manipulate? Journal ACM, 54 (3), Article 14.Copeland, A. (1951). reasonable social welfare function. Mimeographed notesSeminar Applications Mathematics Social Sciences, University Michigan.Cornaz, D., Galand, L., & Spanjaard, O. (2012). Bounded single-peaked width proportional representation. Proceedings 20th European Conference ArtificialIntelligence, pp. 270275. IOS Press.Cornaz, D., Galand, L., & Spanjaard, O. (2013). Kemeny elections bounded singlepeaked single-crossing width. Proceedings 23rd International Joint Conference Artificial Intelligence, pp. 7682. AAAI Press.Davis, O., Hinich, M., & Ordeshook, P. (1970). expository development mathematical model electoral process. American Political Science Review, 54 (2),426448.Dodgson, C. (1876). method taking votes two issues. Pamphlet printedClarendon Press, Oxford, headed yet published.Doignon, J., & Falmagne, J. (1994). polynomial time algorithm unidimensional unfolding representations. Journal Algorithms, 16 (2), 218233.492fiBypassing Combinatorial ProtectionsDuggan, J., & Schwartz, T. (2000). Strategic manipulability without resoluteness sharedbeliefs: GibbardSatterthwaite generalized. Social Choice Welfare, 17 (1), 8593.Dwork, C., Kumar, R., Naor, M., & Sivakumar, D. (2001). Rank aggregation methodsweb. Proceedings 10th International World Wide Web Conference, pp.613622. ACM Press.Ephrati, E., & Rosenschein, J. (1997). heuristic technique multi-agent planning.Annals Mathematics Artificial Intelligence, 20 (14), 1367.Erdelyi, G., Lackner, M., & Pfandler, A. (2013). Computational aspects nearly singlepeaked electorates. Proceedings 27th AAAI Conference Artificial Intelligence, pp. 283289.Erdelyi, G., Nowak, M., & Rothe, J. (2009). Sincere-strategy preference-based approvalvoting fully resists constructive control broadly resists destructive control. Mathematical Logic Quarterly, 55 (4), 425443.Erdelyi, G., Piras, L., & Rothe, J. (2011). complexity voter partition Bucklinfallback voting: Solving three open problems. Proceedings 10th International Conference Autonomous Agents Multiagent Systems, pp. 837844.International Foundation Autonomous Agents Multiagent Systems.Erdelyi, G., & Rothe, J. (2010). Control complexity fallback voting. Proceedings16th Australasian Theory Symposium, pp. 3948. Australian Computer Society.Escoffier, B., Lang, J., & Ozturk, M. (2008). Single-peaked consistency complexity.Proceedings 18th European Conference Artificial Intelligence, pp. 366370.IOS Press.Faliszewski, P. (2008). Nonuniform bribery. Proceedings 7th International Conference Autonomous Agents Multiagent Systems, pp. 15691572. InternationalFoundation Autonomous Agents Multiagent Systems.Faliszewski, P., Hemaspaandra, E., & Hemaspaandra, L. (2009). complexity briberyelections. Journal Artificial Intelligence Research, 35, 485532.Faliszewski, P., Hemaspaandra, E., & Hemaspaandra, L. (2010). Using complexity protectelections. Communications ACM, 53 (11), 7482.Faliszewski, P., Hemaspaandra, E., & Hemaspaandra, L. (2011a). complexity manipulative attacks nearly single-peaked electorates. Tech. rep. arXiv:1105.5032 [cs.GT],Computing Research Repository, arXiv.org/corr/. Revised, July 2012.Faliszewski, P., Hemaspaandra, E., & Hemaspaandra, L. (2011b). complexity manipulative attacks nearly single-peaked electorates. Proceedings 13th Conference Theoretical Aspects Rationality Knowledge, pp. 228237. ACM DigitalLibrary.Faliszewski, P., Hemaspaandra, E., & Hemaspaandra, L. (2013). Weighted electoral control. Proceedings 12th International Conference Autonomous AgentsMultiagent Systems, pp. 367374. International Foundation Autonomous AgentsMultiagent Systems.493fiBrandt, Brill, Hemaspaandra, & HemaspaandraFaliszewski, P., Hemaspaandra, E., & Hemaspaandra, L. (2014). complexity manipulative attacks nearly single-peaked electorates. Artificial Intelligence, 207, 6999.Faliszewski, P., Hemaspaandra, E., Hemaspaandra, L., & Rothe, J. (2009a). LlullCopeland voting computationally resist bribery constructive control. JournalArtificial Intelligence Research, 35, 275341.Faliszewski, P., Hemaspaandra, E., Hemaspaandra, L., & Rothe, J. (2009b). richer understanding complexity election systems. Ravi, S., & Shukla, S. (Eds.), Fundamental Problems Computing: Essays Honor Professor Daniel J. Rosenkrantz,pp. 375406. Springer.Faliszewski, P., Hemaspaandra, E., Hemaspaandra, L., & Rothe, J. (2011). shieldnever was: Societies single-peaked preferences open manipulationcontrol. Information Computation, 209, 89107.Faliszewski, P., Hemaspaandra, E., & Schnoor, H. (2008). Copeland voting: Ties matter.Proceedings 7th International Conference Autonomous Agents Multiagent Systems, pp. 983990. International Foundation Autonomous AgentsMultiagent Systems.Fishburn, P. (1977). Condorcet social choice functions. SIAM Journal Applied Mathematics, 33 (3), 469489.Friedgut, E., Kalai, G., Keller, N., & Nisan, N. (2011). quantitative versionGibbard-Satterthwaite Theorem three alternatives. SIAM Journal Computing,40 (3), 934952.Friedgut, E., Kalai, G., & Nisan, N. (2008). Elections manipulated often. Proceedings 49th IEEE Symposium Foundations Computer Science, pp. 243249.IEEE Computer Society Press.Fulkerson, D., & Gross, G. (1965). Incidence matrices interval graphs. Pacific JournalMathematics, 15 (5), 835855.Garey, M., & Johnson, D. (1979). Computers Intractability: Guide TheoryNP-Completeness. W. H. Freeman.Ghosh, S., Mundhe, M., Hernandez, K., & Sen, S. (1999). Voting movies: anatomyrecommender systems. Proceedings 3rd Annual Conference AutonomousAgents, pp. 434435. ACM Press.Gibbard, A. (1973). Manipulation voting schemes. Econometrica, 41 (4), 587601.Hagele, G., & Pukelsheim, F. (2001). electoral writings Ramon Llull. Studia Lulliana,41 (97), 338.Hemachandra, L. (1989). strong exponential hierarchy collapses. Journal ComputerSystem Sciences, 39 (3), 299322.Hemaspaandra, E., & Hemaspaandra, L. (2000). Computational politics: Electoral systems.Proceedings 25th International Symposium Mathematical FoundationsComputer Science, pp. 6483. Springer-Verlag Lecture Notes Computer Science#1893.494fiBypassing Combinatorial ProtectionsHemaspaandra, E., & Hemaspaandra, L. (2007). Dichotomy voting systems. JournalComputer System Sciences, 73 (1), 7383.Hemaspaandra, E., Hemaspaandra, L., & Menton, C. (2013). Search versus decisionelection manipulation problems. Proceedings 30th Annual SymposiumTheoretical Aspects Computer Science, pp. 377388. Leibniz International Proceedings Informatics (LIPIcs).Hemaspaandra, E., Hemaspaandra, L., & Rothe, J. (1997). Exact analysis Dodgsonelections: Lewis Carrolls 1876 voting system complete parallel access NP.Journal ACM, 44 (6), 806825.Hemaspaandra, E., Hemaspaandra, L., & Rothe, J. (2007). Anyone him: complexityprecluding alternative. Artificial Intelligence, 171 (56), 255285.Hemaspaandra, E., Hemaspaandra, L., & Rothe, J. (2009). Hybrid elections broadencomplexity-theoretic resistance control. Mathematical Logic Quarterly, 55 (4), 397424.Hemaspaandra, E., Spakowski, H., & Vogel, J. (2005). complexity Kemeny elections.Theoretical Computer Science, 349 (3), 382391.Hemaspaandra, L., & Williams, R. (2012). atypical survey typical-case heuristicalgorithms. SIGACT News, 43 (4), 7189.Kemeny, J. (1959). Mathematics without numbers. Ddalus, 88 (4), 571591.Kemeny, J., & Snell, L. (1960). Mathematical Models Social Sciences. Ginn.Konczak, K., & Lang, J. (2005). Voting procedures incomplete preferences. Proceedings Multidisciplinary IJCAI-05 Workshop Advances Preference Handling,pp. 124129.Kramer, G. (1977). dynamical model political equilibrium. Journal EconomicTheory, 16 (2), 310334.Krehbiel, K. (1998). Pivotal Politics: Theory U.S. Lawmaking. University ChicagoPress.McCabe-Dansted, J., Pritchard, G., & Slinko, A. (2008). Approximability Dodgsonsrule. Social Choice Welfare, 31 (2), 311330.Menton, C. (2013). Normalized range voting broadly resists control. Theory ComputingSystems, 53 (4), 507531.Nanson, E. (1882). Methods election. Transactions Proceedings Royal SocietyVictoria, 19, 197240. Available 2009 facsimile reprint Kessinger Publishing.Niemi, R., & Wright, J. (1987). Voting cycles structure individual preferences.Social Choice Welfare, 4 (3), 173183.Niou, E. (1987). note Nansons Rule. Public Choice, 54 (2), 191193.Papadimitriou, C., & Zachos, S. (1983). Two remarks power counting. Proceedings 6th GI Conference Theoretical Computer Science, pp. 269276.Springer-Verlag Lecture Notes Computer Science #145.495fiBrandt, Brill, Hemaspaandra, & HemaspaandraPennock, D., Horvitz, E., & Giles, C. (2000). Social choice theory recommender systems:Analysis axiomatic foundations collaborative filtering. Proceedings17th National Conference Artificial Intelligence, pp. 729734. AAAI Press.Procaccia, A., & Rosenschein, J. (2007). Junta distributions average-case complexitymanipulating elections. Journal Artificial Intelligence Research, 28, 157181.Rothe, J., Spakowski, H., & Vogel, J. (2003). Exact complexity winner problemYoung elections. Theory Computing Systems, 36 (4), 375386.Satterthwaite, M. (1975). Strategy-proofness Arrows conditions: Existence correspondence theorems voting procedures social welfare functions. JournalEconomic Theory, 10 (2), 187217.Schwartz, T. (1972). Rationality myth maximum. Nous, 6 (2), 97117.Simpson, P. (1969). defining areas voter choice: Professor Tullock stable voting.Quarterly Journal Economics, 83 (3), 478490.Sui, X., Boutilier, C., & Sandholm, T. (2013). Analysis optimization multidimensional percentile mechanisms. Proceedings 23rd International JointConference Artificial Intelligence, pp. 367374. AAAI Press.Walsh, T. (2007). Uncertainty preference elicitation aggregation. Proceedings22nd AAAI Conference Artificial Intelligence, pp. 38. AAAI Press.Walsh, T. (2009). really hard manipulation problems? phase transitionmanipulating veto rule. Proceedings 21st International Joint ConferenceArtificial Intelligence, pp. 324329. AAAI Press.Young, H. (1977). Extending Condorcets rule. Journal Economic Theory, 16 (2), 335353.496fiJournal Artificial Intelligence Research 53 (2015) 271-314Submitted 12/14; published 07/15Model Theory XPath Data Trees.Part I: Bisimulation CharacterizationDiego Figueiradiego.figueira@labri.frCNRS, LaBRI, FranceSantiago Figueirasantiago@dc.uba.arUniversidad de Buenos Aires CONICET, ArgentinaCarlos Arecescarlos.areces@gmail.comUniversidad Nacional de Cordoba CONICET, ArgentinaAbstractinvestigate model theoretic properties XPath data (in)equality testsclass data trees, i.e., class trees node contains label finitealphabet data value infinite domain.provide notions (bi)simulations XPath logics containing child, parent,ancestor descendant axes navigate tree. show notions precisely characterize equivalence relation associated logic. study formulacomplexity measures consisting number nested axes nested subformulasformula; notions akin notion quantifier rank first-order logic. showcharacterization results fine grained notions equivalence (bi)simulation takeaccount complexity measures. also prove positive fragmentslogics correspond formulas preserved (non-symmetric) simulations. showlogic including child axis equivalent fragment first-order logicinvariant corresponding notion bisimulation. upward navigation allowedcharacterization fails weaker result still established. results holdclass possibly infinite data trees class finite data trees.Besides intrinsic theoretical value, argue bisimulations useful toolsprove (non)expressivity results logics studied here, substantiate claimexamples.1. Introductionstudy expressive power model theory XPatharguably widely usedXML query language. Indeed, XPath implemented XSLT XQuery usedconstituent part many specification update languages. XPath is, fundamentally,general purpose language addressing, searching, matching pieces XMLdocument. open standard constitutes World Wide Web Consortium (W3C)Recommendation (Clark & DeRose, 1999).Core-XPath (term coined Gottlob, Koch, & Pichler, 2005) fragment XPath1.0 containing navigational behavior XPath. express properties underlying tree structure XML document, label (tag name) node,cannot express conditions actual data contained attributes. words,allows reasoning trees finite alphabet. Core-XPath well studiedsatisfiability problem known decidable even presence Documentc2015AI Access Foundation. rights reserved.fiFigueira, Figueira, & ArecesType Definitions (DTDs) (Marx, 2004; Benedikt, Fan, & Geerts, 2008). Moreover,known equivalent FO2 (first-order logic two variables) appropriatesignature trees terms expressive power (Marx & de Rijke, 2005),strictly less expressive PDL converse trees (Benedikt & Koch, 2008).database perspective, however, Core-XPath fails include single importantconstruct query language: join. Without ability relate nodes basedactual data values attributes, logics expressive power inappropriate manyapplications.extension Core-XPath (in)equality tests attributes elementsXML document named Core-Data-XPath work Bojanczyk, Muscholl,Schwentick, Segoufin (2009). Here, call logic XPath= . Models XPath=data trees seen XML documents. data tree tree whose nodescontains label finite alphabet data value infinite domain (see Figure 1example). relax condition finiteness consider also infinite datatrees, although results hold also finite structures.main characteristic XPath= allow formulas form h = i,, path expressions, navigate tree using axes: descendant, child, ancestor,next-sibling, etc., make tests intermediate nodes. formula truenode x data tree nodes y, z reached relations denoted, , respectively, data value equal data value z.Recent articles investigate several algorithmic problems logics evaluated datatrees. example, satisfiability evaluation discussed works Figueira(2010) Bojanczyk Parys (2011). particular, logics studied articledecidable satisfiability problem (Figueira & Segoufin, 2011; Figueira, 2012); toolsinvestigate expressive power still lacking. good reasons this:presence joins data values, classical notions Ehrenfeucht-Frasse gamesstructural bisimulations difficult handle. article take first stepstowards understanding expressive power model theory XPath= data trees.article focus basic model theory tool bisimulations, definesstructural conditions necessary ensuring two models coincide propertiesexpressible logic. Whereas basic notion bisimulation introducedbasic modal logic, one find adequate notions bisimulations different logics,sense capture notion indistiguishability logic. challengefind adequate notions bisimulation logics XPath, whose navigation akinmodal logics PDL, also test equality data values datatree.Contribution: XPath= navigate data tree means axes like child (thatnote ), descendant ( ), parent (), ancestor ( ), etc. XPath= also navigatedata tree horizontally, going next previous sibling current node. However,focus vertical axes allow downward upward exploration. particular,discuss following languages: XPath= () (XPath= ); XPath= () (XPath=); XPath= ( ) (XPath= ); XPath= ( ) (XPath= ,, ); positive fragments. main contributions summarizedfollows:272fiModel Theory XPath Data Trees. Part I: Bisimulation Characterization3 introduce bisimulation notions XPath= (), XPath= ( ), XPath= ( ),XPath= (), XPath= ( ) show precisely characterize logicalequivalence relation corresponding logic. also consider fine grained versionsbisimulations indexed two measures formula complexity. firstmeasure formula complexity consists maximum number nested axesformula, call downward depth case XPath= () vertical depthcase XPath= (). second one number nested subformulas, callednesting depth.notion bisimulation XPath= () relies normal form alsointroduce. Basically, normal form restricts navigation expressionssimple: either going downward going upward downward. Similarnormal forms langauges trees folklore, work consists mainlyadapting setup tests data values.also show simulations associated defined bisimulations characterizepositive fragments logics: formula equivalent positive formulainvariant simulations.4 characterize XPath= () fragment first-order logic data trees(over signature includes child relation equivalence relation)invariant bisimulations. consider XPath= () instead characterization fails show counter-example. However, weaker result stillestablished, namely first-order formula bisimulation-invariant, bisimulation notion corresponding fixed number nested axes, equivalentXPath= () formula.Using bisimulations show (non)expressivity results XPath= 5.show, example, formulas XPath= () nesting depth n+1 downwarddepth expressive power nesting downward depth nrespectively, long n < d.results proved class arbitrary (possibly infinite) data trees,class finite data trees.1.1 Related Worknotion bisimulation introduced independently van Benthem (1976)context modal correspondence theory, Milner (1980) Park (1981) concurrencytheory, Forti Honsell (1983) non-wellfounded set theory (for historicaloutlook see work Sangiorgi, 2009). classical work defines standard notionbisimulation notion suitably adapted particular, given logic.notion bisimulation given logic L defines two models indistinguishableL, is, formula L true one model falseother. XPath known closely connected known modal languages,PDL modal -calculus, depending fragments taken account (ten Cate,Fontaine, & Litak, 2010). However, fragments studied hitherto data unaware,is, allowing express structure model well fixed set labels.273fiFigueira, Figueira, & Arecesbest knowledge present first work bisimulations invariancelogics data tests.Bisimulations also used obtain model theoretic characterizations identifiesexpressive power logic L1 terms bisimulation invariant fragmentlogic L2 which, hopefully, better understood. challenge, here, pinpointappropriate notion bisimulation required adequate framework logic L2 .classical example result kind Van Benthems characterizationbasic modal logic bisimulation (with standard notion bisimulation) invariantfragment first-order logic (van Benthem, 1976). Van Benthems original resultarbitrary structures proved hold finite structures Rosen (1997). proofsimplified unified Otto (2004a, 2006), later expanded Dawar Otto(2009) classes structures. formalisms different expressive poweralso considered querying data trees, first-order logic two variables(Bojanczyk et al., 2009), tree patterns (David, 2008; Figueira & Libkin, 2014), registerautomata (Neven, Schwentick, & Vianu, 2004), -calculus registers (Jurdzinski &Lazic, 2011), datalog programs (Abiteboul, Bourhis, Muscholl, & Wu, 2013).absence data values, logics semi-structured databases often seen modallogics. fact, structural characterizations XPath without equality test studiedwork Gyssens, Paredaens, Gucht, Fletcher (2006), XPath knowncaptured PDL (Harel, 1984), whose bisimulation well-understood (Blackburn, de Rijke,& Venema, 2001). natural look intuitive bisimulation definitionXPath= .first significant result concerning algorithmic solution bisimulation problem basic modal logic given Hopcroft (1971), polynomial time algorithm state minimization deterministic finite automaton. problem equivalentdetermine coarsest partition set stable respect finite set functions. Paige Tarjan (1987) solved problem general case,restriction stability concerns finite set relations. Kanellakis Smolka (1990)first recognize algorithm Paige Tarjan used determinemaximum bisimulation basic modal logic arbitrary graph. Hencedecided polynomial time whether two nodes finite models bisimilar basicmodal logic though length actual formulas distinguish two non-bisimilarnodes cannot polynomially bounded respect size models (Figueira &Gorn, 2010). case, deciding whether two nodes finite data trees bisimilaralso solved polynomial time.preliminary version present paper appeared work Figueira, Figueira,Areces (2014). Also, continuation (a Part II): work Abriola, Descotte,Figueira (2015), preliminary version Abriola, Descotte, Figueira (2014),address model theoretical questions definability separation,bisimulation notions pairs nodes (instead single nodes) capture ideaindistinguishability means path expressions (instead node expressions).274fiModel Theory XPath Data Trees. Part I: Bisimulation Characterization2. PreliminariesLet N = {1, 2, 3, . . . } let [n] = {1, . . . , n} n N. use symbol denotefinite alphabet, denote infinite domain (e.g., N) data values.examples consider = N. write empty string.Let Trees(A) set ordered unranked trees arbitrary alphabet A.say data tree tree Trees(A D) finite set labelsinfinite set data values. Figure 1 shows example (finite) data tree.xa, 2a, 2b, 2b, 9z b, 5b, 3a, 2b, 1b, 2Figure 1: data tree Trees(AD) = {a, b} = N.data tree finitely branching every node finitely many children.given data tree , denote set nodes. use letters x, y, z, v, w variablesnodes. Given node x , write label (x) denote nodes label,data(x) denote nodes data value.nGiven two nodes x, write xy child x, xy descendant10x distance n. particular, , identity relation.nwrite xy denote (x, y) reflexive transitive closure . (x) denotesnset descendants x distance n, (y) denotes sole ancestordistance n (assuming one).Let P property nodes data trees. property P true node u datatree , say (T , u) satisfies P . binary relation R nodes data trees,say property P R-invariant whenever following condition holds: everydata tree u , (T , u) satisfies P (T , u) R-related (T 0 , u0 ) (T 0 , u0 )satisfies P .introduce query language XPath adapted data trees abstractions XMLdocuments. work simplification XPath, stripped syntactic sugar.consider fragments XPath correspond navigational part XPath 1.0 dataequality inequality. XPath= two-sorted language, path expressions (thatwrite , , ) node expressions (that write , , ). fragment XPath= (O),{, , , }, defined mutual recursion follows:, ::= | | | [], ::= | | | | hi | h = | h 6={}aAformula XPath= (O) either node expression path expression.formally define semantics XPath= follows, data tree:275fiFigueira, Figueira, & Areces[[]]T = {(x, y) | xy}[[ ]]T = reflexive transitive closure [[]]T[[]]T = {(x, y) | yx}[[ ]]T = reflexive transitive closure [[]]T[[]]T = {(x, x) | x }[[]]T = {(x, z) | (y ) (x, y) [[]]T , (y, z) [[]]T }[[ ]]T = [[]]T [[]]T[[[]]]T = {(x, x) | x [[]]T }[[a]]T = {x | label (x) = a}[[]]T = \ [[]]T[[ ]]T = [[]]T [[]]T[[hi]]T = {x | (y ) (x, y) [[]]T }[[h = i]]T = {x | (y,z )(x, y) [[]]T , (x, z) [[]]T , data(y) = data(z)}[[h 6= i]]T = {x | (y,z )(x, y) [[]]T , (x, z) [[]]T , data(y) 6= data(z)}example, data tree shown Figure 1,[[h [ b h[b] 6= [b]i ]i]]T = {x, y, z},formula reads: descendant node labeled b, two children labeled bdifferent data values.data tree u , say , u pointed data tree, write, u |= denote u [[]]T , say , u satisfies . say nodeexpressions , XPath= equivalent (notation: ) iff [[]]T = [[]]T datatrees . Similarly, path expressions , XPath= equivalent (notation: ) iff[[]]T = [[]]T data trees .fragment downward XPath denoted XPath= () vertical XPathdenoted XPath= ().terms expressive power, easy see unessential: every XPath= nodeexpression equivalent 0 path expressions. 0 computedexponential time without incrementing maximum number nested axesmaximum number nested subformulas. enough use following equivalenceseliminate occurrencesh fi h fih( 0 ) 0 h 0 h0 0h fi ( 0 ) 0 h fi 0 h fi 0 0fi {=, 6=}. henceforth assume formulas contain union pathexpressions. sequel see situations also expressions form[] sometimes avoided (3.2.1), although downward axes(Lemma 10).276fiModel Theory XPath Data Trees. Part I: Bisimulation Characterization2.1 Translating First-Order Logicsection show truth-preserving translation XPath= ()first-order logic appropriate signature. so, first must interpret data treesrelational structures, standard way: using binary childrelation, equivalence relation testing data equality, monadic relations testlabels. Fix signature binary relations, unary predicate PaA. data tree seen first-order -structurePaT= {(x, y) 2 | child x};= {(x, y) 2 | data(x) = data(y)};= {x | label (x) = a}.give translation XPath first-order logic . tranlsationfunction indexed free variables formula produced one node expressions,two path expressions.(a A)Trx (a) = Pa (x)Trx ( ) = Trx () Trx ()( {, })Trx () = Trx ()Trx (hi) = (y)Trx,y ()Trx (h = i) = (y)(z) z Trx,y () Trx,z ()Trx (h 6= i) = (y)(z) 6 z Trx,y () Trx,z ()(y new variable)(y, z new variables)(y, z new variables)Trx,y () = (x = y)Trx,y () = (xy)Trx,y () = (yx)Trx,y () = (z) Trx,z () Trz,y ()(z new variable)Trx,y ( ) = Trx,y () Trx,y ()Trx,y ([]) = Trx () (x = y).Proposition 1.1. XPath= () node expression, u [[]]T iff |= Trx ()(u).2. XPath= () path expression, (u, v) [[]]T iff |= Trx,y ()(u, v).Proof. proof structural induction .FO(), let qr() quantifier rank, i.e., depth nesting quantifiers.Observe fi {=, 6=}qr(Trx (hi)) = 1 + qr(Trx ())qr(Trx (h fi i)) = 2 + max(qr(Trx ()), qr(Trx ()))qr(Trx,y ()) = 1 + max(qr(Trx,y ()), qr(Trx,y ()))qr(Trx,y ([])) = qr(Trx ()).277fiFigueira, Figueira, & Areces3. Bisimulationsection define notions bisimulation downward vertical fragmentsXPath, show coincide corresponding logical equivalence relation.case vertical XPath bisimulation notion relies normal formintroduce purpose.3.1 Downward XPathwrite dd() denote downward depth defined follows:dd(a)dd( )dd()dd(hi)dd(h fi i)=====0dd() =max{dd(), dd()}dd() =dd()dd([]) =dd()dd() =max{dd(), dd()}0dd()max{dd(), dd()}1 + dd()A, fi {=, 6=}, path expression empty string . Let`-XPath= () fragment XPath= () consisting formulas dd() `.Let 0 data trees, let u , u0 0 . say , u 0 , u0equivalent XPath= () (notation: , u 0 , u0 ) iff node expressionXPath= (), , u |= iff 0 , u0 |= . say , u 0 , u0 `-equivalentXPath= () (notation: , u ` 0 , u0 ) iff node expression `-XPath= (),, u |= iff 0 , u0 |= .1first show that, every `, finitely many different formulasdd() ` logical equivalence. Formally, usually referred saying `finite index.Proposition 2. ` finite index.Proof. easily shown induction node expression `-XPath= ()unnecessary uses (recall ) qr(Trx ()) bounded.well-known result first order finitely many nonequivalent formulasbounded quantifier rank. Hence finitely many nonequivalent node expressionsbounded downward depth.Corollary 3. {T 0 , u0 | , u ` 0 , u0 } definable node expression `,T ,u `XPath= ().Proof. Consider conjunction `-XPath= () formulas , u |= .Proposition 2, logical equivalence, finitely many s, henceconjunction equivalent finite one. Define `,T ,u finite conjunction.1. Two pointed data trees equivalent indistinguishable formulas given logic.adopted terminology literature, used first word, second.reader confuse notion equivalent formulas.278fiModel Theory XPath Data Trees. Part I: Bisimulation Characterization3.1.1 Bisimulation `-bisimulationLet 0 two data-trees. say u u0 0 bisimilarXPath= () (notation: , u 0 , u0 ) relation Z 0 uZu0x x0 0Harmony: xZx0 label (x) = label (x0 ).nnZig: xZx0 , xv xw v 0 , w0 0 x0 v 0 , x0 w01. data(v) = data(w) data(v 0 ) = data(w0 ),2. (v) Z (v 0 ) 0 < n,3. (w) Z (w0 ) 0 < m.following picture illustrates intended requirements.xxT00Zn9v 0n=)8w(6=(6=)=8v9w0nZag: xZx0 , x0 v 0 x0 w0 v, w xv, xwitems 1, 2 3 verified.bisimulation generalizes classical bisimulation relation (Sangiorgi, 2009),Zig simply: xZx0 , xv, v 0 x0 v 0 vZv 0 (the Zagsymmetrical). fact, restrict Zig condition n = = 1 v = w,Zag condition n = = 1 v 0 = w0 , obtain relation corresponds,precisely, classical bisimulation relation. Thus, bisimilar notiondefine implies bisimlar classical notion.example, dotted lines following two data trees represent bisimulationXPath= ().$#xa, 1y1a, 2 a, 2y2x0a, 1a, 2y0v a, 1 a, 3 ww0a, 3 a, 1 v 0T0279fiFigueira, Figueira, & Arecesnotion bisimulation seen, usual, Ehrenfeucht-Frasse game,Spoiler tries find difference (through logics glasses) nodes u u0 ,Duplicator tries copy him, showing u u0 indistinguishable. gain intuitionnotion bisimulation, briefly explain associated game (without goingtechnical details). board consists data trees 0 ,two pebbles p p0 , along game, p always node ,p0 always node 0 . Initially, p u, p0 u0 . u u0satisfy label Spoiler declared winner game finishes. gameproceeds rounds. Suppose round, pebbles p p0 positions xx0 satisfying label. round consists one move Spoiler, followedanswer Duplicator, final decision made spoiler.Step 1. Spoilers first move: chooses pebble, two integers n m, twopaths, one length length n. paths start x chose px0 chose p0 . Suppose chose p (the case p0 analogous datatree 0 instead ). first path represented w xw,nsecond path represented v xv.Step 2. Duplicators answer: shows two paths 0 (or case duplicatorchosen p0 instead p), one length length n, startingx0 , data(u) = data(v) iff data(u0 ) = data(v 0 ). paths,Spoiler declared winner game finishes.Step 3. Final move Spoiler: chooseseither {0 . . . n 1}, places pebble p (v) pebble p0 (v 0 ){0 . . . 1}, places pebble p (w) pebble p0 (w0 )pebbles two nodes satisfy label, game proceeds.Else, Spoiler declared winner game finishes.Duplicator wins spoiler never declared winner game infinitely many rounds.resemblance game rules Harmony, Zig Zag evident. One seespoiler winning strategy game whose initial pebbles placed x x0, u 0 , u0 .interesting compare game one capturing bisimulationbasic modal logic. latter, Spoiler chooses successor x (or x0 ) followingaccessibility relation. also case Core-XPath PDL. case,adding comparison data values, Spoiler choose whole path (in fact, two paths),making game less local one basic modal logic (or Core-XPath PDL).analogous view game XPath= () would allow Spoiler build pathsstep-by-step fashion, is, extending paths constructed far new singlenode, thus giving Duplicator less certainty. possible change rules gamesecond step round Spoiler builds paths step-by-step fashion?No. Even Spoiler freedom extend step-by-step one paths,would unfair Duplicator. Indeed, consider last example bisimilar , x0 , x0 . Spoiler would initially declare first path x0 length 0,280fiModel Theory XPath Data Trees. Part I: Bisimulation CharacterizationDuplicator define first path x length 0. Spoiler construct,step-by-step, second path. Initially shows path x0 0 Duplicator. Duplicatortwo possible answers: either path xy1 xy2 . Suppose chooses xy1 (thecase xy2 analogous). Spoiler extends path x0 0 x0 0 w0 . Since y1one child, Spoiler one possible answer extending path: xy1 v.Next, Spoiler declares done: constructed two paths starting x0 , onelength 0 one x0 0 w0 , length 2. Duplicator constructed onepath length 0 xy1 v. Duplicator looses, data(x0 ) 6= data(w0 )data(x) = data(v). example shows game fairness established spoilertells duplicator advance two paths chooses.data tree u , let |u denote subtree induced {v |n(n) uv}. Observe root |u u. following results straightforwardconsequences definition bisimulation:Observation 4. , u (T |u), u.Observation 5. subtree 0 u , u 0 , u.say u u0 0 `-bisimilar XPath= () (notation: , u `family relations (Zj )j` 0 uZ` u0 j `,x x0 00 , u0 )Harmony: xZj x0 label (x) = label (x0 ).nZig: xZj x0 , xv xw n, j v 0 , w0 0nx0 v 0 , x0 w01. data(v) = data(w) data(v 0 ) = data(w0 ),2. (v) Zjn+i (v 0 ) 0 < n,3. (w) Zjm+i (w0 ) 0 < m.nZag: xZj x0 , x0 v 0 x0 w0 n, j v, wnxv, xw items 1, 2 3 verified.notion `-bisimulation corresponds game spoiler duplicator` rounds.Clearly , u 0 , u0 , u` 0 , u0 `.Observation 6. Suppose 0 height `, u , u0 0 ., u ` 0 , u0 iff , u 0 , u0 .data tree u , let |` u denote subtree induced {v |n(n `) uv}.Observation 7. , u ` (T |` u), u.281fiFigueira, Figueira, & Areces3.1.2 Equivalence Bisimulationshow coincides finitely branching data trees, `coincides ` .Theorem 8.1. , u 0 , u0 implies , u 0 , u0 . converse also holds 0 finitelybranching.2. , u ` 0 , u0 iff , u ` 0 , u0 .theorem shown consequence Propositions 9 11:Proposition 9. , u ` 0 , u0 implies , u ` 0 , u0 .Proof. actually show , u` 0 , u0 via (Zi )i` 0 n j `,dd() j, dd() j:1. xZj x0 , x |= iff 0 , x0 |= ;nn2. xv, x0 v 0 (v) Z(jn)+i (v 0 ) 0 n, (x, v) [[]]T iff0(x0 , v 0 ) [[]]T .show 1 2 induction || + ||.Let us see item 1. base case = A. Harmony, label (x) =label (x0 ) , x |= iff 0 , x0 |= . Boolean cases straightforward.Suppose = h = i. show , x |= 0 , x0 |= , assume , x |= .nSuppose v, w n, j xv, xw, (x, v) [[]]T , (x, w)n[[]]T data(v) = data(w). Zig, v 0 , w0 0 x0 v 0 , x0 w0 ,(v) Zjn+i (v 0 ) 0 n, (w) Zjm+i (w0 ) 0 m, data(v 0 ) =00data(w0 ). inductive hypothesis 2 (twice), (x0 , v 0 ) [[]]T (x0 , w0 ) [[]]T . Hence0 , x0 |= . implication 0 , x0 |= , x |= analogous. case = h 6=shown similarly. case = hi similar (and simpler) previous case.Let us analyze item 2. show direction. base case0{, }. = v = x n = 0. Since v 0 = x0 , conclude (x0 , v 0 ) [[]]T .0= xv , n = 1. Since x0 v 0 , (x0 , v 0 ) [[]]T .inductive step, let x0 , . . . , xn x00 , . . . , x0n 0x = x0 x1 x2 xn = v0x =x00 x01 x02 x0n=v0,0 ,0xi Zji x0i 0 n. Assume, contradiction, (x0 , v 0 )/ [[]]T . Then,0subformula k {0, . . . , n} , xk |= , x0k 6|= nextLemma shows.nnLemma 10. Let path expression XPath= ( ). Let xv x0 v 00(x, v) [[]]T (x0 , v 0 )/ [[]]T . subformulakkk {0, . . . , n} , (v) |= 0 , (v 0 ) 6|= .282fiModel Theory XPath Data Trees. Part I: Bisimulation CharacterizationProof Lemma. Let x = v0 v1 vn = v x0 = v00 v10 vn0 = v 0 .proceed induction ||. = x = v n = 0. Hence x0 = v 00(x0 , v 0 ) [[]]T , contradicts hypothesis, thus statement trivially0true. = xv n = 1. Hence x0 v 0 (x0 , v 0 ) [[]]T . casealso trivial. case = similar.0Suppose = []. Since (x0 , v 0 )/ [[]]T , x0 = v 0 0 , v 0 6|= . Takingk = 0 = statement holds. Observe subformula .Suppose = . k (x, vk ) [[]]T (vk , v) [[]]T .000Since (x0 , v 0 )/ [[]]T , (x0 , vk0 )/ [[]]T (vk0 , v 0 )/ [[]]T . either case, applyinductive hypothesis straightforwardly.contradicts inductive hypothesis 1.Proposition 11. , u ` 0 , u0 implies , u ` 0 , u0 .Proof. Fix u u0 0 , u ` 0 , u0 . Define (Zi )i`xZi x0iff , x 0 , x0 .show Z `-bisimulation , u 0 , u0 . hypothesis, uZ` u0 . Fixh `. construction, Zh satisfies Harmony. Let us see Zh satisfies Zig (the caseZag analogous). Suppose xZh x0 ,x = v0 v1 vn = vx = w0 w1 wm = w,,data(v) = data(w) (the case data(v) 6= data(w) shown similar way),m, n h. Let P 02 definednP = {(v 0 , w0 ) | x0 v 0 x0 w0 data(v 0 ) = data(w0 )}.Since , x h 0 , x0 , dd(hn =m i) h , x |= hn =m i, conclude P 6= .next show exists (v 0 , w0 ) Pi. x0 = v00 v10 vn0 = v 0 0 ,0 = w 0 0 ,ii. x0 = w00 w10 wmiii. (i {0, . . . , n}) , vi hi 0 , vi0 ,iv. (j {0, . . . , m}) , wj hj 0 , wj0 ,hence Zig satisfied Zh . way contradiction, assume (v 0 , w0 ) Psatisfying ii either(a) (i {0, . . . , n}) , vi 6hi 0 , vi0 ,(b) (j {0, . . . , m}) , wj 6hj 0 , wj0 .283fiFigueira, Figueira, & ArecesFix > tautology dd(>) = 0. (v 0 , w0 ) P define two familiesnode expressions,0v0 ,w0 , . . . , nv0 ,w0v00 ,w0 , . . . , vm0 ,w0 ,satisfying dd(iv0 ,w0 ) h {0, . . . , n} dd(vj 0 ,w0 ) h jj {0, . . . , m} follows:Assume (a) smallest number , vi 6hi 0 , vi0 . Let iv0 ,w0dd(iv0 ,w0 ) h , vi |= iv0 ,w0 0 , vi0 6|= iv0 ,w0 . k{0, . . . , n} \ {i}, let kv0 ,w0 = >, k {0, . . . , m}, let vk0 ,w0 = >.Suppose (a) hold. (b) holds. Let j smallest number, wj 6hj 0 , wj0 . Let vj 0 ,w0 dd(vj 0 ,w0 ) h j , wj |= vj 0 ,w00 , wj0 6|= vj 0 ,w0 . k {0, . . . , m} \ {j}, let vk0 ,w0 = >, k {0, . . . , n}, letkv0 ,w0 = >.{0, . . . , n} j {0, . . . , m}, let=^iv0 ,w0(v 0 ,w0 )Pj =^vj 0 ,w0 .(1)(v 0 ,w0 )PHowever conjunctions could potentially infinite trees infinitely branching. Since dd(iv0 ,w0 ) h i, Proposition 2 finitely many non-equivalent nodeexpressions iv0 ,w0 applies vj 0 ,w0 . Hence, infinite conjunctions (1)equivalent finite ones, may assume j well-formed formulas. Finally, let = [0 ][1 ] [n ] = [0 ][1 ] [m ]. construction,dd(), dd() h dd(h = i) h.clear construction (x, v) [[]]T (x, w) [[]]T , therefore , x |=h = i. see next 0 , x0 6|= h = i. contradicts , x h 0 , x0 ,hence done. Suppose 0 , x0 |= h = i. (v 0 , w0 ) P00(x0 , v 0 ) [[]]T (x0 , w0 ) [[]]T . particular, ii true, either (a)0(b) hold. first case, have, construction, (x0 , v 0 )/ [[]]T , second0clear (x0 , w0 )/ [[]]T . either case, arrive contradiction.Proof Theorem 8. Item 2 direct consequence Propositions 9 11.left-to-right argument item 1 seen consequence item 2. Indeed,, u 0 , u0 implies , u ` 0 , u0 `, item 2 implies , u ` 0 , u0`, turn entails , u 0 , u0 .right-to-left argument item 1 similar Proposition 11, definingZ xZx0 iff , x 0 , x0 . conjunctions (1) finite 0 finitelybranching, P finite (the fact finitely branching used show Zagsatisfied).284fiModel Theory XPath Data Trees. Part I: Bisimulation Characterization3.2 Vertical XPathstudy bisimulation XPath= (). Interestingly, notion give simplerone XPath= () due normal form enjoyed logic.downward fragment XPath= used dd() measure maximum depthcurrent point evaluation formula access. vertical fragmentXPath= , need define maximum distance r going downwardmaximum distance going upward formula reach. call pair (r, s)vertical depth formula (notation: vd()). nesting depth formula(notation: nd()) maximum number nested [ ] appearing .vd(a)vd( )vd()vd(hi)vd(h fi i)=====(0, 0)vd() = (0, 0)max{vd(), vd()}vd() = vd()vd()vd([]) = max{vd(), vd()}vd()vd() = max{(0, 0), vd() + (1, 1)}max{vd(), vd()}vd() = max{(0, 0), vd() + (1, 1)}nd(a)nd( )nd()nd(hi)nd(h fi i)=====0max{nd(), nd()}nd()nd()max{nd(), nd()}nd()nd()nd([])nd()nd()=====max{nd(), nd()}01 + nd()00where, A, fi {=, 6=}, + max performed component-wise, pathexpression empty string .Let (r, s, k)-XPath= () set formulas XPath= () vd() (r, s)nd() k. Let , u 0 , u0 pointed data trees. say , u 0 , u0equivalent XPath= () (notation: , u 0 , u0 ) iff XPath= (),, u |= iff 0 , u0 |= . , x 0 , x0 (r, s)-equivalent [resp. (r, s, k)-equivalent]0 00 0XPath= () (notation: , xr,s , x [resp. , x r,s,k , x ]) satisfynode expressions XPath= () vd() (r, s) [resp. vd() (r, s)nd() k].3.2.1 Normal Formdefine normal form XPath= () implicitly used definitionbisimulation section. n 0, let n denote concatenation n symbols .I.e., 0 empty string , 1 = , n+1 = n (similarly n ).path expression XPath= () downward [resp. upward] formn[] [resp. []n ] n > 0 XPath= (). example, [hi] downwardexpression whereas [hi] not. up-down expression expression form ,, upward downward. Henceforth use , ,denote upward expressions , , denote downward expressions , ,denote up-down expressions. Note particular downward upward expressionup-down expression. XPath= () formula up-down normal form everypath expression contained up-down every data test form h fifi {=, 6=}. Next, show every XPath= () formula equivalent285fiFigueira, Figueira, & Arecesone up-down normal form. course, idea replacing child axes parent axesmeans novel, number works rewriting expressionsequivalent ones improve performance streamability, works Olteanu(2007) Olteanu, Meuss, Furche, Bry (2002). However, rewrite systems aimremoving backward axes (parent, ancestor, etc) maintaining equivalence root,different end, maintain equivalence path expressions pairnodes. Further, doubt normal form useful scenarios sincecomputational streamability perspective resulting formula up-down normalseems complex. Although regular, nested modalitiesintroduces parent axes, shown later. motivation normal formsimplify defintion bisimulation means rendering formula simplepossible form.Given path expression , navigation (notation: nav()) string{, } results removing node expressions [] . example,nav([hi][h = i][b]) = .Proposition 12. Let (r, s, k)-XPath= (), XPath= () up-downnormal form following hold1. ;2. vd( ) = (r, s);3. nd( ) k (r + + 2).Proof. idea factorize path tree going nodetest expression. Consider instance expression = [a]. immediateequivalent up-down expression [h[h[a]i]i], up-down normalform.use following directed equivalences translate path expressionequivalent up-down expression.()[1 ][2 ] [1 2 ]n 1 0 1 nn n1 00 1 n(merge)[hn n 1 1 0 i]n[h0 1 . . . n i]n[h0 1 n i](factor )(shift-r )(shift-l )expressions above, empty string, form [1 ][2 ] . . . [n ],path expression, empty string, path expression.idea (factor ) converts expression goes n times n timesnode expression, this, test done i-th node goingmerged (n i)-th test going up. example, [a][c][b][h[a][b][c]i]. hand, (shift-r ) (shift-l ) group node testslowest node expression, making use fact parent relation functional.Thus, example [a][b] [h[b][a]i] [a][b] [h[a][b]i]. thus clearleft right expressions semantically equivalent.286fiModel Theory XPath Data Trees. Part I: Bisimulation Characterizationfollowing lemma treats case path expressions:Lemma 13. Let XPath= ()-path expression vd() = (r, s) nd() =k, up-down path expression that:1.2. vd( ) = (r, s),3. nd( ) k + r + + 1.Proof Lemma. first apply rule (factor ) many times possible. clearnav() form n n, 0 rule (factor ) cannotapplied done. Hence, suppose nav() contains pattern . Let= 111 = 1 n. . . 01 . . . n1 1{z}| 1matches (factor )22 n. . . 02 . . . n2 22|{zmatches (factor )...}m1 n. . . 0m . . . nmm ,|{z}matches (factor )nav( ), nav(m ) , nav( ), nav(1 ) , ji empty string,i,ji,j[i,j1 ][2 ] . . . [hi,j ]. Furthermore, assume maximal (i.e., impossibleapply (factor ) s) length minimal (i.e.,case nav(i ) ends nav(i+1 ) begins ). Observenav(i ) . apply rule (factor ) 1 marked places obtain11 1 12 = 1 [hn1 11 0 i]1 n1|{z}(factor ) applied22 2 22 [hn2 11 0 i]2 n2|{z(factor ) applied...}m1 [hn11 0 i] ,nm{z}|(factor ) appliedLet vd(nav(1 )) = (r1 , s1 ). Since nav() = nav( 1 ) contains pattern ,r1 > 0. shown vd( 2 ) = (r, s), nd(2 ) nd(1 ) + 1,vd(nav(2 )) (r1 1, s1 ). repeat procedure 2longer apply rule (factor ), end up-down path expression f287fiFigueira, Figueira, & Areces1. f 1 ,2. vd( f ) = (r, s),3. nd(f ) nd(1 ) + r1 .applying () (merge) f many times possible, obtainequivalent 0 , vertical nesting depth f , form0 = 1 2 . . . n n+1 n+2 . . . n+m ,(possibly empty) string form [1i ] . . . [ni ]. apply (shift-l )(shift-r ) 0 obtain equivalent 00 vertical depth (i.e. vd(00 ) =vd(0 ) = (r, s)) nesting depth equal nd(0 ) + 1 form= 0 n 00 ,0 00 empty string form []. Observe nd( ) =nd(0 ) + 1 k + r1 + 1 r + + 1, satisfies requirements lemma.concludes proof Lemma 13.following lemma treats case data tests:Lemma 14. Let , up-down path expressions let = h fi (forfi {=, 6=}) vd() = (r, s) nd() = k. up-down pathexpression that:1. h ,2. vd( ) = (r, s),3. nd( ) k + 1.Proof Lemma. Let us analyse case = [ ]n [ ] =[ ]n [ ], n + > 0, n + > 0, , , , up-downnormal form (the remaining cases = = simpler). Suppose,without loss generality, n n .Hence, h fi h i,= [ ]n [ h fi n n [ ]i].clear formulas equivalent (cf. picture below).288fiModel Theory XPath Data Trees. Part I: Bisimulation Characterization}}||{z|}||{z}{z{zn{z{z[ ]|l||z"#[ ]n}{nnn{z"#}[][[ ]}}[ ][]^]Moreover, right-hand formula one nesting lefthand formula, vertical depth (r, s). concludes proofLemma 14.induction , using Lemmas 13 14, one showdesired.3.2.2 Finite IndexContrary case XPath= () (cf., Proposition 2), logical equivalence relationrestricted XPath= ()-formulas bounded vertical depth infinitely many equivalenceclasses.Proposition 15. r + 2r,s infinite index.}Proof. show every r, r + = 2 infinite set {r,si0non-equivalent node expressions vertical depth (r, s). thus follows every r,r + 2,r,s infinite index.Consider following formulas.i+11,1= h = [1,1]i01,1= h =i+10,2= h = [1,1]i00,2= h =i+12,0= h = [1,1]i02,0= h =n ) = (r, s) nd( n ) = n every n. formula n intuitively saysNote vd(r,sr,sr,schain length n depicted Figure 2.n , xn0data tree Tn figure, Tn , xr,s |= r,sn r,s 6|= r,s}n0 > n. Therefore, {r,si0 infinite set non-equivalent formulas vertical depth(r, s).proof proposition need use formulas unbounded nestingdepth. fact, restricted bounded nesting depth finitely manyformulas logical equivalence, stated next.289fiFigueira, Figueira, & Arecesx2,0Tn :x1,1...x0,2n timesFigure 2: Model verifying ij n verifying l l < n. Dotted linesrepresent equal data values.Proposition 16.r,s,k finite index.Proof. argument proof Proposition 2.0 0Corollary 17. {T 0 , u0 | , ur,s,k , u } definable node expression (r, s, k)XPath= ().Proof. Similar proof Corollary 3.3.2.3 Bisimulation (r, s, k)-bisimulationadvantage normal form presented Section 3.2.1 makes possible usesimple notion bisimulation. disadvantage that, since preservecorrespondsnesting depth,r,s,k correspond precisely r,s,k , althoughprecisely . Nonetheless, obtain, r, s, k,r,s,kr,s,k r,s,k(r+s+2) .Let 0 two data-trees. say u u0 0 bisimilarXPath= () (notation: , u 0 , u0 ) iff relation Z 0 uZu0x x0 0Harmony: xZx0 label (x) = label (x0 ),nnZig: xZx0 , x z 0 , z 0 0 0 x0 , 0 z 0 , data(z)= data(x) data(z 0 ) = data(x0 ), zZz 0 .following picture illustrates intended requirements290fiModel Theory XPath Data Trees. Part I: Bisimulation CharacterizationT09y 08yn9z 0n=)x(6=(6=)=8zZx0nZag: xZx0 , 0 x0 0 z 0 y, z x, z, data(z)= data(x) data(z 0 ) = data(x0 ), zZz 0 .definitions heavily rely normal form Proposition 12. fact,normal form strictly necessary giving notion bisimulation verticalfragment. case downward fragment, normal form used, every pathexpression essentially repetition node test child relation. contrary,case vertical fragment, use normal form would beneficial.notion bisimulation taking account existence normal form wouldrule Zig form: xZx0 n1 , . . . , nk , m1 , . . . , mk , n1 , . . . , nk m1 , . . . , mk{1, . . . , k},v1i . . . vni w1i . . . wm{1, . . . , k},v1i . . . vni w1i . . . wmv1i = w1i v1i = w1i= v i+1 w = v i+1wmni+1mini+1x = vn1 1 x = vn1 10i {1, . . . , k}, v 0i , . . . , v 0i , w 0i , . . . , w 0iv10i , . . . , vn0ii 0 , w10i , . . . , wm11nimi0 {1, . . . , k}0i 0 ,v10i . . . vn0ii 0 w10i . . . wm0i 0 ,v10i . . . vn0ii 0 w10i . . . wmv10i = w10i v10i = w10i0i = v 0i+1 w 0i = v 0i+1wmni+1mini+1x = vn011 x = vn011vji Zvj0i , wji Zwj0i , vji Z vj0i , wji Z wj0idata(wnk k ) = data(wnk k ) iff data(wn0k ) = data(wn0k )kk291fiFigueira, Figueira, & ArecesIntuitively, definition establishes every paths p p going down, manytimes , similar paths p0 p0 , going many times,respecting shape p p respectively j-th node p connectedj-the node p0 via Z, nodes along p, datavalues last node p p equal data values lastnodes p0 p0 so.definition natural extension downward bisimulation, insteadconsidering downward paths, considers general ones. happensdownward bisimulation, every intermediate node paths relatedcorresponding node 0 . one immediately see, definition quite longchecks many conditions. Working normal forms allow us get much simplerdefinition bisimulation, two main advantages: a) one pathdata tree, b) require intermediate nodes related Z. twofeatures direct consequences up-down normal form, normal form a)compares values root (so one non-empty path expressiondiamond node expression) b) make tests beginning endpath expressions (but intermediate nodes). However, notice duenormal form definitions denote bisimulation relation.say u u0 0 (r, s, k)-bisimilar XPath= () (notation:00 0k, ur,s,k , u ) family relations (Zr,s )r+sr+s,kkk u0 r + r + s, k k, x x0 0 followinguZr,sconditions hold.k x0 label (x) = label (x0 ).Harmony: xZr,snk x0 , x z n r + n 0 , z 0 0Zig: xZr,sn0 x0 , 0 z 0 , following hold1. data(z) = data(x) data(z 0 ) = data(x0 ),0002. k > 0, zZrk10 ,s0 z r = r + n m, = n + m.nk x0 , 0 x0 0 z 0 n r + n y, zZag: xZr,snx, z, items (1) (2) verified.nnk x0 , x 0 x0 follows yZ k1 0 , r 0 = r + n,Observation 18. xZr,sr0 ,s0k case bisimilarity.s0 = n. occurs Z instead Zr,sdata tree u , let |sr u denote subtree inducedn{v | (m s) (n r + m) (w ) wu wv}.Observation 19. , ur,s,k (T |r u), u.292fiModel Theory XPath Data Trees. Part I: Bisimulation Characterization3.2.4 Equivalence Bisimulationnext result says coincides finitely branching data trees, statesprecisely wayr,s,k related r,s,k .Theorem 20.1. , u 0 , u0 implies , u 0 , u0 . converse also holds 0finitely branching.0 00 02. , ur,s,k(r+s+2) , u implies , u r,s,k , u .0 00 03. , ur,s,k , u implies , u r,s,k , u .theorem shown consequence following Propositions 2122.0 00 0Proposition 21. , ur,s,k(r+s+2) , u implies , u r,s,k , u .0 0Proof. show , ur,s,k , u viak(Zr,s)r+sr+s,kkn r + n, up-down normal form vd() (r, s),nd() k, upward expression up-down normal form, downwardexpression up-down normal form vd( ), vd( ) (r, s), nd( ), nd( ) k:k x0 , x |= iff 0 , x0 |= .1. xZr,snn0k1 02. x, 0 x0 , x Zr,sx , (x, y) [[ ]]T iff (x0 , 0 ) [[ ]]T .000iff3. z, 0 z 0 , z Zrk10 ,s0 z r = r + n m, = n + m, (y, z) [[ ]]0(y 0 , z 0 ) [[ ]]T .Hence, Proposition 12, main statement follows. simultaneously show 1, 23 induction || + | | + | |.Let us see item 1. base case = A. Harmony, label (x) =label (x0 ) , x |= iff 0 , x0 |= . Boolean cases straightforward.Suppose = h = i. show , x |= 0 , x0 |= , assume , x |= .nSuppose y, z n s, r + n x, z, (x, y) [[ ]]T ,0(y, z) [[ ]]T data(x) = data(z). Zig, 0 , z 0 0 zZrk10 ,s0 zr0 = r + n m, s0 = n + m, data(x0 ) = data(z 0 ). inductive hypothesis 2003, (x0 , 0 ) [[ ]]T (y 0 , z 0 ) [[ ]]T . Hence 0 , x0 |= . implication 0 , x0 |=, x |= analogous. cases = h 6= i, = h fi i, = h fi(fi {=, 6=}) = hi (for up-down normal form) shown similar way.cases = h fi (fi {=, 6=}) trivial.293fiFigueira, Figueira, & ArecesLet us analyze item 2. Let = []n (n 0), let x0 , . . . , xn0x00 , . . . , x0n= x0 x1 xn = x0=x00 x01 x0n=x0,0 ,k1 0000x . Observation 18, x0 Zrk1xZr,s0 ,s0 x0 , r = r + n, = n. Assume0contradiction (x0 , 0 )/ [[ ]]T . necessarily means , x0 |= 0 , x00 6|= .subformula , nd() k 1 nd() (r0 , s0 ) contradictsinductive hypothesis 1.Item 3 shown similar way. Let = [] (m 0), let z0 , . . . , zm00 0z0 , . . . , z= z0 z1 zm = z0=0z00 z10 zm=z0,0 ,000 0 / [[ ]]T . necessarily meanszZrk10 ,s0 z . Assume contradiction (y , z ), xm |= 0 , x0m 6|= . subformula , nd() k 1 nd() (r0 , s0 )contradicts inductive hypothesis 1.0 00 0Proposition 22. , ur,s,k , u implies , u r,s,k , u .0 0kProof. Fix u u0 0 , ur,s,k , u . Define (Zr,s )r+sr+s,kkk 0xxZr,siff, xr,s,k0 , x0 .k (r, s, k)-bisimulation , u 0 , u0 . hypothesis, uZ k u0 .show Zr,sr,sk satisfies Harmony. Let us see Z kfix r + r + s, k k. construction, Zr,sr,sk x0 ,satisfies Zig (the case Zag analogous). Suppose xZr,s= x0 x1 vn = x= z0 z1 zm = z,,data(x) = data(z) (the case data(x) 6= data(z) shown similar way),r + n. Let P 02 definednP = {(y 0 , z 0 ) | 0 x0 0 z 0 data(x0 ) = data(z 0 )}.nn0 0Since , xr,s,k , x , vd(h = i) (r, s), nd(h = i) = 0, , x |= h =ni, conclude P 6= . next show exists (y 0 , z 0 ) Pi. 0 = x00 x01 x0n = x0 00 = z 0 0 ,ii. 0 = z00 z10 zm294fiModel Theory XPath Data Trees. Part I: Bisimulation Characterizationiii. , xr,s,k10 , x0 ,iv. , z 0r ,s0 ,k10 , z 0 , r0 = r + n m, s0 = n + m,k . way contradiction, assumehence, inductive hypothesis, Zig satisfied Zr,s00(y , z ) P satisfying ii either(a) , x 6r,s,k1(b) , z 600 , x0 ;r ,s0 ,k10 , z 0 r0 = r + n m, s0 = n + m.Fix > tautology vd(>) = (0, 0), nd(>) = 0. (y 0 , z 0 ) Pdefine node expressions, y0 ,z 0 y0 ,z 0 , satisfying vd(y0 ,z 0 ) (r, s), nd(y0 ,z 0 ) < kvd(y0 ,z 0 ) (r0 , s0 ), nd(y0 ,z 0 ) < k follows:Suppose (a) holds. Let y0 ,z 0 vd(v0 ,w0 ) (r, s), nd(v0 ,w0 ) < k,, x |= y0 ,z 0 0 , x0 6|= y0 ,z 0 ; let v0 ,w0 = >.Suppose (a) hold. (b) holds. Let y0 ,z 0 vd(y0 ,z 0 ) (r0 , s0 ),nd(y0 ,z 0 ) < k , z |= y0 ,z 0 0 , z 0 6|= y0 ,z 0 ; let y0 ,z 0 = >.Let=^y0 ,z 0(y 0 ,z 0 )P=^y0 ,z 0 .(2)(y 0 ,z 0 )PSince vd(y0 ,z 0 ) (r, s), nd(y0 ,z 0 ) < k, Proposition 16, finitely many nonequivalent formulas y0 ,z 0 . applies formulas y0 ,z 0 . Hence infinite conjunctions (2) equivalent finite ones, therefore without loss generalitymay assume well-formed formulas.Finally, let= []n = [].construction, vd( ) (r, s), nd( ) k. Furthermore, , x |= h =0 , x0 6|= h = i, contradicts fact , x 0 , x0 .r,s,kProof Theorem 20. Items 2 3 shown Propositions 21 22.left-to-right argument item 1 seen consequence item 2. Indeed,0 00 0, u 0 , u0 implies , u(r,s) , u r, s, item 2 implies , u (r,s) , ur, s, turn entalis , u 0 , u0 .right-to-left argument item 1 similar Proposition 22, workingk )0single Z instead (Zr,sr,s,k . converse implication, define Z xZx iff, x 0 , x0 . conjunctions (2) finite 0 finitely branching,P finite (the fact finitely branching used showing Zagsatisfied).Corollary 23.r,s,k finite index.Proof. Immediate Theorem 20 Proposition 16.295fiFigueira, Figueira, & Areces3.3 Simulationsection define notions directed (non-symmetric) simulations XPath= ()XPath= (), done, e.g., works Kurtonina de Rijke (1997) Lutz,Piro, Wolter (2011) modal logics. obtain results similar Theorems 820 relating simulation notion corresponding logical implication.say XPath= formula positive contains negation inequality data tests h 6= i. L one XPath= (), XPath= (), XPath= ( ),XPath= ( ), write L+ positive fragment L.simulation XPath= () [resp. XPath= ()] simply bisimulationZag clause half first condition Zig clause omitted.Observe simulations need symmetric.Formally, say u similar u0 0 XPath= () (notation: , u0, u0 ) iff relation Z 0 uZu0 x x0 0Harmony: xZx0 label (x) = label (x0 ).nnZig: xZx0 , xv xw v 0 , w0 0 x0 v 0 , x0 w01. data(v) = data(w) data(v 0 ) = data(w0 ),2. (v) Z (v 0 ) 0 < n,3. (w) Z (w0 ) 0 < m.u similar u0 0 XPath= () (notation: , u 0 , u0 ) iffrelation Z 0 uZu0 x x0 0Harmony: xZx0 label (x) = label (x0 ).nnZig: xZx0 , x z 0 , z 0 0 0 x0 , 0 z 0 , zZz 0 ,data(z) = data(x) data(z 0 ) = data(x0 ).Relations `r,s,k defined accordingly. define one-way (non-symmetric)logical implication models follows. write , u V 0 , u0( XPath= ()+ ) [T , u |= 0 , u0 |= ].++Define V` , V , Vr,s,k analogous way `-XPath= () , XPath= () , (r, s, k)XPath= ()+ , respectively. bisimulation, coincides V.Theorem 24.1. Let {, }. , u 0 , u0 implies , u V 0 , u0 . converse holds 0finitely branching.2. , u ` 0 , u0 iff , u V` 0 , u0 .0 00 03. , ur,s,k(r+s+2) , u implies , u Vr,s,k , u .296fiModel Theory XPath Data Trees. Part I: Bisimulation Characterization0 00 04. , u Vr,s,k , u implies , u r,s,k , u .Proof. proofs straightforward adaptations proofs Propositions 9 11Propositions 21 22 respectively, ommitted here. particular,part, adaptation proofs Propositions 11 22, simulations definedxZi x0 iff , x Vi 0 , xk 0xZr,sx iff , x Vr,s,k0, xrespectively, conditions (a) (b) page 283 become(a) [i {0, . . . , n} XPath= ()+ ] dd() h , vi |= 0 , vi0 6|= ;(b) [j {0, . . . , m} XPath= ()+ ] dd() h j , wj |= 0 , wj0 6|= ,(a) [i {0, . . . n} XPath= ()+ ] vd() (r + i, i) nd() k 1 , vi |=0 , vi0 6|= ;(b) [j {0, . . . m} XPath= ()+ ] vd() (r + j 0 , j 0 ) j 0 = n + jnd() k 1 , wj |= 0 , wj0 6|=respectively.say 0 substructure 0 data tree results removingnodes , i.e., 0 u, v 0 have: 1) uv iff uv 0 ; 2)label (u) 0 equals label (u) ; 3) data(u) 0 equals data(u) . Equivalently,seen -structures, 0 -substructure induced 0 . One verifyidentity 0 simulation XPath= () 0 .Lemma 25. 0 substructure u0 0 0 , u0 , u0 .Lemma 26.+(1) {T 0 , u0 | , u ` 0 , u0 } definable node expression +`,u,T XPath= ()downward depth `.+0 0+(2) {T 0 , u0 | , ur,s,k , u } definable node expression r,s,k,u,T XPath= ()vertical depth (r, s) nesting depth k.0 00 0Proof. item (2), let simr,s,k (T , u) = {T , u | , u r,s,k , u }. Let 0 ,u0 setpositive node expressions XPath= ()+ vertical depth (r, s) nestingdepth k 0 , u0 |= . Let_^=0 ,u0 .0 ,u0 simr,s,k (T ,u)297fiFigueira, Figueira, & ArecesSince every 0 ,u0 finite logical equivalence Proposition 16, followsvalid node expression. show defines simr,s,k (T , u).V0000Let , u simr,s,k (T , u). Then, , u |= 0 ,u0 thus 0 , u0 |= .Vhand 0 , u0 |= 0 , u0 |= 00 ,u00 00 , u00 simr,s,k (T , u)00 000 000 000 , u0r,s,k , u . Theorem 20-3 , u r,s,k , u ,0 000 0000 000 0particular 00 , u00r,s,k , u . Since , u r,s,k , u , u r,s,k , u ,0 00 0, ur,s,k , u (by transitivity r,s,k ) thus , u simr,s,k (T , u).Item (1) shown similar way, using Proposition 2 Theorem 8-2.obtain node expressions XPath= invariant simulations are, precisely, positive ones.Theorem 27.1. XPath= () -invariant [resp. ` ] iff equivalent node expressionXPath= ()+ [resp. `-XPath= ()+ ].2. XPath= () -invariant iff equivalent node expression XPath= ()+ .3. XPath= ()r,s,k -invariant equivalent node expression(r, s, k)-XPath= ()+ .4. XPath= () equivalent node expression (r, s, k)-XPath= ()+0r,s,k0 -invariant, k = k (r + + 2).Proof. start item (1), case ` . part straightforwardTheorem 24-2, focus part. Let preserved ` .Let {(Ti , ui )}in set pointed models modulo ` (which finite dueTheorem 8-2 together Proposition 2). claim, u |= iff Ti , ui ` , u n.(3)one hand, , u |= n Ti , ui ` , u,Ti , ui ` , u. hand, suppose Ti , ui ` , u i. Since preserved` Ti , ui |= , conclude , u |= .+LetW `,ui ,Ti XPath= () , dd(i ) `, Lemma 26-(1). Using (3) one shows`,ui ,Ti .case item (1), direction follows Theorem 24-1.direction, let preserved . easy see preservediff preserved dd() . apply reasoningstatement follows.Item (3) follows argument item (1) time using Corollary 23Lemma 26-(2).Item (4) straightforward Theorem 24-3.Item (2) follows items (3) (4) observation preservediff preservedr,s,k(r+s+2) vd() = (r, s) nd() = k.298fiModel Theory XPath Data Trees. Part I: Bisimulation Characterization3.4 Transitive Axeshappens, example, basic modal logic propositional dynamic logic,notion bisimulation [resp. simulation] logic captures logical equivalence [resp. logical implication] corresponding fragments including also reflexivetransitive closure axes present. Intuitively, occursinfinite union compositions , similarly . Hence notions bisimulationsXPath= ( ) XPath= ( ) (denoted respectively) coincide, respectively.Let logical equivalence relation fragments XPath= ( )XPath= ( ) respectively, let V V logical implicationXPath= ( )+ XPath= ( )+ respectively.Theorem 28. Let { , }.1. , u 0 , u0 implies , u 0 , u0 . converse also holds 0 finitelybranching.2. , u 0 , u0 implies , u V 0 , u0 . converse also holds 0 finitelybranching.Proof. proof , u 0 , u0 , u 0 , u0 follows simple adaptationProposition 9 logic XPath= ( ) Lemma 10. fact finitely branching,, u 0 , u0 , u 0 , u0 straightforward Theorem 8-1 since .cases XPath= ( ), XPath= ( ) XPath= ( )+ analogous.hard see adequate notion (bi)simulation intermediate fragment XPath= () XPath= ( ) XPath= ( )XPath= ( ) also corresponds XPath= () sense statementabove.hand, restrict formulas transitive axes, obtainnotion bisimulation XPath= ( ) coarser bisimulation notion, definenext.Let 0 two data-trees. say u u0 0 bisimilarXPath= ( ) (notation: , u 0 , u0 ) iff relation Z 0 uZu0x x0 0Harmony: xZx0 label (x) = label (x0 ).Zig: xZx0 xv1 vn , xw1 wm0x0 v10 vn0 , x0 w10 wm00 ),1. data(vn ) = data(wm ) data(vn0 ) = data(wm2. vi Z vi0 1 n,3. wi Z wi0 1 m.0 0Zag: xZx0 x0 v10 vn0 , x0 w10 wmxv1 vn , xw1 wm items 1, 2 3verified.299fiFigueira, Figueira, & Arecesbefore, one define `-bisimilarity XPath= ( ), notated , u ` 0 , u0 ,also notions equivalence ` expected.notions bisimulation coincide corresponding logical equivalences:Theorem 29.1. , u 0 , u0 implies , u 0 , u0 . converse also holds 0finite.2. , u ` 0 , u0 iff , u ` 0 , u0 .case XPath= ( ) obvious adapt bisimulation verticalXPath, since normal form results hold XPath= ( ).4. CharacterizationSection 4.1 characterize XPath= () fragment first-order logic -invariantdata trees. Section 4.2 show result fails XPath= () general,weaker result holds: first-order formular,s,k -invariant r, s, k equivalentXPath= () formula.4.1 Downward XPathRecall data tree u , let |` u denote subtree induced {vn| (n `) uv}. data tree regarded -structure, explained 2.1.FO()-formula (x) `-local data trees u , |= (u)|` u |= (u). Recall FO(), qr() quantifier rank .Observe following result two readings: one classical, one restrictedfinite models.Theorem 30 (Characterization). Let (x) FO(). following equivalent:1. -invariant [finite] data-trees;2. logically equivalent [finite] data-trees node expression `-XPath= (),` = 2qr() 1.proof theorem, whose proof afterwards, consequencefollowing three propositions:Proposition 31. -invariant (x) FO() [finite] data-trees `-local` = 2qr() 1.Proof. follow proof Otto (2004a). Assume (x) FO() -invariant,let q = qr(), put ` = 2q 1. Given data tree u suffices showexistence data trees 0 00 , corresponding elements u0 0 u00 00(a) 0 , u0 , u,300fiModel Theory XPath Data Trees. Part I: Bisimulation Characterization(b) 00 , u00 (T |` u), u,(c) 0 , u0 q 00 , u00 .Indeed, conditions follows|= (u) iff 0 |= (u0 )((a) -invariance )iff 00 |= (u00 )(c)iff (T |` u) |= (u),((b)-invariance)hence `-local. Observation 4 one may assume u root .define 0 00 , structures disjoint copies sufficiently many isomorphiccopies |` u, respectively, tied together common root. structuresq isomorphic copies |` u, distinguish natureone extra subtree, u0 u00 live, respectively: u0 root onecopies u00 root one copies |` u. Consider structures 000 diagram below,u00u0q| {z }q copies| {z }| {z }q copiesq copies| {z }q copiesdistinguished elements u0 u00 marked ; open cones stand copies, closed cones copies |` u. new isomorphic copies datavalues original one. new root arbitrary, fixed, data value label.Observation 5, straightforward conditions (a) (b) satisfied. Condition (c)true one exhibit strategy player II q-round Ehrenfeucht-Frassegame structures 0 00 . strategy exactly one usedpaper Otto (2004a).Proposition 32. -invariant (x) FO() [finite] data-trees `-local,` -invariant.Proof. Let (x) `-local -invariant. Suppose , u ` 0 , u0 |= (u).`-locality, |` u |= (u)., u` 0 , u0 iff (T |` u), u` (T 0 |` u0 ), u0iff (T |` u), u (T 0 |` u0 ), u0 .(Obs. 7)(Obs. 6)-invariance, 0 |` u0 |= (u0 ) `-locality again, 0 |= (u0 ).Proposition 33. (x) FO() ` -invariant [finite] data-trees,`-XPath= () Trx () logically equivalent [finite] data-trees.301fiFigueira, Figueira, & ArecesProof. Corollary 3, every data tree u node expression `,T ,u`-XPath= () , u ` 0 , u0 iff 0 , u0 |= `,T ,u . Let_`,T ,u .=|=(u)Since `,T ,u `-XPath= () and, Proposition 2, ` finite index, followsequivalent finite disjunction.show Trx (). Let us see |= Trx (). Suppose |= (u). Since, u |= `,T ,u , , u |= |= Trx ()(u). Let us see Trx () |= .Assume |= Trx ()(u), , u |= . exists 0 , u0 0 |= (u0 ), u |= `,T 0 ,u0 . property `,T 0 ,u0 , , u ` 0 , u0 since` -invariant (and hence ` -invariant Theorem 8-2) conclude |= (u).Proof theorem 30. implication 2 1 follows straightforwardly Theorem 8.proof 1 2 follows: First, show -invariant (x) FO() `-local` = 2qr() 1 (Proposition 31). Then, prove -invariant (x) FO()`-local ` -invariant (see Proposition 32 below). Finally, show FO()definable property ` -invariant definable `-XPath= () (see Proposition 33below).4.2 Vertical XPathanalog Theorem 30 fails XPath= ().basically propertyp(x) =the tree x belongs contains label -invariant expressible XPath= (). Notice that, however, p -invariant. expected, sinceotherwise p would expressed XPath= () formula. Indeed, consider two data treestwo nodes, root leaf, labeled respectively a, b one tree, b, btree. Note leafs trees -bisimilar although dont coincideproperty p.Lemma 34. FO()-formula (x) Pa (x) -invariant though logically equivalent[finite] data-trees node expression XPath= ().Proof. Let (x) FO()-formula node labeled tree, i.e., (x) =(y) Pa (y). prove -invariant [finite] data-trees, though logicallyequivalent [finite] data-trees node expression XPath= ().see -invariant [finite] data-trees, take , u 0 , u0, u 0 , u0 |= (u). Furthermore, suppose , u |= n adequate nm. Theorem 20, 0 , u0 |= n 0 |= (u0 ).Assume contradiction XPath= () , u |= iff |= (u)data-tree u . Suppose vd() = (r, s) nd() = k. Let data treeformed chain length r+1 starting root u nodes containing labelb except leave, label (the data values irrelevant). Observation 19, ur,s,k (T |r u), u. Since , u |= , Theorem 20, (T |r u), u |= ,|sr u |= (u). last fact contradiction node |sr u labeleda.302fiModel Theory XPath Data Trees. Part I: Bisimulation CharacterizationHence XPath= () fragment FO() -invariant [finite] datatrees. However, following analog Proposition 33 (needed proof Theorem 30)still holds case XPath= (): r, s, k, every first-order formular,s,k invariant equivalent XPath= () formula.Proposition 35. Let k 0 = k (r + + 2). (x) FO()r,s,k0 -invariant [finite]data-trees, (r, s, k)-XPath= () Trx () logically equivalent[finite] data-trees.Proof. Corollary 17, every data tree u node expression r,s,k,T ,u0 00 0(r, s, k)-XPath= () , ur,s,k , u iff , u |= r,s,k,T ,u . Let=_r,s,k,T ,u .|=(u)r,s,k,T ,u (r, s, k)-XPath= () and, Proposition 16,r,s,k finite index,follows equivalent finite disjunction. proof (x) Trx () similarProposition 33, show next. Let us see |= Trx (). Suppose |= (u). Since, u |= r,s,k,T ,a , , u |= |= Trx ()(u). Let us see Trx () |= .Assume |= Trx ()(u), , u |= . exists 0 , u0 0 |= (u0 )0 0, u |= r,s,k,T 0 ,u0 . property r,s,k,T 0 ,u0 , , ur,s,k , u sincer,s,k(r+s+2) -invariant (and hence r,s,k -invariant Theorem 20-2) conclude |=(u).Notice counterexample Lemma 34 unrestricted, existential formula.One may wonder might possible extend expressive power XPath= ()accout unrestricted quantification. natural candidate would modal operatorE (usually known existential modality) which, intuitively, let us expressnode model formula holds. even additional expressive power provided E analog Theorem 30 fails. Formally, consider logicXPath= (l E), results adding operator E XPath= () followingsemantics: [[E]]T = [[]]T 6= , [[E]]T = otherwise.following lemma shows counterexample analog Theorem 30, showingXPath= (l E) fragment FO() -invariant [finite] data-trees.Lemma 36. FO()-formula (y, z) [y z Pa (y) Pb (z)] -invariant thoughlogically equivalent [finite] data-trees node expression XPath= (l E).Proof. Let (x) FO()-formula two nodes data valuelabels b respectively, i.e., (x) = (y, z) [y z Pa (y)Pb (z)]. show cannotexpressed XPath= (, , E). Suppose, means contradiction, nodeexpression XPath= (, , E) expressing , vd() = (r, s) (vd() XPath= (, , E)defined together clause vd(E) = vd()). Let n = r + s, letchain-like data-tree u0 u1 un label (u0 ) = a, label (un ) = b,label (ui ) = c {1, . . . n 1} data(ui ) = {0, . . . , n}.Let 0 chain-like data-tree u00 u01 u0n label (u0i ) = label (ui ){0, . . . n}, data(u0i ) = data(ui ) {0, . . . , n 1} data(u0n ) = 0. Note303fiFigueira, Figueira, & Areces6|= (u0 ) 0 |= (u00 ). However, one show {0, . . . , n}, ui |= iff 0 , u0i |= . Hence, express thus expressibleXPath= (, , E).5. Applicationsdevote section exemplify model theoretic tools developedused show expressiveness results XPath= . intend comprehensive;rather exhibit number different results show possible uses notionsbisimulation introduced.5.1 Safe Operations ModelsBisimulations also used show certain operations models preserve truth.operations usually called safe given logic, applied modelwithout changing truth values formula language. Observation 4,example, already example kind results showing class modelsformula closed sub-model generation. show elaborate example.say 0 subtree replication , 0 result inserting |xsibling x, x node different root. Figure 3 givesschematic representation operation.Figure 3: Closure subtree replication.Proposition 37. XPath= ( ) closed subtree replication, i.e. 0 subtreereplication , u 0 , u , u.Proof. Suppose x root , 0 result inserting |xsibling x. Let us call Tx new copy |x inserted 0 , let Xset nodes |x. Furthermore, v X vx corresponding node Tx .Nodes v vx label data value, position v |x coincidesposition vx Tx .Theorem 28, suffices verify , u 0 , u via Z 0 defined by:Z = {(y, y) | } {(v, vx ) | v X}.Z depicted dotted lines Figure 3.304fiModel Theory XPath Data Trees. Part I: Bisimulation Characterization5.2 Non-expressivity ResultsFinally, use bisimulation show expressivity limits different fragmentsXPath. Let key(a) property stating every node label different datavalue. Let fk(a, b) (for foreign key) property (x)[Pa (x) (y)[Pb (y) x y]].Proposition 38.1. key(a) expressible XPath= ( ).2. fk(a, b) expressible XPath= ( ) expressible XPath= ( )XPath= ( )+ .Proof. first item follows Proposition 37. Since logic closed subtreereplication, trees equivalent.xa, 1a, 2$la, 1x0a, 2 a, 2key(a) holds one other, statement follows.second item, easy see fk(a, b) expressible formulah [a h = [b]i]i. However, property cannot expressed XPath= ( )models 0 bisimilar XPath= () via Z, depicted dottedlines.xc, 0b, 1 b, 2a, 1 a, 2xc, 0a, 3 a, 2 a, 1b, 2b, 1Since , x satisfies fk(a, b) 0 , x0 not, Theorem 28 follows fk(a, b)expressible XPath= ( ).Finally, suppose exists XPath= ( )+ expressing fk(a, b). Sincesubstructure 0 , x 0 , x Lemma 25. Theorem 28(2) fact, x |= , 0 , x |= , contradiction.Let dist3 (x) property stating nodes y, z xyz x, y, zpairwise distinct data values.305fiFigueira, Figueira, & ArecesProposition 39.1. dist3 expressible XPath= ();2. dist3 expressible XPath= ( );3. neither dist3 complement expressed XPath= ( )+ .Proof. 1, one check , x |= iff , x satisfies dist3 ,= h 6= [h 6= [h 6= i]i]i.Let us see 2. Consider data trees , x 0 , x0 depicted below. straightforward, x satisfies dist3 0 , x0 not.xa, 2$#a, 1a, 1 a, 2a, 1 a, 2a, 3xa, 20T0a, 1a, 1a, 1 a, 2Let v10 v20 leaves 0 let v node data value 3.One check , x 0 , x0 via Z 0 definedZ = {hu, u0 | h(u) = h(u0 ) data(u) = data(u0 )} {hv, v10 i, hv, v20 i},h(y) height y, i.e., distance root corresponding tree(Z depicted dotted lines picture above). Since , x satisfies dist3 0 , x0not, Theorem 28 follows dist3 expressible XPath= ( ).3, one verify , x 0 , x0 via Z defined above. dist3 definableXPath= ( )+ via fact , x |= , Theorem 28(2) would0 , x0 |= , contradiction.Let dist3 denote complement dist3 , i.e., dist3 (x) iff y, z xyz,x, y, z pairwise distinct data values. 0 , x0 satisfies dist3, x not. Since 0 substructure , argument analog one usedproof Proposition 38-2, dist3 expressible XPath= ( )+ .5.3 Expressiveness HierarchiesDefine `,k equivalence ` restricted formulas nesting depth k,is, , u `,k 0 , u0 iff XPath= () dd() ` nd() k, u |= iff 0 , u0 |= . Define fine-grained notion bisimulation similarway. say u u0 0 (`, k)-bisimilar XPath= () (notation:, u`,k 0 , u0 ) family relations (Zj,t )j`,tk 0 uZ`,k u0j `, k, x x0 0306fiModel Theory XPath Data Trees. Part I: Bisimulation Characterization0,0 = 0,1 = 0,2 = 0,3 = 0,41,0 1,1 = 1,2 = 1,3 = 1,42,0 2,1 2,2 =2,3 = 2,43,0 3,1 3,2 3,3 = 3,4..................Figure 4: Hierarchy XPath= ().Harmony: xZj,t x0 label (x) = label (x0 ).nZig: xZj,t x0 , xv xw n, j v 0 , w0 0nx0 v 0 , x0 w01. data(v) = data(w) data(v 0 ) = data(w0 ),2. > 0, (v) Zjn+i,t1 (v 0 ) 0 < n,3. > 0, (w) Zjm+i,t1 (w0 ) 0 < m.nZag: xZj,t x0 , x0 v 0 x0 w0 n, j v, wnxv, xw items 1, 2 3 verified.Following ideas used Propositions 9 11, easy show (`, k)bisimulations characterize (`, k)-equivalence.Proposition 40. , u `,k 0 , u0 iff , u `,k 0 , u0 .following theorem characterizes increase nesting depth resultsincrease expressive power (see Figure 4). speculate similar hierarchy holdsabsence data values, direct consequence result.Theorem 41. `, k 0, 1, `,0 ) `,1 )`,k ) `+i,k .) `,` = `,`+i ,Proof. Consider data trees Tni , Tn0i (n 0, {1, 2}) defined every k.307fiFigueira, Figueira, & Areces1,0x10a, 1a, 2b, 1b, 20,0a, 1b, 10,0T01x1na, 1Tn1Tn1Tn21Tn+1a, 1x10b, 2a, 1a, 2a, 1n+1,nTn11,0a, 2b, 1T01n+2,n+1Tn2x20b, 20,0a, 1b, 10,0T02x1nTn1x2na,12Tn2Tn11Tn+1Tn1Tn22Tn+1x20a, 2b, 2T02n+2,n+1a,12n+1,nTn2a, 2Tn2x2nTn1Tn22Tn+1Note `,k+1 `,k `+1,k `,k definition. show `,k 6= `,k+11 1` k + 1. purpose, show Tk1 , x1k k+1,k Tk01 , x01k Tk , xk 6k+1,k+1Tk01 , x01k.Tk1 , x1k 6k+1,k+1 Tk01 , x01k results fact property pathlength k + 1 ending label whose every pair consecutive nodes distinct datavalue definable following formula k+1 depth k + 1 nesting depth k + 1,1 = h 6= [a]ii+1 = h 6= [i ]i> 0.01 011 1Since Tk1 , x1k |= k+1 Tk01 , x01k 6|= k+1 , follows Tk , xk 6k+1,k+1 Tk , xk .1 101 01show Tk1 , x1k k+1,k Tk01 , x01k use Proposition 40 show Tk , xk k+1,k Tk , xk .Note Tk1 Tk2 (resp. Tk01 Tk02 ) equal modulo renaming data values,also showing roots two data trees subindex k (k +1, k)-bisimilar.Observation 42. Note set immediate subtrees roots Tk1 , Tk01 , Tk2 , Tk02Tk01 , Tk2 , Tk02 (and Tk1 , Tk01 , Tk02 ) construction.show Tk1 , x1k k+1,k Tk01 , x01k . every j k + 1, k, let Zj,t set pairs(x, y) Tk1 Tk01 x xik0 x0ik0 {1, 2} k 0 (the notationxik0 x0ik0 necessarily identify unique node but, possibly, many; intendedmeaning refer them). ObserveZj+1,t Zj,tj, k.(4)show (Zj,t )jk+1,tk verify bisimulation conditions. proceed induction j + t. base case, j = = 0, trivial. case l > 0, = 0 alsostraightforward.Suppose > 0. Let (u, u0 ) Zj,t . Again, Harmony met since Zl,t relates0nodes label a. Let us suppose u x1t0 u0 x01t0 t,cases similar simpler.nLet us show Zig. Let v, w x1t0 v x01t0 w n, j.308fiModel Theory XPath Data Trees. Part I: Bisimulation Characterizationv inside subtree Tt20 1 Tt10 , x2t0 1 , choose v 012corresponding node inside subtree Tt10 1 Tt010 . Remember Tt0 1 Tt0 1isomorphic modulo renaming data values, corresponding mean nodeposition tree. data(v) = data(v 0 ) Observation 42. Furthermore,since every node Tt10 1 Zj,t1 -relation corresponding node Tt20 1construction Zj,t1 , follows (v)Zj,t1 (v 0 ) n. Thus, (4),(v)Zjn+i,t1 (v 0 ) n.02If, hand, v x2t0 1 , choose v 0 root Tt020 1 , xt0 1 . Again,00data(v ) = data(v) construction vZj,t1 v . Thus, (4),vZj1,t1 v 0 .001Finally, v falls outside Tt020 1 , choose v node Tt0 , coursedata(v) = data(v 0 ) (v)Zj,t1 (v 0 ) n. Thus,(4), (v)Zjn+i,t1 (v 0 ) n.w w0 . Since every case reach nodedata value corresponding nodes path Zj,t1 -related, followsZig condition satisfied. Zag condition easier, hence concludeTk1 , xk+1,k Tk0 1 , x0 every k.therefore `,k+1 ( `,k ` k + 1.fact `+1,k ( `,k course trivial, formulas depth ` + 1 expresstree least depth ` + 1, cannot expressed formulas depth `.remains show `,k = `,k+1 ` k. show this, prove , x`,k+10 , x0 every , 0 , x`,k 0 , x0 . prove induction ` + k. basecase easy.inductive case, let Zj,t = j,t j `, k. Hence, (Zj,t )j`,tk verifybisimulation conditions. Let Z`,k+1 = {(x, x0 )}. show Z`,k+1 together(Zj,t )j`,tk verifies bisimulation conditions. Harmony follows xZ`,k x0 . shownZig since Zag equivalent. Suppose xv, xw n, `. Then, since Z`,k verifiesnZig, x0 v 0 , x0 w0(1) data(v) = data(w0 ) iff data(v 0 ) = data(w0 ),(2) (v)Z`n+i,k1 (v 0 ) {0, . . . , n 1},(3) (w)Z`m+i,k1 (w0 ) {0, . . . , 1}.Since ` k, `n+i k 1. Further, `n+i+k < `+k, meansapply inductive hypothesis. Hence, inductive hypothesis, , (v)`n+i,k 0 , (v 0 )thus (v)Z`n+i,k (v 0 ). indentical reasoning, , (w)`n+i,k 0 , (w0 )thus (w)Z`n+i,k (w0 ). Thus, Zig condition `,k+1 verified. Zag conditionholds symmetry.309fiFigueira, Figueira, & Arecesrespect vertical XPath, note sincer,s,k r0 ,s0 ,k0 (r, s, k)consequence Proposition 15 obtain every r, s, k r +2 k 0 > kr,s,k ) r,s,k0 . fact, conjecture r,s,k )(r0 , s0 , k 0 ),r,s,k+1 every k. argue proven models (Tn )nproof Proposition 15, showing Tk , xr0 ,s0r,s,k Tk+1 , xr0 ,s0 Tk , xr0 ,s0 6r,s,k+1Tk+1 , , xr0 ,s0 every (r, s) (r0 , s0 ). factr,s,k ) r+1,s,k r,s,k ) r,s+1,kstraightforward. would obtain following.0 0 0Conjecture 43.r,s,k ) r0 ,s0 ,k0 (r, s, k) < (r , , k ), r + 2.6. Discussionarticle studied model theoretic properties XPath finite arbitrarydata trees using bisimulations. One main results discuss characterizationdownward vertical fragments XPath fragments first-order logicinvariant suitable notions bisimulation. seen first steplarger program studying model theory expressiveness XPath datavalues and, generally, logics data trees. would interesting study notionsbisimulation descendant; characterizations XPath child descendant,fragment FO descendant relation data trees.considered XPath horizontal navigation siblings,axes next-sibling () previous-sibling (). fact, adding axes resultsfragment somewhat less interesting since adequate bisimulation notionfinite data trees corresponds precisely data tree isomorphism modulo renamingdata values. Next explain so. Consider following notation denotingpositions nodes tree. Positions elements (N N) , roots positionempty string , position node tree concatenationposition parent pair (l, r), l number siblingsleft node r number siblings right. every position p (N N)tree, path expression p XPath= () access nodeposition (and position) root. p defined = root;(l,r) = l+1 [hk hk+1 i] (l, r) N N;V p(l,r) = p (l,r) p (N N) ,(l, r) N N. easy check testing p hp [hi]i p ranges leafpositions given tree tests property subtree hanging nodeformula evaluated structurally isomorphic . Further, also adding testshp [a] = p0 [a0 ]i every pair positions p, p0 label a, a0 datavalue, well hp [a] 6= p0 [a0 ]i different data value, yields propertyequal , isomorphism data values.Section 5 show number concrete application model theoretic toolsdeveloped, discussing expressivity non-expressivity results. also show examplesoperations safe given XPath fragment. would worthwhile devisemodel operations preserve truth XPath formulas show casesubtree replication.important application bisimulation minimization method: given datatree T1 want find data tree T2 , small possible, T1 T2 bisimilar310fiModel Theory XPath Data Trees. Part I: Bisimulation Characterizationfragment L XPath. Since L cannot distinguish T1 T2 ,use T2 representative T1 expressive power L requiredgiven application. complexity several inference tasks (e.g., model checking) dependsdirectly model size. cases may profitable first applyminimization step.existence efficient minimization algorithms intimately related bisimulations:minimize data tree partitioning terms maximum auto-bisimulation(observe identity always auto-bisimulation, union two bisimulations bisimulation; therefore maximum, often called coarsest, bisimulation).idea find coarsest auto-bisimulation Z given data-tree . Onecannot simply make quotient Z, result necessarily treeclear assign data values class quotient. However, one makequotient equivalence relation Z data value. so, obtainsmaller structure, evaluate queries here.Determining maximum auto-(bi)simulation, either downward vertical, finitedata tree done polynomial time. naive algorithm starts defining Zset nodes satisfy Harmony. time Zig Zag satisfied, removesZ pair responsible Zig Zag true. repeats fixed pointZ found; maximum auto-bisimulation . one interested decidingtwo nodes different finite data trees bisimilar, one use idea: answeryes fixed point empty set. Since checking validity ZigZag polynomial time computable (because linearly many paths tree),step algorithm decreases size Z, whole process polynomialtime. Better implementations, based sophisticated ideas, worksHenzinger, Henzinger, Kopke (1995) Dovier, Piazza, Policriti (2004), leadefficient polynomial time algorithms. plan design implement algorithmsdata tree minimization using bisimulation investigate computational complexity.Acknowledgementswork partially supported grant ANPCyT-PICT-2013-2011, ANPCyT-PICT2010-688, ANPCyT-PICT-2011-0365, UBACyT 20020110100025 FP7-PEOPLE2011-IRSES Project Mobility Europe Argentina applying Logics Systems(MEALS) Laboratoire International Associe INFINIS.ReferencesAbiteboul, S., Bourhis, P., Muscholl, A., & Wu, Z. (2013). Recursive queries treesdata trees. International Conference Database Theory, pp. 93104.Abriola, S., Descotte, M. E., & Figueira, S. (2014). Definability downward verticalXPath data trees. Workshop Logic, Language, Information Computation,Vol. 6642 Lecture Notes Computer Science, pp. 2034.Abriola, S., Descotte, M. E., & Figueira, S. (2015). Model theory XPath data trees.Part II: Binary bisimulation definability. appear Information Computation. http://www.glyc.dc.uba.ar/santiago/papers/xpath-part2.pdf.311fiFigueira, Figueira, & ArecesBenedikt, M., Fan, W., & Geerts, F. (2008). XPath satisfiability presence DTDs.Journal ACM, 55 (2), 179.Benedikt, M., & Koch, C. (2008). XPath leashed. ACM Computing Surveys, 41 (1).Blackburn, P., de Rijke, M., & Venema, Y. (2001). Modal Logic, Vol. 53 Cambridge TractsTheoretical Computer Science. Cambridge University Press.Bojanczyk, M., Muscholl, A., Schwentick, T., & Segoufin, L. (2009). Two-variable logicdata trees XML reasoning. Journal ACM, 56 (3), 148.Bojanczyk, M., & Parys, P. (2011). XPath evaluation linear time. Journal ACM,58 (4), 17.Clark, J., & DeRose, S. (1999). XML path language (XPath). Website. W3C Recommendation. http://www.w3.org/TR/xpath.David, C. (2008). Complexity data tree patterns XML documents. MathematicalFoundations Computer Science, Vol. 5162 Lecture Notes Computer Science,pp. 278289. Springer.Dawar, A., & Otto, M. (2009). Modal characterisation theorems special classesframes. Annals Pure Applied Logic, 161 (1), 142.Dovier, A., Piazza, C., & Policriti, A. (2004). efficient algorithm computing bisimulation equivalence. Theor. Comput. Sci, 311, 221256.Figueira, D. (2010). Reasoning Words Trees Data. PhD thesis, LaboratoireSpecification et Verification, ENS Cachan, France.Figueira, D. (2012). Decidability downward XPath. ACM Transactions ComputationalLogic, 13 (4).Figueira, D., & Segoufin, L. (2011). Bottom-up automata data trees vertical XPath.International Symposium Theoretical Aspects Computer Science, Vol. 9LIPIcs, pp. 93104. Leibniz-Zentrum fur Informatik.Figueira, D., Figueira, S., & Areces, C. (2014). Basic model theory XPath data trees.International Conference Database Theory, pp. 5060.Figueira, D., & Libkin, L. (2014). Pattern logics auxiliary relations. LogicComputer Science, pp. 40:140:10.Figueira, S., & Gorn, D. (2010). size shortest modal descriptions.. AdvancesModal Logic, Vol. 8, pp. 114132.Forti, M., & Honsell, F. (1983). Set theory free construction principles. Annali ScuolaNormale Superiore, Pisa, X (3), 493522.Goranko, V., & Otto, M. (2007). Model theory modal logic. P. Blackburn, J. V. B., &Wolter, F. (Eds.), Handbook Modal Logic, Vol. 3 Studies Logic PracticalReasoning, chap. 5, pp. 249329. Elsevier.Gottlob, G., Koch, C., & Pichler, R. (2005). Efficient algorithms processing XPathqueries. ACM Transactions Database Systems, 30 (2), 444491.312fiModel Theory XPath Data Trees. Part I: Bisimulation CharacterizationGyssens, M., Paredaens, J., Gucht, D. V., & Fletcher, G. (2006). Structural characterizations semantics XPath navigation tool document. PrinciplesDatabase Systems, pp. 318327. ACM.Harel, D. (1984). Dynamic logic. Gabbay, D., & Guenthner, F. (Eds.), HandbookPhilosophical Logic. Vol. II, Vol. 165 Synthese Library, pp. 497604. D. ReidelPublishing Co., Dordrecht. Extensions classical logic.Henzinger, M. R., Henzinger, T. A., & Kopke, P. W. (1995). Computing simulationsfinite infinite graphs. Proc. 36th Annual Symposium FoundationsComputer Science, pp. 453462. IEEE Computer Society Press.Hopcroft, J. (1971). nlog(n) algorithm minimizing states finite automaton.Z. Kohave, editor, Theory Machines Computations. Academic Press.Jurdzinski, M., & Lazic, R. (2011). Alternating automata data trees xpath satisfiability. ACM Transactions Computational Logic, 12 (3), 19.Kanellakis, P., & Smolka, S. (1990). CCS expressions, finite state processes, threeproblems equivalence. Inf. Comput., 86 (1), 4368.Kurtonina, N., & de Rijke, M. (1997). Simulating without negation. Journal LogicComputation, 7, 503524.Lutz, C., Piro, R., & Wolter, F. (2011). Description logic tboxes: Model-theoretic characterizations rewritability. International Joint Conference Artificial Intelligence,Barcelona, Catalonia, Spain, July 16-22, 2011, pp. 983988.Marx, M. (2004). XPath conditional axis relations. International ConferenceExtending Database Technology, Vol. 2992 Lecture Notes Computer Science, pp.477494. Springer.Marx, M., & de Rijke, M. (2005). Semantic characterizations navigational XPath. SIGMOD Record, 34 (2), 4146.Milner, R. (1980). Calculus Communicating Systems, Vol. 92 Lecture NotesComputer Science. Springer.Neven, F., Schwentick, T., & Vianu, V. (2004). Finite state machines strings infinitealphabets. ACM Transactions Computational Logic, 5 (3), 403435.Olteanu, D. (2007). Forward node-selecting queries trees. ACM TransactionsDatabase Systems, 32 (1), 3.Olteanu, D., Meuss, H., Furche, T., & Bry, F. (2002). XPath: Looking forward. International Conference Extending Database Technology, pp. 109127.Otto, M. (2004a). Elementary proof van Benthem-Rosen characterisation theorem.Tech. rep. 2342, Fachbereich Mathematik, Technische Universitat Darmstadt.Otto, M. (2004b). Modal guarded characterisation theorems finite transitionsystems. Annals Pure Applied Logic, 130 (1-3), 173205.Otto, M. (2006). Bisimulation invariance finite models. Logic Colloquium02, Vol. 27Lecture Notes Logic, pp. 276298.313fiFigueira, Figueira, & ArecesPaige, R., & Tarjan, R. (1987). Three partition refinement algorithms. SIAM J. Comput.,16 (6), 973989.Park, D. (1981). Concurrency automata infinite sequences. Theoretical ComputerScience, Vol. 104 Lecture Notes Computer Science, pp. 167183. Springer.Rosen, E. (1997). Modal logic finite structures. Journal Logic, LanguageInformation, 6 (4), 427439.Sangiorgi, D. (2009). origins bisimulation coinduction. ACM TransactionsProgramming Languages Systems, 31 (4).ten Cate, B., Fontaine, G., & Litak, T. (2010). modal aspects XPath. JournalApplied Non-Classical Logics, 20 (3), 139171.van Benthem, J. (1976). Modal Correspondence Theory. PhD thesis, Universiteit vanAmsterdam.314fiJournal Artificial Intelligence Research 53 (2015) 633-658Submitted 01/15; published 08/15Placement Loading Stations Electric Vehicles:Detours Necessary!Stefan FunkeAndre Nusserfunke@fmi.uni-stuttgart.denusser@fmi.uni-stuttgart.deUniversitat StuttgartInstitut fur Formale Methoden der Informatik70569 Stuttgart, GermanySabine Storandtstorandt@cs.uni-freiburg.deAlbert-Ludwigs-Universitat FreiburgInstitut fur Informatik79110 Freiburg, GermanyAbstractCompared conventional cars, electric vehicles (EVs) still suffer considerablyshorter cruising ranges. Combined sparsity battery loading stations, complete transition E-mobility still seems long way go. paper, considerproblem placing loading stations possible shortest pathsufficiently many run energy. show model problemintroduce heuristics provide close-to-optimal solutions even large road networks.1. IntroductionBattery-powered, electric vehicles (EVs) important means towards reductioncarbon dioxide emissions recharged using renewable energies, e.g. solar windpower. Despite environmental advantages EVs still wait breakthroughmain reason limited cruising range (often less 200km) togethersparsity battery loading stations (BLSs). Planning trip B EVnowadays non-trivial undertaking; locations BLSs taken account,many destinations completely range.Hence, early phase E-mobility important goal establish networkBLSs using EV becomes worry-free enterprise. modern BLSs requirelittle space (see Figure 1, left, illustration), placed almost everywhere.generates costs, natural objective minimize number installed BLSs.previous work (Storandt & Funke, 2013), heuristic proposed determine BLSlocations one get anywhere anywhere road network withoutrunning energy (when choosing suitable route). Unfortunately, approachguarantees connectivity reasonability routes. fact, even rather closedestinations routes one recharging stop possible, might require longdetours several recharging stops due placement BLSs. related approachLam, Leung Chu (2013) suffers similar drawbacks. long run, E-Mobilityprevail road trip EV undertaken without unreasonable detoursc2015AI Access Foundation. rights reserved.fiFunke, Nusser, & StorandtFigure 1: Inner-City battery loading station (left image), feasible loading station coversmall map cut-out (right image).introduced. paper ask placement BLSsshortest path enough BLSs get stranded starting fully loadedbattery like typically case gas stations conventional cars. callset BLS locations EV Shortest Path Cover (ESC) define respectiveoptimization problem follows.Definition 1 (EV Shortest Path Cover (ESC)). Given (di)graph G(V, E), edge costsc : E R+ function path decides whether path traveledalong without recharging EV, problem determining minimum subset L VBLSs every shortest path wrt c traveled without running energycalled EV Shortest Path Cover Problem.See Figure 1, right, idea valid ESC looks like. remainderdefine n = |V | = |E| otherwise noted. Also consider sakeclearer presentation assume unique shortest paths (which enforced usingstandard techniques like symbolic perturbation). describe deal ambiguous shortest paths towards end paper. function captures energycharacteristics network considered vehicle. Typically, mountainous areasroads rough surfaces, minimal paths EV runs energyconsiderably shorter flat terrain downhill. experiments determinedenergy consumption road segment e = (v, w) E elevations h(v), h(w)distance(e) + max(h(w) h(v), 0) weighting parameter (dependentEV). is, energy consumption determined Euclidean distanceheight differences, similar energy model used previous work (Artmeier, Haselmayr,Leucker, & Sachenbacher, 2010) disregarding energy recuperation (negative edge costs).function compares path accumulated energy consumption along edgesEVs battery capacity B R+ determine recharging necessary. Noteone could employ kind monotonous function here, approaches introducefollowing work notwithstanding particular choice.634fiPlacement Loading Stations Electric Vehicles1.1 Contributiondescribe model ESC problem instance Hitting Set problemsets shortest paths require least one battery recharge. allowsus use algorithms developed solving Hitting Set problems, e.g. standard greedyapproach. Unfortunately, turns difficulty computing ESC solutionalready instance construction. (n2 ), n = |V | shortest paths network,extracting storing naively requires much time space practical.therefore design new shortest path extraction representation techniques,allow tackle even large road networks. Moreover, develop several refinementsheuristics provide feasible ESC solutions efficiently. prioriapproximation guarantee shown solutions, prove posteriori usinginstance-based lower bounds real-world instances actual approximation ratiosmall constant.extended version original paper (Funke, Nusser, & Storandt, 2014b),present following new results insights regarding ESC: prove ESC problem NP-hard (and even hard approximate). proven hardness motivationjustification development heuristic algorithms. Furthermore, explaintransform shortest paths one (newly developed) representation another, alongtheoretical run time analysis experiments. ability transform representations allows flexibility might prove useful applicationscompact representations shortest paths used. also describe simple minimalitychecks shortest paths deciding whether need considered respective Hitting Set instance. Especially large networks, checks reduce number shortestpaths stored significantly. addition, provide details involvedlower bound constructions. Finally, lay methods dealing ambiguous shortestpaths, augmenting already existing loading station set case loadingstation locations restricted subset nodes network.2. Theoretical AnalysisLet us first prove ESC problem NP-hard, hope efficient algorithmssolve ESC optimality (unless P=NP). Hence remainder paperfocus designing algorithms compute good approximate solutions.Theorem 1 (Hardness). EV-Shortest Path Cover problem (ESC) NP-hard.prove NP-hardness ESC solution size preserving reduction Vertex Cover(VC), one classical NP-hard problems. use following definitionnotation VC:Definition 2 (Vertex Cover). Given graph G(V, E), goal find vertex set C Vminimal cardinality e E : e C 6= .prove Theorem 1, show ability solve ESC problem efficiently impliesability solve VC efficiently well. Hence, ESC NP-hard otherwisewould contradiction NP-hardness VC. end construct given635fiFunke, Nusser, & Storandt11111111111111Figure 2: Left: Vertex Cover instance optimal solution size 3 (red circled nodes).Right: Respective ESC instance constructed inserting auxiliary edge pernode graph left, augmenting edges cost 1. circlednodes indicate optimal Hitting Set path cost least 3 unhit.VC instance Gvc (Vvc , Evc ) corresponding instance ESC specified G(V, E), cfollows:V = Vvc , E = Evc i.e. ESC instance initially contains nodes edgesVC instancev V add auxiliary vertex v 0 auxiliary edge {v, v 0 } Ge E set costs c(e) uniformly 1true paths consisting less three edges false otherwise, i.e. everyshortest path traverses least three edges loading stationmake set loading stations feasible ESCconstruction requires polynomial time size Gvc . Figure 2 illustratestransformation Vertex Cover instance ESC instance small example.first show Vertex Cover solution Gvc also ESC solution ESCinstance constructed described above.Lemma 1. Vertex Cover C Gvc yields ESC L G, c, |L| = |C|.Proof. Let C Vvc VC solution Gvc . ESC graph G contains correspondingvertex every v Vvc , simply set L = C (so obviously |L| = |C|). remains showplacing loading stations according L, every shortest path G traveledwithout running energy. Assume contradiction exists shortest pathG consisting three edges {u, v}{v, w}{w, x} neither v w L. everyedge e Evc least one two vertices L (because L = C Vertex CoverEvc ), follows {v, w} auxiliary edge present GGvc . auxiliary edges cannot middle path containing three edges,every auxiliary vertex degree 1. every path consisting three edges containsloading station, hence L valid ESC.complete proof Theorem 1, show valid ESC solution leadsvalid Vertex Cover solution well.636fiPlacement Loading Stations Electric VehiclesLemma 2. ESC L G, c, yields Vertex Cover C Gvc |C| |L|.Proof. Let L valid ESC solution. L might contain auxiliary vertices, constructC replacing every auxiliary vertex v 0 L respective original vertex v. vmight also part L, conclude |C| |L|. show C valid VertexCover Gvc , prove every edge {v, w} Evc either v w C.Assume contradiction exists edge {v, w} Evc {v, w} C = .Accordingly, neither v, w, respective auxiliary vertices v 0 w0 partESC solution L. implies shortest path {v 0 , v}, {v, w}, {w, w0 } three edgesloading station G. contradicts L valid ESC solution, concludeevery edge {v, w} C 6= therefore C valid Vertex Cover.L optimal solution ESC, obviously |C| = |L| fulfilled Lemma 2,placing loading station auxiliary vertex v 0 corresponding original vertex vtime renders loading station v 0 superfluous. Hence optimal solution,never vertices v v 0 L. combination Lemma 1, showedevery instance VC, construct polynomial time instance ESCoptimal solution translates optimal solution VC instancesize straightforward manner. Therefore hardness results VC carryESC. proves Theorem 1 furthermore rules existence (1 + )polynomial-time approximation schemes ESC via proven APX-hardness factorbetter 1.3606 VC (Dinur & Safra, 2004):Corollary 1. ESC cannot approximated better 1.3606.proven hardness, efficient algorithms solve ESC problem optimalitymight difficult design unless one make use certain problem aspects batterycapacity parameter road network characteristics.3. Modeling ESC Hitting Set Problemfollowing, aim good approximation algorithms heuristics solveESC problem practice. particular, exploit fact ESC modeledinstance well-known Hitting Set problem therefore algorithms suitableHitting Set computations transfer ESC. classical Hitting Set (HS) problem definedfollows:Definition 3 (Hitting Set). Given set system (U, S) U universe elementscollection subsets U , goal find minimum cardinality subset L Uset hit least one element L, i.e. : L 6= .case, U consists nodes road network (the possible BLS locations).set composed vertex sets shortest s-t-paths (excluding themselves)fully charged battery suffice reach t. function characterizespaths energy consumption traversing exceeds battery capacityB R+ call paths B-violating. Clearly, need consider set-minimalpaths supersets hit automatically. Theorem 2 shows Hitting Set formulationindeed solves ESC problem (see also Figure 3 illustration).637fiFunke, Nusser, & StorandtvBllvlBBBvFigure 3: shortest path exhibits B-violating prefix (s-v, marked red),according Hitting Set formulation loading station lsubpath. vehicle fully reloads l, argumentation appliessubpath l-t, illustrated picture cutting prefixs-l every layer. final s-t-path B-violating anymore. Thereforeoriginally considered s-t-path traveled visiting three indicatedloading stations. blue Bs mark nodes battery fully loaded,i.e. charge level equal battery capacity.Theorem 2 (Correctness). Hitting Set formulation leads feasible ESC solution,i.e. placing loading stations according Hitting Set solution L, every shortestpath G traversed EV without running energy according .Proof. Let (s, t) shortest path G B-violating, let EVfully loaded s. Let (s, v) minimal B-violating prefix (s, t). prefixhit loading station l L l 6= s, l 6= v demanded Hitting Setformulation. EV reach l s, (s, v) minimal B-violating prefix lappears v (s, v). l EV fully re-charged. Hence whole argumentationtransfers subpath (l, t). Applying argument recursively, EV finallyreach loading station (s, t) suffix path longer B-violating.Therefore EV reach via (s, t) without running energy.Note precision loss reformulating ESC Hitting Set probleminstance, since every solution ESC feasible solution exactly cardinalityrespective Hitting Set problem instance.point, common Hitting Set solving techniques applied solve ESC, e.g.standard greedy algorithm. greedy algorithm repeatedly picks node hittingfar unhit sets adds solution. terminates soon setshit. solution computed greedy algorithm guaranteed ((ln |S|) + (1))approximation (Chvatal, 1979); ignore lower-order term (1) on.application, number sets system upper bounded number shortestpaths graph. Therefore, |S| n2 hence greedy algorithm provides2 ln(n) approximation guarantee. running time greedy algorithm dependscrucially fast access far unhit sets round.638fiPlacement Loading Stations Electric Vehicles11243341610711961284Figure 4: Cut-out CH-graph: Black edges original edges, blue edges indicate shortcuts. red node labels reflect contraction order. So, example,moment node labeled 6 contracted, shortcut node 10 node 9inserted shortest path 10 9 went 6. right side,search space query leftmost rightmost node illustrated.Green edges show Gout (s) purple edges Gin (t).remainder paper, investigate efficient construction setsystem using different path extraction representation schemes study influencegreedy algorithm.4. Basics Practical ESC Computationdetermine suitable BLS positions, first construct set shortest pathsEV would run energy (according ). Computing shortest pathtwo nodes one nodes classically performed using Dijkstrasalgorithm (also shortly called Dijkstra). large street networks Dijkstra slowprocess large number queries (as necessary application), though.Therefore, instrument speed-up techniques developed accelerating shortest pathqueries achieve better running times approaches. particular, employContraction Hierarchies (CH) (Geisberger, Sanders, Schultes, & Delling, 2008)purpose. basic idea behind CH augment graph G(V, E) set E 0called shortcuts, span (large) sections shortest paths. Using shortcuts insteadoriginal edges allows dramatic reduction operations Dijkstra run.central operation CH preprocessing node contraction. Consideringgraph G(V, E) node v contracted, goal remove v G withoutaffecting shortest path distances remaining nodes. achievedcreating additional shortcut edges neighbors v follows: every pairneighbors u, w v (u, v), (v, w) E, shortcut (u, w) created (with costpath uvw) uvw shortest path u w. resulting graph (withv removed necessary shortcuts added) exhibits shortest path distancesoriginal graph. CH preprocessing phase instruments node contraction firstassigning label l : V N node. Then, nodes contracted increasing labelorder. contracted nodes constructed set shortcuts E 0 way,639fiFunke, Nusser, & Storandtreturn result preprocessing phase CH-graph G0 (V, E E 0 ), is, originalgraph augmented shortcuts (and labeling), see Figure 4 (left) example.According labels, original shortcut edges (v, w) referred upwardsl(v) < l(w) downwards otherwise; paths called up/downwards consistexclusively edges type. shown way created shortcuts,node pair s, V shortest path exists G0 = G(V, E E 0 )decomposed upward path starting followed downward path ending t;highest node path wrt l called peak node following. propertypath allows restrict bidirectional Dijkstra run Gout (s) Gin (t) refersubgraphs G0 containing upwards paths starting downwards pathsending respectively. Figure 4 (right), subgraphs illustrated. resultingoptimal path found bidirectional Dijkstra costs shortest pathoriginal graph. representation path different, pathconsists (partly) shortcuts. get shortest path original graph,unpacking procedure applied. every shortcut, two edges (original shortcut)directly spans memorized CH construction. Thus, unpacking onerecursively replace shortcuts spanned edges original edges identified.Note CH scheme also employed represent shortest pathconcisely replacing many subpaths possible shortcuts. also callrepresentation CH-path. experiments turns CH-pathsextremely economic representation scheme shortest paths.one-to-all shortest path problem, PHAST algorithm (Delling, Goldberg,Nowatzyk, & Werneck, 2011) also takes advantage CH-preprocessing scheme.first phase nodes Gout (s) source V settled via Dijkstra run.second phase downward edges (v, w) relaxed decreasing order induced l(w),thereby computing correct distances nodes V . second phase simply sweepsubset edges requires linear time. Correctness PHAST resultsfact every node shortest path decomposedupwards path (with contained nodes settled first phase) downwardspath. set downwards edges forms directed acyclic graph labels l(w)induce topological order, sweep edges order assures momentedge (v, w) relaxed, node v already settled. Hence PHAST computes exact shortestpath distances nodes network. Note single shortest path queryPHAST method choice, techniques like pure CH-Dijktra computationsnormally run time clearly sublinear number edges practice.5. Construction Set Systemsection, investigate several strategies extract set system given ESCinstance, i.e. set minimal shortest paths G B-violating. Alongdifferent extraction strategies, present different ways represent store respectiveset shortest paths discuss advantages disadvantages representations.640fiPlacement Loading Stations Electric Vehicles5.1 Naive Extractionsimplest approach comes mind compute shortest path tree (via Dijkstra)every V identify nodes tree accumulated energy cost valuesB. nodes priority queue Dijkstra settled predecessorsalready belong B-violating paths, abort exploration source s.respective paths search tree backtracked stored e.g. completevertex sets. small exploration radii (small bounds B) practical approach,larger B space consumption O(n2 n), n = |V | enormous (assuming averagepath length n). Even store Dijkstra search tree V viapredecessor labels, still space consumption O(n2 ). course, could easilyachieve linear space consumption number B-violating paths, storingsource vertex target vertex path. want accessnodes certain path, run Dijkstra computation networkt. huge sets paths computing nodes always demandtime-intensive. matter representation use store paths, timecomplexity O(n (n log n + m)), = |E| naive extraction already limits usabilityreal-world instances; O(n log n + m) runtime one Dijkstra run.fact, also main difficulty Hitting Set-type problems streetnetworks. example, speed-up techniques shortest path queries like Transit Nodes(TN) (Bast, Funke, & Matijevic, 2009) Hub Labeling (HL) (Abraham, Delling, Goldberg,& Werneck, 2012) based hitting certain set shortest paths well. Methodscomplete instance construction impractical there. Therefore several custom-tailoredheuristics developed allow efficient computation without explicitly constructing(Arz, Luxen, & Sanders, 2013). setting differs significantly ours,setting poses additional criterion c identifying paths contained S. Hencedistance bound employed setting leads set equal length paths,scenario, due different energy consumption driving uphill downhill,lengths minimal B-violating paths differ vastly. unfortunately TN HL (andrelated) heuristics carry setting. Therefore need explore newways extracting storing shortest path sets.5.2 PHAST-Based Extractionlarge bounds B finding B-violating paths source node resembles one-to-allshortest path problem. PHAST explicitly designed solve task efficiently.paths backtrack respective search tree CH-representation, i.e.consist partly shortcuts. huge advantage compared conventional pathsterms storage, shortcuts spanning large portions shortest pathnumber nodes CH-path significantly smaller (about two orders magnitudestreet network Germany). downsides, though: Nodes processedsecond phase PHAST l-order increasingly distance; hence incorporatingB stopping criterion seems difficult. Moreover, B large leads pathsvastly differing lengths, (n2 ) lower bound (accumulated) runtime PHASTevery source might already result large overhead. Hence propose differentstrategy also based CH potential significantly faster.641fiFunke, Nusser, & StorandtpB = 103234215G22 ]8,10]G1p9647478 ]4,8]3]7,8]9]1,8]1Figure 5: Left: Schematic representation CH-graph height nodes indicating contraction order. blue-marked peak p, G1 := Gin (p) coloredred G2 := Gout (p) colored green. Note nodes bottomlayer, G1 G2 empty nothing done (which practicetrue 50% nodes). Right: Energy cost labels (black) assignedG1 G2 resulting two Dijkstra runs starting blue node.resulting intervals nodes G2 expressed purple. we, example,search matching targets source node labeled 3 G1 , intervalsreveal node labeled 9 G2 suitable candidate.5.3 Peak Node Mapping (PNM)large number B-violating paths originate source V . Exploringpaths Dijkstra PHAST time-consuming. core idea PNMenumerate B-violating paths completely different also taking CH-representationpaths consideration. explained above, shortest CH-paths unimodal respectlabeling l node maximal label called peak. Intuitively, nodeshigh label appear shortest paths peaks. fact, real-world graphs,5% nodes highest level constitute peaks reasonably long shortest paths.gives rise path enumeration algorithm, explores paths sourcepeak, resulting dramatically reduced search spaces majority nodes.Algorithm. PNM algorithm works follows: consider one one every nodep V potential peak. shortest paths peak p contain nodessmaller label, need search upwards paths ending p downwards pathsstarting p prefix suffix candidates. respective subgraphs CH-graphG0 containing paths called G1 := Gin (p) G2 := Gout (p), see Figure 5, left,illustration. conventional Dijkstra run G1 G2 (which typicallysparse) reveals distances p contained nodes. interestedcombinations shortest (upward) paths G1 shortest (downward) paths G2leading minimal B-violating paths. Testing naively expensive. Therefore,construct p interval tree (Berg, Cheong, Kreveld, & Overmars, 2008)nodes G2 . interval ]a, b], associate node t, denotes rangepossible energy consumption values path prefix (s, p) G1 (s, p) (p, t)minimal B-violating path. intervals easily computed single passDijkstra search tree G2 , see Figure 5, right, example. every possible642fiPlacement Loading Stations Electric VehiclesFigure 6: Illustration three methods representing storing shortest paths (storedelements always colored orange): left complete vertex set,middle shortcut set/CH-path (the heights vertices image correspond l-value), right triple consisting source, targetpeak vertex.source G1 , query interval tree set targets time O(log(|G2 |) + |T |)storing resulting paths quadruples (s, p, t, c(s, p) + c(p, t)), . Noteemployment interval trees make use special choice . different choicesinterval computation procedure adapted.Filtering. nodes processed, set B-violating paths which,unfortunately, shortest paths. concatenation two shortest paths ((s, p)(p, t)) need shortest path itself. remains filter setappropriately. achieved using distance oracles quasi constant look-uptime e.g. provided HL another pass nodes role peak, alwayspruning quadruple s, shorter path found p0 6= p. Note, pruningalready employed construction phase intermediate path set sizesbecome large. final set paths stored list triples (s, p, t) evencompact representation CH-representation. Figure 6, visual comparisonprovided storing path vertex set, shortcut set, PNM triple.Accessing nodes respective shortest s-t-path G required greedyHitting Set algorithm longer trivial sophisticated representation schemes,though. Therefore, develop suitable adaptions greedy algorithm workCH-representations PNM triples Section 6.5.4 Minimality Checksmentioned introducing Hitting Set formulation ESC, need extractstore minimal B-violating shortest paths, i.e. paths subpath B-violatingwell. Adding non-minimal paths set system course invalidatesolution, increases complexity storing sets, running time greedyalgorithm later on.naive extraction scheme, B-violating path = sv1 . . . vk identified Dijkstra run might minimal, path might still B-violating withoutprefix. precisely, check path remains B-violating removingfirst edge (s, v1 ), so, dont include S. respective Dijkstra runconsidering v1 source ensure B-violating path missed.643fiFunke, Nusser, & StorandtPHAST-based extraction, minimality check becomes complex.paths CH-representation, might direct access first edge pathoriginal graph (if path starts shortcut). unpack firstshortcut performing minimality check.PNM prefix suffix deletion might lead subpath still B-violating.immediately decision favor triple (s, p, t), check first edgepath p last edge path p removaldestroy property path B-violating. Again, like PHAST, pathsCH-representation construction, therefore unpack shortcuts first.5.5 TransformabilityNote, extraction scheme tie us certain path representation. fact,mentioned representations (vertex sets, source-target-pairs, CH-paths, triples)converted other. Especially transformation vertex sets CH-pathsturn favorable, CH-paths yield fair trade-off space consumptionapplicability greedy algorithm explained detail Section 6.provide details transformations including theoretical transformation times.latter assume complete vertex set representation contains k elements.source-target-pairs vertex sets. Given s, t, complete path computed viaDijkstra run G backtracking, requiring O(n log n + m) time.vertex sets CH-paths. assume CH-labels l : V N available.recursive procedure allows turn vertex set CH-path. firstidentify node v0 vertex set highest l-value (the peak).split vertex set prefix v0 suffix v0 .sub-paths search node highest l-value, providing usv1 , v2 . two nodes connected v0 via direct edge/shortcut CHgraph (as nodes contracted before), (v1 , v0 ), (v0 , v2 ).provides us prefix (nodes v1 ) suffix (nodes v2 )recurse. algorithm stops prefix suffix(or prefix monotonously increasing wrt l suffix monotonouslydecreasing), see Figure 7, top, illustration. Assuming CH-representationcontains h shortcuts, transformation performed O(k h).CH-paths PNM triples. need extract peak vertex (besidessource target) done O(h) CH-path consists h shortcuts.PNM triples CH-paths. Given source s, target t, peak p, run Dijkstrastarting p G1 := Gin (p) G2 := Gout (p) settled.number edges CH-graph assumed O(m), runtime singletransformation O(n log n+m) like transformation source-targetpairs vertex sets. typically peak small l-value small G1G2 , peak high l-value generates many s-t-paths once, amortizedcosts per path considerably smaller.644fiPlacement Loading Stations Electric VehiclesFigure 7: vertex sets CH-paths back. first row, vertex set given.l-values derived CH construction indicated vertex elevations.recursively vertex highest l value (marked red images)prefix suffix path extracted shortcuts added spanpath sections lower l-value. second row, CH-path recursivelyunpacked. Shortcuts colored blue. red arrows point replacementedges next unpacking step. final path startedfirst row, contain shortcuts.CH-paths vertex sets. Given CH-path, apply unpacking methoddescribed Section 4, i.e. recursively replace shortcuts spanned edgespath consists original edges (see Figure 7, bottom). resultingpath consists k vertices, unpacking performed O(k).vertex sets source-target-pairs. first last vertex completepath stored rest neglected. transformation costs O(1) O(k)consider deletion k 2 elements well.following, longer investigate source-target pair representation,storing PNM triples requires one item per path time allowsefficient access paths vertices.6. Greedy Hitting Set Computationexplained above, greedy approach natural strategy solve Hitting Setproblem approximately. Theoretically yields solutions within factor 2 ln(n)optimum setting. practice greedy performs much better theoretical,priori approximation guarantee implies.simplest set system representation application greedy HittingSet algorithm straightforward requires deliberate operations setsystem/path representations see following.6.1 Complete Vertex Setspaths simply given set contained vertices, single scansets determine best node hitting paths. Another scan remove paths645fiFunke, Nusser, & Storandthit selected node. two scans also combined oneupdating counter values removing newly hit paths (an initial countstill necessary). Unfortunately, space consumption approach enormous, alsomaking single scan quite expensive.6.2 CH-Pathsrepresenting minimal B-violating paths CH-paths, could convert singlepaths original paths unpacking shortcuts operate completevertex set path. Note paths would processed one one oneunpacked path would kept memory time. much better strategyuncompressing every single CH-path get original node sets: maintainingusage counter edge (counting many shortest paths use edge), firstscan edges CH-paths set system hit, incrementing respectivecounters. traverse shortcut edges graph decreasing orderconstruction CH-preprocessing, incrementing counters spanned edges.node counters, maintained identify maximum node, derived finalscan original (non-shortcut) edges. Keeping reverse information edgesspanned shortcut also allows identification sets hitnode. update edge counters removing CH-paths set, pickingnode requires one scan edges push counts non-shortcutedges, one scan usage counters one scan set CH-paths.6.3 Peak Node Triplespaths described triples source, target, peak node, get CHpath representation described Section 5.5. proceed CH-pathrepresentation. Note, CH-path representation computed demandpeak every round avoid keeping paths CH-representation permanently memory.7. Multi-stage Constructioncountry-sized graphs, even improved set system extraction methods representations reduce space time consumption enough practical. Thereforeintroduce procedure interleaves set extraction greedy Hitting Setcomputation multi-stage algorithm. multi-stage algorithm requires significantlyless space complete construction set system, therefore appliedconsiderably larger instances.7.1 Nested Hitting Setsinstance ESC problem determined battery capacity B, makefollowing important observation: every capacity B 0 B, Hitting Set L0instance corresponding B 0 also feasible original instance (having enough BLSssmaller battery capacity also suffices larger battery capacity). So, example,B = 20kWh, solving problem e.g. B 0 = 5kWh would feasible well.construction L0 B 0 B might considerably faster due smaller exploration646fiPlacement Loading Stations Electric Vehicles4446656B 0 = 5, B B 0 = 15B 0 = 10, B B 0 = 10B 0 = 13, B B 0 = 74524B = 20424524526Figure 8: battery capacity B = 20 kWh, shortest path needshit loading station exhibits energy costs 21. conventionalconstruction, complete s-t-path would part Hitting Set instance.three lower images illustrate happens use nested construction different values B 0 . red+purple/dashed subpath indicatesminimal B 0 -violating path starting s. brown square possible hitterpath. purple/dashed+blue path indicates minimal (B-B 0 )-violatingpath starting brown square. path always subpath s-t matter B 0 chosen. hitting blue+purple path (large dot image)assures B-violating paths hit well. nodes marked brownsquares part final solution.radii, L0 typically also much larger necessary instance defined B.simply using solution B 0 = 5kWh although real battery capacity B = 20kWh,expect result many superfluous loading stations.another advantage first quickly computing Hitting Set small valueB 0 : allows us construct new, smaller problem instance feasible HittingSet L00 also feasible original problem (defined B) L00 hopefully muchsmaller L0 . second instance defined set paths originating L0(B-B 0 )-violating.prove Lemma 3 Hitting Set L00 second instance indeed alsoHitting Set original instance.Lemma 3. Given battery capacity B, second capacity B 0 < B. Let L0 feasibleESC solution B 0 , L feasible Hitting Set minimal shortest (B-B 0 )-violatingpaths originating L0 , L valid ESC solution battery capacity B.Proof. Consider B-violating s-t-path original instance. must hitnode v L0 less B 0 away s. path v, . . . , hittertarget (or prefix thereof) new constructed path set (B-B 0 )-violatingpaths originating L0 . Therefore subpath hitter L. Hence L hits Bviolating shortest path, makes L valid ESC solution battery capacity B. Figure8 illustrates proof small example.647fiFunke, Nusser, & Storandt7.2 Path Coversmall values B, even compute Hitting Sets without explorationevaluation function purely based connectivity structure graph usingso-called k-Hop Path Cover (Funke, Nusser, & Storandt, 2014a) generalizationVertex Cover. construct set vertices C V directed (notnecessarily shortest) k-hop path G contains least one vertex C (for k = 1simply Vertex Cover). C ESC solution B B maximal energycost k-hop path, easily upper bounded k times maximal energycost edge. values k 48 takes minutes even large graphs usingvariant depth first search, making step negligible overall running time.7.3 Combinationimplementation combined nested Hitting Sets k-Hop Path Covers multistage procedure, constructing sequence Hitting Sets Lr , Lr1 , , L1 = L sequencevalues Br < Br1 < < B1 = B, finally returning L Hitting Set giveninstance.first Br results k-Hop Cover small value k, subsequent solutionsapply nested Hitting Set approach (and choose Bi manually). mightloss terms quality compared greedy algorithm full set system duenested construction. experimental evaluation show, though, loss termsquality pronounced, running times drastically improved,graph sizes handle approach much larger.8. Refinements Lower Boundssection introduce speed-up strategy greedy algorithm independent employed set representation. develop algorithms constructinstance-based lower bounds ESC solution. bounds helpfulexperimental evaluation, prove posteriori, running algorithmscomputed solutions fact pretty close optima.8.1 Multiple Hitters HeuristicEven non-naive representations, considerable work involved pickingnext best node greedy algorithm. might worthwhile add severalnodes Hitting Set round. Normally, pick node hitsfar unhit sets, refrain picking nodes round pickingfirst node influences hit counters others. hand, pick nodesinterfere other, quality solution decline severely.One way achieve generate list nodes sorted ascending orderhit counters, always picking first one going list selecting nextnodes shortest path distances least nodes already picked.appropriately chosen, e.g. upper bound longest shortest pathB-violating. Thereby make sure path set increased hit counter twonodes picked one round.648fiPlacement Loading Stations Electric VehiclesFigure 9: Set seven node-disjoint B-violating paths (highlighted grey) small example graph. Every valid Hitting Set B-violating paths graphcontain least seven vertices, vertex hit one greymarked paths. Therefore size set node-disjoint paths feasible lowerbound optimal Hitting Set size.8.2 Simple Instance-Based Lower Boundsevaluate quality heuristics, would like compare outcomeoptimal solution. optimal value typically unknown, instead comparegood, easily computable lower bound. study Transit Nodes (Eisner & Funke,2012) rather involved lower bound proposed, takes effort comparablesolving Hitting Set problem itself. propose much simpler alternative sufficespurposes: by-product generation set system obtainset node-disjoint B-violating paths. two paths set non-emptyintersection. Clearly, feasible solution must contain extra node per path set.Hence size set node-disjoint paths yields valid lower bound, see Figure 9illustration.case generate set system explicitly (because use nested Hitting Sets),greedily extract set node-disjoint paths running Dijkstra computationsrandom sources adding B-violating paths set long intersectpreviously selected ones. size set provides valid lower bound time.9. Dealing Real-world SettingsThroughout paper, made assumptions ESC problem sakeclean definition easier algorithm descriptions. assumptions necessarilymet practice, explain following adapt algorithms still performwell real-world settings.649fiFunke, Nusser, & Storandt9.1 Ambiguous Shortest Pathsexposition always assume uniqueness shortest paths. sectiondiscuss necessary modifications case shortest paths ambiguous.First all, enforce uniqueness shortest paths symbolic perturbation.end define cost path = v0 v1 . . . vk sum c edge costs,vector (c , v0 , v1 , . . . , vk ). Two cost vectors compared lexicographically,is, two t-paths 1 = sv1 . . . 2 = sw1 . . . aggregated edgecosts, minimal vi 6= wi , 1 considered shorter vi < wi , otherwise2 considered shorter. symbolic perturbation easily incorporated e.g.Dijkstras algorithm. computation shortest paths node consider(possibly tentative) distance label node v aggregated edge costsds (v) along respective path tuple (ds (v), preds (v)), preds (v) denotespredecessor current path v. ordering case identical ds (v) valuesdetermined node ID predecessor. Edge relaxations well organizationpriority queue made according augmented distance labels. easysee yields canonical unique shortest paths described above.edge lengths typically measured precision around one meter rarely happens two paths exhibit exactly length. circumstances, though,might desirable actually maintain multiple shortest paths nodes (hitting/ allowing travel along without running energy). Fortunately, adapt algorithms cater shortest paths. minimalchange backtracking Dijkstra exploration well PNM approachslight change CH construction. former, retrieve paths/sets, insteadfollowing predecessor reference node v (which set edge relaxation),inspect adjacent nodes check whether distance labels respective edgecost sums distance label v. yields neighbors v lie shortestpath v. Recursing neighbors obtain shortest paths. CHconstruction, crucial operation contraction node v. original version,every pair neighbors u, w v (u, v), (v, w) E, shortcut (u, w) created(with cost path uvw) uvw shortest path u w. maintainshortest paths, add shortcut uvw shortest path u w (but possibleexistence shortest paths). way every shortest path CH representation;comes cost slightly shortcuts added.lower bound construction Section 8.2 modified also yield lower boundcase ambiguous shortest paths follows: s-t-pair contributelower bound shortest paths require least one recharging event.compute valid lower bound retrieve maximal set vertex pairs,two vertex pairs set respective shortest path node sets allowed overlap.generalizes idea node-disjoint shortest paths case ambiguous shortest paths.experiments showed, though, considering shortest paths yieldnoticeably different results mainly due rarity reasonably long ambiguous shortestpaths. disregard ambiguities implementation, extremely smallbattery capacities (corresponding cruising range less 2km), found ambiguous650fiPlacement Loading Stations Electric Vehiclesshortest paths covered BLS placement. larger battery capacitiesBLS placement fact covered (of few) ambiguous shortest paths.9.2 Restricted Loading Station Placementassume ESC problem definition loading stations placed everynode network. practice, though, set possible locations might restricteddue technical, financial legal reasons. set V 0 V candidate nodesloading stations, incorporate algorithms follows: constructionset system, check every shortest path whether least one nodesV 0 . Otherwise, ignore path completely (as never hit anyway).CH-based extraction methods, set flag every edge/shortcut indicating whetherspanned path contains node V 0 not. allows perform checkCH-path without unpack it. actual Hitting Set computation simplyskip nodes V 0 compute feasible solution.Note, depending choice V 0 final Hitting Set might allow driveshortest paths without running energy, though. incorporatelocations suitable become loading stations others without losing globalreachability demanded ESC problem formulation, introduce prize functionp : V R+ . higher prize complicated expensive placecharging station node. exploit weighted Hitting Set problembasis computations. goal find set L elementsP universehit sets set system minimizing accumulated prize p(l).set system extraction methods remain unaffected prizes. greedy HittingSet computation step, selection next best hitter changes. Previously, selectednode next hits far unhit sets. Now, S(v) denotes set far unhitsets contain v, select node minimizes average prize per set p(v)/|S(v)|.approximation guarantee greedy algorithm weighted Hitting Set problemunweighted Hitting Set problem (Chvatal, 1979). expectsolution consist mainly cheap charging stations possibly expensive onesrequired establish reachability two nodes.9.3 Placement Given Initial Loading Station SetAnother assumption made ESC problem definition try constructnetwork loading stations scratch, i.e. starting loading stations all.loading stations still sparse many areas, ones already installedignored. Existing loading stations easily taken account solvingESC problem: given initial set loading stations L0 , check extractionset system path already hit L0 . case, pathpruned. remaining steps Hitting Set computation work like before.10. Experimental Evaluationproposed techniques computing ESC solutions evaluated multi-threadedimplementation written C++ executed 2nd generation Intel Core desktop hard651fiFunke, Nusser, & Storandtware, i7-3930 (6 cores, 64GB RAM) complete set generations i7-2700 (4cores, 32GB RAM) multi-stage construction nested Hitting Sets. usefollowing abbreviations state results: K=103 , M=106 , s=seconds, m=minutes, h=hours,d=days, GB=109 Bytes. distinguish CPU time (total CPU usage) real time(wall clock time). Several road networks Germany derived OpenStreetMap dataregionPforzheimTubingenBaden-Wurttemberg SouthSouthern GermanyGermanyabb.(PF)(TU)(BW)(SG)(GE)|V |0.2M0.5M2.2M4.2M17.7M|E|0.4M1.0M4.6M8.6M36.0MTable 1: Test graph characteristics.(OSM, 2015) used evaluation, see Table 1 overview. edge cost functionc used travel time along edge, paths hit indeed quickest paths (theterm shortest paths conventionally used subsuming kinds metrics). Energy consumption EV modeled explained introduction using distance dataOSM elevations provided Shuttle Radar Topography Mission (NASA, 2015). Bcorresponds battery capacity translates certain terrain dependent cruisingrange. use capacity B PF TU allows drive 40 kilometers average,125 kilometers larger graphs. , models much going uphillincreases energy consumption, equals 4.10.1 Dealing Complete Set SystemsConstruction Representation. Let us first examine time space complexityextracting complete set minimal B-violating paths. constructed set systemsusing naive strategy (NAIVE representing path complete sequencevertices), PHAST-based exploration (PHAST paths CH representation),peak node mapping (PNM representing path source,peak,target triple).respective results found Table 2. Unfortunately, two smallest instancesfeasible process using strategies; already BW graph, time spaceconsumption NAIVE exploded (extrapolated 500GB 23 CPUdays). comparison, PHAST factor 3 faster NAIVE, spaceconsumption CH-paths improvement least order magnitude. PNMconstruct BW instance 4.4 CPU hours, compared week needed PHAST,space consumption using triples decreases another factor 2 (note longerpaths advantage PNM vs. CH representation increases). SG GE, alsoPHAST PNM took much time space (e.g. extrapolated 557GB/112daysPHAST). larger networks, constructing complete set systems seems infeasible.Comparison Path Representations. explained Section 5.5, path extractionscheme tie us path representation. Instead, transform extracted652fiPlacement Loading Stations Electric VehiclesGraphPFTUBWGraphPFTUBW# paths38M168M2715Mspace consumptionNAIVEPHASTPNMvertex sets CH-pathstriples5.2GB0.2GB0.1GB24.0GB2.1GB0.9GB[526.3GB]34.6GB 14.3GBcomputation timeNAIVEPHASTPNMCPUrealCPUrealCPUreal1.5h0.3h 26.7m 5.0m1.8m 25.1m24.6h4.1h7.5h1.4h 27.3m5.4m[23.1d] [3.9d]7.5d 33.1h4.4h 47.0mTable 2: Comparison path extraction/representation schemes. B corresponds40km (PF TU) 125km (BW) cruising range flat terrain. Timings includeCH-construction PHAST/PNM. Values brackets extrapolated.paths introduced representations storing them. representationprovides trade-off space consumption access times single paths. Figure10 illustrates values small large benchmark instance (TU GER).Note, access times paths represented triples amortized. reallywant extract single path only, costs comparable ones (s, t)representation. greedy algorithm, require access huge sets pathsevery round, (s, p, t) representation pays off. CH representation, accesstimes reported figure purely completeness. significantgreedy Hitting Set computation, though, specialized greedy algorithm CH pathsrequire unpack paths. fact, access times relevant greedyalgorithm even ones vertex set representation, CH representationcontains far less elements sweep over. Hence, regard CH-paths bestpath representation soon set system fits memory representation.transformation times two path representations estimatedresults reported Figure 10 well. Every transformation runs constant lineartime according analysis cost less comparable accessing paths vertexset representation. transformation time CH-paths vertex sets vice versacorresponds access time paths CH representation. transform triplesCH-paths, need time access path triple form minus time unpackCH-path.Hitting Set Computation. evaluated standard greedy algorithm wellmultiple hitters (MH) variation set systems PF, TU, BW varying choicesB. Figure 11 shows performance terms quality (standard greedy vs. MH)well running time (how much faster MH compared standard greedy). ratiosaveraged test graphs; bound B chosen almost zero 60 percent653fiFunke, Nusser, & StorandtFigure 10: Comparison several path representation schemes terms space consumption access time. axes log scale.maximum energy consumption shortest path respective network (in factlong paths, set systems got simple greedy even constructed optimum,hence approximation ratio 1 Figure 11). cases, greedy produces results muchcloser optimum theoretical 2 ln n guarantee, maximum deviationlower bound indeed less 4.5. Employing MH strategy increases HS sizeslightly, yields significantly decreased running times especially smaller bounds B(where hitters chosen). Still, compared construction timeset systems, Hitting Set computation times negligible, stateexplicitly here. change employ multi-stage construction, though.10.2 Multi-stage Constructionconstruction complete set system proven infeasible larger roadnetworks, make use idea multi-stage construction.k-Hop Cover+PNM. Let us first examine compact set system constructedusing PNM approach initial k-Hop Path Cover. BW networkcomputed k = 32-Hop Cover C (146, 494 nodes) corresponds ESC solutionB 0 = 8832 (and cruising range 9km flat terrain). PNM usedcreate final compact set system considering (B B 0 )-violating paths startnodes C. surprisingly, number paths hit reduces drastically2715M Table 2 24M Table 3. running times still quite high, though,approach save exploration peak (therefore stages654fiPlacement Loading Stations Electric Vehicles4035runtime ratio6quality greedyquality MHruntime greedy/runtime MH53042520315102approximation factor4550110203040percentage max B5060Figure 11: Performance greedy algorithm multiple hitters variant (MH)averaged PF, TU BW.GraphBWSGGE|C|146,494180,455769,760B088321004815808CPU2.2h6.0h64.8hreal35.5m2.8h27.6h# paths24M75M1085MTable 3: Instance creation (B = 40K) via PNM initial k-hop solution C k = 32.help much here). Since improvements terms running time using PNMmulti-stage approach cannot expected, let us concentrate naive approachextracted paths converted CH-representation.Multi-Stage Hitting Sets. employ following strategy: first, construct k-Hop CoverC e.g. k = 32 yields initial Hitting Set Lr bound Br .construct reduced set system consisting (Br1 Br )-violating paths startingnodes Lr compute Hitting Set Lr1 set system. Here, use naiveGraphTUSGTUSGGEGEGEBr1.8k4.2k15.8k6.2k15.8kBi nested HS1k,5k,40k2k,10k,125k4.8k,40k12.2k,125k17.8k,33.8k,125k8.2k,24.2k,125k17.8k,25.8k,49.8k,125k|L|1201061161108687281212LB33333333190190190APX3.643.213.523.334.573.836.38CPU9m404m8m242m908m1156m645mreal3m106m2m63m265m322m209mTable 4: Multi-stage Hitting Set computation (LB = lower bound, APX = approximationfactor). last two experiments seen detail Table 5.655fiFunke, Nusser, & Storandt4321PBi6.2k8.2k24.2k125k54321PBi15.8k17.8k25.8k49.8k125ktSS363m249m467m1079mtSS203m101m81m146m531m#paths34.6M36.8M13.5M#paths19.7M17.1M9.2M5.6MtHS14s25m21m31m77mtHS36s25m21m17m50m113m|Li |1388k223k16k728|Li |770k208k38.6k84451212CPU14s388m270m498m1156mCPU36s228m122m98m196m645mTable 5: Statistics 4-stage run starting k = 16-Hop Cover (above), 5stage construction initialized k = 32-Hop Cover (below) GE. column#paths gives number sets hit respective stage. tSS tHSdenote CPU time set system construction Hitting Set computationrespectively.extraction transform vertex sets CH-paths efficient storage. proceediteratively reaching B1 = B final Hitting Set L1 = L. intuitive demandgap B2 B1 large make sure last Hitting Setinstance still faithfully characterizes original Hitting Set instance. Table 4 showsresults various choices multi-stage parameters. Table 5 give detailedaccount intermediate calculations large GE graph. experiments confirmlarger gap B2 B1 is, better quality final HittingSet. comes cost expensive last stage, though. contrastexperiments, first two calculations Table 4 conducted without initialk-Hop Cover. results obtained TU SG suggest initial k-Hop Coveraccelerates calculation maintaining similar Hitting Set size. Furthermore,APX values remain low even though lower bounds obtained naive way.Note example graph Germany, priori approximation guaranteeplain greedy algorithm (which feasible due excessive running time spaceconsumption) 2 ln n 19.5. proves excellent quality Hitting Setsparticular instances. Table 5 shows introducing multiple stages keeps intermediateset systems rather compact, efficient computation actually possible.11. Conclusions Future Workshowed model solve natural important facility location problemE-mobility context, taking radically different approach previous ones avoidingdetours loading stations EVs.656fiPlacement Loading Stations Electric Vehiclesnaive strategy allows solution small instances hundredthousand nodes, compact representation schemes underlying set systemsheuristic modifications standard greedy approach make computation solutioneven country-sized networks like Germany possible. Instance-based lower boundscertify solution quality close optimal (within factor 4) farpessimistic theoretically achievable approximation bound. fact remarkableall, possible compute 4-approximate solution seemingly intractable HittingSet problem within hours quadcore desktop PC. computation determinedaround 800 locations placing BLSs would establish complete coverage Germany.framework require metric decides shortest pathshit identical metric determines paths shortest. factfactored using function, depending application scenarioalso used implement hitting criteria (e.g. hop distances risk values).future work intend examine exact hitting requirement relaxed.Naturally, necessary always BLS right respective shortestpath, nearby one suffices. could modeled enlarging vertex setsrespective shortest paths surrounding vertices. Hitting Set sizes variantexpected considerably smaller hitting shortest paths directly. Anotherdirection research take account capacity constraints BLSs (Lam et al.,2013); particular urban areas certainly necessary provide recharging stationslarge number vehicles.ReferencesAbraham, I., Delling, D., Goldberg, A. V., & Werneck, R. F. (2012). Hierarchical hublabelings shortest paths. European Symposium Algorithms (ESA), pp. 2435. Springer.Artmeier, A., Haselmayr, J., Leucker, M., & Sachenbacher, M. (2010). shortest pathproblem revisited: Optimal routing electric vehicles. German ConferenceArtificial Intelligence (KI), pp. 309316.Arz, J., Luxen, D., & Sanders, P. (2013). Transit Node routing reconsidered. InternationalSymposium Experimental algorithms (SEA), pp. 5566. Springer.Bast, H., Funke, S., & Matijevic, D. (2009). Ultrafast shortest-path queries via TransitNodes. shortest path problem : 9th DIMACS implemenation challenge, Vol. 74DIMACS Series Discrete Mathematics Theoretical Computer Science, pp.175192, Providence, RI. AMS.Berg, M. d., Cheong, O., Kreveld, M. v., & Overmars, M. (2008). Computational Geometry:Algorithms Applications (3rd ed. edition). Springer-Verlag TELOS, Santa Clara,CA, USA.Chvatal, V. (1979). greedy heuristic set-covering problem. Math. Oper. Res.,4 (3), 233235.657fiFunke, Nusser, & StorandtDelling, D., Goldberg, A. V., Nowatzyk, A., & Werneck, R. F. F. (2011). PHAST: Hardwareaccelerated shortest path trees. International Parallel Distributed ProcessingSymposium (IPDPS), pp. 921931.Dinur, I., & Safra, S. (2004). hardness approximating minimum Vertex Cover.Annals Mathematics, 162, 2005.Eisner, J., & Funke, S. (2012). Transit Nodes - lower bounds refined construction.Algorithm Engineering Experiments (ALENEX).Funke, S., Nusser, A., & Storandt, S. (2014a). k-Path Covers applications.International Conference Large Databases (VLDB).Funke, S., Nusser, A., & Storandt, S. (2014b). Placement loading stations electricvehicles: detours necessary!. AAAI Conference Artificial Intelligence.Geisberger, R., Sanders, P., Schultes, D., & Delling, D. (2008). Contraction Hierarchies:faster simpler hierarchical routing road networks. International WorkshopExperimental Algorithms (WEA), pp. 319333. Springer.Lam, A., Leung, Y.-W., & Chu, X. (2013). Electric vehicle charging station placement.International Conference Smart Grid Communications (SmartGridComm), pp.510515.NASA (2015). Shuttle Radar Topography Mission. Online. http://www2.jpl.nasa.gov/srtm.OSM (2015). OpenStreetMap Project. Online. http://www.openstreetmap.org.Storandt, S., & Funke, S. (2013). Enabling E-Mobility: Facility location battery loadingstations. Conference Artificial Intelligence (AAAI).658fiJournal Artificial Intelligence Research 53 (2015) 1-40Submitted 08/14; published 05/15Coactive LearningPannaga Shivaswamypshivaswamy@linkedin.comLinkedIn Corporation2029 Stierlin CtMountain View, CA 94043, USAThorsten Joachimstj@cs.cornell.eduDepartment Computer ScienceCornell UniversityIthaca, NY 14853, USAAbstractpropose Coactive Learning model interaction learning systemhuman user, common goal providing results maximum utilityuser. Interactions Coactive Learning model take following form:step, system (e.g. search engine) receives context (e.g. query) predicts object(e.g. ranking); user responds correcting system necessary, providing slightlyimproved necessarily optimal object feedback. argue preferencefeedback inferred large quantity observable user behavior (e.g., clicksweb search), unlike optimal feedback required expert model cardinalvaluations required bandit learning. Despite relaxed requirements feedback,show possible adapt many existing online learning algorithmscoactiveframework. particular, provide algorithms achieve O(1/ ) average regretterms cardinal utility, even though learning algorithm never observes cardinal utilityvalues directly. also provide algorithm O(log(T )/T ) average regretcase -strongly convex loss functions. extensive empirical study demonstratesapplicability model algorithms movie recommendation task, wellranking web search.1. Introductionwide range systems use today, interaction human system takesfollowing form. user issues command (e.g. query) receives possiblystructured result response (e.g. ranking). user interacts results (e.g.clicks), thereby providing implicit feedback users utility function. threeexamples systems typical interaction patterns:Web Search: response query, search engine presents ranking [A, B, C, D, ...]observes user clicks documents B D.Movie Recommendation: online service recommends movie user. However,user rents movie B browsing collection.Machine Translation: online machine translator used translate wiki pagelanguage B. system observes corrections user makes translated text.c2015AI Access Foundation. rights reserved.fiShivaswamy & Joachimsexamples, user provides feedback resultssystem. However, feedback incremental improvement, necessarilyoptimal result. example, clicks web search results inferuser would preferred ranking [B, D, A, C, ...] one presented. However,unlikely best possible ranking. Similarly recommendation example,movie B preferred movie A, may even better moviesuser find browsing. machine translation example, corrected text need best possible translation language language B.three examples, algorithm typically receives slightly improved result userfeedback, necessarily optimal prediction cardinal utilities. conjecturemany applications fall schema, ranging news filtering personalrobotics.paper, propose Coactive Learning model system-user interactions.formalize Coactive Learning general model interaction learning systemuser, define suitable notion regret, validate key modeling assumptionnamely whether observable user behavior provide valid feedback modeluser study web search. new model viewed cooperative learning processsystem user, parties aim optimize utility lack meansachieve goal own. Specifically, (boundedly rational) user computationallylimited maximizing utility space alternatives, system limitedwell knows users utility function.proposed online learning framework differs significantly existing online learningmodels terms observed feedback (see related works section comparison).strength proposed framework possible derive wide range coactivelearning algorithms adapting existing online algorithms convex optimization.provide template Coactive Learning algorithms show several instancestemplate paper, case, prove worst case analysisalgorithm carries conventional online learning framework coactivelearning despite differences two models.In particular, cases linearutility models convex cost functions show O(1/ ) regret bounds matchinglower bound. also show regret bound improved second orderalgorithm strongly convex functions. learning algorithms perform structured outputprediction (see Bakir, Hofmann, Scholkopf, Smola, Taskar, & Vishwanathan, 2007) thusapplied wide variety problems. study several interesting extensionsframework using batch updates, expected feedback, exponentiated learningalgorithm. Finally, provide extensive empirical evaluations algorithms movierecommendation web search task, showing algorithms highly efficienteffective practical settings.rest paper organized follows. discuss related work Section 2.Section 3 formally introduce coactive learning model also motivate modelreal-world user study. present linear version algorithm alongseveral extensions Section 4. Section 5, detail general schema derivingcoactive learning algorithms regret bounds. particular, derive exponentiated gradient algorithm Section 5.1, propose coactive learning algorithmsminimizing general convex losses -strongly convex losses Sections 5.2 5.3.2fiCoactive Learningempirical evaluation proposed framework algorithms done Section 6conclude Section 7. include proofs Appendix.2. Related WorksCoactive Learning Model bridges gap two forms feedbackwell studied online learning. one side multi-armed bandit model (e.g.,Auer, Cesa-Bianchi, Freund, & Schapire, 2002b; Auer, Cesa-Bianchi, & Fischer, 2002a),algorithm chooses action observes utility (only) action.side, utilities possible actions revealed case learningexpert advice (e.g., Cesa-Bianchi & Lugosi, 2006a). Online convex optimization (Zinkevich,2003; Hazan, Agarwal, & Kale, 2007) online convex optimization bandit setting(Flaxman, Kalai, & McMahan, 2005) continuous relaxations expertbandit problems respectively. model, information two arms revealediteration (the one presented one receive feedback user),sits expert bandit setting. closely related Coactive Learningdueling bandits setting (Yue, Broder, Kleinberg, & Joachims, 2009; Yue & Joachims,2009). key difference arms chosen algorithm duelingbandits setting, whereas one arms chosen user Coactive Learningsetting. model allows contextual information like contextual bandits (Langford &Zhang, 2007), however, arms problem structured objects rankings.summary framework compares existing frameworks shownTable 1. types feedback also explored literature. example,multi-class classification problems, algorithm makes prediction basedcontext, feedback received whether prediction correct wrong opposedactual label (Crammer & Gentile, 2011; Kakade, Shalev-Shwartz, & Tewari, 2008).seen observing partial feedback (as opposed actual cardinal feedback)bandit problem.pointed above, Coactive Learning algorithms conventional online learningalgorithms operate different types environments. Coactive Learning algorithms presentobject observe another object feedback, online convex learning algorithmspick vector step observe gradient vector feedback. Despitecontrast online learning Coactive Learning, two algorithms presentedpaper closely related work Zinkevich (2003) Hazan et al.(2007). show possible adapt regret bounds algorithmscorresponding regrets bounds Coactive Learning. heart algorithmsanalysis well-known idea (Polyak & Tsypkin, 1973) descent algorithmsnecessarily need know gradients, vector positive inner productgradient expectation suffices.feedback Coactive Learning takes form preference, differentordinal regression ranking. Ordinal regression (e.g., Crammer & Singer, 2001) assumestraining examples (x, y), rank. Coactive Learning model, absolute ranksnever revealed. closely related learning pairs examples (Herbrich, Graepel, & Obermayer, 2000; Freund, Iyer, Schapire, & Singer, 2003; Chu & Ghahramani, 2005),since circumvents need absolute ranks; relative orderings required. Vari3fiShivaswamy & JoachimsFrameworkBanditsExpertsDueling BanditsCoactive LearningAlgorithmpull armpull armpull two armspull armFeedbackobserve cardinal reward arm pulledobserve cardinal rewards armsobserve feedback one betterobserve another arm betterTable 1: comparison different online learning frameworks.ants pairwise ranking algorithms applied Natural Language Processing(Haddow, Arun, & Koehn, 2011; Zhang, Lei, Barzilay, Jaakkola, & Globerson, 2014)image annotation (Weston, Bengio, & Usunier, 2011). However, existing approaches requireiid assumption typically perform batch learning. Finally, large bodywork ranking (see Liu, 2009). approaches different Coactive Learningrequire training data (x, y) optimal ranking query x. However,draw upon structured prediction approaches ranking problems designmodels.Coactive learning first proposed Shivaswamy Joachims (2012); paperserves journal extension paper, adding complete discussion batch updatesexpected feedback, exponentiated gradient algorithm, O(log(T )/T ) algorithm-strongly convex loss functions, substantially extended empirical evaluation.Since then, coactive learning applied intrinsically diverse retrieval (Raman,Shivaswamy, & Joachims, 2012), learning ranking function click feedback (Raman,Joachims, Shivaswamy, & Schnabel, 2013), optimizing social welfare (Raman & Joachims,2013), personal robotics (Jain, Wojcik, Joachims, & Saxena, 2013), pattern discovery (Boley,Mampaey, Kang, Tokmakov, & Wrobel, 2013), robotic monitoring (Somers & Hollinger,2014), extended allow approximate inference (Goetschalckx, Fern, & Tadepalli, 2014).3. Coactive Learning Modelintroduce coactive learning model interaction (in rounds) learningsystem (e.g. search engine) human (search user) human learningalgorithm goal (of obtaining good results). round t, learningalgorithm observes context xt X (e.g. search query) presents structured objectyt (e.g. ranked list URLs). utility yt user context xt Xdescribed utility function U (xt , yt ), unknown learning algorithm.feedback human user returns improved object yt (e.g. reordered list URLs),i.e.,1U (xt , yt ) > U (xt , yt ),(1)object yt exists. fact, also allow violations (1) formallymodel user feedback Section 3.1.process user generates feedback yt understoodapproximately utility-maximizing action, user modeled boundedly rational1. improvements strict, margin, clear Section 3.1.4fiCoactive Learningagent. particular, user selects feedback object yt approximately maximizingutility user-defined subset Yt possible Y.yt = argmaxyY U (xt , y)(2)approximately boundedly rational user may employ various tools (e.g., queryreformulations, browsing) construct subset perform search. Importantly,however, feedback yt typically optimal label defined as,yt := argmaxyY U (xt , y).(3)way, Coactive Learning covers settings user cannot manually optimizeargmax full (e.g. produce best possible ranking web search),difficulty expressing bandit-style cardinal rating U (xt , yt ) yt consistent manner.puts preference feedback yt stark contrast supervised learning approachesrequire (xt , yt ). even importantly, model implies reliable preference feedback (1) derived observable user behavior (i.e., clicks),demonstrate Section 3.2 web search. conjecture similar feedback strategiesexist many application settings (e.g., Jain et al., 2013; Boley et al., 2013; Somers &Hollinger, 2014; Goetschalckx et al., 2014), especially users assumed actapproximately boundedly rational according U .Despite weak preference feedback, aim algorithm nevertheless presentobjects utility close optimal yt . Whenever, algorithm presentsobject yt context xt , say suffers regret U (xt , yt ) U (xt , yt ) timestep t. Formally, consider average regret suffered algorithm stepsfollows:REGT =1X(U (xt , yt ) U (xt , yt )) .(4)t=1goal learning algorithm minimize REGT , thereby providing humanpredictions yt high utility. Note, however, cardinal value U never observedlearning algorithm, U revealed ordinally preferences (1).3.1 Quantifying Preference Feedback Qualityprovide theoretical guarantees regret learning algorithm coactivesetting, need quantify quality user feedback. Note quantificationtool theoretical analysis, prerequisite parameter algorithm. quantifyfeedback quality much improvement provides utility space. simplest case,say user feedback strictly -informative following inequality satisfied:U (xt , yt ) U (xt , yt ) (U (xt , yt ) U (xt , yt )).(5)inequality, (0, 1] unknown parameter. Feedback utilityyt higher yt fraction maximum possible utility range U (xt , yt )U (xt , yt ). term right hand side inequality ensures user feedback5fiShivaswamy & Joachimsyt better yt , also better margin (U (xt , yt )U (xt , yt )). Violationsfeedback model allowed introducing slack variables :2U (xt , yt ) U (xt , yt ) = (U (xt , yt ) U (xt , yt )) .(6)Note restricted positive, negative well. referfeedback model -informative feedback. Note also possible expressfeedback quality using (6) appropriate value . regret boundscontain , quantifying extent -informative modeling assumption violated.Finally, also consider even weaker feedback model positive utilitygain achieved expectation user actions:Et [U (xt , yt ) U (xt , yt )] = (U (xt , yt ) U (xt , yt )) .(7)refer feedback expected -informative feedback. equation,expectation users choice yt given yt context xt (i.e.,distribution Pxt [yt |yt ] dependent xt ).rest paper, use linear model utility function,U (x, y) = w> (x, y),(8)w RN parameter vector unknown learning system users: X RN known joint feature map known system that3k(x, y)k`2 R,(9)x X Y. Note x structured objects.3.2 User Study: Preferences Clicksvalidate reliable preferences specified Equation (1) indeed inferredimplicit user behavior. particular, focus preference feedback clicksweb-search draw upon data user study (Joachims, Granka, Pan, Hembrooke,Radlinski, & Gay, 2007). study, subjects (undergraduate students, n = 16)asked answer 10 identical questions 5 informational, 5 navigational using Googlesearch engine. queries, result lists, clicks recorded. subject, queriesgrouped query chains question4 . average, query chain contained 2.2queries 1.8 clicks result lists.use following strategy infer ranking users clicks: prependranking first query chain results user clicked throughoutwhole query chain. assess whether U (x, y) indeed larger U (x, y) assumedlearning model, measure utility terms standardmeasure retrieval qualityP10 r(x,y[i])Information Retrieval. use DCG@10(x, y) = i=1 log i+1 , r(x, y[i])relevance score i-th document ranking (see Manning, Raghavan, & Schutze,2. Strictly speaking, value slack variable depends choice definition utility.However, brevity, explicitly show dependence notation.3. make slightly different assumption Section 5.1.4. done manually, automated high accuracy (Jones & Klinkner, 2008).6fiCumulative Distribution FunctionCoactive Learning10.90.80.70.60.50.40.30.20.10Normal ConditionSwapped ConditionReversed ConditionConditions-5-4-3-2-101DCG(x,ybar)-DCG(x,y)2345Figure 1: Cumulative distribution utility differences presented rankingclick-feedback ranking terms DCG@10 three experimental conditionsoverall.2008). get ground-truth relevance assessments r(x, d), five independent human assessors(students) asked manually rank set results encountered querychain. assessors also given true answers navigational queries.linearly normalize resulting ranks relative relevance score r(x, d) [0..5]document.evaluate whether feedback ranking indeed better rankingoriginally presented, i.e., DCG@10(x, y) > DCG@10(x, y). Figure 1 plotsCumulative Distribution functions (CDFs) DCG@10(x, y) DCG@10(x, y) threeexperimental conditions, well average conditions. CDFs shifted farright 0, showing preference feedback strategy highly accurateinformative. Focusing first average conditions, utility difference strictlypositive 60% queries, strictly negative 10%. imbalancesignificant (binomial sign test, p < 0.0001). Among remaining 30% casesDCG@10 difference zero, 88% due = (i.e. click top 1 click).Note learning algorithm easily detect cases may explicitly eliminatefeedback. Overall, shows implicit feedback indeed produce accuratepreferences.remains shown whether reliability feedback affectedquality current prediction, i.e., U (xt , yt ). user study, users actuallyreceived results retrieval quality degraded purpose. particular,one third subjects received Googles top 10 results reverse order (condition reversed) another third received rankings top two positions swapped (conditionswapped). Figure 1 shows, find users provide accurate preferences acrosssubstantial range retrieval quality. Intuitively, worse retrieval system may makeharder find good results, also makes easier baseline yt improve upon.intuition formally captured definition -informative feedback. optimal valuevs. trade-off, however, likely depend many application-specific factors,like user motivation, corpus properties, query difficulty. following, thereforepresent algorithms require knowledge , theoretical bounds holdvalue , experiments explore large range .7fiShivaswamy & JoachimsAlgorithm 1 Preference Perceptron.Initialize w1 0= 1Observe xtPresent yt argmaxyY wt> (xt , y)Obtain feedback ytUpdate: wt+1 wt + (xt , yt ) (xt , yt )end4. Preference Perceptron Coactive Learningsection, start presenting analyzing basic algorithm coactive learning model, call Preference Perceptron (Algorithm 1). PreferencePerceptron maintains weight vector wt initialized 0. time step t,algorithm observes context xt presents object maximizes wt> (xt , y).algorithm observes user feedback yt weight vector wt updateddirection (xt , yt ) (xt , yt ).Although update preference perceptron appears similar standard perceptron multi-class classification problems, key differences. First, standardperceptron algorithm requires true label feedback, whereas much weaker feedbacksuffices algorithm. Second, standard analysis perceptron boundsnumber mistakes made algorithm based margin radius examples.contrast, analysis bounds different regret captures graded notion utility.Further, standard perceptron mistake bound (Novikoff, 1962) contains R2 kwk2bound following Theorem contains Rkwk R defined (9).Theorem 1 average regret preference perceptron algorithm upper bounded,(0, 1] w follows:1 X2Rkw k.REGT+t=1(10)Proof First, consider kwT +1 k2 , have,wT>+1 wT +1 = wT> wT + 2wT> ((xT , yT ) (xT , yT ))+ ((xT , yT ) (xT , yT ))> ((xT , yT ) (xT , yT )wT> wT + 4R2 4R2 T.line one, simply used update rule algorithm 1. line two, usedfact wT> ((xT , yT ) (xT , yT )) 0 choice yT Algorithm 1k(x, y)k R. Further, update rule algorithm 1, have,wT>+1 w = wT> w + ((xT , yT ) (xT , yT ))> w=X(U (xt , yt ) U (xt , yt )) .t=18(11)fiCoactive Learninguse fact wT>+1 w kw kkwT +1 k (Cauchy-Schwarz inequality),impliesX(U (xt , yt ) U (xt , yt )) 2R kw k.t=1-informative modeling user feedback (6),X(U (xt , yt ) U (xt , yt ))t=1X2R kw k,t=1claimed result follows.first term regret bound denotes quality feedback terms violation-informative feedback. particular, user feedback strictly-informative, slack variables (10) vanish REGT = O(1/ ).trivial design algorithms (with even better regret) strict -informativeassumption cardinality context set X finite. One interesting aspectsbound (Theorem 1) subsequent results minimizeregret even context xt different every step. Thus, |X | could infiniteregret bound still holds.note bound Theorem 1 holds w (0, 1]. slacksbased corresponding w .Though user feedback modeled via -informative feedback, algorithmrequire knowledge ; plays role analysis.far, characterized user behavior terms deterministic feedback actions.However, bound expected regret suffices, weaker model Expected Informative Feedback Equation (7) applicable.Corollary 2 expected -informative feedback model, expected regret (overuser behavior distribution) preference perceptron algorithm upper boundedfollows:E[REGT ]1 X 2Rkw k.+t=1(12)corollary proved following argument Theorem 1, takingexpectations user feedback:E[wT>+1 wT +1 ] = E[wT> wT ] + E[2wT> ((xT , yT ) (xT , yT ))]+ ET [((xT , yT ) (xT , yT ))> ((xT , yT ) (xT , yT )]E[wT> wT ] + 4R2 .above, E denotes expectation user feedback yt given yt contextxt . follows E[wT>+1 wT +1 ] 4T R2 .9fiShivaswamy & JoachimsAlgorithm 2 Batch Preference Perceptron.Initialize w1 0l1s0= 1Observe xtPresent yt argmaxyY wl> (xt , y)Obtain feedback yt== + kPUpdate: wl+1 wl + tj=s (xj , yj ) (xj , yj )l l+1stendendApplying Jensens inequality concave function , get:q>E[wT w ] kw kE[kwT k] kw k E[wT> wT ].corollary follows definition expected -informative feedback.4.1 Lower Boundshow upper bound Theorem 1 cannot improved general respectscaling . following lemma, given Coactive Learning algorithm,construct sequence exampleswhere, even = 1 feedback, algorithm suffersaverage regret (1/ ).Lemma 3 coactive learning algorithmlinear utility, exist xt , objectsw REGT steps (1/ ).Proof Consider problem = {1, +1}, X = {x RT : kxk = 1}. Definejoint feature map (x, y) = yx. Consider contexts e1 , . . . , eT ejj th component equal one others equal zero. Let y1 , .. . yTT,sequence outputscontextse,...,e.Constructw=[y/11>y2 / , . . . , yT / ] , construction kw k = 1. Let user feedbacktth step yt . choices, user feedbackalways -informative = 11 PTsince yt = yt . Yet, regret algorithm t=1 (w> (et , yt ) w> (et , yt )) =( 1T ).4.2 Batch UpdatePreference Perceptron stated Algorithm 1 makes update every iteration.applications, due high volumes feedback, might possibleupdate frequently. scenarios, natural consider variant Algorithm 1makes update every k iterations; algorithm simply uses wt obtained10fiCoactive LearningAlgorithm 3 Generic Template Coactive Learning AlgorithmsInitialize w1= 1Observe xtPresent yt argmaxyY wt> (xt , y)Obtain feedback ytPerform update wt using gradient w> ((xt , yt )(xt , yt )) obtain wt+1 .endprevious update next update. type updates shown Algorithm 2 calledmini-batch updates used distributed online optimization (Dekel, GiladBachrach, Shamir, & Xiao, 2012). steps batch update algorithm shownAlgorithm 2. easy show following regret bound batch updates:Lemma 4 average regret batch preference perceptron algorithm upperbounded, (0, 1] w follows:1 X2Rkw k kREGT+.t=1lemma implies mini-batches slow learning factor equalbatch size, see Section 6.2.3 empirically convergence substantially faster.5. Deriving Algorithms Coactive LearningPreference Perceptron regret minimizes, defined Eqn. (4),one point design space different regret definitions learning algorithmscoactive learning. section, outline general strategy deriving coactivelearning algorithms existing algorithms online optimization. Furthermore,demonstrate general notions regret meaningful feasible coactivelearning, derive coactive learning algorithms general convex -strongly convexlosses.coactive learning algorithms derive section follow general templateoutlined Algorithm 3. initializing w1 , iteration context xt observedalgorithm presents yt maximizing current utility estimate represented wt .feedback yt observed, algorithm simply takes gradient w> ((xt , yt )(xt , yt )) uses update standard online convex optimization algorithmobtain wt+1 wt .case, upper bound regret proposed algorithm derivedusing following strategy. First, start notion regret suitedcoactive learning. upper bound regret first reducing formresults standard online convex opimization regret bound applied.gives regret bound original coactive algorithm turn. case, usetemplate algorithm derive specific algorithm. However, still provide self-containedproof (in appendix) clearly pointing used regret boundcorresponding online convex optimization algorithm.11fiShivaswamy & JoachimsAlgorithm 4 Exponentiated Preference PerceptronIntialize w1i N12S1T= 1Observe xtPresent yt argmaxyY wt> (xt , y)Obtain feedback ytwt+1wti exp((i (xt , yt ) (xt , yt )))/Zt , Zt weights addone.end5.1 Exponentiated Preference Perceptronillustrate generic strategy deriving coactive learning algorithms, first deriveexponentiated gradient algorithm coactive learning used alternativePreference Perceptron. exponentiated gradient algorithm inherits abilitylearn quickly sparse weight vectors.Unlike additive updates Preference Perceptron, exponentiated gradientalgorithm summarized Algorithm 4 performs multiplicative updates. exponentiatedalgorithm closely related exponentiated algorithms classification (Kivinen &Warmuth, 1997). start, initializes weights uniformly. subsequent updatestep rate associated it. rate depends upper bound ` normfeatures (i.e., k(, )k` S) time horizon . multiplicativeupdate, weights normalized sum one, steps algorithm repeat.Since updates multiplicative weights initially positive, wt guaranteedremain positive orthant algorithm. note Algoithm 4 assumedknow S. standard techniques (see Cesa-Biachi & Lugosi, 2006b)convert algorithm dependence , however, extensionsfocus paper.provide regret bound Algorithm 4. regret bounds Algorithm 1Algorithm 2 depended `2 norm features, bound exponentiatedalgorithm depends ` norm features.Theorem 5 w RN kw k`1 = 1, w 0, (expected) informative feedback average (expected) regret Exponentiated Preference Perceptron upper bounded as:1 X2 log(m)SREGT++ ,2t=1E[REGT ]1 X 2 log(m)S++ ,2t=1k(x, y)k` S.12fiCoactive LearningProof start regret coactive learning algorithm defined (4):REGT ==1X(U (xt , yt ) U (xt , yt ))t=1X11=(U (xt , yt ) U (xt , yt )) +t=1X1 Xt=1w> (xt , yt )t=1w> (xt , yt )1 X+(13)t=1equation, used definition -informative feedback definedEqn. (6). viewing Algorithm 4 exponentiated online gradient descent algorithm,easy derive following regret bound using techniques initially introduced KivinenWarmuth (1997),XX>(wt ((xt , yt ) (xt , yt )))(U (xt , yt ) U (xt , yt )) + 2 log(N )S +.2t=1t=1Since could find specific bound literature, self-contained proof providedAppendix A. proof, REGT first upper bounded terms differenceKL(w||wt+1 ) KL(w||wt ). telescoping argument used get result.Observing wt> ((xt , yt ) (xt , yt )) 0, get,Xt=1(U (xt , yt ) U (xt , yt )) 2 log(N )S +.2(14)Combining (13) (14), obtain average regret bound. proof expectedregret bound analogous Preference Perceptron.Like result Theorem 1, result (Theorem 5) also bounds regretterms noisein feedback (first term) additional terms converge zerorate O(1/ ). key difference Theorem 1 regret boundexponentiated algorithm scales logarithmically number features,`1 -norm w, advantageous optimal w sparse.5.2 Convex Preference PerceptronGeneralizing definition regret Eqn. (4), allow every time stept, (unknown) convex loss function ct : R R determines lossct (U (xt , yt ) U (xt , yt )) time based difference utility ytoptimal yt . functions ct assumed non-increasing. Non-increasing assumptionct based intuition loss higher U (xt , yt ) fartherU (xt , yt ). Further, sub-derivatives ct assumed bounded. Formally, c0t ()[G, 0] R c0t () denotes sub-derivative ct () .vector w determines utility yt context xt assumed closed13fiShivaswamy & JoachimsAlgorithm 5 Convex Preference Perceptron.Initialize w1 0= 1Set 1tObserve xtPresent yt argmaxyY wt> (xt , y)Obtain feedback ytUpdate: wt+1 wt + ((xt , yt ) (xt , yt ))Project: wt+1 arg minuB ku wt+1 k2endbounded convex set B whose diameter denoted |B|. case convex losses,consider following notion regret:1X1XCREGT :=ct (U (xt , yt ) U (xt , yt ))ct (0)t=1(15)t=1bound (16), ct (0) minimum possible convex loss since U (xt , yt ) U (xt , yt )never greater zero definition yt . Hence regret compares lossalgorithm best loss could achieved convex loss. Note that,case ct () = , definition regret reduces earlier definition regretlinear case (Eqn. (4)).Algorithm 5 minimizes average convex loss. two differencesalgorithm Algorithm 1. First, rate associated update timet. Second, every update, resulting vector wt+1 projected back set B.Algorithm 5 also closely related online convex optimization algorithm propsedZinkevich (2003). However, online convex optimization algorithm assumesgradient loss (ct ()) observed iteration. algorithm doesnt observegradient directly, observes improved object yt presenting objectyt .earlier regret bounds expressed terms slack variables . However,following section, bounds expressed terms clipped versionslack variables defined t+ := max(0, ).Theorem 6 Convex Preference Perceptron -informative feedback, nonincreasing convex losses ct () bounded sub-derivative, have, (0, 1]w B,2G X + G|B||B| 4R2+CREGT++.2t=1(16)Similarly, expected -informative feedback, have,2G X + G|B||B| 4R2+E[CREGT ]++.2t=114(17)fiCoactive Learningproof Theorem provided Appendix B. idea prooffirst divide time steps two types dependingnature feedback.PTallows us upper bound CREGT terms t=1 (wt w )> ((xt , yt ) (xt , yt )).term upper bounded following argument Zinkevich (2003) evenCoactive Learning framework.definition CREGT Eqn. (15), theorem upper boundsaverage convex loss via minimum achievable loss quality feedback. Likeprevious result (Theorem 1), strict-informative feedback, average loss approaches best achievable loss O(1/ ), albeit larger constant factors.case linear utility bounds Theorem 1 Theorem 5, sufficientaverage slack variables zero achieve zero regret. However,case convex losses, upper bound regret approaches zero averageclipped slack variables zero.5.3 Second-Order Preference Perceptronparticular class convex functions, turns give much strongerregret bounds general convex losses. improvement special class lossesparallels improvements online convex optimization general convex losses (Zinkevich,2003) -strongly convex losses (Hazan et al., 2007).Definition 7 convex function f : R -strongly convex points xD, following condition satisfied fixed > 0:f (x) f (y) + f (x)> (x y)||y x||2 ,2(18)f (x) denotes sub-derivative x.Algorithm 6 shows Second-order Preference Perceptron -strongly convex losses.Like previous algorithms, Second-order Preference Perceptron also maintainsweight vector wt , step presenting yt based context xt stillprevious algorithms. However, addition weight vector, also maintainsadditional matrix constructed outer product vector (xt , yt )(xt , yt ). update step projection steps involve shownAlgorithm 6. Algorithm 6 closely related online convex optimization algorithmproposed Hazan et al. (2007). However, pointed case Algorithm 5,algorithm observes user preference feedback step unlike online convexoptimization algorithms observe gradients. still possible prove regret bound-strongly convex case, following result.Theorem 8 second order preference learning algorithm, (expected) -stronglyconvex, non-increasing functions ct , bounded sub-derivatives, have,2X + 2 2G X + G|B|GN4RCREGT+++log+1 ,(19)2T 22Tt=1t=124RX +2 2G X + G|B|GNE[CREGT ]+++log+1 ,(20)2T 22Tt=1t=115fiShivaswamy & JoachimsAlgorithm 6 Second-order Preference Perceptron.Intialize w1 0A0/G.= 1Observe xtPresent yt argmaxyY wt> (xt , y)Obtain feedback ytAt1 + [(xt , yt ) (xt , yt )][(xt , yt ) (xt , yt )]>Update: wt+1 wt + A1[(xt , yt ) (xt , yt )]Project: wt+1 = arg minwB (wt+1 w)> (wt+1 w)endwhere, > 0 initialization parameter, shown Algorithm 6.prove Theorem Appendix C. Like proof Theorem 6, dividetime steps two types. Starting this, possible upper bound CREGTform resulting terms upper bounded using similar argumentsonline strongly convex optimization (Hazan et al., 2007).user feedback strictly -informative w B, first twoterms regret bound (19) result O( logT ) scaling . However,linear dependence dimensionality joint feature map regret boundSecond-order Preference Perceptron algorithm.Even though appears like need invert matrix Second-order Preference Perceptron, avoided since updates rank one.Woodbury matrix inversion lemma, have:> > 1A1= (At1 + [(xt , yt ) (xt , yt )][(xt , yt ) (xt , yt )] ) )= A1t1> 1A1t1 [(xt , yt ) (xt , yt )][(xt , yt ) (xt , yt )] At11/() + [(xt , yt ) (xt , yt )]> A1t1 [(xt , yt ) (xt , yt )].Thus, practice, Second-order Preference Perceptron updateBt iteration. Nevertheless, projection step obtain wt+1 involves solvingquadratically-constrained quadratic program B ball fixed radius, stilltakes O(N 3 ) time. Hence, Second-order Preference Perceptron computationallydemanding Convex Preference Perceptron. show experiments,Second-order Preference Perceptron might still quite useful low-noise data.6. Experimentsempirically evaluate Coactive Learning algorithms two real-world datasets.two datasets differ nature prediction feedback. first dataset,algorithms operate structured objects (rankings) whereas second dataset, atomicitems (movies) presented received feedback.16fiCoactive Learning6.1 Datasets User Feedback ModelsFirst, provide detailed description two datasets used experiments. Along this, provide details strategies used datasetgenerating user feedback.6.1.1 Structured Feedback: Web-Searchfirst dataset publicly available dataset Yahoo! (Chapelle & Chang, 2011)learning rank web-search. dataset consists query-url feature vectors (denotedxqi query q URL i), relevance rating riq ranges zero (irrelevant)four (perfectly relevant). pose ranking structured prediction problem, definedjoint feature map follows:w> (q, y) =5Xw> xqyi.log(i + 1)(21)i=1equation, denotes ranking yi index URLplaced position ranking. Thus, measure considers top five URLsquery q computes score based graded relevance. Note utilityfunction defined via feature-map analogous DCG@5 (see, Manning et al., 2008)replacing relevance label linear prediction based features.query qt time step t, Coactive Learning algorithms present ranking ytqmaximizes wt> (qt , y). Note merely amounts sorting documentsscores wt> xqi , done efficiently. utility regret Eqn. (4), basedPdefinition utility w> (q, y) given T1 Tt=1 w> ((qt , yqt ) (qt , yqt )). yqtdenotes optimal ranking respect w , consider best leastsquares fit relevance labels features using entire dataset. obtainyqt Eqn. 3, is, yqt = argmaxyY w> (qt , y). experiments, queryordering randomly permuted twenty times report average standard errorresults.used following two user models generating simulated user feedbackexperiments. first feedback model idealized version feedback whereas secondfeedback based directly relevance labels available dataset:Strict -informative feedback: model, user assumed providestrictly -informative feedback given value (i.e., slacks zero). Given predicted ranking yt , user would go list found five URLs that,placed top list, resulting yt satisfied strictly -informativefeedback condition w.r.t. optimal w . model assumes useraccess w hence idealized feedback.Noisy feedback depth k: feedback model, given ranking query,user would go list inspecting top k URLs (or URLs listshorter) specified k value. Five URLs highest relevance labels (riq )placed top five locations user feedback. Note produces noisyfeedback since linear model perfectly fit relevance labels dataset.17fiShivaswamy & Joachims6.1.2 Item Feedback: Movie Recommendationcontrast structured prediction problem previous dataset, consideredsecond dataset atomic predictions, namely movie recommendation. iteration,movie presented user, feedback consists single movie well.used MovieLens dataset grouplense.org consists million ratings3900 movies rated 6040 users. movie ratings range one five.randomly divided users two equally sized sets. first set used obtainfeature vector xj movie j using SVD embedding method collaborativefiltering (see Bell & Koren, 2007, Eqn. (15)). dimensionality feature vectorsregularization parameters chosen optimize cross-validation accuracyfirst dataset terms squared error. second set users, consideredproblem recommending movies based movie features xj . experiment setupsimulates task recommending movies new user based movie features oldusers.Txuser second set, found best least squares approximation wijusers utility functions available ratings. enabled us impute utilityvalues movies explicitlyrated user. Furthermore, allowed usP> (x x ), average differencemeasure regret user T1 Tt=1 wiutility recommended movie xt best available movie xt . denotebest available movie time xt obtained Eqn. 3. experiment,user gave particular movie feedback, recommended moviefeedback movie removed set candidates subsequent recommendations.experiments report (average) regret values averaged 3020 userstest set.simulate user behavior, considered following two feedback modelsdataset:Strict -informative feedback: previous dataset, model, userassumed provide strictly -informative feedback given value (i.e., slackszero). Given predicted movie yt , user assumed watch moviealready highest rating remaining corpus movies. not, userpicks another movie corpus lowest utility still satisfies strict informative assumption. model assumes user access w ,hence idealized feedback.Noisy feedback: feedback model, given movie y, user assumedaccess either actual rating movies (when available) assumedround imputed rating nearest legal rating value. used two sub-strategiesuser provides feedback. better feedback, user providessmallest rating (actual rating rounded rating) strictly betterrating y. best feedback, user provideshighest rating (actual rating rounded rating) remaining corpus. couldmultiple movies satisfying criteria, ties broken uniformlyrandom among movies. Note feedback model results noisy feedbackdue rounding movie ratings discrete values.18fiCoactive Learning6.2 Preference Perceptronfirst set experiments, analyze empirical performance scaling behaviorbasic Preference Perceptron Algorithm variants.6.2.1 Strong Versus Weak Feedbackgoal first experiment explore regret algorithm changed feedback quality. get feedback different quality levels , used strict -informativefeedback various values.1.86= 0.1= 0.5= 1.01.6= 0.1= 0.5= 1.05avg. util regretavg. dcg regret1.41.210.84320.60.410.20 0101102310100 010410121010310Figure 2: Regret based strict -informative feedback various values websearch (left) movie recommendation (right).Figure 2 shows results experiment three different values. Overall, regrettypically substantially reduced tens hundreds iterations. expected,regret = 1.0 lower compared regret lower values. Note, however,difference two curves much smaller factor ten. Also notedifferences less prominent case web-search. strictly-informative feedback also strictly -informative feedback . So,user feedback model, could providing much stronger feedback requiredparticular value. expected theoretical bounds, since user feedbackbased linear model noise, utility regret approaches zero cases. Noteshow standard error plots, giving indication statistical significance.left plots Figure 2, standard errors high lower iterations become loweriterations. plots rest paper, error bars smallmay difficult visually identify.rest paper, strict -informative feedback, consider = 0.5unless explicitly mention otherwise.6.2.2 Noisy Feedbackprevious experiment, user feedback based actual utility values computedoptimal w . next study regret changes noisy feedback user behavior19fiShivaswamy & Joachimsfollow linear utility model. web-search dataset, use noisy feedbackdepths 10 25, movie dataset use noisy feedbackbetter best variant it.1.66depth=10depth=251.4betterbest5avg. util regretavg. util regret1.210.80.64320.410.20 0101102310100 010410121010310Figure 3: Regret based noisy feedback web-search (left) movie recommendation(right).results experiment shown Figure 3. first observation makecase web-search, regret values converge zero. Similarly,case movie recommendation regret values higher previousexperiment. results line theory shows regret convergingaverage slack variables user provide strict informative feedback. Interestingly, case web-search average regret slightly higheruser goes greater depth providing feedback. due fact relevancelabels dataset noisy user maximizes (noisy) utility larger setURLs, selection (true) utility maximizers becomes less reliable, degradesuser feedback quality.rest paper, web-search consider noisy feedback depth=10.case movie recommendation, consider better version noisy feedbackunless explicitly mention otherwise.6.2.3 Batch Updatessection, consider Batch Preference Perceptronalgorithm (Algorithm 2).regret bound Section 4.2 scales factor k strict -informative feedback,update made every k iterations algorithm. verify whetherempirical performance scales suggested bound. web-search movies,considered strict -informative feedback noisy feedback. typesfeedback, use Batch Perceptron Algorithm various values k reportresulting average regret.results experiments shown Figure 4 Figure 5. expected,value k becomes smaller, regret converges faster. However, observe20fiCoactive Learning1.66k=1k = 10k=20k=501.4k=1k=10k=20k=505avg. util regretavg. util regret1.210.80.64320.410.20 0101102310100 010410121010310Figure 4: Regret versus time based batch updates strict -informative feedbackweb-search (left) movie recommendation (right).1.61.41.21430.820.610.4 010110231010k=1k=10k=20k=505avg. util regretavg. util regret6k=1k = 10k=20k=500 010410121010310Figure 5: Regret versus time based batch updates noisy feedback web-search(left) movie recommendation (right).empirical scaling k substantially better k factor suggested Lemma 4.results show feasibility using Coactive Learning algorithms systemsmight impractical update every iteration.6.2.4 Expected User Feedbackuser feedback deterministic experiments far. sub-section, consider probabilistic feedback study behavior Preference Perceptron algorithm.Recall provided upper bound expected regret expected user feedbackCorollary 2.provide -informative feedback expectation, consider following strategy.Given object yt context xt , user would first generate deterministic feedback yt21fiShivaswamy & Joachimsfollowing strict -informative feedback model ( = 0.5 web-search = 1.0movie recommendation).5 addition, consider five randomly generated objectsfeedback. put uniform probability mass randomly generated objectsremaining mass deterministic feedback user feedback still-informative = 0.5 expectation.6Expct. feedbackDet. feedback1.61.4Expct. FeedbackDet. Feedback5avg. util regretavg. util regret1.210.80.64320.410.20 0101102310100 010410121010310Figure 6: Expected feedback versus deterministic feedback web-search (left) movierecommendation (right).results experiment shown Figure 6. reference, also plotregret curve deterministic -informative feedback = 0.5. seenmuch difference deterministic expected feedback higher numbersiterations. also seen regret converges zero even -informativefeedback expectation suggested Corollary 2.6.2.5 Comparison Ranking SVMcompare algorithms several baselines, starting conventionalRanking SVM (Joachims, 2002) repeatedly trained. iteration, previousqtSVM model used present ranking user (ysvm). user returns rankingqt(ysvm ) based strict -informative feedback one experiment based noisyqtqtfeedback other. pairs examples (qt , ysvm) (qt , ysvm) used trainingpairs ranking SVM. Note training ranking SVM iteration wouldprohibitive expensive, since involves solving quadratic program cross-validatingregularization parameter C. Thus, retrained SVM whenever 10% examplesadded training set. first training first iterationone pair examples (starting random yq1 ), C value fixed 10050 pairs examples, reliable cross-validation became possible.50 pairs training set, C value obtained via five-fold cross5. Note that, case web-search, user model provide strictly -informative larger0.5.22fiCoactive Learningvalidation. C value determined, SVM trained trainingexamples available time. SVM model used present rankingsnext retraining.1.66SVMPref. Perceptron1.4SVMPref. Perceptron5avg. util regretavg. util regret1.210.80.64320.410.20 0101102310100 010410121010310Figure 7: Preference Perceptron versus Ranking SVM strict -informative feedback web-search (left) movie recommendation (right).6SVMPref. Perceptron1.451.24avg. util regretavg. util regret1.6130.820.610.4 0101102310100 010410SVMPref. Perceptron121010310Figure 8: Preference Perceptron versus Ranking SVM noisy feedback web-search(left) movie recommendation (right).results experiment shown Figure 7 Figure 8. casestrict -informative feedback, Preference Perceptron performed much betterSVM movie recommendation, comparably web search. casenoisy feedback, Preference Perceptron performs significantly better SVMrange datasets. took around 20 minutes runPreference Perceptron experiment, took 20 hours run SVM experiment23fiShivaswamy & Joachimsweb-dataset permutation dataset. Similary, movie recommendationtask took around 125 seconds run preference perceptron user tookaround 260 seconds run SVM user. results show preferenceperceptron perform par better SVMs tasks fractioncomputational cost.6.2.6 Comparison Dueling Banditsecond baseline, compare Preference Perceptron algorithm duelingbandit approach Yue Joachims (2009). step, dueling bandit algorithmmakes comparison vector w perturbed version w1 (in randomdirection u w1 = w + u). results produced two weight vectorsassessed user techniques interleaving (Radlinski, Kurup, & Joachims,2008), providing preference w w1 . preference feedback determinesupdate dueling bandits algorithm makes w. w preferred, retainednext round. w1 preferred, small step length taken directionperturbation u.1.8Dueling BanditPref. Perceptron1.61.61.41.41.21.2avg. util regretavg. util regret1.810.810.80.60.60.40.40.20.20 0101102310100 010410Dueling BanditPref. Perceptron110231010410Figure 9: Preference Perceptron versus Dueling Bandit web-search. left plot basedstrict -informative feedback, right plot shows noisy feedback.first experiment web-search, step, first obtained two ranked listsbased w w1 . features used obtain ranked lists identicalused Preference Perceptron. two rankings interleaved. interleavedranking presented user. first experiment, user provided strict informative feedback interleaved ranking. second experiment, userprovided noisy feedback. Depending feedback, inferred two rankings preferred using Team-Game method proposed Radlinski et al. (2008).w preferred tie, step taken. w1 preferred,step length taken direction u. regret dueling bandit algorithmmeasured considering utility interleaved ranking. Unlike PreferencePerceptron algorithm, dueling bandit algorithm two parameters ( ) need24fiCoactive Learningtuned. considered 25 values parameters (5x5 grid) simply chosebest parameter values dueling bandits algorithm hindsight.results experiment shown Figure 9. Despite advantage settingparameters best possible values, seen dueling bandit algorithm performssignificantly worse compared preference perceptron algorithm orders magnitude.example, performance dueling bandit around 28,000 iterations matchedpreference perceptron less 100 iterations types feedback.surprising, since dueling bandit algorithm basically relies random vectorsdetermine direction step needs taken. Coactive Learning model,user feedback provides (better random) direction guide algorithm.6Dueling BanditPref. Perceptron5544avg. util regretavg. util regret63322110 0101210100 010310Dueling BanditPref. Perceptron121010310Figure 10: Preference Perceptron versus Dueling Bandit movie recommendation.left plot based utility values whereas right plot shows resultsrounded values.Similarly, also conducted comparison dueling bandit algorithmmovie recommendation dataset. However, unlike web-search experiment, duelingbandit model somewhat unnatural dataset experimental setup, since interleaving two rankings natural whereas interleaving two items not. therefore considerdifferent setup. Two movies obtained based w w1 dueling banditalgorithm. User feedback merely indicate two movies higherrating. noisy case, user feedback based actual rating rounded rating. noise-free case, user feedback based utility values. either case,utility dueling bandit considered average utility two movies selectedcomparison.performance dueling bandit algorithm experiment shown Figure 10. Preference Perceptron algorithm, regret curves strict -informativefeedback ( = 0.5) better noisy feedback also shows reference.seen dueling bandit algorithm performs substantially worse comparedPreference Perceptron algorithm.25fiShivaswamy & Joachims6.3 Exponentiated versus Additive Updatesexperiment, compare exponentiated algorithm (Algorithm 4) additivePreference Perceptron algorithm. exponentiated algorithm, componentsmust non-negative.6 obtained non-negative follows:[we ]i=min(0, [w ]i )1 m,max(0, [w ]im ) + 1 2m.(22)equation, [we ]i denotes ith component . Moreover, also modifiedjoint feature map exponentiated algorithm follows:e[ (x, y)]i =+[(x, y)]i1im[(x, y)]im + 1 2m(23)modifications, non-negative components moreover, easy verify > e (x, y) = w> (x, y). makes regretexponentiated algorithm directly comparable regret additive algorithm.exponentiated algorithm fixed rate parameter inversely dependstime horizon . large, small. situation, consider updateAlgorithm 4:wt+1wti exp((i (xt , yt ) (xt , yt )))/Zt .Since, small, approximate exponential term equationfirst order approximation:exp((i (xt , yt ) (xt , yt ))) 1 + (i (xt , yt ) (xt , yt )).Thus exponentiated updates resemble updates additive algorithmnormalization factor. Despite normalization factor, empirically observed behavior two algorithms nearly identical (though exact). thus empiricallyevaluated exponentiated algorithm variable rate parameter = 2S1t time t.Note empirical result without formal theoretical guarantees variablerate.Results experiment shown Figure 11 Figure 12 strict -informativefeedback noisy feedback respectively. seen exponentiated algorithm tends performs slightly better additive algorithm small numberiterations. time horizon becomes large, two algorithms seem comparableperformance cases.6.4 Minimizing Convex Lossessection, empirically evaluate Convex Preference Perceptron (Algorithm 5)Second-Order Preference Perceptron (Algorithm 6).6. put superscript e distinguish joint feature map w used experimentsexponentiated algorithm.26fiCoactive Learning1.66ExponentiatedPref. Perceptron1.4ExponentiatedPref. Perceptron5avg. util regretavg. util regret1.210.80.64320.410.20 0101102310100 010410121010310Figure 11: Exponentiated versus Additive strict -informative feedback websearch (left) movie recommendation (right).1.66ExponentiatedPref. Perceptron1.4ExponentiatedPref. Perceptron5avg. util regretavg. util regret1.210.80.64320.410.20 0101102310100 010410121010310Figure 12: Exponentiated versus Additive noisy feedback web-search (left)movie recommendation (right).6.4.1 Convex Perceptron Versus Second-Order Algorithmregret bounds Section 5 show one get lower regret -strongly convexfunctions using second-order algorithm, first-order Convex Perceptron appliesgeneral convex functions. section, evaluate relative performancefirst-order second-order algorithms empirically. purpose, consideredquadratic loss c() = ( )2 largest utility value possible (x, y)w convex ball radius kw k. verified loss function -stronglyconvex. B set 100 algorithms datasets.27fiShivaswamy & JoachimsSecond OrderConvex Perceptron0.055000.044000.033000.022000.011000 0101210Second OrderConvex Perceptron600Util regretQuad regret0.06310100 010410121031010410Figure 13: Cumulative regret convex perceptron second order convex perceptron web-search.0.03250Second OrderConvex Perceptron2000.02Util regretQuad. regret0.025Second OrderConvex Perceptron0.0151501000.01500.0050 0101210100 010310121010310Figure 14: Cumulative regret convex perceptron second order convex perceptron movie recommendation.first set experiments, considered strict -informative feedback. ransecond-order algorithm well Convex Preference Perceptron algorithm 5.value second order perceptron simply set one. recorded REGTCREGT values methods. Note REGT corresponds utilityregret defined 4.Results experiment shown Figure 13 Figure 14. demonstratequalitative difference two algorithms, plot cumulative regret (i.e.REGT CREGT ) figures. cumulative regret second-orderalgorithm linear log-scale. shows convergence regret indeed28fiCoactive Learninglogarithmic, compared much slower convergence Convex Preference Perceptron.Interestingly, even cumulative regret based raw utility values empirically showssimilar behavior. purely empirical result, since theoretically, O(log(T )/T ) averageregret holds strongly convex losses linear loss strongly convex.010weak@5000strong@5000weak@15000strong@15000weak@25000strong@250001Util. regretQuad regret104weak@5000strong@5000weak@15000strong@15000weak@25000strong@2500010310210310264102100101021010 610410421001010210410Figure 15: Sensitivity second order preference perceptron algorithm parametervalue .1.210weak@5000strong@5000weak@15000strong@15000weak@25000strong@25000Quad. regret1.410102.410Util. regret1.310weak@5000strong@5000weak@15000strong@15000weak@25000strong@250002.51.5102.3101.6102.2101.7102.141020101021041010410201010210410Figure 16: Sensitivity second order preference perceptron algorithm parametervalue movie recommendation.previous experiment, fixed value second-order algorithm one.study sensitivity second-order algorithm value parameter.Figures 15 16 show regret values given number iterations sweptrange values. dotted lines show performance Convex PreferencePerceptron comparison. case web-search, wide range parameter29fiShivaswamy & Joachimsvalues performance algorithm good. parameter takes extremevalue either side, performance algorithm deteriorates. range suitablevalues much broader web-search dataset movie recommendation.interesting note algorithms performed empirically best = 1 amongvalues tried.0.1214000Second OrderConvex Perceptron120000.1Second OrderConvex PerceptronUtil regretQuad regret100000.080.060.04600040000.020 010800020001210310100 010410121031010410Figure 17: Strong convex versus weak convex noisy feedback web-seach.1400Second OrderConvex Perceptron0.1412000.1210000.1Util regretQuad. regret0.160.08Second OrderConvex Perceptron8006000.064000.042000.020 0101210100 010310121010310Figure 18: Strong convex versus weak convex noisy feedback movie recommendation.also tested convex algorithms noisy feedback. regret bounds contain slack terms right hand side. Thus, user feedback -informative, regret bounds second-order algorithm first-order algorithmdominated slack variables. empirical performance two algorithms noisy feedback shown Figures 17 18. case web-search,results second-order algorithm first-order algorithm nearly identi30fiCoactive Learningcal. However, case movie recommendation, still advantagesecond-order algorithm.summary, second-order algorithm performs substantially superior no-noisecircumstances. presence noise feedback, two algorithms showdrastically different behaviors.7. Conclusionsproposed Coactive Learning new model online learning preferencesespecially suited implicit user feedback. Unlike supervised learning approaches,Coactive Learning algorithms require optimal labels, merely (noisy) feedbackimproves prediction. model, cardinal utilities observed,sits experts bandits settings, argue Coactive Learningapplicable wide range systems aim optimize based observableuser actions.provide several algorithms provably optimize regret Coactive Learningframework, empirically validate effectiveness proposed frameworkweb-search ranking movie recommendation datasets simulations noisynoise-free feedback. recurring theme paper wide variety conventionalonline learning algorithms converted Coactive Learning algorithms, despitedifferences learning model itself, nature feedback notion regret.conjecture many online learning algorithms could similarly convertedpractically useful Coactive Learning algorithms.Coactive Learning model, algorithms proposed, ability use weakfeedback observable user behavior offer wide range opportunities new learningapproaches application problems ranging natural language processing information retrieval robotics. also several opportunities developingalgorithms Coactive Learning model. example, algorithm convex lossminimization assume gradient convex losses bounded. However,practical situations, convex loss minimized known apriori.interesting research direction study whether algorithms utilizegradient loss perform better either theoretically empirically. Another questionwhether better algorithms exist special cases linear utility model. lowerbound based argument dimensionally joint feature maps growgiven horizon . dimensionality joint feature map fixed,interesting research question is: algorithms better regret proposedalgorithms?Acknowledgmentswork funded part NSF awards IIS-0905467, IIS-1247637, IIS-1142251.work done Pannaga Shivaswamy postdoctoral associate CornellUniversity. thank Peter Frazier, Bobby Kleinberg, Karthik Raman, Tobias Schnabel31fiShivaswamy & JoachimsYisong Yue helpful discussions. also thank anonymous reviewers thoughtfulcomments earlier version paper.Appendix A. Proof Theorem 5Proof look KL divergence w wt evolves,KL(w||wt ) KL(w||wt+1 ) ==NXi=1NXwi log(wt+1/wti )wi ((i (xt , yt ) (xt , yt ))) log(Zt )i=1= w> ((xt , yt ) (xt , yt )) log(Zt ).(24)Psecond line, pulled log(Zt ) sum since Ni=1 w = 1. Now, considerlast term equation. Denoting (xt , yt ) (xt , yt ) brevity,have, definition,!NXlog(Zt ) = logwti exp(i )logi=1NXwti (122!+ + )i=1log 1 + wt> + 2 2wt> + 2 2 .(25)second line used fact exp(x) 1 + x + x2 x 1. rate ensures(i ) 1. last line, used fact log(1 + x) x. Combing (24)(25), get,(w wt )>KL(w||wt ) KL(w||wt+1 )+ 2 .Adding inequalities, get:1XXKL(w||wt ) KL(w||wt+1 ) X 2(w wt )> ((xt , yt ) (xt , yt ))+.t=1t=1t=1KL(w||w0 )+ 2 T.Rearranging inequality, substituting value Algorithm 4,get:XX>(U (xt , yt ) U (xt , yt ))wt ((xt , yt ) (xt , yt )) + 2 log(N )S +2t=1t=12 log(N )S +.232fiCoactive Learningabove, also used fact KL(w||w1 ) log(N ) since w1 initialized uniformly. Moreover, Holders inequality, obtainedwt> (xt , yt ) kwt k`1 k(xt , yt )k` S.inequality along -informative feedback gives claimed result.Appendix B. Proof Theorem 6Proof First, divide set time steps two different sets based naturefeedback::= {t : U (xt , yt ) U (xt , yt )) 0; 1 },J := {t : U (xt , yt ) U (xt , yt )) < 0; 1 }.brevity denote (xt , a) (xt , b) by7 (a, b) rest proof. startconsidering following term single time step t:ct (U (xt , yt ) U (xt , yt )) ct (0)>wt (yt , yt )ct (U (xt , yt ) U (xt , yt )) ct>>wt (yt , yt )w (yt , yt )ct=ct>>(w wt ) (yt , yt ) 0 w (yt , yt )ct+>>(wt (yt , yt ) + w (yt , yt ))G/(wt> (yt , yt ) + t+ )G/J.w> (y ,y )inequalities, second line follows fact 0 ct ()non-increasing. third line follows -informative feedback (Eqn. (6)). fourthline follows since function ct convex.8 obtain first term next inequality(in either case) since c0t () [G, 0] wt> (yt , yt ) 0 choice ytalgorithm. second terms (in either case) obtained fact c0t (w> (yt , yt ))upper bounded t+ G. step clipped version slack variablesneeded proof. Finally, w> (yt , yt ) either positive negative dependingfeedback leads two different cases depending whether J.7. Since context xt always clear, suppress notation brevity.8. convex function f , f (y) f (x) (y x)f 0 (y) f 0 (y) denotes sub-derivative f y.33fiShivaswamy & JoachimsSumming inequalities 1 , get:Xct (w> (yt , yt ))t=1GXGwt> (yt , yt ) +t=1XXct (0)t=1XGt+t=1tI(wt w )> (yt , yt ) +t=1GX >w (yt , yt )GXt=1t+ +GX >w (yt , yt ).(26)tJPobtained last line simply adding subtracting G tJ w> (yt , yt )/right side previous inequality. point, mostly follow prooftechniques online convex optimization (Zinkevich, 2003).bound first term right hand side (26). purpose, considerfollowing:kwt+1 w k2 = kwt + (yt , yt ) w k2= kwt w k2 + t2 k(yt , yt )k2 + 2t (wt w )> (yt , yt ).(27)Rearranging terms equation, get:1kwt w k22t1kwt w k22t(wt w )> (yt , yt ) =1kwt+1 w k2 + k(yt , yt )k22t21kwt+1 w k2 + 2t R22twhere, last line, used fact kwt+1 w k2 kwt+1 w k2 since wt+1projection wt+1 convex set B (which contains vector w ).bound first term (26) using following telescoping argument.X11222kwt w kkwt+1 w k + 2t R2t2tt=1XX1112kw1 w k +kwt w k2 + 2R2212t 2t1t=2t=1X111|B| +|B| + 2R2 (2 1)212t 2t1t=2+1|B| + 4R2 .2above, obtained second line simply rearranging terms expressionabove.line, used boundedness property set B, wellPTOn thirdfact t=12 1. final line follows cancelling terms fact= 1/ .34fiCoactive LearningNow, consider third term right hand side (26):w> (yt , yt )++w> (yt , yt ) + .first inequality follows -informative feedback. Whereas second inequality follows fact w> (yt , yP) 0 definition yt . Finally, bound (16)+Gfollows trivial fact 0 tI .obtain bound expected regret, consider convex loss step conditioned user behavior far:wt> (yt , yt )Et ct>>Et [w (yt , yt ) ]wt (yt , yt )ctEt ct>>w (yt , yt )wt (yt , yt )Et ctEt ct+>>GEt [wt (yt , yt ) + w (yt , yt )]/GEt [wt> (yt , yt ) + t+ ]/tJct (w> (yt , yt ))second line follows definition expected -informative feedbackthird line follows Jensens inequality. obtain last line following argumentsimilar proof Theorem 6. bound follows expected version(27).Appendix C. Proof Theorem 8Proof First, divide time steps two different sets based nature feedback::= {t : U (xt , yt ) U (xt , yt )) 0; 1 },J := {t : U (xt , yt ) U (xt , yt )) < 0; 1 }.35fiShivaswamy & Joachimsstart considering single time step t, have:ct (w> (yt , yt )) ct (0)>wt (yt , yt )>ct (w (yt , yt )) ct>>+w (yt , yt )wt (yt , yt )ctct2+ >>w (yt , yt ) t+(w wt )> (yt , yt ) t+(w wt ) (yt , yt )0ct22++>>wt> (yt ,yt ),yt )tI+ w (y2 (w wt ) (yt ,yt )G(28)++ 2> (y ,y )> (y ,y )w(ww)+ 2J.Gw> (y ,y )inequalities, second line follows fact 0 ct ()non-increasing. third line follows fact function ct () non-increasingfollowing inequality follows definition t+ :U (xt , yt ) U (xt , yt ) + (U (xt , yt ) U (xt , yt )) t+ .fourth line follows strong convexity. last line follows linereasoning proof Theorem 6.consider last term cases:2=2=2222(w wt )> (yt , yt ) t+22(w wt )> (yt , yt )t+t+ (w wt )> (yt , yt )+22222(w wt )> (yt , yt )+ w> (yt , yt ) t+ wt> (yt , yt ) t++ 222222(w wt )> (yt , yt )t+t+t+>+w (yt , yt ) +2222(w wt )> (yt , yt )++ 2.(29)2equations, second third lines follow simple algebraic expansionexpression first line. fourth line follows definition -informativefeedback fact wt> (yt , yt ) 0. last line follows factw> (yt , yt ) 0 definition yt .36fiCoactive LearningNow, summing terms (28) substituting bound, get,Xct (w> (yt , yt ))t=1Xct (0)t=12 !X w> (yt , yt ) PT + 2(w wt )> (yt , yt )t=1G+G22t=1tI!2>>X (wt w ) (yt , yt ) (w wt ) (yt , yt )G2t=1PP2Tt=1 t+G Tt=1 t+GX >+w (yt , yt ) ++22tJ2 PT + 2 2G PT +GX>>t=1t=1(wt w ) (yt , yt )(wt w ) (yt , yt )+.+222Xwt> (yt , yt ) t++2t=1>P,yt )above, obtained third inequality adding subtracting G tJ w (y.2obtain last line, used fact 1/ 1/ since (0,P 1]). Finally,> (y , )used argument similar proof theorem 6 bound GwtJobtained factor two sum slacks term. point, use argumentssimilar online convex optimization strongly convex losses (Hazan et al.,2007).Next, consider (wt+1 w )> (wt+1 w ) express interms wt At1 :(wt+1 w )> (wt+1 w )1>=(wt A1(yt , yt ) w ) (wt (yt , yt ) w )>=(wt w )> (wt w ) + (yt , yt )> A1(yt , yt ) 2(wt w ) (yt , yt )=(wt w )> (yt , yt )(yt , yt )> (wt w ) + (wt w )> At1 (wt w )>+ (yt , yt )> A1(yt , yt ) + 2(w wt ) (yt , yt )Rearranging terms equation, get:(wt w )> (yt , yt )(yt , yt )> (wt w )2(wt w )> At1 (wt w ) (wt+1 w )> (wt+1 w ) + (yt , yt )> A1(yt , yt ).2(wt w )> (yt , yt )37fiShivaswamy & Joachimsidentify term left hand side inequality occursexpression would like bound (29). therefore have,2Xt=1X(wt w )> (yt , yt ) ((wt w )> (yt , yt ))2(wt w )> At1 (wt w ) (wt+1 w )> (wt+1 w ) + (yt , yt )> A1( byt , yt )t=1(w1 w )> A0 (w1 w ) +X(yt , yt )> A1(yt , yt )t=1|B| +Nlog4R2+1 .P2above, used fact Tt=1 (yt , yt )> A1(yt , yt ) N log(4R /+1),N dimens ionality (x, y) R upper bound norm jointfeature maps (i.e. k(x, y)k`2 R. proof fact found Hazan et al. (2007).ReferencesAuer, P., Cesa-Bianchi, N., & Fischer, P. (2002a). Finite-time analysis multiarmedbandit problem. Machine Learning, 47 (2-3), 235256.Auer, P., Cesa-Bianchi, N., Freund, Y., & Schapire, R. (2002b). non-stochastic multiarmed bandit problem. SIAM Journal Computing, 32 (1), 4877.Bakir, G. H., Hofmann, T., Scholkopf, B., Smola, A., Taskar, B., & Vishwanathan, S. (Eds.).(2007). Predicting Structured Data. MIT Press.Bell, R. M., & Koren, Y. (2007). Scalable collaborative filtering jointly derived neighborhood interpolation weights. ICDM.Boley, M., Mampaey, M., Kang, B., Tokmakov, P., & Wrobel, S. (2013). One click mining:Interactive local pattern discovery implicit preference performance learning. Proceedings ACM SIGKDD Workshop Interactive Data ExplorationAnalytics, pp. 2735.Cesa-Bianchi, N., & Lugosi, G. (2006a). Prediction, learning, games. Cambridge University Press.Cesa-Bianchi, N., & Lugosi, G. (2006b). Prediction, Learning, Games. CambridgeUniversity Press, Cambridge, UK.Chapelle, O., & Chang, Y. (2011). Yahoo! learning rank challenge overview. JMLR Proceedings Track, 14, 124.Chu, W., & Ghahramani, Z. (2005). Preference learning gaussian processes. ICML.Crammer, K., & Singer, Y. (2001). Pranking ranking. NIPS.38fiCoactive LearningCrammer, K., & Gentile, C. (2011). Multiclass classification bandit feedback usingadaptive regularization. Proceedings 28th International Conference Machine Learning (ICML).Dekel, O., Gilad-Bachrach, R., Shamir, O., & Xiao, L. (2012). Optimal distributed onlineprediction using mini-batches. JMLR, 13, 165202.Flaxman, A., Kalai, A. T., & McMahan, H. B. (2005). Online convex optimizationbandit setting: gradient descent without gradient. SODA.Freund, Y., Iyer, R. D., Schapire, R. E., & Singer, Y. (2003). efficient boosting algorithmcombining preferences. Journal Machine Learning Research, 4, 933969.Goetschalckx, R., Fern, A., & Tadepalli, P. (2014). Coactive learning locally optimalproblem solving.. Conference American Association Artificial Intelligence(AAAI), pp. 18241830.Haddow, B., Arun, A., & Koehn, P. (2011). Samplerank training phrase-based machinetranslation. Proceedings Sixth Workshop Statistical Machine Translation,pp. 261271, Edinburgh, Scotland. Association Computational Linguistics.Hazan, E., Agarwal, A., & Kale, S. (2007). Logarithmic regret algorithms online convexoptimization. Machine Learning, 69 (2-3), 169192.Herbrich, R., Graepel, T., & Obermayer, K. (2000). Large margin rank boundariesordinal regression. Advances Large Margin Classifiers. MIT Press.Jain, A., Wojcik, B., Joachims, T., & Saxena, A. (2013). Learning trajectory preferencesmanipulators via iterative improvement. Neural Information Processing Systems(NIPS), pp. 575583.Joachims, T. (2002). Optimizing search engines using clickthrough data. ACM SIGKDDConference Knowledge Discovery Data Mining (KDD), pp. 133142.Joachims, T., Granka, L., Pan, B., Hembrooke, H., Radlinski, F., & Gay, G. (2007). Evaluating accuracy implicit feedback clicks query reformulations websearch. ACM Transactions Information Systems (TOIS), 25 (2).Jones, R., & Klinkner, K. (2008). Beyond session timeout: automatic hierarchicalsegmentation search topics query logs. CIKM.Kakade, S. M., Shalev-Shwartz, S., & Tewari, A. (2008). Efficient bandit algorithmsonline multiclass prediction. Proceedings 25th International ConferenceMachine Learning (ICML).Kivinen, J., & Warmuth, M. (1997). Exponentiated gradient versus gradient gradient descent linear predictors. Journal Information Computation, 132 (1), 164.Langford, J., & Zhang, T. (2007). epoch-greedy algorithm multi-armed banditsside information. NIPS.Liu, T.-Y. (2009). Learning rank information retrieval. Foundations TrendsInformation Retrieval, 3.Manning, C., Raghavan, P., & Schutze, H. (2008). Introduction Information Retrieval.Cambridge University Press.39fiShivaswamy & JoachimsNovikoff, A. (1962). convergence proofs perceptrons. Proceedings SymposiumMathematical Theory Automata, Vol. XII, pp. 615622.Polyak, B., & Tsypkin, Y. (1973). Pseudogradient adaptation training algorithms.Automatic Remote Control, 12, 8394.Radlinski, F., Kurup, M., & Joachims, T. (2008). clickthrough data reflect retrieval quality?. Conference Information Knowledge Management (CIKM).Raman, K., & Joachims, T. (2013). Learning socially optimal information systemsegoistic users. European Conference Machine Learning (ECML), pp. 128144.Raman, K., Joachims, T., Shivaswamy, P., & Schnabel, T. (2013). Stable coactive learningvia perturbation. International Conference Machine Learning (ICML), pp.837845.Raman, K., Shivaswamy, P., & Joachims, T. (2012). Online learning diversifyimplicit feedback. KDD.Shivaswamy, P., & Joachims, T. (2012). Online structured prediction via coactive learning.ICML.Somers, T., & Hollinger, G. (2014). Coactive learning human expert roboticmonitoring. RSS Workshop Robotic Monitoring.Weston, J., Bengio, S., & Usunier, N. (2011). Wsabie: Scaling large vocabularyimage annotation. Proceedings International Joint Conference ArtificialIntelligence (IJCAI).Yue, Y., Broder, J., Kleinberg, R., & Joachims, T. (2009). k-armed dueling banditsproblem. COLT.Yue, Y., & Joachims, T. (2009). Interactively optimizing information retrieval systemsdueling bandits problem. ICML.Zhang, Y., Lei, T., Barzilay, R., Jaakkola, T., & Globerson, A. (2014). Steps excellence: Simple inference refined scoring dependency trees. Proceedings52nd Annual Meeting Association Computational Linguistics (Volume1: Long Papers), pp. 197207, Baltimore, Maryland. Association ComputationalLinguistics.Zinkevich, M. (2003). Online convex programming generalized infinitesimal gradientascent. ICML.40fiJournal Artificial Intelligence Research 53 (2015) 721-744Submitted 9/14; published 8/15Mechanisms Multi-unit CombinatorialAuctions Distinct GoodsPiotr Krystap.krysta@liverpool.ac.ukDeparment Computer ScienceUniversity Liverpool, United KingdomOrestis Telelistelelis@gmail.comDepartment Digital SystemsUniversity Piraeus, GreeceCarmine Ventrec.ventre@tees.ac.ukSchool ComputingTeesside University, United KingdomAbstractdesign analyze deterministic truthful approximation mechanisms multiunit Combinatorial Auctions involving constant number distinct goods,arbitrary limited supply. Prospective buyers (bidders) preferences multisetsitems, i.e., one unit per distinct good. objective determineallocations multisets maximize Social Welfare. main results multiminded submodular bidders. first setting bidder positive valueallocated one multiset prespecified demand set alternatives. secondsetting bidder associated submodular valuation function defines valuemultiset allocated. multi-minded bidders, design truthful Fptasfully optimizes Social Welfare, violating supply constraints goodswithin factor (1 + ), fixed > 0 (i.e., approximation applies constraintsSocial Welfare). result best possible, full optimizationimpossible without violating supply constraints. submodular bidders, obtainPtas approximates optimum Social Welfare within factor (1 + ), fixed> 0, without violating supply constraints. result best possible well.allocation algorithms Maximal-in-Range yield truthful mechanisms, pairedVickrey-Clarke-Groves payments.1. Introductionpaper study design analysis truthful multi-unit Combinatorial Auctions, constant number distinct goods, limited supply. Arguably,widespread modern application general setting allocation radio spectrumlicences (Milgrom, 2004); license use specific frequency band electromagnetic spectrum, within certain geographic area. design SpectrumAuctions, licenses area considered identical units single good (thearea), number distinct geographic areas is, course, bounded constant.formally, consider problem auctioning (allocating) one go multipleunits constant number distinct goods, prospective buyers privatemulti-demand combinatorial valuation functions, maximize Social Welfare.c2015AI Access Foundation. rights reserved.fiKrysta, Telelis, & Ventremulti-demand buyer setting may distinct positive values distinct multisetsgoods, i.e., multiset may demand one unit per good. aimdevise deterministic truthful auction mechanisms, wherein every bidder findsbest interest reveal value truthfully multiset items (i.e., truthful reportvaluation functions dominant strategy). Additionally, interested mechanismscompute approximately efficient allocation polynomial time. problem generalizes simultaneously Combinatorial Auctions multiple goods Multi-unitAuctions single good multi-unit combinatorial settings respectively.Since work Lehmann, OCallaghan, Shoham (2002), Mechanism DesignCombinatorial Auctions multiple heterogeneous goods (each unitary supply) received significant attention recent years (Holzman, Kfir-Dahav, Monderer, & Tennenholtz, 2004; Lehmann, Lehmann, & Nisan, 2006; Dobzinski, Nisan, & Schapira, 2010; Lavi& Swamy, 2011), due various applications, especially online trading systemsInternet. mechanism elicits bids interested buyers, determineassignment bundles payments way, bidders bestinterest reveal valuation function truthfully mechanism. line research,introduces algorithmic efficiency considerations design truthful mechanisms,initialized work Nisan Ronen (2001).related problem auctioning multiple say units single good multidemand bidders already considered Vickrey seminal paper (Vickrey,1961). bidders submodular private valuation functions, Vickrey gave extensioncelebrated single-item Second-Price Auction mechanism, retains truthful revelation valuation functions (weakly) dominant strategy bidders fully optimizesSocial Welfare. drawback mechanism computationallyefficient (constant number of) units, allocation algorithm mustprocess (s) bids least many steps, whereas input number,require number steps bounded polynomial log s. Several drawbacksgeneralized Vickrey-Clarke-Groves (truthful) auction mechanism identifiedAusubel Milgrom (2010). Polynomial-time approximation mechanisms multiunit auctions designed relatively recently (Mualem & Nisan, 2002, 2008; Dobzinski &Nisan, 2010; Vocking, 2012; Nisan, 2014). particular, Nisan (2014) devised deterministic, polynomial time auction mechanism, multi-unit setting submodular biddersfirst considered Vickrey (1961). Vocking designed analyzed recently randomizeduniversally truthful polynomial-time approximation scheme, bidders unrestrictedvaluation functions (Vocking, 2012).Results general setting multi-unit Combinatorial Auctions relativelyscarcer (Bartal, Gonen, & Nisan, 2003; Grandoni, Krysta, Leonardi, & Ventre, 2014; Lavi& Swamy, 2011). exactly setting consider here, constant numberdistinct goods, similarly setting considered Grandoni et al. (2014); particular,number cases auctions analyze Maximal-in-Range (MiR) allocationalgorithms (Nisan & Ronen, 2007), paired Vickrey-Clarke-Grovespayment rule, yield truthful mechanisms.722fiMechanisms Multi-unit Combinatorial Auctions1.1 Contributionmain results concern multi-unit Combinatorial Auctions constant numberdistinct goods two broad classes bidders, specified associated valuationfunctions:1. Multi-minded Bidders: setting bidder associated demand setalternative multisets (the multiple minds). bidders valuation function assigns(possibly distinct) positive value every alternative demand set (and leastmuch value every superset alternative) zero elsewhere.2. Submodular Bidders: setting value bidder particular multisetitems given submodular valuation function.multi-minded bidders design analyze Section 4 truthful Fptas1 ,fully optimizes Social Welfare polynomial time, violating supply constraintsgoods factor (1 + ), fixed > 0. violation supplyconstraints practical well theoretical justification. one hand conceivablethat, certain environments, slight augmentation supply economically viable,sake better solutions (e.g., auctioneers well supplied stocks easily handleoccurrences modest overselling). hand, note relaxationsupply constraints necessary obtaining Fptas, problem otherwise stronglyNP-hard, 2 goods (please see related discussion Section 4). resultsignificantly improves upon Fptas Grandoni et al. (2014), approximatesSocial Welfare supply constraints within factor2 (1+), bidders singleparameter (i.e., associate positive value multiset demand set)overbid demands. Technically, Fptas Grandoni et al. (2014) baseddesign monotone algorithms (Lehmann et al., 2002; Briest, Krysta, & Vocking,2011) requires no-overbidding assumption demands (cf. discussion therein).Section 5 revisit general technique introduced Dobzinski Nisan (2010),multi-unit auction Mechanism Design, generalize setting multiple distinct goods, limited supply. discuss generalization yields truthfulPtas immediately multi-minded bidders, violate supply constraintsapproximates Social Welfare within factor (1+), fixed > 0. Subsequently,use technique design truthful Ptas bidders submodular valuation functions, assuming values (bids) accessed value queries algorithm.Prior result, time-efficient deterministic truthful mechanism known submodular bidders, even 2.3 Although technique Dobzinski Nisanfacilitated development factor 2 approximation mechanism bidders generalvaluation functions single-good multi-unit setting, direct extension settingmultiple distinct goods appear work (for general valuation functions).1. Fully Polynomial Time Approximation Scheme.2. context Social Welfare maximization, approximation within factor 1 (or, equivalently,-approximation, 1) mean recovering least fraction 1 welfare optimumallocation. switch temporarily using 1 Section 5, technical convenience.3. Nisan (2014) devised optimal polynomial time auction = 1, i.e., single good.723fiKrysta, Telelis, & Ventreshow, however, appropriate extension dedicated treatment caseDobzinski Nisan yields constant (m + 1)-approximation (Section 6).assumption constant number = O(1) distinct goods important,otherwise problems become Combinatorial Auctions, thus, hard approximatepolynomial time within less O( m) (Lehmann et al., 2002) multi-minded bideders within less e1submodular bidders (Khot, Lipton, Markakis, & Mehta,2008; Mirrokni, Schapira, & Vondrak, 2008). Moreover, recent results Daniely, Schapira,Shahaf (2015) imply that, unrestricted m, techniques cannot yield truthfulpolynomial-time mechanisms approximation factors less O(m) O( m), respectively. Regarding generalization Dobzinski-Nisan technique, existenceFptas multi-minded bidders single good excluded, unless P = NP (Dobzinski& Nisan, 2010). lower bounds imply results best possible. Finally,shown Nisan Segal (2006) Dobzinski Nisan (2010), regarding general valuation functions, deterministic MiR algorithm achieves better 2-approximationsingle good communication complexity o(s), supply good.Closing gap lower bound upper bound (m + 1) constantnumber multiple distinct goods, remains open problem.2. Related WorkMechanism Design multi-unit auctions initiated already celebrated workVickrey (1961), extended famous mechanism case multiple units,bidders symmetric submodular valuation functions (Lehmann et al., 2006).mechanism however computationally efficient respect number availableunits, already discussed. requires bidders place marginal bid per additionalunit wish receive allocation algorithm processes marginal bids.recently, Nisan (2014) exhibited polynomial-time truthful mechanism case.design multi-unit mechanisms polynomially bounded running time log s, denoting number units, first considered Mualem Nisan (2008). work,Mualem Nisan designed analyzed truthful polynomial-time 2-approximationmechanism multi-unit combinatorial setting, involving multiple distinct goods,limited supply, single-minded bidders. Subsequently, Archer, Papadimitriou, Talwar,Tardos (2003) improved upon approximation ratio similar setting,developed mechanism based randomized rounding truthful expectation. recently, Briest et al. (2011) designed analysed Fptas, single-mindedbidders multi-unit combinatorial setting.Dobzinski Nisan (2010) analyzed general scheme designing MiR polynomialtime truthful approximation mechanisms, single-good multi-unit auctions. resultedPtas case multi-minded bidders, 2-approximation general valuationfunctions accessed (by allocation algorithm) value queries,43 -approximation symmetric subadditive valuation functions. Moreover, authorsapplied scheme class piecewise linear (multi-unit) valuation functionsnumber units single good, obtain truthful Ptas mechanism. special caseclass valuation functions earlier studied Kothari, Parkes, Suri(2005); authors designed Fptas mechanism was, however, approximately724fiMechanisms Multi-unit Combinatorial Auctionstruthful. Dobzinski Dughmi (2013) gave randomized truthful expectation Fptasmulti-minded bidders. Relatively recently, Vocking (2012) gave universally truthfulrandomized Ptas general valuation functions accessed value queries (in contrast,mechanisms deterministic). multi-unit combinatorial setting (i.e.,one distinct goods) known results concern mainly bidders demandssingle unit good (Lehmann et al., 2002; Briest et al., 2011; Blumrosen &Nisan, 2007). contrast, consider constant number goods, multi-demandbidders. Bartal et al. (2003) proved approximation competitiveness results truthfulmulti-unit Combinatorial Auctions multi-demand bidders, bidders demandsnumbers units upper lower bounded. derived approximation guaranteesdepend bounds. Lavi Swamy (2011) improved upon approximationguarantees, devising randomized mechanisms truthful expectation.study constant number goods, arbitrary limited supply, initiatedGrandoni et al. (2014). authors utilized methods multi-objective optimization(approximate Pareto curves Langrangian relaxation) design analyze truthfulpolynomial-time approximation schemes variety settings. particular, devised truthful Fptases approximate objective function (Social WelfareCost) multi-capacitated versions problems within factor (1 + ), violatingcapacity constraints factor (1 + ) (capacity corresponds limited supplydistinct goods). Problems considered Grandoni et al. include multi-unitauctions, minimum spanning tree, shortest path, maximum (perfect) matching matroidintersection; subclass problems truthful Ptas also analyzed,violate capacity constraints.particular interest practice Combinatorial Auctions (also multi-unitcase, good available limited supply identical copies), efficient(near-)optimal resolution Winner Determination problem (Lehmann, Muller, &Sandholm, 2010). Given input set bids prespecified format (formally termedlanguage), items sale, Winner Determination problem prescribes determination feasible allocation items bidders, sum bidscorresponding received allocation maximized. Thus, Winner Determinationproblem implicitly prescribes determination winning bidders receiving allocation, revenue collected corresponding bids maximized. Notice that,comparison work, truthful report bidders valuation functions concernsetting. significant volume research concerned study approximationalgorithms derivation hardness results (see, e.g., Lehmann et al., 2010), muchdevelopment global optimization techniques (Sandholm, 2010). Kelly (2004) studiesMulti-unit Combinatorial Auctions distinct goods, determining allocation computational resources. particular, devises optimal algorithmWinner Determination problem, low-dimensional setting ours.Finally let us mention work Bikhchandani, de Vries, Schummer, Vohra(2011) investigates multi-unit Combinatorial Auction premises similar ours, withoutrestriction number distinct goods. Instead, authors devise ascending priceauction selling subsets goods constitute bases matroid, polymatroid, casemulti-unit demand bidders limited supply distinct good. auctiontruthful runs polynomial pseudopolynomial time, respectively. accesses725fiKrysta, Telelis, & Ventrebidders combinatorial valuation functions Demand Queries; bidderspresented prices goods announce subset willing pay for.comparison, mechanisms use Value Queries, mechanism asksvalue bidder particular set items. Value queries weaker devicesimulated (but cannot generally simulate) demand queries (Blumrosen& Nisan, 2007).3. DefinitionsLet [m] = {1, . . . , m} set goods, assumed fixed constant.s` N units (copies) good ` [m] available. multiset goods denoted vectorx = (x(1), x(2), . . . , x(m)), x(`) number units good ` [m], ` = 1, . . . , m.set multisets denoted U =`=1 {0, 1, . . . , s` }. Let [n] = {1, . . . , n}set n agents (prospective buyers/bidders). Every bidder [n] private valuationfunctionvi : U 7 R+ ,vi (x) x U denotes maximum monetary amount willingpay x U, referred value x. valuation functions normalized, i.e.,vi (0, . . . , 0) = 0 assumed monotone non-decreasing: two multisets xholds component-wise, assume vi (x) vi (y). is, auction theoryterms, assume free disposal (i.e., enlarging set increasing number itemsallocation never decreases value incurred bidder).mechanism consists allocation method (algorithm), A, payment rule, p.allocation method elicits bids b = ( b1 , b2 , . . . , bn ) bidders that, presumably, describe valuation functions outputs allocation A(b) = (x1 , x2 , . . . , xn ),xi U multiset goods allocated bidder i. purposes discussion section, deliberately ignore fact bidders valuation functions maysuccinct representation facilitate efficient communicationallocation algorithm; recall bidders valuation functions generally definedU =`=1 {0, 1, . . . , s` }. succinct representation indeed,allocation algorithms discussed paper access bidders valuation functions iteratively, polynomially many Value Queries; is, algorithm iterationasks every bidder bid specific multiset items.payment rule determines vector p(b) = ( p1 (b), p2 (b), . . . , pn (b) ), pi (b)payment bidder i. Every bidder bids maximize quasi-linear utility,defined as:ui (b) = vi ( A(b) ) pi (b),where, assumption externalities, i.e., value bidder A(b)depends individual allocation others, obtainvi ( A(b) ) = vi (xi ).study truthful mechanisms (A, p) wherein bidder maximizes utilityreporting valuation function truthfully, i.e., bidding bi = vi , independentlybidders reports, bi = (b1 , . . . , bi1 , bi+1 , . . . , bn ):726fiMechanisms Multi-unit Combinatorial AuctionsDefinition 1 mechanism (A, p) truthful if, every bidder bidding profile bi ,satisfies ui (vi , bi ) ui (vi0 , bi ), every vi0 .definition, profile b = v dominant strategy equilibrium. objectivedesign analyze truthful mechanisms, (A, p) render truthful reportingbidders valuation dominant strategy equilibrium, wherein, Social Welfareresulting allocation, SW ( A(b) ) = SW ( A(v) ) (approximately) optimized. socialwelfare allocation, X = (x1 , x2 , . . . , xn ) defined as:SW (X) =nXvi (xi ),i=1sequel use simply X, allocation output A, without specific referenceb, since analyze truthful mechanisms, dictate b = v.well understood general method design truthful mechanismsVickrey-Clarke-Groves (VCG) auction mechanism (Vickrey, 1961; Clarke, 1971; Groves,1973), generalization Vickreys Single-Item 2nd Price Multi-unit Auctions (Vickrey,1961). Deployment VCG auction, however, requires utilization allocationalgorithm, A, outputs welfare-maximizing allocation underlying setting;rarely constitutes computationally efficient alternative combinatorial settings,underlying optimization problem NP-hard.problems consider work indeed NP-hard, mechanisms useMaximal-in-Range (MiR) allocation algorithms (Nisan & Ronen, 2007), maximizesocial welfare approximately.Definition 2 (Nisan & Ronen, 2007) algorithm choosing output setpossible allocations MiR, fully optimizes Social Welfare subset Rallocations.Note subset R, also called range, defined independently bidders declarations. Nisan Ronen (2007) identified MiR allocation algorithms sole devicethat, along VCG payments, yields truthful mechanisms Combinatorial Auctions.particular, given MiR allocation algorithm, A, using algorithm computingoutput allocation computing payments manner VCG paymentsscheme, suffices obtain truthful mechanism. particular, given MiR allocation algorithm, payment bidder computed follows:pi (b) =Xvi0 ( A(bi ) )i0 6=iXvi0 ( A(b) )i0 6=iNotice payment scheme coincides VCG payment scheme, useoptimal allocation algorithm place A. starting point work NisanRonen (2007) pair observations that: (i) VCG mechanism requires fulloptimization social welfare underlying setting, NP-hard probleminteresting settings (ii) VCG-based mechanisms (wherein polynomial-time allocationalgorithm outputs welfare-suboptimal allocations) necessarily truthful.727fiKrysta, Telelis, & Ventre4. Multi-minded Bidderssection consider multi-minded bidders; every bidder [n] associatedcollection multisets Di U, referred demand set. assume[n] values multiset = (d(1), . . . , d(m)) Di amount vi (d) > 0. everymultiset e U \ Di define:finmax vi (d) fifi eDi existsdDivi (e) =0otherwise.Naturally, vi (0) = 0, 0 = (0, . . . , 0). Consequently, setting, valuationfunction bidder compactly expressed collection (vi (d), d)dDi .related literature, assume therefore algorithm expects input bids form,rather (an oracle representing) entire valuation function. say bidderwinner auction, assigned exactly one alternatives Di (orsuperset one alternatives); corresponds XOR-bidding languageCombinatorial Auctions (Lehmann et al., 2006).design Fptas, maximizes Social Welfare may violate supplyconstraints goods factor (1 + ), fixed > 0.allocation algorithm mechanism. analyzing performance respectwelfare optimality allocation outputs bounded violationsupply constraints, prove MiR algorithm, thus paired VCGpayments, yield truthful mechanism. high level, algorithm reminiscentone yields Fptas well-known one-dimensional knapsack problem (seee.g., Vazirani, 2003, ch. 8). proceeds follows. chosen fixed > 0, firstdiscards alternatives bidders demand sets, cannot satisfied, givensupply constraints. alternatives multisets already exceed supplyleast one good. Subsequently, quantities goods multisets remainingwithin bidders demand sets appropriately rounded; supply adjusted well.thus obtain rounded instance. Then, search welfare maximizing allocationrounded instance, usage dynamic programming. allocation shownoptimal initial instance, well, feasible, modulo violation initialsupply constraints within factor (1 + ). light turning algorithmtruthful mechanism, use notation actual valuation functions definitionanalysis below.Fix constant > 0. First, [n], remove alternatives Did(`) > s` ` = 1, . . . , (if alternatives bidder removed, removei). Henceforth, use notation, U, [n], Di , etc., remaining alternativesbidders. demands alternatives Di [n] rounded follows.every [n] every Di , produce multiset d0 = (d0 (1), . . . , d0 (m))that, distinct good ` [m], d0 (`) = b nd(`)s` c. adapt supplyn0good appropriately, s` = e. Given rounded version problem instance,use dynamic programming produce allocation it, immediatelytranslate allocation original problem instance, welfare-optimalviolates (original) supply constraints factor (1 + ). purposesdescription follows, denote d0 rounded version demand d.728fiMechanisms Multi-unit Combinatorial Auctionsdefine dynamic programming table V(i, Y1 , . . . Ym ) = 1, . . . , n Y`{0, 1, 2, . . . , s0` } ` [m]. cell V(i, Y1 , . . . , Ym ) stores maximum welfarePnx (`)allocation X, i.e., j vj (xj ), whose rounded version X0 = (b sj` c)j,` uses multisetsdemand sets biddersP {1, 2, . . . , i}, total demand w.r.t. good` = 1, . . . , precisely Y` , i.e., x0i (`) = Y` .compute entries table V, observe that, problem V(1, Y1 , . . . Ym )collection Y` that: (Y1 , . . . , Ym ) {0, 1, . . . , n e}m , easy solve.entry V(1, Y1 , . . . Ym ) check bidder 1 alternative D1d0 (`) = Y` , ` [m]. yes, let alternative maximum valuation;assign V(1, Y1 , . . . , Ym ) = v1 (d) build auxiliary table A[1, Y1 , . . . Ym ] setcase {(1, d)}. Otherwise, bidder 1 alternative, assignV(1, Y1 , . . . Ym ) = 0 A[1, Y1 , . . . Ym ] = {(1, 0)}. define V(i + 1, Y1 , . . . , Ym ), considerbidder + 1 alternatives = (d(1), . . . , d(m)) Di+1 ; leti+1nfifi00= max vi+1 (d) + V i, Y1 (1), ..., Ym (m) fi d0dDi+1(1)where, i, define V(i, Y1 , . . . Ym ) = and, accordingly, A[i, Y1 , . . . Ym ] = { (i, 0) },demand Di satisfying d0 Y. Consequently:nV(i + 1, Y1 , . . . , Ym ) = max i+1 , V(i, Y1 , . . . Ym ) .Accordingly, i+1 V(i, Y1 , . . . Ym ), set:A[i + 1, Y1 , . . . , Ym ] = A[i, Y1 , . . . , Ym ] {(i + 1, 0)},otherwise:A[i + 1, Y1 , . . . , Ym ] = A[i, Y1 d0 (1), . . . , Ym d0 (m)] {(i + 1, d)},alternative Di+1 maximizing (1). Finally, inspect solutionsentries V(n, Y1 , . . . , Ym ) vectors (Y1 , . . . , Ym ) {0, 1, . . . , n e}m , take onemaximizes Social Welfare output solution given corresponding entrytable.size table V n(d n e+1)m need time roughly O(maxi |Di |+m) computeone entry table, overall time algorithm leads Fptas. optimalityrespect sum bidders values easy verify. Let X = (x1 , x2 , . . . , xn )denote feasible allocation original problem instance.every good, ` = 1, . . . , m,P j xi (`)n k nPP xi (`)nnhave: xi (`) s` , or, equivalently, s` , thus s` = s0` .is, X also feasible rounded problem instance. dynamic programmingalgorithm inspect feasible solutions rounded problem instance outputone largest welfare it, optimum solution original problem instanceinspected well.argue supply constraints s` , ` = 1, . . . , m, violated factor1 + 2. Fix good ` {1, . . . , m} let X output allocation, respect729fiKrysta, Telelis, & Ventreoriginal problem instance. X chosen algorithm means dynamic programming search roundedproblem instance, feasible roundedP j nxi (`) ks0` = n e and, since:problem instance. Thus, have:s`X n xi (`)s`obtain:Pxi (`)X n xi (`)lnms`+n+ |{i|xi Di }|n+ 1 + n,(1 + 2)s` .Example Let us illustrate algorithms functionality simple example.Consider n = 3 bidders = 2 distinct goods. Let supplies goods s1 = s2 = 4.bidders values demand sets defined follows:BidderValuation FunctionDemand Set1v1 ( (3, 4) ) = 1 v1 ( (4, 3) ) = 2 D1 = { (3, 4), (4, 3) }2v2 ( (3, 3) ) = 3D2 = { (3, 3) }3v3 ( (2, 3) ) = 4 v3 ( (3, 2) ) = 5 D3 = { (2, 3), (3, 2) }example evident feasible allocations involve assignment demandsingle bidder, given supplies goods 4. Thus, optimal allocationX ( 0, 0, (3, 2) ). Consider rounded problem = 2. rounded supplytwo goods dn/e = d4/2e = 2. rounded demands biddersfollows:Bidder123Demands (3, 4) (4, 3) (3, 3) (2, 3) (3, 2)Rounded Demands (1, 1) (1, 1) (1, 1) (0, 1) (1, 0)Observe demands bidder 1 rounded (1, 1). poseproblem, algorithm processes original demands, uses roundedversions validate feasibility allocation builds respect rounded supply.example, rounded supply good 2, algorithm outputallocation X = ( 0, (3, 3), (3, 2) ), welfare 8 superoptimalinital instance. Although rounded versions allocated demands violaterounded supplies goods (equal 2), violate original supplies 4, lessfactor 1 + = 3 (particularly example, factor 1.5).Note algorithm exact, grants every bidder multisetdemand set (or none). Assuming = O(1) essential result, even presencesupply constraints relaxation. proof claim given end section.truthfulness Fptas, denoted below, follows fact optimizesfixed range solutions.Theorem 1 exists truthful Fptas multi-unit combinatorial auction problemfixed number goods, bidders private multi-minded valuation functions,defined, bidder, private collection multisets goods. fixed > 0,Fptas fully optimizes social welfare, violating supplies goods within factor(1 + ).730fiMechanisms Multi-unit Combinatorial AuctionsProof. prove theorem show MiR range R = {X|b : A(b) =X}. is, allocation X R bid vectorb, show SW (A(b), b)SW (X, b), bid vector b = (bi (d), d)dDiallocation X R,let SW (X, b) SocialP Welfare allocation X, evaluated according bidvector b, i.e., SW (X, b) = bi (X).Fix allocation X bid vector b = (bi (d), d)dDi; definition range,A(b) = X. Recallexists bid vector b, b = (bi (d), d)dDixi (`), bidder ` = 1, . . . , m, variable indicating many copies item`, allocation X grants bidder i. Note X = A(b) grantsdemanded alternatives (by exactness), exists demand di Di {0} that,` = 1, . . . , m, xi (`)j= di (`).Since X output A, definitionP ndi (`) k n` = 1, . . . , m, s` .let C set bidders b = (bC , bC ) b = (bC , bC ), is,b b differ bids bidders set C. bidders C assumetrue valuation function bi . bidder evaluates alternative xi = digranted allocation X ei Di {0}. is, vi (di ) = vi (ei ). Assume,sake contradiction, SW (X, b) > SW (A(b), b), i.e.:Xbi (ei ) +Xbj (X) >j6CiCXbi (A(b)) +Xbj (A(b)).(2)j6CiCSince di (`) ei (`) ` = 1, . . . , C, setting ei = di 6 C, obtain:X n ei (`)s`X n di (`)s`lnm,` = 1, . . . , m. solution grants bidder alternative ei Di {}considered algorithm input b. solution Social Welfare SW (X, b)therefore (2) contradiction definition A.2related result Briest et al. (2011) truthful Fptas single good limited(not violated) supply; cannot generalized setting one supplyconstraints.4.1 Note HardnessNote problem strongly NP-hard, allow violate supply constraints 2 (Chekuri & Khanna, 2005). well known problem stronglyNP-hard, exist FPTAS problem, unless P=NP (see, e.g., Vazirani, 2003). Also assumption fixed constant necessary. Otherwiseproblem equivalent multi-unit Combinatorial Auctions hard approximatepolynomial time within m1/2 , > 0 (Lehmann et al., 2002). claim true,even allow solutions violate supplies. particular:731fiKrysta, Telelis, & VentreProposition 1 multi-unit combinatorial auction distinct goods, NPhard approximate Social Welfare within factor better m1/2 , even allowmultiplicative (1 + )-relaxation supply constraints, < 1.Proof. argument follows: known hard approximate maximumindependent set problem graph G = (V, E) within factor m1/2 > 0,|E| = (Hastad, 1996). using reduction Lehmann et al. (2002), reduceproblem problem set goods [m] = E set single-mindedbidders V ; bidders u V set contains edges adjacent u graph Gbidders valuation set 1. allow violate supply 1good factor 1 + , < 1, feasible solution relaxed problemindependent set graph G. Thus relaxed problem equivalent maximumindependent set problem G.24.2 Multi-dimensional Knapsackdiscuss application Fptas, relation Multi-dimensional KnapsackProblem (MdKP) (Chekuri & Khanna, 2005). Suppose given MdKP instance,constant number distinct compartments, = O(1), compartment,` = 1, 2, . . . , m, capacity s` . problem asks fit knapsack subsetuniverse, U, n given m-dimensional objects, sum collected objectssizes dimension, `, exceed s` total value collected objectsmaximized. object, = 1, . . . , n MdKP instance representedvector di , represents dimensions, (di (1), . . . , di (m)) value, vi ,hvi , di ( (R+ {0}) U ). Then, object corresponds single bidder i,setting analyzed Section 4, valuation function vi (d) vi , every di ,vi (d) = 0, every d(`) < di (`), ` = 1, . . . , m. Notice biddersingle-parameter, valuation function takes single non-zero value everydi demand set, Di , singleton, i.e., contains single multiset, di . Thus,MdKP corresponds single-parameter version problem treated above.apply Fptas MdKP, algorithm exact, mentionedpreviously, allocates every bidder (read as: fits knapsack) either exactalternative demand set, Di , none. worth mentioning singleparameter version, Fptas Section 4 shown monotone (Lehmann et al.,2002; Briest et al., 2011), one carefully fixes tie-breaking rule. monotone allocationalgorithm ensures that: (single-parameter) bidder allocated single demand dideclares truthfully hvi , di i, also receives (declared) demand d0i ,declares hvi0 , d0i i, vi0 vi d0i di (i.e., intuitively, asks less items offeringmoney). exact monotone allocation algorithm yield truthful mechanismsingle-parameter setting, incorporation critical value payments seework Lehmann et al. (2002) details.Let us note that, generalize MdKP further, following manner. Insteadpacking constraints (of form ) dimensions knapsack,handle mix packing covering constraints (i.e., forms {, }),long constant number dimensions, = O(1), one coveringpacking constraint per dimension. generalized scenario follow732fiMechanisms Multi-unit Combinatorial Auctionsapproach similar approach Section 4 obtain truthful Fptas fullyoptimizes total value fitted items violates constraints factor(1 + ). Violation constraints needed reason mentioned above,note computational hardness, end Section 4.5. Generalized Dobzinski-Nisan Methoddiscuss direct generalization method designed Dobzinski Nisan (2010),truthful single-good multi-unit auction mechanisms. use methods generalization multiple goods next subsection, obtain truthful Ptas bidderssubmodular valuation functions (over multisets). Let polynomial-time MiRallocation algorithm = O(1) bidders s` units good ` = 1, . . . , m,time complexity TA (t, s), = (s1 , . . . , sm ), approximation ratio 1. Then, algorithmused routine within procedure Figure 1, obtain polynomial-timeMiR algorithm n bidders, approximation ratio ( t+1).Given = O(1), procedure executes algorithm every subset biddersevery combination certain pre-specified quantities goods. outputallocation considers rest bidders allocates optimally integralnumber (multi-unit) bundles good. main result shown DobzinskiNisan (2010) single good also proved goods:Theorem 2 Let Maximal-in-Range algorithm complexity TA (t, (s1 , . . . , sm )),bidders s` units good ` = 1, . . . , m. Dobzinski-Nisan MethodMiR runs time polynomial log s1 , . . . , log sm , n, TA (t, (s1 , . . . , sm )), every= O(1). Moreover, outputs allocation value least fraction ( t+1)optimum Social Welfare.proof direct extension proof given Dobzinski Nisan (2010) singlegood. Consider MiR algorithm A, used within Dobzinski-Nisan method;executes polynomial time = O(1) bidders = O(1) distinct goods,limited supply s` , ` [m]. Let RA denote range algorithm. verifiedmethod outputs allocations (R, t, 1 , . . . , )-round, given followingdefinition round allocations (Dobzinski & Nisan, 2010):Definition 3 = O(1), allocation (R, t, 1 , . . . , )-round if:R set allocations and, X R, bidders allocated nonempty bundles. bidders allocated together s` ` units good` = 1, . . . , m.exists set |T | bidders, allocated accordingallocation R.`Pbidder [n] \ receives exactmultiple max b 2nunits good `2 c, 1`and:x(`)nmaxbc,1,`=1,...,i[n]\T2n2733fiKrysta, Telelis, & Ventre1. ` = 1, . . . , do:1(a) define u` := (1 + 2n)blogu s` c2`(b) define L` := 0, 1, bu` c, bu` c, . . . , u`, s`2. every subset [n] bidders, |T | t, do:1. every (1 , . . . , )L`=1 ` do:1 Run s` ` units good ` [m] bidders .2 Split remaining ` units (if ` > 0) fromeach good` [m]`c,1units.2n2 bundles (per good), max b 2n23 Find optimal allocation equi-sized bundles among bidders [n] \ .3. Return best allocation found.Figure 1: Dobzinski-Nisan Method multiple goods.definition, R corresponds range A, parameterized subsetbidders , i.e., R = RA (T ), executed. Then, = O(1), rangemethod subset allocations (RA (T ), , 1 , . . . , )-round, that:(1 , . . . , ) (m`=1 L` ), L` defined step 1.(b) method Figure 1,[n], = |T | t. Formally, methods range RDN subset allocations:n fifiL)=|T|RDN = X fi X (RA (T ), , 1 , . . . , )-round, (` )` (m`=1 `Example Part (I) continuing analyze methods range, let us exemplifyconcept (R, t, 1 , . . . , )-round allocations. consider small instancemulti-minded bidders, similar considered previous section. arguelater, Dobzinski-Nisan method yield truthful Ptas (that respects supplyconstraints goods), multi-minded bidders. Assume = 2 distinct goods, n = 5bidders. assume supplies s1 = 200 = s2 goods. bidders demandsfollows:BidderDemand Set1D1 = { (75, 51), (49, 73) }2D2 = { (51, 27), (25, 49) }3D3 = { (48, 1) }4D4 = { (1, 1) }D5 = { (1, 48) }5Let us exhibit round allocation instance, according Definition 3. = 21 = 2 = 100, consider first allocation:X = ( (75, 51), (25, 49), (48, 2), (2, 2), 0 ),734fiMechanisms Multi-unit Combinatorial Auctionsx1 = (75, 51), x2 = (25, 49), x3 = (48, 2), x4 = (2, 2), x5 = 0. allocation(R, 2, 100, 100)-round, according Definition 3, R denotes subset allocations2 bidders receiving non-empty multisets remaining ones receiving appropriate multi-unit bundles per good. Indeed, set = {1, 2} (for correspondingsubset 2 bidders); bidders 1 2 obtains one demands. totalnumber units allocated two bidders per good exactly 100 = s` ` .remaining 100 = ` units good, make 50 bundles ` /(2n2 ) = 2 units perbundle. Bidder 3 receives 24 2-units bundles good 1 one 2-units bundlegood 2. Bidder 4 obtains one 2-units bundle good. Finally, bidder 5 receivesempty allocation. Notice x3 x4 essentially satisfy unique demands (48, 1)(1, 1) bidders 3 4 respectively.Another (R, 2, 100, 100)-round allocation (according Definition 3) is:X0 = ( (75, 51), (52, 28), (48, 2), 0, 0 ),required subset bidders = {1}. Bidder 1 obtains one demands;bidders 2 3 receive 2-units bundles good; bidders 4 5 receive emptyallocations (i.e., zero 2-units bundles good). Notice X0 also (R, 1, 100, 100)round (i.e., set = 1). let us choose algorithm Dobzinski-Nisanmethod, exhaustive search procedure, optimizes welfare (thus, approximation ratio = 1). Notice range RA (T ) A, chosen values1 , 2 , trivially contains allocation bidders 1 2 receive X (when = {1, 2})allocation bidder 1 X0 (when = {1, 2} = {1});optimizes feasible allocations supplies 200 1 = 100 200 2 = 100two choices . Thus, allocations X X0 also belong range RDN ,defined above.show optimization RDN approximates socially optimal allocation withinfactor ( t+1).Lemma 1 Let X = (x1 , . . . , xn ) socially optimal allocation. exists allocationX RDN SW (X) ( t+1) SW (X ).Proof. proof make use notation L` u` , defined Figure 1. Withoutloss generality (because monotonicity valuation functions), assume unitsgoods allocated X v1 (x1 ) v2 (x2 ) Pvn (xn ). every good` = 1, . . . , choose largest value ` L` s` ` ti=1 xi (`). executedsubset bidders = {1, . . . , t} s` P` units goodP ` = 1, . . . , m, algorithmoutputs allocation (x1 , . . . , xt ) ti=1 vi (xi ) ti=1 vi (xi ).consider good ` = 1, . . . , bidder jP` {t + 1, . . . , n} maximumnumber units X good. Define r` = ni=t+1 xi (`). xj` (`) rn` .definition r` ` good `, r` ` . Also, ` chosenPt2largest possible value L` = { 0, 1, bu` c, bu` c, . . . , s` } satisfying s` ` + i=1 xi (`),r`. every bidder + 1 6= j` ` = 1, . . . , m,must ` ur`` r` 2n`round allocation respect good ` multiple max b 2n2 c, 1 . extraunits good ` take bidders j` may obtain unit good.735fiKrysta, Telelis, & Ventre``Observe may need add n 2n2 2n extra units good `,`r`take bidder j` , least n n units.Thus, bidders except j` , ` = 1, . . . , increased units Pgoods1obtain. j` + 1 v1 (x1 ) vn (xn ), vj` (xj` ) t+1i=1 vi (xi )vi (xi ) vi (xi ) 6= j` , ` = 1, . . . m. Then:SW (X) =Xvi (xi )X=XXi=1vi (xi )Xvi (xi )it+1vi (xi )it+1t+1vi (xi ) +i=1vi (xi ) +i=1XXvi (xj` )`=1+Xvi (xi )it+1t+1SW (X )2concludes proof.lemma completes proof Theorem 2.Example Part (II) revisit example discussed right statementproof Lemma 1, order exemplify approximation implied Lemma.end, assign values bidders demands described following table,v > 0 small positive number V >> v large one. before,s1 = s2 = 200.BidderValuation Function1v1 ( (75, 51) ) = v v1 ( (49, 73) ) = V2v2 ( (51, 27) ) = V v2 ( (25, 49) ) = v3v3 ( (48, 1) ) = V4v4 ( (1, 1) ) = v5v5 ( (1, 48) ) = VD1D2D3D4D5=====Demand Set{ (75, 51), (49, 73) }{ (51, 27), (25, 49) }{ (48, 1) }{ (1, 1) }{ (1, 48) }following socially optimal allocation X instance welfare 4V + v:X = ( (49, 73), (51, 27), (48, 1), (1, 1), (1, 48) )choosing = 2 = {1, 2}, exhibit welfare-approximate allocationimplied Lemma 1, follows. maximum value possible 1 2satisfying s` ` x1 (`) + x2 (`) 100 = 1 = 2 . remaining bidders, bidder3 maximum number units good 1 X bidder 5 maximumnumber units good 2 X . Thus, j1 = 3 j2 = 5. Then, roundallocations bidders 3 4 w.r.t. good 2, one 2-units bundle (for them),taking two units bidder j2 = 5. Accordingly, round allocations bidders4 5 w.r.t. good 1, taking two units bidder j1 = 3. resulting allocation is:X = ( (49, 73), (51, 27), (46, 2), (2, 2), (2, 46) )welfare 2V + v, approaches half optimal welfare (as v becomes vanishingly small). Lemma 1 example guarantees least 1/3 optimal welfare,736fiMechanisms Multi-unit Combinatorial Auctionsalgorithm used within Dobzinski-Nisan method welfare-optimizing exhaustivesearch procedure. hand notice that, particular example = 2,1 = 2 = 100, allocation = ( (49, 73), (51, 27), (48, 2), 0, (2, 48) ) almost optimal welfare, 4V , round according Definition 3. Thus, Dobzinski-Nisanmethod examine return allocation least good.Let us explain find optimal allocation multi-unit bundles goods (i.e.,bundles identical units) bidders [n] \ , step 2.1.3 algorithm (Figure 1).use dynamic programming. re-indexing bidders appropriately, assume= {n + 1, . . . ,n}, thus [n]\ = {1, . . . , n t}. every = 1, . . . , n every2q = (q1 , . . . , qm )i=1 [2n ] , define V(i, q) = V(i, (q1 , . . . , qm )) maximum valuewelfare obtained allocating q` equi-sized bundles (of units)good ` = 1, . . . , bidders 1, . . . , i. entry V(i, q) dynamic programmingtable computed using:000V(i, q) = maxv(qb,...,qb)+V(i1,qq),110q qq0 q taken component-wise; i.e., maximization occurs vectors q0q 0 (`) q(`) ` = 1, . . . , m.5.1 Simple Application: Multi-minded Biddersgeneralized Dobzinski-Nisan method multiple distinct goods applied immediately setting multi-minded bidders, yield Ptas respects fully supplyconstraints goods. = O(1) goods constant number biddersoptimum assignment found exhaustively polynomial time log s` , ` = 1, . . . , s,m. particular, every bidders demand sets contains k demands,exactly O(k ) cases examined exhaustively, optimum found. Pluggingalgorithm procedure Figure 1, yields Ptas that, complementarily developments previous section, approximates optimum Social Welfare within factor(1 + ) respects supply constraints.5.2 Submodular Valuation Functionsconsider submodular valuation functions multisets U, defined Kapralov,Post, Vondrak (2013):Definition 4 ` = 1, . . . , let e` unary vector e` (`) = 1 e` (j) = 0,j 6= `. Let x denote two multisets U, x y, holdscomponent-wise. Then, non-decreasing function v : U 7 R+ submodular v(x + e` )v(x) v(y + e` ) v(y).assume valuation functions, exponentially large describe,accessed algorithm value queries; i.e., algorithm asks biddersvalue, particular multiset needs process.design MiR approximation algorithm A, needed method. rangeconsider setting extension one considered Dobzinski Nisan737fiKrysta, Telelis, & Ventre(2010). > 0, define = 1 + ; assigning bidders multi-unit bundlesgood ` [m], cardinality equal integral power . every good` [m], one n bidders (possibly different bidder per good) always obtainremaining units specific good. show optimization range providesgood approximation unrestricted optimum Social Welfare; also, optimizingrange yields Fptas constant number n bidders. This, used within generalizedDobzinksi-Nisan method yield Ptas number bidders.Lemma2 optimum assignment within defined range recovers least factor2socially optimal welfare.2+2Proof. Let X = (x1 , . . . , xn ) denote welfare maximizing assignment. rounditeratively particular good ` [m] iteration assignment unitsbidder X , integral power . Let X[`] assignment roundingrespect `-th good. final assignment X X[m] approximate welfareX[0] X .beginning `-th iteration process assignment X[`1] , rounding[`1][`1]assignment multi-unit bundles good `. Assume w.l.o.g. x1 (`) x2 (`)[`1]xn (`). Also w.l.o.g., assume every bidder except bidder 1 receivesintegral power units good `; bidder 1 receives remaining units. Let setbidders partitioned [n] = E contains odd indices bidders Eeven ones. consider two cases:X [`1] X [`1]X [`1] X [`1]v xivi xv xi<vi xi.(3)iOiEiOiE[`1]first case, every \ {1} round xi(`) closest integral[`1]power , obtaining extra units rounding xi1 (`), 1 E,[`][`1]nearest appropriately chosen integral power . obtain xi (`) xi[`1][`1][`1]xi1 (`) = xi1 (`) ( 1)xi[`1][`1](`) and:[`1](`) xi1 (`) ( 1)xi1 (`)[`1]thus, xi1 (`) (2 )xi1 (`). ensure bidder 1 obtain integral power[`1][`][`1], may need divide xi1 (`) , thus: xi1 (`) 1 xi1 (`) =welfare emerging assignment X[`] is:X X X[`][`][`]SW X[`] =vi xi =v xi +vi xiiOi[n]X[`1]vi xiE2 X [`]+v xiiEiOX2[`1]=vi+SW X[`1]v xiiOiO2 2 X [`1] 2v xi+SW X[`1]=X[`1]xiiO738!2 [`1]xi1 (`).fiMechanisms Multi-unit Combinatorial Auctions211SW X[`1] +SW X[`1] =SW X[`1]1+[`][`1]second line follows submodularity; ` [m], xi1 (`) 2xi1 (`),[`][`1]2vi1 xi1 vi xi1 . last inequality, recall examiningP[`1]left-hand side case (3), thus, use that:) 12 SW (X[`1] ).iO vi (xiPP[`1][`1]Consider second case (3), iO vi xi< iE vi xi.[`1]E \ {2} round xi(`) closest integral power ; extra units[`1]obtain 1 O, rounding xi1 (`) appropriately chosen[`1]closest integral power . x2 (`) rounded closest integral power[`1][`1][`](contrary rest xi(`), E), i.e., x2 (`) 1 x2 (`). E \ {2}[`][`1]xi (`) xi(`) take:[`]xi1 (`)21 [`1][`1][`1]xi1 (`) ( 1)xi(`)xi1 (`)(4)Then, Social Welfare X[`] have:X X X[`][`][`]v xi =v xi +v xiSW X[`] =i[n]iOiEX2 X [`1] 1 [`1][`]v xi+ v 2 x2+v xiiOiE\{2}!XX1 [`1]2[`1][`1]SW X[`1]v xi+ v 2 x2+v xi=iEiE\{2}X22 21[`1][`1]v2 x2+SW X[`1]=vi xi+iE\{2}121 X[`1][`1]>vi x+v 2 x2+SW X[`1]iE\{2}212SW X[`1] +SW X[`1] =SW X[`1]22 + 2second line derivation due submodularity: factors sum[`1][`][`1]odd-indexed bidders v2 (x2 ) follow (4) x2 (`) 1 x2 (`).last inequality, used fact examining right-hand side caseP[`1](3); then, iE vi ( xi) 12 SW (X[`1] ).Thus, > 0, assignmentrange approximateswithinp thedescribedq21optimum Social Welfare within factor 2+2 1+ , integers p, q,p + q = m. result follows11+22+2 .obtain following (intermediate) result:7392fiKrysta, Telelis, & VentreTheorem 3 multi-unit combinatorial auctions n = O(1) submodular bidders,= O(1) distinct goods, good ` [m] available arbitrary supply, existstruthful deterministic Fptas that, 1, approximates optimum Social Welfarewithin factor (1 + ).Proof. fixed > 0 search specified range exhaustively polynomialtime; find allocation maximum Social Welfare, try O(log s` ) casesn 1 bidders, given fixed bidder assigning remaining units. Thustime required trying possible bundle assignments ofa specific good `possible choices remainders bidder n(log s` )n1 . every fixedallocation specific good need try possible allocations remaining 1goods, overall complexity total nm (log max` s` )(n1)m , polynomiallybounded constant n. Also notice that, 1 obtain Fptas, because:log max s` = (log2 (1 + ))1 (log2 max s` )``log21 (1 + ) 1 .2Using Theorem 3 within general Dobzinski-Nisan method, obtain:Corollary 1 exists truthful Ptas multi-unit combinatorial auctions constant number distinct goods submodular valuation functions.6. General Valuation FunctionsInterestingly, direct generalization Dobzinski-Nisan method constant number multiple goods immediately yield, general valuation functions, resultcomparable one shown Dobzinski Nisan (2010) single good; = 1truthful 2-approximation mechanism obtained (and factor shown optimal). = 1, relevant MiR algorithm involved Theorem 2 solves optimallycase = 1 bidder, allocating units goods him. monotonicityvaluation functions guarantees allocation optimal = 1 bidder. factor 2approximation follows. > 1 goods however, Theorem 2 appears require differentalgorithm (for, possibly, > 1 bidders), yield comparable (constant approximation)result. Instead, constant (m+1)-approximation case general valuation functionsaccessed value queries obtained, simple modification direct approachgiven Dobzinski Nisan, general valuation functions.describe scratch MiR allocation algorithm. algorithm splits everygood number units n2 equi-sized bundles size b` = b ns`2 c; also creates singleextra bundle (per distinct good, `), containing remaining units r` , n2 b` +r` = s` .algorithm allocates optimally whole bundles units good n bidders.First show range approximates factor (m + 1) optimum SocialWelfare. Let X = (x1 , . . . , xn ) denote socially optimal allocation. BeginningX , produce allocation range within algorithm optimizes,approximates SW (X ) within factor (m + 1). Assume w.l.o.g. items allocatedX (by monotonicity valuation functions) and, good ` = 1, . . . , m, let740fiMechanisms Multi-unit Combinatorial Auctionsj` = arg maxi xi (`). xj` (`)here.Either:Xvj` (xj` )`=1s`n.XDefine L = {j1 , . . . , jm }. consider two casesvi (xi ),i6Lor:X`=1vj` (xj` ) <Xvi (xi ).i6Lfirst case, let us denote Y` = (y1` , y2` , . . . , yn` ) ` = 1, . . . ,allocation assigns bundles goods bidder j` L (thus, yi` = (0, . . . , 0),every 6= j` ). allocations, consider = arg maxY` vj` (yj`` ). Then, SW (Y)P1 Pmi6L vi (xi ). Putting inequalities together`=1 vj` (xj` ), thus, also: SW (Y)1yields SW (Y) m+1 SW (X ). Notice allocation examined MiRalgorithm. second case build allocation X, rounding separatelygood ` (optimal) allocation bidders 6 L nearest multiple b` .units needed purpose find good ` corresponding bidderj` L, may obtain unit X. possible add n ns`2 =s`X givesn xj` (`) units total rounding. way make allocation Pmulti-unit bundles good bidders [n] \ L satisfies SW (X) i6L vi (xi ),1 Pm1thus, also: SW (X) >`=1 vj` (xj` ). Then, deduce SW (X) m+1 SW (X ). Noticeallocation X also examined MiR algorithm. Thus, exists solutionwithin range, approximates SW (X ) within constant factor, (m + 1).complete analysis, show compute MiR allocation describedrange, using dynamic programming. Let r = (r1 , . . . , rm ) denote vector amountscorrespond bundles remainders per good described above. Given L 2{1,...,m}denote r[L] projection r indices L; remaining coordinates set0. Let b = (b1 , . . . , bm ). subset L 2{1,...,m} , define V L (i, q), q = (q1 , . . . , qm )maximum welfare achievable allocating q` multi-unit bundlesgood ` = 1, . . . , among bidders 1, . . . , remainders bundle goods` L. compute V L (i, q) follows:n000L\L00V L (i, q) = maxmaxv(qb,...,qb)+r[L]+V(i1,qq)11000 qL L q1 q1 ,...,qm= O(1), entries dynamic programming table computedpolynomial time. Thus:Theorem 4 exists truthful polynomial-time mechanism multi-unit Combinatorial Auctions constant number distinct goods, m, general valuation functionsthat, using value queries, approximates welfare socially optimal assignment withinconstant factor, (m + 1).7. Conclusionspaper analyzed deterministic mechanisms multi-unit Combinatorial Auctionsconstant number distinct goods, limited supply. analyzed particularMaximal-in-Range allocation algorithms (Nisan & Ronen, 2007), optimizing SocialWelfare multi-unit combinatorial setting that, paired VCG payments, yield741fiKrysta, Telelis, & Ventretruthful auctions. main results include (i) truthful Fptas multi-minded bidders,approximates supply constraints within factor (1 + ) optimizes SocialWelfare; (ii) deterministic truthful Ptas submodular bidders, approximatesSocial Welfare within factor (1 + ) without violating supply constraints. achieving(ii), used direct generalization single-good multi-unit allocation method proposedDobzinski Nisan (2010). discussed developments best possibleterms time-efficient approximation, follows relevant hardness results. Finally,showed treat general (unrestricted) valuation functions setting, appropriately adjusting analysis Dobzinski Nisan (2010). Closing gapcommunication complexity lower bound 2 (for single good) Dobzinski Nisan(m + 1)-approximation result = O(1) goods, requires understandingcommunication complexity general setting.Acknowledgmentsthank three anonymous reviewers helping us significantly improving presentation work. also thank Jinshan Zhang, pointing technical inconsistencyearlier version paper, Fabrizio Grandoni Stefano Leonardi,useful discussions early stage work.Piotr Krysta acknowledges support EPSRC grant EP/K01000X/1.Carmine Ventre acknowledges support EPSRC grant EP/M018113/1.Orestis Telelis acknowledges support research project DDCOD(PE6-213), implemented within framework Action Supporting Postdoctoral ResearchersOperational Program Education Lifelong Learning (Actions Beneficiary: General Secretariat Research Technology), co-financed European Union(European Social Fund ESF) Greek State.ReferencesArcher, A., Papadimitriou, C. H., Talwar, K., & Tardos, E. (2003). Approximate Truthful Mechanism Combinatorial Auctions Single Parameter Agents. InternetMathematics, 1 (2), 129150.Ausubel, L. M., & Milgrom, P. (2010). Lovely Lonely Vickrey Auction. Cramton,P., Shoham, Y., Smith, V. L., & Steinberg, R. (Eds.), Combinatorial Auctions, pp.1740. MIT Press.Bartal, Y., Gonen, R., & Nisan, N. (2003). Incentive Compatible Multi Unit Combinatorial Auctions. Halpern, J. Y., & Tennenholtz, M. (Eds.), Proceedings 9thConference Theoretical Aspects Rationality Knowledge (TARK-2003), pp.7287. ACM.Bikhchandani, S., de Vries, S., Schummer, J., & Vohra, R. (2011). Ascending VickreyAuction Selling Bases Matroid. Operations Research, 59 (2), 400413.742fiMechanisms Multi-unit Combinatorial AuctionsBlumrosen, L., & Nisan, N. (2007). Combinatorial Auctions. Nisan, N., Roughgarden,T., Tardos, E., & Vazirani, V. V. (Eds.), Algorithmic Game Theory, pp. 267299.Cambridge University Press.Briest, P., Krysta, P., & Vocking, B. (2011). Approximation Techniques UtilitarianMechanism Design. SIAM Journal Computing, 40 (6), 15871622.Chekuri, C., & Khanna, S. (2005). Polynomial Time Approximation SchemeMultiple Knapsack Problem. SIAM Journal Computing, 35 (3), 713728.Clarke, E. (1971). Multipart Pricing Public Goods. Public Choice, 11 (1), 1733.Daniely, A., Schapira, M., & Shahaf, G. (2015). Inapproximability Truthful Mechanismsvia Generalizations VC Dimension. Servedio, R. A., & Rubinfeld, R. (Eds.),Proceedings 47th Annual ACM Symposium Theory Computing, STOC2015, Portland, OR, USA, June 14-17, 2015, pp. 401408. ACM.Dobzinski, S., & Dughmi, S. (2013). Power Randomization Algorithmic Mechanism Design. SIAM Journal Computing, 42 (6), 22872304.Dobzinski, S., & Nisan, N. (2010). Mechanisms Multi-Unit Auctions. Journal ArtificialIntelligence Research, 37, 8598.Dobzinski, S., Nisan, N., & Schapira, M. (2010). Approximation Algorithms Combinatorial Auctions Complement-Free Bidders. Mathematics Operations Research,35 (1), 113.Grandoni, F., Krysta, P., Leonardi, S., & Ventre, C. (2014). Utilitarian Mechanism DesignMulti-Objective Optimization. SIAM Journal Computing, 43 (4), 12631290.Groves, T. (1973). Incentives Teams. Econometrica, 41 (4), 617631.Hastad, J. (1996). Clique Hard Approximate Within n1 . 37th Annual Symposium Foundations Computer Science (FOCS96), pp. 627636. IEEE ComputerSociety.Holzman, R., Kfir-Dahav, N. E., Monderer, D., & Tennenholtz, M. (2004). Bundling Equilibrium Combinatorial Auctions. Games Economic Behavior, 47 (1), 104123.Kapralov, M., Post, I., & Vondrak, J. (2013). Online Submodular Welfare Maximization:Greedy Optimal. Khanna, S. (Ed.), Proceedings Twenty-Fourth AnnualACM-SIAM Symposium Discrete Algorithms (SODA13), pp. 12161225. SIAM.Kelly, T. (2004). Generalized Knapsack Solvers Multi-Unit Combinatorial Auctions:Analysis Application Computational Resource Allocation. Faratin, P., &Rodrguez-Aguilar, J. A. (Eds.), Agent-Mediated Electronic Commerce VI, TheoriesEngineering Distributed Mechanisms Systems (AAMAS 2004 Workshop, AMEC 2004), Vol. 3435 LNCS.Khot, S., Lipton, R. J., Markakis, E., & Mehta, A. (2008). Inapproximability ResultsCombinatorial Auctions Submodular Utility Functions. Algorithmica, 52 (1),318.Kothari, A., Parkes, D. C., & Suri, S. (2005). Approximately-Strategyproof TractableMultiunit Auctions. Decision Support Systems, 39 (1), 105121.743fiKrysta, Telelis, & VentreLavi, R., & Swamy, C. (2011). Truthful Near-Optimal Mechanism Design via LinearProgramming. Journal ACM, 58 (6), 25.Lehmann, B., Lehmann, D. J., & Nisan, N. (2006). Combinatorial Auctions DecreasingMarginal Utilities. Games Economic Behavior, 55 (2), 270296.Lehmann, D., Muller, R., & Sandholm, T. (2010). Winner Determination Problem.Cramton, P., Shoham, Y., Smith, V. L., & Steinberg, R. (Eds.), CombinatorialAuctions. MIT Press.Lehmann, D. J., OCallaghan, L., & Shoham, Y. (2002). Truth Revelation ApproximatelyEfficient Combinatorial Auctions. Journal ACM, 49 (5), 577602.Milgrom, P. (2004). Putting Auction Theory Work. Cambridge University Press.Mirrokni, V. S., Schapira, M., & Vondrak, J. (2008). Tight Information-Theoretic lowerbounds Welfare Maximization Combinatorial Auctions. Proceedings 9thACM Conference Electronic Commerce (ACM EC), pp. 7077.Mualem, A., & Nisan, N. (2002). Truthful Approximation Mechanisms RestrictedCombinatorial Auctions. Dechter, R., & Sutton, R. S. (Eds.), ProceedingsEighteenth National Conference Artificial Intelligence Fourteenth ConferenceInnovative Applications Artificial Intelligence (AAAI/IAAI 2002), pp. 379384.AAAI Press / MIT Press.Mualem, A., & Nisan, N. (2008). Truthful Approximation Mechanisms RestrictedCombinatorial Auctions. Games Economic Behavior, 64 (2), 612631.Nisan, N. (2014). Algorithmic Mechanism Design, Lens Multi-Unit Auctions.Aumann, R., & Hart, S. (Eds.), Handbook Game Theory, Vol. IV. Elsevier NorthHolland.Nisan, N., & Ronen, A. (2007). Computationally Feasible VCG Mechanisms. JournalArtificial Intelligence Research, 29, 1947.Nisan, N., & Segal, I. (2006). Communication Requirements Efficient AllocationsSupporting Prices. Journal Economic Theory, 129 (1), 192224.Nisan, N., & Ronen, A. (2001). Algorithmic Mechanism Design. Games EconomicBehavior, 35 (1-2), 166196.Sandholm, T. (2010). Optimal Winner Determination Algorithms. Cramton, P., Shoham,Y., Smith, V. L., & Steinberg, R. (Eds.), Combinatorial Auctions. MIT Press.Vazirani, V. V. (2003). Approximation Algorithms. Springer-Verlag.Vickrey, W. (1961). Counterspeculation, Auctions, Competitive Sealed Tenders. Journal Finance, 16 (1), 837.Vocking, B. (2012). Universally Truthful Approximation Scheme Multi-Unit Auctions.Rabani, Y. (Ed.), Proceedings Twenty-Third Annual ACM-SIAM SymposiumDiscrete Algorithms (SODA12), pp. 846855. SIAM.744fiJournal Artificial Intelligence Research 53 (2015) 779-824Submitted 05/15; published 08/15Belief Change Uncertain Action HistoriesAaron Hunteraaron hunter@bcit.caBritish Columbia Institute TechnologyBurnaby, BC, CanadaJames P. Delgrandejim@cs.sfu.caSimon Fraser UniversityBurnaby, BC, CanadaAbstractconsider iterated belief change occurs following alternating sequenceactions observations. instant, agent beliefs actionsoccurred well beliefs resulting state world. representproblems sequence ranking functions, agent assigns quantitative plausibilityvalue every action every state point time. resulting formalism ablerepresent fallible belief, erroneous perception, exogenous actions, failed actions.illustrate framework generalization several existing approaches beliefchange, appropriately captures non-elementary interaction belief updatebelief revision.1. IntroductionMany formal approaches introduced reasoning belief change context actions observations (Jin & Thielscher, 2004; Shapiro, Pagnucco, Lesperance,& Levesque, 2011; Delgrande & Levesque, 2012). general, underlying assumptionagents perform belief update following actions belief revision following observations. Existing formalisms, part, treated actions observationsindependently, little explicit discussion interaction two.paper, consider belief change occurs due alternating sequence actionsobservations. interested action domains agent may erroneousbeliefs, state world well action history.Let K denote beliefs agent, given set possible worlds. 1 n,let Ai denote action let Oi denote observation. Informally, interestedsequences formK A1 O1(1)update operator revision operator. interpretationexpression flexible actions may understood represent actions executedparticular agent, may exogenous. Note sequences may containconflicting information. example, observation may possible followingactions A1 , . . . , . case, two options.1. Reject .2. Accept , modify A1 , . . . , .c2015AI Access Foundation. rights reserved.fiHunter & Delgrandeorder determine option preferable specific problem, agent needsable compare plausibility plausibility Ai .Expressions form (1) previously addressed, assumptionontic action histories infallible recent observations take precedence older observations (Hunter & Delgrande, 2011). Clearly, action domainsassumptions reasonable. paper, propose flexible approachactions observations represented Spohn-style ranking functions.take approach gives uniform treatment plausibility beliefs, observations, actions. presented conflicting information, agent simplycompare relative plausibility action observation; uniform representationevents makes straightforward determine plausible sequence. Moreover, quantitative plausibility values, encode variety distinct scenariosmanipulating magnitudes plausibility values alternative events.paper makes several contributions existing work epistemic action effects.main contribution formal mechanism reasoning incorrect weakly heldbeliefs related action histories. Existing formalisms generally unable compareplausibility action occurrence plausibility state world.problem because, practical reasoning problems, agents often put positioneither believe certain fact holds believe actionoccurred. using formal tool represent beliefs actions states,explicitly address manner prior action occurrences postulated retractedresponse new observations.second contribution work flexible treatment weak unreliable observations. revision operators incorporate new observation, obviousdesirable feature many reasoning domains. many cases, preferablediscard unreliable observation conflicts current, strongly held beliefs. However,approach simply allow unreliable observation discarded. Sinceuse ranking functions represent observations, observation also includes plausiblealternatives. such, observation actually provide evidence several differentstates, differing degrees. see useful representing observationsstates similar appearance. Similarly, ranking functions give natural representation addititive evidence, form observations must occur several timeschanging agents beliefs.formulate results simple transition system framework makestreatment action effects explicit easy compare elaborate actionformalisms. However, fundamental approach dealing uncertaintyactually require transition systems used action effects. intendmethodology described compete alternative formalisms representingepistemic action effects; rather, provide high-level approach dealing uncertainaction histories focuses specifically interaction actions observations.significant feature work demonstrates single representationplausibility used model iterated beliefs actions states simultaneously;basic approach could employed action formalisms. practical level,demonstrate utility work giving series examples involving belief changerelative weight given actions observations varies. suggest780fiBelief Change Uncertain Action Historieswork advances existing work reasoning epistemic action effects provideflexible, elaboration tolerant approach capturing several different kinds belief changeoccur uncertainty action occurrences. Note paperextended version work presented Hunter Delgrande (2006).proceed follows. Section 2, introduce formal preliminaries.define general class plausibility functions Section 3, show sequenceplausibility functions used represent uncertain sequence actionsobservations. refer sequence graded world view, demonstrateagents beliefs event histories captured graded world viewstaking aggregates constituent plausibility functions. Section 4, demonstrategraded world views seen epistemic states, use basic frameworkdefine belief change domains involving uncertainty actions observationsoccurred. compare approach related work Section 5,discuss limitations advantages Section 6. Section 7, offer concludingremarks.2. Preliminariessection, introduce standard formal machinery modelling belief change,reasoning action effects. also introduce simple motivating exampleillustrate sort problem would like address.2.1 Belief RevisionBelief revision refers process agent incorporates new information alongpre-existing beliefs. influential approach belief revision AGMapproach (Alchourron, Gardenfors, & Makinson, 1985). Let F denote finite set fluentsymbols, represent binary properties world may change time.example, may fluent symbol Raining F true case raining.state propositional interpretation F, indicating fluents truefalse. AGM approach belief revision, beliefs agent representedbelief set, deductively closed set formulas F. Since F finite,equivalently define beliefs agent represented single formula.Informally, belief revision operator function takes belief set formula revision input returns new formula represents new belief setincorporating . AGM revision operator binary function satisfies AGMpostulates. following reformulation AGM postulates due KatsunoMendelzon (1991). postulates, denotes logical equivalence.[R1][R2][R3][R4][R5][R6]implies .satisfiable, .satisfiable, satisfiable.1 2 1 2 , 1 1 2 2 .( ) implies ( ).( ) satisfiable, ( ) implies ( ) .781fiHunter & Delgrandeclass AGM revision operators captured semantically introducingformal notion plausibility. particular agent, say state worldplausible another state s0 agent likely abandon beliefs0 presented new information. turns every AGM revision operatorcharacterized class plausibility orderings set states.proved several different representations plausibility, including total pre-ordersstates (Katsuno & Mendelzon, 1991), systems spheres (Grove, 1988), ordinalconditional functions (Spohn, 1988).belief state set states, informally set states agent considerspossible. observation also set states, informally represents peiceinformation agent receives provides evidence actual state .paper, primarily interested belief change process states ratherformulas; clear AGM approach equivalently defined belief states.restricted set fluents set actions finite,really convenience discussing examples. formal model basedtransition systems ranking functions sets. would certainly possibledefine transition relations ranking functions infinite sets. Since definitionaggregate general, would introduce formal complications. However,point on, maintain restriction finite domains order simplifydiscussion.2.2 Transition Systemsinterested action domains described supplementing set Ffluent symbols finite set action symbols transition system describingeffects actions (Gelfond & Lifschitz, 1998). pair (F, A) called action signature.defined state interpretation F, often convenientidentify state set fluent symbols true s. use conventionfollowing definition, throughout rest paper.Definition 1 transition system pair hS, Ri 2F , R S.restrict attention deterministic transition systems, i.e. assume hs, A, s0 Rhs, A, s00 R implies s0 = s00 . also assume always contains distinguishednull action symbol denoted .Belief update belief change occurs agent becomes aware changestate world. Note distinct process belief revision,typically understood capture belief change occurs agent obtained new information unchanged world. One highly influential approachbelief update Katsuno-Mendelzon approach (Katsuno & Mendelzon, 1992),superficially similar AGM revision new information incorporatedencoded propositional formula. contrast, paper, define updaterespect action effects given underlying transition system. words,define belief update operators take belief state action input, returnnew belief state represents agents new beliefs action executed.782fiBelief Change Uncertain Action HistoriesDefinition 2 Let = hS, Ri transition system. update function : 2S 2Sgiven = {s | hs0 , A, si R s0 }.remark notion belief change also called belief progression actionprogression. Note possible general case result updateempty, case transition system include outgoing edge labelledstate . order avoid problem, often convenient restrict attentiontransition systems every action outcome every state. practice,achieved assuming self-loop action state outcomestate given.2.3 Belief Evolutionprevious work, introduced so-called belief evolution operators reason alternating sequences updates revisions (Hunter & Delgrande, 2011). belief evolutionoperator defined respect fixed AGM revision operator fixed updateoperator . action observation , let 1 (A) denote set{s} . Note set may empty. belief evolution operator definedthat, belief state ,hA, = ( 1 (A)) A.complete definition actually defines belief change sequence actionsobservations; details definition required present. importantpoint way observation incorporated depends preceding actions.intuition behind belief evolution final state must possible effectrecently executed action A. intuition satisfied original definitionrevising initial belief set prior computing effects A. result, belief evolutionoperators non-Markovian character; observation incorporatedconsidering current state world. Instead, agent incorporates new observationlooking back original state together complete history actions. However,operation also understood Markovian manner allow current beliefstate include representation states ruled basedactions previously occurred. manner, define Markovian formbelief revision equivalent belief evolution (Hunter, 2014).Belief evolution provides reasonable model problems like Moores litmus paperproblem (Moore, 1985). problem, agent dips piece litmus paper beakerdetermine beaker contains acid base. Hence, agent performingaction first observing results. seems, however, observed resultsaffect agents initial belief state. is, litmus paper turns red,agent likely conclude beaker contained acid even dipping.Belief evolution operators satisfy following properties. properties, A,denotes sequence action symbols indeterminate length, 2F denotes setstates F. symbols range 2F , though thinkbelief state think observation. Following standard conventionpostulates, implicitly quantify universally variables.783fiHunter & Delgrande1. (2F A) 6= , ( A)2. (2F A) = , ( A) =3. ( A) ( A)4. ( A) 6= , ( A) ( A)5. ( A) 2FInformally, properties assert agent respect history actions executed incorporating new observation. Note assuming AGMrevision operator, would appear make properties (1) (3) trivial. However,included properties belief evolution emphasize fact actionspreceding obervation need considered cases revision occurs (Hunter& Delgrande, 2011).One main limitations belief evolution possible representerroneous action histories; assumed action history always correct.reasonable assumption action domains single agent executing actionsfail. However, exogenous failed actions permitted, assumptiondifficult support. general, agent may incorrect beliefs actionsoccurred past. One aims paper generalize previous workallow erroneous action histories.2.4 Motivating Exampleintroduce common-sense example agent needs compare plausibilitycertain actions plausibility observations. return exampleperiodically introduce formal machinery.Consider simple action domain involving four agents: Bob, Alice, Eve, Trent. Bobplaces chocolate chip cookie desk leaves room; believes onelikely eat cookie gone. Time 1, Bob knows Alice desk.Time 2, Bob knows Eve desk. Eve leaves desk, Trent comestells Bob bite taken cookie.Given preceding information, Bob draw three reasonable conclusions: Alicebit cookie, Eve bit cookie, Trent gave poor information. Bobadditional information world, conclusion equally plausible. However,suppose Bob additional information. particular, supposeAlice close friend Bob shared cookies past. Moreover, supposeBob believes Trent always honest. Bobs additional information AliceTrent provides sufficient basis determining three possible conclusionsplausible.Informally, prior Trents report, Bob believes cookie unbittenearlier points time. Trent tells cookie bitten, must determineplausible world history consistent information. case, plausiblesolution conclude Alice bit cookie. Note conclusion requires Bobalter subjective view action history. non-monotonic character784fiBelief Change Uncertain Action Historiesbelief change context, Bob may forced postulate retract actionstime response new observations. consequences changing action historydetermined underlying transition system. order represent kindreasoning, need able compare plausibility action occurrences differentpoints time.example illustrates kind action scenario would like capture,requires agent determine plausible history given priorinotion plausibility actions observations. instance, intuitively clearproblem resolved without comparing plausibility Trents reportaccurate versus plausibility Alice biting cookie. addressing issuestraightforward manner, demonstrate existing actions formalisms extendedemployed handle similar situations.possibly one contentious issue discussion example. information provided Trent really observation usual sense word; instead,report information external source. However, sections follow,treat reports observations manner. Specifically, captureranking function states indicates states supportedobservation/report degree. course, reality, observations reportsquite different manner report incorporated depends trustreporting agent. relationship trust belief change topic currentinterest, generally handled introducing extra formal machinery encodetrust held another agent (Lorini, Jiang, & Perrussel, 2014; Hunter & Booth, 2015).would certainly possible follow approach present paper, using distinctformal tools capture trust phenomenon distinct perceived accuracysensing. However, mathematically, would like end single rankingstates nevertheless. such, present paper, convenient represent reported information single combined ranking captures final plausibilityattached state based considerations agent might make.3. Ranking Functions Actions Statesapproach presented paper based simple notion: agent uncertainaction observation, resolving uncertainty generally involves comparingrelative likelihood possible alternatives. work distinguished factuse sequences ranking functions represent uncertainty actions states.see sequences ranking functions capture many natural reasoning problems.developing high-level representations problems, see notionmagnitude likelihood useful reasoning belief change uncertain actionhistories. allows us compare work existing formalisms reasoningepistemic action effects, particularly representation uncertaintylimited orderings states. fundamental goal demonstrate that,cases, sequences quantitative plausibility orderings expressive advantagesignificant perspective knowledge representation. aim developapproach high-level, manner easily translated actionformalisms.785fiHunter & Delgrande3.1 Plausibility Functionsinterested action domains agents beliefs action history mayincorrect. context, action believed executed given pointtime represented total pre-order possible actions. minimal elementspre-order represent actions likely executed, moving higherordering gives increasingly implausible possibilities. Representing actionsmanner allows agent determine plausible alternative actions face conflictingevidence. Similarly, agent needs mechanism ordering states order representfallible observations fallible beliefs. Moreover, would like able compareorderings actions orderings states. One natural way create mutuallycomparable orderings assigning quantitative plausibility values every actionstate every point time. Towards end, define plausibility functions.Definition 3 Let X non-empty set. plausibility function X functionr : X N.r plausibility function r(x) r(y), say x least plausibley. interested plausibility functions finite sets, alwaysnon-empty set minimally ranked elements.Plausibility functions inspired Spohns ordinal conditional functions (Spohn,1988), important differences. First, allow plausibility functionsarbitrary set X, rather restricting attention propositional interpretations.allows us treat actions manner treat observations. Anotherimportant difference ordinal conditional functions must always assign rank 0non-empty subset elements domain. Plausibility functions restrictedmanner; minimal rank given plausibility function may greater 0.defined plausibility functions manner interested taking sumsplausibility functions, need ensure sums also define plausibilityfunctions.remark Darwiche Pearl also consider ranking functions necessarily assign rank 0 states (Darwiche & Pearl, 1997). However, Darwiche Pearldefine belief state associated r set states assigned rank 0.convention, ranking functions never assign rank 0 associatedempty belief state. contrast, associate non-empty belief state every plausibilityfunction.introduce useful terminology notation. Let r plausibility functionX. minimum maximum values obtained r denoted minr maxr ,respectively. define Bel(r) set {s | r(s) = minr }. notation intendedsuggest Bel(r) set actions states believed. clear,say state believed, mean far agent concerned, actual worldcould described s. hand, say action believed,mean agent views action executed. Note minr alwaysdefined, non-empty set natural numbers minimum element.hand, maxr guaranteed defined X finite. However,concerned plausibility functions states actions; finite setsaccording original definitions.786fiBelief Change Uncertain Action HistoriesX, define r() minimum value obtained r .degree strength plausibility function r least n minr +n = r(s)6 Bel(r). Hence, degree strength r span plausibilityminimally ranked elements non-minimally ranked elements. r degreestrength n, means every 6 Bel(r) plausibility value least nhigher r(Bel(r)). two natural interpretations degree strengthplausibility function r set states. think r initial epistemic state,degree strength indication strongly believed actual stateBel(r). think r observation, degree strength measuresubjective reliability r. case X set states, use termsdegree strength degree belief interchangeably.notion degree strength crucial importance approach. usetotal pre-order represent plausibility, really corresponding notionstrength distinguish situation plausible belief strongly heldversus one weakly held. kind distinction essentialsort sequence events; need notion strength belief decidestate action hardest give up. possible represent kind informationordering empty levels, course. However, focus aggregatingsequences belief states actions. order make simple possible, suggestbetter use compact representation given quantitative ranking functionlends naturally arithmetical combinations.Note Spohn (1988) defines degree strength subset X, ratherdegree strength ranking function. definition coincides Spohns definitionidentify degree strength r Spohns degree strength set Bel(r).Hence, use conception degree strength, interestedstrength belief minimally ranked elements.order illustrate application plausibility functions different domains,continue simple example.Example (contd) Let F = {B iteT aken} let = {B iteAlice, BiteEve}.actions effect, namely make fluent B iteT aken become true.represent problem 3 plausibility functions: a1 , a2 , o2 .1. a1 plausibility function actions Time 12. a2 plausibility function actions Time 23. o2 plausibility function states Time 2Informally, function obtain minimum value event Bob considersplausible given point time. Since Bob initially believes oneeat cookie, a1 a2 obtain minimum value null action . Trentsreport cookie bitten Time 2 represented plausibility functionstates, defining o2 minimum set worlds cookie biteit. Note generally treat reported information manner; degreestrength report indication trust agent providing report.787fiHunter & Delgrandeadditional soft constraints Bobs relationships used determine magnitudevalues event. Define a1 a2 values following table.a1a200B iteAlice110B iteEve103columns table give plausibilities action time. particular,a1 encodes plausibility occurs 0, whereas plausibility B iteAliceB iteEve 1 10, respectively. degree strength a1 1, whereas degreestrength a2 3. fact Alice likely bite cookie representedassigning low plausibility value B iteAlice Time 1.define o2 follows, give plausibility values states time 2.o29{B iteT aken}0Hence, observation {B iteT aken} assigned minimum plausibility value,alternative observation assigned high plausibility value. degreestrength o2 9. reflects fact Trents report understood strongerassumption Alice Eve bite cookie.Note degree strength a1 less degree strength a2 o2 .gives indication Bob comparatively less confidence beliefsaction Time 1.Note that, example, explicitly referred points time. not,however, include formal representation time framework; referencetime interpreted informal explanatory device. concernedreasoning scenarios involve sequences actions action instantanenous, actions executed consecutively. Nevertheless, since allow observationsfollowing null actions, imagine actions executed accordancebounded global clock allows one action per tick.3.2 Graded World Viewsdefine graded world view alternating sequence plausibility functions2F plausibility functions A. Hence, time i, use plausibility function2F represent agents beliefs state world use plausibilityfunction represent agents beliefs action occurs. Informally,graded world view represents agents subjective view evolution worldcontext imperfectly known action histories. rationale behind using sequenceranking functions eventually make possible compare likelihood actionsobservations different points sequence, arrive plausible sequenceevents. following formal definition.Definition 4 graded world view length n (2n + 1)-tuplehOBS0 , ACT1 , OBS1 , . . . , ACTn , OBSn788fiBelief Change Uncertain Action HistoriesOBSi plausibility function 2F ACTi plausibility functionA.time i, plausible actions minimally ranked actions ACTiplausible states minimally ranked states OBSi . take OBS0 represent initial belief state, subsequent OBSi represent new observation.ACT = hACT1 , . . . , ACTn OBS = hOBS0 , . . . , OBSn i, write hACT, OBSishorthand graded world view hOBS0 , ACT1 , OBS1 , . . . , ACTn , OBSn i. Informally, graded world view represents agents subjective view history actionsobservations.remark briefly intuition behind graded world views. interestedaction domains involving actions partially observable fallible. However,moment consider failed actions; address issue briefly 4.6.plausibility action represents agents confidence successfully executedgiven instant. Hence, lowest plausibility values assigned actionsagent executed, actions agent observed directly. Higher plausibilityvalues assigned exogenous actions assumed unlikely, actionoccurrences believed based external reports. 3.4, provideadditional motivation plausibility values illustrating correspondence subjectiveprobability functions.Note graded world views essentially represent initial belief state observation time 0. underlying assumption graded world view initial beliefstate different subsequent observation; reason automaticallyprefer initial beliefs new information, reason automaticallydisregard initial beliefs given new information. definition graded world view,used indices manner symmetric order emphasize uniquestature OBS0 . particular, note ACT0 definition. simplenotational convention intended highlight fact OBS0 slightly differentstature informal level.3.3 Aggregate Plausibility FunctionsGiven graded world view hACT, OBSi, would like able determineplausible history world. formally define notion history transitionsystem.Definition 5 Let = hS, Ri transition system. history length n tuplehs0 , A1 , . . . , , sn i:1. si S,2. Ai A,3. hsi , Ai+1 , si+1 R.Let HISTn denote set histories length n.Note HISTn (A S)n . Ideally, would like use graded world viewsassign plausibility values histories. However, graded world view provide789fiHunter & Delgrandesufficient information define unique plausibility function histories. example,graded world view indicate relative weight recent information versus initialinformation. order determine plausible history, need mechanismcombining sequence plausibility functions.Although graded world view define unique plausibility function histories, define general notion consistency graded world views plausibility functions histories. Let r0 , . . . , rn plausibility functions X0 , . . . , Xn ,respectively. Let r plausibility function X0 Xn . say r consistenthr0 , . . . , rn if, every every xi , x0i Xiri (xi ) < ri (x0i )r(hx0 , . . . , xi , . . . , xn i) < r(hx0 , . . . , x0i , . . . , xn i)r consistent hACT, OBSi case r increases monotonically respectcomponent hACT, OBSi. plausibility function r consistenthACT, OBSi provides potential candidate ranking histories.Define aggregate plausibility function function maps every graded worldview length n plausibility function HISTn . interested aggregateplausibility functions output always consistent input. Hence,say aggregate plausibility function agg admissible if, every hACT, OBSi,function agg(hACT, OBSi) consistent hACT, OBSi.provide examples. Note aggregate plausibility functions return functionvalue; specify behaviour aggregate specifying plausibility valuepair consisting graded world view history. Let h = hs0 , A1 , . . . , , sn i.One admissible aggregate obtained taking sum plausibility values.sum(hACT, OBSi)(h) =nXACTi (Ai ) +i=1nXOBSi (si )i=0weighted sum used reflect relative importance different time points.i, let bi positive integer.sums (hACT, OBSi)(h) =nXACTi (Ai ) +i=1nXbi OBSi (si ).i=0setting bi = 2i , aggregate function sums used represent strict preferencerecent observations. standard assumption many approaches belief revision.could add similar weight action histories well, would give anotherdistinct aggregate. functions sum sums two simple examples; manyexamples defined specifying aggregate functions increase monotonicallycomponent.return cookie example illustrate reasoning involved capturedgraded world views aggregate plausibility functions.Example (contd) already defined plausibility functions a1 , a2 o2 . ordergive complete graded world view, need define two plausibility functions790fiBelief Change Uncertain Action Historiesstates. particular, need give plausibility function o0 representing Bobs initialbeliefs need give plausibility function o1 representing null observationBob makes Time 1.First, reiterate description a1 a2 following table.a1a200B iteAlice110B iteEve103fact Alice likely bite cookie represented assigning lowerplausibility value B iteAlice Time 1.plausibility function o0 assign minimum value state cookieunbitten. plausibility function o1 assign value every state.plausibility function o2 (given previously) represents Trents report cookiebitten. noted previously, treat reported information observation, usedegree strength reported information indication reliabilitysource. case, degree strength o2 indication trust Trent. defineo0 , o1 , o2 next table.o0o1o2009{B iteT aken}900Note degree strength o2 higher degree strength a1 a2 .reflects fact Trents report understood supersede assumptionAlice Eve bite cookie. Graded world views defined preciselykind comparison action plausibilities state plausibilities.use aggregate function sum, interested finding minimal sumplausibilities ho0 , a1 , o1 , a2 , o2 i. inspection, find minimum plausibilityobtained following history:h = h, B iteAlice, B iteT aken, , B iteT akeni.history represents sequence events Alice bites cookie time 1.Intuitively, correct solution: given choice Alice Eve, Bob believesAlice plausible culprit.remark graded world views bear resemblance generalized belief changeframework proposed Liberatore Schaerf (2000). However, Liberatore-Schaerfapproach associates penalty state change, minimized determiningplausible models. such, difficult represent problems non-null actionsstrictly plausible null actions. contrast, graded world views implicitpreference null actions. Moreover, approach differs allow actionsconditional effects given transition system.791fiHunter & Delgrande3.4 Subjective ProbabilitiesOne issue arises definition graded world view fact clearplausibility values assigned practical problems. address problemillustrating correspondence plausibility functions probability functions.simplify discussion restricting attention rational-valued probability functionsfollows.Definition 6 Let X non-empty set. probability function X functionP r : X Qx X, 0 P r(x) 1PxX P r(x) = 1.need axioms probability theory present purposes.common-sense level, clear means say action occurred timeprobability p. contrast, problem plausibility values obvioussense scale; difficult assign numerical plausibility values, numbersclear meaning. illustrate probability functions translated uniformlyplausibility functions, thereby giving sense scale meaning plausibility values.Let P r probability function finite set X. Let Q denote least commondenominator rational numbers pq P r(x) = pq x X. Defineplausibility function r follows.1. P r(x) minimal, set r(x) = Q.2. Otherwise, P r(x) =pQ,set r(x) = Q p.Hence, every probability function translated plausibility function.Example (contd) Consider following probability functions cookie example.P ra1P ra2.5.5B iteAlice.45.15B iteEve.05.35.9.5.1P ro0P ro1P ro2{B iteT aken}.1.5.9corresponding plausibility functions given following tables.a01a021010B iteAlice1120B iteEve2013o00o01o021210{B iteT aken}1021easy see plausibility functions obtained plausibilityfunctions given earlier adding constant value. 4.2, illustrate addingconstant manner affect class minimally ranked histories.Connecting plausibility functions subjective probabilities provides justification use aggregate function sum. particular, assume subjective792fiBelief Change Uncertain Action Historiesprobability functions independent, probability given sequence eventsdetermined taking product. cookie example, compare probabilityAlice biting cookie versus Eve biting cookie:1. P r(h, B iteAlice, B iteT aken, , B iteT akeni)= .9 .45 .5 .5 .9 = .0911252. P r(h, , , B iteEve, B iteT akeni)= .9 .5 .5 .35 .9 = .070875easy check history Alice bites cookie actually probable history. So, example, minimally ranked history according aggregatefunction sum also probable history according sequence probabilityfunctions. general property translation: maximizing probability independent probability functions corresponds minimizing sum plausibility values.follows simply fact probable events assigned minimal plausibility values, fact summation natural numbers increasingfunction, whereas multiplication fractions less 1 decreasing.correspondence descibed section relies assumption sequencesactions independent. worth noting, however, often casepractice. Instead, often case actions occur sequences cleardependence individual actions. However, concern present.reason considering probability functions provide intuition motivationway plausibility values assigned.3.5 Summation Conventionorder ground discussion, useful choose fixed aggregate function assigning plausibility values histories. such, unless otherwise indicated, assumeplausibility values assigned histories aggregate function sum. Althoughapproach combining plausibility functions, provides simple admissible aggregate function appropriate many cases. particular, sawprevious section sum appropriate domains plausibility functionsobtained independent subjective probabilities.introduce notation simplify results next sections.Recall sum(hACT, OBSi) plausibility function histories. underlyinggraded world view clear context, write plaus(h) shorthandsum(hACT, OBSi)(h).useful introduce operator maps graded world view plausiblehistories.Definition 7 Let W Vn denote set graded world views length n fixed actionsignature. Define : W Vn 2HISTn follows:(hACT, OBSi) = {h | plaus(h) plaus(g) g HISTn }.following obvious equivalence(hACT, OBSi) = Bel(sum(hACT, OBSi)).793fiHunter & Delgrandealso useful use plaus define plausibility function states.Definition 8 Let hACT, OBSi graded world view. state s, defineplaus state(hACT, OBSi)(s)least n plaus(hACT, OBSi)(h) = n history h final states.plausibility state rank plausible history ending s.underlying graded world view clear context, simply write plaus state(s)plausibility state s. extend operator Bel() graded world viewsdefining Bel(hACT, OBSi) Bel(plaus state(hACT, OBSi)). Hence, Bel takesgraded world view argument returns plausible set terminal states.3.6 Uniform Representationconsidering applications formal results, briefly discuss novelsignificant features approach. notion plausibility relation theorychange explored extensively literature. Work nonmonotonic consequenceoperators, example, informed notions preferred models (Kraus, Lehmann,& Magidor, 1990) conditional knowledge (Lehmann & Magidor, 1992). alsogreat deal research different representations plausibility, ranging orderings (Baltag & Smets, 2006, 2008; Britz & Varzinczak, 2013), quantitative approachespossibility (Benferhat, Dubois, & Prade, 1999), variations probabilistic models(Friedman & Halpern, 2001). take moment position work context.stated several times, sets work apart applynotion plausibility uniformly states actions. contrasts existingwork, model plausibility used representing initial beliefs, actionshandled different formal machinery. many cases, actions atomic; beliefchange due action concerned complicated plausibility structure changesresponse distinct action occurence.model, action occurrence another plausibility function. severaladvantages, show next sections. First, allows us easily comparestrength belief state strength belief action occurence. example,believe lamp also believe toggled switch: believe?Situations form common, require comparison two differentforms likelihood. general, natural logical aparatus help resolveproblem; need extra-logical information belief stronger, beliefstate belief action. natural intuition actually needgiven rankings make determination; exactly here.second advantage using uniform representation plausibility actionsallows us consider alternative actions. Looking literature belief changepreferential models, clear actually need orderings states orderperform many kinds reasoning. reason need orderings needable specify best alternatives things believed true. arguetrue actions. find action occur, need794fiBelief Change Uncertain Action Historiesmechanism determining next best alternative. see nextsection many practical examples important, examplescaptured straightforward way plausibility functions.tempting look model try position contextalternative models plausibility, argue best way lookwork. fact, could propose approach similar one paper basedsequences probability functions suitable aggregates. fact usingSpohn-style ranking functions particular important point.important using measure plausibility uniformly observationsactions, plausibility measure feature differences plausibilitymagnitude. allows us determine alternatives current beliefsstates actions abandoned, appeal single notionmagnitude determine notion minimal change.4. Using Graded World Viewssection, consider basic approach one use try findminimally ranked history.4.1 Pointwise MinimaLet W = hACT, OBSi graded world viewACT = hACT1 , . . . , ACTnOBS = hOBS0 , . . . , OBSn i.easiest way determine minimally ranked history simply take plausibleactions plausible worlds point time. following definition makesnotion precise.Definition 9 Given history h = hs0 , A1 , . . . , , sn i, say h pointwise minimumhACT, OBSi if, i,1. A, ACTi (Ai ) ACTi (A),2. 2F , OBSi (si ) OBSi (s).following proposition states that, graded world view pointwise minima,plausible histories.Proposition 1 Let W = hACT, OBSi graded world view let setpointwise minima W . 6= , (W ) = .Proof sufficient note that, h , plaus(h) plaus(g) histories g.Note, however, histories restricted world must outcomepreceding action. such, possible graded world view pointwiseminimum. preceding proposition starts assumption set795fiHunter & Delgrandepointwise minima non-empty. cases pointwise minima,still minimally plausible histories.Finding pointwise minima easy general case.Proposition 2 Determining graded world view pointwise minimum N P complete.Proof Given history, clear checking pointwise minimumdone linear time; problem lies N P . Assume fixed set F fluent symbols.Let W = hACT, OBSi OBS length 2|F| , assume OBSi obtainsminimum distinct interpretation F. pointwise minimum W correspondHamiltonian path underlying transition system. result follows since findingHamiltonian path NP-complete.fact already intractable find pointwise minimum suggests findingminimal histories complicated aggregate function likely computationallydifficult. major concern present purposes however, view gradedworld views high-level tool capture variety belief change scenarios. oneinterested modelling concrete action domains, important choose aggregatefunctions well understood computationally easy minimize.4.2 EquivalenceClearly possible two distinct graded world views set minimallyranked world histories. fact, possible two distinct graded world views inducepreference ordering histories. section, define natural equivalencerelation graded world views eye towards categorical representations. startdefining relation plausibility functions.Definition 10 Let r1 r2 plausibility functions set X. say r1= r2if, every x, X,r1 (x) r1 (y) = r2 (x) r2 (y).easy verify following:= equivalence relation, r1 r2 degreestrength, r1rimpliesBel(r1 ) = Bel(r2 ). Essentially, difference= 2equivalent plausibility functions minimum value; make ideaprecise defining notion normalization plausibility functions.Let r plausibility function. integer z minr , translation rz plausibility function x 7 r(x) + z. easy prove r= r00r translation r. define normalization r translation minr .normalization r unique plausibility function equivalent r obtainsminimum 0.extend notion equivalence graded world views.Definition 11 Let W1 W2 graded world views histories fixed action signature given underlying transition system. say W1= W2 if, every pairhistories g h,sum(W1 )(g) sum(W1 )(h) = sum(W2 )(g) sum(W2 )(h).796fiBelief Change Uncertain Action HistoriesUnlike plausibility functions, possible construct equivalent pairs graded worldviews obtained translations.following proposition illustrates every graded world view equivalentgraded world view consisting normalized plausibility functions.Proposition 3 Let hACT, OBSi graded world view. hACT 0 , OBS 0 obtainednormalizing component ACT OBS,hACT, OBSi= hACT 0 , OBS 0 i.ProofLet g, h histories. ease readability, let plaus1 plaus2 denotesum(hACT, OBSi) sum(hACT 0 , OBS 0 i), respectively. Hence, plaus1 plaus2functions histories, obtained minimization total sum. such, plaus1plaus2 must minimum value, corresponding lowest possible sumterms. following equalities immediate:plaus2 (g) plaus2 (h) = plaus1 (g) min plaus1 (h) + minplaus1plaus1= plaus1 (g) plaus1 (h).Hence, although allow plausibility functions minimum values larger 0graded world view, always pass equivalent graded world view consistingnormalized plausibility functions. remark, however, graded world view definedsequence normalized plausibility functions need obtain minimum 0.case, minimum 0 graded world view pointwise minimum.also important note Proposition 3 holds aggregate plausibilityfunction sum.4.3 Representing Belief StatesPlausibility functions defined simply pick distinguished set elementsdomain. X c integer, let c denote function X setintegers defined follows:0c (s) =c otherwisec positive integer, c denotes plausibility function elementsplausible, everything else equally implausible. Plausibility functionsform c called simple. X set states, simple plausibility functionscorrespond belief states; X set actions, simple plausibility functions pickactions believed occurred. Using terminology introduced earlier,say held degree belief c.c > 0, c actually define plausibility function. However, allowingnegative values leads simple symmetry notation. following proposition,denotes complement set difference. set states, = 2F .797fiHunter & DelgrandeProposition 4 set positive integer cc= c.Proof Let s, states. definition,, 6cc 6 ,c (s) c (t) =0otherwise.(c)cc (s) c (t) =06 ,, 6otherwise.Clearly, right hand sides equality same.SupposeACT = hACT1 , . . . , ACTnOBS = hOBS0 , . . . , OBSnACTi OBSi simple, maximum plausibility c. meansACTi OBSi assigns either value 1 value c every elementrespective domains. case, essentially belief states plausibilityordering. case, easy showhs0 , A1 , . . . , , sn (hACT, OBSi)cardinality{Ai | Ai ACTi } {si | si OBSi }maximal among histories. words, plausible historiesagree hACT, OBSi highest number components. reasonableapproach take trivial case prior ranking states actions.emphasize special case plausibility functions simpleshare degree strength. next section, define belief changeoperations terms general concatenation plausibility functions. restrictplausiblity functions here, get much wider range possible beliefchange operations.4.4 Graded World Views Epistemic Statesepistemic state representation agents belief state defines total pre-orderstates (Darwiche & Pearl, 1997). t, underlying agent believeslikely actual state world t. current beliefstate given set -minimal states. Recall also graded world view defines798fiBelief Change Uncertain Action Historiesplausibility function plaus state states. graded world view clearly definesordering states, think graded world view defining epistemicstate. worlds receive minimal rank graded world view worldssupported reliable observations actions. Using ranking defineplausibility ordering tantamount assuming plausibility completelydetermined reliability source reporting occurs.viewing graded world views epistemic states, define belief change operationsfamiliar manner. particular, define belief change simpleconcatenation operator graded world views. Given sequence plausibility functionsr = hr1 , . . . , rn plausibility function r, let r r denote sequence hr1 , . . . , rn , ri.Let hACT, OBSi graded world view, let rA plausibility function actionslet rS plausibility function states. Define follows:hACT, OBSi hrA , rS = hACT rA , OBS rS i.context initial epistemic state given hACT, OBSi, representsagents priori beliefs history observed actions states. New actionsobservations incorporated simply concatenating new plausibility functionsinitial graded world view. new graded world view used define newordering histories aggregate function. example, using sumdefault aggregate, new ordering immediate. Note new graded world viewobtained manner also includes historical information required future beliefchange. special case simple concatenation operation, get new approachupdate. set X, let 0 denote plausibility function uniformly assigns 0every element X. identify update hACT, OBSi rA followingoperation:hACT, OBSi hrA , 0i.also define natural approach revision manner. Let null denoteplausibility function assigns plausibility 0 null action , assigns everythingelse plausibility larger maximum value obtained sum(hACT, OBSi).identify revision hACT, OBSi rS following operation:hACT, OBSi hnull, rS i.Using plausibility functions represent observations allows us represent naturalproblem domains easily represented restrict observations setspossible worlds. particular, consider action domain observationsvarying degrees reliability. domains, agent makes observationinconsistent current belief state, two factors considered:strength belief current belief state reliability observation.obvious conflict arises attempt address factors simultaneously.example, suppose underlying agent strongly believes possible stateworld. suppose agent makes two observations.1. One observation suggests possible, comes unreliable source.799fiHunter & Delgrande2. Another observation suggests possible, comes reliablesource.difficult determine appropriate belief change scenario, particularlystrength belief observational reliability treated independently. quantifyingreliability every observation, graded world views make easy resolve kindissue. remark problems form also addressed useprioritized merging operators (Delgrande, Dubois, & Lang, 2006).Note asymmetry definition revision updateoperator. case update, assume final observation assignsplausibility every state. symmetric definition single observation woulddefined follows:hACT, OBSi h0, rS i.However, definition allows arbitrary action occur immediately observation. want assume graded world view hACT, OBSi gives complete pictureworld time observation, need assume intermediaryaction null. Hence, asymmetry due significant difference actionsobservations; asymmetry simply due fact graded world views involvealternating sequences actions observations, actions occurring first default.section illustrated graded world view defines epistemic state.take epistemic state total pre-order states, converse clearlyfalse: ordering states provide enough information define numerical rankingfunctions states. move epistemic states graded world views motivatedkind concern motivates move belief states epistemic states.particular, belief states AGM revision understood represent minimalelements ordering states. Hence, belief state provide partial descriptionordering, ordering turn provide partial description graded worldview. belief state sufficient single-shot revision, provided ordering implicitrevision operator. However, belief state sufficient need explicitlyreason way plausibility orderings modified. Similarly, orderings statessufficient reasoning preferences states, sufficient needexplicitly reason action histories. next section, clarify pointpractical examples.4.5 Representing Natural Action Domainsillustrate interesting phenomena represented graded world views.simplest examples involve graded world views length 1. particular, initiallyfocus graded world views formhIN hrA , rS i.context, represents initial belief state agent, rA represents agentsbeliefs action executed, rS represents observed stateworld. Previously used OBS0 initial plausibility function states;change notation emphasize priori initial ordering800fiBelief Change Uncertain Action Historiesstates. clear, , rA , rS plausibility functions. such,define degree strength each. facilitate exposition, denote degreesstrength deg(IN ), deg(rA ), deg(rS ) respectively. Varying magnitudesvalues allows us capture several different underlying assumptions.1. Fallible initial beliefs: deg(IN ) < deg(rA ) deg(IN ) < deg(rS ).2. Erroneous perception: deg(rS ) < deg(IN ) deg(rS ) < deg(rA ).3. Fallible action history: deg(rA ) < deg(IN ) deg(rA ) < deg(rS ).simple example, suppose agent believes certain lamp initially on,power switch toggled, agent observes lamp actually stillon. Clearly sequence events consistently believed rational agent.Manipulating degrees strength , rA rS gives agent mechanismresolving conflicts. case (1), agent completely certain lampinitially on. such, easiest way incorporate new information changeinitial belief state. contrast, case (2), agent completely certainlamp still toggling switch. case, since agent confidentlamp initially switch toggled, natural reject observationbelieve lamp off. distinction two cases cannotcaptured without notion reliability. case (3), agent would resolve conflictbelieving attempt toggle power switch failed.special case degree strength 0 also captures importantphenomena. Note plausibility function r degree strength 0 caseconstant c r(x) = c x. such, degree 0 indicates everyelement domain receives minimal rank. consider informal interpretationdegree 0 plausibility function schematic example.1. deg(IN ) = 0, every initial state equally plausible. agentcontingent priori beliefs state world.2. deg(rO ) = 0, rO represents null observation. observation OBSprovide evidence particular state.3. deg(rA ) = 0, every action equally likely. agent completely ignorantaction occurred, think rA exogenous actionbeyond agents control.relatively crude distinctions, still capture important classes problems.Roughly speaking, problems addressed thus far capturedplausibility ordering sequences formA1 1 nbelief state, Ai action symbol, observation.purpose comparison, remark belief evolution operators definedSection 2.3 useful problems underlying plausibility ordering801fiHunter & Delgrandegiven follows, permutation p1 , . . . , pn 1, . . . , n.A1... p1 p2 pncontrast, graded world views suitable total pre-order A1 , 1 , . . . , , n .entire class problems representable graded world views. usingranking function event, able draw two additional distinctionsrepresented simple ordering. First, able represent changes plausibilityaffect ordering states. useful representing action domainsagent must observe single piece evidence multiple times believingcorrect. Second, able represent graded evidence; use term graded evidencedescribe situations observation actually supports several different conclusionsdifferent degrees confidence. conclude section two examples illustratingaction domains difficult represent ordering plausibilityevents.Example (Additive Evidence) Bob believes turned lamp office,completely certain. leaving building, talks first AliceEve. Alice tells lamp still on, believe mistaken.Similarly, Eve tells lamp still on, believe mistaken.However, Alice Eve tell Bob lamp still on, believefact still on.example easily represented graded world view follows. assumeunderlying action signature contains, among others, fluent symbol LampOnaction symbol urnLampOff . underlying transition system defines effectsturning lamp obvious manner. Let denote set statesLampOn true. following plausibility functions define graded world viewrepresents action domain.1. OBS0 = 102. ACT1 = {T urnLampOff } 33. OBS1 = 24. ACT2 = 105. OBS2 = 2Note (hOBS0 , ACT1 , OBS1 i) consists histories lamp turnedtime 1. However, (hOBS0 , ACT1 , OBS1 , ACT2 , OBS2 i) consists historieslamp turned time 1. Two observations required make Bob believeturn lamp off.Example (Graded Evidence) Bob receives gift estimates worth approximately $7. curious price, tries glance quickly receipt without802fiBelief Change Uncertain Action Historiesanyone noticing. believes receipt says price $3. far lowbelievable, Bob concludes must mis-read receipt. Since 3 lookssimilar 8, concludes price receipt must actually $8.represent example, first define ACT1 = 10 Bob believes ontic actions occurred. assume fluent symbols Cost1, Cost2, . . . , Cost9interpreted represent cost gift. define plausibility function OBS0 representing Bobs initial beliefs.0 = {Cost7}1 = {Cost6} = {Cost8}OBS0 (s) =3 otherwiseNote Bob initially believes cost $7, comparatively plausiblecost one dollar less. Finally, define plausibility function OBS1 representingobservation receipt.0 = {Cost3}1 = {Cost8}OBS1 (s) =3 otherwiseBob believes observed digit likely 3, plausible alternative visually similar digit 8.Given plausibility functions, plausible state world stateprice $8. order draw conclusion, Bob needs observations providegraded evidence states world needs able weight informationinitial beliefs.preceding examples illustrate natural common-sense reasoning problems agent needs consider aggregate plausibilities sequence actionsobservations. Graded world views well-suited reasoning problems.4.6 Non-deterministic Failed Actionssection, consider actions non-deterministic effects. remark, particular,fallible actions understood actions non-deterministic effects; fallibleactions actions possible outcomes considered failures.simplest case, example, failed action might one leaves state worldunchanged. Hence, addressing non-deterministic effects, also handling actionsmight fail. basic approach following. introduce new machineryrepresentation non-deterministic actions, demonstrate newmachinery unnecessary use summation determine plausibility histories.such, reasonably restrict attention deterministic actions proving formalexpressibility results graded world views.Given non-deterministic transition system = hS, Ri graded world view W ,clear choose effects action plausible worldhistories. problem solved attaching plausibility value possible effectsaction (Boutilier, 1995). action state s, let EF F (A, s) denote803fiHunter & Delgrandeset states s0 (s, A, s0 ) R. Hence EF F (A, s) set states mayresult, given action executed state s.Definition 12 effect ranking function function maps every action-state pair(A, s) plausibility function EF F (A, s).Informally, effect ranking function gives plausibility possible effectaction. instance, want model coin flipping action, corresponding effectranking function would constant: outcomes coin flip would consideredequally plausible.non-deterministic graded world view pair hW, W graded world vieweffect ranking function. illustrate example.Example Consider action domain involving single fluent symbol LampOn indicatingwhether certain lamp turned on. two action symbols P resshrowP aper respectively representing acts pressing light switch, throwingball paper light switch. Informally, throwing ball paper light switchlikely turn lamp. suppose agent reason believepiece paper thrown lamp and, moreover, lamp turned on.illustrate non-deterministic graded world views provide representationproblem.actions non-deterministic effects may cause LampOn becometrue, may also fail so. define graded world view hACT, OBSi length1. First, define ACT hrowP aper likely action time 1.ACT110P ress2hrowP aper1Next define OBS initially light off, light on.OBS0OBS1100LampOn010Finally, define effect ranking function represents fact pressinglikely turn light on.(P ress, {LampOn})(P ress, )(T hrowP aper, {LampOn})(T hrowP aper, )01090{LampOn}10009Lines 1 2 table indicate pressing switch likely changestate lamp. Lines 3 4 indicate throwing paper switch likely804fiBelief Change Uncertain Action Historieseffect, change caused paper ball seen plausiblefailed effect button pressed.preceding example, two possible solutions: either plausible event occursunlikely outcome, less plausible event occurs expected outcome.priori preference given occurrence plausibilities effect plausibilities;framework flexible enough represent either possibility.Introducing effect ranking functions makes distinction action occurrencesaction effects explicit, turn gives straightforward treatment failed actions. However, need introduce extra machinery order determineplausible action history. general approach extend definitionaggregate plausibility function: non-deterministic aggregate plausibility function takesnon-deterministic graded world view argument, returns plausibility functionhistories. admissible non-deterministic aggregate plausibility function oneincreases monotonically respect given graded world view, well giveneffect ranking function.using function sum standard aggregate plausibility function.natural extension sum non-deterministic graded world views following.history h = s0 , A1 , . . . , , sn , defineXsum(hACT, OBSi, )(h) =OBSi (si ) + ACTi (Ai ) + (Ai , si1 )(si ).easy see admissible non-deterministic aggregate function. Returninglamp example, two minimally ranked histories function: onelamp turned pressing switch one lampturned throwing piece paper switch.remainder section, assume sum default aggregatefunction non-deterministic world views. assumption, demonstratenon-deterministic graded world views translated graded world viewsextended action signature.Let = hS, Ri non-deterministic transition system action signature hA, Fi.Let hhACT, OBSi, non-deterministic graded world view. extend actionsignature new action signature A0 every edge corresponds uniqueaction symbol. particular, let A0 = {A(s,A,t) | (s, A, t) R}. Let 0 = hS, R0 R0closure set {hs, A(s,A,t) , ti | s, S}. Suppose ACT = ACT1 , . . . , ACTn .Define ACT 0 = ACT10 , . . . , ACTn0 where, i, ACTi0 (A(s,A,t) ) = ACTi (A) + (A, s)(t).Proposition 5 non-deterministic transition system , historyh = s0 , A1 , . . . , , snobtains rank hhACT, OBSi,h0 = s0 , A(s0 ,A1 ,s2 ) , . . . , A(sn1 ,An ,sn ) , snobtains hACT 0 , OBSi.805fiHunter & DelgrandeProof plausibility h obtained taking sumXOBSi (si ) + ACTi (Ai ) + (Ai , si1 )(si ),clearly sum taken determine plausibility h0 .Hence non-deterministic actions failed actions represented graded worldview, simply setting plausibility functions carefully.remark conceptually interesting distinction lost translation. Informally, distinction action fails occur actionoccurs, fails produce expected effect. distinction clear considerdifference failing drop glass ground, dropping glass failsbreak hits ground. first case, agent executes drop actionfails occur; perhaps glass sticks agents hand. second case,glass successfully dropped without breaking. framework, eventsrepresented dropping action null effect. suggest acceptabletreatment, cases sequence actions states identical. such,cannot distinguish scenarios based definition history. However,may able distinguish indirectly based values fluents. instance,location glass going change case successfully dropped.5. Comparison Related FormalismsBelief change due actions observations addressed previously literature.section, consider approach related existing work area.5.1 Representing Single-Shot Belief Changefocus thus far use graded world views representationiterated belief change due actions observations, simplest scenario involvessingle ontic epistemic action. important, therefore, verify singleshot belief change operators induced graded world view reasonable respectexisting work area. Recall defined graded world viewsshorthand notation associated concatenation operations. Based resultssection, clear shorthand natural appropriate.first consider case single ontic action.Proposition 6 Let hACT, OBSi graded world view. plausibility function rA,Bel(hACT, OBSi hr, 0i) = Bel(hACT, OBSi) Bel(r).Proof Since every action always executable, Bel(hACT, OBSi hr, 0i)s0 Bel(hACT, OBSi) s0 = Bel(r). HenceBel(hACT, OBSi hr, 0i) Bel(hACT, OBSi) Bel(r).Proposition 6 important primarily interested belief states ontic actions.Basically, case, graded world views unnecessary. plausible final beliefstate determined simply looking belief state associated initialgraded world view.806fiBelief Change Uncertain Action Historiesconsider case single observation. present, primarily interestedcomparing expressive power graded world views AGM revision operators.one sense graded world views clearly expressive AGMoperators. particular, new observation need incorporated agents beliefsobservation come reliable source. demonstrate that,context single observation, essentially difference graded worldview AGM revision operator. specifically, see belief changedefined concatenating single observation onto graded world view capturedAGM operator, provided observation degree strength higherfixed threshold.start proving every plausibility function defines system spheres,defined Grove (1988). first review definition system spheres. Let MLdenote set consistent, complete theories L. set subsets ML systemspheres centered X X ML , satisfies conditions:S1. totally orderedS2. X minimumS3. MLS4. formula || =6 , least sphere c() c() || =6U || =6 implies c() U every Upicture system spheres series concentric circles, innermost circle X.Let r plausibility function X minimum value minr . n, let r[n]denote set complete, consistent theories satisfied interpretationr(I) n.Proposition 7 Let r plausibility function finite action signature. collectionR = {r[n] | n minr } system spheres centered r[minr ].Proof Clearly, n, r(n) r(n + 1). Hence R totally ordered .r[minr ], satisfied r(I) minr . then, n,satisfied r(I) n. Hence r[minr ] r[n] r[n].Since action signature finite, finitely many states. Hencestate assigned maximum plausibility, say maxr . Therefore, r[maxr ] setcomplete, consistent theories.Let consistent formula. Since finitely many states, muststate r(s) r(t) . Let n = r(s). Clearly r(n) 6= .suppose U U 6= . Suppose U = r(m), U set complete,consistent theories satisfied r(I) m. Since elements U also, follows n. Therefore r[n] U , r[n] least sphere intersecting .Using result, show single-shot revision graded world viewscaptured AGM revision operators. make claim precise next proposition.807fiHunter & DelgrandeProposition 8 Let hACT, OBSi graded world view. AGM revision function natural number n that, plausibility function r statesdegree strength larger n,Bel(hACT, OBSi h n, ri) = Bel(hACT, OBSi) Bel(r).Proof Recall plaus plausibility function histories defined minimizing sums hACT, OBSi, plaus state corresponding plausibility functionfinal states.Let n natural number n > plaus(h) every history h. Let rplausibility function rank n. follows Bel(hACT, OBSih n, ri)following conditions hold:1. Bel(r)2. plaus state(s) minimal among states satisfying 1.Proposition 7, plaus state defines system spheres centered Bel(plaus state).follows Groves representation result (Grove, 1988) AGM revisionfunction that, observation , Bel(plaus state)following conditions hold:1.2. plaus state(s) minimal among states satisfying 1.Setting = Bel(r) gives desired result.Proposition 8 illustrates that, single observation, plausible worldsdetermined without considering history actions observations. determineplausible worlds following observation simply abstracting belief stategraded world view, performing AGM revision. easy show conversealso true: every AGM revision operator represented graded world view.precisely, following result.Proposition 9 Let AGM revision operator let belief state.graded world view hACT, OBSi Bel(hACT, OBSi) = natural number nthat, every non-empty observation ,= Bel(hACT, OBSi h n, ri)r plausibility function states minimal ranked elementsdegree larger n.Proof Groves representation result, captured system spheres S.Define graded world view hACT, OBSi system spheres givenProposition 7. Set n n > plaus(h) every history h. result immediate.Taken together, Propositions 8 9 illustrate graded world views equivalent808fiBelief Change Uncertain Action HistoriesAGM revision restrict attention single observation sufficiently high degreereliability. Hence, single-shot belief change, full expressive power graded worldviews unnecessary. ontic actions observations, definebelief change operations start belief state. also correspondenceNayaks work iterated revision (Nayak, 1994); observation sufficientlyplausible, every state observation ends strictly plausibleevery state.5.2 Representing ConditionalizationSpohn uses ranking functions define different form single-shot belief change calledconditionalization (Spohn, 1988). idea new evidence presented pair(, m), set states 0; value indication strengthobservation . Informally, conditionalization r new functionminimally ranked -worlds receive rank 0 non- worlds shifted m.section, illustrate conditionalization defined terms graded worldviews.First, define conditionalization formally. Let r plausibility function minr =0 let subset domain r. Let min() denote minimum value r(s). Spohn defines plausibility function r(|) follows:r(s|) = r(s) min().call r(s|) -part r. conditionalization r, written r(,m) , followingplausibility function.r(s|)r(,m) (s) =+ r(s|)6conditionalization r -part R together -part shifted appropriately.show conditionalization easily represented taking minimal sumsplausibility functions.Definition 13 Let r plausibility function 2F , let non-empty subset 2F ,let natural number. Define rC (, m) follows:0rC (, m) (s) =+ min() 6refer rC (, m) conditionalizer r respect m. followingproposition illustrates define conditionalization plausibility functiontaking appropriate sum.Proposition 10 Let r plausibility function minr = 0. , m, normalization r + rC (, m) conditionalization r(,m) .Proof ,r(s) + rC (, m)(s) = r(s) + 0 = r(s).809fiHunter & Delgrande6 ,r(s) + rC (, m)(s) = r(s) + + min().Since r(s) 0 0, follows minimum value obtained r + rC (, m)min(). Hence, normalization r + rC (, m) plausibility function r0 definedfollows.r0 (s) = r(s) + rC (, m)(s) min()equal r(,m) , wanted show.Proposition 10 illustrates conditionalization r (, m) definedtaking minimal sum two plausibility functions. restricted attentionplausibility functions minimum 0 class coincides closely Spohnsranking functions. However, define conditionalizer mannerplausibility functions non-zero minimums. also define conditionalizationgraded world view. Informally, simply conditionalize associated plausibilityfunction states. Hence, identify conditionalization respect h, mifollowing operation:hACT, OBSi h, plaus stateC (, m)i.straightforward show gives desired result.5.3 Representing Belief Evolution Operatorsnoted previously, previously defined so-called belief evolution operators capture iterated belief change due actions observations (Hunter & Delgrande, 2011).section, show graded world views actually extend approach, verifyingevery belief evolution operator captured graded world view.two underlying assumptions definition belief evolution:1. plausibility observation determined ordering, recency default.2. action history assumed correct.assumptions represented graded world view settingplausibility functions appropriately.Belief evolution operators defined respect metric transition systems.metric transition system transition system, along metric gives distancestates. metric defines belief revision operator follows (Delgrande, 2004):= {w | v1 v2 , v3 Kd(w, v1 ) d(v2 , v3 )}.Assume fixed initial belief state , along metric transition systemdefining revision operator update operator . Let belief evolutionoperator obtained . Let= hA1 , . . . ,810fiBelief Change Uncertain Action Historiesaction trajectory, let= h1 , . . . , nobservation trajectory. want construct graded world view Wev assignsminimal plausibility value histories corresponding hA, i.define Wev = hACT, OBSi presently. combining metric givenmetric transition system, define plausibility function BASE representsinitial ordering states implicit . particular, s, setBASE(s) = min({d(s, k) | k }).Using plausibility function, define observation trajectory OBS. Let maxdenote maximum value obtained BASE.BASE= 0OBSi =(2i + max) otherwiseincrementing plausibility false observations exponentially, assurerecent observations given greater credence.Informally, action symbol Ai translated plausibility function obtainsminimum value set {Ai }. Formally, following, 1 n:ACTi = Ai (2n+1 + max).Proposition 11 hA, = h0 , . . . , n i,h (Wev )h = hs0 , A1 , . . . , , sn si i.Proof Assume moment hA, consistent. Let h = hv0 , B1 , . . . , Bn , vn i.definition h (Wev ) sumnXACTi (Bi ) +i=1nXOBSi (vi )(2)i=0minimal. Since hA, consistent, exist histories hs0 , A1 , . . . , , snsi . histories, sum (2) becomesnXACTi (Ai ) +i=1nXOBSi (si ) = 0 + OBS0 (s0 )i=0remark sum less sum obtained historyeither Bi Ai si 6 . Therefore h (Wev )following three conditions hold:1. Bi = Ai > 0811fiHunter & Delgrande2. vi > 03. OBS0 (v0 ) minimal among states satisfying 1 2.order satisfy condition 2, must case v0 set\V =i1 (Ai ).order simultaneously satisfy condition 3, must also case v0 minimallydistant according metric d. words, v0 V . Therefore, h(Wev ) Bi = Ai following conditions hold:1. v0 i1 (Ai ),2. vi = v0 Ai .definition hA, i, completes proof.case hA, inconsistent similar. difference neednotice degree strength observation increases power 2.use fact that, natural number p, 2p larger every sum terms 2i< p. such, order minimize sum (2), need work backwardsobservations, keeping observation consistent observations followed.equivalent specification (Wev ) increasing powers exponentially forcesstrict preference recent observations.Proposition 11 demonstrates graded world views represent belief evolutionoperator defined respect distance function. perspective graded worldviews, assumption action histories infallible essentially restrictionadmissible plausibility functions.conclude section brief remarks use orderings resolveinconsistency iterated belief change. well-known Darwiche-Pearl postulates iterated belief change (Darwiche & Pearl, 1997) satisfied assumerecent observation takes precedence previous observations. contrast, Papiniillustrates alternative approach iterated revision earlier observations takeprecedence later observations (Papini, 2001). generally, defined belief evolution operators respect arbitrary total ordering observations.natural extension belief evolution would extend ordering include observationsactions. Using techniques section, easy see extended conception belief evolution corresponds class graded world views arbitraryinitial observation followed plausibility functions form 2i , distinct. Hence, even general extension belief evolution representedrelatively restricted class graded world views.5.4 Relation Situation CalculusSituation Calculus (SitCalc) well-establishing framework reasoningeffects actions. Action descriptions SitCalc formulated many-sorted firstorder logic along single second-order induction axiom. Briefly, variables range812fiBelief Change Uncertain Action Historiessituations, entities, actions. Situations understood represent currentstate world, including complete history actions occurred.distinguished constant symbol S0 denotes initial situation distinguishedfunction symbol maps action situation situation resultsexecuting situation s. Predicate symbols take situation argumentcalled fluents. detailed introduction, refer reader foundational summarypresented Levesque, Pirri Reiter (1998).epistemic extension SitCalc introduces sensing actions, alternative initialsituations, accessibility relation, plausibility ordering situations (Shapiroet al., 2011). situations agent believes possible minimal accessiblesituations, effect sensing action changes set accessible states.results form belief revision satisfies AGM postulates.previously proved belief revision SitCalc captured belief evolutionoperator natural translation (Hunter & Delgrande, 2011); therefore followsProposition 11 belief change operators defined standard SitCalc approachcaptured graded world views.similar conclusion drawn regarding representation uncertain actions.Bacchus et. al. (1999) extend SitCalc include noisy sensors non-deterministicactions. Roughly, idea define complex actions terms set primitiveactions. manner, non-deterministic action represented probability functionset primitive actions. similar result Proposition 5, provescapture non-deterministic actions introducing ranking functions actioneffects. think action effect primitive action, essentiallyrepresentation Bacchus et. al. except use ranking functions ratherprobabilities. Moreover, section 3.4 demonstrated translation probabilitiesplausibilities straightforward.approach appears sufficiently general capture belief changeuncertainty actions defined given epistemic extensions SitCalc,important note respects approach actually expressive.particular, allow revision arbitrary rankings formulas; requirefixed set sensing actions. approach also allows flexible representationinteraction uncertainty actions observations, elaborationtolerant sense need modify aggregates plausibility functionscapture different phenomena. hand, SitCalc provides rigorousprecise treatment actions effects ontic change. example, SitCalc treatmentproperty persistence (Kelly & Pearce, 2010) captures natural feature certain worldproperties captured graded world view ad hoc restrictionplausibility functions. Overall, see approach high-level model belief changecapture dynamics belief SitCalc, losingadvantages SitCalc model action effects.5.5 Relation Dynamic Epistemic Logicnotion belief change due reported information addressed DynamicEpistemic Logic (DEL) (van Ditmarsch, van der Hoek, & Kooi, 2007). context, belief813fiHunter & Delgrandechange captured plausibility models. plausibility model Kripke structure,associate well-ordering possible states state; ordering indicates states seen plausible state structure. Belief updatecaptured setting state-changing actions allow different agentsdifferent awareness action executed (Baltag & Smets, 2008); beliefrevision captured mapping plausibility models syntactically definedsuitable modal operators (Baltag & Smets, 2006; Van Benthem, 2007). Althoughcommon use ordering represent plausibility DEL, also variantsplausibility captured quantitative values. example, Laverny Lang(2005) define logic incorporates actions uses ranking functions N {}model strength belief formulas without nested modalities.two main distinctions work related work DEL tradition. first distinction superficial, related high-level perspective newinformation. DEL, external perspective new information, structures explicitly model way agent system views new information.DEL expressive respect nested multi-agent beliefs: ableexplicit perspective agent. presented paper, thinkgraded world views taking internal perspective single agent. provideranking function represents observation, external knowledgeactual state world. advantage approach every observation (resp.action) always possible. contrast, external perspective DEL, maysituations certain information simply cannot provided information update.example, underlying Kripke structure contains states true,information update provided make agent believe false.second distinction work existing work DEL relateduniform representation observations actions. DEL, distinction often drawnso-called hard updates soft updates (Van Benthem, 2007). hard updateoccurs information definite sense, incorporated modifyingaccessible states. might occur, example, common knowledgecertain state-changing action occurred. soft update corresponds belief revision,information incorporated modifying plausbility ordering. However,practical setting, often case one distinguish kind changeactually occur. kind ambiguity occur case graded world views,belief change operations handled uniform manner taking aggregatesplausibility functions. Morever, hard update soft update, update typicallysingle piece information single level plausibility. Hence, observationsactions represented graded manner. one distinguishing featurespresent work: allow observations (and actions) provide different levels evidenceseveral different states simultaneously.Despite differences, important emphasize actually see gradedworld views alternative DEL. Instead, see approach presented toolcould used basis belief change suitably defined DEL quantitativeplausibility rankings. analogous way formal belief change operatorsincorporated modal logics. Iterated revision operators lexicographic revision(Nayak, 1994) natural revision (Boutilier, 1996) originally defined general814fiBelief Change Uncertain Action Historiessetting orderings, used motivating examples information updateDEL. Similarly, suggest modal logic could defined semanticsiterated propositional updates based aggregates plausibility functions.logic would able model practical domains discussed paper,would also able capture complex multi-agent situations involving nested belief.5.6 Representations PlausibilityFollowing Spohn (1988), taken quantitative ranking functions representationplausibility. However, literature belief change defeasible reasoning containsgreat deal work different representations plausibility. section, brieflyconsider alternative approaches literature, argue approachsuitable kind reasoning intend capture.basic representation plausibility literature total pre-orderstates, often see AGM-inspired work. normally think orderingterms series levels plausibility. obvious limitation approachnotion magnitude respect differences plausibility, althoughintroduced allowing empty levels. event, clear rankingfunctions expressive total pre-orders respect modelling plausibility.interesting distinction occurs notion plausibility, orderingsused DEL tradition. noted above, plausibility context typically capturedwell-ordering (Van Benthem, 2007). necessary because, setting,want states comparable; want certain states innaccessibleothers. One might ask ranking functions limited sense respectwell-orderings used plausibility models. choice ranking functions motivatedinternal-external distinction discussed previous section. individual agent needconsider impossible states order modify beliefs appropriately, needconsider highly unlikely states.Note approach superficially similar related work defeasible reasoningfeaturing form preferential ordering states. possible, example, reasontypicality supplementing Kripke structure single ordering states(Britz & Varzinczak, 2013). alternative model setting description logics alsoproposed, function introduced map concept set elementsdeemed typical (Giordano, Olivetti, Gliozzi, & Pozzato, 2013). However,despite superficial similarities, important clear initial plausibilityfunction intended representation typicality normality absolutesense. model plausibility corresponds closely pointed plausibility modelincludes distinguished actual state.Alternative quantitative models plausibility also explored literature.One influential approaches based possibility measures,functions map states [0, 1] (Benferhat et al., 1999). main differencepossibility measure plausibility function really possibility measure 0 actually corresponds impossibility, corresponding plausibility value. However,already shown plausibility functions used capture rational-valued815fiHunter & Delgrandefunctions [0,1]; would straightforward modify proof deal real numbervalues.One general measures plausibility literature plausibility space,analogous probability space except range plausibility valuesset (Friedman & Halpern, 2001). Plausibility spaces intendedgeneral model subsumes great deal existing work reasoning plausibility.Indeed, plausibility functions clearly special case plausibility space;representation belief seen special case general approach.section, restricting discussion alternative representationsplausibility states. noted previously, approach representation plausibilitystates actually new therefore easy position work context.novel feature approach use notion plausibiility actions,order develop novel approach reasoning iterated belief change due actionsobservations6. Limitations Advantagesfocus previous sections establishing expressive power gradedworld views, compared existing frameworks reasoning belief change.result, focused problems involving priori graded world view, alongnew information. However, restriction new information artificial.general case, reason restrict attention problems agentreceives information actions observations occurring recent pointtime. agent could certainly receive new information earlier events actions.Hence, general problem involves agent underlying graded world view,together set constraints plausible histories. section, considerrepresentation problems general form.6.1 Constrained World ViewsSuppose hACT, OBSi graded world view length n. action constraintpair (A, i) action symbol n. Define (hACT, OBSi) (A, i)set histories minimal plausibility, subject restriction ithaction executed A. define observation constraints analogous manner,let (hACT, OBSi) (, i) set minimally ranked histories ith state. set constraints, define (hACT, OBSi) setminimally ranked histories satisfying every constraint . refer historiesconstrained histories refer graded world view together setconstraints constrained world view.presented constrained world views illustrate graded world viewsuseful many problems beyond normally considered realmstandard belief change operator. example, suppose Bob sends encryptedemail message Alice, inviting party house. Bob aware Evesystem administrator, could potentially manipulate messagedelivering it. Alice show up, Bob concludes Eve delivermessage. Bob concerned Eve read message hurt feelings816fiBelief Change Uncertain Action Historiesinvited. However, looking every possible action Eve could take, Bob concludesEve could decrypted message.preceding example, Bob needs consider possible actions Eve couldexecuted. conclusion Bob draws Eves knowledge party invariantrespect actions. formally define invariance follows.Definition 14 Let hACT, OBSi graded world view. say set statesi-invariant hACT, OBSi if, every A, Bel(hACT, OBSi (A, i)) .intuition behind i-invariance that, regardless action time i, underlyingagent always believe actual world . Reasoning invariant propertiesessential agent trying ensure property must hold action domaininvolving exogenous actions. required, example, reasoning cryptographicprotocols.Reasoning invariance one new kind problem addressedconstrained world views. suggest constraints also used provide naturalrepresentations hypothetical reasoning abductive reasoning.6.2 Belief ExtrapolationConstrained world views similar belief extrapolation operators (Dupin de Saint-Cyr& Lang, 2011). Briefly, belief extrapolation operator l takes sequence formulas,called scenario input, outputs another scenario. intuition outputgives general sequence formulas possibly true, given inputassumption fluents tend inertial. give brief description basicconstruction.trajectory sequence interpretations fixed signature. Let (i) denoteith interpretation trajectory . Given scenario , let Traj () denote settrajectories satisfy formula point-by-point basis. Every orderingclass trajectories defines extrapolation operator l follows:|( l (t))| = { (t) | Min(, Traj ())}Hence, l picks minimal trajectories satisfying .present purposes, important feature belief extrapolation operatordefined respect ordering histories. Given orderinghistories together sequence formulas, belief extrapolation operator returnsplausible sequences states. case constrained world views, essentiallything. given graded world view defines ordering states,constraints give sequence conditions need satisfied. easy showthat, using summation aggregate, every graded world view captured beliefextrapolation operator. section, consider converse problem: every beliefextrapolation operator represented suitable graded world view?key observation mapping graded world views orderingshistories surjective; orderings histories describedgraded world view. example, graded world view explicitly captureplausibilities form A1 occurs time i, A2 likely occur time + 1.817fiHunter & Delgrandeeasy see, graded world view ranks histories combining sequencerankings instant. course, might possible devise sequence rankingsalong aggregate function happened support conditional plausibilityfixed action signature. would domain-specific property, temporalrelation actions expressed two independent plausibility functions.Informally, graded world view represent domains ordering historiesbuilt pointwise manner plausibilities point time. section,use limitation establish difference expressive power constrainedworld views belief extrapolation operators.First, need formalize problem would like address precisely.Given belief extrapolation operator, would like able find graded world viewcaptures information.Definition 15 Let l belief extrapolation operator. say l representablegraded world view hACT, OBSi that, every scenario length n,Traj ( l) = (hACT, OBSi) .l representable, behaviour l simulated graded world view.remark abused notation definition Traj ( l) collectionsequences states, whereas (hACT, OBSi) collection histories. interpretequality mean two collections equal ignore action symbolslatter.following proposition indicates belief extrapolation operators expressive advantage.Proposition 12 belief extrapolation operator l representable.Proof Let ordering following trajectories minimal.1. h{a, b}, {a, b}, {a, b}i2. h{a, b}, {a, b}, {a, b}i3. h{a, b}, {a, b}, {a, b}iLet l associated belief extrapolation operator. show l representable.Let = ha, b, bi. Note satisfied three minimal trajectories. Thereforeraj( l) precisely set minimal trajectories.suppose hACT, OBSi graded world viewhACT, OBSiassigns minimal plausibility 1, 2, 3. Hence, exist actions A1 , A2 , A3 , B1 , B2 , B3following sums obtain minimum possible rank:1. OBS0 ({a, b}) + ACT1 (A1 ) + OBS1 ({a, b}) + ACT2 (B1 ) + OBS2 ({a, b})2. OBS0 ({a, b}) + ACT1 (A2 ) + OBS1 ({a, b}) + ACT2 (B2 ) + OBS2 ({a, b})818fiBelief Change Uncertain Action Histories3. OBS0 ({a, b}) + ACT1 (A3 ) + OBS1 ({a, b}) + ACT2 (B3 ) + OBS2 ({a, b})must case ACT1 (A1 ) = ACT1 (A2 ), otherwise either 1 2 couldreduced changing first action. Similarly, must case ACT2 (B1 ) =ACT2 (B3 ), otherwise either 1 3 would minimal. So, rewritesums follows:1. OBS0 ({a, b}) + ACT1 (A1 ) + OBS1 ({a, b}) + ACT2 (B1 ) + OBS2 ({a, b})2. OBS0 ({a, b}) + ACT1 (A1 ) + OBS1 ({a, b}) + ACT2 (B2 ) + OBS2 ({a, b})3. OBS0 ({a, b}) + ACT1 (A3 ) + OBS1 ({a, b}) + ACT2 (B1 ) + OBS2 ({a, b})1 2, follows basic algebraACT2 (B1 ) + OBS2 ({a, b}) = ACT2 (B2 ) + OBS2 ({a, b}).Substituting 3 gives another minimal sum:OBS0 ({a, b}) + ACT1 (A3 ) + OBS1 ({a, b}) + ACT2 (B2 ) + OBS2 ({a, b}).corresponds trajectoryh{a, b}, {a, b}, {a, b}i.Hence, graded world view assigning minimum plausibility 1-3, must also assignminimum plausibility fourth trajectory. Informally, 1-3 preferred trajectoriesaccording graded world view, forced accept another preferred trajectory.already saw raj( l) consists 1-3. Therefore l representable.Note proof Proposition 12 constructive demonstratessimple, concrete, extrapolation operator representable.Informally, Proposition 12 follows fact orderings historiesdefined graded world view. particularly important applicationsagent preferences order events occur. applications,useful assign plausibilities certain sequences actions. suggest, however,class orderings definable graded world views natural class orderings.particular, many action domains agent preconceived assumptionsorder exogenous actions occur. Graded world views provide reasonable tool representation action domains. Graded world views alsoexpressive advantage explicitly represent fallible actions wellforms uncertainty action effects.seen represent every belief extrapolation operator,would mistake conclude graded world views strictly less expressive. Beliefextrapolation really says nothing explicit actions, leads several differencesapproach. Given ordering histories length n, clear usebelief extrapoloation incorporate new action followed new observation;fixed method extending orderings n-tuples orderings n + 1 tuples.819fiHunter & Delgrandecase graded world view, however, clear new ordering definedactions performed. such, graded world views appropriaterepresentation epistemic action domains expect new observations actionsoccur. course, approach, fixed length initial graded worldview. Since null actions, however, value n really maximum lengthsequence actions occurred. such, graded world views sensible domainsimagine maximum number actions previously occurredbounded. Again, suggest class domains satisfies constraintlarge natural.6.3 Beliefs Action EffectsDespite flexible representation observations actions, one aspectrepresentation quite rigid. Specifically, single underlying transition systemgives effects actions; mechanism changing transition systemresponse new information. addressed Varzinczak (2010) modalsetting, introducing formal mechanism allows effects actions changeresponse new information. Combining idea notion plausibility gradedworld view would give even complete picture way agents reasoneffects actions uncertain effects. leave treatment idea futurework.related problem fact underlying transition system frameworkessentially known agent. words, given perfect informationcurrent state world action executed, agent knowsresulting state. alternative approach due Eiter et al. (2010) startaction description specifies actions effects. introduce suitableinformation update mechanisms based (partial) description effects, ratherassuming definite underlying transition system. is, however, superficialdistinction. using effect ranking functions, essentially give partial descriptionaction effects corresponds action description. manner, straightforwarddefine so-called Action Description Update problems graded world views.7. Conclusionintroduced formalism reasoning sequences actions observations.formalism uses Spohn-style ranking functions instant determineplausible action observation, determines plausible histories aggregatefunction instants. proved formalism subsumes belief revision,belief evolution, conditionalization. Moreover, suitable representationfallible beliefs, erroneous perception, exogenous actions, failed actions. usedtransition systems representation actions order facilitate comparisonwide range action formalisms. future work, interested axiomatizingbelief change permitted class admissible aggregate functions.main advantage graded world views related formalisms graded worldviews provide uniform mechanism dealing imperfect information actionsobservations. such, graded world views allow observations need incor820fiBelief Change Uncertain Action Historiesporated agent convinced certain action occurred previously.hand, graded world views also allow agent retract belief action occurredstrong belief observation. Graded world views provide tool representing opposing conclusions, simply considering magnitudes plausibilities,well underlying aggregate.existing work, belief change caused actions often represented startingaction formalism adding revision operators. One problem approachallow beliefs action occurrences. sense, graded world viewstake opposite approach. start ranking functions, originally definedreasoning belief change static environment, plug actions.agents beliefs actions occur independent formal representationaction effects. such, although presented graded world views termstransition systems, would certainly possible use different action formalism.key point that, using ranking functions represent uncertainty statesactions, define framework reasoning epistemic action effectsprimary importance placed evolution agents beliefs.conclude brief remark overall approach taken framework.distinction commonly drawn update revision belief change literature,despite fact difficult practice determine appropriateoperation given particular piece information. many cases, simply clearconflicting information result unseen action result erroneousbeliefs. One solution problem define single, general belief change operationsubsumes (Kern-Isberner, 2008). contrasat, maintain explicit distinctionway beliefs change due actions observations, use uniform modeluncertainty agent level focuses finding plausible sequence eventsexplain available evidence. seems like natural approach many applications,agents perception past events likely influenced convictionrespect senses beliefs.ReferencesAlchourron, C., Gardenfors, P., & Makinson, D. (1985). logic theory change:Partial meet functions contraction revision. Journal Symbolic Logic, 50 (2),510530.Bacchus, F., Halpern, J., & Levesque, H. (1999). Reasoning noisy sensors effectorssituation calculus. Artificial Intelligence, 111 (1-2), 171208.Baltag, A., & Smets, S. (2006). Dynamic belief revision multi-agent plausibility models.Proceedings Logic Foundations Game Decision Theory (LOFT),pp. 1124.Baltag, A., & Smets, S. (2008). qualitative theory dynamic interactive belief revision.Proceedings Logic Foundations Game Decision Theory (LOFT).Benferhat, S., Dubois, D., & Prade, H. (1999). Possibilistic standard probabilisticsemantics conditional knowledge bases. Journal Logic Computation, 9 (6),873895.821fiHunter & DelgrandeBoutilier, C. (1995). Generalized update: Belief change dynamic settings. ProceedingsFourteenth International Joint Conference Artificial Intelligence (IJCAI1995), pp. 15501556.Boutilier, C. (1996). Iterated revision minimal change conditional beliefs. JournalPhilosophical Logic, 25, 263305.Britz, K., & Varzinczak, I. (2013). Defeasible modalities. Proceedings 14th Conference Theoretical Aspects Rationality Knowledge (TARK), pp. 4960.Darwiche, A., & Pearl, J. (1997). logic iterated belief revision. Artificial Intelligence, 89 (1-2), 129.Delgrande, J. (2004). Preliminary considerations modelling belief change operators metric spaces. Proceedings 10th International Workshop NonMonotonic Reasoning (NMR 2004), pp. 118125.Delgrande, J., Dubois, D., & Lang, J. (2006). Iterated revision prioritized merging.Proceedings 10th International Conference Principles Knowledge Representation Reasoning (KR2006).Delgrande, J., & Levesque, H. (2012). Belief revision sensing fallible actions.Thirteenth International Conference Principles Knowledge RepresentationReasoning (KR2012), pp. 148157.Dupin de Saint-Cyr, F., & Lang, J. (2011). Belief extrapolation (or reasonobservations unpredicted change). Artificial Intelligence, 2, 760790.Eiter, T., Erdem, E., Fink, M., & Senko, J. (2010). Updating action domain descriptions.Artificial Intelligence, 174 (15), 11721221.Friedman, N., & Halpern, J. (2001). Plausibility measures default reasoning. JournalACM, 48 (4), 648685.Gelfond, M., & Lifschitz, V. (1998). Action languages. Linkoping Electronic ArticlesComputer Information Science, 3 (16), 116.Giordano, L., Olivetti, N., Gliozzi, V., & Pozzato, G. (2013). non-monotonic descriptionlogic reasoning typicality. Artificial Intelligence, 195, 165202.Grove, A. (1988). Two modellings theory change. Journal Philosophical Logic, 17,157170.Hunter, A. (2014). Belief change non-deterministic actions. ProceedingsCanadian Conference Artificial Intelligence, pp. 289294.Hunter, A., & Booth, R. (2015). Trust-sensitive belief revision. ProceedingsInternational Joint Conference Artificial Intelligence (IJCAI15).Hunter, A., & Delgrande, J. (2006). Belief change context fallible actions observations. Proceedings National Conference Artificial Intelligence(AAAI06),pp. 257262.Hunter, A., & Delgrande, J. (2011). Iterated belief change due actions observations.Journal Artificial Intelligence Research (JAIR), 40, 269304.822fiBelief Change Uncertain Action HistoriesJin, Y., & Thielscher, M. (2004). Representing beliefs fluent calculus. ProceedingsEuropean Conference Artificial Intelligence(ECAI04).Katsuno, H., & Mendelzon, A. (1991). difference updating knowledge baserevising it. Proceedings Second International Conference PrinciplesKnowledge Representation Reasoning (KR 1991), pp. 387394.Katsuno, H., & Mendelzon, A. (1992). difference updating knowledgebase revising it. G ardenfors, P. (Ed.), Belief Revision, pp. 183203. CambridgeUniversity Press.Kelly, R., & Pearce, A. (2010). Property persistence situation calculus. ArtificialIntelligence, 174 (12-13), 865888.Kern-Isberner, G. (2008). Linking iterated belief change operations nonmonotonic reasoning. Proceedings Eleventh International Conference PrinciplesKnowledge Representation Reasoning (KR08), pp. 166176.Kraus, S., Lehmann, D., & Magidor, M. (1990). Nonmonotonic reasoning, preferentialmodels cumulative logics. Artificial Intelligence, 4, 167207.Laverny, N., & Lang, J. (2005). knowledge-based programs graded belief-basedprograms, part i: On-line reasoning. Synthese, 147 (2), 277321.Lehmann, D., & Magidor, M. (1992). conditional knowledge base entail?.Artificial Intelligence, 55, 160.Levesque, H., Pirri, F., & Reiter, R. (1998). Foundations situation calculus.Linkoping Electronic Articles Computer Information Science, 3 (18), 118.Liberatore, P., & Schaerf, M. (2000). BReLS: system integration knowledgebases. Proceedings KR2000, pp. 145152. Morgan Kaufmann Publishers.Lorini, E., Jiang, G., & Perrussel, L. (2014). Trust-based belief change. ECAI 2014 21st European Conference Artificial Intelligence, pp. 549554.Moore, R. (1985). formal theory knowledge action. Hobbs, J., & Moore, R.(Eds.), Formal Theories Commonsense World, pp. 319358. Ablex Publishing.Nayak, A. (1994). Iterated belief change based epistemic entrenchment. Erkenntnis, 41,353390.Papini, O. (2001). Iterated revision operations stemming history agentsobservations. Rott, H., & Williams, M. (Eds.), Frontiers Belief Revision, pp.279301. Kluwer Academic Publishers.Shapiro, S., Pagnucco, M., Lesperance, Y., & Levesque, H. (2011). Iterated belief changesituation calculus. Artificial Intelligence, 175 (1), 165192.Spohn, W. (1988). Ordinal conditional functions. dynamic theory epistemic states.Harper, W., & Skyrms, B. (Eds.), Causation Decision, Belief Change, Statistics, vol. II, pp. 105134. Kluwer Academic Publishers.Van Benthem, J. (2007). Dynamic logic belief revision. Journal applied non-classicallogics, 17 (2), 129155.823fiHunter & Delgrandevan Ditmarsch, H., van der Hoek, W., & Kooi, B. (2007). Dynamic Epistemic Logic.Springer.Varzinczak, I. (2010). action theory change. Journal Artificial Intelligence Research(JAIR), 37, 189246.824fiJournal Artificial Intelligence Research 53 (2015) 375-438Submitted 01/15; published 07/15Approximate Value IterationTemporally Extended ActionsTimothy A. MannShie Mannormann@ee.technion.ac.ilshie@ee.technion.ac.ilElectrical EngineeringTechnion - Israel Institute Technology,Haifa, IsraelDoina Precupdprecup@cs.mcgill.caSchool Computer ScienceMcGill University,Montreal, QC, H3A2A7, CanadaAbstractTemporally extended actions proven useful reinforcement learning,duration also makes valuable efficient planning. options framework providesconcrete way implement reason temporally extended actions. Existingliterature demonstrated value planning options empirically,lack theoretical analysis formalizing planning options efficientplanning primitive actions. provide general analysis convergence ratepopular Approximate Value Iteration (AVI) algorithm called Fitted Value Iteration (FVI)options. analysis reveals longer duration options pessimistic estimatevalue function lead faster convergence. Furthermore, options improveconvergence even suboptimal sparsely distributed throughout statespace. Next consider problem generating useful options planning basedsubset landmark states. suggests new algorithm, Landmark-based AVI (LAVI),represents value function landmark states. analyze FVILAVI using proposed landmark-based options compare two algorithms.experimental results three different domains demonstrate key propertiesanalysis. theoretical experimental results demonstrate options playimportant role AVI decreasing approximation error inducing fast convergence.1. Introductionconsider problem planning Markov Decision Processes (MDPs; Puterman,1994, see Section 2) large even infinite state-spaces. setting, traditionalplanning algorithms, Value Iteration (VI) Policy Iteration (PI), intractablecomputational memory complexities iteration scale (polynomiallylinearly, respectively; Littman, Dean, & Kaelbling, 1995) number statestarget MDP. Approximate Value Iteration (AVI) algorithms scalable VI,compactly represent value function (Bertsekas & Tsitsiklis, 1996).allows AVI algorithms achieve per iteration computational memory complexitiesindependent size state-space. However, many challengesc2015AI Access Foundation. rights reserved.fiMann, Mannor, & Precupusing AVI algorithms practice. AVI VI often need many iterations solve MDP(Munos & Szepesvari, 2008). turns temporally extended actions playimportant role reducing number iterations.options framework defines unified abstraction representing temporallyextended actions primitive actions (Sutton, Precup, & Singh, 1999). optioninitialized, immediately selects primitive action (or lower-level option) executereturn control agent. Then, following timestep, option testswhether return control agent called option continue selectinganother primitive action (or lower-level option). represent temporallyextended actions, options provide valuable tool efficient planning (Sutton et al., 1999;Silver & Ciosek, 2012). analyses AVI, one iteration corresponds planningone additional timestep future. hand, performing single iterationAVI temporally extended actions, one iteration could instead correspond planningseveral timesteps future. derive bounds help us reason AVItemporally extended actions converges faster AVI primitive actions.options framework appealing investigating planning temporally extendedactions. one thing, class options includes primitive actions well widerange temporally extended actions, many well-known properties MarkovDecision Processes generalize arbitrary options added (e.g., Value IterationPolicy Iteration still converge, Precup & Sutton, 1997; Precup, Sutton, & Singh, 1998;Sutton et al., 1999). addition, much effort gone algorithms learn goodoptions exploration (Iba, 1989; Stolle & Precup, 2002; Mannor, Menache, Hoze, & Klein,2004; Konidaris & Barto, 2007). algorithms may produce options also usefulplanning. Lastly, options allow greater flexibility modeling problemsactions temporal resolution. example, inventory managementproblems placing orders may occur regular intervals (Minner, 2003)RoboCup Keepaway domain agents make decisions controlsoccer ball (Stone, Sutton, & Kuhlmann, 2005). Thus, options important candidateinvestigating planning temporally extended actions.1.1 MotivationUltimately care time takes solve MDP. However, focus analyzing convergence rate AVI options, faster convergence rate impliessolution fewer iterations. Using convergence rate determine totalcomputational cost planning bounding computational cost iteration.total computational cost options smaller primitive actions, planningoptions faster planning primitive actions.focus convergence rate provide valuable insightplanning options faster planning primitive actions. However,present full computational complexity planning options computational cost per iteration highly domain dependent. Therefore, convergence rateplanning options gives us insight planning options may fasterplanning primitive actions without getting bogged domain specific details. example, computational cost iteration depends (1) computational376fiApproximate Value Iteration Temporally Extended Actionscomplexity simulating option, (2) computational complexity value functionapproximation method, (3) number primitive actions temporally extendedactions initialized state.sake clarity, discuss factors impact computationalcomplexity AVI.1.1.1 Cost Simulating Actions Optionscomputational cost simulating option depends simulator. assumesimplicity primitive actions simulated approximatelycomputational cost. main question is: compuational cost simulatingtemporally extended actions compared cost simulating primitive actions?general, simulator primitive actions used simulate options executingsequence primitive actions prescribed option. computational costequal cost simulating sequence primitive actions. However,simulator inexpensive, simulation costs may outweighed cost fittingdata function approximator. seen experiments section 5.cases, specialized simulators constructed temporally extendedactions approximately cost primitive actions. discrete state MDPs,accomplished preprocessing step composing options primitiveactions (Silver & Ciosek, 2012). large- continuous-state MDPs, linear optionsframework enables construction option models composing models primitiveactions (Sorg & Singh, 2010). addition, existing simulators carefully designedsimulating actions long short timescales (Chassin, Fuller, & Djilali, 2014).1.1.2 Cost Value Function Approximationchoice function approximation architecture drastic implicationscomputational cost iteration. Ridge Regression, LASSO, SVR, Neural Networks,etc. computational costs scale number features varying rates.cases, cost training suitable function approximation architecture maysignificantly expensive cost querying simulator. cases,decreasing number iterations result significant overall computational savingseven options require queries simulator.1.1.3 Number Actions Optionsiteration, AVI samples actions collection states. large (oreven infinite) number primitive actions, planning made computationallyefficient sample efficient planning instead smaller number options.1.1.4 Cost Acquiring OptionsOne final consideration computational cost acquiring options. optionsdesigned advance experts, additional cost. However, optionsdiscovered generated, cost factored total costalgorithm. landmark-based option generation approach proposed section 5.3.2377fiMann, Mannor, & Precupalmost overhead, given set landmark states. However, computationallyexpensive methods acquiring options (Simsek & Barto, 2004; Mannor et al., 2004) couldjustified options reused planning many tasks (Fernandez & Veloso,2006).1.2 Contributionsmain contributions paper following:propose Options Fitted Value Iteration (OFVI) algorithm, variant popular Fitted Value (or Q-) Iteration (FVI, Riedmiller, 2005; Munos &Szepesvari, 2008; Shantia, Begue, & Wiering, 2011) algorithm samples generatedoptions.analyze OFVI Theorem 1, characterizing asymptotic loss convergence behavior planning given set options. give two corollariesspecifying bound simplifies when: (1) options minimum duration > 1 (Corollary 1) (2) option set contains long duration optionsprimitive actions (Corollary 2).introduce novel method generating options, based landmark states.suggests new algorithm, Landmark-based Approximate Value Iteration (LAVI),needs model value finite set states rather whole valuefunction.analyze asymptotic loss convergence behavior LAVI Theorem 2OFVI landmark options Theorem 3. Comparing bounds LAVIOFVI suggests LAVI may converge faster OFVI. However, asymptoticlosses directly comparable.provide detailed experimental comparison FVI primitive actions, OFVIhand-coded options, OFVI landmark options, LAVI. experimentsdomain realistic pinball-like physics complex inventory managementproblem, demonstrate LAVI achieves favorable performance versus time tradeoff.rest paper organized follows. Section 2 introduces backgroundMarkov Decision Processes, Dynamic Programming, previous analysis FVI, Semi-MarkovDecision Processes, options. Section 3 defines Options Fitted Value Iteration(OFVI) algorithm compares Primitive Actions Fitted Value Iteration (PFVI)considered previous work. Section 3.2 provides detailed discussion convergenceproperties OFVI different conditions. Section 4 introduces landmark optionsexplains landmarks used generate useful options planning. section also provides analyses convergence rates LAVI OFVI landmark-basedoptions. Section 5 provides experiments results comparing PFVI OFVI threedifferent domains. Section 6 discusses relationship results presentedprevious work, well as, extensions directions future work.378fiApproximate Value Iteration Temporally Extended Actions2. BackgroundLet X subset d-dimensional Euclidean space, (X) set probability measures X, f : X R function vectors X real numbers.max-norm kf k = supxX |f (x)|. p 1 (X), (p, )-norm defined1/pRkf kp, =(x)kf (x)kp dx.MDP defined 5-tuple hX, A, P, R, (Puterman, 1994) X setstates, set primitive actions, P maps state-action pairs probabilitydistributions states, R mapping state-action pairs reward distributionsbound interval [RMAX , RMAX ], [0, 1) discount factor. Let B(X; VMAX )denote set functions domain X range bounded [VMAX , VMAX ]MAXVMAX R1. Throughout paper consider MDPs X bounded subsetd-dimensional Euclidean space finite (non-empty) set actions.policy : X mapping states actions. denote set deterministic, stationary Markov policies . standard objective planning MDPderive policy maximizes"#XV (x) = E(1)Rt (xt , (xt ))|x0 = x, ,t=0x long-term value following starting state x. function V calledvalue function respect policy well known writtenrecursively solutionZV , E [R(x, (x))] + P (y|x, (x))V (y)dy,(2)Bellman operator respect V unique fixed point. Givenvector V B(X; VMAX ), greedy policy respect V definedZ(x) = arg max E [R(x, a)] + P (y|x, (x))V (y)dy .(3)aAdenote optimal value function V = max V .Definition 1. policy optimal corresponding value function V . policy-optimal V (x) V (x) x X.Bellman optimality operator definedZ(T V )(x) = max E [R(x, a)] + P (y|x, a)V (y)dy ,aA(4)V B(X; VMAX ), known fixed point V . Value Iteration (VI),popular planning algorithm MDPs, defined repeatedly applying (4). algorithmproduces series value function estimates V0 , V1 , V2 , . . . , VK greedy policy Kconstructed based VK . Since VI converges limit, policy K mayoptimal. However, would still like measure quality K compared .measure quality policy need define notion loss. followingdefines loss policy respect set states loss policy respectprobability distribution.379fiMann, Mannor, & PrecupDefinition 2. Let x X. subset-loss policy respect set statesX definedLY () = max (V (x) V (x)) ,(5)xYdenote special case X L (). Let p 1 (X).loss policy respect distribution states definedLp, () = kV V kp, .(6)VI operates entire state space. able decrease L error,VI computationally intractable MDPs extremely large continuous statespaces. Thus approximate forms VI generally seeks decrease loss respectprobability distribution state space.2.1 Approximate Value Iteration (AVI)Approximate Value Iteration (AVI) family algorithms estimate optimal(action-)value function iteratively applying approximation Bellman optimalityoperator. many possible relaxations VI. states backed according , representation value function estimates, number times samplesimulator, etc. impact loss resulting policy.One popular family AVI algorithms Fitted Value Iteration (FVI) algorithms.algorithms use function approximator represent value function estimatesiteration. Primitive action Fitted Value Iteration (PFVI) generalization VI handlelarge continuous state spaces. PFVI runs iteratively producing sequence K 1estimates {Vk }Kk=1 optimal value function returns policy K greedyrespect final estimate VK . iteration k, algorithm computesset empirical estimates Vk Vk1 n states, fits function approximatorVk . generate Vk , n states {xi }ni=1 sampled distribution (X).}m rewardssampled state xi primitive action A, next states {yi,jj=1}mth iteration, estimates{ri,jj=1 sampled MDP simulator S. kBellman backups computed1 XVk (xi ) = maxri,j + Vk1 (yi,j) ,aA(7)j=1V0 initial estimate optimal value function given argument PFVI.k th estimate optimal value function obtained applying supervised learningalgorithm A, producesn fifipXfifiVk = arg minfif (xi ) Vk (xi )fi ,f F(8)i=1p 1 F B(X; VMAX ) hypothesis space supervised learningalgorithm.work Munos Szepesvari (2008) presented full finite-sample, finite-iterationanalysis PFVI guarantees dependent Lp -norm rather much380fiApproximate Value Iteration Temporally Extended Actionsconservative infinity/max norm. enabled analysis instances PFVI use onemany supervised learning algorithms minimizing L1 L2 norm. key assumptionneeded analysis notion discounted-average concentrability future statedistributions.Assumption 1. [A1(, )] [Discounted-Average Concentrability Future-StateDistributions] (Munos, 2005; Munos & Szepesvari, 2008) Given two distributionsdefined state space X, 1, arbitrary policies 1 , 2 , . . . , ,assume P 1 P 2 . . . P absolutely continuous respect implyingd(P 1 P 2 . . . P )def< + ,c(m) =sup(9)1 ,2 ,...,massumedefC, = (1 )2Xm1 c(m) < +m1discounted average concentrability coefficient, P denotes transition kernelinduced executing action prescribed policy .Intuitively, assumption prevents much transition probability mass landingsmall number states. condition C, finite depends c(m) growingsubexponentially. See work Munos (2005) complete discussionAssumption 1. note work Farahmand, Munos, Szepesvari (2010)presents refined analysis using expectation (9) rather supremum.results tighter bounds bounds difficult interpret due blowupnotation.work Munos Szepesvari (2008) shows given MDP, select probability distributions , (X), positive integer p, supervised learning algorithmbounded function space F returns function f F minimizesempirical p-norm error, V0 F initial estimate optimal value function, > 0(0, 1]. K 1, probability least 1 , exist positiveintegers n, m, K policy K returned PFVI satisfies21/pK+1 1/p 2 kV V0 kLp, (K )C bp, (T F, F) + +,(10)(1 )2 ,(1 )2bp, (T F, F) = sup inf kT f gkp, inherent Bellman error F respectf F gF.1Bellman operatorinherent Bellman error measure well chosenhypothesis space F represent Vk iteration. first term (10) calledapproximation error corresponds error introduced inabilitysupervised learning algorithm exactly capture Vk iteration, secondterm, estimation error, due using finite number samples estimate Vk .last term controlled number iterations K algorithm. increasing K1. paper, consider multi-sample variant PFVI uses fresh samples iteration.bound single-sample variant PFVI, uses batch samples iteration,almost identical (10). See work Munos Szepesvari (2008) details.381fiMann, Mannor, & Precuplast term shrinks exponentially fast. last term characterizes convergence ratealgorithm. size discount factor controls rate convergence. Convergencefaster smaller. Unfortunately, part problem definition. However,options execute multiple timesteps, option effective discountfactor smaller .2.2 Semi-Markov Decision ProcessesSemi-Markov Decision Processes (SMDPs) generalization Markov DecisionProcess (MDP) model incorporates temporally extended actions. Temporally extendedactions primarily applied direct exploration reinforcement learning (Iba,1989; Mannor et al., 2004; Konidaris & Barto, 2007; Jong & Stone, 2008). However,may also play important role planning (Precup & Sutton, 1997; Precup et al., 1998;Sutton et al., 1999; Silver & Ciosek, 2012). example, popular dynamic programmingalgorithms VI PI still converge applied SMDPs (Puterman, 1994). workPrecup et al. (1998) shows options MDP form SMDP. works Suttonet al. (1999) Silver Ciosek (2012) provide experimental results demonstratingoptions speed planning finite state MDPs. However, works applyoptions tasks continuous state spaces theoretical analysisconvergence rate planning options compared planning primitive actions.use SMDP framework investigate planning temporally extended actions.MDP paired set temporally extended actions called options, denotedO, forms SMDP.Definition 3. (Sutton et al., 1999) option defined 3-tuple hIo , ,Io set states initialized from, stationary policy definedprimitive actions followed lifetime o, : X [0, 1] determinesprobability terminate given state.state x X, denote set options initialized xOx = {o | x Io }. Options generalization actions. fact encompass,primitive actions temporally extended actions, also stationary policiescontrol structures. take actions options always terminatefinite number timesteps. Policies hand never terminate. example,stationary policy represented option setting termination probabilities(x) = 0 states.option = hIo , , i, denote probability initialized statex terminates subset states X exactly timesteps P(Y |x)Pdiscounted termination state probability distribution Peo (Y |x) =t=1 Pt (Y |x).state-option pair (x, o), discounted cumulative reward distributione o).options execution denoted R(x,objective planning options derive policy : X statesoptions maximizeshZe (x)) + Pe(x) (y|x)V (y)dy .V (x) = E R(x,382(11)fiApproximate Value Iteration Temporally Extended ActionsBellman operator SMDP definedhZe o) + Pe (y|x)V (y)dy ,(TV )(x) = max E R(x,oOx(12)defined set options instead primitive actions A. differences(4) (12) could potentially lead widely different results embeddedFVI algorithm.3. Options Fitted Value IterationAlgorithm 1 Options Fitted Value Iteration (OFVI)Require: Collection options O, SMDP simulator S, state distribution , functionspace F, initial iterate V0 F, n number states sample, numbersamples obtain state-option pair, K number times iteratereturning1: k = 1, 2, . . . , K {Generate K iterates V1 , V2 , . . . VK .}2:{Collect new batch samples.}3:= 1, 2, . . . , n {Sample N states.}4:x {Sample state distribution .}5:Ox6:j = 1, 2, . . .,, ro ,7:yi,ji,j i,j S(x, o) {Query simulator terminal state, discountedcumulative reward, duration executing (x, o).}8:end9:end10:end11:{Estimate BellmanBackups.}h1 Pm)12:V j=1 ri,j + i,j Vk1 (yi,j{Find best fitting approximation V .}14:Vk = arg inf f F kf V kn15: end16: return K {Return greedy policy wrt VK .}13:Algorithm 1 generalization multisample FVI algorithm casesamples generated options (with primitive actions special case). algorithm,Options Fitted Value Iteration (OFVI), takes arguments positive integers n, m, K,(X), initial value function estimate V0 F, simulator S. iterationk = 1, 2, . . . , K, states xi = 1, 2, . . . , n sampled, option Oxi ,, r , S(x , o) samplednext states, rewards, option execution times hyi,ji,j i,jj = 1, 2, . . . , m. update resulting applying Bellman operatorprevious iterate Vk1 estimated1 XhVk (xi ) maxri,j + i,j Vk1 (yi,j) ,(13)oOxij=1383fiMann, Mannor, & Precupapply supervised learning algorithm obtain best fit according (8).given simulator differs simulator PFVI. returns state optionreturned control agent, total cumulative, discounted reward receivedexecution, duration number timesteps option executed. additional information needed compute (13). Otherwise differences PFVIOFVI minor natural ask OFVI similar finite-sample convergencebehavior compared PFVI.3.1 Simple AnalysisNotice PFVI special case OFVI given options containprimitive action set (i.e., A). Therefore, cannot expect OFVI always outperformPFVI. Instead, aim show OFVI converge slowly PFVIidentify cases OFVI converges quickly PFVI. following propositionprovides general upper bound loss policy derived OFVI containsA. bound compared bounds loss policy derived PFVI.Proposition 1. , > 0 K 1. Fix p 1. Let set optionscontains set primitive actions A. Given initial state distribution (X),sampling distribution (X), V0 B(X, VMAX ), A1(, ) (Assumption 1) holds,exists positive integers n OFVI executed,21/pK+1 1/p 2 kV V0 kLp, (K )C bp, (TF, F) + +(14)(1 )2 ,(1 )2holds probability least 1 .proof Proposition 1 well sufficient values n given appendix. Proposition 1 suggests long contains A, OFVI performance leastcomparable PFVI (if better). two main differences boundProposition 1 work Munos Szepesvari (2008, Thm. 2). First, inherentBellman error Proposition 1 may larger inherent Bellman errorprimitive actions. Second, convergence rate OFVI tracks convergence rateSMDP Bellman operator rather MDP Bellman operator .Proposition 1 implies OFVI converges approximately fast PFVIcontains A. However, two algorithms may converge different value functions duelarger inherent Bellman error OFVI.Proposition 1 two limitations. First considers case containsA. Second, describe OFVI converges quickly PFVI.following section, investigate possibilities.3.2 General Analysistwo perspectives explain applying options AVI decreasenumber iterations needed find near-optimal policy.first perspective, options increase information flow otherwise temporallydisparate states facilitating fast propagation value throughout state-space. example, takes many primitive actions transition state x state y, planning384fiApproximate Value Iteration Temporally Extended Actionsprimitive actions require many iterations information propagatedback x. However, given option initialized state x, terminatesy, value propagated back x every iteration.second perspective, options long duration cause rapid contraction toward optimal near-optimal value function. discounted average rewardobjectives, proof VI converges based contraction argument (for details,see Puterman, 1994). turns options long duration induce fastercontraction primitive actions (or faster options shorter durations).options influence convergence rate AVI depends critically agentsobjective. paper, analyze discounted reward objective. However, putresults context, section, comment finite horizon averagereward objectives well.Undiscounted, Finite Horizon: agent maximizes sum rewards receivedH 1 timesteps. options short circuit number iterations neededpropagate reward back H steps. effect naturally described increasinginformation flow temporally disparate states.Discounted Reward (our analysis): analysis uses contraction argumentshow faster convergence information flow argument show fast contraction occur even temporally extended actions sparsely distributedstate-space.Average Reward: agent maximizes average infinite sequence rewards. consider discounted reward setting, similar contractionarguments could provably applied show options produce closer approximation optimal value function fewer iterations.approach based contraction mapping argument. applying MDPBellman operator V B(X, VMAX ), obtain following contraction mappingkV V k kV V k(15)(the discount factor) serves contraction coefficient. Since < 1, left handside strictly smaller kV V k . Smaller values imply faster convergence rate,discount factor part problem description cannot changed. However,apply MDP Bellman operator , > 1 times, obtain contractionmapping contraction coefficient < . Temporally extended optionssimilar effect. Options speed convergence rate SMDP Bellman operatorinducing smaller contraction coefficient depends number timestepsoption executes for.Intuitively, options long duration desirable planning optionsexecute many timesteps enable OFVI look far future singleiteration. However, duration depends option state optioninitialized. following definition makes notion options duration precise.385fiMann, Mannor, & PrecupDefinition 4. Let x X state Ox option. duration executingoption state x number timesteps executes terminating (i.e.,returning control option policy). denote Dx,Yrandom variable representingduration initializing option state x terminating X.h setoptions O, define minimum duration dmin = min inf X E Dx,Y .xX,oOxFirst notice duration option random variable dependsstate option initialized. complicates analysis compared assumingtemporally extended actions terminate fixed number timesteps,allows much greater flexibility selecting options use planning.Similar analysis PFVI, analysis OFVI depends concentrabilityfuture state distributions. introduce following assumption future statedistributions MDPs set options. given set options may maycontain entire set primitive actions underlying MDP.Assumption 2. [A2(, )] [Option-Policy Discounted-Average ConcentrabilityFuture-State Distributions] Given two distributions defined statespace X, 1, m, arbitrary option policies 1 , 2 , . . . , , assumePt1 2 ...m absolutely continuous respect implying(Pt1 2 ...m )< + ,ct (m) =sup(16)1 ,2 ,...,massumeC, = (1 )2Xt1t=1maxm{1,2,...,t}ct (m) < +(17)option discounted average concentrability coefficient, Pt1 2 ...m (y) assignsprobability mass according event sequence options terminatestate exactly timesteps initial state sampled sequenceoptions executed ith option sequence chosen according .Assumption 2 analogous Assumption 1. Despite fact optionsgeneral framework set primitive actions, Assumption 2 results smallerconcentrability coefficient Assumption 1.Lemma 1. Let , (X). Assumption A1(, ) implies Assumption A2(, ) (i.e.,C, C, ).Proof. First notice since timestep sequence actions generated sequence1 , 2 , . . . , option policies expressed sequence primitive policies1 , 2 , . . . , . Thus...md(Pt 1 2)ct (m) = sup1 ,2 ,...,m12sup1 ,2 ,...,t d(P Pd ...P )= c(t) .386fiApproximate Value Iteration Temporally Extended ActionsSince ct (m) c(t) 1 m,Pt1 maxC, = (1 )2m{1,2,...,t} ct (m)t=1P2t1(1 )c(t)t=1= C, .Lemma 1 implies Assumption 2 holds set options whenever Assumption1 holds. main reason sequence options executes timestepsfewer degrees freedom sequence primitive policies. Furthermore, proofLemma 1 tells us important property discounted concentrability futurestates number options executed sequence number timestepssequence options executes for.analysis convergence rates OFVI, report bounds containingcoefficient C, rather C, . because, cases option set containsmostly temporally extended actions, C, may smaller C, . However, Lemma 1tells us replace C, bounds C, purposes comparing(10) (14).important properties temporally extended actions cause faster convergence(1) quality policy follow, (2) long action executes (orduration). following definition describes set states exists optionfollows near-optimal policy sufficient duration.Definition 5. Let X set states MDP option set O, 0, dmin .(, d)-omega set defined,d x X | oOx s.t. inf E Dx,Y Q (x, o) V (x) ,(18)Xset states -optimal temporally extended action durationlonger optimal option policy.states ,d particularly long duration follow -optimal policy. However, states outside ,d not. states, either available optionssufficiently temporally extended follow suboptimal policy. obtain fasterconvergence, need way connecting convergence rates states outside ,dconvergence rates states ,d .Assumption 3. [A3(, d, , , j)] Let , , j 0, dmin , (X). 0option policies 1 , 2 , . . . , , let = P 1 P 2 . . . P . exists -optimal optionpolicy either (1) Prx [x ,d ] 1 (2) i{1,2,...,j} Pryi [y ,d ]1 = P 1 P 2 . . . P P = 1, 2, . . . , j.Assumption 3 points three key features impact planning performanceoptions:1. Quality option set controlled ,387fiMann, Mannor, & Precup2. Duration options specified d,3. Sparsity ,d state-space characterized j .refer policy bridge policy, bridges gapstates ,d states. Notice assume plannerknowledge . enough policy exists. Assumption 3 says matterpolicies followed, either (1) agent end ,d high probability(2) exists near-optimal option policy transport agent ,dj timesteps high probability. enables us account problemsstates temporally extended actions, states reached quickly withoutfollowing policy suboptimal.following theorem provides comprehensive description convergence behaviorOFVI (with PFVI special case = A).Theorem 1. Let , > 0, , , j 0, K, p 1, dmin , 0 Z K, , (X).Suppose A2(, ) (Assumption 2) A3(, d, , , j) (Assumption 3) hold. GivenV0 B(X, VMAX ), first Z iterates {Vk }Zk=0 produced algorithm pessimistic(i.e., Vk (x) V (x) x X), exists positive integers nOFVI executed,Lp, (K ) Lp, ( ) +2 dmin 1/pC (bp, (TF, F) + ) +(1 )2 ,1/p+ dmin (K+1)+(1)(ddmin )bZ/jc!2 V V0(19)(1 )2holds probability least 1 optimal option policy respectgiven options j = j + 1.Theorem 1 bounds loss option policy K returned performing K 1iterations value iteration respect (p, )-norm. distribution thoughtinitial state distribution. places probability mass regionsstate space want policy K best performance. value p 1generally determined function approximation procedure. p = 1, functionapproximation procedure minimizes L1 -norm p = 2, function approximationprocedure minimizes L2 -norm.right hand side (19) contains four terms.1. first term bounds abstraction loss, loss optimalpolicy primitive actions optimal option policy.2. second term bounds approximation error, error causedinability function approximation architecture exactly fit Vk (xi )iteration shows term due bootstrapping optionsdminfollow -optimal policies gain faster convergence. Notice (1)2 shrinksdmin grows. Thus option sets longer minimum duration shrink approximationerror.388fiApproximate Value Iteration Temporally Extended Actions3. third term sample error, controlled number samplestaken iteration.4. last term controls convergence error. Notice , discount factor,[0, 1) therefore last term shrinks rapidly exponent grows. OFVIactually converge sense loss may never go zero, lastterm goes zero K . worst case, convergence rate controlleddmin (K+1) , convergence rate significantly faster Z largej small.iterate V : X R pessimisticyX V (y) V (y) ,optimal policy defined option set O. Whether iterates pessimistic(or not) critical impact convergence rate OFVI. understand why, supposeq Ox option initialized state x X q -optimalrespect (i.e., Q (x, q) V (x) ) long duration (at least timesteps).V pessimistic, Bellman optimality operator performs updatehZee(TV )(x) = max E R(x, o) + P (y|x)V (y)dy ,definition (12).oOxhZe q) + Peq (y|x)V (y)dy .E R(x,update option q.Since known monotone operator, V (x) (TV )(x). Taken together,facts imply even option q selected update, (TV )(x)least close V (x) q selected. allows us prove iteratespessimistic, convergence rate OFVI rapid (depending d). Unfortunately,iterates pessimistic, reasoning longer holds convergence maydepend options duration dmin instead.Z iterations estimate value function pessimistic, OFVIexploits options duration rather dmin . However, get samplesoptions states ,d . states outside ,d benefit rapidconvergence states ,d j additional iterations. main reasontake j steps propagate value states ,d back states.Using Theorem 1 possible consider convergence rates OFVI wide rangeplanning problems. following subsections, examine special cases Theorem1. First, consider happens dmin greater 1 ignoring possibilityexploiting options longer duration. Second, consider happens mixprimitive actions temporally extended actions.3.2.1 Abstractionimportant case involves planning temporally extended actions available.main advantage case guarantee upper bound convergence389fiMann, Mannor, & Precuprate algorithm strictly faster upper bound PFVI. However, solutionOFVI converges may inferior solution converged PFVI bestpolicy respect given set options poor.Corollary 1. Let , > 0, K, p, dmin 1, , (X). Given V0 B(X, VMAX ),A2(, ) (Assumption 2) A3( = 0, dmin , = 0, , j = 0) (Assumption 3) hold,exist positive integers n OFVI executedLp, (K ) Lp, ( ) +2 dmin 1/pC bp, (TF, F) +(1 )2 ,1/p+ dmin (K+1)!2 V V0(20)(1 )2holds probability least 1 , optimal option policy respectgiven options O.First notice Corollary 1, upper bound respect loss optimalpolicy (over primitive actions). bound loss Corollary 1 depends fourterms,1. first term controlled error optimal policy bestpolicy respect given options O,2. second term controlled option policy future state concentrability coefficient C, inherent bellman error bp, (TF, F),3. third term simply estimation error term (which controlled amountsampling done OFVI),4. last term convergence error controlled dmin (K+1) .dmin > 1 convergence rate OFVI significantly faster PFVI,loss term Lp, ( ) may large given option set cannot represent sufficientlygood policy.Although abstraction setting fast convergence rate, quality policiesproduced depends best possible option policy derived given set options.policy poor, policy produced OFVI also poor. nextsubsection, try overcome limitation augmenting set primitive actionsinstead discarding them.3.2.2 Augmentation Sparsely Scattered Temporally Extended ActionsExperimental results demonstrated well placed temporally extended actions often improve convergence rate planning (Precup et al., 1998). would likedescribe conditions sparsely scattered temporally extended actions cause fasterconvergence.following theorem gives bound OFVI environments sparsely distributedtemporally extended actions.390fiApproximate Value Iteration Temporally Extended ActionsCorollary 2. Let , > 0, , 0, K, p, d, j 1, 0 Z K, , (X).Suppose A2(, ) (Assumption 2) A3(, d, , , j) (Assumption 3) hold. GivenV0 B(X, VMAX ), first Z iterates {Vk }Zk=0 produced algorithm pessimistic(i.e., Vk (x) V (x) x X), exist positive integers nOFVI executed,Lp, (K )2C 1/p (bp, (TF, F) + ) +(1 )2 ,1/p 2 kV V k0K+1+(1)(d1)bZ/jc+(21)(1 )2holds probability least 1 j = j + 1.=Notice abstraction loss Lp, ( ) disappears special case VMVM . improvement convergence rate first Z pessimistic iteratessmall penalty appears approximation error term due exploitation optimal temporally extended actions. convergence rate Corollary 2 drivenK+1+(1)(d1)bZ/jc K+1 , demonstrating OFVI converge faster PFVI.Notice j large, meaning take timesteps visit ,d ,convergence rate slower j small. means convergence improvementmay less dramatic temporally extended actions sparse. j = 1,convergence rate controlled K+1+(1)(d1)Z K+1 .4. Generating Options via LandmarksOne limitation planning options options typically need designedexpert. section, consider one approach generating options automatically.approach similar spirit successful FF-Replan algorithm (Yoon, Fern, &Givan, 2007), plans deterministic projection target MDP. algorithmreplans whenever agent enters state part current plan. However,unlike FF-Replan, approach scalable plan globally entiresystem.specifically, assume access simulator SM target MDP =cbhX, A, P, R, simulator SMc relaxed MDP = hX, A, P , R, deterministic transition dynamics. Given state x option Ox , simulator returnsdiscounted cumulative reward R executing option, duration optionsexecution , termination state y.c deterministic transition probabilities, dynamics captured diSincerected graph G = hX, Pbi. Furthermore, R specifies reward associated edge.two actions transition state x state y, maximum rewardactions associated edge (x, y) G. denote maximum reward pathx X g X pG (x, g) length maximum reward path |pG (x, g)|.Throughout section assume rewards non-positive (i.e. bound[RMAX , 0]). reason stochastic shortest path problems undefinedMDP contains positive reward cycles, however, experiments relaxassumption.391fiMann, Mannor, & Precup^xl4l6l5Optimal TrajectoryOptimal Landmark TrajectoryLandmark Trajectoryw/Local Plannerl3l2l1(a)l4xl2l7gl8l5l6l7gl8Optimal TrajectoryNoise-Free Landmark TrajectoryLandmark Trajectoryw/Local Plannerl3l1(b)Figure 1: trajectory state x state g. Error introduced planning policylandmark options rather following optimal policy. (a) determinc, errors caused landmarks exactlyistic relaxationoptimal trajectory local planner taking maximum reward pathone landmark another. (b) stochastic target problem , errorsintroduced noise, causes agent reach states nearbylandmark states path goal.392fiApproximate Value Iteration Temporally Extended Actionsc computationally efficient planning algorithmspurpose introducingknown minimum cost path problems (Dijkstra, 1959; Hart, Nilsson, & Raphael,1968), equivalent maximum reward path planning problems providedc reasonable approximation ,positive reward cycles. Thus,c. assume efficient localdynamically generate options planningplanner P exists G.However, large directed graphs, even called efficient algorithmscomputationally expensive. Thus, assume P given maximum planning horizond+ 1.Recent work finding minimum cost paths large graphs shown pathsfound efficiently introducing landmarks (Sanders & Schultes, 2005),intuition used robotic control long time (Lazanas & Latombe, 1992).Definition 6. landmark set L finite, non-empty subset state-space.landmark single state, landmark set induces directed graphstate-space. Obtaining provably good landmark set generally hard problem (Peleg& Schaffer, 1989). assume landmark states given, couldc work Simsek Barto (2004)acquired analyzing dynamicsdemonstrations work Konidaris, Kuindersma, Barto, Grupen (2010).Given set landmarks, define corresponding set options, follows.Definition 7. Let 0 metric state-space. landmark set Llocal planner P, set landmark options, denoted O, contains one optionol = hIl , l , l landmark state l L,1. Il = {x X||P(x, l)| d+ } initialization set,2. l (x) = P(x, l) policy x X,1 (x, l) x/ Il3. l (x) =defines termination probabilities state0 otherwisex X.c,words, landmark options result planning deterministic MDPterminate vicinity landmark reached. landmark lsoption executed states reaching l graph would take lessd+ timesteps. discovered, options executed target MDP .denote number valid landmark-option pairs L. Note principle,landmarks might reachable within given planning horizon.idea plan using set landmark options. achieve this, requirelocal planner derive path least one landmark state every stateX:Assumption 4. x X exists l L |P(x, l)| d+ .deterministic MDP, starting landmark state, possible avoid visitingnon-landmark states (Figure 1a). case, possible ignore states393fiMann, Mannor, & Precupplan entirely based landmark states. However, stochastic MDPs, landmark optionsalways terminate landmark states. solve problem allowing landmarkoptions terminate near landmark states (Figure 1b).Landmark-based options used directly OFVI alternatively usedcreate new AVI algorithm maintains estimates value functionfinite number landmark states therefore avoids explicit function approximation.section, discuss approaches analyze convergence properties.4.1 Landmark-Based Approximate Value IterationLandmark-based Approximate Value Iteration (LAVI), Algorithm 2, belongs familyAVI algorithms. takes arguments: (1) K number iterations perform, (2)landmark set L, (3) initial guess V0 value function V states L, (4)number times sample landmark-option pair updates m, (5)simulator S. output, algorithm produces value estimates landmark states L.Algorithm 2 Landmark-based AVIRequire: K, L, V0 , m,1: k = 1, 2, . . . , K2:l L3:ol Ol(j)4:(Rl,o , (j) , (j) ) S(l, ol ) j = 1, 2, . . . ,5:end(j)1 Pm(j) (V(j)6:Vk (l) maxk1 , )j=1 Rl,o +oOlend8: end9: return VK7:Unlike basic VI, LAVI scales large infinite MDPs estimates valueslandmark states, time avoiding use complicated functionapproximation algorithms.target MDP deterministic dynamics, ensure optionsalways terminate landmark states. construct backups directly V (y)L. However, stochastic dynamics, may impossible guaranteeoptions terminate landmark states. less restrictive requirement assumeoptions terminate near landmark state high probability. notion closenessrequires metric : X X [0, ). small positive constantstate x X, defineL (x) = {l L | (x, l) < }(22)set landmark states closer x X. function(V, x) =maxlL (x) V (l) L (x) 6= ,0otherwise394(23)fiApproximate Value Iteration Temporally Extended Actionstakes consideration fact options necessarily terminate landmarkstates. distance termination state landmark l less ,plug V (l). Otherwise, assume value 0.Algorithm 2 returns K th estimate landmark values VK , definegreedy policy LAVI!ZXK (x) = arg max Rxo +Pto (y|x)(VK , y)dy .(24)oOxt=14.1.1 Analysisprovide theoretical analysis LAVI along two dimensions. (1) bound lossassociated policies returned LAVI compared optimal policy primitiveactions, (2) analyze convergence rate LAVI. save space, proofsdeferred Appendix C.c. Thus, error introduced stochasticitydeterministic MDPs, =environment. However, selection landmark states local plannerintroduce error.Definition 8. (Landmark Error) Given landmark set L, smallest Lx X l {l0 L | dbmin |P(x, l0 )| dmax }|pG (x,l)| V (l) ,VM(x)R+(25)LpG (x,l)ccoptimal value functionc Rp (x,l)called landmark error V cGc.discounted reward optimal path x llandmark error quantifies well chosen landmark states preserve maximumreward paths. Figure 1a, landmark error represented distancelandmarks optimal trajectory. definition assumes local planneroptimal, however, may convenient use suboptimal local planner.Definition 9. (Local Planning Error) Given local planner P landmark set L,smallest P x X l L P(x, l) < d+ , path P(x, l) generatedP satisfies|P(x,l)|RpG (x,l) + |pG (x,l)| VM(l)R+V(l)P ,(26)P(x,l)cccalled local planning error.local planning error quantifies loss due using local planner P insteadplanner returns maximum reward path x nearby landmark state.Figure 1a, local planning error represented trajectory (dashed line)transitions landmark landmark, follow shortest pathlandmarks.far, considered factors impact planning error environmentdeterministic. contains stochastic dynamics, need way bound error395fiValueMann, Mannor, & PrecupV*State-SpaceFigure 2: Optimal value function one dimensional state space landmarks depicted black circles. gray hourglass shapes around landmarks depictchange slowly aroundlandmark error. Assumption 5 requires VMlandmarks. value function may change rapidly regions landmarks.c. stochastic, landmark option mayfollowing policy plannedtrouble reaching particular state. Thus, need relax conditionoption always terminates landmark state.Assumption 5. (Locally Lipschitz around Landmarks) given metric(l) V (x)(x, l)state-space X l L x X, (x, l) < , VM0.change dramaticallyAssumption 5 says optimal value function VMstates close landmark states. assumption violated, options terminating arbitrarily close landmark state may unboundedly lower value respect. would lead unboundedly suboptimal landmark policies. Thus, Assumption 5VMcritical obtain meaningful bounds quality landmark policies. Notice, however,Assumption 5 applies near landmarks. Figure 2 depicts value functionchange rapidly regionsone-dimensional state-space illustrates fact VMstate-space close landmark.Assumption 5 allows us treat hypersphere radius around landmark stateone state. However, treating states introduces followingerror.Definition 10. (Local Lipschitz Error) define local Lipschitz error boundH = .local Lipschitz error largest possible difference value landmark l value state within -radius hypersphere centered l.essentially error introduced allowing landmark options terminate statewithin distance l.need define error caused following policy whose options plannedc .396fiApproximate Value Iteration Temporally Extended ActionsDefinition 11. (Stochastic Plan Failure) Let Assumption 5. stochastic planning failure smallest valuePr(R, ,y)SM (x,ol )[(y, l) > ]x X ol Ox l landmark associated ol .stochastic plan failure bounds probability path landmark statec terminate state far desired landmark stateplannedexecuted .c .also need way characterizing good approximationturns characterize relationship simple way.Definition 12. (Relaxation Error) relaxation errorbR = max VMVMVV,0,ccb optimal option policyc.optimal option policySurprisingly, relaxation error depends difference optimalc.policies primitive actions optimal policies optionsc good approximation , even dynamicspolicies similar valuesnoisy.Finally, sampling error controlled Algorithm 2. Increasing corresponds collecting samples consequently decreases .Theorem 2. (LAVI Convergence) Let > 0, (0, 1]. exists1LKm=Oln(S (1 )2 (1 dmin ))2probability greater 1 , Algorithm 2 executed K 1 iterations,greedy policy K derived VK satisfies!!V V02(L + P )(K+1)dminLL1, (K )+ R + + +,(27)dminbmin11dminmin= 11 + (1)(VMAX + (1 )H ) dbmin dmin mindmin1 minc , respectively.imum duration landmark-option pairproof Theorem 2 appears Appendix C. Surprisingly, Eq. (27) holdsinitial state distribution even though LAVI maintains value estimates states L.Although bound directly comparable bounds derived FVI, manycharacteristics bounds found works Farahmand et al. (2010)Mann Mannor (2014). example, first three terms right hand sideEq. (27) correspond approximation error, estimation error controlledlevel sampling, last term characterizes convergence behavior397fiMann, Mannor, & Precupalgorithm. FVI approximation error caused choosing function approximationarchitecture rich enough represent estimates value functioniteration. LAVI approximation error caused choosing landmark setsufficiently rich using planner cannot reliably reach vicinity landmarkstates.first four terms right hand side (27) describe worst case losspolicy derived LAVI K . first term corresponds error associatedchoice landmarks using suboptimal local planner. LAVI uses optimallocal planner, , P = 0. second term relaxation error (discussedbelow). controlled stochastic plan failure local Lipschitz error H .both, H small small. addition, longer duration options (i.e.,larger dmin ) decreases . sample error decreased increasing m.last term corresponds LAVIs convergence rate one keys LAVIsspeed. convergence rate dmin faster , convergence rate FVIprimitive actions (Munos & Szepesvari, 2008; Mann & Mannor, 2014). minimumduration dmin controlled minimum time landmark regions. convergencefaster landmarks provide greater mobility throughout state-space.closer,look last term Eq. (27) shows convergence error depends V0 VMLmax-norm landmark states L. last term represents factLAVI needs estimate value function landmark states.crelaxation error term R (27) determines good approximationgiven set landmark options. One naive bound R terms boundtransition dynamics respect primitive actions= max P (|s, a) Pb(|s, a)1(s,a)SAk k1 L1 norm, P transition probabilities , Pb statetransitions (degenerate probability distributions mass single next state)c. difficult show R 2D . However, bound generally extremely1c whereasconservative. R depends loss best option policiesinfluenced primitive actions states may never visited optionpolicies.total number samples used LAVI LKm, L number validlandmark-option pairs, K number iterations, number landmarkoption samples. hand, number samples used analysis Fitted Value Iteration depends complexity function approximation architecture(Munos & Szepesvari, 2008). MDPs complex value functions, Pinballdomain (see Section 5.2), complex function approximation schemes necessary getFVI work. hand, appropriate landmark set, LAVI simply skipcomplex regions value function.Notice executing policy derived output LAVI requires samplingsimulator. number samples needed depends discount factor .close 1, samples needed ensure policy behaves near-optimally.However, acceptable cost simulator relatively inexpensive comparedoverall cost planning.398fiApproximate Value Iteration Temporally Extended Actions4.2 Landmark-based Options Fitted Value Iterationalso possible consider using landmark-based options OFVI. referresulting case algorithm Landmark-based Options Fitted Value Iteration (LOFVI).Theorem 3. (LOFVI Convergence) Let > 0, (0, 1] set landmark-basedoptions. assumption A2(, ) (Assumption 2) A3( = 0, = dmin , = 0, , j = 0)(Assumption 3) hold, exists n m, probability greater1 , Algorithm 1 executed K 1 iterations, greedy policy K derived VKsatisfiesLp, (K )2(L + P )1 dbmin!+ R+2 dmin 1/pC bp, (TF, F) +(1 )2 ,+ dmin (K+1)1/p!2 VMV0, (28)(1 )2c ,dbmin dmin minimum duration landmark-option pairrespectively.Theorem 3 comparable Theorem 2 provides (p, )-norm bound rather(1, )-norm bound. consider case p = 1, compare Theorem 3Theorem 2. theorems share abstraction loss. Although convergencerates similar, LAVIs convergence term (Theorem 2) significantly smallerconvergence term OFVI. However, LOFVIs convergence depends explicit representation state-space LAVIs convergence depends values maintainedlandmark states.main advantage LOFVI LAVI potential lower sample complexityquerying policy. Although shown here, easy extend analysisOFVI produce action-value functions rather value functions. explicitaction-value function querying policy require additional samples.may important consideration simulator computationally expensive.4.3 Additional ConsiderationsOne barrier applying landmark-based options need access deterministicrelaxation target MDP local planning. many domains, deterministic modelmay already created domain experts. However, relaxation unavailable,might wonder one could acquired.One simple strategy obtaining deterministic MDP target MDP simulatorwould use frequently sampled next state. Algorithm 3 demonstrates onepossible implementation strategy. algorithm builds deterministic modelH : X R X new state-action pairs requested. takes argumentstarget MDP simulator SM state-action pair (x, a), number samples 1,partial deterministic model H returns 3-tuple containing reward rterminal state y. Furthermore, Algorithm 3 easily extended continuous statesetting matching states close together. cost Algorithm 3 depends399fiMann, Mannor, & PrecupAlgorithm 3 DREX (Deterministic RElaXation)Require: SM , x X, A, N, H : X R X1: H(x, a) 6= {Model entry (x, a).}2:= 1, 2, . . . ,3:(ri , , yi ) SM (x, a)4:endP5:arg maxi=1,2...,mj=1 I{yi = yj } {Assign frequent next state.}P16:rmI{y=}r{Average reward next state y.}i=17:H(x, o) (r, y)8: end9: return H(x, o)cost sampling primitive action times, chosen ensurehighest probability terminal state chosen high probability. approachmakes sense exists probable next state (region) state-actionpair. Nevertheless, may capture wide range real-world domains.used example deterministic relaxation local planning. Landmark options could implemented using alternative local planning algorithms, example,UCT (Kocsis & Szepesvari, 2006), Episodic Natural Actor Critic (Peters & Schaal, 2008),etc. approaches advantage applied directly targetMDP simulator. theoretical guarantees provided deterministic planners easilyadapted black box planners whenever local planning error bounded.However, focus analysis deterministic local planners brevity clarity.5. Experiments Resultscompared PFVI OFVI three different tasks: (1) optimal replacement problem(Munos & Szepesvari, 2008), (2) pinball domain (Konidaris & Barto, 2009), (3)eight commodity inventory management problem (Mann & Mannor, 2014).theoretical analysis previous sections characterizes convergence rates.However, also interested trade-off planning effort performance (i.e., cumulative reward) resulting policy. possible comparetime-to-solution, requires setting potentially arbitrary performance threshold. Choosing performance threshold unfairly bias judgment algorithm achievesbest overall performance-time trade-off. measure trade-off introducingfollowing statistic:V k (x)(x, k) = Pk,(29)i=1 tix start state used evaluation k refers number iterationsperformed algorithm far. = 1, 2, . . . , k value ti time secondsith iteration. Higher values desirable imply performanceless time spent planning.experiments, simulated options simulating individual primitive actions, selected option terminates maximum number timesteps (100400fiApproximate Value Iteration Temporally Extended Actions1816k =1||V Vk||11412k =2k =3108432101Deviation x234Figure 3: Optimal Replacement: Expected loss iterates V1 , V2 , V3 OFVI givenprimitive actions single option varying quality. Error bars represent1 standard deviation. Results averaged 20 trials.experiments) occurs. potentially places options-based planning methods disadvantage. Nevertheless, experiments provide strong evidence options speedconvergence rate planning, leads smaller time-to-solution.experiments implemented Java executed using OpenJDK 1.7 desktop computer running Ubuntu 12.04 64-bit 8 core Intel Core i7-3370 CPU 3.40GHz8 gigabytes memory.5.1 Optimal Replacement Taskoptimal replacement problem, compare PFVI OFVI hand craftedoptions. Due simplicity task, option generation unnecessary includetask comparison previous work. problem, agent selects onetwo actions K R, whether maintain product (action K) maintenance cost c(x)depends products condition x replace (action R) product new onefixed cost C. problem easy visualize single dimension,optimal value function optimal policy derived closed form (Munos &Szepesvari, 2008) compare PFVI OFVI directly optimal policy.used parameter values = 0.6, = 0.5, C = 30 c(x) = 4x (identicalused work Munos & Szepesvari, 2008) inverse meanexponential distribution driving transition dynamics task. Similar workMunos Szepesvari (2008), used polynomials approximate value function.results presented used fourth degree polynomials. optimal policy keepsproduct point x replaces product state equals exceeds x.OFVI condition, introduced single option keeps productpoint x = x + terminates state equals exceeds x. modifying ,controlled optimality given option. predicted analysis, adjustingaway 0 (i.e., reducing option quality), resulted slower convergence401fiMann, Mannor, & PrecupTime (s) per Iteration0.0060.0050.0040.0030.0020.0010.000PFVIOFVIFigure 4: Optimal Replacement: Time seconds per iteration PFVI OFVIoptimal replacement task averaged 20 trials.Optimal Replacement TaskConvergence w/V0 =0468102105040302010002||V Vk ||1PFVIOFVI4681046810||V Vk ||2||V Vk ||504030201000Convergence w/V0 = 75504030201000PFVIOFVI||V Vk ||1504030201000246Iteration # (k)8(a) Optimistic (V0 > V )Iteration # (k)(b) Pessimistic (V0 V )Figure 5: Optimal Replacement: Convergence rates PFVI OFVI OptimalReplacement Task. (a) initial value function estimate optimistic,difference convergence rates PFVI OFVI. (b)However, value function estimate pessimistic, OFVI converges fasterPFVI. Results averaged 20 trials.initial value function pessimistic (see Figure 3). optimistic initial value function,behavior PFVI OFVI almost identical.402fiPFVIApproximate Value Iteration Temporally Extended Actions2040OFVI0PFVI4681020400OFVI2V20304050602003040506002V46k=2V2446k=240400246810020204040468101002468108(a) Optimistic (V0 > V )203040506010 200 2 4 6 8 1030405060100 2 4 6 8 1020304050602003040506002468102468108024210V22086206k=58k=5k=10k=10(b) Pessimistic (V0 V )Figure 6: Optimal Replacement: Average iterates Vk (k = 2, 5, 10) PFVIOFVI (a) optimistic (b) pessimistic initial value functions.pessimistic value function OFVI converges significantly faster PFVI.Figure 4 shows OFVI takes slightly longer per iteration PFVI, OFVIconsiders primitive temporally extended actions. Figure 5a shows averageconvergence rates PFVI OFVI (with = 0), initial value function estimateoptimistic max-norm L1 -norm error. cases value functionsconverge almost identical rates predicted analysis. Figure 5b shows averageconvergence rates PFVI OFVI, initial value function estimate pessimistic.pessimistic initial value function, OFVI converges significantly faster PFVIpredicted analysis.Figure 6 compares average iterates Vk OFVI PFVI k = 2, 5, 10optimistic (Figure 6a) pessimistic (Figure 6b) initial value function estimates. solidblack line depicts optimal value function V . optimistic initial value functionbehavior PFVI OFVI qualitatively identical. However, pessimisticinitial value function, OFVIs second iterate qualitatively similar PFVIs fifth iterate.pessimistic initial value function estimate, even suboptimal options ableimprove convergence rates, though lesser degree = 0.403fiMann, Mannor, & PrecupFigure 7: Instance pinball domain used experiments. Black polygonsobstacles. large red circle target, smaller blue circlecontrolled ball.5.2 PinballPinball domain (Konidaris & Barto, 2009) agent applies forces control ball2-dimensional surface containing polygonal obstacles. agents goal directball goal region. Figure 7 depicts instance Pinball domain used experiments. state-space consists four continuous dimensions (x, y, x, y) correspondingcoordinates (x, y) ball velocity (x, y). Similar work Tamar, Castro, Mannor (2013), added zero-mean Gaussian noise velocities standarddeviation 0.03. discount factor = 0.95.pinball domain contains five primitive actions: (1) accelerate along X-axis, (2)decelerate along X-axis, (3) accelerate along Y-axis, (4) decelerate along Y-axis,(5) leave velocities unchanged. Since unclear create useful hand-codedoptions, decided compare PFVI LOFVI LAVI optionsgenerated. experimented randomly placed landmarks landmarks placedgrid. cases, one landmark manually placed goal state. Randomlyplaced landmarks uniformly sampled coordinates state-space. Gridlandmarks placed two-dimensional grid X coordinates statespace. landmarks corresponded states ball zero velocity.sampled landmark fell inside obstacle, new landmark sampledlandmarks corresponded valid states task.metric used determine distance two states ~x = (x, y, x, y)~x0 = (x0 , 0 , x0 , 0 ) givenpp(~x, ~x0 ) = (x x0 )2 + (y 0 )2 + (x x0 ))2 + (y 0 )2 ,(30)404fiApproximate Value Iteration Temporally Extended Actions9015000Time (s) per Iteration8050000500020Iteration #253035(a))96(12096)VI015LAVI1030I(1540FV050LO150006010LAVI(196)LOFVI(196)PFVI1000070PFPerformance10000(b)Figure 8: Pinball: Comparison planning PFVI, LOFVI, LAVI 196 landmarks (+1 goal) arranged grid Pinball domain. (a) Performancepolicies derived iteration PFVI, LOFVI, LAVI. Shaded regions represent 1 standard deviation. (b) Time seconds computeiteration PFVI, LOFVI, LAVI. Results averaged 20 trials., places less emphasis differences velocity differencescoordinates. chose = 0.01 experimentation.PFVI LOFVI, tried many different function approximation architecturesincluding Radial Basis Function Networks (RBF), Cerebellar Model Arithmetic Computer(CMAC), linear regression various features, found experimentationnearest neighbor approximation fast able capture complexityvalue function. LOFVI, used one-nearest neighbor approximation N = 1, 000states sampled iteration. PFVI, averaged value states within 0.1radius queried state N = 30, 000 states sampled iteration. Without30, 000 samples, PFVI either failed solve task produced policy solvedtask unreliably. PFVI LOFVI used L = 5 samples state-option pair.chose settings resulted strongest performance PFVILOFVI.landmark options, experimented different numbers landmarks.simplicity selected landmarks formed uniform grid pinball domains Xand -coordinates. choosing grid sizes 10 10, 12 12, 14 14, numberlandmarks 100, 144, 196, respectively. fewer 100 landmarks performanceLOFVI LAVI degraded significantly. radius hypercube around landmarksset = 0.03, landmark options available state correspondedlandmarks distance less 0.2 balls current state, approximates local planning horizon d+ . brevity, consider results landmarkoptions arranged grid. Randomly selected landmarks gave qualitatively similar resultsslightly higher variance.Figure 8a compares performance PFVI, LOFVI, LAVI pinball domain196 landmarks (+1 landmark goal). six iterations, LOFVI405fiMann, Mannor, & PrecupPerf. / Cumulative Time103LAVI(196)LOFVI(196)PFVI102101100101102051015Iteration #202530Figure 9: Pinball: Performance cumulative time seconds received policiesiteration. Higher better. Results averaged 20 trials.Time-to-Solution (in Minutes)302520151050PFVILOFVILAVIFigure 10: Pinball: Cumulative time-to-solution minutes PFVI, LOFVI, LAVIaveraged 20 trials. LAVI smallest time-to-solution.406fiApproximate Value Iteration Temporally Extended ActionsLAVI able solve task. However, PFVI takes 25 iterations solvetask. Figure 8b compares time per iteration PFVI, LOFVI, LAVI pinballdomain. PFVI highest time per iteration cost. needed uselot samples per iteration PFVI solve task. Notice LAVI less expensiveLOFVI. due fact LAVI needs sample landmark states,whereas LOFVI samples larger number states sampled iteration (althoughless PFVI).Figure 9 compares performance cumulative time spent planning. PFVIpoor performance time trade-off iteration takes time LOFVILAVI, takes many iterations achieve high performance. LOFVI LAVIachieve similar performance, LAVI higher score due fact spends lesstime planning per iteration. Figure 10 compares time minutes PFVI, LOFVI,LAVI produce policy achieves performance greater 8,000. PFVI takeslonger LOFVI LAVI, converges slowly uses expensive functionapproximation step iteration. Despite fact LOFVI LAVI uselandmark options, LAVI faster LOFVI, LAVI approximatesvalue function around landmark states.5.3 Inventory Management Taskbasic inventory management task, objective maintain stock onecommodities meet customer demand time minimizing ordering costsstorage costs (Scarf, 1959; Sethi & Cheng, 1997). time period, agentgiven opportunity order shipments commodities resupply warehouse.created inventory management problem agent restocks warehousen = 8 different commodities (Mann, 2014). warehouse limited storage (500units experiments). Demand commodity stochastic dependstime year. Orders placed twice month total 24 order periods perdemand cycle.state h, xi inventory management problem vector specifying timeyear vector x specifying quantity commodity (denoted xi ithcommodity) stored warehouse. timestep, demand vector drawnsampling demand commodity independently normal distributionmean depended time year (see Table 1 parameters used experiments).demand vector subtracted quantity commodity storedwarehouse. commodities negative subtracting demand vector,agent receives unmet demand penaltyPPnub + us ni=1 [xi ]i=1 [xi ] < 0 ,pud (x ) =(31)0otherwise ,ub = 2 represents baseunmet demand cost, us = 10 represents per unitx x < 0unmet demand cost, [x] =.0 otherwisedemand subtracted, agent given opportunity either resupplywarehouse order nothing. set possible primitive actions n501 = 8501 . Searchingset would intractable. Therefore, designed smaller set primitive actions.407fiMann, Mannor, & PrecupTable 1: Commodity PropertiesCommodity Index12345Unit Cost (os,i )1312 0.5Demand Peak (Month)137 10 8.5Demand Std. Deviation21232Max. Expected Demand 16 10 20 4 10611229711120815.5216primitive actions available agent ability order nothing ordersingle commodity quantities 25 maximum size warehouse.resulted (8 (500/25)) + 1 = 161 primitive actions. action = hi, qi definedcommodity index quantity q. cost order defined0q = 0 ,poc (i, q) =(32)ob + os,i q otherwise ,ob = 8 base ordering cost os,i (see Table 1) commodity dependentunit cost. new state steps forward half month future quantitiesinventory updated remove purchased commodities add orderedcommodities (if any). agent orders fit inventory,portion order fits warehouse kept (but agent chargedcomplete order). end decision step, agent receives negativereward (i.e., cost)R(x, a) = (pud (x ) + poc (i, q)) ,(33)negative sum unmet demands order costs dependinginventory levels x, demand , action = hi, qi. storagecost, limit inventory forces agent make careful decisioncommodities order. discount factor = 0.9.high dimensionality state space (1 dimension commodity 1 dimension time) required function approximation architecture good generalizability.tried many different function approximation architectures settling Radial Basis Function networks (RBFs) grid 1-dimensional radial bases. limitingdimensionality radial bases able achieve good generalization performancesamples. divided state space 24 time periods, value function approximation implemented 24 RBFs. number bases per dimension25 basis widths controlled = 0.1. Throughout experimentssampled n = 1000 states iteration sampled option = 20 times.5.3.1 Hand-crafted Optionsdifficult design good policy problem hand. Inventory managementreceived lot attention operations research community. One mainfindings optimal strategy large class inventory management problemsbelong simple family policies called (s, S)-policies (Scarf, 1959). problemstationary demand distribution single commodity, (s, S)-policy orders enoughstock bring inventory level whenever inventory level falls408fiApproximate Value Iteration Temporally Extended ActionsInventory Management Task80000LOFVI(100)OFVIPFVI7000100060002000ValueValue5000400030003000400020005000100060000700010000510Iteration #15800020(a) Optimistic (V0 > V )LOFVI(100)OFVIPFVI0510Iteration #1520(b) Pessimistic (V0 V )Figure 11: Inventory Management: Average value iterates produced LOFVI, OFVIPFVI. Results averaged 20 trials. Shaded regions represent 1standard deviation.orders new stock otherwise. inventory management task Markov demand,(s, S)-policies optimal demand state (Sethi & Cheng, 1997).problem described cleanly fit Markov demand setting,notion (s, S)-policies provides potential idea temporally extended action.Since high base order cost (Eq. (32) ob = 8) storage free, reasonablepolicy prefer make large orders whenever possible maximize numbertimesteps nothing ordered. One way encode prior knowledge providetemporally extended actions follow policy order nothing thresholdmet. addition primitive actions, provided OFVI 20 temporally extendedactions commodity. policy followed temporally extended actionsorder nothing terminate inventory level particular commodity fellconstant level (one 20 levels spanning 0 maximum storagewarehouse).Since know optimal value function problem, cannot compareiterates PFVI, OFVI, LOFVI ground truth. However, still examineiterates. Figure 11a shows average iterates produced PFVI, OFVI, LOFVIoptimistic V0 . case, see PFVI, OFVI, LOFVI appeardecrease similar rates. Figure 11b shows average iterates produced PFVI, OFVI,LOFVI pessimistic V0 . see OFVI LOFVI increase values(toward V ) quickly PFVI. LOFVI appears converge different solutionPFVI OFVI, probably due fact landmark options usedexperiment may powerful actions available PFVI OFVI. Notecomparison value function produced LAVI straightforwardproduce approximation states (only landmark states).409fiMann, Mannor, & Precup7000700060006000DiscountedCumulative RewardDiscountedCumulative RewardInventory Management Task500040003000LOFVI(100)LAVI(100)OFVIPFVI1-Step GreedyRand200010000510Iteration #15500040003000LOFVI(100)LAVI(100)OFVIPFVI1-Step GreedyRand20001000200(a) Optimistic (V0 > V )510Iteration #1520(b) Pessimistic (V0 V )Figure 12: Inventory Management: Performance policies iteration LAVI,LOFVI, OFVI PFVI starting state inventory. LAVI settles near-optimal policy single iteration. Results averaged20 trials. Shaded regions represent 1 standard deviation.considered performance policies derived iterates PFVI OFVI.V0 initialized pessimistically, Figure 12b shows OFVI quickly convergesbetter policy PFVI. takes PFVI several iterations equally successfulpolicy found. compared policies policy selected uniformly randomavailable primitive actions (denoted Random) policy selects actionimmediate lowest cost (denoted 1-Step Greedy). initial state setbeginning year zero inventory. case V0 optimisticallyinitialized, Figure 12 shows performance PFVI OFVI quickly improve beyondRandom 1-Step Greedy policies, performance similar iterate.5.3.2 Landmark-Based OptionsLAVI, set = 20 (where controls number samples per state-option pair)experimentation showed value works reasonably well. Since state-spaceproblem large use generic graph-based planner, constructed heuristiclocal planner used deterministic instance problem transition closepossible landmark states. Given definition inventory management task,easy define deterministic model replacing samples Gaussian distributionsexpectation distributions. Given landmark l, current statelower l ith commodity, would order amount needed reach ithcommoditys quantity l plus expected demand ith commodity. currentstate higher l ith commodity, would place order commodity.Notice local planner efficient able make use entire set primitiveactions. used Euclidean distance set = 0.05 500 500 maximum410fi30600025VI0FVPF00)2(1LOLAVILAVI(1)200)0)100I(100FVLOFVI(1LOFVI20VI2FVPFR1000I151000(a))1000200015LAVI(130002000)4000I(15000FVTime (s) per Iteration7000PFVI1PerformanceApproximate Value Iteration Temporally Extended Actions(b)Figure 13: Inventory Management: (a) Comparison performance first lastpolicies derived PFVI, OFVI, LAVI. (b) Comparison time per iteration seconds. Results averaged 20 trials. Error bars represent 1standard deviation.Perf. / Cumulative Time104LAVI(100)LOFVI(100)OFVIPFVI1031021010510Iteration #1520Figure 14: Inventory Management: Comparison performance cumulative timeseconds (higher better). LAVI achieves higher performance time investedeven compared LOFVI also uses landmark options. Results averaged 20 trials.inventory level d+ = . reason set d+ = successfully managinginventory requires making large jumps state-space (e.g., going 0 inventorymaximum inventory levels) single timestep.Figure 13a compares performance policy selects primitive actions uniformlyrandom policies derived first last iterates PFVI, OFVI, LOFVI,411fiMann, Mannor, & PrecupTime-to-Solution (s)10080604020)00(1I(1FVLOLAVI00)FVPFVI0Figure 15: Cumulative time-to-solution (with performance threshold 5,500) averaged10 independent trials PFVI, OFVI, LOFVI 100 landmarks, LAVI100 landmarks. LAVI smallest time-to-solution.LAVI. task, LAVI outperforms PFVI OFVI first iteration,LOFVI ultimately higher performance. Figure 13b compares time per iterationseconds PFVI, OFVI, LOFVI, LAVI. task, LAVI significantly fasterPFVI, OFVI, LOFVI. Figure 14 shows LAVI achieves better performance-timetrade-off iterations.Figure 15 shows cumulative time seconds derive policy achieves performance 5,500 averaged 10 independent trials. OFVI, uses mixtureoptions primitive actions, slightly faster time-to-solution PFVI, despiteevaluate primitive temporally extended actions iteration. Thus,OFVIs faster time-to-solution due faster convergence rate. LOFVI LAVIsmaller time-to-solution PFVI OFVI. Although approximatelynumber primitive actions landmark options initializedstate, LOFVI LAVI faster PFVI converge faster. Finally, LAVIfaster LOFVI uses computationally efficient estimate value functionbased landmark states, whereas LOFVI (1) uses potentially expensivefunction approximation architecture (2) make explicit use landmarkstate locations.5.4 Experimental Domains versus Theoretical Assumptionsuseful exercise consider theoretical assumptions map onto experimentaldomains.First, consider concentrability coefficient (Assumptions 1 2). Unfortunately,cannot estimate concentrability coefficients domains dependsupremum norm sequences policies. However, concentrability coefficients412fiApproximate Value Iteration Temporally Extended Actionsgenerally smaller stochastic domains, every policy broad future statedistribution (meaning long-term value state depends little bit lotsstates). Along line reasoning, expect optimal replacementinventory management problems might smaller concentrability coefficientspinball domain. Consistent hypothesis, found algorithmsmuch sensitive sampling distribution pinball domain twodomains.addition, Lemma 1 suggests options concentrability coefficient alwaysless (or equal to) concentrability coefficient primitive actions. also supported experiments pinball domain, PFVI much sensitivesampling distribution LOFVI LAVI.Second, let us consider Assumption 3 respect experimental domains. Assumption 3 deals sparseness options state-space. Informally, saysnearly-optimal temporally extended actions abundant state-space.landmark options, holds true pinball inventory management domainsdefinition, result LAVI LOFVI achieve fast convergence. hand-craftedoptions optimal replacement inventory management domains, hand,may terminate immediately states long duration others. mayaccount landmark-based options resulted faster convergence experiments.consider assumptions definitions analysis LAVI.locally Lipschitz assumption probably holds inventory management domainhigh stochasticity generally smooths value function. pinball domain,regions state-space probably Lipschitz due complex obstacles.Two states opposite side obstacle relatively close extremelydifferent values. However, LAVI needs locally Lipschitz assumption hold aroundlandmark states. Since majority state-space pinball domain probablysmooth, local Lipschitz assumption likely holds landmark configurationsexperiments.Landmark error decreases add landmark states. pinball inventory management domains task could solved landmarks. However,surprised pinball inventory management domains 100 landmarks needed learn reasonable solutions. Furthermore, pinball domain,landmark states chosen large effect performance. Thus gridbased layout landmarks produced slightly better policies uniformly sampledlandmark states. suggests landmark error could made small experimental domains small number landmarks.Local planning error error due using imperfect deterministic planner.inventory management task, local planning error 0, ableuse deterministic model specify order get landmark state.pinball domain, local planning error may large used greedy algorithmselect actions move agent straight line toward landmark. localplanner fail ball needs pushed around corner, worked wellexperiments. suggests local planning error may small average.Stochastic plan failure occurs noise environment prevents landmark optionterminating sufficiently close designated landmark state. analysis413fiMann, Mannor, & PrecupLAVI, even small probability stochastic plan failure caused large increaseapproximation error. due possibility failing reach landmark may leaveagent non-recoverable state. However, pinball (Konidaris & Barto, 2009)inventory management (Mann & Mannor, 2014) domains, agent eventually recovermistake. stochastic plan failure generally much smaller consequencepredicted (27).relaxation error quantifies much worse best landmark option policytarget MDP deterministic relaxation. Despite fact pinballdomain inventory management domain significant stochasticity, LAVILOFVI able derive good policies. Unfortunately, clear measurerelaxation error.6. Discussionproposed analyzed Options Fitted Value Iteration Landmark-based Approximate Value Iteration. algorithms longer temporally extended actions resultfaster convergence smaller approximation error. OFVI, analysis showsvalue function estimate pessimistic respect optimal value function,convergence rate OFVI take advantage temporally extended actionssmaller effective discount factor options minimum duration. Furthermore,options improve convergence even suboptimal spread throughoutenvironment. fact, LAVI LOFVI converge faster landmark-based optionsspread environment.Approximate Modified Policy Iteration (Scherrer, Ghavamzadeh, Gabillon, & Geist,2012) related planning options sense modified policy iteration performsbackups d-step rollouts (rather 1-step rollouts) greedy policy. However,planning options flexible options termination conditionsdepend state time. Furthermore, analysis work Scherrer et al.(2012) point improvement convergence rates increasing lengthrollouts used perform backups.Special representations factorization tasks state action spacesexploited achieve faster planning (Hoey, St-Aubin, Hu, & Boutilier, 1999; Barry,Kaelbling, & Lozano-Prez, 2011). However, many problems simulator already existssimulators convenient way represent task. fact, work Dietterich,Taleghan, Crowley (2013) presents example simulator representingtask computationally efficient, exact inference factored representationtask computationally intractable. Therefore, ability plan black box simulatorsgenerally applicable requiring problem special representation.focus planning black box simulator.Option discovery investigated extensively, many approaches explore heuristics related finding useful subgoals (McGovern & Barto, 2001; Simsek & Barto, 2004;Stolle & Precup, 2002; Wolfe & Barto, 2005), similar spirit finding landmarks.approaches, however, emphasis finding useful subgoals.analysis provides instead way use arbitrary set landmarks, quantifyquality obtained policy. less careful approach selecting landmarks,414fiApproximate Value Iteration Temporally Extended Actionsuse local planning deterministic problem, scalability LAVIsignificantly better, especially high-dimensional problems.Given collection policies, works Comanici Precup (2010) Mankowitz,Mann, Mannor (2014) investigated creating useful options applying optioninterruption. methods rely given collection policies.make use deterministic local planner instead, gives LAVI LOFVIflexibility since restricted predefined policies.clarity, focused learning good approximation optimal valuefunction showed resulting greedy policy bounded loss. However,practice cannot directly obtain greedy policy value function. mustapproximated samples. However, results easily extended handlearguments used prove Thm. 3 work Munos & Szepesvari, 2008approximating action-value function (Farahmand, Ghavamzadeh, Szepesvari, &Mannor, 2008).brevity generality, presented analysis convergence behaviorAVI algorithms (not computational complexity). possible using boundsTheorem 1 Theorem 2 obtain bounds computational complexity. However,two critical decisions needed determine computational complexity. firstcomputational complexity sampling options. example, smart grid simulatorGridlab-d efficiently simulate actions multiple timescales (Chassin et al., 2014).hand, simulators may require sampling outcome sequenceprimitive actions. second decision involves choice function approximation,vary widely.Planning options important setting options natural modelsettings decisions made irregular time intervals. Furthermore, algorithmsplan options potentially make use many algorithms proposed learning options data (Iba, 1989; Mannor et al., 2004). However, algorithms producegood options planning open question, since majority previous researchconsidered generating options exploration. analysis landmark-based optionshelps address question landmark-options similar spirit many existing techniques option generation, skill chaining (Konidaris & Barto, 2009)bottleneck discovery (McGovern & Barto, 2001; Simsek & Barto, 2004).Options may benefits planning besides improving convergence rate(and thus overall speed planning). example, options may enable planningalgorithm skip regions state space highly complex dynamics withoutimpacting quality planned policy. particular, LAVI models valuefunction around landmark states, allows perform well tasksvalue function highly nonlinear (such Pinball domain Section 5.2). partiallyobservable environments, options may exploited decrease uncertainty hiddenstate skipping regions state space large observation variance,testing hypotheses hidden state. Options may also play important rolerobust optimization, dynamics temporally extended actions knowngreater certainty dynamics primitive actions. fact, macro-actionsalready used planning partially observable environments success (He,415fiMann, Mannor, & PrecupBrunskill, & Roy, 2011). However, results consider narrow definitiontemporally extended actions excludes closed loop policies options.focused generalizations value iteration, many algorithms planning benefit options. example, approximate policy iteration(Lazaric, Ghavamzadeh, & Munos, 2010; Scherrer et al., 2012) may also exploit optionsspeed convergence. Another interesting family planning algorithms sparse sampling framework, estimates value single state using either breadth-first-likesearch (Kearns, Mansour, & Ng, 2002) rollouts (Kocsis & Szepesvari, 2006). Optionsmay enable sparse sampling algorithms derive higher quality policies smallerdependence horizon.option generation, assumed existence efficient local planner. manyapplications may much easier create and/or learn efficient local plannerglobal planner. especially true domains local dynamics tend remainsimilar throughout large regions environment (Brunskill, Leffler, Li, Littman, & Roy,2008).Acknowledgmentswork funded part NSERC Discovery grant program EuropeanResearch Council European Unions Seventh Framework Programme (FP/20072013) / ERC Grant Agreement n.306638.Appendix A. Proof Proposition 1Proof. (of Proposition 1) proposition follows Theorem 1. see why, considerZ 0, least one optimal policy defined primitive actions satisfiesAssumption 3 values = 0, = 1, = 0, arbitrary (X), j = 0.case, Theorem 1 gives us following high probability (> 1 ) bound = 0:||V V K ||p,+1/p2C (bp, (TF, F) + ) +(1)2 ,1/pZ2kV V0 k(1)d+ + KZ+1(1)21/p 2kV V0 k1/p2K+1Cb(TF,F)++(1)2 , p,(1)2,replace C, C, since Lemma 1 tells us C, C, .Appendix B. Proof Theorem 1 Supporting Lemmasappendix, prove Theorem 1 provide sufficient values arguments nm, n controls number states sampled iteration controlsnumber samples simulated state-action pairs.proof Theorem 1 similar structure Thm. 2 work Munos &Szepesvari, 2008 several changes due differences options primitiveactions. proof Theorem 1 following structure:416fiApproximate Value Iteration Temporally Extended Actions1. Appendix B.1, derive Lemma 2, bounds number states nnumber samples state-option pair necessary achievehigh-probability bound error single iteration AVI. Lemma 2 useddirectly proof Theorem 1 supporting lemmas.2. Appendix B.2, derive Lemma 6, provides pointwise bound losspolicy produced OFVI K 1 iterations. start derivingupper bound policys pointwise loss based value functions pointwiseerror (Lemma 3). use Lemma 3, need bounds value function estimatespointwise error. derive upper lower bounds pointwise error Kiterations (Lemma 4). Lemma 6 puts Lemmas 3 4 together exploits optionsfollow near-optimal policy get tighter bound estimatevalue function pessimistic. technical reasons, important next partproof (Appendix B.3) coefficients pointwise bound sum 1.Therefore, introduce coefficients k k = 0, 1, 2, . . . , K showindeed sum 1 (Lemma 5).3. Appendix B.3, convert pointwise bound derived Appendix B.2Lp -norm bound, well as, deriving convergence behavior OFVI (Lemma 8).Lemma 7 shows concentrability assumption (Assumption 2) allows usreplace error according future state distribution error accordingsampling distribution. use Lemma 7, well as, Assumption 3 proveLemma 8.4. Appendix B.4 proves Theorem 1. proof uses Lemma 2 select numbersamples needed ensure error K 1 iterations low highprobability. apply Lemma 8 bound error K iterations.moving onto proofs, first introduce additional notation. contrastdiscounted termination state probability density Pe, denote undiscountedprobability option executed state x X terminate subsetstates XXP (Y |x) =Pto (Y |x) .(34)t=dminRRNotice (34) undiscounted Peo (y|x)dy < P (y|x)dy = 1. optionpolicy : X O, denote Pe discounted termination state probability distribution executing state (executing option termination)undiscounted termination state probability distribution P analogously. Noticeoption policy, alsoXP (Y |x) =Pt (Y |x)(35)t=dminX x X.417fiMann, Mannor, & PrecupNotice f option, option policy, policy primitive actionswrite discounted termination state probability densityPef (Y |x) =Xt=dminPtf (Y |x)(36)X x X. compose options o1 , o2 , . . . om , write Peo1 o2 ...om =Peo1 Peo2 . . . Peom , writePeo1 o2 ...om (Y |x) =Xt=mdmin(P o1 P o2 . . . P om )t (Y |x)(37)X x X.assume throughout supplementary material refer optimalpolicy , policy primitive actions. contains set primitive actionsA, fixed point SMDP Bellman operator MDP Bellman operatoroptimal value function V . Thus equivalent .B.1 Bounding Number Samplesfollowing lemma used Theorem 1 select sufficient values parameters nensure per iteration error less > 0 probability least1 .Lemma 2. Letp SMDP option set O, F B(X; VMAX ) bounded functionspace 81 4 , p -covering number bounded N , V F, p fixed positive integer,V 0 result single iteration OFVI derived (13) followed (8)., > 0,0V TV bp, (TV, F) +p,holds probability least 1 provided8VMAX 2pn > 128(log(1/) + log(32N ))(38)8(RMAX + VMAX )2(log(1/) + log(8n|O|)) .(39)2proof Lemma 2 follows proof Lemma 1 work Munos &Szepesvari, 2008 simply replacing MDP Bellman operator SMDP Bellmanoperator everywhere occurs, noting must sample |O| options rather|A| primitive actions. omit proof brevity.m>B.2 Bounding Pointwise Propagation Errorinterested bounding loss due following policy K derived OFVIrather following optimal policy . use factkV V K kp, V V + V V K(40)p,418p,fiApproximate Value Iteration Temporally Extended Actionstriangle inequality focus bounding kV V K kp, , loss duefollowing policy K produced OFVI instead optimal option policy .OFVI value-based method, directly improve policyiteration. Instead performing iterations improves estimateoptimal optionKpolicys value function V . Thus, need relate loss V V p, qualityfinal value function estimate VK produced OFVI algorithm. followinglemma develops pointwise relationship V V K V VK .Lemma 3. Suppose OFVI executed K iterations iterates Vk k = 0, 1, 2, . . . , K.Let optimal policy respect given options K greedy optionpolicy respect K th final iterate VK ,V V K (I PeK )1 Pe PeK V VK ,(41)identity matrix.Proof. Since TV = V TK V K = V K , getV V K=======TV TK V KTV VK + VK TK V KPe V VK + VK TK V KPe V VK + VK TVK + TVK TK V KPe V VK + TVK TK V KPe V VK + TK VK TK V KPe V VK + PeK (VK V K )Pe V VK + PeK VK V + V V K ,initial equality based fact V fixed point V Kfixed point TK . first step obtained inserting (T VK +T VK ) = 0.second step pulls discounted transition probability kernel Pe subtracting VKTV . Since backups performedpolicy , immediate rewardterms canceled, leaving Pe V V K . third step inserts (TVK +TVK ) =0. Since VK TVK , obtain fourth step dropping terms VK TVK ,vector whose elements less zero. obtain fifth step noticingsince K greedy policy respect VK , TVK = TK VK . sixth step pullsPeK subtracting TK V K TK VK . seventh step inserts (V +V ) = 0.manipulate inequalitye V VK + PeK VK V + V V KV V K PV V KPe PeK V VK + PeK V V KV V K PeK V V KPe PeK V VKPeK V V KPe PeK V VK ,identity matrix, V V K terms left hand side.Since (I PeK ) invertible inverse monotone operator, getV V K (I PeK )1 Pe PeK V VK ,419fiMann, Mannor, & Precuprelates (V V K ) (V VK ).Lemma 3 provides us relationship quality estimatesvalue function quality resulting policy, need bound quality valuefunction estimates. iteration k = 1, 2, . . . , K OFVI results errork = TVk1 Vk ,(42)induced fitting process. One main issues proof Theorem 1determine fitting errors propagate iterations.following lemma helps bound error V VK developingpointwise upper lower bounds V VK show error propagates recursivelyiteration.Lemma 4. Suppose optimal policy respect options O, OFVI executedK iterations iterates Vk k = 0, 1, 2, . . . , K iteration errors k k =1, 2, . . . , K defined (42), following upper boundVVKKXPeKkk=1Kk + Pe(V V0 ) ,(43)following lower boundV V K K +K1Xk=1PeK1 PeK2 . . . Pek k + PeK1 PeK2 . . . Pe0 V V0 .(44)Proof. First derive upper bound V VK . equation (42),V Vk ===TV TVk1 + kV Vk1 + Vk1 TVk1 + kTV Vk1 + kPe V Vk1 + k .recursing inequality, obtain upper boundV VKKXPeKkk=1Kk + Pe(V V0 ) .derive lower bound V VK . Let k denote greedy policyrespect Vk . (42),V Vk ===TV TVk1 + kTV Tk1 V + Tk1 V TVk1 + kTk1 V TVk1 + kPek1 V Vk1 + k .420fiApproximate Value Iteration Temporally Extended Actionsrecursing inequality, obtain lower boundV VK K +K1Xk=1PeK1 PeK2 . . . Pek k + PeK1 PeK2 . . . Pe0 V V0 .Lemma 3 gives relationship quality value function estimatesquality resulting greedy policy, Lemma 4 gives upper lower bounds valuefunction estimates. next step combine results lemmas derivepointwise error bound V V K .make use following definition deriving point-wise error bound.lambda values used simplify notation, also use factcarefully designed sum 1.Definition 13. = 1, 2, . . . , , letk =1(Kk)1 K+1(45)k = 0, 1, . . . , K.following lemma shows k values sum 1.PLemma 5. values defined (45) satisfy Kk=0 k = 1 .Proof.PKk=0 kPK1(Kk)=k=0 1 K+1PK1k= 1K+1k=0Pk= 11K+1 Kk=0 (1 )= 11K+1 (1 K+1 )= 1 .ready derive point-wise error bound V V K .Lemma 6. Let Z {0, 1, 2, . . . , K}, k greedy policy respect k th iterateVk derived OFVI, option policy Q (x, (x)) V (x) x X,= dmin . A3(, d, , , j) (Assumption 3) true first Z iterates OFVIpessimistic (i.e., x X k {0, 1, 2, . . . , Z}, V (x) Vk (x)),difference V value option policy K returned OFVI boundedXKXV V Kk Pk,t |k | ,t=1 k=0k defined (45),=2(1 K+1 )(1 )3421,fiMann, Mannor, & PrecupPk,t1,hKZ P ZkP0kZhKk1=P+ (P K1 P K2 . . . P k )t Z < k < K21k=KV V0 k = 0k =+1kZkkZ<kK.Proof. place upper bound (43) lower bound (44) relationshipVK V . use information bound differenceV K V . However, lemma, exploit pessimism first Z iteratesoption policy achieve informative bound.iterate Vk pessimistic V Vk lower bounded 0. upper bound,V Vk = V V + V Vk+ V Vk= + V TVk1 + k= + V Vk1 + Vk1 TVk1 + k+ V Vk1 + kPe (V Vk1 ) + (k + ) ,initial inequality inserts term (T V + V ) = 0. first step followsfact following single decision following produces-optimal policy, V V . second step due definition k(42). third step inserts (T Vk1 + Vk1 ) = 0. fourth step removesVk1 TVk1 sum two terms less equal zero (sinceupdates using max operator, updates using policy ). fifth finalstep pulls discounted transition probability kernel Pe .recursing inequality Z 0 times obtainZ=0VV0ZjZPZV VZ. (46)e(j + ) + PeV V0 1 Z Kj=1 Pcombining upper bound recursion (43) (46), obtain termsZKZePPeV V0 k = 0ZkKZeuk k =PPe(k + ) k = 1, 2, . . . , ZKkPekk = Z + 1, Z + 2, . . . , KV VK422KXk=0uk kfiApproximate Value Iteration Temporally Extended Actionsupper bounds difference V final iterate derived OFVI, VK .Now, since 0 lower bounds difference V first Z iterates OFVI,use 0 lower bound first Z iterations fill rest iterates(44). gives us terms0kZh0PeK1 PeK2 . . . Pek k Z < k < K 1 ,lk k =KKV VKlower boundsdifference VPVK | K(uk=0 k lk )k .Lemma 3,KXlk kk=0final iterate VK . implies |VPK(ul)(I PeK )1 Pe PeKk kfifi P k=0 kfifiK1(u+l)||(I Pe K ) fiPe Pe K fikkk=0 kPK1(I Pe K )(uk + lk )|k |k=0PPKeK )i(u+l)||=(Pkkk=0 ki=0P PKi=0k=0 (uk + lk )|k |P PK(u+l)||kkkk=0i=0PK1(u+lk )|k | ,k=0 kV V Kfirst step taken absolute valuefisides inequality,fifi efiminsecond step used factfiP PeK fi. remainderproof denote dmin .k = 0,==22(u0 + l0 )|0 |11(u0|0 |)2112PeKZPeZZ|0 |KZPe|0 |PeP2K P0,t |0 |(1) K+1t=1P2(1)1K P | |=0,t 0t=1 1 K+1(1)2P0 P0,t |0 | .21t=1k = 1, 2, . . . , Z,(uk + lk )|k |1423fiMann, Mannor, & Precup22===1(uk|k |)ZkKZePPe|k |KZ Zk2PePe|k |1P2Kk Pk,t |k |(1)t=12(1 K+1 ) P1Kk P | |k,t k(1)21 K+121Pt=112t=1k Pk,t |k | .k = Z + 1, Z + 2, . . . , K,(uk + lk )|k |1221(uk + lk ) |k |Kk h21=+ Pe K1 Pe K2 . . . Pe k |k |Pe1 2P2Kk Pk,t |k |(1)t=12(1 K+1 ) P1Kk P | |=k,t k2K+1(1)1==Pt=1t=1k Pk,t |k | .pluggingresults three inequalities, obtain V V KPPKt=1 k=0 k Pk,t |k |.B.3 Pointwise Lp -norm Propagation ErrorLemma 6 gives us pointwise bound loss policy K derived OFVI comparedfollowing optimal option policy , common function approximation architectures minimize Lp -norm (not pointwise loss). subsection, derive Lemma8 transforms pointwise bound Lp -norm bound weighted arbitrary distribution M(X). key transformation based A2(, ) (Assumption 2),allows us bound pointwise transition probability kernels Pk,t Lemma 6c() Assumption 2 iteration k {1, 2, . . . , K}. following lemma providesfirst step transformation.Lemma 7. Suppose A2(, ) (Assumption 2) holds,Pk,tmaxm{1,2,...,i+t}ct (m) ,, (X).Proof. two cases consider (case 1) 1 k Z (case 2) Z < k K.424(47)fiApproximate Value Iteration Temporally Extended Actionscase 1,Pk,t =hPKZ(P )Zkct (K k) .case 2,hKkPk,t = 21 P+ (P K1 P K2 . . . P k )thKk+ (P K1 P K2 . . . P k )t= 12 P12 [ct (K k) + ct (K k)]= ct (K k) .derive Lp -norm bound, need following additional notation representset options initialized state x X duration longer1.Definition 14. Let 1, x X state, set options. set Ox,ddenotesh subsetoptions initialized state x,inf X E Dx,Y d.Notice assumption Ox,dmin Ox .Lemma 8. Let K 1, > 0, Z {0, 1, 2, . . . , K}. Suppose Assumption 2Assumption 3 true first Z iterates OFVI pessimistic,!1/p 2 V V02kV V K kp,C1/p (+)+ dmin (K+1)+(1)(ddmin )bZ/jc(1 )2 ,(1 )2(48)holds, provided approximation errors k satisfy kk kp, k = 1, 2, . . . , K.Proof. First note(x) =arg maxoOx,d Q (x, o) x ,d(x)otherwise.policy Q (x, (x)) V (x) x X. Therefore, Lemma 6,XKXV V Kk Pk,t |k | .t=1 k=0Now,V V K pp,fifip(x) fiV (x) V K (x)fi dxKpRP P(x)k Pk,t |k |(x) dxt=1 k=0pPKRPp(x)k Pk,t |k + | + 0 P0,t |V V0 | (x) dx ,=Rt=1 k=1425fiMann, Mannor, & Precupinitial equality due definition kkp, . first step replaces V V KP PKt=1k=0 k Pk,t |k |. last step pulls k = 0 sum moves outsideintegral.KPRecall Lemma 5k = 1. apply Jensens inequality twice;k=0convex function | |p parameters Pk k = 0, 1, . . . , K, parametersdetermined stochastic operatorst=1 Pk,t , obtain#Z "XXKpk Pk,t |k + |p + 0 P0,t |V V0 |p (x)dx .V V K pp,t=1 k=1Noticing |V V0 | bounded kV V0 k , obtainP PKppV V K pt=1k=1 k Pk,t |k + | +p,R(x)0 P0,t kV V0 kp dx .Assumption 2 Lemma 7,Pk,tmaxm{1,2,...,Kk+t0 1}cKk+t0 1 (m) ,t0 = (K k) + 1. ThusK PPk=1 t=1k Pk,t |k + |pK PPk=1t0 =11Kk1 K+1maxm{1,2,...,Kk+t0 1}K PPk=1 t0 =10 101Kk 1(1 K+1 )maxm{1,2,...,Kk+t0 1}(1)21 K+1K PPk=1 t0 =0maxm{1,2,...,k+t0 }cKk+t0 1 (m)kk + kpp,cKk+t0 1 (m)kk + kpp,0k+tck+t0 (m)kk + kpp,P1(1 )2t1 maxm{1,2,...,t} ct (m)kk1 K+1t=11C ( + )p ,1 K+1 ,+ kpp,C, SMDP discounted average concentrability coefficient Assumption 2.P PKpreplacingt=1k=1 k Pk,t |k + | , getp2(1 K+1 )1V V K pC ( + )p +(1)21 K+1 ,p,(49)P Rp(x)PkVVkdx.00,t0t=1426fiApproximate Value Iteration Temporally Extended ActionsConsider second term last step (49). replacing P0,t definition,getZRRPPKZ(1)K(x)0 P0,t dx =(x)dx(P )P1 K+1K+t1t=1t=1ZRPKZ(1)Kt1=(x)(P )dxPt1 (1 K+1 )K+t1t=1Z(1)2 R1(x) (Pe )KZ PedxK+1(1)2 dmin K+(1)(ddmin )bZ/jc1 K+1,(50)initial equality due expanding P0,t definition. first step simplifiesKZdrops dependence (1 )(I PeK )1 1. final step replaces PeKZZ(KZ)(1)dbZ/jc+dZeminminP. case, Pedmin K .Assumption 3 probability (1 ) either (a) state transitioned ,d ,case effective discount factor , (b) following bridge policycurrent state reaches state ,d j timesteps. timestepsagent ,d effective discount factor dmin , probability (1)Zhappen Z bZ/jc times during. Thus Pe(1+)dmin Z+(1)(ddmin )bZ/jcdmin K+(1)(ddmin )bZ/jc .replacing second term (49) (50), getp2(1 K+1 )1V V K pC ( + )p +(1)21 K+1 ,p,(1)2 dmin K+(1)(ddmin )bZ/jckV1 K+1Since 1 K+1V V K pp,p11 K+1p h2(1)2V0 kp.1,C, ( + )p + (1 )2 dmin K+(1)(ddmin )bZ/jc kV V0 kpThus,V V Kp,1/p2C ((1)2 ,1/p2kV V0 k+ ) + dmin (K+1)+(1)(ddmin )bZ/jc.2(1)B.4 Proof Theorem 1Proof. (of Theorem 1) use Lemma 2 select appropriate values n m,1/p0 = (1 )2 /(2C, ) 0 K .Since iterates V1 , V2 , . . . , VK random objects, cannot directly apply Lemma2 bound error iteration. However, problem resolved proof427.fiMann, Mannor, & PrecupThm. 2 work Munos & Szepesvari, 2008 using fact algorithmcollects independent samples iteration.iterate Vk+1 depends random variable Vk random samples Sk containing n |O| next states, rewards, trajectory lengths. Let functionf (Sk , Vk ) = kVk+1 (Vk , Sk ) TVk kp, dp, (TVk , F) + 0 (1 0 ) ,written Vk+1 (Vk , Sk ) emphasize Vk+1 dependence random variables Vk Sk . Notice Vk Sk independent Sk usedgenerate Vk simulator generates independent samples. Vk Sk independent random variables, apply Lemma 5 work Munos & Szepesvari,2008. lemma tells us E [f (Sk , Vk ) | Vk ] 0 provided E [f (Sk , v)] 0allv F. v F, Lemma 2, choice n m,P kVk+1 (v, Sk ) Tvkp, dp, (Tv, F) + 0 1 0 . implies E [f (Sk , v)] 0.Lemma 5 work Munos & Szepesvari, 2008,E [f (Sk , Vk ) | Vk ] 0.0Thus P kVk+1 (Vk , Sk ) TVk kp, dp, (Tv, F) + 1 0 . unionbound, ensures kkp, K iterations probability least 1 K 0 =1 K(/K) = 1 .result follows applying Lemma 8 kk kp, dp, (TVk , F) + 0 .kV V K kp,V V p, + V V K p,1/p20Lp, ( ) + (1)2 C, (bp, (TF, F) + + )1/p2kV V0 k+ dmin (K+1)+(1)(ddmin )bZ/jc2(1)1/p22 /(2C1/p )Cb(TF,F)++(1)= Lp, ( ) + (1),,p,21/p2kV V0 k+ dmin (K+1)+(1)(ddmin )bZ/jc(1)21/p2= Lp, ( ) + (1)2 C, (bp, (TF, F) + ) +1/p2kV V0 k+ dmin (K+1)+(1)(ddmin )bZ/jc.(1)2Appendix C. Proof Theorems 2, 3appendix, prove Theorems 2, 3. First analyze LAVI provingTheorem 2. use one lemmas developed analyzing LAVI analyze OFVIlandmark-based options prove Theorem 3. Throughout appendix assumerewards bound [RMAX , 0], stochastic shortest path problems welldefined.iteration Algorithm 2 performs operator Tbm defined1 X e(j)(j)bTm V (x) = maxRx,o + (V, (j) )oOxj=0428(51)fiApproximate Value Iteration Temporally Extended ActionsTable 2: Errors Impacting Landmark-based VIError NameLandmark ErrorLoc. Planning ErrorLoc. Lipschitz ErrorSymbolLPHStoc. Plan FailureRelaxation ErrorSampling ErrorRDue . . .selected landmarkscPs sub-optimalityterminate(y, l) > 0prob. terminating farLincreased costfinite # samplesstate x X(V, y) =maxlL (y) V (l) L (y) 6=0otherwise.consider limit Tbm , obtain definedZXe(T V ) (x) = max RPto (y|x)(V, y)dyx,o +oOx(52)(53)t=1 yXstate x X.However, would like compare Bellman optimality operator definedZXe(TV ) (x) = max RPto (y|x)V (y)dy ,(54)x,o +oOxt=1 yXwell known converge optimal value function respect optionset O.Throughout analysis work vectors dimension |X| mostlyfocus |L| elements. vectors V V 0 [VMAX , 0]|X| , define max-normrespect subset states L XfifiV V 0 = max fiV (l) V 0 (l)fi ,(55)Lmeasures difference V V 0 states L.Table 2 provides overview errors contribute sub-optimalitypolicies derived LAVI.C.1 Proof Theorem 2proceed bounding value estimation error, use bound lossderived policy. Next bound error due using deterministic local planner. Finally,use results prove Theorem 2.429fiMann, Mannor, & PrecupC.1.1 Bounding Value Estimation ErrorLemma 9. (Bound Value Estimation Error Tbm ) Let 1 > 0, (0, 1], K 1,V [VMAX , 0]|S| , L set landmark states, set landmark options,optimal policy respect O.2LK1ln,(56)m>2(1 (1 ))2landmark-option pairs duration least dmin , Assumption 5 holds,probability least 1 /KbTm V VMdmin VMAX + (1 ) + (1 ) V VM+ 1LLstochastic plan failure, distance threshold, Lipschitzcoefficient Assumption 5. recursing inequality K times, obtainKdmin (VMAX + (1 )) + 1dmin+(1)VVVK VM0min1LL(57)probability least 1 .Proof. Notice l Lfififififi b(l)fi = fi(T)(l)fifi(Tm V )(l) VMfifi bm V )(l) (TVMfifififi b)(l) + (T V )(l) (TV )(l)fi= fi(Tm V )(l) (T VMfififi fififi bfi)(l) + fi(T V )(l) (TV )(l)fifi(Tm V )(l) (T VMfi(58)(l) = (TV )(l), first step insertsinitial equality due fact VM(T VM )(l) + (T VM )(l) = 0,laststepusestriangleinequality.fififi bfilet X denote event fi Tm V (l) (T V ) (l)fi 1 . event X occurs,first term last step inequality (58)!fififiRfiPfi bfi)(l)el,o +Pto (y|x)(V, y)dyfi(Tm V )(l) (T VMfi = fifi max RoOlt=1 yX!fiRfiP, y)dy fi +el,o +max RPto (y|x)(VM1fioOlmaxRPoOl t=1 yXdmin maxt=1 yXfifi, y)fi dy +Pto (y|x) fi(V, y) (VM1PRoOl t=dmin yXfifi, y)fi dy + ,Pto (y|x) fi(V, y) (VM1last step previous inequality due fact landmark-optionpairs execute least dmin timesteps (meaning effective discount factorless equal dmin ). choice using Hoeffdings inequalityeasily shown event X occurs landmark-option pair probability least430fiApproximate Value Iteration Temporally Extended Actions1 /LK. Since L =P|Ol | total landmark-option pairs, using unionboundP event X holds landmark-options pairs probabilityleast 1 Li=1 /LK = 1 L (/LK) = 1 /K., y)| = |0 0| = 0. hand,Now, L (y) = , |(V, y) (VML (y) 6= ,fififififififi(V, y) (V , y)fi = fi max V (l0 ) max V (l0 )fifil0 L (y)fil0 L (y) fifi00fifimax V (l ) VM (l )l0 L (y)V VM,Lfififi)(l)fi dmin (1 ) V V + holdsimplies fi(Tbm V )(l) (T VMfi1Llandmarks probability least 1 /K.second term last step inequality (58)!fiRfififiP, y)dyel,o +fi(T V )(l) (TV )(l)fi = fi max RPto (y|x)(VMfi oOlt=1 yX!fiRfiP(y)dy fiel,o +max RPto (y|x)VMfioOlt=1 yXRfifiP, y) V (y)fi dymaxPto (y|x) fi(VMoOl t=1 yXdmin maxPRoOl t=dmin yXfifi, y) V (y)fi dyPto (y|x) fi(VMlast step previous inequality due fact landmark-optionpairs execute least dmin timesteps., y) V (y)| |0 V (y)| Vprobability , |(VMMAX, y) V (y)| | max 0(l0 ) V (y)| .probability 1 |(VMVl L (y)fifiThus, fi(T V )(l) (TV )(l)fi dmin (VMAX + (1 )).two terms last stepinequality(58) obtain resultreplacingV V dmin VMAX + (1 ) + V V +1 probability leastLL1 /K.C.1.2 Bounding Policy ErrorLemma 10. (Bound Policy Error) Let 2 > 0, set landmark options dmin 1|L|minimum duration state-options pairs,MAX , 0] , 0,V [Voptimal policy respect O. Suppose V VMLZXe(x) = arg max RPto (y|x) max (V, y)dyx,o +oOxt=1 yXgreedy policy respect V . Assumption 5 holds,dmin ((1 ) ( + ) + VMAX )VM VM1 dmin431(59)fiMann, Mannor, & Precupholds.Proof. Let x X, = (x), = (x). Since (x) = o,ex,o +RZXt=1 yXex,o +Pto (y|x)(V, y)dy RZXPto (y|x)(V, y)dy .(60)t=1 yXLet G = {y X | L (y) 6= } G = X\G. set G contains states closerleast one landmark state. rearranging obtainex,o Rex,oRRPt=1 yXRPPto (y|x) Pto (y|x) (V, y)dyPto (y|x) Pto (y|x) (V, y)dyt=1 yGR+Pt (y|x) Pto (y|x) (V, y)dyex,o Rex,oRex,o Rex,oRex,o Rex,oRex,o Rex,oRyGPRt=1 yGPto (y|x) Pto (y|x) max V (l0 )dyPRt=1yGPt=1l0 L (y)Pto (y|x) Pto (y|x)!max VM (l0 ) + dy!R(y) + + dyPt (y|x) Pto (y|x) VM,l0 L (y)yGinitial inequality rearranges (60) isolate reward terms. first stepobtained dividing sum states states L (y) 6= statesL (y) = . third step replaces (V, y) definition. Since (V, y) = 0L (y) = , second term right hand side disappears. fourth step(l0 ) + , final step uses Assumption 5 replace V (l0 )replaces V (l0 ) VM(y) + .VM432fiApproximate Value Iteration Temporally Extended ActionsR(y) P (y|x)V (y) dy(x) V (x) = Rex,o + Pex,o RPto (y|x)VMVMt=1 yXex,o Rex,o= RP R(y) P (y|x)V (y) dy+Pt (y|x)VM+t=1 yGRPt=1 yG(y) P (y|x)V (y) dyPto (y|x)VMex,o Rex,oRP R(y) P (y|x)V (y) dy+Pt (y|x)VMt=1 yG+ dmin VMAX!RPPt (y|x) Pt (y|x) VM (y) + + dyt=1 yG!RP+Pt (y|x)VM (y) Pt (y|x)VM (y) dyt=1 yG+dmin VMAXRP(y) P (y|x) V (y) + +Pto (y|x)VM=t=1 yG(y) + + P (y|x)V (y) dy + dmin V+ Pt (y|x) VMMAX!RP(y) V (y) + + dy + dmin VPto (y|x) VMdminMAXt=1 yGV + + + dmin Vdmin (1 ) VMMAX .recursing inequality, obtainVM VMdmin ((1 )( + ) + VMAX ).1C.1.3 Bounding Error Deterministic Relaxationb optimal policy optionsc,Lemma 11. LetbVVMcc2(L + P )1holds.Proof. l L,beP(l,l0 ) + P(l,l0 ) V b (l0 ) .VM(l)V(l)V(l)maxRcccc0l433fiMann, Mannor, & Precupdefinition landmark error,bep (l,l0 ) + |pG (l,l0 )| V (l0 ) max ReP(l,l0 ) + |P(l,l0 )| V b (l0 ) + L ,VM(l)V(l)maxRccccG00l Lsldefinition planning error,beP(l,l0 ) + |P(l,l0 )| V b (l0 ) max ReP(l,l0 ) + |P(l,l0 )| V (l0 ) +L +P .VM(l)V(l)maxRcccc00lltake max set valid landmark destinations l, getb(l) VeP(l,l0 ) |P(l,l0 )| V (l0 ) + L + PeP(l,l0 ) + |P(l,l0 )| V b (l0 ) R(l)maxRVccccl00b(l0 ) V0|P(l,l )| V cmaxc (l ) + L + P .0lSincelandmarks separated paths length least planning P,bL +Pobtain V cVc.1LTherefore similar reasoning above, see state x XbVMc(x) VMc (x) L + P +(L + P )2 (L + P ).11C.1.4 Proof Theorem 2Proof. (of Theorem 2)apply Lemma 9 1 =(1 dmin )2(1) dmin(0, 1] Lemma 10 obtaindminKVMAX + (1 ) +VM VM1 dmin1,1dmindmin K[VMAX + (1 )] ++ (1 ).VM V0minmin11L(61)replacing H 1 , getKVV1,dmin1 dmin1+(1 ) dmin1 dmin(VMAX + (1 )H ) +!V V0L+ (1 )2 (K+1)dmin(62)1 dminrearranging terms.Due definition relaxation errorV V1,(Definition 12),bVV+ Rcc2(L +P )b1 dmin4341,+ R(63)fiApproximate Value Iteration Temporally Extended Actionslast step due Lemma 11.combining (62) (63), obtainkV VK k1,=dmin1 dmin1+2(L +P )1 dminb2(L +P )1 dminb+ R + + + (1+ R + + +(1) dmin1 dminVM V0)2 (K+1)dmin(K+1)dmin1 dminVM V01 dmin!L!L(VMAX + (1 )H ).C.2 Proof Theorem 3Proof. (of Theorem 3)Corollary 1,Lp, (K ) Lp, ( ) +1/p2 dmin 1/pdmin (K+1)Cb(TF,F)++p,(1 )2 ,2 kV V0 k(1 )2.(64)(63),Lp, ( )2(L + P )1 dbmin+ R .result follows replacing Lp, ( ) (64) right hand side previousinequality.ReferencesBarry, J. L., Kaelbling, L. P., & Lozano-Prez, T. (2011). DetH*: Approximate HierarchicalSolution Large Markov Decision Processes. International Joint ConferenceArtificial Intelligence.Bertsekas, D. P., & Tsitsiklis, J. (1996). Neuro-dynamic programming. Athena Scientific.Brunskill, E., Leffler, B. R., Li, L., Littman, M. L., & Roy, N. (2008). CORL: ContinuousState Offset-Dynamics Reinforcement Learner. Proceedings 24 th ConferenceUncertainty Artificial Intelligence (UAI-08).Chassin, D. P., Fuller, J. C., & Djilali, N. (2014). GridLAB-D: agent-based simulationframework smart grids. Journal Applied Mathematics, 2014.Comanici, G., & Precup, D. (2010). Optimal policy switching algorithms reinforcementlearning. Proceedings 9 th International Conference Autonomous AgentsMultiagent Systems, pp. 709714.Dietterich, T. G., Taleghan, M. A., & Crowley, M. (2013). PAC optimal planning invasivespecies management: Improved exploration reinforcement learning simulatordefined MDPs. Proceedings National Conference Artificial Intelligence.Dijkstra, E. (1959). note two problems connexion graphs. Numerische Mathematik, 1 (1), 269271.435fiMann, Mannor, & PrecupFarahmand, A., Ghavamzadeh, M., Szepesvari, C., & Mannor, S. (2008). Regularized fittedQ-iteration: Application planning. Recent Advances Reinforcement Learning,pp. 5568. Springer.Farahmand, A., Munos, R., & Szepesvari, C. (2010). Error propagation approximatepolicy value iteration. Advances Neural Information Processing Systems.Fernandez, F., & Veloso, M. (2006). Probabilistic policy reuse reinforcement learningagent. Proceedings 5th International Joint Conference Autonomous AgentsMultiagent Systems, pp. 720727.Hart, P., Nilsson, N., & Raphael, B. (1968). formal basis heuristic determinationminimum cost paths. Systems Science Cybernetics, IEEE Transactions on,4 (2), 100107.He, R., Brunskill, E., & Roy, N. (2011). Efficient planning uncertainty macroactions. Journal Artificial Intelligence Research, 40, 523570.Hoey, J., St-Aubin, R., Hu, A. J., & Boutilier, C. (1999). SPUDD: Stochastic PlanningUsing Decision Diagrams. Proceedings Uncertainty Artificial Intelligence,Stockholm, Sweden.Iba, G. A. (1989). heuristic approach discovery macro-operators. MachineLearning, 3, 285317.Jong, N. K., & Stone, P. (2008). Hierarchical model-based reinforcement learning: Rmax +MAXQ. Proceedings 25th International Conference Machine Learning.Kearns, M., Mansour, Y., & Ng, A. Y. (2002). sparse sampling algorithm near-optimalplanning large Markov decision processes. Machine Learning, 49 (2-3), 193208.Kocsis, L., & Szepesvari, C. (2006). Bandit based Monte-Carlo Planning. MachineLearning: ECML2006, pp. 282293. Springer.Konidaris, G., & Barto, A. (2009). Skill discovery continuous reinforcement learningdomains using skill chaining. Advances Neural Information Processing Systems22, pp. 10151023.Konidaris, G., & Barto, A. G. (2007). Building portable options: Skill transfer reinforcement learning.. Proceedings International Joint Conference ArtificialIntelligence, Vol. 7, pp. 895900.Konidaris, G., Kuindersma, S., Barto, A., & Grupen, R. (2010). Constructing skill treesreinforcement learning agents demonstration trajectories. Advances NeuralInformation Processing Systems, pp. 11621170.Lazanas, A., & Latombe, J.-C. (1992). Landmark-based robot navigation. Tech. rep.,Stanford University.Lazaric, A., Ghavamzadeh, M., & Munos, R. (2010). Analysis classification-based policyiteration algorithm. Proceedings 27th International Conference MachineLearning.Littman, M. L., Dean, T. L., & Kaelbling, L. P. (1995). complexity solvingMarkov decision problems. Proceedings 11th conference Uncertaintyartificial intelligence, pp. 394402.436fiApproximate Value Iteration Temporally Extended ActionsMankowitz, D. J., Mann, T. A., & Mannor, S. (2014). Time-regularized interrupting options.Proceedings 31st International Conference Machine Learning.Mann,T.A.(2014).CyclicInventoryManagementhttps://code.google.com/p/rddlsim/source/browse/trunk/files/rddl2/examples/cim.rddl2. Accessed: 2015-06-29.(CIM).Mann, T. A., & Mannor, S. (2014). Scaling approximate value iteration options:Better policies fewer iterations. Proceedings 31 st International Conference Machine Learning.Mannor, S., Menache, I., Hoze, A., & Klein, U. (2004). Dynamic abstraction reinforcementlearning via clustering. Proceedings 21st International Conference Machinelearning, ICML 04, pp. 71, New York, NY, USA. ACM.McGovern, A., & Barto, A. G. (2001). Automatic discovery subgoals reinforcementlearning using diverse density. Proceedings 18th International ConferenceMachine Learning, pp. 361 368, San Fransisco, USA.Minner, S. (2003). Multiple-supplier inventory models supply chain management:review. International Journal Production Economics, 8182, 265279. Proceedings11th International Symposium Inventories.Munos, R. (2005). Error bounds approximate value iteration. ProceedingsNational Conference Artificial Intelligence.Munos, R., & Szepesvari, C. (2008). Finite-time bounds fitted value iteration. JournalMachine Learning Research, 9, 815857.Peleg, D., & Schaffer, A. A. (1989). Graph spanners. Journal Graph Theory, 13 (1),99116.Peters, J., & Schaal, S. (2008). Reinforcement learning motor skills policy gradients.Neural Networks, 21, 682691.Precup, D., & Sutton, R. S. (1997). Multi-time models temporally abstract planning.Advances Neural Information Processing Systems 10.Precup, D., Sutton, R. S., & Singh, S. (1998). Theoretical results reinforcement learningtemporally abstract options. Machine Learning: ECML1998, pp. 382393.Springer.Puterman, M. L. (1994). Markov Decision Processes - Discrete Stochastic Dynamic Programming. John Wiley & Sons, Inc.Riedmiller, M. (2005). Neural fitted Q iterationfirst experiences data efficientneural reinforcement learning method. Machine Learning: ECML2005, pp. 317328. Springer.Sanders, P., & Schultes, D. (2005). Highway hierarchies hasten exact shortest path queries.Brodal, G., & Leonardi, S. (Eds.), Algorithms: ESA2005, Vol. 3669 LectureNotes Computer Science, pp. 568579. Springer Berlin Heidelberg.Scarf, H. (1959). optimality (s,S) policies dynamic inventory problem. Tech.rep. NR-047-019, Office Naval Research.437fiMann, Mannor, & PrecupScherrer, B., Ghavamzadeh, M., Gabillon, V., & Geist, M. (2012). Approximate ModifiedPolicy Iteration. Proceedings 29th International Conference MachineLearning, Edinburgh, United Kingdom.Sethi, S. P., & Cheng, F. (1997). Optimality (s,S) policies inventory modelsmarkovian demand. Operations Research, 45 (6), 931939.Shantia, A., Begue, E., & Wiering, M. (2011). Connectionist reinforcement learningintelligent unit micro management starcraft. Proceedings InternationalJoint Conference Neural Networks, pp. 17941801. IEEE.Silver, D., & Ciosek, K. (2012). Compositional planning using optimal option models.Proceedings 29th International Conference Machine Learning, Edinburgh.Simsek, O., & Barto, A. G. (2004). Using relative novelty identify useful temporal abstractions reinforcement learning. Proceedings 21st International ConferenceMachine Learning, pp. 95102, New York, NY, USA. ACM.Sorg, J., & Singh, S. (2010). Linear options. Proceedings 9th International Conference Autonomous Agents Multiagent Systems, pp. 3138.Stolle, M., & Precup, D. (2002). Learning options reinforcement learning. Abstraction,Reformulation, Approximation, pp. 212223. Springer.Stone, P., Sutton, R. S., & Kuhlmann, G. (2005). Reinforcement learning robocup soccerkeepaway. Adaptive Behavior, 13 (3), 165188.Sutton, R. S., Precup, D., & Singh, S. (1999). MDPs semi-MDPs: frameworktemporal abstraction reinforcement learning. Artificial Intelligence, 112 (1), 181211.Tamar, A., Castro, D. D., & Mannor, S. (2013). TD methods variance rewardto-go. Proceedings 30 th International Conference Machine Learning.Wolfe, A. P., & Barto, A. G. (2005). Identifying useful subgoals reinforcement learninglocal graph partitioning. Proceedings 22nd International ConferenceMachine Learning, pp. 816823.Yoon, S. W., Fern, A., & Givan, R. (2007). FF-Replan: Baseline Probabilistic Planning. Proceedings International Conference Automated PlanningScheduling, Vol. 7, pp. 352359.438fiJournal Artificial Intelligence Research 53 (2015) 91-126Submitted 12/14; published 05/15Ceteris Paribus Structure Logics Game FormsDavide Grossid.grossi@liverpool.ac.ukDepartment Computer ScienceUniversity LiverpoolEmiliano Loriniemiliano.lorini@irit.frIRIT-CNRSUniversite Paul SabatierFrancois Schwarzentruberfrancois.schwarzentruber@ens-rennes.frENS Rennes - IRISAAbstractarticle introduces ceteris paribus modal logic, called CP, interpretedequivalence classes induced finite sets propositional atoms. logic studiedused embed three logics strategic interaction, namely atemporal STIT,coalition logic propositional control (CLPC) starless fragment dynamiclogic propositional assignments (DLPA). embeddings highlight common ceterisparibus structure underpinning key operators apparently different logicsshow, argue, remarkable similarities behind influential formalismsreasoning strategic interaction.1. Introductionlogical analysis agency gamesfor expository introduction field see vander Hoek Paulys overview paper (2007)has boomed last two decades givingrise plethora different logics particular within multi-agent systems field.1heart logics always representations possible choices (or actions)groups players (or agents) powers force specific outcomes game.logics take former primitives, like STIT (the logic seeing that, Belnap, Perloff,& Xu, 2001; Horty, 2001), take latter like CL (coalition logic, Pauly, 2002; Goranko,Jamroga, & Turrini, 2013) ATL (alternating-time temporal logic, Alur, Henzinger, &Kupferman, 2002).formalisms power players modeled terms notion effectivity.strategic game, -effectivity group players consists sets outcomesgame players collective action forces outcomegame end set, matter players (Moulin & Peleg,1982). So, set outcomes X belongs -effectivity set players J,exists individual action agent J that, actions players,outcome game contained X. keep actions agents1. richness logical landscape object IJCAI13 invited talk A. Herzig LogicsMulti-Agent Systems: Critical Overview.c2015AI Access Foundation. rights reserved.fiGrossi, Lorini, & Schwarzentruberfixed, selection individual action agent J corresponds choiceJ assumption agents stick choices.already observed van Benthem, Girard, Roy (2009) formalizationchoice power games things equal, ceteris paribus, nature.Considering outcomes game possible set players Jplayers fixed actions, amounts considering may caseceteris paribus condition actions agents J equal (to currentones). aforementioned work van Benthem et al. also show intuitionused, instance, give modal formulation Nash equilibria one-shot games.2current paper leverage intuition show provide novelsystematization many influential formalisms field logic games.1.1 Scientific ContextFormal relationships linking logics (or fragments thereof) mentionedobject several publications. Notable examples are: embedding CLnext-time fragment ATL (Goranko, 2001) embedding CL NCL (normalcoalition logic, Broersen, Herzig, & Troquard, 2007; Balbiani, Gasquet, Herzig, Schwarzentruber, & Troquard, 2008a), embedding CL ATL STIT (Broersen, Herzig,& Troquard, 2005, 2006). Earlier contributions also attempted comprehensivesystematizations field logic games. Two particular worth mentioning:Goranko Jamrogas work (2004), compares game logics based computation tree abstraction like ATL variants; Herzigs work (2014), providesconceptual syntax-basedwhile favor semantic methodscomparisonmain formalisms literature.1.2 Aim Paperaim paper provide technical contribution towards unification fieldlogic games. set develop series embeddings highlight commonstructure representation choice power, underpins semanticslogics mentioned above.focus components semantics logics directlyrepresentation choice power, abstract away representationtime repeated interaction. logics working are: atemporalfragment STIT, logic CLPC (coalition logic propositional control, van der Hoek &Wooldridge, 2005) starless fragment DLPA (dynamic logic propositionalassignments, van Eijck, 2000; Balbiani, Herzig, & Troquard, 2013). logics cover,arguably, large spectrum influential existing formalisms.3 Logic STIT oftenconsidered standard literature, embeds CL ATL (Broersen et al., 2005,2. refer reader Osborne Rubinsteins textbook (1994) introduction basic notionsgame theory.3. worth stressing focus logics choice power (that is, notion effectivity) formalisms incorporating also explicit representation choice powerimplemented (that is, explicit notion strategy), instance ATL explicit strategies(Walther, van der Hoek, & Wooldridge, 2007).92fiThe Ceteris Paribus Structure Logics Game FormsCLPCDLPACPonentialS5boundeodelexpSTITrestricted languagesNCLFigure 1: Summary embeddings established paper known literaturearrow indicates formula source logic satisfiablesuitable translation formula satisfiable target logic. DLPAdenotes starless version dynamic logic propositional assignments, NCLSTIT denote atemporal version of, respectively, normal coalition logicseeing-to-it logic. S5 denotes normal modal logic equivalence relations. Dotted lines indicate embeddings known literature: CLPCDLPA (Balbiani et al., 2013) STIT NCL (and vice versa) respect fragments respective languages (Lorini & Schwarzentruber, 2011).embedding STIT CP assumes bound STIT-models.embeddings polynomial except one CP S5.2006), use natural starting point. Logic CLPC influential extensionCL strong formal ties (Dunne, van der Hoek, Kraus, & Wooldridge, 2008) the,equally influential, Boolean games model (Harrenstein, van der Hoek, Meyer, & Witteveen,2001) multi-agent systems. Finally, logic DLPA extension PDL (propositionaldynamic logic, Harel, Kozen, & Tiuryn, 2000), recently proposed newstandard representation choice power (Herzig, Lorini, Moisan, & Troquard,2011; Balbiani et al., 2013).articulate analysis, whose main technical tool consists satisfiability-preservingembeddings, paper introduces studiesin axiomatization complexityasimple ceteris paribus logic based propositional equivalence, call CP.logic yardstick allowing us compare unify STIT, CLPC DLPA.1.3 Outline Summary ResultsSection 2 introduces logic CP. logic compared S5 axiomatized.Section 3 provides study relationship atemporal version STITCP. show CP embeds atemporal group STITthe fragment atemporal STITactions individuals groups representedunder assumptionagents choices bounded. call latter atemporal bounded group STIT.Moreover, show CP embeds atemporal individual STITthe variant atemporal93fiGrossi, Lorini, & SchwarzentruberSTIT actions individuals represented. former embeddingused transfer complexity results CP. also present embedding CP variantatemporal group STIT groups nested (i.e., given two sets agents J J 0either J J 0 viceversa).Section 4 provides embedding coalition logic propositional control atemporalbounded group STITand therefore, indirectly, CPas well direct embeddingCLPC CP.Section 5 provides embedding starless fragment DLPA CP wellembedding CP DLPA therefore, indirectly, STIT (on bounded models)CLPC DLPA.Finally, Section 6 discuss obtained results, put perspective relatedwork draw general implications field. conclude Section 7. Longerproofs collected technical appendix end paper.Figure 1 gives graphical presentation embeddings established paperwell relevant ones already known literature. Two embeddings knownlogics: embedding CLPC DLPA (Balbiani et al., 2013),embedding STIT NCL, vice versa, language STIT (and NCL)restricted fragment allow nesting modalities.42. Ceteris Paribus Logic Based Propositional Equivalencesection introduce study logic used target logicembeddings present. section starts definition equivalence moduloset atoms. present ceteric paribus logic CP whose semantics basedequivalence relations. section finishes exponentially embedding ceterisparibus logic CP S5 proving CP-satisfiability problem decidable.2.1 Equivalence Modulo Set AtomsConsider structure (W, V ) W set states, V : P 2W valuationfunction countable set atomic propositions P subsets W .5Definition 1. (Equivalence modulo X) Given pair (W, V ), X P |X| < ,relation VX W 2 defined as:w VX w0 p X : w V (p) w0 V (p)X singleton (e.g. p), often write Vp instead V{p} . Also, orderavoid clutter, often drop reference V VX clear context.Intuitively, two states w w0 equivalent set X, X-equivalent,satisfy atoms X (according given valuation V ). finiteness4. reader referred Lorini Schwarzentrubers paper (2011) BNF language.5. literature game logics sometimes defined countable set atoms (e.g., Balbiani et al.,2013) sometimes finite set atoms (e.g., van der Hoek & Wooldridge, 2005). optgenerality define language CP countable set. assumption finite supplyatoms results present later would trivialize (for instance CP satisfiability problemwould PTIME) would therefore hide interesting technical features CP.94fiThe Ceteris Paribus Structure Logics Game FormsX clearly essential definition. assumed because, see, setX taken model set actions agent game form sets actionsalways assumed finite.state following simple fact without proof. highlights interesting featuresnotion propositional equivalence modulo subsets P, uselater paper.Fact 1. (Properties P ) following holds set states W , valuation V :P 2W finite sets X, P:(i) X reflexive, transitive symmetric;(ii) X X ;(iii) X singleton, X induces partition W 2 cells;(iv) X = XY ;(v) = W 2 .Intuitively: (i) states X equivalence relation; (ii) states largerset atoms, refined equivalence relation indexed it; (iii) statesset atom singleton, equivalence relation would induce partitionone (if proposition singleton globally true globally false model) twocells (otherwise); (iv) states relation indexed union two sets atomsrelation one obtains intersecting relations two sets; finally (v) statesrelation empty set atoms global relation.2.2 Modal Logic X Relationsection consider simple modal language interpreted relations X axiomatize logic class structures (W, V ). key modal operator languagehXi, whose intuitive meaning case state X-equivalentcurrent one or, stress ceteris paribus reading, possible things expressedX equal. call resulting logic propositional ceteris paribus logic, CP short.2.2.1 Syntax CP.Let P countable set atomic propositions. language LCP (P) definedfollowing BNF:LCP (P) : ::= p | | ( ) | hXip ranges P X finite subset atomic propositions (X P X finite).Note set finite subsets atomic propositions countable, languageLCP (P) also countable. Boolean connectives >, , , dual operators [X]defined usual. Although taken diamond operators primitive,convenience also make use box operators state results later sections.set SF () subformulas formula defined inductively follows:SF (p) = {p};95fiGrossi, Lorini, & SchwarzentruberSF () = {} SF ();SF ( ) = { } SF () SF ();SF (hXi) = {hXi} SF ().say signature X appears exists formula hXi SF ().2.2.2 Semantics CPclass models working with:Definition 2. (CP-models) Given countable set P, CP-model LCP (P) tuple= (W, V ) where:W non-empty set states;V : P 2W valuation function.CP-model called universal W = 2P V s.t. V (p) = {w | p w}. callednon-redundant P identity relation W 2 .Intuitively, CP-model consists state-space valuation function givenset atoms. satisfaction relation defined follows:Definition 3. (Satisfaction CP-models) Let = (W, V ) CP-model LCP (P),w W , LCP (P):M, w |=CP p w V (p);M, w |=CP M, w 6|=CP ;M, w |=CP M, w |=CP M, w |= ;M, w |=CP hXi w0 W : w VX w0 M, w0 |=CPFormula CP-satisfiable, exists model state wM, w |=CP . Formula valid M, noted |=CP , w W ,M, w |=CP . Finally, CP-valid, noted |=CP , valid CP-models.logical consequence formula set formulae, noted |=CP , definedusual.So, modal operators interpreted equivalence relations X inducedvaluation model. worth observing logic class modelsclosed uniform substitution,6 is, logic CP uniform.7 witness that, noticeformula [{p}]p [{p}]p valid, whereas [{p}] [{p}] not.Let us give simple illustration semantics.Example 1. Let us consider following model made 5 states w, x, u, y, z:6. definition uniform substitution reader referred textbook Blackburn, de Rijke,Venema (2001, Def. 1.18).7. terminology comes Goldblatts work (1992).96fiThe Ceteris Paribus Structure Logics Game Formsw : p, qx:pu : p, q, rz:qinstance, M, w |=CP h{p, q}ir M, z |=CP [{p}]r.following lemmas state simple facts concerning relation logic CP logicS5 isolate interesting class CP-models.Lemma 1. Let LCP (P) set formulae LCP (P) containing hi operators.set formulae LCP (P) CP-valid modal logic Kripke frames (W, W 2 ),i.e., logic S5.Proof. follows directly Fact 1 item (v).words, hi operator LCP nothing global modality (Blackburnet al., 2001, pp. 367370). next lemma states CP actually logic classrelevant CP-models.Lemma 2. Every satisfiable CP-formula satisfiable non-redundant model.Proof. Assume M, w |= . show MP , |w|P |= MP quotientequivalence relation P (defined natural way) |w|P setstates P -equivalent w. proceed induction structure .propositional Boolean cases obvious. Let = hXi X P.assumption semantics CP operators exists v w X vM, v |= . construction directly |w|P X |v|P . IH MP , |v|P |= ,therefore MP , |w|P |= hXi.2.2.3 Axiomatics CPobtain axiom system CP standard reduction technique exploiting Lemma1. axiom system given Figure 2. first thing notice system consistsusual S5 axioms plus Reduce axiom. Logic S5 known sound stronglycomplete class models accessibility relation total relation W 2(Blackburn et al., 2001), modality hi therefore axiomatized (dual of)global modality.said this, soundness strong completeness system easyestablish.Theorem 1. axiom system given Figure 2 sound strongly completeclass CP-models.Proof. Soundness suffices show Reduce CP-valid, follows straightforwardly Definition 1. Completeness obtain completeness proceed customaryDEL (van Ditmarsch, Kooi, & van der Hoek, 2007; Wang & Cao, 2013). first fix97fiGrossi, Lorini, & Schwarzentruber(P)tautologies propositional calculus(K)[]( ) ([] [])(T)hi(4)hihi hi(5)hi []hi^^^^^pp []p[X]p(Reduce)X(MP)(N)pYpYpX\YpX\Y`CP `CP `CP`CP `CP []Figure 2: Axiom schemas rules CP. X, range finite elements 2P , ,LCP (P), p P. usual, `CP means exists sequenceformulae either axiom obtained previous formulaeapplication inference rule.translation tr0 : LCP (P) LCP (P) follows:tr0 (p) = ptr0 () = tr0 ()tr0 ( ) = tr0 () tr0 ()^^^^^tr0 ([X]) =pp []pp tr0 ()XpYpYpX\YpX\Yalso write tr0 () {tr0 () | }. Notice translation removes occurrenceshXi [X] operators formulae X 6= structure axiomReduce. Consider following rule substitution provable equivalents (REP):(REP)`CP 0 `CP [/0 ][/0 ] formula results replacing zero occurrences, , 0 . rule REP derivable axiom system Figure 2 ().proof claim provided Appendix A. using axiom Reduce rule REPobtain () that, LCP (P), `CP tr0 () (). proceed follows:|=CP tr0 () |=CP tr0 () (); Lemma 1 strong completenessS5 thus obtain tr0 () `S5 tr0 () therefore tr0 () `CP tr0 (); finally ()follows `CP , proves strong completeness.98fiThe Ceteris Paribus Structure Logics Game Formscrux reduction argument lies use axiom Reduce.axiom enable reduction [X]-formulae taking care possible truthVVvalue combinations atoms X. given combination, e.g.,pp,pYpX\Ytrue given state (for ), accessible states, combinationtrue, occurs scope [X] also true.opted axiomatization virtue simplicity, alternative systemscourse possible. One particular worth mentioning. first reduces hpi operatorsaxiom:hpi ((p hi(p )) (p hi(p )))(1)states hpi equivalent either case current state satisfies pexists (possibly different) p-state true, case p trueexists (possibly different) p-state true (recall property (iii) Fact1). Given reduction, one use axioms enforce appropriate behaviorX relations X consists one atom. aim, axioms usedknown canonical properties (ii) (iv) Fact 1, namely:hX hXi(2)hXii hY ii hX ii(3)ranges set nominals. complete system could obtainedaxiomatizing behavior nominalsthrough axioms rules used hybrid logic(Areces & Ten Cate, 2006). system, named canonical model could built(i.e., canonical model maximal consistent sets contain exactly one nominal)axioms Formulae 1-3 would enforce desirable properties canonicalrelations.2.3 Exponentially Embedding CP S5property expressed axiom Reduce enables truth-preserving translation CPS5 via translation tr0 provided proof Theorem 1. translation is, however,length translated formula grows exponentially tower exponentsheight equal modal depth original formula.section propose translation single exponential preserves satisfiability. Take standard modal language L (P) one modal operator definedset atoms P. S5-models structures = (W, V ) W set states,V : P 2W valuation function. Given S5-model = (W, V ) state w W ,truth conditions defined follows:M, w |=S5 u W : M, u |=S5S5-satisfiability defined usual. possible define exponential truth-preservingreduction tr : LCP (P) L (P) follows:^tr(0 ) = p0(p tr1 ())SF (0 )99fiGrossi, Lorini, & Schwarzentruberp fresh atomic proposition (note p0 p formula 0 itself,also subformula 0 )8 , ranging SF (0 ) tr1 defined follows:tr1 (p) = pp Ptr1 () = tr1 ()tr1 ( ) = tr1 () tr1 ()tr1 ([]) = ptr1 ([X]) =^^XpYp^p^pYpX\Yp^p ppX\YIntuitively, translation designed operate like axiom Reduce avoiding exponential blow-up pile modal depth formula. atomic propositionsp tr1 ([X]) avoid non-elementary size tr(0 ). definition tr1 ([]) corresponds degenerated case tr1 ([X]) X = .The following theorem statessatisfiability preservation. proof given Appendix B.Theorem 2. (tr preserves satisfiability) Let 0 CP-formula. two following statements equivalent: 0 CP-satisfiable; tr(0 ) S5-satisfiable.consequence, also obtain following result.Corollary 1. (Decidability) satisfiability problem CP decidable NEXPTIME.Proof. satisfiability problem S5 decidable NP (Blackburn et al., 2001, Ch.6). result follows Theorem 2 decision procedure may work follows:order check satisfiable compute formula tr() apply NP-decisionprocedure check whether tr() S5-satisfiable not.Notice cardinality X appears operators [X] boundedfixed integer, translation tr becomes polynomial size . Thus,S5-satisfiability problem NP-complete, CP-satisfiability problem boundedcardinality restrictions set atomic propositions modal operators NP.trivially NP-hard, NP-complete.Section 3, embed atemporal version STIT (the logic seeing that)CP thereby obtaining lower bounds results.3. Ceteris Paribus Structure STIT Logicsection, investigate possibility embedding logic agency STITCP. STIT logic (the logic seeing that, Belnap et al., 2001; Horty, 2001) oneprominent logical accounts agency. logic constructions formagent (or group J) sees . STIT non-standard modal semantics basedconcepts moment history. However, shown Balbiani, Herzig, Troquard(2008b) Herzig Schwarzentruber (2008), basic STIT language without temporaloperators simulated standard Kripke semantics.8. use fresh atomic propositions obtain efficient satisfiability preserving translationsbased propositional logic technique known Tseitin transformation (Tseitin, 1968).100fiThe Ceteris Paribus Structure Logics Game Forms3.1 Atemporal Group STITFirst let us recall syntax semantics atemporal group STIT. languagelogic built countable set atomic propositions P finite set agentsAGT = {1, . . . , n} defined following BNF:LGSTIT (P, AGT ) : ::= p | | ( ) | [J : stit]p ranges P J ranges 2AGT . construction [J : stit] read groupJ sees true regardless agents choose. define dualdefoperator hJ : stiti = [J : stit]. J = , construction [ : stit] readtrue regardless every agent chooses simply necessarily true.Definition 4 (STIT-Kripke model, Herzig & Schwarzentruber, 2008). STIT-Kripke model= (W, {RJ }JAGT , V ) 3-tuple where:W non-empty set worlds;J AGT , RJ equivalence relation that:i) RJ R ;ii) RJ = jJ R{j} ;iii)w W (w1 , . . . , wn ) W n , u1 R{1} (w), . . . , un R{n} (w)1jn R{j} (uj ) 6= ;V : P 2W valuation function atomic propositions;RJ (w) = {u W : (w, u) RJ } J 2AGT .partition induced equivalence relation RJ set possible choicesgroup J.9 Indeed, STIT choice group J given world w identifiedset possible worlds RJ (w). call RJ (w) set possible outcomes groupJs choice world w, sense group Js current choice w forces possibleworlds RJ (w). set R (w) simply set possible outcomes w, saiddifferently, set outcomes current game w. According Condition (i),set possible outcomes group Js choice subset set possible outcomes.Condition (ii), called additivity, means choices agents group J madechoices individual agent more. Condition (iii) correspondsproperty independence agents: whatever agent decides do, set outcomescorresponding joint action agents non-empty. intuitively, meansagents never deprived choices due choices made agents.Lorini Schwarzentrubers work (2011) determinism group AGT assumed.say set outcomes corresponding joint action agentssingleton. Hortys group STIT logic (Horty, 2001) suppose this. dealHortys version STIT. STIT model game form joint actionagents might determine one outcome.9. One also see partition induced equivalence relation Rj set actions agent jtry, notion trying corresponds notion volition studied philosophy action(e.g., OShaughnessy, 1974; McCann, 1974).101fiGrossi, Lorini, & SchwarzentruberwuvrzR{1}R{2}Figure 3: STIT-modelExample 2. tuple = (W, R , R{1} , R{2} , R{1,2} , V ) defined by:W = {w, u, v, r, s, t, z};R = W W ;R{1} = {w, u, v}2 {r, s}2 {t, z}2 ;R{2} = {w, r, t}2 {u, v, s, z}2 ;R{1,2} = {(w, w), (r, r), (s, s), (t, t), (z, z), (u, u), (v, v), (u, v), (v, u)};p P, V (p) = .STIT-Kripke model. Figure 3 shows model M. equivalence classes inducedequivalence relation R{1} represented ellipses correspond choicesagent 1. equivalence classes induced equivalence relation R{2} representedrectangles correspond choices agent 2. choice group {1, 2}given world determined intersection choice agent 1 choiceagent 2 world. example, choice agent 1 world u {w, u, v} whereaschoice agent 2 world u {u, v, s, z}. choice group {1, 2} u {u, v}.Note Condition (iii) Definition 4 ensures choice agent 1choice agent 2 intersection two choices non-empty. is,equivalence class induced relation R{1} equivalence class inducedrelation R{2} , intersection two equivalence classes non-empty.Given STIT-Kripke model = (W, {RJ }JAGT , V ) world w M, truthconditions STIT formulae following:M, w |=STIT p w V (p);M, w |=STIT M, w 6|=STIT ;M, w |=STIT M, w |=STIT M, w |=STIT ;M, w |=STIT [J : stit] v RJ (w) : M, v |=STITRJ (w) = {u W | (w, u) RJ }.102fiThe Ceteris Paribus Structure Logics Game Forms3.2 Embedding Atemporal STIT CPable embed group STIT CP many reasons. first onegroup STIT satisfiability problem undecidable 3 agents(Herzig & Schwarzentruber, 2008).10 second one group STITfinite model property. Indeed Herzig Schwarzentruber (2008) provide translationproduct logic S5n group STIT logic, S5n finite modelproperty (Gabbay, Kurucz, Wolter, & Zakharyaschev, 2003), atemporal group STITit. contrary CP inherits finite model property S5. Indeed,formula CP-satisfiable, Theorem 2 says tr() S5-satisfiable. S5polynomial model property, exists polynomial-sized S5-model tr() sizetr(). words, exists exponential S5-model tr() size .Theorem 2 ensures exists exponential CP-model size .nevertheless embed variant group STIT assumption everyagent finite bounded number actions repertoire. every agent j,Rj -equivalence class Rj (u) corresponds action agent j. say agent j kjactions STIT model exactly kj Rj -equivalence classes M.game structure STIT-models enforced CP-models.introduce special atomic propositions encode game structure. Without lossgenerality, assume set P contains special atomic propositions rep j1 , rep j2 , . . .agents j used represent actions agents. Let k maximalnumber actions: k = maxjAGT kj . every agent, represent actions numbers` {0, . . . , k 1} atomic propositions encode binary representation `.Let integer represents number digits need represent action.instance let = dlog2 ke (the ceiling logarithm k). given agent j,Rjm = {rep j1 , . . . , rep jm } set atomic propositions represent binary digitsaction agent j. suppose j 6= Rjm Rim = .Example 3. example, model Example 2, agent 1 k1 = 3 actions agent2 k2 = 2 actions. k = 3 = dlog2 3e = 2. R1m = {rep 11 , rep 12 }R2m = {rep 21 , rep 22 }. instance, may represent action agent 1 correspondingR{1} (w) = {w, u, v} valuation rep 11 rep 12 , action agent 1 corresponding{r, s} rep 11 rep 12 , action agent 1 corresponding {t, z} rep 11 rep 12 ,action agent 2 corresponding {w, r, t} rep 21 rep 22 action agent 2corresponding {u, v, s, z} rep 21 rep 22 .Let Rm = jAGT Rjm set atomic propositions used denote actions. Letus define following CP formula:defGRIDm =VxRm []((xhRm \ {x}ix) (x hRm \ {x}ix))(4)formula enforces CP model universal (over Rm ), is, contain possiblevaluations Rm (recall Definition 2). model satisfies GRIDm interpretedgame form valuation Rjm represents action player j.10. See Lorini Schwarzentrubers paper (2011) study decidable fragments group STIT.103fiGrossi, Lorini, & SchwarzentruberExample 4. instance, world CP model M0 satisfies GRID2 ,skeleton M0 following form (we intentionally draw skeletonmodel M0 looks like model M):|{z}worldsrep 21 rep 22true|{zworldsrep 11 rep 12 trueworldsrep 11 rep 12 trueworldsrep 11 rep 12 true}worldsrep 21 rep 22trueR{1}R{2}define translation LGSTIT LCP (P) follows:tr2 (p) = pp Ptr2 () = tr2 ()tr2 ( ) = tr2 () tr2 ()[tr2 ([J : stit]) = [Rjm ]tr2 ()jJtranslation tr2 parameterized m. notational convenience,follows write tr2 instead tr2m leaving implicit parameter m.set jJ Rjm represents atomic propositions used represented actionscoalition J.Example 5. instance, = 2,tr2 ([{1} : stit][{1, 2} : stit]p) = [{rep 11 , rep 12 }][{rep 11 , rep 12 , rep 21 , rep 22 }]p.obtained desired satisfiability-preservation result. proof givenAppendix C.Theorem 3. Let us consider group STIT formula . Let integer.following items equivalent:1. STIT-satisfiable STIT-model agent 2m actions;2. STIT-satisfiable STIT-model agent exactly 2m actions;3. GRIDm tr2 () CP-satisfiable.104fiThe Ceteris Paribus Structure Logics Game Forms3.3 Atemporal Individual STITsubsection, consider following fragment STIT called atemporal individualSTIT 11 :LISTIT (P, AGT ) : ::= p | | ( ) | [{j} : stit]p ranges P j ranges AGT .fragment STIT, axiomatized Xu (1998), exponential finite modelproperty (see Lemma 7 Balbiani et al., 2008b). Moreover, following theoremhighlights, embedded logic CP.Theorem 4. Let us consider STIT formula individual STIT fragment. Letlength . following three items equivalent:1. STIT-satisfiable2. STIT-satisfiable model agent 2m actions;3. GRIDm tr2 () CP-satisfiable.Proof. 1 2 Consider STIT formula individual STIT fragment. STITsatisfiable length , STIT-satisfiable model2m worlds (see Lemma 7 Balbiani et al., 2008b). implies2m actions model. implications 2 3 3 1 come Theorem3.Thanks Theorem 4, reduce NEXPTIME-complete satisfiability problemindividual STIT (Balbiani et al., 2008b) CP-satisfiability problem. reductionpolynomial, obtain following lower bound complexity result CP-satisfiabilityproblem.Corollary 2. CP-satisfiability problem NEXPTIME-hard.3.4 Group STIT Coalitions Nestedsubsection address satisfiability problem fragment CP consistingformulae LCP sets atomic propositions appear operator [X]occurring form linear set sets atomic propositions. formally, [X] [X 0 ]two operators occurring either X X 0 X 0 X. instance, formula[{p, q}]( [{p}][{p, q, r, s}]) belongs fragment {p} {p, q} {p, q, r, s}.contrary, formula [{p}]p [{q}]p element fragment CP.call satisfiability problem fragment CP CP-nested satisfiabilityproblem. Due embedding proposed Theorem 3 STIT CP, providefollowing lower bound complexity result CP-nested satisfiability problem. proofgiven Appendix D.Theorem 5. CP-nested satisfiability problem PSPACE-hard.11. authors (e.g., Broersen, 2008; Wansing, 2006) use term multi-agent STIT designatelogic operators form [{j} : stit]. prefer use explicit term individualSTIT Herzig Schwarzentrubers work (2008).105fiGrossi, Lorini, & Schwarzentruberfollowing theorem provides upper bound complexity result fragmentCP. proof given Appendix E.Theorem 6. CP-nested satisfiability problem PSPACE.concludes analysis STIT logics via CP. next section move normalcoalition logic.3.5 Normal Coalition Logicconclude section STIT briefly mentioning related system, normal coalitionlogic. Normal coalition logic NCL introduced Broersen et al. (2007) provideembedding normal modal logic influentialand non-normalcoalition logic(Pauly, 2002). embedding based general simulation technique developedGasquet Herzig (1994) showed first time coalition logicwhichalready recognized fragment ATL containing next operator(Goranko, 2001)could actually interpreted traditional structures Kripkeframes based equivalence relations. NCL studied Balbiani et al. (2008a).Also NCL known atemporal variant, introduced studied Balbiani et al. (2008a)Lorini Schwarzentruber (2011).Two results atemporal NCL literature worth mentioning context.First, Balbiani et al. (2008a, Thm. 38) show satisfiability problem atemporalNCL (when |AGT | 2) NEXPTIME-complete, like CP; second, Lorini Schwarzentruber (2011, Prop. 1) show |AGT | 2, atemporal STIT embeddableatemporal NCL vice versa, embedding (in directions) generalcase possible considerably restricting syntax LSTIT .4. Ceteris Paribus Structure Coalition Logic PropositionalControlsection study relationships CP, atemporal bounded group STIT,another well-known game logic, logic CLPC (coalition logic propositional control ).12 Specifically, show CLPC embedded, preserving satisfiability,atemporal bounded group STIT and, fact atemporal bounded group STITembedded CP (Section 3.1), indirectly show CLPC embeddedCP. complete picture also provide direct embedding CLPC CP.latter embedding particular interest highlight striking similaritiesmodels CP CLPC.CLPC introduced van der Hoek Wooldridge (2005) formal languagereasoning capabilities agents coalitions multiagent environments.logic notion capability modeled means concept control. particular,assumed agent associated specific finite subset Pi finite setpropositions P. Pi set propositions controlled agent i. is, agentability assign (truth) value proposition Pi cannot affect truth12. Gerbrandys work (2006) generalizations assumptions underlying CLPCstudied. consider original version CLPC proposed van der Hoek Wooldridge.106fiThe Ceteris Paribus Structure Logics Game Formsvalues propositions P \ Pi . variant CLPC studied van der HoekWooldridge (2005) also assumed control propositions exclusive, is, twoagents cannot control proposition (i.e., 6= j Pi Pj = ). Moreover,assumed control propositions complete, is, every proposition controlledleast one agent (i.e., every p P exists agent p Pi ).preceding concepts assumptions precisely formulated following section, illustrates syntax formal semantics CLPC.4.1 Syntax Semantics CLPClanguage CLPC built finite set atomic propositions P finite setagents AGT = {1, . . . , n}, defined following BNF:LCLPC (P, AGT ) : ::= p | | ( ) | Jp ranges P J ranges 2AGT . Operator J called cooperation modality,construction J means group J contigent ability achieve .Definition 5 (CLPC model). model CLPC tuple = (P1 , . . . , Pn , X) where:P1 , . . . , Pn partition P among agents AGT ;X P set propositions true initial state.every group agents J AGT , let PJ = iJ Pi set atomic propositionscontrolled group J. Moreover, every group J AGT every set atomicpropositions X P, let XJ = X PJ set atomic propositions X controlledgroup J. Sets XJ called J-valuations.Given CLPC model = (P1 , . . . , Pn , X), truth conditions CLPC formulaefollowing:|=CLPC p p X;|=CLPC 6|=CLPC ;|=CLPC |=CLPC |=CLPC ;|=CLPC J XJ0 PJ :XJ0 |=CLPCLXJ0 CLPC model (P1 , . . . , Pn , X 00 ) that:00XAGT\J = XAGT \JXJ00 = XJ0is, J true given model if, coalition J change truthvalues atoms controls way true afterwards (i.e., givenactual truth-value combination atoms controlled J, existstruth-value combination atoms controlled J ensures ).Let us illustrate CLPC semantics example.107fiGrossi, Lorini, & SchwarzentruberExample 6. Let AGT = {1, 2, 3}, P = {p, q, r}, P1 = {p}, P2 = {q} P3 = {r}.Consider CLPC model = (P1 , P2 , , P3 , {r}). that:|=CLPC {1,2} ((p q r) (p q r)).0Indeed, exists set atoms X{1,2}P{1,2} controlled {1, 2}L 00X{1,2} |=CLPC ((p q r) (p q r)). example X{1,2}= {p} P{1,2} ,which,(P,P,P,{p,r})|=((pqr)(pqr))(P1231 , P2 , P3 , {p, r}) =CLPCL{p}.4.2 Embedding CLPC STITaim section provide embedding CLPC variant atemporal group STIT bounded choices (atemporal bounded group STIT)presented Section 3.1.Let us provide following STIT formulae catpure four basic assumptionsCLPC:^^defEXC + =(h : stiti[{i} : stit]p h : stiti[{j} : stit]p)(5)pP i,jAGT :i6=jEXCdef=^^(h : stiti[{i} : stit]p h : stiti[{j} : stit]p)(6)pP i,jAGT :i6=jdefCOMPL =^_[ : stit]([{i} : stit]p [{i} : stit]p)(7)pP iAGTdefGRID =^h : stitiXP^ppX^p(8)pP\XFormulae EXC + EXC mean control atomic propositions P exclusive(i.e., proposition P forced true false oneagent), whereas formula COMPL means exercise control atomic propositionsP complete (i.e., every proposition P exists least one agent either forcestrue forces false). Finally, formula GRID means possibletruth-value combinations atomic propositions P possible. Note EXC + ,EXC , COMPL GRID well-formed STIT formulae assumptionset P finite.13define following translation LCLPC (P, AGT ) LSTIT (P, AGT ):tr3 (p) = pp Ptr3 () = tr3 ()tr3 ( ) = tr3 () tr3 ()tr3 (J ) = hAGT \ J : stititr3 ()following theorem highlights bounded group STIT embeds CLPC. proofgiven Appendix F.13. assumption also made van der Hoek Wooldridge (2005).108fiThe Ceteris Paribus Structure Logics Game FormsTheorem 7. Let = |P|. Then, CLPC formula CLPC-satisfiable(EXC + EXC COMPL GRID ) tr3 () satisfiable STIT modelagent 2m actions.CP embeds atemporal bounded group STIT (Theorem 3 Section 3.1), Theorem 7 follows CP also embeds CLPC. Indeed, given CLPC-satisfiable formula, one use translation tr2 given Section 3.1 order find corresponding STITformula STIT-satisfiable. Then, one uses preceding translation tr3 orderfind corresponding CP formula CP-satisfiable.Corollary 3. Let = |P|. Then, CLPC formula CLPC-satisfiableGRID tr2 ((EXC + EXC COMPL GRID ) tr3 ()) CP-satisfiable.4.3 Directly Embedding CLPC CPcomplete picture, study direct embedding CLPC CP.Definition 6 (From CLPC CP models). Let = (P1 , . . . , Pn , X) CLPC-model.Define MCP = (W, V ) follows:W = 2P ;V V (p) = {w | p w} p P.Intuitively, V truth-assignment P witnessed exactly onew W wX witness truth assignment represented X (i.e., makesatoms X true rest false). MCP non-redundant universal CP modelMCP , X pointed CP-model (Definition 2). define following translationLCLPC (P, AGT ), partition P1 , . . . , Pn P, LCP (P):tr4 (p) = pp Ptr4 () = tr4 ()tr4 ( ) = tr4 () tr4 ()tr4 (J ) = hYJ itr4 ()YJ =jAGTPj (i.e., atoms controlled anybody J).Theorem 8. Let = (P1 , . . . , Pn , X) CLPC-model LCLPC (P, AGT ):|=CLPC MCP , X |=CP tr4 ()Proof. proceed induction syntax . Base Trivial constructionMCP (Definition 6). Step cases Boolean connectives straightforward.focus modal case:|=CLPC J MCP , X |=CP hYJ itr4 ()109fiGrossi, Lorini, & SchwarzentruberYJ =jNPj . case proven following series equivalences:|=CLPC J XJ0 PJ :LXJ0 |=CLPCSemantics JXJ0 PJ : (P1 , . . . , Pn , XJ0 XAGT \J ) |=CLPCLDefinitionXJ0 PJ : MCP , XJ0 XAGT \J |=CP tr4 ()Definition 6 IHYJ X MCP , |=CP tr4 ()Definition 1MCP , X |=CP hYJ itr4 ()Definition 3completes proof.5. Ceteris Paribus Structure Dynamic Logic PropositionalAssignmentsdynamic logic propositional assignments (DLPA) concrete variant propositional dynamic logic (PDL) (Harel et al., 2000) atomic programs assignmentspropositional variables true false.14 complexities model checkingsatisfiability problem DLPA recently studied Balbiani et al. (2013).starless version DLPA previously studied van Eijck (2000) recentlyput use Herzig et al. (2011), shown embeds CLPC. nextsection study relationship CP DLPA. Specifically, provide truthpreserving embedding starless DLPA CP well truth-preserving embeddingCP DLPA.DLPA, argued Herzig et al. (2011), represents generaldirect link PDLnatural formalism reasoning agency.results section, argue, point similar status CLPC, modulo useKleene star comment Section 7.14. Programs standard PDL abstract letters a, b, . . . alphabet.110fiThe Ceteris Paribus Structure Logics Game Forms5.1 Syntax Semantics DLPAlanguage DLPA built finite set atomic propositions P definedfollowing BNF:::= +p | p | ; | | | ?LDLPA (P) : ::= p | | ( ) | hiuse p denote (+p p).Definition 7 (DLPA model). DLPA-model set X P.is, DLPA model propositional valuation.semantics given induction follows:J+pK = {(X, X 0 ) | X 0 = X {p}};JpK = {(X, X 0 ) | X 0 = X {p}};J; 0 K = JK J 0 K;J 0 K = JK J 0 K;J K = kN JKk ;J?K = {(X, X) | X JK};JpK = {X | p X};JK = 2P JK;J K = JK JK;JhiK = {X | exists X 0 s.th. (X, X 0 ) JK X 0 JK}.write X |=DLPA X JK. refer fragment DLPA withoutoperator starless DLPA.5.2 Properties DLPALike PDL, program constructors ; , ? eliminable:Fact 2. following DLPA validities:h; 0 hih 0h 0 hi h 0h?iHowever, unlike PDL, operator also eliminable DLPA:Fact 3 (Balbiani et al., 2013). every LCLPC (P) exists 0 LCLPC (P)0 DLPA valid.111fiGrossi, Lorini, & Schwarzentruber5.3 Embedding Starless DLPA CPdirect adaptation Definition 6 above, DLPA model X translatedpointed CP model MCP , X defined Definition 6. fix following translation:15tr5 (p) = pp Ptr5 () = tr5 ()tr5 ( ) = tr5 () tr5 ()tr5 (h+pi) = hP \ {p}i(p tr5 ())tr5 (hpi) = hP \ {p}i(p tr5 ())Notice translation starless DLPA CP need include casessequential composition (;), nondeterministic choice () test (?) sinceeliminable DLPA. Therefore, guarantees CP could kindreasoning starless DLPA:Theorem 9. Let X DLPA model belong language starless DLPA:X |=DLPA MCP , X |=CP tr5 ()Proof. proceed induction syntax . Base Trivial constructionMCP (Definition 6). Step cases Boolean connectives straightforward.focus modal case:X |=DLPA h+pi MCP , X |=CP hP \ {p}itr5 ()case proven following series equivalences:X |=DLPA h+pi X {p} |=DLPASemantics h+piP{p} X : MCP , |=CP tr5 () Definition 1 IHMCP , X |=CP hP \ {p}itr5 ()Definition 3case hpi identical.5.4 Embedding CP Starless DLPAsubsection shown semantics CP DLPA closely related.However, DLPA built-in assumption effect valuation (i.e., setatoms) feasible. point view CP means DLPA actually worksuniversal models (cf. Definition 2). Here, establish embedding CP interpreteduniversal models,16 starless DLPA. Consider following translation LCP (P)15. must observed translation work P finite. not, {p} co-finite{p} would belong LCP .16. class models one axiomatize extending axiom system Figure 2 axiomsform hi ranges propositional formulae encoding one single valuation.112fiThe Ceteris Paribus Structure Logics Game FormsLDLPA (P):tr7 (p) = pp Ptr7 () = tr7 ()tr7 ( ) = tr7 () tr7 ()tr7 (hXi) = hp1 . . . hpn itr7 ()p1 , . . . , pn enumeration atoms P \ X.17 following result:Theorem 10. Let CP-model LCP (P):M, w |=CP w |=DLPA tr7 ()Proof. proceed induction syntax . Base Trivial constructionMCP (Definition 6). Step cases Boolean connectives straightforward.focus modal case:M, w |=CP hXi w |=DLPA hp1 . . . hpn itr7 ()p1 , . . . , pn enumeration atoms P\X. case proven followingseries equivalences:M, w |=CP hXi w0 X w s.t. M, w0 |=CPDefinition 1w0 X w s.t. w0 |=DLPA tr7 ()IHw0 s.t. w0 = (. . . (wF{p1 })F . . .)F{pn }w0 |=DLPA tr7 ()w |=DLPA hp1 . . . hpn itr7 ()Definition 1Semantics DLPAF {, }, p1 , . . . , pn enumeration atoms P X.Theorem 10 obtain corollary satisfiability-preserving embedding CPDLPA. Fix formula18^^^defGRID =hipp(9)XPpXpP\Xwhich, easy see, forces CP-model contain propositional valuations P.have:Corollary 4. Let LCP (P). Then, tr7 () DLPA satisfiable iff GRID CPsatisfiable.concludes presentation embeddings STIT, CLPC DLPACP (Figure 1). following section take stock commenting technical resultspresented drawing links related work.17. Again, crucial P finite.18. Cf. Formula (8).113fiGrossi, Lorini, & Schwarzentruber6. Discussion Related Worksection provide summary results presented discuss implications.also position work respect existing contributions literature logicgames.6.1 Discussionpaper introduced modal logic arises naturally interpreting modal operators equivalence relations induced finite sets propositional atoms. logic,called CP, axiomatized embedded (exponentially) S5. CPused tool compare three logics one-shot strategic interactionatemporal STIT,coalitional logic propositional control CLPC dynamic logic propositionalassignments DLPA. logics embedded CP.embeddings (recall Figure 1) put us position draw followinggeneral remarks.appears justified talk common ceteris paribus structure underpinning several main logics game forms embeddable CP.illustrates striking uniformity logical tools needed expressing choiceeffectivity games logical languages, CP appears offer well-suitedabstraction systematizing existing formalisms.Furthermore, logics embeddable S5 (either directly via CP), highlighting fact order reason choice effectivity games oneessentially reasons suitably defined partitions state space.New interesting far unexplored embeddings obtainable corollaries.particular, follows results atemporal STIT bounded modelsembedded starless DLPA via CP.Via logic S5, one easily show embeddings directions alsopossible (albeit exponential cost), arrows Figure 1 may actuallymade symmetric. S5 embeds CP, also directly embeddablementioned logic, contain universal modality, following forms: hiCP, hAGT \ : stiti atemporal STIT, AGT CLPC hp1 . . . hpnDLPA (where p1 , . . . , pn enumeration P).results unveil strikingand extent unexpecteduniformityunderpinning formalisms considered.6.2 Related Workreview two sets related contributions.6.2.1 CP Modal Ceteris Paribus Logicstwo logics modal logic literature strictly related CP: releaselogic, logic ceteris paribus preference.114fiThe Ceteris Paribus Structure Logics Game FormsRelease logic relatively less known formalism landscape modal logicsartificial intelligence. introduced studied Krabbendam Meyer (2003,2000) order provide modal logic characterization general notion irrelevancy.Modal operators release logic S5 operators indexed subsets finite set Issabstract elements denoting issues taken irrelevant, released,evaluating formula scope operator. release model therefore tuple(W, {rX }XIss , V ) rX equivalence relations additional constraintX rX rY , is, releasing issues one obtains coarseequivalence relation. Formally, semantics release operators:M, w |= X w0 W : w rX w0 M, w0 |=X Iss = (W, {rX }XIss , V ).One easily observe that, Fact 1 (clause (ii)), CP models release modelsIss = P release relation rX =X . Vice versa, Iss = P, releasemodels CP models. consequence, logic hXi operators CP conservativeextension logic X release operators.Preference logic also long concerned so-called ceteris paribus preferences,is, preferences incorporating things equal condition. first logicalanalysis preferences dates back Von Wrights work (1963), dyadic modaloperators studied representing statements like preferred , ceteris paribus.recently, van Benthem et al. (2009) studied modal logic ceteris paribus preferences basedstandard unary modal operators. Leaving preferential component logic aside,ceteris paribus fragment concerns sentences form hi whose intuitive meaningexists state equivalent current (evaluation) state respectformulae (finite) set satisfies , formulaeatoms formulae full language. Logic CP is, therefore, fragmentceteris paribus logic studied van Benthem et al. allowed consistfinite set atoms.6.2.2 Contributions Systematization Game LogicsDespite wealth approaches found literature game logics,papers attempted form comparison spanning across several formalisms,attempting kind systematization. Two particular worth mentioning here.recent one Herzigs work (2014), provides comprehensiveanalysis field classifying existing logics depending aspects agency(e.g., whether capture strategic interaction not, whether handle uncertaintyepistemic attitudes) capture languages. logics consideredpaper, instance, would fall strategic uncertainty categories accordingterminology used Herzig. analysis conceptual predominantly drivensyntactic features logics, is, theorems agency enable.earlier work methodologically closer focus semanticsGoranko Jamrogas work (2004). paper compares ATL, epistemic variant ATEL(epistemic ATL, van der Hoek & Wooldridge, 2003) ECL (extended CL,19 Pauly, 2001)19. CL extended Kleene star operator.115fiGrossi, Lorini, & Schwarzentruberproviding constructive transformations models establishing, particular,ATL subsumes ECL ATEL embedded ATL preserving satisfiability.7. Conclusions Future Workpaper provided unification the, date, influential logics representation one-shot strategic interactionatemporal STIT, CLPC starless DLPAceteris paribus abstraction formalized logic CP.One natural future research direction presents itself, consists extending logicCP Kleene star operator, analogy DLPA. conjecture DLPAembeddable CP Kleene star remains investigated whether newlogic could play unifying role logics extensive form games, showplays atemporal case. complete systematization program initiatedcurrent paper.Related question, somewhat technical vein, shownpaper CP atemporal individual STIT high complexitysatisfiability problem consider whole languages. study efficientsyntactic fragments important intend pursue study parallelCP atemporal individual STIT. expect several complexity resultsfragments atemporal STIT may transferred fragments CP viceversa.Acknowledgmentsauthors wish thank anonymous reviewers JAIR thorough helpfulcomments. paper greatly improved thanks feedback.Appendix A. Proof Claim () Theorem 1Proof. One show REP derivable every operator [X] follows: first one shows[X] operator satisfies Axiom K rule necessitation N.provide syntactic proofs two claims. notational convenience use following abbreviation:defYb =^ppY116^pX\YpfiThe Ceteris Paribus Structure Logics Game Forms1.Derivation K [X]:^`CP [X]( )Yb [] Yb ( )X2.Reduce`CP Yb ( ) (Yb ) (Yb )P3.^`CP^Yb [] Yb ( )Yb [] (Yb ) (Yb )XX4.P, 2 rule RM [] (i.e., ` ` [] [])^^`CPYb [] (Yb ) (Yb )Yb [](Yb ) [](Yb )5.K P^^Yb [](Yb ) [](Yb )Yb [] Yb`CPXXXX^Yb [] YbXP6.^`CP (^Yb [] YbYb [] Yb ) ([X] [X])XXReduce7.`CP [X]( ) ([X] [X])1 3-6Derivation N [X]:1.`CPhypothesis2.`CP []3.1 N []^`CP[] YbX4.2 S5 theorem [] []( )^`CPYb [] YbX3 P5.`CP [X]4 Reduce MP117fiGrossi, Lorini, & Schwarzentruberone proves REP derivable induction routine analogous one usedChellas (1980, Thm. 4.7).Appendix B. Proof Theorem 2Let 0 CP-formula. equivalence 0 CP-satisfiable tr(0 )S5-satisfiable.Proof. Suppose exists CP-model = (W, V ) world w WM, w |=CP 0 . Let V 0 valuation V modified p true exactlyworlds u M, u |=CP . Let M0 S5-model defined (W, V 0 ). standardinduction provides M0 , w |=S5 tr(0 ). precisely, let us prove inductionSF (0 ), M, u |=CP iff M0 , u |=S5 tr1 () u W .Propositional case: atomic propositions p, M, u |=CP p iff u V (p) iffu V 0 (p) iff M0 , u |=S5 tr1 (p).Negation: M, u |=CP iff M, u 6|=CP iff M0 , u 6|=S5 tr1 () iff M0 , u |=S5 tr1 ().Conjunction: M, u |=CP iff M, u |=CP M, u |=CP iff M0 , u |=S5 tr1 ()M0 , u |=S5 tr1 () iff M0 , u |=S5 tr1 ( ).Case formula form [X]:M, u |=CP [X]iff v W , u VX v implies M, v |=CPiff v W , u VX v implies M0 , v |=S5 p(by construction V 0 )iff M0 , u |=S5 tr1 ([X])Vconstruction V 0 , M0 , w |=S5 SF (0 ) (p tr1 ()). M, w |=CP 0M0 , w |=S5 tr1 (0 ) thus M0 , w |=S5 p0 construction V 0 . result, M0 , w |=S5tr(0 ).Suppose exists S5 model M0 = (W, V ) world w W0, w |=S5 tr(0 ). define relations X X P Definition 1. LetCP-model equal (W, V ). standard induction provides M, w |=CP 0 .precisely, let us prove induction SF (0 ), M, u |=CP iffM0 , u |=S5 tr1 () u W .Propositional case: atomic propositions p, M, u |=CP p iff u V (p) iffu V 0 (p) iff M0 , u |=S5 tr1 (p).Negation: M, u |=CP iff M, u 6|=CP iff M0 , u 6|=S5 iff M0 , u |=S5 .Conjunction: M, u |=CP iff M, u |=CP M, u |=CP iff M0 , u |=S5 tr1 ()M0 , u |=S5 tr1 () iff M0 , u |=S5 tr1 ( ).118fiThe Ceteris Paribus Structure Logics Game FormsCase formula form [X]:M, u |=CP [X]iff v W , u VX v implies M, v |=CPiff v W , u VX v implies M0 , v |=S5 tr1 ()(by induction)iff v W , u VX v implies M0 , v |=S5 p(because, M0 , w |=S5 tr(0 )v W , M0 , v |=S5 (p tr1 ()))iff M0 , u |=S5 tr1 ([X])M0 , w |=S5 tr(0 ), M0 , w |=S5 (p0 tr1 (0 )) M0 , w |=S5 p0 . Thus,M0 , w |=S5 tr1 (0 ). Hence M, w |=CP 0 .Appendix C. Proof Theorem 3Let us consider group STIT formula . Let integer. following itemsequivalent:1. satisfiable model agent 2m actions;2. satisfiable model agent exactly 2m actions;3. GRIDm tr2 () CP-satisfiable.Proof. 1 2 Let M0 = (W 0 , {RJ0 }JAGT , V 0 ) STIT-model 2m actionsper agent w W 0 M0 , w |=STIT . construct sequence modelsMj = (W j , {RJj }JAGT , V j ) agents j 0 {1, . . . , j} exactly 2m actionsMj Mj bisimilar Mj1 . construct Mj Mj1 follows.j1j1j1Let R{j}(w1 ), . . . , R{j}(wk ) enumeration R{j}- classes (that is, actions agentsj1j), k 2m . Let (Copy` )`{k+1,...,2m } family disjoint copies R{j}(w1 ).write uCv say u = v v copy u u copy v. modelMj = (W j , {RJj }JAGT , V j ) defined follows:W j = W j1 `{k+1,...,2m } Copy` ;jj1R{j}= R{j}`{k+1,...,2m } {(u, v)| u, v Copy` }jj10R{j0 } = C R{j 0 } C j 6= j;V j (p) = {v W j | vCu u V j1 (p)}.119fiGrossi, Lorini, & Schwarzentruberconstruction makes Mj Mj1 bisimilar inductionagents j 0 {1, . . . , j} exactly 2m actions Mj . Finally, Mn , w |=STITagent exactly 2m actions Mn .23LetusconsiderSTITmodel= (W, {RJ }JAGT , V ) agent exactly 2 actions. Let w WM, w |=STIT . j AGT , let R{j} (wj,1 ), . . . , R{j} (wj,2m ) enumeration R{j} -classes M. Let us extend V worlds R{j} (wj,i )valuations atomic propositions Rj correspond binary digits binaryrepresentation i. {1, . . . , m}:[R{j} (wj,i )(10)V (rep jd ) =i=1..2m | dth digit 1Independence agents ensures M, w |=CP GRIDm . prove M, u |=CPtr2 () iff M, u |=STIT induction subformulae .3 1 Let = (W, V ) CP-model w W M, w |=CP GRIDmtr2 (). define RJ =SjJ Rj . resulting Kripke-model M0 = (W, {RJ }JAGT , V )STIT-model agent exactly 2m actions. particular, satisfiesindependence agents M, w |=CP GRIDm . prove M, u |=CP tr2 () iffM0 , u |=STIT induction subformulae .Appendix D. Proof Theorem 5CP-nested satisfiability problem PSPACE-hard.Proof. reduce satisfiability problem STIT-formulae coalitions takenlinear set coalitions, PSPACE-complete (Schwarzentruber, 2012)CP-nested satisfiability problem: use translation tr2 Subsection 3.1. LetSTIT-formula. STIT-satisfiable iff tr2 () CP-satisfiable.stated Schwarzentruber (2012), STIT coalitions takenlinear set coalitions exponential model property. result Theorem 3true. Hence STIT-satisfiable GRIDm tr2 () CP-satisfiable (wherelength ). Hence tr2 () CP-satisfiable.Suppose exists CP-model = (W, V ) w W M, w |=tr2 (). define RJ =SjJ . STIT model M0 = (W, (RJ )J , V )M0 , w |= . Remark need specify relations RJ J. longRJ specified coalitions J appear RJ RJ 0 J 0 J,extend Kripke model M0 completely specified STIT-model also satisfying .20Appendix E. Proof Theorem 6CP-nested satisfiability problem PSPACE.Proof. reduce CP-nested satisfiability problem satisfiability problem STITcoalitions taken linear set coalitions. define AX = {jp p X}20. See Schwarzentrubers paper (2012) details construnction.120fiThe Ceteris Paribus Structure Logics Game Formsjp fresh agent corresponding atomic proposition p. Let us define following translation:tr(p) = p;tr() = tr();tr( ) = tr() tr0 ();tr([X]) = [AX : stit]tr().Let us consider fixed CP-formula . recall signature X appearsexists formula hXi SF (). also define following formulaVCON ROL = [ : stit] X appearingVpX (p [AX : stit]p) (p [AX : stit]p).tr() CON ROL STIT-formula computable polynomial timesatisfies condition nesting groups (i.e., two operators [J : stit][J 0 : stit] occurring formula either J J 0 J 0 J). alsoCP-satisfiable iff tr() CON ROL satisfiable STIT-model.Suppose exists CP-model = (W, V ) w WM, w |=CP . define RAX =X . STIT model M0 = (W, (RAX )X , V )M0 , w |=STIT tr() CON ROL. Remark need specifyrelations RJ J. long RJ specified coalitions J appeartr() CON ROL RJ RJ 0 J 0 J, extend Kripke model M0completely specified STIT-model also satisfying tr() CON ROL.21SupposeexistsSTIT-modelM0 = (W, (RAX )X , V ) world w W M0 , w |=STIT tr() CON ROL.M0 , w |= CON ROL, X = RAX . reason define =(W, {X }X2P , V ). Consequently, M, w |=CP .Appendix F. Proof Theorem 7Let = |P|. Then, CLPC formula CLPC satisfiable (EXC +EXC COMPL GRID ) tr3 () satisfiable STIT model agent2m actions.Proof. Let us suppose |P| = m.Let = (P1 , . . . , Pn , X ) CLPC model |=CLPC ,P1 , . . . , Pn partition P among agents AGT .build STITmodel = (W, {RJ }JAGT , V ) follows:W = {X : X P},J AGT X, X 0 W , (X, X 0 ) RJ0 XJ = XJ0 ,21. see Schwarzentrubers paper details construction.121fiGrossi, Lorini, & Schwarzentruberp P X W , X V (p) p X,X P J AGT , XJ = X PJ (with PJ = iJ Pi ). size2m . follows number RAGT -equivalence classes (alias joint actions)equal lower 2m . Consequently, number actions every agent bounded2m .straightforward prove X W M, X |=STIT EXC +EXC COMPL GRID . Moreover, induction structure , proveM, X |=STIT tr3 (). interesting case = J :|=CLPC J iff exists XJ PJ s.t.XJ |=CLPCiff exists XJ PJ s.t.M, XJ XAGT\J |=STIT tr3 () (by I.H.)iff M, X |=STIT hAGT \ J : stititr3 ()Let = (W, {RJ }JAGT , V ) STIT model number actionsevery agent bounded 2m w0 W M, w0 |=STIT (EXC + EXCCOMPL GRID ) tr3 ().AGT , letM, v |= [{i} : stit]pCtrl = p P : v W,M, v |= [{i} : stit]pset atoms P controlled agent i. J AGT , let Ctrl J =iJCtrli .Lemma 3. J AGT , X P, X X w W have:(i) CtrlJ = X CtrlAGT \J = P \ X,VV(ii) M, w |=STIT p+ p p p CtrlJ = X then, v RJ (w),X VXVM, v |=STIT p+ p p p,XX0(iii) CtrlJ = X then, P\XP\X, exists v RJ (w) M, v |=STITVVpp.0+0ppP\XP\X+X P X X, X= X X= X \ X .Proof. (i) Let us suppose p 6 CtrlJ . going prove p CtrlAGT \J .p 6 CtrlJ follows w W M, v |=STIT p v RJ (w).implies J w W M, w |=STIT [{i} : stit]p[{i} : stit]p. M, w0 |=STIT COMPL follows AGT \ JM, w |=STIT [{i} : stit]p [{i} : stit]p w W . latter impliesp CtrlAGT \J . direction (i.e., p CtrlJ implies p 6 CtrlAGT \J ) followsM, w0 |=STIT EXC + EXC .122fiThe Ceteris Paribus Structure Logics Game Forms(ii) Let us suppose M, w |=V+pXpVpXp CtrlJ = X. fact+relations RJ reflexive, follows that, p X, exists JM, w |=STIT [{i} : stit]p p X exists J M, v |=STIT [{i} :+stit]p. latter follows p XM, w |=STIT [J : stit]pp VM,v|=[J:stit]p.Therefore,v RJ (w),STITXVM, v |=STIT p+ p p p.XX0P\X(iii) Let us suppose CtrlJ = X let us consider arbitrary P\Xw W .VFrom M, wV|=GRIDfollowsexistsvW0STITM, v |=STIT p0+ p p0 p. item (ii), latter implies existsP\XP\XVVv W M, v |=STIT [AGT \J : stit]( p0+ p p0 p). constraintP\XP\XV independenceV agents follows exists v RJ (w) M, v |=STITp0+pp 0 p.P\XP\Xtransform STIT model CLPC model = (P1 , . . . , Pn , X ) follows:p P, p X w0 V (p),p P AGT , p Pi p Ctrli .item (i) Lemma 3 easy check indeed CLPC model.particular, P1 , . . . , Pn partition P among agents AGT .induction structure using Lemma 3 straightforward prove|=CP . interesting case = J :M, w0 |=STIT hAGT \ J : stititr3 ()iff M, v |=STIT tr3 () v RAGT \J (w0 )iff exists XJ PJ s.t.(P1 , . . . , Pn , XJ XAGT\J ) |=CP(by I.H., items (ii) (iii)Lemma 3)iff |=CP Jcompletes proof.ReferencesAlur, R., Henzinger, T., & Kupferman, O. (2002). Alternating-time temporal logic. JournalACM, 49, 672713.Areces, C., & Ten Cate, B. (2006). Hybrid logics. Blackburn, P., van Benthem, J., &Wolter, F. (Eds.), Handbook Modal Logic, pp. 821868. Elsevier.Balbiani, P., Gasquet, O., Herzig, A., Schwarzentruber, F., & Troquard, N. (2008a). Coalition games kripke semantics. Degremont, C., Keiff, L., & Ruckert, H. (Eds.),Festschrift Honour Shahid Rahman, pp. 112. College Publications.123fiGrossi, Lorini, & SchwarzentruberBalbiani, P., Herzig, A., & Troquard, N. (2008b). Alternative axiomatics complexitydeliberative stit theories. Journal Philosophical Logic, 37 (4), 387406.Balbiani, P., Herzig, A., & Troquard, N. (2013). Dynamic logic propositional assignments:well-behaved variant PDL. Proceedings 28th ACM/IEEE SymposiumLogic Computer Science (LICS 2013), pp. 143152. IEEE Computer Society.Belnap, N., Perloff, M., & Xu, M. (2001). Facing future: agents choicesindeterminist world. Oxford University Press, USA.Blackburn, P., de Rijke, M., & Venema, Y. (2001). Modal Logic. Cambridge UniversityPress, Cambridge.Broersen, J. (2008). complete STIT logic knowledge action,applications. Proceedings 6th International Workshop Declarative AgentLanguages Technologies (DALT 2008), Vol. 5397 LNCS, pp. 4759. SpringerVerlag.Broersen, J., Herzig, A., & Troquard, N. (2005). coalition logic STIT. Lomuscio,A., de Vink, E., & Wooldridge, M. (Eds.), Proceedings Third InternationalWorkshop Logic Communication Multi-agent Systems (LCMAS05), pp.2335.Broersen, J., Herzig, A., & Troquard, N. (2006). Embedding alternating-time temporal logicstrategic STIT logic agency. Journal Logic Computation, 16 (5), 559578.Broersen, J., Herzig, A., & Troquard, N. a. (2007). normal simulation coalition logicepistemic extension. Samet, D. (Ed.), Proceedings TARK07, pp. 92101.ACM Press.Chellas, B. F. (1980). Modal Logic. Introduction. Cambridge University Press, Cambridge.Dunne, P., van der Hoek, W., Kraus, S., & Wooldridge, M. (2008). Cooperative booleangames. Proceedings AAMAS 2008, pp. 10151022. ACM.Gabbay, D. M., Kurucz, A., Wolter, F., & Zakharyaschev, M. (2003). Many-dimensionalmodal logics: theory applications. Elsevier.Gasquet, O., & Herzig, A. (1994). Translating non-normal modal logics normal modallogics.. Jones, A., & Sergot, M. (Eds.), Proceedings International WorkshopDeontic Logic Computer Science (DEON94).Gerbrandy, J. (2006). Logics propositional control. Proceedings AAMAS06, pp.193200. ACM.Goldblatt, R. (1992). Logics Time Computation. CSLI.Goranko, V. (2001). Coalition games alternating temporal logics. Proceedings8th conference theoretical aspects rationality knowledge (TARK01), pp.259272.Goranko, V., & Jamroga, W. (2004). Comparing semantics logics multi-agent systems.Synthese, 139, 241280.124fiThe Ceteris Paribus Structure Logics Game FormsGoranko, V., Jamroga, W., & Turrini, P. (2013). Strategic games truly playable effectivity functions. Journal Autonomous Agents Multi-Agent Systems, pp.288314.Harel, D., Kozen, D., & Tiuryn, J. (2000). Dynamic Logic. MIT Press.Harrenstein, P., van der Hoek, W., Meyer, J., & Witteveen, C. (2001). Boolean games.van Benthem, J. (Ed.), Proceedings TARK01, pp. 287298. Morgan Kaufmann.Herzig, A. (2014). Logics knowledge action: critical analysis challenges. JournalAutonomous Agents Multi-Agent Systems, DOI: 10.1007/s10458-014-9267-z.Herzig, A., Lorini, E., Moisan, F., & Troquard, N. (2011). dynamic logic normativesystems. Walsh, T. (Ed.), Proceedings Twenty-Second International JointConference Artificial Intelligence (IJCAI 2011), pp. 228233. AAAI Press.Herzig, A., & Schwarzentruber, F. (2008). Properties logics individual groupagency. Advances modal logic, 7, 133149.Horty, J. F. (2001). Agency Deontic Logic. Oxford University Press, Oxford.Krabbendam, J., & Meyer, J. (2003). Contextual deontic logics. McNamara, P., &Prakken, H. (Eds.), Norms, Logics Information Systems, pp. 347362, Amsterdam. IOS Press.Krabbendam, J., & Meyer, J. (2000). Release logics temporalizing dynamic logic, orthogonalising modal logics. Barringer, M., Fisher, M., Gabbay, D., & Gough, G.(Eds.), Advances Temporal Logic, pp. 2145. Kluwer Academic Publisher.Lorini, E., & Schwarzentruber, F. (2011). logic reasoning counterfactual emotions. Artificial Intelligence, 175 (3-4), 814847.McCann, H. J. (1974). Volition basic action. Philosophical Review, 83, 451473.Moulin, H., & Peleg, B. (1982). Cores effectivity functions implementation theory.Journal Mathematical Economics, 10, 115145.Osborne, M. J., & Rubinstein, A. (1994). Course Game Theory. MIT Press.OShaughnessy, B. (1974). Trying (as mental pineal gland). Journal Philosophy,70, 365386.Pauly, M. (2001). logical framework coalitional effectivity dynamic procedures.Bulletin Economic Research, 53 (4), 305324.Pauly, M. (2002). modal logic coalitional power games. Journal LogicComputation, 12 (1), 149166.Schwarzentruber, F. (2012). Complexity results STIT fragments. Studia logica, 100 (5).Tseitin, G. (1968). complexity derivation propositional calculus.. StructuresConstructive Mathematics Mathematical Logic, Part II, Seminars Mathematics (translated Russian). Steklov Mathematical Institute.van Benthem, J., Girard, P., & Roy, O. (2009). Everything else equal: modal logicceteris paribus preferences. Journal Philosophical Logic, 38, 83125.125fiGrossi, Lorini, & Schwarzentrubervan der Hoek, W., & Pauly, M. (2007). Modal logic games information. Blackburn,P., van Benthem, J., & Wolter, F. (Eds.), Handbook Modal Logic, pp. 10771146.Elsevier.van der Hoek, W., & Wooldridge, M. (2003). Cooperation, knowledge time: Alternatingtime temporal epistemic logic applications. Studia logica, 75 (1), 125157.van der Hoek, W., & Wooldridge, M. (2005). logic cooperation propositionalcontrol. Artificial Intelligence, 164, 81119.van Ditmarsch, H., Kooi, B., & van der Hoek, W. (2007). Dynamic Epistemic Logic, Vol.337 Synthese Library Series. Springer.van Eijck, J. (2000). Making things happen. Studia logica, 66 (1), 4158.Von Wright, G. H. (1963). Logic Preference. Edinburgh University Press.Walther, D., van der Hoek, W., & Wooldridge, M. (2007). Alternating-time temporal logicexplicit strategies. Proceedings 11th conference Theoretical AspectsRationality Knowledge, pp. 269278. ACM Press.Wang, Y., & Cao, Q. (2013). axiomatizations public announcement logic. Synthese,190, 103134.Wansing, H. (2006). Tableaux multi-agent deliberative-STIT logic. Governatori, G.,Hodkinson, I., & Venema, Y. (Eds.), Advances Modal Logic, Volume 6, pp. 503520.Kings College Publications.Xu, M. (1998). Axioms deliberative STIT. Journal Philosophical Logic, 27, 505552.126fiJournal Artificial Intelligence Research 53 (2015) 223-270Submitted 12/14; published 06/15Probabilistic Inference Techniques ScalableMultiagent Decision MakingAkshat Kumarakshatkumar@smu.edu.sgSchool Information SystemsSingapore Management University, SingaporeShlomo Zilbersteinshlomo@cs.umass.eduCollege Information Computer SciencesUniversity Massachusetts, Amherst, USAMarc Toussaintmarc.toussaint@informatik.uni-stuttgart.deDepartment Computer ScienceUniversity Stuttgart, GermanyAbstractDecentralized POMDPs provide expressive framework multiagent sequential decision making. However, complexity modelsNEXP-Complete even twoagentshas limited scalability. present promising new class approximation algorithms developing novel connections multiagent planning machinelearning. show multiagent planning problem reformulated inferencemixture dynamic Bayesian networks (DBNs). planning-as-inference approachpaves way application efficient inference techniques DBNs multiagentdecision making. improve scalability, identify certain conditions sufficient extend approach multiagent systems dozens agents. Specifically,show necessary inference within expectation-maximization frameworkdecomposed processes often involve small subset agents, thereby facilitatingscalability. show number existing multiagent planning models satisfyconditions. Experiments large planning benchmarks confirm benefitsapproach terms runtime scalability respect existing techniques.1. IntroductionDecentralized partially observable MDPs (Dec-POMDPs) emerged recent yearsprominent framework modeling sequential decision making team collaborating agents (Bernstein, Givan, Immerman, & Zilberstein, 2002). expressive powermakes possible tackle coordination problems agents must act based different partial information environment maximizeglobal reward function. Applications Dec-POMDPs include coordinating operationplanetary exploration rovers (Becker, Zilberstein, Lesser, & Goldman, 2004), coordinatingfirefighting robots (Oliehoek, Spaan, & Vlassis, 2008), target tracking team sensoragents (Nair, Varakantham, Tambe, & Yokoo, 2005) improving throughput wirelessnetworks (Pajarinen, Hottinen, & Peltonen, 2014).rapid progress exact algorithms Dec-POMDPs (Oliehoek,Spaan, Amato, & Whiteson, 2013), optimal solutions obtained relac2015AI Access Foundation. rights reserved.fiKumar, Zilberstein, & Toussainttively smaller problems. terms computational complexity, optimally solving finitehorizon Dec-POMDP NEXP-Complete (Bernstein et al., 2002). contrast, finite-horizonPOMDPs PSPACE-complete (Mundhenk, Goldsmith, Lusena, & Allender, 2000),strictly lower complexity class highlights difficulty solving Dec-POMDPs.1.1 Related Workfinite-horizon case, substantial number promising point-based approximatealgorithms developed (Kumar & Zilberstein, 2010b; Wu, Zilberstein, & Chen,2010; Dibangoye, Mouaddib, & Chaib-draa, 2009; Kumar & Zilberstein, 2009a; Seuken &Zilberstein, 2007). However, unlike point-based counterparts POMDPs (Pineau,Gordon, & Thrun, 2006; Smith & Simmons, 2004), cannot easily adoptedinfinite-horizon case due variety reasons. example, POMDP algorithms representpolicy compact -vectors, whereas Dec-POMDP algorithms explicitly storepolicy mapping observation sequences actions, making unsuitableinfinite-horizon case. motivated development alternative approaches,approximating factored finite-horizon Dec-POMDPs series collaborative graphicalBayesian games (Oliehoek, Whiteson, & Spaan, 2013) using genetic algorithms (Eker &Akin, 2013).Recently, number approaches developed transform Dec-POMDPcontinuous-state MDP use techniques POMDP literature solvecontinuous-state MDP (Dibangoye, Amato, Doniec, & Charpillet, 2013a; Dibangoye,Amato, Buffet, & Charpillet, 2013b). state continuous MDP reformulationDec-POMDP, also called occupancy state, probability distribution world statehistory observations agent received. Despite adoption efficientPOMDP techniques reformulation, drawback approach sizeobservation histories increases exponentially respect plan horizon. contrast,approach uses notion finite-state controllers (FSCs) summarize relevantfeatures planning problem. Often, compact FSCs provide good approximationlarge planning problems. occupancy state based formulation also appliedinfinite-horizon problems converting infinite-horizon problem approximatefinite-horizon version. done using future reward discount factor derivefinite-horizon H remaining rewards negligible contributionoverall value function (Dibangoye, Buffet, & Charpillet, 2014). drawbacktruncated horizon approach that, high discount factors, required horizon Hprohibitively large.terms solution representation, algorithms infinite-horizon problems represent agent policies finite-state controllers (Amato, Bernstein, & Zilberstein, 2010; Bernstein, Amato, Hansen, & Zilberstein, 2009), unlike algorithms finite-horizon problemsoften use policy trees (Hansen, Bernstein, & Zilberstein, 2004). resulting solutionapproximate limited memory controllers optimizingaction selection transition parameters extremely hard. Previous approachesoptimize finite-state controller based policies include decentralized bounded policy iteration (DEC-BPI) (Bernstein et al., 2009) technique based non-linear programming(NLP) (Amato et al., 2010). DEC-BPI algorithm uses linear programming formula224fiProbabilistic Inference Multiagent Decision Makingtion improve parameters one node one finite-state controller time.is, fixes parameters nodes controllers, except single nodeparticular agent. uses linear program find better action selection transitionparameters particular node. LP guarantees policy value increasedevery belief state. major drawback scheme designed optimize value particular belief state. Therefore, produce good policy, DEC-BPImay need large number controller nodes, reduces effectiveness LPformulation.contrast DEC-BPI approach, NLP formulation Amato et al. (2010)optimize controllers given initial belief state. formulation linear objectivefunction. However, Bellman constraints, involve additional variables representingvalue node, nonlinear non-convex variables. causeNLP solver get stuck local optimum. Furthermore, empirically observedperformance state-of-the-art NLP solvers SNOPT (Gill, Murray, & Saunders,2002) degrades quickly even moderate increase number nonlinear constraints.highlights challenges presented scaling NLP approach larger ( 2 agents)problems. complementary research direction investigate kind structurecontroller enable better quality solutions. example, layered controllersdeveloped POMDPs Dec-POMDPs, optimized point basedapproaches (Pajarinen & Peltonen, 2011b). EM based planning algorithms developwork also take advantage controller structures. approachescompute policies infinite-horizon Dec-POMDPs based controllerrepresentation joint-policy (MacDermed & Isbell, 2013). However, key advantagepolicies based finite-state controllers ease execution resource constrainedenvironments (Grzes, Poupart, & Hoey, 2013; Grzes, Poupart, Yang, & Hoey, 2015), withoutexpensive belief update operations required approaches. Furthermore, policiesrepresented finite-state controllers carry semantic information,controller node summarizes relevant aspects observation history.Generalizing Dec-POMDP algorithms two agents persistentchallenge problem representation algorithmic viewpoints. Many recent attempts increase scalability planners respect number agents imposerestrictions form interaction among agents. Examples restrictions include transition independence (Becker et al., 2004; Nair et al., 2005), weak-coupling amongagents limited certain states (Varakantham, Kwak, Taylor, Marecki, Scerri, &Tambe, 2009), directional transition dependence (Witwicki & Durfee, 2010). Oneearliest models demonstrated scalability limiting interactions among agentstransition-independent Dec-MDP (TI-Dec-MDP) (Becker, Zilberstein, Lesser, & Goldman,2003). Agents models fully affect observe local state, cannotaffect local states observations agents. dependence among agents limited joint reward function. restricted model shown NP-CompleteGoldman Zilberstein (2004), also conducted detailed complexity analysisdifferent subclasses Dec-POMDPs various limitations agent interactions. extension TI-Dec-MDP proposed Becker, Zilberstein, Lesser (2004), introducingstructured transition dependencies.225fiKumar, Zilberstein, & ToussaintTI-Dec-MDP model extended handle partial observability probleminstance Nair et al. (2005), resulting model called network-distributed POMDP(ND-POMDP). shown value function ND-POMDPs factorizes amongsmaller sub-groups agents based immediate reward decomposability. propertyused develop number algorithms scale relatively well respectnumber agents (Nair et al., 2005; Varakantham, Marecki, Yabu, Tambe, & Yokoo, 2007;Marecki, Gupta, Varakantham, Tambe, & Yokoo, 2008). Another restricted class modelstransition-decoupled POMDP (TD-POMDP) (Witwicki & Durfee, 2010). modelexplicitly differentiates agents private state affectedagents local action shared states affected agents. Structuredinteractions also used deciding communicate among agents (Mostafa& Lesser, 2009, 2011). Within framework multiagent MDPs (MMDPs), submodularity property value function class sensor network planning problemsexploited Kumar Zilberstein (2009b).large, models try identify restrictions agent interactionsfacilitate scalable planning. exception work Witwicki Durfee (2011),much work towards general characterization conditionsmultiagent planning made scalable. Witwicki Durfee provide characterizationweak-coupling among agents similar work. However, significant differencepropose concrete algorithm efficiently exploit weak-coupling amongagents enable scalability large multiagent systems. algorithmic outline presentedWitwicki Durfee exploit weak interactions among agents mapping policyoptimization problem constraint optimization scalable involves enumeratingpolicy space agents.article extends two conference papers published UAI10 (Kumar & Zilberstein,2010a) IJCAI11 (Kumar, Zilberstein, & Toussaint, 2011) detailed background, new theorems proofs, simplified EM derivations, detailed derivationEM updates ND-POMDP model. EM based policy optimization approachdeveloped foundation several efforts explore different aspects multiagent planning. example, Wu, Zilberstein, Jennings (2013) developed samplingbased E-step inference techniques. technique particularly useful model-freesetting underlying model known. Pajarinen Peltonen (2011a) extend EM approach factored Dec-POMDPs. present approximationE-step using factored representation forward backward messages definedSection 4.4. approach increases scalability EM algorithm w.r.t. number agents problem parameters expense making EM algorithmapproximate. is, E steps approximate may lead non-monotonicimprovement policy value. Pajarinen Peltonen (2013) extend EMapproach average reward Dec-POMDPs.techniques present article differ previous approachesrather approximating computationally challenging inference larger multiagentsystems, explore natural ways decompose inference process produceexact, yet scalable EM algorithm. show necessary conditionsvalue factorization based decomposition satisfied several existing planning models,confirming generality developed framework.226fiProbabilistic Inference Multiagent Decision Making1.2 Summary Contributionspresent promising new class algorithms combines planning probabilistic inference opens door application rich inference techniques solvinginfinite-horizon Dec-POMDPs. approach based Toussaint et. al.s approachtransforming single-agent planning problem equivalent mixture dynamic Bayesnets (DBNs) using likelihood maximization framework optimize policyvalue (Toussaint & Storkey, 2006; Toussaint, Harmeling, & Storkey, 2006). approachessuccessful solving MDPs POMDPs (Toussaint et al., 2006) easily extend factored hierarchical structures (Toussaint, Charlin, & Poupart, 2008).Furthermore, handle continuous action state spaces thanks advanced probabilistic inference techniques (Hoffman, Kueck, de Freitas, & Doucet, 2009b). showDec-POMDPs, much harder solve MDPs POMDPs, alsoreformulated mixture DBNs. present Expectation Maximization (EM)algorithm (Dempster, Laird, & Rubin, 1977) maximize reward likelihoodpolicy value framework. approach offers attractive anytime algorithm EM improves likelihoodand hence policy valuewith iteration.experiments benchmark domains show EM compares favorably previousapproaches optimize FSCs, DEC-BPI NLP-based optimization.address scalability respect number agents, identify conditionsbased value function factorization sufficient make planning amenablescalable approximation. achieved constructing graphical model exploitslocality interactions among agents. show efficiently extend likelihoodmaximization paradigm generalized graphical model. Furthermore, shownecessary inference decomposed processes involve small subsetagentsaccording interaction graphthereby facilitating scalability. deriveglobal update rule combines local inferences monotonically increase overallsolution quality. Several existing multiagent planning models shown satisfyconditions, thereby validating generality value factorization property.benefit approach amenable massively parallel implementation, sincerelies local computations message-passing among neighboring agents.Experiments large multiagent planning benchmark, joint state joint actionspaces 522 , 320 respectively, confirm approach scalable respectnumber agents provide good quality solutions planning problems 20agents, cannot handled best existing approaches. smaller multiagentsystems, approach provides better solution quality order-of-magnitudefaster previous best nonlinear programming approach optimizing FSCs.2. Decentralized POMDP ModelDec-POMDP model natural extension MDPs POMDPs. definedtuple hI, S, {Ai }, P, R, {Y }, O, i, where:denotes finite set n agentsdenotes finite set states designated initial state distribution 0227fiKumar, Zilberstein, & ToussaintAi denotes finite set actions agentP denotes state transition probabilities: P (s0 |s, ~a), probability transitioningstate s0 joint-action ~a taken agentsR denotes reward function: R(s, ~a) immediate reward statejoint-action taken ~adenotes finite set observations agentdenotes observation probabilities: O(~y |s0 , ~a) probability receivingjoint-observation ~y last joint-action taken ~a resulted environment state s0denotes reward discounting factoragent policy, : Ai , maps set possible observation historiesactions. Solving Dec-POMDP entails finding joint-policy = h 1 , . . . , nmaximizes total expected reward.XER st , ~at ;(1)t=0denotes joint-policy subscript denotes dependence time.Dec-POMDP, agents acting uncertainty underlying environment state also other. Although joint-observation received agentsmay correlated, agent observes component joint-observation.makes coordination problem particularly challenging. Section 2.1, showcompact representation policy finite-state controllers, rather long sequencesobservations.two agents given multiagent system, adopt simplified notationfollows. action set agent 1 denoted agent 2 b B.state transition probability P (s0 |s, a, b) depends upon actions agents.Upon taking joint-action ha, bi state s, agents receive joint-reward R(s, a, b).finite set observations agent 1 Z agent 2. O(yz | s, a, b) denotesprobability P (y, z|s, a, b) agent 1 observing agent 2 observing z Zjoint-action ha, bi taken resulted state s. infinite-horizon Dec-POMDPs,reward discounting factor < 1 used.2.1 Finite State Controllerscase infinite-horizon Dec-POMDPs, agents operate continuously immediate reward R discounted factor < 1. Representing agents local policies usingexplicit tree structured representation feasible case. Therefore, agentspolicies represented cyclic finite-state controllers (FSC).represent agents policy bounded, finite state controller (FSC). approach used successfully POMDPs (Poupart & Boutilier, 2003; Amato,Bernstein, & Zilberstein, 2007) Dec-POMDPs (Amato et al., 2010). case,228fiProbabilistic Inference Multiagent Decision Makingy1z1p2q2y2y2z2z2( )p1 (a, p)q1z1y1Agent 1Agent 2Figure 1: two-agent infinite-horizon joint-policy represented using finite-state controllers.node memory state. Edges represent node transition function. Agent1 two observations, y1 y2. Agent 2 also two observations, z1 z2.agent finite internal memory state, q Qi , summarizes crucial information obtained past observations support efficient action selection. sizeset Qi determines expressiveness FSC based policy. POMDPs, FSCsbeneficial due compactness relative ease policy execution comparedfull belief world states. Dec-POMDPs, belief world states cannot maintainedexecution time due lack availability joint-observations. Therefore, FSCsparticularly useful executing FSC-based policies require maintaining beliefworld states.FSC ith agent parameterized = ( , , ) explained below.agent chooses actions depending internal state q: P (a|q; ) = a,q .internal state updated new observation, node transition function:P (q 0 |q, y; ) = q0 ,q,y .Finally, q0 initial node distribution P (q0 ) agent.Figure 1 shows structure controllers two agents. action selectionparameter node transition parameter could deterministic stochastic.optimize stochastic controllers work generally produce highervalues (Poupart & Boutilier, 2003).Figure 2 shows complete DDN representation two-agent Dec-POMDP depictingenvironment agents policies interact other. use conventionsubscripts denote time superscripts, any, identify agents.2.2 Objective FunctionConsidering two-agent case, denote controller nodes agent 1 pagent 2 q. value starting controllers nodes hp, qi state given by:XV (p, q, s) =a,p b,qa,bhXXXR(s, a, b) +P (s0 | s, a, b)O(yz | s0 , a, b)p0 ,p,y q0 ,q,z V (p0 , q 0 , s0 )s0y,z229p0 q 0fiAgent 1Kumar, Zilberstein, & Toussaintp1p0a0s0b0Agent 2y1s1a0s0z1q1q0p1p0y1s1b0p2a1s2z1b1q1q0r0Figure 2: two-time slice dynamic decision network (DDN) representationtwo-agentp1Dec-POMDP. nodes random variables. Square nodes represent decisions;diamond nodes represent reward; p q represent states policyy1agent 0 1 respectively; subscripts denote time. a0goal set parameters h, , agents controllers(of given size)s1maximize expected discounted reward initial belief 0 :V (0 ) =Xp q 0 (s)V (p, q, s) b0z1p,q,s3. Dec-POMDPs Mixture DBNsq1section, describe Dec-POMDPs reformulated mixture DBNs,maximizing reward likelihood defined equivalent optimizingjoint-policy. approach based framework proposed Toussaint et al. (2006)Toussaint Storkey (2006) solve Markovian planning problems using probabilisticinference. section, develop planning-as-inference strategy two-agent DecPOMDPs later extend multiple ( 2) agents. previous approach Toussaintet al. (2006) Toussaint Storkey (2006) focused single agent MDPs POMDPs.work, develop new mixture models allow us extend planning-asinference paradigm multiple agents, significant generalization single agent case.First, briefly describe intuition behind reformulation describedetail necessary modifications required Dec-POMDPs.Dec-POMDP described using single DBN reward emittedtime step, unrolled DBN corresponding one shown Figure 2.However, approach, described infinite mixture special type DBNsreward emitted end. one mixture componenttime period = 0 . Furthermore, simulate discounting rewards,probability , acts mixture weight, set P (T = t) = (1 ). also230y2z2q2fiProbabilistic Inference Multiagent Decision Makingp0a0s0=0rb0q0p1a0s0y1s1b0Agent2a0p1p0z1q1q0r0Mixture finite-time Dec-POMDPsAgent1p0s0y1s1b0z1q1p0p1a0y1s1b0b1a1p2pTy2yTs2z1q1q0=1rq0s0a1b1rsTz2zTq2qTbTFigure 3: time-dependent DBN mixture (right) corresponding two-agent DecPOMDP (left). first DBN component mixture correspondsreward time step 1, second DBN corresponds reward time step 2.last DBN mixture shows general structure -step DBN.231fiKumar, Zilberstein, & ToussaintPensures mixing weights normalizedt=0 P (T = t) = 1. describestructure mixture component single -step DBN.first DBN DBN mixture model shown Figure 3 describes DBNtime = 0. key intuition reward emitted time step ,separate DBN general structure shown last -step DBN shownFigure 3. DBN shows reward obtained time step depends policyparameters underlying Dec-POMDP model.random variable r shown DBN mixture Figure 3 binary variableconditional distribution (for time ) described using normalized immediatereward as:Rsab = P (r = 1|sT = s, = a, bT = b) = (Rsab Rmin )/(Rmax Rmin ).parameter Rmax maximum reward state action pair given DecPOMDP instance Rmin denotes minimum reward. scaling rewardkey transforming optimization problem realm planning likelihoodmaximization stated below. Let denote joint parameters h, , agentscontroller.Theorem 1. choosing conditional probability binary rewards r RsabRsab introducing discounting time prior P (T ) = (1 ), joint-policy value Vrelates linearly likelihood L observing reward variable 1:V =(Rmax Rmin )LRmin+(1 )1Proof. value function defined as:VX=ER st , ~at ;(2)t=0Consider -step DBN mixture Figure 3. define likelihood timestep DBN follows:LT = P (r = 1|T ; )(3)full mixture corresponding Dec-POMDP, have:L =XP (T )LT = (1 )XP (r = 1|T ; )(4)already chose P (r = 1|sT = s, = a, bT = b) = (Rsab Rmin )/(Rmax Rmin ). Therefore,using construction -step DBN, have:E R(sT , ~aT ) RminP (r = 1|T ; ) =(5)Rmax Rmin232fiProbabilistic Inference Multiagent Decision MakingSubstituting back result expression L , get:X E R(sT , ~aT RminL = (1 )Rmax Rmin=)V(1RminRmax Rmin(6)(7)used linearity expectationXXE R(sT , ~aT = ER(sT , ~aTCombining result definition value function Eq. (2), theoremproved.Using result, establish following result.Lemma 1. Maximizing likelihood L = P (r = 1; ) mixture DBNs equivalentoptimizing Dec-POMDP policy.Theorem 1 Lemma 1 show policy optimization problem reformulatedparameter learning problem suitable DBN mixture. immediately suggestsusing machine learning approaches maximize likelihood. Furthermore, reformulation lossless sense optimizing likelihood would exactly optimizejoint-policy value. note never explicitly create mixture DBNs.computations DBN mixture implemented message-passing original Dec-POMDP DDN Figure 2. additional computational requirementscaling rewards using Rmax Rmin , done easily linear time.next present Expectation-Maximization (EM), well known technique maximize likelihood.4. Policy Optimization via Expectation Maximizationsection describes application EM algorithm (Dempster et al., 1977)maximizing reward likelihood mixture DBNs representing Dec-POMDP.EM also possesses desirable anytime characteristic likelihood (and policyvalue proportional likelihood) guaranteed increase per iterationconvergence. note EM guaranteed converge global optimum. However,experiments show EM almost always achieves similar values NLP basedsolver optimize FSCs (Amato et al., 2010) much better DEC-BPI (Bernsteinet al., 2009). Key potential advantages using EM lie ability easily generalizemuch richer representations currently possible Dec-POMDPs hierarchicalcontrollers (Toussaint et al., 2008), continuous state action spaces (Hoffman et al.,2009b). Another important advantage ability generalize solver larger multiagent systems 2 agents exploiting relative independence amongagents, show later sections.233fiKumar, Zilberstein, & Toussaintl(; x)Q( 2 , )Q( 1 , )21Parameter spaceFigure 4: coordinate ascent strategy EM algorithm4.1 Overview EM Algorithmfirst provide high level overview EM algorithm followed detailing adaptation planning Dec-POMDPs. EM algorithm general approach problemmaximum likelihood (ML) parameter estimation models latent variables.given latent variable model, let X denote observable variables Z denote hiddenvariables. Let denote model parameters. ML problem solve followingoptimization problem:Xmax l(; x) = max logp(x, z; )(8)zhard optimize problem summation inside log. Furthermore,maximizing log-likelihood l(; x) generally non-convex optimization problemshown Figure 4. Therefore, EM algorithm iteratively performs coordinate ascentparameter space. First, EM algorithm computes lower bound functionl(; x) lower bound touches l(; x), say point 1 . lower bounddenoted Q(1 , ), defined as:XXQ(1 , ) =p(z|x; 1 ) log p(x, z; )p(z|x; 1 ) log p(z|x; 1 )(9)zzlast term expression entropy variable Z|x. Figure 4 showslower bound Q(1 , ) blue curve. function Q(1 , ) also called expected completelog-likelihood. Importantly, lower bound Q concave parameters thus,optimized globally provide better parameter estimate 2 . process also shownFigure 4. coordinate ascent continues iteratively defining new lower boundQ(2 , ) point 2 also shown Figure 4, optimizing yield nextbetter parameter estimate convergence.connect iterative maximization strategy planning Dec-POMDPs,note likelihood function directly proportional joint-policy value policy234fiProbabilistic Inference Multiagent Decision Makingparameters (see Theorem 1). Therefore, adapting EM approach Dec-POMDPs,need perform following steps:1. (E-step) Formulate expected complete log-likelihood Q(i , ) DBN mixturemodel Figure 3 iteration2. (M-step) Maximize Q(i , ) w.r.t. yield better policy parameters i+13. Repeat steps 1 2 convergence, i.e., i+1next explain steps 1 2 implemented specifically Dec-POMDPs.4.2 Step 1: Formulating Expected Log-Likelihood Q(, ? )DBN mixture Figure 3, every variable hidden observed databinary reward variable r = 1. particular DBN time step ,last DBN mixture Figure 3, let L = (P, Q, A, B, S, Y, Z) denote latentvariables T-step DBN, variable denotes sequence length . is,P = p0:T , denotes -step long sequence controller state pt agent 1. EM maximizesfollowing expected complete log-likelihood Dec-POMDP DBN mixture. Letdenote previous iterations parameters ? denotes new parameters. expectedlog-likelihood (ignoring entropy term independent ? ) given as:Q(, ? ) =XXP (r = 1, L, ; ) log P (r = 1, L, ; ? )(10)=0 Lrest section, derivations refer general -step DBN structureshown Figure 3. also adopt convention random variable v, v 0 refersnext time slice v refers previous time slice. group variables v,Pt (v, v0 ) refers P (vt = v, vt+1 = v0 ). joint probability variables is:P (r = 1, L, ; ) = P (T ) Rsab t=Tap bq Pssab Oyzsab ppy qqzt=1ap bq p q 0 (s) t=0(11)brackets indicate time slices, i.e., Rsab t=T = R(sT , , bT ). also usedshorthand Pssab = P (s|s, a, b); similarly Oyzsab . Taking log, get:log P (r = 1, L, ) = . . . ++Xt=0Xlog pt +Xlog bt qtt=0log pt pt1 yt +t=1Xlog qt qt1 zt + log p0 + log q0(12)t=1missing terms represent quantities independent , affectmaximization . policy parameters h, , get separatedagent log above, expression expected log-likelihood also formulated235fiKumar, Zilberstein, & Toussaintseparately action parameters, controller node transition parameters initial nodedistribution. action parameters agent, simplified expression as:Qa,p (, ? ) =XP (T )XX?P (r = 1, = a, pt = p|T ; ) log ap(13)t=0 a,p=0Pexpression derived substituting Tt=0 log pt log P (r = 1, L, ; ? )Eq. (10) marginalizing remaining variables (See derivation Appendix A).Analogous expected log-likelihood expressions written node transitioninitial node distribution parameters.4.3 Step 2: Maximizing Expected Log-Likelihood Q(, ? )highlighted section 4.1, formulated expected log-likelihood, nextstep maximize get better policy ? . show maximization firstaction updates. expected log-likelihood action updates given as:Qa,p (, ? ) =XP (T )XX?P (r = 1, = a, pt = p|T ; ) log ap(14)t=0 a,p=0maximization step (M-step) involves solving following convex optimization problem:max Qa,p (, ? )(15)? }{apsubject to:X?ap= 1 p(16)optimization problem easily solved analytically solving KarushKuhn-Tucker (KKT) conditions (Boyd & Vandenberghe, 2004). resulting updatecontroller action parameters given as:?ap==P=0 P (T )PTt=0 P (r = 1, = a, pt = p|T ; )CpE [r = 1, a, p]Cp(17)(18)Cp normalization constant.parameter updates: Analogous action updates above, write controller transition well initial node distribution updates follows:E [r = 1, a, p]CpE [r = 1, p, p, y]?ppy =CpyE [r = 1, p]p? =C?ap=236(19)fiProbabilistic Inference Multiagent Decision Makinghave:E [r = 1, p, p, y] =E [r = 1, p] =X=1XP (T )XP (r = 1, pt = p, pt1 = p, yt = y|T ; )(20)t=1P (T )P (r = 1, p0 = p|T ; )(21)=0Sections 4.2 4.3 summarize two main steps form core EM algorithm. two steps applied iteratively convergence result monotonicimprovement solution quality.4.4 Inference Parameter Updatesdetail inference procedure computes different expectations E requiredparameter updates shown Eq. (19). Computing expectations also forms E-stepEM algorithm. step, fixed parameter , forward messages backwardmessages propagated. forward-backward message passing similarmessage passing Baum-Welch algorithm parameter estimation hidden Markovmodels (Koller & Friedman, 2009). First, define following Markovian transitions(p, q, s) state -step DBN Figure 3. transitions independenttime due stationary joint-policy.XP (p0, q 0, s0 |p, q, s) =p0 py0 q0 qz 0 Oy0 z 0 abs0 ap bq Ps0 sab(22)aby 0 z 0Definition 1. forward message defined probability FSC agent1 state p, FSC agent 2 state q world state time(p, q, s) = P (pt = p, qt = q, st = s; ).might appear need propagate messages DBN DBN mixtureseparately, pointed Toussaint et al. (2006), one sweep requiredhead DBN shared among mixture components. is, 2T-step DBNs 2. omit using long unambiguous.0 (p, q, s) = p q 0 (s)X(p0 , q 0 , s0 ) =P (p0 , q 0 , s0 |p, q, s)t1 (p, q, s)(23)(24)p,q,smessages propagated backwards defined Pt (r = 1|p, q, s; ). However,particular definition would require separate inference DBN 0step DBN, different due difference time-to-go (T 0 t).circumvent problem, messages indexed backward time defined follows.Definition 2. backward message defined probability variable r = 1given FSC agent 1 state p, FSC agent 2 state q worldstate steps-to-go -step DBN:(p, q, s) = P(r = 1|pT = p, qT = q, sT = s)237fiKumar, Zilberstein, & Toussaint= 0 denotes last time slice = . tails DBNs mixtureFigure 3 exactly same, backward indexing avoids performing separate inferenceDBN. example, 3 DBNs length 3 3 computesprobability reward variable one given state Markov chain (p, q, s)3 time steps go. recursive definition follows:X0 (p, q, s) =Rsab ap bq(25)abX(p, q, s) =p0 ,q 0 ,s01 (p0 , q 0 , s0 )P (p0 , q 0 , s0 |p, q, s)(26)Based messages compute two quantities:(p, q, s) =XP (T = t)t (p, q, s)(27)P (T = ) (p, q, s)(28)t=0(p, q, s) =X=0quantities used M-step. cut-off time message propagation eitherfixed priori flexible based likelihood accumulation. messagespropagated t-steps -messages steps, likelihood = +given as:XLt+ = P (r = 1|T = + ; ) =P (r = 1, pt = p, qt = q, st = s|T = + )(29)p,q,s=XP (r = 1|pt = p, qt = q, st = s, = + )P (pt = p, qt = q, st = s|T = + )(30)(p, q, s) (p, q, s)(31)p,q,s=Xp,q,sPmessages propagated k steps L2k 2k1=0 LT ,message propagation stopped. criterion simply means expectedvalue (or likelihood) time step = 2k small compared alreadyaccumulated value time step 2k 1, message propagation stopped.computed messages, compute expectations requireddifferent updates Section 4.3. derivations updates providedAppendix A.Definition 3. Based computing quantities Eq. (27)- (28), parametersagents controller updated EMs iteration follows:?ap=Xap X(p, q, s)Rsab bq +Cp qs1bX000(p , q , )p0 q 0 0 0 z 0Xppy X(p, q, s)(p, q, s)qqzOyzsab Pssab ap bqCpy sqsqzabp Xp? =(p, q, s)q Ps 0 (s)C qs?ppy =238p0 py 0q 0 qz 0Xb0 z 0 s0 abbq Ps0 sabfiProbabilistic Inference Multiagent Decision Making4.5 ComplexityCalculating Markov transitions (p, q, s) chain Section 4.4 complexityO(|Q|4 |S|2 |A|2 |Y |2 ), |Q| maximum number nodes controller.message propagation complexity O(Tmax |Q|4 |S|2 ). Techniques effectively reducecomplexity without sacrificing accuracy discussed experiments section.complexity updating action parameters O(|Q|4 |S|2 |A||Y |2 ). Updating nodetransitions requires O(|Q|4 |S|2 |Y |2 + |Q|2 |S|2 |Y |2 |A|2 ). relatively high compared single agent POMDP updates requiring O(|Q|2 |S|2 |A||Y |) mainly duescale interactions present Dec-POMDPs.experimental settings, observed relatively small sized controller(|Q| 5) suffices yield good quality solutions. main contributor complexityfactor 2 experimented large domains nearly 250 states.good news structure E M-step equations provides way effectivelyreduce complexity significant factor without sacrificing accuracy. given states, joint-action ha, bi joint-observation hy, zi, possible next states calculatedfollows: succ(s, a, b, y, z) = {s0 |P (s0 |s, a, b)O(y, z|s0 , a, b) > 0}. problems,size set typically constant k < 10. simple reachability analysistechniques speed EM algorithm order magnitude largeproblems. effective complexity reduces O(|Q|4 |S||A||Y |2 k) action updatesO(|Q|4 |S||Y |2 k + |Q|2 |S||Y |2 |A|2 k) node transitions.4.6 Intuition Behind EM Update Strategysection, provide insights update strategies EM. actionparameter update according Section 4.3 given as:E r = 1, a, p?ap =(32)CpCp normalization constant. understand Eq. (32) clearly, considerfollowing iterative algorithm optimizing controller. First, fix every controllernodes parameters every agent except parameters single controller nodeparticular agent. Now, deterministically try every action setting particular nodegreedily set action parameter node action results maximumjoint value. Clearly, strategy monotonically improve policy value reacheslocal optima. strategy used decision making modelsinfluence diagrams referred Single Policy Update (SPU) algorithm (Lauritzen& Nilsson, 2001).updates EM algorithm essentially soft version greedydeterministic rule. understand this, let a? denote action maximum expectation:a? = arg max E r = 1, a, p(33)aAconsider applying update rule Eq. (32) infinitely many times without recomputing E-step. Clearly limit, a?? p = 1 rest actionparameters converge zero. essentially SPU algorithm.239fiKumar, Zilberstein, & Toussaintconnection also provides insight soft-max approach EMmay better strategy greedy deterministic update rule. First, greedyupdate rule computes deterministic controllers agents. alreadyshown stochastic controllers achieve better solution quality deterministiccontrollers (Poupart & Boutilier, 2003). EM updates provide stochastic controllers,advantage. Second, already known graphical models community greedy update rule, also referred Hard-Assignment EM (Koller &Friedman, 2009, ch. 19) EM algorithm optimize different objectives.general lead different solutions, example, situations stochastic controllerspreferred deterministic ones. hard-assignment EM traverses combinatorial pathneeds fix parameters except one. soft-assignment EM,hand, simultaneously change parameters multiple nodes. Thus, movesparameter space soft-assignment EM sophisticated general, infeasible hard-assignment EM, cannot simultaneously change multiple parameters.Thus, soft-assignment EM converge better policy. Therefore, using soft-maxbased update strategy EM algorithm advantageous greedydeterministic rule.4.7 Discussionpresented new approach solve Dec-POMDPs using inference mixture DBNs.main benefit EM approach opens possibility using powerfulprobabilistic inference techniques solve decentralized planning problems. Using graphical DBN structure, EM easily extend larger multi-agent systems 2agents, shown following sections. Furthermore, planning-as-inferenceviewpoint help generalize richer representations factored hierarchical controllers (Toussaint et al., 2008), continuous state action spaces (Hoffman,de Freitas, Doucet, & Peters, 2009a).Incidentally, increasing interest applying variational inference techniquesmachine learning graphical models literature, marginal MAP inferencebelief propagation (Liu & Ihler, 2013, 2012), planning uncertainty. Particularlyrelated work use marginal MAP (MMAP) based inference single agentPOMDP planning (Kiselev & Poupart, 2014a, 2014b). MMAP based planning,single dynamic Bayesian network developed introducing additional binary variablessimilar binary reward variable r case. single graphical modeldeveloped POMDP model, shown maximizing likelihood observingone special binary variable equal optimizing joint policy.key difference approach Kiselev Poupart usedifferent graphical models represent underlying planning problem. approachKiselev Poupart uses two additional binary variables per time step representreward discounting value function, approach need. Furthermore,approach, time indexing backward message propagation needfixed priori shown Section 4.4, whereas fixed horizon DBN needs prespecified Kiselev Pouparts (2014b) method. Nonetheless, using MMAP inferenceplanning represents another variational inference-based approach applied240fiProbabilistic Inference Multiagent Decision Makingplanning uncertainty problems. Similar development EM case,one also develop EM algorithm policy optimization single DBN modelKiselev Poupart. remains seen, however, approach KiselevPoupart (2014a, 2014b) gets translated multiagent setting w.r.t. scalabilitysolution quality.5. Achieving Scalability Restricted Modelsprevious sections, developed probabilistic inference based approximate algorithmsefficiently solve 2-agent Dec-POMDPs. However, scaling even approximatealgorithms 2-agents non-trivial task. fact, naive extension leadsexponential increase complexity number agents. Therefore, followingsections, present general characterization interactions among agentspresent multiagent planning model leads relatively scalable approximate algorithms.section, identify conditions sufficient make multiagent planningamenable scalable approximation w.r.t. number agents. achievedconstructing graphical model exploits restricted interactions among agents.illustrate close relationship machine learning showing likelihoodmaximization graphical model equivalent policy optimization. UsingExpectation-Maximization framework likelihood maximization, show necessary inference decomposed processes often involve small subset agents,thereby facilitating scalability. derive global update rule combines localinferences monotonically increase overall solution quality. Furthermore, approacheasily parallelizable takes form message-passing among agents, ideally suitedlarge multiagent systems.Experiments large multiagent planning benchmark, joint state actionspaces 522 , 320 respectively, confirm approach scalable w.r.t. numberagents provide good quality solutions planning problems 20 agents,cannot handled previous best approaches. smaller multiagent systems,approach provides better solution quality order-of-magnitude fasterprevious best nonlinear programming approach optimizing FSCs.5.1 Value Factorization Frameworkvalue factorization framework leads efficient inference large multiagent systemsgeneral enough subsume several existing planning models. before, representagents policy bounded, finite state controller (FSC). assume statespace factored s.t. = (S 1 ... )a common assumption multiagent planningmodels ND-POMDPs (Nair et al., 2005) TD-POMDPs (Witwicki & Durfee,2010). Without making (conditional independence) assumptions problemstructure, general Dec-POMDP requires exact inference full corresponding (finitetime) DBNs, would exponential number state variables agents.approach relies general simplifying property agent interaction, later showconsistent many existing multiagent planning models.241fiff Fs#frf Fq!Kumar, Zilberstein, & Toussaintq!y!y!aiqi#qis#isiaiAfsis#ix#rf F1yi#x(a)(b)Af2r f F34(c)Figure 5: Value factorization property different models: (a) Plate notation transitionindependent Dec-MDPs; (b) Plate notation ND-POMDPs; (c) Agent interaction digraph TD-POMDPsDefinition 4. value factor f defines subset Af {1, .., N } agents subsetSf {1, .., } state variables.Definition 5. multiagent planning problem satisfies value factorization jointpolicy value function decomposed sum value factors:XV (, s) =Vf (f , sf ) ,(34)f FF set value factors, f Af collection parameters agentsfactor f , sf sSf collection state variables factor.Even value factorization property holds, planning models still highlycoupled factors may overlap. is, agent appear multiple factorsstate variables. Therefore, value factor cannot optimized independently. But,show later, leads efficient Expectation Maximization algorithm. additive valuefunctions also used solve large factored MDPs (Koller & Parr, 1999). WitwickiDurfee (2011) use factored value functions analyze complexity solvingmultiagent planning problems. work, contrast, uses value factorization property conjunction graphical models probabilistic inference develop scalablelikelihood maximization based algorithm. require value factor Vf evaluated using DBN mixture based approach Section 3. However, limitgenerality, DBN-based approach model arbitrary Markovian planning problems.Theorem 2. worst case complexity optimally solving multiagent planning problemsatisfying value factorization property NEXP-Hard.proof theorem straightforwardany two agent finite-horizon DecPOMDP NEXP-Complete also satisfies value factorization propertysingle factor involving two agents. fact, previous sections precisely addressedissue using EM framework (see Section 4). Next, investigate propertyholds computationally advantageous, establish following result.242fiProbabilistic Inference Multiagent Decision MakingTheorem 3. value factorization property holds Transition-Independent Dec-MDPs(Becker et al., 2004), Network-Distributed POMDPs (Nair et al., 2005) TransitionDecoupled POMDPs (Witwicki & Durfee, 2010).Proof. joint value shown factorized based immediate-reward factorizationtransition independent Dec-MDPs (Becker et al., 2004) ND-POMDPs (Nair et al.,2005). Figure 5 shows plate notation value factor representationmodels. outer plate shows factor f inner plate depicts interactionamong agent parameters include state, action observation variables.models, key assumption leads scalability agents involvedsingle reward function. Thus, value factor small leads efficient inference.approach also model Transition-Decoupled POMDPs (TD-POMDPs) (Witwicki& Durfee, 2010). case, agents local parameters (factored local state rewards). However, certain features local state depend agents actions.features called nonlocal features agent i. dependency among agentsdescribed using agent interaction digraph (Witwicki, 2011, Section 3.5.1.2).node agent i. directed edge node node j agent affectsnonlocal feature agent j. Let (i) denote ancestors node agentinteraction digraph TD-POMDP. shown Witwicki (2011, Thm. 3.33), jointvalue function TD-POMDP defined N agents factored as:V () =NXi=1Vi , hj | j (i)i(35)state variables involved factor Vi local states agent {i}(i).Furthermore, value factor Vi evaluated constructing DBN mixture involvingagents {i}(i). Therefore, TD-POMDP model satisfies value factorizationproperty. Consider example agent interaction digraph Figure 5(c). joint valuefactorizes V () = V1 (1 ) + V2 (2 , 1 ) + V3 (3 , 1 ) + V4 (4 , 1 , 3 ).Furthermore, TD-POMDPs mainly useful weakly-coupled planning problems(Witwicki, 2011). implies number agents involved single value factorsmall compared total number agents, potentially leading computational savings approaches exploit structure smaller value factors.note value factorization property Eq. (34) trivially satisfiedagent state variables included single factor. Obviously, computationaladvantages approach limited settings factor sparse, involvingmuch fewer agents entire team. allows efficient inference respectiveDBNs (inference still efficient special cases TD-POMDPs largerfactors). general case, additive value function may include components dependingstates agent parameters. analogous factored HMMs (Ghahramani& Jordan, 1995) where, conditioned observations, Markov chains become coupledexact E-step EM becomes infeasible. beyond scope paper, promising approach general case using variational methods approximateposterior P (s1:M1:T | r = 1) (minimizing KL-divergence factored representation true posterior) (Ghahramani & Jordan, 1995). Given approximate243fiKumar, Zilberstein, & Toussaintposterior, M-step updates used realize approximate EM scheme, alsoshown Pajarinen Peltonen (2011a).next section, describe new DBN mixture model value factorizationframework. that, highlight key result behind scalability EMalgorithmTheorem 4. models satisfying value factorization property, inferences requiredE-step EM algorithm performed independently value factor f .e.g., action updates agent j,X fE [r = 1, aj , q j ]E [r = 1, aj , q j ] =f F (j)j denotes particular agent, F (j) denotes set value factors agent jinvolved in, (aj , q j ) denote action controller state agent j, Ef [] (to definedprecisely Section 5.4.1) denotes inference DBN mixture correspondingvalued factor f . constructive proof result provided below. resulthighlights generality scalability approach, whichunlike previous worksrequire independence assumptions.next section, define latent variable model, based mixtureDBNs, likelihood maximization (LM) mixture model equivalentjoint-policy optimization. established relationship LMpolicy optimization, show perform different steps EM mixture modeloutlined section 4.1.5.2 DBN Mixture Value FactorsFigure 6 shows new problem-independent DBN mixture, also called value factor mixture,models Eq. (34). consists two mixture variables: F . F ranges 1|F |, total number value factors. Intuitively, F = denotes time dependentDBN mixture value factor i. zoomed-in view DBN mixture providedFigure 6(b). mixture variable F fixed, uniform distribution (= 1/|F |).distribution variable set Theorem 1.model relies fact representation, value factor represented evaluated using time dependent DBN mixture Figure 6(b) binaryreward variable r, also shown Section 3. DBN mixture particular valuefactor f contain variables agents involved factor f : actions, controllernodes observations, state variables Sf . valuation Vf (f ) calculated finding likelihood Lf (f ; r = 1) = P (r = 1; f ) observing binary rewardvariable r = 1 DBN mixture value factor f . Using Theorem 1,following result:Vf (f ) = kLf (f ; r = 1) + kf(36)k kf constants, k value factors. easilyensured making original rewards positive adding suitable constant. Nextstate one main results. also assuming policy optimized244fiProbabilistic Inference Multiagent Decision Makingx0y0rx0y0x1y1rF =1F =2F = |F |Figure 6: (a) Value factor mixture; (b) Zoomed-in view mixture component (x,generic placeholders random variables).initial belief 0 . also use notational conveniencePf F .P|F |F =1equivalentTheorem 5. Maximizing likelihood L(; r = 1) observing r = 1 value factormixture (Figure 6(a)) equivalent optimizing global policy .Proof. overall likelihood given by:L(; r = 1) = P (r = 1; ) =X 1Lf (f ; r = 1)|F |(37)f Ftheorem follows substituting value L(f ; r = 1) previous equationEq. (36) joint-policy value decomposition assumption Eq. (34).5.3 Step 1: Formulating Expected Log-Likelihood Q(, ? )formulate expected log-likelihood Q(, ? ) DBN mixture Figure 6(a).r = 1 observed data, rest variables latent. Note derivationsdiffer markedly Toussaint Storkey (2006) focus single-agent problemEM approach 2-agent Dec-POMDPs (see Section 4). focus scalabilityw.r.t. number agents generality.assignment mixture variables F = f denotes T-step DBNvalue factor f . example, assume time dependent DBN mixture Figure 6(b)value factor f . F = f = 1 denote 1-step DBN (the second DBN)Figure 6(b). Let Z f denote complete assignment variables slice 0T-step DBN factor f . assume simplicity value factor f involves kagents. full joint mixture is:kkP (r = 1, Z f , T, F = f ) = P (T )P (F = f ) Rsf af t=Tfi (a, q)fi (q, q, y)i=1 t=0ki=1[fi (q)]0 P (Z f \(Af , Qf )|T, F = f )245i=1 t=1(38)fiKumar, Zilberstein, & Toussaintindex fi denotes respective parameters agent involved factor f .square brackets denote dependence upon time: [fi (a, q)]t = fi (at = a, qt = q). also use[P (v, v)]t denote P (vt = v, vt1 = v).Let Z f \(Af , Qf ) denote variables DBN except action controllernodes agents. Importantly, structure previous equation model independent conditional independence policy parameters ((a, q) = P (a|q)),first part equation (the product terms) always written way. model independent, imply structure previous equation remains differentmodels value factorization property. Since EM maximizes expected log-likelihood,take log get:log P (r = 1, Z f , T, F = f ) =k XXk XXlog fi (a, q) +log fi (q, q, y)i=1 t=0i=1 t=1+kXi=1log fi (q) 0 + hother termsi(39)hother termsi denote terms independent policy parameters . EM maximizesfollowing expected log-likelihood:?Q(, ) =XXXf F =0 Z f?P (r = 1, Z f , T, F = f ; f ) log P (r = 1, Z f , T, F = f ; f )(40)denotes previous iterations joint-policy ? current iterations policydetermined maximization. structure log term (Eq. (39)) particularlyadvantageous allows us perform maximization parameter agentindependently. imply complete problem decoupling parameters stilldepend previous iterations parameters agents.5.4 Step 2: Maximizing Expected Log-Likelihood Q(, ? )first derive update action parameters agent j. P (F) ignoredconstant. expected log-likelihood action updates, Qja,q (, ? ), given by:Qja,q (, ? )=X XP (T )f F (j)=X Xf F (j)XZfP (T )X?P (r = 1, Z |T, f ; )log j (a, q)ff(41)t=0XXt=0 a,qP (r = 1, = a, qt = q, |T, f ; f ) log j? (a, q)(42)F (j) set value factors involve agent j. M-step involves solvingfollowing convex optimization problem:maxQja,q (, ? )(43)Xj? (a, q) = 1 q(44){j? (a,q) a,q}subject to:246fiProbabilistic Inference Multiagent Decision Makingf12f23f34f12Ag1f23f34Ag2Ag3Ag4Ag1(a)Ag2Ag3Ag4(b)Figure 7: Message passing value factor graph: (a) shows message directionE-step; (b) shows M-step.optimization problem easily solved analytically solving KarushKuhn-Tucker (KKT) conditions resulting following action parameter updates:PPPTff F (j)=0 P (T )t=0 P (r = 1, = a, qt = q|T, f ; )?j (a, q) =(45)CqPff F (j) E [r = 1, a, q]=(46)CqCq normalization constant.5.4.1 Parameter UpdatesAnalogous action updates previous section, write controllersition well initial node distribution updates agent j follows:Pff F (j) E [r = 1, a, q]?j (a, q) =CqPff F (j) E [r = 1, q, q, y]?j (q, q, y) =CqyPff F (j) E [r = 1, q]j? (q) =Ctran-(47)(48)(49)omitted superscript j denote action controller variableagent j avoid clutter. next two equations too, action, controller variables belongagent j.Ef [r= 1, q, q, y] =Ef [r = 1, q] =X=1XP (T )XP (r = 1, qt = q, qt1 = q, yt = y|T, f ; f )(50)t=1P (T )P (r = 1, q0 = q|T, f ; f )(51)=05.5 Scalability Message Passing Implementationparameter updates Section 5.4.1 highlight high scalability EM DecPOMDPs. Even though planning problem highly coupled agent state247fiKumar, Zilberstein, & Toussaintvariables allowed participate multiple value factors (see Eq. (34)), updating policyparameters requires separate local inference, Ef [r = 1, , ], value factor.global update rules (Eq. (47)(49)) combine local inferences providemonotonic increase overall solution quality. local inference model dependentcomputed using standard probabilistic techniques. problem settingincludes sparse factors, local inference computationally much simplerperforming complete planning model.Furthermore, E M-steps implemented using parallel, distributed messagepassing bipartite value-factor graph G = (U, V, E). set U contains node ujagent j. set V contains node vf factor f F . edge e = (uj , vf )created agent j involved factor f . Figure 7 shows graph three valuefactors black squares (the set V ) 4 agents (the set U ).E-step, factor node vf computes sends message f j = Ef [r =1, , ] node uj connected vf . Figure 7(a) shows step. agent nodeuj upon receiving messages factor node connected it, updatesparameters Eq. (47)(49) sends updated policy parameters ? backfactor node connected (see Figure 7(b)). procedure repeats convergence.Based message-passing interpretation EM, state following result:Theorem 6. iteration EM algorithm linear complexity numberedges value factor graph exponential complexity respect maximumnumber agents involved single value factor.stated earlier, value factors sparse, EM algorithm provide significantcomputational savings approach oblivious underlying interactionamong agents. Another significant advantage EM algorithm messagescomputed parallel factor node. experiments, using 8-core CPUresulted near linear speedup sequential version. characteristics EMalgorithm significantly enhance scalability large, sparse planning problems.5.5.1 Nature Local OptimaVariants Dec-POMDP model often solved fixing policies group agentsfinding best response policy agent interacts group (Nair,Tambe, Yokoo, Pynadath, Marsella, Nair, & Tambe, 2003; Witwicki & Durfee, 2010). EMoffers significant advantages strategy. find local optima, EMstringent satisfies Karush-Kuhn-Tucker conditions (Bertsekas, 1999),norm nonlinear optimization. local optima EM refers stationary pointlikelihood function (or value function) l(; x) Figure 4. parameter spacefigure includes discrete parameters found local optimalalgorithms best response strategy continuous parameters foundalgorithms EM.local optima best response strategy simply refers fact particular algorithm cannot improve policy using best-response strategy. algorithmspecific local optima may stationary point value function Figure 4.solution stationary point, EM would able improve upon248fiProbabilistic Inference Multiagent Decision Makingsolution given EM guaranteed converge stationary point valuefunction. Thus, local optima provided EM satisfies stringent guaranteestationary point value function. best-response strategy providesguarantees.5.6 DiscussionDespite rapid progress multiagent planning, scalability prevailing formal modelslimited. developed new approach multiagent planning identifyinggeneral property value factorization facilitates development scalableapproximate algorithm using probabilistic inference. show several existing classesDec-POMDPs satisfy property. contrast previous approaches, frameworkimpose restrictions agent interaction beyond property, thusproviding general solution value factorization based multiagent planning.key result supports scalability approach that, within EMframework, inference process decomposed separate componentsmuch smaller complete model, thus avoiding exponential complexitynumber agents. Additionally, EM algorithm allows distributed planning usingmessage-passing along edges value-factor graph, amenable parallelization. Results large sensor network problems confirm scalability approach.Empirically, approach, linear complexity number edges agentinteraction graph could scale 20 agents, whereas previous best approach basednonlinear programming could scale 5 agents due increase numbernonlinear constraints.also highlight key differences approach previous approachToussaint et al. (2006, 2008) single-agent MDPs POMDPs. Although ideadecomposing planning problem time-dependent DBN mixture remainsapproach, key differences lie structure DBNs two agentDec-POMDPs value factored Dec-POMDPs, derivation lower bound functionQ(, ? ) maximization Q function Dec-POMDPs required withinEM framework (see Section 4.1), computing required inferences underlyingMarkov chain DBNs shown Section 4.4.interactions FSC-based policy environment presentDBN MDPs POMDPs relatively simple compared interactionspresent Dec-POMDPs. Dec-POMDPs, agents interact environment, also other. inter-agent interactions leads much differentDBN structure, planning challenges Dec-POMDPs. example, DBN mixture value factorization model nested shown Figure 6. uniquefeature required formulation DBN approach, present POMDPs.Due differences structure single DBN well mixture model,adaptation EM requires different formulation alpha beta messages accountinter-agent influences shown Section 4.4. Similarly, structure Q(, ) functiondifferent owing inter-agent influences (see Eq. (40)), leads different updatesprovide scalability inter-agent message-passing structure multiagent systemsshown Sections 5.4.1 5.5. Therefore, adapting EM approach multiagent249fiKumar, Zilberstein, & ToussaintSize1234DEC-BPI4.6874.0688.6377.857NLP9.19.19.19.1EM9.059.059.059.05DEC-BPI< 1s< 1s2s5sEM< 1s< 1s1.7s4.62sTable 1: Broadcast channel: Policy value, execution timeplanning, one key contributions deliberately investigate exploitindependencies present multiagent system translate scalable algorithmic structure. Furthermore, also shown general applicability approachprevious multiagent planning models Theorem 3.6. Empirical Evaluationbegin empirical evaluation experiments conducted 2-agent problems.followed experiments larger problems involving 20 agents.6.1 Two Agents Dec-POMDPsexperimented several standard 2-agent Dec-POMDP benchmarks discounting factor = 0.9. compare EM algorithm decentralized bounded policyiteration (DEC-BPI) algorithm (Bernstein et al., 2009) non-linear, non-convex optimization solver (NLP) (Amato et al., 2010). DEC-BPI algorithm iteratively improvesparameters node using linear program keeping nodes parameters fixed. NLP approach, state-of-the-art infinite-horizonDec-POMDPs, recasts policy optimization problem non-linear program usesoff-the-shelf solver, Snopt (Gill et al., 2002), obtain solution. implementedEM algorithm JAVA. experiments Mac 4GB RAM 2.4GHzCPU. data point every algorithm tested parameter setting average 10runs random initial controller parameters. terms solution quality, EM alwaysbetter DEC-BPI achieves similar higher solution quality NLP. noteNLP solver (Gill et al., 2002) optimized package therefore largertwo agent problems currently faster EM approach. EM algorithm,implement optimizations parallel execution using multithreading,decrease runtime significantly.Table 1 shows results broadcast channel problem, 4 states, 2 actions peragent 5 observations. networking problem agents must decide whethersend message shared channel must avoid collision get reward.tested different controller sizes shown first column. problem,algorithms compare reasonably well, EM better DEC-BPI closevalue NLP. time NLP also 1s.Figure 8(a) compares solution quality EM approach DEC-BPINLP varying controller sizes recycling robots problem. problem, two robots250fi65860755650Time (sec)Policy ValueProbabilistic Inference Multiagent Decision Making4540EM(2)EM(4)NLP(2)NLP(4)DEC-BPI(2)DEC-BPI(4)35302520050100150 200Iteration250543213000350EM(2)EM(4)050100(a) |S| = 3, |A| = 3, |Y | = 2150200Iteration250300350300350(b)8607505Time (sec)Policy Value6432EM(2)EM(3)NLP(2)NLP(3)10050100150200Iteration250403020103000350(c) |S| = 16, |A| = 5, |Y | = 4EM(2)EM(3)050100150 200Iteration250(d)Figure 8: Solution quality runtime recycling robots (a) & (b) meetinggrid (c) & (d)task picking cans office building. search small can,big recharge battery. large item retrievable joint actiontwo robots. goal coordinate actions maximize joint reward. EM(2)NLP(2) show results controller size 2 agents Figure 8(a).problem, EM works much better DEC-BPI NLP approach. EM achievesvalue 62 controller sizes, providing nearly 12% improvement DEC-BPI(= 55) 20% improvement NLP (= 51). Figure 8(b) shows time comparisonsEM different controller sizes. NLP DEC-BPI take nearly 1sconverge. EM controller size 2 comparable performance, expected, EM4-node controllers takes longer complexity EM proportional O(|P|4 ),|P| denotes controller size.Figure 8(c) compares solution quality EM meeting grid problem.problem, agents start diagonally across 2 2 grid goal takeactions meet (i.e., share square) much possible.figure shows, EM provides much better solution quality NLP approach. EMachieves value 7, nearly doubles solution quality achieved NLP (= 3.3).DEC-BPI results plotted performs much worse achieves solution quality0, essentially unable improve policy even large controllers. DECBPI NLP take around 1s converge. Figure 8(d) shows time comparison EMversions. EM 2-node controllers fast takes < 1s converge (50 iterations).251fiKumar, Zilberstein, & Toussaint00.85-100.75LikelihoodPolicy Value0.8-20-30EM(2)EM(4)EM(10)NLP(2)NLP(5)NLP(10)-40-500100200Iteration3000.70.650.60.550.50.45400(a) |S| = 2, |A| = 3, |Y | = 20.4EM(2)EM(10)0100200Iteration300400(b)Figure 9: Solution quality (a) likelihood (b) multiagent tigerAgain, EMs quartic complexity controller size |P|, time requiredlarger controllers higher. Also note cases, EM could run muchlarger controller sizes ( 10), increase size provide tangible improvementsolution quality.Figure 9 shows results multi-agent tiger problem, involving two doorstiger behind one door treasure behind other. Agents coordinateopen door leading treasure (Amato et al., 2010). Figure 9(a) shows qualitycomparisons. EM perform well case; even increasing controllersize, achieves value 19. NLP works better large controller sizes. However,experiment presents interesting insight workings EM related scalingrewards. Recalling relation likelihood policy valueTheorem 1, equation problem is: V = 1210L 1004.5. EM achievesolution best NLP setting (= 3), likelihood .827. Figure 9(b)shows likelihood EM converges .813. Therefore, EMs perspective,finding really good solution. Thus, scaling rewards significant impact (incase, adverse) policy value. potential drawback EM approach,applies Markovian planning problems using technique Toussaintet al. (2006). Incidently, DEC-BPI performs much worse gets quality 77.Figure 10 shows results two largest Dec-POMDP domainsBox pushingMars rovers. box pushing domain, agents need coordinate push boxesgoal area. Mars rovers domain, agents need coordinate actions performexperiments multiple sites. Figure 10(a) shows EM performs much better DECBPI every controller size. controller size 2, EM achieves better quality NLPcomparable runtime (Figure 10(b), 500 iterations). However, larger controllersize (= 3), achieves slightly lower quality NLP. largest Mars rovers domain(Figure 10(c)), EM achieves better solution quality (= 9.9) NLP (= 8.1). However,EM also takes many iterations converge previous problems hence,requires time NLP. EM also much better DEC-BPI, achievesquality 1.18 takes even longer converge (Figure 10(d)). Mars roverdomain, NLP solver able run larger controller sizes due sizenonlinear program.252fiProbabilistic Inference Multiagent Decision Making5010000Time (sec, logscale)40Policy Value3020100EM(2)EM(3)NLP(2)NLP(3)DEC-BPI(2)DEC-BPI(3)-10-20-3002004001000100100.1600 800 1000 1200 1400IterationEM(2)EM(3)NLP(2)NLP(3)DEC-BPI(2)10200 400(a) |S| = 100, |A| = 4, |Y | = 5(b)10000010Time (sec, logscale)Policy Value50-5-10EM(2)NLP(2)DEC-BPI(2)-15-20600 800 1000 1200 1400Iteration0100020003000Iteration40001000010001001015000(c) |S| = 256, |A| = 6, |Y | = 8EM(2)NLP(2)DEC-BPI(2)0100020003000Iteration40005000(d)Figure 10: Solution quality runtime box pushing (a) & (b) Mars rovers(c) & (d)summarise, simple implementation EM approach competitiveindustrial strength off-the-shelf nonlinear programming solver. algorithm providedsimilar better solution quality current best NLP approach. main benefitEM approach lies fact opens possibility using powerfulprobabilistic inference techniques solve decentralised planning problems. shall seenext section, EM scales significantly better NLP approach larger ( 2)multiagent benchmarks NLP approach fails due large size resultingnonlinear programs.6.2 Larger Multiagent Benchmarksexperimented target tracking application sensor networks modeled NDPOMDP (Nair et al., 2005). Figure 11 shows four sensor topologies: 5P, 11H 15-3DMarecki et al. (2008) largest 20D Kumar Zilberstein (2009b).describe develop significantly enriched variant application bettertest approach, originally introduced Nair et al. (2005). node graphssensor agent edges locations targets move. track targetgain reward (= +80), two sensors must scan target location simultaneously, otherwisepenalty (= 1) given. targets independent, stochastic trajectoriespossible locations form external state-space, implying target movement affected253fiKumar, Zilberstein, & ToussaintFigure 11: Benchmarks 20D (left), 15-3D, 5P 11H (right)sensors actions. Sensors internal state, indication battery levelsensor. scan action depletes battery. addition scanning, sensorstwo additional actionssensor recharge. sensor action allows sensorsconserve energy remaining idle. battery completely depleted, sensormust perform recharge action, cost (= 1). sensor three observation:target present, target absent idle. False positives/negatives allowed firsttwo observations. runtime, sensors operate decentralized manner without centralcontroller.Note formulation sensor network application much richer challengingpreviously used benchmarks (Marecki et al., 2008). Earlier benchmarksinclude internal states sensors assumed unbounded battery life.current formulation, planning much complex sensors must reasonscanning, also conserving energy, limited battery.EM algorithm implemented JAVA. experiments done8-core iMac 2GB RAM. implementation used multithreading parallelize EMhighlighted Section 5.5 utilized 8-cores. datapoint average 10runs. speed EMs convergence, used greedy variant M-step presentedToussaint et al. (2008). step positively affects rate convergence EMrelatively little affect solution quality. M-step essentially softerversion hard assignment EM (see Eq.(33)) follows design (Toussaintet al., 2008). next describe problem sizes different instances.5P domain 2 targets, 11H 3 targets, 15-3D 5 targets, 20D6 targets. problems large state-spaces: 6 55 5P, 64 511 11H,144 515 15-3D 2700 520 20D. Evidently, EM efficiently exploits factoredrepresentation state action spaces highly scalable linear complexityw.r.t. number edges graph. also note even solving underlyingfactored MMDP optimally feasible due large state action spaces.Figure 12 shows solution quality EM achieves benchmarksdifferent controller sizes. notable observation graphs EM convergesquickly greedy M-step Toussaint et al. (2008) , taking fewer 200 iterations even large multiagent planning problems. solution quality, expected,increases monotonically iteration highlighting anytime property EM.254fiProbabilistic Inference Multiagent Decision Making14001600140012001200100010008008006006004004002000200EM(2)EM(3)EM(4)EM(5)0204060EM(2)EM(3)EM(4)EM(5)0-20080 100 120 140 160 180 200020(a) 5P406080 100 120 140 160 180 200(b) 11H350045004000300035002500300020002500150020001500100050001000EM(2)EM(3)EM(4)EM(5)0204060EM(2)EM(3)EM(4)EM(5)500080 100 120 140 160 180 2000(c) 15-3D20406080100120140160(d) 20DFigure 12: Solution quality achieved EM (y-axis denotes quality x-axis denotesiteration number).Instance\Size2-Node3-Node4-Node5-Node5P11H15-3D20D.2321.291.175.031.076.075.3922.013.2218.9016.6967.857.7445.2340.47171.26Table 2: Time seconds per iteration EMgeneral, solution quality increased number controller nodes. example,20D, 2-node controller achieves quality 3585.06 5 node controller achieves4154.04. However, 5P 15-3D, observe significant increase qualityincreasing controller size, possibly due relative simplicity configurations.Table 2 shows runtime per iteration EM different instances varying controller sizes. Encouragingly, runtime fairly smallparticularly smaller controllersizeseven large problems 20D. decrease runtime largercontrollers, plan use Monte-Carlo sampling techniques future.Table 3 shows solution quality comparison EM random controllers looseupper bound. upper bound computed assuming target detectedevery time step including battery recharge cost. random controllers, EM255fiKumar, Zilberstein, & ToussaintInstance/Value5P11H15-3D20DEM1250.891509.273094.054154.04(44.3%)(35.6%)(43.8%)(49.1%)U.B.Random282042307050846061.238.41104.231.67Table 3: Quality comparisons loose upper bound random controllersinstancesN234Internal State = 2EMNLP670.8/3.879/5.4670.8/13.02 140.4/14.5710.4/35.8140.4/139.4InternalEM972.5/8.91053.16/35.81062.4/107.4State = 3NLP905.7/17.8887.2/1391024.8/1078.1Table 4: Solution quality/time comparison EM (100 iterations) NLP 5Pdomain, N denotes controller size, Time secondsalways achieves much better solution quality. compared upper bound,see EM performs quite well. Despite loose bound, EM still achievesquality within 49.1% bound largest 20D domaina solid performance.Previously, algorithm could solve infinite-horizon ND-POMDPs (>2-agents).assess EMs performance, developed nonlinear programming (NLP) formulationproblem used state-of-the-art NLP solver called Snopt (Gill et al., 2002). Snoptcould solve smallest 5P domain could scale beyond controller size 4internal state 3 ran memory (=2GB). Table 4 shows solution qualitytime comparisons. internal state size 2, Snopt gets stuck poor local optimumcompared EM. provides competitive solutions internal state 3, EM stillbetter solution quality. Furthermore, runtime Snopt degrades quicklyincrease nonlinear constraints. makes Snopt order-of-magnitude slowercontroller size 4 internal state 3. results highlight scalabilityEM, could scale controller size 10 internal state 5 within 2GB RAM4 hours 100 iterations.Table 5 shows comparison EM handcrafted controllers designed takeaccount target trajectories partial observation 11H benchmark (Figure 11).simplify problem handcrafted solution, penalties zero rewarddetecting target 1. allowed continuous scan sensors without worryingmiscoordination penalty. first row table shows penalty case.see EM competitive handcrafted controller. second row showsresults cost charge batteries. case, sensors need decidebecome idle conserve power. handcrafted controller cannot learn behaviorhence EM produces much better quality case.256fiProbabilistic Inference Multiagent Decision MakingVersion \ FSC Size Handcrafted 2 (EM) 3 (EM) 4 (EM)penaltyPenalty (.25)13.92-3.3613.955.2715.485.2715.75.27Table 5: Quality handcrafted controllers vs. EM (11H)Version \ FSC SizeSerialParallel241.055.033177.5422.014543.5267.8551308.20171.26Table 6: Serial vs. parallel execution times per EM iteration 20D.Finally, Table 6 highlights significant opportunities EM provides parallelcomputation. consistently obtained almost linear speedup using multithreading8-core CPU (total possible parallel threads largest domain 20D 60).using massively parallel platform Googles MapReduce,we could easily scalemuch larger team decision problems currently possible.7. ConclusionDespite rapid progress multiagent planning, scalability prevailing formalmodels algorithms limited. presented new approach multiagent planning developing novel connections multiagent planning machine learning.showed multiagent planning problem reformulated inference mixture dynamic Bayesian networks. viewing multiagent planning lensprobabilistic inference, open door application efficient inference techniquesmultiagent decision making.improve scalability large multiagent systems, identified general condition called value factorization facilitated development scalable approximatealgorithm using probabilistic inference. showed several existing classes DecPOMDPs satisfy property. contrast previous approaches, frameworkimpose restrictions agent interaction beyond property, thus providinggeneral solution value factorization based structured multiagent planning. keyresult supports scalability approach that, within EM framework,inference process decomposed separate components much smallercomplete model, thus avoiding exponential complexity.Empirically, experimented several standard large multiagent planningbenchmarks. inference-based approach competitive previous best approachesbased nonlinear linear programming. approach, linear complexitynumber edges agent interaction graph could scale 20 agents, whereasprevious best approach based nonlinear programming could scale 5 agentsdue increase number nonlinear constraints.theoretical empirical results show exploring methods overlap machine learning planning great potential overcome practical limitationsexisting multiagent planning algorithms. future work, plan explore several257fiKumar, Zilberstein, & Toussaintdirections. interested exploring overlap stochastic control theory multiagent planning continuous action state space models similar work Hoffmanet al. (2009a, 2009b). also plan explore ways overcome effect localoptima solution quality achieved EM algorithm. specifically plan investigate strategies escape local optima (Poupart, Lang, & Toussaint, 2011) adaptmultiagent setting.Another key issue planning-as-inference strategy using EM algorithmlack optimality guarantee upper bounds controller based joint-policy.interesting recent research direction graphical models machine learning literaturedevelopment multiple inference strategies marginal MAP (Liu & Ihler, 2013).shown EM algorithm used one inference approach solvemarginal MAP problem (Liu & Ihler, 2013). Planning uncertainty problemscategorized instance marginal MAP inference (Cheng, Liu, Chen, & Ihler,2013). Therefore, developing graphical models exploit new inference approachesmarginal MAP problem provide quality guarantees interesting new directionexplore frontier planning machine learning.Acknowledgmentswork funded part National Science Foundation grants IIS-0812149IIS-1116917, Air Force Office Scientific Research grant FA9550-08-1-0181,EU 3rdHand project.Appendix A. Proof EM Update Equations Definition 3provide constructive proof, showing derivations relevant update equations.A.1 Proof Eq. (13)Q(, ? ) ==XXXP (r = 1, L, ; )log a?t pt(52)t=0=0 LXXX=0t=0 LP (T )P (r = 1, L|T ; ) log a?t pt(53)equation, variable L includes hidden variables DBN length. simplify summation using marginalization variables{at , pt }. also use fact policy stationary simplify as:==XP (T )XX=0t=0 a,pXXX=0P (T )?log apXL\{at ,pt }P (r = 1, = a, pt = p, L\{at , pt }|T ; )?log apP (r = 1, = a, pt = p|T ; )t=0 a,p258(54)(55)fiProbabilistic Inference Multiagent Decision MakingA.2 Action Parameter Updatesexpectation required action updates given Section 4.3 given as:E [r = 1, a, p] =XXP (T )P (r = 1, a, p|T ; )(56)t=0=0breaking summation = = 0 1, getE [r = 1, a, p] =XXXRsab ap bq (p, q, s)+P (T )P (T )=0=0qbs1XXt=0p 0 q 0 s0t1 (p0 , q 0 , s0 )Pt (a, p, p0 , q 0 , s0 )(57)equation, marginalized last time slice variables (q, b, s).intermediate time slice t, condition upon variables (p0 , q 0 , s0 ) next timeslice + 1. use definition move summation time insidelast time slice marginalize remaining variables (q, s)intermediate slice t:E [r = 1, a, p] =XRsab ap bq (p, q, s) +Xt=0p0 q 0 s0 sqP (T )=0q,b,s1XXt1 (p0 , q 0 , s0 )ap P (p0 , q 0 , s0 |a, p, q, s)t (p, q, s)(58)Upon marginalizing joint observations 0 z 0 simplifying get:E [r = 1, a, p] = apXXqsXRsab bq (p, q, s) +XP (T )p0 q 0 s0 0 z 0 =0b1Xt=0t1 (p0 , q 0 , s0 )P (s |a, q, s)p0 py0 q0 qz 0 P (y z |a, q, )t (p, q, s)00 00(59)resolve time summation, Toussaint et al. (2006), based fact that:1XX=0 t=0f (T 1)g(t) =setting = 1 getFinally get:XXt=0 =t+1Pt=0 g(t)f (T 1)g(t)P=0 f ( ).X1qsbX0 0 000 00(p , q , )p0 py0 q0 qz 0 P (s |a, q, s)P (y z |a, q, )E [r = 1, a, p] = apX(p, q, s)p0 q 0 s0 0 z 0259Rsab bq +(60)fiKumar, Zilberstein, & Toussaintproduct P (s0 |a, q, s)P (y 0 z 0 |a, q, s0 ) simplified marginalizingactions b agent 2 follows:E [r = 1, a, p] = apXX(p, q, s)Rsab bq +qsX00b0(p , q , )p0 py0 q0 qz 0p 0 q 0 s0 0 z 0X1Oy0 z 0 s0 ab bq Ps0 sabbexpectation E [r = 1, b, q] agent found similarly analogueequation.A.3 Controller Node Transition Parameter Updatesexpectation required controller node transition parameters follows:E [r = 1, p, p, y] =XXP (T )P (r = 1, pt = p, pt1 = p, yt = y|T ; )(61)t=1=1marginalizing variables (q, s) current time slice t, getXXXE [r = 1, p, p, y] =P (T )(p, q, s)Pt (p, p, y, s, q|T ; )(62)t=1 sq=1marginalizing variables (s, q) previous time sliceobservations z agent, getE [r = 1, p, p, y] = ppyXP (T )XXt=1 sqsqz=1(p, q, s)qqzP (yz|p, q, s)P (s|p, q, s)t1 (p, q, s)(63)equation simplified marginalizing productP (yz|p, q, s)P (s|p, q, s) actions b agents follows:E [r = 1, p, p, y] = ppyXP (T )XX=1t=1 sqsqz(p, q, s)qqz t1 (p, q, s)XOyzsab Pssab ap bqab(64)Upon resolving time summation before, get final expression as:E [r = 1, p, p, y] = ppyX(p, q, s)(p, q, s)qqzsqsqzXOyzsab Pssab ap bq(65)abexpectation E [r = 1, q, q, z] agent found analogous way.260fiProbabilistic Inference Multiagent Decision MakingA.4 Initial Node Distribution Updateexpectation initial node distribution update given as:E [r = 1, p] =XP (T )P (r = 1, p0 = p|T ; )(66)=0expression computed follows:E [r = 1, p] ===X=0X=0XP (T )[P (r = 1, p|T ; )]t=0P (T )P0 (r = 1|p, q, s, ; )P0 (p, q, s)(68)(p, s, q)p q 0 (s)(69)qsP (T )=0= pX(67)XXqs(p, s, q)q 0 (s)(70)qsAppendix B. EM Derivation ND-POMDP Modeln-agent ND-POMDP following parameters:= 1in Si Su , Si local state agent i; Su set uncontrollableexternal states independent agents actions. sensor networkexample, Si battery level, Su corresponds set locationstargets present.= 1in Ai Ai set actions agent i. sensor network,Ai ={l1 , . . . , lk ,Off, Recharge}, {l1 , . . . , lk } represents edges graphscanned given sensor agent.= 1in Yi joint observation set. sensor network case, Yi = {targetpresent, absent, sensor idle}. assume sensor observe internal state Si .realistic assumption sensors normally monitor battery level.noisy component observation set corresponds target locations.QP P (s0 |s, a) = Pu (s0u |su ) ni=1 Pi (s0i |si , su , ai ) transition model, = ha1 , . . . ,joint action taken joint state = hsu , s1 , . . . , sn resulting joint state s0 =hs0u , s01 , . . . , s0n i. model relies conditional (on external state) transition independence among agents.QO(y|s, a) = ni=1 Pi (yi |ai , su , si , ), joint observation taking jointaction transitioning joint state s. relies conditional observation independence.PR R(s, a) = l Rl (su , sl , al ) reward function, decomposable along subgroupsagents defined set links l. k agents i1 , . . . , ik members particular261fiKumar, Zilberstein, & Toussaintp0p1a0a1y2a2p3pTy3yTu0u1u2uTs0s1s2sTv0v1v2vTb0q0y1p2z1q1b1z2b2q2z3zTq3qTrbTFigure 13: T-step DBN link involving two agents. one DBNlink l every time step .top three layers, p denotes first agents (on1link l) controller nodes, denotes action u denotes internal state. layersi denotes external state. bottom three layers, q denotes second agentscontroller nodes, b denotes action v denotes internal statesubgroup l, sl = hsi1 , . . . , sik denotes internal states agents. Similarly,al = hai1 , . . . , aik i. sensor network 5P Figure 11, reward decomposedamong five subgroups, one per edge. reward function thus induces interaction hypergraph hyperlink l connects subset agents formreward component Rl .bo bo = (buQ, b1 , . . . , bn ) initial belief joint state = hsu , s1 , . . . , sn b(s) =bu (su ) ni=1 bi (si ).joint-value function ND-POMDPs satisfies value factorization property follows (Nair et al., 2005):XV (, s) =Vl (l , su , sl ).lone value factor Vl link l. next present T-step DBN factor linvolves two agents. DBN basis time-dependent DBN mixturevalue factor l. ease exposition, nodes controller one agent denotedp agent q. internal states, actions, observationsfirst agent denoted u, a, respectively v, b, z denote secondagent. external state denoted s. shown Section 5.4.1, E stepEM algorithm requires separate inference, one value factor Vl . Therefore,derive inference required time dependent mixture corresponding DBNFigure 13. Notice differs inference two-agent general Dec-POMDPdue presence conditional transition observation independence. propertyexploited E-step. policy parameters optimized defined262fiProbabilistic Inference Multiagent Decision Makingagent 1 (analogously agent 2 well) as:apu = P (a|p, u)0p0 py = P (p |p, y)p = P (pt=0 = p)(71)(72)(73)Notice also included internal state u action parameter apu . represents expressive accurate policy agents full observability internalstate. Next, similar Section 4.4, define following Markovian chain DBNFigure 13:P (p0,q 0,s0,u0,v 0|p, q, s, u, v) = P (p0,u0|p, u, s)P (q 0,v 0|q, v, s)P (s0|s)XP (p0,u0 |p, u, s) =p0 py Pu0 au Pyasu apu(74)(75)a,yP (q 0,v 0|q, v, s) expressed similarly. transitions independent timeuse stationary policy. Based transitions, define forward messagesfollows: = Pt (p, q, s, u, v; ). Intuitively, represents probability controllersagents link state (p, q), internal state (u, v) external statetime t. messages defined as:0 (p, q, s, u, v) = p q bo (s, u, v)X(p0,q 0,s0,u0,v 0 ) =P (p0,q 0,s0,u0,v 0|p, q, s, u, v)t1 (p, q, s, u, v)(76)(77)p,q,s,u,vSimilarly backward messages defined follows: = PT (r=1|p, q, s, u, v; ),= 0 representing tail end DBN. shown Toussaint et al. (2006), thanksnotation, DBNs share tail. Hence need one sweep computemessages. get:X0 (p, q, s, u, v)=Rsuvab apu bqv(78)a,bX(p, q, s, u, v)= 1 (p0,q 0,s0,u0,v 0 )P (p0,q 0,s0,u0,v 0|p, q, s, u, v)(79)p0,q 0,s0,u0,v 0represents normalized expected reward link controllers agentsstate (p, q), internal state (u, v) external state time ,given policy parameters . Based messages, also calculate twoquantities:(p, q, s, u, v) =(p, q, s, u, v) =Xt=0XP (T = t)t (p, q, s, u, v),(80)P (T = ) (p, q, s, u, v).(81)=0263fiKumar, Zilberstein, & Toussaintcutoff time message propagation fixed shown Section 4.4.shown Section 5.4.1, expectation required action updates followingtime dependent DBN mixture link l:El [r = 1, a, p, u] =XP (T )XP (r = 1, = a, pt = p, ut = u|T ; l )(82)t=0=0Breaking inner summation last time step remainder, get:==XP (T )PT (r = 1, a, p, u)+=0XX1XXP (T )Pt (r = 1, a, p, u)t=0=01 XXXRsuvab apu bqv (p, q, s, u, v)+ P (T )t1 (p0,q 0,s0,u0,v 0 )Pt (a,p,u, p0,q 0,s0,u0,v 0 )=0 svqbt=0 p0 q 0 s0 u0 v 0=0last equality, marginalized variables intermediate time slice.moving summation time inside last time slice, marginalizingintermediate time slice (q, s, v), get:= apu0XRsuvab bqv (p, q, s, u, v) +XP (T )Xt1 (p0 , q 0 , s0 , u0 , v 0 )P (p0 , u0 |a, p, u, s)t=0 qvsp0 q 0 s0 u0 v 0=0svqb01XP (q , v |q, v, s)Ps0 apu (p, q, s, u, v)Upon resolving time summation second part equation (Toussaint et al.,2006), get final expression:Xp0 q 0 s0 u0 v 0X1qsvb0 0 0 0 00 00 00(p , q , , u , v )P (p , u |a, p, u, s)P (q , v |q, v, s)PsEl [r = 1, a, p, u]= apuX(p, q, s, u, v)Rsuvab bqv +expectation El [r = 1, b, q, v] agent calculated analogousmanner.derive expectation controller node transition update:El [r = 1, p, p, y] =XP (T )=1XP (r = 1, pt = p, pt1 = p, yt = y|T ; l )t=1simplifying equation, get:=X=1P (T )XXt=1 qsuv(p, q, s, u, v)Pt (p, q, s, u, v, p, y)264(83)fiProbabilistic Inference Multiagent Decision MakingUpon marginalizing (q, s, u, v), get:=XP (T )XXt=1 qsuvqsuv=1(p, q, s, u, v)Pt (p, q, s, u, v|p, q, s, u, v, y)P (y|p, u, s)t1 (p, q, s, u, v)=XP (T )=1Xt=1Xppyqsuvqsuv(p, q, s, u, v)t1 (p, q, s, u, v)P (y|p, u, s)P (u|p, u, y)Pss P (q, v|q, v, s)= ppyX(p, q, s, u, v)(p, q, s, u, v)P (u, y|p, u, s)Pss P (q, v|q, v, s)qsuvqsuvP (u, y|p, u, s), P (q, v|q, v, s) defined as:XP (u, y|p, u, s) =Puau Pyasu apu(84)P (q, v|q, v, s) =Xqqz Pvbv Pz bsv bqv(85)bzfinal equation El [r = 1, p, p, y] given by:XEl [r = 1, p, p, y] = ppy(p, q, s, u, v)(p, q, s, u, v)P (u, y|p, u, s)Pss P (q, v|q, v, s)qsuvqsuv(86)ReferencesAmato, C., Bernstein, D. S., & Zilberstein, S. (2007). Solving POMDPs using quadratically constrained linear programs. International Joint Conference ArtificialIntelligence, pp. 24182424.Amato, C., Bernstein, D. S., & Zilberstein, S. (2010). Optimizing fixed-size stochasticcontrollers POMDPs decentralized POMDPs. Autonomous Agents MultiAgent Systems, 21 (3), 293320.Becker, R., Zilberstein, S., & Lesser, V. (2004). Decentralized Markov decision processesevent-driven interactions. Proceedings 3rd International ConferenceAutonomous Agents Multiagent Systems, pp. 302309.Becker, R., Zilberstein, S., Lesser, V., & Goldman, C. V. (2003). Transition-independentdecentralized Markov decision processes. Proceedings 2nd International Conference Autonomous Agents Multi Agent Systems, pp. 4148.Becker, R., Zilberstein, S., Lesser, V., & Goldman, C. V. (2004). Solving transition independent decentralized Markov decision processes. Journal Artificial IntelligenceResearch, 22, 423455.265fiKumar, Zilberstein, & ToussaintBernstein, D. S., Amato, C., Hansen, E. A., & Zilberstein, S. (2009). Policy iterationdecentralized control Markov decision processes. Journal Artificial IntelligenceResearch, 34, 89132.Bernstein, D. S., Givan, R., Immerman, N., & Zilberstein, S. (2002). complexitydecentralized control Markov decision processes. Mathematics OperationsResearch, 27, 819840.Bertsekas, D. P. (1999). Nonlinear Programming (2nd edition). Athena Scientific.Boyd, S., & Vandenberghe, L. (2004). Convex Optimization. Cambridge University Press,New York, NY, USA.Cheng, Q., Liu, Q., Chen, F., & Ihler, A. (2013). Variational planning graph-basedMDPs. Advances Neural Information Processing Systems, pp. 29762984.Dempster, A. P., Laird, N. M., & Rubin, D. B. (1977). Maximum likelihood incompletedata via EM algorithm. Journal Royal Statistical society, Series B, 39 (1),138.Dibangoye, J. S., Amato, C., Doniec, A., & Charpillet, F. (2013a). Producing efficient errorbounded solutions transition independent decentralized MDPs. ProceedingsInternational Conference Autonomous Agents Multi-agent Systems, pp.539546.Dibangoye, J. S., Amato, C., Buffet, O., & Charpillet, F. (2013b). Optimally solving DecPOMDPs continuous-state MDPs. Proceedings 23rd International JointConference Artificial Intelligence, pp. 9096.Dibangoye, J. S., Buffet, O., & Charpillet, F. (2014). Error-bounded approximationsinfinite-horizon discounted decentralized POMDPs. Proceedings EuropeanConference Machine Learning Knowledge Discovery Databases, pp. 338353.Dibangoye, J. S., Mouaddib, A.-I., & Chaib-draa, B. (2009). Point-based incremental pruning heuristic solving finite-horizon DEC-POMDPs. Proceedings 8th International Joint Conference Autonomous Agents Multiagent Systems, pp.569576.Eker, B., & Akin, H. L. (2013). Solving decentralized POMDP problems using geneticalgorithms. Autonomous Agents Multi-Agent Systems, 27 (1), 161196.Ghahramani, Z., & Jordan, M. I. (1995). Factorial hidden Markov models. AdvancesNeural Information Processing Systems, Vol. 8, pp. 472478.Gill, P. E., Murray, W., & Saunders, M. A. (2002). SNOPT: SQP algorithm largescale constrained optimization. SIAM Journal Optimization, 12 (4), 9791006.Goldman, C. V., & Zilberstein, S. (2004). Decentralized control cooperative systems:Categorization complexity analysis. Journal Artificial Intelligence Research,22, 143174.Grzes, M., Poupart, P., & Hoey, J. (2013). Controller compilation compression resource constrained applications. International Conference Algorithmic DecisionTheory, pp. 193207.266fiProbabilistic Inference Multiagent Decision MakingGrzes, M., Poupart, P., Yang, X., & Hoey, J. (2015). Energy efficient execution POMDPpolicies. IEEE Transactions Cybernetics, preprint.Hansen, E. A., Bernstein, D. S., & Zilberstein, S. (2004). Dynamic programming partiallyobservable stochastic games. Proceedings 19th AAAI Conference ArtificialIntelligence, pp. 709715.Hoffman, M., de Freitas, N., Doucet, A., & Peters, J. (2009a). expectation maximization algorithm continuous Markov decision processes arbitrary rewards.Proceedings International Conference Artificial Intelligence Statistics,pp. 232239.Hoffman, M., Kueck, H., de Freitas, N., & Doucet, A. (2009b). New inference strategiessolving Markov decision processes using reversible jump MCMC. ProceedingsInternational Conference Uncertainty Artificial Intelligence, pp. 223231.Kiselev, I., & Poupart, P. (2014a). Policy optimization marginal-map probabilistic inference generative models. Proceedings International Conference Autonomous Agents Multi-agent Systems, pp. 16111612.Kiselev, I., & Poupart, P. (2014b). POMDP planning marginal-MAP probabilistic inference generative models. Proceedings 2014 AAMAS Workshop AdaptiveLearning Agents.Koller, D., & Parr, R. (1999). Computing factored value functions policies structured MDPs. Proceedings 16th International Joint Conference ArtificialIntelligence, pp. 13321339.Koller, D., & Friedman, N. (2009). Probabilistic Graphical Models: Principles Techniques. MIT Press.Kumar, A., & Zilberstein, S. (2009a). Constraint-based dynamic programming decentralized POMDPs structured interactions. Proceedings Eighth InternationalConference Autonomous Agents Multiagent Systems, pp. 561568.Kumar, A., & Zilberstein, S. (2009b). Event-detecting multi-agent MDPs: Complexityconstant-factor approximation. Proceedings 21st International JointConference Artificial Intelligence, pp. 201207.Kumar, A., & Zilberstein, S. (2010a). Anytime planning decentralized POMDPs using expectation maximization. Proceedings Conference UncertaintyArtificial Intelligence, pp. 294301.Kumar, A., & Zilberstein, S. (2010b). Point-based backup decentralized POMDPs:Complexity new algorithms. Proceedings 9th International ConferenceAutonomous Agents Multiagent Systems, pp. 13151322.Kumar, A., Zilberstein, S., & Toussaint, M. (2011). Scalable multiagent planning usingprobabilistic inference. Proceedings 22nd International Joint ConferenceArtificial Intelligence, pp. 21402146.Lauritzen, S. L., & Nilsson, D. (2001). Representing solving decision problemslimited information. Management Science, 47, 12351251.267fiKumar, Zilberstein, & ToussaintLiu, Q., & Ihler, A. T. (2012). Belief propagation structured decision making.Proceedings Twenty-Eighth Conference Uncertainty Artificial Intelligence,Catalina Island, CA, USA, August 14-18, 2012, pp. 523532.Liu, Q., & Ihler, A. T. (2013). Variational algorithms marginal MAP. JournalMachine Learning Research, 14 (1), 31653200.MacDermed, L. C., & Isbell, C. (2013). Point based value iteration optimal belief compression Dec-POMDPs. Advances Neural Information Processing Systems,pp. 100108.Marecki, J., Gupta, T., Varakantham, P., Tambe, M., & Yokoo, M. (2008). agentsequal: Scaling distributed POMDPs agent networks. Proceedings7th International Joint Conference Autonomous Agents Multiagent Systems,pp. 485492.Mostafa, H., & Lesser, V. R. (2009). Offline planning communication exploiting structured interactions decentralized MDPs. International Conference IntelligentAgent Technology, pp. 193200.Mostafa, H., & Lesser, V. R. (2011). Compact mathematical programs DEC-MDPsstructured agent interactions. International Conference UncertaintyArtificial Intelligence, pp. 523530.Mundhenk, M., Goldsmith, J., Lusena, C., & Allender, E. (2000). Complexity finitehorizon Markov decision process problems. J. ACM, 47 (4), 681720.Nair, R., Varakantham, P., Tambe, M., & Yokoo, M. (2005). Networked distributedPOMDPs: synthesis distributed constraint optimization POMDPs. Proceedings 20th AAAI Conference Artificial Intelligence, pp. 133139.Nair, R., Tambe, M., Yokoo, M., Pynadath, D., Marsella, S., Nair, R., & Tambe, M. (2003).Taming decentralized POMDPs: Towards efficient policy computation multiagentsettings. Proceedings 18th International Joint Conference Artificial Intelligence, pp. 705711.Oliehoek, F. A., Spaan, M. T. J., Amato, C., & Whiteson, S. (2013). Incremental clusteringexpansion faster optimal planning Dec-POMDPs. Journal ArtificialIntelligence Research, 46, 449509.Oliehoek, F. A., Spaan, M. T. J., & Vlassis, N. A. (2008). Optimal approximate Q-valuefunctions decentralized POMDPs. Journal Artificial Intelligence Research, 32,289353.Oliehoek, F. A., Whiteson, S., & Spaan, M. T. J. (2013). Approximate solutions factoreddec-pomdps many agents. Proceedings 12th International ConferenceAutonomous Agents Multiagent Systems, pp. 563570.Pajarinen, J., Hottinen, A., & Peltonen, J. (2014). Optimizing spatial temporal reusewireless networks decentralized partially observable Markov decision processes.IEEE Transactions Mobile Computing, 13 (4), 866879.Pajarinen, J., & Peltonen, J. (2011a). Efficient planning factored infinite-horizon DECPOMDPs. Proceedings 22nd International Joint Conference ArtificialIntelligence, pp. 325331.268fiProbabilistic Inference Multiagent Decision MakingPajarinen, J., & Peltonen, J. (2011b). Periodic finite state controllers efficient POMDPDEC-POMDP planning. Advances Neural Information Processing Systems,pp. 26362644.Pajarinen, J., & Peltonen, J. (2013). Expectation maximization average reward decentralized POMDPs. Proceedings European Conference Machine Learning,pp. 129144.Pineau, J., Gordon, G., & Thrun, S. (2006). Anytime point-based approximations largePOMDPs. Journal Artificial Intelligence Research, 27, 335380.Poupart, P., & Boutilier, C. (2003). Bounded finite state controllers. Advances NeuralInformation Processing Systems.Poupart, P., Lang, T., & Toussaint, M. (2011). Analyzing escaping local optimaplanning inference partially observable domains. European ConferenceMachine Learning, pp. 613628.Seuken, S., & Zilberstein, S. (2007). Memory-bounded dynamic programming DECPOMDPs. Proceedings 20th International Joint Conference ArtificialIntelligences, pp. 20092015.Smith, T., & Simmons, R. (2004). Heuristic search value iteration POMDPs. International Conference Uncertainty Artificial Intelligence, pp. 520527.Toussaint, M., Harmeling, S., & Storkey, A. (2006). Probabilistic inference solving(PO)MDPs. Tech. rep. EDIINF-RR-0934, University Edinburgh, School Informatics.Toussaint, M., Charlin, L., & Poupart, P. (2008). Hierarchical POMDP controller optimization likelihood maximization. International Conference UncertaintyArtificial Intelligence, pp. 562570.Toussaint, M., & Storkey, A. J. (2006). Probabilistic inference solving discretecontinuous state Markov decision processes. International Conference MachineLearning, pp. 945952.Varakantham, P., Marecki, J., Yabu, Y., Tambe, M., & Yokoo, M. (2007). Letting looseSPIDER network POMDPs: Generating quality guaranteed policies.Proceedings 6th International Joint Conference Autonomous AgentsMultiagent Systems, pp. 18.Varakantham, P., Kwak, J., Taylor, M. E., Marecki, J., Scerri, P., & Tambe, M. (2009).Exploiting coordination locales distributed POMDPs via social model shaping.Proceedings 19th International Conference Automated Planning Scheduling, pp. 313320.Witwicki, S. J. (2011). Abstracting Influences Efficient Multiagent CoordinationUncertainty. Ph.D. thesis, Department Computer Science, University Michigan,Ann Arbor.Witwicki, S. J., & Durfee, E. H. (2010). Influence-based policy abstraction weaklycoupled Dec-POMDPs. Proceedings 20th International Conference Automated Planning Scheduling, pp. 185192.269fiKumar, Zilberstein, & ToussaintWitwicki, S. J., & Durfee, E. H. (2011). Towards unifying characterization quantifyingweak coupling Dec-POMDPs. Proceedings 10th International ConferenceAutonomous Agents Multiagent Systems, pp. 2936.Wu, F., Zilberstein, S., & Chen, X. (2010). Trial-based dynamic programming multiagent planning. Proceedings 24th AAAI Conference Artificial Intelligence,pp. 908914.Wu, F., Zilberstein, S., & Jennings, N. R. (2013). Monte-Carlo expectation maximizationdecentralized POMDPs. Proceedings 23rd International Joint ConferenceArtificial Intelligence, pp. 397403.270fiJournal Artificial Intelligence Research 53 (2015) 541-632Submitted 01/15; published 07/15ITSAT: Efficient SAT-Based Temporal PlannerMasood Feyzbakhsh RankoohGholamreza Ghassem-Sanifeyzbakhsh@ce.sharif.edusani@sharif.eduComputer Engineering Department,Sharif University Technology,Azadi ave., Tehran, IranAbstractPlanning satisfiability known efficient approach deal many typesplanning problems. However, approach competitive state-spacebased methods temporal planning. paper describes ITSAT efficient SAT-based(satisfiability based) temporal planner capable temporally expressive planning.novelty ITSAT lies way handles temporal constraints given problems withoutgetting involved difficulties introducing continuous variables correspondingsatisfiability problems. also show how, SAT-based classical planning, carefullydevised preprocessing encoding schemata considerably improve efficiencySAT-based temporal planning. present two preprocessing methods mutex relationextraction action compression. also show separation causal temporalreasoning enables us employ compact encodings based concept parallelexecution semantics. Although encodings shown quite effectiveclassical planning, ITSAT first temporal planner utilizing type encoding.empirical results show ITSAT outperform state-of-the-art temporallyexpressive planners, also competitive fast temporal planners cannothandle required concurrency.1. IntroductionTemporal planning extension classical planning actions durative ratherinstantaneous. introduction durative actions adds new dimensionsolving planning problems, namely reasoning time. Temporal reasoning per sedifferent causal reasoning, time real-valued quantity, whereas causalaspects planning normally represented propositions.current standard language defining temporal planning problems PDDL2.1(Fox & Long, 2003). Although PDDL+ (Fox & Long, 2002) introducedplanning community expressive language defining temporal numericalplanning problems, throughout paper, focus PDDL2.1, planningproblems tackled need expressive power PDDL+. PDDL2.1,actions separate preconditions effects upon starting ending. temporalaction also invariants, must preserved executionaction. important subset problems defined PDDL2.1 problems everyvalid plan includes concurrent execution two actions. subset calledproblems required concurrency. shown concurrent execution twoactions may necessary solving temporal problems (Halsey, Long, & Fox, 2004;Cushing, Kambhampati, Mausam, & Weld, 2007). instance, temporal planningc2015AI Access Foundation. rights reserved.fiRankooh & Ghassem-Saniproblems, actions may require proposition available executionanother action. cases, two actions must executed concurrently.specific example given Section 2, describe Driverlogshift domain.common approach many planners temporally expressive eliminatecases compressing temporal actions create non-durative classical actions.paper, describe ITSAT, temporally expressive SAT-based (i.e., satisfiabilitybased) planner. ITSAT uses approach takes advantage parallel execution semantics without rendering incomplete problems required concurrency.approach, durations actions given problem first abstracted out.done breaking temporal action two starting ending instantaneous events.obtained temporally abstract problem encoded SAT formula using novel-step -step semantics causally valid plans. show semanticsused encode given temporal planning problem SAT formula. Classical -step-step encoding methods introduced (Rintanen, Heljanko, & Niemela,2006). addition extending methods temporal planning context, alsointroduce new encoding method based -step semantics causally valid plans.show new encoding often results significant reduction number requiredsteps.generating causally valid plan, ITSAT performs scheduling phase.phase, ITSAT tries satisfy temporal constraints imposed consideringdurations actions. done solving Simple Temporal Problem (STP) (Dechter,Meiri, & Pearl, 1991). However, problems required concurrency, posed STPmay inconsistent. cases, cause inconsistency, manifestsnegative cycle corresponding Simple Temporal Network (STN), detected. ITSATgenerates number clauses added SAT formula, collectively preventreoccurrence particular negative cycle occurred similar cycles.process repeated temporally valid plan found.Similar SAT-based planners, ITSAT takes advantage preprocessing phaseextract information structure problems. information usedthroughout encoding phase produce formula whose satisfiability checkedefficiently SAT solver. Section 3, describe preprocessing phaseITSAT, includes reasoning mutual exclusion so-called safe actioncompression (Coles, Coles, Fox, & Long, 2009). Two propositions regarded mutuallyexclusive never jointly true state valid temporal plan. Here,show one detect mutually exclusive propositions temporal problems usingplanning graph analysis (Blum & Furst, 1997). known employing mutual exclusionreasoning significantly improve performance SAT-based planners (Gerevini &Schubert, 1998).mentioned earlier, ITSAT breaks temporal action two startingending instantaneous events. Although cases breaking mightnecessary producing concurrent plans, situations necessaryfinding valid plans. Section 3, show using mutual exclusion information,one identify temporal actions safely compressed classical actionwithout falsifying validity temporal plans. analysis results smaller numberdistinct events therefore simpler planning problem.542fiITSAT: Efficient SAT-Based Temporal Plannerempirically show taking advantage preprocessing, encoding,scheduling phases, ITSAT significantly outperform state-of-the-art temporally expressive planners, also competitive best temporally simple plannersincapable solving problems required concurrency property. components ITSAT shown Figure 1. figure, processing componentsITSAT system shown rectangular blocks, links represents data producedreceived components.Figure 1. block diagram ITSAT543fiRankooh & Ghassem-Sani1.1 Motivationmentioned earlier, temporal planners need reason time, continuousquantity. Nevertheless, causal structures problems temporal planning stillsimilar classical planning. existence abundant temporal planning domainsalso classical versions regarded evidence claim. suggeststemporal planners benefit using approaches previously showneffective dealing classical problems.usage Boolean satisfiability checking well-known paradigm tackling classicalplanning problems (Kautz & Selman, 1992). approach, given planning problemtranslated formula propositional logic. variable SAT formula typicallyrepresents occurrence corresponding action proposition certain placepotential plan. causal constraints planning problem represented numberground clauses. output plan assumed finite number steps. stepmay include one actions. original SAT-based planner allowed one actionper step (Kautz & Selman, 1992). However, previously introduced SAT-based plannersallow multiple occurrence actions step. produced formula giveninput off-the-shelf SAT solver, tries find model it. modelfound, plan extracted it. Otherwise, number steps output planincreased one corresponding SAT formula given SAT solver.process repeated valid plan extracted predefined termination conditionreached. order obtain efficient SAT-based planner, one important issueconsidered encode given planning problem SAT formula.SAT-based planning originally used find optimal plans, i.e., plans minimumnumber actions (Kautz & Selman, 1992). guarantee optimality output plan,formula must include certain clauses ban step containing oneaction. However, so-called satisficing planning, optimality mainobjective, forcing single-action steps necessary. alternative approach consideractions executed parallel step output plan (Ernst, Millstein,& Weld, 1997). Exploiting parallelism result smaller number stepsSAT formula. Another important benefit producing compact formulae lower memoryrequirements. Several encoding methods introduced take advantage actionparallelism. encoding methods based so-called -step -step semanticsvalid plans (Rintanen et al., 2006).-step -step semantics different extent action parallelismallow occur step. -step semantics allows set actions executedparallel, actions executed every possible ordering without affectingvalidity plan. -step semantics, hand, imposes weaker restriction:step plan, must exist least one possible ordering actionsexecuted without falsifying validity plan. clear -stepsemantics potentially allows parallelism permitted -step semantics.fact, taking advantage -step semantics, efficient SAT-based classical planner,i.e., Mp (Rintanen, 2012), competitive state-of-the-art state-space planners.paper, show separation causal temporal reasoning phases temporalplanning enables us employ compact encodings efficient temporal planning.544fiITSAT: Efficient SAT-Based Temporal Planner1.2 Related WorkPrevious research field temporal planning benefited enormously employingwell-developed classical planning strategies. instance, many successful temporal planners utilized ideas partial order planning, e.g. VHPOP (Younes & Simmons,2003) CPT (Vidal & Geffner, 2006). Planning graph analysis also adoptedtemporal planners TGP (Smith & Weld, 1999) TPSYS (Garrido, Fox, & Long,2002). temporal planners embedded temporal reasoning heuristicstate space search. TFD (Eyerich, Mattmuller, & Roger, 2009), LPG-td (Gerevini, Saetti,& Serina, 2006), POPF (Coles, Coles, Fox, & Long, 2010) successful instanceslatter approach.usage Boolean satisfiability checking one well-known paradigms tackling classical planning problems (Kautz & Selman, 1992). order obtain efficientSAT-based planner, one important issue considered encodegiven planning problem SAT formula. fact, devising efficient encoding methodsimportant research trend field SAT-based planning. Examplesefficient encodings are: split action representation (Kautz & Selman, 1996; Ernst et al.,1997; Robinson, Gretton, Pham, & Sattar, 2009), SAS+ based encoding (Huang, Chen,& Zhang, 2012), compact mutual exclusion representation (Rintanen, 2006). Basedparallel semantics plans, another effective encoding method introduced (Rintanen et al., 2006). latter encoding method particular interest paper.Satisfiability checking also employed field temporal planning. However,SAT-based temporal planners encounter major challenge: representing temporal aspects problems. Since time continuous quantity, cannot treated exactway discrete causality handled. tackle problem, STEP (Huang, Chen, &Zhang, 2009), SCP2 (Lu, Huang, Chen, Xu, Zhang, & Chen, 2013), T-SATPLAN (Mali& Liu, 2006) use discrete representation time. planners assign explicit discretetime labels step encoding. Generally speaking, approach, stepexactly one time unit ahead step + 1. result, action duration startsstep i, forced end step + d. One immediate outcome approachintroduction enormous number steps encoding, manycontribute output plan. drawback explicit time representation causesSTEP, SCP2, T-SATPLAN inefficient terms speed memory usage. obtain better performance, SCP2 uses -step semantic allow causal relationsactions time point (Lu et al., 2013).TM-LPSAT (Shin & Davis, 2005), designed solve planning problemsdefined PDDL+ (Fox & Long, 2002), another SAT-based planner capable handlingtemporal planning problems. Similar STEP T-SATPLAN, TM-LPSAT attachestime labels step. However, TM-LPSAT, labels predefined discretenumbers. Instead, label numeric variable whose value determinedproblem solved SMT solver (Armando & Giunchiglia, 1993). approachresult encodings compact produced STEP TSATPLAN.major disadvantage assigning time label step formula parallelism mentioned cannot exploited effectively. two events545fiRankooh & Ghassem-Sanihappen certain step plan, time labels must same, thus,must simultaneous final plan executed. compulsory simultaneityrestriction reduces number events happen step finalplan, turn, increases number steps needed solving input problems.implies efficiency gain one could obtain using parallel execution semanticssacrificed achieve easy way deal temporal constraints. However,majority current temporal planning problems, satisfying temporal constrainshardest task finding valid plan. shown problems without requiredconcurrency, one omit temporal constraints altogether, find causally valid plan,then, considering temporal constraints postproccessing step, scheduleactions plan find temporally valid plan (Cushing et al., 2007). approachactually used many previous temporal planners including YAHSP3-mt (Vidal,2014), winner temporal satisficing track IPC 2014. Despite efficientsolving many temporal problems, planners incomplete, incapablesolving problems required concurrency.addition classical planning problems, SAT-based methods also useddeal categories planning problems. Examples planning uncertainty(Castellini, Giunchiglia, & Tacchella, 2003), cost-optimal planning (Robinson, Gretton,Pham, & Sattar, 2010) numerical planning (Hoffmann, Gomes, Selman, & Kautz,2007).2. Preliminariesstandard language used defining temporal planning problems PDDL2.1 (Fox &Long, 2003). Figure 2 presents example PDDL2.1 representation temporalplanning domain. domain, simplified version Driverlogshift (Halsey, 2004),referred several times throughout paper. Figure 2 shows, PDDL2.1,action separate conditions effects upon starting ending. startingending conditions (or effects) action specified start endtokens, respectively. action may also conditions need preservedexecution. conditions specified using token. Moreover,duration action defined (= ?duration x) statement, x rationalnumber function specifying actual duration action.Driverlogshift temporal version Driverlog domain IPC3.classical counterpart, Driverlogshift, objective transfer several objectsoriginal places destinations. object loaded unloadedcertain truck using LOAD UNLOAD operators, respectively. truck movelocations using MOVE operator. main difference DriverlogshiftDriverlog trucks must rested intervals workingshifts. working shift defined WORK operator, produces (workingtruck) proposition upon starting, deletes proposition upon ending. LOAD, UNLOAD,MOVE (working truck) invariant. (working truck) deletedending WORK, may reproduced REST operator, defines restingshift certain truck.546fiITSAT: Efficient SAT-Based Temporal Planner(define (domain driverlogshift)(:requirements :typing :durative-actions)(:typeslocation locatable - objecttruck obj - locatable)(:predicates(at ?obj - locatable ?loc - location)(in ?obj1 - obj ?obj - truck)(link ?x ?y - location)(working ?t - truck)(need-rest - truck)(rested - truck))(:durative-action WORK:parameters(?truck - truck):duration (= ?duration 100):condition (and(at start (rested ?truck))):effect (and (at start (working ?truck))(at end (not (working ?truck)))(at start (not (rested ?truck)))(at end (need-rest ?truck))))(:durative-action REST:parameters(?truck - truck):duration (= ?duration 20):condition (and(at start (need_rest ?truck))):effect (and(at start (not (need_rest ?truck)))(at end (rested ?truck))))(:durative-action LOAD:parameters(?obj - obj?truck - truck?loc - location):duration (= ?duration 10):condition (and(over (at ?truck ?loc))(over (working ?truck))(at start (at ?obj ?loc))):effect (and(at start (not (at ?obj ?loc)))(at end (in ?obj ?truck))))(:durative-action UNLOAD:parameters(?obj - obj?truck - truck?loc - location):duration (= ?duration 10):condition (and(over (at ?truck ?loc))(over (working ?truck))(at start (in ?obj ?truck))):effect (and(at start (not (in ?obj ?truck)))(at end (at ?obj ?loc))))(:durative-action MOVE:parameters(?truck - truck?loc-from - location?loc-to - location):duration (= ?duration 50):condition (and(at start (at ?truck ?loc-from))(at start (link ?loc-from ?loc-to))(over (working ?truck))):effect (and(at start (not (at ?truck ?loc-from)))(at end (at ?truck ?loc-to)))))Figure 2. PDDL2.1 description Driverlogshift domainNote version Driverlogshift described Figure 2 slightly differentoriginal version (Halsey, 2004), drivers walk to, board,disembark trucks. Furthermore, REST WORK actions performed driversrather trucks. However, order make examples simpler, merged driverstrucks single entity trucks.simple example problems Driverlogshift shown Figure 3. problem,three locations (s0, s1, s2), one truck (truck1), one object (package1).initial state, truck1 package1 s0. objective problemtransfer package1 s2.2.1 Formalism PDDL2.1present formalism specifications PDDL2.1. formalism devisedway simplifies description preprocessing, encoding, scheduling phasesITSAT. mention formalism limitations comparedfull specifications PDDL2.1. limitations discussed details Section 2.2.547fiRankooh & Ghassem-Sani(define (problem DLOG)(:domain driverlogshift)(:objectstruck1- truckpackage1 - objs0 s1 s2 - location)(:init(rested truck1)(at truck1 s0)(at package1 s0)(link s0 s1)(link s1 s0)(link s2 s1)(link s1 s2))(:goal (and(at package1 s2))))Figure 3. PDDL2.1 description problem Driverlogshift domainDefinition 1 (events). event, e, triple (pre(e), add(e), del(e)), pre(e),add(e), del(e) three sets atomic propositions (facts) representing preconditions,positive effects, negative effects e, respectively.Definition 2 (temporal actions) temporal action, a, quadruple (start(a), end(a),inv(a), dur(a)), start(a) end(a) two events denoting starting endingevents a, inv(a) set atomic propositions representing invariants a,dur(a) positive rational number specifying duration a.Example 1. Figure 4 shows temporal action = LOAD(package1, truck1, s0),instance LOAD operator defined Figure 2. Figure 4, depicted rectangular box. Conditions effects written box, respectively.start conditions effects placed left hand side box,end conditions effects placed right hand side box.conditions placed middle box. Here, start(a) end(a)two events, pre(start(a)) = {(at package1 s0)}, add(start(a)) = , del(start(a)) ={(at package1 s0)}, pre(end(a)) = , add(end(a)) = {(at package1 truck1)}, alsodel(end(a)) = . Moreover, inv(a) = {(at truck1 s0), (working truck1)},dur(a) = 10.548fiITSAT: Efficient SAT-Based Temporal PlannerFigure 4. temporal actionDefinition 3 (temporal states). temporal state, s, pair (state(s), agenda(s)),state(s) classical planning state represented set atomic propositions,agenda(s) contains finite set open actions (i.e., actions started prior yetended).Definition 4 (applicability). starting event e action applicable state s,following conditions hold:(1) state(s) contains preconditions einvariants (exceptinvariants added e): pre(e) (inv(a) add(e)) state(s)(2) already open s:/ agenda(s)(3) eSdoes delete theTinvariants open action s:del(e) =agenda(s) inv(a )ending event e action applicable state s, following conditions hold:(1) state(s) contains preconditions e: pre(e) state(s)(2) open s: agenda(s)(3)e delete invariantsopen action (other a):)inv(adel(e)=agenda(s){a}Definition 5 (successors). starting event e action applicable state s,change unique state satisfying following conditions:set openactions equal set open actions a: agenda(s ) =agenda(s) {a}positive negative effectse respectively added deleted :state(s ) = (state(s) del(e)) add(e)ending event e action applicable state s, change unique statesatisfying following conditions:549fiRankooh & Ghassem-Saniset open actions equal set open actions without a:agenda(s ) = agenda(s) {a}positive negativeeffects e respectively added deleted : state(s ) =(state(s) del(e)) add(e)on, may use succ(s, e) represent successor state obtained applyinge s.Definition 4 Definition 5 easily extended also cover sequence events:succ(s, he1 , ..., en i) = succ(succ(s, he1 , ..., en1 i), en ), succ(s, hi) = s. sequenceevents he1 , ..., en applicable temporal state s, succ(s, he1 , ..., en i) defined.Example 2. Let temporal statestate(s) = {(at package1 s0), (at truck1 s0), (working truck1), (link s0 s1)}agenda(s) = .Let = LOAD(package1, truck1, s0) = MOVE(truck1, s0, s1) two temporal actions, respectively instances LOAD MOVE operators presented Figure2. event start(a) applicable changesstate(s ) = {(at truck1 s0), (working truck1), (link s0 s1)}agenda(s ) = {LOAD(package1, truck1, s0)}.Now, start(a) applicable already open . isstart(a ) applicable , deletes (at truck1 s0) invariant a, still open .However, end(a) applicable changesstate(s ) = {(at package1 truck1), (at truck1 s0), (working truck1), (link s0 s1)}agenda(s ) = .Definition 6 (temporal problems). temporal problem, P, triple (I, G, A),I, representing initial state, temporal state agenda(I) = . G setatomic propositions denoting goal conditions, finite set possibletemporal actions P.Definition 7 (causally valid plans). Let P = (I, G, A) temporal problem= he1 , ..., en sequence events i, ei starting ending eventaction A. causally valid plan P, applicable I, G state(succ(s, )),agenda(succ(s, )) = .550fiITSAT: Efficient SAT-Based Temporal PlannerDefinition 8 (pairing events). Let = he1 , ..., en causally valid plan problem P = (I, G, A). Assume ei ej respectively starting ending eventscertain action < j. k < k < j, ek neither startingending event a, say ei (ej ) pairing event ej (ei ) .words, ei ej pairing events related occurrence .Definition 9 (valid temporal plans makespan). Let = he1 , ..., en causallyvalid plan P = (I, G, A), : {1, ..., n} Q scheduling function , Qset rational numbers. (, ) valid temporal plan P followingproperties:i, (i) < (i + 1).A, start(a) = ei , ej pairing event ei , (j) =(i) + dur(a).maximum value assigned events called makespan .Example 3. Consider problem P = (I, G, A) depicted Figure 3, state(I)G contain propositions listed labels :init :goal, respectively,set possible instantiations operators presented Figure 2 objectslisted label :objects Figure 3. Let= hstart(WORK(truck1)),start(LOAD(truck1, package1, s0)),end (LOAD(truck1, package1, s0)),start(MOVE(truck1, s0, s1)),end (MOVE(truck1, s0, s1)),start(MOVE(truck1, s1, s2)),end (MOVE(truck1, s1, s2)),start(UNLOAD(truck1, package1, s2)),end (UNLOAD(truck1, package1, s2)),end (WORK(truck1))ischematic representation depicted Figure 5. straightforward checking showscausally valid plan P. However, valid temporal planduration WORK(truck1) 100, requires serial execution two MOVE actions, oneLOAD action, one UNLOAD action, total duration 120, WORK(truck1)still open. words, one single working shift truck1 sufficient transferpackage1 s0 s2. Therefore, scheduling function propertiesDefinition 9 exists . valid temporal plan P depicted Figure 6.plan, two working shifts truck1 used.551fiRankooh & Ghassem-SaniFigure 5. causally valid planFigure 6. valid plan2.2 Limitationsend section describing differences formalism valid temporalplans PDDL2.1. main limitations formalism listed below:According Definition 4, starting event action applicable statealready open s. means that, similar many previoustemporal planners, permit two versions action overlap.Consequently, current implementation ITSAT allow self-overlappingactions. However, specification PDDL2.1 allows plans actions,shown necessary solving certain temporal problems (Fox &Long, 2007). experimental results indicate restriction renderITSAT incapable solving current benchmark problems. Nevertheless,shown that, theory, self-overlapping actions may cause complexitytemporal planning become EXPSPACE-hard rather PSPACE-hard (Rintanen,2007).formalism allow two events simultaneously appliedstate. example cases simultaneity required, consider twotemporal actions b, starting event adds invariant b,552fiITSAT: Efficient SAT-Based Temporal Plannerstarting event b adds invariant a. case, might necessarysimultaneously apply starting event actions given state.clear specification PDDL2.1 whether simultaneity permittednot. hand, shown almost none current benchmarkproblems require simultaneity solvable (Rankooh & Ghassem-Sani,2013).PDDL2.1 allows usage numerical variables. supported ITSAT.PDDL2.1 also allows duration dependent effects state dependent durationsactions numerical planning problems. features supported ITSATeither; ITSAT currently handle numerical fluents.According formalism, duration temporal action defined (=?duration x) assignment, x rational number function specifyingactual duration action. PDDL2.1, hand, also allows usinginequalities ( ?duration x) ( ?duration x) define rangeduration temporal action. Nevertheless, current benchmark problemsinclude inequalities. Although current implementation ITSATsupport inequalities, quite easy include feature, kindsconstraints duration actions handled Simple Temporal Problems(Dechter et al., 1991).3. Preprocessing PhasePreprocessing important phase many planners. main objective phaseextract certain information problem. information later usedenhance search performance. One important issue addressed devisingpreprocessing method correctness extracted information. words,constraints inferred preprocessing phase must correct sense that,cause planner become incapable finding valid plans. Moreover,preprocessing method effective, required performed polynomialtime. section, explain two different preprocessing methods used ITSAT: mutualexclusion analysis action compression. also formally prove methodscorrect performed polynomial time.3.1 Mutual Exclusion AnalysisMutual exclusion analysis preprocessing method find pairs propositions cannot mutually true state valid plan. SAT-based planners typically addexplicit clause SAT formula pair mutually exclusive propositions.clauses prevent mutually exclusive pairs propositions true truetime. Although information obtained search phase itself, acquiring beforehand, one prune search tree SAT solver thereby improveperformance.Polynomial time mutual exclusion analysis classical planning problems originally performed constructing planning graphs, data structure introduced553fiRankooh & Ghassem-SaniGRAPHPLAN (Blum & Furst, 1997). shown mutual exclusioninformation obtained planning graphs quite effective improving performance SAT-based planners (Gerevini & Schubert, 1998). methods alsointroduced compute n-way mutexes (instead pairwise mutexes computedplanning graphs). hn heuristic (Haslum & Geffner, 2000), analyzes reachability set n propositions initial state, example methods.shown generalization hn heuristic efficiently computedusing syntactic regression operation (Rintanen & Gretton, 2013).method used ITSAT finding mutual exclusion relations basedplanning graph analysis. classical planning graph layered structure. first layerincludes propositions present initial state problem.layer planning graph, mutual exclusion (mutex ) relations pairs propositioncomputed. Two propositions non-mutex first layerpresent initial state. action applicable layer preconditionsnon-mutex layer. Two different actions mutex layer i, least onefollowing conditions holds: 1) interference (i.e., one actiondeletes effect action), 2) conflict (i.e., one actiondeletes precondition action), 3) preconditions mutex layer i.Layer + 1 includes effects actions applicable layer i. Two propositionsmutex layer become non-mutex layer + 1 produced non-mutexactions layer i. transfer propositions one layer next layer, existsspecial noopp action proposition p requires adds p. constructionplanning graph may continue change take places two consecutive layers.case, say graph leveled off.Planning graphs previously employed tackle temporal planning problems(Smith & Weld, 1999). fact, first completely domain-independent temporal plannercalled TGP, extension GRAPHPLAN (Blum & Furst, 1997). TGP requirespreconditions temporal action preserved throughout time actionopen, also allow actions effects upon starting. result, TGPcompatible requirements PDDL2.1. TPSYS (Garrido et al., 2002),extension TGP, another planning graph based temporal planner produceplans domains required concurrency. Similar GRAPHPLAN, additionconstruction planning graph, TPSYS TGP perform backward searchvalid temporal plan.LPGP (Long & Fox, 2003) another planning graph based temporal planner. LPGP,mutex relations proposition actions computed consideringcausal constraints problem; whereas temporal constraints takenaccount later plan extracted solving Linear Programming (LP) problem.Omitting temporal constraints problem done converting given temporalproblem classical problem. result, graph construction LPGPsimilar GRAPHPLAN.mentioned earlier, ITSAT, temporal constraints problem consideredcausally valid plan produced. Therefore, constraints neededdealt planning graph construction phase. makes graph structureLPGP suitable ITSAT. Here, explain graph construction phase LPGP.554fiITSAT: Efficient SAT-Based Temporal Plannercorrectness mutual exclusion information obtained method essentialcorrectness action compression SAT encoding methods. However, descriptionLPGP accompanied formal proof correctness. Therefore, here,formally prove correctness tractability preprocessing method.Definition 10 (causal abstraction temporal problems). Let P = (I, G, A)temporal planning problem Ac set classical actionsexactly three classical actions , ai , ae Ac , following properties:pre(as ) = pre(start(a)) (inv(a) add(a))add(as ) = add(start(a)) {opena }, opena new proposition specifyingstarted yet finisheddel(as ) = del(start(a)) add(start(a))pre(ai ) = inv(a) {opena }add(ai ) = inv(a) {opena }del(ai ) =pre(ae ) = pre(end(a)) {opena }add(ae ) = add(end(a))del(ae ) = (del(end(a)) add(end(a))) {opena }causal abstraction P classical problem P c = (state(I), G, Ac ).fact, Definition 10, produce causal abstraction given temporal planning problem, split temporal action three classical actions , ai , ae .Actions ae correspond respectively starting ending events a. addition normal effects preconditions, adds special proposition named opena ,required deleted ae . action ai called invariant checking actiona, requires invariants plus opena preconditions, produces openaeffect.given temporal planning problem P = (I, G, A), ITSAT producescP = (state(I), G, Ac ) i.e., causal abstraction P. ITSAT constructs classical planning graph P c .planning graph ITSAT similar GRAPHPLAN. onedifference planning graphs two planners. GRAPHPLAN, mentioned earlier, propositions propagated layers so-called noop actions.However, ITSAT, exception usage noop actions: new propositionform opena introduced causal abstraction action a. particular propositionpropagated ai , invariant checking action a. Therefore, ai seen newkind noop action used cover invariants reasoning mutex relations.555fiRankooh & Ghassem-SaniTheorem 1. Let P = (I, G, A) temporal planning problem P c = (state(I), G, Ac )causal abstraction P. Let = he1 , ..., en finite sequence eventsapplicable I, sn = succ(I, ). following conditions must hold:two propositions p q members state(sn ), p q non-mutexlayer n planning graph P c .proposition p member state(sn ), action member agenda(sn ),p opena non-mutex layer n planning graph P c .Proof. See Appendix A.planning graph leveled off, subsequent extensions grapheffect new layers. Therefore, two propositions mutex last layerleveled-off graph, remain mutex subsequently produced layers. case,Theorem 1 implies pairs propositions never appear temporalstate execution valid temporal plan. matter remainsshow mutual exclusion analysis ITSAT performed polynomial time.Let P temporal planning problem, P c causal abstraction P.deduced Definition 10, size P c greater P constantfactor. process constructing planning graph P c obtained modifyingconstruction process planning graphs GRAPHPLAN planner, waytemporal action a, noopopena never used. GRAPHPLAN constructs planninggraphs polynomial time (Blum & Furst, 1997). Therefore, overall time neededmutual exclusion analysis ITSAT also polynomial size given temporalplanning problem.3.2 Action CompressionTemporal actions variety temporal relations one another. popularmodel representing temporal relations actions initially introduced JamesAllen (1984). model included 13 possible temporal relations two actions.Allens temporal relations require starting and/or ending events actionsexecuted simultaneously. mentioned Section 2.2, none temporal plansproduced ITSAT necessitate simultaneity. result, set temporalrelations two temporal actions confined proper subset Allenstemporal relations. possible temporal relations depicted Figure 7.shown Figure 7, 4 6 types relations, actions concurrent, i.e.,exists time two actions executed. concurrencyunnecessary solving temporal planning problems. know two actionsrequired concurrently executed, order find valid plan, checkingtwo temporal relations depicted Figure 7-(c) sufficient searching phaseplanner. However, valid plans include concurrent executions two actions,restricting temporal relations actions two relations depicted Figure7-(c) render planner incomplete.556fiITSAT: Efficient SAT-Based Temporal PlannerFigure 7. Temporal relations two PDDL2.1 actionsDefinition 11 (compression-safe sets actions compressed plans). LetP = (I, G, A) temporal planning problem exists least one validtemporal plan, subset A. say compression-safe P, existscausally valid plan P compressed respect . causally valid plan= he1 , ..., en compressed respect following property:k, ek starting event action , ek+1 ending eventa.According Definition 11, starting ending events membersassumed executed consecutively least one causally valid plan. Therefore,plan executed, event causally needed happen startingending member . suggests members regardedsingle event environment, rather two separate starting ending events.557fiRankooh & Ghassem-Saniwords, member , compress starting ending eventssingle event without rendering problem unsolvable. example, considerDRIVERLOGSHIFT temporal planning problem presented Example 3. plan presentedExample 3 shows set LOAD, MOVE, UNLOAD actions compressionsafe set actions problem. straightforward analysis example showsneither WORK actions presented Example 3 member compression-safesubset actions.Note that, according Definition 11, causally valid plan regardedcompressed sequence events. Although concept compression extendedcover even sequences events lead goal state, sakesimplicity, focused attention sequences causally validplans, defined compression-safe actions solvable temporal planning problems.explain later Section 4, information obtained compression-safety analysisincorporated encoding problem adding extra SAT formulae,makes problem hand tighter. words, information used prunesearch space SAT solver. result, handling compression-safetynever cause planner produce (invalid) plan unsolvable planning problem.Safe action compression employed field temporal planning(Coles et al., 2009). shown temporal problems possessproperty required concurrency, temporal actions safely compressed classicalactions (Cushing et al., 2007). temporal problem said required concurrency,every valid temporal plan includes least one action whose execution overlapsexecution action. problems without required concurrency, temporalactions compressed classical actions. case, problem transformedclassical planning problem. phenomenon completely consistentsemantics Definition 11, easily shown problems without requiredconcurrency, set actions indeed compression-safe set actions. However,case Example 3, even problem required concurrencyproperty, may still exist non-empty compression-safe set actions.CRIKEY3 successor, POPF, two state-space based temporal plannersdetect compression-safe actions preprocessing task (Coles et al., 2009). However,concept compression-safety planners different presentedDefinition 11. CRIKEY3 assume ending event compression-safeaction must executed immediately corresponding starting event. Instead,starting event compression-safe action applied state, using simple inferencemethod, CRIKEY3 determine apply corresponding ending event.method reduce branching factor search space state-space based temporalplanning. Here, show using idea detecting compression-safe actions,one significantly reduce search space satisfiability checking based temporalplanning. later explained Section 4.4, compression-safe action a, addclause SAT formula guarantee starting event present stepending event present step. clauses usedprune search tree SAT solver checking satisfiability producedformula.CRIKEY3 considers action compression-safe following two conditions hold:558fiITSAT: Efficient SAT-Based Temporal Plannerpre(end(a)) inv(a)del(end(a)) =Figure 8-(a) shows temporal plan executed reach proposition q. example ending event action b precondition delete effect. Therefore,CRIKEY3 considers b compression safe. However, goal produce q,singleton = {b} compression-safe set Definition 11. fact, method usedCRIKEY3 specifically devised state-space based temporal planners,cannot easily employed SAT-based planners ITSAT. contrast,later shown, method easily used state-space based temporal plannersSAT-based planners.also cases method used CRIKEY3 cannot detect actionscompression-safe according Definition 11. Consider plan depicted Figure 8(b). Suppose proposition p member initial state, goalproduce proposition g. plan, actions b must executed consecutivelyproduce g. p q, respectively overall conditionsb mutually exclusive, never true together. However, neither bsecond property required CRIKEY3 regarded compression-safe action.section show mutex information used detecting compression-safeactions.Definition 12 (swappable events). Let two different temporal actions, estarting ending event a, e starting ending event . say ee swappable following conditions hold:e e interference other: add(e) del(e ) = add(e )del(e) = .e e conflict other: del(e) (pre(e ) inv(a )) =del(e ) (pre(e) inv(a)) = .e e supporting other: add(e) (pre(e ) (inv(a ) add(e ))) =add(e ) (pre(e) (inv(a) add(e))) = .According Definition 12, two events swappable causal relationthem. means causally valid plan = he1 , ..., e, e , ..., en i, swape e reach another causally valid plan = he1 , ..., e , e, ..., en i. useswapping reorder events given causally valid plan without falsifying it.Consider causally valid plan = he1 , ..., en i. Let ei ej startingending event action. events plan swappable ej ,then, repeatedly swapping, one reorder produce another causally valid plan= he1 , ..., ei , ej , ei+1 , ..., ej1 , ej+1 , ..., en i, ei ej two consecutive events.Therefore, {a} compression-safe set. case, say compressedtowards start. Similarly, every event plan ei ej swappableei , then, repeatedly swapping, one reorder produce causally validplan = he1 , ..., ei1 , ei+1 , ..., ej1 , ei , ej , ..., en i. again, conclude {a}compression-safe set. latter case, say compressed towards end.559fiRankooh & Ghassem-SaniFigure 8. Temporal actions regarded compressible ITSAT (a) CRIKEY3 (b)find whether safe compress given action a, need checkevents swappable starting and/or ending events a. fact, consideringmutex relations obtained planning graph problem, already knowevents never executed open. information effectively usedfind given set actions compression-safe.Definition 13 (compressible actions). Let P = (I, G, A) temporal planning problem, particular temporal action. say compressible towardsstart, every event e e starting ending event {a}, leastone following conditions holds:precondition add effect e mutex opena last layer leveled-offplanning graph causal abstraction P.e swappable end(a).560fiITSAT: Efficient SAT-Based Temporal PlannerSimilarly, say compressible towards end, every event e estarting ending event {a}, least one following conditions holds:precondition add effect e mutex opena last layer leveled-offplanning graph causal abstraction P.e swappable start(a).Theorem 2. Let P = (I, G, A) solvable temporal planning problem. Let setevery member either compressible towards start compressible towardsend. compression-safe P.Proof. See Appendix A.give example clarification matter.Example 4. Let P = (I, G, A) temporal planning problem, setthree temporal actions a, b, c. Consider hypothetical causally valid plan depictedFigure (9-a), execution action includes execution action bturn includes execution action c. Assume compressible towards start,b compressible towards end. show plan converted anothercausally valid plan a, b, c executed sequentially. Figures (9-b)(9-c) show results two consecutive swaps b compressed towardsend. starting event b swapped starting event c transformplan Figure (9-a) plan Figure (9-b). Since b compressible towardsend, swapping cannot result invalid plan. Similarly, starting event bswapped ending event c transform plan Figure (9-b)plan Figure (9-c). Figures (9-d) (9-g) show results four consecutive swapscompressed towards start. result swaps, fullysequential plan shown figure (9-g) produced. implies even plannerallow execution event b open, still capable producingtemporally valid plan Figure (9-g).given problem P = (I, G, A), ITSAT computes compression-safe setTheorem 2. check first condition Definition 13, ITSAT needs constructplanning graph causal abstraction P which, showed previoussubsection, done polynomial time. second condition Definition 13,suffices check every possible pair events see swappable. Sincedone pair constant time, total time O(|A|2 ). concludefinding performed polynomial time.method described finding compression-safe actions used statespace temporal planners, too. State-space temporal planners divided two categories. first category includes planners based so-called decisionepoch planning method (Cushing et al., 2007). Examples decision epoch plannersTP4 (Haslum, 2006), SAPA (Do & Kambhampati, 2003), TFD (Eyerich et al., 2009).561fiRankooh & Ghassem-SaniFigure 9. Action compressionmethod, start action restricted immediately startend another action. state explicit time-stamp. action appliedstate, starting time action set time-stamp state. result,starting event action added plan, time correspondingending event exactly known. searching valid plan, state,562fiITSAT: Efficient SAT-Based Temporal Plannerplanner make decision either advancing time ending eventopen action, open new action. However, know action compressionsafe, planner advance time ending action thereby prunesearch space. Plans produced way might larger makespans comparisonproduced without pruning search space. Nevertheless, produced plansrescheduled find plans improved makespans method explain laterSection 6.alternative approach state space search so-called temporally liftedprogression planning, proved complete PDDL2.1 (Fox & Long,2003). CRIKEY3 POPF examples planners using approach.state temporally lifted progression planning represents permutationnumber events. state, consistency temporal constraints imposedsequence events state checked solving Simple Temporal Problem (STP).Similar decision epoch planning, state, may exist two possible choices:add ending event open action, open new action. However, compressionsafe actions, ending event actions applied immediately starting event,turn reduces future choices planner. show Section 6taking advantage compression-safe actions manner, planner still visitSTPs causally valid permutations events.Table 1 shows comparison average percentage actions regardedcompression-safe new method method used CRIKEY3 POPF, various temporal planning domains. explain information regarding benchmarkdomains problems later Section 6. seen Table 1, compressionmethod detect significantly compressible actions number benchmark domain.4. Encoding Phasesection, explain abstract causal problem associated given temporalproblem encoded SAT formula. classical planning, exist oneway translate particular planning problem corresponding SAT formula. Previousinvestigations field classical planning show choice encoding methodmajor impact efficiency SAT-based planner. mentioned earlier,successful SAT-based classical planners used special encoding methodsbased so-called -step -step semantics valid plans (Rintanen et al., 2006).section, define temporal versions classical -step -step plans.also show exactly semantics used translate given temporal planningproblem SAT formula. introduce -step encoding two different types-step encodings temporal planning. -step first -step encoding methodstemporal versions classical -step -step encodings. Similar classicalversions, new encodings, restrictive simplifying assumptions assumedhold. second type -step encoding, however, obtained relaxing oneassumptions. later show, new -step encoding often requires fewer stepsone. Besides, experimental results show, among new encoding methods,second -step encoding results best performance ITSAT terms speed563fiRankooh & Ghassem-SanidomainzenotravelroversdepotsairportpegsolcrewplanningopenstackselevatorssokobanparcprinterdriverlogfloortilemapanalysermatchcellarparkingrtamsatellitestorageturnandopentmsdriverlogshiftmatchliftCRIKEY31285100010010010010010010010010013961008810010095739895ITSAT1001001009510010010010010010098100969610095989999759895Table 1: Average Percentage Compressed Actionsmemory usage planner. necessary proofs soundness completenessencoding methods also given section.4.1 Parallel Semantics Causally Valid Plansmentioned earlier, classical -step semantics permits parallel executionone action step, validity plan depend executionorder actions. simply guaranteed adding particular clausepair mutually exclusive actions ensure actions includedstep. However, strategy work temporal planning. temporalplanning, temporal constraints imposed starting ending eventsactions, validity particular ordering events certain step, also dependsordering events steps. Nevertheless, ITSAT problemtackled separating causal temporal reasoning phases. general, focusfinding causally valid plans, postpone scheduling phase, mentioned problem,checking feasibility imposing different orderings events step,longer exist. next introduce semantics causally valid -step -step temporalplans.564fiITSAT: Efficient SAT-Based Temporal PlannerDefinition 14 (temporal -steps -steps). Let E = {e1 , ..., en } set events,s1 s2 two temporal states. temporal -step s1 s2one-to-one ordering functions : {1, ..., n} {1, ..., n} (i.e., permutations events),have: s2 = succ(s1 , heO(1) , ..., eO(n) i). temporal -step s1 s2exist least one-to-one ordering function : {1, ..., n} {1, ..., n} (i.e., least onepermutation events), that: s2 = succ(s1 , heO(1) , ..., eO(n) i).Definition 15 (causally valid -step -step plans). Let P = (I, G, A) temporal planning problem. Suppose s0 , ..., sn sequence temporal states s0 = I,G state(sn ), agenda(sn ) = . 1 n, Stepi -step (-step)si1 si , call sequence = hStep1 , ..., Stepn i, causally valid -step (-step)plan P. say hs0 , ..., sn state transition sequence .Classical -step -step encodings (Rintanen et al., 2006) based -step-step semantics classical valid plans, respectively. However, -step encoding,sake improving efficiency planner, following restrictive rulesalso enforced semantics.Rule 1: Instead accepting possible orderings among actions step,fixed arbitrary ordering allowed. result, rule, executionstep necessitates execution actions according fixed ordering.Rule 2: Preconditions actions step must members state immediately step. Similarly, effects actions step mustconsistent state reached immediately step.section, present one -step two -step encodings planning causalabstractions temporal planning. encodings based -step -stepsemantics causally valid plans (Definition 15). considering events, instead actions,rules applied temporal planning, too. first -stepencoding, respect rules, second -step encoding, second restrictive rulerelaxed.fact, second rule imposes serious restrictions applicability actionsstep. instance, prevents proposition produced usedstep plan. Neither allow deletion productionparticular proposition step. relaxing restrictions, encodingcompact, i.e., relaxation permits events occur step. classicalplanning, less relaxed form Rule 2 introduced effects actionsstep used actions step (Wehrle & Rintanen, 2007). Here,however, totally relax Rule 2 allow proposition required, added,deleted many times step.explaining SAT encodings, first define SAT variables auxilary clausescommonly used three encoding methods. Let = hStep1 , ..., Stepn causallyvalid -step (or -step) plan given temporal planning problem P = (I, G, A),hs0 , ..., sn state transition sequence . order encode P SAT formulawhose model translated back , use following SAT variables:565fiRankooh & Ghassem-Saniproposition p, 0 n, define SAT variable pt .Assigning true (f alse) pt implies p (is not) member state(st ).action A, 0 n, define SAT variable .Assigning true (f alse) implies (is not) member agenda(st ).event e e starting ending event action A,1 n, define SAT variable et . Assigning true (f alse) etimplies e (is not) member Stept .SAT formula satisfiable exists model it. model binary functionassigns value true f alse variable formula wayformula satisfied. encoding methods, produced formulamodel , one easily translate corresponding causally valid -step (or -step)plan, using description given variables formula. denoteresulting plan plan(M ). showing correctness particular encoding method,two issues must addressed. First, must show exists causally validplan temporal problem P, encoding P model. callcompleteness encoding method. Second, must show encoding Pmodel , plan(M ) causally valid plan P. called soundnessencoding method.Note here, prove finite-horizon completeness -completenessencodings. words, prove exists -step (or -step) planl steps given problem, problem translated -step (or -step)encoding satisfiable SAT formula l steps, model formulatranslated back . hand, proof -completeness would needvalue l determined. proofs finite-horizon completeness could implied-completeness least upper bound value l determined. Recentresearch field classical planning shown classical planning domains,tight upper bounds length optimal plans determined (Rintanen & Gretton,2013). However, determining upper bounds temporal planning beyond scopecurrent work. find causally valid plan, ITSAT starts encodingone step, sequentially produces tries satisfy formulae increasing numbersteps, satisfiable formula encountered predefined time limitreached.classical SAT-based planning, order produce linear-size encodings -step-step semantics valid plans, special sets clauses, named chains, used(Rintanen et al., 2006). Since also used chains ITSAT, formal definitiontemporal version given here. Let e1 , ..., en arbitrary fixed orderingevents, E R two sets events, k natural number, special symbolassigns unique name chain hand. define chain(e1 , ..., en ; E; R; k; m)conjunction formulae (C-1) (C-3) stated below.(C-1)V{eki bkj,m |i < j, ei E, ej R, {ei+1 , ..., ej1 } R = }(C-2)V{bki,m bkj,m |i < j, {ei , ej } R, {ei+1 , ..., ej1 } R = }566fiITSAT: Efficient SAT-Based Temporal Planner(C-3)V{bki,m eki |ei R}formulae fact encodes message passing strategy. symbol specifiesname message used distinguish SAT variables certain chainchains. number k specifies step whose variables affectedmessage produced. message may produced member E.receivers message members R. bki,m true, means messagereceived i-th event k-th step formula. ei member E, ekitrue, message produced sent ej , first member Rlocated ei fixed ordering. represented chain(e1 , ..., en ; E; R; k; m)clauses form eki bkj,m formula (C-1). message produced,transmitted forward according fixed ordering clauses form bki,m bkj,mformula (C-2). event ei receives message, corresponding SAT variablebef alse clauses form bki,m eki formula (C-3). fact, members Rreceive message certainly excluded final plan.present examples show chains practically used guarantee particular characteristics output plan have.Example 5. Assume e1 , e2 , e3 , e4 four events. Suppose proposition xrequired e1 e4 , deleted e2 , added e3 . Also assume four propositionsp1 , ..., p4 respectively added e1 , ..., e4 . Consider following two cases:Case 1: want prevent proposition x required deletedstep, say k, final plan. purpose, add conjunctionchain(e1 , ..., e4 ; E; R; k; mx1 ) chain(e4 , ..., e1 ; E; R; k; mx2 ) formula, Eset events delete x (i.e., E = {e2 }), R set eventsrequire x (i.e., R = {e1 , e4 }). Note mx1 mx2 two symbols enable usdistinguish SAT variables used two different chains. case,adding chain(e1 , ..., e4 ; E; R; k; mx1 ) add following formulae encodingproblem:ek2 bk4,mx1bk1,mx1bk4,mx1bk1,mx ek11bk4,mx ek41Assume exists model produced SAT encoding(ek2 ) = true. case, since satisfies ek2 bk4,mx , (bk4,mx ) = true.11Consequently, since satisfies bk4,mx ek4 , (ek4 ) = f alse. words,1e2 member step k, e4 cannot member step. Similarly,adding chain(e4 , ..., e1 ; E; R; k; mx2 ) add following formulae encodingproblem:ek2 bk1,mx2567fiRankooh & Ghassem-Sanibk4,mx bk1,mx2bk4,mx22ek4bk1,mx ek12argument similar one given chain(e1 , ..., e4 ; E; R; k; mx1 ) showsadding chain(e4 , ..., e1 ; E; R; k; x2 ), e2 member step k, e1 cannotmember step. result, adding mentioned chains SATformula, execution step k produces p2 , cannot produce p1 p4 .actually occurrence conflicting actions step final planavoided linear-size classical -step encoding (Rintanen et al., 2006).Case 2: allow proposition x required deleted particular stepk deleting event precede requiring event fixed orderinghe1 , e2 , e3 , s4 i. purpose, need add chain(e1 , ..., en ; E; R; k; mx )formula, E R E R case 1. case,execution step k produces p2 , also produce p1 , p4 . strategy, too,initially introduced linear-size classical -step encoding (Rintanen et al.,2006).Note one admits second restrictive rule mentioned above, caseclassical -step -step encodings, proposition added event stepdeleted another event step. result, execution stepk produces p2 , cannot produce p3 cases.4.2 Temporal Versions Classical -step -step Encodingsfirst present temporal versions classical -step -step encodings. Similarclassical forms, temporal versions encodings, assume arbitraryfixed ordering e1 , ..., en events given temporal problem P = (I, G, A).also assume output plan fixed number steps, denoted l.Let = hStep1 , ..., Stepl output plan P, hs0 , ..., sl state transitionsequence . event e, let action(e) member whose startingending event equal e. Let P set propositions P. propositionp P , let Ep = {e|p del(e)}, Ep+ = {e|p add(e)} Rp = {e|p pre(e)} {e|pinv(action(e)) add(e)}. Moreover, assume two dummy events e0 en+1 ,precondition, add effect, delete effect.4.2.1 -step EncodingGiven temporal problem P = (I, G, A), produce SAT-formula l , based-step semantics causally valid plans, P conjunction formulaedescribed below.V(-1) {p0 |p state(I)} {p0 |p/ state(I)}V l(-2) {p |p G}568fiITSAT: Efficient SAT-Based Temporal Planner(-3)V{a0 |a A}(-4)V{al |a A}(-5)V{ek pk1 |0 < k l, p P, e Rp }(-6)V{ek pk |0 < k l, p P, e Ep+ }(-7)V(-9)V(-10)V(-11)V(-12)V{ek ak1 ak |0 < k l, A, e = start(a)}(-13)V{ek ak1 ak |0 < k l, A, e = end(a)}{ek pk |0 < k l, p P, e Ep }VW(-8) {pk1 pk eEp+ ek |0 < k l, p P }{pk1 pkWeEpek |0 < k l, p P }{chain(e1 , ..., en+1 ; Ep ; Rp {en+1 }; k; mp1 )|0 < k l, p P }{(bkn+1,mp ak )|0 < k l, p inv(a)}1{chain(en , ..., e0 ; Ep ; Rp {e0 }; k; mp2 )|0 < k l, p P }{(bk0,mp ak1 )|0 < k l, p inv(a)}2Formula (-1) indicates member state(s0 ) true iff present initial state. Similarly, formula (-2) states members goal state must truestate(sl ). Formulae (-3) (-4) imply agenda(s0 ) agenda(sl ) empty.Formulae (-5) (-7) show event applied step k, preconditions mustpresent state(sk1 ), effects must consistent state(sk ). Formulae (8) (-9) responsible encoding so-called explanatory frame axioms: formula(-8) implies p present step k, must exist leastone event step k p add effects. Similarly, formula (-9) implies ppresent step k, must exist least one event step kdeletes p. Formulae (-10) (-11) added guarantee events stepexecuted possible ordering. Formula (-10) implies p deletedevent ei step k, p cannot required event ej step k j > i.also implies p deleted event step k, action p invariant,cannot member agenda(sk ). Note chain(e1 , ..., en+1 ; Ep ; Rp ; k; mp1 )used formula (-10), value bn+1,mp1 indicates whether p deletedevent step k. reason using dummy event en+1indicator. Analogously, formula (-11) implies p deleted event ei step k,p cannot needed event ej step k j < i. Formula (-11)also implies p deleted event step k, action p invariant,cannot member agenda(sk1 ). Formulae (-12) (-13) responsibleapplying appropriate changes agendas states locatedstep final plan. Formula (-12) implies starting event actionmember step k output plan, must member agenda(sk )agenda(sk1 ). Similarly, formula (-13) implies ending event action569fiRankooh & Ghassem-Sanimember step k plan, must member agenda(sk1 ) agenda(sk ).Theorem 3 (completeness temporal -step encoding). Let P = (I, G, A)solvable temporal planning problem, {e1 , ..., en } set events P, =hStep1 , ..., Stepl causally valid -step plan P. exists model l= plan(M ).Proof. See Appendix A.Theorem 4 (soundness -step encoding). Let P = (I, G, A) temporal planningproblem, {e1 , ..., en } set events P, l -step encoding P.l model , plan(M ) causally valid -step plan P.Proof. See Appendix A.4.2.2 -step Encodingpart, present SAT-formula l , based -step semanticscausally valid plans. considering two restrictive rules stated above, -stepencoding similar -step encoding described previously section. However,two major differences two kinds encoding. First, -stepencoding allows proposition required deleted step, provideddeleting event precede requiring event fixed ordering he1 , ..., sn i.contrast -step encoding, proposition could deletedrequired step final plan. Second, -step encoding,step may also contain starting ending event action. Giventemporal problem P = (I, G, A), produce SAT-formula l , based-step semantics causally valid plans, P conjunction formulae describedbelow.V(-1) {p0 |p state(I)} {p0 |p/ state(I)}V l(-2) {p |p G}V(-3) {a0 |a A}V(-4) {al |a A}V(-5) {ek pk1 |0 < k l, p P, e Rp }V(-6) {ek pk |0 < k l, p P, e Ep+ }V(-7) {ek pk |0 < k l, p P, e Ep }VW(-8) {pk1 pk eEp+ ek |0 < k l, p P }(-9)V{pk1 pkW(-10)V{chain(e1 , ..., en+1 ; Ep ; Rp {en+1 }; k; mp1 )|0 < k l, p P } {(bkn+1,mpeEpek |0 < k l, p P }1ak )|0 < k l, p inv(a)}570fiITSAT: Efficient SAT-Based Temporal Planner(-11)V(-12)V(-13)V(-14)V(-15)V(-16)V(-17)V(-18)V(-19)V(-20)V{eki ak1 |0 < k l, A, ei = start(a), ej = end(a), < j}{eki ak ekj |0 < k l, A, ei = start(a), ej = end(a), < j}{ekj ak |0 < k l, A, ei = start(a), ej = end(a), < j}{ekj ak1 eki |0 < k l, A, ei = start(a), ej = end(a), < j}{eki ak1 ekj |0 < k l, A, ei = start(a), ej = end(a), j < i}{eki ak |0 < k l, A, ei = start(a), ej = end(a), j < i}{ekj ak eki |0 < k l, A, ei = start(a), ej = end(a), j < i}{ekj ak1 |0 < k l, A, ei = start(a), ej = end(a), j < i}{ak1 ak eki |0 < k l, A, ei = start(a)}{ak1 ak ekj |0 < k l, A, ej = end(a)}Note formulae (-1) (-9) exactly formulae (-1) (-9). Similar-step encoding, formulae responsible validity initial state, goalstate, conditions effects events, also explanatory frame axioms explainedbefore. Moreover, notice formula (-10) also present -step encodingformula (-10), formula (-11) present l . results first major differencestated -step encoding -step encoding. Formulae (-11)to (-20)enforce appropriate changes agenda(sk1 ) agenda(sk ), agendasstates immediately step k final plan. According definitions,formulae (-11) (-14) added action property start(a)located end(a) fixed ordering he1 , ..., en i. Formula (-11) ensuresstarted step k, open sk1 . Formula (-12) guaranteesstarted ended step k, must open sk . Formula (-13) ensuresended step k, open sk . Formula (-14) implies endedstarted step k, must open sk1 . Analogously, formulae (-15) (-18)guarantee similar properties action property start(a) locatedend(a) fixed ordering he1 , ..., en i. Formula (-19) ensures memberagenda(sk ) agenda(sk1 ), must started step k. Similarly, formula (-20)ensures member agenda(sk1 ) agenda(sk ), must ended stepk.Since -step encoding conforms two restrictive rules stated earliersection, may exist -step causally valid plan l steps given probleml would unsatisfiable problem. also case linear size step encoding classical planning problems (Rintanen et al., 2006). However, sinceshowed Theorem 3 -step encoding complete, completeness -stepencoding proved showing satisfiability l entails satisfiability l .Theorem 5 (completeness -step encoding). Let P = (I, G, A) solvable temporal planning problem, {e1 , ..., en } set events P, = hStep1 , ..., Steplcausally valid -step plan P. exists model l = plan(M ).571fiRankooh & Ghassem-SaniProof. See Appendix A.Theorem 5 also shows -step encoding, number required stepssolve temporal planning problem less (or equal to) required -stepencoding. words, -step encoding compact -step counterpart.Theorem 6 (soundness -step encoding). Let P = (I, G, A) temporal planningproblem, {e1 , ..., en } set events P, l -step encoding P.l model , plan(M ) causally valid -step plan P.Proof. See Appendix A.4.3 Relaxed -step Encodingmentioned Section 4.2.2, -step encoding allows propositionrequired deleted two events step, deleting eventprecede requiring event fixed ordering he1 , ..., en i. Besides, since formulae (-5)(-6) present -step -step encodings, propositionadded deleted step encodings. restrictions,also present classical -step -step encodings (Rintanen et al., 2006), liftednew relaxed version -step encoding. result, proposition required,added, deleted step many times needed. propertypreviously examined classical -step encoding, consequently, chaining mechanismexplained Section 4.1 compatible it. Here, introduce generalized versionchains explain conceptual difference used classical encodings.also present new kinds chains used specially temporal planning preservinginvariants temporal actions plan produced. Note that, similarnon-relaxed -step encoding, assume events step executedaccording fixed ordering he1 , ..., en i.Let k natural number e1 , ..., en fixed ordering events. reasons discussed later, assume ei starting event action, ei+1ending event action. words, assume ending eventaction located immediately starting event fixed ordering. Note here,demand end action immediately follow start final plan.put constraint fixed ordering. cannot compromise completenessITSAT: SAT solver still choose start action step k, choose whateveractions needed steps k k + arbitrary m, choose endstep k +m. Moreover, suppose two dummy events e0 en+1 ,precondition, add-effect, delete-effect. Let P set propositionsP. proposition p P , let Ep = {e|p del(e)}, Ep+ = {e|p add(e)}, Op = {e|pinv(action(e))} {e0 , en+1 }, Rp = {e|p pre(e)} {e|p inv(action(e)) add(e)}.define chain (e0 , ..., en+1 ; Ep+ ; Ep ; Rp ; k; mp ) conjunction formulae (C -1)(C -8) stated below. Note mp symbol used distinguishing SAT varibalesused formula chain (e0 , ..., en+1 ; Ep+ ; Ep ; Rp ; k; mp ) variables usedformulae.572fiITSAT: Efficient SAT-Based Temporal Planner(C -1)V{eki bkj,mp |i < j, ei Ep+ , ej Rp Ep , {ei+1 , ..., ej1 } (Rp Ep ) = }(C -2)V{eki bkj,mp |i < j, ei Ep , ej Rp Ep+ , {ei+1 , ..., ej1 } (Rp Ep+ ) = }V{bki,mp bkj,mp |i < j, ei Rp (Ep+ Ep ), ej R Ep+ Ep , {ei+1 , ..., ej1 }(Rp Ep+ Ep ) = }V(C -4) {(bki,mp eki ) bkj,mp |i < j, {ei , ej } Rp Ep+ Ep , {ei+1 , ..., ej1 } (Rp Ep+Ep ) = }V(C -5) {(bki,mp eki ) bkj,mp |i < j, {ei , ej } Rp Ep+ Ep , {ei+1 , ..., ej1 } (RpEp+ Ep ) = }V(C -6) {bki,mp eki |ei Rp }(C -3)(C -7) bk0,mp pk1(C -8) bkn+1,mp pkfact, chain (e0 , ..., en+1 ; Ep+ ; Ep ; Rp ; k; mp ) encodes message passing methoddifferent chain(e1 , ..., en ; E; R; k; m). chain (e0 , ..., en+1 ; Ep+ ; Ep ; Rp ; k; mp ),conveyed message fact value proposition p, therefore either truef alse. Similar message passing strategy chain(e1 , ..., en ; E; R; k; m), receivedmessage transferred forward direction fixed ordering e1 , ..., en .event Ep+ , Ep , Rp receives message previous event fixed ordering.Every event may may change value received message. either cases,message passed next event. events Ep+ change valuereceived message true, events p add-effects. Similarly,events Ep change value received message f alse. formulae(C -1) (C -2) impose changes value received message. eventmember Ep+ Ep , neither adds deletes p, thus, pass receivedmessage without altering value. enforced (C -3). (C -4) (C -5) ensurereceived messages passed without changed eventschosen Stepk output plan. According (C -6), event Rp receivesmessage value f alse, event cannot chosen member Stepk .members Rp require p, necessitates received messagesvalue true. (C -7) implies initial value message produced Stepk equalvalue p state immediately execution Stepk . Similarly, (C -8)implies value p state immediately execution Stepkequal final value message Stepk .Example 6. Consider events given Example 5. Let E + set eventsadd x (i.e., E + = {a3 }), E set events delete x (i.e., E = {a2 }),R set events require x (i.e., R = {a1 , a4 }). Moreover, supposetwo dummy events e0 e5 , precondition, add-effect,delete-effect. Assume added chain (e0 , ..., e5 ; E + ; E ; R {e0 , e5 }; k; mx )573fiRankooh & Ghassem-SaniSAT formula. According formulae (C -1) (C -8), chain conjunctionfollowing formulae:ek3 bk4,mpek2 bk3,mpbk0,mp bk1,mpbk1,mp bk2,mpbk4,mp bk5,mpbk0,mp ek0 bk1,mpbk1,mp ek1 bk2,mpbk2,mp ek2 bk3,mpbk3,mp ek3 bk4,mpbk4,mp ek4 bk5,mpbk0,mp ek0 bk1,mpbk1,mp ek1 bk2,mpbk2,mp ek2 bk3,mpbk3,mp ek3 bk4,mpbk4,mp ek4 bk5,mpbk0,mp ek0bk1,mp ek1bk4,mp ek4bk5,mp ek5bk0,mp xk1bk5,mp xk574fiITSAT: Efficient SAT-Based Temporal Plannerstraightforward examination shows model chain mentioned (ek0 ) = (ek1 ) = (ek2 ) = (ek3 ) = (ek4 ) = (ek5 ) = true,(bk0,mp ) = (bk1,mp ) = (bk2,mp ) = (bk4,mp ) = (bk5,mp ) = true, (bk3,mp ) = f alse.words, x deleted e2 Stepk final plan, later producede3 , result, e4 appear Stepk , too. Here, (bk3,mp ) = f alse representsfact x deleted execution e2 . example, four propositionsp1 , p2 , p3 , p4 produced single step final plan. Note neithercases Example 5, producing propositions one step possible.example new -step encoding, employs generalized messagepassing strategy, permit parallelism allowed temporal versionsclassical -step -step encodings.addition chain (e0 , ..., en+1 ; Ep+ ; Ep ; Rp ; k; mp ), responsible trackingvalue p inside Stepk , also need extra formulae prevent p deletedwhenever p invariant open temporal action. Therefore, introduce two newobobchain formulae: chainof (e1 , ..., en+1 ; Ep ; Op ; k; mofp ) chain (e0 , ..., en ; Ep ; Op ; k; mp ).Formula chainof (e1 , ..., en+1 ; Ep ; Op ; k; mofp ) produced conjunction formulae(C -1) (C -4). Similar chains explained before, mofp symbol used distinguish SAT varibales chain formulae.V(Cof -1) {eki bk |i < j, ei Ep , ej Op , {ei+1 , ..., ej1 } Op = }j,mp(Cof -2)V{bk(Cof -3)V{(bkekj ) eki |ei Op , ei = start(a), ej = end(a)}(Cof -4)V{(bkak ) eki |a A, ei = start(a), ei Op }i,mofpbkj,mofpj,mofpn+1,mofp|i < j, {ei , ej } Op , {ei+1 , ..., ej1 } Op = }Similar chain(e1 , ..., en ; Ep ; Rp ; k; mp ), chainof (e1 , ..., en ; Ep ; Op ; k; mofp ) representsmessage produced sent forward direction fixed ordering, wheneverproposition p deleted event. (Cof -1) (Cof -2) responsible productionpropagation mentioned message, respectively. (Cof -3), ending eventaction p invariant receives message step k, step k must alsoinclude starting event a. cases, (Cof -3) prevents open pdeleted. assume fixed ordering, ending eventaction located immediately starting event. (Cof -4) guarantees p deletedsomewhere step k, action p invariant open step k, stepk must also include starting event (otherwise, open everywhere step k,thus, p, invariant a, deleted open).chainof (e1 , ..., en+1 ; Ep ; Op ; k; mofp ), message indicates p deleted sentforward. Thus, cannot help preserving invariants members Opstarted prior deletion p. tackle problem, add another chain,namely chainob (e0 , ..., en ; Ep ; Op ; k; mobp ), formula. chain quite analogouschain (e1 , ..., en+1 ; Ep ; Op ; k; mp ), whenever p deleted event, chain sends575fiRankooh & Ghassem-Sanimessage backward according fixed ordering. chainob (e0 , ..., en ; Ep ; Op ; k; mobp )obobproduced conjunction formulae (C -1) (C -4).(Cob -1)V{eki bkj,mob |j < i, ei Ep , ej Op , {ej+1 , ..., ei1 } Op = }(Cob -2)V{bki,mob bkj,mob |j < i, {ei , ej } Op , {ej+1 , ..., ei1 } Op = }(Cob -3)V{(bki,mob eki ) ekj |ei Op , ei = start(a), ej = end(a)}(Cob -4)V{(bk0,mob ak1 ) ekj |a A, ej = end(a), ej Op }ppppppresent SAT-formula l , represents relaxed -step encodingbased -step semantics causally valid plans. l produced conjunctionformulae described below.V( -1) {p0 |p state(I)} {p0 |p/ state(I)}V( -2) {pl |p G}V( -3) {a0 |a A}V( -4) {al |a A}V( -5) {chain (e0 , e1 , ..., en+1 ; Ep+ ; Ep ; Rp {e0 , en+1 }; k; mp )|0 < k l, p P }( -6)V{chainof (e1 , ..., en+1 ; Ep ; Op ; k; mofp )|0 < k l, p P }( -7)V{chainob (e0 , ..., en ; Ep ; Op ; k; mobp )|0 < k l, p P }( -8)V( -9)V{eki ak1 |0 < k l, A, ei = start(a)}( -10)V{ekj ak |0 < k l, A, ej = end(a)}( -11)V{ekj ak1 eki |0 < k l, A, ei = start(a), ej = end(a)}( -12)V( -13)V{ak1 ak eki |0 < k l, A, ei = start(a)}{eki ak ekj |0 < k l, A, ei = start(a), ej = end(a)}{ak1 ak ekj |0 < k l, A, ej = end(a)}( -1) ensures member state(s0 ) true member presentinitial state. Similarly, ( -2) guarantees members goal state truestate(sl ). ( -3) ( -4) imply agenda(s0 ) agenda(sl ) empty. ( -5),explained before, responsible imposing appropriate changes value SATvariables, whenever proposition p added deleted event certain stepoutput plan. ( -6) ( -7) prevent invariants action deletedopen. ( -8) ( -13) responsible enforcing appropriate changesagenda(sk1 ) agenda(sk ), agendas states immediately576fiITSAT: Efficient SAT-Based Temporal Plannerstep k output plan. ( -8) ensures started step kopen sk1 . ( -9) indicates started ended step k,open sk . ( -10) ensures ended step k, open sk . ( -11)implies ended started step k, open sk1 . ( -12)ensures member agenda(sk ) member agenda(sk1 ),started step k. Similarly, ( -13) ensures member agenda(sk1 )agenda(sk ), ended step k.Theorem 5, know temporal planning problem P satisfiable,exists positive number l, non-relaxed -step encoding P l steps(i.e., l ) satisfiable. Accordingly, completeness relaxed -step encodingproved showing l satisfiable l also satisfiable.Theorem 7 (completeness relaxed -step encoding). Let P = (I, G, A)temporal planning problem formulae l l two -step encodings P explainedabove. model l , l model plan(M ) = plan(M ).Proof. See Appendix A.Theorem 7 also shows that, -step encoding, number required stepssolve temporal planning problem less (or equal to) required -stepencoding, provided fixed ordering used two encodings.words, -step encoding compact -step encoding.Theorem 8 (soundness relaxed -step encoding). Let P = (I, G, A)temporal planning problem, {e1 , ..., en } set events P, l relaxed-step encoding P. l model , plan(M ) causally valid -step planP.Proof. See Appendix A.4.4 Mutual Exclusion Relations Action Compressionmentioned earlier Section 3, performance SAT-based temporal plannerimproved mutual exclusion analysis action compression. section,show information obtained tasks utilized ITSAT. LetP = (I, G, A) temporal planning problem, MU set mutually exclusivepairs propositions P, COM set compression-safe actions P (seeSection 3). Let l encoding P, l , l , l . takingadvantage mutual exclusion relations, add extra formula mutl , mut=llVkk{p q |(p, q) MU , 1 k l}. Theorem 1 shows, two mutually exclusivepropositions p q never true state achieved executionvalid temporal plan starting I. result, adding mutencoding cannotlrender planner incapable finding valid plans.Let compression-safe action. showed Section 3.2, safeassume causally valid plan, ending event occurs immediatelystarting event. One way impose constraint add extra clauses577fiRankooh & Ghassem-Saniencoding guarantee starting ending events always includedstep. However, two events may conflicting effects, case ll allow events present step. Therefore, informationregarding compression-safe actions addedrelexed -step encoding, l .Vdone adding coml , com= {eki eki+1 |a COM, ei = start(a), 1llk l}. Note l , ei starting event action, ei+1 denotes endingevent.5. Scheduling Phasesection, describe causally valid plan augmented temporal informationproduce valid temporal plan. Let = he1 , ..., en causally valid plan producedplanner. scheduling done defining scheduling function Definition9, assigns rational number event execution time. Supposegiven different names different occurrences action plan,events e1 , ..., en unique. assume i, (i) < (i + 1),thereby satisfy first condition Definition 9. However, lead plansunnecessarily large makespans. Alternatively, obtaining plans improved quality,impose relaxed set constraints function .Definition 16 (relaxed scheduling functions). Let causally valid plan.scheduling function relaxed scheduling function following properties:(S-1) j ei located ej , ei swappable ej(cf. Definition 12), require (i) < (j).(S-2) j, ei starting event particular action a, ej pairingevent ei (cf. Definition 8), require (j) = (i) + dur(a).Theorem 9. Let P = (I, G, A) temporal planning problem, = he1 , ..., encausally valid plan P, : {1, ..., n} Q relaxed scheduling function .exists valid temporal plan P.Proof. See Appendix A.Theorem 9 shows whenever relaxed scheduling function exists causally validplan P, valid temporal plan produced P. prove schedulingmethod render ITSAT incomplete, also need show P solvable,planner able produce causally valid plan scheduling functionrelaxed scheduling function . Let (, ) valid temporal planP. Every causally valid plan also regarded causally valid -step plansingleton steps. Therefore, Theorem 3, l model = plan(M ).Theorem 5, also satisfies l . Moreover, Theorem 7, l model= plan(M ) = plan(M ). Therefore, encoding methods usedtranslating P SAT formula, resulting formula model translated. hand, according Definition 9, satisfies constraints form(S-1) (S-2), therefore, relaxed scheduling function . However, mentioned578fiITSAT: Efficient SAT-Based Temporal PlannerSection 4.2.4, may add certain clauses encoding ensure producedcausally valid plan always compressed (Definition 11). show solvable temporal plan, exists compressed causally valid plan scheduledvalid temporal plan relaxed scheduling function.Theorem 10. Let P = (I, G, A) solvable temporal planning problem, COMset every member either compressible towards start compressible towards end (Definition 13). exists valid temporal plan (, ) Pcausally valid plan P, compressed respect COM,relaxed scheduling function .Proof. See Appendix A.check existence function properties stated above, solveinstance Simple Temporal Problem (STP) (Dechter et al., 1991). STP associatedweighted graph named Simple Temporal Network (STN). construct STNnode xi corresponds event ei causally valid plan . Let arbitrarysmall rational number. constraint form (i) < (j), add edgeweight xi xj . constraint form (j) = (i) + dur(a),add edge weight -dur(a) xi xj , another edge weight dur(a)xj xi . also add reference node x0 constructed STN. x0 edgeweight 0 every node. solution STP found computinglength shortest path form x0 nodes (Dechter et al., 1991). Supposeshortest paths exist length shortest x0 xi showndistance(x0 , xi ). event ei , define (i) equal distance(x0 , xi ).case, Theorem 9 guarantees resulting plan specifications validtemporal plan.see intuition behind explained method defining function , suppose constructed STN, edge weight xi xj .means distance(x0 , xj ) distance(x0 , xi ) , implies distance(x0 , xi )distance(x0 , xj ) . This, turn, implies distance(x0 , xi ) < distance(x0 , xj ),(i) < (j). Similarly, easily shown exists edgeweight -dur(a) xi xj , another edge weight dur(a) xj xi ,have: (j) = (i) + dur(a). Bellman-Ford algorithm (Cormen, Leiserson, Rivest,& Stein, 2009) used find single source shortest paths weighted graphpolynomial time. Besides, number nodes produced STN equalnumber events causally valid plan. Therefore, conclude that,mentioned shortest paths exist, (i) computed polynomial time.However, situations shortest paths exist. happenscorresponding STN negative cycle. situations, STP inconsistentconsequently, temporal constraints cannot satisfied time.example case depicted Figure 10.Figure 10, action adds propositions p g starting ending events,respectively. needs proposition q precondition ending event. Action b requiresp upon starting adds q upon ending. Durations actions b, 5 10,respectively. goal planning reaching fact g. problem, = , bs , , ae579fiRankooh & Ghassem-SaniFigure 10. Negative Cyclescausally valid plan, = start(a), ae = end(a), bs = start(b), = end(b).plan depicted Figure 10-(a). plan, execution action b must entirelyinside action (i.e., b started starting ended ending a).However, impossible considering fact duration lessb. invalidity plan caused fact producing causally validplan, durations abstracted out. STN constructed plan Figure10-(a) depicted Figure 10-(b). bs ae negative cycle total weight5 2.5.1 Negative Cycle PreventionSTN causally valid plan includes negative cycle, plan cannot transformedvalid temporal plan. cases, SAT solver forced find differentsolution. done adding extra clause least one eventscurrent negative cycle prevented occurring current step. However,adding blocking clause, planner still produce new plans basicallyequivalent previous plan. instance, consider example given Figure 10.Suppose , bs , , ae members steps 1 4, respectively. Assumeoutput plan 5 steps. forbid exact occurrence negative cycle,580fiITSAT: Efficient SAT-Based Temporal Plannernew causally valid plan still produced shifting ae layer 5 maintainingevents current steps. new solution negative cycletherefore cannot transformed valid temporal plan. fact, causeinvalidity plan changed. show exploiting simple structurenegative cycles, one prevent reoccurrence cycles effectively.discussion given above, clear main reasonnegative cycles encountered STN particular causally valid plan,specific order events plan. fact, events negative cycle reoccurorder new causally valid plan, new plan include negativecycle, too.temporal planning problem P, Pregard set possible sequencesevents language alphabet= {e1 , ..., en }, n numberevents P. set sequences events certain Pevents appearedparticular order also regarded another language . straightforwardshow latter language fact regular language acceptedFinite State Machine (FSM). Figure 10-(c) shows Finite State Machine detectssequences events , ae , bs , appear according order , bs , , ae i.Note that, sake clarity, self-loop transitions Finite State Machineshown Figure 10-(c).PDefinition 17 (FSMs). APFinite State Machine 5-tuple (S , , , xP0 , ),finite set states,finite set alphabet symbols, :mapping defining transitions , x0 starting state, setaccepting states.show adding certain formulae SAT encodings, one avoidmembers given regular languageproduced causally valid plans. LetPP temporal problem,P= {e1 , ..., en } set events P. Let Lregular. Assume L accepted PFinite State MachineP langaue|T (xi , e) = xj , 6= j}= (S , ,P, ). xi , let Ei = {eEiin = {e|T (xj , e) = xi , 6= j}. Assume two dummy events e0en+1 , precondition, add effect, delete effect. define SATvariable xk,i 1 k l, 0 n + 1, x . Assigning value true xk,imeans state x, operating sequence events steps 1k 1 events step k indices less final plan. constructformulal conjunction formulae (-1) (-6) stated below:(-1)Vk,jE {e{eki xk,ixt |1 k l, < j, (xs , ei ) = xt , ej Etn+1 },{ei+1 , ..., ej1 } (Et Et ) = }(-2)V(-3)Vk,j{eki xk,ixs |1 k l, < j, ei Es , ej Es Es {en+1 },{ei+1 , ..., ej1 } (Es Es ) = }k,i{xk,0xs |1 k l, 1 n, xs , ei Es Es ,{e1 , ..., ei1 } (Es Es ) = }581fiRankooh & Ghassem-Sani(-4)V{xk,n+1xk+1,0|1 k < l, xs }(-5)V{xk,i0 |1 k l, 1 n}(-6)V{xk,i |x , 1 k l, 1 n + 1}Addingl encoding problem makes SAT solver somehow simulatebehavior , finding model represents causally valid plan. Assumeobserving ei causes make transition xs xt . Moreover, let ej first eventei (according fixed ordering e1 , ..., en ) may cause transitionxt . Formula (-1) guarantees ei member Stepk , state xstime observing ei , state changed xt , next relevant eventxt (i.e., ej ) become aware transition. (-2) implies ei memberStepk , state xs time observing ei , remain xs ,next relevant event xs become aware current state . (-3) causesinformation regarding state start step propagated firstrelevant event step. (-4) propagates information regarding stateend step next step. (-5) ensures starting stateplace final plan. means simulation startedanywhere plan produced. enables SAT solver detectstrings accepted , also strings subsequences accepted. Finally, (-6) guarantees never one accepting states.Example 7. Let Finite State Machine depicted Figure 10-(c). FiniteState Machine detects sequences events , ae , bs , appear accordingorder , bs , , ae i. Assume four events: e1 = , e2 = ae , e3 = bs ,e4 = . Also assume two dummy events e0 e5 . sake simplicity,suppose problem events e0 e5 , encodingtwo steps. Consider boolean assignment , (e11 ) = (e13 ) = (e14 ) =(e22 ) = true, (e12 ) = f alse. words, choosing , bs ,first step, ae second step. fact, plan(M ) = , bs , , ae i.example, E0in = {e2 }, e2 = ae event causes transitionstate s0 . Similarly, have: E0out = {e1 }, E1in = {e1 }, E1out = {e2 , e3 }, E2in = {e3 },E2out = {e2 , e4 }, E3in = {e4 }, E3out = {e2 }, E4in = {e2 }, E4out = . showuse formulae (-1) (-6) stated encode , cannot modelproduced SAT formula. show contradiction. Assume modelproduced SAT formula.s0 starting state . Hence, according (-5), (s01,1 ) = true,means state s0 , prior checking whether e1 present firststep final plan.1s1,2According (-1), e11 s1,11 . Since (e1 ) = true01,2(s1,10 ) = true, must also (s1 ) = true. words, verifies e1present first step final plan, causes current state582fiITSAT: Efficient SAT-Based Temporal Plannerchanged s0 s1 . (s1,21 ) = true implies state s1 , prior checkingwhether e2 present first step final plan.1,31According (-2), e12 s1,21 s1 . Since (e2 ) = f alse1,31,2(s1 ) = true, must also (s1 ) = true. words, verifiese2 present first step final plan, causes stateremain s1 . (s1,31 ) = true implies state s1 , prior checking whether e3present first step final plan.1According (-1), e13 s1,3s1,412 . Since (e3 ) = true1,41,3(s1 ) = true, must (s2 ) = true. words, verifies e3present first step final plan, causes state changeds1 s2 . (s1,42 ) = true implies state s2 , prior checking whethere4 present first step final plan.1s1,5According (-1), e14 s1,43 . Since (e4 ) = true21,5(s1,42 ) = true, must (s3 ) = true. words, finds e4present first step final plan, causes state changeds2 s3 . (s1,53 ) = true implies state s3 , visiting eventsfirst step final plan.1,52,0According (-4), s1,53 s3 . Since (s3 ) = true, must also(s2,03 ) = true, implies state s3 , prior visiting eventsecond step final plan.2,02,2According (-3), s2,03 s3 . Since (s3 ) = true, must also(s2,23 ) = true, implies state s3 , prior checking whether e2present second step final plan.2s2,5According (-1), e22 s2,24 . Since (e2 ) = true32,5(s2,23 ) = true, must also (s4 ) = true. words, verifiese2 present second step final plan, causes statechanged s3 s4 . (s2,54 ) = true implies state s4 , visitingevents first two steps final plan. hand, s4 acceptingstate . Hence, according (-6), (s2,54 ) = f alse. clearlycontradiction. Therefore, conclude cannot model producedSAT formula.prove addingl encoding given problem, prevents plannerproducing causally valid plans subsequence events equivalentstring accepted . means negative cycle translatedFSM, reoccurrence negative cycle avoided translating FSMSAT formula, adding formula encoding problem.PTheorem 11. Let P = (I, G, A) temporal planning problem,= {e1 , ..., en }set events P, l three formulae l , l , l (defined SectionP 4),non-empty causally valid plan P obtained solving l . Let = (S , , , x0 , )583fiRankooh & Ghassem-SaniFSM accepts subsequence = he1 , ..., em ,l encodingpresented (-1) (-6). exist model ll= plan(M ).Proof. See Appendix A.also need show addingl encoding render planner incapable producing plans contain subsequence accepted .PTheorem 12. Let P = (I, G, A) temporal planning problem,= {e1 , ..., en }set events P, l three formulae l , l , l (definedSection 4). Let model satisfies l , = he1 , ..., em = plan(M ). LetP= (S , , , x0 , ) FSM accept subsequence ,lencoding composed (-1) (-6). exists model l l= plan(M ).Proof. See Appendix A.explain sequence events introduce negative cycle STNcausally valid plan used prevent similar negative cycles reoccurringPfutureplans produced problem hand. Let P temporal planning problem,set events P, = e1 , ..., en causally valid plan P. Assume STNrepresenting scheduling function negative cycle N nodes xi1 , ..., xim . Notexik node corresponding event eik . Without loss generality, assumei1 < ... < im , i.e., events negative cycle ordered orderstarted finished. Let Oik set temporal actions P{e|action(e) Oik } {eik }.reaching eik sequence ei1 , ..., eim , Pik =Consider regular language LN alphabetdefined LN = ei1 i2 ei2 ...im eim ,ik denotes string symbols ik . fact, strings LN , eventsalready present current negative cycle inserted sequenceway temporal constraints among ei1 , ..., eim remain unchanged. seeexclude events open actions ik , consider two hypothetical events eij eijrespectively starting event ending event action a. Therefore,temporal constraint scheduling function form (ij ) (ij ) = dur(a).Here, insert another copy ending event two events,ended execution eij and, result, eij longer pairing eventeij , mentioned constraint longer exist.Theorem 13. Let N = xi1 , ..., xim negative cycle STN correspondingcausally valid plan = e1 , ..., en temporal problem P, xik node corresponding event eik . Let another causally valid plan P. subsequencemember LN (defined above), corresponding STN also Nnegative cycle.Proof. See Appendix A.584fiITSAT: Efficient SAT-Based Temporal PlannerConsrtucting FSM accepts LN straightforward. Let FSM. Theorem13 shows added encoding input problem, ITSAT stillcapable finding valid temporal plan, provided plan exists.6. Empirical Resultssection, show preprocessing, encoding, scheduling methods contribute overall performance ITSAT. Since contribution preprocessingpart investigated encoding fixed, first analyze performancethree encodings explained Section 4. also compare performance ITSATseveral state-of-the-art temporal planners non-numerical temporal planning problemsprevious International Planning Competitions.Section 4, theoretically showed novel relaxed -step encoding leastcompact temporal versions -step -step encodings fixed ordering (i.e.,number steps needed relaxed -step encoding solve given problem lessequal temporal versions -step -step encodings). Here,empirically show relaxed -step often needs significantly smaller number steps,compared -step -step encodings. also show mentioned compactnesscauses relaxed -step significantly outperform -step -step encodingsbenchmark problems terms memory speed.Section 3, explained two preprocessing methods, namely mutual exclusion analysisaction compression. section show methods contributeoverall performance ITSAT benchmark problems. purpose, comparefour versions ITSAT: 1) ITSAT without preprocessing, 2) ITSAT mutual exclusionanalysis, 3) ITSAT action compression, 4) ITSAT mutual exclusionanalysis action compression. experimental results show methodsseparately enhance performance ITSAT.Section 5, discussed adding certain blocking clauses encodingproblem, one prevent negative cycles reoccurring STNs producedcausally valid plans. also introduced elaborate method preventing negative cycles, adding extra clauses based certain Finite State Machines.Here, empirically show FSM-based method crucial efficiency ITSATproblems required concurrency.Finally, compare performance ITSAT state-of-the-art temporal planners, namely OPTIC (Coles et al., 2010), LPG-td (Gerevini et al., 2006),TFD (Eyerich et al., 2009). OPTIC TFD different degrees temporal expressivity, whereas LPG-td temporally expressive (i.e., capable solvingproblems required concurrency). show ITSAT significantly outperformsOPTIC TFD, competitive LPG-td many domains.6.1 Implementation Detailsorder parse planning problems domain, also validating output plansproduced ITSAT, used VAL, plan validation tool developedorganizers IPC 2011. schematic operators given domain instantiatedobjects input problem produce possible valid ground temporal actions. ITSAT585fiRankooh & Ghassem-Saniperforms polynomial reachability analysis recognize actions prepositionsrelevant given problem. purpose, goal conditions initiallyassumed relevant propositions. action produces relevant proposition uponstarting ending considered relevant action. ITSAT adds preconditionsstarting ending events relevant actions current set relevant propositions.invariants relevant actions added set, too. Updating sets relevantpropositions actions repeated changes occur sets.update set relevant propositions omitting relevant propositionspresent initial state given problem. omitted propositionsdeleted relevant action. propositions also omittedat-start, at-end, invariants relevant actions. Mutual exclusion analysis actioncompression methods described Section 3, performed sets relevantactions propositions.mentioned Section 4, encoding methods assume existspredefined fixed ordering events given problem. current implementationITSAT, ordering events produced constructing ground actions,taken presumed fixed ordering events. starting event actionplaced immediately corresponding ending event mentioned ordering.elaborate heuristic methods producing ordering may result compactencoding (Rintanen et al., 2006). Investigating methods beyond scopepaper left future research.current version ITSAT, use P recosat (Biere, 2009), free off-theshelf system, SAT solver. also examined two SAT solvers, namelyinisat (Een & Biere, 2005) Lingeling (Biere, 2013) satisfying formulae.However, precosat best overall performance among three SAT solvers; thoughLingeling better performance terms memory usage.Since P recosat accepts formulae Conjunctive Normal Form (CNF), formulae described throughout paper translated equivalent CNF formulae. performed simply using logical equivalence relations(1 2 1 2 ) ((1 2 ) 1 2 ).problem, start formula one step. set time limitthree minutes precosat find model formula. case failure,add three steps formula repeat process either modelfound predetermined maximum time 30 minutes reached. case successfinding model, causally valid plan extracted model. plangiven scheduling process find valid temporal plan. scheduling functionfails, appropriate FSM generated encoded problem formula (see Section5) without increasing number steps. new formula given P recosatfind new model. Although parallel solving formulae different number stepsshown effective nave sequential approach (Rintanen et al., 2006;Streeter & Smith, 2007), empirical results show even simple sequential methodsufficient outperform current temporal planners many planning domains. leaveinvestigation regarding effect using parallelism future research.experiments explained section conducted 3.1GHz corei5CPU 4GB main memory. benchmark problems, used problem586fiITSAT: Efficient SAT-Based Temporal Plannersets previous IPCs. problems different planning domains includingzenotravel, rovers, depots IPC 2004, airport IPC 2006, pegsol, crewplanning,openstacks, elevators, sokoban, parcprinter IPC 2011, driverlog, f loortile,matchcellar, mapanalyser, parking, rtam, satellite, storage, turnandopen, tmsIPC 2014. Note domains used different IPCs.domains, chosen problem set recent competition domains.problem set IPC 2008 present experiments.Among domains used previous IPCs, matchcellar, turnandopen, tmsinclude problems required concurrency. problem setstemporally expressive planners capable producing valid plans. order achievebetter assessment ITSAT problems required concurrency, used twoextra domains driverlogshift matchlift (Halsey, 2004). also performedexperiments time-window variants satellite airport domains. domains,used IPC 2004 required concurrency, referred throughoutsection satellite-tw airport-tw, respectively. mentioned domainsrequired concurrency explained details Section 6.4.6.2 Impact Different Encoding Methodsevaluate -step, -step, relaxed -step encodings produced three different versions ITSAT, namely, ITSAT-, ITSAT-, ITSAT- , respectively.versions, formula mut , encodes mutex relations, also addedencoding. None versions take advantage action compression. negative cycleprevention method described Section 5 used three versions ITSAT.Table 2 shows comparison domain among versions regard numbersolved problems.seen Table 2, ITSAT- best performance among threeversions. fact, ITSAT- able solve 65 problems ITSAT-,103 problems ITSAT-. Furthermore, almost problems solved ITSAT-ITSAT- also solved ITSAT- . means relaxed -step encodingsignificantly efficient temporal versions classical -step -stepencodings.Table 3, shows detailed comparison among mentioned encodings. different columns Table 3 represent following items: name domain, problemnumber, used encoding method, number steps encoding, resultP recosat terms satisfiability unsatisfiability formula, number clausesvariables divided 1000, amount time taken P recosat determineresult, amount memory needed solving formula. problemencoding method, results presented two cases: unsatisfiable formulahighest number steps, satisfiable formula lowest number steps. Noteproduce results, increased number steps one formulaunsatisfiable. Symbol used time column cases P recosatfailed find model formula 1800 seconds. results presenteddomains least one problems solved least twoplanners. Accordingly, openstacks, elevators, matchcellar, rtam omitted587fiRankooh & Ghassem-Sanidomainzenotravelroversdepotssatellite-twairport-twairportpegsolcrewplanningopenstackselevatorssokobanparcprinterdriverlogfloortilemapanalysermatchcellarparkingrtamsatellitestorageturnandopentmsdriverlogshiftmatchlifttotalproblems202022365050202020202020202020202020202020201014542ITSAT-1318133192020800215010140100001181014208solvedITSAT-1618173212120800316216190100392181014246ITSAT-162019321382020902173201918100392181014311Table 2: Overall Comparison Different Encoding MethodsTable 3. Moreover, satellite storage, results presented-step -step encodings.domain, Table 3 presents results hardest problem (i.e.,problem greatest number propositions). experiments, observedpattern similar chosen problems problems domain. Noteresults presented Table 3 finding first causally valid plan. Therefore,results include information regarding FSM encoding method describedSection 5. explain impact FSM-based negative cycle prevention latersection.588fiITSAT: Efficient SAT-Based Temporal Plannerdomainzenotravelroversdepotssatellite-twairport-twairportprob encoding steps1041331154262518227263106173117412123513136723319773348703120571326Continued next pageresultFFFFFFFFFFFFFFFFFF589C1000V100047413369521167925467444437556734618511795032561008874738021336332673628854151811243557318172709261318943093923290506136332315042325604121558142824125945523613875343269731083151641244154143949138136137140137344time(s)250.40.38330.540.560.1489470.366.62.21.398.932.11.21.40.10.70.70.1243.70.43194.10.5273.50.16214.30.62mem(MB)131181014620174132441235322012598284129100130114132144191227122900283288372573184426336fiRankooh & Ghassem-Sanidomainprob encoding steps1212pegsol205131366969crewplanning 84707051913sokoban46201474231parcprinter208433297driverlog25862211floortile10623127179mapanalyser 152Continued next pageresultFFFFFFFFFFFFFFFFFFFF590C1000V1000342510372712112102311410435422741225712951422325143634523801482385263428035248329120174312118036187009101893299889631074342913530114364371506943382198513912055825818429422121116221271005534122time(s)0.0522.47.30.3030150123.974401.5301.193250.76.2142313.95570.14200.620.1618105.4mem(MB)282611411340491444611637823190125203191192428912826165702801314816549135119651975fiITSAT: Efficient SAT-Based Temporal Plannertimedomainprob encoding steps result(s)18197433 10642610112123 593113400621816.74F17691502.52F605750.5parking111F238380.4518681874.239111122.5247075211F870221satellite35F294911295024415763521104.911F1523125storage98F63384481216621365.99710949.442F241620322F94410633turnandopen 110F371531.1432474207176239871113711406581.39F491512.37F257390.5tms183F91180.110546561.48284430.54115230.318F373651.515F235370driverlogshift 119F5417019411690.616260390.31057200.3Table 3: Detailed Comparison Encoding MethodsC1000591V1000mem(MB)1177538128177703429787724319144095198691497245411241465106426542146742173519739219fiRankooh & Ghassem-SaniFigure 11. Speed Comparison ITSAT- ITSAT-Section 4, theoretically showed order solve given planning problem,relaxed -step encoding requires fewer steps temporal versions classical-step -step encodings ordering fixed. Table 3 shows ITSAT-often needs considerably smaller number steps. phenomenon prominentairport, crewplanning, mapanalyser. Moreover, openstacks matchcellar,neither ITSAT- ITSAT- able solve problem due large numbersteps required. suggests correlation performanceplanner, compactness encoding. Generally speaking, relativelyhigh number steps needed -step encoding solve problem, deducestrong causal connection actions produced plan.hand, -step encoding devised take advantage causal connections.Therefore, -step encoding expected advantage -step encodingdomains. phenomenon visible airport, crewplanning, openstacks,matchcellar domains, numbers steps required -step encodingdomains exceptionally high. Table 3 also shows relaxed -step encoding resultssignificant improvement planner terms memory usage.592fiITSAT: Efficient SAT-Based Temporal PlannerFigure 12. Speed Comparison ITSAT- ITSAT-also compared speed ITSAT- ITSAT- ITSAT-solving benchmark problems. results depicted Figure 11 Figure 12.seen, ITSAT- outperformed ITSAT- ITSAT- almostproblems.6.3 Impact Mutual Exclusion Analysis Action CompressionSection 3, explained mutual exclusion analysis action compression performed preprocessing components ITSAT. Here, empirically show components quite effective enhancing performance planner. showedbefore, encoding results best performance ITSAT. fixedformula base comparison, produced three formulae investigateimpact preprocessing method. three formulae mut (the base encoding plus mutual exclusion information), com (the base encoding plus actioncompression information), mut com (the base encoding plus mutual exclusion action compression information). Table 4 shows number problems solvedmentioned versions ITSAT.593fiRankooh & Ghassem-Sanidomainzenotravelroversdepotssatellite-twairport-twairportpegsolcrewplanningopenstackselevatorssokobanparcprinterdriverlogfloortilemapanalysermatchcellarparkingrtamsatellitestorageturnandpentmsdriverlogshiftmatchlifttotalproblems20202236505020202020202020202020202020202020101454213201132138202010117031403000201014211mut162019321382020902173201918100392181014311com14201432138202050319120192070003181014289mut com182020321392020130820420202017016209181014370Table 4: Impact Mutual Exclusion Analysis Action Compressionseen Table 4, preprocessing methods result significant improvement terms overall coverage. fact, version ITSAT uses methodssolves 159 problems base planner. Besides, version uses methods even considerably outperforms two versions use one preprocessingmethod. suggest preprocessing components necessary producingbest performance ITSAT.investigate effectiveness action compression method domainsITSAT compresses considerably actions CRIKEY, performed anotherexperiment. compressed actions ITSAT considers compression safeCRIKEY3 not. new version ITSAT, also used mutual exclusioninformation. version ITSAT solves six problems version594fiITSAT: Efficient SAT-Based Temporal Plannermutual exclusion information used: six problems, four problemszenotravel, one airport, one mapanalyser. results changemuch domains. Note three mentioned domains ITSATcompresses considerably actions CRIKEY.6.4 Impact FSM-Based Negative Cycle Detectionmentioned earlier, among domains used evaluate ITSAT, matchcellar, turnandopen, tms, driverlogshift, matchlift, time-window versions airport satelliteproblems required concurrency. fact, domains, may impossibleschedule causally valid plan produced solving SAT formula, valid temporalplan. Here, briefly explain problems domains may require concurrency, may introduce negative cycles STN associatedcausally valid plan.matchcellar matchlift, exists action lighting match. actionproduces light certain amount time. objective mend fuses.actions mending fuse executed light. result, actionslighting match mending fuse must executed concurrent. However, causallyvalid plan, since planner consider durations actions, may assumematch remain lit fuses mended. discussed Section 5,introduce negative cycle STN produced causally valid plan.tms, objective produce certain number ceramic structures.structures need several preparations done furnace producingheat. clear domain similar matchcellar matchlift,requires concurrency similar way.simplified version driverlogshift introduced Section 2. differencesimplified version one used section evaluate planners,here, drivers walk to, board, disembark trucks. Furthermore,REST WORK actions performed drivers rather trucks. domain,working shifts drivers analogous action lighting matchmatchcellar domain.turnandopen, exists robot needs move number rooms.doors pair adjacent rooms. doors, closedinitial state, opened robot. robot open doorturning doorknob. domain, actions turning doorknob openingdoor must executed concurrently. However, duration action turningknob 3, whereas opening door 2. enables ITSAT schedule everycausally valid plan valid temporal plan. Therefore, preventing negative cyclesnecessary domain.time-window versions airport satellite, specific timegoals must obtained. deadline introduced problem using specificframe action duration equal time deadline. actionsexecuted frame action executed. words, actionsmust concurrent frame action. However, causally valid plan, sinceplanner consider durations actions, may assume frame action595fiRankooh & Ghassem-Sanidomainproblemsatellite-tw3airport-tw21matchcellar20tms18driverlogshift10matchlift14restarts1211343439C100012552441216872FSM1450540812930180V100036522232615FSM318220310280112memory (MB)FSM1382411977162131073198Table 5: Collective Size SAT Encodings FSMsarbitrarily long, thereby neglect meet deadline achieving goals.introduce negative cycles STNs produced causally valid plans.explained Section 5, STN causally valid plan includes negativecycle, must force SAT solver find different solution. done simplyadding extra blocking clause current SAT formula prevent least oneevents negative cycle reoccurring current step. Alternatively,introduced elaborate method thing, adding encodingcertain FSMs encoding. method, STN causally valid plank steps includes negative cycle, FSM detects negative cycle encodedSAT formula, solver restarted. order decrease numberrestarts, whenever sequence events corresponding negative cycle found, ITSATtries find potential negative cycles replacing actions current sequenceactions problem checking STN resulting sequence negativecycles.Table 5 shows collective size SAT encodings FSMs required solvingproblems domains. base encoding, used relaxed-step encoding mutual exclusion analysis action compression.domain, results shown Table 5 hardest problem solved ITSAT.turnandopen domain excluded Table 5, negative cycle encounteredsolving problems domain. different columns Table 5 representfollowing items: name domain, problem number, number clausesvariables divided 1000, amount memory needed produce formula.results number causes, number variables, used memory presentedseparated columns base encoding encoding FSMs.seen Table 5, negative cycle prevention method helps ITSAT solveconsiderable number problems required concurrency. Nevertheless, SAT encoding required FSMs significantly larger base encoding domainsnumber restarts relatively high. hand, numberrestarts increase, speed ITSAT declines. restart, SATsolver must verify satisfiability formula, scratch. fact, numerousrestarts main reason poor performance ITSAT time-window versionsatellite.596fiITSAT: Efficient SAT-Based Temporal Planner6.5 ITSAT Versus State-of-the-art Temporal Plannerscompare ITSAT three efficient temporal planners, namely, OPTIC (Benton,Coles, & Coles, 2012), TFD (Eyerich et al., 2009), LPG-td (Gerevini et al., 2006).similarities approach used ITSAT SCP2 (Luet al., 2013), also included results planner experimental results.OPTIC newest version POPF (Coles et al., 2010). heuristic state-spacetemporal planner based so-called temporally-lifted progression planning (Cushinget al., 2007). Using approach planning enables OPTIC solve problemsrequired concurrency. Besides, OPTIC handles self-overlapping actions, makesexpressive ITSAT. Although handling self-overlapping actions hardly necessarysolving non-numerical temporal planning problems (Fox & Long, 2007), amongcurrent benchmark domains, zenotravel, rovers, airport permit actions duemodeling errors. fair comparison ITSAT OPTIC, usedcorrected versions three domains1 evaluations. guiding search, OPTICbenefits heuristic function based relaxed planning graph (Hoffmann& Nebel, 2001).TFD another heuristic state-space temporal planner. TFD based so-calleddecision epoch planning (Cushing et al., 2007). planners use approachtemporally expressive planners based temporally lifted progression planning. words, theory, temporal planning problems definedPDDL2.1 solved ITSAT OPTIC TFD. However, current benchmark problems potentially solved using decision epoch planning.guiding search, TFD benefits temporal version so-called Context-enhancedAdditive Heuristic (Helmert & Geffner, 2008).LPG-td fast temporal planner, temporally expressive. fact,LPG-td first generates sequential plan given problem, tries rescheduleplan produce one improved quality. renders LPG-td incapablesolving problem matchcellar, turnandopen, tms, driverlogshift, matchlift. SimilarOPTIC, LPG-td benefits heuristic based relaxed planning graph. However,instead searching state space problem, LPG-td performs search makinglocal improvements structure similar partial plans, called LinearAction Graph. Two different configurations LPG-td used based whetherprefer speed planner quality produced plans. Here, presentresults quality configuration LPG-td, produced better results speedconfiguration experiments.SCP2 (Lu et al., 2013), SAT-based temporal planner uses discrete representation time. planner assigns explicit discrete time labels step encoding.approach, step exactly one time unit ahead step + 1. result,action duration starts step i, forced end step + d. meansnumber layers required producing plan greater equal makespan. SPC2 starts formula one step, increases number stepsone, every time formula unsatisfiable. enables SPC2 find optimal plan1. corrected version mentioned domains downloaded official website POPFplanner.597fiRankooh & Ghassem-Saninumber given problems. obtain better performance, SCP2 uses -step semanticallow causal relations actions time point.compared ITSAT planners based number problemssolve domain also total score given planner usingscoring strategy recent IPCs; is, planner cannot solve problem, getscore 0 problem; Otherwise, score equal makespan bestproduced plan divided makespan plan found planner. resultspresented Table 6.seen Table 6, ITSAT significantly outperforms OPTIC, TFD, SCP2.fact, ITSAT solves 162 problems OPTIC, 145 problems TFD,282 problems SCP2. ITSAT also solves 64 problems LPG-td. However,mainly LPG-td incapable solving problems required concurrency.exclude satellite-tw, airport-tw, matchcellar, turnandopen, tms, driverlogshift,matchlift domains LPG-td cannot solve problem, ITSAT solves31 problems less LPG-td. shows ITSAT quite competitiveLPG-td even solving problems without required concurrency.shown Table 6, OPTIC solves zero problems parcprinter, driverlog, floortile,mapanalyser, matchcellar, rtam, storage, tms. domains, main reasonpoor performance OPTIC runs memory, early search. TFDsolves zero problems satellite-tw, airport-tw, parcprinter, driverlog, floortile, rtam, storage,tms. Except parcprinter, TFD runs memory, domainsTFD performs poorly unable find plan within 1800 seconds.mentioned before, LPG-td solves zero problems domains required concurrency.performance SCP2 rather poor many benchmark domains. reasonpoor performance SCP2 that, many benchmark problems, makespanoptimal plan relatively large. result, problems, SCP2 unablecheck satisfiability formulae numbers steps less makespanoptimal plan, within 1800 seconds time limit.compare quality plans produced ITSAT competingplanners, consider Table 7. numbers presented Table 7 average makespanratio plans mutually solved corresponding planner ITSAT correspondingdomain. Ratios less one indicate better average quality solutions producedITSAT comparison competing planners. cases neither ITSATcompeting planner able solve problem domain, correspondingcell Table 7 remained blank.also performed experiments based number two planners portfoliosdifferent pairs planners. portfolios enabled us combine advantagestwo planners. this, 30 minutes time limit divided equally pairplanners. results running portfolios presented Table 8. resultsshow best configuration obtained combining ITSAT LPG-td.resulting planner capable solving 423 542 benchmark problems. Moreover,planners produced best results combined ITSAT.598fiITSAT: Efficient SAT-Based Temporal PlannersolveddomainNzenotravel2018rovers20depotsITSATOPTICSCP2IPCscoreITSATOPTICTFDLPG-tdSCP2TFDLPG-td121220111.4110.5611.3217.68120202020418.2518.3518.5616.8842220752169.524.213.0419.436satellite-tw363400034000airport-tw50217000217000airport5039242043035.223.3518.1139.680pegsol20201918202019.3618.0217.2418.9820crewplanning202020149018.372011.947.820openstacks201320202007.2617.0119.8315.230elevators20013900137.440sokoban20823517.641.7233.261parcprinter2020007020005.720driverlog204001403.890013.380floortile202000201017.050016.5110mapanalyser202001920018.48015.6214.810matchcellar202020200020201600parking201716202065.0513.9818.7219.026rtam20000200000200satellite20164132002.613.557.05200storage202000182018.77001.4520turnandopen2099180196.5213.3401tms20180000180000driverlogshift1010106098.019.485.0309matchlift14141314013141314013total542 37020822530688305.87 191.75 195.8Table 6: ITSAT Versus State-of-the-art Temporal Planners599256.29 88fiRankooh & Ghassem-Sanidomainzenotravelroversdepotssatellite-twairport-twairportpegsolcrewplanningopenstackselevatorssokobanparcprinterdriverlogfloortilemapanalysermatchcellarparkingrtamsatellitestorageturnandopentmsdriverlogshiftmatchliftOPTICTFDLPG-tdSCP21.470.991.24111.060.981.111.340.8612.946.720.721.1411.501.031.410.950.980.891.901.180.860.802.984.450.480.9811.410.892.020.910.960.881.310.690.811.030.970.793.017.350.1111.272.111.0211.053.151.0511.191Table 7: Average Makespan RatioITSATOPTICTFDLPG-tdSCP2ITSAT375385423348OPTIC375262350237TFD385262360256Table 8: 2-planners Portfolio600LPG-td423350360302SCP2348237256302fiITSAT: Efficient SAT-Based Temporal PlannerFigure 13. Speed Comparison ITSAT OPTICAlthough ITSAT quite competitive state-of-the-art temporal planners,empirical results reveal drawbacks planner. compared speedITSAT OPTIC, TFD, LPG-td, SCP2 benchmark problems.results presented Figure 13, Figure 14, Figure 15, Figure 16, respectively.figures, results required concurrency domains separateddomains using different symbols scatterplots: star symbolrepresents problems required concurrency, diamond symbol representsproblems. seen, ITSAT slower OPTIC, TFD, LPG-tdnumber benchmark problems. major cause drawback ITSAT,SAT solver spends much time refuting several formulae finally findfirst satisfiable formula. shown case classical planning, speedSAT-based planners significantly improved checking satisfiability severalformulae different number steps parallel. discuss detail Section7 future research.Another observation that, ITSAT performs rather slowly solving numberproblems required concurrency quickly solved OPTIC TFD.mainly due restarting SAT solver whenever negative cycles encountered.601fiRankooh & Ghassem-SaniFigure 14. Speed Comparison ITSAT TFDexplained earlier, STN causally valid plan k steps includes negativecycle, FSM detecting negative cycle encoded SAT formula,solver try satisfy new formula k steps, scratch. domainsnegative cycles abundant, performance ITSAT significantly affectednumerous restarts SAT solver.performance ITSAT particularly poor three domains, namely elevators,driverlog, rtam. domains, number ground actions higherdomains. linear increase number ground actions may causeexponential growth size search space problem. tackle problem,state-space based planners take advantage heuristic functions devised speciallypruning search space planning problems. also shown using SATsolvers tailored solving planning problems result significant improvementperformance SAT-based classical planning (Rintanen, 2012). think employingidea also improve speed ITSAT mentioned domains.Another drawback ITSAT poor quality produced plans benchmarkdomains. notably, although ITSAT solves problems depots, openstacks,parking, satellite, quality plans rather low domains, according602fiITSAT: Efficient SAT-Based Temporal PlannerFigure 15. Speed Comparison ITSAT LPG-tdTable 7. mainly due fact ITSAT abstracts duration actions,thus, SAT solver lacks competency evaluating quality plansproduced. Nevertheless, quality plans produced ITSAT generallycomparable planners benchmark domains. Section 7, explainidea improving quality plans produced ITSAT.7. Conclusions Future Researchpaper, described ITSAT, temporally expressive SAT-based planner. ITSATbased approach takes advantage parallel encodings. approach, first,durations actions given problem abstracted out. abstract problemencoded SAT formula using -step -step semantics causally valid plans.generating causally valid plan, ITSAT performs scheduling process.process, ITSAT tries satisfy temporal constraints imposed consideringdurations actions. done solving Simple Temporal Problem (STP).cases inconsistent STP, cause, negative cycle correspondingSimple Temporal Network (STN), detected. ITSAT adds certain clauses SATformula hand prevent reoccurrence negative cycles. process603fiRankooh & Ghassem-SaniFigure 16. Speed Comparison ITSAT SCP2repeated temporally valid plan produced, predefined time limitreached.main contributions paper summarized follows:introduced novel method detect temporal actions compressedclassical ones. new compression technique performed preprocessing taskthus independent planning algorithm usedtemporal planner. makes compression technique generalPOPF, specifically tailored planner. empirical results showedaction compression results improved performance ITSAT. alsoempirically showed method capable detecting compression-safetemporal actions previous action compression method, used POPF.introduced three new encoding methods based concept parallel plansSAT-based temporal planning. two methods adoptedclassical planning, third method, produces compact formulae,employed ITSAT first time. empirical results show newencoding significantly enhance performance SAT-based temporal planning.604fiITSAT: Efficient SAT-Based Temporal Plannerintroduced method avoid producing plans members givenregular language set events. done embedding SATencoding particular FSM accepts language SAT encodinginput problem. used method preventing temporal inconsistenciesproduced causally valid plans reoccurring subsequent causally validplans. experiments showed method contributed considerablyperformance ITSAT current benchmark problems required concurrency.According empirical results, taking advantage new approaches,ITSAT outperform state-of-the-art temporally expressive planners, alsocompetitive efficient temporal planners handle required concurrency. Nevertheless, believe performance ITSAT improved severalways, discussed below.current version ITSAT, satisfiability formulae different numbersteps checked sequential manner, starting formula encoding one step.means SAT solver refute several formulae finds first satisfiableformula. time required checking satisfiability formulae increasednumber steps, policy would result best performance ITSAT. However,almost never case. shown case classical planning, fixedplanning problem, time needed finding model satisfiable formula usuallyconsiderably less time needed refuting unsatisfiable formula (Rintanen et al.,2006). Based experiments, phenomenon happens case temporalplanning, too. Similar SAT-based classical planning, one take advantagephenomenon checking satisfiability formulae different numbers stepsparallel. applicability parallelisms sensistive amountmemory required saving formulae. shown Section 6, newlyintroduced -step encoding considerably efficient temporal versionclassical -step encoding terms memory usage. suggests -stepencoding suitable employing parallelism.linear sized classical -step -step encodings, encoding methods,assume exists predefined fixed ordering events given problem.ordering great impact number steps needed solving inputproblem. example, consider sequential plan ground action appliedonce. potential plan subsequence mentioned fixed ordering,one step sufficient finding plan. hand, case reversedfixed ordering, number steps would required find model mightlarge size plan itself. current implementation ITSAT, orderingevents produced constructing ground actions, taken predefinedfixed ordering events. However, considering causal relationships among actionsgiven problem, one might able find effective orderings would resultfewer steps solving problem. believe enhancement would resultimproved version ITSAT, efficient terms speedmemory usage.current version ITSAT uses off-the-shelf general-purpose SAT solvers.means advancement designing solvers also improve performanceITSAT. Recent investigations field SAT-based classical planning shown605fiRankooh & Ghassem-Sanidesigning SAT solver tailored solving planning problems result much improvedperformance SAT-based planners. particular, efficient SAT-based classicalplanner, Mp (Rintanen, 2012), able competitive sate-of-the-artstate-space based planners employing idea. Since causal structures temporalplanning problems generally similar classical planning problems,believe ITSAT benefit enormously employing planning-oriented SAT solver.mentioned Section 6, one main drawbacks ITSAT poor qualityproduced plans benchmark domains. mainly due factITSAT abstracts duration actions, thus, SAT solverneeded resources evaluating quality plans produced. Alternatively, one add explicit representation time encoding (Shin & Davis,2005). done using SMT solvers (Armando & Giunchiglia, 1993), handle continuous variables. However, discussed Section 1, solution may resultconsiderably slower search. think ITSAT benefit combinationtwo approaches: first plan produced ITSAT, proceedintroducing appropriate numerical constraint SAT formula hand, useSMT solver produce improved plans. subject ongoing research.Finally, mention components ITSAT, also usedfields AI planning. notably, -step encoding also employedSAT-based classical planning. empirical results show encoding methodquite effective reducing number steps needed produce valid plans severaltemporal planning domains also classical version. think improvedperformance -step encoding comparison -step encoding achievedclassical planning, too. Moreover, Section 5, showed prevent membersgiven regular language events input problem producedoutput plan. used method prevent ITSAT producing temporally invalidplans. method employed enforce variety constraints planproduced. example, consider case require certain actionsexecuted specific order. must clear set plans violatingconstraint regarded regular language set actions. Therefore,constraint introduced encoding problem methoddiscussed Section 5.Acknowledgmentsauthors would like thank handling editor, Jorg Hoffmann, anonymousreviewers invaluable contributions quality paper.Appendix A. ProofsTheorem 1. Let P = (I, G, A) temporal planning problem P c = (state(I), G, Ac )causal abstraction P. Assume = he1 , ..., en sequence eventsapplicable I, sn = succ(I, ). following conditions must hold:two propositions p q members state(sn ), p q non-mutexlayer n planning graph P c .606fiITSAT: Efficient SAT-Based Temporal Plannerproposition p member state(sn ), action member agenda(sn ),p opena non-mutex layer n planning graph P c .Proof. give proof induction n (the length ). n = 0, i.e.,event applied I, conclusions obviously hold every member state(I)present first layer graph, mutex first layer,agenda(I) = Definition 6. suppose conclusions hold n = k 1. showalso hold n = k. Assume = he1 , ..., ek sequence eventsapplicable I, sk = succ(I, ), sk1 = succ(I, he1 , ..., ek1 i).Let p q two members state(sk ). three possible cases:Case 1: p q members sk1 , induction hypothesis, pq non-mutex layer k 1 planning graph P c thus noopp noopqnon-mutex layer k 1. Hence, p q mutex layer k.Case 2: neither p q members state(sk ), Definition 5, p qmust members add(ek ). Assume ek ending event action(the case ek starting event analogous thus omitted here).Since ek applicable state sk1 , Definition 4, members pre(ek ) mustalso members state(sk1 ), must member agenda(sk1 ). Therefore,induction hypothesis, members pre(ae ) non-mutex layer k 1.result, p q, based Definition 10 added ae , non-mutexlayer k.Case 3: p member state(sk1 ), Definition 5, q must memberadd(ek ), p cannot member del(ek ). Assume ek ending eventaction (again, case ek starting event analogous thusomitted here). induction hypothesis, members pre(ae ) non-mutexlayer k 1, Definition 10, ae delete p. Therefore, ae presentlayer k 1 cannot mutex noopp . result, p q non-mutexlayer k.Let p member state(sk ), action member agenda(sk ).two possible cases:Case 1: also member agenda(sk1 ), started yet endedreaching sk1 , invariants members state(sk1 ).induction hypothesis, invariants must non-mutex layer k 1. Hence, aipresent layer k 1. Definition 10, ai adds opena . Now, must show padded action mutex ai layer k 1. p memberstate(sk1 ), induction hypothesis, p present layer k 1. Therefore,noopp , mutex ai , applicable layer k 1 and, result, popena mutex layer k. hand, p memberstate(sk1 ), must added ek . Since ek applicable sk1 memberagenda(sk1 ), Definition 4, ek cannot delete invariant a. Assume ekending event action b (the case ek starting event b analogousthus omitted here). induction hypothesis, , mutex607fiRankooh & Ghassem-Saniai must applicable layer k 1. means p opena mutexlayer k.Case 2: member agenda(sk1 ), Definition 5, ek muststarting event a, delete p. Moreover, Definition 4, startinginvariants must present state(sk1 ). Therefore, induction hypothesis,applicable layer k 1. p present state(sk1 ), must addedek . Definition 10, propositions added starting event alsoadded . Since also adds opena , p opena cannot mutex layer k.hand, p member state(sk1 ), induction hypothesis,p present layer k 1. Therefore, noopp , mutex , applicablelayer k 1. means p opena mutex layer k.Theorem 2. Let P = (I, G, A) solvable temporal planning problem. Let setevery member either compressible towards start compressible towardsend. compression-safe P.Proof. Let 0 causally valid plan P (Such plan must exist P solvable).Starting 0 , produce sequence causally valid plans swapping eventsnext plan hand. Assume arbitrary order ha1 , ...,members . Without loss generality, assume action repeated0 (otherwise, different names given different occurrences actioneliminate repetition). producing causally valid plan , considercausally valid plan i1 . ai compressible towards start, keep swapping endingevent ai previous event i1 previous event becomes startingevent ai . fact, swaps collectively cause ai become compressed towardsstart. swaps never falsify causally valid plan hand: assumee event immediately prior ending event ai causally valid plan, estarting event ai . precondition effect e must presentleast one state whose agenda includes ai . Thus, Theorem 1, preconditioneffect e mutex openai last layer levelled-off planning graphcausal abstraction P. Definition 13, e must swappable endingevent ai . Therefore, causally valid plan starting ending eventsai located next other. Similarly, ai compressible towards end, keepswapping starting event ai next event i1 next event becomesending event ai . result, n , ending event members locatednext corresponding starting events, therefore, according Definition 11,compression-safe P.Lemma 1. Let = {e1 , ..., en } set events, E R, two subsets S. Assumesubset ei E, ej/ R j > i. Letfunction defined following rules assigns value true f alseSAT variable chain(e1 , ..., en ; E; R; k; m):608fiITSAT: Efficient SAT-Based Temporal Planneri, (eki ) = true ei member .i, (bki,m ) = true ej E j < i.satisfies chain(e1 , ..., en ; E; R; k; m).Proof. show satisfies formulae (C-1) (C-3), therefore satisfieschain(e1 , ..., en ; E; R; k; m)./(C-1) Consider arbitrary formula eki bkj,m formula (C-1). ei(eki ) = f alse, thus formula trivially satisfied. consider caseei . definition formula (C-1), know < j ei E.Therefore, according definition , must (bkj,m ) = true, thusformula satisfied.(C-2) Consider arbitrary formula bki,m bkj,m formula (C-2). (bki,m ) =f alse, formula trivially satisfied. hand, (bki,m ) = true,must exist l, l < el E. Since < j, mustl < j, therefore, (bkj,m ) = true, hence formula satisfied.(C-3) Consider arbitrary formula bki,m eki formula (C-3). (bki,m ) =f alse, formula trivially satisfied. hand, (bki,m ) = true,must exist l, l < el E. accordingproperties , must ei/ R. However, definitionchain(e1 , ..., en ; E; R; t; m), ei R and, result, ei/ . Therefore,k(ei ) = f alse formula satisfied.Lemma 2. Let = {e1 , ..., en } set events, E R two subsets S. Assumemodel chain(e1 , ..., en ; E; R; k; m). ei E (eki ) = true,j > ej R, (bkj,m ) = true, consequently (ekj ) = f alse.Proof. Suppose sequence e1 , ..., en , event ej first event eiej R. Since formula (C-1) chain(e1 , ..., en ; E; R; k; m), eki bkj,m ,(bkj,m ) = true. Similarly, sequence e1 , ..., en , event ej first event ejej R, must formula bkj,m bkj ,m (C-2), implies(bkj ,m ) = true. repeating argument latter case, inferj > ej R, (bkj,m ) = true, according (C-3),(ekj ) = f alse.Theorem 3 (completeness temporal -step encoding). Let P = (I, G, A)solvable temporal planning problem, {e1 , ..., en } set events P, =hStep1 , ..., Stepl causally valid -step plan P. exists model l= plan(M ).609fiRankooh & Ghassem-SaniProof. construct function assigns true f alse SAT variablesformula l . Let hs0 , ..., sl state transition sequence . definedfollowing rules:proposition p, k 0 k l, (pk ) = true iff pmember state(sk ).action A, k 0 k l, (ak ) = true iff memberagenda(sk ).1 n, k 1 k l, (eki ) = trueiff ei member Stepk . Moreover, k 1 k l, (ek0 ) =(ekn+1 ) = f alse.proposition p, 0 n + 1, k 0 k l,(bki,mp ) = true iff exists event ej , j < i, ej Ep , ej Stepk .1proposition p, 0 n + 1, k 0 k l,(bki,mp ) = true iff exists event ej , j > i, ej Ep , ej Stepk .2show satisfies formulae (-1) (-13), therefore model l . Noteway constructed, directly = plan(M ).(-1) According Definition 15, s0 = I, thus formula (-1) clearly satisfied.(-2) According Definition 15, G state(sl ), thus formula (-2) clearlysatisfied.(-3) According Definition 6, agenda(I) = , thus formula (-3) clearlysatisfied.(-4) According Definition 15, agenda(sl ) = , thus formula (-4) clearlysatisfied.(-5) Let p arbitrary proposition, e event e Rp . e/ Stepk ,(ek ) = f alse and, therefore, formula (-5) trivially satisfied. Considercase e Stepk . According Definition 15, Stepk must -step sk1sk . Thus, Definition 14, possible ordering events Stepk ,must able execute events according ordering, starting statesk1 . One possible ordering specific ordering puts e frontevents. Therefore, e must applicable sk1 . Then, Definition 4,p state(sk1 ). implies (pk1 ) = true, satisfactionformula (-5) easily follows./ Stepk ,(-6) Let p arbitrary proposition, e event e Ep+ . e(ek ) = f alse and, therefore, formula (-6) trivially satisfied. Considercase e Stepk . Similar previous case, starting state sk1 ,must able execute events Stepk possible ordering reach sk .610fiITSAT: Efficient SAT-Based Temporal PlannerOne possible ordering one puts e events. Therefore, addeffects e must members state(sj ), Definition 5, p state(sk ).implies (pk ) = true, satisfaction formula (-6) easilyfollows./ Stepk(-7) Let p arbitrary proposition, e event e Ep . ek(e ) = f alse and, therefore, formula (-7) trivially satisfied. Otherwise,argument given case (-6), p/ state(sk ), satisfactionformula (-7) easily follows.(-8) Let p arbitrary proposition. Consider nontrivial case p memberstate(sk ) state(sk1 ). easily derived Definition 5, padded application sequence events, least one eventsmust add p. implies satisfaction formula (-8).(-9) case analogous case (-8)(-10) Lemma 1 used prove satisfies chain(e1 , ..., en+1 ; Ep ; Rp {en+1 }; k; mp1 ).straightforward see properties model Lemma1. need show proposition p, provided ei Stepk Epj > i, ej/ Stepk Rp . Suppose ej Stepk . Definition 14,possible ordering events Stepk , must able execute eventsaccording ordering, starting state sk1 . One possible orderingone puts ei immediately ej . Notice ei deletes p,ei Ep . Thus, ej cannot p precondition, ej/ Rp . inferej/ Stepk Rp . Therefore, Lemma 1, satisfies chain(e1 , ..., en+1 ; Ep ; Rp{en+1 }; k; mp1 ). Now, show also satisfies bkn+1,mp ak . Consider1nontrivial case, (bkn+1,mp ) = true. Based way construct ,1least one e1 , ..., en , say ej , must delete p. Again, since Stepk -step sk1sk , must able execute events Stepk possible orderingreach sk . Consider specific ordering puts ej events. Now,agenda(sk ), according Definition 5, ej cannot ending event a.Therefore, Definition 4, also member agenda stateej applied. clearly contradicts applicability ej , ej deletes p,invariant a. Therefore, (ak ) = f alse, implies satisfiesbkn+1,mp ak .1(-11) case, too, Lemma 1 used prove satisfies chain(en , ..., e0 ; Ep ; Rp{e0 }; k; mp1 ). Similar previous case, straightforward confirmproperties Lemma 1. Since ordering chain(e1 , ..., en+1 ; Ep ; Rp{en+1 }; k; mp1 ) reversed chain(en , ..., e0 ; Ep ; Rp {e0 }; k; mp1 ), need showproposition p, provided ei Stepk Ep j < i, ej/Stepk Rp . Suppose ej Stepk . Definition 14, possible orderingevents Stepk , must able execute events accordingordering, starting state sk1 . One possible ordering oneputs ei immediately ej . argument one given case611fiRankooh & Ghassem-Sani(-10), infer ej/ Stepk Rp and, therefore, Lemma 1, satisfieschain(en , ..., e0 ; Ep ; Rp {e0 }; k; mp1 ). Now, show also satisfies bk0,mp2ak1 . Consider nontrivial case, (bk0,mp ) = true. Based way2construct , least one e1 , ..., en , say ej , must delete p. Again, Stepk-step sk1 sk , starting state sk1 , must able executeevents Stepk possible ordering. Consider specific ordering puts ejevents. Definition 4, since ej deletes p, invarianta, cannot member agenda(sk1 ). Therefore, (ak ) = f alse, impliessatisfies bk0,mp ak1 .2(-12) Assume e starting event action a. Stepk -step sk1sk , starting state sk1 , must able execute events Stepkpossible ordering. Consider specific ordering puts eevents. Therefore, e must applicable sk1 . Then, Definition 4, cannotmember agenda(sk1 ), thus (ak1 ) = f alse. see (ak ) = true,consider specific ordering events puts e events. eventsexecuted ordering, results applying e appear state sk ,thus must member agenda(sk ). Hence, satisfies ek ak1 ak .(-13) Analogous case (-12), assume e ending event action a. Since Stepk-step sk1 sk , starting state sk1 , must able executeevents Stepk possible ordering. Consider specific ordering puts eevents. Therefore, e must applicable sk1 . Then, Definition4, must member agenda(sk1 ), thus (ak1 ) = true. see(ak ) = f alse, consider specific ordering events puts eevents. events executed ordering, results applying eappear state sk , thus cannot member agenda(sk ). concludesatisfies ek ak1 ak .Theorem 4 (soundness -step encoding). Let P = (I, G, A) temporal planningproblem, {e1 , ..., en } set events P, l -step encoding P.l model , plan(M ) causally valid -step plan P.Proof. obtain plan(M ) follows. k 1 k l, let Stepkset events e (ek ) = true. k 0 k l, letsk temporal state. Assume state(sk ) set propositions p(pk ) = true, agenda(sk ) set actions (ak ) = true.show = plan(M ) = hStep1 , ..., Stepl causally valid -step plan Pstate transition sequence hs0 , ..., sl i.formula (-1), immediately follows = state(s0 ). Formula (-2) impliesG state(sl ). Formulae (-3) (-4) respectively imply agenda(s0 )agenda(sn ) empty sets. Now, need show k 1 k l,Stepk = {e1 , ..., em } {e1 , ..., en } -step sk1 sk . first show612fiITSAT: Efficient SAT-Based Temporal Plannerproposition p, Stepk cannot include two different events ei ej ei Rp ,ej Ep . j < i, since satisfies formula (-10), Lemma 2, infer (eki )(ekj ) cannot equal true. hand, < j, since satisfies formula(-11), Lemma 2, infer (eki ) (ekj ) cannot equal true.Thus, ei ej cannot members Stepk . Let : {1, ..., m} {1, ..., m}arbitrary ordering function. show induction k , k m, sequenceheO(1) , ..., eO(k ) applicable sk1 . k = 0 (i.e., case eventapplied sk1 ), conclusion trivially holds. induction hypothesis, let sktemporal state resulting applying sequence heO(1) , ..., eO(k ) sk1 . Let eO(k +1)starting event action (we omit similar case eO(k +1) endingevent a). show conditions (1) (3) Definition 4 hold thereby eO(k +1)applicable sk . result, heO(1) , ..., eO(k +1) applicable sk1 .(1) formula (-5), easily follows preconditions eO(k +1) invariants (except invariants added eO(k +1) ) membersstate(sk1 ). mentioned above, neither propositions deletedanother member Stepk . Thus, propositions also members state(sk ).(2) formula (-7), easily follows member agenda(sk1 ). Noticeaccording Definition 5, starting event a, i.e., eO(k +1) , eventadd agenda state. Therefore, cannot member agenda(sk ),either.(3) Let action invariant p p del(eO(k +1) ). Clearlystart(a ) Rp , thus, argued above, start(a ) eO(k+1) cannotmembers Stepk . Hence, start(a )/ Stepk . hand, since p deletedstep k, satisfies chain(en , ..., e0 ; Ep ; Rp {e0 }; k; mp2 ), according Lemma 2,have: (b0,mp2 ) = true. Therefore, formula (-11), infer (ak1 ) =f alse, thus,/ agenda(sk1 ). start(a )/ Stepk/ agenda(sk1 ) jointlyimply/ agenda(sk ).show sm , result applying heO(1) , ..., eO(m) sk1 , equalsk .Let p arbitrary member state(sm ). formulae (-6) (-7) followsp deleted member Stepk , cannot added member). Therefore, p deletedStepk thus, p cannot memberWof state(skmember Stepk , formula eEp e satisfied . Besides, padded member Stepk , must member state(sk1 ), thus(pk1 ) = true. Now, formula (-9), infer (pk ) = true, hencep state(sk ). hand, p added member Stepk , formula(-6), deduce (pk ) = true, p state(sk ). Therefore,state(sm ) state(sk ).Let p arbitrary member state(sk ). According formula (-7), p cannotdeleted member Stepk . Besides, formula (-8), p either member613fiRankooh & Ghassem-Sanistate(sk1 ) added member Stepk . cases, Definition 5 impliesp state(sm ). Therefore, state(sk ) state(sm ).Let arbitrary member agenda(sm ). formulae (-12) (-13),follows starting ending events single action membersStepk . agenda(sk1 ), still open state sm , inferend(a)/ Stepk . Therefore, according formula (-13), (ak ) = true, mustmember agenda(sk ). hand,/ agenda(sk1 ), start(a)must member Stepk . Then, formula (-12), have: (ak ) = true,again, must member agenda(sk ). Therefore, agenda(sm ) agenda(sk ).Let arbitrary member agenda(sk ). According formula (-13), start(a)cannot member Stepk . Besides, formula (-12), either memberagenda(sk1 ) start(a) member Stepk . cases, Definition 5 impliesagenda(sm ). Therefore, agenda(sk ) agenda(sm ).argument shows state(sk ) = state(sm ) agenda(sk ) = agenda(sm ). Hence,sk = sm = succ(sk1 , heO(1) , ..., eO(m) i). Therefore, Stepk -step sk1 sk .Theorem 5 (completeness -step encoding). Let P = (I, G, A) solvable temporal planning problem, {e1 , ..., en } set events P, = hStep1 , ..., Steplcausally valid -step plan P. exists model l = plan(M ).Proof. Theorem 3, exists model l = plan(M ). showtranslated model l . Since formulae (1) (10) sharedl l , also satisfies formulae. show also satisfiesformulae (-11) (-20), therefore translated model l .following cases, arbitrary temporal action, ei starting event a, ejending event a.(-11) (eki ) = f alse, formula (-11) trivially satisfied. (eki ) = true,formula (-12) have: (ak1 ) = f alse, therefore formula (-11) satisfied.(-12) (eki ) = f alse, formula (-12) trivially satisfied. (eki ) = true,formula (-12) have: (ak ) = true, therefore formula (-12) satisfied.(-13) (ekj ) = f alse, formula (-13) trivially satisfied. (ekj ) = true,formula (-13) have: (ak ) = f alse, therefore formula (-13) satisfied.(-14) (ekj ) = f alse, formula (-14) trivially satisfied. (ekj ) = true,formula (-13) have: (ak1 ) = true, therefore formula (-14) satisfied.(-15) Exactly case (-11).(-16) Exactly case (-12).(-17) Exactly case (-13).(-18) Exactly case (-14).614fiITSAT: Efficient SAT-Based Temporal Planner(-19) Follows immediately fact satisfies formula (-12).(-20) Follows immediately fact satisfies formula (-13).Theorem 6 (soundness -step encoding). Let P = (I, G, A) temporal planningproblem, {e1 , ..., en } set events P, l -step encoding P.l model , plan(M ) causally valid -step plan P.Proof. obtain plan(M ) follows. k 1 k l, let Stepkset events e (ek ) = true. Moreover, k0 k l, let sk temporal state. Assume state(sk ) set propositions p(pk ) = true agenda(sk ) set actions (ak ) = true.construct = plan(M ) = hStep1 , ..., Stepl show causally valid -stepplan P state transition sequence hs0 , ..., sl i.formula (-1), immediately follows = state(s0 ). Formula (-2) impliesG state(sl ). Formulae (-3) (-4) imply agenda(s0 ) agenda(sn )empty sets. Now, need show k 1 k l,Stepk = {e1 , ..., em } {e1 , ..., en } -step sk1 sk . Without loss generality,assume sequence he1 , ..., em ordered fixed ordering he1 , ..., en i. Notesince satisfies formula (-10), Lemma 2, proposition p, Stepk cannot includetwo events ei ej ei Rp , ej Ep , j < i. induction k , showevery k m, sequence he1 , ..., ek applicable sk1 . k = 0 (i.e.,case event applied sk1 ), conclusion obviously holds. inductionhypothesis, let sk temporal state resulting applying sequence he1 , ..., eksk1 . Assume ek +1 starting event action (we omit similar caseek +1 ending event a). show conditions (1) (3) Definition 4hold thereby ek +1 applicable sk .(1) formula (-5), clearly results preconditions ek +1 invariants(except invariants added eO(k +1) ) members state(sk1 ).stated before, neither propositions deleted ei < k . Thus,propositions also members state(sk ).(2) two possible cases. Consider first case, according fixedordering he1 , ..., en i, ending event located ek +1 . Formula (-11) impliescannot member agenda(sk1 ). Notice according Definition 5,starting event a, i.e., ek +1 , event add agendastate. Therefore, cannot member agenda(sk ). case,ending event located ek +1 , formula (-15) implies eithermember agenda(sk1 ), end(a) member Stepk . However, end(a)member Stepk , certainly remove agenda resulting state. Sinceek +1 event add agenda state, concludecannot member agenda(sk ). Therefore, neither two cases,member agenda(sk ).615fiRankooh & Ghassem-Sani(3) Let action p del(ek +1 ) invariant. Since p deleted step k,satisfies chain(e1 , ..., en ; Ep ; Rp {en+1 }; k; mp1 ), according Lemma 2,(bn+1,np1 ) = true. Therefore, formula (-10),/ agenda(sk ).hand, clearly end(a ) Rp , thus, argued before, end(a )member Stepk , cannot located ek +1 fixed ordering he1 , ..., en i.Hence, member agenda(sk ), cannot member agenda(sk ),either. Therefore, infer/ agenda(sk ).show sm , result applying he1 , ..., em sk1 , equal sk .argument given proof Theorem 4, state(sm ) state(sk )state(sk ) state(sm ), hence, state(sm ) = state(sk ).Let arbitrary member agenda(sm ). Let ei ej starting endingevents a, respectively. three possible cases. Consider first caseagenda(sk1 ), ei/ Stepk , ej/ Stepk (i.e., open immediately stepk neither started ended step k). case, since satisfies (-20),(ak ) = true, therefore, agenda(sk ). Consider second caseagenda(sk1 ), ei Stepk , ej Stepk , j < (i.e., open immediatelystep k, first ended started step k). case, sincesatisfies formula (-16), (ak ) = true, therefore, agenda(sk ).Finally, consider third case/ agenda(sk1 ), ei Stepk , ej/ Stepk(i.e., open immediately step k, started endedstep k). case, j < i, must satisfy formula (-16)(ak ) = true. hand, < j, must satisfy formula (-12) and,since (ekj ) = f alse, must (ak ) = true, therefore, agenda(sk ).Consequently, three cases, must member agenda(sk ); henceagenda(sm ) agenda(sk ).Let arbitrary member agenda(sk ), i.e., (ak ) = true. twopossible cases. Case 1) member agenda(sk1 ), hence (ak1 ) =f alse. formula (-19), have: (eki ) = true. means startedstep k. Now, j < i, ending event cannot happen starting event,therefore, must remain open execution step k, i.e., agenda(sm ).hand, < j, formula (-14) have: (ekj ) = f alse.means started ended step k, therefore must remain openexecution step k, i.e., agenda(sm ). consider case 2)member agenda(sk1 ), hence (ak1 ) = true. < j, formula (-11)(eki ) = f alse, formula (-13) (ekj ) = f alse. meansopen immediately execution step k, neither startedended step k. Therefore, must also open execution step k, i.e.,agenda(sm ). hand, j < i, since (ak ) (ak1 )false, formulae (-15) (-17) combined form formula (eki ekj ).means ended step k later startedstep. Therefore, must open execution step k,agenda(sm ). Therefore, agenda(sk ) agenda(sm ).616fiITSAT: Efficient SAT-Based Temporal Plannerarguments show state(sk ) = state(sm ) agenda(sk ) = agenda(sm ). Hence,sk = sm = succ(sk1 , he1 , ..., em i). Therefore, ordering functions : {1, ..., m}{1, ..., m}, O(i) = i, sk = succ(sk1 , heO(1) , ..., eO(m) i), thus Stepk-step sk1 sk .Lemma 3. Let model chain (e1 , ..., en ; Ep+ ; Ep ; Rp ; k; mp ), ej memberRp , EpM = {e|e Ep+ Ep , (ek ) = true}. following properties:exists event ei ei EpM < j, (bkj,mp ) = (pk1 ).exists event ei ei Ep+ , < j, {ei+1 , ..., ej1 } EpM = ,(eki ) = true, (bkj,mp ) = true.exists event ei ei Ep , < j, {ei+1 , ..., ej1 } EpM = ,(eki ) = true, (bkj,mp ) = f alse.Proof.Assume exists event ei ei EpM < j. Considercase (pk1 ) = true. Let {ei0 , ..., eim } set events eiei Rp Ep+ Ep , 0 j. Without loss generality,assume 0 = i0 < i1 < ... < im = j. Since must satisfy (C -7), know(bki ,m ) = true. Assume arbitrary s, (bkis ,mp ) = true. eis Ep+ Ep ,0pknow (ekis ) = f alse, (C -4) (bkis+1 ,mphand, eisRp Ep+ Ep ,(C -3),(bki ,m )ps+1) = true.= true. infer1 j, (bkis ,mp ) = true, thereby (bkj,mp ) = (pk1 ).proof case (pk1 ) = f alse analogous, exceptinstead (C -4), need use (C -5) .Assume exists event ei ei Ep+ , < j, {ei+1 , ..., ej1 }EpM = , (eki ) = true. Let {ei0 , ..., eim } set events eiei Rp Ep+ Ep , j. Without loss generality, assume =i0 < i1 < ... < im = j. Since must satisfy (C -1), know (bki ,m ) = true.1pAssume arbitrary 1, (bkis ,mp ) = true. eis Ep+ Ep ,know (ekis ) = f alse, (C -4), (bkihand, eis RpEp+) = true.s+1 ,mpk(bi ,m ) = true. inferps+1k(bis ,mp ) = true, thereby (bkj,mp ) = true.Ep ,1 j,(C -3),Assume exists event ei ei Ep , < j, {ei+1 , ..., ej1 }EpM = , (eki ) = true. Let {ei0 , ..., eim } set events eiei Rp Ep+ Ep , j. Without loss generality, assume =617fiRankooh & Ghassem-Sanii0 < i1 < ... < im = j. Since must satisfy (C -1), know (bki ,m ) = f alse.1pAssume arbitrary 1, (bkis ,mp ) = f alse. eis Ep+ Ep ,know (ekis ) = f alse, (C -5), (bkihand, eis RpEp+) = f alse.s+1 ,mpk(bi ,m ) = f alse. inferps+1k(bis ,mp ) = f alse, thereby (bkj,mp ) = f alse.Ep ,1 j,(C -3),Lemma 4. Let model chain(e1 , ..., en+1 ; Ep ; Rp ; k; mofp ). Assume ei Ep ,(eki ) = true, p inv(a). Let ej ej+1 starting event ending eventa, respectively. following properties:(ekj+1 ) = true, < j, (ekj ) = true.(ak ) = true, (ekj ) = true.Proof. Let {ei1 , ..., eim } equal set {es |es Op , < n + 1}. Without lossgenerality, assume i1 < i2 < ... < im = n + 1. Since (eki ) = true,(Cof -1), infer (bi1 ,mof ) = true. s, (bis ,mof ) = true,pp(Cof -2), deduce (bis+1 ,mof ) = true. Therefore, (bn+1,mof ) = true.ppFurthermore, < j, ej+1 {ei1 , ..., eim }, thus (bj+1,mof ) = true. Besides,p(ekj+1 ) = true, (Cof -3), (ekj ) = true. hand, (ak ) =true, infer formula (Cof -4) (ekj ) = true.Lemma 5. Let model chain(e0 , ..., en ; Ep ; Rp ; k; mobp ). Assume ei Ep ,(eki ) = true, p inv(a). Let ej ej+1 starting event ending eventa, respectively. following properties:(ekj ) = true, j + 1 < i, (ekj+1 ) = true.(ak1 ) = true, (ekj+1 ) = true.Proof. proof analogous Lemma 4, thus omitted.Theorem 7 (completeness relaxed -step encoding). Let P = (I, G, A)temporal planning problem formulae l l two -step encodingsP explained Section 4. model l , l modelplan(M ) = plan(M ).Proof. Let model l . construct function assign value truef alse binary variable l , using following rules:(R-1) 1 n 1 k l, (eki ) = (eki ).618fiITSAT: Efficient SAT-Based Temporal Planner(R-2) 1 k l, (ek0 ) = (ekn+1 ) = f alse.(R-3) 0 k l proposition p, (pk ) = (pk ).(R-4) 0 k l action a, (ak ) = (ak ).(R-5) 0 n + 1, 1 k l, proposition p, exist j <(ekj ) = true ej Ep+ Ep (bki,mp ) = (pk ); otherwise, (bki,mp ) =(pk1 ).(R-6) 1 n + 1, 1 k l, proposition p, exist j <(ekj ) = true ej Ep (bk ) = true; otherwise, (bk ) = f alse.i,mpi,mp(R-7) 0 n, 1 k l, proposition p, exist j >(ekj ) = true ej Ep (bki,mob ) = true; otherwise, (bki,mob ) = f alse.ppshow satisfies formulae ( -1) ( -13), therefore modell . rules, clear plan(M ) = plan(M ).( -1) Formula ( -1) exactly (-1). Besides, assignvalue variable formula.( -2) Formula ( -2) exactly (-2). Besides, assignvalue variable formula.( -3) Formula ( -3) exactly (-3). Besides, assignvalue variable formula.( -4) Formula ( -4) exactly (-4). Besides, assignvalue variable formula.( -5) Formula ( -4) conjunction formulae (C -1) (C -8). showsatisfies formulae (C -1) (C -8), thereby, satisfies ( -5).Consider arbitrary formula eki bkj,mp (C -1). (eki ) = f alse,formula trivially satisfied. (eki ) = true, (R-5),(bki,mp ) = (pk ). hand, satisfies (-6),(pk ) = true. Therefore, (bki,mp ) = true, formula satisfied again.Consider arbitrary formula eki bkj,mp (C -2). (eki ) = f alse,formula trivially satisfied. (eki ) = true, (R-5),(bki,mp ) = (pk ). hand, satisfies (-7),(pk ) = f alse. Therefore, (bki,mp ) = f alse, formula satisfiedagain.Consider arbitrary formula bki,mp bkj,mp (C -3). Since eimember Ep+ Ep , none events located ei ejfixed ordering members Ep+ Ep , (R-5), easily show(bki,mp ) = (bkj,mp ). Thus, formula satisfied.619fiRankooh & Ghassem-SaniConsider arbitrary formula bki,mp eki bkj,mp (C -4). (eki ) =true, formula trivially satisfied. (eki ) = f alse, since noneevents located ei ej fixed ordering membersEp+ Ep , (R-5), easily show (bki,mp ) = (bkj,mp ). Thus,formula satisfied.Consider arbitrary formula bki,mp eki bkj,mp (C -5).argument one given (C -4), infer (bki,mp ) = (bkj,mp ).Thus, formula satisfied.Consider arbitrary formula bki,mp eki (C -6). (bki,mp ) = true,formula trivially satisfied. (bki,mp ) = f alse, exist twopossible cases. Case 1: exists event ej j < i, (ekj ) = true,ej Ep+ Ep . case, (R-5), (pk ) = (bki,mp ) = f alse.Since must also satisfy (-6), ej/ Ep+ , thus ej Ep . Besides,must satisfy (-10), implies (eki ) = f alse. (R-1),(eki ) = (eki ) = f alse, therefore, formula satisfied. Case 2:exist event ej j < i, (ekj ) = true, ej Ep+ Ep .case, (R-5), (pk1 ) = (bki,mp ) = f alse. Now, sincemust satisfy (-5), infer (eki ) = f alse. (R-1),(eki ) = (eki ) = f alse, therefore, formula satisfied again.Consider formula bk0,mp pk1 (C -6). (R-5), easily deducted (bk0,mp ) always equal (pk1 ). (R-3),(pk1 ) = (pk1 ). result, (bk0,mp ) = (pk1 ), formulasatisfied.Consider formula bkn+1,mp pk (C -6). two possible cases.Case 1: exists event e (ek ) = true, e Ep+ Ep .case, (R-5), (bn+1,mp ) = (pk ). Now, (R-5),(pk ) = (pk ). Therefore, (bn+1,mp ) = (pk ), formulasatisfied. Case 2: exist event e (ek ) = truee Ep+ Ep . case, (R-5), (bn+1,mp ) = (pk1 ). Besides,since satisfies formulae (-8) right hand side (-8) becomes f alse,left hand side (-8), i.e., pk1 pk , f alse, too. Thus,(pk1 ) = f alse, (pk ) = f alse. similar argument(-9) show (pk1 ) = true, (pk ) = true. Thus,(pk1 ) = (pk ), (R-3), (pk ) = (pk1 ). Therefore,(bn+1,mp ) = (pk1 ) = (pk ), formula satisfied again.( -6) show satisfies formulae (Cof -1) (Cof -4), thereby, satisfies( -6).Consider arbitrary formula eki bkj,mofp(Cof -1). know (Cof -1) < j. (eki ) = f alse, formula trivially satisfied. (eki ) =true, (R-6), (bj,mof ) = true, formula satisfied.p620fiITSAT: Efficient SAT-Based Temporal PlannerConsider arbitrary formula bki,mofp(Cof -2). (bkbkj,mofpi,mofp= f alse, formula trivially satisfied. (bki,mofp)) = true, rule(R-6), must exist event ei ,< i, (eki ) = true,ei Ep . Since < j, must also < j. Now, (R-6),(bj,mof ) = true, formula satisfied.pConsider arbitrary formula bkj,mofpekj eki (Cof -3). (bkj,mofpf alse, formula trivially satisfied. (bkj,mofp)=) = true, (R-6),must exist event ej j < j, (ekj ) = true, ej Ep . Now,since satisfies (-10), infer (ekj ) = f alse. (R-1),(ekj ) = (ekj ) = f alse, therefore, formula satisfied.Consider arbitrary formula bkn+1,mofpak eki (Cof -4). (bkn+1,mofp= f alse, formula trivially satisfied. (bk)) = true, (R-6),n+1,mofpkevent ej (ej ) = true ej Ep . Now,(-10), infer (ak ) = f alse. (R-4),must existsince satisfies(ak ) = (ak ) = f alse, therefore, formula satisfied.( -7) show satisfies formulae (Cob -1) (Cof -4), thereby, satisfies( -7).Consider arbitrary formula eki bkj,mob (Cob -1). know (Cob -1)pj < i. (eki ) = f alse, formula trivially satisfied. (eki ) =true, (R-7), (bj,mob) = true, formula satisfied.pConsider arbitrary formula bki,mob bkj,mob (Cob -2). (bki,mob ) =pppf alse, formula trivially satisfied. (bki,mob ) = true, rule (R-7),pmust exist event ei < , (eki ) = true, ei Ep .Since j < i, must also j < . Now, (R-7),) = true, formula satisfied.(bj,mobpConsider arbitrary formula bki,mob eki ekj (Cob -3). (bki,mob ) =ppf alse (eki ) = f alse, formula trivially satisfied. (bki,mob ) = truep(eki ) = true, (R-7), must exist event ei , < ,(eki ) = true, ei Ep . Since satisfies (-10), infer(ak ) = f alse. However, know = j 1 < j; thus must satisfy (12). Therefore, (ekj ) = true. (R-1), (ekj ) = (ekj ) =true, therefore, formula satisfied.Consider arbitrary formula bk0,mob ak1 ekj (Cob -4). (bk0,mob ) =ppf alse (ak1 ) = f alse, formula trivially satisfied. (bk0,mob ) =ptrue (ak1 ) = true, (R-7), must exist event ei(eki ) = true, ei Ep . Since satisfies (-10), infer(ak ) = f alse. However, must satisfy (-20). Therefore, (ekj ) =621fiRankooh & Ghassem-Sanitrue. (R-1), (ekj ) = (ekj ) = true, therefore, formulasatisfied.( -8) Consider arbitrary formula eki ak1 ( -8). Let ej ending eventa. know = j 1 < j. Therefore, must satisfy (-11). ( -8)exactly (-11). Besides, assign valuevariable formulae. Thus, ( -8) satisfied .( -9) Consider arbitrary formula eki ak ekj ( -9). know = j 1 < j.Therefore, must satisfy formula (-12). ( -9) exactly (-12).Besides, assign value variable formulae. Thus,( -9) satisfied .( -10) Consider arbitrary formula ekj ak ( -10). Let ei starting eventa. know = j 1 < j. Therefore, must satisfy (-13). ( -10)exactly (-13). Besides, assign valuevariable formulae. Thus,( -10) satisfied .( -11) Consider arbitrary formula ekj ak1 eki ( -11). know =j 1 < j. Therefore, must satisfy (-14). ( -11) exactly (-14).Besides, assign value variable formulae. Thus,( -11) satisfied .( -12) ( -12) exactly (-19). Besides, assign valuevariable formulae. Thus, ( -12) satisfied .( -13) ( -13) exactly (-20). Besides, assign valuevariable formulae. Thus, ( -13) satisfied .Theorem 8 (soundness relaxed -step encoding). Let P = (I, G, A)temporal planning problem, {e1 , ..., en } set events P, l relaxed-step encoding P. l model , plan(M ) causally valid -step planP.Proof. obtain plan(M ) follows. k 1 k l, let Stepkset events e (ek ) = true. k 0 k l,let sk temporal state. Assume state(sk ) set propositions p(pk ) = true, agenda(sk ) set actions (ak ) = true.construct = plan(M ) = hStep1 , ..., Stepl show causally valid -step planP state transition sequence hs0 , ..., sl i.( -1), immediately follows = state(s0 ). Also, ( -2) implies Gstate(sl ). Besides, ( -3) ( -4) imply agenda(s0 ) agenda(sn ) empty sets,respectively. need show k 1 k l, Stepk ={ei1 , ..., eim } {e1 , ..., en } -step sk1 sk . Without loss generality,622fiITSAT: Efficient SAT-Based Temporal Plannerassume sequence hei1 , ..., eim ordered according fixed ordering he1 , ..., en i,i.e., i1 < i2 < ... < im .induction k , conclude k m, sequence hei1 , ..., eikapplicable sk1 . k = 0 (i.e., case, event applied sk1 ), conclusion obviously holds. Let sk temporal state resulting applying hei1 , ..., eiksk1 . Assume eik +1 starting event action a. omit similar caseeik +1 ending event a. show conditions (1) (3) Definition 4holds thereby eik +1 applicable sk .(1) Assume p/ state(sk ), p either precondition eik +1 invariantadded eik +1 . two possible cases. Case 1: pmember state(sk1 ), added deleted member {ei1 , ..., eik }.case, (pk1 ) = f alse. Moreover, exists event eiei Ep+ Ep , < k + 1, (eki ) = true. Case 2: p deleted eventei Stepk added deleted event ej Stepk , < j k .case, ei Ep , < ik +1 , {ei+1 , ..., eik +1 } EpM = , (eki ) = true,EpM = {e|e Ep+ Ep , (ek ) = true}. cases, Lemma 3,(bkik +1 ,mp ) = f alse, contradicts fact satisfies (C -6).(2) Since satisfies ( -8), member agenda(sk1 ). However, eik +1event Stepk add agenda state. Thus, memberagenda(sk ).(3) Let b action a, invariant p del(eik +1 ). Let ej ej+1starting ending events b, respectively. mentioned earlier, assumeending event action located immediately starting eventfixed ordering. show b cannot member agenda(sk ).two possible cases b may member agenda(sk ). Case 1: b openaction immediately execution Stepk ; b ended Stepkeik +1 executed. case, (bk1 ) = true, (ekik +1 ) = true. Sincesatisfies ( -7), Lemma 5, (ekj+1 ) = true. assumed bended execution eik +1 , ik +1 < j + 1. hand,since ej starting event b, ik +1 6= j, thus, ik +1 < j. Therefore,Lemma 4, (ekj ) = true. contradicts fact satisfies ( -8),(bk1 ) = true, (ekj ) = true, ej = start(b). Case 2: bstarted step k, ended step k execution eik +1 .case, (ekj ) = true, (ekj+1 ) = f alse, j + 1 < ik +1 , (ekik +1 ) = true.Since satisfies ( -7), Lemma 5, must (ekj+1 ) = true,contradiction.show sm , result applying hei1 , ..., eim sk1 , equal sk .Let p arbitrary proposition. p state(sm ), two possible cases.Case 1: p member state(sk1 ), added deleted member{ei1 , ..., eim }. case, (pk1 ) = true. Moreover, exists event eiei Ep+ Ep , < n + 1, (eki ) = true. Case 2: p added event623fiRankooh & Ghassem-Saniei Stepk added deleted event ej Stepk , < n + 1.case, ei Ep+ , < n + 1, {ei+1 , ..., en } EpM = , (eki ) = true,EpM = {e|e Ep+ Ep , (ek ) = true}. cases, Lemma 3,(bkn+1,mp ) = true. Since satisfies (C -8), (pk ) = true, thusp state(sk ). Therefore, state(sm ) state(sk ).Let p arbitrary proposition. p/ state(sm ), two possible cases. Case1: p member state(sk1 ), added deleted member{ei1 , ..., eim }. case, (pk1 ) = f alse. Moreover, exists eventei ei Ep+ Ep , < n + 1, (eki ) = true. Case 2: p deletedevent ei Stepk added deleted event ej Stepk ,< j < n + 1. case, ei Ep , < n + 1, {ei+1 , ..., en } EpM = ,(eki ) = true, EpM = {e|e Ep+ Ep , (ek ) = true}. cases, Lemma3, (bkn+1,mp ) = f alse. Since satisfies (C -8), (pk ) = f alse,thus p/ state(sk ). Therefore, state(sk ) state(sm ).Let arbitrary action, ei ej starting event ending event,respectively. agenda(sm ), since assume ending event actionlocated immediately starting event fixed ordering, twopossible cases. Case 1: open immediately step k, endedstep k. case, (ak1 ) = true (ekj ) = f alse. Since satisfies( -13), must (ak ) = true. Therefore, agenda(sk ). Case 2: startedended step k. case, (eki ) = true (ekj ) = f alse.satisfies ( -9), must (ak ) = true. Therefore, agenda(sk ). Sincecases, agenda(sk ), infer agenda(sm ) agenda(sk ).Let arbitrary action, ei ej starting event ending event a,respectively./ agenda(sm ), since assume ending event actionlocated immediately starting event fixed ordering, twopossible cases. Case 1: open immediately execution step k,started step k. case, (ak1 ) = f alse (eki ) = f alse.Since satisfies ( -12), must (ak ) = f alse. Therefore,/ agenda(sk ).kCase 2: ended step k. case, (ej ) = true. Since satisfies( -10), must (ak ) = f alse. Therefore,/ agenda(sk ).cases,/ agenda(sk ), infer agenda(sk ) agenda(sm ).arguments show state(sk ) = state(sm ) agenda(sk ) = agenda(sm ).Hence, sk = sm sk = succ(sk1 , hei1 , ..., eim i). Therefore, ordering functions : {1, ..., m} {1, ..., m}, O(i) = i, sk = succ(sk1 , heO(i1 ) , ..., eO(im ) i),thus Stepk -step sk1 sk .Theorem 9. Let P = (I, G, A) temporal planning problem, = he1 , ..., encausally valid plan P, : {1, ..., n} Q relaxed scheduling function .exists valid temporal plan P.624fiITSAT: Efficient SAT-Based Temporal PlannerProof. using bubble sort algorithm, sort events increasing orderaccording values given . algorithm takes two consecutive memberssequence, swaps value first one greatersecond one. continues swaps whole sequence properly sorted. Let eiej two events swapped bubble sort stage algorithm (assumeei located ej sequence prior swapping). Then, must (i) > (j).Thus, according (S-1), know ei ej swappable (c.f., Definition 12).result, whole sequence causally valid plan prior swapping, would alsocausally valid plan swapping. means sorting according valuesgiven result another causally valid plan, say . plan obviously satisfiestwo conditions Definition 9, therefore, ( , ) valid temporal plan P.Theorem 10. Let P = (I, G, A) solvable temporal planning problem, COMset every member either compressible towards start compressibletowards end (Definition 13). exists valid temporal plan (, ) Pcausally valid plan P, compressed respect COM, relaxedscheduling function .Proof. Let 1 = e1 , ..., ei , ei+1 , ..., en causally valid plan P ei ei+1two swappable events. Let 2 = e1 , ..., ei+1 , ei , ..., en result swapping ei ei+11 . show relaxed scheduling function 1 , also relaxedscheduling function 2 .Consider two events ej ek 2 , ej located ek . j 6= + 1k 6= i, 1 , ej definitely located ek , too, therefore property(S-1) holds ej ek . hand, j = + 1 k = i, ej ekswappable therefore property (S-1) trivially holds ej ek .Assume ej starting event particular action a, ek pairingevent ej 2 . Definition 8, easily infer 2 , ei locatedej ek , ei cannot starting ending event a. Similarly,ei+1 located ej ek , ei+1 cannot starting ending eventa. hand, since ei ei+1 swappable, know cannotevents action, therefore, either j 6= + 1 k 6= i. Thus,swapping ei ei+1 cannot falsify fact ej ek pairing events.words, 1 , too, ek pairing event ej . implies property (S-2)holds ej ek .Let ( , ) arbitrary valid temporal plan P. Since scheduling function, obviously also regarded relaxed scheduling function . showedSection 3.2, transformed causally valid plan compressedrespect COM, series swaps, swapping occurs pairconsecutive swappable events. Therefore, must also relaxed scheduling function, (, ) valid temporal plan P, scheduling function.625fiRankooh & Ghassem-SaniPTheorem 11. Let P = (I, G, A) temporal planning problem,= {e1 , ..., en }set events P, l three formulae l , l , l (defined SectionP 4),non-empty causally valid plan P obtained solving l . Let = (S , , , x0 , )FSM accepts subsequence = he1 , ..., em ,l encodingpresented (-1) (-6). exist model ll= plan(M ).Proof. give proof contradiction. Assume exists model ll= plan(M ). Let f : {1, ..., m} {1,P..., n} function i,f (i) equal index i-th event . Moreover, let g : {1, ..., m} {1, ..., l}function i, g(i) equal step number SAT variablel corresponds i-th event . Assume x0 , ..., xm sequence states0 < m, xi = (xi1 , ef (i) ). Since accepts , mustf (1),g(1)xm . satisfies (-5), (x0) = true. Here, two casesconsidered. case 1: g(2) = g(1). case, since = plan(M ), f (1) < j < f (2),g(1)must (ej ) = f alse. Now, considering ( 1) ( 2), inferg(2),f (2)(x1) = true. Case 2: g(2) > g(1). case, considering ( 1) ( 2),g(1),n+1infer (x1) = true. by, considering ( 4), deduceg(1)+1,0(x1) = true. argument plus considering ( 3) showg(2),f (2)g(i),f (i)(x1) = true. whole deduction repeated show (xi1) = trueg(m),f (m)1 m. Therefore, (xm1) = true. Since xm = (xm1 , ef (m) ),E {econsidering ( 1), infer j, ej Emn+1 }g(m),j) = true. However, since xm ,{ef (m)+1 , ..., ej1 } (Em Em ) = , (xmcontradicts assumption satisfies ( 6).PTheorem 12. Let P = (I, G, A) temporal planning problem,= {e1 , ..., en }set events P, l three formulae l , l , l (definedSection 4). Let model satisfies l , = he1 , ..., em = plan(M ). LetP= (S , , , x0 , ) FSM accept subsequence ,lencoding composed (-1) (-6). exists model l l= plan(M ).Proof. Let us introduce total order relation SAT variables l correspondevents input problem. two sat variables eki eki , eki ekione following two conditions holds: 1) k < k . 2) k = k < .Assume f : {1, ..., m} {1, ...,Pn} function i, f (i) equalindex i-th event . Moreover, assume g : {1, ..., m} {1, ..., l}function k, g(k) equal step number SAT variable lcorresponds k-th event . Let uk,i = heu , ..., et denote subsequencefollowing properties:g(t)(ef (t) ) = true.626fiITSAT: Efficient SAT-Based Temporal Plannerg(t)k ef (t) eki eki , (eki ) = f alse.fact, uk,i substring spans u-th event last eventwhose corresponding SAT variable located eki l . define modelll following rules:(R-1) SAT variable v l , (v) = (v).(R-2) 1 k l 1 n, (xk,i0 ) = true.(R-3) 1 k l, 1 < n, xs , (xk,i) = true iff j, sequencejk,i transforms x0 xs .(R-1), infer satisfies l . show also satisfiesformulae (-1) (-6), thereby, satisfiesl .xk,jarbitrary formula (-1). (eki ) = f alse(-1) Let eki xk,ik,ik(xk,i) = f alse, formula trivially satisfied. Assume (ei ) = (xs ) =k,itrue. (R-3), u, sequence u transforms x0 xs . Sinceeki ekj , way defined uk,j , deduce uk,j = uk,i hei , ()denotes concatenation operator sequence events {ei+1 , ..., ej1 }.(-1), (xs , ei ) = xt , therefore ei causes transit xsxt . Besides, {ei+1 , ..., ej1 } Etout = , thus, member causetransit state xt . Therefore, uk,j transforms x0 xt ,(xk,j) = true. Hence, formula satisfied.k,jarbitrary formula (-2). (eki ) = true(-2) Let eki xk,ixsk(xk,i) = f alse, formula trivially satisfied. Assume (ei ) = f alsek,i(xk,i) = true. (R-3), u, sequence u transforms x0 xs .k,jSince eki ekj , way defined u , deduce uk,j = uk,i ,sequence events {ei+1 , ..., ej1 }. Besides, {ei+1 , ..., ej1 } Esout = ,thus, member cause transit state xs . Therefore,uk,j transforms x0 xs , (xk,j) = true. Hence, formula satisfied.k,ik,0(-3) Let xk,0xs arbitrary formula (-3). (xs ) = f alse, formulatrivially satisfied. Assume (xk,0) = true. (R-3), u,k,0sequence u transforms x0 xs . Since ek0 eki , way defined uk,i ,deduce uk,i = uk,0 , sequence events {e1 , ..., ei1 }.Besides, {e1 , ..., ei1 }Esout = , thus, member cause transitstate xs . Therefore, uk,i transforms x0 xs , (xk,i) = true.Hence, formula satisfied.(-4) Let xk,n+1xk+1,0arbitrary formula (-4). way definedk+1,0) =, deduce uk,n+1 = uk+1,0 every u. Therefore, (xk,n+1uk+1,0(xs). Hence, formula satisfied.(-5) According (R-2), formula (-5) directly satisfied , .627fiRankooh & Ghassem-Sani(-6) Let xk,i arbitrary formula (-6). Accorrding assumptions, uk,icannot cause transit accepting states. Since x , (R-3)implies (xk,i ) = f alse. Hence, formula satisfied.Theorem 13. Let N = xi1 , ..., xim negative cycle STN correspondingcausally valid plan = e1 , ..., en temporal problem P, xik node corresponding event eik . Let another causally valid plan P. subsequencemember LN (defined Section 5), corresponding STN also Nnegative cycle.Proof. Let ei1 , e2,1 ..., e2,k2 , ei2 , ..., eim1 , em,1 , ..., em,km , eim subsequence ,ej,1 , ..., ej,kj string symbols j , 1 < j m. Consider two arbitraty eventseij eij sequence, ij < ij . show temporal constraints(eij ) (eij ) also present (ij ) (ij ).constraint (ij ) < (ij ), scheduling constraint (S-1)explained Section 5, eij eij swappable. Besides, , eij clearlylocated eij . Consequently, must (ij ) < (ij ) accordingscheduling constraint (S-1).constraint (ij ) (ij ) = dur(a), scheduling rule (S-2), eijeij starting event ending event a, respectively. Moreover,j < j < j , action(eij ) 6= a. indicates j < j j ,Oj , therefore eij/ j . Since ej ,1 ..., ej ,k string symbols j ,jconclude , yet ended reaching eij . means eijeij pairing events . Thus, scheduling constraint (S-2),(ij ) (ij ) = dur(a).shows edge xij xij corresponding STN also presentcorresponding STN , thus latter STN N negative cycle.ReferencesAllen, J. F. (1984). Towards general theory action time. Artif. Intell., 23 (2),123154.Armando, A., & Giunchiglia, E. (1993). Embedding complex decision procedures insideinteractive theorem prover. Ann. Math. Artif. Intell., 8 (3-4), 475502.Benton, J., Coles, A. J., & Coles, A. (2012). Temporal planning preferencestime-dependent continuous costs. Proceedings Twenty-Second InternationalConference Automated Planning Scheduling, ICAPS 2012, Atibaia, Sao Paulo,Brazil, June 25-19, 2012.Biere, A. (2009). P{re,i}cosat@sc09. solver description SAT competition 2009. SAT2009 Competitive Event Booklet.628fiITSAT: Efficient SAT-Based Temporal PlannerBiere, A. (2013). Lingeling, Plingeling Treengeling entering sat competition 2013.Proceedings SAT Competition 2013.Blum, A., & Furst, M. L. (1997). Fast planning planning graph analysis. Artif.Intell., 90 (1-2), 281300.Castellini, C., Giunchiglia, E., & Tacchella, A. (2003). SAT-based planning complexdomains: Concurrency, constraints nondeterminism. Artif. Intell., 147 (1-2), 85117.Coles, A. J., Coles, A., Fox, M., & Long, D. (2009). Extending use inferencetemporal planning forwards search. Proceedings 19th International Conference Automated Planning Scheduling, ICAPS 2009, Thessaloniki, Greece,September 19-23, 2009.Coles, A. J., Coles, A., Fox, M., & Long, D. (2010). Forward-chaining partial-order planning. Proceedings 20th International Conference Automated PlanningScheduling, ICAPS 2010, Toronto, Ontario, Canada, May 12-16, 2010, pp. 4249.Cormen, T. H., Leiserson, C. E., Rivest, R. L., & Stein, C. (2009). Introduction Algorithms(3. ed.). MIT Press.Cushing, W., Kambhampati, S., Mausam, & Weld, D. S. (2007). temporal planningreally temporal?. IJCAI 2007, Proceedings 20th International Joint Conference Artificial Intelligence, Hyderabad, India, January 6-12, 2007, pp. 18521859.Dechter, R., Meiri, I., & Pearl, J. (1991). Temporal constraint networks. Artif. Intell.,49 (1-3), 6195.Do, M. B., & Kambhampati, S. (2003). Sapa: multi-objective metric temporal planner.J. Artif. Intell. Res. (JAIR), 20, 155194.Een, N., & Biere, A. (2005). Effective preprocessing SAT variable clauseelimination. Theory Applications Satisfiability Testing, 8th InternationalConference, SAT 2005, St. Andrews, UK, June 19-23, 2005, Proceedings, pp. 6175.Ernst, M. D., Millstein, T. D., & Weld, D. S. (1997). Automatic sat-compilation planningproblems. Proceedings Fifteenth International Joint Conference ArtificialIntelligence, IJCAI 97, Nagoya, Japan, August 23-29, 1997, 2 Volumes, pp. 11691177.Eyerich, P., Mattmuller, R., & Roger, G. (2009). Using context-enhanced additiveheuristic temporal numeric planning. Proceedings 19th International Conference Automated Planning Scheduling, ICAPS 2009, Thessaloniki,Greece, September 19-23, 2009.Fox, M., & Long, D. (2002). PDDL+: Modelling continuous time-dependent effects.Third International NASA Workshop Planning Scheduling Space.Fox, M., & Long, D. (2003). PDDL2.1: extension PDDL expressing temporalplanning domains. J. Artif. Intell. Res. (JAIR), 20, 61124.Fox, M., & Long, D. (2007). note concurrency complexity temporal planning.26th Workshop UK Planning Scheduling Special Interest Group.629fiRankooh & Ghassem-SaniGarrido, A., Fox, M., & Long, D. (2002). temporal planning system durative actionsPDDL2.1. Proceedings 15th Eureopean Conference Artificial Intelligence,ECAI2002, Lyon, France, July 2002, pp. 586590.Gerevini, A., Saetti, A., & Serina, I. (2006). approach temporal planning scheduling domains predictable exogenous events. J. Artif. Intell. Res. (JAIR), 25,187231.Gerevini, A., & Schubert, L. K. (1998). Inferring state constraints domain-independentplanning. Proceedings Fifteenth National Conference Artificial IntelligenceTenth Innovative Applications Artificial Intelligence Conference, AAAI 98,IAAI 98, July 26-30, 1998, Madison, Wisconsin, USA., pp. 905912.Halsey, K. (2004). CRIKEY! Co-ordination Temporal Planning. Ph.D. thesis, University Durham.Halsey, K., Long, D., & Fox, M. (2004). Multiple relaxations temporal planning.Proceedings 16th Eureopean Conference Artificial Intelligence, ECAI2004,including Prestigious Applicants Intelligent Systems, PAIS 2004, Valencia, Spain,August 22-27, 2004, pp. 10291030.Haslum, P. (2006). Improving heuristics relaxed search - analysis TP4HSP*a 2004 planning competition. J. Artif. Intell. Res. (JAIR), 25, 233267.Haslum, P., & Geffner, H. (2000). Admissible heuristics optimal planning. Proceedings Fifth International Conference Artificial Intelligence Planning Systems,Breckenridge, CO, USA, April 14-17, 2000, pp. 140149.Helmert, M., & Geffner, H. (2008). Unifying causal graph additive heuristics.Proceedings Eighteenth International Conference Automated PlanningScheduling, ICAPS 2008, Sydney, Australia, September 14-18, 2008, pp. 140147.Hoffmann, J., Gomes, C. P., Selman, B., & Kautz, H. A. (2007). SAT encodings statespace reachability problems numeric domains. IJCAI 2007, Proceedings20th International Joint Conference Artificial Intelligence, Hyderabad, India, January 6-12, 2007, pp. 19181923.Hoffmann, J., & Nebel, B. (2001). FF planning system: Fast plan generationheuristic search. J. Artif. Intell. Res. (JAIR), 14, 253302.Huang, R., Chen, Y., & Zhang, W. (2009). optimal temporally expressive planner:Initial results application P2P network optimization. Proceedings19th International Conference Automated Planning Scheduling, ICAPS 2009,Thessaloniki, Greece, September 19-23, 2009.Huang, R., Chen, Y., & Zhang, W. (2012). SAS+ planning satisfiability. J. Artif. Intell.Res. (JAIR), 43, 293328.Kautz, H. A., & Selman, B. (1992). Planning satisfiability. ECAI, pp. 359363.Kautz, H. A., & Selman, B. (1996). Pushing envelope: Planning, propositional logicstochastic search. Proceedings Thirteenth National Conference ArtificialIntelligence Eighth Innovative Applications Artificial Intelligence Conference,AAAI 96, IAAI 96, Portland, Oregon, August 4-8, 1996, Volume 2., pp. 11941201.630fiITSAT: Efficient SAT-Based Temporal PlannerLong, D., & Fox, M. (2003). Exploiting graphplan framework temporal planning.Proceedings Thirteenth International Conference Automated PlanningScheduling (ICAPS 2003), June 9-13, 2003, Trento, Italy, pp. 5261.Lu, Q., Huang, R., Chen, Y., Xu, Y., Zhang, W., & Chen, G. (2013). SAT-based approachcost-sensitive temporally expressive planning. ACM TIST, 5 (1), 18.Mali, A. D., & Liu, Y. (2006). T-satplan: SAT-based temporal planner. InternationalJournal Artificial Intelligence Tools, 15 (5), 779802.Rankooh, M. F., & Ghassem-Sani, G. (2013). New encoding methods sat-based temporalplanning. Proceedings Twenty-Third International Conference AutomatedPlanning Scheduling, ICAPS 2013, Rome, Italy, June 10-14, 2013.Rintanen, J. (2006). Compact representation sets binary constraints. ECAI 2006,17th European Conference Artificial Intelligence, August 29 - September 1, 2006,Riva del Garda, Italy, Including Prestigious Applications Intelligent Systems (PAIS2006), Proceedings, pp. 143147.Rintanen, J. (2007). Complexity concurrent temporal planning. ProceedingsSeventeenth International Conference Automated Planning Scheduling, ICAPS2007, Providence, Rhode Island, USA, September 22-26, 2007, pp. 280287.Rintanen, J. (2012). Planning satisfiability: Heuristics. Artif. Intell., 193, 4586.Rintanen, J., & Gretton, C. O. (2013). Computing upper bounds lengths transitionsequences. IJCAI 2013, Proceedings 23rd International Joint ConferenceArtificial Intelligence, Beijing, China, August 3-9, 2013.Rintanen, J., Heljanko, K., & Niemela, I. (2006). Planning satisfiability: parallel plansalgorithms plan search. Artif. Intell., 170 (12-13), 10311080.Robinson, N., Gretton, C., Pham, D. N., & Sattar, A. (2009). Sat-based parallel planningusing split representation actions. Proceedings 19th International Conference Automated Planning Scheduling, ICAPS 2009, Thessaloniki, Greece,September 19-23, 2009.Robinson, N., Gretton, C., Pham, D. N., & Sattar, A. (2010). Partial weighted MaxSAToptimal planning. PRICAI 2010: Trends Artificial Intelligence, 11th PacificRim International Conference Artificial Intelligence, Daegu, Korea, August 30September 2, 2010. Proceedings, pp. 231243.Shin, J.-A., & Davis, E. (2005). Processes continuous change SAT-based planner.Artif. Intell., 166 (1-2), 194253.Smith, D. E., & Weld, D. S. (1999). Temporal planning mutual exclusion reasoning.Proceedings Sixteenth International Joint Conference Artificial Intelligence,IJCAI 99, Stockholm, Sweden, July 31 - August 6, 1999. 2 Volumes, 1450 pages, pp.326337.Streeter, M. J., & Smith, S. F. (2007). Using decision procedures efficiently optimization.Proceedings Seventeenth International Conference Automated PlanningScheduling, ICAPS 2007, Providence, Rhode Island, USA, September 22-26, 2007,pp. 312319.631fiRankooh & Ghassem-SaniVidal, V. (2014). Yahsp3 Yahsp3-mt 8th international planning competition.International Planning Competition.Vidal, V., & Geffner, H. (2006). Branching pruning: optimal temporal POCLplanner based constraint programming. Artif. Intell., 170 (3), 298335.Wehrle, M., & Rintanen, J. (2007). Planning satisfiability relaxed -Step plans.AI 2007: Advances Artificial Intelligence, 20th Australian Joint ConferenceArtificial Intelligence, Gold Coast, Australia, December 2-6, 2007, Proceedings, pp.244253.Younes, H. L. S., & Simmons, R. G. (2003). VHPOP: Versatile heuristic partial orderplanner. J. Artif. Intell. Res. (JAIR), 20, 405430.632fiJournal Artificial Intelligence Research 53 (2015) 315374Submitted 09/14; published 07/15Regular Path Queries Lightweight Description Logics:Complexity AlgorithmsMeghyn Bienvenumeghyn@lri.frLaboratoire de Recherche en Informatique,CNRS & Universite Paris-Sud, FranceMagdalena OrtizMantas Simkusortiz@kr.tuwien.ac.atsimkus@dbai.tuwien.ac.atInstitute Information Systems,TU Wien, AustriaAbstractConjunctive regular path queries expressive extension well-known classconjunctive queries. queries extensively studied (graph) databasecommunity, since support controlled form recursion enable sophisticated pathnavigation. Somewhat surprisingly, little work aimed using queriescontext description logic (DL) knowledge bases, particularly lightweightDLs considered best suited data-intensive applications. paper aimsbridge gap providing algorithms tight complexity bounds answering twoway conjunctive regular path queries DL knowledge bases formulated lightweightDLs DL-Lite EL families. results demonstrate data complexity,cost moving richer query language low one could wish for:problem NL-complete DL-Lite P-complete EL. combined complexityquery answering increases NP- PSpace-complete, two-way regular pathqueries (without conjunction), show query answering tractable even respectcombined complexity. results reveal two-way conjunctive regular path queriespromising language querying data enriched ontologies formulated DLsDL-Lite EL families corresponding OWL 2 QL EL profiles.1. IntroductionRecent years seen rapidly growing interest using description logic (DL) ontologiesquery instance data. setting seen generalization related problemquerying graph databases which, like DL instance data, sets ground facts usingunary binary predicates, i.e., node- edge-labeled graphs (Consens & Mendelzon,1990; Barcelo, Libkin, Lin, & Wood, 2012). relevance problems liesfact many application areas, data naturally represented form.applies, particular, XML RDF data. presence DL ontology,domain knowledge expressed ontology exploited querying data,facilitate query formulation provide users complete answersqueries. DL database communities share common research goals,research agendas pursued differ significantly. DL research, focusstudying computational complexity answering (unions of) plain conjunctivequeries (CQs) presence ontological constraints expressed different DLs,c2015AI Access Foundation. rights reserved.fiBienvenu, Ortiz, & Simkusdevelopment efficient algorithms setting, see surveys Ortiz (2013)Ortiz Simkus (2012). contrast, work graph databases typicallyconsider ontological knowledge, instead aims supporting expressive navigationalquery languages.Regular path queries (RPQs) constitute basic navigational query language. Formally, RPQ given regular language (represented regular expression finiteautomaton) binary predicates database facts (arc labels, roles DL parlance), returns pairs objects connected path whose label wordbelonging specified language. crucial feature queries allowcontrolled form recursion computationally well behaved yet sufficient expressing reachability queries traversal paths unbounded length (Florescu, Levy, &Suciu, 1998). two-way RPQs (2RPQs), regular expressions may use arc labelsbackwards direction, allows flexible path navigation. Notably, comescomputational cost: answering RPQs 2RPQs (plain) graph databasescomplete NL combined complexity (that is, complexity measuredterms whole input, case consists query data). Conjunctive (two-way) regular path queries (C(2)RPQs), one expressivepopular languages querying graph databases, simultaneously extend plain CQs(2)RPQs allowing conjunctions atoms share variables arbitrary ways,atoms may contain regular expressions navigate arcs database.consider data complexity measure (in complexity measuredterms size data, inputs considered fixed), answeringC2RPQs still NL-complete. combined complexity, C2RPQ answering problemNP-complete, fact lowest complexity could expected, givenCQ answering already NP-hard. note navigational capabilities providedRPQs extensions long considered crucial querying data Web.Indeed, navigation along regular paths heart XPath language queryingXML data (Berglund, Boag, Chamberlin, Fernandez, Kay, Robie, & Simeon, 2007),SPARQL 1.1, language recently recommended World Wide Web Consortium(W3C) new standard querying RDF data (Harris & Seaborne, 2013), addsprevious standard feature called property paths, roughly amounts extendingcore SPARQL CQs C2RPQs.comes surprise that, despite advantages relevance, RPQs extensions received rather little attention DL literature. first consideredseminal work Calvanese, de Giacomo, Lenzerini (1998) query answeringpresence DL ontologies. However, vast majority subsequent researchtargeted instance queries (IQs), conjunctive queries unions thereof, occasionallypositive first-order queries. handful works considered C2RPQs. Calvanese etal. (2014, 2007, 2009) showed C2RPQ answering 2ExpTime-complete combinedcomplexity expressive DLs1 ZIQ, ZIO, ZOQ, allow regularexpressions role constructors. upper bound shown containmentC2RPQs presence rich ontological knowledge (Calvanese et al., 2009).noteworthy since well-known fact forms recursion make query answer1. Z symbol introduced abbreviation ALCbSelfreg (Calvanese et al., 2009).316fiRegular Path Queries Lightweight Description Logicsing query containment undecidable presence ontological constraints (Levy &Rousset, 1996). Moreover, complexity higher significantlyrestricted settings, answering plain CQs DL ALCI (Lutz, 2008) positive first-order queries ALC (Ortiz & Simkus, 2014). However, hardness 2ExpTimenevertheless prohibitively high complexity many applications. Even data complexity, algorithms underlying aforementioned results still need exponential time.recently, algorithms answering C2RPQs Horn-SHOIQ Horn-SROIQproposed (Ortiz, Rudolph, & Simkus, 2011). algorithms run polynomial timesize data, may still require exponential time size ontology,worst-case optimal logics. contrast, lightweight DLs DL-Lite(Calvanese, De Giacomo, Lembo, Lenzerini, & Rosati, 2007) EL (Baader, Brandt, &Lutz, 2005) families, languages choice ontology-mediated query answering notably underlie OWL 2 QL EL profiles (Motik, Cuenca Grau, Horrocks,Wu, Fokoue, & Lutz, 2012), precise complexity answering C2RPQs left open:ExpTime upper bound combined complexity expressive Horn DLsmatch NP lower bound stemming answering plain CQs, apparentobtain better upper bounds C2RPQs adapting existing techniques.DL-Lite family, data complexity also left open, gap NL-hardnessRPQ answering inherited graph database setting P upper boundestablished expressive Horn DLs.paper, close open questions presenting algorithms precise complexity bounds answering (C)2RPQs EL DL-Lite families lightweight DLs.Many results first announced conference version paper (Bienvenu,Ortiz, & Simkus, 2013), provide full proofs results, additional examples, discussion extensions results applicability OWL 2profiles. also strengthen complexity lower bounds considering restricted classes queries (Proposition 4.5) succinct representations (Theorem 4.2)identify interesting restrictions lead better combined complexity C2RPQs(Theorems 6.10 6.11). main contributions summarized follows:establish P lower bound combined complexity answering 2RPQsDL-Lite, well RPQs DL-LiteR , contrasted NLcompleteness instance checking logics. result improves upon similarlower bound conference version paper adopting (less succinct)regular expression representation queries.present algorithm answering 2RPQs DL-LiteR ELH knowledgebases runs polynomial time combined complexity. tractability resultextended single-atom C2RPQs, including existential variables.show answering CRPQs PSpace-hard DL-Lite EL. resultalready shown conference version, provide differentproof holds even structurally-restricted class strongly acyclic CRPQsregular expressions disjunction-free star-height two.hardness result interesting compared graph database setting,317fiBienvenu, Ortiz, & SimkusC2RPQ answering NP-complete (and thus harder CQs worst case)becomes feasible polynomial time restricted strongly acyclic C2RPQs.develop query rewriting procedure answering C2RPQs DL-LiteRELH, use show problem feasible PSpace logics.PSpace upper bound ELH especially interesting, since C2RPQs allowinverse roles well known adding inverse roles EL immediately leadsExpTime-hardness query answering, even instance queries. result demonstrates including inverses query language, rather ontologylanguage, possible obtain algorithms use polynomial space.Using algorithm, derive NL upper bound data complexity DLLiteR P upper bound ELH. cases, lowest data complexitycould expected light existing results.also identify cases C2RPQ answering feasible NP, thus harderanswering plain CQs. case queries whose existential variablesoccur joins (or occur joins restricted way), arbitrary C2RPQswhenever ontology guaranteed finite canonical model.new complexity results (and relevant existing results) summarized Figure 1.paper organized follows. begin Section 2 introducing lightweightdescription logics DL-LiteR ELH (and relevant sublogics) recalling basicnotions related regular languages computational complexity. Section 3, definesyntax semantics different types path queries considered paper.Section 4 dedicated showing lower bounds, first RPQs CRPQs.cases, start presenting easy bounds follow known results,moving main results. Section 5 presents algorithmic techniques upper bounds2RPQs, Section 6, show extended handle C2RPQs.Section 7, give brief overview related results similar query languagesDLs discuss applicability results profiles OWL Web OntologyLanguage. Conclusions directions future work given Section 8. improvereadability paper, one technical proofs deferred appendix.2. Preliminariesbriefly recall basics description logics, computational complexity classesrelevant paper, notation regular languages.2.1 Description Logicsfirst recall syntax semantics description logics, focusing lightweightfamilies logics DL-Lite (Calvanese et al., 2007) EL (Baader et al., 2005). alsorecall definition canonical model logics.318fiRegular Path Queries Lightweight Description LogicsIQDL-LiteRDFSDL-Lite(R)EL(H)datacombineddataAC0NL-cNL-cNL-c(A)(A)Thm 5.2AC0NL-cNL-cP-c(G)(G)Thm 5.9Thm 4.2, Thm 5.9P-cP-cP-cP-c(E)(C)Thm 5.9Thm 5.9CQDL-LiteRDFSDL-Lite(R)EL(H)(2)RPQcombinedC(2)RPQcombineddatacombineddataAC0NP-cNL-cNP-c(B)Thm 6.8Thm 6.8AC0NP-cNL-cPSpace-c(D)(D)Thm 6.8Prop 4.5, Thm 6.8P-cNP-cP-cPSpace-c(F)(F)Thm 6.8Prop 4.5, Thm 6.8Figure 1: Complexity query answering. c indicates completeness results,used upper lower bounds respectively. New results marked bold.remaining annotations following meanings:P-hardness RPQs applies DL-LiteR(A) Easy reduction NL-complete directed reachability problem(B) Follows NP-hardness CQ answering relational databases(C) Baader et al. (2005)(D) Calvanese et al. (2007)(E) Calvanese, De Giacomo, Lembo, Lenzerini, Rosati (2006)(F) Rosati (2007), Krisnadhi Lutz (2007), Krotzsch Rudolph (2007)(G) Calvanese et al. (2007), Artale, Calvanese, Kontchakov, Zakharyaschev (2009)2.1.1 Description Logic Syntaxusual, assume countably infinite, mutually disjoint sets NC , NR , NI conceptnames, role names, individuals, respectively. inverse role takes form rr NR . use NR refer NR {r | r NR }, R NR , use R meanr R = r r R = r .description logic knowledge base (KB) K = (T , A) consists TBoxABox A. former provides general domain knowledge, latter expresses facts319fiBienvenu, Ortiz, & Simkusparticular entities. Sometimes use generic terms ontology data(set)place TBox ABox.Formally, TBox finite set inclusions, whose form depends DL question.DL-Lite, TBoxes consist set concept inclusions form B v C, BC concepts constructed according following syntax:B := | RC := B | BNC R NR . DL-LiteR additionally allows role inclusions formR1 v ()R2 , R1 , R2 NR . logic DL-LiteRDFS obtained DL-LiteRdisallowing inclusions contain negation existential concepts (R) righthand side. DL-LiteR basis OWL 2 QL profile, DL-LiteRDFS correspondsfragment DL-LiteR expressible RDF Schema ontology language(Brickley & Guha, 2014).EL, concept inclusions form C1 v C2 C1 , C2 complex conceptsconstructed according following syntax:C := > | | C u C | r.CNC r NR . DL ELH additionally allows role inclusions formr1 v r2 , r1 , r2 NR . Note EL(H) TBoxes, inverse roles permitted.use sig(T ) denote signature TBox , is, set conceptrole names appearing . also prove useful introduce set BCT basicconcepts TBox , defined follows: BCT = (NC sig(T )){r, r | r NR sig(T )}DL-LiteR TBox, BCT = (NC sig(T )) {>} ELH TBox.considered DLs, ABox finite set concept assertions formA(b) role assertions form r(b, c), NC , r NR , b, c NI . useInd(A) refer set individuals appearing ABox A.2.1.2 Description Logic Semanticssemantics DL KBs defined terms interpretations, take form =(I , ), non-empty set maps individual NI aI ,concept name NC AI , role name r NR rI .function extended general concepts roles follows:>I =(A)I = \ AI(R)I = (I ) \ RI(r )I = {(c, d) | (d, c) rI }(R)I = {c | : (c, d) RI }(r.C)I = {c | : (c, d) rI , C }interpretation satisfies inclusion G v H, denoted |= G v H, GI H .Similarly, satisfies assertion A(a) aI AI , symbols |= A(a); satisfiesassertion r(a, b) (aI , bI ) rI , symbols |= r(a, b). interpretation model, satisfies inclusions ; model satisfies assertions A;model (T , A) model A. KB (T , A) satisfiablepossesses least one model, else unsatisfiable. Note ELH knowledge bases320fiRegular Path Queries Lightweight Description Logicstramway:T1sbHFTTramwayLinestop:cathSqFTbsubway:U1SubwayLinesbHSuFTsbSubLFlocIntheater:VolkstheatersbLFTlocInpark:huberParkPark,FamFriendlylocIntheater:operalocInlocInpark:cityParklocIntrainSt:ViennaCentertrainStationEquipStopplaygr:cityParkPlaygroundParklocInCafe:SacherCafeTheaterGLStopstop:trainStationCafe:HawelkaCafeTheaterGLStopstop:cityParklocInSquareEquipStopFsbLTramwayLinestop:Volkstheaterstop:operasbSubsbtramway:T2square:cathSqStopsbHsblocInlocInshopping:cityMallShoppingCenterFigure 2: Example ABox Amobalways satisfiable. G TBox, ABox, KB, inclusion assertion, sayG entails , written G |= , |= every model G.Observe make Unique Names Assumption (UNA), definitioninterpretation allows distinct individuals mapped domain element.remark however results paper hold equally well UNA.Example 2.1. motivating example, consider domain public transporturban mobility. partial database domain presented Figure 2. nodestwo leftmost columns (shaded blue) correspond public transport lines stations.arrows represent existing connections, labeled accordingtype transport line serving them: sbSub stands served subway, sbLFTsbHFT respectively stand served low-floor tramway served high-floortramway. Nodes also labeled classes participate. particular,labels GLStop EquipStop indicate two specific kinds public transport stops: groundlevel stops, stops suitably equipped ramps elevators passengersrestricted mobility. remaining columns contain places interest, locInlabeled arrows represent located relation. Note nothingelse graphical representation DL ABox, call Amob , labelnode b corresponds concept assertion A(b), arc labeled r node bnode c corresponds role assertion r(b, c).example, assume information first two columns providedmaintained local public transport authorities, thus complete well structured.contrast, remaining data crowd-sourced, thus likely incomplete mayadhere rigid, predefined structure.order better respond user queries, data enriched domain knowledgeexpressed EL ontology Figure 3. ontology defines subclass relationsconcepts like stop specialized accessible stop, ground-level stop,defines new terms present data may useful query time,food services. also enhances possibly incomplete data asserting existenceplaces interest. example, family-friendly location diningplayground facilities.321fiBienvenu, Ortiz, & Simkus(1) accessible stop (AccStop) public transport stop (Stop). ground-level stop (GLStop)stop suitably equipped rampselevators (EquipStop) accessible stop.(2) Restaurants cafes food services(FoodServ).(3) place family friendly (FamFriendly)food service playground.AccStop v Stop(1a)GLStop v AccStop(1b)EquipStop v AccStop(1c)Restaurant v FoodServ(2a)Cafe v FoodServ(2b)FamFriendly v hasFacility.FoodServ(3a)FamFriendly v hasFacility.Playground (3b)ShoppingCenter v hasFacility.Foodcourt(4a)(4) shopping center supermarketShoppingCenter v hasFacility.Supermarket (4b)food court.Foodcourt v hasFacility.FoodServ(5) food court food service.(5a)Figure 3: Example DL-Lite TBox Tmob expressing domain knowledgekeep example compact, chosen write example ontology EL,knowledge expressed DL-LiteR using auxiliary roles simulateconcept inclusions qualified existential quantification right-hand-side.instance, concept inclusion (3a) replaced following three inclusionssyntax DL-Lite:FamFriendly v hasFoodServhasFoodServ v FoodServhasFoodServ v hasFacilitysimilarly (3b), (4a), (4b), (5a).2.1.3 Normal Form ELH TBoxessimplify presentation, assume throughout paper ELH TBoxesnormal form, meaning concept inclusions one following forms:AvBv r.B1 u A2 v Br.B vA, A1 , A2 , B NC {>}. following well-known property (see (Baader et al., 2005))shows assumption without loss generality.Proposition 2.2. every ELH TBox , one construct polynomial time ELHTBox 0 normal form (possibly using new concept names) 0 modelconservative extension , is, every model 0 model , every model, model 0 0 0 domain coincideinterpretation concept role names except sig(T 0 ) \ sig(T ).322fiRegular Path Queries Lightweight Description Logics2.1.4 Canonical ModelsCanonical models key technical tool used study lightweight description logics,use proofs many results.recall definition canonical model ,A (alternatively denoted IK )satisfiable DL-LiteR ELH KB K = (T , A). domain ,A consists sequencesform aR1 C1 . . . Rn Cn (n 0), Ind(A), Ci concept, Ri(possibly inverse) role. exact definition depends logic consider:(A) DL-LiteR TBox, domain ,A contains exactly sequencesaR1 R1 . . . Rn Rn satisfy:n 1, , |= R1 (a)1 < n, |= Ri v Ri+1 .(B) ELH TBox,2 domain ,A contains exactly sequencesar1 A1 . . . rn ri NR , and:n 1, , |= r1 .A1 (a);1 < n, |= Ai v ri+1 .Ai+1 .elements e ,A \ Ind(A), use notation Tail(e) denote final concepte. set TCT tail concepts TBox defined follows: TCT = {r, r | rNR sig(T )} DL-LiteR TBox, TCT = BCT = (NC sig(T )) {>}ELH TBox. Clearly, e ,A \ Ind(A), Tail(e) TCT .complete definition ,A , must fix interpretation individualnames, concept names, role names. done follows:AIT ,A = {a Ind(A) | , |= A(a)} {e ,A \ Ind(A) | |= Tail(e) v A}rIT ,A = {(a, b) | , |= r(a, b)} {(e1 , e2 ) | e2 = e1 C |= v r}{(e2 , e1 ) | e2 = e1 C |= v r }aIT ,A =Ind(A)Note ,A composed core consisting ABox individuals anonymous part consisting (possibly infinite) trees rooted ABox individuals.use ,A |e denote submodel ,A obtained restricting domainelements containing e prefix. Observe that, construction, ,A |e ,A |e0isomorphic whenever Tail(e) = Tail(e0 ).verified IK |= K every satisfiable KB K. Moreover, well knowncanonical model IK homomorphically embedded model K.Example 2.3. canonical model (Tmob , Amob ) Example 2.1 depicted Figure 4. satisfy existential restrictions inclusions (3a) (5a) Tmob ,2. Recall throughout paper, assume ELH KBs normal form, reason,need consider existential concepts form r.A NC {>}.323fiBienvenu, Ortiz, & Simkustramway:T1sbHFTTramwayLinestop:cathSqbsubway:U1SubwayLinesbHFTsbSubLFFTTramwayLinestop:VolkstheaterlocIntheater:VolkstheaterPark,FamFriendlylo csbLFTstop:trainStationlocInhasFacilitye1FoodServGLStop,AccStop,Stoppark:huberParkhasFacilitystop:cityParksbLlocInTheaterGLStop,AccStop,StopEquipStop,AccStop,Stopsbtramway:T2Cafe,FoodServstop:operasbSubCafe:HawelkaSquareFTSulocInsquare:cathSqStopsbHsblocIntheater:operae2PlaygroundlocInCafe:SacherCafe,FoodServTheaterEquipStop,AccStop,StoplocInlocpark:cityParkplaygr:cityParkParkPlaygroundtrainSt:ViennaCenterlocInshopping:cityMalltrainStationShoppingCenterhasFacilitye3FoodcourthasFacilitye4SupermarkethasFacilitye5FoodServFigure 4: Canonical model ITmob ,Amob KB (Tmob , Amob )canonical model contains following five anonymous elements e1 , . . . e5 , form twotree-shaped structures rooted nodes park:huberPark shopping:cityMall:e1 = park:huberPark hasFacility FoodServe2 = park:huberPark hasFacility Playgrounde3 = shopping:cityMall hasFacility Foodcourte4 = shopping:cityMall hasFacility Supermarkete5 = shopping:cityMall hasFacility Foodcourt hasFacility FoodServExample 2.4. illustrate canonical models infinite, present Figure 5simple DL-LiteR knowledge base (T , A) depiction canonical model ,A .preceding example, use names ei abbreviations anonymous objects,A . Note tree rooted b2 infinite, since every object belongsconcept B r-child also belongs B.2.2 Regular Languagesassume reader familiar regular languages, represented either regularexpressions nondeterministic finite state automata (NFAs). Regular expressions Ealphabet defined grammarE | | E E | E E | Edenotes empty word (i.e., sequence length 0). NFAalphabet tuple = (S, , , s0 , F ), finite set states,324fiRegular Path Queries Lightweight Description LogicsB,rbB v r,B v r1 ,r v B,r1 v r2e1}e11= { r(a, b), r2 (b, c), D(b) }e2Brr1 , r2Be12r1 , r2re111cr1 , r2r={r2e112B...Figure 5: Example DL-LiteR knowledge base (T , A) canonical model ,Atransition relation, s0 initial state, F set final states. use L(E)(resp. L()) denote language defined regular expression E (resp. NFA ).recall NFAs exponentially succinct regular expressions,exists polynomial translation regular expressions equivalent NFAs,translation NFAs regular expressions may incur exponential blowup (Ehrenfeucht& Zeiger, 1974). Thus, ensure complexity results hold regardless chosenrepresentation, prove complexity lower bounds using regular expressionrepresentation, upper bounds, adopt NFA representation.2.3 Computational Complexityassume familiarity standard complexity classes, NL (problems solvablenon-deterministic logarithmic space), P (problems solvable polynomial time), NP (problems solvable non-deterministic polynomial time), PSpace (problems solvable polynomial space), NPspace (problems solvable non-deterministic polynomial space).recall Savitchs theorem, NPspace = PSpace. shall also consider oracle classes NLNL NLP consisting problems solvable non-deterministiclogarithmic space given access NL (respectively, P) oracle. well-knownNLNL = NL NLP = P. circuit complexity class AC0 mentionedFigure 1 comprises problems computed family unbounded fan-in circuitsconstant depth polynomial size. preceding classes ordered follows:AC0 ( NL P NP PSpaceprecise definitions complexity classes, standard notions computational complexity, refer reader recent textbook Arora Barak (2009)references therein.3. Path Queriessection, introduce different query languages considered paperdefine relevant computational problems.325fiBienvenu, Ortiz, & Simkusq1 (x, y) = AccStop? (sbSub sbSub ) (sbLFT sbLFT ) AccStop?(x, y)q2 (x, y) = z1 , z2 . AccStop? (sbSub sbSub ) (sbLFT sbLFT ) AccStop?(x, y)locIn (locIn ) hasFacility FoodServ? (x, z1 )locIn (locIn ) hasFacility Playground? (y, z2 )Figure 6: Example queries3.1 Syntax Path Queriesconjunctive (two-way) regular path query (C2RPQ) form q(~x) = ~y . ~x~y disjoint tuples variables, conjunction atoms forms:(i) A(t), NC NI ~x ~y(ii) (t, t0 ), NFA regular expression defining regular language0x ~yNR {A? | NC }, t, NI ~usual, variables individuals called terms, variables ~x called answervariables, variables ~y called quantified variables. use terms(q), vars(q),avars(q), qvars(q) refer respectively sets terms, variables, answer variables,quantified variables appearing query q. query answer variables calledBoolean query. Note convenient treat query set atoms.Conjunctive (one-way) regular path queries (CRPQs) obtained disallowing symbols NR \ NR atoms type (ii), conjunctive queries (CQs) resultallowing type (ii) atoms form r(t, t0 ) r NR . Two-way regular path queries(2RPQs) consist single atom type (ii) t0 answer variables.Regular path queries (RPQs) 2RPQs use symbols NR \NR . Finally,instance queries (IQs) take form A(x) NC , r(x, y) r NR .Note sometimes prove convenient treat queries sets atoms, usingnotation q indicate atom q.Example 3.1. Figure 6 shows two example queries. 2RPQ q1 retrieves pairs x,public transport stops accessible connection, is, xaccessible stops, public transport route uses subwaylow-floor tramway. query q2 retrieves pairs x, public transport stopsaccessible connection (as q1 ) place eat location xplayground location y.Note using Kleene star ( ), query services restaurantsplaygrounds available location without take care different waysplaces related. example, restaurant could locationstop, could food court inside shopping centerlocation stop. cases, q2 correctly identifies food servicelocation. useful feature RPQs extensions, particularly casesdata comply rigid schema.326fiRegular Path Queries Lightweight Description Logics3.2 Semantics Path Queriesproceed define semantics C2RPQs. Given interpretation I, pathe0 en sequence e0 u1 e1 u2 . . . un en n 0 every ei element, every ui symbol NR {A? | NC }, every 1 n:ui = A?, ei1 = ei AI ;ui = R NR , (ei1 , ei ) R .label (p) path p = e0 u1 e1 u2 . . . un en word u1 u2 . . . un . Note p = e0 ,define (p) .every language L NR {A? | NC }, semantics L w.r.t. interpretation defined follows:LI = {(e0 , en ) | path p e0 en (p) L}match C2RPQ q interpretation mapping terms qelements(c) = cI c NI ,(t) AI atom A(t) q,((t), (t0 )) L()I (t, t0 ) q.Given C2RPQ q answer variables x1 , . . . , xk , say tuple individuals(a1 , . . . , ak ) Ind(A) certain answer q w.r.t. KB K = (T , A) caseevery model K match q (vi ) = aIi every 1 k.use cert(q, K) denote set certain answers q w.r.t. KB K. Noteq Boolean query, either cert(q, K) = {()} (where () denotes empty tuple)cert(q, K) = . former case, say q entailed K, write K |= q.remark normal form ELH TBoxes also assumed without lossgenerality query answering. Indeed, always assume fresh symbolsTBox 0 normal form occur q, follows Proposition 2.2definition certain answers cert(q, (T , A)) = cert(q, (T 0 , A)) every C2RPQ quse symbols sig(T 0 ) \ sig(T ).definition certain answers involves models KB, DLs considered paper, fact sufficient look matches canonical model.Lemma 3.2. every DL-LiteR ELH KB K = (T , A), C2RPQ q(~x) arity k,k-tuple ~a individuals A: ~a cert(q, K) match q IK(~x) = ~a.Proof sketch. well known canonical model IK homomorphically embedded model K (Calvanese et al., 2007; Rosati, 2007; Krisnadhi & Lutz, 2007;Krotzsch & Rudolph, 2007). follows whenever query matches preservedhomomorphisms, existence match IK implies existence match everymodel. often observed CQs, applies equally well C2RPQs (Calvanese et al., 2014; Ortiz et al., 2011). Since converse trivially true, certain answerscoincide answers canonical model.327fiBienvenu, Ortiz, & Simkuss0s0rrs0e1 s01bcs0frxe2rs0 sfrs0 s2r1e11e12s0:s00r1s1r2s2rsfrs01rs0fre111:rs00re112zr2e1111s1 e1112...Figure 7: match witnessing cert(q, K) q K Example 3.4Example 3.3. urban mobility example, stop cathedral squareknown accessible (i.e., AccStop(stop:cathSq) entailed (Tmob , Amob )), hencestop:cathSq cannot participate match q1 . stop theater accessible,connected stops via high-floor tramway. Thus stop:Volkstheaterparticipates one mapping q1 ITmob ,Amob , namely (x) = (y) = stop:Volkstheater.Indeed, pathstop:Volkstheater AccStop? stop:Volkstheater AccStop? stop:Volkstheaterwitnesses (stop:Volkstheater, stop:Volkstheater) LI1 language L1 specified q1 ,longer path starting ending stop:Volkstheater whose label belongs L1 .stops stop:opera, stop:cityPark, stop:trainStation accessible mutually connected via accessible public transport (i.e., subway low-floor tramway lines). Hence,find path pair whose label L1 , pairs certainanswers q1 . Thus cert(q1 , (Tmob , Amob )) contains (stop:Volkstheater, stop:Volkstheater),pairs stops involving stop:opera, stop:cityPark, stop:trainStation.certain answers q2 precisely pairs (s1 , s2 ) stops answerq1 food service location s1 playground locations2 . Since ITmob ,Amob , find food service playground location stop:Volkstheater, (stop:Volkstheater, stop:Volkstheater) cert(q2 , (Tmob , Amob )).also find food services locations stop:opera stop:trainStation, playground location stop:cityPark, hence cert(q2 , (Tmob , Amob )) also contains pairs(stop:opera, stop:cityPark) (stop:trainStation, stop:cityPark).Example 3.4. also give example query KB (T , A) Figure 5:q(x) = y, z. r r1 r2 r (x, y) r r (y, z) D(z)cert(q, K) = {a, b}. see certain answer, consider mapping(x) = a, (y) = e11 , (z) = b. path arbre1 re11 re111 r1 e1112 r2 e111 r e11 witnesses(a, e11 ) L(r r1 r2 r )IT ,A , path e11 r e1 r b witnesses (e11 , b)328fiRegular Path Queries Lightweight Description LogicsL(r r )IT ,A . Since b DIT ,A , mapping match q. match depictedFigure 7. see b also certain answer, consider 0 (x) = 0 (z) = b 0 (y) =e11 , observe 0 also match bre1 re11 re111 r1 e1112 r2 e111 r e11 witnesses(b, e11 ) L(r r1 r2 r )IT ,A .Note matches, mapped element anonymous part,match mapping individual. illustrates anonymous elements may playdecisive role query answering, every complete query answering algorithm mustconsider possible matches possibly infinite anonymous part canonical models.3.3 Computational Problemspaper, interested problem computing certain answersC2RPQs, precisely, associated decision problem determining whethergiven tuple certain answer query. follows, query language Q{IQ, CQ, RPQ, CRPQ, 2RPQ, C2RPQ}, use term Q answering referproblem deciding given KB K, tuple ~a, query q Q, whether ~a cert(q, K).different ways measuring complexity query answering, dependingthree parameters problem (T , A, q) considered inputsconsidered fixed. work, consider two commonly used measures:combined complexity data complexity. Combined complexity treats three parametersinputs, complexity measured respect total size |T | + |A| + |q| (we use| | denote size object, e.g. length string representation accordingsuitable encoding). Data complexity takes input assumes q fixed,complexity measured respect |A|, |T | |q| treated constants.4. Lower Boundssection, establish required complexity lower bounds. beginlower bounds RPQs straightforwardly obtained existing results.Proposition 4.1. RPQ answering1. NL-hard data complexity DL-LiteRDFS ;2. P-hard data complexity EL;Proof. Statement (1) follows analogous result graph databases (Consens &Mendelzon, 1990). shown simple reduction NL-complete directedreachability problem: vertex b reachable vertex directed graph G(a, b) certain answer RPQ r (x, y) w.r.t. KB (, AG ),AG = {r(v1 , v2 ) | directed edge v1 v2 G}.Statement (2) direct consequence P-hardness data complexity instancechecking EL (Calvanese et al., 2006), since instance query A(x) computedusing RPQ A?(x, y).case DL-Lite, establish P lower bound 2RPQs, contrastsNL-completeness instance checking. remark similar result given329fiBienvenu, Ortiz, & Simkusconference version paper (Bienvenu et al., 2013), reduction requiredNFA representation regular language query. complexity 2RPQs using(less succinct) regular expression representation left open resolvedfollowing theorem.Theorem 4.2. 2RPQ answering P-hard combined complexity DL-Lite.Proof. give reduction P-complete entailment problem propositional definite Horn theories. Without loss generality, suppose given propositionalHorn theory variables v1 , . . . , vn consistsset rules = vi1 vi2 vi3 (1 m)single initialization fact: v1 , v1 6= vnIndeed, arbitrary propositional definite Horn theory 0 transformedtheory preceding form follows: take fresh variable v1 appearing 0 , addv1 body every rule 0 , add fact v1 , finally perform standard syntacticmanipulations (possibly introducing additional fresh variables) ensure rulesinitialization fact v1 contain exactly two body variables.follows, show construct, given propositional Horn theoryform above, DL-Lite KB K = (T , A) Boolean 2RPQ q K |= q|= vn . first provide informal description reduction, presentformally. well known, |= vn case exists proof tree vn, defined binary tree node labeled variablev1 , . . . , vn following conditions satisfied: (i) root labeledvn , (ii) leaves labeled v1 , (iii) inner node d, labeled vk ,rule vk = vi3 two children labeledvi1 vi2 , respectively. existence node-labeled proof tree describedequivalent existence edge-labeled proof tree 0 , defined sibling-orderedbinary tree whose edges labeled rules follows. First, two edgesoutgoing root labeled rule vi3 = vn . non-root node d``-th child parent d, ` {1, 2}, edge (d, d` ) labeled ,either vi` = v1 , d` two outgoing edges E1 E2 labeledrule j vj3 = vi` .next show construct K q K |= q existsedge-labeled proof tree 0 vn . Roughly speaking, use K generateanonymous part tree contains possible edge-labeled proof trees. Sinceproof trees based upon sibling-ordered trees, need distinguish firstsecond children node, use two roles ri,1 ri,2 rule .edge-labeled proof tree 0 thus map subtree IK structure,label replaced either ri,1 ri,2 , depending whether edge leads firstsecond child parent node. use 2RPQ q determine whether IK actuallycontains subtree. intuition every path witnesses satisfactionq corresponds complete depth-first traversal (the representation of) valid edgelabeled proof tree starts ends root, left subtree nodealways visited right one.330fiRegular Path Queries Lightweight Description LogicsE =([1imri,1 )[1imri,1[kF1(rk,1rk,2 )[kF2[(rk,2(ri,2) (1im[(ri,1ri,2 ) ))1imFigure 8: Regular expression used proof Theorem 4.2.ABox consists single assertion A(a), TBox contains followingconcept inclusions:v ri,` , ` {1, 2} 1 vi3 = vnri,`v rk,j , `, j {1, 2} 1 i, k vi` = vk3` {1, 2}, define setF` = {k | 1 k m, vk` = v1 }.Intuitively, F` contains index rule turn back since `-th variableinitial variable v1 , (and corresponding child node proof tree wouldleaf). use F1 F2 define regular expression E Figure 8, usedefine following 2RPQ:q = E(a, a).prove correctness reduction.() Suppose K |= q. Lemma 3.2, match q canonicalmodel IK K. means (a, a) = (aIK , aIK ) L(E)IK , exists pathe0 1 . . . p ep IK whose label L(E) e0 = ep = a.Claim 1. every 2 j p:1. j = ri,1 , exists j 0 > j j 0 = ri,2.2. j = ri,2, exists j 0 < j j 0 = ri,1.3. j = ri,16 F1 , j1 = ri0 ,2 vi03 = vi1 .4. j = ri,26 F2 , j1 = ri0 ,2 vi03 = vi2 .Proof claim. Point 1, remark IK roles directed awayABox; formally, every role name s, (g, g 0 ) sIK , g 0 = gss . followsj = ri,1 , ej = ej1 ri,1 ri,1. Since sequence elements ej , . . . , ep defines pathIK ej ep = a, continuity, must j0 > j ej0 1 = ejej0 = ej1 , case must j0 = ri,1. Next note structure Eensures every occurrence ri,1 immediately followed ri,2 . repeatingargument, substituting ri,2 ri,1 , find j 0 > j0 j 0 = ri,2.Point 2, use fact roles IK directed away ABox.Thus, j = ri,2, ej1 = ej ri,2 ri,2. sequence e0 , . . . , ej1 elements forms331fiBienvenu, Ortiz, & Simkuspath IK e0 = ej ri,2 ri,2. Thus, continuity, must exist j 0 < jej 0 = ej , ej 0 +1 = ej ri,2 ri,2, j 0 +1 = ri,2 . examining structure E,see occurrence ri,2 must immediately preceded ri,1, j 0 = ri,1.show Point 3, suppose j = ri,16 F1 . structure E ensuresIKpreceding symbol j1 takes form ri0 ,2 . thus (ej , ej1 ) ri,1(ej1 , ej2 ) riI0K,2 . using fact elements IK contain inverserole names, obtain ej2 = ej ri,1 ri,1ri0 ,2 ri0 ,2 . follows |= ri,1v ri0 ,2 ,case vi03 = vi1 .Finally, Point 4, suppose j = ri,26 F2 . Examining structureE, clear preceding symbol j1 must form ri0 ,2 ,IK(ej , ej1 ) ri,2(ej1 , ej2 ) riI0K,2 . means |= ri,2v ri0 ,2 , hencevi03 = vi2 . (end proof claim)easy see first symbol 1 must form ri,1 ,IKIK(e0 , e1 ) ri,1. Since e0 = a, (a, ari,1 ri,1) ri,1. implies |= v ri,1 ,hence vi3 = vn . Applying Points 1 2 preceding claim, find j, kj = ri,1k = ri,2. complete proof direction, establishfollowing claim.Claim 2. every 1 j p ` {1, 2}, j = ri,`, |= vi` .Proof claim. proceed induction j. base case, suppose j = ri,`,0j < j j 0 = ri0 ,`0 . follows Claim 1 F1 ` = 1.thus vi` = v1 , |= vi` trivially holds.induction step, suppose claim holds j < k, consider k = ri,`.consider three cases:F`Case 1: k = ri,`Since F` , vi` = v1 , |= vi` follows immediately.Case 2: k = ri,16 F1Point 3 Claim 1, k1 = ri0 ,2 vi03 = vi1 . Applying induction hypothesisk1 , obtain |= vi02 . Point 2 Claim 2, exists j < kj = ri0 ,1 . second application induction hypothesis yields |= vi01 .rule vi01 vi02 vi03 belongs , must also |= vi03 . since vi03 = vi1 ,obtain |= vi1 .Case 3: k = ri,26 F2use almost argument Case 2, except must use Point4 Claim 1, rather Point 3. (end proof claim)contains rule vi1 vi2 vi3 , follows Claim 2 |= vn .() |= vn , must exist edge-labeled proof tree 0 vndescribed beginning proof. define mapping f nodes 0domain elements ,A follows:332fiRegular Path Queries Lightweight Description Logicsf (d) = root 0 ;every non-root node d, first (resp., second) child parent dp(dp , d) labeled , f (d) = f (dp )ri,1 ri,1(resp. f (d) = f (dp )ri,2 ri,2).show following claim:Claim 3: every non-leaf node 0 , (f (d), f (d)) L(E)IT ,A .Proof claim. every non-leaf node d, consider depth-first traversal subtree0 rooted always visits left subtree node visiting right one,returns root. Let d1 , d2 , . . . , dn sequence nodes visitedtraversal, d1 = dn = d, every 2 n, let i1,i follows:i1,i = rj,1 di first child di1 (di1 , di ) labeled j ;i1,i = rj,2 di second child di1 (di1 , di ) labeled j ;i1,i = rj,1di1 first child di (di , di1 ) labeled j ;i1,i = rj,2di1 second child di (di , di1 ) labeled j .define path pd follows:pd = f (d1 )1,2 f (d2 )2,3 . . . n1,n f (dn )show claim, suffices show following every non-leaf node d:() pd path ,A (pd ) L(E).shown induction minimal distance leaf 0 . importantobservation that, ` {1, 2}, `th child d` node 0 leaf, edged` labeled , definition F` .order able easily argue words belong L(E), give namesrelevant subexpressions E:[E1 =ri,11imE2 =[(rk,1rk,2 )kF1E3 = ([ri,2)1imE4 = ([(ri,1ri,2 ) )1imE5 =[(rk,2(kF2[ri,2) (1im[(ri,1ri,2 ) )1imE6 =[1imri,1[kF1(rk,1rk,2 )[(rk,2([1imkF2333ri,2) ([(ri,1ri,2 ) ))1imfiBienvenu, Ortiz, & SimkusNote E5 = kF2 (rk,2E3 E4 ), E6 = (E1 E2 E5 ) , E = E1 E6 .ready prove (). base case, children leaves,let label edges children. construction ,A , f (d)ri,1 -child ri,2 -child, pd path ,A (pd ) = ri,1 ri,1ri,2 ri,2.children leaves, F1 F2 . thus ri,1 L(E1 ), ri,1 ri,2 L(E2 ),ri,2L(E5 ) = L( kF2 (rk,2E3 E4 )) (for latter, observe L(E3 ) L(E4 )).Using E6 = (E1 E2 E5 ) , get ri,1ri,2 ri,2L(E6 ), using E = E1 E6 , obtain(pd ) = ri,1 ri,1 ri,2 ri,2 L(E).induction step, let dL dR left right children respectively,let rule used label edges dL dR .construction ,A f , know f (dL ) ri,1 -child f (d) f (dR )ri,2 -child f (d). distinguish three cases:neither children dL dR leaf, know inductionhypothesis pdL pdR paths ,A start end f (dL )f (dR ) respectively {(pdL ), (pdR )} L(E). follows pd =f (d)ri,1 pdL ri,1f (d)ri,2 pdR ri,2f (d) path ,A . let kL (resp. kR ) labelLRlinking (resp. ) two children. Note construction, (pdL ) (resp.(pdL )) ends rkL ,1 (resp. rkL ,2 ). follows (pdL ) L(E1 E6 E5 )ri,2 ) ) final E5 , must select .subexpression E4 = ( 1im (ri,1choosing instantiate E4 ri,1 ri,2 instead, show (pdL ) ri,1ri,2L(E6 ). similar argument (pdR ) used show (pdR ) ri,2L(E6 ).therefore obtain (pd ) = ri,1 (pd1 ) ri,1ri,2 (pd1 ) ri,2L(E1 E6 E6 ) L(E).LRleaf is, apply induction hypothesis inferpdL path ,A starts ends f (dL ) (pdL ) L(E).using reasoning previous case, obtain (pdL ) ri,1ri,2RL(E6 ). leaf, follows F2 , hence ri,2 L(E5 ) (herechoose satisfy subexpressions E3 E4 E5 ). Putting together, find(pd ) = ri,1 (pd1 )ri,1ri,2 ri,2L(E1 E6 E5 ) L(E).LRleaf not, argument analogous previous case.(end proof claim)Since f (d) = root 0 , follows preceding claim (a, a)L(E)IT ,A , hence K |= q.DL-LiteR , strengthen Theorem 4.2 using role inclusions eliminate inverseroles query.Corollary 4.3. RPQ answering P-hard combined complexity DL-LiteR .Proof. Let q 2RPQ (T , A) DL-LiteR KB. inverse role r appearingq, introduce new role name rinv . let q 0 RPQ obtained replacingevery occurrence r query rinv , let 0 extensionrole inclusions r v rinv rinv v r new role name rinv . easy seecert(q, (T , A)) = cert(q 0 , (T 0 , A)).334fiRegular Path Queries Lightweight Description Logicsleave open whether RPQ answering DL-Lite P-hard combined complexity.next provide combined complexity lower bounds CRPQs. CRPQs generalize CQs, inherit NP lower bound well-known NP-hardness combinedcomplexity CQ answering relational databases (see (Abiteboul, Hull, & Vianu, 1995)):Proposition 4.4. CRPQ answering NP-hard combined complexity DL-LiteRDFS .DL-Lite EL, show CRPQ answering PSpace-hard combinedcomplexity, contrast CQ answering NP-complete. Interestingly, PSpacehardness holds even strong restrictions. particular, consider followingrestrictions shape query form regular languages query atoms:(Strong) acyclicity: C2RPQ q acyclic associated undirected graph Gq ={{t, t0 } | L(t, t0 ) q} acyclic. strongly acyclic additionally (i)contain atoms form L(t, t) (ii) every pair distinct atomsL1 (t1 , t01 ), L2 (t2 , t02 ), {t1 , t01 } =6 {t2 , t02 }.Disjunction-freeness star-height regular expressions: regular expressiondisjunction-free contain . star-height regular expressiondefined maximum nesting depth stars appearing regular expression.point graph database setting, (strong) acyclicity leads tractability:acyclic C2RPQs evaluated polynomial time combined complexity (Barceloet al., 2012), strongly C2RPQs, evaluation even done linear timesize database (Barcelo, 2013). contrast, following result shows strongacyclicity impact worst-case complexity CRPQ answering setting:Theorem 4.5. CRPQ answering PSpace-hard combined complexity DL-LiteEL. result applies even restriction strongly acyclic CRPQs whose regularlanguages given disjunction-free regular expressions star-height two.Proof. give reduction problem emptiness intersection arbitrarynumber regular languages, known PSpace-hard. result first shownKozen (1977) regular languages given deterministic NFAs. recently, Bala(2002) proved problem also PSpace-hard regular languages givendisjunction-free regular expressions star-height two. So, let E1 , . . . , En disjunctionfree regular expressions star-height two alphabet = {1 , . . . , }.use symbols role names, also use concept names B.reduction, consider following Boolean CRPQ:q = x1 , . . . , xn , y. A(x1 ) . . . A(xn ) E1 (x1 , y) . . . En (xn , y)Observe q satisfies restrictions proposition statement. KB, useABox = {A(a)} TBox whose form depends logic question.DL-Lite, use= {A v | } {i v j | , j }335fiBienvenu, Ortiz, & SimkusEL, use instead:= {A v B} {B v .B | }.Notice cases canonical model IK K = (T , A) consists infinite treerooted every element interpretation unique -child(and children). Thus, associate every domain element IKword given sequence role names encountered along unique patha, moreover, every word w find element ew sequencerole names path ew exactly w.claim L(E1 ) . . . L(En ) non-empty K |= q. see why, firstnote w L(E1 ) . . . L(En ), define match q canonical modelmapping variables x1 , . . . , xn ew . Conversely, q entailed K,match q IK . Since AIK = {a}, must (xi ) = every1 n. follows unique path (y) IK word belongsevery L(Ei ), means L(E1 ) . . . L(En ) non-empty.note proof preceding theorem conference version (Bienvenuet al., 2013) uses simpler query variables xi replaced atomsA(xi ) dropped. However, query strongly acyclic. also remarksimilar proof already used establish PSpace hardness CQs extensionELH allows regular role hierarchies (Krotzsch & Rudolph, 2007).5. Upper Bounds 2RPQsnext two sections, provide concrete query answering algorithms consideredclasses path queries DLs, leverage derive matching upper boundscomplexity lower bounds Section 4. technical developments presentedstages. begin section giving simple algorithm answering 2RPQs DLLiteRDFS . remainder section devoted showing algorithmextended handle DL-LiteR ELH. Afterwards, Section 6, introduce queryrewriting procedure that, combined algorithms present section,yields method answering C2RPQs.following section, assume binary atoms take form (t, t0 ),NFA NR {A? | NC }. without loss generality, since everyregular expression transformed equivalent NFA; examination standardtechnique constructing NFAs regular expressions (Thompson, 1968) revealstransformation fact performed deterministic logspace transducer.also useful introduce notation NFAs result changing initialfinal states NFA. follows, given NFA = (S, , , s0 , F ),use s,G denote NFA (S, , , s, G), i.e., NFA statestransitions initial state final states G. single final states0 , write s,s0 place s,{s0 } .336fiRegular Path Queries Lightweight Description LogicsAlgorithm BasicEvalInput: NFA = (S, , , s0 , F ) NR {A? | NC }, DL-LiteRDFS KB (T , A),(a, b) Ind(A) Ind(A)1. Initialize current = (a, s0 ) count = 0. Set max = |A| |S|.2. count < max current 6 {(b, sf ) | sf F }(a) Let current = (c, s).(b) Guess pair (d, s0 ) Ind(A) transition (s, , s0 )NR , verify , |= (c, d), return not.= A?, verify c = , |= A(c), return not.(c) Set current = (d, s0 ) increment count.3. current = (b, sf ) sf F , return yes. Else return no.Figure 9: Non-deterministic algorithm 2RPQ answering DL-LiteRDFS .5.1 Warm-up: 2RPQ Answering DL-LiteRDFSstandard technique answering 2RPQs absence ontology nondeterministically guess path pair individuals labeled wordspecified regular language. procedure made run logarithmic spacekeeping small portion path memory time.Figure 9, present simple non-deterministic algorithm BasicEval answering2RPQs DL-LiteRDFS knowledge bases implements idea. algorithm takesinput NFA = (S, , , s0 , F ), DL-LiteRDFS KB K = (T , A), pair individuals(a, b) A, decides whether (a, b) cert((x, y), K). Step 1, initialize currentpair (a, s0 ) counter count 0. also compute maximum value maxcounter, corresponds largest length path needs considered.every iteration loop (Step 2), start single pair (c, s) storedcurrent proceed guess new pair (d, s0 ) together transition form(s, , s0 ). idea would like append path guessed far,so, must ensure conditions paths satisfied. purposeentailment checks Step 2(b). applicable check succeeds, place (d, s0 )current increment count. exit loop reached maximumcounter value pair count takes form (b, sf ) sf final state. lattercase, managed guess path required properties, algorithmreturns yes.use counter ensures algorithm terminates, following proposition proves always outputs correct result.Proposition 5.1. every 2RPQ q = (x, y), DL-LiteRDFS KB K = (T , A), pairindividuals (a, b) Ind(A): (a, b) cert(q, K) executionBasicEval(, K, (a, b)) returns yes.337fiBienvenu, Ortiz, & SimkusProof. Consider 2RPQ q = (x, y) = (S, , , s0 , F ), DL-LiteRDFS KB K =(T , A), pair individuals (a, b) Ind(A).First suppose (a, b) cert(q, K). path p = e0 u1 . . . un en IKe0 = a, en = b, (p) L(). may assume without loss generalitypath shorter length p satisfies conditions. DL-LiteRDFSTBox, know IK = Ind(A), every ei Ind(A). Since (p) L(),find sequence states s0 s1 . . . sn sn F every 1 n,(si1 , ui , si ) . minimality assumption, know (ei , si ) 6= (ej , sj )6= j, sequence pairs (e0 , s0 )(e1 , s1 ) . . . (en , sn ) length |A| |S|.easily verified guessing sequence pairs, together correspondingtransitions (si1 , ui , si ), obtain execution BasicEval returns yes.direction, suppose execution BasicEval(, K, (a, b))returns yes, let (c0 , s0 )(a1 , s1 ) . . . (cn , sn ) sequence pairs guessedexecution. must c0 = a, cn = b, sn F . Moreover, every1 n, must exist transition (si1 , ui , si ) , |= ui (ci1 , ci )ui NR , ci1 = ci , |= A(ci ) ui = A?. follows sequencep = c0 u1 c1 . . . un cn path IK (p) L(), (c0 , cn ) = (a, b) cert(q, K).analyzing complexity procedure BasicEval, obtain NL upper bound,matches NL lower bound Proposition 4.1.Theorem 5.2. 2RPQ answering NL combined complexity DL-LiteRDFS .Proof. Proposition 5.1, know BasicEval decision procedure 2RPQ answering DL-LiteRDFS . see BasicEval runs non-deterministic logarithmic space,note (i) utilizing binary encoding, logarithmic space needed storevalue count, old new values current, guessed transition ,(ii) entailment checks 2(b) performed non-deterministic logarithmic space.latter follows fact instance checking NL combined complexitysuperlogic DL-LiteR (Calvanese et al., 2007).5.2 2RPQ Answering DL-LiteR ELHturn problem answering 2RPQs DL-LiteR ELH knowledge bases.following example shows basic evaluation algorithm used DL-LiteRDFSincomplete logics. Intuitively, problem lies fact algorithmconsiders paths along ABox individuals, whereas satisfy query may necessaryconsider paths pass anonymous part.Example 5.3. remaining paper, consider KB (T , A) ={B v r, r v B, B v r1 , r1 v r2 } = {r(a, b), r2 (b, c), D(b)} Example 2.4.example 2RPQ, consider q 0 (x, y) = (x, y), = hS, , , s0 , {sf }i= {s0 , s1 , s2 , sf }= {r, r1 , r2 , r }= {(s0 , r, s0 ), (s0 , r1 , s1 ), (s1 , r2 , s2 ), (s2 , r , sf )}338fiRegular Path Queries Lightweight Description Logicss0 sfrre1cbs0 s2r2r1rxs1 e2:s0r1s1r2s2rsfe1111e1112...Figure 10: match witnessing (a, a) cert(q, K) q(x, y) = (x, y)NFA depicted upper right-hand-side Figure 10. Observe L() =L(r r1 r2 r ) (i.e., language first atom C2RPQ q Example 3.4).Note (a, a) cert(q, (T , A)), witnessed path arbr1 e2 r2 br a,passes element e2 anonymous part ,A . input, algorithmBasicEval would start (a, s0 ). first iteration loop, could guesspair (b, s0 ) transition (s0 , r, s0 ), entailment check first item Step2(b) would succeed since , |= r(a, b). However, next iteration transitionss0 (s0 , r, s0 ), (s0 , r1 , s1 ), Ind(A) , |= r(b, d), |= r1 (b, d). Hence good pair guess Step 2(b) algorithm wouldfail. Since possible guesses first iteration satisfy entailmentcheck, algorithm incorrectly returns no.aim modify evaluation algorithm take account detoursanonymous part. observe path two ABox individuals IKdecomposed sequence paths two types:paths whose elements belong ABoxpaths begin end ABox individual whose intermediatepoints belong anonymous partPaths first type already handled evaluation algorithm. handle pathssecond type, show check whether path form startsends given individual takes query automaton state state s0 .loop exists individual a, query evaluation, allowedjump directly (a, s) (a, s0 ). modifying evaluation algorithm allowshortcuts addition normal transitions, ensure possible pathscanonical model taken account.key observation decide whether loop available given ABox individualsufficient consider basic concepts hold a. leads us definetable ALoop entry ALoop [s, s0 ] contains set basic concepts Cforce existence path second type whose label takes query automatonstate state s0 . order define ALoop , require second table Loopcontain pair states (s, s0 ), set tail concepts guarantee existence339fiBienvenu, Ortiz, & Simkuspath anonymous element e takes query automaton s0never leaving subtree IK rooted e (note allow e occur multipletimes along path).Let us proceed definition tables ALoop Loop . DL-LiteRTBox, Loop defined inductively using following rules:(L1) every S: Loop [s, s] = TCT .(L2) C Loop [s1 , s2 ] C Loop [s2 , s3 ], C Loop [s1 , s3 ].(L3) C TCT , |= C v A, (s1 , A?, s2 ) , C Loop [s1 , s2 ].(L4) C TCT , |= C v R, |= R v R0 , |= R v R00 , (s1 , R0 , s2 ) , RLoop [s2 , s3 ], (s3 , R00 , s4 ) , C Loop [s1 , s4 ].table ALoop constructed Loop using rule:(L5) C BCT , |= C v R, |= R v R0 , |= R v R00 , (s1 , R0 , s2 ) , RLoop [s2 , s3 ], (s3 , R00 , s4 ) , C ALoop [s1 , s4 ].ELH, use definitions, except rules 4 5 replaced by:(L4) C TCT , |= C v r.D, |= r v r0 , |= r v r00 , (s1 , r0 , s2 ) ,Loop [s2 , s3 ], (s3 , r00 , s4 ) , C Loop [s1 , s4 ].(L5) C BCT , |= C v r.D, |= r v r0 , |= r v r00 , (s1 , r0 , s2 ) ,Loop [s2 , s3 ], (s3 , r00 , s4 ) , C ALoop [s1 , s4 ].Note since TCT = BCT ELH, difference (L4) (L5)former adds concepts table Loop , latter adds concepts ALoop .following example illustrates construction tables Loop ALoop .Example 5.4. Observe running example TCT = {r, r , r1 , r1 , r2 , r2 }BCT = {B} TCT . first step loop computation 2RPQ q 0Example 5.3, get Loop [s, s] = TCT every {s0 , s1 , s2 , sf }. inferr Loop [s0 , s2 ] using rule L4 following facts:|= r v r1|= r1 v r1(s0 , r1 , s1 )r1 Loop [s1 , s1 ]|= r1 v r2(s1 , r2 , s2 )Intuitively, every element e satisfies r r1 -child e0 (by |= r v r1 ),e0 turn r2 -child e (by r1 v r2 ). Hence, starting element e,always use transition (s0 , r1 , s1 ) go child e0 return e usingtransition (s1 , r2 , s2 ), i.e., loop s0 s2 e.step, infer r Loop [s0 , s3 ] using rule L4 together with:|= r v r|= r v r(s0 , r, s0 )r Loop [s0 , s2 ]340|= r v r(s2 , r , sf )fiRegular Path Queries Lightweight Description Logicsreflects whenever element satisfies r , loop s0 s3 follows:move r-child (which exists |= r v r) staying state s0(s0 , r, s0 ), use previously computed loop jump s2 element,go back e transition (s2 , r , sf ).One verify loops inferred rules, obtain:Loop [si , si ] = TCT 0 3Loop [s0 , s2 ] = {r }Loop [s0 , s3 ] = {r }compute ALoop . First note applications L5 analogoustwo described applications L4, respectively result r ALoop [s0 , s2 ]r ALoop [s0 , s3 ]. Moreover, similar applications using |= B v r1 instead|= r v r1 |= B v r instead |= r v r yield B ALoop [s0 , s2 ]B ALoop [s0 , s3 ]. applications L5 yield new loops, hence obtain:ALoop [s0 , s2 ] = {r , B}ALoop [s0 , s3 ] = {r , B}observe tables Loop ALoop constructed polynomial time|T | || since entailment inclusions P DL-LiteR ELH (Calvaneseet al., 2007; Baader et al., 2005). following propositions show Loop ALoopdesired meaning:Proposition 5.5. every DL-LiteR ELH KB K = (T , A) IK \ Ind(A),following equivalent:1. Tail(d) Loop [s, s0 ];2. path p = e0 u1 e1 . . . un en IK (p) L(s,s0 ), e0 = en = d,ei IK |d every 0 n.Proof. Consider KB K = (T , A) automaton = (S, , , s, F ). beginproving first statement implies second. Fix sequence applicationsrules L1, L2, L3, L4 (or L4) generates full table Loop , let klength sequence. suffices show following claim 1 k:Claim: C inserted Loop [s, s0 ] i-th rule application ,A \ Ind(A)Tail(d) = C, path p = e0 u1 e1 . . . un en IK (p)L(s,s0 ), e0 = en = d, ei IK |d every 0 n.Proof claim. proof induction i. First suppose C insertedLoop [s, s0 ] first rule application ,A \ Ind(A) Tail(d) = C.either rule L1 rule L3 must applied. former case, = s0 ,path p = satisfies required conditions (recall case (p) ).instead rule L3 applied, must |= C v (s, A?, s0 )concept name A. Since Tail(d) = C, must AIT ,A . followsp = dA?d path satisfying required conditions.induction step, suppose statement holds 1 < k, let,A \ Ind(A) C = Tail(d) inserted Loop [s, s0 ] k-th ruleapplication. first possibility k-th rule application involves rules L1 L3,case proceed base case. next possibility rule L2341fiBienvenu, Ortiz, & Simkusapplied. must exist s00 first k 1 rule applications,C Loop [s, s00 ] C Loop [s00 , s0 ]. Applying induction hypothesis, find pathsp1 p2 begin end d, contain elements IK |d ,(p1 ) L(s,s00 ) (p2 ) L(s00 ,s0 ). Let p3 path obtained taking p1adding p2 first occurrence removed. p3 begins ends d, containselements IK |d , (p3 ) L(s,s0 ).final possibility k-th rule application involves rule L4. proofdiffers depending whether formulated DL-LiteR ELH. give proofDL-LiteR ; proof ELH proceeds analogously. first note sinceapplication rule L4 leads insertion C Loop [s, s0 ] stage k, must00 000case find R, R0 , R00 NR ,|= C v R, |= R v R0 , |= R v R00 ,(s, R0 , s00 ) (s000 , R00 , s0 ) ,R Loop [s00 , s000 ] (after k 1 rule applications).Tail(d) = C |= C v R, element d0 = dRR must belong ,A .applying induction hypothesis, infer path p0 beginsends d0 , contains elements IK |d0 , (p0 ) L(s00 ,s000 ).follows path p = dR0 p0 R00 satisfies requirements, particular,(p) L(s,s0 ). (end proof claim)show direction, proceed induction length path p =e0 u1 e1 . . . un en . first base case n = 0, i.e., (p) = . L(s,s0 ),implies = s0 . rule L1 definition Loop , must Tail(d)Loop [s, s0 ]. second base case n = 1, i.e., p = dA?d. Since p path,must AIT ,A , means |= Tail(d) v A. also know (p) = A?L(s,s0 ), implies (s, A?, s0 ) . thus shown conditions ruleL3 satisfied, Tail(d) Loop [s, s0 ].induction step, suppose second direction holds 0 ` < k,suppose path p = e0 u1 e1 . . . uk ek IK k > 2 (p) L(s,s0 ),e0 = ek = d, ei IK |d every 0 k. First suppose existsej 0 < j < k ej = d. Let p1 = e0 u1 e1 . . . ej p2 = ej uj . . . ek .know (p) = (p1 )(p2 ) L(s,s0 ), must exist state s00(p1 ) L(s,s00 ) (p2 ) L(s00 ,s0 ). Applying induction hypothesis p1 p2 ,obtain Tail(d) Loop [s00 , s0 ] Tail(d) Loop [s, s00 ]. Hence, rule L2construction Loop , must Tail(d) Loop [s, s0 ].let us consider second possibility, ej 6= 0 < j < k. Since,A |d tree-shaped, p path, must case e1 = ek1 = dRC ,A |d .point, proof slightly differs depending whether DL-LiteR ELH.present proof case ELH, case R = r NR |=Tail(d) v r.C. (p) = u1 . . . uk L(s,s0 ), e0 = ek = d, e1 = ek1 = dRC, mustcaseu1 NR |= r v u1 ,342fiRegular Path Queries Lightweight Description Logicsuk NR |= r v uk = .also know must exist states s00 , s000(s, u1 , s00 ) (s000 , uk , s0 ) ,u2 . . . uk1 L(s00 ,s000 ).apply induction hypothesis p0 = e1 u1 . . . uk1 ek1 infer Tail(e1 ) =C Loop [s00 , s000 ]. thus satisfy required conditions applying rule L4obtain Tail(d) Loop [s, s0 ]. proof DL-LiteR analogous.Proposition 5.6. every DL-LiteR ELH KB K = (T , A), NFA containing statess, s0 , Ind(A), following statements equivalent:1. concept C ALoop [s, s0 ] , |= C(a).2. path p = e0 u1 e1 u2 . . . un en IK (p) L(s,s0 ), e0 = en = a,n > 1, ei 6 Ind(A) 0 < < n.Proof. Fix DL-LiteR TBox NFA = (S, , , s, F ) (the proof ELH similarleft reader). first direction, suppose concept C ALoop [s, s0 ], |= C(a). follows definition ALoop exists roles00 0000R, R0 , R00 NR states , |= C v R, |= R v R , |= R v0000000000000000R , (s, R , ) , R Loop [s , ], (s , R , ) . Since , |= C(a)|= C v R, follows definition IK aRR IK . Proposition 5.5,R Loop [s00 , s000 ] implies path p = e0 u0 . . . un en IK |aRR e0 =en = aRR (p) L(s00 ,s000 ). verified taking p0 = aR0 pR00 a,obtain path IK satisfies conditions second statement. particular,since (s, R0 , s00 ) , (p) L(s00 ,s000 ), (s000 , R00 , s0 ) , (p0 ) L(s,s0 ).second direction, suppose path p = e0 u1 e1 u2 . . . un en IK(p) L(s,s0 ), e0 = en = a, n > 1, ei 6 Ind(A) 0 < < n. Since n > 1,e1 6 Ind(A), p path, must case e1 = aRR R NR.Moreover, since IK |a tree, must en1 = e1 . definition paths,must caseu1 NR |= R v u1 ,un NR |= R v un .also know must exist states s00 , s000 that:(s, u1 , s00 ) (s000 , un , s0 )u2 . . . un1 L(s00 ,s000 )applying Proposition 5.5 p0 = e1 u1 . . . un1 en1 , infer R Loop [s00 , s000 ].Since aRR IK , definition IK ensures C BCTC IK |= C v R. conditions Rule 5 thus satisfied, C ALoop [s, s0 ].343fiBienvenu, Ortiz, & SimkusAlgorithm EvalAtomInput: NFA = (S, , , s0 , F ) NR {A? | NC }, DL-LiteR ELH KB(T , A), (a, b) Ind(A) Ind(A)1. Test whether (T , A) satisfiable, output yes not.2. Initialize current = (a, s0 ) count = 0. Set max = |A| |S| + 1.3. count < max current 6 {(b, sf ) | sf F }(a) Let current = (c, s).(b) Guess pair (d, s0 ) Ind(A) together either (s, , s0 ) BALoop [s, s0 ].(c) (s, , s0 ) guessedNR , verify , |= (c, d), return not.= A?, verify c = , |= A(c), return not.(d) B guessed, verify c = , |= B(c), return not.(e) Set current = (d, s0 ) increment count.4. current = (b, sf ) sf F , return yes. Else return no.Figure 11: Non-deterministic algorithm 2RPQ answering DL-LiteR ELH.means determine loops anonymous partavailable given ABox individual, ready present extended evaluationalgorithm EvalAtom Figure 11 handles DL-LiteR ELH KBs. algorithmEvalAtom differs BasicEval two respects. First, DL-LiteR KBs may containcontradictions, initial consistency check Step 1 determine whether inputKB satisfiable (this step skipped ELH KBs, always satisfiable).KB shown unsatisfiable, query trivially holds, algorithm outputsyes. second difference occurs Step 3(b) within loop,choice guessing pair (d, s0 ) Ind(A) (as before) guessing conceptB ALoop [s, s0 ]. first option corresponds taking step ABox, whereassecond corresponds shortcut anonymous part. choose secondoption, must check selected concept entailed current individual.exit conditions loop criterion outputting yes Step 4 remainunchanged.Example 5.7. Algorithm EvalAtom correctly returns yes input (a, a) togetherexample query KB, contrast BasicEval (as shown Example 5.3). Indeed,successful execution (illustrated pictorially Figure 12) starts (a, s0 ) guessespair (b, s0 ) transition (s0 , r, s0 ) first iteration loop.checks Step 3(c) succeed , |= r(a, b). next iteration, guess (b, s2 ) and,r ALoop [s0 , s2 ], also guess concept r . checks Step 3(d) succeed, |= r (b). third iteration, guesses pair (a, sf ) transition344fiRegular Path Queries Lightweight Description Logicsrs0 sfrs0 s2re1cbx:r2r1(s0 , s2 )-loops1 e2s0r1s1r2s2rsfr ALoop [s0 , s2 ]e1111e1112...Figure 12: Establishing (a, a) cert(q, K) using EvalAtom q(x, y) = (x, y)(s2 , r , sf ). , |= r (b, a), checks Step 3(c) succeed again. Since sf F ,last iteration, Step 4 algorithm returns yes.Proposition 5.8. every 2RPQ q = (x, y), DL-LiteR ELH KB K = (T , A),pair individuals (a, b) Ind(A): (a, b) cert(q, K) executionEvalAtom(, K, (a, b)) returns yes.Proof. Consider 2RPQ q = (x, y) = (S, , , s0 , F ), DL-LiteR ELH KBK = (T , A), pair individuals (a, b) Ind(A).first direction, suppose (a, b) cert(q, K). path p =e0 u1 . . . un en IK e0 = a, en = b, (p) L(). may assume withoutloss generality shorter path properties. Since (p) L(),find sequence states s0 s1 . . . sn sn F every 1 n,(si1 , ui , si ) . Let j1 < . . . < jm indices ei Ind(A),consider sequence pairs = (ej1 , sj1 )(ej2 , sj2 ) . . . (ejm , sjm ). Observe j1 = 0jm = n, ej1 = a, ejm = b, sjm F . Also observe must(ej` , sj` ) 6= (ejk , sjk ) whenever ` 6= k, since otherwise, could construct shorter pathproperties p, contradicting minimality assumption. followssequence contains |A| |S| pairs. Thus, prove sequence leadsexecution EvalAtom returns yes, remains show always possibleguess transition concept 3(b) checks 3(c) 3(d) succeed. Thus,let us suppose current = (ej` , sj` ) guess pair (ej`+1 , sj`+1 ) 3(b).three cases consider:Case 1: j`+1 = j` +1 uj`+1 = R NR . earlier, (sj` , R, sj`+1 ) ,since p path, know (ej` , ej`+1 ) RIK . latter implies, |= R(ej` , ej`+1 ), choosing transition (sj` , R, sj`+1 ) 3(b), ensureentailment check succeed 3(c).Case 2: j`+1 = j` + 1 uj`+1 = A?. earlier, (sj` , A?, sj`+1 ) ,since p path, know ej` = ej`+1 AIK . choosing transition(sj` , A?, sj`+1 ), ensure conditions 3(c) satisfied.Case 3: j`+1 > j` + 1. case, path p0 = ej` uj` +1 . . . uj`+1 ej`+1(p0 ) L(sj` ,sj`+1 ), ej` = ej`+1 Ind(A), every j` < < j`+1 ,345fiBienvenu, Ortiz, & Simkusei 6 Ind(A). thus apply Lemma 5.6 find concept C ALoop [sj` , sj`+1 ], |= C(ej` ). choosing C 3(b), sure entailmentcheck 3(d) succeed.direction, consider execution EvalAtom(, K, (a, b)) returnsyes, let (c0 , s0 )(a1 , s1 ) . . . (cn , sn ) sequence pairs guessedexecution. must c0 = a, cn = b, sn F . complete proof,suffices establish following claim:Claim: every 0 n, path pi c0 ci IK (pi ) L(s0 ,si ).Proof claim. proof induction i. base case (i = 0), simplytake path p0 = c0 since (p0 ) = L(s0 ,s0 ). induction step,suppose pk1 path c0 ck1 (pk1 ) L(s0 ,sk1 ), showconstruct path pk required properties. three cases considerdepending transition concept guessed together (ck , sk ) Step 3(b).Case 1: transition (sk1 , R, sk ) guessed. Since check 3(c) succeeded,, |= R(ck1 , ck ). pk = pk1 Rck path IK c0 ck(pk ) L(s0 ,sk ).Case 2: transition (sk1 , A?, sk ) guessed. since check 3(c)succeeded, ck = ck1 , |= A(ck1 ). pk = pk1 A?ck pathIK c0 ck (pk ) L(s0 ,sk ).Case 3: concept B ALoop [sk1 , sk ]succeeded, ck = ck1 , |=find path p0 = e0 u1 e1 u2 . . . un en IKen = ck1 . pk = pk1 u1 e1 u2 . . . un en(pk1 )(p0 ) L(s0 ,sk ).guessed. Since check 3(d)B(ck1 ). applying Lemma 5.6,(p0 ) L(sk1 ,sk ) e0 =path c0 ck (pk ) =analyzing complexity modified evaluation procedure, obtain upperbounds match lower bounds Section 4.Theorem 5.9. 2RPQ answering1. NL data complexity DL-LiteR ;2. P combined complexity DL-LiteR ;3. P combined data complexity ELH.Proof. procedure EvalAtom involves three different types checks: consistencycheck performed Step 1 entailment loop checks take place Step 3.cost checks depends choice DL complexity measure.Aside checks, base procedure runs non-deterministic logarithmic spacecombined complexity, logarithmic space needed keep track valuecount, old new values current, guesses transitions concepts.DL-LiteR , know existing results (Calvanese et al., 2007) consistencyentailment checks performed non-deterministic logarithmic space combined346fiRegular Path Queries Lightweight Description Logicscomplexity (and hence also data complexity). also seen table ALoopconstructed polynomial time |T | , loop checks performedconstant time |A| polynomial time w.r.t. whole input. followsEvalAtom runs non-deterministic logarithmic space w.r.t. |A|, yielding Statement (1).Regarding Statement (2), note EvalAtom viewed NL procedureuses P oracle handle loop checks. Since NLP = P, yields P upper boundcombined complexity 2RPQ answering DL-LiteR . proof Statement (3)similar. simply note input TBox formulated ELH, three typeschecks performed polynomial time w.r.t. whole input (Baader et al., 2005).Using NLP = P, may conclude EvalAtom provides polynomial-time procedure2RPQ answering ELH.6. Upper Bounds C2RPQsmain objective section define procedure deciding, given KB K =(T , A), C2RPQ q(~x) arity k, k-tuple ~a individuals A, whethermatch q IK (~x) = ~a. nave approach might consist guessingmapping query variables individuals core ,A checkingmatch running EvalAtom algorithm ((t), (t0 )) every query atom(t, t0 ). algorithm would properly take account paths individualspass anonymous part, consider matches send variablesanonymous objects, would still incomplete. particular, procedure wouldreturn b answers Example 3.4. regain completeness, one could insteadguess matches entire domain ,A , would yield decision proceduresince latter may infinite. Moreover, since matches C2RPQs involve domainelements arbitrarily far apart, apparent identify suitable finitesubset domain guaranteed contain match query one exists.address challenges, procedure propose section comprises two mainsteps. first step, rewrite input query q set Q C2RPQsmatch q ,A (~x) = ~a match 0 q 0 Q,A 0 (~x) = ~a. advantage rewritten queries needconsider matches 0 map query variables Ind(A). second step decidesexistence restricted matches rewritten queries using EvalAtom proceduredefined Section 5.purposes section, prove convenient work DL-LiteR TBoxessatisfy following condition: every role name r sig(T ), exists conceptnames Ar ,r contains inclusions Ar v r, r v Ar , Ar v r , r vAr , inclusions involving concept names Ar Ar . Notesatisfy condition, simply choose fresh concepts Ar , Arrole name r sig(T ) add corresponding inclusions . resultingTBox 0 model conservative extension , hence every ABox everyC2RPQ q sig(q) (sig(T 0 ) \ sig(T )) = , cert(q, (T , A)) = cert(q, (T 0 , A)).may therefore assume without loss generality DL-LiteR TBoxes consideredsection satisfy syntactic condition. follows, use concept nameAR , R NR , assume TBox contains inclusions AR v R R v AR .347fiBienvenu, Ortiz, & Simkus6.1 Query Rewritingaim rewrite query way need map variablesanonymous part model. draw inspiration query rewritingprocedure Horn-SHIQ introduced Eiter, Ortiz, Simkus, Tran, Xiao (2012).main intuition follows. Suppose match q maps variableanonymous part, variable mapped (y). modify qway resulting query q 0 match 0 exceptvariables mapped (y) mapped 0 (unique) parent (y),A . delicate point must split atoms form (t, t0 ) {t, t0 }parts satisfied subtree ,A |(y) , occur(y), whose satisfaction still needs determined thus must incorporatednew query. iteration rewriting procedure, obtain querymatch maps variables closer core ,A , eventually obtainquery match maps terms Ind(A).Figure 13, implement intuition defining algorithm OneStep performs single (non-deterministic) rewriting step. illustrate functioning OneStepfollowing examples.Example 6.1. Recall query q(x) = y, z. r r1 r2 r (x, y) r r (y, z) D(z)Example 3.4, KB (T , A) Example 2.4.illustrate rewriting algorithm, first disregard first atom considersimpler Boolean query q1 = y, z. (y, z) D(z), NFA language r rdepicted Figure 14. figure shows match q1 (y) = e11 (z) = b.Since leaf image q1 , want modify q1 query q10match 0 differs 0 (y) = e1 , e1 parent(y) = e11 . Intuitively, done using OneStep choosing Leaf = {y}variable moved up. choose concept B holds e1 ,enforces existence r role child e1 (namely, e11 ) e1 . Hence,checking B holds e1 , implicitly check first r needed satisfy holdse1 . rewriting step illustrated upper part Figure 14. Formally,Step 1 choose Leaf = {y}. Step 2 choose r (since, intuitively,tail concept causes everything holds e11 ). Step 3, simply takefinal state s0f , atom (z, y) remains same, Step 4 nothing.two steps simple example complex paths querymatch need deeper e11 . Next, Step 5, choose B, since |= r,is, B enforces existence node satisfies tail concept r guessedabove. Step 5b need take care atom (y, z). choose s01Step 6, replace s01 ,s0f . Step 7, add atom B(y), output queryB(y) s01 ,s0f (y, z) D(z).lower part figure illustrates successive application OneStepproceed analogously, dropping second r , adding atom B(y).results query q100 = y, z. B(y)s0f ,s0f (y, z)D(z), match 00 (z) = 00 (y) = branging individuals only. Note L(s0f ,s0f ) = {} query equivalenty.B(y) D(y).348fiRegular Path Queries Lightweight Description LogicsAlgorithm OneStepInput: C2RPQ q binary atoms specified NFAs, DL-LiteR ELH TBox1. Guess non-empty set Leaf qvars(q) Leaf.Rename variables Leaf y.2. Guess C TCT |= C v B every atom B(y) q. Drop atomsq.3. atom (t, t0 ) = (S, , , s, F ) NFA {t, t0 },Guess sequence s1 , . . . , sn1 distinct states state sn F .Replace (t, t0 ) atoms s,s1 (t, y), s1 ,s2 (y, y), . . . , sn2 ,sn1 (y, y),sn1 ,sn (y, t0 ).4. Drop atoms s,s0 (y, y) C Loop [s, s0 ].5. Guess BCT R NR that:(a) C = R |= v RR NR |= v R.C(if DL-LiteR TBox)(if ELH TBox)(b) atom (y, t) = (S, , , s, F ), exists s0 U NR(s, U , s0 ) |= R v U .(c) atom (t, y) = (S, , , s, F ), exists s00 S, sf F ,00U NR (s , U, sf ) |= R v U .atoms form (y, y), conditions (b) (c) must satisfied.6. Replaceatom (y, t) 6= s0 ,F (y, t)atom (t, y) 6= s,s00 (t, y)atom (y, y) s0 ,s00 (y, y)s, s0 , s00 , F Step 5.7. NC concept chosen Step 5, add D(y) q. = P chosenconcept, add AP (y) q. Output q.Figure 13: Non-deterministic query rewriting algorithm OneStep.Example 6.2. illustrate two rewriting steps q(x) = y, z. r r1 r2 r (x, y)r r (y, z) D(z) (see Figure 15). First, recall match Figure 7, alsoreproduced top part Figure 15. Observe (y) = e11 leaf image. move match one step, make initial choices Example 6.1,setting Leaf = {y} Step 1 selecting tail concept r characterises e11349fiBienvenu, Ortiz, & Simkusbre1 s01cs0fe2BB v rre11 s00...be12zrs00e1 s01e2Bs0 ,s01e11e12s01rs0fs01s01 ,s0f :zBfbe1 s01rs0fB,cs0fre2s0 ,s0e12zbB1e11r...:Bcs0ffBB v r...cs0fe1e2s0 ,s0fe11e12zf...s01 ,s0f :s01rs0fs0f ,s0f :s0fFigure 14: Two successive applications OneStep q1 = y, z. r r (y, z) D(z)Step 2. However, path satisfies goes deeper (y) = e11 , Step 3,need separate path parts occur e11 occurit. choose sequence states s0 , sf correspond statesautomata visits e11 , replace (x, y) s0 ,s0 (x, y) s0 ,sf (y, y). Noteintermediate query illustrated top Figure 15. Since r Loop [s0 , sf ](see Example 5.4), drop second atom Step 4. move similarlyabove, considering simultaneously atoms s0 ,s0 (x, y) (y, z). Step 5,choose concept B, since satisfies |= B v r. atom (y, z) choose s01U = r (Step 5(b)) s0 ,s0 (x, y), choose s0 U = r (Step 5(c)). Step 6,replace two query atoms s0 ,s0 (x, y) s01 ,s0f (y, z), Step 7, add atomB(y) output resulting query s0 ,s0 (x, y) B(y) s01 ,s0f (y, z), displayedmiddle Figure 15. lower part figure depicts second, similar applicationOneStep outputs query match ranging individuals only.Slightly abusing notation, use OneStep(q, ) denote set queriesoutput execution OneStep input (q,T ). consider set Rewrite(q, )consisting queries obtained (q,T ) zero applicationsOneStep. Formally, define Rewrite(q, ) smallest set contains initialquery q closed applications OneStep, i.e., q 0 Rewrite(q, ) q 00OneStep(q 0 , ), q 00 Rewrite(q, ).next proposition shows using Rewrite(q, ), reduce problemfinding arbitrary query match finding match involving ABox individuals.350fiRegular Path Queries Lightweight Description Logicsrs0bs0rrre1 s01s0cs0fxrs0 sfrs0 s2e11rs0 ,sf :s00:e111r1s0s1r2s2rsfe12rr1s0 ,sfs00s0s0 ,s0e2r(s0 , sf )-loops0 ,so :e112zrs01rs0fr2e1111s1 e1112...r Loop [s0 , s0f ], B v r,rxs0rrbs0re1 s01s0cs0fs0 ,so :s0s01 ,s0f :s01s0 ,s0e2rs0fBBe11s0 ,s01e12...zfB v rrxB,s0s0re1bcs0fe2s0 ,so :s0s0f ,s0f :s0fs0 ,s0...Bs0 ,s0fzfFigure 15: Two rewriting steps q(x) = y, z. r r1 r2 r (x, y) r r (y, z) D(z)Proposition 6.3. every satisfiable DL-LiteR ELH KB (T , A) C2RPQ q:~a cert(q, (T , A)) exists query q 0 (~x) Rewrite(q, ) matchq 0 ,A (~x) = ~a (z) Ind(A) every variable z q 0 .split Proposition 6.3 two lemmas, first showing completeness Rewrite,second showing correctness.Lemma 6.4. ~a cert(q, (T , A)), exists query q 0 (~x) Rewrite(q, )match q 0 ,A (~x) = ~a (z) Ind(A) every variable z q 0 .351fiBienvenu, Ortiz, & SimkusProof. Consider knowledge base (T , A) canonical model ,A . every element e ,A , define distance dist(e) e core ,A follows:dist(aR1 C1 . . . Rn Cn ) = n. Observe dist(e) = 0 implies e Ind(A). Using notiondistance, define cost match query ,A vdom() distT ,A ((v)),dom() domain . remark match cost equal zerocase maps query variables ABox individuals.Suppose ~a cert(q, (T , A)), match q ,A (~x) = ~a.maps variables q Ind(A), done. Otherwise, must existvariable (y) = eSC z vars(q) (y) properprefix (z). aim construct match 0 query q 0 OneStep(q, )(c1) 0 (t) = (t) every terms(q) (t) 6= (y);(c2) 0 (t) = e every terms(q) (t) = (y).words, 0 essentially except maps (t) = (y)one step closer ABox. Observe (c1) (c2) together ensure cost0 strictly inferior cost . Thus, repeatedly applying operation,eventually obtain query q Rewrite(q, ) match q cost zero, i.e.,(z) Ind(A) every variable z q .show obtain query q 0 OneStep(q, ) match 0 properties(c1) (c2). Step 1, set Leaf = {t terms(q) | (t) = (y) = eSC}. NoteLeaf qvars(q) since eSC 6 Ind(A). define function follows: (t) =(t) 6= (y), else (t) = y. end Step 1, query:{B((t)) | B(t) q0 } {((t), (t0 )) | (t, t0 ) q0 }Step 2, choose concept C (note C TCT (y) = eSC). Consideratom B(y) present end Step 1. existence atom B(y)end step means must existed atom B(v) q v Leaf. Sincematch q, know (v) = (y) B ,A . (y) = eSC, followsdefinition ,A |= C v B, required Step 2.Next show select states s1 , . . . , sn Step 3. Consider atom (t1 , t2 )present query start Step 3, {t1 , t2 } = (S, , , s0 , F ).know atom (t01 , t02 ) input query q t1 = (t01 )t2 = (t02 ). Since match q (t1 ) = (t01 ) (t2 ) = (t02 ), know((t1 ), (t2 )) L()IT ,A . follows find path p = e0 u1 e1 . . . um eme0 = (t1 ), em = (t2 ), (p) L(). assume without loss generalityminimal, i.e., cannot find path satisfying properties shorter length.let j1 < . . . < jn1 indices 0 < ` < e` = (y), considerfollowing paths:p1 = e0 u1 . . . uj1 ej1pi = eji1 uji1 +1 . . . uji eji 1 < < npn = ejn1 ujn1 +1 . . . um em352fiRegular Path Queries Lightweight Description Logicsalso define sequence states s1 , . . . , sn(p1 ) L(s0 ,s1 ),(pi ) L(si1 ,si ) 1 < n,sn F .Note sequence states must exist since (p) = (p1 )(p2 ) . . . (pn ) L()start state s0 final states F . Using fact eji = (y) 1 < n,following:((t1 ), (y)) = ((t01 ), (y)) L(s0 ,s1 )IT ,A .((y), (y)) L(si1 ,si )IT ,A , 2 < n.(?)((y), (t2 )) = ((y), (t02 )) L(sn1 ,sn )IT ,A .aim show si 6= sj every 1 k < ` < n. Suppose contradictionsk = s` 1 k < ` < n, consider path p0 = e0 u1 . . . ujk ejk uj` +1 ej` +1 . . . um em .(p0 ) = u1 . . . ujk uj` +1 . . . um , u1 . . . ujk L(s0 ,sk ), uj` +1 . . . um L(s` ,sn ) = L(sk ,sn ),sn F , follows (p0 ) L(). However, means p0 satisfies conditions p strictly shorter length, contradicting minimality assumption. Hencestates sequence s1 , . . . , sn1 must distinct. thus choose sequencestates Step 3, replace atom (t1 , t2 ) = ((t01 ), (t02 )) atoms:s0 ,s1 ((t01 ), y), s1 ,s2 (y, y), sn2 ,sn1 (y, y), sn1 ,sn (y, (t02 )).final choices made occur Step 5, must choose concept BCTrole R NR conditions (a), (b), (c) satisfied. set R = (recall(y) = eSC). e 6 Ind(A), let unique concept e = e0 P D.Note DL-LiteR , = P . follows definition canonicalmodels |= v (if DL-LiteR ) |= v S.C (for ELH),condition (a) holds. instead e Ind, definition canonical models,together normal form ELH TBoxes, guarantees BCTe DIT ,A |= v (if DL-LiteR ) |= v S.C (forELH). Note case DL-LiteR , , |= S(e) implies one followingholds: (i) concept assertion A(e) |= v S, (ii) roleassertion 0 (e, e0 ) |= 0 v S, (iii) role assertion 0 (e0 , e)|= (S 0 ) v S. Thus, always possible choose |= D(e),assume follows property.remains show conditions (b) (c) verified R = S. (b),consider binary atom (y, t) belongs query start Step 5.know must exist atom (t01 , t02 ) q = (S, , , s0 , F )(y, t) equal one following atoms replaced ((t01 ), (t02 )) Step 3:s0 ,s1 ((t01 ), y), s1 ,s2 (y, y), . . . , sn2 ,sn1 (y, y), sn1 ,sn (y, (t02 )). Thus, atomform si1 ,si (y, t). Using property (?) considering different possible valuest, infer ((y), (t)) L(si1 ,si )IT ,A , witnessed path pi =353fiBienvenu, Ortiz, & Simkuseji1 uji1 +1 . . . uji eji . also know e` 6= (y) every ji1 < ` < ji . particular,means either path pi entirely contained subtree rooted (y)never visits element (y). former option cannot hold, since wouldimply = C Loop [si , si+1 ], atom would removedStep 4. Thus, must case first step path pi goes (y),A . Sinceparent e. follows uji1 +1 = U U NR (e, (y)) U(y) = eSC, must |= v U . Since (pi ) L(si1 ,si ), must exist states0 (si1 , U , s0 ) uji1 +2 . . . uji L(s0 ,si ). shows condition(b) satisfied, also (e, (t)) L(s0 ,s )IT ,Aconsider condition (c). Take atom form (t, y) appearsquery start Step 5. know earlier findatom (t01 , t02 ) q (where = (S, , , s0 , F )) (t, y) equal onefollowing atoms replaced ((t01 ), (t02 )) Step 3: s0 ,s1 ((t01 ), y), s1 ,s2 (y, y),. . . , sn2 ,sn1 (y, y), sn1 ,sn (y, (t02 )). follows (t, y) form si ,si+1 (t, y).Using property (?), considering two possible values t, deduce((t), (y)) L(si ,si+1 )IT ,A , witnessed path pi = eji1 uji1 +1 . . . uji eji . Arguing(b), show path pi entirely contained subtree rooted(y) path never visits element (y). former option would imply= C Loop [si , si+1 ], atom would removed Step 5. Thus,must case last step path e (y), uji = U,A . Since (y) = eSC, must |= v U . SinceU NR (e, (y)) U(pi ) L(si ,si+1 ), also know must exist state s00 (s00 , U, si+1 )uji1 +1 . . . uji 1 L(si ,s00 ). shows condition (c) satisfied, also((t), e) L(si ,s00 )IT ,A . also important note = y, applyarguments conditions (b) (c) together show (e, e) L(s0 ,s00 )IT ,A (with states0 (b), s00 required (c)).let q 0 query obtain end Step 7 non-deterministic choicesmade manner described. Consider mapping 0 defined follows:0 (t) = (t) every terms(q) (t) 6= (y).0 (t) = e every terms(q) (t) = (y).Note mapping 0 satisfies properties (c1) (c2). remains show 0match q 0 .Consider first concept atom B(t) q 0 . two possibilities. Either B(t) appearsq 6 Leaf, B(t) introduced Step 7. former case, knowsatisfies B(t), since 0 (t) = (t) (since 6 Leaf), true 0 . lattercase, must = either B = NC B = AP = P . B = D,use fact 0 (t) = e chosen e DIT ,A infer0 satisfies B(t). B = AP , e (P )IT ,A . Since ,A modelP v AP , also e APT,A , means 0 satisfies B(t).consider atom (t0 , t00 ) q 0 . 6 {t0 , t00 }, (t0 , t00 ) q.match q ,A , must case ((t0 ), (t00 )) L()IT ,A . Since 0 (t0 ) = (t0 )0 (t00 ) = (t00 ), holds 0 , atom (t0 , t00 ) satisfied 0 . Next354fiRegular Path Queries Lightweight Description Logicssuppose {t0 , t00 }. examination Rewrite shows (t0 , t00 ) must replacedatom Step 6. distinguish three cases:Case 1: (t0 , t00 ) replaces si ,si+1 (y, t) 6= y. (t0 , t00 ) must forms0 ,si+1 (y, t), s0 state chosen ensure condition (b) Step 5.recall s0 (e, (t)) L(s0 ,si+1 )IT ,A . Since 6= y, know6 Leaf, (t) = 0 (t). follows ( 0 (y), 0 (t)) L(s0 ,si+1 )IT ,A ,atom (t0 , t00 ) satisfied 0 .Case 2: (t0 , t00 ) replaces si ,si+1 (t, y) 6= y. (t0 , t00 ) must formsi ,s00 (t, y), s00 state used condition 5(c). showed earlierexamining condition (c) ((t), e) L(si ,s00 )IT ,A . Using fact0 (t) = (t) 0 (y) = e, infer ( 0 (t), 0 (y)) L(si ,s00 )IT ,A , hence 0satisfies atom (t0 , t00 ).Case 3: (t0 , t00 ) replaces si ,si+1 (y, y). (t0 , t00 ) must form s0 ,s00 (y, y),s0 state 5(b) s00 state 5(c). ( 0 (y), 0 (y)) =(e, e) L(s0 ,s00 )IT ,A , means 0 satisfies atom (t0 , t00 ).0shown every atom q 0 satisfied mapping 0 , followsmatch q 0 ,A , completes proof.Lemma 6.5. ~a cert(q 0 , (T , A)) q 0 Rewrite(q, ), ~a cert(q, (T , A)).Proof. sufficient show q 0 OneStep(q, ) ~a cert(q 0 , (T , A)), ~acert(q, (T , A)). Fix C2RPQ q DL-LiteR ELH TBox , let q 0 OneStep(q, )~a cert(q 0 , (T , A)). Lemma 3.2, exists match 0 q 0 ,A0 (~x) = ~a, ~x answer variables q 0 .Consider execution OneStep(q, ) leads query q 0 output. Let Leafnon-empty subset qvars(q) selected Step 1, let variableLeaf chosen Step 1, let C TCT concept selected Step 2, let BCTR concept role selected Step 5. Step 7, NC , D(y) added,= P , AP (y) added. former case, know 0 (y) DIT ,Aeither (i) |= v R C = R , (ii) |= v R.C, hence must existR-child e 0 (y) ,A Tail(e) = C. latter case, 0 (y) APT,A .assumption DL-LiteR TBoxes, must contain inclusion AP v P . Since ,Amodel , yields 0 (y) (P )IT ,A , hence 0 (y) DIT ,A . usefact |= v R C = R find R-child e 0 (y) ,A Tail(e) = C.define mapping : terms(q) ,A setting (t) = e every Leafsetting (t) = 0 (t) every terms(q 0 ) \ {y}. mapping well-defined since everyterm q either belongs Leaf appears q 0 . Observe (~x) = ~a since 0 (~x) = ~aLeaf contain answer variables. aim show match q ,A .end, consider concept atom B(t) q. First suppose Leaf.know concept C selected Step 2 |= C v B. use factsince Leaf, (t) = e C ,A . 6 Leaf, B(t) q 0 . 0 matchq 0 , 0 (t) B ,A . Since 0 (t) = (t), get (t) B ,A .355fiBienvenu, Ortiz, & Simkusconsider atom form (t, t0 ) q, = (S, , , s0 , F ).6 Leaf t0 6 Leaf, verified (t, t0 ) q 0 . 0 matchq 0 ,A , must case ( 0 (t), 0 (t0 )) L()IT ,A . Since 0 (t) = (t)0 (t) = (t), holds . Let us next consider interesting case{t, t0 } Leaf 6= . Step 3, query containing ((t), (t0 )), mappingdefined follows: (t00 ) = t00 t00 6 Leaf (t00 ) = t00 Leaf. Notesince {t, t0 } Leaf 6= , least one (t) (t0 ) must y. follows Step 3,guess sequence s1 , . . . , sn1 distinct states state sn F ,replace ((t), (t0 )) atoms: s0 ,s1 ((t), y), s1 ,s2 (y, y), . . . , sn2 ,sn1 (y, y),sn1 ,sn (y, (t0 )). Let us denote set atoms Q . Slightly abusing terminology,use phrase match Q refer match Boolean query givenconjunctions atoms Q . establish following claim:Claim 1. match Q ,A , match (t, t0 ) ,A .Proof claim. Suppose match atoms Q ,A . means(((t)), (y)) L(s0 ,s1 )IT ,A ,((y), (y)) L(si ,si+1 )IT ,A every 1 < n 1,((y), ((t0 ))) L(sn1 ,sn )IT ,A .remark language consisting words w1 . . . wn w1 L(s0 ,s1 ),wi L(si ,si+1 ) every 1 < n 1, wn L(sn1 ,sn ) subset languageL(s0 ,sn ), hence L(). Thus, composing paths witnessing statements preceding list, show (((t), ((t0 )) L()IT ,A . completeproof, simply note ((t)) = (t) ((t0 )) = (t), waydefined . (end proof claim)Claim 1, complete proof match q ,A , sufficientshow match Q , established following claim:Claim 2. every s,s0 (u, u0 ) Q : ((u), (u0 )) L(s,s0 )IT ,A .Proof claim. Take s,s0 (u, u0 ) Q . start case u = u0 =C Loop [s, s0 ]. (y) = e Tail(e) = C, Tail((y)) = C.thus apply Proposition 5.5 infer ((y), (y)) L(s,s0 )IT ,A , yields desiredresult given u = u0 = y. Next suppose either u 6= y, u0 6= y, C 6 Loop [s, s0 ].remove s,s0 (u, u0 ) Step 4, still present Step 5.three cases depending u u0 equals y. treat case separately:Case 1: u = u0 6= y. follows (u) = e (u0 ) = 0 (u0 ). Step 6,replace s,s0 (u, u0 ) s00 ,s0 (u, u0 ) s00 (s, U , s00 )0,A , (u) = e, |=U NR |= R v U . Using facts ( (y), e) RR v U , (s, U , s00 ) , infer ((u), 0 (y)) L(s,s00 )IT ,A . alsoknow atom s00 ,s0 (u, u0 ) belongs q 0 , must satisfied 0 ,yields( 0 (u), 0 (u0 )) L(s00 ,s0 )IT ,A . combining ((u), 0 (y)) L(s,s00 )IT ,A( 0 (u), 0 (u0 )) L(s00 ,s0 )IT ,A , using fact ( 0 (u), 0 (u0 )) = ( 0 (y), (u0 )),infer ((u), (u0 )) L(s,s0 )IT ,A .356fiRegular Path Queries Lightweight Description LogicsCase 2: u 6= u0 = y. follows (u) = 0 (u) (u0 ) = e. Step 6,replace s,s0 (u, u0 ) atom s,s00 (u, u0 ) s00 (s00 , U, s0 )U NR |= R v U . Using similar arguments Case 1, show((u), 0 (y)) L(s,s00 )IT ,A ( 0 (y), (u0 )) L(s00 ,s0 )IT ,A ,deduce ((u), (u0 )) L(s,s0 )IT ,A .Case 3: u = u0 = y. follows (u) = (u0 ) = e. Step 6, replaces,s0 (u, u0 ) atom s00 ,s000 (u, u0 ) s00 , s000 (s, U , s00 )0(s00 , U 0 , s0 ) roles U, U 0 NR |= R v U |= R v U . applying similar reasoning used Cases 1 2, show ((u), 0 (y))L(s,s00 )IT ,A , ( 0 (y), 0 (y)) L(s00 ,s000 )IT ,A , ( 0 (y), (u0 )) L(s000 ,s0 )IT ,A .this, infer ((u), (u0 )) L(s,s0 )IT ,A .Together, Lemmas 6.4 6.5 establish Proposition 6.3. remark numberpossible atoms appearing queries Rewrite(q, ) polynomially bounded|q| + |T |. key property used show following:Proposition 6.6. exponentially many queries Rewrite(q, ),size polynomial |q| + |T |.Proof. Consider DL-LiteR ELH TBox , C2RPQ q, q 0 Rewrite(q, ). firstnote OneStep never introduces fresh variables, vars(q 0 ) vars(q). next noteOneStep introduce fresh concept names, introduces binaryatoms whose NFAs obtained one original NFAs changing initialfinite states. Thus, every atom q 0 takes one following forms:A(v), NC sig(T ) v vars(q)s,s0 (v, v 0 ), appears q, s, s0 states , v, v 0 vars(q)easy see number atoms bounded polynomially |T | + |q|,thus, single-exponentially many distinct queries Rewrite(q, ).6.2 Query EvaluationFigure 16, present non-deterministic algorithm EvalQuery C2RPQ answeringDL-LiteR ELH. algorithm starts checking whether input KB satisfiable.check succeeds, algorithm guesses query Rewrite(q, ) variableassignment calls evaluation algorithm3 EvalAtom Section 5 check whetherassignment yields match query IK . following proposition establishescorrectness EvalQuery.Proposition 6.7. every C2RPQ q, DL-LiteR ELH KB K = (T , A), tupleindividuals ~a Ind(A) arity q: ~a cert(q, K)execution EvalQuery(q, K, ~a) returns yes.3. check KB satisfiability first step EvalQuery, may skip satisfiability checkscalls EvalAtom.357fiBienvenu, Ortiz, & SimkusAlgorithm EvalQueryInput: C2RPQ q(x1 , . . . , xk ), DL-LiteR ELH KB K = hT , Ai, tuple ~a Ind(A)k1. Test whether K satisfiable, output yes not.2. Guess q 0 Rewrite(q, ) assignment ~b individuals qvars(q 0 ).(a) Let q 00 query obtained substituting ~a (x1 , . . . , xk ) ~b qvars(q 0 ),replacing atom form B(a) atom B? (a) B?NFA L(B? ) = {B?} consisting initial state sB0 , single final stateBBBsf , single transition (s0 , B?, sf ).(b) every atom (a, b) q 00check EvalAtom(, K, (a, b)) = yes(c) checks succeed, return yes.3. Return no.Figure 16: Non-deterministic C2RPQ answering algorithm EvalQuery.Proof. Let ~x set answer variables q.show first direction, consider execution EvalQuery input (q, K, ~a)returns yes. algorithm returns yes Step 1, K unsatisfiable, trivially~a cert(q, K). Otherwise, Step 2, algorithm guess query q 0 Rewrite(q, )assignment ~b quantified variables ~y q 0 . Let q 00 query obtainedsubstituting ~a ~x ~b ~y , writing atoms form (a, b) NFA.Step 2(c), every atom (a, b) q 00 , call EvalAtom input (, K, (a, b)). Sincealgorithm returns yes Step 3, must case calls return yes,Proposition 5.8, (a, b) cert(q, K) every atom (a, b) q 00 . followsmapping sending ~x ~a ~y ~b defines match q 0 IK , ~a cert(q 0 , K).Applying Proposition 6.3, obtain ~a cert(q, K).Next suppose ~a cert(q, K). K unsatisfiable, algorithm returnyes Step 1. Otherwise, know Proposition 6.3 exists query q 0Rewrite(q, ) match q 0 ,A maps variables Ind(A)(~x) = ~a. Step 2, choose query q 0 tuple (~y ), ~y setquantified variables q 0 . Let q 00 query obtained substituting ~a ~x ~b ~y ,writing atoms form (a, b) NFA. match know(a, b) cert(q, K) every atom (a, b) q 00 . follows Proposition 5.8calls EvalAtom return yes, EvalQuery return yes Step 2(c).analyzing complexity algorithm EvalQuery, obtain following upperbounds C2RPQ answering, match lower bounds given Section 4.Theorem 6.8. C2RPQ answering1. NL data complexity DL-LiteR DL-LiteRDFS ;358fiRegular Path Queries Lightweight Description Logics2. P data complexity ELH;3. NP combined complexity DL-LiteRDFS ;4. PSpace combined complexity DL-LiteR ELH.Proof. Statement (1), consider resources required run EvalQuery input(T , A, q), formulated DL-LiteR . consistency check Step 1performed non-deterministic logarithmic space |A| (Calvanese et al., 2007). qtreated fixed, computing Rewrite(q, ) requires constant time (and space)|A|. follows guessed query q 0 tuple ~b set atoms endStep 2(a) stored using logarithmic space |A|. Step 2(b), call EvalAtomstored atoms. Theorem 5.9, EvalAtom runs non-deterministic logarithmicspace |A|. Since NLNL = NL, obtain desired NL upper bound data complexity.show Statement 2, consider happens input TBox formulated ELH.case, consistency check Step 1 takes constant time (since every ELH KBsatisfiable), Theorem 5.9, EvalAtom runs polynomial time |A|. thusdecision procedure C2RPQ answering ELH runs non-deterministic logarithmicspace |A| access P oracle. Since NLP = P, yields membership Pdata complexity.establish Statement (3), first note DL-LiteRDFS TBox,query cannot rewritten, i.e., Rewrite(q, ) = {q} (we cannot choose requiredStep 5 Algorithm OneStep entail inclusions form v R).Thus, Step 2 EvalQuery, need guess tuple ~b whose size polynomial |A||q|. calls EvalAtom Step 2(b) run polynomial time input (Theorem5.2), overall procedure runs NP.Statement (4), instead computing whole set Rewrite(q, ), containexponentially many queries, generate single q 0 Rewrite(q, ) non-deterministically.Proposition 6.6, every query Rewrite(q, ) generated exponentially many steps, use polynomial-size counter check reachedlimit. Since rewritten query polynomial size (Proposition 6.6), keepone query memory time, generation single query Rewrite(q, ) requirespolynomial space. proceed statement 3, guessing (polynomialsize) tuple ~b performing polynomial number polynomial-time evaluation checks(Theorem 5.9). yields non-deterministic polynomial space procedure deciding~a cert(q, (T , A)). Using well-known fact NPSpace = PSpace, obtaindesired PSpace upper bound.6.3 Cases Lower ComplexityGiven substantial jump combined complexity NP PSpace movingCQs C(2)RPQs, natural look interesting subcases offer lower complexity. pinpoint two subcases, first obtained restricting query language,second obtained restricting class KBs.359fiBienvenu, Ortiz, & SimkusLet us recall 2RPQs single-atom C2RPQs contain quantified variables. following theorem shows restriction inessential, complexityresults 2RPQs hold also single-atom queries quantified variables.4Theorem 6.9. results Theorem 5.9 hold also single-atom C2RPQs.Proof. Fix DL-LiteR ELH KB K = (T , A). six types single-atom queriesconsider: y. (a, y) (with individual), y. (x, y) (with x answer variable),y. (y, a) (with individual), y. (y, x) (with x answer variable), x, y. (x, y)(with x 6= y), y. (y, y). first five types queries, simple reductions2RPQs. q = x, y. (x, y) (with x 6= y), simply replace q 2RPQq 0 (x, y) = 0 (x, y),L(0 ) = (NR sig(T )) L() (NR sig(T )) .following claim establishes correctness reduction.Claim. K |= q cert(q 0 , K) 6= .Proof claim. First suppose K |= q. K unsatisfiable, triviallycert(q 0 , K) 6= . Otherwise, match q IK . means ((x), (y))L()IK , must exist path p0 (x) (y) (p0 ) L(). Let(x) either equal begins a, let p1 path(x). Since (y) reachable (x), must also reachable a,find path p2 (y) a. may choose p1 p2 (p1 ) (p2 ) belong(NR sig(T )) . combining paths p1 , p0 p2 (in order), obtain pathwhose label belongs (NR sig(T )) L() (NR sig(T )) . follows0(a, a) cert(q , K).Suppose next (a, b) cert(q 0 , K) two (not necessarily distinct) individuals a, b.K unsatisfiable L(), trivially K |= q. Otherwise, path p =e0 u1 e1 u2 . . . un en IK e0 = a, en = b, (p) (NR sig(T )) L()(NR sig(T )) .Since 6 L(), exists 0 < < j n ui . . . uj1 L(). setting(x) = ei1 (y) ej , obtain match q IK . (end proof claim)four types queries containing distinct terms handled similarly:y. (x, y), use 2RPQ q 00 (x, y) = 00 (x, y), L(00 ) = L() (NRsig(T )) . Arguing claim, show b cert(y. (x, y), K) iff (b, c)cert(q 00 (x, y), K) c Ind(A).y. (a, y), K |= y. (a, y) iff cert(y. (x, y), K), reuse2RPQ preceding point.y. (y, x), use 2RPQ q 000 (x, y) = 000 (y, x) L(000 ) = (NR sig(T ))L(). Using similar argument used preceding claim, showb cert(y. (y, x), K) iff (b, c) cert(q 000 (x, y), K) c Ind(A).4. preliminary version paper, fact used general notion single-atom queries(possibly quantified variables) definition 2RPQs (Bienvenu et al., 2013).360fiRegular Path Queries Lightweight Description Logicsy. (y, a), K |= y. (y, a) iff cert(y. (y, x), K), reuse2RPQ preceding point.queries form x. (x, x), proof involved passes definitionalternative rewriting procedure 2RPQs, similar spirit algorithmRewrite guaranteed run polynomial time. Details given appendix.interestingly, adapt techniques preceding proof orderprovide NP upper bound class C2RPQ contain existential-joinvariables, i.e., existentially quantified variables occur query.Theorem 6.10. C2RPQ answering NP combined complexity DL-LiteRELH knowledge bases restricted C2RPQs without existential-join variables.Proof. Consider DL-LiteR ELH KB K = (T , A) C2RPQ q answer variables~x existential variables ~y every variable ~y occurs exactly q. letq 0 C2RPQ obtained q follows:Replace every atom (y1 , y2 ) y1 , y2 existential variablesatom 0 (y1 , y2 ) L(0 ) = (NR sig(T )) L() (NR sig(T )) .Replace every atom (t, y) existential variable individualanswer variable atom 00 (t, y) L(00 ) = L() (NR sig(T )) .Replace every atom (y, t) existential variable individualanswer variable atom 000 (y, t) L(000 ) = (NR sig(T )) L().Add ~y set answer variables.Clearly, takes polynomial time construct C2RPQ q 0 . exploiting factevery existential variable q occurs once, applying similar reasoningused proof Theorem 6.9, show ~a cert(q, K) iff (~a, ~b) cert(q 0 , K)tuple individuals ~b arity ~y . decide whether latter holds,non-deterministically guess tuple ~b let variable assignment maps ~x~a ~y ~b. use EvalAtom verify ((t1 ), (2 )) cert((t1 , t2 ), K)every atom (t1 , t2 ) q 0 , return yes case. Correctness describedprocedure follows correctness EvalAtom (Proposition 5.8). Since EvalAtomimplemented run polynomial time DL-LiteR ELH (Theorem 5.9),obtain NP procedure answering C2RPQs without existential-join variables.preceding result extended bit allow simple chains existential variables. Indeed, remark C2RPQ q contains atoms 1 (x, y) 2 (y, z)z existential-join variable existential variable appearing twoatoms, replace {1 (x, y), 2 (y, z)} 3 (x, z) L(3 ) = {w1 w2 | w1L(1 ), w2 L(2 )} (such NFA 3 easily constructed 1 , 2 polynomial time).performing similar polynomial-time equivalence-preserving transformations,eliminate existential-join variables thereby enlarge class C2RPQshandled using NP procedure.361fiBienvenu, Ortiz, & SimkusFinding interesting classes computationally well-behaved queries likelyprove difficult, given PSpace lower bound Section 4 shown hold evenstrong structural restrictions C2RPQs. suggests may fruitful consider restrictions knowledge bases. next proposition identifies naturalrestriction knowledge bases leads improved NP upper bound.Theorem 6.11. C2RPQ answering NP combined complexity DL-LiteRELH knowledge bases whose canonical models finite domains.Proof. Let K = (T , A) satisfiable DL-LiteR ELH knowledge base whose canonicalmodel IK contains finitely many elements (note K unsatisfiable,trivial perform query answering). follows construction IK fact IKfinite every element aR1 C1 . . . Rn Cn IK Ci 6= Cj 6= j,implies particular n |TCT | (indeed, Ci = Cj < j, domain ,Awould contain element aR1 C1 . . . Rj Cj (Ri+1 Ci+1 . . . Rj Cj )m every 0). relyproperty devise non-deterministic algorithm deciding ~a cert(q, K)runs polynomial time combined size inputs.Without loss generality, may suppose input query q contains binaryatoms form (t, t0 ) NFA. first step, guess mapping termsq sequences form aR1 C1 . . . Rn Cn Ri role, Ci conceptTCT , 0 n |TCT |. second step, verify indeed match q.First, check (b) = b every individual b q, (~x) = ~a ~xtuple answer variables q. Next, check whether (z) ,A every z qvars(q).done polynomial number (polynomial-time) entailment checksverify conditions (A) (B) definition canonical models Section 2.1.4.remains check query atoms satisfied mapping . end,construct new ABox follows. Let E set containing aR1 C1 . . . Rj Cj1 j n aR1 C1 . . . Rj Cj . . . Rn Cn range .introduce fresh individual name e E , let ABox obtainedadding following assertions:R(a, ) R NR R (be , a) R NR e = aRC E NIR(be , be0 ) R NR R (be0 , ) R NR , e0 = eRC E e EC(be0 ) e0 = eRC E e E NI C NCDefine mapping 0 terms q individuals follows: 0 (t) = (t)(t) Ind(A) 0 (t) = b(t) otherwise. every atom (t, t0 ) q, call EvalAtominput (, (T , ), ( 0 (t), 0 (t0 ))); Theorem 5.9, calls needs polynomialtime. output yes case every call EvalAtom returns yes.clear algorithm described runs non-deterministic polynomialtime. show algorithm sound, consider execution algorithmreturns yes, let mapping guessed. Since algorithm returnedyes, know every atom (t, t0 ) q, successful execution EvalAtominput (, (T , ), ( 0 (t), 0 (t0 ))). Since EvalAtom known correct (Theorem 6.7),shows 0 match q ,A . follows way definedconstruction canonical models ,A homomorphically embedded ,A .Moreover, choose homomorphism h h(be ) = e new362fiRegular Path Queries Lightweight Description Logicsindividuals . Since matches C2RPQs preserved homomorphisms,follows match q ,A (~x) = ~a, ~a cert(q, (T , A)).show completeness, suppose match q ,A . construction,homomorphism h ,A ,A maps every individual Ind(A)every e E individual . Using fact query matches preservedhomomorphisms, 0 match q ,A . follows every atom(t, t0 ) q, execution EvalAtom (, (T , ), ( 0 (t), 0 (t0 ))) returnsyes, algorithm returns yes guessing mapping .point class knowledge bases considered Theorem 6.11 practical relevance. Indeed, several important large-scale ELH terminologies, like medicalontology SNOMED5 , acyclic terminologies (see, e.g., (Haase & Lutz, 2008)),guaranteed finite canonical models. Moreover, recently arguedreal-world DL-LiteR ontologies often yield canonical models shallow depth (Kikot,Kontchakov, Podolskii, & Zakharyaschev, 2013).7. Beyond C2RPQs Lightweight DLssection, discuss implications results give brief overviewrelated results similar settings.7.1 Extensions C2RPQsargued paper C2RPQs provide significantly expressivenessplain CQs languages querying ontologies, moderate computational cost. However,C2RPQs also many limitations, several application domains seem call evenexpressive query languages. discuss extensions C2RPQs.7.1.1 Complex Labelspreliminary version present work, added C2RPQs ability talkcombinations concepts roles appear along path (Bienvenu, Ortiz, & Simkus,2012). language, called C2RPQs complex labels, one use,example, expression (sbLFT sbLFSub) find paths stations servedlow-floor tramway subway. Complex labels provide concise flexible syntax many queries, fact increase expressiveness C2RPQs.particular DLs support role conjunction, like ones considered here,standard C2RPQs query pairs stations connected two differentmeans transport, cannot require existence one routefully served both. algorithms described paper extended straightforwardly C2RPQs complex labels, given complexity results apply alsoexpressive query language. However, extension complex labels causessignificant overhead notation technicalities algorithms. Hence,sake readability, decided include extension paper.5. http://www.ihtsdo.org/snomed-ct/363fiBienvenu, Ortiz, & Simkus7.1.2 RPQs NestingRecent works database field advocate extension RPQs nesting, allowingone require objects along path satisfy complex conditions, turn expressed(nested) 2RPQs, line XML query language XPath. RPQs nestingproposed basic component navigational language nSPARQL RDF(Perez, Arenas, & Gutierrez, 2010) received attention settinggraph databases (Reutter, 2013; Barcelo, Perez, & Reutter, 2012).Building conference version work, recently studied query answeringproblem nested (C)2RPQs presence DL ontologies (Bienvenu, Calvanese, Ortiz,& Simkus, 2014). establish tight complexity bounds data combined complexityvariety DLs, ranging lightweight DLs DL-Lite EL consideredpresent paper, highly expressive DLs. show adding nesting (C)2RPQsincrease worst-case data complexity query answering, leads ExpTimehardness combined complexity, even (non-conjunctive) 2RPQs lightweightDLs DL-Lite EL. contrasts sharply tractability result obtainedpaper setting without nesting.authors considered nested navigational queries DL KBs. Stefanoni,Motik, Krotzsch, Rudolph (2014) studied complexity answering certain typesnested path queries knowledge bases formulated OWL 2 EL, extendsELH number constructs, notably complex role inclusions. establishPSpace membership query language roughly corresponds nested (C)RPQsmentioned earlier extended unary complex labels, show P membershipnon-conjunctive fragment. results demonstrate nesting computationallysimpler inverse roles allowed neither queries, ontology language.Kostylev, Reutter, Vrgoc (2015) recently investigated complexity socalled DLXPath family query languages knowledge bases expressed lightweightDLs, particular emphasis connection propositional dynamic logic (PDL)effects negation. expressive variant DLXPath used testBoolean conditions nodes edges (and thus fully captures complex labelsprevious subsection), unfortunately, answering queries undecidable evensimplest settings. Disallowing negation binary relations restores decidability,query answering remains coNP-hard data complexity negation unary expressionspermitted. finally note Bourhis, Krotzsch, Rudolph (2014) recently explored several highly expressive extensions RPQs nesting query answeringremains decidable presence DL ontologies.7.1.3 Path Variables Path Relationsarea graph databases, argued C2RPQs sometimes weaksince neither output witnessing paths, talk relationships holdingdifferent paths. motivated recent extension C2RPQs pathvariables relations among tuples paths (Barcelo et al., 2012; Barcelo & Munoz,2014). introduction path variables makes possible refer specific paths(or precisely, labels paths) used witness satisfactionquery atoms. using path variable multiple atoms, one enforce paths364fiRegular Path Queries Lightweight Description Logicslabel used connect different pairs points. Moreover, path variablesappear answer variables query, case compact representationlabels witnessing paths given output (Barcelo et al., 2012). extensionallows queries enforce tuple path labels belongs given relation, either viaregular relations prefix equal length (Barcelo et al., 2012), using commonnon-regular relations like subword subsequence (Barcelo & Munoz, 2014).in-depth study extensions presence DL ontologies ongoing work,preliminary results suggest addition ontological knowledge makes thingssignificantly harder. instance, even presence simple DL-Lite ontologies,labels paths witnessing query answer may form non-regular language, illustratedfollowing example.Example 7.1. Consider DL-Lite KB K consisting TBox {A v R, R v R}ABox {A(a)}, let q 2RPQ E(x, y) E = r (r ) . infinitelymany paths witnessing (a, a) answer q IK , obtained taking n stepsaway via r, n steps back via r . follows set labelswitnessing paths forms non-regular language {rn (r )n | n 0}.previous example crucially uses inverse roles, non-regular (indeed, non-contextfree!) languages also enforced using shared path variables:Example 7.2. Consider EL KB K consisting TBox {A v r.A, v s.A}ABox {A(a)}. Let q Boolean CRPQ x, y, z. E(x, y) E(y, z) E(x, z)E = (r s) , suppose use path variables require labelpath x label path z. every triplepaths (pxy , pyz , pxz ) witnessing satisfaction q (pxy ) = (pyz )(pxz ) = (pxy )(pyz ). follows set labels witnessing paths thirdatom yields language {ww | w L((r s) )}, neither regular context-free.examples may seem artificial, highlight difficulties arisecombining path variables ontologies. particular, demonstrate cannotuse NFAs compact representation path labels (as case graph databases),even path variables existentially quantified, sharing path variableslikely require significant modification query answering algorithms. Interestingly,seems techniques based word equations regular constraintsrecently explored handling non-regular path relations (Barcelo & Munoz, 2014) mayrelevant presence ontologies already answering queries (existentiallyquantified) path variables, possibly also simple regular relations.7.2 DLsrewriting algorithm C2RPQs inspired technique first proposed answeringCQs DL Horn-SHIQ (Eiter et al., 2012), extended constructslogic. fact, similar algorithm nested C2RPQs already developedDL ELHI subsumes DL-LiteR ELH (Bienvenu et al., 2014). ELHIcontains many constructors Horn-SHIQ, behave similarly termscomputational complexity. point transitive roles, often problematic365fiBienvenu, Ortiz, & Simkusquery answering algorithms, major issue setting. easily accommodated ELHI algorithm combining known techniques axiomatizingTBox transitivity roles, machinery handling transitive closureconstructor queries. extension algorithm ELHI Horn-SHIQ runspolynomial time size data, thus worst-case optimal data complexity. Naturally, combined complexity, may require exponential time cases,always runs single-exponential time, worst-case optimalDLs. Moreover, conjecture implemented smartly, exponential behaviorrarely occur real-world ontologies.7.3 OWL 2 Profiles Query Answering Semantic WebWeb Ontology Language family languages specifying ontologies, endorsedstandard W3C. current version standard, called OWL 2 (OWL WorkingGroup, 2009), features three profiles (Motik et al., 2012) sublanguages restrictexpressivity way logical inference ontologies achieved efficientalgorithms. three profiles provide different modeling capabilities, making suitabledifferent applications: EL profile preferred language life science ontologies,QL profile geared towards applications enrich relational data ontologicalinformation, RL profile used mostly reasoning Web data.information profiles, modeling capabilities supported inference services,refer reader introductory text Krotzsch references therein (Krotzsch,2012). EL DL-Lite families lightweight description logics studied presentpaper provide logical underpinnings EL QL profiles (the third profile, RL,based upon Datalog). consequence, results immediately relevantproblem answering regular path queries OWL 2 knowledge bases formulated usingQL EL profiles. particular, algorithms adapted querying datasets,RDF triplestores, enriched ontological knowledge expressed fragmentsprofiles correspond DL-LiteR ELH.8. Conclusion Future Workpaper, provided algorithms tight complexity bounds answering various forms regular path queries knowledge bases formulated lightweight DLsDL-Lite EL families. results demonstrate query answering problemricher query languages often much harder CQs IQs typically considered. Indeed, DL-LiteR ELH, query answering remains tractabledata complexity PSPACE combined complexity highly expressive classC2RPQs, 2RPQs, even retain tractability combined complexity.computational price seem high, particularly consider rich navigational features queries partially compensate limited expressivenesslightweight ontology languages. thus believe C2RPQs constitute promisinglanguage ontology-mediated query answering.important challenge future work implement experimentally evaluatedeveloped algorithms. Although C2RPQs natural query language aim at,believe makes sense start prototype implementation algorithm366fiRegular Path Queries Lightweight Description Logics(2)RPQs. Indeed, algorithm (2)RPQs significantly lowerworst-case complexity, also considerably simpler rewriting-based approachC2RPQs, confident easily translated practical procedure.contrast, rewriting algorithm used establish PSpace upper bound C2RPQsinvolves considerable amount non-determinism, nave implementationexpected perform poorly. nonetheless believe proposed rewriting approach,suitably modified avoid unnecessary non-deterministic guesses, provides goodbasis development practical methods C2RPQ answering. Finally, identifyingrestrictions queries ontologies lead lower combined complexityanother interesting problem future study.Acknowledgmentsauthors would like thank anonymous reviewers careful readingpaper many helpful comments. work supported FrenchNational Research Agency (ANR) project PAGODA 12-JS02-007-01, Austrian ScienceFund (FWF) project T515, FWF project P25518 Vienna Science Technology Fund (WWTF) project ICT12-015.Appendix A. Proof Theorem 6.9complete proof Theorem 6.9, must show handle queries formx. (x, x). seem simple reduction 2RPQs queriesform, propose instead approach based upon query rewriting.define new query rewriting algorithm prove correctness, requirefollowing notion. Given two concepts C, BCT , say C causes w.r.t.TBox , denoted C D, every ABox model A,C 6= implies DI 6= . difficult see checking C feasiblepolynomial time:Lemma A.1. following problem P: given DL-LiteR ELH TBoxconcepts C, BCT , decide whether C D.Proof. start case DL-LiteR TBox. easy see Ciff |= C v exists sequence role names R1 , . . . , Rn|= C v R1 ,|= Rn v D,1 < n, |= Ri v Ri+1 .observe existence sequence R1 , . . . , Rn satisfying conditionsdecided polynomial time (i) initializing set Reach roles R1|= C v R1 , (ii) saturating Reach adding role Reach whenever |= U vU Reach, (iii) checking whether U Reach |=U v D. Since TBox reasoning tractable DL-LiteR , proceduredescribed performed polynomial time.Assume ELH TBox. C iff |= C v existssequence concepts r1 .A1 , . . . , rn .An , {A1 , . . . , } NC ,367fiBienvenu, Ortiz, & Simkus|= C v r1 .A1 ,|= v D,1 < n, |= Ai v ri+1 .Ai+1 .existence sequence r1 .A1 , . . . , rn .An satisfying conditions decided polynomial time, using saturation procedure analogus one used DLLiteR (recall TBox reasoning tractable ELH).Figure 17, present deterministic query rewriting algorithm PolyRewrite takesinput NFA DL-LiteR ELH TBox outputs set queries,denoted PolyRewrite(, ). case Section 6, purpose query rewritingensure need consider query matches map answer variablesABox individuals. Since interested queries form x. (x, x), turnsaside trivial rewriting (x, x), sufficient consider rewritingsforms C(x) C(x) s1 ,s2 (x, x) C basic concept s1 s2 states. Step 1, initialize Frontier tuples (C, s0 , sf ) C basic concept,s0 initial state , sf final state. Then, iteration loop,remove tuple (C, s1 , s2 ) Frontier add Visited record alreadyexamined. C Loop [s1 , s2 ], corresponding query C(x) s1 ,s2 (x, x)equivalent (under ) simpler query C(x), add Q queries D(x)ensure x. C(x) holds. C 6 Loop [s1 , s2 ], add corresponding queryC(x) s1 ,s2 (x, x) Q. next add Frontier unvisited tuples (D, s5 , s6 )match D(x) s5 ,s6 (x, x) maps x e implies existence matchC(x) s1 ,s2 (x, x) maps x child e anonymous part. operationintuitively moves query match one step closer ABox viewedanalogue Steps 6 7 algorithm Rewrite Section 6.simple inspection algorithm PolyRewrite reveals tuple BCTexamined once, |BCT | |S|2 iterationsloop Step 2. Since know loop, entailment, causation checkscarried polynomial time, obtain following:Lemma A.2. algorithm PolyRewrite runs polynomial time || |T |, hencePolyRewrite(, ) contains polynomial number queries.next two lemmas establish correctness rewriting procedure.Lemma A.3. , |= x. (x, x), exists query q(x) PolyRewrite(, )match ,A (x) Ind(A).Proof. Suppose , |= x. (x, x), let match x. (x, x) ,A .(x) Ind(A), statement trivially holds since (x, x) added Q Step 1.Thus, suppose (x) 6 Ind(A). start proving following claim, capturesquery matches anonymous part canonical model moved closerindividuals:Claim: Suppose (C, s1 , s2 ) added Frontier point executionPolyRewrite input (, ). suppose C 6 Loop [s1 , s2 ], matchs1 ,s2 (x, x) ,A (x) = dRC ,A . tuple368fiRegular Path Queries Lightweight Description LogicsAlgorithm PolyRewrite(, )Input: NFA = (S, , , s0 , F ), DL-LiteR ELH TBox1. Set Q = {(x, x)}, Visited = , Frontier = {(C, s0 , sf ) | C BCT , sf F }.2. Frontier 6=(a) Move tuple (C, s1 , s2 ) Frontier Visiteda .(b) C Loop [s1 , s2 ],every BCTC, add D(x) Q.(c) C 6 Loop [s1 , s2 ],Add C(x) s1 ,s2 (x, x) Q.4every tuple (D, R, s3 , s4 , s5 , s6 ) BCT NRC Loop [s1 , s3 ] C Loop [s4 , s2 ],|= v R C = R [DL-LiteR ] |= v R.C [ELH ],exist roles R0 , R00 |= R v R0 , |= R v R00 , (s3 , R0 , s5 ) ,(s6 , R00 , s4 ) ,(D, s5 , s6 ) 6 (Frontier Visited),add (D, s5 , s6 ) Frontier.3. Output Q.a. choose least tuple Frontier according arbitrary lexicographic ordering BCT SS.note however particular choice tuple affect output procedure.Figure 17: Query rewriting algorithm PolyRewrite.(D, s5 , s6 ) added Frontier point query D(x) s5 ,s6 (x, x)match 0 0 (x) = d, |= v R.C, either Ind(A) Tail(d) = D.Proof claim. Suppose (C, s1 , s2 ) satisfy conditions claim. Since(x) = dRC, follows definition canonical models conceptBCT DIT ,A either |= v R C = R (if formulatedDL-LiteR ), |= v R.C (for ELH TBox). Moreover, may choose= Tail(d) 6 Ind(A). also know match s1 ,s2 (x, x),exists path p = e0 u1 e1 u2 . . . un en e0 = en = (x) whose label (p) belongsL(s1 ,s2 ). Since (p) L(s1 ,s2 ), find sequence states s00 s01 . . . s0n s00 = s1s0n = s2 every 1 n, (s0i1 , ui , s0i ) . C 6 Loop [s1 , s2 ],know match fully contained within ,A |(x) . Thus, must leastone occurrence parent (x) path p. Let ej ek respectively firstlast occurrences p (if single occurrence d, j = k). Observeej1 = ek+1 = (x). Set s3 = s0j1 , s4 = s0k+1 , s5 = s0j , s6 = s0k . pathse0 u1 e1 . . . uj1 ej1 ek+1 uk+2 ek+2 . . . un en witness ((x), (x)) L(s1 ,s3 )IT ,A((x), (x)) L(s4 ,s2 )IT ,A . paths e0 . . . ej1 ek+1 . . . en begin end (x)369fiBienvenu, Ortiz, & Simkusfully contained within ,A |(x) , obtain C Loop [s1 , s3 ] C Loop [s4 , s2 ].Finally, know definiton paths construction canonical modelmust exist roles R0 , R00 |= R v R0 , |= R v R00 , (s3 , R0 , s5 ) ,(s6 , R00 , s4 ) .assumption, tuple (C, s1 , s2 ) added Frontier point,eventually selected Step 2. Moreover, since C 6 Loop [s1 , s2 ], enter 2(c)examining (C, s1 , s2 ). shown above, know tuple(D, R, s3 , s4 , s5 , s6 ) satisfies first three requirements for-loop Step 2(c).fourth requirement also holds, means (D, s5 , s6 ) added Frontier,fails, triple already added Frontier earlierexecution algorithm. complete proof claim, remark pathej uj+1 . . . uk ek witnesses (d, d) L(s5 ,s6 )IT ,A . Moreover, seen DIT ,A .follows setting 0 (x) = d, obtain match query D(x) s5 ,s6 (x, x)required properties. (end proof claim)Observe 0 described claim exists, 0 (x) parent (x)canonical model ,A . finalize proof. Indeed, since (x) 6 Ind(A),(x) = dRC R NR C BCT . match (x, x), must alsomatch s0 ,sf (x, x) sf F . Step 1, tuple (C, s0 , sf ) addedFrontier. Repeated applications claim either yield query q(x) PolyRewrite(, )match mapping x ABox, result insertion tuple (D, s1 , s2 )Frontier D(x)s1 ,s2 (x, x) match ,A Loop [s1 , s2 ]. lattercase, let match D(x) s1 ,s2 (x, x), let Ind(A) (x) ,A |a .follows definition canonical models E BCTE E ,A . Thus, match E(x) PolyRewrite(, )maps x Ind(A).Lemma A.4. q(x) PolyRewrite(, ) match q(x) ,A (x)Ind(A), , |= x. (x, x).Proof. simplify presentation introduce notion containment Boolean queriesw.r.t. TBox. Given TBox two Boolean queries q1 , q2 , write q1 q2every ABox , |= q1 implies , |= q2 . slight abuse notationallow q1 q2 contain atoms form R(x). occurrence R(x)query q shorthand R(x, y) variable occurs q.start establishing following claim:Claim: (C, s1 , s2 ) added Frontier point execution PolyRewriteinput (, ), x. C(x) s1 ,s2 (x, x) x. (x, x).Proof claim. proof induction precedence relation obtained setting(C, s, s0 ) (D, s00 , s000 ) tuple (D, s00 , s000 ) added Frontier examinationtuple (C, s, s0 ). base case, tuples (C, s0 , sf ) insertedStep 1. Every tuple form (C, s0 , sf ), sf F , thus triviallyx. C(x) s0 ,sf (x, x) x. (x, x). Next suppose already shownproperty (C, s1 , s2 ), let (D, s5 , s6 ) (C, s1 , s2 ) (D, s5 , s6 ).suppose match D(x) s5 ,s6 (x, x) ,A . find pathp0 = e0 u1 e1 u2 . . . un en e0 = en = (x) (p) L(s5 ,s6 ). follows370fiRegular Path Queries Lightweight Description Logicsmust exist sequence states s00 s01 . . . s0n s00 = s5 s0n = s6every 1 n, (s0i1 , ui , s0i ) . (C, s1 , s2 ) (D, s5 , s6 ), must existtuple (D, R, s3 , s4 , s5 , s6 ) (D, s5 , s6 ) added Frontier examining(D, R, s3 , s4 , s5 , s6 ). know tuple must satisfied four conditions,must|= v R C = R [DL-LiteR ] |= v R.C [ELH ],C Loop [s1 , s3 ] C Loop [s4 , s2 ],exist roles R0 , R00 |= R v R0 , |= R v R00 , (s3 , R0 , s5 ) ,(s6 , R00 , s4 ) .first point, element (x)RC belongs canonical model, secondpoint, find paths p1 = e00 . . . u0m e0m p2 = e000 . . . u00` e00` e00 = e000 = e0m =e00` = (x)RC, (p1 ) L(s1 ,s3 ), (p2 ) L(s4 ,s2 ). Using third point,show path p = p1 R0 p0 R00 p2 (p ) L(s1 ,s2 ). Since p beginsends (x)RC (x)RC C ,A , follows , |= x. C(x) s1 ,s2 (x, x).induction hypothesis, x. C(x) s1 ,s2 (x, x) x. (x, x), must also, |= x. (x, x). establishes desired containment x. D(x) s5 ,s6 (x, x)x. (x, x). (end proof claim)suppose match q(x) PolyRewrite(, ) ,A (x)Ind(A). three possibilities. first q(x) = (x, x), casetrivially , |= x. (x, x). next possibility q(x) = x. C(x) s,s0 (x, x),case apply preceding claim show , |= x. (x, x). finalpossibility q(x) = D(x), case must (C, s, s0 )Frontier C Loop [s, s0 ] x. D(x) x. C(x). case,x. D(x) x. C(x), x. C(x) x. C(x) s,s0 (x, x) (since C Loop [s, s0 ]),x. C(x) s,s0 (x, x) x. (x, x) (by claim). Putting statements together,obtain x. D(x) x. (x, x), yields , |= x. (x, x).complete argument, observe queries output PolyRewrite either2RPQs take form C(x) C(x)s,s0 (x, x), queries latter forms triviallytransformed 2RPQs. follows answer query form x. (x, x)(i) computing set PolyRewrite(, ), (ii) using EvalAtom check, 2RPQ0 (x, x) obtained PolyRewrite(, ), whether cert(0 (x, x), (T , A)) 6= . Correctnessprocedure follows Proposition 5.8 Lemmas A.3 A.4, complexitybounds follow Lemma A.2 Theorem 5.9.ReferencesAbiteboul, S., Hull, R., & Vianu, V. (1995). Foundations Databases. Addison-Wesley.Arora, S., & Barak, B. (2009). Computational Complexity - Modern Approach. CambridgeUniversity Press.Artale, A., Calvanese, D., Kontchakov, R., & Zakharyaschev, M. (2009). DL-Lite familyrelations. Journal Artificial Intelligence Research (JAIR), 36, 169.371fiBienvenu, Ortiz, & SimkusBaader, F., Brandt, S., & Lutz, C. (2005). Pushing EL envelope. ProceedingsNineteenth International Joint Conference Artificial Intelligence (IJCAI 2005).Bala, S. (2002). Intersection regular languages star hierarchy. ProceedingsTwenty-Ninth International Colloquium Automata, Languages Programming(ICALP 2002).Barcelo, P. (2013). Querying graph databases. Proceedings Thirty-Second Symposium Principles Database Systems (PODS 2013).Barcelo, P., Libkin, L., Lin, A. W., & Wood, P. T. (2012). Expressive languages pathqueries graph-structured data. ACM Transactions Database Systems (TODS),37 (4), 31.Barcelo, P., & Munoz, P. (2014). Graph logics rational relations: role wordcombinatorics. Proceedings Twenty-Ninth Annual ACM/IEEE SymposiumLogic Computer Science (LICS 2014).Barcelo, P., Perez, J., & Reutter, J. L. (2012). Relative expressiveness nested regularexpressions. Proceedings Sixth Alberto Mendelzon International WorkshopFoundations Data Management (AMW 2012).Berglund, A., Boag, S., Chamberlin, D., Fernandez, M. F., Kay, M., Robie, J., & Simeon,J. (2007). XML Path Language (XPath) 2.0. W3C Recommendation. Availablehttp://www.w3.org/TR/xpath20/.Bienvenu, M., Calvanese, D., Ortiz, M., & Simkus, M. (2014). Nested regular path queriesdescription logics. Proceedings Fourteenth International ConferencePrinciples Knowledge Representation Reasoning (KR 2014).Bienvenu, M., Ortiz, M., & Simkus, M. (2012). Answering expressive path querieslightweight DL knowledge bases. Proceedings Twenty-Fifth InternationalWorkshop Description Logics (DL 2012).Bienvenu, M., Ortiz, M., & Simkus, M. (2013). Conjunctive regular path querieslightweight description logics. Proceedings Twenty-Third International JointConference Artificial Intelligence (IJCAI 2013).Bourhis, P., Krotzsch, M., & Rudolph, S. (2014). best nest regular path queries.Proceedings Twenty-Seventh International Workshop Description Logics(DL 2014).Brickley, D., & Guha, R. (2014). RDF Schema 1.1. W3C Recommendation. Availablehttp://www.w3.org/TR/rdf-schema/.Calvanese, D., De Giacomo, G., Lembo, D., Lenzerini, M., & Rosati, R. (2006). Datacomplexity query answering description logics. Proceedings TenthInternational Conference Principles Knowledge Representation Reasoning(KR 2006).Calvanese, D., De Giacomo, G., Lembo, D., Lenzerini, M., & Rosati, R. (2007). Tractablereasoning efficient query answering description logics: DL-Lite family.Journal Automated Reasoning, 39 (3), 385429.372fiRegular Path Queries Lightweight Description LogicsCalvanese, D., De Giacomo, G., & Lenzerini, M. (1998). decidability query containment constraints. Proceedings Seventeenth Symposium Principles Database Systems (PODS 1998).Calvanese, D., Eiter, T., & Ortiz, M. (2007). Answering regular path queries expressivedescription logics: automata-theoretic approach. Proceedings TwentySecond AAAI Conference Artificial Intelligence (AAAI 2007).Calvanese, D., Eiter, T., & Ortiz, M. (2009). Regular path queries expressive description logics nominals. Proceedings Twenty-First International JointConference Artificial Intelligence (IJCAI 2009).Calvanese, D., Eiter, T., & Ortiz, M. (2014). Answering regular path queries expressivedescription logics via alternating tree-automata. Information Computation, 237,1255.Consens, M. P., & Mendelzon, A. O. (1990). GraphLog: visual formalism real liferecursion. Proceedings Ninth Symposium Principles Database Systems(PODS 1990).Ehrenfeucht, A., & Zeiger, P. (1974). Complexity measures regular expressions.Proceedings Sixth Annual ACM Symposium Theory Computing (STOC1974).Eiter, T., Ortiz, M., Simkus, M., Tran, T., & Xiao, G. (2012). Query rewriting HornSHIQ plus rules. Proceedings Twenty-Sixth AAAI Conference ArtificialIntelligence (AAAI 2012).Florescu, D., Levy, A., & Suciu, D. (1998). Query containment conjunctive queriesregular expressions. Proceedings Seventeenth Symposium PrinciplesDatabase Systems (PODS 1998).Haase, C., & Lutz, C. (2008). Complexity subsumption EL family description logics: Acyclic cyclic TBoxes. Proceedings Eighteenth EuropeanConference Artificial Intelligence (ECAI 2008).Harris, S., & Seaborne, A. (2013). SPARQL 1.1 Query Language. W3C Recommendation.Available http://www.w3.org/TR/sparql11-query/.Kikot, S., Kontchakov, R., Podolskii, V. V., & Zakharyaschev, M. (2013). Query rewritingshallow ontologies. Proceedings Twenty-Sixth International WorkshopDescription Logics (DL 2013).Kostylev, E. V., Reutter, J. L., & Vrgoc, D. (2015). XPath DL ontologies. ProceedingsTwenty-Ninth AAAI Conference Artificial Intelligence (AAAI 2015).Kozen, D. (1977). Lower bounds natural proof systems. Proceedings EighteenthAnnual Symposium Foundations Computer Science (SFCS 1977).Krisnadhi, A., & Lutz, C. (2007). Data complexity EL family DLs. ProceedingsTwentieth International Workshop Description Logics (DL 2007).Krotzsch, M. (2012). OWL 2 Profiles: introduction lightweight ontology languages.Proceedings Eighth Reasoning Web Summer School (RW 2012).373fiBienvenu, Ortiz, & SimkusKrotzsch, M., & Rudolph, S. (2007). Conjunctive queries EL composition roles.Proceedings Twentieth International Workshop Description Logics (DL2007).Levy, A. Y., & Rousset, M. (1996). limits combining recursive Horn rulesdescription logics. Proceedings Thirteenth National Conference ArtificialIntelligence Eighth Innovative Applications Artificial Intelligence Conference(AAAI 96).Lutz, C. (2008). complexity conjunctive query answering expressive descriptionlogics. Proceedings Fourth Joint Conference Automated Reasoning (IJCAR2008).Motik, B., Cuenca Grau, B., Horrocks, I., Wu, Z., Fokoue, A., & Lutz, C. (2012). OWL 2Web Ontology Language Profiles. W3C Recommendation. Available http://www.w3.org/TR/owl2-profiles/.Ortiz, M. (2013). Ontology based query answering: story far. ProceedingsSeventh Alberto Mendelzon International Workshop Foundations Data Management (AMW 2013).Ortiz, M., Rudolph, S., & Simkus, M. (2011). Query answering Horn fragmentsdescription logics SHOIQ SROIQ. Proceedings Twenty-SecondInternational Joint Conference Artificial Intelligence (IJCAI 2011).Ortiz, M., & Simkus, M. (2012). Reasoning query answering description logics.Proceedings Eighth Reasoning Web Summer School (RW 2012).Ortiz, M., & Simkus, M. (2014). Revisiting hardness query answering expressivedescription logics. Proceedings Eighth International Conference WebReasoning Rule Systems (RR 2014).OWL Working Group, W. (2009). OWL 2 Web Ontology Language: Document Overview.W3C Recommendation. Available http://www.w3.org/TR/owl2-overview/.Perez, J., Arenas, M., & Gutierrez, C. (2010). nSPARQL: navigational language RDF.Journal Web Semantics, 8 (4), 255270.Reutter, J. L. (2013). Containment nested regular expressions. CoRR, abs/1304.2637.Rosati, R. (2007). conjunctive query answering EL. Proceedings TwentiethInternational Workshop Description Logics (DL 2007).Stefanoni, G., Motik, B., Krotzsch, M., & Rudolph, S. (2014). complexity answeringconjunctive navigational queries OWL 2 EL knowledge bases. JournalArtificial Intelligence Research (JAIR), 51, 645705.Thompson, K. (1968). Regular expression search algorithm. Communications ACM,11 (6), 419422.374fiJournal Artificial Intelligence Research 53 (2015) 127-168Submitted 1/15; published 6/15Clause Elimination SAT QSATMarijn HeuleMARIJN @ CS . UTEXAS . EDUDepartment Computer Science,University Texas Austin, USAMatti JarvisaloMATTI . JARVISALO @ CS . HELSINKI . FIHIIT, Department Computer Science,University Helsinki, FinlandFlorian LonsingFLORIAN . LONSING @ TUWIEN . AC .Institute Information Systems,Vienna University Technology, AustriaMartina SeidlArmin BiereMARTINA . SEIDL @ JKU .BIERE @ JKU .Institute Formal Models Verification,Johannes Kepler University Linz, AustriaAbstractfamous archetypical NP-complete problem Boolean satisfiability (SAT) PSPACEcomplete generalization quantified Boolean satisfiability (QSAT) become central declarative programming paradigms real-world instances various computationally hardproblems efficiently solved. success achieved several breakthroughspractical implementations decision procedures SAT QSAT, is, SAT QSATsolvers. Here, simplification techniques conjunctive normal form (CNF) SATprenex conjunctive normal form (PCNF) QSATthe standard input formats SAT QSATsolvershave recently proven effective increasing solver efficiency applied(i.e., preprocessing) (i.e., inprocessing) satisfiability search.article, develop analyze clause elimination procedures pre- inprocessing.Clause elimination procedures form family (P)CNF formula simplification techniquesremove clauses specific (in practice polynomial-time) redundancy properties maintaining satisfiability status formulas. Extending known procedures tautology,subsumption, blocked clause elimination, introduce novel elimination procedures basedasymmetric variants techniques, also develop novel family so-called coveredclause elimination procedures, well natural liftings CNF-level procedures PCNF.analyze considered clause elimination procedures various perspectives. Furthermore,variants preserving logical equivalence clause elimination, show reconstruct solutions original CNFs satisfying assignments simplified CNFs, important practical applications procedures. Complementing theoretical analysis,present results empirical evaluation practical importance clause elimination procedures terms effect solver runtimes standard real-world application benchmarks.turns importance applying clause elimination procedures developed workempirically emphasized context state-of-the-art QSAT solving.c2015AI Access Foundation. rights reserved.fiH EULE , J ARVISALO , L ONSING , EIDL , & B IERE1. IntroductionBoolean satisfiability (SAT) problem determining whether given propositional logic formula solution. SAT become important declarative approach formulate solvevarious NP-hard problemsa general coverage modern satisfiability research providedBiere, Heule, van Maaren, Walsh (2009). Contrasting classical worst-case view NPcompleteness intractability (Cook, 1971; Garey & Johnson, 1979), central successSAT-based approach major advances robust implementations decision procedures SAT,i.e., SAT solvers. Modern SAT solvers routinely used vast number different industrialartificial intelligence applications (Claessen, Een, Sheeran, & Sorensson, 2008; Marques-Silva,2008), giving rise high demand new techniques improving robustnessefficiency current state-of-the-art SAT solvers.SAT archetypical problem NP, quantified Boolean satisfiability (QSAT) problemevaluating quantified Boolean formulas (QBF), well-known extension SAT, archetypical PSPACE, offering powerful framework modelling large range importantcomputational problems artificial intelligence, knowledge representation, verification, synthesis (Benedetti & Mangassarian, 2008). last decade, much effort spentdevelopment efficient QSAT solvers. Despite several success stories, much research effortneeded QSAT solving reach level maturity modern SAT solvers. Due widerange possible QSAT applications, developing efficient QSAT solver technology indeedimportant on-going quest. major part quest lift techniques proven effective SATsolving general framework QSAT solving analyze impact.Simplification techniques applied (i.e., preprocessing) searchproven integral enabling efficient conjunctive normal form (CNF) level SAT solving realworld application domains. Indeed, large body work preprocessing CNF formulas (Freeman, 1995; Le Berre, 2001; Lynce & Marques-Silva, 2001; Bacchus, 2002; Ostrowski,Gregoire, Mazure, & Sas, 2002; Brafman, 2004; Subbarayan & Pradhan, 2005; Gershman & Strichman, 2005; Een & Biere, 2005; Van Gelder, 2005; Fourdrinoy, Gregoire, Mazure, & Sas, 2007a,2007b; Jin & Somenzi, 2005; Han & Somenzi, 2007; Piette, Hamadi, & Sas, 2008; Jarvisalo, Biere,& Heule, 2010; Manthey, Heule, & Biere, 2013; Heule, Jarvisalo, & Biere, 2013b) based on,examples, variable elimination equivalence reasoning. Further, many SAT solvers relymainly Boolean constraint propagation (that is, unit propagation) search, possibleimprove solving efficiency applying additional simplification techniques also search.dynamic interplay simplification search captured inprocessing SAT solvingparadigm (Jarvisalo, Heule, & Biere, 2012b). Inprocessing SAT solvers recently shownpush efficiency SAT solving, witnessed example L INGELING (Biere,2013), one successful SAT solvers recent SAT Competitions (Jarvisalo, Le Berre,Roussel, & Simon, 2012; SAT Competitions Organizing Committee, 2014). Importantly,scheduling combinations simplification techniques search, even quite simple ideas,removal subsumed clauses, bring additional gains enabling simplificationstechniques.Motivated impact preprocessing SAT, preprocessors QSAT startedemerge, proven advantageous evaluation representative QSAT benchmarks (Samulowitz, Davies, & Bacchus, 2006; Bubeck & Kleine Buning, 2007; Giunchiglia, Marin, & Narizzano, 2010; Mangassarian, Le, Goultiaeva, Veneris, & Bacchus, 2010; Pigorsch & Scholl, 2010).128fiC LAUSE E LIMINATIONSATQSATfact, high promise achieving advances efficiency QSAT solversadding stronger simplification techniques solving flow. Intuitively, due factthat, light simplification preprocessing techniques, real-world SAT QSAT instancestend notably differ size characteristics. Real-world application SAT instances still solvable state-of-the-art SAT solvers today contain tens millions variablesclauses (Jarvisalo et al., 2012), restricts use theoretically interesting polynomial-timesimplification techniques practical applications due shear size input CNF formulassolvers must able cope with. contrast, QSAT instances often relatively small, language QBF enables succinct encodings via quantification. Despite smallsize, QBFs challenging state-of-the-art solvers solve. Hence roomsuccessful applications computationally intensive (but still polynomial-time) simplificationrules. Inprocessing QSAT hardly considered far; solver TRU Q (Pulina &Tacchella, 2009) combines search-based solving variable elimination may consideredstep direction.focus article preprocessing simplification techniques SAT QSATsolving. work motivated one hand possibilities improving SAT QSATsolving efficiency integrating additional simplification techniques solving processand/or search, hand understanding relationshipsdifferent simplification techniques. Especially, concentrate developing analyzing clauseelimination procedures CNF (for SAT) PCNF formulas (for QSAT)the standard inputformats SAT QSAT solvers.Clause elimination procedures form specific family simplification techniques focusremoving redundant clauseswith respect specific redundancy propertiesfrom CNF formulas satisfiability-preserving way. precisely, clause elimination procedure basedredundancy property P procedure which, given CNF (or PCNF) formula F , removes iteratively fixpoint F clauses P . well-defined redundancy propertyP , holds clause C P (P)CNF formula F , F F without Csatisfiability-equivalent. words, F satisfiable whenever F without C satisfiable.However, general redundancy property, simply requiring satisfiability-equivalence clause elimination, applicable practice, since checking whether clause C redundantproperty co-NP-complete (Liberatore, 2005). connection practically relevantclause elimination procedures, context work specific interest clause elimination procedures based polynomial-time checkable redundancy properties. simpleexamples context SAT, two well-known redundancy properties tautologysubsumption. corresponding clause elimination procedures tautology elimination subsumption elimination (Een & Biere, 2005). sophisticated redundancy property blockedclauses (Kullmann, 1999) allows blocked clause elimination (Ostrowski et al., 2002; Jarvisaloet al., 2010).extensions known procedures, work introduce novel elimination proceduresbased asymmetric variants techniques. asymmetric variants, clause CNFfirst augmented certain literals satisfiability CNF preserved. originalclause replaced augmented one. augmented clause turns redundancyproperty, eliminated CNF. Otherwise, original clause restored. alsodevelop novel family so-called covered clause elimination procedures. applications129fiH EULE , J ARVISALO , L ONSING , EIDL , & B IEREgeneral setting QSAT, develop natural liftings CNF-level procedures PCNF,turn outnaturallyto somewhat involved.analyze resulting clause elimination procedures various perspectives. One property reduction power, is, ability remove clauses thus reduce size CNFformula. relative reduction power two clause elimination procedures reveals potentialstrengths procedures, subject practical realizations powerful proceduresfast enough speed total solving time. Another orthogonal property consider BCPpreservance, is, ability preserve possible unit propagations also doneoriginal CNF. BCP-preservance amounts question whether different clause elimination procedures maintain arc consistency clausal level w.r.t. original CNF formula.third property consider, confluence, implies procedure unique fixpoint; practical realizations, knowledge whether simplification procedure confluent interest.non-confluent procedures, well-working elimination-ordering heuristics developed.fourth property consider whether procedures maintain logical equivalence respectoriginal CNF, is, preserve set satisfying assignments. Maintaining logical equivalenceoften necessary applications single solution sought for. However,simplification techniques maintain satisfiability logical equivalence, important develop algorithms fast reconstruction satisfying assignment original CNFassignment simplified instance. Motivated this, variants preserve logical equivalence, show efficiently reconstruct solutions original CNFssatisfying assignments simplified CNFs.Complementing analysis properties relationships considered clauseelimination procedures, also provide empirical results practical implications clauseelimination procedures terms runtime improvements state-of-the-art SAT QSATsolvers real-world application benchmarks. empirical results show clause elimination procedures developed work clear positive effect performance variousstate-of-the-art QSAT solvers, impact performance inprocessing SAT solvingless announced.rest article organized follows. preliminaries SAT, QSAT, related necessary concepts (Section 2), present overview results propertiesclause elimination procedures (Section 3). Technical analysis clause elimination proceduresSAT QSAT presented Sections 46, followed section solution reconstruction (Section 7). concluding, results empirical evaluation procedurespresented Section 8.article extends thoroughly revises work presented earlier 17th International Conference Logic Programming, Artificial Intelligence Reasoning (LPAR 2010) (Heule,Jarvisalo, & Biere, 2010, 2013a) 23rd International Conference Automated Deduction (CADE 2011) (Biere, Lonsing, & Seidl, 2011). variants quantified covered clauseelimination (in Section 6) published previously detail. Further, model reconstruction variants covered clause elimination (in Section 7) new. Compared earlierpublications, empirical evaluation presented article extended updatedrecent state-of-the-art solvers benchmarks. Definitions clause elimination procedures, related analysis, updated better reflect current insightsprocedures. Furthermore, discussions, examples, background extended.130fiC LAUSE E LIMINATIONSATQSAT2. Preliminariessection review necessary background concepts: Boolean satisfiability, resolution, Booleanconstraint propagation, well counterpart general context quantified Booleanformulas.2.1 Boolean SatisfiabilityBoolean variable x, two literals, positive literal, denoted x, negativeliteral, denoted x. clause disjunction literals CNF formula conjunctionclauses. clause seen finite set literals CNF formula finite set clauses.set literals occurring CNF formula F denoted lits(F ). unit clause containsexactly one literal. clause tautology contains x x variable x. GivenCNF formula F , clause C1 F subsumes (another) clause C2 F F C1 C2 .C2 subsumed C1 .truth assignment CNF formula F function maps variables F {t, f}.(x) = v, (x) = v, = f f = t. clause C satisfied (l) =l C. assignment satisfies F satisfies every clause F . assignment falsifiesclause C assigns literals occur C f.Two CNF formulas logically equivalent set satisfying assignmentscommon variables.2.1.1 R ESOLUTIONBCPclassical resolution proof system (Robinson, 1965) CNF formulas consists resolutionrule, states that, given two clauses C1 C2 l C1 l C2 , clause C =(C1 \ {l}) (C2 \ {l}), called resolvent C1 C2 , inferred resolving literall. denoted C = C1 l C2 . resolution rule forms complete proof systemSAT, also important inference rule used preprocessing CNF formulas.Boolean constraint propagation (BCP) unit propagation based applying unit resolution,i.e., special case resolution rule one clauses C1 C2 unit clause.BCP central propagation mechanism applied within typical DPLL CDCL-based SATsolvers. CNF formula F , BCP propagates unit clauses, is, repeats followingfixpoint:unit clause (l) F , remove F \ {(l)} clauses containliteral l, remove literal l clauses F .resulting formula referred BCP(F ). easy see BCP unique fixpointCNF formula. words, BCP confluent.(l) BCP(F ) unit clause (l)/ F , say BCP F assigns literal l(and literal l f). (l), (l) BCP(F ) literal l/ F (or, equivalently, BCP(F )),say BCP derives conflict F . notational convenience, partial assignmentvariables F , let BCP(F, ) := BCP(F F ), = {(x) | (x) = t}F = {(x) | (x) = f}. words, BCP(F, ) denotes formula obtained adding F unitclauses corresponding variable assignments .131fiH EULE , J ARVISALO , L ONSING , EIDL , & B IERE2.2 Quantified Boolean Formulasquantified Boolean formula G prenex conjunctive normal form (PCNF) structure .Fquantifier prefix propositional matrix F conjunctive normal form. quantifierprefix ordered partition Q1 . . . Qn variables F . size quantifier prefix= Q1 . . . Qn , denoted ||, |Q1 | + . . . + |Qn |. element Qi called scopequantifier block. function quant(Qi ) assigns either universal quantifier existentialquantifier scope Qi way quant(Qi ) 6= quant(Qi+1 ). convenience alsowrite Qx1 , . . . , xn scope = {x1 , . . . , xn } quant(S) = Q Q {, }.quantifier level variable x x Qi i, i.e., one plus number preceding scopes.following, assume variable F occurs exactly prefix. sayvariable x universal (existential) QBF .F x quant(S) = (quant(S) = ).notions literals, clauses, tautologies follow SAT. function var(l) returns xl form x x. l = x l = x else l = x. literal l var(l) S, quant(l) =quant(S). clause C, existential universal literals given LQ (C) = {l C |quant(l) = Q} Q {, }. literals l, l var(l) Qi var(l ) Qj , l l j.Let G = .F QBF l literal. G[l] denotes QBF obtained Gdeleting clause C l C, removing occurrence l, substituting scopeQi var(l) Qi Qi \{var(l)}.truth value QBF G = .F recursively defined follows.F = G satisfiable, F G unsatisfiable.quant(Q1 ) = x Q1 , G satisfiable iff G[x] G[x] satisfiable.quant(Q1 ) = x Q1 , G satisfiable iff G[x] G[x] satisfiable.definition QBF semantics indicates ordering variables prefix impactstruth value formula. prefix ordering introduces ordering variablesvariable x assigned variable x < y. restriction specificQBF apply propositional logic variables assigned order.following example illustrates consequences swapping quantifiers.Example 1. QBF G = xy.((x y) (x y)) satisfiable, whereas QBF G =yx.((x y) (x y)) obtained G swapping x prefix unsatisfiable.Intuitively, semantics QBF also considered two-player game (Schaefer, 1978)existential player universal player. former controls existentially quantifiedvariables goal satisfy formula latter controls universally quantified variables goal falsify formula. moves performed according ordervariables quantifier prefix left right. Obviously, universal player takesadvantage CNF structure, conflicts easily detected. reduce biaspreserving benefits CNF, approaches realizing duality-aware reasoning presented (Zhang, 2006; Klieber, Sapra, Gao, & Clarke, 2010; Goultiaeva & Bacchus, 2013; Goultiaeva, Seidl, & Biere, 2013; Sabharwal, Ansotegui, Gomes, Hart, & Selman, 2006).2.2.1 QBF ODELScontext QSAT different definitions models (satisfying assignments).choice one particular definition motivated actual application underlying formal132fiC LAUSE E LIMINATIONSATQSATframework. theoretical setting, satisfiability models QBFs presented sets Skolemfunctions (Kleine Buning & Bubeck, 2009). Skolem function fy models values existentialvariable take satisfy matrix respect universal variables depends.general, Skolem function fy one particular unique. Replacing fy producessemantically equivalent formula. definition satisfiability models theoretical foundation certificate extraction QBFs resolution proofs (Balabanov & Jiang, 2011; Niemetz,Preiner, Lonsing, Seidl, & Biere, 2012). context game-based view QBF semantics, similar approach extracting winning strategies introduced Goultiaeva, Van Gelder,Bacchus (2011). approach directly produce Skolem functions symbolic skolemization (Benedetti, 2005a) implemented verify results solver K IZZO (Benedetti, 2005b).Skolem function extraction so-called QRAT proofs recently proposed Heule, Seidl,Biere (2014b).certain applications related preprocessing QSAT, necessary explicitly distinguishvariable assignments satisfy matrix. Recursive semantics satisfiability modelscoarse hence suitable purpose. Instead, tree-like models QBFsapplied (Samer, 2008; Samulowitz et al., 2006). tree-like model, every path roottree leaf comprises variable assignment satisfies matrix. Assignmentsuniversal variables reflected branches tree. Tree-like models formal foundationpreprocessing techniques QSAT hyper binary resolution (Samulowitz et al., 2006)failed literal detection (Van Gelder, Wood, & Lonsing, 2012) also relevant theoreticalwork dependency schemes (Samer, 2008).different notions models give rise different definitions equivalence theoryQSAT. analogy SAT, equivalence two QBFs G1 G2 checked comparingsets tree-like models G1 G2 , respectively. explicit comparison impossiblerecursive semantics applied. example, definition recursive semantics (Kleine Buning& Bubeck, 2009) distinguishes different assignments free variables QBF,i.e., variables occur matrix explicitly quantified prefix.paper, consider closed QBFs without free variables.Two QBFs G G satisfiability-equivalent following holds: G satisfiable G satisfiable. simplicity, context QSAT write equivalentinstead satisfiability-equivalent.2.2.2 Q-R ESOLUTIONMany techniques used SAT transferred QSAT certain adaptions preserve soundness. following, introduce techniques important restpaper.defining Q-resolution (Kleine Buning, Karpinski, & Flogel, 1995), lifting resolutionrule QSAT, first review concept universal reduction (UR) (Kleine Buning et al., 1995;Cadoli, Giovanardi, & Schaerf, 1998).Definition 1. universally reduced clause C obtained clause C applying universalreduction fixpoint, i.e.,C := C\{l C | quant(l) = , l C quant(l ) = l < l }.133fiH EULE , J ARVISALO , L ONSING , EIDL , & B IEREremoval universally quantified literal l clause contain existentially quantified literals higher level l called universal reduction.easily shown application universal reduction confluent preservessatisfiability formula, provided applied non-tautological clauses only. Baseduniversal reduction rule, Q-resolution combination resolution propositional logicuniversal reduction.Definition 2. Q-resolvent C1 l C2 two non-tautological clauses C1 C2 l C1 ,l C2 , quant(l) = defined (C \ {l}) (C \ {l}) C C universally1212reduced clauses obtained C1 C2 , respectively. literal l called pivot element.construction rule Q-resolvents, enhanced universal reduction rule, formsquantified resolution calculus sound refutationally-complete QSAT (Kleine Buninget al., 1995): QBF G unsatisfiable empty clause derived GQ-resolution universal reduction. combining universal reduction (as Definition 1)Q-resolution (as Definition 2), restriction Q-resolution non-tautological clauses crucialsoundness, following example shows.Example 2. Consider satisfiable QBF G = ax.C1 C2 , C1 = (a x)C2 = (x). Universal reduction cannot reduce literals C1 C2 . Furthermore, C1 C2Q-resolvent since C1 tautological. restriction Q-resolution non-tautologicalclauses ignored, Q-resolvent C1 C2 C = C1 x C2 = (aa). Universal reductionreduces C empty clause, erroneously determines G unsatisfiable.2.2.3 U NITP URE L ITERALSQSATunit literal rule QSAT, part definition BCP QSAT (QBCP) givenfollowing, obtained extending SAT QSAT follows. variable unit literalrequired existentially quantified, universal reduction immediately reduces clausecontaining universal literal empty clause. taking universal reduction account,arrive following rule unit propagations QSAT.Definition 3. existentially quantified literal l unit QBF G = .F {l, l1 , . . . , lm } Fquant(li ) = l < li . l unit G, G equivalent G[l].Obviously, QBF G contains non-tautological clause universally quantified literalsonly, G unsatisfiable. Note unit literal elimination allows ignore quantifier ordering evaluation, i.e., assign variable member outermost quantifierblock.Another important rule allowing assign variable occurring outermost quantifierblock quantified pure literal elimination.Definition 4. literal l pure QBF G = Q1 . . . Qn .F l CF l 6 CF . Gequivalent G[l] quant(l) = equivalent G[l] quant(l) = .addition unit propagation BCP SAT defined, QSAT-specific variant BCP (QBCP) includes quantified pure literal elimination universal reduction (UR) applied fixpoint. elimination universal pure literals universal reduction increase134fiC LAUSE E LIMINATIONSATQSATdeductive power QBCP. words, successive application rules togetherunit propagation allows identify unit clauses would missed unit propagationapplied.3. Overview Contributionssection, give overview main results. overview, present severalimportant definitions basic clause elimination techniques. Further, introduce several measurescomparison, notion relative reduction power, allow detailed analysisvarious techniques.3.1 Clause Elimination Procedures SAT QSATGenerally speaking, clause elimination procedure based redundancy property P procedure which, given CNF (or PCNF) formula F , removes iteratively fixpoint F clausesP . well-defined redundancy property P , hold clauseC P (P)CNF formula F , F F \ {C} satisfiability-equivalent. connectionpractically relevant clause elimination procedures, context work specific interest clause elimination procedures based polynomial-time checkable redundancyproperties. simple examples context SAT, two well-known redundancy properties tautology subsumption, give corresponding clause elimination procedurestautology elimination subsumption elimination.Definition 5 (Tautology Elimination). given formula F , tautology elimination (TE) repeatsfollowing fixpoint: tautological clause C F , let F := F \ {C}. CNFformula resulting applying TE F denoted TE(F ).Definition 6 (Subsumption Elimination). given formula F , subsumption elimination (SE)repeats following fixpoint: subsumed clause C F , let F := F \ {C}.CNF formula resulting applying SE F denoted SE(F ).third earlier definedbut somewhat involvedpolynomial-time checkable redundancyproperty clause blocked1 (Kullmann, 1999), gives corresponding technique blocked clause elimination (BCE). Blocked clause elimination recently shownsurprisingly effective simulating various structure-based simplification mechanisms purelyCNF-level (Jarvisalo, Biere, & Heule, 2012a), motivating techniquetheoretical practical perspectives.Definition 7 (Blocked Clause Elimination SAT). Given CNF formula F , clause C,literal l C, literal l blocks C w.r.t. F clause C F l C , C (C \ {l})tautology. Given CNF formula F , clause C blocked w.r.t. F literal blocksC w.r.t. F . CNF formula F , blocked clause elimination (BCE) repeats followingfixpoint: blocked clause C F w.r.t. F , let F := F \ {C}. CNF formula resultingapplying BCE F denoted BCE(F ).1. Kullmann defines blocking literal l C literal holds resolvents C l ltautologies. definition slightly different implies binary tautologies blocked clauses, contrastKullmanns definition. Apart detail, two definitions equivalent.135fiH EULE , J ARVISALO , L ONSING , EIDL , & B IEREExample 3. Consider following CNF formula, structure often observed CNFencodings graph coloring problems. formula encodes graph two vertices v wedge using three colors. variable vi (or wi ) interpretation vertexv (or w) gets color i.FBCE = (v1 v2 v3 ) (w1 w2 w3 ) (v1 w1 ) (v2 w2 ) (v3 w3 )(v1 v2 ) (v1 v3 ) (v2 v3 ) (w1 w2 ) (w1 w3 ) (w2 w3 ).first two clauses encode v w least one color. next three clauses force vw cannot color. last six clauses denote v w one color.easy check last six clauses blocked FBCE , since clauses,two literals block clause. Thus BCE remove last six binary clausesFBCE . Thus formula BCE(FBCE ) include at-most-one-color constraintsnodes v w, hence, contrast FBCE , BCE(FBCE ) satisfying assignmentsv w assigned multiple colors. However, given satisfying assignment, simplelinear-time algorithm (see Section 7 details) reconstructing satisfying assignment FBCE ,i.e., assignment v w assigned single color.work, focus total eight different clause elimination procedures CNF formulas well PCNF formulas, based clause elimination techniques remove tautological,subsumed, blocked, covered clauses. elimination techniques, considerplain well call asymmetric variant. (plain) tautology elimination (TE),introduce asymmetric tautology elimination (ATE). (plain) subsumption elimination (SE),asymmetric variant ASE, (plain) blocked clause elimination (BCE), asymmetric variant ABCE, respectively. Additionally, develop novel family (including plain(CCE) asymmetric (ACCE) variants) so-called covered clause elimination procedures.context QSAT, propose natural liftings CNF-level clause elimination procedures.redundancy properties tautology subsumed corresponding CNF-level clauseelimination procedures directly applicable ignoring quantifier prefix, PCNF-level procedures based properties blocked covered require care necessary takequantifier prefix account.Due somewhat involved definitions, postpone definitions clause elimination procedures based covered property Section 6 analyze procedures detail.Similarly, liftings blocked covered clause elimination procedures QSAT definedSections 5 6, respectively. However, let us already define concept asymmetric clauseelimination procedures, generalizing (plain) clause elimination procedure. motivatedfact that, shown, asymmetric variants achieve simplificationplain procedures.asymmetric variant clause elimination technique relies clause extension ruleasymmetric literal addition (ALA).Definition 8 (Asymmetric Literal Addition). Given clause C CNF formula F , literal lasymmetric literal clause C exist clause C Fl \ {C} C \ {l} subsumesC. clause C CNF formula F , ALA(F, C) denotes unique clause resultingrepeating following fixpoint: l1 , . . . , lk C clause (l1 . . . lk l)F \ {C} literal l, let C := C {l}.136fiC LAUSE E LIMINATIONSATQSATALA(F, (a b c))Example 4. Consider formula F = (a b c) (a b d) (a c d).first adds asymmetric literals using (a b d) (a c d), respectively. Afterwards,fixpointadd asymmetric literals b using (a b d) c using (a c d).ALA(F, (a b c)) (a b b c c d).easy show replacement clause C occurring CNF F ALA(F, C)preserves logical equivalence regardless whether F quantifier free propositional formulamatrix QBF. words, ALA agnostic quantifier prefix.concrete examples, asymmetric tautology elimination, asymmetric subsumption elimination,asymmetric blocked clause elimination defined follows.Definition 9. clause C asymmetric tautology ALA(F, C) tautology.Asymmetric tautology elimination (ATE) repeats following fixpoint: clauseC F ALA(F, C) tautology, let F := F \ {C}.Example 4.Example 5. Consider formula F = (a b c) (a b d) (a c d)F , ALA(F, (a b c)) = (a b b c c d) tautology, hence removedATE F .stated following lemma, ATE performs could called asymmetric branching clausesreferred UP-redundancy Fourdrinoy et al. (2007a, 2007a) Pietteet al. (2008)which used example technique clause distillation (Jin & Somenzi,2005). gives alternative characterization ATE terms Boolean constraint propagation.Lemma 1. ALA(F, C) tautology BCP (F \ {C}) lC {(l)}) derivesconflict.definitions asymmetric subsumption elimination asymmetric blocked clause elimination analogous asymmetric tautology elimination.Definition 10. Asymmetric subsumption elimination (ASE) repeats following fixpoint:clause C F ALA(F, C) subsumed F , let F := F \ {C}.ASE removeExample 6. Consider formula FASE = (a b c) (a b d) (a c d).subsumed (a b d)(a b c) F , ALA(FASE , (a b c)) = (a b c d)(a c d).Definition 11. given CNF formula F , clause C F asymmetric(ally) blockedALA(F, C) blocked w.r.t. F . Asymmetric blocked clause elimination (ABCE) repeats following fixpoint: asymmetric blocked clause C F ALA(F, C)blocked w.r.t. F , let F := F \ {C}.(a d) (b d)(c d).Example 7. Consider formula FABCE = (a b c) (b c d)ABCE eliminate (a b c), ALA(FABCE , (a b c)) = (a b c d) bc blocking literals. Also, ABCE remove clauses FABCE .turns clause elimination procedures preserve logical equivalence caseSAT, consider information quantifier ordering case QSAT, i.e.,137fiH EULE , J ARVISALO , L ONSING , EIDL , & B IERErules SAT QSAT. Procedures preserve satisfiability equivalenceSAT, however, would become unsound quantifier ordering ignored and, therefore,restrictions imposed prefix considered definition procedures.results quantified variants blocked clause elimination (QBCE) asymmetric blockedclause elimination (AQBCE), detailed Section 5, well quantified variants covered clause elimination (QCCE) asymmetric covered clause elimination (AQCCE) detailedSection 6).3.2 Analyzing Clause Elimination Procedurespresent detailed analysis relationships considered clause eliminationprocedures, terms achieved level simplification (relative reduction power), levelequivalence maintained procedures (in terms sets models original simplifiedformulas), confluence (i.e., whether procedures unique fixpoint), well levelconstraint propagation maintained applying procedures. formally defineconcepts give overview results. Detailed proofs results presentedSections 46. Analysis procedures terms properties later (in Section 8)complemented empirical evaluation effect clause elimination proceduresruntimes state-of-the-art SAT QSAT solvers.relevant aspect simplification techniques question much specific techniquereduces size CNF (and PCNF) formulas. paper analyze relative reduction powerconsidered clause elimination procedures based clauses removed procedures.apply following natural definition reduction power.Definition 12 (Relative reduction power). Assume two clause elimination procedures S1 S2take input arbitrary CNF formula F produce output CNF formulaconsists subset F satisfiability-equivalent F .S1 least powerful S2 if, F output S1 (F ) S2 (F ) S1 S2input F , respectively, S1 (F ) S2 (F );S2 powerful S1 F outputs S1 (F ) S2 (F )S1 S2 , respectively, S1 (F ) S2 (F );S1 powerful S2(i) S1 least powerful S2 ,(ii) S2 powerful S1 .definition relative reduction power takes account non-confluent elimination procedures, is, procedures generally unique fixpoint may thusone possible output given input. noted result non-confluentsimplification procedure unpredictable due non-uniqueness results.definition relative reduction power extends naturally QSAT considering sizereduction matrix QBF. Hence, natural liftings2 QS1 QS2 two CNF-level clauseelimination procedures S1 S2 QBFs, hold S1 powerful S2 ,QS1 powerful QS2 .2. lifting QS1 S1 considered natural QS1 behaves exactly like S1 restricted QBFs without universallyquantified variables.138fiC LAUSE E LIMINATIONASESATA(Q)BCEATEQSATA(Q)CCElogical equivalencepreservingsatisfiability-equivalencepreservingSE(Q)BCETE(Q)CCESE: Subsumption elimination (same SAT QSAT).TE: Tautology elimination (same SAT QSAT).ASE: Asymmetric subsumption elimination (same SAT QSAT).ATE: Asymmetric tautology elimination (same SAT QSAT).(Q)BCE: (Quantified) blocked clause elimination.(Q)CCE: (Quantified) covered clause elimination.A(Q)BCE: Asymmetric (quantified) blocked clause elimination.A(Q)CCE: Asymmetric (quantified) covered clause elimination.Figure 1: Relative reduction power hierarchy clause elimination procedures. edge Xmeans X powerful Y. solid edge means corner cases. dashededge means property hold corner case formula containstautologies. dotted edge means property hold corner caseformula contains empty clause. missing edge X means Xpowerful Y. However, notice transitive edges missing figureclarity. Q prefix clause elimination technique indicatesdifferences QSAT SAT variant.analysis results relative reduction power hierarchy (Figure 1) considered elimination procedures. example, show known plain techniques, asymmetric variants powerful. sense, novel variants proper generalizationsknown plain techniques. also turns powerful technique asymmetricvariant covered clause elimination. figure slightly different earlier work (Heule et al.,2010). changes based renewed view subsumption: tautology subsumedclause.3 view justified fact C F subsumes another clause C FCNF F due C C , C logically entailed F . Since tautological clause C Ftrivially entailed F , regard C subsumed clause C F . noteone single corner case: formula contains tautologies, tautology elimination remove tautologies, subsumption elimination remove all, one. Usingdefinition, subsumption elimination techniques powerful tautology elimination techniques.Additionally, consider properties listed Table 1 analysing clause elimination procedures SAT. easy see TE SE confluent BCP-preserving,also CNF formula F , TE(F ) SE(F ) logically equivalent F . Furthermore,QBF .F , tautology elimination subsumption elimination, well asymmetric3. Donald Knuth convinced us view personal communication July 21, 2014.139fiH EULE , J ARVISALO , L ONSING , EIDL , & B IERETable 1: Properties clause elimination procedures SAT.Preserves logical eq. BCP-preserving ConfluentSubsumption-basedSEyesyesyesyesASETautology-basedTEyesyesyesyesATEBlocked clauseBCEyesABCECovered clauseCCEyesACCEvariants, use information variable ordering, i.e., S(.F ) := .S(F ){TE, SE, ATE, ASE}. also holds BCE confluent (Jarvisalo et al., 2010).techniques preserves satisfiability (and thus sound), turnsvariants blocked clause elimination covered clause elimination preserve logical equivalence; motivation demonstrating Section 7 one efficiently reconstructoriginal solutions based satisfying assignments CNFs simplified using variants.property simplification techniques BCP-preservance, implies relevant unitpropagation (restricted remaining variables simplified CNF formula) possibleoriginal CNF also possible simplified CNF partial assignment. propertysolver-related much practically relevant, since BCP integral part vast majoritySAT solvers today.Definition 13 (BCP-preserving). formula F , preprocessing procedure preserves BCPF partial assignment variables F formula S(F ) resultingapplying F ,(i) literal l occurring S(F ), (l) BCP(F, ) implies (l) BCP(S(F ), )(ii) BCP(F, ) implies BCP(S(F ), ) (the empty clause obtained, is, BCPderives conflict).BCP-preserving preserves BCP every CNF formula.Notice definition similar deductive power defined Han Somenzi (2007).Also notice BCP-preserving implies logical equivalence also preserved. Interestingly,turns BCP-preserving quite strict property, plain SE TE it.note procedure BCP-preserving, procedure powerfulS, immediately BCP-preserving. Similarly, preservelogical equivalence, preserve logical equivalence either. Furthermore, viewingCNF formulas PCNF formulas variables existentially quantified, showingCNF-level procedure BCP-preserving confluent typically directly implies140fiC LAUSE E LIMINATIONSATQSATnegative result lifting PCNF formulas. Indeed, case proceduresconsidered article. Furthermore, since quantifier structure impose restrictionsbehavior {TE, SE, ATE, ASE}, positive results BCP-preservance confluencealso directly translate level PCNF formulas. Hence focus analysis proceduresperspectives CNF-level.following, proceed giving detailed analysis variants tautology, subsumption, blocked clause, covered clause based elimination procedures considering equivalence preserving techniques first followed discussion satisfiability preserving techniques.Finally, experimental results practical effectiveness procedures presented Section 8.4. Logical Equivalence Preserving Clause Elimination Techniquesstart analysis shortly considering clause elimination procedures preserve logicalequivalence, namely, well-known tautology subsumption elimination, asymmetricvariants.Lemma 2. ATE powerful TE.Proof. ATE least powerful TE due C ALA(F, C): C tautology,ALA(F, C). Moreover, let F = (ab)(bc)(ac). Since ALA(F, (ac)) = (aabbcc),ATE remove (a c) F , contrast TE.Proposition 1. ATE confluent.Proof. Consider formula F = (ab)(ac)(ac)(bc)(bc). Now, ALA(F, (ab)) =ALA(F, (a c)) = ALA(F, (b c)) = (a b b c c). ATE remove either (a b)(a c), (b c).Proposition 2. CNF formula F , ATE(F ) logically equivalent F .Proof. clause C removed ATE, (F \ {C}) lC {(l)} unsatisfiable. impliesF \ {C} |= C, is, F \ {C} logically entails C.Proposition 3. ATE BCP-preserving.Proof. Consider standard CNF translation x = If-Then-Else(c, t, e) formula(x c t) (x c t) (x c e) (x c e) (x e t) (x e t).Notice ATE remove (x e t) (x e t). However, removing clauses,BCP longer assign x truth assignment (e) = (t) = f. Also, BCPlonger assign x f truth assignment (e) = (t) = t.Next consider asymmetric variants tautology elimination subsumption elimination.Proposition 4. ASE powerful SE.141fiH EULE , J ARVISALO , L ONSING , EIDL , & B IEREProof. ASE least powerful SE since CNF formula F , (i) every clause C F ,C ALA(F, C), (ii) C subsumed clause C C subsumed. Moreover,consider formula F = (a b c) (a b d) (b c). contrast SE, ASE remove(a b d), ALA(F, (a b d)) = (a b c d) subsumed (a b c).connection Proposition 4, note that, UP-redundancy terminology,equivalently observed Fourdrinoy et al. (2007a) that, essentially, removing asymmetric tautologies fixpoint produces formula closed subsumption elimination.Lemma 3. ATE least powerful ASE, except corner case formula containsempty clause.Proof. Consider corner case formula contains empty clause. case, ASEremove clauses empty clause. However, let F := C Ctautology. ATE cannot remove C, ASE can.see ATE least powerful ASE cases, consider following.clause C F ALA(F, C) subsumed C F \ {C}, ALA(F, C)tautology: say ALA(F, C) subsumed C = (l1 . . . lk ). definition ALA,l1 , . . . , lk ALA(F, C).Lemma 4. ASE least powerful ATE, except corner case formula consiststautologies.Proof. Consider corner case formula consists tautologies. case, ATEremove clauses. However, ASE remove one clause.see ASE least powerful ATE, consider following. tautologysubsumed clause. also holds asymmetric tautologies. Hence longleast one clause available subsumption (which case formula contains leastone non-tautological clause), ASE least powerful ATE.Proposition 5. ASE confluent.Proof. replacing ATE ASE proof Proposition 1.Proposition 6. CNF formula F , ASE(F ) logically equivalent F .Proof. clause C removed ASE, (F \ {C}) lC {(l)} unsatisfiable. impliesF \ {C} |= C, is, F \ {C} logically entails C.replacing ATE ASE proof Lemma 3 following.Proposition 7. ASE BCP-preserving.5. Clause Elimination Procedures based Blocked Clausesthird family clause elimination procedures considered paper, analyze procedures eliminate blocked clauses (Kullmann, 1999) present generalizations thereof QSAT.142fiC LAUSE E LIMINATIONSATQSAT5.1 Blocked Clause Elimination SATstart plain variant blocked clause elimination, BCE.Proposition 8. BCE powerful TE.Proof. see BCE least powerful TE, notice tautology C, Calso tautology. case = C C \ {l} C l Definition 7 BCE. Moreover,consider formula F := (a). BCE remove (a) F , contrast TE.Proposition 9. CNF formula F , BCE(F ) logically equivalent F .Proof. Recall formula FBCE Example 3. Consider truth assignment (v1 ) =(v2 ) = (w3 ) = (v3 ) = (w1 ) = (w2 ) = f. Although satisfies BCE(FBCE ), clause(v1 v2 ) FBCE falsified .Proposition 10. BCE(F ) BCP-preserving.Proof. Follows fact BCE preserve logical equivalence (Proposition 9).turn asymmetric variant blocked clause elimination turnspowerful BCE.Proposition 11. Removal asymmetric blocked clause preserves satisfiability.Proof. Follows facts F logically equivalent (F \ {C}) {ALA(F, C)}BCE preserves satisfiability.Lemma 5. ABCE powerful (i) BCE, (ii) ATE.Proof. ABCE least powerful BCE due C ALA(F, C): C tautology,ALA(F, C) tautology. ABCE least powerful ATE since tautologies blockedclauses. Moreover, recall Example 7, ABCE could eliminate clauses FABCE . Neither BCE ATE remove clause FABCE .Proposition 12. ABCE confluent.(b d) (c d). F contains four asymmetricProof. Let F = (a b) (a c) (a d)blocking literal b, ALA(F, (a c)) =blocked clauses: ALA(F, (a b)) = (a b c d)(a b c d) blocking literal c, ALA(F, (b d)) = (a b c d) blocking literal b,ALA(F, (c d)) = (a b c d) blocking literal c. ABCE removes either (a b)(b d), (a c) (c d) F .Replacing BCE ABCE proof Proposition 9, following.Proposition 13. CNF formula F , ABCE(F ) logically equivalent F .143fiH EULE , J ARVISALO , L ONSING , EIDL , & B IERE5.2 Quantified Blocked Clause Eliminationfollowing, generalize notion blocked clauses blocked clause elimination (BCE)QSAT. prove blocked clauses removed also case QSAT, discussdifferences propositional logic.Definition 14. literal l quant(l) = clause C F QBF G = Q1 . . . Qn .F calledquantified blocking literal C F l C , literal l l l existsl , l C (C \ {l}). clause quantified blocked contains quantified blocking literal.QBF G PCNF, quantified blocked clause elimination repeats removal quantifiedblocked clauses G fixpoint. resulting QBF denoted QBCE(G). definitionquantified blocking literals slightly differs original definition (Biere et al., 2011)uses l , l C l C instead l , l C (C \ {l}). definition includes case either CC tautology, i.e., C l C undefined. Apart this, definitions equivalent.contrast propositional logic, two restrictions selection quantified blocking literals. blocking literal existential literals responsible tautologyresolvent smaller level blocking literal. Without restrictions, quantifiedblocked clause elimination would sound, illustrated following examples.Example 8. clauses satisfiable QBF G = xy.((x y)(xy)) quantified blockedclauses since existential literals quantified blocking literals first secondclause, respectively. Note x < prefix ordering. Let G = xy.((x y) (x y))obtained G changing quantifiers x prefix. QBF G unsatisfiable.clause G quantified blocked since x existential x < y. ignored conditionlevel quantified blocking literal, erroneously clauses G would consideredquantified blocked, removing clause G results satisfiable QBF.Example 9. Consider unsatisfiable QBF yxz.((y x z) (y x z) (y) (z)).definition, literals universal variable x cannot quantified blocking. ignoredquantifier type x erroneously x x first second clause, respectively, wouldconsidered quantified blocking literals. Note condition quantifier level holds,is, < x responsible tautological resolvent two clauses containingx. However, removing second clause, erroneously considered quantified blocked,results satisfiable QBF.following theorem shows, quantified blocked clauses contain redundant information only,may therefore removed formula.Theorem 1. Let G = Q1 . . . Qn .(F {C}) QBF let C quantified blocked clauseG blocking literal l. G Q1 . . . Qn .F equivalent.Proof. Let C quantified blocked clause quantified blocking literal l var(l) Qi ,n. direction G Q1 . . . Qn .F trivially holds. show Q1 . . . Qn .F G inductionq = |Q1 . . . Qi1 |.base case, q = 0, i.e., var(l) Q1 quant(Q1 ) = . argumentSAT (Kullmann, 1999) applies: let satisfying assignment F , i.e., C Fexists literal l (l ) = t. satisfies C, implication Q1 .F G holds,144fiC LAUSE E LIMINATIONSATQSATotherwise construct satisfying assignment F {C} follows. Let (l ) = (l )l 6= l (l) = t. satisfies C also clauses C F . l C ,exists literal l 6= l l C l C , (l ) = (C) = (l ) = f thus(C ) = (l ) = t. Note l Q1 due restriction l l.induction step, assume q > 0. Let h literal var(h) = Q1 . Notevar(l) 6= y. show Q1 \{y} . . . Qn .F [h] G[h]. rest follows liftingimplication conjunction defines semantics universal quantification quant(Q1 )= , and, respectively, disjunction defines semantics existential quantificationquant(Q1 ) = . Three cases considered showing C[h] blocked clauseremoved F [h].1. h C. C removed G[h].2. h 6 C h 6 C. Consequently, C[h] = C. Furthermore, C still quantified blockedclause G[h], since h used make resolvent l tautological. inductionhypothesis applicable.3. h C. Consequently, C[h] = C\{h} quantified blocked clause G[h],clause C h, h C l C removed G[h], clauses C k, kC l C 6= var(k) still produce tautological resolvents C l. Note l C[h]since l 6= h.Theorem 2. application QBCE(G) QBF G confluent.Proof. argument similar propositional logic (see Section 5).soundness quantified blocked clause elimination QSAT, level blockingliteral must equal higher level literal making resolvent tautological,following example illustrates.Example 10. extended example related Example 8 universal reduction applicableclause given unsatisfiable QBFG = xyz.((x z) (x z) (y z) (y z)).first two clauses G encode x z equivalent, last two clauses encodez equivalent. variable z prohibits application universal reduction.first two clauses x x, respectively, quantified blocking literals x < z.clauses erroneously considered blocked removed, resulting QBF wouldsatisfiable.Quantified blocked clauses may eliminated formula without changing truth value,contain redundant information only. Hence, quantified blocked clause eliminationapplied order remove clauses QBF may reduce number variables occurringformula too. following properties established SAT (Kullmann, 1999; Heule et al.,2010), also hold QSAT. sake compactness, omit prefix quantifiedconfusion arises.145fiH EULE , J ARVISALO , L ONSING , EIDL , & B IERE1. Formulas smaller respect number clauses potentially containblocked clauses. matrix QBF G1 subset matrix QBF G2might clauses blocked G1 , G2 . clause Cblocked G2 , G1 , C 6 G1 .2. statement above, follows immediately QBCE unique fixpoint.clause C blocked QBF G, clause C C 6= C blocked G alsoblocked G\{C}.3. clause C subsumed blocked clause C , i.e., C C, C also blockedclause. Obviously, direction hold.4. Clauses containing existential pure literal blocked. pure literal blockingliteral. fact, QBCE may considered generalization pure literal elimination ruleexistentially quantified variables. However, elimination pure literalsuniversally quantified simulated QBCE. general, pure literal eliminationuniversal literals eliminate whole clauses, single literals.5. clauses C1 . . . Cn clauses QBF G contain literal l,clause C l C blocked clause Ci , clause C contains literal lili Ci li < l. particular, QBF G contains equivalence form(l, l1 , . . . , ln ), (l, l1 ), . . . , (l, ln ) l occurs clauses, equivalence may removed due QBCE.fifth property indicates QBCE eliminates equivalences certain conditions.fact, like BCE SAT (Jarvisalo et al., 2012a), QBCE achieves structure-based simplificationsdefined circuit-based representations purely PCNF-level, without explicit knowledgestructure original representation.6. Covered Clause Elimination Proceduresfinal family clause elimination procedures considered paper, introduceanalyze CNF PCNF-level procedures eliminate call covered clauses.Covered clause elimination based successively adding certain literals clause CCNF F = F {C} satisfiability-preserving way. Adding literal l C produces extendedclause C = C {l} replaces C F obtain F = F {C }. C becomes blocked dueadding literal l C removed F BCE, effectively eliminating one clauseF . literals added clause C extension steps called covered literals. literalsdetermined inspecting clauses which, resolved C, result non-tautologicalresolvent. clause becomes blocked adding covered literals called covered clause.application covered clause elimination practice, clause C extended covered literalstentatively. extended clause C become blocked eventually, addedliterals discarded original clause C restored.following, formally define set covered literals, safely usedextend clauses CNF. introduce covered clause elimination SAT QSATanalyze properties. Similar BCE, covered clause elimination preserve logical equivalence. Therefore, Section 7 present algorithm reconstruct solutions CNFscovered clauses eliminated.146fiC LAUSE E LIMINATIONSATQSAT6.1 Covered Clause Elimination Procedures SATGiven CNF formula F , clause C, literal l C, set resolution candidates C w.r.t. lRC(F, C, l) := {C | C Fl C l C tautology}.words, set RC(F, C, l) resolution candidates consists clauses C contain oppositeliteral l, meaning clauses resolved C literal l. Notice every clauseRC(F, C, l) contains literall. RC(F, C, l) = , C blocked w.r.t. F . literalsapart l occur clauses RC(F, C, l) form resolution intersection RI(F, C, l)l C w.r.t. F , formally defined\RI(F, C, l) :=RC(F, C, l) \{l}.words, resolution intersection RI(F, C, l) set literals (apart l) occurclause resolution candidate set RC(F, C, l). Given CNF formula F , clause C F ,literal l C, say l covers literals RI(F, C, l) (w.r.t. F C). literal lcovered l C l RI(F, C, l). literal l C covering w.r.t. F C l covers leastone literal, is, RI(F, C, l) 6= .Example 11. Consider formula(a b c) (a b d)(a c d)FCLA = (a b c) (a b d) (a c d)also visualized resolution graph Figure 2. resolution graph constructedfollows. clauses vertices vertices connected resolutiontwo clauses results non-tautological resolvent. words, vertices connectedexactly one clashing literal. edges label shows correspondingvariable clashing literal pair.BCE cannot remove clause FCLA literal occurrence FCLA existsnon-tautological resolvent. Figure 2 illustrates literal clause leastone edge. Now, RC(FCLA , (a b c), b) = {(a, b, d)}, RI(FCLA , (a b c), b) = {a, d}.words, literal b (a b c) covers literals d. discussed following, adding(a b c) preserves satisfiability. 4addition (a b c), several edges disappear. longer holdsliteral occurrence corresponding edge. literals edge, (for example, cbecome blocking literals.(a c d)),Lemma 6. CNF formula F , clause C F , literal l C, holds replacing CC RI(F, C, l) F preserves satisfiability.Proof. literal l C holds VE(F, l) = VE((F \ {C}) {C RI(F, C, l)}, l),VE(F, l) denotes CNF formula resulting variable eliminating variable literal lF (more formally, VE(F, l) = (Fl Fl ) (F \ (Fl Fl )), Fl Fl consistclauses F contain l l, respectively, Fl Fl = {C l C | C Fl , C Fl ,C l C tautology}).4. fact, based reasoning, one could also eliminate literal (a b c).147fiH EULE , J ARVISALO , L ONSING , EIDL , & B IEREabcbbccbabcdccbb cbbcccbbb cFigure 2: Two resolution graphs FCLA : graphs clause FCLA one vertexvertices connected edge exactly one pair complementaryliterals (hence resolvent non-tautological). edges labeled variablecomplementary literals. top figure shows FCLA adding covered literal(a b c) bottom figure shows FCLA addition. Noticetop figure edge literal. Literals bottom figure edgeassociated them, c (a b c d) blocking literals.given clause C CNF formula F , denote (covered literal addition) CLA(F, C)clause resulting repeating following fixpoint:literal l C RI(F, C, l) \ C 6= , let C := C RI(F, C, l).Lemma 7. Replacing clause C F CLA(F, C) preserves satisfiability.Proof. clause CLA(F, C) obtained iteratively applying Lemma 6 clause C.Lemma 8. Assume two clauses C, l C two sets clauses F, G FG. assume blocked w.r.t. F hence C blocked w.r.t. G.RC(G, C, l) RC(F, D, l) 6= hence RI(G, C, l) RI(F, D, l).Proof. Monotonicity RC w.r.t. first argument anti-monotonicity w.r.t. second argumentfollows directly definition. RI, note intersection anti-monotonic non-emptysets sets.148fiC LAUSE E LIMINATIONSATQSATTheorem 3. Given CNF formula F clause C F , CLA(F, C) blocked uniquelydefined.Proof. Assume C blocked w.r.t. F contains two literals l1 , l2 , cover literalsLi = RI(F, C, li ) respectively. Consider clauses C1 = C L1 C2 = C L2 . assumeC1 , C2 blocked w.r.t. F . clauses RC(F, C1 , l2 ) RC(F, C, l2 )contain literals L2 . Since C1 blocked thus RC(F, C1 , l2 ) empty, obtainL2 RI(F, C1 , l2 ). case indices exchanged (i.e., L1 RI(F, C2 , l1 )) symmetric. Thus long clauses become blocked, covered literals added independently.case C1 , C2 blocked trivial.remains (by symmetry) case C2 blocked C1 not. Again, get L2RI(F, C1 , l2 ). C1 = C1 RI(F, C1 , l2 ) C1 = C L1 RI(F, C1 , l2 ) L1 (C L2 )C2 also blocked. generalizes following observation: non-deterministicchoice adding covered literals C, literal l2 remains covering. Further, processclause become blocked, eventually become blocked covered literals l2added.needed preliminaries place, ready introduce covered clause eliminationprocedures. first one plain variant, simply called covered clause elimination.Definition 15. Given CNF formula F , clause C F covered CLA(F, C) blockedw.r.t. F .Example 12. Back Example 11. Recall RI(FCLA , (abc), b) = {a, d}. Also, RI(FCLA , (aTherefore, depending order addition, CLA(FCLA , (a b c)) eib c), c) = {a, d}.startingther (a b c d) starting covering literal b, (a b c d)covering literal c. cases CLA(F CLA , (a b c)) blocked. replacing (a b c)(a b c d), truth assignment (a) = (b) = (c) = f (d) = satisfiesnew formula, falsifying (a b c) FCLA . fact, FCLA witnesses fact noneclause elimination procedures based covered clauses, introduced next, preserve logicalequivalence general.illustration sis show Figure 2. shows resolution graph FCLAadding covered literal.Lemma 9. Removal arbitrary covered clause preserves satisfiability.Proof. Clause C replaced CLA(F, C) (Lemma 7), C removed CLA(F, C)blocked.Definition 16 (Covered Clause Elimination). given formula F , covered clause elimination(CCE) repeats following fixpoint: covered clause C F , let F := F \ {C}.resulting unique formula denoted CCE(F ).Confluence CCE follows following lemma.Lemma 10. following holds CNF formula F , clause C F , set clauses FC 6 S. C covered w.r.t. F , C covered w.r.t. F \ S.149fiH EULE , J ARVISALO , L ONSING , EIDL , & B IEREProof. Let CLA(F, C) = Ck , C0 := C, Ci+1 := Ci RI(F, Ci , li ) = 0..k 1li Ci . define D0 := C and, = 0..k1, Di+1 := Di Di blocked w.r.t. F \SDi+1 := Di RI(F \ S, Di , li ) otherwise. Using Lemma 8, one show inductioneither (i) Di blocked w.r.t. F \ S, (ii) RI(F \ S, Di , li ) RI(F, Ci , li ).(i) holds i, CLA(F \ S, C) blocked w.r.t. F \ C. Di blocked w.r.t. F \i, CLA(F \ S, C) CLA(F, C).Theorem 4. CCE confluent.Proof. Follows directly Lemma 10: two clauses C covered w.r.t. F , Ccovered w.r.t. F \ {D}.Lemma 11. CCE powerful BCE.Proof. CCE least powerful BCE follows fact C CLA(C): Cblocked, CLA(C). Moreover, FCLA clause blocked. However, clauses covered.Hence BCE remove single clause, CCE removes them.fact, cases possible add covered literals ALA(F, CLA(F, C)): casesadding asymmetric literals clause increase |RI(F, C, l)| non-asymmetric literall C.Example 13. Consider CNF formula F = (a b) (b c) (a c) (a d). NoticeCLA(F, (a b), a) = (a b). Literal c asymmetric w.r.t. (a b) due (b c). adding c,extended clause (a b c) covers d.observation motivates following definition asymmetric covered clauses, basedextending clauses iteratively CLA ALA fixpoint reached. formally,given CNF formula F , clause C F asymmetric covered clause resulting repeating1. C := CLA(F, C).2. C := ALA(F, C).fixpoint blocked w.r.t. F . Based definition, arrive asymmetric covered clauseelimination, ACCE.Definition 17. Asymmetric covered clause elimination (ACCE) repeats following fixpoint:asymmetric covered clause C F , let F := F \ {C}.Lemma 12. Removal arbitrary asymmetric covered clause preserves satisfiability.Proof. Follows facts (i) F satisfiability-equivalent (F \ {C}) {CLA(F, C)};(ii) F satisfiability-equivalent (F \{C}){ALA(F, C)}; (iii) BCE preserves satisfiability.Lemma 13. ACCE powerful (i) ABCE, (ii) CCE.150fiC LAUSE E LIMINATIONSATQSATProof. (i) replacing CCE BCE ACCE ABCE proof Lemma 11. (ii) Consider formulaFACCE = (a b c) (a b c) (a b c) (a b c)(a b c) (a b c) (a b c) (a b c)(a b d) (a b d).(a b d) (a b d)CLA cannot add literals clause FACCE . However, ALA add (a b c)(a b d), respectively. ALA, (a b c) tautology, ACCEusing (a b d)remove it.6.2 Quantified Covered Clause Eliminationintroduce lifting covered clause elimination QSAT. Thereby, covered clausesclauses blocked enriched literals contained resolvent pivotelement l, covering literal. QBCE, prefix ordering taken account.Definition 18. Let QRC denote set resolution candidatesQRC(G, C, l) := {C | C F, l C , 6 l : {l , l } C l C },G QBF matrix F , C F , l C. resolution intersection QRI(G, C, l) lC w.r.t. G given\{C | C QRC(G, C, l), C C , l C : l l} \{l}.QRI(G, C, l) :=literal l called covering literal QRI(G, C, l) 6= , i.e., l covers literals QRI(G, C, l).Lemma 14. replacement clause C QBF G C QRI(G, C, l) preserves unsatisfiability.Proof. show QBF G = .(F {C}) holds G unsatisfiable,G = .(F QRI(G, C, l)). Assume G unsatisfiable, G not.least one assignment (C) = f (QRI(G, C, l)) = t. consequence,least one l QRI(G, C, l) (l ) = t. Due construction QRI, holds C Fl C , (C ) = t. means latest, assigning variables v v < lvalue (v), l pure. means F satisfiable assignment (k) = (k)k 6= l (l) = ( (l)), contradiction assumption G unsatisfiable.following, QRI(G, C) denotes clause C extended quantified covered literals,i.e., l QRI(G, C) holds QRI(G, C, l) QRI(G, C).Lemma 15 (Quantified Covered Literal Addition). replacement clause C QBF GQRI(G, C) preserves unsatisfiability.Proof. Iterative application Lemma 14.Definition 19 (Quantified Covered Clause). clause C QBF G covered QRI(G, C)blocked w.r.t. G.151fiH EULE , J ARVISALO , L ONSING , EIDL , & B IERETheorem 5. removal covered clause preserves unsatisfiability.Proof. According Lemma 15, clause may replaced clause QRI(G, C).clause blocked, may removed according Theorem 1. tautology, removeddue standard rewriting rules.Example 14. QBF a, b, c x, y.((x a) (x b) (x c) (y a)) literal xclause (x a) covers literal y. Therefore, replace clause (x y)blocked due blocking literal y. Consequently, clause (x y) eliminated.restriction literals resolution candidates smaller level accordingpivot necessary correctness quantified covered clause elimination, shownfollowing example.Example 15. Consider unsatisfiable QBF xay.((xy)(xa)(y a)). giverestriction selection resolution candidates, would obtain clause (x a)blocked blocking literal y. remove clause, QBF becomes satisfiable.Lemma 16. Covered clause elimination QSAT confluent.Proof. Assume add literal l clause C order make C covered clauseremoved blocked clause elimination. Assume l QRI(C, l ) literal l C.show clause C l C removed due QCCE, either l may still addedC C blocked hence may removed. C clause containing l,clause C l C . l pure C may removed. Otherwise, lintersection resolvents pivot literal l hence l may added C.7. Reconstructing SolutionsSince elimination procedures based blocked clauses covered clauses preservelogical equivalence, truth assignment satisfying, example, BCE(F ) may satisfy F .section shown solutions original CNF formulas reconstructed basedsolutions CNF formulas resulting applying variations blocked clause coveredclause elimination.7.1 Procedures Based Blocked ClausesJarvisalo Biere (2010) showed how, given CNF formula F truth assignmentsatisfies BCE(F ), one construct satisfying assignment F : Add clauses C F \BCE(F ) back opposite order elimination. case C satisfied , nothing.Otherwise, assuming l C blocking C, flip truth value l t. clausesadded, modified satisfies F .show procedure used reconstruct solutions formulas simplifiedusing ABCE.Lemma 17. Given clause C F , ALA(F, C) blocked tautology,literal l C blocking it.152fiC LAUSE E LIMINATIONSATQSATProof. construction, literal l ALA(F, C) \ C, clause C F contains lC \{l} ALA(F, C). Therefore, ALA(F, C) tautology, C l ALA(F, C) =ALA(F, C) \ {l} tautology either. Hence l blocking ALA(F, C).Lemma 18. Given CNF formula F truth assignment satisfying F , C/ F falsified, ALA(F, C) falsified .Proof. Lemma 1 follows F {ALA(F, C)} logically equivalent F {C}. Therefore,ALA(F, C) satisfied satisfies C.Lemma 19. Given CNF formula F truth assignment satisfying F , C/ F falsifiedALA(F, C) blocked w.r.t. F blocking literal l C, satisfies least twoliterals clause C Fl C .Proof. First, C F contain literal l satisfied . Second, l blocking,clause C must contain one literal l 6= l l ALA(F, C). Since literalsALA(F, C) falsified , l must satisfied .Combining three lemmas, reconstruct solution F satisfyingassignment ABCE(F ). clauses C F \ ABCE(F ) added back reverse orderelimination ensure ALA(F, C) blocked. C satisfied F nothing. Otherwise,know literal l C blocking ALA(F, C); recall Lemma 17. Furthermore,literals ALA(F, C) falsified; recall Lemma 18. However, C F containing l twosatisfied literals; recall Lemma 19. Therefore, flipping truth assignment l t, C becomessatisfied, C becomes falsified.Theorem 6. following holds arbitrary CNF formula F truth assignment satisfyingF . clause C/ F C, ALA(F, C) blocked w.r.t. F blocking literal l, either(i) satisfies F {C}, (ii) , copy except (l) = t, satisfies F {C}.reconstruction proof provides several useful elements used implement ABCEefficiently. First, since original literals l C blocking ALA(F, C), avoidblocking literal check literals l ALA(F, C) \ C. Second, enough save removedoriginal clause C. None additional literals extended clause ALA(F, C) occurringC flipped.implemented reconstruction follows. clause C eliminated procedurebased blocking literals (BCE ABCE), C together blocking literal l C pushedreconstruction stack S: i.e., := S, hl:Ci. reconstruction, examine eliminatedclauses reverse order. clause top stack falsified, truth valueblocking literal flipped. Figure 3 shows pseudo-code algorithm.7.2 Procedures Based Covered Clausescovered clauses eliminated, reconstruction solutions becomes tricky. duefollowing. shown previous section, given satisfying formula F , clauseC falsified , Lemma 18 ALA(F, C) also falsified . However, analogousclaim CLA(F, C) true general.153fiH EULE , J ARVISALO , L ONSING , EIDL , & B IEREreconstruction (CNF formula F , truth assignment , elimination sequence S)emptylet hl:Ci := S.pop()C falsifiedflip truth value lF := F {C}returnFigure 3: Pseudo-code reconstructing solution F reduced formula, satisfying assignment F set eliminated clauses ordered last eliminated.Proposition 14. CNF formula F satisfying truth assignment Ffollowing holds. clause C F falsified , CLA(F, C) satisfied .Proof. Let F = FCLA \ {(a b c)} assume truth assignment assigns (a) = (b) =(c) = (d) = f. Let C = (a b c). Now, satisfies F , falsifies C. Since c C covers d,satisfies CLA(F, C) = (a b c d).Additionally, formula F clause C F , ALA(F, C) blocked w.r.t. F ,literal l C blocking definition. However, case CLA(F, C) blocked, mightliteral CLA(F, C) \ C blocking it.Proposition 15. CNF formula F following holds. exist clauseC F C blocked w.r.t. F CLA(F, C) blocked (due blocking literall CLA(F, C) \ C).Proof. Recall FCLA Section 6. FCLA , (a b c) blocked. However, extendedblocked blocking literal d.clause CLA(FCLA , C) = (a b c d)Due properties stated Propositions 14 15, given truth assignment satisfyingformula F covered clause C F , one may required flip truth values multiplevariables order construct satisfying assignments F {C} based . nextshow achieved.Theorem 7. Given CNF formula F truth assignment satisfying F . Let clause C/ Ffalsified , literal l C satisfies C RI(F, C, l), ,copy l assigned t, satisfies F C.Proof. need show flipping l t, clauses Fl still satisfied. twocases. First, consider clause C Fl C l C tautology. mustx C x C . Since x falsified , C falsified , x satisfiedC . second case C Fl C l C tautology. definition,RI(F, C, l) C . Since C falsified C RI(F, C, l) satisfied , RI(F, C, l)satisfied C .154fiC LAUSE E LIMINATIONSATQSATGiven CNF formula F , C/ F CLA(F, C) blocked w.r.t. F , truth assignmentsatisfying F . use observation Theorem 7 compute, given truth assignmentsatisfies F {C}. case satisfies C trivial ( = ). Otherwise, sequenceC0 , C1 , . . . , Cc C0 := C, Cc := CLA(F, C), Ci+1 := Ci RI(F, Ci , li ) li Ci .Now, let reconstruction stack contain sequence hl0 :C0 i, hl1 :C1 i, . . . , hlc :Cc i. Applying= reconstruction(F, , S) using algorithm Figure 3 produces satisfies F C.7.3 Solution Reconstruction QSATbriefly review approaches obtaining satisfiability models preprocessed formulascontext QSAT. approaches classified two categories depending whether fullpartial satisfiability models generated.First, QSAT applications, sufficient extract partial model formulapreprocessed one. Often values leftmost existential block variables QBFinterest. case, partial model represents single assignment variables,Skolem function zero arity. generate partial models practice, preprocessorrestricted apply preprocessing rules affect variables leftmostquantifier block. variables declared dont touch variables (Seidl & Konighofer, 2014).approach originates incremental bounded model checking based SAT (Kupferschmid,Lewis, Schubert, & Becker, 2011) QSAT (Marin, Miller, & Becker, 2012).alternative dont touch variables, preprocessor equipped partial tracingcapabilities (Heyman, Smith, Mahajan, Leong, & Abu-Haimed, 2014). Thereby, applicationpreprocessing rules restricted. Instead, information necessary reconstruct partialmodel terms assignment leftmost existential variables collected preprocessing.second category comprises methods extract full satisfiability models. Reconstructionsteps common preprocessing rules except expansion universal variables presented Janota, Grigore, Marques-Silva (2013). effect universal expansion cannotexpressed solely Q-resolution, contrast equivalence literal substitution, example,hence causes complications. QRAT proof system (Heule, Seidl, & Biere, 2014a; Heule et al.,2014b) first framework allow extraction full satisfiability models formulas preprocessed using currently implemented preprocessing techniques, including universal expansion.8. Experimental EvaluationComplementing theoretical analysis relationships properties consideredclause elimination procedures, present results empirical evaluation effectapplying clause elimination runtimes state-of-the-art SAT QSAT solvers. benchmarks, used standard competition benchmark sets recent SAT Competition (SATCompetitions Organizing Committee, 2014) QSAT solver evaluation (Jordan & Seidl, 2014),focusing real-world application instances. overview results, turnedclause elimination procedures developed work, applied within preprocessing, clearpositive effect performance various state-of-the-art QSAT solvers. pure CNF SAT formulas, effectswhile still positive non-negative wholeare modest,applying clause elimination preprocessing, well within inprocessing. differencepartly explained follows: SAT benchmarks typically large relatively easy considering155fiH EULE , J ARVISALO , L ONSING , EIDL , & B IEREsize, whiledue succinct representation form enabled use quantifiersQSAT benchmarks relatively small terms hard solve practice. Althoughpresented clause elimination techniques require polynomial timewhile solving proceduresexponentialthey times expensive practice, especially large CNF formulasmillions variables clauses.5experiments performed cluster 2.8-GHz Intel Core 2 Quad machinesequipped 8-GB memory running Ubuntu 9.04.8.1 Effectiveness Clause Elimination Context SATevaluated effectiveness clause elimination procedures context state-of-the-artSAT solvers, specifically L INGELING version aqw (Biere, 2013), application track SAT competition 2013. L INGELING heavily relies concept inprocessing (Jarvisalo et al., 2012b). already discussed introduction, inprocessing basedidea interleaving preprocessing, including clause elimination procedures, search.inprocessing paradigm enables use facts learned search, learned unit clauses,subsequent inprocessing phases, simplified clauses search. Besidesynergistic effect, inprocessing allows preprocessing algorithms pre-empted searchresumed next inprocessing phase, avoid getting stuck too-costly preprocessingstages.difference cost, terms running time, specific inprocessing algorithms,well issue certain simplification steps actually achieved different inprocessingtechniques. consequence, extremely difficult evaluate effect individual inprocessing techniques isolation precisely. alternative, investigated performancecompetition version L INGELING affected disabling (i) clause elimination procedures,(ii) pre- inprocessing techniques clause elimination procedures, (iii) preand inprocessing techniques. benchmark set used instances applicationtrack SAT 2013 competition, time limit 5000 seconds per benchmark, runninghardware almost identical speed competition. essence, results showL INGELING would performed competition without clause elimination comparisonusing none pre- inprocessing techniques applied within solver.note conducted experiment also using application track instancesSAT Competition 2014. modest improvements (as shown following) 2013instances observed, 2014 instances clause elimination procedures noticeablyimprove (nor degrade) performance L INGELING.6 Hence present detailsresults 2013 instances. general, appears clause elimination procedures providemodest improvements SAT solvers, much substantial improvement QSATsolversas demonstrate following.5. fact, terms worst-case complexity, recently shown that, conditional so-called strong exponential time hypothesis (SETH) (Impagliazzo, Paturi, & Zane, 2001; Calabro, Impagliazzo, & Paturi, 2009)true, checking whether given CNF formula contains clause cannot done sub-quadratic time, evenrestricting Horn-3-CNF formulas (Jarvisalo & Korhonen, 2014).6. suspect differences 2013 2014 benchmarks due benchmark selection procedureapplied competition organizers, extent balance performance differences set topperforming solvers previous year. benchmark selection procedure used main SAT competitions20122014 described Balint, Belov, Jarvisalo, Sinz (2015).156fiC LAUSE E LIMINATIONconfigurationpre- & inprocessing disabledclause elimination enabledbase line without clause eliminationL INGELING version aqw (base line)#sat108112111119SAT#unsat8386112113QSAT#total191198223232avg1254120911111124total784440749324632852600691solved formulasformulasTable 2: L INGELING configurations application instances SAT Competition 2013.Among inprocessing algorithms competition version L INGELING implementsfollowing clause elimination procedures. separate BCE inprocessor scheduled inprocessing bounded variable elimination (VE) (Een & Biere, 2005) run-to-completion leastonce. Note BCE implemented much faster variable elimination. However, sincelatter often pronounced effect, run completion first, applyingBCE. Further, proposed Han Somenzi (2007), BCE partially performed on-the-flyVE. configuration without clause elimination disable variants BCE.special case on-the-fly subsumption on-the-fly strengthening conflict clauselearning (Han & Somenzi, 2009), also considered clause elimination procedure,performed search. Thus keep enabled configurations L INGELING usedexperiment. applies subsumption elimination (SE) (Een & Biere,2005) subsumed clauses found lazy hyper binary resolution (Heule et al., 2013b). Another separate inprocessor performs transitive reduction binary implication graph. practice,transitive reduction actually quite fast, unfortunately experience give muchbenefit terms solving times.L INGELING aqw also contains implementation ACCE, rather costly usuallynever runs completion. also another simple partial variant ATE, called basicATE (BATE). computationally inexpensive detect asymmetric tautologies (AT)(two-sided) literal probing (Le Berre, 2001), used basic probing technique variousinprocessing algorithms.default configuration L INGELING aqw, discussed clause elimination procedures wait completed least once, BCE does, also require BCEcompleted least (except BCE obviously). Concretely, configuration L GELING clause elimination procedures disabled called following commandline options: --no-bate --no-block --no-cce --no-transred. specifying --plaincompare configuration pre- inprocessing disabled configuration uses clause elimination procedures pre- inprocessing, using --plain--bate --block --cce=3 --transred, first disables preprocessing selectively enables clause elimination procedure, combined --batewait=0 --blockwait=0--ccewait=1, makes sure CCE started BCE run completion (asdefault configuration) BCE delayed.Results experiment shown Figure 4 Table 2. net result evaluationdefault configuration L INGELING, entered competition, clause elimination procedures enabled, solves 9 instances; base line version solves 232 benchmarks223 without clause elimination. nine instances, eight satisfiable, seems157fiH EULE , J ARVISALO , L ONSING , EIDL , & B IERE50004500pre- & inprocessing disabledclause elimination enabledbase line without clause eliminationLingeling version aqw (base line)4000Runtime (sec)3500300025002000150010005000050100150200250Number solved formulasFigure 4: L INGELING version aqw without clause elimination procedures solves 9 instances lessapplication track benchmark set SAT 2013 Competition time limit5000 seconds.suggest additionally applying clause elimination beneficial especially satisfiable instances.results suggest cases benefits using clause elimination procedures,improvements scale enabling disabling (Een & Biere, 2005).note that, explained detail (Jarvisalo et al., 2012a), BCEextent orthogonal terms simplifications achieved CNF formulas, perform various types similar simplifications own. include, examples, various circuit-leveloptimizations, cone-of-influence monotone input gate reductions, well CNF leveltechniques pure literal eliminations.8.2 Effectiveness Clause Elimination Context QSATfollowing, empirically investigate impact PCNF-level clause elimination proceduresapplied preprocessing QSAT. end, implemented techniques QSATpreprocessor BLOQQER (version 35) (Seidl & Biere, 2015). core BLOQQER basedconcept resolve expand realized QSAT solver Q UANTOR (Biere, 2005). Basically,Q UANTOR complete solver using variable elimination remove existential variablesinnermost quantifier block universal expansion remove variables innermostuniversal quantifier block. Depending benchmark family, approach proved eitherextremely efficient formulas hard solvers could solved within secondsextremely memory-consuming. overcome limitation, developed preprocessor158fiC LAUSE E LIMINATION900SATQSATGhostQbloqqer + GhostQDepQBFbloqqer + DepQBFQuBEbloqqer + QuBERAReQSbloqqer + RAReQS800700Runtime (sec)6005004003002001000050100150200250Number solved formulasFigure 5: Runtimes QBFLib Track Benchmarks QBF Gallery 2014.BLOQQER applies resolve expand approach bounded manner. BLOQQER ,preprocessed formula rewritten way complete solver benefitcareful application variable elimination universal expansion repeatedly appliedformula either change limits reached. (Noteformula might already solved preprocessing phase.) integrated clause eliminationtechniques BLOQQER applied cycle variable eliminationuniversal expansion.evaluating implementation, considered benchmarks QBFLib trackApplication track QBF Gallery 2014 (Jordan & Seidl, 2014). formulas includedQBFLib track selection QBFLib, QBF community platform. set contains345 formulas various benchmark families. competitive evaluation QBF Gallery2014 subset 276 formulas directly solved preprocessors used. benchmarkset Application track consists 735 formulas recently presented encodings QSAT.None formulas directly solved BLOQQER.time memory limits set 900 seconds 7 GB, respectively. Time spentpreprocessing included time limit experiments involve QSAT solvers. preprocessor terminate 900 seconds, preprocessing aborted formulaconsidered unsolved. consider four participants QBF Gallery, publicly available: CDCL-based solver EP QBF (Lonsing & Biere, 2010; Egly, Lonsing, & Widl,2013); CEGAR-based solver RAR E QS (Janota, Klieber, Marques-Silva, & Clarke, 2012);G HOST Q solver (Klieber et al., 2010; Klieber, 2014) implementing CEGAR-based approachcombination so-called ghost variables, allowing duality-aware reasoning CNF level;solver Q U includes preprocessor Q UEEZE BF (Giunchiglia et al., 2010).159fiH EULE , J ARVISALO , L ONSING , EIDL , & B IERE900800Runtime (sec)700600500GhostQbloqqer + GhostQDepQBFbloqqer + DepQBFQuBEbloqqer + QuBERAReQSbloqqer + RAReQS40030020010000100200300400500600Number solved formulasFigure 6: Runtimes Application Track Benchmarks QBF Gallery 2014.configurationpreprocessingVE/ExpansionQBCEQCCEasymmetric CEfull preprocessing#sat4570 (2)76 (27)98 (32)98 (28)99 (33)#unsat7472 (8)91 (34)98 (36)94 (33)98 (37)#total119142 (10)167 (61)196 (68)192 (61)197 (70)avg566647425338total210K192K168K142K148K141Kvars329253292833306333423331033381cls.777103686331776280123164227858average runtime solved formulastotal runtime formulasTable 3: Different BLOQQER configurations solver EP QBF QBFLib benchmarks.preprocessor implements several techniques also included BLOQQER well special kindequivalence substitution, clause elimination procedures like BCE CCE.four solvers run standard configuration without BLOQQER.results shown Figure 5 Figure 6. solvers except G HOST Q preprocessingbeneficial. Application track preprocessing hardly effect runtimeG HOST Q, QBFLib track performance G HOST Q decreased preprocessing.G HOST Q relies structural patterns CNF application preprocessor seemsdestroy patterns.Since BLOQQER implements many preprocessing techniques, just-described experimentdirectly indicate power PCNF-level clause elimination procedures. orderevaluate impact various techniques, run different configurations BLOQQER com160fiC LAUSE E LIMINATIONconfigurationpreprocessingVE/ExpansionQBCEQCCEasymmetric CEfull preprocessing#sat155174189196175192#unsat128219202213213217#total283393391409388409SATavg623660694170QSATtotal424K322K333K322K328K322Kvars112621128311340113561134211358cls.227312173487186860173454174992173402average runtime solved formulastotal runtime formulasTable 4: Different BLOQQER configurations solver EP QBF Application benchmarks.bination solver EP QBF. results summarized Table 3 Table 4. tablesgive number solved satisfiable unsatisfiable formulas well average runtimessolved formulas total runtime complete benchmark set. last two columnsshow average number variables clauses original formulas preprocessing configuration. configurations, average number variables clausespreprocessed formulas given. Table 3 additionally contains information numberformulas directly solved BLOQQER (the number solved formulas brackets). ranfollowing configurations: (i) preprocessing, i.e., solver EP QBF, (ii) variable elimination expansion turned clause elimination techniques turned on, (iii) blocked clauseelimination turned off, (iv) covered clause elimination turned off, (v) asymmetric clause eliminationtechniques turned off, (vi) preprocessing techniques turned on.benchmark sets, observe application BLOQQER beneficial E P QBF. best performance achieved applying preprocessing techniques. turningvariable elimination universal expansion, see using clause elimination techniques already beneficial solver. results different BLOQQER configurations showclause elimination techniques considerably improve runtimes number solvedformulas, especially case QBFLib track benchmarks. average, applicationBLOQQER increases number variables. mainly due universal expansion. However,also configuration expansion disabled, observe modest increase numbervariables. BLOQQER splits large clauses smaller ones turnedbeneficial EP QBF. Especially QBFLib track benchmarks, application BLOQQERdrastically decreases number clauses (more 50 percent configurations).9. ConclusionsPreprocessing inprocessing (generally, formula simplification) techniques proven important speeding state-of-the-art SAT QSAT solving. Understanding effects relationships various simplification procedures important gaining better understanding procedures. article, focused specific type preprocessing techniques,clause elimination procedures remove clauses CNF PCNF formulas based different polynomial-time checkable redundancy properties. introduced novel clause eliminationprocedures CNF PCNF formulas asymmetric variants known techniquestautology, subsumption, blocked clause elimination procedures, additionally developed161fiH EULE , J ARVISALO , L ONSING , EIDL , & B IEREnovel family (including plain asymmetric variants) so-called covered clause elimination procedures. analyzed variants various perspectivesrelative effectiveness,BCP-preserving, confluence, logical equivalencehighlighting intricate differencesprocedures. also resulted relative power hierarchy, reflecting relative strengthsprocedures removing clauses. terms relative power, asymmetric variant coveredclause elimination dominates plain procedures, novel covered clause elimination procedures powerful ones among considered procedures. Complementingtheoretical analysis, presented results empirical evaluation practical effectivenessprocedures speeding-up overall solving runtime state-of-the-art SAT QSAT solversreal-world benchmark instances. results show that, effects SAT-levelmodest, applying clause elimination procedures clearly beneficial context QSATsolving.Many SAT-level clause elimination procedures already integrated inprocessing techniques state-of-the-art SAT solver. important aspect future work wouldintegrate procedures inprocessing techniques QSAT solver. motivationsimilar current state-of-the-art inprocessing SAT solvers: speed satisfiability search via interleaving applications preprocessing techniques core searchroutine. example, clauses may become blocked solving process removed.additional question investigate whether possible loosen blocking criterion taking variable dependencies account. would also interesting perform thorough in-depthstudy clause elimination context generalizations formalisms related SAT,maximum satisfiability (MaxSAT) extraction minimally unsatisfiable subsets(MUSes) CNF formulas. recent work looking possibilities applyingSAT-based preprocessing contexts MUS MaxSAT (Belov, Jarvisalo, & Marques-Silva,2013a; Belov, Morgado, & Marques-Silva, 2013b; Berg, Saikko, & Jarvisalo, 2015)includinguse BCEwe believe directions yet fully explored.Acknowledgmentsauthors would like thank Donald Knuth comments helped improve article.authors gratefully acknowledge financial support DARPA contract number N66001-102-4087 (MH); Academy Finland grants 251170 COIN Centre Excellence Computational Inference Research, 276412, 284591 (MJ); Austrian Science Foundation (FWF) NFNGrants S11408-N23 RiSE (AB) S11409-N23 RiSE (FL); Vienna Science TechnologyFund (WWTF) grant ICT10-018 (MS).ReferencesBacchus, F. (2002). Enhancing Davis Putnam extended binary clause reasoning. Dechter, R.,& Sutton, R. S. (Eds.), Proceedings 18th National Conference Artificial Intelligence(AAAI 2002), pp. 613619. AAAI Press.Balabanov, V., & Jiang, J.-H. R. (2011). Resolution proofs Skolem functions QBF evaluation applications. Gopalakrishnan, G., & Qadeer, S. (Eds.), Proceedings 23rd162fiC LAUSE E LIMINATIONSATQSATInternational Conference Computer Aided Verification (CAV 2011), Vol. 6806 LectureNotes Computer Science, pp. 149164. Springer.Balint, A., Belov, A., Jarvisalo, M., & Sinz, C. (2015). Overview analysis SAT Challenge2012 solver competition. Artificial Intelligence, 223, 120155.Belov, A., Jarvisalo, M., & Marques-Silva, J. (2013a). Formula preprocessing MUS extraction.Piterman, N., & Smolka, S. A. (Eds.), Proceedings 19th International ConferenceTools Algorithms Construction Analysis Systems (TACAS 2013), Vol. 7795Lecture Notes Computer Science, pp. 108123. Springer.Belov, A., Morgado, A., & Marques-Silva, J. (2013b). SAT-based preprocessing MaxSAT.McMillan, K. L., Middeldorp, A., & Voronkov, A. (Eds.), Proceedings 19th International Conference Logic Programming, Artificial Intelligence, Reasoning (LPAR19), Vol. 8312 Lecture Notes Computer Science, pp. 96111. Springer.Benedetti, M. (2005a). Extracting certificates quantified boolean formulas. Kaelbling, L. P.,& Saffiotti, A. (Eds.), Proceedings 19th International Joint Conference ArtificialIntelligence (IJCAI 2005), pp. 4753. Professional Book Center.Benedetti, M. (2005b). sKizzo: Suite Evaluate Certify QBFs. Nieuwenhuis, R. (Ed.),Proceedings 20th International Conference Automated Deduction (CADE-20), Vol.3632 Lecture Notes Computer Science, pp. 369376. Springer.Benedetti, M., & Mangassarian, H. (2008). QBF-based formal verification: Experience perspectives. Journal Satisfiability, Boolean Modeling Computation, 5(1-4), 133191.Berg, J., Saikko, P., & Jarvisalo, M. (2015). Improving effectiveness SAT-based preprocessing MaxSAT. Proceedings 24th International Joint Conference ArtificialIntelligence (IJCAI 2015). AAAI Press.Biere, A. (2005). Resolve expand. Hoos, H. H., & Mitchell, D. G. (Eds.), Revised Selected Papers 7th International Conference Theory Applications SatisfiabilityTesting (SAT 2004), Vol. 3542 Lecture Notes Computer Science, pp. 5970. Springer.Biere, A. (2013). Lingeling, Plingeling Treengeling entering SAT Competition 2013.Balint, A., Belov, A., Heule, M., & Jarvisalo, M. (Eds.), Proceedings SAT Competition2013, Vol. B-2013-1 Department Computer Science Series Publications B, pp. 5152. University Helsinki.Biere, A., Heule, M., van Maaren, H., & Walsh, T. (Eds.). (2009). Handbook Satisfiability, Vol.185 Frontiers Artificial Intelligence Applications. IOS Press.Biere, A., Lonsing, F., & Seidl, M. (2011). Blocked clause elimination QBF. Bjrner, N.,& Sofronie-Stokkermans, V. (Eds.), Proceedings 23rd International ConferenceAutomated Deduction (CADE 2011), Vol. 6803 Lecture Notes Computer Science, pp.101115. Springer.Brafman, R. I. (2004). simplifier propositional formulas many binary clauses. IEEETransactions Systems, Man, Cybernetics, Part B, 34(1), 5259.Bubeck, U., & Kleine Buning, H. (2007). Bounded universal expansion preprocessing QBF.Marques-Silva, J., & Sakallah, K. A. (Eds.), Proceedings 10th International Conference163fiH EULE , J ARVISALO , L ONSING , EIDL , & B IERETheory Applications Satisfiability Testing (SAT 2007), Vol. 4501 Lecture NotesComputer Science, pp. 244257. Springer.Cadoli, M., Giovanardi, A., & Schaerf, M. (1998). algorithm evaluate quantified booleanformulae. Mostow, J., & Rich, C. (Eds.), Proceedings 15th National ConferenceArtificial Intelligence (AAAI 1998), pp. 262267. AAAI Press / MIT Press.Calabro, C., Impagliazzo, R., & Paturi, R. (2009). complexity satisfiability small depthcircuits. Chen, J., & Fomin, F. V. (Eds.), Revised Selected Paper 4th InternationalWorkshop Parameterized Exact Computation (IWPEC 2009), Vol. 5917 LectureNotes Computer Science, pp. 7585. Springer.Claessen, K., Een, N., Sheeran, M., & Sorensson, N. (2008). SAT-solving practice. Proceedings 9th International Workshop Discrete Event Systems (WODES 2008), pp. 6167.IEEE.Cook, S. A. (1971). complexity theorem-proving procedures. Harrison, M. A., Banerji,R. B., & Ullman, J. D. (Eds.), Proceedings 3rd Annual ACM Symposium TheoryComputing (STOC 1971), pp. 151158. ACM.Een, N., & Biere, A. (2005). Effective preprocessing SAT variable clause elimination.Bacchus, F., & Walsh, T. (Eds.), Proceedings 8th International Conference TheoryApplications Satisfiability Testing (SAT 2005), Vol. 3569 Lecture Notes ComputerScience, pp. 6175. Springer.Egly, U., Lonsing, F., & Widl, M. (2013). Long-distance resolution: Proof generation strategy extraction search-based QBF solving. McMillan, K., Middeldorp, A., & Voronkov,A. (Eds.), Proceedings 19th International Conference Logic Programming, Artificial Intelligence, Reasoning (LPAR 2013), Vol. 8312 Lecture Notes ComputerScience, pp. 291308. Springer.Fourdrinoy, O., Gregoire, E., Mazure, B., & Sas, L. (2007a). Eliminating redundant clauses SATinstances. Hentenryck, P. V., & Wolsey, L. A. (Eds.), Proceedings 4th InternationalConference Integration AI Techniques Constraint Programming (CPAIOR2007), Vol. 4510 Lecture Notes Computer Science, pp. 7183. Springer.Fourdrinoy, O., Gregoire, E., Mazure, B., & Sas, L. (2007b). Reducing hard SAT instancespolynomial ones. Proceedings 8th IEEE International Conference InformationReuse Integration (IRI 2007), pp. 1823. IEEE.Freeman, J. (1995). Improvements propositional satisfiability search algorithms. Ph.D. thesis,University Pennsylvania.Garey, M. R., & Johnson, D. S. (1979). Computers Intractability: Guide TheoryNP-Completeness. W. H. Freeman.Gershman, R., & Strichman, O. (2005). Cost-effective hyper-resolution preprocessing CNFformulas. Bacchus, F., & Walsh, T. (Eds.), Proceedings 8th International ConferenceTheory Applications Satisfiability Testing (SAT 2005), Vol. 3569 Lecture NotesComputer Science, pp. 423429. Springer.Giunchiglia, E., Marin, P., & Narizzano, M. (2010). sQueezeBF: effective preprocessorQBFs based equivalence reasoning. Strichman, O., & Szeider, S. (Eds.), Proceedings164fiC LAUSE E LIMINATIONSATQSAT13th International Conference Theory Applications Satisfiability Testing (SAT2010), Vol. 6175 Lecture Notes Computer Science, pp. 8598. Springer.Goultiaeva, A., & Bacchus, F. (2013). Recovering utilizing partial duality QBF. Jarvisalo,M., & Gelder, A. V. (Eds.), Proceedings 16th International Conference TheoryApplications Satisfiability Testing (SAT 2013), Vol. 7962 Lecture Notes ComputerScience, pp. 8399. Springer.Goultiaeva, A., Seidl, M., & Biere, A. (2013). Bridging gap dual propagationCNF-based QBF solving. Macii, E. (Ed.), Proceedings Design, Automation TestEurope Conference & Exhibition (DATE 2013), pp. 811814. EDA Consortium / ACM DL.Goultiaeva, A., Van Gelder, A., & Bacchus, F. (2011). uniform approach generating proofsstrategies true false QBF formulas. Walsh, T. (Ed.), Proceedings22nd International Joint Conference Artificial Intelligence (IJCAI 2011), pp. 546553.IJCAI/AAAI Press.Han, H., & Somenzi, F. (2007). Alembic: efficient algorithm CNF preprocessing. Proceedings 44th Design Automation Conference (DAC 2007), pp. 582587. IEEE.Han, H., & Somenzi, F. (2009). On-the-fly clause improvement. Kullmann, O. (Ed.), Proceedings12th International Conference Theory Applications Satisfiability Testing (SAT2009), Vol. 5584 Lecture Notes Computer Science, pp. 209222. Springer.Heule, M., Jarvisalo, M., & Biere, A. (2010). Clause elimination procedures CNF formulas.Fermuller, C., & Voronkov, A. (Eds.), Proceedings 17th International ConferenceLogic Programming, Artificial Intelligence Reasoning (LPAR-17), Vol. 6397Lecture Notes Computer Science, pp. 357371. Springer.Heule, M., Jarvisalo, M., & Biere, A. (2013a). Covered clause elimination. Fermuller, C., &Voronkov, A. (Eds.), Short Paper Proceedings 17th International Conference LogicProgramming, Artificial Intelligence Reasoning (LPAR-17), Vol. 13 EasyChairProceedings Computing, pp. 4146.Heule, M., Jarvisalo, M., & Biere, A. (2013b). Revisiting hyper binary resolution. Gomes, C. P.,& Sellmann, M. (Eds.), Proceedings 10th International Conference IntegrationAI Techniques Constraint Programming Combinatorial Optimization Problems(CPAIOR 2013), Vol. 7874 Lecture Notes Computer Science, pp. 7793. Springer.Heule, M., Seidl, M., & Biere, A. (2014a). Unified Proof System QBF Preprocessing.Demri, S., Kapur, D., & Weidenbach, C. (Eds.), Proceedings 7th International JointConference Automated Reasoning (IJCAR 2014), Vol. 8562 Lecture Notes ComputerScience, pp. 91106. Springer.Heule, M., Seidl, M., & Biere, A. (2014b). Efficient extraction Skolem functions QRATproofs. Claessen, K., & Kuncak, V. (Eds.), Proceedings 14th International Conference Formal Methods Computer-Aided Design (FMCAD 2014), pp. 107114. IEEE.Heyman, T., Smith, D., Mahajan, Y., Leong, L., & Abu-Haimed, H. (2014). Dominant controllabilitycheck using QBF-solver netlist optimizer. Sinz, C., & Egly, U. (Eds.), Proceedings17th International Conference Theory Applications Satisfiability Testing (SAT2014), Vol. 8561 Lecture Notes Computer Science, pp. 227242. Springer.165fiH EULE , J ARVISALO , L ONSING , EIDL , & B IEREImpagliazzo, R., Paturi, R., & Zane, F. (2001). problems strongly exponential complexity?. Journal Computer System Sciences, 63(4), 512530.Janota, M., Grigore, R., & Marques-Silva, J. (2013). QBF proofs preprocessing. McMillan, K. L., Middeldorp, A., & Voronkov, A. (Eds.), Proceedings 19th InternationalConference Logic Programming, Artificial Intelligence, Reasoning (LPAR-19),Vol. 8312 Lecture Notes Computer Science, pp. 473489. Springer.Janota, M., Klieber, W., Marques-Silva, J., & Clarke, E. (2012). Solving QBF counterexampleguided refinement. Cimatti, A., & Sebastiani, R. (Eds.), Proceedings 15th International Conference Theory Applications Satisfiability Testing (SAT 2012), Vol. 7317Lecture Notes Computer Science, pp. 114128. Springer.Jarvisalo, M., & Biere, A. (2010). Reconstructing solutions blocked clause elimination.Strichman, O., & Szeider, S. (Eds.), Proceedings 13th International ConferenceTheory Applications Satisfiability Testing (SAT 2010), Vol. 6175 Lecture NotesComputer Science, pp. 340345. Springer.Jarvisalo, M., Biere, A., & Heule, M. (2010). Blocked clause elimination. Esparza, J., & Majumdar, R. (Eds.), Proceedings 16th International Conference Tools AlgorithmsConstruction Analysis Systems (TACAS 2010), Vol. 6015 Lecture NotesComputer Science, pp. 129144. Springer.Jarvisalo, M., Biere, A., & Heule, M. (2012a). Simulating circuit-level simplifications CNF.Journal Automated Reasoning, 49(4), 583619.Jarvisalo, M., Heule, M., & Biere, A. (2012b). Inprocessing rules. Gramlich, B., Miller, D.,& Sattler, U. (Eds.), Proceedings 6th International Joint Conference AutomatedReasoning (IJCAR 2012), Vol. 7364 Lecture Notes Computer Science, pp. 355370.Springer.Jarvisalo, M., & Korhonen, J. H. (2014). Conditional lower bounds failed literals relatedtechniques. Sinz, C., & Egly, U. (Eds.), Proceedings 17th International ConferenceTheory Applications Satisfiability Testing (SAT 2014), Vol. 8561 Lecture NotesComputer Science, pp. 7584. Springer.Jarvisalo, M., Le Berre, D., Roussel, O., & Simon, L. (2012). international SAT solver competitions. AI Magazine, 33(1), 8992.Jin, H., & Somenzi, F. (2005). incremental algorithm check satisfiability bounded modelchecking. Electronic Notes Theoretical Computer Science, 119(2), 5165.Jordan, C., & Seidl, M. (2014). QBF Gallery 2014. http://qbf.satisfiability.org/gallery/.Kleine Buning, H., & Bubeck, U. (2009). Theory quantified Boolean formulas. Biere, A.,Heule, M., van Maaren, H., & Walsh, T. (Eds.), Handbook Satisfiability, Vol. 185 Frontiers Artificial Intelligence Applications, pp. 735760. IOS Press.Kleine Buning, H., Karpinski, M., & Flogel, A. (1995). Resolution Quantified Boolean Formulas. Information Computation, 117(1), 1218.Klieber, W. (2014).Formal Verification Using Quantified Boolean Formulas(QBF).Ph.D. thesis, Carnegie Mellon University, available http://reportsarchive.adm.cs.cmu.edu/anon/2014/CMU-CS-14-117.pdf.166fiC LAUSE E LIMINATIONSATQSATKlieber, W., Sapra, S., Gao, S., & Clarke, E. M. (2010). non-prenex, non-clausal QBF solvergame-state learning. Strichman, O., & Szeider, S. (Eds.), Proceedings 13thInternational Conference Theory Applications Satisfiability Testing (SAT 2010),Vol. 6175 Lecture Notes Computer Science, pp. 128142. Springer.Kullmann, O. (1999). generalization extended resolution. Discrete Applied Mathematics,9697, 149176.Kupferschmid, S., Lewis, M. D. T., Schubert, T., & Becker, B. (2011). Incremental preprocessingmethods use BMC. Formal Methods System Design, 39(2), 185204.Le Berre, D. (2001). Exploiting real power unit propagation lookahead. Electronic NotesDiscrete Mathematics, 9, 5980.Liberatore, P. (2005). Redundancy logic I: CNF propositional formulae. Artificial Intelligence,163(2), 203232.Lonsing, F., & Biere, A. (2010). DepQBF: dependency-aware QBF solver. Journal Satisfiability, Boolean Modeling Computation, 7(2-3), 7176.Lynce, I., & Marques-Silva, J. (2001). interaction simplification search propositional satisfiability. CP01 Workshop Modeling Problem Formulation.Mangassarian, H., Le, B., Goultiaeva, A., Veneris, A. G., & Bacchus, F. (2010). Leveraging dominators preprocessing QBF. Design, Automation Test Europe (DATE 2010), pp.16951700. IEEE.Manthey, N., Heule, M., & Biere, A. (2013). Automated reencoding boolean formulas. Biere,A., Nahir, A., & Vos, T. E. J. (Eds.), Revised Selected Papers 8th International HaifaVerification Conference (HVC 2012), Vol. 7857 Lecture Notes Computer Science, pp.102117. Springer.Marin, P., Miller, C., & Becker, B. (2012). Incremental QBF preprocessing partial design verification - (poster presentation). Cimatti, A., & Sebastiani, R. (Eds.), Proceedings 15thInternational Conference Theory Applications Satisfiability Testing (SAT 2012),Vol. 7317 Lecture Notes Computer Science, pp. 473474. Springer.Marques-Silva, J. (2008). Practical applications Boolean satisfiability. Proceedings 9thInternational Workshop Discrete Event Systems (WODES 2008), pp. 7480. IEEE.Niemetz, A., Preiner, M., Lonsing, F., Seidl, M., & Biere, A. (2012). Resolution-based certificateextraction QBF - (tool presentation). Cimatti, A., & Sebastiani, R. (Eds.), Proceedings15th International Conference Theory Applications Satisfiability Testing (SAT2012), Vol. 7317 Lecture Notes Computer Science, pp. 430435. Springer.Ostrowski, R., Gregoire, E., Mazure, B., & Sas, L. (2002). Recovering exploiting structuralknowledge CNF formulas. Hentenryck, P. V. (Ed.), Proceedings 8th International Conference Principles Practice Constraint Programming (CP 2002), Vol.2470 Lecture Notes Computer Science, pp. 185199. Springer.Piette, C., Hamadi, Y., & Sas, L. (2008). Vivifying propositional clausal formulae. Ghallab,M., Spyropoulos, C. D., Fakotakis, N., & Avouris, N. M. (Eds.), Proceedings 18th European Conference Artificial Intelligence (ECAI 2008), Vol. 178 Frontiers ArtificialIntelligence Applications, pp. 525529. IOS Press.167fiH EULE , J ARVISALO , L ONSING , EIDL , & B IEREPigorsch, F., & Scholl, C. (2010). AIG-based QBF-solver using SAT preprocessing.Sapatnekar, S. S. (Ed.), Proceedings 47th Design Automation Conference (DAC 2010),pp. 170175. ACM.Pulina, L., & Tacchella, A. (2009). structural approach reasoning quantified booleanformulas. Boutilier, C. (Ed.), Proceedings 21st International Joint ConferenceArtificial Intelligence (IJCAI 2009), pp. 596602.Robinson, J. A. (1965). machine-oriented logic based resolution principle. JournalACM, 12(1), 2341.Sabharwal, A., Ansotegui, C., Gomes, C. P., Hart, J. W., & Selman, B. (2006). QBF Modeling: Exploiting Player Symmetry Simplicity Efficiency. Biere, A., & Gomes, C. P. (Eds.),Proceedings 9th International Conference Theory Applications SatisfiabilityTesting (SAT 2006), Vol. 4121 Lecture Notes Computer Science, pp. 382395. Springer.Samer, M. (2008). Variable dependencies quantified CSPs. Cervesato, I., Veith, H., &Voronkov, A. (Eds.), Proceedings 15th International Conference Logic Programming, Artificial Intelligence, Reasoning (LPAR 2008), Vol. 5330 Lecture NotesComputer Science, pp. 512527. Springer.Samulowitz, H., Davies, J., & Bacchus, F. (2006). Preprocessing QBF. Benhamou, F. (Ed.),Proceedings 12th International Conference Principles Practice ConstraintProgramming (CP 2006), Vol. 4204 Lecture Notes Computer Science, pp. 514529.Springer.SAT Competitions Organizing Committee (2014). international SAT Competitions web page.http://satcompetition.org/.Schaefer, T. J. (1978). complexity two-person perfect-information games. JournalComputer System Sciences, 16(2), 185225.Seidl, M., & Biere, A. (2015). Bloqqer. http://fmv.jku.at/bloqqer.Seidl, M., & Konighofer, R. (2014). Partial witnesses preprocessed quantified Boolean formulas. Proceedings Design, Automation & Test Europe Conference & Exhibition (DATE2014), pp. 16. IEEE.Subbarayan, S., & Pradhan, D. K. (2005). NiVER: Non-increasing variable elimination resolutionpreprocessing SAT instances. Hoos, H. H., & Mitchell, D. G. (Eds.), Proceedings7th International Conference Theory Applications Satisfiability Testing (SAT 2004),Vol. 3542 Lecture Notes Computer Science, pp. 276291. Springer.Van Gelder, A. (2005). Toward leaner binary-clause reasoning satisfiability solver. AnnalsMathematics Artificial Intelligence, 43(1), 239253.Van Gelder, A., Wood, S. B., & Lonsing, F. (2012). Extended failed-literal preprocessing quantified boolean formulas. Cimatti, A., & Sebastiani, R. (Eds.), Proceedings 15thInternational Conference Theory Applications Satisfiability Testing (SAT 2012),Vol. 7317 Lecture Notes Computer Science, pp. 8699. Springer.Zhang, L. (2006). Solving QBF combining conjunctive disjunctive normal forms. Gil, Y.,& Mooney, R. J. (Eds.), Proceedings 21st National Conference Artificial Intelligence(AAAI 2006), pp. 143150. AAAI Press.168fiJournal Artificial Intelligence Research 53 (2015) 41-90Submitted 03/14; published 05/15Learning Relational Event Models VideoKrishna S. R. DubbaAnthony G. CohnDavid C. Hoggkrishna.dubba@gmail.coma.g.cohn@leeds.ac.ukd.c.hogg@leeds.ac.ukSchool Computing, University Leeds,Leeds, UK. LS2 9JTMehul BhattFrank Dyllabhatt@informatik.uni-bremen.dedylla@informatik.uni-bremen.deCognitive Systems, SFB/TR 8 Spatial CognitionUniversity Bremen, Bremen 28334, GermanyAbstractEvent models obtained automatically video used applications rangingabnormal event detection content based video retrieval. multiple agentsinvolved events, characterizing events naturally suggests encoding interactionsrelations. Learning event models kind relational spatio-temporal data usingrelational learning techniques Inductive Logic Programming (ILP) hold promise,successfully applied large datasets result video data.paper, present novel framework remind (Relational Event Model INDuction)supervised relational learning event models large video datasets using ILP.Efficiency achieved learning interpretations setting using typingsystem exploits type hierarchy objects domain. use types alsohelps prevent generalization. Furthermore, also present type-refining operatorprove optimal. learned models used recognizing eventspreviously unseen videos. also present extension framework integratingabduction step improves learning performance noise inputdata. experimental results several hours video data two challenging realworld domains (an airport domain physical action verbs domain) suggesttechniques suitable real world scenarios.1. Introductionadvent digital technology wide availability cameras video recorders,quantity video data increased enormously recent years, e.g., YouTube usersupload 100 hours video site every minute (YouTube, 2015). datasemantically rich lack algorithms process utilize data effectively.number applications demand video processing, especially event modellingrecognition, content based video search, robotics, automatic descriptionactivities, video surveillance etc. main objective work provide supervisedrelational learning framework learn high level human understandable event modelsuse recognize events video. Supervised learning machine learning taskinferring model labelled training data.c2015AI Access Foundation. rights reserved.fiDubba, Cohn, Hogg, Bhatt & DyllaVideo considered sequence images area video analysis poses severalchallenges. interesting aspect video compared images objects(or parts objects) video perceived move space time. changesstate space dimension interesting call events satisfy certainproperties sufficiently frequent sufficiently well defined boundariesetc. event change state single object, moving partsbody (for example people waving hands) interaction multipleobjects. interactions, context, mean movement objects relativesurroundings well relative other. example, interactiontwo objects might objects moving towards one restmoving away it. events recognized, assume objects involveddetected tracked source video. requirement generalsince approaches (Laptev, 2005) require detection objects prior eventdetection.events involving multiple objects, interactions objects become distinguishing factor recognizing event instance. Capturing interactions cruxevent modelling recognition hypothesis event distinguishedinteractions objects involved. events might oneinteraction pattern identifies event. One way capture interactionsabstract interactions relations objects. order represent interactions objects abstract form, use relations objects dependspatial configuration motion pattern objects period time. callspatio-temporal relations paper focus purely use qualitativespatial relations since abstract away metric details particular object trajectories thus facilitate recognition interactions instances eventclass (Cohn et al., 2006). unique way represent interactions using qualitativespatio-temporal relations, best set relations use depends domain, kinddata available (speed, orientation, size moving objects, etc.) objectivestask.Though event class distinguishing interaction patterns, two particularchallenges event learning examples expressed qualitative spatio-temporal relations. Firstly, automatic object detection tracking video perfectintroduce errors relations. Secondly, event may performed differentways.1.1 Overview Frameworkfollow relational learning approach cognitive vision task learning eventmodels videos using recognition (Cohn et al., 2006; Dubba, Cohn, &Hogg, 2010). video data (sequence images pixel data) converted relationalfacts involving qualitative spatio-temporal relations using tracking data objectsinvolved scenes. use several qualitative spatial calculi represent videodata relational form. Event instances annotated temporally spatially thoughobjects involved event delineated separately annotations usedobtaining positive negative examples events. learning procedure well42fiLearning Relational Event Models Videoextension procedure using abduction (explained later sections) appliedrelational data obtain event models. event models formProlog rules used queries relational data unseen video.answer substitutions extract spatial temporal extensions recognized eventinstances.main contributions1 paper are:novel supervised relational learning framework remind learning event modelsvideo recognizing event instances using models.optimal Type Refinement operator upward refinement hypotheses exploits type hierarchy domain finding better event models.extended framework integrate induction abduction interleaved fashionembedded spatial theory improving learning event models.evaluation framework two real world video data sets (aircraft turn-aroundsevents include aircraft arrival, luggage loading human interactionsevents common action verbs exchange, follow, dig etc).Though concentrate relational data obtained tracking objects video,principles techniques work equally apply spatio-temporal relational dataacquired non-visual sources (e.g. laser mapping, GPS tracks, textual descriptions etc).2. Related WorkMuch work event analysis (Ivanov & Bobick, 2000; Medioni, Cohen, Bremond,Hongeng, & Nevatia, 2001; Vu, Bremond, & Thonnat, 2003; Albanese, Moscato, Picariello,Subrahmanian, & Udrea, 2007; Ryoo & Aggarwal, 2009, 2011; Morariu & Davis, 2011),involve learning models used. Instead high level event models hand-codedusing different representations (Nevatia, Hobbs, & Bolles, 2004; Hakeem, Sheikh, & Shah,2004).Techniques based similarity based metric space low level pixel basedfeatures local space-time features (Laptev, 2005) frequently used modellingrecognizing events. generally suitable single agent events like humanactivities based motion. kind activities generally include particular motionsignature event recognized running, jumping, waving handsetc. event recognition systems, hand-coded high level event models used toplearned low level human activity models (Ivanov & Bobick, 2000; Ryoo & Aggarwal,2009, 2011).One best performances date event recognition using low level pixel-basedfeatures obtained Stack convolutional Independent Subspace Analysis (ScISA) (Le,Zou, Yeung, & Ng, 2011) algorithm. ScISA based pixel level flow based featuresused model events using hierarchical representation using deep learningtechniques (Bengio, 2009). authors present extension Independent Subspace1. paper extended version work Dubba et al. (2010, 2012).43fiDubba, Cohn, Hogg, Bhatt & DyllaAnalysis learn invariant spatio-temporal features unsupervised fashion insteadusing predefined features.events considered sequence primitive states events, state-space modelsuseful representing event models. also easy hand-code structurestate space models, though parameters better learned encoded hand.provide robust statistical event model hand-coded models event recognitiondone using inference models. Bayesian Networks popular eventmodelling lack temporal aspect though state space models HiddenMarkov Models (HMM) (Rabiner, 1989) Dynamic Bayesian Networks (DBN) (Ghahramani, 1998) extensively used event modelling recognition. simple HMMeffective modelling complex events. Several extensions HMM used suitcontext type event models. Hoogs Perera (2008) proposed DBN jointlysolving event recognition broken tracks linking problems. event model setdiscrete states expresses actors event interact time. assumestates strictly ordered may limit learning events involve complextemporal relations during, overlaps etc.main problem state space models difficult encode high-leveltemporal relations during, overlaps etc. states sub-events eventassumed sequential order case many domains. Alsostates propositional nature hence semantically less complex relationalrepresentation.Veeraraghavan et al. (2007) learn Stochastic Context Free Grammar based modelstraffic videos using predefined regions image. event model spatio-temporalpattern primitive actions expressed string, = a1 , a2 , . . . , . event learningalgorithm aims find grammar generate corresponding pattern event.primitive actions sequentially arranged, hence Allens temporal relationsused connect primitive actions. Gupta et al. (2009) claim fixed structureDBNs poses serious limitations modelling events many variationsway event happen. Instead use AND-OR graphs modelling event models.order nodes imposes causal relationship among nodes. this,Allen relationships during, overlaps etc. cannot modelled limitsapplication since modelling relations important many domains.Though low-level features state space models popular simple motion patterns,possible build high-level event recognition systems several layers reasoning.systems use simple pattern recognition techniques detect primitive eventsuse temporal structure reason complex events. main motivation usinghigh level temporal structure low level features (like bag-of-features) discardinformation regarding relations different entities datathus makes hard recognize events involving complex interactions multipleobjects.Moyle Muggleton demonstrated using simple blocks world domain specificaxioms learned temporal observations using ILP framework (Moyle & Muggleton, 1997). work Needham et al. (2005), Progol system (Muggleton, 1995)used learn protocols table top games real sensory data video camera microphone. key aspect work method spatio-temporal attention44fiLearning Relational Event Models Videoapplied sensor data audio video devices. identifies subsets sensordata relating discrete concepts. Symbolic description continuous data obtainedclustering within continuous feature spaces processed sensor data. ProgolILP system subsequently used learn symbolic models temporal protocols presentpresence noise over-representation symbolic input data. frameworkbased time points used successor temporal relation.Konik Laird (2006) proposed learning observation framework learn agentprogram mimics human experts behaviour domains games. learnedconcepts used generate behaviour rather classification. applied ILP techniques artificially created examples expert behaviour traces goal annotations.relational data used simple predicate valid situation (an abstract timepoint) hence concepts sophisticated temporal relations Allens intervalalgebra (Allen, 1983) use intervals cannot learned. limits real world applicability framework different events occurring parallel hencerequires using Allens interval algebra model them. framework uses positiveexamples negative examples generated randomly controlled fashion.Fern, Givan Siskind (2002) introduced system, leonard, learns event definitions videos following standard specific-to-general learning approachpositive data. seven simple event types learned system namelypick up, put down, stack, unstack, move, assemble disassemble. relational dataobtained tracking objects indoor scenarios. negative examples suppliedevent models found computing least-general covering formula (LGCF)positive example computing least-general generalisation (LGG)resulting formulae. computing LGCF example, resulting LGCFinterval information. Hence model support equaltemporal relations states.important aspect note review work areadone either artificial simulated data (Moyle & Muggleton, 1997; Konik &Laird, 2006) simple real world data (Fern et al., 2002; Needham et al., 2005)involves objects, events short duration objects sceneinvolved events. case, tracked data videos largetime complex noisy contains objects.Several attempts made literature integrating induction abductionlearning better theories. pointed Tammaddoni-Nezhad et al. (2006) abduction induction integrated general two conditions hold: backgroundknowledge incomplete hypothesis language disjoint observation language. setting latter condition holds called non Observation PredicateLearning (non-OPL) setting (i.e. OPL setting, examples hypotheses definepredicate). assume existence theory connects hypothesislanguage observation language start with. Since theory learned,considered background theory. general strategy case abduce (Kakas & Riguzzi, 2000) missing observations using background theory useabduced data inducing new theories. Muggleton Bryant (2000) proposed Theory Completion using Inverse Entailment (TCIE) non-OPL setting. TCIE abducesadds facts called Start Set connect target predicate observable pred45fiDubba, Cohn, Hogg, Bhatt & Dyllaicates observation data generalizes data. case, missing factsnoise observed data set target predicates setobservables whereas TCIE, target predicate observableset target predicates set observables disjoint.Moyle (2003) introduces ILP system (alecto) combines abduction induction learn theories robot navigation. One limitation systemrestricted positive observations learning. integration interleaved nature abduction first used generate explanations example inductionapplied set explanations. means abduction phase takeconsideration concepts learned induction phase dealing noise dataleft future work.3. Relational Representation Scenes Videorepresent interactions objects relational data, use spatial temporal relations.Since input work video, spatial relations defined eitherimage plane ground plane (if homography used map image planeground plane). spatial relations necessary encode state particular pairobjects in. states two objects change time progresses, henceneed temporal relations connect states. section, explain objectsinteractions converted relational data.Notation: use first-order typed language (L) following alphabet: {, , ,, , , ,R}. Let R = {r1 , r2 , . . . , rm } denote set qualitative spatial relationshipsarbitrary qualitative spatial calculus. sorts (and corresponding variables)given (upper case letter denotes set lower case letter denotes set element):time pointstime intervalsspatial objectseventsEtemporal relationsobject typesspecial event-predicate tran(ri , ok , ol , tm ) E denotes transition spatialrelation ri objects ok ol time point tm . Note work,take values set 13 Allens base relations (Allen, 1983) i.e. = {before, after,meets, met by, overlaps, overlapped by, during, contains, equals, finishes, finished by, starts,started by}. say two intervals disjoint Allen relationset {before, after, meets, met by}.3.1 Spatial Relationsorder get high level description interactions objects videos, need relations encode interactions objects without loss essential information (Cohnet al., 2006). several possibilities kind relations choose.Since interactions objects video take place spatial dimensions, natural46fiLearning Relational Event Models Video???Figure 1: Qualitative Trajectory Calculus (QT CL1 ) (Van de Weghe et al., 2006):blob possible QT CL1 spatial relation. blob, asterix (left object) circle (rightobject) represent objects motion star black dot represent objects restdirection arrow shows direction motion object. example,top-left ellipse interpreted two objects moving towards bottom-leftellipse interpreted right object moving away left object leftobject moving towards right object (i.e left object chasing right object).Though nine relations possible QT CL1 shown figure, practicereduce six exploiting symmetry relations. one object changesmotion state (note object cannot change direction without goingrest state), QTC relation changes along thick line connecting two relations.objects change motion state instantaneously, relation changes along dotted line.use qualitative spatial calculi model interactions. interactions alsotemporal dimension occur period time, extend spatial relationsarguments modelling temporal dimension. say interactions objectsmean interactions bounding boxes2 (aligned axes) objectsget tracking objects using computer vision algorithms (Yilmaz, Javed, & Shah,2006). different kinds spatial calculi target different aspects objectinteractions like topology, orientation, direction, trajectories etc. calculi usedomain dependent choice (Chen, Cohn, Liu, Wang, Ouyang, & Yu, 2015). primarily use three spatial relations encode object interactions topological level:dc (Discrete) intersection pixels bounding boxes two objects empty,(Inside) intersection pixels pixels bounding boxone objects touch every case. set simple topological relationsabstracted version3 RCC-8 (Randell, Cui, & Cohn, 1992) spatial calculus, reducedpractical purposes without loss essential information event analysis. also useQT CL1 (Van de Weghe et al., 2006) (Fig.1) domain specific relations primitivesrepresent interactions objects videos.2. principle, shape abstractions could used well, e.g. convex hulls, silhouettes, bounding ovalsetc.3. two relations version RCC called RCC-5 equal contains (inverse in).relation equal rarely occurs experiments use contains convertreversing arguments.47fiDubba, Cohn, Hogg, Bhatt & Dyllao1o1o1o2o2132dco2touchdc(o1 , o2 , 1 )touch(o1 , o2 , 2 )in(o2 , o1 , 3 )meets(1 , 2 )meets(2 , 3 )before(1 , 3 )Figure 2: Converting interactions objects relational data.3.2 Temporal Interval Relationsdefine temporal relations time intervals based Allens interval algebra.use start end frames interval represent intervals. advantageapproach is, precalculate temporal relations store beforehanddatabase inference. Instead, Prolog rules calculate temporal relations given startend time points two intervals used. order incorporate temporal informationdescribing scenario, extend spatial relations temporal interval extraargument.3.2.1 Temporally Extending Spatial Relationstate spatial relation r objects o1 o2 holds throughout intervalrepresented r(o1 , o2 , ) r R , o1 , o2 . Grounding expressionobjects intervals database provide us spatio-temporal facts.temporal relation two spatio-temporal facts Allen relationintervals spatio-temporal facts.3.3 Representing Event Classevent class represented set Horn clauses head predicateevent name consideration body non empty conjunction atomsconsisting spatial temporal predicates.structure clause event model event class follows:() : 1 , . . . , , . . . , neither form r(o1 , o2 , ) r R, o1 , o2 ,form (1 , 2 ) 1 , 2 .148fiLearning Relational Event Models Video4. Deictic Supervisionsupervised learning, need positive preferably negative examples eventinstances. One major problem supervised learning collecting labelled trainingdata. general ambiguity defining spatial particular temporalextent event (i.e. events precisely start finish), difficult annotatevideos event labels. possible approach annotate objects involvedevent give events temporal extent. annotating objects tedious pronehuman error events may uncertainty objects involved.avoid using Deictic Supervision (Dubba et al., 2010). Instead annotatingexact objects involved training event instances, give bounding spatialtemporal extent event instance may contain objects. spatial extentregion indicating event happening video. temporal extentinterval includes actual temporal extent event, may deliberatelylonger order avoid accidentally truncating state changes relevant event.makes preparation training data easier learning process robust lessbiased labelling learning algorithm able induce reasonablemodels even data.Delineating spatio-temporal volumes videos learn feature-based representations actions hand gestures without precedent computer visionliterature (Laptev & Perez, 2007), use extends multiple simultaneous actors relational descriptions resilience perturbations placement cuboidsprovided events fully enclosed.4.1 Deictic Interval Regionwork, deictic spatial region rectangle image plane indicatingevent happened deictic interval time interval indicating eventhappened. deictic spatial region obtained hand-delimiting event imageplane rectangle4 , hence represented using coordinate point (top-left cornervertex), height width rectangle (x, y, h, w). deictic temporal interval providedspecifying start end time points interval. Together define space-timecuboid delimits spatial temporal extension event.deictic cuboid defines set spatial facts temporal relations them;event instance subset facts corresponds positive examplelearning interpretations setting. Obtaining positive negative examples learningusing event annotations form deictic spatial regions deictic temporal intervalsexplained following sections. Note deictic interval region regardedinterval object respectively spatial relationscomputed accordingly. positive negative examples computed, spatialrelations involving deictic regions one objects discarded databaseuse.4. tracking data ground plane back-project rectangle automaticallyminimum enclosing rectangle ground plane using homography (Hartley & Zisserman, 2004).49fiDubba, Cohn, Hogg, Bhatt & Dylla4.2 Herbrand Interpretation EventLet si deictic spatial region deictic temporal interval instanceevent class video v. Let v set spatio-temporal facts present v, Ovset objects v v set time intervals v. set facts Ei vHerbrand Interpretation event v iff facts containedentailed v , whose temporal intervals disjoint deictic interval whoseobjects relation touch within deictic region.Ei = {r(o1 , o2 , ) : v r(o1 , o2 , )v (i , )/ {before,after,meets,metby}1 [v r1 (si , o1 , 1 ) r1 {touch,in}v 1 (i , 1 ) 1/ {before,after,meets,metby}]2 [v r2 (si , o2 , 2 ) r2 {touch,in}v 2 (i , 2 ) 2/ {before,after,meets,metby}]o1 , o2 , si Ov r R 1 , 2 v}example interpretation event instance AFT Bulk LoadUnload Airportdomain illustrated Fig.3. interpretation includes spatial facts involvingobjects relation touch deictic region lie withintwo vertical dashed lines (the deictic interval). set Herbrand Interpretationscorresponding set deictic regions intervals event form positiveexamples learning phase. rest relational facts video formnegative example event model fires instance database, consideredfalse positive. Herbrand Interpretation extracted set spatiotemporal facts video, interpretation independent factsspatio-temporal database5 video hence facts assumed falseinterpretations point view.Note definition spatio-temporal facts spatio-temporally overlapdeictic region interval event instance relevant event. Consideringfacts outside indicated event occurrence increases size training dataalso makes example instances different event classes less distinct.One limitation using cuboid shaped deictic region delineating event instancepossible differentiate among multiple co-occurring instancesevent type involving different objects region. One way overcome limitationuse one cuboid enclose event instance allowing elimination unwantedfacts.5. spatio-temporal database subset Herbrand Base video obtained usingpredicates (spatio-temporal relations) constants (objects time intervals) video.50fiLearning Relational Event Models VideoFigure 3: example interpretation event AFT Bulk LoadUnload Airportdomain. vertical black lines start end deictic interval. rowrepresents interactions two objects present deictic regiondeictic interval video. colours lines represent spatial relationspairs objects point time. figure show effect deicticspatial region, would correspond elimination certain rows (whereobjects spatial relation touch whilst deictic spatial regiondeictic temporal interval.4.3 Herbrand Interpretation Non-event Interval (Negative Example)framework, negative examples explicitly labelled. negative examplegiven event video set spatio-temporal facts databasevideo present positive examples event video. Notenegative example general contain data might positive examplesevent classes video. Another alternative use labelled positive examplesevents negative examples event learning. convenientclassification purposes recognition tasks miss background datamight useful minimize detections background regions.Let v union spatio-temporal facts Herbrand Interpretationsevent video v. set facts NIv v Herbrand Interpretation negativeexample event video v iff contains facts v v , i.e.,NIv = v v .5. Typed ILPevent learning recognition system, low level image processing computervision techniques may introduce noise system. One kind noise, particularvideo quality bad videos CCTVs, wrong type mayassigned tracker object history. object detector typically trained51fiDubba, Cohn, Hogg, Bhatt & DyllaPersonAircraftGPUTransporterObjectLight VehiclePush BackService VehicleMobile StairsVehicleLoaderConveyor BeltPassenger Boarding BridgeHeavy VehicleContainerCateringTankerBulk LoaderFigure 4: Tree-structured object type hierarchy Airport domain.many example images objects detected. Even though many example imagesgiven training, possible capture possible ways object appearlighting, viewing direction, size, shape, etc. (Lowe, 2004). may resultcorrectly localized objects wrong categories objects, especiallylook visually similar low contrast images.input data huge noisy, several problems ILP systemface. One hypothesis evaluation take lot time sizedata. Also noise tend make hypothesis specific system learnsrules cover inconsistent examples. Using typed ILP system speedevaluation typed arguments hypothesis (Walther, 1985; Cohn, 1989)also reduce number false positives avoiding certain cases typesarguments match. event model objects specialized typefail recognize event instances object appears different type.contrast, event model type system uses generic typeobjects object, thing etc., approach many false positivescannot differentiate events structure involving different typesobjects. One possible approach find appropriate type generalization insteadusing one two extremes: generic type specialized type.ILP systems, type hierarchy objects integrated learningprocess. example, Progol, types objects used mode declarationssince assumes flat type hierarchy domain, search procedure cannottake type hierarchy consideration. example, tracking system sometimesconfuses two types objects (1 , 2 ) objects type 1 misclassified52fiLearning Relational Event Models Videos2s1s4s3s5Figure 5: Tree-structured example object type hierarchy. s1 general types2 , s4 , s5 specific types.type 2 , Progol generates two rules, one 1 another 2 . Evendealing vision system introduces noise high level learningreasoning system, cases event might involve objects particular sub-groupobjects. case, instead using generic type like object particulartypes like type object itself, efficient use intermediate generic typerepresents sub-group. variable without type restrictions satisfiedtype object instantiating Horn clause. However, appropriate generalizationenforced learning system variable type 1 t2 type hierarchy,satisfied6 objects type 1 2 , thereby reducing false positives.5.1 Representing Typed Hierarchywish use existing Prolog engine hypothesis evaluation wayencoding type using terms must found. several ways dependingwhether structure object type hierarchy tree lattice. usetype representation proposed Bundy, Byrd Mellish (1985) deal treestructured type hierarchies; develop refinement operator incorporatingrepresentation hypothesis search procedure. advantage using representationordinary unification used determine whether two types compatible.write < j , subtype j 6= j . Every object type nhypothesis represented term 1 (2 (. . . n (o) . . .)) 1 , . . . , nmaximal sequence types n < . . . < 2 < 1 . denote representationfunction . Note need constraint, i.e. tree structured type hierarchy,order guarantee uniqueness sequence 1 , . . . , n .example, let s1 , s2 , s3 , s4 , s5 types s4 < s3 < s1 , s5 < s3 < s1s2 < s1 shown Fig.5. object type s4 represented follows:(o) = s1 (s3 (s4 (o)))object oi compatible object oj hypothesis (oi ) unifiable(oj ). example: s1 (s3 (o1 )) unify s1 (s2 (o2 )) unifys1 (s3 (s4 (o3 ))) s1 (s3 (s5 (o4 ))), hence compatible.5.1.1 Example Representing Type Hierarchyobject type hierarchy occurs one two domains used evaluationsection work shown Fig.4. hierarchy Fig.4 hand defined based6. variable type 1 2 unify term type 1 2 .53fiDubba, Cohn, Hogg, Bhatt & Dyllaobserved errors object classification tracking data Airport domain.airport domain, ground power unit (GPU), transporter push back vehiclesmall vehicles look similar videos CCTV cameras airportlow resolution contrast without much colour sharp edges. makes challengingtrain object detector use detecting objects videos. objectsVerbs domain present particular challenges automatic classification pointview events involve objects particular subset objects, example,throw event involves balls different types like small ball, basket ball, etc. Hence usingtype hierarchy based utility expected help find event models betterperformance detecting events unseen videos.vehicle V type GPU represented obj(veh(light veh(gpu(V ))))7V type light veh represented obj(veh(light veh(V ))). Noteobj(veh(light veh(V ))) unifies vehicles type GPU vehicles type Transporter. using obj(veh(light veh(V ))) model cover examples eitherinvolve GPU Transporter hence handle noise object detectorconfuses vehicles outputting GPU place Transporter vice versa.5.2 Type Refinement Operatorrefinement operator used traverse hypothesis lattice. twotypes refinement operators: upward downward (Nienhuys-Cheng & De Wolf, 1997).write Hg Hs Hg generic8 hypothesis Hs . assumetop element hypothesis lattice generic hypothesis bottomhypothesis specific hypothesis, upward refinement operatordefined follows (the downward refinement operator defined similar fashion):Let L set possible hypotheses. (upward) refinement operator definedhypothesis H, produces generalizations H, (H) = {Hg | HgH, Hg L}.define (upward) Type Refinement operator operator generalizesobject types H. Apart object types, structure H members (H)identical.define type generalizing operator follows:generalize type(1 (2 (. . . n1 (n (o)) . . .))) = 1 (2 (. . . n1 (o) . . .))Type Refinement operator, , applies generalize type operator selectedobject type present hypothesis, resulting generic hypothesis movingexactly one level type hierarchy.Though specific current representation type hierarchy using functors requirestree structured hierarchy, tree structured hierarchy beneficial computational viewpoint limiting type generalizations, i.e., multiple ancestors.tree-like type hierarchy natural many domains though domains might7. Note short forms used Object, Vehicle Light Vehicle.8. several possible generality orders, important subsumption logical implication (Nienhuys-Cheng & De Wolf, 1997).54fiLearning Relational Event Models Videowell defined tree-like object type hierarchy. cases, lattice structured typehierarchy suitable though increase size search space sincenumber possible refinements increased, particular tree structure type generalization deterministic whilst case lattice structure.5.2.1 Optimality Type Refinement OperatorRefinement operators ideal optimal (Nienhuys-Cheng & De Wolf, 1997)9 .optimal refinement operator generates hypothesis hypothesis latticeunique way produce hypothesis. kind refinement operatordesirable complete search algorithms duplicate generation hypotheses increasecost search procedure. optimality Type Refinement operator provedAppendix A.6. Learning Interpretations Setting Learning Event Modelsresult deictic supervision gives us examples sets spatio-temporal facts.Though examples (sets facts) come different videos,independent other, i.e., mapping example class independentexamples. kind learning setting example independentexample set facts, learning interpretations settingapt choice (Blockeel, De Raedt, Jacobs, & Demoen, 1999). setting specifiedformally thus:Given:set classes C (each class label c nullary predicate).set classified examples E (each element E form (Ei , c) Ei setfacts c class label)background theory B,Find : hypothesis H (a set Horn clauses), (Ei , c) E:H Ei B c,c0 C {c} : H Ei B 2 c0current event learning problem, setting applied event classcase set classes two elements, event class background class. Background class represents negative examples class label cnullary predicate.9. ideal refinement operator proper complete whereas optimal refinement operator weaklycomplete non-redundant. See Appendix formal definitions.55fiDubba, Cohn, Hogg, Bhatt & Dylla6.1 Traversing Search Spacesearch process hypothesis starts initial hypothesis nullarypredicate head empty body. hypothesis lattice traversed using ProgolType Refinement operators interleaved fashion. Progol refinement operatorspecialization operator adds atoms bottom clause hypothesis.specialization operator moves top (empty clause) bottom hypothesisspace lattice bounded bottom clause bottom. Adding atomsbottom clause makes hypothesis specialized bodyhypothesis conjunction atoms atom considered constraint.Adding atoms body increases constraints satisfy become true.Progol refinement operator use based bottom clause alsocalled most-specific clause non-redundant though weakly-completerespect general subsumption order (Tamaddoni-Nezhad & Muggleton, 2009).most-specific clause Progol refinement operator uses computed training examples, mode declarations background knowledge (Muggleton, 1995). Modedeclarations user defined syntactic biases form predicates specifypredicates background knowledge expected target hypothesis alsonature variables (input, output, constant). selection atomsadded hypothesis bottom clause done controlled manner. atomsconsidered starting left moving right atom added(Tamaddoni-Nezhad & Muggleton, 2009). constraints selectionatoms makes refinement process non-redundant, i.e., hypothesis generated twice.additional refinement operator refines unifying two variables arbitrarilyselected hypothesis substituting variable constant. useoperator unifying two variables needs checking hypothesis consistencyrespect underlying spatial theory fixed constants (apart framenumbers) domain constants example independent constantsexamples. example, consider three relations Section 4.1 spatialtheory Allens relations temporal relations: cannot unify two argumentspredicate (spatial temporal) violates semantics relations.Type Refinement operator generalizes hypothesis generalizing typeobject hypothesis (Fig.6). two possible approaches apply TypeRefinement operator: type first approach select type set typeshypothesis generalize type variables belong selected typevariable first approach select variable hypothesis generalize typeoccurrences variable hypothesis. type first approach generalizesselected type throughout hypothesis may involve several variablesvariable first approach generalizes type one variable. work, usetype first approach fewer number refined hypotheses smaller searchspace variable first approach larger number choices hence largersearch space. One reason use type first approach computer visionalgorithm might confuse type whole group objects belong particulartype rather single object video inaccurate object detector.56fiLearning Relational Event Models VideoFigure 6: Type refinement operator (generalization).6.2 Searching Event Modelmost-specific clause computed, sub-lattice bounded mostspecific clause searched using best-first search hypothesis maximumscore calculated based combination (1) number positive examples covered, (2)number answer substitutions negative examples, (3) length hypothesis(4) number distinct variables hypothesis subject given constraints(discussed next subsection).score(H) = p (% n + l + v)= weight positive examplesp = number positive examples covered% = weight answer substitutions negative examplesn = number answer substitutions negative examplesl = length hypothesisv = number distinct variables hypothesisanswer substitution example e substitution grounds hypothesis,h b1 , . . . , bn , query b1 , . . . , bn succeeds database e. Notelearning interpretations setting positive example separate databasehypothesis used Prolog query database, might result multipleanswer substitutions. example considered covered hypothesis oneanswer substitutions. testing hypothesis test database, answersubstitution considered one recognized event instance. recognized event intervalfalls outside event ground truth test video, considered false positive.event recognition domain, hypothesis used recognizing events unseen videos57fiDubba, Cohn, Hogg, Bhatt & Dyllainstead classifying videos, hypothesis fewer false positives desirable. Hencehypotheses penalized using number answer substitutions10 negative examples.number positive negative examples disproportionate numbers, givingweight positive examples negative examples using % resulthypothesis better performance test data.Since starting hypothesis empty completely generic, covernegative examples. hypothesis specialized Progols refinement operator,number false positives decreases. score hypothesis longer increases,Type Refinement operator used generalize types thereby increasing generalityhypothesis possible increase positive examples covered (as well falsepositives). process interleaved application operators continuedhypothesis score longer increases.satisfactory hypothesis found, argument representing temporal informationform list time intervals formed using time intervals bodyevent model introduced head order explicitly represent eventoccurs useful using hypothesis event monitoring allows intervalevent occurs explicitly flagged viewing video.learning algorithm uses set covering method (Quinlan, 1990) learn eventmodel set clauses interpreted disjunction. covering method startsempty model learns clause using provided positive negative examplesadds clause model. repeats procedure positive examplescovered earlier clause. process repeated positiveexamples covered.6.3 Constraining Search Spacesize search space depends size bottom clause (Muggleton, 1995).Thus, event learning domain, depends number spatial relationsused number objects event instances used positive examples. sizebottom clause increases number Allens temporal relations intervalatoms spatial predicates temporally connected every intervalatoms spatial predicates. creates many atoms temporal predicatesbottom clause.order decrease size search space, algorithm makes use domaindependent domain-independent constraints structure hypothesis.constraints algorithm uses restrictions hypothesis length numbervariables hypothesis etc. domain-independent structural constraintsdepend predicates used domain knowledge. following twodomain-dependent constraints reduce search space time thereby makinglearning process efficient.Upper bounds number atoms body rule.10. Counting number answer substitutions instead number examples covered heuristic usedFOIL system (Quinlan & Cameron-Jones, 1993).58fiLearning Relational Event Models Videointerval atom spatial (temporal) predicate appear atomtemporal (spatial) predicate. hypothesis atoms satisfycriteria semantically meaningful since might satisfied factsrelated event question.However constraints listed domain dependent constraints rather application specific constraints, i.e., constraints involve spatial temporalpredicates applicable most, event learning scenarios. Noteconstraints hard (i.e. inviolate). hypothesis violates constraint,discarded without scoring refining. example, domain-independent constraintsfirst domain-dependent constraint mentioned hard. contrast, hypothesis violates constraint hard, example, second domain-dependentconstraint listed above, scored discarded generating refined hypotheses it. discarding hypotheses without refining might obstructtraversal lattice. example, current work, algorithm starts searchprocess empty hypothesis initial hypotheses obtained refining emptyhypothesis violate second domain-dependent constraint listed (since contain exactly one predicate therefore cannot contain spatial temporalpredicate).6.4 Event Recognitionlearned event models used event recognition unseen videos. purpose,test video converted relational data used database event modelsused Prolog queries. querying done whole database intervalsextracted answer substitutions queries give temporal extentrecognized instances events. order record event takes place, changearity event predicate (the rule head) monadic argumentlist interval variables occurring body. Note would also possibleintroduce second argument record objects involved event (i.e. listvariables type object - equivalently occur first two argumentsspatial predicate body).issue arises exactly event occurs given consists multipleoverlapping temporal intervals instantiated predicates given answer substitution. Given list intervals occurring instantiated body hypothesis,various possibilities present themselves. One could take maximal interval exactlyspans intervals . one could take interval exactly spans intervalfirst transition (i.e. pair meeting intervals involving pair objects)last transition. Clearly possibilities too. Ultimately probablydomain dependent decision. experiments, take list intervalstemporal extension event obtained taking minimum maximumtime points .Note may several rules event class, rule capturing variationevent happen. rules weights specifying importantreliable rule recognizing events. recognizing events, rules eventclass used may result multiple answer substitutions.59fiDubba, Cohn, Hogg, Bhatt & Dylla7. Interleaved Induction Abduction (IIA)previous section showed ILP applied learn rule-based relationalevent/activity models, given observation dataset, positive negative examplesevents whose models learnt. However, data visual sensors tendnoisy high variability sample space. leads over-fitted models (i.e.,rules), model cover examples corruptsensor noise. model rules result many false positives usedevent-recognition test data.section, show well-fitted, semantically meaningful event modelslearned noisy data interleaving induction abduction. acquires significancecases training data scarce noisy. apply Typed ILP system presentedprevious section learn event-based models using models domaintheory, explain examples/observations covered induced theory usingabduction. uncovered examples either noisy, examples eventreality happened different way. Using explanation rectify errorsnoisy examples corrupted tracking errors thus reduce requirement additionalrules. framework, examples noisy (i.e. incorrect) thereby requiringobservation data revision manner consistent initially learned theory,general common-sense knowledge space, spatial change, dynamicsdomain. Note many ILP approaches discard examples considering noisyusing heuristic stopping criteria. acceptable cases scarcitytraining data, learning every example potentially important.7.1 Domain-Independent Spatial Theoryorder pursue goal, Axiomatic Characterisation Spatial Theory necessary. Many spatial calculi exist, corresponding different aspect space. Here,suffices focus one spatial domain, e.g., topology, corresponding mereotopological axiomatization way binary relationships RCC-8 fragment Rrcc8 .axiomatic viewpoint, spatial calculus defined R general properties (P1P5),assumed known apriori. realize domain-independent spatial theoryused reasoning (e.g., spatio-temporal abduction) across dynamic domains,necessary formalize domain-independent spatial theory (space ) preserveshigh-level axiomatic semantics generic properties. reasons spacesketch properties P1P5 neglect formal axiomatization.(P1P2) Basic Calculus Properties (cp ) describe jointly exhaustive & pairwise disjoint (JEPD) property, i.e., two entities O, one one spatialrelationship R holds given situation. jointly exhaustive property n = |R|base relations axiomatized n ordinary state constraints and, similarly, pairwise disjoint property axiomatized [n(n 1)/2)] constraints. miscellaneousproperties symmetry asymmetry expressed manner.(P3) primitive relationships R continuity structure, referred Conceptual Neighbourhood (cn ) (CND) (Freksa, 1991), determines direct, continuous changes quality space (e.g., deformation and/or translational motion).(P4) axiomatic viewpoint, spatial calculus defined R (primarily) based60fiLearning Relational Event Models Videoderivation set Composition Theorems (ct ) JEPD set R.general, calculus consisting n JEPD relationships, [n n] compositionsprecomputed. composition theorems equivalent ordinary state constraint, every n-clique spatial situation description satisfy.(P5) Additionally, Axioms Interaction (ai ) necessary one spatial calculus modelled non-integrated manner (i.e., independent compositiontheorems). axioms explicitly characterize relative entailments interdependent aspects space, e.g., topology size.Now, let space def [cp cn ct ai ] denote domain-independent spatial theorybased axiomatizations encompassing (P1P5).7.2 Physically Plausible ScenariosCorresponding spatial situation (e.g., within hypothetical situation space),exists situation description characterizes spatial state system. necessary spatial component state complete specification, possiblydisjunctive information. k spatial calculi modelled, initial situation description involving domain objects requires complete n-clique specification [m(m 1)/2]spatial relationships calculus. Therefore, need define scene descriptionC-Consistent, i.e., compositionally consistent, n-clique state spatial situationdescription corresponding situation satisfies composition constraints everyspatial domain (e.g., topology, orientation, size) modelled. one calculusmodelled inter-dependent constraints (P5) must hold well.viewpoint model elimination narrative descriptions (abductive)explanation process, C-Consistency scenario descriptions key (contributing) factordetermining commonsensical notion physically realizability (abduced) scenario completions. Bhatt Loke (2008) show standard completion semanticscausal minimization presence frame assumptions ramification constraints preserves notion C-Consistency space within logic programming framework,well arbitrary basic action theories.7.3 Inductive-Abductive Frameworkinterleave inductive abductive commonsense reasoning space, eventschange within logic programming framework. Induction used means learn eventmodels generalizing sensory data, whereas abductive reasoning used noisydata correction scenario narrative completion, thereby improving learning.7.3.1 Explanation AbductionDiametrically opposite projection planning task post-dictum explanation (Poole, Goebel, & Aleliunas, 1987), given set time-stamped observationssnap-shots, objective explain events and/or actions may causedobserved state-of-affairs. Explanation problems demand inclusion narrativedescription, essentially distinguished course actual events mayincomplete information (Miller & Shanahan, 1994). Narrative descriptions typi61fiDubba, Cohn, Hogg, Bhatt & Dyllacally available sensory observations real execution system process. Givennarratives, objective often assimilate/explain respect underlyingprocess model.abductive explanation problem stated follows (Kakas, Kowalski, & Toni,1992):Given: Theory observations G, find explanation 4 that:4G4 consistenti.e., observation follows logically non trivially theory extended givenexplanation. Abductive explanations usually restricted ground literals predicates undefined theory, namely abducibles. Abductive explanationsderived trying prove observation initial theory alone: whenever literal encountered clause resolve with, literal addedexplanation.abduction procedure results many valid explanations. order reducenumber explanations, several restrictions listed used (Kakas et al., 1992):Explanations basic means one explanation explain anotherexplanation. enforced allowing abducibles head rule.Explanations minimal means one explanation subsume another explanation.Explanations satisfy integrity constraints restriction, obtain explanations valid domain consideration. work,explanations satisfy spatial constraints underlying spatial theory.7.3.2 Scenario Narrative Completioneasy intuitively infer general structure narrative completion abductiveexplanation. Consider illustration Fig.7 hypothetical situation space characterizes complete evolution system. Fig.7 situation-based history givensolid arrows represents one path, corresponding actual time-line discretizedintervals h0 , 1 , . . . , i, within overall branching-tree structured situation space.Given incomplete narrative descriptions, e.g., corresponding ordered intervalsterms high-level spatial (e.g., topological, orientation) occurrence information,objective explanation derive one paths branching situation space,could best-fit available narrative information. Formally:1 touch(a, c, 1 )dc(a,c,)in(b,a,)dc(b,c,)2444[]|=,space12( , j ).[ meets(1 , ) bef ore(i , 4 ) dc(b, a, )touch(a, c, ) dc(b, c, )][meets(,)meets(,)touch(b,a,)jj4jtouch(a, c, j ) dc(b, c, j )]62(7.1)fiLearning Relational Event Models VideocbccbcbcabcbcbcFigure 7: Branching/Hypothetical Situation Space. possibilities shown.clearly paths initial scenario target scenario. alsopossible states.(7.1), 1 denotes initial situation 2 denotes final situation representedterms spatial relations (RCC-5) among objects present scene. abductivederivation , explains scene changed situation 1 situation 2 ,primarily involves non-monotonic reasoning form minimizing change, additionmaking default assumptions inertia, appropriate treatment ramificationconstraints (Bhatt & Loke, 2008).7.4 IIA AlgorithmILP systems use covering algorithm learn models examples. searchranges hypothesis lattice hypothesis evaluated based numberpositive negative examples covers. selected suitable hypothesis basedscoring function, hypothesis (rule) added model, covered examplesremoved process repeated positive examples covered. Examplescorrupted noise resulting missing incorrect facts. cases,rules learned necessary order cover examples. numberrules concept increases, may result many false positives rulesused classification/recognition test examples. order avoid learning corruptexamples, framework identifies examples corrupted explainingabduction using already induced model background theory (Dubba et al., 2012).63fiDubba, Cohn, Hogg, Bhatt & Dyllamain assumption make noise examples consistent.noise consistent (i.e., present examples similar fashion)becomes part pattern defines concept might learned learningalgorithm.pseudo algorithm given Algorithm 1. induction algorithm inducesinitial hypothesis based score function explained previous sections. positive+examples covered (ERule) hypothesis removed list positive examplesyet covered. induced theory along background knowledge used explainuncovered examples treating example narrative. Abduction gives severalpossible explanations different cost (based nature number factsexplanation). explanations rejected cost specifiedthreshold. Furthermore, given formulation spatial theory space , C-Consistency+abduced explanations ensured. examples (E4) explanation whose costless specified threshold removed positive examples list yetcovered, considered covered already induced model.process induction abduction repeated positive examples covered.Apart constraints enforced spatial theory filter abduced explanations,several heuristics used give score explanation low cost consistentexplanation selected system. One several possible heuristics preferexplanations number transitions spatial relations minimal (Hazarika &Cohn, 2002). heuristic direct consequence McCarthys Common Sense LawInertia (McCarthy, 1986) states change abnormal persistencepreferred absence data. spatio-temporal domain, explanation abducedabsence data set spatio-temporal facts three ways addexplanation: (i) Extend current relation two objects (can donedirections timeline situation permits) (ii) change current relationtwo objects neighbouring relation CND (iii) introduce new object (hypothetical)scene spatial relations objects scene well. costexplanation based type spatio-temporal fact chosen calculatedexplained below.7.4.1 Cost Abduced ExplanationLet 4 explanation abduction procedure 4 set grounded spatiotemporal facts form r(oi , oj , k ) denoted fijrk , Ep+ current positive example(an interpretation, i.e., set facts) let r set spatial relations Rspatial calculus. Let set objects Ep+ . Let cfijrk cost abducing fijrk .Xtotal cost 4 denoted C4cfijrk .fijrk 4cost,,cfl =n,abducing fijrk calculated follows:exists fijrm Ep+ k disjointexists fijsm Ep+ k disjoint r =6n number hypothetical objects (objects O) fijrk< < .64fiLearning Relational Event Models Videofirst case cost function occurs system abduces fact extendsrelation two objects temporal dimension. count spatialtransition hence low cost. contrast, second case occurssystem abduces fact extends existence two objects temporal dimensiondifferent relation (the new spatial relation must neighbour existing relationCND) one already exists them. counts spatialtransition cost first case. third case occurs necessaryhypothetical object satisfy hypothesis Ep+ . case usedobject involved event completely missed object tracker first two casesused scenarios object detected temporal slice life time.Note first case clearly preferred abduction procedure findlow cost explanation third case expensive applies objectcompletely missed object tracker. Though possible avoid transitionsreduce score, sometimes mandatory consider transitions. example, considerscenario two objects dc relation final state relation.case, algorithm abduce facts two transitions (onedc relation changes touch another touch changes relation). Notenecessary abduce temporal relational facts Prolog definitions temporalrelations background theory used compute needed.achieved including temporal predicates list abducibles.abduction procedure uses existing constants database one issuethough number relations objects small, number possibleintervals large constrained. order constrain possible explanations,introduce intervals predefined duration database abduction usesintervals abducing explanations. Note abduction definedadds missing spatio-temporal information cannot used retract corrupteddata resulting noise.Algorithm 1 Interleaved Induction Abduction algorithm (IIA)procedure IIA(E + , E , B) . training sets background knowledge (includes spatialtheory)H4E + 6=RuleInduce(B, E + , E )H H {Rule}+E + E + ERule4 Abduce(B, H, E + )+E + E + E4endreturn H. Learned theoryend procedure65fiDubba, Cohn, Hogg, Bhatt & DyllaFigure 8: Airport domain: videos recorded using 6 static cameras lookingscene different angles.8. Experimental Resultssection, present evaluation remind, well extension presentedSection 7. experiments, used two real world video datasets differentmany aspects. videos datasets shot outdoor settingsdifferent weather light conditions (rainy, cloudy, sunny, night). variationsvideos present various challenges vision system subsequently learningsystem training phase event recognition phase.two datasets used work evaluation airport logistics verbvideos. datasets domains differ many aspects number objectsvideo, length video, duration events, background structures, numbercameras used capture events also plane (image plane ground plane)tracking data made available. view differences datasetspositive aspect - framework shown work two different kinds scenarios.remind11 implemented Python speed, modules implementedCython; SWI-Prolog used underlying Prolog engine storing queryingrelational facts background knowledge.8.1 Airport Logisticsexperiments airport logistics domain, 15 turn-arounds12 usedturn-around shot using 6 cameras different angles (Fig.8) videoaverage one hour long (15 frames per sec).following informal descriptions International Air Transport Association (IATA) events aim learn models for:11. Available request first author made public near future.12. turn-around duration plane entering leaving apron area.66fiLearning Relational Event Models VideoAircraft ArrivalAircraft comes apronAircraft DepartureAircraft moves away position apronGPU PositioningGround power unit comes positions zoneLeft RefuellingFuel truck arrives left side aircraft refuellingPB PositioningPush-back vehicle positioning front aircraftPBB PositioningPassenger Boarding Bridge attaches aircraftPBB RemovingPassenger Boarding Bridge detaches aircraftFWD CN LoadUnloadContainer Loading/Unloading front end aircraftAFT CN LoadUnloadContainer Loading/Unloading rear end aircraftAFT Bulk LoadUnloadBaggage Loading/Unloading rear end aircraftFWD Bulk LoadUnloadCatering Loading/Unloading front end aircraftWithin event, high variability noise tracking alsoobjects extraneous event entering event scene. Note events mightpresent may occur multiple times turn-arounds. scenes involveinteractions vehicles people zones apron. zones specifiedground plane according IATA specifications position zonesdepends type aircraft. zones used parking steering vehiclesdifferent operations carried turn-around. Note zones staticthroughout video change size position, unlike bounding boxesvehicles obtained tracking. Hence zones included type hierarchy useddomain (Fig.4) since suffer visual noise. main reason usezones RCC-5 spatial relations bounding boxes vehicles peopleground plane rarely touch, hence interactions encoded dc zonesused. important use zones interactions happenzones. According IATA specifications, vehicle transition zonesposition vehicle particular zones important determine events.use object tracks provided partner Co-Friend project (Ferryman,Borg, Thirde, Fusier, Valentin, Bremond, Thonnat, Aguilera, & Kampel, 2005); certaindetails events detectable tracking system directionbaggage rail loader vehicle whether trolleys empty arrivescene. Load/Unload events obtained IATA events differ details (iftrolleys loaded arrive scene baggage moving towardsaircraft, event loading trolleys empty arrivescene baggage moving away aircraft, event unloading). Apartdetails, semantically similar hence regarded events (forexample, FWD CN Load FWD CN Unload regarded events namedFWD CN LoadUnload, strategy followed Load/Unload events).8.1.1 Tracking Obtaining Relational Dataapron scene area large covered single static camera. eventsapron occur sides aircraft difficult cover67fiDubba, Cohn, Hogg, Bhatt & Dyllasingle camera size aircraft possible many occludedobjects scene. order solve problems, six cameras used shootscene different angles entire area covered number occludedobjects minimized. Working ground plane data results learned modelsindependent camera view airport models readily applieddifferent airports different camera configurations.tracking data obtained videos six cameras turn-aroundfused together get 3D data ground plane (Ferryman et al., 2005). trackingdata noisy low quality, bad light weather conditions low contrastCCTV videos. noise presence phantom objects, missing objects,wrong types vehicles, inaccurate bounding boxes, broken trajectories, object identity,inconsistencies etc. typical problems computer vision tracking system.turn-around separately processed get relational data consists setspatial relations among vehicles zones apron. Prolog rules decidetemporal relationships among intervals considered background information ILPsystem. data video 250 500 spatial relational facts (excludingtemporal relational facts) depending number objects interactionsobjects.Note event requires least one change state (here, spatio-temporalrelations pairs objects) objects. relation two objectsdc change life span objects, signifies objectsinteracting relational fact discarded spatio-temporal factscontain relevant information defining event models. tracking data also consistsbounding boxes people scenes, discarded people germanesemantics events also increase size relational data.8.1.2 Annotation Eventssupervised learning need positive preferably negative example instancesevents. airport domain, temporal extent events provided individuals expertise IATA protocols apron activities, specifyingstart end frame numbers event instance video. spatial extentobtained using tool polygon drawn one image planescorresponding ground plane region obtained using homography (it easierhuman annotator watch actual video provide spatial annotation ratherview 3D visualization ground plane, fusion imperfectlytracked data always show relevant objects). region gives spatialextent event instance.8.2 Physical Action Verbs DatasetAction Verbs dataset13 corpus video vignettes (Fig.9) portray motion verbsapproach, exchange, jump, collide, etc. enacted natural environments like parks,13. dataset (Minds Eye Year 1 recognition task videos) provided DARPA publicly availablehttp://www.visint.org/datasets68fiLearning Relational Event Models Video(a) Approach event tracked objects(b) Snatch event tracked objectsFigure 9: Example event instances Approach Snatch Action Verbs dataseturban places, etc. vignettes short duration compared videosairport domain, tens seconds. full list verbs given Table 3.Though vignette shot portray single verb action, verbs inevitablypresent well, sometimes overlapping time. primarily unavoidable, example,vignette portrays verb carry, automatically include walk person carryingobject hand. aspect taken consideration annotatingvignettes. able obtain tracked data external source (Morariu, Harwood,& Davis, 2013) including object type information (Fig.10).new challenge using dataset different ways verb enacted.48 verbs dataset total 1615 vignettes used training2348 vignettes used testing.8.2.1 Tracking Obtaining Relational Datatracking data available us often suffers errors, e.g., bouncing ball oftentracked held fast moving objects running person missed.used Qualitative Trajectory Calculus relations (QT CL1 ) (Van de Weghe et al., 2006)primitive spatio-temporal relations. choose RCC datasetseemed unlikely purely topological representation would sufficient. contrast,QT CL1 relations capture typical movements verbs dataset like moving away,approaching, follow etc. example, chase event one object following anotherobject relation dc, using RCC, also two objects standing stilldistance between.difficult model motion patterns objects like run, walk, raise, bend etc. usingrelational data without referring parts person. verbs dataset containsevents involve motion patterns recognize these, pixel based modelsappropriate. primitive events recognized videos using methodproposed Jiang, Lin Davis (2010), action represented sequencejoint HOG-flow descriptors (Dalal & Triggs, 2005) extracted independentlyframe. Instead applying approach entire frame video proposedJiang et al. (2010), input restricted sliding temporal windows along spatio69fiDubba, Cohn, Hogg, Bhatt & DyllaPersonObjectVehicleFigure 10: Tree-structured object type hierarchy Action Verbs domain.temporal volume defined persons bounding box. primitive events14 additionQT CL1 relations provide relational data verbs domain.8.2.2 Annotation Eventsground truth events verbs dataset vignettes different natureground truth airport domain. development test set annotated10 people using Amazon Mechanical Turk (AMT). vignette presentedannotator 48 questions presented form: verb X present vignette?verbs annotated 50% annotators considered events presentvignette. development set, annotations extended providingevent instance temporal extent.8.3 Experimental Results Evaluation Typed ILP FrameworkSample rules15 learned Aircraft Arrival AFT Bulk LoadUnload events givenbelow. example, Aircraft Arrival rule interpreted as: aircraft arrivesaircraft bounding box relation right AFT Bulk TS Zonemoves forward thereby changing relation touch. happens aircraftarrives moving position. rule also correctly identifies boundingbox belong object type aircraft. goals rule orderedspatial predicates come (to left of) temporal predicates sincetemporal facts16 compared spatial facts ordering speeds query execution.aircraft arrival([intv(T1,T2), intv(T3,T4)]) :in(obj(aircraft(V)), right AFT Bulk TS Zone, intv(T1,T2)),touch(right AFT Bulk TS Zone, obj(aircraft(V)), intv(T3,T4)),meets(intv(T1,T2), intv(T3,T4)).aft bulk loadunload([intv(T1,T2), intv(T3,T4)]) :touch(left TK Zone, obj(veh(heavy veh(V1))), intv(T1,T2)),touch(obj(veh(V2)), left TK Zone, intv(T3,T4)),meets(intv(T3,T4), intv(T1,T2)).followed standard leave-one-out methodology testing performanceairport domain. turn-arounds except one used training remaining oneused test case. process iterated turn-around used test case14. data provided Vlad Morariu University Maryland.15. temporal interval represented intv(T1 , T2 ) programming convenience T1 T2starting ending frame numbers interval.16. already noted, temporal facts explicitly stored computed via background knowledgerules.70fiLearning Relational Event Models VideoEvent#ExamplesWithout Type GeneralizationType GeneralizationFWD CN LoadUnload70.860.060.110.860.080.15GPU Positioning160.40.030.050.270.020.04Aircraft Arrival150.430.010.020.360.010.02AFT Bulk LoadUnload290.720.200.310.720.200.31PBB Removing150.430.060.100.360.120.18Left Refuelling80.250.030.050.120.100.11PB Positioning140.280.040.070.140.060.08Aircraft Departure120.410.110.170.330.190.24AFT CN LoadUnload150.800.050.090.670.070.13PBB Positioning150.730.160.260.670.340.45FWD Bulk LoadUnload31.000.240.391.001.001.00Weighted Average0.150.20Table 1: Performance comparison models obtained without using types usingRCC-5 primitives airport domain. first, second third columnscategory recall, precision f1 respectively. best f1 value case presentedbold. clear table using types improves overall performance.without type generalization mean, type information tracker ignored (all objectstype) type generalization performed learning.exactly once. results experiments summarised Table 1. thirdfourth columns show recall precision without using types 15 turn-arounds(i.e., type information tracker ignored, hence objects typetype generalization performed learning). fifth sixth columns showrecall precision using type hierarchy. tables clear using typeinformation increase accuracy event recognition. Also combined executiontime experiments using type generalization reduced roughly 30%compared execution time experiments without type generalization.detailed recognition results (temporal localization) events turn-aroundshown Fig. 11 (best seen colour). plot shows turn-around one subplot showing ground truth event instances another subplot showing recognized instancesTyped ILP system turn-around. event colour coded comparingground truth recognized instance intervals. Note recognized event instanceconsidered true positive overlaps least 20% corresponding event groundtruth interval (Oh et al., 2011). cases temporal extent recognized event in71fiDubba, Cohn, Hogg, Bhatt & DyllaFigure 11: Recognition events turn-around 1 airport domain (best viewedcolour).stances long spatial relations important event extend beyonddeictic interval event.8.3.1 Evaluating Learned Event Models Hand-Coded Event Modelslearned models also evaluated comparing hand-coded models.hand-coded models provided domain experts using set domain-dependentspatial relations (Ferryman et al., 2005). order directly compare performance withoutchange underlying representation, rather using RCC-5, recomputedrelational data remind using domain-dependent primitives. comparisonsgiven Table 2. clear table learned models better performanceevent categories compared performance hand-coded models.hand-coded models single primitives rather set primitives connectedtemporal relations. kind models one single predicate farfalse positives compared models set spatial relations connected72fiLearning Relational Event Models VideoEvent#ExamplesLearned (RCC-5)Learned (d-d)Hand-coded (d-d)FWD CN LoadUnload70.860.080.150.140.500.220.710.040.07GPU Positioning160.270.020.040.440.030.050.001.000.00Aircraft Arrival150.360.010.020.070.010.010.070.050.06AFT Bulk LoadUnload290.720.200.310.590.270.370.030.050.04PBB Removing150.360.120.180.260.140.180.001.000.00Left Refuelling80.120.100.110.380.230.280.001.000.00PB Positioning140.140.060.080.070.080.070.210.090.12Aircraft Departure120.330.190.240.001.000.000.001.000.00AFT CN LoadUnload150.670.070.130.330.050.080.470.070.12PBB Positioning150.670.340.450.260.200.220.400.070.12FWD Bulk LoadUnload31.001.001.000.001.000.001.000.020.04Weighted Average0.200.160.05Table 2: Table comparing learned (RCC-5), learned (domain-dependent) hand-codedmodels performance (domain-dependent). first, second third columnscategory recall, precision f1 respectively. best f1 value case presentedbold.temporal relations. Also hand-coded models use specific vehicle type eventmodels affects performance reducing true positives noiseobject type detection, whereas learned models use appropriate generalized objecttype cover instances.8.3.2 Evaluating Learned Event Models Different Spatial Relationsalso performed evaluation investigate effects different spatial relations.comparison used RCC-5 domain specific relations airport domain.use QTC relations domain examples learnmany spatial relations QTC spatial calculus, patternsevents emerge. results given Table 2. table clearmodels learned using RCC-5 better recognition performance (mean f1: 0.25)compared models learned using domain-dependent relations (mean f1: 0.13). Onereason might RCC-5 better representation granularity compareddomain-dependent primitives. Also RCC-5 JEPD (jointly exhaustive pair-wisedisjoint) property domain-dependent primitives airport domain(it lacks pair-wise disjoint property).8.3.3 Evaluating Verbs Datasetframework uses type generalization also applied verbs dataset48 verbs. Table 3 shows precision, recall f1 scores classification task.video test set, event models used queries event model73fiDubba, Cohn, Hogg, Bhatt & Dyllasucceeds, particular verb considered present video (and variablebindings give time occurrence objects involved). comparedground truth obtain precision recall values.provide sample rules learned events Approach Snatch coverinstances shown Fig.9. QT CL1 relations moto (short form moving towardsstationary object), static depart (short form moving away stationary object)corresponds relations blobs row 2 column 1, row 2 column 2, row 2column 3 respectively Fig.1. Also note unlike models learned AirportDataset, list temporal intervals argument head rules here.want recognize events videos Action Verbsdataset videos short find temporal extent event.approach() :moto(obj(vehicle(J)), obj(person(K)), intv(V 32,V 33)),static(obj(vehicle(J)), obj(person(K)), intv(V 34,V 35)),meets(intv(V 32,V 33), int(V 34,V 35)).snatch() :static(obj(person(J)), obj(person(K)), intv(V 24,V 25)),moto(obj(other(L)), obj(person(J)), intv(V 40,V 41)),depart(obj(other(L)), obj(person(K)), intv(V 18,V 51)),overlaps(intv(V 40,V 41), int(V 18,V 51)),during(intv(V 40,V 41), intv(V 24,V 25)),during(intv(V 18,V 51), intv(V 24,V 25)).proposed framework, compared existing systems resultspresented Tables 4-7. One systems compared with, RedVinesystem, supervised learning version framework proposed Sridhar, CohnHogg (2010). based graphical representation relational facts, eventrepresented histogram graphemes (small graphs represent spatio-temporalinteractions objects involved event) mapped vector space facilitateclassification. Stack convolutional Independent Subspace Analysis (ScISA) (Le et al.,2011)17 based pixel level flow based features used model eventsusing neural network. spatio-temporal features used algorithm learnedunsupervised fashion instead using predefined features SIFT (Lowe, 2004),HoG (Dalal & Triggs, 2005), etc.evaluation dataset provided DARPA total 2348 vignettes.found vignettes (1294) training set also appeared evaluation set.call dataset 2348 vignettes Verb Evaluation Dataset-1 (VED1)remaining vignettes discarding 1294 vignettes appeared training datasetVED2. Evaluation VED1 gives interesting insights overfitting underfittingdifferent learning frameworks compared. chose two different averagemechanisms (macro micro)18 get overall f1 Matthews correlation coefficient(MCC) scores verbs vignettes. True Negatives play role f117. Results using system provided Tuyen Huynh SRI.18. Macro-average calculated first calculating precision recall category takingaverage values, micro-average calculated constructing global contingency tablecalculating precision recall using sums.74fiLearning Relational Event Models VideoVerbprecision recallapproacharriveattachbounceburycarrycatchchaseclosecollidedigdropenterexchangeexitfall0.360.280.080.110.050.140.050.040.070.140.020.080.170.060.150.100.780.730.490.710.570.530.580.440.290.830.360.470.740.560.710.62f1Verb0.490.400.140.190.100.220.100.070.110.240.040.140.280.110.250.17fleeflyfollowgetgivegohandhaulhitholdjumpkickleaveliftmoveprecision recall0.070.060.090.150.110.520.100.090.460.140.470.060.070.291.000.760.820.420.620.500.660.790.660.460.600.640.690.250.380.760.000.74f10.140.110.160.230.180.630.170.150.520.230.560.090.110.420.000.75Verbopenpasspickuppushputdownraisereceivereplacerunsnatchstoptakethrowtouchturnwalkprecision recall0.100.221.000.161.000.330.150.070.100.110.390.240.060.640.470.320.770.390.000.820.000.630.700.770.820.510.780.620.390.530.530.80f10.170.280.000.270.000.440.250.130.180.190.520.350.100.580.500.45Table 3: Classification results per verb physical action verbs domain.scores considerable effect MCC scores MCC differentiatepositive negative classes. MCC give scores even class labelsinterchanged f1 scores change. Note much work literature activityrecognition use f1 scores.Tables 4-7, clear ScISA better MCC scores casesremind better f1 score VED2, though lower MCC scoresMCC scores two algorithms. Also note drop performance ScISAVED2 set compared VED1, whereas remind RedVine almostperformance indicating ScISA overfitting data remind RedVineunderfitting data. reason high f1 low MCC score remindTrue Negatives.ScISA performs quite well (w.r.t. MCC score) modelling capabilityframework since underutilizes temporal domain. outperformstate-of-the-art evaluation measures, proposed scheme still general, i.e.,(i) gives good interpretations activities video scenes; (ii) take temporaldomain account unlike ScISA therefore provides better modelling capabilities;(iii) gives high recall precision improved post-processing(iv) provides (elegant) logical rules easily interpreted human observer.One major drawback ScISA lack spatio-temporal localization recognizedevent. suitable event classification tasks (verbs dataset)event recognition tasks (airport domain). Although report localization(owing short videos data set), deriving localization (or position) informationremind trivial event recognized since intervals objects involvedexplicitly identified rule body.75fiDubba, Cohn, Hogg, Bhatt & DyllaMethodremindRedVineScISAavg-prec0.240.320.91avg-rec0.560.240.54f10.340.280.68MCC0.050.160.67Table 4: Performance verbs domain: VED1, macro-average per verb.MethodremindRedVineScISAtotal prec0.210.370.92total rec0.590.240.60f10.310.300.72MCC0.00.190.70Table 5: Performance verbs domain: VED1, micro-average (total detection classification)MethodremindRedVineScISAavg-prec0.250.350.49avg-rec0.590.250.20f10.350.290.29MCC0.040.170.21Table 6: Performance verbs domain: VED2, macro-average per verbMethodremindRedVineScISAtotal prec0.210.400.59total rec0.630.260.29f10.320.310.39MCC0.080.200.33Table 7: Performance verbs domain: VED2, micro-average (total detection classification)8.4 Experimental Results Evaluation IIAIIA framework evaluated airport verb datasets. useHyprolog, logic programming framework capable abductive inference (Christiansen &Dahl, 2005).8.4.1 Embedding Spatial Theory Airport Domainairport domain, encoded RCC-5 spatial theory space framework contains conceptual neighbourhood graph, JEPD relationshipscomposition theorems spatial relations used follows:76fiLearning Relational Event Models Video% Sampledc(X, Y,dc(X, Y,dc(X, Y,dc(X, Y,dc(X, Y,JEPDT) ,T1),T1),T1),T1),constraintstouch(X, Y,touch(X, Y,touch(X, Y,touch(X, Y,touch(X, Y,(P1 - P2) RCC-5T)T2), during(T1, T2)T2), during(T2, T1)T2), overlaps(T1, T2)T2), overlaps(T2, T1)<=><=><=><=><=>fail.fail.fail.fail.fail.% Conceptual Neighbourhood constraints (P3) RCC-5dc(X, Y, T1), in(X, Y, T2), meets(T1, T2) <=> fail.in(X, Y, T1), dc(X, Y, T2), meets(T1, T2) <=> fail.% Sample Composition Theorem (P4) RCC-5in(X, Y, T1), dc(Y, Z, T2), touch(X, Z, T3), during(T2, T1),during(T3, T2) <=> fail.JEPD CND property constraints forbid abduction facts contradict spatial theory thus avoiding physically impossible scenarios also helpsabduction complete reasonable time.explain approach, consider following fragments actually occurring datasets(Ex:1 - Ex:4) event Aircraft Arrival :Ex:1dc(arr zone,obj(aircraft(obj45)),intv(6661,7137))touch(arr zone,obj(aircraft(obj45)),intv(7138,29114))touch(arr zone,obj(veh(light veh(gpu(obj54)))),intv(7154,8161))dc(arr zone,obj(veh(heavy veh(loader(obj2)))),intv(749,30380))Ex:2dc(arr zone,obj(aircraft(obj68)),intv(2342,2663))touch(arr zone,obj(aircraft(obj68)),intv(2664,29524))Ex:3dc(arr zone,obj(veh(light veh(trolley(obj0)))),intv(285,21494))touch(arr zone,obj(aircraft(obj41)),intv(4458,32404))touch(arr zone,obj(veh(light veh(trolley(obj2)))),intv(1712,32405))Ex:4dc(arr zone,obj(aircraft(obj33)),intv(2435,6987))touch(arr zone,obj(veh(heavy veh(loader(obj27)))),intv(2197,2310))dc(arr zone,obj(veh(heavy veh(loader(obj27)))),intv(2311,2645))obtain following model Aircraft Arrival event learned ILP approachfirst two examples given examples arr zone denoting specific zoneapron Ti denotes time point. fact two time points indicating startend interval spatio-temporal fact holds.aircraft arrival([intv(T1,T2), intv(T3,T4)]) :dc(arr zone, obj(aircraft(V)), intv(T1,T2)),touch(arr zone, obj(aircraft(V)), intv(T3,T4)),meets(intv(T1,T2), intv(T3,T4)).77fiDubba, Cohn, Hogg, Bhatt & DyllaobjobjZ1Z2Z1Z2Z3Z3arr_zoneZ4Z5arr_zoneZ4Z5timeaircraft_arrival(T1,T2)dis(arr_zone,obj(aircraft(V)),T1,T)con(arr_zone,obj(aircraft(V)),T+1,T2)(a) Spatial primitive based event modelling966966Z1Z2Z3Z4Z1Z2Z3arr_zoneZ5Z4arr_zoneZ5timeaircraft_arrival(5338,16868)rel?(arr_zone,obj?,5338,16630)con(arr_zone,obj(aircraft(obj996)),16631,16868)(b) Narrative completion (of data video) previously learned modelFigure 12: IIA Scenario Narrative Completion; E.g., aircraft arrivalrule states aircraft arrival takes place intervalaircraft disconnected arr zone directly followed interval, i.e., meets,aircraft connected arr zone. model cover examplesapart Ex:1 Ex:2. Ex:3 missing dc relation related aircraft whereasEx:4 missing touch relation (Fig. 12b). represent typical data corruptionhigher level tracking error lower level video processing different stagesvideo.8.4.2 Narrative Completion Airport DomainMultiple explanations interesting give several possible scenarios consistent narrative. example, consider Ex:4 touch fact related aircraftarrival event missing narrative. happens vision algorithm failsdetect aircraft coming towards parking zone big object changeslight conditions scene. abduction system comes two explanations (asshown following sample interactive run system), one filling missed factconsistent narrative background knowledge constraints. Anotherexplanation using hypothetical object ( G41673) present database.78fiLearning Relational Event Models Videoexplanation expensive first explanation, system chose firstexplanation.%A small narrative three observations (The touch fact%is missing, happens, vision algorithm fails%to detect aicraft close: Approximate%interval specified aircraft-arrival query%dc(arr_zone,obj(aircraft(obj33)),intv(2435,6987))%touch(arr_zone,obj(veh(heavy_veh(loader(obj7)))),intv(2197,2310))%dc(arr_zone,obj(veh(heavy_veh(loader(obj7)))),intv(2311,2645))?- aircraft_arrival(intv(2000,12000)).touch(arr_zone,obj(aircraft(obj33)),intv(6988,7988))true ;dc(arr_zone,obj(aircraft(_G41673)),intv(2435,6987))touch(arr_zone,obj(aircraft(_G41673)),intv(6988,7988))true ; false.narrative completion, possible cover examples given above, onesingle Aircraft Arrival model learned. avoids learning spurious rules covercorrupted examples thus giving us compact semantically meaningful models.evaluate approach, compare rules learned using induction ruleslearned using IIA algorithm. first column Table 8 shows eventsconsidered experiments, second column shows number instancesparticular event 15 turnarounds. third column shows number rules learnedusing ILP fourth column shows results using IIA algorithmfifth column shows number examples covered induced rulesexplained using abduction hence rules learned them. interleavinginduction abduction, able avoid learning spurious rules shownresults. classes, number rules reduced 50% overallperformance also increased. also observed rules previouslylearned examples covered abduction semantically correspondevents.8.4.3 Evaluating IIA Verbs Datasetverbs domain, encoded spatial theory QT CL1 spatial calculi. Thoughalso used domain-dependent primitive events domain besides QT CL1 ,encode spatial theory relations well defined. example,domain-dependent primitives domain neither jointly exhaustive pair-wisedisjoint. also avoided abducing explanations relations includingrelations list abducibles. 10-fold cross-validation used evaluation verbsdataset. Since video short duration around 200 frames, used classificationinstead recognition. Table 9 clear using abduction reduces numberrules event model thereby giving compact model. verbs dataset results,considerable change performance classification task ratherrecognition task. main performance increase IIA inference comes79fiDubba, Cohn, Hogg, Bhatt & DyllaAirport Events#posFWD CN LoadUnload5GPU Positioning15Aircraft Arrival15Aircraft Departure15AFT Bulk LoadUnload12Left Refuelling6PB Positioning15AFT CN LoadUnload7PBB Positioning15PBB Removing15FWD Bulk LoadUnload3Num rules Induction 225555243452Num2RoIPoIRIAPIA120.80.30.83410.21250.380.260.33270.80.150.71240.630.430.63120.660.50.66320.330.340.33130.570.40.573210.571250.540.230.5411111rules IIA avg num examples covered0.40.40.320.260.650.550.420.510.620.311abdTable 8: Airport domain IIA results averaged iterations leave-one-out testing.RoI, PoI - recall precision induction: RIA, PIA - recall precision usingIIA.Verb Events#pos2RoIApproach584125450.73Arrive82120.50Attach4863121.00Bounce222200.95Catch20174310.59Chase108117190.59Collide10164140.98Dig140107210.96Drop442201.00Exchange186340.40Fall13485180.92Give5522720540.94Jump15064140.98Kick484361.00Leave116104340.67Lift7885170.67Pass7684130.87Pickup406480.81Run767570.57Throw263250.67Num rules Induction 2 Num rules IIA avgPoIRIA0.120.740.050.500.141.000.060.950.110.560.080.570.160.980.380.960.161.000.030.400.350.900.560.940.130.980.151.000.200.670.240.670.100.870.130.810.120.570.110.67num examples coveredPIA0.120.050.170.080.110.080.180.390.160.030.350.600.130.150.220.240.120.160.120.11abdTable 9: Verbs dataset IIA results averaged iterations 10-fold cross-validationtesting. RoI, PoI - recall precision induction: RIA, PIA - recall precisionusing IIA.reduction false positives fewer rules recognition highpossibility multiple rules firing test data thereby giving many false positives.classification, case, vignette classified memberparticular event class rule, classification rules event classaffect overall outcome vignette.80fiLearning Relational Event Models Video9. Limitations Future Workmodels used remind local, i.e., without context wider activity modelcould used filter recognized instances thereby increasing performance.example, turn-arounds airport domain, Aircraft Departure eventsometimes recognized even Aircraft Arrival recognized resulting false positivesAircraft Departure. Another limitation learned models lack representationduration events. Many recognized event instances rejected systemtemporal extent recognized instances long fails criteria 20% overlapground truth. reduced learning global model (Greenall, Cohn, &Hogg, 2011) constrains ordering events Aircraft Departure detectionshappen Aircraft Arrival. activity models also represent expectedduration events, temporal separation events number occurrences.framework sensitive initial example selected start learning procedure.induction system used based algorithm uses bottom clause (Muggleton,1995) constructed selected example guide refinement hypothesissearching lattice. Hence possible might select corrupted example initiallymight affect whole induction process. typical problem machine learningseveral ways avoid this. One promising approach followedwork repeat learning different examples chosen randomly starting pointselecting iteration gives minimum number rules.Another limitation framework dependency tracking objectsuses interactions objects model events. Challenging scenarios object trackingpose limitations current framework. current framework probabilistic, i.e.,neither input data learned models probabilistic. One direction future workextend framework using statistical relational learning use soft evidencelearn robust probabilistic relational models. Since current frameworkhandle hierarchies events, framework could extended handle hierarchicalcomposition events. One possible approach learn models eventsparticular layer using events lower layers primitives.10. Conclusionpaper, proposed supervised relational learning framework, extension using abduction, learn event models complex videos. event modelsused recognize event instances unseen videos. presented Type Refinementoperator exploits object type hierarchy domain search better hypotheses also proved optimal refinement operator. presented empiricalevaluation proposed framework two real world video data sets resultsencouraging, showing framework effectively used real world systemsevent recognition various domains. also showed proposed frameworkbetter generalization capabilities performance compared state-of-the-artsystems event modelling. Finally, note although focused learningvideo data here, fact approach would also suitable learningdata sources provide tracks interacting moving objects (e.g. GPS streams).81fiDubba, Cohn, Hogg, Bhatt & DyllaAcknowledgementsthank colleagues CO-FRIEND, RACE, STRANDS VIGIL projects consortiavaluable inputs research, respective funding EU Framework7 (FP7-ICT-214975, FP7-ICT-27752, FP7-ICT-600623) DARPA (W911NF-10-C-0083).Also financial support Deutsche Forschungsgemeinschaft Transregional Collaborative Research Center SFB/TR 8 Spatial Cognition project R3-[Q-Shape] gratefullyacknowledged.Appendix A. Proof Optimality Type Refinement OperatorLet type hierarchy tree set nodes TV , set leaf nodes TL , i.e.specific types (TL TV ) r root tree (most generic type). typeparent node generic types children nodes write= .Let g function, g : TV TV , maps child node immediate parent.function g considered generalizing operator generalizes type nearestgeneric type. g applied long 6= rLet Si ordered (from most-specific general) set possible generalizations including .Si = {i , g(i ), g(g(i )), . . . , r }set types {1 , 2 , . . . , n }, define corresponding sets S1 , S2 , . . . , Sn .Let {h1 , h2 , . . . , hm } set types19 clause C {h1 , h2 , . . . , hm } TV .{h1 , h2 , . . . , hm }, define Sh1 , Sh2 , . . . , Shm . make set {h1 , h2 , . . . , hm }generic applying g (one times) arbitrarily selected subset typesone type time.Cartesian product Sh1 Sh2 . . . Shm set tuples tuplepossible generalization {h1 , h2 , . . . , hm }.Let l function mapping non-leaf type node integer specifies manytimes g applied original leaf node obtain non-leaf node20 , l : TV N .Using l, generate new set Nhi Shi replacing l(i ).generate new Cartesian product Nh1 Nh2 . . . Nhm .Example .1. Let (1 , 2 , 3 ) set types clause C let type hierarchygiven Fig.13. define S1 , S2 , S3 N1 , N2 , N3 followstree representation Cartesian products S1 S2 S3 N1 N2 N3 givenFig.14 Fig.15 respectively.19. consider list types clause C types may repeatedarguments type, results appendix still valid.20. Note general, non-leaf node obtained leaf nodes descendantsunique leaf node obtained store original leaf node generalized using gget non-leaf type node.82fiLearning Relational Event Models Videor1 g(2 ), g(3 )2 3Figure 13: example type hierarchy.S1 = {1 , g(1 )}S2 = {2 , g(2 ), g(g(2 ))}S3 = {3 , g(3 ), g(g(3 ))}N1 = {0, 1}N2 = {0, 1, 2}N3 = {0, 1, 2}12g(2 )g(1 )2g(g(2 ))g(2 )g(g(2 ))3 g(3 ) g(g(3 )) 3 g(3 ) g(g(3 )) 3 g(3 ) g(g(3 )) 3 g(3 ) g(g(3 )) 3 g(3 ) g(g(3 )) 3 g(3 ) g(g(3 ))Figure 14: Representing Cartesian product S1 S2 S3 tree. root emptynext layer corresponds S1 on. Note g(1 ) = g(g(2 )) = g(g(3 )) = r .path tree leaf possible generalization (1 , 2 , 3 ) leftmost pathnull generalization, i.e. (1 , 2 , 3 ).Definition .2. (Type Substitution, ) type substitution set{h1 /1 , h2 /2 , . . . , hn /n } hi type subset variablesclause C immediate generic type hi (parent node hi tree ).say substituted hi clause. set {h1 , h2 , . . . , hn } called domain, denoted dom( ) set (1 , 2 , . . . , n ) called range , denoted rng( ).type substitution used generalize type subset variables clause.Definition .3. (Most Generic Type Substitution, r ) generic type substitutiontype substitution whose range set {r } r root type hierarchy tree .generic type substitution used check two clauses structurally equivalent(Def:4) substituting types variable r . Note every clause C uniquegeneric type substitution, Cr , whose domain set types C rangeset {r }.83fiDubba, Cohn, Hogg, Bhatt & Dylla001120120 1 2 0 1 2 0 1 2 0 1 2 0 1 2 0 1 2Figure 15: Representing Cartesian product N1 N2 N3 tree. root emptynext layer corresponds N1 on. path leaf represents possiblegeneralization (1 , 2 , 3 ). generalization obtained following pathroot leaf generalizing type layer number times indicatednode value. example, highlighted sequence (1,2,1) corresponds generalization(g(1 ), g(g(2 )), g(3 )). obtained generalizing 1 generalizing 2twice generalizing 3 once. top bottom order (left right case tuples)followed, unique way achieve generalization (g(1 ), g(g(2 )), g(3 ))(1 , 2 , 3 ).Definition .4. (Structurally Equivalent, ) Two clauses, C C 0 structurally equiv0alent, denoted C C 0 , CCr C 0 Cr .clause C structurally equivalent clauses obtained replacing subsettypes variables C generalizations.Definition .5. (Generic Order w.r.t. types, ) clause C said generalw.r.t. type another clause C 0 , denoted C C 0 , iff C C 0 set types Ccorrespondingly generic set types C 0 .Definition .6. (Type-Refinement Operator) Let clausal language, type hierarchyC clause . CT subset defined C clause C 0 CTstructurally equivalent C, i.e., C C 0 . Let subsumption order defined above.Type-Refinement operator hCT , function (C) {D|D C}.One-step type refinement C defined applied once, i.e. 1 =(C). n-step type refinement defined similarly, i.e. n = {D | E, En1(C) (E)}. set type refinements C given(C) = 1 (C) 2 (C) . . ..locally finite every C , (C) finite computable.proper every C , (C) {D|D C}.complete every C, C, E (C)E (i.e. E equivalent order).84fiLearning Relational Event Models Videoweakly complete hCT , (C) = CT .non-redundant every C, D, E , E (C) E (D) impliesC (D) (C)ideal locally finite, proper complete.optimal locally finite, non-redundant weakly complete.type refinement operator selects type hi set {h1 , h2 , . . . , hm } C applies type generalizing operator type resulting set {h1 , h2 , . . . , g(hi ), . . . , hm }used substitution C obtain generic clause C 0 respect type, i.e.,C 0 C . type refinement operator follows left right order generalizing typesavoid generating redundant clauses, i.e., type position generalizednext step refinement h0 type position j, j < selected generalizing.Theorem .7. locally finiteProof. Let type hierarchy tree TV set nodes TC ={h1 , h2 , . . . , hm } set types clause C TC TV . Let g typegeneralizing operator type refinement operator. operates C selectingtype set {h1 , h2 , . . . , hm } generalizing applying g. |TC |possibilities select possible type selected one possiblegeneralization, type one parent tree . Also typegeneralized finite number times (i.e., becomes r ). Hence number possiblerefinements, i.e., | (C)| finite making locally finite.Theorem .8. weakly completeProof. given clause C set types {h1 , h2 , . . . , hm } defined above.1 , 1 , . . .} obtained one-step type refinementLet X1 set substitutions {,1,21 C 0 1 (C). Let X = X X . . . X setCi0 = C,i1221 , 1 , . . . , 1 }substitutions obtained two-step type refinement {i1i2im1 ).rng(,i1 , 1 , . . . , 1 ), . . . , ( 1 , 1 , . . . , 1 ), . . .}, i.e. 1Let 1 set tuples {(11121mi1 i2imset tuples tuple represents possible type refinement {h1 , h2 , . . . , hm }one-step type refinement let = 1 2 . . ..easy observe tuple P also tuple Cartesian productSh1 Sh2 . . . Shm . fact exact one one matching membersmembers Sh1 Sh2 . . . Shm . easy obtain member tuple, say PP = (1 , 2 , . . . , ) Cartesian product generalizing {h1 , h2 , . . . , hm }. type higeneralized equal moving next type immediate righthi . way possible type generalizations {h1 , h2 , . . . , hm } reachable{h1 , h2 , . . . , hm }, i.e., possible type generalized clauses reachable C, henceweakly complete.Theorem .9. non-redundant85fiDubba, Cohn, Hogg, Bhatt & DyllaProof. Let Nh1 Nh2 . . . Nhm defined previously set types {h1 , h2 , . . . , hm }clause C. Cartesian product represented tree rootempty next level elements Nh1 on. path leaf representspossible generalization {h1 , h2 , . . . , hm }. generalization obtained followingpath root leaf generalizing type layer number timesindicated node value. top bottom order (left right case tuples)followed, unique way obtain generalization path generates. Hencenon-redundant.Example .10. example Fig.15, sequence (1,2,1) bold corresponds generalization (g(1 ), g(g(2 )), g(3 )). obtained generalizing 1 generalizing2 twice generalizing 3 once. top bottom order followed,unique way achieve generalization (g(1 ), g(g(2 )), g(3 )) (1 , 2 , 3 ).Theorem .11. optimalProof. Since type refinement operator locally finite, weakly complete non-redundant,optimal.ReferencesAlbanese, M., Moscato, V., Picariello, A., Subrahmanian, V., & Udrea, O. (2007). Detectingstochastically scheduled activities video. Proceedings International JointConference Aritificial Intelligence (IJCAI), pp. 18021807.Allen, J. F. (1983). Maintaining knowledge temporal intervals. CommunicationsACM, 26, 832843.Bengio, Y. (2009). Learning deep architectures AI. Foundations Trends MachineLearning, 2 (1), 1127.Bhatt, M., & Loke, S. (2008). Modelling dynamic spatial systems situation calculus.Spatial Cognition & Computation, 8 (1-2), 86130.Blockeel, H., De Raedt, L., Jacobs, N., & Demoen, B. (1999). Scaling Inductive LogicProgramming learning interpretations. Data Mining Knowledge Discovery, 3 (1), 5993.Bundy, A., Byrd, L., & Mellish, C. (1985). Special-purpose, domain-independent, inference mechanisms. Progress Artificial Intelligence, pp. 93111. London: EllisHorwood.Chen, J., Cohn, A. G., Liu, D., Wang, S., Ouyang, J., & Yu, Q. (2015). surveyqualitative spatial representations. Knowledge Engineering Review, 30, 106136.Christiansen, H., & Dahl, V. (2005). HYPROLOG: new logic programming languageassumptions abduction. Logic Programming, 159173.Cohn, A. G. (1989). Taxonomic reasoning many-sorted logics. Artificial IntelligenceReview, 3 (2), 89128.86fiLearning Relational Event Models VideoCohn, A. G., Hogg, D. C., Bennett, B., Devin, V., Galata, A., Magee, D. R., Needham, C.,& Santos, P. (2006). Cognitive vision: integrating symbolic qualitative representationscomputer vision.. Vol. 3948 LNCS, chap. 14, pp. 221246. Springer.Dalal, N., & Triggs, B. (2005). Histograms oriented gradients human detection.IEEE Conference Computer Vision Pattern Recognition (CVPR), Vol. 1, pp.886893.Dubba, K. S., Bhatt, M., Dylla, F., Hogg, D. C., & Cohn, A. G. (2012). Interleavedinductive-abductive reasoning learning complex event models. Inductive LogicProgramming, pp. 113129. Springer.Dubba, K. S., Cohn, A. G., & Hogg, D. C. (2010). Event model learning complexvideos using ILP. Proceedings European Conference Artificial Intelligence(ECAI), Vol. 215, pp. 9398.Fern, A., Givan, R., & Siskind, J. (2002). Specific-to-general learning temporal eventsapplication learning event definitions video. Journal Artificial Intelligence Research, 17, 379449.Ferryman, J., Borg, M., Thirde, D., Fusier, F., Valentin, V., Bremond, F., Thonnat, M.,Aguilera, J., & Kampel, M. (2005). Automated scene understanding airport aprons.LNCS-3809, Springer Verlag, 3809, 593.Freksa, C. (1991). Conceptual neighborhood role temporal spatial reasoning.Singh, M., & Trave-Massuyes, L. (Eds.), Decision Support Systems QualitativeReasoning, pp. 181187. North-Holland, Amsterdam.Ghahramani, Z. (1998). Learning Dynamic Bayesian networks. Adaptive ProcessingSequences Data Structures, 168197.Greenall, J., Cohn, A. G., & Hogg, D. C. (2011). Temporal structure models eventrecognition. British Machine Vision Conference (BMVC).Gupta, A., Srinivasan, P., Shi, J., & Davis, L. (2009). Understanding videos, constructingplots learning visually grounded storyline model annotated videos. IEEEConference Computer Vision Pattern Recognition (CVPR), pp. 20042011.Hakeem, A., Sheikh, Y., & Shah, M. (2004). CASEE : hierarchical event representationanalysis videos. Proceeding National Conference ArtificialIntelligence (AAAI), pp. 263268.Hartley, R., & Zisserman, A. (2004). Multiple View Geometry Computer Vision (Secondedition). Cambridge University Press.Hazarika, S. M., & Cohn, A. G. (2002). Abducing qualitative spatio-temporal historiespartial observations. International Conference Principles KnowledgeRepresentation Reasoning, pp. 1425.Hoogs, A., & Perera, A. G. A. (2008). Video activity recognition real world.Proceedings National Conference Artificial Intelligence (AAAI), pp. 15511554.87fiDubba, Cohn, Hogg, Bhatt & DyllaIvanov, Y., & Bobick, A. (2000). Recognition visual activities interactions stochastic parsing. IEEE Transactions Pattern Analysis Machine Intelligence (PAMI),22 (8).Jiang, Z., Lin, Z., & Davis, L. S. (2010). tree-based approach integrated action localization, recognition segmentation. Third Workshop Human Motion (inconjuntion ECCV).Kakas, A., Kowalski, R., & Toni, F. (1992). Abductive logic programming. Journal LogicComputation, 2 (6), 719.Kakas, A., & Riguzzi, F. (2000). Abductive concept learning. New Generation Computing,18 (3), 243294.Konik, T., & Laird, J. (2006). Learning goal hierarchies structured observationsexpert annotations. Machine Learning, 64 (1), 263287.Laptev, I. (2005). space-time interest points. International Journal Computer Vision,64 (2), 107123.Laptev, I., & Perez, P. (2007). Retrieving actions movies. IEEE International Conference Computer Vision (ICCV), pp. 18.Le, Q., Zou, W., Yeung, S., & Ng, A. (2011). Learning hierarchical invariant spatio-temporalfeatures action recognition independent subspace analysis. IEEE Conference Computer Vision Pattern Recognition (CVPR), pp. 33613368. IEEE.Lowe, D. (2004). Distinctive image features scale-invariant keypoints. InternationalJournal Computer Vision, 60 (2), 91110.McCarthy, J. (1986). Applications circumscription formalizing common-sense knowledge. Artificial Intelligence, 28 (1), 89116.Medioni, G., Cohen, I., Bremond, F., Hongeng, S., & Nevatia, R. (2001). Event detectionanalysis video streams. IEEE Transactions Pattern Analysis MachineIntelligence (PAMI), 23 (8), 873889.Miller, R., & Shanahan, M. (1994). Narratives Situation Calculus. Journal LogicComputation, 4 (5), 513530.Morariu, V. I., & Davis, L. S. (2011). Multi-agent event recognition structured scenarios..IEEE Conference Computer Vision Pattern Recognition (CVPR), pp. 32893296.Morariu, V. I., Harwood, D., & Davis, L. S. (2013). Tracking peoples hands feetusing mixed network and/or search.. IEEE Transactions Pattern AnalysisMachine Intelligence (PAMI).Moyle, S. (2003). Using theory completion learn robot navigation control program.Proceedings International Conference ILP, 182197.Moyle, S., & Muggleton, S. (1997). Learning programs Event Calculus. LNAI-1297,Springer-Verlag, 205212.Muggleton, S. (1995). Inverse entailment Progol. New Generation Computing, 13 (3&4),245286.88fiLearning Relational Event Models VideoMuggleton, S., & Bryant, C. H. (2000). Theory completion using inverse entailment. Proceedings International Conference ILP, pp. 130146, UK. Springer-Verlag.Needham, C., Santos, P., Magee, D., Devin, V., Hogg, D., & Cohn, A. (2005). Protocolsperceptual observations. Artificial Intelligence, 167 (1-2), 103136.Nevatia, R., Hobbs, J., & Bolles, B. (2004). ontology video event representation.Computer Vision Pattern Recognition Workshop (CVPRW-04), pp. 119119.IEEE.Nienhuys-Cheng, S., & De Wolf, R. (1997). Foundations Inductive Logic Programming,Vol. 1228. Springer Verlag.Oh, S., Hoogs, A., Perera, et al. (2011). large-scale benchmark dataset event recognition surveillance video. IEEE Conference Computer Vision PatternRecognition (CVPR), pp. 31533160.Poole, D., Goebel, R., & Aleliunas, R. (1987). Theorist: logical reasoning systemdefaults diagnosis. Knowledge Frontier, pp. 331352.Quinlan, J., & Cameron-Jones, R. (1993). FOIL: midterm report. ProceedingsEuropean Conference Machine Learning (ECML), pp. 120.Quinlan, J. (1990). Learning logical definitions relations. Machine Learning, 5 (3),239266.Rabiner, L. (1989). tutorial Hidden Markov models selected applications speechrecognition. Proceedings IEEE, 77 (2), 257286.Randell, D. A., Cui, Z., & Cohn, A. (1992). spatial logic based regions connection. Proceedings International Conference Knowledge RepresentationReasoning, pp. 165176. Morgan Kaufmann.Ryoo, M. S., & Aggarwal, J. K. (2009). Semantic representation recognition continuedrecursive human activities. International Journal Computer Vision, 82 (1), 124.Ryoo, M., & Aggarwal, J. (2011). Stochastic representation recognition high-levelgroup activities. International Journal Computer Vision, 93 (2), 183200.Sridhar, M., Cohn, A. G., & Hogg, D. C. (2010). Unsupervised learning event classesvideo. Proceedings National Conference Artificial Intelligence (AAAI),pp. 16311638.Tamaddoni-Nezhad, A., Chaleil, R., Kakas, A., & Muggleton, S. (2006). Applicationabductive ILP learning metabolic network inhibition temporal data. MachineLearning, 64 (1), 209230.Tamaddoni-Nezhad, A., & Muggleton, S. (2009). lattice structure refinementoperators hypothesis space bounded bottom clause. Machine learning,76 (1), 3772.Van de Weghe, N., Cohn, A., De Tre, G., & De Maeyer, P. (2006). qualitative trajectory calculus basis representing moving objects geographical informationsystems. Control Cybernetics, 35 (1), 97.89fiDubba, Cohn, Hogg, Bhatt & DyllaVeeraraghavan, H., Papanikolopoulos, N., & Schrater, P. (2007). Learning dynamic eventdescriptions image sequences. IEEE Conference Computer Vision PatternRecognition (CVPR), pp. 16.Vu, V.-T., Bremond, F., & Thonnat, M. (2003). Automatic video interpretation: novelalgorithm temporal scenario recognition. Proceedings International JointConference Artifical Intelligence (IJCAI), Vol. 3, pp. 12951300.Walther, C. (1985). mechanical solution Schuberts Steamroller many-sorted resolution. Artificial Intelligence, 26 (2), 217224.Yilmaz, A., Javed, O., & Shah, M. (2006). Object tracking: survey. ACM ComputingSurveys (CSUR), 38 (4), 13.YouTube (2015) http://www.youtube.com/yt/press/statistics.html. Accessed January 25, 2015.90fi