Journal Artificial Intelligence Research 57 (2016) 187-227Submitted 9/15; published 10/16Multi-objective Reinforcement LearningContinuous Pareto Manifold ApproximationSimone Parisiparisi@ias.tu-darmstadt.deTechnische Universitat DarmstadtHochschulstr. 10, 64289 Darmstadt, GermanyMatteo PirottaMarcello Restellimatteo.pirotta@polimi.itmarcello.restelli@polimi.itPolitecnico di MilanoPiazza Leonardo da Vinci 32, 20133 Milano, ItalyAbstractMany real-world control applications, economics robotics, characterizedpresence multiple conflicting objectives. problems, standard conceptoptimality replaced Paretooptimality goal find Pareto frontier,set solutions representing different compromises among objectives. Despite recent advances multiobjective optimization, achieving accurate representationPareto frontier still important challenge. paper, propose reinforcementlearning policy gradient approach learn continuous approximation Pareto frontier multiobjective Markov Decision Problems (MOMDPs). Differently previouspolicy gradient algorithms, n optimization routines executed n solutions,approach performs single gradient ascent run, generating step improvedcontinuous approximation Pareto frontier. idea optimize parametersfunction defining manifold policy parameters space, correspondingimage objectives space gets close possible true Pareto frontier. Besidesderiving compute estimate gradient, also discuss nontrivialissue defining metric assess quality candidate Pareto frontiers. Finally,properties proposed approach empirically evaluated two problems,linear-quadratic Gaussian regulator water reservoir control task.1. IntroductionMultiobjective sequential decision problems characterized presence multipleconflicting objectives found many real-world scenarios, economicsystems (Shelton, 2001), medical treatment (Lizotte, Bowling, & Murphy, 2012), controlwater reservoirs (Castelletti, Pianosi, & Restelli, 2013), elevators (Crites & Barto, 1998)robots (Nojima, Kojima, & Kubota, 2003; Ahmadzadeh, Kormushev, & Caldwell, 2014),mention few. problems often modeled Multiobjective Markov DecisionProcesses (MOMDPs), concept optimality typical MDPs replacedone Pareto optimality, defines compromise among different objectives.last decades, Reinforcement Learning (RL) (Sutton & Barto, 1998) establishedeffective theoretically grounded framework allows solve singleobjectiveMDPs whenever either (or little) prior knowledge available system dynamicsdimensionality system controlled high classical optimal control2016 AI Access Foundation. rights reserved.fiParisi, Pirotta, & Restellimethods. Multiobjective Reinforcement Learning (MORL), instead, concerns MOMDPstries solve sequential decision problems two conflicting objectives.Despite successful development RL theory high demand multiobjectivecontrol applications, MORL still relatively young unexplored research topic.MORL approaches divided two categories, based number policieslearn (Vamplew, Dazeley, Berry, Issabekov, & Dekker, 2011): single multiplepolicy. Although MORL approaches belong former category, presentmultiplepolicy approach, able learn set policies approximating Pareto frontier.representation complete Pareto frontier, fact, allows posteriori selectionsolution encapsulates trade-offs among objectives, giving better insightsrelationships among objectives. Among multiplepolicy algorithms possibleidentify two classes: valuebased (Lizotte et al., 2012; Castelletti et al., 2013; Van Moffaert& Nowe, 2014), search optimal solutions value functions space, policy gradient approaches (Shelton, 2001; Parisi, Pirotta, Smacchia, Bascetta, & Restelli, 2014),search policy space. practice, approach different advantages. Valuebased methods usually stronger guarantees convergence, preferred domains lowdimensional state-action spaces prone suffer cursedimensionality (Sutton & Barto, 1998). hand, policy gradient methodsfavorable many domains robotics allow taskappropriateprestructured policies integrated straightforwardly (Deisenroth, Neumann, & Peters,2013) experts knowledge incorporated ease. selecting suitable policyparametrization, learning problem simplified stability well robustnessfrequently ensured (Bertsekas, 2005). Nonetheless, approaches lack guarantees uniform covering true Pareto frontier quality approximatefrontier, terms accuracy (distance true frontier) covering (its extent),related metric used measure discrepancy true Pareto frontier.However, nowadays definition metric open problem MOO literature.paper, overcome limitations proposing novel gradientbased MORLapproach alternative quality measures approximate frontiers. algorithm, namelyParetoManifold Gradient Algorithm (PMGA), exploiting continuous approximationlocally Paretooptimal manifold policy space, able generate arbitrarilydense approximate frontier. article extension preliminary work presentedPirotta, Parisi, Restelli (2015) main contributions are: derivationgradient approach general case, i.e., independent metric used measurequality current solution (Section 3), estimate gradient samples(Section 4), discussion frontier quality measures effectively integratedproposed approach (Section 5), thorough empirical evaluation proposedalgorithm metrics performance multiobjective discrete-time Linear-QuadraticGaussian regulator water reservoir management domain (Sections 6 7).2. Preliminariessection, first briefly summarize terminology used paper discussstate-of-the-art approaches MORL. Subsequently, focus describing policygradient techniques introduce notation used remainder paper.188fiMORL Continuous Pareto Manifold Approximation2.1 Problem Formulationdiscretetime continuous Markov Decision Process (MDP) mathematical frameworkmodeling decision making. described tuple hS, A, P, R, , Di, Rncontinuous state space, Rm continuous action space, P Markoviantransition model P(s0 |s, a) defines transition density state s0action a, R : R reward function, [0, 1) discount factor,distribution initial state drawn. context, behavioragent defined policy, i.e., density distribution (a|s) specifies probabilitytaking action state s. Given initial state distribution D, possible defineexpected return J associated policy"T 1#XJ =ER(st , , st+1 )|s0 ,st P,att=0R(st , , st+1 ) immediate reward obtained state st+1 reached executingaction state st , finite infinite time horizon. goal agentmaximize return.Multiobjective Markov Decision Processes (MOMDPs) extension MDPsseveral pairs reward functions discount factors defined, oneobjective. Formally, MOMDP described tuple hS, A, P, R, , Di, R =[R1 , . . . , Rq ]T = [1 , . . . , q ]T qdimensional column vectors reward functionsRi : R discount factors [0, 1), respectively.MOMDPs, policyassociated q expected returns J = J1 , . . . , Jq ,"T 1#XJi =ERi (st , , st+1 )|s0 .st P,att=0Unlike happens MDPs, MOMDPs single policy dominating othersusually exist, conflicting objectives considered, policy simultaneously maximize them. reason, Multiobjective Optimization (MOO)concept Pareto dominance used. Policy strongly dominates policy 0 , denoted0 , superior objectives, i.e.,00 {1, . . . , q} , Ji > Ji .Similarly, policy weakly dominates policy 0 , denoted 0 , worseobjectives, i.e.,000 {1, . . . , q} , Ji Ji {1, . . . , q} , Ji = Ji .policy 0 0 , policy Paretooptimal. also speaklocally Paretooptimal policies, definition above, exceptrestrict dominance neighborhood . general, multiple(locally) Paretooptimal policies. SolvingMOMDPequivalent determine set= | @ 0 , 0 , maps socalled ParetoParetooptimalpoliciesfrontier F = J | .11. done Harada, Sakuma, Kobayashi (2006), assume locally Paretooptimal solutionsParetooptimal exist.189fiParisi, Pirotta, & Restelli2.2 Related WorkMultiobjective Optimization (MOO) field, two common solution concepts:multiobjective singleobjective strategy Pareto strategy. former approachderives scalar objective multiple objectives and, then, uses standard Singleobjective Optimization (SOO) techniques: weighted sum (Athan & Papalambros, 1996),normbased (Yu & Leitmann, 1974; Koski & Silvennoinen, 1987), sequential (Romero,2001), constrained (Waltz, 1967), physical programming (Messac & Ismail-Yahaya, 2002)min-max methods (Steuer & Choo, 1983). latter strategy based conceptPareto dominance considers Paretooptimal solutions non-inferior solutions amongcandidate solutions. main exponent class convex hull method (Das &Dennis, 1998; Messac, Ismail-Yahaya, & Mattson, 2003).Similar MOO, current MORL approaches divided two categories basednumber policies learn (Vamplew et al., 2011). Singlepolicy methods aimfinding best policy satisfies preference among objectives. majorityMORL approaches belong category differ way preferencesexpressed. easy implement, require priori decision typesolution suffer instability, small changes preferences may resultsignificant variations solution (Vamplew et al., 2011). straightforwardcommon singlepolicy approach scalarization function appliedreward vector order produce scalar signal. Usually, linear combination weightedsum rewards performed weights used express preferencesmultiple objective (Castelletti, Corani, Rizzolli, Soncinie-Sessa, & Weber, 2002; Natarajan& Tadepalli, 2005; Van Moffaert, Drugan, & Nowe, 2013). Less common use nonlinear mappings (Tesauro, Das, Chan, Kephart, Levine, Rawson, & Lefurgy, 2008).main advantage scalarization simplicity. However, linear scalarization presentslimitations: able find solutions lie concave linear regionPareto frontier (Athan & Papalambros, 1996) uniform distribution weights mayproduce accurate evenly distributed points Pareto frontier (Das & Dennis,1997). addition, even frontier convex, solutions cannot achievedscalarization loss one objective may compensated incrementanother one (Perny & Weng, 2010). Different singlepolicy approaches basedthresholds lexicographic ordering (Gabor, Kalmar, & Szepesvari, 1998) differentkinds preferences objective space (Mannor & Shimkin, 2002, 2004).Multiplepolicy approaches, contrary, aim learning multiple policies orderapproximate Pareto frontier. Building exact frontier generally impracticalreal-world problems, thus, goal build approximation frontier containssolutions accurate, evenly distributed along frontier range similarPareto one (Zitzler, Thiele, Laumanns, Fonseca, & da Fonseca, 2003). manyreasons behind superiority multiplepolicy methods: permit posterioriselection solution encapsulate trade-offs among multiple objectives.addition, graphical representation frontier give better insights relationships among objectives useful understanding problemchoice solution. However, benefits come higher computational cost,prevent learning online scenarios. common approach approximate190fiMORL Continuous Pareto Manifold ApproximationPareto frontier perform multiple runs singlepolicy algorithm varyingpreferences among objectives (Castelletti et al., 2002; Van Moffaert et al., 2013).simple approach suffers disadvantages singlepolicy method used.Besides this, examples multiplepolicy algorithms found literature.Barrett Narayanan (2008) proposed algorithm learns deterministic policies defining convex hull Pareto frontier single learning process. Recentworks focused extension fitted Q-iteration multiobjective scenario.Lizotte, Bowling, Murphy (2010), Lizotte et al. (2012) focusedlinear approximation value function, Castelletti, Pianosi, Restelli (2012) ablelearn control policy linear combinations preferences among objectives single learning process. Finally, Wang Sebag (2013) proposed MonteCarloTree Search algorithm able learn solutions lying concave region frontier.Nevertheless, classic approaches exploit deterministic policies resultscattered Pareto frontiers, stochastic policies give continuous range compromisesamong objectives (Roijers, Vamplew, Whiteson, & Dazeley, 2013; Parisi et al., 2014). Shelton (2001, Section 4.2.1) pioneer use stochastic mixture policiesgradient ascent MORL. achieved two well known goals MORL: simultaneousconditional objectives maximization. former, agent must maintain goalstime. algorithm starts mixture policies obtained applying standardRL techniques independent objective. policy subsequently improved followingconvex combination gradients policy space nonnegative w.r.t.objectives. objective i, gradient gi expected return w.r.t. policycomputed vector vi highest dot product gi simultaneouslysatisfying nonnegativity condition returns used improving directioni-th reward. vectors vi combined convex form obtain directionparameter improvement. result policy belongs Pareto frontier.approximation Pareto frontier obtained performing repeated searchesdifferent weights reward gradients vi . hand, conditional optimizationconsists maximizing objective maintaining certain level performanceothers. resulting algorithm gradient search reduced policy spacevalue constrained objectives greater desired performance.studies followed work Shelton (2001) regard policy gradientalgorithms applied MOMDPs. Recently Parisi et al. (2014) proposed two policy gradientbased MORL approaches that, starting initial policies, perform gradient ascentpolicy parameters space order determine set nondominated policies.first approach (called Radial ), given number p Pareto solutions requiredapproximating Pareto frontier, p gradient ascent searches performed, onefollowing different (uniformly spaced) direction within ascent simplex definedconvex combination singleobjective gradients. second approach (called ParetoFollowing) starts performing singleobjective optimization moves alongPareto frontier using two-step iterative process: updating policy parameters followinggradient ascent direction, applying correction procedure movenew solution onto Pareto frontier. Although methods exploit stochastic policiesproved effective several scenarios, still return scattered solutionsguaranteed uniformly cover Pareto frontier. best knowledge, nowadays191fiParisi, Pirotta, & RestelliMORL algorithm returning continuous approximation Pareto frontier2 .following sections present first approach able that: ParetoManifoldGradient Algorithm (PMGA).2.3 Policy Parametrization PolicyGradient ApproachessingleobjectiveMDPs,policygradient approaches consider parameterized policies= : Rd , compact notation (a|s, ) policyparameters space. Given policy parametrization , assume policy performanceJ : F Rq least class C 2 .3 F called objectives space J definedexpected reward space possible trajectoriesZp ( |) r( )d,J () =trajectory drawn density distribution p( |) reward vectorr( )accumulated expected discounted reward trajectory , i.e.,Prepresents1Ri (st , , st+1 ). Examples parametrized policies used contextri ( ) = Tt=0Guassian policies Gibbs policies. MOMDPs, q gradient directions definedpolicy parameter (Peters & Schaal, 2008b), i.e.,ZJi () =p ( |) ri ( )d = E ln p ( |) ri ( )"#1Xb Ji (),E ri ( )ln (at |st , ) =(1)t=0direction Ji associated particular discount factorreward functionb Ji () sample-based estimate. shown Equation (1),pair < , Ri >differentiability expected return connected differentiability policyln p ( |) =1Xln (at |st , ).t=0remark notation. following use symbol DX F denotederivative generic function F : Rmn Rpq w.r.t. matrix X.4 Noticefollowing relationship holds scalar functions vector variable: x f = (Dx f )T . Finally,symbol Ix used denote x x identity matrix.3. Gradient Ascent Policy Manifold Continuous Pareto FrontierApproximationsection first provide general definition optimization problem wantsolve explain solve MOMDP scenario using gradientbased approach. novel contributes section summarized Lemma 3.12. notable exception MOO approach Calandra, Peters, Deisenrothy (2014) GaussianProcesses used obtain continuous approximation Pareto frontier.3. function class C 2 continuous, twice differentiable derivatives continuous.4. derivative operator well defined matrices, vectors scalar functions. Refer workMagnus Neudecker (1999) details.192fiMORL Continuous Pareto Manifold Approximationobjective function gradient described. particular, provide solutionproblem evaluating performance continuous approximation Paretofrontier w.r.t. indicator function. problem non trivial MORLdirect access Pareto frontier manipulate policyparameters. provide step-by-step derivation results leveraging manifoldtheory matrix calculus.3.1 Continuous Pareto Frontier Approximation MultiobjectiveOptimizationshown locally Paretooptimal solutions locally forms (q 1)dimensionalmanifold, assuming > q (Harada, Sakuma, Kobayashi, & Ono, 2007). follows2objective problems, Paretooptimal solutions described curves policyparameters objective spaces. idea behind work parametrize locallyParetooptimal solution curve objectives space, order produce continuousrepresentation Pareto frontier.Let generative space open set Rb b q. analogous highdimensional function parameterized curve smooth map : Rq classC l (l 1), P Rk free variables parameters,respectively. set F = (T ) together map constitute parametrizedmanifold dimension b, denoted F (T ) (Munkres, 1997). manifold representsapproximation Pareto frontier. goal find best approximation, i.e.,parameters minimize distance real frontier= arg max (F (T )) ,(2)P: Rq R indicator function measuring quality F (T ) w.r.t.true Pareto frontier. Notice Equation (2) interpreted special projectionoperator (refer Figure 1a graphical representation). However, since requiresknowledge true Pareto frontier, different indicator function needed.definition metric open problem literature. Recently, several metricsdefined, candidate presents intrinsic flaws prevent definitionunique superior metric (Vamplew et al., 2011). Furthermore, seeremainder section, proposed approach needs metric differentiable w.r.t.policy parameters. investigate topic Section 5.general, MOO algorithms compute value frontier sum valuepoints composing discrete approximation. scenario, continuousapproximate frontier available, maps integration Pareto manifoldZIdV,(3)L () =F (T )L () manifold value, dV denotes integral w.r.t. volume manifold: F (T ) R indicator function measuring Pareto optimality pointF (T ). Assuming continuous, integral given (Munkres, 1997)ZZL () =IdV(I ) V ol (Dt (t)) dt,F (T )193fiParisi, Pirotta, & Restelli(a)(b)Figure 1: Transformation maps generic MOO setting (Figure (a)) MORL (Figure (b)). MOO also possible consider parametrized solutions Figure (b), MORL necessary, mapping Fi knownclosed form determined (discounted) sum rewards.1provided integral exists V ol (X) = det X X 2 . standard way maximizeprevious equation performing gradient ascent, updating parameters accordinggradient manifold value w.r.t. parameters , i.e., + L () .3.2 Continuous Pareto Frontier Approximation MultiobjectiveReinforcement Learningstandard multiobjective optimization function free designed,MORL must satisfy conditions. first thing notice direct mapparameters space objective space unknown, easilydefined reparameterization involving policy space , shown Figure 1b.previous section mentioned tight relationship (local)manifold objective space (local) manifold policy parameters space.mapping well known defined performance function J() definingutility policy . means that, given set policy parameterizations, defineassociated points objective space. consequence, optimization problemreformulated search best approximation Pareto manifoldpolicy parameter space, i.e., search manifold policy parameter spacebest describes optimal Pareto frontier.Formally, let : smooth map class C l (l 1) defineddomain . think map parameterization subset (T ) :choice point gives rise point (t) (T ) . meanssubset (T ) space spanned map , i.e., (T ) bdimensionalparametrized manifold policy parameters space, i.e.,(T ) = { : = (t), } ,and, consequence, associated parameterized Pareto frontier bdimensionalopen set definedF (T ) = {J () : (T )} .194fiMORL Continuous Pareto Manifold Approximation3.3 Gradient Ascent Manifold Spacepoint introduced notation needed derive gradient L ().Lemma 3.1. (Pirotta et al., 2015) Let open set Rb , let F (T ) manifoldparametrized smooth map expressed composition maps J , (i.e., =J : Rq ). Given continuous function defined point F (T ),integral w.r.t. volume givenZZL () =IdV =(I (J )) V ol (D J()Dt (t)) dt,F (T )provided integral exists. associated gradient w.r.t. parameters givenZL ()=(I (J )) V ol (T) dtZ(I (J )) V ol (T) vec+Nb Ib Di Tdt, (4)= J()Dt (t), Kronecker product, Nb = 12 (Ib2 + Kbb ) symmetric(b2 b2 ) idempotent matrix rank 21 b(b + 1) Kbb permutation matrix (Magnus& Neudecker, 1999). Finally,Di = Dt (t)T Iq (D J()) Di (t) + (Ib J()) Di (Dt (t)) .Proof. equation manifold value L () follows directly definitionvolume integral manifold (Munkres, 1997) definition function composition.following, provide detailed derivation i-th component gradient.Let = J( )Dt (t),ZL ()=(I (J )) V ol (T) dtZdet TT1+(I (J ))dt.2V ol (T)indicator derivative determinant derivative respectively expanded(I (J )) = DJ I(Jt ) J( ) Di (t),det TTdet TT vec TT=,(vecT)(vecT)|{z} |{z} | {z } |{z}111b2b2 qbqb1det TT(vec T)TTT(vec T)T,= detvec= 2Nb Ib TT ,195fiParisi, Pirotta, & RestelliKronecker product, Nb = 12 (Ib2 + Kbb ) symmetric (b2 b2 ) idempotentmatrix rank 21 b(b + 1) Kbb permutation matrix (Magnus & Neudecker, 1999).(T)last term expanded Di vec. start basic propertydifferential, i.e.,(D J()Dt (t)) = d(D J())Dt (t) + J() d(Dt (t))then, applying vector operator,dvec (D J()Dt (t)) = vec (d(D J())Dt (t)) + vec (D J() d(Dt (t)))= Dt (t)T Iq dvec (D J()) + (Ib J()) dvec (Dt (t)) .{z} |{z}|{z}{z}||dq1bqdqbqbdbd1Finally, derivative givenvec J() (t)vec Dt (t)Di = Dt (t)T Iq+ (Ib J())|{z} | {zi }|{z}dqdd1bd1= Dt (t) Iq (D J()) Di (t) + (Ib J()) Di (Dt (t)) .interesting notice gradient manifold value L () requirescompute second derivatives policy performance J(). However, (D J()) =vec J()denote Hessian matrix transformation(m,n)HJi=2Dn,mJi ()=nJi= Dp,n (D J()) ,p = + q(m 1) q (number objectives) number rows Jacobianmatrix. Recall Hessianmatrixis defined derivative transposeJacobian, i.e., H J() = J()T .now, little research done second-order methods5 particularHessian formulations. first analysis performed Kakade (2001), providedformulation based policy gradient theorem (Sutton, McAllester, Singh, & Mansour,2000). Recently, extended comparison Newton method, EM algorithmnatural gradient presented Furmston Barber (2012). sake clarity,report Hessian formulation provided Furmston Barber (2012) using notationintroduce optimal baseline (in terms variance reduction) formulation.Lemma 3.2. MOMDP, Hessian H J() expected discounted reward Jw.r.t. policy parameters qd matrix obtained stacking Hessian5. Notable exceptions natural gradient approaches that, although explicitly requirecompute second-order derivatives, usually considered second-order methods.196fiMORL Continuous Pareto Manifold ApproximationcomponentH J() =vecJi ()H J1 ()..=,.H Jq ()ZH Ji () =!p ( |) (ri ( ) bi ) ln p ( |) ln p ( |)T + H ln p ( |) d,(5)ln p ( |) =1Xln (at |st , ),H ln p ( |) =t=01XH ln (at |st , ).t=0(m,n)optimal baseline Hessian estimate HJi provided Equation (5)computed done Greensmith, Bartlett, Baxter (2004) order reducevariance gradient estimate. given component-wise2(m,n)E p(|) Ri ( ) G( )(m,n)bi=2 ,(m,n)E p(|) G( )(m,n)(m,n)nG( ) =ln p ( |) ln p ( |)+HAppendix A.ln p ( |). derivation, refer4. Manifold Gradient Estimation Sample TrajectoriesMORL, prior knowledge reward function state transitionmodel, need estimate gradient L () trajectory samples. sectionaims provide guide estimation manifold gradient. particular, reviewresults related estimation standard RL components (expected discounted returngradient) provide finite-sample analysis Hessian estimate.formulation gradient L () provided Lemma 3.1 composed termsrelated parameterization manifold policy space terms relatedMDP. Since map free designed, associated terms (e.g., Dt (t))computed exactly. hand, terms related MDP (J (), J()H J()) need estimated. estimate expected discounted rewardassociated gradient old topic RL literature several resultsproposed (Kakade, 2001; Pirotta, Restelli, & Bascetta, 2013), literature lacks explicitanalysis Hessian estimate. Recently, simultaneous perturbation stochastic approximation technique exploited estimate Hessian (Fonteneau & Prashanth, 2014).However, rely formulation provided Furmston Barber (2012)Hessian estimated trajectory samples obtained current policy, removingnecessity generating policy perturbations.197fiParisi, Pirotta, & RestelliAlgorithm 1 ParetoManifold Gradient AlgorithmDefine policy , parametric function , indicator learning rateInitialize parametersRepeat terminal condition reachedCollect n = 1 . . . N trajectoriesSample free variable t[n] generative spaceSample policy parameters [n] = t[n]n[n] [n] [n]Execute trajectory collect data st , , rt,t=1b Ji () according Equation (1)Compute gradientsb Ji () according Equation (6)Compute Hessians HCompute manifold value derivative L () according Equation (4)Update parameters + L ()Since p ( |) unknown, expectation approximated empirical average.Assuming access N trajectories, Hessian estimate!N1XX1b Ji () =Hrnt,i bNn=1t=0!T 1!11XXXln ant ,sntln ant ,snt+H ln ant ,snt ,(6)t=0n[n] [n] [n]st , , rt,t=1t=0t=0denotes n-th trajectory. formulation resembles def-inition REINFORCE estimate given Williams (1992) gradient J().estimates, known likelihood ratio methods, overcome problem determining perturbation parameters occurring finite-difference methods. Algorithm 1 describescomplete PMGA procedure.order simplify theoretical analysis Hessian estimate, make following assumptions.Assumption 4.1 (Uniform boundedness). reward function, log-Jacobianlog-Hessian policy uniformly bounded: = 1, . . . , q, = 1, . . . , d, n =1, . . . , d, (s, a, s0 ) ,fifififififififi (m)fifi (m,n)fi0 filn (a|s, )fi G.fiRi (s, a, )fi Ri ,fiD ln (a|s, )fi D,fiHLemma 4.2. Given parametrized policy (a|s, ), Assumption 4.1, i-th component log-Hessian expected return boundedkH Ji ()kmaxRi2TD + G ,1max norm matrix defined kAkmax = maxi,j {aij }.198fiMORL Continuous Pareto Manifold ApproximationProof. Consider definition Hessian Equation (5). assumption 4.1,Hessian components bounded (m, n)fi"11fifi fiZXXfi (m,n)fi filn (at |st , )ln (aj |sj , )Ji ()fi = fi p ( |) ri ( )fiHfint=0j=0#fifi2fi+ln (at |st , ) fifin111XXXRi2Ril1+ G =TD + G .1l=0t=0j=0previous result used derive bound sample complexityHessian estimate.Theorem 4.3. Given parametrized policy (a|s, ), Assumption 4.1, usingfollowing number -step trajectories2 21Ri2N 2TD + Gln2i (1 )b Ji () generated Equation (6) probability 1gradient estimate Hb.H Ji () H Ji ()maxProof. Hoeffdings inequality implies m, nN 2 2fifiPNfi b (m,n)fi(m,n)(bi ai )2i=1=.P fiHJi () HJi () fi 2eSolving equation N noticing Lemma 4.2 provides bound sample,obtain2 21Ri2N= 2TD + Gln .2i (1 )integral estimate computed using standard MonteCarlo techniques. Severalstatistical bounds proposed literature, refer Robert Casella (2004)survey MonteCarlo methods.point paper, reader may expect analysis convergence (orconvergence rate) optimal parametrization. Although consider analysis theoretically challenging interesting, provide result related topic.analysis hard (or even impossible) provide general settings since objectivefunction nonlinear nonconcave. Moreover, analysis simplified scenario (ifpossible) almost useless real applications.199fiParisi, Pirotta, & Restelli5. Metrics Multiobjective Optimizationsection, review indicator functions proposed literature, underlining advantages drawbacks, propose alternatives. Recently, MOO focuseduse indicators turn multiobjective optimization problem singleobjectiveone optimizing indicator itself. indicator function used assign everypoint given frontier scalar measure gives rough idea discrepancy candidate frontier Pareto one. Since instead optimizing objectivefunctions directly indicatorbased algorithms aim finding solution set maximizesindicator metric, natural question arises correctness changeoptimization procedure properties indicator functions enjoy. instance,hypervolume indicator weighted version among widespread metricsliterature. metrics gained popularity refinementsPareto dominance relation (Zitzler, Thiele, & Bader, 2010). Recently, several worksproposed order theoretically investigate properties hypervolume indicator (e.g., Friedrich, Horoba, & Neumann, 2009). Nevertheless, arguedhypervolume indicator may introduce bias search. Furthermore another importantissue dealing hypervolume indicator choice reference point.perspective, main issues metric high computational complexity (thecomputation hypervolume indicator #Phard problem, see Friedrich et al., 2009)and, all, non differentiability. Several metrics defined fieldMOO, refer work Okabe, Jin, Sendhoff (2003) survey. However,MOO literature able provide superior metric among candidatesone suited scenario. Again, main issues non differentiability,capability evaluating discrete representations Pareto frontier intrinsicnature metrics. example, generational distance, another widespread measurebased minimum distance reference frontier, available settings.overcome issues, mixed different indicator concepts novel differentiablemetrics. insights guided metrics definition related MOOdesiderata. Recall goal MOO compute approximation frontierincluding solutions accurate, evenly distributed covering range similaractual one (Zitzler et al., 2003). Note uniformity frontier intrinsically guaranteed continuity approximation introduced. conceptsmind, need induce accuracy extension indicator function.stressed clear definition want indicatormaximized real Pareto frontier. also must ensure indicator functioninduces partial ordering frontiers: manifold F2 solutions (weakly) dominatedmanifold F1 ones, F1 manifold value must better F2 one.Definition 5.1 (Consistent Indicator Function). Let F set (q 1)dimensionalmanifolds associated MOMDP q objectives. Let k manifoldpolicy parametersspace mapping Fk F F true Pareto frontier. LetRLI (F) = F IdV manifold value. indicator function consistentFk 6= Fh , LI (Fh ) > LI (Fk ) Fh F ,h , k , k , j h , j = LI (Fh ) > LI (Fk ).200fiMORL Continuous Pareto Manifold Approximation5.1 Accuracy MetricsGiven reference point p, simple indicator obtained computing distanceevery point frontier F reference point, i.e.,= kJ pk22 .mentioned hypervolume indicator, choice reference point maycritical. However, natural choice utopia (ideal) point (pU ), i.e., pointoptimizes objectives. case goal minimization indicatorfunction, denoted IU (utopia indicator ). Since dominated policy fartherutopia least one Paretooptimal solution, accuracy easily guaranteed.hand, since minimized, measure forces solution collapsesingle point, thus consistent. Note problem mitigated(but solved) forcing transformation pass singleobjectiveoptima. Although trick helpful, discuss Section 6, requiresfind singleobjective optimal policies order constrain parameters. However,information also required properly set utopia.Concerning accuracy frontier, theoretical perspective, possibledefine another metric using definition Pareto optimality. point Paretooptimal(Brown & Smith, 2005)l(, ) =qXJi () = 0,qXi=1= 1,0,i=1is, possible identify ascent direction simultaneously improvesobjectives. consequence, Paretoascent direction l point Paretofrontier null. Formally, metric respects Paretooptimality definedfollows:qX= minq kl(, )k22 ,= 1, 0.Ri=1denote indicator IPN (Pareto norm indicator ). utopiabased metric,extent frontier taken account without constraint optimalsolution collapses single point frontier.5.2 Covering Metricsextension frontier primary concern, maximizing distanceantiutopia (pAU ) results metric grows frontier dimension. However,contrary utopia point, antiutopia located half spacereached solutions MOO problems. means consideringantiutopiabased metric maximization problem could become unbounded movingsolutions arbitrary far Pareto frontier antiutopia point. Thereforemeasure, denoted IAU (antiutopia indicator ), provide guaranteeaccuracy.201fiParisi, Pirotta, & Restelli5.3 Mixed Metricsmentioned indicators provide one desiderata. consequence,resulting approximate frontier might arbitrary far actual one. orderconsider desiderata mix previous concepts following indicator:= IAU ww penalization function, i.e., monotonic function decreasesaccuracy input increases, e.g., w = 1 IPN w = 1 IU . metrics, denotedrespectively I,PN I,U , take advantage expansive behavior antiutopiabased indicator accuracy optimalitybased indicator. waydesiderata met single scalar measure, also C l (l 1) differentiable.Another solution mix utopia antiutopiabased indicators different way.want solutions simultaneously far antiutopia close utopia,consider following metric (to maximized):= 1IAU2 ,IU1 2 free parameters.next section, show proposed mixed metrics effective drivingPMGA close Pareto frontier exact approximate scenarios. However,want make clear consistency guaranteed strongly dependsfree parameters , 1 2 . insights discussed Section 7.6. Experimentssection, evaluate algorithm two problems, Linear-Quadratic Gaussianregulator water reservoir control task. PMGA compared state-of-the-art methods(Peters, Mulling, & Altun, 2010; Castelletti et al., 2013; Parisi et al., 2014; Beume, Naujoks,& Emmerich, 2007) using hypervolume (Vamplew et al., 2011) extensionpreviously defined performance index (Pianosi, Castelletti, & Restelli, 2013), named loss,measuring distance approximate Pareto front reference one. 2objectiveproblems, hypervolume exactly computed. 3objective problems, given highcomputational complexity, hypervolume approximated MonteCarlo estimatepercentage points dominated frontier cube defined utopiaantiutopia points. estimate one million points used.}idea loss index compare true Pareto frontier FW = {JwwWspace weights W frontier JW = {Jbw }wW returned algorithmweights (Jw denotes discounted return new singleobjective MDP definedlinear combination objectives w). Formally loss function l definedl(JJw maxM JbwZJ, F, W, p) =wWJwp(dw),(7)p() probability density simplex W Jw = w J normalization factor, i-th component J difference best202fiMORL Continuous Pareto Manifold Approximationworst value i-th objective Pareto frontier, i.e., Ji = max(Ji ) min(Ji ).M.means that, weight, policy minimizes loss function chosen JWtrue Pareto frontier F known, reference one used.Since PMGA returns continuous frontiers two scores designed discreteones, evaluation frontiers discretized. Also, figures presentedsection show discretized frontiers order allow better representation. Besideshypervolume loss function, report also number solutions returnedalgorithm number rollouts (i.e., total number episodes simulatedlearning process). data collected simulation results averagedten trials6 . experiments, PMGA learning rate,(8)=L () 1 L ()positive definite, symmetric matrix userdefined parameter.stepsize rule comes formulation gradient ascent constrained problempredefined distance metric (Peters, 2007) underlies derivation naturalgradient approaches. However, since algorithm exploits vanilla gradient (i.e.,consider Euclidean space) metric identity matrix I.remainder section organized follows. start studying behaviormetrics proposed Section 5 effects parametrization (t) LQG.Subsequently, focus attention sample complexity, meant number rolloutsneeded approximate Pareto front. Finally, analyze quality algorithmwater reservoir control task, complex real world scenario, comparestate-of-the-art multiobjective techniques. case study, domains firstpresented results reported discussed.6.1 Linear-Quadratic Gaussian Regulator (LQG)first case study discrete-time Linear-Quadratic Gaussian regulator (LQG)multi-dimensional continuous state action spaces (Peters & Schaal, 2008b).LQG problem defined following dynamicsst+1 = Ast + Bat ,N (K st , )R(st , ) = st Qst Ratst n-dimensional column vectors, A, B, Q, R Rnn , Q symmetricsemidefinite matrix, R symmetric positive definite matrix. Dynamicscoupled, i.e., B identity matrices. policy Gaussian parameters= vec(K), K Rnn . Finally, constant covariance matrix = used.LQG easily extended account multiple conflicting objectives.particular, problem minimizing distance origin w.r.t. i-th axistaken account, considering cost action axesXRi (st , ) = s2t,ia2t,j .i6=j6. Source code available https://github.com/sparisi/mips.203fiParisi, Pirotta, & RestelliSince maximization i-th objective requires null action axes,objectives conflicting. reward formulation violates positiveness matrixRi , change adding sufficiently small -perturbationXXRi (st , ) = (1 ) s2t,i +a2t,js2t,j + a2t,i .i6=jj6=iparameters used experiments following: = 0.9, = 0.1 initialstate s0 = [10, 10]T s0 = [10, 10, 10]T 2 3objective case, respectively.following sections compare performance proposed metrics several settings.made use tables summarize results end set experiments.6.1.1 2objective Case ResultsLQG scenario particular instructive since terms involved definition returns, gradients Hessians computed exactly. therefore focus studyingdifferent policy manifold parametrizations (t) metrics I.Unconstrained Parametrization. domain problematic since definedcontrol actions range [1, 0] controls outside range lead divergencesystem. primary concern therefore related boundedness controlactions, leading following parametrization manifold policy space:(1 + exp(1 + 2 t))1,[0, 1].= (t) =(1 + exp(3 + 4 t))1Utopia antiutopia points [150, 150] [310, 310], respectively, metrics IAUIU normalized order 1 reference point.7 learning step parameterEquation (8) = 1.case, exploiting nonmixed metrics, PMGA able learn good approximation Pareto frontier terms accuracy covering. Using utopiabasedindicator, learned frontier collapses one point knee front.behavior occurs using IPN . Using antiutopia point reference point solutionsdominated approximate frontier gets wider, diverging true frontierexpanding opposite half space. behaviors surprising, consideringdefinition indicator functions, explained Section 5.contrary, shown Figure 2, mixed metrics able achieveaccuracy covering. starting 0 set [1, 2, 0, 3]T , algorithm alsoable learn even starting different random parameters. free metric parametersset = 1.5 I,PN , = 1 I,U 1 = 3, 2 = 1 .8 Althoughshown figure, I,U behaved similarly I,PN . notice casesfirst accuracy obtained pushing parametrization onto Pareto frontier,frontier expanded toward extrema order attain covering.7. Recall initially defined = kJ pk22 . slightly modify normalizing policyperformance w.r.t. reference point: = kJ/p 1k22 , / component-wise operator.8. Section 7 study sensitivity proposed metrics parameters .204fiMORL Continuous Pareto Manifold ApproximationTable 1: Summary 2dimensional LQG (unconstrained)MetricsNonmixedIssues:AccuracyCovering77IU , IPN : frontier collapses one pointIAU : diverging behavior dominated solutions found33MixedPartial solutionFinal approximationTrue Pareto frontier30025016L ()23J21002020050121end0150150200250300050J1100Iterations(a) Learning process mixed metric I,PN .3001525010L ()J21,000120050005end1501502002505003000J150100Iterations(b) Learning process mixed metric .Figure 2: Learning processes 2objective LQG without constraintparametrization. Numbers denote iteration, end denotes frontier obtainedterminal condition reached. left, approximated Pareto frontiers,right corresponding L (). Using I,PN (Figure (a)) (Figure (b)) approximated frontier overlaps true one. However, using , PMGA converges faster.205fiParisi, Pirotta, & RestelliConstrained Parametrization. alternative approach consists forcing policymanifold pass extreme points true front knowing parameterizations singleobjective optimal policies. general, requires additionaloptimizations collection additional trajectories must accountedresults. However, extreme points required set utopia antiutopia. Moreover, case optimal singleobjective policies available literature.reasons, count additional samples report total number rollouts.Using constrained parameterization, two improvements easily obtained. First,number free parameters decreases and, consequence, learning processsimplified. Second, approximate frontier forced sufficiently large areacover extrema. Thus, problem covering shown nonmixed indicatorsalleviated or, cases, completely eliminated. 2dimensional LQG,parametrization forced pass extrema frontier following:(1 + exp(2.18708 1 t2 + (3.33837 + 1 )t))1= (t) =,[0, 1].(1 + exp(1.15129 2 t2 + (3.33837 + 2 )t))1initial parameter vector 0 = [2, 2]T . constraint able correct divergingbehavior IU IPN , returned accurate wide approximation Paretofrontier, shown Figure 2a. also notice much faster convergence, since algorithm required learn fewer parameters (two instead four). However, IAU still showsdiverging behavior initial parameters 0 (in Figure 2b, 0 = [6, 6]T ).contrary, solutions obtained metrics independent initial 0 ,algorithm converges close true frontier even starting parametrizationgenerating initial frontier far away true one.6.1.2 3objective Case ResultsUnconstrained Parametrization.(1 + exp(1 + 2 t1 + 3 t2 ))1= (t) = (1 + exp(4 + 5 t1 + 6 t2 ))1 ,(1 + exp(7 + 8 t1 + 9 t2 ))1simplex([0, 1]2 ).Utopia antiutopia points [195, 195, 195] [360, 360, 360], respectively, metricsIAU , IU normalized. initial parameters drawn uniform distribution 0U nif ((0, 0.001)) (0 = 0 causes numerical issues) learning rate parameter = 1.2objective scenario, frontiers learned IU IPN collapse singlepoint, IAU divergent trend (Figure 3a). However, unlike 2objective LQR,I,PN also failed correctly approximate Pareto frontier. reason tuningdifficult, given difference magnitude IPN IAU contrary,I,U = 1.5 1 = 3, 2 = 1 returned high quality approximate frontier.latter shown Figure 3b. Although small areas true Pareto frontiercovered approximate one, stress fact policies foundParetooptimal. strength metrics found normalizationutopia antiutopiabased indicators. expedient, indeed, allows easier tuningfree metric parameters, magnitude single components similar.insights tuning mixed metrics parameters discussed Section 7.206fiMORL Continuous Pareto Manifold ApproximationTable 2: Summary 2dimensional LQG (constrained)MetricsNonmixed: IU , IPNNonmixed: IAUIssues:MixedAccuracyCovering3377IAU : diverging behavior dominated solutions found33Partial solutionFinal approximationTrue Pareto frontier3001120L ()J225022003130end15015020025014030005J110152025100120Iterations(a) Learning process utopiabased metric IU .30023250600J27200L ()3140020015001502002503000J120406080Iterations(b) Learning process antiutopiabased metric IAU .Figure 3: Learning process 2objective LQG parametrization forced passextreme points frontier. constraints able correct behaviorIU (Figure (a)) convergence faster previous parametrization. However,IAU still diverges (Figure (b)) returned frontier includes dominated solutions, sincemetric considers covering frontier accuracy.207fiParisi, Pirotta, & RestelliTable 3: Summary 3dimensional LQG (unconstrained)MetricsNonmixedIssues:AccuracyCovering77IU , IPN : frontier collapses one pointIAU : diverging behavior dominated solutions found77I,PN : difficult tuning33Mixed: I,PNIssues:Mixed: I,U ,True Pareto frontierApproximate frontierJ31,0005005005001,000J11,0005001,000500J1J21,000J2(a) Frontier approximated antiutopiabased metric IAU .J3True Pareto frontierApproximate frontier300350200300200200200J2300300J1250250300200J1J2350(b) Frontier approximated mixed metric .Figure 4: Resulting frontiers 3objective LQG using unconstrained parametrization. Frontiers discretized better representation. IAU learningdiverges (Figure (a)) correctly approximates Pareto frontier (Figure (b)).208fiMORL Continuous Pareto Manifold ApproximationConstrained Parametrization.(1 + exp(a + 1 t1 (b 2 )t2 1 t21 2 t22 3 t2 t1 ))1,(1 + exp(a (b 4 )t1 + 5 t2 4 t21 5 t22 6 t1 t2 ))1= (t) =221(1 + exp(c + (7 + b)t1 + (8 + b)t2 7 t1 8 t2 9 t1 t2 ))= 1.151035476,b = 3.338299811,simplex([0, 1]2 ).c = 2.187264336,initial parameters 0 = 0. Numerical results reported Table 4,hypervolume computed normalizing objective w.r.t. antiutopia. Figure 5shows frontiers obtained using utopia antiutopiabased indicators. clearlysee that, unlike 2objective case, even constrained parametrization metricslead poor solutions, failing providing MO desiderata. Figure 5a, using IUfrontier still tends collapse towards center true one, order minimizedistance utopia point (only constraint prevents that). Although shownfigures, similar slightly broader frontier returned using IPN . However,stress solutions belong Pareto frontier, i.e., nondominated solutionsfound. Figure 5b shows frontier obtained IAU . expected, algorithm triesproduce frontier wide possible, order increase distance antiutopiapoint. behavior leads dominated solutions learning process diverges.contrary, using mixed metrics I,PN ( = 30), I,U ( = 1.4) (1 =2.5, 2 = 1) PMGA able completely accurately cover Pareto frontier, shownFigures 6a 6b. worth notice different magnitude free parameterI,PN compared 2objective case, 1.5. already discussed, duesubstantial difference magnitude IAU IPN . contrary, tuningmixed metrics easier, similar parameters used unconstrainedparametrization proved effective. come back topic Section 7.Finally, shown Table 4, I,U achieve best numerical results, firstattains highest hypervolume lowest loss, latter attains fastestconvergence. superiority also resides easy differentiability tuning, especially compared I,PN . reasons, chosen empirical analysissample complexity comparison state-of-the-art algorithmsreal-world MO problem, discussed next sections.Table 4: Performance comparison different metrics 3objective LQGconstrained parametrization. reference frontier hypervolume 0.7297.MetricHypervolumeLoss#IterationsIU0.62522.9012e-0259IAU0IPN0.71671.9012e-02133I,PN0.71875.2720e-0447I,U0.72124.9656e-04330.72045.0679e-0415209fiParisi, Pirotta, & RestelliTable 5: Summary 3dimensional LQG (constrained)MetricsNonmixedIssues:MixedAccuracyCovering77IU , IPN : frontier collapses one pointIAU : diverging behavior dominated solutions found33J3True Pareto frontierApproximate frontier300350200300200200200J2300300J1250250300200J1J2350(a) Frontier approximated utopiabased metric IU .J3True Pareto frontierApproximate frontier500200350250300200200300J2J1300250300J2350J1200(b) Frontier approximated antiutopiabased metric IAU .Figure 5: Results parametrization forced pass extreme pointsfrontier. Using IU (Figure (a)) frontier shrinks much allowed parametrization. constraint therefore able solve issues metric 2objective scenario. contrary, using IAU frontier gets wider divergestrue one (in Figure (b) intermediate frontier shown).210fiMORL Continuous Pareto Manifold ApproximationJ3True Pareto frontierApproximate frontier3003200200200J23003000.40.60.8J10.40.80.61(a) Frontier objectives space.0.40.620.8(b) Frontier policy parameters space.Figure 6: Results using constrained parametrization. shown Figure (a),approximate frontier perfectly overlaps true one, despite small discrepanciespolicy parameters space learned parameters optimal ones (Figure (b)).Similar frontiers obtainable I,PN I,U .6.1.3 Empirical Sample Complexity Analysissection, provide empirical analysis sample complexity PMGA, meantnumber rollouts needed approximate Pareto frontier. goal identifyrelevant parameter estimate MDP terms J(), J() HJ().analysis performed 2dimensional LQG domain varying numberpolicies used estimate integral per iteration PMGA number episodespolicy evaluation. steps episode fixed 50. first usedparametrization forced pass extreme points frontier 0 = [3, 7]T ,produces initial approximate frontier far true one. parameterlearning rate Equation (8) set = 0.5 parameter I,U set= 1. performance criterion, choose total number rollouts required reachloss smaller 5 104 hypervolume larger 99.5% reference one.criteria also used conditions convergence (both satisfied).evaluation, MDP terms computed closed form. terminal condition mustreached 100, 000 episodes otherwise algorithm forced end. symbol usedrepresent latter case.Table 6a results relevant parameter number episodesused estimate MDP terms. parameter controls variance estimate,i.e., accuracy estimate L (). increasing number episodes,estimation process less prone generate misleading directions, happens, instance,oneepisode case parameters move towards wrong direction. contrary,number points used estimate integral (denoted table #t) seemssignificant impact final performance algorithm, influencesnumber model evaluations needed reach prescribed accuracy. best behavior,211fiParisi, Pirotta, & RestelliTable 6: Total number episodes needed converge varying number points #tapproximate integral number episodes #ep per point. symbolused terminal condition reached.(a) parametrization constrained pass extreme points frontier, onepoint sufficient move whole frontier towards right direction.#ep151025501695 578560 1721, 850 7571, 790 67352, 550 1, 5093, 440 2, 0605, 175 3, 4328, 250 2, 479104, 780 4, 6236, 820 3, 08310, 500 3, 36511, 800 1, 503257, 525 2, 98015, 100 9, 50018, 375 6, 02824, 250 7, 097508, 700 5, 71918, 000 6, 97826, 750 7, 48350, 000 1, 474#t(b) contrary, using unconstrained parametrization, PMGA needs sufficient numberepisodes enough points correct update step.#ep151025501529, 350 7, 3101044, 100 9, 46664, 500 1, 3592560, 500 1, 00083, 500 8, 9235047, 875 18, 55884, 250 1, 457#tsamplebased perspective, obtained exploiting one pointintegral estimate. Although surprising, simple explanation exists. forcingparameterization pass singleobjective optima, correct estimationgradient direction single point enough move entire frontier towardtrue one, i.e., move parameters towards optimal ones.contrary, unconstrained parametrization used, one point sufficientanymore, shown Table 6b. case, initial parameter vector set 0 =[1, 1, 0, 0]T , learning rate parameter = 0.1 terminal condition requiresfrontier loss smaller 103 hypervolume larger 99% referencefrontier. Without constraint, algorithm needs accuracy evaluationsingle points i.e., sufficient number episodes enough points move wholefrontier towards right direction. accuracy gradient estimate L () thereforedepends number points number episodes, PMGA requiresmuch rollouts converge. best behavior, samplebased perspective,obtained exploiting five points integral estimate 50 episodespolicy evaluation.212fiMORL Continuous Pareto Manifold Approximation6.2 Water Reservoirwater reservoir modeled MOMDP continuous state variable representing water volume stored reservoir, continuous action controllingwater release, state-transition model depending also stochastic reservoir inflow ,set conflicting objectives. domain proposed Pianosi et al. (2013).Formally, state-transition function described mass balance equationst+1 = st + t+1 max(at , min(at , )) st reservoir storage time t; t+1reservoir inflow time + 1, generated white noise normal distributiont+1 N (40, 100); release decision; minimum maximumreleases associated storage st according relations = st = max(st 100, 0).work consider three objectives: flooding along lake shores, irrigationsupply hydro-power supply. immediate rewards definedR1 (st , , st+1 ) = max(ht+1 h, 0),R2 (st , , st+1 ) = max( , 0),R3 (st , , st+1 ) = max(e et+1 , 0),ht+1 = st+1 /S reservoir level (in following experiments = 1), hflooding threshold (h = 50), = max(at , min(at , )) release reservoir,water demand ( = 50), e electricity demand (e = 4.36) et+1 electricityproductionet+1 = g H2 0 ht+1 ,= 106 /3.6 dimensional conversion coefficient, g = 9.81 gravitationalacceleration, = 1 turbine efficiency H2 0 = 1, 000 water density. R1 denotesnegative cost due flooding excess level, R2 negative deficitwater supply R3 negative deficit hydro-power production.Like original work, discount factor set 1 objectivesinitial state drawn finite set. However, different settings used learningevaluation phases. Given intrinsic stochasticity problem, policiesevaluated 1,000 episodes 100 steps, learning phase requires differentnumber episodes 30 steps, depending algorithm. discuss detailsresults section.Since problem continuous exploit Gaussian policy model(a|s, ) = N + (s)T , 2 ,: Rd basis functions, = || = {, , }. optimal policiesobjectives linear state variable, use radial basis approximation(s) = eksci k2wi.used four centers ci uniformly placed interval [20, 190] widths wi 60,total six policy parameters.213fiParisi, Pirotta, & Restelli6.2.1 Resultsevaluate effectiveness algorithm analyzed performancefrontiers found weighted sum Stochastic Dynamic Programming (Pianosi et al., 2013),Multi-objective FQI (Pianosi et al., 2013), episodic version Relative Entropy PolicySearch (Peters et al., 2010; Deisenroth et al., 2013), SMS-EMOA (Beume et al., 2007),two recent policy gradient approaches, i.e., Radial Algorithm ParetoFollowingAlgorithm (Parisi et al., 2014). Since optimal Pareto front available, onefound SDP chosen reference one loss computation. MOFQI learnsdeterministic policies (i.e., standard deviation Gaussian set zero)trained using 10, 000 samples dataset 50, 000 tuples 2objectiveproblem 20, 000 samples dataset 500, 000 tuples 3objective problem.remaining competing algorithms learn stochastic policies. number episodesrequired policy update step 25 REPS, 100 PFA RA, 50 SMS-EMOA.Given episodic formulation, REPS draws parameters upper distribution(|) = N (, ) ,diagonal covariance matrix, set zero. However, since algorithmlearns parameters = {, }, overall learned policy still stochastic. SMS-EMOAmaximum population size 100 500 2 3objective case, respectively.crossover uniform mutation, chance 80% occur, adds whitenoise random chromosomes. iteration, top 10% individuals keptnext generation guarantee solution quality decrease. Finally, MOFQIscalarizes objectives using weights SDP, i.e., 11 25 weights 23objective case, respectively. REPS uses instead 50 500 linearly spaced weights. RAalso follows 50 500 linearly spaced directions and, along PFA, exploits naturalgradient (Peters & Schaal, 2008a) adaptive learning step Equation (8), = 4= F , F Fisher information matrix. Concerning parametrizationPMGA, used complete first degree polynomial 2objective case66 1 t2 + (1 16)t105 2 t2 + (2 + 20)t18 3 t2 + (3 16)t,[0, 1].= (t) =223 4 + (4 + 53)t39 5 t2 + (5 + 121)t0.01 6 t2 + (6 + 0.1)tSimilarly, 3objective case complete second degree polynomial used36 + (15 1 )t2 + (1 + 1)t1 t2 + 30t21 + (1 1)t2257 (27 + 2 )t2 + (2 + 1)t1 t2 48t21 + (2 1)t2213 + (7 23 )t1 + (3 + 1)t1 t2 + (23 2)t21 11t222= (t) =30 + (9 24 )t1 + (4 + 1)t1 t2 + (24 2)t2 + 60t2 , simplex([0, 1] ).12104 + (57 5 )t2 + (5 + 1)t1 t2 65t2 + (5 1)t210.05 + (1 6 )t2 + (6 + 1)t1 t2 + (6 1)t222parameterizations forced pass near extreme points Pareto frontier,computed singleobjective policy search. cases starting parameter214fiMORL Continuous Pareto Manifold Approximation1039.5L ()J2 (Water Demand)01210SDPPMGA(0 )PMGA(end )10.51111.550100 150 200Iterations2504(a)3.532.5 2 1.5J1 (Flooding)1(b)Figure 7: Results 2objective water reservoir. Even starting arbitrary poorinitial parametrization, PMGA able approach true Pareto frontier (Figure (b)).Figure (a), trend manifold metric L () averaged ten trials.vector 0 = [0, 0, 0, 0, 0, 50]T . last parameter set 50 order guaranteegeneration sufficiently explorative policies, 6 responsible varianceGaussian distribution. However, fair comparison, also competing algorithmstake advantage information, mean initial policies calculated accordingly behavior optimal ones described Castelletti et al. (2012), i.e.,= [50, 50, 0, 0, 50]T . initial standard deviation set = 20 guarantee sufficient exploration. parametrization avoids completely random poor quality initialpolicies. Utopia antiutopia points set [0.5, 9] [2.5, 11] 2objective case, [0.5, 9, 0.001] [65, 12, 0.7] 3objective one.According results presented Section 6.1.3, integral estimate PMGAperformed using MonteCarlo algorithm fed one random point. instance variable t, 50 trajectories 30 steps used estimate gradientHessian policy. Regarding learning rate, adaptive one described Equation (8) used = 2. evaluation, 1,000 2,000 points usedintegral estimate 2 3objective case, respectively. already discussed, givenresults obtained LQG problem order show capability approximate algorithm, decided consider indicator (1 = 1 2 = 1).main reasons efficiency (in Table 4 attained fastest convergence)easy differentiability. Finally, recall results averaged ten trials.Figure 7b reports initial final frontiers first two objectivesconsidered. Even starting far true Pareto frontier, PMGA able approachit, increasing covering accuracy approximate frontier. Also, shown Figure 7a, despite low number exploited samples, algorithm presents almostmonotonic trend learning process, converges iterations.215fiParisi, Pirotta, & RestelliJ2 (Water Demand)9.51010.5SDPPFARAMOFQIREPSSMS-EMOAPMGA2.62.42.221.81.6J1 (Flooding)1.41.210.8Figure 8: Visual comparison 2objective water reservoir. PMGA frontier comparable ones obtained state-of-the-art algorithms terms accuracy covering.However, continuous one, others scattered.Table 7: Numerical algorithm comparison 2objective water reservoir. SDPreference frontier hypervolume 0.0721 nine solutions.AlgorithmHypervolumeLoss#Rollouts#Solutions0.0620 0.00100.0772 0.004516, 250 1, 072PFA0.0601 0.00120.0861 0.008327, 761 4, 84951.1 10.9RA0.0480 0.00050.1214 0.004359, 253 3, 54216.1 2.9-0.1870 0.009010, 000-REPS0.0540 0.00090.1181 0.003037, 525 2, 23517.0 4.1SMS-EMOA0.0581 0.00220.0884 0.0019149, 825 35, 46014.2 2.4PMGAMOFQIFigure 8 offers visual comparison Pareto points Tables 7 8 reportnumerical evaluation, including hypervolume loss achieved algorithmsw.r.t. SDP approximation9 . PMGA attains best performance 2 3objective cases, followed PFA. SMS-EMOA also returns good approximation,slowest, requiring ten times amount samples used PMGA. MOFQIoutperforms PMGA sample complexity, loss highest. Finally, Figure 9shows hypervolume trend PMGA comparison sample complexity2objective case. PMGA substantially sample efficient algorithms,attaining larger hypervolume much fewer rollouts. example, capablegenerating frontier hypervolume RA one tenth rollouts,outperforms PFA half samples needed latter.9. Results regarding MOFQI include loss number rollouts hypervolumenumber solutions available original paper.216fiMORL Continuous Pareto Manifold Approximation0.065PMGAPFA (27,761)SMS-EMOA (149,825)Hypervolume0.06REPS (37,525)0.055RA (59,253)0.050.0450.042,0004,0006,0008,00010,00012,00014,00016,000#RolloutsFigure 9: Comparison sample complexity 2objective case using hypervolumeevaluation score. brackets number rollouts needed algorithm producebest frontier. PMGA clearly outperforms competing algorithms, requiresmuch fewer samples generate frontiers better hypervolume.Table 8: Numerical algorithm comparison 3objective water reservoir. SDPreference frontier hypervolume 0.7192 25 solutions.AlgorithmHypervolumeLoss#Rollouts#Solutions0.6701 0.00360.0116 0.002262, 640 7, 963PFA0.6521 0.00290.0210 0.0012343, 742 12, 749595 32.3RA0.6510 0.00470.0207 0.0016626, 441 35, 852137.3 25.4-0.0540 0.006120, 000-REPS0.6139 0.00030.0235 0.0014187, 565 8, 64286 9.7SMS-EMOA0.6534 0.00070.0235 0.0020507, 211 56, 823355.6 13.9PMGAMOFQI7. Metrics Tuningsection want examine deeply tuning mixed metric parameters,order provide reader better insights correct use metrics. performance PMGA strongly depends indicator used and, thereby, configurationcritical. precise, mixed metrics, obtained best approximate Paretofrontiers experiments conducted Section 6, include trade-off accuracycovering, expressed parameters. following, analyze fundamentalconcepts behind metrics study performance influenced changesparameters.217fiParisi, Pirotta, & RestelliApproximate frontier1,000True Pareto frontier300300250250200200500150500(a) = 11,000150150200250300(b) = 1.5150200250300(c) = 2Figure 10: Approximate frontiers 2objective LQG learned PMGA using I,PNvarying . Figure (a) indicator penalize enough dominated solutions,Figure (c) frontier wide enough. contrary, Figure (b)algorithm achieves accuracy covering.7.1 Tuningfirst indicator (to maximized) analyze= IAU w,w penalization term. previous sections proposed w = 1 IPNw = 1 IU , order take advantage expansive behavior antiutopiabasedindicator accuracy optimalitybased indicator. section studyperformance mixed metric changing , proposing simple tuning process.idea set initial value increase (or decrease) approximatefrontier contains dominated solutions (or wide enough). Figure 10 shows differentapproximate frontiers obtained different values exact 2objective LQG50 iterations using w = 1 IPN . Starting = 1 indicator behaves mostlylike IAU , meaning small (Figure 10a). Increasing 2 (Figure 10c)algorithm converges, approximate frontier completely cover true one,i.e., IPN mostly condition behavior metric. Finally, = 1.5 (Figure 10b)approximate frontier perfectly matches true one metric correctly mixes twosingle indicators.However, already discussed Section 6, use w = 1 IPN problematicdifference magnitude IAU IPN make tuning hardpoint metric becomes ineffective. drawback solved using w = 1 IUnormalizing reference point indicators (i.e., IU IAU ) I(J, p) = kJ/p 1k22 ,normalization bounds utopia antiutopiabased metrics similar intervals,i.e., (0, ) [0, ), respectively.1010. ratio two vectors a/b component-wise operation.218fiMORL Continuous Pareto Manifold ApproximationJ2J2U110J1AU1(a)J2UJ1AU1(b)U1J1AU1(c)Figure 11: Examples Pareto frontiers. Figures (a) (b) frontiers convex,latter objectives normalized. Figure (c) frontier concave.7.2 Tuningsecond mixed indicator (to maximized) also takes advantage expansive behavior antiutopiabased indicator accuracy utopiabased one.definedIAU= 12 ,IU1 2 free parameters.better understand insights guided metric definition, considerdifferent scenarios according shape Pareto frontier. Figure 11a frontierconvex normalized objectives. case point closerantiutopia utopia is, sure, dominated solution. ratio IAU /IUpoint frontier always greater 1 hence reasonable set 12 1. Therefore, need know exactly antiutopia pointdrawback antiutopiabased metric IAU disappears, since also take accountdistance utopia point. Nevertheless, setting points critical,magnitude strongly affect PMGA performance. example shown Figure 11b,frontier normalized objectives different magnitude.case, setting 1 2 1, indicator evaluated extrema frontier(J1 = [1, 0]T J2 = [0, 10]T ) equal 0.99 99, respectively. first valuenegative, approximate frontier includes points true Pareto frontier,J1 would perform better true Pareto frontier.contrary, frontier concave (Figure 11c) true pointcloser antiutopia utopia dominated solution, ratio IAU /IUpoint frontier (with exception, eventually, ends) alwayssmaller one. Keeping 1 = 1 2 = 1, PMGA would try collapse frontiersingle point, order maximize indicator. Therefore, parameters needchanged accordingly trial-and-error. instance, returned frontierachieve accuracy, possible solution decrease 1 increase 2 .219fiParisi, Pirotta, & Restelli8. Conclusionpaper proposed novel gradientbased approach, namely ParetoManifoldGradient Algorithm (PMGA), learn continuous approximation Pareto frontierMOMDPs. idea define parametric function describes manifoldpolicy parameters space, maps manifold objectives space. Given metricmeasuring quality manifold objectives space (i.e., candidate frontier),shown compute (and estimate trajectory samples) gradient w.r.t.parameters . Updating parameters along gradient direction generates newpolicy manifold associated improved (w.r.t. chosen metric) continuous frontierobjectives space. Although provided derivation independentparametric function metric used measure quality candidate solutions,terms strongly influence final result. Regarding former, achievedhigh quality results forcing parameterization pass singleobjectiveoptima. However, trick might require domain expertise additional samplestherefore could always applicable. Regarding latter, presented differentalternative metrics, examined pros cons one, shown propertiesempirical analysis discussed general tuning process promising ones.evaluation also included sample complexity analysis investigate performancePMGA, comparison state-of-the-art algorithms MORL. results,approach outperforms competing algorithms quality frontier samplecomplexity. would interesting study properties theoretical perspectiveorder provide support empirical evidence. leave open problemsinvestigation convergence rate approximation error true Paretofrontier. However, think hard provide analysis general setting.Future research address study metrics parametric functionsproduce good results general case. particular, investigate problemsmany objectives (i.e., three) highdimensional policies. Since complexity manifold parameterization grows number objectives policyparameters, polynomial parameterization could effective complex problems alternative parameterizations found. Another interesting directionresearch concerns importance sampling techniques reducing sample complexitygradient estimate. Since frontier composed continuum policies, likelytrajectory generated specific policy partially used also estimationquantities related similar policies, thus decreasing number samples neededMonteCarlo estimate integral. Moreover, would interesting investigate automatic techniques tuning metric parameters applicabilityPMGA multi-agent scenario (e.g., Roijers, Whiteson, & Oliehoek, 2015).220fiMORL Continuous Pareto Manifold ApproximationAppendix A. Optimal BaselineTheorem A.1 (Componentdependent baseline). optimal baseline (i, j)-component(i,j)Hessian estimate HRF, JD () given Equation (6)(i,j)bH,2(i,j)G ( )E R( )=2(i,j)E G ( ),(i,j)G(i,j)( ) = ln p ( |) j ln p ( |) + Hln p ( |) .Given baseline b, variance reduction obtained optimal baseline bH,Var (HRF, JD (, b)) Var (HRF, J (, bH, )) =(i,j) 2(i,j)2bbH,(i,j)EG ( ).N(i,j)Proof. Let G( ) (i, j)-th component G ( )(i,j)G(i,j)( ) = ln p ( |) j ln p ( |) + Hln p ( |) .(i,j)variance HRF, JD () given by11Var(i,j)HRF, JDi222 h(i,j)(i,j)(i,j)G ( )E R( ) b(i,j) G ( )() = E R( ) b22(i,j)(i,j)2(i,j) 2+E bG ( )= E R( ) G ( )2hi2(i,j)(i,j)2b(i,j) E R( ) G ( )E R( )G ( ).Minimizing previous equation w.r.t. b(i,j) get(i,j)bH,2(i,j)E R( ) G ( )=2 .(i,j)E G ( )11. use compact notation E [] denote E [].221fiParisi, Pirotta, & Restelliexcess variance given(i,j)(i,j)(i,j)Var G ( )(R( ) b(i,j) ) Var G ( )(R( ) bH, )2222(i,j)(i,j)(i,j)(i,j)(i,j)22bE R( ) G ( )+E bG ( )= E R( ) G ( )h22i2(i,j)(i,j) 2(i,j)(i,j)2E bH,E R( )G ( )E R( ) G ( )G ( )2 hi2(i,j)(i,j)(i,j)+ E R( )G ( )+ 2bH, E R( ) G ( )222(i,j)(i,j)(i,j)(i,j)= bE G ( )2bE R( ) G ( )222(i,j)(i,j)(i,j)(i,j)bH, E G ( )+ 2bH, E R( ) G ( )222(i,j)(i,j)(i,j)2(i,j)E G ( )2bE R( ) G ( )= b2 2(i,j)2E R( ) G ( )(i,j)G ( )2 E(i,j)E G ( )2(i,j)2E R( ) G ( )(i,j)2R( ) G ( )+ 22E(i,j)E G ( )222(i,j)(i,j)(i,j)(i,j)2bE R( ) G ( )E G ( )= b2 2(i,j)E R( ) G ( )+2(i,j)E G ( )2(i,j)G ( )E R( )(i,j) 2(i,j)= b2b2(i,j)E G ( )E(i,j)= b(i,j)G( )2(i,j) 2bH, E2(i,j)G ( ).2222 2(i,j)E R( ) G ( )+2(i,j)E G ( )fiMORL Continuous Pareto Manifold ApproximationReferencesAhmadzadeh, S., Kormushev, P., & Caldwell, D. (2014). Multi-objective reinforcementlearning auv thruster failure recovery. Adaptive Dynamic ProgrammingReinforcement Learning (ADPRL), 2014 IEEE Symposium on, pp. 18.Athan, T. W., & Papalambros, P. Y. (1996). note weighted criteria methods compromise solutions multi-objective optimization. Engineering Optimization, 27 (2),155176.Barrett, L., & Narayanan, S. (2008). Learning optimal policies multiple criteria.Proceedings 25th International Conference Machine Learning, ICML 08,pp. 4147, New York, NY, USA. ACM.Bertsekas, D. P. (2005). Dynamic programming suboptimal control: surveyADP MPC*. European Journal Control, 11 (4-5), 310 334.Beume, N., Naujoks, B., & Emmerich, M. (2007). Sms-emoa: Multiobjective selection baseddominated hypervolume. European Journal Operational Research, 181 (3), 16531669.Brown, M., & Smith, R. E. (2005). Directed multi-objective optimization. InternationalJournal Computers, Systems, Signals, 6 (1), 317.Calandra, R., Peters, J., & Deisenrothy, M. (2014). Pareto front modeling sensitivityanalysis multi-objective bayesian optimization. NIPS Workshop BayesianOptimization, Vol. 5.Castelletti, A., Corani, G., Rizzolli, A., Soncinie-Sessa, R., & Weber, E. (2002). Reinforcement learning operational management water system. IFAC WorkshopModeling Control Environmental Issues, Keio University, Yokohama, Japan,pp. 325330.Castelletti, A., Pianosi, F., & Restelli, M. (2012). Tree-based fitted q-iteration multiobjective markov decision problems. Neural Networks (IJCNN), 2012 International Joint Conference on, pp. 18.Castelletti, A., Pianosi, F., & Restelli, M. (2013). multiobjective reinforcement learningapproach water resources systems operation: Pareto frontier approximationsingle run. Water Resources Research, 49 (6), 34763486.Crites, R. H., & Barto, A. G. (1998). Elevator group control using multiple reinforcementlearning agents. Machine Learning, 33 (2-3), 235262.Das, I., & Dennis, J. (1997). closer look drawbacks minimizing weighted sumsobjectives pareto set generation multicriteria optimization problems. Structuraloptimization, 14 (1), 6369.Das, I., & Dennis, J. E. (1998). Normal-boundary intersection: new method generatingpareto surface nonlinear multicriteria optimization problems. SIAM JournalOptimization, 8 (3), 631657.Deisenroth, M. P., Neumann, G., & Peters, J. (2013). survey policy search robotics.Foundations Trends Robotics, 2 (1-2), 1142.223fiParisi, Pirotta, & RestelliFonteneau, R., & Prashanth, L. A. (2014). Simultaneous perturbation algorithms batchoff-policy search. 53rd IEEE Conference Decision Control, CDC 2014, LosAngeles, CA, USA, December 15-17, 2014, pp. 26222627. IEEE.Friedrich, T., Horoba, C., & Neumann, F. (2009). Multiplicative approximationshypervolume indicator. Proceedings 11th Annual Conference GeneticEvolutionary Computation, GECCO 09, pp. 571578, New York, NY, USA. ACM.Furmston, T., & Barber, D. (2012). unifying perspective parametric policy searchmethods markov decision processes. Pereira, F., Burges, C., Bottou, L., &Weinberger, K. (Eds.), Advances Neural Information Processing Systems 25, pp.27172725. Curran Associates, Inc.Gabor, Z., Kalmar, Z., & Szepesvari, C. (1998). Multi-criteria reinforcement learning.Shavlik, J. W. (Ed.), Proceedings Fifteenth International ConferenceMachine Learning (ICML 1998), Madison, Wisconsin, USA, July 24-27, 1998, pp.197205. Morgan Kaufmann.Greensmith, E., Bartlett, P. L., & Baxter, J. (2004). Variance reduction techniquesgradient estimates reinforcement learning. Journal Machine Learning Research,5, 14711530.Harada, K., Sakuma, J., & Kobayashi, S. (2006). Local search multiobjective functionoptimization: Pareto descent method. Proceedings 8th Annual ConferenceGenetic Evolutionary Computation, GECCO 06, pp. 659666, New York, NY,USA. ACM.Harada, K., Sakuma, J., Kobayashi, S., & Ono, I. (2007). Uniform sampling local paretooptimal solution curves pareto path following applications multi-objectiveGA. Lipson, H. (Ed.), Genetic Evolutionary Computation Conference, GECCO2007, Proceedings, London, England, UK, July 7-11, 2007, pp. 813820. ACM.Kakade, S. (2001). Optimizing average reward using discounted rewards. Helmbold, D. P.,& Williamson, R. C. (Eds.), Computational Learning Theory, 14th Annual ConferenceComputational Learning Theory, COLT 2001 5th European ConferenceComputational Learning Theory, EuroCOLT 2001, Amsterdam, Netherlands, July16-19, 2001, Proceedings, Vol. 2111 Lecture Notes Computer Science, pp. 605615. Springer.Koski, J., & Silvennoinen, R. (1987). Norm methods partial weighting multicriterion optimization structures. International Journal Numerical MethodsEngineering, 24 (6), 11011121.Lizotte, D. J., Bowling, M., & Murphy, S. A. (2012). Linear fitted-q iteration multiplereward functions. Journal Machine Learning Research, 13, 32533295.Lizotte, D. J., Bowling, M. H., & Murphy, S. A. (2010). Efficient reinforcement learningmultiple reward functions randomized controlled trial analysis. Furnkranz, J.,& Joachims, T. (Eds.), Proceedings 27th International Conference MachineLearning (ICML-10), June 21-24, 2010, Haifa, Israel, pp. 695702. Omnipress.224fiMORL Continuous Pareto Manifold ApproximationMagnus, J. R., & Neudecker, H. (1999). Matrix Differential Calculus ApplicationsStatistics Econometrics. Wiley Ser. Probab. Statist.: Texts ReferencesSection. Wiley.Mannor, S., & Shimkin, N. (2002). steering approach multi-criteria reinforcementlearning. Dietterich, T., Becker, S., & Ghahramani, Z. (Eds.), Advances NeuralInformation Processing Systems 14, pp. 15631570. MIT Press.Mannor, S., & Shimkin, N. (2004). geometric approach multi-criterion reinforcementlearning. J. Mach. Learn. Res., 5, 325360.Messac, A., & Ismail-Yahaya, A. (2002). Multiobjective robust design using physical programming. Structural Multidisciplinary Optimization, 23 (5), 357371.Messac, A., Ismail-Yahaya, A., & Mattson, C. A. (2003). normalized normal constraint method generating pareto frontier. Structural multidisciplinaryoptimization, 25 (2), 8698.Munkres, J. R. (1997). Analysis Manifolds. Adv. Books Classics Series. Westview Press.Natarajan, S., & Tadepalli, P. (2005). Dynamic preferences multi-criteria reinforcementlearning. Raedt, L. D., & Wrobel, S. (Eds.), Machine Learning, ProceedingsTwenty-Second International Conference (ICML 2005), Bonn, Germany, August7-11, 2005, Vol. 119 ACM International Conference Proceeding Series, pp. 601608.ACM.Nojima, Y., Kojima, F., & Kubota, N. (2003). Local episode-based learning multiobjective behavior coordination mobile robot dynamic environments. FuzzySystems, 2003. FUZZ 03. 12th IEEE International Conference on, Vol. 1, pp.307312 vol.1.Okabe, T., Jin, Y., & Sendhoff, B. (2003). critical survey performance indicesmulti-objective optimisation. Evolutionary Computation, 2003. CEC 03. 2003Congress on, Vol. 2, pp. 878885 Vol.2.Parisi, S., Pirotta, M., Smacchia, N., Bascetta, L., & Restelli, M. (2014). Policy gradientapproaches multi-objective sequential decision making. 2014 International JointConference Neural Networks, IJCNN 2014, Beijing, China, July 6-11, 2014, pp.23232330. IEEE.Perny, P., & Weng, P. (2010). finding compromise solutions multiobjective markovdecision processes. Coelho, H., Studer, R., & Wooldridge, M. (Eds.), ECAI 2010 19th European Conference Artificial Intelligence, Lisbon, Portugal, August 16-20,2010, Proceedings, Vol. 215 Frontiers Artificial Intelligence Applications, pp.969970. IOS Press.Peters, J. (2007). Machine Learning Motor Skills Robotics. Ph.D. thesis, UniversitySouthern California.Peters, J., Mulling, K., & Altun, Y. (2010). Relative entropy policy search. Fox, M.,& Poole, D. (Eds.), Proceedings Twenty-Fourth AAAI Conference ArtificialIntelligence (AAAI 2010), pp. 16071612. AAAI Press.225fiParisi, Pirotta, & RestelliPeters, J., & Schaal, S. (2008a). Natural actor-critic. Neurocomputing, 71 (7-9), 1180 1190.Progress Modeling, Theory, Application Computational Intelligenc 15thEuropean Symposium Artificial Neural Networks 2007 15th European SymposiumArtificial Neural Networks 2007.Peters, J., & Schaal, S. (2008b). Reinforcement learning motor skills policy gradients.Neural Networks, 21 (4), 682 697. Robotics Neuroscience.Pianosi, F., Castelletti, A., & Restelli, M. (2013). Tree-based fitted q-iteration multiobjective markov decision processes water resource management. Journal Hydroinformatics, 15 (2), 258270.Pirotta, M., Parisi, S., & Restelli, M. (2015). Multi-objective reinforcement learningcontinuous pareto frontier approximation. Bonet, B., & Koenig, S. (Eds.), Proceedings Twenty-Ninth AAAI Conference Artificial Intelligence, January 25-30,2015, Austin, Texas, USA., pp. 29282934. AAAI Press.Pirotta, M., Restelli, M., & Bascetta, L. (2013). Adaptive step-size policy gradientmethods. Burges, C. J. C., Bottou, L., Ghahramani, Z., & Weinberger, K. Q. (Eds.),Advances Neural Information Processing Systems 26: 27th Annual ConferenceNeural Information Processing Systems 2013. Proceedings meeting held December5-8, 2013, Lake Tahoe, Nevada, United States., pp. 13941402.Robert, C., & Casella, G. (2004). Monte Carlo Statistical Methods. Springer TextsStatistics. Springer-Verlag New York.Roijers, D. M., Vamplew, P., Whiteson, S., & Dazeley, R. (2013). survey multi-objectivesequential decision-making. Journal Artificial Intelligence Research, 48, 67113.Roijers, D. M., Whiteson, S., & Oliehoek, F. A. (2015). Computing convex coverage setsfaster multi-objective coordination. Journal Artificial Intelligence Research, 52,399443.Romero, C. (2001). Extended lexicographic goal programming: unifying approach. Omega,29 (1), 6371.Shelton, C. R. (2001). Importance Sampling Reinforcement Learning MultipleObjectives. Ph.D. thesis, Massachusetts Institute Technology.Steuer, R. E., & Choo, E.-U. (1983). interactive weighted tchebycheff proceduremultiple objective programming. Mathematical Programming, 26 (3), 326344.Sutton, R. S., & Barto, A. G. (1998). Reinforcement Learning: Introduction. Bradfordbook. Bradford Book.Sutton, R. S., McAllester, D. A., Singh, S. P., & Mansour, Y. (2000). Policy gradientmethods reinforcement learning function approximation. Solla, S., Leen,T., & Muller, K. (Eds.), Advances Neural Information Processing Systems 12, pp.10571063. MIT Press.Tesauro, G., Das, R., Chan, H., Kephart, J., Levine, D., Rawson, F., & Lefurgy, C. (2008).Managing power consumption performance computing systems using reinforcement learning. Platt, J., Koller, D., Singer, Y., & Roweis, S. (Eds.), AdvancesNeural Information Processing Systems 20, pp. 14971504. Curran Associates, Inc.226fiMORL Continuous Pareto Manifold ApproximationVamplew, P., Dazeley, R., Berry, A., Issabekov, R., & Dekker, E. (2011). Empirical evaluation methods multiobjective reinforcement learning algorithms. Machine Learning,84 (1-2), 5180.Van Moffaert, K., Drugan, M. M., & Nowe, A. (2013). Scalarized multi-objective reinforcement learning: Novel design techniques. Adaptive Dynamic ProgrammingReinforcement Learning (ADPRL), 2013 IEEE Symposium on, pp. 191199.Van Moffaert, K., & Nowe, A. (2014). Multi-objective reinforcement learning using setspareto dominating policies. Journal Machine Learning Research, 15, 34833512.Waltz, F. M. (1967). engineering approach: Hierarchical optimization criteria. AutomaticControl, IEEE Transactions on, 12 (2), 179180.Wang, W., & Sebag, M. (2013). Hypervolume indicator dominance reward based multiobjective monte-carlo tree search. Machine Learning, 92 (2-3), 403429.Williams, R. (1992). Simple statistical gradient-following algorithms connectionist reinforcement learning. Machine Learning, 8 (3-4), 229256.Yu, P., & Leitmann, G. (1974). Compromise solutions, domination structures, salukvadzes solution. Journal Optimization Theory Applications, 13 (3), 362378.Zitzler, E., Thiele, L., & Bader, J. (2010). set-based multiobjective optimization. Evolutionary Computation, IEEE Transactions on, 14 (1), 5879.Zitzler, E., Thiele, L., Laumanns, M., Fonseca, C. M., & da Fonseca, V. G. (2003). Performance assessment multiobjective optimizers: analysis review. EvolutionaryComputation, IEEE Transactions on, 7 (2), 117132.227fiJournal Artificial Intelligence Research 57 (2016) 465-508Submitted 03/16; published 11/16PROMOCA: Probabilistic Modeling AnalysisAgents Commitment ProtocolsAkn GunayYang LiuJie Zhangakingunay@ntu.edu.sgyangliu@ntu.edu.sgzhangj@ntu.edu.sgSchool Computer Science EngineeringNanyang Technological University, SingaporeAbstractSocial commitment protocols regulate interactions agents multiagent systems. Several methods developed analyze properties commitment protocols. However,analysis agents behavior commitment protocol, take accountagents goals beliefs, received less attention. paper present ProMocaframework address issue. Firstly, develop expressive formal language modelagents respect commitments. language provides dedicated elementsdefine commitment protocols, model agents terms goals, behaviors,beliefs. Furthermore, language provides probabilistic non-deterministic elementsmodel uncertainty agents beliefs. Secondly, identify two essential propertiesagent respect commitment protocol, namely compliance goal satisfaction.formalize properties using probabilistic variant linear temporal logic. Thirdly,adapt probabilistic model checking algorithm automatically analyze compliancegoal satisfaction properties. Finally, present empirical results efficiencyscalability ProMoca.1. IntroductionSocial commitments provide formal framework define, regulate, reason interactions agents multiagent systems (Singh, 1999). commitment made debtorcreditor bring condition. instance, merchant (debtor) committedcustomer (creditor) deliver goods purchased customer. Everycommitment state changes according events. instance,merchant delivers purchased goods, commitment customer becomes fulfilled.Commitments enforce agents bring certain events. Instead, regulateagents defining events affect states commitments. words, agents decide fulfilling violating commitments autonomously. instance, merchantmay decide deliver goods customer. However, event result violationcommitment, may consequences (e.g., merchant may sanctionedalso loses reputation). regulation, commitments establish desired levelinterdependence among agents without interfering autonomy. Commitmentscombined form commitment protocols, capture complex interactionsamong agents (Yolum & Singh, 2002).Analysis commitment protocols properties essential ensure effective operation. However, analysis challenging due rapidly increasing complexityc2016AI Access Foundation. rights reserved.fiGunay, Liu & Zhanginteraction protocols. Hence, development efficient formal analysis methodscommitment protocols, cope complexity, essential create effective multiagent systems. Various formal properties commitment protocolsstudied several methods developed analyze (Yolum, 2007; Desai,Cheng, Chopra, & Singh, 2007a; Desai, Narendra, & Singh, 2008; El Menshawy, Bentahar,El Kholy, & Dssouli, 2013; El Kholy, Bentahar, Menshawy, Qu, & Dssouli, 2014).However, analysis agents properties enacting commitment protocolreceived less attention (Marengo, Baldoni, Baroglio, Chopra, Patti, & Singh, 2011; Gunay &Yolum, 2013; Kafal, Gunay, & Yolum, 2014). analysis aims verify formal propertiesagents behavior respect commitment protocol (e.g., compliance agentsbehavior protocol), crucial developing effective agents. key challengeanalyzing agents behavior respect commitment protocol uncertainty,naturally occurs multiagent systems due several factors. One major factoragent autonomy, mainly corresponds epistemic uncertainty. Specifically, agents actautonomously pursue private goals. Hence, agent cannot certainbehaviors agents. Similarly, agents lack awareness environment,may result limited sensory reasoning capabilities, leads epistemicuncertainty. Furthermore, many physical systems involve irreducible aleatory uncertaintyoccurs due physical variability present agents environment. Agents copeuncertainty utilizing reasoning methods use potentially wrong incompletebeliefs instead exact knowledge (Halpern, 2003).previous work commitments address uncertainty. fill gap,previous work, developed analysis method commitment protocols usingprobabilistic model checking, handle uncertainty behaviors agents (Gunay,Songzheng, Liu, & Zhang, 2015). method uses abstract formalism (specifically,probabilistic automaton) modeling analyzing behaviors agents commitmentprotocols. However, practical point view, manual definition commitment protocols behaviors agents abstract formalism time consuming errorprone task. Besides, requires modeler knowledge expertise specificabstract formalism. issues, use abstract formalism modelingadequate practical development settings (e.g., developer verifiesagents implementation). adequate approach use expressive high level formallanguage modeling, automatically translated abstract formalismformal analysis. best knowledge, dedicated formal modelinglanguage capture uncertainty agents context commitment protocols.paper present ProMoca framework address issue. ProMoca provides expressive modeling language includes various language elements modelcommitment protocols, also various aspects agents, different goal types,beliefs, behaviors. Besides, ProMoca supports probabilistic modeling capture uncertainty behaviors beliefs agents. ProMoca also pay special attentiontwo essential properties agents behavior respect commitment protocol.first properties compliance agents behavior commitment protocol.is, whether agents behavior fulfills agents commitments. second propertyconsiders whether agents behavior satisfies agents goals context commitment protocol. Since agents interdependent, neither compliance goal satisfaction466fiProMoca: Probabilistic Modeling Analysis Agents Commitment Protocolsanalyzed considering agents behavior isolation. cope interdependence, ProMoca uses agents beliefs agents behaviors. ProMocaadopts previous probabilistic model checking method (Gunay et al., 2015) analyzingproperties. evaluate efficiency scalability ProMoca use three realistic examples. Besides, compare ProMocas performance PRISM,state-of-the-art probabilistic model checker. main contributions follows:develop new modeling language ProMoca (we use name ProMocamodeling language analysis framework interchangeably). defineformal syntax operational semantics ProMoca, provides dedicatedlanguage elements define manage commitment protocol. ProMoca alsoprovides various language elements define behaviors, goals, beliefs agentcontext commitment protocol. Moreover, ProMoca provides probabilisticnon-deterministic elements model uncertainty agents beliefs.best knowledge, ProMoca first formal language provides dedicatedelements modeling commitment protocols, agents, uncertainty unifiedenvironment.identify develop formal definitions compliance goal satisfaction properties. Different previous definitions properties literature,formalization take uncertainty agents beliefs agents behaviorsaccount using probabilistic variant linear temporal logic. Accordingly,define properties precise flexible manner.analyze agents behavior context commitment protocol verifyingcompliance goal satisfaction, define complete ProMoca framework,modeling done using new formal language developpaper, analysis done adopting previously developed probabilistic modelchecking method (Gunay et al., 2015).substantially extend earlier preliminary experimental result (Gunay et al.,2015), conducting detailed empirical study validate ProMocas practicalusefulness scalability three well-studied scenarios literature, namelyaerospace aftercare, international insurance (Jakob, Pechoucek, Miles, & Luck, 2008),NetBill (Sirbu & Tygar, 1995). results show ProMoca outperformsstate-of-the-art general purpose probabilistic model checker PRISM verifyingcompliance goal satisfaction properties agents behavior contextcommitment protocol.paper organized follows. Section 2, introduce fundamental conceptscommitment protocols, agents, analysis behaviors. Section 3, defineProMocas formal syntax operational semantics. Section 4, define analysisframework model checking algorithm. Section 5, present empirical evaluationframework. Section 6 provides survey related work. Finally, Section 7,conclude paper discussion approach listing future directions.467fiGunay, Liu & Zhang2. Background: Commitments, Agents, Analysissection provide overview commitments, agent concepts, behaviors, goals, beliefs, key ProMoca. also discuss compliance goalsatisfaction properties respect concepts motivate research.2.1 Commitmentscommitment made one agent another bring condition (Singh, 1999).Conventionally, commitment denoted C(debtor, creditor, antecedent, consequent)debtor creditor agents, antecedent consequent conditions.Intuitively, commitment means debtor committed creditor bringconsequent, antecedent holds. instance, commitment C(merchant,customer, goods-purchased, goods-delivered ) captures merchants commitmentcustomer deliver goods (represented proposition goods-delivered ),goods purchased customer (represented proposition goods-purchased ).exact meaning commitment depends type condition usedconsequent. Achievement conditions widely used type commitments consequent. brevity, call commitment condition simplyachievement commitment. commitment merchant deliver purchasedgoods customer example achievement commitment. Use maintenancecondition commitments consequent also considered literature (Fornara& Colombetti, 2002; Mallya & Huhns, 2003; Gunay & Yolum, 2011; Chesani, Mello, Montali, & Torroni, 2013). commitment maintenance condition consequentfulfilled, condition maintained another termination condition occurs. callcommitment condition simply maintenance commitment. instance,internet service provider may committed customer provide internet connectionmonth, customer purchases data plan internet service provider.Commitments also considered subscription model. instance, insteadpurchasing data plan single month, customer may subscribe data planyear monthly basis (i.e., duration period subscription month).result, internet service provider separate commitment month yearprovide internet connection customer, long customer pays correspondingmonthly subscription fee. technical terms, subscription consideredtemplate (e.g., customer pays subscription fee specific month, serviceprovider becomes committed provide internet connection month) creatingconcrete commitment instances period subscription. example,create twelve commitment instances template (one month)setting commitments antecedent consequent propositions model paymentsubscription fee provision internet specific month, respectively. bestknowledge, subscription model formally considered previousresearch. However, subscriptions part many real world settings. Accordingly,formalize ProMoca. Note subscription model consideredspecial case meta-commitment concept (Chopra & Singh, 2015, 2016a),general since bound specification subscription.468fiProMoca: Probabilistic Modeling Analysis Agents Commitment Protocolsnullcreditorreleasesreleasedcreditorreleasesdebtorcreatesdebtordischargesexpiredconditionalcreditordetachesactivefulfilledantecedentexpirescompensatedviolateddebtor cancelsfails dischargedebtorcompensatesFigure 1: lifecycle commitment.commitments state evolves time according public events (i.e., independent agents internal state). lifecycle commitment studiedextensively literature (Yolum & Singh, 2002; Fornara & Colombetti, 2002; Chesaniet al., 2013). Here, use commitment lifecycle show Figure 1,labels rectangles represent commitment states, edge labels show eventscorresponding agents trigger state changes.commitment null state creation. commitment createddebtor conditional state. state neither antecedent consequentcommitment holds. instance, commitment merchant customercreated merchant (i.e., debtor) initially neither payment delivery.Hence, commitment conditional. intuitive meaning conditional commitmentsimilar offer states, antecedent starts holds, debtor becomescommitted creditor bring consequent.commitments antecedent satisfied, commitment becomes expired.creditor conditional commitment may also explicitly release debtor commitment, makes commitment released. Expired released states terminalstates. antecedent conditional commitment satisfied, creditor detachescommitment, commitment becomes active. Detachment commitment independent antecedent satisfied. is, antecedent may satisfied eitherevent occurs direct result action creditor (e.g., customer pays),external event (e.g., customers bank may pay behalf customer).active commitment intuitively means debtor committed bringconsequent commitment.Fulfillment violation commitment depends type commitmentsconsequent. consequent active achievement commitment satisfied, debtorimmediately discharges commitment, commitment becomes fulfilled (e.g.,merchant delivers). maintenance commitment fulfilled, consequent commitment maintained another condition determines termination commitment occurs (e.g., internet service provider maintains internet connection usertermination data plan). case detachment, commitments469fiGunay, Liu & Zhangfulfillment also independent consequent satisfied (e.g., merchant may deliver, could delegate delivery courier). fulfilled commitmentintuitively means debtor honored responsibility, fulfilled state terminal. case conditional commitment, creditor may also release debtoractive commitment.either consequent active commitment satisfied, debtor explicitlycancels commitment, commitment becomes violated. achievement commitment, failure consequent may depend another condition (e.g., deadline).maintenance commitment, failure consequent occurs, consequent conditionhold moment termination condition commitment holds. Notedue autonomy agents, debtor may intentionally choose violate commitment,even fulfill it. instance, merchant may decide sell goods anothercustomer better profit, may violate commitment original customer.hand, debtor may also violate commitment unintentionally. instance,merchant may fail deliver bad weather conditions. case, violatedcommitment intuitively means debtor failed honor responsibility. Dependingdomain application, violated commitment compensated debtortaking certain action, makes commitment state compensated (Torroni, Chesani,Mello, & Montali, 2010; Kafal & Torroni, 2012; Chopra & Singh, 2015). instance,merchant fails deliver goods customer, violates commitment. However,refund customer compensate commitments violation. Compensationallows agents restore interaction back desirable state, interrupteddue violated commitment. Compensated state terminal. commitment violatedway compensation, violated state counted terminal.Note subscription state itself, since define concretecommitment, provides template instantiating concrete commitmentsperiod subscription. Hence, notion state subscription capturedabstract manner states corresponding concrete commitment instances.many applications, agents engage complex interactions cannot representedsingle commitment. capture aspects complex interactions, multiplecommitments considered together commitment protocol (Yolum & Singh, 2002).instance, merchants commitment customer captures paymentdelivery aspects interaction, another commitment C(merchant, customer, goodsdefective, goods-replaced ), states merchant committed customerreplace defective good, captures warranty related aspects interaction.two commitments (and prospective commitments) form commitment protocol.2.2 Agents Analysis Behaviorspaper, main objective develop dedicated formal language modelinganalyzing agents behavior commitment protocol. clearcontext, call particular agent target agent distinguish agents.analysis use three kinds information, available targetagent. first kind information target agents goals. divide goalstwo types achievement maintenance goals customary agent literature470fiProMoca: Probabilistic Modeling Analysis Agents Commitment Protocols(van Riemsdijk, Dastani, & Meyer, 2009; Chopra, Dalpiaz, Giorgini, & Mylopoulos, 2010).Achievement goals model situations, agent aims achieve certain satisfactioncondition. instance, customer may aim possess goods. Maintenance goalsmodel situations agent aims maintain certain satisfaction condition.instance, internet service provider may aim maintain internet servicerunning. Furthermore, goal types considered one-time persistent goals.One-time goals pursued once, general, subject preconditions.example, customer needs certain type good possess it,goal possess good. Similarly, internet service provider aims providemaintain internet connection customer, customer subscribedservice. One-time goals might also termination condition (e.g., deadline).termination condition goal holds satisfaction condition, goal fails.Contrary one-time goals, persistent goals pre termination conditions,persist whole lifespan agent. case persistent achievement goal,agent aims satisfy condition may fail time time, always restoredwhile. instance, merchant may aim dispose obsolete goods (e.g., oldversions mobile phone) warehouse. Occasionally, obsolete goods maykept warehouse (e.g., new version mobile phone first appears, takesdispose old phones), disposed eventually.hand, persistent maintenance goals represents condition agent aims keepsatisfied continuously whole lifespan without precondition. instance,merchant might aim maintain positive bank balance whole lifespan.second kind information, use analysis, target agents behavior.assume target agents behavior persistent (i.e., non-terminating) computation,agent uses set if-then type rules decide next action (e.g.,merchant commitment make delivery commitment active,delivers). uncertainty results agents actions, decision rulesmay include non-deterministic probabilistic components model uncertainty. Supposemerchant may fail deliver time probability 0.1 depending weatherconditions. case, if-then rule defines merchants behavior would be:merchant committed deliver weather condition bad, merchantdelivers time (and fulfills commitment) 0.9 probability, fails delivertime (and violates commitment) 0.1 probability. demonstrate restpaper, combination if-then rules, non-determinism, probabilistic choice,context persistent computation provides us rich flexible model define variouscomplex agent behaviors.last kind information use analysis target agents beliefsbehaviors agents. Uncertainty natural element kind information, sinceagents autonomous. Accordingly, define target agents beliefsagents behaviors similar manner target agents behavior using probabilisticchoice non-determinism. instance, suppose merchant dependentcourier make delivery, necessary fulfill commitment customer.situation merchant may believe courier successfully delivers timeprobability 0.95 (and fails deliver time probability 0.05). demonstratelater, capture situation using probabilistic choice beliefs target471fiGunay, Liu & Zhangagent similar manner earlier example. Note that, paper assumeprobability values agents behavior beliefs set modeler. valuesmay reflect intuition modeler, obtained statistical model (e.g.,previous delivery results merchant courier different weather conditions).Considering three kinds information, objective analyze two key properties target agents behavior commitment protocol. first propertycompliance, holds target agents behavior fulfills active commitmentsprotocol. relaxed version compliance may take compensation account.is, agent complies commitment protocol fulfilling active commitmentsalso compensating violated commitments. second property goal satisfaction,holds target agent satisfies goals enacting commitment protocol. target agents beliefs agents play crucial role analyzing properties sinceinterdependence among agents. words, agents behaviors directlyaffect target agent. instance, merchant relies courier delivery,merchants compliance protocol goal satisfaction cannot correctly verifiedwithout taking couriers behavior account. fact, consider merchants behavior, neither compliance goal satisfaction hold merchant, sincedelivery capability. However, merchant believes courierdelivers high probability, conclude merchant compliesprotocol also satisfies goal enacting protocol.2.3 Running Examplerest paper use running example aerospace aftercare domain,introduced Jakob et al. (2008), used literature evaluationcommitments normative models (Modgil, Faci, Meneguzzi, Oren, Miles, & Luck,2009; Desai, Chopra, & Singh, 2009). example scenario, manufacturerprovides aircraft engines airline operators. manufacturer sells engineairline operator, manufacturer becomes responsible keeping engine operationalperiodically servicing engine. airline operator pay service feemanufacturer. Besides, airline operator also provide operational dataengine manufacturer, needed manufacturer analyze statusengine. order service engine, manufacturer needs spare engine partsseveral suppliers. However, manufacturer use certain engine partsservicing, approved monitoring aerospace agency. airline operator maymonitored different aerospace agencies depending regions airlineoperates. Different agencies may different policies approved spare engine parts.Hence, use certain part repair depends airline respective agencies.operational status engine maintained, manufacturer compensatesituation paying penalty airline operator. manufacturer alsobring engine back operational state within certain amount time.manufacturer fails compensate, contract may canceled airline operator.consider example engine manufacturers point view analyzecompliance goal satisfaction.472fiProMoca: Probabilistic Modeling Analysis Agents Commitment Protocols3. Modeling Commitment Protocols Agents PROMOCAfirst present formal syntax ProMoca Section 3.1. Then, defineoperational semantics ProMoca Section 3.2, formalize compliance goalsatisfaction properties Section 3.3. Finally, discuss key design decisionsProMoca Section 3.4.3.1 SyntaxProMoca model composed three blocks, define set global variables,commitment protocol, target agent (i.e., agent aim verify).define syntax block illustrative examples.3.1.1 Global VariablesProMoca model includes finite set global variables, defined withinblock globals{var; . . . var;}. variable var defined using keyword variablefollowing syntax:var ::= variable variable-name : {value-set} = valuevariable-name unique name variable, value-set finite set stringsdefines domain variable (i.e., enumeration variables possible values),value initial value variable, must element value-set.instance, status aircraft engine modeled using following variable:variable engine-status : {unknown, operational, malfunction, maintenance} = unknown;name variable engine-status. domain variable consists fourvalues, capture different operational states engine. initial valuevariable unknown.3.1.2 Commitment Protocolcommitment protocol composition finite set commitments. commitmentprotocol defined within block protocol{comm; . . . comm;}. commitment commdefined using keyword commitment following syntax:comm ::= commitment(commitment-id, commitment-type, subscription-period,debtor-id, creditor-id, antecedent, expiration, consequent, termination){observers}[commitment-id]first parameter commitment-id unique string identifier commitment.type commitment defined commitment-type, either achievementmaintenance. Subscriptions modeled using subscription-period parameter,finite integer greater 0 represents total number subscriptions periods.commitment subscription, parameter omitted, ProMoca sets473fiGunay, Liu & Zhangvalue 1 default. parameters debtor-id creditor-id identifierscommitments debtor creditor, respectively. parameters antecedent, expiration, consequent, termination expressions define antecedent, expiration, consequent,termination condition commitment, respectively. optional parameter observers set agent identifiers includes agents, observe statecommitment. default, debtor creditor commitment always observestate commitment, required list observers.observers commitments debtor creditor, observers omitted.last optional parameter commitment-id identifier another commitmentused compensate violation commitment. compensationcommitments violation, parameter omitted.expression (e.g., antecedent parameter commitment) logical expressioncompositions conjunctions disjunctions global variable comparisons. Formalsyntax expression follows:expressioncomparisonconst::=::=::=expression expression | expression expression | comparisonvariable-name == value | variable-name != value | constTRUE | FALSEexpression, use standard semantics logical operators or.Similarly, comparison use standard equal equal semanticsoperators == !=, respectively. TRUE FALSE standard boolean constants.Parentheses used regularly define precedence logical operators,omit formal syntax brevity.ProMoca automatically creates several variables capture lifecycle protocols commitments. Firstly, ProMoca creates status variable commitmentprotocol. names variables automatically set ProMoca using<commitment-id>-state pattern (e.g., commitment commitment-id c-1, corresponding variables name c-1-state). status variable domain {null,conditional, active, fulfilled, violated, expired, released, compensated} capturecorresponding state commitment. variables used ProMoca modelread-only variables. Secondly, ProMoca creates subscription counter commitment track fulfillment subscriptions. However, counters internalProMoca, cannot directly accessed within ProMoca model. semanticsvariables formalized later Section 3.2.present example commitments aerospace aftercare scenarioillustrate use ProMocas commitment syntax. Let us start simple achievementcommitment: operator pays price engine manufacturer, manufacturer committed deliver engine. Suppose payment deliverydeadlines (defined variables). commitment observed aerospace agency.commitment violated, cannot compensated. commitment writtenProMoca follows:commitment(c-1, achievement, 1, manufacturer, operator,engine-paid == done, payment-deadline == past,474fiProMoca: Probabilistic Modeling Analysis Agents Commitment Protocolsengine-delivered == done, delivery-deadline == past){aerospace-agency};second example consider maintenance engine according commitment: manufacturer delivers engine operator, manufacturercommitted operator maintain engine operational year, identify c-2. manufacturer fails maintain engine operational, violates c-2,compensate situation repairing engine also paying penalty,defined compensating commitment c-3. Note c-2 explicitly declares c-3compensating commitment. declaration essential correctly managing lifecycles commitments show later Section 3.2. Note use variablecontract commitments capture whether contract manufactureroperator still valid. contract parties terminated (e.g., deliveryengine canceled), commitments expire.commitment(c-2, maintenance, 1, manufacturer, operator,contract == valid engine-delivered == done, contract == terminated,engine-status == operational engine-status == maintenance, end-of-year == past){aerospace-agency}[c-3];commitment(c-3, achievement, 1, manufacturer, operator,contract == valid c-2-status == violated,contract == terminated c-2-status == fulfilled c-2-status == released,engine-status == operational penalty-paid == done,compensation-deadline == past){aerospace-agency};continue, let us emphasize different meaning termination conditionachievement maintenance commitments. achievement commitment, debtorcommitted bring consequent point occurrencetermination condition. example, achievement commitment c-1, terminationcondition delivery deadline, c-1 fulfilled, engine deliveredpoint deadline. Otherwise, c-1 becomes violated. hand,maintenance commitment, debtor committed maintain consequent everypoint commitments detachment occurrence termination condition.example, maintenance commitment c-2, termination condition completionone year delivery engine, fulfillment occurs engines operationalstatus preserved detachment commitment completionyear. Otherwise, commitment becomes violated immediately.complement c-2, need another commitment c-4 defines monthly servicingengine using subscription model follows. delivery engine,manufacturer committed operator service engine monthly basis475fiGunay, Liu & Zhangyear, long operator pays monthly service fee provides engine usagereports. brevity, omit observers compensation commitment.commitment(c-4-, achievement, 12, manufacturer, operator,contract == valid engine-delivered == done service-fee-paid-* == doneengine-report-provided-* == done,contract == terminated fee-deadline-* == past engine-report-provided-* == failed,engine-serviced-* == done,engine-serviced-* == failed engine-serviced-* == late);Since commitment modeled subscription year monthly basis,twelve instances commitment. However, conditions commitmentapply individual instances. example, separate payment servicefee month. ProMoca provides * notation variables correspondinstance conditions. example, service-fee-paid-* means twelve variables(e.g., service-fee-paid-1, service-fee-paid-2, etc.) model separate paymentservice fee. first instance commitment becomes active, service-fee-paid-1conditions antecedent hold. Note conditions instancespecific. conditions, delivery engine (i.e., engine-delivered), usedinstances referring variable.3.1.3 Target Agent Specificationtarget agent specification defined block agent[agent-id]{agent-spec},agent-id unique identifier target agent. target agent specification agent-speccomposed four parts. first part definition target agents finite setlocal variables, enclosed block locals{var; . . . var;}. Local variablesintended model internal state target agent. Hence, cannot usedcontext global elements, accordingly cannot accessed agents.instance, antecedent consequent commitment cannot include localvariable agent. Local variables defined using global variable syntax.second part target agent specification definition target agentsgoals, defined block goals{goal; . . . goal;}. syntax goal follows:goalpa-goalpm-goala-goalm-goal::=::=::=::=::=pa-goal | pm-goal | a-goal | m-goalpagoal(satisfaction)pmgoal(satisfaction)agoal(precondition, satisfaction, termination)mgoal(precondition, satisfaction, termination)Persistent achievement maintenance goals denoted pa-goal pm-goal, respectively. goal types, satisfaction parameters expressions model satisfactioncondition goal, include global local variable comparisons (i.e.,commitment-state variables allowed conditions). example, persistentmaintenance goal manufacturer keep positive bank balance interactingoperators suppliers modeled following goal:476fiProMoca: Probabilistic Modeling Analysis Agents Commitment Protocolspmgoal(bank-balance == positive);One-time achievement maintenance goals denoted a-goal m-goal, respectively. goal types, precondition, satisfaction, termination expressionsmodel pre, satisfaction, termination condition goal. pre terminationconditions goal types include global, local, commitment state variable comparisons. However, satisfaction condition goal types include globallocal variable comparisons.example, manufacturers one-time goal deliver engine paymentmade (captured active status commitment c-1) modeled usingfollowing achievement goal.agoal(c-1-state == active, engine-delivered == done,engine-delivered == failed engine-delivered == late);Note delivery engine fails delivered later deadline (i.e.,delivered == failed delivered == late), one-time goal becomes terminated.last two parts target agent specification definition target agentsbehavior target agents beliefs agents behaviors. targetagents behavior defined block behavior{behavior}. target agents beliefs agents behaviors defined block beliefs{[agent-id]{behavior};. . . [agent-id]{behavior};}. behavior (either target agents behavior believedbehavior another agent) defined according following syntax:behavior::=cont | stop |action-label{assign, . . . , assign} -> behavior |commit{commitment-id} -> behavior |release{commitment-id} -> behavior |cancel{commitment-id} -> behavior |behavior <> behavior |[expression] behavior |(probability) behavior . . . (probability) behaviorLet us explain intuitive meaning element behavior syntax.primitive behaviors cont stop restarts terminates current behavior, respectively.use action-label{assign; . . . ; assign;} capture agent actions effectsvariables. action label action-label used improve readability.is, label action meaning label useddifferent sets assignments different places model. effects actioncaptured assigning new values finite set variables. Actions ProMocaatomic. Hence, assignments occur result action, donegiven order without interruption. syntax assignment assign fallows:assign ::= var-name = value477fiGunay, Liu & ZhangBeside domain dependent actions (e.g., delivering engine), ProMoca also providesthree meta-actions commit, release, cancel capture corresponding commitment operations alter state commitment (i.e., commitment state variable).action commit used debtor create commitment, release used creditor release debtor commitment, cancel used debtor cancelcommitment. three, ProMoca provide meta-actionmanipulate state commitment directly. Instead, state commitmentcaptured internally ProMoca according values commitments parameters(e.g., consequent) define semantics ProMoca.non-deterministic choice behaviors captured behavior <> behavior. is,either first second behavior performed agent, decisionnon-deterministic. [expression] behavior captures guarded behavior (i.e., if-then rule).guard condition expression logical expression (as defined before). guard conditionholds, corresponding behavior performed. Otherwise, behavior becomesblocked condition holds. Note arbitrary number guarded behaviorscombined using non-deterministic choice model complex decision procedures.case, one behaviors, corresponding guard condition holds, selectedexecution non-deterministic manner. Finally, (probability) behavior . . . (probability)behavior denotes probabilistic choice among possible behaviors. probabilityreal value sum probabilities equal 1 probabilistic choice. Probabilistic non-deterministic choices main elements ProMoca incorporateuncertainty modeling analysis processes.important distinction behavior beliefs blocks use variabletypes. Global variables used (both reading assignment) blocks.However, local variables target agent used behavior block, sinceprivate target agent. Local variables accessible either readingassignment beliefs block, since block models agents behaviors,use target agents local variables. Accessibility commitment state variables(always read-only) depend role corresponding agent commitments.instance, target agent debtor, creditor, observer commitment,corresponding state variable queried behavior block. Similarly, anotheragent debtor, creditor, observer commitment, part beliefs blockcorresponds agents behavior, query state commitment.Let us present (partial) behavior example manufacturer below,interpreted follows. commitment manufacturer service engine (i.e.,instance c-4) becomes active, manufacturer may behave three different ways,according current situation. manufacturer already necessary partsservice engine (modeled local variable part-availability), manufacturer servicesengine time 0.99 probability. small probability (0.01) failurecomplete service time, violates c-4. manufacturernecessary parts service engine, order either first secondsupplier. manufacturer believes (as demonstrate later) first supplier mostlydelivers ordered parts time. manufacturer also believes second supplierdelivers ordered parts late almost time. Furthermore, manufacturer believessecond supplier may even completely fail deliver ordered parts. Accordingly,478fiProMoca: Probabilistic Modeling Analysis Agents Commitment Protocolsmanufacturer prefers work first supplier. However, first supplierapproved aerospace agency particular operator, owns engine,manufacturer works second supplier. situation captured guardstatements. Note case late delivery ordered parts, timely serviceengine affected. is, late delivery occurs, manufacturer services time0.75 probability. Hence, bigger risk violating c-4. Finally, servicingengine, availability spare parts next service period determinednon-deterministic choice. is, manufacturer know advance manyspare parts needs, therefore possible result (e.g., running spare parts)considered.[c-4-state == active] {[part-availability == available] {(0.99) service-on-time{engine-serviced = done} ->all-parts-consumed{part-availability == unavailable} <> cont(0.01) service-late{engine-serviced = late} ->all-parts-consumed{part-availability == unavailable} <> cont} <>[part-availability == unavailable supplier-1 == approved] {[part-delivery == on-time](0.99) service-on-time{engine-serviced = done} ->all-parts-consumed{part-availability == unavailable} <> cont(0.01) service-late{engine-serviced = late} ->all-parts-consumed{part-availability == unavailable} <> cont} <>[part-delivery == late] {(0.75) service-on-time{engine-serviced = done} ->all-parts-consumed{part-availability == unavailable} <> cont(0.25) service-late{engine-serviced = late} ->all-parts-consumed{part-availability == unavailable} <> cont}} <>[part-availability == unavailable supplier-1 != approved supplier-2 == approved] {[part-delivery == late](0.75) service-on-time{engine-serviced = done} ->all-parts-consumed{part-availability == unavailable} <> cont(0.25) service-late{engine-serviced = late} ->all-parts-consumed{part-availability == unavailable} <> cont} <>[part-delivery == failed]service-failed{engine-serviced = failed} -> cont}}}479fiGunay, Liu & ZhangLastly, demonstrate beliefs manufacturer suppliers.Suppose interaction manufacturer first second supplierregulated commitments c-5 c-6, respectively. commitments statemanufacturer orders batch spare parts supplier, supplier committeddeliver parts manufacturer. brevity show commitments.mentioned earlier, manufacturer believes first supplier reliable.Precisely, first supplier delivers ordered parts time 0.8 probability, late0.2 probability. manufacturer also believes second supplier unreliable.Precisely, second supplier delivers order parts late 0.95 probability. Besides,0.05 probability, second supplier fails altogether deliver ordered parts.beliefs {[supplier-1] {[c-5-state == active] {(0.8) delivers-on-time{part-delivery = on-time} -> cont(0.2) delivers-late{part-delivery = late} -> cont}};[supplier-2] {[c-6-state == active] {(0.95) delivers-late{part-delivery = late} -> cont(0.05) fails-to-deliver{part-delivery = failed} -> cont}};}3.2 Semanticsdefine ProMocas operational semantics. first define ProMoca modelconfiguration captures global state ProMoca model.Definition 1 (ProMoca Model). ProMoca model tuple = (Var , Vinit , C, G,Bagn |||Bbel1 ||| . . . |||Bbeln ) Var set variables (i.e., composed set global,local, commitment state, internal variables), Vinit initial valuation variables Var , C commitment protocol (i.e., set commitments), G targetagents goal set. Bagn |||Bbel1 ||| . . . |||Bbeln parallel composition interleaved behaviors target agent (represented Bagn ) n number agents (i.e.,Bbeli represents ith agents believed behavior).Definition 2 (Configuration). configuration tuple (V, B), V valuationvariables Var , B behavior.define operational semantics behavioral element using firing rules,operate configurations. Below, denotes set (visible) agent actions,denotes internal (invisible) action. use denote action . writeV |= expression denote logical expression expression evaluates true valuation480fiProMoca: Probabilistic Modeling Analysis Agents Commitment ProtocolsV . start operational semantics cont, causes current behavior Bcontinue initial location without making changes valuation V .case handled invisible action, defined rule [cont].cont encountered B(V, cont)(V, B)[cont]Rule [prefix] captures action behavior B modifies values variablesvaluation V .(V, {assign, . . . , assign} -> B)(update(V, {assign, . . . , assign}, C), B)[prefix]readability, use auxiliary update function handle assignment new valuesvariables modifying configuration. present function Algorithm 1.Algorithm 1 (and also related algorithms) slightly abuse notationreadability follows. assume assignment assign represented variablevalue pair (i.e., (variable, value)). use bracket notation V [variable] accessvariable valuation V . internal state (c-id-state) subscription (c-id-subscription)variables available algorithm commitment identifier c-id. alsoomit observer lists commitments, since irrelevant assignments.Input arguments update function current valuation V , set assignments assignments occur result action , commitment protocolC. function first updates global local variables V according assignments(lines 12). Then, commitment c protocol, function updates state c(i.e., c-id) respect updated values variables necessary follows (lines 322). commitment conditional expiration condition commitment holdsupdated valuation, commitment expires subscription counter updated auxiliary function update-subscription, present Algorithm 2,explain detail later (lines 57). Otherwise, antecedent conditional commitment holds updated valuation, commitment becomes active (lines 89). neitherconditions hold, state conditional commitment change,show Algorithm 1 brevity.commitment active, necessary consider type (i.e., achievement maintenance) determine next state. termination condition active achievementcommitment holds updated valuation, commitment becomes violated (lines 1214). Otherwise, consequent commitment holds updated valuation,commitment becomes fulfilled (lines 1516). neither conditions hold, stateactive achievement commitment change. consequent active maintenance commitment hold updated valuation, commitment becomesviolated (lines 1820). Otherwise, termination condition commitment holdsupdated valuation, commitment becomes fulfilled (lines 2122). neitherconditions hold, state maintenance commitment change. Finally, updatereturns updated valuation (line 23).Subscription fulfillment status commitment handled auxiliary functions update-subscription fulfillment define Algorithms 2, 3, respectively.481fiGunay, Liu & ZhangAlgorithm 1: Function update(V, assignments, C) returns updated valuation V .input : valuation V , set assignments assignments, commitment protocol Coutput: updated valuation V1234567891011121314foreach (variable, value) assignmentsV [variable] valueforeach commitment(c-id, c-type, subs, deb, cre, ant, exp, con, ter)[c-id] c CV [c-id-state] = conditionalV |= expV [c-id-state] expiredV update-subscription(V, c)else V |= antV [c-id-state] activeelse V [c-id-state] = activec-type = achievementV |= terV [c-id-state] violatedV update-subscription(V, c)else V |= conV fulfillment(V, c, C)151617181920else c-type = maintenanceV 6|= conV [c-id-state] violatedV update-subscription(V, c)else V |= terV fulfillment(V, c, C)212223return Vcommitment reaches terminal state (e.g., fulfilled) internal subscriptioncounter commitment updated. commitment subscription(i.e., template commitment enacted once), update effect.Otherwise, update occurs defined Algorithm 2, takes current valuation V commitment c identifier c-id input arguments. First, internalsubscription counter (i.e., c-id-subscription) commitment increased one (line 1).Then, incremented subscription counter less equal total subscription period subs (i.e., periods subscription considered yet),commitment corresponds next period subscription becomes conditional(lines 2-4). Finally, updated valuation returned. Remember subscriptioncounter commitment initially set ProMoca 1. Hence, conditionline 2 include equal case. Also note non-subscription commitment482fiProMoca: Probabilistic Modeling Analysis Agents Commitment ProtocolsAlgorithm 2: Function update-subscription(V, c) returns updated valuation V .input : valuation V , commitment coutput: updated valuation V4V [c-id-subscription] V [c-id-subscription] + 1V [c-id-subscription] subss-id-state concatenate (c-id, c-id-subscription)V [s-id-state] conditional5return V123default period limit 1. Hence, condition line 2 always fails non-subscriptioncommitments result increasing subscription counter one line 1.Algorithm 3 defines auxiliary fulfillment function, takes current valuationV , fulfilled commitment c identifier c-id, commitment protocol Cinput arguments. function first sets state commitment (i.e., c-id-state)fulfilled (line 1). Then, updates subscription counter commitment (line 2).Lastly, fulfilled commitment c compensation another commitment c0context C, determined auxiliary function compensates,commitment c0 currently violated, state c0 set compensated (lines 35). Notethat, c subscription, compensates c0 periods c fulfilled (i.e.,condition subs < V [c-id-subscription] holds).Algorithm 3: Function fulfillment(V, c, C) updates valuation V respectfulfillment commitment c.input : valuation V , commitment c, commitment protocol Coutput: updated valuation V5V [c-id-state] fulfilledV update-subscription(V, c)c0 compensates(c, C)c0 6= none V [c-id-state] = violated subs < V [c-id-subscription]V [c-id-state] compensated6return V1234Note that, algorithms encoded trivially set firing rules,similar ones use define operational semantics ProMocaelements. However, prefer algorithmic representation readability. practice,algorithms implemented efficiently using index structures variablesvaluation commitments include index variable conditions. However,prefer explain presented (less efficient intuitive) iterative formclarity.continue semantics meta-operations create, release cancelcommitment, shown rules [commit], [release] [cancel], respectively.use auxiliary updatecommit , updaterelease updatecancel functions handle change483fiGunay, Liu & Zhangvaluation corresponding commitments state variable (as assignments).instance, [commit] fires commitment identifier commitment-id, updatecommitfunction assigns value conditional variable commitment-id-state, sets corresponding subscription counter 1, returns updated valuation V .V |= commitment-id-state == null(V, commit{commitment-id} -> B)(updatecommit (V, commitment-id), B)V |= commitment-id-state == conditional commitment-id-state == active(V, release{commitment-id} -> B)(updaterelease (V, commitment-id), B)V |= commitment-id-state == active(V, cancel{commitment-id} -> B)(updatecancel (V, commitment-id), B)[commit][release][cancel]three rules define configuration changes condition rulehold. instance, [cancel] rule define configuration changes,commitment canceled active. handle situations definefollowing three rules, ignore commitment operation changecurrent configuration, condition rule hold. instance, [!cancel],commitment active, canceled, cancel operation ignoredcommitments current state preserved (i.e., current configuration change).V |= commitment-id-state ! = null(V, commit{commitment-id} -> B)(V, B)V |= commitment-id-state ! = conditional commitment-id-state ! = active(V, release{commitment-id} -> B)(V, B)V |= commitment-id-state ! = active(V, cancel{commitment-id} -> B)(V, B)[!commit][!release][!cancel]Rules [non-1] [non-2] capture semantics non-deterministic choicebehaviors Bi Bj . non-deterministic choice Bi Bj , either BiBj selected non-deterministic manner progressing according rules [non-1][non-2], respectively.[non-1][non-2](V, Bi <> Bj )(V, Bi )(V, Bi <> Bj )(V, Bj )Rule [guard] captures semantics guarded behaviors. expression guardassociated behavior B evaluated true according valuation V ,action occurs model progresses configuration (V 0 , B 0 ). Otherwise,484fiProMoca: Probabilistic Modeling Analysis Agents Commitment ProtocolsB becomes blocked model progresses another configuration, guardevaluates true. may happen, interleaving behavior assigns new valuesvariables, causes model progress new configuration, guardevaluated true. However, interleaving behavior, current behaviorpermanently blocked (i.e., deadlocked).V |= guard (V, B)(V 0 , B 0 )(V, [guard]B)(V 0 , B 0 )[guard]Lastly, define operational semantics interleaving behaviors parallel composition,denoted |||. Remember ProMoca models target agentsbehavior target agents beliefs agents behaviors separate interleaving behaviors. compose behaviors single behavior verify propertiestarget agents behavior explain Section 4. achieve using rules [int-1][int-2]. Intuitively, two interleaving behaviors Bi Bj (e.g., targetagents behavior believed behavior another agent), either Bi Bj executedindependently behavior.(V, Bi )(V 0 , Bi0 )(V, Bi ||| Bj )(V 0 , Bi0 ||| Bj )[int-1](V, Bj )(V 0 , Bj0 )(V, Bi ||| Bj )(V 0 , Bi ||| Bj0 )[int-2]clarify parallel composition two interleaving behaviors, present simple example Figure 2, shows possible executions two interleaving behaviorsBi = {ia1{vi = 1} -> ia2{vi = 2}} Bj = {ja1{vj = 1} -> ja2{vj = 2}}respect initial valuation V = ((vi : 0), (vj : 0)) variables vi vj. Noteomit stop statements end behaviors brevity. box Figure 2corresponds composed configuration first line valuation Vrest interleaving behaviors Bi Bj . Edges boxes show transitionsconfigurations according actions taken behaviors, shown edge labels.Note action taken, removed corresponding behavior indicatecompletion. instance, two possible actions taken initialconfiguration, namely ia1 Bi ja1 Bj . ia1 taken, value vi set 1,Bi becomes {ia2{vi = 2}} new configuration reach result ia1.final configuration, valuation V ((vi : 2), (vj : 2)), behaviors BiBj empty, hence stop (i.e., possible actions taken).firing rules define behavior progresses one configuration anotherProMoca model. define execution ProMoca model respectrules Markov Decision Process (MDP) (Bellman, 1957), expressive enoughcapture probabilistic non-deterministic interleaving behaviors.Definition 3 (Markov Decision Process). Markov decision process tuple =(S, Act, P, init , AP, L)finite set states,485fiGunay, Liu & Zhang((vi : 0), (vj : 0)),(Bi = {ia1{vi = 1} -> ia2{vi = 2}}|||Bj = {ja1{vj = 1} -> ja2{vj = 2}})ia1{vi = 1}ja1{vj = 1}((vi : 1), (vj : 0)),(Bi = {ia2{vi = 2}}|||Bj = {ja1{vj = 1} -> ja2{vj = 2}})ia2{vi = 2}((vi : 0), (vj : 1)),(Bi = {ia1{vi = 1} -> ia2{vi = 2}}|||Bj = {ja2{vj = 2}})ja1{vj = 1}((vi : 2), (vj : 0)),(Bi = {}|||Bj = {ja1{vj = 1} -> ja2{vj = 2}})ja1{vj = 1}ia1{vi = 1}((vi : 1), (vj : 1)),(Bi = {ia2{vi = 2}}|||Bj = {ja2{vj = 2}})ia2{vi = 2}ja2{vj = 2}((vi : 0), (vj : 2)),(Bi = {ia1{vi = 1} -> ia2{vi = 2}}|||Bj = {})ja2{vj = 2}ia1{vi = 1}((vi : 2), (vj : 1)),((vi : 2), (vj : 2)),((vi : 1), (vj : 2)),(Bi = {}(Bi = {}ja2{vj = 2}ia2{vi = 2} (Bi = ia2{vi = 2}}|||||||||Bj = {ja2{vj = 2}})Bj = {})Bj = {})Figure 2: Possible executions interleaving behaviors Bi Bj .Act finite set actions,P: Act 7 [0, 1] transition probability function every stateevery action Act:XP(s, , s0 ) {0, 1}s0init : 7 1 initial distributionPsS init (s)= 1,AP finite set atomic propositions,L : 7 2AP labeling function.Without loss generality consider finite MDPs (i.e., S, Act AP finitesets), terminal states MDP. Precisely, Act(s) denotes setenabled actions s, sP case Act(s) 6= . actionenabled state s0 P(s, , s0 ) = 1. state s0 -successoranother state s, P(s, , s0 ) > 0. MDP executes follows. initial state sinitselected according stochastic experiment initial distribution init . state s,first non-deterministic choice made enabled actions. Assume actionAct(s) selected. Then, -successor selected randomly accordingdistribution P(s, , ).486fiProMoca: Probabilistic Modeling Analysis Agents Commitment Protocolsready define two necessary rules systematically create MDPProMoca model using operational semantics. Rule [non-prob] captures nonprobabilistic cases. is, non-probabilistic firing rule (V, B)(V 0 , B 0 ),performed configuration (V, B), result single distribution mapsconfiguration (V 0 , B 0 ) 1.(V, B)(V 0 , B 0 ) firing rule(V, B)((V 0 , B 0 )) = 1[non-prob]Rule [prob] handles probabilistic choices, resulting distribution associatesprobability di (V, Bi ) i. Note V remains unmodified transition.(V, (p1 )B1 . . . (pn )Bn )((V, Bi )) = pi[prob]Proposition 1. ProMoca model = (Var , Vinit , C, G, Bagn |||Bbel1 ||| . . . |||Bbeln )exists corresponding MDP = (S, Act, P, init , AP, L).Proof: given ProMoca model O, following procedure constructs corresponding MDP M. Below, use Dom(var) denote domain variable var VarB denote Bagn |||Bbel1 ||| . . . |||Bbeln .1. Creation AP : every value val Dom(var) every variable var Var addnew proposition ap AP . instance, variable engine-status elementV ar domain Dom(engine-status) = {unknown, operational, malfunction,maintenance}, add propositions engine-status-unknown, engine-status-operational,engine-status-malfunction, engine-status-maintenance AP , correspondvalues unknown, operational, malfunction, maintenance engine-status,respectively.2. Creation L: Add state every combination propositionsAP omitting combinations include mutually exclusive propositions. setpropositions mutually exclusive (i.e., cannot hold state),created domain variable Step 1. instance, fourpropositions created domain engine-status mutually exclusive.Update labeling L created state using corresponding combinationpropositions. instance, considering propositions first step, create four states s0 , s1 , s2 , s3 , set labeling function follows: L(s0 ) ={engine-status-unknown}, L(s1 ) = {engine-status-operational }, L(s2 ) = {enginestatus-malfunction}, L(s3 ) = {engine-status-maintenance}. Noteone-to-one correspondence labels states valuations behaviorsconfigurations. result, also direct correspondence statesconfigurations behavior.3. Creation init : Set init probability state,labeling corresponds valuation Vinit , 1, probabilitiesstates 0.487fiGunay, Liu & Zhang4. Creation Act: every assignment behavior B add corresponding actionAct. Besides, every commitment c C add set meta-actions Act,correspond state changes c.5. Creation P: First, state determine set enabled actionsEActEAct. action act enabled state (i.e., act Acts ) onefollowing conditions hold:act corresponds assignment occurs configuration conf ,valuation V conf corresponds labeling state(i.e., L(s)). Note correspondence state configurationalready described Step 2, correspondence actionassignment already described Step 3. Intuitively, condition captures[prefix] rule. is, next behavior element apply configurationassignment, action corresponds assignment enabledstate corresponds configuration.act corresponds meta-action change state commitment,act performed (according algorithms rules definesemantics commitments) configuration conf , correspondslabeling state (i.e., L(s)). condition captures statechanges commitments.Then, state s, ActEincludes one actions change state(s)commitment(s), single transition probability 1 set destinationstate labels updated commitment states according algorithms rulesdefine semantics commitments. rest actions ignored,ActEincludes one actions change state(s) commitment(s).words, commitment states updated instantaneously needed,agent action occurs. Otherwise, actions updatePcommitmenti=Nstates, transition action act ActEprobabilityp/acti=0 pi setdestination states labeled according correspondencesactions assignments, pi probability value action actidefined configuration conf corresponds state s, Ntotal number actions ActE.Note procedure describe proof Proposition 1 creates finiteMDP, since number variables (and domains), number assignmentsProMoca model finite. Also note actual computational complexityprocedure occurs due last step, determine transition probabilitiesMDP, done linear time respect number generated statesStep 2 actions Step 4. However, clear number states MDPexponential number variables domains corresponding ProMocamodel (see Step 1). situation commonly known state space explosion problemconstitutes theoretical lower bound probabilistic model checking (Baier &Katoen, 2008).488fiProMoca: Probabilistic Modeling Analysis Agents Commitment Protocols3.3 Formal Propertiessection formalize compliance goal satisfaction properties using PLTL(Baier & Katoen, 2008), probabilistic variant Linear Temporal Logic (LTL)(Pnueli, 1977). LTL formula defined set atomic propositions AP usingtemporal operators globally (G), eventually (F), (U). Satisfaction LTLformula defined respect infinite sequence states = s0 , s1 , . . . follows.G holds si , holds future states sj j.F holds si , holds least one future state sj j.U 0 holds si , holds future states sj 0 holds future sk ,j < k.PLTL extends LTL probabilistic operator Px (), x RLTL formula. Intuitively, Px () holds MDP model, probability satisfyinggreater equal x. define computation probability detail Section 4.Sections 3.3.1 3.3.2, use , , PLTL formulae logical conjunction,disjunction, implication, negation, respectively.3.3.1 ComplianceCompliance target agents behavior commitment protocol first propertyparticularly aim verify ProMoca. Basically, target agent fulfillsactive commitments commitment protocol, target agents behaviorcomplies commitment protocol. However, due interdependence among agentsuncertainty agents behaviors, usually possible determineagents compliance exactly. instance, aerospace example, manufacturerscompliance depends behaviors suppliers. Hence, define compliancetarget agents behavior commitment protocol relaxed manner respectthreshold C defines minimal acceptable ratio fulfillment target agentsactive commitments. Precisely, commitment target agent, commitmentbecomes active, commitments fulfillment probability greater equalthreshold C . Below, B Bagn |||Bbel1 ||| . . . |||Bbeln .Definition 4. Given ProMoca model (V ar, Vinit , C, G, B) corresponding MDP(S, Act, P, init , AP, L), target agents behavior Bagn complies commitmentprotocol C respect threshold C , following PLTL formula holds:commitment(c-id, debtor, . . . ) C debtor = agn :PC (G(c-id-state-active F(c-id-state-fulfilled c-id-state-released)))Intuitively, every commitment protocol, target agent debtor,commitment becomes active given state MDP, commitmentsprobability finally becoming fulfilled released future state greater489fiGunay, Liu & Zhangequal threshold C . Note Definition 4, omit commitment parameters (i.e.,instead use . . .) irrelevant compliance.Even tough threshold C relaxes requirements compliance, Definition 4still strict notion compliance domains, since requires fulfillment everyactive commitment, ignores compensations case violation. However,discussed Section 2, compensation useful widely used mechanism manydomains. Accordingly, define weak compliance, considers compensation, follows:Definition 5. Given ProMoca model (V ar, Vinit , C, G, B) corresponding MDP(S, Act, P, init , AP, L), target agents behavior Bagn weakly complies commitment protocol C respect threshold C , following PLTL formula holds:commitment(c-id, debtor, . . . ) C debtor = agn :PC (G(c-id-state-activeF(c-id-state-fulfilled c-id-state-released c-id-state-compensated)))Intuitively, every commitment protocol, target agent debtor,commitment becomes active given state MDP, commitmentsprobability finally becoming fulfilled, released, compensated future stategreater equal threshold C .Let us explain compliance satisfied failed example. Since computation probabilities MDP rather involved adequate manually,use simplified case aerospace aftercare example, manufacturerservice engine supplier timely delivers necessary parts maintenance.Suppose manufacturer believes supplier delivers parts timeprobability 0.9. Ignoring details, compliance threshold C set 0.8,verification process concludes manufacturer complies protocol, sinceprobability timely servicing engine threshold. hand,compliance threshold C set 0.95, verification process concludesmanufacturer fails comply protocol, since probability timely servicingengine threshold.3.3.2 Goal Satisfactionsecond property aim analyze ProMoca goal satisfaction, defineswhether target agent satisfy goals enacting commitment protocol. However,case compliance, usually possible exactly determine goal satisfactiondue interdependence among agents uncertainty multiagent system. Hence,before, define threshold defines acceptable ratio satisfaction goalstarget agent.Definition 6. Given ProMoca model (V ar, Vinit , C, G, B) corresponding MDP(S, Act, P, init , AP, L), target agent satisfy goals G enacting commitment protocol C respect threshold , goal G, PLTL formulacorresponds goals type holds below:490fiProMoca: Probabilistic Modeling Analysis Agents Commitment Protocolspersistent achievement goal satisfied, probability achievingsatisfaction condition sat infinitely often greater equal .pagoal(sat) G : PS GF(sat)[pa-sat]persistent maintenance goal satisfied, probability maintainingsatisfaction condition sat every reachable state greater equal .pmgoal(sat) G : PS G(sat)[pm-sat]one-time achievement goal precondition pre holds, satisfiedprobability reaching termination condition ter satisfaction condition sat achieved, greater equal . Intuitively, goalterminated achieved.agoal(pre, sat, ter) G : PS G(pre ( ter U sat))[a-sat]one-time maintenance goal precondition pre holds, satisfiedprobability maintaining satisfaction condition sat reaching terminationcondition ter greater equal . Intuitively, satisfaction conditionmaintained goals termination.mgoal(pre, sat, ter) G : PS G(pre (sat U ter))[m-sat]Let us explain goal satisfaction satisfied failed simplified caseNetBill example, merchant persistent achievement goal receivepayments customers. Suppose merchant believes customerpurchases certain good every day probability 0.5. Ignoring details,goal satisfaction threshold set 0.25, verification process concludesmerchant satisfies goal, since probability receiving payment daily basishigher threshold. hand, goal satisfaction threshold C set0.75, verification process concludes merchant fails satisfy goal, sinceprobability receiving payment daily basis lower threshold.3.4 Remarks PROMOCA Syntax Semanticsdesigning ProMocas modeling language influenced process algebracommunicating sequential processes (Hoare, 1978), successfully used modelingvarious concurrent systems. However, line objective verifying propertiesagents behavior context commitment protocol uncertainty, designednovel language model commitment protocols agents, taking accountgoals, beliefs, behaviors. One main motivations designing ProMocaease modeling commitment protocols agents providing intuitive languageelements model them, differs ProMoca existing analysis tools. discussProMocas modeling related benefits comparing existing tools detailSection 7. rest section discuss important aspects ProMocasmodeling language.491fiGunay, Liu & ZhangProMoca model involves three types variables capture global, localinternal (commitment subscription) state. distinction among variable typesused type checking syntactic level restrict use different variable typescertain language elements (e.g., commitments include global variables sincepublic, target agents beliefs agents behaviors cannot includelocal variables since private, etc.). hand, semantic modelProMoca, variables interpreted global variables. straightforward seetype checking variables syntactic level sufficient correctly defineverify PLTL property, including compliance goal satisfaction. Hence, safeconsider variables global variables semantic level long checkedsyntactic level.discuss ProMoca semantics, states commitment determinedProMoca according evaluation commitments conditions (e.g., consequent).Hence, ProMoca provide explicit meta-actions transitions (e.g., fulfillment). exceptions commit, release, cancel. Initiation commitmenthandled commit done previous work. Furthermore, explicit releasecancellation provides flexibility modeling. instance, many protocols involvecommitments regulate exceptional situations. commitments normally become active unless corresponding exception occurs. Hence, stay conditional stateeven interaction involved parties completed. situation,creditors commitments release debtors conditional commitments. Cancellation used debtor immediately terminate commitment (byviolating it) without waiting occurrence commitments termination condition.useful debtor realizes cannot fulfill commitment. cancelingcommitment, debtor gives time creditor recover undesirable situationoccurs due violation commitment.final remark probabilistic modeling, note probability computationsProMoca model may become rather complex. examples demonstrate, manysituations behaviors belief may arbitrary nesting long sequences actions,involve non-deterministic probabilistic choices. Furthermore, parallel composition interleaving behaviors introduces additional complexity. result scalabilitymodel checking may suffer verifying compliance goal satisfaction large models.common problem probabilistic model checking. address issue detailnext two sections, show ProMoca verify compliance goal satisfactionmany realistic situations, although affected scalability issues.4. Verificationsection present overall verification process ProMoca, depictedFigure 3. inputs verification process ProMoca model, typeproperty (i.e., compliance goal satisfaction) aimed verified, realvalue corresponds threshold property (i.e., C ). First, createMDP input ProMoca model according operational semanticsProMoca Section 3. parallel, extract PLTL property (i.e., propertytype relevant propositions ProMoca model), verify, according492fiProMoca: Probabilistic Modeling Analysis Agents Commitment ProtocolsinputPROMOCA model, property type, thresholdextract PLTL propertycreate corresponding MDPPLTL formulaMDPcreate corresponding Rabin automatonRabin automaton Rcreate product MDP RProduct MDP Rapply probabilistic model checking algorithmproperty failsproperty holds>Figure 3: overview ProMocas verification process.input. Then, create (deterministic) Rabin automaton R using standardtranslation PLTL formula Rabin automaton (Baier & Katoen, 2008).MDP Rabin automaton R, create product R,also MDP (Baier & Katoen, 2008). last step, use probabilistic modelchecking algorithm present Algorithm 4, R compute satisfactionprobability M. result computation greater equal inputthreshold value, verification process returns > indicate property satisfied.hand, computed value threshold, verification processreturns indicate property satisfied.property satisfied non-probabilistic model checking, trace (i.e., counterexample) generated explain failure occurs result model checking.However, probabilistic model checking clear definition counterexample since models probabilistic, properties defined respect thresholds.Although, recent research probabilistic model checking addressed issue several approaches proposed (Andres, DArgenio, & Rossum, 2009; Han, Katoen, &Berteun, 2009; Schmalz, Varacca, & Volzer, 2009), ProMoca currently providefunctionality generate counterexample.ProMoca uses reachability checking algorithm developed previous work (Gunay et al., 2015). present algorithm Algorithm 4 completeness.inputs Algorithm 4 MDP MR = (S, Act, P, init , AP, L), productMDP Rabin automaton R, extracted input ProMocamodel, S, set accept states R input. Algorithm 4 returns P R (T ),minimal probability reaching set projected accept states productMDP. Algorithm 4, use auxiliary function P re(s) returns pre-statesstate MDP. Formally, P re(s) = {s0 | P(s, , s0 ) > 0}. use ps record493fiGunay, Liu & ZhangAlgorithm 4: Computation reachability probabilities target states.input : R = (S, Act, P, init , AP, L),output: ps0123456789101112let cur pre ;foreach curlet ps 1;cur 6=foreach curcur cur \{s};foreach s0 P re(s)pre pre {s0 };foreach (s0 , t, ) P rlet pn = 0.0;foreach s00 (s00 ) > 0pn pn + (s00 ) ps00 ;ps0 in(ps0 , pn );13141516cur pre ;pre ;return ps0 ;probability reaching s. Due existence non-determinism MDP,result reachability checking range instead single value. Algorithm 4 adoptcautious approach compute minimal probability reaching .main idea reachability checking start target states proceed backwards step step updating reachability probabilities MDP states. Accordingly,first 0 assigned cur (Line 1), represents current states iterativeprocess, probabilities states set 1 (Lines 2-3). Then, stateremoved cur (Lines 5-6) pre-state s0 (Line 7) probabilitiesupdated follows: enabled transition s0 distribution , variable pncreated (Line 9-10) record probability reaching 0 s0 via . Afterwards,sum (s00 ) ps00 s00 satisfying (s00 ) > 0 assigned pn , i.e., pn sumtransition probabilities distribution times corresponding successor states probability 0 (Lines 11-12). keep minimal probability, ps0 set minimum valueps0 pn using function (Line 13). states cur considered, curset pre-states (Line 14). loop Line 4 terminates pre-statesleft (i.e., minimal probability s0 computed stored ps0 ). Finally, ps0returned probability reaching s0 (Line 16).5. Evaluationimplement ProMoca framework PAT (Process Analysis Toolkit) (Sun, Liu, Dong,& Pang, 2009), state-of-the-art extendable model checking framework pro494fiProMoca: Probabilistic Modeling Analysis Agents Commitment Protocolsvides various probabilistic model checking techniques PLTL model checkingreachability checking. evaluate efficiency scalability ProMoca, conductedset computational experiments. experiments compared ProMocas performance PRISM (Kwiatkowska, Norman, & Parker, 2011), well-knownprobabilistic model checker. used following four examples experiments:AeroBase: example use aerospace aftercare case. However, assumemanufacturer always sufficient supply spare parts. Hence,consider interactions manufacturer suppliers. example involves commitment model purchase engine commitment modeloverall maintenance agreement. commitments also compensating commitments. Hence, four commitments model base termsagreement. Besides, whole duration agreement, two commitments month model servicing responsibility manufacturer(e.g., twelve month agreement 24 commitments). considerscenario manufacturers perspective. beliefs manufacturer involveprobability engine failure probability repairing failed engine on-time.AeroFull: example, use aerospace aftercare case, assumemanufacturer always sufficient supply spare parts. Hence, considernew commitment month agreement model provision suppliessuppliers (e.g., 36 commitments twelve month agreement). Since,manufacturer interacts suppliers, beliefs manufacturer involveprobability successfully receiving spare parts suppliers.NetBill: example model well-known NetBill protocol (Sirbu & Tygar, 1995). NetBill provides secure protocol transactions two parties(e.g., merchant customer) online environments. standard protocolwidely used commitment literature evaluation. involves threecommitments model offer, payment, delivery phases transaction.experiments, consider arbitrary number transactions merchantset customers merchants perspective. merchants beliefs involveprobability customers acceptance merchants offers.AGFIL: example models real world car insurance claim processing case (Desaiet al., 2009). AGF Irish Life Holdings (AGFIL), subsidiary Allianz, insurancecompany Ireland underwrites car insurance policies. AGFIL cooperatescall center consulting firm process policy holders claims. policy holdercontacts call center make claim. call center forwards claim AGFIL.Then, AGFIL requests investigation claim consultant decideclaims validity. consultant provides report inform AGFILresults investigation. Using investigation report, AGFIL decides whetherpay claimed repair cost. example includes three commitments modelinteractions AGFIL three stakeholders, namely, policy holder,call center, consultant. experiments, consider arbitrary numberclaims set policy holders verify properties AGFILs behavior.Beliefs AGFIL involve probability claim validity.495fiGunay, Liu & Zhangrun experiments PC equipped Intel i7 3.0 GHz processor 8GBRAM, running 64-bit Windows 8 operating system. conducted experimentsverify compliance goal satisfaction properties. However, experiments,observed similar results properties. Hence, brevity, report resultscompliance propertys verification. Table 1 report execution times (inseconds) ProMoca PRISM verifying compliance properties describedexamples. model checking process takes 1200 seconds, report timeout(T/O). case, reported average execution time thirty runs eliminatespike execution times may occur due use resources processessystem. report variance execution times since observed negligible values.evaluate ProMocas scalability respect different complexities examples, use control parameter example determines size corresponding ProMoca model. AeroBase AeroFull examples parameternumber months engine manufacturer committed service engine,represented mon Table 1. NetBill example control parameter numbercustomers merchant interacts, represented cus Table 1. AGFILexample control parameter number claims made policy holders,represented cla Table 1.discussing results Table 1, let us explain characteristicsexample models described parameters affect them. aerospace examples,outcome commitment models service agreement particular month,depends outcomes previous months commitments. is, manufacturerfails service engine previous month, higher risk engine failurecurrent month, may cause manufacturer violate commitment keepengine operational. modeled manufacturers beliefs. Accordingly,dependencies, models aerospace examples become substantiallycomplex duration service agreement (i.e., number months mon) increases.Furthermore, AeroFull example considers also behaviors suppliers partmanufacturers beliefs, increases complexity corresponding modelseven further. Hence, examples capture complex realistic situations.models NetBill AGFIL examples relatively simpler aerospaceexamples. use situation evaluate ProMoca cases onecommitment protocols composed complex protocol. twopossible compositions, namely sequential parallel. used NetBill example examineparallel composition commitment protocols. end, increase numbercustomers merchant interacts parallel 1 10. is, 10 customers,merchant enacts 10 instances NetBill protocol parallel. Parallel composition causesmodels size grow exponentially. Hence, significant impact model complexity.used AGFIL example examine sequential composition independent protocols.end, increase number customer claims 10 100. claim processedsequentially one one (i.e., first come first served) AGFIL. Impact independentsequential protocols model complexity substantially less parallel compositionprotocols, since protocol instance verified independently. Therefore, model sizegrowth linear number claims. Note Table 1, first reported executiontime AeroBase example mon = 6. mon less 6 ProMoca496fiProMoca: Probabilistic Modeling Analysis Agents Commitment ProtocolsAeroBaseAeroFullNetBillAGFILmon ProMoca PRISM mon ProMoca PRISM cus ProMoca PRISM cla ProMoca PRISM67891011120.421.333.769.8127.8684.49242.371.327.3533.68175.81T/OT/OT/O34567890.030.160.753.6217.0185.56365.820.100.273.8027.68591.36T/OT/O456789100.010.010.020.040.090.150.310.070.120.180.381.254.6832.234050607080901000.0240.0300.0410.0510.0630.0720.0872.8224.1975.4316.8438.3969.84111.384Table 1: Execution times ProMoca PRISM verify compliance target agentAeroBase, AeroFull, NetBill, AGFIL examples.PRISM verify compliance almost instantaneously milliseconds. Similarly,report results AeroFull, NetBill, AGFIL examples control parametersstarting mon = 3, cus = 4 cla = 40, respectively.Table 1 indicates two main results. First, ProMoca clearly outperforms PRISMterms execution time verifying agents compliance commitmentsuncertainty. main reason consideration commitments first-class objects syntax semantics ProMoca. Accordingly, ProMoca takes advantagededicated representation, uses several model checking techniques,developed particularly commitment protocols, reducing model size improve efficiency model checking. instance, ProMoca uses specific partial order reductiontechnique exploits dependencies among commitments reduce size MDPmodels state space (Gunay et al., 2015). Effects reduction technique easy seeespecially NetBill example, large number parallel independentcommitments NetBill protocol instance different customer. ProMoca effectively uses dedicated partial order reduction technique detect independencecommitments, reduces model size, provides clear advantage NetBill example. conclusion, results show development dedicated model checking toolsProMoca necessary efficiently verifying agents behavior respectcommitment protocols taking uncertainty account.second main result usability ProMoca practical cases. NetBill exampleProMoca verifies compliance milliseconds ten protocols executed parallel.Similarly, AGFIL example, ProMoca verifies case, 100 claims considered,almost immediately. AeroBase example, ProMoca verifies compliance evenwhole 12 month agreement within reasonable time. complete aerospace scenario,ProMoca verifies nine month agreement successfully. Note given sufficient timeresources ProMoca also verify whole 12 month agreement. However, modelinvolves large number dependent commitments, complex behaviors beliefs,results show, ProMoca suffers exponentially growing execution times,result rapidly growing model size situations. well known issueprobabilistic model checking, unavoidable (Clarke, Grumberg, & Peled, 1999; Baier497fiGunay, Liu & Zhang& Katoen, 2008). Nevertheless, comparative results PRISM show ProMocasignificantly efficient general purpose probabilistic model checkers verifyingcompliance goal satisfaction properties agent commitment protocol.6. Related Worksection provide non-exhaustive survey related research. startprevious work, study various general properties commitment protocols (i.e., independent behaviors enacting agents), verification. Yolum (2007) developedframework verify effectiveness, consistency, recovery, fault-tolerance propertiescommitment protocols. commitment protocol effective, deadlock-free. consistent, involve conflicting propositions commitment conditions. Finally,least one role commitment protocol capable taking certain recovery actioncase failure, commitment protocol recoverable. Besides, role capable recovering commitment protocol, fault-tolerant. addition definingproperties, Yolum also provides set algorithms verification, basedanalyzing states arbitrary runs commitment protocols. Desai et al. (2007a) alsostudy deadlock-free live commitment protocols. develop several models commitment protocols PROMELA language SPIN model checker (Holzmann, 2004),define deadlock-freeness liveness properties LTL. Later, Telang Singh (2012) useNuSMV model checker Computation Tree Logic (CTL) verify correctness businesspatterns modeled commitment protocols. Gerard Singh (2013) introduceapproach specify commitment protocols refinements guarded messages.implement approach using MCMAS model checker.Montali, Calvanese, De Giacomo (2014) develop data-aware framework usingfirst-order formalism study impact data available agents, commitmentsevolution. also show rich set temporal properties -calculus verifiedframework. El-Menshawy et al. (2013) develop ACTLC , extensionCTL, introducing set operators model semantics active commitments.proposed semantics commitment operators influenced previous proposalSingh (2008). paper shows proposed logic reduced another logicGCTL*, verified CWB-NC model checker (Bhat, Cleaveland, & Groce,2001). Later, El Kholy et al. (2014) propose another extension CTL, calledCTLCC , capture lifecycle conditional commitments. also extend standardsymbolic model checking algorithm CTL line proposal. Sultan, Bentahar,Wan, Al-Saqqar (2014) propose PCTLC, extends probabilistic CTL, verifycommitment protocols. PCTLC includes social operators represent active commitmentsfulfillment. proposed model checking technique consists set reductionrules reduce PCTLC model checking problem PCTL model checking,implemented PRISM model checker.proposal differs studies several points. Firstly, none studiesconsider development modeling language ProMoca. either use modeling languages general purpose model checkers abstract formalism modeling.Secondly, studies consider behaviors agents, since aim verify generalproperties commitment protocols. Finally, probabilistic models considered498fiProMoca: Probabilistic Modeling Analysis Agents Commitment Protocolsprevious work. exception work Sultan et al. (2014), uses probabilistic variant CTL. However, Sultan et al. consider active commitments. Besides,due use CTL, consider different model checking algorithm useProMoca.recent work aim analyze commitment protocol agents point view.Objectives studies closer objective ProMoca. Marengo et al. (2011)discuss agents control events commitment protocols. Basically, agent controlevent, agent initiate event, another agent capableinitiate event committed so. also discuss notion safety. commitmentsafe debtor, debtor controls antecedent avoid situationscommitment becomes active, debtor controls consequent thereforeable fulfill commitment becomes active. Marengo et al. develop REGULAframework formalize control safety properties, also provides reasoning rulesevaluate systems properties. However, develop practical reasoneralso address uncertainty.Gunay Yolum (2013) study feasibility commitment protocol agent, considering time constraints resources requirements satisfied agentfulfill commitments. commitment protocol feasible agent, agent ownssufficient resources, agent creditor set commitments provideagent resources fulfill commitments time. They, model verification feasibility constraint satisfaction problem. Gunay Yolum discuss potential behaviorsagents describe unexpected behaviors (e.g., violations commitments) mayhandled. However, consideration behaviors address probabilistic modelsrequires manual configuration framework. Kafal, Gunay, Yolum (2014) develop GOSU framework provides reasoning mechanism determine goal supportcommitment protocol, similar goal satisfaction property. model goalsupport reachability property use reactive event calculus reasoning (Chesaniet al., 2013). approach considers achievement goals, avoid uncertaintyassuming agents always honor commitments.Torroni colleagues develop monitoring framework commitments using SCIFFabductive logic programming proof-procedure (Alberti, Chesani, Gavanelli, Lamma, Mello,& Torroni, 2008; Chesani et al., 2013). main motivation develop formaloperational framework efficiently monitors commitments verifies complianceagents actions protocols enact. Since main interest frameworkrun-time monitoring, Torroni colleagues pay special attention commitments timeconstraints. Although constraints studied also researchers, Torronicolleagues provide concrete operational framework handle constraintsrun-time. purpose utilize event driven implementation event calculuscalled reactive event calculus, based maximum validity interval conceptcached event calculus introduced Chittaro Montanari (1996). Use reactiveevent calculus eliminates necessity backward reasoning event occurrenceaccordingly possible reasoning efficiently run-time. monitoring frameworkProMoca complementary other. ProMoca handles design-timeissues, framework addresses run-time monitoring.499fiGunay, Liu & ZhangCompliance addressed also context norms (e.g., prohibitions). Vasconcelos (2005) develops declarative approach analyze electronic institutions determinewhether agents commit fulfill norms institutions. Aldewereld, Vazquez-Salceda,Dignum, Meyer (2006) develop framework verify norm compliance agent behavior templates, call protocols. consider sequential protocolsdefine norm compliance using LTL. semi-automated theorem-proving approach usedverification instead model checking. Craven Sergot (2008) develop nC+extension action language C+ (Giunchiglia, Lee, Lifschitz, McCain, & Turner, 2004).nC+ introduces two new forms rules, namely state action permission laws, representing normative aspects multiagent systems. Semantics language definedrespect colored labeled transition systems, represent desired undesiredstates, also transition modeled multiagent system. associating subset transitions particular agents actions, verify compliance propertiesagent behaviors. nC+ provides rich language model multiagent systems. However,Craven Sergot consider uncertainty accordingly provide probabilistic modeling reasoning. Besides, norms defined respect lifecyclecommitments. Instead, norms considered (if-then) rules. Furthermore,represent relations different norms explicitly do, instancecompensation. interesting future direction investigate two formalismcombined develop expressive modeling analysis environment.terms model checking, relevant work ProMoca MCMAS,state-of-the-art model checker dedicated verification multiagent systems (Lomuscio, Qu, & Raimondi, 2009). MCMAS uses Interpreted Systems Programming Language(ISPL) modeling, based interpreted systems semantics (Fagin, Halpern,Moses, & Vardi, 2003). ISPL, multiagent system modeled composition setagents environment. agent defined set internal states using setprivate variables, protocol, models decision making mechanismagent. Agents interact publicly observable actions. Local states agents evolveaccording evolution function, uses joint actions agents. MCMAS supportsverification agent-oriented logics, Alternating-time Temporal Logic (Alur, Henzinger, & Kupferman, 2002) epistemic operators (Fagin et al., 2003), using OrderedBinary Decision Diagrams (Bryant, 1986) symbolic model checking techniques.several differences MCMAS ProMoca. MCMAS general modelchecker types multiagent systems, ProMoca focuses verifying agent behaviorscommitment protocols. Accordingly, ProMoca provides dedicated language elementsdefining commitment protocols. Moreover, ProMoca aims verify agents behaviortaking uncertainty agents beliefs account. achieve this, ProMoca providesprobabilistic modeling reasoning capabilities agent beliefs. ProMoca useinterpreted systems semantics, since aim verify epistemic logic specifications.Finally, ProMoca uses automata based approach instead symbolic model checking,appropriate verifying properties.recent years, commitments used model various practical situations.Desai, Chopra, Arrott, Specht, Singh (2007b) provide commitment-based solutionformalizing foreign exchange market protocols. show rigorous specificationverification protocols via commitments solve many issues emerge existing500fiProMoca: Probabilistic Modeling Analysis Agents Commitment Protocolssystems due informal business semantics. Singh, Chopra, Desai (2009) proposecommitment-based service oriented architecture, replaces invocation-based serviceobjects engagement-based autonomous business services. set transaction patternscommitments proposed, reflect business requirements various commonbusiness transactions, provide basic building blocks develop complex interactions.Benefits approach flexible enactment transactions, ease specificationcomposition business processes. Kafal, Gunay, Yolum (2012, 2013) developmethod using commitments capture violation privacy policies social networks.model privacy policies parties social networks using commitments,employ model checking policies capture violations. proposed approachcapture privacy breaches cannot detected traditional systems. Furthermore,prediction tool also developed utilizes Semantic Web technologies capture potential privacy breaches may occur future due evolution social networkrelations. Telang, Kalia and, Singh (2012, 2015) conducted experimental evaluationcommitment-based Comma methodology, show Comma outperforms traditional HL7 Messaging Standard healthcare process modeling. Chopra Singh (2016b)introduce Interaction-Oriented Software Engineering commitment-based paradigmcapture social aspects sociotechnical system emphasizing openness, autonomy, accountability. Chopra Singh (2016a) also develop Custard framework, providesrelational schema queries commitments lifecycle, build abstractionlayer underlying information stores databases.7. Discussionpaper presented ProMoca framework modeling analyzing agent behaviors commitment protocols taking uncertainty account. main motivationdeveloping ProMoca analyze target agents behavioral properties enactingcommitment protocol respect goals, beliefs agents uncertainbehaviors. recent years, commitments applied solve practical challengesmany domains e-commerce, sociotechnical systems, privacy, security, healthcare. Modeling verification essential aspects development processpractical systems, mainly ensure correctness effectiveness systems. ProMocaprovides novel analysis tool handle two key aspects development providingexpressive modeling language efficient model checking algorithm. modelinglanguage ProMoca expressive enough model practical situations demonstrate examples. fact, ProMoca provides expressive power neededprevious work commitments. model checking algorithm ProMocaefficient handle complex situations empirical results show.However, ProMoca also certain limitations. terms modeling, ProMocaextended model wider range practical cases introducing new languageelements discuss future work end section. terms verification,well-known scalability issues probabilistic model checking applies also ProMoca.However, results show ProMocas efficiency many practical situations. comparison state-of-the-art general purpose probabilistic model checker PRISM alsoshows ProMoca outperforms PRISM verifying agents compliance goal501fiGunay, Liu & Zhangsatisfaction commitment protocol. Finally, social commitments frameworkall-around solution model every practical situation. However, integratedapproaches multiagent systems model reason complex practical situations, e.g., integration artifacts (Baldoni, Baroglio, & Capuzzimati, 2015)normative concepts prohibitions authorizations (Chopra & Singh, 2016a).stated earlier, various general purpose tools, PRISM MCMAS, used verify agents respect commitment protocols.also several reasoning methodologies handle uncertainty (Eiter & Lukasiewicz, 2003;Richardson & Domingos, 2006). Let us justify, develop new tool toolsmethodologies already exist. mainly two motivations behind development ProMoca new tool. first one ease modeling. Since generalpurpose tools support commitments, provide facilities modelthem. Therefore, able use one tools commitments, first modelcommitment developed tool. According experience, nontrivial error-prone task. Furthermore, models mostly developed consideringspecific properties aimed verified target system. Hence, reusemodels properties systems also limited. ProMoca solves issuesproviding expressive modeling language includes various facilities model commitments. Hence, users easily model commitment protocols, without worryingunderlying model commitments. Besides, ProMoca based general modelcommitments independent particular properties application specificassumptions. Hence, used domain verify arbitrary properties.second motivation efficiency. experimental results clearly demonstrate, stateof-the-art probabilistic model checker PRISM cannot achieve efficiency ProMocaverifying agents compliance goal satisfaction commitment protocol. mainreason ProMocas efficiency utilization commitment semantics efficientlyverify addressed properties.ProMoca used model wide majority commitment protocolsconsidered previous work. However, still open many improvements. majorimprovement extend ProMoca explicit representation time. Currently,time modeled ProMoca abstract manner using regular variablesdemonstrated examples. sufficient many domains, however, especiallymodeling commitments agent real-time systems, explicit notion timenecessary. Another improvement introduction numerical variables arithmetic operations ProMoca. variables necessary precisely model resource relatedissues (e.g., money, number available spare parts, etc.). Addition featuresfairly straightforward syntactic semantic point view. However, verificationtime numerical variables increase complexity model checking substantially. Hence,development novel abstraction reduction techniques use commitment semantics,essential efficient scalable model checking models. ProMoca alsoextended syntactic elements simplify modeling commitments. exampleuse parameters commitment specifications modeling generic commitments.Beside improvements ProMoca, also aim extend ProMocamodel commitment concepts choice coordination (Baldoni, Baroglio,Chopra, Desai, Patti, & Singh, 2009), relevant properties feasibility (Gunay &502fiProMoca: Probabilistic Modeling Analysis Agents Commitment ProtocolsYolum, 2013) safety (Marengo et al., 2011). Besides, plan support normativeconcepts obligations prohibitions, relevant commitments (Boella& van der Torre, 2004; Craven & Sergot, 2008; Agotnes, van der Hoek, & Wooldridge,2010; Criado, Argente, & Botti, 2011). Last least integration ProMocarecent work dynamic protocol creation open systems interesting future work(Yolum & Singh, 2007; Artikis, 2009; Meneguzzi, Telang, & Singh, 2013; Gunay, Winikoff,& Yolum, 2013, 2015; Cranefield, Savarimuthu, Meneguzzi, & Oren, 2015). researchaims automate creation protocols run-time, requires agents agreecommitment protocol regulate interaction according requirements.achieve this, individual agents able analyze behaviors respectrequirements commitment protocol, ProMoca valuable tool.Acknowledgmentsthank anonymous reviewers insightful comments. work supportedFormal Verification Cloud project Grant No: M4081155.020 BringAdvanced Model Checking Techniques Real-world Problems project Grant No:M4011178.020.ReferencesAlberti, M., Chesani, F., Gavanelli, M., Lamma, E., Mello, P., & Torroni, P. (2008). Verifiable agent interaction abductive logic programming: SCIFF framework. ACMTransactions Computational Logic, 9 (4), 29:129:43.Aldewereld, H., Vazquez-Salceda, J., Dignum, F., & Meyer, J.-J. C. (2006). Verifying normcompliancy protocols. Agents, Norms Institutions Regulated Multi-AgentSystems, pp. 231245.Alur, R., Henzinger, T. A., & Kupferman, O. (2002). Alternating-time temporal logic.Journal ACM, 49 (5), 672713.Andres, M. E., DArgenio, P., & Rossum, P. (2009). Significant diagnostic counterexamplesprobabilistic model checking. Proceedings 4th International Haifa Verification Conference Hardware Software: Verification Testing, pp. 129148.Springer-Verlag.Artikis, A. (2009). Dynamic protocols open agent systems. Proceedings 8thInternational Conference Autonomous Agents Multiagent Systems, pp. 97104.Baier, C., & Katoen, J.-P. (2008). Principles Model Checking. MIT Press.Baldoni, M., Baroglio, C., & Capuzzimati, F. (2015). Programming JADE Jason agentsbased social relationships using uniform approach. Koch, F., Guttmann, C.,& Busquets, D. (Eds.), Advances Social Computing Multiagent Systems, Vol.541, pp. 167184. Springer.Baldoni, M., Baroglio, C., Chopra, A. K., Desai, N., Patti, V., & Singh, M. P. (2009).Choice, interoperability, conformance interaction protocols service chore503fiGunay, Liu & Zhangographies. Proceedings 8th International Conference Autonomous AgentsMultiagent Systems, pp. 843850.Bellman, R. (1957). Markovian decision processes. Journal Mathematics Mechanics,38, 716719.Bhat, G., Cleaveland, R., & Groce, A. (2001). Efficient model checking via Buchi tableauautomata. Proceedings 13th International Conference Computer AidedVerification, pp. 3852.Boella, G., & van der Torre, L. (2004). Regulative constitutive norms normativemultiagent systems. Proceedings 9th International Conference PrinciplesKnowledge Representation Reasoning, pp. 255265.Bryant, R. E. (1986). Graph-based algorithms boolean function manipulation. IEEETransactions Compututers, 35 (8), 677691.Chesani, F., Mello, P., Montali, M., & Torroni, P. (2013). Representing monitoringsocial commitments using event calculus. Autonomous Agents Multi-AgentSystems, 27 (1), 85130.Chittaro, L., & Montanari, A. (1996). Efficient temporal reasoning cached eventcalculus. Computational Intelligence, 12 (3), 359382.Chopra, A. K., Dalpiaz, F., Giorgini, P., & Mylopoulos, J. (2010). Reasoning agentsprotocols via goals commitments. Proceedings Ninth InternationalConference Autonomous Agents Multiagent Systems, pp. 457464.Chopra, A. K., & Singh, M. P. (2015). Cupid: Commitments relational algebra.Proceedings 29th AAAI Conference Artificial Intelligence, pp. 20522059.Chopra, A. K., & Singh, M. P. (2016a). Custard: Computing norm states informationstores. Proceedings 2016 International Conference Autonomous AgentsMultiagent Systems, pp. 10961105.Chopra, A. K., & Singh, M. P. (2016b). social machines social protocols: Software engineering foundations sociotechnical systems. Proceedings 25thInternational Conference World Wide Web, pp. 903914.Clarke, Jr., E. M., Grumberg, O., & Peled, D. A. (1999). Model Checking. MIT Press,Cambridge, MA, USA.Cranefield, S., Savarimuthu, T., Meneguzzi, F., & Oren, N. (2015). bayesian approachnorm identification. Proceedings 2015 International Conference Autonomous Agents Multiagent Systems, pp. 17431744.Craven, R., & Sergot, M. (2008). Agent strands action language n C+. JournalApplied Logic, 6 (2), 172191.Criado, N., Argente, E., & Botti, V. (2011). Open issues normative multi-agent systems.AI Communications, 24 (3), 233264.Desai, N., Cheng, Z., Chopra, A. K., & Singh, M. P. (2007a). Toward verification commitment protocols compositions. Proceedings 6th InternationalJoint Conference Autonomous Agents Multiagent Systems, pp. 33:133:3.504fiProMoca: Probabilistic Modeling Analysis Agents Commitment ProtocolsDesai, N., Chopra, A. K., Arrott, M., Specht, B., & Singh, M. P. (2007b). Engineering foreignexchange processes via commitment protocols. IEEE International ConferenceServices Computing, pp. 514521.Desai, N., Chopra, A. K., & Singh, M. P. (2009). Amoeba: methodology modelingevolving cross-organizational business processes. ACM Transactions SoftwareEngineering Methodology, 19 (2), 6:16:45.Desai, N., Narendra, N. C., & Singh, M. P. (2008). Checking correctness business contracts via commitments. Proceedings 7th International Joint ConferenceAutonomous Agents Multiagent Systems, pp. 787794.Eiter, T., & Lukasiewicz, T. (2003). Probabilistic reasoning actions nonmonotonic causal theories. Proceedings Nineteenth Conference UncertaintyArtificial Intelligence, pp. 192199.El Kholy, W., Bentahar, J., Menshawy, M. E., Qu, H., & Dssouli, R. (2014). Conditionalcommitments: Reasoning model checking. ACM Transactions Software Engineering Methodology, 24 (2), 9:19:49.El Menshawy, M., Bentahar, J., El Kholy, W., & Dssouli, R. (2013). Verifying conformancemulti-agent commitment-based protocols. Expert Systems Applications, 40,122138.Fagin, R., Halpern, J. Y., Moses, Y., & Vardi, M. Y. (2003). Reasoning Knowledge.MIT Press, Cambridge, MA, USA.Fornara, N., & Colombetti, M. (2002). Operational specification commitment-basedagent communication language. Proceedings 1st International Joint Conference Autonomous Agents Multiagent Systems, pp. 536542.Gerard, S. N., & Singh, M. P. (2013). Formalizing verifying protocol refinements. ACMTransactions Intelligent Syststems Technology, 4 (2), 21:121:27.Giunchiglia, E., Lee, J., Lifschitz, V., McCain, N., & Turner, H. (2004). Nonmonotoniccausal theories. Artificial Intelligence, 153 (1-2), 49104.Gunay, A., Songzheng, S., Liu, Y., & Zhang, J. (2015). Automated analysis commitmentprotocols using probabilistic model checking. Proceedings 29th AAAI ConferenceArtificial Intelligence, pp. 20602066.Gunay, A., Winikoff, M., & Yolum, P. (2013). Commitment protocol generation. Declarative Agent Languages Technologies X, Vol. 7784 LNAI, pp. 136152. Springer.Gunay, A., Winikoff, M., & Yolum, P. (2015). Dynamically generated commitment protocolsopen systems. Journal Autonomous Agents Multi-agent Systems, 29, 192229.Gunay, A., & Yolum, P. (2011). Detecting conflicts commitments. Sakama, C.,Sardina, S., Vasconcelos, W., & Winikoff, M. (Eds.), Declarative Agent LanguagesTechnologies IX, Vol. 7169 LNAI, pp. 5166. Springer.Gunay, A., & Yolum, P. (2013). Constraint satisfaction tool modeling checkingfeasibility multiagent commitments. Applied Intelligence, 39 (3), 489509.505fiGunay, Liu & ZhangHalpern, J. Y. (2003). Reasoning Uncertainty. MIT Press, Cambridge, MA, USA.Han, T., Katoen, J.-P., & Berteun, D. (2009). Counterexample generation probabilisticmodel checking. IEEE Transactions Software Engineering, 35 (2), 241257.Hoare, C. A. R. (1978). Communicating sequential processes. Communications ACM,21 (8), 666677.Holzmann, G. J. (Ed.). (2004). SPIN Model Checker: Primer Reference Manual.Addison-Wesley.Jakob, M., Pechoucek, M., Miles, S., & Luck, M. (2008). Case studies contract-basedsystems. Proceedings 7th International Joint Conference AutonomousAgents Multiagent Systems: Industrial Track, pp. 5562.Kafal, O., Gunay, A., & Yolum, P. (2012). PROT OSS: run time tool detectingPRivacy viOlaT ions Online Social networkS. IEEE/ACM International Conference Advances Social Networks Analysis Mining, pp. 429433.Kafal, O., Gunay, A., & Yolum, P. (2013). Detecting predicting privacy violationsonline social networks PROT OSS. Distributed Parallel Databases, 32 (1),161190.Kafal, O., Gunay, A., & Yolum, P. (2014). GOSU: Computing goal support commitments multiagent systems. Proceedings 21st European Conference ArtificialIntelligence, pp. 477482.Kafal, O., & Torroni, P. (2012). Exception diagnosis multiagent contract executions.Annals Mathematics Artificial Intelligence, 64 (1), 73107.Kwiatkowska, M., Norman, G., & Parker, D. (2011). PRISM 4.0: Verification probabilisticreal-time systems. Proceedings 23rd International Conference ComputerAided Verification, pp. 585591.Lomuscio, A., Qu, H., & Raimondi, F. (2009). MCMAS: model checker verification multi-agent systems. Proceedings 21st International ConferenceComputer Aided Verification, pp. 682688.Mallya, A. U., & Huhns, M. N. (2003). Commitments among agents. IEEE InternetComputing, 7 (4), 9093.Marengo, E., Baldoni, M., Baroglio, C., Chopra, A. K., Patti, V., & Singh, M. P. (2011).Commitments regulations: Reasoning safety control REGULA.Proceedings Tenth International Conference Autonomous AgentsMultiagent Systems, pp. 467474.Meneguzzi, F., Telang, P. R., & Singh, M. P. (2013). first-order formalization commitments goals planning. Proceedings 27th AAAI ConferenceArtificial Intelligence, pp. 697703.Modgil, S., Faci, N., Meneguzzi, F., Oren, N., Miles, S., & Luck, M. (2009). frameworkmonitoring agent-based normative systems. Proceedings 8th InternationalConference Autonomous Agents Multiagent Systems, pp. 153160.506fiProMoca: Probabilistic Modeling Analysis Agents Commitment ProtocolsMontali, M., Calvanese, D., & De Giacomo, G. (2014). Verification data-awarecommitment-based multiagent system. Proceedings 2014 International Conference Autonomous Agents Multi-agent Systems, pp. 157164.Pnueli, A. (1977). temporal logic programs. Proceedings 18th AnnualSymposium Foundations Computer Science, pp. 4657.Agotnes, T., van der Hoek, W., & Wooldridge, M. (2010). Robust normative systemslogic norm compliance. Logic Journal IGPL, 18 (1), 430.Richardson, M., & Domingos, P. (2006). Markov logic networks. Machine Learning, 62 (1-2),107136.Schmalz, M., Varacca, D., & Volzer, H. (2009). Counterexamples probabilistic ltl modelchecking markov chains. Proceedings 20th International ConferenceConcurrency Theory, pp. 587602. Springer-Verlag.Singh, M. P. (1999). ontology commitments multiagent systems: Toward unification normative concepts. Artificial Intelligence Law, 7 (1), 97113.Singh, M. P. (2008). Semantical considerations dialectical practical commitments.Proceedings 23rd National Conference Artificial Intelligence, pp. 176181.Singh, M. P., Chopra, A. K., & Desai, N. (2009). Commitment-based service-orientedarchitecture. IEEE Computer, 42 (11), 7279.Sirbu, M. A., & Tygar, J. D. (1995). NetBill: internet commerce system optimizednetwork delivered services. IEEE Personal Communications, 2 (4), 3439.Sultan, K., Bentahar, J., Wan, W., & Al-Saqqar, F. (2014). Modeling verifying probabilistic multi-agent systems using knowledge social commitments. Expert SystemsApplications, 41 (14), 62916304.Sun, J., Liu, Y., Dong, J. S., & Pang, J. (2009). PAT: Towards flexible verificationfairness. Proceedings 21th International Conference Computer AidedVerification (CAV), Vol. 5643 Lecture Notes Computer Science, pp. 709714.Springer.Telang, P., & Singh, M. (2012). Specifying verifying cross-organizational businessmodels: agent-oriented approach. IEEE Transations Services Computing, 5 (3),305318.Telang, P. R., Kalia, A. K., & Singh, M. P. (2015).Modeling healthcare processes using commitments: empirical evaluation.PLoS ONE, 10 (11),doi:10.1371/journal.pone.0141202.Telang, P. R., & Singh, M. P. (2012). Comma: commitment-based business modelingmethodology empirical evaluation. Proceedings 11th InternationalConference Autonomous Agents Multiagent Systems, pp. 10731080.Torroni, P., Chesani, F., Mello, P., & Montali, M. (2010). Social commitments time: Satisfied compensated. Proceedings 7th International Conference DeclarativeAgent Languages Technologies, pp. 228243, Berlin, Heidelberg. Springer-Verlag.507fiGunay, Liu & Zhangvan Riemsdijk, M. B., Dastani, M., & Meyer, J.-J. C. (2009). Goals conflict: Semanticfoundations goals agent programming. Autonomous Agents Multi-AgentSystems, 18 (3), 471500.Vasconcelos, W. W. (2005). Norm verification analysis electronic institutions.Proceedings Second International Conference Declarative Agent LanguagesTechnologies, pp. 166182.Yolum, P. (2007). Design time analysis multiagent protocols. Data KnowledgeEngineering, 63 (1), 137154.Yolum, P., & Singh, M. P. (2002). Flexible protocol specification execution: Applyingevent calculus planning using commitments. Proceedings 1st InternationalJoint Conference Autonomous Agents Multiagent Systems, pp. 527534.Yolum, P., & Singh, M. P. (2007). Enacting protocols commitment concession.Proceedings 6th International Joint Conference Autonomous AgentsMultiagent Systems, pp. 27:127:8.508fiJournal Artificial Intelligence Research 57 (2016) 421-464Submitted 06/16; published 11/16Embarrassingly Parallel Search Constraint ProgrammingArnaud MalapertJean-Charles ReginMohamed Rezguiarnaud.malapert@unice.frjean-charles.regin@unice.frrezgui@i3s.unice.frUniversite Cote dAzur, CNRS, I3S, FranceAbstractintroduce Embarrassingly Parallel Search (EPS) method solving constraintproblems parallel, show method matches even outperforms state-ofthe-art algorithms number problems using various computing infrastructures. EPSsimple method master decomposes problem many disjoint subproblems solved independently workers. approach three advantages:efficient method; involves almost communication synchronizationworkers; implementation made easy master workers relyunderlying constraint solver, require modify it. paper describesmethod, applications various constraint problems (satisfaction, enumeration,optimization). show method adapted different underlying solvers(Gecode, Choco2, OR-tools) different computing infrastructures (multi-core, data centers, cloud computing). experiments cover unsatisfiable, enumeration optimizationproblems, cover first solution search makes results hard analyze. variability observed optimization problems, lesserextent optimality proof required. EPS offers good average performance,matches outperforms available parallel implementations Gecode wellsolvers portfolios. Moreover, perform in-depth analysis various factorsmake approach efficient well anomalies occur. Last, showdecomposition key component efficiency load balancing.1. Introductionsecond half 20th century, frequency processors doubled every 18 monthsso. clear years period free lunch, put SutterLarus (2005), behind us. outlined Bordeaux, Hamadi, Samulowitz (2009),available computational power keep increasing exponentially, increaseterms number available processors, terms frequency per unit. Multi-coreprocessors norm raises significant challenges software development.Data centers high-performance computing readily accessible many academiaindustry. Cloud computing (Amazon, Microsoft Azure, Google, . . . ) offers massiveinfrastructures rent computing storage used demand.facilities anyone gain access super-computing facilities moderate cost.Distributed Computing offers possibilities put computational resources commoneffectively obtains massive capabilities. Examples include Seti@home (Anderson, Cobb,Korpela, Lebofsky, & Werthimer, 2002), Distributed.net (Distributed Computing Technologies Inc, 20) Sharcnet (Bauer, 2007). main challenge therefore scale, i.e.,cope growth.c2016AI Access Foundation. rights reserved.fiMalapert, Regin, & RezguiConstraint programming (CP) appealing technology variety combinatorialproblems grown steadily last three decades. strengths CPuse constraint propagation combined efficient search algorithms. Constraintpropagation aims removing combinations values variable domains cannotappear solution. number years, possible gains offered parallelcomputing attracted attention.Parallel computing form computation many calculations carriedsimultaneously (Almasi & Gottlieb, 1989) operating principle large problemsoften divided smaller ones, solved parallel. Different formsparallel computing exist: bit-level, instruction level, data task parallelism. Taskparallelism common approach parallel branch-and-bound (B&B) algorithms (Mattson, Sanders, & Massingill, 2004) achieved processor executes differentthread (or process) different data. Parallel computer programs difficult write sequential ones, concurrency introduces several new classespotential software bugs, race conditions common. example,memory shared, several tasks algorithm modify datatime. could render program incorrect. Mutual exclusion allows worker lockcertain resources obtain exclusive access, create starvationworkers must wait worker frees resources. Moreover, indeterminismparallel programs makes behaviour execution unpredictable, i.e. resultsdifferent program runs may differ. So, communication synchronization among differentsub-tasks address issue, typically greatest obstacles goodperformance. Another central bottleneck load balancing, i.e. keeping processors busymuch possible.Wilkinson Allen (2005) introduced Embarrassingly Parallel paradigm assumes computation divided number completely independent partspart executed separate processor. paper, introduceEmbarrassingly Parallel Search (EPS) method constraint problems showmethod often outperforms state-of-the-art parallel B&B algorithms numberproblems various computing infrastructures. master decomposes problemmany disjoint subproblems solved independently workers. Since constraint program trivially embarrassingly parallel, decomposition procedure mustcarefully designed. approach three advantages: efficient method;involves almost communication, synchronization, mutual exclusion workers;implementation simple master workers rely underlyingconstraint solver require modify it. Additionally, deterministiccertain restrictions.paper integrates results series publications (Regin, Rezgui, & Malapert,2013, 2014; Rezgui, Regin, & Malapert, 2014). However, paper includes novel contributions, implementations, results. new implementation EPS topJava library Choco2 (Choco, 2010) uses new decomposition procedure. New resultsgiven implementations top C++ library Gecode (Schulte, 2006)OR-tools (Perron, Nikolaj, & Vincent, 2012), problems types instancestested. EPS compared parallelizations Gecode several static422fiEmbarrassingly Parallel Search CPsolvers portfolios, perform in-depth analysis various components, especially decomposition procedures, well anomalies occur.paper organized follows. Section 2 presents constraint programming background, Amdahls law, related work parallel constraint solving. Section 3 givesdetailed description embarrassingly parallel search method. Section 4 gives extensive experimental results various implementations (Gecode, Choco2, OR-tools)different computing infrastructures (multi-core, data center, cloud computing) wellcomparisons state-of-the-art parallel implementations static solver portfolios.2. Related WorkHere, present constraint programming background, two important parallelizationmeasures related Amdahls law, related work parallel constraint solving.2.1 Constraint Programming BackgroundConstraint programming (CP) attracted high attention among experts many areaspotential solving hard real-life problems. extensive reviewconstraint programming, refer reader handbook Rossi, Van Beek,Walsh (2006). constraint satisfaction problem (CSP) consists set X variablesdefined corresponding set possible values (the domains D) set C constraints.constraint relation subset variables restricts possible valuesvariables take simultaneously. important feature constraints declarativemanner, i.e. specify relationship must hold. current domain D(x)variable x X always (non-strict) subset initial domain. partial assignmentrepresents case domains variables reduced singleton(namely variable assigned value). solution CSP assignmentvalue variable constraints simultaneously satisfied.Solutions found searching systematically possible assignmentsvalues variables. backtracking scheme incrementally extends partial assignmentspecifies consistent values variables, toward complete solution,repeatedly choosing value another variable. variables labeled (given value)sequentially. node search tree, uninstantiated variable selectednode extended resulting new branches node represent alternativechoices may examined order find solution. branching strategydetermines next variable instantiated, order valuesdomain selected. partial assignment violates constraints, backtrackingperformed recently assigned variable still alternative values availabledomain. Clearly, whenever partial assignment violates constraint, backtrackingable eliminate subspace Cartesian product variable domains.filtering algorithm associated constraint removes inconsistent valuesdomains variables, i.e. assignments cannot belong solutionconstraint. Constraints handled constraint propagation mechanismallows reduction domains variables global fixpoint reached (nodomain reductions possible). fact, constraint specifies relationship must holdfiltering algorithm computational procedure enforces relationship.423fiMalapert, Regin, & RezguiGenerally, consistency techniques complete, i.e. remove inconsistentvalues domains variables.backtracking scheme consistency techniques used alone completelysolve CSP, combination allows search space explored completeefficient way. propagation mechanism allows reduction variabledomains pruning search tree whereas branching strategy improvedetection solutions (or failures unsatisfiable problems).Here, consider complete standard backtracking scheme depth-first traversalsearch tree combined following variable selection strategies. Note differentvariable selection strategies used although one time. lex selects variableaccording lexicographic ordering. dom selects variable smallest remaining domain (Haralick & Elliott, 1980). ddeg selects variable largest dynamic degree (Beck,Prosser, & Wallace, 2005), is, variable constrained largest numberunassigned variables. Boussemart, Hemery, Lecoutre, Sais (2004) proposed conflictdirected variable ordering heuristics every time constraint causes failuresearch, weight incremented one. variable weighted degree,sum weights constraints variable occurs. wdeg selectsvariable largest weighted degree. current domain variable incorporated give dom/ddeg dom/wdeg selects variable minimum ratiocurrent domain size dynamic weighted degree (Boussemart et al., 2004;Beck et al., 2005). dom/bwdeg variant follows binary labeling scheme. impactselects variable/value pair strongest impact, i.e. leads strongestsearch space reduction (Refalo, 2004).optimization problems, consider standard top-down algorithm maintainslower bound, lb, upper bound, ub, objective value. ub lb, subtreepruned cannot contain better solution.2.2 Parallelization Measures Amdahls LawTwo important parallelization measures speedup efficiency. Let t(c) wallclock time parallel algorithm c number cores let t(1)wall-clock time sequential algorithm. speedup su(c) = t(1) / t(c) measureindicating many times parallel algorithm performs faster due parallelization.efficiency eff (c) = su(c) / c normalized version speedup, speedupvalue divided number cores. maximum possible speedup single programresult parallelization known Amdahls law (Amdahl, 1967). statessmall portion program cannot parallelized limit overall speedupavailable parallelization. Let B [0, 1] fraction algorithm strictlysequential, time t(c)algorithm takes finish executed c corescorresponds to: t(c) = t(1) B + 1c (1 B) . Therefore, theoretical speedup su(c) is:su(c) =1B + (1 B)1c424fiEmbarrassingly Parallel Search CPAccording Amdahls law, speedup never exceed number cores, i.e. linearspeedup. This, terms efficiency measure, means efficiency always less1.Note sequential parallel B&B algorithms always exploresearch space. Therefore, super-linear speedups parallel B&B algorithms contradiction Amdahls law processors access high quality solutions earlyiterations, turn brought reduction search tree problem size.2.3 Parallel Constraint SolvingDesigning developing parallel programs manual process programmer responsible identifying implementing parallelism (Barney & Livermore, 2016). section, discuss parallel constraint solving. parallellogic programming, refer reader surveys De Kergommeaux Codognet(1994), Gupta, Pontelli, Ali, Carlsson, Hermenegildo (2001). parallel integerprogramming, refer reader surveys Crainic, Le Cun, Roucairol (2006),Bader, Hart, Phillips (2005), Gendron Crainic (1994).main approaches parallel constraint solving roughly divided following main categories: search space shared memory; search space splitting; portfolio algorithms; problem splitting. approaches require communication synchronization,important issue load balancing refers practice distributingapproximately equal amounts work among tasks processors kept busytime.2.3.1 Search Space Shared Memorymethods implemented many cores sharing list open nodessearch tree (nodes least one children still unvisited).Starved processors pick promising node list expand it.defining different node evaluation functions, one implement different strategies (DFS,BFS others). Perron (1999) proposed comprehensive framework tested4 processors. Vidal, Bordeaux, Hamadi (2010) reported good performance parallelbest-first search 64 processors. Although kind mechanism intrinsically providesexcellent load balancing, known scale beyond certain number processors;beyond point, performance starts decrease. Indeed, shared memory system,threads must contend communicating memory problemexacerbated cache consistency transactions.2.3.2 Search Space SplittingSearch Space Splitting strategies exploring parallelism provided search spacecommon approaches: branching done, different branches exploredparallel (Pruul, Nemhauser, & Rushmeier, 1988). One challenge load balancing:branches search tree typically extremely imbalanced require non-negligibleoverhead communication work stealing (Lai & Sahni, 1984).work stealing method originally proposed Burton Sleep (1981) firstimplemented Lisp parallel machines (Halstead, 1984). search space dynamically425fiMalapert, Regin, & Rezguisplit resolution. worker finished explore subproblem, asksworkers another subproblem. another worker agrees demand, splitsdynamically current subproblem two disjoint subproblems sends one subproblemstarving worker. starving worker steals work busy one. Noteform locking necessary avoid several starving workers stealsubproblems. starving worker asks workers turn receives newsubproblem. Termination work stealing method must carefully designed reduceoverhead almost workers starving, almost work remains. Recent worksbased approach Zoeteweij Arbab (2004), Jaffar, Santosa, Yap,Zhu (2004), Michel, See, Hentenryck (2009), Chu, Schulte, Stuckey (2009).work stealing uses communication, synchronization computation time,cannot easily scaled thousands processors. address issues, XieDavenport (2010) allocated specific processors coordination tasks, allowing increasenumber processors (linear scaling 256 processors) usedparallel supercomputer performance starts decline.Machado, Pedro, Abreu (2013) proposed hierarchical work stealing scheme correlated cluster physical infrastructure, order reduce communication overhead.worker first tries steal local node, considering remote nodes (startingclosest remote node). approach achieved good scalability 512 coresn-queens quadratic assignment problems. constraint optimization problems,maintaining best solution worker would require large communicationsynchronization overhead. But, Machado et al. observed scalability loweredlazy dissemination so-far best solution, i.e. workers useobsolete best solution.General-purpose programming languages designed multi-threaded parallel computinglike Charm++ (Kale & Krishnan, 1993) Cilk++ (Leiserson, 2010; Budiu, Delling, &Werneck, 2011) ease implementation work stealing approaches. Otherwise,work stealing framework like Bobpp (Galea & Le Cun, 2007; Le Cun, Menouer, & VanderSwalmen, 2007) provides interface solvers parallel computers. Bobpp,work shared via global priority queue search tree decomposed allocateddifferent cores demand search algorithm execution. Periodically, workertests starving workers exist. case, worker stops search pathroot node highest right open node saved inserted global priorityqueue. Then, worker continues search left open node. Otherwise,starving worker exists, worker continues search locally using solver. starvingworkers notified insertions global priority queue, one picksnode starts search. Using OR-tools underlying solver, Menouer Le Cun(2013), Menouer Le Cun (2014) observed good speedups Golomb Rulerproblem 13 marks (41.3 48 workers) 16-queens problem (8.63 12workers). experiments investigate exploration overhead caused approach.Bordeaux et al. (2009) proposed another promising approach based search spacesplitting mechanism based work stealing approach. use hashing functionallocating implicitly leaves processors. processor applies searchstrategy allocated search space. Well-designed hashing constraints addressload balancing issue. approach gives linear speedup 30 processors426fiEmbarrassingly Parallel Search CPn-queens problem, speedups stagnate 30 64 processors. However,got moderate results 100 industrial SAT instances.presented earlier works Embarrassingly Parallel Search method basedsearch space splitting loose communications (Regin et al., 2013, 2014; Rezgui et al.,2014).Fischetti, Monaci, Salvagnin (2014) proposed another paradigm called SelfSplitworker able autonomously determine, without communicationworkers, job parts process. SelfSplit decomposed three phases:enumeration tree initially built workers (sampling); enough open nodesgenerated, sampling phase ends worker applies deterministic ruleidentify solve nodes belong (solving); single worker gathers resultsothers (merging). SelfSplit exhibited linear speedups 16 processors goodspeedups 64 processors five benchmark instances. SelfSplit assumes samplingbottleneck overall computation whereas happen practice (Reginet al., 2014).Sometimes, complex applications good domain specific strategiesknown, parallel algorithm exploit domain-specific strategy. Moisan, Gaudreault, Quimper (2013), Moisan, Quimper, Gaudreault (2014) proposedparallel implementation classic backtracking algorithm, Limited Discrepancy Search(LDS), known efficient centralized context good variable/valueselection heuristic provided (Harvey & Ginsberg, 1995). Xie Davenport (2010) proposed processor locally uses LDS search trees allocated (bytree splitting work stealing algorithm) global system replicate LDSstrategy.Cube-and-Conquer (Heule, Kullmann, Wieringa, & Biere, 2012) approach parallelizing SAT solvers. cube conjunction literals DNF formula disjunctioncubes. SAT problem split several disjoint subproblems DNF formulassolved independently workers. Cube-and-Conquer using ConflictDriven Clause Learning (CDCL) solver Lingeling outperforms parallel SAT solversinstances SAT 2009 benchmarks, also outperformed manyinstances. Thus, Concurrent Cube-and-Conquer (Van Der Tak, Heule, & Biere, 2012) triespredict instances works well abort parallel search secondsfavor sequential CDCL solver not.2.3.3 Las Vegas Algorithms / Portfoliosexplore parallelism provided different viewpoints problem,instance using different algorithms parameter tuning. idea also exploitednon-parallel context (Gomes & Selman, 2000). communication requiredexcellent level load balancing achieved (all workers visit search space). Evenapproach causes high level redundancy processors, shows really goodperformance. greatly improved using randomized restarts (Luby, Sinclair, &Zuckerman, 1993) worker executes restart strategy. recently, Cire,Kadioglu, Sellmann (2014) executed Luby restart strategy, whole, parallel.proved achieves asymptotic linear speedups and, practice, often obtained427fiMalapert, Regin, & Rezguilinear speedups. Besides, authors proposed allow processors share informationlearned search (Hamadi, Jabbour, & Sais, 2008).One challenge find scalable source diverse viewpoints provide orthogonalperformance therefore complementary interest. distinguishtwo aspects parallel portfolios: assumptions made number availableprocessors possible handpick set solvers settings complementoptimally. want face arbitrarily high number processors,need automated methods generate portfolio size demand (Bordeaux et al.,2009). So, portfolio designers became interested feature selection (Gomes & Selman, 1997,1999, 2001; Kautz, Horvitz, Ruan, Gomes, & Selman, 2002). Features characterize probleminstances like number variables, domain sizes, number constraints, constraints arities.Many portfolios select best candidate solvers pool based static featureslearning dynamic behaviour solvers. SAT portfolio iSAC (Amadini, Gabbrielli,& Mauro, 2013) CP portfolio CPHydra (OMahony, Hebrard, Holland, Nugent, &OSullivan, 2008) use feature selection choose solvers yield best performance.Additionally, CPHydra exploits knowledge coming resolution training setinstances candidate solver. Then, given instance, CPHydra determines ksimilar instances training set determines time limit candidatesolver based constraint program maximizing number solved instances withinglobal time limit 30 minutes. Briefly, CPHydra determines switching policysolvers (Choco2, AbsCon, Mistral).Many recent SAT solvers based portfolio ManySAT (Hamadi et al.,2008), SATzilla (Xu, Hutter, Hoos, & Leyton-Brown, 2008), SArTagnan (Stephan & Michael,2011), Hydra (Xu, Hoos, & Leyton-Brown, 2010), Pminisat (Chu, Stuckey, & Harwood,2008) based Minisat (Een & Sorensson, 2005). combine portfolio-basedalgorithm selection automatic algorithm configuration using different underlying solvers.example, SATzilla (Xu et al., 2008) exploits per-instance variation among solversusing learned runtime models.general, main advantage algorithms portfolio approach many strategies automatically tried time. useful defining goodsearch strategies difficult task.2.3.4 Problem SplittingProblem Splitting another idea relates parallelism, problem splitpieces solved processor. problem typically becomes difficultsolve centralized case processor complete view problem.So, reconciling partial solutions subproblem becomes challenging. Problemsplitting typically relates distributed CSPs, framework introduced Yokoo, Ishida,Kuwabara (1990) problem naturally split among agents, privacyreasons. distributed CSP frameworks proposed HirayamaYokoo (1997), Chong Hamadi (2006), Ezzahir, Bessiere, Belaissaoui, Bouyakhf(2007), Leaute, Ottens, Szymanek (2009), Wahbi, Ezzahir, Bessiere, Bouyakhf(2011).428fiEmbarrassingly Parallel Search CP2.3.5 Parallel Constraint Propagationapproaches thought of, typically based parallelization one key algorithm solver, instance constraint propagation (Nguyen & Deville, 1998; Hamadi,2002; Rolf & Kuchcinski, 2009). However, parallelizing propagation challenging (Kasif,1990) scalability limited Amdahls law. approaches focusparticular topologies make assumptions problem.2.3.6 Concluding RemarksNote oldest approaches, scalability issues still investigatedsmall number processors, typically around 16 64 processors. One majorissue approaches may (and must) resort communication. Communicationparallel agents costly general: shared-memory models multi-core,typically means access shared data structure one cannot avoidform locking; cost message-passing cross-CPU even significantly higher. Communication additionally makes difficult get insights solving process sinceexecutions highly inter-dependent understanding parallel executions notoriouslycomplex.parallel B&B algorithms explore leaves search tree different orderwould single-processor system. could pity situationsknow really good search strategy, entirely exploited parallel algorithm.many approaches, experiments parallel programming involve great deal nondeterminism: running algorithm twice instance, identical numberthreads parameters, may result different solutions, sometimes differentruntimes.3. Embarrassingly Parallel Searchsection, present details embarrassingly parallel search. First, Section 3.1introduces key concepts guided design choices. Then, Section 3.2 introducesseveral search space splitting strategies implemented via top-down bottom-up decomposition procedures presented Section 3.3. Section 3.4 gives details architecturecommunication. Section 3.5 explains manage queue subproblemsorder obtain deterministic parallel algorithm. Section 4.1 gives detailsimplementation.3.1 Key Conceptsintroduce key concepts guided design choices: massive static decomposition;loose communication; non-intrusive implementation; toward deterministic algorithm.3.1.1 Massive Static Decompositionmaster decomposes problem p subproblemssolved parallel independently workers. So, solving process equivalentreal-time scheduling p jobs w parallel identical machines known P ||Cmax (Korf &429fiMalapert, Regin, & RezguiSchreiber, 2013). Efficient algorithms exists P ||Cmax even simple list schedulingalgorithms (based priority rules) (2 w1 )-approximation. desirable propertiesdefined Section 3.2 ensure low precision processing times makes problemseasier. hold precision number workers fixed, increase numbersubproblems, problems get harder perfect schedules appear, geteasier. case, number p subproblems range one threeorders magnitude larger number workers w. low, chancefinding perfect schedules, therefore obtain good speedups, low. large,decomposition takes longer becomes difficult. conditions met,unlikely worker assigned work other, therefore,decomposition statistically balanced. Beside, reach good speedups practice,total solving time subproblems must close sequential solving timeproblem.advantage master workers independent. use differentfiltering algorithms, branching strategies, even underlying solvers. decompositioncrucial step, bottleneck computation quality also greatlyimpacts parallelization efficiency.3.1.2 Loose Communicationp subproblems solved parallel independently w workers. load balancingmust statistically obtained decomposition, allow work stealingorder drastically reduce communication. course, communication still neededdispatch subproblems, gather results possibly exchange useful additionalinformation, like objective bound values. Loose communication allows use star networkwithout risk congestion. central node (foreman) connected nodes (masterworkers).3.1.3 Non-intrusive Implementationsake laziness efficiency, rely much possible underlying solver(s)computing infrastructure. Consequently, modify little possible underlying solver. consider nogoods clauses exchanges techniquesintrusive increase communication overhead. Additionally, logging faulttolerance respectively delegated underlying solver infrastructure.3.1.4 Toward Determinismdeterministic algorithm algorithm which, given particular input, always produce output, underlying machine always passing sequence states. determinism already challenging sequential B&B algorithmsdue complexity (randomization, restarts, learning, optimization), stilldifficult parallel B&B algorithms.Here, always guarantee reproducibility real-time assignment subproblems workers stored. Reproducibility means always possible replaysolving process. restrictions detailed later, parallel algorithm madedeterministic additional cost. Moreover, parallel algorithm able430fiEmbarrassingly Parallel Search CPmimic sequential algorithm, i.e. produce identical solutions. requiresparallel algorithm visits tree leaves order sequential algorithm.generally, would useful debugging, performance evaluation, incremental problemsolving parallel algorithm may produce identical solutions matter manyworkers present computing infrastructure used.Conversely, real-time scheduling algorithm applied subproblems. wouldallow improve diversification using randomization, exploit past informationprovided solving process. experiments, use FIFO schedulingsubproblems, scheduling policy would change shape sizesearch tree and, therefore, reduces relevance speedups. Unlike EPS, work stealingapproaches deterministic offer control subproblem scheduling.3.2 Search-Space Splitting StrategiesHere, extend approach search-space splitting proposed Bordeaux et al. (2009),called splitting hashing. Let us recall C set constraints problem.split search space problem p parts, one approach assign subproblem(1 p) extended set constraints C Hi Hi hashing constraint,constrains subproblem particular subset search space. Hashing constraintsmust necessarily sound effective, nontrivial, statistically balanced.Sound Hashing constraints must partition search space: pi=1 Hi must cover entireinitial search space (completeness), mutual intersections Hi Hj (1 < j p)preferably empty (non-overlapping).Effective addition hashing constraints effectively allow workerefficiently skip portions search space assigned current subproblem.subproblem must significantly easier original problem. causes overhead,refer recomputation overhead.Nontrivial addition hashing constraints lead immediatefailure underlying solver. Thus, generating trivial subproblems might paidexploration overhead, many would discarded propagationmechanism sequential algorithm.Statistically Balanced workers given amount work.decomposition appropriate, number p subproblems significantly largernumber w workers. thus unlikely given worker would assignedsignificantly work worker real-time scheduling algorithm. However, possible solving one subproblem requires significantly work anothersubproblem.Bordeaux et al. (2009) defined hashing constraints selecting subset X variablesPproblem stating Hi (1 p) follows: xX x mod p. effectivelydecomposes problem p problems p within reasonable limits. p = 2, imposesparity constraints sum variables. Splitting repeated scale-uparbitrary number processors. splitting obviously sound, less effective431fiMalapert, Regin, & RezguiCP solvers SAT solvers. Here, study assignment splitting node splittinggenerate given number p? subproblems.3.2.1 Assignment SplittingLet us consider non empty subset X X ordered variables: X = (x1 , . . . , xd ). vector = (v1 , . . . , vd ) tuple X vj D(xj ) (j = 1, . . . , d). Let H( ) = dj=1 (xj = vj )hashing constraints restrict search space solutions extending tuple .Qtotal decomposition X splits initial problem di=1 D(xi ) subproblems, i.e. onesubproblem per tuple. total decomposition clearly sound effective, efficientpractice. Indeed, Regin et al. (2013) showed number trivial subproblemsgrow exponentially.table decomposition, subproblem defined set tuples allows reachexactly number p? subproblems. Let ordered list ofj tuplesXk|T |?|T | > p . Then, first subproblem defined first k = p? tuples, secondsubproblem defined following k tuples, on. So, subproblems definednumber tuples possibly exception last.tuple solver-consistent propagation extended set constraints CH( ) underlying solver detect unsatisfiability. order obtain nontrivialdecompositions, total table decompositions restricted solver-consistent tuples.3.2.2 Node SplittingNode splitting allows parallel algorithm exploit domain-specific strategiesdecomposition good strategy known. Let us recall concepts searchtrees (Perron, 1999) basis decomposition procedures introduced later.decompose problems, one needs able map individual parts search treehashing constraints. parts called open nodes. open nodes defined,present search tree decomposed set open nodes.Open Nodes Node Expansion search tree partitioned three sets, opennodes, closed nodes, unexplored nodes. Here, make assumptionarity search tree, i.e. maximal number children nodes. subsetsfollowing properties.ancestors open node closed nodes.unexplored node exactly one open node ancestor.closed node open node ancestor.set open nodes called search frontier illustrated Figure 1. searchactivepathclosedopenFrontierunexploredFigure 1: Node status search frontier search tree.432fiEmbarrassingly Parallel Search CPfrontier evolves simply process known node expansion. removes open nodefrontier, transforms removed node closed node, adds unexploredchildren frontier. Node expansion operation happenssearch. corresponds branch operation B&B algorithm.point search, search frontier sound nontrivial decompositionoriginal problem open node associated subproblem. decomposition effective branching strategy effective. Let us remarkassignment splitting seen special case node splitting static orderingused variables values.Active Path Jumps Search Tree Expanding one node another mayrequire changing state (at least variables domains) search processfirst node second. So, worker charge exploring open node must reconstructstate visits. done using active path jumping operation.going search tree, search process builds active path,list ancestors current open node, illustrated Figure 1. workermoves one node another, jump search tree. make jump,simply recomputes every move root gets target node. causesoverhead, refer recomputation overhead. Recomputation changesearch frontier expand node.3.3 Decomposition Proceduresdecomposition challenge find depth search frontier containsapproximately p? nodes. assignment splitting strategy implemented top-downprocedure starts root node incrementally visits next levels, whereasnode splitting strategy implemented bottom-up procedure starts formlevel deep enough climbs back previous levels.3.3.1 Top-Down Decompositionchallenge top-down decomposition find ordered variables produceapproximately p? solver-consistent tuples. Algorithm 1 realizes solver-consistent tabledecomposition iterated depth-bounded depth-first searches early removals inconsistent assignments (Regin et al., 2013).algorithm starts root nodeempty list tuples (line 1). computes list p? tuples solver-consistenttable decomposition iterativly increasing decomposition depth. Let us assumeexists static order variables. iteration, determines new lowerbound (line 4) decomposition depth d, i.e. number variables involveddecomposition. lower bound uses Cartesian product current domainsnext variables xd+1 , xd+2 , . . . Then, depth-bounded depth-first search extendsdecomposition new depth updates list tuples (line 5). current tuplesadded constraints model search (line 5) order reduceredundant work. search, extended tuples propagated (line 7) reducedomains, improve next lower bound decomposition depth. tuplesolver-consistent (not proven infeasible) last search. process repeatednumber |T | tuples greater equal p? . end, tuples aggregated433fiMalapert, Regin, & RezguiAlgorithm 1: Top-down decomposition.12345678910Data: CSP (X , D, C) number subproblems p?Result: list tuples0;;/* Simulate breadth-first search: iterated depth bounded DFSs.repeat/* Determinedecompositiondepth. */n fi lower boundQlfi?min l fi max(1, |T |) i=d+1 |D(xi )| p ;*//* Extend current decomposition new variables. */depthBoundedDFS (X , C { H( )}, D, {x1 , . . . , xd });== break;/* Propagate tuples (without failure). */propagate (X , C { H( )}, D);|T | < p? ;/* Aggregate tuples generate exactly p? subproblems */aggregateTuples(T ) /* subproblems become simultaneously available.*/foreach sendSubProblem (X , C H( ), D);generate exactly p? subproblems. practice, consecutive tuples aggregated.subproblems become simultaneously available aggregation.Sometimes, sequential decomposition bottleneck Amdahls law. So,parallel decomposition procedure increases scalability (Regin et al., 2014).two steps differ Algorithm 1. First, instead starting depth 0 empty listtuples (line 1 Algorithm 1), first list quickly generated least five tuples perworker.n fi12fi Qlmin l fi i=1 |D(xi )| 5 w ;Qdi=1 D(xi );Second, iteration, tuple extended parallel instead extending sequentially tuples (line 5 Algorithm 1). parallel decomposition change orderingcompared sequential one. Again, subproblems become availableend decomposition.80 ;run parallelforeach/* extend tuple parallel */0 0 depthBoundedDFS (X , C H( ), D, {x1 , . . . , xd });90;567top-down procedures assume variable ordering used decomposition static. next decomposition procedure bypasses limitation handlesbranching strategy.434fiEmbarrassingly Parallel Search CPAlgorithm 2: Bottom-up decomposition.12345678910Data: CSP (X , D, C), decomposition depth d? , subproblem limit P .p 0;/* Generate subproblems visiting top real tree. */Node Callback decomposition(node)depth(node) d?sendSubProblem (node);p p + 1;p P/* Decrease dynamically depth. */d? max(1, d? 1);P 2 P;backtrack;DFS (X ,C,D);3.3.2 Bottom-Up Decompositionbottom-up decomposition explores search frontier depth d? approximately p? nodes. simplest form, decomposition depth d? provideduser good knowledge problem. Algorithm 2 explores search frontier depthd? using depth-first search illustrated Figure 2(a). search callback identifiesnode level d? (line 2), sends immediately active path, defines subproblem,subproblem solved worker. decomposition depth dynamic,reduced number subproblems becomes large (line 6). aimscompensate poor choice decomposition depth d? . practice, depth reducedone unit current number subproblems exceeds given limit P . limitinitially set P = 2 p? doubled time reached. contrary,depth static (P = +) never changes whatever number subproblems.practice, common user provides decomposition depth,automated procedure without users intervention needed. Algorithm 3 aimsidentifying topmost search frontier approximately p? open nodes samplingestimation. procedure divided three phases: build partial tree samplingFinal depthSearch FrontierDynamicp nodesStaticP nodesInitial depth2P nodes(a) Decomposition.(b) Estimation.Figure 2: Bottom-up decomposition estimation.435fiMalapert, Regin, & RezguiAlgorithm 3: Bottom-up estimation.1234567891011Data: CSP (X , D, C) number subproblems p? .Data: time limit t, node limit n, maximum depth large enoughResult: decomposition depth d?/* Set counters width levels */foreach [1, D] width[d] 0;/* Build partial tree sampling. */Node Callback estimation(node)depth(node);width[d] width[d] + 1;width[d] p? 1 ;else backtrack;hasFinished (t,n) break;DFS (X ,C,D);/* Estimate level widths tree decomposition depth.width estimateWidths(width);d? estimateDepth(width, p? );*/top real search tree; estimate level widths real tree; determinedecomposition depth d? greedy heuristic.Since need explore top search tree, upper bound decomposition depth fixed. maximum decomposition depth must chosen accordingnumber workers expected number subproblems per worker.small, decomposition could generate subproblems. large,sampling time increases decomposition quality could decrease.sampling phase builds partial tree p? open nodes level usingcallback depth-first search. number open nodes level partialtree counted callback. maximum depth reduced time p? nodesopened given level (line 6). sampling ends within limits, toptree entirely visited estimation needed. Otherwise (line 8), one needsestimate widths topmost levels tree depending partial tree.estimation straightforward adaptation one proposed Cornuejols, Karamanov,Li (2006) deal n-ary search tree (line 10). practice, main issuehigher arity is, lower precision estimation. Therefore, greedy heuristicdetermines decomposition depth based estimated number nodes per level,also number nodes partial tree (line 11). heuristics minimizesabsolute deviation estimated number nodes expected number p? .several levels identical absolute deviation, lowest level estimatednumber subproblems greater equal p? selected.3.4 Architecture Communicationdescribe messages exchanged actors depending problems type. Then,typical use case illustrates solving process optimization problem. Briefly,436fiEmbarrassingly Parallel Search CPcommunication network star network foreman acts pipe transmitmessages master workers.3.4.1 Actors Messagestotal number messages depends linearly number workers (w)number subproblems (p). messages synchronous sake simplicitymeans work must wait communications completed (Barney & Livermore,2016). Interleaving computation communication single greatest benefit usingasynchronous communications since work done communications takingplace. However, asynchronous communications complicate architecture, instancemessage requests answer.Master control unit decomposes problem collects final results.sends following messages: create foreman; give subproblem foreman;wait foreman gather results; destroy foreman. master dealsforeman. decomposition time elapsed time createwait messages. workers time elapsed time first give destroymessages. wall-clock time elapsed time creation destructionmaster.Foreman central node star network. queuing system stores subproblems received master dispatches workers. also gathers resultscollected workers. foreman allows master concentrate problemsdecomposition, performance bottleneck, handling communicationsworkers. sends following messages: create worker; give subproblem worker;collect (send) final results master; destroy worker. foremandetects search ended, sends collect-message containing final resultsmaster.Workers search engines. send following messages: find subproblem (theforeman must answer give-message); collect (send) results foreman.results contain essential information solution(s) solving process. Workersknow foreman. worker acquires new work (receives give-messageforeman), acquired subproblem recomputed causes recomputation overhead.work stealing context, Schulte (2000) noticed higher node searchtree, smaller recomputation overhead. construction, topmost nodesused here.3.4.2 Problems Typesdiscuss specificities first solution, solution, best solution searches.First Solution Search search complete soon solution found.workers must immediately terminated well decomposition procedure.Solution Search search complete subproblems solved.437fiMalapert, Regin, & RezguiBest Solution Search main design issue best-solution search maintainso-far best solution. sequential B&B algorithm always knows so-far best solution.difficult achieve concurrent setting several workers. Maintaining bestsolution worker could lead large communication synchronization overheads.Instead prefer solution foreman workers maintain so-far bestsolution follows. default, give collect messages foremanworkers carry objective information. Additionally, worker send better messagesforeman intermediate solution, foreman send best solutionworkers. instance, worker finds new solution, informs foremansending better message solution accepted threshold function. Similarly,foreman receives new solution collect better message, checkswhether solution really better. solution accepted threshold function,foreman sends another better message workers. architecture sketchedentails worker might always know so-far best solution. consequence,parts search tree explored, pruned away workerexact knowledge. Thus, loose coupling might paid explorationoverhead.MasterForemanWorker 1Worker 2opt[Allocate Resources]<< create >><< create >><< create >>givefindgiveoptbetter[Best Solution Search]givegivegivecollectfindwaitgivecollectbetteroptbetter[Best Solution Search]collectcollectopt[Release Resources]<< destroy >><< destroy >><< destroy >>MasterForemanMasterWorkerMaster1WorkerMaster2Figure 3: Sequence diagram solving process two workers.438fiEmbarrassingly Parallel Search CP3.4.3 Use CaseFigure 3 sequence diagram illustrating solving process optimization problemtwo workers. shows actors operate chronological order.first horizontal frame resource allocation. master creates foreman.foreman creates workers. Immediately creation, master workerload original problem. foreman transparently manages concurrent queue subproblems produced master consumed workers. that, workersjumps search tree.foreman creation, master starts decomposition original problemp = 3 subproblems. soon subproblem generated, master givesforeman. Here, give find messages interleaved node splittingdecomposition proposed Section 3.3.2. assignment splitting decomposition proposedSection 3.3.1 would produce unique give message subproblems.decomposition finished, master sends wait message foreman waitscollect response containing final result. last collect message triggersresource deallocation.time worker starving, asks foreman subproblem waits it.Here, first subproblem assigned first worker second worker waitssecond subproblem. Best Solution Search frames correspond specific messagesoptimization problems. first worker quickly finds good solution sendsforeman via better message. second subproblem generated mastergiven foreman. turn, foreman gives second subproblem updatedobjective information second worker. second problem quickly solvedsecond worker sends collect message foreman. collect message alsostands find message. Then, third, last, subproblem assigned secondworker.foreman broadcasts better message good quality solutionreceived first worker. Note message useless first worker.foreman detects termination solving process sends collect messagemaster three following conditions met: master waiting; subproblemsqueue empty; workers starving. last horizontal frame resourcedeallocation.3.5 Queuing Determinismforeman plays role queuing system receives subproblems masterdispatches workers. section, show EPS modifiedreturn solution sequential algorithm useful severalscenarios debugging performance evaluation. Generally, queuing policyapplied select next subproblem solve.Let us assume subproblems P1 , P2 , . . . , Pp sent foreman fixedorder case sequential top-down procedure bottom-up procedure.Otherwise, fixed order subproblems obtained sorting subproblems.first solution found sequential algorithm belongs satisfiable subproblemPi smallest index, i.e. leftmost solution. Let us assume parallel439fiMalapert, Regin, & Rezguialgorithm finds first solution subproblem Pj j > i. Then,necessary solve problems Pk k > j one must wait problemPk k < j determine leftmost solution, satisfiable subproblemsmallest index.easily extended optimization problems slightly modifying cuttingconstraints. Usually, cutting constraint stated new solution foundallows strictly improving solution. contrary constraints, cuttingconstraint always propagated backtracking. Here, solution found solvingsubproblem Pj , cutting constraint allows strictly improving solutionsubproblems k j, also allows equivalent solution subproblems k < j.So, parallel algorithm returns solution sequential onesubproblem visited order. Moreover, solution returned parallelalgorithm depend number workers, decomposition.experiments, queuing policy FIFO policy ensures subproblemssolved order speedups relevant. However, guarantysequential parallel algorithms return solution.4. Experimental ResultsHere, describe experiments EPS carry detailed data analysis. aimanswer following questions. EPS efficient? different number workers?different solvers? different computing platforms? Compared parallelapproaches? influence different components (decomposition procedures,search strategies, constraint models)? EPS robust flexible? anomaliesoccur?Section 4.1 presents benchmark instances, execution environments, parameters settings, different implementations. First, Section 4.2, analyze evaluatetop-down bottom-up decomposition procedures well importance searchstrategy, especially decomposition. Then, evaluate efficiency scalabilityparallel solvers multi-core machine (Section 4.3), data center (Section 4.4),cloud platform (Section 4.5). sections, compare implementationsEPS work stealing approaches whenever possible. Section 4.4, also analyze efficiency parallel solver depending search strategy. Section 4.6,transform reasonable effort parallel solver distributed parallel solverusing batch scheduler provided data center. anomalies parallel solverexplained resolved distributed equivalent. Last, Section 4.7 discussesperformance parallel solvers compared static portfolios built underlyingsequential solvers data center.4.1 Experimental Protocolsection, introduce benchmark instances, execution environments, metricsnotations. also give details implementations.440fiEmbarrassingly Parallel Search CP4.1.1 Benchmark Instanceslot benchmark instances available literature. aim select difficultinstances various models represent problems tackled CP. Ideally, instancedifficult none solvers solve quickly. Indeed, parallel solving relevantshortens long wall-clock time. Here, consider unsatisfiable, enumerationoptimization problems instances. ignore problem finding first feasiblesolution parallel speedup completely uncorrelated numberworkers, making results hard analyze. consider optimization problemsvariability observed, lesser extent optimalityproof required. variability unsatisfiable enumeration instances lowered,therefore, often used test bed parallel computing. Besides, unsatisfiableinstances practical importance, instance software testing, enumerationimportant users compare various solutions.first set called fzn selection 18 instances selected 5000instances either repository maintained Kjellerstrand (2014) directlyMinizinc 1.6 distribution written FlatZinc language (NICTA Optimisation ResearchGroup, 2012). instance solved 500 seconds less 1 hourGecode. selection composed 1 unsatisfiable, 6 enumeration, 11 optimizationinstances.set xcsp composed instances categories ACAD REAL XCSP2.1 (Roussel & Lecoutre, 2008). consists difficult instances solved within24 hours Choco2 (Malapert & Lecoutre, 2014). first subset called xcsp1 composed5 unsatisfiable 5 enumeration instances whereas second subset called xcsp2composed 11 unsatisfiable 3 enumeration instances. set xcsp1 composedinstances easier solve xcsp2.Besides, consider two classical problems, n-queens Golomb rulerproblems widely used literature (Gent & Walsh, 1999).4.1.2 Implementation Detailsimplemented EPS method top three solvers: Choco2 2.1.5 written Java, Gecode4.2.1 OR-tools rev. 3163 written C++. use two parallelism implementationtechnologies: Threads (Mueller et al., 1993; Kleiman, Shah, & Smaalders, 1996)MPI (Lester, 1993; Gropp & Lusk, 1993). typical differencethreads (of process) run shared memory space, MPI standardizedportable message-passing system exchange information processes runningseparate memory spaces. Therefore, Thread technology handle multiple nodescluster whereas MPI does.C++, use Threads implemented pthreads, POSIX library (Mueller et al.,1993; Kleiman et al., 1996) used Unix systems. Java, use standard Java Threadtechnology (Hyde, 1999).many implementations MPI like OpenMPI (Gabriel, Fagg, Bosilca, Angskun,Dongarra, Squyres, Sahay, Kambadur, Barrett, Lumsdaine, et al., 2004), Intel MPI (IntelCorporation, 2015), MPI-CH (MPI-CH Team, 2015) MS-MPI (Krishna, Balaji, Lusk,Thakur, & Tiller, 2010; Lantz, 2008). MPI standard API, characteristics441fiMalapert, Regin, & Rezguimachine never taken account. So, machine providers like Bull, IBM Intelprovide MPI implementation according specifications delivered machine. Thus, cluster provided Bull custom Intel MPI 4.0 library, OpenMPI1.6.4 also installed, Microsoft Azure supports MS-MPI 7 library.OR-tools uses sequential top-down decomposition C++ Threads. Gecode usesparallel top-down decomposition C++ Threads MPI technologies. fact, Gecodeuse C++ pthread multi-core computer, OpenMPI data center,MS-MPI cloud platform. Gecode OR-tools use lex variable selectionheuristic top-down decomposition requires fixed variable ordering. Choco2uses bottom-up decomposition Java Threads. every case, foreman schedulesjobs FIFO mimic much possible sequential algorithm speedupsrelevant. needed, master workers read model file.always take value selection heuristic selects smallest value whatevervariable selection heuristic.4.1.3 Execution Environmentsuse three execution environments representative computing platforms available nowadays.Multi-core Dell computer 256 GB RAM 4 Intel E7-4870 2.40 GHz processors running Scientific Linux 6.0 (each processor 10 cores).Data Center Centre de Calcul Interactif hosted Universite Nice SophiaAntipolis provides cluster composed 72 nodes (1152 cores) running CentOS6.3, node 64 GB RAM 2 Intel E5-2670 2.60 GHz processors (8 cores).cluster managed OAR (Capit, Da Costa, Georgiou, Huard, Martin, Mounie, Neyron,& Richard, 2005), i.e., versatile resource task manager. Thread technologylimited single node cluster, Choco2 use 16 physical cores whereas Gecodeuse number nodes thanks MPI.Cloud Computing cloud platform managed Microsoft company (MicrosoftAzure) enables deploy applications Windows Server technology (Li, 2009).node 56 GB RAM Intel Xeon E5-2690E 2.6 GHz processors (8 physical cores)allowed simultaneously use 3 nodes (24 cores) managed Microsoft HPCCluster 2012 (Microsoft Corporation, 2015).computing infrastructures provide hyper-threading technologies. Hyper-threadingimproves parallelization computations (doing multiple tasks once). corephysically present, operating system addresses two logical cores, sharesworkload among possible. multi-core computer provides hyper-threading,whereas deactivated cluster, available cloud.4.1.4 Setting Parameterstime limit solving instance set 12 hours whatever solver.number workers strictly less number cores (w < c), alwaysunused cores. Usually, one chooses w = c, workers work simultaneously.multi-core computer, use two workers per physical core (w = 2c) hyperthreading efficient experimentally demonstrated Appendix A. target number442fiEmbarrassingly Parallel Search CPp? subproblems depends linearly number w workers (p? = 30 w) allowsstatistical balance workload without increasing much total overhead (Reginet al., 2013).experiments, network RAM memory loads low regardscapacities computing infrastructures. Indeed, total number messages dependslinearly number workers number subproblems. RAM pre-allocatedcomputing infrastructure allows it. Last, workers almost produce input/outputdisk access.4.1.5 Metrics NotationsLet solving time (in seconds) algorithm let su speedup parallelalgorithm. tables, row gives results obtained different algorithms giveninstance. row, best solving times speedups indicated bold. Dashesindicate instance solved algorithm. Question marks indicatespeedup cannot computed sequential solver solve instancewithin time limit. Arithmetic means, abbreviated AM, computed solving times,whereas geometrical means, abbreviated GM, computed speedups efficiency.Missing values, i.e. dashes question marks, ignored computing statistics.also use scoring procedure based Borda count voting system (Brams &Fishburn, 2002). benchmark instance treated like voter ranks solvers.solver scores points related number solvers beats. precisely,solver scores points problem P comparing performance solver s0follows:gives better answer s0 , scores 1 point;else answer gives worse answer s0 , scores 0 point;else scoring based execution time comparison (s s0 give indistinguishableanswers).Let t0 respectively denote wall-clock times solvers s0 given problemsinstance. case indistinguishable answers, scores f (t, t0 ) according Borda systemused Minizinc challenge. But, function f capture users preferenceswell. Indeed, solver solves n problems 0.1 seconds n others 1000 secondswhereas solver s0 solves first n problems 0.2 seconds n others 500seconds, solvers obtain score n whereas users would certainlyprefer s0 . So, use another scoring function g(t, t0 ) g(t) interpretedutility function solving problems instance within seconds. function g(t)strictly decreasing 0.5 toward 0. remaining points shared using function f .f (t, t0 ) =t0+ t0g(t, t0 ) = g(t)+(1g(t)g(t0 ))f (t, t0 )g(t) =12 (loga (t + 1) + 1)Using function g (a = 10) previous example, solvers s0 respectivelyscored 0.81 n 1.19 n points.443fiMalapert, Regin, & Rezgui4.2 Analysis Decompositionsection, compare quality performance top-down bottom-updecomposition procedures introduced Section 3.3.4.2.1 Decomposition Qualitytop-down decomposition always returns target number p? = 30 w subproblemswhereas guaranteed bottom-up decomposition. Figure 4(a) boxplotnumber subproblems per worker (p / w) bottom-up decompositionChoco2 depending number workers. Boxplots display differences among populations without making assumptions underlying statistical distribution:non-parametric. box boxplot spans range values first quartilethird quartile. whiskers extend end box range equal1.5 times interquartile range. points lie outside range whiskersconsidered outliers: drawn individual circles.number workers w {16, 80, 512}, decompositions xcsp instancesusing one variable selection heuristic among lex, dom, dom/ddeg,dom/wdeg, dom/bwdeg,impact, combined minVal, considered. bottom-up decomposition obtainssatisfying average performance (mostly 10 100 subproblems per worker)respecting much possible branching strategy. However, anomalies occur.First, decomposition sensitive shape search tree. Sometimes, modelcontains variables large domains forbid accurate decomposition.instance, first second levels knights-80-5 search tree respectively contain6000 50000 nodes. also significant underestimationtree size, especially branching high arity. instance, width secondlevel fapp07-0600-7 estimated around 950 nodes contains 6000nodes. contrary, underestimation occur top nodes eliminatedsearch tree low arity. Apart underestimation, decomposition accuratesearch trees low arity.top-down decomposition accurate, requires fixed variable ordering, whereasbottom-up decomposition less accurate, handles branching strategy.10.8100instances (%)subproblems per worker1000100.60.410.20.116800512workersChoco2 w=80Choco2 w=512Gecode w=80Gecode w=5120.1110100time (s)(a) Number subproblems per worker.(b) Decomposition time.Figure 4: Analysis decomposition procedures (w = 16, 80, 512).4441000fiEmbarrassingly Parallel Search CP4.2.2 Decomposition TimeFigure 4(b) gives percentage decompositions done within given time. Choco2times reported variable selection heuristics xcsp instances. Gecode timesreported lex xcsp fzn instances.implementation differences, times reported Choco2 Gecodeslightly different. Indeed, decomposition time alone given Gecode. Choco2times take also account estimation time, time taken foreman fillqueue subproblems, time taken workers empty queue. Let usalso remind subproblems become available top-down decompositioncomplete whereas become available fly bottom-up decomposition.cases, reported time lower bound solving time.top-down decomposition faster bottom-up decompositionparallelism. fact, Gecode decomposition often faster estimation time alone.One compelling example instance knights-80-5 highest time (around800 seconds) well poor quality structure problem unsuitedbottom-up decomposition: variables large domains (more6000 values); almost domain reduction top tree;propagation long.conclude, parallel top-down decomposition Gecode fast accuratebottom-up decomposition offers greater flexibility, less robustness.4.2.3 Influence Search Strategyanalyze influence search strategies decomposition resolution,apply variable selection heuristic decomposition (master) another oneresolution (workers). Table 1 gives solving times combinations lexdom solving instances xcsp1. Results reported significantdifferences among solving times. choice variable selection heuristic criticaldecomposition resolution. Indeed, initial choices made branchingleast informed important, lead largest subtreessearch hardly recover early mistakes. on, master workersuse variable selection heuristic.InstancesWorkerMastercostasArray-14latinSquare-dg-8lemma-100-9-modpigeons-14quasigroup5-10queenAttacking-6squares-9-9lexdomlexdomlexdom191.2479.4109.71003.8182.2872.4126.8240.9323.8125.9956.3125.3598.31206.5191.4470.6101.8953.2188.5867.8127.8240.0328.1123.4899.1123.5622.51213.0Table 1: Solving times different search strategies (Choco2, multi-core, w = 2c = 80).445fiMalapert, Regin, & Rezgui4.3 Multi-coresection, use parallel solvers based Thread technologies solve instancesxcsp1 n-queens problem using multi-core computer. Let us recalltwo worker per physical core hyper-threading activated (w = 2c = 80). showEPS frequently gives linear speedups, outperforms work stealing approachproposed Schulte (2000), Nielsen (2006).4.3.1 Performance AnalysisTable 2 gives solving times speedups parallel solvers using 80 workersxcsp1 instances. Choco2 tested lex dom whereas Gecode OR-toolsuse lex. also compared work stealing approach denoted Gecode-WS (Schulte,2000; Nielsen, 2006). First, implementations EPS faster efficientwork stealing. EPS often reaches linear speedups number cores whereas neverhappens work stealing. Even worse, three instances solved within 12hours time limit using work stealing whereas using sequential solver.Choco2, dom efficient parallel lex remains slightly sloweraverage. Decomposition key bad performance instances knights-80-5lemma-100-9-mod. outlined before, decomposition knights-80-5 takes1100 seconds generates much subproblems, forbids speedup. issuelessened using sequential decomposition OR-tools resolved paralleltop-down decomposition Gecode. Note also sequential solving times OR-toolsGecode respectively 20 40 times higher. Similarly, long decomposition timeChoco2 lemma-100-9-mod leads low speedup. However, moderate efficiencyChoco2 Gecode squares-9-9 caused decomposition.Gecode OR-tools often efficient faster Choco2. solvers showdifferent behaviors even using variable selection heuristicInstancescostasArray-14knights-80-5latinSquare-dg-8lemma-100-9-modortholatin-5pigeons-14quasigroup5-10queenAttacking-6series-14squares-9-9(t) GM (su)Borda score (rank)Choco2-lexChoco2-domGecodeOR-toolsGecode-WSsususususu191.21138.3479.4109.7248.71003.8182.2872.439.3126.831.41.239.04.030.013.830.723.429.919.0240.01133.1328.1123.4249.9899.1123.5622.539.31213.038.81.539.24.136.015.532.528.532.916.162.3548.7251.76.7421.7211.818.615899.111.317.919.137.642.010.113.539.126.4?34.218.450.92173.9166.61.8167.7730.317.016.281.433.418.535.222.938.118.536.928.735.0594.04488.53.02044.622.8552.3427.82.02.422.32.821.50.70.8439.215.9497.217.41745.024.0378.428.71161.93.320.6 (3)19.7 (4)26.1 (1)22.8 (2)9.8 (5)Table 2: Solving times speedups (multi-core, w = 2c = 80). Gecode OR-tools uselex heuristic.446fiEmbarrassingly Parallel Search CPpropagation mechanisms decompositions differ. Furthermore, parallel top-downdecomposition Gecode preserve ordering subproblems regardsequential algorithm.4.3.2 Variations N-Queens ProblemHere, verify effectiveness EPS classic CSP settings. consider four modelswell-known n-queens problem (n = 17). n-queens puzzle problem placingn chess queens n n chessboard two queens threaten other. Here,enumerate solutions heuristics lex dom reasonable choices. models are:allDifferent global constraints enforce arc-consistency (AC); allDifferent constraints enforce bound-consistency (BC); arithmetic inequalities constraints (NEQ);dedicated global constraint (JC) (Milano & Trick, 2004, ch. 3).Table 3 gives solving times speedups Choco2 80 workersdecomposition depth either 3 4. striking result splittingtechnique gives excellent results, linear speedup 40 processorsexception JC model. unfortunate since JC model clearly best modelsequential solver. Here, dom always better choice lex. numbersubproblems dom whatever model whereas total number nodeschanges. indicates filtering weak top search tree.works report good results, often linear speedups n-queens problem. Bordeaux et al. (2009) reported linear speedups 30 cores 17 queens,improvement 64 cores, whereas Machado et al. (2013) scales 512 workers using hierarchical work stealing approach. Menouer Le Cun (2014) reportedspeedups around 8 using 12 cores 16 queens, Pedro, Abreu, Pedro, Abreu(2010) reported speedups around 20 using 24 cores. Zoeteweij Arbab (2004) reportedlinear speedups 16 cores 15 queens, Pedro et al. (2010) reported speedup20 using 24 cores, So, EPS efficiency slightly average, similarresults observed 15 16 queens.previous experimental setting favor EPS exploring searchspace exhaustively, problem highly symmetric. Indeed, variance subproblems solving time low, especially higher levels consistency. Notelower speedups JC model probably caused load balancing issuessubproblems NEQ model greater mean variance.Modellexdomd=3BCACNEQJCd=4d=3d=4susususu838.83070.2280.7202.438.338.831.820.4835.13038.9241.9196.938.539.336.921.0640.42336.2188.8140.638.738.836.424.2635.52314.7181.1148.839.039.237.922.9Table 3: Variations 17 queens problem (Choco2, multi-core, w = 2c = 80).447fiMalapert, Regin, & RezguiInstanceslexdomsudom/ddegsudom/bwdegsusudom/wdegcc-15-15-21947.1 5.2 25701.7?1524.9 4.6 2192.1costasArray-14500.4 12.4641.9 12.1 895.3 8.6 4445.0 2.4649.9crossword-m11506.1 4.4492.0 1.9204.6crossword-m1c22376.9 0.6 1173.9 0.6 1316.2 0.5 1471.3 0.7 1611.9fapp07-0600-71069.5 2.1 2295.7knights-20-9359.3 17.2353.9 17.3 357.4 14.9 5337.5 1.3491.3knights-25-9855.3 17.8840.6 18.0 986.1 13.3 13264.8 1.3 1645.2knights-80-5708.5 2.0726.9 2.0 716.4 2.1 1829.5 0.9 1395.6langford-3-1738462.7? 708.3 12.5 5701.6 2.5 6397.5 1.9 3062.240465.2? 148.2 14.4 1541.9 2.2 1307.1 2.1538.3langford-4-18langford-4-19747.2 16.90.0 7280.1 2.3 2735.3latinSquare-dg31161.7 14.3903.2 12.2 812.0 14.4416.9 4.2294.8lemma-100-9-mod110.5 4.1117.6 3.7 180.4 3.7154.4 3.5145.3572.6 13.5558.9 13.5 475.5 11.5453.1 11.6 362.4ortholatin-5pigeons-141330.1 9.8 1492.6 8.3 1471.6 11.8 6331.1 2.6 2993.3397.2 12.6 277.3 12.9 1156.6 3.6733.5 5.2451.5quasigroup5-10queenAttacking-62596.7 7.3 1411.8 10.6 4789.7 4.2 2891.0 1.9706.4queensKnights41517.8 0.2 5209.5ruler-70-12-a3137.4 16.8 2410.6 17.551.5 2.442.86832.0 3.9 4021.1 4.7 7549.2 2.2 1412.0 0.9 1331.3ruler-70-12-a4scen11-f538698.7 0.0series-1477.8 14.889.1 12.4 9828.6 3.4 1232.2 2.6338.9220.7 10.5 1987.4 7.2 129.7 9.4697.2 2.2 115.9squares-9-9squaresUnsat53766.1 1.2 3039.8(t) GM (su)Borda score (rank)145243.17.565.1 (6)2332.28.6 2369.372.8 (5)4.84282.349.6 (8)1.6 1385.091.2 (2)2crossword-m1-words-05-06crossword-m1c-words-vg7-7 extqueensKnights-20-5-mul 5 squaresUnsat-19-193suimpactsu2.1 31596.1?11.4652.2 10.55.1 179.5 2.90.6 4689.6 1.91.817.5 215.4 16.514.1 550.8 16.93.4896.3 2.53.7 5995.6?4.8 1041.5 10.05.6 4778.9?11.328.7 5.03.5226.8 2.513.7641.7 10.65.1 3637.2 4.27.9308.4 27.85.4 427.1 6.21.06.724.8 12.12.3 102.9 24.40.09.9346.5 8.511.0138.9 10.82.94.9100.3 (1)2823.97.781.4 (3)latinSquare-dg-8Table 4: Detailed speedups solving times depending variable selection heuristics(Choco2, data center, w = 16).3025speedup20151050lexdomddegbwdegwdegimpactvariable selectionFigure 5: Speedups variable selection heuristics (Choco2, data center, w = 16).448fiEmbarrassingly Parallel Search CP4.4 Data Centersection, study influence search strategy solving timesspeedups, scalability 512 workers, compare EPS work stealing approach.4.4.1 Influence Search Strategystudy performance Choco2 using 16 workers solving xcsp instances usingvariable selection heuristics presented Section 2.1. Figure 5 boxplotspeedups variable selection heuristic. First, speedups lower dom/bwdegdecomposition effective. binary branching states constraint x =left branch x 6= right branch. So, workload left rightbranches imbalanced. case, positive decisions left branchestaken account. Second, without learning (lex dom), parallel algorithmefficient robust terms speedup. learning (dom/bwdeg, dom/wdeg,impact), parallel algorithm may explore different search tree sequentialone. Indeed, master explores top tree changes learning,possibly branching decisions. worker also learns subproblems,whole search tree. frequently causes exploration overhead solvingqueensKnights-20-5-mul (twelve times nodes using dom/wdeg) or, sometimes givessuper-linear speedup solving quasigroup5-10 (three times less nodes using impact).Last, low speedups occur variable selection heuristics.Table 4 gives solving times speedups obtained different variable selectionheuristics. Borda scores computed Choco2 (Table 4) Gecode (Table 5). First,variable selection heuristics strictly dominates others either sequential parallel.However, dom/wdeg robust outlined Borda scores. fact, variability solving times different heuristics reduced parallelization,remains important. Second, spite low speedups, dom/bwdeg remains secondbest variable selection heuristic parallel solving best one sequential.average, using advanced variable selection heuristics dom/bwdeg, dom/wdeg,impact gives lower solving times lex dom spite lower speedups. highlightsfact decomposition procedures handle branching strategy. Section 4.6.1,investigate low speedups instance crossword-m1c-words-vg7-7caused variable selection heuristics.4.4.2 Scalability 512 WorkersTable 5 compares Gecode implementations EPS work stealing (WS) solvingxcsp instances using 16 512 workers. EPS faster efficient workstealing. 16 workers, work stealing ranked last using Borda score.512 workers, EPS average almost 10 times faster work stealing. alsoefficient parallelize sequential solver. multi-coremachine, Gecode faster Choco2 instances xcsp1. Here, performanceGecode mitigated outlined Borda scores. Five instancessolved within time limit Gecode reported Table 5. Six instancessolved 16 workers whereas twelve instances solved sequentialsolver. way comparison, five instances solved Choco2 using lex449fiMalapert, Regin, & Rezguiw = 16Instancesw = 512EPScc-15-15-2costasArray-14crossword-m1c1crossword-m12knights-20-9knights-25-9knights-80-5langford-3-17langford-4-18langford-4-19latinSquare-dg-8lemma-100-9-modortholatin-5pigeons-14quasigroup5-10queenAttacking-6ruler-70-12-a3ruler-70-12-a4series-14squares-9-9EPSWSsusususu64.4240.6171.75190.77462.31413.724351.53203.226871.2613.53.4309.5383.327.142514.896.6178.922.522.813.613.114.5??11.5???13.114.714.114.513.5?15.114.413.411.169.3482.1178.538347.48329.221252.325721.2621.25.8335.86128.933.737446.1105.5185.256.944.312.76.613.9?2.0??13.08.613.00.910.8?13.813.95.35.73.618.713.3153.4214.949.3713.594.6782.523.61.010.415.31.71283.93.76.01.11.3243.8168.6187.3??329.8???341.751.4422.0363.1211.7?389.3429.5264.0191.717.783.157.83312.4282.67443.55643.1124.42.571.72320.29.89151.567.734.18.27.649.838.043.0?57.5??64.719.761.02.437.3?21.575.536.933.75954.813.58196.77.4178.53246.21684.633.5(t) GM (su)Borda score (rank)1WS76.9 (4)crossword-m1-words-05-06260.3 (7)crossword-m1c-words-vg7-7 extTable 5: Speedups solving times xcsp (Gecode, lex, data center, w = 16 512).heuristics whereas instances solved sequential parallel using dom/wdegdom/bwdeg. again, highlights importance search strategy.Figure 6 boxplot speedups different numbers workers solving fzninstances. median speedups around w2 average dispersion remainslow.512256speedup (su)128643216842163264128256512workers (w)Figure 6: Scalability 512 workers (Gecode, lex, data center).450fiEmbarrassingly Parallel Search CPInstanceEPSmarket split s5-02market split s5-06market split u5-09pop stress 0600nmseq 400pop stress 0500fillomino 18steiner-triples 09nmseq 300golombruler 13cc base mzn rnd test.11ghoulomb 3-7-20still life free 8x8bacp-6depot placement st70 6open stacks 01 wbp 20 20 1bacp-27still life still life 9talent scheduling alt film117(t) GM (su)WSsusu467.1452.7468.1874.8342.4433.2160.2108.8114.524.324.424.410.88.510.113.917.26.6658.6650.7609.22195.7943.2811.0184.6242.4313.117.317.018.74.33.15.412.17.72.4154.01143.6618.2931.2400.8433.9302.7260.2189.022.720.67.36.89.616.418.317.616.416.974.0210.42261.33366.01199.4831.01172.5374.1548.4196.8110.515.13.71.27.57.96.814.37.816.215.2414.715.1888.47.7Table 6: Solving times speedups fzn (Gecode, lex, cloud, w = 24).4.5 Cloud ComputingEPS deployed Microsoft Azure cloud platform. available computinginfrastructure organized follows: cluster nodes computes application; one headnode manages cluster nodes; proxy nodes load-balances communicationcluster nodes. contrary data center, cluster nodes may farcommunication time may take longer. Proxy nodes requires 2 cores managedservice provider. Here, 3 nodes 8 cores 56 GB RAM memory provide 24workers (cluster nodes) managed MPI.Table 6 compares Gecode implementations EPS work stealing solvingfzn instances 24 workers. Briefly, EPS always faster work stealing,therefore, efficient parallelize sequential solver. workstealing suffers higher communication overhead cloud data center.Furthermore, architecture computing infrastructure location clusternodes mostly unknown forbid improvements work stealingproposed Machado et al. (2013), Xie Davenport (2010).4.6 Embarrassingly Distributed Searchsection, transform reasonable effort parallel solver (EPS) distributedparallel solver (EDPS) using batch scheduler OAR (Capit et al., 2005) provided451fiMalapert, Regin, & Rezguidata center. fact, batch scheduler OAR plays foreman. parallel Choco2solver modified workers write subproblems files instead solvingthem. Then, script submits jobs/subproblems OAR batch scheduler, waitstermination, gathers results. OAR schedules jobs cluster usingpriority FIFO backfilling fair-share based priorities. Backfilling allows startlower priority jobs without delaying highest priority jobs whereas fair-share meansuser/application preferred way. main drawback new worker mustcreated subproblem. worker process allocated OAR predefinedresources. worker either sequential (EDS) parallel solver (EDPS).approach offers practical advantage resource reservation data center.Indeed, asking MPI process, one wait enough resources availableprocess starts. Here, resources (cores nodes) nibbled soonbecome available drastically reduce waiting time. Furthermore, bypasseslimitations Threads Technology allowing use multiple nodes data center.However, clearly increases recomputation overhead because, worker solves singlesubproblem instead multiple subproblems. So, model creation initial propagationrealized often. also introduces non-negligible submission overheadtime taken create submit jobs OAR batch scheduler.4.6.1 Anomaly crossword-m1c-words-vg7-7 extinvestigate low speedups solving instance crossword-m1c-words-vg7-7variable selection heuristic (see Table 4). compare results parallel(EPS, w = 16) distributed (EDS sequential worker) algorithms different decomposition depths (d = 1, 2, 3). Table 7 gives solving times, speedups, efficiencies.number distinct cores used distributed algorithm bad estimator computing efficiencies, used short period time. Therefore,number c cores used compute efficiency EDS EDPS estimatedratio total runtime wall-clock time.First, parallel algorithm always slower sequential one. However,speedups distributed algorithms significant even decrease quicklydecomposition depth increases. fall efficiency shows EDS scalablesequential workers. Indeed, recomputation, especially submission overheadbecome important number subproblems increases.Second, bad performance parallel algorithms caused statisticallyimbalanced decomposition would observe similar performance distributedalgorithm. Profiling parallel algorithm particular instances suggests badEDSp2341868272935EPS (w = 16)sueffsueff73.0229.0797.010.23.31.10.4350.1280.0391069.91074.21091.80.70.70.70.0440.0440.044Table 7: EDS EPS crossword instance (Choco2, dom, data center).452fiEmbarrassingly Parallel Search CPperformance comes underlying solver itself. Indeed, number instructionssimilar sequential parallel algorithms whereas numbers context switches,cache references cache misses increase considerably. fact, parallel algorithmsspent half time internal methods extensional constraints, i.e.relation constraint specified listing satisfying tuples. issue occurredcomputing infrastructure different Java virtual machines. Note instancesuse extensional constraints, impose fewer consequences. issue wouldhappen MPI implementation shared memory. So, advocatesimplementations EPS based MPI rather Thread Technology.4.6.2 Variations Golomb Ruler ProblemGolomb ruler set marks integer positions along imaginary rulertwo pairs marks distance apart. number marks rulerorder, largest distance two marks length. Here, enumerateoptimal rulers (minimal length specific number marks) simple constraintmodel inspired one Galinier, Jaumard, Morales, Pesant (2001)heuristics lex dom reasonable choice. Table 8 gives solving times, speedups,efficiencies parallel algorithm (w = 16), distributed algorithm sequentialworkers (w = 1), distributed algorithms parallel workers (w = 16worker decomposition depth dw = 2) different master decomposition depths d.First, EPS obtains almost linear speedup decomposition depth large enough.Without surprise, speedups lower enough subproblems. Second,distributed algorithm EDS sequential workers efficient number subproblems remains low. Otherwise, still give speedups (dom), wastesresources since efficiency low. fact, submitting many jobs batchscheduler (lex) lead high submission overhead (around 13 minutes) globally degrades performance. Finally, distributed algorithms parallel workers offergood trade-off speedups efficiencies allows use many resourcessubmitting jobs thus reducing submission recomputation overheads. Note EDS = 1 tested roughly equivalent EPS16 workers, EDPS = 3 tested submission overhead becomesimportant.EDPS (w = 16, dw = 2)EDSpsueffsulex1232057514223769.017880.066.82.90.8460.005572.0497.089.7103.3dom1232022253332394.03018.050,540,00,9890,1461538.0366.078,6330,2EPS (w = 16)sueff0.9680.23211141.74084.23502.64.612.614.70.2880.7860.9160,9350,74228299,99703,68266,64,312,414,60,2670,7780,914effTable 8: EDS EPS Golomb Ruler 14 marks (Choco2, data center).453fiMalapert, Regin, & Rezguiparallel approaches reported good performance Golomb ruler problem. instance, Michel et al. (2009), Chu et al. (2009) respectively reported linearspeedups 4 8 workers. EDS efficient work stealing proposedMenouer Le Cun (2014) using 48 workers ruler 13 marks efficientselfsplit Fischetti et al. (2014) using 64 workers ruler 14 marks.Last, enumerated optimal Golomb Rulers 15 16 marks using EDPS.Master workers use lex heuristic. master decomposition depth equal2 generates around 800 hundreds subproblems. 16 parallel workersdecomposition depth dw equal 2. settings, used 700 coresdata center solving process. So, bypasses limitations numbercores used MPI imposed administrator. Furthermore, solving process startsimmediately cores grabbed soon become available whereas MPIprocess waits enough cores becomes simultaneously available. Enumerating optimalrulers 15 16 marks respectively took 1422 5246 seconds. knowledge,first time constraint solver finds rulers, furthermore reasonable amount time. However, optimal rulers discovered via exhaustivecomputer search (Shearer, 1990). recently, Distributed Computing Technologies Inc(20) found optimum rulers 26 marks. Beside, plane construction (Atkinson & Hassenklover, 1984) allows find larger optimal rulers.4.7 Comparison PortfoliosPortfolio approaches exploit variability performance observed severalsolvers, several parameter settings solver. use 4 portfolios. portfolioCPHydra (OMahony et al., 2008) uses features selection top solvers Mistral,Gecode, Choco2. CPHydra uses case-based reasoning determine solveunseen problem instance exploiting case base problem solving experience. aimsfind feasible solution within 30 minutes, handle optimization solution problems time limit hard-coded. static fixed-size portfolios(Choco2, CAG, OR-tools) use different variable selection heuristics (see Section 2.1) wellrandomization restarts. Details Choco2 CAG found (Malapert &Lecoutre, 2014). CAG portfolio extends Choco2 portfolio also using solversAbsCon Gecode. So, CAG always produces better results Choco2. OR-toolsportfolio gold medal Minizinc challenge 2013 2014. seem unfaircompare parallel solvers portfolios using different numbers workers, designingscalable portfolio (up 512 workers) difficult task almost implementationpublicly available.Table 9 gives solving times EPS portfolios solving xcsp instancesdata center. First, CPHydra 16 workers solves 2 among 16 unsatisfiable instances(cc-15-15-2 pigeons-14), less 2 seconds whereas difficultapproaches. OR-tools second less efficient approach solves fewerproblems often takes longer confirmed low Borda score. parallel Choco2using dom/wdeg better average Choco2 portfolio even portfolio solvesinstances much faster scen11-f5 queensKnights-20-5-mul. case,diversification provided portfolio outperforms speedups offered parallel454fiEmbarrassingly Parallel Search CPInstancesEPSChoco2cc-15-15-2costasArray-14crossword-m1-words-05-06crossword-m1c-words-vg7-7 extfapp07-0600-7knights-20-9knights-25-9knights-80-5langford-3-17langford-4-18langford-4-19latinSquare-dg-8lemma-100-9-modortholatin-5pigeons-14quasigroup5-10queenAttacking-6queensKnights-20-5-mulruler-70-12-a3ruler-70-12-a4scen11-f5series-14squares-9-9squaresUnsat-19-19Arithmetic meanBorda score (rank)PortfolioGecodeChoco2CAGOR-toolsw = 16w = 16w = 512w = 14w = 23w = 162192.1649.9204.61611.92295.7491.31645.21395.63062.2538.32735.3294.8145.3362.42993.3451.5706.45209.542.81331.3338.9115.93039.864.4240.6171.75190.77462.31413.724351.53203.226871.2613.53.4309.5383.327.142514.896.6178.922.522.83.618.713.3153.4214.949.3713.594.6782.523.61.010.415.31.71283.93.76.01.11.31102.66180.8512.3721.237.93553.99324.81451.58884.72126.012640.265.1435.34881.212336.93545.82644.5235.3123.51250.245.31108.31223.74621.13.5879.4512.3721.23.20.81.1301.68884.72126.012640.236.450.14371.05564.5364.32644.51.0123.51250.28.5302.1254.34621.11070.01368.822678.113157.232602.64599.838.24438.712279.6546.08763.1416.2138.31385.05954.8178.53293.81902.77853.665.0 (3)52.2 (5)77.1 (1)57.0 (4)72.8 (2)20.0 (6)Table 9: Solving times EPS portfolio (data center).B&B algorithm. emphasized CAG portfolio solves instancesobtains several best solving times. parallel Gecode 16 workers often slowerless robust portfolios Choco2 CAG. However, increasing numberworkers 512 clearly makes fastest solver, still less robust five instancessolved within time limit.conclude, Choco2 CAG portfolios robust thanks inherent diversification, solving times vary one instance another. 16 workers,implementations EPS outperform CPHydra OR-tools portfolio, competitiveChoco2 portfolio, slightly dominated CAG portfolio. fact,good scaling EPS key beat portfolios.5. Conclusionintroduced Embarrassingly Parallel Search (EPS) method solving constraintsatisfaction problems constraint optimization problems. approach severaladvantages. First, efficient method matches even outperforms state-of-the455fiMalapert, Regin, & Rezguiart algorithms number problems using various computing infrastructures. Second,involves almost communication synchronization mostly relies underlyingsequential solver implementation debugging made easier. Last,simplicity method allows propose many variants adapted specific applicationscomputing infrastructures. Moreover, certain restrictions, parallel algorithmdeterministic, even mimic sequential algorithm importantpractice either production debugging.several interesting perspectives around EPS. First, modified orderprovide diversification learn useful information solving subproblems.instance, easily combined portfolio approach subproblemssolved several search strategies. Second, thanks simplicity, simplest variantsEPS could implemented meta-searches (Rendl, Guns, Stuckey, & Tack, 2015),would offer convenient way parallelize applications satisfactory efficiency. Last,another perspective predict solution time large combinatorial problem, basedknown solution times small set subproblems based statistical machinelearning approaches.Acknowledgmentswould like thank much Christophe Lecoutre, Laurent Perron, Youssef Hamadi,Carine Fedele, Bertrand Lecun Tarek Menouer comments adviceshelped improve paper. work supported CNRS OSEO(BPI France) within ISI project Pajero. work granted access HPCvisualization resources Centre de Calcul Interactif hosted Universite Nice SophiaAntipolis, also Microsoft Azure Cloud. also wish thank anonymousreferees comments.Appendix A. Efficiency Hyper-Threadingsection, show hyper-threading technology improves efficiency EPSsolving instances xcsp1 multi-core computer. Figure 7 boxplotspeedups provided hyper-threading parallel solver among Choco2, Gecode,OR-tools. Here, speedups indicate many times parallel solver using 80 workers(w = 2c) faster one using 40 workers (w = c). maximum speedup accordingAmdahls law 2.Choco2 tested lex dom whereas Gecode OR-tools use lex.also compared work stealing approach proposed Schulte (2000) denotedGecode-WS. Hyper-threading clearly improves parallel efficiency EPS whereasperformance work stealing roughly remains unchanged. interestingEPS high CPU demand resources physical core sharedtwo logical cores. Indeed, performance hyper-threading knownapplication-dependent. exception lemma-100-9-mod squares-9-9, Choco2OR-tools faster 80 workers. lemma-100-9-mod, Choco2 decomposition80 workers takes longer generates many subproblems. instance solved456fiEmbarrassingly Parallel Search CPhyperthreading speedup210.5Choco2-lexChoco2-domGecodeOR-toolsGecode-WSFigure 7: Speedups provided hyper-threading (multi-core, w = 40, 80).easily OR-tools (less two seconds) becomes difficult improve efficiency. squares-9-9, decomposition changes according number workers,cannot explain hyper-threading improve EPS. parallel efficiencyGecode reduced multiple instances interest hyper-threading less obviousChoco2 OR-tools. conclude, hyper-threading globally improves efficiencyEPS limited interest work stealing.ReferencesAlmasi, G. S., & Gottlieb, A. (1989). Highly Parallel Computing. Benjamin-CummingsPublishing Co., Inc., Redwood City, CA, USA.Amadini, R., Gabbrielli, M., & Mauro, J. (2013). Empirical Evaluation PortfoliosApproaches Solving CSPs Gomes, C., & Sellmann, M.Eds., IntegrationAI Techniques Constraint Programming Combinatorial OptimizationProblems, Vol. 7874 Lecture Notes Computer Science, pp. 316324. SpringerBerlin Heidelberg.Amdahl, G. (1967). Validity Single Processor Approach Achieving Large ScaleComputing Capabilities Proceedings April 18-20, 1967, Spring Joint Computer Conference, AFIPS 67, pp. 483485, New York, NY, USA. ACM.Anderson, D. P., Cobb, J., Korpela, E., Lebofsky, M., & Werthimer, D. (2002). Seti@home:experiment public-resource computing Commun. ACM, 45 (11), 5661.Atkinson, M. D., & Hassenklover, A. (1984). Sets Integers Distinct Differences Tech.Rep. SCS-TR-63, School Computer Science, Carlton University, Ottawa Ontario,Canada.Bader, D., Hart, W., & Phillips, C. (2005). Parallel Algorithm Design BranchBound G, H.Ed., Tutorials Emerging Methodologies Applications Operations Research, Vol. 76 International Series Operations Research & ManagementScience, pp. 51544. Springer New York.457fiMalapert, Regin, & RezguiBarney, B., & Livermore, L. (2016). Introduction Parallel Computingcomputing.llnl.gov/tutorials/parallel comp/.https://Bauer, M. A. (2007). High performance computing: software challenges Proceedings2007 International Workshop Parallel Symbolic Computation, PASCO 07,pp. 1112, New York, NY, USA. ACM.Beck, C., Prosser, P., & Wallace, R. (2005). Trying Fail-First Recent AdvancesConstraints, pp. 4155. Springer Berlin Heidelberg.Bordeaux, L., Hamadi, Y., & Samulowitz, H. (2009). Experiments Massively ParallelConstraint Solving. Boutilier (Boutilier, 2009), pp. 443448.Boussemart, F., Hemery, F., Lecoutre, C., & Sais, L. (2004). Boosting Systematic SearchWeighting Constraints Proceedings 16th Eureopean Conference Artificial Intelligence, ECAI2004, including Prestigious Applicants Intelligent Systems,PAIS, pp. 146150.Boutilier, C.Ed.. (2009). IJCAI 2009, Proceedings 21st International Joint ConferenceArtificial Intelligence, Pasadena, California, USA, July 11-17.Brams, S. J., & Fishburn, P. C. (2002). Voting procedures Arrow, K. J., Sen, A. K.,& Suzumura, K.Eds., Handbook Social Choice Welfare, Vol. 1 HandbookSocial Choice Welfare, chap. 4, pp. 173236. Elsevier.Budiu, M., Delling, D., & Werneck, R. (2011). DryadOpt: Branch-and-bound distributeddata-parallel execution engines Parallel Distributed Processing Symposium(IPDPS), 2011 IEEE International, pp. 12781289. IEEE.Burton, F. W., & Sleep, M. R. (1981). Executing Functional Programs Virtual TreeProcessors Proceedings 1981 Conference Functional ProgrammingLanguages Computer Architecture, FPCA 81, pp. 187194, New York, NY, USA.ACM.Capit, N., Da Costa, G., Georgiou, Y., Huard, G., Martin, C., Mounie, G., Neyron, P., &Richard, O. (2005). Batch Scheduler High Level Components ProceedingsFifth IEEE International Symposium Cluster Computing Grid (CCGrid05) - Volume 2 - Volume 02, CCGRID 05, pp. 776783, Washington, DC, USA.IEEE Computer Society.Choco, T. (2010). Choco: open source java constraint programming library Ecole desMines de Nantes, Research report, 1, 1002.Chong, Y. L., & Hamadi, Y. (2006). Distributed Log-Based Reconciliation Proceedings2006 Conference ECAI 2006: 17th European Conference Artificial Intelligence August 29 September 1, 2006, Riva Del Garda, Italy, pp. 108112, Amsterdam,Netherlands, Netherlands. IOS Press.Chu, G., Schulte, C., & Stuckey, P. J. (2009). Confidence-Based Work Stealing Parallel Constraint Programming Gent, I. P.Ed., CP, Vol. 5732 Lecture NotesComputer Science, pp. 226241. Springer.Chu, G., Stuckey, P. J., & Harwood, A. (2008). PMiniSAT: Parallelization MiniSAT2.0 Tech. Rep., NICTA : National ICT Australia.458fiEmbarrassingly Parallel Search CPCire, A. A., Kadioglu, S., & Sellmann, M. (2014). Parallel Restarted Search ProceedingsTwenty-Eighth AAAI Conference Artificial Intelligence, AAAI14, pp. 842848. AAAI Press.Cornuejols, G., Karamanov, M., & Li, Y. (2006). Early Estimates Size Branchand-Bound Trees INFORMS Journal Computing, 18, 8696.Crainic, T. G., Le Cun, B., & Roucairol, C. (2006). Parallel branch-and-bound algorithmsParallel combinatorial optimization, 1, 128.De Kergommeaux, J. C., & Codognet, P. (1994). Parallel logic programming systems ACMComputing Surveys (CSUR), 26 (3), 295336.Distributed Computing Technologies Inc (20). Distributed.net home page http://www.distributed.net/.Een, N., & Sorensson, N. (2005). MiniSat: SAT solver conflict-clause minimizationSat, 5, 1.Ezzahir, R., Bessiere, C., Belaissaoui, M., & Bouyakhf, E. H. (2007). DisChoco: platformdistributed constraint programming DCR07: Eighth International WorkshopDistributed Constraint Reasoning - conjunction IJCAI07, pp. 1621, Hyderabad, India.Fischetti, M., Monaci, M., & Salvagnin, D. (2014). Self-splitting workload parallelcomputation Simonis, H.Ed., Integration AI Techniques ConstraintProgramming: 11th International Conference, CPAIOR 2014, Cork, Ireland, May 1923, 2014. Proceedings, pp. 394404, Cham. Springer International Publishing.Gabriel, E., Fagg, G., Bosilca, G., Angskun, T., Dongarra, J., Squyres, J., Sahay, V., Kambadur, P., Barrett, B., Lumsdaine, A., et al. (2004). Open MPI: Goals, Concept,Design next generation MPI implementation Recent Advances ParallelVirtual Machine Message Passing Interface, pp. 97104. Springer.Galea, Fran c., & Le Cun, B. (2007). Bob++ : Framework Exact CombinatorialOptimization Methods Parallel Machines International Conference High Performance Computing & Simulation 2007 (HPCS07) conjunction 21stEuropean Conference Modeling Simulation (ECMS 2007), pp. 779785.Galinier, P., Jaumard, B., Morales, R., & Pesant, G. (2001). Constraint-Based ApproachGolomb Ruler Problem 3rd International Workshop integration AItechniques.Gendron, B., & Crainic, T. G. (1994). Parallel branch-and-bound algorithms: Surveysynthesis Operations research, 42 (6), 10421066.Gent, I., & Walsh, T. (1999). CSPLIB: Benchmark Library Constraints Proceedings 5th International Conference Principles Practice ConstraintProgramming, CP 99, pp. 480481.Gomes, C., & Selman, B. (1997). Algorithm Portfolio Design: Theory vs. PracticeProceedings Thirteenth conference Uncertainty artificial intelligence, pp.190197.459fiMalapert, Regin, & RezguiGomes, C., & Selman, B. (1999). Search strategies hybrid search spaces ToolsArtificial Intelligence, 1999. Proceedings. 11th IEEE International Conference, pp.359364. IEEE.Gomes, C., & Selman, B. (2000). Hybrid Search Strategies Heterogeneous Search SpacesInternational Journal Artificial Intelligence Tools, 09, 4557.Gomes, C., & Selman, B. (2001). Algorithm Portfolios Artificial Intelligence, 126, 4362.Gropp, W., & Lusk, E. (1993). MPI communication library: design portableimplementation Scalable Parallel Libraries Conference, 1993., Proceedings the,pp. 160165. IEEE.Gupta, G., Pontelli, E., Ali, K. A., Carlsson, M., & Hermenegildo, M. V. (2001). Parallelexecution prolog programs: survey ACM Transactions Programming LanguagesSystems (TOPLAS), 23 (4), 472602.Halstead, R. (1984). Implementation Multilisp: Lisp Multiprocessor Proceedings1984 ACM Symposium LISP Functional Programming, LFP 84, pp.917, New York, NY, USA. ACM.Hamadi, Y. (2002). Optimal Distributed Arc-Consistency Constraints, 7, 367385.Hamadi, Y., Jabbour, S., & Sais, L. (2008). ManySAT: Parallel SAT Solver. JournalSatisfiability, Boolean Modeling Computation, 6 (4), 245262.Haralick, R., & Elliott, G. (1980). Increasing Tree Search Efficiency Constraint Satisfaction Problems Artificial intelligence, 14 (3), 263313.Harvey, W. D., & Ginsberg, M. L. (1995). Limited Discrepancy Search ProceedingsFourteenth International Joint Conference Artificial Intelligence, IJCAI 95,Montreal Quebec, Canada, August 20-25 1995, 2 Volumes, pp. 607615.Heule, M. J., Kullmann, O., Wieringa, S., & Biere, A. (2012). Cube conquer: GuidingCDCL SAT solvers lookaheads Hardware Software: Verification Testing,pp. 5065. Springer.Hirayama, K., & Yokoo, M. (1997). Distributed Partial Constraint Satisfaction ProblemPrinciples Practice Constraint Programming-CP97, pp. 222236. Springer.Hyde, P. (1999). Java thread programming, Vol. 1. Sams.Intel Corporation (2015). Intel MPI Library https://software.intel.com/en-us/intel-mpi-library.Jaffar, J., Santosa, A. E., Yap, R. H. C., & Zhu, K. Q. (2004). Scalable Distributed DepthFirst Search Greedy Work Stealing 16th IEEE International ConferenceTools Artificial Intelligence, pp. 98103. IEEE Computer Society.Kale, L., & Krishnan, S. (1993). CHARM++: portable concurrent object oriented systembased C++, Vol. 28. ACM.Kasif, S. (1990). Parallel Complexity Discrete Relaxation Constraint Satisfaction networks Artificial Intelligence, 45, 275286.Kautz, H., Horvitz, E., Ruan, Y., Gomes, C., & Selman, B. (2002). Dynamic Restart Policies18th National Conference Artificial Intelligence AAAI/IAAI, 97, 674681.460fiEmbarrassingly Parallel Search CPKjellerstrand, H. (2014). Hakan Kjellerstrands Blog http://www.hakank.org/.Kleiman, S., Shah, D., & Smaalders, B. (1996). Programming threads. Sun Soft Press.Korf, R. E., & Schreiber, E. L. (2013). Optimally Scheduling Small Numbers IdenticalParallel Machines Borrajo, D., Kambhampati, S., Oddi, A., & Fratini, S.Eds.,ICAPS. AAAI.Krishna, J., Balaji, P., Lusk, E., Thakur, R., & Tiller, F. (2010). Implementing MPIWindows: Comparison Common Approaches Unix Recent AdvancesMessage Passing Interface, Vol. 6305 Lecture Notes Computer Science, pp.160169. Springer Berlin Heidelberg.Lai, T.-H., & Sahni, S. (1984). Anomalies Parallel Branch-and-bound Algorithms Commun. ACM, 27 (6), 594602.Lantz, E. (2008). Windows HPC Server : Using Microsoft Message Passing Interface (MSMPI).Le Cun, B., Menouer, T., & Vander-Swalmen, P. (2007). Bobpp http://forge.prism.uvsq.fr/projects/bobpp.Leaute, T., Ottens, B., & Szymanek, R. (2009). FRODO 2.0: open-source frameworkdistributed constraint optimization. Boutilier (Boutilier, 2009), pp. 160164.Leiserson, C. E. (2010). Cilk++ concurrency platform Journal Supercomputing,51 (3), 244257.Lester, B. (1993). art parallel programming. Prentice Hall Englewood Cliffs, NJ.Li, H. (2009). Introducing Windows Azure. Apress, Berkely, CA, USA.Luby, M., Sinclair, A., & Zuckerman, D. (1993). Optimal Speedup Las Vegas AlgorithmsInf. Process. Lett., 47, 173180.Machado, R., Pedro, V., & Abreu, S. (2013). Scalability Constraint ProgrammingHierarchical Multiprocessor Systems ICPP, pp. 530535. IEEE.Malapert, A., & Lecoutre, C. (2014). propos de la bibliotheque de modeles XCSP10emes Journees Francophones de Programmation par Contraintes(JFPC15),Angers, France.Mattson, T., Sanders, B., & Massingill, B. (2004). Patterns Parallel Programming (Firsted.). Addison-Wesley Professional.Menouer, T., & Le Cun, B. (2013). Anticipated Dynamic Load Balancing Strategy Parallelize Constraint Programming Search 2013 IEEE 27th International SymposiumParallel Distributed Processing Workshops PhD Forum, pp. 17711777.Menouer, T., & Le Cun, B. (2014). Adaptive N P Portfolio Solving ConstraintProgramming Problems Top Parallel Bobpp Framework 2014 IEEE 28thInternational Symposium Parallel Distributed Processing Workshops PhDForum.Michel, L., See, A., & Hentenryck, P. V. (2009). Transparent Parallelization ConstraintProgramming INFORMS Journal Computing, 21, 363382.461fiMalapert, Regin, & RezguiMicrosoft Corporation (2015). Microsoft HPC Pack 2012 R2 HPC Pack 2012 http://technet.microsoft.com/en-us/library/jj899572.aspx.Milano, M., & Trick, M. (2004). Constraint Integer Programming: Toward UnifiedMethodology. Springer US, Boston, MA.Moisan, T., Gaudreault, J., & Quimper, C.-G. (2013). Parallel Discrepancy-Based SearchPrinciples Practice Constraint Programming, Vol. 8124 Lecture NotesComputer Science, pp. 3046. Springer Berlin Heidelberg.Moisan, T., Quimper, C.-G., & Gaudreault, J. (2014). Parallel Depth-bounded DiscrepancySearch Simonis, H.Ed., Integration AI Techniques Constraint Programming: 11th International Conference, CPAIOR 2014, Cork, Ireland, May 19-23,2014. Proceedings, pp. 377393, Cham. Springer International Publishing.MPI-CH Team (2015). High-Performance Portable MPI http://www.mpich.org/.Mueller, F., et al. (1993). Library Implementation POSIX Threads UNIX.USENIX Winter, pp. 2942.Nguyen, T., & Deville, Y. (1998). distributed arc-consistency algorithm ScienceComputer Programming, 30 (12), 227 250. Concurrent Constraint Programming.NICTA Optimisation Research Group (2012). MiniZinc FlatZinc http://www.g12.csse.unimelb.edu.au/minizinc/.Nielsen, M. (2006). Parallel Search Gecode Masters thesis, KTH Royal InstituteTechnology.OMahony, E., Hebrard, E., Holland, A., Nugent, C., & OSullivan, B. (2008). Using casebased reasoning algorithm portfolio constraint solving Irish ConferenceArtificial Intelligence Cognitive Science, pp. 210216.Pedro, V., Abreu, S., Pedro, V., & Abreu, S. (2010). Distributed Work Stealing Constraint Solving CoRR, abs/1009.3800, 118.Perron, L. (1999). Search Procedures Parallelism Constraint Programming Principles Practice Constraint Programming CP99: 5th International Conference,CP99, Alexandria, VA, USA, October 11-14, 1999. Proceedings, pp. 346360, Berlin,Heidelberg. Springer Berlin Heidelberg.Perron, L., Nikolaj, V. O., & Vincent, F. (2012). Or-Tools Tech. Rep., Google.Pruul, E., Nemhauser, G., & Rushmeier, R. (1988). Branch-and-bound Parallel Computation: historical note Operations Research Letters, 7, 6569.Refalo, P. (2004). Impact-Based Search Strategies Constraint Programming Wallace,M.Ed., Principles Practice Constraint Programming, 10th International Conference, CP 2004, Toronto, Canada, Vol. 3258 Lecture Notes Computer Science,pp. 557571. Springer.Regin, J.-C., Rezgui, M., & Malapert, A. (2013). Embarrassingly Parallel Search Principles Practice Constraint Programming: 19th International Conference, CP2013, Uppsala, Sweden, September 16-20, 2013. Proceedings, pp. 596610. SpringerBerlin Heidelberg, Berlin, Heidelberg.462fiEmbarrassingly Parallel Search CPRegin, J.-C., Rezgui, M., & Malapert, A. (2014). Improvement Embarrassingly Parallel Search Data Centers OSullivan, B.Ed., Principles Practice ConstraintProgramming: 20th International Conference, CP 2014, Lyon, France, September 812, 2014. Proceedings, Vol. 8656 Lecture Notes Computer Science, pp. 622635.Springer International Publishing, Cham.Rendl, A., Guns, T., Stuckey, P., & Tack, G. (2015). MiniSearch: Solver-IndependentMeta-Search Language MiniZinc Pesant, G., Pesant, G., & Pesant, G.Eds.,Principles Practice Constraint Programming: 21st International Conference,CP 2015, Cork, Ireland, August 31 September 4, 2015, Proceedings, Vol. 9255Lecture Notes Computer Science, pp. 376392. Springer International Publishing,Cham.Rezgui, M., Regin, J.-C., & Malapert, A. (2014). Using Cloud Computing SolvingConstraint Programming Problems First Workshop Cloud Computing Optimization, conference workshop CP 2014, Lyon, France.Rolf, C. C., & Kuchcinski, K. (2009). Parallel Consistency Constraint ProgrammingPDPTA 09: 2009 International Conference Parallel Distributed Processing Techniques Applications, 2, 638644.Rossi, F., Van Beek, P., & Walsh, T.Eds.. (2006). Handbook Constraint Programming.Elsevier.Roussel, O., & Lecoutre, C. (2008). Xml representation constraint networks formathttp://www.cril.univ-artois.fr/CPAI08/XCSP2 1Competition.pdf.Schulte, C. (2000). Parallel Search Made Simple Proceedings TRICS: TechniquesImplementing Constraint programming Systems, post-conference workshopCP 2000, pp. 4157, Singapore.Schulte, C. (2006). Gecode: Generic Constraint Development Environment http://www.gecode.org/.Shearer, J. B. (1990). New Optimum Golomb Rulers IEEE Trans. Inf. Theor., 36 (1),183184.Stephan, K., & Michael, K. (2011). SArTagnan - parallel portfolio SAT solverlockless physical clause sharing Pragmatics SAT.Sutter, H., & Larus, J. (2005). free lunch over: fundamental turn toward towardConcurrency Dr. Dobbs Journal, 30, 202210.Van Der Tak, P., Heule, M. J., & Biere, A. (2012). Concurrent cube-and-conquer TheoryApplications Satisfiability TestingSAT 2012, pp. 475476. Springer.Vidal, V., Bordeaux, L., & Hamadi, Y. (2010). Adaptive K-Parallel Best-First Search:Simple Efficient Algorithm Multi-Core Domain-Independent PlanningProceedings Third International Symposium Combinatorial Search. AAAIPress.Wahbi, M., Ezzahir, R., Bessiere, C., & Bouyakhf, E.-H. (2011). DisChoco 2: PlatformDistributed Constraint Reasoning Proceedings IJCAI11 workshopDistributed Constraint Reasoning, DCR11, pp. 112121, Barcelona, Catalonia, Spain.463fiMalapert, Regin, & RezguiWilkinson, B., & Allen, M. (2005). Parallel Programming: Techniques ApplicationUsing Networked Workstations Parallel Computers (2nd ed.). Prentice-Hall Inc.Xie, F., & Davenport, A. (2010). Massively Parallel Constraint Programming Supercomputers: Challenges Initial Results Integration AI TechniquesConstraint Programming Combinatorial Optimization Problems: 7th International Conference, CPAIOR 2010, Bologna, Italy, June 14-18, 2010. Proceedings, Vol.6140 Lecture Notes Computer Science, pp. 334338, Berlin, Heidelberg. SpringerBerlin Heidelberg.Xu, L., Hoos, H., & Leyton-Brown, K. (2010). Hydra: Automatically Configuring Algorithms Portfolio-Based Selection AAAI Conference Artificial Intelligence,Vol. 10, pp. 210216.Xu, L., Hutter, F., Hoos, H., & Leyton-Brown, K. (2008). SATzilla: Portfolio-based Algorithm Selection SAT Journal Artificial Intelligence Research, 32, 565606.Yokoo, M., Ishida, T., & Kuwabara, K. (1990). Distributed Constraint Satisfaction DAIProblems Proceedings 1990 Distributed AI Workshop, Bandara, TX.Zoeteweij, P., & Arbab, F. (2004). Component-Based Parallel Constraint Solver DeNicola, R., Ferrari, G. L., & Meredith, G.Eds., Coordination, Vol. 2949 LectureNotes Computer Science, pp. 307322. Springer.464fiJournal Artificial Intelligence Research 57 (2016) 273-306Submitted 11/15; published 10/16Effective Heuristics Suboptimal Best-First SearchChristopher WiltWheeler Rumlwilt cs.unh.eduruml cs.unh.eduDepartment Computer ScienceUniversity New HampshireDurham, NH 03824 USAAbstractSuboptimal heuristic search algorithms weighted A* greedy best-first searchwidely used solve problems guaranteed optimal solutions expensiveobtain. algorithms crucially rely heuristic function guide search.However, research building heuristics addresses optimal solving. paper,illustrate established wisdom constructing heuristics optimal search failconsidering suboptimal search. consider behavior greedy best-first searchdetail test several hypotheses predicting heuristic effectiveit. results suggest predictive characteristic heuristics goal distance rankcorrelation (GDRC), robust measure whether orders nodes according distancegoal. demonstrate GDRC used automatically construct abstractionbased heuristics greedy best-first search effective builtmethods oriented toward optimal search. results reinforce point suboptimalsearch deserves sustained attention specialized methods own.1. IntroductionA* best-first search expands nodes order f (n) f (n) = g(n) + h(n).optimal solutions provided A* (Hart, Nilsson, & Raphael, 1968)desirable, time memory often prevent application algorithm. A* failseither insufficient time memory, practitioners sometimes turn boundedsuboptimal algorithms may return optimal solution, return solutionguaranteed certain factor expensive optimalsolution.well-known likely Weighted A* (Pohl, 1970), best-firstsearch expands nodes f order, f (n) = g(n) + w h(n) : w (1, ). VariantsWeighted A* used wide variety applications, including domain-independentplanning (Helmert, 2006; Richter & Westphal, 2010) robotics (Likhachev, Gordon, &Thrun, 2003; Likhachev & Ferguson, 2009). Weighted A* also component numberanytime algorithms. example, Anytime Restarting Weighted A* (Richter, Thayer,& Ruml, 2009) Anytime Repairing A* (Likhachev et al., 2003) use Weighted A*.Anytime Nonparametric A* (van den Berg, Shah, Huang, & Goldberg, 2011) doesnt useWeighted A* per se, rather limiting case, greedy best-first search (Doran & Michie,1966), best-first search h(n). anytime algorithms have, built in, implicitassumption Weighted A* high weight greedy best-first search findsolution faster A* Weighted A* small weight.c2016AI Access Foundation. rights reserved.fiWilt & Rumlmany popular heuristic search benchmark domains (e.g., sliding tile puzzles, grid pathplanning, Towers Hanoi, TopSpin, robot motion planning traveling salesmanproblem) increasing weight lead faster search, weight becomeslarge Weighted A* expansion order greedy best-first search,results fastest search. first contribution paper provide illustrationshow, domains, greedy best-first search performs worse Weighted A*,sometimes even worse A*.show failure greedy best-first search merely mathematical curiosity, occurring hand crafted counterexamples, rather phenomenonoccur real domains, including variants popular single-agent heuristic benchmarks.second contribution empirically characterize conditions occurs, knowledgeimportant anyone using suboptimal search. also important first steppredictive theoretical understanding behavior suboptimal heuristic search.root cause failure greedy best-first search ultimately traced backheuristic, used guide greedy best-first search goal. A*,number well-documented techniques constructing effective heuristic.revisit guidelines context greedy best-first search. third contributionshow that, one follows well-established guidelines creating quality heuristicA*, results poor. present several examples following A* wisdomconstructing heuristic leads slower results greedy best-first search. useexamples understand requirements greedy best-first search placesheuristic.fourth contribution quantitative metric assessing greedy heuristic, goaldistance rank correlation (GDRC). GDRC used predict whether greedybest-first search likely perform well. GDRC also used compare differentheuristics domain, allowing us make informed decisionsheuristic select variety choices, case abstraction-basedheuristics like pattern databases. quantitative metric used automaticallyconstruct heuristic greedy best-first search iteratively refining abstractionmeasuring good candidate heuristic is. show iteratively refiningabstraction using simple hill-climbing search guided GDRC yield heuristicspowerful built traditional methods oriented toward optimal search.work increases understanding greedy best-first search, one popular scaleable heuristic search techniques. generally, suggests techniquesdeveloped optimal search necessarily appropriate suboptimal search. Suboptimal search markedly different optimal search, deserves theorymethods.2. Conundrum: Ineffective Weighted A*starting point investigation heuristics suboptional search beginscurious empirical observation: although weighted A* one popular wayspeeding heuristic search, increasing weight Weighted A* always work.order get better grasp question increasing weight ineffective,first need empirical data.274fiEffective Heuristics Suboptimal Best-First SearchDomainDynamic RobotHanoi (14)Pancake (40)11 Tiles (unit)GridTopSpin (3)TopSpin (4)11 Tiles (inverse)City Navigation 3 3City Navigation 4 4City Navigation 5 5Average SolutionLength187.4586.9238.5636.032927.408.5210.0437.9515.6214.3813.99TotalStates20,480,000268,435,4568 1047239,500,8001,560,000479,001,600479,001,600239,500,80022,50022,50022,500BranchingFactor0-2406401-30-312121-33-83-103-12Unit-costYesYesYesYesYesYesTable 1: Domain Attributes benchmark domains considered2.1 Benchmark Domainsconsider six standard benchmark domains: sliding tile puzzle, Towers Hanoipuzzle, grid path planning, pancake problem, TopSpin, dynamic robot navigation.selected domains represent wide variety interesting heuristicsearch features, branching factor, state space size, solution length. Sincewould like compare A*, forced use somewhat smaller puzzlespossible solve using state art suboptimal searches. requirement problemsize problem solvable A*, Weighted A*, greedy best-first searchmain memory (eight gigabytes). Basic statistics domain variantssummarized Table 1.sliding tile 11 puzzle (3 4), used random instances Manhattandistance heuristic. used 11 puzzle, rather 15 puzzle two reasons. First,optimally solving 15 puzzles using A* without running memory requires significantresources (At least 27 gigabytes, significantly eight gigabyte limit, accordingBurns et al., 2012). addition that, consider sliding tile puzzle non-unitcost functions. non-unit problems significantly difficult solveunit-cost variants. non-unit version sliding tile puzzle consider uses inversecost function, cost moving tile n 1/n. Manhattan distance heuristic,weighted appropriately, admissible consistent cost function.Towers Hanoi, considered 14-disk-4 peg problem, used two disjoint patterndatabases, one bottom 12 disks, one top two disks (Korf & Felner,2002). pancake problem, used gap heuristic (Helmert, 2010). grid pathplanning, used maps 2000x1200 cells, 35% cells blocked, usingManhattan distance heuristic four way movement. TopSpin puzzle, objectivesort circular permutation iteratively reversing continuous subsequence fixedsize. example TopSpin puzzle Figure 1. considered problem 12disks turnstile would turn either three four disks, denoted TopSpin(3)TopSpin(4). heuristic, used pattern database 6 contiguous disks present,275fiWilt & RumlFigure 1: 20 disk TopSpin puzzle.remaining 6 disks abstracted. dynamic robot navigation problem, used200x200 world, 32 headings 16 speeds. dynamic robot navigation, objectivenavigate robot one location heading another location heading,respecting dynamics robot. robot able change direction speedinstantaneously, combinations heading/speed reached givenstate. addition that, states domain represent dead ends. example,state robot moving full speed directly towards obstacle producechildren, robot crash matter control action applied.objective minimize total travel time; actions cost.also introduce new domain call City Navigation, designed simulate navigationusing system similar American interstate highways air transportation networks.domain, cities scattered randomly 100x100 square, connected randomtour guarantees possible get city city. city alsoconnected nc nearest neighbors. links cities cost Euclidean distance+ 2. city contains collection locations, randomly scattered throughout city(which 1x1 square). Locations city connected random tour,place also connected nearest np places. Links places cost true distancemultiplied random number 1 1.1. Within city specialnexus node contains connections city. goal navigaterandomly selected start location randomly selected end location. example,might want go Location 3 City 4 Location 23 City 1. citys nexusnode Location 0, reach goal example problem must navigateLocation 3 Location 0 City 4, find path City 4 City 1, pathLocation 0 City 1 Location 23 City 1. example instance typeseen Figure 2. circles left part figure locations, connectedlocations. nexus node, Location 0, also connected nexus nodes neighboring276fiEffective Heuristics Suboptimal Best-First SearchFigure 2: city navigation problem np = nc = 3, 15 cities 15 locationscity.cities. right part figure shows entire world, cities shrunkcircle.City Navigation instances classified np nc . consider problems varyingnumbers connections, always 150 cities 150 places city. Sincelocation within city global position, heuristic direct Euclidean distance.domain, solutions vary length, straightforward manipulate accuracyheuristic. domain bears similarity IPC Logistics domainlocations within cities connected roads, special airport locations usedtravel cities.2.2 ResultsFigures 3 4 show number expansions required A*, greedy best-first search,Weighted A* weights 1.1, 1.2, 2.5, 5, 10, 20. plots allow us comparegreedy best-first search Weighted A* A*, determine whether increasingweight speeds search, slows search.Looking plots Figure 3, easy see increase weightnumber expansions goes down, Figure 4, opposite true.domains, increasing weight initially speeds search, A* relaxed WeightedA*, Weighted A* transforms greedy best-first search, number nodesrequired solve problem increases. two domains, TopSpin turnstilesize 4 City Navigation 3 3, number nodes expanded greedy best-first searchhigher number nodes expanded A*. Explaining phenomenon centralgoal paper.277fiWilt & Ruml600000300000200000100000160008000000A* 1.1 1.2 2.5 5 10 20 GA* 1.1 1.2 2.5 5 10 20 GDynamic RobotA* 1.1 1.2 2.5 5 10 20 GTopSpin(3)Unit Tile1e+06500000Total Nodes Expanded800Total Nodes ExpandedTotal Nodes expandedTotal Nodes ExpandedTotal Nodes ExpandedTotal Nodes Expanded1.2e+0640 Pancake ProblemGrid Navigation14 disk Hanoi400002000000A* 1.1 1.2 2.5 5 10 20 G4000A* 1.1 1.2 2.5 5 10 20 GA* 1.1 1.2 2.5 510 20 GFigure 3: Domains increasing weight speeds search. Numbers denote WeightedA* run specific weight, G denotes greedy best-first search.3. Characteristics Effective Heuristicsestablished increasing weight Weighted A* always speedsearch, situations actually slow search. fact A*sometimes faster greedy best-first search sometimes slower greedy best-firstsearch suggests heuristics work well A* poorly greedy best-first search,heuristics work well greedy best-first search A*. Thus,question precisely driving difference, algorithm, A* greedybest-first search, needs heuristic.first review literature suggestions make good heuristicA*. mind, apply A* rules constructing effective heuristicgreedy best-first search. leads us observations effective heuristics greedybest-first search distinct common recommendations building goodheuristic A*.3.1 Effective Heuristics A*Much literature constitutes good heuristic centers wellheuristic works A*. finding optimal solutions using A*, first important278fiEffective Heuristics Suboptimal Best-First SearchInverse TileTopSpin(4)Total Nodes ExpandedTotal Nodes Expanded1600008000001600080000A* 1.1 1.2 2.5 5 10 20 GA* 1.1 1.2 2.5 5 10 20 GCity Navigation 4 4City Navigation 3 34000Total Nodes ExpandedTotal Nodes Expanded300020000200010000A* 1.1 1.2 2.5 510 20 GA* 1.1 1.2 2.5 510 20 GFigure 4: Domains increasing weight slows search. Numbers denoteWeighted A* specified weight, G denotes greedy best-first search.requirement heuristic admissible, meaning nodes n, h (n) truecheapest path n goal greater equal h(n). heuristicadmissible, A* degenerates (no star) guaranteed find shortestpath.generally believed consistency also important, due fact inadmissible heuristics lead exponential number re-expansions (Martelli, 1977).situation, however, rarely arises practice Felner et. al. (2011) argueinconsistency generally much problem generally believed.widespread rule making good heuristic A* is: dominance good (Nilsson, 1980; Pearl, 1984). heuristic h1 said dominate h2 n G : h1 (n) h2 (n).makes sense, due admissibility, larger values closer h . FurthermoreA* must expand every node n encounters f (n) less cost optimalsolution, large h often reduces expansions. Dominance represents current gold standard comparing two heuristics. practice, heuristics often informally evaluated279fiWilt & Rumlaverage value value initial state benchmark set. eithercase, general idea remains same: bigger heuristics better.ignore effects tie breaking well effects duplicate states, A*last iteration IDA* expand number nodes. allows us applyformula Korf, Reid, Edelkamp (2001). predict number nodesIDA* expand cost bound c is:E(N, c, P ) =cXNi P (c i)i=0function P (h) KRE equation represents equilibrium heuristic distribution,probability node chosen randomly uniformly among nodesgiven depth brute-force search tree heuristic value less equal h (Korfet al., 2001). quantity tends decrease h gets larger, depending nodesspace distributed. dominance relation also transfers KRE equation,meaning heuristic h1 dominates different heuristic h2 , KRE equations predictsexpected expansions using h1 less equal expected expansionsusing h2 .considering pattern database (PDB) heuristics, Korfs conjecture (1997) lendinsight performance IDA*, tells us expect 1+log(m)= namount memory PDB question takes up, amount timeexpect IDA* search consume, n constant (Korf, 2007). willingapply results regarding IDA* A* equation tells us expect largerpattern databases provide faster search A*. summarize, prevailing wisdomregarding heuristics bigger better, terms average heuristic valuepattern database size.3.2 Behavior Greedy Best-First Searchshall see, advice regarding heuristics helpful consideringA*. happens apply wisdom greedy best-first search? answerquestion taking detailed look behavior greedy best-first search threebenchmark problems: Towers Hanoi, TopSpin puzzle, sliding tilepuzzle.3.2.1 Towers Hanoifirst domain consider Towers Hanoi. successful heuristicoptimally solving 4 peg Towers Hanoi problems disjoint pattern databases (Korf &Felner, 2002). Disjoint pattern databases boost heuristic value providing informationdisks top puzzle. example, consider 12-disk puzzle, splittwo disjoint pattern databases: eight disks bottom pattern database, four diskstop pattern database. A*, best results achieved using fulldisjoint pattern database. greedy best-first search, however, faster search resultsuse disjoint pattern database, instead use 8 disk pattern database.exact numbers presented Unit rows Table 2. problems randomlygenerated Towers Hanoi states, goal get disks onto first peg.280fiEffective Heuristics Suboptimal Best-First SearchCostUnitSquareRev SquareHeuristic8/4 PDB8/0 PDB8/4 PDB8/0 PDB8/4 PDB8/0 PDBA* Exp2,153,5584,618,913239,653329,7613,412,0809,896,145Greedy Exp36,0237714,663892559,250730Table 2: Average number nodes expanded solve 51 12-disk Towers Hanoi problems.30252520Minimum hMinimum h20151510105005200400600Expansions8001000005000 10000 15000 20000 25000 30000 35000ExpansionsFigure 5: minimum h value open search progresses, using different patterndatabases (single left, two disjoint additive ones right).theory A* corroborates empirical evidence observed here: disjoint pattern database dominates single pattern database, absent unusual effects tiebreaking, surprise disjoint pattern database results faster A* search.reason different behaviour A* greedy best-first search simple.greedy best-first search using single pattern database, possible follow heuristicdirectly goal, h value head open list monotonically decrease.see this, note every combination bottom disks h value, possiblearrangements disks top also share h value. disks topalways moved around independently bottom disks are. Consequently,always possible arrange top disks next move bottom disksdone, disturbing bottom disks, thus leaving h constant. Eventually,h decreases progress made putting bottom disks problemorder. process repeats h = 0, point greedy best-first search simplyconsiders possible configurations top disks goal found.phenomenon seen left pane Figure 5, minimum h valueopen list monotonically decreases number expansions search done281fiWilt & Rumlh = 10h=9Figure 6: Two Towers Hanoi states, one near goal (top) one far goal(bottom).increases. heuristic created single pattern database creates extremely effectivegradient greedy best-first search algorithm follow two reasons. First,local minima all, global minimum goal is. context, defineminimum region space n , every path n goal nodeleast one node n h(n ) > h(n). Second, exactly 256 states associatedconfiguration bottom 8 disks. means every 256 expansions, hguaranteed decrease. practice, state lower h tends found much faster.right pane Figure 5, heuristic disjoint pattern database. seeh value head open list fluctuates substantially using disjointpattern database, indicating greedy best-first searchs policy follow small h muchless successful. states bottom disks near goalpaired poor arrangement disks top assigned large heuristicvalues, delays expansion nodes. illustrated Figure 6. topstate significantly closer goal, despite higher h value bottom state.ignore top disks completely, top state h = 1 compared bottomstates h = 9, correctly conveys fact top state significantly closergoal. disjoint PDB causes substantial confusion greedy best-first search,prior making progress 8 bottom disks, greedy best-first searchconsiders states top 4 disks closer destination. bottom stateexpanded, produce children lower heuristic values exploredever considering top state, state explored first. Eventually,descendants bottom state h 9 explored, point top stateexpanded, causes h value head open list go down.summarize, disjoint pattern database makes gradient difficultgreedy best-first search follow nodes small h onereason: near goal bottom pattern database returning small value,particularly near goal, top disks arranged target peg.suggests following observation regarding heuristics greedy best-first search:282fiEffective Heuristics Suboptimal Best-First SearchObservation 1. else equal, greedy best-first search tends work wellpossible reach goal every node via path h monotonically decreases alongpath.may seem self-evident, example illustrated conflictscommon wisdom heuristic construction. also important note observationmakes comment relative magnitude heuristic, greedy best-firstcompletely irrelevant; matters relative ordering nodes orderedusing heuristic.Another way view phenomenon analogy Sussman Anomaly (Sussman,1975). Sussman anomaly occurs one must undo subgoal prior ablereach global goal. context Towers Hanoi problems, goal getdisks target peg, solving problem may involveundoing subgoals putting top disks target peg. presence toppattern database encourages greedy best-first searches privilege states subgoalseventually undone accomplished.Korf (1987) discusses different kinds subgoals, different kinds heuristicsearches able leverage subgoals. Greedy best-first search uses heuristic createsubgoals, attempting follow h goal. example, unit-cost domain, firstsubgoal find node h = h(root) 1. heuristic follows Observation 1,subgoals form perfect serialization, subgoals achieved one another.heuristic deviates Observation 1, subgoals induced heuristic cannotserialized.Another important factor is, course, number distinct nodes heuristiclevel one encounters prior finding better node. Consider, example, one worstheuristics, h = 0. Technically, heuristic follows Observation 1 pathscontain nodes h = 0, one plateau contains nodes entire space,obviously undesirable. Hoffmann (2005) discusses general idea using term maximalbench exit distance, again, idea domains quantitysmall, greedy best-first search Enforced Hill Climbing method perform well,finding nodes lower h straightforward.effects exacerbated cost disks top increased relativecost disks bottom. define cost moving diskproportional disks size, get Square cost metric, cost moving diskn n2 . could also imagine tower stacked reverse, requiring largerdisks always top smaller disks, case get Reverse Square costfunction. either case, expect number expansions greedy best-firstsearch require lower using bottom pattern database,indeed effect observe Table 2. However, top disks heavier disksbottom, greedy best-first search suffers even considered unitcost problem, expanding order magnitude nodes. patterndatabase information top disks returning values substantiallylarger bottom pattern database, due fact top pattern databaseconsiders expensive operators. situation reversed, however, toppattern database uses lowest cost operators, top pattern databases contributionh much smaller proportion total expansions. Since greedy best-first search283fiWilt & Ruml14001800Greedy Search Disjoint PDBGreedy Search Disjoint PDB1600120014001200800Minimum hMinimum h1000100060080060040040020000200100020003000Expansions4000005000100000200000300000 400000Expansions500000600000700000Figure 7: minimum h value open searches using disjoint pattern databasesdifferent cost functions (square left, reverse square right).performs best top pattern database isnt even present, naturally performs bettercontribution top pattern database smaller.phenomenon vividly illustrated execution times Figure 7. leftfigure, disks top pattern database much cheaper move disksbottom pattern database, therefore contributing much smaller proportiontotal value h. right part figure, disks top pattern databasemuch expensive move disks bottom pattern database,top pattern database makes much larger contribution h, causing substantiallyconfusion.Hoffmann (2005) notes success FF heuristic many domains attributable fact h+ heuristic produces heuristic local minima.heuristic local minima precisely matches Observation 1, alwayspossible reach goal via path h monotonically decreases.3.2.2 TopSpinconsidered TopSpin 12 disks turnstile flipped 4 disks using patterndatabases contained 5, 6, 7, 8 12 total disks.Korfs conjecture predicts larger pattern databases usefulA*, therefore considered stronger heuristics, indeed, PDBbecomes larger, number expansions done A* dramatically decreases.seen Figure 8. box plot (Tukey, 1977) labeled either A* G (for greedybest-first search), number, denoting number disks PDB tracks.box denotes middle 50% data, top box upper quartile,bottom box bottom quartile, height box interquartilerange. horizontal line middle box represents median. grey stripeindicates 95% confidence interval mean. circles denote points1.5 times interquartile range away either first quartile third284fiEffective Heuristics Suboptimal Best-First Search4/12 TopSpin Different PDB'sExpansions6000030000A*5 G5 A*6 G 6 A*7 G7 A*8 G 8Figure 8: TopSpin puzzle different heuristics. followed number denotesnumber disks PDB heuristic. G followed number denotesgreedy best-first search number disks PDB heuristic.quartile, whiskers represent range non-outlier data. move leftright, PDB heuristic tracks disks, gets substantially better A*.also reductions greedy best-first search terms expansions, gainsnowhere near impressive compared A*.reason greedy best-first search perform better given largerheuristic that, larger heuristic, states h = 0 may still quite fargoal. example, consider TopSpin state represented follows, denotesabstracted disk:State 1: 0 1 2 3 4 5turnstile swaps orientation 4 disks, configurationsputting abstracted disks order requires moving disk abstracted, as:State 2: 0 1 2 3 4 5 6 7 8 9 11 10TopSpin state, abstraction process takes largest N disks convertsabstracted disks, abstracted disks treated same, State 2 wouldabstracted State 1, means abstracts state goal, makingheuristic 0. wanted expand State 2, could one childrenState 3, whose heuristic still 0:State 3: 0 1 2 3 4 5 6 7 10 11 9 8Consider different child, example child obtained rotating middle 4 disks:285fiWilt & RumlState 4: 0 1 2 3 7 6 5 4 8 9 10 11abstracts into:State 5: 0 1 2 3 5 4heuristic State 4 0, State 4 abstracts State 5. State 5abstract state different State 1 (the abstracted goal) heuristic State4 0.abstract disks 6-11, still abstract state before, heuristicstill 0. Moving disk abstracted increase heuristic, movingabstracted disks leave heuristic 0. Unfortunately, transforming State 2goal cannot done without moving least one disks whose index 05, turnstile size 4.means subgraph consisting nodes h = 0 TopSpinproblem disconnected. Thus, greedy best-first search encounters state h = 0,state could h = 0 state connected goal via h = 0 states,would desirable, state could h = 0 state connected goal viapaths contain least one h 6= 0 nodes, would undesirable. case,greedy best-first search first expand h = 0 nodes connected first h = 0node (which hypothesis connected goal node via paths containing h = 0nodes), return expanding nodes h = 1, looking find differenth = 0 node.abstraction controls number size h = 0 regions. example,abstract 6 disks, two strongly connected regions h = 0 nodes, containing360 nodes. instead abstract 5 disks, 12 strongly connected h = 0 regions,10 nodes. heuristic abstracts 6 disks, 50% chancegiven h = 0 node connected goal via h = 0 nodes, greedybest-first search entered correct h = 0 region, finding goal node largelychance. heuristic abstracts 5 disks, probability given h = 0node connected goal via h = 0 nodes lower. correct h = 0 regionfound, however, much easier find goal, region contains 10nodes, compared 360 nodes. Empirically, see two effects roughlycancel one another out, total number expansions done greedy best-firstsearch remains roughly constant matter heuristic used. brings usnext observation.Observation 2. else equal, nodes h = 0 connected goal nodesvia paths contain h = 0 nodes.One view important specific case Observation 1. Interestingly, typesheuristics, delete-relaxation heuristics used domain-independent planning,obey observation implicitly never allowing non-goal states h values 0.One obvious way make heuristic satisfy recommendation changeheuristic non-goal states minimum cost operatordomain cost . this, simply restate recommendation substituting0, arrive similar result.286fiEffective Heuristics Suboptimal Best-First Search891037114196311Figure 9: Different tile abstractions. denotes tile abstracted..AbstractionOuter L (Figure 9 left)Checker (Figure 9 right)Outer L Missing 3Outer L Missing 3 7Instance SpecificGDRC GeneratedAverage 6-tile PDBWorst 6-tile PDBGreedy Exp25811,5833,00620,2678,53042717,641193,849A* Exp1,251,2601,423,378DNFDNF480,2501,197,7891,609,9952,168,785Table 3: Average number expansions required Greedy best-first search A* solve3 4 tile instances different pattern databases. DNF denotes least oneinstance would require 8GB solve.3.2.3 Sliding Tilessliding tile puzzle one commonly used benchmark domains heuristicsearch. such, domain one best understood. Pattern database heuristicsshown strongest heuristics domain, strongestheuristics quite time (Korf & Taylor, 1996; Felner, Korf, Meshulam, & Holte,2007). use 11 puzzle (4 3) case study smaller size puzzleallows creating testing hundreds different pattern databases. central problemconstructing pattern database sliding tile puzzle selecting good abstraction.abstraction keeps outer L, shown left part Figure 9,extremely effective greedy best-first search, greedy best-first searchput abstracted tiles proper places, remains find goal,easy using even completely uninformed search remaining puzzle,6!2 = 360 states h = 0 h = 0 states form connected subgraph.analogous heuristic directing search algorithm follow process outlinedParberry (1995), large sliding tile puzzles solved first solving outer L,treating remaining problem smaller sliding tile puzzle.Compare happens greedy best-first search run checkerboardabstraction, shown right part Figure 9. greedy best-first search identified node h = 0, high chance remaining abstracted tilesconfigured properly, least one non-abstracted tilesmoved. effect seen Table 3, average number expansions required A* comparable either abstraction, average number expansionsrequired greedy best-first search larger two orders magnitude.287fiWilt & Rumlsheer size PDB important greedy best-first searchA*. Table 3, see weaken pattern database removing 37 tiles, number expansions required increases factor 10 greedy best-firstsearch. A* using PDB 3 tile missing, 3 instances unsolvable within 8GB memory (approximately 25 million nodes Java implementation).3 7 tile missing, A* unable solve 16 instances within limit.worth noting even without 3 tile, outer L abstraction still effectivegreedy best-first search compared checkerboard abstraction.underlying reason behind inefficiency greedy best-first search using certainpattern databases fact less useful pattern databases nodes h = 0nowhere near goal. provides evidence favor Observation 2;greedy best-first search concentrates efforts finding expanding nodes low hvalue, nodes are, reality, near goal, clearly causes problemsalgorithm. A* uses f , g contributes f , A* able eliminatestates consideration (not expand them) high g value helps givenode high f value, causes A* relegate node back expansionqueue.checkerboard pattern database also helps make clear another problem facinggreedy best-first search heuristics. algorithm discovers node h = 0,node connected goal via h = 0 nodes, algorithm eventually runh = 0 nodes expand, begin expanding nodes h = 1. expandingh = 1 nodes, greedy best-first search either find h = 0 nodes examine goals,eventually exhaust h = 1 nodes well, forced consider h = 2nodes. natural question ask far algorithm backable find goal. leads us next observation.Observation 3. else equal, greedy best-first search tends work welldifference minimum h value nodes local minimum minimumh allow search escape local minimum reach goal low.phenomenon clearly illustrated considering instance-specific pattern databases(Holte, Grajkowskic, & Tanner, 2005). instance-specific pattern database, tilesstart closest goals abstracted first, leaving tiles furthestaway goals represented pattern database. helps maximizeheuristic values states near root, due consistency alsoundesirable side effect making states required included path goalhigh heuristic values well. Raising heuristic value initial state helpfulA* search, evidenced reduction number expansions A* using instancespecific abstractions size, shown Table 3. Unfortunately, approachstill powerful greedy best-first search simpler outer L abstraction, evensmaller variant missing 3. instance-specific pattern databasesuse patterns difficult greedy best-first search use effectively, similarproblems encountered using checkerboard abstraction.288fiEffective Heuristics Suboptimal Best-First SearchDomainGreedyWorksGreedyFailsTowers HanoiGridPancakeDynamic RobotUnit TilesTopSpin(3)TopSpin(4)Inverse TilesCity Nav 3 3City Nav 4 4Heuristic% Error29.4725.112.4115.6633.3725.9532.8629.4944.5137.41h(n)-h (n)Correlation(Pearson)0.96520.99670.96210.99980.70640.58550.28270.67220.56880.7077h(n)-h (n)Correlation(Spearman)0.94330.99580.95930.99830.70650.45980.31960.65840.61320.7518h(n)-h (n)Correlation(Kendall)0.83060.95270.91980.98690.55050.41580.27360.48770.46750.6238Table 4: Average % error correlation h(n) h (n)4. Predicting Effectiveness Greedy Heuristicsprevious section, saw common wisdom regarding effective heuristicsoptimal search carry suboptimal search. Instead, examples motivatedthree general observations regarding greedy best-first search looks heuristic.qualitative observations perhaps helpful heuristics heuristic design,also useful simple, quantitative metric evaluating comparing heuristics.begin considering two intuitively reasonable quantitative metrics, percenterror h, correlation h h . metrics, showmetric cannot used predict whether greedy best-first search performworse Weighted A*. consider measure search distance go called .(n) h change graph making edges cost 1. findcorrelation h used predict greedy best-first searchperform poorly.4.1 Percent Error h(n)first metric consider perhaps intuitive measure heuristic performance:percent error h. define percent error heuristic h (n)h(n). Since greedyh (n)best-first search increases importance heuristic, reasonable concludeheuristic large amount error, relying upon heavily, greedy best-firstsearch does, going lead fast search.Table 4, average percent error heuristic domainsconsidered. Surprisingly, average percentage error bears little relation whethergreedy best-search poor choice. Towers Hanoi, unit tiles, TopSpin(3),three domains greedy best-first search effective, much heuristicerror domains greedy best-first search works poorly. leads us concludecannot measure average heuristic percent error use predict whetherincreasing weight speed slow search.289fiWilt & Rumlsee intuitively makes sense, note greedy best-first search reallyrequires nodes get put h (n) order heuristic. exact magnitude,therefore error, heuristic unimportant, magnitude huge effectaverage percent error. seen consider heuristic h(n) = h R(n) : R R+large tiny R, always guide greedy best-first search directlyoptimal goal, exhibiting arbitrarily high average percent error heuristicR increases decreases away 1.4.2 h h Correlationnext metric consider correlation h h . consideringpercent error h metric, noted greedy best-first search run time linearsolution length optimal solution nodes h (n) order. One wayquantify observation measure correlation two values.three different ways.well known correlation coefficient Pearsons correlation coefficient r,measures well relationship h(n) h (n) modeled using linearfunction. relationship would mean weighting heuristic appropriatelyreduce error heuristic, could reasonably expected lead fastersearch. addition, relationship h(n) h (n) linear function,order preserved: putting nodes order h(n) also put nodes orderh (n), leads effective greedy best-first search. domain, calculatedPearsons correlation coefficient h (n) h(n), results secondcolumn Table 4.Another reasonable way measure heuristic correlation use rank correlation.Rank correlation measures well one permutation (or order) respects another permutation (or order). context search, use ask similar order onegets putting nodes h order order one gets putting nodes h order. Rankcorrelation coefficients useful less sensitive outliers, abledetect relationships linear.Spearmans rank correlation coefficient () best known rank correlation coefficient.Pearsons r ranked variables. means smallest N heuristicvalues mapped 0, largest n heuristic values mapped N . doneh h , point simply calculate Persons r using rankings.context greedy best-first search, Spearmans rank correlation coefficient high,means h(n) h (n) put nodes close order. Expandingnodes h (n) order leads greedy best-first search running time linear solutionlength, reasonable conclude strong Spearmans rank correlation coefficienth (n) h(n) would lead effective greedy best-first search. domain,calculate Spearmans rank correlation coefficient h (n) h(n),results third column Table 4.natural metric measuring relationship achieved using Kendalls(1938). Kendalls another rank correlation coefficient, measures amountconcordance two rankings. Concordance rankings twoelements agree. context greedy best-first search, concordant pair pair290fiEffective Heuristics Suboptimal Best-First Searchnodes h(n1 ) > h(n2 ) h (n1 ) > h (n2 ) h(n1 ) < h(n2 ) h (n1 ) < h (n2 ).Kendalls proportion pairwise comparisons concordant. h puts nodesh order, pairwise comparisons concordant, Kendalls 1. h putsnodes reverse h order, comparisons discordant, Kendalls -1.sorting nodes h puts nodes random order, expect half comparisonsconcordant half comparisons discordant.Kendalls also understood context bubble sort. Kendall distancenumber swaps bubble sort would order change one listother. case, number swaps bubble sort would rearranging listnodes sorted h list sorted h . Kendalls calculated normalizingKendall distance, done dividing N (N 1)/2. 1Since rank correlation coefficients, related, arguenatural statistic. Consider question: given open list containing nnodes, likely node smallest h front openlist, given nodes ordered h? use predict node will,average, middle list h h completely unrelated, closerfront open list stronger (h, h ) correlation is. reasonassume nodes open list random selection nodes, tells us oftenrandom comparison correct. use therefore predict far back nodeminimum h is. natural interpretation, making naturalstatistic. worth nothing generally related one another, oneused predict (Gibbons, 1985). relationship means practice,generally possible use either metric.Returning Table 4, results lead us reject correlation h hmetric predicting well greedy best-first search work. three correlationcoefficients, examples domains greedy best-first search fails highh(n)-h (n) correlations, examples domains greedy best-first search works wellpoor h(n)-h (n) correlations. example, TopSpin(3), Kendalls.42, lower Inverse Tiles City Navigation problemsconsider.4.3 h Correlationstrategy greedy best-first search discover goal quickly expanding nodessmall h(n) values. nodes small h(n) far away goal reasonablebelieve greedy best-first search would perform poorly. denote (n) countedges node n nearest goal, distance measured summingcost edges path, rather counting edges path.(n) equivalent h (n) modify graph edges cost 1. Lookingplot h(n) vs h (n) left half Figure 10, see City Navigation4 4 reasonable relationship h(n) h (n), nodes lowh(n) tend small h (n) values. denote distance nearest goal terms1. Malte Helmert noted (personal communication) Kendalls , described, ideal metricuse sequences contain ties. integer-valued heuristics, especially, ties may common.One way account ties rankings use Kendalls -b statistic (Kendall & Gibbons, 1990)instead (also known -a). Kendalls -b accounts ties rankings.291fiWilt & Rumlh vs h* City Navigation 4 4h vs d* City Navigation 4 418120d*h*126060080160h4080hFigure 10: Plot h(n) vs h (n), h(n) vs (n) City Navigation 4 4DomainGreedyWorksGreedyFailsTowers HanoiGridPancakeDynamic RobotUnit TilesTopSpin(3)TopSpin(4)Inverse TilesCity Nav 3 3City Nav 4 4h(n)-d (n)Correlation(Pearson)0.96520.99670.96210.99980.70640.58550.28270.52810.02460.0853h(n)-d (n)Correlation(Spearman)0.94330.99580.95930.99830.70650.45980.31960.5173-0.03380.1581h(n)-d (n)Correlation(Kendall)0.83060.95270.91980.98690.55050.41580.27360.3752-0.02670.1192Table 5: Correlation h(n) (n)number edges state space graph (n). right half Figure 10 showsplot h(n) vs (n). clearly see City Navigation 4 4 domain,almost relationship h(n) (n), meaning nodes receive smallh(n) value found distance away goal, could explain greedybest-first search works poorly domain, despite fact h(n) h (n)closely related.nodes small h(n) values also likely small (n) values (andnodes therefore close goal, terms expansions away) expanding nodessmall h(n) values quickly lead goal. converse also reasonable. nodessmall h(n) value uniform distribution (n) values (and thus manynodes far away goal terms expansions away), expanding nodesquickly lead goal.292fiEffective Heuristics Suboptimal Best-First Search7.06.5log(Expansions)6.05.55.04.54.03.53.02.50.00.10.20.30.4GDRC0.50.60.70.8Figure 11: Average log expansions done greedy best-first search different heuristics, plotted according GDRC.domain, quantify concept calculating Pearsons correlation coefficient, Spearmans rank correlation coefficient, Kendalls (n) h(n).Looking Table 5, see that, using Kendalls Pearsons r, finallyable separate domains greedy best-first search performs well domains greedy best-first search performs poorly. Kendalls , drawline approximately 0.4 used separate domains greedy best-firstsearch works well domains greedy best-first search works poorly. Likewise,Pearsons r, draw line approximately .55. call type metricGoal Distance Rank Correlation (GDRC) and, unless otherwise noted, compute usingKendalls .correlation (n) h(n) connects three observations, althoughconnection mathematical necessity (as counterexamples constructed).Note heuristic obeys Observation 1 produce paths h monotonicallydecreases goal. Consider nodes along path goal. hypothesis, hmonotonically decrease along path. Now, consider one nodes goal endpath. Since h monotonically decreases along path, nodes goal endpath low h, near end path, also lowvalue. little else said nodes general, restriction improvesheuristics GDRC compared situation nodes low allowedhigh h values. similar argument used show following Observation 2helps produce heuristic high GDRC.Observation 3 discusses nodes local minimum, difference h nodeslocal minimum, nodes edge local minimum. assumeorder escape local minimum one must go one nodes edge293fiWilt & Rumllocal minimum, know nodes local minimum must highernodes edge local minimum, also know h lower(because node local minimum). means h ranking incorrectlyorders nodes local minimum compared nodes edge localminimum, clear problem producing high GDRC. nodes local minimumlow get goal high h node, relationshipobservation GDRC weaker. Consider personal transportationexample. action as, call taxi might result reaching states near goalone step, high cost. heuristic recognizes cost action, nodecorrectly high h, close goal measuredcall taxi path. situation clearly causes problems domains attemptingfollow Observation 3, believe domains kind attribute are, practice,quite uncommon. example, none example domains exhibit trait.4.4 Comparing Heuristicsquantitative metric, GDRC used compare different heuristicsdomain. test effectiveness, ran experiments Towers Hanoiproblem using 17 different disjoint non-disjoint pattern databases. consideredpattern databases 3 8 disks, well selection pairings PDBstotal number disks less equal 12. pattern database,calculated GDRC heuristic produced PDB. Figure 11 plot,PDB, GDRC PDB X axis average log numberexpansions required greedy best-first search solve 51 random 12-disk Towers Hanoiproblems axis. see figure, GDRC roughly0.4, greedy best-first search performs poorly, GDRC increases, averagenumber expansions done greedy best-first search decreases. suggestspossible use GDRC directly compare heuristics one another.see similar behavior different domain left part Figure 12.dot represents one 462 possible disjoint 5/6 pattern databases (one 6 tile PDBone 5 tile PDB disjoint) 3 4 sliding tile puzzle inverse costs.axis log average expansions required solve 100 random instances.X axis GDRC. Since using non-unit problem, h same,also calculate correlation h h . right part Figure 12,correlation X axis.see, GDRC rank correlation h h yield usefulinformation well greedy best-first search likely work.domains tested, correlation h neatly predictsgreedy best-first search performs worse Weighted A* (or A*). perfect, however.consider heuristic h(n) = h (n), measure correlation h(n)h (n) perfect, relationship h(n) (n) heuristic couldarbitrarily poor. heuristic approaches truth, h(n)-h (n) correlationsapproach 1, allows Weighted A* scale gracefully, greedy best-first searchlinear run time, matter correlation h(n) (n) is.situation, looking solely correlation h(n) (n) determine whether294fi5.05.04.54.54.04.0Log10(expansions)Log10(expansions)Effective Heuristics Suboptimal Best-First Search3.53.03.53.02.52.52.02.01.50.350.400.45GDRC0.500.551.50.450.600.500.550.600.650.700.75GDRC (with h* instead d*)0.800.85Figure 12: Average log expansions done greedy best-first searchpossible 462 5/6 disjoint PDB heuristics, plotted GDRC (left)correlation h(n) h (n)DomainCity Nav 5 5Heuristic h(n)-h (n)% Error Correlation(Pearson)31.190.9533h(n)-h (n)Correlation(Spearman)0.9466h(n)-d (n)Correlation(Pearson)0.0933h(n)-d (n)Correlation(Spearman)0.0718Table 6: Average % error, correlation h(n) h (n), correlationh(n) (n) City Nav 5 5greedy best-first search faster Weighted A* may produce incorrectanswer.seen City Navigation 5 5 domain. City Navigation 5 5 similarCity Navigation problems consider, except cities placesbetter connected, allowing direct routes taken. Since routes direct,thus shorter, heuristic accurate. Table 6 shows various correlationspercent error h(n) City Navigation 5 5. Figure 13 shows increaseweight, despite weak correlation h(n) (n), catastrophe:greedy best-first search expands roughly number nodes Weighted A*best weight speed. occurs extreme strength heuristic,correlates h (n) .95, extremely strong correlation.next question correlation matters more: h (n) (n). Clearly, perfectcorrelation h (n) h(n) (n) h(n) lead fast greedy best-firstsearch, leads us conclusion order greedy best-first searcheffective, nodes small h(n) get expanded required least one virtue:either close goal measured terms remaining search distance(small (n)) close goal measured terms remaining cost (small h (n)).295fiWilt & RumlCity Navigation 5 5Total Nodes Expanded3000200010000A* 1.1 1.2 2.5 510 20 GFigure 13: Expansions done A*, Weighted A*, greedy best-first search CityNavigation 5 5seen empirically two correlations break down, (n) correlation allowsgreedy best-first search survive longer: tested domains (n)-h(n).58, greedy best-first search well, whereas seen domains h (n)h(n) correlation high .70 (or .75, depending correlation metricused) greedy best-first search performs poorly.importance correlation h(n) (n) reflects importancenode ordering greedy best-first search. optimal search, search cannot terminatesolution found, rather solution known optimalpaths pruned. larger heuristic values, sooner nodespruned. means optimal search, heuristic size paramount importance:bigger better. greedy best-first search, heuristic used guide searchsolution, relative magnitude heuristic (or error heuristic) bearingperformance search, saw considered percent error h.common researchers say A*s heuristic guides search, discussionreveals language reserved suboptimal search.heuristics able satisfy needs A* greedy best-first searchsimultaneously. example, dynamic robot navigation heuristic works extremely wellA* greedy best-first search, big, therefore good A*,good differentiating nodes near goal far away goal,helping greedy best-first search.5. Building Heuristic Searching GDRCshown Haslum, Botea, Helmert, Bonet, Koenig (2007), given metric assessing quality heuristic, use metric automatically construct effectiveabstraction-based heuristics simply searching space abstractions. many domains, heuristic constructed initially abstracting everything, slowly refining296fiEffective Heuristics Suboptimal Best-First Searchabstraction construct heuristic. Haslum et al. (2007) concernedoptimal search hence use pruning power evaluate heuristics, focus greedy bestfirst search suggests GDRC might serve useful metric. example, TopSpinproblem, begin heuristic abstracts disks. consider PDBsdevised abstracting everything except one disk, measure GDRCpattern database. GDRC effectively estimated breadth-first searchbackwards goal (we used 10,000 nodes 12 disk problem) establish valuesnodes, h value looked pattern database. sample 10%nodes generated way, used sample calculate estimate Kendalls. elected sample 10%, nodes, sample size taken providedconfidence interval sufficiently small tell better. Last, take PDBhighest value incumbent PDB. process repeats either PDBsworse GDRC previous best PDB, PDB reached desiredsize. reason allow algorithm possibly terminate early cover caseGDRC decreasing larger PDBs. increasing size PDB decreases GDRC,likely increasing size PDB degrade GDRC even more,elect terminate. full algorithm detailed Algorithm 1. simplehill-climbing search appears effective, sophisticated search strategy could certainlyemployed instead.5.1 TopSpinAlgorithm 1 Hill Climbing PDB Builder1: AllTokens = {Tokens problem abstracted}2: RemainingTokens = AllT okens3: BestPDB = build PDB abstracting AllT okens4: BestTau = 05: function tryPDB(tokens)6:pdb = build PDB abstracting AllT okens \ tokens7:allNodes = nodes discovered breadth first search backwards goal state(s)8:sample = randomly sample 10% nodes allNodes9:return calcTau(sample, pdb)10: BestP DB.size < Max Allowed Size11:LocalBestPDB, LocalBestTau, LocalBestToken = (N one, BestT au, N one)12:CurrentToken RemainingT okens13:CurrentTau, CurrentPDB = tryPDB(Ref inedT okens {token})14:CurrentT au > LocalBestT au15:set local best variables current16:LocalBestP DB 6= None17:set best variables local best variables18:RemainingTokens = RemainingT okens \ LocalBestT okens19:else20:Break21: return BestPDB297fiWilt & RumlPDBContiguousBig OperatorsRandomGreedy Exp411.19961.112,386.81A* Exp10,607.45411.2726,017.25Avg. Value52.3594.3747.99Table 7: Expansions solve TopSpin problem stripe cost function using differentPDBsused generate unit-cost TopSpin pattern databases, hill-climbing GDRCalways produced PDBs abstracted disks connected one another,refined disks also connected one another. prevents abstractioncreating regions h = 0, goal nowhere near h = 0 nodes, perObservation 2.unit-cost TopSpin problems, abstractions disks connectedone another work well greedy best-first search A*. change costfunction moving even disk costs 1 moving odd disk costs 10, getstripe cost function, called costs striped across problem.effective PDBs A* keep many odd disks possible, movingodd disks much expensive moving even disk. use bigoperator pattern database greedy best-first search, algorithm align highcost odd disks, great difficulty escaping resulting local minimum.use hill climbing GDRC build heuristic, end contiguous heuristickeeps abstracted refined disks connected one another. Table 7 providesresults various pattern databases solving suite instances. seeimportance creating good pattern database consider Random rowtable, contains average number expansions 20 different randomly selected6 disk pattern databases.5.2 Towers Hanoialready infer Figure 11 that, greedily select PDB bestcollection PDBs, would select best one. certainly also possibleuse hill-climbing search incrementally construct PDB. creating PDBheuristic Towers Hanoi, one maps full size problem onto abstracted versionproblem removing disks larger problem, re-indexingremaining disks map disks smaller problem. technique,critical component terms performance disks abstracted.define mapping selection disks abstract. example,consider 12 disk problem using 8 disk PDB, must select 4 12 total disksabstract. Figure 14 + glyphs represent randomly selected abstraction,heuristic produced. see, abstractions produced extremely poorquality heuristics measured GDRC average number expansions donegreedy best-first search solving problems using heuristic. heuristics faredsignificantly better terms GDRC average expansions greedy best-first298fiEffective Heuristics Suboptimal Best-First SearchAnalysisheuristics generated different Hanoi PDB mappings87Log expansions654320.2Randomly selected mappingsBest MappingHill Climbing Mappings0.00.20.4GDRC0.60.81.0Figure 14: Expansions using different Towers Hanoi PDB abstractions.search. examine plot Figure 14 see several clustersheuristics. heuristics GDRC 0 clustered together, requiringgreedy best-first search expand 107 108 nodes. heuristicsworst heuristics, largest disk abstracted. next cluster heuristicsGDRC 0.4 0.5 require greedy best-first search expand 106.5107 nodes. heuristics largest disk abstracted, secondlargest disk abstracted. abstractions also produce poor quality heuristics,heuristics represent significant improvement heuristics largestdisk abstracted. color Figure 14 represents mapping different largestabstracted disk, blue X glyph representing best pattern databasesmallest disks abstracted. see plot, definite overall trendmappings product heuristics higher GDRC tend fare better overallterms average total expansions used greedy best-first search.hill climbing algorithm selected heuristic contained disks 0, 1, 2, 4, 5, 6,7, 8 (skipping 3 disk). example hill climbing algorithm selectedheuristic seen green circles line Figure 14 startingabstraction abstracted largest disk. hill climbing algorithm climbed hillleading reasonable, albeit effective, heuristic. Despite failing findoptimal heuristic, selected heuristic quite reasonable nonetheless, falling86th 75th percentile overall, significant improvement automated approach.5.3 City Navigationaddition building pattern database heuristics using hill climbing GDRC, alsopossible build portal-style heuristic hill climbing GDRC. Using city navigationdomain, defined portal heuristic (Goldenberg, Felner, Sturtevant, & Schaeffer, 2010)selecting number nodes portal nodes (we used number nodes299fiWilt & RumlHeuristicRandom PortalsNexus PortalsHill Climbed PortalsAverage GDRC0.440.760.60Average greedy best-first search expansions22004881117Table 8: Expansions GDRC using different ways select portal nodescities, 150), calculating true distance every node closest portal node.heuristic two nodes true distance portals associatednode minus distance node portal. event quantitynegative, 0 used. heuristic highly accurate across long distances usestrue distance portals, obviously less accurate comparingtwo nodes share portal. constructing portal heuristics, criticaldifference effective portal heuristic poor quality portal heuristicselection nodes portals. allowed algorithm automate processhill climbing GDRC. algorithm initialized random array nodesportals. step, algorithm iterates indexes array portals,considering moving location currently serving portal different location.implementation, considered two times number cities, 300 differentrandom places. assessed GRDC new heuristic using sample 100,000randomly selected pairs places. moving city new location improved GDRC,kept portal array new place, otherwise, discarded change GDRCinferior incumbent. reach end array, restartbeginning. reach point position array,aspects array remain unchanged since last time modified index,algorithm terminates, returning array portals use heuristic.Results experiment shown Table 8. average GDRC GDRCone obtains selecting 100,000 random pairs start end nodes calculatingGDRC using nodes. average greedy best-first search expansions averagenumber expansions needed solve City Navigation problem random startgoal.considered three different methods selecting portal nodes. firstcompletely randomize selection portal nodes, unsurprisingly resultedlowest GRDC highest number expansions. successful methodselecting portal nodes identify nexus nodes, use nodes portals.Unsurprisingly, method led highest GDRC, fewest number expansions.result demonstrates usefulness GDRC identifying quality heuristicgreedy best-first search. Last, automatic algorithm finding portal nodes performedsignificantly better random, still trailing hand-selected portals. believebetter search strategy may able better capture potential performance gainoffered high GDRC heuristics.300fiEffective Heuristics Suboptimal Best-First Search5.4 Sliding Tile Puzzlealso compare GDRC-generated PDBs instance-specific PDBs slidingtile puzzle (Holte et al., 2005). domain, order get accurate estimate, increase number nodes expanded going backwards 10,0001,500,000. Following hill climbing procedure, algorithm selected pattern databasetracked 1, 3, 4, 7, 8, 11 tiles. results using PDB shown Table3. abstraction strong outer L abstraction, fourth bestPDB minimizing average number expansions done greedy best-first search462 possible 6-tile pattern databases. automatically constructed PDBtwo orders magnitude faster number expansions one would expectusing average 6-tile PDB, three orders magnitude faster worst 6-tilePDB greedy best-first search. GDRC-generated PDB works substantially bettergreedy best-first search state-of-the-art instance-specific PDBs, requiring onetwentieth expansions. One additional advantage GDRC-generated PDBinstance-specific PDBs fact GDRC produces single PDB, unlike instancespecific PDBs, produce new PDB every problem.summary, results show GDRC useful predicting relative qualityheuristics greedy best-first search. also showed possible leveragequantitative metric automatically construct heuristic greedy best-first search,automatically created heuristics extraordinarily effective greedy best-firstsearch.6. Related Workmetric, GDRC predicts heuristics high rank correlationwork well. general, objective h approximate h , , one alternative wayfind quality heuristic leverage fact try construct heuristic directlymimics , generally referred d. Indeed, approach generally quite successful(as opposed relying exclusively h), handily outperforming h many situations (Wilt& Ruml, 2014).Gaschnig (1977) describes predict worst case number nodes expandedA*, also discusses weighting heuristic affect worst case final nodeexpansion count. predictions, however, two limitations. First, predictionsassume search space tree, graph, case many applicationsheuristic search. addition that, worst case predictions depend amounterror present heuristic, error measured relative deviation h (n).A*, criterion makes certain amount sense, greedy best-first search,seen relative deviation h (n) cannot used predict greedybest-first search perform poorly. Gaschnig points increasing weight adinfinitium may decrease performance, precisely phenomenon documentedSection 2.Chenoweth Davis (1991) show heuristic rapidly growing logarithmic cluster, greedy best-first search done polynomial time. heuristicrapidly growing logarithmic cluster if, every node n, h(n) within logarithmicfactor monotonic function f h (n), f grows least fast function301fiWilt & Rumlg(x) = x. aware heuristics proven rapidly growinglogarithmic cluster.number works consider question predicting search algorithm performance(Korf et al., 2001; Pearl, 1984; Helmert & Roger, 2008), although subject attractingfar attention determining many nodes expanded optimalsearch algorithm. saw Section 3, behavior optional search generalpredict behavior GBRS. Lelis, Zilles, Holte (2011) empirical analysissuboptimal search algorithms, predicting number nodes would expandedWeighted IDA*, clear methods predict greedy best-first searchbehavior, thus tell us increasing weight far detrimental.Korf (1993) provides early discussion increasing weight may actuallybad, showing recursive best first search iterative deepening A* usedweight large, expansions actually increase. paper also early exampleexploring weight interacts expansion count, something centralwork.Hoffmann (2005) discusses FF heuristic (Hoffmann & Nebel, 2001) effective way solve many planning benchmarks used conjunction enforcedhill climbing. paper shows many benchmark problems, heuristic smallbounded-size plateaus, implying breadth-first search part enforced hill climbing algorithm bounded, means problems solved quickly, sometimes linear time. Although enforced hill climbing kind greedy best-first search,behaviour different greedy best-first search promising path turnslocal minimum. Greedy best-first search considers nodes searchspace, possibly allowing disparate nodes compete one another expansion.Enforced hill climbing limits consideration nodes near local minimum (withnearness measured edge count), means algorithm caresheuristic performs small local region space. Hoffmann (2011) extendsconcept, describing process automatically proving domain small localminima.Xu, Fern, Yoon (2009) discuss constructing heuristics suboptimal heuristicsearch, algorithm consider beam search. Beam searches inadmissiblyprune nodes save space time, function ultimately used ranknodes, make decision whether keep one node. functionXu et al. create used rank nodes, input function requires varietyfeatures state function, created using training data trial search runs.approach creating heuristic hill-climbing GDRC require traininginstances, require information states themselves. Hill-climbingGDRC does, however, limitation automatic generation heuristicsworks appropriate search space defined, abstraction-basedheuristics.7. ConclusionSuboptimal heuristic searches rely heavily heuristic node evaluation function.first showed greedy best-first search sometimes perform worse A*,302fiEffective Heuristics Suboptimal Best-First Searchalthough many domains general trend larger weight heuristicsWeighted A* leads faster search, also domains larger weight leadsslower search. long understood greedy best-first search boundsperformance, given poor heuristic, greedy best-first search could well expandentire state space, never terminate state space infinite. work showspoor performance theoretical curiosity, behavior occurpractice.considered characteristics effective heuristics greedy best-first search.showed several examples conventional guidelines building heuristics A*actually harm performance greedy best-first search. used experiencedevelop alternative observations desiderata heuristics use greedy bestfirst search. first every node, path goaldecreases h. second, important special case first, nodes h = 0connected goal via nodes h = 0. third observation nodesrequire including high h nodes solution high hvalue possible.showed domains greedy best-first search effective sharecommon trait heuristic function: true distance node goal, defined(n), correlates well h(n). information important anyone runningsuboptimal search interest speed, allows identify whetherassumption weighting speeds search true not, critical knowledgedeciding algorithm use.Finally, showed goal distance rank correlation (GDRC) used comparedifferent heuristics greedy best-first search, demonstrated usedautomatically construct effective abstraction heuristics greedy best-first search.Recent work shown search algorithms explicitly designed suboptimalsetting outperform methods like weighted A*, simple unprincipled derivativeoptimal search (Thayer & Ruml, 2011; Thayer, Benton, & Helmert, 2012; Stern,Puzis, & Felner, 2011). results indicate holds true heuristic functionswell: suboptimal search deserves specialized methods. Given importancesuboptimal methods solving large problems quickly, hope investigation spursanalysis suboptimal search algorithms heuristic functions rely on.8. Acknowledgmentsgratefully acknowledge support NSF (award 1150068). Preliminary expositionsresults published Wilt Ruml (2012, 2015).ReferencesBurns, E. A., Hatem, M., Leighton, M. J., & Ruml, W. (2012). Implementing fast heuristicsearch code. Proceedings Fifth Symposium Combinatorial Search.Chenoweth, S. V., & Davis, H. W. (1991). High-performance A* search using rapidlygrowing heuristics. Proceedings Twelfth International Joint ConferenceArticial Intelligence, pp. 198203.303fiWilt & RumlDoran, J. E., & Michie, D. (1966). Experiments graph traverser program.Proceedings Royal Society London. Series A, Mathematical PhysicalSciences, pp. 235259.Felner, A., Korf, R. E., Meshulam, R., & Holte, R. C. (2007). Compressed pattern databases.Journal Artificial Intelligence Research (JAIR), 30, 213247.Felner, A., Zahavi, U., Holte, R., Schaeffer, J., Sturtevant, N. R., & Zhang, Z. (2011).Inconsistent heuristics theory practice. Artificial Intelligence, 175 (9-10), 15701603.Gaschnig, J. (1977). Exactly good heuristics?: Toward realistic predictive theorybest-first search. Proceedings Fifth International Joint ConferenceArticial Intelligence, pp. 434441.Gibbons, J. D. (1985). Nonparametric Statistical Inference. Marcel Decker, Inc.Goldenberg, M., Felner, A., Sturtevant, N., & Schaeffer, J. (2010). Portal-based truedistance heuristics path finding. Proceedings Third Symposium Combinatorial Search.Hart, P. E., Nilsson, N. J., & Raphael, B. (1968). formal basis heuristic determination minimum cost paths. IEEE Transactions Systems Science Cybernetics,SSC-4 (2), 100107.Haslum, P., Botea, A., Helmert, M., Bonet, B., & Koenig, S. (2007). Domain-independentconstruction pattern database heuristics cost-optimal planning. ProceedingsAAAI-07, pp. 10071012.Helmert, M. (2006). fast downward planning system. Journal Artificial IntelligenceResearch, 26, 191246.Helmert, M. (2010). Landmark heuristics pancake problem. ProceedingsThird Symposium Combinatorial Search.Helmert, M., & Roger, G. (2008). good almost perfect?. ProceedingsTwenty-Third AAAI Conference Artificial Intelligence (AAAI-2008), pp. 944949.Hoffmann, J. (2005). Ignoring delete lists works: Local search topology planningbenchmarks. Journal Artifial Intelligence Research, 24, 685758.Hoffmann, J. (2011). Analyzing search topology without running search: connection causal graphs h+ . Journal Artificial Intelligence Research, 41,155229.Hoffmann, J., & Nebel, B. (2001). FF planning system: Fast plan generationheuristic search. Journal Artificial Intelligence Research, 14, 253302.Holte, R., Grajkowskic, J., & Tanner, B. (2005). Hierachical heuristic search revisitied.Symposium Abstracton Reformulation Approximation, pp. 121133.Kendall, M. G. (1938). new measure rank correlation. Biometrika, 30 (1/2), 8193.Kendall, M., & Gibbons, J. D. (1990). Rank Correlation Methods (Fifth edition). EdwardArnold.304fiEffective Heuristics Suboptimal Best-First SearchKorf, R., & Felner, A. (2002). Disjoint pattern database heuristics. Artificial Intelligence,134, 922.Korf, R. E. (1987). Planning search: quantitative approach. Artificial Intelligence,33 (1), 6588.Korf, R. E. (1993). Linear-space best-first search. Artificial Intelligence, 62, 4178.Korf, R. E. (1997). Finding optimal solutions Rubiks cube using pattern databases.Proceedings Fourteenth National Conference Artificial Intelligence, AAAI97,pp. 700705. AAAI Press.Korf, R. E. (2007). Analyzing performance pattern database heuristics. Proceedings22nd National Conference Artificial Intelligence, AAAI07, pp. 11641170.AAAI Press.Korf, R. E., Reid, M., & Edelkamp, S. (2001). Time complexity iterative-deepening-A*.Artificial Intelligence, 129, 199218.Korf, R. E., & Taylor, L. A. (1996). Finding optimal solutions twenty-four puzzle.AAAI, Vol. 2, pp. 12021207.Lelis, L., Zilles, S., & Holte, R. C. (2011). Improved prediction IDA*s performance viaepsilon-truncation. Proceedings Fourth Symposium Combinatorial Search.Likhachev, M., Gordon, G., & Thrun, S. (2003). ARA*: Anytime A* provable boundssub-optimality. Proceedings Seventeenth Annual Conference NeuralInformation Processing Systems.Likhachev, M., & Ferguson, D. (2009). Planning long dynamically feasible maneuversautonomous vehicles. International Journal Robotic Research, 28 (8), 933945.Martelli, A. (1977). complexity admissible search algorithms. Artificial Intelligence, 8 (1), 113.Nilsson, N. J. (1980). Principles Artificial Intelligence. Tioga Publishing Co.Parberry, I. (1995). real-time algorithm (n2 -1)-puzzle. Information ProcessingLetters, 56 (1), 2328.Pearl, J. (1984). Heuristics: Intelligent Search Strategies Computer Problem Solving.Addison-Wesley.Pohl, I. (1970). Heuristic search viewed path finding graph. Artificial Intelligence,1, 193204.Richter, S., Thayer, J. T., & Ruml, W. (2009). joy forgetting: Faster anytime searchvia restarting. Proceedings Twentieth International Conference AutomatedPlanning Scheduling.Richter, S., & Westphal, M. (2010). LAMA planner: Guiding cost-based anytimeplanning landmarks. Journal Artifial Intelligence Research, 39, 127177.Stern, R. T., Puzis, R., & Felner, A. (2011). Potential search: bounded-cost searchalgorithm. Proceedings 21st International Conference Automated PlanningScheduling, ICAPS.305fiWilt & RumlSussman, G. J. (1975). Computer Model Skill Acquisition. New York: New AmericanElsevier.Thayer, J. T., Benton, J., & Helmert, M. (2012). Better parameter-free anytime searchminimizing time solutions. Proceedings Fifth Annual SymposiumCombinatorial Search, SOCS 2012.Thayer, J. T., & Ruml, W. (2011). Bounded suboptimal search: direct approach using inadmissible estimates. Proceedings Twenty Sixth International JointConference Articial Intelligence (IJCAI-11), pp. 674679.Tukey, J. W. (1977). Exploratory Data Analysis. Addison-Wesley, Reading, MA.van den Berg, J., Shah, R., Huang, A., & Goldberg, K. Y. (2011). Anytime nonparametricA*. Proceedings Twenty Fifth National Conference Articial Intelligence.Wilt, C., & Ruml, W. (2012). weighted A* fail?. Proceedings FifthSymposium Combinatorial Search.Wilt, C., & Ruml, W. (2014). Speedy versus greedy search. Proceedings SeventhSymposium Combinatorial Search.Wilt, C., & Ruml, W. (2015). Building heuristic greedy search. ProceedingsEighth Symposium Combinatorial Search.Xu, Y., Fern, A., & Yoon, S. (2009). Learning linear ranking functions beam searchapplication planning. Journal Machine Learning Research, 10, 15711610.306fiJournal Artificial Intelligence Research 57 (2016) 1-37Submitted 03/16; published 09/16Learning Continuous Time Bayesian NetworksNon-stationary DomainsSimone VillaFabio Stellavilla@disco.unimib.itstella@disco.unimib.itDepartment Informatics, Systems CommunicationUniversity Milano-BicoccaViale Sarca 336, 20126 Milan, ItalyAbstractNon-stationary continuous time Bayesian networks introduced. allowparents set node change continuous time. Three settings developedlearning non-stationary continuous time Bayesian networks data: known transitiontimes, known number epochs unknown number epochs. score functionsetting derived corresponding learning algorithm developed. set numericalexperiments synthetic data used compare effectiveness non-stationary continuous time Bayesian networks non-stationary dynamic Bayesian networks. Furthermore, performance achieved non-stationary continuous time Bayesian networkscompared achieved state-of-the-art algorithms four real-world datasets,namely drosophila, saccharomyces cerevisiae, songbird macroeconomics.1. Introductionidentification relationships statistical dependencies components multivariate time-series, ability reasoning whether dependencieschange time crucial many research domains biology, economics, finance,traffic engineering neurology, mention few. biology, example, knowinggene regulatory network allows understand complex biological mechanisms rulingcell. context, Bayesian networks (BNs) (Pearl, 1989; Segal, Peer, Regev, Koller,& Friedman, 2005; Scutari & Denis, 2014), dynamic Bayesian networks (DBNs) (Dean& Kanazawa, 1989; Zou & Conzen, 2005; Vinh, Chetty, Coppel, & Wangikar, 2012)continuous time Bayesian networks (CTBNs) (Nodelman, Shelton, & Koller, 2002; Acerbi,Zelante, Narang, & Stella, 2014) used reconstruct transcriptional regulatorynetworks gene expression data. effectiveness discrete DBNs investigated identify functional correlations among neuroanatomical regions interest (Burge,Lane, Link, Qiu, & Clark, 2009), useful primer BNs functional magnetic resonance imaging data analysis made available (Mumford & Ramsey, 2014). However,mentioned applications require time-series generated stationary distribution, i.e. one change time. stationarity reasonableassumption many situations, cases data generating process clearlynon-stationary. Indeed, last years, researchers different disciplines, rangingeconomics computational biology, sociology medicine become interestedrepresenting relationships dependencies change time.c2016AI Access Foundation. rights reserved.fiVilla & StellaSpecifically, researchers interested analyzing temporal evolutiongenetic networks (Lebre, Becq, Devaux, Stumpf, & Lelandais, 2010), flow neuralinformation networks (Smith, Yu, Smulders, Hartemink, & Jarvis, 2006), heart failure (Liu,Hommersom, van der Heijden, & Lucas, 2016), complications type 1 diabetes (Marini,Trifoglio, Barbarini, Sambo, Camillo, Malovini, Manfrini, Cobelli, & Bellazzi, 2015)dependence structure among financial markets crisis (Durante & Dunson, 2014).According specialized literature evolution models (Robinson & Hartemink, 2010),divided two main categories: structurally non-stationary, i.e. modelsallowed change structure time, parametrically non-stationary,i.e. models allow parameters values change time.paper, structurally non-stationary continuous time Bayesian network model(nsCTBN) introduced. nsCTBN consists sequence CTBNs improves expressiveness single CTBN. Indeed, nsCTBN allows parents set nodechange time specific transition times thus allows model non-stationary systems. learn nsCTBN, Bayesian score learning CTBNs extended (Nodelman,Shelton, & Koller, 2003). nsCTBN version Bayesian score still decomposablevariable depends knowledge setting be: known transition times,transition times known, known number epochs, number transition times known, unknown number epochs, number transition timesunknown. learning algorithm knowledge setting designed developed.Experiments non-stationary dynamic Bayesian networks (nsDBNs) (Robinson &Hartemink, 2010), i.e. discrete time counterparts nsCTBNs, performed.main contributions paper following:definition structurally non-stationary continuous time Bayesian network model;derivation Bayesian score decomposition knowledge setting;design algorithms learning nsCTBNs different knowledge settings.novel dynamic programming algorithm learning nsCTBNs knowntransition times setting described, learning nsCTBNs others settingsperformed simulated annealing, exploiting dynamic programming algorithm;performance comparison nsCTBNs nsDBNs knowledge settingsrich set synthetic data generated nsCTBNs nsDBNs;performance comparison nsCTBNs state-of-the-art algorithms realworld datasets, namely drosophila, saccharomyces cerevisiae songbird;nsCTBN learned macroeconomics dataset consisting variables evolvingdifferent time granularities spanning 1st January 1986 31st March 2015.rest paper organized follows. Section 2 continuous time Bayesian networks introduced together learning problem complete data. Section 3introduces non-stationary continuous time Bayesian networks, presents three learning settings derives corresponding Bayesian score functions. Algorithms learningnsCTBNs different learning settings described Section 4. Numerical experiments synthetic real-world datasets presented Section 5. Section 6 closespaper making conclusions indicating directions research activities.2fiLearning Continuous Time Bayesian Networks Non-stationary Domains2. Continuous Time Bayesian NetworksContinuous time Bayesian networks combine Bayesian networks homogeneous Markovprocesses together efficiently model discrete state continuous time dynamical systems(Nodelman et al., 2002). particularly useful modeling domains variables evolve different time granularities, model presence peoplecomputers (Nodelman & Horvitz, 2003), study reliability dynamical systems (Boudali& Dugan, 2006), model failures server farms (Herbrich, Graepel, & Murphy, 2007),detect network intrusion (Xu & Shelton, 2008), analyze social networks (Fan & Shelton,2009), model cardiogenic heart failure (Gatti, Luciani, & Stella, 2011) reconstructgene regulatory networks (Acerbi & Stella, 2014; Acerbi, Vigano, Poidinger, Mortellaro,Zelante, & Stella, 2016). Recently, complexity inference continuous time Bayesiannetworks studied (Sturlaugson & Sheppard, 2014).2.1 Basicsrepresentation ability continuous time Bayesian networks inherent factorization system dynamics local continuous time Markov processes dependlimited set states. continuous time Bayesian network model defined follows:Definition 1. Continuous time Bayesian network (Nodelman et al., 2002). Let Xset random variables X = {X1 , X2 , . . . , XN }. X finite domain valuesV al(X) = {x1 , x2 , . . . , xI }. continuous time Bayesian network X consists two0 , specified Bayesian network X,components: first initial distribution PXsecond continuous time transition model specified as: directed (possibly cyclic)P a(X)graph G whose nodes X1 , X2 , . . . , XN ; conditional intensity matrix (CIM), QX,variable X X, P a(X) denotes set parents X graph G.P a(X)conditional intensity matrix QXconsists set intensity matricesqxpa1 uqxpa2 xu1=.qxpaI xu1uQpaX....qxpa1 xuIqxpa2 xuI,.pauqxIpau ranges possible configurations parents set P a(X), qxpai u =Ppaupaupauxj 6=xi qxi xj . Off-diagonal elements QX , i.e. qxi xj , proportional probabilityvariable X transitions state xi state xj given parents state pau .pauuintensity matrix QpaX equivalently summarized two independent sets: q X =pau{qxi : 1 I}, i.e. set intensities parameterizing exponential distributionspaupaupauunext transition occurs, paX = {xi xj = qxi xj /qxi : 1 i, j I, j 6= i},i.e. set probabilities parameterizing multinomial distributionsstate transitions. Note CTBN model assumes one single variablechange state specific instant, transition dynamics specified parentsvia CIM, independent variables given Markov Blanket.3fiVilla & Stella2.2 Structural LearningGiven fully observed dataset D, i.e. dataset consisting multiple trajectories1 whosestates transition times fully known, problem learning structure CTBNaddressed problem selecting graph G maximizes Bayesianscore computed dataset (Nodelman et al., 2003):BS (G : D) = ln P (G) + ln P (D|G).(1)P (G) prior graph G P (D|G) marginal likelihood.prior P (G) graph G, allows us prefer CTBNs structuresothers, usually assumed satisfy structure modularity property (Friedman &Koller, 2000), i.e. decompose following product terms:P (G) =P (P a(X) = P aG (X)),(2)XXterm parents set P aG (X) graph G. uniform prior G often used.marginal likelihood P (D|G) depends prior parameters P (q G , G |G)usually assumed satisfy global parameter independence, local parameter independence parameter modularity properties, outlined below.Global parameter independence (Spiegelhalter & Lauritzen, 1990) states paramP (X)P (X)eters q X GX Gassociated variable X graph G independent,thus prior parameters decomposes variable follows:P (X) P (X)P (q G , G |G) =P (q X G , X G |G).(3)XXLocal parameter independence (Spiegelhalter & Lauritzen, 1990) asserts parameters associated configuration pau parents P aG (X) variable Xindependent. Therefore, parameters associated variable X decomposableparent configuration pau follows:YYP (X) P (X)u(4)P (q X G , X G |G) =P (qxpai u , paxi |G).pau xiParameter modularity (Geiger & Heckerman, 1997) asserts variable Xparents P aG (X) = P aG 0 (X) two distinct graphs G G 0 , probability densityfunctions parameters associated X must identical:P aG (X)P (q XP aG (X), XP aG 0 (X)|G) = P (q XP aG 0 (X), X|G 0 ).(5)Furthermore, also assume sets parameters characterizing exponential distributions independent sets parameters characterizing multinomialdistributions:P (q G , G |G) = P (q G |G)P ( G |G).(6)1. trajectory defined sequence pairs (t, X(t)), transition time [0, ]associated state X(t) random variables corresponding nodes CTBN.4fiLearning Continuous Time Bayesian Networks Non-stationary DomainsDirichlet distribution selected prior parameters associated multinomial distribution, gamma distribution selected prior parametersassociated exponential distribution, i.e.P (qxpai u ) Gamma xpai u , xpai u ,(7)paupaupauP ( xi ) Dir xi x1 , . . . , xi xI ,(8)xpai u , xpai u , xpai xu1 , . . . , xpai xuI priors hyperparameters. particular, hyperparameters represent pseudocounts number transitions state state,parameter represents imaginary amount time spent statedata observed. Note hyperparameter xpai u inversely proportionalnumber joint states parents X. Conditioning dataset D, obtainfollowing posteriors parameters:u,(9)P (qxpai u |D) Gamma xpai u + Mxpai u , xpai u + Txpapaupaupaupaupau(10)P ( xi |D) Dir xi x1 + Mxi x1 , . . . , xi xI + Mxi xI ,uMxpai xuj sufficient statistics CTBN (Nodelman et al., 2003).Txpauparticular, Txpaamount time spent variable X state xiparents P a(X) state pau , Mxpai xuj number times variable Xtransitions state xi state xj parents P a(X) state pau 2 .Bayesian score (1) term P (G) grow size dataset D.Thus, significant term marginal likelihood P (D|G). case complete data,exploiting parameters independence (6) global parameter independenceproperty (3), marginal likelihood written follows:P (X)P (X)P (D|G) =L(q X G |D) L( X G |D),(11)XXP aG (X)L(q X|D) marginal likelihood q derived follows:YYpau xiP aG (X)L( X(xpai u + Mxpai u + 1) (xpai u )u(xpai u + 1) (xpai u + Txpa)u(paxi +1)pauu(paxi +Mxi +1),|D) marginal likelihood derived follows:xpai xuj + Mxpai xuj(xpai u ),paupaupau(+)xxxxjpa x =xx 6=xuj(12)(13)jBayesian-Dirichlet equivalent (BDe) metric version CTBNs (Nodelman, 2007).case, BDe metric uses priors (7) (8), parameter modularity (5),well global (3) local (4) parameter independence properties assumedsatisfied.2. Please note number times Pvariable X leaves state xi parents P a(X)pauustate pau computed follows Mxpa=xj 6=xi Mxi xj .5fiVilla & Stellaconclusion, Bayesian score (1) computed closed form assumingstructure modularity property (2) satisfied, using BDe metric follows:XP (X)P (X)ln P (P a(X) = P aG (X)) + ln L(q X G |D) + ln L( X G |D). (14)BS(G : D) =XXSince graph G CTBN acyclicity constraints, possible maximizeBayesian score (14) separately optimizing parents set P a(X) variableX. worthwhile mention maximum number parents set,search optimal value Bayesian score (14) performed polynomial time.search performed enumerating possible parents set using greedyhill-climbing procedure operators add, delete reverse edges graph G.3. Non-stationary Continuous Time Bayesian NetworksContinuous time Bayesian networks structurally stationary, graphchange time, parametrically stationary, conditional intensity matriceschange time. stationarity assumptions reasonable many situations,cases data generating process intrinsically non-stationarythus CTBNs longer used. Therefore, section, extend CTBNs becomestructurally non-stationary. i.e. allow CTBNs structure change continuoustime.3.1 Definitionnon-stationary continuous time Bayesian network model, graph CTBNreplaced graphs sequence G = (G1 , G2 , . . . , GE ), graph Ge representscausal dependency structure model epoch e {1, 2, . . . , E}3 . modelstructurally non-stationary introduction graphs sequencehandle transition times common whole network and/or node-specific.Following notations definitions used non-stationary dynamic Bayesian networks, let = (t1 , . . . , tE1 ) transition times sequence, i.e. timescausal dependency structure Ge , active epoch e, replaced causal dependencystructure Ge+1 , becomes active epoch e + 1. epoch defined periodtime two consecutive transitions, i.e. epoch e active periodtime starting te1 ending te . graph Ge+1 , active epoche + 1, differs graph Ge , active epoch e, set edgescall set edge changes Ge .Figure 1 shows graphs sequence G = (G1 , G2 , G3 , G4 ) consisting four epochs (E = 4)transition times = (t1 , t2 , t3 ). epoch associated set edge changes.Specifically, graph G2 differs graph G1 following set edge changesG1 = {X3 X2 , X2 6 X3 , X1 6 X2 }, graph G3 differs graph G2following set edge changes G2 = {X2 X1 } graph G4 differs graphG3 following set edge changes G3 = {X3 X4 , X4 X1 , X1 6 X4 , X4 6 X3 }.3. worthwhile mention first epoch, i.e. epoch starting time 0 ending time t1associated graph G1 , last epoch, i.e. epoch starting time tE1 endingtime (the supremum considered time interval, i.e. [0,T]) associated graph GE .6fiLearning Continuous Time Bayesian Networks Non-stationary DomainsX1X2X1X2X1X2X1X2X4X3X4X3X4X3X4X30321t2t14t3Figure 1: Graphs sequence G = (G1 , G2 , G3 , G4 ) nsCTBN four epochs, E = 4,three transition times, = (t1 , t2 , t3 ), edges gained lost time.Non-stationary continuous time Bayesian networks allow nodesequence parents sets, parents set active given epoch. Therefore,introduce concept homogeneous interval H(X) = (h1 , . . . , hM ) associated nodeX, defined union consecutive epochs parents setP a(X) active node X. Note epoch associated differentparents set, equal E.non-stationary continuous time Bayesian network defined follows.Definition 2. (Structurally) non-stationary continuous time Bayesian network. Let Xset random variables X1 , . . . , XN . X finite domain values V al(X) ={x1 , . . . , xI }. (structurally) non-stationary continuous time Bayesian network Nns =(B, Mns ) X consists two components:0 , specified Bayesian network B X,initial distribution PXnon-stationary continuous time transition model Mns specified as:sequence directed (possibly cyclic) graphs G = (Ge )Ee=1 whose nodesX1 , . . . , XN , E represents number epochs;P (X)Gconditional intensity matrix, QX,H(X), X X, P aG (X) denotesparents sets X G, H(X) denotes intervals associated X.P (X)Gconditional intensity matrix QX,H(X)consists set intensity matricesuqxpa1 ,hpaq ux2 x1 ,hm=.pauqxI x1 ,hmuQpaX,hm....qxpa1 xuI ,hmqxpa2 xuI ,hm,.pauqxI ,hmone configuration pau parents set P a(X) P aG (X) activeinterval hm H(X).4u4. Note following equation qxpai ,h=Pxj 6=xi7qxpai xuj ,hm still holds.fiVilla & Stella3.2 Learning FrameworkLearning nsCTBN fully observed dataset done using Bayesian learningframework taking account entire graphs sequence G. nsCTBNs case, mustspecify prior probability graphs sequence G and, possible sequence,density measure possible values parameters q G G . prior P (G)likelihood P (q G , G |G) given, marginal likelihood P (D|G) computedBayesian score evaluated. important note focusedrecovering graphs sequence G detecting possible changes parameters.fact, identify non-stationarity parameters model, i.e. entriesconditional intensity matrices, significant enough result structural changesgraph. Others changes assumed small enough alter graph structure.3.2.1 Prior Probability GraphsGiven transition times , thus number epochs E, assume priornsCTBNs structure G written follows:P (G|T ) = P (G1 , ..., GE |T ) = P (G1 , G1 , ..., GE1 |T ) = P (G1 )P (G1 , ..., GE1 |T ).(15)Equation (15) justified assume probability distribution edgechanges function number changes performed, also definedindependently initial graph G1 . knowledge particular edgesoverall topology available initial network, use informative priorP (G1 ) otherwise resort uniform distribution. CTBNs, P (G1 ) must satisfy structure modularity assumption (2), prior set edge changesP (G1 , . . . , GE1 |T ) defines way edges change adjacent epochs.3.2.2 Prior Probability Parametersprior parameters P (q G , G |G, ) selected satisfy following assumptions:independence sets parameters characterizing exponential multinomial distributions (6), parameter modularity (5) parameter independence. latterassumption divided three components nsCTBNs: global parameter independence,interval parameter independence local parameter independence.Global parameter independence asserts parameters associated nodensCTBNs graphs sequence independent, prior parameters decomposesvariable X follows:P aG (X)P aG (X)P (q G , G |G, ) =P (q X,H(X), X,H(X)|G, ).(16)XXInterval parameter independence states parameters associated intervalactive parents node independent, parameters associatedX parents sets P aG (X) decomposable interval hm H(X) follows:P (X)P (X)GGP (q X,H(X), X,H(X)|G, ) =hm8P (X)P (X)P (q X,hGm , X,hGm |G, ).(17)fiLearning Continuous Time Bayesian Networks Non-stationary DomainsLocal parameter independence states parameters associated statevariable given interval independent, thus parameters associated Xinterval hm H(X) decomposable parent configuration pau follows:YYP (X) P (X)uu(18), paP (qxpai ,hP (q X,hGm , X,hGm |G, ) =xi ,hm |G, ).pau xiCTBNs case, Dirichlet distribution used prior parametersmultinomial distribution gamma distribution used prior parametersuexponential distribution. sufficient statistics modified follows: Txpa,hmamount time spent state X = xi P a(X) = pau interval H(X) = hm ,Mxpai xuj ,hm number transitions state X = xi state X = xj P a(X) = pauPinterval H(X) = hm . let Mxpai ,hu = xj 6=xi Mxpai xuj ,hm number timesX leaves state xi parents P a(X) state pau interval H(X) = hm .3.2.3 Marginal LikelihoodGiven graphs sequence G, transition times , marginal likelihood P (D|G, )dataset computed closed form using priors sufficient statisticspreviously defined. derive Bayesian-Dirichlet equivalent metric nsCTBNs,make assumptions CTBNs. case, parameter independenceassumption divided global (16), interval (17) local (18) parameter independence.Therefore, marginal likelihood becomes:P aG (X)P aG (X)P (D|G, ) =L(q X,H(X)|D) L( X,H(X)|D).(19)XXmarginal likelihood q equation (19) calculated follows:(pau +1)xi ,hmpaupauu+1+xpai ,hxi ,hmxi ,hmP aG (X)L(q X,H(X) |D) =(pau +M pau +1) ,xi ,hmxi ,hmpaupaupahm pau xi u + 1xi ,hm + Txi ,hmxi ,hm(20)marginal likelihood equation (19) calculated follows:paupauuxpai ,h+xi xj ,hmxi xj ,hmP aG (X)L( X,H(X)|D) =.paupaupauxi xj ,hmhm pau xi =xj xi ,hm + Mxi ,hmxi 6=xj(21)important note nsCTBNs, pseudocounts well imaginaryamount time associated interval. aspect requires careful choiceorder biased towards values small intervals analyzed.possible correction weight CTBNs hyperparameters quantity proportional time interval width (hm hm1 ), hM denotes total time. Thus,nsCTBNs hyperparameters could defined follows:xpai xuj ,hmxpai ,hu(hm hm1 ),hM(hm hm1 )= xpai u.hM= xpai xuj9(22)(23)fiVilla & Stellawant control parameter priors using two hyperparameters ,use uniform BDe nsCTBNs (BDeu). case, hyperparametersdefined (22) (23) divided number U possible configurationsparents P a(X) node X times cardinality domain X, follows:xpai xuj ,hm=xpai ,hu=(hm hm1 ),UIhM(hm hm1 ).UIhM(24)(25)Equations (22) (23) rescale hyperparameters way biasedrespect epochs length, equations (24) (25) based uniformdistribution used performing numerical experiments.3.3 Bayesian Score DecompositionBayesian score decomposed variable based information availabletransition times. regard, three knowledge settings used deriveBayesian score, namely: known transition times (KTT), known number epochs (KNE)unknown number epochs (UNE).3.3.1 Known Transition Timessetting, transition times known. Thus, prior probabilitygraphs sequence P (G|T ) decomposes equation (15), marginal likelihooddecomposes variable X according equation (19).Therefore, Bayesian score BS(G : D, ) written follows:BS(G : D, ) = ln P (G1 ) + ln P (G1 , . . . , GE1 |T )P (X)P (X)GG+ ln L(q X,H(X)|D) + ln L( X,H(X)|D).(26)setting structural learning problem non-stationary continuous timeBayesian network consists finding graph G1 active first epoch (e = 1)E 1 sets edge changes G1 , . . . , GE1 together corresponding parametersvalues, maximize Bayesian score defined equation (26).graphs G2 , . . . , GE selected making assumptions waysedges change continuous time. common approach (Robinson & Hartemink, 2010)consists assuming graphs sequence G = (G1 , . . . , GE ) depends parametercontrols number edge changes continuous time. approach usestruncated geometric distribution, parameter p = 1 exp(c ), model numberparents changes occurring transition time te+1 :Xce =|Ge (X)|.(27)XXvariable ce counts number edge changes two consecutive graphs GeGe+1 , parameter c controls impact number edge changes cescore function (26).10fiLearning Continuous Time Bayesian Networks Non-stationary Domainsedge changes Ge assumed mutually independent, probabilityedge changes subsequent epochs written follows:P (G1 , . . . , GE1 |T ) =E1e=1E1(1 exp(c ))(exp(c ))ce(exp(c ))ce ,1 (exp(c ))cmax +1(28)e=1cmax truncation term. Therefore, assume truncated geometric distribution number parents changes occurring transition times equation(28) holds, Bayesian score (26) decomposes variable X follows:BS(G : D, ) =Xln P (P a(X) = P aG1 (X)) cXXP (X)G+ ln L(q X,H(X)|D) +E1Xcee=1P aG (X)ln L( X,H(X)|D).(29)worthwhile notice number parents changes ce epoch epenalizes Bayesian score, thus discourages sudden variations parents setconsecutive epochs, parameter c controls impact changesscore function (26).3.3.2 Known Number Epochstransition times unknown, Bayesian score written follows:BS(G, : D) = ln P (G, ) + ln P (D|G, ).(30)Assuming P (G, ) = P (G)P (T ) Bayesian score (30) becomes:BS(G, : D) = ln P (G) + ln P (T ) + ln P (D|G, ).(31)number epochs E known, prior probability P (G) graphssequence G decomposes equation (15), truncated geometric distributionused number parents changes occurring transition time,known transition times setting.choice P (T ) made include prior knowledge set transitiontimes. However, information available, uniform prior P (T ) used, implyingpossible values transition times equally likely given number epochsE. Thus, Bayesian score (31) decomposed variable X follows:BS(G, : D) = ln P (T ) ++Xln P (P a(X) = P aG1 (X)) cXXP aG (X)ln L(q X,H(X) |D)E1Xcee=1P (X)G+ ln L( X,H(X)|D),(32)ce counts number edge changes two consecutive parents sets, ccontrols impacts BS(G, : D) edge changes, happens KTTsetting.11fiVilla & Stella3.3.3 Unknown Number Epochsnumber epochs E unknown, transition times unknown well.setting, learn nsCTBN exploiting introduced KTTKNE settings. assume structure non-stationary continuous timeBayesian network evolve different speeds continuous time. assumptionincorporated using truncated geometric distribution parameter p = 1exp(e )number epochs. general, large values e encode strong prior beliefstructure nsCTBN changes slowly (i.e. epochs exist).Following presented KTT setting, Bayesian score obtainedsubtracting parameter e times number epochs E. Therefore, Bayesianscore BS(G, : D) decomposes variable X follows:BS(G, : D) = ln P (T ) e E +Xln P (P a(X) = P aG1 (X)) ccee=1XXP (X)E1XP (X)GG+ ln L(q X,H(X)|D) + ln L( X,H(X)|D).(33)Note Bayesian score (33) contains two parameters, namely c e ,encode prior belief structure nsCTBN. Specifically, parameter cregulates prior belief smoothness edge changes (e.g. encouragingdiscouraging edge changes per epoch), parameter e regulates prior beliefnumber epochs (e.g. encouraging discouraging creation epochs).4. Structural Learningoptimal structure nsCTBNs found separately maximizing componentsBayesian score associated node. achieved using exact optimization algorithm based dynamic programming transition timesgiven. contrast, number epochs known informationtransition times available, resort approximate techniques based MonteCarlo simulated annealing. present exact algorithm solving structurallearning problem KTT setting. Then, briefly outline stochastic algorithmssolve structural learning problem KNE setting UNE setting.4.1 Known Transition Timessetting Bayesian score decomposes according equation (29). Thus,optimal graphs sequence G found separately searching optimal parents sequence G X node X. solve problem finding optimal parents sequenceG X node X consider sequence consisting intervals H(X) = (h1 , . . . , hM )possible parents, Z = 2S possible parents sets. find optimal parentssequence G X must compute Z marginal likelihood terms associated q ,one marginal likelihood term possible parents set P az (X) interval hm .Then, optimization algorithm used find maximum componentBayesian score associated node X.12fiLearning Continuous Time Bayesian Networks Non-stationary Domainsexhaustive search would prohibitive, would require evaluating Z scores,one possible parents sequence G X . Unfortunately, also greedy search strategycomputes parents set maximizes Bayesian score intervalviable. fact, function counts parents changes ce (29) binds choicesubsequent parents set, i.e. binds Ge Ge+1 .However, relation score variable X associated parents setP a(X)P a(X) interval hm , denoted BSX,hm , score associated parents setP a(X)P a(X) interval hm1 , denoted BSX,hm1 , defined recursion follows:nP a(X)P (X)P a(X) P a(X)BSX,hm = max BSX,hzm1 c cX,e + ln L(q X,hm , X,hm |D) ,(34)P azcX,e = |Ge (X)|, marginal likelihoods q grouped together.P a(X)score BSX,hm , associated parents set P a(X) node X interval hm ,introduced clarify recursion used Algorithm 1. Note score dependscomponents score hm . particular, marginal likelihoodscomponent involved, also term cX,e , counts parents changes, includedbinds choice subsequent parents sets. Equation (34) exploited dynamicprogramming select optimal parents sequence G X node X.Algorithm 1 takes input marginal likelihoods q intervalparents set, prior probability initial parents set, number parentschanges, parameter c . Algorithm 1 ensures optimal parents sequence G Xnode X corresponding optimal Bayesian score. core computationZ score matrix, denoted SC, dynamic programming recursion.dynamic programming recursion interval h1 (m = 1) defined follows:P (X)SC1z = ln L(q X,hz1P (X), X,hz1|D) + ln P (P az (X) = P aGh1 (X)),(35)1 z Z, while, intervals hm (m = 2, . . . , ), recursion is:nP (X) P (X)zuSCm= max SCm1+ ln L(q X,hzm , X,hzm |D) c cX,e .1uZfilling score matrix SC, value maxz {SC[M, z]} optimal Bayesian score,optimal parents sequence reconstructed backwards 1 usingindex matrix . cost computing dynamic programming recursion O(M Z 2 ),polynomial fixed maximum number parents S.problem selecting optimal parents sequence interesting graph representation. Indeed, possible create graph whose nodes associated marginallikelihoods q interval hm parents set P az (X), node associated interval hm linked nodes associated interval hm+1 .arc associated weight computed difference marginal likelihoods interval hm parents set P az (X) cost switchingparents set interval hm1 parents set interval hm . Two special nodesadded represent start end optimal parents sequence. graphcycles, thus selection optimal parents sequence nodereduced longest path problem start node end node directedacyclic graph, thus solved using either dynamic linear programming.13fiVilla & StellaAlgorithm 1 LearnKTTXRequire: matrix containing marginal likelihoods q LX[M, Z], vector containing prior probability initial parents set P R[Z], matrix containingnumber parents changes C[Z, Z] parameter parents changes c .Ensure: score matrix SC[M, Z] index matrix [M, Z].1: Initialize SC[m, z] , [m, z] 0.2: 1, . . . ,3:z 1, . . . , Z4:(m = 1)5:SC[m, z] ln LX[m, z] + ln P R[z]6:else7:w 1, . . . , Z8:score SC[m 1, w] + ln LX[m, z] c C[w, z]9:(score > SC[m, z])10:SC[m, z] score11:[m, z] w12:end13:end14:end15:end16: endLearning nsCTBN done following following four steps procedure: i) useudataset compute variable X sufficient statistics TxpaMxpai xuj ,hm,hmaccording given transition times ; ii) compute marginal likelihoods (20) (21),fill LX matrix; iii) run Algorithm 1 node X get correspondingoptimal parents sequence; iv) collect optimal parents sequence node Xcompute corresponding CIMs using sufficient statistics already computed step i).allow intervals differ transition times, i.e. obtainedone possible unions transition times; repeat learningprocedure E (E 1)/2 cases. possible speed computationsufficient statistics aggregated intervals. way, readdataset once, precomputed marginal likelihoods stored reusedintervals. Moreover, computations performed parallel node.4.2 Known Number Epochssetting, know number epochs, transition times given,cannot directly apply Algorithm 1. However, tentative allocation transitiontimes given, apply Algorithm 1 obtain optimal nsCTBNs structure,assumption different true transition times . findoptimal tentative allocation , i.e. allocation close possible , applysimulated annealing (SA) algorithm (Kirkpatrick, Gelatt, & Vecchi, 1983).14fiLearning Continuous Time Bayesian Networks Non-stationary DomainsSimulated annealing iterative algorithm attempts find global optimumx given function f (x) stochastic search feasible region. iterationk, SA algorithm assumed state xk , samples proposal state x0according proposal distribution x0 P 0 (|xk ). Then, SA algorithm computesquantity = exp ((f (x) f (x0 ))/CT ), CT computational temperature.SA algorithm accepts proposal state x0 probability equal min{1, }. Concisely,SA always accepts proposal state x0 f (x0 ) > f (x) setting xk+1 = x0 ,accepts proposal state x0 f (x0 ) < f (x) probability setting xk+1 = x0probability xk+1 = xk probability (1 ), i.e. case stateSA algorithm change. computational temperature reduces iterationsaccording cooling schedule. shown one cools sufficiently slowly,algorithm probably find global optimum (Kirkpatrick et al., 1983). designcooling schedule important part SA algorithm (Bertsimas & Tsitsiklis,1993). possible approach use exponential cooling schedule defined follows:CTk = CT0 k , CT0 represents initial temperature, typically set 1.0,cooling rate, usually set close 0.8, k current iteration (Murphy, 2012).nsCTBNs case, state SA algorithm x associated tentativeallocation , function f (x) Bayesian score (32). Algorithm 2 takes inputsufficient statistics, parameters used run Algorithm 1 parametersSA algorithm. solves structural learning problem KNE setting givenvariable X ensuring optimal tentative allocation corresponding score.Algorithm 2 LearnKNEXRequire: sufficient statistics SuffStatsX, prior probability P R[], number parentschanges C[, ], parameter c , tentative allocation , initial temperature CT0 , coolingrate , number iterations Iters, truncation parameter z standard deviation .Ensure: optimal tentative allocation best Bayesian score bestSC.1: Initialize k 0, .2: LX GetMLX(SuffStatsX , )3: bestSC LearnKTTX(M LX, P R[], C[, ], c )4: (k < Iters)5:TentativeAllocation(T , z, )6:LX GetMLX(SuffStatsX , )7:tentSC LearnKTTX(M LX, P R[], C[, ], c )8:CT CT0 kn9:accP rob min 1, exp (bestSCtentSC)CT10:ur UniRand()11:(ur accP rob)12:13:currSC tentSC14:end15:k k+116: end17: bestSC currSC15fiVilla & Stellasimulated annealing parameters used include tentative allocation ,initial temperature CT0 , cooling rate number iterations Itersexponential cooling schedule. Moreover, truncation parameter z standard deviationused selection new tentative allocation 0 according randomprocedure shown Algorithm 3. procedure selects transition time discreteuniform distribution, UniRandDiscr(T ), perturbs according truncated normaldistribution, StdNormRand(), standard deviation equal , additionpoint masses z z, z represents truncation parameter.Algorithm 3 TentativeAllocationRequire: tentative allocation , truncation parameter z standard deviation .Ensure: new tentative allocation 0 .1: UniRandDiscr(T )2: 0 \3: nr StdNormRand()4: (nr < z)5:nr z6: end7: (nr > z)8:nr z9: end10: + nr11: 04.3 Unknown Number Epochssetting number epochs unknown; thus structural learning algorithmmust able move across different number epochs, well correspondingtransition times. Also case, used simulated annealing algorithm statex tentative allocation function optimized f (x) Bayesian scoreshown equation (33). cooling schedule set one usedKNE setting. proposal distribution differs one used KNE settinguses two additional operators, namely split merge operators. splitoperator allows split given interval [tm ; tm+1 ) two subintervals [tm ; t) [t; tm+1 )tm , tm+1 . merge operator allows merge contiguous intervals [tm1 ; tm )[tm ; tm+1 ) form wider interval [tm1 ; tm+1 ) tm1 , tm , tm+1 .new state obtained sampling number epochs changes ec multinoulli distribution parameters (p1 , p2 , p3 ), p1 represents probabilitynumber epochs next iteration |T | decreased one; p3 represents probabilitynumber epochs next iteration |T | increased one, p2 representsprobability number epochs next iteration |T | change respectcurrent one. ec equal 2, Algorithm 2 invoked, ec equal 1,merge operator applied invoking Algorithm 2, ec equal 3,split operator applied invoking Algorithm 2.16fiLearning Continuous Time Bayesian Networks Non-stationary DomainsAlgorithm 4 solves structural learning problem nsCTBN UNE settinggiven node X ensuring optimal tentative allocation correspondingBayesian score. algorithm similar one used KNE settings,uses Algorithm 5 apply split merge operators. left(t) function Algorithm5 returns transition time comes immediately transition time t.Algorithm 4 LearnUNEXRequire: sufficient statistics SuffStatsX, prior probability P R[], number parentschanges C[, ], parameter c , parameter e , tentative allocation , initial temperatureCT0 , cooling rate , number iterations Iters, truncation parameter z, standard deviation , split probability sp merge probability mp.Ensure: optimal tentative allocation best Bayesian score bestSC.1: Initialize k 0, .2: bestSC LearnKTTX(GetMLX(SuffStatsX, ), P R[], C[, ], c ) e |T |3: (k < Iters)4:SplitMerge(T , sp, mp)5:TentativeAllocation(T , z, )6:tentSC LearnKTTX(GetMLX(SuffStatsX, ), P R[], C[, ], c ) e |T |7:CT CT0 kn8:accP rob min 1, exp (bestSCtentSC)CT9:ur UniRand()10:(ur accP rob)11:12:currSC tentSC13:end14:k k+115: end16: bestSC currSCAlgorithm 5 SplitMergeRequire: tentative allocation , split probability sp merge probability mp.Ensure: new tentative allocation 0 .1: 02: p UniRand()3: (p < mp)4:UniRandDiscr(T )5:0 \6: else7:(p < (mp + sp))8:UniRandDiscr(T )9:nt left(t) + tleft(t)210:0 nt11:end12: end17fiVilla & Stella5. Numerical ExperimentsNumerical experiments performed synthetic real-world datasets. Syntheticdatasets used compare nsCTBNs nsDBNs KTT, KNE UNE knowledge settings terms accuracy, precision, recall F1 measure. following real-worlddatasets: drosophila, saccharomyces cerevisiae songbird, used compare nsCTBNsstate-of-the-art algorithms, i.e. TSNI (a method based ordinary differential equations),nsDBN (Robinson & Hartemink, 2010) non-homogeneous dynamic Bayesian networksBayesian regularization (TVDBN) (Dondelinger, Lebre, & Husmeier, 2013),UNE knowledge setting. Drosophila, saccharomyces cerevisiae songbird datasetscollected fixed time intervals, thus analyzed additional real-world dataset, consisting financial/economic variables evolving different time granularities, exploitexpressiveness nsCTBNs events occur asynchronously. Note performance comparison using synthetic datasets benefits knowledge groundtruth, apply performance comparison using real-world datasetsground truth available. cases, comparison exploits partialmeta-knowledge available specialized literature.5.1 Synthetic DatasetsArtificially generated datasets include data sampled rich set nsDBN models,i.e. nsDBN generated datasets, rich set nsCTBN models, i.e. nsCTBN generateddatasets. nsDBN nsCTBN models consist five nodes associated binaryternary variables. Numerical experiments concern learning parents sets, transitiontimes number epochs single node. choice motivated factstructural learning nsCTBN performed single node independentlyremaining ones. However, transition times unknown, multiple parentssets changes could make easier correctly identify times change.5.1.1 nsDBN Generated DatasetsnsDBN generated datasets sampled nsDBN models5 associated followingnumber epochs E {2, 3, 4, 5}. particular, number epochs E, 10 differentnsDBN instances sampled obtain number datasets equal 10, one consisting single trajectory. Thus, 40 synthetic datasets used learn structurensDBN nsCTBN (number models =2) KTT, KNE UNE settings.Structural learning experiments performed c = {1, 2, 4} e = {5, 10, 15}nsCTBN = {1, 2, 4} = {10, 50, 100} nsDBN6 . overall number1,200 experiments performed. particular, performed number epochsnumber datasets number c number models = 41032 = 240 experimentsKTT setting, 240 KNE setting, number epochs numberdatasets number c number e number models = 410332 = 720experiments performed UNE setting.5. Inter-slice arcs allowed, intra-slice arcs allowed. holds true nsDBN modelssampled obtain nsDBN generated datasets.6. worthwhile mention parameters nsDBN counterparts ce parameters nsCTBN.18fiLearning Continuous Time Bayesian Networks Non-stationary Domainsnsdbn jar executable7 (Robinson & Hartemink, 2010) used structural learning nsDBN, set maximum number proposed networks 500,000burn-in period 50,000 nsDBN. nsCTBN learned using following parameters setting: Iters = 1,000, CT0 = 1,000, = 0.8, z = 3, = 1, sp = 0.3, mp = 0.3,= 1 = 0.1 using BDeu metric. Furthermore, nsDBN nsCTBN setmaximum number parents 4. arcs occurred 90 percentsamples8 belong inferred nsDBN nsCTBN models. Accuracy (Acc), precision (P rc), recall (Rec) F1 measure (F1 ) achieved nsDBN nsCTBN learnedKTT, KNE UNE settings reported Table 1, 2 3 respectively.worthwhile mention KNE UNE settings, nsDBNs nsCTBNsalmost always identified correct number epochs location associatedtransition times. Accuracy, precision, recall F1 measure computed twodifferent ways. Firstly, included arcs true network epoch. Secondly,excluded self-reference arcs, i.e. arcs connecting node two consecutivetime-slices true network epoch. fact, node nsCTBNself-reference arc default, happen nsDBNs. meansfirst case nsDBN required learn arcs nsCTBN required do. Therefore,ensure fair comparison nsCTBN nsDBN adopted second case. Tables 1,2 3 report performance measure values computed excluding self-reference arcsset arcs true networks epoch.Table 1: nsCTBN compared nsDBN KTT setting nsDBN generated data.Average, min (subscript) max (superscript) performance values 10 networksc nsCTBN nsDBN.Number epochs E342AccP recRecF15nsDBNnsCTBNnsDBNnsCTBNnsDBNnsCTBNnsDBNnsCTBN0.961.000.930.901.000.670.771.000.400.801.000.570.921.000.751.001.001.000.851.000.500.911.000.670.950.980.930.791.000.500.670.830.430.710.910.471.000.920.751.001.001.001.000.860.631.000.920.770.950.990.890.871.000.400.650.900.250.730.950.311.000.820.631.000.960.751.000.700.381.000.800.500.940.970.890.851.000.500.580.800.250.690.860.350.820.950.550.991.000.800.710.910.330.820.950.47According Tables 1, 2 3, nsDBNs consistently achieve greater accuracy valuesachieved nsCTBNs three settings. Furthermore, nsDBNsaccuracy stable respect number epochs E happennsCTBNs. Indeed, number epochs E greater 3, nsCTBNs achieveaccuracy values significantly smaller achieved numberepochs E equal 2 3. happen nsDBNs accuracyrobust respect number epochs E.7. acknowledge precious help Alex Hartemink let us use nsdbn jar executable programlearning nsDBN models. Furthermore, also provided drosophila songbird datasets.8. Samples obtained parameters values.19fiVilla & StellaTable 2: nsCTBN compared nsDBN KNE setting nsDBN generated data.Average, min (subscript) max (superscript) performance values 10 networksc nsCTBN nsDBN.Number epochs E342AccP recRecF15nsDBNnsCTBNnsDBNnsCTBNnsDBNnsCTBNnsDBNnsCTBN0.941.000.880.911.000.690.761.000.390.801.000.580.921.000.751.001.001.000.851.000.500.911.000.670.950.980.920.791.000.500.680.840.350.720.910.511.000.920.751.001.000.951.000.860.631.000.920.770.940.990.890.860.970.550.650.910.250.740.950.381.000.810.631.000.950.751.000.710.381.000.810.500.930.960.870.850.960.550.590.780.240.700.740.350.820.950.550.981.000.800.700.910.330.810.950.47Table 3: nsCTBN compared nsDBN UNE setting nsDBN generated data.Average, min (subscript) max (superscript) performance values 10 networksc , e nsCTBN , nsDBN.Number epochs E342AccP recRecF15nsDBNnsCTBNnsDBNnsCTBNnsDBNnsCTBNnsDBNnsCTBN0.951.000.880.910.980.700.750.980.380.790.960.550.921.000.751.001.001.000.851.000.500.911.000.670.950.980.930.801.000.520.660.810.410.700.890.481.000.920.751.001.001.001.000.860.631.000.920.770.930.980.890.870.950.670.650.870.260.740.870.410.990.810.611.000.950.730.990.700.360.990.800.480.920.960.890.840.900.710.570.780.230.680.850.340.810.930.550.981.000.800.690.870.330.810.930.47different picture emerges focusing task discover positive arcs. Indeed,case nsCTBNs achieve values precision, recall F1 measure, alwaysgreater achieved nsDBNs. nsCTBNs achieve precision values robustrespect knowledge settings number epochs E.hold true recall performance measure. Indeed, nsCTBNs achieve robust recallrespect knowledge settings (KTT, KNE UNE), recall achievednsCTBNs significantly degrades moving 2 3 epochs knowledgesettings. happens F1 measure achieved nsCTBNs. resultsnumerical experiments suggest nsCTBNs effective nsDBNs discoverpositive arcs, even datasets generated using nsDBNs. possible explanationbehavior learning nsDBNs difficult learning nsCTBNs.particular, nsDBNs must learn self-reference arcs nsCTBNs not. Furthermore,node, nsCTBNs learn locally sequence parents setshappen nsDBNs. fact, nsDBNs learn globally sequence parents setsnodes, i.e. globally learn sequence networks, thus solve learningproblem difficult one solved nsCTBNs.20fiLearning Continuous Time Bayesian Networks Non-stationary Domains5.1.2 nsCTBN Generated Datasetsgenerated 40 synthetic datasets E {2, 3, 4, 5}, datasets usedlearn structure nsCTBN three knowledge settings. parameterssetting used one used nsCTBN learning nsDBN generated datasets (fornsCTBN, used = 1, = 0.1 BDeu metric), while, case,perform structural learning experiments nsDBN models9 . graphical structuresnsCTBN models sampled obtain datasets sampledobtain nsDBN datasets. goal experiments analyze performancensCTBN structural learning algorithms three knowledge settings.analysis data reported Tables 4, 5 6 brings us concludensCTBN structural learning algorithms work well three settings accordingconsidered performance measures. Accuracy, recall F1 measure decrease slightlynumber epochs increases 2 5. particular, recall measure suffersgreatest decrease 1 0.95 number epochs increases 2 5.Accuracy F1 measure robust respect number epochs,precision robust performance measure respect different datasetsdifferent values number epochs knowledge settings.Table 4: nsCTBN KTT setting nsCTBN generated data. Average, min(subscript) max (superscript) performance values 10 networks c .AccP recRecF121.001.001.001.001.001.001.001.001.001.001.001.00Number30.991.000.921.001.001.000.991.000.860.991.000.92epochs E40.991.000.941.001.001.000.991.000.890.991.000.9450.981.000.901.001.001.000.961.000.860.981.000.92Table 5: nsCTBN KNE setting nsCTBN generated data. Average, min(subscript) max (superscript) performance values 10 networks c .AccP recRecF121.001.001.001.001.001.001.001.001.001.001.001.00Number30.981.000.920.991.000.900.971.000.860.981.000.88epochs E40.991.000.941.001.000.990.981.000.890.991.000.9450.971.000.901.001.000.970.961.000.850.981.000.909. nsCTBN generated data asynchronous involving different time granularities, thus nsDBN cannotdirectly applied. option preprocess datasets adapt nsDBNs. Givenwould strongly arbitrary penalizing nsDBNs, decided learn nsCTBN models.21fiVilla & StellaTable 6: nsCTBN UNE setting nsCTBN generated data. Average, min(subscript) max (superscript) performance values 10 networks c e .21.001.001.001.001.001.001.001.001.001.001.001.00AccP recRecF1Number30.991.000.921.001.001.000.991.000.860.991.000.92epochs E40.991.000.941.001.001.000.981.000.890.991.000.9450.971.000.901.001.000.980.951.000.810.971.000.89best worst values accuracy E = 5 reported Table 6 belongexperiments performed synthetic dataset number 3 number 9 respectively.results illustrated hereafter. Figure 2(a) shows graphs sequence true nsCTBNsynthetic datasets number 3, Figure 2(b) displays posterior distributionepochs (right), together distribution corresponding transition times(left)10 learned nsCTBN UNE case. Figure 3 shows informationdepicted Figure 2, synthetic dataset number 9. latter case,distribution epochs slightly favor correct number epochs.(a) True nsCTBN model.Distribution transition timesDistribution number epochs11TrueRetrieved0.8Posterior probabilityProbability transition0.80.60.40.200.60.40.205101520253035 40Time45505560657005Number epochs(b) Learned nsCTBN model results.Figure 2: nsCTBN generated dataset number 3: (a) true graphs sequence E=5 epochs(b) distribution transition times (left) posterior epochs (right) associatednsCTBN inferred UNE setting.10. Transition times whose distance less 0.1 aggregated.22fiLearning Continuous Time Bayesian Networks Non-stationary Domains(a) True nsCTBN model.Distribution transition timesDistribution number epochs11TrueRetrieved0.8Posterior probabilityProbability transition0.80.60.40.200.60.40.20510152025303540 45Time50556065707580045Number epochs(b) Learned nsCTBN model results.Figure 3: nsCTBN generated dataset number 9: (a) true graphs sequence E=5 epochs(b) distribution transition times (left) posterior epochs (right) associatednsCTBN inferred UNE setting.5.2 Real-world Datasetsdifficult find real-world datasets corresponding ground truth modelcompletely known and/or uniform consensus domain experts reached.Therefore, decided use following three well-known datasets: drosophila, saccharomyces cerevisiae songbird compare performance nsCTBNs nsDBNsstate-of-the-art algorithms, i.e. TSNI TVDBN. datasets publiclyavailable, clearly described rich detailed discussion likely ground truthmodels given specialized literature. Furthermore, macroeconomics dataset introduced analyzed. dataset consists 17 financial/economic variables collecteddifferent time granularity spanning 1st January 1986 31st March 2015.5.2.1 Drosophiladrosophila dataset includes mRNA expression levels 4,028 genes 67 successive time-points spanning four stages Drosophila melanogaster life cycle (Lebreet al., 2010): embryonic (31 time-points), larval (10 time-points) pupal stage (18time-points) first 30 days adulthood (8 time-points). comparative purposes(Dondelinger et al., 2013), analyzed reduced drosophila dataset consistinggene expression time-series 11 genes involved wing muscle development. GivennsCTBNs based discrete variables, binarized expression level 11 genesreduced drosophila dataset done literature (Zhao, Serpedin, & Dougherty,2006; Guo, Hanneke, Fu, & Xing, 2007; Robinson & Hartemink, 2010).23fiVilla & StellaFirstly, network inference task embryonic, larval, pupal adulthood morphogenic stages performed KTT setting (Robinson & Hartemink, 2010; Dondelinger et al., 2013). nsCTBN structural learning performed using followingparameter values c = {0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0} setting maximum number parents 4. nsCTBN learned different c values combined,arcs occurred 20 percent samples includedinferred non-stationary continuous time Bayesian network. techniques predictnon-stationary directed networks (Robinson & Hartemink, 2010), precision, recallF1 measure, computed respect networks inferred Zhao et al. (2006) Guo etal. (2007), reported Table 7 nsDBN, nsCTBN TVDBN (Dondelinger et al.,2013). networks associated four epochs, inferred nsCTBNreduced drosophila dataset KTT setting, depicted Figure 4.Table 7: Precision (Prec), recall (Rec) F1 measure (F1 ) achieved nsCTBN, nsDBN,TVDBN drosophila dataset computed respect networks inferredZhao et al. (2006) Guo et al. (2007). Average values (Average) precision, recallF1 measure achieved Zhao et al. (2006) Guo et al. (2007) also reported.nsDBNnsCTBNTVDBNZhaoPrec0.580.330.17et al. (2006)RecF10.38 0.460.37 0.350.27 0.21Guo et al. (2007)Prec RecF10.47 0.34 0.390.41 0.43 0.420.36 0.61 0.45Prec0.520.370.27AverageRecF10.36 0.420.40 0.390.44 0.33According Table 7, optimal algorithm exists reduced drosophila dataset.network retrieved Zhao et al. (2006) used ground truth, nsDBNbest model, network retrieved Guo et al. (2007) network used groundtruth, TVDBN optimal one far F1 measure concerned. averageperformance computed, nsDBN best model TVDBN worst;nsCTBN achieves F1 value close one achieved nsDBN.Secondly, investigated whether transition times inferred structural learningnsCTBN UNE setting correspond known transitions stages (Lebreet al., 2010; Dondelinger et al., 2013). network inference task performed learningnsCTBN UNE setting following parameter values c = {0.2, 0.4, 1, 2}e = {0.5, 1, 2, 5}. Furthermore, set maximum number parents 2,number iterations 1,000 number runs 100.Figure 5 shows distribution transition times11 (left) posteriornumber epochs (right). number epochs correctly detected 4 evenprobability close 0.1 associated 5 epochs. However, transition timescorrectly identified. embryonic stage correctly identified, larval stagecorrectly discovered start time-point 31, inferred end time-point 3811. stem represents posterior probability corresponding time-point starts new epoch.Therefore, stem time-point means epoch ends time-point 1, next epochstarts time-point t.24fiLearning Continuous Time Bayesian Networks Non-stationary Domainsinstead 40. nsCTBN identify pupal adulthood stages, identifiedtwo additional transition times (17 51). behavior observed nsDBNs,TVDBNs capable correctly identify pupal adulthood stages. However, TVDBN-0, TVDBN-Exp TVDBN-Bino inferred networks (Dondelinger et al.,2013) consist number epochs ranging 6 7.mhcmhcgflgflmlc1mlc1eveevemsp300msp300actnactnmyo61fmyo61fprmprmtwitwislssls(a) Embryonic (epoch 0 30).(b) Larval (epoch 31 41).mhcmhcgflgflmlc1mlc1eveevemsp300msp300actnactnmyo61fmyo61fprmprmtwitwislssls(c) Pupal (epoch 42 59).(d) Adulthood (epoch 60 66).Figure 4: Networks inferred nsCTBN KKT setting reduced drosophiladataset. arcs occurred 20 percent networks associateddifferent c values included inferred nsCTBN model.25fiVilla & StellaDistribution transition timesDistribution number epochs11Retrieved0.8Posterior probabilityProbability transition0.80.60.40.200.60.40.20 3 6 9 12 15 18 21 24 27 30 33 36 39 42 45 48 51 54 57 60 63 66Time045Number epochsFigure 5: Transition time graph (left) posterior probability histogram numberepochs E (right) associated nsCTBN model learned drosophila reduceddataset UNE setting c = 0.2 e = 2.5.2.2 Saccharomyces Cerevisiaesaccharomyces cerevisiae dataset obtained synthetic regulatory network5 genes saccharomyces cerevisiae (Cantone, Marucci, Iorio, Ricci, Belcastro, Bansal,Santini, di Bernardo, di Bernardo, & Cosma, 2009). obtained measuring geneexpression time-series RT-PCR (reverse transcription polymerase chain reaction)16 21 time-points two conditions related carbon source: galactose (switchexperimental condition) glucose (switch experimental condition). mergedtime-series two experimental conditions exclusion boundary pointdone literature (Dondelinger et al., 2013). obtained time-series binarizedway 1 indicates gene expression level greater equalsample mean, 0 indicates gene expression level smaller sample mean.obtained dataset used infer saccharomyces cerevisiae networks associatedswitch switch experimental conditions.network inference task performed learning nsCTBN UNE settingfollowing parameter values c = {0.2, 0.4, 1, 2} e = {0.2, 0.4, 1, 2}. Furthermore, set maximum number parents 4, number iterations 1,000number runs 100. arcs occurred 50 percent runsincluded inferred nsCTBN model. Precision, recall F1 measure values achievednsCTBN compared achieved state-of-the-art algorithms (i.e. TSNI,nsDBN TVDBN) Table 8.result performed numerical experiment shows nsCTBN competitive respect state-of-the-art algorithms, achieves non-optimal resultsprecision associated switch experimental condition. condition,5nsCTBN achieves precision equal 0.5 ( 10), optimal value achieved TSNI4TVDBN 0.8 ( 5 ). contrary, nsCTBN achieves best recall value,equal 0.63 ( 85 ). switch experimental condition, nsCTBN achieves bestvalue precision, equal 0.67 ( 69 ), recall, equal 0.75 ( 68 ).26fiLearning Continuous Time Bayesian Networks Non-stationary Domainsalso computed overall performance structural learning algorithms.case, focusing attention F1 measure, conclude nsCTBN (0.63)comparable TVDBN (0.60), considered state-of-the-art algorithmstructural learning task applied saccharomyces cerevisiae dataset. networksinferred nsCTBN model switch switch experimental conditions,using c = 0.2 c = 2, depicted Figure 6.Table 8: nsCTBN compared TSNI, nsDBN, TVDBN learning saccharomyces cerevisiae dataset. nsCTBN learned UNE setting (c = 0.2, e = 2);time-point 17 used transition time switch switch experimental conditions. TSNI, nsDBN TVDBN networks described specializedliterature. Precision, recall F1 measure reported switch switchexperimental conditions. number true positive arcs (superscript) sumtrue false positive arcs (subscript) reported precision, number truepositive arcs (superscript) sum true positive false negative arcs (subscript)reported recall. Performance values achieved aggregating inferred networkstwo epochs also reported.TSNInsDBNTVDBNnsCTBNSwitchP recRec0.8045 0.50480.3326 0.25280.8045 0.50480.50510 0.6358F10.620.290.620.56SwitchP rec RecF10.6035 0.3838 0.460.6035 0.3838 0.460.5659 0.6358 0.590.6769 0.7568 0.71GAL4F10.540.370.600.63GAL4GAL80CBF1SWI5AggregatedP recRec0.70710 0.447160.45511 0.315160.64914 0.569160.58110.69111916GAL80ASH1SWI5(a) Switch network.CBF1ASH1(b) Switch network.Figure 6: Switch (a) switch (b) networks inferred nsCTBN saccharomyces cerevisiae dataset UNE setting c = 0.2, e = 2. two picturesreport positive arcs (black continuous), false negative arcs (red dashed)false positive arcs (green dotted) inferred networks.27fiVilla & StellaFigure 7 shows posterior distribution number epochs (left) togetherdistribution transition times (right) nsCTBN learned c = 0.2 e = 2.transition switch switch experimental conditions knownoccur time-point 17 (i.e. switch epoch starts time-point 18). worthwhilenotice small number arcs, associated synthetic regulatory networksaccharomyces cerevisiae, suggests one careful evaluatingresult performed numerical experiment. particular, think overstatementseffectiveness and/or superiority different structural learning algorithmslearning task saccharomyces cerevisiae dataset avoided.Distribution transition timesDistribution number epochs11Retrieved0.8Posterior probabilityProbability transition0.80.60.40.200.60.40.20246810 12 14 16 18 20 22 24 26 28 30 32 34 36Time02Number epochsFigure 7: Transition time graph (left) posterior probability number epochs(right) associated nsCTBN inferred saccharomyces cerevisiae datasetUNE setting c = 0.2 e = 2. maximum aposteriori estimatenumber epochs associated E = 2 epochs: epoch 1 starts time-point 1ends time-point 17, epoch 2 starts time-point 18 ends time-point 36.5.2.3 Songbirdsongbird dataset collected eight electrodes placed vocal nuclei sixfemale zebra finches (Smith et al., 2006). Voltage changes recorded populationsneurons birds provided four different two-second auditory stimuli,presented 18 20 times. Voltages post-processed root mean squaretransformation binned 5 ms (Robinson & Hartemink, 2010).songbird dataset used learn neural information flow networks, i.e. networksrepresent transmission information different regions songbirdbrain. neural information flow network represents dynamic utilization potentialpathways along information travel. identification neural informationflow networks songbirds auditory stimuli allows understand soundsstored processed songbirds brain. songbird dataset consists data8 variables recorded electrodes two seconds pre-stimulus, two secondsstimulus two seconds post-stimulus six birds. stimuli hear-song, i.e.bird hears another bird singing, white-noise, i.e. bird hears white noise stimulus.28fiLearning Continuous Time Bayesian Networks Non-stationary Domainsshow results nsCTBN learned two six birds songbirddataset, namely bird 648 bird 841. results obtained four birdssimilar. Given nsCTBNs based discrete variables, values 8 variablesdiscretized three bins using uniform quantiles (0, 13 , 23 , 1) according literature(Robinson & Hartemink, 2010). inference task neural information flow networksperformed learning nsCTBN UNE setting following parametervalues c = {0.25, 0.5, 1, 2, 5, 10} e = {0.25, 0.5, 1, 2, 5, 10}. set maximumnumber parents 3, number iterations 500 number runs 10.Figure 8 (a) (b) show probability transition (left) posterior probabilitynumber epochs (right) bird 648 bird 841 white-noise stimulus.Figure 9 (a) (b) show probability transition (left) posterior probabilitynumber epochs (right) bird 648 bird 841 hear-song stimulus.Distribution transition timesDistribution number epochs0.51Retrieved0.8Posterior probabilityProbability transition0.40.30.20.100.60.40.200.511.522.53Time3.544.555.50634Number epochs(a) white-noise stimulus bird 648: learned model results.Distribution transition timesDistribution number epochs0.51Retrieved0.8Posterior probabilityProbability transition0.40.30.20.100.60.40.200.511.522.53Time3.544.555.56034Number epochs(b) white-noise stimulus bird 841: learned model results.Figure 8: Distribution transition times posterior distribution epochsnsCTBN UNE setting songbird dataset white-noise stimulus.29fiVilla & Stellalocation transition time-points white-noise stimulus hearsong stimulus accurately inferred bird 648 bird 841. posterior distributionnumber epochs birds 648 841 white-noise stimulus nearlyequally split 3 4 epochs, hear-song stimulus peaked 3epochs. Therefore, number epochs location transition time-pointsreliably recovered nsCTBN learned UNE setting. Unfortunately,able find additional information validate learned nsCTBNsdataset. Moreover, comparison across different birds eventually develop consensusnetwork possible due songbird data collection settings. Indeed, sixbirds characterized electrodes, make difficult obtain correspondencemap across different birds.Distribution transition timesDistribution number epochs0.51Retrieved0.8Posterior probabilityProbability transition0.40.30.20.100.60.40.200.511.522.53Time3.544.555.50634Number epochs(a) hear-song stimulus bird 648: learned model results.Distribution transition timesDistribution number epochs0.51Retrieved0.8Posterior probabilityProbability transition0.40.30.20.100.60.40.200.511.522.53Time3.544.555.56034Number epochs(b) hear-song stimulus bird 841: learned model results.Figure 9: Distribution transition times posterior distribution epochsnsCTBN UNE setting songbird dataset hear-song stimulus.30fiLearning Continuous Time Bayesian Networks Non-stationary Domains5.2.4 Macroeconomicsmacroeconomics dataset consists 17 financial/economic time-series pertainingeconomy United States. Time-series different time granularity span1st January 1986 31st March 2015. specifically, five time-series daily granularity, namely Crude oil (OIL), USD EUR spot exchange rate (USDEUR), Gold (GOLD),S&P500 equity index (S&P500) 10-years treasury bond yield rate (US10yrsNote).Eleven time-series monthly granularity, namely production total industry (PTI),real manufacturing trade industries sales (RMTIS), personal income (PI), unemployment (UN), consumer price index (CPI), federal funds rate (RATE), producer price index(PPI), non-farm payrolls (NFP), new one-family houses sold (NHSold), new houses sale(NHSale) new private house permits (NHPermit). Finally, gross domestic product(GDP) time-series quarterly granularity.goal study discover financial economic environment evolvestime. particular, focused attention detect business cycles12associated change relationships among financial economic variables. Givenduration business cycle highly variable, ability identify turning pointcycle (i.e. recession starts) considerable importance policymakers, financialcompanies well individuals. substantial literature available businesscycle turning points detection generally relying Markov-switching models (Hamilton &Raj, 2005). However, models able represent important featuresdependence structure among variables business cycle.order use nsCTBN model context, applied binary discretizationvariable associated time-series. Discretization performed using lookback period 1 year, i.e. current value greater past one, binaryvariable set 1 otherwise, set 0. approach looking back pastwidely used finance (Moskowitz, Ooi, & Pedersen, 2012). nsCTBNs learningperformed UNE setting using following parameter values: c = {0.5, 1, 2},e = {0.1, 1, 10}, 2 maximum parents per node, 300 iterations 10 runs.Figure 10 shows probability transition (left side, left axis) versus S&P500equity index used reference (left side, right axis) posterior probabilitynumber epochs (right side). nsCTBN consists three epochs transition timesclose end July 2000 end November 2007. compare datesturning points US business cycle reported National Bureau EconomicResearch13 , see far turning point March 2001close one December 2007, missed turning point occurredJuly 1990, probably limited length dataset.Figure 11 shows structure nsCTBN model corresponding probablenumber epochs, i.e. E = 3. arc included nsCTBN model occurs75% performed runs epoch. retrieved networks correspondfollowing time periods: January 1986 July 2000 (epoch 1), August 2000November 2007 (epoch 2) December 2007 March 2015 (epoch 3).12. Business cycles fluctuations aggregate economic activity, recurrent (i.e. possibleidentify expansion-recession cycles), persistent periodic (i.e. differ length severity).13. official business cycle turning points dates available http://www.nber.org/cycles.html31fiVilla & StellaDistribution transition times vs S&P500Distribution number epochs250010.820000.80.615000.410000.25001Posterior probabilityValueProbability transitionRetrieved (left)S&P500 (right)019851990199520002005Time20100.40.20202020150.602345Number epochsFigure 10: Distribution transition times S&P500 behavior time (left). Posterior probability epochs (right) learned nsCTBN UNE setting.USDEUROILGOLDUSDEUROILUNGOLDUS10YRSUS10YRSPPINHPerCPIPPINHPerPTISP500PTISP500PIRMTISNHSaleRATEPICPIRMTISRATENFPGDPNHSoldNFPGDPUNNHSale(a) Epoch 1 (Jan 1986 - Jul 2000).NHSold(b) Epoch 2 (Aug 2000 - Nov 2007).USDEUROILPPIUS10YRSGOLDNHSaleSP500PTICPIRATENHPerPIRMTISNFPUNGDPNHSold(c) Epoch 3 (Dec 2007 - Mar 2015).Figure 11: nsCTBN learned macroeconomics dataset UNE setting.nsCTBN corresponds probable number epochs (E = 3). arc includednsCTBN model occurs 75% runs epoch.32fiLearning Continuous Time Bayesian Networks Non-stationary Domainsnovelty approach economic analysis opens door many considerations new speculations economic variables business cycles.paper, highlight two patterns emerging learned nsCTBN model: wellknown relevant role personal income (PI) relation unemployment (UN)(Mankiw, 2014) less known relation non-farm payrolls (NFP) S&P500equity index (S&P500) (Miao, Ramchander, & Zumwalt, 2014).6. Conclusionsintroduced non-stationary continuous time Bayesian networks developed threestructural learning algorithms used different knowledge settings (i.e. KTT,KNE UNE) problem analyzed. structural learning algorithmknown transition times case exact exploits graph theory infer optimalnsCTBNs structure. polynomial time complexity assumptionmaximum number parents node fixed. nsCTBNs structural learning algorithms competitive state-of-the-art algorithms synthetic real-worlddatasets considered. statement proved rich set numerical experiments.nsCTBNs adapted use different score metrics, far considered scoremetrics integrates non-structural parameters. nsCTBNs exploit interestingproperty CTBNs offer possibility learn optimal nsCTBNs structuresingle variable. could extremely useful case non-stationarybehavior analyzed system synchronous, thus may casenode changes parents independently nodes change parents set.However, two main limitations exist nsCTBNs: i) variables assumeddiscrete; specifically variable dataset must take value countable numberstates ii) finding optimal value c e hyperparameters extremelydifficult (the true nsDBNs). Concerning i), problem discretizing continuousvariables studied long time robust solutions describedspecialized literature. Discretizing continuous variables whose value measured timestudied intensively many issues still remain. problem ii) selectingoptimal value hyperparameters known specialized literature muchdone experts provide valuable apriori knowledge. However, aprioriknowledge poor available all, selecting optimal hyperparameter valuesextremely difficult. important note one strong limitations studyingcomparing non-stationary models lack ground truth models.Possible directions research include application nsCTBNs structurallearning algorithms datasets, arabidopsis thaliana dataset (Grzegorczyk,Aderhold, & Husmeier, 2015) well financial datasets supported in-deptheconomic analyses. Another interesting perspective study developmentmodeling approach, going towards direction allowing node change parentsset asynchronously. Furthermore, think increase applicability real-worldtime-series data proposed nsCTBNs structural learning algorithms issue timeseries discretization must addressed. particular, think issue mustaddressed integrated manner nsCTBNs structural learning algorithm.33fiVilla & StellaFinally, could interesting apply framework nsCTBNs addresstask classification objects streaming context using probabilistic graphical model based approach (Borchani, Martinez, Masegosa, Langseth, Nielsen, Salmeron,Fernandez, Madsen, & Saez, 2015a; Borchani, Martnez, Masegosa, Langseth, Nielsen,Salmeron, Fernandez, Madsen, & Saez, 2015b).Acknowledgmentsauthors wish thank Alexander Hartemink kindly provided nsDBNjar executable associated datasets. special thank goes Marco Grzegorczykproviding arabidopsis thaliana dataset together fundamental information analyzeit. authors greatly indebted anonymous referees constructive commentsextremely helpful suggestions, contributed significantly improvequality paper. special thank goes Associate Editor Manfred Jaeger.Fabio Stella corresponding author article.ReferencesAcerbi, E., & Stella, F. (2014). Continuous time bayesian networks gene network reconstruction: comparative study time course data. 10th InternationalSymposium Bioinformatics Research Applications, Zhangjiajie, China, 2014,10.Acerbi, E., Vigano, E., Poidinger, M., Mortellaro, A., Zelante, T., & Stella, F. (2016).Continuous time bayesian networks identify prdm1 negative regulator th17 celldifferentiation humans. Scientific Reports, 6, 23128.Acerbi, E., Zelante, T., Narang, V., & Stella, F. (2014). Gene network inference usingcontinuous time bayesian networks: comparative study application th17 celldifferentiation. BMC Bioinformatics, 15 (1).Ahmed, A., & Xing, E. P. (2009). Recovering time-varying networks dependencies socialbiological studies. Proceedings National Academy Sciences, 106 (29),1187811883.Bertsimas, D., & Tsitsiklis, J. (1993). Simulated annealing. Statistical Science, 8 (1), 1015.Borchani, H., Martinez, A. M., Masegosa, A., Langseth, H., Nielsen, T. D., Salmeron, A.,Fernandez, A., Madsen, A. L., & Saez, R. (2015a). Dynamic Bayesian modelingrisk prediction credit operations. 13th Scandinavian Conference ArtificialIntelligence (SCAI 2015), Halmstad, Sweden.Borchani, H., Martnez, A. M., Masegosa, A. R., Langseth, H., Nielsen, T. D., Salmeron,A., Fernandez, A., Madsen, A. L., & Saez, R. (2015b). Modeling concept drift:probabilistic graphical model based approach. 14th International SymposiumIntelligent Data Analysis (IDA 2015), Saint-Etienne, France.Boudali, H., & Dugan, J. B. (2006). continuous-time bayesian network reliability modeling, analysis framework. IEEE Transactions Reliability, 55 (1), 8697.34fiLearning Continuous Time Bayesian Networks Non-stationary DomainsBurge, J., Lane, T., Link, H., Qiu, S., & Clark, V. P. (2009). Discrete dynamic bayesiannetwork analysis fmri data. Human brain mapping, 30 (1), 122137.Cantone, I., Marucci, L., Iorio, F., Ricci, M. A., Belcastro, V., Bansal, M., Santini, S.,di Bernardo, M., di Bernardo, D., & Cosma, M. P. (2009). yeast synthetic networkvivo assessment reverse-engineering modeling approaches. Cell, 137 (1),172 181.Dean, T., & Kanazawa, K. (1989). model reasoning persistence causation.Comput. Intell., 5 (3), 142150.Dondelinger, F., Lebre, S., & Husmeier, D. (2013). Non-homogeneous dynamic bayesiannetworks bayesian regularization inferring gene regulatory networksgradually time-varying structure. Machine Learning, 90 (2), 191230.Durante, D., & Dunson, D. B. (2014). Bayesian dynamic financial networks timevarying predictors. Statistics & Probability Letters, 93, 1926.Fan, Y., & Shelton, C. R. (2009). Learning continuous-time social network dynamics.25th Conference Uncertainty Artificial Intelligence (UAI 2009), Montreal,Canada.Friedman, N., & Koller, D. (2000). bayesian bayesian network structure:bayesian approach structure discovery bayesian networks. Machine Learning,50, 95125.Gatti, E., Luciani, D., & Stella, F. (2011). continuous time bayesian network modelcardiogenic heart failure. Flexible Services Manufacturing Journal, 24 (2),496515.Geiger, D., & Heckerman, D. (1997). characterization dirchlet distributionslocal global independence. Annals Statistics, 25, 13441368.Grzegorczyk, M., Aderhold, A., & Husmeier, D. (2015). Inferring bi-directional interactions circadian clock genes metabolism model ensembles. StatisticalApplications Genetics Molecular Biology, 14 (2), 143167.Guo, F., Hanneke, S., Fu, W., & Xing, E. P. (2007). Recovering temporally rewiring networks: model-based approach. Machine Learning, Proceedings 24th International Conference (ICML 2007), Corvallis, USA, June 20-24, 2007, pp. 321328.Hamilton, J. D., & Raj, B. (Eds.). (2005). Advances Markov-Switching Models: Applications Business Cycle Research Finance. Studies Empirical Economics.Springer-Verlag.Herbrich, R., Graepel, T., & Murphy, B. (2007). Structure failure. 2nd USENIXworkshop Tackling computer systems problems machine learning techniques(SYSML 07), Cambridge, USA, pp. 16.Kirkpatrick, S., Gelatt, C. D., & Vecchi, M. P. (1983). Optimization simulated annealing.Science, 220 (4598), 671680.Lebre, S., Becq, J., Devaux, F., Stumpf, M., & Lelandais, G. (2010). Statistical inferencetime-varying structure gene regulation networks. BMC Systems Biology, 4 (1),130+.35fiVilla & StellaLiu, M., Hommersom, A., van der Heijden, M., & Lucas, P. J. (2016). Hybrid time bayesiannetworks. International Journal Approximate Reasoning, .Mankiw, N. G. (2014). Principles Macroeconomics (7th edition). South-Western CollegePub.Marini, S., Trifoglio, E., Barbarini, N., Sambo, F., Camillo, B. D., Malovini, A., Manfrini,M., Cobelli, C., & Bellazzi, R. (2015). dynamic bayesian network model longterm simulation clinical complications type 1 diabetes. Journal BiomedicalInformatics, 57, 369 376.Miao, H., Ramchander, S., & Zumwalt, J. K. (2014). S&p 500 index-futures price jumpsmacroeconomic news. Journal Futures Markets, 34 (10), 9801001.Moskowitz, T. J., Ooi, Y. H., & Pedersen, L. H. (2012). Time series momentum. JournalFinancial Economics, 104 (2), 228250.Mumford, J. A., & Ramsey, J. D. (2014). Bayesian networks fmri: primer. Neuroimage,86, 573582.Murphy, K. P. (2012). Machine Learning: Probabilistic Perspective. MIT Press.Nodelman, U. (2007). Continuous Time Bayesian Networks. Ph.D. thesis, Stanford University.Nodelman, U., & Horvitz, E. (2003). Continuous time bayesian networks inferring userspresence activities extensions modeling evaluation. Tech. rep. MSRTR-2003-97, Microsoft Research.Nodelman, U., Shelton, C. R., & Koller, D. (2002). Continuous time bayesian networks.18th Conference Uncertainty Artificial Intelligence (UAI 2002), Edmonton,Canada, pp. 378387.Nodelman, U., Shelton, C., & Koller, D. (2003). Learning continuous time bayesian networks. 19th Conference Uncertainty Artificial Intelligence (UAI 2003),Acapulco, Mexico, pp. 451458.Pearl, J. (1989). Probabilistic reasoning intelligent systems - networks plausible inference. Morgan Kaufmann series representation reasoning. Morgan Kaufmann.Robinson, J. W., & Hartemink, A. J. (2010). Learning non-stationary dynamic bayesiannetworks. Journal Machine Learning Research, 11, 36473680.Scutari, M., & Denis, J.-B. (2014). Bayesian Networks Examples R. ChapmanHall, Boca Raton. ISBN 978-1482225587.Segal, E., Peer, D., Regev, A., Koller, D., & Friedman, N. (2005). Learning module networks. Journal Machine Learning Research, 6, 557588.Smith, A. V., Yu, J., Smulders, T. V., Hartemink, A. J., & Jarvis, E. D. (2006). Computational Inference Neural Information Flow Networks. PLoS Computational Biology,2 (11), e161+.Spiegelhalter, D. J., & Lauritzen, S. L. (1990). Sequential updating conditional probabilities directed graphical structures. Networks, 20 (5), 579605.36fiLearning Continuous Time Bayesian Networks Non-stationary DomainsSturlaugson, L., & Sheppard, J. W. (2014). Inference complexity continuous time bayesiannetworks. 30th Conference Uncertainty Artificial Intelligence (UAI2014), Quebec City, Canada, pp. 772779.Vinh, N. X., Chetty, M., Coppel, R., & Wangikar, P. P. (2012). Gene regulatory networkmodeling via global optimization high-order dynamic bayesian network. BMCBioinformatics, 13, 131.Xu, J., & Shelton, C. R. (2008). Continuous time bayesian networks host level networkintrusion detection. European Conference Machine Learning PrinciplesPractice Knowledge Discovery Databases (ECML PKDD 2008), Antwerp,Belgium, pp. 613627.Zhao, W., Serpedin, E., & Dougherty, E. R. (2006). Inferring gene regulatory networkstime series data using minimum description length principle. Bioinformatics,22 (17), 21292135.Zou, M., & Conzen, S. D. (2005). new dynamic bayesian network (dbn) approach identifying gene regulatory networks time course microarray data. Bioinformatics,21 (1), 7179.37fiJournal Artificial Intelligence Research 57 (2016) 345420Submitted 9/15; published 11/16Primer Neural Network ModelsNatural Language ProcessingYoav Goldbergyoav.goldberg@gmail.comComputer Science DepartmentBar-Ilan University, IsraelAbstractpast years, neural networks re-emerged powerful machine-learningmodels, yielding state-of-the-art results fields image recognition speechprocessing. recently, neural network models started applied also textualnatural language signals, promising results. tutorial surveys neuralnetwork models perspective natural language processing research, attemptbring natural-language researchers speed neural techniques. tutorialcovers input encoding natural language tasks, feed-forward networks, convolutionalnetworks, recurrent networks recursive networks, well computation graphabstraction automatic gradient computation.1. Introductiondecade, core NLP techniques dominated machine-learning approachesused linear models support vector machines logistic regression, trainedhigh dimensional yet sparse feature vectors.Recently, field seen success switching linear modelssparse inputs non-linear neural-network models dense inputs.neural network techniques easy apply, sometimes almost drop-in replacementsold linear classifiers, many cases strong barrier entry. tutorialattempt provide NLP practitioners (as well newcomers) basic background,jargon, tools methodology allow understand principles behindneural network models apply work. tutorial expectedself-contained, presenting different approaches unified notationframework. repeats lot material available elsewhere. also pointsexternal sources advanced topics appropriate.primer intended comprehensive resource godevelop next advances neural-network machinery (though may serve good entrypoint). Rather, aimed readers interested taking existing, usefultechnology applying useful creative ways favourite NLP problems.in-depth, general discussion neural networks, theory behind them, advancedoptimization methods advanced topics, reader referred existingresources. particular, book Bengio, Goodfellow, Courville (2015) highlyrecommended.c2016AI Access Foundation. rights reserved.fiGoldberg1.1 Scopefocus applications neural networks language processing tasks. However,subareas language processing neural networks deliberately leftscope tutorial. include vast literature language modeling acousticmodeling, use neural networks machine translation, multi-modal applicationscombining language signals images videos (e.g. caption generation).Caching methods efficient runtime performance, methods efficient training largeoutput vocabularies attention models also discussed. Word embeddingsdiscussed extent needed understand order use inputsmodels. unsupervised approaches, including autoencoders recursiveautoencoders, also fall scope. applications neural networks languagemodeling machine translation mentioned text, treatment meanscomprehensive.1.2 Note Terminologyword feature used refer concrete, linguistic input word, suffix,part-of-speech tag. example, first-order part-of-speech tagger, features mightcurrent word, previous word, next word, previous part speech. term inputvector used refer actual input fed neural-network classifier.Similarly, input vector entry refers specific value input. contrastlot neural networks literature word feature overloadedtwo uses, used primarily refer input-vector entry.1.3 Mathematical Notationuse bold upper case letters represent matrices (X, Y, Z), bold lower-case lettersrepresent vectors (b). series related matrices vectors (for example,matrix corresponds different layer network), superscript indicesused (W1 , W2 ). rare cases want indicate power matrixvector, pair brackets added around item exponentiated: (W)2 , (W3 )2 .Unless otherwise stated, vectors assumed row vectors. use [v1 ; v2 ] denotevector concatenation.choice use row vectors, right multiplied matrices (xW + b)somewhat non standard lot neural networks literature use column vectorsleft multiplied matrices (Wx + b). trust reader able adaptcolumn vectors notation reading literature.11. choice use row vectors notation inspired following benefits: matches wayinput vectors network diagrams often drawn literature; makes hierarchical/layeredstructure network transparent puts input left-most variable rathernested; results fully-connected layer dimensions din dout rather dout din ; mapsbetter way networks implemented code using matrix libraries numpy.346fiA Primer Neural Networks NLP2. Neural Network ArchitecturesNeural networks powerful learning models. discuss two kinds neural networkarchitectures, mixed matched feed-forward networks recurrent /recursive networks. Feed-forward networks include networks fully connected layers,multi-layer perceptron, well networks convolutional poolinglayers. networks act classifiers, different strengths.Fully connected feed-forward neural networks (Section 4) non-linear learnerscan, part, used drop-in replacement wherever linear learner used.includes binary multiclass classification problems, well complex structured prediction problems (Section 8). non-linearity network, wellability easily integrate pre-trained word embeddings, often lead superior classification accuracy. series works2 managed obtain improved syntactic parsing resultssimply replacing linear model parser fully connected feed-forward network. Straight-forward applications feed-forward network classifier replacement(usually coupled use pre-trained word vectors) provide benefits also CCGsupertagging,3 dialog state tracking,4 pre-ordering statistical machine translation5language modeling.6 Iyyer, Manjunatha, Boyd-Graber, Daume III (2015) demonstratemulti-layer feed-forward networks provide competitive results sentiment classification factoid question answering.Networks convolutional pooling layers (Section 9) useful classificationtasks expect find strong local clues regarding class membership,clues appear different places input. example, document classificationtask, single key phrase (or ngram) help determining topic document(Johnson & Zhang, 2015). would like learn certain sequences words goodindicators topic, necessarily care appear document.Convolutional pooling layers allow model learn find local indicators,regardless position. Convolutional pooling architecture show promising resultsmany tasks, including document classification,7 short-text categorization,8 sentimentclassification,9 relation type classification entities,10 event detection,11 paraphraseidentification,12 semantic role labeling,13 question answering,14 predicting box-office rev-2. Chen Manning (2014), Weiss, Alberti, Collins, Petrov (2015) Pei, Ge, Chang (2015)Durrett Klein (2015)3. Lewis Steedman (2014)4. Henderson, Thomson, Young (2013)5. de Gispert, Iglesias, Byrne (2015)6. Bengio, Ducharme, Vincent, Janvin (2003) Vaswani, Zhao, Fossum, Chiang (2013)7. Johnson Zhang (2015)8. Wang, Xu, Xu, Liu, Zhang, Wang, Hao (2015a)9. Kalchbrenner, Grefenstette, Blunsom (2014) Kim (2014)10. Zeng, Liu, Lai, Zhou, Zhao (2014), dos Santos, Xiang, Zhou (2015)11. Chen, Xu, Liu, Zeng, Zhao (2015), Nguyen Grishman (2015)12. Yin Schutze (2015)13. Collobert, Weston, Bottou, Karlen, Kavukcuoglu, Kuksa (2011)14. Dong, Wei, Zhou, Xu (2015)347fiGoldbergenues movies based critic reviews,15 modeling text interestingness,16 modelingrelation character-sequences part-of-speech tags.17natural language often work structured data arbitrary sizes,sequences trees. would like able capture regularities structures,model similarities structures. many cases, means encodingstructure fixed width vector, pass another statisticallearner processing. convolutional pooling architectures allow usencode arbitrary large items fixed size vectors capturing salient features,sacrificing structural information. Recurrent (Section 10)recursive (Section 12) architectures, hand, allow us work sequencestrees preserving lot structural information. Recurrent networks (Elman,1990) designed model sequences, recursive networks (Goller & Kuchler, 1996)generalizations recurrent networks handle trees. also discussextension recurrent networks allow model stacks (Dyer, Ballesteros, Ling,Matthews, & Smith, 2015; Watanabe & Sumita, 2015).Recurrent models shown produce strong results language modeling,18 ; well sequence tagging,19 machine translation,20 dependency parsing,21sentiment analysis,22 noisy text normalization,23 dialog state tracking,24 response generation,25 modeling relation character sequences part-of-speech tags.26Recursive models shown produce state-of-the-art near state-of-the-art resultsconstituency27 dependency28 parse re-ranking, discourse parsing,29 semantic relationclassification,30 political ideology detection based parse trees,31 sentiment classification,32target-dependent sentiment classification33 question answering.3415.16.17.18.19.20.21.22.23.24.25.26.27.28.29.30.31.32.33.34.Bitvai Cohn (2015)Gao, Pantel, Gamon, He, Deng (2014)dos Santos Zadrozny (2014)notable works Mikolov, Karafiat, Burget, Cernocky, Khudanpur (2010), Mikolov,Kombrink, Lukas Burget, Cernocky, Khudanpur (2011), Mikolov (2012), Duh, Neubig, Sudoh,Tsukada (2013), Adel, Vu, Schultz (2013), Auli, Galley, Quirk, Zweig (2013) Auli Gao(2014)Irsoy Cardie (2014), Xu, Auli, Clark (2015), Ling, Dyer, Black, Trancoso, Fermandez, Amir,Marujo, Luis (2015b)Sundermeyer, Alkhouli, Wuebker, Ney (2014), Tamura, Watanabe, Sumita (2014), Sutskever,Vinyals, Le (2014) Cho, van Merrienboer, Gulcehre, Bahdanau, Bougares, Schwenk, Bengio(2014b)Dyer et al. (2015), Watanabe Sumita (2015)Wang, Liu, Sun, Wang, Wang (2015b)Chrupala (2014)Mrksic, Seaghdha, Thomson, Gasic, Su, Vandyke, Wen, Young (2015)Sordoni, Galley, Auli, Brockett, Ji, Mitchell, Nie, Gao, Dolan (2015)Ling et al. (2015b)Socher, Bauer, Manning, Ng (2013)Le Zuidema (2014), Zhu, Qiu, Chen, Huang (2015a)Li, Li, Hovy (2014)Hashimoto, Miwa, Tsuruoka, Chikayama (2013), Liu, Wei, Li, Ji, Zhou, Wang (2015)Iyyer, Enns, Boyd-Graber, Resnik (2014b)Socher, Perelygin, Wu, Chuang, Manning, Ng, Potts (2013), Hermann Blunsom (2013)Dong, Wei, Tan, Tang, Zhou, Xu (2014)Iyyer, Boyd-Graber, Claudino, Socher, Daume III (2014a)348fiA Primer Neural Networks NLP3. Feature Representationdiscussing network structure depth, important pay attentionfeatures represented. now, think feed-forward neural networkfunction NN(x) takes input din dimensional vector x produces doutdimensional output vector. function often used classifier, assigning input xdegree membership one dout classes. function complex,almost always non-linear. Common structures function discussed Section 4.Here, focus input, x. dealing natural language, input x encodesfeatures words, part-of-speech tags linguistic information. Perhapsbiggest conceptual jump moving sparse-input linear models neural-networkbased models stop representing feature unique dimension (the calledone-hot representation) representing instead dense vectors. is, corefeature embedded dimensional space, represented vector space.35embeddings (the vector representation core feature) trained likeparameter function NN. Figure 1 shows two approaches featurerepresentation.feature embeddings (the values vector entries feature) treatedmodel parameters need trained together componentsnetwork. Methods training (or obtaining) feature embeddings discussed later.now, consider feature embeddings given.general structure NLP classification system based feed-forward neuralnetwork thus:1. Extract set core linguistic features f1 , . . . , fk relevant predictingoutput class.2. feature fi interest, retrieve corresponding vector v(fi ).3. Combine vectors (either concatenation, summation combination both)input vector x.4. Feed x non-linear classifier (feed-forward neural network).biggest change input, then, move sparse representationsfeature dimension, dense representation feature mappedvector. Another difference extract core features feature combinations. elaborate changes briefly.3.1 Dense Vectors vs. One-Hot Representationsbenefits representing features vectors instead unique IDs?always represent features dense vectors? Lets consider two kindsrepresentations:35. Different feature types may embedded different spaces. example, one may represent wordfeatures using 100 dimensions, part-of-speech features using 20 dimensions.349fiGoldbergFigure 1: Sparse vs. dense feature representations. Two encodings information: current word dog; previous word the; previous pos-tag DET.(a) Sparse feature vector. dimension represents feature. Feature combinations receive dimensions. Feature values binary. Dimensionalityhigh. (b) Dense, embeddings-based feature vector. core featurerepresented vector. feature corresponds several input vector entries. explicit encoding feature combinations. Dimensionality low.feature-to-vector mappings come embedding table.350fiA Primer Neural Networks NLPOne Hot feature dimension.Dimensionality one-hot vector number distinct features.Features completely independent one another. feature worddog dis-similar word thinking word cat .Dense feature d-dimensional vector.Dimensionality vector d.Model training cause similar features similar vectors informationshared similar features.One benefit using dense low-dimensional vectors computational: majorityneural network toolkits play well high-dimensional, sparse vectors.However, technical obstacle, resolved engineeringeffort.main benefit dense representations generalization power: believefeatures may provide similar clues, worthwhile provide representationable capture similarities. example, assume observed word dogmany times training, observed word cat handful times,all. words associated dimension, occurrences dogtell us anything occurrences cat. However, dense vectors representationlearned vector dog may similar learned vector cat, allowingmodel share statistical strength two events. argument assumesgood vectors somehow given us. Section 5 describes ways obtaining vectorrepresentations.cases relatively distinct features category, believecorrelations different features, may use one-hot representation. However, believe going correlations different featuresgroup (for example, part-of-speech tags, may believe different verbinflections VB VBZ may behave similarly far task concerned) mayworthwhile let network figure correlations gain statistical strengthsharing parameters. may case circumstances,feature space relatively small training data plentiful, wishshare statistical information distinct words, gains made usingone-hot representations. However, still open research question,strong evidence either side. majority work (pioneered Collobert & Weston,2008; Collobert et al. 2011; Chen & Manning, 2014) advocate use dense, trainableembedding vectors features. work using neural network architecture sparsevector encodings see work Johnson Zhang (2015).Finally, important note representing features dense vectors integralpart neural network framework, consequentially differencesusing sparse dense feature representations subtler may appear first.fact, using sparse, one-hot vectors input training neural network amountsdedicating first layer network learning dense embedding vectorfeature based training data. touch Section 4.6.351fiGoldberg3.2 Variable Number Features: Continuous Bag WordsFeed-forward networks assume fixed dimensional input. easily accommodatecase feature-extraction function extracts fixed number features: featurerepresented vector, vectors concatenated. way, regionresulting input vector corresponds different feature. However, cases numberfeatures known advance (for example, document classification commonword sentence feature). thus need represent unboundednumber features using fixed size vector. One way achieving socalled continuous bag words (CBOW) representation (Mikolov, Chen, Corrado, & Dean,2013). CBOW similar traditional bag-of-words representationdiscard order information, works either summing averaging embeddingvectors corresponding features:36CBOW(f1 , ..., fk ) =k1Xv(fi )k(1)i=1simple variation CBOW representation weighted CBOW, differentvectors receive different weights:1WCBOW(f1 , ..., fk ) = Pki=1 aikXai v(fi )(2)i=1Here, feature fi associated weight ai , indicating relative importancefeature. example, document classification task, feature fi may correspondword document, associated weight ai could words TF-IDF score.3.3 Distance Position Featureslinear distance two words sentence may serve informative feature.example, event extraction task37 may given trigger word candidateargument word, asked predict argument word indeed argumenttrigger. distance (or relative position) trigger argument strongsignal prediction task. traditional NLP setup, distances usually encodedbinning distances several groups (i.e. 1, 2, 3, 4, 510, 10+) associatingbin one-hot vector. neural architecture, input vector composedbinary indicator features, may seem natural allocate single input entrydistance feature, numeric value entry distance. However,approach taken practice. Instead, distance features encoded similarly36. Note v(fi )s one-hot vectors rather dense feature representations, CBOW (eq1) WCBOW (eq 2) would reduce traditional (weighted) bag-of-words representations,turn equivalent sparse feature-vector representation binary indicator featurecorresponds unique word.37. event extraction task involves identification events predefined set event types.example identification purchase events terror-attack events. event type triggeredvarious triggering words (commonly verbs), several slots (arguments) needs filled(i.e. purchased? purchased? amount?).352fiA Primer Neural Networks NLPfeature types: bin associated d-dimensional vector, distanceembedding vectors trained regular parameters network (Zeng et al., 2014;dos Santos et al., 2015; Zhu et al., 2015a; Nguyen & Grishman, 2015).3.4 Feature CombinationsNote feature extraction stage neural-network settings deals extraction core features. contrast traditional linear-model-based NLP systemsfeature designer manually specify core features interestalso interactions (e.g., introducing feature stating wordX feature stating tag also combined feature stating word X tagsometimes even word X, tag previous word Z). combinationfeatures crucial linear models introduce dimensions input,transforming space data-points closer linearly separable.hand, space possible combinations large, feature designerspend lot time coming effective set feature combinations. Onepromises non-linear neural network models one needs definecore features. non-linearity classifier, defined network structure,expected take care finding indicative feature combinations, alleviating needfeature combination engineering.Kernel methods (Shawe-Taylor & Cristianini, 2004), particular polynomial kernels(Kudo & Matsumoto, 2003), also allow feature designer specify core features,leaving feature combination aspect learning algorithm. contrast neuralnetwork models, kernels methods convex, admitting exact solutions optimizationproblem. However, computational complexity classification kernel methods scaleslinearly size training data, making slow practical purposes,suitable training large datasets. hand, computationalcomplexity classification using neural networks scales linearly size network,regardless training data size.3.5 Dimensionalitymany dimensions allocate feature? Unfortunately, theoretical bounds even established best-practices space. Clearly, dimensionalitygrow number members class (you probably want assigndimensions word embeddings part-of-speech embeddings) muchenough? current research, dimensionality word-embedding vectors range50 hundreds, and, extreme cases, thousands. Since dimensionality vectors direct effect memory requirements processing time, goodrule thumb would experiment different sizes, choose good trade-offspeed task accuracy.3.6 Vector SharingConsider case features share vocabulary. example,assigning part-of-speech given word, may set features considering353fiGoldbergprevious word, set features considering next word. building inputclassifier, concatenate vector representation previous wordvector representation next word. classifier able distinguish twodifferent indicators, treat differently. two features sharevectors? vector dog:previous-word vector dog:nextword? assign two distinct vectors? This, again, mostly empiricalquestion. believe words behave differently appear different positions(e.g., word X behaves like word previous position, X behaves like Znext position) may good idea use two different vocabularies assigndifferent set vectors feature type. However, believe words behavesimilarly locations, something may gained using shared vocabularyfeature types.3.7 Networks Outputmulti-class classification problems k classes, networks output k-dimensionalvector every dimension represents strength particular output class.is, output remains traditional linear models scalar scores items discreteset. However, see Section 4, k matrix associated outputlayer. columns matrix thought dimensional embeddingsoutput classes. vector similarities vector representations k classesindicate models learned similarities output classes.3.8 Historical NoteRepresenting words dense vectors input neural network popularized Bengioet al. (2003) context neural language modeling. introduced NLP taskspioneering work Collobert, Weston colleagues (2008, 2011).38 Using embeddingsrepresenting words arbitrary features popularized following ChenManning (2014).4. Feed-Forward Neural Networkssection introduces feed-forward neural networks. starts popular braininspired metaphor triggered them, quickly switches back using mathematicalnotation. discuss structure feed forward neural networks, representationpower, common non-linearities loss functions.4.1 Brain-Inspired Metaphorname suggests, neural-networks inspired brains computation mechanism,consists computation units called neurons. metaphor, neuron computational unit scalar inputs outputs. input associated weight.38. work Bengio, Collobert, Weston colleagues popularized approaches,first use them. Earlier authors use dense continuous-space vectors representing word inputsneural networks include Lee et al. (1992) Forcada Neco (1997). Similarly, continuous-spacelanguage models used machine-translation already Schwenk et al. (2006).354fiA Primer Neural Networks NLPneuron multiplies input weight, sums39 them, applies non-linearfunction result, passes output. neurons connected other,forming network: output neuron may feed inputs one neurons.networks shown capable computational devices. weights setcorrectly, neural network enough neurons non-linear activation functionapproximate wide range mathematical functions (we preciselater).OutputlayerHiddenlayerHiddenlayerInput layerRRy1y2y3RRRRRRRRx1x2x3x4RFigure 2: Feed-forward neural network two hidden layers.typical feed-forward neural network may drawn Figure 2. circleneuron, incoming arrows neurons inputs outgoing arrows neurons outputs. arrow carries weight, reflecting importance (not shown). Neuronsarranged layers, reflecting flow information. bottom layer incomingarrows, input network. top-most layer outgoing arrows,output network. layers considered hidden. sigmoid shapeinside neurons middle layers represent non-linear function (i.e., logisticfunction 1/(1 + exa )) applied neurons value passing output.figure, neuron connected neurons next layer calledfully-connected layer affine layer.brain metaphor sexy intriguing, also distracting cumbersomemanipulate mathematically. therefore switch using concise mathematicalnotation. values row neurons network thought vector.Figure 2 input layer 4 dimensional vector (x), layer 6 dimensional vector (h1 ). fully connected layer thought linear transformation39. summing common operation, functions, max, also possible355fiGoldberg4 dimensions 6 dimensions. fully-connected layer implements vector-matrixmultiplication, h = xW weight connection ith neuroninput row jth neuron output row Wij .40 values h transformed non-linear function g applied value passednext input. whole computation input output written as: (g(xW1 ))W2W1 weights first layer W2 weights second one.4.2 Mathematical Notationpoint on, abandon brain metaphor describe networks exclusivelyterms vector-matrix operations.simplest neural network perceptron, linear function inputs:NNPerceptron (x) = xW + b(3)x Rdin , W Rdin dout , b RdoutW weight matrix, b bias term.41 order go beyond linear functions,introduce non-linear hidden layer (the network Figure 2 two layers), resultingMulti Layer Perceptron one hidden-layer (MLP1). feed-forward neural networkone hidden-layer form:NNMLP1 (x) = g(xW1 + b1 )W2 + b2(4)x Rdin , W1 Rdin d1 , b1 Rd1 , W2 Rd1 d2 , b2 Rd2W1 b1 matrix bias term first linear transformationinput, g non-linear function applied element-wise (also called non-linearityactivation function), W2 b2 matrix bias term second lineartransform.Breaking down, xW1 +b1 linear transformation input x din dimensionsd1 dimensions. g applied d1 dimensions, matrix W2 togetherbias vector b2 used transform result d2 dimensional outputvector. non-linear activation function g crucial role networks abilityrepresent complex functions. Without non-linearity g, neural networkrepresent linear transformations input.42add additional linear-transformations non-linearities, resulting MLPtwo hidden-layers (the network Figure 2 form):NNMLP2 (x) = (g 2 (g 1 (xW1 + b1 )W2 + b2 ))W3(5)perhaps clearer write deeper networks like using intermediary variables:40. see Pcase, denote weight ith input jth neuron h wij . valuehj hj = 4i=1 xi wij .41. network figure 2 include bias terms. bias term added layer addingadditional neuron incoming connections, whose value always 1.42. see why, consider sequence linear transformations still linear transformation.356fiA Primer Neural Networks NLPNNMLP2 (x) =yh1 =g 1 (xW1 + b1 )h2 =g 2 (h1 W2 + b2 )(6)=h2 W3vector resulting linear transform referred layer. outer-mostlinear transform results output layer linear transforms result hiddenlayers. hidden layer followed non-linear activation. cases,last layer example, bias vectors forced 0 (dropped).Layers resulting linear transformations often referred fully connected,affine. types architectures exist. particular, image recognition problems benefitconvolutional pooling layers. layers uses also language processing,discussed Section 9. Networks several hidden layers said deepnetworks, hence name deep learning.describing neural network, one specify dimensions layersinput. layer expect din dimensional vector input, transformdout dimensional vector. dimensionality layer taken dimensionalityoutput. fully connected layer l(x) = xW + b input dimensionality dinoutput dimensionality dout , dimensions x 1 din , W din dout b1 dout .output network dout dimensional vector. case dout = 1, networksoutput scalar. networks used regression (or scoring) consideringvalue output, binary classification consulting sign output.Networks dout = k > 1 used k-class classification, associatingdimension class, looking dimension maximal value. Similarly,output vector entries positive sum one, output interpreteddistribution class assignments (such output normalization typically achievedapplying softmax transformation output layer, see Section 4.5).matrices bias terms define linear transformations parameters network. common refer collection parameters . Togetherinput, parameters determine networks output. training algorithmresponsible setting values networks predictions correct. Trainingdiscussed Section 6.4.3 Representation Powerterms representation power, shown Hornik, Stinchcombe, White (1989)Cybenko (1989) MLP1 universal approximator approximatedesired non-zero amount error family functions43 include continuousfunctions closed bounded subset Rn , function mapping finite43. Specifically, feed-forward network linear output layer least one hidden layer squashing activation function approximate Borel measurable function one finite dimensional spaceanother.357fiGoldbergdimensional discrete space another. may suggest reason go beyondMLP1 complex architectures. However, theoretical result discusslearnability neural network (it states representation exists, sayeasy hard set parameters based training data specific learningalgorithm). also guarantee training algorithm find correct functiongenerating training data. Finally, state large hidden layerbe. Indeed, Telgarsky (2016) show exist neural networks many layersbounded size cannot approximated networks fewer layers unless layersexponentially large.practice, train neural networks relatively small amounts data using localsearch methods variants stochastic gradient descent, use hidden layersrelatively modest sizes (up several thousands). universal approximation theoremgive guarantees non-ideal, real-world conditions, definitelybenefit trying complex architectures MLP1. many cases,however, MLP1 indeed provide strong results. discussion representation power feed-forward neural networks, see book Bengio et al. (2015, Section6.5).4.4 Common Non-linearitiesnon-linearity g take many forms. currently good theorynon-linearity apply conditions, choosing correct non-linearitygiven task part empirical question. go common nonlinearities literature: sigmoid, tanh, hard tanh rectified linear unit(ReLU). NLP researchers also experimented forms non-linearitiescube tanh-cube.4.4.1 Sigmoidsigmoid activation function (x) = 1/(1 + ex ), also called logistic function,S-shaped function, transforming value x range [0, 1]. sigmoidcanonical non-linearity neural networks since inception, currently considereddeprecated use internal layers neural networks, choices listedprove work much better empirically.4.4.2 Hyperbolic Tangent (tanh)2xhyperbolic tangent tanh(x) = ee2x 1activation function S-shaped function, trans+1forming values x range [1, 1].358fiA Primer Neural Networks NLP4.4.3 Hard tanhhard-tanh activation function approximation tanh function fastercompute take derivatives of:1 x < 1hardtanh(x) = 1(7)x>1xotherwise4.4.4 Rectifier (ReLU)Rectifier activation function (Glorot, Bordes, & Bengio, 2011), also knownrectified linear unit simple activation function easy workshown many times produce excellent results.44 ReLU unit clips value x < 00. Despite simplicity, performs well many tasks, especially combineddropout regularization technique (see Section 6.4).(0ReLU(x) = max(0, x) =xx<0otherwise(8)rule thumb, ReLU units work better tanh, tanh works bettersigmoid.454.5 Output Transformationsmany cases, output layer vector also transformed. common transformationsoftmax :x =x1 , . . . , xke xisoftmax(xi ) = Pkxjj=1 e(9)44. technical advantages ReLU sigmoid tanh activation functionsinvolve expensive-to-compute functions, importantly saturate. sigmoidtanh activation capped 1, gradients region functions near zero,driving entire gradient near zero. ReLU activation problem, makingespecially suitable networks multiple layers, susceptible vanishing gradientsproblem trained saturating units.45. addition activation functions, recent works NLP community experimentreported success forms non-linearities. Cube activation function, g(x) = (x)3 ,suggested Chen Manning (2014), found effective non-linearitiesfeed-forward network used predict actions greedy transition-based dependencyparser. tanh cube activation function g(x) = tanh((x)3 + x) proposed Pei et al. (2015),found effective non-linearities feed-forward network usedcomponent structured-prediction graph-based dependency parser.cube tanh-cube activation functions motivated desire better capture interactions different features. activation functions reported improve performancecertain situations, general applicability still determined.359fiGoldbergresult vector non-negative real numbers sum one, making discreteprobability distribution k possible outcomes.softmax output transformation used interested modeling probability distribution possible output classes. effective, usedconjunction probabilistic training objective cross-entropy (see Section 4.7.4below).softmax transformation applied output network without hiddenlayer, result well known multinomial logistic regression model, also knownmaximum-entropy classifier.4.6 Embedding Layersnow, discussion ignored source x, treating arbitrary vector.NLP application, x usually composed various embeddings vectors.explicit source x, include networks definition. introduce c(),function core features input vector.common c extract embedding vector associated feature,concatenate them:x = c(f1 , f2 , f3 ) =[v(f1 ); v(f2 ); v(f3 )]NNMLP1 (x) =NNMLP1 (c(f1 , f2 , f3 ))=NNMLP1 ([v(f1 ); v(f2 ); v(f3 )])(10)=(g([v(f1 ); v(f2 ); v(f3 )]W1 + b1 ))W2 + b2Another common choice c sum embedding vectors (this assumes embedding vectors share dimensionality):x = c(f1 , f2 , f3 ) =v(f1 ) + v(f2 ) + v(f3 )NNMLP1 (x) =NNMLP1 (c(f1 , f2 , f3 ))=NNMLP1 (v(f1 ) + v(f2 ) + v(f3 ))(11)=(g((v(f1 ) + v(f2 ) + v(f3 ))W1 + b1 ))W2 + b2form c essential part networks design. many papers, commonrefer c part network, likewise treat word embeddings v(fi ) resultingembedding layer lookup layer. Consider vocabulary |V | words,embedded dimensional vector. collection vectors thought|V | embedding matrix E row corresponds embedded feature. Letfi |V |-dimensional vector, zeros except one index, correspondingvalue ith feature, value 1 (this called one-hot vector).multiplication fi E select corresponding row E. Thus, v(fi ) definedterms E fi :v(fi ) = fi E360(12)fiA Primer Neural Networks NLPsimilarly:CBOW(f1 , ..., fk ) =kX(fi E) = (i=1kXfi )E(13)i=1input network considered collection one-hot vectors.elegant well defined mathematically, efficient implementation typically involveshash-based data structure mapping features corresponding embedding vectors,without going one-hot representation.tutorial, take c separate network architecture: networksinputs always dense real-valued input vectors, c applied input passednetwork, similar feature function familiar linear-models terminology. However, training network, input vector x remember constructed,propagate error gradients back component embedding vectors, appropriate(error propagation discussed section 6).4.6.1 Note Notationdescribing network layers get concatenated vectors x, z input,authors use explicit concatenation ([x; y; z]W +b) others use affine transformation(xU + yV + zW + b). weight matrices U, V, W affine transformationdifferent one another, two notations equivalent.4.6.2 Note Sparse vs. Dense FeaturesConsider network uses traditional sparse representation input vectors,embedding layer. Assuming set available features V kfeatures f1 , . . . , fk , fi V , networks input is:x=kX|V |x N+fii=1(14)first layer (ignoring non-linear activation) is:kXxW + b = (fi )W(15)i=1W R|V |d , b Rdlayer selects rows W corresponding input features x sums them,adding bias term. similar embedding layer produces CBOWrepresentation features, matrix W acts embedding matrix.main difference introduction bias vector b, fact embeddinglayer typically undergo non-linear activation rather passed directlyfirst layer. Another difference scenario forces feature receive separatevector (row W) embedding layer provides flexibility, allowing examplefeatures next word dog previous word dog share vector.361fiGoldbergHowever, differences small subtle. comes multi-layer feed-forwardnetworks, difference dense sparse inputs smaller may seemfirst sight.4.7 Loss Functionstraining neural network (more training Section 6 below), much liketraining linear classifier, one defines loss function L(y, y), stating loss predictingtrue output y. training objective minimize loss acrossdifferent training examples. loss L(y, y) assigns numerical score (a scalar)networks output given true expected output y.46 loss functionbounded below, minimum attained cases networks outputcorrect.parameters network (the matrices Wi , biases bi commonly embeddings E) set order minimize loss L training examples (usually,sum losses different training examples minimized).loss arbitrary function mapping two vectors scalar. practicalpurposes optimization, restrict functions easily computegradients (or sub-gradients). cases, sufficient advisable rely commonloss function rather defining own. detailed discussion loss functionsneural networks see work LeCun, Chopra, Hadsell, Ranzato, Huang (2006), LeCunHuang (2005) Bengio et al. (2015). discuss loss functionscommonly used neural networks NLP.4.7.1 Hinge (binary)binary classification problems, networks output single scalar intendedoutput {+1, 1}. classification rule sign(y), classification consideredcorrect > 0, meaning share sign. hinge loss, also knownmargin loss SVM loss, defined as:Lhinge(binary) (y, y) = max(0, 1 y)(16)loss 0 share sign |y| 1. Otherwise, loss linear.words, binary hinge loss attempts achieve correct classification,margin least 1.4.7.2 Hinge (multiclass)hinge loss extended multiclass setting Crammer Singer (2002). Let= y1 , . . . , yn networks output vector, one-hot vector correctoutput class.classification rule defined selecting class highest score:prediction = arg max yi(17)46. notation, models output expected output vectors, many casesnatural think expected output scalar (class assignment). cases, simplycorresponding one-hot vector.362fiA Primer Neural Networks NLPDenote = arg maxi yi correct class, k = arg maxi6=t yi highest scoringclass k 6= t. multiclass hinge loss defined as:Lhinge(multiclass) (y, y) = max(0, 1 (yt yk ))(18)multiclass hinge loss attempts score correct class classesmargin least 1.binary multiclass hinge losses intended used linear outputlayer. hinge losses useful whenever require hard decision rule,attempt model class membership probability.4.7.3 Log Losslog loss common variation hinge loss, seen soft versionhinge loss infinite margin (LeCun et al., 2006).Llog (y, y) = log(1 + exp((yt yk ))(19)4.7.4 Categorical Cross-Entropy Losscategorical cross-entropy loss (also referred negative log likelihood ) usedprobabilistic interpretation scores desired.Let = y1 , . . . , yn vector representing true multinomial distributionlabels 1, . . . , n, let = y1 , . . . , yn networks output, transformedsoftmax activation function, represent class membership conditional distributionyi = P (y = i|x). categorical cross entropy loss measures dissimilaritytrue label distribution predicted label distribution y, defined crossentropy:Lcross-entropy (y, y) =Xyi log(yi )(20)hard classification problems training example single correctclass assignment, one-hot vector representing true class. cases, crossentropy simplified to:Lcross-entropy(hard classification) (y, y) = log(yt )(21)correct class assignment. attempts set probability mass assignedcorrect class 1. scores transformed using softmaxfunction represent conditional distribution, increasing mass assigned correctclass means decreasing mass assigned classes.cross-entropy loss common neural networks literature, producesmulti-class classifier predict one-best class label also predictsdistribution possible labels. using cross-entropy loss, assumednetworks output transformed using softmax transformation.363fiGoldberg4.7.5 Ranking Lossessettings, given supervision term labels, rather pairscorrect incorrect items x x0 , goal score correct items incorrectones. training situations arise positive examples, generatenegative examples corrupting positive example. useful loss scenariosmargin-based ranking loss, defined pair correct incorrect examples:Lranking(margin) (x, x0 ) = max(0, 1 (NN(x) NN(x0 )))(22)NN(x) score assigned network input vector x. objectivescore (rank) correct inputs incorrect ones margin least 1.common variation use log version ranking loss:Lranking(log) (x, x0 ) = log(1 + exp((NN(x) NN(x0 ))))(23)Examples using ranking hinge loss language tasks include training auxiliary tasks used deriving pre-trained word embeddings (see section 5),given correct word sequence corrupted word sequence, goal scorecorrect sequence corrupt one (Collobert & Weston, 2008). Similarly, Vande Cruys (2014) used ranking loss selectional-preferences task, network trained rank correct verb-object pairs incorrect, automatically derivedones, Weston, Bordes, Yakhnenko, Usunier (2013) trained model score correct(head,relation,trail) triplets corrupted ones information-extraction setting.example using ranking log loss found work Gao et al. (2014).variation ranking log loss allowing different margin negative positiveclass given work dos Santos et al. (2015).5. Word Embeddingsmain component neural-network approach use embeddings representingfeature vector low dimensional space. vectors come from?section survey common approaches.5.1 Random Initializationenough supervised training data available, one treat feature embeddingsmodel parameters: initialize embedding vectors random values,let network-training procedure tune good vectors.care taken way random initialization performed. methodused effective word2vec implementation (Mikolov et al., 2013; Mikolov, Sutskever,Chen, Corrado, & Dean, 2013) initialize word vectors uniformly sampled random1 1numbers range [ 2d, 2d ] number dimensions. Another optionuse xavier(see Section 6.3.1) initialize uniformly sampled valuesh initialization6 6, .364fiA Primer Neural Networks NLPpractice, one often use random initialization approach initialize embedding vectors commonly occurring features, part-of-speech tags individualletters, using form supervised unsupervised pre-training initializepotentially rare features, features individual words. pre-trained vectorseither treated fixed network training process, or, commonly,treated like randomly-initialized vectors tuned task hand.5.2 Supervised Task-Specific Pre-traininginterested task A, limited amount labeled data (forexample, syntactic parsing), auxiliary task B (say, part-of-speech tagging)much labeled data, may want pre-train word vectorsperform well predictors task B, use trained vectors trainingtask A. way, utilize larger amounts labeled data task B.training task either treat pre-trained vectors fixed, tunetask A. Another option train jointly objectives, see Section 7details.5.3 Unsupervised Pre-trainingcommon case auxiliary task large enough amountsannotated data (or maybe want help bootstrap auxiliary task training bettervectors). cases, resort unsupervised methods, trained hugeamounts unannotated text.techniques training word vectors essentially supervised learning,instead supervision task care about, instead create practicallyunlimited number supervised training instances raw text, hoping taskscreated match (or close enough to) final task care about.47key idea behind unsupervised approaches one would like embeddingvectors similar words similar vectors. word similarity hard defineusually task-dependent, current approaches derive distributionalhypothesis (Harris, 1954), stating words similar appear similar contexts.different methods create supervised training instances goal eitherpredict word context, predict context word.important benefit training word embeddings large amounts unannotateddata provides vector representations words appear supervised training set. Ideally, representations words similarrelated words appear training set, allowing model generalize betterunseen events. thus desired similarity word vectors learned unsupervised algorithm captures aspects similarity useful performingintended task network.47. interpretation creating auxiliary problems raw text inspired Ando Zhang (2005a)Ando Zhang (2005b).365fiGoldbergCommon unsupervised word-embedding algorithms include word2vec 48 (Mikolov et al.,2013, 2013), GloVe (Pennington, Socher, & Manning, 2014) Collobert Weston(2008, 2011) embeddings algorithm. models inspired neural networksbased stochastic gradient training. However, deeply connected anotherfamily algorithms evolved NLP IR communities, basedmatrix factorization (for discussion see Levy & Goldberg, 2014b; Levy et al., 2015).Arguably, choice auxiliary problem (what predicted, based kindcontext) affects resulting vectors much learning methodused train them. thus focus different choices auxiliary problemsavailable, skim details training methods. Several software packagesderiving word vectors available, including word2vec49 Gensim50 implementingword2vec models word-windows based contexts, word2vecf51 modifiedversion word2vec allowing use arbitrary contexts, GloVe52 implementingGloVe model. Many pre-trained word vectors also available download web.beyond scope tutorial, worth noting word embeddingsderived unsupervised training algorithms wide range applications NLPbeyond using initializing word-embeddings layer neural-network model.5.4 Training ObjectivesGiven word w context c, different algorithms formulate different auxiliary tasks.cases, word represented d-dimensional vector initializedrandom value. Training model perform auxiliary tasks well result goodword embeddings relating words contexts, turn resultembedding vectors similar words similar other.Language-modeling inspired approaches taken Mikolov et al. (2013),Mnih Kavukcuoglu (2013) well GloVe (Pennington et al., 2014) use auxiliary tasksgoal predict word given context. posed probabilisticsetup, trying model conditional probability P (w|c).approaches reduce problem binary classification. additionset observed word-context pairs, set created random wordscontext pairings. binary classification problem then: given (w, c) paircome not? approaches differ set constructed,structure classifier, objective optimized. CollobertWeston (2008, 2011) take margin-based binary ranking approach, training feed-forwardneural network score correct (w, c) pairs incorrect ones. Mikolov et al. (2013, 2014)take instead probabilistic version, training log-bilinear model predict probabilityP ((w, c) D|w, c) pair come corpus rather random sample.48. often treated single algorithm, word2vec actually software package including varioustraining objectives, optimization methods hyperparameters. See work Rong (2014)Levy, Goldberg, Dagan (2015) discussion.49. https://code.google.com/p/word2vec/50. https://radimrehurek.com/gensim/51. https://bitbucket.org/yoavgo/word2vecf52. http://nlp.stanford.edu/projects/glove/366fiA Primer Neural Networks NLP5.5 Choice Contextscases, contexts word taken words appearsurrounding, either short window around it, within sentence, paragraphdocument. cases text automatically parsed syntactic parser,contexts derived syntactic neighbourhood induced automatic parsetrees. Sometimes, definitions words context change include also parts words,prefixes suffixes.Neural word embeddings originated world language modeling,network trained predict next word based sequence preceding words (Bengioet al., 2003). There, text used create auxiliary tasks aim predictword based context k previous words. training language modelingauxiliary prediction problems indeed produce useful embeddings, approach needlesslyrestricted constraints language modeling task, one allowed lookprevious words. care language modelingresulting embeddings, may better ignoring constraint taking contextsymmetric window around focus word.5.5.1 Window Approachcommon approach sliding window approach, auxiliary taskscreated looking sequence 2k + 1 words. middle word callled focus wordk words side contexts. Then, either single task createdgoal predict focus word based context words (represented eitherusing CBOW, see Mikolov et al., 2013 vector concatenation, see Collobert & Weston,2008), 2k distinct tasks created, pairing focus word different contextword. 2k tasks approach, popularized Mikolov et al. (2013) referredskip-gram model. Skip-gram based approaches shown robust efficient train(Mikolov et al., 2013; Pennington et al., 2014), often produce state art results.Effect Window Size size sliding window strong effect resulting vector similarities. Larger windows tend produce topical similarities (i.e.dog, bark leash grouped together, well walked, run walking), smaller windows tend produce functional syntactic similarities (i.e.Poodle, Pitbull, Rottweiler, walking,running,approaching).Positional Windows using CBOW skip-gram context representations,different context words within window treated equally. distinctioncontext words close focus words fartherit, likewise distinction context words appear focuswords context words appear it. information easily factoredusing positional contexts: indicating context word also relative positionfocus words (i.e. instead context word becomes the:+2, indicatingword appears two positions right focus word). use positional contexttogether smaller windows tend produce similarities syntactic,strong tendency grouping together words share part speech, wellfunctionally similar terms semantics. Positional vectors shown Ling,367fiGoldbergDyer, Black, Trancoso (2015a) effective window-based vectorsused initialize networks part-of-speech tagging syntactic dependency parsing.Variants Many variants window approach possible. One may lemmatize wordslearning, apply text normalization, filter short long sentences, removecapitalization (see, e.g., pre-processing steps described dos Santos & Gatti, 2014).One may sub-sample part corpus, skipping probability creation taskswindows common rare focus words. window size maydynamic, using different window size turn. One may weigh different positionswindow differently, focusing trying predict correctly close word-contextpairs away ones. choices effect resulting vectors.hyperparameters (and others) discussed Levy et al. (2015).5.5.2 Sentences, Paragraphs DocumentsUsing skip-grams (or CBOW) approach, one consider contexts wordwords appear sentence, paragraph document.equivalent using large window sizes, expected result word vectorscapture topical similarity (words topic, i.e. words one would expectappear document, likely receive similar vectors).5.5.3 Syntactic Windowwork replace linear context within sentence syntactic one (Levy &Goldberg, 2014a; Bansal, Gimpel, & Livescu, 2014). text automatically parsedusing dependency parser, context word taken wordsproximity parse tree, together syntactic relationconnected. approaches produce highly functional similarities, grouping together wordsfill role sentence (e.g. colors, names schools, verbs movement).grouping also syntactic, grouping together words share inflection (Levy &Goldberg, 2014a).5.5.4 MultilingualAnother option using multilingual, translation based contexts (Hermann & Blunsom,2014; Faruqui & Dyer, 2014). example, given large amount sentence-aligned paralleltext, one run bilingual alignment model IBM model 1 model 2 (i.e.using GIZA++ software), use produced alignments derive word contexts.Here, context word instance foreign language words aligned it.alignments tend result synonym words receiving similar vectors. authorswork instead sentence alignment level, without relying word alignments (Gouws,Bengio, & Corrado, 2015) train end-to-end machine-translation neural networkuse resulting word embeddings (Hill, Cho, Jean, Devin, & Bengio, 2014). appealingmethod mix monolingual window-based approach multilingual approach,creating kinds auxiliary tasks. likely produce vectors similarwindow-based approach, reducing somewhat undesired effect window368fiA Primer Neural Networks NLPbased approach antonyms (e.g. hot cold, high low) tend receive similarvectors (Faruqui & Dyer, 2014).5.5.5 Character-Based Sub-word Representationsinteresting line work attempts derive vector representation wordcharacters compose it. approaches likely particularly useful taskssyntactic nature, character patterns within words strongly relatedsyntactic function. approaches also benefit producing smallmodel sizes (only one vector character alphabet together handfulsmall matrices needs stored), able provide embedding vector everyword may encountered. Dos Santos Gatti (2014), dos Santos Zadrozny(2014) Kim et al. (2015) model embedding word using convolutional network(see Section 9) characters. Ling et al. (2015b) model embedding wordusing concatenation final states two RNN (LSTM) encoders (Section 10), onereading characters left right, right left. producestrong results part-of-speech tagging. work Ballesteros et al. (2015) showtwo-LSTMs encoding Ling et al. (2015b) beneficial also representing wordsdependency parsing morphologically rich languages.Deriving representations words representations characters motivated unknown words problem encounter wordembedding vector? Working level characters alleviatesproblem large extent, vocabulary possible characters much smallervocabulary possible words. However, working character levelchallenging, relationship form (characters) function (syntax, semantics)language quite loose. Restricting oneself stay character level mayunnecessarily hard constraint. researchers propose middle-ground, wordrepresented combination vector word vectors sub-wordunits comprise it. sub-word embeddings help sharing informationdifferent words similar forms, well allowing back-off subword levelword observed. time, models forced rely solelyform enough observations word available. Botha Blunsom (2014) suggest model embedding vector word sum word-specific vectorvector available, vectors different morphological components comprise(the components derived using Morfessor (Creutz & Lagus, 2007), unsupervisedmorphological segmentation method). Gao et al. (2014) suggest using core featuresword form also unique feature (hence unique embedding vector)letter-trigrams word.6. Neural Network TrainingNeural network training done trying minimize loss function training set,using gradient-based method. Roughly speaking, training methods work repeatedlycomputing estimate error dataset, computing gradient respecterror, moving parameters opposite direction gradient.Models differ error estimate computed, moving opposite369fiGoldbergdirection gradient defined. describe basic algorithm, stochastic gradientdescent (SGD), briefly mention approaches pointersreading. Gradient calculation central approach. Gradients efficientlyautomatically computed using reverse mode differentiation computation graphgeneral algorithmic framework automatically computing gradient networkloss function, discussed Section 6.2.6.1 Stochastic Gradient Trainingcommon approach training neural networks using stochastic gradient descent(SGD) algorithm (Bottou, 2012; LeCun, Bottou, Orr, & Muller, 1998a) variant it.SGD general optimization algorithm. receives function f parameterized ,loss function, desired input output pairs. attempts set parametersloss f respect training examples small. algorithm worksfollows:Algorithm 1 Online Stochastic Gradient Descent Training1: Input: Function f (x; ) parameterized parameters .2: Input: Training set inputs x1 , . . . , xn desired outputs y1 , . . . , yn .3: Input: Loss function L.4: stopping criteria met5:Sample training example xi , yi6:Compute loss L(f (xi ; ), yi )7:g gradients L(f (xi ; ), yi ) w.r.t8:g9: returnPnThe goal algorithm set parameters minimize total lossi=1 L(f (xi ; ), yi ) training set. works repeatedly sampling training example computing gradient error example respect parameters(line 7) input expected output assumed fixed, loss treatedfunction parameters . parameters updated oppositedirection gradient, scaled learning rate (line 8). learning rate eitherfixed throughout training process, decay function time step t.53discussion setting learning rate, see Section 6.3.Note error calculated line 6 based single training example, thusrough estimate corpus-wide loss aiming minimize. noiseloss computation may result inaccurate gradients. common way reducingnoise estimate error gradients based sample examples.gives rise minibatch SGD algorithm:lines 6 9 algorithm estimates gradient corpus loss basedminibatch. loop, g contains gradient estimate, parametersupdated toward g. minibatch size vary size = 1 = n. Highervalues provide better estimates corpus-wide gradients, smaller values allow53. Learning rate decay required order prove convergence SGD.370fiA Primer Neural Networks NLPAlgorithm 2 Minibatch Stochastic Gradient Descent Training1: Input: Function f (x; ) parameterized parameters .2: Input: Training set inputs x1 , . . . , xn desired outputs y1 , . . . , yn .3: Input: Loss function L.4: stopping criteria met5:Sample minibatch examples {(x1 , y1 ), . . . , (xm , ym )}6:g 07:= 18:Compute loss L(f (xi ; ), yi )19:g g + gradientsL(f (xi ; ), yi ) w.r.tg11: return10:updates turn faster convergence. Besides improved accuracy gradientsestimation, minibatch algorithm provides opportunities improved training efficiency.modest sizes m, computing architectures (i.e. GPUs) allow efficient parallelimplementation computation lines 69. properly decreasing learning rate,SGD guaranteed converge global optimum function convex. However,also used optimize non-convex functions neural-network.longer guarantees finding global optimum, algorithm proved robustperforms well practice.54training neural network, parameterized function f neural network,parameters linear-transformation matrices, bias terms, embedding matriceson. gradient computation key step SGD algorithm, wellneural network training algorithms. question is, then, computegradients networks error respect parameters. Fortunately,easy solution form backpropagation algorithm (Rumelhart, Hinton, & Williams,1986; LeCun, Bottou, Bengio, & Haffner, 1998b). backpropagation algorithm fancyname methodically computing derivatives complex expression using chainrule, caching intermediary results. generally, backpropagation algorithmspecial case reverse-mode automatic differentiation algorithm (Neidinger, 2010,Section 7; Baydin, Pearlmutter, Radul, & Siskind, 2015; Bengio, 2012). followingsection describes reverse mode automatic differentiation context computationgraph abstraction.6.1.1 Beyond SGDSGD algorithm often produce good results, advanced algorithms also available. SGD+Momentum (Polyak, 1964) Nesterov Momentum(Sutskever, Martens, Dahl, & Hinton, 2013; Nesterov, 1983, 2004) algorithms variantsSGD previous gradients accumulated affect current update. Adap54. Recent work neural-networks literature argue non-convexity networks manifested proliferation saddle points rather local minima (Dauphin, Pascanu, Gulcehre, Cho,Ganguli, & Bengio, 2014). may explain success training neural networks despiteusing local search techniques.371fiGoldbergtive learning rate algorithms including AdaGrad (Duchi, Hazan, & Singer, 2011), AdaDelta(Zeiler, 2012), RMSProp (Tieleman & Hinton, 2012) Adam (Kingma & Ba, 2014)designed select learning rate minibatch, sometimes per-coordinate basis,potentially alleviating need fiddling learning rate scheduling. detailsalgorithms, see original papers book Bengio et al. (2015, Sections 8.3, 8.4).many neural-network software frameworks provide implementations algorithms,easy sometimes worthwhile try different variants.6.2 Computation Graph Abstractionone compute gradients various parameters network handimplement code, procedure cumbersome error prone. purposes, preferable use automatic tools gradient computation (Bengio, 2012).computation-graph abstraction allows us easily construct arbitrary networks, evaluatepredictions given inputs (forward pass), compute gradients parametersrespect arbitrary scalar losses (backward pass).computation graph representation arbitrary mathematical computationgraph. directed acyclic graph (DAG) nodes correspond mathematicaloperations (bound) variables edges correspond flow intermediary valuesnodes. graph structure defines order computation termsdependencies different components. graph DAG tree,result one operation input several continuations. Consider examplegraph computation (a b + 1) (a b + 2):*++*1b2computation b shared. restrict case computationgraph connected.Since neural network essentially mathematical expression, representedcomputation graph.example, Figure 3a presents computation graph MLP one hiddenlayer softmax output transformation. notation, oval nodes represent mathematical operations functions, shaded rectangle nodes represent parameters (boundvariables). Network inputs treated constants, drawn without surrounding node.Input parameter nodes incoming arcs, output nodes outgoing arcs.output node matrix, dimensionality indicatednode.graph incomplete: without specifying inputs, cannot compute output.Figure 3b shows complete graph MLP takes three words inputs, predictsdistribution part-of-speech tags third word. graph usedprediction, training, output vector (not scalar) graphtake account correct answer loss term. Finally, graph 3c shows372fiA Primer Neural Networks NLP11neg11log11(a)(b)(c)pick1 171 171 17softmaxsoftmaxsoftmax1 171 171 17ADDADDADD1 171 171 17MULMULMUL1 20tanh20 17W21 201 17b220 17W2tanh1 201 17b21 201 20ADDADDADD1 201 201 20MULMULMUL150 20W11 1501 20b1concat150 20W120 171 17150 201 20W2tanh1 201 150x51 1501 20b1concatW11 501 501 501 501 501 50lookuplookuplookuplookuplookuplookupblackdogblackdog|V | 50Eb2b1|V | 50EFigure 3: Computation Graph MLP1. (a) Graph unbound input. (b) Graphconcrete input. (c) Graph concrete input, expected output, lossnode.computation graph specific training example, inputs (embeddingsof) words the, black, dog, expected output NOUN (whose index5). pick node implements indexing operation, receiving vector index (incase, 5) returning corresponding entry vector.graph built, straightforward run either forward computation (compute result computation) backward computation (computing gradients),show below. Constructing graphs may look daunting, actually easyusing dedicated software libraries APIs.6.2.1 Forward Computationforward pass computes outputs nodes graph. Since nodes outputdepends incoming edges, trivial compute outputsnodes traversing nodes topological order computing outputnode given already computed outputs predecessors.373fiGoldbergformally, graph N nodes, associate node index accordingtopological ordering. Let fi function computed node (e.g. multiplication.addition, . . . ). Let (i) parent nodes node i, 1 (i) = {j | (j)}children nodes node (these arguments fi ). Denote v(i) output nodei, is, application fi output values arguments 1 (i). variableinput nodes, fi constant function 1 (i) empty. Forward algorithmcomputes values v(i) [1, N ].Algorithm 3 Computation Graph Forward Pass1: = 1 N2:Let a1 , . . . , = 1 (i)3:v(i) fi (v(a1 ), . . . , v(am ))6.2.2 Backward Computation (Derivatives, Backprop)backward pass begins designating node N scalar (11) output loss-node,running forward computation node. backward computation computesNgradients respect nodes value. Denote d(i) quantity.backpropagation algorithm used compute values d(i) nodes i.backward pass fills table d(i) follows:Algorithm 4 Computation Graph Backward Pass (Backpropagation)1: d(N ) 12: = N-1 1Pfj3:d(i) j(i) d(j)fjpartial derivative fj ( 1 (j)) w.r.t argument 1 (j).value depends function fj values v(a1 ), . . . , v(am ) (where a1 , . . . , =1 (j)) arguments, computed forward pass.quantityThus, order define new kind node, one need define two methods: onecalculating forward value v(i) based nodes inputs, another calculatingfix 1 (i).xinformation automatic differentiation see work Neidinger (2010,Section 7) Baydin et al. (2015). depth discussion backpropagationalgorithm computation graphs (also called flow graphs) see work Bengio et al.(2015, Section 6.4), LeCun et al. (1998b) Bengio (2012). popular yet technicalpresentation, see online post Olah (2015a).374fiA Primer Neural Networks NLP6.2.3 SoftwareSeveral software packages implement computation-graph model, including Theano55 ,Chainer56 , penne57 CNN/pyCNN58 . packages support essential components (node types) defining wide range neural network architectures, coveringstructures described tutorial more. Graph creation made almost transparentuse operator overloading. framework defines type representing graph nodes(commonly called expressions), methods constructing nodes inputs parameters,set functions mathematical operations take expressions input resultcomplex expressions. example, python code creating computationgraph Figure (3c) using pyCNN framework is:import pycnn pc# model initialization.model = pc.Model()pW1 = model.add_parameters((20,150))pb1 = model.add_parameters(20)pW2 = model.add_parameters((17,20))pb2 = model.add_parameters(17)words = model.add_lookup_parameters((100, 50))# Building computation graph:pc.renew_cg() # create new graph.# Wrap model parameters graph-nodes.W1 = pc.parameter(pW1)b1 = pc.parameter(pb1)W2 = pc.parameter(pW2)b2 = pc.parameter(pb2)def get_index(x): return 1 # place holder# Generate embeddings layer.vthe= pc.lookup(words, get_index("the"))vblack = pc.lookup(words, get_index("black"))vdog= pc.lookup(words, get_index("dog"))# Connect leaf nodes complete graph.x = pc.concatenate([vthe, vblack, vdog])output = pc.softmax(W2*(pc.tanh(W1*x)+b1)+b2)loss = -pc.log(pc.pick(output, 5))loss_value = loss.forward()loss.backward() # gradient computed# stored corresponding# parameters.code involves various initializations: first block defines model parametersshared different computation graphs (recall graph correspondsspecific training example). second block turns model parameters graphnode (Expression) types. third block retrieves Expressions embeddings55.56.57.58.http://deeplearning.net/software/theano/http://chainer.orghttps://bitbucket.org/ndnlp/pennehttps://github.com/clab/cnn375fiGoldberginput words. Finally, fourth block graph created. Note transparentgraph creation almost one-to-one correspondence creatinggraph describing mathematically. last block shows forward backwardpass. software frameworks follow similar patterns.Theano involves optimizing compiler computation graphs, blessingcurse. one hand, compiled, large graphs run efficiently eitherCPU GPU, making ideal large graphs fixed structure,inputs change instances. However, compilation step costly,makes interface bit cumbersome work with. contrast, packages focusbuilding large dynamic computation graphs executing fly withoutcompilation step. execution speed may suffer respect Theanos optimizedversion, packages especially convenient working recurrentrecursive networks described Sections 10, 12 well structured prediction settingsdescribed Section 8.6.2.4 Implementation RecipeUsing computation graph abstraction, pseudo-code network training algorithmgiven Algorithm 5.Algorithm 5 Neural Network Training Computation Graph Abstraction (using minibatches size 1)1: Define network parameters.2: iteration = 1 N3:Training example xi , yi dataset4:loss node build computation graph(xi , yi , parameters)5:loss node.forward()6:gradients loss node().backward()7:parameters update parameters(parameters, gradients)8: return parameters.Here, build computation graph user-defined function builds computationgraph given input, output network structure, returning single loss node.update parameters optimizer specific update rule. recipe specifies newgraph created training example. accommodates cases networkstructure varies training example, recurrent recursive neural networks,discussed Sections 10 12. networks fixed structures, MLPs,may efficient create one base computation graph vary inputsexpected outputs examples.6.2.5 Network Compositionlong networks output vector (1 k matrix), trivial compose networksmaking output one network input another, creating arbitrary networks.computation graph abstractions makes ability explicit: node computationgraph computation graph designated output node. One376fiA Primer Neural Networks NLPdesign arbitrarily deep complex networks, able easily evaluate trainthanks automatic forward gradient computation. makes easy definetrain networks structured outputs multi-objective training, discussSection 7, well complex recurrent recursive networks, discussed Sections1012.6.3 Optimization Issuesgradient computation taken care of, network trained using SGD anothergradient-based optimization algorithm. function optimized convex,long time training neural networks considered black art doneselected few. Indeed, many parameters affect optimization process, caretaken tune parameters. tutorial intended comprehensiveguide successfully training neural networks, list prominent issues.discussion optimization techniques algorithms neural networks, referbook Bengio et al. (2015, ch. 8). theoretical discussion analysis, referwork Glorot Bengio (2010). various practical tips recommendations,see work LeCun et al. (1998a) Bottou (2012).6.3.1 Initializationnon-convexity loss function means optimization procedure may get stucklocal minimum saddle point, starting different initial points (e.g.different random values parameters) may result different results. Thus,advised run several restarts training starting different random initializations,choosing best one based development set.59 amount varianceresults different different network formulations datasets, cannot predictedadvance.magnitude random values important effect success training.effective scheme due Glorot Bengio (2010), called xavier initializationGlorots first name, suggests initializing weight matrix W Rdin dout as:#66W U, +din + doutdin + dout"(24)U [a, b] uniformly sampled random value range [a, b]. suggestionbased properties tanh activation function, works well many occasions,preferred default initialization method many.Analysis et al. (2015) suggests using ReLU non-linearities, weightsinitializedsampling zero-mean Gaussian distribution whose standardq2deviationdin . initialization found et al work better xavierinitialization image classification task, especially deep networks involved.59. debugging, reproducibility results, advised used fixed random seed.377fiGoldberg6.3.2 Vanishing Exploding Gradientsdeep networks, common error gradients either vanish (become exceedinglyclose 0) explode (become exceedingly high) propagate back computation graph. problem becomes severe deeper networks, especiallyrecursive recurrent networks (Pascanu, Mikolov, & Bengio, 2012). Dealingvanishing gradients problem still open research question. Solutions include makingnetworks shallower, step-wise training (first train first layers based auxiliaryoutput signal, fix train upper layers complete network basedreal task signal), performing batch-normalization (Ioffe & Szegedy, 2015) (for everyminibatch, normalizing inputs network layers zero mean unitvariance) using specialized architectures designed assist gradient flow (e.g.,LSTM GRU architectures recurrent networks, discussed Section 11). Dealingexploding gradients simple effective solution: clipping gradientsnorm exceeds given threshold. Let g gradients parametersnetwork, kgk L2 norm. Pascanu et al. (2012) suggest set: g thresholdkgk gkgk > threshold.6.3.3 Saturation Dead NeuronsLayers tanh sigmoid activations become saturated resulting output valueslayer close one, upper-limit activation function. Saturatedneurons small gradients, avoided. Layers ReLU activationcannot saturated, die values negative thus clipped zeroinputs, resulting gradient zero layer. network trainwell, advisable monitor network layers many saturated dead neurons.Saturated neurons caused large values entering layer. may controlledchanging initialization, scaling range input values, changinglearning rate. Dead neurons caused signals entering layer negative (forexample happen large gradient update). Reducing learning ratehelp situation. saturated layers, another option normalize valuessaturated layer activation, i.e. instead g(h) = tanh(h) using g(h) = k tanh(h)tanh(h)k .Layer normalization effective measure countering saturation, also expensiveterms gradient computation. related technique batch normalization, due IoffeSzegedy (2015), activations layer normalizedmean 0 variance 1 across mini-batch. batch-normalization techniquesbecame key component effective training deep networks computer vision.writing, less popular natural language applications.6.3.4 Shufflingorder training examples presented network important.SGD formulation specifies selecting random example turn. practice,implementations go training example order. advised shuffle trainingexamples pass data.378fiA Primer Neural Networks NLP6.3.5 Learning RateSelection learning rate important. large learning rates prevent networkconverging effective solution. small learning rates take long timeconverge. rule thumb, one experiment range initial learning ratesrange [0, 1], e.g. 0.001, 0.01, 0.1, 1. Monitor networks loss time, decreaselearning rate loss stops improving. Learning rate scheduling decreases ratefunction number observed minibatches. common schedule dividing initiallearning rate iteration number. Leon Bottou (2012) recommends using learningrate form = 0 (1 + 0 t)1 0 initial learning rate, learningrate use tth training example, additional hyperparameter.recommends determining good value 0 based small sample data priorrunning entire dataset.6.3.6 MinibatchesParameter updates occur either every training example (minibatches size 1) every ktraining examples. problems benefit training larger minibatch sizes.terms computation graph abstraction, one create computation graphk training examples, connecting k loss nodes averaging node,whose output loss minibatch. Large minibatched training alsobeneficial terms computation efficiency specialized computing architecturesGPUs, replacing vector-matrix operations matrix-matrix operations. beyondscope tutorial.6.4 RegularizationNeural network models many parameters, overfitting easily occur. Overfittingalleviated extent regularization. common regularization methodL2 regularization, placing squared penalty parameters large values addingadditive 2 kk2 term objective function minimized, setmodel parameters, k k2 squared L2 norm (sum squares values),hyperparameter controlling amount regularization.recently proposed alternative regularization method dropout (Hinton, Srivastava,Krizhevsky, Sutskever, & Salakhutdinov, 2012). dropout method designed preventnetwork learning rely specific weights. works randomly dropping(setting 0) half neurons network (or specific layer) trainingexample. Work Wager et al. (2013) establishes strong connection dropoutmethod L2 regularization.dropout technique one key factors contributing strong resultsneural-network methods image classification tasks (Krizhevsky, Sutskever, & Hinton,2012), especially combined ReLU activation units (Dahl, Sainath, & Hinton,2013). dropout technique effective also NLP applications neural networks.379fiGoldberg7. Cascading Multi-task Learningcombination online training methods automatic gradient computations usingcomputation graph abstraction allows easy implementation model cascading,parameter sharing multi-task learning.7.1 Model Cascadingpowerful technique large networks built composing smallercomponent networks. example, may feed-forward network predictingpart speech word based neighbouring words and/or characters composeit. pipeline approach, would use network predicting parts speech,feed predictions input features neural network syntactic chunkingparsing. Instead, could think hidden layers network encodingcaptures relevant information predicting part speech. cascadingapproach, take hidden layers network connect (and partspeech prediction themselves) inputs syntactic network.larger network takes input sequences words characters, outputssyntactic structure. computation graph abstraction allows us easily propagateerror gradients syntactic task loss way back characters.combat vanishing gradient problem deep networks, well make betteruse available training material, individual component networks parametersbootstrapped training separately relevant task, plugginglarger network tuning. example, part-of-speech predicting networktrained accurately predict parts-of-speech relatively large annotated corpus,plugging hidden layer syntactic parsing network less trainingdata available. case training data provide direct supervision tasks,make use training creating network two outputs, one task,computing separate loss output, summing losses single nodebackpropagate error gradients.Model cascading common using convolutional, recursive recurrentneural networks, where, example, recurrent network used encode sentencefixed sized vector, used input another network. supervisionsignal recurrent network comes primarily upper network consumesrecurrent networks output inputs.7.2 Multi-task Learningused related prediction tasks necessarily feed one another,believe information useful one type prediction usefulalso tasks. example, chunking, named entity recognition (NER)language modeling examples synergistic tasks. Information predicting chunkboundaries, named-entity boundaries next word sentence relyshared underlying syntactic-semantic representation. Instead training separate networktask, create single network several outputs. common approachmulti-layer feed-forward network, whose final hidden layer (or concatenation380fiA Primer Neural Networks NLPhidden layers) passed different output layers. way, parametersnetwork shared different tasks. Useful information learned onetask help disambiguate tasks. Again, computation graph abstractionmakes easy construct networks compute gradients them,computing separate loss available supervision signal, summinglosses single loss used computing gradients. case severalcorpora, different kind supervision signal (e.g. one corpus NERanother chunking), training procedure shuffle available trainingexample, performing gradient computation updates respect different lossevery turn. Multi-task learning context language-processing introduceddiscussed work Collobert et al. (2011). examples cascaded Multi-tasklearning feed forward network, see work Zhang Weiss (2016). contextrecurrent neural networks, see work Luong, Le, Sutskever, Vinyals, Kaiser(2015) Sgaard Goldberg (2016).8. Structured Output PredictionMany problems NLP involve structured outputs: cases desired outputclass label distribution class labels, structured object sequence,tree graph. Canonical examples sequence tagging (e.g. part-of-speech tagging)sequence segmentation (chunking, NER), syntactic parsing. section, discussfeed-forward neural network models used structured tasks. later sectionsdiscuss specialized neural network models dealing sequences (Section 10)trees (Section 12).8.1 Greedy Structured Predictiongreedy approach structured prediction decompose structure predictionproblem sequence local prediction problems training classifier performlocal decision. test time, trained classifier used greedy manner. Examplesapproach left-to-right tagging models (Gimenez & Marquez, 2004) greedytransition-based parsing (Nivre, 2008). approaches easily adapted use neuralnetworks simply replacing local classifier linear classifier SVMlogistic regression model neural network, demonstrated Chen Manning(2014) Lewis Steedman (2014).greedy approaches suffer error propagation, mistakes early decisionscarry influence later decisions. overall higher accuracy achievable nonlinear neural network classifiers helps offsetting problem extent. addition,training techniques proposed mitigating error propagation problem eitherattempting take easier predictions harder ones (the easy-first approach Goldberg & Elhadad, 2010) making training conditions similar testing conditionsexposing training procedure inputs result likely mistakes (Hal Daume III,Langford, & Marcu, 2009; Goldberg & Nivre, 2013). effective also traininggreedy neural network models, demonstrated Ma, Zhang, Zhu (2014) (easy-firsttagger) Ballesteros, Goldberg, Dyer, Smith (2016) (dynamic oracle traininggreedy dependency parsing).381fiGoldberg8.2 Search Based Structured Predictioncommon approach predicting natural language structures search based. indepth discussion search-based structure prediction NLP, see book Smith (2011).techniques easily adapted use neural-network. neural-networksliterature, models discussed framework energy based learning (LeCunet al., 2006, Section 7). presented using setup terminology familiarNLP community.Search-based structured prediction formulated search problem possible structures:predict(x) = arg max score(x, y)(25)yY(x)x input structure, output x (in typical example x sentencetag-assignment parse-tree sentence), Y(x) set validstructures x, looking output maximize scorex, pair.scoring function defined linear model:score(x, y) = w (x, y)(26)feature extraction function w weight vector.order make search optimal tractable, structure decomposedparts, feature function defined terms parts, (p) part-localfeature extraction function:X(x, y) =(p)(27)pparts(x,y)part scored separately, structure score sum componentparts scores:score(x, y) =w (x, y) = wX(p) =pyXpyw (p) =Xscore(p)(28)pyp shorthand p parts(x, y). decomposition partsexists inference algorithm allows efficient search best scoringstructure given scores individual parts.One trivially replace linear scoring function parts neuralnetwork:score(x, y) =Xscore(p) =pyXNN(c(p))pyc(p) maps part p din dimensional vector.case one hidden-layer feed-forward network:382(29)fiA Primer Neural Networks NLPscore(x, y) =XNNMLP1 (c(p)) =X(g(c(p)W1 + b1 ))w(30)pypyc(p) Rdin , W1 Rdin d1 , b1 Rd1 , w Rd1 . common objective structuredprediction making gold structure score higher structure 0 , leadingfollowing (generalized perceptron) loss:maxscore(x, 0 ) score(x, y)0(31)terms implementation, means: create computation graph CGppossible parts, calculate score. Then, run inference scored partsfind best scoring structure 0 . Connect output nodes computation graphscorresponding parts gold (predicted) structure (y 0 ) summing node CGy(CG0y ). Connect CGy CG0y using minus node, CGl , compute gradients.argued LeCun et al. (2006, Section 5), generalized perceptron loss maygood loss function training structured prediction neural networksmargin, margin-based hinge loss preferred:max(0, + maxscore(x, 0 ) score(x, y))06=y(32)trivial modify implementation work hinge loss.Note cases lose nice properties linear model. particular,model longer convex. expected, even simplest non-linear neuralnetwork already non-convex. Nonetheless, could still use standard neural-networkoptimization techniques train structured model.Training inference slower, evaluate neural network (and takegradients) |parts(x, y)| times.Structured prediction vast field beyond scope tutorial, lossfunctions, regularizers methods described by, e.g., Smith (2011), cost-augmenteddecoding, easily applied adapted neural-network framework.608.2.1 Probabilistic Objective (CRF)probabilistic framework (conditional random fields, CRF), treat partsscores clique potential (see discussions Smith, 2011 Lafferty, McCallum, &Pereira, 2001) define score structure be:60. One keep mind resulting objectives longer convex, lack formal guarantees bounds associated convex optimization problems. Similarly, theory, learning boundsguarantees associated algorithms automatically transfer neural versions.383fiGoldbergPexp( py score(p))Pscorecrf (x, y) = P (y|x) = P0 Y(x) exp( py 0 score(p))Pexp( py NN((p)))P=P0 Y(x) exp( py 0 NN((p)))(33)scoring function defines conditional distribution P (y|x),P wish set parameters network corpus conditional log likelihood (xi ,yi )training log P (yi |xi )maximized.loss given training example (x, y) then: log scorecrf (x, y). Takinggradient respect loss involved building associated computationgraph. tricky part denominator (the partition function) requires summingpotentially exponentially many structures Y. However, problems,dynamic programming algorithm exists efficiently solving summation polynomialtime (i.e. forward-backward viterbi recurrences sequences CKY insideoutside recurrences tree structures). algorithm exists, adaptedalso create polynomial-size computation graph.efficient enough algorithm computing partition function available,approximate methods used. example, one may use beam search inference,partition function sum structures remaining beam insteadexponentially large Y(x).Sequence-level CRFs neural-network clique potentials discussed Peng, Bo,Xu (2009) Do, Arti, others (2010), applied sequence labelingbiological data, OCR data speech signals, Wang Manning (2013)apply traditional natural language tagging tasks (chunking NER). hingebased approach used Pei et al. (2015) arc-factored dependency parsing,probabilistic approach Durrett Klein (2015) CRF constituency parser.approximate beam-based partition function effectively used Zhou et al. (2015)transition based parser.8.2.2 Rerankingsearching possible structures intractable, inefficient hard integratemodel, reranking methods often used. reranking framework (Charniak& Johnson, 2005; Collins & Koo, 2005) base model used produce list kbest scoring structures. complex model trained score candidatesk-best list best structure respect gold one scored highest.search performed k items rather exponential space,complex model condition (extract features from) arbitrary aspects scoredstructure. Reranking methods natural candidates structured prediction using neuralnetwork models, allow modeler focus feature extraction networkstructure, removing need integrate neural network scoring decoder.Indeed, reranking methods often used experimenting neural modelsstraightforward integrate decoder, convolutional, recurrent recursivenetworks, discussed later sections. Works using reranking approach384fiA Primer Neural Networks NLPinclude Schwenk et al. (2006), Socher et al. (2013), Auli et al. (2013), LeZuidema (2014) Zhu et al. (2015a).8.2.3 MEMM Hybrid Approachesformulations are, course, also possible. example, MEMM (McCallum,Freitag, & Pereira, 2000) trivially adapted neural network world replacinglogistic regression (Maximum Entropy) component MLP.Hybrid approaches neural networks linear models also explored.particular, Weiss et al. (2015) report strong results transition-based dependency parsingtwo-stage model. first stage, static feed-forward neural network (MLP2)trained perform well individual decisions structured problemisolation. second stage, neural network model held fixed, different layers(output well hidden layer vectors) input concatenated usedinput features linear structured perceptron model (Collins, 2002) trainedperform beam-search best resulting structure. clear trainingregime effective training single structured-prediction neural network, usetwo simpler, isolated models allowed researchers perform much extensivehyper-parameter search (e.g. tuning layer sizes, activation functions, learning rateson) model feasible complicated networks.9. Convolutional LayersSometimes interested making predictions based ordered sets items (e.g.sequence words sentence, sequence sentences document on).Consider example predicting sentiment (positive, negative neutral) sentence.sentence words informative sentiment, words lessinformative, good approximation, informative clue informative regardlessposition sentence. would like feed sentence wordslearner, let training process figure important clues. One possible solutionfeeding CBOW representation fully connected network MLP. However,downside CBOW approach ignores ordering information completely,assigning sentences good, actually quite bad bad,actually quite good exact representation. global positionindicators good bad matter classification task,local ordering words (that word appears right word bad)important. naive approach would suggest embedding word-pairs (bi-grams) ratherwords, building CBOW embedded bigrams. architecturecould effective, result huge embedding matrices, scale longer ngrams, suffer data sparsity problems share statistical strengthdifferent n-grams (the embedding quite good good completelyindependent one another, learner saw one training,able deduce anything based component words).convolution-and-pooling (also called convolutional neural networks, CNNs) architectureelegant robust solution modeling problem. convolutional neural networkdesigned identify indicative local predictors large structure, combine385fiGoldbergproduce fixed size vector representation structure, capturing local aspectsinformative prediction task hand.Convolution-and-pooling architectures (LeCun & Bengio, 1995) evolved neuralnetworks vision community, showed great success object detectors recognizing object predefined category (cat, bicycles) regardless positionimage (Krizhevsky et al., 2012). applied images, architecture using2-dimensional (grid) convolutions. applied text, mainly concerned1-d (sequence) convolutions. Convolutional networks introduced NLP community pioneering work Collobert, Weston colleagues (2011) usedsemantic-role labeling, later Kalchbrenner et al. (2014) Kim (2014) usedsentiment question-type classification.9.1 Basic Convolution + Poolingmain idea behind convolution pooling architecture language tasks applynon-linear (learned) function instantiation k-word sliding windowsentence. function (also called filter) transforms window k wordsdimensional vector captures important properties words window (eachdimension sometimes referred literature channel). Then, poolingoperation used combine vectors resulting different windows singled-dimensional vector, taking max average value observedchannels different windows. intention focus importantfeatures sentence, regardless location. d-dimensional vectorfed network used prediction. gradients propagatedback networks loss training process used tune parametersfilter function highlight aspects data important tasknetwork trained for. Intuitively, sliding window run sequence,filter function learns identify informative k-grams.formally, consider sequence words x = x1 , . . . , xn , corresponding demb dimensional word embedding v(xi ). 1d convolution layer61 width k worksmoving sliding window size k sentence, applying filterwindow sequence [v(xi ); v(xi+1 ); . . . ; v(xi+k1 )]. filter function usuallylinear transformation followed non-linear activation function.Let concatenated vector ith window wi = [v(xi ); v(xi+1 ); . . . ; v(xi+k1 )],wi Rkdemb . Depending whether pad sentence k 1 words side,may get either = n k + 1 (narrow convolution) = n + k + 1 windows (wideconvolution) (Kalchbrenner et al., 2014). result convolution layer vectorsp1 , . . . , pm , pi Rdconv where:pi = g(wi W + b)(34)g non-linear activation function applied element-wise, W Rkdemb dconvb Rdconv parameters network. pi dconv dimensional vector, encoding61. 1d refers convolution operating 1-dimensional inputs sequences, opposed 2dconvolutions applied images.386fiA Primer Neural Networks NLP63Wmaxquick brown fox jumped lazy dogquick brownMUL+tanhquick brown foxMUL+tanhbrown fox jumpedMUL+tanhfox jumpedMUL+tanhjumpedMUL+tanhlazyMUL+tanhlazy dogMUL+tanhconvolutionpoolingFigure 4: 1d convolution+pooling sentence quick brown fox jumpedlazy dog. narrow convolution (no padding added sentence)window size 3. word translated 2-dim embedding vector(not shown). embedding vectors concatenated, resulting 6-dimwindow representations. seven windows transfered 6 3filter (linear transformation followed element-wise tanh), resulting seven3-dimensional filtered representations. Then, max-pooling operation applied,taking max dimension, resulting final 3-dimensional pooledvector.information wi . Ideally, dimension captures different kind indicative information. vectors combined using max pooling layer, resulting singledconv dimensional vector c.cj = max pi [j]1<im(35)pi [j] denotes jth component pi . effect max-pooling operation getsalient information across window positions. Ideally, dimension specializeparticular sort predictors, max operation pick importantpredictor type.Figure 4 provides illustration process.resulting vector c representation sentence dimensionreflects salient information respect prediction task. c feddownstream network layers, perhaps parallel vectors, culminatingoutput layer used prediction. training procedure network calculatesloss respect prediction task, error gradients propagatedway back pooling convolution layers, well embedding layers. 6262. Besides useful prediction, by-product training procedure set parameters W, Bembeddings v() used convolution pooling architecture encode arbitrary length387fiGoldbergmax-pooling common pooling operation text applications,pooling operations also possible, second common operation averagepooling, taking average value index instead max.9.2 Dynamic, Hierarchical k-max PoolingRather performing single pooling operation entire sequence, may wantretain positional information based domain understanding predictionproblem hand. end, split vectors pi ` distinct groups, applypooling separately group, concatenate ` resulting dconv -dimensionalvectors c1 , . . . , c` . division pi groups performed based domain knowledge. example, may conjecture words appearing early sentenceindicative words appearing late. split sequence ` equallysized regions, applying separate max-pooling region. example, JohnsonZhang (2015) found classifying documents topics, useful 20average-pooling regions, clearly separating initial sentences (where topic usuallyintroduced) later ones, sentiment classification task single max-poolingoperation entire sentence optimal (suggesting one two strongsignals enough determine sentiment, regardless position sentence).Similarly, relation extraction kind task may given two words askeddetermine relation them. could argue words first word,words second word, words provide three different kindsinformation (Chen et al., 2015). thus split pi vectors accordingly, poolingseparately windows resulting group.Another variation using hierarchy convolutional layers, succession convolution pooling layers, stage applies convolution sequence,pools every k neighboring vectors, performs convolution resulting pooled sequence,applies another convolution on. architecture allows sensitivity increasinglylarger structures.Finally, Kalchbrenner et al. (2014) introduced k-max pooling operation,top k values dimension retained instead best one, preservingorder appeared text. example a, consider following matrix:1927326384351111-max pooling column vectors result 9 8 5 , 2-max pooling9 6 3result following matrix:whose rows concatenated7 8 59 6 3 7 8 5sentences fixed-size vectors, sentences share kind predictive informationclose other.388fiA Primer Neural Networks NLPk-max pooling operation makes possible pool k active indicatorsmay number positions apart; preserves order features, insensitivespecific positions. also discern finely number times featurehighly activated (Kalchbrenner et al., 2014).9.3 VariationsRather single convolutional layer, several convolutional layers may appliedparallel. example, may four different convolutional layers, differentwindow size range 25, capturing n-gram sequences varying lengths. resultconvolutional layer pooled, resulting vectors concatenatedfed processing (Kim, 2014).convolutional architecture need restricted linear ordering sentence. example, et al. (2015) generalize convolution operation worksyntactic dependency trees. There, window around node syntactic tree,pooling performed different nodes. Similarly, Liu et al. (2015) applyconvolutional architecture top dependency paths extracted dependency trees. LeZuidema (2015) propose perform max pooling vectors representing differentderivations leading chart item chart parser.10. Recurrent Neural Networks Modeling Sequences Stacksdealing language data, common work sequences, words(sequences letters), sentences (sequences words) documents. saw feedforward networks accommodate arbitrary feature functions sequencesuse vector concatenation vector addition (CBOW). particular, CBOW representations allows encode arbitrary length sequences fixed sized vectors. However,CBOW representation quite limited, forces one disregard order features. convolutional networks also allow encoding sequence fixed size vector.representations derived convolutional networks improvementCBOW representation offer sensitivity word order, order sensitivityrestricted mostly local patterns, disregards order patterns far apartsequence.Recurrent neural networks (RNNs) (Elman, 1990) allow representing arbitrarily sizedstructured inputs fixed-size vector, paying attention structured propertiesinput.10.1 RNN Abstractionuse xi:j denote sequence vectors xi , . . . , xj . RNN abstraction takesinput ordered list input vectors x1 , ..., xn together initial state vector s0 ,returns ordered list state vectors s1 , ..., sn , well ordered list outputvectors y1 , ..., yn . output vector yi function corresponding state vectorsi . input vectors xi presented RNN sequential fashion, statevector si output vector yi represent state RNN observing inputsx1:i . output vector yi used prediction. example, model389fiGoldbergpredicting conditional probability event e given sequence m1:i definedp(e = j|x1:i ) = softmax(yi W + b)[j], jth element output vector resultingsoftmax operation. RNN model provides framework conditioningentire history x1 , . . . , xi without resorting Markov assumption traditionallyused modeling sequences.63 Indeed, RNN-based language models result goodperplexity scores compared n-gram based models.Mathematically, recursively defined function R takes input statevector si input vector xi+1 , results new state vector si+1 . additionalfunction used map state vector si output vector yi .64 constructingRNN, much like constructing feed-forward network, one specify dimensioninputs xi well dimensions outputs yi . dimensions statessi function output dimension.65RNN(s0 , x1:n ) =s1:n , y1:nsi = R(si1 , xi )(36)yi = O(si )xi Rdin , yi Rdout , si Rf (dout )functions R across sequence positions, RNN keepstrack states computation state vector kept passedinvocations R.Graphically, RNN traditionally presented Figure 5.yisi1R,OxisiFigure 5: Graphical representation RNN (recursive).63. kth-order Markov assumption states observation time independent observationstimes (k + j) j > 0 given observations times 1, , k. assumptionbasis many sequence modeling technique n-gram models hidden markov models.64. Using function somewhat non-standard, used order unify different RNN modelspresented next section. Simple RNN (Elman RNN) GRU architectures,identity mapping, LSTM architecture selects fixed subset state.65. RNN architectures state dimension independent output dimensionpossible, current popular architectures, including Simple RNN, LSTM GRUfollow flexibility.390fiA Primer Neural Networks NLPpresentation follows recursive definition, correct arbitrary long sequences.However, finite sized input sequence (and input sequences deal finite)one unroll recursion, resulting structure Figure 6.y1s0R,Ox1y3y2s1R,Os2R,Ox2y4s3x3R,Ox4y5s4R,Os5x5Figure 6: Graphical representation RNN (unrolled).usually shown visualization, include parameters orderhighlight fact parameters shared across time steps. Differentinstantiations R result different network structures, exhibit differentproperties terms running times ability trained effectively usinggradient-based methods. However, adhere abstract interface.provide details concrete instantiations R Simple RNN, LSTMGRU Section 11. that, lets consider modeling RNN abstraction.First, note value si based entire input x1 , ..., xi . example,expanding recursion = 4 get:s4 =R(s3 , x4 )z }|3 {=R(R(s2 , x3 ), x4 )z }|2 {=R(R(R(s1 , x2 ), x3 ), x4 )(37)z }|1 {=R(R(R(R(s0 , x1 ), x2 ), x3 ), x4 )Thus, sn (as well yn ) could thought encoding entire input sequence.66encoding useful? depends definition usefulness. job networktraining set parameters R state conveys useful informationtask tying solve.66. Note that, unless R specifically designed this, likely later elements inputsequence stronger effect sn earlier ones.391fiGoldberg10.2 RNN TrainingViewed Figure 6 easy see unrolled RNN deep neuralnetwork (or rather, large computation graph somewhat complex nodes),parameters shared across many parts computation. trainRNN network, then, need create unrolled computation graphgiven input sequence, add loss node unrolled graph, use backward(backpropagation) algorithm compute gradients respect loss.procedure referred RNN literature backpropagation time, BPTT(Werbos, 1990).67 various ways supervision signal applied.10.2.1 AcceptorOne option base supervision signal final output vector, yn . Viewedway, RNN acceptor. observe final state, decide outcome.68example, consider training RNN read characters word one oneuse final state predict part-of-speech word (this inspired Linget al., 2015b), RNN reads sentence and, based final state decidesconveys positive negative sentiment (this inspired Wang et al., 2015b) RNNreads sequence words decides whether valid noun-phrase. losscases defined terms function yn = O(sn ), error gradientsbackpropagate rest sequence (see Figure 7).69 loss takefamiliar form cross entropy, hinge, margin, etc.10.2.2 EncoderSimilar acceptor case, encoder supervision uses final output vector, yn .However, unlike acceptor, prediction made solely basis finalvector, final vector treated encoding information sequence,used additional information together signals. example, extractivedocument summarization system may first run document RNN, resulting67. Variants BPTT algorithm include unrolling RNN fixed number input symbolstime: first unroll RNN inputs x1:k , resulting s1:k . Compute loss, backpropagateerror network (k steps back). Then, unroll inputs xk+1:2k , time using skinitial state, backpropagate error k steps, on. strategy basedobservations Simple-RNN variant, gradients k steps tend vanish (for large enoughk), omitting negligible. procedure allows training arbitrarily long sequences.RNN variants LSTM GRU designed specifically mitigate vanishinggradients problem, fixed size unrolling less motivated, yet still used, examplelanguage modeling book without breaking sentences. similar variant unrollsnetwork entire sequence forward step, propagates gradients back k stepsposition.68. terminology borrowed Finite-State Acceptors. However, RNN potentially infinitenumber states, making necessary rely function lookup table mapping statesdecisions.69. kind supervision signal may hard train long sequences, especially SimpleRNN, vanishing gradients problem. also generally hard learning task,tell process parts input focus.392fiA Primer Neural Networks NLPlosspredict &calc lossy5s0R,Os1x1R,Os2x2R,Os3x3R,Os4x4R,Ox5Figure 7: Acceptor RNN Training Graph.vector yn summarizing entire document. Then, yn used togetherfeatures order select sentences included summarization.10.2.3 TransducerAnother option treat RNN transducer, producing output inputreads in. Modeled way, compute local loss signal Llocal (yi , yi )outputs yPbased true label yi . loss unrolled sequence be:L(y1:n, y1:n ) = ni=1 Llocal (yi , yi ), using another combination rather sumaverage weighted average (see Figure 8). One example transducersequence tagger, take xi:n feature representations n wordssentence, yi input predicting tag assignment word basedwords 1:i. CCG super-tagger based architecture provides state-of-the artCCG super-tagging results (Xu et al., 2015).losssumpredict &calc losspredict &calc lossy1s0R,Ox1predict &calc lossy2s1R,Ox2predict &calc lossy3s2R,Ox3predict &calc lossy4s3R,Ox4y5s4R,Ox5Figure 8: Transducer RNN Training Graph.natural use-case transduction setup language modeling,sequence words x1:i used predict distribution (i + 1)th word. RNN basedlanguage models shown provide better perplexities traditional language models(Mikolov et al., 2010; Sundermeyer, Schluter, & Ney, 2012; Mikolov, 2012; Jozefowicz,Vinyals, Schuster, Shazeer, & Wu, 2016).Using RNNs transducers allows us relax Markov assumption traditionally taken language models HMM taggers, condition entire prediction393fiGoldberghistory. power ability condition arbitrarily long histories demonstratedgenerative character-level RNN models, text generated character character, character conditioning previous ones (Sutskever, Martens, & Hinton, 2011).generated texts show sensitivity properties captured n-gram languagemodels, including line lengths nested parenthesis balancing. good demonstrationanalysis properties RNN-based character level language models, see workKarpathy, Johnson, Li (2015).10.2.4 Encoder - DecoderFinally, important special case encoder scenario Encoder-Decoder framework(Cho, van Merrienboer, Bahdanau, & Bengio, 2014a; Sutskever et al., 2014). RNNused encode sequence vector representation yn , vector representationused auxiliary input another RNN used decoder. example,machine-translation setup first RNN encodes source sentence vectorrepresentation yn , state vector fed separate (decoder) RNNtrained predict (using transducer-like language modeling objective) wordstarget language sentence based previously predicted words well yn .supervision happens decoder RNN, gradients propagatedway back encoder RNN (see Figure 9).losssumpredict &calc losspredict &calc lossy1sd0RD ,ODy2sd1,OEx1se1sd2RD ,ODx2,OEx2se2predict &calc lossy3RD ,ODx1se0predict &calc lossy4sd3RD ,ODx3,OEx3se3predict &calc lossy5sd4RD ,ODx4,OEx4se4x5,OEse5x5Figure 9: Encoder-Decoder RNN Training Graph.approach shown surprisingly effective Machine Translation (Sutskeveret al., 2014) using LSTM RNNs. order technique work, Sutskever et al. foundeffective input source sentence reverse, xn corresponds first394fiA Primer Neural Networks NLPword sentence. way, easier second RNN establish relationfirst word source sentence first word target sentence.Another use-case encoder-decoder framework sequence transduction. Here,order generate tags t1 , . . . , tn , encoder RNN first used encode sentencex1:n fixed sized vector. vector fed initial state vector another(transducer) RNN, used together x1:n predict label ti positioni. approach used Filippova, Alfonseca, Colmenares, Kaiser, Vinyals (2015)model sentence compression deletion.10.3 Multi-layer (Stacked) RNNsRNNs stacked layers, forming grid (Hihi & Bengio, 1996). Consider k RNNs,jRNN1 , . . . , RNNk , jth RNN states sj1:n outputs y1:n. inputfirst RNN x1:n , input jth RNN (j 2) outputs RNNj1k .it, y1:n. output entire formation output last RNN, y1:nlayered architectures often called deep RNNs. visual representation 3-layerRNN given Figure 10.y1y2y13s30R3 ,O3y23s31y12s20R2 ,O2R1 ,O1x1R3 ,O3R2 ,O2R3 ,O3R2 ,O2R1 ,O1x2R1 ,O1x3R3 ,O3y53s34y42s23y31s12y5y43s33y32s22y21s11y4y33s32y22s21y11s10y3R2 ,O2R1 ,O1x4s35y52s24y41s13R3 ,O3R2 ,O2s25y51s14R1 ,O1s15x5Figure 10: 3-layer (deep) RNN architecture.theoretically clear additional power gained deeperarchitecture, observed empirically deep RNNs work better shallower onestasks. particular, Sutskever et al. (2014) report 4-layers deep architecture crucial achieving good machine-translation performance encoder-decoderframework. Irsoy Cardie (2014) also report improved results moving onelayer biRNN architecture several layers. Many works report result usinglayered RNN architectures, explicitly compare 1-layer RNNs.10.4 Bidirectional RNNs (biRNN)useful elaboration RNN bidirectional-RNN (biRNN, also commonly referredbiRNN) (Schuster & Paliwal, 1997; Graves, 2008).70 Consider task sequencetagging sentence x1 , . . . , xn . RNN allows us compute function ith word70. used specific RNN architecture LSTM, model called biLSTM.395fiGoldbergxi based past words x1:i including it. However, following wordsxi:n may also useful prediction, evident common sliding-window approachfocus word categorized based window k words surrounding it. Muchlike RNN relaxes Markov assumption allows looking arbitrarily backpast, biRNN relaxes fixed window size assumption, allowing look arbitrarily farpast future.Consider input sequence x1:n . biRNN works maintaining two separate states,fsi sbi input position i. forward state sfi based x1 , x2 , . . . , xi ,backward state sbi based xn , xn1 , . . . , xi . forward backward statesgenerated two different RNNs. first RNN (Rf , ) fed input sequence x1:nis, second RNN (Rb , Ob ) fed input sequence reverse. staterepresentation si composed forward backward states.output position based concatenation two output vectorsyi = [yif ; yib ] = [Of (sfi ); Ob (sbi )], taking account past future.vector yi used directly prediction, fed part inputcomplex network. two RNNs run independently other, error gradients position flow forward backward two RNNs. visualrepresentation biRNN architecture given Figure 11.ytheybrownconcatconcatsb5Rb ,Oby1fsf0Rf ,Ofxtheconcaty4by5bsb44Rb ,Obsb33Rf ,OfRb ,Oby3fsf2Rf ,Ofxbrownxfoxconcaty3by2fsf1yjumpedyfoxconcaty2bsb22Rb ,Oby4fsf3Rf ,Ofxjumpedy1bsb11sb00Rb ,Oby5fsf4sf5Rf ,OfxFigure 11: biRNN sentence brown fox jumped ..use biRNNs sequence tagging introduced NLP community IrsoyCardie (2014).10.5 RNNs Representing Stacksalgorithms language processing, including transition-based parsing (Nivre,2008), require performing feature extraction stack. Instead confinedlooking k top-most elements stack, RNN framework used providefixed-sized vector encoding entire stack.main intuition stack essentially sequence, stack staterepresented taking stack elements feeding order RNN, resultingfinal encoding entire stack. order computation efficiently (without396fiA Primer Neural Networks NLPperforming O(n) stack encoding operation time stack changes), RNN statemaintained together stack state. stack push-only, wouldtrivial: whenever new element x pushed stack, corresponding vector xused together RNN state si order obtain new state si+1 . Dealingpop operation challenging, solved using persistent-stackdata-structure (Okasaki, 1999; Goldberg, Zhao, & Huang, 2013). Persistent, immutable,data-structures keep old versions intact modified. persistent stackconstruction represents stack pointer head linked list. empty stackempty list. push operation appends element list, returning new head.pop operation returns parent head, keeping original list intact.point view someone held pointer previous head, stackchange. subsequent push operation add new child node. Applyingprocedure throughout lifetime stack results tree, rootempty stack path node root represents intermediary stack state.Figure 12 provides example tree. process appliedcomputation graph construction, creating RNN tree structure instead chainstructure. Backpropagating error given node affect elementsparticipated stack node created, order. Figure 13 showscomputation graph stack-RNN corresponding last state Figure 12.modeling approach proposed independently Dyer et al. (2015) WatanabeSumita (2015) transition-based dependency parsing.headheadhead(1) pushheadb(2) push bbheadc(3) push cbc(4) pop(5) pushheadbhead(6) popcbcbcbheadeecbfchead(7) pop(8) push e(9) push fFigure 12: immutable stack construction sequence operations push a; push b;push c; pop; push d; pop; pop; push e; push f.10.6 Note Reading LiteratureUnfortunately, often case inferring exact model form readingdescription research paper quite challenging. Many aspects models397fiGoldbergya,eR,Oya,e,fsa,eya,b,d xesayaR,Oxaya:bsaR,Oxbsa:bya:cR,Osa,e,fxfsa,b,dR,Osa:bR,Oxdsa:cxcFigure 13: stack-RNN corresponding final state Figure 12.yet standardized, different researchers use terms refer slightlydifferent things. list examples, inputs RNN either one-hot vectors(in case embedding matrix internal RNN) embedded representations;input sequence padded start-of-sequence and/or end-of-sequence symbols,not; output RNN usually assumed vector expectedfed additional layers followed softmax prediction (as casepresentation tutorial), papers assume softmax part RNN itself;multi-layer RNN, state vector either output top-most layer,concatenation outputs layers; using encoder-decoder framework,conditioning output encoder interpreted various different ways;on. top that, LSTM architecture described next section many smallvariants, referred common name LSTM. choicesmade explicit papers, require careful reading, others still evenmentioned, hidden behind ambiguous figures phrasing.reader, aware issues reading interpret model descriptions.writer, aware issues well: either fully specify model mathematicalnotation, refer different source model fully specified, sourceavailable. using default implementation software package without knowingdetails, explicit fact specify software package use. case,dont rely solely figures natural language text describing model,often ambiguous.398fiA Primer Neural Networks NLP11. Concrete RNN Architecturesturn present three different instantiations abstract RN N architecturediscussed previous section, providing concrete definitions functions R O.Simple RNN (SRNN), Long Short-Term Memory (LSTM) GatedRecurrent Unit (GRU).11.1 Simple RNNsimplest RNN formulation, known Elman Network Simple-RNN (S-RNN),proposed Elman (1990) explored use language modeling Mikolov (2012).S-RNN takes following form:si =Rsrnn (si1 , xi ) = g(xi Wx + si1 Ws + b)yi =Osrnn (si ) = si(38)si , yi Rds , xi Rdx , Wx Rdx ds , Ws Rds ds , b Rdsis, state position linear combination input positionprevious state, passed non-linear activation (commonly tanh ReLU).output position hidden state position.71spite simplicity, Simple RNN provides strong results sequence tagging(Xu et al., 2015) well language modeling. comprehensive discussion usingSimple RNNs language modeling, see PhD thesis Mikolov (2012).11.2 LSTMS-RNN hard train effectively vanishing gradients problem (Pascanuet al., 2012). Error signals (gradients) later steps sequence diminish quicklyback-propagation process, reach earlier input signals, making hardS-RNN capture long-range dependencies. Long Short-Term Memory (LSTM)architecture (Hochreiter & Schmidhuber, 1997) designed solve vanishing gradientsproblem. main idea behind LSTM introduce part state representationalso memory cells (a vector) preserve gradients across time. Accessmemory cells controlled gating components smooth mathematical functionssimulate logical gates. input state, gate used decide much newinput written memory cell, much current contentmemory cell forgotten. Concretely, gate g [0, 1]n vector valuesrange [0, 1] multiplied component-wise another vector v Rn , resultadded another vector. values g designed close either 0 1, i.e.using sigmoid function. Indices v corresponding near-one values g allowedpass, corresponding near-zero values blocked.71. authors treat output position complicated function state, e.g. lineartransformation, MLP. presentation, transformation outputconsidered part RNN, separate computations applied RNNs output.399fiGoldbergMathematically, LSTM architecture defined as:72sj = Rlstm (sj1 , xj ) =[cj ; hj ]cj =cj1 fi f + g fihj = tanh(cj ) fi=(xj Wxi + hj1 Whi )f =(xj Wxf + hj1 Whf )=(xj Wxo+ hj1 Who(39))g = tanh(xj Wxg + hj1 Whg )yj = Olstm (sj ) =hjsj R2dh , xi Rdx , cj , hj , i, f , o, g Rdh , Wx Rdx dh , Wh Rdh dh ,symbol fi used denote component-wise product. state time j composed two vectors, cj hj , cj memory component hj hiddenstate component. three gates, i, f o, controlling input, f orget output.gate values computed based linear combinations current input xjprevious state hj1 , passed sigmoid activation function. update candidate gcomputed linear combination xj hj1 , passed tanh activation function. memory cj updated: forget gate controls much previousmemory keep (cj1 fi f ), input gate controls much proposed updatekeep (g fi i). Finally, value hj (which also output yj ) determined basedcontent memory cj , passed tanh non-linearity controlledoutput gate. gating mechanisms allow gradients related memory part cjstay high across long time ranges.discussion LSTM architecture see PhD thesis Alex Graves(2008), well online-post Olah (2015b). analysis behaviorLSTM used character-level language model, see work Karpathy et al.(2015).explanation motivation behind gating mechanism LSTM(and GRU) relation solving vanishing gradient problem recurrent neuralnetworks, see Sections 4.2 4.3 detailed course notes Cho (2015).LSTMs currently successful type RNN architecture, responsible many state-of-the-art sequence modeling results. main competitorLSTM-RNN GRU, discussed next.72. many variants LSTM architecture presented here. example, forget gatespart original proposal Hochreiter Schmidhuber (1997), shown importantpart architecture. variants include peephole connections gate-tying. overviewcomprehensive empirical comparison various LSTM architectures see work Greff, Srivastava,Koutnk, Steunebrink, Schmidhuber (2015).400fiA Primer Neural Networks NLP11.2.1 Practical Considerationstraining LSTM networks, Jozefowicz et al. (2015) strongly recommend alwaysinitialize bias term forget gate close one. applying dropoutRNN LSTM, Zaremba et al. (2014) found crucial apply dropoutnon-recurrent connection, i.e. apply layerssequence positions.11.3 GRULSTM architecture effective, also quite complicated. complexitysystem makes hard analyze, also computationally expensive work with.gated recurrent unit (GRU) recently introduced Cho et al. (2014b) alternativeLSTM. subsequently shown Chung et al. (2014) perform comparablyLSTM several (non textual) datasets.Like LSTM, GRU also based gating mechanism, substantiallyfewer gates without separate memory component.sj = RGRU (sj1 , xj ) =(1 z) fi sj1 + z fi sjz =(xj Wxz + sj1 Wsz )r =(xj Wxr + sj1 Wsr )sj = tanh(xj Wxs + (sj1 fi r)Wsg )(40)yj = OGRU (sj ) =sjsj , sj Rds , xi Rdx , z, r Rds , Wx Rdx ds , Ws Rds ds ,One gate (r) used control access previous state sj1 compute proposed update sj . updated state sj (which also serves output yj ) determined basedinterpolation previous state sj1 proposal sj , proportionsinterpolation controlled using gate z.73GRU shown effective language modeling machine translation.However, jury still GRU, LSTM possible alternative RNNarchitectures, subject actively researched. empirical explorationGRU LSTM architectures, see work Jozefowicz et al. (2015).11.4 Variantsgated architectures LSTM GRU help alleviating vanishing gradients problem Simple RNN, allow RNNs capture dependencies spanlong time ranges. researchers explore simpler architectures LSTMGRU achieving similar benefits.Mikolov et al. (2014) observed matrix multiplication si1 Ws couplednonlinearity g update rule R Simple RNN causes state vector si undergo73. states often called h GRU literature.401fiGoldberglarge changes time step, prohibiting remembering information longtime periods. propose split state vector si slow changing component ci(context units) fast changing component hi .74 slow changing component ciupdated according linear interpolation input previous component: ci =(1 )xi Wx1 + ci1 , (0, 1). update allows ci accumulate previousinputs. fast changing component hi updated similarly Simple RNN updaterule, changed take ci account well:75 hi = (xi Wx2 + hi1 Wh + ci Wc ).Finally, output yi concatenation slow fast changing partsstate: yi = [ci ; hi ]. Mikolov et al. demonstrate architecture provides competitiveperplexities much complex LSTM language modeling tasks.approach Mikolov et al. interpreted constraining blockmatrix Ws S-RNN corresponding ci multiply identity matrix (seeMikolov et al. (2014) details). Le, Jaitly, Hinton (2015) propose even simplerapproach: set activation function S-RNN ReLU, initialize biases bzeroes matrix Ws identify matrix. causes untrained RNN copyprevious state current state, add effect current input xi setnegative values zero. setting initial bias towards state copying, trainingprocedure allows Ws change freely. Le et al. demonstrate simple modificationmakes S-RNN comparable LSTM number parameters severaltasks, including language modeling.12. Modeling Trees Recursive Neural NetworksRNN useful modeling sequences. language processing, often naturaldesirable work tree structures. trees syntactic trees, discourse trees,even trees representing sentiment expressed various parts sentence (Socheret al., 2013). may want predict values based specific tree nodes, predict valuesbased root nodes, assign quality score complete tree part tree.cases, may care tree structure directly rather reason spanssentence. cases, tree merely used backbone structure helpsguide encoding process sequence fixed size vector.recursive neural network (RecNN) abstraction (Pollack, 1990), popularized NLPRichard Socher colleagues (Socher, Manning, & Ng, 2010; Socher, Lin, Ng, & Manning, 2011; Socher et al., 2013; Socher, 2014) generalization RNN sequences(binary) trees.76Much like RNN encodes sentence prefix state vector, RecNN encodestree-node state vector Rd . use state vectors either predictvalues corresponding nodes, assign quality values node, semanticrepresentation spans rooted nodes.74. depart notation Mikolov et al. (2014) reuse symbols used LSTM description.75. update rule diverges S-RNN update rule also fixing non-linearity sigmoidfunction, using bias term. However, changes discussed centralproposal.76. presented terms binary parse trees, concepts easily transfer general recursively-defineddata structures, major technical challenge definition effective form R,combination function.402fiA Primer Neural Networks NLPmain intuition behind recursive neural networks subtree represented dimensional vector, representation node p children c1 c2function representation nodes: vec(p) = f (vec(c1 ), vec(c2 )), fcomposition function taking two d-dimensional vectors returning single d-dimensionalvector. Much like RNN state si used encode entire sequence x1 : i, RecNNstate associated tree node p encodes entire subtree rooted p. See Figure 14illustration.S=combineN P2 =VP =combineN P1 =V =Figure 14: Illustration recursive neural network. representations V NP1combined form representation VP. representations VPNP2 combined form representation S.12.1 Formal DefinitionConsider binary parse tree n-word sentence. reminder, ordered,unlabeled tree string x1 , . . . , xn represented unique set triplets (i, k, j),s.t. k j. triplet indicates node spanning words xi:j parentnodes spanning xi:k xk+1:j . Triplets form (i, i, i) correspond terminal symbolstree leaves (the words xi ). Moving unlabeled case labeled one,represent tree set 6-tuples (A B, C, i, k, j), whereas i, k j indicate spansbefore, A, B C node labels nodes spanning xi:j , xi:k xk+1:jrespectively. Here, leaf nodes form (A A, A, i, i, i), pre-terminalsymbol. refer tuples production rules. example, consider syntactictree sentence boy saw duck.403fiGoldbergVPNPNPDet Noun VerbboysawDet Nounduckcorresponding unlabeled labeled representations :Unlabeled(1,1,1)(2,2,2)(3,3,3)(4,4,4)(5,5,5)(4,4,5)(3,3,5)(1,1,2)(1,2,5)Labeled(Det, Det, Det, 1, 1, 1)(Noun, Noun, Noun, 2, 2, 2)(Verb, Verb, Verb, 3, 3, 3)(Det, Det, Det, 4, 4, 4)(Noun, Noun, Noun, 5, 5, 5)(NP, Det, Noun, 4, 4, 5)(VP, Verb, NP, 3, 3, 5)(NP, Det, Noun, 1, 1, 2)(S, NP, VP, 1, 2, 5)Corresponding Spanx1:1x2:2 boysawduckducksaw duckboyboy saw duckset production rules uniquely converted set tree nodes qi:j(indicating node symbol span xi:j ) simply ignoring elements(B, C, k) production rule. position define recursive neuralnetwork.recursive neural network (RecNN) function takes input parse treen-word sentence x1 , . . . , xn . sentences words represented d-dimensionalvector xi , tree represented set production rules (A B, C, i, j, k).. RecNN returns output corresponding setDenote nodes qi:jinside state vectors si:j , inside state vector sAi:j R represents corresponding, encodes entire structure rooted node. Like sequence RNN,tree node qi:jtree shaped RecNN defined recursively using function R, inside vectorgiven node defined function inside vectors direct children.77 Formally:RecNN(x1 , . . . , xn , ) ={sAi:j R | qi:j }sAi:i =v(xi )BCsAi:j =R(A, B, C, si:k , sk+1:j )(41)BC, qk+1:jqi:k77. Le Zuidema (2014) extend RecNN definition node has, addition insidestate vector, also outside state vector representing entire structure around subtree rootednode. formulation based recursive computation classic inside-outsidealgorithm, thought biRNN counterpart tree RecNN. details, see workLe Zuidema.404fiA Primer Neural Networks NLPfunction R usually takes form simple linear transformation, maymay followed non-linear activation function g:CBCR(A, B, C, sBi:k , sk+1:j ) = g([si:k ; sk+1:j ]W)(42)formulation R ignores tree labels, using matrix W R2ddcombinations. may useful formulation case node labels exist (e.g.tree represent syntactic structure clearly defined labels)unreliable. However, labels available, generally useful includecomposition function. One approach would introduce label embeddings v(A)mapping non-terminal symbol dnt dimensional vector, change R includeembedded symbols combination function:CBCR(A, B, C, sBi:k , sk+1:j ) = g([si:k ; sk+1:j ; v(A); v(B)]W)(43)(here, W R2d+2dnt ). approach taken Qian, Tian, Huang, Liu, Zhu,Zhu (2015). alternative approach, due Socher et al. (2013) untie weightsaccording non-terminals, using different composition matrix B, C pairsymbols:78BCCBC)R(A, B, C, sBi:k , sk+1:j ) = g([si:k ; sk+1:j ]W(44)formulation useful number non-terminal symbols (or numberpossible symbol combinations) relatively small, usually case phrase-structureparse trees. similar model also used Hashimoto et al. (2013) encode subtreessemantic-relation classification task.12.2 Extensions Variationsdefinitions R suffer vanishing gradients problemSimple RNN, several authors sought replace functions inspired Long ShortTerm Memory (LSTM) gated architecture, resulting Tree-shaped LSTMs (Tai, Socher, &Manning, 2015; Zhu, Sobhani, & Guo, 2015b). question optimal tree representationstill much open research question, vast space possible combinationfunctions R yet explored. proposed variants tree-structured RNNs includesrecursive matrix-vector model (Socher, Huval, Manning, & Ng, 2012) recursive neuraltensor network (Socher et al., 2013). first variant, word representedcombination vector matrix, vector defines words static semanticcontent before, matrix acts learned operator word, allowingsubtle semantic compositions addition weighted averaging impliedconcatenation followed linear transformation function. second variant, wordsassociated vectors usual, composition function becomes expressivebasing tensor instead matrix operations.78. explored literature, trivial extension would condition transformation matrix alsoA.405fiGoldberg12.3 Training Recursive Neural Networkstraining procedure recursive neural network follows recipe trainingforms networks: define loss, spell computation graph, compute gradientsusing backpropagation79 , train parameters using SGD.regard loss function, similar sequence RNN one associate losseither root tree, given node, set nodes, caseindividual nodes losses combined, usually summation. loss function basedlabeled training data associates label quantity different treenodes.Additionally, one treat RecNN Encoder, whereas inside-vector associated node taken encoding tree rooted node. encodingpotentially sensitive arbitrary properties structure. vectorpassed input another network.discussion recursive neural networks use natural languagetasks, refer PhD thesis Richard Socher (2014).13. ConclusionsNeural networks powerful learners, providing opportunities ranging non-linearclassification non-Markovian modeling sequences trees. hope exposition helps NLP researchers incorporate neural network models work takeadvantage power.ReferencesAdel, H., Vu, N. T., & Schultz, T. (2013). Combination Recurrent Neural NetworksFactored Language Models Code-Switching Language Modeling. Proceedings51st Annual Meeting Association Computational Linguistics (Volume 2: Short Papers), pp. 206211, Sofia, Bulgaria. Association ComputationalLinguistics.Ando, R., & Zhang, T. (2005a). High-Performance Semi-Supervised Learning MethodText Chunking. Proceedings 43rd Annual Meeting AssociationComputational Linguistics (ACL05), pp. 19, Ann Arbor, Michigan. AssociationComputational Linguistics.Ando, R. K., & Zhang, T. (2005b). framework learning predictive structuresmultiple tasks unlabeled data. Journal Machine Learning Research, 6,18171853.Auli, M., Galley, M., Quirk, C., & Zweig, G. (2013). Joint Language Translation Modeling Recurrent Neural Networks. Proceedings 2013 ConferenceEmpirical Methods Natural Language Processing, pp. 10441054, Seattle, Washington, USA. Association Computational Linguistics.79. introduction computation graph abstraction, specific backpropagation procedurecomputing gradients RecNN defined referred Back-propagationStructure (BPTS) algorithm (Goller & Kuchler, 1996).406fiA Primer Neural Networks NLPAuli, M., & Gao, J. (2014). Decoder Integration Expected BLEU Training RecurrentNeural Network Language Models. Proceedings 52nd Annual MeetingAssociation Computational Linguistics (Volume 2: Short Papers), pp. 136142,Baltimore, Maryland. Association Computational Linguistics.Ballesteros, M., Dyer, C., & Smith, N. A. (2015). Improved Transition-based ParsingModeling Characters instead Words LSTMs. Proceedings 2015 Conference Empirical Methods Natural Language Processing, pp. 349359, Lisbon,Portugal. Association Computational Linguistics.Ballesteros, M., Goldberg, Y., Dyer, C., & Smith, N. A. (2016). Training ExplorationImproves Greedy Stack-LSTM Parser. arXiv:1603.03793 [cs].Bansal, M., Gimpel, K., & Livescu, K. (2014). Tailoring Continuous Word RepresentationsDependency Parsing. Proceedings 52nd Annual Meeting AssociationComputational Linguistics (Volume 2: Short Papers), pp. 809815, Baltimore,Maryland. Association Computational Linguistics.Baydin, A. G., Pearlmutter, B. A., Radul, A. A., & Siskind, J. M. (2015). Automaticdifferentiation machine learning: survey. arXiv:1502.05767 [cs].Bengio, Y. (2012). Practical recommendations gradient-based training deep architectures. arXiv:1206.5533 [cs].Bengio, Y., Ducharme, R., Vincent, P., & Janvin, C. (2003). Neural Probabilistic Language Model. J. Mach. Learn. Res., 3, 11371155.Bengio, Y., Goodfellow, I. J., & Courville, A. (2015). Deep Learning. Book preparationMIT Press.Bitvai, Z., & Cohn, T. (2015). Non-Linear Text Regression Deep ConvolutionalNeural Network. Proceedings 53rd Annual Meeting AssociationComputational Linguistics 7th International Joint Conference Natural Language Processing (Volume 2: Short Papers), pp. 180185, Beijing, China. AssociationComputational Linguistics.Botha, J. A., & Blunsom, P. (2014). Compositional Morphology Word RepresentationsLanguage Modelling. Proceedings 31st International ConferenceMachine Learning (ICML), Beijing, China. *Award best application paper*.Bottou, L. (2012). Stochastic gradient descent tricks. Neural Networks: TricksTrade, pp. 421436. Springer.Charniak, E., & Johnson, M. (2005). Coarse-to-Fine n-Best Parsing MaxEnt Discriminative Reranking. Proceedings 43rd Annual Meeting AssociationComputational Linguistics (ACL05), pp. 173180, Ann Arbor, Michigan. AssociationComputational Linguistics.Chen, D., & Manning, C. (2014). Fast Accurate Dependency Parser using NeuralNetworks. Proceedings 2014 Conference Empirical Methods NaturalLanguage Processing (EMNLP), pp. 740750, Doha, Qatar. Association Computational Linguistics.407fiGoldbergChen, Y., Xu, L., Liu, K., Zeng, D., & Zhao, J. (2015). Event Extraction via DynamicMulti-Pooling Convolutional Neural Networks. Proceedings 53rd AnnualMeeting Association Computational Linguistics 7th InternationalJoint Conference Natural Language Processing (Volume 1: Long Papers), pp. 167176, Beijing, China. Association Computational Linguistics.Cho, K. (2015). Natural Language Understanding Distributed Representation.arXiv:1511.07916 [cs, stat].Cho, K., van Merrienboer, B., Bahdanau, D., & Bengio, Y. (2014a). PropertiesNeural Machine Translation: EncoderDecoder Approaches. Proceedings SSST8, Eighth Workshop Syntax, Semantics Structure Statistical Translation,pp. 103111, Doha, Qatar. Association Computational Linguistics.Cho, K., van Merrienboer, B., Gulcehre, C., Bahdanau, D., Bougares, F., Schwenk, H., &Bengio, Y. (2014b). Learning Phrase Representations using RNN EncoderDecoderStatistical Machine Translation. Proceedings 2014 Conference EmpiricalMethods Natural Language Processing (EMNLP), pp. 17241734, Doha, Qatar.Association Computational Linguistics.Chrupala, G. (2014). Normalizing tweets edit scripts recurrent neural embeddings.Proceedings 52nd Annual Meeting Association Computational Linguistics (Volume 2: Short Papers), pp. 680686, Baltimore, Maryland. AssociationComputational Linguistics.Chung, J., Gulcehre, C., Cho, K., & Bengio, Y. (2014). Empirical Evaluation GatedRecurrent Neural Networks Sequence Modeling. arXiv:1412.3555 [cs].Collins, M. (2002). Discriminative Training Methods Hidden Markov Models: TheoryExperiments Perceptron Algorithms. Proceedings 2002 Conference Empirical Methods Natural Language Processing, pp. 18. AssociationComputational Linguistics.Collins, M., & Koo, T. (2005). Discriminative Reranking Natural Language Parsing.Computational Linguistics, 31 (1), 2570.Collobert, R., & Weston, J. (2008). unified architecture natural language processing:Deep neural networks multitask learning. Proceedings 25th internationalconference Machine learning, pp. 160167. ACM.Collobert, R., Weston, J., Bottou, L., Karlen, M., Kavukcuoglu, K., & Kuksa, P. (2011).Natural language processing (almost) scratch. Journal Machine LearningResearch, 12, 24932537.Crammer, K., & Singer, Y. (2002). algorithmic implementation multiclass kernelbased vector machines. Journal Machine Learning Research, 2, 265292.Creutz, M., & Lagus, K. (2007). Unsupervised Models Morpheme SegmentationMorphology Learning. ACM Trans. Speech Lang. Process., 4 (1), 3:13:34.Cybenko, G. (1989). Approximation superpositions sigmoidal function. MathematicsControl, Signals Systems, 2 (4), 303314.408fiA Primer Neural Networks NLPDahl, G., Sainath, T., & Hinton, G. (2013). Improving deep neural networks LVCSRusing rectified linear units dropout. 2013 IEEE International ConferenceAcoustics, Speech Signal Processing (ICASSP), pp. 86098613.Dauphin, Y. N., Pascanu, R., Gulcehre, C., Cho, K., Ganguli, S., & Bengio, Y. (2014).Identifying attacking saddle point problem high-dimensional non-convexoptimization. Ghahramani, Z., Welling, M., Cortes, C., Lawrence, N. D., & Weinberger, K. Q. (Eds.), Advances Neural Information Processing Systems 27, pp.29332941. Curran Associates, Inc.de Gispert, A., Iglesias, G., & Byrne, B. (2015). Fast Accurate Preordering SMTusing Neural Networks. Proceedings 2015 Conference North AmericanChapter Association Computational Linguistics: Human Language Technologies, pp. 10121017, Denver, Colorado. Association Computational Linguistics.Do, T., Arti, T., & others (2010). Neural conditional random fields. InternationalConference Artificial Intelligence Statistics, pp. 177184.Dong, L., Wei, F., Tan, C., Tang, D., Zhou, M., & Xu, K. (2014). Adaptive Recursive NeuralNetwork Target-dependent Twitter Sentiment Classification. Proceedings52nd Annual Meeting Association Computational Linguistics (Volume2: Short Papers), pp. 4954, Baltimore, Maryland. Association ComputationalLinguistics.Dong, L., Wei, F., Zhou, M., & Xu, K. (2015). Question Answering FreebaseMulti-Column Convolutional Neural Networks. Proceedings 53rd AnnualMeeting Association Computational Linguistics 7th InternationalJoint Conference Natural Language Processing (Volume 1: Long Papers), pp. 260269, Beijing, China. Association Computational Linguistics.dos Santos, C., & Gatti, M. (2014). Deep Convolutional Neural Networks SentimentAnalysis Short Texts. Proceedings COLING 2014, 25th International Conference Computational Linguistics: Technical Papers, pp. 6978, Dublin, Ireland.Dublin City University Association Computational Linguistics.dos Santos, C., Xiang, B., & Zhou, B. (2015). Classifying Relations RankingConvolutional Neural Networks. Proceedings 53rd Annual MeetingAssociation Computational Linguistics 7th International Joint Conference Natural Language Processing (Volume 1: Long Papers), pp. 626634, Beijing,China. Association Computational Linguistics.dos Santos, C., & Zadrozny, B. (2014). Learning Character-level Representations Partof-Speech Tagging. Proceedings 31st International Conference MachineLearning (ICML), pp. 18181826.Duchi, J., Hazan, E., & Singer, Y. (2011). Adaptive subgradient methods online learningstochastic optimization. Journal Machine Learning Research, 12, 21212159.Duh, K., Neubig, G., Sudoh, K., & Tsukada, H. (2013). Adaptation Data Selection using Neural Language Models: Experiments Machine Translation. Proceedings409fiGoldberg51st Annual Meeting Association Computational Linguistics (Volume 2: Short Papers), pp. 678683, Sofia, Bulgaria. Association ComputationalLinguistics.Durrett, G., & Klein, D. (2015). Neural CRF Parsing. Proceedings 53rd AnnualMeeting Association Computational Linguistics 7th InternationalJoint Conference Natural Language Processing (Volume 1: Long Papers), pp. 302312, Beijing, China. Association Computational Linguistics.Dyer, C., Ballesteros, M., Ling, W., Matthews, A., & Smith, N. A. (2015). TransitionBased Dependency Parsing Stack Long Short-Term Memory. Proceedings53rd Annual Meeting Association Computational Linguistics7th International Joint Conference Natural Language Processing (Volume 1: LongPapers), pp. 334343, Beijing, China. Association Computational Linguistics.Elman, J. L. (1990). Finding Structure Time. Cognitive Science, 14 (2), 179211.Faruqui, M., & Dyer, C. (2014). Improving Vector Space Word Representations Using Multilingual Correlation. Proceedings 14th Conference European ChapterAssociation Computational Linguistics, pp. 462471, Gothenburg, Sweden.Association Computational Linguistics.Filippova, K., Alfonseca, E., Colmenares, C. A., Kaiser, L., & Vinyals, O. (2015). SentenceCompression Deletion LSTMs. Proceedings 2015 ConferenceEmpirical Methods Natural Language Processing, pp. 360368, Lisbon, Portugal.Association Computational Linguistics.Forcada, M. L., & Neco, R. P. (1997). Recursive hetero-associative memories translation.Biological Artificial Computation: Neuroscience Technology, pp. 453462. Springer.Gao, J., Pantel, P., Gamon, M., He, X., & Deng, L. (2014). Modeling InterestingnessDeep Neural Networks. Proceedings 2014 Conference Empirical MethodsNatural Language Processing (EMNLP), pp. 213, Doha, Qatar. AssociationComputational Linguistics.Gimenez, J., & Marquez, L. (2004). SVMTool: general POS tagger generator basedSupport Vector Machines. Proceedings 4th LREC, Lisbon, Portugal.Glorot, X., & Bengio, Y. (2010). Understanding difficulty training deep feedforwardneural networks. International conference artificial intelligence statistics,pp. 249256.Glorot, X., Bordes, A., & Bengio, Y. (2011). Deep sparse rectifier neural networks.International Conference Artificial Intelligence Statistics, pp. 315323.Goldberg, Y., & Elhadad, M. (2010). Efficient Algorithm Easy-First Non-DirectionalDependency Parsing. Human Language Technologies: 2010 Annual ConferenceNorth American Chapter Association Computational Linguistics, pp.742750, Los Angeles, California. Association Computational Linguistics.Goldberg, Y., & Levy, O. (2014). word2vec Explained: deriving Mikolov et al.s negativesampling word-embedding method. arXiv:1402.3722 [cs, stat].410fiA Primer Neural Networks NLPGoldberg, Y., & Nivre, J. (2013). Training Deterministic Parsers Non-DeterministicOracles. Transactions Association Computational Linguistics, 1 (0), 403414.Goldberg, Y., Zhao, K., & Huang, L. (2013). Efficient Implementation Beam-SearchIncremental Parsers. Proceedings 51st Annual Meeting AssociationComputational Linguistics (Volume 2: Short Papers), pp. 628633, Sofia, Bulgaria.Association Computational Linguistics.Goller, C., & Kuchler, A. (1996). Learning Task-Dependent Distributed RepresentationsBackpropagation Structure. Proc. ICNN-96, pp. 347352.IEEE.Gouws, S., Bengio, Y., & Corrado, G. (2015). BilBOWA: Fast Bilingual Distributed Representations without Word Alignments. Proceedings 32nd InternationalConference Machine Learning, pp. 748756.Graves, A. (2008). Supervised sequence labelling recurrent neural networks. Ph.D.thesis, Technische Universitat Munchen.Greff, K., Srivastava, R. K., Koutnk, J., Steunebrink, B. R., & Schmidhuber, J. (2015).LSTM: Search Space Odyssey. arXiv:1503.04069 [cs].Hal Daume III, Langford, J., & Marcu, D. (2009). Search-based Structured Prediction.Machine Learning Journal (MLJ).Harris, Z. (1954). Distributional Structure. Word, 10 (23), 146162.Hashimoto, K., Miwa, M., Tsuruoka, Y., & Chikayama, T. (2013). Simple CustomizationRecursive Neural Networks Semantic Relation Classification. Proceedings2013 Conference Empirical Methods Natural Language Processing, pp.13721376, Seattle, Washington, USA. Association Computational Linguistics.He, K., Zhang, X., Ren, S., & Sun, J. (2015). Delving Deep Rectifiers: SurpassingHuman-Level Performance ImageNet Classification. arXiv:1502.01852 [cs].Henderson, M., Thomson, B., & Young, S. (2013). Deep Neural Network ApproachDialog State Tracking Challenge. Proceedings SIGDIAL 2013 Conference,pp. 467471, Metz, France. Association Computational Linguistics.Hermann, K. M., & Blunsom, P. (2013). Role Syntax Vector Space ModelsCompositional Semantics. Proceedings 51st Annual Meeting Association Computational Linguistics (Volume 1: Long Papers), pp. 894904, Sofia,Bulgaria. Association Computational Linguistics.Hermann, K. M., & Blunsom, P. (2014). Multilingual Models Compositional DistributedSemantics. Proceedings 52nd Annual Meeting Association Computational Linguistics (Volume 1: Long Papers), pp. 5868, Baltimore, Maryland.Association Computational Linguistics.Hihi, S. E., & Bengio, Y. (1996). Hierarchical Recurrent Neural Networks Long-TermDependencies. Touretzky, D. S., Mozer, M. C., & Hasselmo, M. E. (Eds.), AdvancesNeural Information Processing Systems 8, pp. 493499. MIT Press.411fiGoldbergHill, F., Cho, K., Jean, S., Devin, C., & Bengio, Y. (2014). Embedding Word SimilarityNeural Machine Translation. arXiv:1412.6448 [cs].Hinton, G. E., Srivastava, N., Krizhevsky, A., Sutskever, I., & Salakhutdinov, R. R.(2012). Improving neural networks preventing co-adaptation feature detectors.arXiv:1207.0580 [cs].Hochreiter, S., & Schmidhuber, J. (1997). Long short-term memory. Neural computation,9 (8), 17351780.Hornik, K., Stinchcombe, M., & White, H. (1989). Multilayer feedforward networksuniversal approximators. Neural Networks, 2 (5), 359366.Ioffe, S., & Szegedy, C. (2015). Batch Normalization: Accelerating Deep Network TrainingReducing Internal Covariate Shift. arXiv:1502.03167 [cs].Irsoy, O., & Cardie, C. (2014). Opinion Mining Deep Recurrent Neural Networks.Proceedings 2014 Conference Empirical Methods Natural LanguageProcessing (EMNLP), pp. 720728, Doha, Qatar. Association Computational Linguistics.Iyyer, M., Boyd-Graber, J., Claudino, L., Socher, R., & Daume III, H. (2014a). NeuralNetwork Factoid Question Answering Paragraphs. Proceedings 2014Conference Empirical Methods Natural Language Processing (EMNLP), pp.633644, Doha, Qatar. Association Computational Linguistics.Iyyer, M., Enns, P., Boyd-Graber, J., & Resnik, P. (2014b). Political Ideology DetectionUsing Recursive Neural Networks. Proceedings 52nd Annual MeetingAssociation Computational Linguistics (Volume 1: Long Papers), pp. 11131122,Baltimore, Maryland. Association Computational Linguistics.Iyyer, M., Manjunatha, V., Boyd-Graber, J., & Daume III, H. (2015). Deep UnorderedComposition Rivals Syntactic Methods Text Classification. Proceedings53rd Annual Meeting Association Computational Linguistics 7thInternational Joint Conference Natural Language Processing (Volume 1: Long Papers), pp. 16811691, Beijing, China. Association Computational Linguistics.Johnson, R., & Zhang, T. (2015). Effective Use Word Order Text CategorizationConvolutional Neural Networks. Proceedings 2015 Conference NorthAmerican Chapter Association Computational Linguistics: Human Language Technologies, pp. 103112, Denver, Colorado. Association ComputationalLinguistics.Jozefowicz, R., Vinyals, O., Schuster, M., Shazeer, N., & Wu, Y. (2016). ExploringLimits Language Modeling. arXiv:1602.02410 [cs].Jozefowicz, R., Zaremba, W., & Sutskever, I. (2015). Empirical Exploration Recurrent Network Architectures. Proceedings 32nd International ConferenceMachine Learning (ICML-15), pp. 23422350.Kalchbrenner, N., Grefenstette, E., & Blunsom, P. (2014). Convolutional Neural NetworkModelling Sentences. Proceedings 52nd Annual Meeting Association Computational Linguistics (Volume 1: Long Papers), pp. 655665, Baltimore,Maryland. Association Computational Linguistics.412fiA Primer Neural Networks NLPKarpathy, A., Johnson, J., & Li, F.-F. (2015). Visualizing Understanding RecurrentNetworks. arXiv:1506.02078 [cs].Kim, Y. (2014). Convolutional Neural Networks Sentence Classification. Proceedings 2014 Conference Empirical Methods Natural Language Processing(EMNLP), pp. 17461751, Doha, Qatar. Association Computational Linguistics.Kim, Y., Jernite, Y., Sontag, D., & Rush, A. M. (2015). Character-Aware Neural LanguageModels. arXiv:1508.06615 [cs, stat].Kingma, D., & Ba, J. (2014).arXiv:1412.6980 [cs].Adam: Method Stochastic Optimization.Krizhevsky, A., Sutskever, I., & Hinton, G. E. (2012). ImageNet Classification DeepConvolutional Neural Networks. Pereira, F., Burges, C. J. C., Bottou, L., & Weinberger, K. Q. (Eds.), Advances Neural Information Processing Systems 25, pp.10971105. Curran Associates, Inc.Kudo, T., & Matsumoto, Y. (2003). Fast Methods Kernel-based Text Analysis.Proceedings 41st Annual Meeting Association Computational Linguistics Volume 1, ACL 03, pp. 2431, Stroudsburg, PA, USA. Association ComputationalLinguistics.Lafferty, J., McCallum, A., & Pereira, F. C. (2001). Conditional random fields: Probabilisticmodels segmenting labeling sequence data. Proceedings ICML.Le, P., & Zuidema, W. (2014). Inside-Outside Recursive Neural Network modelDependency Parsing. Proceedings 2014 Conference Empirical MethodsNatural Language Processing (EMNLP), pp. 729739, Doha, Qatar. AssociationComputational Linguistics.Le, P., & Zuidema, W. (2015). Forest Convolutional Network: Compositional Distributional Semantics Neural Chart without Binarization. Proceedings2015 Conference Empirical Methods Natural Language Processing, pp.11551164, Lisbon, Portugal. Association Computational Linguistics.Le, Q. V., Jaitly, N., & Hinton, G. E. (2015). Simple Way Initialize Recurrent NetworksRectified Linear Units. arXiv:1504.00941 [cs].LeCun, Y., & Bengio, Y. (1995). Convolutional Networks Images, Speech, TimeSeries. Arbib, M. A. (Ed.), Handbook Brain Theory Neural Networks.MIT Press.LeCun, Y., Bottou, L., Orr, G., & Muller, K. (1998a). Efficient BackProp. Orr, G., &K, M. (Eds.), Neural Networks: Tricks trade. Springer.LeCun, Y., Bottou, L., Bengio, Y., & Haffner, P. (1998b). Gradient Based Learning AppliedPattern Recognition. Proceedings IEEE, 86 (11), 22782324.LeCun, Y., Chopra, S., Hadsell, R., Ranzato, M., & Huang, F. (2006). tutorial energybased learning. Predicting structured data, 1, 0.LeCun, Y., & Huang, F. (2005). Loss functions discriminative training energybasedmodels. Proceedings AISTATS. AIStats.413fiGoldbergLee, G., Flowers, M., & Dyer, M. G. (1992). Learning distributed representations conceptual knowledge application script-based story processing. ConnectionistNatural Language Processing, pp. 215247. Springer.Levy, O., & Goldberg, Y. (2014a). Dependency-Based Word Embeddings. Proceedings52nd Annual Meeting Association Computational Linguistics (Volume2: Short Papers), pp. 302308, Baltimore, Maryland. Association ComputationalLinguistics.Levy, O., & Goldberg, Y. (2014b). Neural Word Embedding Implicit Matrix Factorization. Ghahramani, Z., Welling, M., Cortes, C., Lawrence, N. D., & Weinberger,K. Q. (Eds.), Advances Neural Information Processing Systems 27, pp. 21772185.Curran Associates, Inc.Levy, O., Goldberg, Y., & Dagan, I. (2015). Improving Distributional SimilarityLessons Learned Word Embeddings. Transactions Association Computational Linguistics, 3 (0), 211225.Lewis, M., & Steedman, M. (2014). Improved CCG Parsing Semi-supervised Supertagging. Transactions Association Computational Linguistics, 2 (0), 327338.Li, J., Li, R., & Hovy, E. (2014). Recursive Deep Models Discourse Parsing. Proceedings 2014 Conference Empirical Methods Natural Language Processing(EMNLP), pp. 20612069, Doha, Qatar. Association Computational Linguistics.Ling, W., Dyer, C., Black, A. W., & Trancoso, I. (2015a). Two/Too Simple AdaptationsWord2Vec Syntax Problems. Proceedings 2015 Conference NorthAmerican Chapter Association Computational Linguistics: Human Language Technologies, pp. 12991304, Denver, Colorado. Association ComputationalLinguistics.Ling, W., Dyer, C., Black, A. W., Trancoso, I., Fermandez, R., Amir, S., Marujo, L., &Luis, T. (2015b). Finding Function Form: Compositional Character ModelsOpen Vocabulary Word Representation. Proceedings 2015 ConferenceEmpirical Methods Natural Language Processing, pp. 15201530, Lisbon, Portugal.Association Computational Linguistics.Liu, Y., Wei, F., Li, S., Ji, H., Zhou, M., & Wang, H. (2015). Dependency-Based NeuralNetwork Relation Classification. Proceedings 53rd Annual MeetingAssociation Computational Linguistics 7th International Joint Conference Natural Language Processing (Volume 2: Short Papers), pp. 285290, Beijing,China. Association Computational Linguistics.Luong, M.-T., Le, Q. V., Sutskever, I., Vinyals, O., & Kaiser, L. (2015). Multi-task SequenceSequence Learning. arXiv:1511.06114 [cs, stat].Ma, J., Zhang, Y., & Zhu, J. (2014). Tagging Web: Building Robust Web TaggerNeural Network. Proceedings 52nd Annual Meeting Association Computational Linguistics (Volume 1: Long Papers), pp. 144154, Baltimore,Maryland. Association Computational Linguistics.Ma, M., Huang, L., Zhou, B., & Xiang, B. (2015). Dependency-based Convolutional NeuralNetworks Sentence Embedding. Proceedings 53rd Annual Meeting414fiA Primer Neural Networks NLPAssociation Computational Linguistics 7th International Joint Conference Natural Language Processing (Volume 2: Short Papers), pp. 174179, Beijing,China. Association Computational Linguistics.McCallum, A., Freitag, D., & Pereira, F. C. (2000). Maximum Entropy Markov ModelsInformation Extraction Segmentation.. ICML, Vol. 17, pp. 591598.Mikolov, T., Chen, K., Corrado, G., & Dean, J. (2013). Efficient Estimation WordRepresentations Vector Space. arXiv:1301.3781 [cs].Mikolov, T., Joulin, A., Chopra, S., Mathieu, M., & Ranzato, M. (2014). Learning LongerMemory Recurrent Neural Networks. arXiv:1412.7753 [cs].Mikolov, T., Karafiat, M., Burget, L., Cernocky, J., & Khudanpur, S. (2010). Recurrentneural network based language model.. INTERSPEECH 2010, 11th Annual Conference International Speech Communication Association, Makuhari, Chiba,Japan, September 26-30, 2010, pp. 10451048.Mikolov, T., Kombrink, S., Lukas Burget, Cernocky, J. H., & Khudanpur, S. (2011). Extensions recurrent neural network language model. Acoustics, Speech SignalProcessing (ICASSP), 2011 IEEE International Conference on, pp. 55285531. IEEE.Mikolov, T., Sutskever, I., Chen, K., Corrado, G. S., & Dean, J. (2013). Distributed Representations Words Phrases Compositionality. Burges, C. J. C.,Bottou, L., Welling, M., Ghahramani, Z., & Weinberger, K. Q. (Eds.), AdvancesNeural Information Processing Systems 26, pp. 31113119. Curran Associates, Inc.Mikolov, T. (2012). Statistical language models based neural networks. Ph.D. thesis, Ph.D. thesis, Brno University Technology.Mnih, A., & Kavukcuoglu, K. (2013). Learning word embeddings efficiently noisecontrastive estimation. Burges, C. J. C., Bottou, L., Welling, M., Ghahramani, Z.,& Weinberger, K. Q. (Eds.), Advances Neural Information Processing Systems 26,pp. 22652273. Curran Associates, Inc.Mrksic, N., Seaghdha, D., Thomson, B., Gasic, M., Su, P.-H., Vandyke, D., Wen, T.-H.,& Young, S. (2015). Multi-domain Dialog State Tracking using Recurrent NeuralNetworks. Proceedings 53rd Annual Meeting Association Computational Linguistics 7th International Joint Conference Natural LanguageProcessing (Volume 2: Short Papers), pp. 794799, Beijing, China. AssociationComputational Linguistics.Neidinger, R. (2010). Introduction Automatic Differentiation MATLAB ObjectOriented Programming. SIAM Review, 52 (3), 545563.Nesterov, Y. (1983). method solving convex programming problem convergencerate (1/k2). Soviet Mathematics Doklady, Vol. 27, pp. 372376.Nesterov, Y. (2004). Introductory lectures convex optimization. Kluwer Academic Publishers.Nguyen, T. H., & Grishman, R. (2015). Event Detection Domain AdaptationConvolutional Neural Networks. Proceedings 53rd Annual Meeting415fiGoldbergAssociation Computational Linguistics 7th International Joint Conference Natural Language Processing (Volume 2: Short Papers), pp. 365371, Beijing,China. Association Computational Linguistics.Nivre, J. (2008). Algorithms Deterministic Incremental Dependency Parsing. Computational Linguistics, 34 (4), 513553.Okasaki, C. (1999). Purely Functional Data Structures. Cambridge University Press, Cambridge, U.K.; New York.Olah, C. (2015a). Calculus Computational Graphs: Backpropagation. Retrievedhttp://colah.github.io/posts/2015-08-Backprop/.Olah, C. (2015b). Understanding LSTM Networks. Retrieved http://colah.github.io/posts/2015-08-Understanding-LSTMs/.Pascanu, R., Mikolov, T., & Bengio, Y. (2012). difficulty training RecurrentNeural Networks. arXiv:1211.5063 [cs].Pei, W., Ge, T., & Chang, B. (2015). Effective Neural Network Model Graph-basedDependency Parsing. Proceedings 53rd Annual Meeting AssociationComputational Linguistics 7th International Joint Conference NaturalLanguage Processing (Volume 1: Long Papers), pp. 313322, Beijing, China. Association Computational Linguistics.Peng, J., Bo, L., & Xu, J. (2009). Conditional Neural Fields. Bengio, Y., Schuurmans,D., Lafferty, J. D., Williams, C. K. I., & Culotta, A. (Eds.), Advances NeuralInformation Processing Systems 22, pp. 14191427. Curran Associates, Inc.Pennington, J., Socher, R., & Manning, C. (2014). Glove: Global Vectors Word Representation. Proceedings 2014 Conference Empirical Methods NaturalLanguage Processing (EMNLP), pp. 15321543, Doha, Qatar. Association Computational Linguistics.Pollack, J. B. (1990). Recursive Distributed Representations. Artificial Intelligence, 46,77105.Polyak, B. T. (1964). methods speeding convergence iteration methods.USSR Computational Mathematics Mathematical Physics, 4 (5), 1 17.Qian, Q., Tian, B., Huang, M., Liu, Y., Zhu, X., & Zhu, X. (2015). Learning Tag EmbeddingsTag-specific Composition Functions Recursive Neural Network. Proceedings53rd Annual Meeting Association Computational Linguistics7th International Joint Conference Natural Language Processing (Volume 1: LongPapers), pp. 13651374, Beijing, China. Association Computational Linguistics.Rong, X. (2014). word2vec Parameter Learning Explained. arXiv:1411.2738 [cs].Rumelhart, D. E., Hinton, G. E., & Williams, R. J. (1986). Learning representationsback-propagating errors. Nature, 323 (6088), 533536.Schuster, M., & Paliwal, K. K. (1997). Bidirectional recurrent neural networks. IEEETransactions Signal Processing, 45 (11), 26732681.416fiA Primer Neural Networks NLPSchwenk, H., Dchelotte, D., & Gauvain, J.-L. (2006). Continuous space language modelsstatistical machine translation. Proceedings COLING/ACL Mainconference poster sessions, pp. 723730. Association Computational Linguistics.Shawe-Taylor, J., & Cristianini, N. (2004). Kernel Methods Pattern Analysis. CambridgeUniversity Press.Smith, N. A. (2011). Linguistic Structure Prediction. Synthesis Lectures Human Language Technologies. Morgan Claypool.Socher, R. (2014). Recursive Deep Learning Natural Language Processing ComputerVision. Ph.D. thesis, Stanford University.Socher, R., Bauer, J., Manning, C. D., & Ng, A. Y. (2013). Parsing CompositionalVector Grammars. Proceedings 51st Annual Meeting AssociationComputational Linguistics (Volume 1: Long Papers), pp. 455465, Sofia, Bulgaria.Association Computational Linguistics.Socher, R., Huval, B., Manning, C. D., & Ng, A. Y. (2012). Semantic CompositionalityRecursive Matrix-Vector Spaces. Proceedings 2012 Joint ConferenceEmpirical Methods Natural Language Processing Computational NaturalLanguage Learning, pp. 12011211, Jeju Island, Korea. Association ComputationalLinguistics.Socher, R., Lin, C. C.-Y., Ng, A. Y., & Manning, C. D. (2011). Parsing Natural ScenesNatural Language Recursive Neural Networks. Getoor, L., & Scheffer, T.(Eds.), Proceedings 28th International Conference Machine Learning, ICML2011, Bellevue, Washington, USA, June 28 - July 2, 2011, pp. 129136. Omnipress.Socher, R., Manning, C., & Ng, A. (2010). Learning Continuous Phrase RepresentationsSyntactic Parsing Recursive Neural Networks. Proceedings DeepLearning Unsupervised Feature Learning Workshop {NIPS} 2010, pp. 19.Socher, R., Perelygin, A., Wu, J., Chuang, J., Manning, C. D., Ng, A., & Potts, C. (2013).Recursive Deep Models Semantic Compositionality Sentiment Treebank.Proceedings 2013 Conference Empirical Methods Natural LanguageProcessing, pp. 16311642, Seattle, Washington, USA. Association ComputationalLinguistics.Sgaard, A., & Goldberg, Y. (2016). Deep multi-task learning low level tasks supervisedlower layers. Proceedings 54th Annual Meeting AssociationComputational Linguistics (Volume 2: Short Papers), pp. 231235. AssociationComputational Linguistics.Sordoni, A., Galley, M., Auli, M., Brockett, C., Ji, Y., Mitchell, M., Nie, J.-Y., Gao, J.,& Dolan, B. (2015). Neural Network Approach Context-Sensitive GenerationConversational Responses. Proceedings 2015 Conference NorthAmerican Chapter Association Computational Linguistics: Human Language Technologies, pp. 196205, Denver, Colorado. Association ComputationalLinguistics.Sundermeyer, M., Alkhouli, T., Wuebker, J., & Ney, H. (2014). Translation ModelingBidirectional Recurrent Neural Networks. Proceedings 2014 Conference417fiGoldbergEmpirical Methods Natural Language Processing (EMNLP), pp. 1425, Doha,Qatar. Association Computational Linguistics.Sundermeyer, M., Schluter, R., & Ney, H. (2012). LSTM Neural Networks LanguageModeling.. INTERSPEECH.Sutskever, I., Martens, J., Dahl, G., & Hinton, G. (2013). importance initializationmomentum deep learning. Proceedings 30th international conferencemachine learning (ICML-13), pp. 11391147.Sutskever, I., Martens, J., & Hinton, G. E. (2011). Generating text recurrent neuralnetworks. Proceedings 28th International Conference Machine Learning(ICML-11), pp. 10171024.Sutskever, I., Vinyals, O., & Le, Q. V. V. (2014). Sequence Sequence LearningNeural Networks. Ghahramani, Z., Welling, M., Cortes, C., Lawrence, N. D., &Weinberger, K. Q. (Eds.), Advances Neural Information Processing Systems 27, pp.31043112. Curran Associates, Inc.Tai, K. S., Socher, R., & Manning, C. D. (2015). Improved Semantic RepresentationsTree-Structured Long Short-Term Memory Networks. Proceedings 53rd Annual Meeting Association Computational Linguistics 7th International Joint Conference Natural Language Processing (Volume 1: Long Papers),pp. 15561566, Beijing, China. Association Computational Linguistics.Tamura, A., Watanabe, T., & Sumita, E. (2014). Recurrent Neural Networks WordAlignment Model. Proceedings 52nd Annual Meeting AssociationComputational Linguistics (Volume 1: Long Papers), pp. 14701480, Baltimore,Maryland. Association Computational Linguistics.Telgarsky, M. (2016). Benefits depth neural networks. arXiv:1602.04485 [cs, stat].Tieleman, T., & Hinton, G. (2012). Lecture 6.5RmsProp: Divide gradient runningaverage recent magnitude. COURSERA: Neural Networks Machine Learning.Van de Cruys, T. (2014). Neural Network Approach Selectional Preference Acquisition. Proceedings 2014 Conference Empirical Methods Natural Language Processing (EMNLP), pp. 2635, Doha, Qatar. Association ComputationalLinguistics.Vaswani, A., Zhao, Y., Fossum, V., & Chiang, D. (2013). Decoding Large-Scale Neural Language Models Improves Translation. Proceedings 2013 ConferenceEmpirical Methods Natural Language Processing, pp. 13871392, Seattle, Washington, USA. Association Computational Linguistics.Wager, S., Wang, S., & Liang, P. S. (2013). Dropout Training Adaptive Regularization.Burges, C. J. C., Bottou, L., Welling, M., Ghahramani, Z., & Weinberger, K. Q.(Eds.), Advances Neural Information Processing Systems 26, pp. 351359. CurranAssociates, Inc.Wang, M., & Manning, C. D. (2013). Effect Non-linear Deep Architecture SequenceLabeling.. IJCNLP, pp. 12851291.418fiA Primer Neural Networks NLPWang, P., Xu, J., Xu, B., Liu, C., Zhang, H., Wang, F., & Hao, H. (2015a). Semantic Clustering Convolutional Neural Network Short Text Categorization. Proceedings53rd Annual Meeting Association Computational Linguistics7th International Joint Conference Natural Language Processing (Volume 2: ShortPapers), pp. 352357, Beijing, China. Association Computational Linguistics.Wang, X., Liu, Y., Sun, C., Wang, B., & Wang, X. (2015b). Predicting Polarities TweetsComposing Word Embeddings Long Short-Term Memory. Proceedings53rd Annual Meeting Association Computational Linguistics7th International Joint Conference Natural Language Processing (Volume 1: LongPapers), pp. 13431353, Beijing, China. Association Computational Linguistics.Watanabe, T., & Sumita, E. (2015). Transition-based Neural Constituent Parsing. Proceedings 53rd Annual Meeting Association Computational Linguistics7th International Joint Conference Natural Language Processing (Volume1: Long Papers), pp. 11691179, Beijing, China. Association Computational Linguistics.Weiss, D., Alberti, C., Collins, M., & Petrov, S. (2015). Structured Training NeuralNetwork Transition-Based Parsing. Proceedings 53rd Annual MeetingAssociation Computational Linguistics 7th International Joint Conference Natural Language Processing (Volume 1: Long Papers), pp. 323333, Beijing,China. Association Computational Linguistics.Werbos, P. J. (1990). Backpropagation time: it..Proceedings IEEE, 78 (10), 1550 1560.Weston, J., Bordes, A., Yakhnenko, O., & Usunier, N. (2013). Connecting LanguageKnowledge Bases Embedding Models Relation Extraction. Proceedings2013 Conference Empirical Methods Natural Language Processing, pp.13661371, Seattle, Washington, USA. Association Computational Linguistics.Xu, W., Auli, M., & Clark, S. (2015). CCG Supertagging Recurrent Neural Network.Proceedings 53rd Annual Meeting Association Computational Linguistics 7th International Joint Conference Natural Language Processing(Volume 2: Short Papers), pp. 250255, Beijing, China. Association ComputationalLinguistics.Yin, W., & Schutze, H. (2015). Convolutional Neural Network Paraphrase Identification.Proceedings 2015 Conference North American Chapter Association Computational Linguistics: Human Language Technologies, pp. 901911,Denver, Colorado. Association Computational Linguistics.Zaremba, W., Sutskever, I., & Vinyals, O. (2014). Recurrent Neural Network Regularization.arXiv:1409.2329 [cs].Zeiler, M. D. (2012). ADADELTA: Adaptive Learning Rate Method. arXiv:1212.5701[cs].Zeng, D., Liu, K., Lai, S., Zhou, G., & Zhao, J. (2014). Relation Classification via Convolutional Deep Neural Network. Proceedings COLING 2014, 25th International419fiGoldbergConference Computational Linguistics: Technical Papers, pp. 23352344, Dublin,Ireland. Dublin City University Association Computational Linguistics.Zhang, Y., & Weiss, D. (2016). Stack-propagation: Improved representation learning syntax. Proceedings 54th Annual Meeting Association ComputationalLinguistics (Volume 1: Long Papers), pp. 15571566. Association ComputationalLinguistics.Zhou, H., Zhang, Y., Huang, S., & Chen, J. (2015). Neural Probabilistic StructuredPrediction Model Transition-Based Dependency Parsing. Proceedings53rd Annual Meeting Association Computational Linguistics 7thInternational Joint Conference Natural Language Processing (Volume 1: Long Papers), pp. 12131222, Beijing, China. Association Computational Linguistics.Zhu, C., Qiu, X., Chen, X., & Huang, X. (2015a). Re-ranking Model DependencyParser Recursive Convolutional Neural Network. Proceedings 53rdAnnual Meeting Association Computational Linguistics 7th International Joint Conference Natural Language Processing (Volume 1: Long Papers),pp. 11591168, Beijing, China. Association Computational Linguistics.Zhu, X., Sobhani, P., & Guo, H. (2015b). Long Short-Term Memory Tree Structures.arXiv:1503.04881 [cs].420fiJournal Artificial Intelligence Research 57 (2016) 113-149Submitted 03/16; published 09/16Optimal Partial-Order Plan Relaxation via MaxSATChristian Muisecjmuise@cs.toronto.eduDepartment Computer Science,Toronto, Ontario, Canada. M5S 3G4J. Christopher Beckjcb@mie.utoronto.caDepartment Mechanical & Industrial EngineeringToronto, Ontario, Canada. M5S 3G8Sheila A. McIlraithsheila@cs.toronto.eduDepartment Computer Science,Toronto, Ontario, Canada. M5S 3G4AbstractPartial-order plans (POPs) attractive least-commitment nature,provides enhanced plan flexibility execution time relative sequential plans. Current research automated plan generation focuses producing sequential plans, despiteappeal POPs. paper examine POP generation relaxing modifyingaction orderings sequential plan optimize plan criteria promote flexibility. approach relies novel partial weighted MaxSAT encoding sequentialplan supports minimization deordering reordering actions. Using similartechnique, demonstrate remove redundant actions plan,combine criterion objective maximizing POPs flexibility.partial weighted MaxSAT encoding allows us compute POP sequential planeffectively. compare efficiency approach previous methods POP generation via sequential-plan relaxation. results show existing heuristicapproach consistently produces optimal deordering sequential plan, approachgreater flexibility consider reordering actions plan also providing guarantee optimality. also investigate confirm accuracystandard flex metric typically used predict true flexibility POP measurednumber linearizations represents.1. Introductionagent operate effectively dynamic world, behaviour must flexibleface unexpected changes. context AI planning, several approachesincrease flexibility agent, including giving option select differentplans (Graham, Decker, & Mersic, 2001) expanding applicability existing plansplan generalization (Anderson & Farley, 1988). One example formerdelay committing ordering certain actions plan absolutely necessary,allowing agent dynamically choose plan proceeds execution time (Veloso,Pollack, & Cox, 1998). flexibility precisely partial-order plans provide.Partial-order planning reflects least commitment strategy (Weld, 1994). Unlikesequential plan, specifies set actions total order actions,ideal partial-order plan (POP) specifies action orderings necessary achievegoal. so, POP embodies family sequential plans set linearizationsc2016AI Access Foundation. rights reserved.fiMuise, Beck, & McIlraithsharing actions, differing respect order actions.execution, agent free choose next action execute plan longchosen action preceding actions left execute. Increasing numberlinearizations plan translates directly giving agent freedom executiontime. Thus, typically use number linearizations POP measureflexibility. measure POPs linearizations perfect, quite usefulproxy plans flexibility.flexibility afforded POPs makes attractive real-time execution, multiagent task assignment, range applications (Veloso et al., 1998; Weld, 1994).Nevertheless, recent years research plan generation shifted away partial-orderplanning towards sequential planning, primarily due effectiveness heuristic-basedforward-search planners. regain least commitment nature POPs, leveragingfast sequential plan generation, compelling examine computation POPs viasequential planning technology done, example, forward-chaining partial-orderplanner POPF (Coles, Coles, Fox, & Long, 2010).paper, present alternative approach first generates sequential planstate-of-the-art planner, subsequently relaxes plan minimally constrained POP. Deordering process removing ordering constraints planreordering process allowing arbitrary change ordering constraints;requiring POP remains valid. POP deordering reordering theoretically investigated (Backstrom, 1998), unfortunately optimal deordering reordering NP-hard compute difficult approximate within constant factor (unlessN P DT IM E(npoly log n ), Backstrom, 1998). Despite theoretical impediment,find practice often compute optimal solution.minimum deordering minimum reordering sequential plan cover naturalaspect least commitment planning minimizing ordering constraints placed plan.Intuitively, deordering involves removing existing ordering constraints reorderingallows ordering constraints removed well new ordering constraintsincluded. techniques naturally provide greater flexibility execution time,inverse correlation number ordering constraints numberlinearizations POP. Reordering may achieve greater flexibility deorderingaddition new constraint may allow number existing ordering constraintsremoved still guaranteeing POP validity.approach computing optimally relaxed POP use family novel encodings partial weighted MaxSAT: optimal solution MaxSAT problem correspondsoptimally relaxed POP. Unlike typical SAT-based planning techniques, representaction instance once, giving us succinct representation. empirically compareapproach existing polynomial-time heuristic relaxing sequential plan dueKambhampati Kedar (1994) find latter extremely proficient computing minimum deordering, matching optimal solution every problem tested. find,however, minimum reordering substantially flexible minimumdeordering, fewer ordering constraints far linearizations.also compare efficiency technique related approach usesMixed Integer Linear Programming encoding compute minimum reordering (Do &Kambhampati, 2003) find approach consistently performs better problems114fiOptimal Partial-Order Plan Relaxation via MaxSATnon-trivial size. approach represents practical technique computing guaranteedoptimal deordering reordering POP.Using modern MaxSAT solver compute maximally flexible solutions provides twokey benefits: (1) solver used any-time procedure computes optimally flexible reordering POP given enough time (where technique previouslyexisted), (2) computing optimal deordering POP allows us evaluateefficiency existing heuristic algorithm.1.1 Removing Redundant Actionsgenerality encoding allows us easily define alternative objectives optimizationcriteria. demonstrate key aspect generality, extend characterizationorthogonal metric: minimizing total cost actions plan via removalunnecessary actions. metric commonly used measure plan quality,interestingly directly odds task improving plans flexibility. Here,consider one option combining two metrics puts higher priority actioncost subsequent plan flexibility.majority encodings, theoretical foundations, theorems presentedpaper apply general class problems incorporates metrics. referPOP minimum action cost (over actions POP), subsequentlyminimum number ordering constraints, minimum cost least commitment POP(MCLCP).1 MCLCP compelling free redundant actions wellredundant ordering constraints: MCLCP contains relevant achievegoal.present theoretical aspects general MCLCP criterion,main focus maximizing flexibility POPs, focus experimental evaluationdeorderings reorderings exclusively. leave evaluation methodsolving MCLCP compared plan repair techniques (e.g., Nebel & Koehler, 1995;Gerevini & Serina, 2000) matter future work.1.2 Contributionsfollowing main contributions paper:introduce practical method computing optimal deordering reordering plan. accomplish set novel partial-weighted MaxSATencodings, differing set clause schema define type relaxation desire. model encodings standard partial-order planning concepts, causalsupport threat resolution, draw upon prove correctnessencodings.propose extension least commitment planning, MCLCP, includestotal cost solution. optimization focuses first minimizing total actioncost minimizing number ordering constraints included plan.1. Note minimizing total action cost uniform cost domain equivalent minimizingnumber actions.115fiMuise, Beck, & McIlraithprove correctness approach uses partial weighted MaxSATencoding computing MCLCP.demonstrate, somewhat surprisingly, existing heuristic extremely proficient computing optimal deorderings. existing algorithm produces deorderings, theoretically guaranteed find minimal, let alone optimal,deordering. Nonetheless, find empirically heuristic computes optimaldeordering every instance suite benchmarks.demonstrate efficiency approach compared previous methoduses similar encoding different optimization framework. problemsrelatively difficult relax (i.e., take second compute), approachimproves previous work solving 22% problems within giventime bound.establish empirical connection number linearizations POPstandard flex measure, captures normalized measure numberordering constraints.demonstrate impact starting solution form finalrelaxed plan. particular, consider using two types layered plansproduced Mp POPF planners (Rintanen, 2012; Coles et al., 2010).show achieve greater flexibility, compared optimal deordering,using optimal reordering. result justifies need approachcompute flexible plan.work paper extends conference publications Muise, McIlraith,Beck (2011, 2012). provide full generality using MCLCP baseencoding, paper focus evaluation minimum deordering reorderingaspects. expanded theoretical framework approach, including proofscorrectness, significantly expanded empirical evaluation.1.3 Organizationstart providing, Section 2, necessary background notation automatedplanning partial weighted MaxSAT. Next, detail approach Section 3, includingnew MCLCP criterion Section 3.1 family encodings variousoptimization criteria Section 3.2. Finally, present evaluation Section 4conclude discussion related work summary Section 5.2. Preliminariessection, present necessary background notation concepts work.2.1 Classical PlanningPlanning task synthesizing solution dictates actions agent musttake order achieve prescribed goal. classical planning, assume world116fiOptimal Partial-Order Plan Relaxation via MaxSATfully known deterministic (Russell & Norvig, 2009). Classical planning manyapplications range robotics modelling biological processes (Ghallab, Nau, &Traverso, 2004). standard approach synthesizing classical plan performsearch state space problem, using heuristics guide planner towardshigh quality solution. Here, describe common formalism used specifyingplanning problem: STRIPS (Fikes, Hart, & Nilsson, 1972).STRIPS, planning problem tuple = hF, I, G, Ai F finite setfluents, F initial state, G F goal state, finite setactions. characterize action following three sets:P RE(a): fluents must true order executable.ADD(a): fluents action adds state.DEL(a): fluents action deletes state.work, actions instantaneous adopt standard model interleaved concurrency: two actions occur simultaneously. such, makesimplifying assumption every action a, ADD(a) DEL(a) = . donewithout loss generality, simplifies theoretical results below.say action executable state iff P RE(a) s. resulting stateexecuting action state defined as:((s \ DEL(a)) ADD(a)executabledefP(s, a) =undefinedotherwiseplanning problem = hF, I, G, Ai, associate cost function c mapsevery action non-negative real number: c : R+0.make use two items notation respect set actions A:adders(f ): set actions add fluent f :{a | f ADD(a)}deleters(f ): set actions delete fluent f :{a | f DEL(a)}common representation solution planning problem sequentialplan. sequence actions ~a = [a1 , , ] executable preconditions actionsequence true corresponding state, executable sequence actionssequential plan problem = hF, I, G, Ai executing actions ~a sequence,starting state I, causes goal hold final state:G P(P( P(I, a1 ) , an1 ), )117fiMuise, Beck, & McIlraithreadability, abbreviate progression sequential plan ~a stateP (s, ~a ). cost action sequence ~a = [a1 , . . . , ] sum individualactions costs:nXc (~a ) =c (ai )i=1Rather impose total order actions plan, partial-order plan (POP)specifies set ordering constraints actions. define POP respectplanning problem tuple hA, Oi set actions planset ordering constraints actions (Russell & Norvig, 2009).action may appear A, assume every elementuniquely identifiable. actions a1 , a2 A, denote ordering constrainta1 a2 (a1 a2 ) interpret constraint action a1 appears actiona2 plan. total ordering actions respects linearization.POP provides compact representation multiple linearizations. assume orderingconstraints transitively closed:a1 , a2 , a3 A, (a1 a2 ) (a2 a3 ) (a1 a3 )Assuming transitively closed change fundamental structurePOP set linearizations remains allows us effectively compareflexibility two POPs share action set.Similar cost action sequence, cost POP P = hA, Oi sumaction costs actions P :Xc (P ) =c (a)aAsimplify exposition follows, designate two actions POPrepresent initial state goal state: aI aG respectively. aI orderedevery action, aG analogously ordered every action. planningproblem = hF, I, G, Ai, actions following definition:P RE(aI ) =P RE(aG ) = GADD(aI ) =ADD(aG ) =DEL(aI ) =DEL(aG ) =inclusion aI aG actions allow us simplify presentation many algorithms,avoiding special checks procedure (e.g., assume alwaysfirst last action POP).Depending POP constructed, may include set causal links, C.causal link contains pair ordered actions, a1 , a2 (a1 may aI a2 may aG ),pfluent, p, a1 achieves p a2 : denoted (a1 a2 ). Causal links oftenserve justifications ordering constraints POP.Definition 1 (POP Validity: Notion 1). POP P valid planning problemevery linearization P sequential plan .22. Note notion 1 rely set causal links C.118fiOptimal Partial-Order Plan Relaxation via MaxSATsimple intuitive, notion 1 rarely used verify validity POPmay prohibitively large number linearizations represented POP.is, however, tractable equivalent notion POP validity uses concepts causallinks, open preconditions threats.POP hA, Oi set causal links C, open precondition precondition paction associated causal link:p@a0 s.t. (a0 a) Cprecondition open, say supported, refer associatedaction causal link achiever precondition. typical valid POPone supporter every precondition action included POP,make restriction work keep encoding general.threat POP refers action invalidate causal link twopactions due ordering constraints (or lack thereof). Formally, (a1 a2 ) C,psay action a3 (distinct a1 a2 ) threatens causal link (a1 a2 )following two conditions hold:order a3 a1 a2 :{(a3 a1 ), (a2 a3 )} =action a3 deletes p:p DEL(a3 )existence threat means linearization exists violates causallink, thus may executable. actions aI aG included,following definition characterizes second notion POP validity.Definition 2 (POP Validity: Notion 2). Given planning problem , POP P = hA, Oiset causal links C, P valid POP planning problem actionopen precondition causal link set C threatening action A.causal link structure implicitly assessed verify POP validity polynomialtime (Nebel & Backstrom, 1994), set C strictly necessary. However, implicitlyexplicitly, notion 2 requires actions causally supported threat-free manner.subsequently following connection two notions POP validity:Theorem 1 (POP Validity, due McAllester & Rosenblitt, 1991). notion 2 POPvalidity holds, notion 1 also holds. Additionally, notion 1 holds O,set causal links C must exist notion 2 holds hA, Oi C.final concept use POP based well-established metric measuringconstrained POP (Nguyen & Kambhampati, 2001; Siddiqui & Haslum, 2012): flexmeasure many ordering constraints POP, normalized totalnumber potential ordering constraints. flex tends 1 number orderingconstraints tends 0, vice versa. per usual, assume set orderingconstraints transitively closed.119fiMuise, Beck, & McIlraithDefinition 3 (flex ). Given POP hA, Oi, define flex as,|O|flex (hA, Oi) = 1 P|A|1i=1P|A|1use i=1 denominator instead traditional |A|2 lattercounts number possible ordering constraints. definition flex , fullyunordered POP flex value 1 sequential plan flex 0.strive minimize number ordering constraints transitive closure.Omitting transitive closure would amount optimizing transitive reductionwhich, noted Backstrom (1998), less appeal leads long chainsplan.2.2 Deorderings Reorderingsaim least commitment planning find flexible plans allow us defer decisionsregarding execution plan. Considering ordering constraints POP,two important notions least commitment planning deordering reorderingPOP. Following Backstrom (1998), define formally follows:00Definition 4 (Deordering Reordering). Let P = hA, Oi Q = hA , twoPOPs, STRIPS planning problem:1. Q deordering P wrt. iff P Q valid POPs , = A0 , O0 O.2. Q reordering P wrt. iff P Q valid POPs , = A0 .Recall assume ordering constraints POP transitively closed,every action POP uniquely named (i.e., every repetition action givenunique name). proper deordering one ordering constraints form propersubset (i.e., O0 ( O). define minimum deordering / reordering follows:00Definition 5 (Minimum Deorderings Reorderings). Let P = hA, Oi Q = hA ,two POPs, STRIPS planning problem:1. Q minimum deordering P wrt. iff(a) Q deordering P wrt. ,0000(b) deordering hA , P wrt. s.t. |O00 | < |O0 |.2. Q minimum reordering P wrt. iff(a) Q reordering P wrt. ,0000(b) reordering hA , P wrt. s.t. |O00 | < |O0 |.3. Q minimal deordering P wrt. iff(a) Q deordering P wrt. ,(b) proper deordering Q.120fiOptimal Partial-Order Plan Relaxation via MaxSATNote use cardinality rather set containment 1(b) 2(b)orderings O0 O00 need overlap. equivalently refer minimum deordering(resp. reordering) optimal deordering (resp. reordering). cases, preferPOP smallest set ordering constraints. words, POP existsactions fewer ordering constraints remaining valid respect. problem finding minimum deordering reordering POP NP-hard,cannot approximated within constant factor unless N P DTIME(npoly log n )(Backstrom, 1998). may many optimal deorderings reorderings,work distinguish further. compute minimal deorderingpolynomial time iteratively removing unnecessary ordering constraints (i.e.,cause plan become invalid).2.3 Previous Approachesmany approaches computing partial-order plan, coverrepresentative examples here.2.3.1 Partial-Order Causal Link AlgorithmsTraditional methods producing partial-order plan follow approach called partialorder causal link (POCL) planning (Weld, 1994). POCL planning, modificationsiteratively made incomplete partial-order plan consists set actions, causallinks, ordering constraints. partial-order plan considered completeconditions Definition 2 met.key difference POCL planning standard state-based searchPOCL planning search plan space. POCL planning search, every nodesearch space constitutes partial plan, whereas state-based search every node stateworld; successor nodes generated applying actions state representedcurrent search node. contrast, possible modifications partial plan representchoices available POCL planning search procedure. typical partial planmodifications include:1. Add new action partial plan.2. Order two actions partial plan.3. Create causal link two actions plan.POCL planners popular late 1970s, 1980s, 1990s, starting TatesNONLIN planner (Tate, 1976), forward search techniques one employedFF planner (Hoffmann & Nebel, 2001) led planning research new direction.recent POCL planner VHPOP (Younes & Simmons, 2003), unfortunatelycompetitive state-of-the-art forward search planners.2.3.2 POPFtake advantage flexibility afforded POP search efficiency forwardstate-based planners, Coles et al. introduced forward-chaining partial-order planner121fiMuise, Beck, & McIlraithPOPF (Coles et al., 2010). idea behind POPF restrict modifications permittedpartially completed plan complete state easily computedrepresents truth fluents partial plan executed. Unlike POCL approachesadd actions achieve open preconditions, actions POPF chosenpreconditions satisfied heuristically lead goal (i.e., forward-searchmanner). new action added plan, placed end planaction already incumbent plan ordered newly added actiontime insertion, new action may left unordered respect actionsalready plan. Further, adding new action requires preconditionscausal links created immediately.approach used POPF leverages partial-order nature planning domainsavoiding unnecessary reasoning permutations unordered actions; ordering constraints included required. Sequential planners may trycomplete partial-order plan multiple times change differentpermutation unordered actions, POPF avoid situation timemaintaining partial-order structure. Further, using recently introduced techniquesdetect repeated states (Coles & Coles, 2016), planner avoids even unnecessarypermutations action sequences.Finally, POPF leverages powerful techniques forward-search planners maintaining complete state world reached plan. stateinformation allows powerful heuristics computed efficiently.2.3.3 Petri Net UnfoldingPredating work Coles et al. (2010), alternative approach generating partiallyordered plans via Petri net unfolding (Hickmott, 2008). general idea encodeevolution forward planning system repeated unfolding carefullycrafted Petri net: mathematical structure used model analyze dynamicsdiscrete distributed systems (Murata, 1989). unfolding process naturally representsparallel partially ordered plan (Hickmott, Rintanen, Thiebaux, & White, 2007).2009, Hickmott Sardina detailed theoretical property Petri net unfoldingpartial-order plans, noting plan resulting Petri net unfolding minimaldeordering reordering respects strong independence (Hickmott & Sardina, 2009).Strong independence restriction unordered actions partial-order plan:ambiguity respect action produces particular fluent.result, two different actions produce fluent f , unorderedneither required produce f either service achieving goal servicesuccessful execution action plan. restriction makes deorderingsreorderings produced unfolding restrictive optimal deorderingsreorderings produced approach, require strong independence.Similar POCL POPF approaches, Petri net unfolding exploited producepartial-order plan directly, rather finding deordering reordering existingplan, paper.122fiOptimal Partial-Order Plan Relaxation via MaxSAT2.3.4 Relaxer AlgorithmDue Kambhampati Kedar (1994), Relaxer Algorithm3 operates removingordering constraints sequential plan systematic manner. heuristic guidesprocedure and, detailed Backstrom (1998), process provide guaranteeresulting POP minimally deordered. error counterexampleused Backstrom demonstrate Kambhampati Kedars algorithmnecessarily produce minimally deordered POP. However, conclusion correctprovide new counterexample Appendix A.intuition behind algorithm remove ordering (ai ak ) sequential plan ai achiever precondition ak removing orderinglead threat. algorithm heuristically attempts choose earliest possible action sequential plan achiever precondition. example, considercase sequential plan [a1 , ai , , ak , , ] p P RE(ak ).algorithm keep ordering (ai ak ) leaving would create threatprecondition one actions, ai earliest action sequencefollowing holds:1. p ADD(ai ): ai achiever p2. aj , < j < k, p/ DEL(aj ): p threatened.Algorithm 1 presents approach formally. use index(a,~a) refer indexaction sequence ~a, assume every action plan uniquely named.~a valid plan, line 8 evaluate true either line 11 evaluates truefor-loop line 6 runs actions. is, know unthreatened achiever existsearliest one found. achiever ordered action requiringfluent precondition (line 14), for-loop line 16 adds necessaryordering constraints achiever remains unthreatened. Note deleter foundfor-loop, either line 17 19 must evaluate true. going outerloop line 3, every action newly formed POP unthreatened supporting actionpreconditions. resulting POP therefore valid (cf., Kambhampati& Kedar, 1994, section 5.2).2.3.5 SAPA Post-Processingpart post-processing phase SAPA planner, Kambhampati (2003)introduce approach similar relaxing ordering plan. setting,begin temporal plan actions assigned specific time points,objective optimize either number ordering constraints temporal aspectresulting plan.strategy Kambhampati take (abbreviated DK here), model taskcomputing partial-order relaxation terms constraint satisfaction optimizationproblem (CSOP). Variables introduced represent ordering actions, timingduration actions, resource usage, etc. abstract CSOP formalism,concrete mixed integer linear program (MILP) proposed realize set constraints3. Referred order generalization originally.123fiMuise, Beck, & McIlraithAlgorithm 1: Relaxer Algorithm123456789101112131415161718192021Input: Sequential plan, ~a, including aI aGOutput: Relaxed Partial-order plan, hA, Oi= set(~a);= ;foreachforeach f P RE(a)ach = null;= (index(a, ~a) 1) 0// See earlier achieverf ADD(~a[i])ach = ~a[i];// Stop find deleter ff DEL(~a[i])break;// Add appropriate supporting link= {(ach a)};// Add orderings avoid threatsforeach a0 deleters(f ) \ {a}index(a0 , ~a) < index(ach, ~a)= {(a0 ach)};index(a0 , ~a) > index(a, ~a)= {(a a0 )};return hA, Oi;model valid temporal plan. Similar work, DK contains option enforcing adherence original ordering constraints allows either deorderingreordering produced.DK considers number optimization criteria including minimizing makespan,maximizing sum slack temporal variables, maximizing flexibilitytemporal variables, minimizing number ordering constraints. first threerelated temporal planning domains, final one coincides optimizationcriteria work. Experimental evaluation provided temporal optimizationcriterion, Kambhampati empirically investigate minimizationordering constraints.Differences DK approach include formalism (we focustemporal aspects), model used (unique encoding variables representaction appearing plan unique encoding variables representingtime points resources), underlying solving technology (we rely partial weightedMaxSAT instead MILP), finally MCLCP criterion. Section 4.4 compareefficiency approach computing minimum reordering implementationDK approach uses variables constraints relevant computingminimum reordering.124fiOptimal Partial-Order Plan Relaxation via MaxSAT2.4 Partial Weighted MaxSATcompute relaxed plan, encode task partial weighted MaxSAT problemsolution encoding corresponds minimally relaxed plan optimizesdesired criteria. Here, review notation partial weighted MaxSAT usethroughout paper.Boolean logic, problem Satisfiability (SAT) find true/false settingBoolean variables logical formula referring variables evaluates true(Biere, Heule, van Maaren, & Walsh, 2009). Typically, write problems ConjunctiveNormal Form (CNF), made conjunction clauses, clausedisjunction literals. literal either Boolean variable negation. settingvariables satisfies CNF formula iff every clause least one literal evaluatestrue. example, setting variables x z true satisfy following theory:(x y) (x z)(1)MaxSAT problem optimization variant SAT problemgoal maximize number satisfied clauses (Biere et al., 2009, ch. 19). Althoughcannot satisfy every clause following theory, setting x, true z falsesatisfies five clauses:(x z) (x z) (y z) (x y) (z x) (z y)(2)Adding non-uniform weights clause allows richer version optimizationproblem, refer maximizing weight satisfied clauses weighted MaxSATkproblem. use syntax ( ) indicate clause weight k. Generally,weight must positive real number. Consider setting x false y, z truefollowing theory:31111(x) (x y) (x z) (y) (z)(3)setting satisfies four clauses, total weight 4. aimmaximizing total weight satisfied clauses, achieve sum 5 assigningvariables true:31111(x) (x y) (x z) (y) (z)(4)wish force solver find solution satisfies particular subsetclauses, refer clauses subset hard, clauses problemsoft. syntax use indicate hard clause ( ). mix hardsoft clauses, partial weighted MaxSAT problem (Biere et al., 2009, ch. 19.6).partial weighted MaxSAT problem, soft clauses given weight,feasible solution corresponds setting variables satisfies hard clauses125fiMuise, Beck, & McIlraithCNF. optimal solution partial weighted MaxSAT problem feasiblesolution maximizes sum weights satisfied soft clauses. followingexample, setting variables x, false z true satisfies every hard clause onesoft clauses:123(x) (y) (z) (x z) (y z) (x y)(5)Although required partial weighted MaxSAT general, encodings createnever contain soft clause one literal. special form partialweighted MaxSAT problem, referred binate covering problem (Coudert, 1996), allowsus flip optimization criterion: minimizing sum satisfied soft (unit) clausesequivalent maximizing sum unit clauses literal flipped (e.g., xgoes x vice versa). Using technique solve minimization problempartial weighted MaxSAT solver works soft clauses contain single literal.property key encoding, objective always minimize.3. Approachview sequential plan (also referred total-order plan) special casepartial-order plan exists ordering constraint every pair actions.Quite often, many ordering constraints required: ordering certainactions may switched goal still achieved new sequence actions.aim maximizing flexibility POP, strive minimize number orderingconstraints included solution. objective motivates need identify preciselyordering constraints POP relevant POPs validity.Definition 6 (Ordering Relevance). Given planning problem = hF, I, G, Ai validPOP P = hA, Oi , ordering constraint relevant respect Piff hA, {o}i valid POP .4Ordering relevance plays central role definitions minimal minimum POPdeorderings: relevant ordering constraints precisely cannot removedwithout invalidating POP (Backstrom, 1998). Additionally, Relaxer AlgorithmKambhampati Kedar (1994) operates identifying set ordering constraintssuspected relevant (i.e., selected achievers action preconditions).maximize flexibility POP, focus encoding retaining relevantorderings. difficult measure efficiently, strive maximize flexibility inherentPOP, loosely defined number linearizations POP represents. numberunordered pairs actions POP, typically referred flex (Siddiqui & Haslum,2012), provides approximation POPs flexibility. evaluation, quantifyaccuracy flex approximation POPs flexibility.discussed earlier, verifying POPs validity way linearizationsalways practical. Similarly, attempt compute POPs maximize4. Note transitive closure P necessarily different transitive closure hA, {o}irelevant respect P .126fiOptimal Partial-Order Plan Relaxation via MaxSATnumber linearizations, rather compute POPs adhere onepreviously mentioned criteria removing redundant orderings: minimum deorderingminimum reordering.3.1 Minimum Cost Least Commitment Criterionnotion minimum deordering reordering POP addresses commitment ordering constraints, orthogonal objective commit resourcespossible typically measured either time plan executed parallelsum action costs actions plan. Historically, latter objective takes precedence metrics. end, provide extended criterion computingminimum cost least commitment POP (MCLCP).00Definition 7 (Minimum Cost Least Commitment POP). Let P = hA, Oi Q = hA ,two POPs valid . Q minimum cost least commitment POP (MCLCP) P iff0000Q minimum reordering, A0 A, exist valid POP R = hA ,A00 following condition holds:c (R) < c (Q) (c (R) = c (Q) |O00 | < |O0 |)work, assume every action positive cost. may turnpreferring fewer actions causes us commit ordering constraints, simply dueinteraction actions choose. practice, however, usually place muchgreater emphasis minimizing total cost plan. also worth notingplan exists proper subset actions input plan, computing MCLCPequivalent computing minimum reordering.Following MCLCP criterion, evaluate quality POP totalaction cost number ordering constraints contains; metrics give us directmeasure least commitment nature POP primary emphasis placedremoving unnecessary commitments actions.3.2 Encodingencode task finding minimum deordering, reordering, MCLCP partialweighted MaxSAT problem given input planning problem corresponding initial plan.optimal solution default encoding correspond MCLCP. is,POP exists cheaper overall cost cost fewer ordering constraintstransitive closure. present core encoding Section 3.2.1 provesoundness completeness encoding Section 3.2.2. add clausesproduce encodings correspond optimal deorderings reorderings, presentmodifications Section 3.2.3.3.2.1 Basic Encodingcontrast typical SAT encoding planning problem (e.g., Kautz & Selman,1999), require actions replicated successive plan steps. Instead,represent action occurrence reason orderingactions. actions encoding come provided sequential partial-order plan,127fiMuise, Beck, & McIlraithP = hA, Oi. use (P ) denote partial weighted MaxSAT encoding correspondingPOP P = hA, Oi, refer POP corresponding encodings solutiontarget POP. target POP reconstructed encodings solution lookingvariables set true. use three types propositional variables:xa : every action A, xa indicates action appears target POP.(a1 , a2 ): every pair actions a1 , a2 A, (a1 , a2 ) indicates orderingconstraint (a1 a2 ) appears target POP.(ai , p, aj ): every action aj A, p PRE(aj ), ai adders(p), (ai , p, aj )indicates ai supports aj fluent p target POP.partial weighted MaxSAT encoding distinction hard softclauses. first present hard clauses encoding Boolean formulaesubsequently convert CNF, later describe soft clauses associatedweights.5 define formulae ensure target POP acyclic,ordering constraints include transitive closure. Here, actions universally quantified,formula (9) assume aI 6= ai 6= aG . must ensure that:self-loops:((a, a))(6)include initial goal actions:(xaI ) (xaG )(7)use ordering variable, include actions:(ai , aj ) xai xaj(8)action cannot appear initial action (or goal):xai (aI , ai ) (ai , aG )(9)solution satisfies transitive closure ordering constraints:(ai , aj ) (aj , ak ) (ai , ak )(10)Together, (6) (10) ensure target POP acyclic (note impliesantisymmetry well), remaining formulae tie two types variables togetherdeal initial goal actions. Finally, include formulae needed ensureevery action preconditions met, threats solution:5. readability, omit hard clause symbol, ( ), constraints (6)-(12).128fiOptimal Partial-Order Plan Relaxation via MaxSAT(ai , p, aj )^xak (ak , ai ) (aj , ak )(11)ak deleters(p)^xaj_(ai , aj ) (ai , p, aj )(12)pP RE(aj ) ai adders(p)Intuitively, (ai , p, aj ) holds ai achiever precondition p action ajdeleter p allowed occur actions ai aj ; i.e., correspondsdirectly unthreatened causal link. Formula (11) ensures every causal link remainsunthreatened satisfying variable setting, view two ordering variablesformula form common partial-order planning concepts promotiondemotion (Weld, 1994). Formula (12) ensures include action aj target POP,every precondition p aj must satisfied least one achiever ai . (ai , aj ) ordersachiever correctly, (ai , p, aj ) removes possibility threatening action.far, constraints described capture required POP valid.go address notion ordering relevance presented Definition 6, wellmetric minimizing total action cost MCLCP, make use soft clauses.generate MCLCP, prefer solutions first minimize total action cost,minimize number ordering constraints. add soft unit clause, containingnegation variable, every action ordering variable encoding.violation one unit clauses means solution includes actionordering constraint corresponding violated clauses variable. weight assignedfollows:1((ai , aj )), ai , ajc (a)+|A|2 +1(xa ), \ {aI , aG }Note weight single action clause greater weight ordering constraint clauses combined, |A|2 total orderingconstraints. increased weight guarantees generate solutions minimumaction cost.6 enforce transitive closure ordering constraints, second type soft clause lead solver find POP (among cheapesttotal action cost) minimizes size transitive closure.Richer notions, weighted trade-off ordering constraints actioncosts, also easily modelled using appropriate assignment weights soft clausesencoding. focus primarily deordering reordering aspectswork, leave alternative encodings future work.3.2.2 Theoretical Resultssection present theoretical properties core encoding.6. wish minimize number actions solution, need replace c (a) 0.129fiMuise, Beck, & McIlraithLemma 1 (Variable Setting Implies POP). Given planning problem valid POPP = hA, Oi, variable setting satisfies formulae (6)-(12) (P ) correspond valid POP ordering constraints transitively closed.Proof. already seen POP induced solution hard clausesacyclic transitively closed (due formulae (6)-(10)). seeopen preconditions include aG , conjunction (12) ensuresevery precondition satisfied POP includes action. Additionally,threats final solution formula (11), enforcedevery time precondition met formula (12). POP correspondingsolution hard clauses open preconditions threats, Theorem 1allows us conclude target POP valid .Lemma 2 (POP Implies Variable Setting). Given planning problem valid POP00P = hA, Oi, valid POP Q = hA , i, A0 O0 transitively closed,corresponding feasible variable assignment satisfies (P ).Proof. lemma follows direct encoding POP Q xa = true iffA0 (ai , aj ) = true iff (ai aj ) O0 . Q valid POP, acyclic,include aI aG , actions ordered aI aG , transitivelyclosed (satisfying (6)-(10)). see (11) (12) must satisfied: (12)hold, would action POP precondition pevery potential achiever p threat could ordered achievera. situation possible POP invalid, contradiction.Theorem 2 (Completeness). Given planning problem valid POP P = hA, Oi,complete partial weighted MaxSAT solver find solution soft clauses formulae(6)-(12) (P ) minimizes total cost actions corresponding POP,subsequently minimizes number ordering constraints.Proof. Given |A| actions, |A|2 ordering constraints. every softclause corresponding ordering constraint weight 1, total sum satisfying every ordering constraint clause |A|2 . weight satisfyingaction clause greater |A|2 , soft clauses corresponding actions dominateoptimization criteria. such, valid POP subsetactions P lower total action cost solution satisfies formulae (6)-(12)maximizing weight satisfied soft clauses.Theorem 3 (Encoding Correctness). Given planning problem , valid POP P, solution partial weighted MaxSAT encoding (P ) MCLCP P .Proof. Theorem follows directly Lemmas 1, 2, Theorem 2.3.2.3 VariationsObserve (P ) make use set ordering constraints P . optimalsolution encoding correspond MCLCP, enforce solutionsminimum deorderings reorderings, introduce two additional sets hard clauses.130fiOptimal Partial-Order Plan Relaxation via MaxSATActions: optimal deorderings reorderings, require every action parttarget POP. consider formula ensures use every action (andoptimization works ordering constraints). achieve this, simply needadd action hard clause:(xa ),(13)soft unit clauses trivially unsatisfiable, removed preprocessing phase MaxSAT solving process. optimal solution soft constraintsformulae (6)-(13), referred R (P ), corresponds minimum reordering P .Deordering: deordering must forbid explicit ordering contradictsinput plan. Assuming input plan P = hA, Oi, ensure computed solutiondeordering adding following family hard unit clauses:((ai , aj )), (ai aj )/O(14)Similar introduction hard unit clauses action inclusion, using clauses(14) eliminate number ordering constraint soft clauses encodingpreprocessing phase MaxSAT solver. optimal solution soft constraints formulae (6)-(14), referred (P ), corresponds minimal deorderingP . additionally could use (14) forgo use (13), variation onetypically studied, provide benefit computing MCLCP.4. Evaluationevaluate ability effectiveness state-of-the-art partial weighted MaxSATsolver, Sat4j (Le Berre & Parrain, 2010), optimally relax plan using proposedencodings.7 use MD MR encodings, ensure actions alwaysincluded solution (i.e., using Actions constraint (13)). also investigateeffectiveness Relaxer Algorithm (RX) produce minimally constrained deordering. measure quality POP, use either flex value (cf. Section 2),number linearizations (whenever feasible compute).analysis, considered every STRIPS domain previous InternationalPlanning Competitions (IPC, Hoffmann, 2016). discarded two domains (childsnacktidybot) due difficulty planners generating initial solution.18 discarded due constrained nature; form offers littleflexibility (any domain average flex value less 10% removed).8Using evaluation would uninformative since already relaxed7. Additionally, evaluated 2013 winner partial weighted MaxSAT contest crafted instances,MaxHS (Davies & Bacchus, 2013), however, found Sat4j outperformed MaxHS slightlycoverage time.8. 18 overly constrained domains visitall, blocksworld, sokoban, pegsol, ged, parking, barman, gripper, cybersec, psr-small, storage, nomystery, mystery, mprime, freecell, hiking, floortile, thoughtful.131fiMuise, Beck, & McIlraithpossible, solver determined trivially. evaluate using recentversion domain multiple problem sets exist, Table 1 shows set 15domains considered throughout evaluation.conducted experiments Linux desktop 3.4GHz processor,run Sat4j limited 30 minutes 4GB memory. generate initial sequentialplan, used Mercury planner (Domshlak, Hoffmann, & Katz, 2015); best performing non-portfolio planner recent satisficing IPC competition. Additionally,evaluation, computed initial solutions using state-of-the-art SAT-basedplanner, Mp (Rintanen, 2012), state-of-the-art partial-order planner, POPF (Coleset al., 2010). offer alternative methods generate initial partially ordered plan,investigate impact plans structure relaxation process.assess various aspects approach four separate experiments. First,evaluate difficulty computing feasible solution addition optimal one (weobtain solutions increasing quality using Sat4j any-time fashion). Next, lookquality POP produced encodings well POP producedRelaxer Algorithm. Here, measure quality flex plan transitiveclosure, number linearizations plan wherever feasible compute.also demonstrate empirically accuracy flex measure indicatornumber linearizations. Next, consider impact initial plan formrelaxation, taking account starting solution three planners. Finally,compare approach computing minimum reordering similar approachKambhampati (2003).4.1 Solving Completionbegin brief discussion various configurations approachcoverage, well weaknesses methods. report problemsplanner able find plan within resource limits.9 Table 1 showsfollowing information every domain:number problems domain shown brackets next domain name.number problems solved planner Plans column.Solved column indicates number plans successfully encoded solved.Every problem could encoded MR also could encoded MD,MaxSAT solver produced least one solution every encoded problem. Further,every encoded MD problem solved completion within resource limits.MR column indicates number encoded MR problems solved completion.must emphasize purpose evaluation compare efficiencythree planners (as strengths weaknesses). Rather, considertype plan produces related relaxing ordering constraintsplan. Consequently, purpose Table 1 provide insight problemsincluded analysis, bring light challenges encodingsolving problems completion.9. Providing twice amount time memory planners lead problems solved.132fiOptimal Partial-Order Plan Relaxation via MaxSATDomainMercuryPlans SolvedMRPOPFPlans SolvedMRPlansMpSolvedMRairport (50)322929242121322929depot (22)212119101010202014driverlog (20)202016151515171510elevators (20)201061100--logistics (42)35955551272parcprinter (20)202020151515202020pipesworld (50)424242232322141414rovers (40)403322242421393327satellite (36)352929131313262517scanalyzer (20)2017121077151514tetris (20)1919190--111tpp (30)30281113138202011transport (20)20650--0--woodwork (20)202020544202020zenotravel (20)202020161616202016(460)394323275174167157256239195Table 1: Per domain solver relaxation coverage. Values brackets indicate benchmark size. Plans column indicates many problems respective planner solved.Solved column indicates many solved problems successfully encodedsolved: every encoded problem solvable MD MR, every MD encoding solvable completion. MR column indicates number problemssuccessfully encoded, MR solved completion.problem could encoded, due large number actionsplan; typically plans 200 actions caused issue. domainsproblematic (e.g., elevators, logistics, transport), see initialcoverage non-sequential planners suffers well. problem encoding planscontain many actions due number transitivity clauses included formula(10), cubic number actions.tetris domain proved extremely difficult POPF Mp solve, althoughnumber actions plans Mercury small enough encode. Finally, foundproving optimality MR encoding tpp rovers difficult,clear indication why: rovers high flex , highdomains, opposite true tpp. domains, however, good initial plansproduced quickly Sat4j, solver devoted remaining time making smallimprovements proving optimality.133fiMuise, Beck, & McIlraithFigure 1: number problems solved completion Sat4j given limited amounttime per problem, well number problems solved RX algorithm. EveryMD encoding solved completely Sat4j, RX polynomial sub-optimal techniqueshown comparison solve time.Mercury solved strict superset problems solved POPF Mp. such,use sequential plans produced Mercury input majority evaluation(Section 4.3 one exception). Figure 1 provides view long took Sat4joptimally solve MD MR encodings initial plans Mercury produced:show number problems solved optimally function time (including encodingphase). comparison, include aggregate time RX well. strong run-timeperformance RX expected given polynomial time algorithm withoutoptimality guarantees.4.2 Plan Qualitybegin, discuss surprising result Relaxer algorithm planning benchmarks. every one 323 problems Sat4j solved MD encoding optimally,POP produced Relaxer algorithm contained number orderingconstraints. Even though theoretically Relaxer algorithm guaranteed findminimal POP, nonetheless computes minimum deordering every tested problem. RXproduce deorderings, best RX could hope achieve. Notemay many candidates minimum deordering, RX necessarily findone MD encoding finds.Next, consider difference quality minimum deordering minimum reordering. Quality measured flex transitive closure generatedPOP, include problems MD MR encodings134fiOptimal Partial-Order Plan Relaxation via MaxSATsolved completion Sat4j (275 total plans generated Mercury). Table2 shows average flex MD MR domains, Figure 2 shows flexcomparison per-problem basis domains.DomainMDMRairportdepotdriverlogelevatorslogisticsparcprinterpipesworldroverssatellitescanalyzertetristpptransportwoodworkzenotravel0.280.310.330.310.560.760.160.680.390.310.490.370.510.960.320.370.360.340.320.580.760.160.690.390.310.500.380.510.960.32Table 2: Average flexFigure 2: MD versus MR flex Comparison135fiMuise, Beck, & McIlraithDomains see substantial improvement include airport depot. Domainssaw zero gain terms flexibility include parcprinter, transport, woodwork.total, almost one third (76/275) problems showed improvement flex MRMD varying degrees.10flex value fails convey extreme amount execution flexibility introducedrelaxations. investigate further, computed number linearizationsplans wherever feasible. Determining number total orders partially orderedgraph #P-Complete (Brightwell & Winkler, 1991), practice difficult computeprecisely many graphs. able compute number linearizationsMD MR solutions total 203 problems solution encodingscomputed. found approximately one quarter (51/203) showed differencenumber linearizations, plot ratio #Linears(MR) / #Linears(MD)51 problems Figure 3.Figure 3: Ratio Linearizations. y-axis represents number linearizations inducedPOP optimal reordering divided number linearizations inducedPOP optimal deordering. x-axis ranges problems numberlinearizations differed (25%), sorted based y-axis.extreme, improvement number linearizations massive;13 orders magnitude one airport problem. Conversely, see interestingartefact resulting optimizing metric acts proxy number linearizations: flex value MR never lower MD, POPsproduced approach using flex optimization criterion oppositeeffect number linearizations.10. Many smaller improvements show scatter plot.136fiOptimal Partial-Order Plan Relaxation via MaxSATthree problems (one tetris two depot), found numberlinearizations POP produced MR encoding fewer numberlinearizations POP produced MD encoding. number orderingconstraints POP given number actions usually indicative numberlinearizations POP, three problems indicate universal rule.concrete example, consider two POPs four actions = {a1 , a2 , a3 , a4 }. Ignoringcausal links, Figure 4 shows structure POPs P1 P2 . POPsnumber actions ordering constraints, number linearizations differ:P1 6 linearizations P2 5. POPs serve basic exampleflex criterion capture fully notion POP flexibility usework. may similar notions take differences account,left future investigation (see Say, Cire, Beck (2016) recent workdirection).a2a1a3a1a4a3(a) P1a2a4(b) P2Figure 4: Two POPs number actions ordering constraints,different number linearizations.demonstrate correlation POPs flex number linearizations,focused random partial orders POP 20 actions (not including specialactionis aI aG ).11 constructed 10,000 random partial orders (8,959 unique)spread flex value 0.0 1.0, subsequently computed correspondingnumber linearizations every POP. 100 POPs constructed target flex value(taken 0.01 increments), method construction iteratively add new edgespresent transitive closure POP reached target flex value.Qualitatively, POPs resembled found using planning techniques. reasonuse randomly generated plans due number examples required trendpresent (comparing plans varying number actions uninformative). Figure5 shows flex function number linearizations normalized total numberlinearizations possible (in POPs, equals 20! roughly 2.4 1018 ).Pearson correlation coefficient log normalized linearization countflex value 0.991, clear trend ties together flex POPnumber linearizations. red line Figure 5 line-of-best-fit using log scolelinf lex values (as plot x-axis does). Interestingly, use line11. Similar results hold random POPs different number actions.137fiMuise, Beck, & McIlraithFigure 5: Comparison normalized number linearizations flex valueapproximately 10,000 random POPs 20 actions. Every point represents uniquePOP 20 actions. linf lex value computed normalizing total numberlinearizations possible (20!), note x-axis uses log scale. redline line-of-best-fit using log linf lex.predictor number linearizations, flex overestimates number linearizationshighly constrained plans underestimates number linearizations unconstrainedplans. Though minimizing number ordering constraints transitive closurePOP want optimize directly, serve highly informative proxymaximizing number linearizations POP.4.3 Initial Plan ImpactDifferent planning techniques generate solutions varying forms. sequential plannersfar widely used, planners create inherently partiallyordered solutions. example, POPF planner uses forward-chaining approachresults partial-order plan represented layered sets unordered actions.Similarly, SAT-based planners Mp produce solutions contain layers unorderedactions. two approaches fundamentally differ search solution,fundamentally different sequential planner searches. One questionarises differences whether lead fundamentally different solutions;amenable relaxing different ways. investigate impact starting solutionrelaxed solution quality ability compute optimal solution.encoding minimum reordering take account original sequenceactions. Therefore, encoding used without modification plans produced138fiOptimal Partial-Order Plan Relaxation via MaxSATPOPF Mp. similar sense, plans produced POPF Mp encodedminimum deordering carefully applying equation 14: include linkevery pair actions share layer. obtained layered planrepresentation POPF Mp directly using appropriate planner settings.Across domains, 287 problems mutually solved completion Sat4j usingsolutions produced three planners either MD MR encoding. 78contained number actions. Figure 6 shows time Sat4j requiredsolve problem completion Mercurys plans measured planstwo planners. first plot shows 287 problems mutually solved, seeperformance improvement solutions coming Mercury solver.12 However,limit 78 problems contain number actionssolutions, find Sat4j solve-time much comparablesolvers. Thus, appears little effect solving efficiency based inputsolution format. primary factor Sat4j solve time number actions representedencoding.(a) problems mutually solved Sat4j using (b) subset mutually solved problems consource plan planner.tain number actions.Figure 6: Comparison time relax Mercury plan versus time relax POPFMp plan. MD MR encodings included data.addition, investigated resulting flex produced POPs. 78 problemsmutually solved number actions, two (from scanalyzer domain)contained different set actions resulted slightly higher flex valuesminimum deordering reordering Mercurys solution compared planners.hand, six problems airport domain lower flex valueminimum deordering Mp solutions despite number actions.indicates conditions, initial layered plan produced Mp mayallow much relaxation compared forward search planner MercuryPOPF. note, however, vast majority problems flexminimum deordering reordering coincided across initial plan types.12. Note time include initial planner computation; time encode solveMaxSAT encoding.139fiMuise, Beck, & McIlraithFinally, investigated improvement flex planner compared initialsolution. Mercury, initial flex value always 0, sequential planner.reordering allowed ignore original ordering constraints, considerimprovement flex minimum deordering plans coming POPF Mp.Figure 7 shows relative flex comparison original plan minimumdeordering computed. plots, include every problem solved successfullycompletion Sat4j plans produced POPF (167) Mp (219).(a) flex improvement POPF(b) flex improvement MpFigure 7: Comparison original plan flex versus flex minimum deordering.found majority initial flex values Mp POPF solutions fellwithin range 0 0.2, difference flex solutions solverminimal. moderate correlation original final flex value:Mp POPF solutions Pearson correlation coefficient 0.57 0.42 respectively.However, observed distinction relaxing Mp solutions versus POPFeither time compute relaxation, flex final POP.4.4 Comparison MILP Encodingmodel relaxing ordering plan presented Kambhampati(2003) involves temporal constraints resources aspects beyondconsider here. Nevertheless, fragment model capable computing eitherminimum deordering reordering plan, worthwhile see effectivefinding optimal reordering. forgo testing previous work computingoptimal deordering, Relaxer Algorithm effective so. noteKambhampati considered using model heuristically guide solverreasonable solution instead optimal one.optimization framework Kambhampati use model problem relaxingordering plan Mixed Integer Linear Programming (MILP). MILP consistsset linear constraints defined variables take integer realvalues. optimization criterion specified weighted linear combination subsetvariables problem either maximized minimized.140fiOptimal Partial-Order Plan Relaxation via MaxSATneed go detail, MILP model presented section quite basicuses integer variables encoding.Here, present version MILP model introduced Kambhampaticomparison partial weighted MaxSAT model. modifications fall threecategories: (1) fixes bugs original formulation, (2) removal variables constraints relevant setting (i.e., temporal resource related portionsmodel), (3) adding constraints enforce solution transitive closure.variables use model include following:Xafj ,ai(1=0ai supports aj fluent fotherwiseYafi ,aj(1=0ai ordered aj due interference fluent fotherwiseOai ,aj(1=0ai ordered ajotherwiseNote Xafj ,ai Oai ,aj analogous (ai , f, aj ) (ai , aj ) respectively.interference variables Yafi ,aj defined cases aj conflictexecution ai fluent f : either f (P RE(ai ) ADD(ai )) DEL(aj ) f(P RE(aj ) ADD(aj )) DEL(ai ) holds. constraints MILP model follows(unbound variables assumed universally quantified).Interfering actions must ordered (defined pairs actions interfere):Yafi ,aj + Yafj ,ai = 1Every precondition supported exactly one way:13Xf P RE(aj ),Xafj ,ai = 1ai adders(f )Every support threat free:ad deleters(f ), (1 Xafj ,ai ) + (Yafd ,ai + Yafj ,ad ) 1Support implies ordering:Oai ,aj Xafj ,ai 013. original paper constraint erroneously listed141Pai adders(f )Xafi ,aj = 1.fiMuise, Beck, & McIlraithInterference implies ordering:Oai ,aj Yafi ,aj 0Enforce transitive closure ordering constraints:(1 Oai ,aj ) + (1 Oaj ,ak ) + Oai ,ak 1Forbid self loops ordering:Oa,a = 0Order everything initial state action goal action:OaI ,a = 1Oa,aG = 1final three constraints appear original model. last one replacesconstraints referenced temporal variables achieve effect, first twoensure solution transitively closed. mentioned earlier, optimizing transitive closure preferred optimizing transitive reduction. Finally, optimizationcriterion MILP model follows.inimizeXOa1 ,a2a1 ,a2model produce reorderings input plan feasible solutions,find minimum reordering solved completion. implemented MILP modelusing state-of-the-art MILP solver Gurobi (version 5.6.2) (Gurobi Optimization, Inc.,2015), measured coverage domains function time. Figure 8 containsresults.found using MILP model effective easier problems (those solved2 seconds), anything difficult, solving partial weighted MaxSATencoding Sat4j proved efficient. Overall, 275 problems solved using Sat4jpartial weighted MaxSAT encoding 226 problems solved using GurobiMILP model.additionally tested MILP model mirrors partial weighted MaxSAT encoding presented above. However, results similar shown Figure8, MILP encoding consistently outperformed problems takesecond solve.5. Discussionpaper, proposed practical method computing optimal deorderingreordering sequential partial-order plan. Despite theoretical complexity computing optimal deordering reordering NP-hard, able compute142fiOptimal Partial-Order Plan Relaxation via MaxSATFigure 8: given timeout (x-axis), number problems solved completion withintimeout bound (y-axis) (1) Sat4j using MR encoding (2) Gurobi usingMILP encoding described text.optimal solution leveraging power modern MaxSAT solvers. proposedextension classical least commitment criteria minimal deordering reordering: minimum cost least commitment POP (MCLCP). MCLCP considers totalcost actions solution minimizing number ordering constraints. Centralencodings propose notion ordering relevance: designed optimizationcriteria minimize ordering constraints resulting plan, leavingrelevant plan validity.approach uses family novel encodings partial weighted MaxSAT,solution corresponds optimal POP satisfying one three least commitment criteriainvestigate: minimum deordering, minimum reordering, proposed minimum costleast commitment POP. solve former two encodings state-of-the-art partialweighted MaxSAT solver, Sat4j, find majority problems readily handledMaxSAT solver reasonable amount time.considered various input plan formats, well similar encoding optimizingplan flexibility, found using sequential plan input encodingseffective solution computing reordering; perhaps surprisingly, benefitobserved using planner naturally generates partial orders (Mp).also investigated existing polynomial algorithm deordering sequential plansdiscovered successfully computes optimal deordering every problemtested, despite lack theoretical guarantee. algorithm fast practice,well suited relaxing POP require deordering. Finally, also establishedstrong empirical correspondence commonly used flex metric numberlinearizations represented POP.143fiMuise, Beck, & McIlraithHere, discuss related work conclude discussion potential future work.5.1 Related WorkSection 2.3, detailed variety approaches naturally produce partial-orderplans. Here, review work related aspects approach.standard SAT-based planning encodings also produce POP (Kautz, McAllester,& Selman, 1996), significant difference standard encodings workavoid encoding action every layer planning graph appealingfact already know (superset of) actions solution. Intuitively,view encoding using MaxSAT find implicit layers actions planway computing relevant ordering constraints. additional differencechoosing layer every action unnecessarily restricts timing actionpotentially appear multiple adjacent layers.notion MCLCP related plan repair (Nebel & Koehler, 1995; Gerevini& Serina, 2000). key difference, however, consider addition newactions cost plan improved removing actions MCLCP. focuspaper improving flexibility POPs, forgo full theoretical empiricalcomparison MCLCP criterion existing plan repair techniques. Preliminaryresults effect MCLCP action removal technique found previouswork subject (Muise et al., 2012; Muise, 2014).core encoding similar causal encodings Kautz et al. (1996) Variant-IIRobinson, Gretton, Pham, Sattar (2010). similarly encode orderingpair actions variable ((ai , aj ) case), rather encoding everypotential action occurrence modelling relaxed planning graph, encode formulaemust hold valid POP specific set actions provided part input.mentioned Section 2.3, also similarities workKambhampati (2003). particular, optimization criterion minimizing numberordering constraints coincide, optional use constraints force deordering.Kambhampati focus temporal relaxation context action ordering,take orthogonal view minimizing total action cost.5.2 Conclusionuse method computing optimally relaxed plans provides two key advantages:(1) maximizing flexibility paramount, solving MR encoding lead farflexible solutions MD encoding Relaxer Algorithm achieve, (2)optimal deordering provides useful baseline demonstrating effectivenessRelaxer Algorithm. work leaves open possibility heuristic approach similarRelaxer Algorithm capable producing reorderings partial-order plan.One extension work consider alternative forms optimization criteria.example, one may change soft clauses minimize number fluentsinitial state required plan validity. potential improveplanning formalisms attempt minimize reliance information initialstate, assumption-based planning (Davis-Mendelow, Baier, & McIlraith, 2013).Alternatively, initial set actions need correspond directly plan. long144fiOptimal Partial-Order Plan Relaxation via MaxSATsubset actions achieve goal, compute plan. opens doortechniques optimizing plans adding actions select from, using techniquesintroduced Davies, Pearce, Stuckey, Sndergaard (2014).Acknowledgmentsauthors gratefully acknowledge funding Ontario Ministry InnovationNatural Sciences Engineering Research Council Canada (NSERC). Thanks alsogo anonymous reviewers thoughtful feedback review process.Appendix A. Relaxer CounterexampleRelaxer Algorithm presented Section 2.3.4 deorders input plan, pointedBackstrom (1998), resulting POP may minimal deordering. counterexample provided Backstrom, however, incorrectly states resulting POPminimally deordered (Backstrom, 1998, Figure 14), fact Figure 14(b)deordering 14(a), thus 14(a) minimal deordering (although minimum reordering). Here, present new counterexample supports claim RelaxerAlgorithm may produce minimum deordering.domain theory problem specification shown Figure 9. input plansequence actions [a1 , a2 , a3 ]. Relaxer Algorithm seeks earliestachiever every precondition, algorithm results deordering plantwo ordering constraints: (a1 a3 ) (a2 a3 ). problem deorderinga1 chosen achiever fluent p, fact a2 used achieverp q (note a2 already required fluent q).weakness Relaxer Algorithm uses earliest achiever. weakness surfaces action later plan used achiever already orderedappropriately. Using insight, may modification Relaxer Algorithmfinds achievers already ordered appropriately, opposed finding earliest achiever.145fiMuise, Beck, & McIlraith(define (domain counterexample)(:requirements :strips)(:predicates (p) (q) (g1) (g2) (g3) )(:action a1:parameters():precondition ():effect (and (g1) (p)))(:action a2:parameters():precondition ():effect (and (g2) (p) (q)))(:action a3:parameters():precondition (and (p) (q)):effect (and (g3))))(define (problem counterexample-problem)(:domain counterexample)(:init ())(:goal (and (g1) (g2) (g3) )))Figure 9: Counterexample Domain Problem DescriptionReferencesAnderson, J. S., & Farley, A. M. (1988). Plan abstraction based operator generalization.7th International Conference Artificial Intelligence, pp. 100104.Backstrom, C. (1998). Computational aspects reordering plans. Journal ArtificialIntelligence Research, 9 (1), 99137.Biere, A., Heule, M., van Maaren, H., & Walsh, T. (2009). Handbook satisfiability,frontiers artificial intelligence applications. IOS Press.Brightwell, G., & Winkler, P. (1991). Counting Linear Extensions #P-Complete. 23rdAnnual ACM Symposium Theory Computing, 8 (3), 175181.Coles, A., & Coles, A. (2016). Before? State Memoization TemporalPlanning. 26th International Conference Automated Planning Scheduling,pp. 97105.Coles, A., Coles, A., Fox, M., & Long, D. (2010). Forward-chaining partial-order planning.20th International Conference Automated Planning Scheduling, pp. 4249.Coudert, O. (1996). solving covering problems. 33rd Annual Design AutomationConference, pp. 197202.146fiOptimal Partial-Order Plan Relaxation via MaxSATDavies, J., & Bacchus, F. (2013). Postponing optimization speed MAXSAT solving.19th International Conference Principles Practice Constraint Programming,pp. 247262.Davies, T. O., Pearce, A. R., Stuckey, P. J., & Sndergaard, H. (2014). Fragment-basedplanning using column generation. Proceedings 24th International ConferenceAutomated Planning Scheduling, pp. 8391.Davis-Mendelow, S., Baier, J. A., & McIlraith, S. A. (2013). Assumption-based planning:Generating plans explanations incomplete knowledge. Proceedings27th AAAI Conference Artificial Intelligence, pp. 209216.Do, M. B., & Kambhampati, S. (2003). Improving temporal flexibility positionconstrained metric temporal plans. AIPS Workshop Planning TemporalDomains.Domshlak, C., Hoffmann, J., & Katz, M. (2015). Red-black planning: new systematicapproach partial delete relaxation. Artificial Intelligence, 221, 73114.Fikes, R. E., Hart, P. E., & Nilsson, N. J. (1972). Learning executing generalized robotplans. Artificial intelligence, 3 (1), 251288.Gerevini, A., & Serina, I. (2000). Fast plan adaptation planning graphs: Localsystematic search techniques. Proceedings 5th International ConferenceArtificial Intelligence Planning Systems, pp. 112121.Ghallab, M., Nau, D., & Traverso, P. (2004). Automated Planning: Theory & Practice.Morgan Kaufmann Publishers.Graham, J. R., Decker, K. S., & Mersic, M. (2001). DECAF - Flexible Multi AgentSystem Architecture. Autonomous Agents Multi-Agent Systems, 7 (1), 727.Gurobi Optimization, Inc. (2015). Gurobi optimizer reference manual..Hickmott, S., Rintanen, J., Thiebaux, S., & White, L. B. (2007). Planning via petri netunfolding. 20th International Joint Conference Artificial Intelligence, pp. 19041911.Hickmott, S., & Sardina, S. (2009). Optimality properties planning via Petri net unfolding: formal analysis. 19th International Conference Automated PlanningScheduling, pp. 170177.Hickmott, S. L. (2008). Directed unfolding: reachability analysis concurrent systems &applications automated planning. Ph.D. thesis, University Adelaide.Hoffmann, J., & Nebel, B. (2001). FF planning system: fast plan generationheuristic search. Journal Artificial Intelligence Research, 14 (1), 253302.Hoffmann, J. (2016). ICAPS competition page. http://ipc.icaps-conference.org/.Accessed: 2016-09-06.Kambhampati, S., & Kedar, S. (1994). unified framework explanation-based generalization partially ordered partially instantiated plans. Artificial Intelligence,67 (1), 2970.147fiMuise, Beck, & McIlraithKautz, H. A., McAllester, D. A., & Selman, B. (1996). Encoding plans propositionallogic. 5th International Conference Principles Knowledge RepresentationReasoning, pp. 374384.Kautz, H. A., & Selman, B. (1999). Unifying SAT-based graph-based planning. 16thInternational Joint Conference Artificial Intelligence, pp. 318325.Le Berre, D., & Parrain, A. (2010). Sat4j library, release 2.2 system description. JournalSatisfiability, Boolean Modeling Computation, 7, 5964.McAllester, D. A., & Rosenblitt, D. (1991). Systematic nonlinear planning. Proceedings9th National Conference Artificial Intelligence, pp. 634639.Muise, C. (2014). Exploiting Relevance Improve Robustness Flexibility Plan Generation Execution. Ph.D. thesis, University Toronto.Muise, C., Mcilraith, S. A., & Beck, J. C. (2011). Optimization partial-order plans viaMaxSAT. ICAPS Workshop Constraint Satisfaction Techniques PlanningScheduling Problems, COPLAS.Muise, C., McIlraith, S. A., & Beck, J. C. (2012). Optimally relaxing partial-order plansMaxSAT. 22nd International Conference Automated Planning Scheduling,pp. 358362.Murata, T. (1989). Petri nets: Properties, analysis applications. ProceedingsIEEE, 77 (4), 541580.Nebel, B., & Backstrom, C. (1994). computational complexity temporal projection, planning, plan validation. Artificial Intelligence, 66 (1), 125160.Nebel, B., & Koehler, J. (1995). Plan reuse versus plan generation: theoreticalempirical analysis. Artificial Intelligence, 76 (1-2), 427454.Nguyen, X., & Kambhampati, S. (2001). Reviving partial order planning. Proceedings17th International Joint Conference Artificial Intelligence, pp. 459466.Rintanen, J. (2012). Planning satisfiability: Heuristics. Artificial Intelligence, 193, 4586.Robinson, N., Gretton, C., Pham, D. N., & Sattar, A. (2010). Partial weighted MaxSAToptimal planning. 11th Pacific Rim International Conference ArtificialIntelligence, pp. 231243.Russell, S. J., & Norvig, P. (2009). Artificial intelligence: modern approach. Prentice hall.Say, B., Cire, A. A., & Beck, J. C. (2016). Mathematical programming models optimizingpartial-order plan flexibility. 22nd European Conference Artificial Intelligence(In Press).Siddiqui, F. H., & Haslum, P. (2012). Block-structured plan deordering. AustralasianConference Artificial Intelligence, pp. 803814.Tate, A. (1976). Project planning using hierarchic non-linear planner. D.A.I. ResearchReport No. 25. Department Artificial Intelligence, University Edinburgh.Veloso, M. M., Pollack, M. E., & Cox, M. T. (1998). Rationale-based monitoring planningdynamic environments. 4th International Conference Artificial IntelligencePlanning Systems, pp. 171180.148fiOptimal Partial-Order Plan Relaxation via MaxSATWeld, D. S. (1994). introduction least commitment planning. AI Magazine, 15 (4),2761.Younes, H. L. S., & Simmons, R. G. (2003). VHPOP: versatile heuristic partial orderplanner. Journal Artificial Intelligence Research, 20, 405430.149fiJournal Artificial Intelligence Research 57 (2016) 229271Submitted 03/16; published 10/16Goal Probability Analysis MDP Probabilistic Planning:Exploring Enhancing State ArtMarcel SteinmetzJorg HoffmannSTEINMETZ @ CS . UNI - SAARLAND . DEHOFFMANN @ CS . UNI - SAARLAND . DESaarland University,Saarland Informatics Campus,Saarbrucken, GermanyOlivier BuffetOLIVIER . BUFFET @ LORIA . FRINRIA / Universite de Lorraine / CNRS,Nancy, FranceAbstractUnavoidable dead-ends common many probabilistic planning problems, e.g. actions may fail operating resource constraints. important objective settingsMaxProb, determining maximal probability goal reached, policyachieving probability. Yet algorithms MaxProb probabilistic planning severely underexplored, extent scant evidence empirical state art actually is.close gap comprehensive empirical analysis. design explore large spaceheuristic search algorithms, systematizing known algorithms contributing several new algorithm variants. consider MaxProb, well weaker objectives baptize AtLeastProb(requiring achieve given goal probabilty threshold) ApproxProb (requiring computemaximum goal probability given accuracy). explore general casemay 0-reward cycles, practically relevant special case acyclic planning,planning limited action-cost budget. design suitable termination criteria, search algorithm variants, dead-end pruning methods using classical planning heuristics, node selectionstrategies. design benchmark suite comprising 1000 instances adaptedIPPC, resource-constrained planning, simulated penetration testing. evaluation clarifiesstate art, characterizes behavior wide range heuristic search algorithms,demonstrates significant benefits new algorithm variants.1. IntroductionMany probabilistic planning problems contain unavoidable dead-ends (e.g. Kolobov, Mausam,Weld, & Geffner, 2011; Teichteil-Konigsbuch, Vidal, & Infantes, 2011; Kolobov, Mausam, & Weld,2012; Teichteil-Konigsbuch, 2012), i.e., policy guarantees eventually, circumstances,attain goal. Examples planning resource constraints limited budget, situationsactions may fail eventually run options. One important objectiveMaxProb, determining maximal probability goal reached (and identifyingpolicy achieving probability). MaxProb also partly underlies International Probabilistic Planning Competition (IPPC) (Younes, Littman, Weissman, & Asmuth, 2005; Bryce & Buffet,2008; Coles, Coles, Garca Olaya, Jimenez, Linares Lopez, Sanner, & Yoon, 2012), planners evaluated often reach goal online policy execution. (The time limitIPPC setting mixes MaxProb bias towards policies reaching goal quickly.c2016AI Access Foundation. rights reserved.fiS TEINMETZ & H OFFMANN & B UFFETalso relates proposals Kolobov et al., 2012 Teichteil-Konigsbuch, 2012, askingcheapest policy among maximizing goal probability, proposal Chatterjee,Chmelik, Gupta, & Kanodia, 2015, 2016, asking cheapest policy ensuring target statereached almost surely partially observable setting.)consider MDP-based probabilistic planning, factored models (probabilistic extensionsSTRIPS) whose state spaces may large build explicitly. focus optimal offlinesetting, i.e., solving MaxProb exactly. setup objective certainly relevant,little work towards developing solvers. main effort made Kolobov et al. (2011),discuss detail below. Hou, Yeoh, Varakantham (2014) consider several variantstopological VI (Dai, Mausam, Weld, & Goldsmith, 2011), solving MaxProb necessitatingbuild entire reachable state space. works addressing goal probability maximizationaim guaranteeing optimality (e.g. Teichteil-Konigsbuch, Kuter, & Infantes, 2010; Camacho,Muise, & McIlraith, 2016).MDP heuristic search (Barto, Bradtke, & Singh, 1995; Hansen & Zilberstein, 2001; Bonet& Geffner, 2003b; McMahan, Likhachev, & Gordon, 2005; Smith & Simmons, 2006; Bonet &Geffner, 2006) potential find optimal policies without building entire state space,Kolobov et al. (2011) authors addressing optimal MaxProb heuristic search.Part reason lack research heuristic search MaxProb following two major obstacles. First, MDP heuristic search successful expected-cost minimization,suffers lack admissible (upper-bounding) heuristic estimators goal probability.best known possibility detect dead-ends set initial heuristic estimate 0, usingtrivial upper bound 1 elsewhere. Second, MaxProb fit stochastic shortest path (SSP)framework (Bertsekas, 1995), due 0-reward cycles. pointed Kolobov et al. (2011),MaxProb equivalent non-discounted reward maximization problem, non-goal cyclesreceive 0 reward thus improper policies accumulate reward .address second problem, Kolobov et al. (2011) devised FRET (find, revise, eliminate traps) framework, admits heuristic search, yet requires several iterations completesearches. heuristic search iterations, FRET eliminates 0-reward cycles (traps). FRET iterates cycles persist. Kolobov et al.s contribution mainly theoretical considering MaxProb much larger class generalized SSPs empirical evaluationserves merely proof concept. experiment single domain (ExplodingBlocks),run one configuration search (LRTDP, Bonet & Geffner, 2003b), one possibilitydead-end detection thus non-trivial initial heuristic estimates (SixthSense, Kolobov, Mausam,& Weld, 2010). outperform value iteration (VI), dead-end detection usedVI, remains unclear extent improvement due actual heuristic search,rather state pruning itself.summary, heuristic search MaxProb challenging, addressedKolobov et al. (2011), limited experiments. Given this:(i) actually empirical state art heuristic search MaxProb?known algorithms, variants thereof, work better?explore large design space algorithms, show that, indeed, variants workmuch better.(ii) simpler yet still relevant special cases, weaker objectives, may easiersolve?230fiG OAL P ROBABILITY NALYSIS P ROBABILISTIC P LANNINGindeed practically relevant cases necessitate FRET, weaker objectivesenable refer early termination.elaborate first (ii): state space planning task hand acyclic, clearly FRETneeded: cycles particular 0-reward cycles state spacefinite, execution end (goal non-goal) absorbing state; implieswithin realm SSPs. special case is, however, still practically relevant. illustration,acyclic state spaces occur even standard IPPC benchmarks, namely TriangleTireworlddomain moves made one direction. importantly, planning limitedaction-cost budget, limited-budget planning, acyclic state spaces action costs non-0,strictly decreasing remaining budget. similar class scenarios every action consumes non-0 amount non-replenishable resource. Another example recently proposedmodels simulated penetration testing, per Hoffmann (2015). MDP models networkintrusion point view attacker. state space acyclic exploitattempted (trying exploit network configuration wouldyield outcome). States thus need remember remaining action set, every actionapplication strictly reduces set.Regarding weaker objectives: alternatives MaxProb, reasonable ask whethermaximum goal probability exceeds given threshold , require computing maximum goalprobability given accuracy . refer objectives AtLeastProb ApproxProbrespectively.1 example, penetration testing, AtLeastProb naturally assesses level network security: attacker reach target host probability greater given securitymargin? E.g., customer data server compromised probability greater 0.01?AtLeastProb ApproxProb allow early termination based maintaining both, lower (pessimistic) bound V L upper (admissible/optimistic) bound V U . especially promisingAtLeastProb, terminate lower bound already good enough (V L ),upper bound already proves infeasibility (V U < ). Good anytime behavior, eitherbounds, translates early termination.Let us elaborate (i), exploring state art beyond. design algorithmspace characterized by:(a) Search algorithm. design variants AO (Nilsson, 1971), LRTDP (Bonet & Geffner,2003b), depth-first oriented heuristic searches (Bonet & Geffner, 2003a, 2006), maintainingupper lower bounds early termination.(b) FRET. design new variant FRET better suited problems uninformative initialupper bounds.(c) Bisimulation reduction. design new probabilistic-state-space reduction method, via bisimulation relative all-outcomes determinization (e.g. Bonet & Geffner, 2003b; Yoon, Fern,& Givan, 2007; Little & Thiebaux, 2007).1. AtLeastProb relates MDP model-checking, one typically wants validate given PCTL (ProbabilisticComputation Tree Logic) formula valid probability (Baier, Groer, Leucker, Bollig, & Ciesinski, 2004;Kwiatkowska, Parker, & Qu, 2011a; Kwiatkowska, Norman, & Parker, 2011b). also relates Constrained MDPs(Altman, 1999), enforcing minimum success probability could expressed constraint particularquantity. Chance-Constrained POMDPs (Santana, Thibaux, & Williams, 2016) different AtLeastProbconstraint probability remain safe states, reach goal states.231fiS TEINMETZ & H OFFMANN & B UFFET(d) Dead-end pruning method. employ classical-planning heuristic functions dead-end detection probabilistic planning, via all-outcomes determinization, previously doneTeichteil-Konigsbuch et al. (2011). especially promising limited-budget planning,prune state admissible classical-planning estimate exceeds remainingbudget s.(e) Node selection strategy. design comprehensive arsenal simple strategies, biasing tiebreaking action state selection manners targeted fostering early termination.implemented techniques within Fast Downward (FD) (Helmert, 2006), thus contributing, side effect work, ideal implementation basis exploiting classical-planningheuristic search techniques MDP heuristic search.2algorithm dimensions (a) (e) orthogonal (excepting dependencies, particularbisimulation reduction subsumes dead-end pruning). explore behavior resultingdesign space large benchmark suite design purpose. suite includes domainsIPPC, resource-constrained planning, penetration testing, limitedbudget version unlimited-budget version. suite comprises 1089 benchmark instancestotal.3 Amongst things, observe:Heuristic search yields substantial benefits, even trivial admissible heuristic settinginitial estimate 1 everywhere (+9% total coverage across benchmarks),admissible heuristics based dead-end detection (+12%).Early termination yields substantial benefits (e.g. AtleastProb +8% = 0.2+7% = 0.9).FRET variant yields dramatic benefits (+32% total coverage cyclic benchmarks).Bisimulation reduction yields optimal MaxProb solver excells TriangleTireworld,even surpassing Prob-PRP (Muise, McIlraith, & Beck, 2012; Camacho et al., 2016)standard version goal achieved certainty henceProb-PRP optimal, also limited-budget version so.side, discover landmarks compilation per Domshlak Mirkis (2015), employeddead-end pruning oversubscription planning setting, actually, own, equivalentpruning remaining budget standard admissible landmark heuristic.relevant work because, otherwise, compilation would canonical candidate alsodead-end pruning setting (indeed started investigation).paper organized follows. Section 2 describes model syntax semantics, goalprobability analysis without action-cost budget limit. Section 3 specifies searchalgorithm (a) FRET variants (b). Section 4 describes bisimulation reduction method (c).Section 5 describes dead-end pruning methods (d), Section 6 describes node selectionstrategies (e). present experiments Section 7, conclude Section 8.two appendices giving additional technical details sketch main text, Appendix B2. source code available http://fai.cs.uni-saarland.de/downloads/fd-prob.tar.bz23.benchmarksuiteavailablehttp://fai.cs.uni-saarland.de/downloads/ppddl-benchmarks-acyclic.tar.bz2 (acyclic cases) http://fai.cs.uni-saarland.de/downloads/ppddl-benchmarks-cyclic.tar.bz2 (cyclic cases).232fiG OAL P ROBABILITY NALYSIS P ROBABILISTIC P LANNINGregarding Domshlak Mirkis (2015) landmarks compilation, Appendix regarding depthfirst oriented heuristic searches. 42. MDP Modelsconsider PPDDL-style models (Younes et al., 2005), precisely probabilistic extensionsSTRIPS. employ two formalism variants, without limited action-cost budget.specify first unlimited-budget version. Planning tasks tuples = (F, A, I, G) consistingfinite set F facts, finite set actions, initial state F , goal G F .pair (pre(a), O(a)) pre(a) F precondition, O(a) finite setoutcomes o. O(a) tuple (p(o), add (o), del (o))P outcome probability p(o), add listadd (o) F , delete list del (o) F . require oO(a) p(o) = 1.Given task , state space probabilistic transition system (S, P, I, S> ). Here,set states, associated set F (s) true facts. initial state .set goal states S> contains G F (s). Transitions, transitionprobability function P : 7 [0, 1], defined follows. Action applicable statepre(a) F (s) 6 S> (goal states absorbing, see also below). A[s] denoteset actions applicable s. Given s, A[s], outcome O(a), sJoK denoteresult outcome s, i.e., F (sJoK) := (F (s) add (o)) \ del (o). define P (s, a, t) := p(o)applicable = sJoK.5 Otherwise, define P (s, a, t) := 0 (there transition).Absorbing states outgoing transitions (no applicable actions). set non-goalabsorbing states lost states denoted .limited-budget planning, extend follows. limited-budget task tuple= (F, A, I, G, b), including also budget b R+0 , associating.additiontruefactsF(s),states alsoaction outcome cost c(o) R+0associated remaining budget b(s) R. States negative remaining budget b(s) < 0legal may occur, lost, , due following definitions goal states,action applicability, transitions. goal states S> G F (s)b(s) 0, i.e., must reach goal 0 remaining budget. actions applicablepre(a) F (s) least one outcome fits within remaining budget, i.e.,exists O(a) c(o) b(s). outcome states sJoK, outcomes cost deducedremaining budget, i.e., b(sJoK) := b(s) c(o).notes order regarding limited-budget planning. c(o) > 0 o, statespace viewed directed graph arc (s, t) whenever action mappingnon-0 probability acyclic every transition strictly reduces remaining budget.state space infinite due continuous state variable b(s), reachable part (whichalgorithms consider) finite. Note remaining budget local state.states policy violate budget, parts policy (even outcomesaction) still continue trying reach goal. differs constrained MDPs (Altman,1999), budget bound applied globally expected cost policy. Also note4. paper extension previous conference paper (Steinmetz, Hoffmann, & Buffet, 2016). cover largerspace algorithms (now including depth-first oriented heuristic searches), provide comprehensive explanationsdiscussions, present experiments detail.5. assume O(a) leads different outcome state. simplify notation (ourimplementation make assumption).233fiS TEINMETZ & H OFFMANN & B UFFETthat, single budget considered sake simplicity, framework resultsstraightforwardly extend models multiple budget variables.Limited-budget planning explored deterministic oversubscription setting, objective maximize reward achieved (soft) goals subject budget (Domshlak& Mirkis, 2015). classical-planning variant would relate resource-constrained planning (e.g.Haslum & Geffner, 2001; Nakhost, Hoffmann, & Muller, 2012; Coles, Coles, Fox, & Long, 2013)single consumed resource. probabilistic variant previously consideredHou et al. (2014). Prior work probabilistic planning resources (e.g. Marecki &Tambe, 2008; Meuleau, Benazera, Brafman, Hansen, & Mausam, 2009; Coles, 2012) oftenassumed limited budgets non-0 consumption, dealt uncertain-continuous resourceconsumption, contrast discrete fixed budget consumed action costs.Though relatively restricted, limited-budget probabilistic planning quite natural. Decisionmaking often constrained finite budget. Furthermore, non-0 costs often reasonableassume. applies to, example, penetration testing. Problems asking achieve goal withingiven number steps, e.g. finite-horizon goal probability maximization, special case.Let us define solutions planning tasks, well objectives wishachieve. policy partial function : \ (S> ) 7 {}, mapping non-absorbingstate within domain either action applicable s, dont care symbol .symbol used (only) policies already achieve sufficient goal probability elsewhere,need elaborate act descendants. is, still require closedpolicies (see below), use explicitly indicate special cases actions may chosenarbitrarily. Formally, (s) = extends domain picking, every 6 S> reachable(t) undefined, arbitrary action applicable setting (t) := a.policy closed state if, every state 6 S> reachable , (t)defined. closed closed initial state I. proper if, every statedefined, eventually reaches absorbing state probability 1.6Following Kolobov et al. (2011), formulate goal probability maximal non-discountedexpected reward reaching goal gives reward 1 rewards 0. valueV (s) policy closed state is:S>1V (s) = 0P(1)P (s, (s), t)V (t) otherwiseoptimal value stateV (s) =max: closedV (s)(2)Observe that, difference Kolobov et al. consider problems general MaxProb, dont need exclude improper maximization.negative rewards, i.e., policies cannot gain anything infinite cycles.Given value function V (any function mapping states R), Bellman update operatordefined, usual, maximization actions relative current values given V :6. Keep mind absorbing states setting S> , i.e., goal states lost states. SSPpolicy considered valid executions end goal state finding shortest pathimplies path exists MaxProb policy valid executions end absorbing (goal non-goal)state executions may fail, need always terminate.234fiG OAL P ROBABILITY NALYSIS P ROBABILISTIC P LANNINGS>1V (s) := 0PmaxaA[s] P (s, a, t)V (t) otherwise(3)difference V (s) prior update, updated value according right-handside, called Bellman residual.greedy policy value function V selects non-absorbing state action obtaining maximum right-hand side equation (note greedy policy uniquetie-breaking). refer state space subgraph induced states reachableusing greedy policy -greedy graph. V -greedy graph, referstate space subgraph induced states reachable greedy policy V , i.e.,allowing state choose action greedy V .acyclic state spaces, every run ends absorbing state finite number steps,facing SSP problem (subject definition absorbing states, cf. above)Bellman update operator unique fixed point V , converges initial V .cyclic state spaces, pointed Kolobov et al. (2011), Bellman update operator maymultiple sub-optimal fixed points, updates optimistic (upper-bound) initializationV guaranteed converge optimum V . One either use pessimistic (lowerbound) initialization V , updates guaranteed converge V ; one useKolobov et al.s FRET method described earlier.consider three different objectives (algorithmic problems) goal probability analysis:MaxProb: Find optimal policy, i.e., closed s.t. V (I) = V (I).AtLeastProb: Find policy guaranteeing user-defined goal probability threshold [0, 1], i.e.,closed s.t. V (I) . (Or prove exist.)ApproxProb: Find policy optimal user-defined goal probability accuracy [0, 1], i.e.,closed s.t. V (I) V (I) .define algorithm family addressing problems. cover search algorithms, bisimulation reduction, dead-end pruning, node selection strategies, order.3. Search Algorithmsuse value iteration (VI) baseline. design variants AO LRTDP, well familydepth-first oriented heuristic searches, systematizing algorithm parameters underlying improvedLAO (here: ILAO ) (Hansen & Zilberstein, 2001), heuristic dynamic programming (Bonet &Geffner, 2003a), learning depth-first search (Bonet & Geffner, 2006). furthermore designvariant FRET better suited problems uninformative initial upper bounds.3.1 VIpre-process VI, make one forward pass building reachable state space (actuallypruned subgraph, see Section 5). initialize value function pessimistically, simply 0everywhere. acyclic cases, perform single backward pass Bellman updates, startingabsorbing states updating children parents, thus computing optimal value functionupdating every state exactly once.235fiS TEINMETZ & H OFFMANN & B UFFETprocedure GoalProb-AOinitialize consist I; Initialize(I)loop[MaxProb: V L (I) = 1][AtLeastProb:V L (I) ][ApproxProb: V L (I) 1 V U (I) V L (I) ]return L endif /* early termination (positive) */[AtLeastProb: V U (I) < ]return impossible endif /* early termination (negative) */ex. leaf state 6 S> reachable using Uselect stateelse return U endif /* regular termination */P (s, a, t) > 0already containedinsert child ; Initialize(t)else insert new parentendifendforBackwardsUpdate(s)endloopprocedureInitialize(s):0UV (s) :=1 otherwise1 S>LV (s) :=0 otherwise6 S> L (s) := endifFigure 1: AO* search MaxProb, AtLeastProb, ApproxProb (as indicated), acyclic statespaces. U current greedy policy V U , L current greedy policy V L .BackwardsUpdate(s) procedure updates V U , U , V L , L . states mayseveral parents , first make backwards sweep collect sub-graph |s ending(to update V U U , greedy sub-graph V U suffices). update |sreverse topological order.general/cyclic case, assume convergence parameter (likewise algorithms addressing case), compute -consistent value function, Bellmanresidual every state . efficient value iteration, employ topological VI perDai et al. (2011): find strongly connected components (SCC) state space, handleSCC individually, children SCCs parent SCCs. VI SCC stops every state-consistent.Dai et al. (2011) also introduce focused topological VI, eliminates sub-optimal actionspre-process obtain smaller SCCs. much runtime-effective, stillrequires building entire state space. experiments, runtime/memory exhaustionprocess, i.e., building state space, reason VI failures.consider focused topological VI here.3.2 AOAO , restrict acyclic case, overhead repeated value iterationfixed points, inherent LAO (Hansen & Zilberstein, 2001), disappears. (The ILAO variant,236fiG OAL P ROBABILITY NALYSIS P ROBABILISTIC P LANNINGissue addressed depth-first orientation, covered partdepth-first oriented heuristic search family introduced Section 3.4 below.)Figure 1 shows pseudo-code GoalProb-AO variant. algorithm incrementally constructs subgraph state space. handling duplicates simple, identifying searchnodes states, state space acyclic. reason, simple backward updatingsuffices maintain value function. Adopting ideas prior work (e.g. McMahan et al., 2005;Little, Aberdeen, & Thiebaux, 2005; Smith & Simmons, 2006; Kuter & Hu, 2007), maintaintwo value functions, namely upper bound V U lower bound V L goal probability.lack heuristic estimators goal probability, value functions initialized trivially,1 V U 0 V L , except absorbing states exact value known. (Dead-enddetection, simple non-trivial V U initialization, discussed Section 5.) Nevertheless,bounds useful search, early termination (V L V U ), detectingsub-optimal parts state space (V U ). observe latter, note that, refute action a,may suffice reduce V U one outcomes. Hence, even trivial initialization, V Umay allow disregard parts search space, usual way admissible heuristic functions.shall see, kind behavior occurs frequently practice (as reflected benchmarks).Regarding early termination, lower bound enables positive early terminationalready guarantee sufficient goal probability, namely 1 (MaxProb), (AtLeastProb), 1 (ApproxProb). upper bound enables negative early termination AtLeastProb, V U (I) < .ApproxProb, clearly terminate V U (I) V L (I) . relevant observationV L (I) = 1 (MaxProb) V L (I) 1 (ApproxProb) criteria redundantmaintaining upper bound, i.e., heuristic search: V L (I) 1 , trivially alsoV U (I) V L (I) . V L (I) = 1, search branch achieving goal certainty,V U (I) = 1 well search terminates regularly. configurations maintaining V U ,however, criteria useful reduce search.correctness GoalProb-AO easy establish. standard properties Bellmanupdates, point time execution algorithm, state ,V L (s) V (s) V U (s), i.e., V L V U lower respectively upper bounds goalprobability. Indeed, bounds monotone (Bertsekas & Tsitsiklis,1996), precisely, V LPULV exact absorbing states, satisfy V (s) maxaA[s] P (s, a, t)V L (t) respectivelyPV U (s) maxaA[s] P (s, a, t)V U (t) non-absorbing ones. V L V Uinitialized functions trivially satisfying properties, properties invariantBellman updates non-absorbing states (given monotonicity, V L grow, V Udecrease). Thanks monotonicity, arguments given LAO (Hansen &Zilberstein, 2001), get V U converges V finite time U -greedy graph.Finally, need prove that, case early termination returning L , greedy policy LV L actually achieves want, i.e., (1) L closed (2) L provides sufficient goalLprobability, i.e., V (I) V L (I). (1), L always closed policy, appliesdont care symbol non-absorbing leaf states . (Note also applied LLstates.) (2), show that, states s, V (s) V L (s).claim trivial states L (s) = , never updated V L (s) = 0.states s, claim follows simple inductive reasoning maximal distanceLabsorbing state L -greedy graph. absorbing states s, V (s) = V L (s) = V (s),PLLclaim trivially satisfied. induction step, V (s) = P (s, L (s), t)V (t)LLdefinition V , while, induction hypothesis, V (t) V L (t) states237fiS TEINMETZ & H OFFMANN & B UFFETprocedure GoalProb-LRTDP:= {I}; Initialize(I)loop[early termination criteria exactly GoalProb-AO ]labeled solvedLRTDP-Trial(I)else return U endif /* regular termination */endloopprocedure LRTDP-Trial(s):P := empty stacklabeled solvedpush onto PS> break endif[cyclic: -consistent break endif]P (s, a, t) > 06 Initialize(t) endifendforupdate V U (s), U (s), V L (s), L (s):= sample according P (s, U (s), t)endwhileP emptypop P[acyclic: CheckSolved(s, 0) break endif][cyclic: CheckSolved(s, ) break endif]endwhileFigure 2: LRTDP MaxProb, AtLeastProb, ApproxProb, acyclic general (cyclic) statespaces. U current greedy policy V U , L current greedy policy V L .CheckSolved(s, ) procedure exactly specified Bonet Geffner (2003b).visits states reachable using U , initializing previously visited, stopping-consistent. performs updates bottom-up, labeling solved iffdescendants -consistent. change update V L L along V UU .PLP (s, L (s), t) > 0, words V (s) P (s, L (s), t)V L (t). pluggingdefinition L (s), using monotonicity property, easy concludeLV (s) V L (s), desired.3.3 LRTDPFigure 2 shows pseudo-code GoalProb-LRTDP variant, applicable general case (cyclicwell acyclic problems). assume that, cyclic cases, algorithm run within FRETframework. main change original version LRTDP consists maintaining lowerbound addition upper (optimistic) bound, adding early termination criteriaGoalProb-AO . Correctness early termination follows arguments before, i.e.,V L (s) V U (s) monotone lower respectively upper bounds, L always closed policy.Note true even general/cyclic case, i.e., early termination applies,terminate overall FRET process.change make additional stopping criterion trials cyclic case,namely current state -consistent. Kolobov et al. (2011) use criterion keep trials238fiG OAL P ROBABILITY NALYSIS P ROBABILISTIC P LANNINGprocedure GoalProb-DFHS:= {I}loop[early termination criteria exactly GoalProb-AO ](Label labeled solved)(VI U changed running VI U -greedy graph)DFHS-Exploration(I)clean visited-markerselse return U endif /* regular termination */endloopprocedure DFHS-Exploration(s):6 Initialize(s) endifS> labeled solvedlabel solvedreturnendiff lag :=FWV U (s) -consistent f lag := > endifupdate V U (s), U (s), V L (s), L (s)Consist f lag return > endifendifmark visitedforeach P (s, U (s), t) > 0visited f lag := DFHS-Exploration(t) f lag endifdonef lag FWV U (s) -consistent f lag := > endifupdate V U (s), U (s), V L (s), L (s)endifLabel f lag label solved endifreturn f lagFigure 3: Depth-First Heuristic Search (DFHS) acyclic MaxProb, AtLeastProb, ApproxProb. cyclic version shown Appendix uses Tarjans SCC procedureinstead depth-first search. VI, Label, FW, Consist Boolean algorithm parameters (see text). Recall U -greedy graph set states reachable usingcurrent greedy policy U . f lag returned DFHS-Exploration used insiderecursion (it ignored top-level calls), decide whether backward-updatestate forward-updates use.getting trapped 0-reward (non-goal) cycles. criterion preserves property that, uponregular termination, states reachable using U -consistent.7cyclic case, V U fixed point found LRTDP may sub-optimal, useFRET. acyclic case, use = 0, single call LRTDP suffices.239fiS TEINMETZ & H OFFMANN & B UFFET3.4 Depth-First Heuristic Searchfinally consider systematic heuristic searches (not based trials like LRTDP) strongdepth-first orientation. Intuitively, orientation especially beneficial contextlikely lead absorbing states, thus states non-trivial heuristic function initialization,quickly. refer algorithms Depth-First Heuristic Search (DFHS). Known instancesILAO (Hansen & Zilberstein, 2001),8 heuristic dynamic programming (HDP) (Bonet & Geffner,2003a), learning depth-first search (LDFS) (Bonet & Geffner, 2006). commonality liesconducting depth-first searches (DFS) state-space subgraph defined actions greedycurrent upper bound V U , updated backwards DFS, termination criterion applies. algorithms differ depth-first branches terminated, overall algorithmterminated, whether updates also performed forward direction. Here, systematize parameters, obtaining DFHS algorithm family containing previous algorithmsfamily members.Figure 3 gives pseudo-code description DFHS algorithm family. simplicity,figure considers acyclic problems only. cyclic problems, instead DFS algorithms useTarjans depth-first SCC algorithm (Tarjan, 1972), order detect SCCs timeexploration updates, suggested Bonet Geffner (2003a). (KnowingSCCs required correct solved-labeling general case.) pseudo-code descriptionDFHS algorithm family general (cyclic) case given Appendix A.algorithms search U -greedy graph. variant would instead search V U greedy graph. variant, employed LDFS, effective goal probability analysisV U 1 everywhere initially, V U -greedy graph entire (dead-end pruned) reachablestate space. hence omit option, therewith LDFS, DFHS family (matters maychange better admissible heuristic functions identified future work, cf. Section 8).algorithms update values backward direction, leaving state. FW algorithmparameter true, value updates done also forward direction, entering state.consistently yields (small) advantages empirically, switch FW true algorithmconfigurations, except one corresponding known algorithm ILAO usetechnique. Detecting whether optimal solution found done two ways: (1)Label, maintaining solved-labels DFS; (2) VI, running value iteration U greedy graph DFS terminated. (1), U optimal initial state labeled solved.(2), one terminate greedy policy change VI. use forward updates,(as already check Bellman residual anyway) additional option Consiststop search -inconsistent states, opposed stopping absorbing states. Overall,run 5 different parameter settings DFHS, overviewed Table 1.Correctness early termination follows arguments before.correctness regular termination, need show fixed point policy obtained, i.e., uponregular termination, (*) U -greedy graph contains -inconsistent states. holdsalgorithm variants fit Bonet Geffners (2003a) Find-and-Revise schema finite statespace monotone optimistic bound, (1) search iteration find update7. updates trials are, difference original LRTDP formulation, related trial-stopping guaranteegoal probability maximization. turn consistently yield (small) advantages empirically, keephere.8. brief description ILAO Hansen Zilberstein (2001) thus depth-first orientation subjectinterpretation. design follows Bonet Geffner (2005) mGPT tool.240fiG OAL P ROBABILITY NALYSIS P ROBABILISTIC P LANNINGAcronymDFHSVIDFHSFwdVIDFHSFwdConsVIDFHSFwdLabDFHSFwdConsLabTerminationVIVIVILabelLabelFW?yesyesyesyesCons?yesyesKnown?yes: ILAO (Hansen & Zilberstein, 2001)no: new variantno: new variantno: new variantyes: HDP (Bonet & Geffner, 2003a)Table 1: Depth-First Heuristic Search (DFHS) family overview. include LDFS (Bonet& Geffner, 2006) as, due considering V U -greedy graph rather U -greedygraph, LDFS work well MaxProb (see text).least one -inconsistent state, (2) condition (*) met. Given depth-first search (respectivelyTarjans algorithm, general case) clear (1) holds true. Regarding (2), obviousVI termination option used;9 holds Label termination option statelabeled solved descendant states U -greedy graph -consistent.done Table 1, usually omit GoalProb- algorithm names. Keep mindthough algorithms differ original ones, particular terms early terminationdepends objective MaxProb, AtLeastProb, ApproxProb. study terminationbenefits lower vs. upper bound, switch bound individually.X denotes one search algorithms, denote X|U X|L variants X maintainingV U respectively V L . sometimes write X|LU make explicit boundsused. Early termination criteria involving non-maintained bound disabled. X|U ,leaves negative criterion V U (I) < AtLeastProb; X|L still positive criteria.test version X|L X=AO , canonical representative (non-VI) blind search.AO |L , non-absorbing leaf states open (rather reachable using U ),case regular termination return L .3.5 FRETpreviously hinted, Kolobov et al.s (2011) FRET performs iteration complete searches.starts upper-bound approximation V U V , continuously updated throughoutFRET process. Within FRET iteration, heuristic search algorithm runs termination,i.e., finding fixed point policy. iterations, FRET runs trap eliminationstep, finds traps V U -greedy graph. FRET forces next search iterationinclude traps. FRET terminates V U -greedy graph contain trap.trap elimination step works follows. trap subset non-absorbing statesgreedy policy remain indefinitely, i.e., outgoing transitions V U -greedygraph lead another trap state . trap removed collapsing statessingle state sT . incoming transitions sT incoming state ,outgoing transitions transitions -states exiting (note transitions are,construction, contained V U -greedy graph).transformation obviously prevents occuring later iterations. preservesV trap states identical V values: trap states non-absorbing reachother, states reach 0-reward transitions (note holds regardless9. Note that, acyclic case, full VI actually needed algorithm could simplified. leave wayhere, used ILAO general case, simplicity presentation.241fiS TEINMETZ & H OFFMANN & B UFFETV U , i.e., holds also parts state space V U yet converged).finite number possible traps state space, FRET eventually finds V U whose V U greedy graph contain trap. graph, V U -greedy policy extracted,contain traps, hence proper trap-collapsed state space, hence optimalstate space. optimal policy original task constructed acting, withincollapsed traps, way exit taken eventually reached certainty. (Thiscorrectness argument given Kolobov, 2013.)new variant FRET differs original version terms state spacesubgraph considered: instead V U -greedy graph, use U -greedy graph, i.e., consideractions selected current greedy policy (cf. discussion DFHS above).refer design FRET- U , refer Kolobov et al.s (2011) design FRET-V U .easy see FRET- U still correct. arguments remain intact stated.FRET-V U potentially eliminates traps iteration, may hence require fewer iterations. Yet traps may actually need eliminated (we might eventually find optimalpolicy entering them), trap elimination step may much costly. particular,goal probability analysis, FRET-V U typically ineffective because, similarly discussedDFHS, first FRET step V U often 1 almost everywhere, V U -greedy graphalmost entire reachable state space. shall see, FRET- U clearly outperforms FRET-V U .4. State-Space Reduction via Determinized BisimulationBisimulation known method reduce state space size MDPs/probabilistic planning (e.g.Dean & Givan, 1997). idea essentially group equivalent sets states together blockstates, solve smaller MDP block states. Here, observe approach fruitfully combined state-of-the-art classical planning techniques, namely mergeand-shrink heuristics (Drager, Finkbeiner, & Podelski, 2009; Helmert, Haslum, Hoffmann, & Nissim, 2014), allow effectively compute bisimulation determinized state space.Determinized-bisimilar states bisimilar probabilistic state space well, identifies practical special case probabilistic bisimulation given factored (STRIPS-like) problemspecification.Let us spell little detail. Given task (with without budget limit),probabilistic bisimulation partitioning P = {B1 , . . . , Bn } state set that,every Bi Bj , every action a, every s, Bi , following two properties satisfied(Dean & Givan, 1997):(i) applicable iff applicable t;PP(ii) applicable t, oO(a),sJoKBj p(o) = oO(a),tJoKBj p(o).Dean Givan show optimal solution bisimulation MDP induces optimalsolution MDP itself. words, suffices work block states Bi .Now, denote det all-outcomes determinization (e.g. Yoon et al., 2007; Little& Thiebaux, 2007), separate action adetevery O(a), inheriting preocondition os adds, deletes, cost. determinized bisimulation partitioningP = {B1 , . . . , Bn } states that, every Bi Bj , every determinized action adet,every s, Bi , following two properties satisfied (Milner, 1990; Helmert et al., 2014):det(a) adetapplicable iff ao applicable t;242fiG OAL P ROBABILITY NALYSIS P ROBABILISTIC P LANNINGdetdet(b) adetapplicable t, sJao K Bj iff tJao K Bj .easy see {B1 , . . . , Bn } also probabilistic bisimulation . Since actionadetapplicable state iff corresponding action original MDP applicable s,(a) directly implies (i). (b), know every action applicable s, t,detoutcome O(a), sJadetK Bj iff tJao K Bj . obviously implies (ii);restrictive needed insists subset outcomes sides, rathersummed-up probability same.compute determinized bisimulation ? nave solution build statespace front computing determinized bisimulation it. One potentially muchbetter though, using merge-and-shrink widely employed shrinking strategies basedbisimulation (Nissim, Hoffmann, & Helmert, 2011; Katz, Hoffmann, & Helmert, 2012; Helmertet al., 2014). nutshell, algorithm framework constructs abstraction startingcollection abstractions considering single state variable only, iteratively mergingtwo abstractions (replacing synchronized product) single abstractionleft, shrinking abstractions bisimulation thereof every merging step.shall see experiments, often still incurs prohibitive overhead, feasible,lead substantial state space size reductions. cases, results tremendous performanceimprovements.5. Dead-End Pruningrefer states V (s) = 0, i.e., goal cannot reached s, dead-ends.one detects via dead-end detection technique, one treat exactly like loststate (except setting L (s) := need act non-absorbing states). constitutespruning method itself, useful search algorithm, state space needslonger explored. Apart pruning itself, heuristic search algorithms, dead-enddetection provides non-trivial initialization V U , initialize V U (s) = 0 insteadV U (s) = 1 detected dead-end. informed initial upper bound typicallyleads additional search reductions.detect dead-ends? Kolobov et al. (2011) employ SixthSense (Kolobov et al., 2010),learns dead-end detection rules generalizing information obtained using classical planner. instead exploit power classical-planning heuristic functions readilyavailable FD implementation framework run all-outcomes determinization.especially promising limited-budget planning, use lower bounds determinizedremaining cost detect states insufficient remaining budget. Observe naturaleffective using admissible remaining-cost estimators, yet would impractical using actual classical planner (which would need optimal thus prohibitively slow). unlimited-budgetcase, use heuristic function able detect dead-ends (returning ), appliesknown heuristics. Indeed, merge-and-shrink heuristics recently shown extremely competitive dead-end detectors (Hoffmann, Kissmann, & Torralba, 2014).make concrete, consider state task , denote det alloutcomes determinization . Let h classical-planning heuristic function. h guaranteesreturn dead-ends, h(s) = det , exists sequence actionoutcomes achieving goal s, V (s) = 0. limited-budget task, h admissible,h(s) > b(s), cannot achieve goal within budget, thus also V (s) = 0.243fiS TEINMETZ & H OFFMANN & B UFFETexperiment state-of-the-art heuristic functions, namely (a) admissible landmarkheuristic per Karpas Domshlak (2009), (b) LM-cut (Helmert & Domshlak, 2009), (c) severalvariants merge-and-shrink heuristics, (d) hmax (Bonet & Geffner, 2001) simplecanonical option. (a) turned perform consistently worse (b), report(b) (d).limited-budget planning, also considered adopting problem reformulation Domshlak Mirkis (2015) oversubscription planning, reduces budget b using landmarksexchange allows traversing yet unused landmarks reduced cost search. turnsout, however, pruning states whose reformulated budget < 0 equivalent much simpler method pruning states whose heuristic (a) exceeds (original/not reformulated) remainingbudget. added value Domshlak Mirkis reformulation thus lies, pruning per se,compilation planning language resulting combinability heuristics.give full details Appendix B. get intuition Domshlak Mirkis reformulationis, per se, equivalent (a), assume simplicity L set disjoint disjunctive action landmarks initial state, assume actions unit costs. Say prune reduced budget, b0 (s), < 0. reduced initial budget b0 := b|L|. reduced costs allow applying member actions yet non-used landmarks 0 cost, non-used landmarks given searchpath l L touched path. Consider state reached path ~a. Denotenon-used landmarks L0 . cost saved ~a thanks reformulation exactlyused landmarks, |L\L0 |. Hence b0 (s) = b0 (|~a||L\L0 |) = (b|L|)|~a|+|L\L0 | = b|~a||L0 |.pruned reformulation, b0 (s) < 0, iff b |~a| |L0 | < 0 iff b |~a| < |L0 |. lattercondition, however, exactly pruning condition using simple method (a) instead.6. Node Selection Strategiesalgorithms, good anytime behavior V L and/or V U may translate early termination.explore potential fostering via (1) biasing tie-breaking selection bestactions U greedy respect V U , (2) biasing, respectively, outcome-state samplingtrials (LRTDP) choice expanded leaf states (AO ). precise regardinglatter: usual, maintain state open flags AO , true state open descendants withinU -greedy graph. select leaf state expand going forward using U ,action one open outcome state t, select best according bias (2). Note(2) relevant DFHS, every iteration DFS explores outcomes anyhow.Hence, DFHS, use U tie-breaking criteria (1) explained follows.experimented variety strategies. follows, strategy specifies one(1) (2) only, setting default strategy. strategy correspondscommonly used settings. uses arbitrary tie-breaking (1), fixed manner, changingU (s) action becomes strictly better s, suggested Bonet Geffner(2003b) LRTDP. bias (2) outcome states AO (an open outcome state selectedarbitrarily). Bias (2) LRTDP outcome probability. also tried most-prob-outcomebias strategy AO , likely open outcome state selected.h-bias strategy prefers states smaller h value, heuristic h oneused dead-end pruning.10 Specifically, action selection tie-breaking (1), actions10. also experimented strategy using merge-and-shrink determinized action costs set negatedlogarithm outcome probability (compare e.g. Jimenez, Coles, & Smith, 2006). compelling theory244fiG OAL P ROBABILITY NALYSIS P ROBABILISTIC P LANNINGPUmaximizing optimistic expectedPgoal probability P (s, a, t)V (t), select minimizing expected heuristic value P (s, a, t)h(t). outcome-state bias (2) obtained1renormalizing weighed probabilities h(t)P (s, a, t), prefer high probability outcomessmall h value.Inspired BRTDP (McMahan et al., 2005), experiment gap-bias strategy, biasingULsearch towards states largePrecisely, (1) break ties favor actionsPV V gaps.maximizing expected gap P (s, a, t)[V U (t)V L (t)], (2) renormalize weighedprobabilities [V U (t) V L (t)] P (s, a, t).Inspired common methods classical planning (e.g. Hoffmann & Nebel, 2001; Helmert,2006; Richter & Helmert, 2009), experiment preferred actions strategy, (1)U (s) action participating delete-relaxed determinized plan s,prefers set Pmaximizing P (s, a, t)V U (t) exists.AO |L special case, maintain upper bound thus selection(1) actions U greedy respect V U . apply node selection strategies (2) directlyset (all) leaf states current search graph . default strategy depth-first,rationale try reach absorbing states quickly. h-bias strategy selects deepest leafminimal h value, preferred actions strategy selects deepest open leaf reachable usingpreferred actions. furthermore experiment breadth-first strategy, comparison.7. Experimentsimplemented algorithms Fast Downward (FD) (Helmert, 2006), ran experimentsextensive suite benchmarks.11 evaluation first summarize results acyclicbenchmarks (where FRET needed), ones cyclic benchmarks (where FRETneeded).7.1 Experiments Setupstart giving details implementation describing benchmark suite usedexperiments.7.1.1 MPLEMENTATIONmodel pertains goal-directed MDPs limited number (explicitly listed) outcomesper action, naturally use PPDDL (Younes et al., 2005), rather RDDL (Sanner, 2010; Coleset al., 2012), surface-level language. FDs pre-processes extended handle PPDDL,added support specifying (numeric) budget limit.Given FD implementation framework contrast previous works optimal probabilisticplanning, implemented algorithms scratch. FRET, closely followed originalimplementation, details specified Kolobov et al. (2011), based personal communication Andrey Kolobov. (Kolobovs original source code available anymore, alsoplays role state-of-the-art comparison, see next.)because, then, bisimulation-based heuristic corresponds exact goal probability best outcome sequencestate. Yet, already pointed out, computing heuristic often infeasible.11. source code available online appendix, downloaded http://fai.cs.unisaarland.de/downloads/fd-prob.tar.bz2245fiS TEINMETZ & H OFFMANN & B UFFETGiven scant prior work optimal goal probability analysis (cf. Section 1), state artrepresented topological VI, LRTDP|U dead-end pruning acyclic problems,FRET-V U using LRTDP|U dead-end pruning cyclic problems. configurationsparticular points space configurations explore, comparison state artpart comparison across configurations. thing missing particular formdead-end detection, SixthSense prior work, Kolobov et al. (2011).SixthSense complex method advanced dead-end pruning via heuristic functions readilyavailable framework, re-implement SixthSense. discussion cyclic problemsSection 7.3 includes detailed comparison results Kolobov et al.,IPPC ExplodingBlocks domain Kolobov et al. considered.Note providing quality guarantees important property study. reason,sake clarity, compare unbounded suboptimal approaches,using algorithm discounted criterion assigning large finite penalties dead-ends(Teichteil-Konigsbuch et al., 2011; Kolobov et al., 2012).Furthermore, AtLeastProb special case MDP model checking, one may wonderprobabilistic model checking tools, e.g. PRISM (Kwiatkowska et al., 2011b), would fareproblem planning benchmarks. investigate question here, would entailtranslation PPDDL model checking language, non-trivial makes directcomparison algorithms taking different inputs problematic. One may speculate that, givenfocus blind searches, model checking tools inferior heuristic search approachesfare well; remains question future work.7.1.2 B ENCHMARK UITEaim comprehensively explore relevant problem space, designed broad suitebenchmarks, 1089 instances total, based domains IPPC, resource-constrainedplanning, penetration testing (pentesting).IPPC, selected PDDL domains STRIPS format, moderate nonSTRIPS constructs easily compilable STRIPS. resulted 10 domains IPPC04IPPC08; selected recent benchmark suite these.resource-constrained planning, adopted NoMystery, Rovers, TPP benchmarksNakhost et al. (2012), precisely suites single consumed resource (fuel, energy, money), correspond limited-budget planning.12 created probabilistic versionsadding uncertainty underlying road map, akin Canadian Traveler scenario,road segment present given probability (this encoded separate, probabilistic, action attempting segment first time). simplicity, set probability 0.8throughout.pentesting, general objective using exploits compromise computers network, one another, specific targets reached (or action available). modifiedPOMDP generator Sarraute, Buffet, Hoffmann (2012), based test scenario used Core Security (http://www.coresecurity.com/) output PPDDL encodingsHoffmanns (2015) attack-asset MDP pentesting models. models, network configura12. make benchmarks feasible optimal probabilistic planning, reduce size parameters (numberlocations etc). scaled parameters number < 1, chosen get instances borderlinefeasibility VI.246fiG OAL P ROBABILITY NALYSIS P ROBABILISTIC P LANNINGtion known fixed, exploit callable succeeds (or fails) probability. generator uses network consisting exposed part, sensitive part, user part.allows scale numbers H hosts E exploits. Sarraute et al.s POMDP modelsolver (SARSOP, see Kurniawati, Hsu, & Lee, 2008, guarantee optimality) scaleH = 6, E = 10.13 benchmarks, fixed H = E simplicity (and obtain numberinstances similar benchmark domains). scaled instances 6 . . . 20 withoutbudget limit, 10 . . . 24 budget limit.benchmark tasks (except pentesting ones alreadygenerated separate limited-budget version anyway), obtained several limited-budget benchmarks, follows. set outcome costs 1 otherwise specified. determinedminimum budget, bmin , required achieve non-0 goal probability. resource-constrainedbenchmarks, bmin determined generator itself, minimum amount resource requiredreach goal deterministic domain version. benchmarks, ran FDLM-cut all-outcomes determinization . failed, skipped , otherwiseread bmin cost optimal plan created several limited-budget tasks [C], differingconstrainedness level C. Namely, following Nakhost et al. (2012), set global budget b[C] b := C bmin , C factor available budget exceeds minimumneeded (to able reach goal all). let C range {1.0, 1.2, . . . , 2.0}.AtleastProb, let range {0.1, 0.2, . . . , 1.0} ( = 0 pointless). ApproxProb,let range {0.0, 0.1, . . . , 0.9} ( = 1 pointless). cyclic problems, convergenceparameter set 0.00005 (the value used Kolobov et al., 2011). experimentsrun cluster Intel E5-2660 machines running 2.20 GHz, time/memory cut-offs30 minutes/4 GB.7.2 Acyclic Planningconsider first acyclic planning. pertains budget-limited benchmarks, pentestingwithout budget limit, well IPPC TriangleTireworld (moves madeone direction state space acyclic). consider 3 objectives MaxProb, AtLeastProb,ApproxProb. run 16 search algorithm variants (VI, AO , LRTDP, 5 DFHS variants,subsets bounds applicable), 5 node selection strategies explained. deadend pruning, run LM-cut, well merge-and-shrink (M&S) state-of-the-art shrinkingstrategies based bisimulation abstraction-size bound N ; show data N =N = 100k (we also tried N {10k, 50k, 200k} resulted similar behavior). also runvariants without dead-end pruning. use deterministic-bisimulation (DB) reduced state spaceVI: (and if) bisimulation successfully computed, block-state MDP easilysolved simplest algorithm. Given DB, require dead-end pruningdead-ends already removed reduced state space.Overall, yields 577 different possible algorithm configurations. actually testconfigurations, course, interesting, needed make essentialobservations. instead organize experiment terms three parts (1)(3), focusingparticular issue interest. Consider Table 2, gives overview configurationsconsidered experiment. design experiments follows:13. modeling/solving entire network, is. domain-dependent decomposition algorithm 4AL,trading accuracy performance, Sarraute et al. scale much further.247fiS TEINMETZ & H OFFMANN & B UFFETExperimentSearch AlgorithmPruningNode selection# ConfigsAO |U ,MaxProb search & prun- VI, AO |L ,defaultLRTDP|,DFHS|UU (5), (4)ingVI DBVI, AO |L ,AO |U ,AtLeastProb & Approx- AO |LU ,LRTDP|U ,(2)LM-cutdefaultProb parametersLRTDP|LU ,HDP|U ,HDP|LU , VI DBVI, AO |L ,AO |U ,(1, 4, 4, 5, 3,LRTDP|U ,AtLeastProb & Approx- AO |LU ,(3)LM-cut 4, 3, 4, 1 respecLRTDP|LU ,HDP|U ,Prob node selectiontively)HDP|LU , VI DB(1)371858Table 2: Overview algorithms tested acyclic problems, Section 7.2. Numbers brackets givenumber options number obvious. (2) (3), note totalnumber configurations gets multiplied 2 AtLeastProb vs. ApproxProb resultdifferent algorithm configurations (using different termination criteria). HDPmember DFHS family, corresponding Bonet Geffners (2003a)DFHSFwdConsLabHDP algorithm.(1) first evaluate different search algorithms dead-end pruning methods MaxProb, fixingnode selection strategy default.omit X|LU variants, because, explained earlier, MaxProb heuristic search,maintaining V L redundant (early termination dominated regular termination).Using default node selection strategy makes sense node selection strategiesrelevant anytime performance, i.e., early termination. plays minor roleMaxProb, whose early termination possibility exceptional case initial statelower bound becomes V L (I) = 1.(2) next fix best-performing dead-end pruning method, analyze search algorithm performance AtLeastProb ApproxProb function parameter respectively .fix node selection strategy default here, leaving examination experiment(3).(3) finally let node selection strategies range, keeping otherwise setting experiment(2).conclude discussion (4) additional data illustrating typical anytime behavior.part experiment described separate sub-section follows.7.2.1 (1) EARCH LGORITHMS & P RUNING ETHODS AX P ROBTable 3 shows coverage data, i.e., number benchmark tasks MaxProb solvedwithin given time/memory limits.pruning methods, LM-cut clearly stands out. every search algorithm, yieldsfar best overall coverage. M&S substantial advantages RectangleTireworldNoMystery-b. Note that, N = , overall coverage worse using pruningall. due prohibitive overhead, domains, computing bisimulationdeterminized state space. And, invested effort, pays use bisimulation248fiG OAL P ROBABILITY NALYSIS P ROBABILISTIC P LANNINGDomain#TriaTire10Blocksw-bBoxworl-bDrive-bElevator-bExpBloc-bRandom-bRecTire-bTirewor-bTriaTire-bZenotra-b66189090846036906036NoMystery-b 60Rovers-b60TPP-b60Pentest-bPentestP9015925Domain#TriaTire10Blocksw-bBoxworl-bDrive-bElevator-bExpBloc-bRandom-bRecTire-bTirewor-bTriaTire-bZenotra-b66189090846036906036NoMystery-b 60Rovers-b60TPP-b60Pentest-bPentestP9015925DFHSFwdDFHSFwdCons|UDFHSFwdVI |UVILab |ULM M&SLM M&SLM M&SNNNIPPC Benchmarks9 10 10 109 8 8 8 10 10 10 109 8 8 8 10IPPC Benchmarks Budget Limit24 28 24 24 24 28 24 24 24 28 24 24 24 28 24 24 240 3 0 00 3 0 00 3 0 00 3 0 0090 90 90 52 90 90 90 52 90 90 90 52 90 90 90 52 9078 86 79 33 79 86 79 33 78 86 79 33 79 86 79 33 7837 60 39 37 37 60 39 37 36 66 39 37 37 60 39 37 3636 44 36 33 36 44 36 33 36 44 36 33 36 44 36 33 3628 31 36 36 30 31 36 36 30 31 36 36 30 31 36 36 3090 90 90 90 90 90 90 90 90 90 90 90 90 90 90 90 9046 55 55 55 46 55 55 54 46 55 55 55 46 55 55 54 4615 17 17 18 15 17 17 18 12 15 14 15 15 17 17 18 14Probabilistic Resource-Constrained Benchmarks Budget Limit12 40 50 50 12 41 50 50 12 42 50 50 12 41 50 50 1225 46 36 46 25 46 36 46 25 46 36 47 25 46 36 46 2519 38 27 25 19 38 27 25 20 39 27 25 19 38 27 25 20Pentesting Benchmarks57 63 62 37 57 63 62 37 57 63 62 37 57 63 62 37 579 9 9 89 9 9 88 8 8 89 9 9 89575 710 660 554 578 709 658 551 574 716 656 552 578 709 658 551 577DFHSVI |ULM M&SNHDP|ULM M&SN10 10 102839086664431905516240907939363690551642 50 5046 36 4739 27 2563 62 379 9 8718 659 553AO |LAO |ULRTDP|UHDP|ULM M&SLM M&SLM M&SLM M&SNNNNIPPC Benchmarks4 4 4 44 4 4 4 10 10 10 10 10 10 10 10 10 10 10 10IPPC Benchmarks Budget Limit24 28 24 24 24 28 24 24 24 28 24 24 24 28 24 24 24 28 24 240 3 0 00 3 0 00 3 0 00 3 0 00 3 0 090 90 90 52 90 90 90 52 90 90 90 52 90 90 90 52 90 90 90 5271 82 72 33 74 84 76 33 65 77 67 33 79 86 79 33 78 86 79 3332 46 38 37 32 46 38 37 39 57 39 37 38 65 39 37 36 66 39 3727 33 35 33 39 34 36 33 35 44 36 33 36 44 36 33 36 44 36 3330 31 36 36 30 31 36 36 30 31 36 36 30 31 36 36 30 31 36 3690 90 90 90 90 90 90 90 90 90 90 90 90 90 90 90 90 90 90 9045 52 52 52 45 52 52 52 46 55 55 55 47 57 57 57 46 55 55 5515 16 16 18 15 16 16 18 14 16 16 17 15 17 16 17 14 16 16 16Probabilistic Resource-Constrained Benchmarks Budget Limit11 37 43 44 11 36 42 43 12 39 47 47 12 41 50 50 12 42 50 5023 39 31 40 23 38 31 40 23 44 33 45 25 46 35 46 25 46 36 4718 35 25 25 16 35 24 24 15 37 26 22 19 38 27 25 20 39 27 25Pentesting Benchmarks57 63 62 37 57 63 62 37 57 63 63 37 57 63 63 37 57 63 62 379 9 9 89 9 9 89 9 9 89 9 9 89 9 9 8546 658 627 533 559 659 630 531 559 693 641 546 581 718 661 555 577 718 659 553VILM M&SN2405233373336905516VIDB102405233373336906017515026378564Table 3: Acyclic planning. MaxProb coverage (number tasks solved within time & memorylimits). Best values, within table, boldface. Top: DFHS variants (recall HDPDFHSFwdConsmember DFHS family; DFHSVI ILAO ). Bottom: remainingLabsearch algorithms, including also overall best DFHS variant. Domains -b modifiedbudget limit. #: number instances. : pruning; else pruning,remaining budget -b domains, based h = domains. LM: LM-cut;M&S: merge-and-shrink, N size bound N = 100k, size bound. VI DB:VI run reduced (deterministic-bisimulated) state space. Default node selection.249fiS TEINMETZ & H OFFMANN & B UFFET107107106106LRTDP|U (LM-cut)LRTDP|Ureduced MDP state space (VI DB), rather dead-end pruning. extremeexample latter TriangleTireworld. Far beyond standard benchmarks Table 3 (triangleside length 20), VI DB scales side length 74 original domain limited-budgetversion. comparison, hitherto best solver far Prob-PRP (Camacho et al., 2016),scales side length 70 original domain, optimal goal probability 1, i.e.,presence strong cyclic plans holds original domain limited-budgetversion. (We could actually run Prob-PRP limited-budget domain version, Prob-PRPnatively support budget, hard-coding budget PPDDL resulted encodingslarge pre-process.)Comparing different DFHS|U variants, configuration clearly stands out.Overall, perform equally well, though FwdCons variants (cutting explorationinconsistent states rather absorbing states) slight edge. difference mainly comesTriangleTireworld, ExplodingBlocks, TPP-b, FwdCons configurations solveinstances, Zenotravel-b FwdCons configurations perform slightly worse counterparts. termination parameter (VI vs. Label) almost effect coverage. Duegives best coverage results,similarity DFHS configurations, DFHSFwdConsLabrepresentativeDFHSfamilyremaining discussion.use DFHSFwdConsLabFwdConscorresponds HDP, simplicity refer name.DFHSLabAO |L better VI case early termination V L = 1, full-certaintypolicy found visiting entire state space. happens rarely here, AO |Ldominated VI (this changes AtLeastProb, see Figures 5a 7 below). failures VIdue memory runtime exhaustion building reachable state space. LRTDP|U clearlyoutperforms AO |U , presumably tends find absorbing states quickly. LRTDP|UHDP|U par; LM-cut solve exact number instances (thoughexactly instances), otherwise HDP|U solves slightly fewer tasks LRTDP|U .gauge efficiency heuristic search vs. blind search MaxProb, compare LRTDP|U vs.VI Table 3. Contrary intuition good initial goal probability estimator requiredheuristic search useful, LRTDP|U clearly superior. advantage grow qualityinitialization; LM-cut yields largest coverage increase far. However, even withoutdead-end pruning, i.e., trivial initialization V U , LRTDP|U dominates VI throughout,improves coverage 8 16 domains.105104103104103102102101 110105102103104VI105106101 110107102103104105VI (LM-cut)106107Figure 4: Acyclic planning. Number states visited, VI (x) vs. LRTDP|U (y), pruning(left) respectively LM-cut pruning (right). Default node selection.next shed additional light comparing search space sizes runtime values.Tables 4 5 provide aggregate data, Figure 4 gives scatter plot canonical comparison250fiG OAL P ROBABILITY NALYSIS P ROBABILISTIC P LANNINGAO |ULRTDP|ULMM&SLMM&SNNIPPC Benchmarks843.1 843.1 843.1 843.10.2 0.2 0.2 0.20.8 0.7 0.7 0.70.4 0.4 0.4 0.43.5 1.7 1.7 1.7IPPC Benchmarks Budget Limit12.7 5.8 2.8 2.812 5.2 2.5 2.5 12.3 5.3 2.5 2.54.2 2.4 1.8 1.24.2 2.2 1.614 2.1 1.5112.8 3.9 7.233.3 0.3 0.4 0.13.6 0.3 0.4 0.11.1K 41.9 92.1 33.2 112.2 1.2 12.2 0.8 117.8 1.4 12.5 1.24.1K 213.2 859.9 179 603.1 3.6 133.6 2.6 5884 106.8 3.22.6K 1.5 17.2 1.1 3.1K 2.1 21.3 1.64.5 1.7 1.7 1.71.9 0.8 0.8 0.82 0.8 0.8 0.81.0K 130 127.4 127.4 42.6 6.4 6.4 6.4 43.7 6.4 6.4 6.42.7K 15.9 2.2 2.2 2.9K 15.9 2.2 2.250.6 5.6 1.5 1.5 49.8 5.1 1.2 1.2 50.4 5.1 1.3 1.381.9 8.9 2.4 2.4 81.5 8.2 1.9 1.9 81.6 8.3221.4K 6.4 6.4 6.4 898.6333 896.2 2.9 2.9 2.94.1K 229.4 229.4 229.4 1.8K 52.5 52.5 52.5 1.6K 44.5 44.5 44.57.4K 610.3 610.3 610.3 4.6K 303.3 303.3 303.3491.5 30.2 35.8 18.2 491.3 29.9 35.2 17.9 288.2 23.6 27.1 14.1967.4 104.4 164.664 967.1 102.9 161.1 62.3 478.1 75.3 114.9 45.8Probabilistic Resource-Constrained Benchmarks Budget Limit2.8K 6.9 0.5 0.5 2.6K 6.6 0.4 0.4 2.6K 6.4 0.4 0.412.4K 122.4 14.1 14.1 12.7K 122.3 16.4 16.41.1K 51.8 91.5 22.6 702.9 36.1 58.6 12.4 873.7 38.5 70.8 14.32.2K 290.1 512.6 137.6 1.1K 176 281.4 65.9 1.6K 190 366.2 76.34.7K 287.1 709.7 205.2 8.3K 338.3 1.0K 242.11.1K 49.6 265.4 10.9 660.933 183.3 5.7 897.2 38.5 220.7 7.63.0K 178.7 894.6 36.6 1.5K 100.4 549.5 14.3 2.1K 120.1 701.9 21.5Pentesting Benchmarks19.7 6.3 7.8 6.3 19.5 6.3 7.7 6.3 19.7 6.2 7.7 6.2238.1 165.1 169.2 165.1 237.2 165.1 169 165.1 238.1 165.1 169.1 165.174.3 66.3 66.4 66.3 74.3 66.3 66.4 66.3 74.3 66.3 66.4 66.3194.3 173.4 173.8 173.4 194.3 173.4 173.8 173.4 194.3 173.4 173.8 173.4Domain#TriaTireONLY-H14Blocksw-b18Drive-b20Elevator-b12ExpBloc-b18NON-TRIVIAL 7ONLY-H3Random-b21NON-TRIVIAL 4ONLY-H2RecTire-b18NON-TRIVIAL 12TriaTire-b17NON-TRIVIAL 6ONLY-H1Zenotra-b14NON-TRIVIAL 10NoMystery-b 11ONLY-H1Rovers-b21NON-TRIVIAL 13ONLY-H2TPP-b9NON-TRIVIAL 5Pentest-b28NON-TRIVIAL 5Pentest3NON-TRIVIAL 1VILMM&SNHDP|ULMM&SN2.2 1.8 1.8 1.8160.3 835.4 835.4 835.411.5 4.8 2.3 2.34 2.1 1.5 0.93.4 0.3 0.4 0.1150.7 1.2 13.6 0.8780.4 3.4 125.6 2.25.2K 1.9 23.4 1.11.9 0.8 0.8 0.834.5 5.4 5.4 5.42.9K 15.9 2.2 2.250.45 1.2 1.281.5 8.1 1.9 1.9954 3.4 3.4 3.41.8K 67.4 67.4 67.46.2K 634.8 634.8 634.8285.1 23.6 27.4 14.2468.6 75.3 115.9 46.32.7K 6.5 0.4 0.412.7K 117.3 14.2 14.2782.7 35.8 63.2 12.41.3K 173.8 318.4 65.95.9K 265.5 741 189.5765.4 31.3 188.1 5.61.8K 91.3 561.81419.7 6.2 7.7 6.2238.1 165.1 169.1 165.174.3 66.3 66.4 66.3194.3 173.4 173.8 173.4Table 4: Acyclic planning. MaxProb geometric mean search space size (number states visited)multiples 1000. # gives size instance basis, namely instances solvedshown configurations, skipping instances solved 1 second configurations. NON-TRIVIAL uses instances solved VI < 1 second.ONLY-H uses instances commonly solved AO |U , LRTDP|U , HDP|U ,solved VI. Rows empty instance basis skipped. Default node selection.VI LRTDP|U . Data AO |L shown coverage dominated VI (cf.Table 3), goes runtime search space. include NON-TRIVIAL rowstables show behavior interesting instances, averages skewedmany small instances domains. include ONLY-H rows elucidatebehavior challenging instances beyond reach VI.clear message Table 4 Figure 4 heuristic search algorithms, apartexceptions, visit much fewer states VI does, even trivial upper bound initialization search spaces reduced domains except RectangleTireworld Pentest.instance, using LRTDP|U instead VI results gain around 1 order magnitude manyinstances, larger gains (up 3 orders magnitude) also occur rare cases. givingheuristic search algorithms additional information earlier dead end detection, differences become even larger.251fiS TEINMETZ & H OFFMANN & B UFFETDomain#TriaTireONLY-H14Blocksw-b18Drive-b20Elevator-b12ExpBloc-b18NON-TRIVIAL 7ONLY-H3Random-b21NON-TRIVIAL 4ONLY-H2RecTire-b18NON-TRIVIAL 12TriaTire-b17NON-TRIVIAL 6ONLY-H1Zenotra-b14NON-TRIVIAL 10NoMystery-b 11ONLY-H1Rovers-b21NON-TRIVIAL 13ONLY-H2TPP-b9NON-TRIVIAL 5Pentest-b28NON-TRIVIAL 5Pentest3NON-TRIVIAL 1AO |ULRTDP|UHDP|ULM M&SLM M&SLM M&SNNNIPPC Benchmarks3.5 7.4 4.1400 0.1 0.10 0 000 0 0.1 0.10.1 0.1 0.5 0.5 0.1 0.3 0.6 0.61.4 23.9 12.1 12.1IPPC Benchmarks Budget Limit0.1 0.6 2.5 2.31.8 0.83 2.8 0.2 0.6 2.3 2.40.2 0.52 2.10 0.2 6.9 140.1 0.28 15.40 0.2 7.1 14.20 0.2 6.1 12.30.1 0.1 1.8 4.100 2.2 4.50 0 1.8 4.10 0 1.7 3.86 1 15.5 7.51.60 168 0.8 0.1 14.2 7.10.90 13.4 6.625.3 4.8 36.2 45.711.5 0.1 33 45.94 0.1 29.7 42.15 0.1 27.2 39.629.3 0.1 40.9 40.4 21.4 0.1 30.7 34.9 35.1 0.1 30.2 32.50.5 0.6 4.8 4.80.3 0.3 5.2 5.2 0.3 0.3 4.7 4.80.2 0.3 4.4 4.413.9 10.1 39.2 43.23 0.9 44.4 49.9 1.4 0.8 36.3 43.20.8 0.7 35.3 38.227.8 11.3 38.1 42.9 30.3 11.1 35.4 37.4 29.8 10.8 34.8 35.29 19.4 1.2 1.273.6 20.2 1.3 1.3 43.1 17.6 1.3 1.3 131.2 16.4 1.2 1.220.4 57.3 2.3 2.3 178.9 61.8 2.4 2.4 106.8 51.4 2.3 2.3 330.1 46.5 2.3 2.310.5 0.5 0.6 0.614.5 0.4 0.5 0.5 9.5 0.3 0.4 0.48.4 0.4 0.4 0.427.7 5.9 3.2 3.331.3 2.4 2.12 14.72 1.7 1.6 13.7 2.4 1.8 1.7153.2 25.4 13.6 13.6 41.5 11.9 5.1 4.442 18.2 6.9 7.12.7 4.9 15956 5.7 18.9 11.813 4.3 15.9 9.2 52.55 16.8 9.35.6 16.5 27 13.5 163.4 19.3 37.2 18.7 25.3 13.6 30.1 14.5 118.3 16.8 35.2 15.1Probabilistic Resource-Constrained Benchmarks Budget Limit15.6 0.4 0.3 0.3 242.6 0.4 0.3 0.3 27.8 0.4 0.3 0.3 26.2 0.4 0.3 0.31623.4 8.9 0.6 0.6 158.8 7.8 0.5 0.4 137.2 7.3 0.4 0.49.7 2.3 11.8 1796.2 2.3 16.5 21.7 12.82 11.6 16.1 10.8 1.8 9.9 14.920.9 12.9 20.2 33.7 236.6 12 33.3 45.1 24.9 9.7 19.5 30.3 19.2 8.8 15.9 29.1751.2 19.2 76.9 151.4 127.6 18.6 44.8 126.9 85.4 14.8 34.3 105.18.5 1.6 14.9 69.863.2 1.3 24.6 70.2 12.7 1.3 16 69.19.6 1.1 14.3 65.122.4 5.7 18.5 76.2 203.5 4.5 37.3 78.2 31.3 4.2 20.1 76.3 23.2 3.2 17.7 72.4Pentesting Benchmarks0 0 6.6 16.50.50 8.2 19.80 0 7.3 18.20.30 6.5 16.63.2 2.2 10.1 92.716 4.5 15 108.98.5 5.2 15.2 107.66.4 4.4 12.7 1000.9 0.7 3.2 4.45.9 2.3 5.7 6.5 3.83 5.8 6.32.4 2.7 5.1 6.12.72 6.5 17.223 8.1 20.6 23.815 10.4 16.6 24.49.3 10.6 15.2 24.4VILM M&SNTable 5: Acyclic planning. MaxProb geometric mean runtime (in CPU seconds). setuppresentation Table 4.previously hinted, observations made clarity before.Kolobov et al. (2011) also report LRTDP beat VI MaxProb, consider single domain; experiment trivially initialized V U ; use dead-end pruningVI, LRTDP already benefits smaller state space, impact heuristic searchremains unclear.Even though search space heuristic search algorithms many cases smallfraction whole (dead-end pruned) state space, necessarily reflected runtime.instances solved VI, typically fast, often faster heuristic search rarelyoutperformed significantly. despite larger search spaces, i.e., heuristic searchvisit less states suffers updates (recall VI updatesvisited state exactly once). Significant runtime advantages VI (in NON-TRVIAL rows)obtained heuristic search ExplodingBlocksb, Randomb, TriangleTireworldb.Comparing heuristic search algorithms, conclusions fine-grained overallsimilar concluded coverage above. LRTDP|U dominates AO |U almost throughout.Note that, even though search space size AO |U LRTDP|U almost always similar, AO |Urequires lot time LRTDP|U . performs updates. Across nontrivial commonly solved instances tables, geometric mean number updates done252fiG OAL P ROBABILITY NALYSIS P ROBABILISTIC P LANNINGAO |U 4 times higher LRTDP|U . LRTDP|U HDP|U non-trivialvalue initialization give similar results, terms coverage, also termsruntime search space size. LRTDP|U is, however, effective domains (e.g.,RectangleTireworld Zenotravel) additional dead-end detection method used.hand, HDP|U slight edge probabilistic resource-constrained domains. One notablecase LRTDP|U consistently outperforms HDP|U TriangleTireworld.impact dead-end pruning VI typically moderate. gains heuristic searchmuch pronounced, thanks stronger heuristic function initialization. Especially AO |Ubenefits lot. LRTDP|U HDP|U benefit well, smaller extent, partlyalready effective first place. Comparing across different dead-end pruning methods,although M&S N = clearly yields largest search space reductions, necessarilyrecognizes dead-ends, overhead bisimulation computation outweighs search spacereduction cases. terms pruning power, M&S N = 100k LM-cutheuristic overall roughly similar, yet LM-cut edge runtime.7.2.2 (2) L EAST P ROB PPROX P ROB PARAMETER NALYSISturn weaker objectives, AtLeastProb ApproxProb. fix LM-cut (almostalways effective) dead-end pruning. examine power early termination differentsearch algorithms node selection strategies. best viewed function goal probability threshold AtLeastProb, desired goal probability accuracy ApproxProb. VIforms baseline independent (). Consider Figure 5.VILRTDP|U850VILRTDP|LUAO |LUHDP|UHDP|LU800850825# solved instances# solved instances825AO |LAO |U775750725700675AO |LAO |ULRTDP|LUAO |LUHDP|UHDP|LU8007757507257006756506506256250.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1LRTDP|U0.9 0.8 0.7 0.6 0.5 0.4 0.3 0.2 0.1 0(a)(b)Figure 5: Acyclic planning. Total coverage AtLeastProb function (a), ApproxProb function (b). configurations use default node selection LM-cutdead-end pruning.AtLeastProb (Figure 5a), interesting region benchmark instances feasibleVI yet sometimes feasible search algorithms, one clear feature superiorityLRTDP AO HDP. one see smaller values , LRTDP ableupdate V L much effectively HDP, resulting larger coverage LRTDP region253fiS TEINMETZ & H OFFMANN & B UFFETsmaller values. AO |L exhibits strikingly strong behavior small values , approaching(and one case, surpassing) performance LRTDP|U . Evidently, depth-first expansionstrategy quite effective anytime behavior V L thus termination via V L (I) .way effective heuristic search AO |LU . shall see (Figure 7),often also effective LRTDP. general, algorithms, using V L clear advantagesmall . larger , maintaining V L become burden, yet V U advantage due earlytermination V U (I) < . Algorithms using bounds exhibit easy-hard-easy pattern.spike left-hand side Figure 5 (a), i.e., significantly worse performance = 0.1= 0.2, outlier due Pentest domains without domains, AO |LU ,LRTDP|LU HDP|LU exhibit strict easy-hard-easy pattern. because, contrast typical probabilistic planning scenarios, penetration testing goal probability chancesuccessful attack typically small, indeed benchmarks. Searches usingupper bound quickly obtain V U (I) < 0.2, terminating early based V U (I) < = 0.2.takes long time obtain V U (I) < 0.1.ApproxProb (Figure 5b), smaller values consistently result worse performance.see superiority LRTDP AO HDP, (relatively, compared AO |LU )strong behavior AO |L regions allowing aggressive early termination. Again, keyLRTDP beating HDP clearly due LRTDP updating V L much effectively. HDP|LUimprove HDP|U small margin. Nonetheless, see superiority algorithmsusing bounds dont.7.2.3 (3) N ODE ELECTION TRATEGIESFigure 6 shows different node selection strategies AtLeastProb (the relative performance nodeselection strategies ApproxProb, include separate figure that).LRTDP|LU (def)AO |L (BFS)850# solved instances825AO |LU (def)AO |LU (h)AO |L (DFS)AO |L (h)AO |LU (o-prob)HDP|LU (def)VI8007757507257006756506250.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1Figure 6: Acyclic planning. Total coverage AtLeastProb function , varying nodeselection strategy. configurations use LM-cut dead-end pruning.readability, show competitive base algorithms, AO |L , AO |LU , LRTDP|LU ,HDP|LU (as well VI baseline). LRTDP HDP, show default node selection, consistently works basically well alternatives. AO |L , see254fiG OAL P ROBABILITY NALYSIS P ROBABILISTIC P LANNINGdepth-first strategy important (and way beyond breadth-first, worse VI).h-bias strategy marginally, consistently, better depth-first. AO |LU , h-biasmost-prob-outcome bias helpful, substantially improving default strategy.h-bias consistently improves bit default AO . gap-bias preferred-actions strategiesshown consistently slightly worse (apparently, gap-bias leadsbreadth-first style behavior, preferred actions mainly cause runtime overhead).7.2.4 (4) N LLUSTRATION YPICAL NYTIME B EHAVIORconclude discussion acyclic planning, Figure 7 exemplifies typical anytime behavior, i.e.,development V L (I) V U (I) bounds initial state value, function runtime,LRTDP|LU AO |L .1LRTDP V U LM-cutLRTDP V LLRTDP V L LM-cutAO |AO |L1L LM-cut0.8ProbabilityProbability0.8LRTDP V U0.60.40.20.60.40.2000100200300Time (s)4005000100(a)LRTDP V ULRTDP V U LM-cutLRTDP V LLRTDP V L LM-cutAO |LAO |L LM-cut200300Time (s)400500(b)Figure 7: Acyclic planning. Anytime behavior LRTDP|LU (V V L ) AO |L (V L only),function runtime. Elevators instance 11, without pruning LM-cut pruning,constrainedness level C = 1.4 (a) respectively C = 1.8 (b). Default node selection.Ubenefit LM-cut pruning evident. Observe AO |L way effectiveLRTDP quickly improving lower bound. Indeed, runs shown find optimal policyquickly. Across benchmarks solved AO |L LRTDP, omittingtook < 1 second, 56% cases AO |L finds optimal policy faster LRTDP. (geometric) average, AO |L takes 66% time taken LRTDP purpose. downside,unless V (I) , AO |L must explore entire state space. runs Figure 7 exhaust memoryMaxProb. summary, heuristic search much stronger proving maximum goalprobability found, often distracting improving V L quickly.parts Figure 7 use base instance different constrainedness levels C,also draw conclusions effect surplus budget. budget, actionsapplied reaching absorbing states. adversely affects upper bound (consistentlyacross experiments), takes much longer time decrease. lower bound,hand, often increases quickly higher C easier find goal states.255fiS TEINMETZ & H OFFMANN & B UFFET7.3 Cyclic Planning FRETconsider cyclic planning, pertaining standard IPPC benchmarks, probabilisticNoMystery, Rovers, TPP without budget (nor resource-) limit. run LRTDP DFHS,AO restricted acyclic state spaces. use two different variants FRET described earlier:FRET-V U per Kolobov et al. (2011), new variant FRET- U . consider 3 objectives,4 dead-end pruning methods (as LM-cut returns iff cheaper heuristic hmax does,use hmax here). vary node selection strategies because, like seen before,LRTDP DFHS bring notable advantage default strategy. usedeterministic-bisimulation (DB) reduced state space base algorithm, differencesemerge (in difference acyclic case) VI algorithms, needrun FRET. Again, given DB require dead-end pruning.Overall, yields 305 different possible algorithm configurations. before,interesting, instead organize experiment terms parts focusing issuesinterest. Specifically, parts (1) MaxProb (2) AtLeastProb/ApproxProb before.node selection strategies relevant here, previous part (3) consideringthese. integrate data illustrating anytime behavior discussion (2). Table 6 givesoverview tested configurations.ExperimentFRET variantSearch AlgorithmPruning# ConfigsMaxProb search & prun(1)65, FRET-V U , FRET- U VI, LRTDP|U , DFHS (5) (4), DBing(2)VI,AtLeastProb & ApproxUU LRTDP| ,,FRET-V,FRET-LUProb parametersHDP|LULRTDP|U ,HDP|U ,hmax18Table 6: Overview algorithms tested cyclic problems, Section 7.3. Note VI require, hence combined with, FRET; denote (not using FRET all). (2), note number configurations gets multiplied 2 AtLeastProbvs. ApproxProb result different algorithm configurations (using different terminationcriteria). configurations tested use default node selection.7.3.1 (1) EARCH LGORITHMS & P RUNING ETHODS AX P ROBTable 7 shows coverage data. before, DFHS family shown top, remainingsearch algorithms, including competitive DFHS algorithm HDP,shown bottom. vary FRET variant top space reasons, as,FRET-V U , coverage differences across DFHS family members.Similarly acyclic case, DFHS configurations stopping exploration -inconsistentstates give slightly better results stopping absorbing states. terminationparameter almost effect coverage: HDP (i.e., DFHSFwdCons) solves one taskLabExplodingBlocks DFHSFwdCons,otherwisecoveragesame. Also akinVIacyclic case, LRTDP HDP perform equally well, though HDP slight edgecombination FRET- U .Running search deterministic-bismulation state space less effective cyclicbenchmarks acyclic ones. gives clear advantage Rovers.256fiG OAL P ROBABILITY NALYSIS P ROBABILISTIC P LANNINGDomain#BlocksworldBoxworldDriveElevatorsExplodingBlocksRandomRectangleTireworldTireworldZenotravelNoMysteryRoversTPPPDomainBlocksworldBoxworldDriveElevatorsExplodingBlocksRandomRectangleTireworldTireworldZenotravelNoMysteryRoversTPPP15 415 015 415 1515 515 614 1415 1515 310 410 910 8164 87#FRET- UDFHSVI |UDFHSFwdCons|UDFHSFwdHDP|UVILab |Uhmax M&Shmax M&S hmax M&S hmax M&SN BSN BSN BSN BSNIPPC Benchmarks4 4 4 4 44 4 4 4 44 4 4 4 44 4 4 4 44 4 40 0 0 0 00 0 0 0 00 0 0 0 00 0 0 0 00 0 015 15 6 6 15 15 15 6 6 15 15 15 6 6 15 15 15 6 6 15 15 15 615 15 5 5 15 15 15 5 5 15 15 15 5 5 15 15 15 5 5 15 15 15 512 5 4 4 5 12 5 4 4 5 14 5 4 4 5 12 5 4 4 5 15 5 46 1 0 0 66 2 0 0 66 1 0 0 66 2 0 0 66 1 014 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 1415 15 12 11 15 15 15 12 11 15 15 15 12 11 15 15 15 12 11 15 15 15 123 3 1 1 33 3 1 1 33 3 1 1 33 3 1 1 33 3 1Probabilistic Resource-Constrained Benchmarks4 4 4 0 44 4 4 0 44 4 4 0 44 4 4 1 44 4 49 9 8 9 99 9 8 9 99 9 8 9 99 9 8 9 99 9 88 8 6 6 88 8 6 6 88 8 6 6 88 8 6 6 88 8 6105 93 64 60 98 105 94 64 60 98 107 93 64 60 98 105 94 64 61 98 108 93 64DFHSFwdVI |Uhmax M&S40151540141034015156014103401515401410310 510 510 6164 815568355681151515151515141515FRET-V UFRET- ULRTDP|UHDP|ULRTDP|UHDP|Uhmax M&S hmax M&S hmax M&S hmax M&SN DBN DBN DBNIPPC Benchmarks4 4 44 4 4 4 44 4 4 4 44 4 4 4 44 4 40 0 00 0 0 0 00 0 0 0 00 0 0 0 00 0 06 6 15 15 15 6 6 15 15 15 6 6 15 15 15 6 6 15 15 15 65 5 15 15 15 5 5 15 15 15 5 5 15 15 15 5 5 15 15 15 54 4 46 4 4 4 46 4 4 4 5 14 5 4 4 5 15 5 40 0 00 0 0 0 00 0 0 0 44 0 0 0 66 1 014 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 1410 11 10 11 10 10 11 10 10 10 10 11 15 15 15 12 11 15 15 15 121 0 33 3 1 1 33 3 1 1 33 3 1 1 33 3 1Probabilistic Resource-Constrained Benchmarks5 5 55 5 5 5 55 5 5 5 44 4 4 1 44 4 45 9 55 5 5 9 55 5 5 9 99 9 8 9 99 9 86 6 66 6 6 6 66 6 6 6 88 8 6 6 88 8 660 64 81 84 81 60 65 81 83 81 60 65 96 105 92 64 61 98 108 93 64VIhmax M&SN DBBS4065401411119661DB4065401411119661Table 7: Cyclic planning. MaxProb coverage. Best values, within table, boldface. FRETV U per Kolobov et al. (2011), FRET- U modified version. Top: DFHS variantsmember DFHS family; DFHSVI ILAO );(recall HDP DFHSFwdConsLabshowing dominating FRET version, FRET- U . Bottom: remaining search algorithms, varying FRET version, including also overall best DFHS variant.Dead-end pruning variants: none, else based heuristic value , hmax respectively merge-and-shrink (N size bound N = 100k, size bound). DB: runreduced (deterministic-bisimulated) state space. Default node selection.striking result far FRET- U outperforms VI FRET-V U substantially. Note that, domains except ExplodingBlocks Rovers, advantage VIobtained even without dead-end pruning, i.e., trivial initialization V U . strongly confirmspower heuristic search even absence good admissible goal probability estimators.before, shed additional light coverage results search space size runtimedata. Figure 8 compares search space sizes VI vs. FRET- U . non-trivial initializationusing hmax useful, gains 3 orders magnitude possible even without it.Table 8 provides aggregate search space size runtime data. data shown configuration using FRET-V U HDP, data almost identical FRET-V U LRTDP:257fi107107106106FRET- U (hmax )FRET- UTEINMETZ & H OFFMANN & B UFFET105104103105104103102102101 110102103104VI105106101 110107102103104105VI (hmax )106107Figure 8: Cyclic planning. Number states visited, VI (x) vs. FRET- U using LRTDP|U (y),pruning (left) respectively hmax pruning (right).FRET-V UFRET- ULRTDP|ULRTDP|UM&ShmaxM&ShmaxM&SNNNIPPC Benchmarks2.82.70 0.12.72.80.10.13 2.80.16 42.800 5.8 33.100 6.1 42.802.21.700 2.21.800 2.21.9019.3 18.1 15.9 0.4 31.5 17.7 15.70 28.8 17.53.545.1 110.4 82.2 0.8 112.4 102.6 72.90 104.1 110.1 14.34.74.73.94 4.74.7 19.84.14.74.7 20.49.197.6 7.99.1953 8.19.19.2 55.5143560 55.3 60.2 86.400 3.8 24.7019.5 55.7 92.1 84.5 89.8 13600 4.7 39.8096.3 283.87 12.6 54.3 241.10.20.2 43.5 227.40.2Probabilistic Resource-Constrained Benchmarks29.1 69.4 133.9 127 141.4 166.7 627.3 582.4 676.4 618.7 632.139.1 42.7 439.8 420.3 435.2 425.11.81.36.28.31.820.1 44.8 140.1 125.8 136.6 156.3 32.9 18.3 63.2 71.3 32.931.6 83.5 259.1 241 253.2 299.1 52.5 31.8 118.3 138.8 52.9IPPC Benchmarks1.11.11.1 1.11.11.11.11.11.11.11.10.30.30.3 0.20.20.20.30.20.20.20.30.90.90.9 0.90.90.90.20.20.20.20.2252.3 39.9 408.5 20.1 242.2 16.9 44.30.214 0.1 44.42.0K 142.4 2.0K 34.6 2.0K 32.4 133.60.2 133.60.2 133.7000.7 0.2000.70.2000.7001 0.3001 0.30011.2K 1.2K 1.2K 974.7 974.7 974.70.50.20.20.22.41.7K 1.7K 1.7K 1.4K 1.4K 1.4K0.40.20.20.22.7309.3 309.3 309.3 309.3 309.3 309.32.72.72.72.72.7Probabilistic Resource-Constrained Benchmarks2.6K 2.6K 2.6K 2.6K 2.6K 2.6K 433 430.8 433 430.8 432.62.8K 2.8K 2.8K 2.8K 2.8K 2.8K 15.2 14.8 15.1 14.8 15.21.3K 1.3K 1.3K 1.3K 1.3K 1.3K 112.6 89.2 95.7 89.2 112.62.3K 2.3K 2.3K 2.3K 2.3K 2.3K 149.2 127.2 138.5 127.2 149.2VIhmaxDomain#BlocksworldDriveElevatorsExplodingBlocksNON-TRIVIALRectangleTireworldNON-TRIVIALTireworldNON-TRIVIALZenotravel41542648710002.614.23.77.27.31155.70000.72.747.910.916.549.3NoMysteryRoversTPPNON-TRIVIAL456521.533.111.821.629.840.214.426.2BlocksworldDriveElevatorsExplodingBlocksNON-TRIVIALRectangleTireworldNON-TRIVIALTireworldNON-TRIVIALZenotravel41.11.110.30.350.90.94 408.5 46.52 2.0K 152.660.70.2410.38 1.2K 1.2K7 1.7K 1.7K1 309.3 309.3NoMysteryRoversTPPNON-TRIVIAL45652.6K2.8K1.3K2.3K2.6K2.8K1.3K2.3KHDP|UhmaxM&SN0.13.12.90 7.2 33.50 2.21.80 18.9 18.30 44.4 107.14.14.74.78.19.29.10 3.8 24.90 4.6 39.90.251 233.9580.4 634.2 628.51.36.18.318.5 64.1 70.332.3 120.1 137.11.11.10.20.20.20.20.2140.2 133.70.200.300.50.50.50.52.72.71.10.20.20.10.2000.50.52.7418.8 432.6 418.814.9 15.1 14.989.2 95.7 89.2127.2 138.5 127.2Table 8: Cyclic planning. Top: MaxProb geometric mean runtime (in CPU seconds). Bottom:MaxProb geometric mean search space size (number states visited) multiples 1000.Similar setup presentation Table 4: # gives size instance basis.default commonly solved instances, skipping trivial ones. NON-TRIVIAL usesinstances solved VI < 1 second. (ONLY-H shown, see text.)258fiG OAL P ROBABILITY NALYSIS P ROBABILISTIC P LANNINGsearch space sizes exactly same, runtimes differ seconds. differenceTables 4 5, include ONLY-H rows, would interesting here:FRET-V U hardly solves instances VI, would excluded rows;then, data would compare LRTDP vs. HDP, perform similarly anyway.striking Table 8 consistency which, extent which, FRET- U visitsless states competitors (for LRTDP HDP). advantage typically yields betterruntimes well, notable exception NoMystery, larger number FRET iterations results substantial slow-down, despite much smaller search space: FRET-V ULRTDP requires 11 FRET iterations average, NoMystery instances commonlysolved FRET- U LRTDP, latter configuration requires 20000 iterations average. Similarly using HDP.impact dead-end pruning notably smaller acyclic case: search spacesreduced substantially single domain, ExplodingBlocks. domains, eitherreduction, minor/moderate one only.VI (Kolobov)VIVI (hmax )FRET-V U (Kolobov)FRET-V U (hmax )FRET- U (hmax )104103106Time (s)States visited1081051041021011001021234Problem #510161234Problem #56(a)(b)Figure 9: Cyclic planning. Results ExplodingBlocks, shown Kolobov et al. (2011): FRETvs VI, (a) number states visited, (b) runtime CPU seconds, functionIPPC instance index. Different variants included comparison. data Kolobovet al. taken paper (as code available anymore), hence runtimecomparison modulo different computational platforms, treatedcare. shown FRET configurations use LRTDP|U , default node selection.ExplodingBlocks also happens single domain Kolobov et al. (2011) experimented with.Figure 9 provides detailed comparison Kolobov et al.s data, state artmeasure provided previous work. use exact runtime/search space size data reportedKolobov et al.; recall source code available anymore.Kolobov et al. (2011) ran VI pruning vs. FRET-V U using LRTDP pruning basedSixthSense (Kolobov et al., 2010). observed coverage 4 former 6latter, identical results VI vs. FRET-V U using LRTDP hmax . give259fiS TEINMETZ & H OFFMANN & B UFFETdetail, Figure 9 shows number states visited, total runtime, terms plots IPPCinstance index done Kolobov et al (2011).Consider first Figure 9 (a), search space size. difference VI (Kolobov)VI different task/state representation resulting respective implementationframework, FD framework somewhat effective. substantially better performanceVI hmax dead-end pruning shows omission Kolobov et al.s (2011) study, usingdead-end pruning FRET VI, indeed obfuscates possible conclusions regardingeffect heuristic search vs. effect state pruning itself: hmax pruning, VI almosteffective FRET-V U using pruning. Kolobov et al.s FRET-V U also closethis, except exploring significantly less states large instances. latter shows, especiallygiven effective representation FD, SixthSense stronger dead-end detectorhmax . hardly surprising, considering information sources SixthSense outcomes(determinized) classical planning guidance, h2 (Graphplan) based validity tests.hand, SixthSenses information sources much time-intensive hmax ,presumably reason runtime picture Figure 9 (b). latter qualitativelysimilar (a), except FRET-V U (Kolobov) significantly worse, rather better,largest instance. last conclusion taken grain salt though, given differentcomputational environments.Certainly, given clarity FRET- U advantage search space size runtime, oneconclude variant FRET substantially improves previous state art.7.3.2 (2) L EAST P ROB PPROX P ROB PARAMETER NALYSISweaker objectives AtLeastProb ApproxProb, examine coverage function respectively . Figure 10 shows data.FRET-V U , behavior Figure 10 similar acyclic case Figure 5.particular, maintaining upper lower bound, FRET-V U exhibits easy-hardeasy pattern due advantages early termination.FRET- U , though, curves flat , observation small advantageusing V L addition V U . due scaling benchmarks, combined extremeperformance loss point scaling: domain, instance number xthat, x, FRET- U solve instances completely (i.e., solving MaxProb), xneither V L (I) V U (I) improved all, remaining 0 respectively 1 time/memorylimit. smaller instances, get expected anytime behavior. Figure 11 exemplifies this.easy-hard-easy pattern would thus emerge smaller runtime/memory limits.148. ConclusionOptimal goal probability analysis probabilistic planning notoriously hard problem,extent amount work addressing limited. investigation contributes comprehensive design space known adapted algorithms addressing problem, designing several newalgorithm variants along way, establishing FD implementation basis supporting tightintegration MDP heuristic search classical planning techniques. experiments clarify14. Figure 11 (b) considers largest instance feasible using hmax pruning. Figure 11 (a) considers secondlargest instance feasible without pruning: largest one feasible without pruning, namely instance 05, maximum goal probability 1 anytime curve V U interesting.260fiG OAL P ROBABILITY NALYSIS P ROBABILISTIC P LANNINGFRET-V U LRTDP|UFRET- U LRTDP|UFRET-V U LRTDP|UFRET- U LRTDP|UFRET-V U LRTDP|LUFRET-V U HDP|UFRET-V U HDP|LUVIFRET- U LRTDP|LUFRET- U HDP|UFRET- U HDP|LUFRET-V U LRTDP|LUFRET-V U HDP|UFRET-V U HDP|LUVIFRET- U LRTDP|LUFRET- U HDP|UFRET- U HDP|LU110# solved instances# solved instances11010090100900.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 10.9 0.8 0.7 0.6 0.5 0.4 0.3 0.2 0.1 0(a)(b)110.80.8ProbabilityProbabilityFigure 10: Cyclic planning. Total coverage AtLeastProb function (a), ApproxProb function (b). configurations use default node selection hmaxdead-end pruning.0.60.40.60.40.20.20002040Time (s)060(a)100200300Time (s)400(b)FRET- UFigure 11: Cyclic planning. Anytime behaviorLRTDP|LU HDP|LU ,default node selection, (a) without pruning ExplodingBlocks instance 04, (b)hmax pruning instance 15.empirical state art, exhibit substantial improvements thanks new techniques technique combinations. furthermore showcase opportunities arising naturally acyclicproblems, early termination criteria weaker maximum goal probability.hope encouraging results new implementation basis inspire renewedinterest research important problem. many promising future directions,would like emphasize:Advanced admissible goal probability estimators. could obtained, e.g. abstractions interpreted bounded-parameter MDPs (Givan, Leach, & Dean, 2000). promis261fiS TEINMETZ & H OFFMANN & B UFFETing approach extend state-of-the-art classical-planning abstraction techniques patterndatabases (Edelkamp, 2001; Haslum, Botea, Helmert, Bonet, & Koenig, 2007), merge-andshrink (Helmert et al., 2014), Cartesian abstractions (Seipp & Helmert, 2013, 2014)probabilistic setting.Hybrids heuristic search Monte-Carlo tree search. appears promising optionimprove anytime behavior, respect upper and/or lower bound, thus fosterearly termination. Inspiration could taken existing hybrids, geared towardpurposes (Keller & Eyerich, 2012; Bonet & Geffner, 2012; Keller & Helmert, 2013).Exploiting dominance relations. Goal probability higher dominating states,raising opportunity prune dominated regions and/or transfer upper/lower bounds acrossstates. State domination ubiquitous limited-budget planning (and resource-constrainedplanning). general domination relations shown exist also manyclassical planning problems (Torralba & Hoffmann, 2015), transfer techniques probabilistic case, via all-outcomes determinization, straightforward.Last least, simulated penetration testing application worth algorithms researchright. basic idea exploit particular structure models, specificallypartially delete-relaxed behavior. characterizing property simulated penetration testingaction, applicable, remains applicable first executed (once attacker getsposition enabling exploit, exploit remains enabled). Hence, like delete-relaxed planning,find optimal solution, navely branch action every state ever after.combat this, least three interesting directions. Following Pommerening Helmerts(2012) methods computing h+ , different branching schemes might apply, challengemaintain value function correctness. Following Gefen Brafmans (2012) methods computing h+ , partial-order reduction could adapted, challenge deal actioninterference entailed shared budget. Finally, methods specific probabilistic setting mayapply: intuitively, preserve optimality, certain actions need attempted alternategoal path failed. suggests identify, branch at, particular critical points alongsearch path.Acknowledgmentswork partially supported German Research Foundation (DFG), grant HO2169/5-1, Critically Constrained Planning via Partial Delete Relaxation, well Federal Ministry Education Research (BMBF) funding Center IT-Security,Privacy Accountability (CISPA) grant 16KIS0656. thank Christian MuiseProbabilistic-PDDL extension FD parser. thank Andrey Kolobov discussions.thank anonymous reviewers, whose comments helped improve paper.Appendix A. Depth-First Heuristic Search Cyclic Problemspseudo-code family depth-first heuristic search algorithms (DFHS) general (cyclic)probabilistic planning problems shown Figure 12.262fiG OAL P ROBABILITY NALYSIS P ROBABILISTIC P LANNINGprocedure GoalProb-DFHS:= {I};loop[early termination criteria exactly GoalProb-AO ](Label labeled solved)(VI U changed running VI U -greedy graph)index := 0DFHS-Exploration(I)set IDX visited statesclean stack visitedelse return U endif /* regular termination */endloopprocedure DFHS-Exploration(s):6 Initialize(s) endifS> labeled solvedlabel solvedreturnendiff lag :=FWV U (s) consistent f lag := > endifupdate V U (s), U (s), V L (s), L (s)Consist f lag return > endifendifs.IDX := index; s.lowlink := indexpush onto stack; mark visitedindex := index + 1foreach P (s, U (s), t) > 0t.IDX =f lag := DFHS-Exploration(s) f lagt.IDX < t.lowlink < s.lowlink s.lowlink := t.lowlink endifelse stack t.IDX < s.lowlink s.lowlink := t.IDX endifdonef lag FWV U (s) -consistent f lag := > endifupdate V U (s), U (s), V L (s), L (s)endifLabel f lag s.IDX = s.lowlinkforever:= stack.pop()label solved= break endifdoneendifreturn f lagFigure 12: Depth-First Heuristic Search (DFHS) general (cyclic) MaxProb, AtLeastProb,ApproxProb.Appendix B. Landmarks Pruning: Admissible Heuristic vs. Budget Reductionstated, Domshlak Mirkis (2015) problem reformulation, pruning states based globalbudget reduced using disjunctive action landmarks, equivalent, regarding states prunedmethod own, much simpler method using landmarks pruning263fiS TEINMETZ & H OFFMANN & B UFFETremaining original budget. give argument, previously made unit costspairwise disjoint landmarks, general setting. assume classical planning setupsimplicity. arguments probabilistic oversubscription setups essentially same.Assume STRIPS planning task = (F, A, I, G), action costs c(a) globalbudget b. use notation following admissible landmark heuristics per Karpas Domshlak(2009). Let L set disjunctive action landmarks I, i.e., every l L everyaction sequence ~a leading goal, ~a touches l (there exists l used ~a). Letfurthermorecp : L 7 R+0 cost partitioning, i.e., function satisfying, A,Pc(a, l)Pc(a). Denote h(l) := minal cp(a, l), subset L0 L landmarksdenote h(L0 ) := lL0 h(l). Intuitively, landmark l L assigned weight h(l) via cp,admissible heuristic value h(L) obtained summing weights.describe Domshlak Mirkis (2015) pruning technique terms. DomshlakMirkis formulation terms compilation planning language, complicated, equivalent formulation far pruning concerned.Domshlak Mirkis technique maintains non-used landmarks part states. Namely,state reached path ~a, l L non-used iff ~a touch l. denote set nonused landmarks L(s). Obviously, l L(s) landmarks s. Note also that, L(s)part state, even two search paths lead end state use different landmarks,end states considered different. restriction arises compilation approach,book-keeping landmarks must happen inside language, i.e., inside states. Onecould formulate pruning technique without restriction; get back below.pruning technique arises interplay reduced global budget reducedaction costs depending non-used landmarks. Define reduced global budget b0 := b h(L).action a, denote L(a) set landmarks participates in, i.e., L(a) := {l | l L,l}. state search, applicable action a, transition t[[a]]reduced cost, namely cost c(a) h(L(a) L(t)). words, reduce cost(summed-up) weight non-used landmarks participates in.Consider state search. Denote remaining reduced budget b0 (s).Say prune iff b0 (s) < 0.15 Consider path ~a ending s. non-used landmarkspart state, paths must touchP subset landmarks L, namelyL \ L(s). Denote actual cost ~a c(~a) := a~a c(a). Relative cost, cost savedthanks cost reduction exactly h(L \ L(s)), weight touched landmarks. Therefore,b0 (s) = b0 (c(~a) h(L \ L(s))) =P(b h(L)) c(~a) + h(L \ L(s)). Pdefinition h,Pequals (b h(l)) c(~a) + lL\L(s) h(l), equals b c(~a) lL(s) h(l) =b c(~a) h(L(s)). Thus, pruned, b0 (s) < 0, iff b c(~a) < h(L(s)). latter conditionb(s) < h(L(s)), exactly pruning condition resulting using h(L(s))admissible heuristic function pruning remaining budget.non-compilation setting, one could, indeed customary admissible landmark heuristics, handle landmarks path-dependent manner. is, non-used landmarks maintained15. Domshlak Mirkis (2015) maintain remaining budget part state, instead prune g(s) >b0 . is, obviously, equivalent, except duplicate detection powerful compares states basedfacts F (s) only. purpose discussion here, make difference. Note that,probabilistic setting, distinguish states based F (s) b(s), goal probability dependsmaintaining best way reaching F (s) suffice compute exact goal probabilityinitial state.264fiG OAL P ROBABILITY NALYSIS P ROBABILISTIC P LANNINGannotations states rather part them, multiple search paths may end stateuse different landmarks. set remaining landmarks L(s) unionindividual path; is, l L non-used iff exists least one pathtouch l. still suffices show l landmark s. landmark heuristic approach per Karpas Domshlak (2009) kind book-keeping, uses admissibleheuristic value h(L(s)).one apply Domshlak Mirkis (2015) reformulation technique without maintaininglandmarks part state, notion transition-cost reduction would becomecomplicated (lest one loses information). because, reached a~1 reducedcost due touching landmark l1 , later find another path a~2 touch l1 ,l1 actually still valid landmark s, therefore need reduce costa~1 . account this, would revise path costs posthoc, every time new pathbecomes available. revisions, cost reduction path ~a exactlyh(L \ L(s)): weight non-used landmarks L(s) longer subtracted, weightlandmarks L \ L(s) subtracted every ~a because, definition, every ~a touches everyl L \ L(s). cost saved every path ~a s, relative ~a, exactly h(L \ L(s)),point arguments apply show pruning equivalent pruningvia b(s) < h(L(s)). (This stronger pruning method would get without posthocpath cost revision.)summary, based reduced remaining budget b0 (s) < 0 equivalent pruning basedoriginal remaining budget vs. landmark heuristic b(s) < h(L(s)). noted, though,pruning benefit Domshlak Mirkis (2015) reformulation technique.technique allows compute another, complementary, admissible heuristic h reformulated task 0 (and Domshlak Mirkis point part motivation,practice). perspective here, landmark heuristic h used additivelyadmissible pruning remaining budget, additivity achieved methodgeneralizing cost partitionings: 0 , cost-reduced variant action appliedonce. h abstract away constraint, h uses action twice, employsreduced cost once, yet pays full cost second time. Exploring kind generalizedcost partitioning detail interesting research line future work.ReferencesAltman, E. (1999). Constrained Markov Decision Processes. CRC Press.Baier, C., Groer, M., Leucker, M., Bollig, B., & Ciesinski, F. (2004). Controller SynthesisProbabilistic Systems (Extended Abstract), pp. 493506. Springer US, Boston, MA.Barto, A. G., Bradtke, S. J., & Singh, S. P. (1995). Learning act using real-time dynamic programming. Artificial Intelligence, 72(1-2), 81138.Bertsekas, D. (1995). Dynamic Programming Optimal Control, (2 Volumes). Athena Scientific.Bertsekas, D., & Tsitsiklis, J. (1996). Neurodynamic Programming. Athena Scientific.Bonet, B., & Geffner, H. (2001). Planning heuristic search. Artificial Intelligence, 129(12),533.265fiS TEINMETZ & H OFFMANN & B UFFETBonet, B., & Geffner, H. (2003a). Faster heuristic search algorithms planning uncertaintyfull feedback. Gottlob, G. (Ed.), Proceedings 18th International Joint Conference Artificial Intelligence (IJCAI03), pp. 12331238, Acapulco, Mexico. Morgan Kaufmann.Bonet, B., & Geffner, H. (2003b). Labeled RTDP: Improving convergence real-time dynamicprogramming. Giunchiglia, E., Muscettola, N., & Nau, D. (Eds.), Proceedings 13thInternational Conference Automated Planning Scheduling (ICAPS03), pp. 1221,Trento, Italy. Morgan Kaufmann.Bonet, B., & Geffner, H. (2005). mgpt: probabilistic planner based heuristic search. JournalArtificial Intelligence Research, 24, 933944.Bonet, B., & Geffner, H. (2006). Learning depth-first search: unified approach heuristic searchdeterministic non-deterministic settings, application MDPs. Long, D., &Smith, S. (Eds.), Proceedings 16th International Conference Automated PlanningScheduling (ICAPS06), pp. 142151, Ambleside, UK. Morgan Kaufmann.Bonet, B., & Geffner, H. (2012). Action selection MDPs: Anytime AO* versus UCT. Hoffmann, J., & Selman, B. (Eds.), Proceedings 26th AAAI Conference Artificial Intelligence (AAAI12), Toronto, ON, Canada. AAAI Press.Bryce, D., & Buffet, O. (2008). 6th international planning competition: Uncertainty part. Proceedings 6th International Planning Competition (IPC08).Camacho, A., Muise, C., & McIlraith, S. A. (2016). FOND robust probabilistic planning: Computing compact policies bypass avoidable deadends. Coles, A., Coles, A.,Edelkamp, S., Magazzeni, D., & Sanner, S. (Eds.), Proceedings 26th InternationalConference Automated Planning Scheduling (ICAPS16). AAAI Press.Chatterjee, K., Chmelik, M., Gupta, R., & Kanodia, A. (2015). Optimal cost almost-sure reachability POMDPs. Bonet, B., & Koenig, S. (Eds.), Proceedings 29th AAAI ConferenceArtificial Intelligence (AAAI15), pp. 34963502. AAAI Press.Chatterjee, K., Chmelik, M., Gupta, R., & Kanodia, A. (2016). Optimal cost almost-sure reachability POMDPs. Artificial Intelligence, 234, 2648.Coles, A. J. (2012). Opportunistic branched plans maximise utility presence resourceuncertainty. Raedt, L. D. (Ed.), Proceedings 20th European Conference ArtificialIntelligence (ECAI12), pp. 252257, Montpellier, France. IOS Press.Coles, A. J., Coles, A., Fox, M., & Long, D. (2013). hybrid LP-RPG heuristic modellingnumeric resource flows planning. Journal Artificial Intelligence Research, 46, 343412.Coles, A. J., Coles, A., Garca Olaya, A., Jimenez, S., Linares Lopez, C., Sanner, S., & Yoon, S.(2012). survey seventh international planning competition. AI Magazine, 33(1).Dai, P., Mausam, Weld, D. S., & Goldsmith, J. (2011). Topological value iteration algorithms.Journal Artificial Intelligence Research, 42, 181209.Dean, T. L., & Givan, R. (1997). Model minimization markov decision processes. Kuipers,B. J., & Webber, B. (Eds.), Proceedings 14th National Conference AmericanAssociation Artificial Intelligence (AAAI97), pp. 106111, Portland, OR. MIT Press.266fiG OAL P ROBABILITY NALYSIS P ROBABILISTIC P LANNINGDomshlak, C., & Mirkis, V. (2015). Deterministic oversubscription planning heuristic search:Abstractions reformulations. Journal Artificial Intelligence Research, 52, 97169.Drager, K., Finkbeiner, B., & Podelski, A. (2009). Directed model checking distancepreserving abstractions. International Journal Software Tools Technology Transfer,11(1), 2737.Edelkamp, S. (2001). Planning pattern databases. Cesta, A., & Borrajo, D. (Eds.), Proceedings 6th European Conference Planning (ECP01), pp. 1324. Springer-Verlag.Gefen, A., & Brafman, R. I. (2012). Pruning methods optimal delete-free planning. Bonet,B., McCluskey, L., Silva, J. R., & Williams, B. (Eds.), Proceedings 22nd InternationalConference Automated Planning Scheduling (ICAPS12). AAAI Press.Givan, R., Leach, S. M., & Dean, T. (2000). Bounded-parameter Markov decision processes. Artificial Intelligence, 122(1-2), 71109.Hansen, E. A., & Zilberstein, S. (2001). LAO* : heuristic search algorithm finds solutionsloops. Artificial Intelligence, 129(1-2), 3562.Haslum, P., Botea, A., Helmert, M., Bonet, B., & Koenig, S. (2007). Domain-independent construction pattern database heuristics cost-optimal planning. Howe, A., & Holte,R. C. (Eds.), Proceedings 22nd National Conference American AssociationArtificial Intelligence (AAAI07), pp. 10071012, Vancouver, BC, Canada. AAAI Press.Haslum, P., & Geffner, H. (2001). Heuristic planning time resources. Cesta, A., &Borrajo, D. (Eds.), Proceedings 6th European Conference Planning (ECP01), pp.121132. Springer-Verlag.Helmert, M. (2006). Fast Downward planning system. Journal Artificial Intelligence Research, 26, 191246.Helmert, M., & Domshlak, C. (2009). Landmarks, critical paths abstractions: Whats difference anyway?. Gerevini, A., Howe, A., Cesta, A., & Refanidis, I. (Eds.), Proceedings19th International Conference Automated Planning Scheduling (ICAPS09), pp.162169. AAAI Press.Helmert, M., Haslum, P., Hoffmann, J., & Nissim, R. (2014). Merge & shrink abstraction: methodgenerating lower bounds factored state spaces. Journal Association Computing Machinery, 61(3).Hoffmann, J. (2015). Simulated penetration testing: Dijkstra Turing Test++. Brafman, R., Domshlak, C., Haslum, P., & Zilberstein, S. (Eds.), Proceedings 25th International Conference Automated Planning Scheduling (ICAPS15). AAAI Press.Hoffmann, J., Kissmann, P., & Torralba, A. (2014). Distance? Cares? Tailoring merge-andshrink heuristics detect unsolvability. Schaub, T. (Ed.), Proceedings 21st EuropeanConference Artificial Intelligence (ECAI14), Prague, Czech Republic. IOS Press.Hoffmann, J., & Nebel, B. (2001). FF planning system: Fast plan generation heuristicsearch. Journal Artificial Intelligence Research, 14, 253302.Hou, P., Yeoh, W., & Varakantham, P. (2014). Revisiting risk-sensitive MDPs: New algorithmsresults. Chien, S., Do, M., Fern, A., & Ruml, W. (Eds.), Proceedings 24thInternational Conference Automated Planning Scheduling (ICAPS14). AAAI Press.267fiS TEINMETZ & H OFFMANN & B UFFETJimenez, S., Coles, A., & Smith, A. (2006). Planning probabilistic domains using deterministicnumeric planner. Proceedings 25th Workshop UK Planning SchedulingSpecial Interest Group (PlanSig06).Karpas, E., & Domshlak, C. (2009). Cost-optimal planning landmarks. Boutilier, C. (Ed.),Proceedings 21st International Joint Conference Artificial Intelligence (IJCAI09),pp. 17281733, Pasadena, California, USA. Morgan Kaufmann.Katz, M., Hoffmann, J., & Helmert, M. (2012). relax bisimulation?. Bonet, B., McCluskey, L., Silva, J. R., & Williams, B. (Eds.), Proceedings 22nd International Conference Automated Planning Scheduling (ICAPS12), pp. 101109. AAAI Press.Keller, T., & Eyerich, P. (2012). PROST: Probabilistic planning based UCT. Bonet, B.,McCluskey, L., Silva, J. R., & Williams, B. (Eds.), Proceedings 22nd InternationalConference Automated Planning Scheduling (ICAPS12). AAAI Press.Keller, T., & Helmert, M. (2013). Trial-based heuristic tree search finite horizon MDPs.Borrajo, D., Fratini, S., Kambhampati, S., & Oddi, A. (Eds.), Proceedings 23rd International Conference Automated Planning Scheduling (ICAPS13), Rome, Italy. AAAIPress.Kolobov, A. (2013). Scalable Methods Expressive Models Planning Uncertainty.Ph.D. thesis, University Washington.Kolobov, A., Mausam, & Weld, D. S. (2010). Sixthsense: Fast reliable recognition dead endsMDPs. Fox, M., & Poole, D. (Eds.), Proceedings 24th National ConferenceAmerican Association Artificial Intelligence (AAAI10), Atlanta, GA, USA. AAAI Press.Kolobov, A., Mausam, & Weld, D. S. (2012). theory goal-oriented MDPs dead ends.de Freitas, N., & Murphy, K. P. (Eds.), Proceedings 28th Conference UncertaintyArtificial Intelligence (UAI12), pp. 438447, Catalina Island, CA, USA. AUAI Press.Kolobov, A., Mausam, Weld, D. S., & Geffner, H. (2011). Heuristic search generalized stochasticshortest path MDPs. Bacchus, F., Domshlak, C., Edelkamp, S., & Helmert, M. (Eds.),Proceedings 21st International Conference Automated Planning Scheduling(ICAPS11). AAAI Press.Kurniawati, H., Hsu, D., & Lee, W. S. (2008). SARSOP: Efficient point-based POMDP planningapproximating optimally reachable belief spaces. Robotics: Science Systems IV.Kuter, U., & Hu, J. (2007). Computing using lower upper bounds action eliminationMDP planning. Miguel, I., & Ruml, W. (Eds.), Proceedings 7th International Symposium Abstraction, Reformulation, Approximation (SARA-07), Vol. 4612 LectureNotes Computer Science, Whistler, Canada. Springer-Verlag.Kwiatkowska, M., Parker, D., & Qu, H. (2011a). Incremental quantitative verification markovdecision processes. 2011 IEEE/IFIP 41st International Conference Dependable SystemsNetworks (DSN), pp. 359370.Kwiatkowska, M. Z., Norman, G., & Parker, D. (2011b). Prism 4.0: Verification probabilisticreal-time systems. Gopalakrishnan, G., & Qadeer, S. (Eds.), Proceedings 23rd International Conference Computer Aided Verification (CAV11), Vol. 6806 Lecture NotesComputer Science, pp. 585591. Springer.268fiG OAL P ROBABILITY NALYSIS P ROBABILISTIC P LANNINGLittle, I., Aberdeen, D., & Thiebaux, S. (2005). Prottle: probabilistic temporal planner. Veloso,M. M., & Kambhampati, S. (Eds.), Proceedings 20th National Conference American Association Artificial Intelligence (AAAI05), pp. 11811186, Pittsburgh, Pennsylvania, USA. AAAI Press.Little, I., & Thiebaux, S. (2007). Probabilistic planning vs replanning. ICAPS WorkshopInternational Planning Competition: Past, Present Future.Marecki, J., & Tambe, M. (2008). Towards faster planning continuous resources stochasticdomains. Fox, D., & Gomes, C. (Eds.), Proceedings 23rd National ConferenceAmerican Association Artificial Intelligence (AAAI08), pp. 10491055, Chicago, Illinois,USA. AAAI Press.McMahan, H. B., Likhachev, M., & Gordon, G. J. (2005). Bounded real-time dynamic programming: RTDP monotone upper bounds performance guarantees. Proceedings22nd International Conference Machine Learning (ICML-05).Meuleau, N., Benazera, E., Brafman, R. I., Hansen, E. A., & Mausam, M. (2009). heuristic searchapproach planning continuous resources stochastic domains. Journal ArtificialIntelligence Research, 34(1), 2759.Milner, R. (1990). Operational algebraic semantics concurrent processes. van Leeuwen, J.(Ed.), Handbook Theoretical Computer Science, Volume B: Formal Models Sematics,pp. 12011242. Elsevier MIT Press.Muise, C. J., McIlraith, S. A., & Beck, J. C. (2012). Improved non-deterministic planningexploiting state relevance. Bonet, B., McCluskey, L., Silva, J. R., & Williams, B. (Eds.),Proceedings 22nd International Conference Automated Planning Scheduling(ICAPS12). AAAI Press.Nakhost, H., Hoffmann, J., & Muller, M. (2012). Resource-constrained planning: monte carlorandom walk approach. Bonet, B., McCluskey, L., Silva, J. R., & Williams, B. (Eds.),Proceedings 22nd International Conference Automated Planning Scheduling(ICAPS12), pp. 181189. AAAI Press.Nilsson, N. J. (1971). Problem Solving Methods Artificial Intelligence. McGraw-Hill.Nissim, R., Hoffmann, J., & Helmert, M. (2011). Computing perfect heuristics polynomial time:bisimulation merge-and-shrink abstraction optimal planning. Walsh, T. (Ed.),Proceedings 22nd International Joint Conference Artificial Intelligence (IJCAI11),pp. 19831990. AAAI Press/IJCAI.Pommerening, F., & Helmert, M. (2012). Optimal planning delete-free tasks incrementallm-cut. Bonet, B., McCluskey, L., Silva, J. R., & Williams, B. (Eds.), Proceedings22nd International Conference Automated Planning Scheduling (ICAPS12). AAAIPress.Richter, S., & Helmert, M. (2009). Preferred operators deferred evaluation satisficing planning. Gerevini, A., Howe, A., Cesta, A., & Refanidis, I. (Eds.), Proceedings 19thInternational Conference Automated Planning Scheduling (ICAPS09), pp. 273280.AAAI Press.269fiS TEINMETZ & H OFFMANN & B UFFETSanner, S. (2010). Relational dynamic influence diagram language (rddl): Language description.Available http://users.cecs.anu.edu.au/ssanner/IPPC_2011/RDDL.pdf.Santana, P., Thibaux, S., & Williams, B. (2016). RAO*: algorithm chance-constrainedPOMDPs. Schuurmans, D., & Wellman, M. (Eds.), Proceedings 30th AAAI Conference Artificial Intelligence (AAAI16), pp. 33083314. AAAI Press.Sarraute, C., Buffet, O., & Hoffmann, J. (2012). POMDPs make better hackers: Accountinguncertainty penetration testing. Hoffmann, J., & Selman, B. (Eds.), Proceedings26th AAAI Conference Artificial Intelligence (AAAI12), pp. 18161824, Toronto, ON,Canada. AAAI Press.Seipp, J., & Helmert, M. (2013). Counterexample-guided Cartesian abstraction refinement.Borrajo, D., Fratini, S., Kambhampati, S., & Oddi, A. (Eds.), Proceedings 23rd International Conference Automated Planning Scheduling (ICAPS13), pp. 347351,Rome, Italy. AAAI Press.Seipp, J., & Helmert, M. (2014). Diverse additive cartesian abstraction heuristics. Chien, S.,Do, M., Fern, A., & Ruml, W. (Eds.), Proceedings 24th International ConferenceAutomated Planning Scheduling (ICAPS14). AAAI Press.Smith, T., & Simmons, R. G. (2006). Focused real-time dynamic programming MDPs: Squeezing heuristic. Gil, Y., & Mooney, R. J. (Eds.), Proceedings 21stNational Conference American Association Artificial Intelligence (AAAI06), pp.12271232, Boston, Massachusetts, USA. AAAI Press.Steinmetz, M., Hoffmann, J., & Buffet, O. (2016). Revisiting goal probability analysis probabilistic planning. Coles, A., Coles, A., Edelkamp, S., Magazzeni, D., & Sanner, S. (Eds.),Proceedings 26th International Conference Automated Planning Scheduling(ICAPS16). AAAI Press.Tarjan, R. E. (1972). Depth first search linear graph algorithms. SIAM Journal Computing,1(2), 146160.Teichteil-Konigsbuch, F. (2012). Stochastic safest shortest path problems. Hoffmann, J.,& Selman, B. (Eds.), Proceedings 26th AAAI Conference Artificial Intelligence(AAAI12), Toronto, ON, Canada. AAAI Press.Teichteil-Konigsbuch, F., Kuter, U., & Infantes, G. (2010). Incremental plan aggregation generating policies MDPs. van der Hoek, W., Kaminka, G. A., Lesperance, Y., Luck, M., &Sen, S. (Eds.), Proceedings 9th International Conference Autonomous AgentsMultiagent Systems (AAMAS10), pp. 12311238. IFAAMAS.Teichteil-Konigsbuch, F., Vidal, V., & Infantes, G. (2011). Extending classical planning heuristicsprobabilistic planning dead-ends. Burgard, W., & Roth, D. (Eds.), Proceedings25th National Conference American Association Artificial Intelligence (AAAI11),San Francisco, CA, USA. AAAI Press.Torralba, A., & Hoffmann, J. (2015). Simulation-based admissible dominance pruning. Yang,Q. (Ed.), Proceedings 24th International Joint Conference Artificial Intelligence(IJCAI15), pp. 16891695. AAAI Press/IJCAI.270fiG OAL P ROBABILITY NALYSIS P ROBABILISTIC P LANNINGYoon, S. W., Fern, A., & Givan, R. (2007). FF-Replan: baseline probabilistic planning.Boddy, M., Fox, M., & Thiebaux, S. (Eds.), Proceedings 17th International ConferenceAutomated Planning Scheduling (ICAPS07), pp. 352359, Providence, Rhode Island,USA. Morgan Kaufmann.Younes, H. L. S., Littman, M. L., Weissman, D., & Asmuth, J. (2005). first probabilistic trackinternational planning competition. Journal Artificial Intelligence Research, 24,851887.271fiJournal Artificial Intelligence Research 57 (2016) 509-572Submitted November, 2015; published November, 2016Survey Computational Treatments BiomoleculesRobotics-Inspired MethodsModeling Equilibrium Structure DynamicsAmarda ShehuAMARDA @ GMU . EDUDepartment Computer Science, Department Bioengineering,School Systems BiologyGeorge Mason University, Fairfax, VA, USAErion PlakuPLAKU @ CUA . EDUDepartment Electrical Engineering Computer ScienceCatholic University America, Washington, DC, USAAbstractfifty years research molecular biology demonstrated abilitysmall large molecules interact one another propagate cellular processesliving cell lies ability molecules assume switch specific structuresphysiological conditions. Elucidating biomolecular structure dynamics equilibriumtherefore fundamental furthering understanding biological function, molecular mechanisms cell, biology, disease, disease treatments. now, wealthmethods designed elucidate biomolecular structure dynamics contributed diversescientific communities. survey, focus recent methods contributed Roboticscommunity promise address outstanding challenges regarding disparate length timescales characterize dynamic molecular processes cell. particular, survey roboticsinspired methods designed obtain efficient representations structure spaces molecules isolation assemblies purpose characterizing equilibrium structure dynamics.exhaustive review impossible endeavor, survey balances description importantalgorithmic contributions critical discussion outstanding computational challenges.objective spur research address outstanding challenges modeling equilibriumbiomolecular structure dynamics.1. Introductionway chain amino acid units protein molecule coiled folded spaceworked first time. protein myoglobin, molecule contains2,600 atoms. John Kendrew began feature article Scientific American 1961,reporting first atomistic model protein structure1 obtained via X-ray crystallography (Kendrew, Dickerson, Strandberg, Hart, Davies, Phillips, & Shore, 1960). model drawnvarious graphical representations Figure 1. pioneering work resolving structuresglobular proteins, Kendrew Perutz awarded Nobel Prize chemistry 1962.year Watson, Crick, Wilkins shared Nobel Prize physiology medicineusing X-ray crystallography data determine helical structure DNA.1. purpose survey, distinguish structure conformation. Structure referspecific placement atoms comprise biomolecule R3 . concept conformation definedSection 2.c2016AI Access Foundation. rights reserved.fiS HEHU & P LAKU(a) X-ray model myoglobin heme group(b) Model atomistic detail (no heme group)(c) Various models myoglobin heme groupFigure 1: (a) X-ray model myoglobin heme group bound determined Kendrewdrawn Visual Molecular Dynamics (VMD) software (Humphrey et al., 1996). modelfound Protein Data Bank (PDB) (Berman et al., 2003), repository known protein structures,PDB entry 1MBN. Drawing surface protein facilitates visually locating cavityheme group, helps myoglobin carry oxygen tissue, binds. heme group drawnball-and-stick representation red. (b) heavy atoms comprise 153-amino acid long myoglobinchain drawn ball-and-stick representation, color-coded amino acid belong.backbone connects atoms consecutive amino acids chain drawn white NewCartoonrepresentation VMD. (c) X-ray model myoglobin PDB entry 1MBN superimposed 12models obtained protein bound heme group Nuclear Magnetic Resonance (NMR),deposited PDB PDB entry 1MYF.ability visualize structures biomolecules atomistic detail shot armmolecular biology marked beginning revolution molecular structural biology; racesoon ensued across wet laboratories determine three-dimensional (3d) structures assumed proteins biomolecules physiological conditions. Since early days, set protein structures resolved wet-laboratory, beginning myoglobin lysozyme (Kendrew,Bodo, Dintzis, Parrish, Wyckoff, & Phillips, 1958; Kendrew et al., 1960; Phillips, 1967), grown510fiC OMPUTATIONAL REATMENTS B IOMOLECULES ROBOTICS -I NSPIRED ETHODShundred thousand, freely available anyone download PDB (Bermanet al., 2003).pioneering work Anfinsen, earned Nobel Prize Chemistry 1973,demonstrated ability protein carry biological function dependentability fold onto specific 3d structure reversibly (Anfinsen, 1973). Anfinsen experimentsled view folded structure corresponds global minimum underlying energysurface. also showed information needed protein assume 3d, biologicallyactive structure largely encoded amino-acid sequence. Since then, study biomolecularfunction consider role sequence structure (Fersht, 1999).Figure 1(a), shows surface biologically-active structure myoglobin protein, exposes central cavity allows binding heme group myoglobin. Figure 1(b)traces amino-acid chain makes myoglobin additionally draws heavy atoms constituting amino acid protein. simple images illustrate two important points: first,structure plays central role function (specifically, complementary geometric physicochemical features 3d structures molecules key stable molecular interactions) (Boehr &Wright, 2008); second, ability amino-acid chain fold onto makes proteinstructures complex. Understanding biologically-active structure biomolecule assumes cell key elucidating molecular mechanisms healthy diseasedcell, also determining address abnormal role biomolecule mechanismsorder treat disease. particular, research shown many abnormalities involve proteins aberrant biological function (Soto, 2008; Uversky, 2009; Fernandez-Medarde & Santos,2011; Neudecker, Robustelli, Cavalli, Walsh, Lundstrm, Zarrine-Afsar, Sharpe, Vendruscolo, &Kay, 2012) due external internal perturbations (e.g., DNA mutations, copying errors) affecting ability molecules assume specific structures (Onuchic, Luthey-Schulten, &Wolynes, 1997; Ozenne, Schneider, Yao, Huang, Salmon, Zweckstetter, Jensen, & Blackledge,2012; Levy, Jortner, & Becker, 2001; Miao, Sinko, Pierce, Bucher, Walker, & McCammon, 2014;Gorfe, Grant, & McCammon, 2008; Grant, Gorfe, & McCammon, 2009).treatment relationship structure function would incompletedynamic personality biomolecules taken account (Jenzler-Wildman & Kern, 2007).X-ray models biomolecular structures seem suggest rigid molecules atoms frozenspace, increasing number wet-laboratory, theoretical, computational studies shownbiomolecules systems particles perpetual motion. Indeed, Feynman taught earlyjiggling wiggling atoms (Feynman, Leighton, & Sands, 1963). Cooper others laterposited inherent dynamics biomolecules could explained general, theoreticaltreatment molecules thermodynamic systems striving towards equilibrium, lowest freeenergy state (Cooper, 1984). Thus, inherent dynamics biomolecules could explainedusing fundamental physics principles; statistical mechanics formulation also revealed inherentuncertainty given time particular state molecule (Cooper, 1984).dynamics molecular systems investigated around time first experimentalmodels protein structures emerging. 1967, Verlet simulated dynamics argondemonstrated simulations able reproduce equilibrium properties (Verlet, 1967).Application Verlet algorithm simulating protein dynamics would wait onedecade. 1977, McCammon Karplus reported 9.2 picosecond-long trajectory showing in-vacuum, atomistic fluctuations bovine pancreatic trypsin inhibitor around folded,active structure (the latter already obtained via wet-laboratory techniques) (McCammon,511fiS HEHU & P LAKUGelin, & Karplus, 1977). Advancements wet-laboratory techniques, speweddozen models biologically-active protein structures late 70s, facilitated revolutioncomputational structural biology. pioneering algorithmic work Verlet, Karplus, McCammon,Levitt, Warshel, Lifson (for Karplus, Levitt, Warshel shared 2013 Nobel Prizechemistry) provided earliest frameworks computational treatments biomoleculesmeans investigate equilibrium structure dynamics (Fersht, 2013).Since early days, advances wet-laboratory techniques proceeded hand handadvancements computational techniques, often feeding each-other. advent NMRstructure determination provided evidence ability biomolecules fluctuate different structures even equilibrium (Kay, 1998, 2005). Figure 1(c) shows, addition X-raystructure myoglobin bound heme group, twelve models obtained via NMR, showcasingintrinsic flexibility important biomolecule molecular partner cell. Nowadays, wet-laboratory techniques, NMR cryo-Electron Microscopy (cryo-EM) resolve equilibrium structures quantify equilibrium dynamics. example, NMR usedidentify well-populated intermediate structures along transition (Aden & Wolf-Watz, 2007).Hybrid techniques combine NMR relaxation measurements X-ray models derivedroom-temperature crystallographic, single-molecule spectroscopy techniques tune optical radiation observe one molecule, others elucidate fast slow dynamic processes lastingpicoseconds milliseconds (Torella, Holden, Santoso, Hohlbein, & Kapanidis,2011; Fenwick, van den Bedem, Fraser, & Wright, 2014; Karam, Powdrill, Liu, Vasquez, Mah,Bernatchez, Gotte, & Cosa, 2014; Moerner & Fromm, 2003; Greenleaf, Woodside, & Block, 2007;Michalet, Weiss, & Jager, 2006; Diekmann & Hoischen, 2014; Hohlbein, Craggs, & Cordes, 2014;Schlau-Cohen, Wang, Southall, Cogdell, & Moerner, 2013; Moffat, 2003; Schotte, Lim, Jackson,Smirnov, Soman, Olson, Phillips, Wulff, & Anfinrud, 2003; Roy, Hohng, & Ha, 2008; Fenwicket al., 2014; Hohlbein et al., 2014; Lee, M., Kim, & Suh, 2013; Socher & Imperiali, 2013; Gall,Ilioaia, Kruger, Novoderezhkin, Robert, & van Grondelle, 2015).particular, wet-laboratory techniques employ fluorescence-based sensors, provideinformation dynamic, biological events effectively monitoring changes signalsstrategically-placed fluorophores (Socher & Imperiali, 2013). Depending placementfluorophores, binding two molecular partners switch/transition one molecule different structures monitored real time. techniques promisingrapidly adopted study specific biological systems interest, reliance fluorophores limits generality techniques, well structural detail obtained. moment, wet-laboratory techniques obtain incomplete view equilibrium dynamics, generally unable span disparate length time scales involvedstructural transition molecule (Maximova, Moffatt, Ma, Nussinov, & Shehu, 2016);atomic motions occur picosecond scale, side-chain motions take nanoseconds,concerted motions among groups atoms facilitating structural rearrangements molecular recognition events take anywhere microseconds milliseconds (Shaw,Maragakis, Lindorff-Larsen, Piana, Dror, Eastwood, Bank, Jumper, Salmon, Shan, & Wriggers,2010; Lindorff-Larsen, Piana, Dror, & Shaw, 2011; Zagrovic, Snow, Shirts, & Pande, 2002; Piana, Lindorff-Larsen, & Shaw, 2012b); extreme cases, binding natural drug moleculesproteins occurs hours scale (Hoelder, Clarke, & Workman, 2012).Computational treatments biomolecules driven promise complementing wetlaboratory treatments obtaining comprehensive detailed characterization equilibrium512fiC OMPUTATIONAL REATMENTS B IOMOLECULES ROBOTICS -I NSPIRED ETHODSdynamics. current well-known frameworks employed silico Molecular Dynamics(MD) (Verlet, 1967; McCammon et al., 1977) Monte Carlo (MC) (Hastings, 1970; Metropolis,Rosenbluth, Rosenbluth, Teller, & Teller, 1953). principle, entire equilibrium dynamicsmolecule simulated simply following motions constitutive atoms alongphysical forces atoms impose one another. foundation MD framework.contrast, MC framework, structural perturbation moves applied atoms bonds connectingatoms result physical forces instead design decisions. Different local searchstrategies formulated make use moves iteratively explore neighborhoodsstructure space biomolecule.scope capabilities MD- MC-based treatments biomolecules significantly increased due improvements hardware parallel computation strategies. Specialized architectures, Anton, supercomputer designed MD simulations, (Piana, LindorffLarsen, Dirks, Salmon, Dror, & Shaw, 2012a; Piana et al., 2012b; Lindorff-Larsen et al., 2011),GPUs (Stone, Phillips, Freddolino, Hardy, Trabuco, & Schulten, 2007; Harvey, Giupponi, & deFabritiis, 2009; Tanner, Phillips, & Schulten, 2012; Gotz, Williamson, Xu, Poole, Le Grand, &Walker, 2012), petascale national supercomputers, BlueWaters, Titan, Mira, Stampede (Dubrow, 2015; Zhao, Perilla, Yufenyuy, Meng, Chen, Ning, Ahn, Gronenborn, Schulten,Aiken, & Zhang, 2013) allowed characterizing biomolecular structure dynamicsmicrosecond time scale. Algorithmic improvements dynamic load balancing (Fattebert, Richards,& Glosli, 2012), neighbor searches (Proctor, Lipscomb, Zou, Anderson, & Cho, 2012), optimal force splitting (Batcho, Case, & Schlick, 2001) allow effectively distributing simulationdynamics molecular systems comprised billions particles (Perilla, Goh, Cassidy, Liu,Bernardi, Rudack, Yu, Wu, & Schulten, 2015).principle, full account equilibrium dynamics biomolecule requires comprehensive characterization structure space available biomolecule equilibrium wellunderlying energy surface governs accessibility structures transitionsstructures equilibrium. remains challenging via MD MC-based frameworks,algorithmic enhancements classic MD MC frameworks essentially aim enhancesampling structure space biomolecule. review state-of-the-art enhancementsfound work Maximova et al. (2016).survey paper, focus instead emerging contributions Robotics communityenhance sampling complementary algorithmic strategies. Specifically, reviewrobotics-inspired methods designed model structural excursions biomolecule equilibriumbuilding conceptually techniques designed originally robot motion planning.methods reached crucial stage. shown applicable characterizationdiverse molecular mechanisms computational structural biology, protein-ligand binding,folding unfolding peptides, proteins, RNA molecules, transitions small peptideslarge proteins thermodynamically-stable semi-stable structural states. survey shows, methods capable addressing challenging computational issues posedapplication settings, yet widely adopted computational biologycommunity large. various reasons, discussed survey, methodsseen providing efficient less detailed less accurate characterization biomolecular equilibrium structure dynamics. survey provides critical review robotics-inspiredmethods lays outstanding issues need addressed methods considered reliable tools widely adopted modeling biomolecular structure dynamics.513fiS HEHU & P LAKUsurvey organized follows. background models biomolecular energeticsgeometry provided Section 2. Section 3 introduces main classes problemsbiomolecular modeling addressed robotics-inspired methods, summarizes robot motionplanning frameworks methods build, concludes brief descriptionchallenges faced robotics-inspired methods context biomolecular modeling. Section 4provides examples design decisions address challenges comprehensivedetailed review robotics-inspired methods modeling biomolecular structure dynamics.Section 5 concludes survey critical summary remaining challenges discussionseveral prospects future research.2. Backgroundstructural excursions regulate recognition events biomolecule participatescell understood via theoretical treatment biomolecules thermodynamic systemshopping energetic states. hops fundamentally result concerted motionsatoms make biomolecule; physical system, constitutive particlesstate perpetual motion, fuelled thermal excitation, subjecting one anotherphysical forces (Cooper, 1984). forces cumulatively drive molecular system toward lowerenergy states, thermal excitations kick locally-optimal states, providing sufficientrandomness allow entire system undergo biased exploration structure space.following first summarize current knowledge atomic forces biomolecular energy functions employed computational treatments biomolecular structure dynamics. rest Section provides details biomolecular geometry, showing biomoleculestreated mechanistically modular systems composed numerous, heterogeneous components purpose characterizing equilibrium structure dynamics silico.2.1 Biomolecular Energetics: Molecular Mechanicsphysical interactions among particles make molecular system principlemeasured via quantum mechanics (QM) methods. QM methods carry detailed accurateelectronic structure calculations currently limited applicability molecular systemscomposed hundred atoms (Khaliullin, VandeVondele, & Hutter, 2013). Instead, molecular mechanics (MM) methods methods choice evaluate structuresmacromolecules, proteins, RNA, DNA, large molecular systems comprisedseveral molecules.Though long known atoms molecule subject one another physical forces,Coulomb forces others, work Levitt Warshel Lifson laboratoryWeizmann Institute Science propelled design consistent (now known MM) energyfunctions molecules. Lifson argued possible come small numberconsistent, transferable parameters depend local environment atom allowanalyzing energetics small crystalline molecules (Lifson & Warshel, 1968). Kendrew realizedconsistent energy functions could used conduct energetic evaluations differentplacements (that is, structures) atoms comprising proteins nucleic acids. LevittLifson operationalized realization conduct energy refinements protein structures (Levitt &Lifson, 1969).514fiC OMPUTATIONAL REATMENTS B IOMOLECULES ROBOTICS -I NSPIRED ETHODSMM energy functions become detailed accurate, still estimatestrue potential energy molecule, summing possible, physical interactionsatoms molecule. Research designing MM energy functions active, manydifferent functions offered different computational chemistry labs across world.functions largely follow common functional form, categorize pairwise atomic interactionslocal non-local interactions; noted accurate energy functionsavailable consider n-particle interactions, computationally expensivewidely adopted (Clementi, 2008). Local interactions concern modeling forces due bonds,bond angles, periodicity dihedral/torsion angles. Non-local interactions dividedelectrostatic (measured Coulomb potential) van der Waals (measuredLennard-Jones LJ potential) interactions. different types interactions typicallylinearly combined together, weight, associate potential energy valueparticular placement atoms given molecular structure.following equation provides example popular CHARMM energy function (Brooks,Bruccoleri, Olafson, States, Swaminathan, & Karplus, 1983) integrated NAMD software package simulation biomolecular dynamics (Phillips, Braun, Wang, Gumbart, Tajkhorshid, Villa, Chipot, Skeel, Kale, & Schulten, 2005).ECHARMM =Xkb (b b0 )2+kUB (S S0 )2+X+bondsXUBk ( 0 )2valence anglesXk (1 + cos(n ))+kimp ( 0 )2+dihedral anglesXimproper dihedral anglesXnonbonded atoms i, jXnonbonded atomsi, jijh RminRminij 6ij 122+rijrijqi qjrijk weights constants, 0 subscript indicates equilibrium, ideal values distancesangles. first term effectively penalizes deviations bond lengths equilibrium valuesquadratic potential. second term, also referred Urey Bradley (UB)1,3 term, introduces similar penalty pairs atoms separated two covalent bonds,distance two atoms involved 1,3 interaction denoted S. third term quadraticpotential valence angles (between two consecutive bonds), denoted . fourth termpotential calculated dihedral/torsion angles models presence steric barriersatoms separated three covalent bonds. term, n variables multiplicityphase angles, respectively. CHARMM, improper dihedral angles specially penalized,fifth term. sixth term shows LJ potential CHARMM. LJ term summing515fiS HEHU & P LAKUvan der Waals interactions non-bonded atoms, rij measures Euclidean distancetwo non-bonded atoms (that covered UB term), Rminij = (Rmini + Rminj )/2minimum interaction radius atoms, measured half sum known vander Waals radii Rmini Rminj (ij weight specific types atoms j). LJterm sums weak attraction long distances strong repulsion short distances. LJterm CHARMM 126 functional form, exponent 12 repulsive sub-termexponent 6 attractive sub-term. last term CHARMM function measureselectrostatic interactions via Coulomb potential: qi qj known partial charges atomsj, rij measures Euclidean distance atoms j, dielectric constantencoding type environment biomolecule (vacuum different types solventenvironments).Differences available potential energy functions due different weights, differentexponents used measure repulsion versus attraction terms van der Waals interaction,explicit estimation hydrogen-bonding interactions outside umbrella van der Waals interactions, (Hornak, Abel, Okur, Strockbine, Roitberg, & Simmerling, 2006). Amber suiteenergy functions, integrated Amber MD simulation package (Case, Darden, Cheatham,Simmerling, Wang, Duke, Luo, Merz, Pearlman, Crowley, Walker, Zhang, Wang, Hayik, Roitberg,Seabra, Wong, Paesani, Wu, Brozell, Tsui, Gohlke, Yang, Tan, Mongan, et al., 2014), OPLS (Jorgensen, Maxwell, & Tirado-Reves, 1988), CHARMM follow similar functional form.similar functions CEDAR (Hermans, Berendsen, van Gunsteren, & Postma, 1984) GROMOS (van Gunsteren, Billeter, Eising, Hunenberger, Kruger, Mark, Scott, & Tironi, 1996), incorporated GROMACS simulation package (Van Der Spoel, Lindahl, Hess, Groenhof, Mark,& Berendsen, 2005), others. review functions, known physics-based function,found work Ponder Case (2003). functions, known knowledge-basedfunction, include additional terms derived conducting statistics known active structuresproteins PDB. functions best suited specific applications, rapid modelingequilibrium structures. Rosetta (Leaver-Fay, Tyka, Lewis, Lange, Thompson, Jacak, Kaufman,Renfrew, Smith, Sheffler, Davis, Cooper, Treuille, Mandell, Richter, Ban, Fleishman, Corn, Kim,Lyskov, Berrondo, Mentzer, Popovi, & et. al., 2011) Quark (Xu & Zhang, 2012) recentexamples knowledge-based functions.Whether physics-based knowledge-based (or hybrid), current molecular energy functionsmodels and, such, contain inherent errors need taken account modeling biomolecular structure dynamics (Hornak et al., 2006). addition, functions, despite specific functional form, computationally expensive terms LJCoulomb terms due summation pairs atoms. terms also onessensitive small atomic motions. particular, 12-6 functional form LJ termprovides great complexity non-linearity energy surface one associatestructure space biomolecule. quite common reduce total energy structurehundred calories solely due improvements LJ term imperceptible changesatomic positions. Moreover, small atomic displacements lower value one termincreasing another energy function. optimization point view, termslinearly combined energy function essentially conflicting optimization objectives.computational biology, issue known frustration results rugged rough energysurfaces (that is, rich local minima). broader AI community, surfaces would referred multi-modal. true biomolecular energy surfaces overly rugged (known516fiC OMPUTATIONAL REATMENTS B IOMOLECULES ROBOTICS -I NSPIRED ETHODSprinciple minimal frustration) (Clementi, 2008; Nevo, Brumfeld, Kapon, Hinterdorfer, &Reich, 2005), modeled energy surfaces one probe silico current energy functions shown exceptionally rugged (Olson & Shehu, 2012; Molloy, Saleh, & Shehu, 2013;Lois, Blawzdziewicz, & OHern, 2010).2.2 Biomolecular Energy SurfaceEquilibrium biomolecular dynamics visualized structural excursions energy surface. picture emerges proteins funnel-like, multidimensional energy surface (Onuchic et al., 1997; Dill & Chan, 1997). Projecting surface onto coordinatescapture relevant features different structures would allow summarizing thus visualizingenergy surface terms landscape (Onuchic & Wolynes, 2004).energy landscape shown two different camera views Figure 2 illustrates protein energylandscapes expected reconstructed silico. Horizontal cross-sections landscape everydE units apart correspond different energetic states. cross-sections go widthenergy decreases; fewer options place atoms molecule potential energy gets lowerwithout incurring energetic costs greater dE. width cross-section, structuraldiversity energetic state, captured notion entropy. Thermodynamically-stable stateslow free energy F , measured F = hEi S, hEi average potentialenergy structures grouped together state, temperature, entropy.first visual illustration, proposed Dill Chan (1997), highlighted main featuresexpected true protein energy landscapes, single, deep wide basin correspondingthermodynamically-stable state shallower, narrower basins corresponding metastable states serving possible kinetic traps. landscape shown Figure 2(a) syntheticone closer landscapes corresponding existing MM energy functions; landscapesmooth rather rich local minima; words, landscape highly ruggedrough. different camera view Figure 2(b) emphasizes presence multiple, similarly-deepwide basins among current energy functions cannot distinguish purposepredicting stable state via energetic-based arguments; given inherent errors, structurefunction arguments cannot depend small energetic differences.energy landscape view instrumental linking molecular structure, dynamics, function. Viewing proteins biomolecules terms energy landscapes gave rise betterunderstanding folding binding diffusion-like processes series sequential, deterministic events. new, landscape view (Baldwin, 1995), biomolecules reachstable state equilibrium tumbling energy landscape along multiple routes (Bryngelson & Wolynes, 1987; Bryngelson, Onuchic, Socci, & Wolynes, 1995; Onuchic & Wolynes, 2004).light new view, intermediate, meta-stable states proteins would sometimesfound wet laboratory transitioning stable state correspond widebasins landscape. illustration provided Figure 2(b).new view inspired new understanding dynamic molecular processes, known conformational selection population shift (Ma, Kumar, Tsai, & Nussinov, 1999; Tsai, Ma, & Nussinov,1999b; Tsai, Kumar, Ma, & Nussinov, 1999a). Conformational selection refers ideastates unbound molecular unit present accessible bound unit. many unbound/uncomplexed biomolecules, may many semi-stable states equilibrium. proximity ligand another molecular partner shifts equilibrium (and thus probability distri517fiS HEHU & P LAKU(a) Illustration complex energy landscape(b) Tilted camera view highlights presence multiple energy basinsFigure 2: (a) shown landscape illustrates often reconstructed silico, rough landscapes richlocal minima. (b) tilted camera view emphasizes presence multiple energetic basins. basindefined neighborhood local minimum fitness landscape. interested reader encouraged learn features landscapes arise optimization problems Stadlers seminalreview (Stadler, 2002). Given high dimensionality structure space, many methods probe energylandscapes cannot guarantee particular, sought stable meta-stable state captured amongprobed basins, none probed basins artifacts energy function employed.bution possible states system found equilibrium) towards one statesclose optimal equilibrium unbound/uncomplexed molecule. words, presence binding partner considered external perturbation unbound/uncomplexedenergy landscape. Internal perturbations refer changes biomolecules composition duechanges DNA, copy read errors, post-translation modifications occur.many aberrant versions biomolecule, energy barriers stable semi-stable states518fiC OMPUTATIONAL REATMENTS B IOMOLECULES ROBOTICS -I NSPIRED ETHODSdrastically change modify underlying detailed structural mechanism regulating function,resulting dysfunction even loss function (Clausen, Ma, Nussinov, & Shehu, 2015).principle conformational selection allows employing analysis energy landscapesunbound molecules identify structural states interest complexation events. latterfound among meta-stable stable states uncomplexed molecule thusidentified via modeling simulation uncomplexed molecule.2.3 Computing Structures Structural Transitionstwo main problems addressed silico elucidate biomolecular equilibrium structure dynamics concern (i) computing ensemble structures constituting stablemeta-stable states relevant biological function (ii) computing detailed structural transitions structures. first problem amenable stochastic optimization, fundamentally involves locating deep wide basins/minima nonlinear multimodal energysurface. second problem entails elucidating different routes employed biomoleculeswitches two structures. survey focuses primarily second problem, computing structural transitions bound unbound biomolecules. Specifically, survey reviewsmethods employ robotics analogies address problem. While, principle, roboticsinspired methods also provide information structure space available biomoleculeequilibrium, other, powerful stochastic optimization algorithms exist purpose.refer interested readers review Shehu (2013), surveys state-of-the-art evolutionaryalgorithms (EAs) capable extracting efficient, discrete representations protein energy surfaces.minimum, algorithms aiming model biomolecular structures comprised threefunctional units: (i) way represent/model biomolecular structure; (ii) way modifymodels order obtain new structures; (iii) way evaluate energetics structures.existing MM energy functions summarized context biomolecular energeticsprovide way evaluate models biomolecular structures explored silico. functional units(i) (iii) related, model chosen protein structure determines great extentmoves perturbation operators designed efficiently effectively explorestructure space. Below, summarize models popular among different algorithmsemployed model equilibrium structures dynamics biomolecules. Details regardingmoves perturbation operators designed interface models provided latersurvey reviewing robotics-inspired methods.2.4 Molecular Models: Selecting Variables InterestCovalent bonds link atoms together molecule. protein molecules, atoms organizedamino acids, come twenty different types nature. amino acids contain commoncore heavy atoms make backbone unique set heavy atoms makeside chain (hydrogen/light atoms found backbone side-chain groups). twentynaturally-occurring amino acids differ side chain. Figure 3(a) shows N, CA, C,heavy-atoms comprise backbone amino acid illustrates amino acidsconnected via covalent, peptide bonds serial fashion form (polypeptide) chain.referred protein often one polypeptide chain; protein-protein binding polypeptidechains stay together via non-covalent, weak interactions.519fiS HEHU & P LAKU(a)(b)Figure 3: (a) chain six amino acids, backbone atoms N (gray), CA (black), C (gray),(silver). peptide bond Ni -Ci+1 links two amino acids (i proceeds N- C-terminus, referbackbone N C atoms peptide bonds). Circled atoms comprise side chain shown aminoacid. (b) three types internal coordinates shown here, bond length di , valence angletwo consecutive angles, torsion dihedral angle defined three consecutive bonds.dihedral angle angle two normals corresponding planes definedconsecutive bonds j j + 1 consecutive bonds j + 1 j + 2. Depending backbonebonds defined, dihedral angles referred either , annotated positionamino acid defined (in direction N- C-terminus). instance,refers dihedral angle bond connecting backbone N backbone CA atom amino acidi, refers dihedral angle defined bond connecting backbone CA backbone Catom amino acid i. Characteristic values observed , psi angles among equilibrium proteinstructures (Ramachandran et al., 1963).520fiC OMPUTATIONAL REATMENTS B IOMOLECULES ROBOTICS -I NSPIRED ETHODSFigure 3(a) illustrates side chains dangle backbone polypeptide chain. Treatingprotein molecule model atoms represented balls bondssticks exposes interesting questions regarding perform deformations model withoutbreaking covalent bonds. question essence structure modeling researchersanswer defining variables represent molecule able capture intrinsicflexibility equilibrium.2.4.1 C ARTESIAN C OORDINATE -BASED ODELSintuitive model molecular structure, Cartesian coordinate atomselected variable. Cartesian coordinate-based model preferred one MD algorithms, move individual atoms molecule according cumulative force sumsinteractions atom others molecule. However, model ideal. First,redundant, demanding 3N variables molecule N atoms. small peptide drugmolecules, number atoms may dozens, even small proteins, numberatoms easily surpass hundred; result, variable space hundreds dimensions.Many strategies offered reduce number variables essentially removingcertain atoms modeling. example, side-chain atoms first sacrificed proteinstructure modeling, since demonstrated main features equilibrium proteinstructures captured backbone (Rose, Fleming, Banavar, & Maritan, 2006).reduced structures modeled, side chains modeled via side-chain packing algorithms.studies focusing modeling molecular interactions, atoms comprise interactionsite explicitly modeled. decisions effectively result reduced models (and thus fewer dimensions selected variable space), ranging CA traces, central CA atommodeled amino acid, backbone models, backbone chain tracked3d space (Papoian, Ulander, Eastwood, Luthey-Schulten, & Wolynes, 2004; Matysiak & Clementi,2004; Das, Matysiak, & Clementi, 2005; Matysiak & Clementi, 2006; Hoang, Trovato, Seno, Banavar, & Maritan, 2007; Rose et al., 2006). rich literature reduced modelsenergy functions designed interface models (Clementi, 2008).Representing molecular structure terms Cartesian coordinates (or subset of)constitutive atoms appealing, new instantiation variable space readilyevaluated terms energetics. recall central LJ electrostatic/Coulomb termsenergy functions widely adopted biomolecular structure dynamics modeling operate 3d coordinates atoms. However, Cartesian coordinate-based modelredundant ineffective. First, model results excessive number variables, posesgreat challenges sampling-based method aimed probing structure space one sampletime. Second, ineffective, encode explicit implicit geometricconstraints present molecular structures.Many efforts computational biophysics community target reduction coordinates.resulting models referred coarse-grained models representations. firstmodel, employed MC simulation folding bovine pancreatic trypsin inhibitor,represented amino-acid residue one pseudo-atom (Levitt & Warshel, 1975). Workcoarse-grained multiscale models (in latter, different parts structure representeddifferent levels detail/resolution different time length scales) key extendspatio-temporal reach MD MC simulations biomolecular dynamics. work521fiS HEHU & P LAKUadditional onerous task designing accompanying energy functions reproduce knownthermodynamic properties even lower mixed structural resolution. Indeed, 2013 NobelPrize Warshel recognized seminal work multiscale models built QM/MMmethod (Warshel & Levitt, 1976; Warshel, 2003; Kamerlin, Haranczyk, & Warshel, 2009; Mukherjee & Warshel, 2011, 2012; Dryga, Chakrabarty, Vicatos, & Warshel, 2011; Rychkova, Mukherjee,Bora, & Warshel, 2013; Mukherjee & Warshel, 2013). interested reader directed reviewClementi (2008) coarse-grained models. review Zhou (2014) focuses multiscalemodels.2.4.2 E NCODING VARIABLE EPENDENCIES C ARTESIAN C OORDINATE -BASED ODELSOutside realm modeling chemical reaction processes, bond formation breaking,modeling biomolecular equilibrium structures dynamics, application setups requirepreserving certain structural features formulated local non-local constraints.constraints, keeping bonded atoms distance ideal/equilibrium lengthbond, known explicit, local constraints. trivially extracted specificationchemical composition molecule, involve neighboring atoms. Equilibrium conditionsplace additional, implicit constraints biomolecular structures. need preserve favorableLennard-Jones interactions, instance, places (non-local/long-range) constraints non-bondedatoms. long-range constraints cannot effectively captured modelvariable Cartesian coordinate atom. perturbation operator interfacesmodel modifies variables information invalid energetically-unfavorableassignments subsets variables, variable dependencies captured model.external energy model crucial form energy function evaluate resultsperturbation operator detect variable instantiations resulting violations.Cartesian coordinate-based model encode variable dependencies. latterextracted via several techniques, including multivariate analysis techniques analyze knownequilibrium structures biomolecule identify subsets atoms exhibit simultaneous displacements; is, move concert. essential premise techniques knownstructures good examples solutions near-solutions energy function, analysisexamples expose variable dependencies. dependencies employeddesign reduced Cartesian coordinate-based models readily encode energeticconstraints satisfied provided examples (solution near-solution structures) effectiveperturbation operators readily yield new near-solution instantiations reduced variablespace (Clausen & Shehu, 2015).Multivariate Analysis Techniques Obtain Collective Variables sub-field statisticaltechniques identification collective motions, also referred collective coordinates collective variables rich, review subject survey. Instead, pointrecent work narrow context biomolecular modeling, variance-maximizing techniques, Principal Component Analysis (PCA) (Shlens, 2003), Isomap (Tenenbaum, de Silva,& Langford, 2000), Locally Linear Embedding (Roweis & Saul, 2000), Diffusion Maps (Coifman,Lafon, Lee, Maggioni, Nadler, Warner, & Zucker, 2005), others (van der Maaten, Postma, & vanden Herik, 2009) employed analyze biomolecular structures dynamics (Teodoro,Phillips, & Kavraki, 2003; Das, Moll, Stamati, Kavraki, & Clementi, 2006; Plaku, Stamati, Clementi,& Kavraki, 2007; Gorfe et al., 2008; Grant et al., 2009; Hori, Chikenji, & Takada, 2009; Maisuradze,522fiC OMPUTATIONAL REATMENTS B IOMOLECULES ROBOTICS -I NSPIRED ETHODSLiwo, & Scheraga, 2009; Rohrdanz, Zheng, Maggioni, & Clementi, 2011; Zheng, Rohrdanz, Maggioni, & Clementi, 2011) and, importantly, identify variables represent collective motionsatoms (Zheng, Rohrdanz, & Clementi, 2013; Clausen & Shehu, 2015; Clausen et al., 2015; Molloy, Clausen, & Shehu, 2016; Maximova, Plaku, & Shehu, 2015). addition methods,ones Normal Mode Analysis (NMA) (Ciu & Bahar, 2005) also rich historycomputational structural biology (Atilgan, Durell, Jernigan, Demirel, Keskin, & Bahar, 2001;Delarue & Sanejouand, 2002; Kim, Chirikjian, & Jernigan, 2002b; Zheng & Doniach, 2003; Tama,Valle, Frank, & Brooks, 2003; Bahar & Rader, 2005; Maragakis & Karplus, 2005; Zheng & Brooks,2005; Zheng, Brooks, & Hummer, 2007; Yang, Song, Carriquiry, & Jernigan, 2008; Yang, Majek,& Bahar, 2009; Das, Gur, Cheng, Jo, Bahar, & Roux, 2014). normal modes extractedNMA also often employed effective perturbation operators robotics-inspired methods (Tama & Sanejouand, 2001; Kim, Jernigan, & Chirikjian, 2002a; Kirillova, Cortes, Stefaniu, &Simeon, 2008; Schuyler, Jernigan, Wasba, Ramakrishnan, & Chirikjian, 2009; Teknipar & Zheng,2010; Baron, 2013; Al-Bluwi, Vaisset, Simeon, & Cortes, 2013). summary highlightsrobotics-inspired methods later survey describe greater detail collective variablesemployment effective perturbation operators.2.5 Internal Coordinate- Angular-Based Modelsinternal coordinate model offered effective alternative Cartesian coordinatebased model (Burgess & Scheraga, 1975). internal-coordinate model, variablesselected bond lengths, angles two consecutive bonds, torsion dihedral anglesthree consecutive bonds. Figure 3(b) provides illustration. model allows fastforward kinematics, changes Cartesian coordinates result changes valuesvariables efficiently calculated via accumulation rigid-body transformations (Craig, 1989;Zhang & Kavraki, 2002a).Internal coordinate-based models norm non-MD based molecular structure modeling. additional simplification made equilibrium protein structures. Analysis depositedequilibrium structures proteins reveals bond lengths bond angles constrained characteristic values (Engh & Huber, 1991). consequence energetic constraints placedstructures equilibrium exploited idealize protein geometry modeling effectivelyremoving bond lengths bond angles list variables model. leavesdihedral angles defined three consecutive bonds variables (, backbone anglesfour dihedral side-chain angles per amino acid, shown Figure 3(a)) computationally appealing, number dihedral angles polypeptide chain N atoms average3N/7 (Abayagan, Totrov, & Kuznetsov, 1994). worth noting bond lengths bond angles change even equilibrium, faster pace motions. Employing idealizedgeometry allows devoting computation obtaining slower fluctuations first. structuresrepresentative molecules equilibrium dynamics obtained, deviations bond lengthsbond angles introduced studied via detailed models.2.5.1 B IOMOLECULES K INEMATIC C HAINS R EVOLUTE J OINTSIdealizing protein geometry reveals mechanistic analogies kinematic chains revolutejoints. Similarly joint rotation changes positions following links, rotationdihedral angle change positions following atoms (Craig, 1989). analogies523fiS HEHU & P LAKUemployed robotics researchers apply algorithms plan motions kinematic chainsrevolute joints study protein conformations (Manocha & Zhu, 1994; Singh, Latombe, &Brutlag, 1999; Apaydin, Singh, Brutlag, & Latombe, 2001; Amato, Dill, & Song, 2003; Apaydin,Brutlag, Guestrin, Hsu, & Latombe, 2003; Song & Amato, 2004; Cortes, Simeon, & Tran, 2004;Cortes, Simeon, Guieysse, Remaud-Simeon, & Tran, 2005; Lee, Streinu, & Brock, 2005; Kimet al., 2002a; Chiang, Apaydin, Brutlag, Hsu, & Latombe, 2007; Shehu & Olson, 2010; Molloyet al., 2013; Molloy & Shehu, 2013; Haspel, Moll, Baker, Chiu, & E., 2010; Shehu, Clementi, &Kavraki, 2006). Unlike typical articulated robotic mechanisms, protein chains pose hundreds ratherdozen variables (a short backbone 50 amino acids poses 100 dihedral angles variables).analogies protein chains kinematic chains revolute joints popularamong robotics researchers proposing robotics-inspired methods modeling biomolecular structure dynamics. instance, torsional angles employed early model protein ligandbinding (Singh et al., 1999) remain popular modeling kinetics folding small proteinRNA molecules (Han & Amato, 2001; Amato et al., 2003; Song & Amato, 2004; Thomas,Song, & Amato, 2005; Thomas, Tang, Tapia, & Amato, 2007; Tang, Thomas, Tapia, Giedroc, &Amato, 2008; Tapia, Thomas, & Amato, 2010). angles also proved popular computingfunctionally-relevant structures peptides proteins (Haspel, Tsai, Wolfson, & Nussinov, 2003;Shehu et al., 2006; Shehu, Clementi, & Kavraki, 2007; Shehu, Kavraki, & Clementi, 2007, 2008;Cortes et al., 2004; Shehu, Kavraki, & Clementi, 2009; Shehu, 2009; Shehu & Olson, 2010; Molloyet al., 2013), well modeling peptides proteins switching different functionallyrelevant structures (Cortes et al., 2005; Jaillet, Cortes, & Simeon, 2008; Haspel et al., 2010; Jaillet,Corcho, Perez, & Cortes, 2011; Molloy et al., 2016; Molloy & Shehu, 2013, 2015; Devaurs, Molloy,Vaisset, Shehu, Cortes, & Simeon, 2015; Molloy & Shehu, 2016).Techniques Obtain Reduced Angular-based Models number variables angularbased models reduced via various techniques. instance, consecutive dihedralangles bundled together fragments capture variable dependencies. technique,known molecular fragment replacement introduced context MC-based methodsde novo protein structure prediction (Bradley, Misura, & Baker, 2005), allows operationalizingobservation limited number configurations observed k-bundles consecutivedihedral angles among stable protein structures equilibrium (Han & Baker, 1996). technique incorporated robotics-inspired methods modeling equilibrium protein structure dynamics (Shehu & Olson, 2010; Molloy et al., 2013; Molloy & Shehu, 2013, 2016).application-specific techniques analyze structures reduce prioritize number dihedral angles manipulation perturbation operator. Rigidity-based techniques, instance, analyzegiven structure detect least-constrained regions suggest order dihedral anglesmodify first often order focus computational resources computing large structural deformations first (Thorpe & Ming, 2004; Wells, Menor, Hespenheide, & Thorpe, 2005; Fox& Streinu, 2013). Rigidity-based analysis incorporated robotics-inspired methodsmodeling protein dynamics (Thomas et al., 2007). techniques aimed specifically modeling structural transitions large proteins (Raveh, Enosh, Furman-Schueler, & Halperin, 2009;Haspel et al., 2010). these, comparison two structures transition soughtidentifies differently-valued dihedral angles. similar fashion rigidity-based analysis,angles prioritized modified often perturbation operators order capturepossibly large structural deformations reasonable amount time. techniques make524fiC OMPUTATIONAL REATMENTS B IOMOLECULES ROBOTICS -I NSPIRED ETHODSseveral assumptions variables participate process interest, highlightassumptions implications later survey.Biomolecular Structure versus Biomolecular Conformation light various modelsemployed represent biomolecular structure, distinction needs madeterms structure conformation. term structure meant refer specificationCartesian coordinates atoms comprise molecule (even atoms explicitlymodeled, backbone reduced structure). term conformation meant general refer specification values variables selected model structure;is, conformation particular instantiation employed variable space. instance, conformation instantiation angles angular-based model employed, forward kinematicsallows obtaining structure encoded conformation. worth noting termsconformation structure often used interchangeably slight abuse terminologybiomolecular modeling literature. instance, many algorithms explicitly modify structures via Cartesian coordinate-based models referred conformational search algorithms;course, models employed, structure extracted trivially conformation. survey, distinction made observed referring structuresconformations.specific domain robotics-inspired methods, term (molecular) conformation equivalent (robot) configuration. However, keeping broader computational biology literature, employ term conformation referring macromolecules, proteins,RNA, DNA, reserving term configuration small molecules (also referred ligands)bind macromolecules. addition, term variable often referred parameter broader computational biology biophysics literature degree freedom (dof)robotics AI literature, employ general, non-domain specific term variablevariable space. is, (molecular) conformation instantiation space selectedvariables. Depending number variables selected model molecule investigation, variable space may high-dimensional. Mapping conformation correspondingstructure allows associating structure space employed variable space. Moreover, energyfunctions allow associating energy surface structure space, interesting observationsregarding stable semi-stable structural states excursions among states madeanalyzing structure space low-dimensional projections/embeddings underlying energysurface, hence energy landscape.Educational Resources purpose material related provide enough detailbiomolecular geometry allow seeing biomolecules treated mechanistically modular systems composed numerous, heterogeneous components purpose characterizingsilico. information readers varying levels background interestfound online, educational learning modules designed introduce computer scientists computational structural biology. One set modules, publicly accessible cnx projecthighly popular students researchers, found http://cnx.org/contents/9cMfjngH@6.3:ppj-3H2A@14/Structural-Computational-Biolo. modules, instance, interested readers learn protein architecture greater detail.modules mirror material summarized representations energy functions, yet others introduce readers forward inverse kinematics modular mechanical systems, makingmodules good supplement survey robotics-inspired methods presented here.525fiS HEHU & P LAKU3. Summary Biomolecular Modeling Problems Robot Motion PlanningFrameworksintroduce main classes problems biomolecular modeling addressedrobotics-inspired methods. robot motion planning frameworks methods buildsummarized next. section concludes summary challenges faced algorithmic realizations frameworks modeling biomolecular structure dynamics. challengespreview important design decisions detailed Section 4 context reviewingrepresentative methods.3.1 Representative Problems Biomolecular ModelingTwo main classes molecular mechanisms studied robotics-inspired methods,involve one molecule associating/complexating disassociating one another,involve dynamic, uncomplexated molecule. application setups, concerninforming understanding dynamic events involving dynamic molecules.first application setup, robotics-inspired methods aim model understand proteinligand binding events. Provided unbound structures protein receptor small ligandmolecule, objective elucidate ligand approaches binds protein receptor. related problem, reverse process addressed. ligand bound receptor,goal determine motions ligand protein receptor allow disassociation.Modeling protein-ligand binding important general understanding biologyalso computation-aided drug discovery. molecular recognition eventsprotein-protein, protein-DNA, protein-RNA, protein-membrane binding conceptually fallcategory protein-ligand binding, challenging due higher numbervariables needed model association complexation event currently beyond domain applicability robotics-inspired methods.second application setup concerns modeling understanding dynamics molecules.Almost exclusively, focus robotics-inspired techniques category uncomplexed protein RNA molecules. goal elucidate structural deformations motions allowprotein RNA molecule transition two structural states interest. statesunfolded folded state, case goal highlight folding unfoldingpaths, stable semi-stable structures employed molecule recognizelock onto different molecules, case goal formulate hypothesis regardingimpact structure molecular recognitions healthy diseased cell.Figures 4-5 illustrates problems. Figure 4, robotics-inspired method highlightligand approaches protein receptor, well binds onto receptorconfiguration. variables interest need minimum include translational rotationalvariables ligand, well internal coordinates capture potential structural flexibilityligand. receptor considered frozen 3d space. accurate setup wouldalso consider internal coordinates receptor order model possible structural flexibilityupon ligand binding. However, resulting number variables would large. roboticsinspired method elucidate bound ligand configuration bound placementrelative receptor, also possible routes successive configurations placementsligand may follow approach binding site(s). addition, Figure 5(a) illustrates,robotics-inspired method show possible routes successive structures employed526fiC OMPUTATIONAL REATMENTS B IOMOLECULES ROBOTICS -I NSPIRED ETHODSFigure 4: (a) ligand bind protein receptor? Many methods designedelucidate step-by-step process ligand approaches protein molecule, binds,configuration.protein fold, thus shedding light process protein folding unfolding. Similar setupsconsider RNA molecules. Figure 5(b) illustrates often robotics-inspired methods employedreveal folding unfolding routes protein, also structural transitionstwo structures interest; knowledge probable routes carry transition allowsunderstanding structural level mechanism biomolecule regulates biologicalactivity cell.3.2 Foundations Robotics-inspired Treatments Biomoleculesfundamental assumption robotics-inspired treatments biomolecules mechanisticanalogies molecular chains robot chains allow putting together efficient algorithmsrapid exploration molecular structure spaces modeling excursions moleculesspaces (Manocha & Zhu, 1994; Singh et al., 1999; Apaydin et al., 2001; Amato et al., 2003; Apaydinet al., 2003; Song & Amato, 2004; Cortes et al., 2005; Kim et al., 2002a; Chiang et al., 2007;Kirillova et al., 2008). is, instead simulating molecule navigates energy surfacevia gradient-based local search techniques, powerful techniques put togetherbuilding algorithms demonstrated high exploration capability robot configurationspaces. Robotics-inspired treatments biomolecules draw techniques fast forward527fiS HEHU & P LAKU(a) Protein folding(b) Structural TransitionsFigure 5: (a) proteins fold? Shedding light process protein folding important goal,many robotics-inspired methods devoted elucidating process step step computingprobable succession structures assumed protein navigating unfolded folded state.(b) proteins transition diverse structures use interacting different partnerscell? Robotics-inspired methods seek elucidate structural transitions meta-stable stablestructural states protein.inverse kinematics and, importantly, sampling-based algorithms developed algorithmicrobotics community address robot motion-planning problem (Choset & et al., 2005).528fiC OMPUTATIONAL REATMENTS B IOMOLECULES ROBOTICS -I NSPIRED ETHODSobjective robot motion planning obtain paths take robot given, startconfiguration given, goal configuration. robot motion planning problem bears mechanisticanalogies problem computing conformations along transition trajectory biomolecule;problems, driving objective uncover underlying (molecular) conformation (robot) configuration space employed motions articulated system startgoal conformation configuration. Analogies molecular bonds robot links molecular atoms robot joints help draw techniques perform fast kinematics kinematiclinkages (Manocha, Zhu, & Wright, 1995; Zhang & Kavraki, 2002b); is, specifying valuesvariables selected represent molecular conformation, rapidly update Cartesian coordinatescorresponding structure (Zhang & Kavraki, 2002b). inverse kinematics setting,techniques allow rapidly obtaining values underlying variables consistent Cartesian-basedconstraints (Chirikjian, 1993; Manocha & Canny, 1994; Zhang & Kavraki, 2002a; Kolodny, Guibas,Levitt, & Koehl, 2005).higher level, robotics-inspired methods operationalize two key observations. firstobservation, originally made robot configuration spaces, solution-containing regionshigh-dimensional non-linear variable space found heuristic rather exactapproaches; stochastic, sampling-based techniques construct distribution constraintsatisfying instantiations two-stage manner; initial distribution first constructed via sampling unconstrained variable space. Instantiations evaluated external (energetic) models capable capturing inter-variable dependencies penalizing violations constraints. Violating samples either removed down-weighted initial, uninformed distribution gradually converges containing solutions. second observation transitionssystem two given solutions modeled via discrete, kinetic models essentiallyembed solutions graph-like structures amenable rapid, shortest, lowest-cost path queries,provided lengths cost metrics associated given series configurationspath. Methods embed solutions tree referred tree-based methods,embed solutions graph referred roadmap-based methods.3.3 Motion Planning Framework: Tree- Roadmap-Based Methodscontext molecular modeling, tree-based methods grow tree conformation spacegiven, start given, goal conformation representing structures bridged sought transition. tree incrementally extended, every iteration adding new conformation nodenew branch tree. Depending whether tree pulled towards configurations sampledrandom configuration space pushed leaves towards new regions configuration space, method known Rapidly Random Exploring Tree (RRT) (LaValle & Kuffner,2001), Expansive Spaces Tree (EST) (Hsu, Kindel, Latombe, & Rock, 2002), accordingly.important note sampling connectivity go hand hand, every sampled conformation added growing tree. growth tree biased goal conformationreached reasonable computational time. result, tree-based methods efficientlimited sampling. known single-query methods, answer onestart-to-goal query time; is, one path consecutive conformations connectstart goal extracted. Running multiple times sample ensemble conformation paths query results ensemble high inter-path correlations duebiasing conformation tree.529fiS HEHU & P LAKURoadmap-based methods adapt Probabilistic Road Map (PRM) framework(Kavraki, Svestka, Latombe, & Overmars, 1996). Rather grow tree conformation space,methods detach sampling conformations connectivity model encodesneighborhood relationships among conformations conformation space. Typically, samplingstage first provides discrete representation conformation space interest, conformations satisfying explicit implicit geometric energetic constraints, roadmap buildingstage embeds sampled conformations graph/roadmap connecting one nearest neighbors. Roadmap-based methods provide richer information regarding dynamic event,multiple paths may exist roadmap connecting two structures interest. Moreover,methods support multiple queries, principle graph used extract paths connecting different given structures. structures specified conformations connectednearest neighbors graph, graph queried optimal paths. practice,difficult obtain broad dense sampling sufficient regions conformation spacemolecule elucidate diverse excursions structures interest.provide detail tree-based roadmap-based methods robotics familiarize reader diverse design decisions employed even adapted robotics-inspiredmethods biomolecular modeling.3.3.1 N - HIERARCHICAL REE -BASED ROBOT OTION P LANNING ETHODSTree-based methods categorized broadly based strategies employed select vertexexpand tree. Non-hierarchical strategies consider vertices possiblecandidates. Hierarchical strategies place tree vertices bottom layer introduce additionalhigh-level layers group similar vertices together, proceeding top bottom layerselection process.RRT one widely used non-hierarchical tree-based motion planning methods.RRT (LaValle & Kuffner, 2001), iteration, tree expanded towards randomly-sampledconfiguration qrand . nearest vertex, qnear , tree qrand determined according distance metric. local planner attempts connect qnear qrand . Often local planner interpolatesunderlying variables generate intermediate configurations. basic version RRT,iteration stops one interpolation step. connect version, expansion continuesqrand reached interpolation results invalid configuration, e.g., collision obstacles.process sampling configuration expanding nearest neighbor tree repeated goal reached. Figure 6 shows tree. using random sampling nearestneighbors, RRT exhibits Voronoi bias enables expansion tree toward unexploredregions. also bias search towards goal, qrand often selected probability b (often set0.05) goal configuration probability 1 b uniformly random.years, different RRT variants developed order improve exploration.adaptive dynamic domain RRT (ADDRRT) (Jaillet, Yershova, LaValle, & Simeon, 2005) associates sampling radius tree vertex dynamically adjusts radius basedsuccess local planner. reachability-guided RRT (RGRRT) (Shkolnik, Walter, & Tedrake,2009) relies notion reachable sets increase likelihood successful tree expansions. obstacle-based RRT (OBRRT) (Rodriguez, Tang, Lien, & Amato, 2006b) increasessampling near obstacles, PCARRT (Dalibard & Laumond, 2009) relies PCA, selectiveretraction-based RRT (SRRRT) (Lee, Kwon, Zhang, & Yoon, 2014) uses bridge sampling se530fiC OMPUTATIONAL REATMENTS B IOMOLECULES ROBOTICS -I NSPIRED ETHODSFigure 6: tree built RRT shown simplistic environment.lective retraction order facilitate expansions inside narrow passages. utility-guided RRT(UGRRT) (Burns & Brock, 2007) associates utility measure vertex uses promote expansions increase utility. RRT-Blossom (Kalisiak & van de Panne, 2006) createsflood-fill behavior locally explore area surrounding vertex. Machine learning alsoused derive distance metric captures cost-to-go order improve explorationRRT (Palmieri & Arras, 2015). reachable volume RRT (RVRRT) (McMahon, Thomas, &Amato, 2015) relies notion reachable volumes order restrict sampling feasibleregions improve performance RRT highly-constrained problems. abstractionguided RRT (fRRT) (Kiesel, Burns, & Ruml, 2012) uses A* search grid-based decompositionbias RRT sampling towards low-cost regions. RRT* (Karaman & Frazzoli, 2011) rewiresbranches RRT find optimal solutions respect given cost function.EST (Hsu et al., 2002) takes different approach RRT pushing frontiertree towards unexplored areas. Instead relying expansions nearest neighbor, ESTmaintains probability distribution tree vertices. iteration, vertex v selectedprobability inversely proportional density small neighborhood around v. allowsEST push tree towards less-explored regions configuration space.3.3.2 H IERARCHICAL REE -BASED OTION P LANNING ETHODSHierarchical tree-based methods rely scheme first selects region vertexexpand tree. Regions often defined based decomposition low-dimensionalprojection configuration space. rationale that, grouping similar vertices, betterselections made region level effectively guide tree exploration. instance,single-query, bidirectional, lazy collision-checking (SBL) method (Sanchez & Latombe, 2002)pushes tree toward sparse regions using grid-based decomposition uniform probability distributions select non-empty grid cells. kinodynamic planning interior-exterior cellexploration) (KPIECE) method (Sucan & Kavraki, 2012) relies multi-level grid decomposition constructed user-defined random linear projections. synergistic combinationlayers planning (SyCLoP) method (Plaku, Kavraki, & Vardi, 2010) uses discrete search531fiS HEHU & P LAKUlow-dimensional triangular grid decomposition guide tree exploration along short regionpaths goal. guided sampling tree (GUST) method (Plaku, 2015) partitions motiontree equivalence classes relies multi-objective criteria based shortest-path distances,selection penalties, progress made determine equivalence classes could result rapidexpansions toward goal.path-directed subdivision tree (PDST) method (Ladd & Kavraki, 2004, 2005) reliesgrid subdivision configuration space. cell decomposition keeps tracktree branches fall it. Initially, tree root vertex one cellcorresponding minimum maximum values variable. iteration, treebranch selected expansion. cell c contains selected tree branch dividedtwo cells, c1 c2 , along largest dimension. tree branches c also split accordingboundaries c1 c2 . ensures invariant tree branch containedentirely one cell. selected tree branch b expanded picking configuration q along busing propagation add new branch starting q. Propagation problem-dependent couldcorrespond moving random direction.propagation continues collision found maximum number steps reached.branch split exits cell boundaries. key component PDST weightingscheme associated cell based volume, number branches, number previousselections. selecting tree branch, order increase coverage, priority given cellslarge volumes well-explored. iteration, selected cellc penalized order ensure cells eventually selected expansion.necessary avoid oversampling guarantee probabilistic completeness (Ladd & Kavraki, 2005).PDST also combined artificial potential fields order expand treeregion lowest potential (Bekris & Kavraki, 2007).3.4 Roadmap-Based Robot Motion Planning Methodsintroduction PRM (Kavraki et al., 1996) shifted focus complete probabilisticallycomplete motion-planning algorithms, guarantee find solution, exists, probability approaching one time tends infinity. complete algorithms limited simpleproblems 23 variables, PRM made possible efficiently solve high-dimensional problems. underlying idea PRM construct roadmap captures connectivity(obstacle-)free configuration space. roadmap populated generating numbercollision-free configurations. configuration generated sampling values variablesuniformly random. configuration discarded, results collision. Otherwise, addedroadmap. capture connectivity, neighboring roadmap configurations connectedcollision-free paths. Figure 7 provides illustration roadmap created PRM. common approach compute roadmap configuration k-nearest neighbors accordingdistance metric. path two configurations often obtained linear interpolation.path collision free, added edge roadmap graph. path given startgoal configuration found first connecting start goal configurations roadmapsearching roadmap graph. A* often used efficiently compute shortest roadmappath. Additional sampling may required initial roadmap contain pathstart goal.532fiC OMPUTATIONAL REATMENTS B IOMOLECULES ROBOTICS -I NSPIRED ETHODSbbbbbbbbbbbbbbbbbgoalbstartbbbFigure 7: illustration roadmap used answer start-to-goal queries.years, numerous strategies proposed enhance sampling PRM.Obstacle-based PRM (OBPRM) (Amato, Bayazit, Dale, Jones, & Vallejo, 1998) seeks increasesampling near obstacles order improve connectivity inside narrow passages. BridgePRM(Sun, Hsu, Jiang, Kurniawati, & Reif, 2005) similar objective uses bridge test generatesamples halfway two obstacles. Machine learning also used conjunctionportfolio samplers enhance sampling narrow passages (Hsu, Sanchez-Ante, & Sun, 2005).region-sensitive adaptive PRM (RESAMPL) (Rodriguez, Thomas, Pearce, & Amato, 2006a)uses notion entropy identify regions enhance sampling. TogglePRM (Denny &Amato, 2013) switches free configuration space obstacle space order facilitate connections narrow passages. ANC-Spatial (Ekenna, Thomas, & Amato, 2016) usesspatial-learning approach enhance roadmap connectivity determining appropriate connection methods roadmap vertex. PRM* (Karaman & Frazzoli, 2011) variant PRMleads optimal solutions respect given cost function. modification surprisinglysimple, requires using variable number nearest neighbors instead fixed k.3.5 Biomolecular Modeling Challenges Tree- Roadmap-Based Methodstree- roadmap-based methods experience curse dimensionality several ways.central issue concerns breadth sampling possibly high-dimensional complex variablespaces. particular, context biomolecular modeling, decision variablesrepresent key, determines dimensionality complexity variable/conformationspace. decision tightly tied application setting class biomolecular systemsconsidered. reviewed Section 2, many adaptations selected variablessubset backbone dihedral angles (Han & Amato, 2001; Amato et al., 2003; Song & Amato,2004; Thomas et al., 2005, 2007; Jaillet et al., 2008; Tang et al., 2008; Tapia, Tang, Thomas, &Amato, 2007; Tapia et al., 2010; Jaillet et al., 2011; Shehu & Olson, 2010; Molloy et al., 2013;Molloy & Shehu, 2013), others selected variables capture collective motions atoms3d Cartesian space (Kim et al., 2002b, 2002a; Kirillova et al., 2008; Schuyler et al., 2009; Al-Bluwiet al., 2013; Maximova et al., 2015). Whether values variables sampled individually533fiS HEHU & P LAKUtandem a-priori compiled databases good moves (Shehu & Olson, 2010; Molloy et al.,2013; Molloy & Shehu, 2013), whether diverse perturbation/sampling operators employedmake use different sets variables (Gipson, Moll, & Kavraki, 2013; Molloy & Shehu, 2016),dimensionality size variable space remains key challenge tree- roadmapbased treatments biomolecules.choice variables key design effective sampling perturbation operatorsgenerating conformations satisfy set desired geometric and/or energetic constraintsbiomolecular modeling problem hand. Samples obtained uniformly random lowprobability low-energy region interest sought structural transition.particular, long protein chains hundreds backbone dihedral angles, conformationsampled random highly unlikely physically-realistic.Biased sampling techniques used remedy issue (Amato et al., 2003; Song &Amato, 2004), hard know priori perturbation operators effective. Recent work recognizes issue addresses offering diverse sampling operators possiblydiverse sets variables (Raveh et al., 2009; Gipson et al., 2013; Molloy & Shehu, 2016). particular, work Molloy Shehu (2016) implements probabilistic scheme selects amongrich menu operators making use angular Cartesian variables.worth noting sampling operators may generate samples vacuum incremental modifications existing samples. earlier generations tree- roadmapbased methods typically obtained new conformations sampling values selected variables (Singh et al., 1999), recent methods generate samples neighborhoods existing parentsamples (Shehu & Olson, 2010; Molloy & Shehu, 2013; Maximova et al., 2016) (hence, oftenused term perturbation operator). later strategy higher chance yielding physicallyrealistic conformations, perturbation operators perturb selected sample obtain new onetend preserve good structural features new sample introducing enough changeexplore new regions variable space (Olson, Hashmi, Molloy, & Shehu, 2012). contextperturbation operators, selection schemes critical control sampling. recent phenomenonrobotics-inspired methods recognition selection schemes, centralhierarchical tree-based robot motion planning (as reviewed above), also employedtree- roadmap-based methods steer biomolecular sampling regions interest (Shehu &Olson, 2010; Molloy & Shehu, 2013; Maximova et al., 2016).additional challenge ensuring high sampling capability biomolecules underlying complex energy surfaces encode energetic constraints. Therefore, criterionaccepting sampled conformation adding vertex list tree roadmap needs either rely a-priori set energy threshold probabilistic nature. latter setting providesbalance obtaining low-energy conformations allowing particular algorithm gohigh-energy barriers needed sample conformation space (Jaillet et al., 2008,2011; Molloy & Shehu, 2013; Devaurs et al., 2015; Molloy & Shehu, 2016).roadmap- tree-based methods rely local planners local deformation techniquesconnect neighboring conformations. tree-based methods push tree variablespace generating child conformations selected parent conformations via perturbation operators, child becomes neighbor selected parent; neighborhood function relynotion distance variable space instead tied parent-child relationship.methods, sampled conformation needs connected one nearest neighbors. Nearest-neighbor calculations need specification distance function conforma534fiC OMPUTATIONAL REATMENTS B IOMOLECULES ROBOTICS -I NSPIRED ETHODStions, non-trivial high-dimensional spaces. adaptations employ least Root-MeanSquared-Deviation (lRMSD), modification Euclidean distance differences duerigid-body motions removed optimal superimposition protein conformations comparison (McLachlan, 1972). lRMSD carried Cartesian coordinate-basedinstantiations. distance functions use L1 related variants defined dihedral angles.generally challenging find computationally-efficient dynamics-integrating local planners biomolecular conformations. conformations q1 q2 nearby variable structurespace, local path encoded edge tree roadmap encode processdiffusion. local path provide evidence diffusion biomolecule q1q2 presence thermal vibrations. readily obvious use dynamics steerbiomolecule q1 q2 . principle MD simulations employed searchpaths, guarantee simulations reach q2 . biased MD simulationsemployed reach q2 , simulations modify energy surface model actualdynamics (Ma & Karplus, 1997). Moreover, corrections biased MD simulations modelactual dynamics prove computationally expensive (Ovchinnikov & Karplus, 2012) contextrobotics-inspired methods evaluate thousands edges.result, majority robotics-inspired methods biomolecular modeling employ localplanners carry linear interpolations variables conformations needconnected via tree branch roadmap edge. planners produce unrealistic conformations,significant time spent correcting geometry ensuing energetic violations via energyminimization. Recent work proposes complex, local planners based interpolationinstead re-formulations motion computation problem; is, local planners tree- roadmap-based methods (Molloy & Shehu, 2016). latter idea borrowedsimilarly challenging setting motion planning manipulators, linear interpolation also effective (Nielsen & Kavraki, 2000). making use complex local planners,prioritized path sampling scheme needed prioritize application computationallydemanding planners promising paths order control computational cost (Nielsen &Kavraki, 2000). work Molloy Shehu (2016) provides implementation prioritizedpath sampling biomolecular modeling.4. Robotics-Inspired Methods Equilibrium Biomolecular StructureDynamicsTable 1 categorizes different robotics-inspired methods robot motion planning frameworksadapt application setups address. table comprehensive means,may useful readers selecting focus specific applications. rest Sectiondescribe methods greater detail, paying particular attention recent, state-of-the-artmethods showcase current capabilities robotics-inspired treatments biomolecules.4.1 Tree-Based Methods Modeling Equilibrium Biomolecular Structure DynamicsTree-based methods employed model biomolecular flexibility compute conformation paths connecting given structures (Cortes et al., 2005; Shehu, 2009; Shehu & Olson, 2010;Jaillet et al., 2011; Haspel et al., 2010). tree-based methods address decoy sampling denovo protein structure prediction problem (Shehu & Olson, 2010; Olson, Molloy, Hendi, & Shehu,2012; Molloy et al., 2013) map entire energy landscape pathways connecting stable535fiS HEHU & P LAKUstates molecular loops, peptides, proteins (Porta, Thomas, Corcho, Canto, & Perez, 2007;Jaillet et al., 2011; Porta & Jaillet, 2013; Devaurs et al., 2015; Molloy et al., 2016). Othersfocused specific flexible sub-chains, loops, rather entire protein chains (Cortes et al.,2004, 2005; Yao, Dhanik, Marz, Propper, Kou, Liu, van den Bedem, Latombe, Halperin-Landsberg,& Altman, 2008; Barbe, Cortes, Simeon, Monsan, Remaud-Simeon, & Andre, 2011).Table 1: Categorization Tree- Roadmap-based Methods Application SettingApplicationProteinLoopMotionsProtein-LigandBindingTree-based MethodsRLG-RRT (Cortes et al., 2005; Cortes,Jaillet, & Simeon, 2007), ML-RRT (Barbeet al., 2011)ML-RRT (Cortes et al., 2007)Protein StructurePredictionProtein RNA(Un)FoldingFeLTr (Shehu & Olson, 2010; Molloyet al., 2013)Peptide ProteinStructuralTransitionsNMA-RRT (Kirillova et al., 2008; AlBluwi et al., 2013), PathRover (Enosh,Raveh, Furman-Schueler, Halperin, &Ben-Tal, 2008; Raveh et al., 2009), TRRT (Jaillet et al., 2011), PDST (Haspelet al., 2010), Sprint (Molloy & Shehu,2013), Multi-T-RRT (Devaurs et al., 2015)T-RRT (Jaillet et al., 2011), Multi-TRRT (Devaurs et al., 2015)Peptide Protein Energy landscape MappingRoadmap-based MethodsLoopTK (Yao et al., 2008)PCR (Singh et al., 1999; Apaydinet al., 2001), SRS (Apaydin et al.,2003)SRS (Apaydin et al., 2003), PRMFP (Amato et al., 2003; Song &Amato, 2004; Tang, Kirkpatrick,Thomas, Song, & Amato, 2005;Thomas et al., 2005, 2007; Tapiaet al., 2007; Tang et al., 2008; Tapiaet al., 2010), MaxFlux-PRM (Yang,Wu, Li, Han, & Huo, 2007; Li, Yang,Han, & Huo, 2008)SRS (Molloy et al., 2016), Spiral (Molloy & Shehu, 2016), SoPRIM (Maximova et al., 2015)SoPRIM (Maximova et al., 2015)4.1.1 ODELING P ROTEIN L OOP OTIONS P ROTEIN -L IGAND ISASSOCIATIONEarly adaptations RRT algorithm biomolecules focused modeling equilibrium dynamics protein loops (Cortes et al., 2005) protein-ligand interactions (Cortes et al., 2004).instance, method presented work Cortes et al. (2005) proceeds two stagesmodel large-amplitude structural changes protein loop equilibrium. first stage obtainsensemble collision-free conformations loop protein structure. achievedRandom Loop Generator RRT (RLG-RRT) algorithm, effectively samples loop conformation space satisfies kinematic closure constraints. loop divided activepassive part. passive part selected contain 6 variables, whereas active part containsrest angular variables selected represent loop conformation. RLG-RRT algorithm536fiC OMPUTATIONAL REATMENTS B IOMOLECULES ROBOTICS -I NSPIRED ETHODSdirectly samples values variables active part via scheme increases probabilityobtaining conformation satisfies loop closure. active part loop conformationobtained, exact 6R inverse kinematics technique applied solve passive variables loop closure constraints. Closed loop conformations added treecollision-free. tree run fixed amount time, goal region defined aroundgiven goal conformation order extract many paths one execution RLG-RRTalgorithm. Conformations extracted paths subjected short energetic minimizationsorder elucidate energetically-feasible, large-amplitude motions loop investigation.Analysis extracted loop motions work Cortes et al. (2004) reveals resultscomparable classic molecular modeling methods obtained performance gainseveral orders magnitude. work Cortes et al. (2004) demonstrates efficacy twostage approach studying activity-regulating mobility 17-residue long loop 7amylosucrase enzyme Neisseria polysaccharea.Ideas similar RLG-RRT employed LoopTK (toolkit) algorithm (Yao et al., 2008)explore closed, collision-free conformations flexible loops ranging length 5 25amino acids. algorithm relies interplay sampling deformation obtain loopssatisfy kinematic closure constraints collision-free. sampling procedure focusesobtaining geometrically-diverse, closed loops. deformation procedure based earlier relatedwork loop modeling (Lotan, van den Bedem, Deacon, & Latombe, 2004; van den Bedem, Lotan,Latombe, & Deacon, 2005). procedure makes use null space technique exploreself-motion manifold (the constrained, closure space) around closed loop resolve steric clashesviolating closure constraints. LoopTK shown efficiently handle long loops25 amino acids even generate biologically-interesting, calcium-binding conformations.toolkit available https://simtk.org/home/looptk.time demands RRT-RLG problems hundreds variables addressed Corteset al. (2007) proposing Manhattan-like RRT (ML-RRT) algorithm efficiently computepaths small protein-bound ligand exit protein active site. ML-RRT borrows ideasmechanical disassembly divides variables two groups, active passive. particular,variables model internal rigid-body motions ligand designated active,subspace active variables sampled RLG-RRT algorithm. variablesmodel internal motions amino acids protein receptors active site designatedpassive, slightly perturbed hinder motions ligand. decouplingproves effective, allows possible ensuing collisions ligand proteinaddressed domino-like scheme, illustrated Figure 8.ML-RRT shown efficiently model motions small ligands, side chains, loops,backbone (Cortes, Le, Lehl, & Simeon, 2010; Barbe et al., 2011). work Cortes et al. (2010)subjects paths extracted executions ML-RRT algorithm randomized path smoothingpost-processing technique. technique carried composite space parametersresulting simultaneous motions ligand protein final path. work Barbeet al. (2011) subjects loop conformations paths extracted ML-RRT minimizationMM energy function reveal critical, physically-realistic intermediate conformationsbottlenecks along open-to-closed loop motion Burkholderia cepacia lipase lid domain.Adaptations robot motion planning frameworks model loop structures motions represent fraction diverse methods designed loop modeling. Interested readers referredsurvey work Shehu Kavraki (2012).537fiS HEHU & P LAKUFigure 8: figure reproduced work Al-Bluwi et al. (2012). left panel illustrates disassembly planning problem two articulated objects. ML-RRT algorithm proposed work Corteset al. (2007) problem models escape ligand proteins binding site disassembly problem.red H-shaped object left image considered ligand right image, blue sticksleft image considered flexible side chains binding site receptor proteinright image. figure reproduced permission Computer Science Review Journal.4.1.2 ODELING P EPTIDE P ROTEIN TRUCTURAL RANSITIONS APPINGP EPTIDE E NERGY L ANDSCAPESRLG-RRT algorithm modified work Enosh et al. (2008) model structural transitions proteins and, particular, model open close motions potassium channels. mainmodification RLG-RRT algorithm Enosh et al. concerns addition energetic testcollision-free test performed deciding whether generated conformationadded tree. Several novel analysis techniques introduced. Clustering conductedmany paths obtained several executions algorithm order identify common intermediate conformations paths connecting given start goal conformations. Path alignmentemployed obtain energetically-favored path among computed. schematicmethod proposed Enosh et al. visualization energetically-favored pathobtained KscA protein shown Figure 9.Another extension RRT-based algorithm work Enosh et al. (2008) presentedRaveh et al. (2009); efficient PathRover algorithm proposed modeling structuraltransitions many proteins. PathRover achieves computational efficiency two main ways.First, application many proteins made possible restricting number dihedral anglesused variables. Three strategies used identify subset dihedral angles definevariable space: careful inspection structures, relevant literature, computational tools detectinghinge regions like NMA, comparison structural changes alternative (native homologue)structures. particular, FlexProt alignment algorithm (Shatsky, Nussinov, & Wolfson, 2002)used compare start goal structures reveal structurally-different regions. Variablesmanually restricted dihedral angles regions. Second, PathRover limits exploration538fiC OMPUTATIONAL REATMENTS B IOMOLECULES ROBOTICS -I NSPIRED ETHODSFigure 9: figure reproduced work Enosh et al. (2008). schematic methodshown (a). PathRover algorithm executed multiple times extract 100 plausible paths connectinggiven open closed conformations. paths clustered aligned reveal path clusterminimal energy barrier. cluster visualized KscA protein (b), shows putative threephase motion close open conformations. figure reproduced permissionBiophysical Journal.539fiS HEHU & P LAKUregions space consistent available wet-laboratory data. Branch termination criteriaemployed stop tree pulled towards regions improve agreementwet-laboratory data. integration wet-laboratory data aims circumvent known inaccuraciesmodern biomolecular energy functions.RRT-based algorithms summarized demonstrate utility RRT modelingstructural transitions proteins. particular, PathRover algorithm utilized several schemesreduce number variables order make problem modeling structural transitionstractable (Raveh et al., 2009). work Haspel et al. (2010) continued spirit via clever,reduced representations large proteins. contrast, work Simeon Cortes labs creditedintroducing RRT-based algorithms biomolecular modeling focused instead techniquesenhance sampling. Transition-RRT (T-RRT) algorithm proposed Jaillet et al. (2008)shown particularly effective regard.T-RRT bi- multi-tree variants recently proposed explore obtain comprehensive maps energy landscapes small peptides, dialanine Met-Enkephalin (Jaillet et al., 2011; Devaurs et al., 2015). main modification baseline RRT algorithmT-RRT concerns introduction acceptance criterion state transition test basedMetropolis criterion. New conformations added tree pass transition test (hencename, T-RRT). goal T-RRT steer tree towards exploration low-energy regionsorder map energy minima potential energy surface relaxing transition testneeded cross energy barriers may trap exploration particular local minimum.dynamic modification state transition test makes use reactive temperature scheme.Metropolis criterion, effective temperature effectively controls height energy barriers crossed two consecutive conformations. T-RRT, temperature increasednumber attempts pull tree towards low-energy regions reaches user-specifiedthreshold; is, number failures grow tree taken indication presenceenergy barrier, effective temperature increased order relax state transition test.soon successful edge added tree, temperature lowered pre-specifiedfactor order resume overall bias pulling tree towards local minima. effectreactive temperature scheme search balanced unexplored regions lowenergy regions variable space. Application T-RRT work Jaillet et al. (2011) showsalgorithm map entire known energy landscape dialanine peptide runexploration mode. Another setting, T-RRT used obtain paths connect discoveredminima, also shows recovered transitions known stable states dialanine strongagreement transitions known experiment affirmed simulation studies.work addresses issue limited sampling goal obtain accurate representations energy landscapes longer peptides, Met-Enkephalin (Devaurs et al., 2015).T-RRT algorithm used Devaurs et al. reveal conformation paths connectingalready-identified meta-stable states. states identified EA known Basin Hopping (BH), shown effectively sample local minima energy surfacesbiomolecules (Olson et al., 2012). work Devaurs et al., BH operates dihedral anglesprovides sample-based, discrete representation energy surface peptide. localminima clustered reveal wide basins corresponding meta-stable states.variant T-RRT algorithm, referred Multi-T-RRT, also proposed Devaurs et al.connect identified states. algorithm builds n single trees, rooted conformationrepresentative unique meta-stable state. algorithm proceeds iterations, iteration540fiC OMPUTATIONAL REATMENTS B IOMOLECULES ROBOTICS -I NSPIRED ETHODSFigure 10: figure, reproduced work Devaurs et al. (2015), graph obtained singlerun multi-T-RRT cycles projected key dihedral angles top panel. algorithm seededfour meta-stable states Met-Enkephalin peptide, drawn pink triangles, squares, circles.states capture unfolded state, folded state, two intermediates (shown bottom panel). Costsvarious paths shown table bottom panel. figure reproduced permission IEEETrans Nano BioScience 2015.randomly selecting one n trees expansion conformation q. conformationnearest q n 1 trees identified, within extension step-size,q merges two trees. Iterations continue trees merged graph. graph queriedminimum-cost paths connecting states interest. identified meta-stable statesminimum-cost paths connecting states found comparable reportedstudies employ computationally-demanding exploration strategies (Devaurs et al., 2015).representative result information extracted combination BHMulti-T-RRT shown Figure 10.One limitation readily applying T-RRT variants obtain similar, detailed characterization proteins rather short peptides dimensionality conformation space.work Jaillet et al. (2011), space dimensions due limited number dihedralangles small peptides, dialanine Met-Enkephalin. Detail, desired possiblecharacterizations short peptides, needs sacrificed order model large-scale structural transitions proteins. NMA-RRT (Kirillova et al., 2008), PDST (Haspel et al., 2010),Sprint (Molloy & Shehu, 2013) present three different algorithms make use representationsreduced detail model large-scale structural transitions proteins.Normal Mode Analysis (NMA) used obtain larger-scale moves (low-frequency modes revealed NMA conformation) (Kirillova et al., 2008). moves employedgenerate new conformations RRT framework. NMA-RRT algorithm proposed Kirillova et al. (2008) essentially conducts RRT search low-dimensional variable space541fiS HEHU & P LAKUlow-frequency modes. Since normal modes provided NMA conformationallow get local minimum represented conformation, NMA needs repeatedregularly RRT search order explore breadth conformation space.computationally demanding, application NMA-RRT limited extraction minimumcost paths connecting two conformations interest rather comprehensive map energylandscape connectivity proteins. work Kirillova et al. shows precious information extracted regarding structural transitions proteins, adenylate kinase, evenfocusing motions largely driven normal modes. complementary study minimalenergy paths adenylate kinase via NMA (Maragakis & Karplus, 2005) shows modessufficient capture structural transition open closed structures protein; known wet-lab structures found within 3.0Aof mode-based minimal energypathways (Maragakis & Karplus, 2005).recent extension NMA-RRT aims reduce computational demands algorithm.extension employs reduced representation protein chain based tripeptidesemploys NMA conformations reduced representations. reactive temperature schemeT-RRT employed broaden sampling capture large-scale motions connecting significantlydifferent structural states large proteins several hundred amino acids (Al-Bluwi et al., 2013).Employing reduced representations expanded applicability tree-based algorithmstreating large biomolecules. PDST algorithm adapted Haspel et al. (2010) modeltransition two structures interest large proteins 200 amino acids.assumption made secondary structures unfold sought transition, largelyvalid modeling domain motions proteins. assumption, backbone dihedralangles loops connecting secondary structures selected variables.work Haspel et al. (2010), bias scheme used 10% iterations steertree towards goal conformation. bias scheme employs Euclidean distancefeature vector representations conformations tree. Given conformation, correspondingfeature vector contains Euclidean distances centers mass secondary structure units.Conformations evaluated detailed coarse-grained energy function combines termsenergy function used work Shehu et al. (2009) Amber ff03 energy function.sampled conformation evaluated energy set threshold 100 kcal/molenergy start conformation, conformation subjected 20 steps steepest descentretained energy decreases threshold. rather coarse energeticconstraint, paths collected 100 runs algorithm reach goal conformationless time methods based Simulated Annealing, also reveal credible motions consistentexperimental data large, well-characterized proteins GroEL (Haspel et al., 2010).Sprint algorithm proposed Molloy Shehu (2013) uses complementary approachsimplifying search space explored paths connecting given structures medium-size proteins.Sprint addresses issue sampling high-dimensional variable spaces employing popularidea de novo structure prediction. fragment replacement technique used divideprotein chain bundles consecutive dihedral angles, values bundle fragmentsampled a-priori constructed database fragment configurations known, native proteinstructures. fragment replacement technique used expand tree every iteration.work Molloy Shehu (2013) adapts EST framework via expansionprocedure model structural transitions small- medium-size proteins, Fragment MonteCarlo Tree Exploration (FeLTr) algorithm proposed Shehu Olson (2010) uses related con542fiC OMPUTATIONAL REATMENTS B IOMOLECULES ROBOTICS -I NSPIRED ETHODScepts sample space near-native protein conformations purpose de novo structureprediction small proteins.Sprint FeLTr, state-transition test used steer tree towards low-energy conformations time; is, probabilistic, Metropolis-like criterion used determine whetherchild conformation added tree. FeLTr (Shehu & Olson, 2010) fixedscaling parameter (analogous fixed effective temperature) used Metropolis-like criterion, Sprint (Molloy & Shehu, 2013) integrates reactive temperature scheme order allowtree go high-energy regions low-energy routes found thus expandexploration capability. reactive temperature scheme Sprint slightly differentT-RRT (Jaillet et al., 2008). T-RRT effective temperature increased decreasedfixed amounts, Sprint moves temperature along proportional cooling scheme often employedSimulated Annealing Monte Carlo methods (Shehu et al., 2009). Upon failures expand tree,temperature moves next value cooling scheme; upon successes, temperature goesnext value scheme.FeLTr Sprint operationalize idea easier push rather pulltree conformation space good moves available compiled priori generateenergetically-feasible child conformations selected parent conformations tree.work Molloy Shehu (2013) tree rooted given start conformationgoal get within tolerance region given goal conformation, work ShehuOlson (2010) tree rooted extended conformation, termination criterion compromise desired number low-energy conformations running time.central idea Sprint FeLTr growth tree controlled viaselection mechanism; iteration, conformation tree selected expansion.selection penalizes tree growing towards regions conformation spaceoversampled, thus resulting enhanced sampling conformation space. Two discretizationlayers employed. FeLTr, first layer maps conformations tree 1d grid whosecells energy levels width 2 kcal/mol. Sprint, first layer maps conformations 1dgrid based lRMSD goal conformation. second layer algorithms mapsconformations geometric projection. second layer 3d grid, conformationsassociated 3 shape-based global coordinates (Shehu & Olson, 2010).selection mechanism uses discretization layers. First, selects energy level according probability distribution function. latter defined weights associated energylevels according weighting function. Different weighting functions analyzedstrong global energetic bias needs order reproduce native structure (Molloy et al.,2013). energy level selected, cells geometric projection grid belong conformations selected energy level analyzed. second weighting function cells gridbiases selecting cell selected many times and/or already many conformations it. cell selected, conformation selected expansion uniformlyrandom, since conformations cell energetically- geometrically-indistinguishable.Extensions FeLTr explored effect different weighting functionsdiscretization layers employment different projection coordinates (Molloy et al., 2013;Olson et al., 2012). Different coarse-grained energy functions considered state-of-the-artde novo structure prediction, including Rosetta suite energy functions, employedframework directly compared steer search towards near-native conformations (Molloy et al., 2013). Molloy Shehu (2013) also investigate impact different543fiS HEHU & P LAKUprojection schemes selection mechanisms diversity energetic profiles Sprintextracted paths context computing structural transitions.Applications Sprint different start goal structure pairs calmodulin adenylatekinase proteins show algorithm able find paths reach goal conformation (Molloy& Shehu, 2013). Soft global biasing schemes found provide right compromisetree depth (that is, lower energies) diversity paths (that is, geometrically-diverse conformations). Detailed energetic structural analysis computed paths two hallmark proteins,calmodulin adenylate kinase, reveals Sprint yields accurate characterizationsstructural transitions proteins. Energetic profiles extracted paths indicate presencehigh-energy regions need crossed specific transitions calmodulin, agreementwet-laboratory characterizations. Analysis adenylate kinase shows known intermediatestructures protein present conformation paths computed Sprint (Molloy &Shehu, 2013).4.2 Roadmap-Based Methods Modeling Equilibrium Biomolecular StructureDynamicsRoadmap-based methods employed model protein-ligand binding (Singh et al., 1999),protein RNA folding unfolding (Song & Amato, 2004; Chiang et al., 2007; Chiang, Hsu, &C., 2010), protein structural transitions (Molloy & Shehu, 2016; Maximova et al., 2015).4.2.1 ODELING P ROTEIN -L IGAND B INDINGadaptation roadmap-based motion planning framework protein-ligand bindingSingh et al. (1999) first occurrence robotics-inspired treatments biomolecular structuredynamics. adaptation simplistic provided key design issues replicated extended many robotics researchers. One key simplifications proteinreceptor kept rigid, variables interest allowing model rigid-bodymotions ligand around receptor internal motions ligand. Small ligandsconsidered, 6 + p variables allow modeling motions go dozen.Sampling proceeds uniformly random 6 + p variables, ligand configurations addedroadmap pass geometric energetic criterion. geometric criterion ensures ligandconfigurations within predefined distance center mass receptor.energetic criterion probabilistic: two dynamically-updated thresholds, Emin Emaxvalues, corresponding minimum maximum energy values sampled configurations,recorded. Ligand configurations energy higher Emax rejected. configurationsretained probability (Emax E(q))/(Emax Emin ). energy function incorporatesterms evaluate internal energy ligand configuration well terms evaluatinginteractions ligand configuration rigid protein receptor.Retained ligand configurations embedded nearest-neighbor graph, using lRMSD measure distance two ligand configurations user-set parameter, k, numbernearest neighbors. simple local planner interpolating p + 6 variables two neighboringconfigurations used estimate feasibility q q 0 q 0 q edges generating consecutive configurations. Consecutive configurations qi generated linear interpolation plannerconnect q q 0 distance two consecutive configurations generated series higher 1A. q q 0 q 0 q edges added roadmap qi544fiC OMPUTATIONAL REATMENTS B IOMOLECULES ROBOTICS -I NSPIRED ETHODSconfigurations energies Emax . Weights added retained edges follows:0w(q q ) =s1Xlog[P (qi qi+1 )]i=0P (qi qi+1 ) =e(Ei+1 Ei )/(KB )(e(Ei+1 Ei )/(KB ) + e(Ei1 Ei )/(KB ) )equations, qi1 , qi , qi+1 three consecutive configurations correspondingenergies Ei1 , Ei , Ei+1 , KB Boltzmann constant, effective temperature.weight path qstartqgoal , connects start configuration goal configuration,sum weights edges it. weight path initiated unbound configuration terminating bound configuration estimates association rate (the costligand approaching binding protein receptor). weight reverse path estimatesdisassociation rate (the cost ligand leaving binding site diffusing space).resulting roadmap represents distribution energetically-credible paths ligand approaching binding receptor. work Singh et al. (1999), bound configurationligand p+6 variable space presumed known, RMSD-based clusteringsampled lowest-energy ligand configurations employed reveal likely bound candidates.Analysis reveals true bound configuration indeed present top-populated clusters;however, many false positives reported, well. Weights paths terminating initiatedlowest-energy ligand configurations analyzed order determine characteristics used discriminate true false positives. Paths terminating true,bound configurations found high association rates; reverse paths foundhigh disassociation rates. important result elucidates effective bindersallow ligand reach lowest interaction energy also trap binding site viahigh-energy barriers.4.2.2 ODELING P ROTEIN RNA (U N )F OLDINGSingh et al. (1999) provided much needed template served foundation manyrobotics-inspired treatments biomolecules. particular, suite roadmap-based algorithmsextensions designed Amato lab model unfolding small proteins. reviewroadmap-based methods study molecular motions Amato lab available workTapia et al. (2010), whereas review roadmap-based methods specific protein foldingproblem presented work Moll, Schwartz, Kavraki (2008). seminal contributioncategory Probabilistic Conformation Roadmap (PCR) algorithm (Apaydin et al., 2001),builds upon template presented Singh et al. (1999) study protein folding.PCR addresses complex application domain, number variables needed modelintrinsic flexibility protein chains easily reach 100 more. PCR extensionsfollowed, notably Amato lab, variables employed subset backbonedihedral angles protein chain (Amato et al., 2003; Song & Amato, 2004; Tang et al., 2005;Thomas et al., 2005, 2007; Tapia et al., 2007; Tang et al., 2008; Tapia et al., 2010). variablespaces, uniform random sampling ineffective likely result conformations severeinternal collisions. reason, work Amato lab PCR-based algorithms gradually545fiS HEHU & P LAKUshifted sampling strategies based incremental perturbations given native/folded conformation memory folded conformation lost. Specifically, backbone dihedral anglesfolded conformation perturbed small amounts use Gaussian distributionminimum number conformations obtained category (0 100% 10% increments)percentage native contacts. lower number native contacts conformation,likely conformation belong unfolded state. acceptance criterionsampled conformations work Singh et al. (1999), energy function different,measures internal energy protein chain. function contains terms favoring hydrogenbonds, disulfide bonds, hydrophobic interactions.sampled conformations pass energetic/acceptance criterion embeddednearest-neighbor graph, number nearest neighbor conformation k specified user.contrast original PCR algorithm, directed (u, v) edges graph weighted basedE(u)E(v)Boltzmann-related Metropolis criterionas in: P(u,v) = e KB , E(.) energyconformation, KB Boltzmann constant, a-priori set temperature determiningheight energy barriers crossed edge. early formulation edge weights, reactivetemperature schemes employed later tree- roadmap-based algorithms structuraltransitions. Instead, user-controlled parameter determines great extent abilityalgorithm navigate underlying energy surface.works Song Amato (2004) Thomas et al. (2005), N best paths endfolded conformation start conformations 0 native contacts extracted analyzed.Analysis paths shown that, despite several design decisions intended simplifyprotein folding problem, PCR-based algorithms predict order secondary structure formation. Agreement wet-laboratory data validated general usage PCR-based algorithmsprovide coarse-grained treatment folding unfolding pathways protein chains.works Amato collaborators also show applicability PCR-based algorithms studyRNA folding unfolding (Tapia et al., 2007; Tang et al., 2008; Tapia et al., 2010) .sampling strategy incremental perturbations effective protein chains60 amino acids (Song & Amato, 2004) scales poorly longer chains (Thomas et al., 2005).Ensuing work improves sampling protein chains 110 amino acids reducingnumber variables modeled represent conformations (Thomas et al., 2007). Specifically, rigidity analysis employed detect least-constrained regions given structure. dihedral anglesbelonging regions selected often perturbation sampling stage. modification shown effective revealing subtle folding differences protein G twosequence variants. particular, modification also shown promising capturingdynamic events proteins beyond folding study large-scale conformational changes involvedstructural transitions calmodulin protein. Related ideas employed researchers compute temperature-dependent optimal folding paths peptides proteins (Yanget al., 2007; Li et al., 2008). MaxFlux-PRM algorithm proposed Yang et al. (2007)study structural transitions dialanine peptide folding -hairpin shown Liet al. (2008) capable predicting folding pathways engrailed homeodomain protein.work Amato lab focused exploiting conformation roadmap extractquantities summarizing folding kinetics protein RNA molecules. Tapia et al. (2007) introducetwo new analysis techniques, Map-based Master Equation (MME) Map-based MC (MMC)technique. work shows treating roadmap map folding landscape546fiC OMPUTATIONAL REATMENTS B IOMOLECULES ROBOTICS -I NSPIRED ETHODSexploited estimate kinetic metrics typically extracted MD simulation studies.Metropolis MC simulations conducted roadmap, moving roadmap verticesobserving edge probabilities roadmap. Different statistics calculatedMMC walks, including folding rates population kinetics. Tang et al. (2008) show statisticssummarizing RNA folding predict well relative gene expression rate wild-type MS2phage RNA three mutants, good agreement wet-laboratory data.4.2.3 TOCHASTIC ROADMAP IMULATION ARKOV TATE ODELS ODELINGP ROTEIN RNA (U N ) FOLDING P ROTEIN TRUCTURAL RANSITIONSidea reliable statistics extracted molecular conformation roadmaps presented earlier Latombe colleagues (Apaydin et al., 2003). stochastic roadmap simulation (SRS) framework formalized relation key analogy roadmap Markovstate model (MSM); concept stochastic roadmap probabilistic edges presentedearlier (Song & Amato, 2000), analogy MSM went missing till 2003 formalization Latombe colleagues (Apaydin et al., 2003). latter laid bare analogies stochastic roadmap would later referred point-based MSM.MSM, states MSM single-conformation vertices stochastic roadmap,probabilistically-weighted edges connecting vertices roadmap state-to-state transitionsMSM. analogy brought focus stochastic roadmap better encodes stochastic nature biomolecular motions, analogy MSM could even used extractinteresting summary statistics regarding physics-driven stochastic processes.addition recognizing biased random walks carried roadmapemployed extract statistics interest (Tapia et al., 2007), SRS-MSM analogy highlightseffective, algebra-based techniques (Markov chain) transition state theory employedextract average statistics without launching single simulation (or random walk roadmap).Folding rates, pfold values, values, estimates kinetics, transition rates,obtained without needing perform many random walks in-order propagation transitionprobabilities. analogy stochastic roadmap point-based MSM shown resultcorrectly-predicted pfold values small proteins modeled secondary structure level612 variables (Apaydin, Brutlag, Hsu, & Latombe, 2002; Apaydin et al., 2003). workdemonstrated transition state ensemble (the set conformations pfold =0.5), foldingrates, values could predicted 16 different proteins fraction computationaltime would needed framework launching numerous MC simulations (Chiang, Apaydin,Brutlag, Hsu, & Latombe, 2006; Chiang et al., 2007) .SRS-MSM analogy permits interesting mathematics, practical issuesensure transition matrix prohibitive size allow solving linear algebra equationsaddressed case-by-case basis. formalization presented Apaydin et al. (2003)discuss practical design decisions group conformations statesestimate transition probabilities two sub-ensembles, rather mathematicswould possible analogy stochastic roadmap MSM. Analogies cellbased MSMs, states homogeneous sub-ensembles conformations rather singleconformations need addressing practical issues regarding organize conformations statesassociate transition probabilities states.547fiS HEHU & P LAKUSince seminal work Apaydin et al. (2003), analogies SRS cell-based MSMslargely limited, partly due lack clear objectives design decisionsgeneral ability transform roadmap MSM manageable size. instance,fundamental assumption conformations obtained via MD simulationtemperature , probability edge representing transition vertex u vertex vcould measured via Boltzmann-related Metropolis criterion e(E(v)E(u))/(KB ) . realization allowed Apaydin, Latombe, colleagues see clear connection stochastic (probabilistic) roadmap structures point-based MSM, vertices seen statesMSM edges vertices roadmap transitions states MSM. However, practical considerations convert single conformation vertex probabilitiesstate-state transition probabilities discussed.issue associate probabilities first place conformations sampled vianon-MD algorithms also discussed. Two groups researchers started operationalizingseminal ideas presented Apaydin et al. (2003). Work Latombe colleagues focused either point-based MSMs summarizing uncovering MD-simulated dynamicssynthetic small peptides via cell-based MSMs (Chiang et al., 2007, 2010). Complementary work Shehu lab focused non-MD approaches extracting average statisticsmodel compare transitions healthy aberrant forms disease-participating, small-medium-size proteins (Molloy et al., 2016).Chiang et al. (2010) offer novel representation states individual conformations (Apaydin et al., 2003; Singhal, Snow, & Pande, 2004) even disjoint regions conformation space(Ozkan, Dill, & Bahar, 2002; Chodera, Singhal, Pande, Dill, & Swope, 2007) (as cell-basedMSMs) instead overlapping probabilistic distributions conformation space.distribution relies key recognition single conformation contain enough information uniquely mapped state leads presence hidden statesreferred Markov Dynamics Model (MDM) rather MSM (Chiang et al., 2010).MDM, emission probabilities hidden states measure probability conformation belongs state. transition emission probabilities estimated trajectoriesconformations obtained many MD simulation trajectories. principled criterion basedability model predict long-timescale kinetics allows discriminating possible MDMsselecting optimal one. MDM embedded conformations obtained MD trajectories simulating folding fast-folding villin headpiece subdomain (HP-35 NleNle) shownFigure 11. MDM presents highly-interpretable discrete kinetic model foldingsmall sub-domain, built 400 MD trajectories, 1s long. Figure 11 showsstates, 7, 12, 13, 15 18, frequently-visited states significantly influencelong-term dynamics.Molloy et al. (2016) present strategies embed conformations sampled via non-MD methodcell-based MSM. ability formulate cell-based MSM relies dense samplingconformation space interest. latter provides significantly challenging MD settingeven robotics-inspired setting. Instead, complementary work Shehu lab EAsused obtain rich ensemble local minima conformations healthy variant sequencesgiven protein (Clausen & Shehu, 2015; Clausen et al., 2015). conformations organizedstates via simple lRMSD-based clustering scheme. nearest-neighbor graph imposedstates, additional lRMSD constraint imposed connect nearby statesvia edge. assumption made transitions possible nearby states, prob548fiC OMPUTATIONAL REATMENTS B IOMOLECULES ROBOTICS -I NSPIRED ETHODSFigure 11: figure, reproduced work Chiang et al. (2010), (a) shows MSM connectingtwenty identified states villin headpiece peptide. size node MSM proportionalprobability corresponding state stationary distribution. width edge proportionaltransition probability corresponding states. States probability < 0.01 stationarydistribution, self-transitions, edges transition probability < 0.002 drawn avoid cluttering.initial conformations likely belong state 12, native conformation likelybelong state 15. (b) Representative conformations shown states 7, 12, 13, 15, 18.residues forming important helix 1 villin headpiece peptide drawn red. (c) likely statetransition sequences states 12 15 shown here. figure reproduced BioinformaticsJournals terms Creative Commons Attribution Non-Commercial License.abilities transitions estimated via Boltzmann-like probability. latter makes useconcept energy state. Several schemes employed determine energystate, ranging minimum average value energies conformations groupedstate.549fiS HEHU & P LAKUFigure 12: figure reproduced work Molloy et al. (2016). Panel (a) shows two wet-laboratorystructures representative structural states H-Ras catalytic domain. H-Ras switchestwo states regulate biological activity cell. loop regions changelocalized shown red blue. reactant (GTP) product (GDP) also drawn bindH-Ras. Panel (b) shows two-dimensional projections probed energy surface H-Ras wildtype (WT)oncogenic Q61L variant. Sampled conformations projected top two principal components(PC) obtained via Principal Component Analysis sampled conformations. color-coding followsAmber ff12SB internal energy values all-atom structure corresponding sampled conformation.minimum-cost paths obtained querying stochastic roadmap constructed sampledconformations shown, well. costs paths shown table panel (c). averagenumber edges possible paths obtained treating roadmap MSM.actual energy profiles minimum-cost paths obtained WT Q61L variant shown panel(d). figure reproduced permission Robotica 2016.result process stochastic roadmap used answer lowest-cost pathqueries, traditionally case roadmap-based methods, well yield average statistics,average number edges transition, via analogy stochastic roadmapMSM. path smoothing algorithm based conjugate peak refinement technique (Fischer &Karplus, 1992) provides detail state-state paths improves energetic profile.average statistics, direct measurements transition rates due lack timescale information non-MD methods, allow conducting comparisons wildtype (WT) variant (mutated) sequences proteins interest. work Molloy et al. (2016), statisticsemployed obtain structural explanation role specific mutations biologicalactivity two proteins implicated human disorders. Figure 12 showcases representativeresults application SRS-based approach work Molloy et al. WTQ61L variant H-Ras protein. Ras sequence mutations implicated various humancancers (Karnoub & Weinberg, 2008).550fiC OMPUTATIONAL REATMENTS B IOMOLECULES ROBOTICS -I NSPIRED ETHODSComparison energy landscapes, costs minimum-cost paths, energy profilespaths, expected number edges paths H-Ras sequence Figure 12 provides structural explanation impact Q61L mutation biological activityenzyme. mutation introduces energy barrier states, barrierincreases cost minimum cost path number expected edges transitionpaths. Taken together, results suggest Q61L mutation, preserving stabilitystates, cannot form transition state mimic, agreement wet-laboratorystudies (Gremer, Gilsbach, Ahmadian, & Wittinghofer, 2008; Gibbs, Schaber, Allard, Sigal, & Scolnick, 1988).4.2.4 DDRESSING L IMITED AMPLING ROADMAP -BASED ETHODS ODELINGP ROTEIN TRUCTURAL RANSITIONSSampling remains key issue adaptations roadmap-based methods biomolecular modeling.generally focus robotics-inspired methods demonstrating abilityreproduce experimental knowledge qualitatively even quantitatively specific systemsinvestigation, general applicability largely sacrificed. instance, roadmapbased methods applied model discrete secondary structure formation events protein foldingunfolding largely applicable model folding transition events proteins150 amino acids states sought bridged transition may farther10A away each-other. Strategies reduce number variables controldimensionality variable space important ramifications. instance, rigidity-basedtechniques base conclusions flexible regions analysis specificstructure. NMA techniques suffer similar issue, regular application NMA sampledconformations adds computational time demands algorithm. techniques makeassumptions regions participate particular transition event rulepossibility potentially complex, cooperative events. Others bundle variables togetherobtain values pre-compiled databases make similar assumptions typesstructural changes facilitate transition.Sampling remain challenge, two complementary directions explored.first direction values broad applicability specific improvements. Molloy Shehu (2016)propose community needs benchmark testing dataset baseline approachspecific improvements extensions evaluated. particular, work ignoressystem-specific insights variable sampling schemes effectiveothers instead compiles broad set variables sampling/perturbation operatorsselected via probabilistic scheme. Different schemes employed different stagesroadmap-based method based distance conformations need connectedsize biomolecule investigation. general baseline implementation showscomparable performance system-specific methods promises improvementsguarantee baseline performance broad set biomolecules problem instances. Relatedideas building concept move selector presented Gipson et al. (2013).second direction sacrifices broad applicability interest improving predictivecapability roadmap-based methods point reliable hypotheses formulated guide wet-laboratory experimentation. Maximova et al. (2015) recognize roadmap-basedmethods operate de novo setting instead exploit rich set wet-laboratory551fiS HEHU & P LAKUFigure 13: figure reproduced work Maximova et al. (2015). left panel showsschematic summarizes paths within small energetic threshold minimum-cost path connectingstructure pairs interest calmodulin. Analysis paths reveals known, wet-laboratory structuresmediate transitions interest. PDB ids mediating structures shown along paths.right panel shows successive structures minimum-cost paths found transitions calmodulinstructure PDB id 1CLL PDB id 2F3Y structure PDB id 1CLLPDB id 1NWD. Numbers indicate model number within NMR entry. figure reproducedpermission IEEE Society 2015.structures determine variable space interest. particular, SoPRIM algorithm proposedMaximova et al. subjects wet-laboratory structures different sequences protein statistical multivariate analysis determine variables represent collective motions atoms. Samplingfocuses space variables multiscaling technique converts samples all-atom structures local minima Amber ff14SB energy function. samples embeddedroadmap, distance constraints ensure edges placed neighboring samples.Edges weighted based concept minimum cost, recording energetic increases.additional contrast existing roadmap-based treatments, work Maximova et al.(2015) yields minimum-cost path connecting given start given goal structure,allows extracting additional paths similar costs. concept tours employed, basedrelated work robotics. tours allow investigate specific hypotheses regarding participation known meta-stable structures transition. set structures specified,minimum-cost tours consider subsets orders structures reported. Analysistours costs higher specific threshold minimum-cost path reveals preciousinformation regarding important function-regulation transitions several proteins, including Rascalmodulin. summary result shown Figure 13.Figure 13 extracts several energetically-credible paths representing various, equiprobableroutes transitions calmodulin open, unbound state (represented structure PDBid 1CLL) two different, closed peptide protein-bound states (represented structuresPDB id 2F3Y 1NWD). schematic summary paths Figure 13 highlightsopen-to-closed transitions calmodulin may make use calcium-bound structure(PDB id 1CFD). Indeed, paths go structure higher energetic cost. differentintermediate structure emerges analysis paths. structure (under PDB id 2K0E)also binds calcium slightly different PDB id 1CFD. succession structures shown 13 makes clear domain collapse, re-arrangement, partial unfoldinghelix links N- C-terminal domains calmodulin gradual, captured various structures NMR ensemble PDB id 2K0E. result good agreement552fiC OMPUTATIONAL REATMENTS B IOMOLECULES ROBOTICS -I NSPIRED ETHODSwet-laboratory study work Gsponer, Christodoulou, Cavalli, Bui, Richter, Dobson,Vendruscolo (2008), which, addition contributing NMR entry PDB id 2K0EProtein Data Bank, also concludes correlated motions within 2K0E Ca(2+)-CaM statedirect structural fluctuations toward complex-like substates (Gsponer et al., 2008).wet-laboratory study Gsponer et al. (2008) restricted MLCK binding CaM, resultsobtained SoPRIM algorithm (Maximova et al., 2015) suggest mechanism observed Gsponer et al. (2008) prepares CaM binding peptides (the C-terminal DomainPetunia Glutamate Decarboxylase 1NWD IQ domain 2F3Y). work Maximova et al. (2015) points general mechanism apo-to-closed/complexed dynamicscalmodulin, correlated motions within calcium-bound state direct fluctuationspopulation shift protein peptide-bound states.5. Outstanding Challenges Directions ResearchRobotics-inspired methods becoming powerful diverse algorithmic strategiesproblems address biomolecular modeling. survey focused treeand roadmap-based methods modeling protein-ligand binding, protein de novo structure prediction, protein RNA folding unfolding, structural transitions peptides proteins,energy landscape mapping, methods building related ideas efficiently map ligandmigration channel networks dynamic proteins (Lin & Song, 2011; Na & Song, 2015) evenmodel antibody aggregation processes (Hoard, Jacobson, Manavi, & Tapia, 2016).attempted provide broad deep survey robotics-inspired methods biomolecular modeling, exhaustive survey possible. particular sub-domain interface Roboticscomputational structural biology rapidly progressing, demonstrated increasing numberadaptations applications showcased survey earlier, related reviews roboticsinspired methods (Al-Bluwi et al., 2012; Gipson, Hsu, Kavraki, & Latombe, 2012). surveyshowcases, several algorithmic challenges remain. provide partial list challenges prospects future research.5.1 Problem-Specific versus General Treatmentspressing need community benchmarks. work largely drivenspecific biological systems problems interest, data-driven research often resultedspecific design decisions easily transferable systems problems.instance, key decisions reduce dimensionality variable space design compliant sampling strategies perturbation operators specific problem instance mayapplicable another problem. realization need baseline, general treatments benchmarks leading researchers towards non-specific treatments establish benchmarks baselineperformance. Better sharing problem instances, metrics, algorithms known baselineperformance also key allow researchers build existing work expedite progress.5.2 Samplinggrowing realization sampling remain central issue, despite clever reduced representations sampling strategies. community researchers adapting robot motion planning treatments biomolecular modeling successful integrating important knowledge553fiS HEHU & P LAKUbiomolecules model selection, sampling strategies, energetic evaluations, community largely remained isolated complementary work AI stochastic optimizationcontinuous, non-linear variable spaces. particular, growing body work evolutionary computation community optimization complex fitness landscapes. ideascommunity successfully employed de novo structure prediction (Shehu, 2013)mapping protein energy landscapes (Clausen & Shehu, 2015; Clausen et al., 2015; Sapin, Carr,De Jong, & Shehu, 2016). ideas also beginning incorporated robotics-inspiredtreatments biomolecular dynamics (Molloy et al., 2016). Better awareness integrationeffective practices communities dealing similarly challenging high-dimensional problems likely address issues sampling lead powerful robotics-inspired treatments.context, see great opportunity AI researchers make contributions sampling-basedtreatments biomolecular dynamics.5.3 Decorrelations Pathsparticular, applications tree- roadmap-based methods modeling structural transitionsbiomolecules, path correlation issue. Path correlations potentially skew statisticsinterest even yield incorrect conclusions structural transition. culprit treebased methods bias applied steer conformation tree goal conformation.Even multiple executions tree-based method likely result similar paths.extent, source path correlations addressed. instance, Molloy Shehu (2013)makes use additional projection layer steer tree towards under-sampled regionsconformation space. shown improve path diversity. Yet another culprit sharedtree- roadmap-based methods density sampling. instance, undersampling specificregions may lead conclusion region energetically favorable biomoleculehand. investigation needed quantify reduce path correlations robotics-inspiredmethods. direction also ripe cross-fertilization ideas different sub-communitiesAI.5.4 Injection Dynamicscommon criticism robotics-inspired methods essentially geometric treatmentsbiomolecules. extent geometric treatments accepted modeling biomolecular structure, seen inadequate modeling biomolecular dynamics. Modeling dynamicslargely seen exclusive MD simulation frameworks. somewhat colloquial simplistic characterization robotics-inspired methods, biomolecular dynamics nothingrobot motion planning. characterization overcome pointing superficialanalogies used inspire robotics researchers, deeper analogies exploitedshown impact selection models, variables, fast forward inversekinematics, effective sampling strategies. worth noting latter exclusivelydomain robotics-inspired researchers. contrary, issues effective variable selectionrepresentation, variation operators, employment operators sampling strategies,others broad interest AI researchers working optimization problems part modelingabstract, mechanical, biological systems.various places, survey highlighted robotics-inspired methods capablereproducing wet-laboratory knowledge data also providing novel findings direct554fiC OMPUTATIONAL REATMENTS B IOMOLECULES ROBOTICS -I NSPIRED ETHODSexperimentation wet laboratories. Still, valid criticism robotics-inspired methodsedges trees roadmaps provide detailed view diffusiontwo conformations connect. survey points Section 4 several challengesintegrating MD trajectories robotics-inspired framework, important community thinkways effectively. Injection ideas AI community large may prove beneficialhere. growing body work computational biophysics pointing effective frameworksbiomolecular dynamics integrate thousands short MD trajectories MSMs capturebiomolecular dynamics. Cross-fertiziliation ideas AI biophysics communitieslikely prove fruitful explicitly integrating MD robotics-inspired methods.5.5 Beyond Path Computations: Roadmaps MSMssurvey highlights Section 4, MSMs become popular computational biophysics literature organize extract statistics many, independent MD simulationsbiomolecular folding structural transitions (Jayachandran, Vishal, & Pande, 2006; Choderaet al., 2007; Noe & Fischer, 2008; Prinz, Keller, & Noe, 2011a; Noe, Doose, Daidone, Lollmann,Sauer, Chodera, & Smith, 2011; Perez-Hernandez, Paul, Giorgino, De Fabritiis, & Noe, 2013; Weber, Jack, & Pande, 2013; Deng, Dai, & Levy, 2013; Chodera & Noe, 2014; Malmstrom, Lee,Van Wart, & Amaro, 2014; Song & Zhuang, 2014; Shukla, Hernandez, Weber, & Pande, 2015).Several survey articles dedicated reviewing MSM-based treatments biomolecular dynamics (Pande, Beachamp, & Bowman, 2010; Gipson et al., 2012; Maximova et al., 2016) review MSMbased treatments biomolecular dynamics. Works Chiang et al. (2006), Chiang et al. (2007),Chiang et al. (2010), Molloy et al. (2016) provide important first step integrationMSMs analysis conformation spaces probed via robotics-inspired algorithms. Chiang et al. (2010) Molloy et al. (2016) address issues convert roadmapsMSMs, many others remain, including definition structural states, possible undersampling specific states, feedback mechanisms address undersampling, rigorous calculation transitionprobabilities. issues also contended computational biophysics community, initial treatments emerged (Singhal et al., 2004; Singhal & Pande, 2005; Prinz, Wu,Sarich, Keller, Senne, Held, Chodera, Schutte, & Noe, 2011b; Malmstrom et al., 2014; Da, Sheong,Silva, & Huang, 2014). see great opportunity AI researchers, particularlyexpertise machine learning, coordinate efforts computational biophysicists. effortsundoubtedly lead richer powerful computational treatments biomolecular dynamics.5.6 Cross-Fertilization Ideassurvey shows, work modeling biomolecular structure dynamics highly interdisciplinary, great progress achieved ideas different communities combinedintegrated computational treatments. rich set scientific questions formulated understand role biomolecular structure dynamics human biology health.questions often result exceptionally challenging computational problems necessitatesophisticated algorithmic treatments. Treatments add current knowledge biomolecularsystems chemistry, physics, biophysics likely advance modeling capabilities also make important, general contributions AI research.555fiS HEHU & P LAKUAcknowledgementsFunding work provided part National Science Foundation. work A. Shehusupported NSF-CCF1421001, NSF-ACI1440581, NSF-IIS1144106. work E. Plakusupported NSF-ACI1440581, NSF-IIS1449505, NSF-IIS1548406.ReferencesAbayagan, R., Totrov, M., & Kuznetsov, D. (1994). ICM - new method protein modelingdesign: applications docking structure prediction distorted native conformation. J Comput Chem, 15(5), 488506.Aden, J., & Wolf-Watz, M. (2007). NMR identification transient complexes critical adenylatekinase catalysis. J Amer Chem Soc, 129(45), 14003 14012.Al-Bluwi, I., Simeon, T., & Cortes, J. (2012). Motion planning algorithms molecular simulations: survey. Comput Sci Rev, 6(4), 125143.Al-Bluwi, I., Vaisset, M., Simeon, T., & Cortes, J. (2013). Modeling protein conformational transitions combination coarse-grained normal mode analysis robotics-inspired methods. BMC Struct Biol, 13(S2), Suppl 1.Amato, N. M., Bayazit, B., Dale, L., Jones, C., & Vallejo, D. (1998). OBPRM: obstacle-basedPRM 3D workspaces. Workshop Algorithm Found Robot, Vol. 86 Springer TractsAdvanced Robotics, pp. 156168. Springer.Amato, N. M., Dill, K. A., & Song, G. (2003). Using motion planning map protein foldinglandscapes analyze folding kinetics known native structures. J Comput Biol, 10(3-4),239255.Anfinsen, C. B. (1973). Principles govern folding protein chains. Science, 181(4096),223230.Apaydin, M. S., Brutlag, D. L., Guestrin, C., Hsu, D., & Latombe, J.-C. (2003). Stochastic roadmapsimulation: efficient representation algorithm analyzing molecular motion. J Comput Biol, 10(3-4), 257281.Apaydin, M. S., Brutlag, D. L., Hsu, D., & Latombe, J.-C. (2002). Stochastic conformationalroadmaps computing ensemble properties molecular motion. Workshop AlgorithmFound Robot, pp. 131147, Nice, France. IEEE.Apaydin, M. S., Singh, A. P., Brutlag, D. L., & Latombe, J.-C. (2001). Capturing molecular energylandscapes probabilistic conformational roadmaps. Intl Conf Robot Autom (ICRA),Vol. 1, pp. 932939, Seoul, Korea. IEEE.Atilgan, A., Durell, S., Jernigan, R., Demirel, M., Keskin, O., & Bahar, I. (2001). Anisotropyfluctuation dynamics proteins elastic network model. Biophys J, 80(1), 505515.Bahar, R., & Rader, A. J. (2005). Coarse-grained normal mode analysis structural biology. CurrOpinion Struct Biol, 204(5), 17.Baldwin, R. L. (1995). nature protein folding pathways: classical versus new view. JBiomol NMR, 5(2), 103109.556fiC OMPUTATIONAL REATMENTS B IOMOLECULES ROBOTICS -I NSPIRED ETHODSBarbe, S., Cortes, J., Simeon, T., Monsan, P., Remaud-Simeon, M., & Andre, I. (2011). mixedmolecular modeling-robotics approach investigate lipase large molecular motions. Proteins: Struct Funct Bioinf, 79(8), 25172529.Baron, R. (2013). Fast sampling A-to-B protein global conformational transitions: GalileoGalilei Monte Carlo anisotropic network modeling. Biophys J, 105(7), 15451546.Batcho, P., Case, D. A., & Schlick, T. (2001). Optimized particle-mesh ewald/multiple-time stepintegration molecular dynamics simulations. J Chem Phys, 115(9), 40034018.Bekris, K. E., & Kavraki, L. E. (2007). Greedy safe replanning kinodynamic constraints.Intl Conf Robot Autom (ICRA), pp. 704710, Rome, Italy. IEEE.Berman, H. M., Henrick, K., & Nakamura, H. (2003). Announcing worldwide Protein DataBank. Nat Struct Biol, 10(12), 980980.Boehr, D. D., & Wright, P. E. (2008). proteins interact?. Science, 320(5882), 14291430.Bradley, P., Misura, K. M., & Baker, D. (2005). Toward high-resolution de novo structure predictionsmall proteins. Science, 309(5742), 18681871.Brooks, B. R., Bruccoleri, R. E., Olafson, B. D., States, D. J., Swaminathan, S., & Karplus, M.(1983). CHARMM: program macromolecular energy, minimization, dynamics calculations. J Comput Chem, 4(2), 187217.Bryngelson, J. D., Onuchic, J. N., Socci, N. D., & Wolynes, P. G. (1995). Funnels, pathways,energy landscape protein folding: synthesis. Proteins: Struct Funct Genet, 21(3),167195.Bryngelson, J. D., & Wolynes, P. G. (1987). Spin glasses statistical mechanics proteinfolding. Proc Natl Acad Sci USA, 84(21), 75247528.Burgess, A. W., & Scheraga, H. A. (1975). Assessment problems associated predictionthree-dimensional structure protein amino-acid sequence. Proc Natl AcadSci USA, 72(4), 12211225.Burns, B., & Brock, O. (2007). Single-query motion planning utility-guided random trees.Intl Conf Robot Autom (ICRA), pp. 33073312, Rome, Italy. IEEE.Case, D. A., Darden, T. A., Cheatham, T. E. I., Simmerling, C. L., Wang, J., Duke, R. E., Luo, R.,Merz, K. M., Pearlman, D. A., Crowley, M., Walker, R. C., Zhang, W., Wang, B., Hayik, S.,Roitberg, A., Seabra, G., Wong, K. F., Paesani, F., Wu, X., Brozell, S., Tsui, V., Gohlke, H.,Yang, L., Tan, C., Mongan, J., et al. (2014). Amber 14. http://ambermd.org/.Chiang, T. H., Apaydin, M., Brutlag, D., Hsu, D., & Latombe, J. (2006). Predicting experimentalquantities protein folding kinetics using stochastic roadmap simulation. Res ComputMol Biol, Vol. 3909 Lecture Notes Computer Science, pp. 410424. Springers.Chiang, T. H., Apaydin, M. S., Brutlag, D. L., Hsu, D., & Latombe, J.-C. (2007). Using stochasticroadmap simulation predict experimental quantities protein folding kinetics: foldingrates phi-values. J Comput Biol, 14(5), 578593.Chiang, T. H., Hsu, D., & C., L. J. (2010). Markov dynamic models long-timescale proteinmotion. Bioinformatics, 26(12), 269277.557fiS HEHU & P LAKUChirikjian, G. S. (1993). General methods computing hyper-redundant manipulator inversekinematics. Intl Conf Intell Robot Sys (IROS), Vol. 2, pp. 10671073, Yokohama, Japan.IEEE.Chodera, J. D., & Noe, F. (2014). Markov state models biomolecular conformational dynamics.Curr Opinion Struct Biol, 25, 135144.Chodera, J. D., Singhal, N., Pande, V. S., Dill, K. A., & Swope, W. C. (2007). Automatic discoverymetastable states construction markov models macromolecular conformationaldynamics. J Chem Phys, 126(15), 155101.Choset, H., & et al. (2005). Principles Robot Motion: Theory, Algorithms, Implementations(1st edition). MIT Press, Cambridge, MA.Ciu, Q., & Bahar, I. (2005). Normal Mode Analysis: Theory Applications BiologicalChemical Systems (1st edition). CRC Press.Clausen, R., Ma, B., Nussinov, R., & Shehu, A. (2015). Mapping conformation space wildtypemutant H-Ras memetic, cellular, multiscale evolutionary algorithm. PLoSComput Biol, 11(9), e1004470.Clausen, R., & Shehu, A. (2015). data-driven evolutionary algorithm mapping multi-basinprotein energy landscapes. J Comp Biol, 22(9), 844860.Clementi, C. (2008). Coarse-grained models protein folding: Toy-models predictive tools?.Curr Opinion Struct Biol, 18(1), 1015.Coifman, R. R., Lafon, S., Lee, A. B., Maggioni, M., Nadler, B., Warner, F., & Zucker, S. W. (2005).Geometric diffusions tool harmonic analysis structure definition data: Diffusionmaps. Proc Natl Acad Sci USA, 102(21), 74267431.Cooper, A. (1984). Protein fluctuations thermodynamic uncertainty principle. Prog BiophysMol Biol, 44(3), 181214.Cortes, J., Jaillet, L., & Simeon, T. (2007). Molecular disassembly RRT-like algorithms.Intl Conf Robot Autom (ICRA), pp. 33013306, Roma, Italy.Cortes, J., Le, D. T., Lehl, R., & Simeon, T. (2010). Simulating ligand-induced conformationalchanges proteins using mechanical disassembly method. Phys Chem Chem Phys, 12(29),82688276.Cortes, J., Simeon, T.AND Remauld-Simeon, M., & Tran, V. (2004). Geometric algorithmsconformational analysis long protein loops. J Comput Chem, 25(7), 956967.Cortes, J., Simeon, T.AND de Angulo, R., Guieysse, D., Remaud-Simeon, M., & Tran, V. (2005).path planning approach computing large-amplitude motions flexible molecules. Bioinformatics, 21(S1), 116125.Craig, J. (1989). Introduction robotics: mechanics control (2nd edition). Addison-Wesley,Boston, MA.Da, L. T., Sheong, F. K., Silva, D. A., & Huang, X. (2014). Application Markov state modelssimulate long timescale dynamics biological macromolecules. Adv Exp Med Biol, 805,2966.558fiC OMPUTATIONAL REATMENTS B IOMOLECULES ROBOTICS -I NSPIRED ETHODSDalibard, S., & Laumond, J.-P. (2009). Control probabilistic diffusion motion planning.Workshop Algorithm Found Robot, Vol. 57 Springer Tracts Advanced Robotics, pp. 467481. Springer.Das, A., Gur, M., Cheng, M. H., Jo, S., Bahar, I., & Roux, B. (2014). Exploring conformational transitions biomolecular systems using simple two-state anisotropic networkmodel. PLoS Comput Biol, 10(4), e1003521.Das, P., Matysiak, S., & Clementi, C. (2005). Balancing energy entropy: minimalist modelcharacterization protein folding landscapes. Proc Natl Acad Sci USA, 102(29),1014110146.Das, P., Moll, M., Stamati, H., Kavraki, L. E., & Clementi, C. (2006). Low-dimensional free energylandscapes protein folding reactions nonlinear dimensionality reduction. Proc NatlAcad Sci USA, 103(26), 98859890.Delarue, M., & Sanejouand, Y. H. (2002). Simplified normal mode analysis conformationaltransitions DNA-dependent polymerases: elastic network model. J Mol Biol, 320(5),10111024.Deng, N.-J., Dai, W., & Levy, R. M. (2013). kinetics within unfolded state affects proteinfolding: analysis based markov state models ultra-long md trajectory. J PhysChem B, 117(42), 1278712799.Denny, J., & Amato, N. M. (2013). Toggle PRM: coordinated mapping C-free C-obstaclearbitrary dimension. Workshop Algorithm Found Robot, Vol. 86 Springer TractsAdvanced Robotics, pp. 297312. Springer.Devaurs, D., Molloy, K., Vaisset, M., Shehu, A., Cortes, J., & Simeon, T. (2015). Characterizingenergy landscapes peptides using combination stochastic algorithms. IEEE TransNanoBioScience, 14(5), 545552.Diekmann, S., & Hoischen, C. (2014). Biomolecular dynamics binding studies livingcell. Physics Life Reviews, 11(1), 130.Dill, K. A., & Chan, H. S. (1997). Levinthal pathways funnels. Nat Struct Biol, 4(1),1019.Dryga, A., Chakrabarty, S., Vicatos, S., & Warshel, A. (2011). Realistic simulation activationvoltage-gated ion channels. Proc Natl Acad Sci USA, 109(9), 33353340.Dubrow, A. (2015). got done one year NSFs Stampede supercomputer. Comput Sci Eng,17(2), 8388.Ekenna, C., Thomas, S., & Amato, N. (2016). Adaptive local learning sampling based motionplanning protein folding. BMC Syst Biol, 10(Suppl 2).Engh, R. A., & Huber, R. (1991). Accurate bond angle parameters X-ray protein structurerefinement. Acta Crystallogr, A47, 392400.Enosh, A., Raveh, B., Furman-Schueler, O., Halperin, D., & Ben-Tal, N. (2008). Generation, comparison, merging pathways protein conformations: gating K-channels. Biophys J, 95(8), 38503860.559fiS HEHU & P LAKUFattebert, J.-L., Richards, D. F., & Glosli, J. N. (2012). Dynamic load balancing algorithmmolecular dynamics based voronoi cells domain decompositions. Comput Phys Communic, 183(12), 26082615.Fenwick, R. B., van den Bedem, H., Fraser, J. S., & Wright, P. E. (2014). Integrated descriptionprotein dynamics room-temperature X-ray crystallography NMR. Proc Natl AcadSci USA, 111(4), E445E454.Fernandez-Medarde, A., & Santos, E. (2011). Ras cancer developmental diseases. GenesCancer, 2(3), 344358.Fersht, A. (2013). Profile martin karplus, michael levitt, arieh warshel, 2013 nobel laureateschemistry. Proc Natl Acad Sci USA, 110(49), 1965619657.Fersht, A. R. (1999). Structure Mechanism Protein Science. Guide Enzyme CatalysisProtein Folding (3 edition). W. H. Freeman Co., New York, NY.Feynman, R. P., Leighton, R. B., & Sands, M. (1963). Feynman Lectures Physics. AddisonWesley, Reading, MA.Fischer, S., & Karplus, M. (1992). Conjugate peak refinement: algorithm finding reactionpaths accurate transition states systems many degrees freedom. Chem PhysLett, 194(3), 252261.Fox, N., & Streinu, I. (2013). Towards accurate modeling noncovalent interactions proteinrigidity analysis. BMC Bioinf, 14(Suppl 18), S3.Gall, A., Ilioaia, C., Kruger, T. P., Novoderezhkin, V. I., Robert, B., & van Grondelle, R. (2015).Conformational switching light-harvesting protein followed single-molecule spectroscopy. Biophys J, 108(11), 27132720.Gibbs, J. B., Schaber, M. D., Allard, W. J., Sigal, I. S., & Scolnick, E. M. (1988). Purification RasGTPase activating protein bovine brain. Proc Natl Acad Sci USA, 85(14), 50265030.Gipson, B., Hsu, D., Kavraki, L. E., & Latombe, J.-C. (2012). Computational models proteinkinematics dynamics: Beyond simulation. Annu Rev Anal Chem, 5, 273291.Gipson, B., Moll, M., & Kavraki, L. E. (2013). SIMS: hybrid method rapid conformationalanalysis. PLoS One, 8(7), e68826.Gorfe, A. A., Grant, B. J., & McCammon, J. A. (2008). Mapping nucleotide isoformdependent structural dynamical features Ras proteins. Structure, 16(6), 885896.Gotz, A. W., Williamson, M. J., Xu, D., Poole, D., Le Grand, S., & Walker, R. C. (2012). Routinemicrosecond molecular dynamics simulations amber GPUs. 1. Generalized Born. JChem Theory Comput, 8(5), 15421555.Grant, B. J., Gorfe, A. A., & McCammon, J. A. (2009). Ras conformational switching: Simulatingnucleotide-dependent conformational transitions accelerated molecular dynamics. PLoSComput Biol, 5(3), e1000325.Greenleaf, W. J., Woodside, M. T., & Block, S. M. (2007). High-resolution, single-molecule measurements biomolecular motion. Annu Rev Biophys Biomol Struct, 36, 171190.Gremer, L., Gilsbach, B., Ahmadian, M. R., & Wittinghofer, A. (2008). Fluoride complexesoncogenic Ras mutants study Ras-RasGap interaction. Biol Chem, 389(9), 11631171.560fiC OMPUTATIONAL REATMENTS B IOMOLECULES ROBOTICS -I NSPIRED ETHODSGsponer, J., Christodoulou, J., Cavalli, A., Bui, J. M., Richter, B., Dobson, C. M., & Vendruscolo, M.(2008). coupled equilibrium shift mechanism calmodulin-mediated signal transduction.Structure, 16(5), 736746.Han, K. F., & Baker, D. (1996). Global properties mapping local amino acid sequencelocal structure proteins. Proc Natl Acad Sci USA, 93(12), 58145818.Han, L., & Amato, N. M. (2001). kinematics-based probabilistic roadmap method closed chainsystems. Donald, B. R., Lynch, K. M., & Rus, D. (Eds.), Algorithmic ComputationalRobotics: New Directions, pp. 233246. AK Peters, MA.Harvey, M. J., Giupponi, G., & de Fabritiis, G. (2009). ACEMD: Accelerating biomolecular dynamics microsecond timescale. J Comput Theor Chem, 5(6), 16321639.Haspel, N., Moll, M., Baker, M. L., Chiu, W., & E., K. L. (2010). Tracing conformational changesproteins. BMC Struct Biol, 10(Suppl1), S1.Haspel, N., Tsai, C., Wolfson, H., & Nussinov, R. (2003). Reducing computational complexityprotein folding via fragment folding assembly. Protein Sci, 12(6), 11771187.Hastings, W. K. (1970). Monte Carlo sampling methods using Markov chains applications.Biometrika, 57(1), 97109.Hermans, J., Berendsen, H. J. C., van Gunsteren, W. F., & Postma, J. P. M. (1984). consistentempirical potential water-protein interactions. Biopolymers, 23(8), 15131518.Hoang, T. H., Trovato, A., Seno, F., Banavar, J. R., & Maritan, A. (2007). Geometry symmetrypresculpt free-energy landscape proteins. Proc Natl Acad Sci USA, 101(21), 79607964.Hoard, B., Jacobson, B., Manavi, K., & Tapia, L. (2016). Extending rule-based methods modelmolecular geometry 3d model resolution. BMC Syst Biol, 10(Suppl 2), 48.Hoelder, S., Clarke, P. A., & Workman, P. (2012). Discovery small molecule cancer drugs:Successes, challenges opportunities. Mol Oncol, 6(2), 522524.Hohlbein, J., Craggs, T. D., & Cordes, T. (2014). Alternating-laser excitation: single-moleculeFRET beyond. Chem Soc Rev, 43(4), 11561171.Hori, N., Chikenji, G., & Takada, S. (2009). Folding energy landscape network dynamicssmall globular proteins. Proc Natl Acad Sci USA, 106(1), 7378.Hornak, V., Abel, R., Okur, A., Strockbine, B., Roitberg, A., & Simmerling, C. (2006). Comparisonmultiple amber force fields development improved protein backbone parameters.Proteins: Struct Funct Bioinf, 65(3), 712725.Hsu, D., Kindel, R., Latombe, J.-C., & Rock, S. (2002). Randomized kinodynamic motion planningmoving obstacles. Intl J Robot Res, 21(3), 233255.Hsu, D., Sanchez-Ante, G., & Sun, Z. (2005). Hybrid PRM sampling cost-sensitive adaptivestrategy. Intl Conf Robot Autom (ICRA), pp. 38853891, Barcelona, Spain.Humphrey, W., Dalke, A., & Schulten, K. (1996). VMD - Visual Molecular Dynamics. J Mol GraphModel, 14(1), 3338. http://www.ks.uiuc.edu/Research/vmd/.Jaillet, L., Corcho, F. J., Perez, J.-J., & Cortes, J. (2011). Randomized tree construction algorithmexplore energy landscapes. J Comput Chem, 32(16), 34643474.561fiS HEHU & P LAKUJaillet, L., Cortes, J., & Simeon, T. (2008). Transition-based RRT path planning continuouscost spaces. Intl Conf Intell Robot Sys (IROS), pp. 2226, Stanford, CA. IEEE/RSJ.Jaillet, L., Yershova, A., LaValle, S. M., & Simeon, T. (2005). Adaptive tuning samplingdomain dynamic-domain RRTs. Intl Conf Intell Robot Sys (IROS), pp. 40864091.IEEE/RSJ.Jayachandran, G., Vishal, V., & Pande, V. S. (2006). Using massively parallel simulation Markovian models study protein folding: examining dynamics villin headpiece. J ChemPhys, 124(16), 164902164914.Jenzler-Wildman, K., & Kern, D. (2007). Dynamic personalities proteins. Nature, 450(7172),964972.Jorgensen, W. L., Maxwell, D. S., & Tirado-Reves, J. (1988). Development testing OPLSall-atom force field conformational energetics properties organic liquids. J AmerChem Soc, 118(45), 1122511236.Kalisiak, M., & van de Panne, M. (2006). RRT-blossom: RRT local flood-fill behavior.Intl Conf Robot Autom (ICRA), pp. 12371242, Orlando, FL. IEEE.Kamerlin, S. C., Haranczyk, M., & Warshel, A. (2009). Progresses ab initio QM/MM free energysimulations electrostatic energies proteins: Accelerated QM/MM studies pka, redoxreactions solvation free energies. J Phys Chem B, 113(5), 12531272.Karam, P., Powdrill, M. H., Liu, H. W., Vasquez, C., Mah, W., Bernatchez, J., Gotte, M., & Cosa,G. (2014). Dynamics hepatitis C virus (HCV) RNA-dependent RNA polymerase NS5Bcomplex RNA. J Biol Chem, 289(20), 1439914411.Karaman, S., & Frazzoli, E. (2011). Sampling-based algorithms optimal motion planning. IntlJ Robot Res, 30(7), 846894.Karnoub, A. E., & Weinberg, R. A. (2008). Ras oncogenes: split personalities. Nat Rev Mol CellBiol, 9(7), 517531.Kavraki, L. E., Svestka, P., Latombe, J. C., & Overmars, M. H. (1996). Probabilistic roadmapspath planning high-dimensional configuration spaces. IEEE Trans Robot Automat, 12(4),566580.Kay, L. E. (1998). Protein dynamics NMR. Nat Struct Biol, 5(2-3), 513517.Kay, L. E. (2005). NMR studies protein structure dynamics. J Magn Reson, 173(2), 193207.Kendrew, J. C., Bodo, G., Dintzis, H. M., Parrish, R. G., Wyckoff, H., & Phillips, D. C. (1958).three-dimensional model myoglobin molecule obtained X-ray analysis. Nature,181(4610), 662666.Kendrew, J. C., Dickerson, R. E., Strandberg, B. E., Hart, R. G., Davies, D. R., Phillips, D. C., &Shore, V. C. (1960). Structure myoglobin: three-dimensional Fourier synthesis 2Aresolution. Nature, 185(4711), 422427.Khaliullin, R. Z., VandeVondele, J., & Hutter, J. (2013). Efficient linear-scaling density functionaltheory molecular systems. J Chem Theory Comput, 9(10), 44214427.Kiesel, S., Burns, E., & Ruml, W. (2012). Abstraction-guided sampling motion planning.Symp Combinat Search (SOCS), pp. 162163, Niagara Falls, Canada.562fiC OMPUTATIONAL REATMENTS B IOMOLECULES ROBOTICS -I NSPIRED ETHODSKim, K. M., Jernigan, R. L., & Chirikjian, G. S. (2002a). Efficient generation feasible pathwaysprotein conformational transitions. Biophys J, 83(3), 16201630.Kim, M. K., Chirikjian, G. S., & Jernigan, R. L. (2002b). Elastic models conformational transitions macromolecules. J Mol Graph Model, 21(2), 151160.Kirillova, S., Cortes, J., Stefaniu, A., & Simeon, T. (2008). NMA-guided path planning approachcomputing large-amplitude conformational changes proteins. Proteins: Struct FunctBioinf, 70(1), 131143.Kolodny, R., Guibas, L., Levitt, M., & Koehl, P. (2005). Inverse kinematics biology: proteinloop closure problem. Intl J Robot Res, 24(2-3), 151163.Ladd, A. M., & Kavraki, L. E. (2004). Fast tree-based exploration state space robots dynamics. Workshop Algorithm Found Robot, pp. 297312. Springer, Utrecht/Zeist, Netherlands.Ladd, A. M., & Kavraki, L. E. (2005). Motion planning presence drift, underactuationdiscrete system changes. Robot: Sci Sys, pp. 233241, Boston, MA.LaValle, S. M., & Kuffner, J. J. (2001). Randomized kinodynamic planning. Intl J Robot Res, 20(5),378400.Leaver-Fay, A., Tyka, M., Lewis, S. M., Lange, O. F., Thompson, J., Jacak, R., Kaufman, K., Renfrew, P. D., Smith, C. A., Sheffler, W., Davis, I. W., Cooper, S., Treuille, A., Mandell, D. J.,Richter, F., Ban, Y. E., Fleishman, S. J., Corn, J. E., Kim, D. E., Lyskov, S., Berrondo, M.,Mentzer, S., Popovi, Z., & et. al. (2011). ROSETTA3: object-oriented software suitesimulation design macromolecules. Methods Enzymol, 487, 545574.Lee, A., Streinu, I., & Brock, O. (2005). methodology efficiently sampling conformationspace molecular structures. J Phys Biol, 2(4), 108S115.Lee, H. M., M., K. S., Kim, H. M., & Suh, Y. D. (2013). Single-molecule surface-enhanced Ramanspectroscopy: perspective current status. Phys Chem Chem Phys, 15, 52765287.Lee, J., Kwon, O., Zhang, L., & Yoon, S.-E. (2014). selective retraction-based RRT plannervarious environments. IEEE Trans Robotics, 30(4), 10021011.Levitt, M., & Lifson, S. (1969). Refinement protein conformations using macromolecularenergy minimization procedure. J Mol Biol, 46(2), 269279.Levitt, M., & Warshel, A. (1975). Computer simulation protein folding. Nature, 253(5494),9496.Levy, Y., Jortner, J., & Becker, O. M. (2001). Solvent effects energy landscapes foldingkinetics polyalanine. Proc Natl Acad Sci USA, 98(5), 21882193.Li, D., Yang, H., Han, L., & Huo, S. (2008). Predicting folding pathway engrailed homeodomain probabilistic roadmap enhanced reaction-path algorithm. Biophys J, 94(5),16221629.Lifson, S., & Warshel, A. (1968). consistent force field calculation conformations, vibrational spectra enthalpies cycloalkanes n-alkane molecules. J Phys Chem, 49,51165129.563fiS HEHU & P LAKULin, T., & Song, G. (2011). Efficient mapping ligand migration channel networks dynamicproteins. Proteins: Struct Funct Bioinf, 79(8), 24752490.Lindorff-Larsen, K., Piana, S., Dror, R. O., & Shaw, D. E. (2011). fast-folding proteins fold.Science, 334(6055), 517520.Lois, G., Blawzdziewicz, J., & OHern, C. S. (2010). Protein folding rugged energy landscapes:Conformational diffusion fractal networks. Phys Rev E Stat Nonlin Soft Matter Phys, 81(5Pt 1), 051907.Lotan, I., van den Bedem, H., Deacon, A. M., & Latombe, J.-C. (2004). Computing protein structures electron density maps: mising loop problem. Erdman, M., Hsu, D., Overmars, M., & van der Stappen, F. (Eds.), Algorithmic Foundations Robotics VI, pp. 153168.Springer STAR Series.Ma, B., Kumar, S., Tsai, C., & Nussinov, R. (1999). Folding funnels binding mechanisms.Protein Eng, 12(9), 713720.Ma, J., & Karplus, M. (1997). Molecular switch signal transduction: reaction paths conformational changes ras p21. Proc Natl Acad Sci USA, 94(22), 1190511910.Maisuradze, G. G., Liwo, A., & Scheraga, H. A. (2009). Principal component analysis proteinfolding dynamics. J Mol Biol, 385(1), 312329.Malmstrom, R. D., Lee, C. T., Van Wart, A. T., & Amaro, R. E. (2014). Application moleculardynamics based Markov state models functional proteins. J Chem Theory Comput, 10(7),26482657.Manocha, D., & Canny, J. (1994). Efficient inverse kinematics general 6r manipulator. IEEETrans Robot Autom, 10(5), 648657.Manocha, D., & Zhu, Y. (1994). Kinematic manipulation molecular chains subject rigid constraints. Altman, R. B., Brutlag, D. L., Karp, P. D., Lathrop, R. H., & Searls, D. B. (Eds.),Intl Conf Intell Sys Mol Biol (ISMB), Vol. 2, pp. 285293, Stanford, CA. AAAI.Manocha, D., Zhu, Y., & Wright, W. (1995). Conformational analysis molecular chains usingnano-kinematics. Comput. Appl. Biosci., 11(1), 7186.Maragakis, P., & Karplus, M. (2005). Large amplitude conformational change proteins exploredplastic network model: adenylate kinase. J Mol Biol, 352(4), 807822.Matysiak, S., & Clementi, C. (2004). Optimal combination theory experiment characterization protein folding landscape S6: far minimalist model go?. JMol Biol, 343(8), 235248.Matysiak, S., & Clementi, C. (2006). Minimalist protein model diagnostic tool misfoldingaggregation. J Mol Biol, 363(1), 297308.Maximova, T., Moffatt, R., Ma, B., Nussinov, R., & Shehu, A. (2016). Principles overviewsampling methods modeling macromolecular structure dynamics. PLoS Comput Biol,12(4), e1004619.Maximova, T., Plaku, E., & Shehu, A. (2015). Computing transition paths multiple-basin proteinsprobabilistic roadmap algorithm guided structure data. Intl Conf BioinfBiomed (BIBM), pp. 3542, Washington, D.C. IEEE.564fiC OMPUTATIONAL REATMENTS B IOMOLECULES ROBOTICS -I NSPIRED ETHODSMcCammon, J. A., Gelin, B. R., & Karplus, M. (1977). Dynamics folded proteins. Nature,267(5612), 585590.McLachlan, A. D. (1972). mathematical procedure superimposing atomic coordinatesproteins. Acta Crystallogr A, 26(6), 656657.McMahon, T., Thomas, S., & Amato, N. M. (2015). Reachable volume RRT. Intl Conf RobotAutom (ICRA), pp. 29772984, Seattle, WA. IEEE.Metropolis, N., Rosenbluth, A. W., Rosenbluth, M. N., Teller, A. H., & Teller, E. (1953). Equationstate calculations fast computing machines. J Chem Phys, 21(6), 10871092.Miao, Y., Sinko, W., Pierce, L., Bucher, D., Walker, R. C., & McCammon, J. A. (2014). Improvedreweighting accelerated molecular dynamics simulations free energy calculation. JChem Theory Comput, 10(7), 26772689.Michalet, X., Weiss, S., & Jager, M. (2006). Single-molecule fluorescence studies protein foldingconformational dynamics. Chem Rev, 106(5), 17851813.Moerner, W. E., & Fromm, D. P. (2003). Methods single-molecule fluorescence spectroscopy.Rev Scientific Instruments, 74(8), 35973619.Moffat, K. (2003). frontiers time-resolved macromolecular crystallography: movieschirped X-ray pulses. Faraday Discuss, 122(79-88), 6577.Moll, M., Schwartz, D., & Kavraki, L. E. (2008). Roadmap methods protein folding. Zaki,M., & Bystroff, C. (Eds.), Protein Structure Prediction, Vol. 413 Methods Mol Biol, pp.219239. Springer.Molloy, K., Clausen, R., & Shehu, A. (2016). stochastic roadmap method model proteinstructural transitions. Robotica, 34(8), 17051733.Molloy, K., Saleh, S., & Shehu, A. (2013). Probabilistic search energy guidance biaseddecoy sampling ab-initio protein structure prediction. IEEE/ACM Trans Bioinf CompBiol, 10(5), 11621175.Molloy, K., & Shehu, A. (2013). Elucidating ensemble functionally-relevant transitionsprotein systems robotics-inspired method. BMC Struct Biol, 13(Suppl 1), S8.Molloy, K., & Shehu, A. (2015). Interleaving global local search protein motion computation. Harrison, R., Li, Y., & Mandoiu, I. (Eds.), LNCS: Bioinformatics ResearchApplications, Vol. 9096, pp. 175186, Norfolk, VA. Springer International Publishing.Molloy, K., & Shehu, A. (2016). general, adaptive, roadmap-based algorithm protein motioncomputation. IEEE Trans. NanoBioSci., 2(15), 158165.Mukherjee, S., & Warshel, A. (2011). Electrostatic origin mechanochemical rotary mechanism catalytic dwell F1-ATPase. Proc Natl Acad Sci USA, 108(51), 2055020555.Mukherjee, S., & Warshel, A. (2012). Realistic simulations coupling protomotiveforce mechanical rotation F0-ATPase. Proc Natl Acad Sci USA, 109(3), 1487614881.Mukherjee, S., & Warshel, A. (2013). Electrostatic origin unidirectionality walking myosinv motors. Proc Natl Acad Sci USA, 110(43), 1732617331.565fiS HEHU & P LAKUNa, H., & Song, G. (2015). Quantitative delineation breathing motions open ligand migrationchannels myoglobin mutants. Proteins: Struct Funct Bioinf, 83(4), 757770.Neudecker, P., Robustelli, P., Cavalli, A., Walsh, P., Lundstrm, P., Zarrine-Afsar, A., Sharpe, S.,Vendruscolo, M., & Kay, L. E. (2012). Structure intermediate state protein foldingaggregation. Science, 336(6079), 362366.Nevo, R., Brumfeld, V., Kapon, R., Hinterdorfer, P., & Reich, Z. (2005). Direct measurementprotein energy landscape roughness. EMBO Rep, 6(5), 482486.Nielsen, C. L., & Kavraki, L. E. (2000). two level fuzzy PRM manipulation planning. IntlConf Intell Robot Sys (IROS), Vol. 3, pp. 17161721, Takamatsu, Japan. IEEE/RSJ.Noe, F., Doose, S., Daidone, I., Lollmann, M., Sauer, M., Chodera, J. D., & Smith, J. C. (2011).Dynamical fingerprints probing individual relaxation processes biomolecular dynamicssimulations kinetic experiments. Proc Natl Acad Sci USA, 108(12), 48224827.Noe, F., & Fischer, S. (2008). Transition networks modeling kinetics conformationalchange macromolecules. Curr Opinion Struct Biol, 18(2), 154162.Olson, B., Hashmi, I., Molloy, K., & Shehu, A. (2012). Basin hopping general versatileoptimization framework characterization biological macromolecules. AdvancesAI J, 2012(674832).Olson, B., & Shehu, A. (2012). Evolutionary-inspired probabilistic search enhancing samplinglocal minima protein energy surface. Proteome Sci, 10(Suppl 1), S5.Olson, B. S., Molloy, K., Hendi, S.-F., & Shehu, A. (2012). Guiding search protein conformational space structural profiles. J Bioinf & Comput Biol, 10(3), 1242005.Onuchic, J. N., Luthey-Schulten, Z., & Wolynes, P. G. (1997). Theory protein folding: energylandscape perspective. Annu Rev Phys Chem, 48, 545600.Onuchic, J. N., & Wolynes, P. G. (2004). Theory protein folding. Curr Opinion Struct Biol, 14,7075.Ovchinnikov, V., & Karplus, M. (2012). Analysis elimination bias targeted moleculardynamics simulations conformational transitions: Application calmodulin. J Phys ChemB, 116(29), 85848603.Ozenne, V., Schneider, R., Yao, M., Huang, J. R., Salmon, L., Zweckstetter, M., Jensen, M. R., &Blackledge, M. (2012). Mapping potential energy landscape intrinsically disorderedproteins amino acid resolution. J Amer Chem Soc, 134(36), 1513815148.Ozkan, S. B., Dill, K. A., & Bahar, I. (2002). Fast-folding protein kinetics, hidden intermediates,sequential stabilization model. Protein Sci, 11(8), 19581970.Palmieri, L., & Arras, K. O. (2015). Distance metric learning RRT-based motion planningconstant-time inference. Intl Conf Robot Autom (ICRA), pp. 637643, Seattle, WA. IEEE.Pande, V. S., Beachamp, K., & Bowman, G. R. (2010). Everything wanted knowMarkov state models afraid ask. Nat Methods, 52(1), 99105.Papoian, G. A., Ulander, J., Eastwood, M. P., Luthey-Schulten, Z., & Wolynes, P. G. (2004). Waterprotein structure prediction. Proc Natl Acad Sci USA, 101(10), 33523357.566fiC OMPUTATIONAL REATMENTS B IOMOLECULES ROBOTICS -I NSPIRED ETHODSPerez-Hernandez, G., Paul, F., Giorgino, T., De Fabritiis, G., & Noe, F. (2013). Identification slowmolecular order parameters markov model construction. J Chem Phys, 139(1), 015102.Perilla, J. R., Goh, B. C., Cassidy, C. K., Liu, B., Bernardi, R. C., Rudack, T., Yu, H., Wu, Z., &Schulten, K. (2015). Molecular dynamics simulations large macromolecular complexes.Curr Opin Struct Biol, 31, 6474.Phillips, D. C. (1967). hen egg-white lysozyme molecule. Proc Natl Acad Sci USA, 57(3),483495.Phillips, J. C., Braun, R., Wang, W., Gumbart, J., Tajkhorshid, E., Villa, E., Chipot, C., Skeel, R. D.,Kale, L., & Schulten, K. (2005). Scalable molecular dynamics NAMD. J Comput Chem,26(16), 17811802.Piana, S., Lindorff-Larsen, K., Dirks, R. M., Salmon, J. K., Dror, R. O., & Shaw, D. E. (2012a).Evaluating effects cutoffs treatment long-range electrostatics protein foldingsimulations. PLoS ONE, 7(6), e39918.Piana, S., Lindorff-Larsen, K., & Shaw, D. E. (2012b). Protein folding kinetics thermodynamicsatomistic simulation. Proc Natl Acad Sci USA, 109(44), 1784517850.Plaku, E. (2015). Region-guided sampling-based tree search motion planning dynamics. IEEE Transactions Robotics, 31(3), 723735.Plaku, E., Stamati, H., Clementi, C., & Kavraki, L. E. (2007). Fast reliable analysis molecular motions using proximity relations dimensionality reduction. Proteins: Struct FunctBioinf, 67(4), 897907.Plaku, E., Kavraki, L. E., & Vardi, M. Y. (2010). Motion planning dynamics synergisticcombination layers planning. IEEE Transactions Robotics, 26(3), 469482.Ponder, J. W., & Case, D. A. (2003). Force fields protein simulations. Adv Protein Chem, 66,2785.Porta, J. M., & Jaillet, L. (2013). Exploring energy landscapes flexible molecular loops usinghigher-dimensional continuation. J Comput Chem, 34(3), 234244.Porta, J. M., Thomas, F., Corcho, F., Canto, J., & Perez, J. J. (2007). Complete maps molecularloop conformation spaces. J Comput Chem, 28(13), 21702189.Prinz, J. H., Keller, B., & Noe, F. (2011a). Probing molecular kinetics Markov models:metastable states, transition pathways spectroscopic observables. Phys Chem Chem Phys,13(38), 1691216927.Prinz, J. H., Wu, H., Sarich, M., Keller, B., Senne, M., Held, M., Chodera, J. D., Schutte, C., & Noe,F. (2011b). Markov models molecular kinetics: generation validation. J Chem Phys,134(17), 174105.Proctor, A. J., Lipscomb, T. J., Zou, A., Anderson, J. A., & Cho, S. S. (2012). Performance analysesparallel verlet neighbor list algorithm GPU-optimized MD simulations. ASE/IEEEIntl Conf Biomed Comput (BioMedCom), pp. 1419, Alexandria, VA. IEEE.Ramachandran, G. N., Ramakrishnan, C., & Sasisekharan, V. (1963). Stereochemistry polypeptide chain configurations. J Mol Biol, 7, 9599.567fiS HEHU & P LAKURaveh, B., Enosh, A., Furman-Schueler, O., & Halperin, D. (2009). Rapid sampling molecularmotions prior information constraints,. PLoS Comput Biol, 5(2), e1000295.Rodriguez, S., Thomas, S., Pearce, R., & Amato, N. (2006a). RESAMPL: Region-SensitiveAdaptive Motion Planner. Workshop Algorithm Found Robot, Vol. 47 Springer TractsAdvanced Robotics, pp. 285300. Springer, New York, NY.Rodriguez, S., Tang, X., Lien, J.-M., & Amato, N. M. (2006b). obstacle-based rapidly-exploringrandom tree. Intl Conf Robot Autom (ICRA), pp. 895900, Orlando, FL. IEEE.Rohrdanz, M. A., Zheng, W., Maggioni, M., & Clementi, C. (2011). Determination reactioncoordinates via locally scaled diffusion map. J Chem Phys, 134(12), 124116.Rose, G. D., Fleming, P. J., Banavar, J. R., & Maritan, A. (2006). backbone-based theoryprotein folding. Proc Natl Acad Sci USA, 103(45), 1662316633.Roweis, S. T., & Saul, L. K. (2000). Nonlinear dimensionality reduction locally linear embedding. Science, 290(5500), 23232326.Roy, R., Hohng, S., & Ha, T. (2008). practical guide single-molecule FRET. Nat Methods,5(6), 507516.Rychkova, A., Mukherjee, S., Bora, R. P., & Warshel, A. (2013). Simulating pulling stalledelongated peptide ribosome translocon. Proc Natl Acad Sci USA, 110(25),1019510200.Sanchez, G., & Latombe, J.-C. (2002). delaying collision checking PRM planning: Application multi-robot coordination. Intl J Robot Res, 21(1), 526.Sapin, E., Carr, D. B., De Jong, K. A., & Shehu, A. (2016). Computing energy landscape mapsstructural excursions proteins. BMC Genomics, 17(Suppl 4), 456.Schlau-Cohen, G. S., Wang, Q., Southall, J., Cogdell, R. J., & Moerner, W. E. (2013). Singlemolecule spectroscopy reveals photosynthetic LH2 complexes switch emissivestates. Proc Natl Acad Sci USA, 110(27), 1089910903.Schotte, F., Lim, M., Jackson, T. A., Smirnov, A. V., Soman, J., Olson, J. S., Phillips, G. N., Wulff,M., & Anfinrud, P. A. (2003). Watching protein functions 150-ps time-resolvedX-ray crystallography. Science, 300(5627), 19441947.Schuyler, A. d., Jernigan, R. L., Wasba, P. K., Ramakrishnan, B., & Chirikjian, G. S. (2009). Iterativecluster-NMA (icnma): tool generating conformational transitions proteins. Proteins:Struct Funct Bioinf, 74(3), 760776.Shatsky, M., Nussinov, R., & Wolfson, H. J. (2002). Flexible protein alignment hinge detection.Proteins, 48(2), 242256.Shaw, D. E., Maragakis, P., Lindorff-Larsen, K., Piana, S., Dror, R. O., Eastwood, M. P., Bank, J. A.,Jumper, J. M., Salmon, J. K., Shan, Y., & Wriggers, W. (2010). Atomic-level characterizationstructural dynamics proteins. Science, 330(6002), 341346.Shehu, A. (2009). ab-initio tree-based exploration enhance sampling low-energy proteinconformations. Robot: Sci Sys, pp. 241248, Seattle, WA, USA.Shehu, A. (2013). Probabilistic search optimization protein energy landscapes. Aluru, S.,& Singh, A. (Eds.), Handbook Computational Molecular Biology. Chapman & Hall/CRCComputer & Information Science Series.568fiC OMPUTATIONAL REATMENTS B IOMOLECULES ROBOTICS -I NSPIRED ETHODSShehu, A., Clementi, C., & Kavraki, L. E. (2006). Modeling protein conformational ensembles:missing loops equilibrium fluctuations. Proteins: Struct Funct Bioinf, 65(1), 164179.Shehu, A., Clementi, C., & Kavraki, L. E. (2007). Sampling conformation space model equilibrium fluctuations proteins. Algorithmica, 48(4), 303327.Shehu, A., & Kavraki, L. E. (2012). Modeling structures motions loops protein molecules.Entropy J, 14(2), 252290.Shehu, A., Kavraki, L. E., & Clementi, C. (2007). characterization protein native stateensembles. Biophys J, 92(5), 15031511.Shehu, A., Kavraki, L. E., & Clementi, C. (2008). Unfolding fold cyclic cysteine-rich peptides. Protein Sci, 17(3), 482493.Shehu, A., Kavraki, L. E., & Clementi, C. (2009). Multiscale characterization protein conformational ensembles. Proteins: Struct Funct Bioinf, 76(4), 837851.Shehu, A., & Olson, B. (2010). Guiding search native-like protein conformationsab-initio tree-based exploration. Intl J Robot Res, 29(8), 110611227.Shkolnik, A., Walter, M., & Tedrake, R. (2009). Reachability-guided sampling planningdifferential constraints. Intl Conf Robot Autom (ICRA), pp. 28592865.Shlens,J.(2003).tutorialprincipalcomponenthttps://www.cs.princeton.edu/picasso/mats/PCA-Tutorial-Intuition jp.pdf.analysis.Shukla, D., Hernandez, C. X., Weber, J. K., & Pande, V. S. (2015). Markov state models provideinsights dynamic modulation protein function. Acc Chem Res, 48(2), 414422.Singh, A. P., Latombe, J.-C., & Brutlag, D. L. (1999). motion planning approach flexible ligandbinding. Schneider, R., Bork, P., Brutlag, D. L., Glasgow, J. I., Mewes, H.-W., & Zimmer,R. (Eds.), Intl Conf Intell Sys Mol Biol (ISMB), Vol. 7, pp. 252261, Heidelberg, Germany.AAAI.Singhal, N., & Pande, V. S. (2005). Error analysis efficient sampling markovian state modelsmolecular dynamics. J Chem Phys, 123(20), 204909120490913.Singhal, N., Snow, C. D., & Pande, V. S. (2004). Using path sampling build better markovianstate models: Predicting folding rate mechanism tryptophan zipper beta hairpin.J Chem Phys, 121(1), 415425.Socher, E., & Imperiali, B. (2013). FRET-CAPTURE: sensitive method detectiondynamic protein interactions. Chem Biochem, 14(1), 5357.Song, G., & Amato, N. M. (2000). motion-planning approach folding: paper craftprotein folding. Tech. rep. TR00-001, Department Computer Science, Texas & University.Song, G., & Amato, N. M. (2004). motion planning approach folding: paper craftprotein folding. IEEE Trans Robot Autom, 20(1), 6071.Song, J., & Zhuang, W. (2014). Simulating peptide folding kinetic related spectra basedMarkov state model. Protein Conformational Dynamics, Vol. 805 Adv Exp Med Biol,pp. 199220. Springer.569fiS HEHU & P LAKUSoto, C. (2008). Protein misfolding neurodegeneration. JAMA Neurology, 65(2), 184189.Stadler, P. (2002). Fitness landscapes. Appl Math & Comput, 117, 187207.Stone, J. E., Phillips, J. C., Freddolino, P. L., Hardy, D. J., Trabuco, L. G., & Schulten, K. (2007).Accelerating molecular modeling applications graphics processors. J Comput Chem,28(16), 26182640.Sucan, I. A., & Kavraki, L. E. (2012). sampling-based tree planner systems complexdynamics. IEEE Trans Robotics, 28(1), 116131.Sun, Z., Hsu, D., Jiang, T., Kurniawati, H., & Reif, J. (2005). Narrow passage sampling probabilistic roadmap planners. IEEE Trans Robotics, 21(6), 11051115.Tama, F., & Sanejouand, Y. H. (2001). Conformational change proteins arising normalmode calculations. Protein Eng, 14(1), 16.Tama, F., Valle, M., Frank, J., & Brooks, C. L. (2003). Dynamic reorganization functionallyactive ribosome explored normal mode analysis cryo-electron microscopy. Proc NatlAcad Sci USA, 100(16), 93199323.Tang, X., Kirkpatrick, B., Thomas, S., Song, G., & Amato, N. (2005). Using motion planningstudy rna folding kinetics. J Comput Biol, 12(6), 862881.Tang, X., Thomas, S., Tapia, L., Giedroc, D. P., & Amato, N. (2008). Simulating rna folding kineticsapproximated energy landscapes. J Mol Biol, 381(4), 10551067.Tanner, D. E., Phillips, J. C., & Schulten, K. (2012). GPU/CPU algorithm generalizedborn/solvent-accessible surface area implicit solvent calculations. J Chem Theory Comput,8(7), 25212530.Tapia, L., Tang, X., Thomas, S., & Amato, N. (2007). Kinetics analysis methods approximatefolding landscapes. Bioinformatics, 23, i539i548.Tapia, L., Thomas, S., & Amato, N. (2010). motion planning approach studying molecularmotions. Commun Inf Sys, 10(1), 5368.Teknipar, M., & Zheng, W. (2010). Predicting order conformational changes proteinconformational transitions using interpolated elastic network model. Proteins: Struct FunctBioinf, 78(11), 24692481.Tenenbaum, J. B., de Silva, V., & Langford, J. C. (2000). global geometric framework nonlinear dimensionality reduction. Science, 290(5500), 23192323.Teodoro, M., Phillips, G. N. J., & Kavraki, L. E. (2003). Understanding protein flexibilitydimensionality reduction. J Comput Biol, 10(3-4), 617634.Thomas, S., Song, G., & Amato, N. M. (2005). Protein folding motion planning. J. Phys. Biol.,2(4), 148.Thomas, S., Tang, X., Tapia, L., & Amato, N. M. (2007). Simulating protein motions rigidityanalysis. J. Comput. Biol., 14(6), 839855.Thorpe, M. F., & Ming, L. (2004). Macromolecular flexibility. Phil. Mag., 84(13-16), 132331137.Torella, J. P., Holden, S. J., Santoso, Y., Hohlbein, J., & Kapanidis, A. N. (2011). Identifying molecular dynamics single-molecule FRET experiments burst variance analysis. Biophys J,100(6), 15681577.570fiC OMPUTATIONAL REATMENTS B IOMOLECULES ROBOTICS -I NSPIRED ETHODSTsai, C., Kumar, S., Ma, B., & Nussinov, R. (1999a). Folding funnels, binding funnels, proteinfunction. Protein Sci, 8(6), 11811190.Tsai, C., Ma, B., & Nussinov, R. (1999b). Folding binding cascades: shifts energy landscapes.Proc Natl Acad Sci USA, 96(18), 99709972.Uversky, V. N. (2009). Intrinsic disorder proteins associated neurodegenerative diseases.Protein Folding Misfolding: Neurodegenerative Diseases, Vol. 14 Focus StructuralBiology, pp. 51885238. Springer.van den Bedem, H., Lotan, I., Latombe, J.-C., & Deacon, A. M. (2005). Real-space protein-modelcompletion: inverse-kinematics approach. Acta Crystallogr, D61(1), 213.van der Maaten, L. J. P., Postma, E. O., & van den Herik, H. J. (2009). Dimensionality reduction:comparative review. J Mach Learn Res, 10(1-41), 6671.Van Der Spoel, D., Lindahl, E., Hess, B., Groenhof, G., Mark, A. E., & Berendsen, H. J. (2005).GROMACS: fast, flexible, free. J Comput Chem, 26(16), 17011718.van Gunsteren, W. F., Billeter, S. R., Eising, A. A., Hunenberger, P. H., Kruger, P., Mark, A. E.,Scott, W. R. P., & Tironi, I. G. (1996). Biomolecular simulation: gromos96 manualuser guide. http://www.gromos.net/.Verlet, L. (1967). Computer experiments classical fluids. i. thermodynamical propertiesLennard-Jones molecules. Phys Rev Lett, 159, 98103.Warshel, A. (2003). Computer simulations enzyme catalysis: Methods, progress, insights.Annu Rev Biophys Biomol Struct, 32, 425443.Warshel, A., & Levitt, M. (1976). Theoretical studies enzymatic reactions: Dielectric, electrostatic steric stabilization carbonium ion reaction lysozyme. J Mol Biol,103(2), 227249.Weber, J. K., Jack, R. L., & Pande, V. S. (2013). Emergence glass-like behavior markov statemodels protein folding dynamics. J Amer Chem Soc, 135(15), 55015504.Wells, S., Menor, S., Hespenheide, B., & Thorpe, M. F. (2005). Constrained geometric simulationdiffusive motion proteins. J Phys Biol, 2(4), 127136.Xu, D., & Zhang, Y. (2012). Ab initio protein structure assembly using continuous structure fragments optimized knowledge-based force field. Proteins: Struct Funct Bioinf, 80(7), 17151735.Yang, H., Wu, H., Li, D., Han, L., & Huo, S. (2007). Temperature-dependent probabilistic roadmapalgorithm calculating variationally optimized conformational transition pathways. J ChemTheory Comput, 3(1), 1725.Yang, L., Song, G., Carriquiry, A., & Jernigan, R. L. (2008). Close correspondence essential protein motions principal component analysis multiple HIV-1 protease structures elastic network modes. Structure, 16(2), 321330.Yang, Z., Majek, P., & Bahar, I. (2009). Allosteric transitions supramolecular systems explorednetwork models: Application chaperonin GroEL. PLoS Comput Biol, 5(4), e1000360.Yao, P., Dhanik, A., Marz, N., Propper, R., Kou, C., Liu, G., van den Bedem, H., Latombe, J. C.,Halperin-Landsberg, I., & Altman, R. B. (2008). Efficient algorithms explore conformationspaces flexible protein loops. IEEE/ACM Trans Comput Biol Bioinf, 5(4), 534545.571fiS HEHU & P LAKUZagrovic, B., Snow, C. D., Shirts, M. R., & Pande, V. S. (2002). Simulation folding smallalpha-helical protein atomistic detail using worldwide-distributed computing. J Mol Biol,323(5), 927937.Zhang, M., & Kavraki, L. E. (2002a). Finding solutions inverse kinematics problemcomputer-aided drug design. Florea, L., Walenz, B., & Hannenhalli, S. (Eds.), CurrentsComputational Molecular Biology, pp. 214215, Washington, D.C. ACM.Zhang, M., & Kavraki, L. E. (2002b). new method fast accurate derivation molecularconformations. Chem Inf Comput Sci, 42(1), 6470.Zhao, G., Perilla, J. R., Yufenyuy, E. L., Meng, X., Chen, B., Ning, J., Ahn, J., Gronenborn, A. M.,Schulten, K., Aiken, C., & Zhang, P. (2013). Mature HIV-1 capsid structure cryo-electronmicroscopy all-atom molecular dynamics. Nature, 497(7451), 643646.Zheng, W., & Brooks, B. (2005). Identification dynamical correlations within myosin motordomain normal mode analysis elastic network model. J Mol Biol, 346(3), 745759.Zheng, W., Brooks, B. R., & Hummer, G. (2007). Protein conformational transitions exploredmixed elastic network models. Proteins: Struct Funct Bioinf, 69(1), 4357.Zheng, W., & Doniach, S. (2003). comparative study motor-protein motions using simpleelastic-network model. Proc Natl Acad Sci USA, 100(23), 1325313258.Zheng, W., Rohrdanz, M. A., & Clementi, C. (2013). Rapid exploration configuration spacediffusion-map-directed molecular dynamics. J Phys Chem B, 117(42), 1276912776.Zheng, W., Rohrdanz, M. A., Maggioni, M., & Clementi, C. (2011). Polymer reversal rate calculatedvia locally scaled diffusion map. J Chem Phys, 134(14), 144109.Zhou, H. (2014). Theoretical frameworks multiscale modeling simulation. Curr OpinionStruct Biol, 25, 6776.572fiJournal Artificial Intelligence Research 57 (2016) 307343Submitted 07/15; published 10/16Scrubbing Learning Real-time Heuristic SearchNathan R. Sturtevantsturtevant@cs.du.eduDepartment Computer ScienceUniversity DenverDenver, Colorado, USAVadim Bulitkobulitko@ualberta.caDepartment Computing ScienceUniversity AlbertaEdmonton, Alberta, T6G 2E8, CanadaAbstractReal-time agent-centered heuristic search well-studied problem agentreason locally world must travel goal location using bounded computation memory step. Many algorithms proposed problemtheoretical results also derived worst-case performance simpleexamples demonstrating worst-case performance practice. Lower bounds, however,widely studied. paper study best-case performance generallyderive theoretical lower bounds reaching goal using LRTA*, canonical examplereal-time agent-centered heuristic search algorithm. results show that, givenreasonable restrictions state space heuristic function, number stepsLRTA*-like algorithm requires reach goal grow asymptotically fasterstate space, resulting scrubbing agent repeatedly visits state.show asymptotic analysis hold complex realtime search algorithms, experimental results suggest still descriptive practicalperformance.1. Introductionframework real-time agent-centered heuristic search models agent locallylimited sensing perception trying reach goal interleaving planningmovement (Koenig, 2001). well-studied problem led numerous algorithms (Korf,1990; Furcy & Koenig, 2000; Shimbo & Ishida, 2003; Hernandez & Meseguer, 2005; Bulitko& Lee, 2006; Hernandez & Baier, 2012) various theoretical analysis (Ishida & Korf,1991; Koenig & Simmons, 1993; Koenig, Tovey, & Smirnov, 2003; Bulitko & Lee, 2006;Bulitko & Bulitko, 2009; Sturtevant, Bulitko, & Bjornsson, 2010).Given broad work problem, surprising find little workdone lower bounds. clear examples agent travel directlygoal state optimal path. examples, however, generally require unreasonably accurate initial heuristic favorable domain-specific tie-breaking schemahard guarantee practice. examples (Koenig & Simmons, 1993; Edelkamp &Schrodl, 2012) show worst-case bound tight, examples generallycharacterize worst-case best-case performance coincide.main contribution paper non-trivial lower bound travel distancerequired agent reach goal basic real-time heuristic search framework.c2016AI Access Foundation. rights reserved.fiSturtevant & Bulitkoshow theoretically exists tie-breaking schema forces agent revisitstates (scrub) polynomially growing state spaces; undesirable propertyreal-time heuristic search. result shows phenomenon unavoidableagent limited 1-step lookahead, state space polynomial, edges unit costs,initial heuristic consistent integer valued. later show liftinglookahead unit edge cost restrictions allows agent cases travel directlystart goal. However, counter examples somewhat contrived and,empirical results demonstrate, appear happen frequently practice.open question whether similar theoretical results derived fewer restrictionsagent state space. also examine exponential state spaces learningmultiple trials convergence. insights theoretical work also provideexplanations several approaches taken recent literature effective.paper extended version previously published symposium paper (Sturtevant & Bulitko, 2014). original paper contained proof asymptotic state revisitation assumptions 1-step lookahead, polynomial state spaces, unit edge costs,integer initial heuristics, non-optimal tie-breaking. journal paper adds counterexamples exponential state spaces, larger lookahead, spaces non-unit edge costsand/or non-integer initial heuristic. Convergence travel also analyzed, new experimental results different tie-breaking rules added. Finally, include additionaldiscussion around issues.rest paper organized follows. begin Section 2 formally definingproblem hand. review related work problem Section 3.theoretical analysis presented Section 4. discuss applicabilitytheory broader class state spaces algorithms Section 5 build concretecounter-examples. theoretical results supported brief empirical evaluationSection 6. conclude paper outline directions future work.2. Problem Formulationpaper use common definition real-time heuristic search problem.define search problem n-tuple (S, E, s0 , sg , h) finite state statesE finite set edges them. E jointly define searchgraph undirected: a, b [(a, b) E = (b, a) E]. Two states bimmediate neighbors iff edge them: (a, b) E; denote setimmediate neighbors state N (s). path P sequence states (s0 , s1 , . . . , sn ){0, . . . , n 1}, (si , si+1 ) E. route R simple pathinclude duplicate states. Initially assume edge costs 1 (Assumption 1).times {0, 1, . . . } agent occupies single state st S. state s0start state given part problem. agent change current state,is, move immediately neighboring state N (s). traversal incurs travelcost c(st , st+1 ). agent said solve search problem earliest timearrives goal state: sT = sg . solution path P = (s0 , . . . , sT ): sequencestates visited agent start state goal state.cumulative cost edges solution travel cost primaryperformance metric concerned paper. cost shortest possible308fiScrubbing Learning Real-time Heuristic Searchpath states a, b denoted h (a, b). abbreviate h (s, sg ) h (s).agent access heuristic h : [0, ). heuristic function part searchproblem specification meant give agent estimate remaining costgo. heuristic integer-valued (Assumption 2). search agent modifyheuristic sees fit long remains admissible [h(s) h (s)], consistent a, b[|h(a) h(b)| h (a, b)] integer-valued times. (Admissibility consistencyassumed throughout paper.) heuristic time denoted ht ; h0 = h.total magnitude updates heuristic function performed agent= 0 = called total learning amount.Algorithm 1: Basic Real-time Heuristic Searchinput : search problem (S, E, s0 , sg , h), tie-breaking schemaoutput: path (s0 , s1 , . . . , sT ), sT = sg1 t02 ht h3 st 6= sg4st+1 arg mins0 N (st ) (1 + ht (s0 ))5ht+1 (st ) 1 + ht (st+1 )6tt+17Numerous heuristic search algorithms developed problem described(e.g., Korf, 1990; Bulitko & Lee, 2006; Koenig & Sun, 2009).based Algorithm 1. search agent following algorithm begins start states0 repeatedly loops process choosing next state updatingheuristic reaches goal state sg first time (line 3). Within loop,line 4 agent first computes immediate neighbor minimizes estimatedcost going neighbor (always 1 now) plus estimated cost goingneighbor goal. lookahead 1 thus immediate neighbors (i.e.,N (st )) considered agent (Assumption 3). Ties among neighborsminimal heuristic values broken tie-breaking schema provide(Assumption 4), detailed later paper, sufficiently suboptimal proveresults. Then, line 5, agent updates (or learns) heuristic current statemaking consistent heuristic neighbor picked previous line.agent changes current state neighbor (i.e., makes move). generalproblem allows heuristic decrease, algorithm never decrease heuristicvalue state, since heuristic always consistent.problem consider paper describe minimum amount Tmin (S)travel cost search agent type described would necessarily incurfinding solution = (S, E, s0 , sg , h). exact value Tmin (S) intricatelydepend particulars specific search problem S, derive useful asymptoticlower bound Tmin (S). concerned systematic scrubbing:agent said scrub systematically series growing state spaces iff numberstate visits asymptotically dominates number states space: Tmin (S) (|S|).309fiSturtevant & BulitkoFormally, consider series seach problems {S1 , S2 , . . . S2 , . . . } progressively increasingstate spaces: |Si | = g(i) (e.g., |Si | = i2 open two-dimensional grid Si cells).agent scrubs systematically iff travel time lower-bounded functionTmin (Si ) = f (i) asymptotically dominates state space size: f (g). usestandard definition asymptotic dominance: f (n) (g(n)) iff k > 0n0 n >n0 [kg(n) f (n)]. Since functions positive, omit absolute value.initially work assumption agent trying reachgoal (Assumption 5), measure first-trial travel, workconsidered convergence travel. convergence travel agent teleported backstart state reaching goal, beginning new trial, updated heuristic.agents learning converged trial result updatesheuristic function (Bulitko & Lee, 2006). systematic tie-breaking schema used,convergence entails agent follow path goal subsequenttrials. First-trial travel trivially lower bound convergence travel; discussconnection detail later paper.3. Related WorkPrevious work focused deriving upper bounds agents travel cost. instance, LRTA* (Algorithm 1) guaranteed reach goal O(|S|2 ) steps (Ishida &Korf, 1991). follows analysis MTS (Ishida & Korf, 1991) targetsposition fixed. Examples provided show exact bound, |S|2 /2|S|/2,tight (Edelkamp & Schrodl, 2012).1 analysis extended class reinforcement learning algorithms, LRTA* special case (Koenig & Simmons, 1992,1993, 1996). state-based value-iteration algorithms, search algorithm listedabove, upper bound still O(|S|2 ).also substantial work analyzing algorithms backtracking moves,introduced SLA* (Shue & Zamani, 1993a, 1993b) general SLA*T (Shue,Li, & Zamani, 2001; Zamani & Shue, 2001). algorithms behave wayalgorithm total learning exceeds certain threshold . agentbacktracks previous state whenever raises heuristic value. shown BulitkoLee (2006) travel cost SLA*T upper bounded h (s0 , sg ) +threshold (learning quota). However, upper bound holds pathbuilt SLA*T processed every move state revisits removed it.problem-specific analysis minimum learning required prove optimal pathdescribed Sturtevant et al. (2010) consider first-trial performance. provided proof sketch agents lookahead farther convergeoptimal solution quickly. Empirical results suggested algorithms lookfarther ahead better convergence performance primarily perform lesslearning minimum required.1. chapter containing results authored Koenig.310fiScrubbing Learning Real-time Heuristic Search4. Analysisgoal paper derive non-trivial asymptotic lower-bound amounttravel search agent uses Algorithm 1 need perform reach goal state.achieve goal stages. Section 4.1 illustrates tie-breaking influencebest- worst-case performance, using two simple examples. present high-leveloverview derivation Section 4.2 detail individual steps Sections 4.34.6. apply analysis case polynomially growing state spacesSection 4.9 discuss implications state revisits (i.e., scrubbing). resultsrequire assumptions (1-5). presentation completed, Section 5discuss extensions work state spaces non-unit edge costs larger lookahead.Appendix consider exponential state spaces.4.1 IntuitionConsider five-state grid world Figure 1. goal state 5 far right.agent starts state 2. state agent examines heuristics immediateneighbors, left right, goes neighbor lowest heuristic.neighbors heuristic values identical then, time being, assume tiesbroken neighbor right. favorable fortunate tie-breaking ruleexample moves agent towards goal heuristic sufficientitself. tie-breaking schema breaks ties away goal, example,would unfavorable unfortunate. example temporarily break Assumption 4agent unfortunate tie breaking. use several variations problemillustrate importance tie-breaking solution travel cost.Figure 1: one-dimensional grid world five states numbered top. agentlocated state 2 two available actions shown figure.Figure 2 plot initial heuristic values state ten-state versiongrid, goal far right agent starts far left. initialheuristic values shown dark bars, learned updates heuristic lightbars stacked top. plate shows single time step. agents current positionindicated A. reaching time step 4, agent continue straightgoal without heuristic updates. Due fortunate tie-breaking schemaparticular example, total amount learning (i.e., total area light bars) 8travel cost 9. Scaling example 2k states, total amount learning2(k 1) path produced optimal cost 2k 1, state revisits.Thus, total learning example grows linearly state space sizesystematic scrubbing observed (i.e., Tmin (S) 6 (|S|)).However, tie breaking adversely affect agents performance, generalguidance available state space allow favorable tie-breaking. Consider searchproblem Figure 3 13 states. example, tie broken away goal311fiSturtevant & BulitkoTime = 0Time = 1Time = 2Time = 3Time = 4Figure 2: Heuristic learning favorable tie breaking. ten states problemalong horizontal axis. vertical axis shows value heuristicfunction per time step. darker bars initial heuristic values.lighter bars increases due learning. initial heuristic top.agents current state shown A.(i.e., left). travel cost 20 total amount learning 18 indicatingrevisits 13 states agent, time steps 3, 7, 9. Scalingsearch problem, total amount learning asymptotically quadratic numberstates. amount heuristic learning per move 2 means travelcost also asymptotically quadratic number states number revisitsper state increase state space size. Thus, Tmin (S) (|S|) |S|2 (|S|)systematic scrubbing. difference two cases asymptoticallysignificant. favorable tie-breaking achieved specific examples, cannotalways guaranteed general.4.2 Analysis Overviewgoal quantify travel required agent type described Section 2find solution. examples previous section demonstrated travelcost depend tie-breaking schema used agent. Since may alwayspossible design favorable tie-breaking schema given problem (or seriesproblems), consider agents performance sufficiently suboptimal tie-breakingschemas (Assumption 4) develop meaningful lower bound amount travel.lower bound asymptotic number states and, unfortunately, demonstratescommon conditions agent necessarily revisit states many timesundesirable phenomenon known scrubbing real-time heuristic search.present high-level argument immediately detail step individually subsequent sections. First, due consistency heuristic boundedlookahead, learning performed step constant-bounded. Thus, asymptoticlower bound learning required reach goal also asymptotic lower boundtravel distance (Section 4.3). show sufficiently suboptimal tie breakingschema agent traveling sa sb must raise heuristic sa least312fiScrubbing Learning Real-time Heuristic SearchTime = 1Time = 0Time = 6Time = 10Time = 11Time = 12Time = 7Time = 9Time = 8Time = 5Time = 4Time = 3Time = 2Time = 13Figure 3: Heuristic learning unfortunate tie breaking.sb (Section 4.4). Given search graph, current location, goal, identify lowerbound maximum heuristic value h agent must encounter travelinggoal (Section 4.5). Since heuristic consistent times use h computeminimum amount learning (Section 4.6).apply argument polynomial state spaces number stateswithin distance r given state grows (rd ) (e.g., quadratically commonly usedtwo-dimensional navigation maps = 2).2 spaces show that, givenappropriately inaccurate initial heuristic, amount learning necessarily performedagent grow (rd+1 ) asymptotically dominates number states (rd ).Since learning per step constant-bounded, amount travel also asymptoticallydominate number states. result indicates real-time heuristic searchagent type introduced necessarily scrub systematically (Corollary 2).4.3 Learning per Step Constant Boundedprovide bound learning required solve problem first timecumulative updates heuristic function = 0 = . sectionbegin showing learning per step constant-bounded. implylower bound learning also lower bound movement.2. use standard definition bounded below: f (n) (g(n)) iff k1 > 0k2 >0n0 n > n0 [k1 g(n) f (n) k2 g(n)], bounded below: f (n) (g(n)) iff k > 0n0 n >n0 [kg(n) f (n)] bounded above: f (n) O(g(n)) iff g(n) (f (n)).313fiSturtevant & BulitkoLemma 1 total change heuristic values learning step Algorithm 1constant bounded independently number states state space.Proof. Algorithm 1 updates heuristic state st line 5 pseudo code basedheuristic neighboring state st+1 . st+1 immediate neighbor stheuristic consistent, |ht (st ) ht (st+1 )| h (st , st+1 ) = 1. definition,new heuristic st 1 + ht (st+1 ). Thus, heuristic st increase 2.Since st state heuristic updated, maximum change heuristicvalues time step 2, constant bounded. 2measure learning necessary move different locations world.4.4 Maintaining Non-increasing Heuristic Slopesection prove exists tie-breaking schema, , forcesagent maintain non-increasing heuristic values states along route, callnon-increasing heuristic slope property. better worse tie-breaking schemesmay exist specific problems, sufficiently suboptimal prove main result.defined earlier, agents route simple path start state s0current state st loops removed. instance, time = 5 agenttraversed path P = (s0 , A, B, A, C, D) route R = (s0 , A, C, D). heuristicprofile vector heuristic values along route. heuristic profile alongroute {4, 3, 2, 2}, non-increasing property holds. heuristic profile {2, 3, 4, 3},non-increasing properly hold.construct tie-breaking schema whenever non-increasing propertyviolated raising heuristic current state, agent forced backtrack,removing offending state route. illustrate, consider Figure 3. time step5 agent raises heuristic current state violates non-increasing property(the new, larger heuristic value shown time step 6). agent therefore backtracks,making move left, removes offending state route.reaching state time step 8 agent move forward satisfyingproperty.ht+1htst1stst1sts0Figure 4: Raising h(st ) h(st1 ) allows tie-breaking schema force agentbacktrack.314fiScrubbing Learning Real-time Heuristic SearchLemma 2 (Forced Backtracking) Consider agent non-goal state st time t.current route R = (s0 , . . . , st1 , st ). exists tie-breaking schemaupdating heuristic st ht (st ) ht+1 (st ), updated value raisesheuristic profile ceases non-increasing, agent backtrackprevious state st1 :ht+1 (st1 ) < ht+1 (st ) = st+1 = st1 .(1)Proof. First, agent moved st1 st , must hold ht (st1 ) = 1 + ht (st ),due line 5 Algorithm 1. shown left side Figure 4. Due consistent,integer-valued heuristic unit edge costs, way heuristic increasingalong route learning ht+1 (st ) = ht (st1 ) + 1, shown right sideFigure 4. case, update must come state s0 N (st )state lowest heuristic among st neighbors (Figure 4) ht (s0 ) = ht (st1 ). Evens0 st1 , heuristic value. Thus, tie-breaking schemaable break ties towards st1 , making agent backtrack st st1maintaining non-increasing heuristic. tie-breaking schema . 2Since backtracking removes offending state agents route,following corollary.Corollary 1 (Heuristic Slope) time search, exists tie-breakingschema heuristic along agents route R = (r1 , . . . , rn ) non-increasing:ht (r1 ) ht (r2 ) ht (rn ).(2)Proof. prove claim induction route length n. n = 1 inequality (2)trivially holds. Suppose holds route length n (n + 1)th stateadded route, Lemma 2 must hold heuristic added stateless equal heuristic routes previous end (otherwise agent wouldbacktrack route would grow). 24.5 Lower Bound Maximum Heuristic EncounteredAssume time agent added state sb route. means, accordingCorollary 1, ht (sa ) ht (sb ) state sa already route. Informally,agent passes state high heuristic, must first raise previous statesroute least equally high heuristics. Since heuristic values Algorithm 1 neverdecrease learning (due consistency), also means ht (sa ) h0 (sb )implies agent must already raised heuristic sa least h0 (sb )h0 (sa ),assuming term positive. interested identifying states particularproblem maximize difference h0 (sb ) h0 (sa ), used boundlearning. section show find states. particular, sb statelargest heuristic agent must encounter en route goal. Informally,providing general definition local minima proving agent mustlearn way local minima increasing heuristic values.Figure 5 illustrates concept pathfinding video-game map. Supposeagent state sa trying reach state sg . observe agent must pass315fiSturtevant & Bulitkoone states within bottleneck C1 reaching goal. Similarly,agent must also pass one states C2 reaching goal.C1sgC3C4saC2Figure 5: two-dimensional pathfinding search problem goal state labeled sgstart state labeled sa . C1 , C2 , C3 C4 cut sets.say set states C cut set respect states sa sg iff sa/ C,sg/ C possible routes R = (sa , ..., sg ) non-empty intersection C.Figure 5 sets C1 , C2 C3 C4 three different cut sets respect sasg . Given two states sa sg , denote set cut sets C(sa , sg ). ThusC1 C(sa , sg ), C2 C(sa , sg ) (C3 C4 ) C(sa , sg ).use notion cut sets derive lower bound maximum heuristic valueseen agent en route goal. map Figure 5, assuming standardstraight-line heuristic, C1 best cut set initial heuristic valuesstates relatively small. C2 better initial heuristic values larger.C3 C4 even better cut set largest minimum initial heuristic valuesamong C1 , C2 , C3 C4 .general, find best lower bound considering cut sets choosingone maximal minimal initial heuristic:h(sa , sg ) =maxmin h0 (s)CC(sa ,sg ) sC(3)definition definition cut set follows agent necessarilytravel state h0 (s) h(sa , sg ). Thus, h(sa , sg ) useful lowerbound maximum heuristic encountered along route sa sg .316fiScrubbing Learning Real-time Heuristic Searchh(s0 , sg )hh0sgs0Figure 6: illustration , h h(s0 , sg ).Note state sa arbitrary state S. Thus, R(S) set statesroute generated agent solving problem define:hh = max h(s, sg ) h0 (s)(4)sR(S)h= arg max h(s, sg ) h0 (s) .(5)sR(S)several states h maximized, set them.follows state agents route goal whose heuristic valueraised least h :h hT (s ) h0 (s ).(6)Figure 6 illustrates heuristic profile simple one-dimensional state spaceevery state start state s0 goal state sg forms single-state cutset. Hence, h(s0 , sg ) highest initial heuristic agents route. Thus,heuristic states left peak raised least h(s0 , sg ).maximum amount learning, h , happens state .states along route R(S) may known priori, R(S) must containinitial state s0 which, given (4), means that:h h(s0 , sg ) h0 (s0 ).(7)Furthermore, often possible identify state R(S) yields lower boundh higher h(s0 , sg ) h0 (s0 ). illustrate: h shown Figure 6 strictlygreater h(s0 , sg ) h0 (s0 ). practical example, shown Figure 8, octiledistance h0 eight-connected grid leads h(s0 , sg ) h0 (s0 ) = 0. But, practice,agent move corner first, allowing us identify different state .analyze example detail Section 4.8.4.6 Minimum Learning Minimum Travel Required Overallestablished exists state along agents route goal whoseheuristic agent necessarily raise least h . Per Lemma 1, amountlearning per move constant-bounded, number visits state (h ).317fiSturtevant & BulitkoConsistency heuristic allows us derive even stronger lower bounds totalamount learning travel cost. Indeed, raising heuristic h impliesheuristic values many states raised well, contributing totalamount learning, travel state re-visits.Specifically, since time {0, . . . , } heuristic ht consistent, heuristicvalue state n upper lower bounded respect arbitrary stateS, according distance it:ht (m) h (m, n) ht (n) ht (m) + h (m, n).(8)Thus, agent reaches goal time , heuristic state statespace lower-bounded according distance :n [hT (n) hT (s ) h (s , n)] .(9)initial heuristic consistent hence upper-bounded:n [h0 (n) h0 (s ) + h (s , n)] .(10)state n S, difference left sides (9) (10) least largedifference right sides:hT (n) h0 (n) hT (s ) 2h (s , n) h0 (s )which, due (6), becomes:h 2h (s , n)(11)sum right side (11) states n and, since heuristic value decreaseslearning, derive following lower bound total amount learning:Lmin (S)Xmax{0, h 2h (s , n)}.(12)nSillustrated Figure 7 consistency heuristic determines diamondaround h . area diamond right side inequality (12). amountlearning per move constant bounded (Section 4.3) also derive lower boundamount travel:Tmin (S) (Lmin (S)) .(13)Note one-dimensional example non-increasing heuristic slope propertyallows derive even higher lower bound necessary amount learning. Specifically, time agent reaches goal sg , heuristic values left peakraised least level dotted line. filled-in volume clearlygreater area diamond figure. indicates possible directionfuture work finding lower bound aggressive one inequality (12)use rest paper.318fiScrubbing Learning Real-time Heuristic Searchhh0sgs0Figure 7: lower bound Lmin determined , h .4.7 General Conditions Systematic ScrubbingRecall definition scrubbing number state visits asymptoticallydominates number states space: Tmin (S) (|S|). Thus, one way establishsystematic scrubbing series search problems compute or, least, estimatesum Equation 12 show asymptotically dominates number states |S|.Together link Tmin Lmin given Equation 13, would establishsystematic scrubbing.Generally speaking, sum may depend intricately search problem structureinitial heuristic. Thus, proceed analyzing two special cases.4.8 Special Case: Corner Mapcannot make general statements single problem instances, instead parameterize problem instances size, allowing us describe scale mapsize grows. case measure size radius length one edgemap. Consider series search problems known corner map (Figure 8).s0n=5sgFigure 8: corner map analyzed Sturtevant et al. (2010).map parameterized n: problem instance Sn n > 3 |Sn | O(n2 )states. two-dimensional grid agent occupy vacant cell (whitefigure). agent move four cardinal neighbors unless blockedobstacle (dark grey cells figure), edges unit cost, assumeManhattan distance initial heuristic h0 . Later paper revisit examplediagonal, non-unit-cost moves octile distance heuristic.319fiSturtevant & Bulitkoagent starts corner created obstacles, corner state .Using analysis previous sections, h Equation 3 value n + 1two states labeled figure. Correspondingly, state defined Equation 5also shown figure initial heuristic value 4 (for n); raisedh goal state reached. Thus, h = n + 1 4 = n 3. lower boundLmin (Inequality 12) becomes:XLmin (Sn )max{0, n 3 2h (s , s)}.(14)sSnLooking structure corner, re-write right side (14) summing= h (s , s) multiplying number states value h (s , s).one state (s ) h (s , s) = 0, two states h (s , s) = 1, + 1 statesh (s , s) = i. odd values n, re-write sum (14) as:3n3Lmin (Sn )2X(i + 1)(n 3 2i) =i=0(n 3)(n 1)(n + 1).24(15)(n 2)(n 1)n.24(16)even values n result is:n4Lmin (Sn )2X(i + 1)(n 3 2i) =i=0either case, sum, function n, class (n3 ) puts learningamount Lmin (n3 ). amount learning per move constant bounded, Tmin(n3 ). number states two-dimensional n n corner map O(n2 )asymptotically dominated Tmin proving agent scrub systematically{S1 , S2 , . . . }.Specific properties corner maps allowed us derive complexity classsum (12) well total number states map. following sectionanalyze broader class search spaces.4.9 Special Case: Locally Isotropic Polynomial State Spaceslower bounds amount learning (12) total travel (13) hold searchproblem S. However, bounds explicitly reference number statesthus immediately allow us correlate amount travel number statesorder make claim state revisitation. investigate ways computingnumber states (r, S, E) precisely distance r away state :(r, S, E) = |{s | h (s, ) = r}|.(17)Generally speaking, (r, S, E) depends topology search graph (S, E)arbitrarily complex. However, state space isotropic around state3. still lower-bound example considering full path goalheuristic values raised h(s). analysis assumes first stateheuristic raised.320fiScrubbing Learning Real-time Heuristic Searchnumber states distance r away depend directiondescribed simply (r). term isotropic usually used refer entirestate space; use term locally isotropic refer states spaces isotropicregion within radius r .sum inequality (12) alternatively computed integralshortest distance r state states:XZmax{0, h 2h (s , n)} =h2(r)(h 2r)dr.(18)0nSsimplify computation integral (18) polynomial state spacesextend distance least h /2; is, locally isotropic.state spaces(r) = rd1(19)r [0, h /2]. instance, two-dimensional navigational maps also locallyisotropic least radius h /2 around state , degree polynomial = 2(r) = r21 = r, r [0, h /2]. Note theoretical abstractionstates real-life maps (e.g., Figure 5) always locally isotropic; mapsasymmetric structure may stretch far enough around . Also, maypolynomial obstacles may non-uniformly reduce number available statesdistance r away state.Substituting (r) = rd1 (18), get:Zh2(r)(h 2r)dr =0h2Zrd1 (h 2r)dr =0Zh0h2rd1Zdr 2h2rd1 rdr =0fi hfi hh fifir= 22 d+1 fifir= 2r fir fid+1r=0r=0h h2h d+12d+12d+1(h )(h )d+1d2d(d + 1)2d11(h )d+12d + 1(h )d+12d d(d + 1)====((h )d+1 ), h .(20)Combining (12), (18) (20) conclude locally isotropic polynomial spacesdimension extend distance least h /2 around state , minimum321fiSturtevant & Bulitkoamount total learning lower-bounded as:Lmin (S) (h )d+1 , h .(21)amount learning per step constant-bounded, asymptotic lower boundapplies travel cost:Tmin (S) (h )d+1 , h .(22)Note assumptions, number states within radius r stategrows as:Z rZ rxd1 dx (rd ), r .(23)(x)dx =00Now, consider infinite series growing search problems {S1 , S2 , . . . }. Supposesearch problem Si corresponding state space Si locally isotropicpolynomial radius ri around corresponding state . Assume also degreepolynomial 1 radii search problems monotonicallyunboundedly increase i:r1 < r2 < . . .(24)ri .(25)(23), follows state space size asymptotically lower-bounded rid :|Si | (rid ), .(26)Suppose also state space Si asymptotically upper-bounded rid well:|Si | O(rid ), .(27)Further, suppose initial heuristic search problem Si correspondingh grows linearly ri . Finally suppose local isotropicity expands far enough: ri h /2. Together two conditions are:h /2 ri h(28)1/2 fixed constant.Corollary 2 (Systematic Scrubbing). Given assumptions equations 24-28,real-time heuristic search algorithm fits basic framework formulated earlierpaper (Assumptions 1-5) necessarily scrub systematically.Proof. state space radius ri increases, h problem Si increaselinearly due (28). minimum amount travel Tmin asymptotically growspolynomial degree + 1:Tmin (Si ) d+1,i(29)hTmin (Si ) rid+1 ,(30)322fiScrubbing Learning Real-time Heuristic Searchdue (22), (25) linear relation h Si radius ri (28).time, number states state space asymptotically growpolynomial degree radius:|Si | (rid ),(31)due (26) (27). Combining (30) (31) get necessary amount travelassymptotically dominates state space size:Tmin (Si ) (|Si |),(32)agent scrub systematically. 24.10 Discussioninformally summarize results thus far, shown systematicallymeasure heuristic learning must performed single state lookingmaximum heuristic difference encountered state goal.assumptions total learning required around state asymptotically dominatesnumber states state space. Since learning per step constant-bounded, agentsforced scrub.analysis, general form (Section 4.9), based several importantassumptions. First, assume conservative tie-breaking rule prefers re-visit statesexploring new ones. Second, assume state space locally isotropic around. Third, assume that, general problems, heuristic error growing proportionalradius state space. Finally, assume agent 1-step lookahead,edges unit cost, heuristic values integer valued.consider assumptions detail. First, experimental resultsexplore several tie-breaking rules, well aggressive tie-breaking prefersmove larger g-costs small g-costs. results show that, bettertie-breaking rule improve best-case performance, also large impactworst-case performance.Second, definition systematic scrubbing holds problem totallearning (20) grows asymptotically faster state space (23). provedmust occur polynomial state spaces locally isotropic around ; wouldinteresting future work develop broader range models property.Experimental results provided giving evidence occur practice.Third, heuristic error (h ) series growing state spaces constant,scrubbing behavior guaranteed proofs. requires highly accurateheuristic cannot assumed general. interesting open questionheuristic error grows different classes problems, whether linear, logarithmic,function size radius state space. analysis clearly domainproblem dependent, even heuristic consistently underestimates 10%locations locally isotropic, perfect others, analysis holds (Corollary 2).Finally, address larger lookahead non-unit edge heuristic costs Section 5.323fiSturtevant & Bulitko4.11 Special Case: Exponential State Spacescommon real-time agents traverse exponential state spaces, placeanalysis exponential state spaces Appendix A. techniques used showsystematic scrubbing polynomial spaces locally isotropic insufficientexponential spaces locally isotropic. However, also proofsystematic scrubbing absent. Thus, analysis needed make conclusivestatement scrubbing exponential state spaces.5. Generalizing Theoryfar, proven systematic scrubbing (Corollary 2) holds basic agentdesign simple state space. section investigate extentresult generalizable. independently relax Assumptions 1 & 2 (unit edge costsinteger heuristic values) Assumption 3 (one-step lookahead) showing, counterexamples, Corollary 2 directly generalize. counter-examplescontrast experimental results suggest scrubbing occur practice.open problem succinctly describe conditions asymptotic scrubbingcomplicated scenarios.Relaxing single trial assumption (Assumption 5), however, shows scrubbingexpected learning convergence.5.1 Non-unit Edge Costs Non-Integer Initial Heuristicssection address whether Corollary 2 generalizes search problems non-unitedge costs and/or heuristic values. particular, relax assumption unit edge costs(Assumption 1), replacing assumption constant-bounded edge costs. alsorelax assumption integer heuristic values (Assumption 2).provide set counter-examples systematic scrubbing: specifically constructedsearch problems agent running LRTA* move region low heuristicvalues higher heuristic values without maintaining non-increasing heuristic slope,key assumption previous proofs.0cs01cs12cs21cs30s4Figure 9: Example chain states n = 2.Consider chain 2n + 1 states, illustrated Figure 9 n = 2,{s0 , s1 , s2 , . . . , sn , . . . , s2n } s0 start state s2n goal. Suppose initialheuristic values monotonically increasing along chain state sn (h(s1 ) < h(s2 ) <. . . h(sn )), monotonically decreasing afterwards. Let h(i) = n h(i) = 2ni> n. set growing state spaces well defined n > 0 and, c = 1, meetsconditions Corollary 2. Thus, example cause previously described agentscrub.2s-21.01s-11.00324s01.01s11.01s21.02s31.02s41.01.0ns2n1.0n-1s2n+fiScrubbing Learning Real-time Heuristic SearchHowever, allow heuristic values non-integer edge costsnon-unit scenarios exists agent climb heuristic grade withoutscrubbing. instance, change edge costs c = 1.5 instead 1.0, getbehavior shown Figure 10. agent starts state 0; heuristic stateupdated 2.5 edge cost (1.5) plus h-cost neighbor (1.0).agent moves state 1. Notice heuristic left (2.5 state 0)slightly larger heuristic right (2.0 state 2). learning, heuristicstate 1 updated 3.5, agent continues state 2. last step shown here,agent begin follow gradient goal state 4. Thus, edge costsagent choice move start goal without scrubbing.4444333322221110011.511.521.531.50401.511.521.531.50401.511.521.531.50401.511.521.531.54Figure 10: agent climbs heuristic grade without scrubbing.intuition formalized chain 2n states follows:Lemma 3 Consider chain states {s0 , s1 , s2 , . . . , s2n } s0 starting states2n goal. Suppose initial heuristic values monotonically increasingalong chain intermediate state sn : h(s1 ) < h(s2 ) < . . . h(sn ) formingheuristic grade n states. Assume sn heuristic monotonically decreasing.Suppose heuristic grade constant slope {0, . . . , 2n 1} [|h(si ) h(si+1 )| = ]edge costs uniform {0, . . . , 2n 1} [c(si , si+1 ) = c]. slope strictlyedge cost c agent lookahead 1 climb grade state nwithout scrubbing, regardless tie-breaking schema, reach goal (n)steps.Proof. proof induction state number k. show wheneveragent state 0 k n 1 set heuristic sk greaterheuristic sk+2 (i.e., hnew (sk ) > h(sk+2 )) move state sk+1 . callslope-edge property: slope growing slower edges causes agent climbslope without backtracking.Base case: k = 0. agent increase h(s0 ) h(s1 ) + c move s1choice. Starting c > derive:c >(33)hnew (s0 ) h(s1 ) > h(s2 ) h(s1 )(34)hnew (s0 ) > h(s2 ).(35)proves slope-edge property k = 0.Inductive step. Suppose slope-edge property holds k = j, j n 3.follows agent state sj+1 hnew (sj ) > h(sj+2 ).325fiSturtevant & Bulitkoimmediately conclude agent make next move sj+2 . moveset hnew (sj+1 ) min {hnew (sj ) + c, h(sj+2 ) + c} = h(sj+2 ) + c. Since h(sj+3 ) = h(sj+2 ) +c > , conclude hnew (sj+1 ) > h(sj+3 ) makes slope-edge propertyhold k = j + 1.agent reaches state n, heuristic monotonically decreasing towardsgoal, agent follow slope downward reaching goal. 2lemma hinges interplay c. interplay satisfiedeither non-unit edge costs non-integer valued initial heuristic. example usesc = 1.5 = 1.0, lemma holds c = 1.0 = 0.5, well manyvalues c .4.0 4.5 5.0 5.5 6.0 7.0 8.0 9.04.0 4.5 5.0 5.5 6.08.0 9.03.06.5 7.5 8.53.08.0 7.5 8.52.06.0 7.0 8.02.07.5 7.0 8.01.05.5 6.5 7.51.07.0 6.5 7.5G6.0 7.0G6.5 6.0 7.0Figure 11: agent climbs heuristic grade without scrubbing (intermediate steps omitted).situation happen practice, illustrated Figure 11. stateagent marked state goal marked G. states labeledinitial heuristic value. Diagonal edges cost 1.5 heuristic octile distance,shortest path obstacles diagonal cardinal movementsallowed. real-time heuristic search agent lookahead 1 walk alongwall heuristic increases = 0.5 per step edge costs alongagents path 1. result, agent walk directly local heuristicminimum continue goal, traversing shortest path scrubbing.example, however, somewhat fragile. extend map downward, agentlonger necessarily walk directly goal. illustrate Figure 12.case agent begins walking upwards before, reaches diagonal lineshown right side figure, heuristic longer changes 0.5 per step.slope-edge property longer maintained, agent longer moveheuristic slope. point agent four choices move next (shownfour gray cells figure) and, unfavorable tie breaking backtrack. Runningexample shows that, particular case, typical scrubbing behavior follows.5.2 Larger Lookaheadsection show equipping agent larger lookahead, breaking Assumption 3, style LSS-LRTA* (Koenig & Sun, 2009) eliminate systematic scrubbingeven search problem unit edge costs.326fiScrubbing Learning Real-time Heuristic Search6.0 6.5 7.0 7.5 8.0 8.5 9.0 9.56.0 6.5 7.0 7.5 8.0 8.5 9.0 9.55.07.5 8.5 9.55.08.5 9.57.0 8.0 9.04.08.5 8.0 9.03.06.5 7.5 8.53.08.0 7.5 8.52.06.0 7.0 8.02.07.5 7.0 8.01.05.5 6.5 7.51.07.0 6.5 7.5G6.0 7.0G6.5 6.0 7.04.0= 1.0= 0.5Figure 12: agent cannot climb heuristic grade without scrubbing.First, redefine agent algorithm allow larger lookahead Algorithm 1Algorithm 2. terminology A* algorithm works follows: long goalreached (line 3) agent expands search space current state st .expansion carried via OPEN set seeded current statemoment time contains states generated expanded. expandstate means generate neighbors. neighbors placed OPEN set unlessalready CLOSED set (line 9). CLOSED set contains statesexpanded (line 8). States OPEN set expanded orderminimum f = g + h cost, g-cost distance agents current state st(line 7). number expansions per step l, algorithm parameter (line 10).expansion process finished agent updates heuristic value statesCLOSED list (line 12). call states local learning space. changescurrent state promising state OPEN list (line 13). lines 12 13use different cost function, cLS (s, s0 ). cost shortest paths0 using states inside OPEN CLOSED.provide example set problems where, using larger lookahead, agentwalk directly local minima follow optimal path goal withoutscrubbing. Similar example Section 5.1, heuristic barrier created behindagent drives forward precludes backtracking/scrubbing. exampleFigure 13. example edge costs 1. state marked currentheuristic value, states labeled (b) (n). state agent markedlower left corner. agent lookahead l = 5.first row, agent gray states local learning space.darker/red states indicate OPEN list, used basis updating heuristicvalues; agent also move one states learning. matter tiesbroken (in f -cost metric used ordering state expansions), five stateslocal learning space; gray states must expanded. But, state (h)lower heuristic state (b), agent necessarily moves state (h). Upon reaching state(h) space process repeats, except higher heuristic values. process shownsimilar manner past examples Figure 14.327fiSturtevant & BulitkoAlgorithm 2: Real-time Heuristic Search Lookaheadinput : search problem (S, E, s0 , sg , h), lookahead loutput: path (s0 , s1 , . . . , sT ), sT = sg1 t02 ht h3 st 6= sg4OPEN {st }5CLOSED6repeat7n best state OPEN8CLOSED CLOSED {n}9OPEN OPEN (N (n) \ CLOSED)10OPEN = |CLOSED| = l11state CLOSED12ht+1 (s) 0 min (cLS (s, s0 ) + ht (s0 ))OPEN13st+1 arg14tt+115min (cLS (st , s0 ) + ht (s0 ))s0 OPEN(b)(c)(d)(e)(f)(g)(h)(i)(j)(k)(l)(m)(n)654345567789967887656778996788910 1098 A7899Figure 13: agent climbs heuristic grade without scrubbing.11111110101099988877766655544433322121011.021.031.041.051.061.071.081.091.0101.0111.0121.0101311.021.031.041.051.061.071.081.091.0101.0111.0121.001311.021.031.041.051.061.071.081.0Figure 14: agent climbs heuristic grade without scrubbing.32891.0101.0111.0121.013fi01.0s011.0s121.011.00Real-time Heuristic SearchsScrubbings3 Learnings42example generalized two ways: first value lookahead (l),second arbitrary long sequences states. given problem instance, however, maygeneralize different lookahead start state. build example showslookahead l = 3 build arbitrarily long sequences states lookaheadagent traverse without scrubbing, reaching goal |S| steps.2s-21.01s-11.001.0s011.0s111.0s221.0s321.01.0n1.0s2n+1s2ns4n-11.01.00s2n+nFigure 15: General example l = 3.Lemma 4 Consider chain states {s2 , s1 , s0 , . . . , s3n } s0 starting states3n = s2n+n goal. heuristic state si < 0. heuristicstate si di/2e 0 2n. heuristic state si 3n > 2n shownFigure 15. agent lookahead 3 climb heuristic grade state 2n withoutscrubbing, regardless tie-breaking schema, reach goal 3n steps.Proof. prove inductively showing invariant heuristic valuestwo neighbors side agent. invariant hold agent reachesstate s2n , agent walk directly goal. invariantcurrent state heuristic v, neighbors current state heuristicvalue v + 1, next neighbor right value v + 1, next neighborleft value v + 2. Furthermore, along path agent never backtracksleft, stopping learn even states s0 , s2 , s4 , . . . , s2n .Base case: agent starts s0 heuristic 0. definition, states s1 s1heuristics 1, state s2 heuristic 1, state s2 value 2.learning, h(s1 ) = 3, h(s0 ) = 3 h(s1 ) = 2. agent thus moves state s2heuristic 1. States s1 , s3 , s4 heuristic 2, s0 heuristic 3. agentmoved right thus far, even-numbered state, invariant holdsagents new location.Previously unvisitedv+2si-21.0v+1si-11.0vsi1.0v+1si+11.0v+1si+21.0v+2si+31.0v+2si+4Figure 16: Current heuristic values induction step.Inductive step. current state graph beginning induction stepshown Figure 16. assume invariant holds current agent state siheuristic v = di/2e i/2 since even invariant. states329fiSturtevant & Bulitkosi+1 , si+2 , si+3 , si+4 yet visited included learning, heuristic valuesv + 1, v + 1, v + 2, v + 2 respectively. follows initial heuristic valuesfact even. Furthermore, according invariant, states si1 si+1heuristics v + 1, state si+2 heuristic v + 1, state si2 valuev + 2.learning, h(si1 ) = v + 3, h(si ) = v + 3 h(si+1 ) = v + 2. agentmust move si+2 heuristic v + 1, meets even state condition. h(si+1 )updated v + 2 h(si ) v + 3. States si+3 si+4 yet visitedpart local learning space, still original heuristic values.particular, since even, heuristic value d(i + 3)/2e d(i + 4)/2erespectively, equal. Thus h(si+3 ) = v + 2 h(si+4 ) = v + 2. invariantstill holds, generalizing example.remaining question happens agent reaches state s2n . pointheuristic values left agent higher rightdecrease directly edge cost reach zero. Thus, agent always prefermove right reaches goal. agent never backtracks moves directlystate s0 s3n , thus reaching goal 3n steps. 2example fixed, odd-valued lookahead. structure wellunderstood, difficult construct similar examples odd-valued lookaheads.lookahead even, additional state one neighbor needed next statevisited agent (i.e., single new state connected state s2i ). extra statenever visited, dead end, essentially reduces lookahead one,reducing back odd-value case lookahead.5.3 Discussionexamples presented require particular starting conditions brokenslightly changing properties starting state, agent lookahead,heuristic slope. Thus, examples confirm that, assumptions, agentscan, certain circumstances, reach goal without scrubbing, guaranteehappen practice wide range real-world problem instances (Section 6).may always priori clear parameters LSS-LRTA* style agent needsuse avoid scrubbing particular problem, propose several general approachescombat scrubbing. work removing one assumptions usedtheoretical analysis.first approach learn faster, trying violate bound constant learningper step. several ways this. Algorithms f -LRTA* (Sturtevant& Bulitko, 2011) LSS-LRTA* swamps (Sharon, Sturtevant, & Felner, 2013)prune states state space, effectively raising heuristics infinity singlestep. second approach use better tie-breaking rule. Hernandez Baier (2012)developed tie-breaking rules work well grid worlds, small fractionproblems result poor performance. FALCONS also learns g-costs bettertie-breaking (Furcy & Koenig, 2000).third approach decrease h decrease size local minimaagent must escape. use 0 initial heuristic local minima,330fiScrubbing Learning Real-time Heuristic Searchresulting h = 0 rendering theoretical analysis paper inapplicable,agent would guidance would wander aimlessly. better approachmultiply heuristic constant 0 < < 1, reducing magnitude h .contrast raising initial heuristic multiplicatively attempt reduce heuristicerror (Shimbo & Ishida, 2003). latter method equivalent putting weightg-cost introduced real-time heuristic search Bulitko (2004)equivalence proven Bulitko Lee (2006). question perform weightingrecently revisited Rivera, Baier, Hernandez (2015).Finally, could avoid value-iteration based heuristic search approach altogether,using algorithms RIBS (Sturtevant et al., 2010) EDA* (Sharon, Felner, &Sturtevant, 2014).5.4 Convergence Travelresults derived thus far apply travel first-trial. one runs Algorithm 1Algorithm 2 repeatedly, preserving learning using start goal,heuristic values eventually converge true distance goal alongleast one optimal path start goal (breaking Assumption 5) (Bulitko & Lee,2006). thus build general bound learning required convergence.start, derive analogous result Lemma 1, showing learning per stepconstant-bounded using larger lookahead.Lemma 5 Assuming constant-bounded edge costs, constant-bounded branching factor,constant-bounded lookahead, total change heuristic values learning step Algorithm 2 constant bounded.Proof. Algorithm 2 updates heuristic state closed list line 12pseudo code based heuristic state s0 open list distances0 . number states closed list constant bounded constantbounded lookahead, l. shortest path (cLS ) state open liststate s0 closed list bounded maximum edge cost times l timesbranching factor. three values constants, shortest path constantbounded. Additionally, change heuristic constant bounded due consistency.Thus, change heuristic state closed list also constant bounded. Puttogether, total change heuristic values states CLOSED also constantbounded. 2Previously, used cut set analysis determine minimum learning requiredstate state space. Here, bypass analysis look optimalheuristic must learned least one optimal path start goal.Let P (s0 , sg ) set optimal paths start goal, let Pioptimal path requires minimumith path. define Plearning - is, smallest difference initial final heuristicconvergence. Then, define alternate versions h convergence.331fiSturtevant & BulitkoP= argh ==min(max [h (s, sg )Pi P (s0 ,sG ) sPimax [h (s, sg ) h0 (s)]sParg max [h (s, sg ) h0 (s)] .sPh0 (s)])(36)(37)(38)definition, h depends error perfect heuristicinitial heuristic fact algorithm converges perfect heuristic onepath. depend tie-breaking, lookahead, edge costs environment.order make connection Lmin Tminbelow, do, however, assumeedge costs constant bounded ensure learning per step also constantbounded. Thus, provide convergence form Equation 12:Lmin (S)Xmax{0, h 2h (s , n)}.(39)nSalso show convergence travel bounded convergencelearning:Tmin(S) (Lmin (S)) .(40)Thus, series polynomial state spaces h grows map radius,systematic scrubbing necessarily occur convergence travel.Corollary 3 (Systematic Scrubbing Convergence). Consider series searchproblems {S1 , S2 , . . . } locally isotropic polynomial state spaces {S1 , S2 , . . . }dimension (i.e., number states radius r given state rd1 ). statespace Si radius ri = max h (a, b). Suppose initial heuristic search problem Sia,bSiheuristic error h ri positive constant. Also, suppose heuristicstate space Si extends least h /2 around state . real-time heuristicsearch algorithm runs convergence necessarily scrub systematically.Proof. state space radius ri increases, heuristic error h increaseleast ri . minimum amount travel Tminasymptotically grow least rid+1(Equation 22 holds trivially h well h given grow ri ).time, number states state space (|Si |) asymptotically grow(S ) (|S |) thus agentfaster rid (follows (23)). means Tminscrub systematically. 2Note analyzed influence number trials performedagent. leave analysis future work.332fiScrubbing Learning Real-time Heuristic Search6. Experimental Resultsgoal paper investigate conditions scrubbing occur. showed,certain assumptions, that, given heuristic learning h required state , agentmust perform asymptotically least d+1moves (Tmin ) solve problem polynomialhstate spaces dimension d. h linear radius r state space |S|(rd ) Tmin (S) (|S|) systematic scrubbing occur.experimental section paper focus primarily elements agentconstruction, lookahead tie-breaking rules, also relax assumptionunit edge costs. address questions whether h linear radiuswhether |S| (rd ) general.initial proof required unfavorable tie-breaking rule, first set experiments explore happens vary tie-breaking rule scale sizestate space, showing scrubbing still occurs practice. initial proof alsogeneralize relaxed unit-cost 1-step lookahead assumptions. So,second experiment relax assumptions measure performance game maps,showing scrubbing occurs practice.validate results practical value theoretical claims,implemented version LSS-LRTA* uses essentially opposite tie-breaking ruleused proofs. particular, learns g-costs like FALCONS (Furcy & Koenig,2000) f -LRTA* (Sturtevant & Bulitko, 2011), breaks ties moving towardsstate maximum g-cost. call algorithm gLSS-LRTA*. theoretical tiebreaking rule conservative, choosing move back towards start state (towards statesminimum g-cost) possible. gLSS-LRTA* aggressive, moving awaystart state possible.Evidence elsewhere (Sturtevant, 2012) suggests game mapstwo dimensional. conclude, look maze maps taken moving AI repository,estimated one-dimensional (Sturtevant, 2012). repeat experimentsmaps showing scrubbing also occurring.6.1 Experiments Corner MapConsider corner map used earlier paper (Figure 8). example containscorner-shaped wall start s0 upper left corner goal sg behindwall bottom right corner. consider map 8-connected; diagonalmovement costs 1.5. octile distance heuristic mislead agent travelingstate labeled (Equation (5)) trying reach goal.tie-breaking schema constructed earlier paper, final heuristicvalue state, hT (s ), raised least h(s , sg ) = h0 (s), based statesmarked figure. map h(s , sg ) = h0 (s) = n n number cellsalong side map. case hT (s ) n.recording hT (s ) h(s , sg ) = hT (s ) n see different tie-breakingschema compare . Specifically, measurement hT (s ) n < 0 indicatesagent less learning state would . measurementhT (s ) n indicates least much learning performed required .333fi50510Max DifferenceAverage DifferenceMin Difference20406080100Heuristic Diff. (hT(s)-h0())Heuristic Diff. (hT(s)-h0())Sturtevant & Bulitko0204060gLSS(1)gLSS(10)8020Corner Length/Width (n)406080100Corner Length/Width (n)(a)(b)106400+2.7x2.5LSS-LRTA*(1)106Dist TraveledDist TraveledFigure 17: Values hT (s ) n recorded running LSS-LRTA* gLSS-LRTA*corner maps different sizes.10410410310100Max Learning ()Dist Traveled110400+0.3x2.55LSS-LRTA*(10)5110100Max Learning ()400+0.03x2.65LSS-LRTA*(100)105104103110100Max Learning ()Figure 18: Distance traveled versus maximum learning state solving probleminstance using LSS-LRTA* lookahead depths (l) 1 (top left), 10 (topright) 100 (bottom).long hT (s ) n remains constant map radius grows, scrubbingoccurring. follows analysis Section 4.8 - subtracting constant Equation(14) change asymptotic complexity result.334fiScrubbing Learning Real-time Heuristic Searchvalue n {10, 11, . . . , 100} (i.e., nn map (n2 ) states), ran 20 trialsLRTA* lookahead 1 random tie breaking (instead ). also experimentedfixed tie-breaking (chosen deterministically operator orderings internal datastructures) got similar results. average value, maximum value minimum valuehT (s ) n 20 trials function n plotted Figure 17(a). Analyzingunderlying data, find LRTA* randomized tie-breaking performed less nlearning 18% trials. is, 18% data points fall zero line.used linear regression fit line max min values different segmentsdata test growing. Beyond low values n, min max differencesseem grow significantly problem size increases. Thus, concludescrubbing occurring experiments.Figure 17(b) look performance gLSS-LRTA* corner maplookahead 1 10. lookahead 1, gLSS-LRTA* exhibits scrubbingbehavior LSS-LRTA* radius map scales. However, lookahead10, gLLS-LRTA* able escape corner map without scrubbing. largest maptested, radius local minima 100, gLSS-LRTA*(10) increasedheuristic value 15suspect gLSS-LRTA* need raise heuristic value cornerstate much corner map moving away start state correlatedmoving closer goal.next section look complex maps game Dragon Age: Originssee LSS-LRTA* gLSS-LRTA* perform there.6.2 Pathfinding Video-Game Mapssection look pathfinding video-game maps. experimentsviolate assumptions 1-3 (unit edge costs, integer heuristics, lookahead one),maps also guaranteed locally isotropic around state. Despite this, seemeasure heuristic learning correlates movement grows asymptoticallyfaster state space. Furthermore, experiments gLSS-LRTA* showworse average-case performance LSS-LRTA*.performed experiments Moving AI benchmark set (Sturtevant, 2012),Dragon Age: Origins maps optimal solution cost [400, 404). total 600problems used 60 maps. ran problems LSS-LRTA* (Koenig & Sun,2009) lookahead depths 1, 10 100 (LSS-LRTA* lookahead 1 equivalentAlgorithm 1). Diagonal movement allowed cost 1.5. Ties brokenfixed way state, according operator ordering data structures, withoutrandomization. Note optimal solution cost predictive distance traveledsolving problem, setup gives wide range problem difficultiesconstrained take least 400 steps solve.measured maximum learning = max hT (s) h0 (s) occurredsR(S)state well total distance traveled reaching goal, plotted onepoint problem instance test set. scrubbing occurring practice,values constant-bounded; otherwise expect range values335fi10400+2.7x2.5gLSS-LRTA*(1)6Dist TraveledDist TraveledSturtevant & Bulitko104110410210100Max Learning ()Dist Traveled102400+0.3x2.45gLSS-LRTA*(10)106110100Max Learning ()1000400+0.05x2.40gLSS-LRTA*(100)106105104103110100Max Learning ()1000Figure 19: Distance travelled versus maximum learning state solving problem instance using gLSS-LRTA* lookahead depths (l) 1 (top left), 10(top right) 100 (bottom).. number states given radius map grows polynomially, totalmovement grow faster polynomial degree two.resulting scatter plots found Figure 18. visually fit polynomialform = 400 + c1 xc2 data, knew problems optimal solutioncost 400 403. (y distance traveled x .) values c1 c2three lookahead depths shown figure, although slightly differentvalues significantly change curves residuals.two-dimensional video-game maps isotropic around stateexactly polynomial due topology, non-unit-cost edges, non-unit edgecosts, may extend far enough locally isotropic (Section 4.9).result, theory offer asymptotic bound Tmin ((h )d+1 ) = ((h )3 )travel hold. Furthermore, maximum learning amount measureh defined earlier paper. Yet, manually fit polynomial curves appear comeclose degree polynomial 2.5 2.65. Note degreepolynomial greater two, maximum dimensionality maps. datasuggests predictive total movement required reach goalscrubbing occurring practice.Results experiments gLSS-LRTA* found Figure 19.problems algorithm sometimes raises heuristic substantially higher LSS-LRTA*also travels substantially further.336fiMax Learning ()Scrubbing Learning Real-time Heuristic SearchLSS-LRTA*(10)gLSS-LRTA*(10)50025000255075 100 125Estimate h(s0, sg)-h0(s0)Figure 20: comparison maximum learning practice () estimatelearning required start goal states (h(s0 , sg ) h0 (s0 )).different tie-breaking rule achieved better performance, would expect smallerrange values x-axis (as compared Figure 18), would fewer stateslarge amounts learning. Instead, lookahead 10 100 range valuessignificantly increased, states heuristic raised almost 1000.two-sample Kolmogorov-Smirnov test comparing LSS-LRTA* gLSS-LRTA* resultsproblems suggests differences significant lookahead 10100, lookahead 1. gLSS-LRTA* provides worse performanceLSS-LRTA*.Looking deeper data lookahead 10 find that, although mean maximum learning similar (55.29 LSS-LRTA*(10) versus 59.01 gLSS-LRTA*(10)),higher standard deviation gLSS-LRTA*(10) (68.35 versus 45.79 LSS-LRTA*).data shows instances tie-breaking towards states higherg-cost help agent reach goal faster (324 instances better versus 240 worse).hand, moving towards higher g-costs results worse performance (distance learning), outweighs gains problems, leading worse averageperformance. lookahead 100 difference instance counts better worseperformance almost equal, again, loss performance tie-breaking ruleoutweighs gains. data suggests moving away start state quicklycan, best case, improve performance, worst case significantlydetrimental effects. results suggest corner map representativevideo game maps.compare learning required start goal (h(s0 , sg )h0 (s0 )),lower-bound h , , actual maximum learning performed agent.estimate h(s0 , sg ) h0 (s0 ) measuring single shortest path insteadshortest paths. lower-bound h holds LSS-LRTA*, points Figure 20would straight line x = figure.600 pathfinding problems indeed case LSS-LRTA*(10)one problem. one problem, algorithm maximum amount learning337fiSturtevant & Bulitko1067.1507x2.3067LSS-LRTA*(1)Dist TraveledDist Traveled10710510450100Max Learning ()Dist Traveled20102001061.7745x2.2078LSS-LRTA*(10)1051041032050100Max Learning ()2000.51333x2.0462LSS-LRTA*(100)51041032050100200Max Learning ()Figure 21: Distance travelled versus maximum learning state solving problem instances maze maps corridor size 8 using LSS-LRTA* lookahead depths (l) 1 (top left), 10 (top right) 100 (bottom).() 54.5 yet maximum difference initial heuristic values along particularoptimal solution 55. Repeating experiments gLSS-LRTA*(10), numberproblems rose 1 36 illustrated markers line Figure.Simultaneously, gLSS-LRTA*(10) raised heuristic values states substantially higherLSS-LRTA*(10).6.3 Maze Mapsprevious section looked maps game Dragon Age: Origins. Analysismaps using regression number states level breadth-first searchsuggests nearly two-dimensional (Sturtevant, 2012). Specifically, polynomialregression equation + b x + c x2 gave average value 0.31 constant c.According measure, mazes benchmark set appear approximatelyone-dimensional, regression gives value 0.01 0.03 constant c equation (Sturtevant, 2012). Thus, mazes represent different class problemsre-run experiments. before, theoretical assumptions state spaceshold experiments.duplicated settings experiments Section 6.2 10 maze mapscorridor width 8 Moving AI benchmark set. fewer maps,increased number problems solved solving probelsm optimal solution400 439, resulting 1100 total problems solved. results LSS-LRTA*Figure 21. computed best-fit curve using least squares dataequation c1 xc2 , also shown.338fiScrubbing Learning Real-time Heuristic Searchfits correlation 0.94, 0.94, 0.91 respectively lookaheads 1, 10,100. maps see degree fit polynomial two greater.maps one-dimensional constant, results suggest scrubbingoccurring practice.initial trials maze problems, gLSS-LRTA* worst-case travel distanceseveral orders magnitude higher LSS-LRTA*. precluded us runningexperiments reasonable amount time suggests gLSS-LRTA* practicalalgorithm maps.7. Conclusionsprimary contribution paper development non-trivial lower boundminimum travel LRTA*-like real-time heuristic search agent mayperform reach goal state. previous work provided examples problemsstate revisitation (i.e., scrubbing) would occur, provide general conditionsused analysis. idealized polynomial state spaces lower bound growsasymptotically faster state space. means agent necessarily scrubundesirable behavior many applications real-time pathfinding video games.theoretical results supported experimentally real-world search problems.result may appear discouraging, suggests common real-time heuristicsearch algorithms may not, own, able avoid scrubbing. proofs relyseveral restrictive assumptions, expect results hold broadly.proof suggest four directions future work trying improve asymptoticperformance. include (1) increasing amount learning performed step, (2)using different tie breaking rules, (3) decreasing size heuristic local minima (4)developing algorithms use value-iteration core technique driving agentbehavior. hope future researchers able point four directionsexplain approaches improve performance, able identifyunderlying assumptions state space makes approaches successful.shown lower bound hold assumptionsbroken, continue look properties could use extend lower boundslarger class problems agents.Acknowledgementssecond author received support work National Research Engineering Council (NSERC).Appendix A. Special Case: Locally Isotropic Exponential State Spacessection consider case exponential state spaces. limit analysislocally isotropic exponential state states spaces number states exactly cost raway (up h /2) given state is:(r) = br , r [0, h /2]339(41)fiSturtevant & Bulitkob branching factor space. Corollary 2, assumestate space size expand substantially beyond h /2 total state space sizeasymptotically size state space within radius h /2state (assumption ?).case repeat derivation Section 4.9 substituting (r) = br(18):Z h2(r)(h 2r)dr =0Zh2br (h 2r)dr =0Zhh2Zrb dr 20h2br rdr =0fi hZ h2br fifir= 2br rdr.2hln b fir=00(42)R hrtake integral 0 2 br rdr (42) introduce function g(r) = lnb b g 0 (r) = brintegrate parts:ZZrb rdr = g 0 (r)rdr =Zg(r)r g(r)r0 dr =Z rZbbrdr =g(r)r g(r)dr = rln bln bbrbrbr1r+C =r+ C.(43)ln b ln2 bln bln b(43) equation (42) becomes:fi hZ h2br fifir= 22hbr rdrfiln b r=00fi hfi hbr fifir= 2br1 fifir= 2h2rln b fir=0ln bln b fir=0fi h2 fifir= 2brh 2r +ln bln b fir=02 h22bh +ln bln bln2 b===hb 2 , h(44)Combining (12), (18) (44) conclude locally isotropic exponential spacesbranching factor b extend distance least h /2 around state , minimumamount total learning lower-bounded as:hLmin (S) b 2 , h .(45)340fiScrubbing Learning Real-time Heuristic Searchamount learning per step constant-bounded, asymptotic lower boundapplies travel cost:hTmin (S) b 2 , h .(46)locally isotropic exponential spaces number states within radius h /2 stategrows as:Z0h2Z(r)dr =h2hbr dr b 2 , h(47)0asymptotically total state space according assumption (?)asymptotically lower bound minimum amounttravel(46).hmeans locally isotropic exponential spaces lower bound b 2sufficient show systematic scrubbing (i.e., prove equivalent Corollary 2).Note (46) lower asymptotic bound amount travel whereas (47)upper lower asymptotic bound state space growth. Thus, may possibleTmin grows asymptotically faster state space size lower bound derivedinsufficient claim so.ReferencesBulitko, V. (2004).Learning adaptive real-time search.Tech. rep.http://arxiv.org/abs/cs.AI/0407016, Computer Science Research Repository (CoRR).Bulitko, V., & Lee, G. (2006). Learning real time search: unifying framework. JournalArtificial Intelligence Research, 25, 119157.Bulitko, V. K., & Bulitko, V. (2009). backtracking real-time heuristic search. CoRR,abs/0912.3228.Edelkamp, S., & Schrodl, S. (2012). Heuristic Search - Theory Applications. AcademicPress.Furcy, D., & Koenig, S. (2000). Speeding convergence real-time search. NationalConference Artificial Intelligence (AAAI), pp. 891897.Hernandez, C., & Baier, J. A. (2012). Avoiding escaping depressions real-timeheuristic search. Journal Artificial Intelligence Research (JAIR), 43, 523570.Hernandez, C., & Meseguer, P. (2005). LRTA*(k). International Joint ConferenceArtificial Intelligence (IJCAI), pp. 12381243.Ishida, T., & Korf, R. (1991). Moving target search. International Joint ConferenceArtificial Intelligence (IJCAI), pp. 204210.Koenig, S. (2001). Agent-centered search. Artificial Intelligence Magazine, 22 (4), 109132.Koenig, S., & Simmons, R. G. (1992). Complexity analysis real-time reinforcementlearning applied finding shortest paths deterministic domains. Tech. rep. CMUCS93106, School Computer Science, Carnegie Mellon University, Pittsburgh.341fiSturtevant & BulitkoKoenig, S., & Simmons, R. G. (1993). Complexity analysis real-time reinforcementlearning. National Conference Artificial Intelligence (AAAI), pp. 99105.Koenig, S., & Simmons, R. G. (1996). effect representation knowledgegoal-directed exploration reinforcement-learning algorithms. Machine Learning,22 (1-3), 227250.Koenig, S., & Sun, X. (2009). Comparing real-time incremental heuristic searchreal-time situated agents. Journal Autonomous Agents Multi-Agent Systems,18 (3), 313341.Koenig, S., Tovey, C., & Smirnov, Y. (2003). Performance bounds planning unknownterrain. Artificial Intelligence, 147, 253279.Korf, R. (1990). Real-time heuristic search. Artificial Intelligence, 42 (23), 189211.Rivera, N., Baier, J. A., & Hernandez, C. (2015). Incorporating weights real-timeheuristic search. Artificial Intelligence, 225, 123.Sharon, G., Felner, A., & Sturtevant, N. (2014). Exponential deepening A* real-timeagent-centered search. AAAI Conference Artificial Intelligence, pp. 871877.Sharon, G., Sturtevant, N. R., & Felner, A. (2013). Online detection dead states realtime agent-centered search. Helmert, M., & Roger, G. (Eds.), ProceedingsSixth Annual Symposium Combinatorial Search. AAAI Press.Shimbo, M., & Ishida, T. (2003). Controlling learning process real-time heuristicsearch. Artificial Intelligence, 146 (1), 141.Shue, L.-Y., Li, S.-T., & Zamani, R. (2001). intelligent heuristic algorithm projectscheduling problems. Annual Meeting Decision Sciences Institute, San Francisco.Shue, L.-Y., & Zamani, R. (1993a). admissible heuristic search algorithm. International Symposium Methodologies Intelligent Systems (ISMIS-93), Vol. 689LNAI, pp. 6975.Shue, L.-Y., & Zamani, R. (1993b). heuristic search algorithm learning capability.ACME Transactions, pp. 233236.Sturtevant, N. R. (2012). Benchmarks grid-based pathfinding. Transactions Computational Intelligence AI Games, 4 (2), 144 148.Sturtevant, N. R., Bulitko, V., & Bjornsson, Y. (2010). learning agent-centered search.Autonomous Agents Multiagent Systems (AAMAS), pp. 333340. InternationalFoundation Autonomous Agents Multiagent Systems.Sturtevant, N. R., & Bulitko, V. (2011). Learning going whencecame: H- G-cost learning real-time heuristic search. International JointConference Artificial Intelligence (IJCAI), pp. 365370. AAAI Press.Sturtevant, N. R., & Bulitko, V. (2014). Reaching goal real-time heuristic search:Scrubbing behavior unavoidable. Proceedings Symposium CombinatorialSearch (SoCS), pp. 166174.342fiScrubbing Learning Real-time Heuristic SearchZamani, R., & Shue, L.-Y. (2001). heuristic learning algorithm applicationproject scheduling problems. Tech. rep., Department Information Systems, University Wollongong.343fiJournal Artificial Intelligence Research 57 (2016) 151-185Submitted 05/16; published 10/16Lightweight Random IndexingPolylingual Text ClassificationAlejandro Moreo FernandezAndrea Esulialejandro.moreo@isti.cnr.itandrea.esuli@isti.cnr.itIstituto di Scienza e Tecnologie dellInformazioneConsiglio Nazionale delle Ricerche56124 Pisa,Fabrizio Sebastianifsebastiani@qf.org.qaQatar Computing Research InstituteHamad bin Khalifa UniversityPO Box 5825, Doha, QAAbstractMultilingual Text Classification (MLTC) text classification task documentswritten one among set L natural languages, documents mustclassified classification scheme, irrespective language. two mainvariants MLTC, namely Cross-Lingual Text Classification (CLTC) Polylingual TextClassification (PLTC). PLTC, focus paper, assume (differentlyCLTC) language L representative set training documents;PLTC consists improving accuracy |L| monolingual classifiersalso leveraging training documents written (|L| 1) languages.obvious solution, consisting generating single polylingual classifier juxtaposedmonolingual vector spaces, usually infeasible, since dimensionality resultingvector space roughly |L| times monolingual one, thus often unmanageable.response, use machine translation tools multilingual dictionariesproposed. However, resources always available, always free use.One machine-translation-free dictionary-free method that, best knowledge, never applied PLTC before, Random Indexing (RI). analyse RIterms space time efficiency, propose particular configuration (thatdub Lightweight Random Indexing LRI). running experiments two well known public benchmarks, Reuters RCV1/RCV2 (a comparable corpus) JRC-Acquis (a parallelone), show LRI outperform (both terms effectiveness efficiency) numberpreviously proposed machine-translation-free dictionary-free PLTC methodsuse baselines.1. Introductionrapid growth multicultural multilingual information accessible Internet, properly classify texts written different languages become problemrelevant practical interest. Multilingual Text Classification (MLTC) text classification task documents written one among set L = {l1 , . . . , l|L| }natural languages, documents must classified classification scheme, irrespective language. two main variants MLTC, namelyCross-Lingual Text Classification (CLTC) Polylingual Text Classification (PLTC).c2016AI Access Foundation. rights reserved.fiMoreo, Esuli, & SebastianiCLTC task characterized fact that, languages subset LTL, training documents; task thus consists classifying unlabelleddocuments written languages LT (i.e., target languages) leveragingtraining documents expressed languages LS = L\LT (i.e., source languages).CLTC thus transfer learning problem (Pan & Yang, 2010), one needs transferknowledge acquired learning training data LS , task classifyingdocuments LT . previous work MLTC indeed focuses CLTC, fewer effortsdevoted PLTC, instead focus paper.PLTC, representative set training documents languages L assumedavailable. Therefore, straightforward solution may consist training |L| independentmonolingual classifiers, one language. However, solution suboptimal,classifier obtained disregarding additional supervision could obtainedusing training documents written (|L| 1) languages. PLTC thusconsists leveraging training documents written languages L improveclassification accuracy could obtained simply training |L| independent,monolingual classifiers.However, PLTC entails number obstacles work detriment efficientrepresentation. see this, assume generate single polylingual vector space (hereafter,juxtaposed vector space) juxtaposing monolingual vector spaces. vectorspace monolingual dataset usually consists tens even hundreds thousandsfeatures; juxtaposed vector space polylingual dataset, dimensionality getsroughly multiplied number distinct languages consideration. substantial increase feature space would degrade performance many classificationalgorithms, so-called curse dimensionality, would also bringsevere degradation efficiency. Additionally, co-occurrence-based techniques tend losepower representations polylingual, since terms belonging different languagesrarely co-occur, (a problem usually referred feature disjointness).response, authors proposed use machine translation (MT) toolsdevice simultaneously cope high dimensionality feature disjointnessPLTC. idea reduce problem monolingual case (typically English).is, non-English training documents automatically translated English, addedEnglish training set, monolingual (English) classifier trained. classificationtime, non-English unlabelled documents translated English classified.(Of course, idea also used CLTC; case, training documentstranslate.) However, MT-based PLTC (and CLTC) techniques suffer numberdrawbacks (Wei, Yang, Lee, Shi, & Yang, 2014): (i) automatically translated texts usuallypresent different statistical properties respect human translations; (ii) MT systemsalways available language pairs; (iii) training statistical MT systemfree toolkits available requires collecting large corpora parallel textdomain interest, always easy.Thesaurus-based dictionary-based methods, side, represent lighterapproach MLTC. multilingual dictionary thesaurus encompasses different languages available, kind unification vector representation mayattempted. customarily done replacing non-English words English equivalents dictionary, replacing terms thesaurus codes invariant152fiLightweight Random Indexing Polylingual Text Classificationacross languages (e.g., BabelNet synsets Ehrmann, Cecconi, Vannella, McCrae, Cimiano,& Navigli, 2014). However, bilingual dictionaries thesauri available language pairs, automatically constructing domain-dependent bilingual resource requiressuitable parallel corpus sentence-level alignment.1.1 Distributional Representationsclassification purposes, textual document usually represented vector vectorspace according bag-of-words (BoW) model, i.e., distinct term correspondsdimension vector space. juxtaposed vector space, columnsdocument-by-term matrix thus informative one languages.Since distinct term corresponds dimension vector space, BoW modelagnostic respect semantic similarities among terms. is, dimensionterm governor orthogonal dimension related term president,dimension unrelated term transport. semantic relations among termsuncovered detecting co-occurrences, i.e., contexts words tendused together. idea rests distributional hypothesis, according wordssimilar meanings tend co-occur contexts (Harris, 1968). detectingco-occurrences, possible establish parallelism term meaning geometrical properties vector space. Distributed Semantic Models (DSMs sometimes alsocalled word space models Sahlgren, 2006) aim learning continuous compact distributed term representations, recently called word embeddings (Mikolov,Sutskever, Chen, Corrado, & Dean, 2013b). DSMs gained lot attentionmachine learning community, delivering improved results many natural language processing tasks (Bengio, Schwenk, Senecal, Morin, & Gauvain, 2006; Bullinaria & Levy, 2007;Collobert, Weston, Bottou, Karlen, Kavukcuoglu, & Kuksa, 2011). DSM-based methodscategorised (see Pennington, Socher, & Manning, 2014; Baroni, Dinu, & Kruszewski,2014) belonging (a) class context-counting models, often basedmatrix factorization, e.g., Latent Semantic Analysis (LSA Deerwester, Dumais, Furnas,Landauer, & Harshman, 1990; Osterlund, Odling, & Sahlgren, 2015), (b) classcontext-predicting models, e.g., methods based deep learning architectures (Bengio,2009; Mikolov et al., 2013b).However, multilingual contexts huge quantities plain text languageprocessed order learn meaningful word representations, incurs high computational costs. Trying find representations large multilingual vocabularythus become computationally prohibitive. attempts recently madedirection, leveraging multilingual external resources Wikipedia articles(Al-Rfou, Perozzi, & Skiena, 2013), bilingual dictionaries (Gouws & Sgaard, 2015),word-aligned parallel corpora (Klementiev, Titov, & Bhattarai, 2012), sentence-alignedparallel corpora (Zou, Socher, Cer, & Manning, 2013; Hermann & Blunsom, 2014; Lauly,Boulanger, & Larochelle, 2014; Chandar, Lauly, Larochelle, Khapra, Ravindran, Raykar, &Saha, 2014), document-aligned parallel corpora (Vulic & Moens, 2015). However,external resources may always available language combinations and,available (e.g., Wikipedia articles), may uneven quality quantitylanguages English. Alternatively, approaches require computationally153fiMoreo, Esuli, & Sebastianiexpensive post-processing step align word representations across languages (Mikolov, Le,& Sutskever, 2013a; Faruqui & Dyer, 2014).article discuss efficient representation mechanisms PLTC (i)MT-free, (ii) require external resources, (iii) incur high computationalcosts. particular, investigate suitability Random Indexing (RI Kanerva,Kristofersson, & Holst, 2000; Sahlgren, 2005) effective representation mechanismoriginal co-occurrence matrix PLTC. RI context-counting model belongingfamily random projections methods (Kaski, 1998; Papadimitriou, Raghavan, Tamaki, &Vempala, 1998), produces linear projections nearly-orthogonal reduced spaceoriginal distances vectors approximately preserved (Hecht-Nielsen,1994; Johnson, Lindenstrauss, & Schechtman, 1986). RI expected deliver fastsemantically meaningful representations reduced space, viewed cheaperapproximation LSA (Sahlgren, 2005). RI column polylingualmatrix produced depend single specific language (as insteadBoW representation). hypothesize could advantageous PLTC, sinceentire new space becomes potentially informative languages once, thus makingproblem easily separable enough dimensions considered. RI alreadyapplied bilingual scenarios (Gorman & Curran, 2006; Sahlgren & Karlgren, 2005),best knowledge tested PLTC case far. monolingualTC, RI found competitive, superior, BoW (Sahlgren & Coster, 2004).article demonstrate RI outperforms BoW model PLTC.method present article, dub Lightweight Random Indexing (LRI),inspired works Achlioptas (2001) Li, Hastie, Church (2006)sparse random projections, goes one step pushing sparsity limit. LRIdesigned orthogonality projection base maximized, causes sparsitypreserved projection. empirically show LRI helps Support VectorMachines (SVMs) deliver better classification accuracies PLTC respect manypopular alternative vector space models (including main random projection variants,LSA-based approaches, polylingual topic models), also requiring substantiallyless computation effort.contribution work twofold. First, conduct comparative empiricalstudy several PLTC approaches two representative scenarios: firsttraining corpus comparable topic-level (i.e., documents direct translationsother, simply similar topics; exemplified RCV1/RCV2dataset), second training corpus parallel document-level (i.e.,text available languages thanks intervention human translators;scenario exemplified JRC-Acquis dataset). show LRI yields best resultssettings, terms effectiveness efficiency. second contribution,present analytical study useful better understand nature randommapping methods.rest paper organized follows. Section 2 discuss related work.Section 3 present problem statement, describe Random Indexing methoddetail, present proposal. Section 4 reports results experimentsconducted. Section 5 presents analytical study computational efficiency, Section6 concludes.154fiLightweight Random Indexing Polylingual Text Classification2. Related Worksection gives overview main approaches PLTC emergedliterature. distinguish three groups methods, according whether problem approached (i) leveraging external resources, (ii) combining outcome independentmonolingual classifiers, (iii) reducing dimensionality resulting multilingualfeature space. discussion also includes references CLTC techniquesconsider relevant PLTC approach.2.1 Exploiting External Multilingual ResourcesMultilingual text classification relatively recent area research, previousefforts within devoted CLTC subtask. CLTC labelledinformation languages, previous approaches typically relied automatic translationmechanisms means fill gap source target languages.main difference CLTC PLTC lies fact PLTC exploits labelleddocuments belonging different languages learning. Despite this, two tasksclose-knit relation, since cross-lingual adaptation generally carriedmeans external resources, parallel corpora, bilingual dictionaries,statistical thesauri.suitable (unlabelled) multilingual corpus containing short aligned pieces textsavailable, correlations among groups words two languages could explored.Cross-Lingual Kernel Canonical Correlation Analysis (CL-KCCA) proposed Vinokourov, Shawe-Taylor, Cristianini (2002) means obtain semantic cross-lingualrepresentation, investigating correlations aligned text fragments. CL-KCCAtakes advantage kernel functions order map aligned texts high-dimensionalspace manner correlations mapped aligned texts jointlymaximized. cross-lingual representation could used classification, retrieval,clustering tasks. CL-KCCA investigated combination Support Vector Machines (SVMs) applied cross-lingual patent classification Li Shawe-Taylor(2007). method, called SVM 2k, learns two SVM-based classifiers searching twolinear projections original feature space language distanceprojections (instead correlation projections) two aligned texts minimized.similar vein, polylingual topic models (Mimno, Wallach, Naradowsky, Smith, &McCallum, 2009) proposed extension Latent Dirichlet Allocation (LDABlei, Ng, & Jordan, 2003) polylingual case. LDA generative modelassigns probability distributions documents latent topics, latent topicsterms. distributions viewed compact representations documentslatent space. Since topics discovered Polylingual LDA (PLDA) aligned acrosslanguages, documents represented common vector space regardless languagewritten in. However, PLDA (which use baseline experimentalsection) requires parallel collection documents aligned sentence level.Bilingual dictionaries used straightforward manner carry word-byword translation feature space. However, dictionary-based translations sufferseveral deficiencies, e.g., context-unaware translations might perform poorly handlingpolysemic words; dictionaries might suffer substantial lack coverage novel terms155fiMoreo, Esuli, & Sebastianidomain-dependent terminology; dictionaries might available languagepairs, free use. response drawbacks, automatic acquisitionstatistical bilingual dictionaries proposed. Wei et al. (2014) explored cooccurrence-based method measure polylingual statistical strength correlationamong words parallel corpus. correlations taken account reinforce weight feature order select important (highly weighted) ones.Gliozzo Strapparava (2006) experimented bilingual dictionaries and, interestingly, provided means automatically obtain Multilingual Domain Model (MDM),natural extension domain models multiple languages, additional multilingual resources available. domain model defines soft relations wordsdomain topics. absence multilingual dictionary, MDM could automaticallyobtained comparable corpus performing Latent Semantic Analysis (explaineddetail below).argued words shared across languages play important rolesearching semantic latent space. Accordingly, Steinberger, Pouliquen, Ignat(2004) exploit language-independent tokens shared across languages,propose simple method link documents existing external resources thesauri,nomenclatures, gazetteers. Finally, de Melo Siersdorfer (2007) use ontologiesmap original features onto synset-like identifiers, documents translatedlanguage-independent feature space.MT tools, side, provide elaborated translations texts, represent promising research field multilingual tasks. Unfortunately, above-mentionedproblems regarding availability, accessibility, performance still hold case.effect different translation strategies CLTC investigated Bel, Koster,Villegas (2003), Rigutini, Maggini, Liu (2005), Wei, Lin, Yang (2011).Even available, MT tools may expensive resources. reason,experiments Prettenhofer Stein (2010) restrict use MT tool limited budgetcalls. Structural Correspondence Learning (SCL) method, initially proposeddomain adaptation, indeed applied CLTC. key idea method consistsdiscovering cross-lingual correspondences pairs terms (dubbed pivot features)later used bridge across two languages. Pivot features play importantrole bilingual tasks, since establish pairs words behave similarly sourcetarget languages, allowing one find cross-language structural correspondences. Onespecial type pivot features obviously words shared across languages,proper nouns, technical terms, yet lexicalized terms, stemmed forms etymologicallyrelated terms. Nastase Strapparava (2013) found etymological ancestors wordsactually add useful information, allowing transcend cross-lingual boundaries.method however depends availability etymological thesauri (such WikipediasWiktionary, Etymological WordNet), remains restricted historically interrelatedlanguages.sum, applicability multilingual methods discussed section usuallyconstrained availability external resources. aim overcoming limitations, restrict investigations dictionary-free, MT-free multilingual methods.156fiLightweight Random Indexing Polylingual Text Classification2.2 Monolingual Classifiers Multiview LearningGiven availability representative set labelled documents language,simple baseline, known nave polylingual classifier, could obtained delegatingclassification process individual monolingual classifiers, built upon separatemonolingual data. solution sub-optimal, classifier exploit labelledinformation languages, type information might provide insightsdifferent perspectives semantics classes.Garca Adeva, Calvo, Lopez de Ipina (2005) compared different nave strategies,considering one single polylingual classifier, i.e., classifier works juxtaposedrepresentation (1C), vs. various monolingual ones (NC), one language-independentpreprocessor (1P) vs. various language-specific ones (NP), using various learning methodsbilingual Spanish/Basque benchmark. experimentation combinations NPNC NP-1C, consider baselines, yielded best results termsrunning time, memory usage, accuracy.Even though training separate language-specific classifiers simple way approachPLTC task, strategies could improve final accuracy bettermerging outcomes classifier. Multiview learning (Xu, Tao, & Xu, 2013) TCdeals parallel texts, i.e., case document available languages,language considered separate source. shown Amini, Usunier,Goutte (2009) multiview majority voting algorithm, returns label outputhighest number language-specific classifiers, outperforms nave polylingualclassifier multiview Gibbs classifier, bases predictions mean predictionlanguage-specific classifier. Amini Goutte (2010) proposed co-regularizationapproach multiview text classification minimizes joint loss function takesaccount language-specific classifier loss. However, availability parallelcorpus containing documents views strong restriction, usuallyalleviated leveraging machine translation tools automatically generate missingdocuments views.2.3 Dimensionality Reduction Multilingual ClassificationOne main challenges juxtaposed vector space approach PLTC concernsrelevant increase number features represent documents, i.e., dimensionality vector space (Rigutini et al., 2005). Feature selection methods attemptselect reduced subset informative features original set F sizesubset much smaller |F | reduced set yields high classificationeffectiveness. TC problem usually tackled via filtering approach, reliesmathematical function meant measure contribution feature classification task. Yang Pedersen (1997) showed filtering approaches may improveperformance classification, even aggressive reduction ratios (e.g., removal 90%features).Another important dimensionality reduction technique Latent Semantic Analysis(LSA aka Latent Semantic Indexing), originated information retrievalcommunity (Deerwester et al., 1990), later applied cross-lingual classification (Gliozzo & Strapparava, 2006; Xiao & Guo, 2013) cross-lingual problems general157fiMoreo, Esuli, & Sebastiani(Dumais, Letsche, Littman, & Landauer, 1997). LSA maps original document-term matrix lower dimensional latent semantic space attempts capture (linear)relations among original features documents. mapping carriedmeans singular value decomposition (SVD) original document-term matrix .SVD decomposes = V U , diagonal matrix containing eigenvalues . approximation Mk = Vk k UkT original matrix computedtaking k largest eigenvalues setting remaining ones 0; Mk saidrank-k optimal terms Frobenius norm. Vk Uk orthogonal matricesexplain relations among pairs terms pairs documents, respectively.Although LSA successfully used discover hidden relations indirectlycorrelated features, case terms belonging different languages, suffershigh computational costs. Random mappings arise alternative LSA,perform comparably different machine learning tasks preserving importantcharacteristics LSA, bringing about, time, significant savingsterms computational cost (Fradkin & Madigan, 2003). Random Projections (RPsPapadimitriou et al., 1998) Random Mappings (RMs Kaski, 1998) two equivalentformulations deriving Johnson-Lindenstrauss lemma (Johnson et al., 1986),states distances Euclidean space approximately preserved projected ontolower-dimensional random space. formulations also based fundamentalresult Hecht-Nielsen (1994), proved many nearly orthogonaltruly orthogonal directions high-dimensional spaces.RP-like methods formalized terms projection original documentterm matrix means random matrix , i.e., M|D|n = M|D||F | |F |n ,approximates identity matrix, |D| |F | indicate number documentsterms collection, n stands reduced dimensionality, typicallychosen advance. definition random-projection matrix fundamentalaspect method; Achlioptas (2001) demonstrated random distributionzero mean unit variance satisfies Johnson-Lindenstrauss lemma, proposed twosimple distributions definition elements ij = {ij } random projectionmatrix, setting parameter distribution Equation 1 either = 2 = 3:1+1 probability 2s0 probability 1 1sij =(1)11 probability 2sAchlioptas proved configuration = 3 used speed computation, since case 1/3 data non-zero (sparse random projection),pandtherefore 2/3 computations skipped. Similarly, Li et al. (2006) set = |F |= |F |/ log |F | (very sparse random projections) significantly speed computation still preserving inner distances.Random Indexing (RI), first proposed Kanerva et al. (2000), equivalent formulation RPs also accommodates Achlioptas theory. Sahlgren (2001) defines RIapproximate alternative LSA semantic representation. RI maintains dictionaryrandom index vectors feature original space. random index vector consists n-dimensional sparse vector k non-zero values, randomly distributed across+1 1 (the method explained detail Section 3). work Gorman158fiLightweight Random Indexing Polylingual Text ClassificationCurran (2006) different weighting criteria random index vectors dictionaryproven useful improving matrix representation. RI tested different tasks,search (Rangan, 2011), query expansion (Sahlgren, Karlgren, Coster, & Jarvinen,2002), image text compression (Bingham & Mannila, 2001), event detection (Jurgens & Stevens, 2009). Fradkin Madigan (2003) showed that, since RI distancesapproximately preserved, distance-based learners k-Nearest Neighbours (k-NN)SVMs preferable learning randomly indexed instances. Accordingly,Sahlgren Coster (2004) applied RI (monolingual) text classification using SVMs,suggested random indexing representation (there dubbed Bag ConceptsBoCs Sahlgren & Coster, 2004) performed comparably BoW representation.performance RI also tested Sahlgren Karlgren (2005) GormanCurran (2006) realm automatic bilingual lexicon acquisition.above-discussed works indicate RI promising dimensionality reduction technique representing polylingual data. proposal inspired works Achlioptas(2001) Li et al. (2006) sparse projections taking level sparsity extreme, extends application RI TC (Sahlgren & Coster, 2004) PLTC, which,best knowledge, never done far. following section firstdescribe method detail, propose particular setting aimed overcomingcertain obstacles could arise polylingual setting.3. Lightweight Random Indexing Polylingual Text ClassificationText Classification (TC) formalized task approximating unknown targetfunction : C {1, +1}, indicates documents ought classified,means function : C {1, +1}, called classifier, coincidemuch possible terms given evaluation metric. denotes domaindocuments, C = {c1 , c2 , ..., c|C| } set predefined classes, values +1 1indicate membership non-membership document class, respectively.consider multilabel classification, is, setting documentcould belong zero, one, several classes time; consider flatversion problem, hierarchical relations among classes exist. adopt1 vs. strategy, according multilabel classification problem solved|C| independent binary classification problems.document collection represented via matrix M|D||F |~d1w11w12 w1|F |d~2 w21w22 w2|F |= . = ......... .....w|D|1 w|D|2 w|D||F |d~|D|(2)|D| |F | number documents features collection, realvalues wij represent weight feature fj document di , usually determinedfunction frequency feature document collection.Polylingual Text Classification adds one fundamental aspect TC, i.e., different documents may belong different languages. Let : L return language159fiMoreo, Esuli, & Sebastianigiven document written, L = {l1 , l2 , . . . , l|L| } pool languages, |L| > 1.S|L|Let F = i=1 Fi denote vocabulary collection, expressedunion language-specific vocabularies Fi . polylingual setting assumesdistribution P ((d) = li ) across training set approximately uniform, is,representative quantity labelled documents language.usually small amount shared features across languages (e.g., propernouns)1 , implies hd~0 , d~00 0 (d0 ) 6= (d00 ), h, denotes dotproduct. (Incidentally, means direct similarity comparison among documentsexpressed different languages, e.g., using cosine-similarity, would doomed fail.)thus possible, language li , perform reordering rows columnsM1 M2 0matrix allows polylingual matrix expressed =,0 M3 4[M1 ;2 ]|{d : (d) = li }| |Fi | monolingual matrix representationM2language li ,|D| matrix containing words shared across twoM3languages, 0 denotes all-zero matrices.3.1 Random IndexingRandom Indexing maps observable problem feature random vector vectorspace number dimensions determined number different uniquefeatures want map, instead fixed advance. Originally, RI proposedperforming semantic comparisons terms. document thus mappedrandom index vector accumulated (via vector addition) terms rowterm-document matrix time term occurred document. case,instead interested performing semantic comparisons documents, terms.Thus, term fi assigned n-dimensional random index vector, accumulatedj-th row document-term matrix every time term found document dj .Random index vectors nearly-orthogonal, comply conditions spelledAchlioptas (2001) (see Section 2.3), i.e., zero-mean distribution unit variance,satisfy Johnson-Lindenstrauss lemma. random index vector created randomlysetting k n non-zero values, equally distributed +1 1, n-dimensionalvector n typically order thousands. n fixed, recommendedchoice k literature k = n/100. dub configuration RI1% , usecomparative experiments. vectors RI1% sparse, using sparse data structurerepresentations could bring memory savings. M|D|n = M|D||F | |F |n matrixmultiplication (see Section 2.3) completely skipped, building M|D|n on-the-flyscanning document accumulating corresponding random index vectorsterm read. also avoids need allocate entire matrix M|D||F | memory.According Sahlgren (2005), main advantages RI summarized follows:method (i) incremental, provides intermediate results data read1. Note formulations polylingual problem, e.g., ones Amini et al. (2009)Prettenhofer Stein (2010), actually impose 6= j Fi Fj = . meansshared words across languages, proper nouns, given multiple representations languagespecific features.160fiLightweight Random Indexing Polylingual Text Classificationin; (ii) avoids so-called huge matrix step (i.e., allocating entire M|D||F | matrixmemory), (iii) scalable, since adding new elements data increasedimensionality space (e.g., new features represented via new random index,via new dimension).BoW matrices typically weighted normalized better represent importanceword document avoid giving long documents priori importance,respectively. Weighting schemes could also incorporated RI formalismsimple manner; e.g., time random index added document row, firstmultiplied weight term document. brings improvedaccuracy shown Gorman Curran (2006); however, work alsoshown incremental nature algorithm sacrificed non-linear weightstaken account. experiments, weighting criterion use well-knowntfidf method, expressedtfidf (di , fj ) = tf (di , fj ) log|D||d : tf (d, fj ) > 0|(3)tf (di , fj ) counts number occurrences feature fj document di ; weightsnormalized via cosine normalization,wij = qPtfidf (di , fj )fk F(4)tfidf (di , fk )23.2 Lightweight Random Indexingpreliminary experiments application RI method dimensionalityreduction, observed SVMs required time train training setprocessed RI, original high-dimensional vector space (see Section5.2). also observed correlation training times choice k,choice n smaller impact efficiency.Optimizing choice k RI though means achieve two main goals:(i) able encode large number different features reduced space, (ii)increasing chance two random index vectors orthogonal.respect (i), easy show that, want assign different n-dimensionalindex vectork non-zero values original feature, RI could encode maximumC(n, k) = nk 2k features (representation capacity). C(n, k) grows rapidly functioneither n k; example, C(5000, 50) 2.5 10135 . huge capacity clearlyexceeds representation requirements imposed current future dataset. However,even small values k capacity becomes large enough encode reasonabledataset, e.g., C(5000,2)=49,990,000 distinct features.respect (ii), random-projection-based algorithms rely Hecht-Nielsen(1994) lemma find nearly orthogonal directions reduced space. Two vectors ~u~v inPan inner product space said orthogonal whenever h~u, ~v = 0,h~u, ~v = ui vi dot product. Random indexes chosen sparse orderincrease probability dot product equals zero, non-zero products evenlydistributed +1 1, leaving expected value outcome close zero.161fiMoreo, Esuli, & SebastianiFigure 1: Probability orthogonality two random index vectors function kn.means Monte Carlo algorithm, estimated probability orthogonalitytwo randomly generated vectors grid sample values n k. results,plotted Figure 1, reveal smaller values k main factor favouringorthogonality two random index vectors, n smaller impact.many random index vectors lack orthogonality, information conveyed original distinct features, predominantly pair-wise semantically unrelated, gets mixedup, causing learner difficulty learning meaningful separation patternsthem. orthogonality random index vectors plays even important rolefeatures shared across languages. shown work Gliozzo Strapparava (2005), shared words play relevant role bringing useful information acrosslanguages. corresponding random index vectors orthogonal respectvectors, information contribute process maximized, insteaddiluted less informative features.Following observations above, propose use Random Indexing fixedk = 2; dub configuration Lightweight Random Indexing (LRI). hypothesissetting could advantageous mechanism reduce dimensionality (somitigate problem feature disjointness PLTC), since sufficient orderrepresent large feature vocabularies also preserving vector orthogonality. Notechoosing k = 1, n = |F |, would equivalent performing random permutation162fiLightweight Random Indexing Polylingual Text Classification12345678Output: Dictionary;// Generate random index vector feature= 0 (|F | 1)// choose 1st dimension sequentiallydim1 (i mod n) + 1 ;// choose 2nd dimension uniformly random// dimensions chosen Line 2dim2 rand({1, ..., n)} \ {dim1 }) ;// assign 1st non-zero value uniformly random+1val1 rand({, 12 }) ;2// 2nd non-zero value+1val2 rand({, 12 }) ;2// create sparse random index vectorrandom index vector [(dim1 , val1 ), (dim2 , val2 )] ;// build feature-vector mappingDictionary.map(fi+1 , random index vector) ;endAlgorithm 1: Feature Dictionary Lightweight Random Indexing.feature indexes BoW representation; k = 2 minimum value actualRI performed.Algorithm 1 formalizes process creating dictionary, is, creating mappingconsisting one random vector original feature; mapping created trainingtime used classifying unlabelled documents(this means that, Line 1, Fset features present training set). value 1/ 2 used instead 1 orderobtain vectors length one. Note two dimensions selected differentmanner, step Line 2 ensuring latent dimensions used approximatelynumber times, step Line 3 ensuring dimension chosenprevious step chosen twice.proposal presents following advantages respect standard RI1% and,general, respect RI k > 2:index vector two non-zero values. mapping allocatedmemory number original features, projection performedquickly;Given fixed value n, higher probability instantiationRI generating truly pairwise orthogonal random vectors;Parameter k becomes constant needs tuning.163fiMoreo, Esuli, & Sebastiani4. Experimentssection experimentally compare Lightweight Random Indexing (LRI) methodrepresentation approaches proposed literature.4.1 Baselines Implementation Detailsbaselines compare LRI chosen following methods,group three categories according common characteristics:Orthogonal Mappings: methods using canonical basis co-occurrence matrix:PolyBow: classifier operates juxtaposed BoW representation (PolyBowcorresponds NP-1C setup Garca Adeva et al., 2005).FS: Feature Selection PolyBoW using Information Gain term scoring function Round Robin (Forman, 2004) term selection policy.Majority Voting: multiview voting algorithm returns label outputhighest number language-specific classifiers (Amini et al., 2009).MonoBoW: lower bound baseline uses set nave monolingual classifiers(MonoBoW corresponds NP-NC setup Garca Adeva et al., 2005).MT: upper bound baseline based statistical machine translation, translates non-English training test documents English.Random Mappings: dimensionality reduction methods relying random projections:RI1% : Random Indexing k = n/100 (Sahlgren & Coster, 2004).ACH: Achlioptas mapping ternary distribution obtained setting = 3Equation 1 (Achlioptas, 2001).Non-Random Mappings: dimensionality reduction methods relying mappingsrandom:CL-LSA: Cross-Lingual Latent Semantic Analysis (Dumais et al., 1997).MDM: Multilingual Domain Models (Gliozzo & Strapparava, 2005).PLDA: Polylingual Latent Dirichlet Allocation (Mimno et al., 2009).assume language labels available advance2 training testingdocuments. Note RI methods PolyBoW represent documentsfeature space, irrespective language label. Conversely, MonoBoW keeps separatelanguage-specific classifier language; class label test documentdecided classifier associated documents language label. test PLDAMajority Voting JRC-Acquis parallel corpus, since documentsrequire separate view languages available. Majority Voting maintainsseparate classifier distinct language (5 experiments); test documentthus classified using 5 classification decisions voting, one language-specific2. assumption fair, current language identification models deliver accuracies close 100%164fiLightweight Random Indexing Polylingual Text Classificationview. singular value decomposition used Rohde (2011) package.used Haddow, Hoang, Bertoldi, Bojar, Heafield (2016) implementation generateset statistical translation systems trained sentence-aligned parallel data providedEuroparl data release (Koehn, 2005). Note that, since used method describedGliozzo Strapparava (2005) automatically obtain bilingual model MDM,MT method using external knowledge. PLDA used Richardson(2008) implementation, uses Gibbs sampling; adhere common practicefixing budget iterations 1,000. implemented LRI methodbaseline methods part Esuli, Fagni, Moreo (2016) framework.used Support Vector Machines (SVMs) learning device cases, sinceconsistently delivered state-of-the-art results TC far; used well-knownJoachims (2009) implementation Joachims (2005), default parameters.4.2 Evaluation Measureseffectiveness measure use well-known F1 , harmonic mean precision() recall () defined F1 = (2)/( + ) = (T P )/(2T P + F P + F N ) P ,F P , F N stand numbers true positives, false positives, false negatives,respectively. take F1 = 1 P = F P = F N = 0, since classifier correctlyclassified examples negative.compute micro-averaged F1 (denoted F1 ) macro-averaged F1 (denotedF1M ). F1 obtained (i) computing class-specific values Pr , F Pr , F Nr , (ii)obtaining P summation Pr (same F P F N ), applyingF1 formula. F1M obtained first computing class-specific F1 valuesaveraging across classes. fact F1M attributes equal importanceclasses means low-frequency classes important high-frequency onesdetermining F1M scores; F1 instead influenced high-frequency classeslow-frequency ones. High values F1M thus tend indicate classifier performs wellalso low-prevalence classes, high values F1 may indicate classifierperforms well high-prevalence classes.4.3 Datasetsperformed experiments two publicly available corpora, RCV1/RCV2 (acomparable corpus) JRC-Acquis (a parallel corpus).4.3.1 RCV1/RCV2RCV1 publicly available collection consisting 804,414 English news stories generated Reuters 20 Aug 1996 19 Aug 1997 (Lewis, Yang, Rose, & Li, 2004). RCV2instead polylingual collection, containing 487,000 news stories generatedtimeframe thirteen languages English (Dutch, French, German, Chinese,Japanese, Russian, Portuguese, Spanish, LatinoAmerican Spanish, Italian, Danish, Norwegian, Swedish). union RCV1 RCV2 (hereafter referred RCV1/RCV2)corpus comparable topic-level, news stories direct translationssimply refer related events different languages. Since cor165fiMoreo, Esuli, & Sebastianipus parallel, training document given language generalcounterpart languages.RCV1/RCV2 randomly selected 8,000 news stories 5 languages (English,Italian, Spanish, French, German) pertaining last 4 months (from 1997-04-191997-08-19), performed 70%/30% train/test split, thus obtaining training set28,000 documents (5,600 language) test set 12,000 documents (2,400language)3 . experiments restricted attention 67 classes(out 103) least one positive training example five languages.average number classes per document 2.92, ranging minimum 1maximum 11; number positive examples per class/language combination rangesminimum 1 maximum 4,182.preprocessed corpus removing stop words stemming terms usingPorter stemmer English, Snowball stemmer languages.resulted total 123,258 stemmed terms, distributed across languages shown Table1.EnglishItalianSpanishFrenchGermanEnglish40,483Italian3,42014,762Spanish6,5593,75230,077French6,3703,3006,13926,961German3,9211,9293,0143,44138,232Appearing1 languages2 languages3 languages4 languages5 languages#106,18210,4743,8511,923828Table 1: Feature distribution across languages RCV1/RCV2 comparable corpus.leftmost part table, cell row column j representsnumber features shared across i-specific j-specific sectionsdataset. (The table symmetric, better clarity entriesdiagonal omitted.) rightmost part table indicates manyfeatures shared across x language-specific sections dataset.4.3.2 JRC-AcquisJRC-Acquis corpus (version 3.0) version Acquis Communautaire collectionparallel legislative texts European Union law written 1950s 2006(Steinberger, Pouliquen, Widiger, Ignat, Erjavec, Tufis, & Varga, 2006). JRC-Acquispublicly available research purposes, covers 22 official European languages.corpus parallel sentence-level, i.e., document exists 22 languages,sentence-by-sentence translation. corpus labelled according ontology-basedEuroVoc thesaurus, consists 6,000 classes; experimentsrestricted attention 21 classes top level EuroVoc hierarchy.3. information required replicate experiments, e.g., IDs selected documents, assignedlabels, etc., publicly available (Moreo, 2016). source code used experiments accessiblepart Esuli et al. (2016) framework166fiLightweight Random Indexing Polylingual Text ClassificationEnglishItalianSpanishFrenchGermanEnglish150,866Italian77,878150,838Spanish80,22095,515143,712French89,57390,52288,561147,077German98,74078,91985,43486,905228,834Appearing1 languages2 languages3 languages4 languages5 languages#249,21642,56633,30522,17159,676Table 2: Feature distribution across languages JRC-Acquis parallel corpus;meaning cells Table 1. Note high number features (59,676) appear five languages; due presenceproper names, languages. Note also high numberfeatures (228,834) unique German language: duepresence word compounds, phenomenon present German languagefour languages.selected 7,235 texts 2006 5 languages (English, Italian, Spanish,French, German) removed documents without labels, thus obtaining 6,980 documents per language. taken first 70% documents training (24,430, i.e.,4,886 language) remaining 30% (10,470, i.e., 2,094 language)testing. average number classes per document 3.5, ranging minimum1 maximum 10; number positive examples per class/language combinationranges minimum 47 maximum 2,011.preprocessing RCV1/RCV2 carried dataset, obtaining 406,934 distinct features distributed across languages shown Table 2. SinceJRC-Acquis corpus parallel, language-specific document guaranteedcounterpart languages, results relatively large numberterms (e.g., proper nouns) appearing several languages. Note that, despite factdataset parallel sentence level, interested indexing entire documentswhole, thus disregard sentence order; thus consider corpus paralleldocument level.use JRC-Acquis corpus order test performance LRI casesco-occurrence matrix compacted, defined work Dumais et al.(1997). precisely, compact representation |L| translation-equivalent documentsvector consisting concatenation |L| vectors represent one (monolingual) document. different juxtaposed representation usedprevious chapters, vector corresponding one monolingual documentzeros positions corresponding features languages. compactmatrix thus obtained matrix resulting juxtaposed representationscompressing |L| rows single (compact) row storing sum.167fiMoreo, Esuli, & Sebastiani4.4 Resultssection present results experiments. first compare LRI setmonolingual classifiers (Section 4.4.1), explore dimensionality reductionaspect polylingual problem (Section 4.4.2).4.4.1 Polylingual Informationfirst case study, investigate much addition polylingual informationaffects accuracy monolingual classifier. scenario, compare LRIPolyBoW, train documents languages, lower bound MonoBoW,trains documents language test documents, upperbound MT, first translates training test documents English. NoteMT baseline tested JRC-Acquis corpus documentsalready available direct translation languages. experiment vector spacereduced, i.e., set n = |F | LRI vector spaces PolyBoWLRI number dimensions. Values LRI averaged 10 runs.results illustrated Figure 2 show simple addition examples different languages (PolyBoW) brings improvement accuracy respectmonolingual solution (MonoBoW). improvement likely achieved thanks wordsshared across languages. However, LRI clearly outperforms PolyBoW. improvementsPolyBoW MonoBoW range -0.4% +29.7%, LRI achieves improvements ranging +9.7% +41.1%; LRI obtains smallest improvementMonoBoW terms F1M (on Italian, +9.7%), PolyBoW performs slightly worseMonoBoW (-0.4%). improvements marked F1M F1 , indicatingimprovements especially take place infrequent classes,substantial impact F1M F1 .general, training documents coming languages (PolyBoW, LRI, MT)seems preferable training language-specific documents (MonoBoW).particularly MT baseline, obtained best results casessole exception English, LRI obtained best result. exception mightexplained fact automatically translated documents tend exhibit differentstatistical properties respect documents written humans, meansEnglish test documents (which translations) might tune trainingdocuments (which mostly result automatic translation).language-specific classification performance much homogeneous JRCAcquis RCV1/RCV2. explained fact JRC-Acquis parallelcorpus, therefore language benefits information.significant difference performance among different languages, meanseffects due different difficulty various languages minor. Instead, differencesRCV1/RCV2 explained different amount information trainingsets carry corresponding test sets. example, Spanish classifier worstperformer, one obtains best benefit (with respect MonoBoWbaseline) addition polylingual information (as PolyBoW, LRI, MT).168fiLightweight Random Indexing Polylingual Text ClassificationFigure 2: Monolingual classification RCV1/RCV2 (top) JRC-Acquis (bottom), using F1M (left) F1 (right) evaluation measure.Note experiment matrices PolyBoW LRI feed learningalgorithm size. difference two methods, likelycause difference effectiveness, PolyBoW useful dimensionsspecific language packed specific portion vector space, LRI spreadsacross entire vector space, causing dimensions become potentially usefullanguages. Note substantial increase number useful dimensionsavailable language allows model create easily separable representations.discuss aspect Section 5.3.4.4.2 Dimensionality ReductionPolyBoW setup dimensionality vector space substantially increasedlanguages considered training. following experiments exploredimensionality reduction aspect problem, address realistic polylingualscenario, training test data contain examples language.169fiMoreo, Esuli, & SebastianinMonoBoWPolyBoWMTCL-LSAMDMACHRI1%LRI5000.2730.3650.4720.3660.4260.3751,0000.3530.3990.4930.3890.4830.464F1M5,0000.4440.5130.5390.54710,0000.4720.5300.5430.554full0.4730.4980.5090.5705000.6680.7650.7690.6210.6830.6791,0000.7360.7770.7710.6100.7050.736F15,0000.7860.7360.7560.79210,0000.7950.7550.7750.802full0.8020.8040.8080.811Figure 3: Effects dimensionality reduction RCV1/RCV2 (English Italian). Dottedlines indicate reference values, e.g., green red lines represent performanceLRI PolyBoW, respectively, dimensionality reduced. Valuesbold highlights best performing method dimension.first run sample bilingual experiment RCV1/RCV2 (as languageEnglish picked Italian). total amount features dataset51,828. Restricting experiment two languages allows us compare LRI (i)methods proposed bilingual representations (MDM), (ii) methodswould computationally expensive considering languages (such ACH,see below). explore effect dimensionality reduction, number selectedfeatures ranging 500 10,000 (Figure 3). adhere common practiceestablishes number dimensions ranging 500 1000 LSA MDM. Resultsrandom projection methods (ACH, RI1% , LRI) averaged 10 runs.LRI obtains good results macro- micro-averaged F1 , methods exhibit alternating performance two measures. RI1% obtains comparable resultsterms F1M performs poorly F1 ; contrast, PolyBoW performs comparablyterms F1 worse terms F1M . two-tailed t-test paired examples revealsdifference terms F1M LRI RI1% statistically significant,170fiLightweight Random Indexing Polylingual Text ClassificationnMonoBoWPolyBoWMTCL-LSARI1%LRI5000.2540.3510.3000.2701,0000.3080.3840.4020.376F1M5,0000.4200.4820.49110,0000.4450.5010.511full0.4150.4830.5210.5285000.6060.7280.5800.5731,0000.6570.7460.6490.659F15,0000.7470.6960.74910,0000.7640.7330.766full0.7530.7810.7930.786Figure 4: Accuracy different PLTC methods RCV1/RCV2 5 languages, differentlevels dimensionality reduction.LRI significantly outperforms RI1% F1 rest dimensionality reductionmethods evaluation measures, p < 0.001. Surprisingly, CL-LSA MDMperform worse nave classifier (MonoBoW) features. However,remarked outperform baselines 500 1000 dimensions.seen Section 5, apart drastic dimensionality reduction, methods affected large computational costs negatively impact run timesmemory resources needed. Consistently previous observations (see Figure 2), LRI,PolyBoW, MonoBoW, MT comparable terms F1 , LRI outperformstested algorithms terms F1M .test scalability method several languages involved, extendexperiment five languages (English, Italian, Spanish, French, German) RCV1/RCV2(Figure 4). Note case algorithms able complete executiondue memory constraints, hence incomplete plots table; concretely, ACHlast iterations RI1% overflowed memory resources trying allocate 28, 000123, 258 matrix. insights space time complexity reported Section 5.Results RI1% LRI average 10 runs use different random seeds.results confirm previous observations. RI1% behaves similarly LRI termsF1M (i.e., statistically significant difference) worse terms F1 (p <0.001),171fiMoreo, Esuli, & SebastianinPolyBoWCL-LSAPLDAMajority VoteRI1%LRI5000.3650.5700.4560.5430.5241,0000.4160.5930.4630.5810.581F1M5,0000.5340.6550.65910,0000.5700.6800.672full0.6400.6560.6885000.5600.7250.6440.6560.6601,0000.6060.7390.6500.6760.702F15,0000.6970.7430.76410,0000.7230.7700.776full0.7680.7590.789Figure 5: Accuracy different PLTC methods JRC-Acquis 5 languages, differentlevels dimensionality reduction.PolyBoW behaves opposite way, i.e., performs worse LRI termsF1M (p < 0.001) comparably terms F1 . dimensionality reduction method,LRI thus outperforms methods considering F1M F1 ;dimensionality reduction applied, upper bound MT comparable LRIF1M F1 .Finally, used JRC-Acquis reproduce one last polylingual scenario, namely, onetexts aligned document level. Even situation commonpractice (exceptions include, say, proceedings official events), scenario interestingsince dataset may serve test bed multiview learning methods (Amini et al.,2009). Since documents JRC-Acquis translated humans, results affectednoise MT tools might introduce. Figure 5 shows results obtained consideringcompacted matrix JRC-Acquis (a 4, 886 406, 934 matrix), also tested Majority Voting, combines classification decisions five independently trainedMonoBoW classifiers parallel versions documents, PLDA, first definesgenerative model based polylingual topics trains tests probability distributions topics assigned document. set number polylinguallatent topics 500 1000, respectively.LRI clearly superior PolyBoW case. difference performanceLRI RI1% seems lower case, especially terms F1M ; t-test revealed172fiLightweight Random Indexing Polylingual Text Classificationhowever LRI superior RI1% statistically significant sense (p <0.001). However,considered LRI delivers best performance without reducing dimensionality polylingual matrix, RI1% able accomplish projection duememory restrictions; something expand following section. PLDA,turn, succeeded discovering polylingual topics aligned across languages,proved less effective terms classification performance.5. Analysisexperiments observed substantial differences terms efficiency amongcompared methods, particularly ACH, RI1% , LRI. example, RI1%exhausted memory resources n 10, 000, LRI able represent even fullsized |D||F | matrix (see Figure 4). Given strong relationship two methods,would expected delivered similar performance. anomaly prompted usinvestigate issue depth. section presents analytical study termsefficiency methods discussed previous section.5.1 Space EfficiencyData samples ML usually represented co-occurrence matrix. TC matrixsuffers high-dimensionality, luckily enough also sparse. sparse, low-densitymatrix suggests use non-exhaustive data-structure, zero valuesstored explicitly.random projection direct impact sparsity. feature containeddocument, k non-zero values placed projected matrix. ACH situationworse, since feature mapped, average, n/3 non-zero values. example,n = 5, 000 feature mapped 50 1,666 non-zero values RI1%ACH, respectively.example, rerun RCV1/RCV2 experiments English Italianlanguages, examined matrix density (percentage non-zero valuestotal matrix size) memory footprint (absolute number non-zero values).results displayed Figure 6.LRI requires double space respect standard BoW, succeeds preservingsparsity, RI1% drastically increases matrix density produces large memoryfootprint. MDM, LSA, ACH operate dense matrices. However, since MDMLSA produce extreme dimensionality reduction, overall memory footprint remainsmuch lower RI1% and, especially, ACH. n = |F |, LRI must allocate1, 844103 values (this indicated LRI (full) Figure 6), RI1% (n = 5000)must allocate 28, 463 103 values (requiring 15.42 times space); ACH (n = 5000)must allocate 55, 998 103 values (30.35 times space). Note even though MDMLSA reduce significantly dimensionality (e.g., 51,828 500, 1,000),need allocate values memory LRI (full).example, let us suppose non-zero value represented double(typically: 8 bytes modern programming languages); means roughly need428MB ACH 218MB RI1% , whereas LRI requires 15MB. Althoughdifference substantial, (even taking account actual memory needed higher173fiMoreo, Esuli, & SebastianiFigure 6: Matrix density (left) memory footprint (right) RCV1/RCV2 EnglishItalian run (11, 200 51, 828 full training matrix size).values indexed hash table) still represent real problemterms space modern computers. However, note matrixdata structure need allocate memory. Also mapping dictionary, i.e., datastructure linking original feature random index vector, allocatedmemory. dictionary queried many times terms documentwant classify. dictionary small enough (which LRI), may ableallocate cache order significantly speed indexing new documents.Assuming sparse representation, random index vector described list kpairs (di , vi ), di indicates latent dimension vi encodes value. example,k = 2 random vector (0, 0, +1, 0, 1, 0, ...) could represented [(3, 1), (5, 0)],bit set 1 encodes +1 bit set 0 encodes 1. Equation 5,space occupation dictionary random indexing method depends (i) |F |,number indexes; (ii) k, number non-zero values index; (iii)number bits needed indicate one latent position encode possible non-trivialvalues; is,Cost(RIk ) = O(|F | k (log2 n + log2 2))(5)turns that, given expected number non-zero values ACH n/3, usingdense representation index cheaper. position thus indicates onethree possible values index. cost terms space ACH index dictionarydescribedCost(ACH) = O(|F | n log2 3)174(6)fiLightweight Random Indexing Polylingual Text ClassificationMethodLRIRI1%ACHIndex typesparsesparsedenseIndex size210010,000Index celllog2 n + log2 2 bits encode dimi vali , resp.log2 n + log2 2 bits encode dimi vali , resp.log2 3 bits encode ijMemory required1.39MB69.31MB768.87MBTable 3: Memory occupation feature dictionary different random mapping methods JRC-Acquis dataset (|F | = 406, 934). meanings dimi valiAlgorithm 1. meaning ij Equation 1.Assuming reduced dimensionality set fixed percentage original dimensionality, i.e., n = |F | 0 < 1, following hold:Cost(RI) = O(|F |2 log2 |F |) >Cost(ACH) = O(|F |2 ) >(7)Cost(LRI) = O(|F | log2 |F |)However, hidden constants play key role practice. example, computedtotal amount memory required method storing index dictionariesn = 10, 000 JRC-Acquis, |F | = 406, 934; resulting values reported Table3. observed, index dictionary ACH requires 769MB, spacerequired RI-based versions one three orders magnitude smaller.words, index dictionary LRI could easily fit current cache memories, RI1%ACH need resort higher-capacity, thus slower, storage devices.5.2 Time Efficiencyusually case sparsity benefits space occupation, also executiontime. example, computational cost SVD O(|F |2 |D|) document-by-termmatrix; however, implementation SVDLIBC specifically optimized sparse matricesrequires O(c|F ||D|) steps, c average number non-zero values vector.Figure 7 plot run times experiments bilingual (English-Italian)RCV1/RCV2 experiment paying attention time required (i) obtainingtransformed index training set, (ii) training learning algorithm (SVM), (iii)obtaining transformed index test set, (iv) classifying test documents.experiments run Intel i7 64bit processor 12 cores, running1,600MHz, 24GBs RAM memory.results show takes 3.5 minutes generate test classifieruses BoW representation. Time slightly reduced 3 minutes5000 features selected. total time LRI roughly higher factor 2,7.3 (full) 6.6 (n = 5000) minutes, respectively. Notwithstanding this, figuresstill low compared methods: training testing times growsubstantially RI ACH. Regarding latent methods, pointedtime required preparing matrices also grow substantially, due large175fiMoreo, Esuli, & SebastianiFigure 7: Run times RCV1/RCV2 (English Italian setting).computational cost inherent SVD matrix multiplication, case randomindexing methods times negligible.comparing overall memory footprint (Figure 6, right) execution times (Figure 7) seems clear strong correlation them. investigateddependency experiments computing Pearson correlation them.Pearson correlation quantifies degree linear dependence two variables,ranges 1, meaning perfect negative correlation, +1, meaning perfect positivecorrelation, whereas 0 means linear dependency. found linearPearson correlation +0.988 +0.998 number non-zero valuesmatrix times required training testing, respectively, brings additionalsupport observation: preserving sparsity projection favours executiontimes PLTC.5.3 Effect k Random IndexingPrevious work RI (see, e.g., Sahlgren & Karlgren, 2005; Sahlgren & Coster, 2004) tendset k 1% dimension vector; smaller values k (about k = 0.1%)also explored (Karlgren, Holst, & Sahlgren, 2008). works related randomprojections (see, e.g., Achlioptas, 2001; Li et al., 2006) noticed sparse projectionmatrices help speed computation.Besides run times, sparsity projection matrix also affects orthogonalityrandom projection, turn impact preservation relativedistances. Two random vectors ri rj said orthogonal angle90 degrees. Although probability two randomly picked vectorsorthogonal increases dimensionality vector space grows (Karlgren et al., 2008),random projection approaches choose sparse random vectors, maximizeprobability.176fiLightweight Random Indexing Polylingual Text ClassificationFigure 8: Probability distribution angle two arbitrary vectors highdimensional space (left), excess kurtosis function non-zero valuesprojection matrix 10,000 dimensions (right).could thus establish parallelism degree orthogonality projection matrix probability distribution angle two random vectors.probability distribution skewed towards 90 degrees, closer orthogonalprojection base is, better distances preserved. propose quantifyorthogonality means excess kurtosis distribution angle4 . aim,studied kurtosis angle distributions (as estimated via Monte Carloalgorithm) varies function matrix sparsity k 10,000-dimension projectionmatrix (Figure 8, right).Figure 8 shows orthogonality projection, fixed dimensionality,rapidly degrades density increases. LRI thus expected produce nearlyorthogonal indexing, followed RI ACH.investigated relation orthogonality PLTC accuracy.aim, run series experiments bilingual version RCV1/RCV2,varying (from 2 100) number k non-zero values (from 1,000 10,000)reduced dimensionality n. Figure 9 shows contour lines (equally valued points3-dimensional representation) classification performance (here measured termsF1 ), execution time, probability pairwise orthogonality (i.e., probabilityhri , rj = 0 two randomly chosen random index vectors).following trends directly observed results: (i) accuracy improvesn increases k decreases; (ii) run times tend grow n k increase,(iii) higher dimensionality n smaller parameter k, higherprobability finding two orthogonal random indexes.4. excess kurtosis random variable X typically defined fourth standardized moment minus3, i.e., EKurt[X] = 44 3.177fiMoreo, Esuli, & SebastianiFigure 9: Impact dimensionality n (on x axis) number k non-zero values (onaxis) classification accuracy (left), execution time (center), probabilityfinding orthogonal pair random indexes (right). Darker regions representlower values.Figure 9, behaviour LRI method propose described greenhorizontal line bottom plot, RIs behaviour described bluediagonal line coordinates (n = 1, 000, k = 10) (n = 10, 000, k = 100). performance RI improves cost space time efficiency, gradually disruptingorthogonality base. contrary, following desirable features LRIevident: dimensionality increases (i) accuracy improves without penalizing executiontimes, due preservation sparsity, (ii) orthogonality base improved.6. Conclusionscompared several techniques polylingual text classification, checking suitability dimensionality reduction techniques techniques generation alternative representations co-occurrence matrix, two PLTC benchmarks (one parallelone comparable). investigation indicates reducing dimensionalitydata sufficient reasonable efficiency (in terms time space) required.Based observation proposed variant Random Indexing, method originated within IR community that, best knowledge, never testedPLTC date. proposal, Lightweight Random Indexing, yielded best resultsterms (both time space) efficiency, also terms classification accuracy,Lightweight Random Indexing obtained best results terms macroand micro-averaged F1 . Lightweight Random Indexing preserves matrix sparsity,means memory footprint training time penalized. example,Figures 6 7 may see Lightweight Random Indexing (in full configurationis, random vectors dimensionality original space)improved Latent Semantic Analysis (in n = 1, 000 configuration is,178fiLightweight Random Indexing Polylingual Text Classificationdimensionality reduced space 1,000) margin +4.37% terms F189.69% reduction execution time 82.60% reduction memory footprint.Even though Lightweight Random Indexing works well dimensionality reduction method, achieves best performance projection reduceoriginal dimensionality. Apparently, BoW representation might expectedpreferable case, truly orthogonal. However, polylingual BoWrepresentation features informative restricted set data; e.g.,German term entire dimension reserved vector space model,dimension useful documents written German. Random projections insteadmap feature space space shared among languages once. effectdimension space becomes informative represent documents regardlesslanguage originally written in. configuration, projectionspace larger actual number different features single language, reminiscent kernel-trick effect, informative space language enlargedthus becomes easily separable.light experiments, Lightweight Random Indexing important advantagesrespect previous PLTC approaches. First, method machine translationfree, dictionary-free, require sort additional resources apartlabelled collection. projected matrix preserves sparsity, direct effectreducing running time total memory usage. respect original randomindexing technique, Lightweight Random Indexing presents following advantages: (i)probability finding pair truly orthogonal indexes higher; (ii) requires less memoryallocate index dictionary; (iii) avoids need tuning k parameter.LRI proven effective PLTC, conjecture could bring similarbenefits related tasks, CLTC, cross-lingual information retrieval, welltackling problems dealing sparse heterogeneous sources data general.discussed above, one reasons k = 2 safe configuration still preservesrepresentation capacity. However, might hold circumstances; e.g.,processing huge streams dynamic data (e.g., streams tweets), certainpoint representation capacity might saturate dimensionality spacechosen carefully. cases, opting configurations k > 2 might mitigateproblem.Another fact emerges experiments dimensionality reductionnecessarily synonym computational efficiency. reason modern secondarystorage data structures optimized operate sparse data, dimensionality drastically reduced, matrix density may increase, net effect may decreaseefficiency. true benefit thus achieved extent trade-off sparsityseparability preserved; dimension, LRI proved extremely effective.Although results encouraging, investigations still needed shedlight foundations random projection methods. first question whethercriterion better choose random index vectors; given current criterionrandom, seems might room better motivated strategies, possibly leveragingclass labels taking account document language labels. ConsideringRandom Indexing originally proposed context IR community, wonderwhether proposed approach could produce similar improvements IR tasks179fiMoreo, Esuli, & Sebastianiquery expansion bilingual lexicon acquisition. Finally, could interesting combineLightweight Random Indexing Reflexive Random Indexing (Cohen, Schvaneveldt, &Widdows, 2010; Rangan, 2011), recent formulation model iterativelyalternates row indexing column indexing original co-occurrence matrix.AcknowledgementsFabrizio Sebastiani leave Consiglio Nazionale delle Ricerche, Italy.ReferencesAchlioptas, D. (2001). Database-friendly random projections. Proceedings 20thACM Symposium Principles Database Systems (PODS 2001), pp. 274281,Santa Barbara, US.Al-Rfou, R., Perozzi, B., & Skiena, S. (2013). Polyglot: Distributed word representationsmultilingual NLP. Proceedings 17th Conference Computational NaturalLanguage Learning (CoNLL 2013), pp. 183192, Sofia, BL.Amini, M.-R., & Goutte, C. (2010). co-classification approach learning multilingual corpora. Machine Learning, 79 (1/2), 105121.Amini, M.-R., Usunier, N., & Goutte, C. (2009). Learning multiple partially observedviews; application multilingual text categorization. Proceedings 23rdAnnual Conference Neural Information Processing Systems (NIPS 2009), pp. 2836, Vancouver, CA.Baroni, M., Dinu, G., & Kruszewski, G. (2014). Dont count, predict! systematic comparison context-counting vs. context-predicting semantic vectors. Proceedings52nd Annual Meeting Association Computational Linguistics (ACL2014), pp. 238247, Baltomore, US.Bel, N., Koster, C. H., & Villegas, M. (2003). Cross-lingual text categorization. Proceedings 7th European Conference Research Advanced TechnologyDigital Libraries (ECDL 2003), pp. 126139, Trondheim, NO.Bengio, Y. (2009). Learning deep architectures AI. Foundations Trends MachineLearning, 2 (1), 1127.Bengio, Y., Schwenk, H., Senecal, J.-S., Morin, F., & Gauvain, J.-L. (2006). Neural probabilistic language models. Innovations Machine Learning, pp. 137186. Springer,Heidelberg, DE.Bingham, E., & Mannila, H. (2001). Random projection dimensionality reduction: applications image text data. Proceedings 7th ACM InternationalConference Knowledge Discovery Data Mining (KDD 2001), pp. 245250, SanFrancisco, US.Blei, D. M., Ng, A. Y., & Jordan, M. I. (2003). Latent Dirichlet allocation. JournalMachine Learning Research, 3, 9931022.180fiLightweight Random Indexing Polylingual Text ClassificationBullinaria, J. A., & Levy, J. P. (2007). Extracting semantic representations wordco-occurrence statistics: computational study. Behavior Research Methods, 39 (3),510526.Chandar, S., Lauly, S., Larochelle, H., Khapra, M. M., Ravindran, B., Raykar, V. C., & Saha,A. (2014). autoencoder approach learning bilingual word representations.Proceedings 28th Annual Conference Neural Information Processing Systems(NIPS 2014), pp. 18531861, Montreal, CA.Cohen, T., Schvaneveldt, R., & Widdows, D. (2010). Reflective random indexing indirect inference: scalable method discovery implicit connections. JournalBiomedical Informatics, 43 (2), 240256.Collobert, R., Weston, J., Bottou, L., Karlen, M., Kavukcuoglu, K., & Kuksa, P. (2011).Natural language processing (almost) scratch. Journal Machine LearningResearch, 12, 24932537.de Melo, G., & Siersdorfer, S. (2007). Multilingual text classification using ontologies.Proceedings 29th European Conference Information Retrieval (ECIR 2007),pp. 541548, Roma, IT.Deerwester, S. C., Dumais, S. T., Furnas, G. W., Landauer, T. K., & Harshman, R. A.(1990). Indexing latent semantic analysis. Journal American SocietyInformation Science, 41 (6), 391407.Dumais, S. T., Letsche, T. A., Littman, M. L., & Landauer, T. K. (1997). Automatic crosslanguage retrieval using latent semantic indexing. Working Notes AAAISpring Symposium Cross-language Text Speech Retrieval, pp. 1824, Stanford,US.Ehrmann, M., Cecconi, F., Vannella, D., McCrae, J. P., Cimiano, P., & Navigli, R. (2014).Representing multilingual data linked data: case BabelNet 2.0. Proceedings 9th Conference Language Resources Evaluation (LREC 2014), pp.401408, Reykjavik, IS.Esuli, A., Fagni, T., & Moreo, A. (2016). JaTeCS (Java Text Categorization System).Github. Retrieved September 11, 2016, https://github.com/jatecs/jatecs.Faruqui, M., & Dyer, C. (2014). Improving vector space word representations using multilingual correlation. Proceedings 14th Conference European ChapterAssociation Computational Linguistics (EACL 2014), pp. 462471, Gothenburg,SE.Forman, G. (2004). pitfall solution multi-class feature selection text classification. Proceedings 21st International Conference Machine Learning(ICML 2004), pp. 3845, Banff, CA.Fradkin, D., & Madigan, D. (2003). Experiments random projections machinelearning. Proceedings 9th ACM International Conference KnowledgeDiscovery Data Mining (KDD 2003), pp. 517522, Washington, US.Garca Adeva, J. J., Calvo, R. A., & Lopez de Ipina, D. (2005). Multilingual approachestext categorisation. European Journal Informatics Professional, 6 (3), 4351.181fiMoreo, Esuli, & SebastianiGliozzo, A., & Strapparava, C. (2005). Cross-language text categorization acquiringmultilingual domain models comparable corpora. Proceedings ACLWorkshop Building Using Parallel Texts, pp. 916, Ann Arbor, US.Gliozzo, A., & Strapparava, C. (2006). Exploiting comparable corpora bilingual dictionaries cross-language text categorization. Proceedings 44th AnnualMeeting Association Computational Linguistics (ACL 2006), pp. 553560,Sydney, AU.Gorman, J., & Curran, J. R. (2006). Random indexing using statistical weight functions.Proceedings 4th Conference Empirical Methods Natural Language Processing (EMNLP 2006), pp. 457464, Sydney, AU.Gouws, S., & Sgaard, A. (2015). Simple task-specific bilingual word embeddings.Proceedings North American Chapter Association ComputationalLinguistics Human Language Technologies Conference (NAACL-HLT 2015), pp.13861390.Haddow, B., Hoang, H., Bertoldi, N., Bojar, O., & Heafield, K. (2016). MOSES statisticalmachine translation system. Moses website. Retrieved September 11, 2016,http://www.statmt.org/moses/.Harris, Z. S. (1968). Mathematical structures language. Wiley, New York, US.Hecht-Nielsen, R. (1994). Context vectors: General-purpose approximate meaning representations self-organized raw data. Computational Intelligence: Imitating Life,pp. 4356. IEEE Press.Hermann, K. M., & Blunsom, P. (2014). Multilingual models compositional distributedsemantics. Proceedings 52nd Annual Meeting Association Computational Linguistics (ACL 2014), pp. 5868, Baltimore, US.Joachims, T. (2009). SVMperf: Support Vector Machine multivariate performancemeasures. Cornell University website. Retrieved September 11, 2016,http://www.cs.cornell.edu/people/tj/svm_light/svm_perf.html.Joachims, T. (2005). support vector method multivariate performance measures.Proceedings 22nd International Conference Machine Learning (ICML 2005),pp. 377384, Bonn, DE.Johnson, W. B., Lindenstrauss, J., & Schechtman, G. (1986). Extensions Lipschitz mapsBanach spaces. Israel Journal Mathematics, 54 (2), 129138.Jurgens, D., & Stevens, K. (2009). Event detection blogs using temporal random indexing.Proceedings Workshop Events Emerging Text Types, pp. 916, Borovets,BG.Kanerva, P., Kristofersson, J., & Holst, A. (2000). Random indexing text samples latent semantic analysis. Proceedings 22nd Annual Conference CognitiveScience Society (CogSci 2000), p. 1036, Philadelphia, US.Karlgren, J., Holst, A., & Sahlgren, M. (2008). Filaments meaning word space.Proceedings 30th European Conference Information Retrieval (ECIR 2008),pp. 531538, Glasgow, UK.182fiLightweight Random Indexing Polylingual Text ClassificationKaski, S. (1998). Dimensionality reduction random mapping: Fast similarity computationclustering. Proceedings IEEE International Joint Conference NeuralNetworks (IJCNN 1998), pp. 413418, Anchorage, US.Klementiev, A., Titov, I., & Bhattarai, B. (2012). Inducing crosslingual distributed representations words. Proceedings 24th International Conference Computational Linguistics (COLING 2012), pp. 14591474, Mumbai, IN.Koehn, P. (2005). Europarl: parallel corpus statistical machine translation. MTsummit, Vol. 5, pp. 7986. Publicly available http://www.statmt.org/europarl/.Lauly, S., Boulanger, A., & Larochelle, H. (2014). Learning Multilingual Word Representations using Bag-of-Words Autoencoder. ArXiv e-prints, arXiv:1401.1803 [cs.CL].Lewis, D. D., Yang, Y., Rose, T. G., & Li, F. (2004). Rcv1: new benchmark collectiontext categorization research. Journal machine learning research, 5 (Apr), 361397.Publicly available http://www.jmlr.org/papers/volume5/lewis04a/lyrl2004_rcv1v2_README.htm.Li, P., Hastie, T. J., & Church, K. W. (2006). sparse random projections. Proceedings12th ACM SIGKDD International Conference Knowledge DiscoveryData Mining (KDD 2006), pp. 287296, Philadelphia, US.Li, Y., & Shawe-Taylor, J. (2007). Advanced learning algorithms cross-language patentretrieval classification. Information Processing Management, 43 (5), 11831199.Mikolov, T., Le, Q. V., & Sutskever, I. (2013a). Exploiting Similarities among LanguagesMachine Translation. ArXiv e-prints, arXiv:1309.4168 [cs.CL].Mikolov, T., Sutskever, I., Chen, K., Corrado, G. S., & Dean, J. (2013b). Distributedrepresentations words phrases compositionality. Proceedings27th Annual Conference Neural Information Processing Systems (NIPS 2013), pp.31113119, Lake Tahoe, US.Mimno, D., Wallach, H. M., Naradowsky, J., Smith, D. A., & McCallum, A. (2009). Polylingual topic models. Proceedings 2009 Conference Empirical MethodsNatural Language Processing (EMNLP 2009), pp. 880889, Singapore, SN.Moreo, A. (2016). Data resources reproducing experiments polylingual text classification. Human Language Technologies (HLT) group website. Retrieved September11, 2016, http://hlt.isti.cnr.it/pltc.Nastase, V., & Strapparava, C. (2013). Bridging languages etymology: casecross-language text categorization. Proceedings 51st Annual MeetingAssociation Computational Linguistics (ACL 2013), pp. 651659, Sofia, BL.Osterlund, A., Odling, D., & Sahlgren, M. (2015). Factorization latent variables distributional semantic models. Proceedings Conference Empirical MethodsNatural Language Processing (EMNLP 2015), pp. 227231, Lisbon, PT.Pan, S. J., & Yang, Q. (2010). survey transfer learning. IEEE TransactionsKnowledge Data Engineering, 22 (10), 13451359.183fiMoreo, Esuli, & SebastianiPapadimitriou, C. H., Raghavan, P., Tamaki, H., & Vempala, S. (1998). Latent semanticindexing: probabilistic analysis. Proceedings 17th ACM SymposiumPrinciples Database Systems (PODS 1998), pp. 159168, Seattle, US.Pennington, J., Socher, R., & Manning, C. D. (2014). Glove: Global vectors wordrepresentation. Proceedings Conference Empirical Methods NaturalLanguage Processing (EMNLP 2014), pp. 15321543, Doha, QA.Prettenhofer, P., & Stein, B. (2010). Cross-language text classification using structuralcorrespondence learning. Proceedings 48th Annual Meeting AssociationComputational Linguistics (ACL 2010), pp. 11181127, Uppsala, SE.Rangan, V. (2011). Discovery related terms corpus using reflective random indexing. Proceedings ICAIL 2011 Workshop Setting Standards SearchingElectronically Stored Information, Pittsburgh, US.Richardson, J. (2008). PolyLDA++. Atlassian Bitbucket. Retrieved September 11, 2016,https://bitbucket.org/trickytoforget/polylda.Rigutini, L., Maggini, M., & Liu, B. (2005). EM-based training algorithm crosslanguage text categorization. Proceedings 3rd IEEE/WIC/ACM International Conference Web Intelligence (WI 2005), pp. 529535, Compiegne, FR.Rohde, D. (2011). C library computing singular value decompositions. SVDLIBC.Retrieved September 11, 2016, http://tedlab.mit.edu/~dr/SVDLIBC/.Sahlgren, M. (2001). Vector-based semantic analysis: Representing word meanings basedrandom labels. Proceedings ESSLLI Workshop Semantic KnowledgeAcquistion Categorization, Helsinki, FI.Sahlgren, M. (2005). introduction random indexing. Proceedings WorkshopMethods Applications Semantic Indexing, Copenhagen, DK.Sahlgren, M. (2006). Word-Space Model: Using distributional analysis represent syntagmatic paradigmatic relations words high-dimensional vector spaces.Ph.D. thesis, Swedish Institute Computer Science, University Stockholm, Stockholm, SE.Sahlgren, M., & Coster, R. (2004). Using bag-of-concepts improve performancesupport vector machines text categorization. Proceedings 20th International Conference Computational Linguistics (COLING 2004), Geneva, CH.Sahlgren, M., & Karlgren, J. (2005). Automatic bilingual lexicon acquisition using randomindexing parallel corpora. Natural Language Engineering, 11 (3), 327341.Sahlgren, M., Karlgren, J., Coster, R., & Jarvinen, T. (2002). SICS CLEF 2002: Automatic query expansion using random indexing. Working Notes CrossLanguage Evaluation Forum Workshop (CLEF 2002), pp. 311320, Roma, IT.Steinberger, R., Pouliquen, B., & Ignat, C. (2004). Exploiting multilingual nomenclatureslanguage-independent text features interlingua cross-lingual text analysisapplications. Proceedings 4th Slovenian Language Technology Conference,Ljubljana, SL.184fiLightweight Random Indexing Polylingual Text ClassificationSteinberger, R., Pouliquen, B., Widiger, A., Ignat, C., Erjavec, T., Tufis, D., & Varga,D. (2006). JRC-Acquis: multilingual aligned parallel corpus 20+ languages. Proceedings 5th International Conference Language ResourcesEvaluation (LREC 2006), pp. 21422147, Genova, IT. Publicly availablehttps://ec.europa.eu/jrc/en/language-technologies/jrc-acquis.Vinokourov, A., Shawe-Taylor, J., & Cristianini, N. (2002). Inferring semantic representation text via cross-language correlation analysis. Proceedings 16th AnnualConference Neural Information Processing Systems (NIPS 2002), pp. 14731480,Vancouver, CA.Vulic, I., & Moens, M.-F. (2015). Monolingual cross-lingual information retrieval modelsbased (bilingual) word embeddings. Proceedings 38th International ACMSIGIR Conference Research Development Information Retrieval (SIGIR2015), pp. 363372, Santiago, CL.Wei, C.-P., Lin, Y.-T., & Yang, C. C. (2011). Cross-lingual text categorization: Conqueringlanguage boundaries globalized environments. Information Processing Management, 47 (5), 786804.Wei, C.-P., Yang, C.-S., Lee, C.-H., Shi, H., & Yang, C. C. (2014). Exploiting poly-lingualdocuments improving text categorization effectiveness. Decision Support Systems,57, 6476.Xiao, M., & Guo, Y. (2013). novel two-step method cross-language representationlearning. Proceedings 27th Annual Conference Neural Information Processing Systems (NIPS 2013), pp. 12591267, Lake Tahoe, US.Xu, C., Tao, D., & Xu, C. (2013). survey multi-view learning. ArXiv e-prints,arXiv:1304.5634 [cs.LG].Yang, Y., & Pedersen, J. O. (1997). comparative study feature selection text categorization. Proceedings 14th International Conference Machine Learning(ICML 1997), pp. 412420, Nashville, US.Zou, W. Y., Socher, R., Cer, D. M., & Manning, C. D. (2013). Bilingual word embeddingsphrase-based machine translation. Proceedings Conference EmpiricalMethods Natural Language Processing (EMNLP 2013), pp. 13931398, Melbourne,AU.185fiJournal Artificial Intelligence Research 57 (2016) 39-112Submitted 4/16; published 9/16PDT Logic: Probabilistic Doxastic Temporal LogicReasoning Beliefs Multi-agent SystemsKarsten MartinyRalf Mollerkarsten.martiny@uni-luebeck.demoeller@uni-luebeck.deInstitute Information Systems,Universitat zu LubeckLubeck, GermanyAbstractpresent Probabilistic Doxastic Temporal (PDT) Logic, formalism representreason probabilistic beliefs temporal evolution multi-agent systems.formalism enables quantification agents beliefs probability intervalsincorporates explicit notion time. discuss time agents dynamicallychange beliefs facts, temporal rules, agents beliefs respectnew information receive. introduce appropriate formal semantics PDT Logicshow decidable. Alternative options specifying problems PDT Logicpossible. problem specifications, develop different satisfiability checkingalgorithms provide complexity results respective decision problems. useprobability intervals enables formal representation probabilistic knowledge withoutenforcing (possibly incorrect) exact probability values. incorporating explicit notiontime, PDT Logic provides enriched possibilities represent reason temporalrelations.1. IntroductionLogical analysis knowledge belief active topic research diverse fieldsphilosophy (Hintikka, 1962), economics (Aumann, 1976), game theory (Harsanyi,1967, 1968a, 1968b), computer science (Fagin, Halpern, Moses, & Vardi, 1995). Numerous extensions modal epistemic logic made reason knowledgemulti-agent settings (Fagin et al., 1995; Baltag & Moss, 2004), add probabilistic knowledge (Fagin & Halpern, 1994; Cripps, Ely, Mailath, & Samuelson, 2008), analyzedynamic evolution knowledge (van Ditmarsch, van der Hoek, & Kooi, 2007).realistic scenarios, agent incomplete inaccurate informationactual state world, thus considers several different worlds actuallypossible. receives new information (e.g., observes facts currentlyhold), update beliefs possible worlds consistentnew information. updates example result regarding (previouslyconsidered possible) worlds impossible judging worlds likelybefore. Thus, addition analyzing set worlds agent believes possible,also useful quantify beliefs terms probabilities. provides meansspecify fine-grained distinctions range worlds agent considers possiblehighly unlikely, worlds seem almost certainly actual world.c2016AI Access Foundation. rights reserved.fiMartiny & Mollermultiple agents involved setting, agent may varyingbeliefs regarding facts actual world, also regarding beliefs agents.many scenarios, actions one agent depend belief ontic facts(i.e., facts actual world), also beliefs agents beliefs.illustrate reasoning agents beliefs yield significant advantagespractical scenarios, start following informal description applicationcyber security domain (a formal analysis example using PDT Logicpresented Martiny, Motzek, & Moller, 2015): Suppose adversary tryingbreak computer system. usually done attack graph detectexploit potential vulnerabilities system. attack graph specifies setpaths (i.e., sequences actions) carry attack. Several paths attack graphmight used parallel, potentially different agents (for instance, number infectedcomputers controlled botnet). Usually, attack patterns specified one attack graphused multiple times, two important ramifications: adversary learnexperience paths yield high probability successfully breakingsystem. Defenders turn able gain knowledge attack graphrepeated observation certain patterns. Thus, system attack, defenderbeliefs chosen attack paths adversarys belief regardingsuccess respective path. Thus, defender choose countermeasures effectivelyreacting paths nested beliefs high indeed pose threataccording systems mission impact model.formalize reasoning beliefs multi-agent settings, present Probabilistic Doxastic Temporal (PDT) Logic. PDT Logic builds upon recent work AnnotatedProbabilistic Temporal (APT) Logic (Shakarian, Parker, Simari, & Subrahmanian, 2011;Shakarian, Simari, & Subrahmanian, 2012) provides formalism enables representing reasoning dynamically changing quantified temporal multi-agent beliefsprobability intervals incorporates subset epistemic actions (Baltag & Moss,2004). Using concepts APT Logic semantic foundation, PDT Logic merges workepistemic logic recent work temporal logic Shakarian et al. Apartreasoning imprecise probabilities, introduces temporal concept frequencyfunctions epistemic temporal logic.Quantifying probabilistic knowledge probability intervals instead single probability values yields two main advantages. one hand, using probability intervalssignificantly eases task formally representing existing knowledge human domainexpert. cases, domain expert give reasonable probability estimatesknowledge, inevitably fail giving correct precise numerical values probabilities. Consider instance weather forecast: people find easy give coarseprobabilistic quantifications chance rain high, virtually nobodycould quantify exact numerical value. Employing exact numerical valuesformal representation would inevitably introduce errors probability model.Thus, use probability intervals provides means express probabilistic knowledgeprecisely possible without enforcing unrealistic precision. hand,many scenarios probabilities (and even rough estimates them) simply unavailable, bounds values may known. illustrate this, consider scenariodescribed Ellsberg (1961):40fiPDT LogicExample 1.1 (The Ellsberg paradox, Ellsberg, 1961). Imagine urn known contain30 red balls 60 black yellow balls, latter unknown proportion. One balldrawn random urn; following actions considered: Actionbet red, II bet black.Now, easy see rational agent would believe action successfulprobability 1/3. action II, quantification possiblerespective probability unknown. Yet omitting probabilistic information actionII altogether would ignore available information unknown probability value,namely somewhere 0 2/3. example exhibits two different typesuncertainty: former action subject risk, i.e., outcome unknown,occurs known probability, later action subject ambiguity (also knownKnightian uncertainty), probability unknown (Bradley, 2015).probability intervals, PDT Logic able work imprecise probabilities.width probability interval give additional information certaintyprobability quantification. Naturally, narrow interval associated high certaintyrespective probability vice versa, wide interval associated low certainty.PDT Logic employs explicit notion time thereby facilitates expressionricher temporal relations. allows analysis temporal doxastic problemsbeyond scope previous work. resulting framework provides means reasontemporal evolution beliefs multi-agent systems. Two different applicationsframework possible: First, agent respective multi-agent systememploy framework online run system reason beliefs.analyzing nested beliefs introduced above, gives agent also means reasonprobable evolutions agents belief states. Second, framework usedoffline external observer analyze whether desired evolutions given systempossible.remainder work structured follows: next section presents relatedwork knowledge multi-agent systems APT Logic. Then, Section 3,syntax PDT Logic introduced, followed definition formal semantics. Decisionalgorithms complexity results PDT Logic discussed Section 4.formally defined semantics based precise probability values, section showssatisfiability PDT Logic decided even imprecise probabilities given.Finally, paper concludes Section 5.2. Related WorkApproaches formalize reasoning knowledge belief date back Hintikkas workepistemic logic (Hintikka, 1962). Hintikka proposed represent knowledge setsstates worlds, together binary relation every agent, determine worldsindistinguishable agent. approach sparked multiple branches researchepistemic logic, still active topics research today. branches researchbroadly classified four (not mutually exclusive) areas relevantwork: multi-agent epistemic logic, probabilistic epistemic logic, epistemic temporal logic,41fiMartiny & Mollerdynamic epistemic logic.1 following, give overview key contributionsarea discuss existing approaches merge fields research.Early research epistemic logic culminated influential work ReasoningKnowledge (Fagin et al., 1995), provides unified presentation various precedingcontributions epistemic logic. work uses so-called interpreted systems approachrepresent knowledge multi-agent systems, time represented runs.run sequence systems global states thus identifies state systemevery time point. Among contributions, work provides notions multiagent epistemic modalities nested knowledge, distributed knowledge, commonknowledge.Several works extended epistemic logic represent dynamic evolutions knowledge. direction research known Dynamic Epistemic Logic (DEL). first formalanalysis dynamics knowledge presented Plaza (1989; reprinted Plaza,2007). contribution, Plaza introduces public communication events (now commonlyknown public announcements) analyze dynamic evolution knowledge groupsupon truthful public announcements facts group agents. IndependentlyPlaza, related approach public announcement logic proposed GerbrandyGroeneveld (1997). Baltag, Moss, Solecki (1998) Baltag Moss (2004) generalize dynamic approach epistemic logic incorporate variety complex epistemicactions. Here, epistemic updates represented Kripke models.extends dynamic epistemic logic represent variety additional epistemic actionsprivate group announcements (i.e., announcements agents outside receivinggroup unaware announcement), lies (i.e., untruthful announcements), combinations thereof. PDT Logic, use public private group announcements,assume announcements truthful. thorough treatment dynamic epistemiclogic given van Ditmarsch et al. (2007). Van Eijck (2014) provides recent overviewfield.alternative approach modeling evolution knowledge combine epistemiclogic temporal system. One example aforementioned interpretedsystems Fagin et al. (1995). Another approach modeling temporal aspects epistemic logic proposed Parikh Ramanujam (2003). approach knownEpistemic Temporal Logic (ETL). Here, possible situations represented setshistories, local histories every agent, represent respective agents previousobservations. Based histories, knowledge based semantics messages defined,shown messages vary meaning, depending respective contextmessages receiver. temporal model employ PDT Logic closely relatedepistemic temporal logic. Instead specifying local histories every agent, definesemantics PDT Logic respect global history. However, local contexts1. simplify following discussion, explicitly distinguish epistemic doxasticlogics section, use epistemic general term. Strictly speaking, epistemic formalismsdeal knowledge, doxastic formalisms deal beliefs. usual axiomatic definitionknowledge literature uses Truth Axiom, stipulates agent know truefacts. Omitting axiom leads notion belief. Even though unanimously accepted(cf. e.g., Halpern, Samet, & Segev, 2009), axiom usually considered key distinctionknowledge belief.42fiPDT Logicsense ETL easily extracted global history filtering historyrespective agents observations.traditional work epistemic logic discussed far allow quantifyagents degree belief certain facts; specified whether agentknow (resp. believe) fact. remove limitation, several approachesproposed combine logics knowledge belief probabilistic quantifications.Fagin Halpern (1994) laid foundation combination seminal paper.define belief operator quantify lower bounds probabilities agentassigns formula. modeled associating probability space stateagent. framework, generally guaranteed formulae definemeasurable sets, present properties guarantee measurabilitysets. contrast, semantics defined PDT Logic always produces eventsmeasurable probabilities. special case framework introduced Fagin Halpernpresented Milch Koller (2000). PDT Logic, formalismassumed (i) exists common prior probability distribution set worlds(ii) agents local probability distribution world derivedglobal distribution conditioned respective set worlds agent considers possible.additional feature Milch Koller models represented Bayesiannetworks find probabilities defined formulae. Van der Hoek (1997) introduceslogic PF D, later extended de Carvalho Ferreira, Fisher, van der Hoek(2008). Like Fagin Halpern, framework introduces operator quantifylower bounds probabilistic beliefs. Probabilistic values work semanticallyrestricted finite base set probability values, yielding logically compact frameworkenables efficient implementations.variety approaches proposed extend probabilistic epistemic logicsdynamic frameworks: Kooi (2003) restricts probabilistic epistemic logic FaginHalpern (1994) finite settings combines dynamic epistemic logicGerbrandy Groeneveld (1997) create Probabilistic Dynamic Epistemic Logic(PDEL). work analyzes effects probabilistic beliefs upon public announcements.framework based dynamic epistemic logic, capabilitiesrepresent temporal relationships; features regarding past cannot expressed all,features regarding future expressed limited extent resultcertain actions. Van Benthem (2003) extends framework analyze resultsvarious epistemic actions described Baltag et al. (1998). Another extensionframework proposed van Benthem, Gerbrandy, Kooi (2009b), differentsources probabilities distinguished. simplification approach presentedvan Eijck Schwarzentruber (2014). paper distinguishes workprobabilistic epistemic logic certainty equated knowledge. worksmake explicit distinction belief probability 1 knowledge. differencetwo concepts often illustrated repeatedly throwing fair coin:event coin shows head least 1 infinite number repetitions.Yet agent know example coin eventually show head. PDTLogic works countable models finite time frames, adopt viewvan Eijck Schwarzentruber consider certainty knowledge equivalentmodels. Deviating approaches extend epistemic logic probabilities, PDT43fiMartiny & MollerLogic provides belief operator probability interval quantifications, lowerupper bounds probability values specified explicitly. providesnatural means represent imprecise probabilities discussed introduction.Another direction probabilistic extensions discussed Halpern Pucella (2006)Doder, Markovic, Ognjanovic, Perovic, Raskovic (2010), example. approaches consider problem estimating unknown prior probabilities based givenevidence. Essentially, unknown priors represented set hypotheses,likelihood hypothesis given specific observations estimated. approaches,hypotheses represent possible configurations world thus satisfiable.contrast, aim PDT Logic verify whether possible assignment priors existsgiven set formulae satisfiable.dynamic epistemic logic, possible reason step-wise changesfuture. order reason temporal relations, Sack (2008) extends updatemechanism dynamic epistemic logic temporal operators, namely previous-timenext-time operators. Sack (2009) extends approach probabilistic frameworks augmenting work probabilistic dynamic epistemic logic (Kooi, 2003)previous-time operator ability reason continuous probabilities.approaches enrich dynamic epistemic logic ability reason eventspast. Van Benthem, Gerbrandy, Hoshi, Pacuit (2009a) give systematic precisecomparison ETL (called TEL van Benthem, Gerbrandy, Hoshi, Pacuit)DEL shown approaches merged single framework.Shakarian et al. (2011) Shakarian et al. (2012) introduce APT Logic, frameworkrepresent probabilistic temporal evolutions worlds threads. APT Logic assignsprior probabilities every thread uses probabilities determine probabilitiesevents occurring specific threads. represent temporal relationships events,APT Logic introduces concept frequency functions. utilize approach APTLogic create doxastic multi-agent framework supports explicit reasoningtemporal relationships adoption frequency functions. explicitnotion time formalism increases complexity decision problems, significantlyenhances expressibility temporal relations. instance, contrast approachesimplicit representations time, PDT Logic able specify events occurwithin certain time interval (cf. introduction frequency functions below).3. PDT Logic: Syntax Semanticssection, discuss beliefs multi-agent systems formalized. startdefining syntax PDT Logic, discuss employed model time, provideformal semantics. proposed formalism enables expression different typesbeliefs quantify beliefs using imprecise probabilities. introducing suitableupdate rule show agents beliefs evolve time agents updatebeliefs new information correctly integrated belief state.44fiPDT Logic3.1 Syntaxassume existence function-free quantifier-free fragment first order logic2language L finite sets constant symbols Lcons predicate symbols Lpred ,infinite set variable symbols Lvar . Every predicate symbol p Lpred arity. termmember set Lcons Lvar . term called ground term memberLcons . t1 , .., tn (ground) terms, p predicate symbol Lpred arity n,p(t1 , ..., tn ) (ground) atom. (ground) atom, (ground)literals. former called positive literal, latter called negative literal. setground literals denoted Llit . usual, B denotes Herbrand Base L, i.e.,set ground atoms formed Lpred Lcons .Time modeled discrete steps assume agents reason arbitrarily large, fixed-size window time. set time points given = {1, ..., tmax }.set agents denoted A. Again, assume set may arbitrarily large,finite size. describe agents observe, define observation atoms follows.Definition 3.1 (Observation atoms). non-empty group agents Gground literal l Llit , ObsG (l) observation atom. set observation atomsdenoted Lobs .Intuitively, meaning statement form ObsG (l) agents groupG observe fact l holds. Note l may negative literal thereforeexplicitly specify observations certain facts false (such raining).assume agents G observe l holds, agent G alsoaware agents G make observation. line Baltag Moss(2004), observations viewed effects private group announcements factl group G (i.e., l becomes common knowledge within G, agents outside Gremain entirely oblivious observation): represents epistemic action, i.e., altersbelief states agents G (as formally defined below), influenceontic facts respective world.Definition 3.2 (Formulae). atoms observation atoms formulae. F Gformulae, F G, F G, F formulae. formula ground atomsformula ground.Example 3.1 (Coin toss). Consider two agents 1, 2 coin tossed. eventcoin lands heads denoted primitive proposition Head, accordingly,coin lands tails denoted Head. Let us assume coin actually lands heads.Then, sets possible observations scenario {Obs{1} (Head)}, {Obs{2} (Head)},{Obs{1} (Head), Obs{2} (Head)}, {Obs{1,2} (Head)}.Note difference third fourth set: formerscenario, agents observe outcome coin throw unawareagent actually made observation. latter scenario, agents observeoutcome aware agent observes same. Since allow2. use first order structure language definition syntactically convenient wayrepresenting observations. Apart this, propositional logic could used base language.45fiMartiny & Mollernesting observations (i.e., expressions ObsG1 (ObsG2 (l))) PDT Logic,subset epistemic actions discussed Baltag Moss (2004) representedformalism. limits expressivity epistemic actions extent,ensure resulting set possible observations Lobs always finite thereforeshow PDT Logic decidable (as shown Section 4). Further, noteformal concept observations limited express passive acts observing facts,instead used model wide range actions: instance, exampleone could also use Obs{1,2} (Head) model act one agent tellingoutcome coin throwthe ramifications communication act exactlywould shared observation (assuming agents lie).express temporal relationships, define temporal rules following approachAPT rules Shakarian et al. (2011). definition temporal rules already reliesconcept frequency functions, even though defined next section.still introduce temporal rules enable clearly separated presentation syntaxsemantics PDT Logic.Definition 3.3 (Temporal rules). Let F, G two ground formulae, time interval,fr (F, G)fr name frequency function (as defined Section 3.2.5). rtcalled temporal rule.Frequency functions provide information temporal connections events.fr (F, G) understood F followed Gmeaning expression rttime units w.r.t. frequency function fr. Frequency functions enable specificationvarious types temporal relations. example, used determine oftenF followed G within time units often F followed G exactlytime units. usage fr syntax temporal rules used specify set possiblenames employed types frequency function.`,u`,uNow, define belief operator Bi,t0 express agents beliefs. Intuitively, Bi,t0 ()means time t0 , agent believes fact true probability p [`, u].Particularly, intuitive meaning belief temporal rule agent believesfr (F, G), given F holds time point. callG hold according rtprobability interval [`, u] quantification agent belief. use Ft denoteformula F holds time and, accordingly, ObsG (l)t denote observationObsG (l) occurs time t. call expressions time-stamped formulae timestamped observation atoms, respectively.Definition 3.4 (Belief formulae). Let agent, t0 time point, [`, u] [0, 1].Then, belief formulae inductively defined follows:`,u1. F ground formula time point, Bi,t0 (Ft ) belief formula.fr (F, G) temporal rule, B `,u (r fr (F, G)) belief formula.2. rti,t0`,u3. F G belief formulae, Bi,t0 (F ), F G , F G , F .`,ubelief Bi,t0 () something, call belief object. Belief operators`,uatomic elements PDT Logic, i.e., expression Bi,t0 () (including possibly nested belief46fiPDT Logicformulae) called atom. use script fonts (e.g., F ) distinguish belief formulaestandard formulae. Note ontic facts observation atomsstandard formulae (cf. Definition 3.2) therefore agents also beliefspossible observations.use probability intervals [`, u] provides option represent imprecise probabilities (Bradley, 2015): using imprecise probabilities, usually assumeddegree belief proposition represented using single probability function p(), instead set P functions. Then, belief state P ()proposition represented setP () = {p() : p P }.set probabilities P (), so-called lower upper envelopes defined P () =inf P () P () = sup P (), respectively. belief quantifications belief operatorrepresent imprecise probabilities ` u values probabilistic beliefconsidered lower upper envelopes P P respective imprecise probability.`,uRemark 3.1. decided index belief operators Bi,t0 () facts Ft appearingbelief objects time stamps allow concise representation temporalrelations. Alternatively, one could use traditional approach (cf. Sack, 2009example) introduce previous-time next-time operators language express`,utemporal relationships t0 Bi,t0 (Ft ). Then, could also omit temporal0index belief operator instead evaluate whether belief holds time t0model. However, merely syntactic considerations impactunderlying formalism. Thus decided encode time explicitly belief operatorsavoid introduction additional temporal operators. Moreover, belief operatorsalso used express general temporal relationships modeled domain.illustrate point detail Section 4.3.2 Semanticssection, provide formal semantics PDT Logic captures intuitionsexplained above. ease understanding presentation, start introductionexample, return repeatedly introducing various conceptssemantics. illustration formalisms features, use simplified exemplarydomain. practical use example somewhat limited, serves illustratePDT Logic applied, especially analysis multi-agent beliefsyield valuable information deciding meaningful actions. resulting insightseasily applied sophisticated domains.Example 3.2 (Trains). Let Alice Bob two agents living two different cities CACB , respectively. Suppose Alice wants take train visit Bob. Unfortunately,direct connection cities CA CB , Alice change trainsthird city CC . assume train T1 connects CA CC , train T2 connects CCCB . trains usually require 2 time units trip, might running latearrive one time unit later scheduled. Alice requires one time unit change trainscity CC . T1 runs time, direct connection T2 , otherwise wait47fiMartiny & Mollertwo time units next train T2 leaves city CC . train running late,call Bob let know. calls modeled shared observationsAlice Bob. instance, Alice wants tell Bob train T1 running late (i.e., T1arrive CC expected time), modeled Obs{AB} (at(T1 , CC ))expected arrival time.3.2.1 Possible WorldsOntic facts corresponding observations (e.g., described example) formworlds (or states terminology Fagin et al., 1995). world consists setground atoms set observation atoms, i.e., 2BLobs .3 useObsG (l) denote atom a, resp. observation atom ObsG (l), holds world .Since agents observe facts actually hold respective world, defineadmissibility conditions worlds w.r.t. set observations:Definition 3.5 (Admissible worlds). world admissible, iff every observation atomObsG (l)1. observed fact holds, i.e., x l positive literal x, x 6 l negativeliteral x,2. every subgroup G 0 G, ObsG 0 (l) .use adm() denote world admissible.set possible worlds denoted set admissible worlds .following discussion section assume specification given.possible employ usual definition set combinationsground atoms observation atoms ( = 2BLobs ), maximum subsetcomplying Definition 3.5, usually contains vast number worldsblatantly impossible according respective problem modeled. Therefore, assumesuccinct specification set admissible worlds depending respective domaingiven. main reason assumption simplify following presentationwedescribe method obtain set algorithmically Section 4.Remark 3.2. already discussed Section 3.1, group observations ObsG (l) everyagent G aware agents G observed fact. TogetherDefinition 3.5, semantics observations equivalent usual semanticscommon knowledge. Fagin et al. (1995) give definition common knowledgefixed-point axiom: fact l common knowledge among group G membersG know l true common knowledge. Thus, could also equivalently useestablished common knowledge operator CG (l) instead previously defined observation3. formalisms epistemic logic encode facts directly worlds, instead use setnamed states s1 , s2 , ... valuation function (si ) determine facts hold world si (cf.Fagin et al., 1995). mainly done obtain option multiple worlds si , sjfacts hold (i.e., (si ) = (sj )), knowledge states agents differ. described below,PDT Logic worlds appear within threads, thus possible worlds valuationappear time point multiple threads. Thus, formalism encode facts directlypossible worlds save valuation function without limiting epistemic expressivity.48fiPDT Logicatoms ObsG (l). However, concept common knowledge usually used describeemergent states agents knowledge. hand, context approach,observations extrinsic feature result emergence belief states.keep clear distinction intended use operator, therefore continueuse ObsG (l) instead CG (l).Example 3.3 (Trains continued). Example 3.2, ground terms A, B, CA , CB ,CC , T1 , T2 , representing Alice, Bob, three cities, two trains. Furthermore,atoms on(y, x) indicating person train x, at(x, z) indicating train xcity z. Finally, observation atoms kind ObsG (at(x, z)), indicatingagents G observe train x station z. possible world example1 = {at(T1 , CA ), on(A, T1 ), Obs{A} (at(T1 , CA ))}, indicating train T1 city CAboarded train.define satisfaction ground formula F world usual way (Lloyd,1987):Definition 3.6 (Satisfaction ground formulae). Let F, F 0 , F 00 ground formulaeworld. Then, F satisfied (denoted |= F ) if:case F = ground atom a:.case F = F 0 ground formula F 0 :case F = F 0 F 00 formulae F 0 F 00 :case F = F 0 F 00 formulae F 0 F 00 :6|= F 0 .|= F 0 |= F 00 .|= F 0 |= F 00 .say formula F tautology |= F admissible worlds .say formula F contradiction world |= F . useusual symbols > denote tautologies contradictions, respectively.3.2.2 Threadsmodel temporal evolutions problem domain use definition threadsShakarian et al. (2011):Definition 3.7 (Thread). thread h mapping set time pointsset admissible worlds: h :Thus, thread sequence worlds h(t) identifies actual world timeaccording thread h. set possible threads (i.e., possible sequences constructible ) denoted . Again, refrain directly working, instead assume meaningful problem specification gives informationpossible temporal evolutions system. use represent set relevant possible threads. notational convenience, assume additional prior worldh(0) every thread.Following Definition 3.6, use h |= Ft denote thread h satisfies formulae Ftime (i.e., h |= Ft h(t) |= F ). Accordingly, use |= Ft denote everythread h satisfies formula F time t.49fiObs{A}at(T1 , CC )(at(T1 , Cc ))on(A, T1 ) on(A, T1 ) on(A, T1 ) on(A, T1 )Obs{A,B}at(T1 , CC )(at(T1 , Cc ))on(A, T1 ) on(A, T1 ) on(A, T1 ) on(A, T1 )Obs{A}at(T1 , CC )(at(T1 , Cc ))on(A, T1 ) on(A, T1 ) on(A, T1 ) on(A, T1 )1 2 h71 2 h6h5h411hih12 h2on(A, T1 )at(T1 , CC )on(A, T1 )on(A, T1 ) on(A, T1 )at(T1 , CA )on(A, T1 ) on(A, T1 )3at(T1 , CC )at(T1 , CA )2on(A, T1 )on(A, T1 ) on(A, T1 )1at(T1 , CC )at(T1 , CA )at(T1 , CA )at(T1 , CA )at(T1 , CA )at(T1 , CA )on(A, T2 )on(A, T2 )on(A, T2 )on(A, T2 )415on(A, T2 ) on(A, T2 )at(T2 , CC )at(T2 , CC )6on(A, T2 )at(T2 , CB )7Obs{A}at(T2 , CB )(at(T2 , CB ))on(A, T2 ) on(A, T2 ) on(A, T2 ) on(A, T2 )at(T2 , CC )8at(T2 , CB )at(T2 , CC )on(A, T2 )at(T2 , CB )on(A, T2 )9Obs{A}at(T2 , CB )(at(T2 , CB ))on(A, T2 ) on(A, T2 )on(A, T2 )Obs{A}at(T2 , CB )(at(T2 , CB ))on(A, T2 ) on(A, T2 )on(A, T2 )Obs{A,B}at(T2 , CB )(at(T2 , CB ))on(A, T2 ) on(A, T2 )on(A, T2 )Obs{A,B}at(T2 , CB )(at(T2 , CB ))on(A, T2 ) on(A, T2 )on(A, T2 )at(T2 , CC )on(A, T2 )at(T2 , CC )on(A, T2 )at(T2 , CC )on(A, T2 )at(T2 , CC )on(A, T2 )at(T2 , CC )Obs{A,B}at(T2 , CB )(at(T2 , CB ))on(A, T2 ) on(A, T2 ) on(A, T2 ) on(A, T2 )Obs{A,B}at(T1 , CC )(at(T1 , Cc ))on(A, T1 ) on(A, T1 ) on(A, T1 ) on(A, T1 )2 h3Obs{A}at(T1 , CC )(at(T1 , Cc ))on(A, T1 ) on(A, T1 ) on(A, T1 ) on(A, T1 )1 2 h8at(T1 , CA )Obs{A,B}at(T1 , CC )(at(T1 , Cc ))on(A, T1 ) on(A, T1 ) on(A, T1 ) on(A, T1 )at(T1 , CA )1 2 h9Martiny & MollerFigure 1: Visualization possible threads hi Example 3.2. easier distinction, shared observations B marked blue, single observationsmarked red, situations Alice train 1 train 2marked green orange, respectively. Note train running late(the respective threads marked according circles), always twopossible threads: one observes one shareobservation.50fiPDT Logicassume system synchronous, i.e., agents global clock. Thus,even agent observe anything world h(t), still aware time passingtherefore distinguish worlds h(t) h(t 1).Example 3.4 (Trains continued). description Example 3.2 (p. 47) yieldsset possible threads depicted Figure 1. Note manually specified setthreads containing threads comply description Example 3.2.set possible threads would contain vast number additional threadsirrelevant described scenario.3.2.3 Kripke Structuresdefinition threads, use slightly modified version Kripke structures(Kripke, 1963). usual, define Kripke structure tuple h, K1 , ..., Kn i,set admissible worlds binary relations Ki every agent A. Thus,Kripke relation (also called possibility relation) agent world definedKi () = { 0 : (, 0 ) Ki }(1)Intuitively, (, 0 ) Ki specifies world , agent considers 0 also possibleworld. words, current information agent unable distinguish worlds0 .initialize Kripke structure threads considered possible time= 0:[h : Ki (T h(0)) ={T h0 (0)},(2)h0evolution time, agent eliminate worlds complyrespective observations. elimination worlds, agent also reduceset threads considers possible (ifdue observationa world consideredimpossible time point t, threads h h(t) = considered impossible).assume agents perfect recall therefore consider threadpossible considered impossible one point. Thus, Ki updated w.r.t.agents respective observations, considers threads possible complycurrent observations considered possible previous time point:Ki (T h(t)) = h0 (t) : h0 (t 1) Ki (T h(t 1)){ObsG (l) h(t) : G} = {ObsG (l) h0 (t) : G}(3)following two corollaries describe key properties Ki follow immediatelydefinitions (2) (3):Corollary 3.1 (Equivalence relation). Ki defines equivalence relation possibleworlds Ki (T h(t)) time points .Corollary 3.2 (Reduction considered threads). set threads h0 considered possiblew.r.t. Ki narrowing smaller smaller subset time, i.e., {T h0 : h0 (t)Ki (T h(t))} {T h0 : h0 (t 1) Ki (T h(t 1))} h .51fiMartiny & MollerNote updates Ki defined new information incorporated instantaneously, i.e., time agent observes fact, updates possibility relationsalready time considers every world impossible complyobservation time t.Example 3.5 (Trains continued). Figure 1, obtain time 1,possible world {at(T1 , CA ), on(A, T1 )}, contained possible threads. Thus,Ki (T hj (1)) contains exactly world agents threads j. Consequently,agents consider threads possible time 1.Now, assume time evolves two steps actual thread h4 (i.e., trainT1 running late, inform B this). agents updatepossibility relations accordingly, yieldingKA (T h4 (3)) = {{Obs{A} (at(T1 , CC )), on(A, T1 )}}KB (T h4 (3)) = {{at(T1 , CC ), on(A, T1 )}, {Obs{A} (at(T1 , CC )), on(A, T1 )}},i.e., knows T1 time, B unaware T1 late, since stillconsiders situation possible train T1 city CC time = 3.3.2.4 Subjective Posterior Temporal Probabilistic Interpretationsagent probabilistic beliefs expected evolution time. expressed subjective temporal probabilistic interpretations:Definition 3.8 (Subjective posterior probabilistic temporal interpretation). Given setpossible threads , thread Th , time point t0 > 0 agent i, functionTh : [0, 1] specifies subjective posterior probabilistic temporal interpretationIi,t0agent point view time t0 thread Th, i.e., probability distribution possiblePTh (T h) = 1. Since probabilistic interpretations possible threadsthreads: hT Ii,t0depend respective perspective agent i, Th marks point view subjectiveinterpretation. Thus, call Th point view (pov) thread interpretation h0 .i,tconcept point view threads seen conditional probabilities: subjecTh specifies agent probabilistic interpretationtive posterior probabilistic interpretation Ii,t0time t0 given Th actual thread. Different threads yield different evolutionsworld andsince every possible thread taken pov thread may inducedifferent probabilistic interpretations agent. Thus, notion pov threads allowsreason hypothetical beliefs agent, instance possible future beliefsanalyzed nested beliefs evaluated.Th vector occasionally represent probabilisticsimplify notation, see Ii,t0h vector possible threads vector well, jthinterpretation Ii,t0h refers probability assigned thread h .element Ii,t0jh (T h). Sinceprior probabilities agent threads given Ii,0threads indistinguishable priori, single prior distribution needed52fiPDT Logic00h (T h) = h (T h)). Furthermore, orderagent (i.e., h, Th, Th : Ii,0i,0able reason nested beliefs (as discussed below), assume priorprobability assessments agents commonly known (i.e., agents knowagents assess prior probabilities thread). turn requiresagents exactly prior probability assessment possible threads: twoagents different, commonly known prior probability assessments, essentiallyinstance Aumanns well-known problem agreeing disagree (Aumann,1976). Intuitively, differing priors commonly known, common knowledge(at least) one agents fault revise probability assessments.result, one prior probability distribution viewpoints,denoted I. Note directly corresponds concept temporal probabilisticinterpretations Shakarian et al. (2011).Remark 3.3. could use prior probability distribution alternative methoddistinguish set possible threads set threads relevantspecific problem domain. so, simply assign unwanted threads h 6probability zero.Example 3.6 (Trains continued). meaningful prior interpretationI(T ) = 0.7 0.02 0.09 0.02 0.09 0.01 0.02 0.02 0.03 ,assigns highest probability h1 (no train running late), lower probabilitiesthreads one train running late informs B (T h3 h5 ), even lowerprobabilities events either trains running late informs B (T h7 ,h8 , h9 ) one train running late inform B (T h2 h4 ),lowest probability thread trains running lateinform B (T h6 ). Note represents prior interpretation train examplethus every agent every possible pov thread Th.Even though single prior probability distribution set possiblethreads, still necessary distinguish viewpoints different agents differentthreads, following definition interpretation updates shows.Whenever agent updates Kripke relations according Equation (3) (p. 51),necessary update probabilistic interpretations agent match newknowledge. intuitive way update probabilities conditioning remainingworlds agents Kripke structure. want point conditioning suitablechoice PDT Logic, although known produce undesired incorrect resultsmany cases, notably Monty Hall problem (vos Savant, 1990). GrunwaldHalpern (2003) discuss naive conditioning tends produce errors updatescarried simplified space several events collapsed since seeminglyone event. one uses so-called sophisticated conditioning instead (i.e., conditioningsophisticated space, means possible events represented), probabilitiesupdated correctly. semantics PDT Logic based exhaustive specificationrelevant threads, conditioning proper specification relevant threads inherentlysophisticated sense Grunwald Halpern therefore produce correctresults. One easily verify following update rule, well-known probability53fiMartiny & Mollerpuzzles Monty Hall Problem correctly represented PDT Logic. Thus,use following conditioning-based update rule:Definition 3.9 (Interpretation update). Let agent, t0 time point, Th povthread. Then, system actually thread Th time t0 , agent probabilisticinterpretation set possible threads given update rule:Th (T h) h(t0 ) K (Th(t0 ))1 Ii,t0 1hTh0i,tIi,t0 (T h) =(4)0h(t0 ) 6 Ki (Th(t0 ))1hi,t0normalization factor ensureXThi,t0 =hT ,PhTh (T h) = 1:Ii,t0ThIi,t0 1 (T h)(5)h(t0 )Ki (Th(t0 ))invocation Ki update rule yields obvious ramifications evolutioninterpretations, stated following corollary:Corollary 3.3 (Nonzero probabilities). subjective temporal probabilistic interpretationTh agent assigns nonzero probabilities exactly set threads stillIi,t0considers possible time t0 , i.e., h0 (T h) > 0 iff (T h(t), Th(t)) Kii,tEssentially, update rule assigns impossible threads probability zeroscales probabilities remaining threads proportionalprobabilities previous time point. given prior probability distributionTh specific pov threadset possible threads, subjective posterior probabilities Ii,t00h agents time points induced respective observations containedTh. use h denote set subjective posterior interpretations h0 inducedi,tpov thread Th.Example 3.7 (Trains continued). Applying update rule (4) situationdescribed Example 3.5 (p. 52), given Example 3.6, yields updatedinterpretation A:h4IA,3= 0 0 0 0.4 0 0.2 0 0.4 0(6)i.e., considers exactly threads possible, train running lateinform B (threads h4 , h6 , h8 ). Due lack new information, Beliminate situations indeed inform late timepoint 3, thus Bs interpretation updated to:Th4IB,30.82 0.02 0.10 0.02 0 0.02 0 0.02 0 .54(7)fiPDT Logich(1)h(2)h(3)h(4)h(5)h(6)h(7)h(8)FGFGGFGFFigure 2: Example thread h = {1, ..., 8}, adopted Shakarian et al. (2011).figure shows world satisfies formula F formula G.3.2.5 Frequency Functionsrepresent temporal relationships within threads, adapt concept frequency functions introduced Shakarian et al. (2011). Frequency functions provide flexible wayrepresenting temporal relations occurrences specific events. illustratemotivation behind using frequency functions, consider exemplary thread h depictedFigure 2. thread, one events F G occurs every time point = 1= 8. discussed Shakarian et al., multiple ways characterizing temporalrelationships events F G: instance, one might specify often eventF followed event G in, say, exactly 2 time points. According Figure 2, happensone four occurrences F h. might prove meaningful exclude finaloccurrence F h determining frequency, naturally occurrenceF tmax cannot followed subsequent occurrence G. Excluding finaloccurrence F would yield one three desired frequency. Alternatively, onecould also specify often F followed G within next two time points.exemplary thread Figure 2, would produce frequencies 1 0.75 respectively,depending whether final occurrence F included.example illustrates already four different possible definitions temporal relationsevents. maintain flexibility expressing temporal relations, commit specific definitions PDT Logic, instead adapt axiomatic definitionfrequency functions:Definition 3.10 (Frequency functions, adapted Shakarian et al., 2011). Let hthread, F , F 0 , G, G0 ground formulae, 0 integer. frequencyfunction fr maps quadruples form (T h, F, G, t) [0, 1] followingaxioms hold:(FF1) (F G) tautology, fr(T h, F, G, t) = 1.(FF2) (F G) contradiction, fr(T h, F, G, t) = 0.(FF3) (F G) neither tautology contradiction, exist threads h1 ,h2 fr(T h1 , F, G, t) 6= fr(T h2 , F, G, t).(FF4) F F 0 G G0 , fr(T h, F, G, t) = fr(T h, F 0 , G0 , t).Axioms (FF1) (FF2) ensure special casesi.e., (G >), (F ),(F >, G )frequency functions behave temporal implications premiseF conclusion G. Axiom (FF3) enforces non-trivial frequency functions requiringcases covered first two axioms, must least two threads55fiMartiny & Mollerdiffering frequency values. Axiom (FF4) ensures fr congruent logicalequivalence. Examples frequency functions satisfying axioms introduced below.Remark 3.4. definition mostly corresponds definition frequency functionsShakarian et al. (2011), except require > 0. workShakarian et al., frequency functions intended express temporal relationshipstherefore limited nonzero values. additionally allowing = 0, obtainconcise framework express temporal relationships static constraintswithin one time point. exploited next section, decision proceduresPDT Logic discussed.illustrate concept frequency functions, present formal definitionspoint existential frequency functions adapted Shakarian et al. representinformal descriptions frequencies above:point frequency function pfr expresses frequently event F followedanother event G exactly time units:pfr(T h, F, G, t) =|{t : h(t) |= F h(t + t) |= G}||{t : (t tmax t) h(t) |= F }|(8)denominator zero, define pfr 1. denominator counts total numberoccurrences F given thread h numerator counts number occurrencesF followed G exactly time units. Thus, ratio pfr expresses frequentlyF followed G exactly time units. Note denominator considersoccurrences F time tmax t. done reflect previously discussedintuition occurrences F last time points excludedfrequency, possibility followed subsequent Gtime units.existential frequency function efr expresses frequently event F followedanother event G within next time units:efr(T h, F, G, t) =efn(T h, F, G, t, 0, tmax ),|{t : (t tmax t) h(t) |= F }| + efn(T h, F, G, t, tmax t, tmax )(9)efn(T h, F, G, t, t1 , t2 ) =|{t : (t1 < t2 ) h(t) |= Ft0 [t, min(t2 , + t)] (T h(t0 ) |= G)}|function ef n counts number occurrences F followed subsequent occurrenceG within next time units. first summand denominator countstotal number occurrences F time point tmax t. second summanddenominator, additional occurrences F followed G within time units.intuition definition exclude occurrences F final time unitsfollowed G. Since G may occur within range t, range cannotfully considered final time points, occurrences F accordingsubsequent occurrence G considered final time points. Consequently,56fiPDT Logicratio efr expresses frequently event F followed G within next timeunits without letting single occurrences F final time points decrease ratio.Returning exemplary thread h Figure 2, evaluate frequencyfunctions given thread: Suppose want determine often F followedG exactly two time steps. expressed point frequency function:1pfr(T h, F, G, 2) = .3instead want know often F followed G within next two time steps,use existential frequency function:efr(T h, F, G, 2) =3=13noted frequency functions used model temporal relationshipsusually expressed temporal operators. instance, pfr = 1 reflectsnext operator efr = tmax reflects future operator. meaningadditional temporal operators captured definitionadditional frequency functions, required.3.2.6 Semantics Belief OperatorNow, definitions subjective posterior probabilistic temporal interpretationsintroduction frequency functions, provide formal semantics belief operators defined Section 3.1. semantics extends definitions Shakarianet al. (2011) satisfiability static interpretations obtain formal definitionprobabilistic multi-agent beliefs. start providing definition semanticsatomic belief operators three different types beliefs. Semantics compound beliefformulae (i.e., involving connectives , , ) defined Definition 3.16.Definition 3.11 (Belief Semantics atomic belief operator). Let agentTh agent interpretation time t0 pov thread Th. Then, followsIi,t0interpretation agent believes time t0 probability range [`, u]1. (Belief ground formulae)Th |= B `,u (F )) iffformula F holds time (denoted Ii,t0i,t0`XhT ,T h(t)|=FThIi,t0 (T h) u.(10)2. (Belief rules)fr (F, G) holds (denoted Th |= B `,u (r fr (F, G))) ifftemporal rule rti,t0i,t0`XhTThIi,t0 (T h) fr(T h, F, G, t) u.57(11)fiMartiny & Moller3. (Nested beliefs)` ,ubelief Bj,tj j () agent j holds time t0 (denoted` ,uh |= B `,u (B j j ())) iffIi,t0j,ti,t0`XhT` ,uh |=B j j ()Ij,tj,tThIi,t0 (T h) u.(12)intuition behind semantics follows. beliefs ground formulae Ft ,Th (T h) agent time t0 pov thread Thsubjective posterior probabilities Ii,t0added threads h satisfy F time t. Thus, sum (10) representsTh assigns F . sum within specified boundaries [`, u],exact probability Ii,t0`,urespective belief B 0 (Ft ) holds agent time t0 pov thread Th.i,th (T h) every threadbeliefs rules, subjective posterior probabilities Ii,t0fr (F, G). Thus,weighted corresponding frequency fr(T h, F, G, t) rule rth (T h) (11) represents exact probability Th assignsweighted sum Ii,t0i,t0temporal relation F G according frequency function fr. beliefsfr (F, G) contains information type frequencyrules, belief object rtfunction fr, constraints respective frequency values given beliefquantification [`, u], i.e., agent probabilistic beliefs specific frequencyvalues.Remark 3.5. noted semantics beliefs rules (11) togetheraxiomatic definition frequency functions Definition 3.10 (p. 55) yields certainfr (F, G). G tautology F contradictionconstraints satisfiable beliefs rules rt(i.e., Definition 3.10 FF1 satisfied), holds respective frequency function`,u frfr(T h, F, G, t) = 1 every possible thread h, thus, belief Bi,t0 (rt (F, G))satisfiable belief quantified u = 1, regardless set threadsTh . Analogously, F tautology Gcorresponding interpretation Ii,t0`,u frcontradiction (i.e., FF2 satisfied), belief Bi,t0 (rt (F, G)) satisfiable ` = 0.` ,u`,uj jnested beliefs Bi,t()), expression unnested first determining0 (Bj,t` ,u` ,upossible pov threads h agent j Bj,tj j () satisfied. Bj,tj j () correspondsbelief fact rule, (10) respectively (11) used identify threads hh |= B `j ,uj (). Otherwise, represents another belief formula, beliefIj,tj,tunnested recursively innermost belief expression obtained. Then,h |= B `j ,uj (), agent subjective posterior probabilities Th (T h)threads h Ij,tj,ti,t0added determine whether outer belief holds. Note agentknow actual beliefs agent j. However, due assumption common equalpriors discussed Section 3.2.4, agent able reason agent js hypotheticalinterpretation updates given system specific thread. Thus, agent ablecompute (12) without knowing js exact beliefs.Example 3.8 (Trains continued). use point frequency function express beliefspunctuality trains. Assume B judge probability58fiPDT Logictrain running late (i.e., arriving 3 instead 2 time units, expressedtemporal rule r3pfr (at(T1 , CA ), at(T1 , CC ))) 0.4. yields followingbelief formulae0,0.4 pfrBi,0(r3 (at(T1 , CA ), at(T1 , CC ))),0,0.4 pfrBi,0(r3 (at(T2 , CC ), at(T2 , CB ))){A, B}.(13)temporal rules expressed belief formulae, obtain following frequenciesFigure 1 (p. 50):pfr(T h, at(T1 , CA ), at(T1 , CC ), 3) = 0pfr(T h, at(T1 , CA ), at(T1 , CC ), 3) = 1pfr(T h, at(T2 , CC ), at(T1 , CB ) , 3) = 0pfr(T h, at(T2 , CC ), at(T1 , CB ), 3) = 1h {T h1 , ..., h3 }h {T h4 , ..., h9 }h {T h1 , h4 , h5 }h {T h2 , h3 , h6 , ..., h9 }Combining frequency values prior interpretationI(T ) = 0.7 0.02 0.09 0.02 0.09 0.01 0.02 0.02 0.03 ,given Example 3.6 (p. 53) yields sumXI(T h) pfr(T h, F, G, 3) = 0.19hTF = at(T1 , CA ), G = at(T1 , CC ) F = at(T2 , CC ), G = at(T2 , CB ). sumwithin belief quantification [`, u] = [0, 0.4], belief formulae (13) valid. Noteprior probabilities Example 3.6 specified trainslate probability, thus respective sums frequenciessame.definitions, use belief fact F quantifybelief negation fact F :`,uCorollary 3.4 (Belief negated facts). Let Bi,t0 (Ft ) agents quantified temporal belieffact F according Definition 3.11. Then, agents belief negation`0 ,u000fact F given Bi,t0 (F ) ` = 1 u u = 1 `.3.3 Evolution Timeorder completely specify problem PDT Logic, introduce concept doxasticsystems. following, assume syntactical objects finite.|A||T |Definition 3.12 (Doxastic system). Let set agents, set threads, A0matrix prior probability distributions across every agent A, F|A||T |set frequency functions. Then, call quadruple = hA, , F, A0system.59doxasticfiMartiny & MollerNote several parameters discussed explicitly specifieddoxastic system: neither set possible worlds , set ground atoms B, setobservation atoms Lobs , set time points explicitly specified. However,relevant information regarding parameters already contained specification.Remark 3.6. Since agents share common prior, rows A0 same. Thus,one could obtain parsimonious problem specification providing singleunique row vector prior probabilities. choice using matrix A0 nonethelessnotational purposes only: simplify presentation interpretation updateoperations later on.|A||T |Definition 3.13 (Admissibility doxastic systems). Let = hA, , F, A0doxastic system. called admissible iff every world (implicitly) defined admissible|A||T |(according Definition 3.5, p. 48) rows A0sum one.identify specific situations doxastic system time passedobservations occurred, furthermore define pointed doxastic systems:|A||T |Definition 3.14 (Pointed doxastic system, pds). Let = hA, , F, A0doxasticsystem H set time-stamped observation atoms observation atomsH occur least one worlds (implicitly) defined . call pairhD, Hi pointed doxastic system.Definition 3.15 (Admissibility pointed doxastic systems). Let hD, Hi pointeddoxastic system, set threads D. hD, Hi called admissible iffadmissible exists thread h ObsG (l)t H : ObsG (l) h(t)(i.e., must contain least one thread complies timed observations H).Intuitively, set timed observations specified pds points certain situationdoxastic system. One could view t(H) = max{t : ObsG (l)t H} present timepds: recent observation occurred t(H), observations actually occurredpast (t < t(H)) specified H (and thus deterministic retrospective),information future observations > t(H) given. sense, H specifiescertain history t(H) doxastic system points last event history.Example 3.9 (Trains continued). doxastic system train example specified= h{A, B}, {T h1 , ..., h9 }, {pfr, efr}, A0 i,0.7 0.02 0.09 0.02 0.09 0.01 0.02 0.02 0.03A0 =.0.7 0.02 0.09 0.02 0.09 0.01 0.02 0.02 0.03identify situation described Example 3.5 (p. 52, T1 running late), specifyfollowing pointed doxastic system:hD, {Obs{A} (at(T1 , CC )3 )}i60fiPDT Logic3.3.1 Evolution Probabilistic Interpretationsaccordance prior probability matrix A0 Definition 3.12, defineinterpretation matrix ATt h store interpretations agents (with n denotingnumber agents |A|) across threads h1 , ..., hm given doxastic systempov thread Th time t:Th (T h ) . . . Th (T h )I1,t11,t......(14)ATt h =...h (T h ) . . . h (T h )In,t1n,tdefinition Ki Equation (3) (p. 51), update rule Equation (4)(p. 54), using prior probability matrix A0 Definition 3.12, provideupdate matrix UtT h calculate interpretation matrix pov thread Thtime point ( denotes element-wise multiplication matrices):hATt h = ATt1UtT h(uTt h )ij=01Thi,t0hj (t) 6 Ki (Th(t))hj (t) Ki (Th(t))(15)(16)h normalization factor defined Equation (5) (p. 54).i,t0time-stamped observations specified history H pds hD, Hi induceupdated set reachability relations Ki (T h(t)) every thread h compliesgiven observations (for threads h comply given observationsKi (T h (t)) = ). updated reachability relations turn yield updated interpretations ATt h . complete state interpretations time point every possiblepov thread Th1 , ..., Thm specified block matrix, call beliefstate (bs) pds time t:bs(hD, Hi, t) = ATt h1 , ..., ATt hm(17)use bs(hD, Hi) denote sequence belief states bs(hD, Hi, t) = 1= tmax .definition belief states seen specification conditional probabilities:kth entry bs(hD, Hi, t) specifies interpretations agents across threadstime given system pov thread Thk . Thusas every thread consideredpotential pov threada full specification agents belief state threads requiresconditional probabilities every time point t. general representationbelief states allow easy evaluation subjective posterior interpretationsarbitrary time points pov threads intuitive definition belief state updates.However, general definition contains redundant information. leveraging certain properties semantics PDT Logic, identify means obtain compressedrepresentations belief state following.61fiMartiny & MollerCorollary 3.5 (Null vectors ATt hk ). Due definition (16), ith row ATt hk~0 iff agent actual observations (as specified H) match observations specifiedthread hk .Proposition 3.6 (Belief state compression). Let hD, Hi pointed doxastic systemlet time point t(H). Then, without loss information, beliefstate bs(hD, Hi, t) time represented(18)bs(hD, Hi, t)0 = ~v1,t , ..., ~vn,tone probability distribution vector ~vi,t per agent i.Proof. follows directly Corollaries 3.3 (p. 54) 3.5 matrices ATt hkbs(hD, Hi, t) nonzero rows exactly correspond threads consideredpossible agent time t.properties Ki given Corollary 3.1 (p. 51) follows worlds h0 (t)Ki t(H) indistinguishable agent therefore associatedinterpretation. Thus, nonzero ith rows matrices bs identical. Defining ~vi,tunique nonzero rows bs, obtain representation (18). Informationimpossible pov threads (as described Corollary 3.5) still maintainedassigned probability 0 ~vi,t .important note compressed representation applicable timepoints t(H), retrospective agent able classify threads twocategories: comply observations far (i.e., consideredpossible), not. time points > t(H) classification possibleKi (T h(t)) depends future observations therefore lead branchingseveral distinct interpretations depending respective observations.3.3.2 Evolution Beliefsorder analyze temporal evolution beliefs, use update rule (15)update belief states. Since different possible observations yield different branchesevolution beliefs, update every thread belief state individually, usingrespective update matrices UtT h defined (16):bs(hD, Hi, t) = bs(hD, Hi, 1) (UtT h1 , ..., UtT hm )(19)Furthermore, analyze satisfiability validity arbitrary finite belief expressions`,u~Bi,t0 () w.r.t. given pds hD, Hi, define auxiliary belief vector b() different beliefs`,uB 0 (). vector ~b() contains one entry (~b())j every possible thread hji,tdefined follows:a)`,uBi,t0 (Ft )b)`,u frBi,t0 (rt (F, G)) :c)`,u`k ,ukBi,t()) :0 (Bk,t:(1 hj (t) |= F(~b(Ft ))j =0 hj (t) 6|= Ffr(~b(rt(F, G)))j = fr(T hj , F, G, t)(Th`k ,uk1 Ik,t j |= Bk,t()`,uk k~(b(Bk,t ()))j =hj`k ,uk0 Ik,t 6|= Bk,t ()62(20)fiPDT LogicNote case nested beliefs, respective entries (~b())j set oneinner belief holds thread hj , i.e., assumed hj point view thread`k ,uk() satisfied thread.agent k checked whether ks belief Bk,tUsing (19) (20), determine matrix Pt0 () probabilities pTi,th0 k ()agent assigns time t0 event , possible pov threadsTh1 , ..., Thm :4h1p1,t0.Pt0 () = bs(hD, Hi, t0 ) ~b(), ..., ~b() =..pTn,th01. . . pT1,th0m...... (). . . pTn,th0m(21)n agents threads, results n matrix. rows matrixseen conditional probabilities: agent believes time t0 fact trueprobability pTi,th0 k () given system pov thread Thk .Remark 3.7. Computation Pt0 () straightforward cases 20.a) 20.b). computeprobabilities nested beliefs 20.c), start computing innermost belief(which instance case 20.a) case 20.b) since assume finite expressions),compute nested beliefs iteratively.Using Definition 3.11 (p. 57) Equation (21), provide definitionsatisfiability validity beliefs:Definition 3.16 (Validity satisfiability beliefs). Let B belief formula definedDefinition 3.4 (p. 46), hD, Hi pointed doxastic system, Pt0 () correspondingmatrix probabilities time t0 defined (21). B satisfiable (valid) w.r.t. hD, Hi iff`,u1. B = Bi,t0 ():least one (all) thread(s) Thk , entries row Pt0 () satisfy `hkhkpi,t0 () u pi,t0 ().`,u2. B = Bi,t0 ():least one (all) thread(s) Thk , entries row Pt0 () satisfy ` >hkhkpi,t0 () u < pi,t0 ().3. B = B1 B2 :least one (all) thread(s) Thk , entries corresponding rowsPt0 () satisfy B1 B2 .4. B = B1 B2 :B1 satisfiable (valid) B2 satisfiable (valid).4. Since consider every possible pov thread Thk , multiply every matrix ATt hbs(hD, Hi, t) ~b(), thus need use vector ~b(), ..., ~b()rows.63fiMartiny & MollerRemark 3.8. distinction valid satisfiable belief formulae interestbeliefs time > t(H). time points t(H) agents belief uniquely determined given observations (cf. Proposition 3.6), resulting single probabilityassociated belief. Therefore, invalid belief formulae t(H) unsatisfiable.Definition 3.4 (p. 3.4) follows belief object atomic belief formula BDefinition 3.16-1 arbitrary belief formula. inner belief formulaB 0 one cases defined Definition 3.16, validity satisfiability entire`,u0expression B = Bi,t0 (B ) follows inductively definition: least one(all) thread(s) Thk , inner belief formula B 0 satisfied limits`,u0outer belief respective thread satisfied, entire belief formula B = Bi,t0 (B )satisfiable (valid).Definition 3.16 gives rise important property belief operator, followinglemma shows:`,uLemma 3.7 (Distributivity belief operator). Let B = Bi,t0 (1 2 ) beliefformula belief object (1 2 ) connective {, }. Then, express`,u`,uB equivalently B 0 = Bi,t0 (1 ) Bi,t0 (2 ).Proof. result follows immediately validity satisfiability beliefs Definition 3.16:`,uformula B = Bi,t0 (1 2 ) satisfiable (valid) iff least one (all) thread(s)hk holds hk |= 1 Thk |= 2 respective entries Pt0 () satisfy`,uDefinition 3.16-1. former case, Bi,t0 (1 ) satisfiable (valid) well,`,ulatter case Bi,t0 (2 ) satisfiable (valid), reflects exactly definition disjunctive`,u`,ubelief formulae Definition 3.16-4. Thus, B 0 = Bi,t0 (1 ) Bi,t0 (2 ) satisfiable (valid)`,uiff B = Bi,t0 (1 2 ) satisfiable (valid).`,uSimilarly, formula B = Bi,t0 (1 2 ) satisfiable (valid) iff least one (all)thread(s) hk holds Thk |= 1 Thk |= 2 hold respective`,u`,uentries Pt0 () satisfy Definition 3.16-1. Then, Bi,t0 (1 ) Bi,t0 (2 ) satisfiable`,u`,u(valid) thus, formula B 0 = Bi,t0 (1 ) Bi,t0 (2 ) satisfiable (valid) according`,u`,udefinition Definition 3.16-3. Thus, B 0 = Bi,t0 (1 ) Bi,t0 (2 ) satisfiable (valid) iff`,uB = Bi,t0 (1 2 ) satisfiable (valid).illustrate evolution beliefs, finish train example analysisexpected arrival times.Example 3.10 (Trains continued). D, specified Example 3.9 (p. 60),infer Bob (and course Alice, too) safely assume time 1 Alice arrivetime 8 latest probability range [0.9, 1], expressed beliefformula0.9,1 ef rBB,t = BB,t(r7 (on(A, T1 ), (at(T2 , CB ) on(A, T2 ))))64(22)fiPDT Logic= 1. rule, obtain frequenciesefr(T h, at(T1 , CA ), (at(T2 , CB ) on(A, T2 )), 7) = 1efr(T h, at(T1 , CA ), (at(T2 , CB ) on(A, T2 )), 7) = 0h {T h1 , ..., h5 },h {T h6 , ..., h9 },i.e., threads h1 , ..., h5 Figure 1 (p. 50), event (at(T2 , CB ) on(A, T2 )) occurswithin 7 time points following event on(A, T1 ) time = 1 (and thus time = 8latest), threads h6 , ..., h9 , event (at(T2 , CB ) on(A, T2 )) occurstime = 9, outside scope r7efr thus yields frequency zero.time point 1, Bob still considers threads possible, thus Bobs subjectiveposterior probabilistic interpretationThIB,1(T ) = 0.7 0.02 0.09 0.02 0.09 0.01 0.02 0.02 0.03equal prior interpretation given Example 3.6 (p. 53) possible pov threadsTh. Combining interpretation frequencies given yields sumXThIB,1(T h) efr(T h, at(T1 , CA ), (at(T2 , CB ) on(A, T2 )), 7) = 0.92hTthus formula BB,1 valid.Now, consider previously described situation, T1 running lateinform B it. leads updated interpretations given (6) (7)page 54, i.e.,h4IA,3=(Th4IB,30000.4 00.2 00.4 0 ),( 0.82 0.02 0.10 0.02 0 0.02 0 0.02 0 ).updates lead significant divergence belief expected arrival time:corresponding sum respect Alices updated interpretationXh4IA,3(T h) efr(T h, at(T1 , CA ), (at(T2 , CB ) on(A, T2 )), 7) = 0.4,(23)hT(24)obtained Alices subjective posterior probability assignment thread h4 ,nonzero summand sum; threads h either impossibleh4Alices point view (i.e., IA,3(T h) = 0 threads h {T h1 , h2 , h3 , h5 , h7 , h9 }),corresponding frequency zero (for threads h6 h8 ). Thus, Alices beliefarriving time point 8 latest drastically reduced, lower bound ` Alicesbelief may exceed 0.4. instance,0.4,1 ef rBA,3r8 (on(A, T1 ), (at(T2 , CB ) on(A, T2 ))) ,(25)valid belief formula. corresponding sum Bobs belief time point 3Xh4IB,3(T h) efr(T h, at(T1 , CA ), (at(T2 , CB ) on(A, T2 )), 7) = 0.96,(26)hT65fiMartiny & Mollerobtained summing Bobs subjective posterior interpretations threads h1 , ..., h4 ;remaining threads contribute zero summands either Bobs probability assignment corresponding frequency zero threads. Thus, Bobsprevious belief (expressed (22)) remains valid time point = 3, denoted BB,3 .Even though Alices beliefs changed significantly, aware Bob maintainsbeliefs conflicting own, shown following valid expression nestedbeliefs:1,1BA,3(BB,3 )verify nested belief holds, need consider threads Alice considerspossible (T h4 , h6 , h8 ) determine Bobs hypothetical beliefs wouldthreads. h4 , already analyzed (26). Since threads h4 , h6 ,h8 indistinguishable Bob time point 3, analysis results holdthree threads. Consequently, BB3 holds every thread Alice considers possibletherefore sum nested beliefXThIi,t0 (T h) = 1,hTh |=BIB,3B,3i.e., Alice knows Bobs belief outdated.Finally, consider pointed doxastic system hD, Obs{AB} (at(T1 , CC ))3 i, i.e.,situation difference Alice shares observationdelayed train Bob. immediately follows Bob updates beliefsway Alice, turn yields update Alices beliefs Bobs beliefsfollowing expression valid (because 1 valid lower bound longer):1,1(BB,3 )BA,3example shows Alice reason influence actionsBobs belief state therefore decide actions improve Bobs utility (aswait vain).4. Satisfiability Checking PDT Logicsection describe procedures check whether exists modelgiven set belief formulae B. discussions chapter, assume modelssets formulae finite. start formally defining satisfiability checkingproblem PDT Logic. Using semantics previous section, derive modelchecking algorithm based fully specified doxastic systems. Afterwards, show setbelief formulae used specify problem PDT Logic andtogether givenset threadshow transformed mixed integer linear program orderemploy existing solvers decide satisfiability PDT Logic formulae. Finally, showsuitable threads derived given set belief formulae automatically. Usingtransformations linear programs established approach deciding satisfiabilityprobabilistic logics, discussed example Fagin, Halpern, Megiddo (1990).However, priors given, established decision procedures probabilistic logics66fiPDT Logicapplicable PDT Logic due formalisms update mechanism (cf. update ruleDefinition 3.9, p. 54). update mechanismfully specified doxastic system hD, Hi given, define problem checkingwhether set belief formulae B satisfiable respect doxastic systemfollows. Recall Section 3.2.4 use h denote set subjectiveTh induced prior interpretation pov thread Th.posterior interpretations Ii,t0Definition 4.1 (Satisfiability Checking PDT Logic). Let hD, Hi pointed doxasticsystem set threads according prior interpretation specified hD, Hi,B set belief formulae. say B satisfiable w.r.t. hD, Hi existsthread Th corresponding interpretations satisfy belief formulae BB:sat(B, hD, Hi) Th : B B : h |= B(27)specification given, checking satisfiability B respect hD, Hi corresponds checking whether hD, Hi model B. continue introducing modelchecking procedure fully specified input. Afterwards, discuss satisfiabilityset belief formulae B decided prior probabilities, neither threadsprior probabilities given.4.1 Model Checking Algorithmfirst approach developing algorithm check whether given set belief formulaeB satisfied given pointed doxastic system hD, Hi (i.e., checking whether hD, Himodel B) obtained direct application semantics beliefoperator given Definition 3.11 (p. 57). Algorithm 1 shows resulting model checkingprocedure. starts computing belief states possible evolutions world= 1 tmax . Afterwards, iterates belief formulae B B potentialpov threads Thk determine whether interpretation respective pov threadable satisfy current belief formula. thread unable satisfy belief formula,excluded set potential pov threads subsequent checks. least onepotential pov thread remains belief formulae checked (i.e.,least one thread Thk belief formulae B B satisfied), hD, Hi modelB.Theorem 4.1 (Soundness completeness Algorithm 1). decision procedure Algorithm 1 sound complete therefore model checking procedure PDT Logic.Proof. Since presented algorithm essentially inductive application Definition 3.16(p. 63), easy see yields sound complete decision procedure PDT`,u`,u frLogic. Basic belief formulae (Bi,t0 (Ft ) Bi,t0 (rt (F, G))) return satisfiability resultsdirectly using respective semantic definitions (10) (11) calculation rules.`,u`,u000every possible compound belief formula PDT Logic (Bi,t0 (), Bi,t0 (B), B B ,000B B ), procedure provides appropriate rule according Definition 3.16 breakformulae iteratively base formulae obtained, decidedabove.67fiMartiny & MollerAlgorithm 1 Model Checkingprocedure ModelChecking(hD, Hi, B)h1hmbs(hD, Hi, 0) (AT, ...,)001, tmaxbs(hD, Hi, t) bs(hD, Hi, 1) (UtT h1 , ..., UtT hm )B BThkCheck(bs(hD, Hi), Thk , B))\ {Thk }=return falsereturn true. compute belief states. check B satisfied Thk. otherwise remove Thk threads check. exit Th satisfy B. success nonempty checking B Bfunction Check(bs(hD, Hi), Thk , B)switch (B). check formulae according Def. 3.16`,ucase Bi,t0 ():= B 0. check nested belief formulae recursively (B 0 belief formula)0Check(bs(hD, Hi), hk , B ))return falseThPt0 bs(hD, Hi, t0 ) ~b(). use ~b() (20) compute Pt0 elements pi,t0kThThTh. true pi,t0k [`, u]return (` pi,t0k u pi,t0k )`,ucase Bi,t0 ():Pt0 bs(hD, Hi, t0 ) ~b()ThThTh. true pi,t0k 6 [`, u]return (` pi,t0k u pi,t0k )case B 0 B 00 :return (Check(bs(hD, Hi), Thk , B 0 )Check(bs(hD, Hi), Thk , B 00 ))case B 0 B 00 :return (Check(bs(hD, Hi), Thk , B 0 )Check(bs(hD, Hi), Thk , B 00 ))68fiPDT Logicasymptotic complexity Algorithm 1 depends number belief operators`,uBi,t0 () contained B:Theorem 4.2 (Time complexity Algorithm 1). Let B set belief formulae letk number belief operators contained within B. Then, using Algorithm 1 checkwhether given pointed doxastic system hD, Hi threads model B timecomplexity O(k m).Proof. given pds threads k belief formulae B, main procedure callscheck function k times. B base formula single belief`,uoperator Bi,t0 (), single call check function return result. Otherwise,`,ubelief formula B contains one belief operator Bi,t0 (), check functioncalled recursively, base formulae obtained. Thus, k belief operators B,satisfaction checks performed k times, yielding time complexityO(k m).Theorem 4.2 immediately obtain complexity result model checkingproblem PDT Logic:Corollary 4.3 (Complexity model checking PDT Logic). model checking problemPDT Logic PTIME.result shows model checking set belief formulae w.r.t. given pointeddoxastic system done polynomial time. fully specified pds (and therebyexhaustive specification set possible threads ) given, result showsAlgorithm 1 presents tractable procedure perform model checking task. However,approach significant drawback assumes exhaustive specificationtogether precise prior probability assignments I(T ). Although problemdomains actually come specification (e.g., cf. cyber security scenariodescribed introduction), assumption renders Algorithm 1 infeasibleproblem domains. overcome problem, proceed discussing differentapproach, enables satisfiability checking without requiring specification exactprobabilities. Moreover, show representative threads respect set beliefformulae B constructed automatically, positive satisfiability resultspotentially obtained without requiring full materialization possible threads .4.2 Compact Problem Specificationused (pointed) doxastic system specify problem domain modelchecking set belief formulae B PDT Logic. following sections, showreformulate problem extended set belief formulae togethervalue tmax used. main idea approach background knowledge regarding target domain given explicit specification possible threadsaccording probabilities, instead sets rules B describe targetdomain may evolve time. approach several advantages: scenarios,compared requiring exhaustive set possible threads, specifying set rules (whichexpressed prior beliefs) gives natural means specifying background69fiMartiny & Mollerknowledge problem domain (e.g., cf. Example 3.2 page 47, actually startsverbal description rules later introduces corresponding set possiblethreads). Furthermore, using set rules describe problem domain fairly established approach therefore approach provide options simplify transformationexisting problem specifications PDT Logic. Finally, since set possible threadsgrows exponentially every additional time point set time points everyadditional ground atom language L, exhaustive problem specificationset possible threads quickly becomes infeasible, situation coulddescribed succinctly small set rules. Even though succinct specification shifts exponential nature problem required input specificationcomputational efforts, show exponential effect curtailed heuristicsconstructing possible threads automatically.4.2.1 Identification Key Parameters Set Belief Formulaesimplify following discussion, restrict temporal rules use pointfrequency function pfr. Recall point frequency functions used specifyevent F followed another event G exactly time points, existentialfrequency functions efr used specify event F followed another event Gwithin time interval t. existential frequency functions required specify problemdomain, rewrite disjunctions point frequency functions, followingproposition shows. frequency functions defined, presented techniqueseasily adapted.Proposition 4.4 (efr rewriting). existential frequency function efr equivalentlyrepresented disjunction point frequency functions pfr:efr(F, G)rt_pfrrt(F, G)0ttt:Recall that, according Definitions 3.12 3.14 page 59, specification pdsconsists set agents A, set threads , set frequency functions F, matrix|A||T |prior probability distributions A0, set time-stamped observations H.Since use point frequency functions following, set frequencyfunctions F always fixed {pfr}, thus need specify set separately.Instead explicitly specifying set agents A, determine`,ubelief expressions Bi,t0 () contained set belief formulae B. slight abuse`,u`,unotation, use Bi,t0 () B denote belief operator Bi,t0 () appears somewhereset belief formulae B. Then, define set agents AB specified setbelief formulae B`,uAB = {i : Bi,t(28)0 () B}Generally, possible explicit specification set agents largerset AB . However, obvious beliefs expressed agent (i.e.,6 AB ), agent influence satisfiability checking results whatsoever.Thus, agent simply disregarded and, consequently, suffices use set AB .70fiPDT LogicSimilarly, instead specifying set ground atoms language Lsets predicates Lpred constants Lcons , define set event formulae FBrepresenting belief objects occurring set belief formulae Bn`,u`,u fr`,u frFB = F : Bi,t.(29)0 (Ft ) B Bi,t0 (rt (F, G)) B Bi,t0 (rt (G, F )) Bdefinition gives rise potential definition set possible worldsHerbrand base B FB FB (resp. set admissible worlds complyingDefinition 3.5 (p. 48). However, show later, options constrainsets possible worlds allow concise problem representation.Note according Definition 3.2 (p. 45), formulae may include atomsobservation atoms. Consequently, FB specify ontic facts possible worlds,also possible observations ontic facts. approach, occurrencesobservations limited ones specified FB . seen specificationsensor model groups agents G AB .Remark 4.1. strict application (29) would prohibit simple specifications group observations ObsG (l) |G| > 1 B. ensure set admissible worldsactuallyVcontains worlds ObsG (l), full specification observation G 0 G ObsG 0 (l)B would required (otherwise might world B FB |= ObsG (l)satisfies second property definition possible worlds (cf. Definition 3.5)).However, required full specification observation admissible worlds determined solely simple observation specification ObsG (l). order keepspecification B compact possible,allow simple specifications ObsG (l)Vassume expanded G 0 G ObsG 0 (l) creating FB .alternative approach would construct FB ontic facts appearingB create set admissible worlds combining ontic facts possibleadmissible observations w.r.t. Definition 3.5. approaches differ requirementsobservation specifications: former requires specify every possible observation explicitly, latter requires exclude every impossible observation explicitly. Sincescenarios set observations actually possible (w.r.t. problem domain)significantly smaller set admissible observations, presented approachusually yield compact problem specification. desired, one could employlatter approach instead without impacting functionality following methods.Background knowledge regarding target domainthat given explicitrepresentation possible threads beforecan also specified prior beliefs (i.e.,`,ubeliefs Bi,0()) B. Recall Section 3.2.4 assume commonly known priorh equal agents . belief semantics defineddistribution Ii,tBh (cf. Definition 3.11, p. 57), followsrespect probabilistic interpretations Ii,t0`,uevery prior belief Bi,0() common knowledge well. Consequently, expressbackground knowledge prior beliefs arbitrary agent AB .`,u frpointed Section 3, satisfiability beliefs temporal rules Bi,t0 (rt (F, G))certain properties independent respective set threads associatedinterpretation I(T ) (cf. Remark 3.5, p. 58): respective frequency function corresponds71fiMartiny & MollerFF1 FF2 Definition 3.10 (i.e., F contradiction, G tautology, F tautology G contradiction), beliefs either trivially satisfied quantificationsu = 1 (resp. ` = 0) generally unsatisfiable. former case, trivially satisfiable beliefsdisregarded without influencing satisfiability results, latter case satisfiability checking terminate immediately negative result. Thus, followingassume B contains beliefs rules correspond frequency functionaxioms FF1 FF2.Example 4.1 (Trains revisited). informal verbal description train problemgiven Example 3.2 (p. 47) corresponding formal specification setpossible threads Example 3.4 (p. 51)and probability assignments Example 3.6 (p. 53).Using considerations expression background knowledge beliefs rules,reformulate verbal rules given Example 3.2 together probabilisticinformation Example 3.6 set formal beliefs B according explanationsbelow:1,11,1B1 = BA,0at(T,C)Bon(A,),1111A,0.81,.81 pfr(B20 )r0 (at(T1 , CA ), punct(T1 ))BA,0B=2.81,.81 pfrBA,0r0 (at(T2 , CC ), punct(T2 )) ,(B200 )1,1r3pfr ( punct(T1 ) at(T1 , CA ), at(T2 , CC ) on(A, T2 )) (B30 )BA,0B3 =1,1 pfrBA,0(r5 (punct(T1 ) at(T1 , CA ), at(T2 , CC ) on(A, T2 )) , (B300 )1,1B=r2pfr ( punct(T2 ) at(T2 , CC ), at(T2 , CB ) on(A, T2 )) (B40 )BA,0B4 =1,1BA,0r3pfr (punct(T2 ) at(T2 , CC ), at(T2 , CB ) on(A, T2 )) , (B400 )1,1B5 = BA,0r0pfr (punct(train) at(train, city), Obs{A} (punct(train))) ,.93,.93 pfrB6 = BA,0r2 (Obs{A} (punct(train)), Obs{AB} (punct(train))) ,train {T1 , T2 },city {C , C }BNote beliefs expressed time = 0, i.e., prior beliefsdefinition commonly known among agents. beliefs expressed exampleassigned A, could equivalently assigned B both.B1 states train T1 city CA time = 1 Alice train. B2states agents believe trains punctual (denoted punct(train))probability 0.81. probability values example obtained summingprobabilities given Example 3.6 threads given Example 3.4 respectivebelief object satisfied. equivalent representation previous example,72fiPDT Logicuse exact probability values (i.e., ` = u) instead intervals. Note punct(train)additional predicate variable train helps formulate background knowledgeconcise way. Formula B2 yet specify consequences non-punctualtrain are, train expected punctual certain probability. B3 statesAlice able board train T2 three time steps train T1 punctualAlice wait two additional time points otherwise. B4 states train T2arrive city CB two time points city CC . Otherwise arrive onetime point later. B5 states Alice always notice train leaves citypunctually. example sensor model specification discussed above. Finally,B6 states Alice call Bob probability 0.93 train punctual.Example 4.2 (Trains continued). definition set belief formulae Bexample, also specify set event formulae FB required modelpossible scenarios described B:at(T,C),at(T,C),at(T,C),at(T,C),1122BBCon(A, ), on(A, ), punct(T ), punct(T ),1212FB =Obs{A} (punct(T1 )), Obs{AB} (punct(T1 )),Obs (punct(T2 )), Obs(punct(T))2{A}{AB}simplify following discussion, assume conjunctive formulae B = B 0B replaced individual formulae respective conjuncts: B = B \{B} {B 0 , B 00 }. impact satisfiability checking properties Bformulae B satisfied simultaneously order return positive resultthus, B 0 B 00 satisfied, regardless representation twoindividual formulae one conjunction.Now, remains determined set threads , corresponding priorB 00|A||T |probability distribution I(T ) (resp. matrix prior probability distributions A0,every row formed I(T )), possibly set time-stamped observation atomsH. tasks determining H treated jointly: since set relevantthreads needs determined anyway, simply create |= H.next section show transform set PDT Logic belief formulaeB together given set threads linear program order determinesatisfiability B respect . Afterwards, discuss suitable setthreads represent information contained B constructed automatically.Using results, possible model problem domain PDT Logic solelyset belief formulae B together specification maximum time point tmax .key parameters domainsuch set agents set groundatomscan extracted B automatically.4.3 Representing Satisfiability Problem Linear Programconsiderations previous section show parameters problemspecification extracted given set belief formulae B. section,assume set belief formulae B together set possible threads given.73fiMartiny & MollerB satisfiable respect (denoted sat(B, )) prior interpretation I(T )found belief formulae B satisfied. extracting linear constraintsI(T ) B, show satisfiability problem transformed linearprogram. Checking satisfiability B respect equivalent checkingwhether corresponding linear program feasible solution.given set threads unknown prior interpretation I(T ), satisfiabilitychecking task significantly increases complexity compared model checking task.Formulation satisfiability checking problem Definition 4.1 (p. 67) might somewhat delusive: existence single thread context interpretationsuffices verify satisfiability set belief formulae B, appears intuitive developmethod construct threadif possibleand neglect threads, or, viceversa, start entire set threads iteratively prune threads fail satisfy formula B. fact, pruning approach used Algorithm 1 (p.68)check whether given set threads model set belief formulae. Unfortunately,approaches inapplicable prior interpretation unknown. semanticsbelief operators (cf. Definition 3.11 (p. 57) relies subjective posterior probabilistic interpretations (i.e., probability assignments multiple threads), generally possiblefind single thread Th satisfying satisfiability checking problem Definition 4.1without determining probabilities threads. Vice versa, generally possiblediscard thread, determining whether satisfies belief formuladone respective probability assignment known. Instead, show beliefformulae equivalently expressed sets linear constraints unknown priorinterpretation I(T ). Then, checking satisfiability B equivalent checking whetherpossible assignment I(T ) constraints satisfied.use xk denote unknown prior probability thread hk , i.e., containsthreads, unknown prior probability assignment representedI(T ) = x1 , , xm.(30)goal following methods provide constraints xk beliefformulae B B satisfied. Since variables represent probability distributionset threads, two obvious constraints begin with:0 xk 1, k {1, ..., m}Xxk = 1(31)(32)k=14.3.1 Representation Subjective Posterior ProbabilitiesSince semantics beliefs defined terms respective agents subjective probability assignments respective pov thread, need means express subjectiveTh agent terms prior probabilityposterior probabilistic interpretations Ii,t0values xk . interpretations change time point whenever observation Obs{i} (l)tpossible agent i. observation possible agent, partition setthreads two sets: one partition containing set threads agent observe74fiPDT Logicrespective fact l one partition agent observe respective fact.subjective probability assignments need updated within partition reflectinformation observation occurrences: Taking every thread within partitionpossible pov thread, probability assignments threads within partitionneed scaled according update rule Definition 3.9 pov thread specificprobability assignments threads outside respective partition need setzero.Generally, leads one vector subjective probabilities threads everypossible pov thread (cf. Definition belief states Equation (17), p. 61). However,leverage semantic properties PDT Logic obtain parsimonious representationupdated subjective probabilities without representing every pov thread explicitly.Note threads within one partition described indistinguishable agentrespective time point (i.e., threads within one partition exhibit exactlyset observations agent time point t) therefore receive probabilityassignment every possible pov thread within partition (cf. Proposition 3.6, p. 62).Consequently, updated probability assignments every thread receiveone two different types value assignments: scaled version threads previousprobability assignment according Definition 3.9 (p. 54), zero, depending whetheragent actually observes fact l not. following proposition showsneed consider cases zero probabilities order perform satisfiability checkingtasks.h subjective posteriorProposition 4.5 (Irrelevance zero-interpretations). Let Ii,t00probability interpretation time agent pov thread Th (i.e., interpreta-tion determined prior interpretation interpretation updates correspondingpov thread Th). interpretation assigns probability zero thread h (i.e.,Th (T h) = 0), satisfiability subsequent nontrivial belief B 00 () t00 > t0Ii,t0i,th (T h).independent Ii,t0`,uProof. Every belief Bi,t0 () ` > 0 fact another belief (i.e., = Ft` ,u= Bj,tj j ()) requires needs least one thread h nonzeroh (T h) = 0 clearlyprobability h |= . Therefore, thread h Ii,t0`,u000prove satisfiability belief Bi,t00 () . negative satisfiability result (i.e., Bunsatisfiable w.r.t. ) cannot obtained zero assignment either,consistent interpretation (i.e., probability assignments threads sum one)needs assign nonzero probability least one thread, could possibly`,usatisfy belief. considerations hold beliefs Bi,t0 () ` = 0 u < 1:h (T h) = 0 satisfies lower bound ` = 0, upper bound u < 1Although thread Ii,t0h (T h0 ) > 0requires existence another thread h0 nonzero probability Ii,t0h (T h) = 0 prove satisfiability beliefs B `,u ()h0 |= . Consequently, Ii,t0i,t0` = 0 u = 1. trivial beliefs satisfied every threadevery possible probability assignment thus, satisfiability proven withoutTh (T h) = 0, too.Ii,t075fiMartiny & Moller`,u frAnalogous considerations hold beliefs rules: belief Bi,t0 (rt (F, G)) ` > 0requires existence thread nonzero probability fr(T h, F, G, t) > 0,Th (T h) = 0 cannot prove satisfiability belief. Satisfiaand thus thread h Ii,t0`,u frbility belief Bi,t0 (rt (F, G)) ` = 0 u < 1 depends respective frequencies0fr(T h , F, G, t) additional threads h0 nonzero probabilities.result proposition, merge nonzero entries cases (agentobserves fact l agent observe fact l) single probabilitydistribution vector agent time point t. yields modified versionupdate rule Definition 3.9. use modified update rule determine linearconstraints unknown prior probabilities xk .Definition 4.2 (Modified update rule). Let agent, t0 time point observation Obs{i} (l) occur h thread. Then, compressed subjective posteriorprobability assignment Ii,t0 (T h) agent time t0 thread h givenIi,t0 (T h) =1Ii,t0 1 (T h)Thi,t0(33)h normalization factor ensure probabilities threadsi,t0agent considers possible sum one:XThIi,t0 (T h0 )i,t0 =h0 (t0 )Ki (T h(t0 ))Example 4.3 (Modified update rule). illustrate modified update rule, returnsituation described Example 3.7 (p. 54). example assumed train T1running late inform B it. resulted following updatedinterpretation A:Th8Th6Th4= 0 0 0 0.4 0 0.2 0 0.4 0= IA,3= IA,3IA,3given example, two additional hypothetical partitions set threadspossible Alice time point = 3 . train T1 running late informB it, threads h5 , h7 , h9 indistinguishable A, yielding updatedsubjective interpretationTh5Th7Th9IA,3= IA,3= IA,3= 0 0 0 0 0.14 0 0.65 0 0.21T1 time, Alice considers threads h1 , h2 , h3 possible. correspondingsubjective interpretationTh1Th2Th3IA,3= IA,3= IA,3= 0.86 0.03 0.11 0 0 0 0 0 0three different subjective interpretations nonzero entries exactly threadspartitions respective pov thread. Since partitions overlapping, merge nonzero entries single probability vectorIA,3 = 0.86 0.03 0.11 0.4 0.14 0.2 0.65 0.4 0.21 .76fiPDT LogicNote modified update rule, update pov thread specify interpretations threads anymore, instead reflexive interpretationsthread h, given h pov thread, used. discussed above,satisfiability problem still sufficient representation posterior probabilities,potential pov threads Th respective partition indistinguishableagent therefore yield exactly interpretations. noted however Ii,t0 (T h) probabilistic vector anymore, i.e., elements sumone. Compared representation belief states Section 3.3.1 (p. 61), informationdistinguishable worlds lost. Thus, reconstruction agents belief staterepresentation possible additional specification respective relationsKi .Returning problem representation (30) (p. 74), use modified update rule obtain inductive definition subjective posterior probabilities basedrespective (unknown) prior probabilities xk . I(T ) = x1 , , xm prior interpretation set threads, agent compressed subjective posterior interpretationsIi,t0 time point t0 first possible interpretation representedIi,t0 (T ) =11i,t0x1 , ,1i,t0xm0,(34)k determinedupdate factors i,t01i,t0i,t1,1.i,tx,,x=01.....0i,tm,1i,t0j,k0i,t1,m... ,0i,tm,m(1 hk (t0 ) Ki (T hj (t0 ))=0 hk (t0 ) 6 Ki (T hj (t0 ))0(symmetric) matrix indicators i,tj,k denoting whether agent considers thread0hk possible thread hj time . Using (34) base case, defineinterpretation updates next possible observation time t00 inductivelyIi,t00 (T ) =11i,t0011i,t0x1 , ,1i,t001i,t0xm(35)simplify notation, following use single factor aki,t0 represent agk k ...) observations occurgregated sequence scaling factors (i,ti,t21time points t1 , t2 , ... = 1 = t0 agent i, i.e., agent subjective posteriorinterpretations Ii,t0 (T ) time t0 givenIi,t0 (T ) = a1i,t0 x1 , ,i,t0 xm.(36)Note potential interpretation updates agent occur time pointobservation Obs{i} (l) possible time point. Hence, timeinterval two possible observations, subjective interpretations constant:77fiMartiny & MollerProposition 4.6 (Piecewise constant interpretations). Let t1 t2 t1 < t2 twotime points observations agent possible t1 t2 , timepoint t1 t2 . Then, compressed subjective interpretation Ii,t0 (T )constant time points t1 < t2 :[t1 , t2 1] : Ii,t (T ) = Ii,t1 (T )proposition states constraints identified following sectionrestrict subjective interpretations single time points, instead restrictinterpretations respective time interval two possible observations.4.3.2 Extracting Linear Constraints Belief Formulaeestablished representation (36) subjective posterior interpretationsterms unknown prior probabilities xk , use representation extract linearconstraints xk set belief formulae B.assume distributive property belief operator Lemma 3.7 (p. 64)`,uapplied whenever possible, i.e., belief formulae Bi,t0 (B1 B2 ) {, }`,u`,useparated Bi,t0 (B1 )Bi,t0 (B2 ). Furthermore, without loss generality, assumeconjunctive formulae B = B1 B2 replaced B \ {B} {B1 , B2 }trivial beliefs (with ` = 0 u = 1) removed B.Moreover, assume belief formulae B B represented negation normalform (NNF), i.e., negation operator applied atoms. Since arbitrary logicformula equivalently expressed formula NNF (cf. e.g., Baaz, Egly, Leitsch,Goubault-Larrecq, & Plaisted, 2001), assumption restrict B either.assumptions, following types belief formulae B occur B:`,uatomic belief formulae B = Bi,t0 ()`,unegated atomic belief formulae B = Bi,t0 ()disjunctive belief formulae B = B1 B2types, show respective formula expressedset linear constraints prior probabilities xk .Atomic Belief Formulae Using parsimonious representation subjective posteriorinterpretations Ii,t0 (T h) given modified update rule Definition 4.2 requiresadaption deciding satisfiability belief formulae. Before, satisfaction beliefformula given pov thread could determined summing respective subjective interpretations threads belief object satisfied. Threadsagent consider possible anymore w.r.t. given pov thread automaticallyexcluded probability assignment zero. compressed representation,respective probability assignments threads considered impossible overloadeddifferent probability assignments given agent another pov thread, illustratedExample 4.3. obtain adapted version satisfiability testing explicitly ensuringinterpretations threads summed still considered possiblew.r.t. respective pov thread. additional constraint excludes summands78fiPDT Logiczero-values, original semantics still maintained. Thus, use equivalence classes1 , C 2 , ...} represent set distinguishable situations agent time t0 .Ci,t0 = {Ci,t0i,t0Naturally, two threads h1 , h2 indistinguishable therefore equivalenceclass agent time t0 , exhibit exactly observations agenttime points {1, .., t0 }. threads outside particular equivalence class receiveprobability zero every pov thread Th within respective equivalence class andasdiscussed previous sectiontherefore contribute satisfiability properties. Then, belief semantics Definition 3.11 (p. 57), instead summingk : (Th C k )threads h certain properties, restrict range h Ci,ti,tmaintaining original semantics. Naturally, belief formula satisfiableexists least one equivalence class satisfies respective beliefs. instance,`,ubelief fact Bi,t0 (Ft ) satisfiable respect agent compressed subjectiveposterior interpretation Ii,t0 time t0 iffkCi,t0 Ci,t0 : `Xn:k h (t)|=F )(T hn Ci,tn0ani,t0 xn u(37)constraint equivalently expressed set linear inequalitiesconjunctive disjunctive connectives, leading alternative representationsatisfiability problem.Corollary 4.7 (Alternative satisfiability representation atomic beliefs). Let Ii,t0 (T ) =a1i,t0 x1 , ,Ij,t (T ) = a1j,t x1 , ,compressedj,t xmi,t0 xmrepresentation agent js respective subjective posterior probabilities time t0t, respectively, given (36), let Ci,t0 Cj,t sets worlds agentagent j distinguish respective time point. Then, atomic belief expression Bsatisfiable w.r.t. Ii,t0 (T )`,u1. belief fact B = Bi,t0 (Ft ) iff_k CCi,t0i,t0Xk(T hn Ci,t0n:hn (t)|=F )ani,t0xn `Xk(T hn Ci,t0n:hn (t)|=F )ani,t0xn u!(38)`,u pfr2. belief rule B = Bi,t0 (rt (F, G)) iff_k CCi,t0i,t0Xk )n: (T hn Ci,t0Xn:k )(T hn Ci,t0ani,t0 xn pfr(T hn , F, G, t) `ani,t0 xn pfr(T hn , F, G, t)79u!(39)fiMartiny & Moller` ,u`,uj j3. nested belief B = Bi,t()) iff0 (Bj,t_k CCi,t0i,t0Xk )n: (T hn Cj,tkk }6=)hn |= ({Cj,t Ci,t0Xk )n: (T hn Cj,tk C k }6=)hn |= ({Cj,ti,t0XXn:anj,t xnani,t0 xnk C k }hn {Cj,t0i,t0ujani,t0 xn `k C k }n: hn {Cj,ti,t0hn |=anj,t xn `ju!(40)hn |=discussed above, representations satisfiability beliefs facts (38) beliefsrules (39) obtained directly replacing range threads sumk considered possible agent time t0 . inequalitiesrespective set threads Cj,t0nested beliefs (40) obtained ensuring first two lines every situationagent conceives possible situation agent j (expressed constraintk ) C k C k 6= ), agent js belief respective fact (expressedn : (T hn Cj,tj,ti,t0constraint hn |= ) within [`j , uj ]. latter two lines ensurerespective situations, outer belief agent satisfied, well. Notebelief object (40) might contain additional belief operators, i.e., beliefs multiplelevels nesting expressed. case, evaluation h |= first two lines(40) yields additional constraints type (38)(40), formula evaluatedrecursively.Negated Atomic Belief Formulae satisfy negated atomic belief formula B =`,uBi,t0 (), accumulated probabilities threads satisfy belief objectk must either lower ` higher u, i.e., individualequivalence class Ci,t0disjuncts(38)(40) negated. pushing negations inward usingX( ) representative respective sums defined (38) (39) expresssatisfiability atomic beliefs, represent negations according beliefs expressed(38) (39)!XX_( ) < `( ) < u .(41)k CCi,t0i,t0nested beliefs defined (40) contain negated belief operators, expressedaccordingly replacing conjunctive constraints ` u (resp. `j uj )corresponding disjunctive constraints (41) negated atomic belief formulae.80fiPDT LogicDisjunctive Belief Formulae inequalities, required constraintsdisjunctive formula B = B1 B2 easily expressed additional disjunctioninequalities. Let C1 C2 sets inequalities express satisfiability B1 B2according (38)(41), respectively. Then, constraints B expressedC1 C2(42)Example 4.4 (Trains continued). Example 4.1 (p. 72), set belief formulae Bgiven train example. illustrate extraction linear constraintsset, continue use set threads depicted Figure 1 (p. 50) minormodification: reflect model specified B Example 4.1, assumepredicate punct(train) explicitly encoded respective threads. Moreover,sake example assume prior probabilistic interpretations yet unknown.use x1 , ..., x9 denote unknown probabilities. Note example,dealing prior beliefs, i.e., one equivalence class C =scaling factors ani,t0 equal one. significantly eases presentationexample. course, general deal multiple equivalence classesmultiple varying scaling factors. highly increases complexity presentation,refrain giving explicit examples cases. constraints B extractedfollows:.81,.81 pfrr0 (at(T1 , CA ), punct(T1 )) :belief B20 = BA,0pfr(T h, at(T1 , CA ), punct(T1 ), 0) = 1 h {T h1 , ..., h3 }pfr(T h, at(T1 , CA ), punct(T1 ), 0) = 0 h {T h4 , ..., h9 }thus application rule (39) yields constraintsx1 x2 x3 0.81x1 + x2 + x30.81special case ` = u, simplify constraintx1 + x2 + x3 =0.81Since rules exhibit property, slightly deviate (39)give equivalent equality constraints subsequent rules order simplifypresentation..81,.81 pfrAccordingly, belief B200 = BA,0r0 (at(T2 , CC ), punct(T2 )) obtain:pfr(T h, at(T2 , CC ), punct(T2 ), 0) = 1 h {T h1 , h4 , h5 }pfr(T h, at(T2 , CC ), punct(T2 ), 0) = 0 h {T h2 , h3 , h6 ..., h9 }corresponding constraintsx1 + x4 + x5 =810.81fiMartiny & Moller.93,.93 pfrbelief B6 = BA,0r2 (Obs{A} (punct(train)), Obs{AB} (punct(train))) :h {T h1 , h3 , h5 , h9 } :pfr(T h, punct(train), Obs{AB} (punct(train)), 2) = 1,h {T h2 , h4 , h6 } :pfr(T h, punct(train), Obs{AB} (punct(train)), 2) = 0,h {T h7 , h8 } :pfr(T h, punct(train), Obs{AB} (punct(train)), 2) = 0.5thus application rule (39) yields constraintx1 + x3 + x5 + 0.5 x7 + 0.5 x8 + x9 = 0.93remaining beliefs, respective belief objects satisfied every threadthus obtain redundant constraints9Xxk = 1.k=1One easily verify prior probabilistic interpretation given Example 3.6, i.e.,x = 0.7 0.02 0.09 0.02 0.09 0.01 0.02 0.02 0.03indeed solution respect constraints. course, givenexample, solution expected, B defined exactly reflectssituation described examples previous section.4.3.3 Transformation Disjunctive Programevery belief formula B B, extractions linear constraints yield setinequalities formai,1 x1 + ai,2 x2 + ... + ai,m xm bi ,(43)xj representing unknown prior probabilities threads h1 , ..., hm , coefficientsai,j set respective values ani,t0 contribute constraint set zerootherwise, value b1 set respective limit obtained ` u.Corollary 4.7 shows, every belief formula B B yields disjunctive set inequalityconstraints, i.e., every belief formula B introduces branches set linear constraints.collecting inequalities form (43) constrain single branch, expressconstraints matrix form:Ax b,(44)a1,1..A= .an,1...a1,mx1b1.. , x = , b =.xmbman,m82fiPDT Logicform representation close connection linear programming (LP). Linearprogramming (e.g., Murty, 1983) solution method optimization problemslinear function set continuous variables xk optimized respect givenset linear constraints. task satisfiability checking requireoptimization thus actually solving linear program required work,exploit similarities sets linear constraints LP order showsatisfiability problem solved.standard form LP problem (Murty, 1983) gives set constraints exactlyform (44). Every solution x satisfies constraints called feasibleentire solution space (44) called feasible region. Thus, checking whether set beliefformulae B satisfiable equivalent checking whether corresponding LP problemnon-empty feasible region. standard LP problems constraints form(44), feasible region convex polytope, allows performing check littlecomputational effort (Garey & Johnson, 1979).Unfortunately, extracting linear constraints set belief formulae B describedSection 4.3.2 yield single set constraints form (44), insteaddisjunction different sets constraints. gives rise representationsatisfiability checking problem disjunctive program (DP) (Balas, 1998):Corollary 4.8 (Satisfiability Checking Disjunctive Program). Let B set beliefformulae, let set threads let set disjunctive branches linearconstraints extracted B according extraction rules (38)-(42). Then,satisfiability checking problem formulated disjunctive program (Balas, 1998):_Ad x bd(45)dDB satisfiable respect , denoted sat(B, ), (45) solution.disjunctive program called bounded, range every variable xk restrictedlower upper bounds. Since rely bounded property subsequently,state following result:Lemma 4.9 (Satisfiability Checking Bounded DP). Let B set belief formulaeset threads. Checking satisfiability B respect representedbounded disjunctive program.Proof. straightforward result: Corollary 4.8 shows satisfiability checkingPDT Logic represented disjunctive program form (45). Sinceevery variable xk (45) represents probability value, xk naturally bounded0 xk 1.disjunctive program, feasible region cannot guaranteed convex anymore,guaranteed solution space even represents connected region.significantly increases complexity determining whether nonempty solution spaceexists. analyze problem detail show connections establishedsolution approaches, discuss next section disjunctive programform (45) transformed.83fiMartiny & Moller4.3.4 Transformation 0-1 Mixed Integer Linear Programconcept linear programs continuous variables xk subject linear constraintsform (43) extended so-called mixed integer linear programs (MILPs) (Schrijver,1986). Opposed standard linear programming, MILPs requiredvariables xk continuous domain. Instead, MILPs use mix continuousinteger variables. several equivalent ways representing MILP, adoptrepresentation Fischetti, Glover, Lodi (2005), specifies constraintsMILPAx bxj integerjindex set indicating variables xj integer variables. specialcase MILPs 0-1 mixed integer linear programs (Williams, 2009), integervariables xj restricted binary values:Ax bxj {0, 1}(46)jaugmenting set variables x binary switching variables xj every possibledisjunction, possible represent disjunctive programs form (45) 0-1 MILPsform (46) (Balas, 1985). leads central result satisfiability checkingPDT Logic:Theorem 4.10 (Satisfiability Checking 0-1 MILP). Let B set belief formulaeset threads. problem checking satisfiability B respecttransformed corresponding 0-1 mixed integer linear program Bsatisfiable respect iff feasible solution.Proof. Lemma 4.9 shows satisfiability checking PDT Logic representedbounded disjunctive program, set belief formulae B satisfiable iffcorresponding bounded disjunctive program feasible solution. proof Theorem4.4 Balas (1985) shows every bounded disjunctive program equivalentlyrepresented 0-1 mixed integer program . Consequently, satisfiability checkingPDT Logic equivalent checking whether feasible solution.leverage Theorem 4.10 obtain complexity results satisfiability problemPDT Logic:Theorem 4.11 (Complexity PDT SAT w.r.t. given set threads). Checking satisfiability set PDT Logic belief formulae B respect given set threadsNP-complete.Proof. generally known checking whether bounded 0-1 mixed integer linearprogram feasible solution NP-complete (cf. Bienstock, 1996). Theorem 4.10shows satisfiability checking PDT Logic respect given set threadsreformulated 0-1 MILP bounded variables xk (cf. Lemma 4.9), follows84fiPDT Logicsatisfiability checking set belief formulae B respect given set threadsNP.Arbitrary propositional formulae F (cf. Definition 3.2, p. 45) expressed PDT1,1Logic using belief object strict prior belief Bi,0(F ). Since well knownboolean satisfiability problem (SAT) NP-complete (Cook, 1971), followsproblem NP transformed satisfiability checking problem PDT Logic.Hence, satisfiability checking problem PDT Logic NP-hard consequently NPcomplete.NP-completeness result shows problem NP therefore immediately obtain another important property satisfiability problem PDT Logic:Corollary 4.12 (Decidability PDT SAT). Checking satisfiability set PDT Logicbelief formulae B decidable.MILPs subject extensive research decades, thus ample varietysolving methods proposed (e.g., Balas, Ceria, & Cornuejols, 1993, Balas, Ceria,& Cornuejols, 1996, Balas & Perregaard, 2002, name notable workMILP solving, especially Fischetti et al., 2005 Bertacco, Fischetti, & Lodi, 2007find feasible solutions MILPs). research gave rise various efficient implementationsMILP solvers, commercial (e.g., ILOG, 2016, Gurobi Optimization, Inc., 2016)non-profit products (e.g., Gnu Project, 2016, Computational Infrastructure OperationsResearch (COIN-OR) Project, 2016). given set threads, PDT Logic satisfiabilitychecking reformulated 0-1 MILP problem, thus state-of-the-artMILP solvers exploited relatively fast satisfiability checks instancesPDT Logic belief formulae B respect given set threads .results section show satisfiability set PDT Logic belief formulae B decided respect given set threads, even specific priorprobability assignment specified. overall goal section designdecision procedure requires set belief formulae B input, continuediscussion satisfiability testing development method automaticallyconstruct set threads representing background knowledge specified B.4.4 Prior Constraints Possible Threadsdetermine whether set belief formulae B satisfiable, need obtain setpossible threads reflects background knowledge specified B. section,describe identify certain constraints set possible threads prioractually starting generate threads represent information specified B.identify prior constraints, discuss different properties belief formulae contained B. Using properties, create taxonomy belief formulae dependingrespective impact set possible threads . Beliefs certain propertiesused constrain search space sets possible threads prior actually search sets. discussing prior constraints section, useresults Section 4.5 develop decision procedure PDT Logic requires neitherspecification probabilities specification possible threads.85fiMartiny & Moller4.4.1 Taxonomy Belief Formulaeset belief formulae B may contain beliefs various features differentimpacts sets admissible worlds specific time points t. discussfeatures show yield taxonomy belief formulae. taxonomyallows classification beliefs three different types respect impactsets admissible worlds. particular, identify beliefs independentspecific probability assignment Kripke relations Ki . classificationtechnical purposes: beliefs depend neither specific probability assignmentsspecific Kripke relations used derive initial constraints sets possibleworlds time points tmax . use B denote set worldsadmissible respect set belief formulae B, use B (t) denote setadmissible worlds respect set belief formulae B time t.Recall three different kinds beliefs: beliefs facts, beliefs rules,beliefs beliefs. before, differentiate prior beliefs hold time point= 0 (and therefore commonly known among agents) posterior beliefs holdtime points > 0.`,u pfrdistinguish beliefs rules Bi,t0 (rt (F, G)) respect t: callpfrpfr(F, G) dynamic rule > 0. Accordingly,(F, G) static rule = 0 call rtrtseparate beliefs rules beliefs static rules beliefs dynamic rules,respectively. beliefs differ respect temporal impact: static ruleconstrain possible worlds instantaneously, i.e., r0pfr (F, G) statesworld |= F 6|= G hold. dynamic rule hand requireswhenever world |= F occurs, must another world 0 0 |= Gtime steps.Finally, classify beliefs respect probabilistic quantifications: call`,ubelief Bi,t0 () strict, ` = u = 0 ` = u = 1. sake simplicity,following assume without loss generality strict beliefs always represented0,01,1` = u = 1. strict belief Bi,t() easily rewritten Bi,t().5 call belieftrivial ` = 0 u = 1. Obviously, beliefs trivially satisfied arbitraryinterpretation, thus impact satisfiability checking results thereforeremoved B.Remark 4.2. definition belief semantics (Definition 3.11, p. 57) follows1,1special case strict beliefs Bi,t() (i) agent considers occurrence beliefobjects complement impossible (ii) occurrence indeed impossible.Thus, strict beliefs comply common definitions knowledge justified true beliefbelief stable respect truth (cf. e.g., Shoham & Leyton-Brown, 2009,page 433). Consequently, could also refer strict belief knowledge equivalentlyuse established knowledge operator Ki () instead Bi1,1 ().1,1Remark 4.3. Note concept strict beliefs applies positive beliefs Bi,t().1,1negation belief, Bi,t (), follows Definition 3.16 (p. 63)frfr5. belief object temporal rule rt(F, G), represent rt(F, G). possibleneed consider frequency functions correspond axioms FF1 FF2Definition 3.10 (p. 55) use point frequency functions pfr. frequency functions used,negations need defined accordingly.86fiPDT Logicleast one thread satisfy belief object , turn implies ` < 1.1,1Consequently, beliefs Bi,t() considered non-strict following discussion.Using features, create taxonomy beliefs depicted Figure 3identify prior constraints set possible threads. taxonomy obtainedsuccessively distinguishing strict non-strict, prior posterior beliefs,beliefs facts, rules nested beliefs, finally beliefs static dynamicrules. Nested beliefs considered strict (prior) beliefs, involved beliefsstrict (prior), otherwise considered non-strict (posterior). nested beliefactually strict prior, unnest belief consider innermost beliefexpression: since prior beliefs commonly known therefore identical agentsAB , evident strict belief agent i, agents know agentstrict belief. Consequently, strict prior beliefs nested arbitrary depthwithout introducing constraints: satisfied exactly innermostbelief satisfied. Thus, need consider nested strict prior beliefs explicitly.taxonomy gives rise three different types belief formulae respectimpact sets admissible worlds:Definition 4.3 (Belief formula typification). set belief formulae B categorizedthree different types beliefs:Type 0: beliefs restrict set admissible worlds B (t) everytime point . Thus, type 0 beliefs highest impactexploited prune set admissible worlds B globally. evaluationbeliefs relies neither specific probability assignment given Kripkestructures Ki .Type 1: beliefs restrict sequences possible worlds. Moreover,potentially restrict sets admissible worlds B (t) specific time points.Thus, type 1 beliefs less impact type 0 beliefsexploited prune sets admissible worlds B (t) locally. Again, evaluationbeliefs relies neither specific probability assignment givenKripke structures Ki .Type 2: type encompasses remaining beliefs B neither type 0type 1 beliefs. beliefs situation-specific cannot used prunesets admissible worlds priori. Satisfiability beliefs depends suitableprobability assignment evaluation Kripke structures respectivethreads.use Tk (B) denote set type k beliefs B.main goal belief formula taxonomy identify constraints possibleworlds possible threads h evaluated prior searching suitableprobability assignment, namely using belief formulae T0 (B) T1 (B) prunesearch space possible sets threads may show satisfiability B.noted existence thread h violating belief T0 (B) T1 (B)technically preclude satisfiability B respect , special87fiMartiny & Mollerbeliefsnon-strict beliefs`<1strict beliefs`=1` = 1,innermost beprior beliefslief interestposterior beliefst0 > 00=0belief 0 beliefs1,1` ,u0Bi,0(Bj,t())belief beliefs`,u1,1B1,10 (Bj,t ())TF1 (B)belief rules1,1 frBi,0(rt (F, G))belief facts1,1Bi,0(Ft )disjunctive beliefformulae1,11,1Bi,0(1 ) Bi,0(2 )belief dynamic rules> 0belief facts1,1Bi,t0 (Ft )belief rules1,1 frBi,t0 (rt (F, G))disjunctive beliefformulae1,11,1Bi,0(1 ) Bi,0(2 )belief dynamic rules> 0T1 (B)belief static rules= 0T0 (B)Type 0: beliefshighest impact,restrict everyworld every time point.belief static rules= 0Type 1: beliefs restrict threads independently probabiliy assignment.Moreover, potentially restrict possible worlds individual time points.Figure 3: Taxonomy belief formulae88T2 (B)Type 2: remaining beliefs;treated way.fiPDT Logiccase suitable probability assignment: thread hbelief B T0 (B) B T1 (B) satisfied, could still suitable probabilityassignments I(T ) sat(B, ) holds iff I(T h) = 0. effect excludingthread h assigning prior probability I(T h) zero (cf. Remark 3.3,p. 53), i.e., respective thread marked impossible. Since aim reducingsearch space possible threads input satisfiability check sat(B, ),exploit belief formulae T0 (B) T1 (B) exclude impossible threads prior searchingsuitable probability assignments.Type 0 belief formulae depicted Figure 3, set type 0 belief formulae1,1 pfrformed formulae strict prior beliefs static rules Bi,0(r0 (F, G)) B. Sinceprior beliefs represent background knowledge since follows definitionstrict beliefs cannot violated world, clear rule r0pfr (F, G)always satisfied. static rule, satisfied every worldB . define set type 0 beliefs1,1 pfrT0 (B) = {B B : B = Bi,0(r0 (F, G))}(47)arbitrary formulae F G.Type 1 belief formulae set type 1 beliefs contains strict prior beliefsset T0 (B). contributions set T1 (B) twofold: T1 (B)comprises strict prior beliefs, every thread potential set threads satisfybeliefs B T1 (B). Moreover, constraints T1 (B) may constrain sets worldsB (t) individual time points regardless specific thread. AccordingFigure 3, define set type 1 beliefs1,1T1 (B) = B B :B = Bi,0(Ft )1,1 pfrB = (Bi,0(rt (F, G)) > 0)1,11,1B = (Bi,0(1 ) Bi,0(2 ) )(48)potential set possible threads , beliefs specified set T1 (B)satisfied every thread h . Note satisfiability beliefs dynamic rulesdisjunctive belief formulae generally depends worlds multiple time points thussatisfiability T1 (B) cannot ensured constraining sets worlds single timepoints. However, analyzing strict prior beliefs facts potential interplaydynamic rules derive constraints sets worlds B (t) specific time pointsfollows.1,1Strict prior beliefs facts B = Bi,0(Ft ) restrict set admissible worlds B (t)time enforcing F holds every world B (t). following, use TF1 (B)denote strict prior beliefs facts F certain time points t. Moreover, use1,1B |= Ft shorthand Bi,0(Ft ) B denote B enforces F time t.interplay existing constraints sets possible worlds B (t) individualtime points t, strict beliefs dynamic rules yield additional constraints: belief1,1 pfrformula B = Bi,0(rt (F, G)), > 0, additional constraints might derived, dependingtype belief respective rules premise F : (T0 (B) TF1 (B)) |= Ft given,89fiMartiny & Moller1,1extract strict prior belief fact B 0 = Bi,0(Gt+t ), restrictsset possible worlds time point + therefore added TF1 (B).Since dynamic rules considered temporal implications (cf. Definition 3.10Section 3), rules also applied backwards obtain additional constraints:1,1 pfrbelief formula B = Bi,0(rt (F, G)), > 0 given rules negated conclusion Galready enforced time point (i.e., (T0 (B) TF1 (B)) |= Gt ), rules premise1,1F cannot satisfied time t. Thus, add belief B 0 = Bi,0(Ftt )Fadditional constraint T1 (B).Extending set type 1 beliefs dynamic rules may lead chained ex1,1 pfrtension: belief dynamic rule Bi,0(rt (F, G)) corresponding belief1,11,1FBi,0 (Ft ) T1 (B), lead additional belief Bi,0(Gt+t ) TF1 (B),1,1 pfrturn might trigger another dynamic rule Bi,0(rt (G, G0 )). Analogously, additionalbelief TF1 (B) could also trigger backward rule applications.capture constraints emerge forward backward chaining strictdynamic rules, define set TF1 (B) following fix-point set:6TF1 (B) =1,1{Bi,0(Ft ) B}1,1{Bi,0(Gt+t ) :1,1 pfr> 0 Bi,0(rt (F, G)) B(T0 (B) T1 (B)) |= Ft }1,1{Bi,0(Ftt ) :1,1 pfr> 0 Bi,0(rt (F, G)) B(T0 (B) T1 (B)) |= Gt }(49)determined constraints individual time points, reduce1,1set TF1 (B) contains one belief Bi,0(Ft ) every time point t.1,11,1FT1 (B) contains multiple beliefs Bi,0 (Ft ), Bi,0 (Gt ) regarding time point t,1,1replace joint belief Bi,0(Ft0 ) F 0 = F G. Note substitutionuses Lemma 3.7 (p. 64) merge different belief expressions one expressionconjunctive belief object. still assume belief formulae conjunctions beliefoperators separated atomic belief formulae.Type 2 belief formulae set type 2 belief formulae consists beliefs Bneither type 0 type 1 beliefs. Thus define setT2 (B) = (B \ T0 (B)) \ T1 (B)(50)6. representation, considered influence temporal rules set TF1 (B).1,11,1principle, information disjunctive formulae B = Bi,0(1 ) Bi,0(n ) T1 (B) could yieldadditional constraints sets B (t): TF1 (B) enforces n1 disjuncts B false, remainingdisjunct must satisfied. belief objects respective disjuncts might dynamic rules again,formal representation consideration would result rather intricate specification. Sinceensure potential thread satisfies beliefs T1 (B) anyways, omitting disjunctive formulaeconstruction TF1 (B) impact satisfiability results. Yet actual implementationdescribed procedures could exploit consideration obtain additional pruning conditions specialcases.90fiPDT LogicExample 4.5 (Trains continued). Continuing set belief formulae B Example 4.1 (p. 72) assuming conjunctive formulae B = B 0 B 00 treatedindividual formulae B 0 B 00 , obtain following sets typed belief formulae:1,1 pfrT0 (B) = BA,0r0 (punct(train) at(train, city), Obs{A} (punct(train)))(B5 )1,1T1 (B) = BA,0at(T1 , CA )1 ,1,1BA,0on(A, T1 )1 ,(B10 )(B100 )1,1BA,0r3pfr ( punct(T1 ) at(T1 , CA ), at(T2 , CC ) on(A, T2 )) ,1,1 pfrBA,0(r5 (punct(T1 ) at(T1 , CA ), at(T2 , CC ) on(A, T2 )) ,1,1BA,0r2pfr ( punct(T2 ) at(T2 , CC ), at(T2 , CB ) on(A, T2 ))1,1BA,0r3pfr (punct(T2 ) at(T2 , CC ), at(T2 , CB ) on(A, T2 )) ,1,1TF1 (B) = BA,0at(T1 , CA )1 ,1,1BA,0on(A, T1 )1 ,(B30 )(B300 )(B40 )(B400 )(B10 )(B100 )T2 (B) = B \ T0 (B) \ T1 (B).81,.81 pfr= {BA,0r0 (at(T1 , CA ), punct(T1 )) ,.81,.81 pfrBA,0r0 (at(T2 , CC ), punct(T2 )) ,.93,.93 pfrBA,0r2 (Obs{A} (punct(train)), Obs{AB} (punct(train))) }(B20 )(B200 )(B6 )taxonomy belief formulae provides means construct sets admissible worldsB (t) every time point . Type 0 beliefs (i.e., beliefs highest impact)constrain global set possible worlds B . Certain beliefs type 1materializedset TF1 (B)can give additional constraints specific time points t,subsets B (t) B need considered possible worlds time t. setsT0 (B) T1 (B) together provide satisfiability conditions independentspecific probability assignments. Then, beliefs type 2 need consideredprobabilistic constraints check whether B satisfied respect , i.e.,satisfiability problem sat(B, ) previous section reduced sat(T2 (B), ),unsatisfiability B yet shown constraints T0 (B) T1 (B).Since prior constraints define necessary conditions potential thread, giverise definition thread soundness respect given set belief formulae B:Definition 4.4 (Thread soundness). Let B set belief formulae, let T0 (B)T1 (B) set type 0 type 1 belief formulae set, respectively. Then,thread h sound respect B (denoted snd(T h, B)) satisfies belief formulaeT0 (B) T1 (B):snd(T h, B) B (T0 (B) T1 (B)) : h |= B91(51)fiMartiny & MollerAccordingly, use snd(T , B) denote threads h sound.Note definition relies strict prior beliefs soundness propertytherefore verified every thread individually, without consider threadsprobability assignments. Thus, simplified version model checking procedureSection 4.1 used verify soundness. intuition behind propertyverify easily prior checking sat(B, ) therefore obtain reduced versionsatisfiability problem:Theorem 4.13 (Reduced satisfiability checking). Let B set belief formulae, letT2 (B) set type 2 beliefs B according (50), let set soundthreads. Then, B satisfiable respect iff T2 (B) satisfiable respect :sat(B, ) snd(T , B) sat(T2 (B), )(52)Proof. follows directly Definition 4.4: snd(T , B) defined satisfiesbelief formulae sets T0 (B) T1 (B). Consequently, sets resemble tautologiesrespect therefore impact satisfiability checkingproperties. Thus, instead checking B satisfiability, suffices check set (B \T0 (B)) \ T1 (B), exactly definition T2 (B).4.4.2 Constraining Possible Worlds Individual Time PointsUsing classification beliefs B three different types, continueconstructing sets possible worlds B (t) every time point . main goalsection identification obvious pruning conditions possible worlds specifictime points. Since process searching set possible threadssatisfies set belief formulae B, constraints sets B (t) potentialsignificantly reduce later used search space. Thus, results section highlightpossible optimizations implementation PDT Logic sat solver. Even following constraints notor partiallyapplied, search possible threadsdescribed subsequent Section 4.5 carried out, yet potentially larger searchspace.Since set type 0 beliefs satisfied every admissible world, defineglobal set admissible worlds B follows:Definition 4.5 (Global set admissible worlds). Let B set belief formulae,corresponding sets belief objects FB type 0 beliefs T0 (B). Then, setadmissible worlds B w.r.t. B givenn1,1 pfrB = B FB : adm() Bi,0(r0 (F, G)) T0 (B) : |= (F G) .(53)Remark 4.4. definition uses adm() ensure worlds B admissibledefined external Definition 3.5 (p. 48). Alternatively, could use existingformalism encode admissibility conditions directly strict prior beliefs B:1,1 pfr1,1 pfrBi,0(r0 (ObsG (l), l)) G 0 G : Bi,0(r0 (ObsG (l), ObsG 0 (l))) represent conditions 12 Definition 3.5, respectively. However, since conditions independentrespective problem modeled, include problem-specific beliefset B, use external constraints.92fiPDT LogicExample 4.6 (Trains continued). global set worlds B admissible respectB Example 4.1 (p. 72) automatically constructed combinationsevents FB shown Example 4.2 (p. 73), given combinations admissiblerespect Definition 3.5 satisfy type 0 beliefs T0 (B) Example 4.4(p. 81). refrain enumerating worlds explicitly instead describeworlds excluded Herbrand base B FB FB : FB followspossible shared observation B fact train punctual(Obs{AB} (punct(train))). every possible world observation occurs, admissibility conditions require agents B observe respective trainpunctual train indeed punctual. Furthermore, beliefs T0 (B)require corresponding observation every possible worldtrain punctual (which incidentally also enforces admissibility conditionsobservations).Next, build upon set globally admissible worlds B use settype 1 beliefs prune set admissible worlds B (t) individual time pointst:Definition 4.6 (Local sets admissible worlds). Let B set belief formulaecorresponding sets admissible worlds B , TF1 (B) set materialized strictprior beliefs induced T0 (B) T1 (B), set time points. Then, setadmissible worlds B (t) w.r.t. B time givenn1,1FB (t) = B : Bi,0 (Ft ) T1 (B) : |= F.(54)Example 4.7 (Trains continued). obtain scenario original Example 3.2,assume tmax = 9. set TF1 (B) identified Example 4.5, restrict setworlds time 1nB (1) = B : |= (at(T1 , CA ) on(A, T1 ))time points, options restrictions, thus respectivelocal sets B (t) possible worlds time points 6= 1 remain B .Using Definition 4.6, formulate constraints set sound threads :h , : h(t) B (t).(55)Note constraint provides necessary sufficient condition threadsoundness. illustrate this, consider Example 4.5 again: set TF1 (B) requires{at(T1 , CA ), on(A, T1 )} holds every possible world time = 1 thus constrain B (1) shown Example 4.7, thread violating constraintinherently unsound. hand, thread according (55) may containfact, say punct(T1 ) h(1), whichaccording B30 yields sound thread{at(T2 , CC ), on(A, T2 )} h(4) holds well. Thus, (55) provides general constraintsset threads respect beliefs T0 (B) TF1 (B), additional beliefsT1 (B) discard individual threads catching potential unsatisfiable interplaypossible worlds different time points.93fiMartiny & Mollercourse, general possible methods discussed far result specialcases: one thing, possible B induces set T0 (B) TF1 (B) inconsistentbeliefs, i.e., contain beliefs contradict other. Then, B B (t)empty. precludes creation set threads I(T ) |= B.case, satisfiability checking terminate immediately negative result.another, possible simplification process result empty setT2 (B). case, probabilistic constraints could impact satisfiabilityB thus unnecessary search suitable probability assignment. case,needs checked whether threads compliance (55) sound accordingDefinition 4.4. thread found, satisfiability checking terminateimmediately positive result, otherwise B unsatisfiable. Verifying soundnesssingle thread done simplified version model checking procedureSection 4.1 therefore PTIME (cf. Corollary 4.3). However, number threadssatisfying condition (55) grow exponentially number ground atomsnumber time points, problem finding sound thread complex:Theorem 4.14 (Complexity finding sound thread). Let B set belief formulaeincluded formulae grounded. Deciding whether exists sound threadrespect B, defined Definition 4.4, NP-complete.Proof. According Definition 4.4, set sound satisfies formulae setT0 (B) T1 (B). treating belief objects atoms F time points individualvariables Ft , transform beliefs facts belief rules T0 (B) T1 (B)boolean sat problem follows:71,1Bi,0(Ft )Ft1,1 pfrBi,0(rt (F, G))tmax^tt=0(Ft Gt+t )Accordingly, disjunctive belief formulae expressed transforming everydisjunct individually. transformation requires tmax conjuncts every beliefoperator therefore performed linear time. Since boolean sat problemknown NP-complete (Cook, 1971), follows searching sound threadrespect B NP.NP-hardness problem already shown proof Theorem 4.11(p. 84) consequently follows searching sound thread respect BNP-complete.noted result analyzes worst-case complexity problem,practice finding sound thread usually dominated worst case.cases, sound thread found easily employing principle least effort:1,1 pfrbelief temporal rules Bi,0(rt (F, G)), choosing worlds |= F ensuresconsequences rule evaluated time points. Accordingly,7. transformation defined temporal rules point frequency functions pfr.frequency functions used, transformation adapted accordingly.94fiPDT Logicdisjunctive rules disjunct selected temporal rule triggeredfact. course, heuristic may give sound thread immediatelyevery input B, represents feasible approach problems. illustrateapproach example subsequently.work, consider ground formulae PDT Logic. general, formalismintroduced Section 3 allows treatment non-ground formulae well. However,non-ground formulae complexity result Theorem 4.14 hold,transformation boolean sat problem exponential number possiblegroundings. Finding sound thread requires use sophisticated grounding procedures, (e.g., Dal Palu, Dovier, Pontelli, & Rossi, 2009 Faber, Leone, & Perri, 2012),beyond scope work.sets possible worlds identified every time point , proceedcreating sets representative threads respect constraints. aimfollowing discussion successive generation set representative threadssat(B, ) decided.4.5 Representative ThreadsUsing Definition 4.4 constraint (55) gives rise potential definition setpossible threads constructing possible combinations sound world sequencesB (t) . However, would still result unnecessarily large set possiblethreads. Instead constructing threads explicitly, heuristically createrepresentative threads represent excerpts situations modeled T2 (B).approach uses heuristics successively expand set representative threads. soonsuitable set threads (i.e., model B) found, decision procedure terminatepositive result. set representative threads show satisfiabilityB, additional threads created either positive satisfiability result obtainedpossible threads created. Consequently, heuristic search modelsconstitutes complete decision procedure PDT Logic.following discussion, assume set T2 (B) nonempty, i.e.,additional constraints need satisfied generated set threads. Otherwise,set T2 (B) empty, satisfiability could already determined checking whethersound thread respect B exists, discussed previous sectionwould need generate specific set threads.`,u`0 ,u0beliefs facts Bi,t0 (Ft ) B, dual belief negated fact Bi,t0 (Ft )`0 = 1 u u0 = 1 ` (cf. Corollary 3.4, p. 59) satisfied well.`,u frbeliefs rules Bi,t0 (rt (F, G)), satisfiability depends accumulated subjective posterior interpretations threads weighted respective frequencies. goal`,ufollowing procedure successively create threads every belief fact Bi,t0 (Ft )T2 (B), obtain representatives set threads (i) satisfyrespective fact Ft set threads satisfy Ft , (ii) exhibit varying fre`,u frquencies beliefs temporal rules Bi,t0 (rt (F, G)) T2 (B). Consequently, beliefformulae considered splitting rules application generate representative threads results procedure similar tableau-based methods. However, beliefstemporal rules induce splits forward backward time thusunlike con95fiMartiny & Mollerventional tableau-based methodsthe following procedure create tree structure,instead set sequences represent possible threads. key differencegeneration representative threads logical sat solvers PDT Logicvirtually impossible discard generated potential thread: probabilistic nature semantics requires threads considered given formulaholds, also threads not. Thus, even threads violating objects givenbelief formulae usually required show satisfiability corresponding set beliefformulae B. following discussion provides general outline decision procedurePDT Logic set belief formulae B given. actual implementationmethods possible, obtain feasible run times practical problems, variousoptimization techniques research logic reasoning implementations would needimplemented, beyond scope work.4.5.1 Generating Representative Threads`,uSince existence non-strict belief fact Bi,t0 (Ft ) requires existenceleast two threadsone, respective belief object satisfied one,not8 start creating two threads hB (1), ..., B (tmax )i obtainset = hT h1 , h2 h1 |= h2 |= belief objects = Ft containedset T2 (B) obtain minimal set set threads belief formulaeB T2 (B) potentially satisfied. set subsequently expandedadditional threads either suitable set threads show satisfiability T2 (B)found, additional threads created.allow concise notation, following adapt frequency notationbelief objects use (1 ) denote true, (0 ) denote false,generally (x ) denote holds frequency x. course, values 0 < x < 1occur belief objects represent temporal rules. notation, trycreate initial sound threads^h1 |= (1 j ),(56)jh2 |=^j(0 j )(57)holds respective belief objects j belief formulae Bj T2 (B).9initial set = {T h1 , h2 } meant represent two extreme choices possiblethreads respect T2 (B) provide suitable starting point subsequentlyemployed search heuristic. general, necessarily possible create extremethreads compliance (56) (57) every possible set belief formulae T2 (B).`,u`,uinstance, T2 (B) might contain conflicting beliefs facts Bi,t0 (Ft ) Bi,t0 (Ft ). Obviously,single thread satisfy belief objects simultaneously, might still possible`,u8. Technically, non-strict belief Bi,t0 () could satisfied single thread h h |=beliefs quantification upper bound u = 1. might give rise optimizationsactual implementation, sake simplicity, consider case explicitly.`,u`,u0009. notation slightly simplified: disjunctive belief formulae Bj = Bi,t0 (j ) Bi,t0 (j ), use j000abbreviation j j .96fiPDT Logiccreate set threads thattogether suitable probability assignmentbothbeliefs satisfied. Thus, (56) (57) characterize intended goal creatinginitial threads h1 , h2 , represent hard constraints threads.find suitable threads match constraints, employ principle least`,ueffort adding facts possible thread: every belief fact Bi,t0 (Ft ),add explicit constraints F h1 (t) F 6 h2 (t), h1 representsthread belief objects true h2 represents set belief objects`,u frfalse. beliefs rules Bi,t0 (rt (F, G)) add G h1 (t + t) (resp. F h1 (t t))whenever another constraint enforces F h1 (t) (resp. G h2 (t)). occurrencefr (F, G) trivially satisfied frequencyF respectively G enforced h1 , rule rt1 (i.e., occurrences F followed G steps)constraints need added. Analogously, h2 need ensure F holdsleast whenever F h2 (t) holds, G h2 (t + t) holds, well.`,u`,udisjunctive belief formulae Bi,t0 (1 ) Bi,t0 (2 ), need ensure belief object 12 holds thread h1 , described above, 1 2 holds thread h2 .possible, respective belief object 1 2 thread h1 chosenadditional beliefs triggered (we say belief triggered fact F , existenceF enforces another constraint belief temporal rule disjunctive beliefformula). Nested belief formulae treated respect innermost beliefobject. constraint cannot applied conflict previously addedconstraints T2 (B), simply skipped stage. creation h1 h2initialization step heuristic search possible set threads, skipped constraintsstill considered later subsequent expansions.Whenever constraint regarding fact F added h1 h2 , necessarycheck whether triggers additional rules set type 1 beliefs T1 (B). necessary,resulting facts added respective threads. application works analogouslyconstruction set TF1 (B) described Section 4.4.1. Finally, beliefformulae processed, search sound thread respect createdconstraints. Usually, sound thread found easily choosing factsyet unconstrained h1 h2 trigger additional beliefs.Especially, possible worlds h(t) unconstrained, choose h(t) = Bcontain belief rules purely negative preconditions disjunctive beliefformulae satisfiable . generally, principle least effortemployed worlds selected belief formulae needconsidered. selection impossible addition F Fworld triggers additional beliefs. Then, consequences adding respective factneed evaluated, well. resulting set = {T h1 , h2 } provides minimalset representative threads used check sat(T2 (B), ).following, show principle least effort used obtain representative threads efficiently possible. constraints used following exampleprovide minimal number constraints need enforced obtain representative threads desired threads h1 h2 . worlds without specificconstraints, simply use = . One easily verify indeed yields threadscompliance (56) (57).97fiMartiny & MollerExample 4.8 (Trains continued). continue train example sets typedbelief formulae specified Example 4.5 (p.91). Example 4.7 (p. 93), shownset worlds time 1 B (1) restricted {at(T1 , CA ), on(A, T1 )}every world B (1). set T2 (B) contains three non-strict belief formulae, namely.81,.81 pfrT2 (B) = {BA,0r0 (at(T1 , CA ), punct(T1 )) ,(B20 ).81,.81 pfrBA,0r0 (at(T2 , CC ), punct(T2 )) ,(B200 ).93,.93 pfrBA,0r2 (Obs{A} (punct(train)), Obs{AB} (punct(train))) }(B6 )evaluating belief formulae, obtain constraints possible worldsthreads h1 h2 . visualization following steps given Figure 4.Analysis belief formula B20 results constraints punct(T1 ) h1 (1)punct(T1 ) 6 h2 (1). facts turn trigger rules B30 B300 , respectively:1,1BA,0r3pfr ( punct(T1 ) at(T1 , CA ), at(T2 , CC ) on(A, T2 ))1,1 pfrBA,0(r5 (punct(T1 ) at(T1 , CA ), at(T2 , CC ) on(A, T2 )) ,(B30 )(B300 )resulting additional constraints {at(T2 , CC ), on(A, T2 )} h1 (4) {at(T2 , CC ),on(A, T2 )} h2 (6).Application belief formula B200 yields additional facts punct(T2 ) h1 (4)punct(T2 ) 6 h2 (6). Again, triggers rules T1 (B):1,1(B40 )r2pfr ( punct(T2 ) at(T2 , CC ), at(T2 , CB ) on(A, T2 ))BA,01,1 pfr(B400 )(r3 (punct(T2 ) at(T2 , CC ), at(T2 , CB ) on(A, T2 )) ,BA,0resulting additional constraints h1 (6) = at(T2 , CB ), on(A, T2 ) h2 (9) =at(T2 , CB ), on(A, T2 ).Note belief formula1,1BA,0r0pfr (punct(train) at(train, city), Obs{A} (punct(train)))(B5 )T0 (B) provides global constraint set possible worlds BObs{A} (punct(train)) holds every world punct(train) holds, thus obtainthread h2 additional facts Obs{A} (punct(T1 )) h2 (1) Obs{A} (punct(T1 ))h2 (6).Finally, rule.93,.93 pfrBA,0r2 (Obs{A} (punct(train)), Obs{AB} (punct(train)))(B6 )98fiPDT Logic00h2 B2B50h1 B2at(T1 , CA ), on(A, T1 )punct(T1 )Obs{A} (punct(T1 ))at(T1 , CA ), on(A, T1 )punct(T1 )B300B200B5B30B200at(T2 , CC ), on(A, T2 )punct(T2 )1B404at(T2 , CC ), on(A, T2 )punct(T2 )Obs{A} (punct(T2 ))at(T2 , CB ), on(A, T2 )6B400at(T2 , CB ), on(A, T2 )91Figure 4: Visualization representative thread set generation train example.threads start given facts at(T1 , CA ), on(A, T1 ). Applicationsformulae T2 (B)such h1 contains positive belief objects h2contains negative belief objectsare marked blue, additional constraintsT0 (B) T1 (B) marked red.change created threads h1 , h2 : h1 rules precondition neverenforced satisfied thus resulting frequency one, lackobservation h2 even though nonpunctual trainsensures resultingfrequency zero.trying solve resulting problem sat(T2 (B), {T h1 , h2 }), non-strict beliefformulae yield following constraints h1 :B20 :B200:B6 :0.81 I(T h1 ) 0.810.81 I(T h1 ) 0.810.93 I(T h1 ) 0.93Clearly, constraints cannot satisfied simultaneously therefore set ={T h1 , h2 } insufficient show satisfiability T2 (B) (and therefore B).created set threads fails show satisfiability T2 (B), additional threadscreated continue searching expanded set T2 (B) satisfiedrespect . Based existing thread h, additional thread h0 createdensuring one conjunct h1 h2 (56) (57) satisfied anymore,i.e., given thread h existing constraints (xk k ), new thread h0obtained substitution^^h |= (xj j ) h0 |=(xj j ) x0k k , x0k 6= xk .(58)jj6=kEvery substitution one conjunct new constraint provides choice pointdirect continuation search suitable set threads. constraint notation58 used provide formal characterization choice points. practice, new threadh0 satisfying constraint usually created easily addition newmodification existing facts h follows. simplify following discussion,assume expansion keeps history expansion steps resulting consequences,effects adding additional F undone respective fact Fchanged newly created thread.99fiMartiny & MollerDefinition 4.7 (Principle least effort (ple) expansion). Let set threads letT2 (B) set type 2 belief formulae. principle least effort expansion createsexpanded set 0 = {T h0 } according single application one following rules.`,u(possibly negated) belief fact Bi,t0 (Ft ) T2 (B): exists threadh F h(t) (resp. F 6 h(t)) yet enforced, h0 createdduplication h additional constraint F h(t) (resp. F6 h(t)).`,u frbelief temporal rule Bi,t0 (rt (F, G)) T2 (B): exists threadh F h(t) G h(t + t) (resp. G6 h(t + t))0yet enforced, h created duplication h additional constraintG h(t + t) (resp. G 6 h(t + t)).`,u`,udisjunctive belief formula B = (Bi,t0 (1 ) Bi,t0 (2 ) ) T2 (B): possible,`,uexpansion carried respect one belief Bi,t0 () described twoprevious steps.Nested beliefs treated respect innermost belief object.new thread h0 created h addition F h0fact F time point F 6 h enforced original thread h,consequences adding F 6 h undone new thread h0 .Then, created thread h0 , additional belief formulae T1 (B)triggered modification need evaluated obtain sound thread,described creation initial threads h1 , h2 .intuition behind ple-expansion create additional threads satisfyalternative set belief objects contained set T2 (B) little effort possible.general, possible add constraints arbitrary facts arbitrary time pointscontinue successive expansion based thread. However, would resultrather aimless exploration exponential search space. Following ple-expansioninstead helps direct search suitable model guided rules specifiedT2 (B). illustrate this, consider Figure 4 previous example: Possible pleexpansions could example result additional thread altering punctualitytrain T2 . Clearly, resulting situations intended model, alreadyconsidered original thread specification (cf. Figure 1, p. 50). hand,deviating ple-expansion, one could add additional factssay at(T1 , CA ), on(A, T1 )arbitrary time points > 1. could give rise multiple subsequent expansionsresulting thread may actually serve generate model B,situation intended specification B. example train punctualityalso illustrates requirement undo operation: fact punct(T2 ) h1 (4) producedadditional constraint {at(T2 , CB ), on(A, T2 )} time = 6. Clearly, constraintenforced longer ifbased h1 new thread h0 createdpunct(T2 ) 6 h0 (4).information violated constrains linear program correspondingsat(T2 (B), {T h1 , h2 }), perform dependency-directed selection choice points:100fiPDT Logic`,ulower bound belief Bi,t0 (k ) cannot satisfied current set threads,0additional thread h created existing constraints h1 h2substituting respective constraint k , shown (58).dependency choice points violated lower bounds best illustratedresults previous example: Clearly, upper bounds induced B20 B200lower bound induced B6 hinder satisfiability T2 (B) respect createdthreads. Using belief object formula B20 (or B200 ) create additional thread h3yields updated constraintB20 :0.81 I(T h1 ) + x I(T h3 ) 0.81factor x depending frequency respective belief object h3 ,constraint induced B6 remains unchanged. result, new constraint allowslower values I(T h1 ), thus lower bound induced B6 remains unsatisfiable.Using belief object formula B6 create additional thread instead yieldsconstraintB6 :0.93 I(T h1 ) + x I(T h3 ) 0.93,whichthrough nonzero values x I(T h3 )potentially allows lower valuesI(T h1 ). Note example uses atomic belief formulae. disjunctive belief`,u`,uformulae B = (Bi,t0 (1 )Bi,t0 (2 ) ), respective belief objects violatedlower bound used direct selection subsequent choice points (givendisjunct B satisfiable, course).Combining information violated lower bounds principle least effortprovides multi-stage heuristic proceed dependency-directed selection choicepoints:Definition 4.8 (Dependency-directed search heuristic). Let T2 (B) set type 2 beliefformulae let set threads sat(T2 (B), ) holds. Then, enabledependency-directed search expanded set 0 sat(T2 (B), 0 ) holds,expanded additional thread h0 6 according following rules.1. existing set threads fails satisfy lower bounds constraints inducedbelief formula B belief object additional thread h0 obtainedone ple-expansion respect , expanded 0 = {T h0 }.2. Otherwise, dependency-directed ple-expansion possible, another ple-expansionapplied , possible.3. Finally, ple-expansion possible , additional thread h0 createdadding constraint F h(t) (resp. F 6 h(t)) arbitrary facts Fyet constrained h(t).intuition behind heuristic information violated probabilistic constraints used select suitable next expansion step, possible. Otherwise,possible ple-expansion steps performed use rules T2 (B) guide101fiMartiny & Mollersearch. ple-expansions possible, additional constraints employed continue search. Restricting possible expansions respect criterion 1one step follows principle least effort, again: illustrate this, consider Example 4.8:shown created set threads {T h1 , h2 } fails satisfy lower boundbelief formula B6 . thread h1 , world h1 (t) |= Obs{A} (punct(train))precondition rule B6 satisfied. Consequently, single stepple-expansion h1 could change constraints induced B6 . hand,h2 provides two choice points therefore preferred expansion. Notesoundness requirement determine choices unconstrained facts. Thus,general proposed expansion may produce threads already containedconstraining facts determined before. consider scenarioexplicitly instead assume cases, expansion steps performedadditional thread created.4.5.2 Thread Generation Exampleillustrate expansion set threads respect dependency-directedsearch heuristic Definition 4.8, following resume train example.Example 4.9 (Trains continued). previous example, set threads = {T h1 , h2 }created fails show satisfiability T2 (B). Consequently, heuristicDefinition 4.8 used iteratively expand set expanded set threads0 created model B obtained expansions 0 possible.Belief formula.93,.93 pfrr2 (Obs{A} (punct(train)), Obs{AB} (punct(train)))B6 = BA,0already identified belief formula yields constrains unsatisfiablelower bound therefore used guide subsequent expansion.already discussed before, single-step ple-expansion h1 possible influenceconstraints induced B6 . Therefore continue expansion based thread h2 .visualization following steps given Figure 5.two worlds h2 Obs{A} (punct(train)) satisfied, namelyObs{A} (punct(T1 )) h2 (1) Obs{A} (punct(T2 )) h2 (6). occurrences allow ple-expansion. choose h2 (1) perform expansion. yieldsnew thread h3 additional constraint Obs{A,B} (punct(T1 )) h3 (3),constraints h2 remain intact, since constraints need undoneadding Obs{A,B} h3 (3).expanded set 0 = {T h3 } used check sat(T2 (B), 0 ). threadh3 , rule contained B6 satisfied one two occurrences Obs{A} (punct(train))therefore yields frequency 0.5. Consequently, transformation linearprogram obtain constraintsB20 :B200:B6 :0.81I(T h1 )0.810.93I(T h1 ) + 0.5 I(T h3 )0.930.81I(T h1 )1020.81fiPDT Logich4h300h2 B2B50h1 B2at(T1 , CA ), on(A, T1 )punct(T1 )Obs{A} (punct(T1 ))at(T1 , CA ), on(A, T1 )punct(T1 )Obs{A} (punct(T1 ))at(T1 , CA ), on(A, T1 )punct(T1 )Obs{A} (punct(T1 ))at(T1 , CA ), on(A, T1 )punct(T1 )1Obs{A,B} (punct(T1 ))Obs{A,B} (punct(T1 ))B6B300B200B5B30at(T2 , CC ), on(A, T2 )punct(T2 )B2003B4041Obs{A,B} (punct(T2 ))at(T2 , CC ), on(A, T2 )punct(T2 )Obs{A} (punct(T2 ))at(T2 , CC ), on(A, T2 )punct(T2 )Obs{A} (punct(T2 ))at(T2 , CC ), on(A, T2 )punct(T2 )Obs{A} (punct(T2 ))at(T2 , CB ), on(A, T2 )6B6at(T2 , CB ), on(A, T2 )B40089Figure 5: Visualization ple-expansions train example. Applications formulaeT2 (B) marked blue, additional constraints T0 (B) T1 (B)marked red. Expansion steps marked green.Apparently, B6 allows lower values I(T h1 ) set 0 . constraintsinduced B20 (resp. B200 ) still obtain I(T h1 ) = 0.81. Then, constraint inducedB6 requires I(T h3 ) = 0.24 (since 0.81 + 0.5 0.24 = 0.93). still suitableprobability assignment since sum priors exceeds one. Consequently, threadset expansion continues. constraints show thataccording condition 1search heuristicthread h3 suitable candidate expansion respectbelief object B6 .Thus, based h3 , create additional thread h4 ple-expansion.case, possible expansion step Obs{A,B} h4 (8), results frequencyone rule contained B6 . Thus, testing sat(Tk (B), 0 ) expandedset 0 yields following constraints:B20 :B200:B6 :0.81I(T h1 )0.810.93I(T h1 ) + 0.5 I(T h3 ) + 1 I(T h4 )0.930.81I(T h1 )0.81constraints satisfiable, instanceI(T 0 ) = 0.81, 0.07, 0, 0.12 .Thus, sat(T2 (B), 0 ) returns positive result satisfiability checking B terminateresult.result concludes satisfiability testing set belief formulae B originallyspecified Example 4.1 (p. 72). Nevertheless, illustration purposes show resultapplications ple-expansion steps Figure 6. Changes additionallycreated threads obtained respectively different application beliefformula T2 (B), marked blue respective threads. Worlds h(t) remainunconstrained saturated application ple-expansions marked /.worlds give rise expansions according step 3 search heuristic.103fi1040h1 B200h2 B2B5h3h4h5h6h7h8h91at(T1 , CA ), on(A, T1 )punct(T1 )Obs{A} (punct(T1 ))at(T1 , CA ), on(A, T1 )punct(T1 )Obs{A} (punct(T1 ))at(T1 , CA ), on(A, T1 )punct(T1 )Obs{A} (punct(T1 ))at(T1 , CA ), on(A, T1 )punct(T1 )Obs{A} (punct(T1 ))at(T1 , CA ), on(A, T1 )punct(T1 )at(T1 , CA ), on(A, T1 )punct(T1 )at(T1 , CA ), on(A, T1 )punct(T1 )Obs{A} (punct(T1 ))at(T1 , CA ), on(A, T1 )punct(T1 )Obs{A} (punct(T1 ))at(T1 , CA ), on(A, T1 )punct(T1 )B302//////B200B5B63//B300B200Obs{A,B} (punct(T1 ))Obs{A,B} (punct(T2 ))////Obs{A,B} (punct(T2 ))B6/4B20000/ B2B5/15at(T2 , CC ), on(A, T2 )B40punct(T2 )/////at(T2 , CC ), on(A, T2 )punct(T2 )/Obs{A} (punct(T2 ))at(T2 , CC ), on(A, T2 )punct(T2 )/Obs{A} (punct(T2 ))///6at(T2 , CC ), on(A, T2 )punct(T2 )Obs{A} (punct(T2 ))at(T2 , CC ), on(A, T2 )punct(T2 )Obs{A} (punct(T2 ))at(T2 , CC ), on(A, T2 )punct(T2 )Obs{A} (punct(T2 ))at(T2 , CC ), on(A, T2 )punct(T2 )Obs{A} (punct(T2 ))at(T2 , CB ), on(A, T2 )B400B6Obs{A,B} (punct(T2 ))at(T2 , CC ), on(A, T2 )punct(T2 )at(T2 , CC ), on(A, T2 )punct(T2 )/7/////B4008///Obs{A,B} (punct(T2 ))B69/at(T2 , CB ), on(A, T2 )at(T2 , CB ), on(A, T2 )at(T2 , CB ), on(A, T2 )at(T2 , CB ), on(A, T2 )Obs{A,B} (punct(T2 ))B6/////at(T2 , CB ), on(A, T2 )/at(T2 , CB ), on(A, T2 )at(T2 , CB ), on(A, T2 )at(T2 , CB ), on(A, T2 )B40/Martiny & MollerFigure 6: Visualization continued ple-expansions train example. Applicationsformulae T2 (B) marked blue, additional constraints T0 (B)T1 (B) marked red. Expansion steps originating h1 h2marked green orange, respectively. Unconstrained worlds marked/.fiPDT Logiccomments resulting set threads example necessary. Comparing final threads depicted Figure 6 original set threads introducedFigure 1 shows expansion result largely corresponds original specification(except differing thread labels). notable differences however.First all, additional predicate punct(train), introducedExample 4.1 (p. 72) allow concise specification background knowledge.concept nonpunctual trains (and especially respective ramifications)implicitly encoded Figure 1 well, change propertiesmodeled example.explicit representation train punctuality, observations nonpunctualtrains expressed explicitly example, previous example usesramifications nonpunctual trains model observations. Since rules B3B4 assert ramifications punctual respectively nonpunctual trains commonknowledge among Alice Bob, modeling alternatives preserve intendedmeaning example.Another difference timing Alices observations. original exampleassumed observation occurs time point train supposedarrive destination city. current example assume Alice alreadyobserves train punctual leaving departure city. reasonchange solely illustration purposes: specifying rule B5 Aliceimmediately observes nonpunctual train yields type 0 belief thus servesillustrate additional facts obtained global constraints. Since ruleB6 ensures potential calls Bob (i.e., shared observations) occur two time pointsAlices original observation, intended model original example stillmaintained.points concerned specific details modeled domain.Comparing set threads Figure 1 threads Figure 6 also showsgeneral modeling problem: instance, analyzing worlds time point 2Figure 6 shows Alice (necessarily) train T1 , trainprevious time point later time points. Naturally, one expectAlice train intermediate time points boarding exitingtrain. instance frame problem (e.g., Reiter, 2001) occursspecifying dynamic systems logic formulae. Generally, frame problemconcerned finding suitable set axioms describe adequate evolutionsworld. modeling perspective, evolutions Alice vanishes reappearstrain ride obviously adequate evolutions world. applicationfinal step search heuristic could yield tremendous blow-upconsidered set threads. modeled problem, would clearly resultunintended models, resulting models could still serve show satisfiabilityrespective set belief formulae B, even though result might desired.problem could fixed adding successor state axioms style Reiter,e.g., specifying Alice train, remains next time pointunless explicitly exits train.105fiMartiny & Moller4.5.3 Properties Representative Thread Generationsection, provide results connect set representative threads satisfiability problem PDT Logic discuss complexity generating representativethreads.Theorem 4.15 (PDT Logic Decision Procedure). Let B set PDT Logic beliefformulae, let = {T h1 , h2 } initial set threads length tmax obtainedB according Equations (56) (57). Iteratively expanding set accordingsearch heuristic Definition 4.8 testing sat(T2 (B), 0 ) expanded sets 0(i) sat(T2 (B), 0 ) returns positive result, (ii) 0 fully expanded respectsearch heuristic yields sound complete decision procedure sat(B, tmax ).Proof. initial set threads = {T h1 , h2 } expanded sets 0 obtained ple-expansion steps defined sound threads accordingDefinition 4.4 considered. Theorem 4.13 (p. 92) states decision problemsat(T2 (B), ) equivalent sat(B, ) set contains threads soundrespect B. positive result sat(B, ) threads length tmax showsmodel B thus sat(B, tmax ) follows. Consequently, positive resultsat(T2 (B), 0 ) always proofs B satisfiable tmax time points.hand, model B found possible createadditional threads according search heuristic Definition 4.8 (p. 101), searchspace fully explored. follows model B tmax time pointsexists therefore B unsatisfiable tmax time points. Consequently, followsPDT Logic decision procedure sound.properties, completeness result straightforward: arbitraryinput B tmax , either model found non-existence modelproven full exploration search space, thus completeness procedurefollows.following, analyze complexity generating representative threadsset belief formulae B.Theorem 4.16 (Complexity representative thread generation). Let B set beliefformulae. Creating set expanded representative threads 0 B EXPSPACE.Proof. maximum number possible threads given set belief formulae Bdetermined size |FB | maximum time point tmax . Recall Equation (29) (p. 71) use FB identify event formulae B use setground atoms construct possible worlds. Since every PDT Logic formula containstwo event formulae, obtain constraint |FB | 2 |B|. largest set possiblethreads obtained sequences combinations possible worldstime points, yielding 22tmax |B| possible threads. worst case, |FB | 2 |B| representative threads created obtaining satisfiability result. Consequently, creatingpossible representative threads complexity class DSPACE(2p(n) ),class EXPSPACE.theorem, immediately obtain complexity results satisfiability problem sat(B, tmax ).106fiPDT LogicCorollary 4.17 (Complexity PDT SAT without given set threads). Checking satisfiability set PDT Logic belief formulae B without specification possible threadsEXPSPACE.Proof. generation representative threads EXPSPACE, shown Theorem 4.16. given set threads Theorem 4.11 shows satisfiability checkingPDT Logic NP. Thus, increase complexity PDT sat problem without given set threads follows problem EXPSPACE.comments results necessary. Since decision procedure outlinedTheorem 4.15 yields exponential expansion possible threads 0 needfed decision problem sat(T2 (B), 0 )the exponential space requirementevident. However, illustrated example, positive satisfiability resultspossibly already obtained small sets possible threads 0 diminutivesize compared entire search space. Moreover, discussion train exampleshown major part search space stems insufficient rule specifications.specific problem formalism presented decision procedure, generalproblem rule-based modeling approaches, namely aforementioned frame problem.incomplete model specification leads generation unintended models,serve show satisfiability modeled problem, intendedrespective modeler. could lead worst caseboth complexitymodel perspectivethat exponential execution decision procedure,result shows input specification specify intended model.problem addressed modeling side providing additional axioms ensureunintended model generated. However, leads significant increasespecification size difficult ensure rule specifications indeed everyunintended model prevented.ple-expansion steps could used heuristic discriminate intendedunintended models: shown train example, applying ple-expansion stepsresults relatively small set threads, indeed corresponds intentionmodel, expansions inherently leads exponential growthset threads introduces additional unintended models. Thus, omitting finalstep search heuristic would give significantly faster termination decisionprocedure, even though resulting procedure cannot prove unsatisfiable sets formulaelonger. However, one could use expansion procedure create set intendedthreads first andpossibly inspection modelercontinue use setperform satisfiability checks respect intended model.runtime expansion procedure resulting satisfiability checks clearlytilted towards positive side: set belief formulae satisfiable, goodchance satisfiability shown small number steps. Negative resultshand obtained exhaustive exploration search space.However, many applications negative satisfiability results required. instance,checking entailment B |= B checked reformulation sat(B B).applications relying reformulation, presented procedure unfavorablepositive entailment results never obtained efficiently. One could overcomeproblem sketched generating set intended threads first use107fiMartiny & Mollerset perform subsequent satisfiability testsonce set threads given, decisionproblems complexity significantly decreases, shown Section 4.3.5. Conclusionwork, extending APT Logic dynamic scenarios multiple agents,developed general framework represent reason belief change multiagent systems. Next lifting single-agent case APT Logic multiple agents,also provided suitable semantics temporal evolution beliefs. resultingframework extends previous work dynamic multi-agent epistemic logics enablingquantification agents beliefs probability intervals. explicit notion temporal relationships provided temporal rules building concept frequencyfunctions.quantification beliefs probability intervals instead precise valuesadvantage domain experts model problem, providebackground knowledge problem domain, also specify certaintyrespective specifications. Narrow interval quantifications reflect high certaintyvice versa. significant advantage compared probabilistic approaches,approaches, sharp probability values required humanusually express precise values thus rely guesses. Specifying precisevalues, actually precisely known yield misleading results. PDT Logicexposed problem, required guess sharp values specifyproblem.shown two alternative ways specifying problems PDT Logic,either explicit enumerations possible threads set appropriaterules. approaches exhibit specific advantages drawbacks: many problemdomains, requiring exhaustive enumeration possible threads poses severe obstaclemodeling respective scenarios, combinatorial blow-up renders specificationpractically unmanageable. hand, problem domains (e.g., attackgraphs cyber security scenarios) come explicit specification anyways.types problems, shown possible check satisfiabilitymodels efficiently.overcome modeling disadvantages thread-based approach, also shownproblem domain solely specified set PDT Logic belief formulae.problem domains, natural way specifying problem. Also,provides means easily adapt many existing problemsthat specified formallanguages sets rulesto PDT Logic. hand, waiving requirementexhaustive thread specification according probabilities extremely increasesproblem complexity checking satisfiability set PDT Logic formulae. Nevertheless,even imprecise probabilities given, resulting problem remains decidableincreased complexity might curtailed search heuristics.Combinations approaches possible well: exhaustive specificationpossible threads given, probability intervals specified beliefsimprecise probabilities, satisfiability problem transformed 0-1 mixedinteger linear program. variety efficient solvers available class108fiPDT Logicproblems, transformation provides means exploit existing optimizations checksatisfiability PDT Logic formulae.ReferencesAumann, R. J. (1976). Agreeing Disagree. Annals Statistics, 4 (6), 12361239.Baaz, M., Egly, U., Leitsch, A., Goubault-Larrecq, J., & Plaisted, D. (2001). Normal FormTransformations. Robinson, A., & Voronkov, A. (Eds.), Handbook AutomatedReasoning, chap. 5, pp. 273 333. MIT Press.Balas, E. (1985). Disjunctive Programming Hierarchy Relaxations DiscreteOptimization Problems. SIAM Journal Algebraic Discrete Methods, 6 (3), 466486.Balas, E. (1998). Disjunctive Programming: Properties Convex Hull FeasiblePoints. Discrete Applied Mathematics, 89 (1), 344.Balas, E., Ceria, S., & Cornuejols, G. (1993). Lift-and-project Cutting Plane AlgorithmMixed 0-1 Programs. Mathematical Programming, 58 (3), 295324.Balas, E., Ceria, S., & Cornuejols, G. (1996). Mixed 0-1 Programming Lift-and-projectBranch-and-cut Framework. Management Science, 42 (9), 12291246.Balas, E., & Perregaard, M. (2002). Lift-and-project Mixed 0-1 Programming: RecentProgress. Discrete Applied Mathematics, 123 (1), 129154.Baltag, A., & Moss, L. S. (2004). Logics Epistemic Programs. Synthese, 139 (2), 165224.Baltag, A., Moss, L. S., & Solecki, S. (1998). Logic Public Announcements, CommonKnowledge, Private Suspicions. Proceedings Seventh ConferenceTheoretical Aspects Rationality Knowledge, TARK 98, pp. 4356.Bertacco, L., Fischetti, M., & Lodi, A. (2007). Feasibility Pump Heuristic generalMixed-Integer Problems. Discrete Optimization, 4 (1), 6376.Bienstock, D. (1996). Computational Study Family Mixed-Integer Quadratic Programming Problems. Mathematical Programming, 74 (2), 121140.Bradley, S. (2015). Imprecise probabilities. Zalta, E. N. (Ed.), Stanford EncyclopediaPhilosophy (Summer 2015 edition).Computational Infrastructure Operations Research (COIN-OR) Project, T. (2016).CBC (Coin-or branch cut) user guide. http://www.coin-or.org/Cbc/index.html.accessed: 2016-04-15.Cook, S. A. (1971). Complexity Theorem-proving Procedures. ProceedingsThird Annual ACM Symposium Theory Computing, STOC 71.Cripps, M. W., Ely, J. C., Mailath, G. J., & Samuelson, L. (2008). Common Learning.Econometrica, 76 (4), 909933.Dal Palu, A., Dovier, A., Pontelli, E., & Rossi, G. (2009). Gasp: Answer set programminglazy grounding. Fundamenta Informaticae - Advances Computational Logic,96 (3), 297322.109fiMartiny & Mollerde Carvalho Ferreira, N., Fisher, M., & van der Hoek, W. (2008). Specifying ReasoningUncertain Agents. International Journal Approximate Reasoning, 49 (1),3551.Doder, D., Markovic, Z., Ognjanovic, Z., Perovic, A., & Raskovic, M. (2010). Probabilistic Temporal Logic Model Reasoning Evidence. FoundationsInformation Knowledge Systems: 6th International Symposium, FoIKS 2010.Ellsberg, D. (1961). Risk, Ambiguity, Savage Axioms. Quarterly JournalEconomics, 75 (4), 643669.Faber, W., Leone, N., & Perri, S. (2012). intelligent grounder DLV. CorrectReasoning: Essays Logic-Based AI Honour Vladimir Lifschitz. Springer.Fagin, R., & Halpern, J. Y. (1994). Reasoning Knowledge Probability. JournalACM, 41 (2), 340367.Fagin, R., Halpern, J. Y., & Megiddo, N. (1990). Logic Reasoning Probabilities.Information Computation, 87 (1), 78128.Fagin, R., Halpern, J. Y., Moses, Y., & Vardi, M. Y. (1995). Reasoning Knowledge.MIT Press.Fischetti, M., Glover, F., & Lodi, A. (2005). Feasibility Pump. Mathematical Programming, 104 (1), 91104.Garey, M. R., & Johnson, D. S. (1979). Computers Intractability; Guide TheoryNP-Completeness. W. H. Freeman & Co.Gerbrandy, J., & Groeneveld, W. (1997). Reasoning Information Change. JournalLogic, Language Information, 6 (2), 147169.GnuProject, T. (2016).GLPK: GNU Linear Programminghttp://www.gnu.org/software/glpk/glpk.html. accessed: 2016-04-15.Kit.Grunwald, P. D., & Halpern, J. Y. (2003). Updating Probabilities. Journal ArtificialIntelligence Research, 19 (1), 243278.Gurobi Optimization, Inc. (2016).Gurobi optimizer referencehttp://www.gurobi.com/documentation/. accessed: 2016-04-15.manual.Halpern, J. Y., & Pucella, R. (2006). Logic Reasoning Evidence. JournalArtificial Intelligence Research, 26 (1), 134.Halpern, J. Y., Samet, D., & Segev, E. (2009). Defining Knowledge Terms Belief:Modal Logic Perspective. Review Symbolic Logic, 2 (3), 469487.Harsanyi, J. C. (1967). Games Incomplete Information Played Bayesian Players.Part I. Basic Model. Management Science, 14 (3), 159182.Harsanyi, J. C. (1968a). Games Incomplete Information Played Bayesian Players.Part II. Bayesian Equilibrium Points. Management Science, 14 (5), 320324.Harsanyi, J. C. (1968b). Games Incomplete Information Played Bayesian Players.Part III. Basic Probability Distribution Game. Management Science, 14 (7),486502.110fiPDT LogicHintikka, J. (1962). Knowledge Belief: Introduction Logic Two Notions.Cornell University Press.ILOG,I.(2016).CPLEXOptimizer.01.ibm.com/software/commerce/optimization/cplex-optimizer/.04-15.http://wwwaccessed: 2016-Kooi, B. P. (2003). Probabilistic Dynamic Epistemic Logic. Journal Logic, LanguageInformation, 12 (4), 381408.Kripke, S. A. (1963). Semantical Considerations Modal Logic. Acta Philosophica Fennica,16, 8394.Lloyd, J. W. (1987). Foundations Logic Programming, 2nd Edition. Springer.Martiny, K., Motzek, A., & Moller, R. (2015). Formalizing Agents Beliefs Cyber-SecurityDefense Strategy Planning. CISIS 2015 - Proceedings 8th International Conference Computational Intelligence Security Information Systems, Burgos,Spain, 15-17 June, 2015.Milch, B., & Koller, D. (2000). Probabilistic Models Agents Beliefs Decisions.Proceedings Sixteenth Annual Conference Uncertainty Artificial Intelligence, UAI 00. Morgan Kaufmann Publishers Inc.Murty, K. G. (1983). Linear Programming. John Wiley & Sons.Parikh, R., & Ramanujam, R. (2003). Knowledge Based Semantics Messages. JournalLogic, Language Information, 12 (4), 453467.Plaza, J. (1989). Logics public communications. Proceedings Fourth InternationalSymposium Methodologies Intelligent Systems: Poster session program, ISMIS89. Oak Ridge National Laboratory.Plaza, J. (2007). Logics Public Communications. Synthese, 158 (2), 165179.Reiter, R. (2001). Knowledge Action: Logical Foundations Specifying Implementing Dynamical Systems. MIT Press.Sack, J. (2008). Temporal Languages Epistemic Programs. Journal Logic, LanguageInformation, 17 (2), 183216.Sack, J. (2009). Extending Probabilistic Dynamic Epistemic Logic. Synthese, 169 (2), 241257.Schrijver, A. (1986). Theory Linear Integer Programming. John Wiley & Sons.Shakarian, P., Parker, A., Simari, G., & Subrahmanian, V. S. (2011). Annotated Probabilistic Temporal Logic. ACM Transactions Computational Logic, 12 (2), 14:114:44.Shakarian, P., Simari, G. I., & Subrahmanian, V. S. (2012). Annotated Probabilistic Temporal Logic: Approximate Fixpoint Implementation. ACM Transactions Computational Logic, 13 (2), 13:113:33.Shoham, Y., & Leyton-Brown, K. (2009). Multiagent Systems: Algorithmic, GameTheoretic, Logical Foundations. Cambridge University Press.van Benthem, J. (2003). Conditional Probability Meets Update Logic. Journal Logic,Language Information, 12 (4), 409421.111fiMartiny & Mollervan Benthem, J., Gerbrandy, J., Hoshi, T., & Pacuit, E. (2009a). Merging FrameworksInteraction. Journal Philosophical Logic, 38 (5), 491526.van Benthem, J., Gerbrandy, J., & Kooi, B. (2009b). Dynamic Update Probabilities.Studia Logica, 93 (1), 6796.van der Hoek, W. (1997). Considerations Logic PFD: Logic combiningModality Probability. Journal Applied Non-Classical Logics, 7 (3), 287307.van Ditmarsch, H., van der Hoek, W., & Kooi, B. (2007). Dynamic Epistemic Logic.Springer.van Eijck, J. (2014). Dynamic epistemic logics. Johan van Benthem LogicalInformational Dynamics, chap. 7, pp. 175202. Springer.van Eijck, J., & Schwarzentruber, F. (2014). Epistemic Probability Logic Simplified.Gore, R., Kooi, B. P., & Kurucz, A. (Eds.), Advances Modal Logic 10, invitedcontributed papers tenth conference Advances Modal Logic,, AiML14. College Publications.vos Savant, M. (1990). Ask Marilyn. Parade Magazine, 16.Williams, H. P. (2009). Logic Integer Programming. Springer.112fi