Journal Artificial Intelligence Research 57 (2016) 187-227

Submitted 9/15; published 10/16

Multi-objective Reinforcement Learning
Continuous Pareto Manifold Approximation
Simone Parisi

parisi@ias.tu-darmstadt.de

Technische Universitat Darmstadt
Hochschulstr. 10, 64289 Darmstadt, Germany

Matteo Pirotta
Marcello Restelli

matteo.pirotta@polimi.it
marcello.restelli@polimi.it

Politecnico di Milano
Piazza Leonardo da Vinci 32, 20133 Milano, Italy

Abstract
Many real-world control applications, economics robotics, characterized
presence multiple conflicting objectives. problems, standard concept
optimality replaced Paretooptimality goal find Pareto frontier,
set solutions representing different compromises among objectives. Despite recent advances multiobjective optimization, achieving accurate representation
Pareto frontier still important challenge. paper, propose reinforcement
learning policy gradient approach learn continuous approximation Pareto frontier multiobjective Markov Decision Problems (MOMDPs). Differently previous
policy gradient algorithms, n optimization routines executed n solutions,
approach performs single gradient ascent run, generating step improved
continuous approximation Pareto frontier. idea optimize parameters
function defining manifold policy parameters space, corresponding
image objectives space gets close possible true Pareto frontier. Besides
deriving compute estimate gradient, also discuss nontrivial
issue defining metric assess quality candidate Pareto frontiers. Finally,
properties proposed approach empirically evaluated two problems,
linear-quadratic Gaussian regulator water reservoir control task.

1. Introduction
Multiobjective sequential decision problems characterized presence multiple
conflicting objectives found many real-world scenarios, economic
systems (Shelton, 2001), medical treatment (Lizotte, Bowling, & Murphy, 2012), control
water reservoirs (Castelletti, Pianosi, & Restelli, 2013), elevators (Crites & Barto, 1998)
robots (Nojima, Kojima, & Kubota, 2003; Ahmadzadeh, Kormushev, & Caldwell, 2014),
mention few. problems often modeled Multiobjective Markov Decision
Processes (MOMDPs), concept optimality typical MDPs replaced
one Pareto optimality, defines compromise among different objectives.
last decades, Reinforcement Learning (RL) (Sutton & Barto, 1998) established
effective theoretically grounded framework allows solve singleobjective
MDPs whenever either (or little) prior knowledge available system dynamics
dimensionality system controlled high classical optimal control
2016 AI Access Foundation. rights reserved.

fiParisi, Pirotta, & Restelli

methods. Multiobjective Reinforcement Learning (MORL), instead, concerns MOMDPs
tries solve sequential decision problems two conflicting objectives.
Despite successful development RL theory high demand multiobjective
control applications, MORL still relatively young unexplored research topic.
MORL approaches divided two categories, based number policies
learn (Vamplew, Dazeley, Berry, Issabekov, & Dekker, 2011): single multiple
policy. Although MORL approaches belong former category, present
multiplepolicy approach, able learn set policies approximating Pareto frontier.
representation complete Pareto frontier, fact, allows posteriori selection
solution encapsulates trade-offs among objectives, giving better insights
relationships among objectives. Among multiplepolicy algorithms possible
identify two classes: valuebased (Lizotte et al., 2012; Castelletti et al., 2013; Van Moffaert
& Nowe, 2014), search optimal solutions value functions space, policy gradient approaches (Shelton, 2001; Parisi, Pirotta, Smacchia, Bascetta, & Restelli, 2014),
search policy space. practice, approach different advantages. Value
based methods usually stronger guarantees convergence, preferred domains lowdimensional state-action spaces prone suffer curse
dimensionality (Sutton & Barto, 1998). hand, policy gradient methods
favorable many domains robotics allow taskappropriate
prestructured policies integrated straightforwardly (Deisenroth, Neumann, & Peters,
2013) experts knowledge incorporated ease. selecting suitable policy
parametrization, learning problem simplified stability well robustness
frequently ensured (Bertsekas, 2005). Nonetheless, approaches lack guarantees uniform covering true Pareto frontier quality approximate
frontier, terms accuracy (distance true frontier) covering (its extent),
related metric used measure discrepancy true Pareto frontier.
However, nowadays definition metric open problem MOO literature.
paper, overcome limitations proposing novel gradientbased MORL
approach alternative quality measures approximate frontiers. algorithm, namely
ParetoManifold Gradient Algorithm (PMGA), exploiting continuous approximation
locally Paretooptimal manifold policy space, able generate arbitrarily
dense approximate frontier. article extension preliminary work presented
Pirotta, Parisi, Restelli (2015) main contributions are: derivation
gradient approach general case, i.e., independent metric used measure
quality current solution (Section 3), estimate gradient samples
(Section 4), discussion frontier quality measures effectively integrated
proposed approach (Section 5), thorough empirical evaluation proposed
algorithm metrics performance multiobjective discrete-time Linear-Quadratic
Gaussian regulator water reservoir management domain (Sections 6 7).

2. Preliminaries
section, first briefly summarize terminology used paper discuss
state-of-the-art approaches MORL. Subsequently, focus describing policy
gradient techniques introduce notation used remainder paper.
188

fiMORL Continuous Pareto Manifold Approximation

2.1 Problem Formulation
discretetime continuous Markov Decision Process (MDP) mathematical framework
modeling decision making. described tuple hS, A, P, R, , Di, Rn
continuous state space, Rm continuous action space, P Markovian
transition model P(s0 |s, a) defines transition density state s0
action a, R : R reward function, [0, 1) discount factor,
distribution initial state drawn. context, behavior
agent defined policy, i.e., density distribution (a|s) specifies probability
taking action state s. Given initial state distribution D, possible define
expected return J associated policy
"T 1
#
X


J =
E
R(st , , st+1 )|s0 ,
st P,at

t=0

R(st , , st+1 ) immediate reward obtained state st+1 reached executing
action state st , finite infinite time horizon. goal agent
maximize return.
Multiobjective Markov Decision Processes (MOMDPs) extension MDPs
several pairs reward functions discount factors defined, one
objective. Formally, MOMDP described tuple hS, A, P, R, , Di, R =
[R1 , . . . , Rq ]T = [1 , . . . , q ]T qdimensional column vectors reward functions
Ri : R discount factors [0, 1), respectively.
MOMDPs, policy




associated q expected returns J = J1 , . . . , Jq ,
"T 1
#
X
Ji =
E
Ri (st , , st+1 )|s0 .
st P,at

t=0

Unlike happens MDPs, MOMDPs single policy dominating others
usually exist, conflicting objectives considered, policy simultaneously maximize them. reason, Multiobjective Optimization (MOO)
concept Pareto dominance used. Policy strongly dominates policy 0 , denoted
0 , superior objectives, i.e.,
0

0 {1, . . . , q} , Ji > Ji .
Similarly, policy weakly dominates policy 0 , denoted 0 , worse
objectives, i.e.,
0

0

0 {1, . . . , q} , Ji Ji {1, . . . , q} , Ji = Ji .
policy 0 0 , policy Paretooptimal. also speak
locally Paretooptimal policies, definition above, except
restrict dominance neighborhood . general, multiple
(locally) Paretooptimal policies. Solving
MOMDP

equivalent determine set
= | @ 0 , 0 , maps socalled Pareto
Paretooptimal
policies



frontier F = J | .1
1. done Harada, Sakuma, Kobayashi (2006), assume locally Paretooptimal solutions
Paretooptimal exist.

189

fiParisi, Pirotta, & Restelli

2.2 Related Work
Multiobjective Optimization (MOO) field, two common solution concepts:
multiobjective singleobjective strategy Pareto strategy. former approach
derives scalar objective multiple objectives and, then, uses standard Single
objective Optimization (SOO) techniques: weighted sum (Athan & Papalambros, 1996),
normbased (Yu & Leitmann, 1974; Koski & Silvennoinen, 1987), sequential (Romero,
2001), constrained (Waltz, 1967), physical programming (Messac & Ismail-Yahaya, 2002)
min-max methods (Steuer & Choo, 1983). latter strategy based concept
Pareto dominance considers Paretooptimal solutions non-inferior solutions among
candidate solutions. main exponent class convex hull method (Das &
Dennis, 1998; Messac, Ismail-Yahaya, & Mattson, 2003).
Similar MOO, current MORL approaches divided two categories based
number policies learn (Vamplew et al., 2011). Singlepolicy methods aim
finding best policy satisfies preference among objectives. majority
MORL approaches belong category differ way preferences
expressed. easy implement, require priori decision type
solution suffer instability, small changes preferences may result
significant variations solution (Vamplew et al., 2011). straightforward
common singlepolicy approach scalarization function applied
reward vector order produce scalar signal. Usually, linear combination weighted
sum rewards performed weights used express preferences
multiple objective (Castelletti, Corani, Rizzolli, Soncinie-Sessa, & Weber, 2002; Natarajan
& Tadepalli, 2005; Van Moffaert, Drugan, & Nowe, 2013). Less common use non
linear mappings (Tesauro, Das, Chan, Kephart, Levine, Rawson, & Lefurgy, 2008).
main advantage scalarization simplicity. However, linear scalarization presents
limitations: able find solutions lie concave linear region
Pareto frontier (Athan & Papalambros, 1996) uniform distribution weights may
produce accurate evenly distributed points Pareto frontier (Das & Dennis,
1997). addition, even frontier convex, solutions cannot achieved
scalarization loss one objective may compensated increment
another one (Perny & Weng, 2010). Different singlepolicy approaches based
thresholds lexicographic ordering (Gabor, Kalmar, & Szepesvari, 1998) different
kinds preferences objective space (Mannor & Shimkin, 2002, 2004).
Multiplepolicy approaches, contrary, aim learning multiple policies order
approximate Pareto frontier. Building exact frontier generally impractical
real-world problems, thus, goal build approximation frontier contains
solutions accurate, evenly distributed along frontier range similar
Pareto one (Zitzler, Thiele, Laumanns, Fonseca, & da Fonseca, 2003). many
reasons behind superiority multiplepolicy methods: permit posteriori
selection solution encapsulate trade-offs among multiple objectives.
addition, graphical representation frontier give better insights relationships among objectives useful understanding problem
choice solution. However, benefits come higher computational cost,
prevent learning online scenarios. common approach approximate
190

fiMORL Continuous Pareto Manifold Approximation

Pareto frontier perform multiple runs singlepolicy algorithm varying
preferences among objectives (Castelletti et al., 2002; Van Moffaert et al., 2013).
simple approach suffers disadvantages singlepolicy method used.
Besides this, examples multiplepolicy algorithms found literature.
Barrett Narayanan (2008) proposed algorithm learns deterministic policies defining convex hull Pareto frontier single learning process. Recent
works focused extension fitted Q-iteration multiobjective scenario.
Lizotte, Bowling, Murphy (2010), Lizotte et al. (2012) focused
linear approximation value function, Castelletti, Pianosi, Restelli (2012) able
learn control policy linear combinations preferences among objectives single learning process. Finally, Wang Sebag (2013) proposed MonteCarlo
Tree Search algorithm able learn solutions lying concave region frontier.
Nevertheless, classic approaches exploit deterministic policies result
scattered Pareto frontiers, stochastic policies give continuous range compromises
among objectives (Roijers, Vamplew, Whiteson, & Dazeley, 2013; Parisi et al., 2014). Shelton (2001, Section 4.2.1) pioneer use stochastic mixture policies
gradient ascent MORL. achieved two well known goals MORL: simultaneous
conditional objectives maximization. former, agent must maintain goals
time. algorithm starts mixture policies obtained applying standard
RL techniques independent objective. policy subsequently improved following
convex combination gradients policy space nonnegative w.r.t.
objectives. objective i, gradient gi expected return w.r.t. policy
computed vector vi highest dot product gi simultaneously
satisfying nonnegativity condition returns used improving direction
i-th reward. vectors vi combined convex form obtain direction
parameter improvement. result policy belongs Pareto frontier.
approximation Pareto frontier obtained performing repeated searches
different weights reward gradients vi . hand, conditional optimization
consists maximizing objective maintaining certain level performance
others. resulting algorithm gradient search reduced policy space
value constrained objectives greater desired performance.
studies followed work Shelton (2001) regard policy gradient
algorithms applied MOMDPs. Recently Parisi et al. (2014) proposed two policy gradient
based MORL approaches that, starting initial policies, perform gradient ascent
policy parameters space order determine set nondominated policies.
first approach (called Radial ), given number p Pareto solutions required
approximating Pareto frontier, p gradient ascent searches performed, one
following different (uniformly spaced) direction within ascent simplex defined
convex combination singleobjective gradients. second approach (called Pareto
Following) starts performing singleobjective optimization moves along
Pareto frontier using two-step iterative process: updating policy parameters following
gradient ascent direction, applying correction procedure move
new solution onto Pareto frontier. Although methods exploit stochastic policies
proved effective several scenarios, still return scattered solutions
guaranteed uniformly cover Pareto frontier. best knowledge, nowadays
191

fiParisi, Pirotta, & Restelli

MORL algorithm returning continuous approximation Pareto frontier2 .
following sections present first approach able that: ParetoManifold
Gradient Algorithm (PMGA).
2.3 Policy Parametrization PolicyGradient Approaches
singleobjective
MDPs,

policygradient approaches consider parameterized policies
= : Rd , compact notation (a|s, ) policy
parameters space. Given policy parametrization , assume policy performance
J : F Rq least class C 2 .3 F called objectives space J defined
expected reward space possible trajectories
Z
p ( |) r( )d,
J () =


trajectory drawn density distribution p( |) reward vector
r( )
accumulated expected discounted reward trajectory , i.e.,
Prepresents
1
Ri (st , , st+1 ). Examples parametrized policies used context
ri ( ) = Tt=0
Guassian policies Gibbs policies. MOMDPs, q gradient directions defined
policy parameter (Peters & Schaal, 2008b), i.e.,
Z


Ji () =
p ( |) ri ( )d = E ln p ( |) ri ( )

"
#

1
X
b Ji (),
E ri ( )
ln (at |st , ) =
(1)
t=0

direction Ji associated particular discount factorreward function
b Ji () sample-based estimate. shown Equation (1),
pair < , Ri >
differentiability expected return connected differentiability policy
ln p ( |) =


1
X

ln (at |st , ).

t=0

remark notation. following use symbol DX F denote
derivative generic function F : Rmn Rpq w.r.t. matrix X.4 Notice
following relationship holds scalar functions vector variable: x f = (Dx f )T . Finally,
symbol Ix used denote x x identity matrix.

3. Gradient Ascent Policy Manifold Continuous Pareto Frontier
Approximation
section first provide general definition optimization problem want
solve explain solve MOMDP scenario using gradient
based approach. novel contributes section summarized Lemma 3.1
2. notable exception MOO approach Calandra, Peters, Deisenrothy (2014) Gaussian
Processes used obtain continuous approximation Pareto frontier.
3. function class C 2 continuous, twice differentiable derivatives continuous.
4. derivative operator well defined matrices, vectors scalar functions. Refer work
Magnus Neudecker (1999) details.

192

fiMORL Continuous Pareto Manifold Approximation

objective function gradient described. particular, provide solution
problem evaluating performance continuous approximation Pareto
frontier w.r.t. indicator function. problem non trivial MORL
direct access Pareto frontier manipulate policy
parameters. provide step-by-step derivation results leveraging manifold
theory matrix calculus.
3.1 Continuous Pareto Frontier Approximation Multiobjective
Optimization
shown locally Paretooptimal solutions locally forms (q 1)dimensional
manifold, assuming > q (Harada, Sakuma, Kobayashi, & Ono, 2007). follows
2objective problems, Paretooptimal solutions described curves policy
parameters objective spaces. idea behind work parametrize locally
Paretooptimal solution curve objectives space, order produce continuous
representation Pareto frontier.
Let generative space open set Rb b q. analogous high
dimensional function parameterized curve smooth map : Rq class
C l (l 1), P Rk free variables parameters,
respectively. set F = (T ) together map constitute parametrized
manifold dimension b, denoted F (T ) (Munkres, 1997). manifold represents
approximation Pareto frontier. goal find best approximation, i.e.,
parameters minimize distance real frontier
= arg max (F (T )) ,

(2)

P

: Rq R indicator function measuring quality F (T ) w.r.t.
true Pareto frontier. Notice Equation (2) interpreted special projection
operator (refer Figure 1a graphical representation). However, since requires
knowledge true Pareto frontier, different indicator function needed.
definition metric open problem literature. Recently, several metrics
defined, candidate presents intrinsic flaws prevent definition
unique superior metric (Vamplew et al., 2011). Furthermore, see
remainder section, proposed approach needs metric differentiable w.r.t.
policy parameters. investigate topic Section 5.
general, MOO algorithms compute value frontier sum value
points composing discrete approximation. scenario, continuous
approximate frontier available, maps integration Pareto manifold
Z
IdV,
(3)
L () =
F (T )

L () manifold value, dV denotes integral w.r.t. volume manifold
: F (T ) R indicator function measuring Pareto optimality point
F (T ). Assuming continuous, integral given (Munkres, 1997)
Z
Z
L () =
IdV
(I ) V ol (Dt (t)) dt,
F (T )



193

fiParisi, Pirotta, & Restelli

(a)

(b)

Figure 1: Transformation maps generic MOO setting (Figure (a)) MORL (Figure (b)). MOO also possible consider parametrized solutions Figure (b), MORL necessary, mapping Fi known
closed form determined (discounted) sum rewards.
1
provided integral exists V ol (X) = det X X 2 . standard way maximize
previous equation performing gradient ascent, updating parameters according
gradient manifold value w.r.t. parameters , i.e., + L () .
3.2 Continuous Pareto Frontier Approximation Multiobjective
Reinforcement Learning
standard multiobjective optimization function free designed,
MORL must satisfy conditions. first thing notice direct map
parameters space objective space unknown, easily
defined reparameterization involving policy space , shown Figure 1b.
previous section mentioned tight relationship (local)
manifold objective space (local) manifold policy parameters space.
mapping well known defined performance function J() defining
utility policy . means that, given set policy parameterizations, define
associated points objective space. consequence, optimization problem
reformulated search best approximation Pareto manifold
policy parameter space, i.e., search manifold policy parameter space
best describes optimal Pareto frontier.
Formally, let : smooth map class C l (l 1) defined
domain . think map parameterization subset (T ) :
choice point gives rise point (t) (T ) . means
subset (T ) space spanned map , i.e., (T ) bdimensional
parametrized manifold policy parameters space, i.e.,
(T ) = { : = (t), } ,
and, consequence, associated parameterized Pareto frontier bdimensional
open set defined
F (T ) = {J () : (T )} .
194

fiMORL Continuous Pareto Manifold Approximation

3.3 Gradient Ascent Manifold Space
point introduced notation needed derive gradient L ().
Lemma 3.1. (Pirotta et al., 2015) Let open set Rb , let F (T ) manifold
parametrized smooth map expressed composition maps J , (i.e., =
J : Rq ). Given continuous function defined point F (T ),
integral w.r.t. volume given
Z
Z
L () =
IdV =
(I (J )) V ol (D J()Dt (t)) dt,
F (T )



provided integral exists. associated gradient w.r.t. parameters given
Z

L ()
=
(I (J )) V ol (T) dt





Z





(I (J )) V ol (T) vec
+
Nb Ib Di Tdt, (4)


= J()Dt (t), Kronecker product, Nb = 12 (Ib2 + Kbb ) symmetric
(b2 b2 ) idempotent matrix rank 21 b(b + 1) Kbb permutation matrix (Magnus
& Neudecker, 1999). Finally,


Di = Dt (t)T Iq (D J()) Di (t) + (Ib J()) Di (Dt (t)) .
Proof. equation manifold value L () follows directly definition
volume integral manifold (Munkres, 1997) definition function composition.
following, provide detailed derivation i-th component gradient.
Let = J( )Dt (t),
Z
L ()

=
(I (J )) V ol (T) dt



Z
det TT
1
+
(I (J ))
dt.
2V ol (T)


indicator derivative determinant derivative respectively expanded

(I (J )) = DJ I(Jt ) J( ) Di (t),



det TT
det TT vec TT
=
,



(vec
T)
(vec
T)

|
{z
} |
{z
} | {z } |{z}
11

1b2

b2 qb

qb1



det TT
(vec T)T
TT
(vec T)T





,
= det
vec






= 2Nb Ib TT ,

195

fiParisi, Pirotta, & Restelli

Kronecker product, Nb = 12 (Ib2 + Kbb ) symmetric (b2 b2 ) idempotent
matrix rank 21 b(b + 1) Kbb permutation matrix (Magnus & Neudecker, 1999).
(T)
last term expanded Di vec
. start basic property
differential, i.e.,
(D J()Dt (t)) = d(D J())Dt (t) + J() d(Dt (t))
then, applying vector operator,
dvec (D J()Dt (t)) = vec (d(D J())Dt (t)) + vec (D J() d(Dt (t)))


= Dt (t)T Iq dvec (D J()) + (Ib J()) dvec (Dt (t)) .
{z
} |
{z
}|
{z
}
{z
}|
|
dq1

bqdq

bqbd

bd1

Finally, derivative given

vec J() (t)
vec Dt (t)


Di = Dt (t)T Iq
+ (Ib J())




|
{z
} | {zi }
|
{z
}
dqd



d1

bd1





= Dt (t) Iq (D J()) Di (t) + (Ib J()) Di (Dt (t)) .

interesting notice gradient manifold value L () requires
compute second derivatives policy performance J(). However, (D J()) =
vec J()
denote Hessian matrix transformation

(m,n)
H
Ji

=

2
Dn,m
Ji ()


=
n



Ji




= Dp,n (D J()) ,

p = + q(m 1) q (number objectives) number rows Jacobian
matrix. Recall Hessian
matrixis defined derivative transpose
Jacobian, i.e., H J() = J()T .
now, little research done second-order methods5 particular
Hessian formulations. first analysis performed Kakade (2001), provided
formulation based policy gradient theorem (Sutton, McAllester, Singh, & Mansour,
2000). Recently, extended comparison Newton method, EM algorithm
natural gradient presented Furmston Barber (2012). sake clarity,
report Hessian formulation provided Furmston Barber (2012) using notation
introduce optimal baseline (in terms variance reduction) formulation.
Lemma 3.2. MOMDP, Hessian H J() expected discounted reward J
w.r.t. policy parameters qd matrix obtained stacking Hessian
5. Notable exceptions natural gradient approaches that, although explicitly require
compute second-order derivatives, usually considered second-order methods.

196

fiMORL Continuous Pareto Manifold Approximation

component
H J() =


vec




Ji ()






H J1 ()


..
=
,
.
H Jq ()


Z
H Ji () =

!
p ( |) (ri ( ) bi ) ln p ( |) ln p ( |)T + H ln p ( |) d,

(5)




ln p ( |) =


1
X

ln (at |st , ),

H ln p ( |) =

t=0


1
X

H ln (at |st , ).

t=0
(m,n)

optimal baseline Hessian estimate H
Ji provided Equation (5)
computed done Greensmith, Bartlett, Baxter (2004) order reduce
variance gradient estimate. given component-wise


2
(m,n)
E p(|) Ri ( ) G
( )
(m,n)

bi
=
2 ,
(m,n)
E p(|) G
( )
(m,n)

(m,n)

n
G
( ) =
ln p ( |) ln p ( |)+H
Appendix A.

ln p ( |). derivation, refer

4. Manifold Gradient Estimation Sample Trajectories
MORL, prior knowledge reward function state transition
model, need estimate gradient L () trajectory samples. section
aims provide guide estimation manifold gradient. particular, review
results related estimation standard RL components (expected discounted return
gradient) provide finite-sample analysis Hessian estimate.
formulation gradient L () provided Lemma 3.1 composed terms
related parameterization manifold policy space terms related
MDP. Since map free designed, associated terms (e.g., Dt (t))
computed exactly. hand, terms related MDP (J (), J()
H J()) need estimated. estimate expected discounted reward
associated gradient old topic RL literature several results
proposed (Kakade, 2001; Pirotta, Restelli, & Bascetta, 2013), literature lacks explicit
analysis Hessian estimate. Recently, simultaneous perturbation stochastic approximation technique exploited estimate Hessian (Fonteneau & Prashanth, 2014).
However, rely formulation provided Furmston Barber (2012)
Hessian estimated trajectory samples obtained current policy, removing
necessity generating policy perturbations.
197

fiParisi, Pirotta, & Restelli

Algorithm 1 ParetoManifold Gradient Algorithm
Define policy , parametric function , indicator learning rate
Initialize parameters
Repeat terminal condition reached
Collect n = 1 . . . N trajectories
Sample free variable t[n] generative space

Sample policy parameters [n] = t[n]
n

[n] [n] [n]
Execute trajectory collect data st , , rt,
t=1

b Ji () according Equation (1)
Compute gradients
b Ji () according Equation (6)
Compute Hessians H
Compute manifold value derivative L () according Equation (4)
Update parameters + L ()
Since p ( |) unknown, expectation approximated empirical average.
Assuming access N trajectories, Hessian estimate
!
N

1
X
X
1
b Ji () =
H
rnt,i b
N
n=1
t=0
!T 1
!

1

1
X
X
X

ln ant ,snt
ln ant ,snt
+
H ln ant ,snt ,
(6)
t=0




n
[n] [n] [n]
st , , rt,

t=1

t=0

t=0

denotes n-th trajectory. formulation resembles def-

inition REINFORCE estimate given Williams (1992) gradient J().
estimates, known likelihood ratio methods, overcome problem determining perturbation parameters occurring finite-difference methods. Algorithm 1 describes
complete PMGA procedure.
order simplify theoretical analysis Hessian estimate, make following assumptions.
Assumption 4.1 (Uniform boundedness). reward function, log-Jacobian
log-Hessian policy uniformly bounded: = 1, . . . , q, = 1, . . . , d, n =
1, . . . , d, (s, a, s0 ) ,
fi
fi
fi
fi
fi
fi
fi
fi (m)
fi
fi (m,n)
fi
0 fi
ln (a|s, )fi G.
fiRi (s, a, )fi Ri ,
fiD ln (a|s, )fi D,
fiH
Lemma 4.2. Given parametrized policy (a|s, ), Assumption 4.1, i-th component log-Hessian expected return bounded
kH Ji ()kmax


Ri
2
TD + G ,
1

max norm matrix defined kAkmax = maxi,j {aij }.
198

fiMORL Continuous Pareto Manifold Approximation

Proof. Consider definition Hessian Equation (5). assumption 4.1,
Hessian components bounded (m, n)
fi
"

1

1
fi
fi fiZ
X
X


fi (m,n)
fi fi
ln (at |st , )
ln (aj |sj , )
Ji ()fi = fi p ( |) ri ( )
fiH
fi

n
t=0
j=0
#fi
fi
2
fi
+
ln (at |st , ) fi
fi
n



1

1

1

X
X
X
Ri
2

Ri
l1
+ G =
TD + G .
1
l=0

t=0

j=0

previous result used derive bound sample complexity
Hessian estimate.
Theorem 4.3. Given parametrized policy (a|s, ), Assumption 4.1, using
following number -step trajectories

2 2
1
Ri
2
N 2
TD + G
ln

2i (1 )
b Ji () generated Equation (6) probability 1
gradient estimate H


b

.
H Ji () H Ji ()
max

Proof. Hoeffdings inequality implies m, n
N 2 2
fi
fi

PN
fi b (m,n)
fi
(m,n)
(bi ai )2
i=1
=.
P fiH
Ji () H
Ji () fi 2e

Solving equation N noticing Lemma 4.2 provides bound sample,
obtain

2 2
1
Ri
2
N= 2
TD + G
ln .

2i (1 )

integral estimate computed using standard MonteCarlo techniques. Several
statistical bounds proposed literature, refer Robert Casella (2004)
survey MonteCarlo methods.
point paper, reader may expect analysis convergence (or
convergence rate) optimal parametrization. Although consider analysis theoretically challenging interesting, provide result related topic.
analysis hard (or even impossible) provide general settings since objective
function nonlinear nonconcave. Moreover, analysis simplified scenario (if
possible) almost useless real applications.
199

fiParisi, Pirotta, & Restelli

5. Metrics Multiobjective Optimization
section, review indicator functions proposed literature, underlining advantages drawbacks, propose alternatives. Recently, MOO focused
use indicators turn multiobjective optimization problem singleobjective
one optimizing indicator itself. indicator function used assign every
point given frontier scalar measure gives rough idea discrepancy candidate frontier Pareto one. Since instead optimizing objective
functions directly indicatorbased algorithms aim finding solution set maximizes
indicator metric, natural question arises correctness change
optimization procedure properties indicator functions enjoy. instance,
hypervolume indicator weighted version among widespread metrics
literature. metrics gained popularity refinements
Pareto dominance relation (Zitzler, Thiele, & Bader, 2010). Recently, several works
proposed order theoretically investigate properties hypervolume indicator (e.g., Friedrich, Horoba, & Neumann, 2009). Nevertheless, argued
hypervolume indicator may introduce bias search. Furthermore another important
issue dealing hypervolume indicator choice reference point.
perspective, main issues metric high computational complexity (the
computation hypervolume indicator #Phard problem, see Friedrich et al., 2009)
and, all, non differentiability. Several metrics defined field
MOO, refer work Okabe, Jin, Sendhoff (2003) survey. However,
MOO literature able provide superior metric among candidates
one suited scenario. Again, main issues non differentiability,
capability evaluating discrete representations Pareto frontier intrinsic
nature metrics. example, generational distance, another widespread measure
based minimum distance reference frontier, available settings.
overcome issues, mixed different indicator concepts novel differentiable
metrics. insights guided metrics definition related MOO
desiderata. Recall goal MOO compute approximation frontier
including solutions accurate, evenly distributed covering range similar
actual one (Zitzler et al., 2003). Note uniformity frontier intrinsically guaranteed continuity approximation introduced. concepts
mind, need induce accuracy extension indicator function.
stressed clear definition want indicator
maximized real Pareto frontier. also must ensure indicator function
induces partial ordering frontiers: manifold F2 solutions (weakly) dominated
manifold F1 ones, F1 manifold value must better F2 one.
Definition 5.1 (Consistent Indicator Function). Let F set (q 1)dimensional
manifolds associated MOMDP q objectives. Let k manifold
policy parameters
space mapping Fk F F true Pareto frontier. Let
R
LI (F) = F IdV manifold value. indicator function consistent
Fk 6= Fh , LI (Fh ) > LI (Fk ) Fh F ,



h , k , k , j h , j = LI (Fh ) > LI (Fk ).
200

fiMORL Continuous Pareto Manifold Approximation

5.1 Accuracy Metrics
Given reference point p, simple indicator obtained computing distance
every point frontier F reference point, i.e.,
= kJ pk22 .
mentioned hypervolume indicator, choice reference point may
critical. However, natural choice utopia (ideal) point (pU ), i.e., point
optimizes objectives. case goal minimization indicator
function, denoted IU (utopia indicator ). Since dominated policy farther
utopia least one Paretooptimal solution, accuracy easily guaranteed.
hand, since minimized, measure forces solution collapse
single point, thus consistent. Note problem mitigated
(but solved) forcing transformation pass singleobjective
optima. Although trick helpful, discuss Section 6, requires
find singleobjective optimal policies order constrain parameters. However,
information also required properly set utopia.
Concerning accuracy frontier, theoretical perspective, possible
define another metric using definition Pareto optimality. point Paretooptimal
(Brown & Smith, 2005)
l(, ) =

q
X

Ji () = 0,

q
X

i=1

= 1,

0,

i=1

is, possible identify ascent direction simultaneously improves
objectives. consequence, Paretoascent direction l point Pareto
frontier null. Formally, metric respects Paretooptimality defined
follows:
q
X
= minq kl(, )k22 ,
= 1, 0.
R

i=1

denote indicator IPN (Pareto norm indicator ). utopiabased metric,
extent frontier taken account without constraint optimal
solution collapses single point frontier.
5.2 Covering Metrics
extension frontier primary concern, maximizing distance
antiutopia (pAU ) results metric grows frontier dimension. However,
contrary utopia point, antiutopia located half space
reached solutions MOO problems. means considering
antiutopiabased metric maximization problem could become unbounded moving
solutions arbitrary far Pareto frontier antiutopia point. Therefore
measure, denoted IAU (antiutopia indicator ), provide guarantee
accuracy.
201

fiParisi, Pirotta, & Restelli

5.3 Mixed Metrics
mentioned indicators provide one desiderata. consequence,
resulting approximate frontier might arbitrary far actual one. order
consider desiderata mix previous concepts following indicator:
= IAU w
w penalization function, i.e., monotonic function decreases
accuracy input increases, e.g., w = 1 IPN w = 1 IU . metrics, denoted
respectively I,PN I,U , take advantage expansive behavior antiutopia
based indicator accuracy optimalitybased indicator. way
desiderata met single scalar measure, also C l (l 1) differentiable.
Another solution mix utopia antiutopiabased indicators different way.
want solutions simultaneously far antiutopia close utopia,
consider following metric (to maximized):
= 1

IAU
2 ,
IU

1 2 free parameters.
next section, show proposed mixed metrics effective driving
PMGA close Pareto frontier exact approximate scenarios. However,
want make clear consistency guaranteed strongly depends
free parameters , 1 2 . insights discussed Section 7.

6. Experiments
section, evaluate algorithm two problems, Linear-Quadratic Gaussian
regulator water reservoir control task. PMGA compared state-of-the-art methods
(Peters, Mulling, & Altun, 2010; Castelletti et al., 2013; Parisi et al., 2014; Beume, Naujoks,
& Emmerich, 2007) using hypervolume (Vamplew et al., 2011) extension
previously defined performance index (Pianosi, Castelletti, & Restelli, 2013), named loss,
measuring distance approximate Pareto front reference one. 2objective
problems, hypervolume exactly computed. 3objective problems, given high
computational complexity, hypervolume approximated MonteCarlo estimate
percentage points dominated frontier cube defined utopia
antiutopia points. estimate one million points used.
}
idea loss index compare true Pareto frontier FW = {Jw
wW

space weights W frontier JW = {Jbw }wW returned algorithm
weights (Jw denotes discounted return new singleobjective MDP defined
linear combination objectives w). Formally loss function l defined
l(J



Jw maxM Jbw

Z

J

, F, W, p) =
wW

Jw

p(dw),

(7)

p() probability density simplex W Jw = w J normalization factor, i-th component J difference best
202

fiMORL Continuous Pareto Manifold Approximation

worst value i-th objective Pareto frontier, i.e., Ji = max(Ji ) min(Ji ).
M.
means that, weight, policy minimizes loss function chosen JW
true Pareto frontier F known, reference one used.
Since PMGA returns continuous frontiers two scores designed discrete
ones, evaluation frontiers discretized. Also, figures presented
section show discretized frontiers order allow better representation. Besides
hypervolume loss function, report also number solutions returned
algorithm number rollouts (i.e., total number episodes simulated
learning process). data collected simulation results averaged
ten trials6 . experiments, PMGA learning rate


,
(8)
=

L () 1 L ()
positive definite, symmetric matrix userdefined parameter.
stepsize rule comes formulation gradient ascent constrained problem
predefined distance metric (Peters, 2007) underlies derivation natural
gradient approaches. However, since algorithm exploits vanilla gradient (i.e.,
consider Euclidean space) metric identity matrix I.
remainder section organized follows. start studying behavior
metrics proposed Section 5 effects parametrization (t) LQG.
Subsequently, focus attention sample complexity, meant number rollouts
needed approximate Pareto front. Finally, analyze quality algorithm
water reservoir control task, complex real world scenario, compare
state-of-the-art multiobjective techniques. case study, domains first
presented results reported discussed.
6.1 Linear-Quadratic Gaussian Regulator (LQG)
first case study discrete-time Linear-Quadratic Gaussian regulator (LQG)
multi-dimensional continuous state action spaces (Peters & Schaal, 2008b).
LQG problem defined following dynamics
st+1 = Ast + Bat ,

N (K st , )

R(st , ) = st Qst Rat
st n-dimensional column vectors, A, B, Q, R Rnn , Q symmetric
semidefinite matrix, R symmetric positive definite matrix. Dynamics
coupled, i.e., B identity matrices. policy Gaussian parameters
= vec(K), K Rnn . Finally, constant covariance matrix = used.
LQG easily extended account multiple conflicting objectives.
particular, problem minimizing distance origin w.r.t. i-th axis
taken account, considering cost action axes
X
Ri (st , ) = s2t,i
a2t,j .
i6=j

6. Source code available https://github.com/sparisi/mips.

203

fiParisi, Pirotta, & Restelli

Since maximization i-th objective requires null action axes,
objectives conflicting. reward formulation violates positiveness matrix
Ri , change adding sufficiently small -perturbation




X
X
Ri (st , ) = (1 ) s2t,i +
a2t,j
s2t,j + a2t,i .
i6=j

j6=i

parameters used experiments following: = 0.9, = 0.1 initial
state s0 = [10, 10]T s0 = [10, 10, 10]T 2 3objective case, respectively.
following sections compare performance proposed metrics several settings.
made use tables summarize results end set experiments.
6.1.1 2objective Case Results
LQG scenario particular instructive since terms involved definition returns, gradients Hessians computed exactly. therefore focus studying
different policy manifold parametrizations (t) metrics I.
Unconstrained Parametrization. domain problematic since defined
control actions range [1, 0] controls outside range lead divergence
system. primary concern therefore related boundedness control
actions, leading following parametrization manifold policy space:


(1 + exp(1 + 2 t))1
,
[0, 1].
= (t) =
(1 + exp(3 + 4 t))1
Utopia antiutopia points [150, 150] [310, 310], respectively, metrics IAU
IU normalized order 1 reference point.7 learning step parameter
Equation (8) = 1.
case, exploiting nonmixed metrics, PMGA able learn good approximation Pareto frontier terms accuracy covering. Using utopiabased
indicator, learned frontier collapses one point knee front.
behavior occurs using IPN . Using antiutopia point reference point solutions
dominated approximate frontier gets wider, diverging true frontier
expanding opposite half space. behaviors surprising, considering
definition indicator functions, explained Section 5.
contrary, shown Figure 2, mixed metrics able achieve
accuracy covering. starting 0 set [1, 2, 0, 3]T , algorithm also
able learn even starting different random parameters. free metric parameters
set = 1.5 I,PN , = 1 I,U 1 = 3, 2 = 1 .8 Although
shown figure, I,U behaved similarly I,PN . notice cases
first accuracy obtained pushing parametrization onto Pareto frontier,
frontier expanded toward extrema order attain covering.
7. Recall initially defined = kJ pk22 . slightly modify normalizing policy
performance w.r.t. reference point: = kJ/p 1k22 , / component-wise operator.
8. Section 7 study sensitivity proposed metrics parameters .

204

fiMORL Continuous Pareto Manifold Approximation

Table 1: Summary 2dimensional LQG (unconstrained)
Metrics
Nonmixed
Issues:

Accuracy
Covering
7
7
IU , IPN : frontier collapses one point
IAU : diverging behavior dominated solutions found
3
3

Mixed

Partial solution
Final approximation
True Pareto frontier

300

250

16
L ()

23

J2

100

20

200

50

1

21

end

0

150
150

200

250

300

0

50

J1

100

Iterations

(a) Learning process mixed metric I,PN .

300

15

250
10

L ()

J2

1,000

1

200

500

0

5
end
150
150

200

250

500

300

0

J1

50

100

Iterations

(b) Learning process mixed metric .

Figure 2: Learning processes 2objective LQG without constraint
parametrization. Numbers denote iteration, end denotes frontier obtained
terminal condition reached. left, approximated Pareto frontiers,
right corresponding L (). Using I,PN (Figure (a)) (Figure (b)) approximated frontier overlaps true one. However, using , PMGA converges faster.

205

fiParisi, Pirotta, & Restelli

Constrained Parametrization. alternative approach consists forcing policy
manifold pass extreme points true front knowing parameterizations singleobjective optimal policies. general, requires additional
optimizations collection additional trajectories must accounted
results. However, extreme points required set utopia antiutopia. Moreover, case optimal singleobjective policies available literature.
reasons, count additional samples report total number rollouts.
Using constrained parameterization, two improvements easily obtained. First,
number free parameters decreases and, consequence, learning process
simplified. Second, approximate frontier forced sufficiently large area
cover extrema. Thus, problem covering shown nonmixed indicators
alleviated or, cases, completely eliminated. 2dimensional LQG,
parametrization forced pass extrema frontier following:


(1 + exp(2.18708 1 t2 + (3.33837 + 1 )t))1
= (t) =
,
[0, 1].
(1 + exp(1.15129 2 t2 + (3.33837 + 2 )t))1
initial parameter vector 0 = [2, 2]T . constraint able correct diverging
behavior IU IPN , returned accurate wide approximation Pareto
frontier, shown Figure 2a. also notice much faster convergence, since algorithm required learn fewer parameters (two instead four). However, IAU still shows
diverging behavior initial parameters 0 (in Figure 2b, 0 = [6, 6]T ).
contrary, solutions obtained metrics independent initial 0 ,
algorithm converges close true frontier even starting parametrization
generating initial frontier far away true one.
6.1.2 3objective Case Results
Unconstrained Parametrization.


(1 + exp(1 + 2 t1 + 3 t2 ))1
= (t) = (1 + exp(4 + 5 t1 + 6 t2 ))1 ,
(1 + exp(7 + 8 t1 + 9 t2 ))1

simplex([0, 1]2 ).

Utopia antiutopia points [195, 195, 195] [360, 360, 360], respectively, metrics
IAU , IU normalized. initial parameters drawn uniform distribution 0
U nif ((0, 0.001)) (0 = 0 causes numerical issues) learning rate parameter = 1.
2objective scenario, frontiers learned IU IPN collapse single
point, IAU divergent trend (Figure 3a). However, unlike 2objective LQR,
I,PN also failed correctly approximate Pareto frontier. reason tuning
difficult, given difference magnitude IPN IAU contrary,
I,U = 1.5 1 = 3, 2 = 1 returned high quality approximate frontier.
latter shown Figure 3b. Although small areas true Pareto frontier
covered approximate one, stress fact policies found
Paretooptimal. strength metrics found normalization
utopia antiutopiabased indicators. expedient, indeed, allows easier tuning
free metric parameters, magnitude single components similar.
insights tuning mixed metrics parameters discussed Section 7.
206

fiMORL Continuous Pareto Manifold Approximation

Table 2: Summary 2dimensional LQG (constrained)
Metrics
Nonmixed: IU , IPN
Nonmixed: IAU
Issues:
Mixed

Accuracy
Covering
3
3
7
7
IAU : diverging behavior dominated solutions found
3
3

Partial solution
Final approximation
True Pareto frontier

300

1

120
L ()

J2

250

2

200

3

130

end
150
150

200

250

140

300

0

5

J1

10

15

20

25

100

120

Iterations

(a) Learning process utopiabased metric IU .

300

23

250

600

J2

7

200

L ()

3
1

400
200

150

0

150

200

250

300

0

J1

20

40

60

80

Iterations

(b) Learning process antiutopiabased metric IAU .

Figure 3: Learning process 2objective LQG parametrization forced pass
extreme points frontier. constraints able correct behavior
IU (Figure (a)) convergence faster previous parametrization. However,
IAU still diverges (Figure (b)) returned frontier includes dominated solutions, since
metric considers covering frontier accuracy.

207

fiParisi, Pirotta, & Restelli

Table 3: Summary 3dimensional LQG (unconstrained)
Metrics
Nonmixed
Issues:

Accuracy
Covering
7
7
IU , IPN : frontier collapses one point
IAU : diverging behavior dominated solutions found
7
7
I,PN : difficult tuning
3
3

Mixed: I,PN
Issues:
Mixed: I,U ,

True Pareto frontier
Approximate frontier

J3

1,000

500

500

500

1,000

J1

1,000

500

1,000

500

J1

J2

1,000

J2

(a) Frontier approximated antiutopiabased metric IAU .

J3

True Pareto frontier
Approximate frontier

300
350

200
300

200
200

200
J2

300

300

J1

250
250

300
200

J1

J2

350

(b) Frontier approximated mixed metric .

Figure 4: Resulting frontiers 3objective LQG using unconstrained parametrization. Frontiers discretized better representation. IAU learning
diverges (Figure (a)) correctly approximates Pareto frontier (Figure (b)).

208

fiMORL Continuous Pareto Manifold Approximation

Constrained Parametrization.


(1 + exp(a + 1 t1 (b 2 )t2 1 t21 2 t22 3 t2 t1 ))1
,
(1 + exp(a (b 4 )t1 + 5 t2 4 t21 5 t22 6 t1 t2 ))1
= (t) =
2
2
1
(1 + exp(c + (7 + b)t1 + (8 + b)t2 7 t1 8 t2 9 t1 t2 ))
= 1.151035476,

b = 3.338299811,

simplex([0, 1]2 ).

c = 2.187264336,

initial parameters 0 = 0. Numerical results reported Table 4,
hypervolume computed normalizing objective w.r.t. antiutopia. Figure 5
shows frontiers obtained using utopia antiutopiabased indicators. clearly
see that, unlike 2objective case, even constrained parametrization metrics
lead poor solutions, failing providing MO desiderata. Figure 5a, using IU
frontier still tends collapse towards center true one, order minimize
distance utopia point (only constraint prevents that). Although shown
figures, similar slightly broader frontier returned using IPN . However,
stress solutions belong Pareto frontier, i.e., nondominated solutions
found. Figure 5b shows frontier obtained IAU . expected, algorithm tries
produce frontier wide possible, order increase distance antiutopia
point. behavior leads dominated solutions learning process diverges.
contrary, using mixed metrics I,PN ( = 30), I,U ( = 1.4) (1 =
2.5, 2 = 1) PMGA able completely accurately cover Pareto frontier, shown
Figures 6a 6b. worth notice different magnitude free parameter
I,PN compared 2objective case, 1.5. already discussed, due
substantial difference magnitude IAU IPN . contrary, tuning
mixed metrics easier, similar parameters used unconstrained
parametrization proved effective. come back topic Section 7.
Finally, shown Table 4, I,U achieve best numerical results, first
attains highest hypervolume lowest loss, latter attains fastest
convergence. superiority also resides easy differentiability tuning, especially compared I,PN . reasons, chosen empirical analysis
sample complexity comparison state-of-the-art algorithms
real-world MO problem, discussed next sections.
Table 4: Performance comparison different metrics 3objective LQG
constrained parametrization. reference frontier hypervolume 0.7297.
Metric

Hypervolume

Loss

#Iterations

IU

0.6252

2.9012e-02

59

IAU

0





IPN

0.7167

1.9012e-02

133

I,PN

0.7187

5.2720e-04

47

I,U

0.7212

4.9656e-04

33



0.7204

5.0679e-04

15

209

fiParisi, Pirotta, & Restelli

Table 5: Summary 3dimensional LQG (constrained)
Metrics
Nonmixed
Issues:
Mixed

Accuracy
Covering
7
7
IU , IPN : frontier collapses one point
IAU : diverging behavior dominated solutions found
3
3

J3

True Pareto frontier
Approximate frontier

300
350

200
300

200
200

200
J2

300

300

J1

250
250

300
200

J1

J2

350

(a) Frontier approximated utopiabased metric IU .

J3

True Pareto frontier
Approximate frontier

500
200

350
250

300
200

200
300
J2

J1

300
250

300

J2

350
J1

200

(b) Frontier approximated antiutopiabased metric IAU .

Figure 5: Results parametrization forced pass extreme points
frontier. Using IU (Figure (a)) frontier shrinks much allowed parametrization. constraint therefore able solve issues metric 2
objective scenario. contrary, using IAU frontier gets wider diverges
true one (in Figure (b) intermediate frontier shown).

210

fiMORL Continuous Pareto Manifold Approximation

J3

True Pareto frontier
Approximate frontier

300

3

200
200

200
J2

300

300

0.4
0.6
0.8

J1

0.4

0.8

0.6
1

(a) Frontier objectives space.

0.4

0.6
2
0.8

(b) Frontier policy parameters space.

Figure 6: Results using constrained parametrization. shown Figure (a),
approximate frontier perfectly overlaps true one, despite small discrepancies
policy parameters space learned parameters optimal ones (Figure (b)).
Similar frontiers obtainable I,PN I,U .

6.1.3 Empirical Sample Complexity Analysis
section, provide empirical analysis sample complexity PMGA, meant
number rollouts needed approximate Pareto frontier. goal identify
relevant parameter estimate MDP terms J(), J() HJ().
analysis performed 2dimensional LQG domain varying number
policies used estimate integral per iteration PMGA number episodes
policy evaluation. steps episode fixed 50. first used
parametrization forced pass extreme points frontier 0 = [3, 7]T ,
produces initial approximate frontier far true one. parameter
learning rate Equation (8) set = 0.5 parameter I,U set
= 1. performance criterion, choose total number rollouts required reach
loss smaller 5 104 hypervolume larger 99.5% reference one.
criteria also used conditions convergence (both satisfied).
evaluation, MDP terms computed closed form. terminal condition must
reached 100, 000 episodes otherwise algorithm forced end. symbol used
represent latter case.
Table 6a results relevant parameter number episodes
used estimate MDP terms. parameter controls variance estimate,
i.e., accuracy estimate L (). increasing number episodes,
estimation process less prone generate misleading directions, happens, instance,
oneepisode case parameters move towards wrong direction. contrary,
number points used estimate integral (denoted table #t) seems
significant impact final performance algorithm, influences
number model evaluations needed reach prescribed accuracy. best behavior,
211

fiParisi, Pirotta, & Restelli

Table 6: Total number episodes needed converge varying number points #t
approximate integral number episodes #ep per point. symbol
used terminal condition reached.
(a) parametrization constrained pass extreme points frontier, one
point sufficient move whole frontier towards right direction.

#ep

1

5

10

25

50

1



695 578

560 172

1, 850 757

1, 790 673

5



2, 550 1, 509

3, 440 2, 060

5, 175 3, 432

8, 250 2, 479

10



4, 780 4, 623

6, 820 3, 083

10, 500 3, 365

11, 800 1, 503

25



7, 525 2, 980

15, 100 9, 500

18, 375 6, 028

24, 250 7, 097

50



8, 700 5, 719

18, 000 6, 978

26, 750 7, 483

50, 000 1, 474

#t

(b) contrary, using unconstrained parametrization, PMGA needs sufficient number
episodes enough points correct update step.

#ep

1

5

10

25

50

1











5









29, 350 7, 310

10







44, 100 9, 466

64, 500 1, 359

25







60, 500 1, 000

83, 500 8, 923

50





47, 875 18, 558

84, 250 1, 457



#t

samplebased perspective, obtained exploiting one point
integral estimate. Although surprising, simple explanation exists. forcing
parameterization pass singleobjective optima, correct estimation
gradient direction single point enough move entire frontier toward
true one, i.e., move parameters towards optimal ones.
contrary, unconstrained parametrization used, one point sufficient
anymore, shown Table 6b. case, initial parameter vector set 0 =
[1, 1, 0, 0]T , learning rate parameter = 0.1 terminal condition requires
frontier loss smaller 103 hypervolume larger 99% reference
frontier. Without constraint, algorithm needs accuracy evaluation
single points i.e., sufficient number episodes enough points move whole
frontier towards right direction. accuracy gradient estimate L () therefore
depends number points number episodes, PMGA requires
much rollouts converge. best behavior, samplebased perspective,
obtained exploiting five points integral estimate 50 episodes
policy evaluation.
212

fiMORL Continuous Pareto Manifold Approximation

6.2 Water Reservoir
water reservoir modeled MOMDP continuous state variable representing water volume stored reservoir, continuous action controlling
water release, state-transition model depending also stochastic reservoir inflow ,
set conflicting objectives. domain proposed Pianosi et al. (2013).
Formally, state-transition function described mass balance equation
st+1 = st + t+1 max(at , min(at , )) st reservoir storage time t; t+1
reservoir inflow time + 1, generated white noise normal distribution
t+1 N (40, 100); release decision; minimum maximum
releases associated storage st according relations = st = max(st 100, 0).
work consider three objectives: flooding along lake shores, irrigation
supply hydro-power supply. immediate rewards defined
R1 (st , , st+1 ) = max(ht+1 h, 0),
R2 (st , , st+1 ) = max( , 0),
R3 (st , , st+1 ) = max(e et+1 , 0),
ht+1 = st+1 /S reservoir level (in following experiments = 1), h
flooding threshold (h = 50), = max(at , min(at , )) release reservoir,
water demand ( = 50), e electricity demand (e = 4.36) et+1 electricity
production
et+1 = g H2 0 ht+1 ,
= 106 /3.6 dimensional conversion coefficient, g = 9.81 gravitational
acceleration, = 1 turbine efficiency H2 0 = 1, 000 water density. R1 denotes
negative cost due flooding excess level, R2 negative deficit
water supply R3 negative deficit hydro-power production.
Like original work, discount factor set 1 objectives
initial state drawn finite set. However, different settings used learning
evaluation phases. Given intrinsic stochasticity problem, policies
evaluated 1,000 episodes 100 steps, learning phase requires different
number episodes 30 steps, depending algorithm. discuss details
results section.
Since problem continuous exploit Gaussian policy model


(a|s, ) = N + (s)T , 2 ,
: Rd basis functions, = || = {, , }. optimal policies
objectives linear state variable, use radial basis approximation


(s) = e

ksci k2
wi

.

used four centers ci uniformly placed interval [20, 190] widths wi 60,
total six policy parameters.
213

fiParisi, Pirotta, & Restelli

6.2.1 Results
evaluate effectiveness algorithm analyzed performance
frontiers found weighted sum Stochastic Dynamic Programming (Pianosi et al., 2013),
Multi-objective FQI (Pianosi et al., 2013), episodic version Relative Entropy Policy
Search (Peters et al., 2010; Deisenroth et al., 2013), SMS-EMOA (Beume et al., 2007),
two recent policy gradient approaches, i.e., Radial Algorithm ParetoFollowing
Algorithm (Parisi et al., 2014). Since optimal Pareto front available, one
found SDP chosen reference one loss computation. MOFQI learns
deterministic policies (i.e., standard deviation Gaussian set zero)
trained using 10, 000 samples dataset 50, 000 tuples 2objective
problem 20, 000 samples dataset 500, 000 tuples 3objective problem.
remaining competing algorithms learn stochastic policies. number episodes
required policy update step 25 REPS, 100 PFA RA, 50 SMS-EMOA.
Given episodic formulation, REPS draws parameters upper distribution
(|) = N (, ) ,
diagonal covariance matrix, set zero. However, since algorithm
learns parameters = {, }, overall learned policy still stochastic. SMS-EMOA
maximum population size 100 500 2 3objective case, respectively.
crossover uniform mutation, chance 80% occur, adds white
noise random chromosomes. iteration, top 10% individuals kept
next generation guarantee solution quality decrease. Finally, MOFQI
scalarizes objectives using weights SDP, i.e., 11 25 weights 2
3objective case, respectively. REPS uses instead 50 500 linearly spaced weights. RA
also follows 50 500 linearly spaced directions and, along PFA, exploits natural
gradient (Peters & Schaal, 2008a) adaptive learning step Equation (8), = 4
= F , F Fisher information matrix. Concerning parametrization
PMGA, used complete first degree polynomial 2objective case


66 1 t2 + (1 16)t
105 2 t2 + (2 + 20)t


18 3 t2 + (3 16)t

,
[0, 1].
= (t) =
2

23 4 + (4 + 53)t
39 5 t2 + (5 + 121)t
0.01 6 t2 + (6 + 0.1)t
Similarly, 3objective case complete second degree polynomial used


36 + (15 1 )t2 + (1 + 1)t1 t2 + 30t21 + (1 1)t22
57 (27 + 2 )t2 + (2 + 1)t1 t2 48t21 + (2 1)t22


13 + (7 23 )t1 + (3 + 1)t1 t2 + (23 2)t21 11t22
2

= (t) =
30 + (9 24 )t1 + (4 + 1)t1 t2 + (24 2)t2 + 60t2 , simplex([0, 1] ).
1
2

104 + (57 5 )t2 + (5 + 1)t1 t2 65t2 + (5 1)t2
1

0.05 + (1 6 )t2 + (6 + 1)t1 t2 + (6 1)t22

2

parameterizations forced pass near extreme points Pareto frontier,
computed singleobjective policy search. cases starting parameter
214

fiMORL Continuous Pareto Manifold Approximation

103
9.5

L ()

J2 (Water Demand)

0

1

2

10

SDP
PMGA(0 )
PMGA(end )

10.5
11
11.5

50

100 150 200
Iterations

250

4

(a)

3.5

3

2.5 2 1.5
J1 (Flooding)

1

(b)

Figure 7: Results 2objective water reservoir. Even starting arbitrary poor
initial parametrization, PMGA able approach true Pareto frontier (Figure (b)).
Figure (a), trend manifold metric L () averaged ten trials.

vector 0 = [0, 0, 0, 0, 0, 50]T . last parameter set 50 order guarantee
generation sufficiently explorative policies, 6 responsible variance
Gaussian distribution. However, fair comparison, also competing algorithms
take advantage information, mean initial policies calculated accordingly behavior optimal ones described Castelletti et al. (2012), i.e.,
= [50, 50, 0, 0, 50]T . initial standard deviation set = 20 guarantee sufficient exploration. parametrization avoids completely random poor quality initial
policies. Utopia antiutopia points set [0.5, 9] [2.5, 11] 2
objective case, [0.5, 9, 0.001] [65, 12, 0.7] 3objective one.
According results presented Section 6.1.3, integral estimate PMGA
performed using MonteCarlo algorithm fed one random point. instance variable t, 50 trajectories 30 steps used estimate gradient
Hessian policy. Regarding learning rate, adaptive one described Equation (8) used = 2. evaluation, 1,000 2,000 points used
integral estimate 2 3objective case, respectively. already discussed, given
results obtained LQG problem order show capability approximate algorithm, decided consider indicator (1 = 1 2 = 1).
main reasons efficiency (in Table 4 attained fastest convergence)
easy differentiability. Finally, recall results averaged ten trials.
Figure 7b reports initial final frontiers first two objectives
considered. Even starting far true Pareto frontier, PMGA able approach
it, increasing covering accuracy approximate frontier. Also, shown Figure 7a, despite low number exploited samples, algorithm presents almost
monotonic trend learning process, converges iterations.
215

fiParisi, Pirotta, & Restelli

J2 (Water Demand)

9.5

10

10.5

SDP
PFA
RA
MOFQI
REPS
SMS-EMOA
PMGA
2.6

2.4

2.2

2

1.8

1.6

J1 (Flooding)

1.4

1.2

1

0.8

Figure 8: Visual comparison 2objective water reservoir. PMGA frontier comparable ones obtained state-of-the-art algorithms terms accuracy covering.
However, continuous one, others scattered.
Table 7: Numerical algorithm comparison 2objective water reservoir. SDP
reference frontier hypervolume 0.0721 nine solutions.
Algorithm

Hypervolume

Loss

#Rollouts

#Solutions

0.0620 0.0010

0.0772 0.0045

16, 250 1, 072



PFA

0.0601 0.0012

0.0861 0.0083

27, 761 4, 849

51.1 10.9

RA

0.0480 0.0005

0.1214 0.0043

59, 253 3, 542

16.1 2.9

-

0.1870 0.0090

10, 000

-

REPS

0.0540 0.0009

0.1181 0.0030

37, 525 2, 235

17.0 4.1

SMS-EMOA

0.0581 0.0022

0.0884 0.0019

149, 825 35, 460

14.2 2.4

PMGA

MOFQI

Figure 8 offers visual comparison Pareto points Tables 7 8 report
numerical evaluation, including hypervolume loss achieved algorithms
w.r.t. SDP approximation9 . PMGA attains best performance 2 3
objective cases, followed PFA. SMS-EMOA also returns good approximation,
slowest, requiring ten times amount samples used PMGA. MOFQI
outperforms PMGA sample complexity, loss highest. Finally, Figure 9
shows hypervolume trend PMGA comparison sample complexity
2objective case. PMGA substantially sample efficient algorithms,
attaining larger hypervolume much fewer rollouts. example, capable
generating frontier hypervolume RA one tenth rollouts,
outperforms PFA half samples needed latter.
9. Results regarding MOFQI include loss number rollouts hypervolume
number solutions available original paper.

216

fiMORL Continuous Pareto Manifold Approximation

0.065

PMGA

PFA (27,761)
SMS-EMOA (149,825)

Hypervolume

0.06

REPS (37,525)

0.055

RA (59,253)

0.05
0.045
0.04
2,000

4,000

6,000

8,000

10,000

12,000

14,000

16,000

#Rollouts
Figure 9: Comparison sample complexity 2objective case using hypervolume
evaluation score. brackets number rollouts needed algorithm produce
best frontier. PMGA clearly outperforms competing algorithms, requires
much fewer samples generate frontiers better hypervolume.
Table 8: Numerical algorithm comparison 3objective water reservoir. SDP
reference frontier hypervolume 0.7192 25 solutions.
Algorithm

Hypervolume

Loss

#Rollouts

#Solutions

0.6701 0.0036

0.0116 0.0022

62, 640 7, 963



PFA

0.6521 0.0029

0.0210 0.0012

343, 742 12, 749

595 32.3

RA

0.6510 0.0047

0.0207 0.0016

626, 441 35, 852

137.3 25.4

-

0.0540 0.0061

20, 000

-

REPS

0.6139 0.0003

0.0235 0.0014

187, 565 8, 642

86 9.7

SMS-EMOA

0.6534 0.0007

0.0235 0.0020

507, 211 56, 823

355.6 13.9

PMGA

MOFQI

7. Metrics Tuning
section want examine deeply tuning mixed metric parameters,
order provide reader better insights correct use metrics. performance PMGA strongly depends indicator used and, thereby, configuration
critical. precise, mixed metrics, obtained best approximate Pareto
frontiers experiments conducted Section 6, include trade-off accuracy
covering, expressed parameters. following, analyze fundamental
concepts behind metrics study performance influenced changes
parameters.
217

fiParisi, Pirotta, & Restelli

Approximate frontier
1,000

True Pareto frontier

300

300

250

250

200

200

500

150
500

(a) = 1

1,000

150
150

200

250

300

(b) = 1.5

150

200

250

300

(c) = 2

Figure 10: Approximate frontiers 2objective LQG learned PMGA using I,PN
varying . Figure (a) indicator penalize enough dominated solutions,
Figure (c) frontier wide enough. contrary, Figure (b)
algorithm achieves accuracy covering.

7.1 Tuning
first indicator (to maximized) analyze
= IAU w,
w penalization term. previous sections proposed w = 1 IPN
w = 1 IU , order take advantage expansive behavior antiutopiabased
indicator accuracy optimalitybased indicator. section study
performance mixed metric changing , proposing simple tuning process.
idea set initial value increase (or decrease) approximate
frontier contains dominated solutions (or wide enough). Figure 10 shows different
approximate frontiers obtained different values exact 2objective LQG
50 iterations using w = 1 IPN . Starting = 1 indicator behaves mostly
like IAU , meaning small (Figure 10a). Increasing 2 (Figure 10c)
algorithm converges, approximate frontier completely cover true one,
i.e., IPN mostly condition behavior metric. Finally, = 1.5 (Figure 10b)
approximate frontier perfectly matches true one metric correctly mixes two
single indicators.
However, already discussed Section 6, use w = 1 IPN problematic
difference magnitude IAU IPN make tuning hard
point metric becomes ineffective. drawback solved using w = 1 IU
normalizing reference point indicators (i.e., IU IAU ) I(J, p) = kJ/p 1k22 ,
normalization bounds utopia antiutopiabased metrics similar intervals,
i.e., (0, ) [0, ), respectively.10
10. ratio two vectors a/b component-wise operation.

218

fiMORL Continuous Pareto Manifold Approximation

J2

J2

U

1

10

J1

AU

1
(a)

J2

U

J1

AU

1
(b)

U

1

J1

AU

1
(c)

Figure 11: Examples Pareto frontiers. Figures (a) (b) frontiers convex,
latter objectives normalized. Figure (c) frontier concave.

7.2 Tuning
second mixed indicator (to maximized) also takes advantage expansive behavior antiutopiabased indicator accuracy utopiabased one.
defined
IAU
= 1
2 ,
IU
1 2 free parameters.
better understand insights guided metric definition, consider
different scenarios according shape Pareto frontier. Figure 11a frontier
convex normalized objectives. case point closer
antiutopia utopia is, sure, dominated solution. ratio IAU /IU
point frontier always greater 1 hence reasonable set 1
2 1. Therefore, need know exactly antiutopia point
drawback antiutopiabased metric IAU disappears, since also take account
distance utopia point. Nevertheless, setting points critical,
magnitude strongly affect PMGA performance. example shown Figure 11b,
frontier normalized objectives different magnitude.
case, setting 1 2 1, indicator evaluated extrema frontier
(J1 = [1, 0]T J2 = [0, 10]T ) equal 0.99 99, respectively. first value
negative, approximate frontier includes points true Pareto frontier,
J1 would perform better true Pareto frontier.
contrary, frontier concave (Figure 11c) true point
closer antiutopia utopia dominated solution, ratio IAU /IU
point frontier (with exception, eventually, ends) always
smaller one. Keeping 1 = 1 2 = 1, PMGA would try collapse frontier
single point, order maximize indicator. Therefore, parameters need
changed accordingly trial-and-error. instance, returned frontier
achieve accuracy, possible solution decrease 1 increase 2 .
219

fiParisi, Pirotta, & Restelli

8. Conclusion
paper proposed novel gradientbased approach, namely ParetoManifold
Gradient Algorithm (PMGA), learn continuous approximation Pareto frontier
MOMDPs. idea define parametric function describes manifold
policy parameters space, maps manifold objectives space. Given metric
measuring quality manifold objectives space (i.e., candidate frontier),
shown compute (and estimate trajectory samples) gradient w.r.t.
parameters . Updating parameters along gradient direction generates new
policy manifold associated improved (w.r.t. chosen metric) continuous frontier
objectives space. Although provided derivation independent
parametric function metric used measure quality candidate solutions,
terms strongly influence final result. Regarding former, achieved
high quality results forcing parameterization pass singleobjective
optima. However, trick might require domain expertise additional samples
therefore could always applicable. Regarding latter, presented different
alternative metrics, examined pros cons one, shown properties
empirical analysis discussed general tuning process promising ones.
evaluation also included sample complexity analysis investigate performance
PMGA, comparison state-of-the-art algorithms MORL. results,
approach outperforms competing algorithms quality frontier sample
complexity. would interesting study properties theoretical perspective
order provide support empirical evidence. leave open problems
investigation convergence rate approximation error true Pareto
frontier. However, think hard provide analysis general setting.
Future research address study metrics parametric functions
produce good results general case. particular, investigate problems
many objectives (i.e., three) highdimensional policies. Since complexity manifold parameterization grows number objectives policy
parameters, polynomial parameterization could effective complex problems alternative parameterizations found. Another interesting direction
research concerns importance sampling techniques reducing sample complexity
gradient estimate. Since frontier composed continuum policies, likely
trajectory generated specific policy partially used also estimation
quantities related similar policies, thus decreasing number samples needed
MonteCarlo estimate integral. Moreover, would interesting investigate automatic techniques tuning metric parameters applicability
PMGA multi-agent scenario (e.g., Roijers, Whiteson, & Oliehoek, 2015).

220

fiMORL Continuous Pareto Manifold Approximation

Appendix A. Optimal Baseline
Theorem A.1 (Componentdependent baseline). optimal baseline (i, j)-component
(i,j)
Hessian estimate HRF, JD () given Equation (6)

(i,j)
bH,



2
(i,j)
G ( )



E R( )

=
2
(i,j)
E G ( )

,


(i,j)

G

(i,j)

( ) = ln p ( |) j ln p ( |) + H

ln p ( |) .

Given baseline b, variance reduction obtained optimal baseline bH,
Var (HRF, JD (, b)) Var (HRF, J (, bH, )) =


(i,j) 2

(i,j)
2
b
bH,
(i,j)
E
G ( )
.

N
(i,j)

Proof. Let G

( ) (i, j)-th component G ( )
(i,j)

G

(i,j)

( ) = ln p ( |) j ln p ( |) + H

ln p ( |) .

(i,j)

variance HRF, JD () given by11
Var



(i,j)
HRF, JD



i2
2
2 h

(i,j)
(i,j)
(i,j)
G ( )
E R( ) b(i,j) G ( )
() = E R( ) b





2

2
(i,j)
(i,j)
2
(i,j) 2
+E b
G ( )
= E R( ) G ( )





2
h
i2
(i,j)
(i,j)
2b(i,j) E R( ) G ( )
E R( )G ( )
.




Minimizing previous equation w.r.t. b(i,j) get

(i,j)

bH,



2
(i,j)
E R( ) G ( )

=
2 .
(i,j)
E G ( )

11. use compact notation E [] denote E [].

221

fiParisi, Pirotta, & Restelli

excess variance given




(i,j)
(i,j)
(i,j)
Var G ( )(R( ) b(i,j) ) Var G ( )(R( ) bH, )




2
2
2

2
(i,j)
(i,j)
(i,j)
(i,j)
(i,j)
2
2b
E R( ) G ( )
+E b
G ( )
= E R( ) G ( )





h

2

2
i2
(i,j)
(i,j) 2
(i,j)
(i,j)
2
E bH,
E R( )G ( )
E R( ) G ( )
G ( )





2 h
i2
(i,j)
(i,j)
(i,j)
+ E R( )G ( )
+ 2bH, E R( ) G ( )




2
2

2
(i,j)
(i,j)
(i,j)
(i,j)
= b
E G ( )
2b
E R( ) G ( )




2

2
2
(i,j)
(i,j)
(i,j)
(i,j)
bH, E G ( )
+ 2bH, E R( ) G ( )






2
2

2

(i,j)
(i,j)
(i,j)
2
(i,j)
E G ( )
2b
E R( ) G ( )
= b








2 2



(i,j)

2
E R( ) G ( )

(i,j)




G ( )
2 E

(i,j)
E G ( )


2
(i,j)


2

E R( ) G ( )
(i,j)
2




R( ) G ( )
+ 2

2
E

(i,j)
E G ( )

2

2
2

(i,j)
(i,j)
(i,j)
(i,j)
2b
E R( ) G ( )
E G ( )
= b






2 2
(i,j)
E R( ) G ( )

+
2
(i,j)
E G ( )




2
(i,j)
G ( )



E R( )


(i,j) 2
(i,j)

= b
2b
2

(i,j)
E G ( )
E







(i,j)

= b

(i,j)

G


( )

2


(i,j) 2
bH, E




2
(i,j)
G ( )


.

222



2 2
(i,j)

E R( ) G ( )



+




2

(i,j)
E G ( )


fiMORL Continuous Pareto Manifold Approximation

References
Ahmadzadeh, S., Kormushev, P., & Caldwell, D. (2014). Multi-objective reinforcement
learning auv thruster failure recovery. Adaptive Dynamic Programming
Reinforcement Learning (ADPRL), 2014 IEEE Symposium on, pp. 18.
Athan, T. W., & Papalambros, P. Y. (1996). note weighted criteria methods compromise solutions multi-objective optimization. Engineering Optimization, 27 (2),
155176.
Barrett, L., & Narayanan, S. (2008). Learning optimal policies multiple criteria.
Proceedings 25th International Conference Machine Learning, ICML 08,
pp. 4147, New York, NY, USA. ACM.
Bertsekas, D. P. (2005). Dynamic programming suboptimal control: survey
ADP MPC*. European Journal Control, 11 (4-5), 310 334.
Beume, N., Naujoks, B., & Emmerich, M. (2007). Sms-emoa: Multiobjective selection based
dominated hypervolume. European Journal Operational Research, 181 (3), 1653
1669.
Brown, M., & Smith, R. E. (2005). Directed multi-objective optimization. International
Journal Computers, Systems, Signals, 6 (1), 317.
Calandra, R., Peters, J., & Deisenrothy, M. (2014). Pareto front modeling sensitivity
analysis multi-objective bayesian optimization. NIPS Workshop Bayesian
Optimization, Vol. 5.
Castelletti, A., Corani, G., Rizzolli, A., Soncinie-Sessa, R., & Weber, E. (2002). Reinforcement learning operational management water system. IFAC Workshop
Modeling Control Environmental Issues, Keio University, Yokohama, Japan,
pp. 325330.
Castelletti, A., Pianosi, F., & Restelli, M. (2012). Tree-based fitted q-iteration multiobjective markov decision problems. Neural Networks (IJCNN), 2012 International Joint Conference on, pp. 18.
Castelletti, A., Pianosi, F., & Restelli, M. (2013). multiobjective reinforcement learning
approach water resources systems operation: Pareto frontier approximation
single run. Water Resources Research, 49 (6), 34763486.
Crites, R. H., & Barto, A. G. (1998). Elevator group control using multiple reinforcement
learning agents. Machine Learning, 33 (2-3), 235262.
Das, I., & Dennis, J. (1997). closer look drawbacks minimizing weighted sums
objectives pareto set generation multicriteria optimization problems. Structural
optimization, 14 (1), 6369.
Das, I., & Dennis, J. E. (1998). Normal-boundary intersection: new method generating
pareto surface nonlinear multicriteria optimization problems. SIAM Journal
Optimization, 8 (3), 631657.
Deisenroth, M. P., Neumann, G., & Peters, J. (2013). survey policy search robotics.
Foundations Trends Robotics, 2 (1-2), 1142.
223

fiParisi, Pirotta, & Restelli

Fonteneau, R., & Prashanth, L. A. (2014). Simultaneous perturbation algorithms batch
off-policy search. 53rd IEEE Conference Decision Control, CDC 2014, Los
Angeles, CA, USA, December 15-17, 2014, pp. 26222627. IEEE.
Friedrich, T., Horoba, C., & Neumann, F. (2009). Multiplicative approximations
hypervolume indicator. Proceedings 11th Annual Conference Genetic
Evolutionary Computation, GECCO 09, pp. 571578, New York, NY, USA. ACM.
Furmston, T., & Barber, D. (2012). unifying perspective parametric policy search
methods markov decision processes. Pereira, F., Burges, C., Bottou, L., &
Weinberger, K. (Eds.), Advances Neural Information Processing Systems 25, pp.
27172725. Curran Associates, Inc.
Gabor, Z., Kalmar, Z., & Szepesvari, C. (1998). Multi-criteria reinforcement learning.
Shavlik, J. W. (Ed.), Proceedings Fifteenth International Conference
Machine Learning (ICML 1998), Madison, Wisconsin, USA, July 24-27, 1998, pp.
197205. Morgan Kaufmann.
Greensmith, E., Bartlett, P. L., & Baxter, J. (2004). Variance reduction techniques
gradient estimates reinforcement learning. Journal Machine Learning Research,
5, 14711530.
Harada, K., Sakuma, J., & Kobayashi, S. (2006). Local search multiobjective function
optimization: Pareto descent method. Proceedings 8th Annual Conference
Genetic Evolutionary Computation, GECCO 06, pp. 659666, New York, NY,
USA. ACM.
Harada, K., Sakuma, J., Kobayashi, S., & Ono, I. (2007). Uniform sampling local paretooptimal solution curves pareto path following applications multi-objective
GA. Lipson, H. (Ed.), Genetic Evolutionary Computation Conference, GECCO
2007, Proceedings, London, England, UK, July 7-11, 2007, pp. 813820. ACM.
Kakade, S. (2001). Optimizing average reward using discounted rewards. Helmbold, D. P.,
& Williamson, R. C. (Eds.), Computational Learning Theory, 14th Annual Conference
Computational Learning Theory, COLT 2001 5th European Conference
Computational Learning Theory, EuroCOLT 2001, Amsterdam, Netherlands, July
16-19, 2001, Proceedings, Vol. 2111 Lecture Notes Computer Science, pp. 605
615. Springer.
Koski, J., & Silvennoinen, R. (1987). Norm methods partial weighting multicriterion optimization structures. International Journal Numerical Methods
Engineering, 24 (6), 11011121.
Lizotte, D. J., Bowling, M., & Murphy, S. A. (2012). Linear fitted-q iteration multiple
reward functions. Journal Machine Learning Research, 13, 32533295.
Lizotte, D. J., Bowling, M. H., & Murphy, S. A. (2010). Efficient reinforcement learning
multiple reward functions randomized controlled trial analysis. Furnkranz, J.,
& Joachims, T. (Eds.), Proceedings 27th International Conference Machine
Learning (ICML-10), June 21-24, 2010, Haifa, Israel, pp. 695702. Omnipress.
224

fiMORL Continuous Pareto Manifold Approximation

Magnus, J. R., & Neudecker, H. (1999). Matrix Differential Calculus Applications
Statistics Econometrics. Wiley Ser. Probab. Statist.: Texts References
Section. Wiley.
Mannor, S., & Shimkin, N. (2002). steering approach multi-criteria reinforcement
learning. Dietterich, T., Becker, S., & Ghahramani, Z. (Eds.), Advances Neural
Information Processing Systems 14, pp. 15631570. MIT Press.
Mannor, S., & Shimkin, N. (2004). geometric approach multi-criterion reinforcement
learning. J. Mach. Learn. Res., 5, 325360.
Messac, A., & Ismail-Yahaya, A. (2002). Multiobjective robust design using physical programming. Structural Multidisciplinary Optimization, 23 (5), 357371.
Messac, A., Ismail-Yahaya, A., & Mattson, C. A. (2003). normalized normal constraint method generating pareto frontier. Structural multidisciplinary
optimization, 25 (2), 8698.
Munkres, J. R. (1997). Analysis Manifolds. Adv. Books Classics Series. Westview Press.
Natarajan, S., & Tadepalli, P. (2005). Dynamic preferences multi-criteria reinforcement
learning. Raedt, L. D., & Wrobel, S. (Eds.), Machine Learning, Proceedings
Twenty-Second International Conference (ICML 2005), Bonn, Germany, August
7-11, 2005, Vol. 119 ACM International Conference Proceeding Series, pp. 601608.
ACM.
Nojima, Y., Kojima, F., & Kubota, N. (2003). Local episode-based learning multiobjective behavior coordination mobile robot dynamic environments. Fuzzy
Systems, 2003. FUZZ 03. 12th IEEE International Conference on, Vol. 1, pp.
307312 vol.1.
Okabe, T., Jin, Y., & Sendhoff, B. (2003). critical survey performance indices
multi-objective optimisation. Evolutionary Computation, 2003. CEC 03. 2003
Congress on, Vol. 2, pp. 878885 Vol.2.
Parisi, S., Pirotta, M., Smacchia, N., Bascetta, L., & Restelli, M. (2014). Policy gradient
approaches multi-objective sequential decision making. 2014 International Joint
Conference Neural Networks, IJCNN 2014, Beijing, China, July 6-11, 2014, pp.
23232330. IEEE.
Perny, P., & Weng, P. (2010). finding compromise solutions multiobjective markov
decision processes. Coelho, H., Studer, R., & Wooldridge, M. (Eds.), ECAI 2010 19th European Conference Artificial Intelligence, Lisbon, Portugal, August 16-20,
2010, Proceedings, Vol. 215 Frontiers Artificial Intelligence Applications, pp.
969970. IOS Press.
Peters, J. (2007). Machine Learning Motor Skills Robotics. Ph.D. thesis, University
Southern California.
Peters, J., Mulling, K., & Altun, Y. (2010). Relative entropy policy search. Fox, M.,
& Poole, D. (Eds.), Proceedings Twenty-Fourth AAAI Conference Artificial
Intelligence (AAAI 2010), pp. 16071612. AAAI Press.
225

fiParisi, Pirotta, & Restelli

Peters, J., & Schaal, S. (2008a). Natural actor-critic. Neurocomputing, 71 (7-9), 1180 1190.
Progress Modeling, Theory, Application Computational Intelligenc 15th
European Symposium Artificial Neural Networks 2007 15th European Symposium
Artificial Neural Networks 2007.
Peters, J., & Schaal, S. (2008b). Reinforcement learning motor skills policy gradients.
Neural Networks, 21 (4), 682 697. Robotics Neuroscience.
Pianosi, F., Castelletti, A., & Restelli, M. (2013). Tree-based fitted q-iteration multiobjective markov decision processes water resource management. Journal Hydroinformatics, 15 (2), 258270.
Pirotta, M., Parisi, S., & Restelli, M. (2015). Multi-objective reinforcement learning
continuous pareto frontier approximation. Bonet, B., & Koenig, S. (Eds.), Proceedings Twenty-Ninth AAAI Conference Artificial Intelligence, January 25-30,
2015, Austin, Texas, USA., pp. 29282934. AAAI Press.
Pirotta, M., Restelli, M., & Bascetta, L. (2013). Adaptive step-size policy gradient
methods. Burges, C. J. C., Bottou, L., Ghahramani, Z., & Weinberger, K. Q. (Eds.),
Advances Neural Information Processing Systems 26: 27th Annual Conference
Neural Information Processing Systems 2013. Proceedings meeting held December
5-8, 2013, Lake Tahoe, Nevada, United States., pp. 13941402.
Robert, C., & Casella, G. (2004). Monte Carlo Statistical Methods. Springer Texts
Statistics. Springer-Verlag New York.
Roijers, D. M., Vamplew, P., Whiteson, S., & Dazeley, R. (2013). survey multi-objective
sequential decision-making. Journal Artificial Intelligence Research, 48, 67113.
Roijers, D. M., Whiteson, S., & Oliehoek, F. A. (2015). Computing convex coverage sets
faster multi-objective coordination. Journal Artificial Intelligence Research, 52,
399443.
Romero, C. (2001). Extended lexicographic goal programming: unifying approach. Omega,
29 (1), 6371.
Shelton, C. R. (2001). Importance Sampling Reinforcement Learning Multiple
Objectives. Ph.D. thesis, Massachusetts Institute Technology.
Steuer, R. E., & Choo, E.-U. (1983). interactive weighted tchebycheff procedure
multiple objective programming. Mathematical Programming, 26 (3), 326344.
Sutton, R. S., & Barto, A. G. (1998). Reinforcement Learning: Introduction. Bradford
book. Bradford Book.
Sutton, R. S., McAllester, D. A., Singh, S. P., & Mansour, Y. (2000). Policy gradient
methods reinforcement learning function approximation. Solla, S., Leen,
T., & Muller, K. (Eds.), Advances Neural Information Processing Systems 12, pp.
10571063. MIT Press.
Tesauro, G., Das, R., Chan, H., Kephart, J., Levine, D., Rawson, F., & Lefurgy, C. (2008).
Managing power consumption performance computing systems using reinforcement learning. Platt, J., Koller, D., Singer, Y., & Roweis, S. (Eds.), Advances
Neural Information Processing Systems 20, pp. 14971504. Curran Associates, Inc.
226

fiMORL Continuous Pareto Manifold Approximation

Vamplew, P., Dazeley, R., Berry, A., Issabekov, R., & Dekker, E. (2011). Empirical evaluation methods multiobjective reinforcement learning algorithms. Machine Learning,
84 (1-2), 5180.
Van Moffaert, K., Drugan, M. M., & Nowe, A. (2013). Scalarized multi-objective reinforcement learning: Novel design techniques. Adaptive Dynamic Programming
Reinforcement Learning (ADPRL), 2013 IEEE Symposium on, pp. 191199.
Van Moffaert, K., & Nowe, A. (2014). Multi-objective reinforcement learning using sets
pareto dominating policies. Journal Machine Learning Research, 15, 34833512.
Waltz, F. M. (1967). engineering approach: Hierarchical optimization criteria. Automatic
Control, IEEE Transactions on, 12 (2), 179180.
Wang, W., & Sebag, M. (2013). Hypervolume indicator dominance reward based multiobjective monte-carlo tree search. Machine Learning, 92 (2-3), 403429.
Williams, R. (1992). Simple statistical gradient-following algorithms connectionist reinforcement learning. Machine Learning, 8 (3-4), 229256.
Yu, P., & Leitmann, G. (1974). Compromise solutions, domination structures, salukvadzes solution. Journal Optimization Theory Applications, 13 (3), 362378.
Zitzler, E., Thiele, L., & Bader, J. (2010). set-based multiobjective optimization. Evolutionary Computation, IEEE Transactions on, 14 (1), 5879.
Zitzler, E., Thiele, L., Laumanns, M., Fonseca, C. M., & da Fonseca, V. G. (2003). Performance assessment multiobjective optimizers: analysis review. Evolutionary
Computation, IEEE Transactions on, 7 (2), 117132.

227

fiJournal Artificial Intelligence Research 57 (2016) 465-508

Submitted 03/16; published 11/16

PROMOCA: Probabilistic Modeling Analysis
Agents Commitment Protocols
Akn Gunay
Yang Liu
Jie Zhang

akingunay@ntu.edu.sg
yangliu@ntu.edu.sg
zhangj@ntu.edu.sg

School Computer Science Engineering
Nanyang Technological University, Singapore

Abstract
Social commitment protocols regulate interactions agents multiagent systems. Several methods developed analyze properties commitment protocols. However,
analysis agents behavior commitment protocol, take account
agents goals beliefs, received less attention. paper present ProMoca
framework address issue. Firstly, develop expressive formal language model
agents respect commitments. language provides dedicated elements
define commitment protocols, model agents terms goals, behaviors,
beliefs. Furthermore, language provides probabilistic non-deterministic elements
model uncertainty agents beliefs. Secondly, identify two essential properties
agent respect commitment protocol, namely compliance goal satisfaction.
formalize properties using probabilistic variant linear temporal logic. Thirdly,
adapt probabilistic model checking algorithm automatically analyze compliance
goal satisfaction properties. Finally, present empirical results efficiency
scalability ProMoca.

1. Introduction
Social commitments provide formal framework define, regulate, reason interactions agents multiagent systems (Singh, 1999). commitment made debtor
creditor bring condition. instance, merchant (debtor) committed
customer (creditor) deliver goods purchased customer. Every
commitment state changes according events. instance,
merchant delivers purchased goods, commitment customer becomes fulfilled.
Commitments enforce agents bring certain events. Instead, regulate
agents defining events affect states commitments. words, agents decide fulfilling violating commitments autonomously. instance, merchant
may decide deliver goods customer. However, event result violation
commitment, may consequences (e.g., merchant may sanctioned
also loses reputation). regulation, commitments establish desired level
interdependence among agents without interfering autonomy. Commitments
combined form commitment protocols, capture complex interactions
among agents (Yolum & Singh, 2002).
Analysis commitment protocols properties essential ensure effective operation. However, analysis challenging due rapidly increasing complexity
c
2016
AI Access Foundation. rights reserved.

fiGunay, Liu & Zhang

interaction protocols. Hence, development efficient formal analysis methods
commitment protocols, cope complexity, essential create effective multiagent systems. Various formal properties commitment protocols
studied several methods developed analyze (Yolum, 2007; Desai,
Cheng, Chopra, & Singh, 2007a; Desai, Narendra, & Singh, 2008; El Menshawy, Bentahar,
El Kholy, & Dssouli, 2013; El Kholy, Bentahar, Menshawy, Qu, & Dssouli, 2014).
However, analysis agents properties enacting commitment protocol
received less attention (Marengo, Baldoni, Baroglio, Chopra, Patti, & Singh, 2011; Gunay &
Yolum, 2013; Kafal, Gunay, & Yolum, 2014). analysis aims verify formal properties
agents behavior respect commitment protocol (e.g., compliance agents
behavior protocol), crucial developing effective agents. key challenge
analyzing agents behavior respect commitment protocol uncertainty,
naturally occurs multiagent systems due several factors. One major factor
agent autonomy, mainly corresponds epistemic uncertainty. Specifically, agents act
autonomously pursue private goals. Hence, agent cannot certain
behaviors agents. Similarly, agents lack awareness environment,
may result limited sensory reasoning capabilities, leads epistemic
uncertainty. Furthermore, many physical systems involve irreducible aleatory uncertainty
occurs due physical variability present agents environment. Agents cope
uncertainty utilizing reasoning methods use potentially wrong incomplete
beliefs instead exact knowledge (Halpern, 2003).
previous work commitments address uncertainty. fill gap,
previous work, developed analysis method commitment protocols using
probabilistic model checking, handle uncertainty behaviors agents (Gunay,
Songzheng, Liu, & Zhang, 2015). method uses abstract formalism (specifically,
probabilistic automaton) modeling analyzing behaviors agents commitment
protocols. However, practical point view, manual definition commitment protocols behaviors agents abstract formalism time consuming error
prone task. Besides, requires modeler knowledge expertise specific
abstract formalism. issues, use abstract formalism modeling
adequate practical development settings (e.g., developer verifies
agents implementation). adequate approach use expressive high level formal
language modeling, automatically translated abstract formalism
formal analysis. best knowledge, dedicated formal modeling
language capture uncertainty agents context commitment protocols.
paper present ProMoca framework address issue. ProMoca provides expressive modeling language includes various language elements model
commitment protocols, also various aspects agents, different goal types,
beliefs, behaviors. Besides, ProMoca supports probabilistic modeling capture uncertainty behaviors beliefs agents. ProMoca also pay special attention
two essential properties agents behavior respect commitment protocol.
first properties compliance agents behavior commitment protocol.
is, whether agents behavior fulfills agents commitments. second property
considers whether agents behavior satisfies agents goals context commitment protocol. Since agents interdependent, neither compliance goal satisfaction
466

fiProMoca: Probabilistic Modeling Analysis Agents Commitment Protocols

analyzed considering agents behavior isolation. cope interdependence, ProMoca uses agents beliefs agents behaviors. ProMoca
adopts previous probabilistic model checking method (Gunay et al., 2015) analyzing
properties. evaluate efficiency scalability ProMoca use three realistic examples. Besides, compare ProMocas performance PRISM,
state-of-the-art probabilistic model checker. main contributions follows:
develop new modeling language ProMoca (we use name ProMoca
modeling language analysis framework interchangeably). define
formal syntax operational semantics ProMoca, provides dedicated
language elements define manage commitment protocol. ProMoca also
provides various language elements define behaviors, goals, beliefs agent
context commitment protocol. Moreover, ProMoca provides probabilistic
non-deterministic elements model uncertainty agents beliefs.
best knowledge, ProMoca first formal language provides dedicated
elements modeling commitment protocols, agents, uncertainty unified
environment.
identify develop formal definitions compliance goal satisfaction properties. Different previous definitions properties literature,
formalization take uncertainty agents beliefs agents behaviors
account using probabilistic variant linear temporal logic. Accordingly,
define properties precise flexible manner.
analyze agents behavior context commitment protocol verifying
compliance goal satisfaction, define complete ProMoca framework,
modeling done using new formal language develop
paper, analysis done adopting previously developed probabilistic model
checking method (Gunay et al., 2015).
substantially extend earlier preliminary experimental result (Gunay et al.,
2015), conducting detailed empirical study validate ProMocas practical
usefulness scalability three well-studied scenarios literature, namely
aerospace aftercare, international insurance (Jakob, Pechoucek, Miles, & Luck, 2008),
NetBill (Sirbu & Tygar, 1995). results show ProMoca outperforms
state-of-the-art general purpose probabilistic model checker PRISM verifying
compliance goal satisfaction properties agents behavior context
commitment protocol.
paper organized follows. Section 2, introduce fundamental concepts
commitment protocols, agents, analysis behaviors. Section 3, define
ProMocas formal syntax operational semantics. Section 4, define analysis
framework model checking algorithm. Section 5, present empirical evaluation
framework. Section 6 provides survey related work. Finally, Section 7,
conclude paper discussion approach listing future directions.
467

fiGunay, Liu & Zhang

2. Background: Commitments, Agents, Analysis
section provide overview commitments, agent concepts, behaviors, goals, beliefs, key ProMoca. also discuss compliance goal
satisfaction properties respect concepts motivate research.
2.1 Commitments
commitment made one agent another bring condition (Singh, 1999).
Conventionally, commitment denoted C(debtor, creditor, antecedent, consequent)
debtor creditor agents, antecedent consequent conditions.
Intuitively, commitment means debtor committed creditor bring
consequent, antecedent holds. instance, commitment C(merchant,
customer, goods-purchased, goods-delivered ) captures merchants commitment
customer deliver goods (represented proposition goods-delivered ),
goods purchased customer (represented proposition goods-purchased ).
exact meaning commitment depends type condition used
consequent. Achievement conditions widely used type commitments consequent. brevity, call commitment condition simply
achievement commitment. commitment merchant deliver purchased
goods customer example achievement commitment. Use maintenance
condition commitments consequent also considered literature (Fornara
& Colombetti, 2002; Mallya & Huhns, 2003; Gunay & Yolum, 2011; Chesani, Mello, Montali, & Torroni, 2013). commitment maintenance condition consequent
fulfilled, condition maintained another termination condition occurs. call
commitment condition simply maintenance commitment. instance,
internet service provider may committed customer provide internet connection
month, customer purchases data plan internet service provider.
Commitments also considered subscription model. instance, instead
purchasing data plan single month, customer may subscribe data plan
year monthly basis (i.e., duration period subscription month).
result, internet service provider separate commitment month year
provide internet connection customer, long customer pays corresponding
monthly subscription fee. technical terms, subscription considered
template (e.g., customer pays subscription fee specific month, service
provider becomes committed provide internet connection month) creating
concrete commitment instances period subscription. example,
create twelve commitment instances template (one month)
setting commitments antecedent consequent propositions model payment
subscription fee provision internet specific month, respectively. best
knowledge, subscription model formally considered previous
research. However, subscriptions part many real world settings. Accordingly,
formalize ProMoca. Note subscription model considered
special case meta-commitment concept (Chopra & Singh, 2015, 2016a),
general since bound specification subscription.
468

fiProMoca: Probabilistic Modeling Analysis Agents Commitment Protocols

null
creditor
releases
released

creditor
releases

debtor
creates

debtor
discharges

expired

conditional
creditor
detaches

active

fulfilled

antecedent
expires

compensated

violated
debtor cancels
fails discharge

debtor
compensates

Figure 1: lifecycle commitment.
commitments state evolves time according public events (i.e., independent agents internal state). lifecycle commitment studied
extensively literature (Yolum & Singh, 2002; Fornara & Colombetti, 2002; Chesani
et al., 2013). Here, use commitment lifecycle show Figure 1,
labels rectangles represent commitment states, edge labels show events
corresponding agents trigger state changes.
commitment null state creation. commitment created
debtor conditional state. state neither antecedent consequent
commitment holds. instance, commitment merchant customer
created merchant (i.e., debtor) initially neither payment delivery.
Hence, commitment conditional. intuitive meaning conditional commitment
similar offer states, antecedent starts holds, debtor becomes
committed creditor bring consequent.
commitments antecedent satisfied, commitment becomes expired.
creditor conditional commitment may also explicitly release debtor commitment, makes commitment released. Expired released states terminal
states. antecedent conditional commitment satisfied, creditor detaches
commitment, commitment becomes active. Detachment commitment independent antecedent satisfied. is, antecedent may satisfied either
event occurs direct result action creditor (e.g., customer pays),
external event (e.g., customers bank may pay behalf customer).
active commitment intuitively means debtor committed bring
consequent commitment.
Fulfillment violation commitment depends type commitments
consequent. consequent active achievement commitment satisfied, debtor
immediately discharges commitment, commitment becomes fulfilled (e.g.,
merchant delivers). maintenance commitment fulfilled, consequent commitment maintained another condition determines termination commitment occurs (e.g., internet service provider maintains internet connection user
termination data plan). case detachment, commitments
469

fiGunay, Liu & Zhang

fulfillment also independent consequent satisfied (e.g., merchant may deliver, could delegate delivery courier). fulfilled commitment
intuitively means debtor honored responsibility, fulfilled state terminal. case conditional commitment, creditor may also release debtor
active commitment.
either consequent active commitment satisfied, debtor explicitly
cancels commitment, commitment becomes violated. achievement commitment, failure consequent may depend another condition (e.g., deadline).
maintenance commitment, failure consequent occurs, consequent condition
hold moment termination condition commitment holds. Note
due autonomy agents, debtor may intentionally choose violate commitment,
even fulfill it. instance, merchant may decide sell goods another
customer better profit, may violate commitment original customer.
hand, debtor may also violate commitment unintentionally. instance,
merchant may fail deliver bad weather conditions. case, violated
commitment intuitively means debtor failed honor responsibility. Depending
domain application, violated commitment compensated debtor
taking certain action, makes commitment state compensated (Torroni, Chesani,
Mello, & Montali, 2010; Kafal & Torroni, 2012; Chopra & Singh, 2015). instance,
merchant fails deliver goods customer, violates commitment. However,
refund customer compensate commitments violation. Compensation
allows agents restore interaction back desirable state, interrupted
due violated commitment. Compensated state terminal. commitment violated
way compensation, violated state counted terminal.
Note subscription state itself, since define concrete
commitment, provides template instantiating concrete commitments
period subscription. Hence, notion state subscription captured
abstract manner states corresponding concrete commitment instances.
many applications, agents engage complex interactions cannot represented
single commitment. capture aspects complex interactions, multiple
commitments considered together commitment protocol (Yolum & Singh, 2002).
instance, merchants commitment customer captures payment
delivery aspects interaction, another commitment C(merchant, customer, goodsdefective, goods-replaced ), states merchant committed customer
replace defective good, captures warranty related aspects interaction.
two commitments (and prospective commitments) form commitment protocol.
2.2 Agents Analysis Behaviors
paper, main objective develop dedicated formal language modeling
analyzing agents behavior commitment protocol. clear
context, call particular agent target agent distinguish agents.
analysis use three kinds information, available target
agent. first kind information target agents goals. divide goals
two types achievement maintenance goals customary agent literature
470

fiProMoca: Probabilistic Modeling Analysis Agents Commitment Protocols

(van Riemsdijk, Dastani, & Meyer, 2009; Chopra, Dalpiaz, Giorgini, & Mylopoulos, 2010).
Achievement goals model situations, agent aims achieve certain satisfaction
condition. instance, customer may aim possess goods. Maintenance goals
model situations agent aims maintain certain satisfaction condition.
instance, internet service provider may aim maintain internet service
running. Furthermore, goal types considered one-time persistent goals.
One-time goals pursued once, general, subject preconditions.
example, customer needs certain type good possess it,
goal possess good. Similarly, internet service provider aims provide
maintain internet connection customer, customer subscribed
service. One-time goals might also termination condition (e.g., deadline).
termination condition goal holds satisfaction condition, goal fails.
Contrary one-time goals, persistent goals pre termination conditions,
persist whole lifespan agent. case persistent achievement goal,
agent aims satisfy condition may fail time time, always restored
while. instance, merchant may aim dispose obsolete goods (e.g., old
versions mobile phone) warehouse. Occasionally, obsolete goods may
kept warehouse (e.g., new version mobile phone first appears, takes
dispose old phones), disposed eventually.
hand, persistent maintenance goals represents condition agent aims keep
satisfied continuously whole lifespan without precondition. instance,
merchant might aim maintain positive bank balance whole lifespan.
second kind information, use analysis, target agents behavior.
assume target agents behavior persistent (i.e., non-terminating) computation,
agent uses set if-then type rules decide next action (e.g.,
merchant commitment make delivery commitment active,
delivers). uncertainty results agents actions, decision rules
may include non-deterministic probabilistic components model uncertainty. Suppose
merchant may fail deliver time probability 0.1 depending weather
conditions. case, if-then rule defines merchants behavior would be:
merchant committed deliver weather condition bad, merchant
delivers time (and fulfills commitment) 0.9 probability, fails deliver
time (and violates commitment) 0.1 probability. demonstrate rest
paper, combination if-then rules, non-determinism, probabilistic choice,
context persistent computation provides us rich flexible model define various
complex agent behaviors.
last kind information use analysis target agents beliefs
behaviors agents. Uncertainty natural element kind information, since
agents autonomous. Accordingly, define target agents beliefs
agents behaviors similar manner target agents behavior using probabilistic
choice non-determinism. instance, suppose merchant dependent
courier make delivery, necessary fulfill commitment customer.
situation merchant may believe courier successfully delivers time
probability 0.95 (and fails deliver time probability 0.05). demonstrate
later, capture situation using probabilistic choice beliefs target
471

fiGunay, Liu & Zhang

agent similar manner earlier example. Note that, paper assume
probability values agents behavior beliefs set modeler. values
may reflect intuition modeler, obtained statistical model (e.g.,
previous delivery results merchant courier different weather conditions).
Considering three kinds information, objective analyze two key properties target agents behavior commitment protocol. first property
compliance, holds target agents behavior fulfills active commitments
protocol. relaxed version compliance may take compensation account.
is, agent complies commitment protocol fulfilling active commitments
also compensating violated commitments. second property goal satisfaction,
holds target agent satisfies goals enacting commitment protocol. target agents beliefs agents play crucial role analyzing properties since
interdependence among agents. words, agents behaviors directly
affect target agent. instance, merchant relies courier delivery,
merchants compliance protocol goal satisfaction cannot correctly verified
without taking couriers behavior account. fact, consider merchants behavior, neither compliance goal satisfaction hold merchant, since
delivery capability. However, merchant believes courier
delivers high probability, conclude merchant complies
protocol also satisfies goal enacting protocol.
2.3 Running Example
rest paper use running example aerospace aftercare domain,
introduced Jakob et al. (2008), used literature evaluation
commitments normative models (Modgil, Faci, Meneguzzi, Oren, Miles, & Luck,
2009; Desai, Chopra, & Singh, 2009). example scenario, manufacturer
provides aircraft engines airline operators. manufacturer sells engine
airline operator, manufacturer becomes responsible keeping engine operational
periodically servicing engine. airline operator pay service fee
manufacturer. Besides, airline operator also provide operational data
engine manufacturer, needed manufacturer analyze status
engine. order service engine, manufacturer needs spare engine parts
several suppliers. However, manufacturer use certain engine parts
servicing, approved monitoring aerospace agency. airline operator may
monitored different aerospace agencies depending regions airline
operates. Different agencies may different policies approved spare engine parts.
Hence, use certain part repair depends airline respective agencies.
operational status engine maintained, manufacturer compensate
situation paying penalty airline operator. manufacturer also
bring engine back operational state within certain amount time.
manufacturer fails compensate, contract may canceled airline operator.
consider example engine manufacturers point view analyze
compliance goal satisfaction.
472

fiProMoca: Probabilistic Modeling Analysis Agents Commitment Protocols

3. Modeling Commitment Protocols Agents PROMOCA
first present formal syntax ProMoca Section 3.1. Then, define
operational semantics ProMoca Section 3.2, formalize compliance goal
satisfaction properties Section 3.3. Finally, discuss key design decisions
ProMoca Section 3.4.
3.1 Syntax
ProMoca model composed three blocks, define set global variables,
commitment protocol, target agent (i.e., agent aim verify).
define syntax block illustrative examples.
3.1.1 Global Variables
ProMoca model includes finite set global variables, defined within
block globals{var; . . . var;}. variable var defined using keyword variable
following syntax:
var ::= variable variable-name : {value-set} = value
variable-name unique name variable, value-set finite set strings
defines domain variable (i.e., enumeration variables possible values),
value initial value variable, must element value-set.
instance, status aircraft engine modeled using following variable:
variable engine-status : {unknown, operational, malfunction, maintenance} = unknown;

name variable engine-status. domain variable consists four
values, capture different operational states engine. initial value
variable unknown.
3.1.2 Commitment Protocol
commitment protocol composition finite set commitments. commitment
protocol defined within block protocol{comm; . . . comm;}. commitment comm
defined using keyword commitment following syntax:
comm ::= commitment(commitment-id, commitment-type, subscription-period,
debtor-id, creditor-id, antecedent, expiration, consequent, termination)
{observers}[commitment-id]
first parameter commitment-id unique string identifier commitment.
type commitment defined commitment-type, either achievement
maintenance. Subscriptions modeled using subscription-period parameter,
finite integer greater 0 represents total number subscriptions periods.
commitment subscription, parameter omitted, ProMoca sets
473

fiGunay, Liu & Zhang

value 1 default. parameters debtor-id creditor-id identifiers
commitments debtor creditor, respectively. parameters antecedent, expiration, consequent, termination expressions define antecedent, expiration, consequent,
termination condition commitment, respectively. optional parameter observers set agent identifiers includes agents, observe state
commitment. default, debtor creditor commitment always observe
state commitment, required list observers.
observers commitments debtor creditor, observers omitted.
last optional parameter commitment-id identifier another commitment
used compensate violation commitment. compensation
commitments violation, parameter omitted.
expression (e.g., antecedent parameter commitment) logical expression
compositions conjunctions disjunctions global variable comparisons. Formal
syntax expression follows:
expression
comparison
const

::=
::=
::=

expression expression | expression expression | comparison
variable-name == value | variable-name != value | const
TRUE | FALSE

expression, use standard semantics logical operators or.
Similarly, comparison use standard equal equal semantics
operators == !=, respectively. TRUE FALSE standard boolean constants.
Parentheses used regularly define precedence logical operators,
omit formal syntax brevity.
ProMoca automatically creates several variables capture lifecycle protocols commitments. Firstly, ProMoca creates status variable commitment
protocol. names variables automatically set ProMoca using
<commitment-id>-state pattern (e.g., commitment commitment-id c-1, corresponding variables name c-1-state). status variable domain {null,
conditional, active, fulfilled, violated, expired, released, compensated} capture
corresponding state commitment. variables used ProMoca model
read-only variables. Secondly, ProMoca creates subscription counter commitment track fulfillment subscriptions. However, counters internal
ProMoca, cannot directly accessed within ProMoca model. semantics
variables formalized later Section 3.2.
present example commitments aerospace aftercare scenario
illustrate use ProMocas commitment syntax. Let us start simple achievement
commitment: operator pays price engine manufacturer, manufacturer committed deliver engine. Suppose payment delivery
deadlines (defined variables). commitment observed aerospace agency.
commitment violated, cannot compensated. commitment written
ProMoca follows:
commitment(c-1, achievement, 1, manufacturer, operator,
engine-paid == done, payment-deadline == past,

474

fiProMoca: Probabilistic Modeling Analysis Agents Commitment Protocols

engine-delivered == done, delivery-deadline == past)
{aerospace-agency};

second example consider maintenance engine according commitment: manufacturer delivers engine operator, manufacturer
committed operator maintain engine operational year, identify c-2. manufacturer fails maintain engine operational, violates c-2,
compensate situation repairing engine also paying penalty,
defined compensating commitment c-3. Note c-2 explicitly declares c-3
compensating commitment. declaration essential correctly managing lifecycles commitments show later Section 3.2. Note use variable
contract commitments capture whether contract manufacturer
operator still valid. contract parties terminated (e.g., delivery
engine canceled), commitments expire.
commitment(c-2, maintenance, 1, manufacturer, operator,
contract == valid engine-delivered == done, contract == terminated,
engine-status == operational engine-status == maintenance, end-of-year == past)
{aerospace-agency}[c-3];

commitment(c-3, achievement, 1, manufacturer, operator,
contract == valid c-2-status == violated,
contract == terminated c-2-status == fulfilled c-2-status == released,
engine-status == operational penalty-paid == done,
compensation-deadline == past)
{aerospace-agency};

continue, let us emphasize different meaning termination condition
achievement maintenance commitments. achievement commitment, debtor
committed bring consequent point occurrence
termination condition. example, achievement commitment c-1, termination
condition delivery deadline, c-1 fulfilled, engine delivered
point deadline. Otherwise, c-1 becomes violated. hand,
maintenance commitment, debtor committed maintain consequent every
point commitments detachment occurrence termination condition.
example, maintenance commitment c-2, termination condition completion
one year delivery engine, fulfillment occurs engines operational
status preserved detachment commitment completion
year. Otherwise, commitment becomes violated immediately.
complement c-2, need another commitment c-4 defines monthly servicing
engine using subscription model follows. delivery engine,
manufacturer committed operator service engine monthly basis
475

fiGunay, Liu & Zhang

year, long operator pays monthly service fee provides engine usage
reports. brevity, omit observers compensation commitment.
commitment(c-4-, achievement, 12, manufacturer, operator,
contract == valid engine-delivered == done service-fee-paid-* == done
engine-report-provided-* == done,
contract == terminated fee-deadline-* == past engine-report-provided-* == failed,
engine-serviced-* == done,
engine-serviced-* == failed engine-serviced-* == late);

Since commitment modeled subscription year monthly basis,
twelve instances commitment. However, conditions commitment
apply individual instances. example, separate payment service
fee month. ProMoca provides * notation variables correspond
instance conditions. example, service-fee-paid-* means twelve variables
(e.g., service-fee-paid-1, service-fee-paid-2, etc.) model separate payment
service fee. first instance commitment becomes active, service-fee-paid-1
conditions antecedent hold. Note conditions instance
specific. conditions, delivery engine (i.e., engine-delivered), used
instances referring variable.
3.1.3 Target Agent Specification
target agent specification defined block agent[agent-id]{agent-spec},
agent-id unique identifier target agent. target agent specification agent-spec
composed four parts. first part definition target agents finite set
local variables, enclosed block locals{var; . . . var;}. Local variables
intended model internal state target agent. Hence, cannot used
context global elements, accordingly cannot accessed agents.
instance, antecedent consequent commitment cannot include local
variable agent. Local variables defined using global variable syntax.
second part target agent specification definition target agents
goals, defined block goals{goal; . . . goal;}. syntax goal follows:
goal
pa-goal
pm-goal
a-goal
m-goal

::=
::=
::=
::=
::=

pa-goal | pm-goal | a-goal | m-goal
pagoal(satisfaction)
pmgoal(satisfaction)
agoal(precondition, satisfaction, termination)
mgoal(precondition, satisfaction, termination)

Persistent achievement maintenance goals denoted pa-goal pm-goal, respectively. goal types, satisfaction parameters expressions model satisfaction
condition goal, include global local variable comparisons (i.e.,
commitment-state variables allowed conditions). example, persistent
maintenance goal manufacturer keep positive bank balance interacting
operators suppliers modeled following goal:
476

fiProMoca: Probabilistic Modeling Analysis Agents Commitment Protocols

pmgoal(bank-balance == positive);

One-time achievement maintenance goals denoted a-goal m-goal, respectively. goal types, precondition, satisfaction, termination expressions
model pre, satisfaction, termination condition goal. pre termination
conditions goal types include global, local, commitment state variable comparisons. However, satisfaction condition goal types include global
local variable comparisons.
example, manufacturers one-time goal deliver engine payment
made (captured active status commitment c-1) modeled using
following achievement goal.
agoal(c-1-state == active, engine-delivered == done,
engine-delivered == failed engine-delivered == late);

Note delivery engine fails delivered later deadline (i.e.,
delivered == failed delivered == late), one-time goal becomes terminated.
last two parts target agent specification definition target agents
behavior target agents beliefs agents behaviors. target
agents behavior defined block behavior{behavior}. target agents beliefs agents behaviors defined block beliefs{[agent-id]{behavior};
. . . [agent-id]{behavior};}. behavior (either target agents behavior believed
behavior another agent) defined according following syntax:
behavior

::=

cont | stop |
action-label{assign, . . . , assign} -> behavior |
commit{commitment-id} -> behavior |
release{commitment-id} -> behavior |
cancel{commitment-id} -> behavior |
behavior <> behavior |
[expression] behavior |
(probability) behavior . . . (probability) behavior

Let us explain intuitive meaning element behavior syntax.
primitive behaviors cont stop restarts terminates current behavior, respectively.
use action-label{assign; . . . ; assign;} capture agent actions effects
variables. action label action-label used improve readability.
is, label action meaning label used
different sets assignments different places model. effects action
captured assigning new values finite set variables. Actions ProMoca
atomic. Hence, assignments occur result action, done
given order without interruption. syntax assignment assign fallows:
assign ::= var-name = value
477

fiGunay, Liu & Zhang

Beside domain dependent actions (e.g., delivering engine), ProMoca also provides
three meta-actions commit, release, cancel capture corresponding commitment operations alter state commitment (i.e., commitment state variable).
action commit used debtor create commitment, release used creditor release debtor commitment, cancel used debtor cancel
commitment. three, ProMoca provide meta-action
manipulate state commitment directly. Instead, state commitment
captured internally ProMoca according values commitments parameters
(e.g., consequent) define semantics ProMoca.
non-deterministic choice behaviors captured behavior <> behavior. is,
either first second behavior performed agent, decision
non-deterministic. [expression] behavior captures guarded behavior (i.e., if-then rule).
guard condition expression logical expression (as defined before). guard condition
holds, corresponding behavior performed. Otherwise, behavior becomes
blocked condition holds. Note arbitrary number guarded behaviors
combined using non-deterministic choice model complex decision procedures.
case, one behaviors, corresponding guard condition holds, selected
execution non-deterministic manner. Finally, (probability) behavior . . . (probability)
behavior denotes probabilistic choice among possible behaviors. probability
real value sum probabilities equal 1 probabilistic choice. Probabilistic non-deterministic choices main elements ProMoca incorporate
uncertainty modeling analysis processes.
important distinction behavior beliefs blocks use variable
types. Global variables used (both reading assignment) blocks.
However, local variables target agent used behavior block, since
private target agent. Local variables accessible either reading
assignment beliefs block, since block models agents behaviors,
use target agents local variables. Accessibility commitment state variables
(always read-only) depend role corresponding agent commitments.
instance, target agent debtor, creditor, observer commitment,
corresponding state variable queried behavior block. Similarly, another
agent debtor, creditor, observer commitment, part beliefs block
corresponds agents behavior, query state commitment.
Let us present (partial) behavior example manufacturer below,
interpreted follows. commitment manufacturer service engine (i.e.,
instance c-4) becomes active, manufacturer may behave three different ways,
according current situation. manufacturer already necessary parts
service engine (modeled local variable part-availability), manufacturer services
engine time 0.99 probability. small probability (0.01) failure
complete service time, violates c-4. manufacturer
necessary parts service engine, order either first second
supplier. manufacturer believes (as demonstrate later) first supplier mostly
delivers ordered parts time. manufacturer also believes second supplier
delivers ordered parts late almost time. Furthermore, manufacturer believes
second supplier may even completely fail deliver ordered parts. Accordingly,
478

fiProMoca: Probabilistic Modeling Analysis Agents Commitment Protocols

manufacturer prefers work first supplier. However, first supplier
approved aerospace agency particular operator, owns engine,
manufacturer works second supplier. situation captured guard
statements. Note case late delivery ordered parts, timely service
engine affected. is, late delivery occurs, manufacturer services time
0.75 probability. Hence, bigger risk violating c-4. Finally, servicing
engine, availability spare parts next service period determined
non-deterministic choice. is, manufacturer know advance many
spare parts needs, therefore possible result (e.g., running spare parts)
considered.
[c-4-state == active] {
[part-availability == available] {
(0.99) service-on-time{engine-serviced = done} ->
all-parts-consumed{part-availability == unavailable} <> cont
(0.01) service-late{engine-serviced = late} ->
all-parts-consumed{part-availability == unavailable} <> cont
} <>
[part-availability == unavailable supplier-1 == approved] {
[part-delivery == on-time]
(0.99) service-on-time{engine-serviced = done} ->
all-parts-consumed{part-availability == unavailable} <> cont
(0.01) service-late{engine-serviced = late} ->
all-parts-consumed{part-availability == unavailable} <> cont
} <>
[part-delivery == late] {
(0.75) service-on-time{engine-serviced = done} ->
all-parts-consumed{part-availability == unavailable} <> cont
(0.25) service-late{engine-serviced = late} ->
all-parts-consumed{part-availability == unavailable} <> cont
}
} <>
[part-availability == unavailable supplier-1 != approved supplier-2 == approved] {
[part-delivery == late]
(0.75) service-on-time{engine-serviced = done} ->
all-parts-consumed{part-availability == unavailable} <> cont
(0.25) service-late{engine-serviced = late} ->
all-parts-consumed{part-availability == unavailable} <> cont
} <>
[part-delivery == failed]
service-failed{engine-serviced = failed} -> cont
}
}
}

479

fiGunay, Liu & Zhang

Lastly, demonstrate beliefs manufacturer suppliers.
Suppose interaction manufacturer first second supplier
regulated commitments c-5 c-6, respectively. commitments state
manufacturer orders batch spare parts supplier, supplier committed
deliver parts manufacturer. brevity show commitments.
mentioned earlier, manufacturer believes first supplier reliable.
Precisely, first supplier delivers ordered parts time 0.8 probability, late
0.2 probability. manufacturer also believes second supplier unreliable.
Precisely, second supplier delivers order parts late 0.95 probability. Besides,
0.05 probability, second supplier fails altogether deliver ordered parts.
beliefs {
[supplier-1] {
[c-5-state == active] {
(0.8) delivers-on-time{part-delivery = on-time} -> cont
(0.2) delivers-late{part-delivery = late} -> cont
}
};
[supplier-2] {
[c-6-state == active] {
(0.95) delivers-late{part-delivery = late} -> cont
(0.05) fails-to-deliver{part-delivery = failed} -> cont
}
};
}

3.2 Semantics
define ProMocas operational semantics. first define ProMoca model
configuration captures global state ProMoca model.
Definition 1 (ProMoca Model). ProMoca model tuple = (Var , Vinit , C, G,
Bagn |||Bbel1 ||| . . . |||Bbeln ) Var set variables (i.e., composed set global,
local, commitment state, internal variables), Vinit initial valuation variables Var , C commitment protocol (i.e., set commitments), G target
agents goal set. Bagn |||Bbel1 ||| . . . |||Bbeln parallel composition interleaved behaviors target agent (represented Bagn ) n number agents (i.e.,
Bbeli represents ith agents believed behavior).
Definition 2 (Configuration). configuration tuple (V, B), V valuation
variables Var , B behavior.
define operational semantics behavioral element using firing rules,
operate configurations. Below, denotes set (visible) agent actions,
denotes internal (invisible) action. use denote action . write
V |= expression denote logical expression expression evaluates true valuation
480

fiProMoca: Probabilistic Modeling Analysis Agents Commitment Protocols

V . start operational semantics cont, causes current behavior B
continue initial location without making changes valuation V .
case handled invisible action, defined rule [cont].
cont encountered B


(V, cont)
(V, B)

[cont]

Rule [prefix] captures action behavior B modifies values variables
valuation V .



(V, {assign, . . . , assign} -> B)
(update(V, {assign, . . . , assign}, C), B)

[prefix]

readability, use auxiliary update function handle assignment new values
variables modifying configuration. present function Algorithm 1.
Algorithm 1 (and also related algorithms) slightly abuse notation
readability follows. assume assignment assign represented variable
value pair (i.e., (variable, value)). use bracket notation V [variable] access
variable valuation V . internal state (c-id-state) subscription (c-id-subscription)
variables available algorithm commitment identifier c-id. also
omit observer lists commitments, since irrelevant assignments.
Input arguments update function current valuation V , set assignments assignments occur result action , commitment protocol
C. function first updates global local variables V according assignments
(lines 12). Then, commitment c protocol, function updates state c
(i.e., c-id) respect updated values variables necessary follows (lines 3
22). commitment conditional expiration condition commitment holds
updated valuation, commitment expires subscription counter updated auxiliary function update-subscription, present Algorithm 2,
explain detail later (lines 57). Otherwise, antecedent conditional commitment holds updated valuation, commitment becomes active (lines 89). neither
conditions hold, state conditional commitment change,
show Algorithm 1 brevity.
commitment active, necessary consider type (i.e., achievement maintenance) determine next state. termination condition active achievement
commitment holds updated valuation, commitment becomes violated (lines 12
14). Otherwise, consequent commitment holds updated valuation,
commitment becomes fulfilled (lines 1516). neither conditions hold, state
active achievement commitment change. consequent active maintenance commitment hold updated valuation, commitment becomes
violated (lines 1820). Otherwise, termination condition commitment holds
updated valuation, commitment becomes fulfilled (lines 2122). neither
conditions hold, state maintenance commitment change. Finally, update
returns updated valuation (line 23).
Subscription fulfillment status commitment handled auxiliary functions update-subscription fulfillment define Algorithms 2, 3, respectively.
481

fiGunay, Liu & Zhang

Algorithm 1: Function update(V, assignments, C) returns updated valuation V .
input : valuation V , set assignments assignments, commitment protocol C
output: updated valuation V
1
2
3
4
5
6
7
8
9
10
11
12
13
14

foreach (variable, value) assignments
V [variable] value
foreach commitment(c-id, c-type, subs, deb, cre, ant, exp, con, ter)[c-id] c C
V [c-id-state] = conditional
V |= exp
V [c-id-state] expired
V update-subscription(V, c)
else V |= ant
V [c-id-state] active
else V [c-id-state] = active
c-type = achievement
V |= ter
V [c-id-state] violated
V update-subscription(V, c)
else V |= con
V fulfillment(V, c, C)

15
16
17
18
19
20

else c-type = maintenance
V 6|= con
V [c-id-state] violated
V update-subscription(V, c)
else V |= ter
V fulfillment(V, c, C)

21
22

23

return V

commitment reaches terminal state (e.g., fulfilled) internal subscription
counter commitment updated. commitment subscription
(i.e., template commitment enacted once), update effect.
Otherwise, update occurs defined Algorithm 2, takes current valuation V commitment c identifier c-id input arguments. First, internal
subscription counter (i.e., c-id-subscription) commitment increased one (line 1).
Then, incremented subscription counter less equal total subscription period subs (i.e., periods subscription considered yet),
commitment corresponds next period subscription becomes conditional
(lines 2-4). Finally, updated valuation returned. Remember subscription
counter commitment initially set ProMoca 1. Hence, condition
line 2 include equal case. Also note non-subscription commitment
482

fiProMoca: Probabilistic Modeling Analysis Agents Commitment Protocols

Algorithm 2: Function update-subscription(V, c) returns updated valuation V .
input : valuation V , commitment c
output: updated valuation V

4

V [c-id-subscription] V [c-id-subscription] + 1
V [c-id-subscription] subs
s-id-state concatenate (c-id, c-id-subscription)
V [s-id-state] conditional

5

return V

1
2
3

default period limit 1. Hence, condition line 2 always fails non-subscription
commitments result increasing subscription counter one line 1.
Algorithm 3 defines auxiliary fulfillment function, takes current valuation
V , fulfilled commitment c identifier c-id, commitment protocol C
input arguments. function first sets state commitment (i.e., c-id-state)
fulfilled (line 1). Then, updates subscription counter commitment (line 2).
Lastly, fulfilled commitment c compensation another commitment c0
context C, determined auxiliary function compensates,
commitment c0 currently violated, state c0 set compensated (lines 35). Note
that, c subscription, compensates c0 periods c fulfilled (i.e.,
condition subs < V [c-id-subscription] holds).
Algorithm 3: Function fulfillment(V, c, C) updates valuation V respect
fulfillment commitment c.
input : valuation V , commitment c, commitment protocol C
output: updated valuation V

5

V [c-id-state] fulfilled
V update-subscription(V, c)
c0 compensates(c, C)
c0 6= none V [c-id-state] = violated subs < V [c-id-subscription]
V [c-id-state] compensated

6

return V

1
2
3
4

Note that, algorithms encoded trivially set firing rules,
similar ones use define operational semantics ProMoca
elements. However, prefer algorithmic representation readability. practice,
algorithms implemented efficiently using index structures variables
valuation commitments include index variable conditions. However,
prefer explain presented (less efficient intuitive) iterative form
clarity.
continue semantics meta-operations create, release cancel
commitment, shown rules [commit], [release] [cancel], respectively.
use auxiliary updatecommit , updaterelease updatecancel functions handle change
483

fiGunay, Liu & Zhang

valuation corresponding commitments state variable (as assignments).
instance, [commit] fires commitment identifier commitment-id, updatecommit
function assigns value conditional variable commitment-id-state, sets corresponding subscription counter 1, returns updated valuation V .
V |= commitment-id-state == null


(V, commit{commitment-id} -> B)
(updatecommit (V, commitment-id), B)
V |= commitment-id-state == conditional commitment-id-state == active


(V, release{commitment-id} -> B)
(updaterelease (V, commitment-id), B)
V |= commitment-id-state == active


(V, cancel{commitment-id} -> B)
(updatecancel (V, commitment-id), B)

[commit]

[release]

[cancel]

three rules define configuration changes condition rule
hold. instance, [cancel] rule define configuration changes,
commitment canceled active. handle situations define
following three rules, ignore commitment operation change
current configuration, condition rule hold. instance, [!cancel],
commitment active, canceled, cancel operation ignored
commitments current state preserved (i.e., current configuration change).
V |= commitment-id-state ! = null


(V, commit{commitment-id} -> B)
(V, B)
V |= commitment-id-state ! = conditional commitment-id-state ! = active


(V, release{commitment-id} -> B)
(V, B)
V |= commitment-id-state ! = active


(V, cancel{commitment-id} -> B)
(V, B)

[!commit]

[!release]

[!cancel]

Rules [non-1] [non-2] capture semantics non-deterministic choice
behaviors Bi Bj . non-deterministic choice Bi Bj , either Bi
Bj selected non-deterministic manner progressing according rules [non-1]
[non-2], respectively.


[non-1]



[non-2]

(V, Bi <> Bj )
(V, Bi )
(V, Bi <> Bj )
(V, Bj )

Rule [guard] captures semantics guarded behaviors. expression guard
associated behavior B evaluated true according valuation V ,
action occurs model progresses configuration (V 0 , B 0 ). Otherwise,
484

fiProMoca: Probabilistic Modeling Analysis Agents Commitment Protocols

B becomes blocked model progresses another configuration, guard
evaluates true. may happen, interleaving behavior assigns new values
variables, causes model progress new configuration, guard
evaluated true. However, interleaving behavior, current behavior
permanently blocked (i.e., deadlocked).


V |= guard (V, B)
(V 0 , B 0 )


(V, [guard]B)
(V 0 , B 0 )

[guard]

Lastly, define operational semantics interleaving behaviors parallel composition,
denoted |||. Remember ProMoca models target agents
behavior target agents beliefs agents behaviors separate interleaving behaviors. compose behaviors single behavior verify properties
target agents behavior explain Section 4. achieve using rules [int-1]
[int-2]. Intuitively, two interleaving behaviors Bi Bj (e.g., target
agents behavior believed behavior another agent), either Bi Bj executed
independently behavior.


(V, Bi )
(V 0 , Bi0 )


(V, Bi ||| Bj )
(V 0 , Bi0 ||| Bj )

[int-1]



(V, Bj )
(V 0 , Bj0 )


(V, Bi ||| Bj )
(V 0 , Bi ||| Bj0 )

[int-2]

clarify parallel composition two interleaving behaviors, present simple example Figure 2, shows possible executions two interleaving behaviors
Bi = {ia1{vi = 1} -> ia2{vi = 2}} Bj = {ja1{vj = 1} -> ja2{vj = 2}}
respect initial valuation V = ((vi : 0), (vj : 0)) variables vi vj. Note
omit stop statements end behaviors brevity. box Figure 2
corresponds composed configuration first line valuation V
rest interleaving behaviors Bi Bj . Edges boxes show transitions
configurations according actions taken behaviors, shown edge labels.
Note action taken, removed corresponding behavior indicate
completion. instance, two possible actions taken initial
configuration, namely ia1 Bi ja1 Bj . ia1 taken, value vi set 1,
Bi becomes {ia2{vi = 2}} new configuration reach result ia1.
final configuration, valuation V ((vi : 2), (vj : 2)), behaviors Bi
Bj empty, hence stop (i.e., possible actions taken).
firing rules define behavior progresses one configuration another
ProMoca model. define execution ProMoca model respect
rules Markov Decision Process (MDP) (Bellman, 1957), expressive enough
capture probabilistic non-deterministic interleaving behaviors.
Definition 3 (Markov Decision Process). Markov decision process tuple =
(S, Act, P, init , AP, L)
finite set states,
485

fiGunay, Liu & Zhang

((vi : 0), (vj : 0)),
(Bi = {ia1{vi = 1} -> ia2{vi = 2}}
|||
Bj = {ja1{vj = 1} -> ja2{vj = 2}})
ia1{vi = 1}

ja1{vj = 1}

((vi : 1), (vj : 0)),
(Bi = {ia2{vi = 2}}
|||
Bj = {ja1{vj = 1} -> ja2{vj = 2}})
ia2{vi = 2}

((vi : 0), (vj : 1)),
(Bi = {ia1{vi = 1} -> ia2{vi = 2}}
|||
Bj = {ja2{vj = 2}})
ja1{vj = 1}

((vi : 2), (vj : 0)),
(Bi = {}
|||
Bj = {ja1{vj = 1} -> ja2{vj = 2}})
ja1{vj = 1}

ia1{vi = 1}

((vi : 1), (vj : 1)),
(Bi = {ia2{vi = 2}}
|||
Bj = {ja2{vj = 2}})
ia2{vi = 2}

ja2{vj = 2}
((vi : 0), (vj : 2)),
(Bi = {ia1{vi = 1} -> ia2{vi = 2}}
|||
Bj = {})

ja2{vj = 2}

ia1{vi = 1}

((vi : 2), (vj : 1)),
((vi : 2), (vj : 2)),
((vi : 1), (vj : 2)),
(Bi = {}
(Bi = {}
ja2{vj = 2}
ia2{vi = 2} (Bi = ia2{vi = 2}}
|||
|||
|||
Bj = {ja2{vj = 2}})
Bj = {})
Bj = {})

Figure 2: Possible executions interleaving behaviors Bi Bj .
Act finite set actions,
P: Act 7 [0, 1] transition probability function every state
every action Act:
X
P(s, , s0 ) {0, 1}
s0

init : 7 1 initial distribution

P

sS init (s)

= 1,

AP finite set atomic propositions,
L : 7 2AP labeling function.
Without loss generality consider finite MDPs (i.e., S, Act AP finite
sets), terminal states MDP. Precisely, Act(s) denotes set
enabled actions s, sP case Act(s) 6= . action
enabled state s0 P(s, , s0 ) = 1. state s0 -successor
another state s, P(s, , s0 ) > 0. MDP executes follows. initial state sinit
selected according stochastic experiment initial distribution init . state s,
first non-deterministic choice made enabled actions. Assume action
Act(s) selected. Then, -successor selected randomly according
distribution P(s, , ).
486

fiProMoca: Probabilistic Modeling Analysis Agents Commitment Protocols

ready define two necessary rules systematically create MDP
ProMoca model using operational semantics. Rule [non-prob] captures non
probabilistic cases. is, non-probabilistic firing rule (V, B)
(V 0 , B 0 ),
performed configuration (V, B), result single distribution maps
configuration (V 0 , B 0 ) 1.


(V, B)
(V 0 , B 0 ) firing rule


(V, B)
((V 0 , B 0 )) = 1

[non-prob]

Rule [prob] handles probabilistic choices, resulting distribution associates
probability di (V, Bi ) i. Note V remains unmodified transition.


(V, (p1 )B1 . . . (pn )Bn )
((V, Bi )) = pi

[prob]

Proposition 1. ProMoca model = (Var , Vinit , C, G, Bagn |||Bbel1 ||| . . . |||Bbeln )
exists corresponding MDP = (S, Act, P, init , AP, L).
Proof: given ProMoca model O, following procedure constructs corresponding MDP M. Below, use Dom(var) denote domain variable var Var
B denote Bagn |||Bbel1 ||| . . . |||Bbeln .
1. Creation AP : every value val Dom(var) every variable var Var add
new proposition ap AP . instance, variable engine-status element
V ar domain Dom(engine-status) = {unknown, operational, malfunction,
maintenance}, add propositions engine-status-unknown, engine-status-operational,
engine-status-malfunction, engine-status-maintenance AP , correspond
values unknown, operational, malfunction, maintenance engine-status,
respectively.
2. Creation L: Add state every combination propositions
AP omitting combinations include mutually exclusive propositions. set
propositions mutually exclusive (i.e., cannot hold state),
created domain variable Step 1. instance, four
propositions created domain engine-status mutually exclusive.
Update labeling L created state using corresponding combination
propositions. instance, considering propositions first step, create four states s0 , s1 , s2 , s3 , set labeling function follows: L(s0 ) =
{engine-status-unknown}, L(s1 ) = {engine-status-operational }, L(s2 ) = {enginestatus-malfunction}, L(s3 ) = {engine-status-maintenance}. Note
one-to-one correspondence labels states valuations behaviors
configurations. result, also direct correspondence states
configurations behavior.
3. Creation init : Set init probability state,
labeling corresponds valuation Vinit , 1, probabilities
states 0.
487

fiGunay, Liu & Zhang

4. Creation Act: every assignment behavior B add corresponding action
Act. Besides, every commitment c C add set meta-actions Act,
correspond state changes c.
5. Creation P: First, state determine set enabled actions
E
ActE
Act. action act enabled state (i.e., act Acts ) one
following conditions hold:
act corresponds assignment occurs configuration conf ,
valuation V conf corresponds labeling state
(i.e., L(s)). Note correspondence state configuration
already described Step 2, correspondence action
assignment already described Step 3. Intuitively, condition captures
[prefix] rule. is, next behavior element apply configuration
assignment, action corresponds assignment enabled
state corresponds configuration.
act corresponds meta-action change state commitment,
act performed (according algorithms rules define
semantics commitments) configuration conf , corresponds
labeling state (i.e., L(s)). condition captures state
changes commitments.
Then, state s, ActE
includes one actions change state(s)
commitment(s), single transition probability 1 set destination
state labels updated commitment states according algorithms rules
define semantics commitments. rest actions ignored,
ActE
includes one actions change state(s) commitment(s).
words, commitment states updated instantaneously needed,
agent action occurs. Otherwise, actions update
Pcommitment
i=N
states, transition action act ActE

probability
p
/
act

i=0 pi set
destination states labeled according correspondences
actions assignments, pi probability value action acti
defined configuration conf corresponds state s, N
total number actions ActE
.
Note procedure describe proof Proposition 1 creates finite
MDP, since number variables (and domains), number assignments
ProMoca model finite. Also note actual computational complexity
procedure occurs due last step, determine transition probabilities
MDP, done linear time respect number generated states
Step 2 actions Step 4. However, clear number states MDP
exponential number variables domains corresponding ProMoca
model (see Step 1). situation commonly known state space explosion problem
constitutes theoretical lower bound probabilistic model checking (Baier &
Katoen, 2008).
488

fiProMoca: Probabilistic Modeling Analysis Agents Commitment Protocols

3.3 Formal Properties
section formalize compliance goal satisfaction properties using PLTL
(Baier & Katoen, 2008), probabilistic variant Linear Temporal Logic (LTL)
(Pnueli, 1977). LTL formula defined set atomic propositions AP using
temporal operators globally (G), eventually (F), (U). Satisfaction LTL
formula defined respect infinite sequence states = s0 , s1 , . . . follows.
G holds si , holds future states sj j.
F holds si , holds least one future state sj j.
U 0 holds si , holds future states sj 0 holds future sk ,
j < k.
PLTL extends LTL probabilistic operator Px (), x R
LTL formula. Intuitively, Px () holds MDP model, probability satisfying
greater equal x. define computation probability detail Section 4.
Sections 3.3.1 3.3.2, use , , PLTL formulae logical conjunction,
disjunction, implication, negation, respectively.
3.3.1 Compliance
Compliance target agents behavior commitment protocol first property
particularly aim verify ProMoca. Basically, target agent fulfills
active commitments commitment protocol, target agents behavior
complies commitment protocol. However, due interdependence among agents
uncertainty agents behaviors, usually possible determine
agents compliance exactly. instance, aerospace example, manufacturers
compliance depends behaviors suppliers. Hence, define compliance
target agents behavior commitment protocol relaxed manner respect
threshold C defines minimal acceptable ratio fulfillment target agents
active commitments. Precisely, commitment target agent, commitment
becomes active, commitments fulfillment probability greater equal
threshold C . Below, B Bagn |||Bbel1 ||| . . . |||Bbeln .
Definition 4. Given ProMoca model (V ar, Vinit , C, G, B) corresponding MDP
(S, Act, P, init , AP, L), target agents behavior Bagn complies commitment
protocol C respect threshold C , following PLTL formula holds:
commitment(c-id, debtor, . . . ) C debtor = agn :
PC (G(c-id-state-active F(c-id-state-fulfilled c-id-state-released)))
Intuitively, every commitment protocol, target agent debtor,
commitment becomes active given state MDP, commitments
probability finally becoming fulfilled released future state greater
489

fiGunay, Liu & Zhang

equal threshold C . Note Definition 4, omit commitment parameters (i.e.,
instead use . . .) irrelevant compliance.
Even tough threshold C relaxes requirements compliance, Definition 4
still strict notion compliance domains, since requires fulfillment every
active commitment, ignores compensations case violation. However,
discussed Section 2, compensation useful widely used mechanism many
domains. Accordingly, define weak compliance, considers compensation, follows:
Definition 5. Given ProMoca model (V ar, Vinit , C, G, B) corresponding MDP
(S, Act, P, init , AP, L), target agents behavior Bagn weakly complies commitment protocol C respect threshold C , following PLTL formula holds:

commitment(c-id, debtor, . . . ) C debtor = agn :
PC (G(c-id-state-active
F(c-id-state-fulfilled c-id-state-released c-id-state-compensated)))
Intuitively, every commitment protocol, target agent debtor,
commitment becomes active given state MDP, commitments
probability finally becoming fulfilled, released, compensated future state
greater equal threshold C .
Let us explain compliance satisfied failed example. Since computation probabilities MDP rather involved adequate manually,
use simplified case aerospace aftercare example, manufacturer
service engine supplier timely delivers necessary parts maintenance.
Suppose manufacturer believes supplier delivers parts time
probability 0.9. Ignoring details, compliance threshold C set 0.8,
verification process concludes manufacturer complies protocol, since
probability timely servicing engine threshold. hand,
compliance threshold C set 0.95, verification process concludes
manufacturer fails comply protocol, since probability timely servicing
engine threshold.
3.3.2 Goal Satisfaction
second property aim analyze ProMoca goal satisfaction, defines
whether target agent satisfy goals enacting commitment protocol. However,
case compliance, usually possible exactly determine goal satisfaction
due interdependence among agents uncertainty multiagent system. Hence,
before, define threshold defines acceptable ratio satisfaction goals
target agent.
Definition 6. Given ProMoca model (V ar, Vinit , C, G, B) corresponding MDP
(S, Act, P, init , AP, L), target agent satisfy goals G enacting commitment protocol C respect threshold , goal G, PLTL formula
corresponds goals type holds below:
490

fiProMoca: Probabilistic Modeling Analysis Agents Commitment Protocols

persistent achievement goal satisfied, probability achieving
satisfaction condition sat infinitely often greater equal .
pagoal(sat) G : PS GF(sat)

[pa-sat]

persistent maintenance goal satisfied, probability maintaining
satisfaction condition sat every reachable state greater equal .
pmgoal(sat) G : PS G(sat)

[pm-sat]

one-time achievement goal precondition pre holds, satisfied
probability reaching termination condition ter satisfaction condition sat achieved, greater equal . Intuitively, goal
terminated achieved.
agoal(pre, sat, ter) G : PS G(pre ( ter U sat))

[a-sat]

one-time maintenance goal precondition pre holds, satisfied
probability maintaining satisfaction condition sat reaching termination
condition ter greater equal . Intuitively, satisfaction condition
maintained goals termination.
mgoal(pre, sat, ter) G : PS G(pre (sat U ter))

[m-sat]

Let us explain goal satisfaction satisfied failed simplified case
NetBill example, merchant persistent achievement goal receive
payments customers. Suppose merchant believes customer
purchases certain good every day probability 0.5. Ignoring details,
goal satisfaction threshold set 0.25, verification process concludes
merchant satisfies goal, since probability receiving payment daily basis
higher threshold. hand, goal satisfaction threshold C set
0.75, verification process concludes merchant fails satisfy goal, since
probability receiving payment daily basis lower threshold.
3.4 Remarks PROMOCA Syntax Semantics
designing ProMocas modeling language influenced process algebra
communicating sequential processes (Hoare, 1978), successfully used modeling
various concurrent systems. However, line objective verifying properties
agents behavior context commitment protocol uncertainty, designed
novel language model commitment protocols agents, taking account
goals, beliefs, behaviors. One main motivations designing ProMoca
ease modeling commitment protocols agents providing intuitive language
elements model them, differs ProMoca existing analysis tools. discuss
ProMocas modeling related benefits comparing existing tools detail
Section 7. rest section discuss important aspects ProMocas
modeling language.
491

fiGunay, Liu & Zhang

ProMoca model involves three types variables capture global, local
internal (commitment subscription) state. distinction among variable types
used type checking syntactic level restrict use different variable types
certain language elements (e.g., commitments include global variables since
public, target agents beliefs agents behaviors cannot include
local variables since private, etc.). hand, semantic model
ProMoca, variables interpreted global variables. straightforward see
type checking variables syntactic level sufficient correctly define
verify PLTL property, including compliance goal satisfaction. Hence, safe
consider variables global variables semantic level long checked
syntactic level.
discuss ProMoca semantics, states commitment determined
ProMoca according evaluation commitments conditions (e.g., consequent).
Hence, ProMoca provide explicit meta-actions transitions (e.g., fulfillment). exceptions commit, release, cancel. Initiation commitment
handled commit done previous work. Furthermore, explicit release
cancellation provides flexibility modeling. instance, many protocols involve
commitments regulate exceptional situations. commitments normally become active unless corresponding exception occurs. Hence, stay conditional state
even interaction involved parties completed. situation,
creditors commitments release debtors conditional commitments. Cancellation used debtor immediately terminate commitment (by
violating it) without waiting occurrence commitments termination condition.
useful debtor realizes cannot fulfill commitment. canceling
commitment, debtor gives time creditor recover undesirable situation
occurs due violation commitment.
final remark probabilistic modeling, note probability computations
ProMoca model may become rather complex. examples demonstrate, many
situations behaviors belief may arbitrary nesting long sequences actions,
involve non-deterministic probabilistic choices. Furthermore, parallel composition interleaving behaviors introduces additional complexity. result scalability
model checking may suffer verifying compliance goal satisfaction large models.
common problem probabilistic model checking. address issue detail
next two sections, show ProMoca verify compliance goal satisfaction
many realistic situations, although affected scalability issues.

4. Verification
section present overall verification process ProMoca, depicted
Figure 3. inputs verification process ProMoca model, type
property (i.e., compliance goal satisfaction) aimed verified, real
value corresponds threshold property (i.e., C ). First, create
MDP input ProMoca model according operational semantics
ProMoca Section 3. parallel, extract PLTL property (i.e., property
type relevant propositions ProMoca model), verify, according
492

fiProMoca: Probabilistic Modeling Analysis Agents Commitment Protocols

input
PROMOCA model, property type, threshold
extract PLTL property

create corresponding MDP

PLTL formula
MDP
create corresponding Rabin automaton
Rabin automaton R

create product MDP R
Product MDP R
apply probabilistic model checking algorithm



property fails

property holds

>

Figure 3: overview ProMocas verification process.

input. Then, create (deterministic) Rabin automaton R using standard
translation PLTL formula Rabin automaton (Baier & Katoen, 2008).
MDP Rabin automaton R, create product R,
also MDP (Baier & Katoen, 2008). last step, use probabilistic model
checking algorithm present Algorithm 4, R compute satisfaction
probability M. result computation greater equal input
threshold value, verification process returns > indicate property satisfied.
hand, computed value threshold, verification process
returns indicate property satisfied.
property satisfied non-probabilistic model checking, trace (i.e., counterexample) generated explain failure occurs result model checking.
However, probabilistic model checking clear definition counterexample since models probabilistic, properties defined respect thresholds.
Although, recent research probabilistic model checking addressed issue several approaches proposed (Andres, DArgenio, & Rossum, 2009; Han, Katoen, &
Berteun, 2009; Schmalz, Varacca, & Volzer, 2009), ProMoca currently provide
functionality generate counterexample.
ProMoca uses reachability checking algorithm developed previous work (Gunay et al., 2015). present algorithm Algorithm 4 completeness.
inputs Algorithm 4 MDP MR = (S, Act, P, init , AP, L), product
MDP Rabin automaton R, extracted input ProMoca
model, S, set accept states R input. Algorithm 4 returns P R (T ),
minimal probability reaching set projected accept states product
MDP. Algorithm 4, use auxiliary function P re(s) returns pre-states
state MDP. Formally, P re(s) = {s0 | P(s, , s0 ) > 0}. use ps record
493

fiGunay, Liu & Zhang

Algorithm 4: Computation reachability probabilities target states.
input : R = (S, Act, P, init , AP, L),
output: ps0
1
2
3
4
5
6
7
8
9
10
11
12

let cur pre ;
foreach cur
let ps 1;
cur 6=
foreach cur
cur cur \{s};
foreach s0 P re(s)
pre pre {s0 };
foreach (s0 , t, ) P r
let pn = 0.0;
foreach s00 (s00 ) > 0
pn pn + (s00 ) ps00 ;
ps0 in(ps0 , pn );

13
14
15
16

cur pre ;
pre ;
return ps0 ;

probability reaching s. Due existence non-determinism MDP,
result reachability checking range instead single value. Algorithm 4 adopt
cautious approach compute minimal probability reaching .
main idea reachability checking start target states proceed backwards step step updating reachability probabilities MDP states. Accordingly,
first 0 assigned cur (Line 1), represents current states iterative
process, probabilities states set 1 (Lines 2-3). Then, state
removed cur (Lines 5-6) pre-state s0 (Line 7) probabilities
updated follows: enabled transition s0 distribution , variable pn
created (Line 9-10) record probability reaching 0 s0 via . Afterwards,
sum (s00 ) ps00 s00 satisfying (s00 ) > 0 assigned pn , i.e., pn sum
transition probabilities distribution times corresponding successor states probability 0 (Lines 11-12). keep minimal probability, ps0 set minimum value
ps0 pn using function (Line 13). states cur considered, cur
set pre-states (Line 14). loop Line 4 terminates pre-states
left (i.e., minimal probability s0 computed stored ps0 ). Finally, ps0
returned probability reaching s0 (Line 16).

5. Evaluation
implement ProMoca framework PAT (Process Analysis Toolkit) (Sun, Liu, Dong,
& Pang, 2009), state-of-the-art extendable model checking framework pro494

fiProMoca: Probabilistic Modeling Analysis Agents Commitment Protocols

vides various probabilistic model checking techniques PLTL model checking
reachability checking. evaluate efficiency scalability ProMoca, conducted
set computational experiments. experiments compared ProMocas performance PRISM (Kwiatkowska, Norman, & Parker, 2011), well-known
probabilistic model checker. used following four examples experiments:
AeroBase: example use aerospace aftercare case. However, assume
manufacturer always sufficient supply spare parts. Hence,
consider interactions manufacturer suppliers. example involves commitment model purchase engine commitment model
overall maintenance agreement. commitments also compensating commitments. Hence, four commitments model base terms
agreement. Besides, whole duration agreement, two commitments month model servicing responsibility manufacturer
(e.g., twelve month agreement 24 commitments). consider
scenario manufacturers perspective. beliefs manufacturer involve
probability engine failure probability repairing failed engine on-time.
AeroFull: example, use aerospace aftercare case, assume
manufacturer always sufficient supply spare parts. Hence, consider
new commitment month agreement model provision supplies
suppliers (e.g., 36 commitments twelve month agreement). Since,
manufacturer interacts suppliers, beliefs manufacturer involve
probability successfully receiving spare parts suppliers.
NetBill: example model well-known NetBill protocol (Sirbu & Tygar, 1995). NetBill provides secure protocol transactions two parties
(e.g., merchant customer) online environments. standard protocol
widely used commitment literature evaluation. involves three
commitments model offer, payment, delivery phases transaction.
experiments, consider arbitrary number transactions merchant
set customers merchants perspective. merchants beliefs involve
probability customers acceptance merchants offers.
AGFIL: example models real world car insurance claim processing case (Desai
et al., 2009). AGF Irish Life Holdings (AGFIL), subsidiary Allianz, insurance
company Ireland underwrites car insurance policies. AGFIL cooperates
call center consulting firm process policy holders claims. policy holder
contacts call center make claim. call center forwards claim AGFIL.
Then, AGFIL requests investigation claim consultant decide
claims validity. consultant provides report inform AGFIL
results investigation. Using investigation report, AGFIL decides whether
pay claimed repair cost. example includes three commitments model
interactions AGFIL three stakeholders, namely, policy holder,
call center, consultant. experiments, consider arbitrary number
claims set policy holders verify properties AGFILs behavior.
Beliefs AGFIL involve probability claim validity.
495

fiGunay, Liu & Zhang

run experiments PC equipped Intel i7 3.0 GHz processor 8GB
RAM, running 64-bit Windows 8 operating system. conducted experiments
verify compliance goal satisfaction properties. However, experiments,
observed similar results properties. Hence, brevity, report results
compliance propertys verification. Table 1 report execution times (in
seconds) ProMoca PRISM verifying compliance properties described
examples. model checking process takes 1200 seconds, report timeout
(T/O). case, reported average execution time thirty runs eliminate
spike execution times may occur due use resources processes
system. report variance execution times since observed negligible values.
evaluate ProMocas scalability respect different complexities examples, use control parameter example determines size corresponding ProMoca model. AeroBase AeroFull examples parameter
number months engine manufacturer committed service engine,
represented mon Table 1. NetBill example control parameter number
customers merchant interacts, represented cus Table 1. AGFIL
example control parameter number claims made policy holders,
represented cla Table 1.
discussing results Table 1, let us explain characteristics
example models described parameters affect them. aerospace examples,
outcome commitment models service agreement particular month,
depends outcomes previous months commitments. is, manufacturer
fails service engine previous month, higher risk engine failure
current month, may cause manufacturer violate commitment keep
engine operational. modeled manufacturers beliefs. Accordingly,
dependencies, models aerospace examples become substantially
complex duration service agreement (i.e., number months mon) increases.
Furthermore, AeroFull example considers also behaviors suppliers part
manufacturers beliefs, increases complexity corresponding models
even further. Hence, examples capture complex realistic situations.
models NetBill AGFIL examples relatively simpler aerospace
examples. use situation evaluate ProMoca cases one
commitment protocols composed complex protocol. two
possible compositions, namely sequential parallel. used NetBill example examine
parallel composition commitment protocols. end, increase number
customers merchant interacts parallel 1 10. is, 10 customers,
merchant enacts 10 instances NetBill protocol parallel. Parallel composition causes
models size grow exponentially. Hence, significant impact model complexity.
used AGFIL example examine sequential composition independent protocols.
end, increase number customer claims 10 100. claim processed
sequentially one one (i.e., first come first served) AGFIL. Impact independent
sequential protocols model complexity substantially less parallel composition
protocols, since protocol instance verified independently. Therefore, model size
growth linear number claims. Note Table 1, first reported execution
time AeroBase example mon = 6. mon less 6 ProMoca
496

fiProMoca: Probabilistic Modeling Analysis Agents Commitment Protocols

AeroBase

AeroFull

NetBill

AGFIL

mon ProMoca PRISM mon ProMoca PRISM cus ProMoca PRISM cla ProMoca PRISM

6
7
8
9
10
11
12

0.42
1.33
3.76
9.81
27.86
84.49
242.37

1.32
7.35
33.68
175.81
T/O
T/O
T/O

3
4
5
6
7
8
9

0.03
0.16
0.75
3.62
17.01
85.56
365.82

0.10
0.27
3.80
27.68
591.36
T/O
T/O

4
5
6
7
8
9
10

0.01
0.01
0.02
0.04
0.09
0.15
0.31

0.07
0.12
0.18
0.38
1.25
4.68
32.23

40
50
60
70
80
90
100

0.024
0.030
0.041
0.051
0.063
0.072
0.087

2.822
4.197
5.431
6.843
8.396
9.841
11.384

Table 1: Execution times ProMoca PRISM verify compliance target agent
AeroBase, AeroFull, NetBill, AGFIL examples.

PRISM verify compliance almost instantaneously milliseconds. Similarly,
report results AeroFull, NetBill, AGFIL examples control parameters
starting mon = 3, cus = 4 cla = 40, respectively.
Table 1 indicates two main results. First, ProMoca clearly outperforms PRISM
terms execution time verifying agents compliance commitments
uncertainty. main reason consideration commitments first-class objects syntax semantics ProMoca. Accordingly, ProMoca takes advantage
dedicated representation, uses several model checking techniques,
developed particularly commitment protocols, reducing model size improve efficiency model checking. instance, ProMoca uses specific partial order reduction
technique exploits dependencies among commitments reduce size MDP
models state space (Gunay et al., 2015). Effects reduction technique easy see
especially NetBill example, large number parallel independent
commitments NetBill protocol instance different customer. ProMoca effectively uses dedicated partial order reduction technique detect independence
commitments, reduces model size, provides clear advantage NetBill example. conclusion, results show development dedicated model checking tools
ProMoca necessary efficiently verifying agents behavior respect
commitment protocols taking uncertainty account.
second main result usability ProMoca practical cases. NetBill example
ProMoca verifies compliance milliseconds ten protocols executed parallel.
Similarly, AGFIL example, ProMoca verifies case, 100 claims considered,
almost immediately. AeroBase example, ProMoca verifies compliance even
whole 12 month agreement within reasonable time. complete aerospace scenario,
ProMoca verifies nine month agreement successfully. Note given sufficient time
resources ProMoca also verify whole 12 month agreement. However, model
involves large number dependent commitments, complex behaviors beliefs,
results show, ProMoca suffers exponentially growing execution times,
result rapidly growing model size situations. well known issue
probabilistic model checking, unavoidable (Clarke, Grumberg, & Peled, 1999; Baier
497

fiGunay, Liu & Zhang

& Katoen, 2008). Nevertheless, comparative results PRISM show ProMoca
significantly efficient general purpose probabilistic model checkers verifying
compliance goal satisfaction properties agent commitment protocol.

6. Related Work
section provide non-exhaustive survey related research. start
previous work, study various general properties commitment protocols (i.e., independent behaviors enacting agents), verification. Yolum (2007) developed
framework verify effectiveness, consistency, recovery, fault-tolerance properties
commitment protocols. commitment protocol effective, deadlock-free. consistent, involve conflicting propositions commitment conditions. Finally,
least one role commitment protocol capable taking certain recovery action
case failure, commitment protocol recoverable. Besides, role capable recovering commitment protocol, fault-tolerant. addition defining
properties, Yolum also provides set algorithms verification, based
analyzing states arbitrary runs commitment protocols. Desai et al. (2007a) also
study deadlock-free live commitment protocols. develop several models commitment protocols PROMELA language SPIN model checker (Holzmann, 2004),
define deadlock-freeness liveness properties LTL. Later, Telang Singh (2012) use
NuSMV model checker Computation Tree Logic (CTL) verify correctness business
patterns modeled commitment protocols. Gerard Singh (2013) introduce
approach specify commitment protocols refinements guarded messages.
implement approach using MCMAS model checker.
Montali, Calvanese, De Giacomo (2014) develop data-aware framework using
first-order formalism study impact data available agents, commitments
evolution. also show rich set temporal properties -calculus verified
framework. El-Menshawy et al. (2013) develop ACTLC , extension
CTL, introducing set operators model semantics active commitments.
proposed semantics commitment operators influenced previous proposal
Singh (2008). paper shows proposed logic reduced another logic
GCTL*, verified CWB-NC model checker (Bhat, Cleaveland, & Groce,
2001). Later, El Kholy et al. (2014) propose another extension CTL, called
CTLCC , capture lifecycle conditional commitments. also extend standard
symbolic model checking algorithm CTL line proposal. Sultan, Bentahar,
Wan, Al-Saqqar (2014) propose PCTLC, extends probabilistic CTL, verify
commitment protocols. PCTLC includes social operators represent active commitments
fulfillment. proposed model checking technique consists set reduction
rules reduce PCTLC model checking problem PCTL model checking,
implemented PRISM model checker.
proposal differs studies several points. Firstly, none studies
consider development modeling language ProMoca. either use modeling languages general purpose model checkers abstract formalism modeling.
Secondly, studies consider behaviors agents, since aim verify general
properties commitment protocols. Finally, probabilistic models considered
498

fiProMoca: Probabilistic Modeling Analysis Agents Commitment Protocols

previous work. exception work Sultan et al. (2014), uses probabilistic variant CTL. However, Sultan et al. consider active commitments. Besides,
due use CTL, consider different model checking algorithm use
ProMoca.
recent work aim analyze commitment protocol agents point view.
Objectives studies closer objective ProMoca. Marengo et al. (2011)
discuss agents control events commitment protocols. Basically, agent control
event, agent initiate event, another agent capable
initiate event committed so. also discuss notion safety. commitment
safe debtor, debtor controls antecedent avoid situations
commitment becomes active, debtor controls consequent therefore
able fulfill commitment becomes active. Marengo et al. develop REGULA
framework formalize control safety properties, also provides reasoning rules
evaluate systems properties. However, develop practical reasoner
also address uncertainty.
Gunay Yolum (2013) study feasibility commitment protocol agent, considering time constraints resources requirements satisfied agent
fulfill commitments. commitment protocol feasible agent, agent owns
sufficient resources, agent creditor set commitments provide
agent resources fulfill commitments time. They, model verification feasibility constraint satisfaction problem. Gunay Yolum discuss potential behaviors
agents describe unexpected behaviors (e.g., violations commitments) may
handled. However, consideration behaviors address probabilistic models
requires manual configuration framework. Kafal, Gunay, Yolum (2014) develop GOSU framework provides reasoning mechanism determine goal support
commitment protocol, similar goal satisfaction property. model goal
support reachability property use reactive event calculus reasoning (Chesani
et al., 2013). approach considers achievement goals, avoid uncertainty
assuming agents always honor commitments.
Torroni colleagues develop monitoring framework commitments using SCIFF
abductive logic programming proof-procedure (Alberti, Chesani, Gavanelli, Lamma, Mello,
& Torroni, 2008; Chesani et al., 2013). main motivation develop formal
operational framework efficiently monitors commitments verifies compliance
agents actions protocols enact. Since main interest framework
run-time monitoring, Torroni colleagues pay special attention commitments time
constraints. Although constraints studied also researchers, Torroni
colleagues provide concrete operational framework handle constraints
run-time. purpose utilize event driven implementation event calculus
called reactive event calculus, based maximum validity interval concept
cached event calculus introduced Chittaro Montanari (1996). Use reactive
event calculus eliminates necessity backward reasoning event occurrence
accordingly possible reasoning efficiently run-time. monitoring framework
ProMoca complementary other. ProMoca handles design-time
issues, framework addresses run-time monitoring.
499

fiGunay, Liu & Zhang

Compliance addressed also context norms (e.g., prohibitions). Vasconcelos (2005) develops declarative approach analyze electronic institutions determine
whether agents commit fulfill norms institutions. Aldewereld, Vazquez-Salceda,
Dignum, Meyer (2006) develop framework verify norm compliance agent behavior templates, call protocols. consider sequential protocols
define norm compliance using LTL. semi-automated theorem-proving approach used
verification instead model checking. Craven Sergot (2008) develop nC+
extension action language C+ (Giunchiglia, Lee, Lifschitz, McCain, & Turner, 2004).
nC+ introduces two new forms rules, namely state action permission laws, representing normative aspects multiagent systems. Semantics language defined
respect colored labeled transition systems, represent desired undesired
states, also transition modeled multiagent system. associating subset transitions particular agents actions, verify compliance properties
agent behaviors. nC+ provides rich language model multiagent systems. However,
Craven Sergot consider uncertainty accordingly provide probabilistic modeling reasoning. Besides, norms defined respect lifecycle
commitments. Instead, norms considered (if-then) rules. Furthermore,
represent relations different norms explicitly do, instance
compensation. interesting future direction investigate two formalism
combined develop expressive modeling analysis environment.
terms model checking, relevant work ProMoca MCMAS,
state-of-the-art model checker dedicated verification multiagent systems (Lomuscio, Qu, & Raimondi, 2009). MCMAS uses Interpreted Systems Programming Language
(ISPL) modeling, based interpreted systems semantics (Fagin, Halpern,
Moses, & Vardi, 2003). ISPL, multiagent system modeled composition set
agents environment. agent defined set internal states using set
private variables, protocol, models decision making mechanism
agent. Agents interact publicly observable actions. Local states agents evolve
according evolution function, uses joint actions agents. MCMAS supports
verification agent-oriented logics, Alternating-time Temporal Logic (Alur, Henzinger, & Kupferman, 2002) epistemic operators (Fagin et al., 2003), using Ordered
Binary Decision Diagrams (Bryant, 1986) symbolic model checking techniques.
several differences MCMAS ProMoca. MCMAS general model
checker types multiagent systems, ProMoca focuses verifying agent behaviors
commitment protocols. Accordingly, ProMoca provides dedicated language elements
defining commitment protocols. Moreover, ProMoca aims verify agents behavior
taking uncertainty agents beliefs account. achieve this, ProMoca provides
probabilistic modeling reasoning capabilities agent beliefs. ProMoca use
interpreted systems semantics, since aim verify epistemic logic specifications.
Finally, ProMoca uses automata based approach instead symbolic model checking,
appropriate verifying properties.
recent years, commitments used model various practical situations.
Desai, Chopra, Arrott, Specht, Singh (2007b) provide commitment-based solution
formalizing foreign exchange market protocols. show rigorous specification
verification protocols via commitments solve many issues emerge existing
500

fiProMoca: Probabilistic Modeling Analysis Agents Commitment Protocols

systems due informal business semantics. Singh, Chopra, Desai (2009) propose
commitment-based service oriented architecture, replaces invocation-based service
objects engagement-based autonomous business services. set transaction patterns
commitments proposed, reflect business requirements various common
business transactions, provide basic building blocks develop complex interactions.
Benefits approach flexible enactment transactions, ease specification
composition business processes. Kafal, Gunay, Yolum (2012, 2013) develop
method using commitments capture violation privacy policies social networks.
model privacy policies parties social networks using commitments,
employ model checking policies capture violations. proposed approach
capture privacy breaches cannot detected traditional systems. Furthermore,
prediction tool also developed utilizes Semantic Web technologies capture potential privacy breaches may occur future due evolution social network
relations. Telang, Kalia and, Singh (2012, 2015) conducted experimental evaluation
commitment-based Comma methodology, show Comma outperforms traditional HL7 Messaging Standard healthcare process modeling. Chopra Singh (2016b)
introduce Interaction-Oriented Software Engineering commitment-based paradigm
capture social aspects sociotechnical system emphasizing openness, autonomy, accountability. Chopra Singh (2016a) also develop Custard framework, provides
relational schema queries commitments lifecycle, build abstraction
layer underlying information stores databases.

7. Discussion
paper presented ProMoca framework modeling analyzing agent behaviors commitment protocols taking uncertainty account. main motivation
developing ProMoca analyze target agents behavioral properties enacting
commitment protocol respect goals, beliefs agents uncertain
behaviors. recent years, commitments applied solve practical challenges
many domains e-commerce, sociotechnical systems, privacy, security, healthcare. Modeling verification essential aspects development process
practical systems, mainly ensure correctness effectiveness systems. ProMoca
provides novel analysis tool handle two key aspects development providing
expressive modeling language efficient model checking algorithm. modeling
language ProMoca expressive enough model practical situations demonstrate examples. fact, ProMoca provides expressive power needed
previous work commitments. model checking algorithm ProMoca
efficient handle complex situations empirical results show.
However, ProMoca also certain limitations. terms modeling, ProMoca
extended model wider range practical cases introducing new language
elements discuss future work end section. terms verification,
well-known scalability issues probabilistic model checking applies also ProMoca.
However, results show ProMocas efficiency many practical situations. comparison state-of-the-art general purpose probabilistic model checker PRISM also
shows ProMoca outperforms PRISM verifying agents compliance goal
501

fiGunay, Liu & Zhang

satisfaction commitment protocol. Finally, social commitments framework
all-around solution model every practical situation. However, integrated
approaches multiagent systems model reason complex practical situations, e.g., integration artifacts (Baldoni, Baroglio, & Capuzzimati, 2015)
normative concepts prohibitions authorizations (Chopra & Singh, 2016a).
stated earlier, various general purpose tools, PRISM MCMAS, used verify agents respect commitment protocols.
also several reasoning methodologies handle uncertainty (Eiter & Lukasiewicz, 2003;
Richardson & Domingos, 2006). Let us justify, develop new tool tools
methodologies already exist. mainly two motivations behind development ProMoca new tool. first one ease modeling. Since general
purpose tools support commitments, provide facilities model
them. Therefore, able use one tools commitments, first model
commitment developed tool. According experience, nontrivial error-prone task. Furthermore, models mostly developed considering
specific properties aimed verified target system. Hence, reuse
models properties systems also limited. ProMoca solves issues
providing expressive modeling language includes various facilities model commitments. Hence, users easily model commitment protocols, without worrying
underlying model commitments. Besides, ProMoca based general model
commitments independent particular properties application specific
assumptions. Hence, used domain verify arbitrary properties.
second motivation efficiency. experimental results clearly demonstrate, stateof-the-art probabilistic model checker PRISM cannot achieve efficiency ProMoca
verifying agents compliance goal satisfaction commitment protocol. main
reason ProMocas efficiency utilization commitment semantics efficiently
verify addressed properties.
ProMoca used model wide majority commitment protocols
considered previous work. However, still open many improvements. major
improvement extend ProMoca explicit representation time. Currently,
time modeled ProMoca abstract manner using regular variables
demonstrated examples. sufficient many domains, however, especially
modeling commitments agent real-time systems, explicit notion time
necessary. Another improvement introduction numerical variables arithmetic operations ProMoca. variables necessary precisely model resource related
issues (e.g., money, number available spare parts, etc.). Addition features
fairly straightforward syntactic semantic point view. However, verification
time numerical variables increase complexity model checking substantially. Hence,
development novel abstraction reduction techniques use commitment semantics,
essential efficient scalable model checking models. ProMoca also
extended syntactic elements simplify modeling commitments. example
use parameters commitment specifications modeling generic commitments.
Beside improvements ProMoca, also aim extend ProMoca
model commitment concepts choice coordination (Baldoni, Baroglio,
Chopra, Desai, Patti, & Singh, 2009), relevant properties feasibility (Gunay &
502

fiProMoca: Probabilistic Modeling Analysis Agents Commitment Protocols

Yolum, 2013) safety (Marengo et al., 2011). Besides, plan support normative
concepts obligations prohibitions, relevant commitments (Boella
& van der Torre, 2004; Craven & Sergot, 2008; Agotnes, van der Hoek, & Wooldridge,
2010; Criado, Argente, & Botti, 2011). Last least integration ProMoca
recent work dynamic protocol creation open systems interesting future work
(Yolum & Singh, 2007; Artikis, 2009; Meneguzzi, Telang, & Singh, 2013; Gunay, Winikoff,
& Yolum, 2013, 2015; Cranefield, Savarimuthu, Meneguzzi, & Oren, 2015). research
aims automate creation protocols run-time, requires agents agree
commitment protocol regulate interaction according requirements.
achieve this, individual agents able analyze behaviors respect
requirements commitment protocol, ProMoca valuable tool.

Acknowledgments
thank anonymous reviewers insightful comments. work supported
Formal Verification Cloud project Grant No: M4081155.020 Bring
Advanced Model Checking Techniques Real-world Problems project Grant No:
M4011178.020.

References
Alberti, M., Chesani, F., Gavanelli, M., Lamma, E., Mello, P., & Torroni, P. (2008). Verifiable agent interaction abductive logic programming: SCIFF framework. ACM
Transactions Computational Logic, 9 (4), 29:129:43.
Aldewereld, H., Vazquez-Salceda, J., Dignum, F., & Meyer, J.-J. C. (2006). Verifying norm
compliancy protocols. Agents, Norms Institutions Regulated Multi-Agent
Systems, pp. 231245.
Alur, R., Henzinger, T. A., & Kupferman, O. (2002). Alternating-time temporal logic.
Journal ACM, 49 (5), 672713.
Andres, M. E., DArgenio, P., & Rossum, P. (2009). Significant diagnostic counterexamples
probabilistic model checking. Proceedings 4th International Haifa Verification Conference Hardware Software: Verification Testing, pp. 129148.
Springer-Verlag.
Artikis, A. (2009). Dynamic protocols open agent systems. Proceedings 8th
International Conference Autonomous Agents Multiagent Systems, pp. 97104.
Baier, C., & Katoen, J.-P. (2008). Principles Model Checking. MIT Press.
Baldoni, M., Baroglio, C., & Capuzzimati, F. (2015). Programming JADE Jason agents
based social relationships using uniform approach. Koch, F., Guttmann, C.,
& Busquets, D. (Eds.), Advances Social Computing Multiagent Systems, Vol.
541, pp. 167184. Springer.
Baldoni, M., Baroglio, C., Chopra, A. K., Desai, N., Patti, V., & Singh, M. P. (2009).
Choice, interoperability, conformance interaction protocols service chore503

fiGunay, Liu & Zhang

ographies. Proceedings 8th International Conference Autonomous Agents
Multiagent Systems, pp. 843850.
Bellman, R. (1957). Markovian decision processes. Journal Mathematics Mechanics,
38, 716719.
Bhat, G., Cleaveland, R., & Groce, A. (2001). Efficient model checking via Buchi tableau
automata. Proceedings 13th International Conference Computer Aided
Verification, pp. 3852.
Boella, G., & van der Torre, L. (2004). Regulative constitutive norms normative
multiagent systems. Proceedings 9th International Conference Principles
Knowledge Representation Reasoning, pp. 255265.
Bryant, R. E. (1986). Graph-based algorithms boolean function manipulation. IEEE
Transactions Compututers, 35 (8), 677691.
Chesani, F., Mello, P., Montali, M., & Torroni, P. (2013). Representing monitoring
social commitments using event calculus. Autonomous Agents Multi-Agent
Systems, 27 (1), 85130.
Chittaro, L., & Montanari, A. (1996). Efficient temporal reasoning cached event
calculus. Computational Intelligence, 12 (3), 359382.
Chopra, A. K., Dalpiaz, F., Giorgini, P., & Mylopoulos, J. (2010). Reasoning agents
protocols via goals commitments. Proceedings Ninth International
Conference Autonomous Agents Multiagent Systems, pp. 457464.
Chopra, A. K., & Singh, M. P. (2015). Cupid: Commitments relational algebra.
Proceedings 29th AAAI Conference Artificial Intelligence, pp. 20522059.
Chopra, A. K., & Singh, M. P. (2016a). Custard: Computing norm states information
stores. Proceedings 2016 International Conference Autonomous Agents
Multiagent Systems, pp. 10961105.
Chopra, A. K., & Singh, M. P. (2016b). social machines social protocols: Software engineering foundations sociotechnical systems. Proceedings 25th
International Conference World Wide Web, pp. 903914.
Clarke, Jr., E. M., Grumberg, O., & Peled, D. A. (1999). Model Checking. MIT Press,
Cambridge, MA, USA.
Cranefield, S., Savarimuthu, T., Meneguzzi, F., & Oren, N. (2015). bayesian approach
norm identification. Proceedings 2015 International Conference Autonomous Agents Multiagent Systems, pp. 17431744.
Craven, R., & Sergot, M. (2008). Agent strands action language n C+. Journal
Applied Logic, 6 (2), 172191.
Criado, N., Argente, E., & Botti, V. (2011). Open issues normative multi-agent systems.
AI Communications, 24 (3), 233264.
Desai, N., Cheng, Z., Chopra, A. K., & Singh, M. P. (2007a). Toward verification commitment protocols compositions. Proceedings 6th International
Joint Conference Autonomous Agents Multiagent Systems, pp. 33:133:3.
504

fiProMoca: Probabilistic Modeling Analysis Agents Commitment Protocols

Desai, N., Chopra, A. K., Arrott, M., Specht, B., & Singh, M. P. (2007b). Engineering foreign
exchange processes via commitment protocols. IEEE International Conference
Services Computing, pp. 514521.
Desai, N., Chopra, A. K., & Singh, M. P. (2009). Amoeba: methodology modeling
evolving cross-organizational business processes. ACM Transactions Software
Engineering Methodology, 19 (2), 6:16:45.
Desai, N., Narendra, N. C., & Singh, M. P. (2008). Checking correctness business contracts via commitments. Proceedings 7th International Joint Conference
Autonomous Agents Multiagent Systems, pp. 787794.
Eiter, T., & Lukasiewicz, T. (2003). Probabilistic reasoning actions nonmonotonic causal theories. Proceedings Nineteenth Conference Uncertainty
Artificial Intelligence, pp. 192199.
El Kholy, W., Bentahar, J., Menshawy, M. E., Qu, H., & Dssouli, R. (2014). Conditional
commitments: Reasoning model checking. ACM Transactions Software Engineering Methodology, 24 (2), 9:19:49.
El Menshawy, M., Bentahar, J., El Kholy, W., & Dssouli, R. (2013). Verifying conformance
multi-agent commitment-based protocols. Expert Systems Applications, 40,
122138.
Fagin, R., Halpern, J. Y., Moses, Y., & Vardi, M. Y. (2003). Reasoning Knowledge.
MIT Press, Cambridge, MA, USA.
Fornara, N., & Colombetti, M. (2002). Operational specification commitment-based
agent communication language. Proceedings 1st International Joint Conference Autonomous Agents Multiagent Systems, pp. 536542.
Gerard, S. N., & Singh, M. P. (2013). Formalizing verifying protocol refinements. ACM
Transactions Intelligent Syststems Technology, 4 (2), 21:121:27.
Giunchiglia, E., Lee, J., Lifschitz, V., McCain, N., & Turner, H. (2004). Nonmonotonic
causal theories. Artificial Intelligence, 153 (1-2), 49104.
Gunay, A., Songzheng, S., Liu, Y., & Zhang, J. (2015). Automated analysis commitment
protocols using probabilistic model checking. Proceedings 29th AAAI Conference
Artificial Intelligence, pp. 20602066.
Gunay, A., Winikoff, M., & Yolum, P. (2013). Commitment protocol generation. Declarative Agent Languages Technologies X, Vol. 7784 LNAI, pp. 136152. Springer.
Gunay, A., Winikoff, M., & Yolum, P. (2015). Dynamically generated commitment protocols
open systems. Journal Autonomous Agents Multi-agent Systems, 29, 192
229.
Gunay, A., & Yolum, P. (2011). Detecting conflicts commitments. Sakama, C.,
Sardina, S., Vasconcelos, W., & Winikoff, M. (Eds.), Declarative Agent Languages
Technologies IX, Vol. 7169 LNAI, pp. 5166. Springer.
Gunay, A., & Yolum, P. (2013). Constraint satisfaction tool modeling checking
feasibility multiagent commitments. Applied Intelligence, 39 (3), 489509.
505

fiGunay, Liu & Zhang

Halpern, J. Y. (2003). Reasoning Uncertainty. MIT Press, Cambridge, MA, USA.
Han, T., Katoen, J.-P., & Berteun, D. (2009). Counterexample generation probabilistic
model checking. IEEE Transactions Software Engineering, 35 (2), 241257.
Hoare, C. A. R. (1978). Communicating sequential processes. Communications ACM,
21 (8), 666677.
Holzmann, G. J. (Ed.). (2004). SPIN Model Checker: Primer Reference Manual.
Addison-Wesley.
Jakob, M., Pechoucek, M., Miles, S., & Luck, M. (2008). Case studies contract-based
systems. Proceedings 7th International Joint Conference Autonomous
Agents Multiagent Systems: Industrial Track, pp. 5562.
Kafal, O., Gunay, A., & Yolum, P. (2012). PROT OSS: run time tool detecting
PRivacy viOlaT ions Online Social networkS. IEEE/ACM International Conference Advances Social Networks Analysis Mining, pp. 429433.
Kafal, O., Gunay, A., & Yolum, P. (2013). Detecting predicting privacy violations
online social networks PROT OSS. Distributed Parallel Databases, 32 (1),
161190.
Kafal, O., Gunay, A., & Yolum, P. (2014). GOSU: Computing goal support commitments multiagent systems. Proceedings 21st European Conference Artificial
Intelligence, pp. 477482.
Kafal, O., & Torroni, P. (2012). Exception diagnosis multiagent contract executions.
Annals Mathematics Artificial Intelligence, 64 (1), 73107.
Kwiatkowska, M., Norman, G., & Parker, D. (2011). PRISM 4.0: Verification probabilistic
real-time systems. Proceedings 23rd International Conference Computer
Aided Verification, pp. 585591.
Lomuscio, A., Qu, H., & Raimondi, F. (2009). MCMAS: model checker verification multi-agent systems. Proceedings 21st International Conference
Computer Aided Verification, pp. 682688.
Mallya, A. U., & Huhns, M. N. (2003). Commitments among agents. IEEE Internet
Computing, 7 (4), 9093.
Marengo, E., Baldoni, M., Baroglio, C., Chopra, A. K., Patti, V., & Singh, M. P. (2011).
Commitments regulations: Reasoning safety control REGULA.
Proceedings Tenth International Conference Autonomous Agents
Multiagent Systems, pp. 467474.
Meneguzzi, F., Telang, P. R., & Singh, M. P. (2013). first-order formalization commitments goals planning. Proceedings 27th AAAI Conference
Artificial Intelligence, pp. 697703.
Modgil, S., Faci, N., Meneguzzi, F., Oren, N., Miles, S., & Luck, M. (2009). framework
monitoring agent-based normative systems. Proceedings 8th International
Conference Autonomous Agents Multiagent Systems, pp. 153160.
506

fiProMoca: Probabilistic Modeling Analysis Agents Commitment Protocols

Montali, M., Calvanese, D., & De Giacomo, G. (2014). Verification data-aware
commitment-based multiagent system. Proceedings 2014 International Conference Autonomous Agents Multi-agent Systems, pp. 157164.
Pnueli, A. (1977). temporal logic programs. Proceedings 18th Annual
Symposium Foundations Computer Science, pp. 4657.
Agotnes, T., van der Hoek, W., & Wooldridge, M. (2010). Robust normative systems
logic norm compliance. Logic Journal IGPL, 18 (1), 430.
Richardson, M., & Domingos, P. (2006). Markov logic networks. Machine Learning, 62 (1-2),
107136.
Schmalz, M., Varacca, D., & Volzer, H. (2009). Counterexamples probabilistic ltl model
checking markov chains. Proceedings 20th International Conference
Concurrency Theory, pp. 587602. Springer-Verlag.
Singh, M. P. (1999). ontology commitments multiagent systems: Toward unification normative concepts. Artificial Intelligence Law, 7 (1), 97113.
Singh, M. P. (2008). Semantical considerations dialectical practical commitments.
Proceedings 23rd National Conference Artificial Intelligence, pp. 176181.
Singh, M. P., Chopra, A. K., & Desai, N. (2009). Commitment-based service-oriented
architecture. IEEE Computer, 42 (11), 7279.
Sirbu, M. A., & Tygar, J. D. (1995). NetBill: internet commerce system optimized
network delivered services. IEEE Personal Communications, 2 (4), 3439.
Sultan, K., Bentahar, J., Wan, W., & Al-Saqqar, F. (2014). Modeling verifying probabilistic multi-agent systems using knowledge social commitments. Expert Systems
Applications, 41 (14), 62916304.
Sun, J., Liu, Y., Dong, J. S., & Pang, J. (2009). PAT: Towards flexible verification
fairness. Proceedings 21th International Conference Computer Aided
Verification (CAV), Vol. 5643 Lecture Notes Computer Science, pp. 709714.
Springer.
Telang, P., & Singh, M. (2012). Specifying verifying cross-organizational business
models: agent-oriented approach. IEEE Transations Services Computing, 5 (3),
305318.
Telang, P. R., Kalia, A. K., & Singh, M. P. (2015).
Modeling healthcare processes using commitments: empirical evaluation.
PLoS ONE, 10 (11),
doi:10.1371/journal.pone.0141202.
Telang, P. R., & Singh, M. P. (2012). Comma: commitment-based business modeling
methodology empirical evaluation. Proceedings 11th International
Conference Autonomous Agents Multiagent Systems, pp. 10731080.
Torroni, P., Chesani, F., Mello, P., & Montali, M. (2010). Social commitments time: Satisfied compensated. Proceedings 7th International Conference Declarative
Agent Languages Technologies, pp. 228243, Berlin, Heidelberg. Springer-Verlag.
507

fiGunay, Liu & Zhang

van Riemsdijk, M. B., Dastani, M., & Meyer, J.-J. C. (2009). Goals conflict: Semantic
foundations goals agent programming. Autonomous Agents Multi-Agent
Systems, 18 (3), 471500.
Vasconcelos, W. W. (2005). Norm verification analysis electronic institutions.
Proceedings Second International Conference Declarative Agent Languages
Technologies, pp. 166182.
Yolum, P. (2007). Design time analysis multiagent protocols. Data Knowledge
Engineering, 63 (1), 137154.
Yolum, P., & Singh, M. P. (2002). Flexible protocol specification execution: Applying
event calculus planning using commitments. Proceedings 1st International
Joint Conference Autonomous Agents Multiagent Systems, pp. 527534.
Yolum, P., & Singh, M. P. (2007). Enacting protocols commitment concession.
Proceedings 6th International Joint Conference Autonomous Agents
Multiagent Systems, pp. 27:127:8.

508

fiJournal Artificial Intelligence Research 57 (2016) 421-464

Submitted 06/16; published 11/16

Embarrassingly Parallel Search Constraint Programming
Arnaud Malapert
Jean-Charles Regin
Mohamed Rezgui

arnaud.malapert@unice.fr
jean-charles.regin@unice.fr
rezgui@i3s.unice.fr

Universite Cote dAzur, CNRS, I3S, France

Abstract
introduce Embarrassingly Parallel Search (EPS) method solving constraint
problems parallel, show method matches even outperforms state-ofthe-art algorithms number problems using various computing infrastructures. EPS
simple method master decomposes problem many disjoint subproblems solved independently workers. approach three advantages:
efficient method; involves almost communication synchronization
workers; implementation made easy master workers rely
underlying constraint solver, require modify it. paper describes
method, applications various constraint problems (satisfaction, enumeration,
optimization). show method adapted different underlying solvers
(Gecode, Choco2, OR-tools) different computing infrastructures (multi-core, data centers, cloud computing). experiments cover unsatisfiable, enumeration optimization
problems, cover first solution search makes results hard analyze. variability observed optimization problems, lesser
extent optimality proof required. EPS offers good average performance,
matches outperforms available parallel implementations Gecode well
solvers portfolios. Moreover, perform in-depth analysis various factors
make approach efficient well anomalies occur. Last, show
decomposition key component efficiency load balancing.

1. Introduction
second half 20th century, frequency processors doubled every 18 months
so. clear years period free lunch, put Sutter
Larus (2005), behind us. outlined Bordeaux, Hamadi, Samulowitz (2009),
available computational power keep increasing exponentially, increase
terms number available processors, terms frequency per unit. Multi-core
processors norm raises significant challenges software development.
Data centers high-performance computing readily accessible many academia
industry. Cloud computing (Amazon, Microsoft Azure, Google, . . . ) offers massive
infrastructures rent computing storage used demand.
facilities anyone gain access super-computing facilities moderate cost.
Distributed Computing offers possibilities put computational resources common
effectively obtains massive capabilities. Examples include Seti@home (Anderson, Cobb,
Korpela, Lebofsky, & Werthimer, 2002), Distributed.net (Distributed Computing Technologies Inc, 20) Sharcnet (Bauer, 2007). main challenge therefore scale, i.e.,
cope growth.
c
2016
AI Access Foundation. rights reserved.

fiMalapert, Regin, & Rezgui

Constraint programming (CP) appealing technology variety combinatorial
problems grown steadily last three decades. strengths CP
use constraint propagation combined efficient search algorithms. Constraint
propagation aims removing combinations values variable domains cannot
appear solution. number years, possible gains offered parallel
computing attracted attention.
Parallel computing form computation many calculations carried
simultaneously (Almasi & Gottlieb, 1989) operating principle large problems
often divided smaller ones, solved parallel. Different forms
parallel computing exist: bit-level, instruction level, data task parallelism. Task
parallelism common approach parallel branch-and-bound (B&B) algorithms (Mattson, Sanders, & Massingill, 2004) achieved processor executes different
thread (or process) different data. Parallel computer programs difficult write sequential ones, concurrency introduces several new classes
potential software bugs, race conditions common. example,
memory shared, several tasks algorithm modify data
time. could render program incorrect. Mutual exclusion allows worker lock
certain resources obtain exclusive access, create starvation
workers must wait worker frees resources. Moreover, indeterminism
parallel programs makes behaviour execution unpredictable, i.e. results
different program runs may differ. So, communication synchronization among different
sub-tasks address issue, typically greatest obstacles good
performance. Another central bottleneck load balancing, i.e. keeping processors busy
much possible.
Wilkinson Allen (2005) introduced Embarrassingly Parallel paradigm assumes computation divided number completely independent parts
part executed separate processor. paper, introduce
Embarrassingly Parallel Search (EPS) method constraint problems show
method often outperforms state-of-the-art parallel B&B algorithms number
problems various computing infrastructures. master decomposes problem
many disjoint subproblems solved independently workers. Since constraint program trivially embarrassingly parallel, decomposition procedure must
carefully designed. approach three advantages: efficient method;
involves almost communication, synchronization, mutual exclusion workers;
implementation simple master workers rely underlying
constraint solver require modify it. Additionally, deterministic
certain restrictions.
paper integrates results series publications (Regin, Rezgui, & Malapert,
2013, 2014; Rezgui, Regin, & Malapert, 2014). However, paper includes novel contributions, implementations, results. new implementation EPS top
Java library Choco2 (Choco, 2010) uses new decomposition procedure. New results
given implementations top C++ library Gecode (Schulte, 2006)
OR-tools (Perron, Nikolaj, & Vincent, 2012), problems types instances
tested. EPS compared parallelizations Gecode several static
422

fiEmbarrassingly Parallel Search CP

solvers portfolios, perform in-depth analysis various components, especially decomposition procedures, well anomalies occur.
paper organized follows. Section 2 presents constraint programming background, Amdahls law, related work parallel constraint solving. Section 3 gives
detailed description embarrassingly parallel search method. Section 4 gives extensive experimental results various implementations (Gecode, Choco2, OR-tools)
different computing infrastructures (multi-core, data center, cloud computing) well
comparisons state-of-the-art parallel implementations static solver portfolios.

2. Related Work
Here, present constraint programming background, two important parallelization
measures related Amdahls law, related work parallel constraint solving.
2.1 Constraint Programming Background
Constraint programming (CP) attracted high attention among experts many areas
potential solving hard real-life problems. extensive review
constraint programming, refer reader handbook Rossi, Van Beek,
Walsh (2006). constraint satisfaction problem (CSP) consists set X variables
defined corresponding set possible values (the domains D) set C constraints.
constraint relation subset variables restricts possible values
variables take simultaneously. important feature constraints declarative
manner, i.e. specify relationship must hold. current domain D(x)
variable x X always (non-strict) subset initial domain. partial assignment
represents case domains variables reduced singleton
(namely variable assigned value). solution CSP assignment
value variable constraints simultaneously satisfied.
Solutions found searching systematically possible assignments
values variables. backtracking scheme incrementally extends partial assignment
specifies consistent values variables, toward complete solution,
repeatedly choosing value another variable. variables labeled (given value)
sequentially. node search tree, uninstantiated variable selected
node extended resulting new branches node represent alternative
choices may examined order find solution. branching strategy
determines next variable instantiated, order values
domain selected. partial assignment violates constraints, backtracking
performed recently assigned variable still alternative values available
domain. Clearly, whenever partial assignment violates constraint, backtracking
able eliminate subspace Cartesian product variable domains.
filtering algorithm associated constraint removes inconsistent values
domains variables, i.e. assignments cannot belong solution
constraint. Constraints handled constraint propagation mechanism
allows reduction domains variables global fixpoint reached (no
domain reductions possible). fact, constraint specifies relationship must hold
filtering algorithm computational procedure enforces relationship.
423

fiMalapert, Regin, & Rezgui

Generally, consistency techniques complete, i.e. remove inconsistent
values domains variables.
backtracking scheme consistency techniques used alone completely
solve CSP, combination allows search space explored complete
efficient way. propagation mechanism allows reduction variable
domains pruning search tree whereas branching strategy improve
detection solutions (or failures unsatisfiable problems).
Here, consider complete standard backtracking scheme depth-first traversal
search tree combined following variable selection strategies. Note different
variable selection strategies used although one time. lex selects variable
according lexicographic ordering. dom selects variable smallest remaining domain (Haralick & Elliott, 1980). ddeg selects variable largest dynamic degree (Beck,
Prosser, & Wallace, 2005), is, variable constrained largest number
unassigned variables. Boussemart, Hemery, Lecoutre, Sais (2004) proposed conflictdirected variable ordering heuristics every time constraint causes failure
search, weight incremented one. variable weighted degree,
sum weights constraints variable occurs. wdeg selects
variable largest weighted degree. current domain variable incorporated give dom/ddeg dom/wdeg selects variable minimum ratio
current domain size dynamic weighted degree (Boussemart et al., 2004;
Beck et al., 2005). dom/bwdeg variant follows binary labeling scheme. impact
selects variable/value pair strongest impact, i.e. leads strongest
search space reduction (Refalo, 2004).
optimization problems, consider standard top-down algorithm maintains
lower bound, lb, upper bound, ub, objective value. ub lb, subtree
pruned cannot contain better solution.
2.2 Parallelization Measures Amdahls Law
Two important parallelization measures speedup efficiency. Let t(c) wallclock time parallel algorithm c number cores let t(1)
wall-clock time sequential algorithm. speedup su(c) = t(1) / t(c) measure
indicating many times parallel algorithm performs faster due parallelization.
efficiency eff (c) = su(c) / c normalized version speedup, speedup
value divided number cores. maximum possible speedup single program
result parallelization known Amdahls law (Amdahl, 1967). states
small portion program cannot parallelized limit overall speedup
available parallelization. Let B [0, 1] fraction algorithm strictly
sequential, time t(c)
algorithm takes finish executed c cores
corresponds to: t(c) = t(1) B + 1c (1 B) . Therefore, theoretical speedup su(c) is:

su(c) =

1
B + (1 B)
1
c

424

fiEmbarrassingly Parallel Search CP

According Amdahls law, speedup never exceed number cores, i.e. linear
speedup. This, terms efficiency measure, means efficiency always less
1.
Note sequential parallel B&B algorithms always explore
search space. Therefore, super-linear speedups parallel B&B algorithms contradiction Amdahls law processors access high quality solutions early
iterations, turn brought reduction search tree problem size.
2.3 Parallel Constraint Solving
Designing developing parallel programs manual process programmer responsible identifying implementing parallelism (Barney & Livermore, 2016). section, discuss parallel constraint solving. parallel
logic programming, refer reader surveys De Kergommeaux Codognet
(1994), Gupta, Pontelli, Ali, Carlsson, Hermenegildo (2001). parallel integer
programming, refer reader surveys Crainic, Le Cun, Roucairol (2006),
Bader, Hart, Phillips (2005), Gendron Crainic (1994).
main approaches parallel constraint solving roughly divided following main categories: search space shared memory; search space splitting; portfolio algorithms; problem splitting. approaches require communication synchronization,
important issue load balancing refers practice distributing
approximately equal amounts work among tasks processors kept busy
time.
2.3.1 Search Space Shared Memory
methods implemented many cores sharing list open nodes
search tree (nodes least one children still unvisited).
Starved processors pick promising node list expand it.
defining different node evaluation functions, one implement different strategies (DFS,
BFS others). Perron (1999) proposed comprehensive framework tested
4 processors. Vidal, Bordeaux, Hamadi (2010) reported good performance parallel
best-first search 64 processors. Although kind mechanism intrinsically provides
excellent load balancing, known scale beyond certain number processors;
beyond point, performance starts decrease. Indeed, shared memory system,
threads must contend communicating memory problem
exacerbated cache consistency transactions.
2.3.2 Search Space Splitting
Search Space Splitting strategies exploring parallelism provided search space
common approaches: branching done, different branches explored
parallel (Pruul, Nemhauser, & Rushmeier, 1988). One challenge load balancing:
branches search tree typically extremely imbalanced require non-negligible
overhead communication work stealing (Lai & Sahni, 1984).
work stealing method originally proposed Burton Sleep (1981) first
implemented Lisp parallel machines (Halstead, 1984). search space dynamically
425

fiMalapert, Regin, & Rezgui

split resolution. worker finished explore subproblem, asks
workers another subproblem. another worker agrees demand, splits
dynamically current subproblem two disjoint subproblems sends one subproblem
starving worker. starving worker steals work busy one. Note
form locking necessary avoid several starving workers steal
subproblems. starving worker asks workers turn receives new
subproblem. Termination work stealing method must carefully designed reduce
overhead almost workers starving, almost work remains. Recent works
based approach Zoeteweij Arbab (2004), Jaffar, Santosa, Yap,
Zhu (2004), Michel, See, Hentenryck (2009), Chu, Schulte, Stuckey (2009).
work stealing uses communication, synchronization computation time,
cannot easily scaled thousands processors. address issues, Xie
Davenport (2010) allocated specific processors coordination tasks, allowing increase
number processors (linear scaling 256 processors) used
parallel supercomputer performance starts decline.
Machado, Pedro, Abreu (2013) proposed hierarchical work stealing scheme correlated cluster physical infrastructure, order reduce communication overhead.
worker first tries steal local node, considering remote nodes (starting
closest remote node). approach achieved good scalability 512 cores
n-queens quadratic assignment problems. constraint optimization problems,
maintaining best solution worker would require large communication
synchronization overhead. But, Machado et al. observed scalability lowered
lazy dissemination so-far best solution, i.e. workers use
obsolete best solution.
General-purpose programming languages designed multi-threaded parallel computing
like Charm++ (Kale & Krishnan, 1993) Cilk++ (Leiserson, 2010; Budiu, Delling, &
Werneck, 2011) ease implementation work stealing approaches. Otherwise,
work stealing framework like Bobpp (Galea & Le Cun, 2007; Le Cun, Menouer, & VanderSwalmen, 2007) provides interface solvers parallel computers. Bobpp,
work shared via global priority queue search tree decomposed allocated
different cores demand search algorithm execution. Periodically, worker
tests starving workers exist. case, worker stops search path
root node highest right open node saved inserted global priority
queue. Then, worker continues search left open node. Otherwise,
starving worker exists, worker continues search locally using solver. starving
workers notified insertions global priority queue, one picks
node starts search. Using OR-tools underlying solver, Menouer Le Cun
(2013), Menouer Le Cun (2014) observed good speedups Golomb Ruler
problem 13 marks (41.3 48 workers) 16-queens problem (8.63 12
workers). experiments investigate exploration overhead caused approach.
Bordeaux et al. (2009) proposed another promising approach based search space
splitting mechanism based work stealing approach. use hashing function
allocating implicitly leaves processors. processor applies search
strategy allocated search space. Well-designed hashing constraints address
load balancing issue. approach gives linear speedup 30 processors
426

fiEmbarrassingly Parallel Search CP

n-queens problem, speedups stagnate 30 64 processors. However,
got moderate results 100 industrial SAT instances.
presented earlier works Embarrassingly Parallel Search method based
search space splitting loose communications (Regin et al., 2013, 2014; Rezgui et al.,
2014).
Fischetti, Monaci, Salvagnin (2014) proposed another paradigm called SelfSplit
worker able autonomously determine, without communication
workers, job parts process. SelfSplit decomposed three phases:
enumeration tree initially built workers (sampling); enough open nodes
generated, sampling phase ends worker applies deterministic rule
identify solve nodes belong (solving); single worker gathers results
others (merging). SelfSplit exhibited linear speedups 16 processors good
speedups 64 processors five benchmark instances. SelfSplit assumes sampling
bottleneck overall computation whereas happen practice (Regin
et al., 2014).
Sometimes, complex applications good domain specific strategies
known, parallel algorithm exploit domain-specific strategy. Moisan, Gaudreault, Quimper (2013), Moisan, Quimper, Gaudreault (2014) proposed
parallel implementation classic backtracking algorithm, Limited Discrepancy Search
(LDS), known efficient centralized context good variable/value
selection heuristic provided (Harvey & Ginsberg, 1995). Xie Davenport (2010) proposed processor locally uses LDS search trees allocated (by
tree splitting work stealing algorithm) global system replicate LDS
strategy.
Cube-and-Conquer (Heule, Kullmann, Wieringa, & Biere, 2012) approach parallelizing SAT solvers. cube conjunction literals DNF formula disjunction
cubes. SAT problem split several disjoint subproblems DNF formulas
solved independently workers. Cube-and-Conquer using ConflictDriven Clause Learning (CDCL) solver Lingeling outperforms parallel SAT solvers
instances SAT 2009 benchmarks, also outperformed many
instances. Thus, Concurrent Cube-and-Conquer (Van Der Tak, Heule, & Biere, 2012) tries
predict instances works well abort parallel search seconds
favor sequential CDCL solver not.
2.3.3 Las Vegas Algorithms / Portfolios
explore parallelism provided different viewpoints problem,
instance using different algorithms parameter tuning. idea also exploited
non-parallel context (Gomes & Selman, 2000). communication required
excellent level load balancing achieved (all workers visit search space). Even
approach causes high level redundancy processors, shows really good
performance. greatly improved using randomized restarts (Luby, Sinclair, &
Zuckerman, 1993) worker executes restart strategy. recently, Cire,
Kadioglu, Sellmann (2014) executed Luby restart strategy, whole, parallel.
proved achieves asymptotic linear speedups and, practice, often obtained
427

fiMalapert, Regin, & Rezgui

linear speedups. Besides, authors proposed allow processors share information
learned search (Hamadi, Jabbour, & Sais, 2008).
One challenge find scalable source diverse viewpoints provide orthogonal
performance therefore complementary interest. distinguish
two aspects parallel portfolios: assumptions made number available
processors possible handpick set solvers settings complement
optimally. want face arbitrarily high number processors,
need automated methods generate portfolio size demand (Bordeaux et al.,
2009). So, portfolio designers became interested feature selection (Gomes & Selman, 1997,
1999, 2001; Kautz, Horvitz, Ruan, Gomes, & Selman, 2002). Features characterize problem
instances like number variables, domain sizes, number constraints, constraints arities.
Many portfolios select best candidate solvers pool based static features
learning dynamic behaviour solvers. SAT portfolio iSAC (Amadini, Gabbrielli,
& Mauro, 2013) CP portfolio CPHydra (OMahony, Hebrard, Holland, Nugent, &
OSullivan, 2008) use feature selection choose solvers yield best performance.
Additionally, CPHydra exploits knowledge coming resolution training set
instances candidate solver. Then, given instance, CPHydra determines k
similar instances training set determines time limit candidate
solver based constraint program maximizing number solved instances within
global time limit 30 minutes. Briefly, CPHydra determines switching policy
solvers (Choco2, AbsCon, Mistral).
Many recent SAT solvers based portfolio ManySAT (Hamadi et al.,
2008), SATzilla (Xu, Hutter, Hoos, & Leyton-Brown, 2008), SArTagnan (Stephan & Michael,
2011), Hydra (Xu, Hoos, & Leyton-Brown, 2010), Pminisat (Chu, Stuckey, & Harwood,
2008) based Minisat (Een & Sorensson, 2005). combine portfolio-based
algorithm selection automatic algorithm configuration using different underlying solvers.
example, SATzilla (Xu et al., 2008) exploits per-instance variation among solvers
using learned runtime models.
general, main advantage algorithms portfolio approach many strategies automatically tried time. useful defining good
search strategies difficult task.
2.3.4 Problem Splitting
Problem Splitting another idea relates parallelism, problem split
pieces solved processor. problem typically becomes difficult
solve centralized case processor complete view problem.
So, reconciling partial solutions subproblem becomes challenging. Problem
splitting typically relates distributed CSPs, framework introduced Yokoo, Ishida,
Kuwabara (1990) problem naturally split among agents, privacy
reasons. distributed CSP frameworks proposed Hirayama
Yokoo (1997), Chong Hamadi (2006), Ezzahir, Bessiere, Belaissaoui, Bouyakhf
(2007), Leaute, Ottens, Szymanek (2009), Wahbi, Ezzahir, Bessiere, Bouyakhf
(2011).
428

fiEmbarrassingly Parallel Search CP

2.3.5 Parallel Constraint Propagation
approaches thought of, typically based parallelization one key algorithm solver, instance constraint propagation (Nguyen & Deville, 1998; Hamadi,
2002; Rolf & Kuchcinski, 2009). However, parallelizing propagation challenging (Kasif,
1990) scalability limited Amdahls law. approaches focus
particular topologies make assumptions problem.
2.3.6 Concluding Remarks
Note oldest approaches, scalability issues still investigated
small number processors, typically around 16 64 processors. One major
issue approaches may (and must) resort communication. Communication
parallel agents costly general: shared-memory models multi-core,
typically means access shared data structure one cannot avoid
form locking; cost message-passing cross-CPU even significantly higher. Communication additionally makes difficult get insights solving process since
executions highly inter-dependent understanding parallel executions notoriously
complex.
parallel B&B algorithms explore leaves search tree different order
would single-processor system. could pity situations
know really good search strategy, entirely exploited parallel algorithm.
many approaches, experiments parallel programming involve great deal nondeterminism: running algorithm twice instance, identical number
threads parameters, may result different solutions, sometimes different
runtimes.

3. Embarrassingly Parallel Search
section, present details embarrassingly parallel search. First, Section 3.1
introduces key concepts guided design choices. Then, Section 3.2 introduces
several search space splitting strategies implemented via top-down bottom-up decomposition procedures presented Section 3.3. Section 3.4 gives details architecture
communication. Section 3.5 explains manage queue subproblems
order obtain deterministic parallel algorithm. Section 4.1 gives details
implementation.
3.1 Key Concepts
introduce key concepts guided design choices: massive static decomposition;
loose communication; non-intrusive implementation; toward deterministic algorithm.
3.1.1 Massive Static Decomposition
master decomposes problem p subproblems
solved parallel independently workers. So, solving process equivalent
real-time scheduling p jobs w parallel identical machines known P ||Cmax (Korf &
429

fiMalapert, Regin, & Rezgui

Schreiber, 2013). Efficient algorithms exists P ||Cmax even simple list scheduling
algorithms (based priority rules) (2 w1 )-approximation. desirable properties
defined Section 3.2 ensure low precision processing times makes problems
easier. hold precision number workers fixed, increase number
subproblems, problems get harder perfect schedules appear, get
easier. case, number p subproblems range one three
orders magnitude larger number workers w. low, chance
finding perfect schedules, therefore obtain good speedups, low. large,
decomposition takes longer becomes difficult. conditions met,
unlikely worker assigned work other, therefore,
decomposition statistically balanced. Beside, reach good speedups practice,
total solving time subproblems must close sequential solving time
problem.
advantage master workers independent. use different
filtering algorithms, branching strategies, even underlying solvers. decomposition
crucial step, bottleneck computation quality also greatly
impacts parallelization efficiency.
3.1.2 Loose Communication
p subproblems solved parallel independently w workers. load balancing
must statistically obtained decomposition, allow work stealing
order drastically reduce communication. course, communication still needed
dispatch subproblems, gather results possibly exchange useful additional
information, like objective bound values. Loose communication allows use star network
without risk congestion. central node (foreman) connected nodes (master
workers).
3.1.3 Non-intrusive Implementation
sake laziness efficiency, rely much possible underlying solver(s)
computing infrastructure. Consequently, modify little possible underlying solver. consider nogoods clauses exchanges techniques
intrusive increase communication overhead. Additionally, logging fault
tolerance respectively delegated underlying solver infrastructure.
3.1.4 Toward Determinism
deterministic algorithm algorithm which, given particular input, always produce output, underlying machine always passing sequence states. determinism already challenging sequential B&B algorithms
due complexity (randomization, restarts, learning, optimization), still
difficult parallel B&B algorithms.
Here, always guarantee reproducibility real-time assignment subproblems workers stored. Reproducibility means always possible replay
solving process. restrictions detailed later, parallel algorithm made
deterministic additional cost. Moreover, parallel algorithm able
430

fiEmbarrassingly Parallel Search CP

mimic sequential algorithm, i.e. produce identical solutions. requires
parallel algorithm visits tree leaves order sequential algorithm.
generally, would useful debugging, performance evaluation, incremental problem
solving parallel algorithm may produce identical solutions matter many
workers present computing infrastructure used.
Conversely, real-time scheduling algorithm applied subproblems. would
allow improve diversification using randomization, exploit past information
provided solving process. experiments, use FIFO scheduling
subproblems, scheduling policy would change shape size
search tree and, therefore, reduces relevance speedups. Unlike EPS, work stealing
approaches deterministic offer control subproblem scheduling.
3.2 Search-Space Splitting Strategies
Here, extend approach search-space splitting proposed Bordeaux et al. (2009),
called splitting hashing. Let us recall C set constraints problem.
split search space problem p parts, one approach assign subproblem
(1 p) extended set constraints C Hi Hi hashing constraint,
constrains subproblem particular subset search space. Hashing constraints
must necessarily sound effective, nontrivial, statistically balanced.
Sound Hashing constraints must partition search space: pi=1 Hi must cover entire
initial search space (completeness), mutual intersections Hi Hj (1 < j p)
preferably empty (non-overlapping).
Effective addition hashing constraints effectively allow worker
efficiently skip portions search space assigned current subproblem.
subproblem must significantly easier original problem. causes overhead,
refer recomputation overhead.
Nontrivial addition hashing constraints lead immediate
failure underlying solver. Thus, generating trivial subproblems might paid
exploration overhead, many would discarded propagation
mechanism sequential algorithm.
Statistically Balanced workers given amount work.
decomposition appropriate, number p subproblems significantly larger
number w workers. thus unlikely given worker would assigned
significantly work worker real-time scheduling algorithm. However, possible solving one subproblem requires significantly work another
subproblem.
Bordeaux et al. (2009) defined hashing constraints selecting subset X variables
P
problem stating Hi (1 p) follows: xX x mod p. effectively
decomposes problem p problems p within reasonable limits. p = 2, imposes
parity constraints sum variables. Splitting repeated scale-up
arbitrary number processors. splitting obviously sound, less effective
431

fiMalapert, Regin, & Rezgui

CP solvers SAT solvers. Here, study assignment splitting node splitting
generate given number p? subproblems.
3.2.1 Assignment Splitting
Let us consider non empty subset X X ordered variables: X = (x1 , . . . , xd ). vector = (v1 , . . . , vd ) tuple X vj D(xj ) (j = 1, . . . , d). Let H( ) = dj=1 (xj = vj )
hashing constraints restrict search space solutions extending tuple .
Q
total decomposition X splits initial problem di=1 D(xi ) subproblems, i.e. one
subproblem per tuple. total decomposition clearly sound effective, efficient
practice. Indeed, Regin et al. (2013) showed number trivial subproblems
grow exponentially.
table decomposition, subproblem defined set tuples allows reach
exactly number p? subproblems. Let ordered list ofj tuples
X
k
|T |
?
|T | > p . Then, first subproblem defined first k = p? tuples, second
subproblem defined following k tuples, on. So, subproblems defined
number tuples possibly exception last.
tuple solver-consistent propagation extended set constraints C
H( ) underlying solver detect unsatisfiability. order obtain nontrivial
decompositions, total table decompositions restricted solver-consistent tuples.
3.2.2 Node Splitting
Node splitting allows parallel algorithm exploit domain-specific strategies
decomposition good strategy known. Let us recall concepts search
trees (Perron, 1999) basis decomposition procedures introduced later.
decompose problems, one needs able map individual parts search tree
hashing constraints. parts called open nodes. open nodes defined,
present search tree decomposed set open nodes.
Open Nodes Node Expansion search tree partitioned three sets, open
nodes, closed nodes, unexplored nodes. Here, make assumption
arity search tree, i.e. maximal number children nodes. subsets
following properties.
ancestors open node closed nodes.
unexplored node exactly one open node ancestor.
closed node open node ancestor.
set open nodes called search frontier illustrated Figure 1. search
active
path
closed

open

Frontier

unexplored

Figure 1: Node status search frontier search tree.
432

fiEmbarrassingly Parallel Search CP

frontier evolves simply process known node expansion. removes open node
frontier, transforms removed node closed node, adds unexplored
children frontier. Node expansion operation happens
search. corresponds branch operation B&B algorithm.
point search, search frontier sound nontrivial decomposition
original problem open node associated subproblem. decomposition effective branching strategy effective. Let us remark
assignment splitting seen special case node splitting static ordering
used variables values.
Active Path Jumps Search Tree Expanding one node another may
require changing state (at least variables domains) search process
first node second. So, worker charge exploring open node must reconstruct
state visits. done using active path jumping operation.
going search tree, search process builds active path,
list ancestors current open node, illustrated Figure 1. worker
moves one node another, jump search tree. make jump,
simply recomputes every move root gets target node. causes
overhead, refer recomputation overhead. Recomputation change
search frontier expand node.
3.3 Decomposition Procedures
decomposition challenge find depth search frontier contains
approximately p? nodes. assignment splitting strategy implemented top-down
procedure starts root node incrementally visits next levels, whereas
node splitting strategy implemented bottom-up procedure starts form
level deep enough climbs back previous levels.
3.3.1 Top-Down Decomposition
challenge top-down decomposition find ordered variables produce
approximately p? solver-consistent tuples. Algorithm 1 realizes solver-consistent table
decomposition iterated depth-bounded depth-first searches early removals inconsistent assignments (Regin et al., 2013).
algorithm starts root node
empty list tuples (line 1). computes list p? tuples solver-consistent
table decomposition iterativly increasing decomposition depth. Let us assume
exists static order variables. iteration, determines new lower
bound (line 4) decomposition depth d, i.e. number variables involved
decomposition. lower bound uses Cartesian product current domains
next variables xd+1 , xd+2 , . . . Then, depth-bounded depth-first search extends
decomposition new depth updates list tuples (line 5). current tuples
added constraints model search (line 5) order reduce
redundant work. search, extended tuples propagated (line 7) reduce
domains, improve next lower bound decomposition depth. tuple
solver-consistent (not proven infeasible) last search. process repeated
number |T | tuples greater equal p? . end, tuples aggregated
433

fiMalapert, Regin, & Rezgui

Algorithm 1: Top-down decomposition.

1
2

3

4

5
6

7
8

9

10

Data: CSP (X , D, C) number subproblems p?
Result: list tuples
0;
;
/* Simulate breadth-first search: iterated depth bounded DFSs.
repeat
/* Determine
decomposition
depth. */

n fi lower bound
Ql
fi
?
min l fi max(1, |T |) i=d+1 |D(xi )| p ;

*/

/* Extend current decomposition new variables. */
depthBoundedDFS (X , C { H( )}, D, {x1 , . . . , xd });
== break;
/* Propagate tuples (without failure). */
propagate (X , C { H( )}, D);
|T | < p? ;
/* Aggregate tuples generate exactly p? subproblems */
aggregateTuples(T ) /* subproblems become simultaneously available.
*/
foreach sendSubProblem (X , C H( ), D);

generate exactly p? subproblems. practice, consecutive tuples aggregated.
subproblems become simultaneously available aggregation.
Sometimes, sequential decomposition bottleneck Amdahls law. So,
parallel decomposition procedure increases scalability (Regin et al., 2014).
two steps differ Algorithm 1. First, instead starting depth 0 empty list
tuples (line 1 Algorithm 1), first list quickly generated least five tuples per
worker.
n fi

1
2

fi Ql
min l fi i=1 |D(xi )| 5 w ;
Qd
i=1 D(xi );

Second, iteration, tuple extended parallel instead extending sequentially tuples (line 5 Algorithm 1). parallel decomposition change ordering
compared sequential one. Again, subproblems become available
end decomposition.

8

0 ;
run parallel
foreach
/* extend tuple parallel */
0 0 depthBoundedDFS (X , C H( ), D, {x1 , . . . , xd });

9

0;

5
6
7

top-down procedures assume variable ordering used decomposition static. next decomposition procedure bypasses limitation handles
branching strategy.
434

fiEmbarrassingly Parallel Search CP

Algorithm 2: Bottom-up decomposition.
1

2
3
4
5
6

7
8
9
10

Data: CSP (X , D, C), decomposition depth d? , subproblem limit P .
p 0;
/* Generate subproblems visiting top real tree. */
Node Callback decomposition(node)
depth(node) d?
sendSubProblem (node);
p p + 1;
p P
/* Decrease dynamically depth. */
d? max(1, d? 1);
P 2 P;
backtrack;
DFS (X ,C,D);

3.3.2 Bottom-Up Decomposition
bottom-up decomposition explores search frontier depth d? approximately p? nodes. simplest form, decomposition depth d? provided
user good knowledge problem. Algorithm 2 explores search frontier depth
d? using depth-first search illustrated Figure 2(a). search callback identifies
node level d? (line 2), sends immediately active path, defines subproblem,
subproblem solved worker. decomposition depth dynamic,
reduced number subproblems becomes large (line 6). aims
compensate poor choice decomposition depth d? . practice, depth reduced
one unit current number subproblems exceeds given limit P . limit
initially set P = 2 p? doubled time reached. contrary,
depth static (P = +) never changes whatever number subproblems.
practice, common user provides decomposition depth,
automated procedure without users intervention needed. Algorithm 3 aims
identifying topmost search frontier approximately p? open nodes sampling
estimation. procedure divided three phases: build partial tree sampling

Final depth

Search Frontier

Dynamic



p nodes

Static
P nodes

Initial depth

2P nodes

(a) Decomposition.

(b) Estimation.

Figure 2: Bottom-up decomposition estimation.
435

fiMalapert, Regin, & Rezgui

Algorithm 3: Bottom-up estimation.

1

2
3
4
5
6
7
8
9

10
11

Data: CSP (X , D, C) number subproblems p? .
Data: time limit t, node limit n, maximum depth large enough
Result: decomposition depth d?
/* Set counters width levels */
foreach [1, D] width[d] 0;
/* Build partial tree sampling. */
Node Callback estimation(node)
depth(node);

width[d] width[d] + 1;
width[d] p? 1 ;
else backtrack;
hasFinished (t,n) break;
DFS (X ,C,D);
/* Estimate level widths tree decomposition depth.
width estimateWidths(width);
d? estimateDepth(width, p? );

*/

top real search tree; estimate level widths real tree; determine
decomposition depth d? greedy heuristic.
Since need explore top search tree, upper bound decomposition depth fixed. maximum decomposition depth must chosen according
number workers expected number subproblems per worker.
small, decomposition could generate subproblems. large,
sampling time increases decomposition quality could decrease.
sampling phase builds partial tree p? open nodes level using
callback depth-first search. number open nodes level partial
tree counted callback. maximum depth reduced time p? nodes
opened given level (line 6). sampling ends within limits, top
tree entirely visited estimation needed. Otherwise (line 8), one needs
estimate widths topmost levels tree depending partial tree.
estimation straightforward adaptation one proposed Cornuejols, Karamanov,
Li (2006) deal n-ary search tree (line 10). practice, main issue
higher arity is, lower precision estimation. Therefore, greedy heuristic
determines decomposition depth based estimated number nodes per level,
also number nodes partial tree (line 11). heuristics minimizes
absolute deviation estimated number nodes expected number p? .
several levels identical absolute deviation, lowest level estimated
number subproblems greater equal p? selected.
3.4 Architecture Communication
describe messages exchanged actors depending problems type. Then,
typical use case illustrates solving process optimization problem. Briefly,
436

fiEmbarrassingly Parallel Search CP

communication network star network foreman acts pipe transmit
messages master workers.
3.4.1 Actors Messages
total number messages depends linearly number workers (w)
number subproblems (p). messages synchronous sake simplicity
means work must wait communications completed (Barney & Livermore,
2016). Interleaving computation communication single greatest benefit using
asynchronous communications since work done communications taking
place. However, asynchronous communications complicate architecture, instance
message requests answer.
Master control unit decomposes problem collects final results.
sends following messages: create foreman; give subproblem foreman;
wait foreman gather results; destroy foreman. master deals
foreman. decomposition time elapsed time create
wait messages. workers time elapsed time first give destroy
messages. wall-clock time elapsed time creation destruction
master.
Foreman central node star network. queuing system stores subproblems received master dispatches workers. also gathers results
collected workers. foreman allows master concentrate problems
decomposition, performance bottleneck, handling communications
workers. sends following messages: create worker; give subproblem worker;
collect (send) final results master; destroy worker. foreman
detects search ended, sends collect-message containing final results
master.
Workers search engines. send following messages: find subproblem (the
foreman must answer give-message); collect (send) results foreman.
results contain essential information solution(s) solving process. Workers
know foreman. worker acquires new work (receives give-message
foreman), acquired subproblem recomputed causes recomputation overhead.
work stealing context, Schulte (2000) noticed higher node search
tree, smaller recomputation overhead. construction, topmost nodes
used here.
3.4.2 Problems Types
discuss specificities first solution, solution, best solution searches.
First Solution Search search complete soon solution found.
workers must immediately terminated well decomposition procedure.
Solution Search search complete subproblems solved.
437

fiMalapert, Regin, & Rezgui

Best Solution Search main design issue best-solution search maintain
so-far best solution. sequential B&B algorithm always knows so-far best solution.
difficult achieve concurrent setting several workers. Maintaining best
solution worker could lead large communication synchronization overheads.
Instead prefer solution foreman workers maintain so-far best
solution follows. default, give collect messages foreman
workers carry objective information. Additionally, worker send better messages
foreman intermediate solution, foreman send best solution
workers. instance, worker finds new solution, informs foreman
sending better message solution accepted threshold function. Similarly,
foreman receives new solution collect better message, checks
whether solution really better. solution accepted threshold function,
foreman sends another better message workers. architecture sketched
entails worker might always know so-far best solution. consequence,
parts search tree explored, pruned away worker
exact knowledge. Thus, loose coupling might paid exploration
overhead.

Master

Foreman

Worker 1

Worker 2

opt

[Allocate Resources]
<< create >>
<< create >>
<< create >>
give

find
give
opt

better

[Best Solution Search]

give

give

give
collect
find
wait

give
collect
better

opt

better

[Best Solution Search]

collect

collect
opt
[Release Resources]
<< destroy >>
<< destroy >>

<< destroy >>

Master

Foreman
Master

Worker
Master1

Worker
Master2

Figure 3: Sequence diagram solving process two workers.
438

fiEmbarrassingly Parallel Search CP

3.4.3 Use Case
Figure 3 sequence diagram illustrating solving process optimization problem
two workers. shows actors operate chronological order.
first horizontal frame resource allocation. master creates foreman.
foreman creates workers. Immediately creation, master worker
load original problem. foreman transparently manages concurrent queue subproblems produced master consumed workers. that, workers
jumps search tree.
foreman creation, master starts decomposition original problem
p = 3 subproblems. soon subproblem generated, master gives
foreman. Here, give find messages interleaved node splitting
decomposition proposed Section 3.3.2. assignment splitting decomposition proposed
Section 3.3.1 would produce unique give message subproblems.
decomposition finished, master sends wait message foreman waits
collect response containing final result. last collect message triggers
resource deallocation.
time worker starving, asks foreman subproblem waits it.
Here, first subproblem assigned first worker second worker waits
second subproblem. Best Solution Search frames correspond specific messages
optimization problems. first worker quickly finds good solution sends
foreman via better message. second subproblem generated master
given foreman. turn, foreman gives second subproblem updated
objective information second worker. second problem quickly solved
second worker sends collect message foreman. collect message also
stands find message. Then, third, last, subproblem assigned second
worker.
foreman broadcasts better message good quality solution
received first worker. Note message useless first worker.
foreman detects termination solving process sends collect message
master three following conditions met: master waiting; subproblems
queue empty; workers starving. last horizontal frame resource
deallocation.
3.5 Queuing Determinism
foreman plays role queuing system receives subproblems master
dispatches workers. section, show EPS modified
return solution sequential algorithm useful several
scenarios debugging performance evaluation. Generally, queuing policy
applied select next subproblem solve.
Let us assume subproblems P1 , P2 , . . . , Pp sent foreman fixed
order case sequential top-down procedure bottom-up procedure.
Otherwise, fixed order subproblems obtained sorting subproblems.
first solution found sequential algorithm belongs satisfiable subproblem
Pi smallest index, i.e. leftmost solution. Let us assume parallel
439

fiMalapert, Regin, & Rezgui

algorithm finds first solution subproblem Pj j > i. Then,
necessary solve problems Pk k > j one must wait problem
Pk k < j determine leftmost solution, satisfiable subproblem
smallest index.
easily extended optimization problems slightly modifying cutting
constraints. Usually, cutting constraint stated new solution found
allows strictly improving solution. contrary constraints, cutting
constraint always propagated backtracking. Here, solution found solving
subproblem Pj , cutting constraint allows strictly improving solution
subproblems k j, also allows equivalent solution subproblems k < j.
So, parallel algorithm returns solution sequential one
subproblem visited order. Moreover, solution returned parallel
algorithm depend number workers, decomposition.
experiments, queuing policy FIFO policy ensures subproblems
solved order speedups relevant. However, guaranty
sequential parallel algorithms return solution.

4. Experimental Results
Here, describe experiments EPS carry detailed data analysis. aim
answer following questions. EPS efficient? different number workers?
different solvers? different computing platforms? Compared parallel
approaches? influence different components (decomposition procedures,
search strategies, constraint models)? EPS robust flexible? anomalies
occur?
Section 4.1 presents benchmark instances, execution environments, parameters settings, different implementations. First, Section 4.2, analyze evaluate
top-down bottom-up decomposition procedures well importance search
strategy, especially decomposition. Then, evaluate efficiency scalability
parallel solvers multi-core machine (Section 4.3), data center (Section 4.4),
cloud platform (Section 4.5). sections, compare implementations
EPS work stealing approaches whenever possible. Section 4.4, also analyze efficiency parallel solver depending search strategy. Section 4.6,
transform reasonable effort parallel solver distributed parallel solver
using batch scheduler provided data center. anomalies parallel solver
explained resolved distributed equivalent. Last, Section 4.7 discusses
performance parallel solvers compared static portfolios built underlying
sequential solvers data center.
4.1 Experimental Protocol
section, introduce benchmark instances, execution environments, metrics
notations. also give details implementations.
440

fiEmbarrassingly Parallel Search CP

4.1.1 Benchmark Instances
lot benchmark instances available literature. aim select difficult
instances various models represent problems tackled CP. Ideally, instance
difficult none solvers solve quickly. Indeed, parallel solving relevant
shortens long wall-clock time. Here, consider unsatisfiable, enumeration
optimization problems instances. ignore problem finding first feasible
solution parallel speedup completely uncorrelated number
workers, making results hard analyze. consider optimization problems
variability observed, lesser extent optimality
proof required. variability unsatisfiable enumeration instances lowered,
therefore, often used test bed parallel computing. Besides, unsatisfiable
instances practical importance, instance software testing, enumeration
important users compare various solutions.
first set called fzn selection 18 instances selected 5000
instances either repository maintained Kjellerstrand (2014) directly
Minizinc 1.6 distribution written FlatZinc language (NICTA Optimisation Research
Group, 2012). instance solved 500 seconds less 1 hour
Gecode. selection composed 1 unsatisfiable, 6 enumeration, 11 optimization
instances.
set xcsp composed instances categories ACAD REAL XCSP
2.1 (Roussel & Lecoutre, 2008). consists difficult instances solved within
24 hours Choco2 (Malapert & Lecoutre, 2014). first subset called xcsp1 composed
5 unsatisfiable 5 enumeration instances whereas second subset called xcsp2
composed 11 unsatisfiable 3 enumeration instances. set xcsp1 composed
instances easier solve xcsp2.
Besides, consider two classical problems, n-queens Golomb ruler
problems widely used literature (Gent & Walsh, 1999).
4.1.2 Implementation Details
implemented EPS method top three solvers: Choco2 2.1.5 written Java, Gecode
4.2.1 OR-tools rev. 3163 written C++. use two parallelism implementation
technologies: Threads (Mueller et al., 1993; Kleiman, Shah, & Smaalders, 1996)
MPI (Lester, 1993; Gropp & Lusk, 1993). typical difference
threads (of process) run shared memory space, MPI standardized
portable message-passing system exchange information processes running
separate memory spaces. Therefore, Thread technology handle multiple nodes
cluster whereas MPI does.
C++, use Threads implemented pthreads, POSIX library (Mueller et al.,
1993; Kleiman et al., 1996) used Unix systems. Java, use standard Java Thread
technology (Hyde, 1999).
many implementations MPI like OpenMPI (Gabriel, Fagg, Bosilca, Angskun,
Dongarra, Squyres, Sahay, Kambadur, Barrett, Lumsdaine, et al., 2004), Intel MPI (Intel
Corporation, 2015), MPI-CH (MPI-CH Team, 2015) MS-MPI (Krishna, Balaji, Lusk,
Thakur, & Tiller, 2010; Lantz, 2008). MPI standard API, characteristics
441

fiMalapert, Regin, & Rezgui

machine never taken account. So, machine providers like Bull, IBM Intel
provide MPI implementation according specifications delivered machine. Thus, cluster provided Bull custom Intel MPI 4.0 library, OpenMPI
1.6.4 also installed, Microsoft Azure supports MS-MPI 7 library.
OR-tools uses sequential top-down decomposition C++ Threads. Gecode uses
parallel top-down decomposition C++ Threads MPI technologies. fact, Gecode
use C++ pthread multi-core computer, OpenMPI data center,
MS-MPI cloud platform. Gecode OR-tools use lex variable selection
heuristic top-down decomposition requires fixed variable ordering. Choco2
uses bottom-up decomposition Java Threads. every case, foreman schedules
jobs FIFO mimic much possible sequential algorithm speedups
relevant. needed, master workers read model file.
always take value selection heuristic selects smallest value whatever
variable selection heuristic.
4.1.3 Execution Environments
use three execution environments representative computing platforms available nowadays.
Multi-core Dell computer 256 GB RAM 4 Intel E7-4870 2.40 GHz processors running Scientific Linux 6.0 (each processor 10 cores).
Data Center Centre de Calcul Interactif hosted Universite Nice Sophia
Antipolis provides cluster composed 72 nodes (1152 cores) running CentOS
6.3, node 64 GB RAM 2 Intel E5-2670 2.60 GHz processors (8 cores).
cluster managed OAR (Capit, Da Costa, Georgiou, Huard, Martin, Mounie, Neyron,
& Richard, 2005), i.e., versatile resource task manager. Thread technology
limited single node cluster, Choco2 use 16 physical cores whereas Gecode
use number nodes thanks MPI.
Cloud Computing cloud platform managed Microsoft company (Microsoft
Azure) enables deploy applications Windows Server technology (Li, 2009).
node 56 GB RAM Intel Xeon E5-2690E 2.6 GHz processors (8 physical cores)
allowed simultaneously use 3 nodes (24 cores) managed Microsoft HPC
Cluster 2012 (Microsoft Corporation, 2015).
computing infrastructures provide hyper-threading technologies. Hyper-threading
improves parallelization computations (doing multiple tasks once). core
physically present, operating system addresses two logical cores, shares
workload among possible. multi-core computer provides hyper-threading,
whereas deactivated cluster, available cloud.
4.1.4 Setting Parameters
time limit solving instance set 12 hours whatever solver.
number workers strictly less number cores (w < c), always
unused cores. Usually, one chooses w = c, workers work simultaneously.
multi-core computer, use two workers per physical core (w = 2c) hyperthreading efficient experimentally demonstrated Appendix A. target number
442

fiEmbarrassingly Parallel Search CP

p? subproblems depends linearly number w workers (p? = 30 w) allows
statistical balance workload without increasing much total overhead (Regin
et al., 2013).
experiments, network RAM memory loads low regards
capacities computing infrastructures. Indeed, total number messages depends
linearly number workers number subproblems. RAM pre-allocated
computing infrastructure allows it. Last, workers almost produce input/output
disk access.
4.1.5 Metrics Notations
Let solving time (in seconds) algorithm let su speedup parallel
algorithm. tables, row gives results obtained different algorithms given
instance. row, best solving times speedups indicated bold. Dashes
indicate instance solved algorithm. Question marks indicate
speedup cannot computed sequential solver solve instance
within time limit. Arithmetic means, abbreviated AM, computed solving times,
whereas geometrical means, abbreviated GM, computed speedups efficiency.
Missing values, i.e. dashes question marks, ignored computing statistics.
also use scoring procedure based Borda count voting system (Brams &
Fishburn, 2002). benchmark instance treated like voter ranks solvers.
solver scores points related number solvers beats. precisely,
solver scores points problem P comparing performance solver s0
follows:
gives better answer s0 , scores 1 point;
else answer gives worse answer s0 , scores 0 point;
else scoring based execution time comparison (s s0 give indistinguishable
answers).
Let t0 respectively denote wall-clock times solvers s0 given problems
instance. case indistinguishable answers, scores f (t, t0 ) according Borda system
used Minizinc challenge. But, function f capture users preferences
well. Indeed, solver solves n problems 0.1 seconds n others 1000 seconds
whereas solver s0 solves first n problems 0.2 seconds n others 500
seconds, solvers obtain score n whereas users would certainly
prefer s0 . So, use another scoring function g(t, t0 ) g(t) interpreted
utility function solving problems instance within seconds. function g(t)
strictly decreasing 0.5 toward 0. remaining points shared using function f .

f (t, t0 ) =

t0
+ t0

g(t, t0 ) = g(t)+(1g(t)g(t0 ))f (t, t0 )

g(t) =

1
2 (loga (t + 1) + 1)

Using function g (a = 10) previous example, solvers s0 respectively
scored 0.81 n 1.19 n points.
443

fiMalapert, Regin, & Rezgui

4.2 Analysis Decomposition
section, compare quality performance top-down bottom-up
decomposition procedures introduced Section 3.3.
4.2.1 Decomposition Quality
top-down decomposition always returns target number p? = 30 w subproblems
whereas guaranteed bottom-up decomposition. Figure 4(a) boxplot
number subproblems per worker (p / w) bottom-up decomposition
Choco2 depending number workers. Boxplots display differences among populations without making assumptions underlying statistical distribution:
non-parametric. box boxplot spans range values first quartile
third quartile. whiskers extend end box range equal
1.5 times interquartile range. points lie outside range whiskers
considered outliers: drawn individual circles.
number workers w {16, 80, 512}, decompositions xcsp instances
using one variable selection heuristic among lex, dom, dom/ddeg,dom/wdeg, dom/bwdeg,
impact, combined minVal, considered. bottom-up decomposition obtains
satisfying average performance (mostly 10 100 subproblems per worker)
respecting much possible branching strategy. However, anomalies occur.
First, decomposition sensitive shape search tree. Sometimes, model
contains variables large domains forbid accurate decomposition.
instance, first second levels knights-80-5 search tree respectively contain
6000 50000 nodes. also significant underestimation
tree size, especially branching high arity. instance, width second
level fapp07-0600-7 estimated around 950 nodes contains 6000
nodes. contrary, underestimation occur top nodes eliminated
search tree low arity. Apart underestimation, decomposition accurate
search trees low arity.
top-down decomposition accurate, requires fixed variable ordering, whereas
bottom-up decomposition less accurate, handles branching strategy.
1

0.8

100
instances (%)

subproblems per worker

1000

10

0.6

0.4

1
0.2

0.1
16

80

0

512

workers

Choco2 w=80
Choco2 w=512
Gecode w=80
Gecode w=512
0.1

1

10

100

time (s)

(a) Number subproblems per worker.

(b) Decomposition time.

Figure 4: Analysis decomposition procedures (w = 16, 80, 512).
444

1000

fiEmbarrassingly Parallel Search CP

4.2.2 Decomposition Time
Figure 4(b) gives percentage decompositions done within given time. Choco2
times reported variable selection heuristics xcsp instances. Gecode times
reported lex xcsp fzn instances.
implementation differences, times reported Choco2 Gecode
slightly different. Indeed, decomposition time alone given Gecode. Choco2
times take also account estimation time, time taken foreman fill
queue subproblems, time taken workers empty queue. Let us
also remind subproblems become available top-down decomposition
complete whereas become available fly bottom-up decomposition.
cases, reported time lower bound solving time.
top-down decomposition faster bottom-up decomposition
parallelism. fact, Gecode decomposition often faster estimation time alone.
One compelling example instance knights-80-5 highest time (around
800 seconds) well poor quality structure problem unsuited
bottom-up decomposition: variables large domains (more
6000 values); almost domain reduction top tree;
propagation long.
conclude, parallel top-down decomposition Gecode fast accurate
bottom-up decomposition offers greater flexibility, less robustness.
4.2.3 Influence Search Strategy
analyze influence search strategies decomposition resolution,
apply variable selection heuristic decomposition (master) another one
resolution (workers). Table 1 gives solving times combinations lex
dom solving instances xcsp1. Results reported significant
differences among solving times. choice variable selection heuristic critical
decomposition resolution. Indeed, initial choices made branching
least informed important, lead largest subtrees
search hardly recover early mistakes. on, master workers
use variable selection heuristic.

Instances

Worker
Master

costasArray-14
latinSquare-dg-8
lemma-100-9-mod
pigeons-14
quasigroup5-10
queenAttacking-6
squares-9-9

lex

dom

lex

dom

lex

dom

191.2
479.4
109.7
1003.8
182.2
872.4
126.8

240.9
323.8
125.9
956.3
125.3
598.3
1206.5

191.4
470.6
101.8
953.2
188.5
867.8
127.8

240.0
328.1
123.4
899.1
123.5
622.5
1213.0

Table 1: Solving times different search strategies (Choco2, multi-core, w = 2c = 80).
445

fiMalapert, Regin, & Rezgui

4.3 Multi-core
section, use parallel solvers based Thread technologies solve instances
xcsp1 n-queens problem using multi-core computer. Let us recall
two worker per physical core hyper-threading activated (w = 2c = 80). show
EPS frequently gives linear speedups, outperforms work stealing approach
proposed Schulte (2000), Nielsen (2006).
4.3.1 Performance Analysis
Table 2 gives solving times speedups parallel solvers using 80 workers
xcsp1 instances. Choco2 tested lex dom whereas Gecode OR-tools
use lex. also compared work stealing approach denoted Gecode-WS (Schulte,
2000; Nielsen, 2006). First, implementations EPS faster efficient
work stealing. EPS often reaches linear speedups number cores whereas never
happens work stealing. Even worse, three instances solved within 12
hours time limit using work stealing whereas using sequential solver.
Choco2, dom efficient parallel lex remains slightly slower
average. Decomposition key bad performance instances knights-80-5
lemma-100-9-mod. outlined before, decomposition knights-80-5 takes
1100 seconds generates much subproblems, forbids speedup. issue
lessened using sequential decomposition OR-tools resolved parallel
top-down decomposition Gecode. Note also sequential solving times OR-tools
Gecode respectively 20 40 times higher. Similarly, long decomposition time
Choco2 lemma-100-9-mod leads low speedup. However, moderate efficiency
Choco2 Gecode squares-9-9 caused decomposition.
Gecode OR-tools often efficient faster Choco2. solvers show
different behaviors even using variable selection heuristic
Instances

costasArray-14
knights-80-5
latinSquare-dg-8
lemma-100-9-mod
ortholatin-5
pigeons-14
quasigroup5-10
queenAttacking-6
series-14
squares-9-9
(t) GM (su)
Borda score (rank)

Choco2-lex

Choco2-dom

Gecode

OR-tools

Gecode-WS



su



su



su



su



su

191.2
1138.3
479.4
109.7
248.7
1003.8
182.2
872.4
39.3
126.8

31.4
1.2
39.0
4.0
30.0
13.8
30.7
23.4
29.9
19.0

240.0
1133.1
328.1
123.4
249.9
899.1
123.5
622.5
39.3
1213.0

38.8
1.5
39.2
4.1
36.0
15.5
32.5
28.5
32.9
16.1

62.3
548.7
251.7
6.7
421.7
211.8
18.6
15899.1
11.3
17.9

19.1
37.6
42.0
10.1
13.5
39.1
26.4
?
34.2
18.4

50.9
2173.9
166.6
1.8
167.7
730.3
17.0

16.2
81.4

33.4
18.5
35.2
22.9
38.1
18.5
36.9

28.7
35.0

594.0

4488.5
3.0
2044.6

22.8

552.3
427.8

2.0

2.4
22.3
2.8

21.5

0.7
0.8

439.2

15.9

497.2

17.4

1745.0

24.0

378.4

28.7

1161.9

3.3

20.6 (3)

19.7 (4)

26.1 (1)

22.8 (2)

9.8 (5)

Table 2: Solving times speedups (multi-core, w = 2c = 80). Gecode OR-tools use
lex heuristic.

446

fiEmbarrassingly Parallel Search CP

propagation mechanisms decompositions differ. Furthermore, parallel top-down
decomposition Gecode preserve ordering subproblems regard
sequential algorithm.
4.3.2 Variations N-Queens Problem
Here, verify effectiveness EPS classic CSP settings. consider four models
well-known n-queens problem (n = 17). n-queens puzzle problem placing
n chess queens n n chessboard two queens threaten other. Here,
enumerate solutions heuristics lex dom reasonable choices. models are:
allDifferent global constraints enforce arc-consistency (AC); allDifferent constraints enforce bound-consistency (BC); arithmetic inequalities constraints (NEQ);
dedicated global constraint (JC) (Milano & Trick, 2004, ch. 3).
Table 3 gives solving times speedups Choco2 80 workers
decomposition depth either 3 4. striking result splitting
technique gives excellent results, linear speedup 40 processors
exception JC model. unfortunate since JC model clearly best model
sequential solver. Here, dom always better choice lex. number
subproblems dom whatever model whereas total number nodes
changes. indicates filtering weak top search tree.
works report good results, often linear speedups n-queens problem. Bordeaux et al. (2009) reported linear speedups 30 cores 17 queens,
improvement 64 cores, whereas Machado et al. (2013) scales 512 workers using hierarchical work stealing approach. Menouer Le Cun (2014) reported
speedups around 8 using 12 cores 16 queens, Pedro, Abreu, Pedro, Abreu
(2010) reported speedups around 20 using 24 cores. Zoeteweij Arbab (2004) reported
linear speedups 16 cores 15 queens, Pedro et al. (2010) reported speedup
20 using 24 cores, So, EPS efficiency slightly average, similar
results observed 15 16 queens.
previous experimental setting favor EPS exploring search
space exhaustively, problem highly symmetric. Indeed, variance subproblems solving time low, especially higher levels consistency. Note
lower speedups JC model probably caused load balancing issues
subproblems NEQ model greater mean variance.

Model

lex

dom

d=3

BC
AC
NEQ
JC

d=4

d=3

d=4



su



su



su



su

838.8
3070.2
280.7
202.4

38.3
38.8
31.8
20.4

835.1
3038.9
241.9
196.9

38.5
39.3
36.9
21.0

640.4
2336.2
188.8
140.6

38.7
38.8
36.4
24.2

635.5
2314.7
181.1
148.8

39.0
39.2
37.9
22.9

Table 3: Variations 17 queens problem (Choco2, multi-core, w = 2c = 80).
447

fiMalapert, Regin, & Rezgui

Instances

lex


dom
su



dom/ddeg
su



dom/bwdeg

su



su

dom/wdeg


cc-15-15-2
1947.1 5.2 25701.7
?

1524.9 4.6 2192.1
costasArray-14
500.4 12.4
641.9 12.1 895.3 8.6 4445.0 2.4
649.9
crossword-m11
506.1 4.4




492.0 1.9
204.6
crossword-m1c2
2376.9 0.6 1173.9 0.6 1316.2 0.5 1471.3 0.7 1611.9
fapp07-0600-7





1069.5 2.1 2295.7
knights-20-9
359.3 17.2
353.9 17.3 357.4 14.9 5337.5 1.3
491.3
knights-25-9
855.3 17.8
840.6 18.0 986.1 13.3 13264.8 1.3 1645.2
knights-80-5
708.5 2.0
726.9 2.0 716.4 2.1 1829.5 0.9 1395.6
langford-3-17
38462.7
? 708.3 12.5 5701.6 2.5 6397.5 1.9 3062.2
40465.2
? 148.2 14.4 1541.9 2.2 1307.1 2.1
538.3
langford-4-18
langford-4-19

747.2 16.9
0.0 7280.1 2.3 2735.3
latinSquare-dg3
1161.7 14.3
903.2 12.2 812.0 14.4
416.9 4.2
294.8
lemma-100-9-mod
110.5 4.1
117.6 3.7 180.4 3.7
154.4 3.5
145.3
572.6 13.5
558.9 13.5 475.5 11.5
453.1 11.6 362.4
ortholatin-5
pigeons-14
1330.1 9.8 1492.6 8.3 1471.6 11.8 6331.1 2.6 2993.3
397.2 12.6 277.3 12.9 1156.6 3.6
733.5 5.2
451.5
quasigroup5-10
queenAttacking-6
2596.7 7.3 1411.8 10.6 4789.7 4.2 2891.0 1.9
706.4
queensKnights4





1517.8 0.2 5209.5
ruler-70-12-a3
137.4 16.8 2410.6 17.5


51.5 2.4
42.8
6832.0 3.9 4021.1 4.7 7549.2 2.2 1412.0 0.9 1331.3
ruler-70-12-a4
scen11-f5





38698.7 0.0

series-14
77.8 14.8
89.1 12.4 9828.6 3.4 1232.2 2.6
338.9
220.7 10.5 1987.4 7.2 129.7 9.4
697.2 2.2 115.9
squares-9-9
squaresUnsat5





3766.1 1.2 3039.8
(t) GM (su)
Borda score (rank)
1
4

5243.1

7.5

65.1 (6)

2332.2

8.6 2369.3

72.8 (5)

4.8

4282.3

49.6 (8)

1.6 1385.0

91.2 (2)

2

crossword-m1-words-05-06
crossword-m1c-words-vg7-7 ext
queensKnights-20-5-mul 5 squaresUnsat-19-19

3

su

impact


su

2.1 31596.1
?
11.4
652.2 10.5
5.1 179.5 2.9
0.6 4689.6 1.9
1.8


17.5 215.4 16.5
14.1 550.8 16.9
3.4
896.3 2.5
3.7 5995.6
?
4.8 1041.5 10.0
5.6 4778.9
?
11.3
28.7 5.0
3.5
226.8 2.5
13.7
641.7 10.6
5.1 3637.2 4.2
7.9
308.4 27.8
5.4 427.1 6.2
1.0


6.7
24.8 12.1
2.3 102.9 24.4
0.0


9.9
346.5 8.5
11.0
138.9 10.8
2.9


4.9

100.3 (1)

2823.9

7.7

81.4 (3)

latinSquare-dg-8

Table 4: Detailed speedups solving times depending variable selection heuristics
(Choco2, data center, w = 16).

30

25

speedup

20

15

10

5

0

lex

dom

ddeg

bwdeg

wdeg

impact

variable selection

Figure 5: Speedups variable selection heuristics (Choco2, data center, w = 16).

448

fiEmbarrassingly Parallel Search CP

4.4 Data Center
section, study influence search strategy solving times
speedups, scalability 512 workers, compare EPS work stealing approach.
4.4.1 Influence Search Strategy
study performance Choco2 using 16 workers solving xcsp instances using
variable selection heuristics presented Section 2.1. Figure 5 boxplot
speedups variable selection heuristic. First, speedups lower dom/bwdeg
decomposition effective. binary branching states constraint x =
left branch x 6= right branch. So, workload left right
branches imbalanced. case, positive decisions left branches
taken account. Second, without learning (lex dom), parallel algorithm
efficient robust terms speedup. learning (dom/bwdeg, dom/wdeg,
impact), parallel algorithm may explore different search tree sequential
one. Indeed, master explores top tree changes learning,
possibly branching decisions. worker also learns subproblems,
whole search tree. frequently causes exploration overhead solving
queensKnights-20-5-mul (twelve times nodes using dom/wdeg) or, sometimes gives
super-linear speedup solving quasigroup5-10 (three times less nodes using impact).
Last, low speedups occur variable selection heuristics.
Table 4 gives solving times speedups obtained different variable selection
heuristics. Borda scores computed Choco2 (Table 4) Gecode (Table 5). First,
variable selection heuristics strictly dominates others either sequential parallel.
However, dom/wdeg robust outlined Borda scores. fact, variability solving times different heuristics reduced parallelization,
remains important. Second, spite low speedups, dom/bwdeg remains second
best variable selection heuristic parallel solving best one sequential.
average, using advanced variable selection heuristics dom/bwdeg, dom/wdeg,
impact gives lower solving times lex dom spite lower speedups. highlights
fact decomposition procedures handle branching strategy. Section 4.6.1,
investigate low speedups instance crossword-m1c-words-vg7-7
caused variable selection heuristics.
4.4.2 Scalability 512 Workers
Table 5 compares Gecode implementations EPS work stealing (WS) solving
xcsp instances using 16 512 workers. EPS faster efficient work
stealing. 16 workers, work stealing ranked last using Borda score.
512 workers, EPS average almost 10 times faster work stealing. also
efficient parallelize sequential solver. multi-core
machine, Gecode faster Choco2 instances xcsp1. Here, performance
Gecode mitigated outlined Borda scores. Five instances
solved within time limit Gecode reported Table 5. Six instances
solved 16 workers whereas twelve instances solved sequential
solver. way comparison, five instances solved Choco2 using lex
449

fiMalapert, Regin, & Rezgui

w = 16

Instances

w = 512

EPS

cc-15-15-2
costasArray-14
crossword-m1c1
crossword-m12
knights-20-9
knights-25-9
knights-80-5
langford-3-17
langford-4-18
langford-4-19
latinSquare-dg-8
lemma-100-9-mod
ortholatin-5
pigeons-14
quasigroup5-10
queenAttacking-6
ruler-70-12-a3
ruler-70-12-a4
series-14
squares-9-9

EPS

WS



su



su



su



su


64.4
240.6
171.7
5190.7
7462.3
1413.7
24351.5
3203.2
26871.2
613.5
3.4
309.5
383.3
27.1
42514.8
96.6
178.9
22.5
22.8


13.6
13.1
14.5
?
?
11.5
?
?
?
13.1
14.7
14.1
14.5
13.5
?
15.1
14.4
13.4
11.1


69.3
482.1
178.5
38347.4

8329.2
21252.3
25721.2

621.2
5.8
335.8
6128.9
33.7
37446.1
105.5
185.2
56.9
44.3


12.7
6.6
13.9
?

2.0
?
?

13.0
8.6
13.0
0.9
10.8
?
13.8
13.9
5.3
5.7


3.6
18.7
13.3
153.4
214.9
49.3
713.5
94.6
782.5
23.6
1.0
10.4
15.3
1.7
1283.9
3.7
6.0
1.1
1.3


243.8
168.6
187.3
?
?
329.8
?
?
?
341.7
51.4
422.0
363.1
211.7
?
389.3
429.5
264.0
191.7


17.7
83.1
57.8
3312.4

282.6
7443.5
5643.1

124.4
2.5
71.7
2320.2
9.8
9151.5
67.7
34.1
8.2
7.6


49.8
38.0
43.0
?

57.5
?
?

64.7
19.7
61.0
2.4
37.3
?
21.5
75.5
36.9
33.7

5954.8

13.5

8196.7

7.4

178.53

246.2

1684.6

33.5

(t) GM (su)
Borda score (rank)
1

WS

76.9 (4)

crossword-m1-words-05-06

2

60.3 (7)

crossword-m1c-words-vg7-7 ext

Table 5: Speedups solving times xcsp (Gecode, lex, data center, w = 16 512).
heuristics whereas instances solved sequential parallel using dom/wdeg
dom/bwdeg. again, highlights importance search strategy.
Figure 6 boxplot speedups different numbers workers solving fzn
instances. median speedups around w2 average dispersion remains
low.
512
256

speedup (su)

128
64
32
16
8
4
2

16

32

64

128

256

512

workers (w)

Figure 6: Scalability 512 workers (Gecode, lex, data center).
450

fiEmbarrassingly Parallel Search CP

Instance

EPS

market split s5-02
market split s5-06
market split u5-09
pop stress 0600
nmseq 400
pop stress 0500
fillomino 18
steiner-triples 09
nmseq 300
golombruler 13
cc base mzn rnd test.11
ghoulomb 3-7-20
still life free 8x8
bacp-6
depot placement st70 6
open stacks 01 wbp 20 20 1
bacp-27
still life still life 9
talent scheduling alt film117
(t) GM (su)

WS



su



su

467.1
452.7
468.1
874.8
342.4
433.2
160.2
108.8
114.5

24.3
24.4
24.4
10.8
8.5
10.1
13.9
17.2
6.6

658.6
650.7
609.2
2195.7
943.2
811.0
184.6
242.4
313.1

17.3
17.0
18.7
4.3
3.1
5.4
12.1
7.7
2.4

154.0
1143.6
618.2
931.2
400.8
433.9
302.7
260.2
189.0
22.7

20.6
7.3
6.8
9.6
16.4
18.3
17.6
16.4
16.9
74.0

210.4
2261.3
3366.0
1199.4
831.0
1172.5
374.1
548.4
196.8
110.5

15.1
3.7
1.2
7.5
7.9
6.8
14.3
7.8
16.2
15.2

414.7

15.1

888.4

7.7

Table 6: Solving times speedups fzn (Gecode, lex, cloud, w = 24).

4.5 Cloud Computing
EPS deployed Microsoft Azure cloud platform. available computing
infrastructure organized follows: cluster nodes computes application; one head
node manages cluster nodes; proxy nodes load-balances communication
cluster nodes. contrary data center, cluster nodes may far
communication time may take longer. Proxy nodes requires 2 cores managed
service provider. Here, 3 nodes 8 cores 56 GB RAM memory provide 24
workers (cluster nodes) managed MPI.
Table 6 compares Gecode implementations EPS work stealing solving
fzn instances 24 workers. Briefly, EPS always faster work stealing,
therefore, efficient parallelize sequential solver. work
stealing suffers higher communication overhead cloud data center.
Furthermore, architecture computing infrastructure location cluster
nodes mostly unknown forbid improvements work stealing
proposed Machado et al. (2013), Xie Davenport (2010).
4.6 Embarrassingly Distributed Search
section, transform reasonable effort parallel solver (EPS) distributed
parallel solver (EDPS) using batch scheduler OAR (Capit et al., 2005) provided
451

fiMalapert, Regin, & Rezgui

data center. fact, batch scheduler OAR plays foreman. parallel Choco2
solver modified workers write subproblems files instead solving
them. Then, script submits jobs/subproblems OAR batch scheduler, waits
termination, gathers results. OAR schedules jobs cluster using
priority FIFO backfilling fair-share based priorities. Backfilling allows start
lower priority jobs without delaying highest priority jobs whereas fair-share means
user/application preferred way. main drawback new worker must
created subproblem. worker process allocated OAR predefined
resources. worker either sequential (EDS) parallel solver (EDPS).
approach offers practical advantage resource reservation data center.
Indeed, asking MPI process, one wait enough resources available
process starts. Here, resources (cores nodes) nibbled soon
become available drastically reduce waiting time. Furthermore, bypasses
limitations Threads Technology allowing use multiple nodes data center.
However, clearly increases recomputation overhead because, worker solves single
subproblem instead multiple subproblems. So, model creation initial propagation
realized often. also introduces non-negligible submission overhead
time taken create submit jobs OAR batch scheduler.
4.6.1 Anomaly crossword-m1c-words-vg7-7 ext
investigate low speedups solving instance crossword-m1c-words-vg7-7
variable selection heuristic (see Table 4). compare results parallel
(EPS, w = 16) distributed (EDS sequential worker) algorithms different decomposition depths (d = 1, 2, 3). Table 7 gives solving times, speedups, efficiencies.
number distinct cores used distributed algorithm bad estimator computing efficiencies, used short period time. Therefore,
number c cores used compute efficiency EDS EDPS estimated
ratio total runtime wall-clock time.
First, parallel algorithm always slower sequential one. However,
speedups distributed algorithms significant even decrease quickly
decomposition depth increases. fall efficiency shows EDS scalable
sequential workers. Indeed, recomputation, especially submission overhead
become important number subproblems increases.
Second, bad performance parallel algorithms caused statistically
imbalanced decomposition would observe similar performance distributed
algorithm. Profiling parallel algorithm particular instances suggests bad
EDS


p

2
3
4

186
827
2935

EPS (w = 16)



su

eff



su

eff

73.0
229.0
797.0

10.2
3.3
1.1

0.435
0.128
0.039

1069.9
1074.2
1091.8

0.7
0.7
0.7

0.044
0.044
0.044

Table 7: EDS EPS crossword instance (Choco2, dom, data center).
452

fiEmbarrassingly Parallel Search CP

performance comes underlying solver itself. Indeed, number instructions
similar sequential parallel algorithms whereas numbers context switches,
cache references cache misses increase considerably. fact, parallel algorithms
spent half time internal methods extensional constraints, i.e.
relation constraint specified listing satisfying tuples. issue occurred
computing infrastructure different Java virtual machines. Note instances
use extensional constraints, impose fewer consequences. issue would
happen MPI implementation shared memory. So, advocates
implementations EPS based MPI rather Thread Technology.
4.6.2 Variations Golomb Ruler Problem
Golomb ruler set marks integer positions along imaginary ruler
two pairs marks distance apart. number marks ruler
order, largest distance two marks length. Here, enumerate
optimal rulers (minimal length specific number marks) simple constraint
model inspired one Galinier, Jaumard, Morales, Pesant (2001)
heuristics lex dom reasonable choice. Table 8 gives solving times, speedups,
efficiencies parallel algorithm (w = 16), distributed algorithm sequential
workers (w = 1), distributed algorithms parallel workers (w = 16
worker decomposition depth dw = 2) different master decomposition depths d.
First, EPS obtains almost linear speedup decomposition depth large enough.
Without surprise, speedups lower enough subproblems. Second,
distributed algorithm EDS sequential workers efficient number subproblems remains low. Otherwise, still give speedups (dom), wastes
resources since efficiency low. fact, submitting many jobs batch
scheduler (lex) lead high submission overhead (around 13 minutes) globally degrades performance. Finally, distributed algorithms parallel workers offer
good trade-off speedups efficiencies allows use many resources
submitting jobs thus reducing submission recomputation overheads. Note EDS = 1 tested roughly equivalent EPS
16 workers, EDPS = 3 tested submission overhead becomes
important.

EDPS (w = 16, dw = 2)

EDS


p



su

eff



su

lex

1
2
3

20
575
14223


769.0
17880.0


66.8
2.9


0.846
0.005

572.0
497.0


89.7
103.3


dom

1
2
3

20
222
5333


2394.0
3018.0


50,5
40,0


0,989
0,146

1538.0
366.0


78,6
330,2


EPS (w = 16)


su

eff

0.968
0.232


11141.7
4084.2
3502.6

4.6
12.6
14.7

0.288
0.786
0.916

0,935
0,742


28299,9
9703,6
8266,6

4,3
12,4
14,6

0,267
0,778
0,914

eff

Table 8: EDS EPS Golomb Ruler 14 marks (Choco2, data center).
453

fiMalapert, Regin, & Rezgui

parallel approaches reported good performance Golomb ruler problem. instance, Michel et al. (2009), Chu et al. (2009) respectively reported linear
speedups 4 8 workers. EDS efficient work stealing proposed
Menouer Le Cun (2014) using 48 workers ruler 13 marks efficient
selfsplit Fischetti et al. (2014) using 64 workers ruler 14 marks.
Last, enumerated optimal Golomb Rulers 15 16 marks using EDPS.
Master workers use lex heuristic. master decomposition depth equal
2 generates around 800 hundreds subproblems. 16 parallel workers
decomposition depth dw equal 2. settings, used 700 cores
data center solving process. So, bypasses limitations number
cores used MPI imposed administrator. Furthermore, solving process starts
immediately cores grabbed soon become available whereas MPI
process waits enough cores becomes simultaneously available. Enumerating optimal
rulers 15 16 marks respectively took 1422 5246 seconds. knowledge,
first time constraint solver finds rulers, furthermore reasonable amount time. However, optimal rulers discovered via exhaustive
computer search (Shearer, 1990). recently, Distributed Computing Technologies Inc
(20) found optimum rulers 26 marks. Beside, plane construction (Atkinson & Hassenklover, 1984) allows find larger optimal rulers.
4.7 Comparison Portfolios
Portfolio approaches exploit variability performance observed several
solvers, several parameter settings solver. use 4 portfolios. portfolio
CPHydra (OMahony et al., 2008) uses features selection top solvers Mistral,
Gecode, Choco2. CPHydra uses case-based reasoning determine solve
unseen problem instance exploiting case base problem solving experience. aims
find feasible solution within 30 minutes, handle optimization solution problems time limit hard-coded. static fixed-size portfolios
(Choco2, CAG, OR-tools) use different variable selection heuristics (see Section 2.1) well
randomization restarts. Details Choco2 CAG found (Malapert &
Lecoutre, 2014). CAG portfolio extends Choco2 portfolio also using solvers
AbsCon Gecode. So, CAG always produces better results Choco2. OR-tools
portfolio gold medal Minizinc challenge 2013 2014. seem unfair
compare parallel solvers portfolios using different numbers workers, designing
scalable portfolio (up 512 workers) difficult task almost implementation
publicly available.
Table 9 gives solving times EPS portfolios solving xcsp instances
data center. First, CPHydra 16 workers solves 2 among 16 unsatisfiable instances
(cc-15-15-2 pigeons-14), less 2 seconds whereas difficult
approaches. OR-tools second less efficient approach solves fewer
problems often takes longer confirmed low Borda score. parallel Choco2
using dom/wdeg better average Choco2 portfolio even portfolio solves
instances much faster scen11-f5 queensKnights-20-5-mul. case,
diversification provided portfolio outperforms speedups offered parallel
454

fiEmbarrassingly Parallel Search CP

Instances

EPS
Choco2

cc-15-15-2
costasArray-14
crossword-m1-words-05-06
crossword-m1c-words-vg7-7 ext
fapp07-0600-7
knights-20-9
knights-25-9
knights-80-5
langford-3-17
langford-4-18
langford-4-19
latinSquare-dg-8
lemma-100-9-mod
ortholatin-5
pigeons-14
quasigroup5-10
queenAttacking-6
queensKnights-20-5-mul
ruler-70-12-a3
ruler-70-12-a4
scen11-f5
series-14
squares-9-9
squaresUnsat-19-19
Arithmetic mean
Borda score (rank)

Portfolio

Gecode

Choco2

CAG

OR-tools

w = 16

w = 16

w = 512

w = 14

w = 23

w = 16

2192.1
649.9
204.6
1611.9
2295.7
491.3
1645.2
1395.6
3062.2
538.3
2735.3
294.8
145.3
362.4
2993.3
451.5
706.4
5209.5
42.8
1331.3

338.9
115.9
3039.8


64.4
240.6
171.7

5190.7
7462.3
1413.7
24351.5
3203.2
26871.2
613.5
3.4
309.5
383.3
27.1
42514.8

96.6
178.9

22.5
22.8



3.6
18.7
13.3

153.4
214.9
49.3
713.5
94.6
782.5
23.6
1.0
10.4
15.3
1.7
1283.9

3.7
6.0

1.1
1.3


1102.6
6180.8
512.3
721.2
37.9
3553.9
9324.8
1451.5
8884.7
2126.0
12640.2
65.1
435.3
4881.2
12336.9
3545.8
2644.5
235.3
123.5
1250.2
45.3
1108.3
1223.7
4621.1

3.5
879.4
512.3
721.2
3.2
0.8
1.1
301.6
8884.7
2126.0
12640.2
36.4
50.1
4371.0
5564.5
364.3
2644.5
1.0
123.5
1250.2
8.5
302.1
254.3
4621.1

1070.0
1368.8
22678.1
13157.2



32602.6



4599.8
38.2
4438.7
12279.6
546.0


8763.1


416.2
138.3


1385.0

5954.8

178.5

3293.8

1902.7

7853.6

65.0 (3)

52.2 (5)

77.1 (1)

57.0 (4)

72.8 (2)

20.0 (6)

Table 9: Solving times EPS portfolio (data center).
B&B algorithm. emphasized CAG portfolio solves instances
obtains several best solving times. parallel Gecode 16 workers often slower
less robust portfolios Choco2 CAG. However, increasing number
workers 512 clearly makes fastest solver, still less robust five instances
solved within time limit.
conclude, Choco2 CAG portfolios robust thanks inherent diversification, solving times vary one instance another. 16 workers,
implementations EPS outperform CPHydra OR-tools portfolio, competitive
Choco2 portfolio, slightly dominated CAG portfolio. fact,
good scaling EPS key beat portfolios.

5. Conclusion
introduced Embarrassingly Parallel Search (EPS) method solving constraint
satisfaction problems constraint optimization problems. approach several
advantages. First, efficient method matches even outperforms state-of-the455

fiMalapert, Regin, & Rezgui

art algorithms number problems using various computing infrastructures. Second,
involves almost communication synchronization mostly relies underlying
sequential solver implementation debugging made easier. Last,
simplicity method allows propose many variants adapted specific applications
computing infrastructures. Moreover, certain restrictions, parallel algorithm
deterministic, even mimic sequential algorithm important
practice either production debugging.
several interesting perspectives around EPS. First, modified order
provide diversification learn useful information solving subproblems.
instance, easily combined portfolio approach subproblems
solved several search strategies. Second, thanks simplicity, simplest variants
EPS could implemented meta-searches (Rendl, Guns, Stuckey, & Tack, 2015),
would offer convenient way parallelize applications satisfactory efficiency. Last,
another perspective predict solution time large combinatorial problem, based
known solution times small set subproblems based statistical machine
learning approaches.

Acknowledgments
would like thank much Christophe Lecoutre, Laurent Perron, Youssef Hamadi,
Carine Fedele, Bertrand Lecun Tarek Menouer comments advices
helped improve paper. work supported CNRS OSEO
(BPI France) within ISI project Pajero. work granted access HPC
visualization resources Centre de Calcul Interactif hosted Universite Nice Sophia
Antipolis, also Microsoft Azure Cloud. also wish thank anonymous
referees comments.

Appendix A. Efficiency Hyper-Threading
section, show hyper-threading technology improves efficiency EPS
solving instances xcsp1 multi-core computer. Figure 7 boxplot
speedups provided hyper-threading parallel solver among Choco2, Gecode,
OR-tools. Here, speedups indicate many times parallel solver using 80 workers
(w = 2c) faster one using 40 workers (w = c). maximum speedup according
Amdahls law 2.
Choco2 tested lex dom whereas Gecode OR-tools use lex.
also compared work stealing approach proposed Schulte (2000) denoted
Gecode-WS. Hyper-threading clearly improves parallel efficiency EPS whereas
performance work stealing roughly remains unchanged. interesting
EPS high CPU demand resources physical core shared
two logical cores. Indeed, performance hyper-threading known
application-dependent. exception lemma-100-9-mod squares-9-9, Choco2
OR-tools faster 80 workers. lemma-100-9-mod, Choco2 decomposition
80 workers takes longer generates many subproblems. instance solved
456

fiEmbarrassingly Parallel Search CP

hyperthreading speedup

2

1

0.5

Choco2-lex

Choco2-dom

Gecode

OR-tools

Gecode-WS

Figure 7: Speedups provided hyper-threading (multi-core, w = 40, 80).
easily OR-tools (less two seconds) becomes difficult improve efficiency. squares-9-9, decomposition changes according number workers,
cannot explain hyper-threading improve EPS. parallel efficiency
Gecode reduced multiple instances interest hyper-threading less obvious
Choco2 OR-tools. conclude, hyper-threading globally improves efficiency
EPS limited interest work stealing.

References
Almasi, G. S., & Gottlieb, A. (1989). Highly Parallel Computing. Benjamin-Cummings
Publishing Co., Inc., Redwood City, CA, USA.
Amadini, R., Gabbrielli, M., & Mauro, J. (2013). Empirical Evaluation Portfolios
Approaches Solving CSPs Gomes, C., & Sellmann, M.Eds., Integration
AI Techniques Constraint Programming Combinatorial Optimization
Problems, Vol. 7874 Lecture Notes Computer Science, pp. 316324. Springer
Berlin Heidelberg.
Amdahl, G. (1967). Validity Single Processor Approach Achieving Large Scale
Computing Capabilities Proceedings April 18-20, 1967, Spring Joint Computer Conference, AFIPS 67, pp. 483485, New York, NY, USA. ACM.
Anderson, D. P., Cobb, J., Korpela, E., Lebofsky, M., & Werthimer, D. (2002). Seti@home:
experiment public-resource computing Commun. ACM, 45 (11), 5661.
Atkinson, M. D., & Hassenklover, A. (1984). Sets Integers Distinct Differences Tech.
Rep. SCS-TR-63, School Computer Science, Carlton University, Ottawa Ontario,
Canada.
Bader, D., Hart, W., & Phillips, C. (2005). Parallel Algorithm Design Branch
Bound G, H.Ed., Tutorials Emerging Methodologies Applications Operations Research, Vol. 76 International Series Operations Research & Management
Science, pp. 51544. Springer New York.
457

fiMalapert, Regin, & Rezgui

Barney, B., & Livermore, L. (2016). Introduction Parallel Computing
computing.llnl.gov/tutorials/parallel comp/.

https://

Bauer, M. A. (2007). High performance computing: software challenges Proceedings
2007 International Workshop Parallel Symbolic Computation, PASCO 07,
pp. 1112, New York, NY, USA. ACM.
Beck, C., Prosser, P., & Wallace, R. (2005). Trying Fail-First Recent Advances
Constraints, pp. 4155. Springer Berlin Heidelberg.
Bordeaux, L., Hamadi, Y., & Samulowitz, H. (2009). Experiments Massively Parallel
Constraint Solving. Boutilier (Boutilier, 2009), pp. 443448.
Boussemart, F., Hemery, F., Lecoutre, C., & Sais, L. (2004). Boosting Systematic Search
Weighting Constraints Proceedings 16th Eureopean Conference Artificial Intelligence, ECAI2004, including Prestigious Applicants Intelligent Systems,
PAIS, pp. 146150.
Boutilier, C.Ed.. (2009). IJCAI 2009, Proceedings 21st International Joint Conference
Artificial Intelligence, Pasadena, California, USA, July 11-17.
Brams, S. J., & Fishburn, P. C. (2002). Voting procedures Arrow, K. J., Sen, A. K.,
& Suzumura, K.Eds., Handbook Social Choice Welfare, Vol. 1 Handbook
Social Choice Welfare, chap. 4, pp. 173236. Elsevier.
Budiu, M., Delling, D., & Werneck, R. (2011). DryadOpt: Branch-and-bound distributed
data-parallel execution engines Parallel Distributed Processing Symposium
(IPDPS), 2011 IEEE International, pp. 12781289. IEEE.
Burton, F. W., & Sleep, M. R. (1981). Executing Functional Programs Virtual Tree
Processors Proceedings 1981 Conference Functional Programming
Languages Computer Architecture, FPCA 81, pp. 187194, New York, NY, USA.
ACM.
Capit, N., Da Costa, G., Georgiou, Y., Huard, G., Martin, C., Mounie, G., Neyron, P., &
Richard, O. (2005). Batch Scheduler High Level Components Proceedings
Fifth IEEE International Symposium Cluster Computing Grid (CCGrid05) - Volume 2 - Volume 02, CCGRID 05, pp. 776783, Washington, DC, USA.
IEEE Computer Society.
Choco, T. (2010). Choco: open source java constraint programming library Ecole des
Mines de Nantes, Research report, 1, 1002.
Chong, Y. L., & Hamadi, Y. (2006). Distributed Log-Based Reconciliation Proceedings
2006 Conference ECAI 2006: 17th European Conference Artificial Intelligence August 29 September 1, 2006, Riva Del Garda, Italy, pp. 108112, Amsterdam,
Netherlands, Netherlands. IOS Press.
Chu, G., Schulte, C., & Stuckey, P. J. (2009). Confidence-Based Work Stealing Parallel Constraint Programming Gent, I. P.Ed., CP, Vol. 5732 Lecture Notes
Computer Science, pp. 226241. Springer.
Chu, G., Stuckey, P. J., & Harwood, A. (2008). PMiniSAT: Parallelization MiniSAT
2.0 Tech. Rep., NICTA : National ICT Australia.
458

fiEmbarrassingly Parallel Search CP

Cire, A. A., Kadioglu, S., & Sellmann, M. (2014). Parallel Restarted Search Proceedings
Twenty-Eighth AAAI Conference Artificial Intelligence, AAAI14, pp. 842
848. AAAI Press.
Cornuejols, G., Karamanov, M., & Li, Y. (2006). Early Estimates Size Branchand-Bound Trees INFORMS Journal Computing, 18, 8696.
Crainic, T. G., Le Cun, B., & Roucairol, C. (2006). Parallel branch-and-bound algorithms
Parallel combinatorial optimization, 1, 128.
De Kergommeaux, J. C., & Codognet, P. (1994). Parallel logic programming systems ACM
Computing Surveys (CSUR), 26 (3), 295336.
Distributed Computing Technologies Inc (20). Distributed.net home page http://
www.distributed.net/.
Een, N., & Sorensson, N. (2005). MiniSat: SAT solver conflict-clause minimization
Sat, 5, 1.
Ezzahir, R., Bessiere, C., Belaissaoui, M., & Bouyakhf, E. H. (2007). DisChoco: platform
distributed constraint programming DCR07: Eighth International Workshop
Distributed Constraint Reasoning - conjunction IJCAI07, pp. 1621, Hyderabad, India.
Fischetti, M., Monaci, M., & Salvagnin, D. (2014). Self-splitting workload parallel
computation Simonis, H.Ed., Integration AI Techniques Constraint
Programming: 11th International Conference, CPAIOR 2014, Cork, Ireland, May 1923, 2014. Proceedings, pp. 394404, Cham. Springer International Publishing.
Gabriel, E., Fagg, G., Bosilca, G., Angskun, T., Dongarra, J., Squyres, J., Sahay, V., Kambadur, P., Barrett, B., Lumsdaine, A., et al. (2004). Open MPI: Goals, Concept,
Design next generation MPI implementation Recent Advances Parallel
Virtual Machine Message Passing Interface, pp. 97104. Springer.
Galea, Fran c., & Le Cun, B. (2007). Bob++ : Framework Exact Combinatorial
Optimization Methods Parallel Machines International Conference High Performance Computing & Simulation 2007 (HPCS07) conjunction 21st
European Conference Modeling Simulation (ECMS 2007), pp. 779785.
Galinier, P., Jaumard, B., Morales, R., & Pesant, G. (2001). Constraint-Based Approach
Golomb Ruler Problem 3rd International Workshop integration AI
techniques.
Gendron, B., & Crainic, T. G. (1994). Parallel branch-and-bound algorithms: Survey
synthesis Operations research, 42 (6), 10421066.
Gent, I., & Walsh, T. (1999). CSPLIB: Benchmark Library Constraints Proceedings 5th International Conference Principles Practice Constraint
Programming, CP 99, pp. 480481.
Gomes, C., & Selman, B. (1997). Algorithm Portfolio Design: Theory vs. Practice
Proceedings Thirteenth conference Uncertainty artificial intelligence, pp.
190197.
459

fiMalapert, Regin, & Rezgui

Gomes, C., & Selman, B. (1999). Search strategies hybrid search spaces Tools
Artificial Intelligence, 1999. Proceedings. 11th IEEE International Conference, pp.
359364. IEEE.
Gomes, C., & Selman, B. (2000). Hybrid Search Strategies Heterogeneous Search Spaces
International Journal Artificial Intelligence Tools, 09, 4557.
Gomes, C., & Selman, B. (2001). Algorithm Portfolios Artificial Intelligence, 126, 4362.
Gropp, W., & Lusk, E. (1993). MPI communication library: design portable
implementation Scalable Parallel Libraries Conference, 1993., Proceedings the,
pp. 160165. IEEE.
Gupta, G., Pontelli, E., Ali, K. A., Carlsson, M., & Hermenegildo, M. V. (2001). Parallel
execution prolog programs: survey ACM Transactions Programming Languages
Systems (TOPLAS), 23 (4), 472602.
Halstead, R. (1984). Implementation Multilisp: Lisp Multiprocessor Proceedings
1984 ACM Symposium LISP Functional Programming, LFP 84, pp.
917, New York, NY, USA. ACM.
Hamadi, Y. (2002). Optimal Distributed Arc-Consistency Constraints, 7, 367385.
Hamadi, Y., Jabbour, S., & Sais, L. (2008). ManySAT: Parallel SAT Solver. Journal
Satisfiability, Boolean Modeling Computation, 6 (4), 245262.
Haralick, R., & Elliott, G. (1980). Increasing Tree Search Efficiency Constraint Satisfaction Problems Artificial intelligence, 14 (3), 263313.
Harvey, W. D., & Ginsberg, M. L. (1995). Limited Discrepancy Search Proceedings
Fourteenth International Joint Conference Artificial Intelligence, IJCAI 95,
Montreal Quebec, Canada, August 20-25 1995, 2 Volumes, pp. 607615.
Heule, M. J., Kullmann, O., Wieringa, S., & Biere, A. (2012). Cube conquer: Guiding
CDCL SAT solvers lookaheads Hardware Software: Verification Testing,
pp. 5065. Springer.
Hirayama, K., & Yokoo, M. (1997). Distributed Partial Constraint Satisfaction Problem
Principles Practice Constraint Programming-CP97, pp. 222236. Springer.
Hyde, P. (1999). Java thread programming, Vol. 1. Sams.
Intel Corporation (2015). Intel MPI Library https://software.intel.com/en-us/intel
-mpi-library.
Jaffar, J., Santosa, A. E., Yap, R. H. C., & Zhu, K. Q. (2004). Scalable Distributed DepthFirst Search Greedy Work Stealing 16th IEEE International Conference
Tools Artificial Intelligence, pp. 98103. IEEE Computer Society.
Kale, L., & Krishnan, S. (1993). CHARM++: portable concurrent object oriented system
based C++, Vol. 28. ACM.
Kasif, S. (1990). Parallel Complexity Discrete Relaxation Constraint Satisfaction networks Artificial Intelligence, 45, 275286.
Kautz, H., Horvitz, E., Ruan, Y., Gomes, C., & Selman, B. (2002). Dynamic Restart Policies
18th National Conference Artificial Intelligence AAAI/IAAI, 97, 674681.
460

fiEmbarrassingly Parallel Search CP

Kjellerstrand, H. (2014). Hakan Kjellerstrands Blog http://www.hakank.org/.
Kleiman, S., Shah, D., & Smaalders, B. (1996). Programming threads. Sun Soft Press.
Korf, R. E., & Schreiber, E. L. (2013). Optimally Scheduling Small Numbers Identical
Parallel Machines Borrajo, D., Kambhampati, S., Oddi, A., & Fratini, S.Eds.,
ICAPS. AAAI.
Krishna, J., Balaji, P., Lusk, E., Thakur, R., & Tiller, F. (2010). Implementing MPI
Windows: Comparison Common Approaches Unix Recent Advances
Message Passing Interface, Vol. 6305 Lecture Notes Computer Science, pp.
160169. Springer Berlin Heidelberg.
Lai, T.-H., & Sahni, S. (1984). Anomalies Parallel Branch-and-bound Algorithms Commun. ACM, 27 (6), 594602.
Lantz, E. (2008). Windows HPC Server : Using Microsoft Message Passing Interface (MSMPI).
Le Cun, B., Menouer, T., & Vander-Swalmen, P. (2007). Bobpp http://forge.prism
.uvsq.fr/projects/bobpp.
Leaute, T., Ottens, B., & Szymanek, R. (2009). FRODO 2.0: open-source framework
distributed constraint optimization. Boutilier (Boutilier, 2009), pp. 160164.
Leiserson, C. E. (2010). Cilk++ concurrency platform Journal Supercomputing,
51 (3), 244257.
Lester, B. (1993). art parallel programming. Prentice Hall Englewood Cliffs, NJ.
Li, H. (2009). Introducing Windows Azure. Apress, Berkely, CA, USA.
Luby, M., Sinclair, A., & Zuckerman, D. (1993). Optimal Speedup Las Vegas Algorithms
Inf. Process. Lett., 47, 173180.
Machado, R., Pedro, V., & Abreu, S. (2013). Scalability Constraint Programming
Hierarchical Multiprocessor Systems ICPP, pp. 530535. IEEE.
Malapert, A., & Lecoutre, C. (2014). propos de la bibliotheque de modeles XCSP
10emes Journees Francophones de Programmation par Contraintes(JFPC15),
Angers, France.
Mattson, T., Sanders, B., & Massingill, B. (2004). Patterns Parallel Programming (First
ed.). Addison-Wesley Professional.
Menouer, T., & Le Cun, B. (2013). Anticipated Dynamic Load Balancing Strategy Parallelize Constraint Programming Search 2013 IEEE 27th International Symposium
Parallel Distributed Processing Workshops PhD Forum, pp. 17711777.
Menouer, T., & Le Cun, B. (2014). Adaptive N P Portfolio Solving Constraint
Programming Problems Top Parallel Bobpp Framework 2014 IEEE 28th
International Symposium Parallel Distributed Processing Workshops PhD
Forum.
Michel, L., See, A., & Hentenryck, P. V. (2009). Transparent Parallelization Constraint
Programming INFORMS Journal Computing, 21, 363382.
461

fiMalapert, Regin, & Rezgui

Microsoft Corporation (2015). Microsoft HPC Pack 2012 R2 HPC Pack 2012 http://
technet.microsoft.com/en-us/library/jj899572.aspx.
Milano, M., & Trick, M. (2004). Constraint Integer Programming: Toward Unified
Methodology. Springer US, Boston, MA.
Moisan, T., Gaudreault, J., & Quimper, C.-G. (2013). Parallel Discrepancy-Based Search
Principles Practice Constraint Programming, Vol. 8124 Lecture Notes
Computer Science, pp. 3046. Springer Berlin Heidelberg.
Moisan, T., Quimper, C.-G., & Gaudreault, J. (2014). Parallel Depth-bounded Discrepancy
Search Simonis, H.Ed., Integration AI Techniques Constraint Programming: 11th International Conference, CPAIOR 2014, Cork, Ireland, May 19-23,
2014. Proceedings, pp. 377393, Cham. Springer International Publishing.
MPI-CH Team (2015). High-Performance Portable MPI http://www.mpich.org/.
Mueller, F., et al. (1993). Library Implementation POSIX Threads UNIX.
USENIX Winter, pp. 2942.
Nguyen, T., & Deville, Y. (1998). distributed arc-consistency algorithm Science
Computer Programming, 30 (12), 227 250. Concurrent Constraint Programming.
NICTA Optimisation Research Group (2012). MiniZinc FlatZinc http://www.g12
.csse.unimelb.edu.au/minizinc/.
Nielsen, M. (2006). Parallel Search Gecode Masters thesis, KTH Royal Institute
Technology.
OMahony, E., Hebrard, E., Holland, A., Nugent, C., & OSullivan, B. (2008). Using casebased reasoning algorithm portfolio constraint solving Irish Conference
Artificial Intelligence Cognitive Science, pp. 210216.
Pedro, V., Abreu, S., Pedro, V., & Abreu, S. (2010). Distributed Work Stealing Constraint Solving CoRR, abs/1009.3800, 118.
Perron, L. (1999). Search Procedures Parallelism Constraint Programming Principles Practice Constraint Programming CP99: 5th International Conference,
CP99, Alexandria, VA, USA, October 11-14, 1999. Proceedings, pp. 346360, Berlin,
Heidelberg. Springer Berlin Heidelberg.
Perron, L., Nikolaj, V. O., & Vincent, F. (2012). Or-Tools Tech. Rep., Google.
Pruul, E., Nemhauser, G., & Rushmeier, R. (1988). Branch-and-bound Parallel Computation: historical note Operations Research Letters, 7, 6569.
Refalo, P. (2004). Impact-Based Search Strategies Constraint Programming Wallace,
M.Ed., Principles Practice Constraint Programming, 10th International Conference, CP 2004, Toronto, Canada, Vol. 3258 Lecture Notes Computer Science,
pp. 557571. Springer.
Regin, J.-C., Rezgui, M., & Malapert, A. (2013). Embarrassingly Parallel Search Principles Practice Constraint Programming: 19th International Conference, CP
2013, Uppsala, Sweden, September 16-20, 2013. Proceedings, pp. 596610. Springer
Berlin Heidelberg, Berlin, Heidelberg.
462

fiEmbarrassingly Parallel Search CP

Regin, J.-C., Rezgui, M., & Malapert, A. (2014). Improvement Embarrassingly Parallel Search Data Centers OSullivan, B.Ed., Principles Practice Constraint
Programming: 20th International Conference, CP 2014, Lyon, France, September 812, 2014. Proceedings, Vol. 8656 Lecture Notes Computer Science, pp. 622635.
Springer International Publishing, Cham.
Rendl, A., Guns, T., Stuckey, P., & Tack, G. (2015). MiniSearch: Solver-Independent
Meta-Search Language MiniZinc Pesant, G., Pesant, G., & Pesant, G.Eds.,
Principles Practice Constraint Programming: 21st International Conference,
CP 2015, Cork, Ireland, August 31 September 4, 2015, Proceedings, Vol. 9255
Lecture Notes Computer Science, pp. 376392. Springer International Publishing,
Cham.
Rezgui, M., Regin, J.-C., & Malapert, A. (2014). Using Cloud Computing Solving
Constraint Programming Problems First Workshop Cloud Computing Optimization, conference workshop CP 2014, Lyon, France.
Rolf, C. C., & Kuchcinski, K. (2009). Parallel Consistency Constraint Programming
PDPTA 09: 2009 International Conference Parallel Distributed Processing Techniques Applications, 2, 638644.
Rossi, F., Van Beek, P., & Walsh, T.Eds.. (2006). Handbook Constraint Programming.
Elsevier.
Roussel, O., & Lecoutre, C. (2008). Xml representation constraint networks format
http://www.cril.univ-artois.fr/CPAI08/XCSP2 1Competition.pdf.
Schulte, C. (2000). Parallel Search Made Simple Proceedings TRICS: Techniques
Implementing Constraint programming Systems, post-conference workshop
CP 2000, pp. 4157, Singapore.
Schulte, C. (2006). Gecode: Generic Constraint Development Environment http://www
.gecode.org/.
Shearer, J. B. (1990). New Optimum Golomb Rulers IEEE Trans. Inf. Theor., 36 (1),
183184.
Stephan, K., & Michael, K. (2011). SArTagnan - parallel portfolio SAT solver
lockless physical clause sharing Pragmatics SAT.
Sutter, H., & Larus, J. (2005). free lunch over: fundamental turn toward toward
Concurrency Dr. Dobbs Journal, 30, 202210.
Van Der Tak, P., Heule, M. J., & Biere, A. (2012). Concurrent cube-and-conquer Theory
Applications Satisfiability TestingSAT 2012, pp. 475476. Springer.
Vidal, V., Bordeaux, L., & Hamadi, Y. (2010). Adaptive K-Parallel Best-First Search:
Simple Efficient Algorithm Multi-Core Domain-Independent Planning
Proceedings Third International Symposium Combinatorial Search. AAAI
Press.
Wahbi, M., Ezzahir, R., Bessiere, C., & Bouyakhf, E.-H. (2011). DisChoco 2: Platform
Distributed Constraint Reasoning Proceedings IJCAI11 workshop
Distributed Constraint Reasoning, DCR11, pp. 112121, Barcelona, Catalonia, Spain.
463

fiMalapert, Regin, & Rezgui

Wilkinson, B., & Allen, M. (2005). Parallel Programming: Techniques Application
Using Networked Workstations Parallel Computers (2nd ed.). Prentice-Hall Inc.
Xie, F., & Davenport, A. (2010). Massively Parallel Constraint Programming Supercomputers: Challenges Initial Results Integration AI Techniques
Constraint Programming Combinatorial Optimization Problems: 7th International Conference, CPAIOR 2010, Bologna, Italy, June 14-18, 2010. Proceedings, Vol.
6140 Lecture Notes Computer Science, pp. 334338, Berlin, Heidelberg. Springer
Berlin Heidelberg.
Xu, L., Hoos, H., & Leyton-Brown, K. (2010). Hydra: Automatically Configuring Algorithms Portfolio-Based Selection AAAI Conference Artificial Intelligence,
Vol. 10, pp. 210216.
Xu, L., Hutter, F., Hoos, H., & Leyton-Brown, K. (2008). SATzilla: Portfolio-based Algorithm Selection SAT Journal Artificial Intelligence Research, 32, 565606.
Yokoo, M., Ishida, T., & Kuwabara, K. (1990). Distributed Constraint Satisfaction DAI
Problems Proceedings 1990 Distributed AI Workshop, Bandara, TX.
Zoeteweij, P., & Arbab, F. (2004). Component-Based Parallel Constraint Solver De
Nicola, R., Ferrari, G. L., & Meredith, G.Eds., Coordination, Vol. 2949 Lecture
Notes Computer Science, pp. 307322. Springer.

464

fiJournal Artificial Intelligence Research 57 (2016) 273-306

Submitted 11/15; published 10/16

Effective Heuristics Suboptimal Best-First Search
Christopher Wilt
Wheeler Ruml

wilt cs.unh.edu
ruml cs.unh.edu

Department Computer Science
University New Hampshire
Durham, NH 03824 USA

Abstract
Suboptimal heuristic search algorithms weighted A* greedy best-first search
widely used solve problems guaranteed optimal solutions expensive
obtain. algorithms crucially rely heuristic function guide search.
However, research building heuristics addresses optimal solving. paper,
illustrate established wisdom constructing heuristics optimal search fail
considering suboptimal search. consider behavior greedy best-first search
detail test several hypotheses predicting heuristic effective
it. results suggest predictive characteristic heuristics goal distance rank
correlation (GDRC), robust measure whether orders nodes according distance
goal. demonstrate GDRC used automatically construct abstractionbased heuristics greedy best-first search effective built
methods oriented toward optimal search. results reinforce point suboptimal
search deserves sustained attention specialized methods own.

1. Introduction
A* best-first search expands nodes order f (n) f (n) = g(n) + h(n).
optimal solutions provided A* (Hart, Nilsson, & Raphael, 1968)
desirable, time memory often prevent application algorithm. A* fails
either insufficient time memory, practitioners sometimes turn bounded
suboptimal algorithms may return optimal solution, return solution
guaranteed certain factor expensive optimal
solution.
well-known likely Weighted A* (Pohl, 1970), best-first
search expands nodes f order, f (n) = g(n) + w h(n) : w (1, ). Variants
Weighted A* used wide variety applications, including domain-independent
planning (Helmert, 2006; Richter & Westphal, 2010) robotics (Likhachev, Gordon, &
Thrun, 2003; Likhachev & Ferguson, 2009). Weighted A* also component number
anytime algorithms. example, Anytime Restarting Weighted A* (Richter, Thayer,
& Ruml, 2009) Anytime Repairing A* (Likhachev et al., 2003) use Weighted A*.
Anytime Nonparametric A* (van den Berg, Shah, Huang, & Goldberg, 2011) doesnt use
Weighted A* per se, rather limiting case, greedy best-first search (Doran & Michie,
1966), best-first search h(n). anytime algorithms have, built in, implicit
assumption Weighted A* high weight greedy best-first search find
solution faster A* Weighted A* small weight.
c
2016
AI Access Foundation. rights reserved.

fiWilt & Ruml

many popular heuristic search benchmark domains (e.g., sliding tile puzzles, grid path
planning, Towers Hanoi, TopSpin, robot motion planning traveling salesman
problem) increasing weight lead faster search, weight becomes
large Weighted A* expansion order greedy best-first search,
results fastest search. first contribution paper provide illustrations
how, domains, greedy best-first search performs worse Weighted A*,
sometimes even worse A*.
show failure greedy best-first search merely mathematical curiosity, occurring hand crafted counterexamples, rather phenomenon
occur real domains, including variants popular single-agent heuristic benchmarks.
second contribution empirically characterize conditions occurs, knowledge
important anyone using suboptimal search. also important first step
predictive theoretical understanding behavior suboptimal heuristic search.
root cause failure greedy best-first search ultimately traced back
heuristic, used guide greedy best-first search goal. A*,
number well-documented techniques constructing effective heuristic.
revisit guidelines context greedy best-first search. third contribution
show that, one follows well-established guidelines creating quality heuristic
A*, results poor. present several examples following A* wisdom
constructing heuristic leads slower results greedy best-first search. use
examples understand requirements greedy best-first search places
heuristic.
fourth contribution quantitative metric assessing greedy heuristic, goal
distance rank correlation (GDRC). GDRC used predict whether greedy
best-first search likely perform well. GDRC also used compare different
heuristics domain, allowing us make informed decisions
heuristic select variety choices, case abstraction-based
heuristics like pattern databases. quantitative metric used automatically
construct heuristic greedy best-first search iteratively refining abstraction
measuring good candidate heuristic is. show iteratively refining
abstraction using simple hill-climbing search guided GDRC yield heuristics
powerful built traditional methods oriented toward optimal search.
work increases understanding greedy best-first search, one popular scaleable heuristic search techniques. generally, suggests techniques
developed optimal search necessarily appropriate suboptimal search. Suboptimal search markedly different optimal search, deserves theory
methods.

2. Conundrum: Ineffective Weighted A*
starting point investigation heuristics suboptional search begins
curious empirical observation: although weighted A* one popular way
speeding heuristic search, increasing weight Weighted A* always work.
order get better grasp question increasing weight ineffective,
first need empirical data.
274

fiEffective Heuristics Suboptimal Best-First Search

Domain
Dynamic Robot
Hanoi (14)
Pancake (40)
11 Tiles (unit)
Grid
TopSpin (3)
TopSpin (4)
11 Tiles (inverse)
City Navigation 3 3
City Navigation 4 4
City Navigation 5 5

Average Solution
Length
187.45
86.92
38.56
36.03
2927.40
8.52
10.04
37.95
15.62
14.38
13.99

Total
States
20,480,000
268,435,456
8 1047
239,500,800
1,560,000
479,001,600
479,001,600
239,500,800
22,500
22,500
22,500

Branching
Factor
0-240
6
40
1-3
0-3
12
12
1-3
3-8
3-10
3-12

Unit-cost

Yes
Yes
Yes
Yes
Yes
Yes





Table 1: Domain Attributes benchmark domains considered
2.1 Benchmark Domains
consider six standard benchmark domains: sliding tile puzzle, Towers Hanoi
puzzle, grid path planning, pancake problem, TopSpin, dynamic robot navigation.
selected domains represent wide variety interesting heuristic
search features, branching factor, state space size, solution length. Since
would like compare A*, forced use somewhat smaller puzzles
possible solve using state art suboptimal searches. requirement problem
size problem solvable A*, Weighted A*, greedy best-first search
main memory (eight gigabytes). Basic statistics domain variants
summarized Table 1.
sliding tile 11 puzzle (3 4), used random instances Manhattan
distance heuristic. used 11 puzzle, rather 15 puzzle two reasons. First,
optimally solving 15 puzzles using A* without running memory requires significant
resources (At least 27 gigabytes, significantly eight gigabyte limit, according
Burns et al., 2012). addition that, consider sliding tile puzzle non-unit
cost functions. non-unit problems significantly difficult solve
unit-cost variants. non-unit version sliding tile puzzle consider uses inverse
cost function, cost moving tile n 1/n. Manhattan distance heuristic,
weighted appropriately, admissible consistent cost function.
Towers Hanoi, considered 14-disk-4 peg problem, used two disjoint pattern
databases, one bottom 12 disks, one top two disks (Korf & Felner,
2002). pancake problem, used gap heuristic (Helmert, 2010). grid path
planning, used maps 2000x1200 cells, 35% cells blocked, using
Manhattan distance heuristic four way movement. TopSpin puzzle, objective
sort circular permutation iteratively reversing continuous subsequence fixed
size. example TopSpin puzzle Figure 1. considered problem 12
disks turnstile would turn either three four disks, denoted TopSpin(3)
TopSpin(4). heuristic, used pattern database 6 contiguous disks present,
275

fiWilt & Ruml

Figure 1: 20 disk TopSpin puzzle.
remaining 6 disks abstracted. dynamic robot navigation problem, used
200x200 world, 32 headings 16 speeds. dynamic robot navigation, objective
navigate robot one location heading another location heading,
respecting dynamics robot. robot able change direction speed
instantaneously, combinations heading/speed reached given
state. addition that, states domain represent dead ends. example,
state robot moving full speed directly towards obstacle produce
children, robot crash matter control action applied.
objective minimize total travel time; actions cost.
also introduce new domain call City Navigation, designed simulate navigation
using system similar American interstate highways air transportation networks.
domain, cities scattered randomly 100x100 square, connected random
tour guarantees possible get city city. city also
connected nc nearest neighbors. links cities cost Euclidean distance
+ 2. city contains collection locations, randomly scattered throughout city
(which 1x1 square). Locations city connected random tour,
place also connected nearest np places. Links places cost true distance
multiplied random number 1 1.1. Within city special
nexus node contains connections city. goal navigate
randomly selected start location randomly selected end location. example,
might want go Location 3 City 4 Location 23 City 1. citys nexus
node Location 0, reach goal example problem must navigate
Location 3 Location 0 City 4, find path City 4 City 1, path
Location 0 City 1 Location 23 City 1. example instance type
seen Figure 2. circles left part figure locations, connected
locations. nexus node, Location 0, also connected nexus nodes neighboring
276

fiEffective Heuristics Suboptimal Best-First Search

Figure 2: city navigation problem np = nc = 3, 15 cities 15 locations
city.

cities. right part figure shows entire world, cities shrunk
circle.
City Navigation instances classified np nc . consider problems varying
numbers connections, always 150 cities 150 places city. Since
location within city global position, heuristic direct Euclidean distance.
domain, solutions vary length, straightforward manipulate accuracy
heuristic. domain bears similarity IPC Logistics domain
locations within cities connected roads, special airport locations used
travel cities.
2.2 Results
Figures 3 4 show number expansions required A*, greedy best-first search,
Weighted A* weights 1.1, 1.2, 2.5, 5, 10, 20. plots allow us compare
greedy best-first search Weighted A* A*, determine whether increasing
weight speeds search, slows search.
Looking plots Figure 3, easy see increase weight
number expansions goes down, Figure 4, opposite true.
domains, increasing weight initially speeds search, A* relaxed Weighted
A*, Weighted A* transforms greedy best-first search, number nodes
required solve problem increases. two domains, TopSpin turnstile
size 4 City Navigation 3 3, number nodes expanded greedy best-first search
higher number nodes expanded A*. Explaining phenomenon central
goal paper.
277

fiWilt & Ruml

600000

300000

200000

100000

16000

8000

0

0

0

A* 1.1 1.2 2.5 5 10 20 G

A* 1.1 1.2 2.5 5 10 20 G

Dynamic Robot

A* 1.1 1.2 2.5 5 10 20 G

TopSpin(3)

Unit Tile

1e+06

500000

Total Nodes Expanded

800

Total Nodes Expanded

Total Nodes expanded

Total Nodes Expanded

Total Nodes Expanded

Total Nodes Expanded

1.2e+06

40 Pancake Problem

Grid Navigation

14 disk Hanoi

40000

20000

0

0

A* 1.1 1.2 2.5 5 10 20 G

400

0

A* 1.1 1.2 2.5 5 10 20 G

A* 1.1 1.2 2.5 5

10 20 G

Figure 3: Domains increasing weight speeds search. Numbers denote Weighted
A* run specific weight, G denotes greedy best-first search.

3. Characteristics Effective Heuristics
established increasing weight Weighted A* always speed
search, situations actually slow search. fact A*
sometimes faster greedy best-first search sometimes slower greedy best-first
search suggests heuristics work well A* poorly greedy best-first search,
heuristics work well greedy best-first search A*. Thus,
question precisely driving difference, algorithm, A* greedy
best-first search, needs heuristic.
first review literature suggestions make good heuristic
A*. mind, apply A* rules constructing effective heuristic
greedy best-first search. leads us observations effective heuristics greedy
best-first search distinct common recommendations building good
heuristic A*.
3.1 Effective Heuristics A*
Much literature constitutes good heuristic centers well
heuristic works A*. finding optimal solutions using A*, first important
278

fiEffective Heuristics Suboptimal Best-First Search

Inverse Tile

TopSpin(4)

Total Nodes Expanded

Total Nodes Expanded

160000

80000

0

16000

8000

0

A* 1.1 1.2 2.5 5 10 20 G

A* 1.1 1.2 2.5 5 10 20 G
City Navigation 4 4

City Navigation 3 3

4000

Total Nodes Expanded

Total Nodes Expanded

3000

2000

0

2000

1000

0

A* 1.1 1.2 2.5 5

10 20 G

A* 1.1 1.2 2.5 5

10 20 G

Figure 4: Domains increasing weight slows search. Numbers denote
Weighted A* specified weight, G denotes greedy best-first search.

requirement heuristic admissible, meaning nodes n, h (n) true
cheapest path n goal greater equal h(n). heuristic
admissible, A* degenerates (no star) guaranteed find shortest
path.
generally believed consistency also important, due fact inadmissible heuristics lead exponential number re-expansions (Martelli, 1977).
situation, however, rarely arises practice Felner et. al. (2011) argue
inconsistency generally much problem generally believed.
widespread rule making good heuristic A* is: dominance good (Nilsson, 1980; Pearl, 1984). heuristic h1 said dominate h2 n G : h1 (n) h2 (n).
makes sense, due admissibility, larger values closer h . Furthermore
A* must expand every node n encounters f (n) less cost optimal
solution, large h often reduces expansions. Dominance represents current gold standard comparing two heuristics. practice, heuristics often informally evaluated
279

fiWilt & Ruml

average value value initial state benchmark set. either
case, general idea remains same: bigger heuristics better.
ignore effects tie breaking well effects duplicate states, A*
last iteration IDA* expand number nodes. allows us apply
formula Korf, Reid, Edelkamp (2001). predict number nodes
IDA* expand cost bound c is:
E(N, c, P ) =

c
X

Ni P (c i)

i=0

function P (h) KRE equation represents equilibrium heuristic distribution,
probability node chosen randomly uniformly among nodes
given depth brute-force search tree heuristic value less equal h (Korf
et al., 2001). quantity tends decrease h gets larger, depending nodes
space distributed. dominance relation also transfers KRE equation,
meaning heuristic h1 dominates different heuristic h2 , KRE equations predicts
expected expansions using h1 less equal expected expansions
using h2 .
considering pattern database (PDB) heuristics, Korfs conjecture (1997) lend

insight performance IDA*, tells us expect 1+log(m)
= n
amount memory PDB question takes up, amount time
expect IDA* search consume, n constant (Korf, 2007). willing
apply results regarding IDA* A* equation tells us expect larger
pattern databases provide faster search A*. summarize, prevailing wisdom
regarding heuristics bigger better, terms average heuristic value
pattern database size.
3.2 Behavior Greedy Best-First Search
shall see, advice regarding heuristics helpful considering
A*. happens apply wisdom greedy best-first search? answer
question taking detailed look behavior greedy best-first search three
benchmark problems: Towers Hanoi, TopSpin puzzle, sliding tile
puzzle.
3.2.1 Towers Hanoi
first domain consider Towers Hanoi. successful heuristic
optimally solving 4 peg Towers Hanoi problems disjoint pattern databases (Korf &
Felner, 2002). Disjoint pattern databases boost heuristic value providing information
disks top puzzle. example, consider 12-disk puzzle, split
two disjoint pattern databases: eight disks bottom pattern database, four disks
top pattern database. A*, best results achieved using full
disjoint pattern database. greedy best-first search, however, faster search results
use disjoint pattern database, instead use 8 disk pattern database.
exact numbers presented Unit rows Table 2. problems randomly
generated Towers Hanoi states, goal get disks onto first peg.
280

fiEffective Heuristics Suboptimal Best-First Search

Cost
Unit
Square
Rev Square

Heuristic
8/4 PDB
8/0 PDB
8/4 PDB
8/0 PDB
8/4 PDB
8/0 PDB

A* Exp
2,153,558
4,618,913
239,653
329,761
3,412,080
9,896,145

Greedy Exp
36,023
771
4,663
892
559,250
730

Table 2: Average number nodes expanded solve 51 12-disk Towers Hanoi problems.
30

25

25

20

Minimum h

Minimum h

20

15

15

10

10

5
00

5
200

400
600
Expansions

800

1000

00

5000 10000 15000 20000 25000 30000 35000
Expansions

Figure 5: minimum h value open search progresses, using different pattern
databases (single left, two disjoint additive ones right).

theory A* corroborates empirical evidence observed here: disjoint pattern database dominates single pattern database, absent unusual effects tiebreaking, surprise disjoint pattern database results faster A* search.
reason different behaviour A* greedy best-first search simple.
greedy best-first search using single pattern database, possible follow heuristic
directly goal, h value head open list monotonically decrease.
see this, note every combination bottom disks h value, possible
arrangements disks top also share h value. disks top
always moved around independently bottom disks are. Consequently,
always possible arrange top disks next move bottom disks
done, disturbing bottom disks, thus leaving h constant. Eventually,
h decreases progress made putting bottom disks problem
order. process repeats h = 0, point greedy best-first search simply
considers possible configurations top disks goal found.
phenomenon seen left pane Figure 5, minimum h value
open list monotonically decreases number expansions search done
281

fiWilt & Ruml

h = 10

h=9
Figure 6: Two Towers Hanoi states, one near goal (top) one far goal
(bottom).

increases. heuristic created single pattern database creates extremely effective
gradient greedy best-first search algorithm follow two reasons. First,
local minima all, global minimum goal is. context, define
minimum region space n , every path n goal node
least one node n h(n ) > h(n). Second, exactly 256 states associated
configuration bottom 8 disks. means every 256 expansions, h
guaranteed decrease. practice, state lower h tends found much faster.
right pane Figure 5, heuristic disjoint pattern database. see
h value head open list fluctuates substantially using disjoint
pattern database, indicating greedy best-first searchs policy follow small h much
less successful. states bottom disks near goal
paired poor arrangement disks top assigned large heuristic
values, delays expansion nodes. illustrated Figure 6. top
state significantly closer goal, despite higher h value bottom state.
ignore top disks completely, top state h = 1 compared bottom
states h = 9, correctly conveys fact top state significantly closer
goal. disjoint PDB causes substantial confusion greedy best-first search,
prior making progress 8 bottom disks, greedy best-first search
considers states top 4 disks closer destination. bottom state
expanded, produce children lower heuristic values explored
ever considering top state, state explored first. Eventually,
descendants bottom state h 9 explored, point top state
expanded, causes h value head open list go down.
summarize, disjoint pattern database makes gradient difficult
greedy best-first search follow nodes small h one
reason: near goal bottom pattern database returning small value,
particularly near goal, top disks arranged target peg.
suggests following observation regarding heuristics greedy best-first search:
282

fiEffective Heuristics Suboptimal Best-First Search

Observation 1. else equal, greedy best-first search tends work well
possible reach goal every node via path h monotonically decreases along
path.
may seem self-evident, example illustrated conflicts
common wisdom heuristic construction. also important note observation
makes comment relative magnitude heuristic, greedy best-first
completely irrelevant; matters relative ordering nodes ordered
using heuristic.
Another way view phenomenon analogy Sussman Anomaly (Sussman,
1975). Sussman anomaly occurs one must undo subgoal prior able
reach global goal. context Towers Hanoi problems, goal get
disks target peg, solving problem may involve
undoing subgoals putting top disks target peg. presence top
pattern database encourages greedy best-first searches privilege states subgoals
eventually undone accomplished.
Korf (1987) discusses different kinds subgoals, different kinds heuristic
searches able leverage subgoals. Greedy best-first search uses heuristic create
subgoals, attempting follow h goal. example, unit-cost domain, first
subgoal find node h = h(root) 1. heuristic follows Observation 1,
subgoals form perfect serialization, subgoals achieved one another.
heuristic deviates Observation 1, subgoals induced heuristic cannot
serialized.
Another important factor is, course, number distinct nodes heuristic
level one encounters prior finding better node. Consider, example, one worst
heuristics, h = 0. Technically, heuristic follows Observation 1 paths
contain nodes h = 0, one plateau contains nodes entire space,
obviously undesirable. Hoffmann (2005) discusses general idea using term maximal
bench exit distance, again, idea domains quantity
small, greedy best-first search Enforced Hill Climbing method perform well,
finding nodes lower h straightforward.
effects exacerbated cost disks top increased relative
cost disks bottom. define cost moving disk
proportional disks size, get Square cost metric, cost moving disk
n n2 . could also imagine tower stacked reverse, requiring larger
disks always top smaller disks, case get Reverse Square cost
function. either case, expect number expansions greedy best-first
search require lower using bottom pattern database,
indeed effect observe Table 2. However, top disks heavier disks
bottom, greedy best-first search suffers even considered unit
cost problem, expanding order magnitude nodes. pattern
database information top disks returning values substantially
larger bottom pattern database, due fact top pattern database
considers expensive operators. situation reversed, however, top
pattern database uses lowest cost operators, top pattern databases contribution
h much smaller proportion total expansions. Since greedy best-first search
283

fiWilt & Ruml

1400

1800

Greedy Search Disjoint PDB

Greedy Search Disjoint PDB

1600

1200

1400
1200

800

Minimum h

Minimum h

1000

1000

600

800
600

400

400
200
0
0

200
1000

2000
3000
Expansions

4000

0
0

5000

100000

200000

300000 400000
Expansions

500000

600000

700000

Figure 7: minimum h value open searches using disjoint pattern databases
different cost functions (square left, reverse square right).

performs best top pattern database isnt even present, naturally performs better
contribution top pattern database smaller.
phenomenon vividly illustrated execution times Figure 7. left
figure, disks top pattern database much cheaper move disks
bottom pattern database, therefore contributing much smaller proportion
total value h. right part figure, disks top pattern database
much expensive move disks bottom pattern database,
top pattern database makes much larger contribution h, causing substantially
confusion.
Hoffmann (2005) notes success FF heuristic many domains attributable fact h+ heuristic produces heuristic local minima.
heuristic local minima precisely matches Observation 1, always
possible reach goal via path h monotonically decreases.
3.2.2 TopSpin
considered TopSpin 12 disks turnstile flipped 4 disks using pattern
databases contained 5, 6, 7, 8 12 total disks.
Korfs conjecture predicts larger pattern databases useful
A*, therefore considered stronger heuristics, indeed, PDB
becomes larger, number expansions done A* dramatically decreases.
seen Figure 8. box plot (Tukey, 1977) labeled either A* G (for greedy
best-first search), number, denoting number disks PDB tracks.
box denotes middle 50% data, top box upper quartile,
bottom box bottom quartile, height box interquartile
range. horizontal line middle box represents median. grey stripe
indicates 95% confidence interval mean. circles denote points
1.5 times interquartile range away either first quartile third
284

fiEffective Heuristics Suboptimal Best-First Search

4/12 TopSpin Different PDB's

Expansions

60000

30000

A*5 G5 A*6 G 6 A*7 G7 A*8 G 8

Figure 8: TopSpin puzzle different heuristics. followed number denotes
number disks PDB heuristic. G followed number denotes
greedy best-first search number disks PDB heuristic.

quartile, whiskers represent range non-outlier data. move left
right, PDB heuristic tracks disks, gets substantially better A*.
also reductions greedy best-first search terms expansions, gains
nowhere near impressive compared A*.
reason greedy best-first search perform better given larger
heuristic that, larger heuristic, states h = 0 may still quite far
goal. example, consider TopSpin state represented follows, denotes
abstracted disk:
State 1: 0 1 2 3 4 5
turnstile swaps orientation 4 disks, configurations
putting abstracted disks order requires moving disk abstracted, as:
State 2: 0 1 2 3 4 5 6 7 8 9 11 10
TopSpin state, abstraction process takes largest N disks converts
abstracted disks, abstracted disks treated same, State 2 would
abstracted State 1, means abstracts state goal, making
heuristic 0. wanted expand State 2, could one children
State 3, whose heuristic still 0:
State 3: 0 1 2 3 4 5 6 7 10 11 9 8
Consider different child, example child obtained rotating middle 4 disks:
285

fiWilt & Ruml

State 4: 0 1 2 3 7 6 5 4 8 9 10 11
abstracts into:
State 5: 0 1 2 3 5 4
heuristic State 4 0, State 4 abstracts State 5. State 5
abstract state different State 1 (the abstracted goal) heuristic State
4 0.
abstract disks 6-11, still abstract state before, heuristic
still 0. Moving disk abstracted increase heuristic, moving
abstracted disks leave heuristic 0. Unfortunately, transforming State 2
goal cannot done without moving least one disks whose index 0
5, turnstile size 4.
means subgraph consisting nodes h = 0 TopSpin
problem disconnected. Thus, greedy best-first search encounters state h = 0,
state could h = 0 state connected goal via h = 0 states,
would desirable, state could h = 0 state connected goal via
paths contain least one h 6= 0 nodes, would undesirable. case,
greedy best-first search first expand h = 0 nodes connected first h = 0
node (which hypothesis connected goal node via paths containing h = 0
nodes), return expanding nodes h = 1, looking find different
h = 0 node.
abstraction controls number size h = 0 regions. example,
abstract 6 disks, two strongly connected regions h = 0 nodes, containing
360 nodes. instead abstract 5 disks, 12 strongly connected h = 0 regions,
10 nodes. heuristic abstracts 6 disks, 50% chance
given h = 0 node connected goal via h = 0 nodes, greedy
best-first search entered correct h = 0 region, finding goal node largely
chance. heuristic abstracts 5 disks, probability given h = 0
node connected goal via h = 0 nodes lower. correct h = 0 region
found, however, much easier find goal, region contains 10
nodes, compared 360 nodes. Empirically, see two effects roughly
cancel one another out, total number expansions done greedy best-first
search remains roughly constant matter heuristic used. brings us
next observation.
Observation 2. else equal, nodes h = 0 connected goal nodes
via paths contain h = 0 nodes.
One view important specific case Observation 1. Interestingly, types
heuristics, delete-relaxation heuristics used domain-independent planning,
obey observation implicitly never allowing non-goal states h values 0.
One obvious way make heuristic satisfy recommendation change
heuristic non-goal states minimum cost operator
domain cost . this, simply restate recommendation substituting
0, arrive similar result.
286

fiEffective Heuristics Suboptimal Best-First Search


8



9



10

3
7
11

4


1

9


6


3

11

Figure 9: Different tile abstractions. denotes tile abstracted..
Abstraction
Outer L (Figure 9 left)
Checker (Figure 9 right)
Outer L Missing 3
Outer L Missing 3 7
Instance Specific
GDRC Generated
Average 6-tile PDB
Worst 6-tile PDB

Greedy Exp
258
11,583
3,006
20,267
8,530
427
17,641
193,849

A* Exp
1,251,260
1,423,378
DNF
DNF
480,250
1,197,789
1,609,995
2,168,785

Table 3: Average number expansions required Greedy best-first search A* solve
3 4 tile instances different pattern databases. DNF denotes least one
instance would require 8GB solve.

3.2.3 Sliding Tiles
sliding tile puzzle one commonly used benchmark domains heuristic
search. such, domain one best understood. Pattern database heuristics
shown strongest heuristics domain, strongest
heuristics quite time (Korf & Taylor, 1996; Felner, Korf, Meshulam, & Holte,
2007). use 11 puzzle (4 3) case study smaller size puzzle
allows creating testing hundreds different pattern databases. central problem
constructing pattern database sliding tile puzzle selecting good abstraction.
abstraction keeps outer L, shown left part Figure 9,
extremely effective greedy best-first search, greedy best-first search
put abstracted tiles proper places, remains find goal,
easy using even completely uninformed search remaining puzzle,
6!2 = 360 states h = 0 h = 0 states form connected subgraph.
analogous heuristic directing search algorithm follow process outlined
Parberry (1995), large sliding tile puzzles solved first solving outer L,
treating remaining problem smaller sliding tile puzzle.
Compare happens greedy best-first search run checkerboard
abstraction, shown right part Figure 9. greedy best-first search identified node h = 0, high chance remaining abstracted tiles
configured properly, least one non-abstracted tiles
moved. effect seen Table 3, average number expansions required A* comparable either abstraction, average number expansions
required greedy best-first search larger two orders magnitude.
287

fiWilt & Ruml

sheer size PDB important greedy best-first search
A*. Table 3, see weaken pattern database removing 3
7 tiles, number expansions required increases factor 10 greedy best-first
search. A* using PDB 3 tile missing, 3 instances unsolvable within 8
GB memory (approximately 25 million nodes Java implementation).
3 7 tile missing, A* unable solve 16 instances within limit.
worth noting even without 3 tile, outer L abstraction still effective
greedy best-first search compared checkerboard abstraction.
underlying reason behind inefficiency greedy best-first search using certain
pattern databases fact less useful pattern databases nodes h = 0
nowhere near goal. provides evidence favor Observation 2;
greedy best-first search concentrates efforts finding expanding nodes low h
value, nodes are, reality, near goal, clearly causes problems
algorithm. A* uses f , g contributes f , A* able eliminate
states consideration (not expand them) high g value helps give
node high f value, causes A* relegate node back expansion
queue.
checkerboard pattern database also helps make clear another problem facing
greedy best-first search heuristics. algorithm discovers node h = 0,
node connected goal via h = 0 nodes, algorithm eventually run
h = 0 nodes expand, begin expanding nodes h = 1. expanding
h = 1 nodes, greedy best-first search either find h = 0 nodes examine goals,
eventually exhaust h = 1 nodes well, forced consider h = 2
nodes. natural question ask far algorithm back
able find goal. leads us next observation.

Observation 3. else equal, greedy best-first search tends work well
difference minimum h value nodes local minimum minimum
h allow search escape local minimum reach goal low.

phenomenon clearly illustrated considering instance-specific pattern databases
(Holte, Grajkowskic, & Tanner, 2005). instance-specific pattern database, tiles
start closest goals abstracted first, leaving tiles furthest
away goals represented pattern database. helps maximize
heuristic values states near root, due consistency also
undesirable side effect making states required included path goal
high heuristic values well. Raising heuristic value initial state helpful
A* search, evidenced reduction number expansions A* using instancespecific abstractions size, shown Table 3. Unfortunately, approach
still powerful greedy best-first search simpler outer L abstraction, even
smaller variant missing 3. instance-specific pattern databases
use patterns difficult greedy best-first search use effectively, similar
problems encountered using checkerboard abstraction.
288

fiEffective Heuristics Suboptimal Best-First Search

Domain

Greedy
Works

Greedy
Fails

Towers Hanoi
Grid
Pancake
Dynamic Robot
Unit Tiles
TopSpin(3)
TopSpin(4)
Inverse Tiles
City Nav 3 3
City Nav 4 4

Heuristic
% Error
29.47
25.11
2.41
15.66
33.37
25.95
32.86
29.49
44.51
37.41

h(n)-h (n)
Correlation
(Pearson)
0.9652
0.9967
0.9621
0.9998
0.7064
0.5855
0.2827
0.6722
0.5688
0.7077

h(n)-h (n)
Correlation
(Spearman)
0.9433
0.9958
0.9593
0.9983
0.7065
0.4598
0.3196
0.6584
0.6132
0.7518

h(n)-h (n)
Correlation
(Kendall)
0.8306
0.9527
0.9198
0.9869
0.5505
0.4158
0.2736
0.4877
0.4675
0.6238

Table 4: Average % error correlation h(n) h (n)

4. Predicting Effectiveness Greedy Heuristics
previous section, saw common wisdom regarding effective heuristics
optimal search carry suboptimal search. Instead, examples motivated
three general observations regarding greedy best-first search looks heuristic.
qualitative observations perhaps helpful heuristics heuristic design,
also useful simple, quantitative metric evaluating comparing heuristics.
begin considering two intuitively reasonable quantitative metrics, percent
error h, correlation h h . metrics, show
metric cannot used predict whether greedy best-first search perform
worse Weighted A*. consider measure search distance go called .
(n) h change graph making edges cost 1. find
correlation h used predict greedy best-first search
perform poorly.
4.1 Percent Error h(n)
first metric consider perhaps intuitive measure heuristic performance:
percent error h. define percent error heuristic h (n)h(n)
. Since greedy
h (n)
best-first search increases importance heuristic, reasonable conclude
heuristic large amount error, relying upon heavily, greedy best-first
search does, going lead fast search.
Table 4, average percent error heuristic domains
considered. Surprisingly, average percentage error bears little relation whether
greedy best-search poor choice. Towers Hanoi, unit tiles, TopSpin(3),
three domains greedy best-first search effective, much heuristic
error domains greedy best-first search works poorly. leads us conclude
cannot measure average heuristic percent error use predict whether
increasing weight speed slow search.
289

fiWilt & Ruml

see intuitively makes sense, note greedy best-first search really
requires nodes get put h (n) order heuristic. exact magnitude,
therefore error, heuristic unimportant, magnitude huge effect
average percent error. seen consider heuristic h(n) = h R(n) : R R+
large tiny R, always guide greedy best-first search directly
optimal goal, exhibiting arbitrarily high average percent error heuristic
R increases decreases away 1.
4.2 h h Correlation
next metric consider correlation h h . considering
percent error h metric, noted greedy best-first search run time linear
solution length optimal solution nodes h (n) order. One way
quantify observation measure correlation two values.
three different ways.
well known correlation coefficient Pearsons correlation coefficient r,
measures well relationship h(n) h (n) modeled using linear
function. relationship would mean weighting heuristic appropriately
reduce error heuristic, could reasonably expected lead faster
search. addition, relationship h(n) h (n) linear function,
order preserved: putting nodes order h(n) also put nodes order
h (n), leads effective greedy best-first search. domain, calculated
Pearsons correlation coefficient h (n) h(n), results second
column Table 4.
Another reasonable way measure heuristic correlation use rank correlation.
Rank correlation measures well one permutation (or order) respects another permutation (or order). context search, use ask similar order one
gets putting nodes h order order one gets putting nodes h order. Rank
correlation coefficients useful less sensitive outliers, able
detect relationships linear.
Spearmans rank correlation coefficient () best known rank correlation coefficient.
Pearsons r ranked variables. means smallest N heuristic
values mapped 0, largest n heuristic values mapped N . done
h h , point simply calculate Persons r using rankings.
context greedy best-first search, Spearmans rank correlation coefficient high,
means h(n) h (n) put nodes close order. Expanding
nodes h (n) order leads greedy best-first search running time linear solution
length, reasonable conclude strong Spearmans rank correlation coefficient
h (n) h(n) would lead effective greedy best-first search. domain,
calculate Spearmans rank correlation coefficient h (n) h(n),
results third column Table 4.
natural metric measuring relationship achieved using Kendalls
(1938). Kendalls another rank correlation coefficient, measures amount
concordance two rankings. Concordance rankings two
elements agree. context greedy best-first search, concordant pair pair
290

fiEffective Heuristics Suboptimal Best-First Search

nodes h(n1 ) > h(n2 ) h (n1 ) > h (n2 ) h(n1 ) < h(n2 ) h (n1 ) < h (n2 ).
Kendalls proportion pairwise comparisons concordant. h puts nodes
h order, pairwise comparisons concordant, Kendalls 1. h puts
nodes reverse h order, comparisons discordant, Kendalls -1.
sorting nodes h puts nodes random order, expect half comparisons
concordant half comparisons discordant.
Kendalls also understood context bubble sort. Kendall distance
number swaps bubble sort would order change one list
other. case, number swaps bubble sort would rearranging list
nodes sorted h list sorted h . Kendalls calculated normalizing
Kendall distance, done dividing N (N 1)/2. 1
Since rank correlation coefficients, related, argue
natural statistic. Consider question: given open list containing n
nodes, likely node smallest h front open
list, given nodes ordered h? use predict node will,
average, middle list h h completely unrelated, closer
front open list stronger (h, h ) correlation is. reason
assume nodes open list random selection nodes, tells us often
random comparison correct. use therefore predict far back node
minimum h is. natural interpretation, making natural
statistic. worth nothing generally related one another, one
used predict (Gibbons, 1985). relationship means practice,
generally possible use either metric.
Returning Table 4, results lead us reject correlation h h
metric predicting well greedy best-first search work. three correlation
coefficients, examples domains greedy best-first search fails high
h(n)-h (n) correlations, examples domains greedy best-first search works well
poor h(n)-h (n) correlations. example, TopSpin(3), Kendalls
.42, lower Inverse Tiles City Navigation problems
consider.
4.3 h Correlation
strategy greedy best-first search discover goal quickly expanding nodes
small h(n) values. nodes small h(n) far away goal reasonable
believe greedy best-first search would perform poorly. denote (n) count
edges node n nearest goal, distance measured summing
cost edges path, rather counting edges path.
(n) equivalent h (n) modify graph edges cost 1. Looking
plot h(n) vs h (n) left half Figure 10, see City Navigation
4 4 reasonable relationship h(n) h (n), nodes low
h(n) tend small h (n) values. denote distance nearest goal terms
1. Malte Helmert noted (personal communication) Kendalls , described, ideal metric
use sequences contain ties. integer-valued heuristics, especially, ties may common.
One way account ties rankings use Kendalls -b statistic (Kendall & Gibbons, 1990)
instead (also known -a). Kendalls -b accounts ties rankings.

291

fiWilt & Ruml

h vs h* City Navigation 4 4

h vs d* City Navigation 4 4
18

120

d*

h*

12

60

6
0
0

80

160

h

40

80

h

Figure 10: Plot h(n) vs h (n), h(n) vs (n) City Navigation 4 4
Domain

Greedy
Works

Greedy
Fails

Towers Hanoi
Grid
Pancake
Dynamic Robot
Unit Tiles
TopSpin(3)
TopSpin(4)
Inverse Tiles
City Nav 3 3
City Nav 4 4

h(n)-d (n)
Correlation
(Pearson)
0.9652
0.9967
0.9621
0.9998
0.7064
0.5855
0.2827
0.5281
0.0246
0.0853

h(n)-d (n)
Correlation
(Spearman)
0.9433
0.9958
0.9593
0.9983
0.7065
0.4598
0.3196
0.5173
-0.0338
0.1581

h(n)-d (n)
Correlation
(Kendall)
0.8306
0.9527
0.9198
0.9869
0.5505
0.4158
0.2736
0.3752
-0.0267
0.1192

Table 5: Correlation h(n) (n)

number edges state space graph (n). right half Figure 10 shows
plot h(n) vs (n). clearly see City Navigation 4 4 domain,
almost relationship h(n) (n), meaning nodes receive small
h(n) value found distance away goal, could explain greedy
best-first search works poorly domain, despite fact h(n) h (n)
closely related.
nodes small h(n) values also likely small (n) values (and
nodes therefore close goal, terms expansions away) expanding nodes
small h(n) values quickly lead goal. converse also reasonable. nodes
small h(n) value uniform distribution (n) values (and thus many
nodes far away goal terms expansions away), expanding nodes
quickly lead goal.
292

fiEffective Heuristics Suboptimal Best-First Search

7.0
6.5

log(Expansions)

6.0
5.5
5.0
4.5
4.0
3.5
3.0
2.5
0.0

0.1

0.2

0.3

0.4
GDRC

0.5

0.6

0.7

0.8

Figure 11: Average log expansions done greedy best-first search different heuristics, plotted according GDRC.

domain, quantify concept calculating Pearsons correlation coefficient, Spearmans rank correlation coefficient, Kendalls (n) h(n).
Looking Table 5, see that, using Kendalls Pearsons r, finally
able separate domains greedy best-first search performs well domains greedy best-first search performs poorly. Kendalls , draw
line approximately 0.4 used separate domains greedy best-first
search works well domains greedy best-first search works poorly. Likewise,
Pearsons r, draw line approximately .55. call type metric
Goal Distance Rank Correlation (GDRC) and, unless otherwise noted, compute using
Kendalls .
correlation (n) h(n) connects three observations, although
connection mathematical necessity (as counterexamples constructed).
Note heuristic obeys Observation 1 produce paths h monotonically
decreases goal. Consider nodes along path goal. hypothesis, h
monotonically decrease along path. Now, consider one nodes goal end
path. Since h monotonically decreases along path, nodes goal end
path low h, near end path, also low
value. little else said nodes general, restriction improves
heuristics GDRC compared situation nodes low allowed
high h values. similar argument used show following Observation 2
helps produce heuristic high GDRC.
Observation 3 discusses nodes local minimum, difference h nodes
local minimum, nodes edge local minimum. assume
order escape local minimum one must go one nodes edge
293

fiWilt & Ruml

local minimum, know nodes local minimum must higher
nodes edge local minimum, also know h lower
(because node local minimum). means h ranking incorrectly
orders nodes local minimum compared nodes edge local
minimum, clear problem producing high GDRC. nodes local minimum
low get goal high h node, relationship
observation GDRC weaker. Consider personal transportation
example. action as, call taxi might result reaching states near goal
one step, high cost. heuristic recognizes cost action, node
correctly high h, close goal measured
call taxi path. situation clearly causes problems domains attempting
follow Observation 3, believe domains kind attribute are, practice,
quite uncommon. example, none example domains exhibit trait.
4.4 Comparing Heuristics
quantitative metric, GDRC used compare different heuristics
domain. test effectiveness, ran experiments Towers Hanoi
problem using 17 different disjoint non-disjoint pattern databases. considered
pattern databases 3 8 disks, well selection pairings PDBs
total number disks less equal 12. pattern database,
calculated GDRC heuristic produced PDB. Figure 11 plot,
PDB, GDRC PDB X axis average log number
expansions required greedy best-first search solve 51 random 12-disk Towers Hanoi
problems axis. see figure, GDRC roughly
0.4, greedy best-first search performs poorly, GDRC increases, average
number expansions done greedy best-first search decreases. suggests
possible use GDRC directly compare heuristics one another.
see similar behavior different domain left part Figure 12.
dot represents one 462 possible disjoint 5/6 pattern databases (one 6 tile PDB
one 5 tile PDB disjoint) 3 4 sliding tile puzzle inverse costs.
axis log average expansions required solve 100 random instances.
X axis GDRC. Since using non-unit problem, h same,
also calculate correlation h h . right part Figure 12,
correlation X axis.
see, GDRC rank correlation h h yield useful
information well greedy best-first search likely work.
domains tested, correlation h neatly predicts
greedy best-first search performs worse Weighted A* (or A*). perfect, however.
consider heuristic h(n) = h (n), measure correlation h(n)
h (n) perfect, relationship h(n) (n) heuristic could
arbitrarily poor. heuristic approaches truth, h(n)-h (n) correlations
approach 1, allows Weighted A* scale gracefully, greedy best-first search
linear run time, matter correlation h(n) (n) is.
situation, looking solely correlation h(n) (n) determine whether
294

fi5.0

5.0

4.5

4.5

4.0

4.0
Log10(expansions)

Log10(expansions)

Effective Heuristics Suboptimal Best-First Search

3.5
3.0

3.5
3.0

2.5

2.5

2.0

2.0

1.5
0.35

0.40

0.45

GDRC

0.50

0.55

1.5
0.45

0.60

0.50

0.55

0.60
0.65
0.70
0.75
GDRC (with h* instead d*)

0.80

0.85

Figure 12: Average log expansions done greedy best-first search
possible 462 5/6 disjoint PDB heuristics, plotted GDRC (left)
correlation h(n) h (n)
Domain

City Nav 5 5

Heuristic h(n)-h (n)
% Error Correlation
(Pearson)
31.19
0.9533

h(n)-h (n)
Correlation
(Spearman)
0.9466

h(n)-d (n)
Correlation
(Pearson)
0.0933

h(n)-d (n)
Correlation
(Spearman)
0.0718

Table 6: Average % error, correlation h(n) h (n), correlation
h(n) (n) City Nav 5 5

greedy best-first search faster Weighted A* may produce incorrect
answer.
seen City Navigation 5 5 domain. City Navigation 5 5 similar
City Navigation problems consider, except cities places
better connected, allowing direct routes taken. Since routes direct,
thus shorter, heuristic accurate. Table 6 shows various correlations
percent error h(n) City Navigation 5 5. Figure 13 shows increase
weight, despite weak correlation h(n) (n), catastrophe:
greedy best-first search expands roughly number nodes Weighted A*
best weight speed. occurs extreme strength heuristic,
correlates h (n) .95, extremely strong correlation.
next question correlation matters more: h (n) (n). Clearly, perfect
correlation h (n) h(n) (n) h(n) lead fast greedy best-first
search, leads us conclusion order greedy best-first search
effective, nodes small h(n) get expanded required least one virtue:
either close goal measured terms remaining search distance
(small (n)) close goal measured terms remaining cost (small h (n)).
295

fiWilt & Ruml

City Navigation 5 5

Total Nodes Expanded

3000

2000

1000

0

A* 1.1 1.2 2.5 5

10 20 G

Figure 13: Expansions done A*, Weighted A*, greedy best-first search City
Navigation 5 5

seen empirically two correlations break down, (n) correlation allows
greedy best-first search survive longer: tested domains (n)-h(n)
.58, greedy best-first search well, whereas seen domains h (n)h(n) correlation high .70 (or .75, depending correlation metric
used) greedy best-first search performs poorly.
importance correlation h(n) (n) reflects importance
node ordering greedy best-first search. optimal search, search cannot terminate
solution found, rather solution known optimal
paths pruned. larger heuristic values, sooner nodes
pruned. means optimal search, heuristic size paramount importance:
bigger better. greedy best-first search, heuristic used guide search
solution, relative magnitude heuristic (or error heuristic) bearing
performance search, saw considered percent error h.
common researchers say A*s heuristic guides search, discussion
reveals language reserved suboptimal search.
heuristics able satisfy needs A* greedy best-first search
simultaneously. example, dynamic robot navigation heuristic works extremely well
A* greedy best-first search, big, therefore good A*,
good differentiating nodes near goal far away goal,
helping greedy best-first search.

5. Building Heuristic Searching GDRC
shown Haslum, Botea, Helmert, Bonet, Koenig (2007), given metric assessing quality heuristic, use metric automatically construct effective
abstraction-based heuristics simply searching space abstractions. many domains, heuristic constructed initially abstracting everything, slowly refining
296

fiEffective Heuristics Suboptimal Best-First Search

abstraction construct heuristic. Haslum et al. (2007) concerned
optimal search hence use pruning power evaluate heuristics, focus greedy bestfirst search suggests GDRC might serve useful metric. example, TopSpin
problem, begin heuristic abstracts disks. consider PDBs
devised abstracting everything except one disk, measure GDRC
pattern database. GDRC effectively estimated breadth-first search
backwards goal (we used 10,000 nodes 12 disk problem) establish values
nodes, h value looked pattern database. sample 10%
nodes generated way, used sample calculate estimate Kendalls
. elected sample 10%, nodes, sample size taken provided
confidence interval sufficiently small tell better. Last, take PDB
highest value incumbent PDB. process repeats either PDBs
worse GDRC previous best PDB, PDB reached desired
size. reason allow algorithm possibly terminate early cover case
GDRC decreasing larger PDBs. increasing size PDB decreases GDRC,
likely increasing size PDB degrade GDRC even more,
elect terminate. full algorithm detailed Algorithm 1. simple
hill-climbing search appears effective, sophisticated search strategy could certainly
employed instead.
5.1 TopSpin
Algorithm 1 Hill Climbing PDB Builder
1: AllTokens = {Tokens problem abstracted}
2: RemainingTokens = AllT okens
3: BestPDB = build PDB abstracting AllT okens
4: BestTau = 0
5: function tryPDB(tokens)
6:
pdb = build PDB abstracting AllT okens \ tokens
7:
allNodes = nodes discovered breadth first search backwards goal state(s)
8:
sample = randomly sample 10% nodes allNodes
9:
return calcTau(sample, pdb)
10: BestP DB.size < Max Allowed Size
11:
LocalBestPDB, LocalBestTau, LocalBestToken = (N one, BestT au, N one)
12:
CurrentToken RemainingT okens
13:
CurrentTau, CurrentPDB = tryPDB(Ref inedT okens {token})
14:
CurrentT au > LocalBestT au
15:
set local best variables current
16:
LocalBestP DB 6= None
17:
set best variables local best variables
18:
RemainingTokens = RemainingT okens \ LocalBestT okens
19:
else
20:
Break
21: return BestPDB
297

fiWilt & Ruml

PDB
Contiguous
Big Operators
Random

Greedy Exp
411.19
961.11
2,386.81

A* Exp
10,607.45
411.27
26,017.25

Avg. Value
52.35
94.37
47.99

Table 7: Expansions solve TopSpin problem stripe cost function using different
PDBs

used generate unit-cost TopSpin pattern databases, hill-climbing GDRC
always produced PDBs abstracted disks connected one another,
refined disks also connected one another. prevents abstraction
creating regions h = 0, goal nowhere near h = 0 nodes, per
Observation 2.
unit-cost TopSpin problems, abstractions disks connected
one another work well greedy best-first search A*. change cost
function moving even disk costs 1 moving odd disk costs 10, get
stripe cost function, called costs striped across problem.
effective PDBs A* keep many odd disks possible, moving
odd disks much expensive moving even disk. use big
operator pattern database greedy best-first search, algorithm align high
cost odd disks, great difficulty escaping resulting local minimum.
use hill climbing GDRC build heuristic, end contiguous heuristic
keeps abstracted refined disks connected one another. Table 7 provides
results various pattern databases solving suite instances. see
importance creating good pattern database consider Random row
table, contains average number expansions 20 different randomly selected
6 disk pattern databases.
5.2 Towers Hanoi
already infer Figure 11 that, greedily select PDB best
collection PDBs, would select best one. certainly also possible
use hill-climbing search incrementally construct PDB. creating PDB
heuristic Towers Hanoi, one maps full size problem onto abstracted version
problem removing disks larger problem, re-indexing
remaining disks map disks smaller problem. technique,
critical component terms performance disks abstracted.
define mapping selection disks abstract. example,
consider 12 disk problem using 8 disk PDB, must select 4 12 total disks
abstract. Figure 14 + glyphs represent randomly selected abstraction,
heuristic produced. see, abstractions produced extremely poor
quality heuristics measured GDRC average number expansions done
greedy best-first search solving problems using heuristic. heuristics fared
significantly better terms GDRC average expansions greedy best-first
298

fiEffective Heuristics Suboptimal Best-First Search

Analysis
heuristics generated different Hanoi PDB mappings
8
7

Log expansions

6
5
4
3
2
0.2

Randomly selected mappings
Best Mapping
Hill Climbing Mappings
0.0

0.2

0.4
GDRC

0.6

0.8

1.0

Figure 14: Expansions using different Towers Hanoi PDB abstractions.
search. examine plot Figure 14 see several clusters
heuristics. heuristics GDRC 0 clustered together, requiring
greedy best-first search expand 107 108 nodes. heuristics
worst heuristics, largest disk abstracted. next cluster heuristics
GDRC 0.4 0.5 require greedy best-first search expand 106.5
107 nodes. heuristics largest disk abstracted, second
largest disk abstracted. abstractions also produce poor quality heuristics,
heuristics represent significant improvement heuristics largest
disk abstracted. color Figure 14 represents mapping different largest
abstracted disk, blue X glyph representing best pattern database
smallest disks abstracted. see plot, definite overall trend
mappings product heuristics higher GDRC tend fare better overall
terms average total expansions used greedy best-first search.
hill climbing algorithm selected heuristic contained disks 0, 1, 2, 4, 5, 6,
7, 8 (skipping 3 disk). example hill climbing algorithm selected
heuristic seen green circles line Figure 14 starting
abstraction abstracted largest disk. hill climbing algorithm climbed hill
leading reasonable, albeit effective, heuristic. Despite failing find
optimal heuristic, selected heuristic quite reasonable nonetheless, falling
86th 75th percentile overall, significant improvement automated approach.
5.3 City Navigation
addition building pattern database heuristics using hill climbing GDRC, also
possible build portal-style heuristic hill climbing GDRC. Using city navigation
domain, defined portal heuristic (Goldenberg, Felner, Sturtevant, & Schaeffer, 2010)
selecting number nodes portal nodes (we used number nodes
299

fiWilt & Ruml

Heuristic
Random Portals
Nexus Portals
Hill Climbed Portals

Average GDRC
0.44
0.76
0.60

Average greedy best-first search expansions
2200
488
1117

Table 8: Expansions GDRC using different ways select portal nodes

cities, 150), calculating true distance every node closest portal node.
heuristic two nodes true distance portals associated
node minus distance node portal. event quantity
negative, 0 used. heuristic highly accurate across long distances uses
true distance portals, obviously less accurate comparing
two nodes share portal. constructing portal heuristics, critical
difference effective portal heuristic poor quality portal heuristic
selection nodes portals. allowed algorithm automate process
hill climbing GDRC. algorithm initialized random array nodes
portals. step, algorithm iterates indexes array portals,
considering moving location currently serving portal different location.
implementation, considered two times number cities, 300 different
random places. assessed GRDC new heuristic using sample 100,000
randomly selected pairs places. moving city new location improved GDRC,
kept portal array new place, otherwise, discarded change GDRC
inferior incumbent. reach end array, restart
beginning. reach point position array,
aspects array remain unchanged since last time modified index,
algorithm terminates, returning array portals use heuristic.
Results experiment shown Table 8. average GDRC GDRC
one obtains selecting 100,000 random pairs start end nodes calculating
GDRC using nodes. average greedy best-first search expansions average
number expansions needed solve City Navigation problem random start
goal.
considered three different methods selecting portal nodes. first
completely randomize selection portal nodes, unsurprisingly resulted
lowest GRDC highest number expansions. successful method
selecting portal nodes identify nexus nodes, use nodes portals.
Unsurprisingly, method led highest GDRC, fewest number expansions.
result demonstrates usefulness GDRC identifying quality heuristic
greedy best-first search. Last, automatic algorithm finding portal nodes performed
significantly better random, still trailing hand-selected portals. believe
better search strategy may able better capture potential performance gain
offered high GDRC heuristics.
300

fiEffective Heuristics Suboptimal Best-First Search

5.4 Sliding Tile Puzzle
also compare GDRC-generated PDBs instance-specific PDBs sliding
tile puzzle (Holte et al., 2005). domain, order get accurate estimate
, increase number nodes expanded going backwards 10,000
1,500,000. Following hill climbing procedure, algorithm selected pattern database
tracked 1, 3, 4, 7, 8, 11 tiles. results using PDB shown Table
3. abstraction strong outer L abstraction, fourth best
PDB minimizing average number expansions done greedy best-first search
462 possible 6-tile pattern databases. automatically constructed PDB
two orders magnitude faster number expansions one would expect
using average 6-tile PDB, three orders magnitude faster worst 6-tile
PDB greedy best-first search. GDRC-generated PDB works substantially better
greedy best-first search state-of-the-art instance-specific PDBs, requiring one
twentieth expansions. One additional advantage GDRC-generated PDB
instance-specific PDBs fact GDRC produces single PDB, unlike instance
specific PDBs, produce new PDB every problem.
summary, results show GDRC useful predicting relative quality
heuristics greedy best-first search. also showed possible leverage
quantitative metric automatically construct heuristic greedy best-first search,
automatically created heuristics extraordinarily effective greedy best-first
search.

6. Related Work
metric, GDRC predicts heuristics high rank correlation
work well. general, objective h approximate h , , one alternative way
find quality heuristic leverage fact try construct heuristic directly
mimics , generally referred d. Indeed, approach generally quite successful
(as opposed relying exclusively h), handily outperforming h many situations (Wilt
& Ruml, 2014).
Gaschnig (1977) describes predict worst case number nodes expanded
A*, also discusses weighting heuristic affect worst case final node
expansion count. predictions, however, two limitations. First, predictions
assume search space tree, graph, case many applications
heuristic search. addition that, worst case predictions depend amount
error present heuristic, error measured relative deviation h (n).
A*, criterion makes certain amount sense, greedy best-first search,
seen relative deviation h (n) cannot used predict greedy
best-first search perform poorly. Gaschnig points increasing weight ad
infinitium may decrease performance, precisely phenomenon documented
Section 2.
Chenoweth Davis (1991) show heuristic rapidly growing logarithmic cluster, greedy best-first search done polynomial time. heuristic
rapidly growing logarithmic cluster if, every node n, h(n) within logarithmic
factor monotonic function f h (n), f grows least fast function
301

fiWilt & Ruml

g(x) = x. aware heuristics proven rapidly growing
logarithmic cluster.
number works consider question predicting search algorithm performance
(Korf et al., 2001; Pearl, 1984; Helmert & Roger, 2008), although subject attracting
far attention determining many nodes expanded optimal
search algorithm. saw Section 3, behavior optional search general
predict behavior GBRS. Lelis, Zilles, Holte (2011) empirical analysis
suboptimal search algorithms, predicting number nodes would expanded
Weighted IDA*, clear methods predict greedy best-first search
behavior, thus tell us increasing weight far detrimental.
Korf (1993) provides early discussion increasing weight may actually
bad, showing recursive best first search iterative deepening A* used
weight large, expansions actually increase. paper also early example
exploring weight interacts expansion count, something central
work.
Hoffmann (2005) discusses FF heuristic (Hoffmann & Nebel, 2001) effective way solve many planning benchmarks used conjunction enforced
hill climbing. paper shows many benchmark problems, heuristic small
bounded-size plateaus, implying breadth-first search part enforced hill climbing algorithm bounded, means problems solved quickly, sometimes linear time. Although enforced hill climbing kind greedy best-first search,
behaviour different greedy best-first search promising path turns
local minimum. Greedy best-first search considers nodes search
space, possibly allowing disparate nodes compete one another expansion.
Enforced hill climbing limits consideration nodes near local minimum (with
nearness measured edge count), means algorithm cares
heuristic performs small local region space. Hoffmann (2011) extends
concept, describing process automatically proving domain small local
minima.
Xu, Fern, Yoon (2009) discuss constructing heuristics suboptimal heuristic
search, algorithm consider beam search. Beam searches inadmissibly
prune nodes save space time, function ultimately used rank
nodes, make decision whether keep one node. function
Xu et al. create used rank nodes, input function requires variety
features state function, created using training data trial search runs.
approach creating heuristic hill-climbing GDRC require training
instances, require information states themselves. Hill-climbing
GDRC does, however, limitation automatic generation heuristics
works appropriate search space defined, abstraction-based
heuristics.

7. Conclusion
Suboptimal heuristic searches rely heavily heuristic node evaluation function.
first showed greedy best-first search sometimes perform worse A*,
302

fiEffective Heuristics Suboptimal Best-First Search

although many domains general trend larger weight heuristics
Weighted A* leads faster search, also domains larger weight leads
slower search. long understood greedy best-first search bounds
performance, given poor heuristic, greedy best-first search could well expand
entire state space, never terminate state space infinite. work shows
poor performance theoretical curiosity, behavior occur
practice.
considered characteristics effective heuristics greedy best-first search.
showed several examples conventional guidelines building heuristics A*
actually harm performance greedy best-first search. used experience
develop alternative observations desiderata heuristics use greedy bestfirst search. first every node, path goal
decreases h. second, important special case first, nodes h = 0
connected goal via nodes h = 0. third observation nodes
require including high h nodes solution high h
value possible.
showed domains greedy best-first search effective share
common trait heuristic function: true distance node goal, defined
(n), correlates well h(n). information important anyone running
suboptimal search interest speed, allows identify whether
assumption weighting speeds search true not, critical knowledge
deciding algorithm use.
Finally, showed goal distance rank correlation (GDRC) used compare
different heuristics greedy best-first search, demonstrated used
automatically construct effective abstraction heuristics greedy best-first search.
Recent work shown search algorithms explicitly designed suboptimal
setting outperform methods like weighted A*, simple unprincipled derivative
optimal search (Thayer & Ruml, 2011; Thayer, Benton, & Helmert, 2012; Stern,
Puzis, & Felner, 2011). results indicate holds true heuristic functions
well: suboptimal search deserves specialized methods. Given importance
suboptimal methods solving large problems quickly, hope investigation spurs
analysis suboptimal search algorithms heuristic functions rely on.

8. Acknowledgments
gratefully acknowledge support NSF (award 1150068). Preliminary expositions
results published Wilt Ruml (2012, 2015).

References
Burns, E. A., Hatem, M., Leighton, M. J., & Ruml, W. (2012). Implementing fast heuristic
search code. Proceedings Fifth Symposium Combinatorial Search.
Chenoweth, S. V., & Davis, H. W. (1991). High-performance A* search using rapidly
growing heuristics. Proceedings Twelfth International Joint Conference
Articial Intelligence, pp. 198203.
303

fiWilt & Ruml

Doran, J. E., & Michie, D. (1966). Experiments graph traverser program.
Proceedings Royal Society London. Series A, Mathematical Physical
Sciences, pp. 235259.
Felner, A., Korf, R. E., Meshulam, R., & Holte, R. C. (2007). Compressed pattern databases.
Journal Artificial Intelligence Research (JAIR), 30, 213247.
Felner, A., Zahavi, U., Holte, R., Schaeffer, J., Sturtevant, N. R., & Zhang, Z. (2011).
Inconsistent heuristics theory practice. Artificial Intelligence, 175 (9-10), 1570
1603.
Gaschnig, J. (1977). Exactly good heuristics?: Toward realistic predictive theory
best-first search. Proceedings Fifth International Joint Conference
Articial Intelligence, pp. 434441.
Gibbons, J. D. (1985). Nonparametric Statistical Inference. Marcel Decker, Inc.
Goldenberg, M., Felner, A., Sturtevant, N., & Schaeffer, J. (2010). Portal-based truedistance heuristics path finding. Proceedings Third Symposium Combinatorial Search.
Hart, P. E., Nilsson, N. J., & Raphael, B. (1968). formal basis heuristic determination minimum cost paths. IEEE Transactions Systems Science Cybernetics,
SSC-4 (2), 100107.
Haslum, P., Botea, A., Helmert, M., Bonet, B., & Koenig, S. (2007). Domain-independent
construction pattern database heuristics cost-optimal planning. Proceedings
AAAI-07, pp. 10071012.
Helmert, M. (2006). fast downward planning system. Journal Artificial Intelligence
Research, 26, 191246.
Helmert, M. (2010). Landmark heuristics pancake problem. Proceedings
Third Symposium Combinatorial Search.
Helmert, M., & Roger, G. (2008). good almost perfect?. Proceedings
Twenty-Third AAAI Conference Artificial Intelligence (AAAI-2008), pp. 944949.
Hoffmann, J. (2005). Ignoring delete lists works: Local search topology planning
benchmarks. Journal Artifial Intelligence Research, 24, 685758.
Hoffmann, J. (2011). Analyzing search topology without running search: connection causal graphs h+ . Journal Artificial Intelligence Research, 41,
155229.
Hoffmann, J., & Nebel, B. (2001). FF planning system: Fast plan generation
heuristic search. Journal Artificial Intelligence Research, 14, 253302.
Holte, R., Grajkowskic, J., & Tanner, B. (2005). Hierachical heuristic search revisitied.
Symposium Abstracton Reformulation Approximation, pp. 121133.
Kendall, M. G. (1938). new measure rank correlation. Biometrika, 30 (1/2), 8193.
Kendall, M., & Gibbons, J. D. (1990). Rank Correlation Methods (Fifth edition). Edward
Arnold.
304

fiEffective Heuristics Suboptimal Best-First Search

Korf, R., & Felner, A. (2002). Disjoint pattern database heuristics. Artificial Intelligence,
134, 922.
Korf, R. E. (1987). Planning search: quantitative approach. Artificial Intelligence,
33 (1), 6588.
Korf, R. E. (1993). Linear-space best-first search. Artificial Intelligence, 62, 4178.
Korf, R. E. (1997). Finding optimal solutions Rubiks cube using pattern databases.
Proceedings Fourteenth National Conference Artificial Intelligence, AAAI97,
pp. 700705. AAAI Press.
Korf, R. E. (2007). Analyzing performance pattern database heuristics. Proceedings
22nd National Conference Artificial Intelligence, AAAI07, pp. 11641170.
AAAI Press.
Korf, R. E., Reid, M., & Edelkamp, S. (2001). Time complexity iterative-deepening-A*.
Artificial Intelligence, 129, 199218.
Korf, R. E., & Taylor, L. A. (1996). Finding optimal solutions twenty-four puzzle.
AAAI, Vol. 2, pp. 12021207.
Lelis, L., Zilles, S., & Holte, R. C. (2011). Improved prediction IDA*s performance via
epsilon-truncation. Proceedings Fourth Symposium Combinatorial Search.
Likhachev, M., Gordon, G., & Thrun, S. (2003). ARA*: Anytime A* provable bounds
sub-optimality. Proceedings Seventeenth Annual Conference Neural
Information Processing Systems.
Likhachev, M., & Ferguson, D. (2009). Planning long dynamically feasible maneuvers
autonomous vehicles. International Journal Robotic Research, 28 (8), 933945.
Martelli, A. (1977). complexity admissible search algorithms. Artificial Intelligence, 8 (1), 113.
Nilsson, N. J. (1980). Principles Artificial Intelligence. Tioga Publishing Co.
Parberry, I. (1995). real-time algorithm (n2 -1)-puzzle. Information Processing
Letters, 56 (1), 2328.
Pearl, J. (1984). Heuristics: Intelligent Search Strategies Computer Problem Solving.
Addison-Wesley.
Pohl, I. (1970). Heuristic search viewed path finding graph. Artificial Intelligence,
1, 193204.
Richter, S., Thayer, J. T., & Ruml, W. (2009). joy forgetting: Faster anytime search
via restarting. Proceedings Twentieth International Conference Automated
Planning Scheduling.
Richter, S., & Westphal, M. (2010). LAMA planner: Guiding cost-based anytime
planning landmarks. Journal Artifial Intelligence Research, 39, 127177.
Stern, R. T., Puzis, R., & Felner, A. (2011). Potential search: bounded-cost search
algorithm. Proceedings 21st International Conference Automated Planning
Scheduling, ICAPS.
305

fiWilt & Ruml

Sussman, G. J. (1975). Computer Model Skill Acquisition. New York: New American
Elsevier.
Thayer, J. T., Benton, J., & Helmert, M. (2012). Better parameter-free anytime search
minimizing time solutions. Proceedings Fifth Annual Symposium
Combinatorial Search, SOCS 2012.
Thayer, J. T., & Ruml, W. (2011). Bounded suboptimal search: direct approach using inadmissible estimates. Proceedings Twenty Sixth International Joint
Conference Articial Intelligence (IJCAI-11), pp. 674679.
Tukey, J. W. (1977). Exploratory Data Analysis. Addison-Wesley, Reading, MA.
van den Berg, J., Shah, R., Huang, A., & Goldberg, K. Y. (2011). Anytime nonparametric
A*. Proceedings Twenty Fifth National Conference Articial Intelligence.
Wilt, C., & Ruml, W. (2012). weighted A* fail?. Proceedings Fifth
Symposium Combinatorial Search.
Wilt, C., & Ruml, W. (2014). Speedy versus greedy search. Proceedings Seventh
Symposium Combinatorial Search.
Wilt, C., & Ruml, W. (2015). Building heuristic greedy search. Proceedings
Eighth Symposium Combinatorial Search.
Xu, Y., Fern, A., & Yoon, S. (2009). Learning linear ranking functions beam search
application planning. Journal Machine Learning Research, 10, 15711610.

306

fiJournal Artificial Intelligence Research 57 (2016) 1-37

Submitted 03/16; published 09/16

Learning Continuous Time Bayesian Networks
Non-stationary Domains
Simone Villa
Fabio Stella

villa@disco.unimib.it
stella@disco.unimib.it

Department Informatics, Systems Communication
University Milano-Bicocca
Viale Sarca 336, 20126 Milan, Italy

Abstract
Non-stationary continuous time Bayesian networks introduced. allow
parents set node change continuous time. Three settings developed
learning non-stationary continuous time Bayesian networks data: known transition
times, known number epochs unknown number epochs. score function
setting derived corresponding learning algorithm developed. set numerical
experiments synthetic data used compare effectiveness non-stationary continuous time Bayesian networks non-stationary dynamic Bayesian networks. Furthermore, performance achieved non-stationary continuous time Bayesian networks
compared achieved state-of-the-art algorithms four real-world datasets,
namely drosophila, saccharomyces cerevisiae, songbird macroeconomics.

1. Introduction
identification relationships statistical dependencies components multivariate time-series, ability reasoning whether dependencies
change time crucial many research domains biology, economics, finance,
traffic engineering neurology, mention few. biology, example, knowing
gene regulatory network allows understand complex biological mechanisms ruling
cell. context, Bayesian networks (BNs) (Pearl, 1989; Segal, Peer, Regev, Koller,
& Friedman, 2005; Scutari & Denis, 2014), dynamic Bayesian networks (DBNs) (Dean
& Kanazawa, 1989; Zou & Conzen, 2005; Vinh, Chetty, Coppel, & Wangikar, 2012)
continuous time Bayesian networks (CTBNs) (Nodelman, Shelton, & Koller, 2002; Acerbi,
Zelante, Narang, & Stella, 2014) used reconstruct transcriptional regulatory
networks gene expression data. effectiveness discrete DBNs investigated identify functional correlations among neuroanatomical regions interest (Burge,
Lane, Link, Qiu, & Clark, 2009), useful primer BNs functional magnetic resonance imaging data analysis made available (Mumford & Ramsey, 2014). However,
mentioned applications require time-series generated stationary distribution, i.e. one change time. stationarity reasonable
assumption many situations, cases data generating process clearly
non-stationary. Indeed, last years, researchers different disciplines, ranging
economics computational biology, sociology medicine become interested
representing relationships dependencies change time.
c
2016
AI Access Foundation. rights reserved.

fiVilla & Stella

Specifically, researchers interested analyzing temporal evolution
genetic networks (Lebre, Becq, Devaux, Stumpf, & Lelandais, 2010), flow neural
information networks (Smith, Yu, Smulders, Hartemink, & Jarvis, 2006), heart failure (Liu,
Hommersom, van der Heijden, & Lucas, 2016), complications type 1 diabetes (Marini,
Trifoglio, Barbarini, Sambo, Camillo, Malovini, Manfrini, Cobelli, & Bellazzi, 2015)
dependence structure among financial markets crisis (Durante & Dunson, 2014).
According specialized literature evolution models (Robinson & Hartemink, 2010),
divided two main categories: structurally non-stationary, i.e. models
allowed change structure time, parametrically non-stationary,
i.e. models allow parameters values change time.
paper, structurally non-stationary continuous time Bayesian network model
(nsCTBN) introduced. nsCTBN consists sequence CTBNs improves expressiveness single CTBN. Indeed, nsCTBN allows parents set node
change time specific transition times thus allows model non-stationary systems. learn nsCTBN, Bayesian score learning CTBNs extended (Nodelman,
Shelton, & Koller, 2003). nsCTBN version Bayesian score still decomposable
variable depends knowledge setting be: known transition times,
transition times known, known number epochs, number transition times known, unknown number epochs, number transition times
unknown. learning algorithm knowledge setting designed developed.
Experiments non-stationary dynamic Bayesian networks (nsDBNs) (Robinson &
Hartemink, 2010), i.e. discrete time counterparts nsCTBNs, performed.
main contributions paper following:
definition structurally non-stationary continuous time Bayesian network model;
derivation Bayesian score decomposition knowledge setting;
design algorithms learning nsCTBNs different knowledge settings.
novel dynamic programming algorithm learning nsCTBNs known
transition times setting described, learning nsCTBNs others settings
performed simulated annealing, exploiting dynamic programming algorithm;
performance comparison nsCTBNs nsDBNs knowledge settings
rich set synthetic data generated nsCTBNs nsDBNs;
performance comparison nsCTBNs state-of-the-art algorithms realworld datasets, namely drosophila, saccharomyces cerevisiae songbird;
nsCTBN learned macroeconomics dataset consisting variables evolving
different time granularities spanning 1st January 1986 31st March 2015.
rest paper organized follows. Section 2 continuous time Bayesian networks introduced together learning problem complete data. Section 3
introduces non-stationary continuous time Bayesian networks, presents three learning settings derives corresponding Bayesian score functions. Algorithms learning
nsCTBNs different learning settings described Section 4. Numerical experiments synthetic real-world datasets presented Section 5. Section 6 closes
paper making conclusions indicating directions research activities.
2

fiLearning Continuous Time Bayesian Networks Non-stationary Domains

2. Continuous Time Bayesian Networks
Continuous time Bayesian networks combine Bayesian networks homogeneous Markov
processes together efficiently model discrete state continuous time dynamical systems
(Nodelman et al., 2002). particularly useful modeling domains variables evolve different time granularities, model presence people
computers (Nodelman & Horvitz, 2003), study reliability dynamical systems (Boudali
& Dugan, 2006), model failures server farms (Herbrich, Graepel, & Murphy, 2007),
detect network intrusion (Xu & Shelton, 2008), analyze social networks (Fan & Shelton,
2009), model cardiogenic heart failure (Gatti, Luciani, & Stella, 2011) reconstruct
gene regulatory networks (Acerbi & Stella, 2014; Acerbi, Vigano, Poidinger, Mortellaro,
Zelante, & Stella, 2016). Recently, complexity inference continuous time Bayesian
networks studied (Sturlaugson & Sheppard, 2014).
2.1 Basics
representation ability continuous time Bayesian networks inherent factorization system dynamics local continuous time Markov processes depend
limited set states. continuous time Bayesian network model defined follows:
Definition 1. Continuous time Bayesian network (Nodelman et al., 2002). Let X
set random variables X = {X1 , X2 , . . . , XN }. X finite domain values
V al(X) = {x1 , x2 , . . . , xI }. continuous time Bayesian network X consists two
0 , specified Bayesian network X,
components: first initial distribution PX
second continuous time transition model specified as: directed (possibly cyclic)
P a(X)
graph G whose nodes X1 , X2 , . . . , XN ; conditional intensity matrix (CIM), QX
,
variable X X, P a(X) denotes set parents X graph G.
P a(X)

conditional intensity matrix QX

consists set intensity matrices

qxpa1 u
qxpa2 xu1
=

.
qxpaI xu1


u
Qpa
X

.
.
.
.


qxpa1 xuI
qxpa2 xuI
,

.
pau
qxI


pau ranges possible configurations parents set P a(X), qxpai u =
P
pau
pau
pau
xj 6=xi qxi xj . Off-diagonal elements QX , i.e. qxi xj , proportional probability
variable X transitions state xi state xj given parents state pau .
pau
u
intensity matrix Qpa
X equivalently summarized two independent sets: q X =
pau
{qxi : 1 I}, i.e. set intensities parameterizing exponential distributions
pau
pau
pau
u
next transition occurs, pa
X = {xi xj = qxi xj /qxi : 1 i, j I, j 6= i},
i.e. set probabilities parameterizing multinomial distributions
state transitions. Note CTBN model assumes one single variable
change state specific instant, transition dynamics specified parents
via CIM, independent variables given Markov Blanket.
3

fiVilla & Stella

2.2 Structural Learning
Given fully observed dataset D, i.e. dataset consisting multiple trajectories1 whose
states transition times fully known, problem learning structure CTBN
addressed problem selecting graph G maximizes Bayesian
score computed dataset (Nodelman et al., 2003):
BS (G : D) = ln P (G) + ln P (D|G).

(1)

P (G) prior graph G P (D|G) marginal likelihood.
prior P (G) graph G, allows us prefer CTBNs structures
others, usually assumed satisfy structure modularity property (Friedman &
Koller, 2000), i.e. decompose following product terms:

P (G) =
P (P a(X) = P aG (X)),
(2)
XX

term parents set P aG (X) graph G. uniform prior G often used.
marginal likelihood P (D|G) depends prior parameters P (q G , G |G)
usually assumed satisfy global parameter independence, local parameter independence parameter modularity properties, outlined below.
Global parameter independence (Spiegelhalter & Lauritzen, 1990) states paramP (X)
P (X)
eters q X G
X G
associated variable X graph G independent,
thus prior parameters decomposes variable follows:

P (X) P (X)
P (q G , G |G) =
P (q X G , X G |G).
(3)
XX

Local parameter independence (Spiegelhalter & Lauritzen, 1990) asserts parameters associated configuration pau parents P aG (X) variable X
independent. Therefore, parameters associated variable X decomposable
parent configuration pau follows:
YY
P (X) P (X)
u
(4)
P (q X G , X G |G) =
P (qxpai u , pa
xi |G).
pau xi

Parameter modularity (Geiger & Heckerman, 1997) asserts variable X
parents P aG (X) = P aG 0 (X) two distinct graphs G G 0 , probability density
functions parameters associated X must identical:
P aG (X)

P (q X

P aG (X)

, X

P aG 0 (X)

|G) = P (q X

P aG 0 (X)

, X

|G 0 ).

(5)

Furthermore, also assume sets parameters characterizing exponential distributions independent sets parameters characterizing multinomial
distributions:
P (q G , G |G) = P (q G |G)P ( G |G).
(6)
1. trajectory defined sequence pairs (t, X(t)), transition time [0, ]
associated state X(t) random variables corresponding nodes CTBN.

4

fiLearning Continuous Time Bayesian Networks Non-stationary Domains

Dirichlet distribution selected prior parameters associated multinomial distribution, gamma distribution selected prior parameters
associated exponential distribution, i.e.

P (qxpai u ) Gamma xpai u , xpai u ,
(7)

pau
pau
pau
P ( xi ) Dir xi x1 , . . . , xi xI ,
(8)
xpai u , xpai u , xpai xu1 , . . . , xpai xuI priors hyperparameters. particular, hyperparameters represent pseudocounts number transitions state state,
parameter represents imaginary amount time spent state
data observed. Note hyperparameter xpai u inversely proportional
number joint states parents X. Conditioning dataset D, obtain
following posteriors parameters:

u
,
(9)
P (qxpai u |D) Gamma xpai u + Mxpai u , xpai u + Txpa


pau
pau
pau
pau
pau
(10)
P ( xi |D) Dir xi x1 + Mxi x1 , . . . , xi xI + Mxi xI ,
u
Mxpai xuj sufficient statistics CTBN (Nodelman et al., 2003).
Txpa

u
particular, Txpa
amount time spent variable X state xi

parents P a(X) state pau , Mxpai xuj number times variable X
transitions state xi state xj parents P a(X) state pau 2 .
Bayesian score (1) term P (G) grow size dataset D.
Thus, significant term marginal likelihood P (D|G). case complete data,
exploiting parameters independence (6) global parameter independence
property (3), marginal likelihood written follows:

P (X)
P (X)
P (D|G) =
L(q X G |D) L( X G |D),
(11)

XX
P aG (X)

L(q X

|D) marginal likelihood q derived follows:
YY
pau xi

P aG (X)

L( X

(xpai u + Mxpai u + 1) (xpai u )
u
(xpai u + 1) (xpai u + Txpa
)

u
(pa
xi +1)

pau
u
(pa
xi +Mxi +1)

,

|D) marginal likelihood derived follows:


xpai xuj + Mxpai xuj
(xpai u )
,
pau
pau
pau

(
+

)


x
x
x


xj
pa x =x
x 6=x
u



j



(12)

(13)

j

Bayesian-Dirichlet equivalent (BDe) metric version CTBNs (Nodelman, 2007).
case, BDe metric uses priors (7) (8), parameter modularity (5),
well global (3) local (4) parameter independence properties assumed
satisfied.
2. Please note number times P
variable X leaves state xi parents P a(X)
pau
u
state pau computed follows Mxpa
=
xj 6=xi Mxi xj .


5

fiVilla & Stella

conclusion, Bayesian score (1) computed closed form assuming
structure modularity property (2) satisfied, using BDe metric follows:
X
P (X)
P (X)
ln P (P a(X) = P aG (X)) + ln L(q X G |D) + ln L( X G |D). (14)
BS(G : D) =
XX

Since graph G CTBN acyclicity constraints, possible maximize
Bayesian score (14) separately optimizing parents set P a(X) variable
X. worthwhile mention maximum number parents set,
search optimal value Bayesian score (14) performed polynomial time.
search performed enumerating possible parents set using greedy
hill-climbing procedure operators add, delete reverse edges graph G.

3. Non-stationary Continuous Time Bayesian Networks
Continuous time Bayesian networks structurally stationary, graph
change time, parametrically stationary, conditional intensity matrices
change time. stationarity assumptions reasonable many situations,
cases data generating process intrinsically non-stationary
thus CTBNs longer used. Therefore, section, extend CTBNs become
structurally non-stationary. i.e. allow CTBNs structure change continuous
time.
3.1 Definition
non-stationary continuous time Bayesian network model, graph CTBN
replaced graphs sequence G = (G1 , G2 , . . . , GE ), graph Ge represents
causal dependency structure model epoch e {1, 2, . . . , E}3 . model
structurally non-stationary introduction graphs sequence
handle transition times common whole network and/or node-specific.
Following notations definitions used non-stationary dynamic Bayesian networks, let = (t1 , . . . , tE1 ) transition times sequence, i.e. times
causal dependency structure Ge , active epoch e, replaced causal dependency
structure Ge+1 , becomes active epoch e + 1. epoch defined period
time two consecutive transitions, i.e. epoch e active period
time starting te1 ending te . graph Ge+1 , active epoch
e + 1, differs graph Ge , active epoch e, set edges
call set edge changes Ge .
Figure 1 shows graphs sequence G = (G1 , G2 , G3 , G4 ) consisting four epochs (E = 4)
transition times = (t1 , t2 , t3 ). epoch associated set edge changes.
Specifically, graph G2 differs graph G1 following set edge changes
G1 = {X3 X2 , X2 6 X3 , X1 6 X2 }, graph G3 differs graph G2
following set edge changes G2 = {X2 X1 } graph G4 differs graph
G3 following set edge changes G3 = {X3 X4 , X4 X1 , X1 6 X4 , X4 6 X3 }.
3. worthwhile mention first epoch, i.e. epoch starting time 0 ending time t1
associated graph G1 , last epoch, i.e. epoch starting time tE1 ending
time (the supremum considered time interval, i.e. [0,T]) associated graph GE .

6

fiLearning Continuous Time Bayesian Networks Non-stationary Domains

X1

X2

X1

X2

X1

X2

X1

X2

X4

X3

X4

X3

X4

X3

X4

X3

0

3

2

1

t2

t1

4

t3



Figure 1: Graphs sequence G = (G1 , G2 , G3 , G4 ) nsCTBN four epochs, E = 4,
three transition times, = (t1 , t2 , t3 ), edges gained lost time.
Non-stationary continuous time Bayesian networks allow node
sequence parents sets, parents set active given epoch. Therefore,
introduce concept homogeneous interval H(X) = (h1 , . . . , hM ) associated node
X, defined union consecutive epochs parents set
P a(X) active node X. Note epoch associated different
parents set, equal E.
non-stationary continuous time Bayesian network defined follows.
Definition 2. (Structurally) non-stationary continuous time Bayesian network. Let X
set random variables X1 , . . . , XN . X finite domain values V al(X) =
{x1 , . . . , xI }. (structurally) non-stationary continuous time Bayesian network Nns =
(B, Mns ) X consists two components:
0 , specified Bayesian network B X,
initial distribution PX

non-stationary continuous time transition model Mns specified as:
sequence directed (possibly cyclic) graphs G = (Ge )E
e=1 whose nodes
X1 , . . . , XN , E represents number epochs;
P (X)

G
conditional intensity matrix, QX,H(X)
, X X, P aG (X) denotes
parents sets X G, H(X) denotes intervals associated X.

P (X)

G
conditional intensity matrix QX,H(X)
consists set intensity matrices
u
qxpa1 ,h

pa
q u
x2 x1 ,hm
=

.
pau
qxI x1 ,hm



u
Qpa
X,hm

.
.
.
.


qxpa1 xuI ,hm
qxpa2 xuI ,hm
,

.
pau
qxI ,hm

one configuration pau parents set P a(X) P aG (X) active
interval hm H(X).4
u
4. Note following equation qxpai ,h
=


P

xj 6=xi

7

qxpai xuj ,hm still holds.

fiVilla & Stella

3.2 Learning Framework
Learning nsCTBN fully observed dataset done using Bayesian learning
framework taking account entire graphs sequence G. nsCTBNs case, must
specify prior probability graphs sequence G and, possible sequence,
density measure possible values parameters q G G . prior P (G)
likelihood P (q G , G |G) given, marginal likelihood P (D|G) computed
Bayesian score evaluated. important note focused
recovering graphs sequence G detecting possible changes parameters.
fact, identify non-stationarity parameters model, i.e. entries
conditional intensity matrices, significant enough result structural changes
graph. Others changes assumed small enough alter graph structure.
3.2.1 Prior Probability Graphs
Given transition times , thus number epochs E, assume prior
nsCTBNs structure G written follows:
P (G|T ) = P (G1 , ..., GE |T ) = P (G1 , G1 , ..., GE1 |T ) = P (G1 )P (G1 , ..., GE1 |T ).
(15)
Equation (15) justified assume probability distribution edge
changes function number changes performed, also defined
independently initial graph G1 . knowledge particular edges
overall topology available initial network, use informative prior
P (G1 ) otherwise resort uniform distribution. CTBNs, P (G1 ) must satisfy structure modularity assumption (2), prior set edge changes
P (G1 , . . . , GE1 |T ) defines way edges change adjacent epochs.
3.2.2 Prior Probability Parameters
prior parameters P (q G , G |G, ) selected satisfy following assumptions:
independence sets parameters characterizing exponential multinomial distributions (6), parameter modularity (5) parameter independence. latter
assumption divided three components nsCTBNs: global parameter independence,
interval parameter independence local parameter independence.
Global parameter independence asserts parameters associated node
nsCTBNs graphs sequence independent, prior parameters decomposes
variable X follows:

P aG (X)
P aG (X)
P (q G , G |G, ) =
P (q X,H(X)
, X,H(X)
|G, ).
(16)
XX

Interval parameter independence states parameters associated interval
active parents node independent, parameters associated
X parents sets P aG (X) decomposable interval hm H(X) follows:
P (X)

P (X)

G
G
P (q X,H(X)
, X,H(X)
|G, ) =


hm

8

P (X)

P (X)

P (q X,hGm , X,hGm |G, ).

(17)

fiLearning Continuous Time Bayesian Networks Non-stationary Domains

Local parameter independence states parameters associated state
variable given interval independent, thus parameters associated X
interval hm H(X) decomposable parent configuration pau follows:
YY
P (X) P (X)
u
u
(18)
, pa
P (qxpai ,h
P (q X,hGm , X,hGm |G, ) =
xi ,hm |G, ).

pau xi

CTBNs case, Dirichlet distribution used prior parameters
multinomial distribution gamma distribution used prior parameters
u

exponential distribution. sufficient statistics modified follows: Txpa
,hm
amount time spent state X = xi P a(X) = pau interval H(X) = hm ,
Mxpai xuj ,hm number transitions state X = xi state X = xj P a(X) = pau
P
interval H(X) = hm . let Mxpai ,hu = xj 6=xi Mxpai xuj ,hm number times
X leaves state xi parents P a(X) state pau interval H(X) = hm .
3.2.3 Marginal Likelihood
Given graphs sequence G, transition times , marginal likelihood P (D|G, )
dataset computed closed form using priors sufficient statistics
previously defined. derive Bayesian-Dirichlet equivalent metric nsCTBNs,
make assumptions CTBNs. case, parameter independence
assumption divided global (16), interval (17) local (18) parameter independence.
Therefore, marginal likelihood becomes:

P aG (X)
P aG (X)
P (D|G, ) =
L(q X,H(X)
|D) L( X,H(X)
|D).
(19)
XX

marginal likelihood q equation (19) calculated follows:
(pau +1)


xi ,hm
pau
pau
u
+
1

+

xpai ,h



xi ,hm
xi ,hm

P aG (X)
L(q X,H(X) |D) =
(pau +M pau +1) ,


xi ,hm
xi ,hm
pau
pau
pa
hm pau xi u + 1
xi ,hm + Txi ,hm
xi ,hm

(20)

marginal likelihood equation (19) calculated follows:




pau
pau
u
xpai ,h


+





xi xj ,hm
xi xj ,hm

P aG (X)




L( X,H(X)
|D) =
.
pau
pau
pau
xi xj ,hm
hm pau xi =xj xi ,hm + Mxi ,hm
xi 6=xj
(21)
important note nsCTBNs, pseudocounts well imaginary
amount time associated interval. aspect requires careful choice
order biased towards values small intervals analyzed.
possible correction weight CTBNs hyperparameters quantity proportional time interval width (hm hm1 ), hM denotes total time. Thus,
nsCTBNs hyperparameters could defined follows:
xpai xuj ,hm
xpai ,hu

(hm hm1 )
,
hM
(hm hm1 )
= xpai u
.
hM
= xpai xuj

9

(22)
(23)

fiVilla & Stella

want control parameter priors using two hyperparameters ,
use uniform BDe nsCTBNs (BDeu). case, hyperparameters
defined (22) (23) divided number U possible configurations
parents P a(X) node X times cardinality domain X, follows:
xpai xuj ,hm

=

xpai ,hu

=

(hm hm1 )
,
UI
hM
(hm hm1 )
.
UI
hM

(24)
(25)

Equations (22) (23) rescale hyperparameters way biased
respect epochs length, equations (24) (25) based uniform
distribution used performing numerical experiments.
3.3 Bayesian Score Decomposition
Bayesian score decomposed variable based information available
transition times. regard, three knowledge settings used derive
Bayesian score, namely: known transition times (KTT), known number epochs (KNE)
unknown number epochs (UNE).
3.3.1 Known Transition Times
setting, transition times known. Thus, prior probability
graphs sequence P (G|T ) decomposes equation (15), marginal likelihood
decomposes variable X according equation (19).
Therefore, Bayesian score BS(G : D, ) written follows:
BS(G : D, ) = ln P (G1 ) + ln P (G1 , . . . , GE1 |T )
P (X)

P (X)

G
G
+ ln L(q X,H(X)
|D) + ln L( X,H(X)
|D).

(26)

setting structural learning problem non-stationary continuous time
Bayesian network consists finding graph G1 active first epoch (e = 1)
E 1 sets edge changes G1 , . . . , GE1 together corresponding parameters
values, maximize Bayesian score defined equation (26).
graphs G2 , . . . , GE selected making assumptions ways
edges change continuous time. common approach (Robinson & Hartemink, 2010)
consists assuming graphs sequence G = (G1 , . . . , GE ) depends parameter
controls number edge changes continuous time. approach uses
truncated geometric distribution, parameter p = 1 exp(c ), model number
parents changes occurring transition time te+1 :
X
ce =
|Ge (X)|.
(27)
XX

variable ce counts number edge changes two consecutive graphs Ge
Ge+1 , parameter c controls impact number edge changes ce
score function (26).
10

fiLearning Continuous Time Bayesian Networks Non-stationary Domains

edge changes Ge assumed mutually independent, probability
edge changes subsequent epochs written follows:
P (G1 , . . . , GE1 |T ) =

E1

e=1

E1

(1 exp(c ))(exp(c ))ce

(exp(c ))ce ,
1 (exp(c ))cmax +1

(28)

e=1

cmax truncation term. Therefore, assume truncated geometric distribution number parents changes occurring transition times equation
(28) holds, Bayesian score (26) decomposes variable X follows:
BS(G : D, ) =

X

ln P (P a(X) = P aG1 (X)) c

XX
P (X)

G
+ ln L(q X,H(X)
|D) +

E1
X

ce
e=1
P aG (X)
ln L( X,H(X)
|D).

(29)

worthwhile notice number parents changes ce epoch e
penalizes Bayesian score, thus discourages sudden variations parents set
consecutive epochs, parameter c controls impact changes
score function (26).
3.3.2 Known Number Epochs
transition times unknown, Bayesian score written follows:
BS(G, : D) = ln P (G, ) + ln P (D|G, ).

(30)

Assuming P (G, ) = P (G)P (T ) Bayesian score (30) becomes:
BS(G, : D) = ln P (G) + ln P (T ) + ln P (D|G, ).

(31)

number epochs E known, prior probability P (G) graphs
sequence G decomposes equation (15), truncated geometric distribution
used number parents changes occurring transition time,
known transition times setting.
choice P (T ) made include prior knowledge set transition
times. However, information available, uniform prior P (T ) used, implying
possible values transition times equally likely given number epochs
E. Thus, Bayesian score (31) decomposed variable X follows:
BS(G, : D) = ln P (T ) +
+

X

ln P (P a(X) = P aG1 (X)) c

XX
P aG (X)
ln L(q X,H(X) |D)

E1
X

ce

e=1
P (X)

G
+ ln L( X,H(X)
|D),

(32)

ce counts number edge changes two consecutive parents sets, c
controls impacts BS(G, : D) edge changes, happens KTT
setting.
11

fiVilla & Stella

3.3.3 Unknown Number Epochs
number epochs E unknown, transition times unknown well.
setting, learn nsCTBN exploiting introduced KTT
KNE settings. assume structure non-stationary continuous time
Bayesian network evolve different speeds continuous time. assumption
incorporated using truncated geometric distribution parameter p = 1exp(e )
number epochs. general, large values e encode strong prior belief
structure nsCTBN changes slowly (i.e. epochs exist).
Following presented KTT setting, Bayesian score obtained
subtracting parameter e times number epochs E. Therefore, Bayesian
score BS(G, : D) decomposes variable X follows:
BS(G, : D) = ln P (T ) e E +

X

ln P (P a(X) = P aG1 (X)) c

ce

e=1

XX
P (X)

E1
X

P (X)

G
G
+ ln L(q X,H(X)
|D) + ln L( X,H(X)
|D).

(33)

Note Bayesian score (33) contains two parameters, namely c e ,
encode prior belief structure nsCTBN. Specifically, parameter c
regulates prior belief smoothness edge changes (e.g. encouraging
discouraging edge changes per epoch), parameter e regulates prior belief
number epochs (e.g. encouraging discouraging creation epochs).

4. Structural Learning
optimal structure nsCTBNs found separately maximizing components
Bayesian score associated node. achieved using exact optimization algorithm based dynamic programming transition times
given. contrast, number epochs known information
transition times available, resort approximate techniques based Monte
Carlo simulated annealing. present exact algorithm solving structural
learning problem KTT setting. Then, briefly outline stochastic algorithms
solve structural learning problem KNE setting UNE setting.
4.1 Known Transition Times
setting Bayesian score decomposes according equation (29). Thus,
optimal graphs sequence G found separately searching optimal parents sequence G X node X. solve problem finding optimal parents sequence
G X node X consider sequence consisting intervals H(X) = (h1 , . . . , hM )
possible parents, Z = 2S possible parents sets. find optimal parents
sequence G X must compute Z marginal likelihood terms associated q ,
one marginal likelihood term possible parents set P az (X) interval hm .
Then, optimization algorithm used find maximum component
Bayesian score associated node X.
12

fiLearning Continuous Time Bayesian Networks Non-stationary Domains

exhaustive search would prohibitive, would require evaluating Z scores,
one possible parents sequence G X . Unfortunately, also greedy search strategy
computes parents set maximizes Bayesian score interval
viable. fact, function counts parents changes ce (29) binds choice
subsequent parents set, i.e. binds Ge Ge+1 .
However, relation score variable X associated parents set
P a(X)
P a(X) interval hm , denoted BSX,hm , score associated parents set
P a(X)

P a(X) interval hm1 , denoted BSX,hm1 , defined recursion follows:
n

P a(X)
P (X)
P a(X) P a(X)
BSX,hm = max BSX,hzm1 c cX,e + ln L(q X,hm , X,hm |D) ,
(34)
P az

cX,e = |Ge (X)|, marginal likelihoods q grouped together.
P a(X)
score BSX,hm , associated parents set P a(X) node X interval hm ,
introduced clarify recursion used Algorithm 1. Note score depends
components score hm . particular, marginal likelihoods
component involved, also term cX,e , counts parents changes, included
binds choice subsequent parents sets. Equation (34) exploited dynamic
programming select optimal parents sequence G X node X.
Algorithm 1 takes input marginal likelihoods q interval
parents set, prior probability initial parents set, number parents
changes, parameter c . Algorithm 1 ensures optimal parents sequence G X
node X corresponding optimal Bayesian score. core computation
Z score matrix, denoted SC, dynamic programming recursion.
dynamic programming recursion interval h1 (m = 1) defined follows:
P (X)

SC1z = ln L(q X,hz1

P (X)

, X,hz1

|D) + ln P (P az (X) = P aGh1 (X)),

(35)

1 z Z, while, intervals hm (m = 2, . . . , ), recursion is:
n

P (X) P (X)
z
u
SCm
= max SCm1
+ ln L(q X,hzm , X,hzm |D) c cX,e .
1uZ

filling score matrix SC, value maxz {SC[M, z]} optimal Bayesian score,
optimal parents sequence reconstructed backwards 1 using
index matrix . cost computing dynamic programming recursion O(M Z 2 ),
polynomial fixed maximum number parents S.
problem selecting optimal parents sequence interesting graph representation. Indeed, possible create graph whose nodes associated marginal
likelihoods q interval hm parents set P az (X), node associated interval hm linked nodes associated interval hm+1 .
arc associated weight computed difference marginal likelihoods interval hm parents set P az (X) cost switching
parents set interval hm1 parents set interval hm . Two special nodes
added represent start end optimal parents sequence. graph
cycles, thus selection optimal parents sequence node
reduced longest path problem start node end node directed
acyclic graph, thus solved using either dynamic linear programming.
13

fiVilla & Stella

Algorithm 1 LearnKTTX
Require: matrix containing marginal likelihoods q LX[M, Z], vector containing prior probability initial parents set P R[Z], matrix containing
number parents changes C[Z, Z] parameter parents changes c .
Ensure: score matrix SC[M, Z] index matrix [M, Z].
1: Initialize SC[m, z] , [m, z] 0.
2: 1, . . . ,
3:
z 1, . . . , Z
4:
(m = 1)
5:
SC[m, z] ln LX[m, z] + ln P R[z]
6:
else
7:
w 1, . . . , Z
8:
score SC[m 1, w] + ln LX[m, z] c C[w, z]
9:
(score > SC[m, z])
10:
SC[m, z] score
11:
[m, z] w
12:
end
13:
end
14:
end
15:
end
16: end
Learning nsCTBN done following following four steps procedure: i) use
u
dataset compute variable X sufficient statistics Txpa
Mxpai xuj ,hm
,hm
according given transition times ; ii) compute marginal likelihoods (20) (21),
fill LX matrix; iii) run Algorithm 1 node X get corresponding
optimal parents sequence; iv) collect optimal parents sequence node X
compute corresponding CIMs using sufficient statistics already computed step i).
allow intervals differ transition times, i.e. obtained
one possible unions transition times; repeat learning
procedure E (E 1)/2 cases. possible speed computation
sufficient statistics aggregated intervals. way, read
dataset once, precomputed marginal likelihoods stored reused
intervals. Moreover, computations performed parallel node.
4.2 Known Number Epochs
setting, know number epochs, transition times given,
cannot directly apply Algorithm 1. However, tentative allocation transition
times given, apply Algorithm 1 obtain optimal nsCTBNs structure,
assumption different true transition times . find
optimal tentative allocation , i.e. allocation close possible , apply
simulated annealing (SA) algorithm (Kirkpatrick, Gelatt, & Vecchi, 1983).
14

fiLearning Continuous Time Bayesian Networks Non-stationary Domains

Simulated annealing iterative algorithm attempts find global optimum
x given function f (x) stochastic search feasible region. iteration
k, SA algorithm assumed state xk , samples proposal state x0
according proposal distribution x0 P 0 (|xk ). Then, SA algorithm computes
quantity = exp ((f (x) f (x0 ))/CT ), CT computational temperature.
SA algorithm accepts proposal state x0 probability equal min{1, }. Concisely,
SA always accepts proposal state x0 f (x0 ) > f (x) setting xk+1 = x0 ,
accepts proposal state x0 f (x0 ) < f (x) probability setting xk+1 = x0
probability xk+1 = xk probability (1 ), i.e. case state
SA algorithm change. computational temperature reduces iterations
according cooling schedule. shown one cools sufficiently slowly,
algorithm probably find global optimum (Kirkpatrick et al., 1983). design
cooling schedule important part SA algorithm (Bertsimas & Tsitsiklis,
1993). possible approach use exponential cooling schedule defined follows:
CTk = CT0 k , CT0 represents initial temperature, typically set 1.0,
cooling rate, usually set close 0.8, k current iteration (Murphy, 2012).
nsCTBNs case, state SA algorithm x associated tentative
allocation , function f (x) Bayesian score (32). Algorithm 2 takes input
sufficient statistics, parameters used run Algorithm 1 parameters
SA algorithm. solves structural learning problem KNE setting given
variable X ensuring optimal tentative allocation corresponding score.
Algorithm 2 LearnKNEX
Require: sufficient statistics SuffStatsX, prior probability P R[], number parents
changes C[, ], parameter c , tentative allocation , initial temperature CT0 , cooling
rate , number iterations Iters, truncation parameter z standard deviation .
Ensure: optimal tentative allocation best Bayesian score bestSC.
1: Initialize k 0, .
2: LX GetMLX(SuffStatsX , )
3: bestSC LearnKTTX(M LX, P R[], C[, ], c )
4: (k < Iters)
5:
TentativeAllocation(T , z, )
6:
LX GetMLX(SuffStatsX , )
7:
tentSC LearnKTTX(M LX, P R[], C[, ], c )
8:
CT CT0 kn


9:
accP rob min 1, exp (bestSCtentSC)
CT
10:
ur UniRand()
11:
(ur accP rob)
12:

13:
currSC tentSC
14:
end
15:
k k+1
16: end
17: bestSC currSC
15

fiVilla & Stella

simulated annealing parameters used include tentative allocation ,
initial temperature CT0 , cooling rate number iterations Iters
exponential cooling schedule. Moreover, truncation parameter z standard deviation
used selection new tentative allocation 0 according random
procedure shown Algorithm 3. procedure selects transition time discrete
uniform distribution, UniRandDiscr(T ), perturbs according truncated normal
distribution, StdNormRand(), standard deviation equal , addition
point masses z z, z represents truncation parameter.
Algorithm 3 TentativeAllocation
Require: tentative allocation , truncation parameter z standard deviation .
Ensure: new tentative allocation 0 .
1: UniRandDiscr(T )
2: 0 \
3: nr StdNormRand()
4: (nr < z)
5:
nr z
6: end
7: (nr > z)
8:
nr z
9: end
10: + nr
11: 0

4.3 Unknown Number Epochs
setting number epochs unknown; thus structural learning algorithm
must able move across different number epochs, well corresponding
transition times. Also case, used simulated annealing algorithm state
x tentative allocation function optimized f (x) Bayesian score
shown equation (33). cooling schedule set one used
KNE setting. proposal distribution differs one used KNE setting
uses two additional operators, namely split merge operators. split
operator allows split given interval [tm ; tm+1 ) two subintervals [tm ; t) [t; tm+1 )
tm , tm+1 . merge operator allows merge contiguous intervals [tm1 ; tm )
[tm ; tm+1 ) form wider interval [tm1 ; tm+1 ) tm1 , tm , tm+1 .
new state obtained sampling number epochs changes ec multinoulli distribution parameters (p1 , p2 , p3 ), p1 represents probability
number epochs next iteration |T | decreased one; p3 represents probability
number epochs next iteration |T | increased one, p2 represents
probability number epochs next iteration |T | change respect
current one. ec equal 2, Algorithm 2 invoked, ec equal 1,
merge operator applied invoking Algorithm 2, ec equal 3,
split operator applied invoking Algorithm 2.
16

fiLearning Continuous Time Bayesian Networks Non-stationary Domains

Algorithm 4 solves structural learning problem nsCTBN UNE setting
given node X ensuring optimal tentative allocation corresponding
Bayesian score. algorithm similar one used KNE settings,
uses Algorithm 5 apply split merge operators. left(t) function Algorithm
5 returns transition time comes immediately transition time t.
Algorithm 4 LearnUNEX
Require: sufficient statistics SuffStatsX, prior probability P R[], number parents
changes C[, ], parameter c , parameter e , tentative allocation , initial temperature
CT0 , cooling rate , number iterations Iters, truncation parameter z, standard deviation , split probability sp merge probability mp.
Ensure: optimal tentative allocation best Bayesian score bestSC.
1: Initialize k 0, .
2: bestSC LearnKTTX(GetMLX(SuffStatsX, ), P R[], C[, ], c ) e |T |
3: (k < Iters)
4:
SplitMerge(T , sp, mp)
5:
TentativeAllocation(T , z, )
6:
tentSC LearnKTTX(GetMLX(SuffStatsX, ), P R[], C[, ], c ) e |T |
7:
CT CT0 kn


8:
accP rob min 1, exp (bestSCtentSC)
CT
9:
ur UniRand()
10:
(ur accP rob)
11:

12:
currSC tentSC
13:
end
14:
k k+1
15: end
16: bestSC currSC
Algorithm 5 SplitMerge
Require: tentative allocation , split probability sp merge probability mp.
Ensure: new tentative allocation 0 .
1: 0
2: p UniRand()
3: (p < mp)
4:
UniRandDiscr(T )
5:
0 \
6: else
7:
(p < (mp + sp))
8:
UniRandDiscr(T )
9:
nt left(t) + tleft(t)
2
10:
0 nt
11:
end
12: end
17

fiVilla & Stella

5. Numerical Experiments
Numerical experiments performed synthetic real-world datasets. Synthetic
datasets used compare nsCTBNs nsDBNs KTT, KNE UNE knowledge settings terms accuracy, precision, recall F1 measure. following real-world
datasets: drosophila, saccharomyces cerevisiae songbird, used compare nsCTBNs
state-of-the-art algorithms, i.e. TSNI (a method based ordinary differential equations),
nsDBN (Robinson & Hartemink, 2010) non-homogeneous dynamic Bayesian networks
Bayesian regularization (TVDBN) (Dondelinger, Lebre, & Husmeier, 2013),
UNE knowledge setting. Drosophila, saccharomyces cerevisiae songbird datasets
collected fixed time intervals, thus analyzed additional real-world dataset, consisting financial/economic variables evolving different time granularities, exploit
expressiveness nsCTBNs events occur asynchronously. Note performance comparison using synthetic datasets benefits knowledge ground
truth, apply performance comparison using real-world datasets
ground truth available. cases, comparison exploits partial
meta-knowledge available specialized literature.
5.1 Synthetic Datasets
Artificially generated datasets include data sampled rich set nsDBN models,
i.e. nsDBN generated datasets, rich set nsCTBN models, i.e. nsCTBN generated
datasets. nsDBN nsCTBN models consist five nodes associated binary
ternary variables. Numerical experiments concern learning parents sets, transition
times number epochs single node. choice motivated fact
structural learning nsCTBN performed single node independently
remaining ones. However, transition times unknown, multiple parents
sets changes could make easier correctly identify times change.
5.1.1 nsDBN Generated Datasets
nsDBN generated datasets sampled nsDBN models5 associated following
number epochs E {2, 3, 4, 5}. particular, number epochs E, 10 different
nsDBN instances sampled obtain number datasets equal 10, one consisting single trajectory. Thus, 40 synthetic datasets used learn structure
nsDBN nsCTBN (number models =2) KTT, KNE UNE settings.
Structural learning experiments performed c = {1, 2, 4} e = {5, 10, 15}
nsCTBN = {1, 2, 4} = {10, 50, 100} nsDBN6 . overall number
1,200 experiments performed. particular, performed number epochs
number datasets number c number models = 41032 = 240 experiments
KTT setting, 240 KNE setting, number epochs number
datasets number c number e number models = 410332 = 720
experiments performed UNE setting.
5. Inter-slice arcs allowed, intra-slice arcs allowed. holds true nsDBN models
sampled obtain nsDBN generated datasets.
6. worthwhile mention parameters nsDBN counterparts c
e parameters nsCTBN.

18

fiLearning Continuous Time Bayesian Networks Non-stationary Domains

nsdbn jar executable7 (Robinson & Hartemink, 2010) used structural learning nsDBN, set maximum number proposed networks 500,000
burn-in period 50,000 nsDBN. nsCTBN learned using following parameters setting: Iters = 1,000, CT0 = 1,000, = 0.8, z = 3, = 1, sp = 0.3, mp = 0.3,
= 1 = 0.1 using BDeu metric. Furthermore, nsDBN nsCTBN set
maximum number parents 4. arcs occurred 90 percent
samples8 belong inferred nsDBN nsCTBN models. Accuracy (Acc), precision (P rc), recall (Rec) F1 measure (F1 ) achieved nsDBN nsCTBN learned
KTT, KNE UNE settings reported Table 1, 2 3 respectively.
worthwhile mention KNE UNE settings, nsDBNs nsCTBNs
almost always identified correct number epochs location associated
transition times. Accuracy, precision, recall F1 measure computed two
different ways. Firstly, included arcs true network epoch. Secondly,
excluded self-reference arcs, i.e. arcs connecting node two consecutive
time-slices true network epoch. fact, node nsCTBN
self-reference arc default, happen nsDBNs. means
first case nsDBN required learn arcs nsCTBN required do. Therefore,
ensure fair comparison nsCTBN nsDBN adopted second case. Tables 1,
2 3 report performance measure values computed excluding self-reference arcs
set arcs true networks epoch.
Table 1: nsCTBN compared nsDBN KTT setting nsDBN generated data.
Average, min (subscript) max (superscript) performance values 10 networks
c nsCTBN nsDBN.
Number epochs E
3
4

2
Acc
P rec
Rec
F1

5

nsDBN

nsCTBN

nsDBN

nsCTBN

nsDBN

nsCTBN

nsDBN

nsCTBN

0.961.00
0.93
0.901.00
0.67
0.771.00
0.40
0.801.00
0.57

0.921.00
0.75
1.001.00
1.00
0.851.00
0.50
0.911.00
0.67

0.950.98
0.93
0.791.00
0.50
0.670.83
0.43
0.710.91
0.47

1.00
0.920.75
1.00
1.001.00
1.00
0.860.63
1.00
0.920.77

0.950.99
0.89
0.871.00
0.40
0.650.90
0.25
0.730.95
0.31

1.00
0.820.63
1.00
0.960.75
1.00
0.700.38
1.00
0.800.50

0.940.97
0.89
0.851.00
0.50
0.580.80
0.25
0.690.86
0.35

0.820.95
0.55
0.991.00
0.80
0.710.91
0.33
0.820.95
0.47

According Tables 1, 2 3, nsDBNs consistently achieve greater accuracy values
achieved nsCTBNs three settings. Furthermore, nsDBNs
accuracy stable respect number epochs E happen
nsCTBNs. Indeed, number epochs E greater 3, nsCTBNs achieve
accuracy values significantly smaller achieved number
epochs E equal 2 3. happen nsDBNs accuracy
robust respect number epochs E.
7. acknowledge precious help Alex Hartemink let us use nsdbn jar executable program
learning nsDBN models. Furthermore, also provided drosophila songbird datasets.
8. Samples obtained parameters values.

19

fiVilla & Stella

Table 2: nsCTBN compared nsDBN KNE setting nsDBN generated data.
Average, min (subscript) max (superscript) performance values 10 networks
c nsCTBN nsDBN.
Number epochs E
3
4

2
Acc
P rec
Rec
F1

5

nsDBN

nsCTBN

nsDBN

nsCTBN

nsDBN

nsCTBN

nsDBN

nsCTBN

0.941.00
0.88
0.911.00
0.69
0.761.00
0.39
0.801.00
0.58

0.921.00
0.75
1.001.00
1.00
0.851.00
0.50
0.911.00
0.67

0.950.98
0.92
0.791.00
0.50
0.680.84
0.35
0.720.91
0.51

1.00
0.920.75
1.00
1.000.95
1.00
0.860.63
1.00
0.920.77

0.940.99
0.89
0.860.97
0.55
0.650.91
0.25
0.740.95
0.38

1.00
0.810.63
1.00
0.950.75
1.00
0.710.38
1.00
0.810.50

0.930.96
0.87
0.850.96
0.55
0.590.78
0.24
0.700.74
0.35

0.820.95
0.55
0.981.00
0.80
0.700.91
0.33
0.810.95
0.47

Table 3: nsCTBN compared nsDBN UNE setting nsDBN generated data.
Average, min (subscript) max (superscript) performance values 10 networks
c , e nsCTBN , nsDBN.
Number epochs E
3
4

2
Acc
P rec
Rec
F1

5

nsDBN

nsCTBN

nsDBN

nsCTBN

nsDBN

nsCTBN

nsDBN

nsCTBN

0.951.00
0.88
0.910.98
0.70
0.750.98
0.38
0.790.96
0.55

0.921.00
0.75
1.001.00
1.00
0.851.00
0.50
0.911.00
0.67

0.950.98
0.93
0.801.00
0.52
0.660.81
0.41
0.700.89
0.48

1.00
0.920.75
1.00
1.001.00
1.00
0.860.63
1.00
0.920.77

0.930.98
0.89
0.870.95
0.67
0.650.87
0.26
0.740.87
0.41

0.99
0.810.61
1.00
0.950.73
0.99
0.700.36
0.99
0.800.48

0.920.96
0.89
0.840.90
0.71
0.570.78
0.23
0.680.85
0.34

0.810.93
0.55
0.981.00
0.80
0.690.87
0.33
0.810.93
0.47

different picture emerges focusing task discover positive arcs. Indeed,
case nsCTBNs achieve values precision, recall F1 measure, always
greater achieved nsDBNs. nsCTBNs achieve precision values robust
respect knowledge settings number epochs E.
hold true recall performance measure. Indeed, nsCTBNs achieve robust recall
respect knowledge settings (KTT, KNE UNE), recall achieved
nsCTBNs significantly degrades moving 2 3 epochs knowledge
settings. happens F1 measure achieved nsCTBNs. results
numerical experiments suggest nsCTBNs effective nsDBNs discover
positive arcs, even datasets generated using nsDBNs. possible explanation
behavior learning nsDBNs difficult learning nsCTBNs.
particular, nsDBNs must learn self-reference arcs nsCTBNs not. Furthermore,
node, nsCTBNs learn locally sequence parents sets
happen nsDBNs. fact, nsDBNs learn globally sequence parents sets
nodes, i.e. globally learn sequence networks, thus solve learning
problem difficult one solved nsCTBNs.
20

fiLearning Continuous Time Bayesian Networks Non-stationary Domains

5.1.2 nsCTBN Generated Datasets
generated 40 synthetic datasets E {2, 3, 4, 5}, datasets used
learn structure nsCTBN three knowledge settings. parameters
setting used one used nsCTBN learning nsDBN generated datasets (for
nsCTBN, used = 1, = 0.1 BDeu metric), while, case,
perform structural learning experiments nsDBN models9 . graphical structures
nsCTBN models sampled obtain datasets sampled
obtain nsDBN datasets. goal experiments analyze performance
nsCTBN structural learning algorithms three knowledge settings.
analysis data reported Tables 4, 5 6 brings us conclude
nsCTBN structural learning algorithms work well three settings according
considered performance measures. Accuracy, recall F1 measure decrease slightly
number epochs increases 2 5. particular, recall measure suffers
greatest decrease 1 0.95 number epochs increases 2 5.
Accuracy F1 measure robust respect number epochs,
precision robust performance measure respect different datasets
different values number epochs knowledge settings.
Table 4: nsCTBN KTT setting nsCTBN generated data. Average, min
(subscript) max (superscript) performance values 10 networks c .

Acc
P rec
Rec
F1

2
1.00
1.001.00
1.00
1.001.00
1.00
1.001.00
1.00
1.001.00

Number
3
0.991.00
0.92
1.001.00
1.00
0.991.00
0.86
0.991.00
0.92

epochs E
4
0.991.00
0.94
1.001.00
1.00
0.991.00
0.89
0.991.00
0.94

5
0.981.00
0.90
1.001.00
1.00
0.961.00
0.86
0.981.00
0.92

Table 5: nsCTBN KNE setting nsCTBN generated data. Average, min
(subscript) max (superscript) performance values 10 networks c .

Acc
P rec
Rec
F1

2
1.00
1.001.00
1.00
1.001.00
1.00
1.001.00
1.00
1.001.00

Number
3
0.981.00
0.92
0.991.00
0.90
0.971.00
0.86
0.981.00
0.88

epochs E
4
0.991.00
0.94
1.001.00
0.99
0.981.00
0.89
0.991.00
0.94

5
0.971.00
0.90
1.001.00
0.97
0.961.00
0.85
0.981.00
0.90

9. nsCTBN generated data asynchronous involving different time granularities, thus nsDBN cannot
directly applied. option preprocess datasets adapt nsDBNs. Given
would strongly arbitrary penalizing nsDBNs, decided learn nsCTBN models.

21

fiVilla & Stella

Table 6: nsCTBN UNE setting nsCTBN generated data. Average, min
(subscript) max (superscript) performance values 10 networks c e .

2
1.00
1.001.00
1.00
1.001.00
1.00
1.001.00
1.00
1.001.00

Acc
P rec
Rec
F1

Number
3
0.991.00
0.92
1.001.00
1.00
0.991.00
0.86
0.991.00
0.92

epochs E
4
0.991.00
0.94
1.001.00
1.00
0.981.00
0.89
0.991.00
0.94

5
0.971.00
0.90
1.001.00
0.98
0.951.00
0.81
0.971.00
0.89

best worst values accuracy E = 5 reported Table 6 belong
experiments performed synthetic dataset number 3 number 9 respectively.
results illustrated hereafter. Figure 2(a) shows graphs sequence true nsCTBN
synthetic datasets number 3, Figure 2(b) displays posterior distribution
epochs (right), together distribution corresponding transition times
(left)10 learned nsCTBN UNE case. Figure 3 shows information
depicted Figure 2, synthetic dataset number 9. latter case,
distribution epochs slightly favor correct number epochs.

(a) True nsCTBN model.
Distribution transition times

Distribution number epochs

1

1
True
Retrieved
0.8
Posterior probability

Probability transition

0.8

0.6

0.4

0.2

0

0.6

0.4

0.2

0

5

10

15

20

25

30

35 40
Time

45

50

55

60

65

70

0

5
Number epochs

(b) Learned nsCTBN model results.

Figure 2: nsCTBN generated dataset number 3: (a) true graphs sequence E=5 epochs
(b) distribution transition times (left) posterior epochs (right) associated
nsCTBN inferred UNE setting.

10. Transition times whose distance less 0.1 aggregated.

22

fiLearning Continuous Time Bayesian Networks Non-stationary Domains

(a) True nsCTBN model.
Distribution transition times

Distribution number epochs

1

1
True
Retrieved
0.8
Posterior probability

Probability transition

0.8

0.6

0.4

0.2

0

0.6

0.4

0.2

0

5

10

15

20

25

30

35

40 45
Time

50

55

60

65

70

75

80

0

4
5
Number epochs

(b) Learned nsCTBN model results.

Figure 3: nsCTBN generated dataset number 9: (a) true graphs sequence E=5 epochs
(b) distribution transition times (left) posterior epochs (right) associated
nsCTBN inferred UNE setting.

5.2 Real-world Datasets
difficult find real-world datasets corresponding ground truth model
completely known and/or uniform consensus domain experts reached.
Therefore, decided use following three well-known datasets: drosophila, saccharomyces cerevisiae songbird compare performance nsCTBNs nsDBNs
state-of-the-art algorithms, i.e. TSNI TVDBN. datasets publicly
available, clearly described rich detailed discussion likely ground truth
models given specialized literature. Furthermore, macroeconomics dataset introduced analyzed. dataset consists 17 financial/economic variables collected
different time granularity spanning 1st January 1986 31st March 2015.
5.2.1 Drosophila
drosophila dataset includes mRNA expression levels 4,028 genes 67 successive time-points spanning four stages Drosophila melanogaster life cycle (Lebre
et al., 2010): embryonic (31 time-points), larval (10 time-points) pupal stage (18
time-points) first 30 days adulthood (8 time-points). comparative purposes
(Dondelinger et al., 2013), analyzed reduced drosophila dataset consisting
gene expression time-series 11 genes involved wing muscle development. Given
nsCTBNs based discrete variables, binarized expression level 11 genes
reduced drosophila dataset done literature (Zhao, Serpedin, & Dougherty,
2006; Guo, Hanneke, Fu, & Xing, 2007; Robinson & Hartemink, 2010).
23

fiVilla & Stella

Firstly, network inference task embryonic, larval, pupal adulthood morphogenic stages performed KTT setting (Robinson & Hartemink, 2010; Dondelinger et al., 2013). nsCTBN structural learning performed using following
parameter values c = {0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0} setting maximum number parents 4. nsCTBN learned different c values combined,
arcs occurred 20 percent samples included
inferred non-stationary continuous time Bayesian network. techniques predict
non-stationary directed networks (Robinson & Hartemink, 2010), precision, recall
F1 measure, computed respect networks inferred Zhao et al. (2006) Guo et
al. (2007), reported Table 7 nsDBN, nsCTBN TVDBN (Dondelinger et al.,
2013). networks associated four epochs, inferred nsCTBN
reduced drosophila dataset KTT setting, depicted Figure 4.
Table 7: Precision (Prec), recall (Rec) F1 measure (F1 ) achieved nsCTBN, nsDBN,
TVDBN drosophila dataset computed respect networks inferred
Zhao et al. (2006) Guo et al. (2007). Average values (Average) precision, recall
F1 measure achieved Zhao et al. (2006) Guo et al. (2007) also reported.

nsDBN
nsCTBN
TVDBN

Zhao
Prec
0.58
0.33
0.17

et al. (2006)
Rec
F1
0.38 0.46
0.37 0.35
0.27 0.21

Guo et al. (2007)
Prec Rec
F1
0.47 0.34 0.39
0.41 0.43 0.42
0.36 0.61 0.45

Prec
0.52
0.37
0.27

Average
Rec
F1
0.36 0.42
0.40 0.39
0.44 0.33

According Table 7, optimal algorithm exists reduced drosophila dataset.
network retrieved Zhao et al. (2006) used ground truth, nsDBN
best model, network retrieved Guo et al. (2007) network used ground
truth, TVDBN optimal one far F1 measure concerned. average
performance computed, nsDBN best model TVDBN worst;
nsCTBN achieves F1 value close one achieved nsDBN.
Secondly, investigated whether transition times inferred structural learning
nsCTBN UNE setting correspond known transitions stages (Lebre
et al., 2010; Dondelinger et al., 2013). network inference task performed learning
nsCTBN UNE setting following parameter values c = {0.2, 0.4, 1, 2}
e = {0.5, 1, 2, 5}. Furthermore, set maximum number parents 2,
number iterations 1,000 number runs 100.
Figure 5 shows distribution transition times11 (left) posterior
number epochs (right). number epochs correctly detected 4 even
probability close 0.1 associated 5 epochs. However, transition times
correctly identified. embryonic stage correctly identified, larval stage
correctly discovered start time-point 31, inferred end time-point 38
11. stem represents posterior probability corresponding time-point starts new epoch.
Therefore, stem time-point means epoch ends time-point 1, next epoch
starts time-point t.

24

fiLearning Continuous Time Bayesian Networks Non-stationary Domains

instead 40. nsCTBN identify pupal adulthood stages, identified
two additional transition times (17 51). behavior observed nsDBNs,
TVDBNs capable correctly identify pupal adulthood stages. However, TVDBN-0, TVDBN-Exp TVDBN-Bino inferred networks (Dondelinger et al.,
2013) consist number epochs ranging 6 7.

mhc

mhc
gfl

gfl

mlc1

mlc1

eve

eve

msp300

msp300

actn

actn

myo61f

myo61f





prm

prm
twi

twi

sls

sls

(a) Embryonic (epoch 0 30).

(b) Larval (epoch 31 41).

mhc

mhc
gfl

gfl

mlc1

mlc1

eve

eve

msp300

msp300

actn

actn

myo61f

myo61f





prm

prm
twi

twi

sls

sls

(c) Pupal (epoch 42 59).

(d) Adulthood (epoch 60 66).

Figure 4: Networks inferred nsCTBN KKT setting reduced drosophila
dataset. arcs occurred 20 percent networks associated
different c values included inferred nsCTBN model.

25

fiVilla & Stella

Distribution transition times

Distribution number epochs

1

1
Retrieved
0.8
Posterior probability

Probability transition

0.8

0.6

0.4

0.2

0

0.6

0.4

0.2

0 3 6 9 12 15 18 21 24 27 30 33 36 39 42 45 48 51 54 57 60 63 66
Time

0

4
5
Number epochs

Figure 5: Transition time graph (left) posterior probability histogram number
epochs E (right) associated nsCTBN model learned drosophila reduced
dataset UNE setting c = 0.2 e = 2.

5.2.2 Saccharomyces Cerevisiae
saccharomyces cerevisiae dataset obtained synthetic regulatory network
5 genes saccharomyces cerevisiae (Cantone, Marucci, Iorio, Ricci, Belcastro, Bansal,
Santini, di Bernardo, di Bernardo, & Cosma, 2009). obtained measuring gene
expression time-series RT-PCR (reverse transcription polymerase chain reaction)
16 21 time-points two conditions related carbon source: galactose (switch
experimental condition) glucose (switch experimental condition). merged
time-series two experimental conditions exclusion boundary point
done literature (Dondelinger et al., 2013). obtained time-series binarized
way 1 indicates gene expression level greater equal
sample mean, 0 indicates gene expression level smaller sample mean.
obtained dataset used infer saccharomyces cerevisiae networks associated
switch switch experimental conditions.
network inference task performed learning nsCTBN UNE setting
following parameter values c = {0.2, 0.4, 1, 2} e = {0.2, 0.4, 1, 2}. Furthermore, set maximum number parents 4, number iterations 1,000
number runs 100. arcs occurred 50 percent runs
included inferred nsCTBN model. Precision, recall F1 measure values achieved
nsCTBN compared achieved state-of-the-art algorithms (i.e. TSNI,
nsDBN TVDBN) Table 8.
result performed numerical experiment shows nsCTBN competitive respect state-of-the-art algorithms, achieves non-optimal results
precision associated switch experimental condition. condition,
5
nsCTBN achieves precision equal 0.5 ( 10
), optimal value achieved TSNI
4
TVDBN 0.8 ( 5 ). contrary, nsCTBN achieves best recall value,
equal 0.63 ( 85 ). switch experimental condition, nsCTBN achieves best
value precision, equal 0.67 ( 69 ), recall, equal 0.75 ( 68 ).
26

fiLearning Continuous Time Bayesian Networks Non-stationary Domains

also computed overall performance structural learning algorithms.
case, focusing attention F1 measure, conclude nsCTBN (0.63)
comparable TVDBN (0.60), considered state-of-the-art algorithm
structural learning task applied saccharomyces cerevisiae dataset. networks
inferred nsCTBN model switch switch experimental conditions,
using c = 0.2 c = 2, depicted Figure 6.
Table 8: nsCTBN compared TSNI, nsDBN, TVDBN learning saccharomyces cerevisiae dataset. nsCTBN learned UNE setting (c = 0.2, e = 2);
time-point 17 used transition time switch switch experimental conditions. TSNI, nsDBN TVDBN networks described specialized
literature. Precision, recall F1 measure reported switch switch
experimental conditions. number true positive arcs (superscript) sum
true false positive arcs (subscript) reported precision, number true
positive arcs (superscript) sum true positive false negative arcs (subscript)
reported recall. Performance values achieved aggregating inferred networks
two epochs also reported.

TSNI
nsDBN
TVDBN
nsCTBN

Switch
P rec
Rec
0.8045 0.5048
0.3326 0.2528
0.8045 0.5048
0.50510 0.6358

F1
0.62
0.29
0.62
0.56

Switch
P rec Rec
F1
0.6035 0.3838 0.46
0.6035 0.3838 0.46
0.5659 0.6358 0.59
0.6769 0.7568 0.71

GAL4

F1
0.54
0.37
0.60
0.63

GAL4

GAL80

CBF1

SWI5

Aggregated
P rec
Rec
0.70710 0.44716
0.45511 0.31516
0.64914 0.56916
0.5811
0.6911
19
16

GAL80

ASH1

SWI5

(a) Switch network.

CBF1

ASH1

(b) Switch network.

Figure 6: Switch (a) switch (b) networks inferred nsCTBN saccharomyces cerevisiae dataset UNE setting c = 0.2, e = 2. two pictures
report positive arcs (black continuous), false negative arcs (red dashed)
false positive arcs (green dotted) inferred networks.
27

fiVilla & Stella

Figure 7 shows posterior distribution number epochs (left) together
distribution transition times (right) nsCTBN learned c = 0.2 e = 2.
transition switch switch experimental conditions known
occur time-point 17 (i.e. switch epoch starts time-point 18). worthwhile
notice small number arcs, associated synthetic regulatory network
saccharomyces cerevisiae, suggests one careful evaluating
result performed numerical experiment. particular, think overstatements
effectiveness and/or superiority different structural learning algorithms
learning task saccharomyces cerevisiae dataset avoided.
Distribution transition times

Distribution number epochs

1

1
Retrieved
0.8
Posterior probability

Probability transition

0.8

0.6

0.4

0.2

0

0.6

0.4

0.2

0

2

4

6

8

10 12 14 16 18 20 22 24 26 28 30 32 34 36
Time

0

2
Number epochs

Figure 7: Transition time graph (left) posterior probability number epochs
(right) associated nsCTBN inferred saccharomyces cerevisiae dataset
UNE setting c = 0.2 e = 2. maximum aposteriori estimate
number epochs associated E = 2 epochs: epoch 1 starts time-point 1
ends time-point 17, epoch 2 starts time-point 18 ends time-point 36.

5.2.3 Songbird
songbird dataset collected eight electrodes placed vocal nuclei six
female zebra finches (Smith et al., 2006). Voltage changes recorded populations
neurons birds provided four different two-second auditory stimuli,
presented 18 20 times. Voltages post-processed root mean square
transformation binned 5 ms (Robinson & Hartemink, 2010).
songbird dataset used learn neural information flow networks, i.e. networks
represent transmission information different regions songbird
brain. neural information flow network represents dynamic utilization potential
pathways along information travel. identification neural information
flow networks songbirds auditory stimuli allows understand sounds
stored processed songbirds brain. songbird dataset consists data
8 variables recorded electrodes two seconds pre-stimulus, two seconds
stimulus two seconds post-stimulus six birds. stimuli hear-song, i.e.
bird hears another bird singing, white-noise, i.e. bird hears white noise stimulus.
28

fiLearning Continuous Time Bayesian Networks Non-stationary Domains

show results nsCTBN learned two six birds songbird
dataset, namely bird 648 bird 841. results obtained four birds
similar. Given nsCTBNs based discrete variables, values 8 variables
discretized three bins using uniform quantiles (0, 13 , 23 , 1) according literature
(Robinson & Hartemink, 2010). inference task neural information flow networks
performed learning nsCTBN UNE setting following parameter
values c = {0.25, 0.5, 1, 2, 5, 10} e = {0.25, 0.5, 1, 2, 5, 10}. set maximum
number parents 3, number iterations 500 number runs 10.
Figure 8 (a) (b) show probability transition (left) posterior probability
number epochs (right) bird 648 bird 841 white-noise stimulus.
Figure 9 (a) (b) show probability transition (left) posterior probability
number epochs (right) bird 648 bird 841 hear-song stimulus.
Distribution transition times

Distribution number epochs

0.5

1
Retrieved
0.8
Posterior probability

Probability transition

0.4

0.3

0.2

0.1

0

0.6

0.4

0.2

0

0.5

1

1.5

2

2.5

3
Time

3.5

4

4.5

5

5.5

0

6

3
4
Number epochs

(a) white-noise stimulus bird 648: learned model results.
Distribution transition times

Distribution number epochs

0.5

1
Retrieved
0.8
Posterior probability

Probability transition

0.4

0.3

0.2

0.1

0

0.6

0.4

0.2

0

0.5

1

1.5

2

2.5

3
Time

3.5

4

4.5

5

5.5

6

0

3
4
Number epochs

(b) white-noise stimulus bird 841: learned model results.

Figure 8: Distribution transition times posterior distribution epochs
nsCTBN UNE setting songbird dataset white-noise stimulus.
29

fiVilla & Stella

location transition time-points white-noise stimulus hearsong stimulus accurately inferred bird 648 bird 841. posterior distribution
number epochs birds 648 841 white-noise stimulus nearly
equally split 3 4 epochs, hear-song stimulus peaked 3
epochs. Therefore, number epochs location transition time-points
reliably recovered nsCTBN learned UNE setting. Unfortunately,
able find additional information validate learned nsCTBNs
dataset. Moreover, comparison across different birds eventually develop consensus
network possible due songbird data collection settings. Indeed, six
birds characterized electrodes, make difficult obtain correspondence
map across different birds.

Distribution transition times

Distribution number epochs

0.5

1
Retrieved
0.8
Posterior probability

Probability transition

0.4

0.3

0.2

0.1

0

0.6

0.4

0.2

0

0.5

1

1.5

2

2.5

3
Time

3.5

4

4.5

5

5.5

0

6

3
4
Number epochs

(a) hear-song stimulus bird 648: learned model results.
Distribution transition times

Distribution number epochs

0.5

1
Retrieved
0.8
Posterior probability

Probability transition

0.4

0.3

0.2

0.1

0

0.6

0.4

0.2

0

0.5

1

1.5

2

2.5

3
Time

3.5

4

4.5

5

5.5

6

0

3
4
Number epochs

(b) hear-song stimulus bird 841: learned model results.

Figure 9: Distribution transition times posterior distribution epochs
nsCTBN UNE setting songbird dataset hear-song stimulus.

30

fiLearning Continuous Time Bayesian Networks Non-stationary Domains

5.2.4 Macroeconomics
macroeconomics dataset consists 17 financial/economic time-series pertaining
economy United States. Time-series different time granularity span
1st January 1986 31st March 2015. specifically, five time-series daily granularity, namely Crude oil (OIL), USD EUR spot exchange rate (USDEUR), Gold (GOLD),
S&P500 equity index (S&P500) 10-years treasury bond yield rate (US10yrsNote).
Eleven time-series monthly granularity, namely production total industry (PTI),
real manufacturing trade industries sales (RMTIS), personal income (PI), unemployment (UN), consumer price index (CPI), federal funds rate (RATE), producer price index
(PPI), non-farm payrolls (NFP), new one-family houses sold (NHSold), new houses sale
(NHSale) new private house permits (NHPermit). Finally, gross domestic product
(GDP) time-series quarterly granularity.
goal study discover financial economic environment evolves
time. particular, focused attention detect business cycles12
associated change relationships among financial economic variables. Given
duration business cycle highly variable, ability identify turning point
cycle (i.e. recession starts) considerable importance policymakers, financial
companies well individuals. substantial literature available business
cycle turning points detection generally relying Markov-switching models (Hamilton &
Raj, 2005). However, models able represent important features
dependence structure among variables business cycle.
order use nsCTBN model context, applied binary discretization
variable associated time-series. Discretization performed using lookback period 1 year, i.e. current value greater past one, binary
variable set 1 otherwise, set 0. approach looking back past
widely used finance (Moskowitz, Ooi, & Pedersen, 2012). nsCTBNs learning
performed UNE setting using following parameter values: c = {0.5, 1, 2},
e = {0.1, 1, 10}, 2 maximum parents per node, 300 iterations 10 runs.
Figure 10 shows probability transition (left side, left axis) versus S&P500
equity index used reference (left side, right axis) posterior probability
number epochs (right side). nsCTBN consists three epochs transition times
close end July 2000 end November 2007. compare dates
turning points US business cycle reported National Bureau Economic
Research13 , see far turning point March 2001
close one December 2007, missed turning point occurred
July 1990, probably limited length dataset.
Figure 11 shows structure nsCTBN model corresponding probable
number epochs, i.e. E = 3. arc included nsCTBN model occurs
75% performed runs epoch. retrieved networks correspond
following time periods: January 1986 July 2000 (epoch 1), August 2000
November 2007 (epoch 2) December 2007 March 2015 (epoch 3).
12. Business cycles fluctuations aggregate economic activity, recurrent (i.e. possible
identify expansion-recession cycles), persistent periodic (i.e. differ length severity).
13. official business cycle turning points dates available http://www.nber.org/cycles.html

31

fiVilla & Stella

Distribution transition times vs S&P500

Distribution number epochs
2500

1

0.8

2000

0.8

0.6

1500

0.4

1000

0.2

500

1

Posterior probability

Value

Probability transition

Retrieved (left)
S&P500 (right)

0
1985

1990

1995

2000
2005
Time

2010

0.4

0.2

0
2020

2015

0.6

0

2

3
4
5
Number epochs

Figure 10: Distribution transition times S&P500 behavior time (left). Posterior probability epochs (right) learned nsCTBN UNE setting.
USDEUR

OIL
GOLD

USDEUR
OIL

UN

GOLD

US10YRS

US10YRS

PPI

NHPer

CPI

PPI

NHPer

PTI

SP500

PTI

SP500

PI
RMTIS

NHSale

RATE

PI

CPI

RMTIS

RATE
NFP

GDP
NHSold
NFP

GDP
UN

NHSale

(a) Epoch 1 (Jan 1986 - Jul 2000).

NHSold

(b) Epoch 2 (Aug 2000 - Nov 2007).
USDEUR
OIL

PPI

US10YRS

GOLD
NHSale

SP500
PTI

CPI

RATE

NHPer
PI
RMTIS
NFP
UN
GDP

NHSold

(c) Epoch 3 (Dec 2007 - Mar 2015).

Figure 11: nsCTBN learned macroeconomics dataset UNE setting.
nsCTBN corresponds probable number epochs (E = 3). arc included
nsCTBN model occurs 75% runs epoch.

32

fiLearning Continuous Time Bayesian Networks Non-stationary Domains

novelty approach economic analysis opens door many considerations new speculations economic variables business cycles.
paper, highlight two patterns emerging learned nsCTBN model: well
known relevant role personal income (PI) relation unemployment (UN)
(Mankiw, 2014) less known relation non-farm payrolls (NFP) S&P500
equity index (S&P500) (Miao, Ramchander, & Zumwalt, 2014).

6. Conclusions
introduced non-stationary continuous time Bayesian networks developed three
structural learning algorithms used different knowledge settings (i.e. KTT,
KNE UNE) problem analyzed. structural learning algorithm
known transition times case exact exploits graph theory infer optimal
nsCTBNs structure. polynomial time complexity assumption
maximum number parents node fixed. nsCTBNs structural learning algorithms competitive state-of-the-art algorithms synthetic real-world
datasets considered. statement proved rich set numerical experiments.
nsCTBNs adapted use different score metrics, far considered score
metrics integrates non-structural parameters. nsCTBNs exploit interesting
property CTBNs offer possibility learn optimal nsCTBNs structure
single variable. could extremely useful case non-stationary
behavior analyzed system synchronous, thus may case
node changes parents independently nodes change parents set.
However, two main limitations exist nsCTBNs: i) variables assumed
discrete; specifically variable dataset must take value countable number
states ii) finding optimal value c e hyperparameters extremely
difficult (the true nsDBNs). Concerning i), problem discretizing continuous
variables studied long time robust solutions described
specialized literature. Discretizing continuous variables whose value measured time
studied intensively many issues still remain. problem ii) selecting
optimal value hyperparameters known specialized literature much
done experts provide valuable apriori knowledge. However, apriori
knowledge poor available all, selecting optimal hyperparameter values
extremely difficult. important note one strong limitations studying
comparing non-stationary models lack ground truth models.
Possible directions research include application nsCTBNs structural
learning algorithms datasets, arabidopsis thaliana dataset (Grzegorczyk,
Aderhold, & Husmeier, 2015) well financial datasets supported in-depth
economic analyses. Another interesting perspective study development
modeling approach, going towards direction allowing node change parents
set asynchronously. Furthermore, think increase applicability real-world
time-series data proposed nsCTBNs structural learning algorithms issue timeseries discretization must addressed. particular, think issue must
addressed integrated manner nsCTBNs structural learning algorithm.
33

fiVilla & Stella

Finally, could interesting apply framework nsCTBNs address
task classification objects streaming context using probabilistic graphical model based approach (Borchani, Martinez, Masegosa, Langseth, Nielsen, Salmeron,
Fernandez, Madsen, & Saez, 2015a; Borchani, Martnez, Masegosa, Langseth, Nielsen,
Salmeron, Fernandez, Madsen, & Saez, 2015b).

Acknowledgments
authors wish thank Alexander Hartemink kindly provided nsDBN
jar executable associated datasets. special thank goes Marco Grzegorczyk
providing arabidopsis thaliana dataset together fundamental information analyze
it. authors greatly indebted anonymous referees constructive comments
extremely helpful suggestions, contributed significantly improve
quality paper. special thank goes Associate Editor Manfred Jaeger.
Fabio Stella corresponding author article.

References
Acerbi, E., & Stella, F. (2014). Continuous time bayesian networks gene network reconstruction: comparative study time course data. 10th International
Symposium Bioinformatics Research Applications, Zhangjiajie, China, 2014,
10.
Acerbi, E., Vigano, E., Poidinger, M., Mortellaro, A., Zelante, T., & Stella, F. (2016).
Continuous time bayesian networks identify prdm1 negative regulator th17 cell
differentiation humans. Scientific Reports, 6, 23128.
Acerbi, E., Zelante, T., Narang, V., & Stella, F. (2014). Gene network inference using
continuous time bayesian networks: comparative study application th17 cell
differentiation. BMC Bioinformatics, 15 (1).
Ahmed, A., & Xing, E. P. (2009). Recovering time-varying networks dependencies social
biological studies. Proceedings National Academy Sciences, 106 (29),
1187811883.
Bertsimas, D., & Tsitsiklis, J. (1993). Simulated annealing. Statistical Science, 8 (1), 1015.
Borchani, H., Martinez, A. M., Masegosa, A., Langseth, H., Nielsen, T. D., Salmeron, A.,
Fernandez, A., Madsen, A. L., & Saez, R. (2015a). Dynamic Bayesian modeling
risk prediction credit operations. 13th Scandinavian Conference Artificial
Intelligence (SCAI 2015), Halmstad, Sweden.
Borchani, H., Martnez, A. M., Masegosa, A. R., Langseth, H., Nielsen, T. D., Salmeron,
A., Fernandez, A., Madsen, A. L., & Saez, R. (2015b). Modeling concept drift:
probabilistic graphical model based approach. 14th International Symposium
Intelligent Data Analysis (IDA 2015), Saint-Etienne, France.
Boudali, H., & Dugan, J. B. (2006). continuous-time bayesian network reliability modeling, analysis framework. IEEE Transactions Reliability, 55 (1), 8697.
34

fiLearning Continuous Time Bayesian Networks Non-stationary Domains

Burge, J., Lane, T., Link, H., Qiu, S., & Clark, V. P. (2009). Discrete dynamic bayesian
network analysis fmri data. Human brain mapping, 30 (1), 122137.
Cantone, I., Marucci, L., Iorio, F., Ricci, M. A., Belcastro, V., Bansal, M., Santini, S.,
di Bernardo, M., di Bernardo, D., & Cosma, M. P. (2009). yeast synthetic network
vivo assessment reverse-engineering modeling approaches. Cell, 137 (1),
172 181.
Dean, T., & Kanazawa, K. (1989). model reasoning persistence causation.
Comput. Intell., 5 (3), 142150.
Dondelinger, F., Lebre, S., & Husmeier, D. (2013). Non-homogeneous dynamic bayesian
networks bayesian regularization inferring gene regulatory networks
gradually time-varying structure. Machine Learning, 90 (2), 191230.
Durante, D., & Dunson, D. B. (2014). Bayesian dynamic financial networks timevarying predictors. Statistics & Probability Letters, 93, 1926.
Fan, Y., & Shelton, C. R. (2009). Learning continuous-time social network dynamics.
25th Conference Uncertainty Artificial Intelligence (UAI 2009), Montreal,
Canada.
Friedman, N., & Koller, D. (2000). bayesian bayesian network structure:
bayesian approach structure discovery bayesian networks. Machine Learning,
50, 95125.
Gatti, E., Luciani, D., & Stella, F. (2011). continuous time bayesian network model
cardiogenic heart failure. Flexible Services Manufacturing Journal, 24 (2),
496515.
Geiger, D., & Heckerman, D. (1997). characterization dirchlet distributions
local global independence. Annals Statistics, 25, 13441368.
Grzegorczyk, M., Aderhold, A., & Husmeier, D. (2015). Inferring bi-directional interactions circadian clock genes metabolism model ensembles. Statistical
Applications Genetics Molecular Biology, 14 (2), 143167.
Guo, F., Hanneke, S., Fu, W., & Xing, E. P. (2007). Recovering temporally rewiring networks: model-based approach. Machine Learning, Proceedings 24th International Conference (ICML 2007), Corvallis, USA, June 20-24, 2007, pp. 321328.
Hamilton, J. D., & Raj, B. (Eds.). (2005). Advances Markov-Switching Models: Applications Business Cycle Research Finance. Studies Empirical Economics.
Springer-Verlag.
Herbrich, R., Graepel, T., & Murphy, B. (2007). Structure failure. 2nd USENIX
workshop Tackling computer systems problems machine learning techniques
(SYSML 07), Cambridge, USA, pp. 16.
Kirkpatrick, S., Gelatt, C. D., & Vecchi, M. P. (1983). Optimization simulated annealing.
Science, 220 (4598), 671680.
Lebre, S., Becq, J., Devaux, F., Stumpf, M., & Lelandais, G. (2010). Statistical inference
time-varying structure gene regulation networks. BMC Systems Biology, 4 (1),
130+.
35

fiVilla & Stella

Liu, M., Hommersom, A., van der Heijden, M., & Lucas, P. J. (2016). Hybrid time bayesian
networks. International Journal Approximate Reasoning, .
Mankiw, N. G. (2014). Principles Macroeconomics (7th edition). South-Western College
Pub.
Marini, S., Trifoglio, E., Barbarini, N., Sambo, F., Camillo, B. D., Malovini, A., Manfrini,
M., Cobelli, C., & Bellazzi, R. (2015). dynamic bayesian network model longterm simulation clinical complications type 1 diabetes. Journal Biomedical
Informatics, 57, 369 376.
Miao, H., Ramchander, S., & Zumwalt, J. K. (2014). S&p 500 index-futures price jumps
macroeconomic news. Journal Futures Markets, 34 (10), 9801001.
Moskowitz, T. J., Ooi, Y. H., & Pedersen, L. H. (2012). Time series momentum. Journal
Financial Economics, 104 (2), 228250.
Mumford, J. A., & Ramsey, J. D. (2014). Bayesian networks fmri: primer. Neuroimage,
86, 573582.
Murphy, K. P. (2012). Machine Learning: Probabilistic Perspective. MIT Press.
Nodelman, U. (2007). Continuous Time Bayesian Networks. Ph.D. thesis, Stanford University.
Nodelman, U., & Horvitz, E. (2003). Continuous time bayesian networks inferring users
presence activities extensions modeling evaluation. Tech. rep. MSRTR-2003-97, Microsoft Research.
Nodelman, U., Shelton, C. R., & Koller, D. (2002). Continuous time bayesian networks.
18th Conference Uncertainty Artificial Intelligence (UAI 2002), Edmonton,
Canada, pp. 378387.
Nodelman, U., Shelton, C., & Koller, D. (2003). Learning continuous time bayesian networks. 19th Conference Uncertainty Artificial Intelligence (UAI 2003),
Acapulco, Mexico, pp. 451458.
Pearl, J. (1989). Probabilistic reasoning intelligent systems - networks plausible inference. Morgan Kaufmann series representation reasoning. Morgan Kaufmann.
Robinson, J. W., & Hartemink, A. J. (2010). Learning non-stationary dynamic bayesian
networks. Journal Machine Learning Research, 11, 36473680.
Scutari, M., & Denis, J.-B. (2014). Bayesian Networks Examples R. Chapman
Hall, Boca Raton. ISBN 978-1482225587.
Segal, E., Peer, D., Regev, A., Koller, D., & Friedman, N. (2005). Learning module networks. Journal Machine Learning Research, 6, 557588.
Smith, A. V., Yu, J., Smulders, T. V., Hartemink, A. J., & Jarvis, E. D. (2006). Computational Inference Neural Information Flow Networks. PLoS Computational Biology,
2 (11), e161+.
Spiegelhalter, D. J., & Lauritzen, S. L. (1990). Sequential updating conditional probabilities directed graphical structures. Networks, 20 (5), 579605.
36

fiLearning Continuous Time Bayesian Networks Non-stationary Domains

Sturlaugson, L., & Sheppard, J. W. (2014). Inference complexity continuous time bayesian
networks. 30th Conference Uncertainty Artificial Intelligence (UAI
2014), Quebec City, Canada, pp. 772779.
Vinh, N. X., Chetty, M., Coppel, R., & Wangikar, P. P. (2012). Gene regulatory network
modeling via global optimization high-order dynamic bayesian network. BMC
Bioinformatics, 13, 131.
Xu, J., & Shelton, C. R. (2008). Continuous time bayesian networks host level network
intrusion detection. European Conference Machine Learning Principles
Practice Knowledge Discovery Databases (ECML PKDD 2008), Antwerp,
Belgium, pp. 613627.
Zhao, W., Serpedin, E., & Dougherty, E. R. (2006). Inferring gene regulatory networks
time series data using minimum description length principle. Bioinformatics,
22 (17), 21292135.
Zou, M., & Conzen, S. D. (2005). new dynamic bayesian network (dbn) approach identifying gene regulatory networks time course microarray data. Bioinformatics,
21 (1), 7179.

37

fiJournal Artificial Intelligence Research 57 (2016) 345420

Submitted 9/15; published 11/16

Primer Neural Network Models
Natural Language Processing
Yoav Goldberg

yoav.goldberg@gmail.com

Computer Science Department
Bar-Ilan University, Israel

Abstract
past years, neural networks re-emerged powerful machine-learning
models, yielding state-of-the-art results fields image recognition speech
processing. recently, neural network models started applied also textual
natural language signals, promising results. tutorial surveys neural
network models perspective natural language processing research, attempt
bring natural-language researchers speed neural techniques. tutorial
covers input encoding natural language tasks, feed-forward networks, convolutional
networks, recurrent networks recursive networks, well computation graph
abstraction automatic gradient computation.

1. Introduction
decade, core NLP techniques dominated machine-learning approaches
used linear models support vector machines logistic regression, trained
high dimensional yet sparse feature vectors.
Recently, field seen success switching linear models
sparse inputs non-linear neural-network models dense inputs.
neural network techniques easy apply, sometimes almost drop-in replacements
old linear classifiers, many cases strong barrier entry. tutorial
attempt provide NLP practitioners (as well newcomers) basic background,
jargon, tools methodology allow understand principles behind
neural network models apply work. tutorial expected
self-contained, presenting different approaches unified notation
framework. repeats lot material available elsewhere. also points
external sources advanced topics appropriate.
primer intended comprehensive resource go
develop next advances neural-network machinery (though may serve good entry
point). Rather, aimed readers interested taking existing, useful
technology applying useful creative ways favourite NLP problems.
in-depth, general discussion neural networks, theory behind them, advanced
optimization methods advanced topics, reader referred existing
resources. particular, book Bengio, Goodfellow, Courville (2015) highly
recommended.
c
2016
AI Access Foundation. rights reserved.

fiGoldberg

1.1 Scope
focus applications neural networks language processing tasks. However,
subareas language processing neural networks deliberately left
scope tutorial. include vast literature language modeling acoustic
modeling, use neural networks machine translation, multi-modal applications
combining language signals images videos (e.g. caption generation).
Caching methods efficient runtime performance, methods efficient training large
output vocabularies attention models also discussed. Word embeddings
discussed extent needed understand order use inputs
models. unsupervised approaches, including autoencoders recursive
autoencoders, also fall scope. applications neural networks language
modeling machine translation mentioned text, treatment means
comprehensive.
1.2 Note Terminology
word feature used refer concrete, linguistic input word, suffix,
part-of-speech tag. example, first-order part-of-speech tagger, features might
current word, previous word, next word, previous part speech. term input
vector used refer actual input fed neural-network classifier.
Similarly, input vector entry refers specific value input. contrast
lot neural networks literature word feature overloaded
two uses, used primarily refer input-vector entry.
1.3 Mathematical Notation
use bold upper case letters represent matrices (X, Y, Z), bold lower-case letters
represent vectors (b). series related matrices vectors (for example,
matrix corresponds different layer network), superscript indices
used (W1 , W2 ). rare cases want indicate power matrix
vector, pair brackets added around item exponentiated: (W)2 , (W3 )2 .
Unless otherwise stated, vectors assumed row vectors. use [v1 ; v2 ] denote
vector concatenation.
choice use row vectors, right multiplied matrices (xW + b)
somewhat non standard lot neural networks literature use column vectors
left multiplied matrices (Wx + b). trust reader able adapt
column vectors notation reading literature.1

1. choice use row vectors notation inspired following benefits: matches way
input vectors network diagrams often drawn literature; makes hierarchical/layered
structure network transparent puts input left-most variable rather
nested; results fully-connected layer dimensions din dout rather dout din ; maps
better way networks implemented code using matrix libraries numpy.

346

fiA Primer Neural Networks NLP

2. Neural Network Architectures
Neural networks powerful learning models. discuss two kinds neural network
architectures, mixed matched feed-forward networks recurrent /
recursive networks. Feed-forward networks include networks fully connected layers,
multi-layer perceptron, well networks convolutional pooling
layers. networks act classifiers, different strengths.
Fully connected feed-forward neural networks (Section 4) non-linear learners
can, part, used drop-in replacement wherever linear learner used.
includes binary multiclass classification problems, well complex structured prediction problems (Section 8). non-linearity network, well
ability easily integrate pre-trained word embeddings, often lead superior classification accuracy. series works2 managed obtain improved syntactic parsing results
simply replacing linear model parser fully connected feed-forward network. Straight-forward applications feed-forward network classifier replacement
(usually coupled use pre-trained word vectors) provide benefits also CCG
supertagging,3 dialog state tracking,4 pre-ordering statistical machine translation5
language modeling.6 Iyyer, Manjunatha, Boyd-Graber, Daume III (2015) demonstrate
multi-layer feed-forward networks provide competitive results sentiment classification factoid question answering.
Networks convolutional pooling layers (Section 9) useful classification
tasks expect find strong local clues regarding class membership,
clues appear different places input. example, document classification
task, single key phrase (or ngram) help determining topic document
(Johnson & Zhang, 2015). would like learn certain sequences words good
indicators topic, necessarily care appear document.
Convolutional pooling layers allow model learn find local indicators,
regardless position. Convolutional pooling architecture show promising results
many tasks, including document classification,7 short-text categorization,8 sentiment
classification,9 relation type classification entities,10 event detection,11 paraphrase
identification,12 semantic role labeling,13 question answering,14 predicting box-office rev-

2. Chen Manning (2014), Weiss, Alberti, Collins, Petrov (2015) Pei, Ge, Chang (2015)
Durrett Klein (2015)
3. Lewis Steedman (2014)
4. Henderson, Thomson, Young (2013)
5. de Gispert, Iglesias, Byrne (2015)
6. Bengio, Ducharme, Vincent, Janvin (2003) Vaswani, Zhao, Fossum, Chiang (2013)
7. Johnson Zhang (2015)
8. Wang, Xu, Xu, Liu, Zhang, Wang, Hao (2015a)
9. Kalchbrenner, Grefenstette, Blunsom (2014) Kim (2014)
10. Zeng, Liu, Lai, Zhou, Zhao (2014), dos Santos, Xiang, Zhou (2015)
11. Chen, Xu, Liu, Zeng, Zhao (2015), Nguyen Grishman (2015)
12. Yin Schutze (2015)
13. Collobert, Weston, Bottou, Karlen, Kavukcuoglu, Kuksa (2011)
14. Dong, Wei, Zhou, Xu (2015)

347

fiGoldberg

enues movies based critic reviews,15 modeling text interestingness,16 modeling
relation character-sequences part-of-speech tags.17
natural language often work structured data arbitrary sizes,
sequences trees. would like able capture regularities structures,
model similarities structures. many cases, means encoding
structure fixed width vector, pass another statistical
learner processing. convolutional pooling architectures allow us
encode arbitrary large items fixed size vectors capturing salient features,
sacrificing structural information. Recurrent (Section 10)
recursive (Section 12) architectures, hand, allow us work sequences
trees preserving lot structural information. Recurrent networks (Elman,
1990) designed model sequences, recursive networks (Goller & Kuchler, 1996)
generalizations recurrent networks handle trees. also discuss
extension recurrent networks allow model stacks (Dyer, Ballesteros, Ling,
Matthews, & Smith, 2015; Watanabe & Sumita, 2015).
Recurrent models shown produce strong results language modeling,18 ; well sequence tagging,19 machine translation,20 dependency parsing,21
sentiment analysis,22 noisy text normalization,23 dialog state tracking,24 response generation,25 modeling relation character sequences part-of-speech tags.26
Recursive models shown produce state-of-the-art near state-of-the-art results
constituency27 dependency28 parse re-ranking, discourse parsing,29 semantic relation
classification,30 political ideology detection based parse trees,31 sentiment classification,32
target-dependent sentiment classification33 question answering.34
15.
16.
17.
18.

19.
20.

21.
22.
23.
24.
25.
26.
27.
28.
29.
30.
31.
32.
33.
34.

Bitvai Cohn (2015)
Gao, Pantel, Gamon, He, Deng (2014)
dos Santos Zadrozny (2014)
notable works Mikolov, Karafiat, Burget, Cernocky, Khudanpur (2010), Mikolov,
Kombrink, Lukas Burget, Cernocky, Khudanpur (2011), Mikolov (2012), Duh, Neubig, Sudoh,
Tsukada (2013), Adel, Vu, Schultz (2013), Auli, Galley, Quirk, Zweig (2013) Auli Gao
(2014)
Irsoy Cardie (2014), Xu, Auli, Clark (2015), Ling, Dyer, Black, Trancoso, Fermandez, Amir,
Marujo, Luis (2015b)
Sundermeyer, Alkhouli, Wuebker, Ney (2014), Tamura, Watanabe, Sumita (2014), Sutskever,
Vinyals, Le (2014) Cho, van Merrienboer, Gulcehre, Bahdanau, Bougares, Schwenk, Bengio
(2014b)
Dyer et al. (2015), Watanabe Sumita (2015)
Wang, Liu, Sun, Wang, Wang (2015b)
Chrupala (2014)
Mrksic, Seaghdha, Thomson, Gasic, Su, Vandyke, Wen, Young (2015)
Sordoni, Galley, Auli, Brockett, Ji, Mitchell, Nie, Gao, Dolan (2015)
Ling et al. (2015b)
Socher, Bauer, Manning, Ng (2013)
Le Zuidema (2014), Zhu, Qiu, Chen, Huang (2015a)
Li, Li, Hovy (2014)
Hashimoto, Miwa, Tsuruoka, Chikayama (2013), Liu, Wei, Li, Ji, Zhou, Wang (2015)
Iyyer, Enns, Boyd-Graber, Resnik (2014b)
Socher, Perelygin, Wu, Chuang, Manning, Ng, Potts (2013), Hermann Blunsom (2013)
Dong, Wei, Tan, Tang, Zhou, Xu (2014)
Iyyer, Boyd-Graber, Claudino, Socher, Daume III (2014a)

348

fiA Primer Neural Networks NLP

3. Feature Representation
discussing network structure depth, important pay attention
features represented. now, think feed-forward neural network
function NN(x) takes input din dimensional vector x produces dout
dimensional output vector. function often used classifier, assigning input x
degree membership one dout classes. function complex,
almost always non-linear. Common structures function discussed Section 4.
Here, focus input, x. dealing natural language, input x encodes
features words, part-of-speech tags linguistic information. Perhaps
biggest conceptual jump moving sparse-input linear models neural-network
based models stop representing feature unique dimension (the called
one-hot representation) representing instead dense vectors. is, core
feature embedded dimensional space, represented vector space.35
embeddings (the vector representation core feature) trained like
parameter function NN. Figure 1 shows two approaches feature
representation.
feature embeddings (the values vector entries feature) treated
model parameters need trained together components
network. Methods training (or obtaining) feature embeddings discussed later.
now, consider feature embeddings given.
general structure NLP classification system based feed-forward neural
network thus:
1. Extract set core linguistic features f1 , . . . , fk relevant predicting
output class.
2. feature fi interest, retrieve corresponding vector v(fi ).
3. Combine vectors (either concatenation, summation combination both)
input vector x.
4. Feed x non-linear classifier (feed-forward neural network).
biggest change input, then, move sparse representations
feature dimension, dense representation feature mapped
vector. Another difference extract core features feature combinations. elaborate changes briefly.
3.1 Dense Vectors vs. One-Hot Representations
benefits representing features vectors instead unique IDs?
always represent features dense vectors? Lets consider two kinds
representations:

35. Different feature types may embedded different spaces. example, one may represent word
features using 100 dimensions, part-of-speech features using 20 dimensions.

349

fiGoldberg

Figure 1: Sparse vs. dense feature representations. Two encodings information: current word dog; previous word the; previous pos-tag DET.
(a) Sparse feature vector. dimension represents feature. Feature combinations receive dimensions. Feature values binary. Dimensionality
high. (b) Dense, embeddings-based feature vector. core feature
represented vector. feature corresponds several input vector entries. explicit encoding feature combinations. Dimensionality low.
feature-to-vector mappings come embedding table.

350

fiA Primer Neural Networks NLP

One Hot feature dimension.
Dimensionality one-hot vector number distinct features.

Features completely independent one another. feature word
dog dis-similar word thinking word cat .
Dense feature d-dimensional vector.
Dimensionality vector d.

Model training cause similar features similar vectors information
shared similar features.
One benefit using dense low-dimensional vectors computational: majority
neural network toolkits play well high-dimensional, sparse vectors.
However, technical obstacle, resolved engineering
effort.
main benefit dense representations generalization power: believe
features may provide similar clues, worthwhile provide representation
able capture similarities. example, assume observed word dog
many times training, observed word cat handful times,
all. words associated dimension, occurrences dog
tell us anything occurrences cat. However, dense vectors representation
learned vector dog may similar learned vector cat, allowing
model share statistical strength two events. argument assumes
good vectors somehow given us. Section 5 describes ways obtaining vector
representations.
cases relatively distinct features category, believe
correlations different features, may use one-hot representation. However, believe going correlations different features
group (for example, part-of-speech tags, may believe different verb
inflections VB VBZ may behave similarly far task concerned) may
worthwhile let network figure correlations gain statistical strength
sharing parameters. may case circumstances,
feature space relatively small training data plentiful, wish
share statistical information distinct words, gains made using
one-hot representations. However, still open research question,
strong evidence either side. majority work (pioneered Collobert & Weston,
2008; Collobert et al. 2011; Chen & Manning, 2014) advocate use dense, trainable
embedding vectors features. work using neural network architecture sparse
vector encodings see work Johnson Zhang (2015).
Finally, important note representing features dense vectors integral
part neural network framework, consequentially differences
using sparse dense feature representations subtler may appear first.
fact, using sparse, one-hot vectors input training neural network amounts
dedicating first layer network learning dense embedding vector
feature based training data. touch Section 4.6.
351

fiGoldberg

3.2 Variable Number Features: Continuous Bag Words
Feed-forward networks assume fixed dimensional input. easily accommodate
case feature-extraction function extracts fixed number features: feature
represented vector, vectors concatenated. way, region
resulting input vector corresponds different feature. However, cases number
features known advance (for example, document classification common
word sentence feature). thus need represent unbounded
number features using fixed size vector. One way achieving socalled continuous bag words (CBOW) representation (Mikolov, Chen, Corrado, & Dean,
2013). CBOW similar traditional bag-of-words representation
discard order information, works either summing averaging embedding
vectors corresponding features:36
CBOW(f1 , ..., fk ) =

k
1X
v(fi )
k

(1)

i=1

simple variation CBOW representation weighted CBOW, different
vectors receive different weights:
1
WCBOW(f1 , ..., fk ) = Pk

i=1 ai

k
X

ai v(fi )

(2)

i=1

Here, feature fi associated weight ai , indicating relative importance
feature. example, document classification task, feature fi may correspond
word document, associated weight ai could words TF-IDF score.
3.3 Distance Position Features
linear distance two words sentence may serve informative feature.
example, event extraction task37 may given trigger word candidate
argument word, asked predict argument word indeed argument
trigger. distance (or relative position) trigger argument strong
signal prediction task. traditional NLP setup, distances usually encoded
binning distances several groups (i.e. 1, 2, 3, 4, 510, 10+) associating
bin one-hot vector. neural architecture, input vector composed
binary indicator features, may seem natural allocate single input entry
distance feature, numeric value entry distance. However,
approach taken practice. Instead, distance features encoded similarly
36. Note v(fi )s one-hot vectors rather dense feature representations, CBOW (eq
1) WCBOW (eq 2) would reduce traditional (weighted) bag-of-words representations,
turn equivalent sparse feature-vector representation binary indicator feature
corresponds unique word.
37. event extraction task involves identification events predefined set event types.
example identification purchase events terror-attack events. event type triggered
various triggering words (commonly verbs), several slots (arguments) needs filled
(i.e. purchased? purchased? amount?).

352

fiA Primer Neural Networks NLP

feature types: bin associated d-dimensional vector, distanceembedding vectors trained regular parameters network (Zeng et al., 2014;
dos Santos et al., 2015; Zhu et al., 2015a; Nguyen & Grishman, 2015).
3.4 Feature Combinations
Note feature extraction stage neural-network settings deals extraction core features. contrast traditional linear-model-based NLP systems
feature designer manually specify core features interest
also interactions (e.g., introducing feature stating word
X feature stating tag also combined feature stating word X tag
sometimes even word X, tag previous word Z). combination
features crucial linear models introduce dimensions input,
transforming space data-points closer linearly separable.
hand, space possible combinations large, feature designer
spend lot time coming effective set feature combinations. One
promises non-linear neural network models one needs define
core features. non-linearity classifier, defined network structure,
expected take care finding indicative feature combinations, alleviating need
feature combination engineering.
Kernel methods (Shawe-Taylor & Cristianini, 2004), particular polynomial kernels
(Kudo & Matsumoto, 2003), also allow feature designer specify core features,
leaving feature combination aspect learning algorithm. contrast neuralnetwork models, kernels methods convex, admitting exact solutions optimization
problem. However, computational complexity classification kernel methods scales
linearly size training data, making slow practical purposes,
suitable training large datasets. hand, computational
complexity classification using neural networks scales linearly size network,
regardless training data size.
3.5 Dimensionality
many dimensions allocate feature? Unfortunately, theoretical bounds even established best-practices space. Clearly, dimensionality
grow number members class (you probably want assign
dimensions word embeddings part-of-speech embeddings) much
enough? current research, dimensionality word-embedding vectors range
50 hundreds, and, extreme cases, thousands. Since dimensionality vectors direct effect memory requirements processing time, good
rule thumb would experiment different sizes, choose good trade-off
speed task accuracy.
3.6 Vector Sharing
Consider case features share vocabulary. example,
assigning part-of-speech given word, may set features considering
353

fiGoldberg

previous word, set features considering next word. building input
classifier, concatenate vector representation previous word
vector representation next word. classifier able distinguish two
different indicators, treat differently. two features share
vectors? vector dog:previous-word vector dog:nextword? assign two distinct vectors? This, again, mostly empirical
question. believe words behave differently appear different positions
(e.g., word X behaves like word previous position, X behaves like Z
next position) may good idea use two different vocabularies assign
different set vectors feature type. However, believe words behave
similarly locations, something may gained using shared vocabulary
feature types.
3.7 Networks Output
multi-class classification problems k classes, networks output k-dimensional
vector every dimension represents strength particular output class.
is, output remains traditional linear models scalar scores items discrete
set. However, see Section 4, k matrix associated output
layer. columns matrix thought dimensional embeddings
output classes. vector similarities vector representations k classes
indicate models learned similarities output classes.
3.8 Historical Note
Representing words dense vectors input neural network popularized Bengio
et al. (2003) context neural language modeling. introduced NLP tasks
pioneering work Collobert, Weston colleagues (2008, 2011).38 Using embeddings
representing words arbitrary features popularized following Chen
Manning (2014).

4. Feed-Forward Neural Networks
section introduces feed-forward neural networks. starts popular brain
inspired metaphor triggered them, quickly switches back using mathematical
notation. discuss structure feed forward neural networks, representation
power, common non-linearities loss functions.
4.1 Brain-Inspired Metaphor
name suggests, neural-networks inspired brains computation mechanism,
consists computation units called neurons. metaphor, neuron computational unit scalar inputs outputs. input associated weight.
38. work Bengio, Collobert, Weston colleagues popularized approaches,
first use them. Earlier authors use dense continuous-space vectors representing word inputs
neural networks include Lee et al. (1992) Forcada Neco (1997). Similarly, continuous-space
language models used machine-translation already Schwenk et al. (2006).

354

fiA Primer Neural Networks NLP

neuron multiplies input weight, sums39 them, applies non-linear
function result, passes output. neurons connected other,
forming network: output neuron may feed inputs one neurons.
networks shown capable computational devices. weights set
correctly, neural network enough neurons non-linear activation function
approximate wide range mathematical functions (we precise
later).
Output
layer

Hidden
layer

Hidden
layer

Input layer

R

R

y1

y2

y3

R

R

R

R

R

R

R

R

x1

x2

x3

x4

R

Figure 2: Feed-forward neural network two hidden layers.
typical feed-forward neural network may drawn Figure 2. circle
neuron, incoming arrows neurons inputs outgoing arrows neurons outputs. arrow carries weight, reflecting importance (not shown). Neurons
arranged layers, reflecting flow information. bottom layer incoming
arrows, input network. top-most layer outgoing arrows,
output network. layers considered hidden. sigmoid shape
inside neurons middle layers represent non-linear function (i.e., logistic
function 1/(1 + exa )) applied neurons value passing output.
figure, neuron connected neurons next layer called
fully-connected layer affine layer.
brain metaphor sexy intriguing, also distracting cumbersome
manipulate mathematically. therefore switch using concise mathematical
notation. values row neurons network thought vector.
Figure 2 input layer 4 dimensional vector (x), layer 6 dimensional vector (h1 ). fully connected layer thought linear transformation
39. summing common operation, functions, max, also possible

355

fiGoldberg

4 dimensions 6 dimensions. fully-connected layer implements vector-matrix
multiplication, h = xW weight connection ith neuron
input row jth neuron output row Wij .40 values h transformed non-linear function g applied value passed
next input. whole computation input output written as: (g(xW1 ))W2
W1 weights first layer W2 weights second one.
4.2 Mathematical Notation
point on, abandon brain metaphor describe networks exclusively
terms vector-matrix operations.
simplest neural network perceptron, linear function inputs:
NNPerceptron (x) = xW + b

(3)

x Rdin , W Rdin dout , b Rdout
W weight matrix, b bias term.41 order go beyond linear functions,
introduce non-linear hidden layer (the network Figure 2 two layers), resulting
Multi Layer Perceptron one hidden-layer (MLP1). feed-forward neural network
one hidden-layer form:
NNMLP1 (x) = g(xW1 + b1 )W2 + b2

(4)

x Rdin , W1 Rdin d1 , b1 Rd1 , W2 Rd1 d2 , b2 Rd2
W1 b1 matrix bias term first linear transformation
input, g non-linear function applied element-wise (also called non-linearity
activation function), W2 b2 matrix bias term second linear
transform.
Breaking down, xW1 +b1 linear transformation input x din dimensions
d1 dimensions. g applied d1 dimensions, matrix W2 together
bias vector b2 used transform result d2 dimensional output
vector. non-linear activation function g crucial role networks ability
represent complex functions. Without non-linearity g, neural network
represent linear transformations input.42
add additional linear-transformations non-linearities, resulting MLP
two hidden-layers (the network Figure 2 form):
NNMLP2 (x) = (g 2 (g 1 (xW1 + b1 )W2 + b2 ))W3

(5)

perhaps clearer write deeper networks like using intermediary variables:
40. see P
case, denote weight ith input jth neuron h wij . value
hj hj = 4i=1 xi wij .
41. network figure 2 include bias terms. bias term added layer adding
additional neuron incoming connections, whose value always 1.
42. see why, consider sequence linear transformations still linear transformation.

356

fiA Primer Neural Networks NLP

NNMLP2 (x) =y
h1 =g 1 (xW1 + b1 )
h2 =g 2 (h1 W2 + b2 )

(6)

=h2 W3
vector resulting linear transform referred layer. outer-most
linear transform results output layer linear transforms result hidden
layers. hidden layer followed non-linear activation. cases,
last layer example, bias vectors forced 0 (dropped).
Layers resulting linear transformations often referred fully connected,
affine. types architectures exist. particular, image recognition problems benefit
convolutional pooling layers. layers uses also language processing,
discussed Section 9. Networks several hidden layers said deep
networks, hence name deep learning.
describing neural network, one specify dimensions layers
input. layer expect din dimensional vector input, transform
dout dimensional vector. dimensionality layer taken dimensionality
output. fully connected layer l(x) = xW + b input dimensionality din
output dimensionality dout , dimensions x 1 din , W din dout b
1 dout .
output network dout dimensional vector. case dout = 1, networks
output scalar. networks used regression (or scoring) considering
value output, binary classification consulting sign output.
Networks dout = k > 1 used k-class classification, associating
dimension class, looking dimension maximal value. Similarly,
output vector entries positive sum one, output interpreted
distribution class assignments (such output normalization typically achieved
applying softmax transformation output layer, see Section 4.5).
matrices bias terms define linear transformations parameters network. common refer collection parameters . Together
input, parameters determine networks output. training algorithm
responsible setting values networks predictions correct. Training
discussed Section 6.
4.3 Representation Power
terms representation power, shown Hornik, Stinchcombe, White (1989)
Cybenko (1989) MLP1 universal approximator approximate
desired non-zero amount error family functions43 include continuous
functions closed bounded subset Rn , function mapping finite
43. Specifically, feed-forward network linear output layer least one hidden layer squashing activation function approximate Borel measurable function one finite dimensional space
another.

357

fiGoldberg

dimensional discrete space another. may suggest reason go beyond
MLP1 complex architectures. However, theoretical result discuss
learnability neural network (it states representation exists, say
easy hard set parameters based training data specific learning
algorithm). also guarantee training algorithm find correct function
generating training data. Finally, state large hidden layer
be. Indeed, Telgarsky (2016) show exist neural networks many layers
bounded size cannot approximated networks fewer layers unless layers
exponentially large.
practice, train neural networks relatively small amounts data using local
search methods variants stochastic gradient descent, use hidden layers
relatively modest sizes (up several thousands). universal approximation theorem
give guarantees non-ideal, real-world conditions, definitely
benefit trying complex architectures MLP1. many cases,
however, MLP1 indeed provide strong results. discussion representation power feed-forward neural networks, see book Bengio et al. (2015, Section
6.5).

4.4 Common Non-linearities
non-linearity g take many forms. currently good theory
non-linearity apply conditions, choosing correct non-linearity
given task part empirical question. go common nonlinearities literature: sigmoid, tanh, hard tanh rectified linear unit
(ReLU). NLP researchers also experimented forms non-linearities
cube tanh-cube.

4.4.1 Sigmoid
sigmoid activation function (x) = 1/(1 + ex ), also called logistic function,
S-shaped function, transforming value x range [0, 1]. sigmoid
canonical non-linearity neural networks since inception, currently considered
deprecated use internal layers neural networks, choices listed
prove work much better empirically.

4.4.2 Hyperbolic Tangent (tanh)
2x

hyperbolic tangent tanh(x) = ee2x 1
activation function S-shaped function, trans+1
forming values x range [1, 1].
358

fiA Primer Neural Networks NLP

4.4.3 Hard tanh
hard-tanh activation function approximation tanh function faster
compute take derivatives of:


1 x < 1
hardtanh(x) = 1
(7)
x>1


x
otherwise
4.4.4 Rectifier (ReLU)
Rectifier activation function (Glorot, Bordes, & Bengio, 2011), also known
rectified linear unit simple activation function easy work
shown many times produce excellent results.44 ReLU unit clips value x < 0
0. Despite simplicity, performs well many tasks, especially combined
dropout regularization technique (see Section 6.4).
(
0
ReLU(x) = max(0, x) =
x

x<0
otherwise

(8)

rule thumb, ReLU units work better tanh, tanh works better
sigmoid.45
4.5 Output Transformations
many cases, output layer vector also transformed. common transformation
softmax :
x =x1 , . . . , xk
e xi
softmax(xi ) = Pk
xj
j=1 e

(9)

44. technical advantages ReLU sigmoid tanh activation functions
involve expensive-to-compute functions, importantly saturate. sigmoid
tanh activation capped 1, gradients region functions near zero,
driving entire gradient near zero. ReLU activation problem, making
especially suitable networks multiple layers, susceptible vanishing gradients
problem trained saturating units.
45. addition activation functions, recent works NLP community experiment
reported success forms non-linearities. Cube activation function, g(x) = (x)3 ,
suggested Chen Manning (2014), found effective non-linearities
feed-forward network used predict actions greedy transition-based dependency
parser. tanh cube activation function g(x) = tanh((x)3 + x) proposed Pei et al. (2015),
found effective non-linearities feed-forward network used
component structured-prediction graph-based dependency parser.
cube tanh-cube activation functions motivated desire better capture interactions different features. activation functions reported improve performance
certain situations, general applicability still determined.

359

fiGoldberg

result vector non-negative real numbers sum one, making discrete
probability distribution k possible outcomes.
softmax output transformation used interested modeling probability distribution possible output classes. effective, used
conjunction probabilistic training objective cross-entropy (see Section 4.7.4
below).
softmax transformation applied output network without hidden
layer, result well known multinomial logistic regression model, also known
maximum-entropy classifier.
4.6 Embedding Layers
now, discussion ignored source x, treating arbitrary vector.
NLP application, x usually composed various embeddings vectors.
explicit source x, include networks definition. introduce c(),
function core features input vector.
common c extract embedding vector associated feature,
concatenate them:
x = c(f1 , f2 , f3 ) =[v(f1 ); v(f2 ); v(f3 )]
NNMLP1 (x) =NNMLP1 (c(f1 , f2 , f3 ))
=NNMLP1 ([v(f1 ); v(f2 ); v(f3 )])

(10)

=(g([v(f1 ); v(f2 ); v(f3 )]W1 + b1 ))W2 + b2
Another common choice c sum embedding vectors (this assumes embedding vectors share dimensionality):
x = c(f1 , f2 , f3 ) =v(f1 ) + v(f2 ) + v(f3 )
NNMLP1 (x) =NNMLP1 (c(f1 , f2 , f3 ))
=NNMLP1 (v(f1 ) + v(f2 ) + v(f3 ))

(11)

=(g((v(f1 ) + v(f2 ) + v(f3 ))W1 + b1 ))W2 + b2
form c essential part networks design. many papers, common
refer c part network, likewise treat word embeddings v(fi ) resulting
embedding layer lookup layer. Consider vocabulary |V | words,
embedded dimensional vector. collection vectors thought
|V | embedding matrix E row corresponds embedded feature. Let
fi |V |-dimensional vector, zeros except one index, corresponding
value ith feature, value 1 (this called one-hot vector).
multiplication fi E select corresponding row E. Thus, v(fi ) defined
terms E fi :
v(fi ) = fi E
360

(12)

fiA Primer Neural Networks NLP

similarly:
CBOW(f1 , ..., fk ) =

k
X

(fi E) = (

i=1

k
X

fi )E

(13)

i=1

input network considered collection one-hot vectors.
elegant well defined mathematically, efficient implementation typically involves
hash-based data structure mapping features corresponding embedding vectors,
without going one-hot representation.
tutorial, take c separate network architecture: networks
inputs always dense real-valued input vectors, c applied input passed
network, similar feature function familiar linear-models terminology. However, training network, input vector x remember constructed,
propagate error gradients back component embedding vectors, appropriate
(error propagation discussed section 6).
4.6.1 Note Notation
describing network layers get concatenated vectors x, z input,
authors use explicit concatenation ([x; y; z]W +b) others use affine transformation
(xU + yV + zW + b). weight matrices U, V, W affine transformation
different one another, two notations equivalent.
4.6.2 Note Sparse vs. Dense Features
Consider network uses traditional sparse representation input vectors,
embedding layer. Assuming set available features V k
features f1 , . . . , fk , fi V , networks input is:
x=

k
X

|V |

x N+

fi

i=1

(14)

first layer (ignoring non-linear activation) is:
k
X
xW + b = (
fi )W

(15)

i=1

W R|V |d , b Rd
layer selects rows W corresponding input features x sums them,
adding bias term. similar embedding layer produces CBOW
representation features, matrix W acts embedding matrix.
main difference introduction bias vector b, fact embedding
layer typically undergo non-linear activation rather passed directly
first layer. Another difference scenario forces feature receive separate
vector (row W) embedding layer provides flexibility, allowing example
features next word dog previous word dog share vector.
361

fiGoldberg

However, differences small subtle. comes multi-layer feed-forward
networks, difference dense sparse inputs smaller may seem
first sight.
4.7 Loss Functions
training neural network (more training Section 6 below), much like
training linear classifier, one defines loss function L(y, y), stating loss predicting
true output y. training objective minimize loss across
different training examples. loss L(y, y) assigns numerical score (a scalar)
networks output given true expected output y.46 loss function
bounded below, minimum attained cases networks output
correct.
parameters network (the matrices Wi , biases bi commonly embeddings E) set order minimize loss L training examples (usually,
sum losses different training examples minimized).
loss arbitrary function mapping two vectors scalar. practical
purposes optimization, restrict functions easily compute
gradients (or sub-gradients). cases, sufficient advisable rely common
loss function rather defining own. detailed discussion loss functions
neural networks see work LeCun, Chopra, Hadsell, Ranzato, Huang (2006), LeCun
Huang (2005) Bengio et al. (2015). discuss loss functions
commonly used neural networks NLP.
4.7.1 Hinge (binary)
binary classification problems, networks output single scalar intended
output {+1, 1}. classification rule sign(y), classification considered
correct > 0, meaning share sign. hinge loss, also known
margin loss SVM loss, defined as:
Lhinge(binary) (y, y) = max(0, 1 y)

(16)

loss 0 share sign |y| 1. Otherwise, loss linear.
words, binary hinge loss attempts achieve correct classification,
margin least 1.
4.7.2 Hinge (multiclass)
hinge loss extended multiclass setting Crammer Singer (2002). Let
= y1 , . . . , yn networks output vector, one-hot vector correct
output class.
classification rule defined selecting class highest score:
prediction = arg max yi


(17)

46. notation, models output expected output vectors, many cases
natural think expected output scalar (class assignment). cases, simply
corresponding one-hot vector.

362

fiA Primer Neural Networks NLP

Denote = arg maxi yi correct class, k = arg maxi6=t yi highest scoring
class k 6= t. multiclass hinge loss defined as:
Lhinge(multiclass) (y, y) = max(0, 1 (yt yk ))

(18)

multiclass hinge loss attempts score correct class classes
margin least 1.
binary multiclass hinge losses intended used linear output
layer. hinge losses useful whenever require hard decision rule,
attempt model class membership probability.
4.7.3 Log Loss
log loss common variation hinge loss, seen soft version
hinge loss infinite margin (LeCun et al., 2006).
Llog (y, y) = log(1 + exp((yt yk ))

(19)

4.7.4 Categorical Cross-Entropy Loss
categorical cross-entropy loss (also referred negative log likelihood ) used
probabilistic interpretation scores desired.
Let = y1 , . . . , yn vector representing true multinomial distribution
labels 1, . . . , n, let = y1 , . . . , yn networks output, transformed
softmax activation function, represent class membership conditional distribution
yi = P (y = i|x). categorical cross entropy loss measures dissimilarity
true label distribution predicted label distribution y, defined cross
entropy:
Lcross-entropy (y, y) =

X

yi log(yi )

(20)



hard classification problems training example single correct
class assignment, one-hot vector representing true class. cases, cross
entropy simplified to:
Lcross-entropy(hard classification) (y, y) = log(yt )

(21)

correct class assignment. attempts set probability mass assigned
correct class 1. scores transformed using softmax
function represent conditional distribution, increasing mass assigned correct
class means decreasing mass assigned classes.
cross-entropy loss common neural networks literature, produces
multi-class classifier predict one-best class label also predicts
distribution possible labels. using cross-entropy loss, assumed
networks output transformed using softmax transformation.
363

fiGoldberg

4.7.5 Ranking Losses
settings, given supervision term labels, rather pairs
correct incorrect items x x0 , goal score correct items incorrect
ones. training situations arise positive examples, generate
negative examples corrupting positive example. useful loss scenarios
margin-based ranking loss, defined pair correct incorrect examples:
Lranking(margin) (x, x0 ) = max(0, 1 (NN(x) NN(x0 )))

(22)

NN(x) score assigned network input vector x. objective
score (rank) correct inputs incorrect ones margin least 1.
common variation use log version ranking loss:
Lranking(log) (x, x0 ) = log(1 + exp((NN(x) NN(x0 ))))

(23)

Examples using ranking hinge loss language tasks include training auxiliary tasks used deriving pre-trained word embeddings (see section 5),
given correct word sequence corrupted word sequence, goal score
correct sequence corrupt one (Collobert & Weston, 2008). Similarly, Van
de Cruys (2014) used ranking loss selectional-preferences task, network trained rank correct verb-object pairs incorrect, automatically derived
ones, Weston, Bordes, Yakhnenko, Usunier (2013) trained model score correct
(head,relation,trail) triplets corrupted ones information-extraction setting.
example using ranking log loss found work Gao et al. (2014).
variation ranking log loss allowing different margin negative positive
class given work dos Santos et al. (2015).

5. Word Embeddings
main component neural-network approach use embeddings representing
feature vector low dimensional space. vectors come from?
section survey common approaches.
5.1 Random Initialization
enough supervised training data available, one treat feature embeddings
model parameters: initialize embedding vectors random values,
let network-training procedure tune good vectors.
care taken way random initialization performed. method
used effective word2vec implementation (Mikolov et al., 2013; Mikolov, Sutskever,
Chen, Corrado, & Dean, 2013) initialize word vectors uniformly sampled random
1 1
numbers range [ 2d
, 2d ] number dimensions. Another option
use xavier
(see Section 6.3.1) initialize uniformly sampled values
h initialization

6 6

, .
364

fiA Primer Neural Networks NLP

practice, one often use random initialization approach initialize embedding vectors commonly occurring features, part-of-speech tags individual
letters, using form supervised unsupervised pre-training initialize
potentially rare features, features individual words. pre-trained vectors
either treated fixed network training process, or, commonly,
treated like randomly-initialized vectors tuned task hand.
5.2 Supervised Task-Specific Pre-training
interested task A, limited amount labeled data (for
example, syntactic parsing), auxiliary task B (say, part-of-speech tagging)
much labeled data, may want pre-train word vectors
perform well predictors task B, use trained vectors training
task A. way, utilize larger amounts labeled data task B.
training task either treat pre-trained vectors fixed, tune
task A. Another option train jointly objectives, see Section 7
details.
5.3 Unsupervised Pre-training
common case auxiliary task large enough amounts
annotated data (or maybe want help bootstrap auxiliary task training better
vectors). cases, resort unsupervised methods, trained huge
amounts unannotated text.
techniques training word vectors essentially supervised learning,
instead supervision task care about, instead create practically
unlimited number supervised training instances raw text, hoping tasks
created match (or close enough to) final task care about.47
key idea behind unsupervised approaches one would like embedding
vectors similar words similar vectors. word similarity hard define
usually task-dependent, current approaches derive distributional
hypothesis (Harris, 1954), stating words similar appear similar contexts.
different methods create supervised training instances goal either
predict word context, predict context word.
important benefit training word embeddings large amounts unannotated
data provides vector representations words appear supervised training set. Ideally, representations words similar
related words appear training set, allowing model generalize better
unseen events. thus desired similarity word vectors learned unsupervised algorithm captures aspects similarity useful performing
intended task network.
47. interpretation creating auxiliary problems raw text inspired Ando Zhang (2005a)
Ando Zhang (2005b).

365

fiGoldberg

Common unsupervised word-embedding algorithms include word2vec 48 (Mikolov et al.,
2013, 2013), GloVe (Pennington, Socher, & Manning, 2014) Collobert Weston
(2008, 2011) embeddings algorithm. models inspired neural networks
based stochastic gradient training. However, deeply connected another
family algorithms evolved NLP IR communities, based
matrix factorization (for discussion see Levy & Goldberg, 2014b; Levy et al., 2015).
Arguably, choice auxiliary problem (what predicted, based kind
context) affects resulting vectors much learning method
used train them. thus focus different choices auxiliary problems
available, skim details training methods. Several software packages
deriving word vectors available, including word2vec49 Gensim50 implementing
word2vec models word-windows based contexts, word2vecf51 modified
version word2vec allowing use arbitrary contexts, GloVe52 implementing
GloVe model. Many pre-trained word vectors also available download web.
beyond scope tutorial, worth noting word embeddings
derived unsupervised training algorithms wide range applications NLP
beyond using initializing word-embeddings layer neural-network model.
5.4 Training Objectives
Given word w context c, different algorithms formulate different auxiliary tasks.
cases, word represented d-dimensional vector initialized
random value. Training model perform auxiliary tasks well result good
word embeddings relating words contexts, turn result
embedding vectors similar words similar other.
Language-modeling inspired approaches taken Mikolov et al. (2013),
Mnih Kavukcuoglu (2013) well GloVe (Pennington et al., 2014) use auxiliary tasks
goal predict word given context. posed probabilistic
setup, trying model conditional probability P (w|c).
approaches reduce problem binary classification. addition
set observed word-context pairs, set created random words
context pairings. binary classification problem then: given (w, c) pair
come not? approaches differ set constructed,
structure classifier, objective optimized. Collobert
Weston (2008, 2011) take margin-based binary ranking approach, training feed-forward
neural network score correct (w, c) pairs incorrect ones. Mikolov et al. (2013, 2014)
take instead probabilistic version, training log-bilinear model predict probability
P ((w, c) D|w, c) pair come corpus rather random sample.
48. often treated single algorithm, word2vec actually software package including various
training objectives, optimization methods hyperparameters. See work Rong (2014)
Levy, Goldberg, Dagan (2015) discussion.
49. https://code.google.com/p/word2vec/
50. https://radimrehurek.com/gensim/
51. https://bitbucket.org/yoavgo/word2vecf
52. http://nlp.stanford.edu/projects/glove/

366

fiA Primer Neural Networks NLP

5.5 Choice Contexts
cases, contexts word taken words appear
surrounding, either short window around it, within sentence, paragraph
document. cases text automatically parsed syntactic parser,
contexts derived syntactic neighbourhood induced automatic parse
trees. Sometimes, definitions words context change include also parts words,
prefixes suffixes.
Neural word embeddings originated world language modeling,
network trained predict next word based sequence preceding words (Bengio
et al., 2003). There, text used create auxiliary tasks aim predict
word based context k previous words. training language modeling
auxiliary prediction problems indeed produce useful embeddings, approach needlessly
restricted constraints language modeling task, one allowed look
previous words. care language modeling
resulting embeddings, may better ignoring constraint taking context
symmetric window around focus word.
5.5.1 Window Approach
common approach sliding window approach, auxiliary tasks
created looking sequence 2k + 1 words. middle word callled focus word
k words side contexts. Then, either single task created
goal predict focus word based context words (represented either
using CBOW, see Mikolov et al., 2013 vector concatenation, see Collobert & Weston,
2008), 2k distinct tasks created, pairing focus word different context
word. 2k tasks approach, popularized Mikolov et al. (2013) referred
skip-gram model. Skip-gram based approaches shown robust efficient train
(Mikolov et al., 2013; Pennington et al., 2014), often produce state art results.
Effect Window Size size sliding window strong effect resulting vector similarities. Larger windows tend produce topical similarities (i.e.
dog, bark leash grouped together, well walked, run walking), smaller windows tend produce functional syntactic similarities (i.e.
Poodle, Pitbull, Rottweiler, walking,running,approaching).
Positional Windows using CBOW skip-gram context representations,
different context words within window treated equally. distinction
context words close focus words farther
it, likewise distinction context words appear focus
words context words appear it. information easily factored
using positional contexts: indicating context word also relative position
focus words (i.e. instead context word becomes the:+2, indicating
word appears two positions right focus word). use positional context
together smaller windows tend produce similarities syntactic,
strong tendency grouping together words share part speech, well
functionally similar terms semantics. Positional vectors shown Ling,
367

fiGoldberg

Dyer, Black, Trancoso (2015a) effective window-based vectors
used initialize networks part-of-speech tagging syntactic dependency parsing.
Variants Many variants window approach possible. One may lemmatize words
learning, apply text normalization, filter short long sentences, remove
capitalization (see, e.g., pre-processing steps described dos Santos & Gatti, 2014).
One may sub-sample part corpus, skipping probability creation tasks
windows common rare focus words. window size may
dynamic, using different window size turn. One may weigh different positions
window differently, focusing trying predict correctly close word-context
pairs away ones. choices effect resulting vectors.
hyperparameters (and others) discussed Levy et al. (2015).
5.5.2 Sentences, Paragraphs Documents
Using skip-grams (or CBOW) approach, one consider contexts word
words appear sentence, paragraph document.
equivalent using large window sizes, expected result word vectors
capture topical similarity (words topic, i.e. words one would expect
appear document, likely receive similar vectors).
5.5.3 Syntactic Window
work replace linear context within sentence syntactic one (Levy &
Goldberg, 2014a; Bansal, Gimpel, & Livescu, 2014). text automatically parsed
using dependency parser, context word taken words
proximity parse tree, together syntactic relation
connected. approaches produce highly functional similarities, grouping together words
fill role sentence (e.g. colors, names schools, verbs movement).
grouping also syntactic, grouping together words share inflection (Levy &
Goldberg, 2014a).
5.5.4 Multilingual
Another option using multilingual, translation based contexts (Hermann & Blunsom,
2014; Faruqui & Dyer, 2014). example, given large amount sentence-aligned parallel
text, one run bilingual alignment model IBM model 1 model 2 (i.e.
using GIZA++ software), use produced alignments derive word contexts.
Here, context word instance foreign language words aligned it.
alignments tend result synonym words receiving similar vectors. authors
work instead sentence alignment level, without relying word alignments (Gouws,
Bengio, & Corrado, 2015) train end-to-end machine-translation neural network
use resulting word embeddings (Hill, Cho, Jean, Devin, & Bengio, 2014). appealing
method mix monolingual window-based approach multilingual approach,
creating kinds auxiliary tasks. likely produce vectors similar
window-based approach, reducing somewhat undesired effect window368

fiA Primer Neural Networks NLP

based approach antonyms (e.g. hot cold, high low) tend receive similar
vectors (Faruqui & Dyer, 2014).
5.5.5 Character-Based Sub-word Representations
interesting line work attempts derive vector representation word
characters compose it. approaches likely particularly useful tasks
syntactic nature, character patterns within words strongly related
syntactic function. approaches also benefit producing small
model sizes (only one vector character alphabet together handful
small matrices needs stored), able provide embedding vector every
word may encountered. Dos Santos Gatti (2014), dos Santos Zadrozny
(2014) Kim et al. (2015) model embedding word using convolutional network
(see Section 9) characters. Ling et al. (2015b) model embedding word
using concatenation final states two RNN (LSTM) encoders (Section 10), one
reading characters left right, right left. produce
strong results part-of-speech tagging. work Ballesteros et al. (2015) show
two-LSTMs encoding Ling et al. (2015b) beneficial also representing words
dependency parsing morphologically rich languages.
Deriving representations words representations characters motivated unknown words problem encounter word
embedding vector? Working level characters alleviates
problem large extent, vocabulary possible characters much smaller
vocabulary possible words. However, working character level
challenging, relationship form (characters) function (syntax, semantics)
language quite loose. Restricting oneself stay character level may
unnecessarily hard constraint. researchers propose middle-ground, word
represented combination vector word vectors sub-word
units comprise it. sub-word embeddings help sharing information
different words similar forms, well allowing back-off subword level
word observed. time, models forced rely solely
form enough observations word available. Botha Blunsom (2014) suggest model embedding vector word sum word-specific vector
vector available, vectors different morphological components comprise
(the components derived using Morfessor (Creutz & Lagus, 2007), unsupervised
morphological segmentation method). Gao et al. (2014) suggest using core features
word form also unique feature (hence unique embedding vector)
letter-trigrams word.

6. Neural Network Training
Neural network training done trying minimize loss function training set,
using gradient-based method. Roughly speaking, training methods work repeatedly
computing estimate error dataset, computing gradient respect
error, moving parameters opposite direction gradient.
Models differ error estimate computed, moving opposite
369

fiGoldberg

direction gradient defined. describe basic algorithm, stochastic gradient
descent (SGD), briefly mention approaches pointers
reading. Gradient calculation central approach. Gradients efficiently
automatically computed using reverse mode differentiation computation graph
general algorithmic framework automatically computing gradient network
loss function, discussed Section 6.2.
6.1 Stochastic Gradient Training
common approach training neural networks using stochastic gradient descent
(SGD) algorithm (Bottou, 2012; LeCun, Bottou, Orr, & Muller, 1998a) variant it.
SGD general optimization algorithm. receives function f parameterized ,
loss function, desired input output pairs. attempts set parameters
loss f respect training examples small. algorithm works
follows:
Algorithm 1 Online Stochastic Gradient Descent Training
1: Input: Function f (x; ) parameterized parameters .
2: Input: Training set inputs x1 , . . . , xn desired outputs y1 , . . . , yn .
3: Input: Loss function L.
4: stopping criteria met
5:
Sample training example xi , yi
6:
Compute loss L(f (xi ; ), yi )
7:
g gradients L(f (xi ; ), yi ) w.r.t
8:
g
9: return
PnThe goal algorithm set parameters minimize total loss
i=1 L(f (xi ; ), yi ) training set. works repeatedly sampling training example computing gradient error example respect parameters
(line 7) input expected output assumed fixed, loss treated
function parameters . parameters updated opposite
direction gradient, scaled learning rate (line 8). learning rate either
fixed throughout training process, decay function time step t.53
discussion setting learning rate, see Section 6.3.
Note error calculated line 6 based single training example, thus
rough estimate corpus-wide loss aiming minimize. noise
loss computation may result inaccurate gradients. common way reducing
noise estimate error gradients based sample examples.
gives rise minibatch SGD algorithm:
lines 6 9 algorithm estimates gradient corpus loss based
minibatch. loop, g contains gradient estimate, parameters
updated toward g. minibatch size vary size = 1 = n. Higher
values provide better estimates corpus-wide gradients, smaller values allow
53. Learning rate decay required order prove convergence SGD.

370

fiA Primer Neural Networks NLP

Algorithm 2 Minibatch Stochastic Gradient Descent Training
1: Input: Function f (x; ) parameterized parameters .
2: Input: Training set inputs x1 , . . . , xn desired outputs y1 , . . . , yn .
3: Input: Loss function L.
4: stopping criteria met
5:
Sample minibatch examples {(x1 , y1 ), . . . , (xm , ym )}
6:
g 0
7:
= 1
8:
Compute loss L(f (xi ; ), yi )
1
9:
g g + gradients
L(f (xi ; ), yi ) w.r.t
g
11: return
10:

updates turn faster convergence. Besides improved accuracy gradients
estimation, minibatch algorithm provides opportunities improved training efficiency.
modest sizes m, computing architectures (i.e. GPUs) allow efficient parallel
implementation computation lines 69. properly decreasing learning rate,
SGD guaranteed converge global optimum function convex. However,
also used optimize non-convex functions neural-network.
longer guarantees finding global optimum, algorithm proved robust
performs well practice.54
training neural network, parameterized function f neural network,
parameters linear-transformation matrices, bias terms, embedding matrices
on. gradient computation key step SGD algorithm, well
neural network training algorithms. question is, then, compute
gradients networks error respect parameters. Fortunately,
easy solution form backpropagation algorithm (Rumelhart, Hinton, & Williams,
1986; LeCun, Bottou, Bengio, & Haffner, 1998b). backpropagation algorithm fancy
name methodically computing derivatives complex expression using chainrule, caching intermediary results. generally, backpropagation algorithm
special case reverse-mode automatic differentiation algorithm (Neidinger, 2010,
Section 7; Baydin, Pearlmutter, Radul, & Siskind, 2015; Bengio, 2012). following
section describes reverse mode automatic differentiation context computation
graph abstraction.
6.1.1 Beyond SGD
SGD algorithm often produce good results, advanced algorithms also available. SGD+Momentum (Polyak, 1964) Nesterov Momentum
(Sutskever, Martens, Dahl, & Hinton, 2013; Nesterov, 1983, 2004) algorithms variants
SGD previous gradients accumulated affect current update. Adap54. Recent work neural-networks literature argue non-convexity networks manifested proliferation saddle points rather local minima (Dauphin, Pascanu, Gulcehre, Cho,
Ganguli, & Bengio, 2014). may explain success training neural networks despite
using local search techniques.

371

fiGoldberg

tive learning rate algorithms including AdaGrad (Duchi, Hazan, & Singer, 2011), AdaDelta
(Zeiler, 2012), RMSProp (Tieleman & Hinton, 2012) Adam (Kingma & Ba, 2014)
designed select learning rate minibatch, sometimes per-coordinate basis,
potentially alleviating need fiddling learning rate scheduling. details
algorithms, see original papers book Bengio et al. (2015, Sections 8.3, 8.4).
many neural-network software frameworks provide implementations algorithms,
easy sometimes worthwhile try different variants.
6.2 Computation Graph Abstraction
one compute gradients various parameters network hand
implement code, procedure cumbersome error prone. purposes, preferable use automatic tools gradient computation (Bengio, 2012).
computation-graph abstraction allows us easily construct arbitrary networks, evaluate
predictions given inputs (forward pass), compute gradients parameters
respect arbitrary scalar losses (backward pass).
computation graph representation arbitrary mathematical computation
graph. directed acyclic graph (DAG) nodes correspond mathematical
operations (bound) variables edges correspond flow intermediary values
nodes. graph structure defines order computation terms
dependencies different components. graph DAG tree,
result one operation input several continuations. Consider example
graph computation (a b + 1) (a b + 2):
*
+

+
*

1



b

2

computation b shared. restrict case computation
graph connected.
Since neural network essentially mathematical expression, represented
computation graph.
example, Figure 3a presents computation graph MLP one hiddenlayer softmax output transformation. notation, oval nodes represent mathematical operations functions, shaded rectangle nodes represent parameters (bound
variables). Network inputs treated constants, drawn without surrounding node.
Input parameter nodes incoming arcs, output nodes outgoing arcs.
output node matrix, dimensionality indicated
node.
graph incomplete: without specifying inputs, cannot compute output.
Figure 3b shows complete graph MLP takes three words inputs, predicts
distribution part-of-speech tags third word. graph used
prediction, training, output vector (not scalar) graph
take account correct answer loss term. Finally, graph 3c shows
372

fiA Primer Neural Networks NLP

11
neg
11
log
11
(a)

(b)

(c)

pick

1 17

1 17

1 17

softmax

softmax

softmax

1 17

1 17

1 17

ADD

ADD

ADD

1 17

1 17

1 17

MUL

MUL

MUL

1 20
tanh

20 17
W2

1 20

1 17
b2

20 17
W2

tanh

1 20

1 17
b2

1 20

1 20

ADD

ADD

ADD

1 20

1 20

1 20

MUL

MUL

MUL

150 20
W1

1 150

1 20
b1

concat

150 20
W1

20 17

1 17

150 20

1 20

W2

tanh

1 20

1 150
x

5

1 150

1 20
b1

concat

W1

1 50

1 50

1 50

1 50

1 50

1 50

lookup

lookup

lookup

lookup

lookup

lookup



black

dog



black

dog

|V | 50
E

b2

b1

|V | 50
E

Figure 3: Computation Graph MLP1. (a) Graph unbound input. (b) Graph
concrete input. (c) Graph concrete input, expected output, loss
node.

computation graph specific training example, inputs (embeddings
of) words the, black, dog, expected output NOUN (whose index
5). pick node implements indexing operation, receiving vector index (in
case, 5) returning corresponding entry vector.
graph built, straightforward run either forward computation (compute result computation) backward computation (computing gradients),
show below. Constructing graphs may look daunting, actually easy
using dedicated software libraries APIs.
6.2.1 Forward Computation
forward pass computes outputs nodes graph. Since nodes output
depends incoming edges, trivial compute outputs
nodes traversing nodes topological order computing output
node given already computed outputs predecessors.
373

fiGoldberg

formally, graph N nodes, associate node index according
topological ordering. Let fi function computed node (e.g. multiplication.
addition, . . . ). Let (i) parent nodes node i, 1 (i) = {j | (j)}
children nodes node (these arguments fi ). Denote v(i) output node
i, is, application fi output values arguments 1 (i). variable
input nodes, fi constant function 1 (i) empty. Forward algorithm
computes values v(i) [1, N ].
Algorithm 3 Computation Graph Forward Pass
1: = 1 N
2:
Let a1 , . . . , = 1 (i)
3:
v(i) fi (v(a1 ), . . . , v(am ))

6.2.2 Backward Computation (Derivatives, Backprop)
backward pass begins designating node N scalar (11) output loss-node,
running forward computation node. backward computation computes
N
gradients respect nodes value. Denote d(i) quantity
.

backpropagation algorithm used compute values d(i) nodes i.
backward pass fills table d(i) follows:
Algorithm 4 Computation Graph Backward Pass (Backpropagation)
1: d(N ) 1
2: = N-1 1
P
fj
3:
d(i) j(i) d(j)


fj
partial derivative fj ( 1 (j)) w.r.t argument 1 (j).

value depends function fj values v(a1 ), . . . , v(am ) (where a1 , . . . , =
1 (j)) arguments, computed forward pass.

quantity

Thus, order define new kind node, one need define two methods: one
calculating forward value v(i) based nodes inputs, another calculating
fi
x 1 (i).
x
information automatic differentiation see work Neidinger (2010,
Section 7) Baydin et al. (2015). depth discussion backpropagation
algorithm computation graphs (also called flow graphs) see work Bengio et al.
(2015, Section 6.4), LeCun et al. (1998b) Bengio (2012). popular yet technical
presentation, see online post Olah (2015a).
374

fiA Primer Neural Networks NLP

6.2.3 Software
Several software packages implement computation-graph model, including Theano55 ,
Chainer56 , penne57 CNN/pyCNN58 . packages support essential components (node types) defining wide range neural network architectures, covering
structures described tutorial more. Graph creation made almost transparent
use operator overloading. framework defines type representing graph nodes
(commonly called expressions), methods constructing nodes inputs parameters,
set functions mathematical operations take expressions input result
complex expressions. example, python code creating computation
graph Figure (3c) using pyCNN framework is:
import pycnn pc
# model initialization.
model = pc.Model()
pW1 = model.add_parameters((20,150))
pb1 = model.add_parameters(20)
pW2 = model.add_parameters((17,20))
pb2 = model.add_parameters(17)
words = model.add_lookup_parameters((100, 50))
# Building computation graph:
pc.renew_cg() # create new graph.
# Wrap model parameters graph-nodes.
W1 = pc.parameter(pW1)
b1 = pc.parameter(pb1)
W2 = pc.parameter(pW2)
b2 = pc.parameter(pb2)
def get_index(x): return 1 # place holder
# Generate embeddings layer.
vthe
= pc.lookup(words, get_index("the"))
vblack = pc.lookup(words, get_index("black"))
vdog
= pc.lookup(words, get_index("dog"))
# Connect leaf nodes complete graph.
x = pc.concatenate([vthe, vblack, vdog])
output = pc.softmax(W2*(pc.tanh(W1*x)+b1)+b2)
loss = -pc.log(pc.pick(output, 5))
loss_value = loss.forward()
loss.backward() # gradient computed
# stored corresponding
# parameters.

code involves various initializations: first block defines model parameters
shared different computation graphs (recall graph corresponds
specific training example). second block turns model parameters graphnode (Expression) types. third block retrieves Expressions embeddings
55.
56.
57.
58.

http://deeplearning.net/software/theano/
http://chainer.org
https://bitbucket.org/ndnlp/penne
https://github.com/clab/cnn

375

fiGoldberg

input words. Finally, fourth block graph created. Note transparent
graph creation almost one-to-one correspondence creating
graph describing mathematically. last block shows forward backward
pass. software frameworks follow similar patterns.
Theano involves optimizing compiler computation graphs, blessing
curse. one hand, compiled, large graphs run efficiently either
CPU GPU, making ideal large graphs fixed structure,
inputs change instances. However, compilation step costly,
makes interface bit cumbersome work with. contrast, packages focus
building large dynamic computation graphs executing fly without
compilation step. execution speed may suffer respect Theanos optimized
version, packages especially convenient working recurrent
recursive networks described Sections 10, 12 well structured prediction settings
described Section 8.
6.2.4 Implementation Recipe
Using computation graph abstraction, pseudo-code network training algorithm
given Algorithm 5.
Algorithm 5 Neural Network Training Computation Graph Abstraction (using minibatches size 1)
1: Define network parameters.
2: iteration = 1 N
3:
Training example xi , yi dataset
4:
loss node build computation graph(xi , yi , parameters)
5:
loss node.forward()
6:
gradients loss node().backward()
7:
parameters update parameters(parameters, gradients)
8: return parameters.
Here, build computation graph user-defined function builds computation
graph given input, output network structure, returning single loss node.
update parameters optimizer specific update rule. recipe specifies new
graph created training example. accommodates cases network
structure varies training example, recurrent recursive neural networks,
discussed Sections 10 12. networks fixed structures, MLPs,
may efficient create one base computation graph vary inputs
expected outputs examples.
6.2.5 Network Composition
long networks output vector (1 k matrix), trivial compose networks
making output one network input another, creating arbitrary networks.
computation graph abstractions makes ability explicit: node computation
graph computation graph designated output node. One
376

fiA Primer Neural Networks NLP

design arbitrarily deep complex networks, able easily evaluate train
thanks automatic forward gradient computation. makes easy define
train networks structured outputs multi-objective training, discuss
Section 7, well complex recurrent recursive networks, discussed Sections
1012.
6.3 Optimization Issues
gradient computation taken care of, network trained using SGD another
gradient-based optimization algorithm. function optimized convex,
long time training neural networks considered black art done
selected few. Indeed, many parameters affect optimization process, care
taken tune parameters. tutorial intended comprehensive
guide successfully training neural networks, list prominent issues.
discussion optimization techniques algorithms neural networks, refer
book Bengio et al. (2015, ch. 8). theoretical discussion analysis, refer
work Glorot Bengio (2010). various practical tips recommendations,
see work LeCun et al. (1998a) Bottou (2012).
6.3.1 Initialization
non-convexity loss function means optimization procedure may get stuck
local minimum saddle point, starting different initial points (e.g.
different random values parameters) may result different results. Thus,
advised run several restarts training starting different random initializations,
choosing best one based development set.59 amount variance
results different different network formulations datasets, cannot predicted
advance.
magnitude random values important effect success training.
effective scheme due Glorot Bengio (2010), called xavier initialization
Glorots first name, suggests initializing weight matrix W Rdin dout as:


#

6
6
W U
, +
din + dout
din + dout
"

(24)

U [a, b] uniformly sampled random value range [a, b]. suggestion
based properties tanh activation function, works well many occasions,
preferred default initialization method many.
Analysis et al. (2015) suggests using ReLU non-linearities, weights
initialized
sampling zero-mean Gaussian distribution whose standard
q
2
deviation
din . initialization found et al work better xavier
initialization image classification task, especially deep networks involved.
59. debugging, reproducibility results, advised used fixed random seed.

377

fiGoldberg

6.3.2 Vanishing Exploding Gradients
deep networks, common error gradients either vanish (become exceedingly
close 0) explode (become exceedingly high) propagate back computation graph. problem becomes severe deeper networks, especially
recursive recurrent networks (Pascanu, Mikolov, & Bengio, 2012). Dealing
vanishing gradients problem still open research question. Solutions include making
networks shallower, step-wise training (first train first layers based auxiliary
output signal, fix train upper layers complete network based
real task signal), performing batch-normalization (Ioffe & Szegedy, 2015) (for every
minibatch, normalizing inputs network layers zero mean unit
variance) using specialized architectures designed assist gradient flow (e.g.,
LSTM GRU architectures recurrent networks, discussed Section 11). Dealing
exploding gradients simple effective solution: clipping gradients
norm exceeds given threshold. Let g gradients parameters
network, kgk L2 norm. Pascanu et al. (2012) suggest set: g threshold
kgk g
kgk > threshold.
6.3.3 Saturation Dead Neurons
Layers tanh sigmoid activations become saturated resulting output values
layer close one, upper-limit activation function. Saturated
neurons small gradients, avoided. Layers ReLU activation
cannot saturated, die values negative thus clipped zero
inputs, resulting gradient zero layer. network train
well, advisable monitor network layers many saturated dead neurons.
Saturated neurons caused large values entering layer. may controlled
changing initialization, scaling range input values, changing
learning rate. Dead neurons caused signals entering layer negative (for
example happen large gradient update). Reducing learning rate
help situation. saturated layers, another option normalize values
saturated layer activation, i.e. instead g(h) = tanh(h) using g(h) = k tanh(h)
tanh(h)k .
Layer normalization effective measure countering saturation, also expensive
terms gradient computation. related technique batch normalization, due Ioffe
Szegedy (2015), activations layer normalized
mean 0 variance 1 across mini-batch. batch-normalization techniques
became key component effective training deep networks computer vision.
writing, less popular natural language applications.
6.3.4 Shuffling
order training examples presented network important.
SGD formulation specifies selecting random example turn. practice,
implementations go training example order. advised shuffle training
examples pass data.
378

fiA Primer Neural Networks NLP

6.3.5 Learning Rate
Selection learning rate important. large learning rates prevent network
converging effective solution. small learning rates take long time
converge. rule thumb, one experiment range initial learning rates
range [0, 1], e.g. 0.001, 0.01, 0.1, 1. Monitor networks loss time, decrease
learning rate loss stops improving. Learning rate scheduling decreases rate
function number observed minibatches. common schedule dividing initial
learning rate iteration number. Leon Bottou (2012) recommends using learning
rate form = 0 (1 + 0 t)1 0 initial learning rate, learning
rate use tth training example, additional hyperparameter.
recommends determining good value 0 based small sample data prior
running entire dataset.
6.3.6 Minibatches
Parameter updates occur either every training example (minibatches size 1) every k
training examples. problems benefit training larger minibatch sizes.
terms computation graph abstraction, one create computation graph
k training examples, connecting k loss nodes averaging node,
whose output loss minibatch. Large minibatched training also
beneficial terms computation efficiency specialized computing architectures
GPUs, replacing vector-matrix operations matrix-matrix operations. beyond
scope tutorial.
6.4 Regularization
Neural network models many parameters, overfitting easily occur. Overfitting
alleviated extent regularization. common regularization method
L2 regularization, placing squared penalty parameters large values adding
additive 2 kk2 term objective function minimized, set
model parameters, k k2 squared L2 norm (sum squares values),
hyperparameter controlling amount regularization.
recently proposed alternative regularization method dropout (Hinton, Srivastava,
Krizhevsky, Sutskever, & Salakhutdinov, 2012). dropout method designed prevent
network learning rely specific weights. works randomly dropping
(setting 0) half neurons network (or specific layer) training
example. Work Wager et al. (2013) establishes strong connection dropout
method L2 regularization.
dropout technique one key factors contributing strong results
neural-network methods image classification tasks (Krizhevsky, Sutskever, & Hinton,
2012), especially combined ReLU activation units (Dahl, Sainath, & Hinton,
2013). dropout technique effective also NLP applications neural networks.
379

fiGoldberg

7. Cascading Multi-task Learning
combination online training methods automatic gradient computations using
computation graph abstraction allows easy implementation model cascading,
parameter sharing multi-task learning.
7.1 Model Cascading
powerful technique large networks built composing smaller
component networks. example, may feed-forward network predicting
part speech word based neighbouring words and/or characters compose
it. pipeline approach, would use network predicting parts speech,
feed predictions input features neural network syntactic chunking
parsing. Instead, could think hidden layers network encoding
captures relevant information predicting part speech. cascading
approach, take hidden layers network connect (and part
speech prediction themselves) inputs syntactic network.
larger network takes input sequences words characters, outputs
syntactic structure. computation graph abstraction allows us easily propagate
error gradients syntactic task loss way back characters.
combat vanishing gradient problem deep networks, well make better
use available training material, individual component networks parameters
bootstrapped training separately relevant task, plugging
larger network tuning. example, part-of-speech predicting network
trained accurately predict parts-of-speech relatively large annotated corpus,
plugging hidden layer syntactic parsing network less training
data available. case training data provide direct supervision tasks,
make use training creating network two outputs, one task,
computing separate loss output, summing losses single node
backpropagate error gradients.
Model cascading common using convolutional, recursive recurrent
neural networks, where, example, recurrent network used encode sentence
fixed sized vector, used input another network. supervision
signal recurrent network comes primarily upper network consumes
recurrent networks output inputs.
7.2 Multi-task Learning
used related prediction tasks necessarily feed one another,
believe information useful one type prediction useful
also tasks. example, chunking, named entity recognition (NER)
language modeling examples synergistic tasks. Information predicting chunk
boundaries, named-entity boundaries next word sentence rely
shared underlying syntactic-semantic representation. Instead training separate network
task, create single network several outputs. common approach
multi-layer feed-forward network, whose final hidden layer (or concatenation
380

fiA Primer Neural Networks NLP

hidden layers) passed different output layers. way, parameters
network shared different tasks. Useful information learned one
task help disambiguate tasks. Again, computation graph abstraction
makes easy construct networks compute gradients them,
computing separate loss available supervision signal, summing
losses single loss used computing gradients. case several
corpora, different kind supervision signal (e.g. one corpus NER
another chunking), training procedure shuffle available training
example, performing gradient computation updates respect different loss
every turn. Multi-task learning context language-processing introduced
discussed work Collobert et al. (2011). examples cascaded Multi-task
learning feed forward network, see work Zhang Weiss (2016). context
recurrent neural networks, see work Luong, Le, Sutskever, Vinyals, Kaiser
(2015) Sgaard Goldberg (2016).

8. Structured Output Prediction
Many problems NLP involve structured outputs: cases desired output
class label distribution class labels, structured object sequence,
tree graph. Canonical examples sequence tagging (e.g. part-of-speech tagging)
sequence segmentation (chunking, NER), syntactic parsing. section, discuss
feed-forward neural network models used structured tasks. later sections
discuss specialized neural network models dealing sequences (Section 10)
trees (Section 12).
8.1 Greedy Structured Prediction
greedy approach structured prediction decompose structure prediction
problem sequence local prediction problems training classifier perform
local decision. test time, trained classifier used greedy manner. Examples
approach left-to-right tagging models (Gimenez & Marquez, 2004) greedy
transition-based parsing (Nivre, 2008). approaches easily adapted use neural
networks simply replacing local classifier linear classifier SVM
logistic regression model neural network, demonstrated Chen Manning
(2014) Lewis Steedman (2014).
greedy approaches suffer error propagation, mistakes early decisions
carry influence later decisions. overall higher accuracy achievable nonlinear neural network classifiers helps offsetting problem extent. addition,
training techniques proposed mitigating error propagation problem either
attempting take easier predictions harder ones (the easy-first approach Goldberg & Elhadad, 2010) making training conditions similar testing conditions
exposing training procedure inputs result likely mistakes (Hal Daume III,
Langford, & Marcu, 2009; Goldberg & Nivre, 2013). effective also training
greedy neural network models, demonstrated Ma, Zhang, Zhu (2014) (easy-first
tagger) Ballesteros, Goldberg, Dyer, Smith (2016) (dynamic oracle training
greedy dependency parsing).
381

fiGoldberg

8.2 Search Based Structured Prediction
common approach predicting natural language structures search based. indepth discussion search-based structure prediction NLP, see book Smith (2011).
techniques easily adapted use neural-network. neural-networks
literature, models discussed framework energy based learning (LeCun
et al., 2006, Section 7). presented using setup terminology familiar
NLP community.
Search-based structured prediction formulated search problem possible structures:
predict(x) = arg max score(x, y)

(25)

yY(x)

x input structure, output x (in typical example x sentence
tag-assignment parse-tree sentence), Y(x) set valid
structures x, looking output maximize score
x, pair.
scoring function defined linear model:
score(x, y) = w (x, y)

(26)

feature extraction function w weight vector.
order make search optimal tractable, structure decomposed
parts, feature function defined terms parts, (p) part-local
feature extraction function:
X
(x, y) =
(p)
(27)
pparts(x,y)

part scored separately, structure score sum component
parts scores:

score(x, y) =w (x, y) = w

X

(p) =

py

X
py

w (p) =

X

score(p)

(28)

py

p shorthand p parts(x, y). decomposition parts
exists inference algorithm allows efficient search best scoring
structure given scores individual parts.
One trivially replace linear scoring function parts neuralnetwork:

score(x, y) =

X

score(p) =

py

X

NN(c(p))

py

c(p) maps part p din dimensional vector.
case one hidden-layer feed-forward network:
382

(29)

fiA Primer Neural Networks NLP

score(x, y) =

X

NNMLP1 (c(p)) =

X
(g(c(p)W1 + b1 ))w

(30)

py

py

c(p) Rdin , W1 Rdin d1 , b1 Rd1 , w Rd1 . common objective structured
prediction making gold structure score higher structure 0 , leading
following (generalized perceptron) loss:

max
score(x, 0 ) score(x, y)
0


(31)

terms implementation, means: create computation graph CGp
possible parts, calculate score. Then, run inference scored parts
find best scoring structure 0 . Connect output nodes computation graphs
corresponding parts gold (predicted) structure (y 0 ) summing node CGy
(CG0y ). Connect CGy CG0y using minus node, CGl , compute gradients.
argued LeCun et al. (2006, Section 5), generalized perceptron loss may
good loss function training structured prediction neural networks
margin, margin-based hinge loss preferred:

max(0, + max
score(x, 0 ) score(x, y))
0
6=y

(32)

trivial modify implementation work hinge loss.
Note cases lose nice properties linear model. particular,
model longer convex. expected, even simplest non-linear neural
network already non-convex. Nonetheless, could still use standard neural-network
optimization techniques train structured model.
Training inference slower, evaluate neural network (and take
gradients) |parts(x, y)| times.
Structured prediction vast field beyond scope tutorial, loss
functions, regularizers methods described by, e.g., Smith (2011), cost-augmented
decoding, easily applied adapted neural-network framework.60
8.2.1 Probabilistic Objective (CRF)
probabilistic framework (conditional random fields, CRF), treat parts
scores clique potential (see discussions Smith, 2011 Lafferty, McCallum, &
Pereira, 2001) define score structure be:
60. One keep mind resulting objectives longer convex, lack formal guarantees bounds associated convex optimization problems. Similarly, theory, learning bounds
guarantees associated algorithms automatically transfer neural versions.

383

fiGoldberg

P
exp( py score(p))
P
scorecrf (x, y) = P (y|x) = P
0 Y(x) exp( py 0 score(p))
P
exp( py NN((p)))
P
=P
0 Y(x) exp( py 0 NN((p)))

(33)

scoring function defines conditional distribution P (y|x),
P wish set parameters network corpus conditional log likelihood (xi ,yi )training log P (yi |xi )
maximized.
loss given training example (x, y) then: log scorecrf (x, y). Taking
gradient respect loss involved building associated computation
graph. tricky part denominator (the partition function) requires summing
potentially exponentially many structures Y. However, problems,
dynamic programming algorithm exists efficiently solving summation polynomial
time (i.e. forward-backward viterbi recurrences sequences CKY insideoutside recurrences tree structures). algorithm exists, adapted
also create polynomial-size computation graph.
efficient enough algorithm computing partition function available,
approximate methods used. example, one may use beam search inference,
partition function sum structures remaining beam instead
exponentially large Y(x).
Sequence-level CRFs neural-network clique potentials discussed Peng, Bo,
Xu (2009) Do, Arti, others (2010), applied sequence labeling
biological data, OCR data speech signals, Wang Manning (2013)
apply traditional natural language tagging tasks (chunking NER). hinge
based approach used Pei et al. (2015) arc-factored dependency parsing,
probabilistic approach Durrett Klein (2015) CRF constituency parser.
approximate beam-based partition function effectively used Zhou et al. (2015)
transition based parser.
8.2.2 Reranking
searching possible structures intractable, inefficient hard integrate
model, reranking methods often used. reranking framework (Charniak
& Johnson, 2005; Collins & Koo, 2005) base model used produce list kbest scoring structures. complex model trained score candidates
k-best list best structure respect gold one scored highest.
search performed k items rather exponential space,
complex model condition (extract features from) arbitrary aspects scored
structure. Reranking methods natural candidates structured prediction using neuralnetwork models, allow modeler focus feature extraction network
structure, removing need integrate neural network scoring decoder.
Indeed, reranking methods often used experimenting neural models
straightforward integrate decoder, convolutional, recurrent recursive
networks, discussed later sections. Works using reranking approach
384

fiA Primer Neural Networks NLP

include Schwenk et al. (2006), Socher et al. (2013), Auli et al. (2013), Le
Zuidema (2014) Zhu et al. (2015a).
8.2.3 MEMM Hybrid Approaches
formulations are, course, also possible. example, MEMM (McCallum,
Freitag, & Pereira, 2000) trivially adapted neural network world replacing
logistic regression (Maximum Entropy) component MLP.
Hybrid approaches neural networks linear models also explored.
particular, Weiss et al. (2015) report strong results transition-based dependency parsing
two-stage model. first stage, static feed-forward neural network (MLP2)
trained perform well individual decisions structured problem
isolation. second stage, neural network model held fixed, different layers
(output well hidden layer vectors) input concatenated used
input features linear structured perceptron model (Collins, 2002) trained
perform beam-search best resulting structure. clear training
regime effective training single structured-prediction neural network, use
two simpler, isolated models allowed researchers perform much extensive
hyper-parameter search (e.g. tuning layer sizes, activation functions, learning rates
on) model feasible complicated networks.

9. Convolutional Layers
Sometimes interested making predictions based ordered sets items (e.g.
sequence words sentence, sequence sentences document on).
Consider example predicting sentiment (positive, negative neutral) sentence.
sentence words informative sentiment, words less
informative, good approximation, informative clue informative regardless
position sentence. would like feed sentence words
learner, let training process figure important clues. One possible solution
feeding CBOW representation fully connected network MLP. However,
downside CBOW approach ignores ordering information completely,
assigning sentences good, actually quite bad bad,
actually quite good exact representation. global position
indicators good bad matter classification task,
local ordering words (that word appears right word bad)
important. naive approach would suggest embedding word-pairs (bi-grams) rather
words, building CBOW embedded bigrams. architecture
could effective, result huge embedding matrices, scale longer ngrams, suffer data sparsity problems share statistical strength
different n-grams (the embedding quite good good completely
independent one another, learner saw one training,
able deduce anything based component words).
convolution-and-pooling (also called convolutional neural networks, CNNs) architecture
elegant robust solution modeling problem. convolutional neural network
designed identify indicative local predictors large structure, combine
385

fiGoldberg

produce fixed size vector representation structure, capturing local aspects
informative prediction task hand.
Convolution-and-pooling architectures (LeCun & Bengio, 1995) evolved neural
networks vision community, showed great success object detectors recognizing object predefined category (cat, bicycles) regardless position
image (Krizhevsky et al., 2012). applied images, architecture using
2-dimensional (grid) convolutions. applied text, mainly concerned
1-d (sequence) convolutions. Convolutional networks introduced NLP community pioneering work Collobert, Weston colleagues (2011) used
semantic-role labeling, later Kalchbrenner et al. (2014) Kim (2014) used
sentiment question-type classification.
9.1 Basic Convolution + Pooling
main idea behind convolution pooling architecture language tasks apply
non-linear (learned) function instantiation k-word sliding window
sentence. function (also called filter) transforms window k words
dimensional vector captures important properties words window (each
dimension sometimes referred literature channel). Then, pooling
operation used combine vectors resulting different windows single
d-dimensional vector, taking max average value observed
channels different windows. intention focus important
features sentence, regardless location. d-dimensional vector
fed network used prediction. gradients propagated
back networks loss training process used tune parameters
filter function highlight aspects data important task
network trained for. Intuitively, sliding window run sequence,
filter function learns identify informative k-grams.
formally, consider sequence words x = x1 , . . . , xn , corresponding demb dimensional word embedding v(xi ). 1d convolution layer61 width k works
moving sliding window size k sentence, applying filter
window sequence [v(xi ); v(xi+1 ); . . . ; v(xi+k1 )]. filter function usually
linear transformation followed non-linear activation function.
Let concatenated vector ith window wi = [v(xi ); v(xi+1 ); . . . ; v(xi+k1 )],
wi Rkdemb . Depending whether pad sentence k 1 words side,
may get either = n k + 1 (narrow convolution) = n + k + 1 windows (wide
convolution) (Kalchbrenner et al., 2014). result convolution layer vectors
p1 , . . . , pm , pi Rdconv where:
pi = g(wi W + b)

(34)

g non-linear activation function applied element-wise, W Rkdemb dconv
b Rdconv parameters network. pi dconv dimensional vector, encoding
61. 1d refers convolution operating 1-dimensional inputs sequences, opposed 2d
convolutions applied images.

386

fiA Primer Neural Networks NLP

63
W

max

quick brown fox jumped lazy dog
quick brown

MUL+tanh

quick brown fox

MUL+tanh

brown fox jumped

MUL+tanh

fox jumped

MUL+tanh

jumped

MUL+tanh

lazy

MUL+tanh

lazy dog

MUL+tanh

convolution

pooling

Figure 4: 1d convolution+pooling sentence quick brown fox jumped
lazy dog. narrow convolution (no padding added sentence)
window size 3. word translated 2-dim embedding vector
(not shown). embedding vectors concatenated, resulting 6-dim
window representations. seven windows transfered 6 3
filter (linear transformation followed element-wise tanh), resulting seven
3-dimensional filtered representations. Then, max-pooling operation applied,
taking max dimension, resulting final 3-dimensional pooled
vector.

information wi . Ideally, dimension captures different kind indicative information. vectors combined using max pooling layer, resulting single
dconv dimensional vector c.
cj = max pi [j]
1<im

(35)

pi [j] denotes jth component pi . effect max-pooling operation get
salient information across window positions. Ideally, dimension specialize
particular sort predictors, max operation pick important
predictor type.
Figure 4 provides illustration process.
resulting vector c representation sentence dimension
reflects salient information respect prediction task. c fed
downstream network layers, perhaps parallel vectors, culminating
output layer used prediction. training procedure network calculates
loss respect prediction task, error gradients propagated
way back pooling convolution layers, well embedding layers. 62
62. Besides useful prediction, by-product training procedure set parameters W, B
embeddings v() used convolution pooling architecture encode arbitrary length

387

fiGoldberg

max-pooling common pooling operation text applications,
pooling operations also possible, second common operation average
pooling, taking average value index instead max.
9.2 Dynamic, Hierarchical k-max Pooling
Rather performing single pooling operation entire sequence, may want
retain positional information based domain understanding prediction
problem hand. end, split vectors pi ` distinct groups, apply
pooling separately group, concatenate ` resulting dconv -dimensional
vectors c1 , . . . , c` . division pi groups performed based domain knowledge. example, may conjecture words appearing early sentence
indicative words appearing late. split sequence ` equally
sized regions, applying separate max-pooling region. example, Johnson
Zhang (2015) found classifying documents topics, useful 20
average-pooling regions, clearly separating initial sentences (where topic usually
introduced) later ones, sentiment classification task single max-pooling
operation entire sentence optimal (suggesting one two strong
signals enough determine sentiment, regardless position sentence).
Similarly, relation extraction kind task may given two words asked
determine relation them. could argue words first word,
words second word, words provide three different kinds
information (Chen et al., 2015). thus split pi vectors accordingly, pooling
separately windows resulting group.
Another variation using hierarchy convolutional layers, succession convolution pooling layers, stage applies convolution sequence,
pools every k neighboring vectors, performs convolution resulting pooled sequence,
applies another convolution on. architecture allows sensitivity increasingly
larger structures.
Finally, Kalchbrenner et al. (2014) introduced k-max pooling operation,
top k values dimension retained instead best one, preserving
order appeared text. example a, consider following matrix:

1
9

2

7
3

2
6
3
8
4


3
5

1

1
1



1-max pooling column vectors result 9 8 5 , 2-max pooling


9 6 3
result following matrix:
whose rows concatenated
7 8 5


9 6 3 7 8 5
sentences fixed-size vectors, sentences share kind predictive information
close other.

388

fiA Primer Neural Networks NLP

k-max pooling operation makes possible pool k active indicators
may number positions apart; preserves order features, insensitive
specific positions. also discern finely number times feature
highly activated (Kalchbrenner et al., 2014).
9.3 Variations
Rather single convolutional layer, several convolutional layers may applied
parallel. example, may four different convolutional layers, different
window size range 25, capturing n-gram sequences varying lengths. result
convolutional layer pooled, resulting vectors concatenated
fed processing (Kim, 2014).
convolutional architecture need restricted linear ordering sentence. example, et al. (2015) generalize convolution operation work
syntactic dependency trees. There, window around node syntactic tree,
pooling performed different nodes. Similarly, Liu et al. (2015) apply
convolutional architecture top dependency paths extracted dependency trees. Le
Zuidema (2015) propose perform max pooling vectors representing different
derivations leading chart item chart parser.

10. Recurrent Neural Networks Modeling Sequences Stacks
dealing language data, common work sequences, words
(sequences letters), sentences (sequences words) documents. saw feedforward networks accommodate arbitrary feature functions sequences
use vector concatenation vector addition (CBOW). particular, CBOW representations allows encode arbitrary length sequences fixed sized vectors. However,
CBOW representation quite limited, forces one disregard order features. convolutional networks also allow encoding sequence fixed size vector.
representations derived convolutional networks improvement
CBOW representation offer sensitivity word order, order sensitivity
restricted mostly local patterns, disregards order patterns far apart
sequence.
Recurrent neural networks (RNNs) (Elman, 1990) allow representing arbitrarily sized
structured inputs fixed-size vector, paying attention structured properties
input.
10.1 RNN Abstraction
use xi:j denote sequence vectors xi , . . . , xj . RNN abstraction takes
input ordered list input vectors x1 , ..., xn together initial state vector s0 ,
returns ordered list state vectors s1 , ..., sn , well ordered list output
vectors y1 , ..., yn . output vector yi function corresponding state vector
si . input vectors xi presented RNN sequential fashion, state
vector si output vector yi represent state RNN observing inputs
x1:i . output vector yi used prediction. example, model
389

fiGoldberg

predicting conditional probability event e given sequence m1:i defined
p(e = j|x1:i ) = softmax(yi W + b)[j], jth element output vector resulting
softmax operation. RNN model provides framework conditioning
entire history x1 , . . . , xi without resorting Markov assumption traditionally
used modeling sequences.63 Indeed, RNN-based language models result good
perplexity scores compared n-gram based models.
Mathematically, recursively defined function R takes input state
vector si input vector xi+1 , results new state vector si+1 . additional
function used map state vector si output vector yi .64 constructing
RNN, much like constructing feed-forward network, one specify dimension
inputs xi well dimensions outputs yi . dimensions states
si function output dimension.65
RNN(s0 , x1:n ) =s1:n , y1:n
si = R(si1 , xi )

(36)

yi = O(si )
xi Rdin , yi Rdout , si Rf (dout )
functions R across sequence positions, RNN keeps
track states computation state vector kept passed
invocations R.
Graphically, RNN traditionally presented Figure 5.
yi

si1

R,O



xi

si

Figure 5: Graphical representation RNN (recursive).
63. kth-order Markov assumption states observation time independent observations
times (k + j) j > 0 given observations times 1, , k. assumption
basis many sequence modeling technique n-gram models hidden markov models.
64. Using function somewhat non-standard, used order unify different RNN models
presented next section. Simple RNN (Elman RNN) GRU architectures,
identity mapping, LSTM architecture selects fixed subset state.
65. RNN architectures state dimension independent output dimension
possible, current popular architectures, including Simple RNN, LSTM GRU
follow flexibility.

390

fiA Primer Neural Networks NLP

presentation follows recursive definition, correct arbitrary long sequences.
However, finite sized input sequence (and input sequences deal finite)
one unroll recursion, resulting structure Figure 6.
y1

s0

R,O

x1

y3

y2

s1

R,O

s2

R,O

x2

y4

s3

x3

R,O

x4

y5

s4

R,O

s5

x5



Figure 6: Graphical representation RNN (unrolled).

usually shown visualization, include parameters order
highlight fact parameters shared across time steps. Different
instantiations R result different network structures, exhibit different
properties terms running times ability trained effectively using
gradient-based methods. However, adhere abstract interface.
provide details concrete instantiations R Simple RNN, LSTM
GRU Section 11. that, lets consider modeling RNN abstraction.
First, note value si based entire input x1 , ..., xi . example,
expanding recursion = 4 get:

s4 =R(s3 , x4 )


z }|3 {
=R(R(s2 , x3 ), x4 )


z }|2 {
=R(R(R(s1 , x2 ), x3 ), x4 )

(37)



z }|1 {
=R(R(R(R(s0 , x1 ), x2 ), x3 ), x4 )
Thus, sn (as well yn ) could thought encoding entire input sequence.66
encoding useful? depends definition usefulness. job network
training set parameters R state conveys useful information
task tying solve.
66. Note that, unless R specifically designed this, likely later elements input
sequence stronger effect sn earlier ones.

391

fiGoldberg

10.2 RNN Training
Viewed Figure 6 easy see unrolled RNN deep neural
network (or rather, large computation graph somewhat complex nodes),
parameters shared across many parts computation. train
RNN network, then, need create unrolled computation graph
given input sequence, add loss node unrolled graph, use backward
(backpropagation) algorithm compute gradients respect loss.
procedure referred RNN literature backpropagation time, BPTT
(Werbos, 1990).67 various ways supervision signal applied.
10.2.1 Acceptor
One option base supervision signal final output vector, yn . Viewed
way, RNN acceptor. observe final state, decide outcome.68
example, consider training RNN read characters word one one
use final state predict part-of-speech word (this inspired Ling
et al., 2015b), RNN reads sentence and, based final state decides
conveys positive negative sentiment (this inspired Wang et al., 2015b) RNN
reads sequence words decides whether valid noun-phrase. loss
cases defined terms function yn = O(sn ), error gradients
backpropagate rest sequence (see Figure 7).69 loss take
familiar form cross entropy, hinge, margin, etc.
10.2.2 Encoder
Similar acceptor case, encoder supervision uses final output vector, yn .
However, unlike acceptor, prediction made solely basis final
vector, final vector treated encoding information sequence,
used additional information together signals. example, extractive
document summarization system may first run document RNN, resulting
67. Variants BPTT algorithm include unrolling RNN fixed number input symbols
time: first unroll RNN inputs x1:k , resulting s1:k . Compute loss, backpropagate
error network (k steps back). Then, unroll inputs xk+1:2k , time using sk
initial state, backpropagate error k steps, on. strategy based
observations Simple-RNN variant, gradients k steps tend vanish (for large enough
k), omitting negligible. procedure allows training arbitrarily long sequences.
RNN variants LSTM GRU designed specifically mitigate vanishing
gradients problem, fixed size unrolling less motivated, yet still used, example
language modeling book without breaking sentences. similar variant unrolls
network entire sequence forward step, propagates gradients back k steps
position.
68. terminology borrowed Finite-State Acceptors. However, RNN potentially infinite
number states, making necessary rely function lookup table mapping states
decisions.
69. kind supervision signal may hard train long sequences, especially SimpleRNN, vanishing gradients problem. also generally hard learning task,
tell process parts input focus.

392

fiA Primer Neural Networks NLP

loss
predict &
calc loss
y5
s0

R,O

s1

x1

R,O

s2

x2

R,O

s3

x3

R,O

s4

x4

R,O

x5

Figure 7: Acceptor RNN Training Graph.
vector yn summarizing entire document. Then, yn used together
features order select sentences included summarization.
10.2.3 Transducer
Another option treat RNN transducer, producing output input
reads in. Modeled way, compute local loss signal Llocal (yi , yi )
outputs yP
based true label yi . loss unrolled sequence be:
L(y1:n
, y1:n ) = ni=1 Llocal (yi , yi ), using another combination rather sum
average weighted average (see Figure 8). One example transducer
sequence tagger, take xi:n feature representations n words
sentence, yi input predicting tag assignment word based
words 1:i. CCG super-tagger based architecture provides state-of-the art
CCG super-tagging results (Xu et al., 2015).
loss

sum

predict &
calc loss

predict &
calc loss

y1
s0

R,O

x1

predict &
calc loss

y2
s1

R,O

x2

predict &
calc loss

y3
s2

R,O

x3

predict &
calc loss

y4
s3

R,O

x4

y5
s4

R,O

x5

Figure 8: Transducer RNN Training Graph.
natural use-case transduction setup language modeling,
sequence words x1:i used predict distribution (i + 1)th word. RNN based
language models shown provide better perplexities traditional language models
(Mikolov et al., 2010; Sundermeyer, Schluter, & Ney, 2012; Mikolov, 2012; Jozefowicz,
Vinyals, Schuster, Shazeer, & Wu, 2016).
Using RNNs transducers allows us relax Markov assumption traditionally taken language models HMM taggers, condition entire prediction
393

fiGoldberg

history. power ability condition arbitrarily long histories demonstrated
generative character-level RNN models, text generated character character, character conditioning previous ones (Sutskever, Martens, & Hinton, 2011).
generated texts show sensitivity properties captured n-gram language
models, including line lengths nested parenthesis balancing. good demonstration
analysis properties RNN-based character level language models, see work
Karpathy, Johnson, Li (2015).
10.2.4 Encoder - Decoder
Finally, important special case encoder scenario Encoder-Decoder framework
(Cho, van Merrienboer, Bahdanau, & Bengio, 2014a; Sutskever et al., 2014). RNN
used encode sequence vector representation yn , vector representation
used auxiliary input another RNN used decoder. example,
machine-translation setup first RNN encodes source sentence vector
representation yn , state vector fed separate (decoder) RNN
trained predict (using transducer-like language modeling objective) words
target language sentence based previously predicted words well yn .
supervision happens decoder RNN, gradients propagated
way back encoder RNN (see Figure 9).
loss

sum

predict &
calc loss

predict &
calc loss

y1
sd0

RD ,OD

y2
sd1

,OE

x1

se1

sd2

RD ,OD

x2

,OE

x2

se2

predict &
calc loss

y3

RD ,OD

x1

se0

predict &
calc loss

y4
sd3

RD ,OD

x3

,OE

x3

se3

predict &
calc loss
y5
sd4

RD ,OD

x4

,OE

x4

se4

x5

,OE

se5

x5

Figure 9: Encoder-Decoder RNN Training Graph.
approach shown surprisingly effective Machine Translation (Sutskever
et al., 2014) using LSTM RNNs. order technique work, Sutskever et al. found
effective input source sentence reverse, xn corresponds first
394

fiA Primer Neural Networks NLP

word sentence. way, easier second RNN establish relation
first word source sentence first word target sentence.
Another use-case encoder-decoder framework sequence transduction. Here,
order generate tags t1 , . . . , tn , encoder RNN first used encode sentence
x1:n fixed sized vector. vector fed initial state vector another
(transducer) RNN, used together x1:n predict label ti position
i. approach used Filippova, Alfonseca, Colmenares, Kaiser, Vinyals (2015)
model sentence compression deletion.
10.3 Multi-layer (Stacked) RNNs
RNNs stacked layers, forming grid (Hihi & Bengio, 1996). Consider k RNNs,
j
RNN1 , . . . , RNNk , jth RNN states sj1:n outputs y1:n
. input
first RNN x1:n , input jth RNN (j 2) outputs RNN
j1
k .
it, y1:n
. output entire formation output last RNN, y1:n
layered architectures often called deep RNNs. visual representation 3-layer
RNN given Figure 10.
y1

y2

y13
s30

R3 ,O3

y23
s31

y12
s20

R2 ,O2

R1 ,O1

x1

R3 ,O3

R2 ,O2

R3 ,O3

R2 ,O2

R1 ,O1

x2

R1 ,O1

x3

R3 ,O3

y53
s34

y42
s23

y31
s12

y5

y43
s33

y32
s22

y21
s11

y4

y33
s32

y22
s21

y11
s10

y3

R2 ,O2

R1 ,O1

x4

s35

y52
s24

y41
s13

R3 ,O3

R2 ,O2

s25

y51
s14

R1 ,O1

s15

x5

Figure 10: 3-layer (deep) RNN architecture.
theoretically clear additional power gained deeper
architecture, observed empirically deep RNNs work better shallower ones
tasks. particular, Sutskever et al. (2014) report 4-layers deep architecture crucial achieving good machine-translation performance encoder-decoder
framework. Irsoy Cardie (2014) also report improved results moving onelayer biRNN architecture several layers. Many works report result using
layered RNN architectures, explicitly compare 1-layer RNNs.
10.4 Bidirectional RNNs (biRNN)
useful elaboration RNN bidirectional-RNN (biRNN, also commonly referred
biRNN) (Schuster & Paliwal, 1997; Graves, 2008).70 Consider task sequence
tagging sentence x1 , . . . , xn . RNN allows us compute function ith word
70. used specific RNN architecture LSTM, model called biLSTM.

395

fiGoldberg

xi based past words x1:i including it. However, following words
xi:n may also useful prediction, evident common sliding-window approach
focus word categorized based window k words surrounding it. Much
like RNN relaxes Markov assumption allows looking arbitrarily back
past, biRNN relaxes fixed window size assumption, allowing look arbitrarily far
past future.
Consider input sequence x1:n . biRNN works maintaining two separate states,
f
si sbi input position i. forward state sfi based x1 , x2 , . . . , xi ,
backward state sbi based xn , xn1 , . . . , xi . forward backward states
generated two different RNNs. first RNN (Rf , ) fed input sequence x1:n
is, second RNN (Rb , Ob ) fed input sequence reverse. state
representation si composed forward backward states.
output position based concatenation two output vectors
yi = [yif ; yib ] = [Of (sfi ); Ob (sbi )], taking account past future.
vector yi used directly prediction, fed part input
complex network. two RNNs run independently other, error gradients position flow forward backward two RNNs. visual
representation biRNN architecture given Figure 11.
ythe

ybrown

concat

concat

sb5

Rb ,Ob
y1f

sf0

Rf ,Of

xthe

concat
y4b

y5b
sb44

Rb ,Ob

sb33

Rf ,Of

Rb ,Ob
y3f

sf2

Rf ,Of

xbrown

xfox



concat
y3b

y2f
sf1

yjumped

yfox

concat
y2b

sb22

Rb ,Ob
y4f

sf3

Rf ,Of

xjumped

y1b
sb11

sb00

Rb ,Ob
y5f

sf4

sf5

Rf ,Of

x

Figure 11: biRNN sentence brown fox jumped ..
use biRNNs sequence tagging introduced NLP community Irsoy
Cardie (2014).
10.5 RNNs Representing Stacks
algorithms language processing, including transition-based parsing (Nivre,
2008), require performing feature extraction stack. Instead confined
looking k top-most elements stack, RNN framework used provide
fixed-sized vector encoding entire stack.
main intuition stack essentially sequence, stack state
represented taking stack elements feeding order RNN, resulting
final encoding entire stack. order computation efficiently (without
396

fiA Primer Neural Networks NLP

performing O(n) stack encoding operation time stack changes), RNN state
maintained together stack state. stack push-only, would
trivial: whenever new element x pushed stack, corresponding vector x
used together RNN state si order obtain new state si+1 . Dealing
pop operation challenging, solved using persistent-stack
data-structure (Okasaki, 1999; Goldberg, Zhao, & Huang, 2013). Persistent, immutable,
data-structures keep old versions intact modified. persistent stack
construction represents stack pointer head linked list. empty stack
empty list. push operation appends element list, returning new head.
pop operation returns parent head, keeping original list intact.
point view someone held pointer previous head, stack
change. subsequent push operation add new child node. Applying
procedure throughout lifetime stack results tree, root
empty stack path node root represents intermediary stack state.
Figure 12 provides example tree. process applied
computation graph construction, creating RNN tree structure instead chain
structure. Backpropagating error given node affect elements
participated stack node created, order. Figure 13 shows
computation graph stack-RNN corresponding last state Figure 12.
modeling approach proposed independently Dyer et al. (2015) Watanabe
Sumita (2015) transition-based dependency parsing.
head

head


head







(1) push

head




b

(2) push b

b



head

c





(3) push c

b

c





(4) pop

(5) push

head







b
head

(6) pop

c







b

c





b

c

b

head

e

e





c





b

f

c

head
(7) pop

(8) push e

(9) push f

Figure 12: immutable stack construction sequence operations push a; push b;
push c; pop; push d; pop; pop; push e; push f.

10.6 Note Reading Literature
Unfortunately, often case inferring exact model form reading
description research paper quite challenging. Many aspects models
397

fiGoldberg

ya,e

R,O

ya,e,f

sa,e

ya,b,d xe

sa

ya



R,O

xa

ya:b

sa

R,O

xb

sa:b

ya:c

R,O

sa,e,f

xf

sa,b,d

R,O

sa:b

R,O

xd

sa:c

xc

Figure 13: stack-RNN corresponding final state Figure 12.

yet standardized, different researchers use terms refer slightly
different things. list examples, inputs RNN either one-hot vectors
(in case embedding matrix internal RNN) embedded representations;
input sequence padded start-of-sequence and/or end-of-sequence symbols,
not; output RNN usually assumed vector expected
fed additional layers followed softmax prediction (as case
presentation tutorial), papers assume softmax part RNN itself;
multi-layer RNN, state vector either output top-most layer,
concatenation outputs layers; using encoder-decoder framework,
conditioning output encoder interpreted various different ways;
on. top that, LSTM architecture described next section many small
variants, referred common name LSTM. choices
made explicit papers, require careful reading, others still even
mentioned, hidden behind ambiguous figures phrasing.
reader, aware issues reading interpret model descriptions.
writer, aware issues well: either fully specify model mathematical
notation, refer different source model fully specified, source
available. using default implementation software package without knowing
details, explicit fact specify software package use. case,
dont rely solely figures natural language text describing model,
often ambiguous.
398

fiA Primer Neural Networks NLP

11. Concrete RNN Architectures
turn present three different instantiations abstract RN N architecture
discussed previous section, providing concrete definitions functions R O.
Simple RNN (SRNN), Long Short-Term Memory (LSTM) Gated
Recurrent Unit (GRU).
11.1 Simple RNN
simplest RNN formulation, known Elman Network Simple-RNN (S-RNN),
proposed Elman (1990) explored use language modeling Mikolov (2012).
S-RNN takes following form:
si =Rsrnn (si1 , xi ) = g(xi Wx + si1 Ws + b)
yi =Osrnn (si ) = si

(38)

si , yi Rds , xi Rdx , Wx Rdx ds , Ws Rds ds , b Rds
is, state position linear combination input position
previous state, passed non-linear activation (commonly tanh ReLU).
output position hidden state position.71
spite simplicity, Simple RNN provides strong results sequence tagging
(Xu et al., 2015) well language modeling. comprehensive discussion using
Simple RNNs language modeling, see PhD thesis Mikolov (2012).
11.2 LSTM
S-RNN hard train effectively vanishing gradients problem (Pascanu
et al., 2012). Error signals (gradients) later steps sequence diminish quickly
back-propagation process, reach earlier input signals, making hard
S-RNN capture long-range dependencies. Long Short-Term Memory (LSTM)
architecture (Hochreiter & Schmidhuber, 1997) designed solve vanishing gradients
problem. main idea behind LSTM introduce part state representation
also memory cells (a vector) preserve gradients across time. Access
memory cells controlled gating components smooth mathematical functions
simulate logical gates. input state, gate used decide much new
input written memory cell, much current content
memory cell forgotten. Concretely, gate g [0, 1]n vector values
range [0, 1] multiplied component-wise another vector v Rn , result
added another vector. values g designed close either 0 1, i.e.
using sigmoid function. Indices v corresponding near-one values g allowed
pass, corresponding near-zero values blocked.
71. authors treat output position complicated function state, e.g. linear
transformation, MLP. presentation, transformation output
considered part RNN, separate computations applied RNNs output.

399

fiGoldberg

Mathematically, LSTM architecture defined as:72

sj = Rlstm (sj1 , xj ) =[cj ; hj ]
cj =cj1 fi f + g fi

hj = tanh(cj ) fi

=(xj Wxi + hj1 Whi )

f =(xj Wxf + hj1 Whf )
=(xj W

xo

+ hj1 W

ho

(39)

)

g = tanh(xj Wxg + hj1 Whg )
yj = Olstm (sj ) =hj

sj R2dh , xi Rdx , cj , hj , i, f , o, g Rdh , Wx Rdx dh , Wh Rdh dh ,
symbol fi used denote component-wise product. state time j composed two vectors, cj hj , cj memory component hj hidden
state component. three gates, i, f o, controlling input, f orget output.
gate values computed based linear combinations current input xj
previous state hj1 , passed sigmoid activation function. update candidate g
computed linear combination xj hj1 , passed tanh activation function. memory cj updated: forget gate controls much previous
memory keep (cj1 fi f ), input gate controls much proposed update
keep (g fi i). Finally, value hj (which also output yj ) determined based
content memory cj , passed tanh non-linearity controlled
output gate. gating mechanisms allow gradients related memory part cj
stay high across long time ranges.
discussion LSTM architecture see PhD thesis Alex Graves
(2008), well online-post Olah (2015b). analysis behavior
LSTM used character-level language model, see work Karpathy et al.
(2015).
explanation motivation behind gating mechanism LSTM
(and GRU) relation solving vanishing gradient problem recurrent neural
networks, see Sections 4.2 4.3 detailed course notes Cho (2015).
LSTMs currently successful type RNN architecture, responsible many state-of-the-art sequence modeling results. main competitor
LSTM-RNN GRU, discussed next.
72. many variants LSTM architecture presented here. example, forget gates
part original proposal Hochreiter Schmidhuber (1997), shown important
part architecture. variants include peephole connections gate-tying. overview
comprehensive empirical comparison various LSTM architectures see work Greff, Srivastava,
Koutnk, Steunebrink, Schmidhuber (2015).

400

fiA Primer Neural Networks NLP

11.2.1 Practical Considerations
training LSTM networks, Jozefowicz et al. (2015) strongly recommend always
initialize bias term forget gate close one. applying dropout
RNN LSTM, Zaremba et al. (2014) found crucial apply dropout
non-recurrent connection, i.e. apply layers
sequence positions.
11.3 GRU
LSTM architecture effective, also quite complicated. complexity
system makes hard analyze, also computationally expensive work with.
gated recurrent unit (GRU) recently introduced Cho et al. (2014b) alternative
LSTM. subsequently shown Chung et al. (2014) perform comparably
LSTM several (non textual) datasets.
Like LSTM, GRU also based gating mechanism, substantially
fewer gates without separate memory component.
sj = RGRU (sj1 , xj ) =(1 z) fi sj1 + z fi sj
z =(xj Wxz + sj1 Wsz )
r =(xj Wxr + sj1 Wsr )
sj = tanh(xj Wxs + (sj1 fi r)Wsg )

(40)

yj = OGRU (sj ) =sj
sj , sj Rds , xi Rdx , z, r Rds , Wx Rdx ds , Ws Rds ds ,
One gate (r) used control access previous state sj1 compute proposed update sj . updated state sj (which also serves output yj ) determined based
interpolation previous state sj1 proposal sj , proportions
interpolation controlled using gate z.73
GRU shown effective language modeling machine translation.
However, jury still GRU, LSTM possible alternative RNN
architectures, subject actively researched. empirical exploration
GRU LSTM architectures, see work Jozefowicz et al. (2015).
11.4 Variants
gated architectures LSTM GRU help alleviating vanishing gradients problem Simple RNN, allow RNNs capture dependencies span
long time ranges. researchers explore simpler architectures LSTM
GRU achieving similar benefits.
Mikolov et al. (2014) observed matrix multiplication si1 Ws coupled
nonlinearity g update rule R Simple RNN causes state vector si undergo
73. states often called h GRU literature.

401

fiGoldberg

large changes time step, prohibiting remembering information long
time periods. propose split state vector si slow changing component ci
(context units) fast changing component hi .74 slow changing component ci
updated according linear interpolation input previous component: ci =
(1 )xi Wx1 + ci1 , (0, 1). update allows ci accumulate previous
inputs. fast changing component hi updated similarly Simple RNN update
rule, changed take ci account well:75 hi = (xi Wx2 + hi1 Wh + ci Wc ).
Finally, output yi concatenation slow fast changing parts
state: yi = [ci ; hi ]. Mikolov et al. demonstrate architecture provides competitive
perplexities much complex LSTM language modeling tasks.
approach Mikolov et al. interpreted constraining block
matrix Ws S-RNN corresponding ci multiply identity matrix (see
Mikolov et al. (2014) details). Le, Jaitly, Hinton (2015) propose even simpler
approach: set activation function S-RNN ReLU, initialize biases b
zeroes matrix Ws identify matrix. causes untrained RNN copy
previous state current state, add effect current input xi set
negative values zero. setting initial bias towards state copying, training
procedure allows Ws change freely. Le et al. demonstrate simple modification
makes S-RNN comparable LSTM number parameters several
tasks, including language modeling.

12. Modeling Trees Recursive Neural Networks
RNN useful modeling sequences. language processing, often natural
desirable work tree structures. trees syntactic trees, discourse trees,
even trees representing sentiment expressed various parts sentence (Socher
et al., 2013). may want predict values based specific tree nodes, predict values
based root nodes, assign quality score complete tree part tree.
cases, may care tree structure directly rather reason spans
sentence. cases, tree merely used backbone structure helps
guide encoding process sequence fixed size vector.
recursive neural network (RecNN) abstraction (Pollack, 1990), popularized NLP
Richard Socher colleagues (Socher, Manning, & Ng, 2010; Socher, Lin, Ng, & Manning, 2011; Socher et al., 2013; Socher, 2014) generalization RNN sequences
(binary) trees.76
Much like RNN encodes sentence prefix state vector, RecNN encodes
tree-node state vector Rd . use state vectors either predict
values corresponding nodes, assign quality values node, semantic
representation spans rooted nodes.
74. depart notation Mikolov et al. (2014) reuse symbols used LSTM description.
75. update rule diverges S-RNN update rule also fixing non-linearity sigmoid
function, using bias term. However, changes discussed central
proposal.
76. presented terms binary parse trees, concepts easily transfer general recursively-defined
data structures, major technical challenge definition effective form R,
combination function.

402

fiA Primer Neural Networks NLP

main intuition behind recursive neural networks subtree represented dimensional vector, representation node p children c1 c2
function representation nodes: vec(p) = f (vec(c1 ), vec(c2 )), f
composition function taking two d-dimensional vectors returning single d-dimensional
vector. Much like RNN state si used encode entire sequence x1 : i, RecNN
state associated tree node p encodes entire subtree rooted p. See Figure 14
illustration.

S=
combine

N P2 =

VP =

combine

N P1 =

V =

Figure 14: Illustration recursive neural network. representations V NP1
combined form representation VP. representations VP
NP2 combined form representation S.

12.1 Formal Definition
Consider binary parse tree n-word sentence. reminder, ordered,
unlabeled tree string x1 , . . . , xn represented unique set triplets (i, k, j),
s.t. k j. triplet indicates node spanning words xi:j parent
nodes spanning xi:k xk+1:j . Triplets form (i, i, i) correspond terminal symbols
tree leaves (the words xi ). Moving unlabeled case labeled one,
represent tree set 6-tuples (A B, C, i, k, j), whereas i, k j indicate spans
before, A, B C node labels nodes spanning xi:j , xi:k xk+1:j
respectively. Here, leaf nodes form (A A, A, i, i, i), pre-terminal
symbol. refer tuples production rules. example, consider syntactic
tree sentence boy saw duck.
403

fiGoldberg


VP

NP

NP

Det Noun Verb


boy

saw

Det Noun


duck

corresponding unlabeled labeled representations :
Unlabeled
(1,1,1)
(2,2,2)
(3,3,3)
(4,4,4)
(5,5,5)
(4,4,5)
(3,3,5)
(1,1,2)
(1,2,5)

Labeled
(Det, Det, Det, 1, 1, 1)
(Noun, Noun, Noun, 2, 2, 2)
(Verb, Verb, Verb, 3, 3, 3)
(Det, Det, Det, 4, 4, 4)
(Noun, Noun, Noun, 5, 5, 5)
(NP, Det, Noun, 4, 4, 5)
(VP, Verb, NP, 3, 3, 5)
(NP, Det, Noun, 1, 1, 2)
(S, NP, VP, 1, 2, 5)

Corresponding Span
x1:1
x2:2 boy
saw

duck
duck
saw duck
boy
boy saw duck


set production rules uniquely converted set tree nodes qi:j
(indicating node symbol span xi:j ) simply ignoring elements
(B, C, k) production rule. position define recursive neural
network.
recursive neural network (RecNN) function takes input parse tree
n-word sentence x1 , . . . , xn . sentences words represented d-dimensional
vector xi , tree represented set production rules (A B, C, i, j, k).
. RecNN returns output corresponding set
Denote nodes qi:j


inside state vectors si:j , inside state vector sA
i:j R represents corresponding
, encodes entire structure rooted node. Like sequence RNN,
tree node qi:j
tree shaped RecNN defined recursively using function R, inside vector
given node defined function inside vectors direct children.77 Formally:



RecNN(x1 , . . . , xn , ) ={sA
i:j R | qi:j }

sA
i:i =v(xi )

B
C
sA
i:j =R(A, B, C, si:k , sk+1:j )

(41)
B
C
, qk+1:j

qi:k

77. Le Zuidema (2014) extend RecNN definition node has, addition inside
state vector, also outside state vector representing entire structure around subtree rooted
node. formulation based recursive computation classic inside-outside
algorithm, thought biRNN counterpart tree RecNN. details, see work
Le Zuidema.

404

fiA Primer Neural Networks NLP

function R usually takes form simple linear transformation, may
may followed non-linear activation function g:
C
B
C
R(A, B, C, sB
i:k , sk+1:j ) = g([si:k ; sk+1:j ]W)

(42)

formulation R ignores tree labels, using matrix W R2dd
combinations. may useful formulation case node labels exist (e.g.
tree represent syntactic structure clearly defined labels)
unreliable. However, labels available, generally useful include
composition function. One approach would introduce label embeddings v(A)
mapping non-terminal symbol dnt dimensional vector, change R include
embedded symbols combination function:
C
B
C
R(A, B, C, sB
i:k , sk+1:j ) = g([si:k ; sk+1:j ; v(A); v(B)]W)

(43)

(here, W R2d+2dnt ). approach taken Qian, Tian, Huang, Liu, Zhu,
Zhu (2015). alternative approach, due Socher et al. (2013) untie weights
according non-terminals, using different composition matrix B, C pair
symbols:78
BC
C
B
C
)
R(A, B, C, sB
i:k , sk+1:j ) = g([si:k ; sk+1:j ]W

(44)

formulation useful number non-terminal symbols (or number
possible symbol combinations) relatively small, usually case phrase-structure
parse trees. similar model also used Hashimoto et al. (2013) encode subtrees
semantic-relation classification task.
12.2 Extensions Variations
definitions R suffer vanishing gradients problem
Simple RNN, several authors sought replace functions inspired Long ShortTerm Memory (LSTM) gated architecture, resulting Tree-shaped LSTMs (Tai, Socher, &
Manning, 2015; Zhu, Sobhani, & Guo, 2015b). question optimal tree representation
still much open research question, vast space possible combination
functions R yet explored. proposed variants tree-structured RNNs includes
recursive matrix-vector model (Socher, Huval, Manning, & Ng, 2012) recursive neural
tensor network (Socher et al., 2013). first variant, word represented
combination vector matrix, vector defines words static semantic
content before, matrix acts learned operator word, allowing
subtle semantic compositions addition weighted averaging implied
concatenation followed linear transformation function. second variant, words
associated vectors usual, composition function becomes expressive
basing tensor instead matrix operations.
78. explored literature, trivial extension would condition transformation matrix also
A.

405

fiGoldberg

12.3 Training Recursive Neural Networks
training procedure recursive neural network follows recipe training
forms networks: define loss, spell computation graph, compute gradients
using backpropagation79 , train parameters using SGD.
regard loss function, similar sequence RNN one associate loss
either root tree, given node, set nodes, case
individual nodes losses combined, usually summation. loss function based
labeled training data associates label quantity different tree
nodes.
Additionally, one treat RecNN Encoder, whereas inside-vector associated node taken encoding tree rooted node. encoding
potentially sensitive arbitrary properties structure. vector
passed input another network.
discussion recursive neural networks use natural language
tasks, refer PhD thesis Richard Socher (2014).

13. Conclusions
Neural networks powerful learners, providing opportunities ranging non-linear
classification non-Markovian modeling sequences trees. hope exposition helps NLP researchers incorporate neural network models work take
advantage power.

References
Adel, H., Vu, N. T., & Schultz, T. (2013). Combination Recurrent Neural Networks
Factored Language Models Code-Switching Language Modeling. Proceedings
51st Annual Meeting Association Computational Linguistics (Volume 2: Short Papers), pp. 206211, Sofia, Bulgaria. Association Computational
Linguistics.
Ando, R., & Zhang, T. (2005a). High-Performance Semi-Supervised Learning Method
Text Chunking. Proceedings 43rd Annual Meeting Association
Computational Linguistics (ACL05), pp. 19, Ann Arbor, Michigan. Association
Computational Linguistics.
Ando, R. K., & Zhang, T. (2005b). framework learning predictive structures
multiple tasks unlabeled data. Journal Machine Learning Research, 6,
18171853.
Auli, M., Galley, M., Quirk, C., & Zweig, G. (2013). Joint Language Translation Modeling Recurrent Neural Networks. Proceedings 2013 Conference
Empirical Methods Natural Language Processing, pp. 10441054, Seattle, Washington, USA. Association Computational Linguistics.
79. introduction computation graph abstraction, specific backpropagation procedure
computing gradients RecNN defined referred Back-propagation
Structure (BPTS) algorithm (Goller & Kuchler, 1996).

406

fiA Primer Neural Networks NLP

Auli, M., & Gao, J. (2014). Decoder Integration Expected BLEU Training Recurrent
Neural Network Language Models. Proceedings 52nd Annual Meeting
Association Computational Linguistics (Volume 2: Short Papers), pp. 136142,
Baltimore, Maryland. Association Computational Linguistics.
Ballesteros, M., Dyer, C., & Smith, N. A. (2015). Improved Transition-based Parsing
Modeling Characters instead Words LSTMs. Proceedings 2015 Conference Empirical Methods Natural Language Processing, pp. 349359, Lisbon,
Portugal. Association Computational Linguistics.
Ballesteros, M., Goldberg, Y., Dyer, C., & Smith, N. A. (2016). Training Exploration
Improves Greedy Stack-LSTM Parser. arXiv:1603.03793 [cs].
Bansal, M., Gimpel, K., & Livescu, K. (2014). Tailoring Continuous Word Representations
Dependency Parsing. Proceedings 52nd Annual Meeting Association
Computational Linguistics (Volume 2: Short Papers), pp. 809815, Baltimore,
Maryland. Association Computational Linguistics.
Baydin, A. G., Pearlmutter, B. A., Radul, A. A., & Siskind, J. M. (2015). Automatic
differentiation machine learning: survey. arXiv:1502.05767 [cs].
Bengio, Y. (2012). Practical recommendations gradient-based training deep architectures. arXiv:1206.5533 [cs].
Bengio, Y., Ducharme, R., Vincent, P., & Janvin, C. (2003). Neural Probabilistic Language Model. J. Mach. Learn. Res., 3, 11371155.
Bengio, Y., Goodfellow, I. J., & Courville, A. (2015). Deep Learning. Book preparation
MIT Press.
Bitvai, Z., & Cohn, T. (2015). Non-Linear Text Regression Deep Convolutional
Neural Network. Proceedings 53rd Annual Meeting Association
Computational Linguistics 7th International Joint Conference Natural Language Processing (Volume 2: Short Papers), pp. 180185, Beijing, China. Association
Computational Linguistics.
Botha, J. A., & Blunsom, P. (2014). Compositional Morphology Word Representations
Language Modelling. Proceedings 31st International Conference
Machine Learning (ICML), Beijing, China. *Award best application paper*.
Bottou, L. (2012). Stochastic gradient descent tricks. Neural Networks: Tricks
Trade, pp. 421436. Springer.
Charniak, E., & Johnson, M. (2005). Coarse-to-Fine n-Best Parsing MaxEnt Discriminative Reranking. Proceedings 43rd Annual Meeting Association
Computational Linguistics (ACL05), pp. 173180, Ann Arbor, Michigan. Association
Computational Linguistics.
Chen, D., & Manning, C. (2014). Fast Accurate Dependency Parser using Neural
Networks. Proceedings 2014 Conference Empirical Methods Natural
Language Processing (EMNLP), pp. 740750, Doha, Qatar. Association Computational Linguistics.
407

fiGoldberg

Chen, Y., Xu, L., Liu, K., Zeng, D., & Zhao, J. (2015). Event Extraction via Dynamic
Multi-Pooling Convolutional Neural Networks. Proceedings 53rd Annual
Meeting Association Computational Linguistics 7th International
Joint Conference Natural Language Processing (Volume 1: Long Papers), pp. 167
176, Beijing, China. Association Computational Linguistics.
Cho, K. (2015). Natural Language Understanding Distributed Representation.
arXiv:1511.07916 [cs, stat].
Cho, K., van Merrienboer, B., Bahdanau, D., & Bengio, Y. (2014a). Properties
Neural Machine Translation: EncoderDecoder Approaches. Proceedings SSST8, Eighth Workshop Syntax, Semantics Structure Statistical Translation,
pp. 103111, Doha, Qatar. Association Computational Linguistics.
Cho, K., van Merrienboer, B., Gulcehre, C., Bahdanau, D., Bougares, F., Schwenk, H., &
Bengio, Y. (2014b). Learning Phrase Representations using RNN EncoderDecoder
Statistical Machine Translation. Proceedings 2014 Conference Empirical
Methods Natural Language Processing (EMNLP), pp. 17241734, Doha, Qatar.
Association Computational Linguistics.
Chrupala, G. (2014). Normalizing tweets edit scripts recurrent neural embeddings.
Proceedings 52nd Annual Meeting Association Computational Linguistics (Volume 2: Short Papers), pp. 680686, Baltimore, Maryland. Association
Computational Linguistics.
Chung, J., Gulcehre, C., Cho, K., & Bengio, Y. (2014). Empirical Evaluation Gated
Recurrent Neural Networks Sequence Modeling. arXiv:1412.3555 [cs].
Collins, M. (2002). Discriminative Training Methods Hidden Markov Models: Theory
Experiments Perceptron Algorithms. Proceedings 2002 Conference Empirical Methods Natural Language Processing, pp. 18. Association
Computational Linguistics.
Collins, M., & Koo, T. (2005). Discriminative Reranking Natural Language Parsing.
Computational Linguistics, 31 (1), 2570.
Collobert, R., & Weston, J. (2008). unified architecture natural language processing:
Deep neural networks multitask learning. Proceedings 25th international
conference Machine learning, pp. 160167. ACM.
Collobert, R., Weston, J., Bottou, L., Karlen, M., Kavukcuoglu, K., & Kuksa, P. (2011).
Natural language processing (almost) scratch. Journal Machine Learning
Research, 12, 24932537.
Crammer, K., & Singer, Y. (2002). algorithmic implementation multiclass kernelbased vector machines. Journal Machine Learning Research, 2, 265292.
Creutz, M., & Lagus, K. (2007). Unsupervised Models Morpheme Segmentation
Morphology Learning. ACM Trans. Speech Lang. Process., 4 (1), 3:13:34.
Cybenko, G. (1989). Approximation superpositions sigmoidal function. Mathematics
Control, Signals Systems, 2 (4), 303314.
408

fiA Primer Neural Networks NLP

Dahl, G., Sainath, T., & Hinton, G. (2013). Improving deep neural networks LVCSR
using rectified linear units dropout. 2013 IEEE International Conference
Acoustics, Speech Signal Processing (ICASSP), pp. 86098613.
Dauphin, Y. N., Pascanu, R., Gulcehre, C., Cho, K., Ganguli, S., & Bengio, Y. (2014).
Identifying attacking saddle point problem high-dimensional non-convex
optimization. Ghahramani, Z., Welling, M., Cortes, C., Lawrence, N. D., & Weinberger, K. Q. (Eds.), Advances Neural Information Processing Systems 27, pp.
29332941. Curran Associates, Inc.
de Gispert, A., Iglesias, G., & Byrne, B. (2015). Fast Accurate Preordering SMT
using Neural Networks. Proceedings 2015 Conference North American
Chapter Association Computational Linguistics: Human Language Technologies, pp. 10121017, Denver, Colorado. Association Computational Linguistics.
Do, T., Arti, T., & others (2010). Neural conditional random fields. International
Conference Artificial Intelligence Statistics, pp. 177184.
Dong, L., Wei, F., Tan, C., Tang, D., Zhou, M., & Xu, K. (2014). Adaptive Recursive Neural
Network Target-dependent Twitter Sentiment Classification. Proceedings
52nd Annual Meeting Association Computational Linguistics (Volume
2: Short Papers), pp. 4954, Baltimore, Maryland. Association Computational
Linguistics.
Dong, L., Wei, F., Zhou, M., & Xu, K. (2015). Question Answering Freebase
Multi-Column Convolutional Neural Networks. Proceedings 53rd Annual
Meeting Association Computational Linguistics 7th International
Joint Conference Natural Language Processing (Volume 1: Long Papers), pp. 260
269, Beijing, China. Association Computational Linguistics.
dos Santos, C., & Gatti, M. (2014). Deep Convolutional Neural Networks Sentiment
Analysis Short Texts. Proceedings COLING 2014, 25th International Conference Computational Linguistics: Technical Papers, pp. 6978, Dublin, Ireland.
Dublin City University Association Computational Linguistics.
dos Santos, C., Xiang, B., & Zhou, B. (2015). Classifying Relations Ranking
Convolutional Neural Networks. Proceedings 53rd Annual Meeting
Association Computational Linguistics 7th International Joint Conference Natural Language Processing (Volume 1: Long Papers), pp. 626634, Beijing,
China. Association Computational Linguistics.
dos Santos, C., & Zadrozny, B. (2014). Learning Character-level Representations Partof-Speech Tagging. Proceedings 31st International Conference Machine
Learning (ICML), pp. 18181826.
Duchi, J., Hazan, E., & Singer, Y. (2011). Adaptive subgradient methods online learning
stochastic optimization. Journal Machine Learning Research, 12, 2121
2159.
Duh, K., Neubig, G., Sudoh, K., & Tsukada, H. (2013). Adaptation Data Selection using Neural Language Models: Experiments Machine Translation. Proceedings
409

fiGoldberg

51st Annual Meeting Association Computational Linguistics (Volume 2: Short Papers), pp. 678683, Sofia, Bulgaria. Association Computational
Linguistics.
Durrett, G., & Klein, D. (2015). Neural CRF Parsing. Proceedings 53rd Annual
Meeting Association Computational Linguistics 7th International
Joint Conference Natural Language Processing (Volume 1: Long Papers), pp. 302
312, Beijing, China. Association Computational Linguistics.
Dyer, C., Ballesteros, M., Ling, W., Matthews, A., & Smith, N. A. (2015). TransitionBased Dependency Parsing Stack Long Short-Term Memory. Proceedings
53rd Annual Meeting Association Computational Linguistics
7th International Joint Conference Natural Language Processing (Volume 1: Long
Papers), pp. 334343, Beijing, China. Association Computational Linguistics.
Elman, J. L. (1990). Finding Structure Time. Cognitive Science, 14 (2), 179211.
Faruqui, M., & Dyer, C. (2014). Improving Vector Space Word Representations Using Multilingual Correlation. Proceedings 14th Conference European Chapter
Association Computational Linguistics, pp. 462471, Gothenburg, Sweden.
Association Computational Linguistics.
Filippova, K., Alfonseca, E., Colmenares, C. A., Kaiser, L., & Vinyals, O. (2015). Sentence
Compression Deletion LSTMs. Proceedings 2015 Conference
Empirical Methods Natural Language Processing, pp. 360368, Lisbon, Portugal.
Association Computational Linguistics.
Forcada, M. L., & Neco, R. P. (1997). Recursive hetero-associative memories translation.
Biological Artificial Computation: Neuroscience Technology, pp. 453
462. Springer.
Gao, J., Pantel, P., Gamon, M., He, X., & Deng, L. (2014). Modeling Interestingness
Deep Neural Networks. Proceedings 2014 Conference Empirical Methods
Natural Language Processing (EMNLP), pp. 213, Doha, Qatar. Association
Computational Linguistics.
Gimenez, J., & Marquez, L. (2004). SVMTool: general POS tagger generator based
Support Vector Machines. Proceedings 4th LREC, Lisbon, Portugal.
Glorot, X., & Bengio, Y. (2010). Understanding difficulty training deep feedforward
neural networks. International conference artificial intelligence statistics,
pp. 249256.
Glorot, X., Bordes, A., & Bengio, Y. (2011). Deep sparse rectifier neural networks.
International Conference Artificial Intelligence Statistics, pp. 315323.
Goldberg, Y., & Elhadad, M. (2010). Efficient Algorithm Easy-First Non-Directional
Dependency Parsing. Human Language Technologies: 2010 Annual Conference
North American Chapter Association Computational Linguistics, pp.
742750, Los Angeles, California. Association Computational Linguistics.
Goldberg, Y., & Levy, O. (2014). word2vec Explained: deriving Mikolov et al.s negativesampling word-embedding method. arXiv:1402.3722 [cs, stat].
410

fiA Primer Neural Networks NLP

Goldberg, Y., & Nivre, J. (2013). Training Deterministic Parsers Non-Deterministic
Oracles. Transactions Association Computational Linguistics, 1 (0), 403
414.
Goldberg, Y., Zhao, K., & Huang, L. (2013). Efficient Implementation Beam-Search
Incremental Parsers. Proceedings 51st Annual Meeting Association
Computational Linguistics (Volume 2: Short Papers), pp. 628633, Sofia, Bulgaria.
Association Computational Linguistics.
Goller, C., & Kuchler, A. (1996). Learning Task-Dependent Distributed Representations
Backpropagation Structure. Proc. ICNN-96, pp. 347352.
IEEE.
Gouws, S., Bengio, Y., & Corrado, G. (2015). BilBOWA: Fast Bilingual Distributed Representations without Word Alignments. Proceedings 32nd International
Conference Machine Learning, pp. 748756.
Graves, A. (2008). Supervised sequence labelling recurrent neural networks. Ph.D.
thesis, Technische Universitat Munchen.
Greff, K., Srivastava, R. K., Koutnk, J., Steunebrink, B. R., & Schmidhuber, J. (2015).
LSTM: Search Space Odyssey. arXiv:1503.04069 [cs].
Hal Daume III, Langford, J., & Marcu, D. (2009). Search-based Structured Prediction.
Machine Learning Journal (MLJ).
Harris, Z. (1954). Distributional Structure. Word, 10 (23), 146162.
Hashimoto, K., Miwa, M., Tsuruoka, Y., & Chikayama, T. (2013). Simple Customization
Recursive Neural Networks Semantic Relation Classification. Proceedings
2013 Conference Empirical Methods Natural Language Processing, pp.
13721376, Seattle, Washington, USA. Association Computational Linguistics.
He, K., Zhang, X., Ren, S., & Sun, J. (2015). Delving Deep Rectifiers: Surpassing
Human-Level Performance ImageNet Classification. arXiv:1502.01852 [cs].
Henderson, M., Thomson, B., & Young, S. (2013). Deep Neural Network Approach
Dialog State Tracking Challenge. Proceedings SIGDIAL 2013 Conference,
pp. 467471, Metz, France. Association Computational Linguistics.
Hermann, K. M., & Blunsom, P. (2013). Role Syntax Vector Space Models
Compositional Semantics. Proceedings 51st Annual Meeting Association Computational Linguistics (Volume 1: Long Papers), pp. 894904, Sofia,
Bulgaria. Association Computational Linguistics.
Hermann, K. M., & Blunsom, P. (2014). Multilingual Models Compositional Distributed
Semantics. Proceedings 52nd Annual Meeting Association Computational Linguistics (Volume 1: Long Papers), pp. 5868, Baltimore, Maryland.
Association Computational Linguistics.
Hihi, S. E., & Bengio, Y. (1996). Hierarchical Recurrent Neural Networks Long-Term
Dependencies. Touretzky, D. S., Mozer, M. C., & Hasselmo, M. E. (Eds.), Advances
Neural Information Processing Systems 8, pp. 493499. MIT Press.
411

fiGoldberg

Hill, F., Cho, K., Jean, S., Devin, C., & Bengio, Y. (2014). Embedding Word Similarity
Neural Machine Translation. arXiv:1412.6448 [cs].
Hinton, G. E., Srivastava, N., Krizhevsky, A., Sutskever, I., & Salakhutdinov, R. R.
(2012). Improving neural networks preventing co-adaptation feature detectors.
arXiv:1207.0580 [cs].
Hochreiter, S., & Schmidhuber, J. (1997). Long short-term memory. Neural computation,
9 (8), 17351780.
Hornik, K., Stinchcombe, M., & White, H. (1989). Multilayer feedforward networks
universal approximators. Neural Networks, 2 (5), 359366.
Ioffe, S., & Szegedy, C. (2015). Batch Normalization: Accelerating Deep Network Training
Reducing Internal Covariate Shift. arXiv:1502.03167 [cs].
Irsoy, O., & Cardie, C. (2014). Opinion Mining Deep Recurrent Neural Networks.
Proceedings 2014 Conference Empirical Methods Natural Language
Processing (EMNLP), pp. 720728, Doha, Qatar. Association Computational Linguistics.
Iyyer, M., Boyd-Graber, J., Claudino, L., Socher, R., & Daume III, H. (2014a). Neural
Network Factoid Question Answering Paragraphs. Proceedings 2014
Conference Empirical Methods Natural Language Processing (EMNLP), pp.
633644, Doha, Qatar. Association Computational Linguistics.
Iyyer, M., Enns, P., Boyd-Graber, J., & Resnik, P. (2014b). Political Ideology Detection
Using Recursive Neural Networks. Proceedings 52nd Annual Meeting
Association Computational Linguistics (Volume 1: Long Papers), pp. 11131122,
Baltimore, Maryland. Association Computational Linguistics.
Iyyer, M., Manjunatha, V., Boyd-Graber, J., & Daume III, H. (2015). Deep Unordered
Composition Rivals Syntactic Methods Text Classification. Proceedings
53rd Annual Meeting Association Computational Linguistics 7th
International Joint Conference Natural Language Processing (Volume 1: Long Papers), pp. 16811691, Beijing, China. Association Computational Linguistics.
Johnson, R., & Zhang, T. (2015). Effective Use Word Order Text Categorization
Convolutional Neural Networks. Proceedings 2015 Conference North
American Chapter Association Computational Linguistics: Human Language Technologies, pp. 103112, Denver, Colorado. Association Computational
Linguistics.
Jozefowicz, R., Vinyals, O., Schuster, M., Shazeer, N., & Wu, Y. (2016). Exploring
Limits Language Modeling. arXiv:1602.02410 [cs].
Jozefowicz, R., Zaremba, W., & Sutskever, I. (2015). Empirical Exploration Recurrent Network Architectures. Proceedings 32nd International Conference
Machine Learning (ICML-15), pp. 23422350.
Kalchbrenner, N., Grefenstette, E., & Blunsom, P. (2014). Convolutional Neural Network
Modelling Sentences. Proceedings 52nd Annual Meeting Association Computational Linguistics (Volume 1: Long Papers), pp. 655665, Baltimore,
Maryland. Association Computational Linguistics.
412

fiA Primer Neural Networks NLP

Karpathy, A., Johnson, J., & Li, F.-F. (2015). Visualizing Understanding Recurrent
Networks. arXiv:1506.02078 [cs].
Kim, Y. (2014). Convolutional Neural Networks Sentence Classification. Proceedings 2014 Conference Empirical Methods Natural Language Processing
(EMNLP), pp. 17461751, Doha, Qatar. Association Computational Linguistics.
Kim, Y., Jernite, Y., Sontag, D., & Rush, A. M. (2015). Character-Aware Neural Language
Models. arXiv:1508.06615 [cs, stat].
Kingma, D., & Ba, J. (2014).
arXiv:1412.6980 [cs].

Adam: Method Stochastic Optimization.

Krizhevsky, A., Sutskever, I., & Hinton, G. E. (2012). ImageNet Classification Deep
Convolutional Neural Networks. Pereira, F., Burges, C. J. C., Bottou, L., & Weinberger, K. Q. (Eds.), Advances Neural Information Processing Systems 25, pp.
10971105. Curran Associates, Inc.
Kudo, T., & Matsumoto, Y. (2003). Fast Methods Kernel-based Text Analysis.
Proceedings 41st Annual Meeting Association Computational Linguistics Volume 1, ACL 03, pp. 2431, Stroudsburg, PA, USA. Association Computational
Linguistics.
Lafferty, J., McCallum, A., & Pereira, F. C. (2001). Conditional random fields: Probabilistic
models segmenting labeling sequence data. Proceedings ICML.
Le, P., & Zuidema, W. (2014). Inside-Outside Recursive Neural Network model
Dependency Parsing. Proceedings 2014 Conference Empirical Methods
Natural Language Processing (EMNLP), pp. 729739, Doha, Qatar. Association
Computational Linguistics.
Le, P., & Zuidema, W. (2015). Forest Convolutional Network: Compositional Distributional Semantics Neural Chart without Binarization. Proceedings
2015 Conference Empirical Methods Natural Language Processing, pp.
11551164, Lisbon, Portugal. Association Computational Linguistics.
Le, Q. V., Jaitly, N., & Hinton, G. E. (2015). Simple Way Initialize Recurrent Networks
Rectified Linear Units. arXiv:1504.00941 [cs].
LeCun, Y., & Bengio, Y. (1995). Convolutional Networks Images, Speech, TimeSeries. Arbib, M. A. (Ed.), Handbook Brain Theory Neural Networks.
MIT Press.
LeCun, Y., Bottou, L., Orr, G., & Muller, K. (1998a). Efficient BackProp. Orr, G., &
K, M. (Eds.), Neural Networks: Tricks trade. Springer.
LeCun, Y., Bottou, L., Bengio, Y., & Haffner, P. (1998b). Gradient Based Learning Applied
Pattern Recognition. Proceedings IEEE, 86 (11), 22782324.
LeCun, Y., Chopra, S., Hadsell, R., Ranzato, M., & Huang, F. (2006). tutorial energybased learning. Predicting structured data, 1, 0.
LeCun, Y., & Huang, F. (2005). Loss functions discriminative training energybased
models. Proceedings AISTATS. AIStats.
413

fiGoldberg

Lee, G., Flowers, M., & Dyer, M. G. (1992). Learning distributed representations conceptual knowledge application script-based story processing. Connectionist
Natural Language Processing, pp. 215247. Springer.
Levy, O., & Goldberg, Y. (2014a). Dependency-Based Word Embeddings. Proceedings
52nd Annual Meeting Association Computational Linguistics (Volume
2: Short Papers), pp. 302308, Baltimore, Maryland. Association Computational
Linguistics.
Levy, O., & Goldberg, Y. (2014b). Neural Word Embedding Implicit Matrix Factorization. Ghahramani, Z., Welling, M., Cortes, C., Lawrence, N. D., & Weinberger,
K. Q. (Eds.), Advances Neural Information Processing Systems 27, pp. 21772185.
Curran Associates, Inc.
Levy, O., Goldberg, Y., & Dagan, I. (2015). Improving Distributional Similarity
Lessons Learned Word Embeddings. Transactions Association Computational Linguistics, 3 (0), 211225.
Lewis, M., & Steedman, M. (2014). Improved CCG Parsing Semi-supervised Supertagging. Transactions Association Computational Linguistics, 2 (0), 327338.
Li, J., Li, R., & Hovy, E. (2014). Recursive Deep Models Discourse Parsing. Proceedings 2014 Conference Empirical Methods Natural Language Processing
(EMNLP), pp. 20612069, Doha, Qatar. Association Computational Linguistics.
Ling, W., Dyer, C., Black, A. W., & Trancoso, I. (2015a). Two/Too Simple Adaptations
Word2Vec Syntax Problems. Proceedings 2015 Conference North
American Chapter Association Computational Linguistics: Human Language Technologies, pp. 12991304, Denver, Colorado. Association Computational
Linguistics.
Ling, W., Dyer, C., Black, A. W., Trancoso, I., Fermandez, R., Amir, S., Marujo, L., &
Luis, T. (2015b). Finding Function Form: Compositional Character Models
Open Vocabulary Word Representation. Proceedings 2015 Conference
Empirical Methods Natural Language Processing, pp. 15201530, Lisbon, Portugal.
Association Computational Linguistics.
Liu, Y., Wei, F., Li, S., Ji, H., Zhou, M., & Wang, H. (2015). Dependency-Based Neural
Network Relation Classification. Proceedings 53rd Annual Meeting
Association Computational Linguistics 7th International Joint Conference Natural Language Processing (Volume 2: Short Papers), pp. 285290, Beijing,
China. Association Computational Linguistics.
Luong, M.-T., Le, Q. V., Sutskever, I., Vinyals, O., & Kaiser, L. (2015). Multi-task Sequence
Sequence Learning. arXiv:1511.06114 [cs, stat].
Ma, J., Zhang, Y., & Zhu, J. (2014). Tagging Web: Building Robust Web Tagger
Neural Network. Proceedings 52nd Annual Meeting Association Computational Linguistics (Volume 1: Long Papers), pp. 144154, Baltimore,
Maryland. Association Computational Linguistics.
Ma, M., Huang, L., Zhou, B., & Xiang, B. (2015). Dependency-based Convolutional Neural
Networks Sentence Embedding. Proceedings 53rd Annual Meeting
414

fiA Primer Neural Networks NLP

Association Computational Linguistics 7th International Joint Conference Natural Language Processing (Volume 2: Short Papers), pp. 174179, Beijing,
China. Association Computational Linguistics.
McCallum, A., Freitag, D., & Pereira, F. C. (2000). Maximum Entropy Markov Models
Information Extraction Segmentation.. ICML, Vol. 17, pp. 591598.
Mikolov, T., Chen, K., Corrado, G., & Dean, J. (2013). Efficient Estimation Word
Representations Vector Space. arXiv:1301.3781 [cs].
Mikolov, T., Joulin, A., Chopra, S., Mathieu, M., & Ranzato, M. (2014). Learning Longer
Memory Recurrent Neural Networks. arXiv:1412.7753 [cs].
Mikolov, T., Karafiat, M., Burget, L., Cernocky, J., & Khudanpur, S. (2010). Recurrent
neural network based language model.. INTERSPEECH 2010, 11th Annual Conference International Speech Communication Association, Makuhari, Chiba,
Japan, September 26-30, 2010, pp. 10451048.
Mikolov, T., Kombrink, S., Lukas Burget, Cernocky, J. H., & Khudanpur, S. (2011). Extensions recurrent neural network language model. Acoustics, Speech Signal
Processing (ICASSP), 2011 IEEE International Conference on, pp. 55285531. IEEE.
Mikolov, T., Sutskever, I., Chen, K., Corrado, G. S., & Dean, J. (2013). Distributed Representations Words Phrases Compositionality. Burges, C. J. C.,
Bottou, L., Welling, M., Ghahramani, Z., & Weinberger, K. Q. (Eds.), Advances
Neural Information Processing Systems 26, pp. 31113119. Curran Associates, Inc.
Mikolov, T. (2012). Statistical language models based neural networks. Ph.D. thesis, Ph.
D. thesis, Brno University Technology.
Mnih, A., & Kavukcuoglu, K. (2013). Learning word embeddings efficiently noisecontrastive estimation. Burges, C. J. C., Bottou, L., Welling, M., Ghahramani, Z.,
& Weinberger, K. Q. (Eds.), Advances Neural Information Processing Systems 26,
pp. 22652273. Curran Associates, Inc.
Mrksic, N., Seaghdha, D., Thomson, B., Gasic, M., Su, P.-H., Vandyke, D., Wen, T.-H.,
& Young, S. (2015). Multi-domain Dialog State Tracking using Recurrent Neural
Networks. Proceedings 53rd Annual Meeting Association Computational Linguistics 7th International Joint Conference Natural Language
Processing (Volume 2: Short Papers), pp. 794799, Beijing, China. Association
Computational Linguistics.
Neidinger, R. (2010). Introduction Automatic Differentiation MATLAB ObjectOriented Programming. SIAM Review, 52 (3), 545563.
Nesterov, Y. (1983). method solving convex programming problem convergence
rate (1/k2). Soviet Mathematics Doklady, Vol. 27, pp. 372376.
Nesterov, Y. (2004). Introductory lectures convex optimization. Kluwer Academic Publishers.
Nguyen, T. H., & Grishman, R. (2015). Event Detection Domain Adaptation
Convolutional Neural Networks. Proceedings 53rd Annual Meeting
415

fiGoldberg

Association Computational Linguistics 7th International Joint Conference Natural Language Processing (Volume 2: Short Papers), pp. 365371, Beijing,
China. Association Computational Linguistics.
Nivre, J. (2008). Algorithms Deterministic Incremental Dependency Parsing. Computational Linguistics, 34 (4), 513553.
Okasaki, C. (1999). Purely Functional Data Structures. Cambridge University Press, Cambridge, U.K.; New York.
Olah, C. (2015a). Calculus Computational Graphs: Backpropagation. Retrieved
http://colah.github.io/posts/2015-08-Backprop/.
Olah, C. (2015b). Understanding LSTM Networks. Retrieved http://colah.
github.io/posts/2015-08-Understanding-LSTMs/.
Pascanu, R., Mikolov, T., & Bengio, Y. (2012). difficulty training Recurrent
Neural Networks. arXiv:1211.5063 [cs].
Pei, W., Ge, T., & Chang, B. (2015). Effective Neural Network Model Graph-based
Dependency Parsing. Proceedings 53rd Annual Meeting Association
Computational Linguistics 7th International Joint Conference Natural
Language Processing (Volume 1: Long Papers), pp. 313322, Beijing, China. Association Computational Linguistics.
Peng, J., Bo, L., & Xu, J. (2009). Conditional Neural Fields. Bengio, Y., Schuurmans,
D., Lafferty, J. D., Williams, C. K. I., & Culotta, A. (Eds.), Advances Neural
Information Processing Systems 22, pp. 14191427. Curran Associates, Inc.
Pennington, J., Socher, R., & Manning, C. (2014). Glove: Global Vectors Word Representation. Proceedings 2014 Conference Empirical Methods Natural
Language Processing (EMNLP), pp. 15321543, Doha, Qatar. Association Computational Linguistics.
Pollack, J. B. (1990). Recursive Distributed Representations. Artificial Intelligence, 46,
77105.
Polyak, B. T. (1964). methods speeding convergence iteration methods.
USSR Computational Mathematics Mathematical Physics, 4 (5), 1 17.
Qian, Q., Tian, B., Huang, M., Liu, Y., Zhu, X., & Zhu, X. (2015). Learning Tag Embeddings
Tag-specific Composition Functions Recursive Neural Network. Proceedings
53rd Annual Meeting Association Computational Linguistics
7th International Joint Conference Natural Language Processing (Volume 1: Long
Papers), pp. 13651374, Beijing, China. Association Computational Linguistics.
Rong, X. (2014). word2vec Parameter Learning Explained. arXiv:1411.2738 [cs].
Rumelhart, D. E., Hinton, G. E., & Williams, R. J. (1986). Learning representations
back-propagating errors. Nature, 323 (6088), 533536.
Schuster, M., & Paliwal, K. K. (1997). Bidirectional recurrent neural networks. IEEE
Transactions Signal Processing, 45 (11), 26732681.
416

fiA Primer Neural Networks NLP

Schwenk, H., Dchelotte, D., & Gauvain, J.-L. (2006). Continuous space language models
statistical machine translation. Proceedings COLING/ACL Main
conference poster sessions, pp. 723730. Association Computational Linguistics.
Shawe-Taylor, J., & Cristianini, N. (2004). Kernel Methods Pattern Analysis. Cambridge
University Press.
Smith, N. A. (2011). Linguistic Structure Prediction. Synthesis Lectures Human Language Technologies. Morgan Claypool.
Socher, R. (2014). Recursive Deep Learning Natural Language Processing Computer
Vision. Ph.D. thesis, Stanford University.
Socher, R., Bauer, J., Manning, C. D., & Ng, A. Y. (2013). Parsing Compositional
Vector Grammars. Proceedings 51st Annual Meeting Association
Computational Linguistics (Volume 1: Long Papers), pp. 455465, Sofia, Bulgaria.
Association Computational Linguistics.
Socher, R., Huval, B., Manning, C. D., & Ng, A. Y. (2012). Semantic Compositionality
Recursive Matrix-Vector Spaces. Proceedings 2012 Joint Conference
Empirical Methods Natural Language Processing Computational Natural
Language Learning, pp. 12011211, Jeju Island, Korea. Association Computational
Linguistics.
Socher, R., Lin, C. C.-Y., Ng, A. Y., & Manning, C. D. (2011). Parsing Natural Scenes
Natural Language Recursive Neural Networks. Getoor, L., & Scheffer, T.
(Eds.), Proceedings 28th International Conference Machine Learning, ICML
2011, Bellevue, Washington, USA, June 28 - July 2, 2011, pp. 129136. Omnipress.
Socher, R., Manning, C., & Ng, A. (2010). Learning Continuous Phrase Representations
Syntactic Parsing Recursive Neural Networks. Proceedings Deep
Learning Unsupervised Feature Learning Workshop {NIPS} 2010, pp. 19.

Socher, R., Perelygin, A., Wu, J., Chuang, J., Manning, C. D., Ng, A., & Potts, C. (2013).
Recursive Deep Models Semantic Compositionality Sentiment Treebank.
Proceedings 2013 Conference Empirical Methods Natural Language
Processing, pp. 16311642, Seattle, Washington, USA. Association Computational
Linguistics.
Sgaard, A., & Goldberg, Y. (2016). Deep multi-task learning low level tasks supervised
lower layers. Proceedings 54th Annual Meeting Association
Computational Linguistics (Volume 2: Short Papers), pp. 231235. Association
Computational Linguistics.
Sordoni, A., Galley, M., Auli, M., Brockett, C., Ji, Y., Mitchell, M., Nie, J.-Y., Gao, J.,
& Dolan, B. (2015). Neural Network Approach Context-Sensitive Generation
Conversational Responses. Proceedings 2015 Conference North
American Chapter Association Computational Linguistics: Human Language Technologies, pp. 196205, Denver, Colorado. Association Computational
Linguistics.
Sundermeyer, M., Alkhouli, T., Wuebker, J., & Ney, H. (2014). Translation Modeling
Bidirectional Recurrent Neural Networks. Proceedings 2014 Conference
417

fiGoldberg

Empirical Methods Natural Language Processing (EMNLP), pp. 1425, Doha,
Qatar. Association Computational Linguistics.
Sundermeyer, M., Schluter, R., & Ney, H. (2012). LSTM Neural Networks Language
Modeling.. INTERSPEECH.
Sutskever, I., Martens, J., Dahl, G., & Hinton, G. (2013). importance initialization
momentum deep learning. Proceedings 30th international conference
machine learning (ICML-13), pp. 11391147.
Sutskever, I., Martens, J., & Hinton, G. E. (2011). Generating text recurrent neural
networks. Proceedings 28th International Conference Machine Learning
(ICML-11), pp. 10171024.
Sutskever, I., Vinyals, O., & Le, Q. V. V. (2014). Sequence Sequence Learning
Neural Networks. Ghahramani, Z., Welling, M., Cortes, C., Lawrence, N. D., &
Weinberger, K. Q. (Eds.), Advances Neural Information Processing Systems 27, pp.
31043112. Curran Associates, Inc.
Tai, K. S., Socher, R., & Manning, C. D. (2015). Improved Semantic Representations
Tree-Structured Long Short-Term Memory Networks. Proceedings 53rd Annual Meeting Association Computational Linguistics 7th International Joint Conference Natural Language Processing (Volume 1: Long Papers),
pp. 15561566, Beijing, China. Association Computational Linguistics.
Tamura, A., Watanabe, T., & Sumita, E. (2014). Recurrent Neural Networks Word
Alignment Model. Proceedings 52nd Annual Meeting Association
Computational Linguistics (Volume 1: Long Papers), pp. 14701480, Baltimore,
Maryland. Association Computational Linguistics.
Telgarsky, M. (2016). Benefits depth neural networks. arXiv:1602.04485 [cs, stat].
Tieleman, T., & Hinton, G. (2012). Lecture 6.5RmsProp: Divide gradient running
average recent magnitude. COURSERA: Neural Networks Machine Learning.
Van de Cruys, T. (2014). Neural Network Approach Selectional Preference Acquisition. Proceedings 2014 Conference Empirical Methods Natural Language Processing (EMNLP), pp. 2635, Doha, Qatar. Association Computational
Linguistics.
Vaswani, A., Zhao, Y., Fossum, V., & Chiang, D. (2013). Decoding Large-Scale Neural Language Models Improves Translation. Proceedings 2013 Conference
Empirical Methods Natural Language Processing, pp. 13871392, Seattle, Washington, USA. Association Computational Linguistics.
Wager, S., Wang, S., & Liang, P. S. (2013). Dropout Training Adaptive Regularization.
Burges, C. J. C., Bottou, L., Welling, M., Ghahramani, Z., & Weinberger, K. Q.
(Eds.), Advances Neural Information Processing Systems 26, pp. 351359. Curran
Associates, Inc.
Wang, M., & Manning, C. D. (2013). Effect Non-linear Deep Architecture Sequence
Labeling.. IJCNLP, pp. 12851291.
418

fiA Primer Neural Networks NLP

Wang, P., Xu, J., Xu, B., Liu, C., Zhang, H., Wang, F., & Hao, H. (2015a). Semantic Clustering Convolutional Neural Network Short Text Categorization. Proceedings
53rd Annual Meeting Association Computational Linguistics
7th International Joint Conference Natural Language Processing (Volume 2: Short
Papers), pp. 352357, Beijing, China. Association Computational Linguistics.
Wang, X., Liu, Y., Sun, C., Wang, B., & Wang, X. (2015b). Predicting Polarities Tweets
Composing Word Embeddings Long Short-Term Memory. Proceedings
53rd Annual Meeting Association Computational Linguistics
7th International Joint Conference Natural Language Processing (Volume 1: Long
Papers), pp. 13431353, Beijing, China. Association Computational Linguistics.
Watanabe, T., & Sumita, E. (2015). Transition-based Neural Constituent Parsing. Proceedings 53rd Annual Meeting Association Computational Linguistics
7th International Joint Conference Natural Language Processing (Volume
1: Long Papers), pp. 11691179, Beijing, China. Association Computational Linguistics.
Weiss, D., Alberti, C., Collins, M., & Petrov, S. (2015). Structured Training Neural
Network Transition-Based Parsing. Proceedings 53rd Annual Meeting
Association Computational Linguistics 7th International Joint Conference Natural Language Processing (Volume 1: Long Papers), pp. 323333, Beijing,
China. Association Computational Linguistics.
Werbos, P. J. (1990). Backpropagation time: it..
Proceedings IEEE, 78 (10), 1550 1560.
Weston, J., Bordes, A., Yakhnenko, O., & Usunier, N. (2013). Connecting Language
Knowledge Bases Embedding Models Relation Extraction. Proceedings
2013 Conference Empirical Methods Natural Language Processing, pp.
13661371, Seattle, Washington, USA. Association Computational Linguistics.
Xu, W., Auli, M., & Clark, S. (2015). CCG Supertagging Recurrent Neural Network.
Proceedings 53rd Annual Meeting Association Computational Linguistics 7th International Joint Conference Natural Language Processing
(Volume 2: Short Papers), pp. 250255, Beijing, China. Association Computational
Linguistics.
Yin, W., & Schutze, H. (2015). Convolutional Neural Network Paraphrase Identification.
Proceedings 2015 Conference North American Chapter Association Computational Linguistics: Human Language Technologies, pp. 901911,
Denver, Colorado. Association Computational Linguistics.
Zaremba, W., Sutskever, I., & Vinyals, O. (2014). Recurrent Neural Network Regularization.
arXiv:1409.2329 [cs].
Zeiler, M. D. (2012). ADADELTA: Adaptive Learning Rate Method. arXiv:1212.5701
[cs].
Zeng, D., Liu, K., Lai, S., Zhou, G., & Zhao, J. (2014). Relation Classification via Convolutional Deep Neural Network. Proceedings COLING 2014, 25th International
419

fiGoldberg

Conference Computational Linguistics: Technical Papers, pp. 23352344, Dublin,
Ireland. Dublin City University Association Computational Linguistics.
Zhang, Y., & Weiss, D. (2016). Stack-propagation: Improved representation learning syntax. Proceedings 54th Annual Meeting Association Computational
Linguistics (Volume 1: Long Papers), pp. 15571566. Association Computational
Linguistics.
Zhou, H., Zhang, Y., Huang, S., & Chen, J. (2015). Neural Probabilistic StructuredPrediction Model Transition-Based Dependency Parsing. Proceedings
53rd Annual Meeting Association Computational Linguistics 7th
International Joint Conference Natural Language Processing (Volume 1: Long Papers), pp. 12131222, Beijing, China. Association Computational Linguistics.
Zhu, C., Qiu, X., Chen, X., & Huang, X. (2015a). Re-ranking Model Dependency
Parser Recursive Convolutional Neural Network. Proceedings 53rd
Annual Meeting Association Computational Linguistics 7th International Joint Conference Natural Language Processing (Volume 1: Long Papers),
pp. 11591168, Beijing, China. Association Computational Linguistics.
Zhu, X., Sobhani, P., & Guo, H. (2015b). Long Short-Term Memory Tree Structures.
arXiv:1503.04881 [cs].

420

fiJournal Artificial Intelligence Research 57 (2016) 113-149

Submitted 03/16; published 09/16

Optimal Partial-Order Plan Relaxation via MaxSAT
Christian Muise

cjmuise@cs.toronto.edu

Department Computer Science,
Toronto, Ontario, Canada. M5S 3G4

J. Christopher Beck

jcb@mie.utoronto.ca

Department Mechanical & Industrial Engineering
Toronto, Ontario, Canada. M5S 3G8

Sheila A. McIlraith

sheila@cs.toronto.edu

Department Computer Science,
Toronto, Ontario, Canada. M5S 3G4

Abstract
Partial-order plans (POPs) attractive least-commitment nature,
provides enhanced plan flexibility execution time relative sequential plans. Current research automated plan generation focuses producing sequential plans, despite
appeal POPs. paper examine POP generation relaxing modifying
action orderings sequential plan optimize plan criteria promote flexibility. approach relies novel partial weighted MaxSAT encoding sequential
plan supports minimization deordering reordering actions. Using similar
technique, demonstrate remove redundant actions plan,
combine criterion objective maximizing POPs flexibility.
partial weighted MaxSAT encoding allows us compute POP sequential plan
effectively. compare efficiency approach previous methods POP generation via sequential-plan relaxation. results show existing heuristic
approach consistently produces optimal deordering sequential plan, approach
greater flexibility consider reordering actions plan also providing guarantee optimality. also investigate confirm accuracy
standard flex metric typically used predict true flexibility POP measured
number linearizations represents.

1. Introduction
agent operate effectively dynamic world, behaviour must flexible
face unexpected changes. context AI planning, several approaches
increase flexibility agent, including giving option select different
plans (Graham, Decker, & Mersic, 2001) expanding applicability existing plans
plan generalization (Anderson & Farley, 1988). One example former
delay committing ordering certain actions plan absolutely necessary,
allowing agent dynamically choose plan proceeds execution time (Veloso,
Pollack, & Cox, 1998). flexibility precisely partial-order plans provide.
Partial-order planning reflects least commitment strategy (Weld, 1994). Unlike
sequential plan, specifies set actions total order actions,
ideal partial-order plan (POP) specifies action orderings necessary achieve
goal. so, POP embodies family sequential plans set linearizations
c
2016
AI Access Foundation. rights reserved.

fiMuise, Beck, & McIlraith

sharing actions, differing respect order actions.
execution, agent free choose next action execute plan long
chosen action preceding actions left execute. Increasing number
linearizations plan translates directly giving agent freedom execution
time. Thus, typically use number linearizations POP measure
flexibility. measure POPs linearizations perfect, quite useful
proxy plans flexibility.
flexibility afforded POPs makes attractive real-time execution, multiagent task assignment, range applications (Veloso et al., 1998; Weld, 1994).
Nevertheless, recent years research plan generation shifted away partial-order
planning towards sequential planning, primarily due effectiveness heuristic-based
forward-search planners. regain least commitment nature POPs, leveraging
fast sequential plan generation, compelling examine computation POPs via
sequential planning technology done, example, forward-chaining partial-order
planner POPF (Coles, Coles, Fox, & Long, 2010).
paper, present alternative approach first generates sequential plan
state-of-the-art planner, subsequently relaxes plan minimally constrained POP. Deordering process removing ordering constraints plan
reordering process allowing arbitrary change ordering constraints;
requiring POP remains valid. POP deordering reordering theoretically investigated (Backstrom, 1998), unfortunately optimal deordering reordering NP-hard compute difficult approximate within constant factor (unless
N P DT IM E(npoly log n ), Backstrom, 1998). Despite theoretical impediment,
find practice often compute optimal solution.
minimum deordering minimum reordering sequential plan cover natural
aspect least commitment planning minimizing ordering constraints placed plan.
Intuitively, deordering involves removing existing ordering constraints reordering
allows ordering constraints removed well new ordering constraints
included. techniques naturally provide greater flexibility execution time,
inverse correlation number ordering constraints number
linearizations POP. Reordering may achieve greater flexibility deordering
addition new constraint may allow number existing ordering constraints
removed still guaranteeing POP validity.
approach computing optimally relaxed POP use family novel encodings partial weighted MaxSAT: optimal solution MaxSAT problem corresponds
optimally relaxed POP. Unlike typical SAT-based planning techniques, represent
action instance once, giving us succinct representation. empirically compare
approach existing polynomial-time heuristic relaxing sequential plan due
Kambhampati Kedar (1994) find latter extremely proficient computing minimum deordering, matching optimal solution every problem tested. find,
however, minimum reordering substantially flexible minimum
deordering, fewer ordering constraints far linearizations.
also compare efficiency technique related approach uses
Mixed Integer Linear Programming encoding compute minimum reordering (Do &
Kambhampati, 2003) find approach consistently performs better problems
114

fiOptimal Partial-Order Plan Relaxation via MaxSAT

non-trivial size. approach represents practical technique computing guaranteed
optimal deordering reordering POP.
Using modern MaxSAT solver compute maximally flexible solutions provides two
key benefits: (1) solver used any-time procedure computes optimally flexible reordering POP given enough time (where technique previously
existed), (2) computing optimal deordering POP allows us evaluate
efficiency existing heuristic algorithm.
1.1 Removing Redundant Actions
generality encoding allows us easily define alternative objectives optimization
criteria. demonstrate key aspect generality, extend characterization
orthogonal metric: minimizing total cost actions plan via removal
unnecessary actions. metric commonly used measure plan quality,
interestingly directly odds task improving plans flexibility. Here,
consider one option combining two metrics puts higher priority action
cost subsequent plan flexibility.
majority encodings, theoretical foundations, theorems presented
paper apply general class problems incorporates metrics. refer
POP minimum action cost (over actions POP), subsequently
minimum number ordering constraints, minimum cost least commitment POP
(MCLCP).1 MCLCP compelling free redundant actions well
redundant ordering constraints: MCLCP contains relevant achieve
goal.
present theoretical aspects general MCLCP criterion,
main focus maximizing flexibility POPs, focus experimental evaluation
deorderings reorderings exclusively. leave evaluation method
solving MCLCP compared plan repair techniques (e.g., Nebel & Koehler, 1995;
Gerevini & Serina, 2000) matter future work.
1.2 Contributions
following main contributions paper:
introduce practical method computing optimal deordering reordering plan. accomplish set novel partial-weighted MaxSAT
encodings, differing set clause schema define type relaxation desire. model encodings standard partial-order planning concepts, causal
support threat resolution, draw upon prove correctness
encodings.
propose extension least commitment planning, MCLCP, includes
total cost solution. optimization focuses first minimizing total action
cost minimizing number ordering constraints included plan.
1. Note minimizing total action cost uniform cost domain equivalent minimizing
number actions.

115

fiMuise, Beck, & McIlraith

prove correctness approach uses partial weighted MaxSAT
encoding computing MCLCP.
demonstrate, somewhat surprisingly, existing heuristic extremely proficient computing optimal deorderings. existing algorithm produces deorderings, theoretically guaranteed find minimal, let alone optimal,
deordering. Nonetheless, find empirically heuristic computes optimal
deordering every instance suite benchmarks.
demonstrate efficiency approach compared previous method
uses similar encoding different optimization framework. problems
relatively difficult relax (i.e., take second compute), approach
improves previous work solving 22% problems within given
time bound.
establish empirical connection number linearizations POP
standard flex measure, captures normalized measure number
ordering constraints.
demonstrate impact starting solution form final
relaxed plan. particular, consider using two types layered plans
produced Mp POPF planners (Rintanen, 2012; Coles et al., 2010).
show achieve greater flexibility, compared optimal deordering,
using optimal reordering. result justifies need approach
compute flexible plan.
work paper extends conference publications Muise, McIlraith,
Beck (2011, 2012). provide full generality using MCLCP base
encoding, paper focus evaluation minimum deordering reordering
aspects. expanded theoretical framework approach, including proofs
correctness, significantly expanded empirical evaluation.
1.3 Organization
start providing, Section 2, necessary background notation automated
planning partial weighted MaxSAT. Next, detail approach Section 3, including
new MCLCP criterion Section 3.1 family encodings various
optimization criteria Section 3.2. Finally, present evaluation Section 4
conclude discussion related work summary Section 5.

2. Preliminaries
section, present necessary background notation concepts work.
2.1 Classical Planning
Planning task synthesizing solution dictates actions agent must
take order achieve prescribed goal. classical planning, assume world
116

fiOptimal Partial-Order Plan Relaxation via MaxSAT

fully known deterministic (Russell & Norvig, 2009). Classical planning many
applications range robotics modelling biological processes (Ghallab, Nau, &
Traverso, 2004). standard approach synthesizing classical plan perform
search state space problem, using heuristics guide planner towards
high quality solution. Here, describe common formalism used specifying
planning problem: STRIPS (Fikes, Hart, & Nilsson, 1972).
STRIPS, planning problem tuple = hF, I, G, Ai F finite set
fluents, F initial state, G F goal state, finite set
actions. characterize action following three sets:
P RE(a): fluents must true order executable.
ADD(a): fluents action adds state.
DEL(a): fluents action deletes state.
work, actions instantaneous adopt standard model interleaved concurrency: two actions occur simultaneously. such, make
simplifying assumption every action a, ADD(a) DEL(a) = . done
without loss generality, simplifies theoretical results below.
say action executable state iff P RE(a) s. resulting state
executing action state defined as:
(
(s \ DEL(a)) ADD(a)
executable
def
P(s, a) =
undefined
otherwise
planning problem = hF, I, G, Ai, associate cost function c maps
every action non-negative real number: c : R+
0.
make use two items notation respect set actions A:
adders(f ): set actions add fluent f :
{a | f ADD(a)}
deleters(f ): set actions delete fluent f :
{a | f DEL(a)}
common representation solution planning problem sequential
plan. sequence actions ~a = [a1 , , ] executable preconditions action
sequence true corresponding state, executable sequence actions
sequential plan problem = hF, I, G, Ai executing actions ~a sequence,
starting state I, causes goal hold final state:
G P(P( P(I, a1 ) , an1 ), )
117

fiMuise, Beck, & McIlraith

readability, abbreviate progression sequential plan ~a state
P (s, ~a ). cost action sequence ~a = [a1 , . . . , ] sum individual
actions costs:
n
X
c (~a ) =
c (ai )
i=1

Rather impose total order actions plan, partial-order plan (POP)
specifies set ordering constraints actions. define POP respect
planning problem tuple hA, Oi set actions plan
set ordering constraints actions (Russell & Norvig, 2009).
action may appear A, assume every element
uniquely identifiable. actions a1 , a2 A, denote ordering constraint
a1 a2 (a1 a2 ) interpret constraint action a1 appears action
a2 plan. total ordering actions respects linearization.
POP provides compact representation multiple linearizations. assume ordering
constraints transitively closed:
a1 , a2 , a3 A, (a1 a2 ) (a2 a3 ) (a1 a3 )
Assuming transitively closed change fundamental structure
POP set linearizations remains allows us effectively compare
flexibility two POPs share action set.
Similar cost action sequence, cost POP P = hA, Oi sum
action costs actions P :
X
c (P ) =
c (a)
aA

simplify exposition follows, designate two actions POP
represent initial state goal state: aI aG respectively. aI ordered
every action, aG analogously ordered every action. planning
problem = hF, I, G, Ai, actions following definition:
P RE(aI ) =

P RE(aG ) = G

ADD(aI ) =

ADD(aG ) =

DEL(aI ) =

DEL(aG ) =

inclusion aI aG actions allow us simplify presentation many algorithms,
avoiding special checks procedure (e.g., assume always
first last action POP).
Depending POP constructed, may include set causal links, C.
causal link contains pair ordered actions, a1 , a2 (a1 may aI a2 may aG ),
p
fluent, p, a1 achieves p a2 : denoted (a1 a2 ). Causal links often
serve justifications ordering constraints POP.
Definition 1 (POP Validity: Notion 1). POP P valid planning problem
every linearization P sequential plan .2
2. Note notion 1 rely set causal links C.

118

fiOptimal Partial-Order Plan Relaxation via MaxSAT

simple intuitive, notion 1 rarely used verify validity POP
may prohibitively large number linearizations represented POP.
is, however, tractable equivalent notion POP validity uses concepts causal
links, open preconditions threats.
POP hA, Oi set causal links C, open precondition precondition p
action associated causal link:
p

@a0 s.t. (a0 a) C
precondition open, say supported, refer associated
action causal link achiever precondition. typical valid POP
one supporter every precondition action included POP,
make restriction work keep encoding general.
threat POP refers action invalidate causal link two
p
actions due ordering constraints (or lack thereof). Formally, (a1 a2 ) C,
p
say action a3 (distinct a1 a2 ) threatens causal link (a1 a2 )
following two conditions hold:
order a3 a1 a2 :
{(a3 a1 ), (a2 a3 )} =
action a3 deletes p:
p DEL(a3 )
existence threat means linearization exists violates causal
link, thus may executable. actions aI aG included,
following definition characterizes second notion POP validity.
Definition 2 (POP Validity: Notion 2). Given planning problem , POP P = hA, Oi
set causal links C, P valid POP planning problem action
open precondition causal link set C threatening action A.
causal link structure implicitly assessed verify POP validity polynomial
time (Nebel & Backstrom, 1994), set C strictly necessary. However, implicitly
explicitly, notion 2 requires actions causally supported threat-free manner.
subsequently following connection two notions POP validity:
Theorem 1 (POP Validity, due McAllester & Rosenblitt, 1991). notion 2 POP
validity holds, notion 1 also holds. Additionally, notion 1 holds O,
set causal links C must exist notion 2 holds hA, Oi C.
final concept use POP based well-established metric measuring
constrained POP (Nguyen & Kambhampati, 2001; Siddiqui & Haslum, 2012): flex
measure many ordering constraints POP, normalized total
number potential ordering constraints. flex tends 1 number ordering
constraints tends 0, vice versa. per usual, assume set ordering
constraints transitively closed.
119

fiMuise, Beck, & McIlraith

Definition 3 (flex ). Given POP hA, Oi, define flex as,
|O|
flex (hA, Oi) = 1 P|A|1
i=1



P|A|1
use i=1 denominator instead traditional |A|2 latter
counts number possible ordering constraints. definition flex , fully
unordered POP flex value 1 sequential plan flex 0.
strive minimize number ordering constraints transitive closure.
Omitting transitive closure would amount optimizing transitive reduction
which, noted Backstrom (1998), less appeal leads long chains
plan.
2.2 Deorderings Reorderings
aim least commitment planning find flexible plans allow us defer decisions
regarding execution plan. Considering ordering constraints POP,
two important notions least commitment planning deordering reordering
POP. Following Backstrom (1998), define formally follows:
0

0

Definition 4 (Deordering Reordering). Let P = hA, Oi Q = hA , two
POPs, STRIPS planning problem:
1. Q deordering P wrt. iff P Q valid POPs , = A0 , O0 O.
2. Q reordering P wrt. iff P Q valid POPs , = A0 .
Recall assume ordering constraints POP transitively closed,
every action POP uniquely named (i.e., every repetition action given
unique name). proper deordering one ordering constraints form proper
subset (i.e., O0 ( O). define minimum deordering / reordering follows:
0

0

Definition 5 (Minimum Deorderings Reorderings). Let P = hA, Oi Q = hA ,
two POPs, STRIPS planning problem:
1. Q minimum deordering P wrt. iff
(a) Q deordering P wrt. ,
00

00

(b) deordering hA , P wrt. s.t. |O00 | < |O0 |.
2. Q minimum reordering P wrt. iff
(a) Q reordering P wrt. ,
00

00

(b) reordering hA , P wrt. s.t. |O00 | < |O0 |.
3. Q minimal deordering P wrt. iff
(a) Q deordering P wrt. ,
(b) proper deordering Q.
120

fiOptimal Partial-Order Plan Relaxation via MaxSAT

Note use cardinality rather set containment 1(b) 2(b)
orderings O0 O00 need overlap. equivalently refer minimum deordering
(resp. reordering) optimal deordering (resp. reordering). cases, prefer
POP smallest set ordering constraints. words, POP exists
actions fewer ordering constraints remaining valid respect
. problem finding minimum deordering reordering POP NP-hard,
cannot approximated within constant factor unless N P DTIME(npoly log n )
(Backstrom, 1998). may many optimal deorderings reorderings,
work distinguish further. compute minimal deordering
polynomial time iteratively removing unnecessary ordering constraints (i.e.,
cause plan become invalid).
2.3 Previous Approaches
many approaches computing partial-order plan, cover
representative examples here.
2.3.1 Partial-Order Causal Link Algorithms
Traditional methods producing partial-order plan follow approach called partialorder causal link (POCL) planning (Weld, 1994). POCL planning, modifications
iteratively made incomplete partial-order plan consists set actions, causal
links, ordering constraints. partial-order plan considered complete
conditions Definition 2 met.
key difference POCL planning standard state-based search
POCL planning search plan space. POCL planning search, every node
search space constitutes partial plan, whereas state-based search every node state
world; successor nodes generated applying actions state represented
current search node. contrast, possible modifications partial plan represent
choices available POCL planning search procedure. typical partial plan
modifications include:
1. Add new action partial plan.
2. Order two actions partial plan.
3. Create causal link two actions plan.
POCL planners popular late 1970s, 1980s, 1990s, starting Tates
NONLIN planner (Tate, 1976), forward search techniques one employed
FF planner (Hoffmann & Nebel, 2001) led planning research new direction.
recent POCL planner VHPOP (Younes & Simmons, 2003), unfortunately
competitive state-of-the-art forward search planners.
2.3.2 POPF
take advantage flexibility afforded POP search efficiency forward
state-based planners, Coles et al. introduced forward-chaining partial-order planner
121

fiMuise, Beck, & McIlraith

POPF (Coles et al., 2010). idea behind POPF restrict modifications permitted
partially completed plan complete state easily computed
represents truth fluents partial plan executed. Unlike POCL approaches
add actions achieve open preconditions, actions POPF chosen
preconditions satisfied heuristically lead goal (i.e., forward-search
manner). new action added plan, placed end plan
action already incumbent plan ordered newly added action
time insertion, new action may left unordered respect actions
already plan. Further, adding new action requires preconditions
causal links created immediately.
approach used POPF leverages partial-order nature planning domains
avoiding unnecessary reasoning permutations unordered actions; ordering constraints included required. Sequential planners may try
complete partial-order plan multiple times change different
permutation unordered actions, POPF avoid situation time
maintaining partial-order structure. Further, using recently introduced techniques
detect repeated states (Coles & Coles, 2016), planner avoids even unnecessary
permutations action sequences.
Finally, POPF leverages powerful techniques forward-search planners maintaining complete state world reached plan. state
information allows powerful heuristics computed efficiently.
2.3.3 Petri Net Unfolding
Predating work Coles et al. (2010), alternative approach generating partially
ordered plans via Petri net unfolding (Hickmott, 2008). general idea encode
evolution forward planning system repeated unfolding carefully
crafted Petri net: mathematical structure used model analyze dynamics
discrete distributed systems (Murata, 1989). unfolding process naturally represents
parallel partially ordered plan (Hickmott, Rintanen, Thiebaux, & White, 2007).
2009, Hickmott Sardina detailed theoretical property Petri net unfolding
partial-order plans, noting plan resulting Petri net unfolding minimal
deordering reordering respects strong independence (Hickmott & Sardina, 2009).
Strong independence restriction unordered actions partial-order plan:
ambiguity respect action produces particular fluent.
result, two different actions produce fluent f , unordered
neither required produce f either service achieving goal service
successful execution action plan. restriction makes deorderings
reorderings produced unfolding restrictive optimal deorderings
reorderings produced approach, require strong independence.
Similar POCL POPF approaches, Petri net unfolding exploited produce
partial-order plan directly, rather finding deordering reordering existing
plan, paper.
122

fiOptimal Partial-Order Plan Relaxation via MaxSAT

2.3.4 Relaxer Algorithm
Due Kambhampati Kedar (1994), Relaxer Algorithm3 operates removing
ordering constraints sequential plan systematic manner. heuristic guides
procedure and, detailed Backstrom (1998), process provide guarantee
resulting POP minimally deordered. error counterexample
used Backstrom demonstrate Kambhampati Kedars algorithm
necessarily produce minimally deordered POP. However, conclusion correct
provide new counterexample Appendix A.
intuition behind algorithm remove ordering (ai ak ) sequential plan ai achiever precondition ak removing ordering
lead threat. algorithm heuristically attempts choose earliest possible action sequential plan achiever precondition. example, consider
case sequential plan [a1 , ai , , ak , , ] p P RE(ak ).
algorithm keep ordering (ai ak ) leaving would create threat
precondition one actions, ai earliest action sequence
following holds:
1. p ADD(ai ): ai achiever p
2. aj , < j < k, p
/ DEL(aj ): p threatened.
Algorithm 1 presents approach formally. use index(a,~a) refer index
action sequence ~a, assume every action plan uniquely named.
~a valid plan, line 8 evaluate true either line 11 evaluates true
for-loop line 6 runs actions. is, know unthreatened achiever exists
earliest one found. achiever ordered action requiring
fluent precondition (line 14), for-loop line 16 adds necessary
ordering constraints achiever remains unthreatened. Note deleter found
for-loop, either line 17 19 must evaluate true. going outer
loop line 3, every action newly formed POP unthreatened supporting action
preconditions. resulting POP therefore valid (cf., Kambhampati
& Kedar, 1994, section 5.2).
2.3.5 SAPA Post-Processing
part post-processing phase SAPA planner, Kambhampati (2003)
introduce approach similar relaxing ordering plan. setting,
begin temporal plan actions assigned specific time points,
objective optimize either number ordering constraints temporal aspect
resulting plan.
strategy Kambhampati take (abbreviated DK here), model task
computing partial-order relaxation terms constraint satisfaction optimization
problem (CSOP). Variables introduced represent ordering actions, timing
duration actions, resource usage, etc. abstract CSOP formalism,
concrete mixed integer linear program (MILP) proposed realize set constraints
3. Referred order generalization originally.

123

fiMuise, Beck, & McIlraith

Algorithm 1: Relaxer Algorithm

1
2
3
4
5
6
7
8
9
10
11
12

13
14
15
16
17
18
19
20

21

Input: Sequential plan, ~a, including aI aG
Output: Relaxed Partial-order plan, hA, Oi
= set(~a);
= ;
foreach
foreach f P RE(a)
ach = null;
= (index(a, ~a) 1) 0
// See earlier achiever
f ADD(~a[i])
ach = ~a[i];
// Stop find deleter f
f DEL(~a[i])
break;
// Add appropriate supporting link
= {(ach a)};
// Add orderings avoid threats
foreach a0 deleters(f ) \ {a}
index(a0 , ~a) < index(ach, ~a)
= {(a0 ach)};
index(a0 , ~a) > index(a, ~a)
= {(a a0 )};
return hA, Oi;

model valid temporal plan. Similar work, DK contains option enforcing adherence original ordering constraints allows either deordering
reordering produced.
DK considers number optimization criteria including minimizing makespan,
maximizing sum slack temporal variables, maximizing flexibility
temporal variables, minimizing number ordering constraints. first three
related temporal planning domains, final one coincides optimization
criteria work. Experimental evaluation provided temporal optimization
criterion, Kambhampati empirically investigate minimization
ordering constraints.
Differences DK approach include formalism (we focus
temporal aspects), model used (unique encoding variables represent
action appearing plan unique encoding variables representing
time points resources), underlying solving technology (we rely partial weighted
MaxSAT instead MILP), finally MCLCP criterion. Section 4.4 compare
efficiency approach computing minimum reordering implementation
DK approach uses variables constraints relevant computing
minimum reordering.
124

fiOptimal Partial-Order Plan Relaxation via MaxSAT

2.4 Partial Weighted MaxSAT
compute relaxed plan, encode task partial weighted MaxSAT problem
solution encoding corresponds minimally relaxed plan optimizes
desired criteria. Here, review notation partial weighted MaxSAT use
throughout paper.
Boolean logic, problem Satisfiability (SAT) find true/false setting
Boolean variables logical formula referring variables evaluates true
(Biere, Heule, van Maaren, & Walsh, 2009). Typically, write problems Conjunctive
Normal Form (CNF), made conjunction clauses, clause
disjunction literals. literal either Boolean variable negation. setting
variables satisfies CNF formula iff every clause least one literal evaluates
true. example, setting variables x z true satisfy following theory:
(x y) (x z)

(1)

MaxSAT problem optimization variant SAT problem
goal maximize number satisfied clauses (Biere et al., 2009, ch. 19). Although
cannot satisfy every clause following theory, setting x, true z false
satisfies five clauses:
(x z) (x z) (y z) (x y) (z x) (z y)

(2)

Adding non-uniform weights clause allows richer version optimization
problem, refer maximizing weight satisfied clauses weighted MaxSAT
k

problem. use syntax ( ) indicate clause weight k. Generally,
weight must positive real number. Consider setting x false y, z true
following theory:
3

1

1

1

1

(x) (x y) (x z) (y) (z)

(3)

setting satisfies four clauses, total weight 4. aim
maximizing total weight satisfied clauses, achieve sum 5 assigning
variables true:
3

1

1

1

1

(x) (x y) (x z) (y) (z)

(4)

wish force solver find solution satisfies particular subset
clauses, refer clauses subset hard, clauses problem


soft. syntax use indicate hard clause ( ). mix hard
soft clauses, partial weighted MaxSAT problem (Biere et al., 2009, ch. 19.6).
partial weighted MaxSAT problem, soft clauses given weight,
feasible solution corresponds setting variables satisfies hard clauses
125

fiMuise, Beck, & McIlraith

CNF. optimal solution partial weighted MaxSAT problem feasible
solution maximizes sum weights satisfied soft clauses. following
example, setting variables x, false z true satisfies every hard clause one
soft clauses:
1

2

3







(x) (y) (z) (x z) (y z) (x y)

(5)

Although required partial weighted MaxSAT general, encodings create
never contain soft clause one literal. special form partial
weighted MaxSAT problem, referred binate covering problem (Coudert, 1996), allows
us flip optimization criterion: minimizing sum satisfied soft (unit) clauses
equivalent maximizing sum unit clauses literal flipped (e.g., x
goes x vice versa). Using technique solve minimization problem
partial weighted MaxSAT solver works soft clauses contain single literal.
property key encoding, objective always minimize.

3. Approach
view sequential plan (also referred total-order plan) special case
partial-order plan exists ordering constraint every pair actions.
Quite often, many ordering constraints required: ordering certain
actions may switched goal still achieved new sequence actions.
aim maximizing flexibility POP, strive minimize number ordering
constraints included solution. objective motivates need identify precisely
ordering constraints POP relevant POPs validity.
Definition 6 (Ordering Relevance). Given planning problem = hF, I, G, Ai valid
POP P = hA, Oi , ordering constraint relevant respect P
iff hA, {o}i valid POP .4
Ordering relevance plays central role definitions minimal minimum POP
deorderings: relevant ordering constraints precisely cannot removed
without invalidating POP (Backstrom, 1998). Additionally, Relaxer Algorithm
Kambhampati Kedar (1994) operates identifying set ordering constraints
suspected relevant (i.e., selected achievers action preconditions).
maximize flexibility POP, focus encoding retaining relevant
orderings. difficult measure efficiently, strive maximize flexibility inherent
POP, loosely defined number linearizations POP represents. number
unordered pairs actions POP, typically referred flex (Siddiqui & Haslum,
2012), provides approximation POPs flexibility. evaluation, quantify
accuracy flex approximation POPs flexibility.
discussed earlier, verifying POPs validity way linearizations
always practical. Similarly, attempt compute POPs maximize
4. Note transitive closure P necessarily different transitive closure hA, {o}i
relevant respect P .

126

fiOptimal Partial-Order Plan Relaxation via MaxSAT

number linearizations, rather compute POPs adhere one
previously mentioned criteria removing redundant orderings: minimum deordering
minimum reordering.
3.1 Minimum Cost Least Commitment Criterion
notion minimum deordering reordering POP addresses commitment ordering constraints, orthogonal objective commit resources
possible typically measured either time plan executed parallel
sum action costs actions plan. Historically, latter objective takes precedence metrics. end, provide extended criterion computing
minimum cost least commitment POP (MCLCP).
0

0

Definition 7 (Minimum Cost Least Commitment POP). Let P = hA, Oi Q = hA ,
two POPs valid . Q minimum cost least commitment POP (MCLCP) P iff
00
00
Q minimum reordering, A0 A, exist valid POP R = hA ,
A00 following condition holds:
c (R) < c (Q) (c (R) = c (Q) |O00 | < |O0 |)
work, assume every action positive cost. may turn
preferring fewer actions causes us commit ordering constraints, simply due
interaction actions choose. practice, however, usually place much
greater emphasis minimizing total cost plan. also worth noting
plan exists proper subset actions input plan, computing MCLCP
equivalent computing minimum reordering.
Following MCLCP criterion, evaluate quality POP total
action cost number ordering constraints contains; metrics give us direct
measure least commitment nature POP primary emphasis placed
removing unnecessary commitments actions.
3.2 Encoding
encode task finding minimum deordering, reordering, MCLCP partial
weighted MaxSAT problem given input planning problem corresponding initial plan.
optimal solution default encoding correspond MCLCP. is,
POP exists cheaper overall cost cost fewer ordering constraints
transitive closure. present core encoding Section 3.2.1 prove
soundness completeness encoding Section 3.2.2. add clauses
produce encodings correspond optimal deorderings reorderings, present
modifications Section 3.2.3.
3.2.1 Basic Encoding
contrast typical SAT encoding planning problem (e.g., Kautz & Selman,
1999), require actions replicated successive plan steps. Instead,
represent action occurrence reason ordering
actions. actions encoding come provided sequential partial-order plan,
127

fiMuise, Beck, & McIlraith

P = hA, Oi. use (P ) denote partial weighted MaxSAT encoding corresponding
POP P = hA, Oi, refer POP corresponding encodings solution
target POP. target POP reconstructed encodings solution looking
variables set true. use three types propositional variables:
xa : every action A, xa indicates action appears target POP.
(a1 , a2 ): every pair actions a1 , a2 A, (a1 , a2 ) indicates ordering
constraint (a1 a2 ) appears target POP.
(ai , p, aj ): every action aj A, p PRE(aj ), ai adders(p), (ai , p, aj )
indicates ai supports aj fluent p target POP.
partial weighted MaxSAT encoding distinction hard soft
clauses. first present hard clauses encoding Boolean formulae
subsequently convert CNF, later describe soft clauses associated
weights.5 define formulae ensure target POP acyclic,
ordering constraints include transitive closure. Here, actions universally quantified,
formula (9) assume aI 6= ai 6= aG . must ensure that:
self-loops:
((a, a))

(6)

include initial goal actions:
(xaI ) (xaG )

(7)

use ordering variable, include actions:
(ai , aj ) xai xaj

(8)

action cannot appear initial action (or goal):
xai (aI , ai ) (ai , aG )

(9)

solution satisfies transitive closure ordering constraints:
(ai , aj ) (aj , ak ) (ai , ak )

(10)

Together, (6) (10) ensure target POP acyclic (note implies
antisymmetry well), remaining formulae tie two types variables together
deal initial goal actions. Finally, include formulae needed ensure
every action preconditions met, threats solution:


5. readability, omit hard clause symbol, ( ), constraints (6)-(12).

128

fiOptimal Partial-Order Plan Relaxation via MaxSAT

(ai , p, aj )

^

xak (ak , ai ) (aj , ak )

(11)

ak deleters(p)

^

xaj

_

(ai , aj ) (ai , p, aj )

(12)

pP RE(aj ) ai adders(p)

Intuitively, (ai , p, aj ) holds ai achiever precondition p action aj
deleter p allowed occur actions ai aj ; i.e., corresponds
directly unthreatened causal link. Formula (11) ensures every causal link remains
unthreatened satisfying variable setting, view two ordering variables
formula form common partial-order planning concepts promotion
demotion (Weld, 1994). Formula (12) ensures include action aj target POP,
every precondition p aj must satisfied least one achiever ai . (ai , aj ) orders
achiever correctly, (ai , p, aj ) removes possibility threatening action.
far, constraints described capture required POP valid.
go address notion ordering relevance presented Definition 6, well
metric minimizing total action cost MCLCP, make use soft clauses.
generate MCLCP, prefer solutions first minimize total action cost,
minimize number ordering constraints. add soft unit clause, containing
negation variable, every action ordering variable encoding.
violation one unit clauses means solution includes action
ordering constraint corresponding violated clauses variable. weight assigned
follows:
1

((ai , aj )), ai , aj
c (a)+|A|2 +1



(xa )

, \ {aI , aG }

Note weight single action clause greater weight ordering constraint clauses combined, |A|2 total ordering
constraints. increased weight guarantees generate solutions minimum
action cost.6 enforce transitive closure ordering constraints, second type soft clause lead solver find POP (among cheapest
total action cost) minimizes size transitive closure.
Richer notions, weighted trade-off ordering constraints action
costs, also easily modelled using appropriate assignment weights soft clauses
encoding. focus primarily deordering reordering aspects
work, leave alternative encodings future work.
3.2.2 Theoretical Results
section present theoretical properties core encoding.
6. wish minimize number actions solution, need replace c (a) 0.

129

fiMuise, Beck, & McIlraith

Lemma 1 (Variable Setting Implies POP). Given planning problem valid POP
P = hA, Oi, variable setting satisfies formulae (6)-(12) (P ) correspond valid POP ordering constraints transitively closed.
Proof. already seen POP induced solution hard clauses
acyclic transitively closed (due formulae (6)-(10)). see
open preconditions include aG , conjunction (12) ensures
every precondition satisfied POP includes action. Additionally,
threats final solution formula (11), enforced
every time precondition met formula (12). POP corresponding
solution hard clauses open preconditions threats, Theorem 1
allows us conclude target POP valid .
Lemma 2 (POP Implies Variable Setting). Given planning problem valid POP
0
0
P = hA, Oi, valid POP Q = hA , i, A0 O0 transitively closed,
corresponding feasible variable assignment satisfies (P ).
Proof. lemma follows direct encoding POP Q xa = true iff
A0 (ai , aj ) = true iff (ai aj ) O0 . Q valid POP, acyclic,
include aI aG , actions ordered aI aG , transitively
closed (satisfying (6)-(10)). see (11) (12) must satisfied: (12)
hold, would action POP precondition p
every potential achiever p threat could ordered achiever
a. situation possible POP invalid, contradiction.
Theorem 2 (Completeness). Given planning problem valid POP P = hA, Oi,
complete partial weighted MaxSAT solver find solution soft clauses formulae
(6)-(12) (P ) minimizes total cost actions corresponding POP,
subsequently minimizes number ordering constraints.
Proof. Given |A| actions, |A|2 ordering constraints. every soft
clause corresponding ordering constraint weight 1, total sum satisfying every ordering constraint clause |A|2 . weight satisfying
action clause greater |A|2 , soft clauses corresponding actions dominate
optimization criteria. such, valid POP subset
actions P lower total action cost solution satisfies formulae (6)-(12)
maximizing weight satisfied soft clauses.
Theorem 3 (Encoding Correctness). Given planning problem , valid POP P
, solution partial weighted MaxSAT encoding (P ) MCLCP P .
Proof. Theorem follows directly Lemmas 1, 2, Theorem 2.
3.2.3 Variations
Observe (P ) make use set ordering constraints P . optimal
solution encoding correspond MCLCP, enforce solutions
minimum deorderings reorderings, introduce two additional sets hard clauses.
130

fiOptimal Partial-Order Plan Relaxation via MaxSAT

Actions: optimal deorderings reorderings, require every action part
target POP. consider formula ensures use every action (and
optimization works ordering constraints). achieve this, simply need
add action hard clause:


(xa ),

(13)

soft unit clauses trivially unsatisfiable, removed preprocessing phase MaxSAT solving process. optimal solution soft constraints
formulae (6)-(13), referred R (P ), corresponds minimum reordering P .
Deordering: deordering must forbid explicit ordering contradicts
input plan. Assuming input plan P = hA, Oi, ensure computed solution
deordering adding following family hard unit clauses:


((ai , aj )), (ai aj )
/O

(14)

Similar introduction hard unit clauses action inclusion, using clauses
(14) eliminate number ordering constraint soft clauses encoding
preprocessing phase MaxSAT solver. optimal solution soft constraints formulae (6)-(14), referred (P ), corresponds minimal deordering
P . additionally could use (14) forgo use (13), variation one
typically studied, provide benefit computing MCLCP.

4. Evaluation
evaluate ability effectiveness state-of-the-art partial weighted MaxSAT
solver, Sat4j (Le Berre & Parrain, 2010), optimally relax plan using proposed
encodings.7 use MD MR encodings, ensure actions always
included solution (i.e., using Actions constraint (13)). also investigate
effectiveness Relaxer Algorithm (RX) produce minimally constrained deordering. measure quality POP, use either flex value (cf. Section 2),
number linearizations (whenever feasible compute).
analysis, considered every STRIPS domain previous International
Planning Competitions (IPC, Hoffmann, 2016). discarded two domains (childsnack
tidybot) due difficulty planners generating initial solution.
18 discarded due constrained nature; form offers little
flexibility (any domain average flex value less 10% removed).8
Using evaluation would uninformative since already relaxed
7. Additionally, evaluated 2013 winner partial weighted MaxSAT contest crafted instances,
MaxHS (Davies & Bacchus, 2013), however, found Sat4j outperformed MaxHS slightly
coverage time.
8. 18 overly constrained domains visitall, blocksworld, sokoban, pegsol, ged, parking, barman, gripper, cybersec, psr-small, storage, nomystery, mystery, mprime, freecell, hiking, floortile, thoughtful.

131

fiMuise, Beck, & McIlraith

possible, solver determined trivially. evaluate using recent
version domain multiple problem sets exist, Table 1 shows set 15
domains considered throughout evaluation.
conducted experiments Linux desktop 3.4GHz processor,
run Sat4j limited 30 minutes 4GB memory. generate initial sequential
plan, used Mercury planner (Domshlak, Hoffmann, & Katz, 2015); best performing non-portfolio planner recent satisficing IPC competition. Additionally,
evaluation, computed initial solutions using state-of-the-art SAT-based
planner, Mp (Rintanen, 2012), state-of-the-art partial-order planner, POPF (Coles
et al., 2010). offer alternative methods generate initial partially ordered plan,
investigate impact plans structure relaxation process.
assess various aspects approach four separate experiments. First,
evaluate difficulty computing feasible solution addition optimal one (we
obtain solutions increasing quality using Sat4j any-time fashion). Next, look
quality POP produced encodings well POP produced
Relaxer Algorithm. Here, measure quality flex plan transitive
closure, number linearizations plan wherever feasible compute.
also demonstrate empirically accuracy flex measure indicator
number linearizations. Next, consider impact initial plan form
relaxation, taking account starting solution three planners. Finally,
compare approach computing minimum reordering similar approach
Kambhampati (2003).
4.1 Solving Completion
begin brief discussion various configurations approach
coverage, well weaknesses methods. report problems
planner able find plan within resource limits.9 Table 1 shows
following information every domain:
number problems domain shown brackets next domain name.
number problems solved planner Plans column.
Solved column indicates number plans successfully encoded solved.
Every problem could encoded MR also could encoded MD,
MaxSAT solver produced least one solution every encoded problem. Further,
every encoded MD problem solved completion within resource limits.
MR column indicates number encoded MR problems solved completion.
must emphasize purpose evaluation compare efficiency
three planners (as strengths weaknesses). Rather, consider
type plan produces related relaxing ordering constraints
plan. Consequently, purpose Table 1 provide insight problems
included analysis, bring light challenges encoding
solving problems completion.
9. Providing twice amount time memory planners lead problems solved.

132

fiOptimal Partial-Order Plan Relaxation via MaxSAT

Domain

Mercury
Plans Solved

MR

POPF
Plans Solved

MR

Plans

Mp
Solved

MR

airport (50)

32

29

29

24

21

21

32

29

29

depot (22)

21

21

19

10

10

10

20

20

14

driverlog (20)

20

20

16

15

15

15

17

15

10

elevators (20)

20

10

6

1

1

0

0

-

-

logistics (42)

35

9

5

5

5

5

12

7

2

parcprinter (20)

20

20

20

15

15

15

20

20

20

pipesworld (50)

42

42

42

23

23

22

14

14

14

rovers (40)

40

33

22

24

24

21

39

33

27

satellite (36)

35

29

29

13

13

13

26

25

17

scanalyzer (20)

20

17

12

10

7

7

15

15

14

tetris (20)

19

19

19

0

-

-

1

1

1

tpp (30)

30

28

11

13

13

8

20

20

11

transport (20)

20

6

5

0

-

-

0

-

-

woodwork (20)

20

20

20

5

4

4

20

20

20

zenotravel (20)

20

20

20

16

16

16

20

20

16

(460)

394

323

275

174

167

157

256

239

195

Table 1: Per domain solver relaxation coverage. Values brackets indicate benchmark size. Plans column indicates many problems respective planner solved.
Solved column indicates many solved problems successfully encoded
solved: every encoded problem solvable MD MR, every MD encoding solvable completion. MR column indicates number problems
successfully encoded, MR solved completion.

problem could encoded, due large number actions
plan; typically plans 200 actions caused issue. domains
problematic (e.g., elevators, logistics, transport), see initial
coverage non-sequential planners suffers well. problem encoding plans
contain many actions due number transitivity clauses included formula
(10), cubic number actions.
tetris domain proved extremely difficult POPF Mp solve, although
number actions plans Mercury small enough encode. Finally, found
proving optimality MR encoding tpp rovers difficult,
clear indication why: rovers high flex , high
domains, opposite true tpp. domains, however, good initial plans
produced quickly Sat4j, solver devoted remaining time making small
improvements proving optimality.
133

fiMuise, Beck, & McIlraith

Figure 1: number problems solved completion Sat4j given limited amount
time per problem, well number problems solved RX algorithm. Every
MD encoding solved completely Sat4j, RX polynomial sub-optimal technique
shown comparison solve time.

Mercury solved strict superset problems solved POPF Mp. such,
use sequential plans produced Mercury input majority evaluation
(Section 4.3 one exception). Figure 1 provides view long took Sat4j
optimally solve MD MR encodings initial plans Mercury produced:
show number problems solved optimally function time (including encoding
phase). comparison, include aggregate time RX well. strong run-time
performance RX expected given polynomial time algorithm without
optimality guarantees.
4.2 Plan Quality
begin, discuss surprising result Relaxer algorithm planning benchmarks. every one 323 problems Sat4j solved MD encoding optimally,
POP produced Relaxer algorithm contained number ordering
constraints. Even though theoretically Relaxer algorithm guaranteed find
minimal POP, nonetheless computes minimum deordering every tested problem. RX
produce deorderings, best RX could hope achieve. Note
may many candidates minimum deordering, RX necessarily find
one MD encoding finds.
Next, consider difference quality minimum deordering minimum reordering. Quality measured flex transitive closure generated
POP, include problems MD MR encodings
134

fiOptimal Partial-Order Plan Relaxation via MaxSAT

solved completion Sat4j (275 total plans generated Mercury). Table
2 shows average flex MD MR domains, Figure 2 shows flex
comparison per-problem basis domains.
Domain

MD

MR

airport
depot
driverlog
elevators
logistics
parcprinter
pipesworld
rovers
satellite
scanalyzer
tetris
tpp
transport
woodwork
zenotravel

0.28
0.31
0.33
0.31
0.56
0.76
0.16
0.68
0.39
0.31
0.49
0.37
0.51
0.96
0.32

0.37
0.36
0.34
0.32
0.58
0.76
0.16
0.69
0.39
0.31
0.50
0.38
0.51
0.96
0.32

Table 2: Average flex

Figure 2: MD versus MR flex Comparison
135

fiMuise, Beck, & McIlraith

Domains see substantial improvement include airport depot. Domains
saw zero gain terms flexibility include parcprinter, transport, woodwork.
total, almost one third (76/275) problems showed improvement flex MR
MD varying degrees.10
flex value fails convey extreme amount execution flexibility introduced
relaxations. investigate further, computed number linearizations
plans wherever feasible. Determining number total orders partially ordered
graph #P-Complete (Brightwell & Winkler, 1991), practice difficult compute
precisely many graphs. able compute number linearizations
MD MR solutions total 203 problems solution encodings
computed. found approximately one quarter (51/203) showed difference
number linearizations, plot ratio #Linears(MR) / #Linears(MD)
51 problems Figure 3.

Figure 3: Ratio Linearizations. y-axis represents number linearizations induced
POP optimal reordering divided number linearizations induced
POP optimal deordering. x-axis ranges problems number
linearizations differed (25%), sorted based y-axis.
extreme, improvement number linearizations massive;
13 orders magnitude one airport problem. Conversely, see interesting
artefact resulting optimizing metric acts proxy number linearizations: flex value MR never lower MD, POPs
produced approach using flex optimization criterion opposite
effect number linearizations.
10. Many smaller improvements show scatter plot.

136

fiOptimal Partial-Order Plan Relaxation via MaxSAT

three problems (one tetris two depot), found number
linearizations POP produced MR encoding fewer number
linearizations POP produced MD encoding. number ordering
constraints POP given number actions usually indicative number
linearizations POP, three problems indicate universal rule.
concrete example, consider two POPs four actions = {a1 , a2 , a3 , a4 }. Ignoring
causal links, Figure 4 shows structure POPs P1 P2 . POPs
number actions ordering constraints, number linearizations differ:
P1 6 linearizations P2 5. POPs serve basic example
flex criterion capture fully notion POP flexibility use
work. may similar notions take differences account,
left future investigation (see Say, Cire, Beck (2016) recent work
direction).

a2
a1

a3

a1

a4

a3

(a) P1

a2

a4
(b) P2

Figure 4: Two POPs number actions ordering constraints,
different number linearizations.

demonstrate correlation POPs flex number linearizations,
focused random partial orders POP 20 actions (not including special
actionis aI aG ).11 constructed 10,000 random partial orders (8,959 unique)
spread flex value 0.0 1.0, subsequently computed corresponding
number linearizations every POP. 100 POPs constructed target flex value
(taken 0.01 increments), method construction iteratively add new edges
present transitive closure POP reached target flex value.
Qualitatively, POPs resembled found using planning techniques. reason
use randomly generated plans due number examples required trend
present (comparing plans varying number actions uninformative). Figure
5 shows flex function number linearizations normalized total number
linearizations possible (in POPs, equals 20! roughly 2.4 1018 ).
Pearson correlation coefficient log normalized linearization count
flex value 0.991, clear trend ties together flex POP
number linearizations. red line Figure 5 line-of-best-fit using log scole
linf lex values (as plot x-axis does). Interestingly, use line
11. Similar results hold random POPs different number actions.

137

fiMuise, Beck, & McIlraith

Figure 5: Comparison normalized number linearizations flex value
approximately 10,000 random POPs 20 actions. Every point represents unique
POP 20 actions. linf lex value computed normalizing total number
linearizations possible (20!), note x-axis uses log scale. red
line line-of-best-fit using log linf lex.
predictor number linearizations, flex overestimates number linearizations
highly constrained plans underestimates number linearizations unconstrained
plans. Though minimizing number ordering constraints transitive closure
POP want optimize directly, serve highly informative proxy
maximizing number linearizations POP.
4.3 Initial Plan Impact
Different planning techniques generate solutions varying forms. sequential planners
far widely used, planners create inherently partially
ordered solutions. example, POPF planner uses forward-chaining approach
results partial-order plan represented layered sets unordered actions.
Similarly, SAT-based planners Mp produce solutions contain layers unordered
actions. two approaches fundamentally differ search solution,
fundamentally different sequential planner searches. One question
arises differences whether lead fundamentally different solutions;
amenable relaxing different ways. investigate impact starting solution
relaxed solution quality ability compute optimal solution.
encoding minimum reordering take account original sequence
actions. Therefore, encoding used without modification plans produced
138

fiOptimal Partial-Order Plan Relaxation via MaxSAT

POPF Mp. similar sense, plans produced POPF Mp encoded
minimum deordering carefully applying equation 14: include link
every pair actions share layer. obtained layered plan
representation POPF Mp directly using appropriate planner settings.
Across domains, 287 problems mutually solved completion Sat4j using
solutions produced three planners either MD MR encoding. 78
contained number actions. Figure 6 shows time Sat4j required
solve problem completion Mercurys plans measured plans
two planners. first plot shows 287 problems mutually solved, see
performance improvement solutions coming Mercury solver.12 However,
limit 78 problems contain number actions
solutions, find Sat4j solve-time much comparable
solvers. Thus, appears little effect solving efficiency based input
solution format. primary factor Sat4j solve time number actions represented
encoding.

(a) problems mutually solved Sat4j using (b) subset mutually solved problems consource plan planner.
tain number actions.

Figure 6: Comparison time relax Mercury plan versus time relax POPF
Mp plan. MD MR encodings included data.
addition, investigated resulting flex produced POPs. 78 problems
mutually solved number actions, two (from scanalyzer domain)
contained different set actions resulted slightly higher flex values
minimum deordering reordering Mercurys solution compared planners.
hand, six problems airport domain lower flex value
minimum deordering Mp solutions despite number actions.
indicates conditions, initial layered plan produced Mp may
allow much relaxation compared forward search planner Mercury
POPF. note, however, vast majority problems flex
minimum deordering reordering coincided across initial plan types.
12. Note time include initial planner computation; time encode solve
MaxSAT encoding.

139

fiMuise, Beck, & McIlraith

Finally, investigated improvement flex planner compared initial
solution. Mercury, initial flex value always 0, sequential planner.
reordering allowed ignore original ordering constraints, consider
improvement flex minimum deordering plans coming POPF Mp.
Figure 7 shows relative flex comparison original plan minimum
deordering computed. plots, include every problem solved successfully
completion Sat4j plans produced POPF (167) Mp (219).

(a) flex improvement POPF

(b) flex improvement Mp

Figure 7: Comparison original plan flex versus flex minimum deordering.
found majority initial flex values Mp POPF solutions fell
within range 0 0.2, difference flex solutions solver
minimal. moderate correlation original final flex value:
Mp POPF solutions Pearson correlation coefficient 0.57 0.42 respectively.
However, observed distinction relaxing Mp solutions versus POPF
either time compute relaxation, flex final POP.
4.4 Comparison MILP Encoding
model relaxing ordering plan presented Kambhampati
(2003) involves temporal constraints resources aspects beyond
consider here. Nevertheless, fragment model capable computing either
minimum deordering reordering plan, worthwhile see effective
finding optimal reordering. forgo testing previous work computing
optimal deordering, Relaxer Algorithm effective so. note
Kambhampati considered using model heuristically guide solver
reasonable solution instead optimal one.
optimization framework Kambhampati use model problem relaxing
ordering plan Mixed Integer Linear Programming (MILP). MILP consists
set linear constraints defined variables take integer real
values. optimization criterion specified weighted linear combination subset
variables problem either maximized minimized.
140

fiOptimal Partial-Order Plan Relaxation via MaxSAT

need go detail, MILP model presented section quite basic
uses integer variables encoding.
Here, present version MILP model introduced Kambhampati
comparison partial weighted MaxSAT model. modifications fall three
categories: (1) fixes bugs original formulation, (2) removal variables constraints relevant setting (i.e., temporal resource related portions
model), (3) adding constraints enforce solution transitive closure.
variables use model include following:

Xafj ,ai

(
1
=
0

ai supports aj fluent f
otherwise

Yafi ,aj

(
1
=
0

ai ordered aj due interference fluent f
otherwise

Oai ,aj

(
1
=
0

ai ordered aj
otherwise

Note Xafj ,ai Oai ,aj analogous (ai , f, aj ) (ai , aj ) respectively.
interference variables Yafi ,aj defined cases aj conflict
execution ai fluent f : either f (P RE(ai ) ADD(ai )) DEL(aj ) f
(P RE(aj ) ADD(aj )) DEL(ai ) holds. constraints MILP model follows
(unbound variables assumed universally quantified).
Interfering actions must ordered (defined pairs actions interfere):
Yafi ,aj + Yafj ,ai = 1
Every precondition supported exactly one way:13
X
f P RE(aj ),
Xafj ,ai = 1
ai adders(f )

Every support threat free:
ad deleters(f ), (1 Xafj ,ai ) + (Yafd ,ai + Yafj ,ad ) 1
Support implies ordering:
Oai ,aj Xafj ,ai 0
13. original paper constraint erroneously listed

141

P

ai adders(f )

Xafi ,aj = 1.

fiMuise, Beck, & McIlraith

Interference implies ordering:
Oai ,aj Yafi ,aj 0
Enforce transitive closure ordering constraints:
(1 Oai ,aj ) + (1 Oaj ,ak ) + Oai ,ak 1
Forbid self loops ordering:
Oa,a = 0
Order everything initial state action goal action:
OaI ,a = 1
Oa,aG = 1
final three constraints appear original model. last one replaces
constraints referenced temporal variables achieve effect, first two
ensure solution transitively closed. mentioned earlier, optimizing transitive closure preferred optimizing transitive reduction. Finally, optimization
criterion MILP model follows.
inimize

X

Oa1 ,a2

a1 ,a2

model produce reorderings input plan feasible solutions,
find minimum reordering solved completion. implemented MILP model
using state-of-the-art MILP solver Gurobi (version 5.6.2) (Gurobi Optimization, Inc.,
2015), measured coverage domains function time. Figure 8 contains
results.
found using MILP model effective easier problems (those solved
2 seconds), anything difficult, solving partial weighted MaxSAT
encoding Sat4j proved efficient. Overall, 275 problems solved using Sat4j
partial weighted MaxSAT encoding 226 problems solved using Gurobi
MILP model.
additionally tested MILP model mirrors partial weighted MaxSAT encoding presented above. However, results similar shown Figure
8, MILP encoding consistently outperformed problems take
second solve.

5. Discussion
paper, proposed practical method computing optimal deordering
reordering sequential partial-order plan. Despite theoretical complexity computing optimal deordering reordering NP-hard, able compute
142

fiOptimal Partial-Order Plan Relaxation via MaxSAT

Figure 8: given timeout (x-axis), number problems solved completion within
timeout bound (y-axis) (1) Sat4j using MR encoding (2) Gurobi using
MILP encoding described text.

optimal solution leveraging power modern MaxSAT solvers. proposed
extension classical least commitment criteria minimal deordering reordering: minimum cost least commitment POP (MCLCP). MCLCP considers total
cost actions solution minimizing number ordering constraints. Central
encodings propose notion ordering relevance: designed optimization
criteria minimize ordering constraints resulting plan, leaving
relevant plan validity.
approach uses family novel encodings partial weighted MaxSAT,
solution corresponds optimal POP satisfying one three least commitment criteria
investigate: minimum deordering, minimum reordering, proposed minimum cost
least commitment POP. solve former two encodings state-of-the-art partial
weighted MaxSAT solver, Sat4j, find majority problems readily handled
MaxSAT solver reasonable amount time.
considered various input plan formats, well similar encoding optimizing
plan flexibility, found using sequential plan input encodings
effective solution computing reordering; perhaps surprisingly, benefit
observed using planner naturally generates partial orders (Mp).
also investigated existing polynomial algorithm deordering sequential plans
discovered successfully computes optimal deordering every problem
tested, despite lack theoretical guarantee. algorithm fast practice,
well suited relaxing POP require deordering. Finally, also established
strong empirical correspondence commonly used flex metric number
linearizations represented POP.
143

fiMuise, Beck, & McIlraith

Here, discuss related work conclude discussion potential future work.
5.1 Related Work
Section 2.3, detailed variety approaches naturally produce partial-order
plans. Here, review work related aspects approach.
standard SAT-based planning encodings also produce POP (Kautz, McAllester,
& Selman, 1996), significant difference standard encodings work
avoid encoding action every layer planning graph appealing
fact already know (superset of) actions solution. Intuitively,
view encoding using MaxSAT find implicit layers actions plan
way computing relevant ordering constraints. additional difference
choosing layer every action unnecessarily restricts timing action
potentially appear multiple adjacent layers.
notion MCLCP related plan repair (Nebel & Koehler, 1995; Gerevini
& Serina, 2000). key difference, however, consider addition new
actions cost plan improved removing actions MCLCP. focus
paper improving flexibility POPs, forgo full theoretical empirical
comparison MCLCP criterion existing plan repair techniques. Preliminary
results effect MCLCP action removal technique found previous
work subject (Muise et al., 2012; Muise, 2014).
core encoding similar causal encodings Kautz et al. (1996) Variant-II
Robinson, Gretton, Pham, Sattar (2010). similarly encode ordering
pair actions variable ((ai , aj ) case), rather encoding every
potential action occurrence modelling relaxed planning graph, encode formulae
must hold valid POP specific set actions provided part input.
mentioned Section 2.3, also similarities work
Kambhampati (2003). particular, optimization criterion minimizing number
ordering constraints coincide, optional use constraints force deordering.
Kambhampati focus temporal relaxation context action ordering,
take orthogonal view minimizing total action cost.
5.2 Conclusion
use method computing optimally relaxed plans provides two key advantages:
(1) maximizing flexibility paramount, solving MR encoding lead far
flexible solutions MD encoding Relaxer Algorithm achieve, (2)
optimal deordering provides useful baseline demonstrating effectiveness
Relaxer Algorithm. work leaves open possibility heuristic approach similar
Relaxer Algorithm capable producing reorderings partial-order plan.
One extension work consider alternative forms optimization criteria.
example, one may change soft clauses minimize number fluents
initial state required plan validity. potential improve
planning formalisms attempt minimize reliance information initial
state, assumption-based planning (Davis-Mendelow, Baier, & McIlraith, 2013).
Alternatively, initial set actions need correspond directly plan. long
144

fiOptimal Partial-Order Plan Relaxation via MaxSAT

subset actions achieve goal, compute plan. opens door
techniques optimizing plans adding actions select from, using techniques
introduced Davies, Pearce, Stuckey, Sndergaard (2014).

Acknowledgments
authors gratefully acknowledge funding Ontario Ministry Innovation
Natural Sciences Engineering Research Council Canada (NSERC). Thanks also
go anonymous reviewers thoughtful feedback review process.

Appendix A. Relaxer Counterexample
Relaxer Algorithm presented Section 2.3.4 deorders input plan, pointed
Backstrom (1998), resulting POP may minimal deordering. counterexample provided Backstrom, however, incorrectly states resulting POP
minimally deordered (Backstrom, 1998, Figure 14), fact Figure 14(b)
deordering 14(a), thus 14(a) minimal deordering (although minimum reordering). Here, present new counterexample supports claim Relaxer
Algorithm may produce minimum deordering.
domain theory problem specification shown Figure 9. input plan
sequence actions [a1 , a2 , a3 ]. Relaxer Algorithm seeks earliest
achiever every precondition, algorithm results deordering plan
two ordering constraints: (a1 a3 ) (a2 a3 ). problem deordering
a1 chosen achiever fluent p, fact a2 used achiever
p q (note a2 already required fluent q).
weakness Relaxer Algorithm uses earliest achiever. weakness surfaces action later plan used achiever already ordered
appropriately. Using insight, may modification Relaxer Algorithm
finds achievers already ordered appropriately, opposed finding earliest achiever.

145

fiMuise, Beck, & McIlraith

(define (domain counterexample)
(:requirements :strips)
(:predicates (p) (q) (g1) (g2) (g3) )
(:action a1
:parameters()
:precondition ()
:effect (and (g1) (p)))
(:action a2
:parameters()
:precondition ()
:effect (and (g2) (p) (q)))
(:action a3
:parameters()
:precondition (and (p) (q))
:effect (and (g3))))
(define (problem counterexample-problem)
(:domain counterexample)
(:init ())
(:goal (and (g1) (g2) (g3) )))
Figure 9: Counterexample Domain Problem Description

References
Anderson, J. S., & Farley, A. M. (1988). Plan abstraction based operator generalization.
7th International Conference Artificial Intelligence, pp. 100104.
Backstrom, C. (1998). Computational aspects reordering plans. Journal Artificial
Intelligence Research, 9 (1), 99137.
Biere, A., Heule, M., van Maaren, H., & Walsh, T. (2009). Handbook satisfiability,
frontiers artificial intelligence applications. IOS Press.
Brightwell, G., & Winkler, P. (1991). Counting Linear Extensions #P-Complete. 23rd
Annual ACM Symposium Theory Computing, 8 (3), 175181.
Coles, A., & Coles, A. (2016). Before? State Memoization Temporal
Planning. 26th International Conference Automated Planning Scheduling,
pp. 97105.
Coles, A., Coles, A., Fox, M., & Long, D. (2010). Forward-chaining partial-order planning.
20th International Conference Automated Planning Scheduling, pp. 4249.
Coudert, O. (1996). solving covering problems. 33rd Annual Design Automation
Conference, pp. 197202.
146

fiOptimal Partial-Order Plan Relaxation via MaxSAT

Davies, J., & Bacchus, F. (2013). Postponing optimization speed MAXSAT solving.
19th International Conference Principles Practice Constraint Programming,
pp. 247262.
Davies, T. O., Pearce, A. R., Stuckey, P. J., & Sndergaard, H. (2014). Fragment-based
planning using column generation. Proceedings 24th International Conference
Automated Planning Scheduling, pp. 8391.
Davis-Mendelow, S., Baier, J. A., & McIlraith, S. A. (2013). Assumption-based planning:
Generating plans explanations incomplete knowledge. Proceedings
27th AAAI Conference Artificial Intelligence, pp. 209216.
Do, M. B., & Kambhampati, S. (2003). Improving temporal flexibility position
constrained metric temporal plans. AIPS Workshop Planning Temporal
Domains.
Domshlak, C., Hoffmann, J., & Katz, M. (2015). Red-black planning: new systematic
approach partial delete relaxation. Artificial Intelligence, 221, 73114.
Fikes, R. E., Hart, P. E., & Nilsson, N. J. (1972). Learning executing generalized robot
plans. Artificial intelligence, 3 (1), 251288.
Gerevini, A., & Serina, I. (2000). Fast plan adaptation planning graphs: Local
systematic search techniques. Proceedings 5th International Conference
Artificial Intelligence Planning Systems, pp. 112121.
Ghallab, M., Nau, D., & Traverso, P. (2004). Automated Planning: Theory & Practice.
Morgan Kaufmann Publishers.
Graham, J. R., Decker, K. S., & Mersic, M. (2001). DECAF - Flexible Multi Agent
System Architecture. Autonomous Agents Multi-Agent Systems, 7 (1), 727.
Gurobi Optimization, Inc. (2015). Gurobi optimizer reference manual..
Hickmott, S., Rintanen, J., Thiebaux, S., & White, L. B. (2007). Planning via petri net
unfolding. 20th International Joint Conference Artificial Intelligence, pp. 1904
1911.
Hickmott, S., & Sardina, S. (2009). Optimality properties planning via Petri net unfolding: formal analysis. 19th International Conference Automated Planning
Scheduling, pp. 170177.
Hickmott, S. L. (2008). Directed unfolding: reachability analysis concurrent systems &
applications automated planning. Ph.D. thesis, University Adelaide.
Hoffmann, J., & Nebel, B. (2001). FF planning system: fast plan generation
heuristic search. Journal Artificial Intelligence Research, 14 (1), 253302.
Hoffmann, J. (2016). ICAPS competition page. http://ipc.icaps-conference.org/.
Accessed: 2016-09-06.
Kambhampati, S., & Kedar, S. (1994). unified framework explanation-based generalization partially ordered partially instantiated plans. Artificial Intelligence,
67 (1), 2970.
147

fiMuise, Beck, & McIlraith

Kautz, H. A., McAllester, D. A., & Selman, B. (1996). Encoding plans propositional
logic. 5th International Conference Principles Knowledge Representation
Reasoning, pp. 374384.
Kautz, H. A., & Selman, B. (1999). Unifying SAT-based graph-based planning. 16th
International Joint Conference Artificial Intelligence, pp. 318325.
Le Berre, D., & Parrain, A. (2010). Sat4j library, release 2.2 system description. Journal
Satisfiability, Boolean Modeling Computation, 7, 5964.
McAllester, D. A., & Rosenblitt, D. (1991). Systematic nonlinear planning. Proceedings
9th National Conference Artificial Intelligence, pp. 634639.
Muise, C. (2014). Exploiting Relevance Improve Robustness Flexibility Plan Generation Execution. Ph.D. thesis, University Toronto.
Muise, C., Mcilraith, S. A., & Beck, J. C. (2011). Optimization partial-order plans via
MaxSAT. ICAPS Workshop Constraint Satisfaction Techniques Planning
Scheduling Problems, COPLAS.
Muise, C., McIlraith, S. A., & Beck, J. C. (2012). Optimally relaxing partial-order plans
MaxSAT. 22nd International Conference Automated Planning Scheduling,
pp. 358362.
Murata, T. (1989). Petri nets: Properties, analysis applications. Proceedings
IEEE, 77 (4), 541580.
Nebel, B., & Backstrom, C. (1994). computational complexity temporal projection, planning, plan validation. Artificial Intelligence, 66 (1), 125160.
Nebel, B., & Koehler, J. (1995). Plan reuse versus plan generation: theoretical
empirical analysis. Artificial Intelligence, 76 (1-2), 427454.
Nguyen, X., & Kambhampati, S. (2001). Reviving partial order planning. Proceedings
17th International Joint Conference Artificial Intelligence, pp. 459466.
Rintanen, J. (2012). Planning satisfiability: Heuristics. Artificial Intelligence, 193, 4586.
Robinson, N., Gretton, C., Pham, D. N., & Sattar, A. (2010). Partial weighted MaxSAT
optimal planning. 11th Pacific Rim International Conference Artificial
Intelligence, pp. 231243.
Russell, S. J., & Norvig, P. (2009). Artificial intelligence: modern approach. Prentice hall.
Say, B., Cire, A. A., & Beck, J. C. (2016). Mathematical programming models optimizing
partial-order plan flexibility. 22nd European Conference Artificial Intelligence
(In Press).
Siddiqui, F. H., & Haslum, P. (2012). Block-structured plan deordering. Australasian
Conference Artificial Intelligence, pp. 803814.
Tate, A. (1976). Project planning using hierarchic non-linear planner. D.A.I. Research
Report No. 25. Department Artificial Intelligence, University Edinburgh.
Veloso, M. M., Pollack, M. E., & Cox, M. T. (1998). Rationale-based monitoring planning
dynamic environments. 4th International Conference Artificial Intelligence
Planning Systems, pp. 171180.
148

fiOptimal Partial-Order Plan Relaxation via MaxSAT

Weld, D. S. (1994). introduction least commitment planning. AI Magazine, 15 (4),
2761.
Younes, H. L. S., & Simmons, R. G. (2003). VHPOP: versatile heuristic partial order
planner. Journal Artificial Intelligence Research, 20, 405430.

149

fiJournal Artificial Intelligence Research 57 (2016) 229271

Submitted 03/16; published 10/16

Goal Probability Analysis MDP Probabilistic Planning:
Exploring Enhancing State Art
Marcel Steinmetz
Jorg Hoffmann

STEINMETZ @ CS . UNI - SAARLAND . DE
HOFFMANN @ CS . UNI - SAARLAND . DE

Saarland University,
Saarland Informatics Campus,
Saarbrucken, Germany

Olivier Buffet

OLIVIER . BUFFET @ LORIA . FR

INRIA / Universite de Lorraine / CNRS,
Nancy, France

Abstract
Unavoidable dead-ends common many probabilistic planning problems, e.g. actions may fail operating resource constraints. important objective settings
MaxProb, determining maximal probability goal reached, policy
achieving probability. Yet algorithms MaxProb probabilistic planning severely underexplored, extent scant evidence empirical state art actually is.
close gap comprehensive empirical analysis. design explore large space
heuristic search algorithms, systematizing known algorithms contributing several new algorithm variants. consider MaxProb, well weaker objectives baptize AtLeastProb
(requiring achieve given goal probabilty threshold) ApproxProb (requiring compute
maximum goal probability given accuracy). explore general case
may 0-reward cycles, practically relevant special case acyclic planning,
planning limited action-cost budget. design suitable termination criteria, search algorithm variants, dead-end pruning methods using classical planning heuristics, node selection
strategies. design benchmark suite comprising 1000 instances adapted
IPPC, resource-constrained planning, simulated penetration testing. evaluation clarifies
state art, characterizes behavior wide range heuristic search algorithms,
demonstrates significant benefits new algorithm variants.

1. Introduction
Many probabilistic planning problems contain unavoidable dead-ends (e.g. Kolobov, Mausam,
Weld, & Geffner, 2011; Teichteil-Konigsbuch, Vidal, & Infantes, 2011; Kolobov, Mausam, & Weld,
2012; Teichteil-Konigsbuch, 2012), i.e., policy guarantees eventually, circumstances,
attain goal. Examples planning resource constraints limited budget, situations
actions may fail eventually run options. One important objective
MaxProb, determining maximal probability goal reached (and identifying
policy achieving probability). MaxProb also partly underlies International Probabilistic Planning Competition (IPPC) (Younes, Littman, Weissman, & Asmuth, 2005; Bryce & Buffet,
2008; Coles, Coles, Garca Olaya, Jimenez, Linares Lopez, Sanner, & Yoon, 2012), planners evaluated often reach goal online policy execution. (The time limit
IPPC setting mixes MaxProb bias towards policies reaching goal quickly.
c
2016
AI Access Foundation. rights reserved.

fiS TEINMETZ & H OFFMANN & B UFFET

also relates proposals Kolobov et al., 2012 Teichteil-Konigsbuch, 2012, asking
cheapest policy among maximizing goal probability, proposal Chatterjee,
Chmelik, Gupta, & Kanodia, 2015, 2016, asking cheapest policy ensuring target state
reached almost surely partially observable setting.)
consider MDP-based probabilistic planning, factored models (probabilistic extensions
STRIPS) whose state spaces may large build explicitly. focus optimal offline
setting, i.e., solving MaxProb exactly. setup objective certainly relevant,
little work towards developing solvers. main effort made Kolobov et al. (2011),
discuss detail below. Hou, Yeoh, Varakantham (2014) consider several variants
topological VI (Dai, Mausam, Weld, & Goldsmith, 2011), solving MaxProb necessitating
build entire reachable state space. works addressing goal probability maximization
aim guaranteeing optimality (e.g. Teichteil-Konigsbuch, Kuter, & Infantes, 2010; Camacho,
Muise, & McIlraith, 2016).
MDP heuristic search (Barto, Bradtke, & Singh, 1995; Hansen & Zilberstein, 2001; Bonet
& Geffner, 2003b; McMahan, Likhachev, & Gordon, 2005; Smith & Simmons, 2006; Bonet &
Geffner, 2006) potential find optimal policies without building entire state space,
Kolobov et al. (2011) authors addressing optimal MaxProb heuristic search.
Part reason lack research heuristic search MaxProb following two major obstacles. First, MDP heuristic search successful expected-cost minimization,
suffers lack admissible (upper-bounding) heuristic estimators goal probability.
best known possibility detect dead-ends set initial heuristic estimate 0, using
trivial upper bound 1 elsewhere. Second, MaxProb fit stochastic shortest path (SSP)
framework (Bertsekas, 1995), due 0-reward cycles. pointed Kolobov et al. (2011),
MaxProb equivalent non-discounted reward maximization problem, non-goal cycles
receive 0 reward thus improper policies accumulate reward .
address second problem, Kolobov et al. (2011) devised FRET (find, revise, eliminate traps) framework, admits heuristic search, yet requires several iterations complete
searches. heuristic search iterations, FRET eliminates 0-reward cycles (traps). FRET iterates cycles persist. Kolobov et al.s contribution mainly theoretical considering MaxProb much larger class generalized SSPs empirical evaluation
serves merely proof concept. experiment single domain (ExplodingBlocks),
run one configuration search (LRTDP, Bonet & Geffner, 2003b), one possibility
dead-end detection thus non-trivial initial heuristic estimates (SixthSense, Kolobov, Mausam,
& Weld, 2010). outperform value iteration (VI), dead-end detection used
VI, remains unclear extent improvement due actual heuristic search,
rather state pruning itself.
summary, heuristic search MaxProb challenging, addressed
Kolobov et al. (2011), limited experiments. Given this:
(i) actually empirical state art heuristic search MaxProb?
known algorithms, variants thereof, work better?
explore large design space algorithms, show that, indeed, variants work
much better.
(ii) simpler yet still relevant special cases, weaker objectives, may easier
solve?
230

fiG OAL P ROBABILITY NALYSIS P ROBABILISTIC P LANNING

indeed practically relevant cases necessitate FRET, weaker objectives
enable refer early termination.
elaborate first (ii): state space planning task hand acyclic, clearly FRET
needed: cycles particular 0-reward cycles state space
finite, execution end (goal non-goal) absorbing state; implies
within realm SSPs. special case is, however, still practically relevant. illustration,
acyclic state spaces occur even standard IPPC benchmarks, namely TriangleTireworld
domain moves made one direction. importantly, planning limited
action-cost budget, limited-budget planning, acyclic state spaces action costs non-0,
strictly decreasing remaining budget. similar class scenarios every action consumes non-0 amount non-replenishable resource. Another example recently proposed
models simulated penetration testing, per Hoffmann (2015). MDP models network
intrusion point view attacker. state space acyclic exploit
attempted (trying exploit network configuration would
yield outcome). States thus need remember remaining action set, every action
application strictly reduces set.
Regarding weaker objectives: alternatives MaxProb, reasonable ask whether
maximum goal probability exceeds given threshold , require computing maximum goal
probability given accuracy . refer objectives AtLeastProb ApproxProb
respectively.1 example, penetration testing, AtLeastProb naturally assesses level network security: attacker reach target host probability greater given security
margin? E.g., customer data server compromised probability greater 0.01?
AtLeastProb ApproxProb allow early termination based maintaining both, lower (pessimistic) bound V L upper (admissible/optimistic) bound V U . especially promising
AtLeastProb, terminate lower bound already good enough (V L ),
upper bound already proves infeasibility (V U < ). Good anytime behavior, either
bounds, translates early termination.
Let us elaborate (i), exploring state art beyond. design algorithm
space characterized by:
(a) Search algorithm. design variants AO (Nilsson, 1971), LRTDP (Bonet & Geffner,
2003b), depth-first oriented heuristic searches (Bonet & Geffner, 2003a, 2006), maintaining
upper lower bounds early termination.
(b) FRET. design new variant FRET better suited problems uninformative initial
upper bounds.
(c) Bisimulation reduction. design new probabilistic-state-space reduction method, via bisimulation relative all-outcomes determinization (e.g. Bonet & Geffner, 2003b; Yoon, Fern,
& Givan, 2007; Little & Thiebaux, 2007).
1. AtLeastProb relates MDP model-checking, one typically wants validate given PCTL (Probabilistic
Computation Tree Logic) formula valid probability (Baier, Groer, Leucker, Bollig, & Ciesinski, 2004;
Kwiatkowska, Parker, & Qu, 2011a; Kwiatkowska, Norman, & Parker, 2011b). also relates Constrained MDPs
(Altman, 1999), enforcing minimum success probability could expressed constraint particular
quantity. Chance-Constrained POMDPs (Santana, Thibaux, & Williams, 2016) different AtLeastProb
constraint probability remain safe states, reach goal states.

231

fiS TEINMETZ & H OFFMANN & B UFFET

(d) Dead-end pruning method. employ classical-planning heuristic functions dead-end detection probabilistic planning, via all-outcomes determinization, previously done
Teichteil-Konigsbuch et al. (2011). especially promising limited-budget planning,
prune state admissible classical-planning estimate exceeds remaining
budget s.
(e) Node selection strategy. design comprehensive arsenal simple strategies, biasing tie
breaking action state selection manners targeted fostering early termination.
implemented techniques within Fast Downward (FD) (Helmert, 2006), thus contributing, side effect work, ideal implementation basis exploiting classical-planning
heuristic search techniques MDP heuristic search.2
algorithm dimensions (a) (e) orthogonal (excepting dependencies, particular
bisimulation reduction subsumes dead-end pruning). explore behavior resulting
design space large benchmark suite design purpose. suite includes domains
IPPC, resource-constrained planning, penetration testing, limitedbudget version unlimited-budget version. suite comprises 1089 benchmark instances
total.3 Amongst things, observe:
Heuristic search yields substantial benefits, even trivial admissible heuristic setting
initial estimate 1 everywhere (+9% total coverage across benchmarks),
admissible heuristics based dead-end detection (+12%).
Early termination yields substantial benefits (e.g. AtleastProb +8% = 0.2
+7% = 0.9).
FRET variant yields dramatic benefits (+32% total coverage cyclic benchmarks).
Bisimulation reduction yields optimal MaxProb solver excells TriangleTireworld,
even surpassing Prob-PRP (Muise, McIlraith, & Beck, 2012; Camacho et al., 2016)
standard version goal achieved certainty hence
Prob-PRP optimal, also limited-budget version so.
side, discover landmarks compilation per Domshlak Mirkis (2015), employed
dead-end pruning oversubscription planning setting, actually, own, equivalent
pruning remaining budget standard admissible landmark heuristic.
relevant work because, otherwise, compilation would canonical candidate also
dead-end pruning setting (indeed started investigation).
paper organized follows. Section 2 describes model syntax semantics, goal
probability analysis without action-cost budget limit. Section 3 specifies search
algorithm (a) FRET variants (b). Section 4 describes bisimulation reduction method (c).
Section 5 describes dead-end pruning methods (d), Section 6 describes node selection
strategies (e). present experiments Section 7, conclude Section 8.
two appendices giving additional technical details sketch main text, Appendix B
2. source code available http://fai.cs.uni-saarland.de/downloads/fd-prob.tar.bz2
3.
benchmark
suite

available

http://fai.cs.uni-saarland.de/downloads/
ppddl-benchmarks-acyclic.tar.bz2 (acyclic cases) http://fai.cs.uni-saarland.
de/downloads/ppddl-benchmarks-cyclic.tar.bz2 (cyclic cases).

232

fiG OAL P ROBABILITY NALYSIS P ROBABILISTIC P LANNING

regarding Domshlak Mirkis (2015) landmarks compilation, Appendix regarding depthfirst oriented heuristic searches. 4

2. MDP Models
consider PPDDL-style models (Younes et al., 2005), precisely probabilistic extensions
STRIPS. employ two formalism variants, without limited action-cost budget.
specify first unlimited-budget version. Planning tasks tuples = (F, A, I, G) consisting
finite set F facts, finite set actions, initial state F , goal G F .
pair (pre(a), O(a)) pre(a) F precondition, O(a) finite set
outcomes o. O(a) tuple (p(o), add (o), del (o))
P outcome probability p(o), add list
add (o) F , delete list del (o) F . require oO(a) p(o) = 1.
Given task , state space probabilistic transition system (S, P, I, S> ). Here,
set states, associated set F (s) true facts. initial state .
set goal states S> contains G F (s). Transitions, transition
probability function P : 7 [0, 1], defined follows. Action applicable state
pre(a) F (s) 6 S> (goal states absorbing, see also below). A[s] denote
set actions applicable s. Given s, A[s], outcome O(a), sJoK denote
result outcome s, i.e., F (sJoK) := (F (s) add (o)) \ del (o). define P (s, a, t) := p(o)
applicable = sJoK.5 Otherwise, define P (s, a, t) := 0 (there transition).
Absorbing states outgoing transitions (no applicable actions). set non-goal
absorbing states lost states denoted .
limited-budget planning, extend follows. limited-budget task tuple
= (F, A, I, G, b), including also budget b R+
0 , associating
.

addition


true
facts
F
(s),
states also
action outcome cost c(o) R+
0
associated remaining budget b(s) R. States negative remaining budget b(s) < 0
legal may occur, lost, , due following definitions goal states,
action applicability, transitions. goal states S> G F (s)
b(s) 0, i.e., must reach goal 0 remaining budget. actions applicable
pre(a) F (s) least one outcome fits within remaining budget, i.e.,
exists O(a) c(o) b(s). outcome states sJoK, outcomes cost deduced
remaining budget, i.e., b(sJoK) := b(s) c(o).
notes order regarding limited-budget planning. c(o) > 0 o, state
space viewed directed graph arc (s, t) whenever action mapping
non-0 probability acyclic every transition strictly reduces remaining budget.
state space infinite due continuous state variable b(s), reachable part (which
algorithms consider) finite. Note remaining budget local state.
states policy violate budget, parts policy (even outcomes
action) still continue trying reach goal. differs constrained MDPs (Altman,
1999), budget bound applied globally expected cost policy. Also note
4. paper extension previous conference paper (Steinmetz, Hoffmann, & Buffet, 2016). cover larger
space algorithms (now including depth-first oriented heuristic searches), provide comprehensive explanations
discussions, present experiments detail.
5. assume O(a) leads different outcome state. simplify notation (our
implementation make assumption).

233

fiS TEINMETZ & H OFFMANN & B UFFET

that, single budget considered sake simplicity, framework results
straightforwardly extend models multiple budget variables.
Limited-budget planning explored deterministic oversubscription setting, objective maximize reward achieved (soft) goals subject budget (Domshlak
& Mirkis, 2015). classical-planning variant would relate resource-constrained planning (e.g.
Haslum & Geffner, 2001; Nakhost, Hoffmann, & Muller, 2012; Coles, Coles, Fox, & Long, 2013)
single consumed resource. probabilistic variant previously considered
Hou et al. (2014). Prior work probabilistic planning resources (e.g. Marecki &
Tambe, 2008; Meuleau, Benazera, Brafman, Hansen, & Mausam, 2009; Coles, 2012) often
assumed limited budgets non-0 consumption, dealt uncertain-continuous resource
consumption, contrast discrete fixed budget consumed action costs.
Though relatively restricted, limited-budget probabilistic planning quite natural. Decision
making often constrained finite budget. Furthermore, non-0 costs often reasonable
assume. applies to, example, penetration testing. Problems asking achieve goal within
given number steps, e.g. finite-horizon goal probability maximization, special case.
Let us define solutions planning tasks, well objectives wish
achieve. policy partial function : \ (S> ) 7 {}, mapping non-absorbing
state within domain either action applicable s, dont care symbol .
symbol used (only) policies already achieve sufficient goal probability elsewhere,
need elaborate act descendants. is, still require closed
policies (see below), use explicitly indicate special cases actions may chosen
arbitrarily. Formally, (s) = extends domain picking, every 6 S> reachable
(t) undefined, arbitrary action applicable setting (t) := a.
policy closed state if, every state 6 S> reachable , (t)
defined. closed closed initial state I. proper if, every state
defined, eventually reaches absorbing state probability 1.6
Following Kolobov et al. (2011), formulate goal probability maximal non-discounted
expected reward reaching goal gives reward 1 rewards 0. value
V (s) policy closed state is:

S>
1

V (s) = 0P
(1)


P (s, (s), t)V (t) otherwise
optimal value state
V (s) =

max

: closed

V (s)

(2)

Observe that, difference Kolobov et al. consider problems general MaxProb, dont need exclude improper maximization.
negative rewards, i.e., policies cannot gain anything infinite cycles.
Given value function V (any function mapping states R), Bellman update operator
defined, usual, maximization actions relative current values given V :
6. Keep mind absorbing states setting S> , i.e., goal states lost states. SSP
policy considered valid executions end goal state finding shortest path
implies path exists MaxProb policy valid executions end absorbing (goal non-goal)
state executions may fail, need always terminate.

234

fiG OAL P ROBABILITY NALYSIS P ROBABILISTIC P LANNING


S>
1

V (s) := 0
P

maxaA[s] P (s, a, t)V (t) otherwise

(3)

difference V (s) prior update, updated value according right-hand
side, called Bellman residual.
greedy policy value function V selects non-absorbing state action obtaining maximum right-hand side equation (note greedy policy unique
tie-breaking). refer state space subgraph induced states reachable
using greedy policy -greedy graph. V -greedy graph, refer
state space subgraph induced states reachable greedy policy V , i.e.,
allowing state choose action greedy V .
acyclic state spaces, every run ends absorbing state finite number steps,
facing SSP problem (subject definition absorbing states, cf. above)
Bellman update operator unique fixed point V , converges initial V .
cyclic state spaces, pointed Kolobov et al. (2011), Bellman update operator may
multiple sub-optimal fixed points, updates optimistic (upper-bound) initialization
V guaranteed converge optimum V . One either use pessimistic (lowerbound) initialization V , updates guaranteed converge V ; one use
Kolobov et al.s FRET method described earlier.
consider three different objectives (algorithmic problems) goal probability analysis:
MaxProb: Find optimal policy, i.e., closed s.t. V (I) = V (I).
AtLeastProb: Find policy guaranteeing user-defined goal probability threshold [0, 1], i.e.,
closed s.t. V (I) . (Or prove exist.)
ApproxProb: Find policy optimal user-defined goal probability accuracy [0, 1], i.e.,
closed s.t. V (I) V (I) .
define algorithm family addressing problems. cover search algorithms, bisimulation reduction, dead-end pruning, node selection strategies, order.

3. Search Algorithms
use value iteration (VI) baseline. design variants AO LRTDP, well family
depth-first oriented heuristic searches, systematizing algorithm parameters underlying improved
LAO (here: ILAO ) (Hansen & Zilberstein, 2001), heuristic dynamic programming (Bonet &
Geffner, 2003a), learning depth-first search (Bonet & Geffner, 2006). furthermore design
variant FRET better suited problems uninformative initial upper bounds.
3.1 VI
pre-process VI, make one forward pass building reachable state space (actually
pruned subgraph, see Section 5). initialize value function pessimistically, simply 0
everywhere. acyclic cases, perform single backward pass Bellman updates, starting
absorbing states updating children parents, thus computing optimal value function
updating every state exactly once.
235

fiS TEINMETZ & H OFFMANN & B UFFET

procedure GoalProb-AO
initialize consist I; Initialize(I)
loop
[MaxProb: V L (I) = 1]
[AtLeastProb:V L (I) ]
[ApproxProb: V L (I) 1 V U (I) V L (I) ]
return L endif /* early termination (positive) */
[AtLeastProb: V U (I) < ]
return impossible endif /* early termination (negative) */
ex. leaf state 6 S> reachable using U
select state
else return U endif /* regular termination */
P (s, a, t) > 0
already contained
insert child ; Initialize(t)
else insert new parent
endif
endfor
BackwardsUpdate(s)
endloop
procedure
Initialize(s):
0
U
V (s) :=
1 otherwise
1 S>
L
V (s) :=
0 otherwise
6 S> L (s) := endif

Figure 1: AO* search MaxProb, AtLeastProb, ApproxProb (as indicated), acyclic state
spaces. U current greedy policy V U , L current greedy policy V L .
BackwardsUpdate(s) procedure updates V U , U , V L , L . states may
several parents , first make backwards sweep collect sub-graph |s ending
(to update V U U , greedy sub-graph V U suffices). update |s
reverse topological order.
general/cyclic case, assume convergence parameter (likewise algorithms addressing case), compute -consistent value function, Bellman
residual every state . efficient value iteration, employ topological VI per
Dai et al. (2011): find strongly connected components (SCC) state space, handle
SCC individually, children SCCs parent SCCs. VI SCC stops every state
-consistent.
Dai et al. (2011) also introduce focused topological VI, eliminates sub-optimal actions
pre-process obtain smaller SCCs. much runtime-effective, still
requires building entire state space. experiments, runtime/memory exhaustion
process, i.e., building state space, reason VI failures.
consider focused topological VI here.
3.2 AO
AO , restrict acyclic case, overhead repeated value iteration
fixed points, inherent LAO (Hansen & Zilberstein, 2001), disappears. (The ILAO variant,
236

fiG OAL P ROBABILITY NALYSIS P ROBABILISTIC P LANNING

issue addressed depth-first orientation, covered part
depth-first oriented heuristic search family introduced Section 3.4 below.)
Figure 1 shows pseudo-code GoalProb-AO variant. algorithm incrementally constructs subgraph state space. handling duplicates simple, identifying search
nodes states, state space acyclic. reason, simple backward updating
suffices maintain value function. Adopting ideas prior work (e.g. McMahan et al., 2005;
Little, Aberdeen, & Thiebaux, 2005; Smith & Simmons, 2006; Kuter & Hu, 2007), maintain
two value functions, namely upper bound V U lower bound V L goal probability.
lack heuristic estimators goal probability, value functions initialized trivially,
1 V U 0 V L , except absorbing states exact value known. (Dead-end
detection, simple non-trivial V U initialization, discussed Section 5.) Nevertheless,
bounds useful search, early termination (V L V U ), detecting
sub-optimal parts state space (V U ). observe latter, note that, refute action a,
may suffice reduce V U one outcomes. Hence, even trivial initialization, V U
may allow disregard parts search space, usual way admissible heuristic functions.
shall see, kind behavior occurs frequently practice (as reflected benchmarks).
Regarding early termination, lower bound enables positive early termination
already guarantee sufficient goal probability, namely 1 (MaxProb), (AtLeastProb), 1 (ApproxProb). upper bound enables negative early termination AtLeastProb, V U (I) < .
ApproxProb, clearly terminate V U (I) V L (I) . relevant observation
V L (I) = 1 (MaxProb) V L (I) 1 (ApproxProb) criteria redundant
maintaining upper bound, i.e., heuristic search: V L (I) 1 , trivially also
V U (I) V L (I) . V L (I) = 1, search branch achieving goal certainty,
V U (I) = 1 well search terminates regularly. configurations maintaining V U ,
however, criteria useful reduce search.
correctness GoalProb-AO easy establish. standard properties Bellman
updates, point time execution algorithm, state ,
V L (s) V (s) V U (s), i.e., V L V U lower respectively upper bounds goal
probability. Indeed, bounds monotone (Bertsekas & Tsitsiklis,
1996), precisely, V L
P
U
L
V exact absorbing states, satisfy V (s) maxaA[s] P (s, a, t)V L (t) respectively
P
V U (s) maxaA[s] P (s, a, t)V U (t) non-absorbing ones. V L V U
initialized functions trivially satisfying properties, properties invariant
Bellman updates non-absorbing states (given monotonicity, V L grow, V U
decrease). Thanks monotonicity, arguments given LAO (Hansen &
Zilberstein, 2001), get V U converges V finite time U -greedy graph.
Finally, need prove that, case early termination returning L , greedy policy L
V L actually achieves want, i.e., (1) L closed (2) L provides sufficient goal
L
probability, i.e., V (I) V L (I). (1), L always closed policy, applies
dont care symbol non-absorbing leaf states . (Note also applied L
L
states.) (2), show that, states s, V (s) V L (s).
claim trivial states L (s) = , never updated V L (s) = 0.
states s, claim follows simple inductive reasoning maximal distance
L
absorbing state L -greedy graph. absorbing states s, V (s) = V L (s) = V (s),
P
L
L
claim trivially satisfied. induction step, V (s) = P (s, L (s), t)V (t)
L
L
definition V , while, induction hypothesis, V (t) V L (t) states
237

fiS TEINMETZ & H OFFMANN & B UFFET

procedure GoalProb-LRTDP
:= {I}; Initialize(I)
loop
[early termination criteria exactly GoalProb-AO ]
labeled solved
LRTDP-Trial(I)
else return U endif /* regular termination */
endloop
procedure LRTDP-Trial(s):
P := empty stack
labeled solved
push onto P
S> break endif
[cyclic: -consistent break endif]
P (s, a, t) > 0
6 Initialize(t) endif
endfor
update V U (s), U (s), V L (s), L (s)
:= sample according P (s, U (s), t)
endwhile
P empty
pop P
[acyclic: CheckSolved(s, 0) break endif]
[cyclic: CheckSolved(s, ) break endif]
endwhile

Figure 2: LRTDP MaxProb, AtLeastProb, ApproxProb, acyclic general (cyclic) state
spaces. U current greedy policy V U , L current greedy policy V L .
CheckSolved(s, ) procedure exactly specified Bonet Geffner (2003b).
visits states reachable using U , initializing previously visited, stopping
-consistent. performs updates bottom-up, labeling solved iff
descendants -consistent. change update V L L along V U
U .
P
L
P (s, L (s), t) > 0, words V (s) P (s, L (s), t)V L (t). plugging
definition L (s), using monotonicity property, easy conclude
L
V (s) V L (s), desired.
3.3 LRTDP
Figure 2 shows pseudo-code GoalProb-LRTDP variant, applicable general case (cyclic
well acyclic problems). assume that, cyclic cases, algorithm run within FRET
framework. main change original version LRTDP consists maintaining lower
bound addition upper (optimistic) bound, adding early termination criteria
GoalProb-AO . Correctness early termination follows arguments before, i.e.,
V L (s) V U (s) monotone lower respectively upper bounds, L always closed policy.
Note true even general/cyclic case, i.e., early termination applies,
terminate overall FRET process.
change make additional stopping criterion trials cyclic case,
namely current state -consistent. Kolobov et al. (2011) use criterion keep trials
238

fiG OAL P ROBABILITY NALYSIS P ROBABILISTIC P LANNING

procedure GoalProb-DFHS
:= {I}
loop
[early termination criteria exactly GoalProb-AO ]
(Label labeled solved)
(VI U changed running VI U -greedy graph)
DFHS-Exploration(I)
clean visited-markers
else return U endif /* regular termination */
endloop
procedure DFHS-Exploration(s):
6 Initialize(s) endif
S> labeled solved
label solved
return
endif
f lag :=
FW
V U (s) -consistent f lag := > endif
update V U (s), U (s), V L (s), L (s)
Consist f lag return > endif
endif
mark visited
foreach P (s, U (s), t) > 0
visited f lag := DFHS-Exploration(t) f lag endif
done
f lag FW
V U (s) -consistent f lag := > endif
update V U (s), U (s), V L (s), L (s)
endif
Label f lag label solved endif
return f lag

Figure 3: Depth-First Heuristic Search (DFHS) acyclic MaxProb, AtLeastProb, ApproxProb. cyclic version shown Appendix uses Tarjans SCC procedure
instead depth-first search. VI, Label, FW, Consist Boolean algorithm parameters (see text). Recall U -greedy graph set states reachable using
current greedy policy U . f lag returned DFHS-Exploration used inside
recursion (it ignored top-level calls), decide whether backward-update
state forward-updates use.

getting trapped 0-reward (non-goal) cycles. criterion preserves property that, upon
regular termination, states reachable using U -consistent.7

cyclic case, V U fixed point found LRTDP may sub-optimal, use
FRET. acyclic case, use = 0, single call LRTDP suffices.
239

fiS TEINMETZ & H OFFMANN & B UFFET

3.4 Depth-First Heuristic Search
finally consider systematic heuristic searches (not based trials like LRTDP) strong
depth-first orientation. Intuitively, orientation especially beneficial context
likely lead absorbing states, thus states non-trivial heuristic function initialization,
quickly. refer algorithms Depth-First Heuristic Search (DFHS). Known instances
ILAO (Hansen & Zilberstein, 2001),8 heuristic dynamic programming (HDP) (Bonet & Geffner,
2003a), learning depth-first search (LDFS) (Bonet & Geffner, 2006). commonality lies
conducting depth-first searches (DFS) state-space subgraph defined actions greedy
current upper bound V U , updated backwards DFS, termination criterion applies. algorithms differ depth-first branches terminated, overall algorithm
terminated, whether updates also performed forward direction. Here, systematize parameters, obtaining DFHS algorithm family containing previous algorithms
family members.
Figure 3 gives pseudo-code description DFHS algorithm family. simplicity,
figure considers acyclic problems only. cyclic problems, instead DFS algorithms use
Tarjans depth-first SCC algorithm (Tarjan, 1972), order detect SCCs time
exploration updates, suggested Bonet Geffner (2003a). (Knowing
SCCs required correct solved-labeling general case.) pseudo-code description
DFHS algorithm family general (cyclic) case given Appendix A.
algorithms search U -greedy graph. variant would instead search V U greedy graph. variant, employed LDFS, effective goal probability analysis
V U 1 everywhere initially, V U -greedy graph entire (dead-end pruned) reachable
state space. hence omit option, therewith LDFS, DFHS family (matters may
change better admissible heuristic functions identified future work, cf. Section 8).
algorithms update values backward direction, leaving state. FW algorithm
parameter true, value updates done also forward direction, entering state.
consistently yields (small) advantages empirically, switch FW true algorithm
configurations, except one corresponding known algorithm ILAO use
technique. Detecting whether optimal solution found done two ways: (1)
Label, maintaining solved-labels DFS; (2) VI, running value iteration U greedy graph DFS terminated. (1), U optimal initial state labeled solved.
(2), one terminate greedy policy change VI. use forward updates,
(as already check Bellman residual anyway) additional option Consist
stop search -inconsistent states, opposed stopping absorbing states. Overall,
run 5 different parameter settings DFHS, overviewed Table 1.
Correctness early termination follows arguments before.
correctness regular termination, need show fixed point policy obtained, i.e., upon
regular termination, (*) U -greedy graph contains -inconsistent states. holds
algorithm variants fit Bonet Geffners (2003a) Find-and-Revise schema finite state
space monotone optimistic bound, (1) search iteration find update
7. updates trials are, difference original LRTDP formulation, related trial-stopping guarantee
goal probability maximization. turn consistently yield (small) advantages empirically, keep
here.
8. brief description ILAO Hansen Zilberstein (2001) thus depth-first orientation subject
interpretation. design follows Bonet Geffner (2005) mGPT tool.

240

fiG OAL P ROBABILITY NALYSIS P ROBABILISTIC P LANNING

Acronym
DFHSVI
DFHSFwd
VI
DFHSFwdCons
VI
DFHSFwd
Lab
DFHSFwdCons
Lab

Termination
VI
VI
VI
Label
Label

FW?

yes
yes
yes
yes

Cons?


yes

yes

Known?
yes: ILAO (Hansen & Zilberstein, 2001)
no: new variant
no: new variant
no: new variant
yes: HDP (Bonet & Geffner, 2003a)


Table 1: Depth-First Heuristic Search (DFHS) family overview. include LDFS (Bonet
& Geffner, 2006) as, due considering V U -greedy graph rather U -greedy
graph, LDFS work well MaxProb (see text).
least one -inconsistent state, (2) condition (*) met. Given depth-first search (respectively
Tarjans algorithm, general case) clear (1) holds true. Regarding (2), obvious
VI termination option used;9 holds Label termination option state
labeled solved descendant states U -greedy graph -consistent.
done Table 1, usually omit GoalProb- algorithm names. Keep mind
though algorithms differ original ones, particular terms early termination
depends objective MaxProb, AtLeastProb, ApproxProb. study termination
benefits lower vs. upper bound, switch bound individually.
X denotes one search algorithms, denote X|U X|L variants X maintaining
V U respectively V L . sometimes write X|LU make explicit bounds
used. Early termination criteria involving non-maintained bound disabled. X|U ,
leaves negative criterion V U (I) < AtLeastProb; X|L still positive criteria.
test version X|L X=AO , canonical representative (non-VI) blind search.
AO |L , non-absorbing leaf states open (rather reachable using U ),
case regular termination return L .
3.5 FRET
previously hinted, Kolobov et al.s (2011) FRET performs iteration complete searches.
starts upper-bound approximation V U V , continuously updated throughout
FRET process. Within FRET iteration, heuristic search algorithm runs termination,
i.e., finding fixed point policy. iterations, FRET runs trap elimination
step, finds traps V U -greedy graph. FRET forces next search iteration
include traps. FRET terminates V U -greedy graph contain trap.
trap elimination step works follows. trap subset non-absorbing states
greedy policy remain indefinitely, i.e., outgoing transitions V U -greedy
graph lead another trap state . trap removed collapsing states
single state sT . incoming transitions sT incoming state ,
outgoing transitions transitions -states exiting (note transitions are,
construction, contained V U -greedy graph).
transformation obviously prevents occuring later iterations. preserves

V trap states identical V values: trap states non-absorbing reach
other, states reach 0-reward transitions (note holds regardless
9. Note that, acyclic case, full VI actually needed algorithm could simplified. leave way
here, used ILAO general case, simplicity presentation.

241

fiS TEINMETZ & H OFFMANN & B UFFET

V U , i.e., holds also parts state space V U yet converged).
finite number possible traps state space, FRET eventually finds V U whose V U greedy graph contain trap. graph, V U -greedy policy extracted,
contain traps, hence proper trap-collapsed state space, hence optimal
state space. optimal policy original task constructed acting, within
collapsed traps, way exit taken eventually reached certainty. (This
correctness argument given Kolobov, 2013.)
new variant FRET differs original version terms state space
subgraph considered: instead V U -greedy graph, use U -greedy graph, i.e., consider
actions selected current greedy policy (cf. discussion DFHS above).
refer design FRET- U , refer Kolobov et al.s (2011) design FRET-V U .
easy see FRET- U still correct. arguments remain intact stated.
FRET-V U potentially eliminates traps iteration, may hence require fewer iterations. Yet traps may actually need eliminated (we might eventually find optimal
policy entering them), trap elimination step may much costly. particular,
goal probability analysis, FRET-V U typically ineffective because, similarly discussed
DFHS, first FRET step V U often 1 almost everywhere, V U -greedy graph
almost entire reachable state space. shall see, FRET- U clearly outperforms FRET-V U .

4. State-Space Reduction via Determinized Bisimulation
Bisimulation known method reduce state space size MDPs/probabilistic planning (e.g.
Dean & Givan, 1997). idea essentially group equivalent sets states together block
states, solve smaller MDP block states. Here, observe approach fruitfully combined state-of-the-art classical planning techniques, namely mergeand-shrink heuristics (Drager, Finkbeiner, & Podelski, 2009; Helmert, Haslum, Hoffmann, & Nissim, 2014), allow effectively compute bisimulation determinized state space.
Determinized-bisimilar states bisimilar probabilistic state space well, identifies practical special case probabilistic bisimulation given factored (STRIPS-like) problem
specification.
Let us spell little detail. Given task (with without budget limit),
probabilistic bisimulation partitioning P = {B1 , . . . , Bn } state set that,
every Bi Bj , every action a, every s, Bi , following two properties satisfied
(Dean & Givan, 1997):
(i) applicable iff applicable t;
P
P
(ii) applicable t, oO(a),sJoKBj p(o) = oO(a),tJoKBj p(o).
Dean Givan show optimal solution bisimulation MDP induces optimal
solution MDP itself. words, suffices work block states Bi .
Now, denote det all-outcomes determinization (e.g. Yoon et al., 2007; Little
& Thiebaux, 2007), separate action adet
every O(a), inheriting preo
condition os adds, deletes, cost. determinized bisimulation partitioning
P = {B1 , . . . , Bn } states that, every Bi Bj , every determinized action adet
,
every s, Bi , following two properties satisfied (Milner, 1990; Helmert et al., 2014):
det
(a) adet
applicable iff ao applicable t;

242

fiG OAL P ROBABILITY NALYSIS P ROBABILISTIC P LANNING

det
det
(b) adet
applicable t, sJao K Bj iff tJao K Bj .

easy see {B1 , . . . , Bn } also probabilistic bisimulation . Since action
adet
applicable state iff corresponding action original MDP applicable s,
(a) directly implies (i). (b), know every action applicable s, t,
det
outcome O(a), sJadet
K Bj iff tJao K Bj . obviously implies (ii);
restrictive needed insists subset outcomes sides, rather
summed-up probability same.
compute determinized bisimulation ? nave solution build state
space front computing determinized bisimulation it. One potentially much
better though, using merge-and-shrink widely employed shrinking strategies based
bisimulation (Nissim, Hoffmann, & Helmert, 2011; Katz, Hoffmann, & Helmert, 2012; Helmert
et al., 2014). nutshell, algorithm framework constructs abstraction starting
collection abstractions considering single state variable only, iteratively merging
two abstractions (replacing synchronized product) single abstraction
left, shrinking abstractions bisimulation thereof every merging step.
shall see experiments, often still incurs prohibitive overhead, feasible,
lead substantial state space size reductions. cases, results tremendous performance
improvements.

5. Dead-End Pruning
refer states V (s) = 0, i.e., goal cannot reached s, dead-ends.
one detects via dead-end detection technique, one treat exactly like lost
state (except setting L (s) := need act non-absorbing states). constitutes
pruning method itself, useful search algorithm, state space needs
longer explored. Apart pruning itself, heuristic search algorithms, dead-end
detection provides non-trivial initialization V U , initialize V U (s) = 0 instead
V U (s) = 1 detected dead-end. informed initial upper bound typically
leads additional search reductions.
detect dead-ends? Kolobov et al. (2011) employ SixthSense (Kolobov et al., 2010),
learns dead-end detection rules generalizing information obtained using classical planner. instead exploit power classical-planning heuristic functions readily
available FD implementation framework run all-outcomes determinization.
especially promising limited-budget planning, use lower bounds determinized
remaining cost detect states insufficient remaining budget. Observe natural
effective using admissible remaining-cost estimators, yet would impractical using actual classical planner (which would need optimal thus prohibitively slow). unlimited-budget
case, use heuristic function able detect dead-ends (returning ), applies
known heuristics. Indeed, merge-and-shrink heuristics recently shown extremely competitive dead-end detectors (Hoffmann, Kissmann, & Torralba, 2014).
make concrete, consider state task , denote det alloutcomes determinization . Let h classical-planning heuristic function. h guarantees
return dead-ends, h(s) = det , exists sequence action
outcomes achieving goal s, V (s) = 0. limited-budget task, h admissible,
h(s) > b(s), cannot achieve goal within budget, thus also V (s) = 0.
243

fiS TEINMETZ & H OFFMANN & B UFFET

experiment state-of-the-art heuristic functions, namely (a) admissible landmark
heuristic per Karpas Domshlak (2009), (b) LM-cut (Helmert & Domshlak, 2009), (c) several
variants merge-and-shrink heuristics, (d) hmax (Bonet & Geffner, 2001) simple
canonical option. (a) turned perform consistently worse (b), report
(b) (d).
limited-budget planning, also considered adopting problem reformulation Domshlak Mirkis (2015) oversubscription planning, reduces budget b using landmarks
exchange allows traversing yet unused landmarks reduced cost search. turns
out, however, pruning states whose reformulated budget < 0 equivalent much simpler method pruning states whose heuristic (a) exceeds (original/not reformulated) remaining
budget. added value Domshlak Mirkis reformulation thus lies, pruning per se,
compilation planning language resulting combinability heuristics.
give full details Appendix B. get intuition Domshlak Mirkis reformulation
is, per se, equivalent (a), assume simplicity L set disjoint disjunctive action landmarks initial state, assume actions unit costs. Say prune reduced budget, b0 (s), < 0. reduced initial budget b0 := b|L|. reduced costs allow applying member actions yet non-used landmarks 0 cost, non-used landmarks given search
path l L touched path. Consider state reached path ~a. Denote
non-used landmarks L0 . cost saved ~a thanks reformulation exactly
used landmarks, |L\L0 |. Hence b0 (s) = b0 (|~a||L\L0 |) = (b|L|)|~a|+|L\L0 | = b|~a||L0 |.
pruned reformulation, b0 (s) < 0, iff b |~a| |L0 | < 0 iff b |~a| < |L0 |. latter
condition, however, exactly pruning condition using simple method (a) instead.

6. Node Selection Strategies
algorithms, good anytime behavior V L and/or V U may translate early termination.
explore potential fostering via (1) biasing tie-breaking selection best
actions U greedy respect V U , (2) biasing, respectively, outcome-state sampling
trials (LRTDP) choice expanded leaf states (AO ). precise regarding
latter: usual, maintain state open flags AO , true state open descendants within
U -greedy graph. select leaf state expand going forward using U ,
action one open outcome state t, select best according bias (2). Note
(2) relevant DFHS, every iteration DFS explores outcomes anyhow.
Hence, DFHS, use U tie-breaking criteria (1) explained follows.
experimented variety strategies. follows, strategy specifies one
(1) (2) only, setting default strategy. strategy corresponds
commonly used settings. uses arbitrary tie-breaking (1), fixed manner, changing
U (s) action becomes strictly better s, suggested Bonet Geffner
(2003b) LRTDP. bias (2) outcome states AO (an open outcome state selected
arbitrarily). Bias (2) LRTDP outcome probability. also tried most-prob-outcome
bias strategy AO , likely open outcome state selected.
h-bias strategy prefers states smaller h value, heuristic h one
used dead-end pruning.10 Specifically, action selection tie-breaking (1), actions
10. also experimented strategy using merge-and-shrink determinized action costs set negated
logarithm outcome probability (compare e.g. Jimenez, Coles, & Smith, 2006). compelling theory

244

fiG OAL P ROBABILITY NALYSIS P ROBABILISTIC P LANNING

P
U
maximizing optimistic expected
Pgoal probability P (s, a, t)V (t), select minimizing expected heuristic value P (s, a, t)h(t). outcome-state bias (2) obtained
1
renormalizing weighed probabilities h(t)
P (s, a, t), prefer high probability outcomes
small h value.
Inspired BRTDP (McMahan et al., 2005), experiment gap-bias strategy, biasing
U
L
search towards states large
Precisely, (1) break ties favor actions
PV V gaps.
maximizing expected gap P (s, a, t)[V U (t)V L (t)], (2) renormalize weighed
probabilities [V U (t) V L (t)] P (s, a, t).
Inspired common methods classical planning (e.g. Hoffmann & Nebel, 2001; Helmert,
2006; Richter & Helmert, 2009), experiment preferred actions strategy, (1)
U (s) action participating delete-relaxed determinized plan s,
prefers set P
maximizing P (s, a, t)V U (t) exists.
AO |L special case, maintain upper bound thus selection
(1) actions U greedy respect V U . apply node selection strategies (2) directly
set (all) leaf states current search graph . default strategy depth-first,
rationale try reach absorbing states quickly. h-bias strategy selects deepest leaf
minimal h value, preferred actions strategy selects deepest open leaf reachable using
preferred actions. furthermore experiment breadth-first strategy, comparison.

7. Experiments
implemented algorithms Fast Downward (FD) (Helmert, 2006), ran experiments
extensive suite benchmarks.11 evaluation first summarize results acyclic
benchmarks (where FRET needed), ones cyclic benchmarks (where FRET
needed).
7.1 Experiments Setup
start giving details implementation describing benchmark suite used
experiments.
7.1.1 MPLEMENTATION
model pertains goal-directed MDPs limited number (explicitly listed) outcomes
per action, naturally use PPDDL (Younes et al., 2005), rather RDDL (Sanner, 2010; Coles
et al., 2012), surface-level language. FDs pre-processes extended handle PPDDL,
added support specifying (numeric) budget limit.
Given FD implementation framework contrast previous works optimal probabilistic
planning, implemented algorithms scratch. FRET, closely followed original
implementation, details specified Kolobov et al. (2011), based personal communication Andrey Kolobov. (Kolobovs original source code available anymore, also
plays role state-of-the-art comparison, see next.)
because, then, bisimulation-based heuristic corresponds exact goal probability best outcome sequence
state. Yet, already pointed out, computing heuristic often infeasible.
11. source code available online appendix, downloaded http://fai.cs.unisaarland.de/downloads/fd-prob.tar.bz2

245

fiS TEINMETZ & H OFFMANN & B UFFET

Given scant prior work optimal goal probability analysis (cf. Section 1), state art
represented topological VI, LRTDP|U dead-end pruning acyclic problems,
FRET-V U using LRTDP|U dead-end pruning cyclic problems. configurations
particular points space configurations explore, comparison state art
part comparison across configurations. thing missing particular form
dead-end detection, SixthSense prior work, Kolobov et al. (2011).
SixthSense complex method advanced dead-end pruning via heuristic functions readily
available framework, re-implement SixthSense. discussion cyclic problems
Section 7.3 includes detailed comparison results Kolobov et al.,
IPPC ExplodingBlocks domain Kolobov et al. considered.
Note providing quality guarantees important property study. reason,
sake clarity, compare unbounded suboptimal approaches,
using algorithm discounted criterion assigning large finite penalties dead-ends
(Teichteil-Konigsbuch et al., 2011; Kolobov et al., 2012).
Furthermore, AtLeastProb special case MDP model checking, one may wonder
probabilistic model checking tools, e.g. PRISM (Kwiatkowska et al., 2011b), would fare
problem planning benchmarks. investigate question here, would entail
translation PPDDL model checking language, non-trivial makes direct
comparison algorithms taking different inputs problematic. One may speculate that, given
focus blind searches, model checking tools inferior heuristic search approaches
fare well; remains question future work.
7.1.2 B ENCHMARK UITE
aim comprehensively explore relevant problem space, designed broad suite
benchmarks, 1089 instances total, based domains IPPC, resource-constrained
planning, penetration testing (pentesting).
IPPC, selected PDDL domains STRIPS format, moderate nonSTRIPS constructs easily compilable STRIPS. resulted 10 domains IPPC04
IPPC08; selected recent benchmark suite these.
resource-constrained planning, adopted NoMystery, Rovers, TPP benchmarks
Nakhost et al. (2012), precisely suites single consumed resource (fuel, energy, money), correspond limited-budget planning.12 created probabilistic versions
adding uncertainty underlying road map, akin Canadian Traveler scenario,
road segment present given probability (this encoded separate, probabilistic, action attempting segment first time). simplicity, set probability 0.8
throughout.
pentesting, general objective using exploits compromise computers network, one another, specific targets reached (or action available). modified
POMDP generator Sarraute, Buffet, Hoffmann (2012), based test scenario used Core Security (http://www.coresecurity.com/) output PPDDL encodings
Hoffmanns (2015) attack-asset MDP pentesting models. models, network configura12. make benchmarks feasible optimal probabilistic planning, reduce size parameters (number
locations etc). scaled parameters number < 1, chosen get instances borderline
feasibility VI.

246

fiG OAL P ROBABILITY NALYSIS P ROBABILISTIC P LANNING

tion known fixed, exploit callable succeeds (or fails) probability. generator uses network consisting exposed part, sensitive part, user part.
allows scale numbers H hosts E exploits. Sarraute et al.s POMDP model
solver (SARSOP, see Kurniawati, Hsu, & Lee, 2008, guarantee optimality) scale
H = 6, E = 10.13 benchmarks, fixed H = E simplicity (and obtain number
instances similar benchmark domains). scaled instances 6 . . . 20 without
budget limit, 10 . . . 24 budget limit.
benchmark tasks (except pentesting ones already
generated separate limited-budget version anyway), obtained several limited-budget benchmarks, follows. set outcome costs 1 otherwise specified. determined
minimum budget, bmin , required achieve non-0 goal probability. resource-constrained
benchmarks, bmin determined generator itself, minimum amount resource required
reach goal deterministic domain version. benchmarks, ran FD
LM-cut all-outcomes determinization . failed, skipped , otherwise
read bmin cost optimal plan created several limited-budget tasks [C], differing
constrainedness level C. Namely, following Nakhost et al. (2012), set global budget b
[C] b := C bmin , C factor available budget exceeds minimum
needed (to able reach goal all). let C range {1.0, 1.2, . . . , 2.0}.
AtleastProb, let range {0.1, 0.2, . . . , 1.0} ( = 0 pointless). ApproxProb,
let range {0.0, 0.1, . . . , 0.9} ( = 1 pointless). cyclic problems, convergence
parameter set 0.00005 (the value used Kolobov et al., 2011). experiments
run cluster Intel E5-2660 machines running 2.20 GHz, time/memory cut-offs
30 minutes/4 GB.
7.2 Acyclic Planning
consider first acyclic planning. pertains budget-limited benchmarks, pentesting
without budget limit, well IPPC TriangleTireworld (moves made
one direction state space acyclic). consider 3 objectives MaxProb, AtLeastProb,
ApproxProb. run 16 search algorithm variants (VI, AO , LRTDP, 5 DFHS variants,
subsets bounds applicable), 5 node selection strategies explained. deadend pruning, run LM-cut, well merge-and-shrink (M&S) state-of-the-art shrinking
strategies based bisimulation abstraction-size bound N ; show data N =
N = 100k (we also tried N {10k, 50k, 200k} resulted similar behavior). also run
variants without dead-end pruning. use deterministic-bisimulation (DB) reduced state space
VI: (and if) bisimulation successfully computed, block-state MDP easily
solved simplest algorithm. Given DB, require dead-end pruning
dead-ends already removed reduced state space.
Overall, yields 577 different possible algorithm configurations. actually test
configurations, course, interesting, needed make essential
observations. instead organize experiment terms three parts (1)(3), focusing
particular issue interest. Consider Table 2, gives overview configurations
considered experiment. design experiments follows:
13. modeling/solving entire network, is. domain-dependent decomposition algorithm 4AL,
trading accuracy performance, Sarraute et al. scale much further.

247

fiS TEINMETZ & H OFFMANN & B UFFET

Experiment

Search Algorithm


Pruning

Node selection

# Configs



AO |U ,
MaxProb search & prun- VI, AO |L ,
default
LRTDP|
,
DFHS|
U
U (5), (4)
ing
VI DB
VI, AO |L ,
AO |U ,

AtLeastProb & Approx- AO |LU ,
LRTDP|U ,
(2)
LM-cut
default
Prob parameters
LRTDP|LU ,
HDP|U ,
HDP|LU , VI DB
VI, AO |L ,
AO |U ,
(1, 4, 4, 5, 3,

LRTDP|U ,
AtLeastProb & Approx- AO |LU ,
(3)
LM-cut 4, 3, 4, 1 respecLRTDP|LU ,
HDP|U ,
Prob node selection
tively)
HDP|LU , VI DB
(1)

37

18

58

Table 2: Overview algorithms tested acyclic problems, Section 7.2. Numbers brackets give
number options number obvious. (2) (3), note total
number configurations gets multiplied 2 AtLeastProb vs. ApproxProb result
different algorithm configurations (using different termination criteria). HDP
member DFHS family, corresponding Bonet Geffners (2003a)
DFHSFwdCons
Lab
HDP algorithm.
(1) first evaluate different search algorithms dead-end pruning methods MaxProb, fixing
node selection strategy default.
omit X|LU variants, because, explained earlier, MaxProb heuristic search,
maintaining V L redundant (early termination dominated regular termination).
Using default node selection strategy makes sense node selection strategies
relevant anytime performance, i.e., early termination. plays minor role
MaxProb, whose early termination possibility exceptional case initial state
lower bound becomes V L (I) = 1.
(2) next fix best-performing dead-end pruning method, analyze search algorithm performance AtLeastProb ApproxProb function parameter respectively .
fix node selection strategy default here, leaving examination experiment
(3).
(3) finally let node selection strategies range, keeping otherwise setting experiment
(2).
conclude discussion (4) additional data illustrating typical anytime behavior.
part experiment described separate sub-section follows.
7.2.1 (1) EARCH LGORITHMS & P RUNING ETHODS AX P ROB
Table 3 shows coverage data, i.e., number benchmark tasks MaxProb solved
within given time/memory limits.
pruning methods, LM-cut clearly stands out. every search algorithm, yields
far best overall coverage. M&S substantial advantages RectangleTireworld
NoMystery-b. Note that, N = , overall coverage worse using pruning
all. due prohibitive overhead, domains, computing bisimulation
determinized state space. And, invested effort, pays use bisimulation
248

fiG OAL P ROBABILITY NALYSIS P ROBABILISTIC P LANNING

Domain

#

TriaTire

10

Blocksw-b
Boxworl-b
Drive-b
Elevator-b
ExpBloc-b
Random-b
RecTire-b
Tirewor-b
TriaTire-b
Zenotra-b

66
18
90
90
84
60
36
90
60
36

NoMystery-b 60
Rovers-b
60
TPP-b
60
Pentest-b
Pentest
P

90
15
925

Domain

#

TriaTire

10

Blocksw-b
Boxworl-b
Drive-b
Elevator-b
ExpBloc-b
Random-b
RecTire-b
Tirewor-b
TriaTire-b
Zenotra-b

66
18
90
90
84
60
36
90
60
36

NoMystery-b 60
Rovers-b
60
TPP-b
60
Pentest-b
Pentest
P

90
15
925

DFHSFwd
DFHSFwdCons
|U
DFHSFwd
VI |U
VI
Lab |U
LM M&S
LM M&S
LM M&S

N
N
N
IPPC Benchmarks
9 10 10 10
9 8 8 8 10 10 10 10
9 8 8 8 10
IPPC Benchmarks Budget Limit
24 28 24 24 24 28 24 24 24 28 24 24 24 28 24 24 24
0 3 0 0
0 3 0 0
0 3 0 0
0 3 0 0
0
90 90 90 52 90 90 90 52 90 90 90 52 90 90 90 52 90
78 86 79 33 79 86 79 33 78 86 79 33 79 86 79 33 78
37 60 39 37 37 60 39 37 36 66 39 37 37 60 39 37 36
36 44 36 33 36 44 36 33 36 44 36 33 36 44 36 33 36
28 31 36 36 30 31 36 36 30 31 36 36 30 31 36 36 30
90 90 90 90 90 90 90 90 90 90 90 90 90 90 90 90 90
46 55 55 55 46 55 55 54 46 55 55 55 46 55 55 54 46
15 17 17 18 15 17 17 18 12 15 14 15 15 17 17 18 14
Probabilistic Resource-Constrained Benchmarks Budget Limit
12 40 50 50 12 41 50 50 12 42 50 50 12 41 50 50 12
25 46 36 46 25 46 36 46 25 46 36 47 25 46 36 46 25
19 38 27 25 19 38 27 25 20 39 27 25 19 38 27 25 20
Pentesting Benchmarks
57 63 62 37 57 63 62 37 57 63 62 37 57 63 62 37 57
9 9 9 8
9 9 9 8
8 8 8 8
9 9 9 8
9
575 710 660 554 578 709 658 551 574 716 656 552 578 709 658 551 577
DFHSVI |U
LM M&S
N

HDP|U
LM M&S
N
10 10 10
28
3
90
86
66
44
31
90
55
16

24
0
90
79
39
36
36
90
55
16

42 50 50
46 36 47
39 27 25
63 62 37
9 9 8
718 659 553

AO |L
AO |U
LRTDP|U
HDP|U
LM M&S
LM M&S
LM M&S
LM M&S
N
N
N
N
IPPC Benchmarks
4 4 4 4
4 4 4 4 10 10 10 10 10 10 10 10 10 10 10 10
IPPC Benchmarks Budget Limit
24 28 24 24 24 28 24 24 24 28 24 24 24 28 24 24 24 28 24 24
0 3 0 0
0 3 0 0
0 3 0 0
0 3 0 0
0 3 0 0
90 90 90 52 90 90 90 52 90 90 90 52 90 90 90 52 90 90 90 52
71 82 72 33 74 84 76 33 65 77 67 33 79 86 79 33 78 86 79 33
32 46 38 37 32 46 38 37 39 57 39 37 38 65 39 37 36 66 39 37
27 33 35 33 39 34 36 33 35 44 36 33 36 44 36 33 36 44 36 33
30 31 36 36 30 31 36 36 30 31 36 36 30 31 36 36 30 31 36 36
90 90 90 90 90 90 90 90 90 90 90 90 90 90 90 90 90 90 90 90
45 52 52 52 45 52 52 52 46 55 55 55 47 57 57 57 46 55 55 55
15 16 16 18 15 16 16 18 14 16 16 17 15 17 16 17 14 16 16 16
Probabilistic Resource-Constrained Benchmarks Budget Limit
11 37 43 44 11 36 42 43 12 39 47 47 12 41 50 50 12 42 50 50
23 39 31 40 23 38 31 40 23 44 33 45 25 46 35 46 25 46 36 47
18 35 25 25 16 35 24 24 15 37 26 22 19 38 27 25 20 39 27 25
Pentesting Benchmarks
57 63 62 37 57 63 62 37 57 63 63 37 57 63 63 37 57 63 62 37
9 9 9 8
9 9 9 8
9 9 9 8
9 9 9 8
9 9 9 8
546 658 627 533 559 659 630 531 559 693 641 546 581 718 661 555 577 718 659 553
VI
LM M&S
N

24
0
52
33
37
33
36
90
55
16

VI

DB
10
24
0
52
33
37
33
36
90
60
17
51
50
26
37
8
564

Table 3: Acyclic planning. MaxProb coverage (number tasks solved within time & memory
limits). Best values, within table, boldface. Top: DFHS variants (recall HDP
DFHSFwdCons
member DFHS family; DFHSVI ILAO ). Bottom: remaining
Lab
search algorithms, including also overall best DFHS variant. Domains -b modified
budget limit. #: number instances. : pruning; else pruning,
remaining budget -b domains, based h = domains. LM: LM-cut;
M&S: merge-and-shrink, N size bound N = 100k, size bound. VI DB:
VI run reduced (deterministic-bisimulated) state space. Default node selection.

249

fiS TEINMETZ & H OFFMANN & B UFFET

107

107

106

106

LRTDP|U (LM-cut)

LRTDP|U

reduced MDP state space (VI DB), rather dead-end pruning. extreme
example latter TriangleTireworld. Far beyond standard benchmarks Table 3 (triangleside length 20), VI DB scales side length 74 original domain limited-budget
version. comparison, hitherto best solver far Prob-PRP (Camacho et al., 2016),
scales side length 70 original domain, optimal goal probability 1, i.e.,
presence strong cyclic plans holds original domain limited-budget
version. (We could actually run Prob-PRP limited-budget domain version, Prob-PRP
natively support budget, hard-coding budget PPDDL resulted encodings
large pre-process.)
Comparing different DFHS|U variants, configuration clearly stands out.
Overall, perform equally well, though FwdCons variants (cutting exploration
inconsistent states rather absorbing states) slight edge. difference mainly comes
TriangleTireworld, ExplodingBlocks, TPP-b, FwdCons configurations solve
instances, Zenotravel-b FwdCons configurations perform slightly worse counterparts. termination parameter (VI vs. Label) almost effect coverage. Due
gives best coverage results,
similarity DFHS configurations, DFHSFwdCons
Lab


representative


DFHS
family

remaining discussion.
use DFHSFwdCons
Lab
FwdCons
corresponds HDP, simplicity refer name.
DFHSLab
AO |L better VI case early termination V L = 1, full-certainty
policy found visiting entire state space. happens rarely here, AO |L
dominated VI (this changes AtLeastProb, see Figures 5a 7 below). failures VI
due memory runtime exhaustion building reachable state space. LRTDP|U clearly
outperforms AO |U , presumably tends find absorbing states quickly. LRTDP|U
HDP|U par; LM-cut solve exact number instances (though
exactly instances), otherwise HDP|U solves slightly fewer tasks LRTDP|U .
gauge efficiency heuristic search vs. blind search MaxProb, compare LRTDP|U vs.
VI Table 3. Contrary intuition good initial goal probability estimator required
heuristic search useful, LRTDP|U clearly superior. advantage grow quality
initialization; LM-cut yields largest coverage increase far. However, even without
dead-end pruning, i.e., trivial initialization V U , LRTDP|U dominates VI throughout,
improves coverage 8 16 domains.

105
104
103

104
103
102

102
101 1
10

105

102

103

104
VI

105

106

101 1
10

107

102

103

104
105
VI (LM-cut)

106

107

Figure 4: Acyclic planning. Number states visited, VI (x) vs. LRTDP|U (y), pruning
(left) respectively LM-cut pruning (right). Default node selection.
next shed additional light comparing search space sizes runtime values.
Tables 4 5 provide aggregate data, Figure 4 gives scatter plot canonical comparison
250

fiG OAL P ROBABILITY NALYSIS P ROBABILISTIC P LANNING

AO |U
LRTDP|U
LM
M&S

LM
M&S
N

N

IPPC Benchmarks
843.1 843.1 843.1 843.1
0.2 0.2 0.2 0.2
0.8 0.7 0.7 0.7
0.4 0.4 0.4 0.4
3.5 1.7 1.7 1.7
IPPC Benchmarks Budget Limit
12.7 5.8 2.8 2.8
12 5.2 2.5 2.5 12.3 5.3 2.5 2.5
4.2 2.4 1.8 1.2
4.2 2.2 1.6
1
4 2.1 1.5
1
12.8 3.9 7.2
3
3.3 0.3 0.4 0.1
3.6 0.3 0.4 0.1
1.1K 41.9 92.1 33.2 112.2 1.2 12.2 0.8 117.8 1.4 12.5 1.2
4.1K 213.2 859.9 179 603.1 3.6 133.6 2.6 588
4 106.8 3.2
2.6K 1.5 17.2 1.1 3.1K 2.1 21.3 1.6
4.5 1.7 1.7 1.7
1.9 0.8 0.8 0.8
2 0.8 0.8 0.8
1.0K 130 127.4 127.4 42.6 6.4 6.4 6.4 43.7 6.4 6.4 6.4
2.7K 15.9 2.2 2.2 2.9K 15.9 2.2 2.2
50.6 5.6 1.5 1.5 49.8 5.1 1.2 1.2 50.4 5.1 1.3 1.3
81.9 8.9 2.4 2.4 81.5 8.2 1.9 1.9 81.6 8.3
2
2
1.4K 6.4 6.4 6.4 898.6
3
3
3 896.2 2.9 2.9 2.9
4.1K 229.4 229.4 229.4 1.8K 52.5 52.5 52.5 1.6K 44.5 44.5 44.5
7.4K 610.3 610.3 610.3 4.6K 303.3 303.3 303.3
491.5 30.2 35.8 18.2 491.3 29.9 35.2 17.9 288.2 23.6 27.1 14.1
967.4 104.4 164.6
64 967.1 102.9 161.1 62.3 478.1 75.3 114.9 45.8
Probabilistic Resource-Constrained Benchmarks Budget Limit
2.8K 6.9 0.5 0.5 2.6K 6.6 0.4 0.4 2.6K 6.4 0.4 0.4
12.4K 122.4 14.1 14.1 12.7K 122.3 16.4 16.4
1.1K 51.8 91.5 22.6 702.9 36.1 58.6 12.4 873.7 38.5 70.8 14.3
2.2K 290.1 512.6 137.6 1.1K 176 281.4 65.9 1.6K 190 366.2 76.3
4.7K 287.1 709.7 205.2 8.3K 338.3 1.0K 242.1
1.1K 49.6 265.4 10.9 660.9
33 183.3 5.7 897.2 38.5 220.7 7.6
3.0K 178.7 894.6 36.6 1.5K 100.4 549.5 14.3 2.1K 120.1 701.9 21.5
Pentesting Benchmarks
19.7 6.3 7.8 6.3 19.5 6.3 7.7 6.3 19.7 6.2 7.7 6.2
238.1 165.1 169.2 165.1 237.2 165.1 169 165.1 238.1 165.1 169.1 165.1
74.3 66.3 66.4 66.3 74.3 66.3 66.4 66.3 74.3 66.3 66.4 66.3
194.3 173.4 173.8 173.4 194.3 173.4 173.8 173.4 194.3 173.4 173.8 173.4


Domain

#

TriaTire
ONLY-H

1
4

Blocksw-b
18
Drive-b
20
Elevator-b
12
ExpBloc-b
18
NON-TRIVIAL 7
ONLY-H
3
Random-b
21
NON-TRIVIAL 4
ONLY-H
2
RecTire-b
18
NON-TRIVIAL 12
TriaTire-b
17
NON-TRIVIAL 6
ONLY-H
1
Zenotra-b
14
NON-TRIVIAL 10
NoMystery-b 11
ONLY-H
1
Rovers-b
21
NON-TRIVIAL 13
ONLY-H
2
TPP-b
9
NON-TRIVIAL 5
Pentest-b
28
NON-TRIVIAL 5
Pentest
3
NON-TRIVIAL 1

VI
LM
M&S
N






HDP|U
LM
M&S
N


2.2 1.8 1.8 1.8
160.3 835.4 835.4 835.4
11.5 4.8 2.3 2.3
4 2.1 1.5 0.9
3.4 0.3 0.4 0.1
150.7 1.2 13.6 0.8
780.4 3.4 125.6 2.2
5.2K 1.9 23.4 1.1
1.9 0.8 0.8 0.8
34.5 5.4 5.4 5.4
2.9K 15.9 2.2 2.2
50.4
5 1.2 1.2
81.5 8.1 1.9 1.9
954 3.4 3.4 3.4
1.8K 67.4 67.4 67.4
6.2K 634.8 634.8 634.8
285.1 23.6 27.4 14.2
468.6 75.3 115.9 46.3
2.7K 6.5 0.4 0.4
12.7K 117.3 14.2 14.2
782.7 35.8 63.2 12.4
1.3K 173.8 318.4 65.9
5.9K 265.5 741 189.5
765.4 31.3 188.1 5.6
1.8K 91.3 561.8
14
19.7 6.2 7.7 6.2
238.1 165.1 169.1 165.1
74.3 66.3 66.4 66.3
194.3 173.4 173.8 173.4

Table 4: Acyclic planning. MaxProb geometric mean search space size (number states visited)
multiples 1000. # gives size instance basis, namely instances solved
shown configurations, skipping instances solved 1 second configurations. NON-TRIVIAL uses instances solved VI < 1 second.
ONLY-H uses instances commonly solved AO |U , LRTDP|U , HDP|U ,
solved VI. Rows empty instance basis skipped. Default node selection.
VI LRTDP|U . Data AO |L shown coverage dominated VI (cf.
Table 3), goes runtime search space. include NON-TRIVIAL rows
tables show behavior interesting instances, averages skewed
many small instances domains. include ONLY-H rows elucidate
behavior challenging instances beyond reach VI.
clear message Table 4 Figure 4 heuristic search algorithms, apart
exceptions, visit much fewer states VI does, even trivial upper bound initialization search spaces reduced domains except RectangleTireworld Pentest.
instance, using LRTDP|U instead VI results gain around 1 order magnitude many
instances, larger gains (up 3 orders magnitude) also occur rare cases. giving
heuristic search algorithms additional information earlier dead end detection, differences become even larger.
251

fiS TEINMETZ & H OFFMANN & B UFFET

Domain

#

TriaTire
ONLY-H

1
4

Blocksw-b
18
Drive-b
20
Elevator-b
12
ExpBloc-b
18
NON-TRIVIAL 7
ONLY-H
3
Random-b
21
NON-TRIVIAL 4
ONLY-H
2
RecTire-b
18
NON-TRIVIAL 12
TriaTire-b
17
NON-TRIVIAL 6
ONLY-H
1
Zenotra-b
14
NON-TRIVIAL 10
NoMystery-b 11
ONLY-H
1
Rovers-b
21
NON-TRIVIAL 13
ONLY-H
2
TPP-b
9
NON-TRIVIAL 5
Pentest-b
28
NON-TRIVIAL 5
Pentest
3
NON-TRIVIAL 1

AO |U
LRTDP|U
HDP|U
LM M&S
LM M&S
LM M&S
N

N

N

IPPC Benchmarks
3.5 7.4 4.1
4
0
0 0.1 0.1
0 0 0
0
0 0 0.1 0.1
0.1 0.1 0.5 0.5 0.1 0.3 0.6 0.6
1.4 23.9 12.1 12.1
IPPC Benchmarks Budget Limit
0.1 0.6 2.5 2.3
1.8 0.8
3 2.8 0.2 0.6 2.3 2.4
0.2 0.5
2 2.1
0 0.2 6.9 14
0.1 0.2
8 15.4
0 0.2 7.1 14.2
0 0.2 6.1 12.3
0.1 0.1 1.8 4.1
0
0 2.2 4.5
0 0 1.8 4.1
0 0 1.7 3.8
6 1 15.5 7.5
1.6
0 16
8 0.8 0.1 14.2 7.1
0.9
0 13.4 6.6
25.3 4.8 36.2 45.7
11.5 0.1 33 45.9
4 0.1 29.7 42.1
5 0.1 27.2 39.6
29.3 0.1 40.9 40.4 21.4 0.1 30.7 34.9 35.1 0.1 30.2 32.5
0.5 0.6 4.8 4.8
0.3 0.3 5.2 5.2 0.3 0.3 4.7 4.8
0.2 0.3 4.4 4.4
13.9 10.1 39.2 43.2
3 0.9 44.4 49.9 1.4 0.8 36.3 43.2
0.8 0.7 35.3 38.2
27.8 11.3 38.1 42.9 30.3 11.1 35.4 37.4 29.8 10.8 34.8 35.2
9 19.4 1.2 1.2
73.6 20.2 1.3 1.3 43.1 17.6 1.3 1.3 131.2 16.4 1.2 1.2
20.4 57.3 2.3 2.3 178.9 61.8 2.4 2.4 106.8 51.4 2.3 2.3 330.1 46.5 2.3 2.3
10.5 0.5 0.6 0.6
14.5 0.4 0.5 0.5 9.5 0.3 0.4 0.4
8.4 0.4 0.4 0.4
27.7 5.9 3.2 3.3
31.3 2.4 2.1
2 14.7
2 1.7 1.6 13.7 2.4 1.8 1.7
153.2 25.4 13.6 13.6 41.5 11.9 5.1 4.4
42 18.2 6.9 7.1
2.7 4.9 15
9
56 5.7 18.9 11.8
13 4.3 15.9 9.2 52.5
5 16.8 9.3
5.6 16.5 27 13.5 163.4 19.3 37.2 18.7 25.3 13.6 30.1 14.5 118.3 16.8 35.2 15.1
Probabilistic Resource-Constrained Benchmarks Budget Limit
15.6 0.4 0.3 0.3 242.6 0.4 0.3 0.3 27.8 0.4 0.3 0.3 26.2 0.4 0.3 0.3
1623.4 8.9 0.6 0.6 158.8 7.8 0.5 0.4 137.2 7.3 0.4 0.4
9.7 2.3 11.8 17
96.2 2.3 16.5 21.7 12.8
2 11.6 16.1 10.8 1.8 9.9 14.9
20.9 12.9 20.2 33.7 236.6 12 33.3 45.1 24.9 9.7 19.5 30.3 19.2 8.8 15.9 29.1
751.2 19.2 76.9 151.4 127.6 18.6 44.8 126.9 85.4 14.8 34.3 105.1
8.5 1.6 14.9 69.8
63.2 1.3 24.6 70.2 12.7 1.3 16 69.1
9.6 1.1 14.3 65.1
22.4 5.7 18.5 76.2 203.5 4.5 37.3 78.2 31.3 4.2 20.1 76.3 23.2 3.2 17.7 72.4
Pentesting Benchmarks
0 0 6.6 16.5
0.5
0 8.2 19.8
0 0 7.3 18.2
0.3
0 6.5 16.6
3.2 2.2 10.1 92.7
16 4.5 15 108.9
8.5 5.2 15.2 107.6
6.4 4.4 12.7 100
0.9 0.7 3.2 4.4
5.9 2.3 5.7 6.5 3.8
3 5.8 6.3
2.4 2.7 5.1 6.1
2.7
2 6.5 17.2
23 8.1 20.6 23.8
15 10.4 16.6 24.4
9.3 10.6 15.2 24.4
VI
LM M&S
N



Table 5: Acyclic planning. MaxProb geometric mean runtime (in CPU seconds). setup
presentation Table 4.
previously hinted, observations made clarity before.
Kolobov et al. (2011) also report LRTDP beat VI MaxProb, consider single domain; experiment trivially initialized V U ; use dead-end pruning
VI, LRTDP already benefits smaller state space, impact heuristic search
remains unclear.
Even though search space heuristic search algorithms many cases small
fraction whole (dead-end pruned) state space, necessarily reflected runtime.
instances solved VI, typically fast, often faster heuristic search rarely
outperformed significantly. despite larger search spaces, i.e., heuristic search
visit less states suffers updates (recall VI updates
visited state exactly once). Significant runtime advantages VI (in NON-TRVIAL rows)
obtained heuristic search ExplodingBlocksb, Randomb, TriangleTireworldb.
Comparing heuristic search algorithms, conclusions fine-grained overall
similar concluded coverage above. LRTDP|U dominates AO |U almost throughout.
Note that, even though search space size AO |U LRTDP|U almost always similar, AO |U
requires lot time LRTDP|U . performs updates. Across nontrivial commonly solved instances tables, geometric mean number updates done
252

fiG OAL P ROBABILITY NALYSIS P ROBABILISTIC P LANNING

AO |U 4 times higher LRTDP|U . LRTDP|U HDP|U non-trivial
value initialization give similar results, terms coverage, also terms
runtime search space size. LRTDP|U is, however, effective domains (e.g.,
RectangleTireworld Zenotravel) additional dead-end detection method used.
hand, HDP|U slight edge probabilistic resource-constrained domains. One notable
case LRTDP|U consistently outperforms HDP|U TriangleTireworld.
impact dead-end pruning VI typically moderate. gains heuristic search
much pronounced, thanks stronger heuristic function initialization. Especially AO |U
benefits lot. LRTDP|U HDP|U benefit well, smaller extent, partly
already effective first place. Comparing across different dead-end pruning methods,
although M&S N = clearly yields largest search space reductions, necessarily
recognizes dead-ends, overhead bisimulation computation outweighs search space
reduction cases. terms pruning power, M&S N = 100k LM-cut
heuristic overall roughly similar, yet LM-cut edge runtime.
7.2.2 (2) L EAST P ROB PPROX P ROB PARAMETER NALYSIS
turn weaker objectives, AtLeastProb ApproxProb. fix LM-cut (almost
always effective) dead-end pruning. examine power early termination different
search algorithms node selection strategies. best viewed function goal probability threshold AtLeastProb, desired goal probability accuracy ApproxProb. VI
forms baseline independent (). Consider Figure 5.
VI
LRTDP|U

850

VI

LRTDP|LU

AO |LU

HDP|U

HDP|LU

800

850
825
# solved instances

# solved instances

825

AO |L

AO |U

775
750
725
700
675

AO |L

AO |U

LRTDP|LU

AO |LU

HDP|U

HDP|LU

800
775
750
725
700
675

650

650

625

625
0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1


LRTDP|U

0.9 0.8 0.7 0.6 0.5 0.4 0.3 0.2 0.1 0


(a)
(b)
Figure 5: Acyclic planning. Total coverage AtLeastProb function (a), ApproxProb function (b). configurations use default node selection LM-cut
dead-end pruning.
AtLeastProb (Figure 5a), interesting region benchmark instances feasible
VI yet sometimes feasible search algorithms, one clear feature superiority
LRTDP AO HDP. one see smaller values , LRTDP able
update V L much effectively HDP, resulting larger coverage LRTDP region
253

fiS TEINMETZ & H OFFMANN & B UFFET

smaller values. AO |L exhibits strikingly strong behavior small values , approaching
(and one case, surpassing) performance LRTDP|U . Evidently, depth-first expansion
strategy quite effective anytime behavior V L thus termination via V L (I) .
way effective heuristic search AO |LU . shall see (Figure 7),
often also effective LRTDP. general, algorithms, using V L clear advantage
small . larger , maintaining V L become burden, yet V U advantage due early
termination V U (I) < . Algorithms using bounds exhibit easy-hard-easy pattern.
spike left-hand side Figure 5 (a), i.e., significantly worse performance = 0.1
= 0.2, outlier due Pentest domains without domains, AO |LU ,
LRTDP|LU HDP|LU exhibit strict easy-hard-easy pattern. because, contrast typical probabilistic planning scenarios, penetration testing goal probability chance
successful attack typically small, indeed benchmarks. Searches using
upper bound quickly obtain V U (I) < 0.2, terminating early based V U (I) < = 0.2.
takes long time obtain V U (I) < 0.1.
ApproxProb (Figure 5b), smaller values consistently result worse performance.
see superiority LRTDP AO HDP, (relatively, compared AO |LU )
strong behavior AO |L regions allowing aggressive early termination. Again, key
LRTDP beating HDP clearly due LRTDP updating V L much effectively. HDP|LU
improve HDP|U small margin. Nonetheless, see superiority algorithms
using bounds dont.
7.2.3 (3) N ODE ELECTION TRATEGIES
Figure 6 shows different node selection strategies AtLeastProb (the relative performance node
selection strategies ApproxProb, include separate figure that).
LRTDP|LU (def)
AO |L (BFS)

850

# solved instances

825

AO |LU (def)
AO |LU (h)

AO |L (DFS)
AO |L (h)

AO |LU (o-prob)
HDP|LU (def)

VI

800
775
750
725
700
675
650
625
0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1


Figure 6: Acyclic planning. Total coverage AtLeastProb function , varying node
selection strategy. configurations use LM-cut dead-end pruning.
readability, show competitive base algorithms, AO |L , AO |LU , LRTDP|LU ,
HDP|LU (as well VI baseline). LRTDP HDP, show default node selection, consistently works basically well alternatives. AO |L , see
254

fiG OAL P ROBABILITY NALYSIS P ROBABILISTIC P LANNING

depth-first strategy important (and way beyond breadth-first, worse VI).
h-bias strategy marginally, consistently, better depth-first. AO |LU , h-bias
most-prob-outcome bias helpful, substantially improving default strategy.
h-bias consistently improves bit default AO . gap-bias preferred-actions strategies
shown consistently slightly worse (apparently, gap-bias leads
breadth-first style behavior, preferred actions mainly cause runtime overhead).
7.2.4 (4) N LLUSTRATION YPICAL NYTIME B EHAVIOR
conclude discussion acyclic planning, Figure 7 exemplifies typical anytime behavior, i.e.,
development V L (I) V U (I) bounds initial state value, function runtime,
LRTDP|LU AO |L .
1

LRTDP V U LM-cut

LRTDP V L

LRTDP V L LM-cut

AO |

AO |

L

1

L LM-cut

0.8
Probability

Probability

0.8

LRTDP V U

0.6
0.4
0.2

0.6
0.4
0.2

0

0
0

100

200
300
Time (s)

400

500

0

100

(a)

LRTDP V U

LRTDP V U LM-cut

LRTDP V L

LRTDP V L LM-cut

AO |L

AO |L LM-cut

200
300
Time (s)

400

500

(b)

Figure 7: Acyclic planning. Anytime behavior LRTDP|LU (V V L ) AO |L (V L only),
function runtime. Elevators instance 11, without pruning LM-cut pruning,
constrainedness level C = 1.4 (a) respectively C = 1.8 (b). Default node selection.
U

benefit LM-cut pruning evident. Observe AO |L way effective
LRTDP quickly improving lower bound. Indeed, runs shown find optimal policy
quickly. Across benchmarks solved AO |L LRTDP, omitting
took < 1 second, 56% cases AO |L finds optimal policy faster LRTDP. (geometric) average, AO |L takes 66% time taken LRTDP purpose. downside,
unless V (I) , AO |L must explore entire state space. runs Figure 7 exhaust memory
MaxProb. summary, heuristic search much stronger proving maximum goal
probability found, often distracting improving V L quickly.
parts Figure 7 use base instance different constrainedness levels C,
also draw conclusions effect surplus budget. budget, actions
applied reaching absorbing states. adversely affects upper bound (consistently
across experiments), takes much longer time decrease. lower bound,
hand, often increases quickly higher C easier find goal states.
255

fiS TEINMETZ & H OFFMANN & B UFFET

7.3 Cyclic Planning FRET
consider cyclic planning, pertaining standard IPPC benchmarks, probabilistic
NoMystery, Rovers, TPP without budget (nor resource-) limit. run LRTDP DFHS,
AO restricted acyclic state spaces. use two different variants FRET described earlier:
FRET-V U per Kolobov et al. (2011), new variant FRET- U . consider 3 objectives,
4 dead-end pruning methods (as LM-cut returns iff cheaper heuristic hmax does,
use hmax here). vary node selection strategies because, like seen before,
LRTDP DFHS bring notable advantage default strategy. use
deterministic-bisimulation (DB) reduced state space base algorithm, differences
emerge (in difference acyclic case) VI algorithms, need
run FRET. Again, given DB require dead-end pruning.
Overall, yields 305 different possible algorithm configurations. before,
interesting, instead organize experiment terms parts focusing issues
interest. Specifically, parts (1) MaxProb (2) AtLeastProb/ApproxProb before.
node selection strategies relevant here, previous part (3) considering
these. integrate data illustrating anytime behavior discussion (2). Table 6 gives
overview tested configurations.
Experiment
FRET variant
Search Algorithm
Pruning
# Configs
MaxProb search & prun(1)
65
, FRET-V U , FRET- U VI, LRTDP|U , DFHS (5) (4), DB
ing
(2)

VI,
AtLeastProb & ApproxU
U LRTDP| ,
,
FRET-V
,
FRET-
LU
Prob parameters
HDP|LU

LRTDP|U ,
HDP|U ,

hmax

18

Table 6: Overview algorithms tested cyclic problems, Section 7.3. Note VI require, hence combined with, FRET; denote (not using FRET all)
. (2), note number configurations gets multiplied 2 AtLeastProb
vs. ApproxProb result different algorithm configurations (using different termination
criteria). configurations tested use default node selection.
7.3.1 (1) EARCH LGORITHMS & P RUNING ETHODS AX P ROB
Table 7 shows coverage data. before, DFHS family shown top, remaining
search algorithms, including competitive DFHS algorithm HDP,
shown bottom. vary FRET variant top space reasons, as,
FRET-V U , coverage differences across DFHS family members.
Similarly acyclic case, DFHS configurations stopping exploration -inconsistent
states give slightly better results stopping absorbing states. termination
parameter almost effect coverage: HDP (i.e., DFHSFwdCons
) solves one task
Lab
ExplodingBlocks DFHSFwdCons
,

otherwise

coverage


same. Also akin
VI
acyclic case, LRTDP HDP perform equally well, though HDP slight edge
combination FRET- U .
Running search deterministic-bismulation state space less effective cyclic
benchmarks acyclic ones. gives clear advantage Rovers.
256

fiG OAL P ROBABILITY NALYSIS P ROBABILISTIC P LANNING


Domain

#

Blocksworld
Boxworld
Drive
Elevators
ExplodingBlocks
Random
RectangleTireworld
Tireworld
Zenotravel
NoMystery
Rovers
TPP
P

Domain
Blocksworld
Boxworld
Drive
Elevators
ExplodingBlocks
Random
RectangleTireworld
Tireworld
Zenotravel
NoMystery
Rovers
TPP
P

15 4
15 0
15 4
15 15
15 5
15 6
14 14
15 15
15 3
10 4
10 9
10 8
164 87

#

FRET- U
DFHSVI |U
DFHSFwdCons
|U
DFHSFwd
HDP|U
VI
Lab |U
hmax M&S
hmax M&S hmax M&S hmax M&S
N BS
N BS
N BS
N BS
N
IPPC Benchmarks
4 4 4 4 4
4 4 4 4 4
4 4 4 4 4
4 4 4 4 4
4 4 4
0 0 0 0 0
0 0 0 0 0
0 0 0 0 0
0 0 0 0 0
0 0 0
15 15 6 6 15 15 15 6 6 15 15 15 6 6 15 15 15 6 6 15 15 15 6
15 15 5 5 15 15 15 5 5 15 15 15 5 5 15 15 15 5 5 15 15 15 5
12 5 4 4 5 12 5 4 4 5 14 5 4 4 5 12 5 4 4 5 15 5 4
6 1 0 0 6
6 2 0 0 6
6 1 0 0 6
6 2 0 0 6
6 1 0
14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14
15 15 12 11 15 15 15 12 11 15 15 15 12 11 15 15 15 12 11 15 15 15 12
3 3 1 1 3
3 3 1 1 3
3 3 1 1 3
3 3 1 1 3
3 3 1
Probabilistic Resource-Constrained Benchmarks
4 4 4 0 4
4 4 4 0 4
4 4 4 0 4
4 4 4 1 4
4 4 4
9 9 8 9 9
9 9 8 9 9
9 9 8 9 9
9 9 8 9 9
9 9 8
8 8 6 6 8
8 8 6 6 8
8 8 6 6 8
8 8 6 6 8
8 8 6
105 93 64 60 98 105 94 64 60 98 107 93 64 60 98 105 94 64 61 98 108 93 64
DFHSFwd
VI |U
hmax M&S

4
0
15
15
4
0
14
10
3

4
0
15
15
6
0
14
10
3

4
0
15
15
4
0
14
10
3

10 5
10 5
10 6
164 81

5
5
6
83

5
5
6
81

15
15
15
15
15
15
14
15
15

FRET-V U
FRET- U
LRTDP|U
HDP|U
LRTDP|U
HDP|U
hmax M&S hmax M&S hmax M&S hmax M&S
N DB
N DB
N DB
N
IPPC Benchmarks
4 4 4
4 4 4 4 4
4 4 4 4 4
4 4 4 4 4
4 4 4
0 0 0
0 0 0 0 0
0 0 0 0 0
0 0 0 0 0
0 0 0
6 6 15 15 15 6 6 15 15 15 6 6 15 15 15 6 6 15 15 15 6
5 5 15 15 15 5 5 15 15 15 5 5 15 15 15 5 5 15 15 15 5
4 4 4
6 4 4 4 4
6 4 4 4 5 14 5 4 4 5 15 5 4
0 0 0
0 0 0 0 0
0 0 0 0 4
4 0 0 0 6
6 1 0
14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14
10 11 10 11 10 10 11 10 10 10 10 11 15 15 15 12 11 15 15 15 12
1 0 3
3 3 1 1 3
3 3 1 1 3
3 3 1 1 3
3 3 1
Probabilistic Resource-Constrained Benchmarks
5 5 5
5 5 5 5 5
5 5 5 5 4
4 4 4 1 4
4 4 4
5 9 5
5 5 5 9 5
5 5 5 9 9
9 9 8 9 9
9 9 8
6 6 6
6 6 6 6 6
6 6 6 6 8
8 8 6 6 8
8 8 6
60 64 81 84 81 60 65 81 83 81 60 65 96 105 92 64 61 98 108 93 64

VI
hmax M&S
N DB


BS
4
0
6
5
4
0
14
11
1
1
9
6
61


DB
4
0
6
5
4
0
14
11
1
1
9
6
61

Table 7: Cyclic planning. MaxProb coverage. Best values, within table, boldface. FRETV U per Kolobov et al. (2011), FRET- U modified version. Top: DFHS variants
member DFHS family; DFHSVI ILAO );
(recall HDP DFHSFwdCons
Lab
showing dominating FRET version, FRET- U . Bottom: remaining search algorithms, varying FRET version, including also overall best DFHS variant.
Dead-end pruning variants: none, else based heuristic value , hmax respectively merge-and-shrink (N size bound N = 100k, size bound). DB: run
reduced (deterministic-bisimulated) state space. Default node selection.
striking result far FRET- U outperforms VI FRET-V U substantially. Note that, domains except ExplodingBlocks Rovers, advantage VI
obtained even without dead-end pruning, i.e., trivial initialization V U . strongly confirms
power heuristic search even absence good admissible goal probability estimators.
before, shed additional light coverage results search space size runtime
data. Figure 8 compares search space sizes VI vs. FRET- U . non-trivial initialization
using hmax useful, gains 3 orders magnitude possible even without it.
Table 8 provides aggregate search space size runtime data. data shown configuration using FRET-V U HDP, data almost identical FRET-V U LRTDP:
257

fi107

107

106

106
FRET- U (hmax )

FRET- U

TEINMETZ & H OFFMANN & B UFFET

105
104
103

105
104
103
102

102
101 1
10

102

103

104
VI

105

106

101 1
10

107

102

103

104
105
VI (hmax )

106

107

Figure 8: Cyclic planning. Number states visited, VI (x) vs. FRET- U using LRTDP|U (y),
pruning (left) respectively hmax pruning (right).
FRET-V U
FRET- U
LRTDP|U
LRTDP|U
M&S
hmax
M&S
hmax
M&S

N

N

N

IPPC Benchmarks
2.8
2.7
0 0.1
2.7
2.8
0.1
0.1
3 2.8
0.1
6 42.8
0
0 5.8 33.1
0
0 6.1 42.8
0
2.2
1.7
0
0 2.2
1.8
0
0 2.2
1.9
0
19.3 18.1 15.9 0.4 31.5 17.7 15.7
0 28.8 17.5
3.5
45.1 110.4 82.2 0.8 112.4 102.6 72.9
0 104.1 110.1 14.3
4.7
4.7
3.9
4 4.7
4.7 19.8
4.1
4.7
4.7 20.4
9.1
9
7.6 7.9
9.1
9
53 8.1
9.1
9.2 55.5
14
35
60 55.3 60.2 86.4
0
0 3.8 24.7
0
19.5 55.7 92.1 84.5 89.8 136
0
0 4.7 39.8
0
96.3 283.8
7 12.6 54.3 241.1
0.2
0.2 43.5 227.4
0.2
Probabilistic Resource-Constrained Benchmarks
29.1 69.4 133.9 127 141.4 166.7 627.3 582.4 676.4 618.7 632.1
39.1 42.7 439.8 420.3 435.2 425.1
1.8
1.3
6.2
8.3
1.8
20.1 44.8 140.1 125.8 136.6 156.3 32.9 18.3 63.2 71.3 32.9
31.6 83.5 259.1 241 253.2 299.1 52.5 31.8 118.3 138.8 52.9
IPPC Benchmarks
1.1
1.1
1.1 1.1
1.1
1.1
1.1
1.1
1.1
1.1
1.1
0.3
0.3
0.3 0.2
0.2
0.2
0.3
0.2
0.2
0.2
0.3
0.9
0.9
0.9 0.9
0.9
0.9
0.2
0.2
0.2
0.2
0.2
252.3 39.9 408.5 20.1 242.2 16.9 44.3
0.2
14 0.1 44.4
2.0K 142.4 2.0K 34.6 2.0K 32.4 133.6
0.2 133.6
0.2 133.7
0
0
0.7 0.2
0
0
0.7
0.2
0
0
0.7
0
0
1 0.3
0
0
1 0.3
0
0
1
1.2K 1.2K 1.2K 974.7 974.7 974.7
0.5
0.2
0.2
0.2
2.4
1.7K 1.7K 1.7K 1.4K 1.4K 1.4K
0.4
0.2
0.2
0.2
2.7
309.3 309.3 309.3 309.3 309.3 309.3
2.7
2.7
2.7
2.7
2.7
Probabilistic Resource-Constrained Benchmarks
2.6K 2.6K 2.6K 2.6K 2.6K 2.6K 433 430.8 433 430.8 432.6
2.8K 2.8K 2.8K 2.8K 2.8K 2.8K 15.2 14.8 15.1 14.8 15.2
1.3K 1.3K 1.3K 1.3K 1.3K 1.3K 112.6 89.2 95.7 89.2 112.6
2.3K 2.3K 2.3K 2.3K 2.3K 2.3K 149.2 127.2 138.5 127.2 149.2

VI
hmax
Domain

#

Blocksworld
Drive
Elevators
ExplodingBlocks
NON-TRIVIAL
RectangleTireworld
NON-TRIVIAL
Tireworld
NON-TRIVIAL
Zenotravel

4
1
5
4
2
6
4
8
7
1

0
0
0
2.6
14.2
3.7
7.2
7.3
11
55.7

0
0
0
0.7
2.7
4
7.9
10.9
16.5
49.3

NoMystery
Rovers
TPP
NON-TRIVIAL

4
5
6
5

21.5
33.1
11.8
21.6

29.8
40.2
14.4
26.2

Blocksworld
Drive
Elevators
ExplodingBlocks
NON-TRIVIAL
RectangleTireworld
NON-TRIVIAL
Tireworld
NON-TRIVIAL
Zenotravel

4
1.1
1.1
1
0.3
0.3
5
0.9
0.9
4 408.5 46.5
2 2.0K 152.6
6
0.7
0.2
4
1
0.3
8 1.2K 1.2K
7 1.7K 1.7K
1 309.3 309.3

NoMystery
Rovers
TPP
NON-TRIVIAL

4
5
6
5

2.6K
2.8K
1.3K
2.3K

2.6K
2.8K
1.3K
2.3K

HDP|U
hmax
M&S
N

0.1
3.1
2.9
0 7.2 33.5
0 2.2
1.8
0 18.9 18.3
0 44.4 107.1
4.1
4.7
4.7
8.1
9.2
9.1
0 3.8 24.9
0 4.6 39.9
0.2
51 233.9
580.4 634.2 628.5
1.3
6.1
8.3
18.5 64.1 70.3
32.3 120.1 137.1
1.1
1.1
0.2
0.2
0.2
0.2
0.2
14
0.2 133.7
0.2
0
0.3
0
0.5
0.5
0.5
0.5
2.7
2.7

1.1
0.2
0.2
0.1
0.2
0
0
0.5
0.5
2.7

418.8 432.6 418.8
14.9 15.1 14.9
89.2 95.7 89.2
127.2 138.5 127.2

Table 8: Cyclic planning. Top: MaxProb geometric mean runtime (in CPU seconds). Bottom:
MaxProb geometric mean search space size (number states visited) multiples 1000.
Similar setup presentation Table 4: # gives size instance basis.
default commonly solved instances, skipping trivial ones. NON-TRIVIAL uses
instances solved VI < 1 second. (ONLY-H shown, see text.)

258

fiG OAL P ROBABILITY NALYSIS P ROBABILISTIC P LANNING

search space sizes exactly same, runtimes differ seconds. difference
Tables 4 5, include ONLY-H rows, would interesting here:
FRET-V U hardly solves instances VI, would excluded rows;
then, data would compare LRTDP vs. HDP, perform similarly anyway.
striking Table 8 consistency which, extent which, FRET- U visits
less states competitors (for LRTDP HDP). advantage typically yields better
runtimes well, notable exception NoMystery, larger number FRET iterations results substantial slow-down, despite much smaller search space: FRET-V U
LRTDP requires 11 FRET iterations average, NoMystery instances commonly
solved FRET- U LRTDP, latter configuration requires 20000 iterations average. Similarly using HDP.
impact dead-end pruning notably smaller acyclic case: search spaces
reduced substantially single domain, ExplodingBlocks. domains, either
reduction, minor/moderate one only.
VI (Kolobov)
VI
VI (hmax )
FRET-V U (Kolobov)
FRET-V U (hmax )
FRET- U (hmax )

104
103

106

Time (s)

States visited

108

105

104

102
101
100

102
1

2

3
4
Problem #

5

101

6

1

2

3
4
Problem #

5

6

(a)
(b)
Figure 9: Cyclic planning. Results ExplodingBlocks, shown Kolobov et al. (2011): FRET
vs VI, (a) number states visited, (b) runtime CPU seconds, function
IPPC instance index. Different variants included comparison. data Kolobov
et al. taken paper (as code available anymore), hence runtime
comparison modulo different computational platforms, treated
care. shown FRET configurations use LRTDP|U , default node selection.
ExplodingBlocks also happens single domain Kolobov et al. (2011) experimented with.
Figure 9 provides detailed comparison Kolobov et al.s data, state art
measure provided previous work. use exact runtime/search space size data reported
Kolobov et al.; recall source code available anymore.
Kolobov et al. (2011) ran VI pruning vs. FRET-V U using LRTDP pruning based
SixthSense (Kolobov et al., 2010). observed coverage 4 former 6
latter, identical results VI vs. FRET-V U using LRTDP hmax . give
259

fiS TEINMETZ & H OFFMANN & B UFFET

detail, Figure 9 shows number states visited, total runtime, terms plots IPPC
instance index done Kolobov et al (2011).
Consider first Figure 9 (a), search space size. difference VI (Kolobov)
VI different task/state representation resulting respective implementation
framework, FD framework somewhat effective. substantially better performance
VI hmax dead-end pruning shows omission Kolobov et al.s (2011) study, using
dead-end pruning FRET VI, indeed obfuscates possible conclusions regarding
effect heuristic search vs. effect state pruning itself: hmax pruning, VI almost
effective FRET-V U using pruning. Kolobov et al.s FRET-V U also close
this, except exploring significantly less states large instances. latter shows, especially
given effective representation FD, SixthSense stronger dead-end detector
hmax . hardly surprising, considering information sources SixthSense outcomes
(determinized) classical planning guidance, h2 (Graphplan) based validity tests.
hand, SixthSenses information sources much time-intensive hmax ,
presumably reason runtime picture Figure 9 (b). latter qualitatively
similar (a), except FRET-V U (Kolobov) significantly worse, rather better,
largest instance. last conclusion taken grain salt though, given different
computational environments.
Certainly, given clarity FRET- U advantage search space size runtime, one
conclude variant FRET substantially improves previous state art.
7.3.2 (2) L EAST P ROB PPROX P ROB PARAMETER NALYSIS
weaker objectives AtLeastProb ApproxProb, examine coverage function respectively . Figure 10 shows data.
FRET-V U , behavior Figure 10 similar acyclic case Figure 5.
particular, maintaining upper lower bound, FRET-V U exhibits easy-hardeasy pattern due advantages early termination.
FRET- U , though, curves flat , observation small advantage
using V L addition V U . due scaling benchmarks, combined extreme
performance loss point scaling: domain, instance number x
that, x, FRET- U solve instances completely (i.e., solving MaxProb), x
neither V L (I) V U (I) improved all, remaining 0 respectively 1 time/memory
limit. smaller instances, get expected anytime behavior. Figure 11 exemplifies this.
easy-hard-easy pattern would thus emerge smaller runtime/memory limits.14

8. Conclusion
Optimal goal probability analysis probabilistic planning notoriously hard problem,
extent amount work addressing limited. investigation contributes comprehensive design space known adapted algorithms addressing problem, designing several new
algorithm variants along way, establishing FD implementation basis supporting tight
integration MDP heuristic search classical planning techniques. experiments clarify
14. Figure 11 (b) considers largest instance feasible using hmax pruning. Figure 11 (a) considers secondlargest instance feasible without pruning: largest one feasible without pruning, namely instance 05, maximum goal probability 1 anytime curve V U interesting.

260

fiG OAL P ROBABILITY NALYSIS P ROBABILISTIC P LANNING

FRET-V U LRTDP|U

FRET- U LRTDP|U

FRET-V U LRTDP|U

FRET- U LRTDP|U

FRET-V U LRTDP|LU
FRET-V U HDP|U
FRET-V U HDP|LU
VI

FRET- U LRTDP|LU
FRET- U HDP|U
FRET- U HDP|LU

FRET-V U LRTDP|LU
FRET-V U HDP|U
FRET-V U HDP|LU
VI

FRET- U LRTDP|LU
FRET- U HDP|U
FRET- U HDP|LU

110
# solved instances

# solved instances

110

100

90

100

90

0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1


0.9 0.8 0.7 0.6 0.5 0.4 0.3 0.2 0.1 0


(a)

(b)

1

1

0.8

0.8
Probability

Probability

Figure 10: Cyclic planning. Total coverage AtLeastProb function (a), ApproxProb function (b). configurations use default node selection hmax
dead-end pruning.

0.6
0.4

0.6
0.4

0.2

0.2

0

0
0

20

40
Time (s)

0

60

(a)

100

200
300
Time (s)

400

(b)
FRET- U

Figure 11: Cyclic planning. Anytime behavior
LRTDP|LU HDP|LU ,
default node selection, (a) without pruning ExplodingBlocks instance 04, (b)
hmax pruning instance 15.
empirical state art, exhibit substantial improvements thanks new techniques technique combinations. furthermore showcase opportunities arising naturally acyclic
problems, early termination criteria weaker maximum goal probability.
hope encouraging results new implementation basis inspire renewed
interest research important problem. many promising future directions,
would like emphasize:
Advanced admissible goal probability estimators. could obtained, e.g. abstractions interpreted bounded-parameter MDPs (Givan, Leach, & Dean, 2000). promis261

fiS TEINMETZ & H OFFMANN & B UFFET

ing approach extend state-of-the-art classical-planning abstraction techniques pattern
databases (Edelkamp, 2001; Haslum, Botea, Helmert, Bonet, & Koenig, 2007), merge-andshrink (Helmert et al., 2014), Cartesian abstractions (Seipp & Helmert, 2013, 2014)
probabilistic setting.
Hybrids heuristic search Monte-Carlo tree search. appears promising option
improve anytime behavior, respect upper and/or lower bound, thus foster
early termination. Inspiration could taken existing hybrids, geared toward
purposes (Keller & Eyerich, 2012; Bonet & Geffner, 2012; Keller & Helmert, 2013).
Exploiting dominance relations. Goal probability higher dominating states,
raising opportunity prune dominated regions and/or transfer upper/lower bounds across
states. State domination ubiquitous limited-budget planning (and resource-constrained
planning). general domination relations shown exist also many
classical planning problems (Torralba & Hoffmann, 2015), transfer techniques probabilistic case, via all-outcomes determinization, straightforward.
Last least, simulated penetration testing application worth algorithms research
right. basic idea exploit particular structure models, specifically
partially delete-relaxed behavior. characterizing property simulated penetration testing
action, applicable, remains applicable first executed (once attacker gets
position enabling exploit, exploit remains enabled). Hence, like delete-relaxed planning,
find optimal solution, navely branch action every state ever after.
combat this, least three interesting directions. Following Pommerening Helmerts
(2012) methods computing h+ , different branching schemes might apply, challenge
maintain value function correctness. Following Gefen Brafmans (2012) methods computing h+ , partial-order reduction could adapted, challenge deal action
interference entailed shared budget. Finally, methods specific probabilistic setting may
apply: intuitively, preserve optimality, certain actions need attempted alternate
goal path failed. suggests identify, branch at, particular critical points along
search path.

Acknowledgments
work partially supported German Research Foundation (DFG), grant HO
2169/5-1, Critically Constrained Planning via Partial Delete Relaxation, well Federal Ministry Education Research (BMBF) funding Center IT-Security,
Privacy Accountability (CISPA) grant 16KIS0656. thank Christian Muise
Probabilistic-PDDL extension FD parser. thank Andrey Kolobov discussions.
thank anonymous reviewers, whose comments helped improve paper.

Appendix A. Depth-First Heuristic Search Cyclic Problems
pseudo-code family depth-first heuristic search algorithms (DFHS) general (cyclic)
probabilistic planning problems shown Figure 12.
262

fiG OAL P ROBABILITY NALYSIS P ROBABILISTIC P LANNING

procedure GoalProb-DFHS
:= {I};
loop
[early termination criteria exactly GoalProb-AO ]
(Label labeled solved)
(VI U changed running VI U -greedy graph)
index := 0
DFHS-Exploration(I)
set IDX visited states
clean stack visited
else return U endif /* regular termination */
endloop
procedure DFHS-Exploration(s):
6 Initialize(s) endif
S> labeled solved
label solved
return
endif
f lag :=
FW
V U (s) consistent f lag := > endif
update V U (s), U (s), V L (s), L (s)
Consist f lag return > endif
endif
s.IDX := index; s.lowlink := index
push onto stack; mark visited
index := index + 1
foreach P (s, U (s), t) > 0
t.IDX =
f lag := DFHS-Exploration(s) f lag
t.IDX < t.lowlink < s.lowlink s.lowlink := t.lowlink endif
else stack t.IDX < s.lowlink s.lowlink := t.IDX endif
done
f lag FW
V U (s) -consistent f lag := > endif
update V U (s), U (s), V L (s), L (s)
endif
Label f lag s.IDX = s.lowlink
forever
:= stack.pop()
label solved
= break endif
done
endif
return f lag

Figure 12: Depth-First Heuristic Search (DFHS) general (cyclic) MaxProb, AtLeastProb,
ApproxProb.

Appendix B. Landmarks Pruning: Admissible Heuristic vs. Budget Reduction
stated, Domshlak Mirkis (2015) problem reformulation, pruning states based global
budget reduced using disjunctive action landmarks, equivalent, regarding states pruned
method own, much simpler method using landmarks pruning
263

fiS TEINMETZ & H OFFMANN & B UFFET

remaining original budget. give argument, previously made unit costs
pairwise disjoint landmarks, general setting. assume classical planning setup
simplicity. arguments probabilistic oversubscription setups essentially same.
Assume STRIPS planning task = (F, A, I, G), action costs c(a) global
budget b. use notation following admissible landmark heuristics per Karpas Domshlak
(2009). Let L set disjunctive action landmarks I, i.e., every l L every
action sequence ~a leading goal, ~a touches l (there exists l used ~a). Let
furthermore
cp : L 7 R+
0 cost partitioning, i.e., function satisfying, A,
P
c(a, l)P
c(a). Denote h(l) := minal cp(a, l), subset L0 L landmarks
denote h(L0 ) := lL0 h(l). Intuitively, landmark l L assigned weight h(l) via cp,
admissible heuristic value h(L) obtained summing weights.
describe Domshlak Mirkis (2015) pruning technique terms. Domshlak
Mirkis formulation terms compilation planning language, complicated, equivalent formulation far pruning concerned.
Domshlak Mirkis technique maintains non-used landmarks part states. Namely,
state reached path ~a, l L non-used iff ~a touch l. denote set nonused landmarks L(s). Obviously, l L(s) landmarks s. Note also that, L(s)
part state, even two search paths lead end state use different landmarks,
end states considered different. restriction arises compilation approach,
book-keeping landmarks must happen inside language, i.e., inside states. One
could formulate pruning technique without restriction; get back below.
pruning technique arises interplay reduced global budget reduced
action costs depending non-used landmarks. Define reduced global budget b0 := b h(L).
action a, denote L(a) set landmarks participates in, i.e., L(a) := {l | l L,
l}. state search, applicable action a, transition t[[a]]
reduced cost, namely cost c(a) h(L(a) L(t)). words, reduce cost
(summed-up) weight non-used landmarks participates in.
Consider state search. Denote remaining reduced budget b0 (s).
Say prune iff b0 (s) < 0.15 Consider path ~a ending s. non-used landmarks
part state, paths must touch
P subset landmarks L, namely
L \ L(s). Denote actual cost ~a c(~a) := a~a c(a). Relative cost, cost saved
thanks cost reduction exactly h(L \ L(s)), weight touched landmarks. Therefore,
b0 (s) = b0 (c(~
a) h(L \ L(s))) =P(b h(L)) c(~a) + h(L \ L(s)). P
definition h,
P
equals (b h(l)) c(~a) + lL\L(s) h(l), equals b c(~a) lL(s) h(l) =
b c(~a) h(L(s)). Thus, pruned, b0 (s) < 0, iff b c(~a) < h(L(s)). latter condition
b(s) < h(L(s)), exactly pruning condition resulting using h(L(s))
admissible heuristic function pruning remaining budget.
non-compilation setting, one could, indeed customary admissible landmark heuristics, handle landmarks path-dependent manner. is, non-used landmarks maintained
15. Domshlak Mirkis (2015) maintain remaining budget part state, instead prune g(s) >
b0 . is, obviously, equivalent, except duplicate detection powerful compares states based
facts F (s) only. purpose discussion here, make difference. Note that,
probabilistic setting, distinguish states based F (s) b(s), goal probability depends
maintaining best way reaching F (s) suffice compute exact goal probability
initial state.

264

fiG OAL P ROBABILITY NALYSIS P ROBABILISTIC P LANNING

annotations states rather part them, multiple search paths may end state
use different landmarks. set remaining landmarks L(s) union
individual path; is, l L non-used iff exists least one path
touch l. still suffices show l landmark s. landmark heuristic approach per Karpas Domshlak (2009) kind book-keeping, uses admissible
heuristic value h(L(s)).
one apply Domshlak Mirkis (2015) reformulation technique without maintaining
landmarks part state, notion transition-cost reduction would become
complicated (lest one loses information). because, reached a~1 reduced
cost due touching landmark l1 , later find another path a~2 touch l1 ,
l1 actually still valid landmark s, therefore need reduce cost
a~1 . account this, would revise path costs posthoc, every time new path
becomes available. revisions, cost reduction path ~a exactly
h(L \ L(s)): weight non-used landmarks L(s) longer subtracted, weight
landmarks L \ L(s) subtracted every ~a because, definition, every ~a touches every
l L \ L(s). cost saved every path ~a s, relative ~a, exactly h(L \ L(s)),
point arguments apply show pruning equivalent pruning
via b(s) < h(L(s)). (This stronger pruning method would get without posthoc
path cost revision.)
summary, based reduced remaining budget b0 (s) < 0 equivalent pruning based
original remaining budget vs. landmark heuristic b(s) < h(L(s)). noted, though,
pruning benefit Domshlak Mirkis (2015) reformulation technique.
technique allows compute another, complementary, admissible heuristic h reformulated task 0 (and Domshlak Mirkis point part motivation,
practice). perspective here, landmark heuristic h used additively
admissible pruning remaining budget, additivity achieved method
generalizing cost partitionings: 0 , cost-reduced variant action applied
once. h abstract away constraint, h uses action twice, employs
reduced cost once, yet pays full cost second time. Exploring kind generalized
cost partitioning detail interesting research line future work.

References
Altman, E. (1999). Constrained Markov Decision Processes. CRC Press.
Baier, C., Groer, M., Leucker, M., Bollig, B., & Ciesinski, F. (2004). Controller Synthesis
Probabilistic Systems (Extended Abstract), pp. 493506. Springer US, Boston, MA.
Barto, A. G., Bradtke, S. J., & Singh, S. P. (1995). Learning act using real-time dynamic programming. Artificial Intelligence, 72(1-2), 81138.
Bertsekas, D. (1995). Dynamic Programming Optimal Control, (2 Volumes). Athena Scientific.
Bertsekas, D., & Tsitsiklis, J. (1996). Neurodynamic Programming. Athena Scientific.
Bonet, B., & Geffner, H. (2001). Planning heuristic search. Artificial Intelligence, 129(12),
533.
265

fiS TEINMETZ & H OFFMANN & B UFFET

Bonet, B., & Geffner, H. (2003a). Faster heuristic search algorithms planning uncertainty
full feedback. Gottlob, G. (Ed.), Proceedings 18th International Joint Conference Artificial Intelligence (IJCAI03), pp. 12331238, Acapulco, Mexico. Morgan Kaufmann.
Bonet, B., & Geffner, H. (2003b). Labeled RTDP: Improving convergence real-time dynamic
programming. Giunchiglia, E., Muscettola, N., & Nau, D. (Eds.), Proceedings 13th
International Conference Automated Planning Scheduling (ICAPS03), pp. 1221,
Trento, Italy. Morgan Kaufmann.
Bonet, B., & Geffner, H. (2005). mgpt: probabilistic planner based heuristic search. Journal
Artificial Intelligence Research, 24, 933944.
Bonet, B., & Geffner, H. (2006). Learning depth-first search: unified approach heuristic search
deterministic non-deterministic settings, application MDPs. Long, D., &
Smith, S. (Eds.), Proceedings 16th International Conference Automated Planning
Scheduling (ICAPS06), pp. 142151, Ambleside, UK. Morgan Kaufmann.
Bonet, B., & Geffner, H. (2012). Action selection MDPs: Anytime AO* versus UCT. Hoffmann, J., & Selman, B. (Eds.), Proceedings 26th AAAI Conference Artificial Intelligence (AAAI12), Toronto, ON, Canada. AAAI Press.
Bryce, D., & Buffet, O. (2008). 6th international planning competition: Uncertainty part. Proceedings 6th International Planning Competition (IPC08).
Camacho, A., Muise, C., & McIlraith, S. A. (2016). FOND robust probabilistic planning: Computing compact policies bypass avoidable deadends. Coles, A., Coles, A.,
Edelkamp, S., Magazzeni, D., & Sanner, S. (Eds.), Proceedings 26th International
Conference Automated Planning Scheduling (ICAPS16). AAAI Press.
Chatterjee, K., Chmelik, M., Gupta, R., & Kanodia, A. (2015). Optimal cost almost-sure reachability POMDPs. Bonet, B., & Koenig, S. (Eds.), Proceedings 29th AAAI Conference
Artificial Intelligence (AAAI15), pp. 34963502. AAAI Press.
Chatterjee, K., Chmelik, M., Gupta, R., & Kanodia, A. (2016). Optimal cost almost-sure reachability POMDPs. Artificial Intelligence, 234, 2648.
Coles, A. J. (2012). Opportunistic branched plans maximise utility presence resource
uncertainty. Raedt, L. D. (Ed.), Proceedings 20th European Conference Artificial
Intelligence (ECAI12), pp. 252257, Montpellier, France. IOS Press.
Coles, A. J., Coles, A., Fox, M., & Long, D. (2013). hybrid LP-RPG heuristic modelling
numeric resource flows planning. Journal Artificial Intelligence Research, 46, 343412.
Coles, A. J., Coles, A., Garca Olaya, A., Jimenez, S., Linares Lopez, C., Sanner, S., & Yoon, S.
(2012). survey seventh international planning competition. AI Magazine, 33(1).
Dai, P., Mausam, Weld, D. S., & Goldsmith, J. (2011). Topological value iteration algorithms.
Journal Artificial Intelligence Research, 42, 181209.
Dean, T. L., & Givan, R. (1997). Model minimization markov decision processes. Kuipers,
B. J., & Webber, B. (Eds.), Proceedings 14th National Conference American
Association Artificial Intelligence (AAAI97), pp. 106111, Portland, OR. MIT Press.
266

fiG OAL P ROBABILITY NALYSIS P ROBABILISTIC P LANNING

Domshlak, C., & Mirkis, V. (2015). Deterministic oversubscription planning heuristic search:
Abstractions reformulations. Journal Artificial Intelligence Research, 52, 97169.
Drager, K., Finkbeiner, B., & Podelski, A. (2009). Directed model checking distancepreserving abstractions. International Journal Software Tools Technology Transfer,
11(1), 2737.
Edelkamp, S. (2001). Planning pattern databases. Cesta, A., & Borrajo, D. (Eds.), Proceedings 6th European Conference Planning (ECP01), pp. 1324. Springer-Verlag.
Gefen, A., & Brafman, R. I. (2012). Pruning methods optimal delete-free planning. Bonet,
B., McCluskey, L., Silva, J. R., & Williams, B. (Eds.), Proceedings 22nd International
Conference Automated Planning Scheduling (ICAPS12). AAAI Press.
Givan, R., Leach, S. M., & Dean, T. (2000). Bounded-parameter Markov decision processes. Artificial Intelligence, 122(1-2), 71109.
Hansen, E. A., & Zilberstein, S. (2001). LAO* : heuristic search algorithm finds solutions
loops. Artificial Intelligence, 129(1-2), 3562.
Haslum, P., Botea, A., Helmert, M., Bonet, B., & Koenig, S. (2007). Domain-independent construction pattern database heuristics cost-optimal planning. Howe, A., & Holte,
R. C. (Eds.), Proceedings 22nd National Conference American Association
Artificial Intelligence (AAAI07), pp. 10071012, Vancouver, BC, Canada. AAAI Press.
Haslum, P., & Geffner, H. (2001). Heuristic planning time resources. Cesta, A., &
Borrajo, D. (Eds.), Proceedings 6th European Conference Planning (ECP01), pp.
121132. Springer-Verlag.
Helmert, M. (2006). Fast Downward planning system. Journal Artificial Intelligence Research, 26, 191246.
Helmert, M., & Domshlak, C. (2009). Landmarks, critical paths abstractions: Whats difference anyway?. Gerevini, A., Howe, A., Cesta, A., & Refanidis, I. (Eds.), Proceedings
19th International Conference Automated Planning Scheduling (ICAPS09), pp.
162169. AAAI Press.
Helmert, M., Haslum, P., Hoffmann, J., & Nissim, R. (2014). Merge & shrink abstraction: method
generating lower bounds factored state spaces. Journal Association Computing Machinery, 61(3).
Hoffmann, J. (2015). Simulated penetration testing: Dijkstra Turing Test++. Brafman, R., Domshlak, C., Haslum, P., & Zilberstein, S. (Eds.), Proceedings 25th International Conference Automated Planning Scheduling (ICAPS15). AAAI Press.
Hoffmann, J., Kissmann, P., & Torralba, A. (2014). Distance? Cares? Tailoring merge-andshrink heuristics detect unsolvability. Schaub, T. (Ed.), Proceedings 21st European
Conference Artificial Intelligence (ECAI14), Prague, Czech Republic. IOS Press.
Hoffmann, J., & Nebel, B. (2001). FF planning system: Fast plan generation heuristic
search. Journal Artificial Intelligence Research, 14, 253302.
Hou, P., Yeoh, W., & Varakantham, P. (2014). Revisiting risk-sensitive MDPs: New algorithms
results. Chien, S., Do, M., Fern, A., & Ruml, W. (Eds.), Proceedings 24th
International Conference Automated Planning Scheduling (ICAPS14). AAAI Press.
267

fiS TEINMETZ & H OFFMANN & B UFFET

Jimenez, S., Coles, A., & Smith, A. (2006). Planning probabilistic domains using deterministic
numeric planner. Proceedings 25th Workshop UK Planning Scheduling
Special Interest Group (PlanSig06).
Karpas, E., & Domshlak, C. (2009). Cost-optimal planning landmarks. Boutilier, C. (Ed.),
Proceedings 21st International Joint Conference Artificial Intelligence (IJCAI09),
pp. 17281733, Pasadena, California, USA. Morgan Kaufmann.
Katz, M., Hoffmann, J., & Helmert, M. (2012). relax bisimulation?. Bonet, B., McCluskey, L., Silva, J. R., & Williams, B. (Eds.), Proceedings 22nd International Conference Automated Planning Scheduling (ICAPS12), pp. 101109. AAAI Press.
Keller, T., & Eyerich, P. (2012). PROST: Probabilistic planning based UCT. Bonet, B.,
McCluskey, L., Silva, J. R., & Williams, B. (Eds.), Proceedings 22nd International
Conference Automated Planning Scheduling (ICAPS12). AAAI Press.
Keller, T., & Helmert, M. (2013). Trial-based heuristic tree search finite horizon MDPs.
Borrajo, D., Fratini, S., Kambhampati, S., & Oddi, A. (Eds.), Proceedings 23rd International Conference Automated Planning Scheduling (ICAPS13), Rome, Italy. AAAI
Press.
Kolobov, A. (2013). Scalable Methods Expressive Models Planning Uncertainty.
Ph.D. thesis, University Washington.
Kolobov, A., Mausam, & Weld, D. S. (2010). Sixthsense: Fast reliable recognition dead ends
MDPs. Fox, M., & Poole, D. (Eds.), Proceedings 24th National Conference
American Association Artificial Intelligence (AAAI10), Atlanta, GA, USA. AAAI Press.
Kolobov, A., Mausam, & Weld, D. S. (2012). theory goal-oriented MDPs dead ends.
de Freitas, N., & Murphy, K. P. (Eds.), Proceedings 28th Conference Uncertainty
Artificial Intelligence (UAI12), pp. 438447, Catalina Island, CA, USA. AUAI Press.
Kolobov, A., Mausam, Weld, D. S., & Geffner, H. (2011). Heuristic search generalized stochastic
shortest path MDPs. Bacchus, F., Domshlak, C., Edelkamp, S., & Helmert, M. (Eds.),
Proceedings 21st International Conference Automated Planning Scheduling
(ICAPS11). AAAI Press.
Kurniawati, H., Hsu, D., & Lee, W. S. (2008). SARSOP: Efficient point-based POMDP planning
approximating optimally reachable belief spaces. Robotics: Science Systems IV.
Kuter, U., & Hu, J. (2007). Computing using lower upper bounds action elimination
MDP planning. Miguel, I., & Ruml, W. (Eds.), Proceedings 7th International Symposium Abstraction, Reformulation, Approximation (SARA-07), Vol. 4612 Lecture
Notes Computer Science, Whistler, Canada. Springer-Verlag.
Kwiatkowska, M., Parker, D., & Qu, H. (2011a). Incremental quantitative verification markov
decision processes. 2011 IEEE/IFIP 41st International Conference Dependable Systems
Networks (DSN), pp. 359370.
Kwiatkowska, M. Z., Norman, G., & Parker, D. (2011b). Prism 4.0: Verification probabilistic
real-time systems. Gopalakrishnan, G., & Qadeer, S. (Eds.), Proceedings 23rd International Conference Computer Aided Verification (CAV11), Vol. 6806 Lecture Notes
Computer Science, pp. 585591. Springer.
268

fiG OAL P ROBABILITY NALYSIS P ROBABILISTIC P LANNING

Little, I., Aberdeen, D., & Thiebaux, S. (2005). Prottle: probabilistic temporal planner. Veloso,
M. M., & Kambhampati, S. (Eds.), Proceedings 20th National Conference American Association Artificial Intelligence (AAAI05), pp. 11811186, Pittsburgh, Pennsylvania, USA. AAAI Press.
Little, I., & Thiebaux, S. (2007). Probabilistic planning vs replanning. ICAPS Workshop
International Planning Competition: Past, Present Future.
Marecki, J., & Tambe, M. (2008). Towards faster planning continuous resources stochastic
domains. Fox, D., & Gomes, C. (Eds.), Proceedings 23rd National Conference
American Association Artificial Intelligence (AAAI08), pp. 10491055, Chicago, Illinois,
USA. AAAI Press.
McMahan, H. B., Likhachev, M., & Gordon, G. J. (2005). Bounded real-time dynamic programming: RTDP monotone upper bounds performance guarantees. Proceedings
22nd International Conference Machine Learning (ICML-05).
Meuleau, N., Benazera, E., Brafman, R. I., Hansen, E. A., & Mausam, M. (2009). heuristic search
approach planning continuous resources stochastic domains. Journal Artificial
Intelligence Research, 34(1), 2759.
Milner, R. (1990). Operational algebraic semantics concurrent processes. van Leeuwen, J.
(Ed.), Handbook Theoretical Computer Science, Volume B: Formal Models Sematics,
pp. 12011242. Elsevier MIT Press.
Muise, C. J., McIlraith, S. A., & Beck, J. C. (2012). Improved non-deterministic planning
exploiting state relevance. Bonet, B., McCluskey, L., Silva, J. R., & Williams, B. (Eds.),
Proceedings 22nd International Conference Automated Planning Scheduling
(ICAPS12). AAAI Press.
Nakhost, H., Hoffmann, J., & Muller, M. (2012). Resource-constrained planning: monte carlo
random walk approach. Bonet, B., McCluskey, L., Silva, J. R., & Williams, B. (Eds.),
Proceedings 22nd International Conference Automated Planning Scheduling
(ICAPS12), pp. 181189. AAAI Press.
Nilsson, N. J. (1971). Problem Solving Methods Artificial Intelligence. McGraw-Hill.
Nissim, R., Hoffmann, J., & Helmert, M. (2011). Computing perfect heuristics polynomial time:
bisimulation merge-and-shrink abstraction optimal planning. Walsh, T. (Ed.),
Proceedings 22nd International Joint Conference Artificial Intelligence (IJCAI11),
pp. 19831990. AAAI Press/IJCAI.
Pommerening, F., & Helmert, M. (2012). Optimal planning delete-free tasks incremental
lm-cut. Bonet, B., McCluskey, L., Silva, J. R., & Williams, B. (Eds.), Proceedings
22nd International Conference Automated Planning Scheduling (ICAPS12). AAAI
Press.
Richter, S., & Helmert, M. (2009). Preferred operators deferred evaluation satisficing planning. Gerevini, A., Howe, A., Cesta, A., & Refanidis, I. (Eds.), Proceedings 19th
International Conference Automated Planning Scheduling (ICAPS09), pp. 273280.
AAAI Press.
269

fiS TEINMETZ & H OFFMANN & B UFFET

Sanner, S. (2010). Relational dynamic influence diagram language (rddl): Language description.
Available http://users.cecs.anu.edu.au/ssanner/IPPC_2011/RDDL.
pdf.
Santana, P., Thibaux, S., & Williams, B. (2016). RAO*: algorithm chance-constrained
POMDPs. Schuurmans, D., & Wellman, M. (Eds.), Proceedings 30th AAAI Conference Artificial Intelligence (AAAI16), pp. 33083314. AAAI Press.
Sarraute, C., Buffet, O., & Hoffmann, J. (2012). POMDPs make better hackers: Accounting
uncertainty penetration testing. Hoffmann, J., & Selman, B. (Eds.), Proceedings
26th AAAI Conference Artificial Intelligence (AAAI12), pp. 18161824, Toronto, ON,
Canada. AAAI Press.
Seipp, J., & Helmert, M. (2013). Counterexample-guided Cartesian abstraction refinement.
Borrajo, D., Fratini, S., Kambhampati, S., & Oddi, A. (Eds.), Proceedings 23rd International Conference Automated Planning Scheduling (ICAPS13), pp. 347351,
Rome, Italy. AAAI Press.
Seipp, J., & Helmert, M. (2014). Diverse additive cartesian abstraction heuristics. Chien, S.,
Do, M., Fern, A., & Ruml, W. (Eds.), Proceedings 24th International Conference
Automated Planning Scheduling (ICAPS14). AAAI Press.
Smith, T., & Simmons, R. G. (2006). Focused real-time dynamic programming MDPs: Squeezing heuristic. Gil, Y., & Mooney, R. J. (Eds.), Proceedings 21st
National Conference American Association Artificial Intelligence (AAAI06), pp.
12271232, Boston, Massachusetts, USA. AAAI Press.
Steinmetz, M., Hoffmann, J., & Buffet, O. (2016). Revisiting goal probability analysis probabilistic planning. Coles, A., Coles, A., Edelkamp, S., Magazzeni, D., & Sanner, S. (Eds.),
Proceedings 26th International Conference Automated Planning Scheduling
(ICAPS16). AAAI Press.
Tarjan, R. E. (1972). Depth first search linear graph algorithms. SIAM Journal Computing,
1(2), 146160.
Teichteil-Konigsbuch, F. (2012). Stochastic safest shortest path problems. Hoffmann, J.,
& Selman, B. (Eds.), Proceedings 26th AAAI Conference Artificial Intelligence
(AAAI12), Toronto, ON, Canada. AAAI Press.
Teichteil-Konigsbuch, F., Kuter, U., & Infantes, G. (2010). Incremental plan aggregation generating policies MDPs. van der Hoek, W., Kaminka, G. A., Lesperance, Y., Luck, M., &
Sen, S. (Eds.), Proceedings 9th International Conference Autonomous Agents
Multiagent Systems (AAMAS10), pp. 12311238. IFAAMAS.
Teichteil-Konigsbuch, F., Vidal, V., & Infantes, G. (2011). Extending classical planning heuristics
probabilistic planning dead-ends. Burgard, W., & Roth, D. (Eds.), Proceedings
25th National Conference American Association Artificial Intelligence (AAAI11),
San Francisco, CA, USA. AAAI Press.
Torralba, A., & Hoffmann, J. (2015). Simulation-based admissible dominance pruning. Yang,
Q. (Ed.), Proceedings 24th International Joint Conference Artificial Intelligence
(IJCAI15), pp. 16891695. AAAI Press/IJCAI.
270

fiG OAL P ROBABILITY NALYSIS P ROBABILISTIC P LANNING

Yoon, S. W., Fern, A., & Givan, R. (2007). FF-Replan: baseline probabilistic planning.
Boddy, M., Fox, M., & Thiebaux, S. (Eds.), Proceedings 17th International Conference
Automated Planning Scheduling (ICAPS07), pp. 352359, Providence, Rhode Island,
USA. Morgan Kaufmann.
Younes, H. L. S., Littman, M. L., Weissman, D., & Asmuth, J. (2005). first probabilistic track
international planning competition. Journal Artificial Intelligence Research, 24,
851887.

271

fiJournal Artificial Intelligence Research 57 (2016) 509-572

Submitted November, 2015; published November, 2016

Survey Computational Treatments Biomolecules
Robotics-Inspired Methods
Modeling Equilibrium Structure Dynamics
Amarda Shehu

AMARDA @ GMU . EDU

Department Computer Science, Department Bioengineering,
School Systems Biology
George Mason University, Fairfax, VA, USA

Erion Plaku

PLAKU @ CUA . EDU

Department Electrical Engineering Computer Science
Catholic University America, Washington, DC, USA

Abstract
fifty years research molecular biology demonstrated ability
small large molecules interact one another propagate cellular processes
living cell lies ability molecules assume switch specific structures
physiological conditions. Elucidating biomolecular structure dynamics equilibrium
therefore fundamental furthering understanding biological function, molecular mechanisms cell, biology, disease, disease treatments. now, wealth
methods designed elucidate biomolecular structure dynamics contributed diverse
scientific communities. survey, focus recent methods contributed Robotics
community promise address outstanding challenges regarding disparate length time
scales characterize dynamic molecular processes cell. particular, survey roboticsinspired methods designed obtain efficient representations structure spaces molecules isolation assemblies purpose characterizing equilibrium structure dynamics.
exhaustive review impossible endeavor, survey balances description important
algorithmic contributions critical discussion outstanding computational challenges.
objective spur research address outstanding challenges modeling equilibrium
biomolecular structure dynamics.

1. Introduction
way chain amino acid units protein molecule coiled folded space
worked first time. protein myoglobin, molecule contains
2,600 atoms. John Kendrew began feature article Scientific American 1961,
reporting first atomistic model protein structure1 obtained via X-ray crystallography (Kendrew, Dickerson, Strandberg, Hart, Davies, Phillips, & Shore, 1960). model drawn
various graphical representations Figure 1. pioneering work resolving structures
globular proteins, Kendrew Perutz awarded Nobel Prize chemistry 1962.
year Watson, Crick, Wilkins shared Nobel Prize physiology medicine
using X-ray crystallography data determine helical structure DNA.
1. purpose survey, distinguish structure conformation. Structure refer
specific placement atoms comprise biomolecule R3 . concept conformation defined
Section 2.
c
2016
AI Access Foundation. rights reserved.

fiS HEHU & P LAKU

(a) X-ray model myoglobin heme group

(b) Model atomistic detail (no heme group)

(c) Various models myoglobin heme group
Figure 1: (a) X-ray model myoglobin heme group bound determined Kendrew
drawn Visual Molecular Dynamics (VMD) software (Humphrey et al., 1996). model
found Protein Data Bank (PDB) (Berman et al., 2003), repository known protein structures,
PDB entry 1MBN. Drawing surface protein facilitates visually locating cavity
heme group, helps myoglobin carry oxygen tissue, binds. heme group drawn
ball-and-stick representation red. (b) heavy atoms comprise 153-amino acid long myoglobin
chain drawn ball-and-stick representation, color-coded amino acid belong.
backbone connects atoms consecutive amino acids chain drawn white NewCartoon
representation VMD. (c) X-ray model myoglobin PDB entry 1MBN superimposed 12
models obtained protein bound heme group Nuclear Magnetic Resonance (NMR),
deposited PDB PDB entry 1MYF.

ability visualize structures biomolecules atomistic detail shot arm
molecular biology marked beginning revolution molecular structural biology; race
soon ensued across wet laboratories determine three-dimensional (3d) structures assumed proteins biomolecules physiological conditions. Since early days, set protein structures resolved wet-laboratory, beginning myoglobin lysozyme (Kendrew,
Bodo, Dintzis, Parrish, Wyckoff, & Phillips, 1958; Kendrew et al., 1960; Phillips, 1967), grown
510

fiC OMPUTATIONAL REATMENTS B IOMOLECULES ROBOTICS -I NSPIRED ETHODS

hundred thousand, freely available anyone download PDB (Berman
et al., 2003).
pioneering work Anfinsen, earned Nobel Prize Chemistry 1973,
demonstrated ability protein carry biological function dependent
ability fold onto specific 3d structure reversibly (Anfinsen, 1973). Anfinsen experiments
led view folded structure corresponds global minimum underlying energy
surface. also showed information needed protein assume 3d, biologicallyactive structure largely encoded amino-acid sequence. Since then, study biomolecular
function consider role sequence structure (Fersht, 1999).
Figure 1(a), shows surface biologically-active structure myoglobin protein, exposes central cavity allows binding heme group myoglobin. Figure 1(b)
traces amino-acid chain makes myoglobin additionally draws heavy atoms constituting amino acid protein. simple images illustrate two important points: first,
structure plays central role function (specifically, complementary geometric physicochemical features 3d structures molecules key stable molecular interactions) (Boehr &
Wright, 2008); second, ability amino-acid chain fold onto makes protein
structures complex. Understanding biologically-active structure biomolecule assumes cell key elucidating molecular mechanisms healthy diseased
cell, also determining address abnormal role biomolecule mechanisms
order treat disease. particular, research shown many abnormalities involve proteins aberrant biological function (Soto, 2008; Uversky, 2009; Fernandez-Medarde & Santos,
2011; Neudecker, Robustelli, Cavalli, Walsh, Lundstrm, Zarrine-Afsar, Sharpe, Vendruscolo, &
Kay, 2012) due external internal perturbations (e.g., DNA mutations, copying errors) affecting ability molecules assume specific structures (Onuchic, Luthey-Schulten, &
Wolynes, 1997; Ozenne, Schneider, Yao, Huang, Salmon, Zweckstetter, Jensen, & Blackledge,
2012; Levy, Jortner, & Becker, 2001; Miao, Sinko, Pierce, Bucher, Walker, & McCammon, 2014;
Gorfe, Grant, & McCammon, 2008; Grant, Gorfe, & McCammon, 2009).
treatment relationship structure function would incomplete
dynamic personality biomolecules taken account (Jenzler-Wildman & Kern, 2007).
X-ray models biomolecular structures seem suggest rigid molecules atoms frozen
space, increasing number wet-laboratory, theoretical, computational studies shown
biomolecules systems particles perpetual motion. Indeed, Feynman taught early
jiggling wiggling atoms (Feynman, Leighton, & Sands, 1963). Cooper others later
posited inherent dynamics biomolecules could explained general, theoretical
treatment molecules thermodynamic systems striving towards equilibrium, lowest freeenergy state (Cooper, 1984). Thus, inherent dynamics biomolecules could explained
using fundamental physics principles; statistical mechanics formulation also revealed inherent
uncertainty given time particular state molecule (Cooper, 1984).
dynamics molecular systems investigated around time first experimental
models protein structures emerging. 1967, Verlet simulated dynamics argon
demonstrated simulations able reproduce equilibrium properties (Verlet, 1967).
Application Verlet algorithm simulating protein dynamics would wait one
decade. 1977, McCammon Karplus reported 9.2 picosecond-long trajectory showing in-vacuum, atomistic fluctuations bovine pancreatic trypsin inhibitor around folded,
active structure (the latter already obtained via wet-laboratory techniques) (McCammon,
511

fiS HEHU & P LAKU

Gelin, & Karplus, 1977). Advancements wet-laboratory techniques, spewed
dozen models biologically-active protein structures late 70s, facilitated revolution
computational structural biology. pioneering algorithmic work Verlet, Karplus, McCammon,
Levitt, Warshel, Lifson (for Karplus, Levitt, Warshel shared 2013 Nobel Prize
chemistry) provided earliest frameworks computational treatments biomolecules
means investigate equilibrium structure dynamics (Fersht, 2013).
Since early days, advances wet-laboratory techniques proceeded hand hand
advancements computational techniques, often feeding each-other. advent NMR
structure determination provided evidence ability biomolecules fluctuate different structures even equilibrium (Kay, 1998, 2005). Figure 1(c) shows, addition X-ray
structure myoglobin bound heme group, twelve models obtained via NMR, showcasing
intrinsic flexibility important biomolecule molecular partner cell. Nowadays, wet-laboratory techniques, NMR cryo-Electron Microscopy (cryo-EM) resolve equilibrium structures quantify equilibrium dynamics. example, NMR used
identify well-populated intermediate structures along transition (Aden & Wolf-Watz, 2007).
Hybrid techniques combine NMR relaxation measurements X-ray models derived
room-temperature crystallographic, single-molecule spectroscopy techniques tune optical radiation observe one molecule, others elucidate fast slow dynamic processes lasting
picoseconds milliseconds (Torella, Holden, Santoso, Hohlbein, & Kapanidis,
2011; Fenwick, van den Bedem, Fraser, & Wright, 2014; Karam, Powdrill, Liu, Vasquez, Mah,
Bernatchez, Gotte, & Cosa, 2014; Moerner & Fromm, 2003; Greenleaf, Woodside, & Block, 2007;
Michalet, Weiss, & Jager, 2006; Diekmann & Hoischen, 2014; Hohlbein, Craggs, & Cordes, 2014;
Schlau-Cohen, Wang, Southall, Cogdell, & Moerner, 2013; Moffat, 2003; Schotte, Lim, Jackson,
Smirnov, Soman, Olson, Phillips, Wulff, & Anfinrud, 2003; Roy, Hohng, & Ha, 2008; Fenwick
et al., 2014; Hohlbein et al., 2014; Lee, M., Kim, & Suh, 2013; Socher & Imperiali, 2013; Gall,
Ilioaia, Kruger, Novoderezhkin, Robert, & van Grondelle, 2015).
particular, wet-laboratory techniques employ fluorescence-based sensors, provide
information dynamic, biological events effectively monitoring changes signals
strategically-placed fluorophores (Socher & Imperiali, 2013). Depending placement
fluorophores, binding two molecular partners switch/transition one molecule different structures monitored real time. techniques promising
rapidly adopted study specific biological systems interest, reliance fluorophores limits generality techniques, well structural detail obtained. moment, wet-laboratory techniques obtain incomplete view equilibrium dynamics, generally unable span disparate length time scales involved
structural transition molecule (Maximova, Moffatt, Ma, Nussinov, & Shehu, 2016);
atomic motions occur picosecond scale, side-chain motions take nanoseconds,
concerted motions among groups atoms facilitating structural rearrangements molecular recognition events take anywhere microseconds milliseconds (Shaw,
Maragakis, Lindorff-Larsen, Piana, Dror, Eastwood, Bank, Jumper, Salmon, Shan, & Wriggers,
2010; Lindorff-Larsen, Piana, Dror, & Shaw, 2011; Zagrovic, Snow, Shirts, & Pande, 2002; Piana, Lindorff-Larsen, & Shaw, 2012b); extreme cases, binding natural drug molecules
proteins occurs hours scale (Hoelder, Clarke, & Workman, 2012).
Computational treatments biomolecules driven promise complementing wetlaboratory treatments obtaining comprehensive detailed characterization equilibrium
512

fiC OMPUTATIONAL REATMENTS B IOMOLECULES ROBOTICS -I NSPIRED ETHODS

dynamics. current well-known frameworks employed silico Molecular Dynamics
(MD) (Verlet, 1967; McCammon et al., 1977) Monte Carlo (MC) (Hastings, 1970; Metropolis,
Rosenbluth, Rosenbluth, Teller, & Teller, 1953). principle, entire equilibrium dynamics
molecule simulated simply following motions constitutive atoms along
physical forces atoms impose one another. foundation MD framework.
contrast, MC framework, structural perturbation moves applied atoms bonds connecting
atoms result physical forces instead design decisions. Different local search
strategies formulated make use moves iteratively explore neighborhoods
structure space biomolecule.
scope capabilities MD- MC-based treatments biomolecules significantly increased due improvements hardware parallel computation strategies. Specialized architectures, Anton, supercomputer designed MD simulations, (Piana, LindorffLarsen, Dirks, Salmon, Dror, & Shaw, 2012a; Piana et al., 2012b; Lindorff-Larsen et al., 2011),
GPUs (Stone, Phillips, Freddolino, Hardy, Trabuco, & Schulten, 2007; Harvey, Giupponi, & de
Fabritiis, 2009; Tanner, Phillips, & Schulten, 2012; Gotz, Williamson, Xu, Poole, Le Grand, &
Walker, 2012), petascale national supercomputers, BlueWaters, Titan, Mira, Stampede (Dubrow, 2015; Zhao, Perilla, Yufenyuy, Meng, Chen, Ning, Ahn, Gronenborn, Schulten,
Aiken, & Zhang, 2013) allowed characterizing biomolecular structure dynamics
microsecond time scale. Algorithmic improvements dynamic load balancing (Fattebert, Richards,
& Glosli, 2012), neighbor searches (Proctor, Lipscomb, Zou, Anderson, & Cho, 2012), optimal force splitting (Batcho, Case, & Schlick, 2001) allow effectively distributing simulation
dynamics molecular systems comprised billions particles (Perilla, Goh, Cassidy, Liu,
Bernardi, Rudack, Yu, Wu, & Schulten, 2015).
principle, full account equilibrium dynamics biomolecule requires comprehensive characterization structure space available biomolecule equilibrium well
underlying energy surface governs accessibility structures transitions
structures equilibrium. remains challenging via MD MC-based frameworks,
algorithmic enhancements classic MD MC frameworks essentially aim enhance
sampling structure space biomolecule. review state-of-the-art enhancements
found work Maximova et al. (2016).
survey paper, focus instead emerging contributions Robotics community
enhance sampling complementary algorithmic strategies. Specifically, review
robotics-inspired methods designed model structural excursions biomolecule equilibrium
building conceptually techniques designed originally robot motion planning.
methods reached crucial stage. shown applicable characterization
diverse molecular mechanisms computational structural biology, protein-ligand binding,
folding unfolding peptides, proteins, RNA molecules, transitions small peptides
large proteins thermodynamically-stable semi-stable structural states. survey shows, methods capable addressing challenging computational issues posed
application settings, yet widely adopted computational biology
community large. various reasons, discussed survey, methods
seen providing efficient less detailed less accurate characterization biomolecular equilibrium structure dynamics. survey provides critical review robotics-inspired
methods lays outstanding issues need addressed methods considered reliable tools widely adopted modeling biomolecular structure dynamics.
513

fiS HEHU & P LAKU

survey organized follows. background models biomolecular energetics
geometry provided Section 2. Section 3 introduces main classes problems
biomolecular modeling addressed robotics-inspired methods, summarizes robot motion
planning frameworks methods build, concludes brief description
challenges faced robotics-inspired methods context biomolecular modeling. Section 4
provides examples design decisions address challenges comprehensive
detailed review robotics-inspired methods modeling biomolecular structure dynamics.
Section 5 concludes survey critical summary remaining challenges discussion
several prospects future research.

2. Background
structural excursions regulate recognition events biomolecule participates
cell understood via theoretical treatment biomolecules thermodynamic systems
hopping energetic states. hops fundamentally result concerted motions
atoms make biomolecule; physical system, constitutive particles
state perpetual motion, fuelled thermal excitation, subjecting one another
physical forces (Cooper, 1984). forces cumulatively drive molecular system toward lowerenergy states, thermal excitations kick locally-optimal states, providing sufficient
randomness allow entire system undergo biased exploration structure space.
following first summarize current knowledge atomic forces biomolecular energy functions employed computational treatments biomolecular structure dynamics. rest Section provides details biomolecular geometry, showing biomolecules
treated mechanistically modular systems composed numerous, heterogeneous components purpose characterizing equilibrium structure dynamics silico.
2.1 Biomolecular Energetics: Molecular Mechanics
physical interactions among particles make molecular system principle
measured via quantum mechanics (QM) methods. QM methods carry detailed accurate
electronic structure calculations currently limited applicability molecular systems
composed hundred atoms (Khaliullin, VandeVondele, & Hutter, 2013). Instead, molecular mechanics (MM) methods methods choice evaluate structures
macromolecules, proteins, RNA, DNA, large molecular systems comprised
several molecules.
Though long known atoms molecule subject one another physical forces,
Coulomb forces others, work Levitt Warshel Lifson laboratory
Weizmann Institute Science propelled design consistent (now known MM) energy
functions molecules. Lifson argued possible come small number
consistent, transferable parameters depend local environment atom allow
analyzing energetics small crystalline molecules (Lifson & Warshel, 1968). Kendrew realized
consistent energy functions could used conduct energetic evaluations different
placements (that is, structures) atoms comprising proteins nucleic acids. Levitt
Lifson operationalized realization conduct energy refinements protein structures (Levitt &
Lifson, 1969).
514

fiC OMPUTATIONAL REATMENTS B IOMOLECULES ROBOTICS -I NSPIRED ETHODS

MM energy functions become detailed accurate, still estimates
true potential energy molecule, summing possible, physical interactions
atoms molecule. Research designing MM energy functions active, many
different functions offered different computational chemistry labs across world.
functions largely follow common functional form, categorize pairwise atomic interactions
local non-local interactions; noted accurate energy functions
available consider n-particle interactions, computationally expensive
widely adopted (Clementi, 2008). Local interactions concern modeling forces due bonds,
bond angles, periodicity dihedral/torsion angles. Non-local interactions divided
electrostatic (measured Coulomb potential) van der Waals (measured
Lennard-Jones LJ potential) interactions. different types interactions typically
linearly combined together, weight, associate potential energy value
particular placement atoms given molecular structure.
following equation provides example popular CHARMM energy function (Brooks,
Bruccoleri, Olafson, States, Swaminathan, & Karplus, 1983) integrated NAMD software package simulation biomolecular dynamics (Phillips, Braun, Wang, Gumbart, Tajkhorshid, Villa, Chipot, Skeel, Kale, & Schulten, 2005).

ECHARMM =

X

kb (b b0 )2

+

kUB (S S0 )2

+

X

+

bonds

X
UB

k ( 0 )2

valence angles

X

k (1 + cos(n ))

+

kimp ( 0 )2

+

dihedral angles

X
improper dihedral angles

X
nonbonded atoms i, j

X
nonbonded atomsi, j

ij

h Rmin
Rminij 6
ij 12
2
+
rij
rij

qi qj
rij

k weights constants, 0 subscript indicates equilibrium, ideal values distances
angles. first term effectively penalizes deviations bond lengths equilibrium values
quadratic potential. second term, also referred Urey Bradley (UB)
1,3 term, introduces similar penalty pairs atoms separated two covalent bonds,
distance two atoms involved 1,3 interaction denoted S. third term quadratic
potential valence angles (between two consecutive bonds), denoted . fourth term
potential calculated dihedral/torsion angles models presence steric barriers
atoms separated three covalent bonds. term, n variables multiplicity
phase angles, respectively. CHARMM, improper dihedral angles specially penalized,
fifth term. sixth term shows LJ potential CHARMM. LJ term summing
515

fiS HEHU & P LAKU

van der Waals interactions non-bonded atoms, rij measures Euclidean distance
two non-bonded atoms (that covered UB term), Rminij = (Rmini + Rminj )/2
minimum interaction radius atoms, measured half sum known van
der Waals radii Rmini Rminj (ij weight specific types atoms j). LJ
term sums weak attraction long distances strong repulsion short distances. LJ
term CHARMM 126 functional form, exponent 12 repulsive sub-term
exponent 6 attractive sub-term. last term CHARMM function measures
electrostatic interactions via Coulomb potential: qi qj known partial charges atoms
j, rij measures Euclidean distance atoms j, dielectric constant
encoding type environment biomolecule (vacuum different types solvent
environments).
Differences available potential energy functions due different weights, different
exponents used measure repulsion versus attraction terms van der Waals interaction,
explicit estimation hydrogen-bonding interactions outside umbrella van der Waals interactions, (Hornak, Abel, Okur, Strockbine, Roitberg, & Simmerling, 2006). Amber suite
energy functions, integrated Amber MD simulation package (Case, Darden, Cheatham,
Simmerling, Wang, Duke, Luo, Merz, Pearlman, Crowley, Walker, Zhang, Wang, Hayik, Roitberg,
Seabra, Wong, Paesani, Wu, Brozell, Tsui, Gohlke, Yang, Tan, Mongan, et al., 2014), OPLS (Jorgensen, Maxwell, & Tirado-Reves, 1988), CHARMM follow similar functional form.
similar functions CEDAR (Hermans, Berendsen, van Gunsteren, & Postma, 1984) GROMOS (van Gunsteren, Billeter, Eising, Hunenberger, Kruger, Mark, Scott, & Tironi, 1996), incorporated GROMACS simulation package (Van Der Spoel, Lindahl, Hess, Groenhof, Mark,
& Berendsen, 2005), others. review functions, known physics-based function,
found work Ponder Case (2003). functions, known knowledge-based
function, include additional terms derived conducting statistics known active structures
proteins PDB. functions best suited specific applications, rapid modeling
equilibrium structures. Rosetta (Leaver-Fay, Tyka, Lewis, Lange, Thompson, Jacak, Kaufman,
Renfrew, Smith, Sheffler, Davis, Cooper, Treuille, Mandell, Richter, Ban, Fleishman, Corn, Kim,
Lyskov, Berrondo, Mentzer, Popovi, & et. al., 2011) Quark (Xu & Zhang, 2012) recent
examples knowledge-based functions.
Whether physics-based knowledge-based (or hybrid), current molecular energy functions
models and, such, contain inherent errors need taken account modeling biomolecular structure dynamics (Hornak et al., 2006). addition, functions, despite specific functional form, computationally expensive terms LJ
Coulomb terms due summation pairs atoms. terms also ones
sensitive small atomic motions. particular, 12-6 functional form LJ term
provides great complexity non-linearity energy surface one associate
structure space biomolecule. quite common reduce total energy structure
hundred calories solely due improvements LJ term imperceptible changes
atomic positions. Moreover, small atomic displacements lower value one term
increasing another energy function. optimization point view, terms
linearly combined energy function essentially conflicting optimization objectives.
computational biology, issue known frustration results rugged rough energy
surfaces (that is, rich local minima). broader AI community, surfaces would referred multi-modal. true biomolecular energy surfaces overly rugged (known
516

fiC OMPUTATIONAL REATMENTS B IOMOLECULES ROBOTICS -I NSPIRED ETHODS

principle minimal frustration) (Clementi, 2008; Nevo, Brumfeld, Kapon, Hinterdorfer, &
Reich, 2005), modeled energy surfaces one probe silico current energy functions shown exceptionally rugged (Olson & Shehu, 2012; Molloy, Saleh, & Shehu, 2013;
Lois, Blawzdziewicz, & OHern, 2010).
2.2 Biomolecular Energy Surface
Equilibrium biomolecular dynamics visualized structural excursions energy surface. picture emerges proteins funnel-like, multidimensional energy surface (Onuchic et al., 1997; Dill & Chan, 1997). Projecting surface onto coordinates
capture relevant features different structures would allow summarizing thus visualizing
energy surface terms landscape (Onuchic & Wolynes, 2004).
energy landscape shown two different camera views Figure 2 illustrates protein energy
landscapes expected reconstructed silico. Horizontal cross-sections landscape every
dE units apart correspond different energetic states. cross-sections go width
energy decreases; fewer options place atoms molecule potential energy gets lower
without incurring energetic costs greater dE. width cross-section, structural
diversity energetic state, captured notion entropy. Thermodynamically-stable states
low free energy F , measured F = hEi S, hEi average potential
energy structures grouped together state, temperature, entropy.
first visual illustration, proposed Dill Chan (1997), highlighted main features
expected true protein energy landscapes, single, deep wide basin corresponding
thermodynamically-stable state shallower, narrower basins corresponding metastable states serving possible kinetic traps. landscape shown Figure 2(a) synthetic
one closer landscapes corresponding existing MM energy functions; landscape
smooth rather rich local minima; words, landscape highly rugged
rough. different camera view Figure 2(b) emphasizes presence multiple, similarly-deep
wide basins among current energy functions cannot distinguish purpose
predicting stable state via energetic-based arguments; given inherent errors, structurefunction arguments cannot depend small energetic differences.
energy landscape view instrumental linking molecular structure, dynamics, function. Viewing proteins biomolecules terms energy landscapes gave rise better
understanding folding binding diffusion-like processes series sequential, deterministic events. new, landscape view (Baldwin, 1995), biomolecules reach
stable state equilibrium tumbling energy landscape along multiple routes (Bryngelson & Wolynes, 1987; Bryngelson, Onuchic, Socci, & Wolynes, 1995; Onuchic & Wolynes, 2004).
light new view, intermediate, meta-stable states proteins would sometimes
found wet laboratory transitioning stable state correspond wide
basins landscape. illustration provided Figure 2(b).
new view inspired new understanding dynamic molecular processes, known conformational selection population shift (Ma, Kumar, Tsai, & Nussinov, 1999; Tsai, Ma, & Nussinov,
1999b; Tsai, Kumar, Ma, & Nussinov, 1999a). Conformational selection refers idea
states unbound molecular unit present accessible bound unit. many unbound/uncomplexed biomolecules, may many semi-stable states equilibrium. proximity ligand another molecular partner shifts equilibrium (and thus probability distri517

fiS HEHU & P LAKU

(a) Illustration complex energy landscape

(b) Tilted camera view highlights presence multiple energy basins
Figure 2: (a) shown landscape illustrates often reconstructed silico, rough landscapes rich
local minima. (b) tilted camera view emphasizes presence multiple energetic basins. basin
defined neighborhood local minimum fitness landscape. interested reader encouraged learn features landscapes arise optimization problems Stadlers seminal
review (Stadler, 2002). Given high dimensionality structure space, many methods probe energy
landscapes cannot guarantee particular, sought stable meta-stable state captured among
probed basins, none probed basins artifacts energy function employed.

bution possible states system found equilibrium) towards one states
close optimal equilibrium unbound/uncomplexed molecule. words, presence binding partner considered external perturbation unbound/uncomplexed
energy landscape. Internal perturbations refer changes biomolecules composition due
changes DNA, copy read errors, post-translation modifications occur.
many aberrant versions biomolecule, energy barriers stable semi-stable states
518

fiC OMPUTATIONAL REATMENTS B IOMOLECULES ROBOTICS -I NSPIRED ETHODS

drastically change modify underlying detailed structural mechanism regulating function,
resulting dysfunction even loss function (Clausen, Ma, Nussinov, & Shehu, 2015).
principle conformational selection allows employing analysis energy landscapes
unbound molecules identify structural states interest complexation events. latter
found among meta-stable stable states uncomplexed molecule thus
identified via modeling simulation uncomplexed molecule.
2.3 Computing Structures Structural Transitions
two main problems addressed silico elucidate biomolecular equilibrium structure dynamics concern (i) computing ensemble structures constituting stable
meta-stable states relevant biological function (ii) computing detailed structural transitions structures. first problem amenable stochastic optimization, fundamentally involves locating deep wide basins/minima nonlinear multimodal energy
surface. second problem entails elucidating different routes employed biomolecule
switches two structures. survey focuses primarily second problem, computing structural transitions bound unbound biomolecules. Specifically, survey reviews
methods employ robotics analogies address problem. While, principle, roboticsinspired methods also provide information structure space available biomolecule
equilibrium, other, powerful stochastic optimization algorithms exist purpose.
refer interested readers review Shehu (2013), surveys state-of-the-art evolutionary
algorithms (EAs) capable extracting efficient, discrete representations protein energy surfaces.
minimum, algorithms aiming model biomolecular structures comprised three
functional units: (i) way represent/model biomolecular structure; (ii) way modify
models order obtain new structures; (iii) way evaluate energetics structures.
existing MM energy functions summarized context biomolecular energetics
provide way evaluate models biomolecular structures explored silico. functional units
(i) (iii) related, model chosen protein structure determines great extent
moves perturbation operators designed efficiently effectively explore
structure space. Below, summarize models popular among different algorithms
employed model equilibrium structures dynamics biomolecules. Details regarding
moves perturbation operators designed interface models provided later
survey reviewing robotics-inspired methods.
2.4 Molecular Models: Selecting Variables Interest
Covalent bonds link atoms together molecule. protein molecules, atoms organized
amino acids, come twenty different types nature. amino acids contain common
core heavy atoms make backbone unique set heavy atoms make
side chain (hydrogen/light atoms found backbone side-chain groups). twenty
naturally-occurring amino acids differ side chain. Figure 3(a) shows N, CA, C,
heavy-atoms comprise backbone amino acid illustrates amino acids
connected via covalent, peptide bonds serial fashion form (polypeptide) chain.
referred protein often one polypeptide chain; protein-protein binding polypeptide
chains stay together via non-covalent, weak interactions.
519

fiS HEHU & P LAKU

(a)

(b)

Figure 3: (a) chain six amino acids, backbone atoms N (gray), CA (black), C (gray),
(silver). peptide bond Ni -Ci+1 links two amino acids (i proceeds N- C-terminus, refer
backbone N C atoms peptide bonds). Circled atoms comprise side chain shown amino
acid. (b) three types internal coordinates shown here, bond length di , valence angle
two consecutive angles, torsion dihedral angle defined three consecutive bonds.
dihedral angle angle two normals corresponding planes defined
consecutive bonds j j + 1 consecutive bonds j + 1 j + 2. Depending backbone
bonds defined, dihedral angles referred either , annotated position
amino acid defined (in direction N- C-terminus). instance,
refers dihedral angle bond connecting backbone N backbone CA atom amino acid
i, refers dihedral angle defined bond connecting backbone CA backbone C
atom amino acid i. Characteristic values observed , psi angles among equilibrium protein
structures (Ramachandran et al., 1963).

520

fiC OMPUTATIONAL REATMENTS B IOMOLECULES ROBOTICS -I NSPIRED ETHODS

Figure 3(a) illustrates side chains dangle backbone polypeptide chain. Treating
protein molecule model atoms represented balls bonds
sticks exposes interesting questions regarding perform deformations model without
breaking covalent bonds. question essence structure modeling researchers
answer defining variables represent molecule able capture intrinsic
flexibility equilibrium.
2.4.1 C ARTESIAN C OORDINATE -BASED ODELS
intuitive model molecular structure, Cartesian coordinate atom
selected variable. Cartesian coordinate-based model preferred one MD algorithms, move individual atoms molecule according cumulative force sums
interactions atom others molecule. However, model ideal. First,
redundant, demanding 3N variables molecule N atoms. small peptide drug
molecules, number atoms may dozens, even small proteins, number
atoms easily surpass hundred; result, variable space hundreds dimensions.
Many strategies offered reduce number variables essentially removing
certain atoms modeling. example, side-chain atoms first sacrificed protein
structure modeling, since demonstrated main features equilibrium protein
structures captured backbone (Rose, Fleming, Banavar, & Maritan, 2006).
reduced structures modeled, side chains modeled via side-chain packing algorithms.
studies focusing modeling molecular interactions, atoms comprise interaction
site explicitly modeled. decisions effectively result reduced models (and thus fewer dimensions selected variable space), ranging CA traces, central CA atom
modeled amino acid, backbone models, backbone chain tracked
3d space (Papoian, Ulander, Eastwood, Luthey-Schulten, & Wolynes, 2004; Matysiak & Clementi,
2004; Das, Matysiak, & Clementi, 2005; Matysiak & Clementi, 2006; Hoang, Trovato, Seno, Banavar, & Maritan, 2007; Rose et al., 2006). rich literature reduced models
energy functions designed interface models (Clementi, 2008).
Representing molecular structure terms Cartesian coordinates (or subset of)
constitutive atoms appealing, new instantiation variable space readily
evaluated terms energetics. recall central LJ electrostatic/Coulomb terms
energy functions widely adopted biomolecular structure dynamics modeling operate 3d coordinates atoms. However, Cartesian coordinate-based model
redundant ineffective. First, model results excessive number variables, poses
great challenges sampling-based method aimed probing structure space one sample
time. Second, ineffective, encode explicit implicit geometric
constraints present molecular structures.
Many efforts computational biophysics community target reduction coordinates.
resulting models referred coarse-grained models representations. first
model, employed MC simulation folding bovine pancreatic trypsin inhibitor,
represented amino-acid residue one pseudo-atom (Levitt & Warshel, 1975). Work
coarse-grained multiscale models (in latter, different parts structure represented
different levels detail/resolution different time length scales) key extend
spatio-temporal reach MD MC simulations biomolecular dynamics. work
521

fiS HEHU & P LAKU

additional onerous task designing accompanying energy functions reproduce known
thermodynamic properties even lower mixed structural resolution. Indeed, 2013 Nobel
Prize Warshel recognized seminal work multiscale models built QM/MM
method (Warshel & Levitt, 1976; Warshel, 2003; Kamerlin, Haranczyk, & Warshel, 2009; Mukherjee & Warshel, 2011, 2012; Dryga, Chakrabarty, Vicatos, & Warshel, 2011; Rychkova, Mukherjee,
Bora, & Warshel, 2013; Mukherjee & Warshel, 2013). interested reader directed review
Clementi (2008) coarse-grained models. review Zhou (2014) focuses multiscale
models.
2.4.2 E NCODING VARIABLE EPENDENCIES C ARTESIAN C OORDINATE -BASED ODELS
Outside realm modeling chemical reaction processes, bond formation breaking,
modeling biomolecular equilibrium structures dynamics, application setups require
preserving certain structural features formulated local non-local constraints.
constraints, keeping bonded atoms distance ideal/equilibrium length
bond, known explicit, local constraints. trivially extracted specification
chemical composition molecule, involve neighboring atoms. Equilibrium conditions
place additional, implicit constraints biomolecular structures. need preserve favorable
Lennard-Jones interactions, instance, places (non-local/long-range) constraints non-bonded
atoms. long-range constraints cannot effectively captured model
variable Cartesian coordinate atom. perturbation operator interfaces
model modifies variables information invalid energetically-unfavorable
assignments subsets variables, variable dependencies captured model.
external energy model crucial form energy function evaluate results
perturbation operator detect variable instantiations resulting violations.
Cartesian coordinate-based model encode variable dependencies. latter
extracted via several techniques, including multivariate analysis techniques analyze known
equilibrium structures biomolecule identify subsets atoms exhibit simultaneous displacements; is, move concert. essential premise techniques known
structures good examples solutions near-solutions energy function, analysis
examples expose variable dependencies. dependencies employed
design reduced Cartesian coordinate-based models readily encode energetic
constraints satisfied provided examples (solution near-solution structures) effective
perturbation operators readily yield new near-solution instantiations reduced variable
space (Clausen & Shehu, 2015).
Multivariate Analysis Techniques Obtain Collective Variables sub-field statistical
techniques identification collective motions, also referred collective coordinates collective variables rich, review subject survey. Instead, point
recent work narrow context biomolecular modeling, variance-maximizing techniques, Principal Component Analysis (PCA) (Shlens, 2003), Isomap (Tenenbaum, de Silva,
& Langford, 2000), Locally Linear Embedding (Roweis & Saul, 2000), Diffusion Maps (Coifman,
Lafon, Lee, Maggioni, Nadler, Warner, & Zucker, 2005), others (van der Maaten, Postma, & van
den Herik, 2009) employed analyze biomolecular structures dynamics (Teodoro,
Phillips, & Kavraki, 2003; Das, Moll, Stamati, Kavraki, & Clementi, 2006; Plaku, Stamati, Clementi,
& Kavraki, 2007; Gorfe et al., 2008; Grant et al., 2009; Hori, Chikenji, & Takada, 2009; Maisuradze,
522

fiC OMPUTATIONAL REATMENTS B IOMOLECULES ROBOTICS -I NSPIRED ETHODS

Liwo, & Scheraga, 2009; Rohrdanz, Zheng, Maggioni, & Clementi, 2011; Zheng, Rohrdanz, Maggioni, & Clementi, 2011) and, importantly, identify variables represent collective motions
atoms (Zheng, Rohrdanz, & Clementi, 2013; Clausen & Shehu, 2015; Clausen et al., 2015; Molloy, Clausen, & Shehu, 2016; Maximova, Plaku, & Shehu, 2015). addition methods,
ones Normal Mode Analysis (NMA) (Ciu & Bahar, 2005) also rich history
computational structural biology (Atilgan, Durell, Jernigan, Demirel, Keskin, & Bahar, 2001;
Delarue & Sanejouand, 2002; Kim, Chirikjian, & Jernigan, 2002b; Zheng & Doniach, 2003; Tama,
Valle, Frank, & Brooks, 2003; Bahar & Rader, 2005; Maragakis & Karplus, 2005; Zheng & Brooks,
2005; Zheng, Brooks, & Hummer, 2007; Yang, Song, Carriquiry, & Jernigan, 2008; Yang, Majek,
& Bahar, 2009; Das, Gur, Cheng, Jo, Bahar, & Roux, 2014). normal modes extracted
NMA also often employed effective perturbation operators robotics-inspired methods (Tama & Sanejouand, 2001; Kim, Jernigan, & Chirikjian, 2002a; Kirillova, Cortes, Stefaniu, &
Simeon, 2008; Schuyler, Jernigan, Wasba, Ramakrishnan, & Chirikjian, 2009; Teknipar & Zheng,
2010; Baron, 2013; Al-Bluwi, Vaisset, Simeon, & Cortes, 2013). summary highlights
robotics-inspired methods later survey describe greater detail collective variables
employment effective perturbation operators.
2.5 Internal Coordinate- Angular-Based Models
internal coordinate model offered effective alternative Cartesian coordinatebased model (Burgess & Scheraga, 1975). internal-coordinate model, variables
selected bond lengths, angles two consecutive bonds, torsion dihedral angles
three consecutive bonds. Figure 3(b) provides illustration. model allows fast
forward kinematics, changes Cartesian coordinates result changes values
variables efficiently calculated via accumulation rigid-body transformations (Craig, 1989;
Zhang & Kavraki, 2002a).
Internal coordinate-based models norm non-MD based molecular structure modeling. additional simplification made equilibrium protein structures. Analysis deposited
equilibrium structures proteins reveals bond lengths bond angles constrained characteristic values (Engh & Huber, 1991). consequence energetic constraints placed
structures equilibrium exploited idealize protein geometry modeling effectively
removing bond lengths bond angles list variables model. leaves
dihedral angles defined three consecutive bonds variables (, backbone angles
four dihedral side-chain angles per amino acid, shown Figure 3(a)) computationally appealing, number dihedral angles polypeptide chain N atoms average
3N/7 (Abayagan, Totrov, & Kuznetsov, 1994). worth noting bond lengths bond angles change even equilibrium, faster pace motions. Employing idealized
geometry allows devoting computation obtaining slower fluctuations first. structures
representative molecules equilibrium dynamics obtained, deviations bond lengths
bond angles introduced studied via detailed models.
2.5.1 B IOMOLECULES K INEMATIC C HAINS R EVOLUTE J OINTS
Idealizing protein geometry reveals mechanistic analogies kinematic chains revolute
joints. Similarly joint rotation changes positions following links, rotation
dihedral angle change positions following atoms (Craig, 1989). analogies
523

fiS HEHU & P LAKU

employed robotics researchers apply algorithms plan motions kinematic chains
revolute joints study protein conformations (Manocha & Zhu, 1994; Singh, Latombe, &
Brutlag, 1999; Apaydin, Singh, Brutlag, & Latombe, 2001; Amato, Dill, & Song, 2003; Apaydin,
Brutlag, Guestrin, Hsu, & Latombe, 2003; Song & Amato, 2004; Cortes, Simeon, & Tran, 2004;
Cortes, Simeon, Guieysse, Remaud-Simeon, & Tran, 2005; Lee, Streinu, & Brock, 2005; Kim
et al., 2002a; Chiang, Apaydin, Brutlag, Hsu, & Latombe, 2007; Shehu & Olson, 2010; Molloy
et al., 2013; Molloy & Shehu, 2013; Haspel, Moll, Baker, Chiu, & E., 2010; Shehu, Clementi, &
Kavraki, 2006). Unlike typical articulated robotic mechanisms, protein chains pose hundreds rather
dozen variables (a short backbone 50 amino acids poses 100 dihedral angles variables).
analogies protein chains kinematic chains revolute joints popular
among robotics researchers proposing robotics-inspired methods modeling biomolecular structure dynamics. instance, torsional angles employed early model protein ligand
binding (Singh et al., 1999) remain popular modeling kinetics folding small protein
RNA molecules (Han & Amato, 2001; Amato et al., 2003; Song & Amato, 2004; Thomas,
Song, & Amato, 2005; Thomas, Tang, Tapia, & Amato, 2007; Tang, Thomas, Tapia, Giedroc, &
Amato, 2008; Tapia, Thomas, & Amato, 2010). angles also proved popular computing
functionally-relevant structures peptides proteins (Haspel, Tsai, Wolfson, & Nussinov, 2003;
Shehu et al., 2006; Shehu, Clementi, & Kavraki, 2007; Shehu, Kavraki, & Clementi, 2007, 2008;
Cortes et al., 2004; Shehu, Kavraki, & Clementi, 2009; Shehu, 2009; Shehu & Olson, 2010; Molloy
et al., 2013), well modeling peptides proteins switching different functionallyrelevant structures (Cortes et al., 2005; Jaillet, Cortes, & Simeon, 2008; Haspel et al., 2010; Jaillet,
Corcho, Perez, & Cortes, 2011; Molloy et al., 2016; Molloy & Shehu, 2013, 2015; Devaurs, Molloy,
Vaisset, Shehu, Cortes, & Simeon, 2015; Molloy & Shehu, 2016).
Techniques Obtain Reduced Angular-based Models number variables angularbased models reduced via various techniques. instance, consecutive dihedral
angles bundled together fragments capture variable dependencies. technique,
known molecular fragment replacement introduced context MC-based methods
de novo protein structure prediction (Bradley, Misura, & Baker, 2005), allows operationalizing
observation limited number configurations observed k-bundles consecutive
dihedral angles among stable protein structures equilibrium (Han & Baker, 1996). technique incorporated robotics-inspired methods modeling equilibrium protein structure dynamics (Shehu & Olson, 2010; Molloy et al., 2013; Molloy & Shehu, 2013, 2016).
application-specific techniques analyze structures reduce prioritize number dihedral angles manipulation perturbation operator. Rigidity-based techniques, instance, analyze
given structure detect least-constrained regions suggest order dihedral angles
modify first often order focus computational resources computing large structural deformations first (Thorpe & Ming, 2004; Wells, Menor, Hespenheide, & Thorpe, 2005; Fox
& Streinu, 2013). Rigidity-based analysis incorporated robotics-inspired methods
modeling protein dynamics (Thomas et al., 2007). techniques aimed specifically modeling structural transitions large proteins (Raveh, Enosh, Furman-Schueler, & Halperin, 2009;
Haspel et al., 2010). these, comparison two structures transition sought
identifies differently-valued dihedral angles. similar fashion rigidity-based analysis,
angles prioritized modified often perturbation operators order capture
possibly large structural deformations reasonable amount time. techniques make
524

fiC OMPUTATIONAL REATMENTS B IOMOLECULES ROBOTICS -I NSPIRED ETHODS

several assumptions variables participate process interest, highlight
assumptions implications later survey.
Biomolecular Structure versus Biomolecular Conformation light various models
employed represent biomolecular structure, distinction needs made
terms structure conformation. term structure meant refer specification
Cartesian coordinates atoms comprise molecule (even atoms explicitly
modeled, backbone reduced structure). term conformation meant general refer specification values variables selected model structure;
is, conformation particular instantiation employed variable space. instance, conformation instantiation angles angular-based model employed, forward kinematics
allows obtaining structure encoded conformation. worth noting terms
conformation structure often used interchangeably slight abuse terminology
biomolecular modeling literature. instance, many algorithms explicitly modify structures via Cartesian coordinate-based models referred conformational search algorithms;
course, models employed, structure extracted trivially conformation. survey, distinction made observed referring structures
conformations.
specific domain robotics-inspired methods, term (molecular) conformation equivalent (robot) configuration. However, keeping broader computational biology literature, employ term conformation referring macromolecules, proteins,
RNA, DNA, reserving term configuration small molecules (also referred ligands)
bind macromolecules. addition, term variable often referred parameter broader computational biology biophysics literature degree freedom (dof)
robotics AI literature, employ general, non-domain specific term variable
variable space. is, (molecular) conformation instantiation space selected
variables. Depending number variables selected model molecule investigation, variable space may high-dimensional. Mapping conformation corresponding
structure allows associating structure space employed variable space. Moreover, energy
functions allow associating energy surface structure space, interesting observations
regarding stable semi-stable structural states excursions among states made
analyzing structure space low-dimensional projections/embeddings underlying energy
surface, hence energy landscape.
Educational Resources purpose material related provide enough detail
biomolecular geometry allow seeing biomolecules treated mechanistically modular systems composed numerous, heterogeneous components purpose characterizing
silico. information readers varying levels background interest
found online, educational learning modules designed introduce computer scientists computational structural biology. One set modules, publicly accessible cnx project
highly popular students researchers, found http://cnx.org/contents/
9cMfjngH@6.3:ppj-3H2A@14/Structural-Computational-Biolo. modules, instance, interested readers learn protein architecture greater detail.
modules mirror material summarized representations energy functions, yet others introduce readers forward inverse kinematics modular mechanical systems, making
modules good supplement survey robotics-inspired methods presented here.
525

fiS HEHU & P LAKU

3. Summary Biomolecular Modeling Problems Robot Motion Planning
Frameworks
introduce main classes problems biomolecular modeling addressed
robotics-inspired methods. robot motion planning frameworks methods build
summarized next. section concludes summary challenges faced algorithmic realizations frameworks modeling biomolecular structure dynamics. challenges
preview important design decisions detailed Section 4 context reviewing
representative methods.
3.1 Representative Problems Biomolecular Modeling
Two main classes molecular mechanisms studied robotics-inspired methods,
involve one molecule associating/complexating disassociating one another,
involve dynamic, uncomplexated molecule. application setups, concern
informing understanding dynamic events involving dynamic molecules.
first application setup, robotics-inspired methods aim model understand proteinligand binding events. Provided unbound structures protein receptor small ligand
molecule, objective elucidate ligand approaches binds protein receptor. related problem, reverse process addressed. ligand bound receptor,
goal determine motions ligand protein receptor allow disassociation.
Modeling protein-ligand binding important general understanding biology
also computation-aided drug discovery. molecular recognition events
protein-protein, protein-DNA, protein-RNA, protein-membrane binding conceptually fall
category protein-ligand binding, challenging due higher number
variables needed model association complexation event currently beyond domain applicability robotics-inspired methods.
second application setup concerns modeling understanding dynamics molecules.
Almost exclusively, focus robotics-inspired techniques category uncomplexed protein RNA molecules. goal elucidate structural deformations motions allow
protein RNA molecule transition two structural states interest. states
unfolded folded state, case goal highlight folding unfolding
paths, stable semi-stable structures employed molecule recognize
lock onto different molecules, case goal formulate hypothesis regarding
impact structure molecular recognitions healthy diseased cell.
Figures 4-5 illustrates problems. Figure 4, robotics-inspired method highlight
ligand approaches protein receptor, well binds onto receptor
configuration. variables interest need minimum include translational rotational
variables ligand, well internal coordinates capture potential structural flexibility
ligand. receptor considered frozen 3d space. accurate setup would
also consider internal coordinates receptor order model possible structural flexibility
upon ligand binding. However, resulting number variables would large. roboticsinspired method elucidate bound ligand configuration bound placement
relative receptor, also possible routes successive configurations placements
ligand may follow approach binding site(s). addition, Figure 5(a) illustrates,
robotics-inspired method show possible routes successive structures employed
526

fiC OMPUTATIONAL REATMENTS B IOMOLECULES ROBOTICS -I NSPIRED ETHODS

Figure 4: (a) ligand bind protein receptor? Many methods designed
elucidate step-by-step process ligand approaches protein molecule, binds,
configuration.

protein fold, thus shedding light process protein folding unfolding. Similar setups
consider RNA molecules. Figure 5(b) illustrates often robotics-inspired methods employed
reveal folding unfolding routes protein, also structural transitions
two structures interest; knowledge probable routes carry transition allows
understanding structural level mechanism biomolecule regulates biological
activity cell.
3.2 Foundations Robotics-inspired Treatments Biomolecules
fundamental assumption robotics-inspired treatments biomolecules mechanistic
analogies molecular chains robot chains allow putting together efficient algorithms
rapid exploration molecular structure spaces modeling excursions molecules
spaces (Manocha & Zhu, 1994; Singh et al., 1999; Apaydin et al., 2001; Amato et al., 2003; Apaydin
et al., 2003; Song & Amato, 2004; Cortes et al., 2005; Kim et al., 2002a; Chiang et al., 2007;
Kirillova et al., 2008). is, instead simulating molecule navigates energy surface
via gradient-based local search techniques, powerful techniques put together
building algorithms demonstrated high exploration capability robot configuration
spaces. Robotics-inspired treatments biomolecules draw techniques fast forward
527

fiS HEHU & P LAKU

(a) Protein folding

(b) Structural Transitions
Figure 5: (a) proteins fold? Shedding light process protein folding important goal,
many robotics-inspired methods devoted elucidating process step step computing
probable succession structures assumed protein navigating unfolded folded state.
(b) proteins transition diverse structures use interacting different partners
cell? Robotics-inspired methods seek elucidate structural transitions meta-stable stable
structural states protein.

inverse kinematics and, importantly, sampling-based algorithms developed algorithmic
robotics community address robot motion-planning problem (Choset & et al., 2005).
528

fiC OMPUTATIONAL REATMENTS B IOMOLECULES ROBOTICS -I NSPIRED ETHODS

objective robot motion planning obtain paths take robot given, start
configuration given, goal configuration. robot motion planning problem bears mechanistic
analogies problem computing conformations along transition trajectory biomolecule;
problems, driving objective uncover underlying (molecular) conformation (robot) configuration space employed motions articulated system start
goal conformation configuration. Analogies molecular bonds robot links molecular atoms robot joints help draw techniques perform fast kinematics kinematic
linkages (Manocha, Zhu, & Wright, 1995; Zhang & Kavraki, 2002b); is, specifying values
variables selected represent molecular conformation, rapidly update Cartesian coordinates
corresponding structure (Zhang & Kavraki, 2002b). inverse kinematics setting,
techniques allow rapidly obtaining values underlying variables consistent Cartesian-based
constraints (Chirikjian, 1993; Manocha & Canny, 1994; Zhang & Kavraki, 2002a; Kolodny, Guibas,
Levitt, & Koehl, 2005).
higher level, robotics-inspired methods operationalize two key observations. first
observation, originally made robot configuration spaces, solution-containing regions
high-dimensional non-linear variable space found heuristic rather exact
approaches; stochastic, sampling-based techniques construct distribution constraintsatisfying instantiations two-stage manner; initial distribution first constructed via sampling unconstrained variable space. Instantiations evaluated external (energetic) models capable capturing inter-variable dependencies penalizing violations constraints. Violating samples either removed down-weighted initial, uninformed distribution gradually converges containing solutions. second observation transitions
system two given solutions modeled via discrete, kinetic models essentially
embed solutions graph-like structures amenable rapid, shortest, lowest-cost path queries,
provided lengths cost metrics associated given series configurations
path. Methods embed solutions tree referred tree-based methods,
embed solutions graph referred roadmap-based methods.
3.3 Motion Planning Framework: Tree- Roadmap-Based Methods
context molecular modeling, tree-based methods grow tree conformation space
given, start given, goal conformation representing structures bridged sought transition. tree incrementally extended, every iteration adding new conformation node
new branch tree. Depending whether tree pulled towards configurations sampled
random configuration space pushed leaves towards new regions configuration space, method known Rapidly Random Exploring Tree (RRT) (LaValle & Kuffner,
2001), Expansive Spaces Tree (EST) (Hsu, Kindel, Latombe, & Rock, 2002), accordingly.
important note sampling connectivity go hand hand, every sampled conformation added growing tree. growth tree biased goal conformation
reached reasonable computational time. result, tree-based methods efficient
limited sampling. known single-query methods, answer one
start-to-goal query time; is, one path consecutive conformations connect
start goal extracted. Running multiple times sample ensemble conformation paths query results ensemble high inter-path correlations due
biasing conformation tree.
529

fiS HEHU & P LAKU

Roadmap-based methods adapt Probabilistic Road Map (PRM) framework
(Kavraki, Svestka, Latombe, & Overmars, 1996). Rather grow tree conformation space,
methods detach sampling conformations connectivity model encodes
neighborhood relationships among conformations conformation space. Typically, sampling
stage first provides discrete representation conformation space interest, conformations satisfying explicit implicit geometric energetic constraints, roadmap building
stage embeds sampled conformations graph/roadmap connecting one nearest neighbors. Roadmap-based methods provide richer information regarding dynamic event,
multiple paths may exist roadmap connecting two structures interest. Moreover,
methods support multiple queries, principle graph used extract paths connecting different given structures. structures specified conformations connected
nearest neighbors graph, graph queried optimal paths. practice,
difficult obtain broad dense sampling sufficient regions conformation space
molecule elucidate diverse excursions structures interest.
provide detail tree-based roadmap-based methods robotics familiarize reader diverse design decisions employed even adapted robotics-inspired
methods biomolecular modeling.
3.3.1 N - HIERARCHICAL REE -BASED ROBOT OTION P LANNING ETHODS
Tree-based methods categorized broadly based strategies employed select vertex
expand tree. Non-hierarchical strategies consider vertices possible
candidates. Hierarchical strategies place tree vertices bottom layer introduce additional
high-level layers group similar vertices together, proceeding top bottom layer
selection process.
RRT one widely used non-hierarchical tree-based motion planning methods.
RRT (LaValle & Kuffner, 2001), iteration, tree expanded towards randomly-sampled
configuration qrand . nearest vertex, qnear , tree qrand determined according distance metric. local planner attempts connect qnear qrand . Often local planner interpolates
underlying variables generate intermediate configurations. basic version RRT,
iteration stops one interpolation step. connect version, expansion continues
qrand reached interpolation results invalid configuration, e.g., collision obstacles.
process sampling configuration expanding nearest neighbor tree repeated goal reached. Figure 6 shows tree. using random sampling nearest
neighbors, RRT exhibits Voronoi bias enables expansion tree toward unexplored
regions. also bias search towards goal, qrand often selected probability b (often set
0.05) goal configuration probability 1 b uniformly random.
years, different RRT variants developed order improve exploration.
adaptive dynamic domain RRT (ADDRRT) (Jaillet, Yershova, LaValle, & Simeon, 2005) associates sampling radius tree vertex dynamically adjusts radius based
success local planner. reachability-guided RRT (RGRRT) (Shkolnik, Walter, & Tedrake,
2009) relies notion reachable sets increase likelihood successful tree expansions. obstacle-based RRT (OBRRT) (Rodriguez, Tang, Lien, & Amato, 2006b) increases
sampling near obstacles, PCARRT (Dalibard & Laumond, 2009) relies PCA, selective
retraction-based RRT (SRRRT) (Lee, Kwon, Zhang, & Yoon, 2014) uses bridge sampling se530

fiC OMPUTATIONAL REATMENTS B IOMOLECULES ROBOTICS -I NSPIRED ETHODS

Figure 6: tree built RRT shown simplistic environment.

lective retraction order facilitate expansions inside narrow passages. utility-guided RRT
(UGRRT) (Burns & Brock, 2007) associates utility measure vertex uses promote expansions increase utility. RRT-Blossom (Kalisiak & van de Panne, 2006) creates
flood-fill behavior locally explore area surrounding vertex. Machine learning also
used derive distance metric captures cost-to-go order improve exploration
RRT (Palmieri & Arras, 2015). reachable volume RRT (RVRRT) (McMahon, Thomas, &
Amato, 2015) relies notion reachable volumes order restrict sampling feasible
regions improve performance RRT highly-constrained problems. abstractionguided RRT (fRRT) (Kiesel, Burns, & Ruml, 2012) uses A* search grid-based decomposition
bias RRT sampling towards low-cost regions. RRT* (Karaman & Frazzoli, 2011) rewires
branches RRT find optimal solutions respect given cost function.
EST (Hsu et al., 2002) takes different approach RRT pushing frontier
tree towards unexplored areas. Instead relying expansions nearest neighbor, EST
maintains probability distribution tree vertices. iteration, vertex v selected
probability inversely proportional density small neighborhood around v. allows
EST push tree towards less-explored regions configuration space.
3.3.2 H IERARCHICAL REE -BASED OTION P LANNING ETHODS
Hierarchical tree-based methods rely scheme first selects region vertex
expand tree. Regions often defined based decomposition low-dimensional
projection configuration space. rationale that, grouping similar vertices, better
selections made region level effectively guide tree exploration. instance,
single-query, bidirectional, lazy collision-checking (SBL) method (Sanchez & Latombe, 2002)
pushes tree toward sparse regions using grid-based decomposition uniform probability distributions select non-empty grid cells. kinodynamic planning interior-exterior cell
exploration) (KPIECE) method (Sucan & Kavraki, 2012) relies multi-level grid decomposition constructed user-defined random linear projections. synergistic combination
layers planning (SyCLoP) method (Plaku, Kavraki, & Vardi, 2010) uses discrete search
531

fiS HEHU & P LAKU

low-dimensional triangular grid decomposition guide tree exploration along short region
paths goal. guided sampling tree (GUST) method (Plaku, 2015) partitions motion
tree equivalence classes relies multi-objective criteria based shortest-path distances,
selection penalties, progress made determine equivalence classes could result rapid
expansions toward goal.
path-directed subdivision tree (PDST) method (Ladd & Kavraki, 2004, 2005) relies
grid subdivision configuration space. cell decomposition keeps track
tree branches fall it. Initially, tree root vertex one cell
corresponding minimum maximum values variable. iteration, tree
branch selected expansion. cell c contains selected tree branch divided
two cells, c1 c2 , along largest dimension. tree branches c also split according
boundaries c1 c2 . ensures invariant tree branch contained
entirely one cell. selected tree branch b expanded picking configuration q along b
using propagation add new branch starting q. Propagation problem-dependent could
correspond moving random direction.
propagation continues collision found maximum number steps reached.
branch split exits cell boundaries. key component PDST weighting
scheme associated cell based volume, number branches, number previous
selections. selecting tree branch, order increase coverage, priority given cells
large volumes well-explored. iteration, selected cell
c penalized order ensure cells eventually selected expansion.
necessary avoid oversampling guarantee probabilistic completeness (Ladd & Kavraki, 2005).
PDST also combined artificial potential fields order expand tree
region lowest potential (Bekris & Kavraki, 2007).
3.4 Roadmap-Based Robot Motion Planning Methods
introduction PRM (Kavraki et al., 1996) shifted focus complete probabilisticallycomplete motion-planning algorithms, guarantee find solution, exists, probability approaching one time tends infinity. complete algorithms limited simple
problems 23 variables, PRM made possible efficiently solve high-dimensional problems. underlying idea PRM construct roadmap captures connectivity
(obstacle-)free configuration space. roadmap populated generating number
collision-free configurations. configuration generated sampling values variables
uniformly random. configuration discarded, results collision. Otherwise, added
roadmap. capture connectivity, neighboring roadmap configurations connected
collision-free paths. Figure 7 provides illustration roadmap created PRM. common approach compute roadmap configuration k-nearest neighbors according
distance metric. path two configurations often obtained linear interpolation.
path collision free, added edge roadmap graph. path given start
goal configuration found first connecting start goal configurations roadmap
searching roadmap graph. A* often used efficiently compute shortest roadmap
path. Additional sampling may required initial roadmap contain path
start goal.
532

fiC OMPUTATIONAL REATMENTS B IOMOLECULES ROBOTICS -I NSPIRED ETHODS

b
b

b
b

b
b
b

b
b

b

b
b

b

b

b
b

b

goal

b

start

b
b
b

Figure 7: illustration roadmap used answer start-to-goal queries.

years, numerous strategies proposed enhance sampling PRM.
Obstacle-based PRM (OBPRM) (Amato, Bayazit, Dale, Jones, & Vallejo, 1998) seeks increase
sampling near obstacles order improve connectivity inside narrow passages. BridgePRM
(Sun, Hsu, Jiang, Kurniawati, & Reif, 2005) similar objective uses bridge test generate
samples halfway two obstacles. Machine learning also used conjunction
portfolio samplers enhance sampling narrow passages (Hsu, Sanchez-Ante, & Sun, 2005).
region-sensitive adaptive PRM (RESAMPL) (Rodriguez, Thomas, Pearce, & Amato, 2006a)
uses notion entropy identify regions enhance sampling. TogglePRM (Denny &
Amato, 2013) switches free configuration space obstacle space order facilitate connections narrow passages. ANC-Spatial (Ekenna, Thomas, & Amato, 2016) uses
spatial-learning approach enhance roadmap connectivity determining appropriate connection methods roadmap vertex. PRM* (Karaman & Frazzoli, 2011) variant PRM
leads optimal solutions respect given cost function. modification surprisingly
simple, requires using variable number nearest neighbors instead fixed k.
3.5 Biomolecular Modeling Challenges Tree- Roadmap-Based Methods
tree- roadmap-based methods experience curse dimensionality several ways.
central issue concerns breadth sampling possibly high-dimensional complex variable
spaces. particular, context biomolecular modeling, decision variables
represent key, determines dimensionality complexity variable/conformation
space. decision tightly tied application setting class biomolecular systems
considered. reviewed Section 2, many adaptations selected variables
subset backbone dihedral angles (Han & Amato, 2001; Amato et al., 2003; Song & Amato,
2004; Thomas et al., 2005, 2007; Jaillet et al., 2008; Tang et al., 2008; Tapia, Tang, Thomas, &
Amato, 2007; Tapia et al., 2010; Jaillet et al., 2011; Shehu & Olson, 2010; Molloy et al., 2013;
Molloy & Shehu, 2013), others selected variables capture collective motions atoms
3d Cartesian space (Kim et al., 2002b, 2002a; Kirillova et al., 2008; Schuyler et al., 2009; Al-Bluwi
et al., 2013; Maximova et al., 2015). Whether values variables sampled individually
533

fiS HEHU & P LAKU

tandem a-priori compiled databases good moves (Shehu & Olson, 2010; Molloy et al.,
2013; Molloy & Shehu, 2013), whether diverse perturbation/sampling operators employed
make use different sets variables (Gipson, Moll, & Kavraki, 2013; Molloy & Shehu, 2016),
dimensionality size variable space remains key challenge tree- roadmapbased treatments biomolecules.
choice variables key design effective sampling perturbation operators
generating conformations satisfy set desired geometric and/or energetic constraints
biomolecular modeling problem hand. Samples obtained uniformly random low
probability low-energy region interest sought structural transition.
particular, long protein chains hundreds backbone dihedral angles, conformation
sampled random highly unlikely physically-realistic.
Biased sampling techniques used remedy issue (Amato et al., 2003; Song &
Amato, 2004), hard know priori perturbation operators effective. Recent work recognizes issue addresses offering diverse sampling operators possibly
diverse sets variables (Raveh et al., 2009; Gipson et al., 2013; Molloy & Shehu, 2016). particular, work Molloy Shehu (2016) implements probabilistic scheme selects among
rich menu operators making use angular Cartesian variables.
worth noting sampling operators may generate samples vacuum incremental modifications existing samples. earlier generations tree- roadmapbased methods typically obtained new conformations sampling values selected variables (Singh et al., 1999), recent methods generate samples neighborhoods existing parent
samples (Shehu & Olson, 2010; Molloy & Shehu, 2013; Maximova et al., 2016) (hence, often
used term perturbation operator). later strategy higher chance yielding physicallyrealistic conformations, perturbation operators perturb selected sample obtain new one
tend preserve good structural features new sample introducing enough change
explore new regions variable space (Olson, Hashmi, Molloy, & Shehu, 2012). context
perturbation operators, selection schemes critical control sampling. recent phenomenon
robotics-inspired methods recognition selection schemes, central
hierarchical tree-based robot motion planning (as reviewed above), also employed
tree- roadmap-based methods steer biomolecular sampling regions interest (Shehu &
Olson, 2010; Molloy & Shehu, 2013; Maximova et al., 2016).
additional challenge ensuring high sampling capability biomolecules underlying complex energy surfaces encode energetic constraints. Therefore, criterion
accepting sampled conformation adding vertex list tree roadmap needs either rely a-priori set energy threshold probabilistic nature. latter setting provides
balance obtaining low-energy conformations allowing particular algorithm go
high-energy barriers needed sample conformation space (Jaillet et al., 2008,
2011; Molloy & Shehu, 2013; Devaurs et al., 2015; Molloy & Shehu, 2016).
roadmap- tree-based methods rely local planners local deformation techniques
connect neighboring conformations. tree-based methods push tree variable
space generating child conformations selected parent conformations via perturbation operators, child becomes neighbor selected parent; neighborhood function rely
notion distance variable space instead tied parent-child relationship.
methods, sampled conformation needs connected one nearest neighbors. Nearest-neighbor calculations need specification distance function conforma534

fiC OMPUTATIONAL REATMENTS B IOMOLECULES ROBOTICS -I NSPIRED ETHODS

tions, non-trivial high-dimensional spaces. adaptations employ least Root-MeanSquared-Deviation (lRMSD), modification Euclidean distance differences due
rigid-body motions removed optimal superimposition protein conformations comparison (McLachlan, 1972). lRMSD carried Cartesian coordinate-based
instantiations. distance functions use L1 related variants defined dihedral angles.
generally challenging find computationally-efficient dynamics-integrating local planners biomolecular conformations. conformations q1 q2 nearby variable structure
space, local path encoded edge tree roadmap encode process
diffusion. local path provide evidence diffusion biomolecule q1
q2 presence thermal vibrations. readily obvious use dynamics steer
biomolecule q1 q2 . principle MD simulations employed search
paths, guarantee simulations reach q2 . biased MD simulations
employed reach q2 , simulations modify energy surface model actual
dynamics (Ma & Karplus, 1997). Moreover, corrections biased MD simulations model
actual dynamics prove computationally expensive (Ovchinnikov & Karplus, 2012) context
robotics-inspired methods evaluate thousands edges.
result, majority robotics-inspired methods biomolecular modeling employ local
planners carry linear interpolations variables conformations need
connected via tree branch roadmap edge. planners produce unrealistic conformations,
significant time spent correcting geometry ensuing energetic violations via energy
minimization. Recent work proposes complex, local planners based interpolation
instead re-formulations motion computation problem; is, local planners tree- roadmap-based methods (Molloy & Shehu, 2016). latter idea borrowed
similarly challenging setting motion planning manipulators, linear interpolation also effective (Nielsen & Kavraki, 2000). making use complex local planners,
prioritized path sampling scheme needed prioritize application computationallydemanding planners promising paths order control computational cost (Nielsen &
Kavraki, 2000). work Molloy Shehu (2016) provides implementation prioritized
path sampling biomolecular modeling.

4. Robotics-Inspired Methods Equilibrium Biomolecular Structure
Dynamics
Table 1 categorizes different robotics-inspired methods robot motion planning frameworks
adapt application setups address. table comprehensive means,
may useful readers selecting focus specific applications. rest Section
describe methods greater detail, paying particular attention recent, state-of-the-art
methods showcase current capabilities robotics-inspired treatments biomolecules.
4.1 Tree-Based Methods Modeling Equilibrium Biomolecular Structure Dynamics
Tree-based methods employed model biomolecular flexibility compute conformation paths connecting given structures (Cortes et al., 2005; Shehu, 2009; Shehu & Olson, 2010;
Jaillet et al., 2011; Haspel et al., 2010). tree-based methods address decoy sampling de
novo protein structure prediction problem (Shehu & Olson, 2010; Olson, Molloy, Hendi, & Shehu,
2012; Molloy et al., 2013) map entire energy landscape pathways connecting stable
535

fiS HEHU & P LAKU

states molecular loops, peptides, proteins (Porta, Thomas, Corcho, Canto, & Perez, 2007;
Jaillet et al., 2011; Porta & Jaillet, 2013; Devaurs et al., 2015; Molloy et al., 2016). Others
focused specific flexible sub-chains, loops, rather entire protein chains (Cortes et al.,
2004, 2005; Yao, Dhanik, Marz, Propper, Kou, Liu, van den Bedem, Latombe, Halperin-Landsberg,
& Altman, 2008; Barbe, Cortes, Simeon, Monsan, Remaud-Simeon, & Andre, 2011).
Table 1: Categorization Tree- Roadmap-based Methods Application Setting
Application
Protein
Loop
Motions
Protein-Ligand
Binding

Tree-based Methods
RLG-RRT (Cortes et al., 2005; Cortes,
Jaillet, & Simeon, 2007), ML-RRT (Barbe
et al., 2011)
ML-RRT (Cortes et al., 2007)

Protein Structure
Prediction
Protein RNA
(Un)Folding

FeLTr (Shehu & Olson, 2010; Molloy
et al., 2013)

Peptide Protein
Structural
Transitions

NMA-RRT (Kirillova et al., 2008; AlBluwi et al., 2013), PathRover (Enosh,
Raveh, Furman-Schueler, Halperin, &
Ben-Tal, 2008; Raveh et al., 2009), TRRT (Jaillet et al., 2011), PDST (Haspel
et al., 2010), Sprint (Molloy & Shehu,
2013), Multi-T-RRT (Devaurs et al., 2015)
T-RRT (Jaillet et al., 2011), Multi-TRRT (Devaurs et al., 2015)

Peptide Protein Energy landscape Mapping

Roadmap-based Methods
LoopTK (Yao et al., 2008)

PCR (Singh et al., 1999; Apaydin
et al., 2001), SRS (Apaydin et al.,
2003)

SRS (Apaydin et al., 2003), PRMFP (Amato et al., 2003; Song &
Amato, 2004; Tang, Kirkpatrick,
Thomas, Song, & Amato, 2005;
Thomas et al., 2005, 2007; Tapia
et al., 2007; Tang et al., 2008; Tapia
et al., 2010), MaxFlux-PRM (Yang,
Wu, Li, Han, & Huo, 2007; Li, Yang,
Han, & Huo, 2008)
SRS (Molloy et al., 2016), Spiral (Molloy & Shehu, 2016), SoPRIM (Maximova et al., 2015)

SoPRIM (Maximova et al., 2015)

4.1.1 ODELING P ROTEIN L OOP OTIONS P ROTEIN -L IGAND ISASSOCIATION
Early adaptations RRT algorithm biomolecules focused modeling equilibrium dynamics protein loops (Cortes et al., 2005) protein-ligand interactions (Cortes et al., 2004).
instance, method presented work Cortes et al. (2005) proceeds two stages
model large-amplitude structural changes protein loop equilibrium. first stage obtains
ensemble collision-free conformations loop protein structure. achieved
Random Loop Generator RRT (RLG-RRT) algorithm, effectively samples loop conformation space satisfies kinematic closure constraints. loop divided active
passive part. passive part selected contain 6 variables, whereas active part contains
rest angular variables selected represent loop conformation. RLG-RRT algorithm
536

fiC OMPUTATIONAL REATMENTS B IOMOLECULES ROBOTICS -I NSPIRED ETHODS

directly samples values variables active part via scheme increases probability
obtaining conformation satisfies loop closure. active part loop conformation
obtained, exact 6R inverse kinematics technique applied solve passive variables loop closure constraints. Closed loop conformations added tree
collision-free. tree run fixed amount time, goal region defined around
given goal conformation order extract many paths one execution RLG-RRT
algorithm. Conformations extracted paths subjected short energetic minimizations
order elucidate energetically-feasible, large-amplitude motions loop investigation.
Analysis extracted loop motions work Cortes et al. (2004) reveals results
comparable classic molecular modeling methods obtained performance gain
several orders magnitude. work Cortes et al. (2004) demonstrates efficacy twostage approach studying activity-regulating mobility 17-residue long loop 7
amylosucrase enzyme Neisseria polysaccharea.
Ideas similar RLG-RRT employed LoopTK (toolkit) algorithm (Yao et al., 2008)
explore closed, collision-free conformations flexible loops ranging length 5 25
amino acids. algorithm relies interplay sampling deformation obtain loops
satisfy kinematic closure constraints collision-free. sampling procedure focuses
obtaining geometrically-diverse, closed loops. deformation procedure based earlier related
work loop modeling (Lotan, van den Bedem, Deacon, & Latombe, 2004; van den Bedem, Lotan,
Latombe, & Deacon, 2005). procedure makes use null space technique explore
self-motion manifold (the constrained, closure space) around closed loop resolve steric clashes
violating closure constraints. LoopTK shown efficiently handle long loops
25 amino acids even generate biologically-interesting, calcium-binding conformations.
toolkit available https://simtk.org/home/looptk.
time demands RRT-RLG problems hundreds variables addressed Cortes
et al. (2007) proposing Manhattan-like RRT (ML-RRT) algorithm efficiently compute
paths small protein-bound ligand exit protein active site. ML-RRT borrows ideas
mechanical disassembly divides variables two groups, active passive. particular,
variables model internal rigid-body motions ligand designated active,
subspace active variables sampled RLG-RRT algorithm. variables
model internal motions amino acids protein receptors active site designated
passive, slightly perturbed hinder motions ligand. decoupling
proves effective, allows possible ensuing collisions ligand protein
addressed domino-like scheme, illustrated Figure 8.
ML-RRT shown efficiently model motions small ligands, side chains, loops,
backbone (Cortes, Le, Lehl, & Simeon, 2010; Barbe et al., 2011). work Cortes et al. (2010)
subjects paths extracted executions ML-RRT algorithm randomized path smoothing
post-processing technique. technique carried composite space parameters
resulting simultaneous motions ligand protein final path. work Barbe
et al. (2011) subjects loop conformations paths extracted ML-RRT minimization
MM energy function reveal critical, physically-realistic intermediate conformations
bottlenecks along open-to-closed loop motion Burkholderia cepacia lipase lid domain.
Adaptations robot motion planning frameworks model loop structures motions represent fraction diverse methods designed loop modeling. Interested readers referred
survey work Shehu Kavraki (2012).
537

fiS HEHU & P LAKU

Figure 8: figure reproduced work Al-Bluwi et al. (2012). left panel illustrates disassembly planning problem two articulated objects. ML-RRT algorithm proposed work Cortes
et al. (2007) problem models escape ligand proteins binding site disassembly problem.
red H-shaped object left image considered ligand right image, blue sticks
left image considered flexible side chains binding site receptor protein
right image. figure reproduced permission Computer Science Review Journal.

4.1.2 ODELING P EPTIDE P ROTEIN TRUCTURAL RANSITIONS APPING
P EPTIDE E NERGY L ANDSCAPES
RLG-RRT algorithm modified work Enosh et al. (2008) model structural transitions proteins and, particular, model open close motions potassium channels. main
modification RLG-RRT algorithm Enosh et al. concerns addition energetic test
collision-free test performed deciding whether generated conformation
added tree. Several novel analysis techniques introduced. Clustering conducted
many paths obtained several executions algorithm order identify common intermediate conformations paths connecting given start goal conformations. Path alignment
employed obtain energetically-favored path among computed. schematic
method proposed Enosh et al. visualization energetically-favored path
obtained KscA protein shown Figure 9.
Another extension RRT-based algorithm work Enosh et al. (2008) presented
Raveh et al. (2009); efficient PathRover algorithm proposed modeling structural
transitions many proteins. PathRover achieves computational efficiency two main ways.
First, application many proteins made possible restricting number dihedral angles
used variables. Three strategies used identify subset dihedral angles define
variable space: careful inspection structures, relevant literature, computational tools detecting
hinge regions like NMA, comparison structural changes alternative (native homologue)
structures. particular, FlexProt alignment algorithm (Shatsky, Nussinov, & Wolfson, 2002)
used compare start goal structures reveal structurally-different regions. Variables
manually restricted dihedral angles regions. Second, PathRover limits exploration
538

fiC OMPUTATIONAL REATMENTS B IOMOLECULES ROBOTICS -I NSPIRED ETHODS

Figure 9: figure reproduced work Enosh et al. (2008). schematic method
shown (a). PathRover algorithm executed multiple times extract 100 plausible paths connecting
given open closed conformations. paths clustered aligned reveal path cluster
minimal energy barrier. cluster visualized KscA protein (b), shows putative threephase motion close open conformations. figure reproduced permission
Biophysical Journal.

539

fiS HEHU & P LAKU

regions space consistent available wet-laboratory data. Branch termination criteria
employed stop tree pulled towards regions improve agreement
wet-laboratory data. integration wet-laboratory data aims circumvent known inaccuracies
modern biomolecular energy functions.
RRT-based algorithms summarized demonstrate utility RRT modeling
structural transitions proteins. particular, PathRover algorithm utilized several schemes
reduce number variables order make problem modeling structural transitions
tractable (Raveh et al., 2009). work Haspel et al. (2010) continued spirit via clever,
reduced representations large proteins. contrast, work Simeon Cortes labs credited
introducing RRT-based algorithms biomolecular modeling focused instead techniques
enhance sampling. Transition-RRT (T-RRT) algorithm proposed Jaillet et al. (2008)
shown particularly effective regard.
T-RRT bi- multi-tree variants recently proposed explore obtain comprehensive maps energy landscapes small peptides, dialanine Met-Enkephalin (Jaillet et al., 2011; Devaurs et al., 2015). main modification baseline RRT algorithm
T-RRT concerns introduction acceptance criterion state transition test based
Metropolis criterion. New conformations added tree pass transition test (hence
name, T-RRT). goal T-RRT steer tree towards exploration low-energy regions
order map energy minima potential energy surface relaxing transition test
needed cross energy barriers may trap exploration particular local minimum.
dynamic modification state transition test makes use reactive temperature scheme.
Metropolis criterion, effective temperature effectively controls height energy barriers crossed two consecutive conformations. T-RRT, temperature increased
number attempts pull tree towards low-energy regions reaches user-specified
threshold; is, number failures grow tree taken indication presence
energy barrier, effective temperature increased order relax state transition test.
soon successful edge added tree, temperature lowered pre-specified
factor order resume overall bias pulling tree towards local minima. effect
reactive temperature scheme search balanced unexplored regions lowenergy regions variable space. Application T-RRT work Jaillet et al. (2011) shows
algorithm map entire known energy landscape dialanine peptide run
exploration mode. Another setting, T-RRT used obtain paths connect discovered
minima, also shows recovered transitions known stable states dialanine strong
agreement transitions known experiment affirmed simulation studies.
work addresses issue limited sampling goal obtain accurate representations energy landscapes longer peptides, Met-Enkephalin (Devaurs et al., 2015).
T-RRT algorithm used Devaurs et al. reveal conformation paths connecting
already-identified meta-stable states. states identified EA known Basin Hopping (BH), shown effectively sample local minima energy surfaces
biomolecules (Olson et al., 2012). work Devaurs et al., BH operates dihedral angles
provides sample-based, discrete representation energy surface peptide. local
minima clustered reveal wide basins corresponding meta-stable states.
variant T-RRT algorithm, referred Multi-T-RRT, also proposed Devaurs et al.
connect identified states. algorithm builds n single trees, rooted conformation
representative unique meta-stable state. algorithm proceeds iterations, iteration
540

fiC OMPUTATIONAL REATMENTS B IOMOLECULES ROBOTICS -I NSPIRED ETHODS

Figure 10: figure, reproduced work Devaurs et al. (2015), graph obtained single
run multi-T-RRT cycles projected key dihedral angles top panel. algorithm seeded
four meta-stable states Met-Enkephalin peptide, drawn pink triangles, squares, circles.
states capture unfolded state, folded state, two intermediates (shown bottom panel). Costs
various paths shown table bottom panel. figure reproduced permission IEEE
Trans Nano BioScience 2015.

randomly selecting one n trees expansion conformation q. conformation
nearest q n 1 trees identified, within extension step-size,
q merges two trees. Iterations continue trees merged graph. graph queried
minimum-cost paths connecting states interest. identified meta-stable states
minimum-cost paths connecting states found comparable reported
studies employ computationally-demanding exploration strategies (Devaurs et al., 2015).
representative result information extracted combination BH
Multi-T-RRT shown Figure 10.
One limitation readily applying T-RRT variants obtain similar, detailed characterization proteins rather short peptides dimensionality conformation space.
work Jaillet et al. (2011), space dimensions due limited number dihedral
angles small peptides, dialanine Met-Enkephalin. Detail, desired possible
characterizations short peptides, needs sacrificed order model large-scale structural transitions proteins. NMA-RRT (Kirillova et al., 2008), PDST (Haspel et al., 2010),
Sprint (Molloy & Shehu, 2013) present three different algorithms make use representations
reduced detail model large-scale structural transitions proteins.
Normal Mode Analysis (NMA) used obtain larger-scale moves (low-frequency modes revealed NMA conformation) (Kirillova et al., 2008). moves employed
generate new conformations RRT framework. NMA-RRT algorithm proposed Kirillova et al. (2008) essentially conducts RRT search low-dimensional variable space
541

fiS HEHU & P LAKU

low-frequency modes. Since normal modes provided NMA conformation
allow get local minimum represented conformation, NMA needs repeated
regularly RRT search order explore breadth conformation space.
computationally demanding, application NMA-RRT limited extraction minimumcost paths connecting two conformations interest rather comprehensive map energy
landscape connectivity proteins. work Kirillova et al. shows precious information extracted regarding structural transitions proteins, adenylate kinase, even
focusing motions largely driven normal modes. complementary study minimal
energy paths adenylate kinase via NMA (Maragakis & Karplus, 2005) shows modes
sufficient capture structural transition open closed structures protein; known wet-lab structures found within 3.0Aof mode-based minimal energy
pathways (Maragakis & Karplus, 2005).
recent extension NMA-RRT aims reduce computational demands algorithm.
extension employs reduced representation protein chain based tripeptides
employs NMA conformations reduced representations. reactive temperature scheme
T-RRT employed broaden sampling capture large-scale motions connecting significantly
different structural states large proteins several hundred amino acids (Al-Bluwi et al., 2013).
Employing reduced representations expanded applicability tree-based algorithms
treating large biomolecules. PDST algorithm adapted Haspel et al. (2010) model
transition two structures interest large proteins 200 amino acids.
assumption made secondary structures unfold sought transition, largely
valid modeling domain motions proteins. assumption, backbone dihedral
angles loops connecting secondary structures selected variables.
work Haspel et al. (2010), bias scheme used 10% iterations steer
tree towards goal conformation. bias scheme employs Euclidean distance
feature vector representations conformations tree. Given conformation, corresponding
feature vector contains Euclidean distances centers mass secondary structure units.
Conformations evaluated detailed coarse-grained energy function combines terms
energy function used work Shehu et al. (2009) Amber ff03 energy function.
sampled conformation evaluated energy set threshold 100 kcal/mol
energy start conformation, conformation subjected 20 steps steepest descent
retained energy decreases threshold. rather coarse energetic
constraint, paths collected 100 runs algorithm reach goal conformation
less time methods based Simulated Annealing, also reveal credible motions consistent
experimental data large, well-characterized proteins GroEL (Haspel et al., 2010).
Sprint algorithm proposed Molloy Shehu (2013) uses complementary approach
simplifying search space explored paths connecting given structures medium-size proteins.
Sprint addresses issue sampling high-dimensional variable spaces employing popular
idea de novo structure prediction. fragment replacement technique used divide
protein chain bundles consecutive dihedral angles, values bundle fragment
sampled a-priori constructed database fragment configurations known, native protein
structures. fragment replacement technique used expand tree every iteration.
work Molloy Shehu (2013) adapts EST framework via expansion
procedure model structural transitions small- medium-size proteins, Fragment Monte
Carlo Tree Exploration (FeLTr) algorithm proposed Shehu Olson (2010) uses related con542

fiC OMPUTATIONAL REATMENTS B IOMOLECULES ROBOTICS -I NSPIRED ETHODS

cepts sample space near-native protein conformations purpose de novo structure
prediction small proteins.
Sprint FeLTr, state-transition test used steer tree towards low-energy conformations time; is, probabilistic, Metropolis-like criterion used determine whether
child conformation added tree. FeLTr (Shehu & Olson, 2010) fixed
scaling parameter (analogous fixed effective temperature) used Metropolis-like criterion, Sprint (Molloy & Shehu, 2013) integrates reactive temperature scheme order allow
tree go high-energy regions low-energy routes found thus expand
exploration capability. reactive temperature scheme Sprint slightly different
T-RRT (Jaillet et al., 2008). T-RRT effective temperature increased decreased
fixed amounts, Sprint moves temperature along proportional cooling scheme often employed
Simulated Annealing Monte Carlo methods (Shehu et al., 2009). Upon failures expand tree,
temperature moves next value cooling scheme; upon successes, temperature goes
next value scheme.
FeLTr Sprint operationalize idea easier push rather pull
tree conformation space good moves available compiled priori generate
energetically-feasible child conformations selected parent conformations tree.
work Molloy Shehu (2013) tree rooted given start conformation
goal get within tolerance region given goal conformation, work Shehu
Olson (2010) tree rooted extended conformation, termination criterion compromise desired number low-energy conformations running time.
central idea Sprint FeLTr growth tree controlled via
selection mechanism; iteration, conformation tree selected expansion.
selection penalizes tree growing towards regions conformation space
oversampled, thus resulting enhanced sampling conformation space. Two discretization
layers employed. FeLTr, first layer maps conformations tree 1d grid whose
cells energy levels width 2 kcal/mol. Sprint, first layer maps conformations 1d
grid based lRMSD goal conformation. second layer algorithms maps
conformations geometric projection. second layer 3d grid, conformations
associated 3 shape-based global coordinates (Shehu & Olson, 2010).
selection mechanism uses discretization layers. First, selects energy level according probability distribution function. latter defined weights associated energy
levels according weighting function. Different weighting functions analyzed
strong global energetic bias needs order reproduce native structure (Molloy et al.,
2013). energy level selected, cells geometric projection grid belong conformations selected energy level analyzed. second weighting function cells grid
biases selecting cell selected many times and/or already many conformations it. cell selected, conformation selected expansion uniformly
random, since conformations cell energetically- geometrically-indistinguishable.
Extensions FeLTr explored effect different weighting functions
discretization layers employment different projection coordinates (Molloy et al., 2013;
Olson et al., 2012). Different coarse-grained energy functions considered state-of-the-art
de novo structure prediction, including Rosetta suite energy functions, employed
framework directly compared steer search towards near-native conformations (Molloy et al., 2013). Molloy Shehu (2013) also investigate impact different
543

fiS HEHU & P LAKU

projection schemes selection mechanisms diversity energetic profiles Sprintextracted paths context computing structural transitions.
Applications Sprint different start goal structure pairs calmodulin adenylate
kinase proteins show algorithm able find paths reach goal conformation (Molloy
& Shehu, 2013). Soft global biasing schemes found provide right compromise
tree depth (that is, lower energies) diversity paths (that is, geometrically-diverse conformations). Detailed energetic structural analysis computed paths two hallmark proteins,
calmodulin adenylate kinase, reveals Sprint yields accurate characterizations
structural transitions proteins. Energetic profiles extracted paths indicate presence
high-energy regions need crossed specific transitions calmodulin, agreement
wet-laboratory characterizations. Analysis adenylate kinase shows known intermediate
structures protein present conformation paths computed Sprint (Molloy &
Shehu, 2013).
4.2 Roadmap-Based Methods Modeling Equilibrium Biomolecular Structure
Dynamics
Roadmap-based methods employed model protein-ligand binding (Singh et al., 1999),
protein RNA folding unfolding (Song & Amato, 2004; Chiang et al., 2007; Chiang, Hsu, &
C., 2010), protein structural transitions (Molloy & Shehu, 2016; Maximova et al., 2015).
4.2.1 ODELING P ROTEIN -L IGAND B INDING
adaptation roadmap-based motion planning framework protein-ligand binding
Singh et al. (1999) first occurrence robotics-inspired treatments biomolecular structure
dynamics. adaptation simplistic provided key design issues replicated extended many robotics researchers. One key simplifications protein
receptor kept rigid, variables interest allowing model rigid-body
motions ligand around receptor internal motions ligand. Small ligands
considered, 6 + p variables allow modeling motions go dozen.
Sampling proceeds uniformly random 6 + p variables, ligand configurations added
roadmap pass geometric energetic criterion. geometric criterion ensures ligand
configurations within predefined distance center mass receptor.
energetic criterion probabilistic: two dynamically-updated thresholds, Emin Emax
values, corresponding minimum maximum energy values sampled configurations,
recorded. Ligand configurations energy higher Emax rejected. configurations
retained probability (Emax E(q))/(Emax Emin ). energy function incorporates
terms evaluate internal energy ligand configuration well terms evaluating
interactions ligand configuration rigid protein receptor.
Retained ligand configurations embedded nearest-neighbor graph, using lRMSD measure distance two ligand configurations user-set parameter, k, number
nearest neighbors. simple local planner interpolating p + 6 variables two neighboring
configurations used estimate feasibility q q 0 q 0 q edges generating consecutive configurations. Consecutive configurations qi generated linear interpolation planner
connect q q 0 distance two consecutive configurations generated series higher 1A. q q 0 q 0 q edges added roadmap qi
544

fiC OMPUTATIONAL REATMENTS B IOMOLECULES ROBOTICS -I NSPIRED ETHODS

configurations energies Emax . Weights added retained edges follows:
0

w(q q ) =

s1
X

log[P (qi qi+1 )]

i=0


P (qi qi+1 ) =

e(Ei+1 Ei )/(KB )
(e(Ei+1 Ei )/(KB ) + e(Ei1 Ei )/(KB ) )

equations, qi1 , qi , qi+1 three consecutive configurations corresponding
energies Ei1 , Ei , Ei+1 , KB Boltzmann constant, effective temperature.
weight path qstart
qgoal , connects start configuration goal configuration,
sum weights edges it. weight path initiated unbound configuration terminating bound configuration estimates association rate (the cost
ligand approaching binding protein receptor). weight reverse path estimates
disassociation rate (the cost ligand leaving binding site diffusing space).
resulting roadmap represents distribution energetically-credible paths ligand approaching binding receptor. work Singh et al. (1999), bound configuration
ligand p+6 variable space presumed known, RMSD-based clustering
sampled lowest-energy ligand configurations employed reveal likely bound candidates.
Analysis reveals true bound configuration indeed present top-populated clusters;
however, many false positives reported, well. Weights paths terminating initiated
lowest-energy ligand configurations analyzed order determine characteristics used discriminate true false positives. Paths terminating true,
bound configurations found high association rates; reverse paths found
high disassociation rates. important result elucidates effective binders
allow ligand reach lowest interaction energy also trap binding site via
high-energy barriers.
4.2.2 ODELING P ROTEIN RNA (U N )F OLDING
Singh et al. (1999) provided much needed template served foundation many
robotics-inspired treatments biomolecules. particular, suite roadmap-based algorithms
extensions designed Amato lab model unfolding small proteins. review
roadmap-based methods study molecular motions Amato lab available work
Tapia et al. (2010), whereas review roadmap-based methods specific protein folding
problem presented work Moll, Schwartz, Kavraki (2008). seminal contribution
category Probabilistic Conformation Roadmap (PCR) algorithm (Apaydin et al., 2001),
builds upon template presented Singh et al. (1999) study protein folding.
PCR addresses complex application domain, number variables needed model
intrinsic flexibility protein chains easily reach 100 more. PCR extensions
followed, notably Amato lab, variables employed subset backbone
dihedral angles protein chain (Amato et al., 2003; Song & Amato, 2004; Tang et al., 2005;
Thomas et al., 2005, 2007; Tapia et al., 2007; Tang et al., 2008; Tapia et al., 2010). variable
spaces, uniform random sampling ineffective likely result conformations severe
internal collisions. reason, work Amato lab PCR-based algorithms gradually
545

fiS HEHU & P LAKU

shifted sampling strategies based incremental perturbations given native/folded conformation memory folded conformation lost. Specifically, backbone dihedral angles
folded conformation perturbed small amounts use Gaussian distribution
minimum number conformations obtained category (0 100% 10% increments)
percentage native contacts. lower number native contacts conformation,
likely conformation belong unfolded state. acceptance criterion
sampled conformations work Singh et al. (1999), energy function different,
measures internal energy protein chain. function contains terms favoring hydrogen
bonds, disulfide bonds, hydrophobic interactions.
sampled conformations pass energetic/acceptance criterion embedded
nearest-neighbor graph, number nearest neighbor conformation k specified user.
contrast original PCR algorithm, directed (u, v) edges graph weighted based
E(u)E(v)

Boltzmann-related Metropolis criterionas in: P(u,v) = e KB , E(.) energy
conformation, KB Boltzmann constant, a-priori set temperature determining
height energy barriers crossed edge. early formulation edge weights, reactive
temperature schemes employed later tree- roadmap-based algorithms structural
transitions. Instead, user-controlled parameter determines great extent ability
algorithm navigate underlying energy surface.
works Song Amato (2004) Thomas et al. (2005), N best paths end
folded conformation start conformations 0 native contacts extracted analyzed.
Analysis paths shown that, despite several design decisions intended simplify
protein folding problem, PCR-based algorithms predict order secondary structure formation. Agreement wet-laboratory data validated general usage PCR-based algorithms
provide coarse-grained treatment folding unfolding pathways protein chains.
works Amato collaborators also show applicability PCR-based algorithms study
RNA folding unfolding (Tapia et al., 2007; Tang et al., 2008; Tapia et al., 2010) .
sampling strategy incremental perturbations effective protein chains
60 amino acids (Song & Amato, 2004) scales poorly longer chains (Thomas et al., 2005).
Ensuing work improves sampling protein chains 110 amino acids reducing
number variables modeled represent conformations (Thomas et al., 2007). Specifically, rigidity analysis employed detect least-constrained regions given structure. dihedral angles
belonging regions selected often perturbation sampling stage. modification shown effective revealing subtle folding differences protein G two
sequence variants. particular, modification also shown promising capturing
dynamic events proteins beyond folding study large-scale conformational changes involved
structural transitions calmodulin protein. Related ideas employed researchers compute temperature-dependent optimal folding paths peptides proteins (Yang
et al., 2007; Li et al., 2008). MaxFlux-PRM algorithm proposed Yang et al. (2007)
study structural transitions dialanine peptide folding -hairpin shown Li
et al. (2008) capable predicting folding pathways engrailed homeodomain protein.
work Amato lab focused exploiting conformation roadmap extract
quantities summarizing folding kinetics protein RNA molecules. Tapia et al. (2007) introduce
two new analysis techniques, Map-based Master Equation (MME) Map-based MC (MMC)
technique. work shows treating roadmap map folding landscape
546

fiC OMPUTATIONAL REATMENTS B IOMOLECULES ROBOTICS -I NSPIRED ETHODS

exploited estimate kinetic metrics typically extracted MD simulation studies.
Metropolis MC simulations conducted roadmap, moving roadmap vertices
observing edge probabilities roadmap. Different statistics calculated
MMC walks, including folding rates population kinetics. Tang et al. (2008) show statistics
summarizing RNA folding predict well relative gene expression rate wild-type MS2
phage RNA three mutants, good agreement wet-laboratory data.
4.2.3 TOCHASTIC ROADMAP IMULATION ARKOV TATE ODELS ODELING
P ROTEIN RNA (U N ) FOLDING P ROTEIN TRUCTURAL RANSITIONS
idea reliable statistics extracted molecular conformation roadmaps presented earlier Latombe colleagues (Apaydin et al., 2003). stochastic roadmap simulation (SRS) framework formalized relation key analogy roadmap Markov
state model (MSM); concept stochastic roadmap probabilistic edges presented
earlier (Song & Amato, 2000), analogy MSM went missing till 2003 formalization Latombe colleagues (Apaydin et al., 2003). latter laid bare analogies stochastic roadmap would later referred point-based MSM.
MSM, states MSM single-conformation vertices stochastic roadmap,
probabilistically-weighted edges connecting vertices roadmap state-to-state transitions
MSM. analogy brought focus stochastic roadmap better encodes stochastic nature biomolecular motions, analogy MSM could even used extract
interesting summary statistics regarding physics-driven stochastic processes.
addition recognizing biased random walks carried roadmap
employed extract statistics interest (Tapia et al., 2007), SRS-MSM analogy highlights
effective, algebra-based techniques (Markov chain) transition state theory employed
extract average statistics without launching single simulation (or random walk roadmap).
Folding rates, pfold values, values, estimates kinetics, transition rates,
obtained without needing perform many random walks in-order propagation transition
probabilities. analogy stochastic roadmap point-based MSM shown result
correctly-predicted pfold values small proteins modeled secondary structure level
612 variables (Apaydin, Brutlag, Hsu, & Latombe, 2002; Apaydin et al., 2003). work
demonstrated transition state ensemble (the set conformations pfold =0.5), folding
rates, values could predicted 16 different proteins fraction computational
time would needed framework launching numerous MC simulations (Chiang, Apaydin,
Brutlag, Hsu, & Latombe, 2006; Chiang et al., 2007) .
SRS-MSM analogy permits interesting mathematics, practical issues
ensure transition matrix prohibitive size allow solving linear algebra equations
addressed case-by-case basis. formalization presented Apaydin et al. (2003)
discuss practical design decisions group conformations states
estimate transition probabilities two sub-ensembles, rather mathematics
would possible analogy stochastic roadmap MSM. Analogies cellbased MSMs, states homogeneous sub-ensembles conformations rather single
conformations need addressing practical issues regarding organize conformations states
associate transition probabilities states.
547

fiS HEHU & P LAKU

Since seminal work Apaydin et al. (2003), analogies SRS cell-based MSMs
largely limited, partly due lack clear objectives design decisions
general ability transform roadmap MSM manageable size. instance,
fundamental assumption conformations obtained via MD simulation
temperature , probability edge representing transition vertex u vertex v
could measured via Boltzmann-related Metropolis criterion e(E(v)E(u))/(KB ) . realization allowed Apaydin, Latombe, colleagues see clear connection stochastic (probabilistic) roadmap structures point-based MSM, vertices seen states
MSM edges vertices roadmap transitions states MSM. However, practical considerations convert single conformation vertex probabilities
state-state transition probabilities discussed.
issue associate probabilities first place conformations sampled via
non-MD algorithms also discussed. Two groups researchers started operationalizing
seminal ideas presented Apaydin et al. (2003). Work Latombe colleagues focused either point-based MSMs summarizing uncovering MD-simulated dynamics
synthetic small peptides via cell-based MSMs (Chiang et al., 2007, 2010). Complementary work Shehu lab focused non-MD approaches extracting average statistics
model compare transitions healthy aberrant forms disease-participating, small-
medium-size proteins (Molloy et al., 2016).
Chiang et al. (2010) offer novel representation states individual conformations (Apaydin et al., 2003; Singhal, Snow, & Pande, 2004) even disjoint regions conformation space
(Ozkan, Dill, & Bahar, 2002; Chodera, Singhal, Pande, Dill, & Swope, 2007) (as cell-based
MSMs) instead overlapping probabilistic distributions conformation space.
distribution relies key recognition single conformation contain enough information uniquely mapped state leads presence hidden states
referred Markov Dynamics Model (MDM) rather MSM (Chiang et al., 2010).
MDM, emission probabilities hidden states measure probability conformation belongs state. transition emission probabilities estimated trajectories
conformations obtained many MD simulation trajectories. principled criterion based
ability model predict long-timescale kinetics allows discriminating possible MDMs
selecting optimal one. MDM embedded conformations obtained MD trajectories simulating folding fast-folding villin headpiece subdomain (HP-35 NleNle) shown
Figure 11. MDM presents highly-interpretable discrete kinetic model folding
small sub-domain, built 400 MD trajectories, 1s long. Figure 11 shows
states, 7, 12, 13, 15 18, frequently-visited states significantly influence
long-term dynamics.
Molloy et al. (2016) present strategies embed conformations sampled via non-MD method
cell-based MSM. ability formulate cell-based MSM relies dense sampling
conformation space interest. latter provides significantly challenging MD setting
even robotics-inspired setting. Instead, complementary work Shehu lab EAs
used obtain rich ensemble local minima conformations healthy variant sequences
given protein (Clausen & Shehu, 2015; Clausen et al., 2015). conformations organized
states via simple lRMSD-based clustering scheme. nearest-neighbor graph imposed
states, additional lRMSD constraint imposed connect nearby states
via edge. assumption made transitions possible nearby states, prob548

fiC OMPUTATIONAL REATMENTS B IOMOLECULES ROBOTICS -I NSPIRED ETHODS

Figure 11: figure, reproduced work Chiang et al. (2010), (a) shows MSM connecting
twenty identified states villin headpiece peptide. size node MSM proportional
probability corresponding state stationary distribution. width edge proportional
transition probability corresponding states. States probability < 0.01 stationary
distribution, self-transitions, edges transition probability < 0.002 drawn avoid cluttering.
initial conformations likely belong state 12, native conformation likely
belong state 15. (b) Representative conformations shown states 7, 12, 13, 15, 18.
residues forming important helix 1 villin headpiece peptide drawn red. (c) likely state
transition sequences states 12 15 shown here. figure reproduced Bioinformatics
Journals terms Creative Commons Attribution Non-Commercial License.

abilities transitions estimated via Boltzmann-like probability. latter makes use
concept energy state. Several schemes employed determine energy
state, ranging minimum average value energies conformations grouped
state.
549

fiS HEHU & P LAKU

Figure 12: figure reproduced work Molloy et al. (2016). Panel (a) shows two wet-laboratory
structures representative structural states H-Ras catalytic domain. H-Ras switches
two states regulate biological activity cell. loop regions change
localized shown red blue. reactant (GTP) product (GDP) also drawn bind
H-Ras. Panel (b) shows two-dimensional projections probed energy surface H-Ras wildtype (WT)
oncogenic Q61L variant. Sampled conformations projected top two principal components
(PC) obtained via Principal Component Analysis sampled conformations. color-coding follows
Amber ff12SB internal energy values all-atom structure corresponding sampled conformation.
minimum-cost paths obtained querying stochastic roadmap constructed sampled
conformations shown, well. costs paths shown table panel (c). average
number edges possible paths obtained treating roadmap MSM.
actual energy profiles minimum-cost paths obtained WT Q61L variant shown panel
(d). figure reproduced permission Robotica 2016.

result process stochastic roadmap used answer lowest-cost path
queries, traditionally case roadmap-based methods, well yield average statistics,
average number edges transition, via analogy stochastic roadmap
MSM. path smoothing algorithm based conjugate peak refinement technique (Fischer &
Karplus, 1992) provides detail state-state paths improves energetic profile.
average statistics, direct measurements transition rates due lack timescale information non-MD methods, allow conducting comparisons wildtype (WT) variant (mutated) sequences proteins interest. work Molloy et al. (2016), statistics
employed obtain structural explanation role specific mutations biological
activity two proteins implicated human disorders. Figure 12 showcases representative
results application SRS-based approach work Molloy et al. WT
Q61L variant H-Ras protein. Ras sequence mutations implicated various human
cancers (Karnoub & Weinberg, 2008).
550

fiC OMPUTATIONAL REATMENTS B IOMOLECULES ROBOTICS -I NSPIRED ETHODS

Comparison energy landscapes, costs minimum-cost paths, energy profiles
paths, expected number edges paths H-Ras sequence Figure 12 provides structural explanation impact Q61L mutation biological activity
enzyme. mutation introduces energy barrier states, barrier
increases cost minimum cost path number expected edges transition
paths. Taken together, results suggest Q61L mutation, preserving stability
states, cannot form transition state mimic, agreement wet-laboratory
studies (Gremer, Gilsbach, Ahmadian, & Wittinghofer, 2008; Gibbs, Schaber, Allard, Sigal, & Scolnick, 1988).
4.2.4 DDRESSING L IMITED AMPLING ROADMAP -BASED ETHODS ODELING
P ROTEIN TRUCTURAL RANSITIONS
Sampling remains key issue adaptations roadmap-based methods biomolecular modeling.
generally focus robotics-inspired methods demonstrating ability
reproduce experimental knowledge qualitatively even quantitatively specific systems
investigation, general applicability largely sacrificed. instance, roadmapbased methods applied model discrete secondary structure formation events protein folding
unfolding largely applicable model folding transition events proteins
150 amino acids states sought bridged transition may farther
10A away each-other. Strategies reduce number variables control
dimensionality variable space important ramifications. instance, rigidity-based
techniques base conclusions flexible regions analysis specific
structure. NMA techniques suffer similar issue, regular application NMA sampled
conformations adds computational time demands algorithm. techniques make
assumptions regions participate particular transition event rule
possibility potentially complex, cooperative events. Others bundle variables together
obtain values pre-compiled databases make similar assumptions types
structural changes facilitate transition.
Sampling remain challenge, two complementary directions explored.
first direction values broad applicability specific improvements. Molloy Shehu (2016)
propose community needs benchmark testing dataset baseline approach
specific improvements extensions evaluated. particular, work ignores
system-specific insights variable sampling schemes effective
others instead compiles broad set variables sampling/perturbation operators
selected via probabilistic scheme. Different schemes employed different stages
roadmap-based method based distance conformations need connected
size biomolecule investigation. general baseline implementation shows
comparable performance system-specific methods promises improvements
guarantee baseline performance broad set biomolecules problem instances. Related
ideas building concept move selector presented Gipson et al. (2013).
second direction sacrifices broad applicability interest improving predictive
capability roadmap-based methods point reliable hypotheses formulated guide wet-laboratory experimentation. Maximova et al. (2015) recognize roadmap-based
methods operate de novo setting instead exploit rich set wet-laboratory
551

fiS HEHU & P LAKU

Figure 13: figure reproduced work Maximova et al. (2015). left panel shows
schematic summarizes paths within small energetic threshold minimum-cost path connecting
structure pairs interest calmodulin. Analysis paths reveals known, wet-laboratory structures
mediate transitions interest. PDB ids mediating structures shown along paths.
right panel shows successive structures minimum-cost paths found transitions calmodulin
structure PDB id 1CLL PDB id 2F3Y structure PDB id 1CLL
PDB id 1NWD. Numbers indicate model number within NMR entry. figure reproduced
permission IEEE Society 2015.

structures determine variable space interest. particular, SoPRIM algorithm proposed
Maximova et al. subjects wet-laboratory structures different sequences protein statistical multivariate analysis determine variables represent collective motions atoms. Sampling
focuses space variables multiscaling technique converts samples all-atom structures local minima Amber ff14SB energy function. samples embedded
roadmap, distance constraints ensure edges placed neighboring samples.
Edges weighted based concept minimum cost, recording energetic increases.
additional contrast existing roadmap-based treatments, work Maximova et al.
(2015) yields minimum-cost path connecting given start given goal structure,
allows extracting additional paths similar costs. concept tours employed, based
related work robotics. tours allow investigate specific hypotheses regarding participation known meta-stable structures transition. set structures specified,
minimum-cost tours consider subsets orders structures reported. Analysis
tours costs higher specific threshold minimum-cost path reveals precious
information regarding important function-regulation transitions several proteins, including Ras
calmodulin. summary result shown Figure 13.
Figure 13 extracts several energetically-credible paths representing various, equiprobable
routes transitions calmodulin open, unbound state (represented structure PDB
id 1CLL) two different, closed peptide protein-bound states (represented structures
PDB id 2F3Y 1NWD). schematic summary paths Figure 13 highlights
open-to-closed transitions calmodulin may make use calcium-bound structure
(PDB id 1CFD). Indeed, paths go structure higher energetic cost. different
intermediate structure emerges analysis paths. structure (under PDB id 2K0E)
also binds calcium slightly different PDB id 1CFD. succession structures shown 13 makes clear domain collapse, re-arrangement, partial unfolding
helix links N- C-terminal domains calmodulin gradual, captured various structures NMR ensemble PDB id 2K0E. result good agreement
552

fiC OMPUTATIONAL REATMENTS B IOMOLECULES ROBOTICS -I NSPIRED ETHODS

wet-laboratory study work Gsponer, Christodoulou, Cavalli, Bui, Richter, Dobson,
Vendruscolo (2008), which, addition contributing NMR entry PDB id 2K0E
Protein Data Bank, also concludes correlated motions within 2K0E Ca(2+)-CaM state
direct structural fluctuations toward complex-like substates (Gsponer et al., 2008).
wet-laboratory study Gsponer et al. (2008) restricted MLCK binding CaM, results
obtained SoPRIM algorithm (Maximova et al., 2015) suggest mechanism observed Gsponer et al. (2008) prepares CaM binding peptides (the C-terminal Domain
Petunia Glutamate Decarboxylase 1NWD IQ domain 2F3Y). work Maximova et al. (2015) points general mechanism apo-to-closed/complexed dynamics
calmodulin, correlated motions within calcium-bound state direct fluctuations
population shift protein peptide-bound states.

5. Outstanding Challenges Directions Research
Robotics-inspired methods becoming powerful diverse algorithmic strategies
problems address biomolecular modeling. survey focused treeand roadmap-based methods modeling protein-ligand binding, protein de novo structure prediction, protein RNA folding unfolding, structural transitions peptides proteins,
energy landscape mapping, methods building related ideas efficiently map ligand
migration channel networks dynamic proteins (Lin & Song, 2011; Na & Song, 2015) even
model antibody aggregation processes (Hoard, Jacobson, Manavi, & Tapia, 2016).
attempted provide broad deep survey robotics-inspired methods biomolecular modeling, exhaustive survey possible. particular sub-domain interface Robotics
computational structural biology rapidly progressing, demonstrated increasing number
adaptations applications showcased survey earlier, related reviews roboticsinspired methods (Al-Bluwi et al., 2012; Gipson, Hsu, Kavraki, & Latombe, 2012). survey
showcases, several algorithmic challenges remain. provide partial list challenges prospects future research.
5.1 Problem-Specific versus General Treatments
pressing need community benchmarks. work largely driven
specific biological systems problems interest, data-driven research often resulted
specific design decisions easily transferable systems problems.
instance, key decisions reduce dimensionality variable space design compliant sampling strategies perturbation operators specific problem instance may
applicable another problem. realization need baseline, general treatments benchmarks leading researchers towards non-specific treatments establish benchmarks baseline
performance. Better sharing problem instances, metrics, algorithms known baseline
performance also key allow researchers build existing work expedite progress.
5.2 Sampling
growing realization sampling remain central issue, despite clever reduced representations sampling strategies. community researchers adapting robot motion planning treatments biomolecular modeling successful integrating important knowledge
553

fiS HEHU & P LAKU

biomolecules model selection, sampling strategies, energetic evaluations, community largely remained isolated complementary work AI stochastic optimization
continuous, non-linear variable spaces. particular, growing body work evolutionary computation community optimization complex fitness landscapes. ideas
community successfully employed de novo structure prediction (Shehu, 2013)
mapping protein energy landscapes (Clausen & Shehu, 2015; Clausen et al., 2015; Sapin, Carr,
De Jong, & Shehu, 2016). ideas also beginning incorporated robotics-inspired
treatments biomolecular dynamics (Molloy et al., 2016). Better awareness integration
effective practices communities dealing similarly challenging high-dimensional problems likely address issues sampling lead powerful robotics-inspired treatments.
context, see great opportunity AI researchers make contributions sampling-based
treatments biomolecular dynamics.
5.3 Decorrelations Paths
particular, applications tree- roadmap-based methods modeling structural transitions
biomolecules, path correlation issue. Path correlations potentially skew statistics
interest even yield incorrect conclusions structural transition. culprit treebased methods bias applied steer conformation tree goal conformation.
Even multiple executions tree-based method likely result similar paths.
extent, source path correlations addressed. instance, Molloy Shehu (2013)
makes use additional projection layer steer tree towards under-sampled regions
conformation space. shown improve path diversity. Yet another culprit shared
tree- roadmap-based methods density sampling. instance, undersampling specific
regions may lead conclusion region energetically favorable biomolecule
hand. investigation needed quantify reduce path correlations robotics-inspired
methods. direction also ripe cross-fertilization ideas different sub-communities
AI.
5.4 Injection Dynamics
common criticism robotics-inspired methods essentially geometric treatments
biomolecules. extent geometric treatments accepted modeling biomolecular structure, seen inadequate modeling biomolecular dynamics. Modeling dynamics
largely seen exclusive MD simulation frameworks. somewhat colloquial simplistic characterization robotics-inspired methods, biomolecular dynamics nothing
robot motion planning. characterization overcome pointing superficial
analogies used inspire robotics researchers, deeper analogies exploited
shown impact selection models, variables, fast forward inverse
kinematics, effective sampling strategies. worth noting latter exclusively
domain robotics-inspired researchers. contrary, issues effective variable selection
representation, variation operators, employment operators sampling strategies,
others broad interest AI researchers working optimization problems part modeling
abstract, mechanical, biological systems.
various places, survey highlighted robotics-inspired methods capable
reproducing wet-laboratory knowledge data also providing novel findings direct
554

fiC OMPUTATIONAL REATMENTS B IOMOLECULES ROBOTICS -I NSPIRED ETHODS

experimentation wet laboratories. Still, valid criticism robotics-inspired methods
edges trees roadmaps provide detailed view diffusion
two conformations connect. survey points Section 4 several challenges
integrating MD trajectories robotics-inspired framework, important community think
ways effectively. Injection ideas AI community large may prove beneficial
here. growing body work computational biophysics pointing effective frameworks
biomolecular dynamics integrate thousands short MD trajectories MSMs capture
biomolecular dynamics. Cross-fertiziliation ideas AI biophysics communities
likely prove fruitful explicitly integrating MD robotics-inspired methods.
5.5 Beyond Path Computations: Roadmaps MSMs
survey highlights Section 4, MSMs become popular computational biophysics literature organize extract statistics many, independent MD simulations
biomolecular folding structural transitions (Jayachandran, Vishal, & Pande, 2006; Chodera
et al., 2007; Noe & Fischer, 2008; Prinz, Keller, & Noe, 2011a; Noe, Doose, Daidone, Lollmann,
Sauer, Chodera, & Smith, 2011; Perez-Hernandez, Paul, Giorgino, De Fabritiis, & Noe, 2013; Weber, Jack, & Pande, 2013; Deng, Dai, & Levy, 2013; Chodera & Noe, 2014; Malmstrom, Lee,
Van Wart, & Amaro, 2014; Song & Zhuang, 2014; Shukla, Hernandez, Weber, & Pande, 2015).
Several survey articles dedicated reviewing MSM-based treatments biomolecular dynamics (Pande, Beachamp, & Bowman, 2010; Gipson et al., 2012; Maximova et al., 2016) review MSMbased treatments biomolecular dynamics. Works Chiang et al. (2006), Chiang et al. (2007),
Chiang et al. (2010), Molloy et al. (2016) provide important first step integration
MSMs analysis conformation spaces probed via robotics-inspired algorithms. Chiang et al. (2010) Molloy et al. (2016) address issues convert roadmaps
MSMs, many others remain, including definition structural states, possible undersampling specific states, feedback mechanisms address undersampling, rigorous calculation transition
probabilities. issues also contended computational biophysics community, initial treatments emerged (Singhal et al., 2004; Singhal & Pande, 2005; Prinz, Wu,
Sarich, Keller, Senne, Held, Chodera, Schutte, & Noe, 2011b; Malmstrom et al., 2014; Da, Sheong,
Silva, & Huang, 2014). see great opportunity AI researchers, particularly
expertise machine learning, coordinate efforts computational biophysicists. efforts
undoubtedly lead richer powerful computational treatments biomolecular dynamics.
5.6 Cross-Fertilization Ideas
survey shows, work modeling biomolecular structure dynamics highly interdisciplinary, great progress achieved ideas different communities combined
integrated computational treatments. rich set scientific questions formulated understand role biomolecular structure dynamics human biology health.
questions often result exceptionally challenging computational problems necessitate
sophisticated algorithmic treatments. Treatments add current knowledge biomolecular
systems chemistry, physics, biophysics likely advance modeling capabilities also make important, general contributions AI research.
555

fiS HEHU & P LAKU

Acknowledgements
Funding work provided part National Science Foundation. work A. Shehu
supported NSF-CCF1421001, NSF-ACI1440581, NSF-IIS1144106. work E. Plaku
supported NSF-ACI1440581, NSF-IIS1449505, NSF-IIS1548406.

References
Abayagan, R., Totrov, M., & Kuznetsov, D. (1994). ICM - new method protein modeling
design: applications docking structure prediction distorted native conformation. J Comput Chem, 15(5), 488506.
Aden, J., & Wolf-Watz, M. (2007). NMR identification transient complexes critical adenylate
kinase catalysis. J Amer Chem Soc, 129(45), 14003 14012.
Al-Bluwi, I., Simeon, T., & Cortes, J. (2012). Motion planning algorithms molecular simulations: survey. Comput Sci Rev, 6(4), 125143.
Al-Bluwi, I., Vaisset, M., Simeon, T., & Cortes, J. (2013). Modeling protein conformational transitions combination coarse-grained normal mode analysis robotics-inspired methods. BMC Struct Biol, 13(S2), Suppl 1.
Amato, N. M., Bayazit, B., Dale, L., Jones, C., & Vallejo, D. (1998). OBPRM: obstacle-based
PRM 3D workspaces. Workshop Algorithm Found Robot, Vol. 86 Springer Tracts
Advanced Robotics, pp. 156168. Springer.
Amato, N. M., Dill, K. A., & Song, G. (2003). Using motion planning map protein folding
landscapes analyze folding kinetics known native structures. J Comput Biol, 10(3-4),
239255.
Anfinsen, C. B. (1973). Principles govern folding protein chains. Science, 181(4096),
223230.
Apaydin, M. S., Brutlag, D. L., Guestrin, C., Hsu, D., & Latombe, J.-C. (2003). Stochastic roadmap
simulation: efficient representation algorithm analyzing molecular motion. J Comput Biol, 10(3-4), 257281.
Apaydin, M. S., Brutlag, D. L., Hsu, D., & Latombe, J.-C. (2002). Stochastic conformational
roadmaps computing ensemble properties molecular motion. Workshop Algorithm
Found Robot, pp. 131147, Nice, France. IEEE.
Apaydin, M. S., Singh, A. P., Brutlag, D. L., & Latombe, J.-C. (2001). Capturing molecular energy
landscapes probabilistic conformational roadmaps. Intl Conf Robot Autom (ICRA),
Vol. 1, pp. 932939, Seoul, Korea. IEEE.
Atilgan, A., Durell, S., Jernigan, R., Demirel, M., Keskin, O., & Bahar, I. (2001). Anisotropy
fluctuation dynamics proteins elastic network model. Biophys J, 80(1), 505515.
Bahar, R., & Rader, A. J. (2005). Coarse-grained normal mode analysis structural biology. Curr
Opinion Struct Biol, 204(5), 17.
Baldwin, R. L. (1995). nature protein folding pathways: classical versus new view. J
Biomol NMR, 5(2), 103109.
556

fiC OMPUTATIONAL REATMENTS B IOMOLECULES ROBOTICS -I NSPIRED ETHODS

Barbe, S., Cortes, J., Simeon, T., Monsan, P., Remaud-Simeon, M., & Andre, I. (2011). mixed
molecular modeling-robotics approach investigate lipase large molecular motions. Proteins: Struct Funct Bioinf, 79(8), 25172529.
Baron, R. (2013). Fast sampling A-to-B protein global conformational transitions: Galileo
Galilei Monte Carlo anisotropic network modeling. Biophys J, 105(7), 15451546.
Batcho, P., Case, D. A., & Schlick, T. (2001). Optimized particle-mesh ewald/multiple-time step
integration molecular dynamics simulations. J Chem Phys, 115(9), 40034018.
Bekris, K. E., & Kavraki, L. E. (2007). Greedy safe replanning kinodynamic constraints.
Intl Conf Robot Autom (ICRA), pp. 704710, Rome, Italy. IEEE.
Berman, H. M., Henrick, K., & Nakamura, H. (2003). Announcing worldwide Protein Data
Bank. Nat Struct Biol, 10(12), 980980.
Boehr, D. D., & Wright, P. E. (2008). proteins interact?. Science, 320(5882), 14291430.
Bradley, P., Misura, K. M., & Baker, D. (2005). Toward high-resolution de novo structure prediction
small proteins. Science, 309(5742), 18681871.
Brooks, B. R., Bruccoleri, R. E., Olafson, B. D., States, D. J., Swaminathan, S., & Karplus, M.
(1983). CHARMM: program macromolecular energy, minimization, dynamics calculations. J Comput Chem, 4(2), 187217.
Bryngelson, J. D., Onuchic, J. N., Socci, N. D., & Wolynes, P. G. (1995). Funnels, pathways,
energy landscape protein folding: synthesis. Proteins: Struct Funct Genet, 21(3),
167195.
Bryngelson, J. D., & Wolynes, P. G. (1987). Spin glasses statistical mechanics protein
folding. Proc Natl Acad Sci USA, 84(21), 75247528.
Burgess, A. W., & Scheraga, H. A. (1975). Assessment problems associated prediction
three-dimensional structure protein amino-acid sequence. Proc Natl Acad
Sci USA, 72(4), 12211225.
Burns, B., & Brock, O. (2007). Single-query motion planning utility-guided random trees.
Intl Conf Robot Autom (ICRA), pp. 33073312, Rome, Italy. IEEE.
Case, D. A., Darden, T. A., Cheatham, T. E. I., Simmerling, C. L., Wang, J., Duke, R. E., Luo, R.,
Merz, K. M., Pearlman, D. A., Crowley, M., Walker, R. C., Zhang, W., Wang, B., Hayik, S.,
Roitberg, A., Seabra, G., Wong, K. F., Paesani, F., Wu, X., Brozell, S., Tsui, V., Gohlke, H.,
Yang, L., Tan, C., Mongan, J., et al. (2014). Amber 14. http://ambermd.org/.
Chiang, T. H., Apaydin, M., Brutlag, D., Hsu, D., & Latombe, J. (2006). Predicting experimental
quantities protein folding kinetics using stochastic roadmap simulation. Res Comput
Mol Biol, Vol. 3909 Lecture Notes Computer Science, pp. 410424. Springers.
Chiang, T. H., Apaydin, M. S., Brutlag, D. L., Hsu, D., & Latombe, J.-C. (2007). Using stochastic
roadmap simulation predict experimental quantities protein folding kinetics: folding
rates phi-values. J Comput Biol, 14(5), 578593.
Chiang, T. H., Hsu, D., & C., L. J. (2010). Markov dynamic models long-timescale protein
motion. Bioinformatics, 26(12), 269277.
557

fiS HEHU & P LAKU

Chirikjian, G. S. (1993). General methods computing hyper-redundant manipulator inverse
kinematics. Intl Conf Intell Robot Sys (IROS), Vol. 2, pp. 10671073, Yokohama, Japan.
IEEE.
Chodera, J. D., & Noe, F. (2014). Markov state models biomolecular conformational dynamics.
Curr Opinion Struct Biol, 25, 135144.
Chodera, J. D., Singhal, N., Pande, V. S., Dill, K. A., & Swope, W. C. (2007). Automatic discovery
metastable states construction markov models macromolecular conformational
dynamics. J Chem Phys, 126(15), 155101.
Choset, H., & et al. (2005). Principles Robot Motion: Theory, Algorithms, Implementations
(1st edition). MIT Press, Cambridge, MA.
Ciu, Q., & Bahar, I. (2005). Normal Mode Analysis: Theory Applications Biological
Chemical Systems (1st edition). CRC Press.
Clausen, R., Ma, B., Nussinov, R., & Shehu, A. (2015). Mapping conformation space wildtype
mutant H-Ras memetic, cellular, multiscale evolutionary algorithm. PLoS
Comput Biol, 11(9), e1004470.
Clausen, R., & Shehu, A. (2015). data-driven evolutionary algorithm mapping multi-basin
protein energy landscapes. J Comp Biol, 22(9), 844860.
Clementi, C. (2008). Coarse-grained models protein folding: Toy-models predictive tools?.
Curr Opinion Struct Biol, 18(1), 1015.
Coifman, R. R., Lafon, S., Lee, A. B., Maggioni, M., Nadler, B., Warner, F., & Zucker, S. W. (2005).
Geometric diffusions tool harmonic analysis structure definition data: Diffusion
maps. Proc Natl Acad Sci USA, 102(21), 74267431.
Cooper, A. (1984). Protein fluctuations thermodynamic uncertainty principle. Prog Biophys
Mol Biol, 44(3), 181214.
Cortes, J., Jaillet, L., & Simeon, T. (2007). Molecular disassembly RRT-like algorithms.
Intl Conf Robot Autom (ICRA), pp. 33013306, Roma, Italy.
Cortes, J., Le, D. T., Lehl, R., & Simeon, T. (2010). Simulating ligand-induced conformational
changes proteins using mechanical disassembly method. Phys Chem Chem Phys, 12(29),
82688276.
Cortes, J., Simeon, T.AND Remauld-Simeon, M., & Tran, V. (2004). Geometric algorithms
conformational analysis long protein loops. J Comput Chem, 25(7), 956967.
Cortes, J., Simeon, T.AND de Angulo, R., Guieysse, D., Remaud-Simeon, M., & Tran, V. (2005).
path planning approach computing large-amplitude motions flexible molecules. Bioinformatics, 21(S1), 116125.
Craig, J. (1989). Introduction robotics: mechanics control (2nd edition). Addison-Wesley,
Boston, MA.
Da, L. T., Sheong, F. K., Silva, D. A., & Huang, X. (2014). Application Markov state models
simulate long timescale dynamics biological macromolecules. Adv Exp Med Biol, 805,
2966.
558

fiC OMPUTATIONAL REATMENTS B IOMOLECULES ROBOTICS -I NSPIRED ETHODS

Dalibard, S., & Laumond, J.-P. (2009). Control probabilistic diffusion motion planning.
Workshop Algorithm Found Robot, Vol. 57 Springer Tracts Advanced Robotics, pp. 467
481. Springer.
Das, A., Gur, M., Cheng, M. H., Jo, S., Bahar, I., & Roux, B. (2014). Exploring conformational transitions biomolecular systems using simple two-state anisotropic network
model. PLoS Comput Biol, 10(4), e1003521.
Das, P., Matysiak, S., & Clementi, C. (2005). Balancing energy entropy: minimalist model
characterization protein folding landscapes. Proc Natl Acad Sci USA, 102(29),
1014110146.
Das, P., Moll, M., Stamati, H., Kavraki, L. E., & Clementi, C. (2006). Low-dimensional free energy
landscapes protein folding reactions nonlinear dimensionality reduction. Proc Natl
Acad Sci USA, 103(26), 98859890.
Delarue, M., & Sanejouand, Y. H. (2002). Simplified normal mode analysis conformational
transitions DNA-dependent polymerases: elastic network model. J Mol Biol, 320(5),
10111024.
Deng, N.-J., Dai, W., & Levy, R. M. (2013). kinetics within unfolded state affects protein
folding: analysis based markov state models ultra-long md trajectory. J Phys
Chem B, 117(42), 1278712799.
Denny, J., & Amato, N. M. (2013). Toggle PRM: coordinated mapping C-free C-obstacle
arbitrary dimension. Workshop Algorithm Found Robot, Vol. 86 Springer Tracts
Advanced Robotics, pp. 297312. Springer.
Devaurs, D., Molloy, K., Vaisset, M., Shehu, A., Cortes, J., & Simeon, T. (2015). Characterizing
energy landscapes peptides using combination stochastic algorithms. IEEE Trans
NanoBioScience, 14(5), 545552.
Diekmann, S., & Hoischen, C. (2014). Biomolecular dynamics binding studies living
cell. Physics Life Reviews, 11(1), 130.
Dill, K. A., & Chan, H. S. (1997). Levinthal pathways funnels. Nat Struct Biol, 4(1),
1019.
Dryga, A., Chakrabarty, S., Vicatos, S., & Warshel, A. (2011). Realistic simulation activation
voltage-gated ion channels. Proc Natl Acad Sci USA, 109(9), 33353340.
Dubrow, A. (2015). got done one year NSFs Stampede supercomputer. Comput Sci Eng,
17(2), 8388.
Ekenna, C., Thomas, S., & Amato, N. (2016). Adaptive local learning sampling based motion
planning protein folding. BMC Syst Biol, 10(Suppl 2).
Engh, R. A., & Huber, R. (1991). Accurate bond angle parameters X-ray protein structure
refinement. Acta Crystallogr, A47, 392400.
Enosh, A., Raveh, B., Furman-Schueler, O., Halperin, D., & Ben-Tal, N. (2008). Generation, comparison, merging pathways protein conformations: gating K-channels. Biophys J, 95(8), 38503860.
559

fiS HEHU & P LAKU

Fattebert, J.-L., Richards, D. F., & Glosli, J. N. (2012). Dynamic load balancing algorithm
molecular dynamics based voronoi cells domain decompositions. Comput Phys Communic, 183(12), 26082615.
Fenwick, R. B., van den Bedem, H., Fraser, J. S., & Wright, P. E. (2014). Integrated description
protein dynamics room-temperature X-ray crystallography NMR. Proc Natl Acad
Sci USA, 111(4), E445E454.
Fernandez-Medarde, A., & Santos, E. (2011). Ras cancer developmental diseases. Genes
Cancer, 2(3), 344358.
Fersht, A. (2013). Profile martin karplus, michael levitt, arieh warshel, 2013 nobel laureates
chemistry. Proc Natl Acad Sci USA, 110(49), 1965619657.
Fersht, A. R. (1999). Structure Mechanism Protein Science. Guide Enzyme Catalysis
Protein Folding (3 edition). W. H. Freeman Co., New York, NY.
Feynman, R. P., Leighton, R. B., & Sands, M. (1963). Feynman Lectures Physics. AddisonWesley, Reading, MA.
Fischer, S., & Karplus, M. (1992). Conjugate peak refinement: algorithm finding reaction
paths accurate transition states systems many degrees freedom. Chem Phys
Lett, 194(3), 252261.
Fox, N., & Streinu, I. (2013). Towards accurate modeling noncovalent interactions protein
rigidity analysis. BMC Bioinf, 14(Suppl 18), S3.
Gall, A., Ilioaia, C., Kruger, T. P., Novoderezhkin, V. I., Robert, B., & van Grondelle, R. (2015).
Conformational switching light-harvesting protein followed single-molecule spectroscopy. Biophys J, 108(11), 27132720.
Gibbs, J. B., Schaber, M. D., Allard, W. J., Sigal, I. S., & Scolnick, E. M. (1988). Purification Ras
GTPase activating protein bovine brain. Proc Natl Acad Sci USA, 85(14), 50265030.
Gipson, B., Hsu, D., Kavraki, L. E., & Latombe, J.-C. (2012). Computational models protein
kinematics dynamics: Beyond simulation. Annu Rev Anal Chem, 5, 273291.
Gipson, B., Moll, M., & Kavraki, L. E. (2013). SIMS: hybrid method rapid conformational
analysis. PLoS One, 8(7), e68826.
Gorfe, A. A., Grant, B. J., & McCammon, J. A. (2008). Mapping nucleotide isoformdependent structural dynamical features Ras proteins. Structure, 16(6), 885896.
Gotz, A. W., Williamson, M. J., Xu, D., Poole, D., Le Grand, S., & Walker, R. C. (2012). Routine
microsecond molecular dynamics simulations amber GPUs. 1. Generalized Born. J
Chem Theory Comput, 8(5), 15421555.
Grant, B. J., Gorfe, A. A., & McCammon, J. A. (2009). Ras conformational switching: Simulating
nucleotide-dependent conformational transitions accelerated molecular dynamics. PLoS
Comput Biol, 5(3), e1000325.
Greenleaf, W. J., Woodside, M. T., & Block, S. M. (2007). High-resolution, single-molecule measurements biomolecular motion. Annu Rev Biophys Biomol Struct, 36, 171190.
Gremer, L., Gilsbach, B., Ahmadian, M. R., & Wittinghofer, A. (2008). Fluoride complexes
oncogenic Ras mutants study Ras-RasGap interaction. Biol Chem, 389(9), 11631171.
560

fiC OMPUTATIONAL REATMENTS B IOMOLECULES ROBOTICS -I NSPIRED ETHODS

Gsponer, J., Christodoulou, J., Cavalli, A., Bui, J. M., Richter, B., Dobson, C. M., & Vendruscolo, M.
(2008). coupled equilibrium shift mechanism calmodulin-mediated signal transduction.
Structure, 16(5), 736746.
Han, K. F., & Baker, D. (1996). Global properties mapping local amino acid sequence
local structure proteins. Proc Natl Acad Sci USA, 93(12), 58145818.
Han, L., & Amato, N. M. (2001). kinematics-based probabilistic roadmap method closed chain
systems. Donald, B. R., Lynch, K. M., & Rus, D. (Eds.), Algorithmic Computational
Robotics: New Directions, pp. 233246. AK Peters, MA.
Harvey, M. J., Giupponi, G., & de Fabritiis, G. (2009). ACEMD: Accelerating biomolecular dynamics microsecond timescale. J Comput Theor Chem, 5(6), 16321639.
Haspel, N., Moll, M., Baker, M. L., Chiu, W., & E., K. L. (2010). Tracing conformational changes
proteins. BMC Struct Biol, 10(Suppl1), S1.
Haspel, N., Tsai, C., Wolfson, H., & Nussinov, R. (2003). Reducing computational complexity
protein folding via fragment folding assembly. Protein Sci, 12(6), 11771187.
Hastings, W. K. (1970). Monte Carlo sampling methods using Markov chains applications.
Biometrika, 57(1), 97109.
Hermans, J., Berendsen, H. J. C., van Gunsteren, W. F., & Postma, J. P. M. (1984). consistent
empirical potential water-protein interactions. Biopolymers, 23(8), 15131518.
Hoang, T. H., Trovato, A., Seno, F., Banavar, J. R., & Maritan, A. (2007). Geometry symmetry
presculpt free-energy landscape proteins. Proc Natl Acad Sci USA, 101(21), 7960
7964.
Hoard, B., Jacobson, B., Manavi, K., & Tapia, L. (2016). Extending rule-based methods model
molecular geometry 3d model resolution. BMC Syst Biol, 10(Suppl 2), 48.
Hoelder, S., Clarke, P. A., & Workman, P. (2012). Discovery small molecule cancer drugs:
Successes, challenges opportunities. Mol Oncol, 6(2), 522524.
Hohlbein, J., Craggs, T. D., & Cordes, T. (2014). Alternating-laser excitation: single-molecule
FRET beyond. Chem Soc Rev, 43(4), 11561171.
Hori, N., Chikenji, G., & Takada, S. (2009). Folding energy landscape network dynamics
small globular proteins. Proc Natl Acad Sci USA, 106(1), 7378.
Hornak, V., Abel, R., Okur, A., Strockbine, B., Roitberg, A., & Simmerling, C. (2006). Comparison
multiple amber force fields development improved protein backbone parameters.
Proteins: Struct Funct Bioinf, 65(3), 712725.
Hsu, D., Kindel, R., Latombe, J.-C., & Rock, S. (2002). Randomized kinodynamic motion planning
moving obstacles. Intl J Robot Res, 21(3), 233255.
Hsu, D., Sanchez-Ante, G., & Sun, Z. (2005). Hybrid PRM sampling cost-sensitive adaptive
strategy. Intl Conf Robot Autom (ICRA), pp. 38853891, Barcelona, Spain.
Humphrey, W., Dalke, A., & Schulten, K. (1996). VMD - Visual Molecular Dynamics. J Mol Graph
Model, 14(1), 3338. http://www.ks.uiuc.edu/Research/vmd/.
Jaillet, L., Corcho, F. J., Perez, J.-J., & Cortes, J. (2011). Randomized tree construction algorithm
explore energy landscapes. J Comput Chem, 32(16), 34643474.
561

fiS HEHU & P LAKU

Jaillet, L., Cortes, J., & Simeon, T. (2008). Transition-based RRT path planning continuous
cost spaces. Intl Conf Intell Robot Sys (IROS), pp. 2226, Stanford, CA. IEEE/RSJ.
Jaillet, L., Yershova, A., LaValle, S. M., & Simeon, T. (2005). Adaptive tuning sampling
domain dynamic-domain RRTs. Intl Conf Intell Robot Sys (IROS), pp. 40864091.
IEEE/RSJ.
Jayachandran, G., Vishal, V., & Pande, V. S. (2006). Using massively parallel simulation Markovian models study protein folding: examining dynamics villin headpiece. J Chem
Phys, 124(16), 164902164914.
Jenzler-Wildman, K., & Kern, D. (2007). Dynamic personalities proteins. Nature, 450(7172),
964972.
Jorgensen, W. L., Maxwell, D. S., & Tirado-Reves, J. (1988). Development testing OPLS
all-atom force field conformational energetics properties organic liquids. J Amer
Chem Soc, 118(45), 1122511236.
Kalisiak, M., & van de Panne, M. (2006). RRT-blossom: RRT local flood-fill behavior.
Intl Conf Robot Autom (ICRA), pp. 12371242, Orlando, FL. IEEE.
Kamerlin, S. C., Haranczyk, M., & Warshel, A. (2009). Progresses ab initio QM/MM free energy
simulations electrostatic energies proteins: Accelerated QM/MM studies pka, redox
reactions solvation free energies. J Phys Chem B, 113(5), 12531272.
Karam, P., Powdrill, M. H., Liu, H. W., Vasquez, C., Mah, W., Bernatchez, J., Gotte, M., & Cosa,
G. (2014). Dynamics hepatitis C virus (HCV) RNA-dependent RNA polymerase NS5B
complex RNA. J Biol Chem, 289(20), 1439914411.
Karaman, S., & Frazzoli, E. (2011). Sampling-based algorithms optimal motion planning. Intl
J Robot Res, 30(7), 846894.
Karnoub, A. E., & Weinberg, R. A. (2008). Ras oncogenes: split personalities. Nat Rev Mol Cell
Biol, 9(7), 517531.
Kavraki, L. E., Svestka, P., Latombe, J. C., & Overmars, M. H. (1996). Probabilistic roadmaps
path planning high-dimensional configuration spaces. IEEE Trans Robot Automat, 12(4),
566580.
Kay, L. E. (1998). Protein dynamics NMR. Nat Struct Biol, 5(2-3), 513517.
Kay, L. E. (2005). NMR studies protein structure dynamics. J Magn Reson, 173(2), 193207.
Kendrew, J. C., Bodo, G., Dintzis, H. M., Parrish, R. G., Wyckoff, H., & Phillips, D. C. (1958).
three-dimensional model myoglobin molecule obtained X-ray analysis. Nature,
181(4610), 662666.
Kendrew, J. C., Dickerson, R. E., Strandberg, B. E., Hart, R. G., Davies, D. R., Phillips, D. C., &
Shore, V. C. (1960). Structure myoglobin: three-dimensional Fourier synthesis 2A
resolution. Nature, 185(4711), 422427.
Khaliullin, R. Z., VandeVondele, J., & Hutter, J. (2013). Efficient linear-scaling density functional
theory molecular systems. J Chem Theory Comput, 9(10), 44214427.
Kiesel, S., Burns, E., & Ruml, W. (2012). Abstraction-guided sampling motion planning.
Symp Combinat Search (SOCS), pp. 162163, Niagara Falls, Canada.
562

fiC OMPUTATIONAL REATMENTS B IOMOLECULES ROBOTICS -I NSPIRED ETHODS

Kim, K. M., Jernigan, R. L., & Chirikjian, G. S. (2002a). Efficient generation feasible pathways
protein conformational transitions. Biophys J, 83(3), 16201630.
Kim, M. K., Chirikjian, G. S., & Jernigan, R. L. (2002b). Elastic models conformational transitions macromolecules. J Mol Graph Model, 21(2), 151160.
Kirillova, S., Cortes, J., Stefaniu, A., & Simeon, T. (2008). NMA-guided path planning approach
computing large-amplitude conformational changes proteins. Proteins: Struct Funct
Bioinf, 70(1), 131143.
Kolodny, R., Guibas, L., Levitt, M., & Koehl, P. (2005). Inverse kinematics biology: protein
loop closure problem. Intl J Robot Res, 24(2-3), 151163.
Ladd, A. M., & Kavraki, L. E. (2004). Fast tree-based exploration state space robots dynamics. Workshop Algorithm Found Robot, pp. 297312. Springer, Utrecht/Zeist, Netherlands.
Ladd, A. M., & Kavraki, L. E. (2005). Motion planning presence drift, underactuation
discrete system changes. Robot: Sci Sys, pp. 233241, Boston, MA.
LaValle, S. M., & Kuffner, J. J. (2001). Randomized kinodynamic planning. Intl J Robot Res, 20(5),
378400.
Leaver-Fay, A., Tyka, M., Lewis, S. M., Lange, O. F., Thompson, J., Jacak, R., Kaufman, K., Renfrew, P. D., Smith, C. A., Sheffler, W., Davis, I. W., Cooper, S., Treuille, A., Mandell, D. J.,
Richter, F., Ban, Y. E., Fleishman, S. J., Corn, J. E., Kim, D. E., Lyskov, S., Berrondo, M.,
Mentzer, S., Popovi, Z., & et. al. (2011). ROSETTA3: object-oriented software suite
simulation design macromolecules. Methods Enzymol, 487, 545574.
Lee, A., Streinu, I., & Brock, O. (2005). methodology efficiently sampling conformation
space molecular structures. J Phys Biol, 2(4), 108S115.
Lee, H. M., M., K. S., Kim, H. M., & Suh, Y. D. (2013). Single-molecule surface-enhanced Raman
spectroscopy: perspective current status. Phys Chem Chem Phys, 15, 52765287.
Lee, J., Kwon, O., Zhang, L., & Yoon, S.-E. (2014). selective retraction-based RRT planner
various environments. IEEE Trans Robotics, 30(4), 10021011.
Levitt, M., & Lifson, S. (1969). Refinement protein conformations using macromolecular
energy minimization procedure. J Mol Biol, 46(2), 269279.
Levitt, M., & Warshel, A. (1975). Computer simulation protein folding. Nature, 253(5494),
9496.
Levy, Y., Jortner, J., & Becker, O. M. (2001). Solvent effects energy landscapes folding
kinetics polyalanine. Proc Natl Acad Sci USA, 98(5), 21882193.
Li, D., Yang, H., Han, L., & Huo, S. (2008). Predicting folding pathway engrailed homeodomain probabilistic roadmap enhanced reaction-path algorithm. Biophys J, 94(5),
16221629.
Lifson, S., & Warshel, A. (1968). consistent force field calculation conformations, vibrational spectra enthalpies cycloalkanes n-alkane molecules. J Phys Chem, 49,
51165129.
563

fiS HEHU & P LAKU

Lin, T., & Song, G. (2011). Efficient mapping ligand migration channel networks dynamic
proteins. Proteins: Struct Funct Bioinf, 79(8), 24752490.
Lindorff-Larsen, K., Piana, S., Dror, R. O., & Shaw, D. E. (2011). fast-folding proteins fold.
Science, 334(6055), 517520.
Lois, G., Blawzdziewicz, J., & OHern, C. S. (2010). Protein folding rugged energy landscapes:
Conformational diffusion fractal networks. Phys Rev E Stat Nonlin Soft Matter Phys, 81(5
Pt 1), 051907.
Lotan, I., van den Bedem, H., Deacon, A. M., & Latombe, J.-C. (2004). Computing protein structures electron density maps: mising loop problem. Erdman, M., Hsu, D., Overmars, M., & van der Stappen, F. (Eds.), Algorithmic Foundations Robotics VI, pp. 153168.
Springer STAR Series.
Ma, B., Kumar, S., Tsai, C., & Nussinov, R. (1999). Folding funnels binding mechanisms.
Protein Eng, 12(9), 713720.
Ma, J., & Karplus, M. (1997). Molecular switch signal transduction: reaction paths conformational changes ras p21. Proc Natl Acad Sci USA, 94(22), 1190511910.
Maisuradze, G. G., Liwo, A., & Scheraga, H. A. (2009). Principal component analysis protein
folding dynamics. J Mol Biol, 385(1), 312329.
Malmstrom, R. D., Lee, C. T., Van Wart, A. T., & Amaro, R. E. (2014). Application moleculardynamics based Markov state models functional proteins. J Chem Theory Comput, 10(7),
26482657.
Manocha, D., & Canny, J. (1994). Efficient inverse kinematics general 6r manipulator. IEEE
Trans Robot Autom, 10(5), 648657.
Manocha, D., & Zhu, Y. (1994). Kinematic manipulation molecular chains subject rigid constraints. Altman, R. B., Brutlag, D. L., Karp, P. D., Lathrop, R. H., & Searls, D. B. (Eds.),
Intl Conf Intell Sys Mol Biol (ISMB), Vol. 2, pp. 285293, Stanford, CA. AAAI.
Manocha, D., Zhu, Y., & Wright, W. (1995). Conformational analysis molecular chains using
nano-kinematics. Comput. Appl. Biosci., 11(1), 7186.
Maragakis, P., & Karplus, M. (2005). Large amplitude conformational change proteins explored
plastic network model: adenylate kinase. J Mol Biol, 352(4), 807822.
Matysiak, S., & Clementi, C. (2004). Optimal combination theory experiment characterization protein folding landscape S6: far minimalist model go?. J
Mol Biol, 343(8), 235248.
Matysiak, S., & Clementi, C. (2006). Minimalist protein model diagnostic tool misfolding
aggregation. J Mol Biol, 363(1), 297308.
Maximova, T., Moffatt, R., Ma, B., Nussinov, R., & Shehu, A. (2016). Principles overview
sampling methods modeling macromolecular structure dynamics. PLoS Comput Biol,
12(4), e1004619.
Maximova, T., Plaku, E., & Shehu, A. (2015). Computing transition paths multiple-basin proteins
probabilistic roadmap algorithm guided structure data. Intl Conf Bioinf
Biomed (BIBM), pp. 3542, Washington, D.C. IEEE.
564

fiC OMPUTATIONAL REATMENTS B IOMOLECULES ROBOTICS -I NSPIRED ETHODS

McCammon, J. A., Gelin, B. R., & Karplus, M. (1977). Dynamics folded proteins. Nature,
267(5612), 585590.
McLachlan, A. D. (1972). mathematical procedure superimposing atomic coordinates
proteins. Acta Crystallogr A, 26(6), 656657.
McMahon, T., Thomas, S., & Amato, N. M. (2015). Reachable volume RRT. Intl Conf Robot
Autom (ICRA), pp. 29772984, Seattle, WA. IEEE.
Metropolis, N., Rosenbluth, A. W., Rosenbluth, M. N., Teller, A. H., & Teller, E. (1953). Equation
state calculations fast computing machines. J Chem Phys, 21(6), 10871092.
Miao, Y., Sinko, W., Pierce, L., Bucher, D., Walker, R. C., & McCammon, J. A. (2014). Improved
reweighting accelerated molecular dynamics simulations free energy calculation. J
Chem Theory Comput, 10(7), 26772689.
Michalet, X., Weiss, S., & Jager, M. (2006). Single-molecule fluorescence studies protein folding
conformational dynamics. Chem Rev, 106(5), 17851813.
Moerner, W. E., & Fromm, D. P. (2003). Methods single-molecule fluorescence spectroscopy.
Rev Scientific Instruments, 74(8), 35973619.
Moffat, K. (2003). frontiers time-resolved macromolecular crystallography: movies
chirped X-ray pulses. Faraday Discuss, 122(79-88), 6577.
Moll, M., Schwartz, D., & Kavraki, L. E. (2008). Roadmap methods protein folding. Zaki,
M., & Bystroff, C. (Eds.), Protein Structure Prediction, Vol. 413 Methods Mol Biol, pp.
219239. Springer.
Molloy, K., Clausen, R., & Shehu, A. (2016). stochastic roadmap method model protein
structural transitions. Robotica, 34(8), 17051733.
Molloy, K., Saleh, S., & Shehu, A. (2013). Probabilistic search energy guidance biased
decoy sampling ab-initio protein structure prediction. IEEE/ACM Trans Bioinf Comp
Biol, 10(5), 11621175.
Molloy, K., & Shehu, A. (2013). Elucidating ensemble functionally-relevant transitions
protein systems robotics-inspired method. BMC Struct Biol, 13(Suppl 1), S8.
Molloy, K., & Shehu, A. (2015). Interleaving global local search protein motion computation. Harrison, R., Li, Y., & Mandoiu, I. (Eds.), LNCS: Bioinformatics Research
Applications, Vol. 9096, pp. 175186, Norfolk, VA. Springer International Publishing.
Molloy, K., & Shehu, A. (2016). general, adaptive, roadmap-based algorithm protein motion
computation. IEEE Trans. NanoBioSci., 2(15), 158165.
Mukherjee, S., & Warshel, A. (2011). Electrostatic origin mechanochemical rotary mechanism catalytic dwell F1-ATPase. Proc Natl Acad Sci USA, 108(51), 2055020555.
Mukherjee, S., & Warshel, A. (2012). Realistic simulations coupling protomotive
force mechanical rotation F0-ATPase. Proc Natl Acad Sci USA, 109(3), 14876
14881.
Mukherjee, S., & Warshel, A. (2013). Electrostatic origin unidirectionality walking myosin
v motors. Proc Natl Acad Sci USA, 110(43), 1732617331.
565

fiS HEHU & P LAKU

Na, H., & Song, G. (2015). Quantitative delineation breathing motions open ligand migration
channels myoglobin mutants. Proteins: Struct Funct Bioinf, 83(4), 757770.
Neudecker, P., Robustelli, P., Cavalli, A., Walsh, P., Lundstrm, P., Zarrine-Afsar, A., Sharpe, S.,
Vendruscolo, M., & Kay, L. E. (2012). Structure intermediate state protein folding
aggregation. Science, 336(6079), 362366.
Nevo, R., Brumfeld, V., Kapon, R., Hinterdorfer, P., & Reich, Z. (2005). Direct measurement
protein energy landscape roughness. EMBO Rep, 6(5), 482486.
Nielsen, C. L., & Kavraki, L. E. (2000). two level fuzzy PRM manipulation planning. Intl
Conf Intell Robot Sys (IROS), Vol. 3, pp. 17161721, Takamatsu, Japan. IEEE/RSJ.
Noe, F., Doose, S., Daidone, I., Lollmann, M., Sauer, M., Chodera, J. D., & Smith, J. C. (2011).
Dynamical fingerprints probing individual relaxation processes biomolecular dynamics
simulations kinetic experiments. Proc Natl Acad Sci USA, 108(12), 48224827.
Noe, F., & Fischer, S. (2008). Transition networks modeling kinetics conformational
change macromolecules. Curr Opinion Struct Biol, 18(2), 154162.
Olson, B., Hashmi, I., Molloy, K., & Shehu, A. (2012). Basin hopping general versatile
optimization framework characterization biological macromolecules. Advances
AI J, 2012(674832).
Olson, B., & Shehu, A. (2012). Evolutionary-inspired probabilistic search enhancing sampling
local minima protein energy surface. Proteome Sci, 10(Suppl 1), S5.
Olson, B. S., Molloy, K., Hendi, S.-F., & Shehu, A. (2012). Guiding search protein conformational space structural profiles. J Bioinf & Comput Biol, 10(3), 1242005.
Onuchic, J. N., Luthey-Schulten, Z., & Wolynes, P. G. (1997). Theory protein folding: energy
landscape perspective. Annu Rev Phys Chem, 48, 545600.
Onuchic, J. N., & Wolynes, P. G. (2004). Theory protein folding. Curr Opinion Struct Biol, 14,
7075.
Ovchinnikov, V., & Karplus, M. (2012). Analysis elimination bias targeted molecular
dynamics simulations conformational transitions: Application calmodulin. J Phys Chem
B, 116(29), 85848603.
Ozenne, V., Schneider, R., Yao, M., Huang, J. R., Salmon, L., Zweckstetter, M., Jensen, M. R., &
Blackledge, M. (2012). Mapping potential energy landscape intrinsically disordered
proteins amino acid resolution. J Amer Chem Soc, 134(36), 1513815148.
Ozkan, S. B., Dill, K. A., & Bahar, I. (2002). Fast-folding protein kinetics, hidden intermediates,
sequential stabilization model. Protein Sci, 11(8), 19581970.
Palmieri, L., & Arras, K. O. (2015). Distance metric learning RRT-based motion planning
constant-time inference. Intl Conf Robot Autom (ICRA), pp. 637643, Seattle, WA. IEEE.
Pande, V. S., Beachamp, K., & Bowman, G. R. (2010). Everything wanted know
Markov state models afraid ask. Nat Methods, 52(1), 99105.
Papoian, G. A., Ulander, J., Eastwood, M. P., Luthey-Schulten, Z., & Wolynes, P. G. (2004). Water
protein structure prediction. Proc Natl Acad Sci USA, 101(10), 33523357.
566

fiC OMPUTATIONAL REATMENTS B IOMOLECULES ROBOTICS -I NSPIRED ETHODS

Perez-Hernandez, G., Paul, F., Giorgino, T., De Fabritiis, G., & Noe, F. (2013). Identification slow
molecular order parameters markov model construction. J Chem Phys, 139(1), 015102.
Perilla, J. R., Goh, B. C., Cassidy, C. K., Liu, B., Bernardi, R. C., Rudack, T., Yu, H., Wu, Z., &
Schulten, K. (2015). Molecular dynamics simulations large macromolecular complexes.
Curr Opin Struct Biol, 31, 6474.
Phillips, D. C. (1967). hen egg-white lysozyme molecule. Proc Natl Acad Sci USA, 57(3),
483495.
Phillips, J. C., Braun, R., Wang, W., Gumbart, J., Tajkhorshid, E., Villa, E., Chipot, C., Skeel, R. D.,
Kale, L., & Schulten, K. (2005). Scalable molecular dynamics NAMD. J Comput Chem,
26(16), 17811802.
Piana, S., Lindorff-Larsen, K., Dirks, R. M., Salmon, J. K., Dror, R. O., & Shaw, D. E. (2012a).
Evaluating effects cutoffs treatment long-range electrostatics protein folding
simulations. PLoS ONE, 7(6), e39918.
Piana, S., Lindorff-Larsen, K., & Shaw, D. E. (2012b). Protein folding kinetics thermodynamics
atomistic simulation. Proc Natl Acad Sci USA, 109(44), 1784517850.
Plaku, E. (2015). Region-guided sampling-based tree search motion planning dynamics. IEEE Transactions Robotics, 31(3), 723735.
Plaku, E., Stamati, H., Clementi, C., & Kavraki, L. E. (2007). Fast reliable analysis molecular motions using proximity relations dimensionality reduction. Proteins: Struct Funct
Bioinf, 67(4), 897907.
Plaku, E., Kavraki, L. E., & Vardi, M. Y. (2010). Motion planning dynamics synergistic
combination layers planning. IEEE Transactions Robotics, 26(3), 469482.
Ponder, J. W., & Case, D. A. (2003). Force fields protein simulations. Adv Protein Chem, 66,
2785.
Porta, J. M., & Jaillet, L. (2013). Exploring energy landscapes flexible molecular loops using
higher-dimensional continuation. J Comput Chem, 34(3), 234244.
Porta, J. M., Thomas, F., Corcho, F., Canto, J., & Perez, J. J. (2007). Complete maps molecularloop conformation spaces. J Comput Chem, 28(13), 21702189.
Prinz, J. H., Keller, B., & Noe, F. (2011a). Probing molecular kinetics Markov models:
metastable states, transition pathways spectroscopic observables. Phys Chem Chem Phys,
13(38), 1691216927.
Prinz, J. H., Wu, H., Sarich, M., Keller, B., Senne, M., Held, M., Chodera, J. D., Schutte, C., & Noe,
F. (2011b). Markov models molecular kinetics: generation validation. J Chem Phys,
134(17), 174105.
Proctor, A. J., Lipscomb, T. J., Zou, A., Anderson, J. A., & Cho, S. S. (2012). Performance analyses
parallel verlet neighbor list algorithm GPU-optimized MD simulations. ASE/IEEE
Intl Conf Biomed Comput (BioMedCom), pp. 1419, Alexandria, VA. IEEE.
Ramachandran, G. N., Ramakrishnan, C., & Sasisekharan, V. (1963). Stereochemistry polypeptide chain configurations. J Mol Biol, 7, 9599.
567

fiS HEHU & P LAKU

Raveh, B., Enosh, A., Furman-Schueler, O., & Halperin, D. (2009). Rapid sampling molecular
motions prior information constraints,. PLoS Comput Biol, 5(2), e1000295.
Rodriguez, S., Thomas, S., Pearce, R., & Amato, N. (2006a). RESAMPL: Region-Sensitive
Adaptive Motion Planner. Workshop Algorithm Found Robot, Vol. 47 Springer Tracts
Advanced Robotics, pp. 285300. Springer, New York, NY.
Rodriguez, S., Tang, X., Lien, J.-M., & Amato, N. M. (2006b). obstacle-based rapidly-exploring
random tree. Intl Conf Robot Autom (ICRA), pp. 895900, Orlando, FL. IEEE.
Rohrdanz, M. A., Zheng, W., Maggioni, M., & Clementi, C. (2011). Determination reaction
coordinates via locally scaled diffusion map. J Chem Phys, 134(12), 124116.
Rose, G. D., Fleming, P. J., Banavar, J. R., & Maritan, A. (2006). backbone-based theory
protein folding. Proc Natl Acad Sci USA, 103(45), 1662316633.
Roweis, S. T., & Saul, L. K. (2000). Nonlinear dimensionality reduction locally linear embedding. Science, 290(5500), 23232326.
Roy, R., Hohng, S., & Ha, T. (2008). practical guide single-molecule FRET. Nat Methods,
5(6), 507516.
Rychkova, A., Mukherjee, S., Bora, R. P., & Warshel, A. (2013). Simulating pulling stalled
elongated peptide ribosome translocon. Proc Natl Acad Sci USA, 110(25),
1019510200.
Sanchez, G., & Latombe, J.-C. (2002). delaying collision checking PRM planning: Application multi-robot coordination. Intl J Robot Res, 21(1), 526.
Sapin, E., Carr, D. B., De Jong, K. A., & Shehu, A. (2016). Computing energy landscape maps
structural excursions proteins. BMC Genomics, 17(Suppl 4), 456.
Schlau-Cohen, G. S., Wang, Q., Southall, J., Cogdell, R. J., & Moerner, W. E. (2013). Singlemolecule spectroscopy reveals photosynthetic LH2 complexes switch emissive
states. Proc Natl Acad Sci USA, 110(27), 1089910903.
Schotte, F., Lim, M., Jackson, T. A., Smirnov, A. V., Soman, J., Olson, J. S., Phillips, G. N., Wulff,
M., & Anfinrud, P. A. (2003). Watching protein functions 150-ps time-resolved
X-ray crystallography. Science, 300(5627), 19441947.
Schuyler, A. d., Jernigan, R. L., Wasba, P. K., Ramakrishnan, B., & Chirikjian, G. S. (2009). Iterative
cluster-NMA (icnma): tool generating conformational transitions proteins. Proteins:
Struct Funct Bioinf, 74(3), 760776.
Shatsky, M., Nussinov, R., & Wolfson, H. J. (2002). Flexible protein alignment hinge detection.
Proteins, 48(2), 242256.
Shaw, D. E., Maragakis, P., Lindorff-Larsen, K., Piana, S., Dror, R. O., Eastwood, M. P., Bank, J. A.,
Jumper, J. M., Salmon, J. K., Shan, Y., & Wriggers, W. (2010). Atomic-level characterization
structural dynamics proteins. Science, 330(6002), 341346.
Shehu, A. (2009). ab-initio tree-based exploration enhance sampling low-energy protein
conformations. Robot: Sci Sys, pp. 241248, Seattle, WA, USA.
Shehu, A. (2013). Probabilistic search optimization protein energy landscapes. Aluru, S.,
& Singh, A. (Eds.), Handbook Computational Molecular Biology. Chapman & Hall/CRC
Computer & Information Science Series.
568

fiC OMPUTATIONAL REATMENTS B IOMOLECULES ROBOTICS -I NSPIRED ETHODS

Shehu, A., Clementi, C., & Kavraki, L. E. (2006). Modeling protein conformational ensembles:
missing loops equilibrium fluctuations. Proteins: Struct Funct Bioinf, 65(1), 164
179.
Shehu, A., Clementi, C., & Kavraki, L. E. (2007). Sampling conformation space model equilibrium fluctuations proteins. Algorithmica, 48(4), 303327.
Shehu, A., & Kavraki, L. E. (2012). Modeling structures motions loops protein molecules.
Entropy J, 14(2), 252290.
Shehu, A., Kavraki, L. E., & Clementi, C. (2007). characterization protein native state
ensembles. Biophys J, 92(5), 15031511.
Shehu, A., Kavraki, L. E., & Clementi, C. (2008). Unfolding fold cyclic cysteine-rich peptides. Protein Sci, 17(3), 482493.
Shehu, A., Kavraki, L. E., & Clementi, C. (2009). Multiscale characterization protein conformational ensembles. Proteins: Struct Funct Bioinf, 76(4), 837851.
Shehu, A., & Olson, B. (2010). Guiding search native-like protein conformations
ab-initio tree-based exploration. Intl J Robot Res, 29(8), 110611227.
Shkolnik, A., Walter, M., & Tedrake, R. (2009). Reachability-guided sampling planning
differential constraints. Intl Conf Robot Autom (ICRA), pp. 28592865.
Shlens,
J.
(2003).

tutorial

principal
component
https://www.cs.princeton.edu/picasso/mats/PCA-Tutorial-Intuition jp.pdf.

analysis.

Shukla, D., Hernandez, C. X., Weber, J. K., & Pande, V. S. (2015). Markov state models provide
insights dynamic modulation protein function. Acc Chem Res, 48(2), 414422.
Singh, A. P., Latombe, J.-C., & Brutlag, D. L. (1999). motion planning approach flexible ligand
binding. Schneider, R., Bork, P., Brutlag, D. L., Glasgow, J. I., Mewes, H.-W., & Zimmer,
R. (Eds.), Intl Conf Intell Sys Mol Biol (ISMB), Vol. 7, pp. 252261, Heidelberg, Germany.
AAAI.
Singhal, N., & Pande, V. S. (2005). Error analysis efficient sampling markovian state models
molecular dynamics. J Chem Phys, 123(20), 204909120490913.
Singhal, N., Snow, C. D., & Pande, V. S. (2004). Using path sampling build better markovian
state models: Predicting folding rate mechanism tryptophan zipper beta hairpin.
J Chem Phys, 121(1), 415425.
Socher, E., & Imperiali, B. (2013). FRET-CAPTURE: sensitive method detection
dynamic protein interactions. Chem Biochem, 14(1), 5357.
Song, G., & Amato, N. M. (2000). motion-planning approach folding: paper craft
protein folding. Tech. rep. TR00-001, Department Computer Science, Texas & University.
Song, G., & Amato, N. M. (2004). motion planning approach folding: paper craft
protein folding. IEEE Trans Robot Autom, 20(1), 6071.
Song, J., & Zhuang, W. (2014). Simulating peptide folding kinetic related spectra based
Markov state model. Protein Conformational Dynamics, Vol. 805 Adv Exp Med Biol,
pp. 199220. Springer.
569

fiS HEHU & P LAKU

Soto, C. (2008). Protein misfolding neurodegeneration. JAMA Neurology, 65(2), 184189.
Stadler, P. (2002). Fitness landscapes. Appl Math & Comput, 117, 187207.
Stone, J. E., Phillips, J. C., Freddolino, P. L., Hardy, D. J., Trabuco, L. G., & Schulten, K. (2007).
Accelerating molecular modeling applications graphics processors. J Comput Chem,
28(16), 26182640.
Sucan, I. A., & Kavraki, L. E. (2012). sampling-based tree planner systems complex
dynamics. IEEE Trans Robotics, 28(1), 116131.
Sun, Z., Hsu, D., Jiang, T., Kurniawati, H., & Reif, J. (2005). Narrow passage sampling probabilistic roadmap planners. IEEE Trans Robotics, 21(6), 11051115.
Tama, F., & Sanejouand, Y. H. (2001). Conformational change proteins arising normal
mode calculations. Protein Eng, 14(1), 16.
Tama, F., Valle, M., Frank, J., & Brooks, C. L. (2003). Dynamic reorganization functionally
active ribosome explored normal mode analysis cryo-electron microscopy. Proc Natl
Acad Sci USA, 100(16), 93199323.
Tang, X., Kirkpatrick, B., Thomas, S., Song, G., & Amato, N. (2005). Using motion planning
study rna folding kinetics. J Comput Biol, 12(6), 862881.
Tang, X., Thomas, S., Tapia, L., Giedroc, D. P., & Amato, N. (2008). Simulating rna folding kinetics
approximated energy landscapes. J Mol Biol, 381(4), 10551067.
Tanner, D. E., Phillips, J. C., & Schulten, K. (2012). GPU/CPU algorithm generalized
born/solvent-accessible surface area implicit solvent calculations. J Chem Theory Comput,
8(7), 25212530.
Tapia, L., Tang, X., Thomas, S., & Amato, N. (2007). Kinetics analysis methods approximate
folding landscapes. Bioinformatics, 23, i539i548.
Tapia, L., Thomas, S., & Amato, N. (2010). motion planning approach studying molecular
motions. Commun Inf Sys, 10(1), 5368.
Teknipar, M., & Zheng, W. (2010). Predicting order conformational changes protein
conformational transitions using interpolated elastic network model. Proteins: Struct Funct
Bioinf, 78(11), 24692481.
Tenenbaum, J. B., de Silva, V., & Langford, J. C. (2000). global geometric framework nonlinear dimensionality reduction. Science, 290(5500), 23192323.
Teodoro, M., Phillips, G. N. J., & Kavraki, L. E. (2003). Understanding protein flexibility
dimensionality reduction. J Comput Biol, 10(3-4), 617634.
Thomas, S., Song, G., & Amato, N. M. (2005). Protein folding motion planning. J. Phys. Biol.,
2(4), 148.
Thomas, S., Tang, X., Tapia, L., & Amato, N. M. (2007). Simulating protein motions rigidity
analysis. J. Comput. Biol., 14(6), 839855.
Thorpe, M. F., & Ming, L. (2004). Macromolecular flexibility. Phil. Mag., 84(13-16), 132331137.
Torella, J. P., Holden, S. J., Santoso, Y., Hohlbein, J., & Kapanidis, A. N. (2011). Identifying molecular dynamics single-molecule FRET experiments burst variance analysis. Biophys J,
100(6), 15681577.
570

fiC OMPUTATIONAL REATMENTS B IOMOLECULES ROBOTICS -I NSPIRED ETHODS

Tsai, C., Kumar, S., Ma, B., & Nussinov, R. (1999a). Folding funnels, binding funnels, protein
function. Protein Sci, 8(6), 11811190.
Tsai, C., Ma, B., & Nussinov, R. (1999b). Folding binding cascades: shifts energy landscapes.
Proc Natl Acad Sci USA, 96(18), 99709972.
Uversky, V. N. (2009). Intrinsic disorder proteins associated neurodegenerative diseases.
Protein Folding Misfolding: Neurodegenerative Diseases, Vol. 14 Focus Structural
Biology, pp. 51885238. Springer.
van den Bedem, H., Lotan, I., Latombe, J.-C., & Deacon, A. M. (2005). Real-space protein-model
completion: inverse-kinematics approach. Acta Crystallogr, D61(1), 213.
van der Maaten, L. J. P., Postma, E. O., & van den Herik, H. J. (2009). Dimensionality reduction:
comparative review. J Mach Learn Res, 10(1-41), 6671.
Van Der Spoel, D., Lindahl, E., Hess, B., Groenhof, G., Mark, A. E., & Berendsen, H. J. (2005).
GROMACS: fast, flexible, free. J Comput Chem, 26(16), 17011718.
van Gunsteren, W. F., Billeter, S. R., Eising, A. A., Hunenberger, P. H., Kruger, P., Mark, A. E.,
Scott, W. R. P., & Tironi, I. G. (1996). Biomolecular simulation: gromos96 manual
user guide. http://www.gromos.net/.
Verlet, L. (1967). Computer experiments classical fluids. i. thermodynamical properties
Lennard-Jones molecules. Phys Rev Lett, 159, 98103.
Warshel, A. (2003). Computer simulations enzyme catalysis: Methods, progress, insights.
Annu Rev Biophys Biomol Struct, 32, 425443.
Warshel, A., & Levitt, M. (1976). Theoretical studies enzymatic reactions: Dielectric, electrostatic steric stabilization carbonium ion reaction lysozyme. J Mol Biol,
103(2), 227249.
Weber, J. K., Jack, R. L., & Pande, V. S. (2013). Emergence glass-like behavior markov state
models protein folding dynamics. J Amer Chem Soc, 135(15), 55015504.
Wells, S., Menor, S., Hespenheide, B., & Thorpe, M. F. (2005). Constrained geometric simulation
diffusive motion proteins. J Phys Biol, 2(4), 127136.
Xu, D., & Zhang, Y. (2012). Ab initio protein structure assembly using continuous structure fragments optimized knowledge-based force field. Proteins: Struct Funct Bioinf, 80(7), 1715
1735.
Yang, H., Wu, H., Li, D., Han, L., & Huo, S. (2007). Temperature-dependent probabilistic roadmap
algorithm calculating variationally optimized conformational transition pathways. J Chem
Theory Comput, 3(1), 1725.
Yang, L., Song, G., Carriquiry, A., & Jernigan, R. L. (2008). Close correspondence essential protein motions principal component analysis multiple HIV-1 protease structures elastic network modes. Structure, 16(2), 321330.
Yang, Z., Majek, P., & Bahar, I. (2009). Allosteric transitions supramolecular systems explored
network models: Application chaperonin GroEL. PLoS Comput Biol, 5(4), e1000360.
Yao, P., Dhanik, A., Marz, N., Propper, R., Kou, C., Liu, G., van den Bedem, H., Latombe, J. C.,
Halperin-Landsberg, I., & Altman, R. B. (2008). Efficient algorithms explore conformation
spaces flexible protein loops. IEEE/ACM Trans Comput Biol Bioinf, 5(4), 534545.
571

fiS HEHU & P LAKU

Zagrovic, B., Snow, C. D., Shirts, M. R., & Pande, V. S. (2002). Simulation folding small
alpha-helical protein atomistic detail using worldwide-distributed computing. J Mol Biol,
323(5), 927937.
Zhang, M., & Kavraki, L. E. (2002a). Finding solutions inverse kinematics problem
computer-aided drug design. Florea, L., Walenz, B., & Hannenhalli, S. (Eds.), Currents
Computational Molecular Biology, pp. 214215, Washington, D.C. ACM.
Zhang, M., & Kavraki, L. E. (2002b). new method fast accurate derivation molecular
conformations. Chem Inf Comput Sci, 42(1), 6470.
Zhao, G., Perilla, J. R., Yufenyuy, E. L., Meng, X., Chen, B., Ning, J., Ahn, J., Gronenborn, A. M.,
Schulten, K., Aiken, C., & Zhang, P. (2013). Mature HIV-1 capsid structure cryo-electron
microscopy all-atom molecular dynamics. Nature, 497(7451), 643646.
Zheng, W., & Brooks, B. (2005). Identification dynamical correlations within myosin motor
domain normal mode analysis elastic network model. J Mol Biol, 346(3), 745
759.
Zheng, W., Brooks, B. R., & Hummer, G. (2007). Protein conformational transitions explored
mixed elastic network models. Proteins: Struct Funct Bioinf, 69(1), 4357.
Zheng, W., & Doniach, S. (2003). comparative study motor-protein motions using simple
elastic-network model. Proc Natl Acad Sci USA, 100(23), 1325313258.
Zheng, W., Rohrdanz, M. A., & Clementi, C. (2013). Rapid exploration configuration space
diffusion-map-directed molecular dynamics. J Phys Chem B, 117(42), 1276912776.
Zheng, W., Rohrdanz, M. A., Maggioni, M., & Clementi, C. (2011). Polymer reversal rate calculated
via locally scaled diffusion map. J Chem Phys, 134(14), 144109.
Zhou, H. (2014). Theoretical frameworks multiscale modeling simulation. Curr Opinion
Struct Biol, 25, 6776.

572

fiJournal Artificial Intelligence Research 57 (2016) 307343

Submitted 07/15; published 10/16

Scrubbing Learning Real-time Heuristic Search
Nathan R. Sturtevant

sturtevant@cs.du.edu

Department Computer Science
University Denver
Denver, Colorado, USA

Vadim Bulitko

bulitko@ualberta.ca

Department Computing Science
University Alberta
Edmonton, Alberta, T6G 2E8, Canada

Abstract
Real-time agent-centered heuristic search well-studied problem agent
reason locally world must travel goal location using bounded computation memory step. Many algorithms proposed problem
theoretical results also derived worst-case performance simple
examples demonstrating worst-case performance practice. Lower bounds, however,
widely studied. paper study best-case performance generally
derive theoretical lower bounds reaching goal using LRTA*, canonical example
real-time agent-centered heuristic search algorithm. results show that, given
reasonable restrictions state space heuristic function, number steps
LRTA*-like algorithm requires reach goal grow asymptotically faster
state space, resulting scrubbing agent repeatedly visits state.
show asymptotic analysis hold complex realtime search algorithms, experimental results suggest still descriptive practical
performance.

1. Introduction
framework real-time agent-centered heuristic search models agent locally
limited sensing perception trying reach goal interleaving planning
movement (Koenig, 2001). well-studied problem led numerous algorithms (Korf,
1990; Furcy & Koenig, 2000; Shimbo & Ishida, 2003; Hernandez & Meseguer, 2005; Bulitko
& Lee, 2006; Hernandez & Baier, 2012) various theoretical analysis (Ishida & Korf,
1991; Koenig & Simmons, 1993; Koenig, Tovey, & Smirnov, 2003; Bulitko & Lee, 2006;
Bulitko & Bulitko, 2009; Sturtevant, Bulitko, & Bjornsson, 2010).
Given broad work problem, surprising find little work
done lower bounds. clear examples agent travel directly
goal state optimal path. examples, however, generally require unreasonably accurate initial heuristic favorable domain-specific tie-breaking schema
hard guarantee practice. examples (Koenig & Simmons, 1993; Edelkamp &
Schrodl, 2012) show worst-case bound tight, examples generally
characterize worst-case best-case performance coincide.
main contribution paper non-trivial lower bound travel distance
required agent reach goal basic real-time heuristic search framework.
c
2016
AI Access Foundation. rights reserved.

fiSturtevant & Bulitko

show theoretically exists tie-breaking schema forces agent revisit
states (scrub) polynomially growing state spaces; undesirable property
real-time heuristic search. result shows phenomenon unavoidable
agent limited 1-step lookahead, state space polynomial, edges unit costs,
initial heuristic consistent integer valued. later show lifting
lookahead unit edge cost restrictions allows agent cases travel directly
start goal. However, counter examples somewhat contrived and,
empirical results demonstrate, appear happen frequently practice.
open question whether similar theoretical results derived fewer restrictions
agent state space. also examine exponential state spaces learning
multiple trials convergence. insights theoretical work also provide
explanations several approaches taken recent literature effective.
paper extended version previously published symposium paper (Sturtevant & Bulitko, 2014). original paper contained proof asymptotic state revisitation assumptions 1-step lookahead, polynomial state spaces, unit edge costs,
integer initial heuristics, non-optimal tie-breaking. journal paper adds counterexamples exponential state spaces, larger lookahead, spaces non-unit edge costs
and/or non-integer initial heuristic. Convergence travel also analyzed, new experimental results different tie-breaking rules added. Finally, include additional
discussion around issues.
rest paper organized follows. begin Section 2 formally defining
problem hand. review related work problem Section 3.
theoretical analysis presented Section 4. discuss applicability
theory broader class state spaces algorithms Section 5 build concrete
counter-examples. theoretical results supported brief empirical evaluation
Section 6. conclude paper outline directions future work.

2. Problem Formulation
paper use common definition real-time heuristic search problem.
define search problem n-tuple (S, E, s0 , sg , h) finite state states
E finite set edges them. E jointly define search
graph undirected: a, b [(a, b) E = (b, a) E]. Two states b
immediate neighbors iff edge them: (a, b) E; denote set
immediate neighbors state N (s). path P sequence states (s0 , s1 , . . . , sn )
{0, . . . , n 1}, (si , si+1 ) E. route R simple path
include duplicate states. Initially assume edge costs 1 (Assumption 1).
times {0, 1, . . . } agent occupies single state st S. state s0
start state given part problem. agent change current state,
is, move immediately neighboring state N (s). traversal incurs travel
cost c(st , st+1 ). agent said solve search problem earliest time
arrives goal state: sT = sg . solution path P = (s0 , . . . , sT ): sequence
states visited agent start state goal state.
cumulative cost edges solution travel cost primary
performance metric concerned paper. cost shortest possible
308

fiScrubbing Learning Real-time Heuristic Search

path states a, b denoted h (a, b). abbreviate h (s, sg ) h (s).
agent access heuristic h : [0, ). heuristic function part search
problem specification meant give agent estimate remaining cost
go. heuristic integer-valued (Assumption 2). search agent modify
heuristic sees fit long remains admissible [h(s) h (s)], consistent a, b
[|h(a) h(b)| h (a, b)] integer-valued times. (Admissibility consistency
assumed throughout paper.) heuristic time denoted ht ; h0 = h.
total magnitude updates heuristic function performed agent
= 0 = called total learning amount.
Algorithm 1: Basic Real-time Heuristic Search
input : search problem (S, E, s0 , sg , h), tie-breaking schema
output: path (s0 , s1 , . . . , sT ), sT = sg
1 t0
2 ht h
3 st 6= sg
4
st+1 arg mins0 N (st ) (1 + ht (s0 ))
5
ht+1 (st ) 1 + ht (st+1 )
6
tt+1
7



Numerous heuristic search algorithms developed problem described
(e.g., Korf, 1990; Bulitko & Lee, 2006; Koenig & Sun, 2009).
based Algorithm 1. search agent following algorithm begins start state
s0 repeatedly loops process choosing next state updating
heuristic reaches goal state sg first time (line 3). Within loop,
line 4 agent first computes immediate neighbor minimizes estimated
cost going neighbor (always 1 now) plus estimated cost going
neighbor goal. lookahead 1 thus immediate neighbors (i.e.,
N (st )) considered agent (Assumption 3). Ties among neighbors
minimal heuristic values broken tie-breaking schema provide
(Assumption 4), detailed later paper, sufficiently suboptimal prove
results. Then, line 5, agent updates (or learns) heuristic current state
making consistent heuristic neighbor picked previous line.
agent changes current state neighbor (i.e., makes move). general
problem allows heuristic decrease, algorithm never decrease heuristic
value state, since heuristic always consistent.
problem consider paper describe minimum amount Tmin (S)
travel cost search agent type described would necessarily incur
finding solution = (S, E, s0 , sg , h). exact value Tmin (S) intricately
depend particulars specific search problem S, derive useful asymptotic
lower bound Tmin (S). concerned systematic scrubbing:
agent said scrub systematically series growing state spaces iff number
state visits asymptotically dominates number states space: Tmin (S) (|S|).
309

fiSturtevant & Bulitko

Formally, consider series seach problems {S1 , S2 , . . . S2 , . . . } progressively increasing
state spaces: |Si | = g(i) (e.g., |Si | = i2 open two-dimensional grid Si cells).
agent scrubs systematically iff travel time lower-bounded function
Tmin (Si ) = f (i) asymptotically dominates state space size: f (g). use
standard definition asymptotic dominance: f (n) (g(n)) iff k > 0n0 n >
n0 [kg(n) f (n)]. Since functions positive, omit absolute value.
initially work assumption agent trying reach
goal (Assumption 5), measure first-trial travel, work
considered convergence travel. convergence travel agent teleported back
start state reaching goal, beginning new trial, updated heuristic.
agents learning converged trial result updates
heuristic function (Bulitko & Lee, 2006). systematic tie-breaking schema used,
convergence entails agent follow path goal subsequent
trials. First-trial travel trivially lower bound convergence travel; discuss
connection detail later paper.

3. Related Work
Previous work focused deriving upper bounds agents travel cost. instance, LRTA* (Algorithm 1) guaranteed reach goal O(|S|2 ) steps (Ishida &
Korf, 1991). follows analysis MTS (Ishida & Korf, 1991) targets
position fixed. Examples provided show exact bound, |S|2 /2|S|/2,
tight (Edelkamp & Schrodl, 2012).1 analysis extended class reinforcement learning algorithms, LRTA* special case (Koenig & Simmons, 1992,
1993, 1996). state-based value-iteration algorithms, search algorithm listed
above, upper bound still O(|S|2 ).
also substantial work analyzing algorithms backtracking moves,
introduced SLA* (Shue & Zamani, 1993a, 1993b) general SLA*T (Shue,
Li, & Zamani, 2001; Zamani & Shue, 2001). algorithms behave way
algorithm total learning exceeds certain threshold . agent
backtracks previous state whenever raises heuristic value. shown Bulitko
Lee (2006) travel cost SLA*T upper bounded h (s0 , sg ) +
threshold (learning quota). However, upper bound holds path
built SLA*T processed every move state revisits removed it.
problem-specific analysis minimum learning required prove optimal path
described Sturtevant et al. (2010) consider first-trial performance. provided proof sketch agents lookahead farther converge
optimal solution quickly. Empirical results suggested algorithms look
farther ahead better convergence performance primarily perform less
learning minimum required.

1. chapter containing results authored Koenig.

310

fiScrubbing Learning Real-time Heuristic Search

4. Analysis
goal paper derive non-trivial asymptotic lower-bound amount
travel search agent uses Algorithm 1 need perform reach goal state.
achieve goal stages. Section 4.1 illustrates tie-breaking influence
best- worst-case performance, using two simple examples. present high-level
overview derivation Section 4.2 detail individual steps Sections 4.3
4.6. apply analysis case polynomially growing state spaces
Section 4.9 discuss implications state revisits (i.e., scrubbing). results
require assumptions (1-5). presentation completed, Section 5
discuss extensions work state spaces non-unit edge costs larger lookahead.
Appendix consider exponential state spaces.
4.1 Intuition
Consider five-state grid world Figure 1. goal state 5 far right.
agent starts state 2. state agent examines heuristics immediate
neighbors, left right, goes neighbor lowest heuristic.
neighbors heuristic values identical then, time being, assume ties
broken neighbor right. favorable fortunate tie-breaking rule
example moves agent towards goal heuristic sufficient
itself. tie-breaking schema breaks ties away goal, example,
would unfavorable unfortunate. example temporarily break Assumption 4
agent unfortunate tie breaking. use several variations problem
illustrate importance tie-breaking solution travel cost.

Figure 1: one-dimensional grid world five states numbered top. agent
located state 2 two available actions shown figure.
Figure 2 plot initial heuristic values state ten-state version
grid, goal far right agent starts far left. initial
heuristic values shown dark bars, learned updates heuristic light
bars stacked top. plate shows single time step. agents current position
indicated A. reaching time step 4, agent continue straight
goal without heuristic updates. Due fortunate tie-breaking schema
particular example, total amount learning (i.e., total area light bars) 8
travel cost 9. Scaling example 2k states, total amount learning
2(k 1) path produced optimal cost 2k 1, state revisits.
Thus, total learning example grows linearly state space size
systematic scrubbing observed (i.e., Tmin (S) 6 (|S|)).
However, tie breaking adversely affect agents performance, general
guidance available state space allow favorable tie-breaking. Consider search
problem Figure 3 13 states. example, tie broken away goal
311

fiSturtevant & Bulitko

Time = 0

Time = 1



Time = 2





Time = 3

Time = 4





Figure 2: Heuristic learning favorable tie breaking. ten states problem
along horizontal axis. vertical axis shows value heuristic
function per time step. darker bars initial heuristic values.
lighter bars increases due learning. initial heuristic top.
agents current state shown A.

(i.e., left). travel cost 20 total amount learning 18 indicating
revisits 13 states agent, time steps 3, 7, 9. Scaling
search problem, total amount learning asymptotically quadratic number
states. amount heuristic learning per move 2 means travel
cost also asymptotically quadratic number states number revisits
per state increase state space size. Thus, Tmin (S) (|S|) |S|2 (|S|)
systematic scrubbing. difference two cases asymptotically
significant. favorable tie-breaking achieved specific examples, cannot
always guaranteed general.
4.2 Analysis Overview
goal quantify travel required agent type described Section 2
find solution. examples previous section demonstrated travel
cost depend tie-breaking schema used agent. Since may always
possible design favorable tie-breaking schema given problem (or series
problems), consider agents performance sufficiently suboptimal tie-breaking
schemas (Assumption 4) develop meaningful lower bound amount travel.
lower bound asymptotic number states and, unfortunately, demonstrates
common conditions agent necessarily revisit states many times
undesirable phenomenon known scrubbing real-time heuristic search.
present high-level argument immediately detail step individually subsequent sections. First, due consistency heuristic bounded
lookahead, learning performed step constant-bounded. Thus, asymptotic
lower bound learning required reach goal also asymptotic lower bound
travel distance (Section 4.3). show sufficiently suboptimal tie breaking
schema agent traveling sa sb must raise heuristic sa least
312

fiScrubbing Learning Real-time Heuristic Search

Time = 1

Time = 0







Time = 6





Time = 10



Time = 11





Time = 12

Time = 7





Time = 9

Time = 8





Time = 5

Time = 4

Time = 3

Time = 2

Time = 13





Figure 3: Heuristic learning unfortunate tie breaking.

sb (Section 4.4). Given search graph, current location, goal, identify lower
bound maximum heuristic value h agent must encounter traveling
goal (Section 4.5). Since heuristic consistent times use h compute
minimum amount learning (Section 4.6).
apply argument polynomial state spaces number states
within distance r given state grows (rd ) (e.g., quadratically commonly used
two-dimensional navigation maps = 2).2 spaces show that, given
appropriately inaccurate initial heuristic, amount learning necessarily performed
agent grow (rd+1 ) asymptotically dominates number states (rd ).
Since learning per step constant-bounded, amount travel also asymptotically
dominate number states. result indicates real-time heuristic search
agent type introduced necessarily scrub systematically (Corollary 2).
4.3 Learning per Step Constant Bounded
provide bound learning required solve problem first time
cumulative updates heuristic function = 0 = . section
begin showing learning per step constant-bounded. imply
lower bound learning also lower bound movement.
2. use standard definition bounded below: f (n) (g(n)) iff k1 > 0k2 >
0n0 n > n0 [k1 g(n) f (n) k2 g(n)], bounded below: f (n) (g(n)) iff k > 0n0 n >
n0 [kg(n) f (n)] bounded above: f (n) O(g(n)) iff g(n) (f (n)).

313

fiSturtevant & Bulitko

Lemma 1 total change heuristic values learning step Algorithm 1
constant bounded independently number states state space.
Proof. Algorithm 1 updates heuristic state st line 5 pseudo code based
heuristic neighboring state st+1 . st+1 immediate neighbor st
heuristic consistent, |ht (st ) ht (st+1 )| h (st , st+1 ) = 1. definition,
new heuristic st 1 + ht (st+1 ). Thus, heuristic st increase 2.
Since st state heuristic updated, maximum change heuristic
values time step 2, constant bounded. 2
measure learning necessary move different locations world.
4.4 Maintaining Non-increasing Heuristic Slope
section prove exists tie-breaking schema, , forces
agent maintain non-increasing heuristic values states along route, call
non-increasing heuristic slope property. better worse tie-breaking schemes
may exist specific problems, sufficiently suboptimal prove main result.
defined earlier, agents route simple path start state s0
current state st loops removed. instance, time = 5 agent
traversed path P = (s0 , A, B, A, C, D) route R = (s0 , A, C, D). heuristic
profile vector heuristic values along route. heuristic profile along
route {4, 3, 2, 2}, non-increasing property holds. heuristic profile {2, 3, 4, 3},
non-increasing properly hold.
construct tie-breaking schema whenever non-increasing property
violated raising heuristic current state, agent forced backtrack,
removing offending state route. illustrate, consider Figure 3. time step
5 agent raises heuristic current state violates non-increasing property
(the new, larger heuristic value shown time step 6). agent therefore backtracks,
making move left, removes offending state route.
reaching state time step 8 agent move forward satisfying
property.

ht+1

ht

st

1

st

st

1

st

s0

Figure 4: Raising h(st ) h(st1 ) allows tie-breaking schema force agent
backtrack.

314

fiScrubbing Learning Real-time Heuristic Search

Lemma 2 (Forced Backtracking) Consider agent non-goal state st time t.
current route R = (s0 , . . . , st1 , st ). exists tie-breaking schema
updating heuristic st ht (st ) ht+1 (st ), updated value raises
heuristic profile ceases non-increasing, agent backtrack
previous state st1 :
ht+1 (st1 ) < ht+1 (st ) = st+1 = st1 .

(1)

Proof. First, agent moved st1 st , must hold ht (st1 ) = 1 + ht (st ),
due line 5 Algorithm 1. shown left side Figure 4. Due consistent,
integer-valued heuristic unit edge costs, way heuristic increasing
along route learning ht+1 (st ) = ht (st1 ) + 1, shown right side
Figure 4. case, update must come state s0 N (st )
state lowest heuristic among st neighbors (Figure 4) ht (s0 ) = ht (st1 ). Even
s0 st1 , heuristic value. Thus, tie-breaking schema
able break ties towards st1 , making agent backtrack st st1
maintaining non-increasing heuristic. tie-breaking schema . 2
Since backtracking removes offending state agents route,
following corollary.
Corollary 1 (Heuristic Slope) time search, exists tie-breaking
schema heuristic along agents route R = (r1 , . . . , rn ) non-increasing:
ht (r1 ) ht (r2 ) ht (rn ).

(2)

Proof. prove claim induction route length n. n = 1 inequality (2)
trivially holds. Suppose holds route length n (n + 1)th state
added route, Lemma 2 must hold heuristic added state
less equal heuristic routes previous end (otherwise agent would
backtrack route would grow). 2
4.5 Lower Bound Maximum Heuristic Encountered
Assume time agent added state sb route. means, according
Corollary 1, ht (sa ) ht (sb ) state sa already route. Informally,
agent passes state high heuristic, must first raise previous states
route least equally high heuristics. Since heuristic values Algorithm 1 never
decrease learning (due consistency), also means ht (sa ) h0 (sb )
implies agent must already raised heuristic sa least h0 (sb )h0 (sa ),
assuming term positive. interested identifying states particular
problem maximize difference h0 (sb ) h0 (sa ), used bound
learning. section show find states. particular, sb state
largest heuristic agent must encounter en route goal. Informally,
providing general definition local minima proving agent must
learn way local minima increasing heuristic values.
Figure 5 illustrates concept pathfinding video-game map. Suppose
agent state sa trying reach state sg . observe agent must pass
315

fiSturtevant & Bulitko

one states within bottleneck C1 reaching goal. Similarly,
agent must also pass one states C2 reaching goal.

C1
sg

C3
C4

sa

C2
Figure 5: two-dimensional pathfinding search problem goal state labeled sg
start state labeled sa . C1 , C2 , C3 C4 cut sets.

say set states C cut set respect states sa sg iff sa
/ C,
sg
/ C possible routes R = (sa , ..., sg ) non-empty intersection C.
Figure 5 sets C1 , C2 C3 C4 three different cut sets respect sa
sg . Given two states sa sg , denote set cut sets C(sa , sg ). Thus
C1 C(sa , sg ), C2 C(sa , sg ) (C3 C4 ) C(sa , sg ).
use notion cut sets derive lower bound maximum heuristic value
seen agent en route goal. map Figure 5, assuming standard
straight-line heuristic, C1 best cut set initial heuristic values
states relatively small. C2 better initial heuristic values larger.
C3 C4 even better cut set largest minimum initial heuristic values
among C1 , C2 , C3 C4 .
general, find best lower bound considering cut sets choosing
one maximal minimal initial heuristic:
h(sa , sg ) =

max

min h0 (s)

CC(sa ,sg ) sC

(3)

definition definition cut set follows agent necessarily
travel state h0 (s) h(sa , sg ). Thus, h(sa , sg ) useful lower
bound maximum heuristic encountered along route sa sg .
316

fiScrubbing Learning Real-time Heuristic Search

h(s0 , sg )
h

h0
sg

s0



Figure 6: illustration , h h(s0 , sg ).

Note state sa arbitrary state S. Thus, R(S) set states
route generated agent solving problem define:
h

h = max h(s, sg ) h0 (s)
(4)
sR(S)
h

= arg max h(s, sg ) h0 (s) .
(5)
sR(S)

several states h maximized, set them.
follows state agents route goal whose heuristic value
raised least h :
h hT (s ) h0 (s ).

(6)

Figure 6 illustrates heuristic profile simple one-dimensional state space
every state start state s0 goal state sg forms single-state cut
set. Hence, h(s0 , sg ) highest initial heuristic agents route. Thus,
heuristic states left peak raised least h(s0 , sg ).
maximum amount learning, h , happens state .
states along route R(S) may known priori, R(S) must contain
initial state s0 which, given (4), means that:
h h(s0 , sg ) h0 (s0 ).

(7)

Furthermore, often possible identify state R(S) yields lower bound
h higher h(s0 , sg ) h0 (s0 ). illustrate: h shown Figure 6 strictly
greater h(s0 , sg ) h0 (s0 ). practical example, shown Figure 8, octile
distance h0 eight-connected grid leads h(s0 , sg ) h0 (s0 ) = 0. But, practice,
agent move corner first, allowing us identify different state .
analyze example detail Section 4.8.
4.6 Minimum Learning Minimum Travel Required Overall
established exists state along agents route goal whose
heuristic agent necessarily raise least h . Per Lemma 1, amount
learning per move constant-bounded, number visits state (h ).
317

fiSturtevant & Bulitko

Consistency heuristic allows us derive even stronger lower bounds total
amount learning travel cost. Indeed, raising heuristic h implies
heuristic values many states raised well, contributing total
amount learning, travel state re-visits.
Specifically, since time {0, . . . , } heuristic ht consistent, heuristic
value state n upper lower bounded respect arbitrary state
S, according distance it:
ht (m) h (m, n) ht (n) ht (m) + h (m, n).

(8)

Thus, agent reaches goal time , heuristic state state
space lower-bounded according distance :
n [hT (n) hT (s ) h (s , n)] .

(9)

initial heuristic consistent hence upper-bounded:
n [h0 (n) h0 (s ) + h (s , n)] .

(10)

state n S, difference left sides (9) (10) least large
difference right sides:
hT (n) h0 (n) hT (s ) 2h (s , n) h0 (s )
which, due (6), becomes:
h 2h (s , n)

(11)

sum right side (11) states n and, since heuristic value decreases
learning, derive following lower bound total amount learning:
Lmin (S)

X

max{0, h 2h (s , n)}.

(12)

nS

illustrated Figure 7 consistency heuristic determines diamond
around h . area diamond right side inequality (12). amount
learning per move constant bounded (Section 4.3) also derive lower bound
amount travel:
Tmin (S) (Lmin (S)) .

(13)

Note one-dimensional example non-increasing heuristic slope property
allows derive even higher lower bound necessary amount learning. Specifically, time agent reaches goal sg , heuristic values left peak
raised least level dotted line. filled-in volume clearly
greater area diamond figure. indicates possible direction
future work finding lower bound aggressive one inequality (12)
use rest paper.
318

fiScrubbing Learning Real-time Heuristic Search

h

h0
sg

s0

Figure 7: lower bound Lmin determined , h .

4.7 General Conditions Systematic Scrubbing
Recall definition scrubbing number state visits asymptotically
dominates number states space: Tmin (S) (|S|). Thus, one way establish
systematic scrubbing series search problems compute or, least, estimate
sum Equation 12 show asymptotically dominates number states |S|.
Together link Tmin Lmin given Equation 13, would establish
systematic scrubbing.
Generally speaking, sum may depend intricately search problem structure
initial heuristic. Thus, proceed analyzing two special cases.
4.8 Special Case: Corner Map
cannot make general statements single problem instances, instead parameterize problem instances size, allowing us describe scale map
size grows. case measure size radius length one edge
map. Consider series search problems known corner map (Figure 8).
s0







n=5
sg

Figure 8: corner map analyzed Sturtevant et al. (2010).
map parameterized n: problem instance Sn n > 3 |Sn | O(n2 )
states. two-dimensional grid agent occupy vacant cell (white
figure). agent move four cardinal neighbors unless blocked
obstacle (dark grey cells figure), edges unit cost, assume
Manhattan distance initial heuristic h0 . Later paper revisit example
diagonal, non-unit-cost moves octile distance heuristic.
319

fiSturtevant & Bulitko

agent starts corner created obstacles, corner state .
Using analysis previous sections, h Equation 3 value n + 1
two states labeled figure. Correspondingly, state defined Equation 5
also shown figure initial heuristic value 4 (for n); raised
h goal state reached. Thus, h = n + 1 4 = n 3. lower bound
Lmin (Inequality 12) becomes:
X
Lmin (Sn )
max{0, n 3 2h (s , s)}.
(14)
sSn

Looking structure corner, re-write right side (14) summing
= h (s , s) multiplying number states value h (s , s).
one state (s ) h (s , s) = 0, two states h (s , s) = 1, + 1 states
h (s , s) = i. odd values n, re-write sum (14) as:3
n3

Lmin (Sn )

2
X

(i + 1)(n 3 2i) =

i=0

(n 3)(n 1)(n + 1)
.
24

(15)

(n 2)(n 1)n
.
24

(16)

even values n result is:
n4

Lmin (Sn )

2
X

(i + 1)(n 3 2i) =

i=0

either case, sum, function n, class (n3 ) puts learning
amount Lmin (n3 ). amount learning per move constant bounded, Tmin
(n3 ). number states two-dimensional n n corner map O(n2 )
asymptotically dominated Tmin proving agent scrub systematically
{S1 , S2 , . . . }.
Specific properties corner maps allowed us derive complexity class
sum (12) well total number states map. following section
analyze broader class search spaces.
4.9 Special Case: Locally Isotropic Polynomial State Spaces
lower bounds amount learning (12) total travel (13) hold search
problem S. However, bounds explicitly reference number states
thus immediately allow us correlate amount travel number states
order make claim state revisitation. investigate ways computing
number states (r, S, E) precisely distance r away state :
(r, S, E) = |{s | h (s, ) = r}|.

(17)

Generally speaking, (r, S, E) depends topology search graph (S, E)
arbitrarily complex. However, state space isotropic around state
3. still lower-bound example considering full path goal
heuristic values raised h(s). analysis assumes first state
heuristic raised.

320

fiScrubbing Learning Real-time Heuristic Search

number states distance r away depend direction
described simply (r). term isotropic usually used refer entire
state space; use term locally isotropic refer states spaces isotropic
region within radius r .
sum inequality (12) alternatively computed integral
shortest distance r state states:
X

Z



max{0, h 2h (s , n)} =

h
2

(r)(h 2r)dr.

(18)

0

nS

simplify computation integral (18) polynomial state spaces
extend distance least h /2; is, locally isotropic.
state spaces
(r) = rd1

(19)

r [0, h /2]. instance, two-dimensional navigational maps also locally
isotropic least radius h /2 around state , degree polynomial = 2
(r) = r21 = r, r [0, h /2]. Note theoretical abstraction
states real-life maps (e.g., Figure 5) always locally isotropic; maps
asymmetric structure may stretch far enough around . Also, may
polynomial obstacles may non-uniformly reduce number available states
distance r away state.
Substituting (r) = rd1 (18), get:
Z

h
2

(r)(h 2r)dr =

0
h
2

Z

rd1 (h 2r)dr =

0

Z
h
0

h
2

r

d1

Z
dr 2

h
2

rd1 rdr =

0

fi h
fi h
h fifir= 2
2 d+1 fifir= 2
r fi
r fi


d+1
r=0
r=0




h h
2
h d+1


2
d+1
2


d+1
(h )

(h )d+1
d2d
(d + 1)2d


1
1

(h )d+1
2d + 1

(h )d+1
2d d(d + 1)

=
=
=
=
((h )d+1 ), h .

(20)

Combining (12), (18) (20) conclude locally isotropic polynomial spaces
dimension extend distance least h /2 around state , minimum
321

fiSturtevant & Bulitko

amount total learning lower-bounded as:


Lmin (S) (h )d+1 , h .

(21)

amount learning per step constant-bounded, asymptotic lower bound
applies travel cost:


Tmin (S) (h )d+1 , h .
(22)
Note assumptions, number states within radius r state
grows as:
Z r
Z r
xd1 dx (rd ), r .
(23)
(x)dx =
0

0

Now, consider infinite series growing search problems {S1 , S2 , . . . }. Suppose
search problem Si corresponding state space Si locally isotropic
polynomial radius ri around corresponding state . Assume also degree
polynomial 1 radii search problems monotonically
unboundedly increase i:
r1 < r2 < . . .

(24)

ri .

(25)

(23), follows state space size asymptotically lower-bounded rid :
|Si | (rid ), .

(26)

Suppose also state space Si asymptotically upper-bounded rid well:
|Si | O(rid ), .

(27)

Further, suppose initial heuristic search problem Si corresponding
h grows linearly ri . Finally suppose local isotropicity expands far enough
: ri h /2. Together two conditions are:
h /2 ri h

(28)

1/2 fixed constant.
Corollary 2 (Systematic Scrubbing). Given assumptions equations 24-28,
real-time heuristic search algorithm fits basic framework formulated earlier
paper (Assumptions 1-5) necessarily scrub systematically.
Proof. state space radius ri increases, h problem Si increase
linearly due (28). minimum amount travel Tmin asymptotically grows
polynomial degree + 1:


Tmin (Si ) d+1
,i
(29)
h


Tmin (Si ) rid+1 ,
(30)
322

fiScrubbing Learning Real-time Heuristic Search

due (22), (25) linear relation h Si radius ri (28).
time, number states state space asymptotically grow
polynomial degree radius:
|Si | (rid ),

(31)

due (26) (27). Combining (30) (31) get necessary amount travel
assymptotically dominates state space size:
Tmin (Si ) (|Si |),

(32)

agent scrub systematically. 2
4.10 Discussion
informally summarize results thus far, shown systematically
measure heuristic learning must performed single state looking
maximum heuristic difference encountered state goal.
assumptions total learning required around state asymptotically dominates
number states state space. Since learning per step constant-bounded, agents
forced scrub.
analysis, general form (Section 4.9), based several important
assumptions. First, assume conservative tie-breaking rule prefers re-visit states
exploring new ones. Second, assume state space locally isotropic around
. Third, assume that, general problems, heuristic error growing proportional
radius state space. Finally, assume agent 1-step lookahead,
edges unit cost, heuristic values integer valued.
consider assumptions detail. First, experimental results
explore several tie-breaking rules, well aggressive tie-breaking prefers
move larger g-costs small g-costs. results show that, better
tie-breaking rule improve best-case performance, also large impact
worst-case performance.
Second, definition systematic scrubbing holds problem total
learning (20) grows asymptotically faster state space (23). proved
must occur polynomial state spaces locally isotropic around ; would
interesting future work develop broader range models property.
Experimental results provided giving evidence occur practice.
Third, heuristic error (h ) series growing state spaces constant,
scrubbing behavior guaranteed proofs. requires highly accurate
heuristic cannot assumed general. interesting open question
heuristic error grows different classes problems, whether linear, logarithmic,
function size radius state space. analysis clearly domain
problem dependent, even heuristic consistently underestimates 10%
locations locally isotropic, perfect others, analysis holds (Corollary 2).
Finally, address larger lookahead non-unit edge heuristic costs Section 5.
323

fiSturtevant & Bulitko

4.11 Special Case: Exponential State Spaces
common real-time agents traverse exponential state spaces, place
analysis exponential state spaces Appendix A. techniques used show
systematic scrubbing polynomial spaces locally isotropic insufficient
exponential spaces locally isotropic. However, also proof
systematic scrubbing absent. Thus, analysis needed make conclusive
statement scrubbing exponential state spaces.

5. Generalizing Theory
far, proven systematic scrubbing (Corollary 2) holds basic agent
design simple state space. section investigate extent
result generalizable. independently relax Assumptions 1 & 2 (unit edge costs
integer heuristic values) Assumption 3 (one-step lookahead) showing, counterexamples, Corollary 2 directly generalize. counter-examples
contrast experimental results suggest scrubbing occur practice.
open problem succinctly describe conditions asymptotic scrubbing
complicated scenarios.
Relaxing single trial assumption (Assumption 5), however, shows scrubbing
expected learning convergence.
5.1 Non-unit Edge Costs Non-Integer Initial Heuristics
section address whether Corollary 2 generalizes search problems non-unit
edge costs and/or heuristic values. particular, relax assumption unit edge costs
(Assumption 1), replacing assumption constant-bounded edge costs. also
relax assumption integer heuristic values (Assumption 2).
provide set counter-examples systematic scrubbing: specifically constructed
search problems agent running LRTA* move region low heuristic
values higher heuristic values without maintaining non-increasing heuristic slope,
key assumption previous proofs.

0

c

s0

1

c

s1

2

c

s2

1

c

s3

0
s4

Figure 9: Example chain states n = 2.
Consider chain 2n + 1 states, illustrated Figure 9 n = 2,
{s0 , s1 , s2 , . . . , sn , . . . , s2n } s0 start state s2n goal. Suppose initial
heuristic values monotonically increasing along chain state sn (h(s1 ) < h(s2 ) <
. . . h(sn )), monotonically decreasing afterwards. Let h(i) = n h(i) = 2ni
> n. set growing state spaces well defined n > 0 and, c = 1, meets
conditions Corollary 2. Thus, example cause previously described agent
scrub.

2
s-2

1.0

1
s-1

1.0

0
324
s0

1.0

1
s1

1.0

1
s2

1.0

2
s3

1.0

2
s4

1.0



1.0

n
s2n

1.0

n-1

s2n+

fiScrubbing Learning Real-time Heuristic Search

However, allow heuristic values non-integer edge costs
non-unit scenarios exists agent climb heuristic grade without
scrubbing. instance, change edge costs c = 1.5 instead 1.0, get
behavior shown Figure 10. agent starts state 0; heuristic state
updated 2.5 edge cost (1.5) plus h-cost neighbor (1.0).
agent moves state 1. Notice heuristic left (2.5 state 0)
slightly larger heuristic right (2.0 state 2). learning, heuristic
state 1 updated 3.5, agent continues state 2. last step shown here,
agent begin follow gradient goal state 4. Thus, edge costs
agent choice move start goal without scrubbing.
4

4

4

4

3

3

3

3

2

2

2

2

1

1

1


0
0

1


1.5

1

1.5

2

1.5

3

1.5

0
4

0

1.5

1


1.5

2

1.5

3

1.5

0
4

0

1.5

1

1.5

2


1.5

3

1.5

0
4

0

1.5

1

1.5

2

1.5

3

1.5

4

Figure 10: agent climbs heuristic grade without scrubbing.
intuition formalized chain 2n states follows:
Lemma 3 Consider chain states {s0 , s1 , s2 , . . . , s2n } s0 starting state
s2n goal. Suppose initial heuristic values monotonically increasing
along chain intermediate state sn : h(s1 ) < h(s2 ) < . . . h(sn ) forming
heuristic grade n states. Assume sn heuristic monotonically decreasing.
Suppose heuristic grade constant slope {0, . . . , 2n 1} [|h(si ) h(si+1 )| = ]
edge costs uniform {0, . . . , 2n 1} [c(si , si+1 ) = c]. slope strictly
edge cost c agent lookahead 1 climb grade state n
without scrubbing, regardless tie-breaking schema, reach goal (n)
steps.
Proof. proof induction state number k. show whenever
agent state 0 k n 1 set heuristic sk greater
heuristic sk+2 (i.e., hnew (sk ) > h(sk+2 )) move state sk+1 . call
slope-edge property: slope growing slower edges causes agent climb
slope without backtracking.
Base case: k = 0. agent increase h(s0 ) h(s1 ) + c move s1
choice. Starting c > derive:
c >

(33)

hnew (s0 ) h(s1 ) > h(s2 ) h(s1 )

(34)

hnew (s0 ) > h(s2 ).

(35)

proves slope-edge property k = 0.
Inductive step. Suppose slope-edge property holds k = j, j n 3.
follows agent state sj+1 hnew (sj ) > h(sj+2 ).
325

fiSturtevant & Bulitko

immediately conclude agent make next move sj+2 . move
set hnew (sj+1 ) min {hnew (sj ) + c, h(sj+2 ) + c} = h(sj+2 ) + c. Since h(sj+3 ) = h(sj+2 ) +
c > , conclude hnew (sj+1 ) > h(sj+3 ) makes slope-edge property
hold k = j + 1.
agent reaches state n, heuristic monotonically decreasing towards
goal, agent follow slope downward reaching goal. 2
lemma hinges interplay c. interplay satisfied
either non-unit edge costs non-integer valued initial heuristic. example uses
c = 1.5 = 1.0, lemma holds c = 1.0 = 0.5, well many
values c .
4.0 4.5 5.0 5.5 6.0 7.0 8.0 9.0

4.0 4.5 5.0 5.5 6.0

8.0 9.0

3.0

6.5 7.5 8.5

3.0

8.0 7.5 8.5

2.0

6.0 7.0 8.0

2.0

7.5 7.0 8.0

1.0

5.5 6.5 7.5

1.0

7.0 6.5 7.5

G

6.0 7.0

G

6.5 6.0 7.0

Figure 11: agent climbs heuristic grade without scrubbing (intermediate steps omitted).
situation happen practice, illustrated Figure 11. state
agent marked state goal marked G. states labeled
initial heuristic value. Diagonal edges cost 1.5 heuristic octile distance,
shortest path obstacles diagonal cardinal movements
allowed. real-time heuristic search agent lookahead 1 walk along
wall heuristic increases = 0.5 per step edge costs along
agents path 1. result, agent walk directly local heuristic
minimum continue goal, traversing shortest path scrubbing.
example, however, somewhat fragile. extend map downward, agent
longer necessarily walk directly goal. illustrate Figure 12.
case agent begins walking upwards before, reaches diagonal line
shown right side figure, heuristic longer changes 0.5 per step.
slope-edge property longer maintained, agent longer move
heuristic slope. point agent four choices move next (shown
four gray cells figure) and, unfavorable tie breaking backtrack. Running
example shows that, particular case, typical scrubbing behavior follows.
5.2 Larger Lookahead
section show equipping agent larger lookahead, breaking Assumption 3, style LSS-LRTA* (Koenig & Sun, 2009) eliminate systematic scrubbing
even search problem unit edge costs.
326

fiScrubbing Learning Real-time Heuristic Search

6.0 6.5 7.0 7.5 8.0 8.5 9.0 9.5

6.0 6.5 7.0 7.5 8.0 8.5 9.0 9.5

5.0

7.5 8.5 9.5

5.0

8.5 9.5

7.0 8.0 9.0

4.0

8.5 8.0 9.0

3.0

6.5 7.5 8.5

3.0

8.0 7.5 8.5

2.0

6.0 7.0 8.0

2.0

7.5 7.0 8.0

1.0

5.5 6.5 7.5

1.0

7.0 6.5 7.5

G

6.0 7.0

G

6.5 6.0 7.0

4.0

= 1.0
= 0.5

Figure 12: agent cannot climb heuristic grade without scrubbing.

First, redefine agent algorithm allow larger lookahead Algorithm 1
Algorithm 2. terminology A* algorithm works follows: long goal
reached (line 3) agent expands search space current state st .
expansion carried via OPEN set seeded current state
moment time contains states generated expanded. expand
state means generate neighbors. neighbors placed OPEN set unless
already CLOSED set (line 9). CLOSED set contains states
expanded (line 8). States OPEN set expanded order
minimum f = g + h cost, g-cost distance agents current state st
(line 7). number expansions per step l, algorithm parameter (line 10).
expansion process finished agent updates heuristic value states
CLOSED list (line 12). call states local learning space. changes
current state promising state OPEN list (line 13). lines 12 13
use different cost function, cLS (s, s0 ). cost shortest path
s0 using states inside OPEN CLOSED.
provide example set problems where, using larger lookahead, agent
walk directly local minima follow optimal path goal without
scrubbing. Similar example Section 5.1, heuristic barrier created behind
agent drives forward precludes backtracking/scrubbing. example
Figure 13. example edge costs 1. state marked current
heuristic value, states labeled (b) (n). state agent marked
lower left corner. agent lookahead l = 5.
first row, agent gray states local learning space.
darker/red states indicate OPEN list, used basis updating heuristic
values; agent also move one states learning. matter ties
broken (in f -cost metric used ordering state expansions), five states
local learning space; gray states must expanded. But, state (h)
lower heuristic state (b), agent necessarily moves state (h). Upon reaching state
(h) space process repeats, except higher heuristic values. process shown
similar manner past examples Figure 14.
327

fiSturtevant & Bulitko

Algorithm 2: Real-time Heuristic Search Lookahead
input : search problem (S, E, s0 , sg , h), lookahead l
output: path (s0 , s1 , . . . , sT ), sT = sg
1 t0
2 ht h
3 st 6= sg
4
OPEN {st }
5
CLOSED
6
repeat
7
n best state OPEN
8
CLOSED CLOSED {n}
9
OPEN OPEN (N (n) \ CLOSED)
10
OPEN = |CLOSED| = l
11
state CLOSED
12
ht+1 (s) 0 min (cLS (s, s0 ) + ht (s0 ))
OPEN

13

st+1 arg

14

tt+1

15

min (cLS (st , s0 ) + ht (s0 ))

s0 OPEN


(b)

(c)

(d)

(e)

(f)

(g)

(h)

(i)

(j)

(k)

(l)

(m)

(n)

6

5

4

3

4

5

5

6

7

7

8

9

9

6

7

8

8

7

6

5

6

7

7

8

9

9

6

7

8

8

9

10 10

9

8 A7

8

9

9





Figure 13: agent climbs heuristic grade without scrubbing.
11

11

11

10

10

10

9

9

9

8

8

8

7

7

7

6

6

6

5

5

5

4

4

4

3

3

3

2

2

1

2

1



0
1

1.0

2

1.0

3

1.0

4

1.0

5

1.0

6

1.0

7

1.0

8

1.0

9

1.0

10

1.0

11

1.0

12

1.0

1



0
13

1

1.0

2

1.0

3

1.0

4

1.0

5

1.0

6

1.0

7

1.0

8

1.0

9

1.0

10

1.0

11

1.0

12

1.0



0
13

1

1.0

2

1.0

3

1.0

4

1.0

5

1.0

6

1.0

7

1.0

8

1.0

Figure 14: agent climbs heuristic grade without scrubbing.

328

9

1.0

10

1.0

11

1.0

12

1.0

13

fi0

1.0

s0

1

1.0

s1

2

1.0

1

1.0

0

Real-time Heuristic Search
sScrubbing
s3 Learning
s4
2

example generalized two ways: first value lookahead (l),
second arbitrary long sequences states. given problem instance, however, may
generalize different lookahead start state. build example shows
lookahead l = 3 build arbitrarily long sequences states lookahead
agent traverse without scrubbing, reaching goal |S| steps.

2
s-2

1.0

1
s-1

1.0

0

1.0

s0

1

1.0

s1

1

1.0

s2

2

1.0

s3

2

1.0



1.0

n

1.0

s2n+1

s2n

s4

n-1

1.0



1.0

0
s2n+n

Figure 15: General example l = 3.

Lemma 4 Consider chain states {s2 , s1 , s0 , . . . , s3n } s0 starting state
s3n = s2n+n goal. heuristic state si < 0. heuristic
state si di/2e 0 2n. heuristic state si 3n > 2n shown
Figure 15. agent lookahead 3 climb heuristic grade state 2n without
scrubbing, regardless tie-breaking schema, reach goal 3n steps.
Proof. prove inductively showing invariant heuristic values
two neighbors side agent. invariant hold agent reaches
state s2n , agent walk directly goal. invariant
current state heuristic v, neighbors current state heuristic
value v + 1, next neighbor right value v + 1, next neighbor
left value v + 2. Furthermore, along path agent never backtracks
left, stopping learn even states s0 , s2 , s4 , . . . , s2n .
Base case: agent starts s0 heuristic 0. definition, states s1 s1
heuristics 1, state s2 heuristic 1, state s2 value 2.
learning, h(s1 ) = 3, h(s0 ) = 3 h(s1 ) = 2. agent thus moves state s2
heuristic 1. States s1 , s3 , s4 heuristic 2, s0 heuristic 3. agent
moved right thus far, even-numbered state, invariant holds
agents new location.
Previously unvisited

v+2

si-2

1.0

v+1

si-1

1.0

v

si

1.0

v+1

si+1

1.0

v+1

si+2

1.0

v+2

si+3

1.0

v+2

si+4

Figure 16: Current heuristic values induction step.
Inductive step. current state graph beginning induction step
shown Figure 16. assume invariant holds current agent state si
heuristic v = di/2e i/2 since even invariant. states
329

fiSturtevant & Bulitko

si+1 , si+2 , si+3 , si+4 yet visited included learning, heuristic values
v + 1, v + 1, v + 2, v + 2 respectively. follows initial heuristic values
fact even. Furthermore, according invariant, states si1 si+1
heuristics v + 1, state si+2 heuristic v + 1, state si2 value
v + 2.
learning, h(si1 ) = v + 3, h(si ) = v + 3 h(si+1 ) = v + 2. agent
must move si+2 heuristic v + 1, meets even state condition. h(si+1 )
updated v + 2 h(si ) v + 3. States si+3 si+4 yet visited
part local learning space, still original heuristic values.
particular, since even, heuristic value d(i + 3)/2e d(i + 4)/2e
respectively, equal. Thus h(si+3 ) = v + 2 h(si+4 ) = v + 2. invariant
still holds, generalizing example.
remaining question happens agent reaches state s2n . point
heuristic values left agent higher right
decrease directly edge cost reach zero. Thus, agent always prefer
move right reaches goal. agent never backtracks moves directly
state s0 s3n , thus reaching goal 3n steps. 2
example fixed, odd-valued lookahead. structure wellunderstood, difficult construct similar examples odd-valued lookaheads.
lookahead even, additional state one neighbor needed next state
visited agent (i.e., single new state connected state s2i ). extra state
never visited, dead end, essentially reduces lookahead one,
reducing back odd-value case lookahead.
5.3 Discussion
examples presented require particular starting conditions broken
slightly changing properties starting state, agent lookahead,
heuristic slope. Thus, examples confirm that, assumptions, agents
can, certain circumstances, reach goal without scrubbing, guarantee
happen practice wide range real-world problem instances (Section 6).
may always priori clear parameters LSS-LRTA* style agent needs
use avoid scrubbing particular problem, propose several general approaches
combat scrubbing. work removing one assumptions used
theoretical analysis.
first approach learn faster, trying violate bound constant learning
per step. several ways this. Algorithms f -LRTA* (Sturtevant
& Bulitko, 2011) LSS-LRTA* swamps (Sharon, Sturtevant, & Felner, 2013)
prune states state space, effectively raising heuristics infinity single
step. second approach use better tie-breaking rule. Hernandez Baier (2012)
developed tie-breaking rules work well grid worlds, small fraction
problems result poor performance. FALCONS also learns g-costs better
tie-breaking (Furcy & Koenig, 2000).
third approach decrease h decrease size local minima
agent must escape. use 0 initial heuristic local minima,
330

fiScrubbing Learning Real-time Heuristic Search

resulting h = 0 rendering theoretical analysis paper inapplicable,
agent would guidance would wander aimlessly. better approach
multiply heuristic constant 0 < < 1, reducing magnitude h .
contrast raising initial heuristic multiplicatively attempt reduce heuristic
error (Shimbo & Ishida, 2003). latter method equivalent putting weight
g-cost introduced real-time heuristic search Bulitko (2004)
equivalence proven Bulitko Lee (2006). question perform weighting
recently revisited Rivera, Baier, Hernandez (2015).
Finally, could avoid value-iteration based heuristic search approach altogether,
using algorithms RIBS (Sturtevant et al., 2010) EDA* (Sharon, Felner, &
Sturtevant, 2014).
5.4 Convergence Travel
results derived thus far apply travel first-trial. one runs Algorithm 1
Algorithm 2 repeatedly, preserving learning using start goal,
heuristic values eventually converge true distance goal along
least one optimal path start goal (breaking Assumption 5) (Bulitko & Lee,
2006). thus build general bound learning required convergence.
start, derive analogous result Lemma 1, showing learning per step
constant-bounded using larger lookahead.

Lemma 5 Assuming constant-bounded edge costs, constant-bounded branching factor,
constant-bounded lookahead, total change heuristic values learning step Algorithm 2 constant bounded.

Proof. Algorithm 2 updates heuristic state closed list line 12
pseudo code based heuristic state s0 open list distance
s0 . number states closed list constant bounded constantbounded lookahead, l. shortest path (cLS ) state open list
state s0 closed list bounded maximum edge cost times l times
branching factor. three values constants, shortest path constant
bounded. Additionally, change heuristic constant bounded due consistency.
Thus, change heuristic state closed list also constant bounded. Put
together, total change heuristic values states CLOSED also constant
bounded. 2
Previously, used cut set analysis determine minimum learning required
state state space. Here, bypass analysis look optimal
heuristic must learned least one optimal path start goal.
Let P (s0 , sg ) set optimal paths start goal, let Pi
optimal path requires minimum
ith path. define P
learning - is, smallest difference initial final heuristic
convergence. Then, define alternate versions h convergence.
331

fiSturtevant & Bulitko


P
= arg

h =
=

min
(max [h (s, sg )
Pi P (s0 ,sG ) sPi
max [h (s, sg ) h0 (s)]
sP
arg max [h (s, sg ) h0 (s)] .
sP

h0 (s)])

(36)
(37)
(38)

definition, h depends error perfect heuristic
initial heuristic fact algorithm converges perfect heuristic one
path. depend tie-breaking, lookahead, edge costs environment.

order make connection Lmin Tmin
below, do, however, assume
edge costs constant bounded ensure learning per step also constant
bounded. Thus, provide convergence form Equation 12:

Lmin (S)

X

max{0, h 2h (s , n)}.

(39)

nS

also show convergence travel bounded convergence
learning:


Tmin
(S) (Lmin (S)) .

(40)

Thus, series polynomial state spaces h grows map radius,
systematic scrubbing necessarily occur convergence travel.
Corollary 3 (Systematic Scrubbing Convergence). Consider series search
problems {S1 , S2 , . . . } locally isotropic polynomial state spaces {S1 , S2 , . . . }
dimension (i.e., number states radius r given state rd1 ). state
space Si radius ri = max h (a, b). Suppose initial heuristic search problem Si
a,bSi

heuristic error h ri positive constant. Also, suppose heuristic
state space Si extends least h /2 around state . real-time heuristic
search algorithm runs convergence necessarily scrub systematically.
Proof. state space radius ri increases, heuristic error h increase

least ri . minimum amount travel Tmin
asymptotically grow least rid+1

(Equation 22 holds trivially h well h given grow ri ).
time, number states state space (|Si |) asymptotically grow
(S ) (|S |) thus agent
faster rid (follows (23)). means Tmin


scrub systematically. 2
Note analyzed influence number trials performed
agent. leave analysis future work.
332

fiScrubbing Learning Real-time Heuristic Search

6. Experimental Results
goal paper investigate conditions scrubbing occur. showed,
certain assumptions, that, given heuristic learning h required state , agent
must perform asymptotically least d+1
moves (Tmin ) solve problem polynomial
h
state spaces dimension d. h linear radius r state space |S|
(rd ) Tmin (S) (|S|) systematic scrubbing occur.
experimental section paper focus primarily elements agent
construction, lookahead tie-breaking rules, also relax assumption
unit edge costs. address questions whether h linear radius
whether |S| (rd ) general.
initial proof required unfavorable tie-breaking rule, first set experiments explore happens vary tie-breaking rule scale size
state space, showing scrubbing still occurs practice. initial proof also
generalize relaxed unit-cost 1-step lookahead assumptions. So,
second experiment relax assumptions measure performance game maps,
showing scrubbing occurs practice.
validate results practical value theoretical claims,
implemented version LSS-LRTA* uses essentially opposite tie-breaking rule
used proofs. particular, learns g-costs like FALCONS (Furcy & Koenig,
2000) f -LRTA* (Sturtevant & Bulitko, 2011), breaks ties moving towards
state maximum g-cost. call algorithm gLSS-LRTA*. theoretical tiebreaking rule conservative, choosing move back towards start state (towards states
minimum g-cost) possible. gLSS-LRTA* aggressive, moving away
start state possible.
Evidence elsewhere (Sturtevant, 2012) suggests game maps
two dimensional. conclude, look maze maps taken moving AI repository,
estimated one-dimensional (Sturtevant, 2012). repeat experiments
maps showing scrubbing also occurring.
6.1 Experiments Corner Map
Consider corner map used earlier paper (Figure 8). example contains
corner-shaped wall start s0 upper left corner goal sg behind
wall bottom right corner. consider map 8-connected; diagonal
movement costs 1.5. octile distance heuristic mislead agent traveling
state labeled (Equation (5)) trying reach goal.
tie-breaking schema constructed earlier paper, final heuristic
value state, hT (s ), raised least h(s , sg ) = h0 (s), based states
marked figure. map h(s , sg ) = h0 (s) = n n number cells
along side map. case hT (s ) n.
recording hT (s ) h(s , sg ) = hT (s ) n see different tie-breaking
schema compare . Specifically, measurement hT (s ) n < 0 indicates
agent less learning state would . measurement
hT (s ) n indicates least much learning performed required .
333

fi5
0
5
10

Max Difference
Average Difference
Min Difference
20

40

60

80

100

Heuristic Diff. (hT(s)-h0())

Heuristic Diff. (hT(s)-h0())

Sturtevant & Bulitko

0
20
40
60

gLSS(1)
gLSS(10)

80

20

Corner Length/Width (n)

40

60

80

100

Corner Length/Width (n)

(a)

(b)

106

400+2.7x2.5
LSS-LRTA*(1)

106

Dist Traveled

Dist Traveled

Figure 17: Values hT (s ) n recorded running LSS-LRTA* gLSS-LRTA*
corner maps different sizes.

104

104
103

10
100
Max Learning ()
Dist Traveled

1

10

400+0.3x2.55
LSS-LRTA*(10)

5

1

10
100
Max Learning ()

400+0.03x2.65
LSS-LRTA*(100)

105
104
103
1

10
100
Max Learning ()

Figure 18: Distance traveled versus maximum learning state solving problem
instance using LSS-LRTA* lookahead depths (l) 1 (top left), 10 (top
right) 100 (bottom).

long hT (s ) n remains constant map radius grows, scrubbing
occurring. follows analysis Section 4.8 - subtracting constant Equation
(14) change asymptotic complexity result.
334

fiScrubbing Learning Real-time Heuristic Search

value n {10, 11, . . . , 100} (i.e., nn map (n2 ) states), ran 20 trials
LRTA* lookahead 1 random tie breaking (instead ). also experimented
fixed tie-breaking (chosen deterministically operator orderings internal data
structures) got similar results. average value, maximum value minimum value
hT (s ) n 20 trials function n plotted Figure 17(a). Analyzing
underlying data, find LRTA* randomized tie-breaking performed less n
learning 18% trials. is, 18% data points fall zero line.
used linear regression fit line max min values different segments
data test growing. Beyond low values n, min max differences
seem grow significantly problem size increases. Thus, conclude
scrubbing occurring experiments.
Figure 17(b) look performance gLSS-LRTA* corner map
lookahead 1 10. lookahead 1, gLSS-LRTA* exhibits scrubbing
behavior LSS-LRTA* radius map scales. However, lookahead
10, gLLS-LRTA* able escape corner map without scrubbing. largest map
tested, radius local minima 100, gLSS-LRTA*(10) increased
heuristic value 15
suspect gLSS-LRTA* need raise heuristic value corner
state much corner map moving away start state correlated
moving closer goal.
next section look complex maps game Dragon Age: Origins
see LSS-LRTA* gLSS-LRTA* perform there.
6.2 Pathfinding Video-Game Maps
section look pathfinding video-game maps. experiments
violate assumptions 1-3 (unit edge costs, integer heuristics, lookahead one),
maps also guaranteed locally isotropic around state. Despite this, see
measure heuristic learning correlates movement grows asymptotically
faster state space. Furthermore, experiments gLSS-LRTA* show
worse average-case performance LSS-LRTA*.
performed experiments Moving AI benchmark set (Sturtevant, 2012),
Dragon Age: Origins maps optimal solution cost [400, 404). total 600
problems used 60 maps. ran problems LSS-LRTA* (Koenig & Sun,
2009) lookahead depths 1, 10 100 (LSS-LRTA* lookahead 1 equivalent
Algorithm 1). Diagonal movement allowed cost 1.5. Ties broken
fixed way state, according operator ordering data structures, without
randomization. Note optimal solution cost predictive distance traveled
solving problem, setup gives wide range problem difficulties
constrained take least 400 steps solve.
measured maximum learning = max hT (s) h0 (s) occurred
sR(S)

state well total distance traveled reaching goal, plotted one
point problem instance test set. scrubbing occurring practice,
values constant-bounded; otherwise expect range values
335

fi10

400+2.7x2.5
gLSS-LRTA*(1)

6

Dist Traveled

Dist Traveled

Sturtevant & Bulitko

104

1

104
102

10
100
Max Learning ()
Dist Traveled

102

400+0.3x2.45
gLSS-LRTA*(10)

106

1

10
100
Max Learning ()

1000

400+0.05x2.40
gLSS-LRTA*(100)

106
105
104
103
1

10
100
Max Learning ()

1000

Figure 19: Distance travelled versus maximum learning state solving problem instance using gLSS-LRTA* lookahead depths (l) 1 (top left), 10
(top right) 100 (bottom).

. number states given radius map grows polynomially, total
movement grow faster polynomial degree two.
resulting scatter plots found Figure 18. visually fit polynomial
form = 400 + c1 xc2 data, knew problems optimal solution
cost 400 403. (y distance traveled x .) values c1 c2
three lookahead depths shown figure, although slightly different
values significantly change curves residuals.
two-dimensional video-game maps isotropic around state
exactly polynomial due topology, non-unit-cost edges, non-unit edge
costs, may extend far enough locally isotropic (Section 4.9).
result, theory offer asymptotic bound Tmin ((h )d+1 ) = ((h )3 )
travel hold. Furthermore, maximum learning amount measure
h defined earlier paper. Yet, manually fit polynomial curves appear come
close degree polynomial 2.5 2.65. Note degree
polynomial greater two, maximum dimensionality maps. data
suggests predictive total movement required reach goal
scrubbing occurring practice.
Results experiments gLSS-LRTA* found Figure 19.
problems algorithm sometimes raises heuristic substantially higher LSS-LRTA*
also travels substantially further.
336

fiMax Learning ()

Scrubbing Learning Real-time Heuristic Search

LSS-LRTA*(10)
gLSS-LRTA*(10)

500
250
0

0

25
50
75 100 125
Estimate h(s0, sg)-h0(s0)

Figure 20: comparison maximum learning practice () estimate
learning required start goal states (h(s0 , sg ) h0 (s0 )).

different tie-breaking rule achieved better performance, would expect smaller
range values x-axis (as compared Figure 18), would fewer states
large amounts learning. Instead, lookahead 10 100 range values
significantly increased, states heuristic raised almost 1000.
two-sample Kolmogorov-Smirnov test comparing LSS-LRTA* gLSS-LRTA* results
problems suggests differences significant lookahead 10
100, lookahead 1. gLSS-LRTA* provides worse performance
LSS-LRTA*.
Looking deeper data lookahead 10 find that, although mean maximum learning similar (55.29 LSS-LRTA*(10) versus 59.01 gLSS-LRTA*(10)),
higher standard deviation gLSS-LRTA*(10) (68.35 versus 45.79 LSS-LRTA*).
data shows instances tie-breaking towards states higher
g-cost help agent reach goal faster (324 instances better versus 240 worse).
hand, moving towards higher g-costs results worse performance (distance learning), outweighs gains problems, leading worse average
performance. lookahead 100 difference instance counts better worse
performance almost equal, again, loss performance tie-breaking rule
outweighs gains. data suggests moving away start state quickly
can, best case, improve performance, worst case significantly
detrimental effects. results suggest corner map representative
video game maps.
compare learning required start goal (h(s0 , sg )h0 (s0 )),
lower-bound h , , actual maximum learning performed agent.
estimate h(s0 , sg ) h0 (s0 ) measuring single shortest path instead
shortest paths. lower-bound h holds LSS-LRTA*, points Figure 20
would straight line x = figure.
600 pathfinding problems indeed case LSS-LRTA*(10)
one problem. one problem, algorithm maximum amount learning
337

fiSturtevant & Bulitko

10

6

7.1507x2.3067
LSS-LRTA*(1)

Dist Traveled

Dist Traveled

107

105
104
50
100
Max Learning ()
Dist Traveled

20

10

200

106

1.7745x2.2078
LSS-LRTA*(10)

105
104
103
20

50
100
Max Learning ()

200

0.51333x2.0462
LSS-LRTA*(100)

5

104
103
20

50
100
200
Max Learning ()

Figure 21: Distance travelled versus maximum learning state solving problem instances maze maps corridor size 8 using LSS-LRTA* lookahead depths (l) 1 (top left), 10 (top right) 100 (bottom).

() 54.5 yet maximum difference initial heuristic values along particular
optimal solution 55. Repeating experiments gLSS-LRTA*(10), number
problems rose 1 36 illustrated markers line Figure.
Simultaneously, gLSS-LRTA*(10) raised heuristic values states substantially higher
LSS-LRTA*(10).
6.3 Maze Maps
previous section looked maps game Dragon Age: Origins. Analysis
maps using regression number states level breadth-first search
suggests nearly two-dimensional (Sturtevant, 2012). Specifically, polynomial
regression equation + b x + c x2 gave average value 0.31 constant c.
According measure, mazes benchmark set appear approximately
one-dimensional, regression gives value 0.01 0.03 constant c equation (Sturtevant, 2012). Thus, mazes represent different class problems
re-run experiments. before, theoretical assumptions state spaces
hold experiments.
duplicated settings experiments Section 6.2 10 maze maps
corridor width 8 Moving AI benchmark set. fewer maps,
increased number problems solved solving probelsm optimal solution
400 439, resulting 1100 total problems solved. results LSS-LRTA*
Figure 21. computed best-fit curve using least squares data
equation c1 xc2 , also shown.
338

fiScrubbing Learning Real-time Heuristic Search

fits correlation 0.94, 0.94, 0.91 respectively lookaheads 1, 10,
100. maps see degree fit polynomial two greater.
maps one-dimensional constant, results suggest scrubbing
occurring practice.
initial trials maze problems, gLSS-LRTA* worst-case travel distance
several orders magnitude higher LSS-LRTA*. precluded us running
experiments reasonable amount time suggests gLSS-LRTA* practical
algorithm maps.

7. Conclusions
primary contribution paper development non-trivial lower bound
minimum travel LRTA*-like real-time heuristic search agent may
perform reach goal state. previous work provided examples problems
state revisitation (i.e., scrubbing) would occur, provide general conditions
used analysis. idealized polynomial state spaces lower bound grows
asymptotically faster state space. means agent necessarily scrub
undesirable behavior many applications real-time pathfinding video games.
theoretical results supported experimentally real-world search problems.
result may appear discouraging, suggests common real-time heuristic
search algorithms may not, own, able avoid scrubbing. proofs rely
several restrictive assumptions, expect results hold broadly.
proof suggest four directions future work trying improve asymptotic
performance. include (1) increasing amount learning performed step, (2)
using different tie breaking rules, (3) decreasing size heuristic local minima (4)
developing algorithms use value-iteration core technique driving agent
behavior. hope future researchers able point four directions
explain approaches improve performance, able identify
underlying assumptions state space makes approaches successful.
shown lower bound hold assumptions
broken, continue look properties could use extend lower bounds
larger class problems agents.

Acknowledgements
second author received support work National Research Engineering Council (NSERC).

Appendix A. Special Case: Locally Isotropic Exponential State Spaces
section consider case exponential state spaces. limit analysis
locally isotropic exponential state states spaces number states exactly cost r
away (up h /2) given state is:
(r) = br , r [0, h /2]
339

(41)

fiSturtevant & Bulitko

b branching factor space. Corollary 2, assume
state space size expand substantially beyond h /2 total state space size
asymptotically size state space within radius h /2
state (assumption ?).
case repeat derivation Section 4.9 substituting (r) = br
(18):
Z h
2
(r)(h 2r)dr =
0

Z

h
2

br (h 2r)dr =

0

Z
h

h
2

Z

r

b dr 2

0

h
2

br rdr =

0

fi h
Z h
2
br fifir= 2
br rdr.

2
h
ln b fir=0
0

(42)

R h
r
take integral 0 2 br rdr (42) introduce function g(r) = lnb b g 0 (r) = br
integrate parts:
Z
Z
r
b rdr = g 0 (r)rdr =
Z
g(r)r g(r)r0 dr =
Z r
Z
b
br

dr =
g(r)r g(r)dr = r
ln b
ln b


br
br
br
1
r

+C =
r
+ C.
(43)
ln b ln2 b
ln b
ln b
(43) equation (42) becomes:
fi h
Z h
2
br fifir= 2
2
h
br rdr
fi
ln b r=0
0
fi h

fi h
br fifir= 2
br
1 fifir= 2
h
2
r
ln b fir=0
ln b
ln b fir=0

fi h
2 fifir= 2
br

h 2r +
ln b
ln b fir=0


2 h

2
2
b
h +
ln b
ln b
ln2 b

=
=
=
h
b 2 , h

(44)

Combining (12), (18) (44) conclude locally isotropic exponential spaces
branching factor b extend distance least h /2 around state , minimum
amount total learning lower-bounded as:
h
Lmin (S) b 2 , h .
(45)
340

fiScrubbing Learning Real-time Heuristic Search

amount learning per step constant-bounded, asymptotic lower bound
applies travel cost:
h
Tmin (S) b 2 , h .
(46)
locally isotropic exponential spaces number states within radius h /2 state
grows as:
Z
0

h
2

Z
(r)dr =

h
2

h
br dr b 2 , h

(47)

0

asymptotically total state space according assumption (?)
asymptotically lower bound minimum amount
travel
(46).
h

means locally isotropic exponential spaces lower bound b 2

sufficient show systematic scrubbing (i.e., prove equivalent Corollary 2).
Note (46) lower asymptotic bound amount travel whereas (47)
upper lower asymptotic bound state space growth. Thus, may possible
Tmin grows asymptotically faster state space size lower bound derived
insufficient claim so.

References
Bulitko, V. (2004).
Learning adaptive real-time search.
Tech. rep.
http://arxiv.org/abs/cs.AI/0407016, Computer Science Research Repository (CoRR).
Bulitko, V., & Lee, G. (2006). Learning real time search: unifying framework. Journal
Artificial Intelligence Research, 25, 119157.
Bulitko, V. K., & Bulitko, V. (2009). backtracking real-time heuristic search. CoRR,
abs/0912.3228.
Edelkamp, S., & Schrodl, S. (2012). Heuristic Search - Theory Applications. Academic
Press.
Furcy, D., & Koenig, S. (2000). Speeding convergence real-time search. National
Conference Artificial Intelligence (AAAI), pp. 891897.
Hernandez, C., & Baier, J. A. (2012). Avoiding escaping depressions real-time
heuristic search. Journal Artificial Intelligence Research (JAIR), 43, 523570.
Hernandez, C., & Meseguer, P. (2005). LRTA*(k). International Joint Conference
Artificial Intelligence (IJCAI), pp. 12381243.
Ishida, T., & Korf, R. (1991). Moving target search. International Joint Conference
Artificial Intelligence (IJCAI), pp. 204210.
Koenig, S. (2001). Agent-centered search. Artificial Intelligence Magazine, 22 (4), 109132.
Koenig, S., & Simmons, R. G. (1992). Complexity analysis real-time reinforcement
learning applied finding shortest paths deterministic domains. Tech. rep. CMU
CS93106, School Computer Science, Carnegie Mellon University, Pittsburgh.
341

fiSturtevant & Bulitko

Koenig, S., & Simmons, R. G. (1993). Complexity analysis real-time reinforcement
learning. National Conference Artificial Intelligence (AAAI), pp. 99105.
Koenig, S., & Simmons, R. G. (1996). effect representation knowledge
goal-directed exploration reinforcement-learning algorithms. Machine Learning,
22 (1-3), 227250.
Koenig, S., & Sun, X. (2009). Comparing real-time incremental heuristic search
real-time situated agents. Journal Autonomous Agents Multi-Agent Systems,
18 (3), 313341.
Koenig, S., Tovey, C., & Smirnov, Y. (2003). Performance bounds planning unknown
terrain. Artificial Intelligence, 147, 253279.
Korf, R. (1990). Real-time heuristic search. Artificial Intelligence, 42 (23), 189211.
Rivera, N., Baier, J. A., & Hernandez, C. (2015). Incorporating weights real-time
heuristic search. Artificial Intelligence, 225, 123.
Sharon, G., Felner, A., & Sturtevant, N. (2014). Exponential deepening A* real-time
agent-centered search. AAAI Conference Artificial Intelligence, pp. 871877.
Sharon, G., Sturtevant, N. R., & Felner, A. (2013). Online detection dead states realtime agent-centered search. Helmert, M., & Roger, G. (Eds.), Proceedings
Sixth Annual Symposium Combinatorial Search. AAAI Press.
Shimbo, M., & Ishida, T. (2003). Controlling learning process real-time heuristic
search. Artificial Intelligence, 146 (1), 141.
Shue, L.-Y., Li, S.-T., & Zamani, R. (2001). intelligent heuristic algorithm project
scheduling problems. Annual Meeting Decision Sciences Institute, San Francisco.
Shue, L.-Y., & Zamani, R. (1993a). admissible heuristic search algorithm. International Symposium Methodologies Intelligent Systems (ISMIS-93), Vol. 689
LNAI, pp. 6975.
Shue, L.-Y., & Zamani, R. (1993b). heuristic search algorithm learning capability.
ACME Transactions, pp. 233236.
Sturtevant, N. R. (2012). Benchmarks grid-based pathfinding. Transactions Computational Intelligence AI Games, 4 (2), 144 148.
Sturtevant, N. R., Bulitko, V., & Bjornsson, Y. (2010). learning agent-centered search.
Autonomous Agents Multiagent Systems (AAMAS), pp. 333340. International
Foundation Autonomous Agents Multiagent Systems.
Sturtevant, N. R., & Bulitko, V. (2011). Learning going whence
came: H- G-cost learning real-time heuristic search. International Joint
Conference Artificial Intelligence (IJCAI), pp. 365370. AAAI Press.
Sturtevant, N. R., & Bulitko, V. (2014). Reaching goal real-time heuristic search:
Scrubbing behavior unavoidable. Proceedings Symposium Combinatorial
Search (SoCS), pp. 166174.
342

fiScrubbing Learning Real-time Heuristic Search

Zamani, R., & Shue, L.-Y. (2001). heuristic learning algorithm application
project scheduling problems. Tech. rep., Department Information Systems, University Wollongong.

343

fiJournal Artificial Intelligence Research 57 (2016) 151-185

Submitted 05/16; published 10/16

Lightweight Random Indexing
Polylingual Text Classification
Alejandro Moreo Fernandez
Andrea Esuli

alejandro.moreo@isti.cnr.it
andrea.esuli@isti.cnr.it

Istituto di Scienza e Tecnologie dellInformazione
Consiglio Nazionale delle Ricerche
56124 Pisa,

Fabrizio Sebastiani

fsebastiani@qf.org.qa

Qatar Computing Research Institute
Hamad bin Khalifa University
PO Box 5825, Doha, QA

Abstract
Multilingual Text Classification (MLTC) text classification task documents
written one among set L natural languages, documents must
classified classification scheme, irrespective language. two main
variants MLTC, namely Cross-Lingual Text Classification (CLTC) Polylingual Text
Classification (PLTC). PLTC, focus paper, assume (differently
CLTC) language L representative set training documents;
PLTC consists improving accuracy |L| monolingual classifiers
also leveraging training documents written (|L| 1) languages.
obvious solution, consisting generating single polylingual classifier juxtaposed
monolingual vector spaces, usually infeasible, since dimensionality resulting
vector space roughly |L| times monolingual one, thus often unmanageable.
response, use machine translation tools multilingual dictionaries
proposed. However, resources always available, always free use.
One machine-translation-free dictionary-free method that, best knowledge, never applied PLTC before, Random Indexing (RI). analyse RI
terms space time efficiency, propose particular configuration (that
dub Lightweight Random Indexing LRI). running experiments two well known public benchmarks, Reuters RCV1/RCV2 (a comparable corpus) JRC-Acquis (a parallel
one), show LRI outperform (both terms effectiveness efficiency) number
previously proposed machine-translation-free dictionary-free PLTC methods
use baselines.

1. Introduction
rapid growth multicultural multilingual information accessible Internet, properly classify texts written different languages become problem
relevant practical interest. Multilingual Text Classification (MLTC) text classification task documents written one among set L = {l1 , . . . , l|L| }
natural languages, documents must classified classification scheme, irrespective language. two main variants MLTC, namely
Cross-Lingual Text Classification (CLTC) Polylingual Text Classification (PLTC).
c
2016
AI Access Foundation. rights reserved.

fiMoreo, Esuli, & Sebastiani

CLTC task characterized fact that, languages subset LT
L, training documents; task thus consists classifying unlabelled
documents written languages LT (i.e., target languages) leveraging
training documents expressed languages LS = L\LT (i.e., source languages).
CLTC thus transfer learning problem (Pan & Yang, 2010), one needs transfer
knowledge acquired learning training data LS , task classifying
documents LT . previous work MLTC indeed focuses CLTC, fewer efforts
devoted PLTC, instead focus paper.
PLTC, representative set training documents languages L assumed
available. Therefore, straightforward solution may consist training |L| independent
monolingual classifiers, one language. However, solution suboptimal,
classifier obtained disregarding additional supervision could obtained
using training documents written (|L| 1) languages. PLTC thus
consists leveraging training documents written languages L improve
classification accuracy could obtained simply training |L| independent,
monolingual classifiers.
However, PLTC entails number obstacles work detriment efficient
representation. see this, assume generate single polylingual vector space (hereafter,
juxtaposed vector space) juxtaposing monolingual vector spaces. vector
space monolingual dataset usually consists tens even hundreds thousands
features; juxtaposed vector space polylingual dataset, dimensionality gets
roughly multiplied number distinct languages consideration. substantial increase feature space would degrade performance many classification
algorithms, so-called curse dimensionality, would also bring
severe degradation efficiency. Additionally, co-occurrence-based techniques tend lose
power representations polylingual, since terms belonging different languages
rarely co-occur, (a problem usually referred feature disjointness).
response, authors proposed use machine translation (MT) tools
device simultaneously cope high dimensionality feature disjointness
PLTC. idea reduce problem monolingual case (typically English).
is, non-English training documents automatically translated English, added
English training set, monolingual (English) classifier trained. classification
time, non-English unlabelled documents translated English classified.
(Of course, idea also used CLTC; case, training documents
translate.) However, MT-based PLTC (and CLTC) techniques suffer number
drawbacks (Wei, Yang, Lee, Shi, & Yang, 2014): (i) automatically translated texts usually
present different statistical properties respect human translations; (ii) MT systems
always available language pairs; (iii) training statistical MT system
free toolkits available requires collecting large corpora parallel text
domain interest, always easy.
Thesaurus-based dictionary-based methods, side, represent lighter
approach MLTC. multilingual dictionary thesaurus encompasses different languages available, kind unification vector representation may
attempted. customarily done replacing non-English words English equivalents dictionary, replacing terms thesaurus codes invariant
152

fiLightweight Random Indexing Polylingual Text Classification

across languages (e.g., BabelNet synsets Ehrmann, Cecconi, Vannella, McCrae, Cimiano,
& Navigli, 2014). However, bilingual dictionaries thesauri available language pairs, automatically constructing domain-dependent bilingual resource requires
suitable parallel corpus sentence-level alignment.
1.1 Distributional Representations
classification purposes, textual document usually represented vector vector
space according bag-of-words (BoW) model, i.e., distinct term corresponds
dimension vector space. juxtaposed vector space, columns
document-by-term matrix thus informative one languages.
Since distinct term corresponds dimension vector space, BoW model
agnostic respect semantic similarities among terms. is, dimension
term governor orthogonal dimension related term president,
dimension unrelated term transport. semantic relations among terms
uncovered detecting co-occurrences, i.e., contexts words tend
used together. idea rests distributional hypothesis, according words
similar meanings tend co-occur contexts (Harris, 1968). detecting
co-occurrences, possible establish parallelism term meaning geometrical properties vector space. Distributed Semantic Models (DSMs sometimes also
called word space models Sahlgren, 2006) aim learning continuous compact distributed term representations, recently called word embeddings (Mikolov,
Sutskever, Chen, Corrado, & Dean, 2013b). DSMs gained lot attention
machine learning community, delivering improved results many natural language processing tasks (Bengio, Schwenk, Senecal, Morin, & Gauvain, 2006; Bullinaria & Levy, 2007;
Collobert, Weston, Bottou, Karlen, Kavukcuoglu, & Kuksa, 2011). DSM-based methods
categorised (see Pennington, Socher, & Manning, 2014; Baroni, Dinu, & Kruszewski,
2014) belonging (a) class context-counting models, often based
matrix factorization, e.g., Latent Semantic Analysis (LSA Deerwester, Dumais, Furnas,
Landauer, & Harshman, 1990; Osterlund, Odling, & Sahlgren, 2015), (b) class
context-predicting models, e.g., methods based deep learning architectures (Bengio,
2009; Mikolov et al., 2013b).
However, multilingual contexts huge quantities plain text language
processed order learn meaningful word representations, incurs high computational costs. Trying find representations large multilingual vocabulary
thus become computationally prohibitive. attempts recently made
direction, leveraging multilingual external resources Wikipedia articles
(Al-Rfou, Perozzi, & Skiena, 2013), bilingual dictionaries (Gouws & Sgaard, 2015),
word-aligned parallel corpora (Klementiev, Titov, & Bhattarai, 2012), sentence-aligned
parallel corpora (Zou, Socher, Cer, & Manning, 2013; Hermann & Blunsom, 2014; Lauly,
Boulanger, & Larochelle, 2014; Chandar, Lauly, Larochelle, Khapra, Ravindran, Raykar, &
Saha, 2014), document-aligned parallel corpora (Vulic & Moens, 2015). However,
external resources may always available language combinations and,
available (e.g., Wikipedia articles), may uneven quality quantity
languages English. Alternatively, approaches require computationally
153

fiMoreo, Esuli, & Sebastiani

expensive post-processing step align word representations across languages (Mikolov, Le,
& Sutskever, 2013a; Faruqui & Dyer, 2014).
article discuss efficient representation mechanisms PLTC (i)
MT-free, (ii) require external resources, (iii) incur high computational
costs. particular, investigate suitability Random Indexing (RI Kanerva,
Kristofersson, & Holst, 2000; Sahlgren, 2005) effective representation mechanism
original co-occurrence matrix PLTC. RI context-counting model belonging
family random projections methods (Kaski, 1998; Papadimitriou, Raghavan, Tamaki, &
Vempala, 1998), produces linear projections nearly-orthogonal reduced space
original distances vectors approximately preserved (Hecht-Nielsen,
1994; Johnson, Lindenstrauss, & Schechtman, 1986). RI expected deliver fast
semantically meaningful representations reduced space, viewed cheaper
approximation LSA (Sahlgren, 2005). RI column polylingual
matrix produced depend single specific language (as instead
BoW representation). hypothesize could advantageous PLTC, since
entire new space becomes potentially informative languages once, thus making
problem easily separable enough dimensions considered. RI already
applied bilingual scenarios (Gorman & Curran, 2006; Sahlgren & Karlgren, 2005),
best knowledge tested PLTC case far. monolingual
TC, RI found competitive, superior, BoW (Sahlgren & Coster, 2004).
article demonstrate RI outperforms BoW model PLTC.
method present article, dub Lightweight Random Indexing (LRI),
inspired works Achlioptas (2001) Li, Hastie, Church (2006)
sparse random projections, goes one step pushing sparsity limit. LRI
designed orthogonality projection base maximized, causes sparsity
preserved projection. empirically show LRI helps Support Vector
Machines (SVMs) deliver better classification accuracies PLTC respect many
popular alternative vector space models (including main random projection variants,
LSA-based approaches, polylingual topic models), also requiring substantially
less computation effort.
contribution work twofold. First, conduct comparative empirical
study several PLTC approaches two representative scenarios: first
training corpus comparable topic-level (i.e., documents direct translations
other, simply similar topics; exemplified RCV1/RCV2
dataset), second training corpus parallel document-level (i.e.,
text available languages thanks intervention human translators;
scenario exemplified JRC-Acquis dataset). show LRI yields best results
settings, terms effectiveness efficiency. second contribution,
present analytical study useful better understand nature random
mapping methods.
rest paper organized follows. Section 2 discuss related work.
Section 3 present problem statement, describe Random Indexing method
detail, present proposal. Section 4 reports results experiments
conducted. Section 5 presents analytical study computational efficiency, Section
6 concludes.
154

fiLightweight Random Indexing Polylingual Text Classification

2. Related Work
section gives overview main approaches PLTC emerged
literature. distinguish three groups methods, according whether problem approached (i) leveraging external resources, (ii) combining outcome independent
monolingual classifiers, (iii) reducing dimensionality resulting multilingual
feature space. discussion also includes references CLTC techniques
consider relevant PLTC approach.
2.1 Exploiting External Multilingual Resources
Multilingual text classification relatively recent area research, previous
efforts within devoted CLTC subtask. CLTC labelled
information languages, previous approaches typically relied automatic translation
mechanisms means fill gap source target languages.
main difference CLTC PLTC lies fact PLTC exploits labelled
documents belonging different languages learning. Despite this, two tasks
close-knit relation, since cross-lingual adaptation generally carried
means external resources, parallel corpora, bilingual dictionaries,
statistical thesauri.
suitable (unlabelled) multilingual corpus containing short aligned pieces texts
available, correlations among groups words two languages could explored.
Cross-Lingual Kernel Canonical Correlation Analysis (CL-KCCA) proposed Vinokourov, Shawe-Taylor, Cristianini (2002) means obtain semantic cross-lingual
representation, investigating correlations aligned text fragments. CL-KCCA
takes advantage kernel functions order map aligned texts high-dimensional
space manner correlations mapped aligned texts jointly
maximized. cross-lingual representation could used classification, retrieval,
clustering tasks. CL-KCCA investigated combination Support Vector Machines (SVMs) applied cross-lingual patent classification Li Shawe-Taylor
(2007). method, called SVM 2k, learns two SVM-based classifiers searching two
linear projections original feature space language distance
projections (instead correlation projections) two aligned texts minimized.
similar vein, polylingual topic models (Mimno, Wallach, Naradowsky, Smith, &
McCallum, 2009) proposed extension Latent Dirichlet Allocation (LDA
Blei, Ng, & Jordan, 2003) polylingual case. LDA generative model
assigns probability distributions documents latent topics, latent topics
terms. distributions viewed compact representations documents
latent space. Since topics discovered Polylingual LDA (PLDA) aligned across
languages, documents represented common vector space regardless language
written in. However, PLDA (which use baseline experimental
section) requires parallel collection documents aligned sentence level.
Bilingual dictionaries used straightforward manner carry word-byword translation feature space. However, dictionary-based translations suffer
several deficiencies, e.g., context-unaware translations might perform poorly handling
polysemic words; dictionaries might suffer substantial lack coverage novel terms
155

fiMoreo, Esuli, & Sebastiani

domain-dependent terminology; dictionaries might available language
pairs, free use. response drawbacks, automatic acquisition
statistical bilingual dictionaries proposed. Wei et al. (2014) explored cooccurrence-based method measure polylingual statistical strength correlation
among words parallel corpus. correlations taken account reinforce weight feature order select important (highly weighted) ones.
Gliozzo Strapparava (2006) experimented bilingual dictionaries and, interestingly, provided means automatically obtain Multilingual Domain Model (MDM),
natural extension domain models multiple languages, additional multilingual resources available. domain model defines soft relations words
domain topics. absence multilingual dictionary, MDM could automatically
obtained comparable corpus performing Latent Semantic Analysis (explained
detail below).
argued words shared across languages play important role
searching semantic latent space. Accordingly, Steinberger, Pouliquen, Ignat
(2004) exploit language-independent tokens shared across languages,
propose simple method link documents existing external resources thesauri,
nomenclatures, gazetteers. Finally, de Melo Siersdorfer (2007) use ontologies
map original features onto synset-like identifiers, documents translated
language-independent feature space.
MT tools, side, provide elaborated translations texts, represent promising research field multilingual tasks. Unfortunately, above-mentioned
problems regarding availability, accessibility, performance still hold case.
effect different translation strategies CLTC investigated Bel, Koster,
Villegas (2003), Rigutini, Maggini, Liu (2005), Wei, Lin, Yang (2011).
Even available, MT tools may expensive resources. reason,
experiments Prettenhofer Stein (2010) restrict use MT tool limited budget
calls. Structural Correspondence Learning (SCL) method, initially proposed
domain adaptation, indeed applied CLTC. key idea method consists
discovering cross-lingual correspondences pairs terms (dubbed pivot features)
later used bridge across two languages. Pivot features play important
role bilingual tasks, since establish pairs words behave similarly source
target languages, allowing one find cross-language structural correspondences. One
special type pivot features obviously words shared across languages,
proper nouns, technical terms, yet lexicalized terms, stemmed forms etymologically
related terms. Nastase Strapparava (2013) found etymological ancestors words
actually add useful information, allowing transcend cross-lingual boundaries.
method however depends availability etymological thesauri (such Wikipedias
Wiktionary, Etymological WordNet), remains restricted historically interrelated
languages.
sum, applicability multilingual methods discussed section usually
constrained availability external resources. aim overcoming limitations, restrict investigations dictionary-free, MT-free multilingual methods.
156

fiLightweight Random Indexing Polylingual Text Classification

2.2 Monolingual Classifiers Multiview Learning
Given availability representative set labelled documents language,
simple baseline, known nave polylingual classifier, could obtained delegating
classification process individual monolingual classifiers, built upon separate
monolingual data. solution sub-optimal, classifier exploit labelled
information languages, type information might provide insights
different perspectives semantics classes.
Garca Adeva, Calvo, Lopez de Ipina (2005) compared different nave strategies,
considering one single polylingual classifier, i.e., classifier works juxtaposed
representation (1C), vs. various monolingual ones (NC), one language-independent
preprocessor (1P) vs. various language-specific ones (NP), using various learning methods
bilingual Spanish/Basque benchmark. experimentation combinations NPNC NP-1C, consider baselines, yielded best results terms
running time, memory usage, accuracy.
Even though training separate language-specific classifiers simple way approach
PLTC task, strategies could improve final accuracy better
merging outcomes classifier. Multiview learning (Xu, Tao, & Xu, 2013) TC
deals parallel texts, i.e., case document available languages,
language considered separate source. shown Amini, Usunier,
Goutte (2009) multiview majority voting algorithm, returns label output
highest number language-specific classifiers, outperforms nave polylingual
classifier multiview Gibbs classifier, bases predictions mean prediction
language-specific classifier. Amini Goutte (2010) proposed co-regularization
approach multiview text classification minimizes joint loss function takes
account language-specific classifier loss. However, availability parallel
corpus containing documents views strong restriction, usually
alleviated leveraging machine translation tools automatically generate missing
documents views.
2.3 Dimensionality Reduction Multilingual Classification
One main challenges juxtaposed vector space approach PLTC concerns
relevant increase number features represent documents, i.e., dimensionality vector space (Rigutini et al., 2005). Feature selection methods attempt
select reduced subset informative features original set F size
subset much smaller |F | reduced set yields high classification
effectiveness. TC problem usually tackled via filtering approach, relies
mathematical function meant measure contribution feature classification task. Yang Pedersen (1997) showed filtering approaches may improve
performance classification, even aggressive reduction ratios (e.g., removal 90%
features).
Another important dimensionality reduction technique Latent Semantic Analysis
(LSA aka Latent Semantic Indexing), originated information retrieval
community (Deerwester et al., 1990), later applied cross-lingual classification (Gliozzo & Strapparava, 2006; Xiao & Guo, 2013) cross-lingual problems general
157

fiMoreo, Esuli, & Sebastiani

(Dumais, Letsche, Littman, & Landauer, 1997). LSA maps original document-term matrix lower dimensional latent semantic space attempts capture (linear)
relations among original features documents. mapping carried
means singular value decomposition (SVD) original document-term matrix .
SVD decomposes = V U , diagonal matrix containing eigenvalues . approximation Mk = Vk k UkT original matrix computed
taking k largest eigenvalues setting remaining ones 0; Mk said
rank-k optimal terms Frobenius norm. Vk Uk orthogonal matrices
explain relations among pairs terms pairs documents, respectively.
Although LSA successfully used discover hidden relations indirectly
correlated features, case terms belonging different languages, suffers
high computational costs. Random mappings arise alternative LSA,
perform comparably different machine learning tasks preserving important
characteristics LSA, bringing about, time, significant savings
terms computational cost (Fradkin & Madigan, 2003). Random Projections (RPs
Papadimitriou et al., 1998) Random Mappings (RMs Kaski, 1998) two equivalent
formulations deriving Johnson-Lindenstrauss lemma (Johnson et al., 1986),
states distances Euclidean space approximately preserved projected onto
lower-dimensional random space. formulations also based fundamental
result Hecht-Nielsen (1994), proved many nearly orthogonal
truly orthogonal directions high-dimensional spaces.
RP-like methods formalized terms projection original documentterm matrix means random matrix , i.e., M|D|n = M|D||F | |F |n ,
approximates identity matrix, |D| |F | indicate number documents
terms collection, n stands reduced dimensionality, typically
chosen advance. definition random-projection matrix fundamental
aspect method; Achlioptas (2001) demonstrated random distribution
zero mean unit variance satisfies Johnson-Lindenstrauss lemma, proposed two
simple distributions definition elements ij = {ij } random projection
matrix, setting parameter distribution Equation 1 either = 2 = 3:

1
+1 probability 2s

0 probability 1 1s
ij =

(1)

1
1 probability 2s
Achlioptas proved configuration = 3 used speed computation, since case 1/3 data non-zero (sparse random projection),pand
therefore 2/3 computations skipped. Similarly, Li et al. (2006) set = |F |
= |F |/ log |F | (very sparse random projections) significantly speed computation still preserving inner distances.
Random Indexing (RI), first proposed Kanerva et al. (2000), equivalent formulation RPs also accommodates Achlioptas theory. Sahlgren (2001) defines RI
approximate alternative LSA semantic representation. RI maintains dictionary
random index vectors feature original space. random index vector consists n-dimensional sparse vector k non-zero values, randomly distributed across
+1 1 (the method explained detail Section 3). work Gorman
158

fiLightweight Random Indexing Polylingual Text Classification

Curran (2006) different weighting criteria random index vectors dictionary
proven useful improving matrix representation. RI tested different tasks,
search (Rangan, 2011), query expansion (Sahlgren, Karlgren, Coster, & Jarvinen,
2002), image text compression (Bingham & Mannila, 2001), event detection (Jurgens & Stevens, 2009). Fradkin Madigan (2003) showed that, since RI distances
approximately preserved, distance-based learners k-Nearest Neighbours (k-NN)
SVMs preferable learning randomly indexed instances. Accordingly,
Sahlgren Coster (2004) applied RI (monolingual) text classification using SVMs,
suggested random indexing representation (there dubbed Bag Concepts
BoCs Sahlgren & Coster, 2004) performed comparably BoW representation.
performance RI also tested Sahlgren Karlgren (2005) Gorman
Curran (2006) realm automatic bilingual lexicon acquisition.
above-discussed works indicate RI promising dimensionality reduction technique representing polylingual data. proposal inspired works Achlioptas
(2001) Li et al. (2006) sparse projections taking level sparsity extreme, extends application RI TC (Sahlgren & Coster, 2004) PLTC, which,
best knowledge, never done far. following section first
describe method detail, propose particular setting aimed overcoming
certain obstacles could arise polylingual setting.

3. Lightweight Random Indexing Polylingual Text Classification
Text Classification (TC) formalized task approximating unknown target
function : C {1, +1}, indicates documents ought classified,
means function : C {1, +1}, called classifier, coincide
much possible terms given evaluation metric. denotes domain
documents, C = {c1 , c2 , ..., c|C| } set predefined classes, values +1 1
indicate membership non-membership document class, respectively.
consider multilabel classification, is, setting document
could belong zero, one, several classes time; consider flat
version problem, hierarchical relations among classes exist. adopt
1 vs. strategy, according multilabel classification problem solved
|C| independent binary classification problems.
document collection represented via matrix M|D||F |
~

d1
w11
w12 w1|F |
d~2 w21
w22 w2|F |



= . = .
..
..
..
.. ..
.
.
.
w|D|1 w|D|2 w|D||F |
d~|D|

(2)

|D| |F | number documents features collection, real
values wij represent weight feature fj document di , usually determined
function frequency feature document collection.
Polylingual Text Classification adds one fundamental aspect TC, i.e., different documents may belong different languages. Let : L return language
159

fiMoreo, Esuli, & Sebastiani

given document written, L = {l1 , l2 , . . . , l|L| } pool languages, |L| > 1.
S|L|
Let F = i=1 Fi denote vocabulary collection, expressed
union language-specific vocabularies Fi . polylingual setting assumes
distribution P ((d) = li ) across training set approximately uniform, is,
representative quantity labelled documents language.
usually small amount shared features across languages (e.g., proper
nouns)1 , implies hd~0 , d~00 0 (d0 ) 6= (d00 ), h, denotes dot
product. (Incidentally, means direct similarity comparison among documents
expressed different languages, e.g., using cosine-similarity, would doomed fail.)
thus possible, language li , perform reordering rows columns

M1 M2 0
matrix allows polylingual matrix expressed =
,
0 M3 4
[M1 ;
2 ]
|{d : (d) = li }| |Fi | monolingual matrix representation
M2
language li ,
|D| matrix containing words shared across two
M3
languages, 0 denotes all-zero matrices.
3.1 Random Indexing
Random Indexing maps observable problem feature random vector vector
space number dimensions determined number different unique
features want map, instead fixed advance. Originally, RI proposed
performing semantic comparisons terms. document thus mapped
random index vector accumulated (via vector addition) terms row
term-document matrix time term occurred document. case,
instead interested performing semantic comparisons documents, terms.
Thus, term fi assigned n-dimensional random index vector, accumulated
j-th row document-term matrix every time term found document dj .
Random index vectors nearly-orthogonal, comply conditions spelled
Achlioptas (2001) (see Section 2.3), i.e., zero-mean distribution unit variance,
satisfy Johnson-Lindenstrauss lemma. random index vector created randomly
setting k n non-zero values, equally distributed +1 1, n-dimensional
vector n typically order thousands. n fixed, recommended
choice k literature k = n/100. dub configuration RI1% , use
comparative experiments. vectors RI1% sparse, using sparse data structure
representations could bring memory savings. M|D|n = M|D||F | |F |n matrix
multiplication (see Section 2.3) completely skipped, building M|D|n on-the-fly
scanning document accumulating corresponding random index vectors
term read. also avoids need allocate entire matrix M|D||F | memory.
According Sahlgren (2005), main advantages RI summarized follows:
method (i) incremental, provides intermediate results data read
1. Note formulations polylingual problem, e.g., ones Amini et al. (2009)
Prettenhofer Stein (2010), actually impose 6= j Fi Fj = . means
shared words across languages, proper nouns, given multiple representations languagespecific features.

160

fiLightweight Random Indexing Polylingual Text Classification

in; (ii) avoids so-called huge matrix step (i.e., allocating entire M|D||F | matrix
memory), (iii) scalable, since adding new elements data increase
dimensionality space (e.g., new features represented via new random index,
via new dimension).
BoW matrices typically weighted normalized better represent importance
word document avoid giving long documents priori importance,
respectively. Weighting schemes could also incorporated RI formalism
simple manner; e.g., time random index added document row, first
multiplied weight term document. brings improved
accuracy shown Gorman Curran (2006); however, work also
shown incremental nature algorithm sacrificed non-linear weights
taken account. experiments, weighting criterion use well-known
tfidf method, expressed
tfidf (di , fj ) = tf (di , fj ) log

|D|
|d : tf (d, fj ) > 0|

(3)

tf (di , fj ) counts number occurrences feature fj document di ; weights
normalized via cosine normalization,
wij = qP

tfidf (di , fj )

fk F

(4)

tfidf (di , fk )2

3.2 Lightweight Random Indexing
preliminary experiments application RI method dimensionality
reduction, observed SVMs required time train training set
processed RI, original high-dimensional vector space (see Section
5.2). also observed correlation training times choice k,
choice n smaller impact efficiency.
Optimizing choice k RI though means achieve two main goals:
(i) able encode large number different features reduced space, (ii)
increasing chance two random index vectors orthogonal.
respect (i), easy show that, want assign different n-dimensional
index vector
k non-zero values original feature, RI could encode maximum
C(n, k) = nk 2k features (representation capacity). C(n, k) grows rapidly function
either n k; example, C(5000, 50) 2.5 10135 . huge capacity clearly
exceeds representation requirements imposed current future dataset. However,
even small values k capacity becomes large enough encode reasonable
dataset, e.g., C(5000,2)=49,990,000 distinct features.
respect (ii), random-projection-based algorithms rely Hecht-Nielsen
(1994) lemma find nearly orthogonal directions reduced space. Two vectors ~u
~v inPan inner product space said orthogonal whenever h~u, ~v = 0,
h~u, ~v = ui vi dot product. Random indexes chosen sparse order
increase probability dot product equals zero, non-zero products evenly
distributed +1 1, leaving expected value outcome close zero.
161

fiMoreo, Esuli, & Sebastiani

Figure 1: Probability orthogonality two random index vectors function k
n.

means Monte Carlo algorithm, estimated probability orthogonality
two randomly generated vectors grid sample values n k. results,
plotted Figure 1, reveal smaller values k main factor favouring
orthogonality two random index vectors, n smaller impact.
many random index vectors lack orthogonality, information conveyed original distinct features, predominantly pair-wise semantically unrelated, gets mixed
up, causing learner difficulty learning meaningful separation patterns
them. orthogonality random index vectors plays even important role
features shared across languages. shown work Gliozzo Strapparava (2005), shared words play relevant role bringing useful information across
languages. corresponding random index vectors orthogonal respect
vectors, information contribute process maximized, instead
diluted less informative features.
Following observations above, propose use Random Indexing fixed
k = 2; dub configuration Lightweight Random Indexing (LRI). hypothesis
setting could advantageous mechanism reduce dimensionality (so
mitigate problem feature disjointness PLTC), since sufficient order
represent large feature vocabularies also preserving vector orthogonality. Note
choosing k = 1, n = |F |, would equivalent performing random permutation
162

fiLightweight Random Indexing Polylingual Text Classification

1

2

3

4

5

6

7
8

Output: Dictionary;
// Generate random index vector feature
= 0 (|F | 1)
// choose 1st dimension sequentially
dim1 (i mod n) + 1 ;
// choose 2nd dimension uniformly random
// dimensions chosen Line 2
dim2 rand({1, ..., n)} \ {dim1 }) ;
// assign 1st non-zero value uniformly random
+1
val1 rand({
, 12 }) ;
2
// 2nd non-zero value
+1
val2 rand({
, 12 }) ;
2
// create sparse random index vector
random index vector [(dim1 , val1 ), (dim2 , val2 )] ;
// build feature-vector mapping
Dictionary.map(fi+1 , random index vector) ;
end
Algorithm 1: Feature Dictionary Lightweight Random Indexing.

feature indexes BoW representation; k = 2 minimum value actual
RI performed.
Algorithm 1 formalizes process creating dictionary, is, creating mapping
consisting one random vector original feature; mapping created training
time used classifying unlabelled documents(this means that, Line 1, F
set features present training set). value 1/ 2 used instead 1 order
obtain vectors length one. Note two dimensions selected different
manner, step Line 2 ensuring latent dimensions used approximately
number times, step Line 3 ensuring dimension chosen
previous step chosen twice.
proposal presents following advantages respect standard RI1% and,
general, respect RI k > 2:
index vector two non-zero values. mapping allocated
memory number original features, projection performed
quickly;
Given fixed value n, higher probability instantiation
RI generating truly pairwise orthogonal random vectors;
Parameter k becomes constant needs tuning.

163

fiMoreo, Esuli, & Sebastiani

4. Experiments
section experimentally compare Lightweight Random Indexing (LRI) method
representation approaches proposed literature.
4.1 Baselines Implementation Details
baselines compare LRI chosen following methods,
group three categories according common characteristics:
Orthogonal Mappings: methods using canonical basis co-occurrence matrix:
PolyBow: classifier operates juxtaposed BoW representation (PolyBow
corresponds NP-1C setup Garca Adeva et al., 2005).
FS: Feature Selection PolyBoW using Information Gain term scoring function Round Robin (Forman, 2004) term selection policy.
Majority Voting: multiview voting algorithm returns label output
highest number language-specific classifiers (Amini et al., 2009).
MonoBoW: lower bound baseline uses set nave monolingual classifiers
(MonoBoW corresponds NP-NC setup Garca Adeva et al., 2005).
MT: upper bound baseline based statistical machine translation, translates non-English training test documents English.
Random Mappings: dimensionality reduction methods relying random projections:
RI1% : Random Indexing k = n/100 (Sahlgren & Coster, 2004).
ACH: Achlioptas mapping ternary distribution obtained setting = 3
Equation 1 (Achlioptas, 2001).
Non-Random Mappings: dimensionality reduction methods relying mappings
random:
CL-LSA: Cross-Lingual Latent Semantic Analysis (Dumais et al., 1997).
MDM: Multilingual Domain Models (Gliozzo & Strapparava, 2005).
PLDA: Polylingual Latent Dirichlet Allocation (Mimno et al., 2009).
assume language labels available advance2 training testing
documents. Note RI methods PolyBoW represent documents
feature space, irrespective language label. Conversely, MonoBoW keeps separate
language-specific classifier language; class label test document
decided classifier associated documents language label. test PLDA
Majority Voting JRC-Acquis parallel corpus, since documents
require separate view languages available. Majority Voting maintains
separate classifier distinct language (5 experiments); test document
thus classified using 5 classification decisions voting, one language-specific
2. assumption fair, current language identification models deliver accuracies close 100%

164

fiLightweight Random Indexing Polylingual Text Classification

view. singular value decomposition used Rohde (2011) package.
used Haddow, Hoang, Bertoldi, Bojar, Heafield (2016) implementation generate
set statistical translation systems trained sentence-aligned parallel data provided
Europarl data release (Koehn, 2005). Note that, since used method described
Gliozzo Strapparava (2005) automatically obtain bilingual model MDM,
MT method using external knowledge. PLDA used Richardson
(2008) implementation, uses Gibbs sampling; adhere common practice
fixing budget iterations 1,000. implemented LRI method
baseline methods part Esuli, Fagni, Moreo (2016) framework.
used Support Vector Machines (SVMs) learning device cases, since
consistently delivered state-of-the-art results TC far; used well-known
Joachims (2009) implementation Joachims (2005), default parameters.
4.2 Evaluation Measures
effectiveness measure use well-known F1 , harmonic mean precision
() recall () defined F1 = (2)/( + ) = (T P )/(2T P + F P + F N ) P ,
F P , F N stand numbers true positives, false positives, false negatives,
respectively. take F1 = 1 P = F P = F N = 0, since classifier correctly
classified examples negative.
compute micro-averaged F1 (denoted F1 ) macro-averaged F1 (denoted
F1M ). F1 obtained (i) computing class-specific values Pr , F Pr , F Nr , (ii)
obtaining P summation Pr (same F P F N ), applying
F1 formula. F1M obtained first computing class-specific F1 values
averaging across classes. fact F1M attributes equal importance
classes means low-frequency classes important high-frequency ones
determining F1M scores; F1 instead influenced high-frequency classes
low-frequency ones. High values F1M thus tend indicate classifier performs well
also low-prevalence classes, high values F1 may indicate classifier
performs well high-prevalence classes.
4.3 Datasets
performed experiments two publicly available corpora, RCV1/RCV2 (a
comparable corpus) JRC-Acquis (a parallel corpus).
4.3.1 RCV1/RCV2
RCV1 publicly available collection consisting 804,414 English news stories generated Reuters 20 Aug 1996 19 Aug 1997 (Lewis, Yang, Rose, & Li, 2004). RCV2
instead polylingual collection, containing 487,000 news stories generated
timeframe thirteen languages English (Dutch, French, German, Chinese,
Japanese, Russian, Portuguese, Spanish, LatinoAmerican Spanish, Italian, Danish, Norwegian, Swedish). union RCV1 RCV2 (hereafter referred RCV1/RCV2)
corpus comparable topic-level, news stories direct translations
simply refer related events different languages. Since cor165

fiMoreo, Esuli, & Sebastiani

pus parallel, training document given language general
counterpart languages.
RCV1/RCV2 randomly selected 8,000 news stories 5 languages (English,
Italian, Spanish, French, German) pertaining last 4 months (from 1997-04-19
1997-08-19), performed 70%/30% train/test split, thus obtaining training set
28,000 documents (5,600 language) test set 12,000 documents (2,400
language)3 . experiments restricted attention 67 classes
(out 103) least one positive training example five languages.
average number classes per document 2.92, ranging minimum 1
maximum 11; number positive examples per class/language combination ranges
minimum 1 maximum 4,182.
preprocessed corpus removing stop words stemming terms using
Porter stemmer English, Snowball stemmer languages.
resulted total 123,258 stemmed terms, distributed across languages shown Table
1.

English
Italian
Spanish
French
German

English
40,483

Italian
3,420
14,762

Spanish
6,559
3,752
30,077

French
6,370
3,300
6,139
26,961

German
3,921
1,929
3,014
3,441
38,232

Appearing
1 languages
2 languages
3 languages
4 languages
5 languages

#
106,182
10,474
3,851
1,923
828

Table 1: Feature distribution across languages RCV1/RCV2 comparable corpus.
leftmost part table, cell row column j represents
number features shared across i-specific j-specific sections
dataset. (The table symmetric, better clarity entries
diagonal omitted.) rightmost part table indicates many
features shared across x language-specific sections dataset.

4.3.2 JRC-Acquis
JRC-Acquis corpus (version 3.0) version Acquis Communautaire collection
parallel legislative texts European Union law written 1950s 2006
(Steinberger, Pouliquen, Widiger, Ignat, Erjavec, Tufis, & Varga, 2006). JRC-Acquis
publicly available research purposes, covers 22 official European languages.
corpus parallel sentence-level, i.e., document exists 22 languages,
sentence-by-sentence translation. corpus labelled according ontology-based
EuroVoc thesaurus, consists 6,000 classes; experiments
restricted attention 21 classes top level EuroVoc hierarchy.
3. information required replicate experiments, e.g., IDs selected documents, assigned
labels, etc., publicly available (Moreo, 2016). source code used experiments accessible
part Esuli et al. (2016) framework

166

fiLightweight Random Indexing Polylingual Text Classification

English
Italian
Spanish
French
German

English
150,866

Italian
77,878
150,838

Spanish
80,220
95,515
143,712

French
89,573
90,522
88,561
147,077

German
98,740
78,919
85,434
86,905
228,834

Appearing
1 languages
2 languages
3 languages
4 languages
5 languages

#
249,216
42,566
33,305
22,171
59,676

Table 2: Feature distribution across languages JRC-Acquis parallel corpus;
meaning cells Table 1. Note high number features (59,676) appear five languages; due presence
proper names, languages. Note also high number
features (228,834) unique German language: due
presence word compounds, phenomenon present German language
four languages.

selected 7,235 texts 2006 5 languages (English, Italian, Spanish,
French, German) removed documents without labels, thus obtaining 6,980 documents per language. taken first 70% documents training (24,430, i.e.,
4,886 language) remaining 30% (10,470, i.e., 2,094 language)
testing. average number classes per document 3.5, ranging minimum
1 maximum 10; number positive examples per class/language combination
ranges minimum 47 maximum 2,011.
preprocessing RCV1/RCV2 carried dataset, obtaining 406,934 distinct features distributed across languages shown Table 2. Since
JRC-Acquis corpus parallel, language-specific document guaranteed
counterpart languages, results relatively large number
terms (e.g., proper nouns) appearing several languages. Note that, despite fact
dataset parallel sentence level, interested indexing entire documents
whole, thus disregard sentence order; thus consider corpus parallel
document level.
use JRC-Acquis corpus order test performance LRI cases
co-occurrence matrix compacted, defined work Dumais et al.
(1997). precisely, compact representation |L| translation-equivalent documents
vector consisting concatenation |L| vectors represent one (monolingual) document. different juxtaposed representation used
previous chapters, vector corresponding one monolingual document
zeros positions corresponding features languages. compact
matrix thus obtained matrix resulting juxtaposed representations
compressing |L| rows single (compact) row storing sum.
167

fiMoreo, Esuli, & Sebastiani

4.4 Results
section present results experiments. first compare LRI set
monolingual classifiers (Section 4.4.1), explore dimensionality reduction
aspect polylingual problem (Section 4.4.2).
4.4.1 Polylingual Information
first case study, investigate much addition polylingual information
affects accuracy monolingual classifier. scenario, compare LRI
PolyBoW, train documents languages, lower bound MonoBoW,
trains documents language test documents, upper
bound MT, first translates training test documents English. Note
MT baseline tested JRC-Acquis corpus documents
already available direct translation languages. experiment vector space
reduced, i.e., set n = |F | LRI vector spaces PolyBoW
LRI number dimensions. Values LRI averaged 10 runs.
results illustrated Figure 2 show simple addition examples different languages (PolyBoW) brings improvement accuracy respect
monolingual solution (MonoBoW). improvement likely achieved thanks words
shared across languages. However, LRI clearly outperforms PolyBoW. improvements
PolyBoW MonoBoW range -0.4% +29.7%, LRI achieves improvements ranging +9.7% +41.1%; LRI obtains smallest improvement
MonoBoW terms F1M (on Italian, +9.7%), PolyBoW performs slightly worse
MonoBoW (-0.4%). improvements marked F1M F1 , indicating
improvements especially take place infrequent classes,
substantial impact F1M F1 .
general, training documents coming languages (PolyBoW, LRI, MT)
seems preferable training language-specific documents (MonoBoW).
particularly MT baseline, obtained best results cases
sole exception English, LRI obtained best result. exception might
explained fact automatically translated documents tend exhibit different
statistical properties respect documents written humans, means
English test documents (which translations) might tune training
documents (which mostly result automatic translation).
language-specific classification performance much homogeneous JRCAcquis RCV1/RCV2. explained fact JRC-Acquis parallel
corpus, therefore language benefits information.
significant difference performance among different languages, means
effects due different difficulty various languages minor. Instead, differences
RCV1/RCV2 explained different amount information training
sets carry corresponding test sets. example, Spanish classifier worst
performer, one obtains best benefit (with respect MonoBoW
baseline) addition polylingual information (as PolyBoW, LRI, MT).
168

fiLightweight Random Indexing Polylingual Text Classification

Figure 2: Monolingual classification RCV1/RCV2 (top) JRC-Acquis (bottom), using F1M (left) F1 (right) evaluation measure.

Note experiment matrices PolyBoW LRI feed learning
algorithm size. difference two methods, likely
cause difference effectiveness, PolyBoW useful dimensions
specific language packed specific portion vector space, LRI spreads
across entire vector space, causing dimensions become potentially useful
languages. Note substantial increase number useful dimensions
available language allows model create easily separable representations.
discuss aspect Section 5.3.
4.4.2 Dimensionality Reduction
PolyBoW setup dimensionality vector space substantially increased
languages considered training. following experiments explore
dimensionality reduction aspect problem, address realistic polylingual
scenario, training test data contain examples language.
169

fiMoreo, Esuli, & Sebastiani

n
MonoBoW
PolyBoW
MT
CL-LSA
MDM
ACH
RI1%
LRI

500
0.273
0.365
0.472
0.366
0.426
0.375

1,000
0.353
0.399
0.493
0.389
0.483
0.464

F1M
5,000
0.444
0.513
0.539
0.547

10,000
0.472
0.530
0.543
0.554

full
0.473
0.498
0.509
0.570

500
0.668
0.765
0.769
0.621
0.683
0.679

1,000
0.736
0.777
0.771
0.610
0.705
0.736

F1
5,000
0.786
0.736
0.756
0.792

10,000
0.795
0.755
0.775
0.802

full
0.802
0.804
0.808
0.811

Figure 3: Effects dimensionality reduction RCV1/RCV2 (English Italian). Dotted
lines indicate reference values, e.g., green red lines represent performance
LRI PolyBoW, respectively, dimensionality reduced. Values
bold highlights best performing method dimension.

first run sample bilingual experiment RCV1/RCV2 (as language
English picked Italian). total amount features dataset
51,828. Restricting experiment two languages allows us compare LRI (i)
methods proposed bilingual representations (MDM), (ii) methods
would computationally expensive considering languages (such ACH,
see below). explore effect dimensionality reduction, number selected
features ranging 500 10,000 (Figure 3). adhere common practice
establishes number dimensions ranging 500 1000 LSA MDM. Results
random projection methods (ACH, RI1% , LRI) averaged 10 runs.
LRI obtains good results macro- micro-averaged F1 , methods exhibit alternating performance two measures. RI1% obtains comparable results
terms F1M performs poorly F1 ; contrast, PolyBoW performs comparably
terms F1 worse terms F1M . two-tailed t-test paired examples reveals
difference terms F1M LRI RI1% statistically significant,
170

fiLightweight Random Indexing Polylingual Text Classification

n
MonoBoW
PolyBoW
MT
CL-LSA
RI1%
LRI

500
0.254
0.351
0.300
0.270

1,000
0.308
0.384
0.402
0.376

F1M
5,000
0.420
0.482
0.491

10,000
0.445
0.501
0.511

full
0.415
0.483
0.521
0.528

500
0.606
0.728
0.580
0.573

1,000
0.657
0.746
0.649
0.659

F1
5,000
0.747
0.696
0.749

10,000
0.764
0.733
0.766

full
0.753
0.781
0.793
0.786

Figure 4: Accuracy different PLTC methods RCV1/RCV2 5 languages, different
levels dimensionality reduction.

LRI significantly outperforms RI1% F1 rest dimensionality reduction
methods evaluation measures, p < 0.001. Surprisingly, CL-LSA MDM
perform worse nave classifier (MonoBoW) features. However,
remarked outperform baselines 500 1000 dimensions.
seen Section 5, apart drastic dimensionality reduction, methods affected large computational costs negatively impact run times
memory resources needed. Consistently previous observations (see Figure 2), LRI,
PolyBoW, MonoBoW, MT comparable terms F1 , LRI outperforms
tested algorithms terms F1M .
test scalability method several languages involved, extend
experiment five languages (English, Italian, Spanish, French, German) RCV1/RCV2
(Figure 4). Note case algorithms able complete execution
due memory constraints, hence incomplete plots table; concretely, ACH
last iterations RI1% overflowed memory resources trying allocate 28, 000
123, 258 matrix. insights space time complexity reported Section 5.
Results RI1% LRI average 10 runs use different random seeds.
results confirm previous observations. RI1% behaves similarly LRI terms
F1M (i.e., statistically significant difference) worse terms F1 (p <0.001),
171

fiMoreo, Esuli, & Sebastiani

n
PolyBoW
CL-LSA
PLDA
Majority Vote
RI1%
LRI

500
0.365
0.570
0.456
0.543
0.524

1,000
0.416
0.593
0.463
0.581
0.581

F1M
5,000
0.534
0.655
0.659

10,000
0.570
0.680
0.672

full
0.640
0.656
0.688

500
0.560
0.725
0.644
0.656
0.660

1,000
0.606
0.739
0.650
0.676
0.702

F1
5,000
0.697
0.743
0.764

10,000
0.723
0.770
0.776

full
0.768
0.759
0.789

Figure 5: Accuracy different PLTC methods JRC-Acquis 5 languages, different
levels dimensionality reduction.

PolyBoW behaves opposite way, i.e., performs worse LRI terms
F1M (p < 0.001) comparably terms F1 . dimensionality reduction method,
LRI thus outperforms methods considering F1M F1 ;
dimensionality reduction applied, upper bound MT comparable LRI
F1M F1 .
Finally, used JRC-Acquis reproduce one last polylingual scenario, namely, one
texts aligned document level. Even situation common
practice (exceptions include, say, proceedings official events), scenario interesting
since dataset may serve test bed multiview learning methods (Amini et al.,
2009). Since documents JRC-Acquis translated humans, results affected
noise MT tools might introduce. Figure 5 shows results obtained considering
compacted matrix JRC-Acquis (a 4, 886 406, 934 matrix), also tested Majority Voting, combines classification decisions five independently trained
MonoBoW classifiers parallel versions documents, PLDA, first defines
generative model based polylingual topics trains tests probability distributions topics assigned document. set number polylingual
latent topics 500 1000, respectively.
LRI clearly superior PolyBoW case. difference performance
LRI RI1% seems lower case, especially terms F1M ; t-test revealed
172

fiLightweight Random Indexing Polylingual Text Classification

however LRI superior RI1% statistically significant sense (p <0.001). However,
considered LRI delivers best performance without reducing dimensionality polylingual matrix, RI1% able accomplish projection due
memory restrictions; something expand following section. PLDA,
turn, succeeded discovering polylingual topics aligned across languages,
proved less effective terms classification performance.

5. Analysis
experiments observed substantial differences terms efficiency among
compared methods, particularly ACH, RI1% , LRI. example, RI1%
exhausted memory resources n 10, 000, LRI able represent even fullsized |D||F | matrix (see Figure 4). Given strong relationship two methods,
would expected delivered similar performance. anomaly prompted us
investigate issue depth. section presents analytical study terms
efficiency methods discussed previous section.
5.1 Space Efficiency
Data samples ML usually represented co-occurrence matrix. TC matrix
suffers high-dimensionality, luckily enough also sparse. sparse, low-density
matrix suggests use non-exhaustive data-structure, zero values
stored explicitly.
random projection direct impact sparsity. feature contained
document, k non-zero values placed projected matrix. ACH situation
worse, since feature mapped, average, n/3 non-zero values. example,
n = 5, 000 feature mapped 50 1,666 non-zero values RI1%
ACH, respectively.
example, rerun RCV1/RCV2 experiments English Italian
languages, examined matrix density (percentage non-zero values
total matrix size) memory footprint (absolute number non-zero values).
results displayed Figure 6.
LRI requires double space respect standard BoW, succeeds preserving
sparsity, RI1% drastically increases matrix density produces large memory
footprint. MDM, LSA, ACH operate dense matrices. However, since MDM
LSA produce extreme dimensionality reduction, overall memory footprint remains
much lower RI1% and, especially, ACH. n = |F |, LRI must allocate
1, 844103 values (this indicated LRI (full) Figure 6), RI1% (n = 5000)
must allocate 28, 463 103 values (requiring 15.42 times space); ACH (n = 5000)
must allocate 55, 998 103 values (30.35 times space). Note even though MDM
LSA reduce significantly dimensionality (e.g., 51,828 500, 1,000),
need allocate values memory LRI (full).
example, let us suppose non-zero value represented double
(typically: 8 bytes modern programming languages); means roughly need
428MB ACH 218MB RI1% , whereas LRI requires 15MB. Although
difference substantial, (even taking account actual memory needed higher
173

fiMoreo, Esuli, & Sebastiani

Figure 6: Matrix density (left) memory footprint (right) RCV1/RCV2 EnglishItalian run (11, 200 51, 828 full training matrix size).

values indexed hash table) still represent real problem
terms space modern computers. However, note matrix
data structure need allocate memory. Also mapping dictionary, i.e., data
structure linking original feature random index vector, allocated
memory. dictionary queried many times terms document
want classify. dictionary small enough (which LRI), may able
allocate cache order significantly speed indexing new documents.
Assuming sparse representation, random index vector described list k
pairs (di , vi ), di indicates latent dimension vi encodes value. example,
k = 2 random vector (0, 0, +1, 0, 1, 0, ...) could represented [(3, 1), (5, 0)],
bit set 1 encodes +1 bit set 0 encodes 1. Equation 5,
space occupation dictionary random indexing method depends (i) |F |,
number indexes; (ii) k, number non-zero values index; (iii)
number bits needed indicate one latent position encode possible non-trivial
values; is,
Cost(RIk ) = O(|F | k (log2 n + log2 2))

(5)

turns that, given expected number non-zero values ACH n/3, using
dense representation index cheaper. position thus indicates one
three possible values index. cost terms space ACH index dictionary
described
Cost(ACH) = O(|F | n log2 3)
174

(6)

fiLightweight Random Indexing Polylingual Text Classification

Method
LRI
RI1%
ACH

Index type
sparse
sparse
dense

Index size
2
100
10,000

Index cell
log2 n + log2 2 bits encode dimi vali , resp.
log2 n + log2 2 bits encode dimi vali , resp.
log2 3 bits encode ij

Memory required
1.39MB
69.31MB
768.87MB

Table 3: Memory occupation feature dictionary different random mapping methods JRC-Acquis dataset (|F | = 406, 934). meanings dimi vali
Algorithm 1. meaning ij Equation 1.

Assuming reduced dimensionality set fixed percentage original dimensionality, i.e., n = |F | 0 < 1, following hold:
Cost(RI) = O(|F |2 log2 |F |) >
Cost(ACH) = O(|F |2 ) >

(7)

Cost(LRI) = O(|F | log2 |F |)
However, hidden constants play key role practice. example, computed
total amount memory required method storing index dictionaries
n = 10, 000 JRC-Acquis, |F | = 406, 934; resulting values reported Table
3. observed, index dictionary ACH requires 769MB, space
required RI-based versions one three orders magnitude smaller.
words, index dictionary LRI could easily fit current cache memories, RI1%
ACH need resort higher-capacity, thus slower, storage devices.
5.2 Time Efficiency
usually case sparsity benefits space occupation, also execution
time. example, computational cost SVD O(|F |2 |D|) document-by-term
matrix; however, implementation SVDLIBC specifically optimized sparse matrices
requires O(c|F ||D|) steps, c average number non-zero values vector.
Figure 7 plot run times experiments bilingual (English-Italian)
RCV1/RCV2 experiment paying attention time required (i) obtaining
transformed index training set, (ii) training learning algorithm (SVM), (iii)
obtaining transformed index test set, (iv) classifying test documents.
experiments run Intel i7 64bit processor 12 cores, running
1,600MHz, 24GBs RAM memory.
results show takes 3.5 minutes generate test classifier
uses BoW representation. Time slightly reduced 3 minutes
5000 features selected. total time LRI roughly higher factor 2,
7.3 (full) 6.6 (n = 5000) minutes, respectively. Notwithstanding this, figures
still low compared methods: training testing times grow
substantially RI ACH. Regarding latent methods, pointed
time required preparing matrices also grow substantially, due large
175

fiMoreo, Esuli, & Sebastiani

Figure 7: Run times RCV1/RCV2 (English Italian setting).

computational cost inherent SVD matrix multiplication, case random
indexing methods times negligible.
comparing overall memory footprint (Figure 6, right) execution times (Figure 7) seems clear strong correlation them. investigated
dependency experiments computing Pearson correlation them.
Pearson correlation quantifies degree linear dependence two variables,
ranges 1, meaning perfect negative correlation, +1, meaning perfect positive
correlation, whereas 0 means linear dependency. found linear
Pearson correlation +0.988 +0.998 number non-zero values
matrix times required training testing, respectively, brings additional
support observation: preserving sparsity projection favours execution
times PLTC.
5.3 Effect k Random Indexing
Previous work RI (see, e.g., Sahlgren & Karlgren, 2005; Sahlgren & Coster, 2004) tend
set k 1% dimension vector; smaller values k (about k = 0.1%)
also explored (Karlgren, Holst, & Sahlgren, 2008). works related random
projections (see, e.g., Achlioptas, 2001; Li et al., 2006) noticed sparse projection
matrices help speed computation.
Besides run times, sparsity projection matrix also affects orthogonality
random projection, turn impact preservation relative
distances. Two random vectors ri rj said orthogonal angle
90 degrees. Although probability two randomly picked vectors
orthogonal increases dimensionality vector space grows (Karlgren et al., 2008),
random projection approaches choose sparse random vectors, maximize
probability.
176

fiLightweight Random Indexing Polylingual Text Classification

Figure 8: Probability distribution angle two arbitrary vectors highdimensional space (left), excess kurtosis function non-zero values
projection matrix 10,000 dimensions (right).

could thus establish parallelism degree orthogonality projection matrix probability distribution angle two random vectors.
probability distribution skewed towards 90 degrees, closer orthogonal
projection base is, better distances preserved. propose quantify
orthogonality means excess kurtosis distribution angle4 . aim,
studied kurtosis angle distributions (as estimated via Monte Carlo
algorithm) varies function matrix sparsity k 10,000-dimension projection
matrix (Figure 8, right).
Figure 8 shows orthogonality projection, fixed dimensionality,
rapidly degrades density increases. LRI thus expected produce nearly
orthogonal indexing, followed RI ACH.
investigated relation orthogonality PLTC accuracy.
aim, run series experiments bilingual version RCV1/RCV2,
varying (from 2 100) number k non-zero values (from 1,000 10,000)
reduced dimensionality n. Figure 9 shows contour lines (equally valued points
3-dimensional representation) classification performance (here measured terms
F1 ), execution time, probability pairwise orthogonality (i.e., probability
hri , rj = 0 two randomly chosen random index vectors).
following trends directly observed results: (i) accuracy improves
n increases k decreases; (ii) run times tend grow n k increase,
(iii) higher dimensionality n smaller parameter k, higher
probability finding two orthogonal random indexes.
4. excess kurtosis random variable X typically defined fourth standardized moment minus
3, i.e., EKurt[X] = 44 3.

177

fiMoreo, Esuli, & Sebastiani

Figure 9: Impact dimensionality n (on x axis) number k non-zero values (on
axis) classification accuracy (left), execution time (center), probability
finding orthogonal pair random indexes (right). Darker regions represent
lower values.

Figure 9, behaviour LRI method propose described green
horizontal line bottom plot, RIs behaviour described blue
diagonal line coordinates (n = 1, 000, k = 10) (n = 10, 000, k = 100). performance RI improves cost space time efficiency, gradually disrupting
orthogonality base. contrary, following desirable features LRI
evident: dimensionality increases (i) accuracy improves without penalizing execution
times, due preservation sparsity, (ii) orthogonality base improved.

6. Conclusions
compared several techniques polylingual text classification, checking suitability dimensionality reduction techniques techniques generation alternative representations co-occurrence matrix, two PLTC benchmarks (one parallel
one comparable). investigation indicates reducing dimensionality
data sufficient reasonable efficiency (in terms time space) required.
Based observation proposed variant Random Indexing, method originated within IR community that, best knowledge, never tested
PLTC date. proposal, Lightweight Random Indexing, yielded best results
terms (both time space) efficiency, also terms classification accuracy,
Lightweight Random Indexing obtained best results terms macroand micro-averaged F1 . Lightweight Random Indexing preserves matrix sparsity,
means memory footprint training time penalized. example,
Figures 6 7 may see Lightweight Random Indexing (in full configuration
is, random vectors dimensionality original space)
improved Latent Semantic Analysis (in n = 1, 000 configuration is,
178

fiLightweight Random Indexing Polylingual Text Classification

dimensionality reduced space 1,000) margin +4.37% terms F1
89.69% reduction execution time 82.60% reduction memory footprint.
Even though Lightweight Random Indexing works well dimensionality reduction method, achieves best performance projection reduce
original dimensionality. Apparently, BoW representation might expected
preferable case, truly orthogonal. However, polylingual BoW
representation features informative restricted set data; e.g.,
German term entire dimension reserved vector space model,
dimension useful documents written German. Random projections instead
map feature space space shared among languages once. effect
dimension space becomes informative represent documents regardless
language originally written in. configuration, projection
space larger actual number different features single language, reminiscent kernel-trick effect, informative space language enlarged
thus becomes easily separable.
light experiments, Lightweight Random Indexing important advantages
respect previous PLTC approaches. First, method machine translationfree, dictionary-free, require sort additional resources apart
labelled collection. projected matrix preserves sparsity, direct effect
reducing running time total memory usage. respect original random
indexing technique, Lightweight Random Indexing presents following advantages: (i)
probability finding pair truly orthogonal indexes higher; (ii) requires less memory
allocate index dictionary; (iii) avoids need tuning k parameter.
LRI proven effective PLTC, conjecture could bring similar
benefits related tasks, CLTC, cross-lingual information retrieval, well
tackling problems dealing sparse heterogeneous sources data general.
discussed above, one reasons k = 2 safe configuration still preserves
representation capacity. However, might hold circumstances; e.g.,
processing huge streams dynamic data (e.g., streams tweets), certain
point representation capacity might saturate dimensionality space
chosen carefully. cases, opting configurations k > 2 might mitigate
problem.
Another fact emerges experiments dimensionality reduction
necessarily synonym computational efficiency. reason modern secondary
storage data structures optimized operate sparse data, dimensionality drastically reduced, matrix density may increase, net effect may decrease
efficiency. true benefit thus achieved extent trade-off sparsity
separability preserved; dimension, LRI proved extremely effective.
Although results encouraging, investigations still needed shed
light foundations random projection methods. first question whether
criterion better choose random index vectors; given current criterion
random, seems might room better motivated strategies, possibly leveraging
class labels taking account document language labels. Considering
Random Indexing originally proposed context IR community, wonder
whether proposed approach could produce similar improvements IR tasks
179

fiMoreo, Esuli, & Sebastiani

query expansion bilingual lexicon acquisition. Finally, could interesting combine
Lightweight Random Indexing Reflexive Random Indexing (Cohen, Schvaneveldt, &
Widdows, 2010; Rangan, 2011), recent formulation model iteratively
alternates row indexing column indexing original co-occurrence matrix.

Acknowledgements
Fabrizio Sebastiani leave Consiglio Nazionale delle Ricerche, Italy.

References
Achlioptas, D. (2001). Database-friendly random projections. Proceedings 20th
ACM Symposium Principles Database Systems (PODS 2001), pp. 274281,
Santa Barbara, US.
Al-Rfou, R., Perozzi, B., & Skiena, S. (2013). Polyglot: Distributed word representations
multilingual NLP. Proceedings 17th Conference Computational Natural
Language Learning (CoNLL 2013), pp. 183192, Sofia, BL.
Amini, M.-R., & Goutte, C. (2010). co-classification approach learning multilingual corpora. Machine Learning, 79 (1/2), 105121.
Amini, M.-R., Usunier, N., & Goutte, C. (2009). Learning multiple partially observed
views; application multilingual text categorization. Proceedings 23rd
Annual Conference Neural Information Processing Systems (NIPS 2009), pp. 28
36, Vancouver, CA.
Baroni, M., Dinu, G., & Kruszewski, G. (2014). Dont count, predict! systematic comparison context-counting vs. context-predicting semantic vectors. Proceedings
52nd Annual Meeting Association Computational Linguistics (ACL
2014), pp. 238247, Baltomore, US.
Bel, N., Koster, C. H., & Villegas, M. (2003). Cross-lingual text categorization. Proceedings 7th European Conference Research Advanced Technology
Digital Libraries (ECDL 2003), pp. 126139, Trondheim, NO.
Bengio, Y. (2009). Learning deep architectures AI. Foundations Trends Machine
Learning, 2 (1), 1127.
Bengio, Y., Schwenk, H., Senecal, J.-S., Morin, F., & Gauvain, J.-L. (2006). Neural probabilistic language models. Innovations Machine Learning, pp. 137186. Springer,
Heidelberg, DE.
Bingham, E., & Mannila, H. (2001). Random projection dimensionality reduction: applications image text data. Proceedings 7th ACM International
Conference Knowledge Discovery Data Mining (KDD 2001), pp. 245250, San
Francisco, US.
Blei, D. M., Ng, A. Y., & Jordan, M. I. (2003). Latent Dirichlet allocation. Journal
Machine Learning Research, 3, 9931022.
180

fiLightweight Random Indexing Polylingual Text Classification

Bullinaria, J. A., & Levy, J. P. (2007). Extracting semantic representations word
co-occurrence statistics: computational study. Behavior Research Methods, 39 (3),
510526.
Chandar, S., Lauly, S., Larochelle, H., Khapra, M. M., Ravindran, B., Raykar, V. C., & Saha,
A. (2014). autoencoder approach learning bilingual word representations.
Proceedings 28th Annual Conference Neural Information Processing Systems
(NIPS 2014), pp. 18531861, Montreal, CA.
Cohen, T., Schvaneveldt, R., & Widdows, D. (2010). Reflective random indexing indirect inference: scalable method discovery implicit connections. Journal
Biomedical Informatics, 43 (2), 240256.
Collobert, R., Weston, J., Bottou, L., Karlen, M., Kavukcuoglu, K., & Kuksa, P. (2011).
Natural language processing (almost) scratch. Journal Machine Learning
Research, 12, 24932537.
de Melo, G., & Siersdorfer, S. (2007). Multilingual text classification using ontologies.
Proceedings 29th European Conference Information Retrieval (ECIR 2007),
pp. 541548, Roma, IT.
Deerwester, S. C., Dumais, S. T., Furnas, G. W., Landauer, T. K., & Harshman, R. A.
(1990). Indexing latent semantic analysis. Journal American Society
Information Science, 41 (6), 391407.
Dumais, S. T., Letsche, T. A., Littman, M. L., & Landauer, T. K. (1997). Automatic crosslanguage retrieval using latent semantic indexing. Working Notes AAAI
Spring Symposium Cross-language Text Speech Retrieval, pp. 1824, Stanford,
US.
Ehrmann, M., Cecconi, F., Vannella, D., McCrae, J. P., Cimiano, P., & Navigli, R. (2014).
Representing multilingual data linked data: case BabelNet 2.0. Proceedings 9th Conference Language Resources Evaluation (LREC 2014), pp.
401408, Reykjavik, IS.
Esuli, A., Fagni, T., & Moreo, A. (2016). JaTeCS (Java Text Categorization System).
Github. Retrieved September 11, 2016, https://github.com/jatecs/jatecs.
Faruqui, M., & Dyer, C. (2014). Improving vector space word representations using multilingual correlation. Proceedings 14th Conference European Chapter
Association Computational Linguistics (EACL 2014), pp. 462471, Gothenburg,
SE.
Forman, G. (2004). pitfall solution multi-class feature selection text classification. Proceedings 21st International Conference Machine Learning
(ICML 2004), pp. 3845, Banff, CA.
Fradkin, D., & Madigan, D. (2003). Experiments random projections machine
learning. Proceedings 9th ACM International Conference Knowledge
Discovery Data Mining (KDD 2003), pp. 517522, Washington, US.
Garca Adeva, J. J., Calvo, R. A., & Lopez de Ipina, D. (2005). Multilingual approaches
text categorisation. European Journal Informatics Professional, 6 (3), 4351.
181

fiMoreo, Esuli, & Sebastiani

Gliozzo, A., & Strapparava, C. (2005). Cross-language text categorization acquiring
multilingual domain models comparable corpora. Proceedings ACL
Workshop Building Using Parallel Texts, pp. 916, Ann Arbor, US.
Gliozzo, A., & Strapparava, C. (2006). Exploiting comparable corpora bilingual dictionaries cross-language text categorization. Proceedings 44th Annual
Meeting Association Computational Linguistics (ACL 2006), pp. 553560,
Sydney, AU.
Gorman, J., & Curran, J. R. (2006). Random indexing using statistical weight functions.
Proceedings 4th Conference Empirical Methods Natural Language Processing (EMNLP 2006), pp. 457464, Sydney, AU.
Gouws, S., & Sgaard, A. (2015). Simple task-specific bilingual word embeddings.
Proceedings North American Chapter Association Computational
Linguistics Human Language Technologies Conference (NAACL-HLT 2015), pp.
13861390.
Haddow, B., Hoang, H., Bertoldi, N., Bojar, O., & Heafield, K. (2016). MOSES statistical
machine translation system. Moses website. Retrieved September 11, 2016,
http://www.statmt.org/moses/.
Harris, Z. S. (1968). Mathematical structures language. Wiley, New York, US.
Hecht-Nielsen, R. (1994). Context vectors: General-purpose approximate meaning representations self-organized raw data. Computational Intelligence: Imitating Life,
pp. 4356. IEEE Press.
Hermann, K. M., & Blunsom, P. (2014). Multilingual models compositional distributed
semantics. Proceedings 52nd Annual Meeting Association Computational Linguistics (ACL 2014), pp. 5868, Baltimore, US.
Joachims, T. (2009). SVMperf: Support Vector Machine multivariate performance
measures. Cornell University website. Retrieved September 11, 2016,
http://www.cs.cornell.edu/people/tj/svm_light/svm_perf.html.
Joachims, T. (2005). support vector method multivariate performance measures.
Proceedings 22nd International Conference Machine Learning (ICML 2005),
pp. 377384, Bonn, DE.
Johnson, W. B., Lindenstrauss, J., & Schechtman, G. (1986). Extensions Lipschitz maps
Banach spaces. Israel Journal Mathematics, 54 (2), 129138.
Jurgens, D., & Stevens, K. (2009). Event detection blogs using temporal random indexing.
Proceedings Workshop Events Emerging Text Types, pp. 916, Borovets,
BG.
Kanerva, P., Kristofersson, J., & Holst, A. (2000). Random indexing text samples latent semantic analysis. Proceedings 22nd Annual Conference Cognitive
Science Society (CogSci 2000), p. 1036, Philadelphia, US.
Karlgren, J., Holst, A., & Sahlgren, M. (2008). Filaments meaning word space.
Proceedings 30th European Conference Information Retrieval (ECIR 2008),
pp. 531538, Glasgow, UK.
182

fiLightweight Random Indexing Polylingual Text Classification

Kaski, S. (1998). Dimensionality reduction random mapping: Fast similarity computation
clustering. Proceedings IEEE International Joint Conference Neural
Networks (IJCNN 1998), pp. 413418, Anchorage, US.
Klementiev, A., Titov, I., & Bhattarai, B. (2012). Inducing crosslingual distributed representations words. Proceedings 24th International Conference Computational Linguistics (COLING 2012), pp. 14591474, Mumbai, IN.
Koehn, P. (2005). Europarl: parallel corpus statistical machine translation. MT
summit, Vol. 5, pp. 7986. Publicly available http://www.statmt.org/europarl/.
Lauly, S., Boulanger, A., & Larochelle, H. (2014). Learning Multilingual Word Representations using Bag-of-Words Autoencoder. ArXiv e-prints, arXiv:1401.1803 [cs.CL].
Lewis, D. D., Yang, Y., Rose, T. G., & Li, F. (2004). Rcv1: new benchmark collection
text categorization research. Journal machine learning research, 5 (Apr), 361397.
Publicly available http://www.jmlr.org/papers/volume5/lewis04a/lyrl2004_
rcv1v2_README.htm.
Li, P., Hastie, T. J., & Church, K. W. (2006). sparse random projections. Proceedings
12th ACM SIGKDD International Conference Knowledge Discovery
Data Mining (KDD 2006), pp. 287296, Philadelphia, US.
Li, Y., & Shawe-Taylor, J. (2007). Advanced learning algorithms cross-language patent
retrieval classification. Information Processing Management, 43 (5), 1183
1199.
Mikolov, T., Le, Q. V., & Sutskever, I. (2013a). Exploiting Similarities among Languages
Machine Translation. ArXiv e-prints, arXiv:1309.4168 [cs.CL].
Mikolov, T., Sutskever, I., Chen, K., Corrado, G. S., & Dean, J. (2013b). Distributed
representations words phrases compositionality. Proceedings
27th Annual Conference Neural Information Processing Systems (NIPS 2013), pp.
31113119, Lake Tahoe, US.
Mimno, D., Wallach, H. M., Naradowsky, J., Smith, D. A., & McCallum, A. (2009). Polylingual topic models. Proceedings 2009 Conference Empirical Methods
Natural Language Processing (EMNLP 2009), pp. 880889, Singapore, SN.
Moreo, A. (2016). Data resources reproducing experiments polylingual text classification. Human Language Technologies (HLT) group website. Retrieved September
11, 2016, http://hlt.isti.cnr.it/pltc.
Nastase, V., & Strapparava, C. (2013). Bridging languages etymology: case
cross-language text categorization. Proceedings 51st Annual Meeting
Association Computational Linguistics (ACL 2013), pp. 651659, Sofia, BL.
Osterlund, A., Odling, D., & Sahlgren, M. (2015). Factorization latent variables distributional semantic models. Proceedings Conference Empirical Methods
Natural Language Processing (EMNLP 2015), pp. 227231, Lisbon, PT.
Pan, S. J., & Yang, Q. (2010). survey transfer learning. IEEE Transactions
Knowledge Data Engineering, 22 (10), 13451359.
183

fiMoreo, Esuli, & Sebastiani

Papadimitriou, C. H., Raghavan, P., Tamaki, H., & Vempala, S. (1998). Latent semantic
indexing: probabilistic analysis. Proceedings 17th ACM Symposium
Principles Database Systems (PODS 1998), pp. 159168, Seattle, US.
Pennington, J., Socher, R., & Manning, C. D. (2014). Glove: Global vectors word
representation. Proceedings Conference Empirical Methods Natural
Language Processing (EMNLP 2014), pp. 15321543, Doha, QA.
Prettenhofer, P., & Stein, B. (2010). Cross-language text classification using structural
correspondence learning. Proceedings 48th Annual Meeting Association
Computational Linguistics (ACL 2010), pp. 11181127, Uppsala, SE.
Rangan, V. (2011). Discovery related terms corpus using reflective random indexing. Proceedings ICAIL 2011 Workshop Setting Standards Searching
Electronically Stored Information, Pittsburgh, US.
Richardson, J. (2008). PolyLDA++. Atlassian Bitbucket. Retrieved September 11, 2016,
https://bitbucket.org/trickytoforget/polylda.
Rigutini, L., Maggini, M., & Liu, B. (2005). EM-based training algorithm crosslanguage text categorization. Proceedings 3rd IEEE/WIC/ACM International Conference Web Intelligence (WI 2005), pp. 529535, Compiegne, FR.
Rohde, D. (2011). C library computing singular value decompositions. SVDLIBC.
Retrieved September 11, 2016, http://tedlab.mit.edu/~dr/SVDLIBC/.
Sahlgren, M. (2001). Vector-based semantic analysis: Representing word meanings based
random labels. Proceedings ESSLLI Workshop Semantic Knowledge
Acquistion Categorization, Helsinki, FI.
Sahlgren, M. (2005). introduction random indexing. Proceedings Workshop
Methods Applications Semantic Indexing, Copenhagen, DK.
Sahlgren, M. (2006). Word-Space Model: Using distributional analysis represent syntagmatic paradigmatic relations words high-dimensional vector spaces.
Ph.D. thesis, Swedish Institute Computer Science, University Stockholm, Stockholm, SE.
Sahlgren, M., & Coster, R. (2004). Using bag-of-concepts improve performance
support vector machines text categorization. Proceedings 20th International Conference Computational Linguistics (COLING 2004), Geneva, CH.
Sahlgren, M., & Karlgren, J. (2005). Automatic bilingual lexicon acquisition using random
indexing parallel corpora. Natural Language Engineering, 11 (3), 327341.
Sahlgren, M., Karlgren, J., Coster, R., & Jarvinen, T. (2002). SICS CLEF 2002: Automatic query expansion using random indexing. Working Notes CrossLanguage Evaluation Forum Workshop (CLEF 2002), pp. 311320, Roma, IT.
Steinberger, R., Pouliquen, B., & Ignat, C. (2004). Exploiting multilingual nomenclatures
language-independent text features interlingua cross-lingual text analysis
applications. Proceedings 4th Slovenian Language Technology Conference,
Ljubljana, SL.
184

fiLightweight Random Indexing Polylingual Text Classification

Steinberger, R., Pouliquen, B., Widiger, A., Ignat, C., Erjavec, T., Tufis, D., & Varga,
D. (2006). JRC-Acquis: multilingual aligned parallel corpus 20+ languages. Proceedings 5th International Conference Language Resources
Evaluation (LREC 2006), pp. 21422147, Genova, IT. Publicly available
https://ec.europa.eu/jrc/en/language-technologies/jrc-acquis.
Vinokourov, A., Shawe-Taylor, J., & Cristianini, N. (2002). Inferring semantic representation text via cross-language correlation analysis. Proceedings 16th Annual
Conference Neural Information Processing Systems (NIPS 2002), pp. 14731480,
Vancouver, CA.
Vulic, I., & Moens, M.-F. (2015). Monolingual cross-lingual information retrieval models
based (bilingual) word embeddings. Proceedings 38th International ACM
SIGIR Conference Research Development Information Retrieval (SIGIR
2015), pp. 363372, Santiago, CL.
Wei, C.-P., Lin, Y.-T., & Yang, C. C. (2011). Cross-lingual text categorization: Conquering
language boundaries globalized environments. Information Processing Management, 47 (5), 786804.
Wei, C.-P., Yang, C.-S., Lee, C.-H., Shi, H., & Yang, C. C. (2014). Exploiting poly-lingual
documents improving text categorization effectiveness. Decision Support Systems,
57, 6476.
Xiao, M., & Guo, Y. (2013). novel two-step method cross-language representation
learning. Proceedings 27th Annual Conference Neural Information Processing Systems (NIPS 2013), pp. 12591267, Lake Tahoe, US.
Xu, C., Tao, D., & Xu, C. (2013). survey multi-view learning. ArXiv e-prints,
arXiv:1304.5634 [cs.LG].
Yang, Y., & Pedersen, J. O. (1997). comparative study feature selection text categorization. Proceedings 14th International Conference Machine Learning
(ICML 1997), pp. 412420, Nashville, US.
Zou, W. Y., Socher, R., Cer, D. M., & Manning, C. D. (2013). Bilingual word embeddings
phrase-based machine translation. Proceedings Conference Empirical
Methods Natural Language Processing (EMNLP 2013), pp. 13931398, Melbourne,
AU.

185

fiJournal Artificial Intelligence Research 57 (2016) 39-112

Submitted 4/16; published 9/16

PDT Logic: Probabilistic Doxastic Temporal Logic
Reasoning Beliefs Multi-agent Systems
Karsten Martiny
Ralf Moller

karsten.martiny@uni-luebeck.de
moeller@uni-luebeck.de

Institute Information Systems,
Universitat zu Lubeck
Lubeck, Germany

Abstract
present Probabilistic Doxastic Temporal (PDT) Logic, formalism represent
reason probabilistic beliefs temporal evolution multi-agent systems.
formalism enables quantification agents beliefs probability intervals
incorporates explicit notion time. discuss time agents dynamically
change beliefs facts, temporal rules, agents beliefs respect
new information receive. introduce appropriate formal semantics PDT Logic
show decidable. Alternative options specifying problems PDT Logic
possible. problem specifications, develop different satisfiability checking
algorithms provide complexity results respective decision problems. use
probability intervals enables formal representation probabilistic knowledge without
enforcing (possibly incorrect) exact probability values. incorporating explicit notion
time, PDT Logic provides enriched possibilities represent reason temporal
relations.

1. Introduction
Logical analysis knowledge belief active topic research diverse fields
philosophy (Hintikka, 1962), economics (Aumann, 1976), game theory (Harsanyi,
1967, 1968a, 1968b), computer science (Fagin, Halpern, Moses, & Vardi, 1995). Numerous extensions modal epistemic logic made reason knowledge
multi-agent settings (Fagin et al., 1995; Baltag & Moss, 2004), add probabilistic knowledge (Fagin & Halpern, 1994; Cripps, Ely, Mailath, & Samuelson, 2008), analyze
dynamic evolution knowledge (van Ditmarsch, van der Hoek, & Kooi, 2007).
realistic scenarios, agent incomplete inaccurate information
actual state world, thus considers several different worlds actually
possible. receives new information (e.g., observes facts currently
hold), update beliefs possible worlds consistent
new information. updates example result regarding (previously
considered possible) worlds impossible judging worlds likely
before. Thus, addition analyzing set worlds agent believes possible,
also useful quantify beliefs terms probabilities. provides means
specify fine-grained distinctions range worlds agent considers possible
highly unlikely, worlds seem almost certainly actual world.
c
2016
AI Access Foundation. rights reserved.

fiMartiny & Moller

multiple agents involved setting, agent may varying
beliefs regarding facts actual world, also regarding beliefs agents.
many scenarios, actions one agent depend belief ontic facts
(i.e., facts actual world), also beliefs agents beliefs.
illustrate reasoning agents beliefs yield significant advantages
practical scenarios, start following informal description application
cyber security domain (a formal analysis example using PDT Logic
presented Martiny, Motzek, & Moller, 2015): Suppose adversary trying
break computer system. usually done attack graph detect
exploit potential vulnerabilities system. attack graph specifies set
paths (i.e., sequences actions) carry attack. Several paths attack graph
might used parallel, potentially different agents (for instance, number infected
computers controlled botnet). Usually, attack patterns specified one attack graph
used multiple times, two important ramifications: adversary learn
experience paths yield high probability successfully breaking
system. Defenders turn able gain knowledge attack graph
repeated observation certain patterns. Thus, system attack, defender
beliefs chosen attack paths adversarys belief regarding
success respective path. Thus, defender choose countermeasures effectively
reacting paths nested beliefs high indeed pose threat
according systems mission impact model.
formalize reasoning beliefs multi-agent settings, present Probabilistic Doxastic Temporal (PDT) Logic. PDT Logic builds upon recent work Annotated
Probabilistic Temporal (APT) Logic (Shakarian, Parker, Simari, & Subrahmanian, 2011;
Shakarian, Simari, & Subrahmanian, 2012) provides formalism enables representing reasoning dynamically changing quantified temporal multi-agent beliefs
probability intervals incorporates subset epistemic actions (Baltag & Moss,
2004). Using concepts APT Logic semantic foundation, PDT Logic merges work
epistemic logic recent work temporal logic Shakarian et al. Apart
reasoning imprecise probabilities, introduces temporal concept frequency
functions epistemic temporal logic.
Quantifying probabilistic knowledge probability intervals instead single probability values yields two main advantages. one hand, using probability intervals
significantly eases task formally representing existing knowledge human domain
expert. cases, domain expert give reasonable probability estimates
knowledge, inevitably fail giving correct precise numerical values probabilities. Consider instance weather forecast: people find easy give coarse
probabilistic quantifications chance rain high, virtually nobody
could quantify exact numerical value. Employing exact numerical values
formal representation would inevitably introduce errors probability model.
Thus, use probability intervals provides means express probabilistic knowledge
precisely possible without enforcing unrealistic precision. hand,
many scenarios probabilities (and even rough estimates them) simply unavailable, bounds values may known. illustrate this, consider scenario
described Ellsberg (1961):
40

fiPDT Logic

Example 1.1 (The Ellsberg paradox, Ellsberg, 1961). Imagine urn known contain
30 red balls 60 black yellow balls, latter unknown proportion. One ball
drawn random urn; following actions considered: Action
bet red, II bet black.
Now, easy see rational agent would believe action successful
probability 1/3. action II, quantification possible
respective probability unknown. Yet omitting probabilistic information action
II altogether would ignore available information unknown probability value,
namely somewhere 0 2/3. example exhibits two different types
uncertainty: former action subject risk, i.e., outcome unknown,
occurs known probability, later action subject ambiguity (also known
Knightian uncertainty), probability unknown (Bradley, 2015).
probability intervals, PDT Logic able work imprecise probabilities.
width probability interval give additional information certainty
probability quantification. Naturally, narrow interval associated high certainty
respective probability vice versa, wide interval associated low certainty.
PDT Logic employs explicit notion time thereby facilitates expression
richer temporal relations. allows analysis temporal doxastic problems
beyond scope previous work. resulting framework provides means reason
temporal evolution beliefs multi-agent systems. Two different applications
framework possible: First, agent respective multi-agent system
employ framework online run system reason beliefs.
analyzing nested beliefs introduced above, gives agent also means reason
probable evolutions agents belief states. Second, framework used
offline external observer analyze whether desired evolutions given system
possible.
remainder work structured follows: next section presents related
work knowledge multi-agent systems APT Logic. Then, Section 3,
syntax PDT Logic introduced, followed definition formal semantics. Decision
algorithms complexity results PDT Logic discussed Section 4.
formally defined semantics based precise probability values, section shows
satisfiability PDT Logic decided even imprecise probabilities given.
Finally, paper concludes Section 5.

2. Related Work
Approaches formalize reasoning knowledge belief date back Hintikkas work
epistemic logic (Hintikka, 1962). Hintikka proposed represent knowledge sets
states worlds, together binary relation every agent, determine worlds
indistinguishable agent. approach sparked multiple branches research
epistemic logic, still active topics research today. branches research
broadly classified four (not mutually exclusive) areas relevant
work: multi-agent epistemic logic, probabilistic epistemic logic, epistemic temporal logic,
41

fiMartiny & Moller

dynamic epistemic logic.1 following, give overview key contributions
area discuss existing approaches merge fields research.
Early research epistemic logic culminated influential work Reasoning
Knowledge (Fagin et al., 1995), provides unified presentation various preceding
contributions epistemic logic. work uses so-called interpreted systems approach
represent knowledge multi-agent systems, time represented runs.
run sequence systems global states thus identifies state system
every time point. Among contributions, work provides notions multiagent epistemic modalities nested knowledge, distributed knowledge, common
knowledge.
Several works extended epistemic logic represent dynamic evolutions knowledge. direction research known Dynamic Epistemic Logic (DEL). first formal
analysis dynamics knowledge presented Plaza (1989; reprinted Plaza,
2007). contribution, Plaza introduces public communication events (now commonly
known public announcements) analyze dynamic evolution knowledge groups
upon truthful public announcements facts group agents. Independently
Plaza, related approach public announcement logic proposed Gerbrandy
Groeneveld (1997). Baltag, Moss, Solecki (1998) Baltag Moss (2004) generalize dynamic approach epistemic logic incorporate variety complex epistemic
actions. Here, epistemic updates represented Kripke models.
extends dynamic epistemic logic represent variety additional epistemic actions
private group announcements (i.e., announcements agents outside receiving
group unaware announcement), lies (i.e., untruthful announcements), combinations thereof. PDT Logic, use public private group announcements,
assume announcements truthful. thorough treatment dynamic epistemic
logic given van Ditmarsch et al. (2007). Van Eijck (2014) provides recent overview
field.
alternative approach modeling evolution knowledge combine epistemic
logic temporal system. One example aforementioned interpreted
systems Fagin et al. (1995). Another approach modeling temporal aspects epistemic logic proposed Parikh Ramanujam (2003). approach known
Epistemic Temporal Logic (ETL). Here, possible situations represented sets
histories, local histories every agent, represent respective agents previous
observations. Based histories, knowledge based semantics messages defined,
shown messages vary meaning, depending respective context
messages receiver. temporal model employ PDT Logic closely related
epistemic temporal logic. Instead specifying local histories every agent, define
semantics PDT Logic respect global history. However, local contexts
1. simplify following discussion, explicitly distinguish epistemic doxastic
logics section, use epistemic general term. Strictly speaking, epistemic formalisms
deal knowledge, doxastic formalisms deal beliefs. usual axiomatic definition
knowledge literature uses Truth Axiom, stipulates agent know true
facts. Omitting axiom leads notion belief. Even though unanimously accepted
(cf. e.g., Halpern, Samet, & Segev, 2009), axiom usually considered key distinction
knowledge belief.

42

fiPDT Logic

sense ETL easily extracted global history filtering history
respective agents observations.
traditional work epistemic logic discussed far allow quantify
agents degree belief certain facts; specified whether agent
know (resp. believe) fact. remove limitation, several approaches
proposed combine logics knowledge belief probabilistic quantifications.
Fagin Halpern (1994) laid foundation combination seminal paper.
define belief operator quantify lower bounds probabilities agent
assigns formula. modeled associating probability space state
agent. framework, generally guaranteed formulae define
measurable sets, present properties guarantee measurability
sets. contrast, semantics defined PDT Logic always produces events
measurable probabilities. special case framework introduced Fagin Halpern
presented Milch Koller (2000). PDT Logic, formalism
assumed (i) exists common prior probability distribution set worlds
(ii) agents local probability distribution world derived
global distribution conditioned respective set worlds agent considers possible.
additional feature Milch Koller models represented Bayesian
networks find probabilities defined formulae. Van der Hoek (1997) introduces
logic PF D, later extended de Carvalho Ferreira, Fisher, van der Hoek
(2008). Like Fagin Halpern, framework introduces operator quantify
lower bounds probabilistic beliefs. Probabilistic values work semantically
restricted finite base set probability values, yielding logically compact framework
enables efficient implementations.
variety approaches proposed extend probabilistic epistemic logics
dynamic frameworks: Kooi (2003) restricts probabilistic epistemic logic Fagin
Halpern (1994) finite settings combines dynamic epistemic logic
Gerbrandy Groeneveld (1997) create Probabilistic Dynamic Epistemic Logic
(PDEL). work analyzes effects probabilistic beliefs upon public announcements.
framework based dynamic epistemic logic, capabilities
represent temporal relationships; features regarding past cannot expressed all,
features regarding future expressed limited extent result
certain actions. Van Benthem (2003) extends framework analyze results
various epistemic actions described Baltag et al. (1998). Another extension
framework proposed van Benthem, Gerbrandy, Kooi (2009b), different
sources probabilities distinguished. simplification approach presented
van Eijck Schwarzentruber (2014). paper distinguishes work
probabilistic epistemic logic certainty equated knowledge. works
make explicit distinction belief probability 1 knowledge. difference
two concepts often illustrated repeatedly throwing fair coin:
event coin shows head least 1 infinite number repetitions.
Yet agent know example coin eventually show head. PDT
Logic works countable models finite time frames, adopt view
van Eijck Schwarzentruber consider certainty knowledge equivalent
models. Deviating approaches extend epistemic logic probabilities, PDT
43

fiMartiny & Moller

Logic provides belief operator probability interval quantifications, lower
upper bounds probability values specified explicitly. provides
natural means represent imprecise probabilities discussed introduction.
Another direction probabilistic extensions discussed Halpern Pucella (2006)
Doder, Markovic, Ognjanovic, Perovic, Raskovic (2010), example. approaches consider problem estimating unknown prior probabilities based given
evidence. Essentially, unknown priors represented set hypotheses,
likelihood hypothesis given specific observations estimated. approaches,
hypotheses represent possible configurations world thus satisfiable.
contrast, aim PDT Logic verify whether possible assignment priors exists
given set formulae satisfiable.
dynamic epistemic logic, possible reason step-wise changes
future. order reason temporal relations, Sack (2008) extends update
mechanism dynamic epistemic logic temporal operators, namely previous-time
next-time operators. Sack (2009) extends approach probabilistic frameworks augmenting work probabilistic dynamic epistemic logic (Kooi, 2003)
previous-time operator ability reason continuous probabilities.
approaches enrich dynamic epistemic logic ability reason events
past. Van Benthem, Gerbrandy, Hoshi, Pacuit (2009a) give systematic precise
comparison ETL (called TEL van Benthem, Gerbrandy, Hoshi, Pacuit)
DEL shown approaches merged single framework.
Shakarian et al. (2011) Shakarian et al. (2012) introduce APT Logic, framework
represent probabilistic temporal evolutions worlds threads. APT Logic assigns
prior probabilities every thread uses probabilities determine probabilities
events occurring specific threads. represent temporal relationships events,
APT Logic introduces concept frequency functions. utilize approach APT
Logic create doxastic multi-agent framework supports explicit reasoning
temporal relationships adoption frequency functions. explicit
notion time formalism increases complexity decision problems, significantly
enhances expressibility temporal relations. instance, contrast approaches
implicit representations time, PDT Logic able specify events occur
within certain time interval (cf. introduction frequency functions below).

3. PDT Logic: Syntax Semantics
section, discuss beliefs multi-agent systems formalized. start
defining syntax PDT Logic, discuss employed model time, provide
formal semantics. proposed formalism enables expression different types
beliefs quantify beliefs using imprecise probabilities. introducing suitable
update rule show agents beliefs evolve time agents update
beliefs new information correctly integrated belief state.
44

fiPDT Logic

3.1 Syntax
assume existence function-free quantifier-free fragment first order logic2
language L finite sets constant symbols Lcons predicate symbols Lpred ,
infinite set variable symbols Lvar . Every predicate symbol p Lpred arity. term
member set Lcons Lvar . term called ground term member
Lcons . t1 , .., tn (ground) terms, p predicate symbol Lpred arity n,
p(t1 , ..., tn ) (ground) atom. (ground) atom, (ground)
literals. former called positive literal, latter called negative literal. set
ground literals denoted Llit . usual, B denotes Herbrand Base L, i.e.,
set ground atoms formed Lpred Lcons .
Time modeled discrete steps assume agents reason arbitrarily large, fixed-size window time. set time points given = {1, ..., tmax }.
set agents denoted A. Again, assume set may arbitrarily large,
finite size. describe agents observe, define observation atoms follows.
Definition 3.1 (Observation atoms). non-empty group agents G
ground literal l Llit , ObsG (l) observation atom. set observation atoms
denoted Lobs .
Intuitively, meaning statement form ObsG (l) agents group
G observe fact l holds. Note l may negative literal therefore
explicitly specify observations certain facts false (such raining).
assume agents G observe l holds, agent G also
aware agents G make observation. line Baltag Moss
(2004), observations viewed effects private group announcements fact
l group G (i.e., l becomes common knowledge within G, agents outside G
remain entirely oblivious observation): represents epistemic action, i.e., alters
belief states agents G (as formally defined below), influence
ontic facts respective world.
Definition 3.2 (Formulae). atoms observation atoms formulae. F G
formulae, F G, F G, F formulae. formula ground atoms
formula ground.
Example 3.1 (Coin toss). Consider two agents 1, 2 coin tossed. event
coin lands heads denoted primitive proposition Head, accordingly,
coin lands tails denoted Head. Let us assume coin actually lands heads.
Then, sets possible observations scenario {Obs{1} (Head)}, {Obs{2} (Head)},
{Obs{1} (Head), Obs{2} (Head)}, {Obs{1,2} (Head)}.
Note difference third fourth set: former
scenario, agents observe outcome coin throw unaware
agent actually made observation. latter scenario, agents observe
outcome aware agent observes same. Since allow
2. use first order structure language definition syntactically convenient way
representing observations. Apart this, propositional logic could used base language.

45

fiMartiny & Moller

nesting observations (i.e., expressions ObsG1 (ObsG2 (l))) PDT Logic,
subset epistemic actions discussed Baltag Moss (2004) represented
formalism. limits expressivity epistemic actions extent,
ensure resulting set possible observations Lobs always finite therefore
show PDT Logic decidable (as shown Section 4). Further, note
formal concept observations limited express passive acts observing facts,
instead used model wide range actions: instance, example
one could also use Obs{1,2} (Head) model act one agent telling
outcome coin throwthe ramifications communication act exactly
would shared observation (assuming agents lie).
express temporal relationships, define temporal rules following approach
APT rules Shakarian et al. (2011). definition temporal rules already relies
concept frequency functions, even though defined next section.
still introduce temporal rules enable clearly separated presentation syntax
semantics PDT Logic.
Definition 3.3 (Temporal rules). Let F, G two ground formulae, time interval,
fr (F, G)
fr name frequency function (as defined Section 3.2.5). rt
called temporal rule.
Frequency functions provide information temporal connections events.
fr (F, G) understood F followed G
meaning expression rt
time units w.r.t. frequency function fr. Frequency functions enable specification
various types temporal relations. example, used determine often
F followed G within time units often F followed G exactly
time units. usage fr syntax temporal rules used specify set possible
names employed types frequency function.
`,u
`,u
Now, define belief operator Bi,t
0 express agents beliefs. Intuitively, Bi,t0 ()
means time t0 , agent believes fact true probability p [`, u].
Particularly, intuitive meaning belief temporal rule agent believes
fr (F, G), given F holds time point. call
G hold according rt
probability interval [`, u] quantification agent belief. use Ft denote
formula F holds time and, accordingly, ObsG (l)t denote observation
ObsG (l) occurs time t. call expressions time-stamped formulae timestamped observation atoms, respectively.
Definition 3.4 (Belief formulae). Let agent, t0 time point, [`, u] [0, 1].
Then, belief formulae inductively defined follows:
`,u
1. F ground formula time point, Bi,t
0 (Ft ) belief formula.
fr (F, G) temporal rule, B `,u (r fr (F, G)) belief formula.
2. rt
i,t0
`,u
3. F G belief formulae, Bi,t
0 (F ), F G , F G , F .
`,u
belief Bi,t
0 () something, call belief object. Belief operators
`,u
atomic elements PDT Logic, i.e., expression Bi,t
0 () (including possibly nested belief

46

fiPDT Logic

formulae) called atom. use script fonts (e.g., F ) distinguish belief formulae
standard formulae. Note ontic facts observation atoms
standard formulae (cf. Definition 3.2) therefore agents also beliefs
possible observations.
use probability intervals [`, u] provides option represent imprecise probabilities (Bradley, 2015): using imprecise probabilities, usually assumed
degree belief proposition represented using single probability function p(), instead set P functions. Then, belief state P ()
proposition represented set
P () = {p() : p P }.
set probabilities P (), so-called lower upper envelopes defined P () =
inf P () P () = sup P (), respectively. belief quantifications belief operator
represent imprecise probabilities ` u values probabilistic belief
considered lower upper envelopes P P respective imprecise probability.
`,u
Remark 3.1. decided index belief operators Bi,t
0 () facts Ft appearing
belief objects time stamps allow concise representation temporal
relations. Alternatively, one could use traditional approach (cf. Sack, 2009
example) introduce previous-time next-time operators language express
`,u
temporal relationships t0 Bi,t
0 (Ft ). Then, could also omit temporal
0
index belief operator instead evaluate whether belief holds time t0
model. However, merely syntactic considerations impact
underlying formalism. Thus decided encode time explicitly belief operators
avoid introduction additional temporal operators. Moreover, belief operators
also used express general temporal relationships modeled domain.
illustrate point detail Section 4.

3.2 Semantics
section, provide formal semantics PDT Logic captures intuitions
explained above. ease understanding presentation, start introduction
example, return repeatedly introducing various concepts
semantics. illustration formalisms features, use simplified exemplary
domain. practical use example somewhat limited, serves illustrate
PDT Logic applied, especially analysis multi-agent beliefs
yield valuable information deciding meaningful actions. resulting insights
easily applied sophisticated domains.
Example 3.2 (Trains). Let Alice Bob two agents living two different cities CA
CB , respectively. Suppose Alice wants take train visit Bob. Unfortunately,
direct connection cities CA CB , Alice change trains
third city CC . assume train T1 connects CA CC , train T2 connects CC
CB . trains usually require 2 time units trip, might running late
arrive one time unit later scheduled. Alice requires one time unit change trains
city CC . T1 runs time, direct connection T2 , otherwise wait
47

fiMartiny & Moller

two time units next train T2 leaves city CC . train running late,
call Bob let know. calls modeled shared observations
Alice Bob. instance, Alice wants tell Bob train T1 running late (i.e., T1
arrive CC expected time), modeled Obs{AB} (at(T1 , CC ))
expected arrival time.
3.2.1 Possible Worlds
Ontic facts corresponding observations (e.g., described example) form
worlds (or states terminology Fagin et al., 1995). world consists set
ground atoms set observation atoms, i.e., 2BLobs .3 use
ObsG (l) denote atom a, resp. observation atom ObsG (l), holds world .
Since agents observe facts actually hold respective world, define
admissibility conditions worlds w.r.t. set observations:
Definition 3.5 (Admissible worlds). world admissible, iff every observation atom
ObsG (l)
1. observed fact holds, i.e., x l positive literal x, x 6 l negative
literal x,
2. every subgroup G 0 G, ObsG 0 (l) .
use adm() denote world admissible.
set possible worlds denoted set admissible worlds .
following discussion section assume specification given.
possible employ usual definition set combinations
ground atoms observation atoms ( = 2BLobs ), maximum subset
complying Definition 3.5, usually contains vast number worlds
blatantly impossible according respective problem modeled. Therefore, assume
succinct specification set admissible worlds depending respective domain
given. main reason assumption simplify following presentationwe
describe method obtain set algorithmically Section 4.
Remark 3.2. already discussed Section 3.1, group observations ObsG (l) every
agent G aware agents G observed fact. Together
Definition 3.5, semantics observations equivalent usual semantics
common knowledge. Fagin et al. (1995) give definition common knowledge
fixed-point axiom: fact l common knowledge among group G members
G know l true common knowledge. Thus, could also equivalently use
established common knowledge operator CG (l) instead previously defined observation
3. formalisms epistemic logic encode facts directly worlds, instead use set
named states s1 , s2 , ... valuation function (si ) determine facts hold world si (cf.
Fagin et al., 1995). mainly done obtain option multiple worlds si , sj
facts hold (i.e., (si ) = (sj )), knowledge states agents differ. described below,
PDT Logic worlds appear within threads, thus possible worlds valuation
appear time point multiple threads. Thus, formalism encode facts directly
possible worlds save valuation function without limiting epistemic expressivity.

48

fiPDT Logic

atoms ObsG (l). However, concept common knowledge usually used describe
emergent states agents knowledge. hand, context approach,
observations extrinsic feature result emergence belief states.
keep clear distinction intended use operator, therefore continue
use ObsG (l) instead CG (l).
Example 3.3 (Trains continued). Example 3.2, ground terms A, B, CA , CB ,
CC , T1 , T2 , representing Alice, Bob, three cities, two trains. Furthermore,
atoms on(y, x) indicating person train x, at(x, z) indicating train x
city z. Finally, observation atoms kind ObsG (at(x, z)), indicating
agents G observe train x station z. possible world example
1 = {at(T1 , CA ), on(A, T1 ), Obs{A} (at(T1 , CA ))}, indicating train T1 city CA
boarded train.
define satisfaction ground formula F world usual way (Lloyd,
1987):
Definition 3.6 (Satisfaction ground formulae). Let F, F 0 , F 00 ground formulae
world. Then, F satisfied (denoted |= F ) if:
case F = ground atom a:
.
case F = F 0 ground formula F 0 :

case F = F 0 F 00 formulae F 0 F 00 :

case F = F 0 F 00 formulae F 0 F 00 :

6|= F 0 .

|= F 0 |= F 00 .

|= F 0 |= F 00 .

say formula F tautology |= F admissible worlds .
say formula F contradiction world |= F . use
usual symbols > denote tautologies contradictions, respectively.
3.2.2 Threads
model temporal evolutions problem domain use definition threads
Shakarian et al. (2011):
Definition 3.7 (Thread). thread h mapping set time points
set admissible worlds: h :
Thus, thread sequence worlds h(t) identifies actual world time
according thread h. set possible threads (i.e., possible sequences constructible ) denoted . Again, refrain directly working
, instead assume meaningful problem specification gives information
possible temporal evolutions system. use represent set relevant possible threads. notational convenience, assume additional prior world
h(0) every thread.
Following Definition 3.6, use h |= Ft denote thread h satisfies formulae F
time (i.e., h |= Ft h(t) |= F ). Accordingly, use |= Ft denote every
thread h satisfies formula F time t.
49

fiObs{A}
at(T1 , CC )
(at(T1 , Cc ))
on(A, T1 ) on(A, T1 ) on(A, T1 ) on(A, T1 )

Obs{A,B}
at(T1 , CC )
(at(T1 , Cc ))
on(A, T1 ) on(A, T1 ) on(A, T1 ) on(A, T1 )

Obs{A}
at(T1 , CC )
(at(T1 , Cc ))
on(A, T1 ) on(A, T1 ) on(A, T1 ) on(A, T1 )

1 2 h7

1 2 h6

h5

h4

1

1

hi

h1

2 h2
on(A, T1 )
at(T1 , CC )
on(A, T1 )

on(A, T1 ) on(A, T1 )
at(T1 , CA )
on(A, T1 ) on(A, T1 )

3

at(T1 , CC )

at(T1 , CA )

2

on(A, T1 )

on(A, T1 ) on(A, T1 )

1

at(T1 , CC )

at(T1 , CA )

at(T1 , CA )

at(T1 , CA )

at(T1 , CA )

at(T1 , CA )

on(A, T2 )

on(A, T2 )

on(A, T2 )

on(A, T2 )

4
1

5

on(A, T2 ) on(A, T2 )

at(T2 , CC )

at(T2 , CC )

6

on(A, T2 )

at(T2 , CB )

7

Obs{A}
at(T2 , CB )
(at(T2 , CB ))
on(A, T2 ) on(A, T2 ) on(A, T2 ) on(A, T2 )

at(T2 , CC )

8

at(T2 , CB )

at(T2 , CC )
on(A, T2 )

at(T2 , CB )
on(A, T2 )

9



Obs{A}
at(T2 , CB )
(at(T2 , CB ))
on(A, T2 ) on(A, T2 )
on(A, T2 )

Obs{A}
at(T2 , CB )
(at(T2 , CB ))
on(A, T2 ) on(A, T2 )
on(A, T2 )

Obs{A,B}
at(T2 , CB )
(at(T2 , CB ))
on(A, T2 ) on(A, T2 )
on(A, T2 )

Obs{A,B}
at(T2 , CB )
(at(T2 , CB ))
on(A, T2 ) on(A, T2 )
on(A, T2 )

at(T2 , CC )

on(A, T2 )

at(T2 , CC )

on(A, T2 )

at(T2 , CC )

on(A, T2 )

at(T2 , CC )

on(A, T2 )

at(T2 , CC )

Obs{A,B}
at(T2 , CB )
(at(T2 , CB ))
on(A, T2 ) on(A, T2 ) on(A, T2 ) on(A, T2 )

Obs{A,B}
at(T1 , CC )
(at(T1 , Cc ))
on(A, T1 ) on(A, T1 ) on(A, T1 ) on(A, T1 )

2 h3

Obs{A}
at(T1 , CC )
(at(T1 , Cc ))
on(A, T1 ) on(A, T1 ) on(A, T1 ) on(A, T1 )

1 2 h8

at(T1 , CA )

Obs{A,B}
at(T1 , CC )
(at(T1 , Cc ))
on(A, T1 ) on(A, T1 ) on(A, T1 ) on(A, T1 )

at(T1 , CA )

1 2 h9

Martiny & Moller

Figure 1: Visualization possible threads hi Example 3.2. easier distinction, shared observations B marked blue, single observations
marked red, situations Alice train 1 train 2
marked green orange, respectively. Note train running late
(the respective threads marked according circles), always two
possible threads: one observes one share
observation.
50

fiPDT Logic

assume system synchronous, i.e., agents global clock. Thus,
even agent observe anything world h(t), still aware time passing
therefore distinguish worlds h(t) h(t 1).
Example 3.4 (Trains continued). description Example 3.2 (p. 47) yields
set possible threads depicted Figure 1. Note manually specified set
threads containing threads comply description Example 3.2.
set possible threads would contain vast number additional threads
irrelevant described scenario.
3.2.3 Kripke Structures
definition threads, use slightly modified version Kripke structures
(Kripke, 1963). usual, define Kripke structure tuple h, K1 , ..., Kn i,
set admissible worlds binary relations Ki every agent A. Thus,
Kripke relation (also called possibility relation) agent world defined
Ki () = { 0 : (, 0 ) Ki }

(1)

Intuitively, (, 0 ) Ki specifies world , agent considers 0 also possible
world. words, current information agent unable distinguish worlds
0 .
initialize Kripke structure threads considered possible time
= 0:
[
h : Ki (T h(0)) =
{T h0 (0)},
(2)
h0

evolution time, agent eliminate worlds comply
respective observations. elimination worlds, agent also reduce
set threads considers possible (ifdue observationa world considered
impossible time point t, threads h h(t) = considered impossible).
assume agents perfect recall therefore consider thread
possible considered impossible one point. Thus, Ki updated w.r.t.
agents respective observations, considers threads possible comply
current observations considered possible previous time point:

Ki (T h(t)) = h0 (t) : h0 (t 1) Ki (T h(t 1))

{ObsG (l) h(t) : G} = {ObsG (l) h0 (t) : G}
(3)
following two corollaries describe key properties Ki follow immediately
definitions (2) (3):
Corollary 3.1 (Equivalence relation). Ki defines equivalence relation possible
worlds Ki (T h(t)) time points .
Corollary 3.2 (Reduction considered threads). set threads h0 considered possible
w.r.t. Ki narrowing smaller smaller subset time, i.e., {T h0 : h0 (t)
Ki (T h(t))} {T h0 : h0 (t 1) Ki (T h(t 1))} h .
51

fiMartiny & Moller

Note updates Ki defined new information incorporated instantaneously, i.e., time agent observes fact, updates possibility relations
already time considers every world impossible comply
observation time t.
Example 3.5 (Trains continued). Figure 1, obtain time 1,
possible world {at(T1 , CA ), on(A, T1 )}, contained possible threads. Thus,
Ki (T hj (1)) contains exactly world agents threads j. Consequently,
agents consider threads possible time 1.
Now, assume time evolves two steps actual thread h4 (i.e., train
T1 running late, inform B this). agents update
possibility relations accordingly, yielding
KA (T h4 (3)) = {{Obs{A} (at(T1 , CC )), on(A, T1 )}}

KB (T h4 (3)) = {{at(T1 , CC ), on(A, T1 )}, {Obs{A} (at(T1 , CC )), on(A, T1 )}},
i.e., knows T1 time, B unaware T1 late, since still
considers situation possible train T1 city CC time = 3.
3.2.4 Subjective Posterior Temporal Probabilistic Interpretations
agent probabilistic beliefs expected evolution time. expressed subjective temporal probabilistic interpretations:
Definition 3.8 (Subjective posterior probabilistic temporal interpretation). Given set
possible threads , thread Th , time point t0 > 0 agent i, function
Th : [0, 1] specifies subjective posterior probabilistic temporal interpretation
Ii,t
0
agent point view time t0 thread Th, i.e., probability distribution possible
P
Th (T h) = 1. Since probabilistic interpretations possible threads
threads: hT Ii,t
0
depend respective perspective agent i, Th marks point view subjective

interpretation. Thus, call Th point view (pov) thread interpretation h0 .
i,t

concept point view threads seen conditional probabilities: subjecTh specifies agent probabilistic interpretation
tive posterior probabilistic interpretation Ii,t
0
time t0 given Th actual thread. Different threads yield different evolutions
world andsince every possible thread taken pov thread may induce
different probabilistic interpretations agent. Thus, notion pov threads allows
reason hypothetical beliefs agent, instance possible future beliefs
analyzed nested beliefs evaluated.
Th vector occasionally represent probabilistic
simplify notation, see Ii,t
0


h vector possible threads vector well, jth
interpretation Ii,t
0


h refers probability assigned thread h .
element Ii,t
0
j



h (T h). Since
prior probabilities agent threads given Ii,0
threads indistinguishable priori, single prior distribution needed

52

fiPDT Logic

0



0

h (T h) = h (T h)). Furthermore, order
agent (i.e., h, Th, Th : Ii,0
i,0
able reason nested beliefs (as discussed below), assume prior
probability assessments agents commonly known (i.e., agents know
agents assess prior probabilities thread). turn requires
agents exactly prior probability assessment possible threads: two
agents different, commonly known prior probability assessments, essentially
instance Aumanns well-known problem agreeing disagree (Aumann,
1976). Intuitively, differing priors commonly known, common knowledge
(at least) one agents fault revise probability assessments.
result, one prior probability distribution viewpoints,
denoted I. Note directly corresponds concept temporal probabilistic
interpretations Shakarian et al. (2011).

Remark 3.3. could use prior probability distribution alternative method
distinguish set possible threads set threads relevant
specific problem domain. so, simply assign unwanted threads h 6
probability zero.
Example 3.6 (Trains continued). meaningful prior interpretation

I(T ) = 0.7 0.02 0.09 0.02 0.09 0.01 0.02 0.02 0.03 ,
assigns highest probability h1 (no train running late), lower probabilities
threads one train running late informs B (T h3 h5 ), even lower
probabilities events either trains running late informs B (T h7 ,
h8 , h9 ) one train running late inform B (T h2 h4 ),
lowest probability thread trains running late
inform B (T h6 ). Note represents prior interpretation train example
thus every agent every possible pov thread Th.
Even though single prior probability distribution set possible
threads, still necessary distinguish viewpoints different agents different
threads, following definition interpretation updates shows.
Whenever agent updates Kripke relations according Equation (3) (p. 51),
necessary update probabilistic interpretations agent match new
knowledge. intuitive way update probabilities conditioning remaining
worlds agents Kripke structure. want point conditioning suitable
choice PDT Logic, although known produce undesired incorrect results
many cases, notably Monty Hall problem (vos Savant, 1990). Grunwald
Halpern (2003) discuss naive conditioning tends produce errors updates
carried simplified space several events collapsed since seemingly
one event. one uses so-called sophisticated conditioning instead (i.e., conditioning
sophisticated space, means possible events represented), probabilities
updated correctly. semantics PDT Logic based exhaustive specification
relevant threads, conditioning proper specification relevant threads inherently
sophisticated sense Grunwald Halpern therefore produce correct
results. One easily verify following update rule, well-known probability
53

fiMartiny & Moller

puzzles Monty Hall Problem correctly represented PDT Logic. Thus,
use following conditioning-based update rule:
Definition 3.9 (Interpretation update). Let agent, t0 time point, Th pov
thread. Then, system actually thread Th time t0 , agent probabilistic
interpretation set possible threads given update rule:

Th (T h) h(t0 ) K (Th(t0 ))
1 Ii,t
0 1

h
Th

0
i,t
Ii,t0 (T h) =
(4)
0
h(t0 ) 6 Ki (Th(t0 ))


1
h

i,t0

normalization factor ensure


X

Th
i,t
0 =

hT ,

P



hT

h (T h) = 1:
Ii,t
0



Th
Ii,t
0 1 (T h)

(5)

h(t0 )Ki (Th(t0 ))

invocation Ki update rule yields obvious ramifications evolution
interpretations, stated following corollary:
Corollary 3.3 (Nonzero probabilities). subjective temporal probabilistic interpretation
Th agent assigns nonzero probabilities exactly set threads still
Ii,t
0

considers possible time t0 , i.e., h0 (T h) > 0 iff (T h(t), Th(t)) Ki
i,t

Essentially, update rule assigns impossible threads probability zero
scales probabilities remaining threads proportional
probabilities previous time point. given prior probability distribution
Th specific pov thread
set possible threads, subjective posterior probabilities Ii,t
0
0

h agents time points induced respective observations contained


Th. use h denote set subjective posterior interpretations h0 induced
i,t

pov thread Th.

Example 3.7 (Trains continued). Applying update rule (4) situation
described Example 3.5 (p. 52), given Example 3.6, yields updated
interpretation A:


h4
IA,3
= 0 0 0 0.4 0 0.2 0 0.4 0



(6)

i.e., considers exactly threads possible, train running late
inform B (threads h4 , h6 , h8 ). Due lack new information, B
eliminate situations indeed inform late time
point 3, thus Bs interpretation updated to:

Th4
IB,3
0.82 0.02 0.10 0.02 0 0.02 0 0.02 0 .
54

(7)

fiPDT Logic

h(1)

h(2)

h(3)

h(4)

h(5)

h(6)

h(7)

h(8)

F

G

F

G

G

F

G

F

Figure 2: Example thread h = {1, ..., 8}, adopted Shakarian et al. (2011).
figure shows world satisfies formula F formula G.

3.2.5 Frequency Functions
represent temporal relationships within threads, adapt concept frequency functions introduced Shakarian et al. (2011). Frequency functions provide flexible way
representing temporal relations occurrences specific events. illustrate
motivation behind using frequency functions, consider exemplary thread h depicted
Figure 2. thread, one events F G occurs every time point = 1
= 8. discussed Shakarian et al., multiple ways characterizing temporal
relationships events F G: instance, one might specify often event
F followed event G in, say, exactly 2 time points. According Figure 2, happens
one four occurrences F h. might prove meaningful exclude final
occurrence F h determining frequency, naturally occurrence
F tmax cannot followed subsequent occurrence G. Excluding final
occurrence F would yield one three desired frequency. Alternatively, one
could also specify often F followed G within next two time points.
exemplary thread Figure 2, would produce frequencies 1 0.75 respectively,
depending whether final occurrence F included.
example illustrates already four different possible definitions temporal relations
events. maintain flexibility expressing temporal relations, commit specific definitions PDT Logic, instead adapt axiomatic definition
frequency functions:
Definition 3.10 (Frequency functions, adapted Shakarian et al., 2011). Let h
thread, F , F 0 , G, G0 ground formulae, 0 integer. frequency
function fr maps quadruples form (T h, F, G, t) [0, 1] following
axioms hold:
(FF1) (F G) tautology, fr(T h, F, G, t) = 1.
(FF2) (F G) contradiction, fr(T h, F, G, t) = 0.
(FF3) (F G) neither tautology contradiction, exist threads h1 ,
h2 fr(T h1 , F, G, t) 6= fr(T h2 , F, G, t).
(FF4) F F 0 G G0 , fr(T h, F, G, t) = fr(T h, F 0 , G0 , t).
Axioms (FF1) (FF2) ensure special casesi.e., (G >), (F ),
(F >, G )frequency functions behave temporal implications premise
F conclusion G. Axiom (FF3) enforces non-trivial frequency functions requiring
cases covered first two axioms, must least two threads
55

fiMartiny & Moller

differing frequency values. Axiom (FF4) ensures fr congruent logical
equivalence. Examples frequency functions satisfying axioms introduced below.
Remark 3.4. definition mostly corresponds definition frequency functions
Shakarian et al. (2011), except require > 0. work
Shakarian et al., frequency functions intended express temporal relationships
therefore limited nonzero values. additionally allowing = 0, obtain
concise framework express temporal relationships static constraints
within one time point. exploited next section, decision procedures
PDT Logic discussed.
illustrate concept frequency functions, present formal definitions
point existential frequency functions adapted Shakarian et al. represent
informal descriptions frequencies above:
point frequency function pfr expresses frequently event F followed
another event G exactly time units:
pfr(T h, F, G, t) =

|{t : h(t) |= F h(t + t) |= G}|
|{t : (t tmax t) h(t) |= F }|

(8)

denominator zero, define pfr 1. denominator counts total number
occurrences F given thread h numerator counts number occurrences
F followed G exactly time units. Thus, ratio pfr expresses frequently
F followed G exactly time units. Note denominator considers
occurrences F time tmax t. done reflect previously discussed
intuition occurrences F last time points excluded
frequency, possibility followed subsequent G
time units.
existential frequency function efr expresses frequently event F followed
another event G within next time units:
efr(T h, F, G, t) =
efn(T h, F, G, t, 0, tmax )
,
|{t : (t tmax t) h(t) |= F }| + efn(T h, F, G, t, tmax t, tmax )

(9)


efn(T h, F, G, t, t1 , t2 ) =|{t : (t1 < t2 ) h(t) |= F

t0 [t, min(t2 , + t)] (T h(t0 ) |= G)}|

function ef n counts number occurrences F followed subsequent occurrence
G within next time units. first summand denominator counts
total number occurrences F time point tmax t. second summand
denominator, additional occurrences F followed G within time units.
intuition definition exclude occurrences F final time units
followed G. Since G may occur within range t, range cannot
fully considered final time points, occurrences F according
subsequent occurrence G considered final time points. Consequently,
56

fiPDT Logic

ratio efr expresses frequently event F followed G within next time
units without letting single occurrences F final time points decrease ratio.
Returning exemplary thread h Figure 2, evaluate frequency
functions given thread: Suppose want determine often F followed
G exactly two time steps. expressed point frequency function:
1
pfr(T h, F, G, 2) = .
3
instead want know often F followed G within next two time steps,
use existential frequency function:
efr(T h, F, G, 2) =

3
=1
3

noted frequency functions used model temporal relationships
usually expressed temporal operators. instance, pfr = 1 reflects
next operator efr = tmax reflects future operator. meaning
additional temporal operators captured definition
additional frequency functions, required.
3.2.6 Semantics Belief Operator
Now, definitions subjective posterior probabilistic temporal interpretations
introduction frequency functions, provide formal semantics belief operators defined Section 3.1. semantics extends definitions Shakarian
et al. (2011) satisfiability static interpretations obtain formal definition
probabilistic multi-agent beliefs. start providing definition semantics
atomic belief operators three different types beliefs. Semantics compound belief
formulae (i.e., involving connectives , , ) defined Definition 3.16.
Definition 3.11 (Belief Semantics atomic belief operator). Let agent
Th agent interpretation time t0 pov thread Th. Then, follows
Ii,t
0
interpretation agent believes time t0 probability range [`, u]
1. (Belief ground formulae)
Th |= B `,u (F )) iff
formula F holds time (denoted Ii,t
0

i,t0
`

X
hT ,T h(t)|=F



Th
Ii,t
0 (T h) u.

(10)

2. (Belief rules)
fr (F, G) holds (denoted Th |= B `,u (r fr (F, G))) iff
temporal rule rt
i,t0
i,t0
`

X
hT



Th
Ii,t
0 (T h) fr(T h, F, G, t) u.

57

(11)

fiMartiny & Moller

3. (Nested beliefs)
` ,u
belief Bj,tj j () agent j holds time t0 (denoted


` ,u

h |= B `,u (B j j ())) iff
Ii,t
0
j,t
i,t0

`



X
hT
` ,u
h |=B j j ()
Ij,t
j,t

Th
Ii,t
0 (T h) u.

(12)

intuition behind semantics follows. beliefs ground formulae Ft ,
Th (T h) agent time t0 pov thread Th
subjective posterior probabilities Ii,t
0
added threads h satisfy F time t. Thus, sum (10) represents
Th assigns F . sum within specified boundaries [`, u],
exact probability Ii,t
0

`,u
respective belief B 0 (Ft ) holds agent time t0 pov thread Th.
i,t



h (T h) every thread
beliefs rules, subjective posterior probabilities Ii,t
0
fr (F, G). Thus,
weighted corresponding frequency fr(T h, F, G, t) rule rt

h (T h) (11) represents exact probability Th assigns
weighted sum Ii,t
0
i,t0
temporal relation F G according frequency function fr. beliefs
fr (F, G) contains information type frequency
rules, belief object rt
function fr, constraints respective frequency values given belief
quantification [`, u], i.e., agent probabilistic beliefs specific frequency
values.

Remark 3.5. noted semantics beliefs rules (11) together
axiomatic definition frequency functions Definition 3.10 (p. 55) yields certain
fr (F, G). G tautology F contradiction
constraints satisfiable beliefs rules rt
(i.e., Definition 3.10 FF1 satisfied), holds respective frequency function
`,u fr
fr(T h, F, G, t) = 1 every possible thread h, thus, belief Bi,t
0 (rt (F, G))
satisfiable belief quantified u = 1, regardless set threads
Th . Analogously, F tautology G
corresponding interpretation Ii,t
0
`,u fr
contradiction (i.e., FF2 satisfied), belief Bi,t
0 (rt (F, G)) satisfiable ` = 0.
` ,u

`,u
j j
nested beliefs Bi,t
()), expression unnested first determining
0 (Bj,t
` ,u

` ,u

possible pov threads h agent j Bj,tj j () satisfied. Bj,tj j () corresponds
belief fact rule, (10) respectively (11) used identify threads h
h |= B `j ,uj (). Otherwise, represents another belief formula, belief
Ij,t
j,t
unnested recursively innermost belief expression obtained. Then,
h |= B `j ,uj (), agent subjective posterior probabilities Th (T h)
threads h Ij,t
j,t
i,t0
added determine whether outer belief holds. Note agent
know actual beliefs agent j. However, due assumption common equal
priors discussed Section 3.2.4, agent able reason agent js hypothetical
interpretation updates given system specific thread. Thus, agent able
compute (12) without knowing js exact beliefs.
Example 3.8 (Trains continued). use point frequency function express beliefs
punctuality trains. Assume B judge probability
58

fiPDT Logic

train running late (i.e., arriving 3 instead 2 time units, expressed
temporal rule r3pfr (at(T1 , CA ), at(T1 , CC ))) 0.4. yields following
belief formulae
0,0.4 pfr
Bi,0
(r3 (at(T1 , CA ), at(T1 , CC )))

,
0,0.4 pfr
Bi,0
(r3 (at(T2 , CC ), at(T2 , CB )))

{A, B}.

(13)

temporal rules expressed belief formulae, obtain following frequencies
Figure 1 (p. 50):
pfr(T h, at(T1 , CA ), at(T1 , CC ), 3) = 0
pfr(T h, at(T1 , CA ), at(T1 , CC ), 3) = 1
pfr(T h, at(T2 , CC ), at(T1 , CB ) , 3) = 0
pfr(T h, at(T2 , CC ), at(T1 , CB ), 3) = 1

h {T h1 , ..., h3 }

h {T h4 , ..., h9 }

h {T h1 , h4 , h5 }

h {T h2 , h3 , h6 , ..., h9 }

Combining frequency values prior interpretation

I(T ) = 0.7 0.02 0.09 0.02 0.09 0.01 0.02 0.02 0.03 ,
given Example 3.6 (p. 53) yields sum
X
I(T h) pfr(T h, F, G, 3) = 0.19
hT

F = at(T1 , CA ), G = at(T1 , CC ) F = at(T2 , CC ), G = at(T2 , CB ). sum
within belief quantification [`, u] = [0, 0.4], belief formulae (13) valid. Note
prior probabilities Example 3.6 specified trains
late probability, thus respective sums frequencies
same.
definitions, use belief fact F quantify
belief negation fact F :

`,u
Corollary 3.4 (Belief negated facts). Let Bi,t
0 (Ft ) agents quantified temporal belief
fact F according Definition 3.11. Then, agents belief negation
`0 ,u0
0
0
fact F given Bi,t
0 (F ) ` = 1 u u = 1 `.

3.3 Evolution Time
order completely specify problem PDT Logic, introduce concept doxastic
systems. following, assume syntactical objects finite.
|A||T |

Definition 3.12 (Doxastic system). Let set agents, set threads, A0
matrix prior probability distributions across every agent A, F
|A||T |

set frequency functions. Then, call quadruple = hA, , F, A0
system.
59

doxastic

fiMartiny & Moller

Note several parameters discussed explicitly specified
doxastic system: neither set possible worlds , set ground atoms B, set
observation atoms Lobs , set time points explicitly specified. However,
relevant information regarding parameters already contained specification
.

Remark 3.6. Since agents share common prior, rows A0 same. Thus,
one could obtain parsimonious problem specification providing single
unique row vector prior probabilities. choice using matrix A0 nonetheless
notational purposes only: simplify presentation interpretation update
operations later on.
|A||T |

Definition 3.13 (Admissibility doxastic systems). Let = hA, , F, A0

doxastic system. called admissible iff every world (implicitly) defined admissible
|A||T |

(according Definition 3.5, p. 48) rows A0

sum one.

identify specific situations doxastic system time passed
observations occurred, furthermore define pointed doxastic systems:
|A||T |

Definition 3.14 (Pointed doxastic system, pds). Let = hA, , F, A0
doxastic
system H set time-stamped observation atoms observation atoms
H occur least one worlds (implicitly) defined . call pair
hD, Hi pointed doxastic system.
Definition 3.15 (Admissibility pointed doxastic systems). Let hD, Hi pointed
doxastic system, set threads D. hD, Hi called admissible iff
admissible exists thread h ObsG (l)t H : ObsG (l) h(t)
(i.e., must contain least one thread complies timed observations H).
Intuitively, set timed observations specified pds points certain situation
doxastic system. One could view t(H) = max{t : ObsG (l)t H} present time
pds: recent observation occurred t(H), observations actually occurred
past (t < t(H)) specified H (and thus deterministic retrospective),
information future observations > t(H) given. sense, H specifies
certain history t(H) doxastic system points last event history.
Example 3.9 (Trains continued). doxastic system train example specified

= h{A, B}, {T h1 , ..., h9 }, {pfr, efr}, A0 i,




0.7 0.02 0.09 0.02 0.09 0.01 0.02 0.02 0.03
A0 =
.
0.7 0.02 0.09 0.02 0.09 0.01 0.02 0.02 0.03

identify situation described Example 3.5 (p. 52, T1 running late), specify
following pointed doxastic system:
hD, {Obs{A} (at(T1 , CC )3 )}i
60

fiPDT Logic

3.3.1 Evolution Probabilistic Interpretations
accordance prior probability matrix A0 Definition 3.12, define

interpretation matrix ATt h store interpretations agents (with n denoting
number agents |A|) across threads h1 , ..., hm given doxastic system
pov thread Th time t:


Th (T h ) . . . Th (T h )
I1,t

1
1,t



..
..
..

(14)
ATt h =
.
.
.






h (T h ) . . . h (T h )
In,t

1
n,t

definition Ki Equation (3) (p. 51), update rule Equation (4)
(p. 54), using prior probability matrix A0 Definition 3.12, provide

update matrix UtT h calculate interpretation matrix pov thread Th
time point ( denotes element-wise multiplication matrices):






h
ATt h = ATt1
UtT h



(uTt h )ij

=


0
1

Th

i,t0

hj (t) 6 Ki (Th(t))
hj (t) Ki (Th(t))

(15)

(16)



h normalization factor defined Equation (5) (p. 54).
i,t
0
time-stamped observations specified history H pds hD, Hi induce
updated set reachability relations Ki (T h(t)) every thread h complies
given observations (for threads h comply given observations
Ki (T h (t)) = ). updated reachability relations turn yield updated interpre
tations ATt h . complete state interpretations time point every possible
pov thread Th1 , ..., Thm specified block matrix, call belief
state (bs) pds time t:



bs(hD, Hi, t) = ATt h1 , ..., ATt hm
(17)

use bs(hD, Hi) denote sequence belief states bs(hD, Hi, t) = 1
= tmax .
definition belief states seen specification conditional probabilities:
kth entry bs(hD, Hi, t) specifies interpretations agents across threads
time given system pov thread Thk . Thusas every thread considered
potential pov threada full specification agents belief state threads requires
conditional probabilities every time point t. general representation
belief states allow easy evaluation subjective posterior interpretations
arbitrary time points pov threads intuitive definition belief state updates.
However, general definition contains redundant information. leveraging certain properties semantics PDT Logic, identify means obtain compressed
representations belief state following.
61

fiMartiny & Moller





Corollary 3.5 (Null vectors ATt hk ). Due definition (16), ith row ATt hk
~0 iff agent actual observations (as specified H) match observations specified
thread hk .
Proposition 3.6 (Belief state compression). Let hD, Hi pointed doxastic system
let time point t(H). Then, without loss information, belief
state bs(hD, Hi, t) time represented

(18)
bs(hD, Hi, t)0 = ~v1,t , ..., ~vn,t
one probability distribution vector ~vi,t per agent i.


Proof. follows directly Corollaries 3.3 (p. 54) 3.5 matrices ATt hk
bs(hD, Hi, t) nonzero rows exactly correspond threads considered
possible agent time t.
properties Ki given Corollary 3.1 (p. 51) follows worlds h0 (t)
Ki t(H) indistinguishable agent therefore associated
interpretation. Thus, nonzero ith rows matrices bs identical. Defining ~vi,t
unique nonzero rows bs, obtain representation (18). Information
impossible pov threads (as described Corollary 3.5) still maintained
assigned probability 0 ~vi,t .
important note compressed representation applicable time
points t(H), retrospective agent able classify threads two
categories: comply observations far (i.e., considered
possible), not. time points > t(H) classification possible
Ki (T h(t)) depends future observations therefore lead branching
several distinct interpretations depending respective observations.
3.3.2 Evolution Beliefs
order analyze temporal evolution beliefs, use update rule (15)
update belief states. Since different possible observations yield different branches
evolution beliefs, update every thread belief state individually, using

respective update matrices UtT h defined (16):




bs(hD, Hi, t) = bs(hD, Hi, 1) (UtT h1 , ..., UtT hm )

(19)

Furthermore, analyze satisfiability validity arbitrary finite belief expressions
`,u
~
Bi,t
0 () w.r.t. given pds hD, Hi, define auxiliary belief vector b() different beliefs
`,u
B 0 (). vector ~b() contains one entry (~b())j every possible thread hj
i,t

defined follows:
a)

`,u
Bi,t
0 (Ft )

b)

`,u fr
Bi,t
0 (rt (F, G)) :

c)

`,u
`k ,uk
Bi,t
()) :
0 (Bk,t

:

(
1 hj (t) |= F
(~b(Ft ))j =
0 hj (t) 6|= F

fr
(~b(rt
(F, G)))j = fr(T hj , F, G, t)
(
Th
`k ,uk
1 Ik,t j |= Bk,t
()
`
,u
k k
~
(b(Bk,t ()))j =
hj
`k ,uk
0 Ik,t 6|= Bk,t ()

62

(20)

fiPDT Logic

Note case nested beliefs, respective entries (~b())j set one
inner belief holds thread hj , i.e., assumed hj point view thread
`k ,uk
() satisfied thread.
agent k checked whether ks belief Bk,t


Using (19) (20), determine matrix Pt0 () probabilities pTi,th0 k ()
agent assigns time t0 event , possible pov threads
Th1 , ..., Thm :4




h1

p1,t0
.
Pt0 () = bs(hD, Hi, t0 ) ~b(), ..., ~b() =
..


pTn,th01



. . . pT1,th0m
..
..

.
. ()

. . . pTn,th0m

(21)

n agents threads, results n matrix. rows matrix
seen conditional probabilities: agent believes time t0 fact true

probability pTi,th0 k () given system pov thread Thk .
Remark 3.7. Computation Pt0 () straightforward cases 20.a) 20.b). compute
probabilities nested beliefs 20.c), start computing innermost belief
(which instance case 20.a) case 20.b) since assume finite expressions),
compute nested beliefs iteratively.
Using Definition 3.11 (p. 57) Equation (21), provide definition
satisfiability validity beliefs:
Definition 3.16 (Validity satisfiability beliefs). Let B belief formula defined
Definition 3.4 (p. 46), hD, Hi pointed doxastic system, Pt0 () corresponding
matrix probabilities time t0 defined (21). B satisfiable (valid) w.r.t. hD, Hi iff
`,u
1. B = Bi,t
0 ():

least one (all) thread(s) Thk , entries row Pt0 () satisfy `




hk
hk
pi,t
0 () u pi,t0 ().

`,u
2. B = Bi,t
0 ():

least one (all) thread(s) Thk , entries row Pt0 () satisfy ` >




hk
hk
pi,t
0 () u < pi,t0 ().

3. B = B1 B2 :
least one (all) thread(s) Thk , entries corresponding rows
Pt0 () satisfy B1 B2 .
4. B = B1 B2 :
B1 satisfiable (valid) B2 satisfiable (valid).


4. Since consider every possible pov thread Thk , multiply every matrix ATt h


bs(hD, Hi, t) ~b(), thus need use vector ~b(), ..., ~b()
rows.

63

fiMartiny & Moller

Remark 3.8. distinction valid satisfiable belief formulae interest
beliefs time > t(H). time points t(H) agents belief uniquely determined given observations (cf. Proposition 3.6), resulting single probability
associated belief. Therefore, invalid belief formulae t(H) unsatisfiable.
Definition 3.4 (p. 3.4) follows belief object atomic belief formula B
Definition 3.16-1 arbitrary belief formula. inner belief formula
B 0 one cases defined Definition 3.16, validity satisfiability entire
`,u
0
expression B = Bi,t
0 (B ) follows inductively definition: least one
(all) thread(s) Thk , inner belief formula B 0 satisfied limits
`,u
0
outer belief respective thread satisfied, entire belief formula B = Bi,t
0 (B )
satisfiable (valid).
Definition 3.16 gives rise important property belief operator, following
lemma shows:
`,u
Lemma 3.7 (Distributivity belief operator). Let B = Bi,t
0 (1 2 ) belief
formula belief object (1 2 ) connective {, }. Then, express
`,u
`,u
B equivalently B 0 = Bi,t
0 (1 ) Bi,t0 (2 ).

Proof. result follows immediately validity satisfiability beliefs Definition 3.16:
`,u
formula B = Bi,t
0 (1 2 ) satisfiable (valid) iff least one (all) thread(s)


hk holds hk |= 1 Thk |= 2 respective entries Pt0 () satisfy

`,u
Definition 3.16-1. former case, Bi,t
0 (1 ) satisfiable (valid) well,
`,u
latter case Bi,t
0 (2 ) satisfiable (valid), reflects exactly definition disjunctive
`,u
`,u
belief formulae Definition 3.16-4. Thus, B 0 = Bi,t
0 (1 ) Bi,t0 (2 ) satisfiable (valid)

`,u
iff B = Bi,t
0 (1 2 ) satisfiable (valid).

`,u
Similarly, formula B = Bi,t
0 (1 2 ) satisfiable (valid) iff least one (all)

thread(s) hk holds Thk |= 1 Thk |= 2 hold respective
`,u
`,u
entries Pt0 () satisfy Definition 3.16-1. Then, Bi,t
0 (1 ) Bi,t0 (2 ) satisfiable
`,u
`,u
(valid) thus, formula B 0 = Bi,t
0 (1 ) Bi,t0 (2 ) satisfiable (valid) according
`,u
`,u
definition Definition 3.16-3. Thus, B 0 = Bi,t
0 (1 ) Bi,t0 (2 ) satisfiable (valid) iff
`,u
B = Bi,t
0 (1 2 ) satisfiable (valid).

illustrate evolution beliefs, finish train example analysis
expected arrival times.
Example 3.10 (Trains continued). D, specified Example 3.9 (p. 60),
infer Bob (and course Alice, too) safely assume time 1 Alice arrive
time 8 latest probability range [0.9, 1], expressed belief
formula
0.9,1 ef r
BB,t = BB,t
(r7 (on(A, T1 ), (at(T2 , CB ) on(A, T2 ))))

64

(22)

fiPDT Logic

= 1. rule, obtain frequencies
efr(T h, at(T1 , CA ), (at(T2 , CB ) on(A, T2 )), 7) = 1

efr(T h, at(T1 , CA ), (at(T2 , CB ) on(A, T2 )), 7) = 0

h {T h1 , ..., h5 },

h {T h6 , ..., h9 },

i.e., threads h1 , ..., h5 Figure 1 (p. 50), event (at(T2 , CB ) on(A, T2 )) occurs
within 7 time points following event on(A, T1 ) time = 1 (and thus time = 8
latest), threads h6 , ..., h9 , event (at(T2 , CB ) on(A, T2 )) occurs
time = 9, outside scope r7efr thus yields frequency zero.
time point 1, Bob still considers threads possible, thus Bobs subjective
posterior probabilistic interpretation

Th
IB,1
(T ) = 0.7 0.02 0.09 0.02 0.09 0.01 0.02 0.02 0.03
equal prior interpretation given Example 3.6 (p. 53) possible pov threads
Th. Combining interpretation frequencies given yields sum
X
Th
IB,1
(T h) efr(T h, at(T1 , CA ), (at(T2 , CB ) on(A, T2 )), 7) = 0.92
hT

thus formula BB,1 valid.
Now, consider previously described situation, T1 running late
inform B it. leads updated interpretations given (6) (7)
page 54, i.e.,


h4
IA,3
=(

Th4
IB,3

0

0

0

0.4 0

0.2 0

0.4 0 ),



( 0.82 0.02 0.10 0.02 0 0.02 0 0.02 0 ).

updates lead significant divergence belief expected arrival time:
corresponding sum respect Alices updated interpretation
X
h4
IA,3
(T h) efr(T h, at(T1 , CA ), (at(T2 , CB ) on(A, T2 )), 7) = 0.4,
(23)
hT

(24)
obtained Alices subjective posterior probability assignment thread h4 ,
nonzero summand sum; threads h either impossible
h4
Alices point view (i.e., IA,3
(T h) = 0 threads h {T h1 , h2 , h3 , h5 , h7 , h9 }),
corresponding frequency zero (for threads h6 h8 ). Thus, Alices belief
arriving time point 8 latest drastically reduced, lower bound ` Alices
belief may exceed 0.4. instance,

0.4,1 ef r
BA,3
r8 (on(A, T1 ), (at(T2 , CB ) on(A, T2 ))) ,
(25)
valid belief formula. corresponding sum Bobs belief time point 3
X
h4
IB,3
(T h) efr(T h, at(T1 , CA ), (at(T2 , CB ) on(A, T2 )), 7) = 0.96,
(26)
hT

65

fiMartiny & Moller

obtained summing Bobs subjective posterior interpretations threads h1 , ..., h4 ;
remaining threads contribute zero summands either Bobs probability assignment corresponding frequency zero threads. Thus, Bobs
previous belief (expressed (22)) remains valid time point = 3, denoted BB,3 .
Even though Alices beliefs changed significantly, aware Bob maintains
beliefs conflicting own, shown following valid expression nested
beliefs:
1,1
BA,3
(BB,3 )
verify nested belief holds, need consider threads Alice considers
possible (T h4 , h6 , h8 ) determine Bobs hypothetical beliefs would
threads. h4 , already analyzed (26). Since threads h4 , h6 ,
h8 indistinguishable Bob time point 3, analysis results hold
three threads. Consequently, BB3 holds every thread Alice considers possible
therefore sum nested belief
X
Th
Ii,t
0 (T h) = 1,
hT

h |=B
IB,3
B,3

i.e., Alice knows Bobs belief outdated.
Finally, consider pointed doxastic system hD, Obs{AB} (at(T1 , CC ))3 i, i.e.,
situation difference Alice shares observation
delayed train Bob. immediately follows Bob updates beliefs
way Alice, turn yields update Alices beliefs Bobs beliefs
following expression valid (because 1 valid lower bound longer):
1,1
(BB,3 )
BA,3

example shows Alice reason influence actions
Bobs belief state therefore decide actions improve Bobs utility (as
wait vain).

4. Satisfiability Checking PDT Logic
section describe procedures check whether exists model
given set belief formulae B. discussions chapter, assume models
sets formulae finite. start formally defining satisfiability checking
problem PDT Logic. Using semantics previous section, derive model
checking algorithm based fully specified doxastic systems. Afterwards, show set
belief formulae used specify problem PDT Logic andtogether given
set threadshow transformed mixed integer linear program order
employ existing solvers decide satisfiability PDT Logic formulae. Finally, show
suitable threads derived given set belief formulae automatically. Using
transformations linear programs established approach deciding satisfiability
probabilistic logics, discussed example Fagin, Halpern, Megiddo (1990).
However, priors given, established decision procedures probabilistic logics
66

fiPDT Logic

applicable PDT Logic due formalisms update mechanism (cf. update rule
Definition 3.9, p. 54). update mechanism
fully specified doxastic system hD, Hi given, define problem checking
whether set belief formulae B satisfiable respect doxastic system

follows. Recall Section 3.2.4 use h denote set subjective
Th induced prior interpretation pov thread Th.
posterior interpretations Ii,t
0
Definition 4.1 (Satisfiability Checking PDT Logic). Let hD, Hi pointed doxastic
system set threads according prior interpretation specified hD, Hi,
B set belief formulae. say B satisfiable w.r.t. hD, Hi exists
thread Th corresponding interpretations satisfy belief formulae B
B:



sat(B, hD, Hi) Th : B B : h |= B
(27)
specification given, checking satisfiability B respect hD, Hi corresponds checking whether hD, Hi model B. continue introducing model
checking procedure fully specified input. Afterwards, discuss satisfiability
set belief formulae B decided prior probabilities, neither threads
prior probabilities given.
4.1 Model Checking Algorithm
first approach developing algorithm check whether given set belief formulae
B satisfied given pointed doxastic system hD, Hi (i.e., checking whether hD, Hi
model B) obtained direct application semantics belief
operator given Definition 3.11 (p. 57). Algorithm 1 shows resulting model checking
procedure. starts computing belief states possible evolutions world
= 1 tmax . Afterwards, iterates belief formulae B B potential
pov threads Thk determine whether interpretation respective pov thread
able satisfy current belief formula. thread unable satisfy belief formula,
excluded set potential pov threads subsequent checks. least one
potential pov thread remains belief formulae checked (i.e.,
least one thread Thk belief formulae B B satisfied), hD, Hi model
B.
Theorem 4.1 (Soundness completeness Algorithm 1). decision procedure Algorithm 1 sound complete therefore model checking procedure PDT Logic.
Proof. Since presented algorithm essentially inductive application Definition 3.16
(p. 63), easy see yields sound complete decision procedure PDT
`,u
`,u fr
Logic. Basic belief formulae (Bi,t
0 (Ft ) Bi,t0 (rt (F, G))) return satisfiability results
directly using respective semantic definitions (10) (11) calculation rules.
`,u
`,u
0
00
every possible compound belief formula PDT Logic (Bi,t
0 (), Bi,t0 (B), B B ,
0
00
B B ), procedure provides appropriate rule according Definition 3.16 break
formulae iteratively base formulae obtained, decided
above.
67

fiMartiny & Moller

Algorithm 1 Model Checking
procedure ModelChecking(hD, Hi, B)
h1
hm
bs(hD, Hi, 0) (AT
, ...,
)
0
0
1, tmax
bs(hD, Hi, t) bs(hD, Hi, 1) (UtT h1 , ..., UtT hm )
B B
Thk
Check(bs(hD, Hi), Thk , B))
\ {Thk }
=
return false
return true

. compute belief states

. check B satisfied Thk
. otherwise remove Thk threads check
. exit Th satisfy B
. success nonempty checking B B

function Check(bs(hD, Hi), Thk , B)
switch (B)
. check formulae according Def. 3.16
`,u
case Bi,t
0 ():
= B 0
. check nested belief formulae recursively (B 0 belief formula)
0

Check(bs(hD, Hi), hk , B ))
return false
Th
Pt0 bs(hD, Hi, t0 ) ~b()
. use ~b() (20) compute Pt0 elements pi,t0k
Th

Th

Th

. true pi,t0k [`, u]

return (` pi,t0k u pi,t0k )
`,u
case Bi,t
0 ():

Pt0 bs(hD, Hi, t0 ) ~b()
Th

Th

Th

. true pi,t0k 6 [`, u]

return (` pi,t0k u pi,t0k )
case B 0 B 00 :
return (Check(bs(hD, Hi), Thk , B 0 )
Check(bs(hD, Hi), Thk , B 00 ))
case B 0 B 00 :
return (Check(bs(hD, Hi), Thk , B 0 )
Check(bs(hD, Hi), Thk , B 00 ))

68

fiPDT Logic

asymptotic complexity Algorithm 1 depends number belief operators
`,u
Bi,t
0 () contained B:
Theorem 4.2 (Time complexity Algorithm 1). Let B set belief formulae let
k number belief operators contained within B. Then, using Algorithm 1 check
whether given pointed doxastic system hD, Hi threads model B time
complexity O(k m).
Proof. given pds threads k belief formulae B, main procedure calls
check function k times. B base formula single belief
`,u
operator Bi,t
0 (), single call check function return result. Otherwise,
`,u
belief formula B contains one belief operator Bi,t
0 (), check function
called recursively, base formulae obtained. Thus, k belief operators B,
satisfaction checks performed k times, yielding time complexity
O(k m).

Theorem 4.2 immediately obtain complexity result model checking
problem PDT Logic:
Corollary 4.3 (Complexity model checking PDT Logic). model checking problem
PDT Logic PTIME.
result shows model checking set belief formulae w.r.t. given pointed
doxastic system done polynomial time. fully specified pds (and thereby
exhaustive specification set possible threads ) given, result shows
Algorithm 1 presents tractable procedure perform model checking task. However,
approach significant drawback assumes exhaustive specification
together precise prior probability assignments I(T ). Although problem
domains actually come specification (e.g., cf. cyber security scenario
described introduction), assumption renders Algorithm 1 infeasible
problem domains. overcome problem, proceed discussing different
approach, enables satisfiability checking without requiring specification exact
probabilities. Moreover, show representative threads respect set belief
formulae B constructed automatically, positive satisfiability results
potentially obtained without requiring full materialization possible threads .
4.2 Compact Problem Specification
used (pointed) doxastic system specify problem domain model
checking set belief formulae B PDT Logic. following sections, show
reformulate problem extended set belief formulae together
value tmax used. main idea approach background knowledge regarding target domain given explicit specification possible threads
according probabilities, instead sets rules B describe target
domain may evolve time. approach several advantages: scenarios,
compared requiring exhaustive set possible threads, specifying set rules (which
expressed prior beliefs) gives natural means specifying background
69

fiMartiny & Moller

knowledge problem domain (e.g., cf. Example 3.2 page 47, actually starts
verbal description rules later introduces corresponding set possible
threads). Furthermore, using set rules describe problem domain fairly established approach therefore approach provide options simplify transformation
existing problem specifications PDT Logic. Finally, since set possible threads
grows exponentially every additional time point set time points every
additional ground atom language L, exhaustive problem specification
set possible threads quickly becomes infeasible, situation could
described succinctly small set rules. Even though succinct specification shifts exponential nature problem required input specification
computational efforts, show exponential effect curtailed heuristics
constructing possible threads automatically.
4.2.1 Identification Key Parameters Set Belief Formulae
simplify following discussion, restrict temporal rules use point
frequency function pfr. Recall point frequency functions used specify
event F followed another event G exactly time points, existential
frequency functions efr used specify event F followed another event G
within time interval t. existential frequency functions required specify problem
domain, rewrite disjunctions point frequency functions, following
proposition shows. frequency functions defined, presented techniques
easily adapted.
Proposition 4.4 (efr rewriting). existential frequency function efr equivalently
represented disjunction point frequency functions pfr:
efr
(F, G)
rt

_

pfr
rt
(F, G)

0tt

t:

Recall that, according Definitions 3.12 3.14 page 59, specification pds
consists set agents A, set threads , set frequency functions F, matrix
|A||T |

prior probability distributions A0
, set time-stamped observations H.
Since use point frequency functions following, set frequency
functions F always fixed {pfr}, thus need specify set separately.
Instead explicitly specifying set agents A, determine
`,u
belief expressions Bi,t
0 () contained set belief formulae B. slight abuse
`,u
`,u
notation, use Bi,t
0 () B denote belief operator Bi,t0 () appears somewhere
set belief formulae B. Then, define set agents AB specified set
belief formulae B
`,u
AB = {i : Bi,t
(28)
0 () B}

Generally, possible explicit specification set agents larger
set AB . However, obvious beliefs expressed agent (i.e.,
6 AB ), agent influence satisfiability checking results whatsoever.
Thus, agent simply disregarded and, consequently, suffices use set AB .
70

fiPDT Logic

Similarly, instead specifying set ground atoms language L
sets predicates Lpred constants Lcons , define set event formulae FB
representing belief objects occurring set belief formulae B
n

`,u
`,u fr
`,u fr
FB = F : Bi,t
.
(29)
0 (Ft ) B Bi,t0 (rt (F, G)) B Bi,t0 (rt (G, F )) B
definition gives rise potential definition set possible worlds
Herbrand base B FB FB (resp. set admissible worlds complying
Definition 3.5 (p. 48). However, show later, options constrain
sets possible worlds allow concise problem representation.
Note according Definition 3.2 (p. 45), formulae may include atoms
observation atoms. Consequently, FB specify ontic facts possible worlds,
also possible observations ontic facts. approach, occurrences
observations limited ones specified FB . seen specification
sensor model groups agents G AB .
Remark 4.1. strict application (29) would prohibit simple specifications group observations ObsG (l) |G| > 1 B. ensure set admissible worlds
actually
V
contains worlds ObsG (l), full specification observation G 0 G ObsG 0 (l)
B would required (otherwise might world B FB |= ObsG (l)
satisfies second property definition possible worlds (cf. Definition 3.5)).
However, required full specification observation admissible worlds determined solely simple observation specification ObsG (l). order keep
specification B compact possible,
allow simple specifications ObsG (l)
V
assume expanded G 0 G ObsG 0 (l) creating FB .
alternative approach would construct FB ontic facts appearing
B create set admissible worlds combining ontic facts possible
admissible observations w.r.t. Definition 3.5. approaches differ requirements
observation specifications: former requires specify every possible observation explicitly, latter requires exclude every impossible observation explicitly. Since
scenarios set observations actually possible (w.r.t. problem domain)
significantly smaller set admissible observations, presented approach
usually yield compact problem specification. desired, one could employ
latter approach instead without impacting functionality following methods.
Background knowledge regarding target domainthat given explicit
representation possible threads beforecan also specified prior beliefs (i.e.,
`,u
beliefs Bi,0
()) B. Recall Section 3.2.4 assume commonly known prior


h equal agents . belief semantics defined
distribution Ii,t
B


h (cf. Definition 3.11, p. 57), follows
respect probabilistic interpretations Ii,t
0

`,u
every prior belief Bi,0
() common knowledge well. Consequently, express
background knowledge prior beliefs arbitrary agent AB .
`,u fr
pointed Section 3, satisfiability beliefs temporal rules Bi,t
0 (rt (F, G))

certain properties independent respective set threads associated
interpretation I(T ) (cf. Remark 3.5, p. 58): respective frequency function corresponds
71

fiMartiny & Moller

FF1 FF2 Definition 3.10 (i.e., F contradiction, G tautology, F tautology G contradiction), beliefs either trivially satisfied quantifications
u = 1 (resp. ` = 0) generally unsatisfiable. former case, trivially satisfiable beliefs
disregarded without influencing satisfiability results, latter case satisfiability checking terminate immediately negative result. Thus, following
assume B contains beliefs rules correspond frequency function
axioms FF1 FF2.
Example 4.1 (Trains revisited). informal verbal description train problem
given Example 3.2 (p. 47) corresponding formal specification set
possible threads Example 3.4 (p. 51)and probability assignments Example 3.6 (p. 53).
Using considerations expression background knowledge beliefs rules,
reformulate verbal rules given Example 3.2 together probabilistic
information Example 3.6 set formal beliefs B according explanations
below:



1,1
1,1


B1 = BA,0
at(T
,
C
)

B
on(A,

)
,
1
1
1
1


A,0







.81,.81 pfr


(B20 )
r0 (at(T1 , CA ), punct(T1 ))
BA,0


B
=

2


.81,.81 pfr

BA,0
r0 (at(T2 , CC ), punct(T2 )) ,
(B200 )









1,1


r3pfr ( punct(T1 ) at(T1 , CA ), at(T2 , CC ) on(A, T2 )) (B30 )
BA,0


B3 =



1,1 pfr

BA,0
(r5 (punct(T1 ) at(T1 , CA ), at(T2 , CC ) on(A, T2 )) , (B300 )







1,1
B=
r2pfr ( punct(T2 ) at(T2 , CC ), at(T2 , CB ) on(A, T2 )) (B40 )
BA,0

B4 =



1,1


BA,0
r3pfr (punct(T2 ) at(T2 , CC ), at(T2 , CB ) on(A, T2 )) , (B400 )








1,1


B5 = BA,0
r0pfr (punct(train) at(train, city), Obs{A} (punct(train))) ,









.93,.93 pfr

B6 = BA,0
r2 (Obs{A} (punct(train)), Obs{AB} (punct(train))) ,









train {T1 , T2 },




city {C , C }


B













































































Note beliefs expressed time = 0, i.e., prior beliefs
definition commonly known among agents. beliefs expressed example
assigned A, could equivalently assigned B both.
B1 states train T1 city CA time = 1 Alice train. B2
states agents believe trains punctual (denoted punct(train))
probability 0.81. probability values example obtained summing
probabilities given Example 3.6 threads given Example 3.4 respective
belief object satisfied. equivalent representation previous example,
72

fiPDT Logic

use exact probability values (i.e., ` = u) instead intervals. Note punct(train)
additional predicate variable train helps formulate background knowledge
concise way. Formula B2 yet specify consequences non-punctual
train are, train expected punctual certain probability. B3 states
Alice able board train T2 three time steps train T1 punctual
Alice wait two additional time points otherwise. B4 states train T2
arrive city CB two time points city CC . Otherwise arrive one
time point later. B5 states Alice always notice train leaves city
punctually. example sensor model specification discussed above. Finally,
B6 states Alice call Bob probability 0.93 train punctual.
Example 4.2 (Trains continued). definition set belief formulae B
example, also specify set event formulae FB required model
possible scenarios described B:






at(T
,
C
),
at(T
,
C
),
at(T
,
C
),
at(T
,
C
),
1
1
2
2

B
B
C






on(A, ), on(A, ), punct(T ), punct(T ),

1
2
1
2
FB =


Obs{A} (punct(T1 )), Obs{AB} (punct(T1 )),








Obs (punct(T2 )), Obs

(punct(T
))
2
{A}
{AB}
simplify following discussion, assume conjunctive formulae B = B 0
B replaced individual formulae respective conjuncts: B = B \
{B} {B 0 , B 00 }. impact satisfiability checking properties B
formulae B satisfied simultaneously order return positive result
thus, B 0 B 00 satisfied, regardless representation two
individual formulae one conjunction.
Now, remains determined set threads , corresponding prior
B 00

|A||T |

probability distribution I(T ) (resp. matrix prior probability distributions A0
,
every row formed I(T )), possibly set time-stamped observation atoms
H. tasks determining H treated jointly: since set relevant
threads needs determined anyway, simply create |= H.
next section show transform set PDT Logic belief formulae
B together given set threads linear program order determine
satisfiability B respect . Afterwards, discuss suitable set
threads represent information contained B constructed automatically.
Using results, possible model problem domain PDT Logic solely
set belief formulae B together specification maximum time point tmax .
key parameters domainsuch set agents set ground
atomscan extracted B automatically.
4.3 Representing Satisfiability Problem Linear Program

considerations previous section show parameters problem
specification extracted given set belief formulae B. section,
assume set belief formulae B together set possible threads given.
73

fiMartiny & Moller

B satisfiable respect (denoted sat(B, )) prior interpretation I(T )
found belief formulae B satisfied. extracting linear constraints
I(T ) B, show satisfiability problem transformed linear
program. Checking satisfiability B respect equivalent checking
whether corresponding linear program feasible solution.
given set threads unknown prior interpretation I(T ), satisfiability
checking task significantly increases complexity compared model checking task.
Formulation satisfiability checking problem Definition 4.1 (p. 67) might somewhat delusive: existence single thread context interpretation
suffices verify satisfiability set belief formulae B, appears intuitive develop
method construct threadif possibleand neglect threads, or, vice
versa, start entire set threads iteratively prune threads fail satisfy formula B. fact, pruning approach used Algorithm 1 (p.68)
check whether given set threads model set belief formulae. Unfortunately,
approaches inapplicable prior interpretation unknown. semantics
belief operators (cf. Definition 3.11 (p. 57) relies subjective posterior probabilistic interpretations (i.e., probability assignments multiple threads), generally possible
find single thread Th satisfying satisfiability checking problem Definition 4.1
without determining probabilities threads. Vice versa, generally possible
discard thread, determining whether satisfies belief formula
done respective probability assignment known. Instead, show belief
formulae equivalently expressed sets linear constraints unknown prior
interpretation I(T ). Then, checking satisfiability B equivalent checking whether
possible assignment I(T ) constraints satisfied.
use xk denote unknown prior probability thread hk , i.e., contains
threads, unknown prior probability assignment represented
I(T ) = x1 , , xm



.

(30)

goal following methods provide constraints xk belief
formulae B B satisfied. Since variables represent probability distribution
set threads, two obvious constraints begin with:
0 xk 1, k {1, ..., m}



X

xk = 1

(31)

(32)

k=1

4.3.1 Representation Subjective Posterior Probabilities
Since semantics beliefs defined terms respective agents subjective probability assignments respective pov thread, need means express subjective
Th agent terms prior probability
posterior probabilistic interpretations Ii,t
0
values xk . interpretations change time point whenever observation Obs{i} (l)t
possible agent i. observation possible agent, partition set
threads two sets: one partition containing set threads agent observe
74

fiPDT Logic

respective fact l one partition agent observe respective fact.
subjective probability assignments need updated within partition reflect
information observation occurrences: Taking every thread within partition
possible pov thread, probability assignments threads within partition
need scaled according update rule Definition 3.9 pov thread specific
probability assignments threads outside respective partition need set
zero.
Generally, leads one vector subjective probabilities threads every
possible pov thread (cf. Definition belief states Equation (17), p. 61). However,
leverage semantic properties PDT Logic obtain parsimonious representation
updated subjective probabilities without representing every pov thread explicitly.
Note threads within one partition described indistinguishable agent
respective time point (i.e., threads within one partition exhibit exactly
set observations agent time point t) therefore receive probability
assignment every possible pov thread within partition (cf. Proposition 3.6, p. 62).
Consequently, updated probability assignments every thread receive
one two different types value assignments: scaled version threads previous
probability assignment according Definition 3.9 (p. 54), zero, depending whether
agent actually observes fact l not. following proposition shows
need consider cases zero probabilities order perform satisfiability checking
tasks.


h subjective posterior
Proposition 4.5 (Irrelevance zero-interpretations). Let Ii,t
0
0
probability interpretation time agent pov thread Th (i.e., interpreta-

tion determined prior interpretation interpretation updates corresponding
pov thread Th). interpretation assigns probability zero thread h (i.e.,
Th (T h) = 0), satisfiability subsequent nontrivial belief B 00 () t00 > t0
Ii,t
0
i,t


h (T h).
independent Ii,t
0

`,u
Proof. Every belief Bi,t
0 () ` > 0 fact another belief (i.e., = Ft
` ,u

= Bj,tj j ()) requires needs least one thread h nonzero


h (T h) = 0 clearly
probability h |= . Therefore, thread h Ii,t
0
`,u
00
0
prove satisfiability belief Bi,t
00 () . negative satisfiability result (i.e., B

unsatisfiable w.r.t. ) cannot obtained zero assignment either,
consistent interpretation (i.e., probability assignments threads sum one)
needs assign nonzero probability least one thread, could possibly
`,u
satisfy belief. considerations hold beliefs Bi,t
0 () ` = 0 u < 1:


h (T h) = 0 satisfies lower bound ` = 0, upper bound u < 1
Although thread Ii,t
0


h (T h0 ) > 0
requires existence another thread h0 nonzero probability Ii,t
0


h (T h) = 0 prove satisfiability beliefs B `,u ()
h0 |= . Consequently, Ii,t
0
i,t0
` = 0 u = 1. trivial beliefs satisfied every thread
every possible probability assignment thus, satisfiability proven without
Th (T h) = 0, too.
Ii,t
0

75

fiMartiny & Moller

`,u fr
Analogous considerations hold beliefs rules: belief Bi,t
0 (rt (F, G)) ` > 0
requires existence thread nonzero probability fr(T h, F, G, t) > 0,
Th (T h) = 0 cannot prove satisfiability belief. Satisfiaand thus thread h Ii,t
0
`,u fr
bility belief Bi,t
0 (rt (F, G)) ` = 0 u < 1 depends respective frequencies
0
fr(T h , F, G, t) additional threads h0 nonzero probabilities.

result proposition, merge nonzero entries cases (agent
observes fact l agent observe fact l) single probability
distribution vector agent time point t. yields modified version
update rule Definition 3.9. use modified update rule determine linear
constraints unknown prior probabilities xk .
Definition 4.2 (Modified update rule). Let agent, t0 time point observation Obs{i} (l) occur h thread. Then, compressed subjective posterior
probability assignment Ii,t0 (T h) agent time t0 thread h given
Ii,t0 (T h) =

1
Ii,t0 1 (T h)
Th
i,t
0

(33)

h normalization factor ensure probabilities threads
i,t
0
agent considers possible sum one:
X
Th
Ii,t0 (T h0 )
i,t
0 =
h0 (t0 )Ki (T h(t0 ))

Example 4.3 (Modified update rule). illustrate modified update rule, return
situation described Example 3.7 (p. 54). example assumed train T1
running late inform B it. resulted following updated
interpretation A:

Th8
Th6
Th4
= 0 0 0 0.4 0 0.2 0 0.4 0
= IA,3
= IA,3
IA,3
given example, two additional hypothetical partitions set threads
possible Alice time point = 3 . train T1 running late inform
B it, threads h5 , h7 , h9 indistinguishable A, yielding updated
subjective interpretation

Th5
Th7
Th9
IA,3
= IA,3
= IA,3
= 0 0 0 0 0.14 0 0.65 0 0.21
T1 time, Alice considers threads h1 , h2 , h3 possible. corresponding
subjective interpretation

Th1
Th2
Th3
IA,3
= IA,3
= IA,3
= 0.86 0.03 0.11 0 0 0 0 0 0
three different subjective interpretations nonzero entries exactly threads
partitions respective pov thread. Since partitions overlapping, merge nonzero entries single probability vector

IA,3 = 0.86 0.03 0.11 0.4 0.14 0.2 0.65 0.4 0.21 .
76

fiPDT Logic

Note modified update rule, update pov thread specify interpretations threads anymore, instead reflexive interpretations
thread h, given h pov thread, used. discussed above,
satisfiability problem still sufficient representation posterior probabilities,
potential pov threads Th respective partition indistinguishable
agent therefore yield exactly interpretations. noted however Ii,t0 (T h) probabilistic vector anymore, i.e., elements sum
one. Compared representation belief states Section 3.3.1 (p. 61), information
distinguishable worlds lost. Thus, reconstruction agents belief state
representation possible additional specification respective relations
Ki .
Returning problem representation (30) (p. 74), use modified update rule obtain inductive definition subjective posterior probabilities based

respective (unknown) prior probabilities xk . I(T ) = x1 , , xm prior interpretation set threads, agent compressed subjective posterior interpretations
Ii,t0 time point t0 first possible interpretation represented
Ii,t0 (T ) =



1
1i,t0

x1 , ,

1

i,t0

xm



0



,

(34)

k determined
update factors i,t
0

1
i,t
0



i,t
1,1



.


i,t
x
,



,
x
=

0
1

..


..
.

0

i,t
m,1

i,t0

j,k


0
i,t
1,m
..

. ,
0

i,t
m,m

(
1 hk (t0 ) Ki (T hj (t0 ))
=
0 hk (t0 ) 6 Ki (T hj (t0 ))
0

(symmetric) matrix indicators i,t
j,k denoting whether agent considers thread
0
hk possible thread hj time . Using (34) base case, define
interpretation updates next possible observation time t00 inductively
Ii,t00 (T ) =



1
1i,t00



1
1i,t0

x1 , ,

1


i,t00



1


i,t0

xm



(35)

simplify notation, following use single factor aki,t0 represent agk k ...) observations occur
gregated sequence scaling factors (i,t
i,t2
1
time points t1 , t2 , ... = 1 = t0 agent i, i.e., agent subjective posterior
interpretations Ii,t0 (T ) time t0 given
Ii,t0 (T ) = a1i,t0 x1 , ,
i,t0 xm



.

(36)

Note potential interpretation updates agent occur time point
observation Obs{i} (l) possible time point. Hence, time
interval two possible observations, subjective interpretations constant:
77

fiMartiny & Moller

Proposition 4.6 (Piecewise constant interpretations). Let t1 t2 t1 < t2 two
time points observations agent possible t1 t2 , time
point t1 t2 . Then, compressed subjective interpretation Ii,t0 (T )
constant time points t1 < t2 :
[t1 , t2 1] : Ii,t (T ) = Ii,t1 (T )
proposition states constraints identified following section
restrict subjective interpretations single time points, instead restrict
interpretations respective time interval two possible observations.
4.3.2 Extracting Linear Constraints Belief Formulae
established representation (36) subjective posterior interpretations
terms unknown prior probabilities xk , use representation extract linear
constraints xk set belief formulae B.
assume distributive property belief operator Lemma 3.7 (p. 64)
`,u
applied whenever possible, i.e., belief formulae Bi,t
0 (B1 B2 ) {, }
`,u
`,u
separated Bi,t
0 (B1 )Bi,t0 (B2 ). Furthermore, without loss generality, assume
conjunctive formulae B = B1 B2 replaced B \ {B} {B1 , B2 }
trivial beliefs (with ` = 0 u = 1) removed B.
Moreover, assume belief formulae B B represented negation normal
form (NNF), i.e., negation operator applied atoms. Since arbitrary logic
formula equivalently expressed formula NNF (cf. e.g., Baaz, Egly, Leitsch,
Goubault-Larrecq, & Plaisted, 2001), assumption restrict B either.
assumptions, following types belief formulae B occur B:
`,u
atomic belief formulae B = Bi,t
0 ()
`,u
negated atomic belief formulae B = Bi,t
0 ()

disjunctive belief formulae B = B1 B2
types, show respective formula expressed
set linear constraints prior probabilities xk .
Atomic Belief Formulae Using parsimonious representation subjective posterior
interpretations Ii,t0 (T h) given modified update rule Definition 4.2 requires
adaption deciding satisfiability belief formulae. Before, satisfaction belief
formula given pov thread could determined summing respective subjective interpretations threads belief object satisfied. Threads
agent consider possible anymore w.r.t. given pov thread automatically
excluded probability assignment zero. compressed representation,
respective probability assignments threads considered impossible overloaded
different probability assignments given agent another pov thread, illustrated
Example 4.3. obtain adapted version satisfiability testing explicitly ensuring
interpretations threads summed still considered possible
w.r.t. respective pov thread. additional constraint excludes summands
78

fiPDT Logic

zero-values, original semantics still maintained. Thus, use equivalence classes
1 , C 2 , ...} represent set distinguishable situations agent time t0 .
Ci,t0 = {Ci,t
0
i,t0
Naturally, two threads h1 , h2 indistinguishable therefore equivalence
class agent time t0 , exhibit exactly observations agent
time points {1, .., t0 }. threads outside particular equivalence class receive
probability zero every pov thread Th within respective equivalence class andas
discussed previous sectiontherefore contribute satisfiability properties. Then, belief semantics Definition 3.11 (p. 57), instead summing
k : (Th C k )
threads h certain properties, restrict range h Ci,t
i,t
maintaining original semantics. Naturally, belief formula satisfiable
exists least one equivalence class satisfies respective beliefs. instance,
`,u
belief fact Bi,t
0 (Ft ) satisfiable respect agent compressed subjective
posterior interpretation Ii,t0 time t0 iff
k
Ci,t
0 Ci,t0 : `

X
n:

k h (t)|=F )
(T hn Ci,t
n
0

ani,t0 xn u

(37)

constraint equivalently expressed set linear inequalities
conjunctive disjunctive connectives, leading alternative representation
satisfiability problem.
Corollary 4.7 (Alternative satisfiability representation atomic beliefs). Let Ii,t0 (T ) =


a1i,t0 x1 , ,
Ij,t (T ) = a1j,t x1 , ,
compressed
j,t xm
i,t0 xm
representation agent js respective subjective posterior probabilities time t0
t, respectively, given (36), let Ci,t0 Cj,t sets worlds agent
agent j distinguish respective time point. Then, atomic belief expression B
satisfiable w.r.t. Ii,t0 (T )
`,u
1. belief fact B = Bi,t
0 (Ft ) iff



_
k C
Ci,t
0
i,t0

X
k
(T hn Ci,t
0

n:
hn (t)|=F )

ani,t0



xn `



X
k
(T hn Ci,t
0

n:
hn (t)|=F )

ani,t0


xn u

!
(38)

`,u pfr
2. belief rule B = Bi,t
0 (rt (F, G)) iff

_



k C
Ci,t
0
i,t0

X
k )
n: (T hn Ci,t
0




X
n:

k )
(T hn Ci,t
0


ani,t0 xn pfr(T hn , F, G, t) `
ani,t0 xn pfr(T hn , F, G, t)

79


u

!
(39)

fiMartiny & Moller

` ,u

`,u
j j
3. nested belief B = Bi,t
()) iff
0 (Bj,t

_



k C
Ci,t
0
i,t0

X
k )
n: (T hn Cj,t
k
k }6=)
hn |= ({Cj,t Ci,t
0




X
k )
n: (T hn Cj,t
k C k }6=)
hn |= ({Cj,t
i,t0




X

X
n:

anj,t xn

ani,t0 xn

k C k }
hn {Cj,t
0
i,t0



uj

ani,t0 xn `

k C k }
n: hn {Cj,t
i,t0
hn |=




anj,t xn `j

u







!
(40)

hn |=

discussed above, representations satisfiability beliefs facts (38) beliefs
rules (39) obtained directly replacing range threads sum
k considered possible agent time t0 . inequalities
respective set threads Cj,t
0
nested beliefs (40) obtained ensuring first two lines every situation
agent conceives possible situation agent j (expressed constraint
k ) C k C k 6= ), agent js belief respective fact (expressed
n : (T hn Cj,t
j,t
i,t0
constraint hn |= ) within [`j , uj ]. latter two lines ensure
respective situations, outer belief agent satisfied, well. Note
belief object (40) might contain additional belief operators, i.e., beliefs multiple
levels nesting expressed. case, evaluation h |= first two lines
(40) yields additional constraints type (38)(40), formula evaluated
recursively.
Negated Atomic Belief Formulae satisfy negated atomic belief formula B =
`,u
Bi,t
0 (), accumulated probabilities threads satisfy belief object
k must either lower ` higher u, i.e., individual
equivalence class Ci,t
0
disjuncts
(38)(40) negated. pushing negations inward using
X
( ) representative respective sums defined (38) (39) express


satisfiability atomic beliefs, represent negations according beliefs expressed
(38) (39)
!
X
X

_

( ) < `
( ) < u .
(41)
k C
Ci,t
0
i,t0





nested beliefs defined (40) contain negated belief operators, expressed
accordingly replacing conjunctive constraints ` u (resp. `j uj )
corresponding disjunctive constraints (41) negated atomic belief formulae.
80

fiPDT Logic

Disjunctive Belief Formulae inequalities, required constraints
disjunctive formula B = B1 B2 easily expressed additional disjunction
inequalities. Let C1 C2 sets inequalities express satisfiability B1 B2
according (38)(41), respectively. Then, constraints B expressed
C1 C2

(42)

Example 4.4 (Trains continued). Example 4.1 (p. 72), set belief formulae B
given train example. illustrate extraction linear constraints
set, continue use set threads depicted Figure 1 (p. 50) minor
modification: reflect model specified B Example 4.1, assume
predicate punct(train) explicitly encoded respective threads. Moreover,
sake example assume prior probabilistic interpretations yet unknown.
use x1 , ..., x9 denote unknown probabilities. Note example,
dealing prior beliefs, i.e., one equivalence class C =
scaling factors ani,t0 equal one. significantly eases presentation
example. course, general deal multiple equivalence classes
multiple varying scaling factors. highly increases complexity presentation,
refrain giving explicit examples cases. constraints B extracted
follows:

.81,.81 pfr
r0 (at(T1 , CA ), punct(T1 )) :
belief B20 = BA,0
pfr(T h, at(T1 , CA ), punct(T1 ), 0) = 1 h {T h1 , ..., h3 }

pfr(T h, at(T1 , CA ), punct(T1 ), 0) = 0 h {T h4 , ..., h9 }

thus application rule (39) yields constraints
x1 x2 x3 0.81
x1 + x2 + x3

0.81

special case ` = u, simplify constraint
x1 + x2 + x3 =

0.81

Since rules exhibit property, slightly deviate (39)
give equivalent equality constraints subsequent rules order simplify
presentation.

.81,.81 pfr
Accordingly, belief B200 = BA,0
r0 (at(T2 , CC ), punct(T2 )) obtain:
pfr(T h, at(T2 , CC ), punct(T2 ), 0) = 1 h {T h1 , h4 , h5 }

pfr(T h, at(T2 , CC ), punct(T2 ), 0) = 0 h {T h2 , h3 , h6 ..., h9 }

corresponding constraints
x1 + x4 + x5 =
81

0.81

fiMartiny & Moller


.93,.93 pfr
belief B6 = BA,0
r2 (Obs{A} (punct(train)), Obs{AB} (punct(train))) :
h {T h1 , h3 , h5 , h9 } :

pfr(T h, punct(train), Obs{AB} (punct(train)), 2) = 1,

h {T h2 , h4 , h6 } :

pfr(T h, punct(train), Obs{AB} (punct(train)), 2) = 0,

h {T h7 , h8 } :

pfr(T h, punct(train), Obs{AB} (punct(train)), 2) = 0.5

thus application rule (39) yields constraint
x1 + x3 + x5 + 0.5 x7 + 0.5 x8 + x9 = 0.93
remaining beliefs, respective belief objects satisfied every thread
thus obtain redundant constraints
9
X

xk = 1.

k=1

One easily verify prior probabilistic interpretation given Example 3.6, i.e.,

x = 0.7 0.02 0.09 0.02 0.09 0.01 0.02 0.02 0.03
indeed solution respect constraints. course, given
example, solution expected, B defined exactly reflects
situation described examples previous section.
4.3.3 Transformation Disjunctive Program
every belief formula B B, extractions linear constraints yield set
inequalities form
ai,1 x1 + ai,2 x2 + ... + ai,m xm bi ,

(43)

xj representing unknown prior probabilities threads h1 , ..., hm , coefficients
ai,j set respective values ani,t0 contribute constraint set zero
otherwise, value b1 set respective limit obtained ` u.
Corollary 4.7 shows, every belief formula B B yields disjunctive set inequality
constraints, i.e., every belief formula B introduces branches set linear constraints.
collecting inequalities form (43) constrain single branch, express
constraints matrix form:
Ax b,
(44)




a1,1
..
A= .
an,1


..
.





a1,m
x1
b1
.. , x = , b =
.
xm
bm
an,m
82

fiPDT Logic

form representation close connection linear programming (LP). Linear
programming (e.g., Murty, 1983) solution method optimization problems
linear function set continuous variables xk optimized respect given
set linear constraints. task satisfiability checking require
optimization thus actually solving linear program required work,
exploit similarities sets linear constraints LP order show
satisfiability problem solved.
standard form LP problem (Murty, 1983) gives set constraints exactly
form (44). Every solution x satisfies constraints called feasible
entire solution space (44) called feasible region. Thus, checking whether set belief
formulae B satisfiable equivalent checking whether corresponding LP problem
non-empty feasible region. standard LP problems constraints form
(44), feasible region convex polytope, allows performing check little
computational effort (Garey & Johnson, 1979).
Unfortunately, extracting linear constraints set belief formulae B described
Section 4.3.2 yield single set constraints form (44), instead
disjunction different sets constraints. gives rise representation
satisfiability checking problem disjunctive program (DP) (Balas, 1998):
Corollary 4.8 (Satisfiability Checking Disjunctive Program). Let B set belief
formulae, let set threads let set disjunctive branches linear
constraints extracted B according extraction rules (38)-(42). Then,
satisfiability checking problem formulated disjunctive program (Balas, 1998):
_
Ad x bd
(45)
dD

B satisfiable respect , denoted sat(B, ), (45) solution.
disjunctive program called bounded, range every variable xk restricted
lower upper bounds. Since rely bounded property subsequently,
state following result:
Lemma 4.9 (Satisfiability Checking Bounded DP). Let B set belief formulae
set threads. Checking satisfiability B respect represented
bounded disjunctive program.
Proof. straightforward result: Corollary 4.8 shows satisfiability checking
PDT Logic represented disjunctive program form (45). Since
every variable xk (45) represents probability value, xk naturally bounded
0 xk 1.
disjunctive program, feasible region cannot guaranteed convex anymore,
guaranteed solution space even represents connected region.
significantly increases complexity determining whether nonempty solution space
exists. analyze problem detail show connections established
solution approaches, discuss next section disjunctive program
form (45) transformed.
83

fiMartiny & Moller

4.3.4 Transformation 0-1 Mixed Integer Linear Program
concept linear programs continuous variables xk subject linear constraints
form (43) extended so-called mixed integer linear programs (MILPs) (Schrijver,
1986). Opposed standard linear programming, MILPs required
variables xk continuous domain. Instead, MILPs use mix continuous
integer variables. several equivalent ways representing MILP, adopt
representation Fischetti, Glover, Lodi (2005), specifies constraints
MILP
Ax b

xj integer

j

index set indicating variables xj integer variables. special
case MILPs 0-1 mixed integer linear programs (Williams, 2009), integer
variables xj restricted binary values:
Ax b

xj {0, 1}

(46)
j

augmenting set variables x binary switching variables xj every possible
disjunction, possible represent disjunctive programs form (45) 0-1 MILPs
form (46) (Balas, 1985). leads central result satisfiability checking
PDT Logic:
Theorem 4.10 (Satisfiability Checking 0-1 MILP). Let B set belief formulae
set threads. problem checking satisfiability B respect
transformed corresponding 0-1 mixed integer linear program B
satisfiable respect iff feasible solution.
Proof. Lemma 4.9 shows satisfiability checking PDT Logic represented
bounded disjunctive program, set belief formulae B satisfiable iff
corresponding bounded disjunctive program feasible solution. proof Theorem
4.4 Balas (1985) shows every bounded disjunctive program equivalently
represented 0-1 mixed integer program . Consequently, satisfiability checking
PDT Logic equivalent checking whether feasible solution.
leverage Theorem 4.10 obtain complexity results satisfiability problem
PDT Logic:
Theorem 4.11 (Complexity PDT SAT w.r.t. given set threads). Checking satisfiability set PDT Logic belief formulae B respect given set threads
NP-complete.
Proof. generally known checking whether bounded 0-1 mixed integer linear
program feasible solution NP-complete (cf. Bienstock, 1996). Theorem 4.10
shows satisfiability checking PDT Logic respect given set threads
reformulated 0-1 MILP bounded variables xk (cf. Lemma 4.9), follows
84

fiPDT Logic

satisfiability checking set belief formulae B respect given set threads
NP.
Arbitrary propositional formulae F (cf. Definition 3.2, p. 45) expressed PDT
1,1
Logic using belief object strict prior belief Bi,0
(F ). Since well known
boolean satisfiability problem (SAT) NP-complete (Cook, 1971), follows
problem NP transformed satisfiability checking problem PDT Logic.
Hence, satisfiability checking problem PDT Logic NP-hard consequently NPcomplete.
NP-completeness result shows problem NP therefore immediately obtain another important property satisfiability problem PDT Logic:
Corollary 4.12 (Decidability PDT SAT). Checking satisfiability set PDT Logic
belief formulae B decidable.
MILPs subject extensive research decades, thus ample variety
solving methods proposed (e.g., Balas, Ceria, & Cornuejols, 1993, Balas, Ceria,
& Cornuejols, 1996, Balas & Perregaard, 2002, name notable work
MILP solving, especially Fischetti et al., 2005 Bertacco, Fischetti, & Lodi, 2007
find feasible solutions MILPs). research gave rise various efficient implementations
MILP solvers, commercial (e.g., ILOG, 2016, Gurobi Optimization, Inc., 2016)
non-profit products (e.g., Gnu Project, 2016, Computational Infrastructure Operations
Research (COIN-OR) Project, 2016). given set threads, PDT Logic satisfiability
checking reformulated 0-1 MILP problem, thus state-of-the-art
MILP solvers exploited relatively fast satisfiability checks instances
PDT Logic belief formulae B respect given set threads .
results section show satisfiability set PDT Logic belief formulae B decided respect given set threads, even specific prior
probability assignment specified. overall goal section design
decision procedure requires set belief formulae B input, continue
discussion satisfiability testing development method automatically
construct set threads representing background knowledge specified B.
4.4 Prior Constraints Possible Threads
determine whether set belief formulae B satisfiable, need obtain set
possible threads reflects background knowledge specified B. section,
describe identify certain constraints set possible threads prior
actually starting generate threads represent information specified B.
identify prior constraints, discuss different properties belief formulae contained B. Using properties, create taxonomy belief formulae depending
respective impact set possible threads . Beliefs certain properties
used constrain search space sets possible threads prior actually search sets. discussing prior constraints section, use
results Section 4.5 develop decision procedure PDT Logic requires neither
specification probabilities specification possible threads.
85

fiMartiny & Moller

4.4.1 Taxonomy Belief Formulae
set belief formulae B may contain beliefs various features different
impacts sets admissible worlds specific time points t. discuss
features show yield taxonomy belief formulae. taxonomy
allows classification beliefs three different types respect impact
sets admissible worlds. particular, identify beliefs independent
specific probability assignment Kripke relations Ki . classification
technical purposes: beliefs depend neither specific probability assignments
specific Kripke relations used derive initial constraints sets possible
worlds time points tmax . use B denote set worlds
admissible respect set belief formulae B, use B (t) denote set
admissible worlds respect set belief formulae B time t.
Recall three different kinds beliefs: beliefs facts, beliefs rules,
beliefs beliefs. before, differentiate prior beliefs hold time point
= 0 (and therefore commonly known among agents) posterior beliefs hold
time points > 0.
`,u pfr
distinguish beliefs rules Bi,t
0 (rt (F, G)) respect t: call
pfr
pfr
(F, G) dynamic rule > 0. Accordingly,
(F, G) static rule = 0 call rt
rt
separate beliefs rules beliefs static rules beliefs dynamic rules,
respectively. beliefs differ respect temporal impact: static rule
constrain possible worlds instantaneously, i.e., r0pfr (F, G) states
world |= F 6|= G hold. dynamic rule hand requires
whenever world |= F occurs, must another world 0 0 |= G
time steps.
Finally, classify beliefs respect probabilistic quantifications: call
`,u
belief Bi,t
0 () strict, ` = u = 0 ` = u = 1. sake simplicity,
following assume without loss generality strict beliefs always represented
0,0
1,1
` = u = 1. strict belief Bi,t
() easily rewritten Bi,t
().5 call belief
trivial ` = 0 u = 1. Obviously, beliefs trivially satisfied arbitrary
interpretation, thus impact satisfiability checking results therefore
removed B.
Remark 4.2. definition belief semantics (Definition 3.11, p. 57) follows
1,1
special case strict beliefs Bi,t
() (i) agent considers occurrence belief
objects complement impossible (ii) occurrence indeed impossible.
Thus, strict beliefs comply common definitions knowledge justified true belief
belief stable respect truth (cf. e.g., Shoham & Leyton-Brown, 2009,
page 433). Consequently, could also refer strict belief knowledge equivalently
use established knowledge operator Ki () instead Bi1,1 ().
1,1
Remark 4.3. Note concept strict beliefs applies positive beliefs Bi,t
().
1,1
negation belief, Bi,t (), follows Definition 3.16 (p. 63)
fr
fr
5. belief object temporal rule rt
(F, G), represent rt
(F, G). possible
need consider frequency functions correspond axioms FF1 FF2
Definition 3.10 (p. 55) use point frequency functions pfr. frequency functions used,
negations need defined accordingly.

86

fiPDT Logic

least one thread satisfy belief object , turn implies ` < 1.
1,1
Consequently, beliefs Bi,t
() considered non-strict following discussion.

Using features, create taxonomy beliefs depicted Figure 3
identify prior constraints set possible threads. taxonomy obtained
successively distinguishing strict non-strict, prior posterior beliefs,
beliefs facts, rules nested beliefs, finally beliefs static dynamic
rules. Nested beliefs considered strict (prior) beliefs, involved beliefs
strict (prior), otherwise considered non-strict (posterior). nested belief
actually strict prior, unnest belief consider innermost belief
expression: since prior beliefs commonly known therefore identical agents
AB , evident strict belief agent i, agents know agent
strict belief. Consequently, strict prior beliefs nested arbitrary depth
without introducing constraints: satisfied exactly innermost
belief satisfied. Thus, need consider nested strict prior beliefs explicitly.
taxonomy gives rise three different types belief formulae respect
impact sets admissible worlds:
Definition 4.3 (Belief formula typification). set belief formulae B categorized
three different types beliefs:
Type 0: beliefs restrict set admissible worlds B (t) every
time point . Thus, type 0 beliefs highest impact
exploited prune set admissible worlds B globally. evaluation
beliefs relies neither specific probability assignment given Kripke
structures Ki .
Type 1: beliefs restrict sequences possible worlds. Moreover,
potentially restrict sets admissible worlds B (t) specific time points.
Thus, type 1 beliefs less impact type 0 beliefs
exploited prune sets admissible worlds B (t) locally. Again, evaluation
beliefs relies neither specific probability assignment given
Kripke structures Ki .
Type 2: type encompasses remaining beliefs B neither type 0
type 1 beliefs. beliefs situation-specific cannot used prune
sets admissible worlds priori. Satisfiability beliefs depends suitable
probability assignment evaluation Kripke structures respective
threads.
use Tk (B) denote set type k beliefs B.
main goal belief formula taxonomy identify constraints possible
worlds possible threads h evaluated prior searching suitable
probability assignment, namely using belief formulae T0 (B) T1 (B) prune
search space possible sets threads may show satisfiability B.
noted existence thread h violating belief T0 (B) T1 (B)
technically preclude satisfiability B respect , special
87

fiMartiny & Moller

beliefs

non-strict beliefs
`<1

strict beliefs
`=1

` = 1,
innermost beprior beliefs
lief interest

posterior beliefs
t0 > 0

0

=0
belief 0 beliefs
1,1
` ,u0
Bi,0
(Bj,t
())

belief beliefs
`,u
1,1
B1,1
0 (Bj,t ())
TF
1 (B)

belief rules
1,1 fr
Bi,0
(rt (F, G))

belief facts
1,1
Bi,0
(Ft )

disjunctive belief
formulae
1,1
1,1
Bi,0
(1 ) Bi,0
(2 )

belief dynamic rules
> 0

belief facts
1,1
Bi,t
0 (Ft )
belief rules
1,1 fr
Bi,t
0 (rt (F, G))

disjunctive belief
formulae
1,1
1,1
Bi,0
(1 ) Bi,0
(2 )

belief dynamic rules
> 0

T1 (B)

belief static rules
= 0
T0 (B)

Type 0: beliefs
highest impact,
restrict every
world every time point.

belief static rules
= 0

Type 1: beliefs restrict threads independently probabiliy assignment.
Moreover, potentially restrict possible worlds individual time points.

Figure 3: Taxonomy belief formulae

88

T2 (B)

Type 2: remaining beliefs;
treated way.

fiPDT Logic

case suitable probability assignment: thread h
belief B T0 (B) B T1 (B) satisfied, could still suitable probability
assignments I(T ) sat(B, ) holds iff I(T h) = 0. effect excluding
thread h assigning prior probability I(T h) zero (cf. Remark 3.3,
p. 53), i.e., respective thread marked impossible. Since aim reducing
search space possible threads input satisfiability check sat(B, ),
exploit belief formulae T0 (B) T1 (B) exclude impossible threads prior searching
suitable probability assignments.
Type 0 belief formulae depicted Figure 3, set type 0 belief formulae
1,1 pfr
formed formulae strict prior beliefs static rules Bi,0
(r0 (F, G)) B. Since
prior beliefs represent background knowledge since follows definition
strict beliefs cannot violated world, clear rule r0pfr (F, G)
always satisfied. static rule, satisfied every world
B . define set type 0 beliefs
1,1 pfr
T0 (B) = {B B : B = Bi,0
(r0 (F, G))}

(47)

arbitrary formulae F G.
Type 1 belief formulae set type 1 beliefs contains strict prior beliefs
set T0 (B). contributions set T1 (B) twofold: T1 (B)
comprises strict prior beliefs, every thread potential set threads satisfy
beliefs B T1 (B). Moreover, constraints T1 (B) may constrain sets worlds
B (t) individual time points regardless specific thread. According
Figure 3, define set type 1 beliefs

1,1
T1 (B) = B B :
B = Bi,0
(Ft )
1,1 pfr
B = (Bi,0
(rt (F, G)) > 0)

1,1
1,1
B = (Bi,0
(1 ) Bi,0
(2 ) )



(48)

potential set possible threads , beliefs specified set T1 (B)
satisfied every thread h . Note satisfiability beliefs dynamic rules
disjunctive belief formulae generally depends worlds multiple time points thus
satisfiability T1 (B) cannot ensured constraining sets worlds single time
points. However, analyzing strict prior beliefs facts potential interplay
dynamic rules derive constraints sets worlds B (t) specific time points
follows.
1,1
Strict prior beliefs facts B = Bi,0
(Ft ) restrict set admissible worlds B (t)
time enforcing F holds every world B (t). following, use TF1 (B)
denote strict prior beliefs facts F certain time points t. Moreover, use
1,1
B |= Ft shorthand Bi,0
(Ft ) B denote B enforces F time t.
interplay existing constraints sets possible worlds B (t) individual
time points t, strict beliefs dynamic rules yield additional constraints: belief
1,1 pfr
formula B = Bi,0
(rt (F, G)), > 0, additional constraints might derived, depending
type belief respective rules premise F : (T0 (B) TF1 (B)) |= Ft given,
89

fiMartiny & Moller

1,1
extract strict prior belief fact B 0 = Bi,0
(Gt+t ), restricts
set possible worlds time point + therefore added TF1 (B).
Since dynamic rules considered temporal implications (cf. Definition 3.10
Section 3), rules also applied backwards obtain additional constraints:
1,1 pfr
belief formula B = Bi,0
(rt (F, G)), > 0 given rules negated conclusion G
already enforced time point (i.e., (T0 (B) TF1 (B)) |= Gt ), rules premise
1,1
F cannot satisfied time t. Thus, add belief B 0 = Bi,0
(Ftt )
F
additional constraint T1 (B).
Extending set type 1 beliefs dynamic rules may lead chained ex1,1 pfr
tension: belief dynamic rule Bi,0
(rt (F, G)) corresponding belief
1,1
1,1
F
Bi,0 (Ft ) T1 (B), lead additional belief Bi,0
(Gt+t ) TF1 (B),
1,1 pfr
turn might trigger another dynamic rule Bi,0
(rt (G, G0 )). Analogously, additional
belief TF1 (B) could also trigger backward rule applications.
capture constraints emerge forward backward chaining strict
dynamic rules, define set TF1 (B) following fix-point set:6

TF1 (B) =

1,1
{Bi,0
(Ft ) B}
1,1
{Bi,0
(Gt+t ) :

1,1 pfr
> 0 Bi,0
(rt (F, G)) B

(T0 (B) T1 (B)) |= Ft }

1,1
{Bi,0
(Ftt ) :

1,1 pfr
> 0 Bi,0
(rt (F, G)) B

(T0 (B) T1 (B)) |= Gt }

(49)

determined constraints individual time points, reduce
1,1
set TF1 (B) contains one belief Bi,0
(Ft ) every time point t.
1,1
1,1
F
T1 (B) contains multiple beliefs Bi,0 (Ft ), Bi,0 (Gt ) regarding time point t,
1,1
replace joint belief Bi,0
(Ft0 ) F 0 = F G. Note substitution
uses Lemma 3.7 (p. 64) merge different belief expressions one expression
conjunctive belief object. still assume belief formulae conjunctions belief
operators separated atomic belief formulae.
Type 2 belief formulae set type 2 belief formulae consists beliefs B
neither type 0 type 1 beliefs. Thus define set
T2 (B) = (B \ T0 (B)) \ T1 (B)

(50)

6. representation, considered influence temporal rules set TF
1 (B).
1,1
1,1
principle, information disjunctive formulae B = Bi,0
(1 ) Bi,0
(n ) T1 (B) could yield
additional constraints sets B (t): TF
1 (B) enforces n1 disjuncts B false, remaining
disjunct must satisfied. belief objects respective disjuncts might dynamic rules again,
formal representation consideration would result rather intricate specification. Since
ensure potential thread satisfies beliefs T1 (B) anyways, omitting disjunctive formulae
construction TF
1 (B) impact satisfiability results. Yet actual implementation
described procedures could exploit consideration obtain additional pruning conditions special
cases.

90

fiPDT Logic

Example 4.5 (Trains continued). Continuing set belief formulae B Example 4.1 (p. 72) assuming conjunctive formulae B = B 0 B 00 treated
individual formulae B 0 B 00 , obtain following sets typed belief formulae:
1,1 pfr

T0 (B) = BA,0
r0 (punct(train) at(train, city), Obs{A} (punct(train)))
(B5 )
1,1

T1 (B) = BA,0
at(T1 , CA )1 ,

1,1
BA,0
on(A, T1 )1 ,

(B10 )
(B100 )


1,1
BA,0
r3pfr ( punct(T1 ) at(T1 , CA ), at(T2 , CC ) on(A, T2 )) ,

1,1 pfr
BA,0
(r5 (punct(T1 ) at(T1 , CA ), at(T2 , CC ) on(A, T2 )) ,

1,1
BA,0
r2pfr ( punct(T2 ) at(T2 , CC ), at(T2 , CB ) on(A, T2 ))

1,1
BA,0
r3pfr (punct(T2 ) at(T2 , CC ), at(T2 , CB ) on(A, T2 )) ,
1,1

TF1 (B) = BA,0
at(T1 , CA )1 ,

1,1
BA,0
on(A, T1 )1 ,

(B30 )
(B300 )
(B40 )
(B400 )
(B10 )
(B100 )

T2 (B) = B \ T0 (B) \ T1 (B)

.81,.81 pfr
= {BA,0
r0 (at(T1 , CA ), punct(T1 )) ,

.81,.81 pfr
BA,0
r0 (at(T2 , CC ), punct(T2 )) ,

.93,.93 pfr
BA,0
r2 (Obs{A} (punct(train)), Obs{AB} (punct(train))) }

(B20 )
(B200 )
(B6 )

taxonomy belief formulae provides means construct sets admissible worlds
B (t) every time point . Type 0 beliefs (i.e., beliefs highest impact)
constrain global set possible worlds B . Certain beliefs type 1materialized
set TF1 (B)can give additional constraints specific time points t,
subsets B (t) B need considered possible worlds time t. sets
T0 (B) T1 (B) together provide satisfiability conditions independent
specific probability assignments. Then, beliefs type 2 need considered
probabilistic constraints check whether B satisfied respect , i.e.,
satisfiability problem sat(B, ) previous section reduced sat(T2 (B), ),
unsatisfiability B yet shown constraints T0 (B) T1 (B).
Since prior constraints define necessary conditions potential thread, give
rise definition thread soundness respect given set belief formulae B:
Definition 4.4 (Thread soundness). Let B set belief formulae, let T0 (B)
T1 (B) set type 0 type 1 belief formulae set, respectively. Then,
thread h sound respect B (denoted snd(T h, B)) satisfies belief formulae
T0 (B) T1 (B):
snd(T h, B) B (T0 (B) T1 (B)) : h |= B
91

(51)

fiMartiny & Moller

Accordingly, use snd(T , B) denote threads h sound.
Note definition relies strict prior beliefs soundness property
therefore verified every thread individually, without consider threads
probability assignments. Thus, simplified version model checking procedure
Section 4.1 used verify soundness. intuition behind property
verify easily prior checking sat(B, ) therefore obtain reduced version
satisfiability problem:
Theorem 4.13 (Reduced satisfiability checking). Let B set belief formulae, let
T2 (B) set type 2 beliefs B according (50), let set sound
threads. Then, B satisfiable respect iff T2 (B) satisfiable respect :
sat(B, ) snd(T , B) sat(T2 (B), )

(52)

Proof. follows directly Definition 4.4: snd(T , B) defined satisfies
belief formulae sets T0 (B) T1 (B). Consequently, sets resemble tautologies
respect therefore impact satisfiability checking
properties. Thus, instead checking B satisfiability, suffices check set (B \
T0 (B)) \ T1 (B), exactly definition T2 (B).
4.4.2 Constraining Possible Worlds Individual Time Points
Using classification beliefs B three different types, continue
constructing sets possible worlds B (t) every time point . main goal
section identification obvious pruning conditions possible worlds specific
time points. Since process searching set possible threads
satisfies set belief formulae B, constraints sets B (t) potential
significantly reduce later used search space. Thus, results section highlight
possible optimizations implementation PDT Logic sat solver. Even following constraints notor partiallyapplied, search possible threads
described subsequent Section 4.5 carried out, yet potentially larger search
space.
Since set type 0 beliefs satisfied every admissible world, define
global set admissible worlds B follows:
Definition 4.5 (Global set admissible worlds). Let B set belief formulae,
corresponding sets belief objects FB type 0 beliefs T0 (B). Then, set
admissible worlds B w.r.t. B given
n


1,1 pfr
B = B FB : adm() Bi,0
(r0 (F, G)) T0 (B) : |= (F G) .
(53)
Remark 4.4. definition uses adm() ensure worlds B admissible
defined external Definition 3.5 (p. 48). Alternatively, could use existing
formalism encode admissibility conditions directly strict prior beliefs B:
1,1 pfr
1,1 pfr
Bi,0
(r0 (ObsG (l), l)) G 0 G : Bi,0
(r0 (ObsG (l), ObsG 0 (l))) represent conditions 1
2 Definition 3.5, respectively. However, since conditions independent
respective problem modeled, include problem-specific belief
set B, use external constraints.
92

fiPDT Logic

Example 4.6 (Trains continued). global set worlds B admissible respect
B Example 4.1 (p. 72) automatically constructed combinations
events FB shown Example 4.2 (p. 73), given combinations admissible
respect Definition 3.5 satisfy type 0 beliefs T0 (B) Example 4.4
(p. 81). refrain enumerating worlds explicitly instead describe
worlds excluded Herbrand base B FB FB : FB follows
possible shared observation B fact train punctual
(Obs{AB} (punct(train))). every possible world observation occurs, admissibility conditions require agents B observe respective train
punctual train indeed punctual. Furthermore, beliefs T0 (B)
require corresponding observation every possible world
train punctual (which incidentally also enforces admissibility conditions
observations).
Next, build upon set globally admissible worlds B use set
type 1 beliefs prune set admissible worlds B (t) individual time points
t:
Definition 4.6 (Local sets admissible worlds). Let B set belief formulae
corresponding sets admissible worlds B , TF1 (B) set materialized strict
prior beliefs induced T0 (B) T1 (B), set time points. Then, set
admissible worlds B (t) w.r.t. B time given
n


1,1
F
B (t) = B : Bi,0 (Ft ) T1 (B) : |= F
.
(54)
Example 4.7 (Trains continued). obtain scenario original Example 3.2,
assume tmax = 9. set TF1 (B) identified Example 4.5, restrict set
worlds time 1
n

B (1) = B : |= (at(T1 , CA ) on(A, T1 ))
time points, options restrictions, thus respective
local sets B (t) possible worlds time points 6= 1 remain B .
Using Definition 4.6, formulate constraints set sound threads :
h , : h(t) B (t).

(55)

Note constraint provides necessary sufficient condition thread
soundness. illustrate this, consider Example 4.5 again: set TF1 (B) requires
{at(T1 , CA ), on(A, T1 )} holds every possible world time = 1 thus constrain B (1) shown Example 4.7, thread violating constraint
inherently unsound. hand, thread according (55) may contain
fact, say punct(T1 ) h(1), whichaccording B30 yields sound thread
{at(T2 , CC ), on(A, T2 )} h(4) holds well. Thus, (55) provides general constraints
set threads respect beliefs T0 (B) TF1 (B), additional beliefs
T1 (B) discard individual threads catching potential unsatisfiable interplay
possible worlds different time points.
93

fiMartiny & Moller

course, general possible methods discussed far result special
cases: one thing, possible B induces set T0 (B) TF1 (B) inconsistent
beliefs, i.e., contain beliefs contradict other. Then, B B (t)
empty. precludes creation set threads I(T ) |= B.
case, satisfiability checking terminate immediately negative result.
another, possible simplification process result empty set
T2 (B). case, probabilistic constraints could impact satisfiability
B thus unnecessary search suitable probability assignment. case,
needs checked whether threads compliance (55) sound according
Definition 4.4. thread found, satisfiability checking terminate
immediately positive result, otherwise B unsatisfiable. Verifying soundness
single thread done simplified version model checking procedure
Section 4.1 therefore PTIME (cf. Corollary 4.3). However, number threads
satisfying condition (55) grow exponentially number ground atoms
number time points, problem finding sound thread complex:
Theorem 4.14 (Complexity finding sound thread). Let B set belief formulae
included formulae grounded. Deciding whether exists sound thread
respect B, defined Definition 4.4, NP-complete.
Proof. According Definition 4.4, set sound satisfies formulae set
T0 (B) T1 (B). treating belief objects atoms F time points individual
variables Ft , transform beliefs facts belief rules T0 (B) T1 (B)
boolean sat problem follows:7
1,1
Bi,0
(Ft )

Ft

1,1 pfr
Bi,0
(rt (F, G))

tmax
^t
t=0

(Ft Gt+t )

Accordingly, disjunctive belief formulae expressed transforming every
disjunct individually. transformation requires tmax conjuncts every belief
operator therefore performed linear time. Since boolean sat problem
known NP-complete (Cook, 1971), follows searching sound thread
respect B NP.
NP-hardness problem already shown proof Theorem 4.11
(p. 84) consequently follows searching sound thread respect B
NP-complete.
noted result analyzes worst-case complexity problem,
practice finding sound thread usually dominated worst case.
cases, sound thread found easily employing principle least effort:
1,1 pfr
belief temporal rules Bi,0
(rt (F, G)), choosing worlds |= F ensures
consequences rule evaluated time points. Accordingly,
7. transformation defined temporal rules point frequency functions pfr.
frequency functions used, transformation adapted accordingly.

94

fiPDT Logic

disjunctive rules disjunct selected temporal rule triggered
fact. course, heuristic may give sound thread immediately
every input B, represents feasible approach problems. illustrate
approach example subsequently.
work, consider ground formulae PDT Logic. general, formalism
introduced Section 3 allows treatment non-ground formulae well. However,
non-ground formulae complexity result Theorem 4.14 hold,
transformation boolean sat problem exponential number possible
groundings. Finding sound thread requires use sophisticated grounding procedures, (e.g., Dal Palu, Dovier, Pontelli, & Rossi, 2009 Faber, Leone, & Perri, 2012),
beyond scope work.
sets possible worlds identified every time point , proceed
creating sets representative threads respect constraints. aim
following discussion successive generation set representative threads
sat(B, ) decided.
4.5 Representative Threads
Using Definition 4.4 constraint (55) gives rise potential definition set
possible threads constructing possible combinations sound world sequences
B (t) . However, would still result unnecessarily large set possible
threads. Instead constructing threads explicitly, heuristically create
representative threads represent excerpts situations modeled T2 (B).
approach uses heuristics successively expand set representative threads. soon
suitable set threads (i.e., model B) found, decision procedure terminate
positive result. set representative threads show satisfiability
B, additional threads created either positive satisfiability result obtained
possible threads created. Consequently, heuristic search models
constitutes complete decision procedure PDT Logic.
following discussion, assume set T2 (B) nonempty, i.e.,
additional constraints need satisfied generated set threads. Otherwise,
set T2 (B) empty, satisfiability could already determined checking whether
sound thread respect B exists, discussed previous section
would need generate specific set threads.
`,u
`0 ,u0
beliefs facts Bi,t
0 (Ft ) B, dual belief negated fact Bi,t0 (Ft )
`0 = 1 u u0 = 1 ` (cf. Corollary 3.4, p. 59) satisfied well.
`,u fr
beliefs rules Bi,t
0 (rt (F, G)), satisfiability depends accumulated subjective posterior interpretations threads weighted respective frequencies. goal
`,u
following procedure successively create threads every belief fact Bi,t
0 (Ft )
T2 (B), obtain representatives set threads (i) satisfy
respective fact Ft set threads satisfy Ft , (ii) exhibit varying fre`,u fr
quencies beliefs temporal rules Bi,t
0 (rt (F, G)) T2 (B). Consequently, belief
formulae considered splitting rules application generate representative threads results procedure similar tableau-based methods. However, beliefs
temporal rules induce splits forward backward time thusunlike con95

fiMartiny & Moller

ventional tableau-based methodsthe following procedure create tree structure,
instead set sequences represent possible threads. key difference
generation representative threads logical sat solvers PDT Logic
virtually impossible discard generated potential thread: probabilistic nature semantics requires threads considered given formula
holds, also threads not. Thus, even threads violating objects given
belief formulae usually required show satisfiability corresponding set belief
formulae B. following discussion provides general outline decision procedure
PDT Logic set belief formulae B given. actual implementation
methods possible, obtain feasible run times practical problems, various
optimization techniques research logic reasoning implementations would need
implemented, beyond scope work.
4.5.1 Generating Representative Threads
`,u
Since existence non-strict belief fact Bi,t
0 (Ft ) requires existence
least two threadsone, respective belief object satisfied one,
not8 start creating two threads hB (1), ..., B (tmax )i obtain
set = hT h1 , h2 h1 |= h2 |= belief objects = Ft contained
set T2 (B) obtain minimal set set threads belief formulae
B T2 (B) potentially satisfied. set subsequently expanded
additional threads either suitable set threads show satisfiability T2 (B)
found, additional threads created.
allow concise notation, following adapt frequency notation
belief objects use (1 ) denote true, (0 ) denote false,
generally (x ) denote holds frequency x. course, values 0 < x < 1
occur belief objects represent temporal rules. notation, try
create initial sound threads
^
h1 |= (1 j ),
(56)
j

h2 |=

^
j

(0 j )

(57)

holds respective belief objects j belief formulae Bj T2 (B).9
initial set = {T h1 , h2 } meant represent two extreme choices possible
threads respect T2 (B) provide suitable starting point subsequently
employed search heuristic. general, necessarily possible create extreme
threads compliance (56) (57) every possible set belief formulae T2 (B).
`,u
`,u
instance, T2 (B) might contain conflicting beliefs facts Bi,t
0 (Ft ) Bi,t0 (Ft ). Obviously,
single thread satisfy belief objects simultaneously, might still possible
`,u
8. Technically, non-strict belief Bi,t
0 () could satisfied single thread h h |=
beliefs quantification upper bound u = 1. might give rise optimizations
actual implementation, sake simplicity, consider case explicitly.
`,u
`,u
0
00
9. notation slightly simplified: disjunctive belief formulae Bj = Bi,t
0 (j ) Bi,t0 (j ), use j
0
00
abbreviation j j .

96

fiPDT Logic

create set threads thattogether suitable probability assignmentboth
beliefs satisfied. Thus, (56) (57) characterize intended goal creating
initial threads h1 , h2 , represent hard constraints threads.
find suitable threads match constraints, employ principle least
`,u
effort adding facts possible thread: every belief fact Bi,t
0 (Ft ),
add explicit constraints F h1 (t) F 6 h2 (t), h1 represents
thread belief objects true h2 represents set belief objects
`,u fr
false. beliefs rules Bi,t
0 (rt (F, G)) add G h1 (t + t) (resp. F h1 (t t))
whenever another constraint enforces F h1 (t) (resp. G h2 (t)). occurrence
fr (F, G) trivially satisfied frequency
F respectively G enforced h1 , rule rt
1 (i.e., occurrences F followed G steps)
constraints need added. Analogously, h2 need ensure F holds
least whenever F h2 (t) holds, G h2 (t + t) holds, well.
`,u
`,u
disjunctive belief formulae Bi,t
0 (1 ) Bi,t0 (2 ), need ensure belief object 1
2 holds thread h1 , described above, 1 2 holds thread h2 .
possible, respective belief object 1 2 thread h1 chosen
additional beliefs triggered (we say belief triggered fact F , existence
F enforces another constraint belief temporal rule disjunctive belief
formula). Nested belief formulae treated respect innermost belief
object. constraint cannot applied conflict previously added
constraints T2 (B), simply skipped stage. creation h1 h2
initialization step heuristic search possible set threads, skipped constraints
still considered later subsequent expansions.
Whenever constraint regarding fact F added h1 h2 , necessary
check whether triggers additional rules set type 1 beliefs T1 (B). necessary,
resulting facts added respective threads. application works analogously
construction set TF1 (B) described Section 4.4.1. Finally, belief
formulae processed, search sound thread respect created
constraints. Usually, sound thread found easily choosing facts
yet unconstrained h1 h2 trigger additional beliefs.
Especially, possible worlds h(t) unconstrained, choose h(t) = B
contain belief rules purely negative preconditions disjunctive belief
formulae satisfiable . generally, principle least effort
employed worlds selected belief formulae need
considered. selection impossible addition F F
world triggers additional beliefs. Then, consequences adding respective fact
need evaluated, well. resulting set = {T h1 , h2 } provides minimal
set representative threads used check sat(T2 (B), ).
following, show principle least effort used obtain representative threads efficiently possible. constraints used following example
provide minimal number constraints need enforced obtain representative threads desired threads h1 h2 . worlds without specific
constraints, simply use = . One easily verify indeed yields threads
compliance (56) (57).

97

fiMartiny & Moller

Example 4.8 (Trains continued). continue train example sets typed
belief formulae specified Example 4.5 (p.91). Example 4.7 (p. 93), shown
set worlds time 1 B (1) restricted {at(T1 , CA ), on(A, T1 )}
every world B (1). set T2 (B) contains three non-strict belief formulae, namely

.81,.81 pfr
T2 (B) = {BA,0
r0 (at(T1 , CA ), punct(T1 )) ,
(B20 )

.81,.81 pfr
BA,0
r0 (at(T2 , CC ), punct(T2 )) ,
(B200 )

.93,.93 pfr
BA,0
r2 (Obs{A} (punct(train)), Obs{AB} (punct(train))) }
(B6 )
evaluating belief formulae, obtain constraints possible worlds
threads h1 h2 . visualization following steps given Figure 4.
Analysis belief formula B20 results constraints punct(T1 ) h1 (1)
punct(T1 ) 6 h2 (1). facts turn trigger rules B30 B300 , respectively:

1,1
BA,0
r3pfr ( punct(T1 ) at(T1 , CA ), at(T2 , CC ) on(A, T2 ))

1,1 pfr
BA,0
(r5 (punct(T1 ) at(T1 , CA ), at(T2 , CC ) on(A, T2 )) ,

(B30 )
(B300 )

resulting additional constraints {at(T2 , CC ), on(A, T2 )} h1 (4) {at(T2 , CC ),
on(A, T2 )} h2 (6).
Application belief formula B200 yields additional facts punct(T2 ) h1 (4)
punct(T2 ) 6 h2 (6). Again, triggers rules T1 (B):

1,1
(B40 )
r2pfr ( punct(T2 ) at(T2 , CC ), at(T2 , CB ) on(A, T2 ))
BA,0

1,1 pfr
(B400 )
(r3 (punct(T2 ) at(T2 , CC ), at(T2 , CB ) on(A, T2 )) ,
BA,0
resulting additional constraints h1 (6) = at(T2 , CB ), on(A, T2 ) h2 (9) =
at(T2 , CB ), on(A, T2 ).
Note belief formula

1,1
BA,0
r0pfr (punct(train) at(train, city), Obs{A} (punct(train)))
(B5 )
T0 (B) provides global constraint set possible worlds B
Obs{A} (punct(train)) holds every world punct(train) holds, thus obtain
thread h2 additional facts Obs{A} (punct(T1 )) h2 (1) Obs{A} (punct(T1 ))
h2 (6).
Finally, rule

.93,.93 pfr
BA,0
r2 (Obs{A} (punct(train)), Obs{AB} (punct(train)))
(B6 )

98

fiPDT Logic

00
h2 B2
B5
0
h1 B2

at(T1 , CA ), on(A, T1 )
punct(T1 )
Obs{A} (punct(T1 ))
at(T1 , CA ), on(A, T1 )
punct(T1 )

B300

B200
B5

B30

B200

at(T2 , CC ), on(A, T2 )
punct(T2 )



1

B40


4

at(T2 , CC ), on(A, T2 )
punct(T2 )
Obs{A} (punct(T2 ))
at(T2 , CB ), on(A, T2 )

6

B400



at(T2 , CB ), on(A, T2 )

9



1

Figure 4: Visualization representative thread set generation train example.
threads start given facts at(T1 , CA ), on(A, T1 ). Applications
formulae T2 (B)such h1 contains positive belief objects h2
contains negative belief objectsare marked blue, additional constraints
T0 (B) T1 (B) marked red.

change created threads h1 , h2 : h1 rules precondition never
enforced satisfied thus resulting frequency one, lack
observation h2 even though nonpunctual trainsensures resulting
frequency zero.
trying solve resulting problem sat(T2 (B), {T h1 , h2 }), non-strict belief
formulae yield following constraints h1 :
B20 :
B200

:

B6 :

0.81 I(T h1 ) 0.81

0.81 I(T h1 ) 0.81

0.93 I(T h1 ) 0.93

Clearly, constraints cannot satisfied simultaneously therefore set =
{T h1 , h2 } insufficient show satisfiability T2 (B) (and therefore B).
created set threads fails show satisfiability T2 (B), additional threads
created continue searching expanded set T2 (B) satisfied
respect . Based existing thread h, additional thread h0 created
ensuring one conjunct h1 h2 (56) (57) satisfied anymore,
i.e., given thread h existing constraints (xk k ), new thread h0
obtained substitution
^
^
h |= (xj j ) h0 |=
(xj j ) x0k k , x0k 6= xk .
(58)
j

j6=k

Every substitution one conjunct new constraint provides choice point
direct continuation search suitable set threads. constraint notation
58 used provide formal characterization choice points. practice, new thread
h0 satisfying constraint usually created easily addition new
modification existing facts h follows. simplify following discussion,
assume expansion keeps history expansion steps resulting consequences,
effects adding additional F undone respective fact F
changed newly created thread.
99

fiMartiny & Moller

Definition 4.7 (Principle least effort (ple) expansion). Let set threads let
T2 (B) set type 2 belief formulae. principle least effort expansion creates
expanded set 0 = {T h0 } according single application one following rules.
`,u
(possibly negated) belief fact Bi,t
0 (Ft ) T2 (B): exists thread

h F h(t) (resp. F 6 h(t)) yet enforced, h0 created
duplication h additional constraint F h(t) (resp. F
6 h(t)).

`,u fr
belief temporal rule Bi,t
0 (rt (F, G)) T2 (B): exists thread

h F h(t) G h(t + t) (resp. G
6 h(t + t))
0
yet enforced, h created duplication h additional constraint
G h(t + t) (resp. G 6 h(t + t)).

`,u
`,u
disjunctive belief formula B = (Bi,t
0 (1 ) Bi,t0 (2 ) ) T2 (B): possible,
`,u
expansion carried respect one belief Bi,t
0 () described two
previous steps.

Nested beliefs treated respect innermost belief object.
new thread h0 created h addition F h0
fact F time point F 6 h enforced original thread h,
consequences adding F 6 h undone new thread h0 .

Then, created thread h0 , additional belief formulae T1 (B)
triggered modification need evaluated obtain sound thread,
described creation initial threads h1 , h2 .

intuition behind ple-expansion create additional threads satisfy
alternative set belief objects contained set T2 (B) little effort possible.
general, possible add constraints arbitrary facts arbitrary time points
continue successive expansion based thread. However, would result
rather aimless exploration exponential search space. Following ple-expansion
instead helps direct search suitable model guided rules specified
T2 (B). illustrate this, consider Figure 4 previous example: Possible pleexpansions could example result additional thread altering punctuality
train T2 . Clearly, resulting situations intended model, already
considered original thread specification (cf. Figure 1, p. 50). hand,
deviating ple-expansion, one could add additional factssay at(T1 , CA ), on(A, T1 )
arbitrary time points > 1. could give rise multiple subsequent expansions
resulting thread may actually serve generate model B,
situation intended specification B. example train punctuality
also illustrates requirement undo operation: fact punct(T2 ) h1 (4) produced
additional constraint {at(T2 , CB ), on(A, T2 )} time = 6. Clearly, constraint
enforced longer ifbased h1 new thread h0 created
punct(T2 ) 6 h0 (4).
information violated constrains linear program corresponding
sat(T2 (B), {T h1 , h2 }), perform dependency-directed selection choice points:
100

fiPDT Logic

`,u
lower bound belief Bi,t
0 (k ) cannot satisfied current set threads,
0
additional thread h created existing constraints h1 h2
substituting respective constraint k , shown (58).
dependency choice points violated lower bounds best illustrated
results previous example: Clearly, upper bounds induced B20 B200
lower bound induced B6 hinder satisfiability T2 (B) respect created
threads. Using belief object formula B20 (or B200 ) create additional thread h3
yields updated constraint

B20 :

0.81 I(T h1 ) + x I(T h3 ) 0.81

factor x depending frequency respective belief object h3 ,
constraint induced B6 remains unchanged. result, new constraint allows
lower values I(T h1 ), thus lower bound induced B6 remains unsatisfiable.
Using belief object formula B6 create additional thread instead yields
constraint
B6 :

0.93 I(T h1 ) + x I(T h3 ) 0.93,

whichthrough nonzero values x I(T h3 )potentially allows lower values
I(T h1 ). Note example uses atomic belief formulae. disjunctive belief
`,u
`,u
formulae B = (Bi,t
0 (1 )Bi,t0 (2 ) ), respective belief objects violated
lower bound used direct selection subsequent choice points (given
disjunct B satisfiable, course).
Combining information violated lower bounds principle least effort
provides multi-stage heuristic proceed dependency-directed selection choice
points:
Definition 4.8 (Dependency-directed search heuristic). Let T2 (B) set type 2 belief
formulae let set threads sat(T2 (B), ) holds. Then, enable
dependency-directed search expanded set 0 sat(T2 (B), 0 ) holds,
expanded additional thread h0 6 according following rules.
1. existing set threads fails satisfy lower bounds constraints induced
belief formula B belief object additional thread h0 obtained
one ple-expansion respect , expanded 0 = {T h0 }.
2. Otherwise, dependency-directed ple-expansion possible, another ple-expansion
applied , possible.
3. Finally, ple-expansion possible , additional thread h0 created
adding constraint F h(t) (resp. F 6 h(t)) arbitrary facts F
yet constrained h(t).
intuition behind heuristic information violated probabilistic constraints used select suitable next expansion step, possible. Otherwise,
possible ple-expansion steps performed use rules T2 (B) guide
101

fiMartiny & Moller

search. ple-expansions possible, additional constraints employed continue search. Restricting possible expansions respect criterion 1
one step follows principle least effort, again: illustrate this, consider Example 4.8:
shown created set threads {T h1 , h2 } fails satisfy lower bound
belief formula B6 . thread h1 , world h1 (t) |= Obs{A} (punct(train))
precondition rule B6 satisfied. Consequently, single step
ple-expansion h1 could change constraints induced B6 . hand,
h2 provides two choice points therefore preferred expansion. Note
soundness requirement determine choices unconstrained facts. Thus,
general proposed expansion may produce threads already contained
constraining facts determined before. consider scenario
explicitly instead assume cases, expansion steps performed
additional thread created.
4.5.2 Thread Generation Example
illustrate expansion set threads respect dependency-directed
search heuristic Definition 4.8, following resume train example.
Example 4.9 (Trains continued). previous example, set threads = {T h1 , h2 }
created fails show satisfiability T2 (B). Consequently, heuristic
Definition 4.8 used iteratively expand set expanded set threads
0 created model B obtained expansions 0 possible.
Belief formula

.93,.93 pfr
r2 (Obs{A} (punct(train)), Obs{AB} (punct(train)))
B6 = BA,0
already identified belief formula yields constrains unsatisfiable
lower bound therefore used guide subsequent expansion.
already discussed before, single-step ple-expansion h1 possible influence
constraints induced B6 . Therefore continue expansion based thread h2 .
visualization following steps given Figure 5.
two worlds h2 Obs{A} (punct(train)) satisfied, namely
Obs{A} (punct(T1 )) h2 (1) Obs{A} (punct(T2 )) h2 (6). occurrences allow ple-expansion. choose h2 (1) perform expansion. yields
new thread h3 additional constraint Obs{A,B} (punct(T1 )) h3 (3),
constraints h2 remain intact, since constraints need undone
adding Obs{A,B} h3 (3).
expanded set 0 = {T h3 } used check sat(T2 (B), 0 ). thread
h3 , rule contained B6 satisfied one two occurrences Obs{A} (punct(train))
therefore yields frequency 0.5. Consequently, transformation linear
program obtain constraints
B20 :
B200

:

B6 :

0.81

I(T h1 )

0.81

0.93

I(T h1 ) + 0.5 I(T h3 )

0.93

0.81

I(T h1 )

102

0.81

fiPDT Logic

h4

h3

00
h2 B2
B5
0
h1 B2

at(T1 , CA ), on(A, T1 )
punct(T1 )
Obs{A} (punct(T1 ))
at(T1 , CA ), on(A, T1 )
punct(T1 )
Obs{A} (punct(T1 ))
at(T1 , CA ), on(A, T1 )
punct(T1 )
Obs{A} (punct(T1 ))
at(T1 , CA ), on(A, T1 )
punct(T1 )
1

Obs{A,B} (punct(T1 ))

Obs{A,B} (punct(T1 ))
B6
B300

B200
B5

B30



at(T2 , CC ), on(A, T2 )
punct(T2 )

B200
3

B40

4
1

Obs{A,B} (punct(T2 ))

at(T2 , CC ), on(A, T2 )
punct(T2 )
Obs{A} (punct(T2 ))
at(T2 , CC ), on(A, T2 )
punct(T2 )
Obs{A} (punct(T2 ))
at(T2 , CC ), on(A, T2 )
punct(T2 )
Obs{A} (punct(T2 ))
at(T2 , CB ), on(A, T2 )



6

B6

at(T2 , CB ), on(A, T2 )

B400



8

9



Figure 5: Visualization ple-expansions train example. Applications formulae
T2 (B) marked blue, additional constraints T0 (B) T1 (B)
marked red. Expansion steps marked green.

Apparently, B6 allows lower values I(T h1 ) set 0 . constraints
induced B20 (resp. B200 ) still obtain I(T h1 ) = 0.81. Then, constraint induced
B6 requires I(T h3 ) = 0.24 (since 0.81 + 0.5 0.24 = 0.93). still suitable
probability assignment since sum priors exceeds one. Consequently, thread
set expansion continues. constraints show thataccording condition 1
search heuristicthread h3 suitable candidate expansion respect
belief object B6 .
Thus, based h3 , create additional thread h4 ple-expansion.
case, possible expansion step Obs{A,B} h4 (8), results frequency
one rule contained B6 . Thus, testing sat(Tk (B), 0 ) expanded
set 0 yields following constraints:
B20 :
B200

:

B6 :

0.81

I(T h1 )

0.81

0.93

I(T h1 ) + 0.5 I(T h3 ) + 1 I(T h4 )

0.93

0.81

I(T h1 )

0.81

constraints satisfiable, instance

I(T 0 ) = 0.81, 0.07, 0, 0.12 .
Thus, sat(T2 (B), 0 ) returns positive result satisfiability checking B terminate
result.
result concludes satisfiability testing set belief formulae B originally
specified Example 4.1 (p. 72). Nevertheless, illustration purposes show result
applications ple-expansion steps Figure 6. Changes additionally
created threads obtained respectively different application belief
formula T2 (B), marked blue respective threads. Worlds h(t) remain
unconstrained saturated application ple-expansions marked /.
worlds give rise expansions according step 3 search heuristic.
103

fi104

0
h1 B2

00
h2 B2
B5

h3

h4

h5

h6

h7

h8

h9

1

at(T1 , CA ), on(A, T1 )
punct(T1 )
Obs{A} (punct(T1 ))
at(T1 , CA ), on(A, T1 )
punct(T1 )
Obs{A} (punct(T1 ))
at(T1 , CA ), on(A, T1 )
punct(T1 )
Obs{A} (punct(T1 ))
at(T1 , CA ), on(A, T1 )
punct(T1 )
Obs{A} (punct(T1 ))
at(T1 , CA ), on(A, T1 )
punct(T1 )

at(T1 , CA ), on(A, T1 )
punct(T1 )

at(T1 , CA ), on(A, T1 )
punct(T1 )
Obs{A} (punct(T1 ))
at(T1 , CA ), on(A, T1 )
punct(T1 )
Obs{A} (punct(T1 ))
at(T1 , CA ), on(A, T1 )
punct(T1 )

B30

2

/

/

/

/

/

/

B200
B5

B6

3

/

/

B300

B200

Obs{A,B} (punct(T1 ))

Obs{A,B} (punct(T2 ))

/

/

/

/

Obs{A,B} (punct(T2 ))
B6

/

4

B200

00
/ B2
B5

/

1

5

at(T2 , CC ), on(A, T2 )
B40
punct(T2 )
/

/

/

/

/

at(T2 , CC ), on(A, T2 )
punct(T2 )
/
Obs{A} (punct(T2 ))
at(T2 , CC ), on(A, T2 )
punct(T2 )
/
Obs{A} (punct(T2 ))

/

/

/

6

at(T2 , CC ), on(A, T2 )
punct(T2 )
Obs{A} (punct(T2 ))
at(T2 , CC ), on(A, T2 )
punct(T2 )
Obs{A} (punct(T2 ))
at(T2 , CC ), on(A, T2 )
punct(T2 )
Obs{A} (punct(T2 ))
at(T2 , CC ), on(A, T2 )
punct(T2 )
Obs{A} (punct(T2 ))
at(T2 , CB ), on(A, T2 )

B400

B6

Obs{A,B} (punct(T2 ))

at(T2 , CC ), on(A, T2 )
punct(T2 )

at(T2 , CC ), on(A, T2 )
punct(T2 )

/

7

/

/

/

/

/

B400

8

/

/

/

Obs{A,B} (punct(T2 ))
B6

9

/


at(T2 , CB ), on(A, T2 )

at(T2 , CB ), on(A, T2 )

at(T2 , CB ), on(A, T2 )

at(T2 , CB ), on(A, T2 )

Obs{A,B} (punct(T2 ))
B6

/

/

/

/

/

at(T2 , CB ), on(A, T2 )

/

at(T2 , CB ), on(A, T2 )

at(T2 , CB ), on(A, T2 )

at(T2 , CB ), on(A, T2 )

B40

/

Martiny & Moller

Figure 6: Visualization continued ple-expansions train example. Applications
formulae T2 (B) marked blue, additional constraints T0 (B)
T1 (B) marked red. Expansion steps originating h1 h2
marked green orange, respectively. Unconstrained worlds marked
/.

fiPDT Logic

comments resulting set threads example necessary. Comparing final threads depicted Figure 6 original set threads introduced
Figure 1 shows expansion result largely corresponds original specification
(except differing thread labels). notable differences however.
First all, additional predicate punct(train), introduced
Example 4.1 (p. 72) allow concise specification background knowledge.
concept nonpunctual trains (and especially respective ramifications)
implicitly encoded Figure 1 well, change properties
modeled example.
explicit representation train punctuality, observations nonpunctual
trains expressed explicitly example, previous example uses
ramifications nonpunctual trains model observations. Since rules B3
B4 assert ramifications punctual respectively nonpunctual trains common
knowledge among Alice Bob, modeling alternatives preserve intended
meaning example.
Another difference timing Alices observations. original example
assumed observation occurs time point train supposed
arrive destination city. current example assume Alice already
observes train punctual leaving departure city. reason
change solely illustration purposes: specifying rule B5 Alice
immediately observes nonpunctual train yields type 0 belief thus serves
illustrate additional facts obtained global constraints. Since rule
B6 ensures potential calls Bob (i.e., shared observations) occur two time points
Alices original observation, intended model original example still
maintained.
points concerned specific details modeled domain.
Comparing set threads Figure 1 threads Figure 6 also shows
general modeling problem: instance, analyzing worlds time point 2
Figure 6 shows Alice (necessarily) train T1 , train
previous time point later time points. Naturally, one expect
Alice train intermediate time points boarding exiting
train. instance frame problem (e.g., Reiter, 2001) occurs
specifying dynamic systems logic formulae. Generally, frame problem
concerned finding suitable set axioms describe adequate evolutions
world. modeling perspective, evolutions Alice vanishes reappears
train ride obviously adequate evolutions world. application
final step search heuristic could yield tremendous blow-up
considered set threads. modeled problem, would clearly result
unintended models, resulting models could still serve show satisfiability
respective set belief formulae B, even though result might desired.
problem could fixed adding successor state axioms style Reiter,
e.g., specifying Alice train, remains next time point
unless explicitly exits train.
105

fiMartiny & Moller

4.5.3 Properties Representative Thread Generation
section, provide results connect set representative threads satisfiability problem PDT Logic discuss complexity generating representative
threads.
Theorem 4.15 (PDT Logic Decision Procedure). Let B set PDT Logic belief
formulae, let = {T h1 , h2 } initial set threads length tmax obtained
B according Equations (56) (57). Iteratively expanding set according
search heuristic Definition 4.8 testing sat(T2 (B), 0 ) expanded sets 0
(i) sat(T2 (B), 0 ) returns positive result, (ii) 0 fully expanded respect
search heuristic yields sound complete decision procedure sat(B, tmax ).
Proof. initial set threads = {T h1 , h2 } expanded sets 0 obtained ple-expansion steps defined sound threads according
Definition 4.4 considered. Theorem 4.13 (p. 92) states decision problem
sat(T2 (B), ) equivalent sat(B, ) set contains threads sound
respect B. positive result sat(B, ) threads length tmax shows
model B thus sat(B, tmax ) follows. Consequently, positive result
sat(T2 (B), 0 ) always proofs B satisfiable tmax time points.
hand, model B found possible create
additional threads according search heuristic Definition 4.8 (p. 101), search
space fully explored. follows model B tmax time points
exists therefore B unsatisfiable tmax time points. Consequently, follows
PDT Logic decision procedure sound.
properties, completeness result straightforward: arbitrary
input B tmax , either model found non-existence model
proven full exploration search space, thus completeness procedure
follows.
following, analyze complexity generating representative threads
set belief formulae B.
Theorem 4.16 (Complexity representative thread generation). Let B set belief
formulae. Creating set expanded representative threads 0 B EXPSPACE.
Proof. maximum number possible threads given set belief formulae B
determined size |FB | maximum time point tmax . Recall Equation (29) (p. 71) use FB identify event formulae B use set
ground atoms construct possible worlds. Since every PDT Logic formula contains
two event formulae, obtain constraint |FB | 2 |B|. largest set possible
threads obtained sequences combinations possible worlds
time points, yielding 22tmax |B| possible threads. worst case, |FB | 2 |B| representative threads created obtaining satisfiability result. Consequently, creating
possible representative threads complexity class DSPACE(2p(n) ),
class EXPSPACE.
theorem, immediately obtain complexity results satisfiability problem sat(B, tmax ).
106

fiPDT Logic

Corollary 4.17 (Complexity PDT SAT without given set threads). Checking satisfiability set PDT Logic belief formulae B without specification possible threads
EXPSPACE.
Proof. generation representative threads EXPSPACE, shown Theorem 4.16. given set threads Theorem 4.11 shows satisfiability checking
PDT Logic NP. Thus, increase complexity PDT sat problem without given set threads follows problem EXPSPACE.
comments results necessary. Since decision procedure outlined
Theorem 4.15 yields exponential expansion possible threads 0 need
fed decision problem sat(T2 (B), 0 )the exponential space requirement
evident. However, illustrated example, positive satisfiability results
possibly already obtained small sets possible threads 0 diminutive
size compared entire search space. Moreover, discussion train example
shown major part search space stems insufficient rule specifications.
specific problem formalism presented decision procedure, general
problem rule-based modeling approaches, namely aforementioned frame problem.
incomplete model specification leads generation unintended models,
serve show satisfiability modeled problem, intended
respective modeler. could lead worst caseboth complexity
model perspectivethat exponential execution decision procedure,
result shows input specification specify intended model.
problem addressed modeling side providing additional axioms ensure
unintended model generated. However, leads significant increase
specification size difficult ensure rule specifications indeed every
unintended model prevented.
ple-expansion steps could used heuristic discriminate intended
unintended models: shown train example, applying ple-expansion steps
results relatively small set threads, indeed corresponds intention
model, expansions inherently leads exponential growth
set threads introduces additional unintended models. Thus, omitting final
step search heuristic would give significantly faster termination decision
procedure, even though resulting procedure cannot prove unsatisfiable sets formulae
longer. However, one could use expansion procedure create set intended
threads first andpossibly inspection modelercontinue use set
perform satisfiability checks respect intended model.
runtime expansion procedure resulting satisfiability checks clearly
tilted towards positive side: set belief formulae satisfiable, good
chance satisfiability shown small number steps. Negative results
hand obtained exhaustive exploration search space.
However, many applications negative satisfiability results required. instance,
checking entailment B |= B checked reformulation sat(B B).
applications relying reformulation, presented procedure unfavorable
positive entailment results never obtained efficiently. One could overcome
problem sketched generating set intended threads first use
107

fiMartiny & Moller

set perform subsequent satisfiability testsonce set threads given, decision
problems complexity significantly decreases, shown Section 4.3.

5. Conclusion
work, extending APT Logic dynamic scenarios multiple agents,
developed general framework represent reason belief change multiagent systems. Next lifting single-agent case APT Logic multiple agents,
also provided suitable semantics temporal evolution beliefs. resulting
framework extends previous work dynamic multi-agent epistemic logics enabling
quantification agents beliefs probability intervals. explicit notion temporal relationships provided temporal rules building concept frequency
functions.
quantification beliefs probability intervals instead precise values
advantage domain experts model problem, provide
background knowledge problem domain, also specify certainty
respective specifications. Narrow interval quantifications reflect high certainty
vice versa. significant advantage compared probabilistic approaches,
approaches, sharp probability values required human
usually express precise values thus rely guesses. Specifying precise
values, actually precisely known yield misleading results. PDT Logic
exposed problem, required guess sharp values specify
problem.
shown two alternative ways specifying problems PDT Logic,
either explicit enumerations possible threads set appropriate
rules. approaches exhibit specific advantages drawbacks: many problem
domains, requiring exhaustive enumeration possible threads poses severe obstacle
modeling respective scenarios, combinatorial blow-up renders specification
practically unmanageable. hand, problem domains (e.g., attack
graphs cyber security scenarios) come explicit specification anyways.
types problems, shown possible check satisfiability
models efficiently.
overcome modeling disadvantages thread-based approach, also shown
problem domain solely specified set PDT Logic belief formulae.
problem domains, natural way specifying problem. Also,
provides means easily adapt many existing problemsthat specified formal
languages sets rulesto PDT Logic. hand, waiving requirement
exhaustive thread specification according probabilities extremely increases
problem complexity checking satisfiability set PDT Logic formulae. Nevertheless,
even imprecise probabilities given, resulting problem remains decidable
increased complexity might curtailed search heuristics.
Combinations approaches possible well: exhaustive specification
possible threads given, probability intervals specified beliefs
imprecise probabilities, satisfiability problem transformed 0-1 mixed
integer linear program. variety efficient solvers available class
108

fiPDT Logic

problems, transformation provides means exploit existing optimizations check
satisfiability PDT Logic formulae.

References
Aumann, R. J. (1976). Agreeing Disagree. Annals Statistics, 4 (6), 12361239.
Baaz, M., Egly, U., Leitsch, A., Goubault-Larrecq, J., & Plaisted, D. (2001). Normal Form
Transformations. Robinson, A., & Voronkov, A. (Eds.), Handbook Automated
Reasoning, chap. 5, pp. 273 333. MIT Press.
Balas, E. (1985). Disjunctive Programming Hierarchy Relaxations Discrete
Optimization Problems. SIAM Journal Algebraic Discrete Methods, 6 (3), 466
486.
Balas, E. (1998). Disjunctive Programming: Properties Convex Hull Feasible
Points. Discrete Applied Mathematics, 89 (1), 344.
Balas, E., Ceria, S., & Cornuejols, G. (1993). Lift-and-project Cutting Plane Algorithm
Mixed 0-1 Programs. Mathematical Programming, 58 (3), 295324.
Balas, E., Ceria, S., & Cornuejols, G. (1996). Mixed 0-1 Programming Lift-and-project
Branch-and-cut Framework. Management Science, 42 (9), 12291246.
Balas, E., & Perregaard, M. (2002). Lift-and-project Mixed 0-1 Programming: Recent
Progress. Discrete Applied Mathematics, 123 (1), 129154.
Baltag, A., & Moss, L. S. (2004). Logics Epistemic Programs. Synthese, 139 (2), 165224.
Baltag, A., Moss, L. S., & Solecki, S. (1998). Logic Public Announcements, Common
Knowledge, Private Suspicions. Proceedings Seventh Conference
Theoretical Aspects Rationality Knowledge, TARK 98, pp. 4356.
Bertacco, L., Fischetti, M., & Lodi, A. (2007). Feasibility Pump Heuristic general
Mixed-Integer Problems. Discrete Optimization, 4 (1), 6376.
Bienstock, D. (1996). Computational Study Family Mixed-Integer Quadratic Programming Problems. Mathematical Programming, 74 (2), 121140.
Bradley, S. (2015). Imprecise probabilities. Zalta, E. N. (Ed.), Stanford Encyclopedia
Philosophy (Summer 2015 edition).
Computational Infrastructure Operations Research (COIN-OR) Project, T. (2016).
CBC (Coin-or branch cut) user guide. http://www.coin-or.org/Cbc/index.html.
accessed: 2016-04-15.
Cook, S. A. (1971). Complexity Theorem-proving Procedures. Proceedings
Third Annual ACM Symposium Theory Computing, STOC 71.
Cripps, M. W., Ely, J. C., Mailath, G. J., & Samuelson, L. (2008). Common Learning.
Econometrica, 76 (4), 909933.
Dal Palu, A., Dovier, A., Pontelli, E., & Rossi, G. (2009). Gasp: Answer set programming
lazy grounding. Fundamenta Informaticae - Advances Computational Logic,
96 (3), 297322.
109

fiMartiny & Moller

de Carvalho Ferreira, N., Fisher, M., & van der Hoek, W. (2008). Specifying Reasoning
Uncertain Agents. International Journal Approximate Reasoning, 49 (1),
3551.
Doder, D., Markovic, Z., Ognjanovic, Z., Perovic, A., & Raskovic, M. (2010). Probabilistic Temporal Logic Model Reasoning Evidence. Foundations
Information Knowledge Systems: 6th International Symposium, FoIKS 2010.
Ellsberg, D. (1961). Risk, Ambiguity, Savage Axioms. Quarterly Journal
Economics, 75 (4), 643669.
Faber, W., Leone, N., & Perri, S. (2012). intelligent grounder DLV. Correct
Reasoning: Essays Logic-Based AI Honour Vladimir Lifschitz. Springer.
Fagin, R., & Halpern, J. Y. (1994). Reasoning Knowledge Probability. Journal
ACM, 41 (2), 340367.
Fagin, R., Halpern, J. Y., & Megiddo, N. (1990). Logic Reasoning Probabilities.
Information Computation, 87 (1), 78128.
Fagin, R., Halpern, J. Y., Moses, Y., & Vardi, M. Y. (1995). Reasoning Knowledge.
MIT Press.
Fischetti, M., Glover, F., & Lodi, A. (2005). Feasibility Pump. Mathematical Programming, 104 (1), 91104.
Garey, M. R., & Johnson, D. S. (1979). Computers Intractability; Guide Theory
NP-Completeness. W. H. Freeman & Co.
Gerbrandy, J., & Groeneveld, W. (1997). Reasoning Information Change. Journal
Logic, Language Information, 6 (2), 147169.
Gnu

Project, T. (2016).
GLPK: GNU Linear Programming
http://www.gnu.org/software/glpk/glpk.html. accessed: 2016-04-15.

Kit.

Grunwald, P. D., & Halpern, J. Y. (2003). Updating Probabilities. Journal Artificial
Intelligence Research, 19 (1), 243278.
Gurobi Optimization, Inc. (2016).
Gurobi optimizer reference
http://www.gurobi.com/documentation/. accessed: 2016-04-15.

manual.

Halpern, J. Y., & Pucella, R. (2006). Logic Reasoning Evidence. Journal
Artificial Intelligence Research, 26 (1), 134.
Halpern, J. Y., Samet, D., & Segev, E. (2009). Defining Knowledge Terms Belief:
Modal Logic Perspective. Review Symbolic Logic, 2 (3), 469487.
Harsanyi, J. C. (1967). Games Incomplete Information Played Bayesian Players.
Part I. Basic Model. Management Science, 14 (3), 159182.
Harsanyi, J. C. (1968a). Games Incomplete Information Played Bayesian Players.
Part II. Bayesian Equilibrium Points. Management Science, 14 (5), 320324.
Harsanyi, J. C. (1968b). Games Incomplete Information Played Bayesian Players.
Part III. Basic Probability Distribution Game. Management Science, 14 (7),
486502.
110

fiPDT Logic

Hintikka, J. (1962). Knowledge Belief: Introduction Logic Two Notions.
Cornell University Press.
ILOG,
I.
(2016).
CPLEX
Optimizer.
01.ibm.com/software/commerce/optimization/cplex-optimizer/.
04-15.

http://wwwaccessed: 2016-

Kooi, B. P. (2003). Probabilistic Dynamic Epistemic Logic. Journal Logic, Language
Information, 12 (4), 381408.
Kripke, S. A. (1963). Semantical Considerations Modal Logic. Acta Philosophica Fennica,
16, 8394.
Lloyd, J. W. (1987). Foundations Logic Programming, 2nd Edition. Springer.
Martiny, K., Motzek, A., & Moller, R. (2015). Formalizing Agents Beliefs Cyber-Security
Defense Strategy Planning. CISIS 2015 - Proceedings 8th International Conference Computational Intelligence Security Information Systems, Burgos,
Spain, 15-17 June, 2015.
Milch, B., & Koller, D. (2000). Probabilistic Models Agents Beliefs Decisions.
Proceedings Sixteenth Annual Conference Uncertainty Artificial Intelligence, UAI 00. Morgan Kaufmann Publishers Inc.
Murty, K. G. (1983). Linear Programming. John Wiley & Sons.
Parikh, R., & Ramanujam, R. (2003). Knowledge Based Semantics Messages. Journal
Logic, Language Information, 12 (4), 453467.
Plaza, J. (1989). Logics public communications. Proceedings Fourth International
Symposium Methodologies Intelligent Systems: Poster session program, ISMIS
89. Oak Ridge National Laboratory.
Plaza, J. (2007). Logics Public Communications. Synthese, 158 (2), 165179.
Reiter, R. (2001). Knowledge Action: Logical Foundations Specifying Implementing Dynamical Systems. MIT Press.
Sack, J. (2008). Temporal Languages Epistemic Programs. Journal Logic, Language
Information, 17 (2), 183216.
Sack, J. (2009). Extending Probabilistic Dynamic Epistemic Logic. Synthese, 169 (2), 241
257.
Schrijver, A. (1986). Theory Linear Integer Programming. John Wiley & Sons.
Shakarian, P., Parker, A., Simari, G., & Subrahmanian, V. S. (2011). Annotated Probabilistic Temporal Logic. ACM Transactions Computational Logic, 12 (2), 14:114:44.
Shakarian, P., Simari, G. I., & Subrahmanian, V. S. (2012). Annotated Probabilistic Temporal Logic: Approximate Fixpoint Implementation. ACM Transactions Computational Logic, 13 (2), 13:113:33.
Shoham, Y., & Leyton-Brown, K. (2009). Multiagent Systems: Algorithmic, GameTheoretic, Logical Foundations. Cambridge University Press.
van Benthem, J. (2003). Conditional Probability Meets Update Logic. Journal Logic,
Language Information, 12 (4), 409421.
111

fiMartiny & Moller

van Benthem, J., Gerbrandy, J., Hoshi, T., & Pacuit, E. (2009a). Merging Frameworks
Interaction. Journal Philosophical Logic, 38 (5), 491526.
van Benthem, J., Gerbrandy, J., & Kooi, B. (2009b). Dynamic Update Probabilities.
Studia Logica, 93 (1), 6796.
van der Hoek, W. (1997). Considerations Logic PFD: Logic combining
Modality Probability. Journal Applied Non-Classical Logics, 7 (3), 287307.
van Ditmarsch, H., van der Hoek, W., & Kooi, B. (2007). Dynamic Epistemic Logic.
Springer.
van Eijck, J. (2014). Dynamic epistemic logics. Johan van Benthem Logical
Informational Dynamics, chap. 7, pp. 175202. Springer.
van Eijck, J., & Schwarzentruber, F. (2014). Epistemic Probability Logic Simplified.
Gore, R., Kooi, B. P., & Kurucz, A. (Eds.), Advances Modal Logic 10, invited
contributed papers tenth conference Advances Modal Logic,, AiML
14. College Publications.
vos Savant, M. (1990). Ask Marilyn. Parade Magazine, 16.
Williams, H. P. (2009). Logic Integer Programming. Springer.

112

fi
