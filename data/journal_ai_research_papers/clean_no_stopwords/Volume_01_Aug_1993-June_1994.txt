Journal Artificial Intelligence Research 1 (1993) 91-107Submitted 8/93; published 11/93Diculties Learning Logic Programs CutFrancesco Bergadanobergadan@di.unito.itDaniele GunettiUmberto Trincherogunetti@di.unito.ittrincher@di.unito.itUniversita di Catania, Dipartimento di Matematica,via Andrea Doria 6, 95100 Catania, ItalyUniversita di Torino, Dipartimento di Informatica,corso Svizzera 185, 10149 Torino, ItalyAbstractreal logic programmers normally use cut (!), effective learning procedure logicprograms able deal it. cut predicate proceduralmeaning, clauses containing cut cannot learned using extensional evaluation method,done learning systems. hand, searching space possibleprograms (instead space independent clauses) unfeasible. alternative solutiongenerate first candidate base program covers positive examples,make consistent inserting cut appropriate. problem learning programscut investigated seems natural reasonableapproach. generalize scheme investigate diculties arise.major shortcomings actually caused, general, need intensional evaluation.conclusion, analysis paper suggests, precise technical grounds,learning cut dicult, current induction techniques probably restrictedpurely declarative logic languages.1. IntroductionMuch recent research AI Machine Learning addressing problem learningrelations examples, especially title Inductive Logic Programming (Muggleton, 1991). One goal line research, although certainly one,inductive synthesis logic programs. generally, interested constructionprogram development tools based Machine Learning techniques. techniquesinclude ecient algorithms induction logical descriptions recursive relations.However, real logic programs contain features purely logical, notablycut (!) predicate. problem learning programs cut studiedInductive Logic Programming, paper analyzes diculties involved.1.1 Learn Programs Cut?two main motivations learning logic programs cut:1. ILP provide practical tools developing logic programs, contextgeneral program development methodology (e.g., (Bergadano, 1993b)); realsize logic programs normally contain cut, learning cut important creatingintegrated Software Engineering framework.c 1993 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.fiBergadano, Gunetti, & Trinchero2. Extensive use cut make programs sensibly shorter, diculty learninggiven logic program much related length.objectives, need cuts make programsecient without changing input-output behavior (\green cuts"), also cutseliminate possible computed results (\red cuts"). Red cuts sometimes consideredbad programming style, often useful. Moreover, red cuts effectivemaking programs shorter. Green cuts also important, less controversial.correct program inferred via inductive methods, could made ecientinsertion green cuts, either manually means automated programtransformation techniques (Lau & Clement, 1993).1.2 Standard Approaches Cannot Used?Machine Learning algorithms generate rules clauses one time independentlyother: rule useful (it covers positive example) correct (itcover negative example), added description programgenerated, positive examples covered. means searchingspace possible clauses, without backtracking. obviously great advantage,programs sets clauses, therefore space possible programs exponentiallylarger.one principle allows simplification problem extensionalevaluation possible clauses, used determine whether clause C covers examplee. fact clause C covers example e used approximationfact logic program containing C derives e. Consider, instance, clause C =\p(X,Y) ff", suppose example e p(a,b). order see whether C covers e,extensionality principle makes us evaluate literal ff true matchesgiven positive example. instance, ff = q(X,Z) ^ p(Z,Y), example p(a,b)extensionally covered iff ground term c q(a,c) p(c,b) givenpositive examples. particular, order obtain truth value p(c,b),need call clauses learned previously. reason, determiningwhether C covers e depends C positive examples. Therefore, learningsystem decide whether accept C part final program P independentlyclauses P contain.extensionality principle found Foil (Quinlan, 1990) derivatives,also used bottom-up methods Golem (Muggleton & Feng, 1990). Shapiro's MISsystem (Shapiro, 1983) uses refining clauses, although backtracinginconsistencies. also used extensional evaluation clauses FILP system(Bergadano & Gunetti, 1993).learning programs cut, clauses longer independent standalone extensional evaluation meaningless. cut predicate evaluated, possible clauses proving goal ignored. changes meaningclauses. Even clause extensionally covers example e, may casefinal program derive e, derivation paths eliminatedevaluation cut predicate.92fiThe Difficulties Learning Logic Programs CutHowever, exhaustive search space programs prohibitive. Learning methods,even based extensionality, often considered inecient sucient prior informationavailable; searching sets clauses exponentially worse. would amountbrute-force enumeration possible logic programs containing cut, programconsistent given examples found.1.3 Alternative Method?Cut eliminate computed results, i.e., adding cut program,may case example longer derived. observation suggests generallearning strategy: base program P induced standard techniques, given positivemaybe negative examples, remaining negative examples ruledinserting cut clause P. Obviously, inserting cut, must make surepositive examples may still derived.Given present technology discussion above, seems viablepath possible solution. Using standard techniques, base program P would generated one clause time, positive examples extensionally covered. However,think view restrictive, programs derive given positiveexamples, although cover extensionally (Bergadano, 1993a; DeRaedt,Lavrac, & Dzeroski, 1993). generally, consider traces positive examples:Definition 1 Given hypothesis space possible clauses, example e`e, set clauses TS used derivation e called trace e.use candidate base program P subset uniontraces positive examples. PS extensionally covers positive examples,also union traces, converse always true. candidateprogram generated, attempt made insert cuts negative examplesderived. successful, solution, otherwise, backtrack anothercandidate base program. analyze many problems inherent learning cutclass trace-based learning methods, but, discuss later (Section 4),problems need faced restrictive framework extensional evaluation.words, even choose learn base program P extensionally,try make consistent using cut, computational problems would still arise.main difference standard approaches based extensionality allowbacktracking guarantee correct solution found (Bergadano, 1993a).far computational complexity concerned, trace-based methods complexitystanding search space independent clauses (for extensional methods)exhaustive search space possible programs. need following:Definition 2 Given hypothesis space S, depth example e maximumnumber clauses successfully used derivation e.example, list processing domain, contains recursive callstype \P([HjT]) :- ..., P(T), ..." depth example P(L) length L.practical program induction tasks, often case depth example93fiBergadano, Gunetti, & Trincherorelated complexity, hypothesis space S. maximum depthgiven positive examples, complexity trace-based methods orderjS jmd, extensional methods enumerate possible clauses complexitylinear jS j, enumerating possible programs exponential jS j.2. Simple Induction Proceduretrace-based induction procedure analyze takes input finite set clausesset positive negative examples E+ E- tries find subsetderives positive examples none negative examples. everypositive example e+ 2 E+, assume large enough derive it. Moreover,assume clauses attened1 . case, clauses attenedpreprocessing step.consider one possible proof ` e+, build intermediate programcontaining trace derivation. done positive examples,corresponding traces merged. Every time updated, checkednegative examples. derived T, cut (!) inserted antecedentsclauses T, consistent program found, exists. case,procedure backtracks different proof ` e+. algorithm informallydescribed follows:input: set clausesset positive examples E+set negative examples ES := atten(S);positive example e+ 2 E+find T1 T1 `SLD e+ (backtracking point 1)[ T1derives negative example e- trycut(T,e-)trycut(T,e-) fails backtrackoutput clauses listedtrycut(T,e-):insert ! somewhere (backtracking point 2)1. previously covered positive examples still derived T,2. 6`SLD e-complexity adding cut somewhere trace T, negative example eis longer derived, obviously depends size T. size dependsdepth positive examples, size hypothesis space S. Although1. clause flattened contain functional symbol. Given un attened clause, alwaypossible atten (by turning functions new predicates additional argument representingresult function) vice versa (Rouveirol, press).94fiThe Difficulties Learning Logic Programs Cutclever ways devised, based particular example e-, proposesimple enumerative technique implementation described Appendix.3. Example: Simplifying Listsection show example use induction procedure learn logicprogram \simplify ". Simplify takes input list whose members may lists,transforms \ attened" list single members, containing repetitionslists members. program appears exercise number 25 (Coelho & Cotta, 1988),composed nine clauses (plus clauses append member); sixrecursive, one doubly-recursive cut extensively used. Even simplifycomplex logic program, complex usual ILP test cases. instance,quicksort partition program, often used, composed fiveclauses (plus append), three recursive. Moreover, noteconciseness simplify essentially due extensive use cut. Without cut,program would much longer. general, longer logic program, dicultlearn it.consequence, start relatively strong bias; suppose followinghypothesis space N=8449 possible clauses defined user:clause \simplify(L,NL) :- atten(L,L1), remove(L1,NL)."clauses whose head \ atten(X,L)" whose body composed conjunctionfollowing literals:head(X,H), tail(X,L1), equal(X,[L1,T]), null(T), null(H), null(L1), equal(X,[L1]),atten(H,X1), atten(L1,X2),append(X1,X2,L), assign(X1,L), assign(X2,L), list(X,L).clauses whose head \remove(IL,OL)" whose body composed conjunction following literals:cons(X,N,OL), null(IL), assign([],OL),head(IL,X), tail(IL,L), member(X,L), remove(L,OL), remove(L,N).correct clauses null, head, tail, equal, assign, member, append given:null([]).head([Hj ],H).tail([ jT],T).equal(X,X).assign(X,X).member(X,[Xj ]).member(X,[ jT]) :- member(X,T).95fiBergadano, Gunetti, & Trincheroappend([],Z,Z).append([HjX],Y,[HjZ]) :- append(X,Y,Z).using various kinds constraints, initial number clauses strongly reduced.Possible constraints following:output produced must instantiated again. meansvariable cannot occur output antecedent once.Inputs must used: input variables head clause must also occurantecedent.conjunctions literals ruled never true, e.g.null(IL)^head(IL,X).applying various combination constraints possible strongly restrictinitial hypothesis space, given input learning procedure. setpositive negative examples used learning task is:simplify pos([[[],[b,a,a]],[]],[b,a]). remove pos([a,a],[a]).(simplify neg([[[],[b,a,a]],[]],X),not equal(X,[b,a])).simplify neg([[a,b,a],[]],[a,[b,a]]). remove neg([a,a],[a,a]).Note define negative examples simplify examplesinput given positive example different output, instance simplify neg([[[],[b,a,a]],[]],[a,b]). Obviously, also possible give negative examplesnormal ground literals. learning procedure outputs program simplify reportedbelow, turns substantially equivalent one described (Coelho &Cotta, 1988) (we kept clauses un attened).simplify(L,NL) :- atten(L,L1), remove(L1,NL).atten(X,L) :- equal(X,[L1,T]), null(T), !, atten(L1,X2), assign(X2,L).atten(X,L) :- head(X,H), tail(X,L1), null(H), !, atten(L1,X2), assign(X2,L).atten(X,L) :- equal(X,[L1]), !, atten(L1,X2), assign(X2,L).atten(X,L) :- head(X,H), tail(X,L1), !,atten(H,X1), !, atten(L1,X2), append(X1,X2,L).atten(X,L) :- list(X,L).remove(IL,OL) :- head(IL,X), tail(IL,L), member(X,L), !, remove(L,OL).remove(IL,OL) :- head(IL,X), tail(IL,L), remove(L,N), cons(X,N,OL).remove(IL,OL) :- null(IL), assign([],OL).learning task takes 44 seconds implementation. However, obtainedspecial conditions, thoroughly discussed next sections:constraints listed applied, final hypothesis spacereduced less one hundred clauses.96fiThe Difficulties Learning Logic Programs CutClauses hypothesis space generated correct order, must appearfinal program. Moreover, literals clause correct position.important, since logic program cut relative position clausesliterals significant. consequence, learn simplify without testdifferent clause literal orderings (see subsections 4.2 4.5).tell learning procedure use two cuts per clause. seemsquite intuitive constraint since, fact, many classical logic programsone cut per clause (see subsections 4.1 5.4).4. ProblemsExperiments induction procedure shown many problems ariselearning logic programs containing cut. following, analyze problems,major contribution present paper. cut cannot evaluated extensionally,analysis general, depend specific induction method adopted.possible partial solutions discussed Section 5.4.1 Problem 1: Intensional Evaluation, Backtracking Cutlearning procedure Section 2 simple, inecient. However,believe common every intensional method, clauses cannot learnedindependently one another. consequence, backtracking cannot avoidedimpact complexity learning process. Moreover, cut mustadded every trace covering negative examples. constraints force,range one cut whole trace cut two literals clausetrace. Clearly, number possibilities exponential number literalstrace. Fortunately, number usually much smaller size hypothesisspace, depends depth positive examples.However, backtracking also advantages; particular, useful searchalternative solutions. alternative programs confronted basisrequired characteristic, simplicity eciency. example, using backtrackingdiscovered version simplify equivalent one given without cut predicatetwo recursive calls fourth clause flatten.4.2 Problem 2: Ordering Clauses Tracelogic program containing cut, mutual position clauses significant, different ordering lead different (perhaps wrong) behavior program. example,following program intersection:c1) int(X,S2,Y) :- null(X), null(Y).c2) int(X,S2,Y) :- head(X,H), tail(X,Tail), member(H,S2), !, int(Tail,S2,S), cons(H,S,Y).c3) int(X,S2,Y) :- head(X,H), tail(X,Tail), int(Tail,S2,Y).behaves correctly c2 comes c3. Suppose hypothesis space given inputinduction procedure consists three clauses above, c397fiBergadano, Gunetti, & Trincheroc2. :int([a],[a],[]) given negative example, learning task fails,clauses c1 c3 derive example.words, learning program containing cut means learn setclauses, also specific ordering clauses. terms induction proceduremeans every trace covering negative example, must checkevery position inserting cuts, also every possible clause ordering trace.\generate test" behavior dicult implement, dramatically decreaseperformance learning task. worst case possible permutations mustgenerated checked, requires time proportional (md)! trace mdclauses2 .necessity test different permutations clauses trace primary sourceineciency learning programs cut, probably dicult problemsolve.4.3 Problem 3: Kinds Given Examplesinduction procedure able learn programs traces, i.e. everyclause program used derive least one positive example. learning definiteclauses, problem, derivation monotone, every program P,complete consistent w.r.t. given examples, program P0P alsocomplete consistent trace3. hand, learning clauses containing cut, may happen complete consistent program(s) hypothesisspace neither trace, contains subset. derivation longermonotone case negative example derived set clauses,superset them, following simple example:= fsum(A,B,C) :- A>0, !, A-1, sum(M,B,N), C N+1.sum(A,B,C) :- C B.gsum pos(0,2,2), sum neg(2,2,2).two clauses hypothesis space represent complete consistent programgiven examples, procedure unable learn it. Observe negativeexample derived second clause, trace positive example,first second together.problem avoided require that, every negative example, corresponding positive example input given (in case, examplerequired sum pos(2,2,4)). way, complete program exists hypothesisspace, also trace, learned. made consistent usingcut, order rule derivation negative examples. constraint positivenegative examples seems quite intuitive. fact, writing program,2. must noted learning programs two different predicates, j k clausesrespectively (that is, md = j +k), consider (j +k)! different programs,j !+k!. better if, inside program, known non-recursive clauses fixedposition, put recursive clauses.3. learned program P complete derives given positive examples, consistentderive given negative examples98fiThe Difficulties Learning Logic Programs Cutprogrammer usually thinks terms program compute given inputs,tries avoid wrong computations inputs.4.4 Problem 4: Ordering Given Exampleslearning clauses cut, even order positive examples may significant.example above, sum pos(2,2,4) comes sum pos(0,2,2) learning taskfails learn correct program sum, cannot find program consistent w.r.t.first positive example negative one(s).general, given set positive examples problem remediedtesting different example orderings. Again, worst case k! different orderings setk positive examples must checked. Moreover, situations favorable orderingexist. Consider following hypothesis space:c1) int(X,Y,W) :- head(X,A), tail(X,B), notmember(A,Y), int(B,Y,W).c2) int(X,Y,W) :- head(X,A), tail(X,B), notmember(A,Y), !, int(B,Y,W).c3) int(X,Y,Z) :- head(X,A), tail(X,B), int(B,Y,W), cons(A,W,Z).c4) int(X,Y,Z) :- head(X,A), tail(X,B), !, int(B,Y,W), cons(A,W,Z).c5) int(X,Y,Z) :- null(Z).together set examples:e1 ) int pos([a],[b],[ ]).e2 ) int pos([a],[a],[a]).e3 ) int neg([a],[b],[a]).e4 ) int neg([a],[a],[ ]).induction procedure able find correct program orderingtwo positive examples, even program exist ([c2,c4,c5]). programunion two traces: [c2,c5], covers e1 , [c4,c5], covers e2 . tracesinconsistent, first covers e4 , second covers e3 . problemremedied positive examples derived check negativeexamples done.However, case loss eciency, inconsistenttraces discarded end. words, would need learn programcovering positive examples, make consistent using cut reordering clauses. Moreover, way make program consistent using cutreorderings. consequence, time used build program wasted.example, suppose given following hypothesis space:c01) int(X,Y,Z) :- head(X,A), tail(X,B), int(B,Y,W), cons(A,W,Z).c02) int(X,Y,Z) :- null(X), null(Z).c03) int(X,Y,Z) :- null(Z).99fiBergadano, Gunetti, & Trincheroexamples:e01) int pos([a],[a],[a]).e02 ) int pos([a,b],[c],[]).e03 ) int neg([a],[b],[a]).learn trace [c01,c02] e01 trace [c03] e02 . [c01,c02,c03] coverse03, way make consistent using cut reordering clauses. fact,first partial trace responsible inconsistency, hence time used learn[c03] totally wasted.also possible understand need attened clauses. Consider following program intersection, equivalent [c2,c4,c5], three clausesun attened:u2 ) int([AjB],Y,W) :- notmember(A,Y), !, int(B,Y,W).u4 ) int([AjB],Y,[AjW]) :- !, int(B,Y,W).u5 ) int( , ,[]).Now, program covers int neg([a],[a],[]), i.e. [u2 ,u4,u5 ] ` int([a],[a],[]). fact, clauseu2 fails example member [a]. Clause u4 fails emptylist cannot matched [AjW]. clause u5 succeeds arguments matchnegative example. consequence, program would rejectedinduction procedure.problem that, use un attened clauses, may happen clause bodyevaluated example match head clause. consequence,possible cuts clause evaluated cannot uence behavior entireprogram. example, cut clause u4 effect output argumentint([a],[a],[]) match [AjW], body u4 evaluated all. u5fired negative example covered. attened version, clause c4 failscons(a,[],[]) reached, point cut force clause c5 cannot activated.Note program [u2 ,u4,u5] behaves correctly query int([a],[a],X), gives X=[a]output.4.5 Problem 5: Ordering LiteralsEven relative position literals cut clause significant. Considercorrect program intersection ([c2,c4,c5]), c4 modified puttingcons literal front antecedent:c04) int(X,Y,Z) :- cons(A,W,Z), head(X,A), tail(X,B), int(B,Y,W).Then, way get correct program intersection using clause. rulenegative example int neg([a],[a],[]) must put cut cons predicate,order prevent activation c5. But, then, positive examples longercovered, int pos([a],[],[]). fact, wrong behavior every time clause c04100fiThe Difficulties Learning Logic Programs Cutcalled fails, since prevents activation c5 . general, problem cannotavoided even reordering clauses: put c04 c2 c5 , int neg([a],[a],[])covered. consequence, also test every possible permutation literalsevery clause candidate program.5. Situations Learning Cut still Practicalanalysis, learning cut appears dicult since, general, learningprocedure able backtrack candidate base programs (e.g., traces),position cut(s) program, order clauses program,order literals clauses order given positive examples. However,spotted general conditions learning cut could still practical. Clearly,conditions cannot final solution learning cut, but, applicable, alleviatecomputational problems task.5.1 Small Hypothesis SpaceFirst all, restricted hypothesis space necessary. clauses cannot learned independently one another, small hypothesis space would help limit backtrackingrequired candidate traces (problem 1). Moreover, even number clauses tracewould probably smaller, hence also number different permutationsnumber different positions inserted cuts (problems 2 1). small trace would alsoslight positive impact need test different literal orderings clauses(problem 5).general, many kinds constraints applied keep hypothesis space small,ij-determinism (Muggleton & Feng, 1990), rule sets schemata (Kietz & Wrobel,1991; Bergadano & Gunetti, 1993), determinations (Russell, 1988), locality (Cohen, 1993),etc (in fact, restrictions others, listed Section 3,available actual implementation procedure - see Appendix4 ). Moreover,candidate recursive clauses must designed infinite chains recursive callstake place (Bergadano & Gunetti, 1993) (otherwise learning task couldnon-terminating). general, number possible recursive calls must kept small,order avoid much backtracking searching possible traces. However, generalconstraints may sucient. hypothesis space must designed carefullybeginning, dicult. example learning simplify initialhypothesis space \only" 8449 clauses obtained specifying set requiredpredicates, even variables occurring every literal.clauses cannot learned independently, experiments shown us dramatic improvement learning task obtained generating clauseshypothesis space recursive clauses, general complex clauses, takenconsideration simpler non-recursive ones. Since simpler non recursiveclauses require less time evaluated, small impact learning time.Moreover, learning simpler clauses (i.e. shorter) also alleviates problem 5.4. found constraints particularly useful. using often able restrict hypothesisspace one order magnitude without ruling possible solution.101fiBergadano, Gunetti, & TrincheroFinally, must noted induction procedure necessarily requirehypothesis space possible clauses represented explicitly. learning task couldstart empty set implicit description hypothesis space, exampleone given Section 3. positive example cannot derived S, new clauseasked clause generator added S. step repeated examplederivable updated S, learning task proceed normally.5.2 Simple ExamplesAnother improvement achieved using examples simple possible.fact, example may involve recursive call potentially responsibleactivation corresponding clauses hypothesis space. complexexample, larger number consecutive recursive activations clauses largernumber traces considered backtracking (problem 1). instance, learnappend relation, may sucient use example like append([a],[b],[a,b]) insteadone like append([a,b,c,d],[b],[a,b,c,d,b]). Since simple examples would probably requiresmaller number different clauses derived, would result smaller traces,alleviating problem permutation clauses literals trace (problems 2 5)decreasing number positions cuts (problem 1).5.3 Small Number ExamplesSince candidate program formed taking union partial traces learned singleexamples, want small trace (problems 2 5) must use examplespossible, still completely describing required concept. words,avoid redundant information. example, want learn program append,normally sucient use one two positive examples append([a],[b],[a,b])append([c],[d],[c,d]). Obviously may happen different examples derivedset clauses, case final program change.check possible orderings set positive examples, small numberexamples also solution problem 4. Fortunately, experiments shown normallypositive examples needed learn program, hence correspondingnumber different orderings is, case, small number. Moreover, sincemethod positive example sucient learn clauses necessary derive it,time complete program learned using one well chosen example.example found (as case learning task section 3, oneexample simplify one remove given), computational problem testingdifferent example orderings automatically solved.However, must noted that, general, small number examples maysucient, except simple programs. fact, want learn logic programsmember, append, reverse on, example involving recursionsucient. complex programs choice may trivial. example,procedure able learn quicksort (plus partition) program one \good"example. one know quicksort partition work, likelyprovide example allowing learn partial description partition.particularly clear example simplify . used positive example102fiThe Difficulties Learning Logic Programs Cutsimplify pos([[[],[b,a,a]]],[b,a]) (which close one effectively used), first clauseflatten would learned. words, give examples must givegood examples, often possible mind (at least partiallyinformal way) target program. Moreover, complex programs, good examplesmean complex examples, contrast previous requirement.studies learning good examples refer reader work Ling (1991)Aha, Ling, Matwin Lapointe (1993).5.4 Constrained Positions Cut LiteralsExperiments shown practical allow learning procedure testpossible positions cut trace, even able keep number clausestrace small. user must able indicate positions cut allowedoccur, e.g., beginning clause body, recursive call. case, manyalternative programs cut automatically ruled thus testednegative examples. may also useful limit maximum number cutsper clause per trace. example, time one cut per clause sucientlearn correct program. actual implementation procedure, factpossible specify exact position cut w.r.t. literal group literals withinclause hypothesis space, information known.eliminate need test different ordering literals (problem 5), may alsoimpose particular global order, must maintained every clause hypothesisspace. However requires deep knowledge program want, otherwise(or even all) solutions lost. Moreover, solution contrast useconstrained positions cut, since solution program particular literal orderingparticular positions cuts may exist.6. Conclusioninduction procedure based intensional evaluation clauses. Since cutpredicate declarative meaning, believe intensional evaluation clausescannot abandoned, independently kind learning method adopted.decrease performance learning task, compared extensional methods,examine clauses one time without backtracking. However, computational problemsoutlined Section 4 remain even choose learn complete program extensionally,try make consistent inserting cut. differencebacktracking (problem 1), situation probably worse, since extensionalmethods fail learn complete program even exists hypothesis space.(Bergadano, 1993a).Even ability learn clauses containing procedural predicates like cut seemsfundamental learning \real" logic programs, particular short ecient programs,many problems uencing complexity learning task must faced. includenumber relative ordering clauses literals hypothesis space, kindrelative ordering given examples. problems seem related needintensional evaluation clauses general, particular learning methodadopted. Even alleviate problems, seems necessary know lot103fiBergadano, Gunetti, & Trincherotarget program. alternative solution simply ignore problems. is,avoid testing different clause and/or literal and/or example orderings. Clearly,way learning process become feasible, fail find solution evenexists. However, many ILP systems (such Foil) adopt \incomplete-but-fast"approach, guided heuristic information.consequence, view results presented paper as, least partially, negative. problems raised appear computationally dicult, suggest attentionrestricted purely declarative logic languages, are, case, sucientlyexpressive.Acknowledgementswork part supported BRA ESPRIT project 6020 Inductive Logic Programming.Appendixinduction procedure Section 2 written C-prolog (interpreted) runsSUNsparcstation 1. planning translate QUINTUS prolog. Appendixcontains simplified description implementation. preliminary step, orderrecord trace clauses deriving positive example e+, every clause hypothesisspace5 must numbered modified adding body two literals. firstone, allowed(n,m) used activate clauses must checkednegative examples. second one, marker(n), used remember clause number nsuccessfully used deriving e+. Hence, general, clause hypothesisspace takes following form:P (X1 ,: : : ,Xm) :- allowed(n,m), ,marker(n).actual body clause, n number clause setnumber used deal cuts. every clause n, one without cut augmentedallowed(n,0), containing cut somewhere body augmentedallowed(n,1), allowed(n,2), ..., on. Moreover, every augmented clause above,fact \alt(n,m)." inserted S, order implement enumeration mechanism.simplified (but running) version learning algorithm reported below.algorithm, output, any, variable Trace containing list (numbers the)clauses representing learned program P. using backtracking mechanism Prolog,one solution (trace) found. assume two predicates listpositivelistnegative build list given positive negative examples, respectively.consult(file containing set clauses S).5. assume clauses hypothesis space attened104fiThe Difficulties Learning Logic Programs Cutallowed(X,0).marker(X) :- assert(trace(X)).marker(X) :- retract(trace(X)), !, fail.main :- listpositive(Posexamplelist), tracer([],Posexamplelist,Trace).tracer(Covered,[ExamplejCdr],Trace) :- Example, /? backtracking point 1 ?/setof(L,trace(L),Trace1),notneg(Trace1,[ExamplejCovered],Cdr),tracer([ExamplejCovered],Cdr,Trace).tracer( ,[],Trace) :- setof((I,J),allowed(I,J),Trace), asserta((marker(X) :- true, !)).assertem([]).assertem([IjCdr]) :- alt(I,J), backassert(allowed(I,J)), assertem(Cdr).prep(T) :- retract(allowed(X,0)), assertem(T).backassert(X) :- assert(X).backassert(X) :- retract(X), !, fail.resetallowed([]) :- !.resetallowed( ) :- abolish(allowed,2), assert(allowed(X,0)), !.notneg(T,Covered,Remaining) :- listnegative([]).notneg(T,Covered,Remaining) :- listnegative(Negexamplelist),asserta((marker(X) :- true,!)),prep(T), /? backtracking point 2 ?/trypos(Covered), trynegs(Negexamplelist),resetallowed(Remaining),retract((marker(X) :- true,!)).notneg(T,Covered,Remaining) :- resetallowed(Remaining),retract((marker(X) :- true,!)), !, fail.trypos([ExamplejCdr]) :- Example, !, trypos(Cdr).trypos([]) :- !.trynegs([ExamplejCdr]) :- Example,!,fail.trynegs([ExamplejCdr]) :- trynegs(Cdr).trynegs([]) :- !.Actually, complete implementation complex, also order achieve greatereciency. behavior learning task quite simple. Initially, set clausesread Prolog interpreter, together learning algorithm. learningtask started calling predicate main. list positive examples formed105fiBergadano, Gunetti, & Trincherotracer procedure called list. every positive example, tracer callsexample itself, firing clauses may resolved example.Observe that, initially, allowed(X,0) predicate asserted database: wayclauses containing cut allowed used (this clauses cutemployed negative example derived). Then, trace, any, (the numbersassociated to) clauses successfully used derivation example built, usingsetof predicate.trace added traces found previous examples, resultchecked set negative examples calling notneg procedure. notnegfail (i.e. negative examples covered trace) new positiveexample taken consideration. Otherwise notneg modifies trace cuttests again. also fails, backtracking occurs new trace current example(and possibly previous ones) searched for.notneg procedure works follows. First, clauses trace allowedchecked negative examples, retracting allowed(X,0) clauseasserting allowed(n,0) n-th clause (without cut) trace. doneprep assertem predicates. list negative examples formedcheck derived clauses trace. least one negative examplecovered, (i.e., trynegs fails) backtrack prep procedure (backtracking point2) clause trace substituted equivalent one cut insertedsomewhere (or different position). correct program found waytrying possible alternatives (i.e. using cut possible ways), notneg fails,backtracking backtracking point 1 occurs, another trace searched for. Otherwise,clauses without cut reactivated asserting allowed(X,0), nextpositive example considered. Note trypos used notneg verify modifiedtrace still derives set positive examples derived initially. possibility substituteclauses current trace others cut inserted somewhere achievedalt predicate assertem procedure. Finally, note simplified versionlearning procedure able generate test different orderings clausestrace different ordering literals clause, use different orderingsset positive examples.order derive positive examples check negative ones(see subsection 4.4), must change first clause tracer procedure into:tracer([Pos1, ... ,Posn]):-Pos1, ... ,Posn, setof(L,trace(L),T), notneg(T).actual implementation induction procedure available ftp.information contact gunetti@di.unito.it.ReferencesAha, D., Ling, C., Matwin, S., & Lapointe, S. (1993). Learning Singly Recursive RelationsSmall Datasets. Proceedings IJCAI-93 workshop ILP.Bergadano, F. (1993a). Inductive database relations. IEEE Transactions DataKnowledge Engineering, 5 (6).106fiThe Difficulties Learning Logic Programs CutBergadano, F. (1993b). Test Case Generation Means Learning Techniques. Proceedings ACM SIGSOFT-93.Bergadano, F., & Gunetti, D. (1993). interactive system learn functional logic programs. Proceedings IJCAI-93.Coelho, H., & Cotta, J. C. (1988). Prolog Example: learn teach use it. Berlin:Springer-Verlag.Cohen, W. (1993). Rapid Prototyping ILP Systems Using Explicit Bias. ProceedingsIJCAI-93 workshop ILP.DeRaedt, L., Lavrac, N., & Dzeroski, S. (1993). Multiple predicate learning. ProceedingsIJCAI-93.Kietz, J. U., & Wrobel, S. (1991). Controlling Complexity Learning LogicSyntactic Task-Oriented Models. Muggleton, S. (Ed.), Inductive Logic Programming. London: Academic Press.Lau, K. K., & Clement, T. (Eds.). (1993). Logic Program Synthesis Transformation.Berlin: Springer-Verlag.Ling, X. C. (1991). Learning Good Examples. Proceedings IJCAI-91.Muggleton, S. (Ed.). (1991). Inductive Logic Programming. London: Academic Press.Muggleton, S., & Feng, C. (1990). Ecient Induction Logic Programs. Proceedingsfirst conference Algorithmic Learning Theory.Quinlan, R. (1990). Learning Logical Definitions Relations. Machine Learning, 5,239{266.Rouveirol, C. (in press). Flattening: representation change generalization. MachineLearning.Russell, S. (1988). Tree-structured bias. Proceedings AAAI-88.Shapiro, E. Y. (1983). Algorithmic Program Debugging. Cambridge, CA: MIT Press.107fiJournal Artificial Intelligence Research 1 (1994) 257-275Submitted 11/93; published 3/94Exploring Decision Forest: Empirical InvestigationOccam's Razor Decision Tree InductionPatrick M. MurphyMichael J. PazzaniDepartment Information & Computer ScienceUniversity California, Irvine, CA 92717pmurphy@ics.uci.edupazzani@ics.uci.eduAbstractreport series experiments decision trees consistenttraining data constructed. experiments run gain understandingproperties set consistent decision trees factors affect accuracyindividual trees. particular, investigated relationship sizedecision tree consistent training data accuracy tree test data.experiments performed massively parallel Maspar computer. resultsexperiments several artificial two real world problems indicate that, manyproblems investigated, smaller consistent decision trees average less accurateaverage accuracy slightly larger trees.1. Introductiontop-down induction decision trees approach machine learningused variety real world tasks. Decision trees well-suited tasks sincescale fairly well number training examples number features,represent complex concepts representation fairly easy people understand.Decision tree induction algorithms (Breiman, Friedman, Olshen, & Stone, 1984; Quinlan, 1986; Fayyad & Irani, 1992) typically operate choosing feature partitionstraining data according evaluation function (e.g., purity resulting partitions). Partitions partitioned recursively stopping criterionreached (e.g., partitions contain training examples single class). Nearly decisiontree induction algorithms create single decision tree based upon local informationwell feature partitions training data. However, decision tree one setdecision trees consistent training data. paper, experimentally examineproperties set consistent decision trees. call set decision treesconsistent training data decision forest.experiments run several artificial concepts know correctanswer two naturally occurring databases real world tasks available UCIMachine Learning Repository (Murphy & Aha, 1994) correct answerknown. goal experiments gain insight factorssize consistent decision tree related error rate classifying unseen testinstances. Decision tree learners, well learners, attempt producec 1994 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.fiMurphy & Pazzanismallest consistent hypothesis.1 Occam's razor often used justify bias. Here,experimentally evaluate bias towards simplicity investigating relationshipsize consistent decision tree accuracy. average errordecision trees N test nodes less average error decision trees size N +(for > 0), appropriate bias learner attempting minimize average error wouldreturn smallest decision tree find within resource constraints.paper, restrict attention decision trees consistenttraining data ignore issues pruning trade consistency trainingdata simplicity hypothesis. purposes paper, consistentdecision tree one correctly classifies every training example.2 also place twoadditional constraints decision trees. First, discriminator pass instancessingle branch. insures test made decision tree partitions trainingdata. Second, training instances node class, additionaldiscriminations made. case, leaf formed class label specified classinstances leaf. two constraints added insure decisiontrees analyzed experiments correspond could formed topdecision tree induction algorithms. paper, investigate problemscontinuous-valued features missing feature values.Section 2 (and appendix), report initial exploratory experimentssmallest consistent decision trees tend less accurate averageaccuracy slightly larger. Section 3 provides results additional experimentsaddress issue. Section 4 addresses implication findings policy learnertake deciding many consistent hypotheses prefer. Section5 relates work previous empirical theoretical research.2. Initial Experimentsinvestigate relationship various tree characteristics error. particular, look node cardinality (i.e., number internal nodes tree)leaf cardinality (i.e., total number leaves tree).noted even using powerful massively parallel computer,choice problems severely constrained computational complexity task.number trees node cardinality might generated O(dc )number discriminators c node cardinality. Even massively parallelcomputer, precluded use problems many features continuous-valuedfeatures.first experiment considered learning training data 5 booleanfeatures. concept learned XY Z _ AB . concept chosenmoderate complexity, requiring decision tree least 8 nodes represent correctly.5 boolean features, smallest concept (e.g., True) would require 0 test nodeslargest (e.g., parity) would require 31.1. say \attempt produce smallest consistent hypothesis" systems use formlimited look-ahead greedy search. result, smallest consistent tree rarely found.2. artificial natural problems study consistent training sets.258fiExploring Decision Forest0.61000.580Error0.4600.3400.2ErrorTrials0.1200.0Number Trialsran 100 trials, creating training set randomly choosing without replacement20 32 possible training examples using remaining 12 examples testset. trial, every consistent decision tree created, computed averageerror rate made trees node cardinality. Figure 1 plots mean 95%confidence interval average errors function node cardinality. Figure 1also plots number trials least one decision tree given node cardinalityconsistent training data.002468 10 12 14Node Cardinality161820Figure 1. average error 100 trials function node cardinality numbertrials node cardinality.node cardinality 7 node cardinality 16, monotonic increase errorincreasing node cardinality. range 2 3 nodes, error varied;however little evidence error values based 21 trials, respectively. range node cardinalities 4 7, average errordefinitely monotonically increasing function node cardinality. seen curve,5 node trees average accurate 4 node trees, 7 node treesaverage accurate trees 6 nodes. last result somewhat surprisingsince one gets impression reading machine learning literature (Muggleton,Srinivasan, & Bain, 1992) smaller hypothesis (i.e., one providescompression data (Rissanen, 1978)) likely accurate. exploreissue detail Section 3. Appendix 1 presents data showing resultunique particular concept. final, interesting finding explorepaper large node cardinalities, error begins decreasenode cardinality increases.Table 1 lists average number consistent trees node cardinalityaverage number correct trees (i.e., trees consistent training data makeerrors unseen test examples). correct trees fewer 8 nodes,since least 8 nodes required represent concept. Clearly, since manytrees consistent training data, learner needs policy decide treereturn. return issue Section 4.259fiMurphy & PazzaniNodes2345678910111213141516171819NumberNumberConsistent Trees Correct Trees2.00.04.00.03.30.012.30.027.60.0117.10.0377.017.8879.437.81799.950.23097.841.64383.095.45068.966.64828.337.73631.531.31910.614.8854.44.0308.63.6113.80.0Table 1. average number trees consistent 20 training examples XY Z_ABconcept.3. Experimentationproblems studied, found average, smallest decision treesconsistent training data error unseen examples slightly largertrees. ran additional experiments make sure result artifactexperimental methodology used, reported next sections.3.1 Representative Train/Test PartitionsOne possible explanation finding previous section smaller decisiontrees formed unrepresentative samples. example, 11 positive 21negative examples concept XY Z _ AB . examples trainingset negative, small tree may learned would probably poorlymostly positive test set. insure results caused unrepresentativetraining sets, eliminated training data reasonably representative.11 probability training instance positive, representativeparticular, since 32training set7 positive instances. Since one standard deviationq size11 20 would11would 20 3 32 3 (1 0 32 ), eliminated analysis training sets greater8 fewer 5 positive instances. Similarly, 0.5 probabilitybinary feature takes true value, eliminated analysis training datafeature true greater 13 fewer 7 instances. Figure 2 based260fiExploring Decision Forest0.61000.580Error0.4600.3400.2ErrorTrials0.1200.0Number Trials69 100 trials XY Z _ AB concept met representative test. Noticetwo trials formed 2 3 node trees removed. Evenrepresentative training sets considered, average error trees size 4greater average error size 5 trees.002468 10 12 14Node Cardinality161820Figure 2. Error rate consistent trees representative training sets functionnode cardinality.regrouping results 100 trials XY Z _AB concept trialsminimum-sized trees grouped together, set five curves, associatedsubgroup, formed (Figure 3). intent grouping allow us determinewhether minimum-sized trees given trial average accuratelarger trees.0.60.5Error0.40.3Min. Tree Size = 2Min. Tree Size = 4Min. Tree Size = 5Min. Tree Size = 6Min. Tree Size = 70.20.10.002468 10 12 14Node Cardinality1618Figure 3. Error function node cardinalitygrouped minimum-sized trees built.20XY Z _ AB concept firstNote Figure 3, minimum tree sizes, error monotonically increasing function node cardinality. Furthermore, average error smallest trees foundaccurate smallest tree 4 6 nodes. addition, regardless261fiMurphy & Pazzani0.61000.580Error0.4600.3400.2ErrorTrials0.1200.0Number Trialssize smallest tree found, average accuracy trees size 8 (the sizesmallest correct tree) rarely minimum average error.Another interesting finding becomes apparent way viewing data:average error rates trees training sets allow creation smaller consistent treestends higher training sets form larger trees. example,error rate training sets whose minimum-sized trees 4 nodes highererror rate trials whose minimum-sized trees 7 nodes.002468 10 12 14Node Cardinality161820Figure 4. Error rate consistent trees 2 examples per leaf correct 8 node treefunction node cardinality.definition representative used earlier section used global characteristics training data determine representativeness. Here, considerdetailed view representativeness takes structure correct concept account. unreasonable expect decision tree learner learn accurate conceptexamples correspond leaves correct decision tree.generate training data next experiment, first randomly selected one72 trees 8 nodes consistent data. Next, leaf tree,randomly selected two examples (if possible) include training set. leafone example, example included training set. Finally, randomlyselected remaining examples 20 training examples 12 testexamples. anticipated representative training sets formed manner,small consistent trees would rare perhaps error rate would monotonicallyincrease node cardinality. However, results 100 trials, displayed Figure 4,indicate general pattern before. particular, average error trees 7nodes substantially less average error 6 nodes. Another experimentone randomly selected example per leaf similar results.3.2 Training Set Size Concept Complexityminimum-sized decision tree concept XY Z _AB 8 tests 9 leaves. Sincecorrect tree provide much compression3 set 20 examples used induce3. exact amount compression provided depends upon particular scheme chosen encodingtraining data. See (Quinlan & Rivest, 1989; Wallace & Patrick, 1993) two schemes.262fiExploring Decision Foresttree, one might argue sample used small complex concept.Therefore, increased number training examples maximum possible. Figure5 plots average error 32 trials formed decision trees consistent 31examples. tree evaluated remaining unseen example. Figure 5 showssmaller trees formed samples size 31 error slightly largertrees. Since minimum correct decision tree 8 nodes consistent trees classify31 training examples correctly, decision tree fewer 8 nodes classifiestest example incorrectly.3228Error0.8ErrorTrials242016128400.60.40.20.00246Number Trials1.08 10 12 14 16 18 20 22 24 26Node CardinalityFigure 5. Error rate consistent trees leave-one-out testing function nodecardinality.refute hypothesis results obtained far based usingsmall training set given concept complexity, considered two less complexconcepts. particular, investigated single attribute discrimination, fourirrelevant features (Figure 6) simple conjunction, AB three irrelevant features(Figure 7).0.6100Error0.4800.30.260ErrorTrials0.10.0Number Trials0.54002468 10 12 14Node Cardinality161820Figure 6. Error function node cardinality single attribute discriminationconcept.263fiMurphy & Pazzani10080Error0.3600.2400.1ErrorTrials200.0Number Trials0.4002468 10 12 14Node Cardinality161820Figure 7. Error function node cardinality simple conjunctionAB concept.concept, 100 trials run 20 examples used trainingremaining 12 testing. simpler concepts, though smallest treesaccurate, error monotonically increasing function node cardinality.3.3 Training Testing using Probability Distribution.previous experiments, used methodology typical empirical evaluationsmachine learning systems: training data test data disjoint. contrast,theoretical work PAC model (Valiant, 1984) assumes trainingtest data generated probability distribution examples.section, ran experiment training test examples selectedreplacement distribution ensure results dependentparticular experimental methodology.10080Error0.15600.10400.05ErrorTrials0.0020Number Trials0.20002468 10 12 14 16 18 20 22Node CardinalityFigure 8. Error function node cardinality training test examplesgenerated distribution XY Z _ AB concept.again, target concept XY Z _ AB . randomly choosing 31 trainingexamples replacement set 32 possible instances, average approximately20 distinct training examples selected. Error estimated randomly choosing 1000264fiExploring Decision Forestexamples replacement set possible instances. Figure 8 graphs meanerror (averaged 100 trials) function node cardinality.testing methodology produces much smaller values proportion test examples misclassified disjoint training test set methodology testexamples also training examples always classified correctly. However,basic pattern results observed. Error minimum smallest decision trees decision trees 8 nodes (the minimum-sized correct tree). Errormonotonically increases starting trees 7 nodes begins decreaselarge node cardinalities. Note trials, possible build decisiontrees 21 nodes since training sets contained 22 distinct examples.3.4 Average Path Lengthinformation gain metric ID3 intended minimize number tests requiredclassify example. Figure 9 reanalyzes data Figure 1 graphing average errorfunction average path length XY Z _ AB concept.100800.3Error60400.2ErrorTrials200.1Number Trials0.401.02.03.04.0Average Path Length5.0Figure 9. Error function average path length XY Z _ AB concept.results similar obtained relating number test nodeserror rate: error monotonically increasing function average path length. Similaranalyses performed similar results obtained conceptspresented Appendix.4. Minimum-Sized Decision Tree Policydesigner learning algorithm either explicitly implicitly must decide hypothesis prefer multiple hypotheses consistent training data. Table 1shows, many consistent decision trees. learner always prefersmallest consistent decision tree? learner adopts strategy saidfollowing minimum-sized decision tree policy.265fiMurphy & Pazzanisection, present results additional experiments evaluate policy.particular, gather evidence address two related questions:Given two consistent decision trees different node cardinalities,probability smaller decision tree accurate?Given minimum-sized decision tree larger consistent decision tree,probability smallest decision tree accurate?first question interest current practice decision tree inductionsince, eciency reasons, algorithm attempts find smallest consistent decisiontree large data sets. Nonetheless, algorithms biased toward favoring treesfewer nodes.0.8Probability0.6Prob(Smaller > Larger)Prob(Larger > Smaller)Prob(Smaller = Larger)0.40.20.0024681012Difference Node Cardinality1416Number trials10008006004002000024681012Difference Node Cardinality1416Figure 10. probability accuracy smaller decision tree greater than,equal to, less accuracy larger tree function difference nodecardinalities XY Z _AB concept (upper). number trials 1000least 2 trees given difference node cardinality (lower).address question whether learner prefer smaller two randomlyselected consistent trees, ran 1000 trials learning concept XY Z _ AB 20training examples. trial, recorded node cardinality accuracy (on12 test examples) every consistent tree. pair consistent trees (with different266fiExploring Decision Forestnode cardinalities), computed difference node cardinality indicated whetheraccuracy smaller tree greater than, equal to, less accuracylarger tree. data, computed observed probability one decision treeaccurate another function difference node cardinalities (seeFigure 10 upper). graph shows concept, probability smallertwo randomly chosen consistent decision trees accurate greaterprobability larger tree accurate. Furthermore, probabilitysmaller tree accurate increases difference node cardinality increases.exception trend occurs large differences node cardinality. However,Figure 10 lower shows, exceptions quite rare. Consistent decision trees whosenode cardinalities differed 16 found 6 1000 trials.4 resultsexperiment indicate average, learner prefers smaller two randomlyselected decision trees higher probability accurate conceptlearner selects larger tree.Probability0.80.6Prob(Smallest > Larger)Prob (Larger > Smallest)Prob(Smallest = Larger)0.40.20.0024681012Difference Node Cardinality1416Figure 11. probability accuracy minimum-sized decision greater than,equal to, less accuracy larger tree function difference nodecardinalities XY Z _ AB concept.address question whether learner prefer smallest consistent decision randomly selected consistent tree test nodes, reanalyzed dataprevious experiment. Figure 11 graphs observed probability consistentdecision tree minimum node cardinality accurate larger treefunction difference node cardinalities two trees. graph showslearner chooses randomly among consistent decision trees minimum nodecardinalities likely find tree accurate learner randomlyselects among larger trees.5Figure 11 clearly shows particular concept, preferring minimum-sizeddecision tree policy average better policy preferring decision tree4. Four trials minimum-sized trees 2 nodes maximally sized trees 18 nodes. Two trialsminimum-sized trees 3 nodes maximally sized trees 19 nodes.5. Except rare case extremely small extremely large decision trees foundtrial.267fiMurphy & Pazzanifixed size larger smallest decision tree. However, clear minimumsized decision tree best possible policy concept. Indeed, lookingdata Figure 3, apparent better strategy concept would findminimum-sized tree decide whether return minimum-sized tree treedifferent node cardinality function node cardinality minimum-sizedconsistent tree. Table 2 shows node cardinality highest probabilityaccurate function minimally sized tree, together number trials(out 1000) minimum-sized tree particular node cardinality.MinimumPreferredNumberNode Cardinality Node CardinalityTrials224935174530055351682117871881Table 2. policy returning larger decision tree function minimum-sizedtree XY Z _ AB concept.Figure 11 provides data illustrates policy Table 2perform better preferring minimum-sized decision tree concept. Figure12 graphs observed probability consistent decision tree minimum nodecardinality 5 (upper), 6 (middle), 7 (lower) accurate larger treefunction difference node cardinalities two trees. graph showsminimum-sized decision tree 5 nodes, probability larger treeaccurate less probability smaller tree accuratenode cardinalities. particularly interesting shows giving decisiontree learner size correct tree decision tree learner producehypothesis size best strategy concept. However, smallestconsistent tree 6 nodes, 0.560 probability randomly chosen tree8 nodes accurate 0.208 probability tree 8 test nodesaccuracy. addition, minimum-sized tree 7 test nodes,probability tree 8 nodes accurate 0.345 probabilityless accurate 0.312.Note believe policy Table 2 uniformly superior preferringminimum-sized decision tree. Rather, probably interactioncomplexity concept learned, number training examples, sizesmallest consistent decision tree. Furthermore, learner tuned learnparticular concept, perform well variety concepts. Clearly, extremelysimple concepts learned suciently frequently, minimum-sized decision treepolicy better policy Table 2. Indeed, minimum-sized decision tree268fiExploring Decision Forestpolicy would work well simple concepts AB discussed Section 3.2. However,simple concepts rarely encountered, may better policies. best policy mustdepend upon distribution concepts encountered. Clearly, conceptMinimum Node Cardinality = 51.0Probability0.8Prob(Smallest>Larger)Prob(Larger>Smallest)Prob(Smallest=Larger)0.60.40.20.00510Difference Node Cardinality15Minimum Node Cardinality = 61.0Probability0.8Prob(Smallest>Larger)Prob(Larger>Smallest)Prob(Smallest=Larger)0.60.40.20.00510Difference Node Cardinality15Minimum Node Cardinality = 71.0Probability0.8Prob(Smallest>Larger)Prob(Larger>Smallest)Prob(Smallest=Larger)0.60.40.20.00510Difference Node Cardinality15Figure 12. probability accuracy minimum-sized decision tree greaterthan, equal to, less accuracy larger tree function differencenode cardinalities XY Z _ AB concept minimum-sized decision tree 5(upper), 6 (middle), 7 (lower) test nodes.269fiMurphy & Pazzanilearned XY Z _AB , best policy would ignore training data returndecision tree representation XY Z _ AB . may Occam's razorviewed philosophical statement distribution concepts one likelyencounter. Occam's razor shown guarantee learningcomplex concept, simplest hypothesis consistent data likelyaccurate randomly-chosen complex hypothesis consistent trainingdata.5. AnalysisSchaffer (1992, 1993) presents series experiments overfitting avoidance algorithms.Overfitting avoidance algorithms prefer simpler decision trees complex ones, eventhough simpler decision trees less accurate training data, hopestrees accurate test data. Schaffer shows overfitting avoidancealgorithms form bias. Rather uniformly improving performance, overfittingavoidance algorithms improve performance distributions concepts worsenperformance distributions concepts.results experiments go step Schaffer's. shownconcepts, preference simpler decision trees result increasepredictive accuracy unseen test data, even simple trees consistenttraining data. Like Schaffer, dispute theoretical results Occam'srazor (Blumer, Ehrenfeucht, Haussler, & Warmuth, 1987), minimum description length(Quinlan & Rivest, 1989; Muggleton et al., 1992), minimizing number leavesdecision tree (Fayyad & Irani, 1990). Rather, point variety reasons,assumptions behind theoretical results mean results applyexperiments reported here. example, (Blumer et al., 1987) indicates one findshypothesis suciently small hypothesis space (and simpler hypotheses one examplesmall hypothesis space) hypothesis consistent suciently large sampletraining data, one fairly confident fairly accurate unseen datadrawn distribution examples. However, say averagehypothesis accurate consistent hypotheses smallhypothesis space.(Fayyad & Irani, 1990) paper explicitly states results minimizingnumber leaves decision trees worst case results used makeabsolute statements concerning improvements performances. Nonetheless, informal arguments paper state: \This may serve basis provably establishing onemethod inducing decision trees better another proving one algorithmalways produces tree smaller number leaves, given training data."Furthermore, informal arguments imply result probabilisticexistence \pathological training sets." However, shown Figures 2 4(as well reanalysis mux6 data Appendix), eliminating pathological (i.e.,unrepresentative) training sets change qualitative result concepts,smaller trees less accurate predictors slightly larger trees.270fiExploring Decision Forest6. Conclusionreported series experiments generated decision treesvariety artificial concepts two naturally occurring data sets. foundmany concepts, consistent decision trees smaller number nodesless accurate unseen data slightly larger ones. results contradictexisting theoretical results. Rather, serve remind us cautious informallyusing intuitions derived theoretical results problems coveredtheorems using intuitions derived worst-case results predict average-caseperformance.stress results purely experimental. Like reader, wouldpleased theoretical results indicated, given sample training data,decision tree likely accurate. However, clear whetherdone without knowledge distribution concepts one likely encounter (Schaffer,1994).also note results may due small size training sets relativesize correct tree. tried rule possibility using larger training sets(31 32 possible examples) testing simpler concepts. simpler concepts,smallest decision trees accurate, error monotonically increasenode cardinality. Since decision tree learners greedily build decision treesreturn smallest decision tree, results may practical interest evensimple concepts. future, experiments features examples couldhelp answer question, considerably complex problems cannot handledeven future generations parallel supercomputers. addition, noteexperiments, build decision trees test partition trainingdata. explains found relatively extremely large decision trees mayexplain large trees made errors. knowledge, decision tree algorithmsconstraint. However, theoretical work learning make useinformation. could rerun experiments without constraint, wouldprefer future theoretical work take constraint account.Although found situations smallest consistent decision treeaverage accurate cases greater 0.5 probabilitylarger decision tree accurate smallest, believe learning algorithms(and people) relevant knowledge concept informationdistribution concepts likely encountered prefer simpler hypotheses.bias appropriate learning simple concepts. complex concepts,opposite bias, preferring complex hypotheses, unlikely produce accuratehypothesis (Blumer et al., 1987) (Fayyad & Irani, 1990) due large numberconsistent complex hypotheses. believe way learn complex hypothesesreliably bias (e.g., prior domain knowledge) favors particular complexhypotheses combinations existing hypotheses learned inductively OCCAM(Pazzani, 1990). Indeed, (Valiant, 1984) advocates similar position: \If classlearnable concepts severely limited suggested results, would followway teaching complex concepts build simplerones."271fiMurphy & PazzaniAcknowledgementsthank Ross Quinlan, Geoffrey Hinton, Michael Cameron-Jones, Cullen Schaffer, Dennis Kibler, Steve Hampson, Jason Catlett, Haym Hirsh, Anselm Blumer, Steve Minton,Michael Kearns, Tom Dietterich, Pat Langley, David Schulenburg commentingvarious aspects research. research reported supported partNSF infrastructure grant number MIP-9205737, NSF Grant INT-9201842, AFOSR grantF49620-92-J-0430, AFOSR AASERT grant F49620-93-1-0569.Appendix A. Experiments Additional Problemsappendix, provide data experiments ran additional problems.experiments show basic findings paper unique artificialconcept, XY Z _ AB .Mux6multiplexor concept consider, mux6, total 8 binary features. Six featuresrepresent functionality multiplexor 2 features irrelevant. minimum sizedtree 7 nodes. particular concept chosen dicult top-downinductive decision tree learner limited look ahead find small hypothesis (Quinlan,1993). trial, selected 20 examples randomly tested remainingexamples. Since computational cost building consistent trees largernode cardinalities primarily interested trees small node cardinalities,computed consistent trees 10 nodes 10 trials 8 nodes 3400.45350ErrorTrialsError2502000.351501000.30500.25Number Trials3000.400246Node Cardinality810Figure 13. Error function node cardinality mux6 concept.trials. Figure 13 presents average error function node cardinalitytrials. graph shows average error monotonically increase nodecardinality. Trees 4 nodes average 4% less accurate trees 5 nodes.272fiExploring Decision ForestLenses0.70.70.60.60.50.50.40.4ErrorErrorlenses domain one 3-valued three binary features, three classes, 24 instances. Since lenses domain one non-binary feature, trees range leafcardinalities possible particular node cardinality. minimum-sized tree6 nodes 9 leaves. Separate analyses leaf node cardinalities performed.used training set sizes 8, 12, 18 domain, built consistent trees,measured error rate unseen examples.0.30.20.2Size = 8Size = 12Size = 180.10.3Size = 8Size = 12Size = 180.10.00.00246 8 10 12Node Cardinality14 16 180246 8 10 12 14 16 18 20Leaf CardinalityFigure 14. Error function node cardinality (left) error function leafcardinality (right).Figure 14 (left) shows error function node cardinality 3 trainingset sizes averaged 50 trials. curves indicate smallest consistent treesalways accurate. observing larger node cardinalities trainingset sizes 12 18, error monotonically decreases increasing node cardinality. Similarstatements said curve Figure 14 (right), relates average errorfunction leaf cardinality.Shuttle Landingshuttle landing domain four binary two 4-valued features, two classes, 277instances. minimum-sized consistent tree 7 nodes 14 leaves. used trainingsets size 20, 50, 100 shuttle domain, generating consistent decision treesfewer 8, 10, 12 nodes, measured error trees unseenexamples. Figure 15 presents error function leaf cardinality, averaged273fiMurphy & Pazzani10 trials. domain, monotonically increasing relationship nodecardinality error.0.4size = 20size = 50size = 100Error0.30.20.10.00246810Node Cardinality1214Figure 15. Error function node cardinality Shuttle concept.ReferencesBlumer, A., Ehrenfeucht, A., Haussler, D., & Warmuth, M. (1987). Occam's razor. Information Processing Letters, 24, 377{380.Breiman, L., Friedman, J., Olshen, R., & Stone, C. (1984). Classification RegressionTrees. Pacific Grove, CA: Wadsworth & Brooks.Fayyad, U., & Irani, K. (1990). minimized decision tree?. ProceedingsEighth National Conference Artificial Intelligence, AAAI-90.Fayyad, U., & Irani, K. (1992). attribute selection problem decision tree generation..Proceedings Tenth National Conference Artificial Intelligence, AAAI-92.Muggleton, S., Srinivasan, A., & Bain, M. (1992). Compression, significance accuracy.Machine Learning: Proceedings Ninth International Workshop.Murphy, P., & Aha, D. (1994). UCI Repository machine learning databases [Machinereadable data repository]. Irvine, CA: University California, Department Information Computer Science.Pazzani, M. (1990). Creating memory causal relationships: integration empiricalexplanation-based learning methods. Hillsdale, NJ: Lawrence Erlbaum Associates.Quinlan, J. (1986). Induction decision trees. Machine Learning, 1 (1), 81{106.Quinlan, J. (1993). C4.5 Programs Machine Learning. San Mateo,CA: Morgan Kaufmann.Quinlan, J., & Rivest, R. (1989). Inferring decision trees using minimum descriptionlength principle. Information Computation, 80, 227{248.274fiExploring Decision ForestRissanen, J. (1978). Modeling shortest data description. Automatica, 14, 465{471.Schaffer, C. (1992). Sparse data effect overfitting avoidance decision treeinduction. Proceedings Tenth National Conference Artificial Intelligence,AAAI-92.Schaffer, C. (1993). Overfitting avoidance bias. Machine Learning, 10 (2), 153{178.Schaffer, C. (1994). conservation law generalization performance. UnpublishedManuscript.Valiant, L. (1984). theory learnable. Communications ACM, 27 (11), 1134{1142.Wallace, C., & Patrick, J. (1993). Coding decision trees. Machine Learning, 11 (1), 7{22.275fiJournal Artificial Intelligence Research 1 (1994) 231-255Submitted 12/93; published 2/94Substructure Discovery Using Minimum DescriptionLength Background KnowledgeDiane J. CookLawrence B. HolderDepartment Computer Science EngineeringBox 19015University Texas ArlingtonArlington, TX 76019 USAcook@cse.uta.eduholder@cse.uta.eduAbstractability identify interesting repetitive substructures essential component discovering knowledge structural data. describe new version Subdue substructure discovery system based minimum description length principle.Subdue system discovers substructures compress original data representstructural concepts data. replacing previously-discovered substructuresdata, multiple passes Subdue produce hierarchical description structural regularities data. Subdue uses computationally-bounded inexact graph matchidentifies similar, identical, instances substructure finds approximatemeasure closeness two substructures computational constraints. addition minimum description length principle, background knowledge usedSubdue guide search towards appropriate substructures. Experimentsvariety domains demonstrate Subdue's ability find substructures capable compressing original data discover structural concepts important domain.1. Introductionlarge amount data collected today quickly overwhelming researchers' abilitiesinterpret data discover interesting patterns within data. responseproblem, number researchers developed techniques discovering conceptsdatabases. techniques work well data expressed non-structural, attributevalue representation, address issues data relevance, missing data, noise uncertainty, utilization domain knowledge. However, recent data acquisition projectscollecting structural data describing relationships among data objects. Correspondingly, exists need techniques analyze discover concepts structuraldatabases.One method discovering knowledge structural data identification common substructures within data. motivation process find substructurescapable compressing data identify conceptually interesting substructuresenhance interpretation data. Substructure discovery process identifyingconcepts describing interesting repetitive substructures within structural data.discovered, substructure concept used simplify data replacing instancessubstructure pointer newly discovered concept. discovered substructure concepts allow abstraction detailed structure original data providec 1994 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.fiCook & Holdernew, relevant attributes interpreting data. Iteration substructure discoveryreplacement process constructs hierarchical description structural data termsdiscovered substructures. hierarchy provides varying levels interpretationaccessed based goals data analysis.describe system called Subdue (Holder, Cook, & Bunke, 1992; Holder & Cook,1993) discovers interesting substructures structural data based minimumdescription length principle. Subdue system discovers substructures compressoriginal data represent structural concepts data. replacing previouslydiscovered substructures data, multiple passes Subdue produce hierarchical description structural regularities data. Subdue uses computationally-boundedinexact graph match identifies similar, identical, instances substructurefinds approximate measure closeness two substructures computationalconstraints. addition minimum description length principle, backgroundknowledge used Subdue guide search towards appropriate substructures.following sections describe approach detail. Section 2 describes processsubstructure discovery introduces needed definitions. Section 3 compares Subduediscovery system work found literature. Section 4 introduces minimumdescription length encoding used approach, Section 5 presents inexactgraph match algorithm employed Subdue. Section 6 describes methods incorporatingbackground knowledge substructure discovery process. experiments detailedSection 7 demonstrate Subdue's ability find substructures compress datare-discover known concepts variety domains. Section 8 details hierarchicaldiscovery process. conclude observations directions future research.2. Substructure Discoverysubstructure discovery system represents structured data labeled graph. Objectsdata map vertices small subgraphs graph, relationshipsobjects map directed undirected edges graph. substructure connectedsubgraph within graphical representation. graphical representation serves inputsubstructure discovery system. Figure 1 shows geometric example inputgraph. objects figure (e.g., T1, S1, R1) become labeled vertices graph,relationships (e.g., on(T1,S1), shape(C1,circle)) become labeled edges graph.graphical representation substructure discovered Subdue dataalso shown Figure 1.instance substructure input graph set vertices edgesinput graph match, graph theoretically, graphical representationsubstructure. example, instances substructure Figure 1 shownFigure 2.substructure discovery algorithm used Subdue computationally-constrainedbeam search. algorithm begins substructure matching single vertexgraph. iteration algorithm selects best substructure expandsinstances substructure one neighboring edge possible ways. new uniquegenerated substructures become candidates expansion. algorithm searches232fiSubstructure DiscoveryInput GraphSubstructureT1peS1triangleshC1R1T2T3S2S3T4pesquareshS4Figure 1: Example substructure graph form.Instance1Instance2Instance3InstanceT1T2T3T4S1S2S3S44Figure 2: Instances substructure.best substructure possible substructures considered totalamount computation exceeds given limit. evaluation substructure guidedMDL principle background knowledge provided user.Typically, description length expanding substructure begins increase,expansion substructure yield smaller description length.result, Subdue makes use optional pruning mechanism eliminates substructureexpansions consideration description lengths expansions increases.3. Related WorkSeveral approaches substructure discovery developed. Winston's Arch program (Winston, 1975) discovers substructures order deepen hierarchical descriptionscene group objects general concepts. Arch program searchestwo types substructure blocks-world domain. first type involves sequenceobjects connected chain similar relations. second type involves setobjects similar relationship \grouping" object. main differencesubstructure discovery procedures used Arch program SubdueArch program designed specifically blocks-world domain. instance,sequence discovery method looks supported-by in-front-of relations only.Subdue's substructure discovery method domain independent, although inclusiondomain-specific knowledge would improve Subdue's performance.Motivated need construct knowledge base chemical structures, Levinson(Levinson, 1984) developed system storing labeled graphs individual graphs233fiCook & Holderrepresented set vertices universal graph. addition, individual graphsmaintained partial ordering defined subgraph-of relation, improvesperformance graph comparisons. universal graph representation providesmethod compressing set graphs stored knowledge base. Subgraphsuniversal graph used several individual graphs suggest common substructureindividual graphs. One difference two approaches Levinson's systemdesigned incrementally process smaller individual graphs; whereas, Subdue processeslarger graphs once. Also, Levinson's system discovers common substructureindirect result universal graph construction; whereas, Subdue's main goaldiscover output substructure definitions reduce minimum descriptionlength encoding graph. Finally, subgraph-of partial ordering used Levinson'ssystem included Subdue, maintaining partial ordering would improveperformance graph matching procedure pruning number possible matchinggraphs.Segen (Segen, 1990) describes system storing graphs using probabilistic graphmodel represent subsets graph. Alternative models evaluated based minimum description length measure information needed represent stored graphsusing model. addition, Segen's system clusters graphs classes basedminimizing description length graphs according entire clustering. Apartprobabilistic representation, Segen's approach similar Levinson's systemmethods take advantage commonalities graphs assist graph storage matching. probabilistic graphs contain information identifying commonsubstructure exact graphs represent. portion probabilistic graphhigh probability defines substructure appears frequently exact graphs.notion emphasized Segen's work, provides alternative methodsubstructure discovery clustering subgraphs original input graphs. Levinson's approach, graphs processed incrementally, substructure found across severalgraphs, within single graph Subdue.Labyrinth system (Thompson & Langley, 1991) extends Cobweb incrementalconceptual clustering system (Fisher, 1987) handle structured objects. Labyrinth usesCobweb form hierarchical concepts individual objects domain basedprimitive attributes. Concepts structured objects formed similar mannerusing individual objects attributes. resulting hierarchy represents componentialmodel structured objects. Cobweb's concepts probabilistic, Labyrinthproduces probabilistic models structured objects, added hierarchicalorganization. upper-level components structured-object hierarchy producedLabyrinth represent substructures common examples. Therefore, althoughprimary focus, Labyrinth discovering substructure, constrained contextgeneral graph representation used Subdue.Conklin et al. (Conklin & Glasgow, 1992) developed i-mem system constructing image hierarchy, similar Labyrinth, used discovering commonsubstructures set images ecient retrieval images similar given image.Images expressed terms set relations defined user. Specific general(conceptual) images stored hierarchy based subsumption relation similar234fiSubstructure DiscoveryLevinson's subgraph-of partial ordering. Image matching utilizes transformationalapproach (similar Subdue's inexact graph match) measure image closeness.approaches Segen Levinson, i-mem designed process individualimages. Therefore, general image concepts appear higher i-mem's hierarchyrepresent common substructures across several images. Subdue designed discovercommon substructures within single image. Subdue mimic individual approachsystems processing set individual images one disconnected graph.substructures found common individual images. hierarchy also representscomponential view images. view constructed Subdue usingmultiple passes graph replacing portions input graph substructuresdiscovered previous passes. i-mem performed well simple chess domainmolecular chemistry domains (Conklin & Glasgow, 1992). However, i-mem requiresdomain-specific relations expressing images order hierarchy find relevantsubstructures image matching ecient. Again, maintaining concepts(images, graphs) partially-ordered hierarchy improves eciency matchingretrieval, suggests possible improvement Subdue.CLiP system (Yoshida, Motoda, & Indurkhya, 1993) graph-based inductionsimilar Subdue previous systems. CLiP iteratively discovers patternsgraphs expanding combining patterns discovered previous iterations. Patternsgrouped views based collective ability compress original inputgraph. iteration CLiP uses existing views contract input graphconsiders adding views new patterns consisting two vertices edgecontracted graph. compression new proposed views estimated,best views (according given beam width) retained next iteration.CLiP discovers substructures (patterns) differently Subdue. First, CLiP producesset substructures collectively compress input graph; whereas, Subdue producessingle substructures evaluated using principled minimum description length.CLiP ability grow substructures agglomeratively (i.e., merging two substructurestogether); whereas, Subdue always produces new substructures using incremental growthalong one new edge. CLiP initially estimates compression value new views basedcompression value parent view; whereas, Subdue performs expensive exactmeasurement compression new substructure. Finally, CLiP employs ecientgraph match based graph identity, graph isomorphism Subdue. Graph identityassumes ordering incident edges vertex consider possiblemappings looking occurrences pattern input graph. differencesCLiP suggest possible enhancements Subdue.Research pattern recognition begun investigate use graphs graphgrammars underlying representation structural problems (Schalkoff, 1992). Manyresults grammatical inference applicable constrained classes graphs (e.g., trees)(Fu, 1982; Miclet, 1986). approach begins set sample graphs producesgeneralized graph grammar capable deriving original sample graphs many others.production rules general grammar capture regularities (substructures)sample graphs. Jeltsch Kreowski (Jeltsch & Kreowski, 1991) describe approachbegins maximally-specific grammar iteratively identifies common subgraphsright-hand sides production rules. common subgraphs used form235fiCook & Holdernew, general production rules. Although method address underlyingcombinatorial nondeterminism, heuristic approaches could provide feasible methodextracting substructures form graph grammars. Furthermore, graph grammarproduction-rule may provide suitable representation background knowledgesubstructure discovery process.4. Minimum Description Length Encoding Graphsminimum description length principle (MDLP) introduced Rissanen (Rissanen,1989) states best theory describe set data theory minimizesdescription length entire data set. MDL principle used decisiontree induction (Quinlan & Rivest, 1989), image processing (Pednault, 1989; Pentland, 1989;Leclerc, 1989), concept learning relational data (Derthick, 1991), learning modelsnon-homogeneous engineering domains (Rao & Lu, 1992).demonstrate minimum description length principle used discoversubstructures complex data. particular, substructure evaluated based wellcompress entire dataset using minimum description length. defineminimum description length graph number bits necessary completelydescribe graph.According minimum description length (MDL) principle, theory bestaccounts collection data one minimizes (S ) + (GjS ),discovered substructure, G input graph, (S ) number bits required encodediscovered substructure, (GjS ) number bits required encode inputgraph G respect .graph connectivity represented adjacency matrix. Consider graphn vertices, numbered 0; 1; : : :; n , 1. n n adjacency matrixformed entry A[i; j ] set 0 1. A[i; j ] = 0, connectionvertex vertex j . A[i; j ] = 1, least one connection vertexvertex j . Undirected edges recorded one entry matrix. adjacencymatrix graph Figure 3 shown below.x 20 1 1 0 0 03triangle 66 0 0 0 0 0 0 77666 0 0 0 1 1 0 777square 66 0 0 0 0 0 0 77r 40 0 0 0 0 15rectangle 0 0 0 0 0 0encoding graph consists following steps. assume decodertable lu unique labels original graph G.1. Determine number bits vbits needed encode vertex labels graph.First, need (lg v ) bits encode number vertices v graph. Then,encoding labels v vertices requires (v lg lu ) bits. assume verticesspecified order appear adjacency matrix. total numberbits encode vertex labelsvbits = lg v + v lg lu236fiSubstructure DiscoverytriangleephaxpesquareshperectangleshrFigure 3: MDL example graph.example Figure 3, v = 6, assume lu = 8 uniquelabels original graph. number bits needed encode verticeslg 6 + 6 lg 8 = 20:58 bits.2. Determine number bits rbits needed encode rows adjacency matrixA. Typically, large graphs, single vertex edges small percentagevertices entire graph. Therefore, typical row adjacency matrixmuch fewer v 1s, v total number vertices graph.apply variant coding scheme used (Quinlan & Rivest, 1989) encode bitstrings length n consisting k 1s (n , k) 0s, k (n , k).case, row (1 v ) represented bit string length v containing ki1s. let b = maxi ki , ith row adjacency matrix encodedfollows.(a) Encoding value ki requires lg(b + 1) bits.(b) Given ki 1s occur row bit string length v , kvi strings0s 1sSince strings equal probabilitypossible.voccurrence, lg ki bits needed encode positions 1s row i.value v known vertex encoding.Finally, need additional lg(b + 1) bits encode number bits neededspecify value ki row. total encoding length bits adjacencymatrixrbits = lg(b + 1) +vXi=1= (v + 1) lg(b + 1)237lg(b + 1) + lg kvivXi=1lg kvifiCook & Holderexample Figure 3, b = 2,numberbitsneededencode666666adjacency matrix (7 lg 3)+lg 2 +lg 0 +lg 2 +lg 0 +lg 1 +lg 0 = 21:49bits.3. Determine number bits ebits needed encode edges representedentries A[i; j ] = 1 adjacency matrix A. number bits needed encodeentry A[i; j ] (lg m) + e(i; j )[1 + lg lu ], e(i; j ) actual number edgesvertex j graph = maxi;j e(i; j ). (lg m) bits neededencode number edges vertex j , [1 + lg lu ] bits neededper edge encode edge label whether edge directed undirected.addition encoding edges, need encode number bits (lg m) neededspecify number edges per entry. total encoding edgesebits = lg +v XvXi=1 j =1lg + e(i; j )[1 + lg lu ]= lg + e(1 + lg lu ) +v XvXi=1 j =1A[i; j ] lg= e(1 + lg lu ) + (K + 1) lge number edges graph, K number 1s adjacencymatrix A. example Figure 3, e = 5, K = 5, = 1, lu = 8, numberbits needed encode edges 5(1 + lg 8) + 6 lg 1 = 20.total encoding graph takes (vbits + rbits + ebits) bits. exampleFigure 3, value 62:07 bits.input graph discovered substructure encoded usingscheme. substructure discovered, instance substructure inputgraph replaced single vertex representing entire substructure. discoveredsubstructure represented (S ) bits, graph substructure replacementrepresented (GjS ) bits. Subdue searches substructure graph G minimizing(S ) + (GjS ).5. Inexact Graph MatchAlthough exact structure match used find many interesting substructures, manyinteresting substructures show slightly different form throughoutdata. differences may due noise distortion, may illustrate slightdifferences instances general class structures. Consider imageshown Figure 9. pencil cube would make ideal substructures picture,exact match algorithm may consider strong substructures,rarely occur form level detail throughout picture.Given input graph set defined substructures, want find subgraphsinput graph closely resemble given substructures. Furthermore, wantassociate distance measure pair graphs consisting given substructuresubgraph input graph. adopt approach inexact graph match givenBunke Allermann (Bunke & Allermann, 1983).238fiSubstructure Discoveryg1g2bBB1234bb5BFigure 4: Two similar graphs g1 g2 .inexact match approach, distortion graph assigned cost. distortiondescribed terms basic transformations deletion, insertion, substitutionvertices edges. distortion costs determined user bias matchparticular types distortions.inexact graph match two graphs g1 g2 maps g1 g2 g2interpreted distorted version g1. Formally, inexact graph match mappingf : N1 ! N2 [ fg, N1 N2 sets vertices g1 g2, respectively.vertex v 2 N1 mapped (i.e., f (v ) = ) deleted. is, correspondingvertex g2. Given set particular distortion costs discussed above, define costinexact graph match cost(f ), sum cost individual transformationsresulting f , define matchcost(g1 ; g2) value least-cost functionmaps graph g1 onto graph g2.Given g1 , g2, set distortion costs, actual computation matchcost(g1 ; g2)determined using tree search procedure. state search tree correspondspartial match maps subset vertices g1 subset vertices g2.Initially, start empty mapping root search tree. Expanding statecorresponds adding pair vertices, one g1 one g2, partial mappingconstructed far. final state search tree match maps vertices g1g2 . complete search tree example Figure 4 shown Figure 5.example assign value 1 distortion cost. numbers circlesfigure represent cost state. eventually interested mappingminimum cost, state search tree gets assigned cost partial mappingrepresents. Thus goal state found tree search procedurefinal state minimum cost among final states. Figure 5 concludeminimum cost inexact graph match g1 g2 given mapping f (1) = 4, f (2) = 3.cost mapping 4.Given graphs g1 n vertices g2 vertices, n, complexityfull inexact graph match O(nm+1 ). routine used heavily throughout239fiCook & Holder(1, 3) 1(1, 5) 1(1, 4) 0(1,)1(2,4) (2,5) (2, ) (2,3) (2,5) (2, ) (2,3) (2,4) (2, ) (2,3) (2,4) (2,5) (2, )76103697710910911Figure 5: Search tree computing matchcost(g1,g2) Figure 4.discovery evaluation process, complexity algorithm significantly degradeperformance system.improve performance inexact graph match algorithm, extend Bunke'sapproach applying branch-and-bound search tree. cost roottree given node computed described above. Nodes considered pairingsorder heavily connected vertex least connected, constrainsremaining match. branch-and-bound search guarantees optimal solution,search ends soon first complete mapping found.addition, user place limit number search nodes consideredbranch-and-bound procedure (defined function size input graphs).number nodes expanded search tree reaches defined limit, searchresorts hill climbing using cost mapping far measure choosingbest node given level. defining limit, significant speedup realizedexpense accuracy computed match cost.Another approach inexact graph match would encode differencetwo graphs using MDL principle. Smaller encodings would indicate lower match costtwo graphs. leave future research direction.6. Guiding Discovery Process Background KnowledgeAlthough principle minimum description length useful discovering substructures maximize compression data, scientists may realize benefitdiscovery substructures exhibit domain-specific domain-independent characteristics.make Subdue powerful across wide variety domains, addedability guide discovery process background knowledge. Although minimumdescription length principle still drives discovery process, background knowledgeused input bias toward certain types substructures. background knowledgeencoded form rules evaluating substructures, represent domainindependent domain-dependent rules. time substructure evaluated, input240fiSubstructure Discoveryrules used determine value substructure consideration.most-favored substructures kept expanded, rules bias discoveryprocess system.background rule assigned positive, zero, negative weight, biasesprocedure toward type substructure, eliminates use rule, biasesprocedure away type substructure, respectively. value substructuredefined description length (DL) input graph using substructure multiplied weighted value background rule set rules R appliedsubstructure.value(s) = DL(G; s)jRjr=1ruler (s)er(1)Three domain-independent heuristics incorporated rules Subdue system compactness, connectivity, coverage. definitions rules,let G represent input graph, represent substructure graph,represent set instances substructure G. instance weight winstance 2 substructure defined(i; s)(2)w(i; s) = 1 , matchcostsize(i) ;size(i) = #vertices(i) + #edges(i). match cost greater sizelarger graph, w(i; s) = 0. instance weights used rules computeweighted average instances substructure. value 1 added formulaexponential weights used control rule's significance.first rule, compactness, generalization Wertheimer's Factor Closure,states human attention drawn closed structures (Wertheimer, 1939). closedsubstructure least many edges vertices, whereas non-closed substructurefewer edges vertices (Prather, 1976). Thus, closed substructures highercompactness value. Compactness defined weighted average rationumber edges substructure number vertices substructure.compactness(s) = 1 + j1I jXi2Iedges(i)w(i; s) ##vertices(i)(3)second rule, connectivity, measures amount external connection instances substructure. connectivity rule variant Wertheimer's FactorProximity (Wertheimer, 1939), related earlier numerical clustering techniques(Zahn, 1971). works demonstrate human preference \isolated" substructures,is, substructures minimally related adjoining structure. Connectivity measures \isolation" substructure computing inverse average numberexternal connections weighted instances substructure input graph.external connection defined edge connects vertex substructurevertex outside substructure. formula determining connectivitysubstructure instances input graph G given below.241fiCook & Holder"connectivity(s) = 1 + 1XjI j i2I w(i; s) num external conns(i)#,1(4)third rule, coverage, measures fraction structure input graph describedsubstructure. coverage rule motivated research inductive learningprovides concept descriptions describing input examples considered better(Michalski & Stepp, 1983). Although MDL measures amount structure, coveragerule includes relevance savings respect size entire input graph.Coverage defined number unique vertices edges instancessubstructure divided total number vertices edges input graph.formula, unique structure(i) instance number vertices edgesalready appeared previous instances summation.coverage(s) = 1 +Pi2I w(i; s) uniquesize(G)structure(i)(5)Domain-dependent rules also used guide discovery process domainscientists contribute expertise. example, CAD circuits generally consisttwo types components, active passive components. active componentsmain driving components. Identifying active components first step understanding main function circuit. add knowledge Subdue includerule assigns higher values substructures (circuit components) representing activecomponents lower values substructures representing passive components. Sinceactive components higher scores, expected selected. systemfocus attention active components expanded functionalsubstructures.Another method biasing discovery process background knowledge letbackground rules affect prior probabilities possible substructures. However, choosingappropriate prior probabilities express desired properties substructures dicult, indicates future direction inclusion background knowledgesubstructure discovery process.7. Experimentsexperiments section evaluate Subdue's substructure discovery capabilityseveral domains, including chemical compound analysis, scene analysis, CAD circuit designanalysis, analysis artificially-generated structural database.Two goals substructure discovery system find substructures reduceamount information needed describe data, find substructuresconsidered interesting given database. result, evaluate Subdue systemsection along two criteria. First, measure amount compressionSubdue provides across variety databases. Second, use Subdue systemadditional background knowledge rules re-discover substructures identifiedinteresting experts specific domain. Section 7.1 describes domains usedexperiments, Section 7.2 presents experimental results.242fiSubstructure DiscoveryCH 2OHCH 3CH 3COHFigure 6: Cortisone.CH 3CCH2CH 3HCCCH2CHCH2CCH 32CH 3HCCCHCH22CHCH22CCCH 3HHCH2CCH2CHFigure 7: Natural rubber (all-cis polyisoprene).7.1 Domains7.1.1 Chemical Compound AnalysisChemical compounds rich structure. Identification common interestingsubstructures benefit scientists identifying recurring components, simplying datadescription, focusing substructures stand merit additional attention.Chemical compounds represented graphically mapping individual atoms,carbon oxygen, labeled vertices graph, mapping bondsatoms onto labeled edges graph. Figures 6, 7, 8 show graphs representingchemical compound databases cortisone, rubber, portion DNA molecule.7.1.2 Scene AnalysisImages scene descriptions provide rich source structure. Images humansencounter, natural synthesized, many structured subcomponents drawattention help us interpret data scene.Discovering common structures scenes useful computer vision system.First, automatic substructure discovery help system interpret image. Insteadworking low-level vertices edges, Subdue provide abstract structuredcomponents, resulting hierarchical view image machine analyzemany levels detail focus, depending goal analysis. Second, substructurediscovery makes use inexact graph match help identify objects 2D image3D scene noise orientation differences likely exist. object appears often scene, inexact graph match driving Subdue system may captureslightly different views object. Although object may dicult identify243fiCook & HolderCH2NadenineNNNNPHNOHNCH 3HPHONHNHNguanineNPCH2thymineCH2HNNNHOHNcytosineCH2CH 3HPHOCH2NthyminePNHNNNNCH 3HOHCH2adenineNHPHOFigure 8: Portion DNA molecule.Figure 9: Scene analysis example.244fiSubstructure DiscoveryfkxlpFigure 10: Possible vertices labels.llllllllllllllllllllfllFigure 11: Portion graph representing scene Figure 4.one 2D picture, Subdue match instances similar objects, differences instances provide additional information identification. Third,substructure discovery used compress image. Replacing common interestingsubstructures single vertex simplifies image description reduces amountstorage necessary represent image.apply Subdue image data, extract edge information imageconstruct graph representing scene. graph representation consists eight typesvertices two types arcs (edge space). vertex labels (f , a, l, t, k, x, p,m) follow Waltz labelings (Waltz, 1975) junctions edges image representtypes vertices shown Figure 10. edge arc represents edge objectimage, space arc links non-connecting objects together. edge arcs representedge scene connects two vertices, space arcs connect closest verticestwo disjoint neighboring objects. Distance, curve, angle informationincluded graph representation, added give additional informationscene. Figure 11 shows graph representation portion scene depictedFigure 9. figure, edge arcs solid space arcs dashed.245fiCook & HolderVCCext_pindraindraingaten_mosfetgatesourcesourceconnectdraindraingateconnectgaten_mosfetsourceext_pinGNDFigure 12: Amplifier circuit graph representation.7.1.3 CAD Circuit Analysisdomain, employ Subdue find circuit components CAD circuit data. Discovery substructures circuit data valuable tool engineer attemptingidentify common reusable parts circuit layout. Replacing individual componentscircuit description larger substructure descriptions also simplify representationcircuit.data circuit domain obtained National Semiconductor, consists set components making circuit output Cadence Design System.particular circuit used experiment portion analog-to-digital converter. Figure 12 presents circuit amplifier gives corresponding graphrepresentation.7.1.4 Artificial Domainfinal domain, artificially generate graphs evaluate Subdue's ability discoversubstructures capable compressing graph. Four substructures created varyingsizes randomly-selected vertices edges (see Figure 13). name substructureects number vertices edges graph representation. Next, substructures embedded larger graphs whose size 15 times size substructure.graphs vary across four parameters: number possible vertex edge labels (onetimes two times number labels used substructure), connectivitysubstructure (1 2 external connections), coverage instances (60% 80%),246fiSubstructure Discoverye1e2e3n4n1e1n3e2n2n4n3e3n2e3e6n7e3n5e1n2e4n5e6e3n1n6n3n1e9e3e5n3e2n3n1e2e3n1n7e8n2n4e6e1e7e8Figure 13: Four artificial substructures used evaluate Subdue.amount distortion instances (0, 1 2 distortions). yields total 96graphs (24 different substructure).7.2 Experimental Results7.2.1 Experiment 1: Data compressionfirst experiment, test Subdue's ability compress structural database. Usingbeam width 4 Subdue's pruning mechanism, applied discovery algorithmdatabases mentioned above. repeat experiment match thresholdsranging 0.0 1.0 increments 0.1. Table 1 shows description length (DL)original graph, description length best substructure discovered Subdue,graphvalue compression. Compression defined DLDLofofcompressedoriginal graph . Figure 14,shows actual discovered substructures first four datasets.seen Table 1, Subdue able reduce database slightlylarger 14 original size best case. average compression valuedomains (treating artificial graphs one value) 0.62. resultsexperiment demonstrate substructure discovered Subdue significantlyreduce amount data needed represent input graph. expect compressinggraph using combinations substructures hierarchies substructures realizeeven greater compression databases.247fiCook & HolderDatabaseDLoriginal Thresholdoptimal DLcompressed CompressionRubber371.780.195.200.26Cortisone355.030.3173.250.49DNA2427.931.02211.870.91Pencils1592.331.0769.180.48CAD { M14095.730.72148.80.52CAD { S1SegDec1860.140.71149.290.62CAD { S1DrvBlk12715.120.79070.210.71CAD { BlankSub8606.690.76204.740.72CAD { And2427.730.1324.520.76Artificial (avg. 96 graphs) 1636.250.0: : :1.01164.020.71Table 1: Graph compression results.CH 3HCH2CCCCCCHCH22(a)CC(b)Cl(c)(d)Figure 14: Best substructure (a) rubber database, (b) cortisone database, (c) DNAdatabase, (d) image database.248fiSubstructure DiscoveryFigure 15: Benzene ring discovered Subdue.7.2.2 Experiment 2: Re-discovery known substructures using backgroundknowledgeAnother way evaluating discovery process evaluate interestingnessdiscovered substructures. determination value change domaindomain. result, second set experiments test Subdue's ability discoversubstructures already labeled important experts domainsconsideration.chemical compound domain, chemists frequently describe compounds termsbuilding-block components heavily used. example, rubber compounddatabase shown Figure 7, compound made chain structureslabeled chemists isoprene units. Subdue's ability re-discover structureexemplified Figure 14a. substructure, discovered using MDL principleextra background knowledge, represents isoprene unit.Although Subdue able re-discover isoprene units without extra backgroundknowledge, substructure affording compression always interesting important substructure database. example, cortisone databasebenzene ring consists ring carbons discovered using MDLprinciple. However, additional background rules used increase chancefinding interesting substructures domains. case cortisone compound,know interesting structures exhibit characteristic closure. Therefore,give strong weight (8.0) compactness background rule use match threshold0.2 allow deviations benzene ring instances. resulting output, Subduefinds benzene ring shown Figure 15.way, use background rules find pencil substructureimage data. image Figure 9 viewed, substructure interestpencil various forms. However, substructure afforded compressionmake entire pencil. know pencils high degree closurecoverage, weights rules set 1.0. weights, Subdueable find pencil substructure shown Figure 16 tested match thresholds0.0 1.0.8. Hierarchical Concept Discoverysubstructure discovered, instance substructure input graphreplaced single vertex representing entire substructure. discovery procedurerepeated compressed data set, resulting new interesting substructures.newly-discovered substructures defined terms existing substructure concepts,substructure definitions form hierarchy substructure concepts.249fiCook & HolderlllFigure 16: Pencil substructure discovered Subdue.Hierarchical concept discovery also adds capability improve Subdue's performance. Subdue applied large input graph, complexity algorithmprevents consideration larger substructures. Using hierarchical concept discovery, Subdue first discover smaller substructures best compress data. Applyingcompression reduces graph manageable size, increasing chanceSubdue find larger substructures subsequent passes database.Subdue selects substructure, vertices comprise exact instancessubstructure replaced graph single vertex representing discoveredsubstructure. Edges connecting vertices outside instance vertices inside instanceconnect new vertex. Edges internal instance removed. discoveryprocess applied compressed data. hierarchical description conceptsparticularly desired, heavier weight given substructures utilize previouslydiscovered substructures. increased weight ects increased attention substructure. Figure 17 illustrates compressed rubber compound graph using substructureshown Figure 14a.demonstrate ability Subdue find hierarchy substructures, let system make multiple passes database represents portion DNA molecule.Figure 8 shows portion two chains double helix, using three pairs basesheld together hydrogen bonds. Figure 18 shows substructures found Subduethree passes data. Note that, third pass, Subdue linkedtogether instances substructure second pass find chains doublehelix.Although replacing portions input graph discovered substructures compresses data provides basis discovering hierarchical concepts data,substructure replacement procedure becomes complicated concepts inexactinstances discovered. inexact instances discovered concept replacedsingle vertex data, distortions graph (differences instancegraph substructure definition) must attached annotations vertex label.250fiSubstructure DiscoveryHighest-valued substructureCH 3H=1CCCHCH22Compressed graph using discovered substructureGS1=CHCHC2C2CHCH22CCH 3CHH3CCHS1S1CHH3=S11CCCHCH22CHCH22CCCH 3HH3CH2CHFigure 17: Compressed graph rubber compound data.251CCH2fiCook & HolderHighest-valued substructureFirst PassCH2S1 =Highest-valued substructureSecond PassS1CCH2S2 ==PPCH2Highest-valued substructureThird PassS2POHOH=S3 =CH2S2OHS2OHPOHCH2POHFigure 18: Hierarchical discovery DNA data.252fiSubstructure Discovery9. ConclusionsExtracting knowledge structural databases requires identification repetitive substructures data. Substructure discovery identifies interesting repetitive structurestructural data. substructures represent concepts found data meansreducing complexity representation abstracting instances substructure. shown minimum description length (MDL) principle usedperform substructure discovery variety domains. substructure discovery processalso guided background knowledge. use inexact graph match allowsdeviation instances substructure. substructure discovered, instancessubstructure replaced concept definition, affording compressiondata description providing basis discovering hierarchically-defined structures.Future work combine structural discovery discovery concepts using linearbased representation AutoClass (Cheeseman, Kelly, Self, Stutz, Taylor, & Freeman,1988). particular, use Subdue compress data fed AutoClass,let Subdue evaluate interesting structures classes generated AutoClass.addition, developing parallel implementation AutoClass / Subduesystem enable application substructure discovery larger structural databases.Acknowledgementsproject supported NASA grant NAS5-32337. authors would like thankMike Shay National Semiconductor providing circuit data. would also likethank Surnjani Djoko Tom Lai help project. Thanks alsoreviewers numerous insightful comments.ReferencesBunke, H., & Allermann, G. (1983). Inexact graph matching structural pattern recognition. Pattern Recognition Letters, 1 (4), 245{253.Cheeseman, P., Kelly, J., Self, M., Stutz, J., Taylor, W., & Freeman, D. (1988). Autoclass:bayesian classification system. Proceedings Fifth International WorkshopMachine Learning, pp. 54{64.Conklin, D., & Glasgow, J. (1992). Spatial analogy subsumption. ProceedingsNinth International Machine Learning Workshop, pp. 111{116.Derthick, M. (1991). minimal encoding approach feature discovery. ProceedingsNinth National Conference Artificial Intelligence, pp. 565{571.Fisher, D. H. (1987). Knowledge acquisition via incremental conceptual clustering. MachineLearning, 2 (2), 139{172.Fu, K. S. (1982). Syntactic Pattern Recognition Applications. Prentice-Hall.Holder, L. B., Cook, D. J., & Bunke, H. (1992). Fuzzy substructure discovery. ProceedingsNinth International Machine Learning Conference, pp. 218{223.253fiCook & HolderHolder, L. B., & Cook, D. J. (1993). Discovery inexact concepts structural data.IEEE Transactions Knowledge Data Engineering, 5 (6), 992{994.Jeltsch, E., & Kreowski, H. J. (1991). Grammatical inference based hyperedge replacement. Fourth International Workshop Graph Grammars ApplicationComputer Science, pp. 461{474.Leclerc, Y. G. (1989). Constructing simple stable descriptions image partitioning. International journal Computer Vision, 3 (1), 73{102.Levinson, R. (1984). self-organizing retrieval system graphs. ProceedingsSecond National Conference Artificial Intelligence, pp. 203{206.Michalski, R. S., & Stepp, R. E. (1983). Learning observation: Conceptual clustering.Michalski, R. S., Carbonell, J. G., & Mitchell, T. M. (Eds.), Machine Learning:Artificial Intelligence Approach, Vol. I, pp. 331{363. Tioga Publishing Company.Miclet, L. (1986). Structural Methods Pattern Recognition. Chapman Hall.Pednault, E. P. D. (1989). experiments applying inductive inference principlessurfa ce reconstruction. Proceedings International Joint ConferenceArtificial Intelligence, pp. 1603{1609.Pentland, A. (1989). Part segmentation object recognition. Neural Computation, 1,82{91.Prather, R. (1976). Discrete Mathemetical Structures Computer Science. HoughtonMin Company.Quinlan, J. R., & Rivest, R. L. (1989). Inferring decision trees using minimum description length principle. Information Computation, 80, 227{248.Rao, R. B., & Lu, S. C. (1992). Learning engineering models minimum description length principle. Proceedings Tenth National Conference ArtificialIntelligence, pp. 717{722.Rissanen, J. (1989). Stochastic Complexity Statistical Inquiry. World Scientific PublishingCompany.Schalkoff, R. J. (1992). Pattern Recognition: Statistical, Structural Neural Approaches.John Wiley & Sons.Segen, J. (1990). Graph clustering model learning data compression. ProceedingsSeventh International Machine Learning Workshop, pp. 93{101.Thompson, K., & Langley, P. (1991). Concept formation structured domains. Fisher,D. H., & Pazzani, M. (Eds.), Concept Formation: Knowledge Experience Unsupervised Learning, chap. 5. Morgan Kaufmann Publishers, Inc.Waltz, D. (1975). Understanding line drawings scenes shadows. Winston, P. H.(Ed.), Psychology Computer Vision. McGraw-Hill.254fiSubstructure DiscoveryWertheimer, M. (1939). Laws organization perceptual forms. Ellis, W. D. (Ed.),Sourcebook Gestalt Psychology, pp. 331{363. Harcourt, Brace Company.Winston, P. H. (1975). Learning structural descriptions examples. Winston, P. H.(Ed.), Psychology Computer Vision, pp. 157{210. McGraw-Hill.Yoshida, K., Motoda, H., & Indurkhya, N. (1993). Unifying learning methods coloreddigraphs. Proceedings Learning Knowledge Acquisition WorkshopIJCAI-93.Zahn, C. T. (1971). Graph-theoretical methods detecting describing gestalt clusters.IEEE Transactions Computers, 20 (1), 68{86.255fiJournal Artificial Intelligence Research 1 (1994) 139-158Submitted 9/93; published 1/94Teleo-Reactive Programs Agent ControlNils J. Nilssonnilsson@cs.stanford.eduRobotics Laboratory, Department Computer ScienceStanford University, Stanford, CA 94305 USAAbstractformalism presented computing organizing actions autonomous agentsdynamic environments. introduce notion teleo-reactive (T-R) programs whoseexecution entails construction circuitry continuous computation parameters conditions agent action based. addition continuous feedback,T-R programs support parameter binding recursion. primary differenceT-R programs many circuit-based systems circuitry T-R programscompact; constructed run time thus anticipatecontingencies might arise possible runs. addition, T-R programsintuitive easy write written form compatible automaticplanning learning methods. brie describe experimental applications T-Rprograms control simulated actual mobile robots.1. IntroductionAutonomous agents, mobile robots, typically operate dynamic uncertainenvironments. environments sensed imperfectly, effectsalways completely predictable, may subject changes agent'scontrol. Designing agents operate environments presented challengesstandard methods artificial intelligence, based explicit declarative representations reasoning processes. Prominent among alternative approachesso-called behavior-based, situated, animat methods (Brooks, 1986; Maes, 1989; Kaelbling & Rosenschein, 1990; Wilson, 1991), convert sensory inputs actionsmuch direct fashion AI systems based representation reasoning. Manyalternative approaches share control theory central notion continuousfeedback environment necessary component effective action.Perhaps relatively easier control theorists computer scientistsdeal continuous feedback control theorists accustomed thinkingcontrolling mechanisms composed analog electrical circuits physicalsystems rather automata discrete read-compute-write cycles. notionsgoal-seeking servo-mechanisms, homeostasis, feedback, filtering, stability|so essentialcontrol dynamic environments|were developed analog circuitry mind.Circuits, nature, continously responsive inputs.contrast, central ideas computer science, namely sequences, events,discrete actions, subroutines, seem odds notion continuous feedback.example, conventional programming one program calls another, callingprogram suspended called program returns control. feature awkwardapplications called program might encounter unexpected environmentalc 1994 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.fiNilssoncircumstances designed cope. cases, calling programregain control interrupts explicitly provided programmer.sure, attempts blend control theory computer science.example, work Ramadge Wonham (Ramadge & Wonham, 1989) discrete-eventsystems used computer science notions events, grammars, discrete statesstudy control processes ideas appropriate. book DeanWellman (Dean & Wellman, 1991) focusses overlap control theoryartificial intelligence. little effort import fundamental control-theoryideas computer science. precisely set paper.propose computational system works differently conventional ones.formalism call circuit semantics (Nilsson, 1992); program execution produces(at least conceptually) electrical circuits, circuits used control.importing control-theory concept continuous feedback, nevertheless wantretain useful ideas computer science. control programs parametersbound run time passed subordinate routines. hierarchicalorganization, recursive. contrast behavior-basedapproaches, want programs responsive stored models environmentwell immediate sensory inputs.presentation ideas somewhat informal line beliefformalization best done certain amount experience obtained. Althoughpreliminary experiments indicate formalism works quite well, work remainsdone establish place agent control.2. Teleo-Reactive Sequences2.1 Condition-Action Rulesteleo-reactive (T-R) sequence agent control program directs agent towardgoal (hence teleo) manner takes account changing environmental circumstances(hence reactive). simplest form, consists ordered set production rules:K1K2!!a1a2111Ki!ai111Km!Ki conditions (on sensory inputs model world), aiactions (on world change model). T-R sequence interpretedmanner roughly similar way production systems interpreted.list rules scanned top first rule whose condition part satisfied,corresponding action executed. T-R sequences differ substantively conventionalproduction systems, however. T-R actions durative rather discrete. durative140fiTeleo-Reactive Programsaction one continues indefinitely. example, mobile robot capable executingdurative action move, propels robot ahead (say constant speed) indefinitely.action contrasts discrete one, move forward one meter. T-Rsequence, durative action continues long corresponding condition remains firsttrue condition. first true condition changes, action changes correspondingly.Thus, unlike production systems computer science, conditions must continuouslyevaluated; action associated currently first true condition always oneexecuted. action terminates energizing condition ceasesfirst true condition.Indeed, rather thinking T-R sequences terms computer science ideadiscrete events, appropriate think implemented circuitry.example, sequence implemented circuit shown figure 1.Furthermore, imagine conditions, Ki , also continuously computed.sensorsmodelconditioncomputingcircuitsK1a1^K2a2K3^a3^KmFigure 1: Implementing T-R Sequence Circuitryactions, ai , T-R sequence either primitive actions, T-Rsequences themselves. Thus, programs written formalism hierarchical (evenrecursive, shall see later). case hierarchical programs, importantrealize conditions levels hierarchy continuously evaluated;high level sequence redirect control different path lower level sequencesdictated values conditions various levels.141fiNilssonwriting T-R sequence, programmer ordinarily works backward whatever goalcondition sequence designed achieve. condition K1 takengoal condition, corresponding action, a1, null action. condition K2weakest condition satisfied (and K1 not), durative executiona2 (all things equal) eventually achieve K1 . on. non-nullaction, ai , supposed achieve condition, Kj , strictly higher list (j < i).conditions therefore regressions (Nilsson, 1980) higher conditions actionsachieve higher conditions.Formally, say T-R sequence satisfies regression property condition,> 1), regression higher condition sequence, Kj (j < i),action ai . say T-R sequence complete K1 _ 1 1 1 _ Ki _1 1 1 _ Km tautology. T-R sequence universal satisfies regression propertycomplete. easy see universal T-R sequence always achieve goalcondition, K1 , sensing execution errors.Ki (mSometimes action effect anticipated agent's designer(the normal effect), sometimes exogenous events (separate actionsagent) change world unexpected ways. phenomena, course, reasoncontinuous feedback required. Universal T-R sequences, like universal plans (Schoppers,1987), robust face occasional deviations normal execution.also exploit serendipitous effects; may accidentally happen action achievescondition higher list condition/action rules normally expected. Evenaction sometimes achieve normal effect (due occasional sensing executionerrors), nevertheless action executed. long environmentoften frustrate achievement normal effects actions, goal conditionuniversal T-R sequence ultimately achieved.2.2 Examplefollowing rather simple example make ideas concrete. Considersimulated robots figure 2. Let's suppose robots move bars aroundtwo-dimensional world. robot right holding bar, wantrobot go grab bar marked A. presume robot senseenvironment evaluate conditions tell whether already grabbingbar (is-grabbing), facing toward bar (facing-bar), positioned respect barreach grab (at-bar-center), perpendicular bisector bar(on-bar-midline), facing zone perpendicular bisector barwould appropriate move toward bar (facing-midline-zone). Let's assume alsoconditions appropriate amount hysteresis hunting behaviordampened. Suppose robot capable executing primitive actions grab-bar, move,rotate obvious effects. Execution following T-R sequence resultrobot grabbing bar A:142fibar-midlinebar-centermidline-zoneFigure 2: Robots BarsNotice properly executed action sequence achieves conditionrule it. way, actions inexorably proceed toward goal. Occasionalsetbacks merely cause delays achieving goal long actions usually1 achievenormal effects.3. Teleo-Reactive Programs3.1 Rules Variablesgeneralize notion T-R sequence permitting rules contain freevariables bound sequence \called." call sequence T-Rprogram. Additional generality obtained assume variables necessarilybound constants quantities whose values continuously computed (ascircuitry) environment changes.simple example involving robot go designated goal location twodimensions serve illustrate. Suppose goal location given valuevariable loc. run time, loc bound pair X; coordinates, although allowbinding change run time. time process, robot's X;position given value variable position. (We assume robotkind navigational aid reliably continuously computes value position.)instantaneous values loc position, robot compute direction1. choose define usually precisely here, although probabilistic analysis could given.143fiNilssonface proceed straight line toward loc. Let value directiontime given value function course(position, loc). timeprocess, robot's angular heading given value variable heading. Usingvariables, T-R program drive robot loc is:goto(loc)equal(position, loc)equal(heading, course(position, loc))!!!nilmoverotateImplementing goto(loc) circuitry straightforward. single parameterprogram loc whose (possibly changing) value specified run time user,higher level program, circuitry. (global) parameters, position heading,provided circuitry, assume function course continuouslycomputed circuitry. Given values parameters, computing actionenergize computed circuitry manner figure 1.3.2 Hierarchical Programsformalism allows writing hierarchical recursive programs actionsrules T-R programs. example, write recursive navigationprogram calls goto. new navigation program requires complex sensoryfunctions. Imagine function clear-path(place1, place2) valuedirect path clear place1 place2. (We assume robot computefunction, continuously, place1 = position, place2 equal target location.)Also imagine function new-point(place1, place2) computes intermediate positionplace1 place2 whenever clear-path value . value newpoint lies appropriately side obstacle determined place1place2 (so robot heads toward new-point first toward place2,navigate around obstacle). clear-path new-point continuously computedperceptual systems endow robot. We'll name new navigationprogram amble(loc). code:amble(loc)equal(position, loc)clear-path(position, loc)!!!nilgoto(loc)amble(new-point(position, loc))show figure 3 path robot controlled program might takenavigating around obstacles shown. (The program doesn't necessarily compute shortestpaths; present program simply illustration recursion.) Noteobstacle positions goal location change execution, changes ectedvalues parameters used program, program execution proceedmanner appropriate changes. particular, clear path ever becomes manifest144figoal locationFigure 3: Navigating using amblecontinuous computation parameters involved T-R programs abilityhigh level programs redirect control account great robustness formalism.formal syntax T-R programs given (Nilsson, 1992).3.3 Implementational IssuesT-R formalism, implicit assumption continuous computation conditionsparameters, thought fully legitimate \level" hierarchy programstructure controlling agent, regardless level implemented levels below|computer scientists think list processing level actual operation even thoughimplemented primitive logical operations below. assume (as do)pace events agent's environment slow compared amount timetaken perform \continuous" computations required T-R program, T-Rprogrammer justified assuming \real" continuous sensing s/he writes programs (eventhough underlying implentation may involve discrete sampling). recommendT-R formalism applications assumption justified.applications, T-R level shields programmer worrylevel implemented greatly facilitates program construction.several different ways T-R programs interpreted lowerlevel implementations. beyond scope paper pointobvious methods, leave important questions properties methodssubsequent research. One method implementation involves construction actualsimulated circuits according basic scheme figure 1. First, top level conditioncomputing circuits (including circuits computing parameters used conditions)constructed allowed function. specific action, say ai , energized result. ai145fiNilssonprimitive, turned on, keeping circuitry place functioningtop-level action energized, on. ai T-R sequence, circuitry neededimplement constructed (just done top level), action selected,on|and levels circuitry left functioning. new lower levelcircuitry constructed, circuitry longer functioning (that is, circuitry longer\called" functioning higher level circuitry) garbage collected.important questions parameter passing timing processdeal here|relying assumption times needed create circuitry circuitry function negligible compared pace eventsworld. assumption similar synchrony hypothesis ESTEREL programming language (Berry & Gonthier, 1992) assumed program's reaction \. . .takes time respect external environment, remains invariant [thereaction]."Although reason principle circuitry could simulated actuallyconstructed (using sort programmable network logic gates), also straightforward implement T-R program using standard computational techniques. T-Rprograms written LISP cond statements, durative actions simulatediterating short action increments. example, increment move actionsimulated robot might move robot ahead small amount. actionincrement, top level LISP cond executed anew, course functionsparameters contains evaluated anew. simulations robots movingtwo-dimensional worlds (to discussed below), computations involved sucientlyfast effect reasonable pace apparent smooth motion.implementation method essentially involves sampling environment irregularintervals. course, questions concerning computation times (and thussampling rate) affect real-time aspects agent behavior addresshere|again assuming sampling rate short.Whatever method used interpret T-R programs, care must taken con ateT-R level levels below. programmer ought thinkcircuit simulators sampling intervals imagine sensing done continuouslyimmediately.3.4 Graphical Representationsgoto program represented graph well list rules used earlier.graphical representation program shown figure 4. nodes labeledconditions, arcs actions. execute graphical version program,look shallowest true node (taking goal condition root) executeaction labeling arc leading node.graph figure 4, action normally achieves condition head arc(when condition tail arc shallowest true condition).one action achieve condition, would tree instead single-pathgraph. general graph, then, teleo-reactive tree depicted figure 5.T-R trees executed searching shallowest true node executing actionlabeling arc leaving node. Alternatively, could search true node judged146fiTeleo-Reactive Programsequal(position, loc)moveequal(heading, course(position, loc))rotateFigure 4: Graphical Representation gotopath least cost goal, appropriate heuristic measure costused. [For simplicity, phrase \shallowest true node" taken mean eithershallowest true node (literally) true node path least cost goal.] Tiesamong several equally shallow true nodes broken according fixed tie-breaking rule.figure 5 see that, particular, least two ways achieve condition K1 .One way uses action a2 (when K2 shallowest true node), one way uses action a3(when K3 shallowest true node).analogy definitions given T-R sequences, T-R tree satisfies regressionproperty every non-root node regression parent node action linkingparent. T-R tree complete disjunction conditionstautology. T-R tree universal satisfies regression propertyalso complete. fixed tie-breaking rule, T-R tree becomes T-R sequence.T-R tree universal, corresponding T-R sequence.One might first object method executing T-R tree groundssequence actions emerge hop erratically one path another.tree satisfies regression property, heuristic measuring costgoal reasonable, (however erratic actions may appear be), successfullyexecuted action brings agent closer goal.4. Experimentscarried several preliminary experiments agents programmed language (using LISP cond statements short action increments). One set experimentsuses simulated robots acting two-dimensional space, called Botworld 2, construction2. original Botworld interface, including primitive perceptual functions actions robots,designed implemented Jonas Karlsson NeXT computer system (Karlsson, 1990). Sub-147fiNilssonK1a2a3K2K3Km -1KmFigure 5: T-R Treematerials, structures made materials, robots. construction materials bars, robots build structures connecting bars various ways.robot turn move, grab release suitably adjacent bar, turn movegrabbed bar, connect bar bars structures. robots continuouslysense whether holding bar, \see" front (givinginformation location bars structures). existencerobots may change world sometimes unexpected ways, importantrobot sense certain critical aspects environment continuously.typical Botworld graphical display shown figure 6.written various T-R programs cause robots build structuresvarious kinds (like triangle constructed figure 6). robot controlled oneprograms exhibits homeostatic behavior. long main goal (whatever is)satisfied, robot inactive. Whenever goal (for whatever reason) satisfied,robot becomes active persists achieves goal. another agent achievespart goal, robot carries appropriately situation findscomplete process.experiments, conditions used T-R rules conditions modelenvironment robot constructs sensory system maintains separatelyT-R mechanism. use model permits robot perform actionsresponse sensory stimuli (past present) used help constructmodel. But, T-R actions include direct changes model (in additionsequently, Patrick Teo implemented version runs X-windows several different workstations (Teo, 1991, 1992). latter version allows simulation several robots simultaneously|control independently running process.148fiTeleo-Reactive ProgramsFigure 6: Botworld Displaychanges resulting perceived changes environment), potentialundesirable instabilities (as system positive feedback). (The problemmodel environment model updated response sensorydata separate major research problem outside scope work reported here.)experiments, used Nomadic Technologies 100 series mobile robot.robot equipped ring 16 infrared sensors ring 16 sonar sensors.controlled via radio modem Macintosh II running Allegro Common Lisp.implemented robust T-R programs simple oce-environment tasks,wall-following corridor-following (Galles, 1993). programs initially developeddebugged using Nomadics simulator actual robot; changesmade porting programs simulator robot. performing tasks,robot highly reactive persistent even face occasional extreme sonarinfrared range errors deliberate attempts confuse it. robot quickly adaptssudden changes environment, caused people sharing hallways.writing T-R programs, one need concerned inventing appropriatepredicates using available perceptual functions model database. One needworry providing interrupts lower level programs higher level ones regaincontrol. found debugging T-R programs presents challenges, though.Since designed quite robust face environmental uncertainty,also sometimes work rather well even though completely debugged.residual errors might undesirable effects programs used higherlevel programs|making higher ones dicult debug.149fiNilsson5. Approaches Specifying Behaviorseveral formalisms proposed prescribing sensory-directed, real-timeactivity dynamic environments. closely related T-R formalismproposed here. section point major similarities differences T-Rprograms representative, though complete, sample closest relatives.reactive formalisms two types, namely, sample environmentsdiscrete intervals (perhaps rapidly enough suciently reactive),create circuitry (like T-R programs). discrete-sampling systems abstractactivity higher level environment monitored continuously,circuitry-creating systems prior run time (unlike T-R programs createcircuitry run time).5.1 Discrete-Sampling Systems5.1.1 Production Systemsalready mentioned, T-R programs similar production systems (Waterman & Hayes-Roth, 1978). intermediate-level actions (ILAs) used SRI robotShakey (Nilsson, 1984) programmed using production rules much likeT-R programs. T-R program also resembles plan represented triangle-table formconstructed STRIPS (Fikes, Hart & Nilsson, 1972). conditions T-Rsequence corresponds triangle table kernel. PLANEX execution system triangle tables, action corresponding highest-numbered satisfied kernel executed.major difference previous production-system style programs TR programs T-R programs continuously responsive environmentordinary production systems not.5.1.2 Reactive PlansSeveral researchers adopted approach using current situation indexset pre-arranged action sequences (Georgeff & Lansky, 1987; Schoppers, 1987; Firby,1987). set either large enough cover substantial number situationsagent likely find cover possible situations. lattercase, plan set said universal. Unlike T-R programs, systems explicitlysample environments discrete time steps rather continuously. T-Rprograms, time-space trade-offs must taken account considering manydifferent conditions must anticipated providing reactive plans. Ginsberg notedseveral domains, number situations likely encountered agentintractably large agent forced postpone planning run timesituations actually encountered (Ginsberg, 1989). (For discussionpoint, see (Selman, 1993).) T-R programs advantage least rudimentaryform planning, namely parameter binding, done run time. PRS system (Georgeff& Lansky, 1987) capable extensive planning run time well reactingappropriately current situation.150fiTeleo-Reactive Programs5.1.3 Situated Control RulesDrummond (Drummond, 1989) introduces notion plan net kind Petrinet (Reisig, 1985) representing effects actions (which executed parallel).Taking account possible interactions actions, projects effectspossible actions present state horizon. effects representedstructure called plan projection. plan projection analyzed see, stateit, states possibly path goal state. analysis forward versionbackward analysis used programmer producing T-R tree. Situated controlrules result analysis; constrain actions might takenstate result state still possibly path goal. Plannets Petri nets based discrete events thus continuously responsiveenvironments way T-R programs are.5.2 Circuit-Based SystemsKaelbling proposed formalism called GAPPS (Kaelbling, 1988; Kaelbling & Rosenschein, 1990), involving goal reduction rules, implicitly describing achieve goals.GAPPS programmer defines activity agent providing sucient goal reduction rules connect agent's goals situations might find itself.rules compiled circuitry real-time control agent. RosenscheinKaelbling (Rosenschein & Kaelbling, 1986) call circuitry situated automata.collection GAPPS rules achieving goal thought implicitspecification T-R program computations needed construct programperformed rules compiled. GAPPS programmer typically exerts lessspecific control agent's activity|leaving work search processperformed GAPPS compiler. example, T-R program achieve goal, p ,implicitly specified following GAPPS rule:(defgoalr (ach ?p)(if ((holds ?p) (do nil))((holds (regress ?a ?p)) (do ?a))(T ach (regress ?a ?p)) ))recursion defined rule bottoms rules form:(defgoalr (ach )((holds) (doff)) )conditions ff specific action.GAPPS compiles rules circuitry run time, whereas circuit implementation T-R program depends parameters bound run time. systemsresult control continuously responsive environment.implementing system play video game, Chapman (Chapman, 1990) compilesproduction-like rules digital circuitry real-time control using approachcalls \arbitration macrology." situated automata, compilation process occursprior run time.Brooks developed behavior language, BL, (Brooks, 1989), writing reactiverobot control programs based \subsumption architecture" (Brooks, 1986). similarlanguage, ALFA, implemented Gat (Gat, 1991). Programs written151fiNilssonlanguages compile structures much like circuits. Again, compilation occurs priorrun time. relatively straightforward translate examples subsumptionarchitecture programs T-R programs.circuit-based systems, pre-run-time compiling means circuitrymust built might needed given run possible contingenciesmust anticipated compile time.3 T-R programs, parameters bound runtime, circuitry required specific bindings constructed.6. Future WorkT-R formalism might easily augmented embody featuresdiscussed paper. Explicit reference time specifying actions might necessary.example, might want make sure action initiatedtime t1 ceases time t2. Time predicates, whose time terms evaluatedusing internal clock, may suce purpose.Also, applications may want control conditions T-R programactually tested. may be, example, conditions won't checkedtruth falsity guessed compelling accuracy.Simultaneous asynchronous execution multiple actions achieved allowing right-hand side rules contain sets actions. member setduratively executed asynchronously independently (so long conditionrule sustains set remains highest true condition). course, programmermust decide conditions appropriate call parallel actions. Futurework related formalisms might reveal ways parallel actions might emergeinteraction program environment rather explicitlyprogrammed.Although intend T-R programs agent control written human programmers, also interested methods modifying automatic planningmachine learning. brie discuss preliminary ideas planninglearning here.T-R trees resemble search trees constructed planning systems workbackwards goal condition. overall goal root tree; non-rootnode gi regression parent node, gj action, ak , connecting them.similarity suggests T-R trees constructed (and modified) automaticplanning system capable regressing conditions durative actions. Indeed triangletables (Fikes, Hart & Nilsson, 1972), degenerate form T-R tree consistingsingle path, constructed automatic planning system EBL-style generalizer(Mitchell, Keller & Kedar-Cabelli, 1986).reader might object reason suppose search trees produced automatic planning process contain nodes whose conditionsagent likely encounter behavior. process incremental modification, however, gradually make constructed trees matched agent'senvironment. tree achieving desired goal true nodes certain situation,3. Agre's \running arguments" construct (Agre, 1989) one example circuit-based systemadd circuitry run time needed.152fiTeleo-Reactive Programssearch process employed automatic planner yet terminatedsubgoal search tree satisfied current state. case,planning system called upon continue search; is, existing T-R treeexpanded true node produced. Pruning T-R trees accomplishedkeeping statistics often nodes satisfied. Portions trees neverseldom used erased. Early unpublished work Scott Benson indicates T-Rprograms effectively generated automatic planning methods (Benson, 1993).considering learning mechanisms, note first T-R sequences relatedclass Boolean functions Rivest termed k-decision lists (Rivest, 1987; Kohavi &Benson, 1993). k-decision list ordered list condition-value pairscondition conjunction Boolean variables length k, value truthvalue (T F ). value Boolean function represented k-decision listvalue associated highest true condition. Rivest shown functionspolynomially PAC learnable presented supervised learning procedure them.see T-R sequence whose conditions limited k-length conjunctionsBoolean features slight generalization k-decision lists. differenceT-R sequence two different \values" (that is, actions).observe T-R sequence (with, say, n different actions) also PAC learnablesince actions encoded log2 n decision lists. George John (John, 1993)investigated supervised learning mechanism learning T-R sequences.Typically, conditions used T-R programs conjunctions propositional features robot's world and/or model. linear threshold function implementconjunctions, one led propose neural net implementation T-R sequence. neural net implementation, turn, evokes ideas possible learning mechanisms. ConsiderT-R sequence:K1K2!!a1a2111Ki!ai111Km!Suppose stipulate Ki linear threshold functions set propositionalfeatures. ai necessarily distinct; fact assumek distinct actions. Let denoted b1; 1 1 1 ; bk . network structure figure7 implements T-R sequence.propositional features tested conditions grouped n-dimensionalbinary (0,1) vector, X called input vector. conditions implementedthreshold elements weighted connections components input vector.process finding first true condition implemented layer containing appropriateinhibitory weights units one unit ever outputvalue 1, unit corresponds first true condition. unique action associatedcondition layer binary-valued weights OR-unit associators.153fiNilssoninhibitory weights1 0 weightsXK1Vb1K2Vb2......biVKi......Kminputvector......bkVunitsconditionsassociatorsactions(ORunits)Figure 7: Neural Net Implements T-R Sequenceunit connected one one associator non-zero weight. Sinceone unit non-zero output, unit's associator non-zerooutput. (But associator could connected multiple units.) example,action bi associated conditions Kj Kl , unit weightsj-th l-th units associator representing action bi zero-valued weightsunits associator. action selected execution actioncorresponding single associator non-zero output. investigatingvarious learning methods suggested neural net implementation.Work must also done question constitutes goal. assumedgoals achievement. mechanisms found continously avoid making certainconditions true (or false) attempting achieve others? suppose prioritiesnumber possibly mutually contradictory conditions specified; reasonablemethods attending achievable goals highest priorities?Also, interesting ask sense T-R programs proved correct.would seem verification would make assumptions dynamicsenvironment; environments might malevolent agents could neverachieve goals. Even so, verifier equipped model effects actions couldleast check see regression property satisfied note lapses.work remains methods implementing interpreting T-R programsreal-time properties implementations. properties will, course, dependdepth T-R program hierarchy conditions features mustevaluated.154fiTeleo-Reactive ProgramsFinally, might worthwhile investigate \fuzzy" versions T-R trees. One couldimagine fuzzy predicates would energize actions \strength" dependsdegree predicates true. SRI robot, Flakey, uses fuzzy controller(Saotti, Ruspini & Konolige, 1993).7. Conclusionspresented formalism specifying actions dynamic uncertain domains. Sincework rests ideas somewhat different conventional computer science,expect considerably analysis experimentation required T-Rformalism fully evaluated. need robotics control-theoretic ideashomeostasis, continuous feedback, stability appears suciently strong, however,seems appropriate candidate formalisms embodying ideas put forwardconsideration.Experiments language produce stock advice write T-Rprograms effectively. Already, example, apparent sustaining conditionT-R sequence must carefully specified restrictive really needsbe; overly restrictive condition likely rendered false actionsupposed sustain action succeeds making higher conditionsequence true. But, course, overly restrictive conditions won't occur T-R programssatisfy regression property.usefully employed, T-R programs (or programs controlling agent action)need embodied overall agent architecture integrates perceptual processing,goal selection, action computation, environmental modeling, planning learningmechanisms. Several architectural schemes suggested, summarizeexcept say three layers control often delineated. typical exampleSSS architecture Connell (Connell, 1993). top (Symbolic) layer overallgoal setting sequencing, middle (Subsumption) level selects specific actions,lower (Servo) level exerts standard feedback control effectors. believe T-Rprograms would appropriately used middle level architectures.major limitation T-R programs involve much computationprograms check relevant conditions. conditions computedT-R program selecting action either irrelevant situation handvalues might accurately predicted (if programmer wanted take troubleso). essentially trading computing time ease programming,particular trade advantageous certain applications. Among these, think,mid-level control robots (possibly) software agents.conclusion, three main features embodied T-R formalism. Onecontinuous computation parameters conditions action based. TR programs allow continuous feedback still supporting parameter bindingrecursion. second feature regression relationship conditions T-Rprogram. condition regression condition closer goalaction normally achieves closer-to-the-goal condition. regression propertyassures robust goal-seeking behavior. Third, conceptual circuitry controlling actionconstructed run time, feature permits programs universal still155fiNilssoncompact. addition, T-R programs intuitive easy write writtenformalism compatible automatic planning learning methods.Acknowledgementstrace interest reactive, yet purposive, systems early collaborative worktriangle tables ILAs. Several former Stanford students, including Jonas Karlsson, EricLy, Rebecca Moore, Mark Torrance, helped early stages work. alsowant thank sabbatical hosts, Prof. Rodney Brooks MIT, Prof. Barbara GroszHarvard, people Santa Fe Institute. recently, benefitteddiscussions Scott Benson, George John, Ron Kohavi. also thank anonymousreferees helpful suggestions. work performed NASA Grant NCC2494 NSF Grant IRI-9116399.ReferencesAgre, P. (1989). Dynamic Structure Everyday Life. Tech. rep. TR 1085, AI Lab.,Massachusetts Institute Technology.Benson, S. (1993). Unpublished working paper. Robotics Laboratory, Stanford University.Berry, G., & Gonthier, G. (1992). ESTEREL Synchronous Programming Language.Science Computer Programming, 19, no. 2, 87-152, November.Brooks, R. (1986). Robust Layered Control System Mobile Robot. IEEE JournalRobotics Automation, March.Brooks, R. (1989). Behavior Language User's Guide. Seymour Implementation Note 2,AI Lab., Massachusetts Institute Technology.Chapman, D. (1990). Vision, Instruction Action. Tech. rep. 1204, AI Lab., Massachusetts Institute Technology.Connell, J. (1993). SSS: Hybrid Architecture Applied Robot Navigation. ResearchReport, IBM Research Division, T. J. Watson Research Center, Yorktown Heights,NY 10598.Dean, T., & Wellman, M. (1991). Planning Control. San Francisco, CA: Morgan Kaufmann.Drummond, M. (1989). Situated Control Rules. Proc. First International Conf. Principles Knowledge Representation Reasoning. San Francisco, CA: Morgan Kaufmann.Fikes, R., Hart, P., & Nilsson, N. (1972). Learning Executing Generalized Robot Plans.Artificial Intelligence, 3, 251-288.Firby, R. (1987). Investigation Reactive Planning Complex Domains. Proc.AAAI-87. San Francisco, CA: Morgan Kaufmann.156fiTeleo-Reactive ProgramsGalles, D. (1993). Map Building Following Using Teleo-Reactive Trees. IntelligentAutonomous Systems: IAS-3, Groen, F. C. A., Hirose, S. & Thorpe, C. E. (Eds.),390-398. Washington: IOS Press.Gat, E. (1991). ALFA: Language Programming Reactive Robotic Control Systems.Proceedings 1991 IEEE Robotics Automation Conference.Georgeff, M., & Lansky, A. (1989). Reactive Reasoning Planning. Proc. AAAI-87.San Francisco, CA: Morgan Kaufmann.Ginsberg, M. L. (1989). Universal Planning: (Almost) Universally Bad Idea. AAAIMagazine, 10, no. 4, 40-44, Winter.John, G. (1993). `SQUISH: Preprocessing Method Supervised Learning T-R TreesSolution Paths, (unpublished). Robotics Laboratory, Stanford University.Kaelbling, L. P. (1988). Goals Parallel Program Specifications. Proceedings AAAI-88,60-65. Menlo Park, CA: American Association Artificial Intelligence.Kaelbling, L. P., & Rosenschein, S. J. (1990). Action Planning Embedded Agents.Robotics Autonomous Systems, 6, nos. 1 2, 35-48, June.Karlsson, J. (1990). Building Triangle Using Action Nets. Unpublished project paper.Computer Science Dept., Stanford University. June.Kohavi, R., & Benson, S. (1993). Research Note Decision Lists. Machine Learning, 13,131-134.Maes, P. (1989). Right Thing. Connection Science, 1, no.3, 291-323.Mitchell, T. M., Keller, R. M., & Kedar-Cabelli, S. T. (1986). Explanation-based Generalization: Unifying View. Machine Learning, 1, 47-80.Nilsson, N. J. (1980). Principles Artificial Intelligence. San Francisco, CA: Morgan Kaufmann.Nilsson, N. (Ed.) (1984). Shakey Robot. Tech. Note 323, Artificial Intelligence Center,SRI International, Menlo Park, CA 94025.Nilsson, N. (1992). Toward Agent Programs Circuit Semantics. Tech. rep. STAN-CS92-1412, Department Computer Science, Stanford University.Ramadge, P. J. G., & Wonham, W. M. (1989). Control Discrete Event Systems.Proceedings IEEE, 77, no. 1, 81-98, January.Reisig, W. (1985). Petri Nets: Introduction, Springer Verlag.Rivest, R. L. (1987). Learning Decision Lists. Machine Learning, 2, 229-246.157fiNilssonRosenschein, S. J. & Kaelbling, L.P. (1986). Synthesis Machines ProvableEpistemic Properties. Proceedings 1986 Conference Theoretical AspectsReasoning Knowledge. Halpern, J. (Ed.), 83-98, San Francisco, CA: MorganKaufmann. (Updated version: Technical Note 412, Artificial Intelligence Center, SRIInternational, Menlo Park, CA.)Saotti, A., Ruspini, E., & Konolige, K. (1993). Integrating Reactivity Goaldirectedness Fuzzy Controller. Proc. 2nd Fuzzy-IEEE Conference, SanFrancisco, CA.Schoppers, M. J. (1987). Universal Plans Reactive Robots Unpredictable Domains.Proceedings IJCAI-87. San Francisco, CA: Morgan Kaufmann.Selman, B. (1993). Near-Optimal Plans, Tractability, Reactivity. Tech. rep., AI Dept.,AT&T Bell Laboratories.Teo, P. C-S. (1991). \Botworld," (unpublished). Robotics Laboratory, Computer ScienceDept., Stanford University, December.Teo, P. C-S. (1992). Botworld Structures, (unpublished). Robotics Laboratory, ComputerScience Dept., Stanford University, June.Waterman, D. A. & Hayes-Roth, F. (1978). Overview Pattern-Directed InferenceSystems. Pattern-Directed Inference Systems, Waterman, D. A. & Hayes-Roth, F.(Eds.), 3-22. New York:Academic Press.Wilson, S. (1991). Animat Path AI. Animals Animats; ProceedingsFirst International Conference Simulation Adaptive Behavior, Meyer, J.A., & Wilson, S. (Eds.). Cambridge, MA: MIT Press/Bradford Books.158fiJournal Artificial Intelligence Research 1 (1994) 309-314Submitted 1/94; published 6/94Research NoteApplying GSAT Non-Clausal FormulasRoberto SebastianiMechanized Reasoning Group, DIST, viale Causa 13, 16145 Genova, Italy.Mechanized Reasoning Group, IRST, loc. Pante, 38050 Povo, Trento, Italy.rseba@dist.unige.itAbstractpaper describe modify GSAT applied non-clausalformulas. idea use particular \score" function gives number clausesCNF conversion formula false given truth assignment.value computed linear time, without constructing CNF conversion itself.proposed methodology applies variants GSAT proposed far.1. IntroductionGSAT (Selman, Levesque, & Mitchell, 1992; Selman & Kautz, 1993) incompletemodel-finding algorithm clausal propositional formulas performs randomizedlocal search. GSAT shown solve many \hard" problems much ecientlytraditional algorithms like, e.g., DP (Davis & Putnam, 1960). Since GSATapplies clausal formulas, using find models ordinary propositional formulasrequires previous clausal-form conversion. requires extra computation (whichextremely heavy \standard" clausal conversion used). Much worse, clausal-formconversion causes either large increase size input formula enlargementsearch space.paper describe modify GSAT applied non-clausalformulas directly , i.e., previous clausal form conversion. extended versionpaper (Sebastiani, 1994) provides proofs theorems detailed descriptionalgorithm introduced.achievement could enlarge GSAT's application domain. Selman et al. (1992) suggest traditional AI problems formulated model-finding tasks; e.g., visualinterpretation (Reiter & Mackworth, 1989), planning (Kautz & Selman, 1992), generation\vivid" knowledge representation (Levesque, 1986). often case non-clausalrepresentations compact problems. instance, rule form\Vi " gives rise several distinct clauses disjuncts conjunct. automated theorem proving (a.t.p.) applications model-findingproposed (see, e.g., (Artosi & Governatori, 1994; Klingerbeck, 1994)). instance,decision procedures decidable subclasses first-order logic iteratively perform nonclausal model-finding propositional instances input formulas (Jeroslow, 1988).generally, model-guided techniques proof search, like goal deletion (Ballantyne & Bledsoe, 1982), false preference , semantic resolution (Slaney, 1993), seemapplicable non-clausal a.t.p. well.c 1994 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.fiSebastianiprocedure GSAT()j := 1 Max-tries:= initial()k := 1 Max- ipsj=returnelse Poss- ips := hill-climb(; )V := pick(Poss- ips):= ip(V,T)UpdateScores(; V )endendreturn \no satisfying assignment found".Figure 1: general schema GSAT.2. GSATclausal propositional formula truth assignment variables, number clauses falsified called score(score(T; )). satisfies iff score(T; ) = 0. notion score plays key roleGSAT, considered \distance" truth assignment satisfying one.schema Figure 2 describes GSAT well many possible variants. usenotation (Gent & Walsh, 1993). GSAT performs iterative search satisfyingtruth assignment , starting random assignment provided initial() .step, successive assignment obtained ipping (inverting) truth value onesingle variable V . V chosen minimize score. Let Ti assignment obtainedipping i-th variable Vi . hill-climb() returns set Poss- ips variablesVr minimize score(Tr ; ). current values si = score(Ti; ) , score(T; )stored every variable Vi , hill-climb() simply returns set variables Vrbest sr . pick() chooses randomly one variables. ip() returns V 'svalue ipped. ipping, UpdateScores() updates values si , i.paper exploits observation functions initial() , hill-climb() , pick()ip() depend structure input formula , computationscores step input formula required clausal form.idea thus find suitable notion score non-clausal formulas, ecientalgorithm computing it.3. extended notion scoreLet cnf(') result converting propositional formula ' clausal formstandard method (i.e., applying rules De Morgan). following definitionextends notion score propositional formulas.Definition 3.1 score truth assignment propositional formula 'number clauses cnf(') falsified .310fiApplying GSAT Non-Clausal FormulasmPPPPPPPP [2,-][1,-]P[14,-]" b"[7,-]......... ....... .................... ............... ....# @b................. "#b [2,-]@[2,-] #... .. [4,-]"".....b#@[1,-].... -C... .-E B ,... [1,-]J [0,-] [1,-] [0,-][1,-]E... ..,JSS [2,-] ...E[1,-][2,0][2,-],... [2,-]JAA...[1,-][0,1]......-F-B... -DBB[1,-] C ...[1,-][1,-]....BBC .BC ......B.... -A -B C -E -F ... -D -E C F -A -F -B E -C F[0,-] [1,-] [0,-] [1,-] [0,-]...[1,-]. . . . . .[1,-]. . . . .[0,-]. . . . . .[1,-]. . . . . .[1,-]. . . . . ... [1 , 0][0,1][1 , 0] [0,1] [0,1] [0,-] [1,-] [1,-]... ..................... ........ ...................... ............. ............. ............... ...... ..................... ............. ....Figure 2: computation tree s(T; ').cnf() represents \natural" clausal form conversion. cnf(') numberpropositional variables ' logically equivalent '. problem cnf()exponential size growth cnf(') , is, jcnf (')j = O(2j'j). Definition 3.1 overcomesproblem, possible introduce linear-time computable function s(T; ')gives score formula '. done directly, i.e., without converting 'clausal form. define s(T; ') recursively follows: 1's((T; ')s(,(T; ')0 j= '1 j= '' literal1 otherwise0 otherwise:V'1sP, (T; '1)sQ(T; '1), 'k )'(T;')Wk 'kQ k s(T; ' k)Pk ss,((T;T; 'k)kk kkk'1 '2 s, (T; '1) s(T; '2)s(T; '1) + s, (T; '2),'2)+ (s(T; '1) + s, (T; '2))'1 '2 ss((T;T;''1))ss,(T;(T; ' )(s, (T; ' ) + s(T; ' ))1212s, (T; 'k) s(T; :'k ). distinction s(T; 'k ) s, (T; 'k) due polaritycurrent subformula 'k . computation s(T; '), call functions(T; 'j ) [s, (T; 'j )] invoked iff 'j positive [negative] subformula '.Example 3.1 Figure 2 represents computation tree score truth assignmentformula ' :(D(((^:^:B C ) ( E F )) C (( E ) (C F )))E B ) (((D A) ( F B ) F ) ((E C F ) B )):^:^__:^:_:_^::^^:^:^_::^^^:^^:^^__:assigns \true" variables '. information square brackets associatedsubformula 'j represents [s(T; 'j ); s, (T; 'j )]. instance, consider smallsubtree left Figure 2, score computed following way:1. Notice definition s(T; ') easily extended formulas involving connectives (e.g.,nand , , xor , if-then-else , : : : ) complicate boolean functions.311fiSebastianis(T; ( B C ) ( E F ) ) =s(T; B C ) s(T; D) s(T; E F ) =(s(T; A) + s(T; B ) + s(T; C )) s(T; D) (s(T; E ) + s(T; F )) =(1 + 1 + 0) 1 (1 + 1) = 4:::^:^:^^::_:_::^::^::::WQ; s(T; Vk 'k ) = Pk s(T; 'k ); s(T; k 'k ) = k s(T; 'k ); literals2Notice cnf (') 360 clauses long.Theorem 3.1 Let ' propositional formula truth assignment variables'. function s(T; ') gives score '.proof follows consideration that, truth assignment , setfalse clauses cnf('1 _ '2) cross product two sets false clausescnf('1) cnf('2) .Theorem 3.2 Let ' propositional formula truth assignment variables'. number operations required calculating s(T; ') grows linearlysize '.proof follows fact that, Time(s ('i; )) number operations requiredcomputing s(T; 'i) s, (T; 'i), Time(s ('i; )) ai j'ij + bi ,Time(s ('1 '2; )) maxi (ai) j'1 '2j + 2 maxi (bi) + 6, 2 f^; _; ; g.number operations required computing score assignmentclausal formula O(jj). = cnf ('), jj = O(2j'j). Thus standardcomputation score requires O(2j'j) operations, s(T; ') performsresult directly linear time.4. GSAT non-clausal formulasfollows Sections 2, 3 extend GSAT non-clausal formulas ' simplyusing extended notion score Definition 3.1. Let NC-GSAT (non-clausal GSAT)new version GSAT scores computed implementationfunction s() . follows Theorem 3.1 NC-GSAT(') function hillclimb() always returns sets variables GSAT(cnf(')), NC-GSAT(')performs ips returns result GSAT(cnf(')). Theorem 3.2 ensuresevery score computation performed linear time.current implementation GSAT (Selman & Kautz, 1993) provides highlyoptimized implementation Updatescores(; V ) , analyzes clauseslast- ipped variable V occurs in. allows strong reduction computational cost.(Sebastiani, 1994) describe detail analogous optimized version updatingprocedure NC-GSAT, called NC-Updatescores('; V ) , prove following properties:(i) ' clausal form, i.e., ' = cnf ('), NC-UpdateScores('; V )complexity UpdateScores('; V ) ;(ii) = cnf ('), NC-UpdateScores('; V ) O(j'j). UpdateScores(; V ) O(2j'j).latter mirrors complexity issues presented Section 3.312fiApplying GSAT Non-Clausal Formulasidea introduced paper applied variants GSAT. \CSAT"(Cautious SAT) hill-climb() returns variables cause decrease score;\DSAT" (Deterministic SAT) function pick() performs deterministic choice;\RSAT" (Random walk SAT) variable picked randomly among variables;\MSAT" (Memory SAT) pick() remembers last ipped variable avoids picking it.variants, proposed (Gent & Walsh, 1992, 1993), transposed NCGSAT well, independent structure input formula. SelmanKautz (1993) suggest variants improve performance overcomeproblems, escaping local minima. strategy \Averaging " suggestsdifferent implementation function initial() : instead random assignment, initial()returns bitwise average best assignments two latest cycles. independentform input formula. strategy \random walk " sequence hill-climb()- pick() substituted probability p simpler choice function: \choose randomlyvariable occurring unsatisfied clause". idea transposed NC-GSATwell: \choose randomly branch passing nodes whose score differentzero, pick variable leaf".One final observation worth making. order overcome exponential growthCNF formulas, algorithms proposed (Plaisted & Greenbaum, 1986; de laTour, 1990) convert propositional formulas ' polynomial-size clausal formulas .methods based introduction new variables, representing subformulaoriginal input '. Unfortunately, issue size-polynomiality valid \"occurs ', number clauses grows exponentially number \"'. Even worse, introduction k new variables enlarges search space 2k factorreduces strongly solution ratio. fact, model also model ',model ' know one 2k extensions model (Plaisted &Greenbaum, 1986).AcknowledgementsFausto Giunchiglia Enrico Giunchiglia given substantial continuous feedbackwhole development paper. Toby Walsh provided important feedbackprevious version paper. Aaron Noble, Paolo Pecchiari, Luciano Serafinihelped final revision. Bart Selman Henry Kautz thanked assistanceGSAT code.ReferencesArtosi, A., & Governatori, G. (1994). Labelled Model Modal Logic. Proc. CADE12Workshop Automated Model Building.Ballantyne, M., & Bledsoe, W. (1982). Generating Using Examples Proof Discovery. Michie, D. (Ed.), Machines intelligence, Vol. 10, pp. 3{39. Halsted Press.Davis, M., & Putnam, H. (1960). computing procedure quantification theory. JournalACM, 7, 201{215.313fiSebastianide la Tour, T. B. (1990). Minimizing Number Clauses Renaming. Proc.10th Conference Automated Deduction, pp. 558{572. Springer-Verlag.Gent, I. P., & Walsh, T. (1992). Enigma SAT Hill-climbing Procedures. Tech. rep.605, University Edinburgh, Dept. Artificial Intelligence.Gent, I. P., & Walsh, T. (1993). Towards Understanding Hill-climbing ProceduresSAT. Proc. 11th National Conference Artificial Intelligence, pp. 28{33.Jeroslow, R. (1988). Computation-Oriented Reduction Predicate Propositional Logic.Decision Support System, 4, 183{197.Kautz, H., & Selman, B. (1992). Planning Satisfiability. Proc. 10th European Conference Artificial Intelligence, pp. 359{363.Klingerbeck, S. (1994). Generating Finite Counter Examples Semantic TableauxInterpretation Revision. Proc. CADE12 Workshop Automated Model Building.Levesque, H. (1986). Making believers computers. Artificial Intelligence., 30, 81{108.Plaisted, D., & Greenbaum, S. (1986). Structure-preserving Clause Form Translation.Journal Symbolic Computation, 2, 293{304.Reiter, R., & Mackworth, A. (1989). logical framework depiction image interpretation. Artificial Intelligence., 41 (2), 125{155.Sebastiani, R. (1994). Applying GSAT Non-Clausal Formulas. Tech. rep. 94-0018,DIST, University Genova, Italy. Available via anonimous ftp mrg.dist.unige.it,/pub/mrg-ftp/.Selman, B., & Kautz, H. (1993). Domain-Independent Extension GSAT: Solving LargeStructured Satisfiability Problems. Proc. 13th International Joint ConferenceArtificial Intelligence, pp. 290{295.Selman, B., Levesque, H., & Mitchell, D. (1992). New Method Solving Hard Satisfiability Problems. Proc. 10th National Conference Artificial Intelligence,pp. 440{446.Slaney, J. (1993). SCOTT: Model-Guided Theorem Prover. Proc. 13th International Joint Conference Artificial Intelligence, pp. 109{114. Morgan Kaufmann.314fiJournal Artificial Intelligence Research 1 (1993) 1-23Submitted 5/93; published 8/93Market-Oriented Programming EnvironmentApplication Distributed Multicommodity Flow ProblemsMichael P. Wellmanwellman@engin.umich.eduUniversity Michigan, Dept. Electrical Engineering Computer Science,Ann Arbor, MI 48109 USAAbstractMarket price systems constitute well-understood class mechanismscertain conditions provide effective decentralization decision making minimal communication overhead. market-oriented programming approach distributed problemsolving, derive activities resource allocations set computational agentscomputing competitive equilibrium artificial economy. Walras provides basicconstructs defining computational market structures, protocols derivingcorresponding price equilibria. particular realization approach formmulticommodity ow problem, see careful construction decision process according economic principles lead ecient distributed resource allocation,behavior system meaningfully analyzed economic terms.1. Distributed Planning Economicsdistributed multiagent planning system, plan system whole composite plans produced constituent agents. plans may interact significantlyresources required agents' activities (preconditions) products resulting activities (postconditions). Despite interactions, oftenadvantageous necessary distribute planning process agents separatedgeographically, different information, possess distinct capabilities authority,designed implemented separately. case, agent limitedcompetence awareness decisions produced others, sort coordinationrequired maximize performance overall system. However, allocating resourcesvia central control extensive communication deemed infeasible, violates whateverconstraints dictated distribution planning task first place.task facing designer distributed planning system define computationally ecient coordination mechanism realization collection agents.agent configuration may given, may design parameter. term agent,refer module acts within mechanism according knowledgeinterests. capabilities agents organization overall decision-makingstructure determine behavior system whole. concerns collective behavior self-interested decision makers, design decentralized structurefundamentally exercise economics incentive engineering. problem developingarchitectures distributed planning fits within framework mechanism design (Hurwicz, 1977; Reiter, 1986), many ideas results economics directly applicable.particular, class mechanisms based price systems competitiondeeply investigated economists, characterized conditions eciencyc 1993 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.fiWellmancompatibility features economy. applicable, competitivemechanism achieves coordination minimal communication requirements (in precisesense related dimensionality messages transmitted among agents (Reiter, 1986)).theory general equilibrium (Hildenbrand & Kirman, 1976) provides foundation general approach construction distributed planning systems basedprice mechanisms. approach, regard constituent planning agents consumersproducers artificial economy, define individual activities terms production consumption commodities. Interactions among agents cast exchanges,terms mediated underlying economic mechanism, protocol.specifying universe commodities, configuration agents, interactionprotocol, achieve variety interesting often effective decentralized behaviors.Furthermore, apply economic theory analysis alternative architectures,thus exploit wealth existing knowledge design distributed planners.use phrase market-oriented programming refer general approach deriving solutions distributed resource allocation problems computing competitiveequilibrium artificial economy.1 following, describe general approachprimitive programming environment supporting specification computationalmarkets derivation equilibrium prices. example problem distributed transportation planning demonstrates feasibility decentralizing problem nontrivialinteractions, applicability economic principles distributed problem solving.2. WALRAS: Market-Oriented Programming Environmentexplore use market mechanisms coordination distributed planning modules, developed prototype environment specifying simulating computationalmarkets. system called walras, 19th-century French economist Leon Walras, first envision system interconnected markets price equilibrium.Walras provides basic mechanisms implementing various sorts agents, auctions,bidding protocols. specify computational economy, one defines set goodsinstantiates collection agents produce consume goods. Dependingcontext, goods agents may fixed exogenously, example, could correspond real-world goods agents participating planning process. Others mightcompletely artificial ones invented designer decentralize problem-solvingprocess particular way. Given market configuration, walras runs agentsdetermine equilibrium allocation goods activities. distribution goodsactivities constitutes market solution planning problem.1. name inspired Shoham's use agent-oriented programming refer specializationobject-oriented programming entities described terms agent concepts interactvia speech acts (Shoham, 1993). Market-oriented programming analogous specialization,entities economic agents interact according market concepts production exchange.phrase also invoked Lavoie, Baetjer, Tulloh (1991) refer real markets softwarecomponents.2fiMarket-Oriented Programming2.1 General Equilibriumwalras framework patterned directly general-equilibrium theory. brief exposition, glossing many fine points, follows; elaboration see text microeconomictheory (e.g., (Varian, 1984)).start k goods n agents. Agents fall two general classes. Consumersbuy, sell, consume goods, preferences consuming various combinationsbundles goods specified utility function. agent consumer,utility function, u : <+ ! <, ranks various bundles goods according preference.Consumers may also start initial allocation goods, termed endowment. Let e denote agent i's endowment good j , x amount good jultimately consumes. objective consumer choose feasible bundle goods,(x 1; : : :; x ) (rendered vector notation x ), maximize utility. bundlefeasible consumer total cost going prices exceed valuei's endowment prices. consumer's choice expressed followingconstrained optimization problem:ki;ji;i;ji;kmaxu (x ) s.t. p x p e ;x(1)p = (p1; : : :; p ) vector prices k goods.Agents second type, producers, transform sorts goodsothers, according technology. technology specifies feasible combinationsinputs outputs producer. Let us consider special case oneoutput good, indexed j , remaining goods potential inputs. case,technology producer described production function,k= ,x = f (x 1; : : :; xi;ji;i;j,1; x +1 ; : : :; x );i;ji;kspecifying maximum output producible given inputs. (When goodinput production, production function characterizes net output.)case, producer's objective choose production plan maximizes profits subjecttechnology going price output input goods. involves choosingproduction level, , along levels inputs produce minimum cost.Let x p denote consumption prices, respectively, input goods.corresponding constrained optimization problem maximize profits, differencerevenues costs:i;||max p , minp x s.t. f (x ) ;xyiequivalently,ji;||i;|minp x s.t. , x f (x ):xi;ji;|i;|(2)agent acts competitively takes prices given, neglecting impactbehavior prices. formulation implicitly assumes perfect competition,prices parameters agents' constrained optimization problems. Perfectcompetition realistically ects individual rationality numerous agents,small respect entire economy. Even case, however,3fiWellmanimplement competitive behavior individual agents choose. implicationsrestriction perfect competition discussed below.pair (p; x) price vector vector demands agent constitutescompetitive equilibrium economy if:1. agent i, x solution constrained optimization problem|(1)(2)|at prices p,2. net amount good produced consumed equals total endowment,nX=1x =nXi;j=1e ; j = 1; : : :; k:i;j(3)words, total amount consumed equals total amount produced (countednegative quantities consumption bundles producers), plus total amounteconomy started (the endowments).certain \classical" assumptions (essentially continuity, monotonicity, concavity utility production functions; see, e.g., (Hildenbrand & Kirman, 1976; Varian,1984)), competitive equilibria exist, unique given strictness conditions.perspective mechanism design, competitive equilibria possess several desirableproperties, particular, two fundamental welfare theorems general equilibrium theory: (1) competitive equilibria Pareto optimal (no agent better withoutworse), (2) feasible Pareto optimum competitive equilibriuminitial allocation endowments. properties seem offer exactlyneed: bound quality solution, plus prospect achievedesired behavior carefully engineering configuration computationalmarket. Moreover, equilibrium, prices ect exactly information requireddistributed agents optimally evaluate perturbations behavior without resortingcommunication reconsideration full set possibilities (Koopmans, 1970).2.2 Computing Competitive EquilibriaCompetitive equilibria also computable, algorithms based fixed-point methods (Scarf, 1984) optimization techniques (Nagurney, 1993) developed.sorts algorithms effect operate collecting solving simultaneous equilibrium equations (1), (2), (3)). Without expressly distributed formulation, however,techniques may violate decentralization considerations underlying distributedproblem-solving context. quite acceptable purposes algorithmsoriginally designed, namely analyze existing decentralized structures, transportation industries even entire economies (Shoven & Whalley, 1992). purposeimplement distributed system, must obey computational distributivity constraintsrelevant usual purposes applied general-equilibrium analysis. general, explicitly examining space commodity bundle allocations search equilibriumundercuts original motive decomposing complex activities consumptionproduction separate goods.4fiMarket-Oriented ProgrammingAnother important constraint internal details agents' state (such utilityproduction functions bidding policy) considered private order maximize modularity permit inclusion agents designers' direct control.consequence computationally exploiting global properties arising special features agents would generally permissible purposes. example,constraint profits zero consequence competitive behavior constantreturns production technology. Since information form technologybidding policy private producer agents, could considered cheating embedzero-profit condition equilibrium derivation procedure.Walras's procedure decentralized relaxation method, akin mechanismtatonnement originally sketched Leon Walras explain prices might derived.basic tatonnement method, begin initial vector prices, p0 . agentsdetermine demands prices (by solving corresponding constrained optimization problems), report quantities demanded \auctioneer". Basedreports, auctioneer iteratively adjusts prices excessdemand supply, respectively. instance, adjustment proportional excesscould modeled difference equationnXp +1 = p + ff( x ,=1nX=1e ):sequence p0 ; p1; : : : converges, excess demand market approaches zero,result competitive equilibrium. well known, however, tatonnementprocesses converge equilibrium general (Scarf, 1984). class economiestatonnement works so-called stable equilibria (Hicks, 1948). sucientcondition stability gross substitutability (Arrow & Hurwicz, 1977): priceone good rises, net demands goods decrease. Intuitively,gross substitutability violated complementarities preferencestechnologies reduced consumption one good cause reduced consumptionothers well (Samuelson, 1974).2.3 WALRAS Bidding Protocolmethod employed walras successively computes equilibrium price separate market, manner detailed below. Like tatonnement, involves iterative adjustment prices based reactions agents market. However, differstraditional tatonnement procedures (1) agents submit supply demand curvesrather single point quantities particular price, (2) auction adjusts individual prices clear, rather adjusting entire price vector increment(usually function summary statistics excess demand).2Walras associates auction distinct good. Agents act marketsubmitting bids auctions. walras, bids specify correspondence prices2. general approach called progressive equilibration Dafermos Nagurney (1989), appliedparticular transportation network equilibrium problem. Although model market dynamicsappear investigated extensively general-equilibrium theory, seemmatch kind price adjustment process envisioned Hicks pioneering study dynamicsstability (Hicks, 1948).5fiWellmanquantities good agent offers demand supply. bid particulargood corresponds one dimension agent's optimal demand, parametrizedprices relevant goods. Let x (p) solution equation (1) (2),appropriate, prices p. walras agent bids good j assumption pricesremaining goods fixed current values, p. Formally, agent i's bidgood j function x : <+ ! <, prices quantities satisfying|i;jx (p ) = x (p ; p) ;i;jjj|jsubscript j right-hand side selects quantity demanded good joverall demand vector. agent computes sends function (encodedvariety formats) auction good j .Given bids interested agents, auction derives market-clearing price,quantity demanded balances supplied, within prespecified tolerance.clearing price simply zero crossing aggregate demand function,sum demands agents. zero crossing exist long aggregatedemand suciently well-behaved, particular, continuous decreasing price.Gross substitutability, along classical conditions existence equilibrium,sucient ensure existence clearing price stage bidding protocol.Walras calculates zero crossing aggregate demand function via binary search.aggregate demand well-behaved, result auction may non-clearingprice.current price clearing respect current bids, say marketcommodity equilibrium. say agent equilibrium setoutstanding bids corresponds solution optimization problem going prices.agents commodity markets equilibrium, allocation goods dictatedauction results competitive equilibrium.Figure 1 presents schematic view walras bidding process. auctiondistinct good, agent, link auctions interest.also \tote board" current prices, kept up-to-date various auctions.current implementation tote board global data structure, however, since pricechange notifications explicitly transmitted interested agents, central informationcould easily dispensed with.agent maintains agenda bid tasks, specifying markets mustupdate bid compute new one. Figure 1, agent pending tasks submitbids auctions G1 , G7, G4. bidding process highly distributed,agent need communicate directly auctions goods interest (thosedomain utility production function, nonzero endowments).interactions concerns single good; auctions never coordinateother. Agents need negotiate directly agents, even know other'sexistence.new bids received auction, previously computed clearing price becomesobsolete. Periodically, auction computes new clearing price (if new updatedbids received) posts tote board. price updated,may invalidate agent's outstanding bids, since computedassumption prices remaining goods fixed previous values. finding6fiMarket-Oriented ProgrammingG1A1G2GkA2AiTask Agenda[1], [7], [4]Figure 1:Walras's bidding process. Gtote board p1p2}}pkdenotes auction j th good,ith trading agent. item [j ] task agenda denotes pending taskcompute submit bid good j .jprice change, agent augments task agenda include potentially affectedbids.times, walras maintains vector going prices quantities wouldexchanged prices. agents nonempty bid agendas auctions newbids, goods may disequilibrium. auctions clear agendasexhausted, however, economy competitive equilibrium (up numerictolerance). Using recent result Milgrom Roberts (1991, Theorem 12),shown condition sucient convergence tatonnement|gross substitutability|also sucient convergence walras's price-adjustment process. key observationprogressive equilibration (synchronous not) price time basedset previous supply demand bids.Although precise results effect, computational effort requiredconvergence fixed tolerance seems highly sensitive number goods, muchless number agents. Eydeland Nagurney (1989) analyzed detailconvergence pattern progressive equilibration algorithms related walras particular special cases, found roughly linear growth number agents. However,general conclusions dicult draw cost computing equilibrium particular computational economy may well depend interconnectedness strengthinteractions among agents goods.2.4 Market-Oriented Programmingdescribed above, walras provides facilities specifying market configurationscomputing competitive equilibrium. also view walras programmingenvironment decentralized resource allocation procedures. environment providesconstructs specifying various sorts agents defining interactions via7fiWellmanrelations common commodities. setting initial configuration, marketrun determine equilibrium level activities distribution resourcesthroughout economy.cast distributed planning problem market, one needs identify (1) goodstraded, (2) agents trading, (3) agents' bidding behavior. design stepsserially dependent, definition constitutes exchangeable produciblecommodity severely restricts type agents makes sense include.mentioned above, sometimes take fixed real-world agents goodspresented part problem specification. configuration determined,might advantageous adjust general parameters bidding protocol. Below,illustrate design task walras formulation multicommodity ow problem.2.5 ImplementationWalras implemented Common Lisp Common Lisp Object System (CLOS).current version provides basic infrastructure running computational economies,including underlying bidding protocol library CLOS classes implementingvariety agent types. object-oriented implementation supports incremental development market configurations. particular, new types agents often definedslight variations existing types, example modifying isolated features demandbehavior, bidding strategies (e.g., management task agenda), bid format. WangSlagle (1993) present detailed case use object-oriented languages representgeneral-equilibrium models. proposed system similar walras respectformulation, although designed interface conventional model-solving packages,rather support decentralized computation equilibrium directly.Although models distributed system, walras runs serially single processor.Distribution constraints information communication enforced programmingspecification conventions rather fundamental mechanisms software environment. Asynchrony simulated randomizing bidding sequences agentscalled unpredictably. Indeed, artificial synchronization lead undesirableoscillation clearing prices, agents collectively overcompensate imbalancespreceding iteration.3current experimental system runs transportation models sort described below, well abstract exchange production economies parametrized utilityproduction functions (including expository examples Scarf (1984) ShovenWhalley (1984)). Customized tuning basic bidding protocol necessary. process getting walras run examples, addedgenerically useful building blocks class libraries, much required fillcomprehensive taxonomy agents, bidding strategies, auction policies.3. formal dynamic models (Huberman, 1988; Kephart, Hogg, & Huberman, 1989), homogeneousagents choose instantaneously optimal policies without accounting others simultaneouslymaking choice. Since value particular choice varies inversely number agentschoosing it, delayed feedback others' decisions leads systematic errors, henceoscillation. also observed phenomenon empirically synchronized version WALRAS.eliminating synchronization, agents tend work different markets one time, hencesuffer much delayed feedback prices.8fiMarket-Oriented Programming3. Example: Multicommodity Flowsimple version multicommodity ow problem, task allocate givenset cargo movements given transportation network. transportation networkcollection locations, links (directed edges) identifying feasible transportationoperations. Associated link specification cost moving cargo along it.suppose cargo homogeneous, amounts cargo arbitrarilydivisible. movement requirement associates amount cargo origin-destinationpair. planning problem determine amount transport link ordermove cargo minimum cost. simplification ignores salient aspects realtransportation planning. instance, model completely atemporal, hencesuitable planning steady-state ows planning dynamic movements.distributed version problem would decentralize responsibility transporting separate cargo elements. example, planning modules corresponding geographically organizationally disparate units might arrange transportation cargowithin respective spheres authority. decision-making activity might decomposed along hierarchical levels abstraction, gross functional characteristics, accordingrelevant distinction. decentralization might result real distributionauthority within human organization, inherent informational asymmetriescommunication barriers, modularity imposed facilitate software engineering.Consider, example, abstract transportation network Figure 2, takenHarker (1988). four locations, directed links shown. Consider two movement requirements. first transport cargo location 1 location 4,second reverse direction. Suppose wish decentralize authority separateagents (called shippers) decide allocate cargo movement. first shipper decides split cargo units paths 1 ! 2 ! 4 1 ! 2 ! 3 ! 4,second figures split paths 4 ! 2 ! 1 4 ! 2 ! 3 ! 1. Notelatter paths shipper share common resource: link 2 ! 3.2413Figure 2: simple network (from Harker (1988)).overlapping resource demands, shippers' decisions appearnecessarily intertwined. congested network, example, cost transportingunit cargo link increasing overall usage link. shipper planningcargo movements user network would thus underestimatecosts potentially misallocate transportation resources.9fiWellmananalysis networks this, transportation researchers developedequilibrium concepts describing collective behavior shippers. system equilibrium, overall transportation cargo proceeds omniscient centralplanner directing movement shipment minimize total aggregatecost meeting requirements. user equilibrium, overall allocation cargomovements shipper minimizes total cost, sharing proportionatelycost shared resources. system equilibrium thus global optimum,user equilibrium corresponds composition locally optimal solutions subproblems.also intermediate possibilities, corresponding game-theoretic equilibriumconcepts Nash equilibrium, shipper behaves optimally giventransportation policies remaining shippers (Harker, 1986).4perspective designer distributed planner, seek decentralizationmechanism reach system equilibrium, come close possible givendistributed decision-making structure. general, however, cannot expect derivesystem equilibrium globally optimal solution without central control. Limits coordination communication may prevent distributed resource allocation exploitingopportunities inhibiting agents acting cross purposes. certainconditions decision making indeed decentralized effectively via market mechanisms.General-equilibrium analysis help us recognize take advantage opportunities.Note multicommodity ow problem, effective distributed solutiondue Gallager (1977). One market structures described effectively mimicssolution, even though Gallager's algorithm formulated expressly market terms.point crack hitherto unsolved distributed optimization problem (thoughwould nice), rather illustrate general approach simply described yetnontrivial task.4. WALRAS Transportation Marketsection, present series three transportation market structures implementedwalras. first simplest model comprises basic transportation goods shipperagents, augmented succeeding models include agent types. Comparative analysis three market structures reveals qualitatively distinct economiccomputational behaviors realized alternate walras configurations.4.1 Basic Shipper Modelresource primary interest multicommodity ow problem movement cargo.value cost cargo movement depends location, designatedistinct good capacity origin-destination pair network (see Figure 2).capture cost input required move cargo, define another good denoting generictransportation resources. concrete model, might consist vehicles, fuel,labor, factors contributing transportation.4. Nash solution, shippers correctly anticipate effect cargo movements averagecost link. resulting equilibrium converges user equilibrium number shippersincreases effect individual's behavior prices diminishes (Haurie & Marcotte, 1985).10fiMarket-Oriented Programmingdecentralize decision making, identify movement requirementdistinct shipper agent. shippers, consumers, interest moving variousunits cargo specified origins destinations.interconnectedness agents goods defines market configuration. Figure 3depicts walras configuration basic shipper model corresponding examplenetwork Figure 2. model two shippers, S1 4 S4 1, denotesshipper requirement move goods origin destination j . Shippers connectgoods might serve objectives: case, movement along links belongsimple path shipper's origin destination. diagram, G denotesgood representing amount cargo moved link ! j . G0 denotes specialtransportation resource good. Notice goods interest shippersG0, endowments, G2 3, transportation link servingorigin-destination pairs.;;i;ji;j;GG 2,3G 2,4S4,1S1,4G0G 1,2Figure 3:G 3,13,4GG2,14,2Walras basic shipper market configuration example transportation network.model employ transportation costs based network congestion,thus exhibiting diseconomies scale. words, marginal average costs (interms transportation resources required) increasing level servicelink. Using Harker's data, take costs quadratic. quadratic cost model posedsimply concreteness, represent substantive claim transportationnetworks. important qualitative feature model (and one necessaryexample work) exhibits decreasing returns, defining characteristiccongested networks. Note also Harker's model terms monetary costs, whereasintroduce abstract input good.Let c (x) denote cost transportation resources (good G0 ) required transportx units cargo link j . complete cost functions are:c1 2(x) = c2 1(x) = c2 4(x) = c4 2(x) = x2 + 20x;c3 1(x) = c2 3(x) = c3 4(x) = 2x2 + 5x:Finally, shipper's objective transport 10 units cargo origindestination.i;j;;;;;;;11fiWellmanbasic shipper model, assume shippers pay proportionately (in unitsG0 ) total cost link. amounts policy average cost pricing.take shipper's objective ship much possible (up movementrequirement) least costly manner. Notice objective expressibleterms consumer's optimization problem, equation (1), hence modeltechnically instance general-equilibrium framework.Given network prices link, cheapest cargo movement correspondsshortest path graph, distances equated prices. Thus, givenlink, shipper would prefer ship entire quota link shortest path,zero otherwise. case ties, indifferent among possible allocations.bid link i; j , shipper derive threshold price determines whether linkshortest path taking difference shortest-path distance networkslink i; j 's distance set zero infinity, respectively.incrementally changing bids, shipper also consider outstanding bidscurrent prices. value reserving capacity particular link zerocannot get service links path. Similarly, already committedshipping cargo parallel path, gain obtaining capacity (evenlower price) withdraws bids.5 Therefore, actual demand policyshipper spend uncommitted income potential ow increase (derivedmaximum- ow calculations) could obtain purchasing capacity given link.willing spend threshold value link, described above. determinesone point demand curve. unsatisfied requirement uncommittedincome also indicates willingness pay lower price greater amount capacity.Boundary points serve bootstrap economy; initial conditionstypically case individual link contributes overall ow shipper'sorigin destination. Finally, demand curve completed smoothing operationpoints.Details boundary points smoothing operation rather arbitrary,make claim particular bidding policy ideal guaranteed work broadclass problems. crude approach appears sucient present examplesimilar ones, long shippers' policies become accurate prices approachequilibrium.Walras successfully computes competitive equilibrium example,case basic shipper model corresponds user equilibrium (UE)transportation network. UE example network, shipper sends 2.86 unitscargo shared link 2 ! 3, remaining cargo direct linklocation 2 destination. allocation inecient, total cost 1143 resource5. Even shipper could simultaneously update bids markets, would good ideahere. competitive shipper would send cargo least costly path, neglecting possibilitydemand may increase prices longer cheapest. outstanding bids providesensitivity effect, functions price. cannot respond changesmany prices once, thus policy updating bids simultaneously lead perpetualoscillation. example, network considered here, unique competitive equilibriumshipper splitting cargo two different paths. Policies allocating cargo one path neverlead result, hence convergence competitive equilibrium depends incrementalitybidding behavior.12fiMarket-Oriented Programmingunits, somewhat greater global minimum-cost solution 1136 units.economic terms, cause ineciency externality respect usageshared link. shippers effectively charged average cost|which casedecreasing returns marginal cost|the price face ect fullincremental social cost additional usage resource. effect, incremental usageresource one agent subsidized other. steeper decreasing returns,agents incentive overutilize resource.6 simple exampleclassic tragedy commons.classical remedy problems internalize externality allocatingownership shared resource decision maker proper incentivesuse eciently. implement solution walras augmenting marketstructure another type agent.4.2 Carrier Agentsextend basic shipper model introducing carriers, agents type producercapability transport cargo units specified links, given varying amountstransportation resources. model described here, associate one carrieravailable link. production function carrier simply inversecost function described above. achieve global movement cargo, shippers obtaintransportation services carriers exchange necessary transportation resources.Let C denote carrier transports cargo location location j .carrier C connected auction G , output good, along G0|its inputproduction process. Shipper agents also connected G0 , endowedtransportation resources exchange transportation services. Figure 4 depictswalras market structure carriers included economy.i;ji;ji;jGC 2,4Figure 4:3,4C 3,4G 2,4S1,4G 1,2C 1,2G 2,3C 2,3G0C 3,1G 3,1S4,1GCG4,22,1C 2,14,2Walras market configuration example transportation network economy shippers carriers.6. Average-cost pricing perhaps common mechanism allocating costs shared resource.Shenker (1991) points problems scheme|with respect eciency strategicbehavior|in context allocating access congested computer networks, problem analogoustransportation task.13fiWellmancase decreasing returns technology, producer's (carrier's) optimizationproblem unique solution. optimal level activity maximizes revenues minus costs,occurs point output price equals marginal cost. Using result,carriers submit supply bids specifying transportation services function link prices(with resource price fixed), demand bids specifying required resources functioninput prices (for activity level computed output price fixed).example, consider carrier C1 2. output price p1 2 input price p0 , carrier'sprofitp1 2y , p0c1 2(y);level service chooses supply. Given cost function above,expression maximized = (p1 2 , 20p0)=2p0. Taking p0 fixed, carrier submitssupply bid function p1 2. demand side, carrier takes p1 2 fixedsubmits demand bid enough good G0 produce , treated functionp0.revised configuration agent behaviors described, walras derives system equilibrium (SE), is, cargo allocation minimizing overall transportation costs.derived cargo movements correct within 10% 36 bidding cycles, 1%72, cycle every agent submits average one bid one auction.total cost (in units G0 ), division shippers' expenditures carriers' profits,equilibrium prices presented Table 1. Data UE solution basic shipper model included comparison. decentralized process producesglobal optimum perfectly consistent competitive behavior|the carriers priceoutputs marginal cost, technologies convex.;;;;;;;TC expense profit p1 2 p2 1 p2 3 p2 4 p3 1 p3 4 p4 2pricingMC (SE) 11361514 378 40.0 35.7 22.1 35.7 13.6 13.6 40.011430 30.0 27.1 16.3 27.1 10.7 10.7 30.0AC (UE) 1143;;;;;;;Table 1: Equilibria derived walras transportation example. TC, MC, ACstand total, marginal, average cost, respectively. TC = shipper expense ,carrier profit.simple check prices Table 1, verify p2 3 + p3 4 = p2 4p2 3 + p3 1 = p2 1. relationships must hold equilibrium (assuming linksnonzero movements), else shipper could reduce cost rerouting cargo. Indeed,simple (small symmetric) example this, easy derive equilibriumanalytically using global equations these. argued above, would improperexploit relationships implementation truly distributed decision process.lesson exercise achieve qualitatively distinct results simple variations market configuration agent policies. designers' perspective,prefer configuration leads transportation-ecient SE. ExaminationTable 1 reveals achieve result allowing carriers earn nonzeroprofits (economically speaking, really rents fixed factor represented;;;;14;;fiMarket-Oriented Programmingcongested channel) redistributing profits shippers cover increasedexpenditures. (In model general equilibrium production, consumers sharesproducers' profits. closes loop value ultimately realizedconsumption. specify shares part initial configuration, likeendowment.) example, distribute profits evenly two shippers.4.3 Arbitrageur Agentspreceding results demonstrate walras indeed implement decentralizedsolution multicommodity ow problem. market structure Figure 4distributed might be, (1) agents connected G0, (2) shippersneed know links potentially serving origin-destination pair. firstconcerns easily remedied, choice single transportation resource goodcompletely arbitrary. example, would straightforward consider collectionresources (e.g., fuel, labor, vehicles), endow shipper subsets these.second concern also addressed within walras. so, introduce yetanother sort producer agent. new agents, called arbitrageurs, act specializedmiddlemen, monitoring isolated pieces network ineciencies. arbitrageurproduces transportation k buying capacity j j k.production function simply specifies amount output good, G , equalminimum two inputs, G G . p + p < p , productionprofitable. bidding policy walras increment level activityiteration amount proportional current profitability (or decrement proportionalloss). incremental behavior necessary constant-returns producerswalras, profit maximization problem interior solution linear case.7incorporate arbitrageurs transportation market structure, first create newgoods corresponding transitive closure transportation network. examplenetwork, leads goods every location pair. Next, add arbitrageurevery triple locations (1) ! j original network, (2) existspath j k traverse location i. two conditions ensurearbitrageur every pair i; k connected path one link,eliminate combinations either redundant clearly unprofitable.revised market structure running example depicted Figure 5, newgoods agents shaded. goods agents inactive market solutionomitted diagram avoid clutter.Notice Figure 5 connectivity shippers significantly decreased,shippers need aware good directly serving origin-destinationpair. dramatically simplifies bidding problem, avoid analysisprice network. structure whole seems distributed, agent concernedthree goods.i;j;ki;ki;jj;ki;jj;ki;ki;j;ki;j;k7. Without restriction bidding behavior, competitive constant-returns producer wouldchoose operate level infinity zero, depending whether activity profitableunprofitable going prices (at break-even, producer indifferent among levels).would lead perpetual oscillation, problem noticed (and solved) Paul Samuelson 1949considered use market mechanisms solve linear programming problems (Samuelson, 1966).15fiWellmanG 2,4A2,3,12,3,4G 2,3C 2,4A1,2,4G3,4C 3,4G1,4G 1,2C 1,2C 2,1C 2,3G0S1,4G2,1C 3,1G3,14,2,1C 4,2G 4,2G4,1S4,1Figure 5: revised walras market configuration arbitrageurs.Despite simplified shipper behavior, walras still converges SE, optimalsolution, configuration. Although resulting allocation resources identical,qualitative change market structure corresponds qualitative changedegree decentralization.fact, behavior walras market configuration arbitrageurs virtually identical standard distributed algorithm (Gallager, 1977) multicommodityow (minimum delay communication networks). Gallager's algorithm, distributedmodules expressly differentiate cost function derive marginal cost increasingow communication link. Flows adjusted equate marginalcosts along competing subpaths. procedure provably converges optimal solutionlong iterative adjustment parameter suciently small. Similarly, convergencewalras model requires arbitrageurs adjust activity levelsquickly response profit opportunities loss situations.4.4 Summarypreceding sections developed three progressively elaborate market configurationsmulticommodity ow problem. Table 2 summarizes size shape configuration transportation network V locations E links, movementrequirements. basic shipper model results user equilibrium,augmented models produce globally optimal system equilibrium. carrier model requires E new producer agents produce superior result. arbitrageur model addsO(V E ) producers potentially new goods well, reduces numbergoods interest individual agent O(E ) small constant.market models represent three qualitatively distinct points spectrumpotential configurations. Hybrid models also conceivable, example, partialset arbitrageurs included, perhaps arranged hierarchy regular16fiMarket-Oriented ProgrammingmodelBasic shipper: : : plus carriers: : : plus arbitrageursgoodsshippersE + 1 [O(E )]E + 1 [O(E )]O(V 2) [2]carriers arbitrageurs||E [2]|E [2] O(V E ) [3]Table 2: Numbers goods agents three market configurations. typeagent, figure brackets indicates number goods individualbids.structure. would expect configurations exhibit behaviors intermediatespecific models studied here, respect equilibrium produced degreedecentralization.5. LimitationsOne serious limitation walras assumption agents act competitively.mentioned above, behavior rational many agents, smallrespect overall economy. However, individual agent large enough affectprices significantly (i.e., possesses market power), forfeits utility profits failingtake account. two approaches toward alleviating restriction perfectcompetition computational economy. First, could simply adopt models imperfectcompetition, perhaps based specific forms imperfection (e.g., spatial monopolisticcompetition) general game-theoretic models. Second, architects configuremarkets promote competitive behavior. example, decreasing agent's grain sizeenabling free entry agents enhance degree competition. Perhapsinterestingly, controlling agents' knowledge market structure (via standardinformation-encapsulation techniques), degrade ability exploit whatevermarket power possess. Uncertainty shown increase competitiveness amongrisk-averse agents formal bidding models (McAfee & McMillan, 1987),computational environment substantial control uncertainty.existence competitive equilibria ecient market allocations also dependscritically assumption nonincreasing returns scale. Although congestionreal factor transportation networks, example, many modes transportoften economies scale density may lead returns increasingoverall (Harker, 1987). Note strategic interactions, increasing returns, factorsdegrading effectiveness market mechanisms also inhibit decentralization general,would need addressed directly approach.cast walras general environment distributed planning, naturalask universal \market-oriented programming" computational paradigm.characterize computational power model easily enough, correspondenceclass convex programming problems represented economies satisfying classical conditions. However, interesting issue well conceptual framework market17fiWellmanequilibrium corresponds salient features distributed planning problems. Althoughearly make definitive assertion this, seems clear many planningtasks fundamentally problems resource allocation, units distributionoften correspond well units agency. Economics prominent (andarguably successful) approach modeling resource allocation decentralizeddecision making, reasonable suppose concepts economists find usefulsocial context prove similarly useful analogous computational context.course, economics ideal analyzing aspects social interaction,expect many issues organization distributed planning wellaccounted-for framework.Finally, transportation network model presented highly simplified version actual planning problem domain. realistic treatment wouldcover multiple commodity types, discrete movements, temporal extent, hierarchical network structure, critical features problem. may capturedincremental extensions simple model, perhaps applying elaborations developedtransportation science community. example, many transportation models (including Harker's elaborate formulation (Harker, 1987)) allow variable supplydemand commodities complex shipper-carrier relationships. Conceptsspatial price equilibrium, based markets commodities location, seem offerdirect approach toward extending transportation model within walras.6. Related Work6.1 Distributed Optimizationtechniques models described obviously build much work economics,transportation science, operations research. intended research contributionfields, rather application construction computationalframework decentralized decision making general. Nevertheless, wordsorder regarding relation approach described extant methods distributedoptimization.Although elaborate walras model essentially equivalent existing algorithms distributed multicommodity ow (Bertsekas & Tsitsiklis, 1989; Gallager, 1977),market framework offers approach toward extensions beyond strict scopeparticular optimization problem. example, could reduce number arbitrageurs,would eliminate guarantees optimality, might still reasonableexpectation graceful degradation. Similarly, could realize conceptual extensionsstructure problem, distributed production goods addition transportation, adding new types agents. given extension, may wellcustomized distributed optimization algorithm would outperform computationalmarket, coming algorithm would likely involve completely new analysis.Nevertheless, must stated speculations regarding methodological advantagesmarket-oriented framework indeed speculations point, relativeexibility applications programming paradigm must ultimately demonstratedempirically.18fiMarket-Oriented ProgrammingFinally, large literature decomposition methods mathematical programming problems, perhaps common approach distributed optimization.Many techniques interpreted economic terms, using closerelationship prices Lagrange multipliers. Again, main distinctionapproach advocated conceptual. Rather taking global optimization problem decentralizing it, aim provide framework formulating taskdistributed manner first place.6.2 Market-Based Computationbasic idea applying economic mechanisms coordinate distributed problem solvingnew AI community. Starting contract net (Davis & Smith, 1983),many found metaphor markets appealing, built systems organizedaround markets market-like mechanisms (Malone, Fikes, Grant, & Howard, 1988).original contract net actually include economic notions biddingmechanism, however, recent work Sandholm (1993) shown cost priceincorporated contract net protocol make like true market mechanism. Miller Drexler (Drexler & Miller, 1988; Miller & Drexler, 1988) examinedmarket-based approach depth, presenting underlying rationale addressingspecific issues salient computational environment. Waldspurger, Hogg, Huberman,Kephart, Stornetta (1992) investigated concepts actually implementingmarket mechanisms allocate computational resources distributed operating system.Researchers distributed computing (Kurose & Simha, 1989) also applied specializedalgorithms based economic analyses specific resource-allocation problems arisingdistributed systems. remarks line work, see (Wellman, 1991).Recently, Kuwabara Ishida (1992) experimented demand adjustmentmethods task similar multicommodity ow problem considered here. Onesignificant difference method would consider path networkseparate resource, whereas market structures manipulate links locationpairs. Although cast system competitive-equilibrium framework,results congruent obtained walras.Walras distinct prior efforts two primary respects. First, constructed expressly terms concepts general equilibrium theory, promote mathematical analysis system facilitate application economic principlesarchitectural design. Second, walras designed serve general programming environment implementing computational economies. Although developed specificallyallocate computational resources, reason could included market structures configured particular application domains. Indeed, idea groundingmeasures value computation real-world values (e.g., cargo movements) followsnaturally general-equilibrium view interconnected markets, oneexciting prospects future applications walras distributed problem-solving.Organizational theorists studied markets mechanisms coordinating activitiesallocating resources within firms. example, Malone (1987) models informationrequirements, exibility performance characteristics variety marketnon-market structures. terminology, walras implements centralized market,19fiWellmanallocation good mediated auction. Using models, determinewhether gross form organization advantageous, given information costcommunication, exibility individual modules, related features.paper, examine greater detail coordination process computational markets,elaborating criteria designing decentralized allocation mechanisms. takedistributivity constraint exogenously imposed; constraint relaxable,organizational economic analysis illuminate tradeoffs underlying mechanismdesign problem.Finally, market-oriented programming shares Shoham's agent-oriented programming (Shoham, 1993) view distributed problem-solving modules best designedunderstood rational agents. two approaches support different agent operations(transactions versus speech acts), adopt different rationality criteria, emphasize different agent descriptors, ultimately aimed achieving goal specifyingcomplex behavior terms agent concepts (e.g., belief, desire, capability) social organizations. Combining individual rationality laws social interaction provides perhapsnatural approach generalizing Newell's \knowledge level analysis" idea (Newell,1982) distributed computation.7. Conclusionsummary, walras represents general approach construction analysisdistributed planning systems, based general equilibrium theory competitive mechanisms. approach works deriving competitive equilibrium correspondingparticular configuration agents commodities, specified using walras's basic constructs defining computational market structures. particular realizationapproach simplified form distributed transportation planning, see qualitative differences economic structure (e.g., cost-sharing among shippers versus ownershipshared resources profit-maximizing carriers) correspond qualitatively distinct behaviors (user versus system equilibrium). exercise demonstrates careful designdistributed decision structure according economic principles sometimes leadeffective decentralization, behaviors alternative systems meaningfullyanalyzed economic terms.contribution work reported lies idea market-oriented programming, algorithm distributed computation competitive equilibria computationaleconomies, initial illustration approach simple problem distributedresource allocation. great deal additional work required understand precise capabilities limitations approach, establish broader methodologyconfiguration computational economies.Acknowledgementspaper revised extended version (Wellman, 1992). benefiteddiscussions computational economies many colleagues, would like thankparticular Jon Doyle, Ed Durfee, Eli Gafni, Daphne Koller, Tracy Mullen, Anna Nagurney,20fiMarket-Oriented ProgrammingScott Shenker, Yoav Shoham, Hal Varian, Carl Waldspurger, Martin Weitzman,anonymous reviewers helpful comments suggestions.ReferencesArrow, K. J., & Hurwicz, L. (Eds.). (1977). Studies Resource Allocation Processes.Cambridge University Press, Cambridge.Bertsekas, D. P., & Tsitsiklis, J. N. (1989). Parallel Distributed Computation. PrenticeHall, Englewood Cliffs, NJ.Dafermos, S., & Nagurney, A. (1989). Supply demand equilibration algorithmsclass market equilibrium problems. Transportation Science, 23, 118{124.Davis, R., & Smith, R. G. (1983). Negotiation metaphor distributed problemsolving. Artificial Intelligence, 20, 63{109.Drexler, K. E., & Miller, M. S. (1988). Incentive engineering computational resourcemanagement. Huberman (1988), pp. 231{266.Eydeland, A., & Nagurney, A. (1989). Progressive equilibration algorithms: caselinear transaction costs. Computer Science Economics Management, 2, 197{219.Gallager, R. G. (1977). minimum delay routing algorithm using distributed computation.IEEE Transactions Communications, 25, 73{85.Harker, P. T. (1986). Alternative models spatial competition. Operations Research, 34,410{425.Harker, P. T. (1987). Predicting Intercity Freight Flows. VNU Science Press, Utrecht,Netherlands.Harker, P. T. (1988). Multiple equilibrium behaviors networks. Transportation Science,22, 39{46.Haurie, A., & Marcotte, P. (1985). relationship Nash-Cournot Wardropequilibria. Networks, 15, 295{308.Hicks, J. R. (1948). Value Capital (second edition). Oxford University Press, London.Hildenbrand, W., & Kirman, A. P. (1976). Introduction Equilibrium Analysis: Variations Themes Edgeworth Walras. North-Holland Publishing Company,Amsterdam.Huberman, B. A. (Ed.). (1988). Ecology Computation. North-Holland.Hurwicz, L. (1977). design resource allocation mechanisms. Arrow Hurwicz(1977), pp. 3{37. Reprinted American Economic Review Papers Proceedings,1973.21fiWellmanKephart, J. O., Hogg, T., & Huberman, B. A. (1989). Dynamics computational ecosystems. Physical Review A, 40, 404{421.Koopmans, T. C. (1970). Uses prices. Scientific Papers Tjalling C. Koopmans, pp.243{257. Springer-Verlag. Originally published Proceedings ConferenceOperations Research Production Inventory Control, 1954.Kurose, J. F., & Simha, R. (1989). microeconomic approach optimal resource allocationdistributed computer systems. IEEE Transactions Computers, 38, 705{717.Kuwabara, K., & Ishida, T. (1992). Symbiotic approach distributed resource allocation:Toward coordinated balancing. Pre-Proceedings 4th European WorkshopModeling Autonomous Agents Multi-Agent World.Lavoie, D., Baetjer, H., & Tulloh, W. (1991). Coping complexity: OOPSeconomists' critique central planning. Hotline Object-Oriented Technology, 3 (1),6{8.Malone, T. W., Fikes, R. E., Grant, K. R., & Howard, M. T. (1988). Enterprise: marketlike task scheduler distributed computing environments. Huberman (1988), pp.177{205.Malone, T. W. (1987). Modeling coordination organizations markets. ManagementScience, 33, 1317{1332.McAfee, R. P., & McMillan, J. (1987). Auctions bidding. Journal Economic Literature, 25, 699{738.Milgrom, P., & Roberts, J. (1991). Adaptive sophisticated learning normal formgames. Games Economic Behavior, 3, 82{100.Miller, M. S., & Drexler, K. E. (1988). Markets computation: Agoric open systems.Huberman (1988), pp. 133{176.Nagurney, A. (1993). Network Economics: Variational Inequality Approach. KluwerAcademic Publishers.Newell, A. (1982). knowledge level. Artificial Intelligence, 18, 87{127.Reiter, S. (1986). Information incentive performance (new)2 welfare economics.Reiter, S. (Ed.), Studies Mathematical Economics. MAA Studies Mathematics.Samuelson, P. A. (1966). Market mechanisms maximization. Stiglitz, J. E. (Ed.),Collected Scientific Papers Paul A. Samuelson, Vol. 1, pp. 415{492. MIT Press,Cambridge, MA. Originally appeared RAND research memoranda, 1949.Samuelson, P. A. (1974). Complementarity: essay 40th anniversary HicksAllen revolution demand theory. Journal Economic Literature, 12, 1255{1289.22fiMarket-Oriented ProgrammingSandholm, T. (1993). implementation contract net protocol based marginalcost calculations. Proceedings National Conference Artificial Intelligence,pp. 256{262 Washington, DC. AAAI.Scarf, H. E. (1984). computation equilibrium prices. Scarf, H. E., & Shoven, J. B.(Eds.), Applied General Equilibrium Analysis, pp. 1{49. Cambridge University Press,Cambridge.Shenker, S. (1991). Congestion control computer networks: exercise cost-sharing.Prepared delivery Annual Meeting American Political Science Association.Shoham, Y. (1993). Agent-oriented programming. Artificial Intelligence, 60, 51{92.Shoven, J. B., & Whalley, J. (1984). Applied general-equilibrium models taxationinternational trade: introduction survey. Journal Economic Literature, 22,1007{1051.Shoven, J. B., & Whalley, J. (1992). Applying General Equilibrium. Cambridge UniversityPress.Varian, H. R. (1984). Microeconomic Analysis (second edition). W. W. Norton & Company,New York.Waldspurger, C. A., Hogg, T., Huberman, B. A., Kephart, J. O., & Stornetta, S. (1992).Spawn: distributed computational economy. IEEE Transactions Software Engineering, 18, 103{117.Wang, Z., & Slagle, J. (1993). object-oriented knowledge-based approach formulatingapplied general equilibrium models. Third International Workshop ArtificialIntelligence Economics Management Portland, OR.Wellman, M. P. (1991). Review Huberman (1988). Artificial Intelligence, 52, 205{218.Wellman, M. P. (1992). general-equilibrium approach distributed transportation planning. Proceedings National Conference Artificial Intelligence, pp. 282{289San Jose, CA. AAAI.23fiJournal Artificial Intelligence Research 1 (1994) 209-229Submitted 11/93; published 2/94Learning Past Tense English Verbs:Symbolic Pattern Associator vs. Connectionist ModelsCharles X. Lingling@csd.uwo.caDepartment Computer ScienceUniversity Western OntarioLondon, Ontario, Canada N6A 5B7AbstractLearning past tense English verbs | seemingly minor aspect language acquisition | generated heated debates since 1986, become landmark tasktesting adequacy cognitive modeling. Several artificial neural networks (ANNs)implemented, challenge better symbolic models posed.paper, present general-purpose Symbolic Pattern Associator (SPA) based upondecision-tree learning algorithm ID3. conduct extensive head-to-head comparisonsgeneralization ability ANN models SPA different representations. conclude SPA generalizes past tense unseen verbs betterANN models wide margin, offer insights case.also discuss new default strategy decision-tree learning algorithms.1. IntroductionLearning past tense English verbs, seemingly minor aspect language acquisition,generated heated debates since first connectionist implementation 1986 (Rumelhart & McClelland, 1986). Based results, Rumelhart McClelland claimeduse acquisition human knowledge language best formulated ANN(Artificial Neural Network) models without symbol processing postulates existenceexplicit symbolic representation rules. Since then, learning past tense become landmark task testing adequacy cognitive modeling. yearsnumber criticisms connectionist modeling appeared (Pinker & Prince, 1988; Lachter &Bever, 1988; Prasada & Pinker, 1993; Ling, Cherwenka, & Marinov, 1993). criticismscentered mainly upon issues high error rates low reliability experimental results, inappropriateness training testing procedures, \hidden" featuresrepresentation network architecture facilitate learning, well opaqueknowledge representation networks. Several subsequent attempts improvingoriginal results new ANN models made (Plunkett & Marchman, 1991; Cottrell & Plunkett, 1991; MacWhinney & Leinbach, 1991; Daugherty & Seidenberg, 1993).notably, MacWhinney Leinbach (1991) constructed multilayer neural networkbackpropagation (BP), attempted answer early criticisms. hand,supporters symbolic approach believe symbol structures parse trees,propositions, etc., rules manipulations, critical cognitive level,connectionist approach may provide account neural structurestraditional symbol-processing cognitive architecture implemented (Fodor& Pylyshyn, 1988). Pinker (1991) Prasada Pinker (1993) argue properc 1994 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.fiLingaccounting regular verbs dependent upon production rules, irregularpast-tense ections may generalized ANN-like associative memory.proper way debating adequacy symbolic connectionist modelingcontrasting competitive implementations. Thus, symbolic implementation neededcompared ANN models. is, fact, challenge posed MacWhinneyLeinbach (1991), assert symbolic methods would work wellmodel. section titled \Is better symbolic model?" claim:approach provided even accuratecharacterization learning process, might still forced rejectconnectionist approach, despite successes. proper way debating conceptualizations contrasting competitive implementations.present case, would need symbolic implementation could contrastedcurrent implementation. (MacWhinney & Leinbach, 1991, page 153)paper, present general-purpose Symbolic Pattern Associator (SPA) basedupon symbolic decision tree learning algorithm ID3 (Quinlan, 1986). shown(Ling & Marinov, 1993) SPA's results much psychologically realisticANN models compared human subjects. issue predictive accuracy,MacWhinney Leinbach (1991) report important results model unseenregular verbs. reply criticism, MacWhinney (1993) re-implemented ANNmodel, claimed raw generalization power close SPA.believed case systems learn data set:good reason equivalent performance twomodels. [...] two computationally powerful systems givenset input data, extract every bit data regularity input.Without processing, much blood squeezedturnip, systems [SPA ANN] extractedcould. (MacWhinney, 1993, page 295)show case; obviously reasons one learningalgorithm outperforms another (otherwise study different learning algorithms?).Occam's Razor Principle | preferring simplest hypothesis complexones | creates preference biases learning algorithms. preference bias preferenceorder among competitive hypotheses hypothesis space. Different learning algorithms,however, employ different ways measuring simplicity, thus concepts biasdifferent. well learning program generalizes depends upon degreeregularity data fits bias. study compare raw generalizationability symbolic ANN models task learning past tense Englishverbs. perform extensive head-to-head comparisons ANN SPA, showeffects different representations encodings generalization abilities.experimental results demonstrate clearly1. distributed representation, feature connectionists advocating,lead better generalization compared symbolic representation, arbitrary error-correcting codes proper length;210fiLearning Past Tense: Symbolic vs Connectionist Models2. ANNs cannot learn identity mapping preserves verb stem pasttense well SPA can;3. new representation suggested MacWhinney (1993) improves predictive accuracy SPA ANN, SPA still outperforms ANN models;4. sum, SPA generalizes past tense unseen verbs better ANN modelswide margin.Section 5 discuss reasons SPA better learning modeltask English past-tense acquisition. results support view manyrule-governed cognitive processes better modeled symbolic, rather connectionist, systems.2. Review Previous Worksection, review brie two main connectionist models learning pasttenses English verbs, subsequent criticisms.2.1 Rumelhart McClelland's ModelRumelhart McClelland's model based simple perceptron-based pattern associator interfaced input/output encoding/decoding network allows modelassociate verb stems past tenses using special Wickelphone/Wickelfeaturephoneme-representation format. learning algorithm classical perceptron convergence procedure. training testing sets mutually disjoint experiments.errors made model training process broadly follow U-shaped learning curve stages acquisition English past tense exhibited young children.testing sample consists 86 \unseen" low frequency verbs (14 irregular 72 regular)randomly chosen. testing sample results 93% error rateirregulars. regulars fare better 33.3% error rate. Thus, overall error ratewhole testing sample 43% | 37 wrong ambiguous past tense forms 86 tested.Rumelhart McClelland (1986) claim outcome experiment disconfirmsview exist explicit (though inaccessible) rules underlie human knowledgelanguage.2.2 MacWhinney Leinbach's ModelMacWhinney Leinbach (1991) report new connectionist model learningpast tenses English verbs. claim results new simulation farsuperior Rumelhart McClelland's results, answer criticisms aimed earlier model. major departure Rumelhart McClelland'smodel Wickelphone/Wickelfeature representational format replacedUNIBET (MacWhinney, 1990) phoneme representational system allows assignment single alphabetic/numerical letter total 36 phonemes. MacWhinneyLeinbach use special templates code phoneme positionword. actual input network created coding individual phonemes sets211fiLingphonetic features way similar coding Wickelphones Wickelfeatures (cfSection 4.3). network two layers 200 \hidden" units fully connected adjacentlayers. number arrived trial error. addition, networkspecial-purpose set connections copy input units directly onto output units.Altogether, 2062 regular irregular English verbs selected experiment| 1650 used training (1532 regular 118 irregular), 13 lowfrequency irregular verbs used testing (MacWhinney & Leinbach, 1991, page 144).Training network takes 24,000 epochs. end training still 11 errorsirregular pasts. MacWhinney Leinbach believe allow networkrun several additional days give additional hidden unit resources, probablyreach complete convergence (MacWhinney & Leinbach, 1991, page 151).testing error rate reported based small biased test sample 13 unseenirregular verbs; 9 13 predicted incorrectly. test modelunseen regular verbs: \Unfortunately, test similar set 13 regulars."(MacWhinney & Leinbach, 1991, page 151).2.3 Criticism Connectionist ModelsPrevious current criticisms connectionist models learning past tensesEnglish verbs center mainly several issues. issues summarizedfollowing subsections.2.3.1 Error Rateserror rate producing past tenses \unseen" test verbs highANN models, important tests carried MacWhinney Leinbach(1991) model. experimental results indicate neither model reaches leveladult competence. addition, relatively large numbers errors psychologicallyrealistic since humans rarely make them.2.3.2 Training Testing ProceduresRumelhart McClelland's model, MacWhinney Leinbach's model,generalization ability measured one training/testing sample. Further, testingsets randomly chosen, small. accuracy testing irregularverbs vary greatly depending upon particular set testing verbs chosen, thusmultiple runs large testing samples necessary assess true generalizationability learning model. Therefore, results previous connectionist modelsreliable. Section 4, set reliable testing procedure compare connectionistmodels symbolic approach. Previous connectionist simulations alsocriticized crude training processes (for example, sudden increase regularverbs training set), create behavior U-shaped learning curves.2.3.3 Data Representation Network Architecturepast criticisms connectionist models aimed datarepresentation formats employed simulations. Lachter Bever (1988) pointed212fiLearning Past Tense: Symbolic vs Connectionist Modelsresults achieved Rumelhart McClelland's model would impossible without use several TRICS (The Representations Crucially Supposes)introduced adoption Wickelphone/Wickelfeature representational format.MacWhinney Leinbach claim improved upon earlier connectionistmodel getting rid Wickelphone/Wickelfeature representation format, thusresponded many criticisms format entailed. However, MacWhinney Leinbach also introduce several TRICS data-representation format.example, instead coding predecessor successor phonemes Wickelphones, introduce special templates code positional information. meansnetwork learn associate patterns phoneme/positions within predetermined consonant/vowel pattern. Further, use restrictive templates gets rid many Englishverbs fit chosen template. may bias model favour shorterverbs, predominantly Anglo-Saxon origin, longer verbs, predominantly composite Latin French origin. Another TRICS introduced phonetic featureencoding (a distributed representation). clear phonetic features front,centre, back, high, etc. chosen. represent finer grained \microfeatures"help capture regularities English past tenses? Section 4.5, showstraightforward symbolic representation leads better generalizationcarefully engineered distributed representation. undermines claimed advantagesdistributed representation connectionist models.2.3.4 Knowledge Representation Integration Acquired KnowledgePinker Prince (1988), Lachter Bever (1988) point RumelhartMcClelland try model acquisition production past tense isolationrest English morphological system. Rumelhart McClelland, wellMacWhinney Leinbach, assume acquisition process establishes directmapping phonetic representation stem phonetic representationpast tense form. direct mapping collapses well-established distinctionslexical item vs. phoneme string, morphological category vs. morpheme. Simplyremaining level phonetic patterns, impossible express new categoricalinformation first-order (predicate/function/variable) format. One inherent deficitsconnectionist implementations thing variable verbstem, hence way model attain knowledge one couldadd sux stem get past tense (Pinker & Prince, 1988, page 124). Sinceacquired knowledge networks large weight matrix, usually opaquehuman observer, unclear phonological levels processing connectionistmodels carry integrated morphological, lexical, syntactical levelprocessing. Neither Rumelhart McClelland MacWhinney Leinbach addressissue. contrast ANNs whose internal representations entirely opaque,SPA represent acquired knowledge form production rules, allowprocessing, resulting higher-level categories verb stem voicedconsonants, linguistically realistic production rules using new categories regularverbs, associative templates irregular verbs (Ling & Marinov, 1993).213fiLing3. Symbolic Pattern Associatortake MacWhinney Leinbach's challenge better symbolic model learningpast tense English verbs, present general-purpose Symbolic Pattern Associator(SPA)1 generalize past tense unseen verbs much accuratelyconnectionist models section. model symbolic several reasons. First,input/output representation learning program set phoneme symbols,basic elements governing past-tense ection. Second, learningprogram operates phoneme symbols directly, acquired knowledgerepresented form production rules using phoneme symbols well. Third,production rules phonological level easily generalized firstorder rules use abstract, high-level symbolic categories morphemesverb stem (Ling & Marinov, 1993). contrast, connectionist models operatedistributed representation (phonetic feature vectors), acquired knowledgeembedded large weight matrix; therefore hard see knowledgegeneralized abstract representations categories.3.1 Architecture Symbolic Pattern AssociatorSPA based C4.5 (Quinlan, 1993) improved implementation ID3learning algorithm (cf. (Quinlan, 1986)). ID3 program inducing classification rulesform decision trees set classified examples. uses information gain ratiocriterion selecting attributes roots subtrees. divide-and-conquer strategyrecursively applied building subtrees remaining examples training setbelong single concept (class); leaf labeled concept. informationgain guides greedy heuristic search locally relevant discriminating attributemaximally reduces entropy (randomness) divided set examples.use heuristic usually results building small decision trees instead larger onesalso fit training data.task learn classify set different patterns single class severalmutually exclusive categories, ID3 shown comparable neural networks(i.e., within 5% range predictive accuracy) many real-world learning tasks(cf. (Shavlik, Mooney, & Towell, 1991; Feng, King, Sutherland, & Henery, 1992; Ripley,1992; Weiss & Kulikowski, 1991)). However, task classify set (input) patterns(output) patterns many attributes, ID3 cannot applied directly. reasonID3 treats different output patterns mutually exclusive classes, numberclasses would exponentially large and, importantly, generalization individualoutput attributes within output patterns would lost.turn ID3 similar N-to-1 classification system general purpose N-to-Msymbolic pattern associators, SPA applies ID3 output attributes combinesindividual decision trees \forest", set trees. similar approach proposeddealing distributed (binary) encoding multiclass learning tasks NETtalk(English text-to-speech mapping) (Dietterich, Hild, & Bakiri, 1990). tree takesinput set attributes input patterns, used determine value1. SPA programs relevant datasets obtained anonymously ftp.csd.uwo.capub/SPA/ .214fiLearning Past Tense: Symbolic vs Connectionist Modelsone attribute output pattern. specifically, pair input attributes (1 n )output attributes (!1 !m ) represented as:1; :::; n ! !1; :::; !mSPA build total decision trees, one output attribute !i (1m) taking input attributes 1; :::; n per tree. trees built, SPAuse jointly determine output pattern !1 ; :::; !m input pattern1; :::; n.important feature SPA explicit knowledge representation. Decision treesoutput attributes easily transformed propositional production rules (Quinlan,1993). Since entities rules symbols semantic meanings, acquiredknowledge often comprehensible human observer. addition, processingintegration rules yield high-level knowledge (e.g., rules using verb stems)(Ling & Marinov, 1993). Another feature SPA trees different outputattributes contain identical components (branches subtrees) (Ling & Marinov, 1993).components similar roles hidden units ANNs since shareddecision trees one output attribute. identical components alsoviewed high-level concepts feature combinations created learning program.3.2 Default Strategiesinteresting research issue decision-tree learning algorithms handle defaultclass. default class class assigned leaves training examplesclassified into. call leaves empty leaves. happens attributesmany different values, training set relatively small. cases,tree construction, branches explored attributes. testingexamples fall empty leaves, default strategy needed assign classesempty leaves.easier understanding, use spelling form verbs subsection explaindifferent default strategies work. (In actual learning experiment verbsrepresented phonetic form.) use consecutive left-to-right alphabetic representation,verb stems past tenses small training set represented follows:a,f,f,o,r,d,_,_,_,_,_,_,_,_,_e,a,t,_,_,_,_,_,_,_,_,_,_,_,_l,a,u,n,c,h,_,_,_,_,_,_,_,_,_l,e,a,v,e,_,_,_,_,_,_,_,_,_,_=>=>=>=>a,f,f,o,r,d,e,d,_,_,_,_,_,_,_a,t,e,_,_,_,_,_,_,_,_,_,_,_,_l,a,u,n,c,h,e,d,_,_,_,_,_,_,_l,e,f,t,_,_,_,_,_,_,_,_,_,_,_used filler empty space. left-hand 15 columns input patternsstems verbs; right-hand 15 columns output patternscorresponding correct past tense forms.discussed, 15 decision trees constructed, one output attribute.decision tree first output attribute constructed (see Figure 1 (a))following 4 examples:a,f,f,o,r,d,_,_,_,_,_,_,_,_,_ =>e,a,t,_,_,_,_,_,_,_,_,_,_,_,_ =>l,a,u,n,c,h,_,_,_,_,_,_,_,_,_ => l215fiLingl,e,a,v,e,_,_,_,_,_,_,_,_,_,_ => llast column classification first output attribute. However, manybranches (such 1 = c Figure 1 (a)) explored, since training exampleattribute value. testing pattern first input attribute equal c,class assigned to? ID3 uses majority default. is, popularclass whole subtree 1 assigned empty leaves. example above,either class l chosen since 2 training examples. However,clearly right strategy task since verb create would outputl...... a......, incorrect. unlikely small training setvariations attribute values, majority default strategy ID3 appropriatetask.1e6lcz<= Passthrough__5a:1a:1l:2c:0o:2z:0d:20px:n indicates n examplesclassified leaf labelled x.x:0 (boxed) indicates empty leaves.t:10Figure 1: (a) Passthrough default<= Majorityrd:2ld:5kt:0(b) Various defaultapplications verb past-tense learning, new default heuristic | passthrough| may suitable. is, classification empty leafattribute value branch. example, using passthrough default strategy,create output c....... passthrough strategy gives decision trees first-orderavor, since production rules empty leaves represented Attribute = XClass = X X unused attribute values. Passthrough domaindependent heuristic strategy class labels may nothingattribute values applications.Applying passthrough strategy alone, however, adequate every outputattribute. endings regular past tenses identical inputpatterns, irregular verbs may vowel consonant changes middleverbs. cases, majority default may suitable passthrough.order choose right default strategy | majority passthrough | decisionmade based upon training data corresponding subtree. SPA first determinesmajority class, counts number examples subtrees belongclass. counts number examples subtrees coincide216fiLearning Past Tense: Symbolic vs Connectionist Modelspassthrough strategy. two numbers compared, default strategy employedexamples chosen. instance, example (see Figure 1 (a)),majority class l (or a) 2 instances. However, 3 examples coincidingpassthrough default: two l one a. Thus passthrough strategy takes over,assigns empty leaves level. empty attribute branch c would assignedclass c. Note default strategy empty leaves attribute X depends upontraining examples falling subtree rooted X . localized method ensuresrelated objects uence calculating default classes. result, SPAadapt default strategy best suited different levels decision trees.example, Figure 1 (b), two different default strategies used different levelstree. use SPA adaptive default strategy throughout remainderpaper. Note new default strategy TRICS data representation;rather, represents bias learning program. learning algorithm defaultstrategy independent data representation. effect different data representationsgeneralization discussed Sections 4.3, 4.5, 4.6. passthrough strategyimposed ANNs well adding set copy connections input unitstwin output units. See Section 4.4 detail.3.3 Comparisons Default Strategies ID3, SPA, ANNdefault strategy neural networks tend take generalizing default classescompared ID3 SPA? conducted several experiments determine neuralnetworks' default strategy. assume domain one attribute Xmay take values a, b, c, d. class also one a, b, c, d. trainingexamples attribute values a, b, c | reserved testing defaultclass. training set contains multiple copies example form certainmajority class. Table 1 shows two sets training/testing examples used testcompare default strategies ID3, SPA neural networks.Data set 1Data set 2Training examplesTraining examplesValues X Class # copies Values X Class # copies10c10bb2bb6cc3cc7Testing exampleTesting example?1?1Table 1: Two data sets testing default strategies various methods.classification testing examples ID3 SPA quite easy decide. SinceID3 takes majority default, output class (with 10 training examples)first data set, c (with 17 training examples) second data set. SPA,number examples using passthrough 15 first data set, 13 second217fiLingdata set. Therefore, passthrough strategy wins first case output classd, majority strategy wins second case output class c.neural networks, various coding methods used represent values attribute X . dense coding, used 00 represent a, 01 b, 10 c 11d. also tried standard one-per-class encoding, real number encoding (0.2 a,0.4 b, 0.6 c 0.8 d). networks trained using hidden unitspossible case. found cases classification testing example stable; varies different random seeds initialize networks. Table2 summarises experimental results. ANNs, various classifications obtained 20different random seeds listed first ones occurring frequently. seemsneural networks consistent default strategy, alsoneither majority default ID3 passthrough default SPA. mayexplain connectionist models cannot generalize unseen regular verbs well eventraining set contains regular verbs (see Section 4.4). networks diculty(or underconstrained) generalizing identity mapping copies attributesverb stems past tenses.classification testing exampleData set 1 Data set 2ID3cSPAcANN, dense codingb; cbANN, one-per-classb; c;c; bANN, real numbersc;d; cTable 2: Default strategies ID3, SPA ANN two data sets.4. Head-to-head Comparisons Symbolic ANN Modelssection, perform series extensive head-to-head comparisons using severaldifferent representations encoding methods, demonstrate SPA generalizespast tense unseen verbs better ANN models wide margin.4.1 Format dataverb set came MacWhinney's original list verbs. set contains1400 stem/past tense pairs. Learning based upon phonological UNIBET representation (MacWhinney, 1990), different phonemes represented differentalphabetic/numerical letters. total 36 phonemes. source file transferredstandard format pairs input output patterns. example, verbsTable 3 represented pairs input output patterns (verb stem => past tense):6,b,&,n,d,6,n=>6,b,&,n,d,6,n,dI,k,s,E,l,6,r,e,t => I,k,s,E,l,6,r,e,t,I,d218fiLearning Past Tense: Symbolic vs Connectionist Models6,r,3,z => 6,r,o,zb,I,k,6,m => b,I,k,e,mSee Table 3 (The original verb set available Online Appendix 1). keep oneform past tense among multiple past tenses (such hang-hanged hang-hung)data set. addition, homophones exist original data set. Consequently,noise (contradictory data input pattern different outputpatterns) training testing examples. Note also information whetherverb regular irregular provided training/testing processes.base (stem)UNIBETb=base1 = irregularspelling form phonetic form d= past tense 0 = regularabandon6b&nd6nb0abandoned6b&nd6nd0benefitbEn6fItb0benefitedbEn6fItId0arise6r3zb0arose6roz1becomebIk6mb0becamebIkem1......Table 3: Source file MacWhinney Leinbach.4.2 Experiment Setupguarantee unbiased reliable comparison results, use training testing samplesrandomly drawn several independent runs. SPA ANN providedsets training/testing examples run. allows us achieve reliableestimate inductive generalization capabilities model task.neural network program used package called Xerion, developedUniversity Toronto. several sophisticated search mechanismsstandard steepest gradient descent method momentum. found trainingconjugate-gradient method much faster standard backpropagationalgorithm. Using conjugate-gradient method also avoids need search propersettings parameters learning rate. However, need determineproper number hidden units. experiments ANNs, first tried variousnumbers hidden units chose one produced best predictive accuracytrial run, use network number hidden units actual runs.SPA, hand, parameters adjust.One major difference implementation ANNs SPA SPA take(symbolic) phoneme letters directly ANNs normally encode phoneme letterbinary bits. (Of course, SPA also apply binary representation). studiedvarious binary encoding methods compared results SPA using symbolic letter219fiLingrepresentation. Since outputs neural networks real numbers, need decodenetwork outputs back phoneme letters. used standard method decoding:phoneme letter minimal real-number Hamming distance (smallest angle)network outputs chosen. see binary encoding affects generalization,SPA also trained binary representation. Since SPA's outputsbinary, decoding process may tie several phoneme letters. case, onechosen randomly. ects probability correct decoding levelphoneme letters. phoneme letters decoded, one lettersincorrect, whole pattern counted incorrect word level.4.3 Templated, Distributed Representationset experiments conducted using distributed representation suggestedMacWhinney Leinbach (1991). According MacWhinney Leinbach, outputleft-justified template format CCCVVCCCVVCCCVVCCC, C standsconsonant V vowel space holders. input two components: left-justifiedtemplate format input, right-justified template formatVVCCC. example, verb bet, represented UNIBET coding bEt, showntemplate format follows ( blank phoneme):INPUTbEttemplate:OUTPUTbEttemplate:b__E_t____________CCCVVCCCVVCCCVVCCC(left-justified)_E__tVVCCC(right-justified)b__E_t____________CCCVVCCCVVCCCVVCCC(left-justified)specific distributed representation | set (binary) phonetic features | usedencode phoneme letters connectionist networks. vowel (Vtemplates) encoded 8 phonetic features (front, centre, back, high, low, middle, round,diphthong) consonant (C templates) 10 phonetic features(voiced, labial, dental, palatal, velar, nasal, liquid, trill, fricative interdental). Notetwo feature sets vowels consonants identical, templatesneeded order decode right type phoneme letters outputsnetwork.experimental comparison, decided use right-justified template(VVCCC) since information redundant. Therefore, used left-justifiedtemplate (CCCVVCCCVVCCCVVCCC) input output. (The whole verb settemplated phoneme representation available Online Appendix 1. contains1320 pairs verb stems past tenses fit template). ease implementation,added two extra features always assigned 0 vowel phonetic featureset. Therefore, vowels consonants encoded 10 binary bits. ANNthus 18 10 = 180 input bits 180 output bits, found one layer 200hidden units (same MacWhinney (1993) model) reached highest predictive accuracytrial run. See Figure 2 network architecture used.220fiLearning Past Tense: Symbolic vs Connectionist Models(180 output units)C...........................CCVVCCCVVCCCVVCCC(full connection two layers)......(200 hidden units)......(full connection two layers)C...........................CCVVCCCVVCCCVVCCC(180 input units)Figure 2: architecture network used experiment.SPA trained tested data sets phoneme letters directly;is, 18 decision trees built phoneme letters output templates.see phonetic feature encoding affects generalization, also trained SPAdistributed representation | binary bit patterns 180 input bits180 output bits | exactly ANN simulation. addition, see\symbolic" encoding works ANN, also train another neural network (with 120hidden units) \one-per-class" encoding. is, phoneme letter (total 37;36 phoneme letters plus one blank) encoded 37 bits, one phoneme letter.used 500 verb pairs (including regular irregular verbs) trainingtesting sets. Sampling done randomly without replacement, training testingsets disjoint. Three runs SPA ANN conducted, SPA ANNtrained tested data set run. Training reached 100% accuracySPA around 99% ANN.Testing accuracy novel verbs produced interesting results. ANN modelSPA using distributed representation similar accuracy, ANNslightly better. may well caused binary outputs SPA suppressfine differences prediction. hand, SPA using phoneme letters directlyproduces much higher accuracy testing. SPA outperforms neural networks (witheither distributed one-per-class representations) 20 percentage points! testingresults ANN SPA found Table 4. findings clearly indicateSPA using symbolic representation leads much better generalization ANN models.4.4 Learning Regular VerbsPredicting past tense unseen verb, either regular irregular,easy task. Irregular verbs learned rote traditionally thought since221fiLingDistributed representationANN: % CorrectSPA: % CorrectReg Irrg Comb Reg Irrg Comb65.3 14.6 60.4 62.2 18.8 58.059.7 8.6 53.8 57.9 8.2 52.260.0 16.0 55.6 58.0 8.0 53.061.7 13.1 56.6 59.4 11.7 54.4Symbolic representationANN: % CorrectSPA: % CorrectReg Irrg Comb Reg Irrg Comb63.3 18.8 59.2 83.0 29.2 77.858.8 10.3 53.2 83.3 22.4 76.258.7 16.0 54.4 80.9 20.0 74.860.3 15.0 55.6 82.4 23.9 76.3Table 4: Comparisons testing accuracy SPA ANN distributed symbolicrepresentations.children adults occasionally extend irregular ection irregular-sounding regularverbs pseudo verbs (such cleef | cleft) (Prasada & Pinker, 1993). similarnovel verb cluster irregular verbs similar phonological patterns,likely prediction irregular past-tense form. Pinker (1991) PrasadaPinker (1993) argue regular past tenses governed rules, irregulars maygenerated associated memory graded effect irregular past-tensegeneralization. would interesting, therefore, compare SPA ANNpast-tense generalization regular verbs only. SPA ANN use same,position specific, representation, learning regular past tenses would require learning differentsuxes2 different positions, learn identity mapping copies verb stempast tenses verbs different lengths.used templated representation previous section, trainingtesting sets contained regular verbs. samples drawn randomly withoutreplacement. maximize size testing sets, testing sets simply consistedregular verbs sampled training sets. training testing setsused following methods compared. see effect adaptivedefault strategy (as discussed Section 3.2) generalization, SPA majoritydefault adaptive default tested. ANN models similarused previous section (except 160 one-layer hidden units, turnedbest predictive accuracy test run). passthrough default strategyimposed neural networks adding set copy connections connect directlyinput units twin output units. MacWhinney Leinbach (1991) usedcopy connections simulation. therefore tested networks copyconnection see generalization would improved well.results predictive accuracy SPA ANNs one runrandomly sampled training testing sets summarized Table 5. see,SPA adaptive default strategy, combines majority passthroughdefault, outperforms SPA majority default strategy used ID3.2. phonological form three different suxes regular verbs. verb stem ends(UNIBET phonetic representations), sux Id. example, extend | extended (inspelling form). verb stem ends unvoiced consonant, sux t. example, talk| talked. verb stem ends voiced consonant vowel, sux d. example,solve | solved.222fiLearning Past Tense: Symbolic vs Connectionist ModelsANNs copy connections generalize better ones without. However, evenANN models copy connections lower predictive accuracy SPA (majority). addition, differences predictive accuracy larger smaller setstraining examples. Smaller training sets make difference testing accuracyevident. training set contains 1000 patterns (out 1184), testing accuracybecomes similar, would approach asymptotically 100% larger training sets.Upon examination, errors made ANN models occur identity mapping(i.e., strange phoneme change drop); verb stems cannot preserved pasttense phonemes previously seen training examples. contradictsfindings Prasada Pinker (1993), show native English speakers generateregular sux-adding past tenses equally well unfamiliar-sounding verb stems (as longverb stems sound close irregular verbs). also indicates biasANN learning algorithms suitable type task. See discussionSection 5.TrainingPercent correct testingsizeSPA (adaptive) SPA (majority) ANN (copy con.) ANN (normal)5055.430.014.67.310072.958.634.624.930087.083.759.858.250092.589.082.667.9100093.592.492.087.3Table 5: Predictive accuracy learning past tense regular verbs4.5 Error Correcting CodesDietterich Bakiri (1991) reported increase predictive accuracy errorcorrecting codes large Hamming distances used encode values attributes.codes larger Hamming distance (d) allow correcting fewer d=2bits errors. Thus, learning programs allowed make mistakes bit levelwithout outputs misinterpreted word level.wanted find performances SPA ANNs improved errorcorrecting codes encoding 36 phonemes. chose error-correcting codes rangingones small Hamming distance ones large Hamming distance (usingBHC codes, see Dietterich Bakiri (1991)). number attributesphoneme large, data representation changed slightly experiment.Instead 18 phoneme holders templates, 8 consecutive, left-to-right phoneme holdersused. Verbs stems past tenses 8 phonemes removedtraining/testing sets. (The whole verb set representation available OnlineAppendix 1. contains 1225 pairs verb stems past tenses whose lengths shorter8). SPA ANN take exactly training/testing sets, contains 500pairs verb stems past tenses, error-correcting codes encoding phoneme223fiLingletter. Still, training networks 92-bit longer error-correcting codes takes longrun (there 8 92 = 736 input attributes 736 output attributes). Therefore,two runs 23- 46-bit codes conducted. Consistent Dietterich Bakiri(1991)'s findings, found testing accuracy generally increases Hammingdistance increases. However, also observed testing accuracy decreasesslightly codes become long. accuracy using 46-bit codes (with Hammingdistance 20) reaches maximum value (77.2%), quite close accuracy(78.3%) SPA using direct phoneme letter representation. seems trade-offtolerance errors large Hamming distance diculty learninglonger codes. addition, found testing accuracy ANNs lower oneSPA 23 bit- 46-bit error-correcting codes. results summarizedTable 6.ANNHamming Distance Correct bit level Correct word level23-bit codes1093.5%65.6%46-bit codes2094.1%67.4%SPAHamming Distance Correct bit level Correct word level23-bit codes1096.3%72.4%46-bit codes2096.3%77.2%92-bit codes4096.1%75.6%127-bit codes5496.1%75.4%Table 6: Comparisons testing accuracy SPA ANNs error-correcting codesresults previous two subsections undermine advantagesdistributed representation ANNs, unique feature advocated connectionists.demonstrated that, task, distributed representation actually allowadequate generalization. SPA using direct symbolic phoneme letters SPAerror-correcting codes outperform ANNs distributed representation wide margin.However, neither phoneme symbols bits error-correcting codes encode, implicitlyexplicitly, micro-features distributed representation. maydistributed representation used optimally designed. Nevertheless, straightforwardsymbolic format requires little representation engineering compared distributedrepresentation ANNs.4.6 Right-justified, Isolated Sux RepresentationMacWhinney Leinbach (1991) report important results predictive accuracy model unseen regular verbs. reply (MacWhinney, 1993)paper (Ling & Marinov, 1993), MacWhinney re-implemented ANN model. newimplementation, 1,200 verb stem past-tense pairs training set, among1081 regular 119 irregular. Training took 4,200 epochs, reached 100%correct regulars 80% irregulars. testing set consisted 87 regulars 15irregulars. percent correct testing epoch 4,200 91% regulars 27%irregulars, combined 80.0% testing set. MacWhinney claimed raw224fiLearning Past Tense: Symbolic vs Connectionist Modelsgeneralization power ANN model close SPA. believescase simply systems trained data set.realize (via private communication) new representation used MacWhinney'srecent implementation plays critical role improved performance. MacWhinney'snew representation, input (for verb stems) coded right-justified templateCCCVVCCCVVCCCVVCCC. output contains two parts: right-justified templateone input, coda form VVCCC. rightjustified template output used represent past tense without includingsux regular verbs. sux regular past tense always stays coda,isolated main, right-justified templates. irregular past tense,coda left empty. example, input output templated patterns past tenseverbs Table 3 represented as:INPUT(right-justified)CCCVVCCCVVCCCVVCCC___6_b__&_nd_6_n__b__E_n__6_f__I_t__________6_r__3_z_______b__I_k__6_m__OUTPUT(right-justified)CCCVVCCCVVCCCVVCCC___6_b__&_nd_6_n__b__E_n__6_f__I_t__________6_r__o_z_______b__I_k__e_m__(suffix only)VVCCC__d__ (for abandon-abandoned)I_d__ (for benefit-benefited)_____ (for arise-arose)_____ (for become-became)data representation clearly facilitates learning. regular verbs, outputpatterns always identical input patterns. addition, verb-ending phonemeletters always appear fixed positions (i.e., right VVCCC sectioninput template) due right-justified, templated representation. Furthermore, suxalways occupies coda, isolated right-justified templates.performed series experiments see much improvement could accomplish using new representation MacWhinney's recent ANN modelleft-justified representation discussed Section 4.3. SPA (with averaged predictiveaccuracy 89.0%) outperforms MacWhinney's recent ANN implementation (with predictive accuracy 80.0%) wide margin. addition, predictive accuracy alsoimproved average 76.3% left-justified representation 82.8%right-justified, isolated sux one. See results Table 7.5. General Discussion ConclusionsTwo factors contribute generalization ability learning program. firstdata representation, bias learning program. Arrivingright, optimal, representation dicult task. argued Prasada Pinker(1993), regular verbs represented coarse grain terms verb stemsuxes; irregular verbs finer grain terms phonological properties.Admittedly, SPA works uniformly level phoneme letters, ANNs do. However,SPA produces simple production rules use phoneme letters directly,rules generalized first-order rules new representations stemsvoiced consonants used across board rule-learningmodules (Ling & Marinov, 1993). one major advantages ANN models.225fiLingPredictive accuracy right-justified, isolated sux representationSPAMacWhinney's ANN modeltraining/testing training/testingtraining/testing500/5001200/1021200/102Run 181.389.2Run 284.190.4Run 383.187.4Average82.889.080.0 (one run)Table 7: Comparisons testing accuracy SPA ANN (with right-justified, isolatedsux representation)seems quite conceivable children acquire high-level concepts stemsvoiced consonants learning noun plurals, verb past tense, verb third-personsingular, comparative adjectives, on. large weight matrix resultlearning, hard see knowledge generalized ANN modelsshared modules.Even exactly data representation, exist learning taskssymbolic methods SPA generalize categorically better ANNs. converse also true. fact ects different inductive biases different learningalgorithms. Occam's Razor Principle | preferring simplest hypothesiscomplex ones | creates preference bias, preference choosing certain hypothesesothers hypothesis space. However, different learning algorithms choose different hypotheses use different measurements simplicity. example, amongpossible decision trees fit training examples, ID3 SPA induce simple decisiontrees instead complicated ones. Simple decision trees converted small setsproduction rules. well learning algorithm generalizes depends upon degreeunderlying regularities target concept fit bias. words,underlying regularities represented compactly format hypotheses producedlearning algorithm, data generalized well, even small set trainingexamples. Otherwise, underlying regularities large hypothesis,algorithm looking compact ones (as per Occam's Razor Principle), hypotheses inferred accurate. learning algorithm searches hypotheses largernecessary (i.e., use Occam's Razor Principle) normally \underconstrained"; know, based training examples only, manycompetitive hypotheses large size inferred.also describe bias learning algorithm looking training examplesdifferent classes separated n-dimensional hyperspace n numberattributes. decision node decision tree forms hyperplane describedlinear function X = a. hyperplanes perpendicular axis,also partial-space hyperplanes extend within subregion formedhyperplanes parents' nodes. Likewise, hidden units threshold functionANNs viewed forming hyperplanes hyperspace. However, unlike onesdecision trees, need perpendicular axis, full-space226fiLearning Past Tense: Symbolic vs Connectionist Modelshyperplanes extend whole space. ID3 applied concepts fitANN's bias, especially hyperplanes perpendicular axis, manyzigzag hyperplanes perpendicular axes would needed separate differentclasses examples. Hence, large decision tree would needed, fitID3's bias. Similarly, ANN learning algorithms applied concepts fit ID3'sbias, especially hyperplanes form many separated, partial-space regions, manyhidden units may needed regions.Another major difference ANNs ID3 ANNs larger variationweaker bias (cf. (Geman, Bienenstock, & Doursat, 1992)) ID3. ManyBoolean functions (e.g., linearly separable functions) fit small network (e.g., onehidden units) small decision tree. sometimes attributedclaimed versatility exibility ANNs; learn (but necessarily predict reliably well) many functions, symbolic methods brittle. However, beliefhumans versatile, learning algorithm large variation,rather set strong-biased learning algorithms, somehowsearch bias space add new members set new learning tasks. Symbolic learning algorithms clear semantic components explicit representation,thus easily construct strong-based algorithms motivated various specificlearning tasks. adaptive default strategy SPA example.hand, still largely know effectively strengthen bias ANNs manyspecific tasks (such identity mapping, k-term DNF, etc.). techniques (suchadding copy connections weight decaying) exist, exact effects biasingtowards classes functions clear.analyses (Ling & Marinov, 1993), underlying regularities governingection past tense English verbs form small set production rulesphoneme letters. especially regular verbs; rules either identityrules sux-adding rules. example, decision trees converted setprecedence-ordered production rules complicated rules (rules conditions) listed first. example, using consecutive, left-to-right phonetic representation,typical sux-adding rule verb stems 4 phoneme letters (such talk | talked) is:4 = k 5 = , !5 =is, fourth input phoneme k fifth blank (i.e., verbending) fifth output phoneme t. hand, identity-mapping rulesone condition. typical identity rule looks like:3 = l, !3 = lfact, passthrough default strategy allows identity-mapping rules represented simple first-order format:3 = X, !3 = XX phoneme. Clearly, knowledge forming regular past tensesthus expressed simple, conjunctive rules fit bias SPA (ID3),therefore, SPA much better generalization ability ANN models.conclude, demonstrated, via extensive head-to-head comparisons,SPA realistic better generalization capacity ANNs learningpast tense English verbs. argued symbolic decision-tree/production-rulelearning algorithms outperform ANNs. because, first, domain seems227fiLinggoverned compact set rules, thus fits bias symbolic learning algorithm;second, SPA directly manipulates representation better ANNs (i.e.,symbolic phoneme letters vs. distributed representation); third, SPA ablederive high-level concepts used throughout English morphology. results supportview many high-level, rule-governed cognitive tasks better modeledsymbolic, rather connectionist, systems.Acknowledgementsgratefully thank Steve Pinker constant encouragement, Marin Marinov, SteveCherwenka Huaqing Zeng discussions help implementing SPA.thank Brian MacWhinney providing verb data used simulation. DiscussionsTom Dietterich, Dave Touretzky Brian MacWhinney, well commentsreviewers, helpful. research conducted support NSERCResearch Grant computing facilities Department.ReferencesCottrell, G., & Plunkett, K. (1991). Using recurrent net learn past tense.Proceedings Cognitive Science Society Conference.Daugherty, K., & Seidenberg, M. (1993). Beyond rules exceptions: connectionistmodeling approach ectional morphology. Lima, S. (Ed.), RealityLinguistic Rules. John Benjamins.Dietterich, T., & Bakiri, G. (1991). Error-correcting output codes: general methodimproving multiclass inductive learning programs. AAAI-91 (Proceedings NinthNational Conference Artificial Intelligence).Dietterich, T., Hild, H., & Bakiri, G. (1990). comparative study ID3 backpropagation English text-to-speech mapping. Proceedings 7th InternationalConference Machine Learning. Morgan Kaufmann.Feng, C., King, R., Sutherland, A., & Henery, R. (1992). Comparison symbolic, statistical neural network classifiers. Manuscript. Department Computer Science,University Ottawa.Fodor, J., & Pylyshyn, Z. (1988). Connectionism cognitive architecture: criticalanalysis. Pinker, S., & Mehler, J. (Eds.), Connections Symbols, pp. 3 { 71.Cambridge, MA: MIT Press.Geman, S., Bienenstock, E., & Doursat, R. (1992). Neural networks bias/variancedilemma. Neural Computation, 4, 1 { 58.Lachter, J., & Bever, T. (1988). relation linguistic structure associativetheories language learning { constructive critique connectionist learningmodels. Pinker, S., & Mehler, J. (Eds.), Connections Symbols, pp. 195 { 247.Cambridge, MA: MIT Press.228fiLearning Past Tense: Symbolic vs Connectionist ModelsLing, X., Cherwenka, S., & Marinov, M. (1993). symbolic model learning pasttenses English verbs. Proceedings IJCAI-93 (Thirteenth International Conference Artificial Intelligence), pp. 1143{1149. Morgan Kaufmann Publishers.Ling, X., & Marinov, M. (1993). Answering connectionist challenge: symbolic modellearning past tense English verbs. Cognition, 49 (3), 235{290.MacWhinney, B. (1990). CHILDES Project: Tools Analyzing Talk. Hillsdale, NJ:Erlbaum.MacWhinney, B. (1993). Connections symbols: closing gap. Cognition, 49 (3),291{296.MacWhinney, B., & Leinbach, J. (1991). Implementations conceptualizations: Revising verb model. Cognition, 40, 121 { 157.Pinker, S. (1991). Rules language. Science, 253, 530 { 535.Pinker, S., & Prince, A. (1988). language connectionism: Analysis paralleldistributed processing model language acquisition. Pinker, S., & Mehler, J.(Eds.), Connections Symbols, pp. 73 { 193. Cambridge, MA: MIT Press.Plunkett, K., & Marchman, V. (1991). U-shaped learning frequency effects multilayered perceptron: Implications child language acquisition. Cognition, 38, 43 {102.Prasada, S., & Pinker, S. (1993). Generalization regular irregular morphologicalpatterns. Language Cognitive Processes, 8 (1), 1 { 56.Quinlan, J. (1986). Induction decision trees. Machine Learning, 1 (1), 81 { 106.Quinlan, J. (1993). C4.5 Programs Machine Learning. Morgan Kaufmann: San Mateo,CA.Ripley, B. (1992). Statistical aspects neural networks. Invited lectures SemStat(Seminaire Europeen de Statistique, Sandbjerg, Denmark, 25-30 April 1992).Rumelhart, D., & McClelland, J. (1986). learning past tenses English verbs.Rumelhart, D., McClelland, J., & PDP Research Group (Eds.), Parallel Distributed Processing Vol 2, pp. 216 { 271. Cambridge, MA: MIT Press.Shavlik, J., Mooney, R., & Towell, G. (1991). Symbolic neural learning algorithms:experimental comparison. Machine Learning, 6 (2), 111 { 144.Weiss, S., & Kulikowski, C. (1991). Computer Systems Learn: classification prediction methods statistics, neural networks, machine learning, expert systems.Morgan Kaufmann, San Mateo, CA.229fiJournal Artificial Intelligence Research 1 (1993) 47-59Submitted 6/93; published 9/93Empirical Analysis Search GSATIan P. GentI.P.Gent@edinburgh.ac.ukToby Walshwalsh@loria.frDepartment Artificial Intelligence, University Edinburgh80 South Bridge, Edinburgh EH1 1HN, United KingdomINRIA-Lorraine, 615, rue du Jardin Botanique,54602 Villers-les-Nancy, FranceAbstractdescribe extensive study search GSAT, approximation procedurepropositional satisfiability. GSAT performs greedy hill-climbing number satisfiedclauses truth assignment. experiments provide complete picture GSAT'ssearch previous accounts. describe detail two phases search: rapid hillclimbing followed long plateau search. demonstrate applied randomlygenerated 3-SAT problems, simple scaling problem sizemean number satisfied clauses mean branching rate. results allow usmake detailed numerical conjectures length hill-climbingphase, averagegradient phase, conjecture average score average branchingrate decay exponentially plateau search. end showing resultsused direct future theoretical analysis. work provides case studycomputer experiments used improve understanding theoretical propertiesalgorithms.1. IntroductionMathematicians increasingly recognizing usefulness experiments computershelp advance mathematical theory. surprising therefore one area mathematicsbenefitted little empirical results theory algorithms, especiallyused AI. Since objects theory abstract descriptions computer programs,principle able reason programs entirely deductively. However,theoretical analysis often complex current mathematical tools.theoretical analysis practical, often limited (unrealistically) simple cases.example, results presented (Koutsoupias & Papadimitriou, 1992) greedy algorithmsatisfiability apply interesting hard region problems described x3.addition, actual behaviour real problems sometimes quite different worstaverage case analyses. therefore support calls McGeoch (McGeoch, 1986), Hooker(Hooker, 1993) others development empirical science algorithms.science, experiments well theory used advance understandingproperties algorithms. One aims paper demonstrate benefitsempirical approach. present surprising experimental resultsdemonstrate results direct future efforts theoretical analysis.algorithm studied paper GSAT, randomized hill-climbing procedurepropositional satisfiability (or SAT) (Selman, Levesque, & Mitchell, 1992; Selman & Kautz,1993a). Propositional satisfiability problem deciding assignmentc 1993 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.fiGent & Walshvariables propositional formula makes formula true. Recently,considerable interest GSAT appears able solve large dicult satisfiability problems beyond range conventional procedures like Davis-Putnam (Selmanet al., 1992). believe results give actually apply larger familyprocedures satisfiability called GenSAT (Gent & Walsh, 1993). Understandingprocedures fully considerable practical interest since SAT is, many ways,archetypical (and intractable) NP-hard problem. addition, many AI problemsencoded quite naturally SAT (eg. constraint satisfaction, diagnosis vision interpretation, refutational theorem proving, planning).paper structured follows. x2 introduce GSAT, algorithm studiedrest paper. x3 define motivate choice problems usedexperiments. experiments described x4. experiments providecomplete picture GSAT's search previous informal accounts. resultsexperiments analysed closely x5 using powerful statistical tools.analysis allow us make various experimentally verifiable conjectures GSAT'ssearch. example, able conjecture: length GSAT's initial hill-climbingphase; average gradient phase; simple scaling various important featureslike score (on hill-climbing performed) branching rate. x6 suggestresults used direct future theoretical analysis. Finally, x7 describerelated work end brief conclusions x8.2. GSATGSAT random greedy hill-climbing procedure. GSAT deals formulae conjunct-ive normal form (CNF); formula, CNF iff conjunction clauses,clause disjunction literals. GSAT starts randomly generated truth assignment,hill-climbs \ ipping" variable assignment gives largest increasenumber clauses satisfied (called \score" on). Given choiceseveral equally good ips, GSAT picks one random. ip increase score,variable ipped change score (failing that) decreasesscore least. Thus GSAT starts random part search space searchesglobal solution using local information. Despite simplicity, procedureshown give good performance hard satisfiability problems (Selman et al., 1992).procedure GSAT():= 1 Max-tries:= random truth assignmentj := 1 Max- ipssatisfies returnelse Poss- ips := set vars increase satisfiabilityV := random element Poss- ips:= V's truth assignment ippedendendreturn\no satisfying assignment found"48fiAn Empirical Analysis Search GSAT(Gent & Walsh, 1993) describe large number experiments suggestneither greediness randomness important performance procedure.experiments also suggest various conjectures. instance, random 3-SATproblems (see x3) log runtime appears scale less linear dependencyproblem size. Conjectures could, noted introduction,profitably used direct future efforts analyse GSAT theoretically. Indeed,believe experiments reported suggest various conjectures woulduseful proof relationship runtime problem size (see x6details)3. Problem Spaceable perform experiments algorithm, need source problemsrun algorithm. Ideally problems come probability distributionwell-defined properties, contain simple parameters representativeproblems occur real situations. Unfortunately, often dicult meetcriteria. practice, one usually forced accept either problems well-defineddistribution simple parameters benchmark set real problems, necessarilyunknown distribution. experiments adopt former approachuse CNF formulae randomly generated according random k-SAT model.Problems random k-SAT N variables L clauses generated follows:random subset size k N variables selected clause, variable made positive negative probability 21 . random 3-SAT, phasetransition satisfiable unsatisfiable L approximately 4.3N (Mitchell, Selman,& Levesque, 1992; Larrabee & Tsuji, 1992; Crawford & Auton, 1993). lower L,problems generated under-constrained thus satisfiable; higher L, problems generated over-constrained thus unsatisfiable. many NP-completeproblems, problems phase transition typically much dicult solveproblems away transition (Cheeseman, Kanefsky, & Taylor, 1991). regionL=4.3N thus generally considered good source hard SAT problemsfocus much recent experimental effort.4. GSAT's searchGSAT first introduced, noted search try divided twophases. first phase try, ip increases score. However, phaserelatively short followed second phase ips increasescore, instead sideways moves leave number clauses satisfied.phase search \plateau" occasional ip increase score.1One aims paper improve upon informal observations makingquantitative measurements GSAT's search, using measurements makeseveral experimentally testable predictions.1. Informal observations effect made Bart Selman presentation (Selman et al.,1992) AAAI-92. observations enlarged upon (Gent & Walsh, 1992).49fiGent & Walshexperiments, followed three methodological principles (McGeoch, 1986).First, performed experiments large problem sizes many repetitions, reducevariance allow emergent properties. Second, sought good views data.is, looked features performance meaningful predictablepossible. Third, analysed results closely. Suitable analysis data may showfeatures clear simple presentation. rest paper showprinciples enabled us make detailed conjectures GSAT's search.Many features GSAT's search space graphically illustrated plottingvary try. obvious feature plot score, number satisfiedclauses. quest good view GSAT's search space, also decided plot \poss ips" ip: is, number equally good ips GSAT randomlypicks. interesting measure since indicates branching rate GSAT's searchspace.begin one try GSAT 500 variable random 3-SAT problemdicult region L = 4.3N (Figure 1a). Although considerable variationtries, graph illustrates features common tries. score (in Figure 1a)poss- ips (in Figure 1b) plotted percentages maximal values, L Nrespectively. percentage score starts 87.5%, might seem surprisinglyhigh.Theoretically, however, expect random truth assignment k-SAT satisfy2k ,1 clauses (in instance, 7 ). expected earlier informal description,82kscore climbs rapidly first, attens mount plateau. graphdiscrete since positive moves increase score fixed amount,discreteness lost due small scale. illustrate discreteness, Figure 1bplot change number satisfied clauses made ip (as exact value,unscaled). Note x-axis plots Figure 1b same.Change scorePercentage score1006597.543952192.50% poss-flips-190201087.5004080120160200240flips04080120160200240flips(a) Score(b) Change score, poss- ipsFigure 1: GSAT's behaviour one try, N = 500, L = 2150, first 250 ipsbehaviour poss- ips considerably complicated score.easiest first consider poss- ips plateau. start plateau search,115 ips, coincides large increase poss- ips, corresponding change50fiAn Empirical Analysis Search GSATregion small number ips increase score 1 regionlarge number ips made leave score unchanged. plateau,several sharp dips poss- ips. correspond ips increase 1score effected, seen Figure 1b. seems increasescore plateau, small number ways it. Also,dominance ips make change score graphically illustrates need\sideways" ips, need noted (Selman et al., 1992; Gent & Walsh,1993).Perhaps fascinating feature initial behaviour poss- ips.four well defined wedges starting 5, 16, 26, 57 ips, occasional sharp dips.wedges demonstrate behaviour analogous poss- ips plateau.plateau spans region ips typically change score: callregion H0 since hill-climbing typically makes zero change score. last wedgespans region H1 hill-climbing typically increases score 1, seenclearly Figure 1b. Figure 1b shows next three wedges (readingright left) span regions H2, H3 , H4 . transition onto plateau,transition region marked sharp increase poss- ips. Dipswedges represent unusual ips increase score characteristicvalue region, dips poss- ips plateau represent ipsincrease score possible. exact correlation seen clearly Figure 1b. Noteexperiment, region H change score j + 2 occur,change score ,1 all. addition, wedge poss- ips appears decayclose linearly. explained facts variable ipped longerappears poss- ips ( ipping back would decrease score), variablesposs- ips ipped independently other, new variables rarelyadded poss- ips consequence earlier ip. plateau, however,variable ipped change score, remains poss- ips since ippingback also change score.determine behaviour typical, generated 500 random 3-SAT problemsN=500 L=4.3N, ran 10 tries GSAT problem. Figure 2a showsmean percentage score2 Figure 2b presents mean percentage poss- ips togethermean change score ip. (The small discreteness figure duediscreteness Postscript's plotting.)average percentage score similar behaviour individual runFigure 1, naturally somewhat smoother. graph average poss- ips seems quitedifferent, expected neither observe sharply defined dipsposs- ips Figure 1b, sharply defined start wedges, sincehappen varying times. remarkable wedges consistent enoughvisible averaged 5,000 tries; smoothing wedges startplateau caused regions starting exactly time try.Figure 2 distinguish satisfiable unsatisfiable problems.current technique determining satisfiability 500 variable 3-SAT problemsfeasible time. instances able test, believe largej2. paper assign score 100% ips performed satisfying truthassignment already found.51fiGent & WalshMean percentage scoreMean change score1006597.543952192.50Mean percent poss-flips90-1201087.5004080120160200240flips04080120160200240flips(a) Mean score(b) Mean change score, poss- ipsFigure 2: Mean GSAT behaviour, N = 500, L = 4.3N, first 250 ipsdifferences Figure 2 seen possible plot satisfiable unsatisfiableproblems separately, remains interesting topic investigate future.Experiments values N ratio clauses variables demonstrated qualitatively similar behaviour. careful analysis shows remarkable factbehaviour qualitatively similar, quantitatively similar, simple linear dependency N. graphs similar Figure 2 plotted N x-axisscaled N, behaviour almost identical. illustrate this, Figure 3 shows meanpercentage score, percentage poss- ips, change score, N = 500, 750, 1000,L = 4.3N first 0.5N ips (250 ips N = 500). Figure 3a Figure 3bdemonstrate closeness scaling, extent may appear containone thick line. Figure 3b slight tendency different regions hill-climbingbecome better defined increasing N.figures presented reach early stage plateau search.investigate along plateau, performed experiments 100, 200, 300, 400,500 variables 0 2.5N ips.3 Figure 4a shows mean percentage scorecase, Figure 4b shows mean percentage poss- ips, magnified -axisclarity. figures demonstrate closeness scaling plateau.Figure 4b graphs quite close together Figure 4a. phases hillclimbing become much better defined increasing N. plateau search, althoughseparate lines distinguishable, difference always considerably less 1%total number variables.problems used experiments (random 3-SAT L=4.3N) believedunusually hard satisfiable probability approximately 12 . Neitherfacts appears relevant scaling GSAT's search. check performedsimilar range experiments ratio clauses variables 6. Although almostproblems unsatisfiable, observed exactly scaling behaviour. score3. 100 variables, 2.5N ips close optimal value Max- ips. However, experimentssuggested Max- ips may need vary quadratically larger N (Gent & Walsh, 1993).52fiAn Empirical Analysis Search GSATMean change scoreMean percentage score1006597.543952192.50Mean percent poss-flips90-1201087.5000.08N 0.16N 0.24N 0.32N 0.40N 0.48Nflips0.08N 0.16N 0.24N 0.32N 0.40N 0.48Nflips0(a) Mean score(b) Mean change score, poss- ipsFigure 3: Scaling mean GSAT behaviour, N = 500, 750, 1000, first 0.5N ipsMean percentage scoreMean percentage poss-flips10012.597.510957.592.55902.587.5000.4N0.8N1.2N1.6N2.0N2.4Nflips00.4N0.8N1.2N1.6N2.0N2.4Nflips(a) mean score, L = 4.3N(b) mean poss- ips, L = 4.3NFigure 4: Scaling mean GSAT behaviour, N = 100, 200, 300, 400, 500reach high value Figure 4a, expected, nevertheless showslinear scaling. plateau, mean value poss- ips lower before.observed behaviour L = 3N, almost problems satisfiable.score approaches 100% faster before, higher value poss- ips reachedplateau, decay value poss- ips seen Figure 4b seempresent.summarise, shown GSAT's hill-climbing goes several distinctphases, average behaviour certain important features scale linear fashionN. results provide considerable advance previous informal descriptionsGSAT's search.53fiGent & Walsh5. Numerical Conjecturessection, show detailed numerical conjectures made datapresented graphically x4 analysed numerically. divide analysis two parts:first deal plateau search, behaviour relatively simple, analysehill-climbing search.plateau, average score poss- ips seem decay exponentiallysimple linear dependency problem size. test this, performed regression analysisexperimental data, using models(x) = N (B , C e, AxN )P (x) = N (E + F e, DxN )(1)(2)x represents number ips, (x) average score ip x P (x) averagenumber possible ips. determine GSAT's behaviour plateau, analyseddata mean score, starting 0.4N ips, time plateau search always appearsstarted (see x5). experimental data fitted model well. Detailed resultsN = 500 given Table 1 three significant figures. values A, B, C changeslightly N, providing evidence scaling GSAT's behaviour. L= 3N asymptotic mean percentage score close 100% clauses satisfied,L = 4.3N approximately 99.3% clauses L = 6N approximately98.2% clauses. good fit also found mean poss- ips behaviour (see Table 2N = 500), except L = 3N, mean value poss- ips plateau mayconstant. seems L = 4.3N asymptotic value poss- ips 10% N6 5% N.important note behaviour analysed mean behavioursatisfiable unsatisfiable problems. likely individual problems exhibitsimilar behaviour different asymptotes, expect even satisfiable problemsyield mean score 100% asymptotically. Note N increases small errorpercentage terms may correspond large error actual score. result,predictions asymptotic score may inaccurate large N, large numbersips. experimentation necessary examine issues detail.L/N NBCR23 500 0.511 2.997 0.0428 0.9954.3 500 0.566 4.27 0.0772 0.9956 500 0.492 5.89 0.112 0.993Table 1: Regression results average score GSAT.44. value R2 number interval [0; 1] indicating well variance data explainedregression formula. 1 , R2 ratio variance data predicted value,variance data mean data. value R2 close 1 indicates regressionformula fits data well.54fiAn Empirical Analysis Search GSATL/N NEFR24.3 500 0.838 0.100 0.0348 0.9966 500 0.789 0.0502 0.0373 0.999Table 2: Regression results average poss- ips GSAT.also analysed GSAT's behaviour hill-climbing phase. Figure 1bshows regions ips increase score 4, 3, 2, 1.Analysis data suggested phase lasts roughly twice length previousone. motivates following conjectures: GSAT moves sequence regionsH j = :::; 3; 2; 1 majority ips increase score j ,length region H proportional 2, (except region H0 representsplateau search).investigate conjecture, analysed 50 tries 20 different problemsrandom 3-SAT problems N=500 L=4.3N. rarely observe ips Hincrease score less j , define H region first ipincreases score exactly j first ip increases score lessj (unless latter actually appears former, case H empty). Onesimple test conjecture compare total time spent H total timeend H ; predict ratio 12 . j = 1 4 mean standarddeviations ratio, length region shown Table 3.5 datasupports conjecture although j increases region slightly longer predicted.total length hill-climbing N=500 0.22N ips, N=100 0.23N.consistent scaling behaviour observed x4.jjjjjjjjRegionmean ratioclimbing|H10.486H20.513H30.564H40.574s.d. mean length|1120.051054.70.067229.50.095915.70.01617.00s.d.7.597.695.123.612.48Table 3: Comparative Absolute Lengths hill-climbing phasesconjecture appealing corollary. Namely, non-empty hillclimbing regions, average change score per ip hill-climbing is:1 1 + 1 2 + 1 3 + 1 4 + + 1 2:(3)248162follows mean gradient entire hill-climbing phase approximately 2.N=500, observed mean ratio change score per ip hill-climbing 1.945. data \All climbing" length start H0 .55fiGent & Walshstandard deviation 0.1. N=100, ratio 1.95 standard deviation0.2.model presented ignores ips H increase scorej . ips seen Figure 1b regions H3 H1. experiment 9.8% ipsH1 size 2 6.3% ips H2 size 3. However, ips size j + 2rare, forming 0.02% ips H1 H2 . conjecturedexponential decay similar H0 occurs H . is, conjectureaverage change number satisfied clauses ip x ip x + 1 H given by:jjjj+Exe, Dj N(4)might correspond model GSAT's search certain numberips size j + 1 region H , probability making j + 1 ip merelydependent number ips left; rest time, GSAT obliged makeip size j . data 1000 tries fitted model well, giving values R2 96.8%H1 97.5% H2 . regression gave estimates parameters of: D1 = 0:045,E1 = 0:25, D2 = 0:025, E2 = 0:15. surprisingly, since region H3 short,data noisy obtain better fit model (4) one linear decay.results support conjecture, experiments larger problems neededlengthen region H j 3.jjj6. Theoretical ConjecturesEmpirical results like given x5 used direct efforts analyse algorithmstheoretically. example, consider plateau region GSAT's search. model (1)applies also successful tries, asymptotic score L, giving(x) = L , C N e, AxNDifferentiating respect x get,dS (x) = C e, axN = L , (x)dxgradient good approximation , average size ip x. Hence,= L A, SN(x)experiments suggest downward ips +1 rareplateau. Thus, good (first order) approximation follows, prob(D = j )probability ip x size j .xxxXL=xjHence,=,Lxj prob(D = j ) = prob(D = 1)xprob(D = 1) = L A, SN(x)x56xfiAn Empirical Analysis Search GSATis, plateau probability making ip size +1 may directly proportional L , (x), average number clauses remaining unsatisfied inverselyproportional N, number variables. similar analysis result givenprob(D = j +1) hill-climbing region H , would explain model (4) proposedx5.theoretical conjecture correct, used show mean numberips successful tries proportional N ln N. investigation, experimental theoretical, needed determine accuracy prediction.conjectures section seen conjectures formal theoryGSAT's search might look like, useful determining results average runtime optimal setting parameter like Max- ips. addition,develop model GSAT's search prob(D = j ) related numberunsatisfied clauses N equation, experimentally observedexponential behaviour linear scaling score follow immediately.xjx7. Related WorkPrior introduction GSAT (Selman et al., 1992), closely related set procedures studied Gu (Gu, 1992). procedures different control structureGSAT allows them, instance, make sideways moves upwards movespossible. makes dicult compare results directly. Nevertheless,confident approach taken would apply equally well procedures,similar results could expected. Another \greedy algorithm satisfiability"analysed (Koutsoupias & Papadimitriou, 1992), results directlyapplicable because, unlike GSAT, disallows sideways ips.(Gent & Walsh, 1993) describe empirical study GenSAT, family procedures related GSAT. study focuses importance randomness, greedinesshill-climbing effectiveness procedures. addition, determineperformance depends parameters like Max-tries Max- ips. showed alsocertain variants GenSAT could outperform GSAT random problems. wouldinteresting perform similar analysis given closely relatedprocedures.GSAT closely related simulated annealing (van Laarhoven & Aarts, 1987)Metropolis algorithm, use greedy local search randomised methodallowing non-optimal ips. Theoretical work algorithms applied SATproblems, example (Jerrum, 1992; Jerrum & Sorkin, 1993), experimental studiesrelationship GSAT simulated annealing yet reached tentativeconclusions (Selman & Kautz, 1993b; Spears, 1993).Procedures like GSAT also successfully applied constraint satisfactionproblems satisfiability. example, (Minton, Johnston, Philips, & Laird, 1990)proposed greedy local search procedure performed well scheduling observationsHubble Space Telescope, constraint problems like million-queens,3-colourability. would interesting see results given map acrossnew problem domains.57fiGent & Walsh8. Conclusionsdescribed empirical study search GSAT, approximation proceduresatisfiability. performed detailed analysis two basic phases GSAT's search,initial period fast hill-climbing followed longer period plateau search.shown hill-climbing phases broken numberdistinct phases corresponding progressively slower climbing, phase lastingtwice long last. also shown that, certain well defined problem classes,average behaviour certain important features GSAT's search (the average scoreaverage branching rate given point) scale remarkably simple wayproblem size also demonstrated behaviour featuresmodelled well simple exponential decay, plateau hill-climbingphase. Finally, used experiments conjecture various properties (eg. probabilitymaking ip certain size) useful theoretical analysis GSAT.results illustrate carefully performed experiments used guide theory,computers increasingly important r^ole play analysis algorithms.Acknowledgementsresearch supported SERC Postdoctoral Fellowship first authorHCM Postdoctoral fellowship second. thank Alan Bundy, Ian Green,members Mathematical Reasoning Group constructive commentsquadrillion CPU cycles donated experiments SERC grantGR/H/23610. also thank Andrew Bremner, Judith Underwood, reviewersjournal help.ReferencesCheeseman, P., Kanefsky, B., & Taylor, W. (1991). really hard problems are.Proceedings 12th IJCAI, pp. 163{169. International Joint ConferenceArtificial Intelligence.Crawford, J., & Auton, L. (1993). Experimental results crossover point satisfiability problems. Proceedings Eleventh National Conference ArtificialIntelligence, pp. 21{27. AAAI Press/The MIT Press.Gent, I. P., & Walsh, T. (1993). Towards Understanding Hill-climbing ProceduresSAT. Proceedings Eleventh National Conference Artificial Intelligence,pp. 28{33. AAAI Press/The MIT Press.Gent, I. P., & Walsh, T. (1992). enigma SAT hill-climbing procedures. Researchpaper 605, Dept. Artificial Intelligence, University Edinburgh.Gu, J. (1992). Ecient local search large-scale satisfiability problems. SIGARTBulletin, 3 (1).58fiAn Empirical Analysis Search GSATHooker, J. N. (1993). Needed: empirical science algorithms. Tech. rep., GraduateSchool Industrial Administration, Carnegie Mellon University, Pittsburgh PA.Jerrum, M. (1992). Large cliques elude Metropolis process. Random StructuresAlgorithms, 3 (4), 347{359.Jerrum, M., & Sorkin, G. (1993). Simulated annealing graph bisection. Tech. rep.ECS-LFCS-93-260, Department Computer Science, University Edinburgh.Koutsoupias, E., & Papadimitriou, C. H. (1992). greedy algorithm satisfiability.Information Processing Letters, 43, 53{55.Larrabee, T., & Tsuji, Y. (1992). Evidence Satisfiability Threshold Random 3CNFFormulas. Tech. rep. UCSC-CRL-92-42, Baskin Center Computer EngineeringInformation Sciences, University California, Santa Cruz.McGeoch, C. (1986). Experimental Analysis Algorithms. Ph.D. thesis, Carnegie MellonUniversity. Also available CMU-CS-87-124.Minton, S., Johnston, M. D., Philips, A. B., & Laird, P. (1990). Solving large-scale constraint satisfaction scheduling problems using heuristic repair method.AAAI-90, Proceedings Eighth National Conference Artificial Intelligence, pp. 17{24. AAAI Press/MIT Press.Mitchell, D., Selman, B., & Levesque, H. (1992). Hard easy distributions SATproblems. Proceedings, 10th National Conference Artificial Intelligence. AAAIPress/The MIT Press.Selman, B., & Kautz, H. (1993a). Domain-independent extensions GSAT: Solving largestructured satisfiability problems. Proceedings, IJCAI-93. International Joint Conference Artificial Intelligence.Selman, B., & Kautz, H. (1993b). empirical study greedy local search satisfiabilitytesting. Proceedings Eleventh National Conference Artificial Intelligence,pp. 46{51. AAAI Press/The MIT Press.Selman, B., Levesque, H., & Mitchell, D. (1992). new method solving hard satisfiabilityproblems. Proceedings, 10th National Conference Artificial Intelligence. AAAIPress/The MIT Press.Spears, W. M. (1993). Simulated annealing hard satisfiability problems. Tech. rep.AIC-93-015, AI Center, Naval Research Laboratory.van Laarhoven, P., & Aarts, E. (1987). Simulated Annealing: Theory Applications. D.Reidel Publishing Company, Dordrecht, Holland.59fiJournal Artificial Intelligence Research 1 (1993) 109-138Submitted 7/93; published 12/93Decidable Reasoning Terminological KnowledgeRepresentation SystemsMartin BuchheitGerman Research Center Artificial Intelligence (DFKI)Stuhlsatzenhausweg 3, D-66123 Saarbrucken, GermanyFrancesco M. DoniniAndrea Schaerfbuchheit@dfki.uni-sb.dedonini@assi.dis.uniroma1.itaschaerf@assi.dis.uniroma1.itDipartimento di Informatica e SistemisticaUniversita di Roma \La Sapienza", Via Salaria 113, I-00198 Roma, ItalyAbstractTerminological knowledge representation systems (TKRSs) tools designingusing knowledge bases make use terminological languages (or concept languages).analyze theoretical point view TKRS whose capabilities go beyondones presently available TKRSs. new features studied, often required practicalapplications, summarized three main points. First, consider highly expressive terminological language, called ALCNR, including general complements concepts,number restrictions role conjunction. Second, allow express inclusion statements general concepts, terminological cycles particular case. Third,prove decidability number desirable TKRS-deduction services (like satisfiability,subsumption instance checking) sound, complete terminating calculusreasoning ALCNR-knowledge bases. calculus extends general techniqueconstraint systems. byproduct proof, get also result inclusionstatements ALCNR simulated terminological cycles, descriptive semanticsadopted.1. Introductiongeneral characteristic many proposed terminological knowledge representation systems(TKRSs) krypton (Brachman, Pigman Gilbert, & Levesque, 1985), nikl (Kaczmarek, Bates, & Robins, 1986), back (Quantz & Kindermann, 1990), loom (MacGregor &Bates, 1987), classic (Borgida, Brachman, McGuinness, & Alperin Resnick, 1989), kris(Baader & Hollunder, 1991), k-rep (Mays, Dionne, & Weida, 1991), others (see Rich,editor, 1991; Woods & Schmolze, 1992), made two different components. Informally speaking, first general schema concerning classes individualsrepresented, general properties mutual relationships, second(partial) instantiation schema, containing assertions relating either individualsclasses, individuals other. characteristic, mentioned proposalsinherit seminal TKRS kl-one (Brachman & Schmolze, 1985), shared alsoseveral proposals database models Abrial's (1974), candide (Beck, Gala, &Navathe, 1989), taxis (Mylopoulos, Bernstein, & Wong, 1980).Retrieving information actual knowledge bases (KBs) built using one systems deductive process involving schema (TBox) instantiation (ABox).c 1993 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.fiBuchheit, Donini, & Schaerffact, TBox set constraints possible ABoxes, contains intensionalinformation classes. information taken account answering queriesKB.realization use KB, TKRS provide mechanical solutionleast following problems (from point on, use word concept referclass):1. KB-satisfiability : ABox TBox consistent other? is,KB admit model? positive answer useful validation phase,negative answer used make inferences refutation-style. latterprecisely approach taken paper.2. Concept Satisfiability : given KB concept C , exist least onemodel KB assigning non-empty extension C ? importantrule meaningless concepts KB design phase, also processinguser's queries, eliminate parts query cannot contribute answer.3. Subsumption : given KB two concepts C D, C generalmodel KB? Subsumption detects implicit dependencies among conceptsKB.4. Instance Checking : given KB, individual concept C , instanceC model KB? Note retrieving individuals describedgiven concept (a query database lexicon) formulated set parallelinstance checkings.questions precisely characterized TKRS given semantics(see next section), defines models KB gives meaning expressionsKB. problems formalized, one start theoretical analysisthem, and|maybe independently|a search reasoning procedures accomplishingtasks. Completeness correctness procedures judged respect formalstatements problems.now, proposed systems give incomplete procedures solvingproblems 1{4, except kris1. is, inferences missed, cases withoutprecise semantical characterization ones are. designer user needs(more) complete reasoning, she/he must either write programs suitable programminglanguage (as database proposal Abrial, taxis), define appropriate inference rules completing inference capabilities system (as back, loom,classic). theoretical point view, several systems (e.g., loom) evenknown complete procedures ever exist|i.e., decidability correspondingproblems known.Recent research computational complexity subsumption uencemany TKRSs choice incomplete procedures. Brachman Levesque (1984)1. Also system classic complete, w.r.t. non-standard semantics treatmentindividuals. Complete reasoning w.r.t. standard semantics individuals provided, coNPhard (Lenzerini & Schaerf, 1991).110fiDecidable Reasoning Terminological KR Systemsstarted research analyzing complexity subsumption pure concept expressions, abstracting KBs (we call problem later paper pure subsumption). motivation focusing small problem pure subsumptionfundamental inference TKRS. turned pure subsumption tractable(i.e., worst-case polynomial-time solvable) simple languages, intractable slightextensions languages, subsequent research definitely confirmed (Nebel, 1988;Donini, Lenzerini, Nardi, & Nutt, 1991a, 1991b; Schmidt-Schau & Smolka, 1991; Donini,Hollunder, Lenzerini, Marchetti Spaccamela, Nardi, & Nutt, 1992). Also, beyond computational complexity, pure subsumption proved undecidable TKRSs U (Schild,1988), kl-one (Schmidt-Schau, 1989) nikl (Patel-Schneider, 1989).Note extending language results enhancing expressiveness, thereforeresult research could summarized as: TKRS language expressive,higher computational complexity reasoning language|as Levesque(1984) first noted. result interpreted two different ways, leading twodifferent TKRSs design philosophies:1. `General-purpose languages TKRSs intractable, even undecidable,tractable languages expressive enough practical interest'. Following interpretation, several TKRSs (such nikl, loom back) incompleteprocedures pure subsumption considered satisfactory (e.g., see (MacGregor &Brill, 1992) loom). completeness abandoned basic subproblem,completeness overall reasoning procedures issue anymore; issuesarise, compare incomplete procedures (Heinsohn, Kudenko, Nebel,& Profitlich, 1992), judge procedure \complete enough" (MacGregor,1991). practical tool, inference rules used systems achieveexpected behavior KB w.r.t. information contained it.2. `A TKRS (by definition) general-purpose, hence must provide tractablecomplete reasoning user'. Following line, TKRSs (such kryptonclassic) provide limited tractable languages expressing concepts, following\small-can-be-beautiful" approach (see Patel-Schneider, 1984). gapexpressible TKRS language needed expressedapplication filled user, (sort of) programming inference rules.course, usual problems present program development debugging arise(McGuinness, 1992).common approaches user must cope incomplete reasoning.difference former approach, burden regaining useful yet missedinferences mostly left developers TKRS (and user supposed specify\complete enough"), latter mainly left user.perfectly reasonable approaches practical context, incomplete proceduresspecialized programs often used deal intractable problems. opinionincomplete procedures provisional answer problem|the best possiblenow. order improve answer, theoretical analysis general problems1{4 done.Previous theoretical results deal problems 1{4 full generality.example, problems studied (Nebel, 1990, Chapter 4), incomplete111fiBuchheit, Donini, & Schaerfprocedures given, cycles considered. (Donini, Lenzerini, Nardi, & Schaerf,1993; Schaerf, 1993a) complexity instance checking analyzed, KBswithout TBox treated. Instance checking also analyzed (Vilain, 1991),addressing part problem performed parsing.addition, think expressiveness actual systems enhancedmaking terminological cycles (see Nebel, 1990, Chapter 5) available TKRSs.feature undoubtable practical interest (MacGregor, 1992), yet present TKRSsapproximate cycles, using forward inference rules (as back, classic, loom).opinion, order make terminological cycles fully available complete TKRSs,theoretical investigation still needed.Previous theoretical work cycles done (Baader, 1990a, 1990b; Baader, Burkert,Hollunder, Nutt, & Siekmann, 1990; Dionne, Mays, & Oles, 1992, 1993; Nebel, 1990, 1991;Schild, 1991), considering KBs formed TBox alone. Moreover, approachesdeal number restrictions (except Nebel, 1990, Section 5.3.5) |a basic featurealready provided TKRSs| techniques used seem easily extensiblereasoning ABoxes. compare detail several works Section 4.paper, propose TKRS equipped highly expressive language, including constructors often required practical applications, prove decidability problems1{4. particular, system uses language ALCNR, supports general complements concepts, number restrictions role conjunction. Moreover, system allowsone express inclusion statements general concepts and, particular case,terminological cycles. prove decidability means suitable calculus, developed extending well established framework constraint systems (see Donini et al.,1991a; Schmidt-Schau & Smolka, 1991), thus exploiting uniform approach reasoningTKRSs. Moreover, calculus easily turned decision procedure.paper organized follows. Section 2 introduce language,give Tarski-style extensional semantics, commonly used. Usingsemantics, establish relationships problems 1{4 allow us concentrateKB-satisfiability only. Section 3 provide calculus KB-satisfiability, showcorrectness termination calculus. Hence, conclude KB-satisfiabilitydecidable ALCNR, main result paper. Section 4 compareapproach previous results decidable TKRSs, establish equivalencegeneral (cyclic) inclusion statements general concept definitions using descriptivesemantics. Finally, discuss detail several practical issues related resultsSection 5.2. Preliminariessection first present basic notions regarding concept languages.describe knowledge bases built using concept languages, reasoning servicesmust provided extracting information knowledge bases.2.1 Concept Languagesconcept languages, concepts represent classes objects domain interest,roles represent binary relations objects. Complex concepts roles112fiDecidable Reasoning Terminological KR Systemsdefined means suitable constructors applied concept names role names.particular, concepts roles ALCNR formed means following syntax(where Pi (for = 1; : : :; k) denotes role name, C denote arbitrary concepts,R arbitrary role):C; ,! j>j?j(C u D) j(C D) j:C j8R.C j9R.C j( n R) j ( n R)R ,! P1 u u Pk(concept name)(top concept)(bottom concept)(conjunction)(disjunction)(complement)(universal quantification)(existential quantification)(number restrictions)(role conjunction)confusion arises drop brackets around conjunctions disjunctions.interpret concepts subsets domain roles binary relations domain.precisely, interpretation = (I ; ) consists nonempty set (the domain) function (the extension function ), maps every concept subsetevery role subset . interpretation concept namesrole names thus restricted AI , P , respectively. Moreover,interpretation complex concepts roles must satisfy following equations (]fgdenotes cardinality set):>I =?I = ;(C u D)I(C D)I(:C )I(8R.C )I(9R.C )I( n R)I( n R)I(P1 u u Pk )I========C \ DIC [ DIn Cfd1 2 j 8d2 : (d1; d2) 2 RI ! d2 2 C gfd1 2 j 9d2 : (d1; d2) 2 RI ^ d2 2 C gfd1 2 j ]fd2 j (d1; d2) 2 RI g ngfd1 2 j ]fd2 j (d1; d2) 2 RI g ngP1I \ \ PkI2.2 Knowledge Bases(1)knowledge base built means concept languages generally formed two components: intensional one, called TBox, extensional one, called ABox.first turn attention TBox. said before, intensional level specifies properties concepts interest particular application. Syntactically,properties expressed terms call inclusion statements. inclusion113fiBuchheit, Donini, & Schaerfstatement (or simply inclusion) formCvDC two arbitrary ALCNR-concepts. Intuitively, statement specifiesevery instance C also instance D. precisely, interpretation satisfiesinclusion C v C DI .TBox finite set inclusions. interpretation model TBoxsatisfies inclusions .general, TKRSs provide user mechanisms stating concept introductions(e.g., Nebel, 1990, Section 3.2) form =: (concept definition, interpreted setequality), _ (concept specification, interpreted set inclusion), restrictionsleft-hand side concept must concept name, concept nameone introduction allowed, terminological cycles allowed, i.e.,concept name may occur|neither directly indirectly|within introduction.restrictions make possible substitute occurrence defined conceptdefinition.impose restrictions form inclusions, obtaining statementssyntactically expressive concept introductions. particular, definitionform =: expressed system using pair inclusions vv specification form _ simply expressed v D.Conversely, inclusion form C v D, C arbitrary concepts, cannotexpressed concept introductions. Moreover, cyclic inclusions allowedstatements, realizing terminological cycles.shown (Nebel, 1991), least three types semantics terminological cycles, namely least fixpoint, greatest fixpoint, descriptive semantics.Fixpoint semantics choose particular models among set interpretations satisfystatement form =: D. models chosen least greatest fixpointequation. descriptive semantics instead considers interpretationssatisfy statement (i.e., fixpoints) models.However, fixpoint semantics naturally apply fixpoint statements like =: D,\function" A, i.e., may appear D, obvious wayextend general inclusions. addition, since language includes constructorcomplement general concepts, \function" may monotone, thereforeleast greatest fixpoints may unique. Whether existsdefinitional semantics suitable cyclic definitions expressive languages stillunclear.Conversely, descriptive semantics interprets statements restricting setpossible models, definitional import. Although completely satisfactorypractical cases (Baader, 1990b; Nebel, 1991), descriptive semantics consideredappropriate one general cyclic statements powerful concept languages.Hence, seems suitable extended case exactly oneadopted above.Observe decision put general inclusions TBox standard one.fact, TKRS like krypton statements put ABox. However, conceive114fiDecidable Reasoning Terminological KR Systemsinclusions generalization traditional TBox statements: acyclic concept introductions,definitional import, perfectly expressed inclusions; cyclic conceptintroductions expressed well, descriptive semantics adopted. Therefore,believe inclusions part TBox.Notice role conjunction allows one express practical feature subroles.example, role ADOPTEDCHILD written CHILD u ADOPTEDCHILD0, ADOPTEDCHILD' role name, making subrole CHILD. Following idea, every hierarchyrole names rephrased set role conjunctions, vice versa.Actual systems usually provide construction hierarchies roles meansrole introductions (i.e., statements form P =: R P _ R) TBox. However,simple language roles, cyclic definitions roles always reduced acyclicdefinitions, explained (Nebel, 1990, Sec.5.3.1). role definitions acyclic, onealways substitute every concept role name definition, obtainingequivalent concept. Therefore, consider role definitions paper,conceive TBox set concept inclusions.Even so, worth notice concept inclusions express knowledge roles.particular, domain range restrictions roles expressed, way similarone (Catarci & Lenzerini, 1993). Restricting domain role R concept Crange concept done two inclusions9R.> v C; > v 8R.Dstraightforward show interpretation satisfies two inclusions,RI C .Combining subroles domain range restrictions also possible partiallyexpress constructor role restriction, present various proposals (e.g.,language FL Brachman & Levesque, 1984). Role restriction, written R : C ,defined (R : C )I = f(d1; d2) 2 j (d1; d2) 2 RI ^ d2 2 C g. examplerole DAUGHTER, formulated CHILD:Female, partially simulatedCHILD u DAUGHTER0, inclusion > v 8DAUGHTER0.Female. However, simulationwould complete number restrictions: E.g., mother least three daughters,know least three female children; instead know threefemale children cannot infer three daughters.turn attention extensional level, i.e., ABox. ABoxessentially allows one specify instance-of relations individuals concepts,pairs individuals roles.Let alphabet symbols, called individuals. Instance-of relationships expressed terms membership assertions form:C (a);R(a; b);b individuals, C ALCNR-concept, R ALCNR-role. Intuitively, first form states instance C , whereas second form statesrelated b means role R.115fiBuchheit, Donini, & Schaerforder assign meaning membership assertions, extension functioninterpretation extended individuals mapping elementsway aI 6= bI 6= b. property called Unique Name Assumption; ensuresdifferent individuals interpreted different objects.interpretation satisfies assertion C (a) aI 2 C , satisfies R(a; b)(a ; bI ) 2 RI . ABox finite set membership assertions. model ABoxsatisfies assertions A.ALCNR-knowledge base pair = hT ; Ai TBoxABox. interpretation model model model A.formally define problems 1{4 mentioned introduction. LetALCNR-knowledge base.1. KB-satisfiability : satisfiable, model;2. Concept Satisfiability : C satisfiable w.r.t , exists modelC 6= ;;3. Subsumption : C subsumed w.r.t. , C DI every model ;4. Instance Checking : instance C , written j= C (a), assertion C (a)satisfied every model .(Nebel, 1990, Sec.3.3.2) shown ABox plays active role checkingconcept satisfiability subsumption. particular, Nebel shows ABox (subjectsatisfiability) replaced empty one without affecting resultservices. Actually, (Nebel, 1990), property stated language less expressive ALCNR. However, easy show extends ALCNR. importantremark property valid concept languages. fact,languages include constructors refer individuals concept language, e.g., constructor one-of (Borgida et al., 1989) forms concept setenumerated individuals. concept language includes constructor individualsTBox interact individuals ABox, shown (Schaerf, 1993b).consequence, concept satisfiability subsumption depend also ABox.Example 2.1 Consider following knowledge base = hT ; Ai:= f9TEACHES.Course v (Student u 9DEGREE.BS) Prof;Prof v 9DEGREE.MS;9DEGREE.MS v 9DEGREE.BS;MS u BS v ?g= fTEACHES(john; cs156); ( 1 DEGREE)(john); Course(cs156)gfragment hypothetical knowledge base describing organization university.first inclusion, instance, states persons teaching course either graduatestudents (students BS degree) professors. easy see satisfiable.example, following interpretation satisfies inclusions assertions116fiDecidable Reasoning Terminological KR SystemsA, therefore model := fjohn; cs156; csbg; johnI = john; cs156I = cs156StudentI = fjohng; ProfI = ;; CourseI = fcs156g; BSI = fcsbgMSI = ;; TEACHESI = f(john; cs156)g; DEGREEI = f(john; csb)gdescribed interpretation giving , valuesconcept names role names. straightforward see values complexconcepts roles uniquely determined imposing must satisfy Equations 1page 113.Notice possible draw several non-trivial conclusions . example,infer j= Student(john). Intuitively shown follows: John teachescourse, thus either student BS professor. can't professorsince professors least two degrees (BS MS) one, thereforestudent.Given previous semantics, problems 1{4 reduced KB-satisfiability(or complement) linear time. fact, given knowledge base = hT ; Ai, twoconcepts C D, individual a, individual b appearing , followingequivalences hold:C satisfiable w:r:t iff hT ; [ fC (b)gi satisfiable:C subsumed w:r:t: iff hT ; [ f(C u :D)(b)gi satisfiable:j= C (a) iff hT ; [ f(:C )(a)gi satisfiable:slightly different form equivalences given (Hollunder, 1990).equivalences given straightforward consequence ones given Hollunder.However, equivalences valid languages including constructors referindividuals concept language. equivalences reasoning serviceslanguages studied (Schaerf, 1993b).Based equivalences, next section concentrate KBsatisfiability.3. Decidability Resultsection provide calculus deciding KB-satisfiability. particular, Subsection 3.1 present calculus state correctness. Then, Subsection 3.2,prove termination calculus. sucient assess decidabilityproblems 1{4, thanks relationships four problems.3.1 calculus correctnessmethod makes use notion constraint system (Donini et al., 1991a; SchmidtSchau & Smolka, 1991; Donini, Lenzerini, Nardi, & Schaerf, 1991c), basedtableaux-like calculus (Fitting, 1990) tries build model logical formulacorresponding KB.117fiBuchheit, Donini, & Schaerfintroduce alphabet variable symbols V together well-founded totalordering `' V . alphabet V disjoint ones defined far.purpose ordering become clear later. elements V denotedletters x; y; z; w. point on, use term object abstraction individualvariable (i.e., object element [ V ). Objects denoted symbolss; and, Section 2, individuals denoted a; b.constraint syntactic entity one forms:s: C; sPt;8x.x: C; =6 : t;C concept P role name. Concepts assumed simple, i.e.,complements contain form :A, concept name. ArbitraryALCNR-concepts rewritten equivalent simple concepts linear time (Doniniet al., 1991a). constraint system finite nonempty set constraints.Given interpretation , define -assignment ff function maps everyvariable V element , every individual aI (i.e., ff(a) = aI2 O).pair (I ; ff) satisfies: constraint s: C ff(s) 2 C , constraint sPt (ff(s); ff(t))2 P , constraint =6 ff(s) 6= ff(t), finally, constraint 8x.x: C C =(notice ff play role case). constraint system satisfiablepair (I ; ff) satisfies every constraint .ALCNR-knowledge base = hT ; Ai translated constraint systemreplacing every inclusion C v 2 constraint 8x.x: :C D, everymembership assertion C (a) constraint a: C , every R(a; b) constraintsaP1 b; : : :; aPk b R = P1 u : : : u Pk , including constraint =6 : b every pair (a; b)individuals appearing A. easy see satisfiablesatisfiable.order check constraint system satisfiability, technique adds constraintseither evident contradiction generated interpretation satisfyingobtained resulting system. Constraints added basis suitable setso-called propagation rules.providing rules, need additional definitions. Let constraintsystem R = P1 u : : : u Pk (k 1) role. say R-successorsP1 t; : : :; sPk . say direct successor role R,R-successor s. call direct predecessor inverse relation direct successor.clear context omit it. Moreover, denote successor transitiveclosure relation direct successor, denote predecessor inverse.assume variables introduced constraint system according ordering`'. means, introduced constraint system x variables xalready .denote [x=s] constraint system obtained replacing occurrencevariable x object s.say separated constraint =6 : .Given constraint system object s, define function (; ) follows:(S; s) := fC j s: C 2 g. Moreover, say two variables x -equivalent,118fiDecidable Reasoning Terminological KR Systemswritten x , (S; x) = (S; ). Intuitively, two S-equivalent variables representelement potential interpretation built rules, unless separated.propagation rules are:1. !u fs: C1; s: C2g [1. s: C1 u C2 ,2. s: C1 s: C22. !t fs: Dg [1. s: C1 C2 ,2. neither s: C1 s: C2 ,3. = C1 = C23. !8 ft: C g [1. s: 8R.C ,2. R-successor s,3. t: C4. !9 fsP1 y; : : :; sPk y; : C g [1. s: 9R.C ,2. R = P1 u : : : u Pk ,3. new variable,4. R-successor t: C ,5. variable variable w w w5. ! fsP1 yi ; : : :; sPk yi j 2 1::ng [ fyi 6=: yj j i; j 2 1::n; 6= j g [1. s: ( n R) ,2. R = P1 u : : : u Pk ,3. y1 ; : : :; yn new variables,4. exist n pairwise separated R-successors ,5. variable variable w w w6. ! [y=t]1. s: ( n R) ,2. n R-successors ,3. y; two R-successors separated7. !8x fs: C g [1. 8x.x: C ,2. appears ,3. s: C .call rules !t ! nondeterministic rules, since applieddifferent ways constraint system (intuitively, correspond branchingrules tableaux). rules called deterministic rules. Moreover, callrules !9 ! generating rules, since introduce new variables constraintsystem. rules called nongenerating ones.119fiBuchheit, Donini, & Schaerfuse condition based -equivalence relation generating rules(condition 5) related goal keeping constraint system finite even presencepotentially infinite chains applications generating rules. role become clearerlater paper.One verify rules always applied system either presencegiven constraint s: C (condition 1), or, case !8x-rule,presence object . confusion arises, say rule appliedconstraint s: C object (instead saying applied constraintsystem ).Proposition 3.1 (Invariance) Let 0 constraint systems. Then:1. 0 obtained application deterministic rule, satisfiable0 satisfiable.2. 0 obtained application nondeterministic rule, satisfiable 0 satisfiable. Conversely, satisfiable nondeterministic ruleapplicable object , applied way yieldssatisfiable constraint system.Proof. proof mainly rephrasing typical soundness proofs tableaux methods (e.g., Fitting, 1990, Lemma 6.3.2). non-standard constructors numberrestrictions.1. \(" Considering deterministic rules one directly check subset 0.obvious satisfiable 0 satisfiable.\)" order show 0 satisfiable case consider turnpossible deterministic rule application leading 0. assume (I ; ff)satisfies .!u -rule applied s: C1 u C2 , 0 = [ fs: C1; s: C2g. Since (I ; ff)satisfies s: C1 u C2, (I ; ff) satisfies s: C1 s: C2 therefore 0.!8-rule applied s: 8R.C , must R-successor0 = [ft: C g. Since (I ; ff) satisfies , holds (ff(s); ff(t)) 2 RI . Since (I ; ff) satisfiess: 8R.C , holds ff(t) 2 C . (I ; ff) satisfies t: C therefore 0.!8x-rule applied presence 8x.x: C , 0 =[ fs: C g. Since (I ; ff) satisfies holds C = . Therefore ff(s) 2 C(I ; ff) satisfies 0 .!9 -rule applied s: 9R.C , 0 = [ fsP1 y; : : :; sPk y; : C g. Since (I ; ff)satisfies , exists (ff(s); d) 2 RI 2 C . define -assignmentff0 ff0 (y) := ff0(t) := ff(t) 6= . easy show (I ; ff0) satisfies 0.! -rule applied s: ( n R), 0 = [ fsP1 yi ; : : :; sPk yi j 2 1::ng [fyi 6=: yj j i; j 2 1::n; 6= j g. Since (I ; ff) satisfies , exist n distinct elementsd1; : : :; dn 2 (ff(s); di) 2 RI . define -assignment ff0 ff0 (yi) := di2 1::n ff0 (t) := ff(t) 62 fy1 ; : : :; yn g. easy show (I ; ff0) satisfies 0.2. \(" Assume 0 satisfied (I ; ff0). show also satisfiable. 0obtained application !t -rule, subset 0 thereforesatisfied (I ; ff0).120fiDecidable Reasoning Terminological KR Systems0 obtained application ! -rule s: ( n R) ,y; 0 = [y=t]. define -assignment ff ff(y ) := ff0 (t)ff(v ) := ff0(v ) every object v v 6= y. Obviously (I ; ff) satisfies .\)" suppose satisfied (I ; ff) nondeterministic rule applicableobject s.!t -rule applicable s: C1 C2 then, since satisfiable, ff(s) 2 (C1 C2)I .follows either ff(s) 2 C1I ff(s) 2 C2I (or both). Hence, !t -rule obviouslyapplied way (I ; ff) satisfies resulting constraint system 0.! -rule applicable s: ( n R), then|since (I ; ff) satisfies |it holdsff(s) 2 ( n R)I therefore set fd 2 j (ff(s); d) 2 RI g n elements.hand, n R-successors R-successor(ff(s); ff(t)) 2 RI . Thus, conclude Pigeonhole Principle (see e.g.,Lewis & Papadimitriou, 1981, page 26) exist least :two R-successors t; t0ff(t) = ff(t0 ). Since (I ; ff) satisfies , constraint 6= t0 . Thereforeone two must variable, let's say t0 = . obviously (I ; ff) satisfies [y=t].Given constraint system , one rule might applicable it. definefollowing strategy application rules:1. apply rule variable rule applicable individuals;2. apply rule variable x rule applicable variable x;3. apply generating rules nongenerating rule applicable.strategy ensures variables processed one time accordingordering `'.point on, assume rules always applied according strategyalways start constraint system coming ALCNR-knowledgebase . following lemma direct consequence assumptions.Lemma 3.2 (Stability) Let constraint system x variable . Letgenerating rule applicable x according strategy. Let 0 constraint systemderivable sequence (possibly empty) applications rules.1. rule applicable 0 variable x2. (S; x) = (S 0; x)3. variable x variable 0, i.e., variablesubstituted another variable constant.1. contradiction: Suppose S0 ! S1 ! ! Sn 0, 2ft; u; 9; 8; ; ; 8xg rule applicable variable x 0.exists minimal i, n, case Si . Note 6= 0;fact, strategy, rule applicable x rule applicable .rule applicable variable z z x S0; : : :; Si,1. followsSi,1 Si rule applied x variable w x w. exhaustiveProof.121fiBuchheit, Donini, & Schaerfanalysis rules see that|whichever rule applied Si,1 Si |no newconstraint form : C yRz added Si,1 , therefore rule applicableSi , contradicting assumption.2. contradiction: Suppose (S; x) 6= (S 0; x). Call direct predecessor x,rule must applied either x itself. Obviously x, thereforeformer case cannot point 1. case analysis shows rulesapplied x generating ones !8 ! rules.rules add new constraints direct successors x xtherefore change (; x).3. follows point 1. strategy.Lemma 3.2 proves variable x direct successor, (; x) stable,i.e., change subsequent applications rules. fact, variabledirect successor means generating rule applied it, therefore(Lemma 3.2.2) point (; x) change.constraint system complete propagation rule applies it. complete systemderived system also called completion . clash constraint systemone following forms:fs: ?gfs: A; s: :Ag, concept name.fs: ( n R)g [ fsP1: ti ; : : :; sPk ti j 2 1::n + 1g[ fti =6 tj j i; j 2 1::n + 1; =6 j g,R = P1 u : : : u Pk .clash evidently unsatisfiable constraint system. example, last caserepresents situation object at-most restriction set Rsuccessors cannot identified (either individualscreated at-least restrictions).constraint system containing clash obviously unsatisfiable. purposecalculus generate completions, look presence clashes inside.completion contains clash, prove always possible constructmodel basis . looking technical details proof, let usconsider example application calculus checking satisfiability.Example 3.3 Consider following knowledge base = hT ; Ai:= fItalian v 9FRIEND.Italiang= fFRIEND(peter; susan);8FRIEND.:Italian(peter);9FRIEND.Italian(susan)gcorresponding constraint system is:= f8x.x: :Italian 9FRIEND.Italian;peterFRIENDsusan;122fiDecidable Reasoning Terminological KR Systems89:.:.g;peter: FRIEND Italiansusan: FRIEND Italianpeter = susan6sequence applications propagation rules follows:S1 = [ fsusan: :Italiang (!8-rule)S2 = S1 [ fpeter: :Italian 9FRIEND.Italiang (!8x-rule)S3 = S2 [ fsusan: :Italian 9FRIEND.Italiang (!8x-rule)S4 = S3 [ fpeter: :Italiang (!t -rule)S5 = S4 [ fsusanFRIENDx; x: Italiang (!9 -rule)S6 = S5 [ fx: :Italian 9FRIEND.Italiang (!8x-rule)S7 = S6 [ fx: 9FRIEND.Italiang (!t-rule)S8 = S7 [ fxFRIENDy; y: Italiang (!9-rule)S9 = S8 [ fy: :Italian 9FRIEND.Italiang (!8x-rule)S10 = S9 [ fy: 9FRIEND.Italiang (!t -rule)One verify S10 complete clash-free constraint system. particular, !9 rule applicable . fact, since x S10 condition 5 satisfied. S10 onebuild interpretation , follows (again, give interpretation conceptrole names):= fpeter; susan; x; ygpeterI = peter, susanI = susan, ff(x) = x, ff(y) = y,ItalianI = fx; ygFRIENDI = f(peter; susan); (susan; x); (x; y); (y; y)geasy see indeed model .order prove always possible obtain interpretation completeclash-free constraint system need additional notions. Let constraint systemx, w variables . call w witness x three following conditions hold:1. x w2. w x3. variable z z w z satisfies conditions 1. 2., i.e., wleast variable w.r.t. satisfying conditions 1. 2.say x blocked (by w) x witness (w) . following lemma statesproperty witnesses.Lemma 3.4 Let constraint system, x variable . x blocked1. x direct successor2. x exactly one witness.123fiBuchheit, Donini, & Schaerf1. contradiction: Suppose x blocked xPy .completion process leading generating rule must applied x system0. follows definition rules 0 every variable w xx6s w. Lemma 3.2 know, constraint system derivable0 every w x also x6s w. Hence witness x ,contradicting hypothesis x blocked.2. follows directly condition 3. witness.consequence Lemma 3.4, constraint system , w1 witness x w1cannot witness itself, since relations `' -equivalence transitive.uniqueness witness blocked variable important defining followingparticular interpretation .Let constraint system. define canonical interpretation canonical -assignment ffS follows:Proof.01.2.3.4.:= fs j object gffS (s) :=2 AIS s:(s; t) 2 P(a) sPt(b) blocked variable, w witness wPt .call (s; t) P-role-pair (s; t) 2 P , call (s; t) role-pair(s; t) P-role-pair role P . call role-pair explicit comes case4.(a) definition canonical interpretation call implicit comescase 4.(b).Lemma 3.4 obvious role-pair cannot explicit implicit.Moreover, variable implicit role-pair role-pairs implicitcome exactly one witness, stated following lemma.Lemma 3.5 Let completion x variable . Let canonical interpretation . x implicit role-pair (x; ),1. role-pairs x implicit2. exactly one witness w x roles P P -rolepairs (x,y) x, constraint wPy .first statement follows Lemma 3.4 (point 1 ). second statement followsLemma 3.4 (point 2 ) together definition .machinery needed prove main theorem subsection.Proof.Theorem 3.6 Let complete constraint system. contains clashsatisfiable.124fiDecidable Reasoning Terminological KR SystemsProof. Let ffS canonical interpretation canonical -assignment .We: prove pair (IS ; ffS ) satisfies every constraint c . c form sPt6= t, (IS ; ffS ) satisfies definition :and ffS . Considering ! -rule! -rule see constraint form =6 . c forms: C , show induction structure C 2 C .first consider base cases. C concept name, 2 C definition. C = >, obviously 2 >IS . case C = ? cannot occur sinceclash-free.Next analyze turn possible complex concept C . C form :C1C1 concept name since concepts simple. constraint s: C1since clash-free. 62 C1IS , is, 2 n C1IS . Hence 2 (:C1)IS .C form C1 u C2 (since complete) s: C1 s: C2 .induction hypothesis, 2 C1IS 2 C2IS . Hence 2 (C1 u C2)IS .C form C1 C2 (since complete) either s: C1 s: C2. induction hypothesis, either 2 C1IS 2 C2IS . Hence 2 (C1 C2)IS .C form 8R.D, show (s; t) 2 RIS holds2 DIS . (s; t) 2 RIS , according Lemma 3.5 two cases occur. EitherR-successor blocked witness w R-successor w .first case t: must also since complete. induction hypothesis2 DIS . second case definition witness, w: 8R.Dcompleteness , t: must . induction hypothesis2 DIS .C form 9R.D show exists 2 (s; t) 2 RIS2 DIS . Since complete, either R-successort: , variable blocked witness w . first case, inductionhypothesis definition , 2 DIS (s; t) 2 RIS . second casew: 9R.D . Since w cannot blocked complete,R-successor w t: . induction hypothesis2 DIS definition (s; t) 2 RIS .C form ( n R) show goal contradiction. Assume 62 (n R)IS . exist atleast n + 1 distinct objects t1 ; : : :; tn+1 (s; ti ) 2 RIS ; 21::n + 1. means that, since R = P1 u : : : u Pk , pairs (s; ti) 2 PjIS ,2 1::n + 1 j 2 1::k. according Lemma 3.5 one two following cases mustoccur. Either sPj ti j 2 1::k; 2 1::n + 1 exists witness wwPiti j 2 1::k 2 1::n + 1 . first case ! -ruleapplicable completeness. :This means ti 's pairwise separated,i.e., contains constraints ti 6= tj ; i; j 2 1::n + 1; 6= j . contradicts factclash-free. second case leads analogous contradiction.C form ( n R) show goal contradiction. Assume 62 (n R)IS . exist atmost < n (m possibly 0) distinct objects t1; : : :; tm(s; ti ) 2 RIS ; 2 1::m. consider two cases. First case: blocked. Since R-successors , ! -rule applicable s.contradicts fact complete. Second case: blocked witness w .Since R-successors w , ! -rule applicable w. leadscontradiction.125fiBuchheit, Donini, & Schaerfc form 8x.x: then, since complete, object , t:|and, previous cases, 2 DIS . Therefore, pair (IS ; ffS ) satisfies 8x.x: D.Finally, since (IS ; ffS ) satisfies constraints , (IS ; ffS ) satisfies .Theorem 3.7 (Correctness) constraint system satisfiable existsleast one clash-free completion .\(" Follows immediately Theorem 3.6. \)" Clearly, system containingclash unsatisfiable. every completion unsatisfiable, Proposition 3.1, unsatisfiable.Proof.3.2 Termination complexity calculusGiven constraint system , call nS number concepts appearing , includingalso concepts appearing substring another concept. Notice nS boundedlength string expressing .Lemma 3.8 Let constraint system let 0 derived meanspropagation rules. set variables 0 including 2nS variablesleast two variables x,y x .0constraint x: C 2 0 may contain concepts constraint system .Since nS concepts, given variable x cannot 2nS differentsets constraints x: C 0 .Proof.Lemma 3.9 Let constraint system let 0 constraint system derivedapplying propagation rules given strategy. Then, 02nS non-blocked variables.Suppose 2nS + 1 non-blocked variables. Lemma 3.8, know0 least two variables y1 , y2 y1 y2 . Obviously either y1 y2y2 y1 holds; suppose y1 y2 . definitions witness blocked either y1witness y2 exists variable y3 y3 y1 y3 witness y2 .cases y2 blocked, contradicting hypothesis.Proof.Theorem 3.10 (Termination space complexity) Let ALCNR-knowledgebase let n size. Every completion finite size O(24n ).Let completion . Lemma 3.9 follows 2nnon-blocked variables . Therefore 2n total variables ,maximum number direct successors variable .Observe bounded number 9R.C concepts (at n) plus sumnumbers appearing number restrictions. Since numbers expressed binary,sum bounded 2n . Hence, 2n + n. Since number individuals alsobounded n, total number objects (2n + n) (2n + n) (2n + n),is, O(22n).Proof.126fiDecidable Reasoning Terminological KR Systemsnumber different constraints form s: C , 8x.x: C objectinvolved bounded n, constraint size linear n. Hence, total sizeconstraints bounded n n 22n , O(23n).number constraints form sPt, =6 : bounded (22n)2 = 24n,constraint constant size.conclusion, size O(24n).Notice one coarse upper bound, obtained theoretical purposes.practical cases expect actual size much smaller that. example,numbers involved number restrictions either expressed unary notation,limited constant (the latter reasonable restriction practical systems)argumentation analogous one would lead bound 23n .Theorem 3.11 (Decidability) Given ALCNR-knowledge base , checking whethersatisfiable decidable problem.follows Theorems 3.7 3.10 fact satisfiablesatisfiable.refine theorem, giving tighter bounds time requireddecide satisfiability.Proof.Theorem 3.12 (Time complexity) Given ALCNR-knowledge base , checkingwhether satisfiable done nondeterministic exponential time.order prove claim sucient show completion obtainedexponential number applications rules. Since number constraintscompletion exponential (Theorem 3.10) rule, ! -rule, adds newconstraints constraint system, follows rules appliedexponential number times. Regarding ! -rule, applied objectmany times number direct successors. Since number exponential(if numbers coded binary) w.r.t. size knowledge base, claim follows.lower bound complexity KB-satisfiability obtained exploiting previousresults language ALC , sublanguage ALCNR includenumber restrictions role conjunction. know McAllester (1991), (independently) observation Nutt (1992) KB-satisfiability ALC -knowledge basesEXPTIME-hard (see (Garey & Johnson, 1979, page 183) definition) hencehard ALCNR-knowledge bases, too. Hence, expect find algorithmsolving problem polynomial space, unless PSPACE=EXPTIME. Therefore,expect substantially improve space complexity calculus, already worksexponential space. discuss possible improvements time complexity.proposed calculus works nondeterministic exponential time, hence improvesone proposed (Buchheit, Donini, & Schaerf, 1993, Sec.4), works deterministic double exponential time. key improvement showed KBmodel model exponential size. However, may arguedis, calculus cannot yet turned practical procedure, since procedure would simply simulate nondeterminism second level exponentiality, resultingProof.127fiBuchheit, Donini, & Schaerfdouble exponential time procedure. However, different combinations conceptsexponentially many (this cardinality powerset set concepts). Hence, double exponential time procedure wastes time re-analyzingobjects different names yet (; ), different constraintsystems. could avoided allow variable blocked witnesspreviously analyzed constraint system. technique would similar oneused (Pratt, 1978), tree-automata technique used (Vardi & Wolper, 1986),improving simple tableaux methods variants propositional dynamic logics. Sincecalculus considers one constraint system time, modification calculuswould necessary accomplish task formal way, outside scopepaper. formal development deterministic exponential time proceduresubject future research.Notice that, since domain canonical interpretation always finite,also implicitly proved ALCNR-knowledge bases finite model property,i.e., satisfiable knowledge base finite model. property extensivelystudied modal logics (Hughes & Cresswell, 1984) dynamic logics (Harel, 1984).particular, technique, called filtration, developed prove finite modelproperty build finite model satisfiable formula. technique allows onebuild finite model infinite one grouping worlds structure equivalenceclasses, based set formulae satisfied world. interestingobserve calculus, based witnesses, considered variant filtrationtechnique equivalence classes determined basis -equivalencerelation. However, number restrictions, variables -equivalent cannotgrouped, since might separated (e.g., might introducedapplication ! -rule). Nevertheless, direct successors,stated point 4.(b) definition canonical interpretation page 124. wouldcorrespond grouping variables infinite model way separationspreserved.4. Relation previous worksection discuss relation paper previous work reasoning inclusions. particular, first consider previously proposed reasoning techniques dealinclusions terminological cycles, discuss relation inclusionsterminological cycles.4.1 Reasoning Techniquesmentioned introduction, previous results obtained Baader et al. (1990),Baader (1990a, 1990b), Nebel (1990, 1991), Schild (1991) Dionne et al. (1992, 1993).Nebel (1990, Chapter 5) considers language F , containing concept conjunction,universal quantification number restrictions, TBoxes containing (possibly cyclic)concept definitions, role definitions disjointness axioms (stating two concept namesdisjoint). Nebel shows subsumption F -concepts w.r.t. TBox decidable.However, argument uses non-constructive: shows sucient con128fiDecidable Reasoning Terminological KR Systemssider finite interpretations size bounded size TBox order decidesubsumption.(Baader, 1990b) effect three types semantics|descriptive, greatest fixpoint least fixpoint semantics|for language FL0, containing concept conjunctionuniversal quantification, described help finite automata. Baader reducessubsumption FL0 -concepts w.r.t. TBox containing (possibly cyclic) definitionsform =: C (which calls terminological axioms) decision problems finite automata.particular, shows subsumption w.r.t. descriptive semantics decided polynomial space using Buchi automata. Using results (Baader, 1990b), (Nebel, 1991)characterization subsumption problem w.r.t. descriptive semantics givenhelp deterministic automata (whereas Buchi automata nondeterministic).also yields PSPACE-algorithm deciding subsumption.(Baader et al., 1990) attention restricted language ALC . particular,paper considers problem checking satisfiability single equationform C = >, C ALC -concept. problem, called universal satisfiability problem, shown equivalent checking satisfiability ALC -TBox (seeProposition 4.1).(Baader, 1990a), extension ALC , called ALC reg , introduced, supportsconstructor express transitive closure roles. means transitive closureroles possible replace cyclic inclusions form v equivalent acyclicones. problem checking satisfiability ALC reg -concept solvedpaper. also shown using transitive closure possible reduce satisfiabilityALC -concept w.r.t. ALC -TBox = fC1 v D1; : : :; Cn v Dn g conceptsatisfiability problem ALC reg (w.r.t. empty TBox). Since problem conceptsatisfiability w.r.t. TBox trivially harder checking satisfiability TBox,paper extends result given (Baader et al., 1990).technique exploited (Baader et al., 1990) (Baader, 1990a) basednotion concept tree. concept tree generated starting concept C ordercheck satisfiability (or universal satisfiability). way concept tree generatedconcept C similar avor way complete constraint system generatedconstraint system fx: C g. However, extension concept tree methoddeal number restrictions individuals knowledge base neither obvious,suggested cited papers; hand, extension calculus basedconstraint systems immediate, provided additional features counterpartFirst Order Logic.(Schild, 1991) results general (Baader, 1990a) obtainedconsidering languages expressive ALC reg dealing concept satisfiability problem languages. results obtained establishing correspondenceconcept languages Propositional Dynamic Logics (PDL), reducinggiven problem satisfiability problem PDL. approach allows Schild findseveral new results exploiting known results PDL framework. However, cannotused deal every concept language. fact, correspondence cannot establishedlanguage includes concept constructors counterpart PDL (e.g.,number restrictions, individuals ABox).129fiBuchheit, Donini, & SchaerfRecently, algebraic approach cycles proposed (Dionne et al., 1992),(possibly cyclic) definitions interpreted determining equivalence relationterms describing concepts. existence uniqueness equivalence relationderives Aczel's results non-well founded sets. (Dionne et al., 1993)researchers prove subsumption based approach equivalent subsumptiongreatest fixpoint semantics. language analyzed small fragment one usedTKRS k-rep, contains conjunction existential-universal quantifications combinedone construct (hence similar FL0 ). diculty extending resultslies fact clear individuals interpreted algebraicsetting. Moreover, believe constructive approaches like algebraic one, givecounterintuitive results applied non-constructive features concept languages|asnegation number restrictions.conclusion, approaches, i.e., reduction automata problems, concept trees,reduction PDL algebraic semantics, deal TBoxes don't seemsuitable deal also ABoxes. hand, constraint system technique, eventhough conceived TBox-reasoning, easily extended ABox-reasoning,also shown (Hollunder, 1990; Baader & Hollunder, 1991; Donini et al., 1993).4.2 Inclusions versus Concept Definitionscompare expressive power TBoxes defined set inclusions (as donepaper) TBoxes defined set (possibly cyclic) concept introductionsform _ =: D.Unlike (Baader, 1990a) (Schild, 1991), consider reasoning problems dealingTBox ABox together. Moreover, use descriptive semantics concept introductions, inclusions. result obtained inclusion statementsconcept introductions actually expressive power. detail, showsatisfiability knowledge base = hA; i, set inclusion statements,reduced satisfiability knowledge base 0 = hA0; 0i 0 setconcept introductions. direction, concept introductions inclusions,trivial since introductions form =: expressed pair inclusionsv v A, concept name specification _ rewritteninclusion v (as already mentioned Section 2).notation, given TBox = fC1 v D1 ; : : :; Cn v Dn g, define concept CTCT = (:C1 D1) u u (:Cn Dn ). pointed (Baader, 1990a) ALC ,interpretation satisfies TBox satisfies equation CT = >. resulteasily extends ALCNR, stated following proposition.Proposition 4.1 Given ALCNR-TBox = fC1 v D1; : : :; Cn v Dng, interpretation satisfies satisfies equation CT = >.interpretation satisfies inclusion C v satisfies equation:C = >; satisfies set equations :C1 D1 = >,: : : , :Cn Dn = >satisfies (:C1 D1) u u (:Cn Dn ) = >. claim follows.Proof.130fiDecidable Reasoning Terminological KR SystemsGiven knowledge base = hA; concept appearing , defineknowledge base 0 = hA0 ; 0 follows:A0 = [ fA(b) j b individual g0 = fA _ CT u 8P1.A u u 8Pn .AgP1 ; P2; : : :; Pn role names appearing . Note 0 singleinclusion, could also thought one primitive concept specification.Theorem 4.2 = hA; satisfiable 0 = hA0; 0i satisfiable.0 followingProof. order simplify machinery proof, use(logically equivalent) form:0 = fA v CT ; v 8P1.A; : : :; v 8Pn .Ag(Note use symbol `v' instead `_ ' concept name appearsleft-hand side many statements, must consider statements inclusions).\)" Suppose = hA; satisfiable. Theorem 3.7, exists completeconstraint system without clash, defines canonical interpretationmodel . Define constraint system 0 follows:0 = [ fw: j w object gcall canonical interpretation associated 0. prove model0 .First observe every assertion satisfied since equal exceptinterpretation A, appear A. Therefore, every assertion A0also satisfied , either assertion A, (if assertionform A(b)) definition 0.Regarding 0 , note definition 0, AIS = = ; thereforesides inclusions form v 8Pi .A (i = 1; : : :; n) interpreted , hencesatisfied . Since appear CT , (CT )IS = (CT )IS .Moreover, since satisfies , also have, Proposition 4.1, (CT )IS = ,therefore (CT )IS = (CT )IS = = . follows also sides inclusionv CT interpreted . conclusion, satisfies 0 .\(" Suppose 0 = hA0 ; 0 satisfiable. Again, Theorem 3.7, existscomplete constraint system 0 without clash, defines canonical interpretationmodel 0. show also model .First all, assertions satisfied A0 , satisfies everyassertion A0 . prove satisfies , first prove following equation:AIS =(2)Equation 2 proved showing that, every object 2 , AIS . orderthat, observe general property constraint systems: Every variable 0 successorindividual. comes definition generating rules, add variablesconstraint system direct successors existing objects, beginningcontains individuals.Then, Equation 2 proved observing following three facts:00000000000000000000001310fiBuchheit, Donini, & Schaerf1. every individual b , b 2 AIS ;002. object AIS , satisfies inclusions AIS (8P1.A)IS ; : : :;AIS (8Pn .A)IS , every direct successor AIS ;3. successor relation closed direct successor relation0000000Fundamental Theorem Induction (see e.g., Wand, 1980, page 41) conclude every object AIS . proves Equation 2 holds.Equation 2, fact satisfies inclusion AIS (CT )IS , derive(CT )IS = , satisfies equation CT = >. Hence, Proposition4.1, satisfies , completes proof theorem.machinery present proof new. fact, realizing inclusionsv 8P1 .A; : : :; v 8Pn .A simulate transitive closure roles P1 ; : : :; Pn , onerecognize similarities proofs given Schild (1991) Baader (1990a). difference proofs rely notion connected model (Baader uses equivalentnotion rooted model). contrast, models obtain connected,individuals knowledge base not. exploit weaker propertyevery variable model successor individual.Note reduction strongly relies fact disjunction `t' complement `:' within language. fact, disjunction complement necessaryorder express inclusions TBox inside concept CT . Therefore,proof holds ALC -knowledge bases, hold TKRSs allowingconstructors concepts (e.g., back).Furthermore, language FL0 introduced Section 4.1, opposite result holds.fact, McAllester (1991) proves computing subsumption w.r.t. set inclusionsEXPTIME-hard, even small language FL0 . Conversely, Nebel (1991) provessubsumption w.r.t. set cyclic definitions FL0 done PSPACE. Combiningtwo results, conclude FL0 subsumption w.r.t. set inclusionssubsumption w.r.t. set definitions different complexity classes, hence (assumingEXPTIME 6= PSPACE) inclusion statements strictly expressive conceptdefinitions FL0.still open whether inclusions definitions equivalent languages whoseexpressivity FL0 ALC .0000000005. Discussionpaper proved decidability main inference services TKRS basedconcept language ALCNR. believe result theoreticalimportance, bears impact existing TKRSs, complete procedureeasily devised calculus provided Section 3. procedure, one buildecient (but still complete) ones, described end Section 3.2, alsoapplying standard optimization techniques described (Baader, Hollunder,Nebel, Profitlich, & Franconi, 1992). optimized procedure perform well smallsublanguages reasoning tractable, still complete solvingcomplex tasks. However, complete procedure still take exponential time132fiDecidable Reasoning Terminological KR Systemsspace worst case, may argued could practical applicability.comment following point.Firstly, complete procedure (possibly optimized) offers benchmark comparingincomplete procedures, terms performance, also terms missed inferences. Let us illustrate point detail, providing blatant paradox: considermostly incomplete constant-time procedure, answering always \No" check. Obviously useless procedure outperforms one, missed inferences takenaccount. paradox shows incomplete procedures meaningfully compared missed inferences considered. recognize missed inferences largeexamples, one needs exactly complete procedure|even ecient one|like ours.believe fair detection missed inferences would great help evensatisfaction end users primary criterion judging incomplete procedures.Secondly, complete procedure used \anytime classification", proposed(MacGregor, 1992). idea use fast, incomplete algorithm first stepanalyzing input knowledge, reasoning background.cited paper, resolution-based theorem provers proposed performing backgroundreasoning. argue specialized complete procedure perform bettergeneral theorem prover. instance, theorem provers usually specifically designeddeal filtration techniques.Moreover, calculus easily adapted deal rules. outlinedintroduction, rules often used practical TKRSs. Rules behave like one-way conceptinclusions|no contrapositive allowed|and applied known individuals.result shows rules ALCNR applied also unknown individuals (ourvariables constraint system) without endangering decidability. resultcompared negative result (Baader & Hollunder, 1992), shownsubsumption becomes undecidable rules applied unknown individuals classic.Finally, calculus provides new way building incomplete procedures, modifyingpropagation rules. Since rules build model, modificationssemantical counterpart gives precise account incomplete proceduresobtained. example, one could limit size canonical model polynomialsize KB. Semantically, would mean consider \small" models,reasonable intended models KB much bigger sizeKB itself. believe way designing incomplete procedures \from above", i.e.,starting complete set inferences weakening it, dual way incompleteprocedures realized far \from below", i.e., starting already incompleteinferences adding inference power need.research still needed address problems issuing practical systems.example, completely express role restrictions inside number restrictions, qualified numberrestrictions (Hollunder & Baader, 1991) taken account. Also, languageresulting addition enumerated sets (called one-of classic), role fillersALCNR still studied, although seem endanger filtrationmethod used. Instead, different method might necessary inverse roles addedALCNR, since finite model property lost (as shown Schild, 1991). Finally,addition concrete domains (Baader & Hanschke, 1991) remains open.133fiBuchheit, Donini, & SchaerfAcknowledgementsthank Maurizio Lenzerini inspiration work, well several discussions contributed paper. Werner Nutt pointed us observation mentioned end Section 3, thank Franz Baader helpful commentsearlier drafts. thank also anonymous reviewers, whose stimulating commentshelped us improving submitted version.research partly done first author visiting Dipartimento di Informatica e Sistemistica, Universita di Roma \La Sapienza". third author also acknowledges Yoav Shoham hospitality Computer Science Department StanfordUniversity, author developing part research.work supported ESPRIT Basic Research Action N.6810 (COMPULOG 2) Progetto Finalizzato Sistemi Informatici e Calcolo ParalleloCNR (Italian Research Council), LdR \Ibridi".ReferencesAbrial, J. (1974). Data semantics. Klimbie, J., & Koffeman, K. (Eds.), Data BaseManagement, pp. 1{59. North-Holland Publ. Co., Amsterdam.Baader, F. (1990a). Augmenting concept languages transitive closure roles: alternative terminological cycles. Tech. rep. RR-90-13, Deutsches Forschungszentrumfur Kunstliche Intelligenz (DFKI), Kaiserslautern, Germany. abridged version appeared Proc. 12th Int. Joint Conf. Artificial Intelligence IJCAI-91, pp.446{451.Baader, F. (1990b). Terminological cycles KL-ONE-based knowledge representation languages. Tech. rep. RR-90-01, Deutsches Forschungszentrum fur Kunstliche Intelligenz(DFKI), Kaiserslautern, Germany. abridged version appeared Proc. 8thNat. Conf. Artificial Intelligence AAAI-90, pp. 621{626.Baader, F., Burkert, H.-J., Hollunder, B., Nutt, W., & Siekmann, J. H. (1990). Conceptlogics. Lloyd, J. W. (Ed.), Computational Logics, Symposium Proceedings, pp.177{201. Springer-Verlag.Baader, F., & Hanschke, P. (1991). schema integrating concrete domains conceptlanguages. Proc. 12th Int. Joint Conf. Artificial Intelligence IJCAI-91,pp. 452{457 Sydney.Baader, F., & Hollunder, B. (1991). terminological knowledge representation systemcomplete inference algorithm. Proc. Workshop Processing DeclarativeKnowledge, PDK-91, Lecture Notes Artificial Intelligence, pp. 67{86. SpringerVerlag.Baader, F., & Hollunder, B. (1992). Embedding defaults terminological knowledgerepresentation formalisms. Proc. 3rd Int. Conf. Principles KnowledgeRepresentation Reasoning KR-92, pp. 306{317. Morgan Kaufmann, Los Altos.134fiDecidable Reasoning Terminological KR SystemsBaader, F., Hollunder, B., Nebel, B., Profitlich, H.-J., & Franconi, E. (1992). empiricalanalisys optimization techniques terminological representation systems. Proc.3rd Int. Conf. Principles Knowledge Representation Reasoning KR92, pp. 270{281. Morgan Kaufmann, Los Altos.Beck, H. W., Gala, S. K., & Navathe, S. B. (1989). Classification query processingtechnique CANDIDE semantic data model. Proc. 5th IEEE Int. Conf.Data Engineering.Borgida, A., Brachman, R. J., McGuinness, D. L., & Alperin Resnick, L. (1989). CLASSIC:structural data model objects. Proc. ACM SIGMOD Int. Conf.Management Data, pp. 59{67.Brachman, R. J., & Levesque, H. J. (1984). tractability subsumption framebased description languages. Proc. 4th Nat. Conf. Artificial IntelligenceAAAI-84, pp. 34{37.Brachman, R. J., Pigman Gilbert, V., & Levesque, H. J. (1985). essential hybridreasoning system: Knowledge symbol level accounts KRYPTON. Proc.9th Int. Joint Conf. Artificial Intelligence IJCAI-85, pp. 532{539 Los Angeles.Brachman, R. J., & Schmolze, J. G. (1985). overview KL-ONE knowledge representation system. Cognitive Science, 9 (2), 171{216.Buchheit, M., Donini, F. M., & Schaerf, A. (1993). Decidable reasoning terminologicalknowledge representation systems. Tech. rep. RR-93-10, Deutsches Forschungszentrum fur Kunstliche Intelligenz (DFKI), Saarbrucken, Germany. abridged versionappeared Proc. 13th Int. Joint Conf. Artificial Intelligence IJCAI-93 pp.704{709.Catarci, T., & Lenzerini, M. (1993). Representing using interschema knowledgecooperative information systems. Journal Intelligent Cooperative Inf. Syst.appear.Dionne, R., Mays, E., & Oles, F. J. (1992). non-well-founded approach terminologicalcycles. Proc. 10th Nat. Conf. Artificial Intelligence AAAI-92, pp. 761{766.AAAI Press/The MIT Press.Dionne, R., Mays, E., & Oles, F. J. (1993). equivalence model theoretic structuralsubsumption description logics. Proc. 13th Int. Joint Conf. ArtificialIntelligence IJCAI-93, pp. 710{716 Chambery, France. Morgan Kaufmann, Los Altos.Donini, F. M., Hollunder, B., Lenzerini, M., Marchetti Spaccamela, A., Nardi, D., & Nutt,W. (1992). complexity existential quantification concept languages. ArtificialIntelligence, 2{3, 309{327.Donini, F. M., Lenzerini, M., Nardi, D., & Nutt, W. (1991a). complexity conceptlanguages. Allen, J., Fikes, R., & Sandewall, E. (Eds.), Proc. 2nd Int.Conf. Principles Knowledge Representation Reasoning KR-91, pp. 151{162.Morgan Kaufmann, Los Altos.135fiBuchheit, Donini, & SchaerfDonini, F. M., Lenzerini, M., Nardi, D., & Nutt, W. (1991b). Tractable concept languages.Proc. 12th Int. Joint Conf. Artificial Intelligence IJCAI-91, pp. 458{463Sydney.Donini, F. M., Lenzerini, M., Nardi, D., & Schaerf, A. (1991c). hybrid system integratingdatalog concept languages. Proc. 2nd Conf. Italian AssociationArtificial Intelligence, No. 549 Lecture Notes Artificial Intelligence. SpringerVerlag. extended version appeared also Working Notes AAAI FallSymposium \Principles Hybrid Reasoning".Donini, F. M., Lenzerini, M., Nardi, D., & Schaerf, A. (1993). Deduction concept languages: subsumption instance checking. Journal Logic Computation.appear.Fitting, M. (1990). First-Order Logic Automated Theorem Proving. Springer-Verlag.Garey, M., & Johnson, D. (1979). Computers Intractability|A guide NPcompleteness. W.H. Freeman Company, San Francisco.Harel, D. (1984). Dynamic logic. Handbook Philosophical Logic, Vol. 2, pp. 497{640.D. Reidel, Dordrecht, Holland.Heinsohn, J., Kudenko, D., Nebel, B., & Profitlich, H.-J. (1992). empirical analysisterminological representation systems. Proc. 10th Nat. Conf. ArtificialIntelligence AAAI-92, pp. 767{773. AAAI Press/The MIT Press.Hollunder, B. (1990). Hybrid inferences KL-ONE-based knowledge representation systems. Proc. German Workshop Artificial Intelligence, pp. 38{47. SpringerVerlag.Hollunder, B., & Baader, F. (1991). Qualifying number restrictions concept languages.Tech. rep. RR-91-03, Deutsches Forschungszentrum fur Kunstliche Intelligenz (DFKI),Kaiserslautern, Germany. abridged version appeared Proc. 2nd Int. Conf.Principles Knowledge Representation Reasoning KR-91.Hughes, G. E., & Cresswell, M. J. (1984). Companion Modal Logic. Methuen, London.Kaczmarek, T. S., Bates, R., & Robins, G. (1986). Recent developments NIKL. Proc.5th Nat. Conf. Artificial Intelligence AAAI-86, pp. 978{985.Lenzerini, M., & Schaerf, A. (1991). Concept languages query languages. Proc.9th Nat. Conf. Artificial Intelligence AAAI-91, pp. 471{476.Levesque, H. J. (1984). Foundations functional approach knowledge representation.Artificial Intelligence, 23, 155{212.Lewis, H. R., & Papadimitriou, C. H. (1981). Elements Theory Computation.Prentice-Hall, Englewood Cliffs, New Jersey.MacGregor, R. (1991). Inside LOOM description classifier. SIGART Bulletin, 2 (3),88{92.136fiDecidable Reasoning Terminological KR SystemsMacGregor, R. (1992). What's needed make description logic good KR citizen.Working Notes AAAI Fall Symposium Issues Description Logics: Usersmeet Developers, pp. 53{55.MacGregor, R., & Bates, R. (1987). Loom knowledge representation language. Tech.rep. ISI/RS-87-188, University Southern California, Information Science Institute,Marina del Rey, Cal.MacGregor, R., & Brill, D. (1992). Recognition algorithms LOOM classifier.Proc. 10th Nat. Conf. Artificial Intelligence AAAI-92, pp. 774{779. AAAIPress/The MIT Press.Mays, E., Dionne, R., & Weida, R. (1991). K-REP system overview. SIGART Bulletin,2 (3).McAllester, D. (1991). Unpublished manuscript.McGuinness, D. L. (1992). Making description logic based knowledge representation systemsusable. Working Notes AAAI Fall Sysmposium Issues DescriptionLogics: Users meet Developers, pp. 56{58.Mylopoulos, J., Bernstein, P., & Wong, E. (1980). language facility designing databaseintensive applications. ACM Trans. Database Syst., 5 (2), 185{207.Nebel, B. (1988). Computational complexity terminological reasoning BACK. ArtificialIntelligence, 34 (3), 371{383.Nebel, B. (1990). Reasoning Revision Hybrid Representation Systems. Lecture NotesArtificial Intelligence. Springer-Verlag.Nebel, B. (1991). Terminological cycles: Semantics computational properties. Sowa,J. F. (Ed.), Principles Semantic Networks, pp. 331{361. Morgan Kaufmann, LosAltos.Nutt, W. (1992). Personal communication.Patel-Schneider, P. F. (1984). Small beautiful knowledge representation. Proc.IEEE Workshop Knowledge-Based Systems. extended version appearedFairchild Tech. Rep. 660 FLAIR Tech. Rep. 37, October 1984.Patel-Schneider, P. (1989). Undecidability subsumption NIKL. Artificial Intelligence,39, 263{272.Pratt, V. R. (1978). practical decision method propositional dynamic logic. Proc.10th ACM SIGACT Symp. Theory Computing STOC-78, pp. 326{337.Quantz, J., & Kindermann, C. (1990). Implementation BACK system version 4. Tech.rep. KIT-Report 78, FB Informatik, Technische Universitat Berlin, Berlin, Germany.Rich, editor, C. (1991). SIGART bulletin. Special issue implemented knowledge representation reasoning systems. (2)3.137fiBuchheit, Donini, & SchaerfSchaerf, A. (1993a). complexity instance checking problem concept languages existential quantification. Journal Intelligent Information Systems, 2,265{278. abridged version appeared Proc. 7th Int. Symp. Methodologies Intelligent Systems ISMIS-93.Schaerf, A. (1993b). Reasoning individuals concept languages. Tech. rep. 07.93,Dipartimento di Informatica e Sistemistica, Universita di Roma \La Sapienza".abridged version appeared Proc. 3rd Conf. Italian AssociationArtificial Intelligence AI*IA-93.Schild, K. (1988). Undecidability subsumption U . Tech. rep. KIT-Report 67, FBInformatik, Technische Universitat Berlin, Berlin, Germany.Schild, K. (1991). correspondence theory terminological logics: Preliminary report.Proc. 12th Int. Joint Conf. Artificial Intelligence IJCAI-91, pp. 466{471Sydney.Schmidt-Schau, M. (1989). Subsumption KL-ONE undecidable. Brachman, R. J.,Levesque, H. J., & Reiter, R. (Eds.), Proc. 1st Int. Conf. PrinciplesKnowledge Representation Reasoning KR-89, pp. 421{431. Morgan Kaufmann,Los Altos.Schmidt-Schau, M., & Smolka, G. (1991). Attributive concept descriptions complements. Artificial Intelligence, 48 (1), 1{26.Vardi, M., & Wolper, P. (1986). Automata-theoretic techniques modal logics programs. Journal Computer System Science, 32, 183{221. preliminary versionappeared Proc. 16th ACM SIGACT Symp. Theory Computing STOC84.Vilain, M. (1991). Deduction parsing: Tractable classification KL-ONE framework.Proc. 9th Nat. Conf. Artificial Intelligence AAAI-91, pp. 464{470.Wand, M. (1980). Induction, Recursion, Programming. North-Holland Publ. Co.,Amsterdam.Woods, W. A., & Schmolze, J. G. (1992). KL-ONE family. Lehmann, F. (Ed.),Semantic Networks Artificial Intelligence, pp. 133{178. Pergamon Press. Publishedspecial issue Computers & Mathematics Applications, Volume 23, Number2{9.138fiJournal Artificial Intelligence Research 1 (1994) 277{308Submitted 3/94; published 6/94Semantics Complete AlgorithmSubsumption CLASSIC Description LogicAlex Borgidaborgida@cs.rutgers.eduDepartment Computer ScienceRutgers UniversityNew Brunswick, NJ 08904 U. S. A.Peter F. Patel-Schneiderpfps@research.att.comAT&T Bell Laboratories600 Mountain AvenueMurray Hill, NJ 07974 U. S. A.Abstractpaper analyzes correctness subsumption algorithm used classic,description logic-based knowledge representation system used practicalapplications. order deal eciently individuals classic descriptions, developers use algorithm incomplete respect standard,model-theoretic semantics description logics. provide variant semantics descriptions respect current implementation complete,independently motivated. soundness completeness polynomial-time subsumption algorithm established using description graphs, abstracted versionimplementation structures used classic, independent interest.1. Introduction Description LogicsData knowledge bases models part natural world. modelsoften built individual objects inter-related relationships groupedclasses capture commonalities among instances. Description logics (DLs),also known terminological logics, form class languages used build accessmodels; distinguishing feature classes (usually called concepts) definedintensionally|in terms descriptions specify properties objects must satisfybelong concept. descriptions expressed using language allowsconstruction composite descriptions, including restrictions binary relationships(usually called roles) connecting objects.example, consider descriptionGAME u 4 participants u 8participants:(PERSON u gender : Female):1description characterizes objects intersection (u) three sub-descriptions:GAME|objects belong atomic concept; 4 participants|objects leastfour fillers participants role; 8participants:(PERSON u gender : Female)|objectswhose participants fillers restricted belong PERSONs,gender role filled value Female.1. notation used descriptions standard notation description logic community(Baader et al., 1991). classic notation used verbose.c 1994 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.fiBorgida & Patel-Schneiderkey difference DLs standard representation formalisms basedFirst-Order Logic, e.g., relational deductive databases, DLs provide arenaexploring new sets \logical connectives"|the constructors used form compositedescriptions|that different standard connectives conjunction, universalquantifiers, etc.. Therefore, DLs provide new space search expressiveyet effectively computable representation languages. Moreover, although possibletranslate many aspects DLs currently encountered First Order Logic, reasoningtranslation would poor substitute DL-based systems reasonway resemble standard theorem proving (e.g., making use imperativeprogramming features).Descriptions one used several ways knowledge basemanagement system (KBMS) based description logic:1. state queries: KBMS locate objects satisfy description'sproperties.2. define classify concepts: Identifiers attached descriptions, manner views relational DBMSs. system addition automatically determine\subclass" relationship pairs concepts based definitions.example, concept defined description would subsumedconcept defined \games least two participants" (GAME u 2 participants).3. provide partial information objects: important understand distinct DL descriptions ascribed arbitrary individuals (e.g., \today's gamecards|individual Bgm#467|will exactly two participants followingset three : : : , like tea rum"). Note unlike database systems, DL-based KBMSs require descriptions predefined. providesconsiderable power recording partial knowledge objects.4. detect errors: possible determine whether two descriptions disjoint,whether description incoherent not, whether ascribing descriptionindividual leads inconsistency.Quite number KBMSs based description logics built, including classic(Resnick et al., 1992), loom (MacGregor & Bates, 1987), back (Peltason et al., 1987).systems used several practical situations, including software informationbases (Devanbu et al., 1991), financial management (Mays et al., 1987), configuration management (Owsnicki-Klewe, 1988; Wright et al., 1993), data exploration. Additionalsigns DLs significant subjects study several recent workshops DLs(Nebel et al., 1991; Peltason et al., 1991; AAAI, 1992).1.1 Tractability Completeness DL Implementationsfundamental operation descriptions determining whether one descriptiongeneral, subsumes, another, sense object satisfying latter would alsosatisfy conditions former. parallel surge work finding tractableyet expressive subsets first order logic, DL research community investigatingcomplexity reasoning various constructors. first result area (Levesque278fiSubsumption CLASSIC& Brachman, 1987) showed even seemingly simple addition small languagelead subsumption determination becoming NP-hard. recent, striking pairresults (Patel-Schneider, 1989b; Schmidt-Schauss, 1989) shows adding abilityrepresent equalities role compositions makes complexity subsumption problemleap quadratic undecidable.three possible responses intractability results:Provide incomplete implementation DL reasoner, senseinferences sanctioned standard semantics constructorsperformed algorithm. approach, explicitly adopted loom systemimplementers (MacGregor & Bates, 1987), advocated users (Doyle &Patil, 1991), one major diculty: one describe users inferencesactually drawn implementation systems known propertiesimplemented top KBMS? Two solutions problem suggested: alternative semantic accounts (based weaker, 4-valued logics, example)(Patel-Schneider, 1989a), proof-theoretic semantics (Borgida, 1992).Provide complete implementation specific DL reasoner, acknowledgingcertain circumstances may take inordinate amount time. approach,followed systems kris (Baader & Hollunder, 1991), problemunpredictability: system \go wild blue yonder"?course, circumstances impossible even attempt since reasoningproblem undecidable.Carefully devise language limited expressive power reasoning tractable,provide complete implementation it. approach chosendesigners languages kandor (Patel-Schneider, 1984) krypton(Brachman et al., 1983), close approach classic (Borgida et al.,1989).hidden diculty second third approach produce implementationcorrect (\complete") respect semantics. diculty illustrateddiscovery, several years later, implementation kandor, well candide(Beck et al., 1989), fact incomplete, subsumption problem NP-hard (Nebel,1988), rather polynomial, claimed; happened despite fact Kandor\small" language comparison DLs, implementation appearedevidently correct. avoid problems, necessary produce convincingdemonstrations algorithm correct; several proofs fact already appeared DL literature (e.g., (Patel-Schneider, 1987; Hollunder & Nutt, 1990; Doniniet al., 1991)), albeit languages seen use practical applications.1.2 Outlineclassic 12 system reasoner based moderately complicated DL.used commercial (Wright et al., 1993) prototype applications AT&T, madeavailable academic researchers AT&T Bell Laboratories.2. classic 1 first released version classic. new version, classic 2, expressive DL,recently released.279fiBorgida & Patel-SchneiderOne purpose paper provide rigorous formal analysis correctnesseciency classic DL subsumption algorithm.3 start presentingresult subset language, call Basic classic. subsumptionalgorithm relies transformation descriptions data structure, calldescription graphs, generalization A-Kaci's psi-terms (1984).process normalizing graph canonical form, remove obvious redundanciesexplicate certain implicit facts, encoding particular infinite set inferencesdrawn so-called \coreference constraints". correctness subsumptionalgorithm demonstrated rigorously showing construct (inductively) countermodel case algorithm returns answer \no".Next, explore effect adding individuals descriptions. show that, usingindividuals, one encode disjunctive information leading need examine combinatorially many possibilities. classic implementation fact incomplete respectstandard semantics. second contribution paper well-motivated,understandable, small change standard semantics alleviates problem.extend subsumption algorithm proof correctness deal individualsmodified semantics, thereby characterizing sense \incompleteness"reasoner.paper therefore illustrates three paradigms described above, albeit nonstandard manner second paradigm, first time realisticlanguage significant practical use.2. Basic CLASSICDescriptions Basic classic built collection atomic concept names, rolenames, attribute names. Roles attributes always atomic descriptionsbuilt using operators/constructors value restrictions number restrictions,indicate below.Basic classic incorporates objects host programming language,4 called hostindividuals, form distinct group classic individuals; latterroles attributes own, former restricted role attribute fillers.denotational semantics classic descriptions starts, usual, domainvalues, , subsets extensions descriptions, subsetsextensions roles attributes. domain fact disjointly divided two realms,host realm, H , containing objects corresponding host language individuals,classic realm C , containing objects. Every description, except THING,denotes entire domain extension subset either classic realmhost realm. (NOTHING denotes empty set, therefore classic hostconcept.) extension role possible world relation classic realmentire domain, extension attribute function classic realmentire domain.3. empirical tests (Heinsohn et al., 1992), classic emerged fastest current DLimplementations.4. general scheme incorporating host objects described (Baader & Hanschke, 1991).280fiSubsumption CLASSICHost descriptions relatively simple: (i) HOST-THING, denoting entire host realm,H ; (ii) special, pre-defined names corresponding types host programming language; (iii) conjunctions descriptions. descriptions correspondinghost programming language types pre-defined extensions subsumption relationships, mirroring subtype relationship host programming language.subtype relationship satisfied possible worlds/interpretations. require (i)host concepts extension either infinite size empty; (ii)extensions two host concepts overlap, one must subsumed other, i.e.,types disjoint, unless subtypes other; (iii) host conceptinfinite number extra instances child concepts. (These conditionsneeded avoid able infer conclusions size host descriptions.)allows host concepts like INTEGER, REAL, COMPLEX, STRING, BOOLEANNON-ZERO-INTEGER .Non-host (classic) descriptions Basic classic formed according followingsyntax:SyntaxConstructor NameCLASSIC-THINGEAtomic Concept NameCuDIntersection8R:CRole Value Restriction8A:CAttribute Value Restrictionn RMinimum Number RestrictionRMaximum Number RestrictionA1 : : : Ak = B1 : : : Bh Equality RestrictionE atomic concept name; C classic descriptions; R role; A, Ai ,Bj attributes; n,k,h positive integers; non-negative integer. setconstructors Basic classic judiciously chosen result languagesubsumption easy compute.denotational semantics descriptions Basic classic recursively builtextensions assigned atomic names possible world:Definition 1 possible world/interpretation, , consists domain, , interpretation function :I . domain disjointly divided classic realm, C , hostrealm, H . interpretation function assigns extensions atomic identifiers follows:extension atomic concept name E subset EI classic realm.extension atomic role name R subset RI C .extension atomic attribute name total function AI C.extension CI non-atomic classic description computed follows:CLASSIC-THINGI = C .(C u D)I = CI \ DI .281fiBorgida & Patel-Schneider(8p:C)I = fd 2 C j 8x (d; x) 2 pI ) x 2 CI g, i.e., objects Cwhose p-role p-attribute fillers extension C;(n p)I (resp. (n p)I ) objects C least (resp. most) n fillersrole p.(A1 : : : Ak = B1 : : : Bh )I = fd 2 C j Ak (: : : A1I (d)) = BhI (: : : B1I (d))g, i.e.,objects C property applying composition extensionAi composition extension Bj object resultvalue.5description, D1, said subsume another, D2 , possible worlds , D2ID1 .key interest computation subsumption relationship descriptionsBasic classic. Subsumption computation multi-part process. First, descriptionsturned description graphs. Next, description graphs put canonical form,certain inferences explicated redundancies reduced combiningnodes edges graph. Finally, subsumption determined descriptioncanonical description graph.describe detail process, start formal definition notiondescription graph (Definition 2), present techniquestranslating description description graph (Section 2.2), requires mergingpairs nodes, pairs graphs (Definitions 4 5);putting description graph canonical form (Section 2.3);determining whether description subsumes description graph (Algorithm 1).prove correctness approach, need show first two stepslead us right direction, i.e., following three questions equivalent: \Doesdescription subsume description C?", \Does description subsume graph GC ?",\Does description subsume graph canonical(GC )?". this, need defineformal semantics descriptions graphs (Definitions 1 3), proveresults (Theorems 1 2). prove \completeness" subsumption algorithm,show algorithm indicate subsumes canonical(GC ),construct interpretation (\graphical world") object denotationcanonical(GC ) D.2.1 Description GraphsOne way developing subsumption algorithm first transform descriptionscanonical form, determine subsumption relationships them. Canonicaldescriptions normally thought trees since descriptions terms first orderterm language. presence equality restrictions classic significantly changes5. Note attribute chains must definite value, last cannot evaluatehost individuals, since cannot attributes.282fiSubsumption CLASSICfCLASSIC-THINGgfTHINGg:,,captain,coach,participants - fPERSONg,fGAMEgfather[0; 1]Figure 1: description graph.handling subsumption introduce relationships different piecesnormal form. significantly, presence equalities, small description,8friend:TALL u friend = friendfriend, subsumed descriptions arbitrary size,8friend:(8friend:(: : : (8friend:TALL) : : :)):order record sets inferences canonical form, resort graphbased representation, suggested semantic-network origins description logics,work A-Kaci (1984).Intuitively, description graph labelled, directed multigraph, distinguishednode. Nodes graph correspond descriptions, edges graph correspondrestrictions roles attributes. edges graph labelled role nameminimum maximum number fillers associated edge,attribute name. nodes graph labelled concept names associatednode concept. example, Figure 1 description graph, which, shall see later,corresponds description GAME u 8participants: PERSON u coach = (captainfather).equality restrictions (and hence non-tree portions graph) involveattributes, edges labelled roles cut-edges, i.e., removal increases onenumber connected components graph. restriction importantgraph tree form, really difference graphical linear notation,semantics simple develop. graph general directed acyclic graph,problem relating semantics generated two different pathsgraph share beginning ending nodes. graph contains cycles,problem developing correct semantics even dicult, simplistic semanticsnon-well-founded, sort fixed-point model-preference semanticsrequired. Fortunately, non-tree parts graphical notation involve attributesonly, attributes functional, job much easier.result restrictions, possible view description graphfollowing recursive structure: (i) distinguished node r, \island"nodes connected edges labelled attributes. (ii) Nodes island may0 edges labelled roles leaving them, pointing distinguished nodesdescription graphs. (iii) graphs share nodes edges commonother, islands them.283fiBorgida & Patel-Schneiderrecursive structure, easier represent description graphs usingrecursive definition, instead usual graph definition. recursive definition similarrecursive definition tree, states tree consists information(the information root tree) plus set trees (the children roottree). description graphs complex simple trees, usetwo-part definition.Definition 2 description graph triple, hN; E; ri, consisting set N nodes;bag E edges (a-edges) labelled attribute names; distinguished node r N .Elements E written hn1 ; n2; Ai n1 n2 nodes attributename.node description graph pair, hC; H consisting set C concept names(the atoms node), bag H tuples (the r-edges node). r-edgetuple, hR; m; M; Gi, role name, R; min, m, non-negative integer; max,, non-negative integer 1; (recursively nested) description graph G,representing restriction fillers role. (G often called restrictiongraph node.)Concept names description graph atomic concept names, host concept names,THING, CLASSIC-THING, HOST-THING.Descriptions graphs provided extensions starting possible worldsused descriptions. However, addition need way identifying individualsrelated attributes, given function .Definition 3 Let G = hN; E; ri description graph let possible world.interpretation GI G, interpretation nI nodes N , recursively (and mutually) defined follows:element, d, GI , iff function, , N1. = (r);2. n 2 N (n) 2 nI ;3. hn1 ; n2; Ai 2 E h(n1 ); (n2)i 2 AI , (which equivalent (n2 ) =AI ((n1)), since AI function).element, d, nI , n = hC; H i, iff1. C 2 C , 2 CI ;2. hR; m; M; Gi 2 H ,(a) elements, d0, domain hd; d0i 2 RI(b) d0 2 GI d0 hd; d0i 2 RI .284fiSubsumption CLASSIC2.2 Translating Descriptions Description GraphsBasic classic description turned description graph recursive process,working \inside out". process, description graphs nodes oftenmerged.Definition 4 merge two nodes, n1 n2, new node whose atoms unionatoms two nodes whose r-edges union r-edges twonodes6.Definition 5 merge two description graphs, G1 G2, description graph whosenodes disjoint union7 non-distinguished nodes G1 G2 plus newdistinguished node. edges merged graph union edges G1 G2,except edges touching distinguished nodes G1 G2 modified touchnew distinguished node. new distinguished node merge two distinguishednodes G1 G2.rules translating description C Basic classic description graph GCfollows:1. description consists concept name turned description graphone node a-edges. atoms node contains concept name.node r-edges.2. description form n R turned description graph one nodea-edges. node atoms CLASSIC-THING single r-edgerole R, min n, max 1, restriction GTHING .3. description form n R turned description graph one nodea-edges. node atoms CLASSIC-THING single r-edge roleR, min 0, max n, restriction GTHING .4. description form 8R:C, R role, turned description graphone node a-edges. node atoms CLASSIC-THING singler-edge role R, min 0, max 1, restriction GC.5. turn description form C u description graph, construct GCGD merge them.6. turn description form 8A:C, attribute, description graph,first construct description graph hNC ; EC ; rC C. description graph8A:C hNC [ ftg; EC [ fht; rC ; Aig; ti, node hfCLASSIC-THINGg; fgi.7. turn description form A1 : : : = B1 : : : Bm description graphfirst create distinguished node, node r, CLASSIC-THING atoms,node e, THING atoms. 1 n , 1 create node ai , atoms6. Note duplicate edges, ones joining ni ni , removed, since edges form bag.7. taking disjoint union two sets, elements one may systematically renamed first makesure sets non-overlapping.285fiBorgida & Patel-SchneiderCLASSIC-THING. 1 j , 1 create node bj , atomsCLASSIC-THING. None ai bj r-edges.n = 1, create edge hr; e; A1i; n > 1 create edges hr; a1; A1i, han,1 ; e; i,hai,1 ; ai; Ai 2 n , 1.Similarly, = 1, create edge hr; e; B1i; > 1 create edges hr; b1; B1 i,hbm,1; e; Bmi, hbi,1; bi; Bii 2 , 1.creates two disjoint paths, one Ai one Bj , distinguished node end node.Figure 1 presents view description graph constructed fashiondescription GAME u 8participants:PERSON u coach = captainfather:want show process preserves extensions. use mergeoperations first show work correctly.Lemma 1 n1 n2 nodes (n1 n2)I = nI1 \ nI2 . D1 D2 descriptiongraphs (D1 D2)I = D1I \ D2I .Proof: Since components (atoms r-edges) merged node obtainedunioning components respective nodes, since interpretation nodeintersection interpretation components, result obviously truenodes.merging graphs, difference root nodes replacedmerger edges, well root. element (D1 D2)I clearlyelement D1I D2I . Conversely, since take disjoint union nodestwo graphs, mapping functions 1 2 Definition 3 simply unioned,element D1I D2I element merged root node, hence(D1 D2 )I .Theorem 1 possible worlds, extension description ex-tension description graph.Proof: proof structural induction descriptions.extension concept names, cardinality restrictions, 8-restrictions roleseasily seen agree extension description graphs formed them.Lemma 1 shows conjunction properly handled. 8-restrictions attributes,construction correct attributes functional.equalities A1 : : : = B1 : : : Bm construction forms description graphtwo disjoint paths distinguished node end node, one labelled Ai ,nodes ai , labelled Bj , nodes bj .2 (A1 : : : = B1 : : : Bm)I = fd 2 C j Ak (: : : A1 (d)) = Bh (: : : B1 (d))g;defining (ai ) = Ai (: : : A1 (d)) (bj ) = Bj (: : : B1 (d))g, yields mappingrequired Definition 3. converse satisfied requirement Definition 3a-edge hn1 ; n2; Ai 2 E , (n2 ) = AI ((n1 )).286fiSubsumption CLASSIC2.3 Canonical Description Graphsfollowing sections occasionally refer \marking node incoherent";consists replacing special node outgoing r-edges, includingatoms NOTHING, always empty interpretation. Marking descriptiongraph incoherent consists replacing description graph consistingincoherent node. (Incoherent graphs thought representing conceptsempty extension.)Description graphs transformed canonical form repeating following normalization steps whenever possible description graph descendants.1. node atoms pre-defined host concept, add HOST-THINGatoms. node atomic concept name atoms, add CLASSIC-THINGatoms. pre-defined host concept atoms node, addmore-general pre-defined host concepts atoms.2. node HOST-THING CLASSIC-THING atoms, marknode incoherent. node atoms pair host conceptsrelated pre-defined subsumption relationship, mark node incoherent, sinceintersection empty.3. node description graph marked incoherent, mark description graphincoherent. (Reason: Even node root, attributes must always value,value cannot belong empty set.)4. r-edge node min greater max, mark node incoherent.5. r-edge node description graph marked incoherent, change max0. (Reason: cannot fillers belong empty set.)6. r-edge node max 0, mark description graph incoherent.(Reason: normalization step records equivalence 0 R 8R:NOTHING,used infer concept 8R:C arbitrary C subsumes 0 R.)7. node two r-edges labelled role, merge two edges,described below.8. description graph two a-edges node labelledattribute, merge two edges.merge two r-edges node, identical roles, replace one redge. new r-edge role role, maximum two mins min,minimum two maxs max, merge two description graphsrestriction.merge two a-edges hn; n1 ; Ai hn; n2; Ai, replace single new edgehn; n0; Ai, n0 results merging n1 n2, i.e., n0 = n1 n2. (If n1 = n2n0 = n1.) addition, replace n1 n2 n0 a-edges description graph.287fiBorgida & Patel-Schneiderneed show transformations canonical form change extensiongraph. main diculty showing two edge-merging processeschange extension.Lemma 2 Let G = hN; E; ri description graph two mergeable a-edges letG0 = hN 0; E 0; r0i result merging two a-edges. GI = G0I .Proof: Let two edges hn; n1; Ai hn; n2; Ai new node n0 n1 n2.Choose 2 GI , let function N domain satisfying conditionsextensions (Definition 3) (r) = d. (n1 ) = (n2 )equal AI ((n)). Let 0 except 0 (n0 ) = (n1 ) = (n2 ).0 satisfies Definition 3, part 3, G0, replace n1 n2 n0 everywhere.Moreover, 0 (n0) = (n1 ) 2 nI1 \ nI2 , which, Lemma 1, equals (n1 n2 )I ; part 2satisfied too, since n0 = n1 n2 . Finally, root modified merger, i.e., n1n2 r, say n1, = (n1) = 0 (n0), part 1 definition also satisfied.Conversely, given arbitrary 2 G0I , let 0 function stipulated Definition 30 (r0) = d. Let 0 except (n1 ) = (n0 ) (n2 ) = 0 (n0 ).argument traversed reverse verify satisfies Definition 3,2 GI .Lemma 3 Let n node two mergeable r-edges let n0 nodeedges merged. nI = n0I .Proof: Let two r-edges hR; m1; M1; G1i hR; m2; M2; G2i.Let 2 nI . m1 (m2) M1 (M2) elements domain, d0,hd; d0i 2 RI . Therefore maximum m1 m2minimum M1 M2 elements domain, d0, hd; d0i 2 RI . Also, d0hd; d0i 2 RI GI1 (GI2 ). Therefore, d0 hd; d0i 2 RI GI1 \ GI2 ,equals (G1 G2)I Lemma 1. Thus 2 n0I .Let 2 n0I . maximum m1 m2 minimumM1 M2 elements domain, d0 , hd; d0i 2 RI . Thereforem1 (m2) M1 (M2) elements domain, d0, hd; d0i 2 RI . Also, d0hd; d0i 2 RI (G1 G2 )I = GI1 \ GI2 . Therefore, d0 hd; d0i 2 RIGI1 (GI2 ). Therefore 2 nI .dealt issue merging, return desired result: showing\normalization" affect meaning description graphs.Theorem 2 possible worlds , extension canonical form descriptiongraph, G, resulting Basic classic description extensiondescription.Proof: Steps 1 2 justified since GI subset either H C ,disjoint.Step 3 justified fact that, definition description graphs, mustelement domain extension node description graph.Steps 4, 5, 6 easily derived Definition 3.Steps 7 8 dealt preceding two lemmas.288fiSubsumption CLASSIC2.4 Subsumption Algorithmfinal part subsumption process checking see canonical description graphsubsumed description. turns possible carry subsumptiontest without expense normalizing candidate subsumer concept.Algorithm 1 (Subsumption Algorithm) Given description description graphG = hN; E; ri, subsumes?(D; G) defined true followingconditions hold:1. description graph G marked incoherent.2. equivalent THING. (This determined checking first D=THING,recursively testing whether subsumes canonical description graph GTHING .)3. concept name element atoms r.4. n R r-edge r R role min greater equal n.5. n R r-edge r R role max less equal n.6. 8R:C r-edge r R role G0 restriction graphsubsumes?(C; G0).7. 8R:C subsumes?(C; GTHING) r CLASSIC-THING atoms. (Reason: 8R:THING requires possibility R applicable object, absenthost values.)8. 8A:C a-edge G form hr; r0; Ai, subsumes?(C; hN; E; r0i).9. 8A:C subsumes?(C; GTHING) r CLASSIC-THING atoms.10. A1 : : : = B1 : : : Bm paths A1 ; : : :; B1 ; : : :; Bm exist Gstarting r end node.11. A1 : : : = B1 : : : Bm Bm paths A1 ; : : :; An,1B1 ; : : :; Bm,1 exist G starting r end node,CLASSIC-THING atoms. (Reason: AiI ( A1 ( )) = Bj ( B1 ( ))::::::FI (AiI (: : : A1I (d))) = FI (Bj (: : : B1 (d)))attribute F, long attribute applicable (i.e., value hostdomain).)12. C u E subsumes?(C; G) subsumes?(E; G) true.289fiBorgida & Patel-Schneider2.5 Correctness Subsumption Algorithmsoundness algorithm fairly obvious, shall dwell it. completeness algorithm is, usual, dicult establish. First showcanonical description graph node marked incoherent, possibleworld non-empty extension description graph node constructed.constructive, inductive manner, constructing collection possible worlds, called graphical worlds description graph. graphical worlddistinguished domain element extension description graph node.common operation merge two possible worlds.Definition 6 Let I1 I2 two possible worlds. merge I1 I2, I1 I2,possible world classic realm disjoint union classic realm I1classic realm I2 . extension atomic names I1 I2 disjoint unionextensions I1 I2 .easy show extension description, description graph, nodeI1 I2 union (disjoint union classic realm, regular union host realm)extensions I1 I2 .Another operation add new domain elements possible world. new domainelements must classic realm. extension atomic identifiers remainexcept new domain elements belong arbitrary set atomic conceptnames arbitrary set fillers (filler) role (attribute). Again,easy show domain element original world extension originalworld iff extension augmented world.Given node, n, marked incoherent, construct graphical worldsn follows:1. atoms n precisely THING, n r-edges,constructs cause r-edges created also add CLASSIC-THING atoms.possible world, domain element distinguished domain element,graphical world n.2. atoms n include HOST-THING, n r-edges. possibleworld, distinguished element domain element extensionatoms n host concepts, graphical world n. (Becauserequirements host domain, infinite number domainelements.)3. atoms n include CLASSIC-THING, r-edge, hR; m; M; Gi, n,construct graphical worlds G. done number> 0 G marked incoherent, Gmarked incoherent = 0.two graphical worlds host domain elementdistinguished element. (Again, possible extension host concepteither empty infinite.) merge graphical worlds r-edgeone possible world. Add new domain elements one exactly290fiSubsumption CLASSICextensions atoms n fillers R exactly distinguishedelements appropriate graphical worlds. domain elementcorrect number fillers r-edge, disjoint union classicrealms merge process different host domain elements pickedabove; therefore extension n. Thus resulting world graphicalworld n.Given description graph, G = hN; E; ri, marked incoherent, constructgraphical worlds G follows: node n 2 N construct graphical worldn. done none marked incoherent. Merge graphicalworlds. Modify resulting world hn1 ; n2; Ai 2 E A-fillerdistinguished node graphical world n1 distinguished node graphicalworld n2 . easy show distinguished node graphical world rextension G, making graphical world G.show final part result.Theorem 3 subsumption algorithm indicates canonical descriptiongraph G subsumed Basic classic description D, possible worlddomain element extension graph extension D.Therefore G subsumed D.Proof: proof actually shows subsumption algorithm indicatescanonical description graph, G, subsumed description, D,graphical worlds G distinguished domain elementsextension D. Remember subsumption algorithm indicates G subsumedD, G must marked incoherent thus graphical worlds G.proof proceeds structural induction D. Let G = hN; E; ri.atomic concept name pre-defined host concept, occuratoms r. construction, graphical world G distinguisheddomain element extension D. Similarly, CLASSIC-THINGHOST-THING, distinguished domain elements wrong realm.THING, possible subsumption algorithm indicatenon-subsumption. case graphical world G propertydistinguished domain element extension D.form D1 u D2 subsumption algorithm must indicate Gsubsumed least one D1 D2 . inductive hypothesis, getgraphical worlds G distinguished domain elementsextension D1 extension D2, thus extension D.form n R either r-edge r labelled R min lessn r-edge.former case graphical worlds G distinguished noden , 1 fillers R, n greater min r-edge R, thusdistinguished node extension D.291fiBorgida & Patel-Schneiderlatter case, graphical worlds G distinguished nodenumber fillers R. n , 1 fillers propertydistinguished node extension D.form n R either r-edge r labelled R max greatern (including 1) r-edge.former case graphical worlds G distinguished noden + 1 fillers R, n less max r-edge R, thusdistinguished node extension D.latter case, graphical worlds G distinguished nodenumber fillers R. n + 1 fillers propertydistinguished node extension D.form 8R:C, R role, two cases arise.1. subsumes?(C; GTHING) CLASSIC-THING atoms r.graphical worlds G whose distinguished element hostrealm, thus extension D.2. Otherwise, either r-edge r role R description graph Hsubsumes?(C; H ) false r-edge r role R. Noteextension C entire domain, thus must subseteither host realm classic realm.former case H marked incoherent (or else subsumption couldfalse) max r-edge cannot 0. Thus graphicalworlds H whose distinguished element extension Cgraphical worlds G use graphical worlds H distinguisheddomain element R-fillers. graphical worlds G distinguished element extension D.latter case, pick graphical worlds G distinguished nodeR-filler wrong realm. graphical worlds G distinguishedelement extension D.form 8A:C attribute two cases arise.1. subsumes?(C; GTHING) CLASSIC-THING atoms r.graphical worlds G whose distinguished element hostrealm, thus extension D.2. Otherwise, either a-edge r attribute noder0 subsumes?(C; H ) false, H = hN; E; r0i; a-edger attribute A. Note extension C entire domain,thus must subset either host realm classic realm.former case H marked incoherent, G marked incoherent. Thus graphical worlds H whose distinguished elementextension C. Given graphical world H , graphical worldG formed simply changing distinguished domain element.292fiSubsumption CLASSICoriginal graphical world's distinguished element extension C,new graphical world's distinguished element extensionD, required.latter case, pick graphical worlds G distinguished nodeA-filler wrong realm. graphical worlds G distinguishedelement extension D.form A1 : : : = B1 : : : Bm several cases arise.1. one paths A1 ; : : :; An,1 B1 ; : : :; Bm,1 exist G startingr, find end partial path use graphical worldsdomain element node element host domain fillernext attribute path. one full paths filler.2. paths A1 ; : : :; B1 ; : : :; Bm exist G starting r enddifferent nodes, use graphical worlds domain elementstwo nodes different.3. one paths A1 ; : : :; B1 ; : : :; Bm exist G startingr paths A1 ; : : :; An,1 B1; : : :; Bm,1 exist G starting rend node either CLASSIC-THING atomsnode 6= Bm. former case use graphical worlds domainelement node host realm. latter case use graphical worldsdifferent fillers Bm domain element node.4. one paths A1 ; : : :; B1 ; : : :; Bm exist G startingr paths A1 ; : : :; An,1 B1; : : :; Bm,1 exist G starting rend different nodes use graphical worlds different fillersdomain elements nodes domain elementshost realm.cases either one (: : : A1 )(d) BmI (: : : B1 )(d)exist (: : : A1 )(d) 6= BmI (: : : B1 )(d), distinguished domain elementextension D.2.6 Implementing subsumption algorithmsection provide comments actual subsumption algorithmused classic system, including rough analysis complexity.described it, deciding whether description C subsumes accomplishedthree phases:1. Convert description graph GD .2. Normalize GD .3. Verify whether C subsumes GD .Step 1: Conversion accomplished simple recursive descent parser, takesadvantage fact syntax description logics (i.e., leading term constructor) makes amenable predictive parsing. Clearly, constructing graphs fixed sized293fiBorgida & Patel-Schneiderterms (like at-least) constant time (if measure size integer size 1 matter large), time non-recursive terms (like same-as) proportionallength. Finally, recursive terms (like all, and) require fixed amount additionalwork, top recursive processing. Therefore, first stage accomplishedtime proportional size input description. order speed later processing,useful maintain various lists, lists atomic concept identifiers,roles/attributes, sorted order. sorting needs done initially (later, orderingmaintained performing list merges) incurs, worst case quadraticoverhead processing8 . case, total size graph constructed (includingsizes nodes, etc.) proportional size original concept description.Step 3: Checking whether description C subsumes description graph GD ,seen run time proportional size subsuming concept, modulo costlookups various lists. Since sorted, lookup costs boundedlogarithm size candidate subsumee graph, total cost boundedO(j C j log j GD j).Step 2: Normalization accomplished post-order traversal descriptiongraph: processing description graph hN; E; ri, node N normalized first independently (see details below), afterwards attribute edges E normalized.later task involves identifying multiple identically-labelled attribute edges leaving node(this done one pass since attribute edges grouped source node, sortedattribute name), \merging" them. Merging two edges quite easy itself, merging nodes tips, must careful node mergersmay cascade; example, concept form a1 = b1 u a2 = b2 u : : : u = bn ua1 = a2 u a2 = a3 u : : : u an,1 = original graph 2n + 1 nodes, 2ncollapsed normalization step 8. discover eciently, use versionA-Kaci's algorithm unifying -terms (At-Kaci, 1984; At-Kaci & Nasr, 1986);algorithm relies UNION-FIND technique identify nodes merged, runstime slightly linear number nodes N . Therefore costnon-recursive portion graph normalization roughly linear number nodesit.merging two description graph nodes quite similar normalizationsingle node: atomic concept identifier lists need sorted/merged, duplicateseliminated y. done time proportional size nodesthemselves, make size node include size various lists it,atoms. processing role edges leaving node is, again, one identifying mergingidentically-labelled edges. (But case mergers labelled edges interact,single pass role-edge list sucient.) cost non-recursive aspectsmerger proportional size local information.therefore left problem bounding total number procedure callsNormalizeGraph, NormalizeNode, MergeEdge, MergeNode, boundingsizes nodes merged.NormalizeGraph NormalizeNode called exactly every (sub)graphnode original graph, part depth-first traversal, argued above,8. tend use fancy sorting techniques since lists likely long.294fiSubsumption CLASSICcontribute time proportional total size original graph,proportional size original description.number calls MergeEdge MergeNode simply bounded however {node may merged several times others. However, calls paired,invocation MergeNode reduces number nodes graph one. Therefore, since number nodes incremented elsewhere, total number callsMergeEdge MergeNode bounded number nodes original graph.problem non-recursive cost call MergeNode depends sizeargument nodes, call may increase size remaining nodesum sizes two original nodes.Therefore, original concept size S, graph n nodes, sizevi, worst case cost would result iterative summation sizes:(vi1 + vi2 ) + (vi1 + vi2 + vi3 ) + (vi1 + vi2 + vi3 + vi4 ) + : : := n vi1 + (n , 1) vi2 + : : : + 1 vinGiven n vj bounded, clearly worst case O(S 3).Pfact, given constraint j =1 nvj = , possible argue worst casecost occur vj = 1 every j, (i.e., n = ), case cost reallyO(S 2).theoretical improvements could attempted algorithm(e.g., merging nodes correct order increasing size) well analysis (e.g.,nodes graphs depth tree merged).remark like description logics, classic permits identifiers associated complex descriptions identifiers used descriptions(though recursion allowed). expansion identifiers standard operationlead exponential growth size certain pathological cases (Nebel, 1990), makingsubsumption problem inherently intractable. type system programming language Standard ML, pathological cases encountered practice,correct algorithm simple, straightforward ecient normal cases (unlikecorrect algorithm reasoning set constructor, say).users rarely ask whether concept subsumes another, ratherinterested relationship pairs concepts, classic fact constructsnormalized description graph description given it. suggests mightbetter check whether one description graph subsumes another one, rather checkingwhether description subsumes graph. general, works quite well, exceptwould verify attribute edges subsumer graph form subgraphsubsumee's attribute edges. Since edges uniquely labelled normalization,inherently hard, still requires complete traversal (and hence marking/unmarking)upper graph. therefore found useful encode part descriptiongraph's root same-as restrictions lead construction corresponding aedges; then, subsumption testing, aspect subsumer related same-aschecked list same-as pairs.Also, description algorithm tried optimize cost normalization, dominates checking single subsumption. overall use295fiBorgida & Patel-Schneidersystem (e.g., processing individuals), inquiries restrictions roles/attributesfrequent, space usage problem, may practically advantageousmaintain r-edges a-edges node hash table, rather sorted list,order speed access. (Note merging r-edges, one must however stillway iterating values stored hash table.)3. Individuals Descriptionspractical applications DLs used, integrity constraint checking,often useful able specify ranges atomic values roles. commonexamples involve integers, e.g., \the year student 1,2,3 4",called enumerated types Pascal, e.g., \the gender person either F". One wayallow constraints introduce new description constructor, set description,creates description list individual names, whose obvious extensionset consisting extensions individuals appear list. constructcould used terms like 8year:f1 2 3 4g. Another useful constructor involving individualsfills restriction, p : I, denotes objects extension individualone fillers relationship denoted role attribute p. (Noteattribute, q, 8q:fIg q : I.)Within paradigm DLs, constructors quite useful fact usedexpress new forms incomplete information. example, know Ringoearly fifties, simply assert Ringo described 8age:f50 51 52 53 54g.constructors also used ask useful queries. example, findmale persons suces determine instances gender : M.new constructors interact previous ones, cardinality constraints:clearly size set upper cardinality bound role restricts. interactionproblematic long individuals set host values, since individualsproperties fixed known ahead time. However, allow classicindividuals members sets, properties individuals mightaffect subsumption. simple example, know Ringo instanceconcept ROCK-SINGER (which shall write Ringo 2 ROCK-SINGER ) extension8friends:ROCK-SINGER always superset extension 8friends:fRingog.disturbing classification hierarchy definitions would changenew facts individuals added knowledge base. Definitions meantcontingent facts current world. Therefore, subsumption usually definedindependent \contingent" assertions. shall see below, use individualproperties description subsumption also leads intractability.3.1 Complex Subsumption Reasoning: ExampleTraditional proofs intractability (e.g. (Levesque & Brachman, 1987)) occasionallyleft users DLs puzzled intuitive aspects language make reasoningdicult. reason present example illustrates complexity reasoningset description.Suppose concept JADED-PERSON one wantsvisit Arctic and/or Antarctic, wherever penguins:296fiSubsumption CLASSICJADED-PERSON =: 8wantsToVisit:(fArctic Antarcticg u 8hasPenguins!: fYesg)Suppose remember Arctic Antarctic; knowSouth Pole located one two places, penguins there,North Pole located one two places, penguins there.Assuming isLocatedIn! hasPenguins! attributes|roles exactly one filler,recordSouthpole 2 8isLocatedIn!:(fArctic Antarcticg u 8hasPenguins!: fYesg)Northpole 2 8isLocatedIn!:(fArctic Antarcticg u 8hasPenguins!: fNog)thus unable distinguish exact location Southpole Northpole; however,since hasPenguins! single filler, exactly one Arctic Antarctic (and factmust) Yes filler hasPenguins!, therefore exactly one locationSouthpole .result facts, know extension JADED-PERSON mustsubset extension 1 wantsToVisit database containing factsSouthpole Northpole.Observe occasional worse-case behavior, generalizeddiculty reasoning set descriptions. subsumption ignores assertionsindividuals, (yet) show subsumption per se must perform inferences.simple transformation, given appendix, establishes fact, convertingrecognition individuals question subsumption two descriptionsmaking individuals involved attribute-fillers new dummy attributes,descriptions restrictions attributes. result, description non-emptyattribute values must satisfy corresponding restrictions.3.2 Modified Semantics Individualsseen two problems individuals appearing descriptions: (1) effect\mutable facts" extensional relationships \immutable" descriptions, (2)computational intractability subsumption caused appearance individualsdescriptions.deal first problem, reasonable restrict computation subsumption cannot access \database facts" individuals, role fillers,individuals treated like host identifiers. procedural descriptionaspect reasoning, sense negation-by-failure Prolog. Prolog,would desirable find semantic account phenomenon.semantics ignores mutable facts determining subsumption harddevise|all required two different sets possible worlds correspondingKB containing concepts individuals. One set consists possible worldsmodel information KB; second consists possible worldsmodel information concepts (and roles attributes). asking questions individuals, first set possible worlds must considered; askingsubsumption questions, second, larger, set must considered, thus ignoring effectsmutable facts.297fiBorgida & Patel-SchneiderHowever, semantics solve computational problem individualsdescriptions. deal problem, semantics individuals modifiedfollows: instead mapping individuals separate elements domain, donestandard semantics, individuals mapped disjoint subsets domain, intuitivelyrepresenting different possible realizations (Platonic) individual.Therefore, semantics set constructor stated follows: Domain valuebelongs extension fB1 : : : Bn g iff belongs extension one Bi .associated change notion cardinality required|two elements domainconsidered congruent belong extension individualidentical. cardinality set elements domain size setmodulo congruence relationship. means occurrences different identifiersdescription(s) guaranteed unequal, distinct occurrences individualidentifier guaranteed denote individual.two consequences stance:1. Looking descriptions Southpole Northpole Section 3.1, distinctoccurrences Arctic might satisfied distinct domain elements, different rolefillers. (In greater detail: extension Arctic might include domain elements d1d2, d1 satisfying condition hasPenguins! : Yes, d2 satisfies hasPenguins! : No.Southpole located d1, Northpole located d2 , stillsatisfying isLocatedIn! : Arctic. Similarly domain elements d3 d4extension Antarctic. Therefore one could two places visitpenguins, d1 d3.)2. Even though individual may description includesisLocatedIn! : Arctic u originatesIn! : Arctic;need satisfy condition isLocatedIn! = originatesIn!, since equality restriction requires identity domain values.4. Adding Individuals CLASSICIndividuals occur classic host descriptions. following constructs createclassic descriptions:R:IA:IfI1 : : : Ingattribute, R role, name classic individual host value,collectively called individuals, Ij names classic individuals. New host descriptionsconstructed using fI1 : : : g, Ij host values.interpretation function :I extended individual identifiers, requiring IInon-empty subset C , syntactically recognized host individual,making II = fIg host values I. stated earlier, interpretations distinct identifiersmust non-overlapping.interpretation CI non-atomic descriptions modified follows:298fiSubsumption CLASSICp : II = fd 2 C j 9x (d; x) 2 pI ^ x 2 II gfI1 : : : IngI = Sk IIk Ik classic individuals; fI1 : : : IngI = fI1 : : : g Ikhost individuals; empty otherwise.(n p)I (resp. (n p)I ) objects C least (resp. most) n noncongruent fillers role pdevelopment subsumption algorithm Section 2 modified takeaccount added constructs modified semantics introduced earlier.First description graphs extended. node description graph given thirdfield, either finite set individuals special marker denoting \universal"set. field often called dom node. a-edges r-edges givenextra field, called fillers edge. field finite set individuals.unspecified, constructions previous sections, dom node universal setfillers a-edge r-edge empty set.semantics description graphs Definition 3 extended following:Definition 7 Let G = hN; E; ri description graph let possible world.element, d, GI , iff function, , N1. = (r);2. n 2 N (n) 2 nI ;3. hn1 ; n2; A; F 2 E h(n1 ); (n2)i 2 AI , f 2 F , (n2 ) 2 f .element, d, nI , n = hC; H; i, iff1. C 2 C , 2 CI ;2. hR; m; M; G; F 2 H ,(a)(b)(c)elements, d0, domain hd; d0i 2 RI ;d0 2 GI d0 hd; d0i 2 RI ;f 2 F domain element, d0 , hd; d0i 2 RI d0 2 f3. universal set 9f 2 2 f .merging nodes, dom sets intersected. Merging description graphs unchanged. merging a-edges r-edges, sets fillers unioned.translation descriptions description graphs extended following rules:8. description form R : turned description graph one nodea-edges. node atoms CLASSIC-THING single r-edge roleR, min 0, max 1, fillers fIg. description graph restricting r-edgeGCLASSIC-THING classic individual, GHOST-THING otherwise.299fiBorgida & Patel-Schneider9. description form : turned description graph two nodessingle a-edge them. distinguished node graph sourcea-edge. r-edges atoms CLASSIC-THING. nodealso r-edges. atoms CLASSIC-THING classic individual,HOST-THING otherwise. a-edge single filler I.10. description form fI1 : : : g turned description graph one node.node dom set containing I1 , r-edges. atomsnode HOST-THING individuals host values, CLASSIC-THINGindividuals classic individual names. (Note parser ensuresindividuals either must host values must classic individual names.)short examination shows Theorem 1 true graphs, i.e., extensiondescription graphs formed using rules extension descriptionformed.following transformations added canonicalization algorithm:9. dom node empty, mark node incoherent.10. host value dom node atoms node, removedom.11. a-edge one filler, mark description graph incoherent.12. a-edge filler node end universal dom, make domfiller.13. filler a-edge included dom node end, markdescription graph incoherent.14. node one element dom, make element fillera-edges pointing it.15. fillers r-edge subset dom distinguished noderestriction graph edge, mark node r-edge incoherent.16. min r-edge less cardinality fillers it, let mincardinality.17. max r-edge greater cardinality dom distinguished node description graph r-edge, make max edgecardinality dom.18. min r-edge greater equal cardinality domdistinguished node restriction graph r-edge, let fillers edgeunion fillers dom above. (If min greater cardinality,steps 4 17 detect inconsistency.)300fiSubsumption CLASSIC19. max edge equal cardinality fillers edge, let domdistinguished node description graph r-edge intersectiondom fillers. (If max less cardinality, steps 18 4 detectinconsistency.)Note new canonical form a-edges pointing single nodevalue fillers, empty set, node setvalue dom.proofs Lemmas 3 2 also work extension description graphs.proof Theorem 2 extended graphs.subsumption algorithm page 289 extended follows:13. R : r-edge r role R fillers including I.14. : a-edge r attribute fillers including I.15. fI1 : : : g dom r subset fI1 : : : g.Again, soundness extended algorithm fairly obvious. completenessproof following additions construction graphical worlds:extension classic individual names starts empty.constructing graphical worlds node includes HOST-THINGatoms non-universal dom, pick domain elements correspondingelements dom.constructing graphical worlds node includes CLASSIC-THINGatoms non-universal dom, add distinguished domain elementextension one dom elements.constructing graphical worlds r-edges node, ensure elementfillers r-edge distinguished element least one graphicalworlds extension either adding extension using appropriatehost domain elements. (This done fillers must subsetdom distinguished node graphical world host values must belongatoms.)fillers a-edges need considered \pushed" onto nodescanonicalization process.proof Theorem 3 extended following cases:form fI1 : : : Ing dom r subset fI1; : : :; Ing. Thusgraphical worlds G distinguished domain elementextension Ij.form : either a-edge r labelledfiller a-edge.301fiBorgida & Patel-Schneiderformer case node pointed a-edge cannot domainsingleton consisting I. Therefore graphical worlds Gdistinguished node A-filler extension I, required.latter case, pick graphical worlds G distinguished node Afiller wrong realm. graphical worlds G distinguished elementextension D.form R : either r-edge r labelled Rfiller r-edge.former case either cardinality dom distinguished nodedescription graph r-edge greater min, m, r-edge, dominclude I. dom include I, graphical worldsnode distinguished element extension I, required.dom include I, least elements dom besides I,fillers r-edge subset set elements. thus graphicalworlds G use elements, required.latter case, pick graphical worlds G distinguished node Rfiller wrong realm. graphical worlds G distinguished elementextension D.shows subsumption algorithm given sound completemodified semantics presented here.5. Complete CLASSICmake final pass deal less problematic aspects classic descriptionsappropriately covered far.classic allows primitive descriptions form (PRIMITIVE T),description, symbol. extension arbitrary subsetextension D, extension (PRIMITIVE E T), providedE subsume other. way one express EMPLOYEE, kind personmust employee number,(PRIMITIVE (PERSON u 1 employeeNr) employee)construct removed creating every primitive atomic concept (e.g.,EMPLOYEEHOOD) replacing definition concept conjunctionnecessary conditions atom, case EMPLOYEEHOOD u (PERSON u1 employeeNr). Care taken use atomic concept equivalent primitives.classic permits declaration disjoint primitives, essentially allowing one stateextensions various atomic concepts must disjoint possible worlds.deal declarations, need modify algorithm creating canonical graphsadding step marks node incoherent whenever atoms contains two identifiersdeclared disjoint.302fiSubsumption CLASSICallow approximate representation ideas cannot encoded usingconstructors expressly provided, classic allows use test-defined concepts, usingfollowing syntax:(TEST [host-language Boolean function])e.g., (TEST Prime-Number-Testing-Function).9 purposes subsumption,treated \black-boxes", semantics assigned atomic concepts. (Test conceptsreal effect reasoning level individuals, perform constraintchecking.)simple additions, algorithm sound complete subsumptionalgorithm descriptions classic 1, modified semantics introducedpaper.6. Summary, Related Work, Conclusionsbelieve paper makes two kinds contributions: First, paper presents abstracted form subsumption algorithm classic description logic, showsecient correct modified semantics. significantprevious claims correct ecient subsumption algorithms implemented DLskandor (Patel-Schneider, 1984) candide (Beck et al., 1989) turnedunfounded (Nebel, 1988).tractability proof language like Basic classic claimed exist (butproven) (Donini et al., 1991), alternate proof technique may found considering restriction (corrected) subsumption algorithm (Hollunder & Nutt, 1990).Description graphs also turned interest supporttheoretical results DLs, concerning learnability (Cohen & Hirsh, 1994; Pitt &Frazier, 1994)|results would seem harder obtain using standard notationDLs.Second, paper investigates effect allowing individuals appear descriptions DLs. independently demonstrated (Lenzerini & Schaerf, 1991), addingset description introduces yet another source intractability, providedintuitive example illustrating source diculties. implementers classicsystem, like others use refutation/tableaux theorem-proving techniques, choseperform inferences validated standard semantics,formal intractability result obvious algorithm apparent, short enumerating possible ways filling roles. subset inferences actually performedinitially described procedurally: \facts" individuals taken accountsubsumption algorithm. paper provides denotational semantic accountincomplete set inferences. formal proof correct account corollarycompleteness proof subsumption algorithm Section 4, observationgraph construction subsumption algorithms section indeed ignore9. order deal two realms, classic fact provides two constructors: H-TEST CTEST, host classic descriptions, cause added complications besideskeeping track correct realm.303fiBorgida & Patel-Schneiderproperties individuals involved. one difference original implementation classic current semantics attribute paths endingfiller used imply equality condition. noted Section 3.2, modifiedsemantics support inference, taken implementationclassic. significant change standard semantics small, easy explainusers (either procedurally semantically), affects desired aspectslanguage (i.e., reasoning Basic classic remains exactly before).Acknowledgmentswish thank Ronald Brachman colleagues classic projectcollaboration, JAIR referees excellent suggestions improvingpaper. particular, one referees deserves medal thoroughness caretaken locating weaknesses arguments, thankful. remainingerrors course responsibility.ReferencesAt-Kaci, H. (1984). Lattice Theoretic Approach Computation Based CalculusPartially-Ordered Type Structures. Ph.D. thesis, University Pennsylvania.At-Kaci, H., & Nasr, R. (1986). LOGIN: logic programming language built-ininheritance. Journal Logic Programming, 3, 187{215.American Association Artificial Intelligence (1992). Issues Description Logics: UsersMeet Developers. Working Notes AAAI 1992 Fall Symposium.Baader, F., Burckert, H.-J., Heinsohn, J., Hollunder, B., Muller, J., Nebel, B., Nutt, W.,& Profitlich, H.-J. (1991). Terminological knowledge representation: proposalterminological logic. German Research Center Artificial Intelligence (DFKI).Baader, F., & Hanschke, P. (1991). scheme integrating concrete domains conceptlanguages. Proceedings Twelfth International Joint Conference ArtificialIntelligence, pp. 452{457. International Joint Committee Artificial Intelligence.long version appears Research Report RR-91-10 German Research CenterArtificial Intelligence (DFKI), April 1991.Baader, F., & Hollunder, B. (1991). KRIS: Knowledge Representation Inference System.SIGART Bulletin, 2 (2), 8{15.Beck, H. W., Gala, S. K., & Navathe, S. B. (1989). Classification query processingtechnique CANDIDE semantic data model. Proceedings Fifth International Data Engineering Conference, pp. 572{581. Institute Electric ElectronicEngineers.Borgida, A., Brachman, R. J., McGuinness, D. L., & Resnick, L. A. (1989). CLASSIC:structural data model objects. Proceedings 1989 ACM SIGMOD International Conference Mangement Data, pp. 59{67. Association ComputingMachinery.304fiSubsumption CLASSICBorgida, A. (1992). type systems knowledge representation: Natural semanticsspecifications description logics. International Journal Intelligent Cooperative Information Systems, 1 (1), 93{126.Brachman, R. J., Fikes, R. E., & Levesque, H. J. (1983). KRYPTON: functional approachknowledge representation. IEEE Computer, 16 (10), 67{73.Cohen, W. W., & Hirsh, H. (forthcoming). Learnability description logics equalityconstraints. Machine Learning. preliminary version appears ProceedingsFourth Annual Workshop Computational Learning Theory.Devanbu, P., Brachman, R. J., Ballard, B., & Selfridge, P. G. (1991). LaSSIE: knowledgebased software information system. Communications ACM, 34 (5), 35{49.Donini, F. M., Lenzerini, M., Nardi, D., & Nutt, W. (1991). Tractable concept languages.Proceedings Twelfth International Joint Conference Artificial Intelligence,pp. 458{453. International Joint Committee Artificial Intelligence.Doyle, J., & Patil, R. (1991). Two theses knowledge representation: Language restrictions, taxonomic classification, utility representation services. ArtificialIntelligence, 48 (3), 261{297.Pitt, L., & Frazier, M. (1994). Classic learning. Proceedings Seventh Annual ACMConference Computational Learning Theory New Brunswick, NJ. ACM Press.Heinsohn, J., Kudenko, D., Nebel, B., & Profitlich, H.-J. (1992). empirical analysis terminological representation systems. Proceedings Tenth NationalConference Artificial Intelligence, pp. 767{773. American Association ArtificialIntelligence.Hollunder, B., & Nutt, W. (1990). Subsumption algorithms concept languages. Researchreport RR-90-04, German Research Center Artificial Intelligence (DFKI).Lenzerini, M., & Schaerf, A. (1991). Concept languages query languages. ProceedingsNinth National Conference Artificial Intelligence, pp. 471{476. AmericanAssociation Artificial Intelligence.Levesque, H. J., & Brachman, R. J. (1987). Expressiveness tractability knowledgerepresentation reasoning. Computational Intelligence, 3 (2), 78{93.MacGregor, R. M., & Bates, R. (1987). Loom knowledge representation language. Tech.rep. ISI/RS-87-188, Information Sciences Institute, University Southern California.Mays, E., Apte, C., Griesmer, J., & Kastner, J. (1987). Organizing knowledge complexfinancial domain. IEEE Expert, 2, 61{70.Nebel, B. (1988). Computational complexity terminological reasoning BACK. ArtificialIntelligence, 34 (3), 371{383.Nebel, B. (1990). Terminological reasoning inherently intractable. Artificial Intelligence,43 (2), 235{249.305fiBorgida & Patel-SchneiderNebel, B., Peltason, C., & von Luck, K. (Eds.). (1991). International Workshop Terminological Logics. Document D-91-13, German Research Center Artificial Intelligence(DFKI).Owsnicki-Klewe, B. (1988). Configuration consistency maintenance task. Hoeppner, W. (Ed.), Proceedings GWAI-88|the 12th German Workshop ArtificialIntelligence, pp. 77{87. Springer Verlag.Patel-Schneider, P. F. (1984). Small beautiful knowledge representation.Proceedings IEEE Workshop Principles Knowledge-Based Systems, pp.11{16. IEEE Computer Society.Patel-Schneider, P. F. (1987). Decidable, Logic-Based Knowledge Representation. Ph.D.thesis, Department Computer Science, University Toronto.Patel-Schneider, P. F. (1989a). four-valued semantics terminological logics. ArtificialIntelligence, 38 (3), 319{351.Patel-Schneider, P. F. (1989b). Undecidability subsumption NIKL. Artificial Intelligence, 39 (2), 263{272.Peltason, C., von Luck, K., & Kindermann, C. (Eds.). (1991). Terminological Logic UsersWorkshop. Fachbereich Informatik, Technische Universitat Berlin.Peltason, C., von Luck, K., Nebel, B., & Schmiedel, A. (1987). user's guideBACK system. Kit-report 42, Fachbereich Informatik, Technische Universitat Berlin.Resnick, L. A., Borgida, A., Brachman, R. J., McGuinness, D. L., & Patel-Schneider,P. F. (1992). CLASSIC description reference manual COMMON LISPimplementation. AI Principles Research Department, AT&T Bell Laboratories.Schmidt-Schauss, M. (1989). Subsumption KL-ONE undecidable. ProceedingsFirst International Conference Principles Knowledge RepresentationReasoning, pp. 421{431. Morgan Kaufmann.Wright, J. R., Weixelbaum, E. S., Brown, K., Vesonder, G. T., Palmer, S. R., Berman,J. I., & Moore, H. H. (1993). knowledge-based configurator supports sales,engineering, manufacturing AT&T network systems. ProceedingsInnovative Applications Artificial Intelligence Conference, pp. 183{193. AmericanAssociation Artificial Intelligence.A. Intractability Reasoning ONE-OFpresent formal proof subsumption set descriptions fact NP-hard.10show term language allows set description need\case analysis" order check whether extension individual belongsdescription not; constructor behaves like disjunction elements10. original result submitted publication 1990. different, independent, proofresult since outlined (Lenzerini & Schaerf, 1991).306fiSubsumption CLASSICextensions individuals whose membership terms known priori, i.e., nonhost individuals. particular, show encode testing unsatisfiabilityformula 3CNF question recognizing individual instance description.Since problem known NP-hard, strong indication intractability.Start formula F , 3CNF. Using DeMorgan's laws, construct formula G,negation F , 3DNF. Testing validity G equivalent checkingunsatisfiability F .Construct every propositional symbol p used F , two individual names P P^ .(Here P^ represent negation p.) individual attribute truthValue,possible fillers True FalseP; P^ 2 8truthValue: fTrue Falseg:make sure P P^ exactly one, opposite, truth values, create twoindividual names, Yesp Nop, additional attributes approve deny respectively,whose fillers need truth value True False respectively:Yesp 2 8approve:(fP P^ g u 8truthValue: fTrueg)Nop 2 8deny:(fP P^ g u 8truthValue: fFalseg)Now, given formula G = C 1 _ C 2 _ : : : _ Cn, create individual names C1, C2,: : : , Cn, role conjuncts containing propositions conjuncts.example, C 1 = p ^ :q ^ :rC1 2 8conjuncts: fP Q^ R^ g u 3 conjuncts:Finally, construct individual G C1, C2, : : : , Cn possible fillers new roledisjunctsHolding :G 2 8disjunctsHolding: fC1 C2 : : : Cng:formula G valid iff always least one disjunct holds.equivalent membership concept VALID-FORMULAE defined1 disjunctsHolding u 8disjunctsHolding:(8conjuncts:(8truthValue:fTrueg)):shows recognizing whether individuals instances descriptionsintractable presence set descriptions, minimum number restrictions, valuerestrictions.convert question concerning subsumption two descriptionsessentially making individuals involved attribute-fillers new dummy attributes,descriptions restrictions attributes. description nonempty attribute values must satisfy corresponding restrictions.So, define concept UPPER8formula:VALID-FORMULAEdefine concept LOWER307fiBorgida & Patel-Schneider8dummy1-p:(fPg u [P 0s concept descriptor ]) u8dummy2-p:(fP^g u [P^ 0s concept descriptor ]) u8dummy3-p:(fYespg u : : :) u8dummy4-p:(fNopg u : : :) u:::8dummy5-ci:(fCig u : : :) u:::8formula:(fGg u : : :)database state either concept LOWER instances, casesubset extension UPPER, least one instance, caseindividual names filling various dummy attributes must properties ascribedthem, whence C VALID-FORMULAE (and hence UPPER subsume LOWER) iffC valid, completes proof.308fiJournal Artificial Intelligence Research 1 (1994) 159-208Submitted 8/93; published 2/94Bias-Driven Revision Logical Domain TheoriesMoshe KoppelRonen FeldmanKOPPEL@BIMACS.CS.BIU.AC.ILFELDMAN@BIMACS.CS.BIU.AC.ILDepartment Mathematics Computer Science, Bar-Ilan University,Ramat-Gan, IsraelAlberto Maria SegreSEGRE@CS.CORNELL.EDUDepartment Computer Science, Cornell University,Ithaca, NY 14853, USAAbstracttheory revision problem problem best go revising deficientdomain theory using information contained examples expose inaccuracies. paperpresent approach theory revision problem propositional domain theories.approach described here, called PTR, uses probabilities associated domain theory elementsnumerically track flow proof theory. allows us measure preciserole clause literal allowing preventing (desired undesired) derivation givenexample. information used efficiently locate repair flawed elements theory.PTR proved converge theory correctly classifies examples, shownexperimentally fast accurate even deep theories.1. IntroductionOne main problems building expert systems models elicited experts tendapproximately correct. Although hand-coded models might make good firstapproximation real world, typically contain inaccuracies exposed factasserted agree empirical observation. theory revision problemproblem best go revising knowledge base basis collectionexamples, expose inaccuracies original knowledge base. course,may many possible revisions sufficiently account observed examples; ideally,one would find revised knowledge base consistent examplesfaithful possible original knowledge base.Consider, example, following simple propositional domain theory, . theory,although flawed incomplete, meant recognize situations investor buystock soft drink company.buy-stock increased-demand product-liabilityproduct-liability popular-product unsafe-packagingincreased-demand popular-product established-marketincreased-demand new-market superior-flavor.theory essentially states buying stock company good idea demandproduct expected increase company expected face product liability lawsuits.theory, product liability lawsuits may result product popular (and therefore maypresent attractive target sabotage) packaging tamper-proof. Increasedproduct demand results product popular enjoys large market share,1994 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.fiKOPPEL, FELDMAN, & SEGREnew market opportunities product boasts superior flavor. Using closed worldassumption, buy-stock derivable given set true observable propositions precisely,say,{popular-product, established-market, celebrity-endorsement},{popular-product, established-market, colorful-label}are, say,{unsafe-packaging, new-market},{popular-product, unsafe-packaging, established-market}.Suppose told various examples whether buy-stock derivable.example, suppose told set true observable propositions is:(1){popular-product, unsafe-packaging, established-market} buy-stock false,(2){unsafe-packaging, new-market} buy-stock true,(3){popular-product, established-market, celebrity-endorsement} buy-stock true,(4){popular-product, established-market, superior-flavor} buy-stock false,(5){popular-product, established-market, ecologically-correct} buy-stock false,(6){new-market, celebrity-endorsement} buy-stock true.Observe examples 2, 4, 5 6 misclassified current theory . Assumingexplicitly given information regarding examples correct, question revisetheory examples correctly classified.1.1. Two ParadigmsOne approach problem consists enumerating partial proofs various examplesorder find minimal set domain theory elements (i.e., literals clauses) repairsatisfy examples (EITHER, Ourston & Mooney, press). One problemapproach proof enumeration even single example potentially exponential sizetheory. Another problem approach unable handle negated internalliterals, restricted situations example must belong one one class.problems suggest would worthwhile circumvent proof enumerationemploying incremental numerical schemes focusing blame specific elements.completely different approach revision problem based use neuralnetworks (KBANN, Towell & Shavlik, 1993). idea transform original domain theorynetwork form, assigning weights graph according pre-established scheme.connection weights adjusted accordance observed examples usingstandard neural-network backpropagation techniques. resulting network translatedback clausal form. main disadvantage method lacks representationaltransparency; neural network representation preserve structure originalknowledge base revising it. result, great deal structural information may losttranslating back forth representations. Moreover, translation imposeslimitations representations; example, since neural networks typically slowconverge, method practical shallow domain theories. Finally, revised domaintheories obtained via translation neural networks tend significantly largercorresponding original domain theories.160fiBIAS DRIVEN REVISIONapproaches theory revision much less closely related approachespouse RTLS (Ginsberg, 1990), KR-FOCL (Pazzani & Brunk, 1991),ODYSSEUS (Wilkins, 1988).1.2. Probabilistic Theory RevisionProbabilistic Theory Revision (PTR) new approach theory revision combinesbest features two approaches discussed above. starting point PTRobservation method choosing among several possible revisions basedimplicit bias, namely priori probability element (clause literal) domaintheory requires revision.PTR bias made explicit right start. is, element theoryassigned priori probability flawed. probabilities might assignedexpert simply chosen default.mere existence probabilities solves two central problems once. First,probabilities naturally define best (i.e., probable) revision given setpossible revisions. Thus, objective well-defined; need impose artificialsyntactic semantic criteria identifying optimal revision. Second, probabilitiesadjusted response newly-obtained information. Thus provide frameworkincremental revision flawed domain theory.Briefly, then, PTR algorithm uses set provided examples incrementallyadjust probabilities associated elements possibly-flawed domain theory orderfind probable set revisions theory bring accordexamples.1 Like KBANN, PTR incrementally adjusts weights associated domain theoryelements; like EITHER, stages PTR carried within symbolic logic frameworkobtained theories probabilistic.result PTR following features:(1)handle broad range theories including negated internal literalsmultiple roots.(2)linear size theory times number given examples.(3)produces relatively small, accurate theories retain much structureoriginal theory.(4)exploit additional user-provided bias.next section paper formally define theory revision problem discussissues data representation. lay foundations future approach theory revisionintroducing sharply defined terminology notation. Section 3 proposeefficient algorithm finding flawed elements theory, Section 4 showrevise elements. Section 5 describes two components combined formPTR algorithm. Section 5, also discuss termination convergence properties PTRwalk simple example PTR action. Section 6 experimentally evaluatePTR compare theory revision algorithms. Section 7, sum results1following section make precise notion probable set revisions.161fiKOPPEL, FELDMAN, & SEGREindicate directions research.formal presentation work described is, unfortunately, necessarily dense.aid casual reader, moved formal proofs three separate appendices.particular, third appendix prove that, appropriate conditions, PTR converges.Reading appendices safely postponed rest paperread. addition, provide Appendix D, quick reference guide notation usedthroughout paper. would suggest casual reader might prefer focusSection 2, followed cursory reading Sections 3 4, thorough readingSection 5.2. Representing Problempropositional domain theory, denoted , stratified set clauses form C : H BiC clause label, H proposition (called head C ) Bi set positivenegative literals (called body C ). usual, clause C : H Bi representsassertion proposition H implied conjunction literals Bi . domain theorysimply conjunction clauses. may convenient think propositionallogic program without facts (but negation allowed).proposition appear head clause said observable.proposition appears head clause appear bodyclause called root. example, E, truth assignment observable propositions.convenient think E set true observable propositions.Let domain theory roots r 1 , . . . , r n . example, E, define vector(E) = 1 (E), . . . , n (E) (E) = 1 E | r (using resolution) (E) = 0E |/ r . Intuitively, (E) tells us conclusions r 1 , . . . , r n drawn expertsystem given truth assignment E.Let target domain theory, , domain theory accurately models domaininterest. words, represents correct domain theory. ordered pair, E, (E) ,called exemplar domain: (E) = 1 exemplar said exemplarr , (E) = 0 exemplar said exemplar r . Typically,theory revision, know (E) without knowing .Let possibly incorrect theory domain turn correctly modeledtarget theory . inaccuracies reflected exemplars (E) (E).exemplars said misclassified . Thus, misclassified exemplar r , falsenegative r , (E) = 1 (E) = 0, misclassified exemplar r ,false positive r , (E) = 0 (E) = 1.2 Typically, theory revision know(E) without knowing .Consider, example, domain theory, , example set introduced Section 1.theory single root, buy-stock. observable propositions mentionedexamples popular-product, unsafe-packaging, established-market, new-market, celebrity2prefer new terminology IN/OUT standard positive/negative latter often used refer classification example given theory, use IN/OUTrefer specifically actual classification example.162fiBIAS DRIVEN REVISIONendorsement,superior-flavor,ecologically-correct.exampleE = {unsafe-packaging, new-market} (E) = 1 (E) = 0 . Nevertheless, told(E) = 1 (E) = 1 . Thus, E = {unsafe-packaging, new-market}, 1misclassified exemplar root buy-stock.Now, given misclassified exemplars, four revision operators available usepropositional domain theories:(1)add literal existing clause,(2)delete existing clause,(3)add new clause,(4)delete literal existing clause.negation-free domain theories, first two operations result specializing , since mayallow exemplars become exemplars. latter two operations resultgeneralizing , since may allow exemplars become exemplars.3say set revisions adequate set exemplars if, revisionoperators applied, exemplars correctly classified revised domain theory .Note implying identical , rather every exemplarE, (E) , (E) = (E). Thus, may one adequate revision set. goaltheory revision system, then, find best revision set , adequategiven set exemplars.2.1. Domain Theories Graphsorder define problem even precisely set stage solution,show represent domain theory form weighted digraph. begin defininggeneral version standard ANDOR proof tree, collapses distinctionnodes nodes.set propositions {P 1 , . . . , P n }, let NAND({P 1 , . . . , P n }) Boolean formulafalse {P 1 , . . . , P n } true. domain theory translatedequivalent domain theory consisting NAND equations follows:(1)clause C : H Bi , equation C = NAND(Bi ) .(2)non-observable proposition P appearing equation P = NAND(C P ), C P = {C H = P}, i.e., set consisting label clause whosehead P.(3)negative literal P appearing , equation P = NAND({P}) .contains equations these. Observe literals literalstogether new literals {C } correspond clauses . important,equivalent sense literal l assignment E truth valuesobservable propositions , E | l E | l.3event negative literals appear domain theory, consequences applyingoperators slightly less obvious. made precise second part section.163fiKOPPEL, FELDMAN, & SEGREConsider, example, domain theory Section 1. set NAND equationsbuy-stock = NAND({C 1 }),C 1 = NAND({increased-demand, product-liability}),product-liability = NAND({product-liability}),increased-demand = NAND({C 3 , C 4 }),product-liability = NAND({C 2 }),C 2 = NAND({popular-product, unsafe-packaging}),C 3 = NAND({popular-product, established-market}),C 4 = NAND({new-market, superior-flavor}).Observe buy-stock true precisely truth assignments observablesbuy-stock true .use obtain useful graph representation . equation , let h(i )refer left side let b(i ) refer set literals appear right side. words, h(i ) = NAND(b(i )).Definition: dt-graph domain theory consists set nodescorrespond literals set directed edges corresponding setordered pairs { x, x = h(i ), b(i ), }. addition, rootr add edge, er , leading r (from artificial node).words, consists edges literal antecedents. dtgraph representation shown Figure 1.Let n e node edge e leads let n e node comes.n e clause, say e clause edge; n e root, say e root edge;n e literal n e clause, say e literal edge; n e proposition n enegation, say e negation edge.dt-graph much like ANDOR graph . has, however, significantadvantage ANDOR graphs collapses distinction clause edgesliteral edges central ANDOR graph representation. fact, even negation edges(which appear ANDOR representation) distinguished literal edgesclause edges dt-graph representation.terms dt-graph , two basic revision operators deleting edges addingedges. effects adding deleting edges ? length every pathroot r node n even (odd) n said even (odd) node r . n e even (odd)r , e said even (odd) r . (Of course possible depth edgeneither even odd.) Deleting even edge r specializes definitions r senseresult deletion, (E) (E) exemplars E, (E) ; likewise,adding even edge r generalizes definition r sense resultadding edge (E) (E). Analogously, deleting odd edge r generalizesdefinition r , adding odd edge r specializes definition r . (Deletingadding edge neither odd even r might result new definition rneither strictly general strictly specific.)understand intuitively, first consider case negation edges. even edge represents clause , deleting specialization addinggeneralization. odd edge represents literal body clausedeleting generalization adding specialization. Now, odd number negation edges164fiBIAS DRIVEN REVISIONbuy-stockC1increased-demandproduct-liabilityC4new-marketC3product-liabilityestablished-marketsuperior-flavorC2popular-productunsafe-packagingFigure 1: dt-graph, , theory .present path r edge role edge reversed.2.2. Weighted Graphsweighted dt-graph ordered pair , w dt-graph w assignmentvalues (0, 1] node edge . edge e, w(e) meant representusers degree confidence edge e need deleted obtain correct domaintheory. node n, w(n) users degree confidence edge leading noden need added order obtain correct domain theory. Thus, example, assignmentw(n) = 1 means certain edge need added node n assignmentw(e) means certain e deleted. Observe node n labelednegative literal observable proposition w(n) = 1 definition, since graphs obtainedadding edges nodes correspond domain theory. Likewise, e rootedge negation-edge, w(e) = 1.165fiKOPPEL, FELDMAN, & SEGREpractical reasons, conflate weight w(e) edge e weight, w(n e ),node n e , single value, p(e) = w(e) w(n e ), associated edge e. value p(e)users confidence e need repaired, either deletion dilution via additionchild edges.many ways values assigned. Ideally, providedexpert actually reflect experts degree confidence elementtheory. However, even absence information, values assigned default;example, elements assigned equal value. sophisticated method assigningvalues assign higher values elements greater semantic impact (e.g.,closer roots). details one method given Appendix A. also,course, possible expert assign weights rest assigned accordingdefault scheme. example, weighted dt-graph, , p , shown Figure 2,edges assigned weight near 1 others assigned weights accordingsimple default scheme.semantics values associated edges made clear consideringcase known correct dt-graph subset given dt-graph, . Considerprobability function space subgraphs . weight edge simply sumprobabilities subgraphs edge appears. Thus weight edgeprobability edge indeed appear target dt-graph. easily extendcase target dt-graph necessarily subgraph given one.4Conversely, given probabilities associated edges assuming deletiondifferent edges independent events, compute probability subgraph, .Since p(e) probability e deleted 1 p(e) probability e deleted,followsp() =ep(e)e1 p(e).Letting = , rewritep() =ep(e)e1 p(e).use formula basis assigning value dt-graph obtainable viarevision set edges S, even case edge-independence hold evencase subset . simply definew() =ep(e)e1 p(e).(In event uniquely defined, choose w()maximized.) Note independence holds subgraph ,4order avoid confusion emphasized meaning weights associatededges completely different associated edges Pearls Bayesian networks (1988). us,weights represent meta-domain-theory concept: probability edge appears unknown target domain theory. Pearl represent conditional probabilities within probabilistic domain theory. Thus, updating method introduce totally unrelated Pearl.166fiBIAS DRIVEN REVISION.999buy-stock.99C11.0.95increased-demand.9product-liabilty.9C4.8new-market.9C3.8product-liability.8.8.9established-marketsuperior-flavorC2.8.99popular-productunsafe-packagingFigure 2: weighted dt-graph, , p .w() = p().2.3. Objectives Theory Revisionformally define proper objective theory revision algorithm:Given weighted dt-graph , p set exemplars , find dt-graphcorrectly classifies every exemplar w() maximal dt-graphs.Restating terminology information theory, define radicality dt-graphrelative initial weighted dt-graph = , pRad () =elog( p(e)) +elog(1 p(e))set edges need revised order obtain . Thus givenweighted dt-graph set exemplars , wish find least radical dt-graph relative167fiKOPPEL, FELDMAN, & SEGREcorrectly classifies set exemplars .Note radicality straightforward measure quality revision set neatlybalances syntactic semantic considerations. often noted minimizing syntacticchange alone lead counter-intuitive results giving preference changes near rootradically alter semantics theory. hand, regardless distributionexamples, minimizing semantic change alone results simply appending domain theorycorrect classifications given misclassified examples without affecting classificationexamples.Minimizing radicality automatically takes account criteria. Thus, example,assigning higher initial weights edges greater semantic impact (as defaultscheme Appendix A), syntactic advantage revising close root offsethigher cost revisions. example, suppose given theory introductionsingle misclassified exemplar{unsafe-packaging, new-market}, 1 .several possible revisions would bring accord exemplar.could, example, add new clausebuy-stock unsafe-packaging new-market,delete superior-flavor clause C4, delete popular-product established-market clauseC3, delete increased-demand clause C1. Given weights Figure 2, deletionsuperior-flavor clause C4 clearly least radical revision.Observe special case edges assigned identical initial weights,regardless semantic strength, minimization radicality indeed reduce formminimization syntactic change. wish point out, however, even casedefinition syntactic change differs previous definitions (Wogulis &Pazzani, 1993). Whereas definitions count number deleted added edges,count number edges deleted added to. understand preferable, considercase internal literal, happens large definition, omitted oneclause target theory. Methods count number added edgesstrongly biased restoring literal, prefering instead make several different repairscollectively involve fewer edges make single repair involving edges.Nevertheless, given assumption probabilities various edges given theorymistaken equal, far intuitive repair single edge, PTR does. (Weagree, though, edge chosen repair, chosen repair minimalequally effective repairs.)3. Finding Flawed ElementsPTR algorithm finds adequate set revisions approximately minimumradicality. achieves locating flawed edges repairing them. sectiongive algorithm locating flawed edges; next section show repair them.underlying principle locating flawed edges process exemplars one time,case updating weights associated edges accordance informationcontained exemplars. measure flow proof (or refutation) edgesgraph. edge contributes correct classification example,weight raised; contributes misclassification example,168fiBIAS DRIVEN REVISIONweight lowered. weight edge drops prespecified revision threshold ,revised.core algorithm method updating weights. Recall weightrepresents probability edge appears target domain theory. natural wayupdate weights, then, replace probability edge need revisedconditional probability need revised given classification exemplar.shall see later, computation conditional probabilities ensures many desirable propertiesupdating ad hoc methods liable miss.3.1. Processing Single ExemplarOne important results paper certain conditions conditionalprobabilities edges graph computed single bottom-up-then-top-downsweep dt-graph. shall employ method computation evenconditions hold. way, updating performed highly efficient fashion while,time, retaining relevant desirable properties conditional probabilities.precisely, algorithm proceeds follows. think nodesrepresent observable propositions input nodes, think values assignedexample E observable proposition inputs. Recall assignment weightsedges associated implicit assignment probabilities various dt-graphs obtainablevia revision . dt-graphs, root r provable example E,others not. wish make bottom-up pass = , p order compute(or least approximate) root r , probability target domain theoryr true example E. obtained probability compared desiredresult, (E), resulting difference used basis adjusting weights, w(e),edge e.Let1 P true EE(P) =0 P false E.say node n true literal labels true. Now, node passesvalue true graph either true deleted, i.e., undeleted false.Thus, edge e n e observable proposition P, valueu E (e) = 1 [ p(e) (1 E(P))] probability value true passed graphe.5Now, recalling node represents NAND operation, truth nodeindependent truth brothers, edge e, probability truepassed graph5Note that, principle, updating performed exactly way even 0 < E(P) < 1.Thus, algorithm extends naturally case uncertainty regarding truth-valueobservable propositions.169fiKOPPEL, FELDMAN, & SEGREu E (e) = 1 p(e)children(e)u E (s).call u E (e) flow E e.defined flow u E (e) that, appropriate independence conditions,node n e , u E (e) fact probability n e true given , w E. (For formal proofthis, see Appendix B.) particular, root r , flow u E (er ) is, even absenceindependence conditions, good approximation probability target theoryr true given , w E.second stage updating algorithm, propagate differencecomputed value u E (er ) (which lies somewhere 0 1) target value (E)(which either 0 1) top-down process similar backpropagation neuralnetworks. proceed, compute new value v E (e) well updated value p(e),every edge e . new value v E (e) represents updating u E (e) correctclassification, (E), example E taken account.Thus, begin setting value v E (r ) reflect correct classificationexample. Let > 0 small constant6 let(E) = 0v E (er ) =1(E) = 1.proceed top , computing v E (e) edge . casecompute v E (e) basis u E (e), is, basis much proof (or refutation)E flows edge e. precise formulav E (e) = 1 (1 u E (e))v E ( f (e))u E ( f (e))max[v E ( f (e)), u E ( f (e))]f (e) parent e 1greatest. showmin[v(f(e)),u(f(e))]EEAppendix B formula works.Finally, compute p new (e), new values p(e), using current value p(e)values v E (e) u E (e) computed:p new (e) = 1 (1 p(e))v E (e).u E (e)deletion different edges independent events known subgraph, p new (e) conditional probability edge e appears , given exemplarE, (E) (see proof Appendix B). Figure 3 gives pseudo code processing singleexemplar.Strictly speaking, computation conditional probabilities, need use = 0. However,order ensure convergence algorithm cases, choose > 0 (see Appendix C). experiments reported Section 6, use value = . 01.6170fiBIAS DRIVEN REVISIONfunction BottomUp( , p : weighted dt-graph, E: exemplar): array real;begin; V Leaves();e Leaves()begine E u(e) 1;else u(e) 1 p(e);Merge(S, Parents(e, ));endbegine PopSuitableParent(S, V ); V AddElement(e, V );u(e) 1 ( p(e)u(d));Children(e,)Merge(S, Parents(e, ));endreturn u;endfunction TopDown( , p : weighted dt-graph, u: array real,E: exemplar, : real): weighted dt-graph;begin; V Roots();r Roots()begin(E) = 1 v(r ) ;else v(r ) 1 ;Merge(S, Children(r , ));endbegine PopSuitableChild(S, V ); V AddElement(e, V ); f MostChangedParent(e, );v( f )v(e) 1 (1 u(e));u( f )v(e)p(e) 1 (1 p(e));u(e)Merge(S, Children(e, ));endreturn , p ;endFigure 3: Pseudo code processing single exemplar. functions BottomUp TopDownsweep dt-graph. BottomUp returns array edges representing proof flow, TopDownreturns updated weighted dt-graph. assuming dt-graph datastructure defined initialized appropriately. Functions Children, Parents, Roots, Leaves return setsedges corresponding corresponding graph relation dt-graph. Function Merge AddElement operate sets, functions PopSuitableParent PopSuitableChild return element first argument whose children parents, respectively, already elementssecond argument simultaneously deleting element first set, thus guaranteeingappropriate graph traversal strategy.171fiKOPPEL, FELDMAN, & SEGREConsider application updating algorithm weighted dt-graph Figure 2.given exemplar {unsafe-packaging, new-market}, 1 , i.e., exampleunsafe-packaging new-market true (and observables false) yieldderivation root buy-stock. weighted dt-graph obtained applying algorithmshown Figure 4.example illustrates important general properties method.(1)Given exemplar, weight odd edge cannot decrease weighteven edge cannot increase. (The analogous property holds exemplar.)case negation edge appears , corresponds fact clausecannot help prevent proof, literals body clause cannot help complete.998buy-stock.999C1.941.0increased-demand.98product-liability.91C4.8new-market1.0C3.15product-liability.69.69.88established-marketsuperior-flavorC2.96.99popular-productunsafe-packagingFigure 4: weighted dt-graph{unsafe-packaging, new-market}, 1 .Figure1722processingexemplarfiBIAS DRIVEN REVISIONproof. Note particular weights edges corresponding literalspopular-product established-market clause C3 dropped amount,reflecting identical roles played example. However, weightedge corresponding literal superior-flavor clause C4 drops great dealedges, reflecting fact deletion superior-flavor alone would allowproof buy-stock, deletion either popular-product alone establishedmarket alone would allow proof buy-stock.(2)edge initial weight 1 immutable; weight remains 1 forever. Thus althoughedge weight 1, corresponding literal increased-demand clauseC1, may contribute prevention desired proof, weight diminished sincetold possibility literal flawed.(3)processed exemplar correctly classified particular edge e revised,updated probability e approach 0 e immediately revised.7Thus, example, initial weights edge corresponding establishedmarket popular-product C3 approach 1, weight edge correspondingsuperior-flavor C4 would approach 0. Since use weights temporarydevice locating flawed elements, property renders updating methodappropriate purposes standard backpropagation techniques adjustweights gradually ensure convergence.(4)computational complexity processing single exemplar linear sizetheory . Thus, updating algorithm quite efficient compared revisiontechniques rely enumerating proofs root. Notecomputation required update weight identical every edge regardlessedge type. Thus, PTR well suited mapping onto fine-grained SIMD machines.3.2. Processing Multiple Exemplarsstated above, updating method applied iteratively one example time (in randomorder) edge drops revision threshold, . complete cycle edgedropped revision threshold, examples reordered (randomly)updating continued.8example, consider weighted dt-graph Figure 2. processing exemplars{unsafe-packaging, new-market}, 1 ,{popular-product, established-market, superior-flavor}, 0 ,{popular-product, established-market, celebrity-endorsement}, 0obtain dt-graph shown Figure 5. threshold is, say, = . 1, reviseedge corresponding clause C3. reflects fact clause C3 contributed7choose = 0 definition v E (er ), updated probability would equal 0.8course, processing examples one time abandon pretense algorithmBayesian. respect, proceeding spirit connectionist learning algorithmsassumed sequential processing examples random order, actually independent,approximates collective effect examples.173fiKOPPEL, FELDMAN, & SEGRE.999...buy-stock.998C1.951.0increased-demand.98product-liability.02C4.99new-market1.0product-liabilityC3.15.69.69established-marketsuperior-flavor.89C2.96.88popular-productunsafe-packagingFigure 5: weighted dt-graph Figure 2 processing exemplars{unsafe-packaging, new-market}, 1 ,{popular-product, established-market, superior-flavor}, 0 ,{popular-product, established-market, celebrity-endorsement}, 0 .clause C3 dropped threshold.substantially misclassification second third examples listcontributing substantially correct classification first.4. Revising Flawed Edgeedge selected revision, must decide revise it. Recall p(e)represents product w(e) w(n e ). Thus, drop p(e) indicates either e needsdeleted that, less dramatically, subtree needs appended node n e . Thus, needdetermine whether delete edge completely simply weaken adding children;intuitively, adding edges clause node weakens clause adding conditions body,174fiBIAS DRIVEN REVISIONadding edges proposition node weakens propositions refutation power addingclauses definition. Further, decide add children, need determinechildren add.4.1. Finding Relevant Exemplarsfirst stage making determination consists establishing, exemplar, roleedge enabling preventing derivation root. specifically,exemplar, E, (E) , root, r, edge e might play positive role facilitating proofr, play destructive role preventing proof r, may simply irrelevant proofr.sets exemplars e plays positive role destructive roledetermined, possible append e appropriate subtree effectively redefinesrole e used exemplars plays positive role.9 How,then, measure role e allowing preventing proof r E?first glance, would appear sufficient compare graph graph eresults deleting e . E | r E |/ e r (or vice versa) clear eresponsible r provable provable given exemplar E, (E) . But,criterion rigid. case exemplar, even case E |/ e r, stillnecessary modify e event e allowed additional proof r E. And,case exemplar, even case E | r still necessary modify eway prevent proof r E, since ultimately proof needed.Fortunately, weights assigned edges allow us flexibility merely determinewhether proof r E given e also measure numerically flowE r without e. needed design simple heuristiccaptures degree e contributes proof r E.Let = , p weighted dt-graph revised. Let e = , p pidentical p, except p(e) = 1. Let e = , p p identical p, exceptp(e) = 0; is, e obtained deleting edge e.define root r1 (E) ue (e )riERi ( E, (E) , e, ) =.1 (E) ue (e )rERi ( E, (E) , e, ) > 2, say e needed E rRi ( E, (E) , e, ) < 1/2 say e destructive E r .9PTR strictly incremental sense edge revised role proving refuting exemplar checked. strict incrementality desideratum, PTR slightly modifiededge revised basis exemplars already processed. Moreover,generally necessary check exemplars relevance. example, e odd edge Ecorrectly classified exemplar, e neither needed E (since odd edges makederivations difficult) destructive E (since E correctly classified despite e).175fiKOPPEL, FELDMAN, & SEGREIntuitively, means, example, edge e needed exemplar, E, r ,derivation r E passes edge e. simply given formaldefinition notion derivation passes e, namely, flow,u E e (er ), E r without e less half flow, u E e (er ), E r e.negation-free theories, corresponds case edge e represents clausecritical derivation r E. intuition destructive edgesexemplars analogous. Figure 6 gives pseudo code computing needed destructivesets given edge e exemplar set .order understand better, let us return example dt-graph stateleft Figure 5. edge corresponding clause C3 droppedthreshold. let us check exemplars edge neededdestructive. Computing R( E, (E) , C3, ) example E obtain following:R( {popular-product, unsafe-packaging, established-market}, 0 , C3, ) = 0. 8R( {unsafe-packaging, new-market}, 1 , C3, ) = 1. 0R( {popular-product, established-market, celebrity-endorsement}, 1 , C3, ) = 136. 1R( {popular-product, established-market, superior-flavor}, 0 , C3, ) = 0. 1R( {popular-product, established-market, ecologically-correct}, 0 , C3, ) = 0. 1R( {new-market, celebrity-endorsement}, 1 , C3, ) = 1. 0function Relevance( , p : weighted dt-graph , : exemplar set, e: edge): tuple set;beginN ;;p saved Copy( p);Er Roots()p(e) 1; u BottomUp(, p, E); u E e u(r ); p p saved ;p(e) 0; u BottomUp(, p, E); u E e u(r ); p p saved ;eu(E) = 1 Ri E e ;uE1 uEeelse Ri;1 uEeRi > 2 N N {E};1Ri < {E};2endendreturn N , ;endFigure 6: Pseudo code computing relevant sets (i.e., needed destructive sets)given edge e exemplar set . general idea compare proof flow (computed usingfunction BottomUp) without edge question exemplar exemplarset. Note original weights saved later restored end computation.176fiBIAS DRIVEN REVISIONhigh valueR( {popular-product, established-market, celebrity-endorsement}, 1 , C3, )reflects fact without clause C3, scant hope derivation buy-stockexample. (Of course, principle, new-market superior-flavor might still deletedbody clause C4, thus obviating need C3, high weight associatedliteral new-market C4 indicates unlikely.) low valuesR( {popular-product, established-market, superior-flavor}, 0 , C3, )R( {popular-product, established-market, ecologically-correct}, 0 , C3, )reflect fact eliminating clause C3 would greatly diminish currently undesirablyhigh flow buy-stock (i.e., probability derivation buy-stock)examples.interesting case examine{popular-product, unsafe-packaging, established-market}, 0 .true elimination C3 helpful preventing unwanted derivation buy-stockprevents derivation increased-demand necessary buy-stock clauseC1. Nevertheless, R correctly reflects fact clause C3 destructiveexemplar since even presence C3, buy-stock derivable due failureliteral product-liability.4.2. Appending SubtreeLet N set examples e needed root let set examplese destructive root (and needed root). foundsets N D, repair e?point, set non-empty set N empty, simply delete edge. justify deletion noting exemplars require e, deletioncompromise performance theory. hand, N empty, applyinductive algorithm10 produce disjunctive normal form (DNF) logical expression constructedobservable propositions true exemplar exemplar N .reformulate DNF expression conjunction clauses taking single new literal lhead clause, using conjunct DNF expression body oneclauses. set clauses converted dt-graph n l root. suture n eadding new node t, edge e t, another edge root, l, n .order understand works, first note important fact (like everysubroutine PTR), method essentially identical whether edge, e, repairedclause edge, literal edge negation edge. However, translating back dt-graph formdomain theory form, new node interpreted differently depending whether n eclause literal. n e literal, interpreted clause n e l. n e clause,10standard algorithm constructing decision trees positive negative examplesused. implementation PTR uses ID3 (Quinlan, 1986). use inductive component addnew substructure due Ourston Mooney (Ourston & Mooney, press).177fiKOPPEL, FELDMAN, & SEGREinterpreted negative literal l.11plain exemplars e destructive use graph rootedovercome effect e. n e literal undesirably excludes E, E get n esatisfying clause t; n e clause undesirably allows E, E stoppedfunction Revise( , p : weighted dt-graph , : set exemplars, e: edge, : real): weighted dt-graph;beginN , Relevance( , p , , e);beginN = p(e) 0;elsebeginp(e) ;l NewLiteral();ID3 = DTGraph(l, DNF-ID3(D, N ));NewNode(); AddNode(, t);Clause?(n e ) Label(t) l;else Label(t) NewClause();AddEdge(, n e , ); p( n e , ) ;AddEdge(, t, Root( ID3 ) ); p( t, Root( ID3 ) ) 1;ID3 ; e ID3 p(e) 1;endendreturn , p ;endFigure 7: Pseudo code performing revision. function Revise takes dt-graph, set exemplars , edge revised e, parameter inputs produces revised dt-graphoutput. function DNF-ID3 inductive learning algorithm produces DNF formulaaccepts elements N , function DTGraph produces dt-graphgiven root given DNF expression described text. sake expository simplicity, shown special cases n e leaf e negation edge, discussed Footnote 11.11course, willing sacrifice elegance, could allow separate sub-routinesclause case literal case. would allow us make dt-graphs sutured considerablycompact. particular, n e literal could suture children l n directly n e . n eclause, could use inductive algorithm find DNF expression excludes examplesincludes N (rather way around it). Translating expression dtgraph root l, could suture n simply adding edge clause n e root l.Moreover, n represents single clause l l 1 , . . . , l simply suture leaf-nodesl 1 , . . . , l directly n e . Note n e leaf negative literal, inappropriate append childedges n e . cases, simply replace n e new literal l append l n graphclause l n e .178fiBIAS DRIVEN REVISIONnew literal = l.Whenever graph n sutured , must assign weights edges n . Unlikeoriginal domain theory, however, new substructure really artifact inductivealgorithm used current relevant exemplar set. reason, almost certainlyinadvisable try revise new exemplars encountered. Instead, would prefernew structure removed replaced appropriate new constructneed arise. ensure replacement instead revision, assign unit certainty factors edgessubstructure. Since internal edges new structure weights equal 1,never revised. Finally, assign default weight substructure root edge n e , ,connects new component existing reset weight revised edge,e, value . Figure 7 gives pseudo code performing revision stepdescribed.Consider example above. repairing clause C3. already foundset consists examples{popular-product, established-market, superior-flavor}{popular-product, established-market, ecologically-correct}set N consists single example{popular-product, established-market, celebrity-endorsement}.Using ID3 find formula excludes N includes D, obtain { celebrityendorsement} translates single clause, {l celebrity-endorsement}. Translatingdt-graph form suturing (and simplifying using technique Footnote 11), obtaindt-graph shown Figure 8.Observe domain theory represented dt-graph correctly classifiesexamples{popular-product, established-market, superior-flavor}{popular-product, established-market, ecologically-correct}misclassified original domain theory .5. PTR Algorithmsection give details control algorithm puts pieces previoustwo sections together determines termination.5.1. ControlPTR algorithm shown Figure 9. briefly summarize operation follows:(1)PTR process exemplars random order, updating weights performing revisionsnecessary.(2)Whenever revision made, domain theory corresponds newly revisedgraph checked exemplars.(3)PTR terminates if:(i) exemplars correctly classified,(ii) Every edge newly revised graph weight 1.179fiKOPPEL, FELDMAN, & SEGRE.999...buy-stock.998C1.951.0increased-demandproduct-liability.70.981.0C4.99new-marketC3.15.69.70product-liability.69established-marketcelebrity-endorsementsuperior-flavor.89C2.96.88popular-productunsafe-packagingFigure 8: weighted dt-graph Figure 2 revising clause C3 (the graphslightly simplified accordance remark Footnote 11).(4)If, revision made, PTR terminate, continues processingexemplars random order.(5)if, complete cycle exemplars processed, remain misclassifiedexemplars,(i) Increment revision threshold = min[ + , 1],(ii) Increment value assigned revised edge root edge addedcomponent, = min[ + , 1].(6)begin anew, processing exemplars (new) random order.easy see PTR guaranteed terminate. argument follows. Within1 1max , cycles, reach 1. point, every edge weight less180fiBIAS DRIVEN REVISION1 revised either deleted weight reset = 1. Moreover, edgesadded revision also assigned certainty factor = 1. Thus edges weight1 algorithm terminates termination criterion (ii).Now, wish show PTR terminates, terminates everyexemplar correctly classified. is, wish show that, fact, termination criterion (ii)never satisfied unless termination criterion (i) satisfied well. call propertyconvergence. Appendix C prove that, certain general conditions, PTRguaranteed converge.5.2. Complete ExampleLet us review example considering throughout paper.begin flawed domain theory set exemplars introduced Section 1.C1: buy-stock increased-demand product-liabilityC2: product-liability popular-product unsafe-packagingC3: increased-demand popular-product established-marketC4: increased-demand new-market superior-flavor.translate domain theory weighted dt-graph , p Figure 2, assigningweights via combination user-provided information default values. example, userindicated confidence first literal (increased-demand) body clause C1greater confidence second literal ( product-liability).function PTR( , p : weighted dt-graph, : set exemplars,0 , 0 , , , : five tuple real): weighted dt-graph;begin0;0;E (E) (E)beginE RandomlyPermute()beginu BottomUp( , p , E);, p TopDown( , p , u, E, );e p(e) , p Revise( , p , , , );e , p(e) = 1 E , (E) = (E) return , p ;endmax[ + , 1];max[ + , 1];endendFigure 9: PTR control algorithm. Input algorithm consists weighted dt-graph, p , set exemplars , five real-valued parameters 0 , 0 , , , . algorithmproduces revised weighted dt-graph whose implicit theory correctly classifies exemplars .181fiKOPPEL, FELDMAN, & SEGREset revision threshold .1, reset value initially .7 respectiveincrements . 03. start updating weights edges processingexemplars random order.first process exemplar{unsafe-packaging, new-market}, 1 .First, leaves dt-graph labeled according presence absence exemplar.Second, u E (e) values (proof flow) computed edges dt-graph bottomfashion. Next, v E (er ) values set reflect vector correct classifications example(E). New values v E (e) computed top fashion edge dt-graph.values computed, new values p(e) also computed. Processing firstexemplar produces updated dt-graph shown Figure 3.Processing exemplars continues either edge weight falls (indicatingflawed domain theory element located), cycle (processing known exemplars)completed, PTR termination conditions met. example, processingadditional exemplars{popular-product, established-market, superior-flavor}, 0{popular-product, established-market, ecologically-correct}, 0weight edge corresponding clause C3 drops (see Figure 5), indicatingedge needs revised.proceed revision using heuristic Section 4.2 order determineset exemplars edge question needed destructive. edgecorresponding clause C3 needed{ {popular-product, established-market, celebrity-endorsement}, 1 }destructive{ {popular-product, established-market, ecologically-correct}, 0 ,{popular-product, established-market, superior-flavor}, 0 }.Since set edge needed empty, PTR chooses append subtreeweakening clause C3 rather simply deleting clause outright. Using sets inputID3, determine fact celebrity-endorsement suitably discriminates neededdestructive sets. repair graph obtain weighted dt-graph shown Figure 8.graph corresponds theory literal celebrity-endorsement addedbody C3.check newly-obtained theory embodied dt-graph Figure 8 (i.e., ignoringweights) exemplars determine still misclassified exemplars,namely{unsafe-packaging, new-market}, 1{new-market, celebrity-endorsement}, 1 .Thus, continue processing remaining exemplars original (random) order.processing exemplars{popular-product, unsafe-packaging, established-market}, 0 ,{popular-product, established-market, celebrity-endorsement}, 1 ,{new-market, celebrity-endorsement}, 1 ,182fiBIAS DRIVEN REVISIONweight edge corresponding literal superior-flavor clause C4 dropsrevision threshold . determine edge needed exemplar thusedge simply deleted.point, misclassified exemplars remain. final domain theory is:C1: buy-stock increased-demand product-liabilityC2: product-liability popular-product unsafe-packagingC3: increased-demand popular-product established-market celebrity-endorsementC4: increased-demand new-market.theory correctly classifies known exemplars PTR terminates.6. Experimental Evaluationsection examine experimental evidence illustrates several fundamentalhypotheses concerning PTR. wish show that:(1)theories produced PTR high quality three respects: low radicality,reasonable size, provide accurate information regarding exemplarsused training.(2)PTR converges rapidly is, requires cycles find adequate setrevisions.(3)well-chosen initial weights provided domain expert significantly improveperformance PTR.precisely, given theory obtained using PTR revise theory basisset training examplars, test hypotheses follows.Radicality. claim Rad () typically close minimal theoriescorrectly classify examples. cases target theory, , known, measureRad (). value less 1, PTR said done even betterRad ()finding target theory sense able correctly classify training examplesusing less radical revisions required restore target theory. value greater1, PTR said over-revised theory.Cross-validation. perform one hundred repetitions cross-validation using nested setstraining examples. noted actual objective minimize radicality,often theories less radical target theory also satisfytraining examples. Thus, cross-validation gives indication theory revisionsuccessfully performed, primary objective theory revision.Theory size. count number clauses literals revised theory merelydemonstrate theories obtained using PTR comprehensible. course, precise sizetheory obtained PTR largely artifact choice inductive component.Complexity. Processing complete cycle exemplars O(n d) n numberedges graph number exemplars. Likewise repairing edge O(n d).measure number cycles number repairs made convergence. (Recall1 1number cycles convergence event bounded max , .show that, practice, number cycles small even = = 0.183fiKOPPEL, FELDMAN, & SEGREUtility Bias. wish show user-provided guidance choosing initial weightsleads faster accurate results. cases target theory, , known, letset edges need revised order restore target theory . Define11/ S, p (e) = ( p(e)) .p (e) e S, 1 p (e) = (1 p(e)) eis, edge needs revised obtain intended theory initial weightdiminished edge need revised obtain intended theory weightincreased. Let = , p . Then, ,1Rad () = log( (1 p(e))e1( p(e)) ) =e/1Rad ().Here, compare results cross-validation number-of-cycles experiments = 2unbiased counterparts (i.e., = 1).6.1. Comparison Methodsorder put results perspective compare results obtainedmethods.12(1)ID3 (Quinlan, 1986) inductive component use PTR. Thus using ID3equivalent learning directly examples without using initial flawed domaintheory. comparing results obtained using ID3 obtained using PTRgauge usefulness given theory.(2)EITHER (Ourston & Mooney, press) uses enumeration partial proofs order findminimal set literals, repair satisfy exemplars. Repairsmade using inductive component. EITHER exponential sizetheory. cannot handle theories negated internal literals. also cannot handletheories multiple roots unless roots mutually exclusive.(3)KBANN (Towell & Shavlik, 1993) translates symbolic domain theory neural net,uses backpropagation adjust weights nets edges, translates backnet form partially symbolic form. rules theory outputKBANN might numerical, i.e., strictly symbolic.(4)RAPTURE (Mahoney & Mooney, 1993) uses variant backpropagation adjustcertainty factors probabilistic domain theory. necessary, also add clauseroot. rules produced RAPTURE numerical. Like EITHER, RAPTUREcannot handle negated internal literals multiple roots mutually exclusive.Observe that, relative methods considered here, PTR liberal termstheories handle, (like KBANN, unlike EITHER RAPTURE) handlenegated literals non-mutually exclusive multiple roots; also strict terms theoriesyields (like EITHER, unlike KBANN RAPTURE) produces strictly symbolictheories.12interesting theory revision algorithms, RTLS (Ginsberg, 1990),comparable data available.184fiBIAS DRIVEN REVISIONnoted KBANN RAPTURE output numerical rules. caseKBANN, numerical rule one fires sum weights associated satisfiedantecedents exceeds threshold. case RAPTURE, rules probabilistic rules usingcertainty factors along lines MYCIN (Buchanan & Shortliffe, 1984). One might ask, then,extent results obtained theory revision algorithms output numerical rulesmerely artifacts use numerical rules? words, separate effectsusing numerical rules effects learning?make concrete, consider following simple method transformingsymbolic domain theory probabilistic domain theory reclassifying examples usingobtained probabilistic theory. Suppose given possibly-flawed domain theory .Suppose given classification even single example. Assign weightp(e) edge according default scheme Appendix A. Now, using bottomup subroutine updating algorithm, compute u E (er ) test example E. (Recallu E (er ) measure close derivation r E is, given weighted dt-graph, p .) Now, chosen cutoff value 0 n 100, E 0 u E 0 (er ) liesupper n% set values {u E (er )} conclude true E 0 ; otherwise concludefalse E 0 .method, purpose discussion call PTR*, use trainingexamples all. Thus results theory revision systems employ numerical rulesmatched PTR* performs learning clear results merelyartifacts use numerical rules.6.2. Results PROMOTER Theoryfirst consider PROMOTER theory molecular biology (Murphy & Aha, 1992),interest solely extensively studied theory revision literature(Towell & Shavlik, 1993), thus enabling explicit performance comparison algorithms.PROMOTER theory flawed theory intended recognize promoters DNA nucleotides.theory recognized none set 106 examples promoters despite fact preciselyhalf indeed promoters.13Unfortunately, PROMOTER theory (like many others used theory revisionliterature) trivial shallow. Moreover, atypical flawed domainsoverly specific overly general. Given shortcomings PROMOTER theory,also test PTR synthetically-generated theory errors artificiallyintroduced. synthetic theories significantly deeper used test previousmethods. Moreover, fact intended theory known enable us performexperiments involving radicality bias.13experiments, use default initial weights assigned scheme Appendix A. addition, clause whose head proposition contact treated definition subject revisiondeletion whole.185fiKOPPEL, FELDMAN, & SEGRE6.2.1. Cross-validationFigure 10 compare results cross-validation PROMOTER. distinguishmethods use numerical rules (top plot) purely symbolic(bottom plot).lower plot Figure 10 highlights fact that, using value n = 50, PTR* achievesbetter accuracy, using training examples, methods considered achieveusing 90 training examples. particular, computing u E (er ) example, obtain53 highest-ranking examples 50 indeed promoters (and, therefore, 53 lowestranking examples 50 indeed non-promoters). Thus, PTR* achieves 94. 3% accuracy. (In fact,47 highest-ranking examples promoters 47 lowest-rankingpromoters. Thus, conservative version PTR* classifies the, say, 40% highestranking examples 40% lowest-ranking OUT, would indeed achieve 100%accuracy examples ventured prediction.)merely shows original PROMOTER theory accurate providedgiven numerical interpretation. Thus conclude success RAPTURE KBANNdomain consequence learning examples rather artifact usenumerical rules.three methods EITHER, PTR ID3 yield symbolic rules, seetop plot Figure 10 that, reported (Ourston & Mooney, press; Towell &Shavlik, 1993), methods exploit given flawed theory indeed achieve betterresults PROMOTER ID3, exploit theory. Moreover, sizetraining set grows, performance PTR increasingly better EITHER.14Finally, wish point interesting fact example set. set 13106 examples contain information substantially differentrest examples. Experiments show using ten-fold cross-validation 93 goodexamples yields 99. 2% accuracy, training 93 examples testing 13bad examples yields 40% accuracy.6.2.2. Theory sizesize output theory important measure comprehensibility outputtheory. Ideally, size theory grow rapidly number trainingexamples increased, larger theories necessarily harder interpret. observationholds number clauses theory well average numberantecedents clauses.Theory sizes theories produced PTR shown Figure 11. strikingaspect numbers measures theory size relatively stable respecttraining set size. Naturally, exact values large degree artifact inductivelearning component used. contrast, EITHER, theory size increases training set size14readers familiar PROMOTER theory note improvement EITHER consequence PTR repairing one flaw time using sharper relevance criterion.results PTR always deleting extraneous conformation literal, EITHER occasionallly failsso, particularly number training exmaple increases.186fiBIAS DRIVEN REVISION60% Misclassified50ID3EITHERPTR403020100020406060% Misclassified5080100# Training ExemplarsRAPTUREKBANNPTR*403020100020406080100# Training ExemplarsFigure 10: PROMOTER: Error rates using nested training sets purely symbolic theories (topplot) numeric theories (bottom plot). Results EITHER, RAPTURE, KBANN taken(Mahoney & Mooney, 1993), results ID3 PTR generated using similar experimental procedures. Recall PTR* non-learning numerical rule system; PTR* lineextended horizontally clarity.187fiKOPPEL, FELDMAN, & SEGRETrainingSet SizeMeanClausesOutputMeanLiteralsOutputOriginalTheory14832040608010011111111123936353236MeanRevisionsConvergenceMeanExemplarsConvergence10.715.218.222.122.088140186232236Figure 11: PROMOTER: Results. Numbers reported training set size average valuesone hundred trials (ten trials ten example partitions).(Ourston, 1991). example, 20 training examples output theory size (clauses plusliterals) 78, 80 training examples, output theory size 106.Unfortunately, making direct comparisons KBANN RAPTURE difficult.case KBANN RAPTURE, allow numerical rules, comparison impossible givendifferences underlying representation languages. Nevertheless, clear that,expected, KBANN produces significantly larger theories PTR. example, using 90training examples PROMOTER theory, KBANN produces numerical theories with,average, 10 clauses 102 literals (Towell & Shavlik, 1993). numbers would growsubstantially theory converted strictly symbolic terms. RAPTURE,hand, change theory size, but, like KBANN, yields numerical rules (Mahoney &Mooney, 1993).6.2.3. ComplexityEITHER exponential size theory number training examples.KBANN, cycle training-by-backpropagation subroutine O(d n) (wheresize network n number exemplars), number cycles typicallynumbers hundreds even shallow nets.Like backpropagation, cost processing example PTR linear sizetheory. contrast, however, PTR typically converges processing tiny fractionnumber examples required standard backpropagation techniques. Figure 11 showsaverage number exemplars (not cycles!) processed PTR convergence functiontraining set size. cost incurred PTR revising theory.revision O(d n). average number revisions convergence also shown Figure 11.6.3. Results Synthetic Theoriescharacter PROMOTER theory make less ideal testing theory revisionalgorithms. wish consider theories (i) deeper, (ii) make substantial usenegated internal literals (iii) overly general well overly specific. opposedshallow theories generally easily repaired leaf level, deeper theories often188fiBIAS DRIVEN REVISIONrequire repairs internal levels theory. Therefore, theory revision algorithm mayperform well shallow theories necessarily scale well larger theories. Moreover,theory size increases, computational complexity algorithm might precludeapplication altogether. wish show PTR scales well larger, deeper theories.Since deeper, propositional, real-world theories scarce, generatedsynthetically. added bonus, know target theory perform controlledexperiments bias radicality. (Feldman, 1993) aggregate results experimentsperformed collection synthetic theories reported. order avoid dubiouspractice averaging results different theories order highlight significant featuresparticular application PTR, consider one synthetic theory typical studied(Feldman, 1993).r A, Br C,E, Fp0 , G, p1 , p2 , p3B p0B p1 , HB p4 , p11C I, JC p2 , KC p8 , p9p10 , p12 , Lp3 , p9 ,E N , p5 , p6E O, p7 , p8F p4F Q, RG S, p3 , p8G p10 , p12H U, VH p1 , p2 ; p3 , p4Wp6J X, p5JK P, p5 , p9K p6 , p9L , p1L p2 , p12 , p16Z , p17p18 , p19N p0 , p1N p3 , p4 , p6N p10 , p12Z p2 , p3Z p2 , p3 , p17 , p18 , p20p3 , p4 , p5 , p11 , p12p13 , p18p4 , p5 p6P p6 , p7 , p8X p7 , p9Q p0 , p4Q p3 , p13 , p14 , p15W p10 , p11W p3 , p9R p12 , p13 , p14V p14 , p15p3 , p6 , p14 , p15 , p16U p11 , p12U p13 , p14 , p15 , p16 , p17p7p7 , p8 , p9 , p16 , p17 , p18Figure 12: synthetic domain theory used experiments Section 6.189fiKOPPEL, FELDMAN, & SEGREtheory shown Figure 12. Observe includes four levels clausesmany negated internal nodes. thus substantially deeper theories consideredtesting theory revision algorithms. artificially introduce, succession, 15 errorstheory . errors shown Figure 13. theories, use default initialweights assigned scheme Appendix A.Let theory obtained introducing first errors. Figure 14show radicality, Rad (), relative flawed theories, = 3, 6, 9, 12, 15,well number examples misclassified theories. Note that, general,number misclassified examples cannot necessarily assumed increase monotonicallynumber errors introduced since introducing error may either generalizespecialize theory. example, fourth error introduced undone fifth error.Nevertheless, case particular set errors, successive theoryradical misclassifies larger number examples respect .measure radicality accuracy, choose 200 exemplars classified according. (i = 3, 6, 9, 12, 15), withhold 100 test examples train nested sets20, 40, 60, 80 100 training examples. choose ten partitions run ten trialspartition.Rad (), theory producedFigure 15, graph average valueRad ()PTR. seen, value consistently 1. indicates revisions found123456789101112131415Added clause p6Added clause p5Added clause p8 , p15Added literal p6 clause B p4 , p11Deleted clause B p4 , p6 , p11Added clause p14Added clause G p12 , p8Added literal p2 clause E, FAdded clause L p16Added clause p13 , p7Deleted clause Q p3 , p13 , p14 , p15Deleted clause L p2 , p12 , p16Added clause J p11Deleted literal p4 clause F p4Deleted literal p1 clause B p1 , HFigure 13: errors introduced synthetic theory order produce flawed synthetic theories . Note fifth randomly-generated error obviates fourth.190fiBIAS DRIVEN REVISION369Number Errors369Rad()7.321215121517.5322.6627.1533.60MisclassifiedMisclassified0502645344534462764Initial Accuracy75%64.5%60.5%60%54.5%Figure 14: Descriptive statistics flawed synthetic theories (i = 3, 6, 9, 12, 15).1NormalizedRadicality0.80.60.415129630.2020406080100# Training ExemplarsRad (), output theories produced PTRRad ()(i = 3, 6, 9, 12, 15). Error bars reflect 1 standard error.Figure 15: normalized radicality,PTR less radical needed restore original . Thus criterionsuccess PTR set itself, minimizing radicality, PTR better restoring .expected, larger training set closer value 1. Also note numbererrors introduced increases, saving radicality achieved PTR increases well, sincelarger number opportunities created parsimonious revision. precisely,191fiKOPPEL, FELDMAN, & SEGREaverage number revisions made PTR 3 , 6 , 9 , 12 , 15 100 element trainingset 1.4, 4.1, 7.6, 8.3, 10.4, respectively.example show PTR achieves this. Note Figure 13 errors introduced3 additions rules:p6p5p8 , p15 .cases, PTR quickly locates extraneous clause p6 , discovers deletingresults correct classification exemplars training set. fact, change alsoresults correct classification test examples well. two added rulesaffect classification training examples, therefore deleted repairedPTR. Thus radicality changes made PTR lower required restoringoriginal theory. minority cases, PTR first deletes clause B p0 deletesclause p6 . Since literal B higher tree literal S, radicalitychanges marginally higher required restore original theory.Figure 16, graph accuracy test set. expected, accuracy degeneratessomewhat number errors increased. Nevertheless, even 15 , PTR yields theoriesgeneralize accurately.Figure 17 shows average number exemplars required convergence. expected,fewer errors theory, fewer exemplars PTR requires convergence. Moreover,60% Misclassified501512963403020100020406080100# Training ExemplarsFigure 16: Error rates output theories produced PTR (i = 3, 6, 9, 12, 15).192fiBIAS DRIVEN REVISION300ExemplarsConvergence2501512963200150100500020406080100# Training ExemplarsFigure 17: Number exemplars processed convergence (i = 3, 6, 9, 12, 15).number exemplars processed grows less linearly training set size. fact,case average number examples processed greater 4 times training set size.comparison, backpropagation typically requires hundreds cycles converges.Next wish show effects positive bias, i.e., show user-provided guidancechoice initial weights improve speed convergence accuracy cross-validation.flawed theories 3 15 , compare performance PTR using defaultinitial weights biased initial weights ( = 2). Figure 18, show cross-validationaccuracy increases bias introduced. Figure 19, show number examplesneed processed convergence decreases bias introduced.Returning example above, see introduction bias allows PTRimmediately find flawed clause p6 delete straight away. fact, PTR neverrequires processing 8 exemplars so. Thus, case, introductionbias speeds revision process results consistent choice optimalrevision.Moreover, also shown (Feldman, 1993) PTR robust respectrandom perturbations initial weights. particular, tests thirty different syntheticallygenerated theories, introducing small random perturbations edge dt-graphtraining resulted less 2% test examples classified differently trainingperformed using original initial weights.193fiKOPPEL, FELDMAN, & SEGRE60% Misclassified5015315 + bias3 + bias403020100020406080100# Training ExemplarsFigure 18: Error rates output theories produced PTR (i = 3, 6, 9, 12, 15), usingfavorably-biased initial weights.6.4. SummaryRepairing internal literals clauses natural PTR repairing leaves. Moreover, PTRconverges rapidly. result, PTR scales deep theories without difficulty. Evenbadly flawed theories, PTR quickly finds repairs correctly classify known exemplars.repairs typically less radical restoring original theory close enoughoriginal theory generalize accurately test examples.Moreover, although PTR robust respect initial weights, user guidance choosingweights significantly improve speed convergence cross-validation accuracy.7. Conclusionspaper, presented approach, called PTR, theory revision problempropositional theories. approach uses probabilities associated domain theory elementsnumerically track flow proof theory, allowing us efficiently locaterepair flawed elements theory. prove PTR converges theory correctlyclassifies examples, show experimentally PTR fast accurate even deeptheories.several ways PTR extended.First-order theories. updating method core PTR assumes providedexemplars unambiguously assign truth values observable proposition. first-ordertheory revision truth observable predicate typically depends variable assignments.194fiBIAS DRIVEN REVISION300ExemplarsConvergence2501515 + bias33 + bias200150100500020406080100# Training ExemplarsFigure 19: Number exemplars processed convergence using favorably-biased initialweights.Thus, order apply PTR first-order theory revision necessary determine optimalvariable assignments basis probabilities updated. One methoddiscussed (Feldman, 1993).Inductive bias. PTR uses bias locate flawed elements theory. Another type biasused determine revision make. example, might known particularclause might missing literal body circumstances deleted,certain types literals added clause others. Likewise, mightknown particular literal replaceable deletable, etc. shown (Feldman etal., 1993) modifying inductive component PTR account bias,convergence speed cross-validation accuracy substantially improved.Noisy exemplars. assumed domain theory needrevision, exemplars correctly classified. Often case. Thus,necessary modify PTR take account possibility reclassifying exemplarsbasis theory rather vice-versa. PTR* algorithm (Section 6) suggestsmisclassed exemplars sometimes detected processing. Briefly, ideaexample allows multiple proofs root almost certainly root regardlessclassification told. Thus, u E (er ) high, E probably regardlesstold; analogously, u E (er ) low. modified version PTR basedobservation already successfully implemented (Koppel et al., 1993).conclusion, believe PTR system marks important contribution domaintheory revision problem. specifically, primary innovations reported are:195fiKOPPEL, FELDMAN, & SEGRE(1)assigning bias form probability element domain theoryflawed, clearly define objective theory revision algorithm.(2)reformulating domain theory weighted dt-graph, numerically traceflow proof refutation various elements domain theory.(3)Proof flow used efficiently update probability element flawedbasis exemplar.(4)updating probabilities basis exemplars, efficiently locate flawedelements theory.(5)using proof flow, determine precisely basis exemplars reviseflawed element theory.Acknowledgmentsauthors wish thank Hillel Walters Bar-Ilan University significant contributionscontent paper. authors also wish thank JAIR reviewersexceptionally prompt helpful remarks. Support research provided partOffice Naval Research grant N00014-90-J-1542 (AMS, RF) Air Force OfficeScientific Research contract F30602-93-C-0018 (AMS).196fiBIAS DRIVEN REVISIONAppendix A: Assigning Initial Weightsappendix give one method assigning initial weights elements domaintheory. method based topology domain theory assumes userprovided information regarding likelihood errors available. informationavailable, used override values determined method.method works follows. First, edge e define semantic impacte, (e). (e) meant signify proportion examples whose classification directlyaffected presence e .One straightforward way formally defining (e) following. Let pair, assigns root negation edges weight 1 edges1weight . Let (e) identical except e ancestor edges assigned2weight 1. Let E example observable proposition P , E(P)priori probability P true randomly selected example.15 particular, typical1case observable propositions Boolean example equiprobable, E(P) = .2E thought average example. Then, edge one parentedge, formally define semantic significance, (e), edge e follows:(e) = uE (er ) u E e(e)(e)(er ).is, (e) difference flow E root r, without edge e.Note (e) efficiently computed first computing uE (e) every edge esingle bottom-up traversal , computing (e) every edge e single top-downtraversal , follows:root edge r, (r) = 1 uE (r).(1)2(1 uE (e)), f (e) parent edge e.uE (e)edge one parent-edge define (e) edgeusing method computation, place ( f (e)) use max ( f (e)).fedges, (e) = ( f (e))(2)Finally, set, R, edges G, define (R) =e R(e).16Now, computed (e) compute initial weight assignment e, p(e),following way. Choose large C.17 e define:15Although defined example {0, 1} truth assignment observable proposition,already noted Footnote 4 easily process examples assign observables value interval [0, 1].16Observe number examples reclassified result edge-deletion is, fact, superadditive, fact reflected last definition.17tested choose C optimally. experiments reported Section 6, value C = 106 used.197fiKOPPEL, FELDMAN, & SEGREC (e).C (e) + 1Now, regardless (e) defined, virtue method computing p(e) (e)following: initial assignment, p, two sets edges , p equal totalstrength revision sets equal radicality. means revision setsequal strength priori equally probable.p(e) =set edges , define1 eS(e) =/0 eformalized follows:Theorem A1: R sets elements (R) = (S)follows Rad(R) = Rad(S).Proof Theorem A1: Let R sets edges (R) = (S).RecallRad(S) = log[1 p(e)]S(e) [ p(e)]1S(e) .e[1 p(e)]S(e) p(e)1S(e)exp(Rad(S))=exp(Rad(R)) e [1 p(e)] R(e) p(e)1R(e)=p(e)1 p(e)e=C (e)eR(e)S(e)R(e)S(e)= C (R)(S) = 1.follows immediately Rad(R) = Rad(S).simple consequence illustrates intuitiveness theorem following:suppose two possible revisions , entails deleting simple literal.Suppose one literal, l 1 , deep tree other, l 2 , higher tree(l 2 ) = 4 (l 1 ). Then, using default initial weights assigned above, radicalitydeleting l 2 4 times great radicality deleting l 1 .198fiBIAS DRIVEN REVISIONAppendix B: Updated Weights Conditional Probabilitiesappendix prove certain limiting conditions, algorithm computesconditional probabilities edges given classification example.first assumption purpose appendix correct dt-graph knownsubgraph given dt-graph . means every node n , w(n) = 1 (and,consequently, every edge e , p(e) = w(e)). pair , w property saiddeletion-only.Although informally defined probabilities directly edges, purposesappendix formally define probability function space subgraphs . is,elementary events form = . probability esimply { p( = )|e }.say deletion-only, weighted dt-graph , p edge-independent,p( = ) =ep(e)e/1 p(e).Finally, say tree-like edge e one parent-edge. Observedt-graph connected tree-like one root.prove results deletion-only, edge-independent, tree-like weighted dt-graphs.18First introduce terminology. Recall every node labeled oneliterals definition, literal true children true.Recall also dt-graph represents sets NAND equations, . literal lforces parent true, given set equations example E, l appearsfalse given E. (This follows definition NAND.) Thus sayedge e used E e | E n e .e used E write N E (e). Note N E (er ) (E) = 1.Note that, given probabilities elementary events = , probability p(N E (e))edge e used E target domain theory simplyp( = )|N E (e). ambiguity use N E (e) refer N E (e).Theorem B1: , w deletion-only, edge-independent, tree-like weighteddt-graph, every edge e , u E (e) = p(N E (e)).Proof Theorem B1: use induction distance n e deepestdescendant. n e observable proposition P e used Eprecisely e P false E. Thus probability e used E[1 p(e)] [1 E(P)] = u E (e).18Empirical results show algorithm yields reasonable approximations conditional probabilities even conditions hold.199fiKOPPEL, FELDMAN, & SEGREn e observable proposition | E n e preciselychildren true , is, children unused .p(N E (e)) = p(e) p( |= p(e)Ep(N E (s))u E (s)children(e)= p(e)(edge independence)n e )children(e)(induction hypothesis)= u E (e).justifies bottom-up part algorithm. order justify top-down part needone definition.Let p(e| E, (E) ) probability e given , p exemplarE, (E) .p(e| E, (E) ) ={ p( = )|e , (E) = (E)}{ p( = )|(E) = (E)}.Theorem B2: , w deletion-only, edge-independent tree-like,every edge e , p new (e) = p(e| E, (E) ).order prove theorem need several lemmas:Lemma B1: every example E every edge ep( N E (e)) = p( N E (e), N E ( f (e))) = p( N E (e)|N E ( f (e))) p(N E ( f (e))).follows immediately fact edge, e, used, parent-edge, f (e),used.Lemma B2: every example E every edge e ,p(N E (E)|N E ( f (e)), E, (E) ) = p(N E (e)|N E ( f (e))).lemma states N E (e) E, (E) conditionally independent given N E ( f (e))(Pearl, 1988). is, N E ( f (e)) known, E, (E) adds information regardingN E (e). immediate fact p( E, (E) |N E ( f (e))) expressed termsprobabilities associated non-descendants f (e), p(N E (e)) expressedterms probabilities associated descendants r(e).Lemma B3: every example E every edge e ,v E (e) = p(N E (e)| E, (E) ).Proof Lemma B3: proof induction depth edge, e.root edge, er ,200fiBIAS DRIVEN REVISIONv E (er ) = (E) = p((E) = 1| E, (E) ) = p(N E (er )| E, (E) ).Assuming theorem known f (e), show holds efollows:v ( f (e))1 v E (e) = 1 u E (e) Eu E ( f (e))= p( N E (e))(definition v)v E ( f (e))p(N E ( f (e))= p(N E (e)| E, (E) )p( N E (e))p(N E ( f (e))(Theorem B1)(induction hypothesis)= p(N E (e)| E, (E) ) p( N E (e)|N E ( f (e))(Lemma B1)= p(N E (e)| E, (E) )p( N E (e)|N E ( f (e)), E, (E) )(Lemma B2)= p( N E (e), N E ( f (e))| E, (E) )(Bayes rule)= p( N E (e)| E, (E) )(Lemma B1)= 1 p(N E (e)| E, (E) ).Let e short event e/ .Lemma B4: every example E every edge e ,p( e) = p( e, N E (e)) = p( e|N E (e)) p(N E (e)).lemma, analogous Lemma B1, follows fact e deleted, eunused.Lemma B5: every example E every edge e ,p( e| N E (e), E, (E) ) = p( e| N E (e)).lemma, analogous Lemma B2, states e E, (E) conditionallyindependent given N E (e). is, N E (e) known, E, (E) adds informationregarding probability e. immediate fact p( E, (E) | N E (e))expressed terms probabilities edges e.pieces prove Theorem B2.Proof Theorem B2:v (e)1 p new (e) = 1 p(e) Eu E (e)= p( e)(definition pnew)v E (e)p(N E (e))(Theorem B1)201fiKOPPEL, FELDMAN, & SEGRE= p(N E (e)| E, (E) )p( e)p(N E (e))(Lemma B3)= p(N E (e)| E, (E) ) p( e|N E (e))(Lemma B4)= p(N E (e)| E, (E) ) p( e|N E (e), E, (E)(Lemma B5)= p( e, N E (e)| E, (E) )(Bayes rule)= p( e| E, (E) )(Lemma B4)= 1 p(e| E, (E) ).202fiBIAS DRIVEN REVISIONAppendix C: Proof Convergenceseen Section 5 PTR always terminates. wish show does,exemplars classified correctly. prove domain theories satisfy certainconditions made precise below. general idea proof following:definition, algorithm terminates either exemplars correctly classifiededges weight 1. Thus, necessary show possible reach stateedges weight 1 exemplar misclassified. provestate fails possess property consistency assumed hold initialweighted dt-graph , preserved times algorithm.Definition (Consistency): weighted dt-graph = , p consistentexemplar E, (E) if, every root r , either:(i) (E) = 1 uE (r ) > 0,(ii) (E) = 0 uE (r ) < 1.Recall edge e defined even even depth along every path rootodd odd depth along every path root. domain theory said unambiguousevery edge either odd even. Note negation-free domain theories unambiguous.prove main theorem unambiguous, single-root domain theories.Recall operations performed PTR are:(1)updating weights,(2)deleting even edges,(3)deleting odd edges,(4)adding subtree beneath even edge,(5)adding subtree beneath odd edge.shall show operations performed way preserveconsistency.Theorem C1 (Consistency): = , p single-rooted, unambiguousweighted dt-graph consistent exemplar E, (E)= , p obtained via single operation performed PTR,also single-rooted, unambiguous dt-graph consistent E.prove theorem show easily implies convergence algorithm.Theorem C2 (Convergence): Given single-rooted, unambiguous weighted dtgraph set exemplars consistent every exemplar, PTR terminates produces dt-graph classifies every exemplarcorrectly.Proof Theorem C2: PTR terminates prior edge assignedweight 1, definition, exemplars correctly classified. SupposePTR produces weighted dt-graph = , p p(e) = 1 everye . Assume, contrary theorem, exemplar E, (E)misclassified root r. Without loss generality, assumeE, (E) exemplar r. Since p(e) = 1 every edge, meansuE (er ) = 0. impossible since consistency impliesu KE (er ) > 0 thus follows Theorem C1 obtainable form203fiKOPPEL, FELDMAN, & SEGRE, uE (er ) > 0. contradicts assumption E misclassified .Let us turn proof Theorem C1. use following four lemmas, slightvariants proved (Feldman, 1993).Lemma C1: = , p obtained = , p via updating weights,every edge e 0 < p(e) < 1, 0 < p(e) < 1.19Lemma C2: Let = , p weighted dt-graph 0 < uE (er ) < 1let = , p . every edge e 0 < p(e) < 1,0 < p(e) < 1, follows 0 < uE (er ) < 1.Lemma C3: Let = , p weighted dt-graph uE (er ) > 0 let= , p . The, every edge e , holds either:(i) p(e) = p(e),(ii) depth(e) odd uE (e) > 0,(iii) depth(e) even uE (e) < 1uE (e) > 0.analogous lemma holds roles > 0 < 1 reversed.Lemma C4: e even edge , u E e (er ) uE (er ) u E e (r). addition,e odd edge , u E e (er ) uE (er ) u E e (r).prove consistency (Theorem C1). assume, without loss generality,E, (E) exemplar root r prove one five operations(updating four revision operators) PTR, obtained operationuE (er ) > 0, uE (er ) > 0.Proof Theorem C1: proof consists five separate cases,corresponding one operations performed PTR.Case 1: obtained via updating weights.Lemma C1, every edge e , 0 < p(e) < 1 0 < p(e) < 1.Lemma C2, uE (er ) > 0 uE (er ) > 0.Case 2: obtained via deletion even edge, e.Lemma C4(i), u E e (er ) uE (er ) > 0.Case 3: obtained via deletion odd edge, e.edge e deleted needed exemplar. Suppose that,contrary theorem, exemplar E, (E) uE (er ) > 0uE (er ) = 0.19Recall updating algorithm defined(E) = 0v E (er ) =.1 (E) = 1somewhat annoying presence > 0 necessary proof Lemma C1.204fiBIAS DRIVEN REVISIONR( E, (E) , e, ) ==u E e (er )u E e (er )u E e (er )uE (er )u E e (er )> 2.0e needed E, contradicting fact e neededexemplar.=Case 4: obtained via appending subtree beneath even edge, e.p(e) < 1, result immediate Lemma C2. Otherwise, let froot edge subtree appended , beneath e. | f = e .Suppose that, contrary theorem, exemplar E, (E)uE (er ) > 0uLemmaC4(ii),E (er ) = 0.e|eu E (er ) = u E (er ) u E (er ) = 0. then,R( E, (E) , e, ) =u E e (er )u E e (er )0u E e (er )= 0.Thus e destructive E . then, construction , uE ( f ) = 1.(e)=0<1.resultfollowsimmediatelyLemmaC3.Thus, uECase 5: obtained via appending subtree beneath odd edge,e.Suppose that, contrary theorem, exemplar E, (E) , uE (er ) > 0uE (er ) = 0. Since e = e , followsR( E, (E) , e, ) ==u E e (er )u E e (er )u E e (er )u E e (er ).Now, using Lemma C4(ii) numerator denominator,u E e (er )u E e (er )uE (er )uE (er ) = > 2.Thus, e needed E . Now, let f root edge appended subtree,. Then, construction , follows uE ( f ) < 1 and, thereforeu(e)>0.resultimmediateLemmaC3.E205fiKOPPEL, FELDMAN, & SEGREcompletes proof theorem.instructive note proof Theorem C1 fails restrictedunambiguous single-rooted dt-graphs. case 4 proof Theorem C1, use factedge e destructive exemplar E, (E) revision algorithm usedconstruct subgraph, , appended e uE ( f ) = 1. However, facthold case e simultaneously needed destructive. occur edescendant two roots E one root another root. also occurone path e root r even length another path odd length.206fiBIAS DRIVEN REVISIONAppendix D: Guide Notationdomain theory consisting set clauses form C : H Bi .Ciclause label.Hiclause head; consists single positive literal.Biclause body; consists conjunction positive negative literals.Eexample; set observable propositions.(E)classification example E ith root according domaintheory .(E)correct classification example E ith root.E, (E)exemplar, classified example.set NAND clauses equivalent .dt-graph representation .nenode edge e leads.nenode edge e comes.p(e)weight edge e; represents probability edge eneeds deleted edges need appended node n e .= , pweighted dt-graph.eweight edge e equal 1.eedge e deleted.u E (e)flow proof example E edge e.v E (e)adjusted flow proof e taking account correctclassification example E.Ri ( E, (E) , e, )extent (ranging 0 ) edge e weighted dtgraph contributes correct classification example Eith root. Ri less/more 1, e harmful/helpful; Ri = 1e irrelevant.revision threshold; p(e) < e revised.weight assigned revised edge root appendedcomponent.revision threshold increment.revised edge weight increment.Rad ()radicality changes required order obtain revisedtheory .207fiKOPPEL, FELDMAN, & SEGREReferencesBuchanan, B. & Shortliffe, E.H. (1984). Rule-Based Expert Systems: MYCIN ExperimentsStanford Heuristic Programming Project. Reading, MA: Addison Wesley.Feldman, R. (1993). Probabilistic Revision Logical Domain Theories. Ithaca, NY: Ph.D.Thesis, Department Computer Science, Cornell University.Feldman, R., Koppel, M. & Segre, A.M. (August 1993). Relevance Bias RevisionApproximate Domain Theories. Working Notes 1993 IJCAI Workshop MachineLearning Knowledge Acquisition: Common Issues, Contrasting Methods, IntegratedApproaches, 44-60.Ginsberg, A. (July 1990). Theory Reduction, Theory Revision, Retranslation. ProceedingsNational Conference Artificial Intelligence, 777-782.Koppel, M., Feldman, R. & Segre, A.M. (December 1993). Theory Revision Using NoisyExemplars. Proceedings Tenth Israeli Symposium Artificial Intelligence ComputerVision, 96-107.Mahoney, J. & Mooney, R. (1993). Combining Connectionist Symbolic Learning RefineCertainty-Factor Rule-Bases. Connection Science, 5, 339-364.Murphy, P.M. & Aha, D.W. (1992). UCI Repository Machine Learning Databases [Machinereadable data repository]. Irvine, CA: Department Information Computer Science,University California Irvine.Ourston, D. (August 1991). Using Explanation-Based Empirical Methods TheoryRevision. Austin, TX: Ph.D. Thesis, University Texas Austin.Ourston, D. & Mooney, R. (in press). Theory Refinement Combining Analytical EmpiricalMethods. Artificial Intelligence.Pazzani, M. & Brunk, C. (June 1991). Detecting Correcting Errors Rule-Based ExpertSystems: Integration Empirical Explanation-Based Learning. Knowledge Acquisition,3(2), 157-173.Pearl, J. (1988). Probabilistic Reasoning Intelligent Systems. San Mateo, CA: MorganKaufmann.Quinlan, J.R. (1986). Induction Decision Trees. Machine Learning, 1(1), 81-106.Towell, G.G. & Shavlik, J.W. (October 1993). Extracting Refined Rules Knowledge-BasedNeural Networks. Machine Learning, 13(1), 71-102.Wilkins, D.C. (July 1988). Knowledge Base Refinement Using Apprenticeship LearningTechniques. Proceedings National Conference Artificial Intelligence, 646-653.Wogulis, J. & Pazzani, M.J. (August 1993). Methodology Evaluating Theory RevisionSystems: Results Audrey II. Proceedings Thirteenth International Joint ConferenceArtificial Intelligence, 1128-1134.208fiJournal Artificial Intelligence Research 1 (1993) 6189Submitted 8/93; published 11/93Software Agents: Completing PatternsConstructing User InterfacesJeffrey C. SchlimmerLeonard A. HermensSchool Electrical Engineering & Computer Science,Washington State University, Pullman, WA 99164-2752, U.S.A.SCHLIMMER@EECS.WSU.EDULHERMENS@EECS.WSU.EDUAbstractsupport goal allowing users record retrieve information, paperdescribes interactive note-taking system pen-based computers two distinctivefeatures. First, actively predicts user going write. Second, automaticallyconstructs custom, button-box user interface request. system examplelearning-apprentice software-agent. machine learning component characterizessyntax semantics users information. performance system uses learnedinformation generate completion strings construct user interface.1. Introduction MotivationPeople like record information later consultation. many, media choicepaper. easy use, inexpensive, durable. disadvantage, paper recordsscale well. amount information grows, retrieval becomes inefficient, physical storage becomes excessive, duplication distribution become expensive. Digital mediaoffers better scaling capabilities. indexing sub-linear algorithms, retrieval efficient; using high density devices, storage space minimal; electronic storagehigh-speed networks, duplication distribution fast inexpensive. clearcomputing environments evolving several vendors beginning market inexpensive, hand-held, highly portable computers convert handwriting text. viewstart new paradigm shift traditional digital information gathered used. One obvious change computers embrace paper metaphor,eliminating need typing. paradigm research inspired, oneprimary goals combine best worlds making digital media convenient paper.document describes interactive note-taking software system computerspen-based input devices. software two distinctive features: first, actively predictsuser going write provides default user may select; second,software automatically constructs graphical interface users request. purposefeatures speed information entry reduce user errors. Viewed largercontext, interactive note-taking system type self-customizing software.clarify notion, consider pair dimensions characterizing software.Figure 1 depicts, one dimension task specificity. Software addresses generic task(e.g., spreadsheet) lies task independent software (e.g., compiler) taskspecific software (e.g., particular companys accounting software). Another dimensionamount user customization required make software useful. Task generic software lies two extremes, requiring modest programming specialized1993 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.fiS CHLIMMER & H ERMENSHighVisual BASICUserCustomizationRequiredSpreadsheetsSelf-CustomizingCustom SoftwareLowGenericLowTask Specificity ProductDevelopment Cost / UserSpecificHighFigure 1: Continuum software development depicting traditional trade-offdevelopment cost per user amount user customization required.Self-customizing software eliminates need user customization startingpartially-specified software applying machine learning methods completeremaining customization.language. Self-customizing software uses machine learning techniques automatically customize task generic software specific user. software learns assist userwatching complete tasks, software also learning apprentice. Similarly,user explicitly program defaults user interface notetaking system, type software agent. Agents new user interface paradigmfree user explicitly command computer. user record information directly free-form manner. Behind interface, software acting behalfuser, helping capture organize information.Next introduce performance component note-taking softwaredetail, describe representations algorithms used learning methods.also present empirical results, comparing performance seven alternate methodsnine realistic note-taking domains, finally, describe related research identifysystems limitations.62fiS OFTWARE GENTS : C OMPLETING P ATTERNS & C ONSTRUCTING U SER NTERFACESFigure 2: Screen snapshot note-taking software contextual prompting modePowerBook note. two triangles lower left scroller buttons.2. Performance Taskprimary function note-taking software improve users speed accuracyenter notes various domains interest. note short sequence descriptive terms describe single object interest. Example 1 shows note describing particular personal computer (recorded first author Usenet newsgroup1992):4096K PowerBook 170, 1.4MB 40MB Int. Drives, 2400/9600 Baud FAX Modem(Example 1)Example 2 note describing fabric pattern (recorded first authors wife):Butterick 3611 Size 10 dress, top(Example 2)Tables 5 11 later paper list sample notes drawn seven domains.user may enter notes different domains convenience may use whateversyntactic style comes naturally.users point view, software operates one two modes: contextualprompting mode, interactive graphical interface mode. first mode, softwarecontinuously predicts likely completion user writes note. offersdefault user. location presentation default must balance conflictingrequirements convenient yet unobtrusive. example, hand hideindicated default user writing. solution small, colored completion button follow left user writing. location, visibleeither right- left-handed people write notes. user reposition button another location prefer. default text displayed immediate rightbutton smaller font. completion button green; text black. completion button saturation ranges 1 (appearing green), software highly confidentpredicted value, 0 (appearing white), software lacks confidence. button light gray frame, visible even software prediction. Figure 263fiS CHLIMMER & H ERMENSFigure 3: Screen snapshot note-taking software button-box modePowerBook note.portrays screen snapshot software operating contextual prompting modePowerBook note.softwares second mode presents interactive graphical interface. Insteadrequiring user write text note, software presents radio-buttoncheck-box interface (what call button-box interface). this, user may selecttext fragments, portions notes called descriptive terms , tapping radio-buttonscheck-boxes pen interface device. selection button-box interfaceadded current note. Intuitively, check boxes generated depict optional descriptive terms, whereas radio-button panels generated depict alternate, exclusive descriptive terms. user convenience, radio-buttons clustered panels sortedalphabetically ascending order top bottom. allow user add new descriptive terms button-box panel, additional blank button included bottom each.user selects radio button item, graphical interface expanded depict additional choices corresponding descriptive terms follow syntactically. softwareindicates predictions preselecting corresponding buttons highlightinggreen. user may easily override default selection tapping desired button.Figure 3 portrays screen snapshot software operating interactive graphicalinterface mode PowerBook note.software prompting mode user begins write note. learned syntax domain note sufficiently mature (see Section 6, Constructing ButtonBox Interface), software switch button-box mode. indicateuser, mode switch depicted radio button presented users notice. convenient unobtrusive location switch completion button. keepingcolor theme, mode switch also green hue. user taps switch,written text removed, appropriate radio buttons check boxes inserted.system automatically selects buttons match user-written text. user makesadditional selections, interface expands include additional buttons. userfinishes note, either mode, software returns prompting mode anticipationanother note.1 interface constructed learned syntax, software64fiS OFTWARE GENTS : C OMPLETING P ATTERNS & C ONSTRUCTING U SER NTERFACESrefines representation domains notes, button-box interface also improves.On-line Appendix 1 demonstration systems operation two modes.3. Learning Syntaximplement two modes note taking software, system internally learns twostructures. characterize syntax users notes, learns finite-state machines (FSMs).generate predictions, learns decision tree classifiers situated states within FSMs.order construct graphical user interface, system converts FSM setbuttons. section describes representation method learning FSMs. nextsection discusses learning embedded classifiers.3.1TokenizationPrior learning finite-state machine, users note must first convertedsequence tokens. Useful tokenizers domain independent. However, handcrafteddomain-specific tokenizers lead useful representations. generic tokenizer usedresults reported uses normal punctuation, whitespace, alpha-numeric character boundaries token delimiters. example, generic tokenizer splits samplePowerBook note Example 1 following 16 tokens::NULL"4096"" K"" PowerBook"" 170"", 1.4""MB"" and"" 40""MB"" Int."" Drives"", 2400/9600"" Baud"" FAX"" Modem" .token :NULL prepended tokenizer. convention simplifies codeconstructing FSM.3.2Learning Finite-State MachineDeterministic finite-state machines (FSMs) one candidate approach describingsyntax users notes well understood relatively expressive. Moreover, Angluin (1982) Berwick Pilato (1987) present straightforward algorithmlearning specific subclass FSMs called k-reversible FSMs. algorithm incremental1. functionality described here, prototype implements transition button-box contextual prompting. mechanism transition machine dependent germane research.65fiS CHLIMMER & H ERMENSstartstart:NULL:NULL:NULLButterickButterickButterick303530353611SizeSizeSize11/1211/1210dressdressdressterminalterminaltopterminal(a)(b)Figure 4: (a) Degenerate finite-state machine processing single fabric patternnote, (b) prefix tree finite-state machine adding second fabric pattern note(cf. Example 2).suffer presentation order effects. Berwick Pilato define k-reversibleFSM as:regular language k-reversible, k non-negative integer, whenever twoprefixes whose last k words [tokens] match tail common, two prefixestails common. words, deterministic finite-state automaton (DFA)[FSM] k-reversible deterministic lookahead k sets initialfinal states swapped arcs [transitions] reversed.Given list tokens, k-reversible FSM algorithm first constructs prefix tree,token sequences common k-leaders share k-length path FSM.example, Figure 4a depicts simple FSM constructed single fabric pattern note.text users note converted sequence tokens. transition createdtoken sequence states created link together. One state servesinitial state, another indicates completion sequence. convenience,latter, terminal state depicted double circle. FSM able find transitiontoken sequence, arrives terminal state, FSM acceptstoken sequence instance language defines. Figure 4b depicts FSManother path added corresponding second fabric pattern note (Example 2).FSM accept either note expressed sequence tokens. FSMtrivial prefix tree first state shared two paths.66fiS OFTWARE GENTS : C OMPLETING P ATTERNS & C ONSTRUCTING U SER NTERFACESk-leader defined path length k accepts given state.Merge two states either following true:1. Another state transitions states token;(This enforces determinism.)2. states common k-leadera. states accepting states,b. states transition common state via token.Table 1: FSM state merging rules (Angluin, 1982).prefix tree minimal observed token sequences, may general enoughuse prediction. (The prefix tree is, essence, expensive method memorizingtoken sequenceswhich desired result.) sake prediction, desirableFSM accept new, previously unseen combinations tokens. prefixtree automaton converted general FSM merging states.particular method converts prefix tree k-reversible FSM via Angluins(1982) algorithm. algorithm merges states similar transitions, createsFSM accepts token sequences prefix tree, well candidate sequences.Table 1 lists three rules deciding merge pair states prefix tree formk-reversible FSM. special case k equals zero, states common kleader, Rule 2a ensures one accepting state.rules Table 1 must applied pair states FSM,time pair states merged process must repeated, asymptoticcomplexity process O( n3 ), n number states FSM.Applying rules prefix tree Figure 4b k equal zero results FSMdepicted Figure 5a. Notice first two states merged make FSMdeterministic (Rule 1). accepting states also merged complianceRule 2a. resulting FSM fewer states general. accepts twotoken sequences originally seen. Extending example, Figure 5b illustrates additionthird fabric pattern note prefix tree path FSM. Reapplying rules resultsFSM shown Figure 6. first two states merged actiondeterminism Rule 1. Note pair latter states also mergedshare common zero-leader (true pairs states) transitioncommon terminal state token "dress".Figure 7 depicts sophisticated result; shows learned zero-reversible FSMnotes PowerBook computers. example shows model number "100"never followed specification internal floppy drive, model numbersare. model may external floppy drive. Note single terminal state.Whitespace punctuation eliminated clarity figure.rules listed Table 1 generalization operators allow FSM acceptpreviously unobserved sequences. Whenever two states merged one,FSM accept sequences new state tail end transitions one previous states new state head end least onetransition. example, state State 1 Figure 7 merged severalprevious states generalizes memory sizes PowerBook models. rules compriseheuristic bias may conservative. example, Figure 8 depicts FSM notes67fiS CHLIMMER & H ERMENSstartstart:NULL:NULLButterick:NULLButterickButterick30353611303536113674SizeSizeSizeSizeSize11/121011/121010dressdressdressdressdressterminaltoptopterminalterminal(a)(b)Figure 5: (a) Finite-state machine processing two fabric pattern notesapplying state merging rules Table 1, (b) prefix tree finite-state machineadding third fabric pattern note.fabric patterns. Many states prior accepting state could usefullymerged, using rules listed Table 1, many notes processedhappens. FSM Figure 8 rendered button-box interface, wouldreflect little true structure domain fabric patterns. Table 2 lists specializationsRules 2a 2b additional pair rules developed make FSM generalizereadily. Note parameter k set zero Rule 2 one Rule 3.Effectively, two states merged Rules 3a 2b' share incoming outgoingtransition. Rule 3b Kleene rule encourages FSM generalize numbertimes token may appear sequence. one state transition another, mergingresult transition loops newly merged state. Figure 9depicts FSM notes fabric patterns learned using three generalization rulesTable 2. resulting FSM accurately captures syntax users fabric pattern notescorrectly indicates syntactically optional tokens may appear end note.rendered button-box interface, clearly depicts users syntax (as illustratedlater Figure 12). added generalization rules may marginal effectssystems ability accurately predict completion user writes note (as Table 14indicates). purpose improve quality custom interface.Cohen (1988) uses interesting alternative representation learning syntactic form.goal work guide generation proof structures. Intuitively, representation finite-state machine accepts tree rather sequence, reasontermed tree automaton. Like rules Tables 1 2, tree automatons generalized68fiS OFTWARE GENTS : C OMPLETING P ATTERNS & C ONSTRUCTING U SER NTERFACESstart:NULLButterick303536743611SizeSizeSize11/121010dressdresstopterminalFigure 6: Sample finite-state machine processing three fabric pattern notes.Merge two states following true:1. Another state transitions states token;(This enforces determinism.)2'. states common 0-leadera. states accepting states,b. states transition common state via token;3. states common 1-leadera. states transition common state via token,b. One transitions via token.Table 2: Extended FSM state merging rules.merging states share similar transitions. Oddly enough, one motivation using treeautomatons less likely introduce extraneous loops, oppositeproblem original FSM merging rules Table 1. clear mapsequence tokens users notes tree structure, less sequential naturetree automaton may help alleviate sequencing problems rendering custom userinterface (see Section 9, Observations/Limitations).3.3Parsinguse finite-state machine prediction, software needs strategy dealingnovel tokens. example, user takes note PowerBook computer69fiS CHLIMMER & H ERMENSstart:NULL12048409661448192KPowerBook21001401451601703801.4MBMBInt42040201.4MBMBInt40801205ExtDriveDrives6terminalDrives2xBattery,Battery,Case,Charger,FPU,Video Output14.4v1.4K32MB9.696002400/48002400/96004800/9600ExtKBaudbis7FAXModemFigure 7: Zero-reversible FSM characterizing PowerBook notes (cf. Example 1).70fiS OFTWARE GENTS : C OMPLETING P ATTERNS & C ONSTRUCTING U SER NTERFACESstart:NULLButterickMcCall's4198372243526171367430353611SizeSizesSizeSizeSizeSize128-10-1212101011/12DressJumperTopDress486450575377SuzeSize1012DressDressSkirtSimplicity590654245465SizeSizeSize1211/1211/12JumperDressJumperSkirtTopterminalFigure 8: Zero-reversible finite-state machine characterizing fabric pattern noteslearned using merging rules listed Table 1.new memory configuration, FSM transition first token. software prompt user, must means deciding novel tokens lienotes syntaxwhich state predict from. Without mechanism, meaningfulprediction generated novel tokens.state may transition next token. general, single symptomthree possible causes: (1) novel token inserted, (2) suitable tokenomitted next token would accepted subsequent state, (3) tokensimply replaced another syntax. example, sequence tokens {:NULL,"12288", "K", "PB"}, "12288" novel token, familiar memory size omitted,"PowerBook" replaced "PB".optimal solution would identify state requiring minimum number insertions,omissions, replacements necessary parse new sequence. efficient, heuristicapproximation greedy search using special marker. time marked stateFSM transition next token written user, marker moved forward,prediction generated state. transition next token,greedy search conducted state (including marked one reachableit) transition token (including next one following).state found, marker moved forward state, tokens transitionsskipped states assumed omitted, novel tokens assumed inserted. state pastmarker transition remaining tokens, remaining tokensassumed replacements number likely transitions; markermoved. user writes subsequent token state transition,71fiS CHLIMMER & H ERMENSstart:NULLButterick37224198435261713674McCall's3035Sizes3611486450575377Simplicity590654245465Size8-10-121011/12Dress12JumperterminalJumperSkirtTopFigure 9: Finite-state machine characterizing fabric pattern notes learned usingextended rules Table 2. Compare zero-reversible finite-state machinedomain Figure 8.marker moved described above, syntax users note realignedlearned syntax. Continuing simple PowerBook example, marker movedState 1 FSM Figure 7 initial state transition first token:NULL. State 1 doesnt transition next token "12288", greedy searchconducted find nearby state accepts either "12288", "K", "PB". stateState 2 accepts "K", marker moved state. Another greedy searchstarted find state accepts "PB". one cannot found, heuristic parsingassumes skip next transition. case one labeled "PowerBook".Consequently, system generates prediction State 2 prompt user.3.4Multiple Finite-State Machinesuser decides take notes multiple domains, may necessary learn separate syntax domain. example, single syntax generalized PowerBook fabric pattern notes likely yield confusing predictions unnatural userinterface. Maintenance multiple finite-state machines instance clustering problemdeciding notes clustered together share FSM. Fisher (1987)discusses, involves trade-off maximizing similarity within cluster minimizing similarity clusters. Without first criteria, notes would putsingle cluster. Without second criteria, note would put cluster.One obvious approach would require user prepend note uniquetoken identify notes domain. simplifies clustering computation. notessharing first token would share FSM. However, scheme, user would72fiS OFTWARE GENTS : C OMPLETING P ATTERNS & C ONSTRUCTING U SER NTERFACESstartterminalXFigure 10: Simple finite-state machine one state.remember identifying token name domain. interface could providepop-up list previously used domain identifiers. satisfactoryrequires overhead needed taking notes paper.alternative approach doesnt require extra effort part user. newnote grouped FSM skips fewest tokens. heuristic encourageswithin cluster similarity FSM accept new token sequences similarsummarizes. inhibit formation single-note FSMs, new FSM constructedFSMs skip half new notes tokens. parametrized solutionencourage between-cluster dissimilarity.4. Learning Embedded ClassifiersFinite-state machines useful representations capturing syntax users notes,easy learn. predicting notes completion, essential prediction made correct state FSM (as discussed above). also necessarydecide whether terminate (indicating acceptance note) continue prediction, and,later case, transition predict. facilitate decisions, FSM maintain count many times parsing terminated many times transitiontaken. Prediction return option maximum frequency.Figure 10 depicts FSM method prove insufficient. onestate, accepting state, transition corresponding token "X" optional. (Thiscorresponds check box interface item.) two problems frequency-basedprediction. First, FSM indicate transition taken once, yetquite clear user interface. Second, simple frequency-based prediction wouldalways recommend termination never transition. FSM accepts whether boxchecked not, thus frequency termination greater equal frequencytransition. problem arises whenever loop.Embedding general classifiers FSM alleviate FSMs representationalshortcomings. example, FSM depicted Figure 10, decision tree embeddedstate easily tests whether transition already taken adviserepeating it. Moreover, classifier predict based previous transitions ratherfrequency current states transitions. Therefore, decision tree embeddedstate Figure 10 predict transition taken function other,earlier tokens sequence. Table 3 lists sample decision trees embedded statesFSM depicted Figure 7. first tree tests token parsed distant state,effect augmenting FSM representation. relates memory size hard disk capacity(small amounts memory correlate small hard disk). second tree preventsoptional loop taken second time testing see state yetvisited parse note. processing additional notes, second decision tree73fiS CHLIMMER & H ERMENSDecision tree embedded State 3:State 1 exited "2048"predict " 20"Else "4096"predict " 40"Else "6144"predict " 40"Else "8192"predict " 40" .Decision tree embedded State 7:State 7 visitedpredict " FAX"Else State 7 exited " FAX"predict " Modem" .Table 3: Sample decision trees embedded finite-state machine depictedFigure 7.becomes complex system tries predict PowerBooks FAX modemsnot.classifier trained state FSM which: (a) one transition,(b) marked terminal state also transition. classifiers updated incrementally user finishes note. classifiers training data token sequencesparsed state. class value data transition taken from, termination at,state token sequences. classifiers whose states used parseupdated. attributes data names states prior one, valuesattributes transitions taken states. distinct attribute definedtime state visited given parse, loop transition taken specificattribute reflects fact. attributes, corresponding state visitedparsing token sequence, attribute special, empty value.Consider PowerBook FSM shown Figure 7. classifier would embeddedStates 1, 2, 3, 4, 5, 6, 7. training example corresponding note Example 1classifier State 6 would be:Attributes:S1=S2=S3=S4=S5=S6=S7=S7-1=Class:=Values:"4096"" 170"NIL" 40"" Drives"", 2400/9600"" FAX"" Modem":TERMINATE .Note value State 3, denoting wasnt visited parseExample 1. Also two attributes State 7 denoting visited twice.classifier gives informed advice transition take whether terminate. FSM turn gives classifier specific context operation. singleclassifier used predict next token, would hard pressed represent different predictions required. domain naturally narrowed FSM thereforereduces representational demands classifier. Later, present empirical results74fiS OFTWARE GENTS : C OMPLETING P ATTERNS & C ONSTRUCTING U SER NTERFACEScomparing single classifier set classifiers embedded FSM. findingsshow latter outperforms former, confirming intuition learningeffective situated within narrow context.classifiers point view, learning task non-stationary. conceptlearned changing time structure FSM changing. two statesmerged, one two classifiers discarded. embedded differentposition FSM, sees different training data. Similarly, statesmerged, attributes training data also change. help mitigate effect, newstate takes oldest identifier assigned two merged states. Empirical resultsTable 14 illustrate FSM fixed classifier learnuseful information.5. Contextual Promptingprompting mode, software continuously predicts likely completion userwrites note. presents default next completion button. buttonssaturation ranges white green proportion confidence prediction.user taps completion button, prompt text inserted end current note.completion generated parsing tokens already written user, findinglast state visited FSM, predicting next likely transition (or termination).process repeated stopping criterion satisfied, discussed below.last token written user incomplete, matching prefix states transition,remainder transition predicted. last token matches onetransition, generalized string predicted using special characters indicate typenumber characters expected. digit expected, "#" included; letter, "a"included; either possible, "?" included; transitions tokens longerothers, "" appended end. example, user written"4096K PowerBook 1", possible values PowerBook models "100", "140","160C", "170" generalized, prompt "#0".simple calculation used compute confidence prediction setbuttons color saturation. simple ratiof ( prediction )f ( total ) ( 1 + skipped )f ( prediction ) frequency predicted arc (or terminate) [i.e., numbertimes choice taken parsing previously observed notes], f ( total ) totalfrequency arcs (and terminate), skipped number tokens skippedheuristic parsing (cf. Section 3.3, Parsing). Confidence directly proportional simplelikelihood prediction degraded proportion number tokens FSMskip get point. information used simple way, unclearsophisticated measures needed.stopping criterion used determine much prompt offer user.one extreme, single token predicted. gives user little context mayprovide much assistance. extreme, sequence tokens completesnote predicted. may lengthy, user would edit promptselected. stopping criterion Table 4 balances two extremes attempts limitprompts consistent set tokens. particular, Condition 3 stops expanding prompt75fiS CHLIMMER & H ERMENSStop expanding prompt following true:1. next prediction terminate;2. next prediction generalized string;3. least one token already predicteda. prediction starts punctuation,b. confidence prediction lower;4. next prediction last prediction;5. 10 tokens already predicted.Table 4: Stopping criterion contextual prompting.upon reaching syntactic boundary (leading punctuation) upon reaching semanticboundary (falling confidence).6. Constructing Button-Box Interfacebutton-box mode, software presents interactive graphical interface. Insteadwriting note, user may select note fragments tapping buttons. switchcontextual mode button-box mode, green radio button indicator displayedcompletion button software confident users syntax. user tapsindicator, existing text removed, corresponding buttons button-box interface selected. user selects additional buttons, interface dynamically expandsreveal additional choices. interface reflects improving syntactic representation, also improves successive notes.button-box interface direct presentation finite-state machine. userwritten token note, software finds FSM best parsestokens. mode switch presented syntax sufficiently matureif averagenumber times state used parse earlier notes greater 2. userselects indicator, FSM incrementally rendered set radio buttons checkboxes.two user interface item types correspond optional choices (check boxes)exclusive choices (radio buttons). Mapping FSM two item types proceeds onestate time. Given particular state rendered, transition starts pathbranch eventually returns back state rendered check box (a loop).loop corresponds syntactically optional information. label check box consists transition labels along looping path. non-looping transitionsrendered buttons single radio button panel along extra, unlabeled button.correspond syntactically exclusive information. label radio button consiststransition label point subsequent branch termination. example,compare FSM depicted Figure 7 corresponding button-box interfaceFigure 3.transitions different radio buttons lead different parts FSM,may confuse user render entire FSM once. So, branching state renderedvisited. Initially, first state FSM rendered. Then, radio buttonselected, branching state end transition path rendered. Note checkboxes trigger additional rendering branching state end loop76fiS OFTWARE GENTS : C OMPLETING P ATTERNS & C ONSTRUCTING U SER NTERFACESalready rendered. interactive process repeated long user selectsradio buttons lead branching states.7. Empirical Resultstested interactive note taking software notes drawn variety domains.Tables 5 11 list sample notes seven domains (in addition PowerBookfabric pattern sample notes listed above).CVA-62 8/6/63 3/4/64 Mediterranean A-5A AG 60XCVA-61 8/5/64 5/6/65 Vietnam RA-5C NG 10XTable 5: Sample notes airwing domain. Listed 2 78 notesairwing assignments aboard aircraft carriers collected (Grove & Miller,1989).B, 81, 5, 151 (2.5), Cyl. 4, 2-bbl., PontiacC, 82, X, 173 (2.8), Cyl. 6, 2-bbl., ChevroletTable 6: Sample notes engine code domain. Listed 2 20 notesmeaning engine codes stamped automobile identification platescollected Chiltons Repair & Tune-Up Guide (1985).90, Mazda MPV, 40K MI, 7 Pass, V6, AutoABS, PL/PW, Cruise, Dual Air87, Grand Caravan, 35K MI, 7 Pass, V6, AutoCruise, Air, Tilt, TintingTable 7: Sample notes minivan domain. Listed 2 22 notesminivan automobiles collected first author.Lorus Disney Oversize Mickey Mouse Watch.Genuine leather strap.Seiko Disney Ladies' Minnie Mouse Watch.Leather strap.Table 8: Sample notes watch domain. Listed 2 89 notespersonal watches collected Best catalog (a department store).77fiS CHLIMMER & H ERMENSazatadine maleateBlood: thrombocytopenia.CNS: disturbed coordination, dizziness, drowsiness, sedation,vertigo.CV: palpitations, hypotension.GI: anorexia, dry mouth throat, nausea, vomiting.GU: Urinary retention.Skin: rash, urticaria.Other: chills, thickening bronchial secretions.brompheniramine maleateBlood: aganulocytosis, thrombocytopenia.CNS: dizziness, insomnia, irritability, tremors.CV: hypotension, palpitations.GI: anorexia, dry mouth throat, nausea, vomiting.GU: urinary retention.Skin: rash, urticaria.parenteral administration:local reaction, sweating, syncope may occur.Table 9: Sample notes antihistamine domain. Listed 2 17notes side effects antihistamines collected Nurses Guide Drugs(1979).Canon FD f/1.8, 6oz., f/22, 13in.,good sharpness, poor freedom flare,better freedom distortion,focal length marked sides wellfront lensChinon f/1.7, 6oz., f/22, 9in.,poor sharpness, good freedom flare,good freedom distortion,cannot locked program mode,problem, course, lensused program-mode camerasTable 10: Sample notes lens domain. Listed 2 31 notes35mm SLR camera normal lenses collected Consumer Reports (1988).78fiS OFTWARE GENTS : C OMPLETING P ATTERNS & C ONSTRUCTING U SER NTERFACES22in. W. 48in.large falcon. Three color phases occur:blackish, white, gray-brown.uniformly coloredPeregrine Falcon, darkmustaches hood.16-24in. W. 42in.Long-winged, long-tailed hawkwhite rump, usually seen soaringunsteadily marshes wingsheld shallow 'V'. Male palegray back, head, breast. Femaleyoung brown above, streakedbelow, young birds rusty tone.Table 11: Sample notes raptor domain. Listed 2 21 notesNorth American birds prey collected (Bull & Farrand, 1977).Summary characteristics nine domains listed Table 12 togethersimple measures indicate prediction difficulty. instance, Column 1 shows numbernotes domain. larger number notes, easier accuratelytrain predictive method. Column 4 shows standard deviation (STD) lengthnotes domain. likely well-behaved FSM discoveredSTD low. successive tables, domains ranked STD. Column 5presents percentage unique tokens notes. fewer novel tokens note has,likely successive tokens predicted. measure places upper boundpredictive accuracy. Column 6 shows percentage constant tokens, ones alwaysappear fixed position. easier predict constant tokens. Finally, Column 7indicates percentage repeated tokens. fewer tokens repeated verbatim withinnote, likely predictive method become confused localewithin note prediction.first six domains natural interactive note taking task exhibitregular syntax. last three domains included test softwares ability lesssuitable domains. Notes Antihistamine, Lens, Raptor domains contain highlyvariable lists terms natural language sentences. Learned FSMs notesdomains unlikely converge, and, experiments reported here, FSMLens data exceeded maturity threshold (average state usage greater 2).7.1Contextual Prediction AccuracyColumn 7 Table 13 lists accuracy next-token predictions made softwareprompting mode. first nine rows list predictive accuracy tokens notesnine domains independently processed order collected.last row lists predictive accuracy tokens notes nine domains collectively processed. simulates user taking notes several domains simultaneously.put results context, table also lists predictive accuracies severalmethods. Column 1 lists accuracy lower bound method. assumes noteshares fixed sequence tokens. Termed common , method initializes structure79fiS CHLIMMER & H ERMENSDomainAirwingPatternEngine CodeMinivanPowerBookWatchAntihistamineLensRaptor1234567N Notes N Tokens Tokens/Note STD % Unique % Constant % Repeated7893612.0 0.3188013755.8 0.721002022211.1 0.80002233515.2 1.7917095123813.0 2.613115898329.3 5.113011742124.8 9.4178131106634.4 9.6126192187841.8 11.533722Table 12: Quantitative properties nine domains used test alternative methods.first note. removes token sequential structure cannot foundorder notes. best, method predict constant, delimiter-like tokensmay appear regularly notes. performance limited percentage constanttokens reported Column 6 Table 12. performs best PowerBook noteslearns following note syntax:* :NULL * "K" * " PowerBook" * "MB" * "MB" * " Int." * .(Example 3)(The asterisks indicate Kleene star notation.) reads sequence zerotokens token :NULL, followed zero tokens "K", followed zerotokens "PowerBook", on. less successful minivan noteslearns simpler syntax:* :NULL * "K" * " MI" * " Pass" * .(Example 4)Columns 2 3 Table 13 list accuracy using classifier directly predictnext token without explicitly learning syntax. paradigm, examples prefixestoken sequences. Attributes last token sequence, second last token,third last token, on. Class values next token sequencethe onepredicted. Column 2 lists performance simple Bayes classifier, Column 3 listsperformance incremental variant ID3 (Schlimmer & Fisher, 1986). Perhapssurprisingly, methods perform considerably worse simple conjunctive method.Without benefit narrow context provided FSM, methods must implicitlyconstruct representations detect differences similar situations arise withinsingle note. example, PowerBook notes, classifier-only approach must learndiscriminate first second occurrence "MB" token.Column 4 Table 13 lists accuracy viable prediction mechanism. Basedsimple ideas memorization termed digram, method maintains list tokensimmediately followed observed token. example, fabric patterndomain, method retains list tokens {"8-10-12", "10", "11/12", "12"}follow token "Size". list follow tokens kept order leastfrequent. predict next token, system looks last token written predicts80fiS OFTWARE GENTS : C OMPLETING P ATTERNS & C ONSTRUCTING U SER NTERFACESDomainAirwingPatternEngine CodeMinivanPowerBookWatchAntihistamineLensRaptorCombined12345Common Bayes ID4 Digram FSM198847622515 1634431888596429675446407873702110 1444391146402422336863923111248466FSM+Bayes444363447633226094578FSM+ID4 Upper62795168698747808296427824686391125549Table 13: Percentage tokens correctly predicted function learningmethod.frequent follow token. method nearly effective Table 13,especially combined task notes domain entered random order.Laird (1992) describes efficient algorithm maintaining higher-dimensional n-grams,effect increasing context prediction effectively memorizing longer sequencestokens. Lairds algorithm builds Markov tree incorporates heuristics keepsize tree growing excessively large. Regrettably, methods unsuitableinteractive note-taking software difficulty using constructcustom user interface. plausible construct panel exclusive choices based directlyset follow tokens, unclear identify optional choices correspondingloops finite-state machines. Moreover, notes drawn different domains,domains share even single token, follow set include tokensdifferent domains. Using follow sets construct user interface unnecessarilyconfuse user introducing options one domain time.Column 5 Table 13 lists accuracy prediction based solely learned FSMs.Without embedded classifier, method must rely prediction commontransition (or termination) state. prediction based simple counts(as noted Section 4, Learning Embedded Classifiers), method never predicts optionaltransitions.Columns 6 7 Table 13 list accuracy predicting using FSMs embeddedclassifiers. classifiers used simple Bayes incremental ID3, respectively.latter outperforms either FSM alone FSM embedded Bayes classifiers.system makes predictions confidence measure greater 0.25, accuracy significantly different Engine Code, Minivan, Lens, Raptor domains,ranging 10 22 percentage points improvement.Column 8 Table 13 lists estimate upper-bound predictive accuracy.calculated assuming prediction errors made first time distincttoken written.81fiS CHLIMMER & H ERMENS1DomainAirwingPatternEngine CodeMinivanPowerBookWatchAntihistamineLensRaptorNorm6251694782422463122DiffTokens6251714880422566113Rules2a,b63537248834324641245678910RulesAccept Accept Repeat DropNew IDs2ab,3a Restart = 1/4= 3/4Atts Classr62626262626163525051515151536943696969677247284747524548837782828180824328424242414324924242424246346636363636412111212121212Table 14: Percentage tokens correctly predicted function design variations.7.2Design Decisionsnote taking software embodies number design decisions. Table 14 lists effectsdecisions predictive accuracy comparing versions software without design feature. first column lists predictive accuracy softwaresnominal configuration. Column 2 lists accuracy data slightly different generictokenizer. Accuracy higher domains, lower others. custom-built tokenizerone way incorporate knowledge domain. Columns 3 4 show accuracysystem using original two FSM merging rules (cf. Table 1)last merging rule (cf. Table 2), respectively. decreased structural generality tendslower predictive accuracy, embedded classifiers help compensate reducedaccuracy. Column 5 lists accuracy FSM heuristically continueparsing upon encountering token immediate transition. expected,accuracy suffers considerably domains novel token sequencecompletely foils subsequent prediction. Columns 6 7 list accuracy differentvalues free parameter controlling clustering notes together FSM.little effect predictive accuracy case. Column 8 shows accuracyembedded classifiers use information repeated states FSM. Withoutinformation, classifiers cannot predict loop transition taken exactly once.Surprisingly, elimination feature little effect accuracy. Column 9 lists accuracy embedded classifiers associated pair FSM states discardedstates merged. Finally, Column 10 lists accuracy new FSM stateassigned unique ID rather ID oldest two merged states.7.3Sample Button-Box Interfacesaddition Figure 3, Figures 11 15 depict button-box interfaces fivewell-behaved note taking domains listed top Table 12. interfaces visualoffer user organized view notes, presenting options natural way.However, whenever unique tokens involved, current software makes attemptexplicitly generalize tokens. effect reflected tour dates Airwing notesFigure 11. Note radio button panel consists long series dates, nonelikely selected new note.82fiS OFTWARE GENTS : C OMPLETING P ATTERNS & C ONSTRUCTING U SER NTERFACESFigure 11: Screen snapshot note-taking software button-box modeairwing note.Figure 12: Screen snapshot note-taking software button-box modefabric pattern note.8. Related WorkSelf-customizing software agents several subjective dimensionsevaluated compared:AnticipationDoes system present alternatives without userrequest them?User interfaceIs system graphical, command-line oriented?User controlCan user override choose ignore predictive actions?ModalityIf system number working modes, user workmode without explicitly selecting one them?Learning updateIs learning incremental, continuous and/or real-time?83fiS CHLIMMER & H ERMENSFigure 13: Screen snapshot note-taking software button-box modeengine code note.Figure 14: Screen snapshot note-taking software button-box modeminivan note.User adjustableCan user tune system parameters manually?describe related systems exhibit properties agent dimensions.note taking software utilizes anticipation user interface technique pioneeredEager (Cypher, 1991). Eager non-intrusive system learns perform iterative procedures watching user. such, learning apprentice, software agent,example programming example demonstration. Situated within HyperCard environment, continuously watches users actions. detects second cycleiteration, presents execute icon users notice. also visually indicates anticipated next action highlighting appropriate button, menu item, text selectiongreen. user performs task, verify Eager learned correct84fiS OFTWARE GENTS : C OMPLETING P ATTERNS & C ONSTRUCTING U SER NTERFACESFigure 15: Screen snapshot note-taking software button-box modewatch note.procedure comparing anticipations actions. user confident enough,click execution icon, Eager run iterative procedure completion. Eager highly anticipatory, uses graphical interface, non-obtrusive, non-modal,learns real-time, user adjustable.CAP apprenticeship system learns predict default values (Dent, et al., 1992).domain operation calendar management, learns preferences knowledgablesecretary might. example, professor may prefer hold regular group meetingparticular room particular time day particular durationinformationsecretary would know experience. CAP collects information user managescalendar, learns previous meetings, uses regularities learns offer defaultvalues meeting location, time, duration. learning system re-run nightrecent meeting data, learned rules applied prediction followingday. CAP also designed utilize extensible knowledge base contains calendarinformation database personnel information. system continues usedmanage individual faculty calendars. Though offering intelligence, CAPs user interface line-oriented based Emacs editor. Questions asked usermeetings presented using command-line dialog, default predictionsdisplayed one-at-a-time. CAP characterized anticipatory, command-line orientedmodal user control (but user adjustable), learning done batch.Another related system addresses task learning fill form (Hermens &Schlimmer, 1993). system recreates paper form on-screen facsimile, allowinguser view pertinent information glance. Input typed user electronic form processed central form-filling module. user completes formcopy, printed, field value form forwarded learning module (a decision tree learning method). learned representations predict default values fieldform referring values observed fields previous form copy.users point view, spreadsheet functions learnedfield form. Empirical studies indicate system reduced number keystrokes required user 87% 269 forms processed 8 month period85fiS CHLIMMER & H ERMENSactually used office personnel. system unobtrusive, non-modalanticipatory, uses graphical interface, updates learning real-time.Maes Kozierok (1993) addressing problem self-customizing softwaremuch task-independent level. identify three learning opportunities softwareagent: observing users actions imitating them, receiving user feedback upon error,incorporating explicit training user. illustrate generality framework, demonstrate simple learning apprentices help sort users electronic mailschedule meetings. initial systems use instance-based (case- memory-based)approach primarily allows efficient update naturally generatesconfidence predictions. Users may set thresholds predictions, corresponding minimum confidence agent prompt user (a tell-methreshold) higher minimum confidence agent act immediately behalfuser (a do-it threshold). framework learning case anticipatory, utilizesgraphical user interface, devoted user control, non-modal, learns real-time,user adjustable.system developed Macintosh Common Lisp (MCL) provides word-completionmechanism word prefixes typed user window. J. Salem A. Ruttenberg(unpublished) devised MCL methods display word completion status barwindow. user desires add completion window, simply pressCLEAR key. word completion mechanism similar file-name completionEMACS C-shell UNIX systems, except word displayed useradded. system anticipatory (unlike UNIX file completion), commandline oriented (but displays default completion graphical window), fullycontrolled user, non-modal, learns real time, intended user adjustable(though knowledgeable MCL programmers could easily make changes code).interactive note taking software devised require user programming. receives implicit user feedback user chooses complete notedifferent way prompted. mechanisms direct user instructionthreshold tuning. system designed easy use paper, explicit adjustmentmay inappropriate. characterize system anticipatory, graphically-oriented,modal (due switching takes place user wishes display button-boxinterface). allows user override default prompts predictions, learnsreal-time. included features allow user configure performanceagent.9. Observations/Limitationsinteractive note-taking software designed help users capture information digitally,speed entry improve accuracy, support longer term goal efficientretrieval. software incorporates two distinctive features. First, actively predictsuser going write. Second, automatically constructs custom radio-button, checkbox user interface.research explores extremes FSM learning prediction, systemexplicit priori knowledge note domains. tried design systemlearn quickly, yet adapt well semantic syntactic changes, withoutknowledge store draw. clear knowledge form domain-specific tokenizer would aid FSM learning chunking significant phrases relating similarnotations abbreviations. preliminary work shown that, notes86fiS OFTWARE GENTS : C OMPLETING P ATTERNS & C ONSTRUCTING U SER NTERFACESwritten, users may create abbreviations instead writing whole words. domainspecific tokenizer would able relate abbreviation whole wordclass, therefore allow flexibility note taking. example,domain-specific tokenizer may recognize "Megabytes", "Meg", "MB", "M" represent token memory sizes. One could imagine framework would allowdomain-specific tokenizers simply plugged in.prototype built demonstrate ideas implemented conventional,micro computer keyboard input. consequence, impossible evaluate useracceptance new interface adaptive agent. newly available computingdevices incorporating pen input handwriting recognition, possible reengineer user interface field test ideas actual users.One aspect note learning, related tokenization button-box user interfacedisplay, difficulty generalizing numeric strings unique tokens. cardinalityrange model numbers, telephone numbers, quantities, sizes, numeric values,even proper names large note domains. finite-state machine learningmethod presented incapable generalizing transitions particular state,and, consequence, current system problem displaying lengthybutton-box interface list. (A button displayed value encountered syntaxnotes, may many choices.) example, large variety pattern numbers mayavailable fabric pattern note domain. appropriate mechanism desired determine list numeric choices large useful button-box interface.system generalize expected number, indicating number digits promptuser: ####, example. may helpful remind user numberexpected without presenting overbearing list possibilities.Another limitation current effort lies choice finite-state machinesrepresent syntax users notes. Notes may regular expressionsconsequence FSMs may become large learning method attempts acquiresyntax. may place unreasonable demand memory lead reduced promptingeffectiveness.choice finite-state machines also apparently constraints custom user interface.FSMs branch unpredicable ways, button-box interfaces must rendered incrementally. user indicates particular transition (by selecting button), systemrender states reachable transition user. Ideally, user ableselect buttons corresponding note fragments order, allowing writesize pattern number, example. construct non-modal user interface,flexible syntactic representation needed.Several low-level design decisions employed system crude responsestechnical issues. instance, decision render syntax button-box interfaceaverage number times state used parse notes greater 2.ignores fact parts state machine used frequently parsingnotes parts rarely used. Similarly, particular measure estimating prompting confidence (and setting saturation completion button) simplisticwould benefit sound statistical basis.AcknowledgmentsAnonymous reviewers suggested additional example Section 3, offered refinements user interface, graciously identified limitations work listed87fiS CHLIMMER & H ERMENSSection 9, pointed additional related work. Mike Kibler, Karl Hakimian,EECS staff provided consistent reliable computing environment. Apple Cambridgedeveloped supports Macintosh Common Lisp programming environment. AllenCypher provided tokenizer code. work supported part NationalScience Foundation grant number 92-1290 grant Digital EquipmentCorporation.ReferencesAngluin, D. (1982). Inference reversible languages. Journal AssociationComputing Machinery, 29, 741765.Berwick, R. C., & Pilato, S. (1987). Learning syntax automata induction. Machine Learning, 2, 938.Bull, J., & Farrand, J., Jr. (1977). Audubon Society Field Guide North American Birds(Eastern Edition). NY: Alfred A. Knopf (pp. 401682).Chiltons Repair & Tune-Up Guide: GM X-Body 1980-1985 (1985). Randor, PA: ChiltonBook (p. 7).Cohen, W. W. (1988). Generalizing number learning multiple examples explanation based learning. Proceedings Fifth International Conference MachineLearning (pp. 256269). Ann Arbor, MI: Morgan Kaufmann.Consumer Reports (1988), 53 (12), 302303. Mount Vernon, NY: Consumers Union.Cypher, A. (1991). Eager: Programming repetitive tasks example. Proceedings CHI(pp. 3339). New Orleans, LA: ACM.Dent, L., Boticario, J., McDermott, J., Mitchell, T., & Zabowski, D. (1992). personallearning apprentice. Proceedings Tenth National Conference Artificial Intelligence (pp. 96103). San Jose, CA: AAAI Press.Fisher, D. H. (1987). Knowledge acquisition via incremental conceptual clustering. MachineLearning, 2, 139172.Grove, M., & Miller, J. (1989). North American Rockwell A3J/A-5 Vigilante. Arlington, TX:Aerofax (pp. 1315).Hermens, L. A., & Schlimmer, J. C. (1993). machine-learning apprentice completion repetitive forms. Proceedings Ninth IEEE Conference Artificial Intelligence Applications. Orlando, FL.Laird, P. (1992). Discrete sequence prediction applications. Proceedings TenthNational Conference Artificial Intelligence (pp. 135140). San Jose, CA: AAAI Press.88fiS OFTWARE GENTS : C OMPLETING P ATTERNS & C ONSTRUCTING U SER NTERFACESMaes, P., & Kozierok, R. (1993). Learning interface agents. Proceedings EleventhNational Conference Artificial Intelligence (pp. 459465). Washington, D. C.: AAAIPress.Nurses Guide Drugs (1979). Horsham, PA: Intermed Communications (pp. 454462).Schlimmer, J. C., & Fisher, D. H. (1986). case study incremental concept induction.Proceedings Fifth National Conference Artificial Intelligence (pp. 496501).Philadelphia, PA: AAAI Press.89fiJournal Artificial Intelligence Research 1 (1993) 25-46Submitted 7/93; published 8/93Dynamic BacktrackingMatthew L. Ginsbergginsberg@cs.uoregon.eduCIRL, University Oregon,Eugene, 97403-1269 USAAbstractoccasional need return shallow points search tree, existingbacktracking methods sometimes erase meaningful progress toward solving searchproblem. paper, present method backtrack points moveddeeper search space, thereby avoiding diculty. technique developedvariant dependency-directed backtracking uses polynomial space stillproviding useful control information retaining completeness guarantees providedearlier approaches.1. IntroductionImagine trying solve constraint-satisfaction problem, csp.interests definiteness, suppose csp question involves coloring mapUnited States subject restriction adjacent states colored differently.Imagine begin coloring states along Mississippi, thereby splittingremaining problem two. begin color states western halfcountry, coloring perhaps half dozen deciding likely ablecolor rest. Suppose also last state colored Arizona.point, change focus eastern half country. all, can'tcolor eastern half coloring choices states along Mississippi,point wasting time completing coloring western states.successfully color eastern states return west. Unfortunately,color New Mexico Utah get stuck, unable color (say) Nevada. What's more,backtracking doesn't help, least sense changing colors New MexicoUtah alone allow us proceed farther. Depth-first search wouldus backtrack eastern states, trying new color (say) New York vain hopewould solve problems West.obviously pointless; blockade along Mississippi makes impossibleNew York impact attempt color Nevada western states.What's more, likely examine every possible coloring eastern statesaddressing problem actually source diculties.solutions proposed involve finding ways backtrack directlystate might actually allow us make progress, case Arizona earlier.Dependency-directed backtracking (Stallman & Sussman, 1977) involves direct backtracksource diculty; backjumping (Gaschnig, 1979) avoids computational overhead technique using syntactic methods estimate point backtracknecessary.c 1993 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.fiGinsbergcases, however, note although backtrack source problem,backtrack successful solution half original problem, discardingsolution problem coloring states East. again, problemworse { recolor Arizona, danger solving East yetrealizing new choice Arizona needs changed all. won'texamine every possible coloring eastern states, danger rediscoveringsuccessful coloring exponential number times.hardly seems sensible; human problem solver working problem wouldsimply ignore East possible, returning directly Arizona proceeding.states along Mississippi needed new colors would East reconsidered { evennew coloring could found Mississippi consistenteastern solution.paper formalize technique, presenting modification conventionalsearch techniques capable backtracking recently expandednode, also directly node elsewhere search tree. dynamic waysearch structured, refer technique dynamic backtracking.specific outline follows: begin next section introducingvariety notational conventions allow us cast existing work newideas uniform computational setting. Section 3 discusses backjumping, intermediatesimple chronological backtracking ideas, presentedSection 4. example dynamic backtracking algorithm use appears Section5 experimental analysis technique Section 6. summary resultssuggestions future work Section 7. proofs deferred appendixinterests continuity exposition.2. PreliminariesDefinition 2.1 constraint satisfaction problem (I; V; ) mean set vari-ables; 2 , set Vi possible values variable i. setconstraints, pair (J; P ) J = (j1; . . . ; jk ) ordered subset Psubset Vj1 Vjk .solution csp set vi values variables vi 2 Vievery constraint (J; P ) form , (vj1 ; . . . ; vjk ) 2 P .example introduction, set states Vi set possiblecolors state i. constraint, first part constraint pair adjacentstates second part set allowable color combinations states.basic plan paper present formal versions search algorithmsdescribed introduction, beginning simple depth-first search proceedingbackjumping dynamic backtracking. start, make following definitionpartial solution csp:Definition 2.2 Let (I; V; ) csp. partial solution csp mean orderedsubset J assignment value variable J .26fiDynamic Backtrackingdenote partial solution tuple ordered pairs, ordered pair(i; v ) assigns value v variable i. partial solution P , denote Pset variables assigned values P .Constraint-satisfaction problems solved practice taking partial solutionsextending assigning values new variables. general, course, valueassigned variable inconsistent constraints. thereforemake following definition:Definition 2.3 Given partial solution Pcsp, eliminating explanationvariable pair (v; ) v 2 Vi P . intended meaningcannot take value v values already assigned P variables .elimination mechanism csp function accepts arguments partialsolution P , variable 62 P . function returns (possibly empty) set (P; i)eliminating explanations i.set E eliminating explanations, denote Eb valuesidentified eliminated, ignoring reasons given. therefore denote b(P; i) setvalues eliminated elements (P; i).Note definition somewhat exible regard amount workdone elimination mechanism { values violate completed constraints mighteliminated, amount lookahead might done. will, however, makefollowing assumptions elimination mechanisms:1. correct. partial solution P , value vi 62 b(P; i), everyconstraint (S; ) P [fig satisfied values partial solutionvalue vi i. constraints complete value viassigned i.2. complete. Suppose P partial solution csp,solution extends P assigning value v i. P 0 extension P(v; E ) 2 (P 0 ; i),E \ (P 0 , P ) 6=(1)words, whenever P successfully extended assigning vP 0 cannot be, least one element P 0 , P identified possible reasonproblem.3. concise. partial solution P , variable eliminated value v ,single element form (v; E ) 2 (P; i). one reason givenvariable cannot value v .Lemma 2.4 Let complete elimination mechanism csp, let P partial solution csp let 62 P . P successfully extended complete solutionassigning value v , v 62 b(P; i).apologize swarm definitions, allow us give clean descriptiondepth-first search:27fiGinsbergAlgorithm 2.5 (Depth-first search) Given inputs constraint-satisfaction problemelimination mechanism :1. Set P = . P partial solution csp. Set Ei = 2 ; Eiset values eliminated variable i.2. P = , P assigns value every element , solutionoriginal problem. Return it. Otherwise, select variable 2 , P . Set Ei = b(P; i),values eliminated possible choices i.3. Set = Vi , Ei, set remaining possibilities i. nonempty, chooseelement v 2 . Add (i; v ) P , thereby setting i's value v , return step 2.4. empty, let (j; vj ) last entry P ; entry, return failure.Remove (j; vj ) P , add vj Ej , set = j return step 3.written algorithm returns single answer csp; modification accumulate answers straightforward.problem Algorithm 2.5 looks little like conventional depth-firstsearch, since instead recording unexpanded children particular node,keeping track failed siblings node. following:Lemma 2.6 point execution Algorithm 2.5, last element partialsolution P assigns value variable i, unexplored siblings current nodeassign values Vi , Ei .Proposition 2.7 Algorithm 2.5 equivalent depth-first search therefore complete.remarked, basic difference Algorithm 2.5 conventional description depth-first search inclusion elimination sets Ei.conventional description expects nodes include pointers back parents; siblings given node found examining children node's parent. Sincereorganizing space search, impractical framework.might seem natural solution diculty would recordvalues eliminated variable i, remain considered.technical reason done much easier maintainelimination information search progresses. understand intuitive level,note search backtracks, conclusion implicitly drawnparticular node fails expand solution, opposed conclusioncurrently unexplored portion search space. little surpriseecient way manipulate information recording approximately form.3. Backjumpingdescribe dependency-directed backtracking backjumping setting?cases, partial solution forced backtrack;sophisticated backtracking mechanisms use information reason failureidentify backtrack points might allow problem addressed. start, needmodify Algorithm 2.5 maintain explanations eliminated values:28fiDynamic BacktrackingAlgorithm 3.1 Given inputs constraint-satisfaction problem elimination mechanism :1. Set P = Ei = 2 . Ei set eliminating explanations i.2. P = , return P . Otherwise, select variable 2 , P . Set Ei = (P; i):3. Set = Vi , Ebi. nonempty, choose element v 2 . Add (i; v ) Preturn step 2.4. empty, let (j; vj ) last entry P ; entry, return failure.Remove (j; vj ) P . must Ebi = Vi, every valueeliminated; let E set variables appearing explanationseliminated value. Add (vj ; E , fj g) Ej , set = j return step 3.Lemma 3.2 Let P partial solution obtained execution Algorithm 3.1,let 2 P variable assigned value P . P 0 P successfullyextended complete solution assigning value v (v; E ) 2 Ei , mustE \ (P , P 0) 6=words, assignment value variable P , P 0 correctly identifiedsource problem.Note step 4 algorithm, could added (vj ; E \ P ) instead (vj ; E ,fj g) Ej ; either way, idea remove E variables longer assignedvalues P .backjumping, simply change backtrack method; instead removingsingle entry P returning variable assigned value prior problematicvariable i, return variable actually impact i. words,return variable set E .Algorithm 3.3 (Backjumping) Given inputs constraint-satisfaction problemelimination mechanism :1. Set P = Ei = 2 .2. P = , return P . Otherwise, select variable 2 , P . Set Ei = (P; i):3. Set = Vi , Ebi. nonempty, choose element v 2 . Add (i; v ) Preturn step 2.4. empty, must Ebi = Vi . Let E set variables appearingexplanations eliminated value.5. E = , return failure. Otherwise, let (j; vj ) last entry P j 2 E .Remove P entry entry following it. Add (vj ; E \ P ) Ej , set = jreturn step 3.29fiGinsbergstep 5, add (vj ; E \ P ) Ej , removing E variables longerassigned values P .Proposition 3.4 Backjumping complete always expands fewer nodes depthfirst search.Let us look map-coloring example. partial coloringP looking specific state i, suppose denote C set colorsobviously illegal con ict color already assigned one i'sneighbors.One possible elimination mechanism returns (P; i) list (c; P ) colorc 2 C used color neighbor i. reproduces depth-first search, sincegradually try possible colors idea went wrong needbacktrack since every colored state included P . far sensible choice would take(P; i) list (c; fng) n neighbor already colored c. wouldensure backjump neighbor coloring found.causes us backjump another state j , add i's neighbors eliminating explanation j 's original color, need backtrack still further,consider neighbors either j . be, since changing color onei's neighbors might allow us solve coloring problem reverting originalchoice color state j .also have:Proposition 3.5 amount space needed backjumping o(i2v), = jI jnumber variables problem v number values variablelargest value set Vi .result contrasts sharply approach csps relies truth-maintenancetechniques maintain list nogoods (de Kleer, 1986). There, number nogoodsfound grow linearly time taken analysis, typicallyexponential size problem. Backjumping avoids problem resettingset Ei eliminating explanations step 2 Algorithm 3.3.description given quite similar developed (Bruynooghe,1981). explanations somewhat coarser ours, listing variablesinvolved eliminating explanation particular variable csp,idea essentially same. Bruynooghe's eliminating explanations storedo(i2) space (instead o(i2v )), associated loss information makes techniqueless effective practice. earlier work also description backjumping only, sinceintermediate information erased search proceeds.4. Dynamic backtrackingfinally turn new results. basic problem Algorithm 3.3 backjumps wrong place, needlessly erases great deal workdone thus far. least, retain values selected variablesbackjumped over, sense moving backjump variable end partial30fiDynamic Backtrackingsolution order replace value without modifying values variablesfollowed it.additional modification probably clearest returnexample introduction. Suppose example, color easternstates returning western half country. reorder variables orderbacktrack Arizona eventually succeed coloring West without disturbingcolors used East.Unfortunately, return East backtracking required findneeding change coloring eastern states dealt earlier.ideas presented allow us avoid erasing solution problemsWest, search eastern states ecient, needretain information portion East's search spaceeliminated. all, determined New York cannot colored yellow,changes West reverse conclusion { Mississippi really isolate onesection country other.machinery needed capture sort reasoning already place.backjump variable k, retain choice value k, also k'selimination set. do, however, need remove elimination set entryinvolves eventual backtrack variable j , since entries longer valid {depend assumption j takes old value, assumption false.Algorithm 4.1 (Dynamic backtracking I) Given inputs constraint-satisfaction problem elimination mechanism :1. Set P = Ei = 2 .2. P = , return P . Otherwise, select variable 2 , P . Set Ei = Ei [ (P; i).3. Set = Vi , Ebi. nonempty, choose element v 2 . Add (i; v ) Preturn step 2.4. empty, must Ebi = Vi ; let E set variables appearingexplanations eliminated value.5. E = , return failure. Otherwise, let (j; vj ) last entry P j 2 E .Remove (j; vj ) P and, variable k assigned value j , removeEk eliminating explanation involves j . SetEj = Ej [ (P; j ) [ f(vj ; E \ P )g(2)vj eliminated value j values taken variablesE \ P . inclusion term (P; j ) incorporates new information variablesassigned values since original assignment vj j . set = jreturn step 3.Theorem 4.2 Dynamic backtracking always terminates complete. continuessatisfy Proposition 3.5 expected expand fewer nodes backjumping providedgoal nodes distributed randomly search space.31fiGinsbergessential difference dynamic dependency-directed backtrackingstructure eliminating explanations means save nogood informationbased current values assigned variables; nogood depends outdated information, drop it. this, avoid need retain exponential amountnogood information. makes technique valuable (as stated theorem)termination still guaranteed.one trivial modification make Algorithm 4.1 quite usefulpractice. removing current value backtrack variable j , Algorithm 4.1immediately replaces another. real reason this; couldinstead pick value entirely different variable:Algorithm 4.3 (Dynamic backtracking) Given inputs constraint-satisfaction problem elimination mechanism :1. Set P = Ei = 2 .2. P = , return P . Otherwise, select variable 2 , P . Set Ei = Ei [ (P; i).3. Set = Vi , Ebi. nonempty, choose element v 2 . Add (i; v ) Preturn step 2.4. empty, must Ebi = Vi ; let E set variables appearingexplanations eliminated value.5. E = , return failure. Otherwise, let (j; vj ) last entry P bindsvariable appearing E . Remove (j; vj ) P and, variable k assignedvalue j , remove Ek eliminating explanation involves j . Add(vj ; E \ P ) Ej return step 2.5. exampleorder make Algorithm 4.3 bit clearer, suppose consider small mapcoloring problem detail. map shown Figure 1 consists five countries:Albania, Bulgaria, Czechoslovakia, Denmark England. assume (wrongly!)countries border shown figure, countries denoted nodesborder one another arc connecting them.coloring map, use three colors red, yellow blue. typicallyabbreviate country names single letters obvious way.begin search Albania, deciding (say) color red. lookBulgaria, colors eliminated Albania Bulgaria share border;decide color Bulgaria yellow. (This mistake.)go consider Czechoslovakia; since borders Albania, color redeliminated. decide color Czechoslovakia blue situation this:32fiDynamic BacktrackingDenmarkCzechoslovakia,,@@,@@,,@,@@,Albanias,@,sBulgaria@@,,@@,,@,@@ ,@,sEnglandFigure 1: small map-coloring problemcountrycolor red yellow blueAlbaniaredBulgariayellowCzechoslovakia blueDenmarkEnglandcountry, indicate current color eliminating explanations meancannot colored three colors (when explanations exist). lookDenmark.Denmark cannot colored red border Albania cannot coloredyellow border Bulgaria; must therefore colored blue.England cannot colored color borders Albania, BulgariaDenmark, therefore need backtrack one three countries.point, elimination lists follows:countrycolor red yellow blueAlbaniaredBulgariayellowCzechoslovakia blueDenmarkblueBEnglandBbacktrack Denmark recent three possibilities,begin removing eliminating explanation involving Denmark tableget:33fiGinsbergcolor red yellow bluecountryAlbaniaredBulgariayellowCzechoslovakia blueDenmarkBEnglandBNext, add Denmark's elimination list pair(blue; fA; B g)indicates correctly current colors Albania Bulgaria, Denmark cannot colored blue (because subsequent dead end England). Since everycolor eliminated, must backtrack country set fA; B g. ChangingCzechoslovakia's color won't help must deal Bulgaria instead. eliminationlists now:countrycolor red yellow blueAlbaniaredBulgariaCzechoslovakia blueDenmarkB A,BEnglandBremove eliminating explanations involving Bulgaria also add Bulgaria's elimination list pair(yellow; A)indicating correctly Bulgaria cannot colored yellow current choicecolor Albania (red).situation now:color red yellow bluecountryAlbaniaredCzechoslovakia blueBulgariaDenmarkEnglandmoved Bulgaria past Czechoslovakia ect search reordering algorithm. complete problem coloring Bulgaria red, Denmark either yellowblue, England color used Denmark.example almost trivially simple, course; thing notechanged color Bulgaria, retained blue color Czechoslovakiainformation indicating none Czechoslovakia, Denmark England could red.complex examples, information may hard-won retaining maysave us great deal subsequent search effort.Another feature specific example (and example introductionwell) computational benefits dynamic backtracking consequence34fiDynamic Backtrackingautomatic realization problem splits disjoint subproblems. authorsalso discussed idea applying divide-and-conquer techniques csps (Seidel, 1981;Zabih, 1990), methods suffer disadvantage constrain orderunassigned variables assigned values, perhaps odds common heuristicassigning values first variables tightly constrained. Dynamicbacktracking also expected use situations problem questionsplit two disjoint subproblems.16. ExperimentationDynamic backtracking incorporated crossword-puzzle generation programdescribed (Ginsberg, Frank, Halpin, & Torrance, 1990), leads significant performance improvements restricted domain. specifically, method testedproblem generating 19 puzzles sizes ranging 2 2 13 13; puzzleattempted 100 times using dynamic backtracking simple backjumping.dictionary shued solution attempts maximum 1000 backtrackspermitted program deemed failed.cases, algorithms extended include iterative broadening (Ginsberg& Harvey, 1992), cheapest-first heuristic forward checking. Cheapest-firstalso called \most constrained first" selects instantiation variablefewest number remaining possibilities (i.e., variable cheapestenumerate possible values (Smith & Genesereth, 1985)). Forward checking prunesset possibilities crossing words whenever new word entered constitutesexperimental choice elimination mechanism: point, words legalcrossing word eliminated. ensures word entered crosswordword potential crossing words point. cheapest-first heuristicwould identify problem next step search, forward checking reducesnumber backtracks substantially. \least-constraining" heuristic (Ginsberg et al.,1990) used; heuristic suggests word slot filled wordminimally constrains subsequent search. heuristic used wouldinvalidate technique shuing dictionary solution attempts ordergather useful statistics.table Figure 2 indicates number successful solution attempts (out 100)two methods 19 crossword frames. Dynamic backtrackingsuccessful six cases less successful none.regard number nodes expanded two methods, consider datapresented Figure 3, graph average number backtracks neededtwo methods.2 Although initially comparable, dynamic backtracking provides increasingcomputational savings problems become dicult. somewhat broader setexperiments described (Jonsson & Ginsberg, 1993) leads similar conclusions.examples (Jonsson & Ginsberg, 1993) dynamic backtrackingleads performance degradation, however; typical case appears Figure 4.31. indebted David McAllester observations.2. 17 points shown point plotted backjumping unable solve problem.3. worst performance degradation observed factor approximately 4.35fiGinsbergDynamicDynamicFrame backtracking Backjumping Frame backtracking Backjumping110010011100981001001210010023100100131001001001001410010045100100159914100100161002667100100171003010010018610891001001910010100100Figure 2: Number problems solved successfully400rrdynamic 200backtrackingrrr rrrrrrrrrrr200400600backjumpingFigure 3: Number backtracks needed368001000fiDynamic BacktrackingRegion1,,,,,,,Bsas,@@aaaaaaaaaa @@aaa @aa@a@a@sRegion 2Figure 4: dicult problem dynamic backtrackingfigure, first color A, B , countries region 1, get stuck region2.presumably backtrack directly B , leaving coloring region 1 alone.may well mistake { colors region 1 restrict choices B , perhapsmaking subproblem consisting A, B region 2 dicult might be.region 1 easy color, would better erasing even though didn'tneed to.analysis suggests dependency-directed backtracking also fare worsecoloring problems dynamic backtracking trouble, currentlyextending experiments (Jonsson & Ginsberg, 1993) confirm this. conjectureborne out, variety solutions come mind. might, example, recordmany backtracks made node B figure, usedetermine exibility B important retaining choices made region1. diculty finding coloring region 1 also determined numberbacktracks involved search.7. Summary7.1 workstwo separate ideas exploited development Algorithm 4.3others leading it. first, easily important, notionpossible modify variable order way allows us retainresults earlier work backtracking variable assigned value earlysearch.37fiGinsbergreordering confused work authors suggesteddynamic choice among variables remain assigned values (Dechter & Meiri,1989; Ginsberg et al., 1990; P. Purdom & Robertson, 1981; Zabih & McAllester, 1988);instead reordering variables assigned values search thus far.Another way look idea found way \erase" value givenvariable directly opposed backtracking it. idea also exploredMinton et.al. (Minton, Johnston, Philips, & Laird, 1990) Selman et.al.(Selman, Levesque, & Mitchell, 1992); authors also directly replace values assignedvariables satisfiability problems. Unfortunately, heuristic repair method usedincomplete dependency information retained one state problemsolver next.third way view well. space examining reallygraph, opposed tree; reach point coloring Albania blueBulgaria red color opposite order. decide backjumpparticular node search space, know need back particularproperty node ceases hold { key idea backtracking alongpath one node generated, may able backtrackslightly would otherwise need retreat great deal. observationinteresting may well apply problems csps. Unfortunately,clear guarantee completeness search discovers node using one pathbacktracks using another.idea less novel. already remarked, use eliminatingexplanations quite similar use nogoods atms community; principaldifference attach explanations variables impact dropcease relevant. (They might become relevant later, course.)avoids prohibitive space requirements systems permanently cache resultsnogood calculations; observation also may extensible beyond domaincsps specifically. Again, ways view { Gashnig's notion backmarking(Gaschnig, 1979) records similar information reason particular portionssearch space known contain solutions.7.2 Future workvariety ways techniques presented extended;section, sketch obvious ones.7.2.1 Backtracking older culpritsOne extension work involves lifting restriction Algorithm 4.3 variableerased always recently assigned member set E .general, cannot retaining completeness search. Considerfollowing example:Imagine csp involves three variables, x, z , take value 01. Further, suppose csp solutions, pick two valuesx , realize suitable choice z .38fiDynamic Backtrackingbegin taking x = = 0; realize need backtrack, introducenogoodx = 0 6= 0(3)replace value = 1.fails, too, suppose decide backtrack x, introducingnew nogood= 1 x 6= 0(4)change x's value 1 erase (3).also fails. decide problem change value 0, introducingnogoodx = 1 6= 1erasing (4). fails, danger returning x = = 0,eliminated beginning example. loop may cause modified versiondynamic backtracking algorithm fail terminate.terms proof Theorem 4.2, nogoods discovered already include informationassigned variables, difference (7) (8). drop(3) favor (4), longer position recover (3).deal placing conditions variables choosebacktrack; conditions need defined proof Theorem 4.2 continueshold.4 Experimentation indicates loops form described extremelyrare practice; may also possible detect directly thereby retainsubstantial freedom choice backtrack point.freedom backtrack raises important question yet addressedliterature: backtracking avoid diculty sort, onebacktrack?Previous work constrained backtrack recent choicemight impact problem question; decision would incompleteinecient. Although extension Algorithm 4.3 need operate restriction,given indication backtrack point selected.several easily identified factors expected bear choice.first remains reason expect backtracking chronologically recentchoices effective { choices expected contributedfewest eliminating explanations, obvious advantage retaining manyeliminating explanations possible one point search next. possible, however, simply identify backtrack point affects fewest numbereliminating explanations use that.Alternatively, might important backtrack choice pointmany new choices possible; extreme example, variableevery value current one already eliminatedreasons, backtracking guaranteed generate another backtrack immediatelyprobably avoided possible.4. Another solution appears (McAllester, 1993).39fiGinsbergFinally, measure \directness" variable bearsproblem. unable find value particular variable i, probably sensiblebacktrack second variable shares constraint itself, opposedvariable affects indirectly.competing considerations weighed? idea. framework developed interesting allows us work question.basic terms, \debug" partial solutions csps directly, moving laterallysearch space attempt remain close solution possible.sort lateral movement seems central human solution dicult search problems,encouraging begin understand formal way.7.2.2 Dependency pruningoften case one value variable eliminated solving csp,others eliminated well. example, solving scheduling problem particularchoice time (say = 16) may eliminated task isn't enoughtime subsequent task B ; case, later times obviouslyeliminated well.Formalizing subtle; all, later time isn't uniformly worseearlier time may tasks need precede making latermakes part schedule easier. It's problem B alone forcesearlier; again, analysis depends ability maintain dependency informationsearch proceeds.formalize follows. Given csp (I; V; ), suppose value vassigned 2 . construct new csp (I 0; V 0 ; 0) involvingremaining variables 0 = ,fig, new set V 0 need mention possible valuesVi i, 0 generated modifying constraints indicateassigned value v . also make following definition:Definition 7.1 Given csp, suppose variable two possible values uv. say v stricter u every constraint csp induced assigningu also constraint csp induced assigning value v.point, course, v stricter u is, point tryingsolution involving v u eliminated. all, finding solution wouldinvolve satisfying constraints v restriction, supersetu restriction, unable satisfy constraints u restriction originally.example began section generalizes following:Proposition 7.2 Suppose csp involves set variables,partial solution assigns values variables subset P . Supposeextend partial solution assigning value u variable 62 P ,extension solution entire csp. consider csp involvingvariables , P induced choices values variables P . v stricteru choice value problem, original csp solutionassigns v extends given partial solution P .40fiDynamic Backtrackingproposition isn't quite enough; earlier example, choice = 17stricter = 16 task needs scheduled is.need record fact B (which longer assigned value) sourcediculty. this, need augment dependency informationworking.precisely, say set variables fxi g eliminates value v variablex, mean search date allowed us conclude(v1 = x1) ^ ^ (vk = xk ) v 6= xvi current choices xi . obviously rewrite(v1 = x1 ) ^ ^ (vk = xk ) ^ (v = x) F(5)F indicates csp question solution.Let's specific still, indicating (5) exactly csp solution:(v1 = x1 ) ^ ^ (vk = xk ) ^ (v = x) F (I )(6)set variables complete csp.address example began section; cspknown fail expression (6) entire problem, subset it.example, considering, subproblem involves two tasks B .general, augment nogoods include information subproblemsfail, measure strictness respect restricted subproblemsonly. example, indeed allow us eliminate = 17 considerationpossible time A.additional information stored nogoods doubles size (we storesecond subset variables csp), variable sets involved manipulatedeasily search proceeds. cost involved employing technique thereforestrictness computation. may substantial given data structures currentlyused represent csps (which typically support need check constraintviolated little more), seems likely compile-time modifications datastructures used make strictness question easier answer. schedulingproblems, preliminary experimental work shows idea important one; here,too, much done.basic lesson dynamic backtracking retaining nogoodsstill relevant given partial solution working, storage dicultiesencountered full dependency-directed methods alleviated. makesideas proposed possible { erasing values, selecting alternate backtrackpoints, dependency pruning. surely many effective uses practicaldependency maintenance system well.Acknowledgementswork supported Air Force Oce Scientific Research grantnumber 92-0693 DARPA/Rome Labs grant number F30602-91-C-0036.41fiGinsbergwould like thank Rina Dechter, Mark Fox, Geddis, Harvey, Vipin Kumar,Scott Roy Narinder Singh helpful comments ideas. Ari JonssonDavid McAllester provided invaluable assistance experimentation proofsrespectively.A. ProofsLemma 2.4 Let complete elimination mechanism csp, let P partial solutioncsp let 62 P . P successfully extended complete solutionassigning value v , v 62 b(P; i).Proof. Suppose otherwise, (v; E ) 2 (P; i). follows directly completenessE \ (P , P ) 6=contradiction.Lemma 2.6 point execution Algorithm 2.5, last element partialsolution P assigns value variable i, unexplored siblings current nodeassign values Vi , Ei .Proof. first note decide assign value new variable step 2algorithm, take Ei = b(P; i) Vi , Ei set allowed valuesvariable. lemma therefore holds case. fact continues holdrepetition loop steps 3 4 simple induction; point,add Ei node failed possible value assigned i.Proposition 2.7 Algorithm 2.5 equivalent depth-first search therefore complete.Proof. easy consequence lemma. Partial solutions correspond nodessearch space.Lemma 3.2 Let P partial solution obtained execution Algorithm 3.1,let 2 P variable assigned value P . P 0 P successfully extendedcomplete solution assigning value v (v; E ) 2 Ei , mustE \ (P , P 0) 6=Proof. proof Lemma 2.6, show step Algorithm 3.1 causeLemma 3.2 become false.lemma holds step 2, search extended consider newvariable, immediate consequence assumption elimination mechanismcomplete.step 4, add (vj ; E , fj g) set eliminating explanations j ,simply recording fact search solution j set vj failedunable extend solution i. consequence inductive hypothesislong variable E , fj g changes, conclusion remain valid.Proposition 3.4 Backjumping complete always expands fewer nodes depthfirst search.42fiDynamic BacktrackingProof. fewer nodes examined clear; completeness, follows Lemma3.2 backtrack element E step 5 always necessary solutionfound.Proposition 3.5 amount space needed backjumping o(i2v), = jI jnumber variables problem v number values variablelargest value set Vi .Proof. amount space needed dominated storage requirements elimination sets Ej ; these. one might refer possible valuesparticular variable j ; space needed store reason value j eliminatedjI j, since reason simply list variables assigned values.never two eliminating explanations variable, since concisenever rebind variable value eliminated.Theorem 4.2 Dynamic backtracking always terminates complete. continuessatisfy Proposition 3.5 expected expand fewer nodes backjumping providedgoal nodes distributed randomly search space.Proof. four things need show: dynamic backtracking needs o(i2v)space, complete, expected expand fewer nodes backjumping,terminates. prove things order.Space clear; amount space needed continues bounded structureeliminating explanations.Completeness also clear, since Lemma 3.2, eliminating explanationsretained algorithm obviously still valid. new explanations added (2)also obviously correct, since indicate j cannot take value vj backjumpingj also cannot take values eliminated variables backjumpedover.Eciency see expect expand fewer nodes, suppose subprobleminvolving variables jumped solutions total, one givenexisting variable assignments. Assuming solutions distributed randomlysearch space, least 1=s chance particular solution leadssolution entire csp; so, reordered search { considers solution earlier{ save expense either assigning new values variablesrepeating search led existing choices. reordered search also benefitinformation nogoods retained variables jumpedover.Termination dicult part proof.work algorithm, generating (and discarding) varietyeliminating explanations. Suppose e explanation, saying j cannottake value vj values currently taken variables set eV .denote variables eV x1 ; . . . ; xk current values v1; . . . ; vk .declarative terms, eliminating explanation telling us(x1 = v1) ^ ^ (xk = vk ) j 6= vj43(7)fiGinsbergDependency-directed backtracking would us accumulate nogoods; dynamicbacktracking allows us drop particular instance (7) antecedentlonger valid.reason dependency-directed backtracking guaranteed terminateset accumulated nogoods eliminates monotonically increasing amount searchspace. nogood eliminates new section search space naturesearch process node examined consistent nogoodsaccumulated thus far; process monotonic nogoods retained throughoutsearch. arguments cannot applied dynamic backtracking, since nogoodsforgotten search proceeds. make analogous argument.this, suppose discover nogood like (7), recordvariables precede variable j partial order, together values currentlyassigned variables. Thus eliminating explanation becomes essentially nogoodn form (7) together set variable/value pairs.define mapping (n; ) changes antecedent (7) include assumptions variables bound , = fsi ; vi g,(n; ) = [(s1 = v1) ^ ^ (sl = vl) j 6= vj ](8)point execution algorithm, denote N conjunctionmodified nogoods form (8).make following claims:1. eliminating explanation (n; ), n j= (n; ) (n; ) validproblem hand.2. new eliminating explanation (n; ), (n; ) consequence N .3. deductive consequences N grow monotonically dynamic backtrackingalgorithm proceeds.theorem follow three observations, since know N validset conclusions search problem making monotonicprogress toward eliminating entire search space concluding problemunsolvable.(n; ) consequence (n; ) clear, since modification used obtain(8) (7) involves strengthening antecedent (7). also clear (n; )consequence nogoods already obtained, since added antecedentconditions hold node search space currently examination.(n; ) consequence nogoods obtained thus far, node wouldconsidered.last observation depends following lemma:Lemma A.1 Suppose x variable assigned value partial solutionx appears antecedent nogood n pair (n; ). 0 setvariables assigned values later x, 0 .44fiDynamic BacktrackingProof. Consider 2 0, suppose . cannot = x, sincewould mentioned nogood n therefore . supposeactually assigned value earlier x is. (n; ) added seteliminating explanations, must case x assigned value (sinceappears antecedent n) not. also knowlater time assigned value x not, since precedes x currentpartial solution. means x must changed value point (n; )added set eliminating explanations { (n; ) would deletedhappened. contradiction completes proof.Returning proof Theorem 4.2, suppose eventually drop (n; )collection nogoods so, new nogood added (n0; 0).follows lemma 0 . Since xi = vi clause antecedent (n; ),follows (n0 ; 0) imply negation antecedent (n; ) thereforeimply (n; ) itself. Although drop (n; ) drop nogood (n; ), (n; )continues entailed modified set N , consequences seengrowing monotonically.ReferencesBruynooghe, M. (1981). Solving combinatorial search problems intelligent backtracking.Information Processing Letters, 12 (1), 36{39.de Kleer, J. (1986). assumption-based truth maintenance system. Artificial Intelligence,28, 127{162.Dechter, R., & Meiri, I. (1989). Experimental evaluation preprocessing techniquesconstraint satisfaction problems. Proceedings Eleventh International JointConference Artificial Intelligence, pp. 271{277.Gaschnig, J. (1979). Performance measurement analysis certain search algorithms.Tech. rep. CMU-CS-79-124, Carnegie-Mellon University.Ginsberg, M. L., Frank, M., Halpin, M. P., & Torrance, M. C. (1990). Search lessons learnedcrossword puzzles. Proceedings Eighth National Conference ArtificialIntelligence, pp. 210{215.Ginsberg, M. L., & Harvey, W. D. (1992). Iterative broadening. Artificial Intelligence, 55,367{383.Jonsson, A. K., & Ginsberg, M. L. (1993). Experimenting new systematic nonsystematic search techniques. Proceedings AAAI Spring Symposium AINP-Hard Problems Stanford, California.McAllester, D. A. (1993). Partial order backtracking. Journal Artificial IntelligenceResearch, 1. Submitted.Minton, S., Johnston, M. D., Philips, A. B., & Laird, P. (1990). Solving large-scale constraint satisfaction scheduling problems using heuristic repair method. Proceedings Eighth National Conference Artificial Intelligence, pp. 17{24.45fiGinsbergP. Purdom, C. B., & Robertson, E. (1981). Backtracking multi-level dynamic searchrearrangement. Acta Informatica, 15, 99{114.Seidel, R. (1981). new method solving constraint satisfaction problems. ProceedingsSeventh International Joint Conference Artificial Intelligence, pp. 338{342.Selman, B., Levesque, H., & Mitchell, D. (1992). new method solving hard satisfiabilityproblems. Proceedings Tenth National Conference Artificial Intelligence.Smith, D. E., & Genesereth, M. R. (1985). Ordering conjunctive queries. Artificial Intelligence, 26 (2), 171{215.Stallman, R. M., & Sussman, G. J. (1977). Forward reasoning dependency-directedbacktracking system computer-aided circuit analysis. Artificial Intelligence,9 (2), 135{196.Zabih, R. (1990). applications graph bandwidth constraint satisfaction problems.Proceedings Eighth National Conference Artificial Intelligence, pp. 46{51.Zabih, R., & McAllester, D. A. (1988). rearrangement search strategy determiningpropositional satisfiability. Proceedings Seventh National ConferenceArtificial Intelligence, pp. 155{160.46fi