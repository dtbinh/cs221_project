Journal Artificial Intelligence Research 1 (1993) 91-107

Submitted 8/93; published 11/93

Diculties Learning Logic Programs Cut
Francesco Bergadano

bergadan@di.unito.it

Daniele Gunetti
Umberto Trinchero

gunetti@di.unito.it
trincher@di.unito.it

Universita di Catania, Dipartimento di Matematica,
via Andrea Doria 6, 95100 Catania, Italy
Universita di Torino, Dipartimento di Informatica,
corso Svizzera 185, 10149 Torino, Italy

Abstract

real logic programmers normally use cut (!), effective learning procedure logic
programs able deal it. cut predicate procedural
meaning, clauses containing cut cannot learned using extensional evaluation method,
done learning systems. hand, searching space possible
programs (instead space independent clauses) unfeasible. alternative solution
generate first candidate base program covers positive examples,
make consistent inserting cut appropriate. problem learning programs
cut investigated seems natural reasonable
approach. generalize scheme investigate diculties arise.
major shortcomings actually caused, general, need intensional evaluation.
conclusion, analysis paper suggests, precise technical grounds,
learning cut dicult, current induction techniques probably restricted
purely declarative logic languages.

1. Introduction

Much recent research AI Machine Learning addressing problem learning
relations examples, especially title Inductive Logic Programming (Muggleton, 1991). One goal line research, although certainly one,
inductive synthesis logic programs. generally, interested construction
program development tools based Machine Learning techniques. techniques
include ecient algorithms induction logical descriptions recursive relations.
However, real logic programs contain features purely logical, notably
cut (!) predicate. problem learning programs cut studied
Inductive Logic Programming, paper analyzes diculties involved.

1.1 Learn Programs Cut?

two main motivations learning logic programs cut:
1. ILP provide practical tools developing logic programs, context
general program development methodology (e.g., (Bergadano, 1993b)); real
size logic programs normally contain cut, learning cut important creating
integrated Software Engineering framework.

c 1993 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.

fiBergadano, Gunetti, & Trinchero

2. Extensive use cut make programs sensibly shorter, diculty learning
given logic program much related length.
objectives, need cuts make programs
ecient without changing input-output behavior (\green cuts"), also cuts
eliminate possible computed results (\red cuts"). Red cuts sometimes considered
bad programming style, often useful. Moreover, red cuts effective
making programs shorter. Green cuts also important, less controversial.
correct program inferred via inductive methods, could made ecient
insertion green cuts, either manually means automated program
transformation techniques (Lau & Clement, 1993).

1.2 Standard Approaches Cannot Used?
Machine Learning algorithms generate rules clauses one time independently
other: rule useful (it covers positive example) correct (it
cover negative example), added description program
generated, positive examples covered. means searching
space possible clauses, without backtracking. obviously great advantage,
programs sets clauses, therefore space possible programs exponentially
larger.
one principle allows simplification problem extensional
evaluation possible clauses, used determine whether clause C covers example
e. fact clause C covers example e used approximation
fact logic program containing C derives e. Consider, instance, clause C =
\p(X,Y) ff", suppose example e p(a,b). order see whether C covers e,
extensionality principle makes us evaluate literal ff true matches
given positive example. instance, ff = q(X,Z) ^ p(Z,Y), example p(a,b)
extensionally covered iff ground term c q(a,c) p(c,b) given
positive examples. particular, order obtain truth value p(c,b),
need call clauses learned previously. reason, determining
whether C covers e depends C positive examples. Therefore, learning
system decide whether accept C part final program P independently
clauses P contain.
extensionality principle found Foil (Quinlan, 1990) derivatives,
also used bottom-up methods Golem (Muggleton & Feng, 1990). Shapiro's MIS
system (Shapiro, 1983) uses refining clauses, although backtracing
inconsistencies. also used extensional evaluation clauses FILP system
(Bergadano & Gunetti, 1993).
learning programs cut, clauses longer independent standalone extensional evaluation meaningless. cut predicate evaluated, possible clauses proving goal ignored. changes meaning
clauses. Even clause extensionally covers example e, may case
final program derive e, derivation paths eliminated
evaluation cut predicate.
92

fiThe Difficulties Learning Logic Programs Cut

However, exhaustive search space programs prohibitive. Learning methods,
even based extensionality, often considered inecient sucient prior information
available; searching sets clauses exponentially worse. would amount
brute-force enumeration possible logic programs containing cut, program
consistent given examples found.

1.3 Alternative Method?

Cut eliminate computed results, i.e., adding cut program,
may case example longer derived. observation suggests general
learning strategy: base program P induced standard techniques, given positive
maybe negative examples, remaining negative examples ruled
inserting cut clause P. Obviously, inserting cut, must make sure
positive examples may still derived.
Given present technology discussion above, seems viable
path possible solution. Using standard techniques, base program P would generated one clause time, positive examples extensionally covered. However,
think view restrictive, programs derive given positive
examples, although cover extensionally (Bergadano, 1993a; DeRaedt,
Lavrac, & Dzeroski, 1993). generally, consider traces positive examples:

Definition 1 Given hypothesis space possible clauses, example e
`

e, set clauses TS used derivation e called trace e.

use candidate base program P subset union
traces positive examples. PS extensionally covers positive examples,
also union traces, converse always true. candidate
program generated, attempt made insert cuts negative examples
derived. successful, solution, otherwise, backtrack another
candidate base program. analyze many problems inherent learning cut
class trace-based learning methods, but, discuss later (Section 4),
problems need faced restrictive framework extensional evaluation.
words, even choose learn base program P extensionally,
try make consistent using cut, computational problems would still arise.
main difference standard approaches based extensionality allow
backtracking guarantee correct solution found (Bergadano, 1993a).
far computational complexity concerned, trace-based methods complexity
standing search space independent clauses (for extensional methods)
exhaustive search space possible programs. need following:

Definition 2 Given hypothesis space S, depth example e maximum

number clauses successfully used derivation e.

example, list processing domain, contains recursive calls
type \P([HjT]) :- ..., P(T), ..." depth example P(L) length L.
practical program induction tasks, often case depth example
93

fiBergadano, Gunetti, & Trinchero

related complexity, hypothesis space S. maximum depth
given positive examples, complexity trace-based methods order
jS jmd, extensional methods enumerate possible clauses complexity
linear jS j, enumerating possible programs exponential jS j.

2. Simple Induction Procedure
trace-based induction procedure analyze takes input finite set clauses
set positive negative examples E+ E- tries find subset
derives positive examples none negative examples. every
positive example e+ 2 E+, assume large enough derive it. Moreover,
assume clauses attened1 . case, clauses attened
preprocessing step.
consider one possible proof ` e+, build intermediate program
containing trace derivation. done positive examples,
corresponding traces merged. Every time updated, checked
negative examples. derived T, cut (!) inserted antecedents
clauses T, consistent program found, exists. case,
procedure backtracks different proof ` e+. algorithm informally
described follows:
input: set clauses
set positive examples E+
set negative examples ES := atten(S)
;
positive example e+ 2 E+
find T1 T1 `SLD e+ (backtracking point 1)
[ T1
derives negative example e- trycut(T,e-)
trycut(T,e-) fails backtrack
output clauses listed
trycut(T,e-):
insert ! somewhere (backtracking point 2)
1. previously covered positive examples still derived T,
2. 6`SLD e-

complexity adding cut somewhere trace T, negative example eis longer derived, obviously depends size T. size depends
depth positive examples, size hypothesis space S. Although
1. clause flattened contain functional symbol. Given un attened clause, alway
possible atten (by turning functions new predicates additional argument representing
result function) vice versa (Rouveirol, press).

94

fiThe Difficulties Learning Logic Programs Cut

clever ways devised, based particular example e-, propose
simple enumerative technique implementation described Appendix.

3. Example: Simplifying List

section show example use induction procedure learn logic
program \simplify ". Simplify takes input list whose members may lists,
transforms \ attened" list single members, containing repetitions
lists members. program appears exercise number 25 (Coelho & Cotta, 1988),
composed nine clauses (plus clauses append member); six
recursive, one doubly-recursive cut extensively used. Even simplify
complex logic program, complex usual ILP test cases. instance,
quicksort partition program, often used, composed five
clauses (plus append), three recursive. Moreover, note
conciseness simplify essentially due extensive use cut. Without cut,
program would much longer. general, longer logic program, dicult
learn it.
consequence, start relatively strong bias; suppose following
hypothesis space N=8449 possible clauses defined user:



clause \simplify(L,NL) :- atten(L,L1), remove(L1,NL)."
clauses whose head \ atten(X,L)" whose body composed conjunction
following literals:
head(X,H), tail(X,L1), equal(X,[L1,T]), null(T), null(H), null(L1), equal(X,[L1]),
atten(H,X1), atten(L1,X2),
append(X1,X2,L), assign(X1,L), assign(X2,L), list(X,L).



clauses whose head \remove(IL,OL)" whose body composed conjunction following literals:
cons(X,N,OL), null(IL), assign([],OL),
head(IL,X), tail(IL,L), member(X,L), remove(L,OL), remove(L,N).



correct clauses null, head, tail, equal, assign, member, append given:
null([]).
head([Hj ],H).
tail([ jT],T).
equal(X,X).
assign(X,X).
member(X,[Xj ]).
member(X,[ jT]) :- member(X,T).
95

fiBergadano, Gunetti, & Trinchero

append([],Z,Z).
append([HjX],Y,[HjZ]) :- append(X,Y,Z).
using various kinds constraints, initial number clauses strongly reduced.
Possible constraints following:
output produced must instantiated again. means
variable cannot occur output antecedent once.
Inputs must used: input variables head clause must also occur
antecedent.
conjunctions literals ruled never true, e.g.
null(IL)^head(IL,X).
applying various combination constraints possible strongly restrict
initial hypothesis space, given input learning procedure. set
positive negative examples used learning task is:
simplify pos([[[],[b,a,a]],[]],[b,a]). remove pos([a,a],[a]).
(simplify neg([[[],[b,a,a]],[]],X),not equal(X,[b,a])).
simplify neg([[a,b,a],[]],[a,[b,a]]). remove neg([a,a],[a,a]).
Note define negative examples simplify examples
input given positive example different output, instance simplify neg([[[],[b,a,a]],[]],[a,b]). Obviously, also possible give negative examples
normal ground literals. learning procedure outputs program simplify reported
below, turns substantially equivalent one described (Coelho &
Cotta, 1988) (we kept clauses un attened).
simplify(L,NL) :- atten(L,L1), remove(L1,NL).
atten(X,L) :- equal(X,[L1,T]), null(T), !, atten(L1,X2), assign(X2,L).
atten(X,L) :- head(X,H), tail(X,L1), null(H), !, atten(L1,X2), assign(X2,L).
atten(X,L) :- equal(X,[L1]), !, atten(L1,X2), assign(X2,L).
atten(X,L) :- head(X,H), tail(X,L1), !,
atten(H,X1), !, atten(L1,X2), append(X1,X2,L).
atten(X,L) :- list(X,L).
remove(IL,OL) :- head(IL,X), tail(IL,L), member(X,L), !, remove(L,OL).
remove(IL,OL) :- head(IL,X), tail(IL,L), remove(L,N), cons(X,N,OL).
remove(IL,OL) :- null(IL), assign([],OL).
learning task takes 44 seconds implementation. However, obtained
special conditions, thoroughly discussed next sections:
constraints listed applied, final hypothesis space
reduced less one hundred clauses.
96

fiThe Difficulties Learning Logic Programs Cut





Clauses hypothesis space generated correct order, must appear
final program. Moreover, literals clause correct position.
important, since logic program cut relative position clauses
literals significant. consequence, learn simplify without test
different clause literal orderings (see subsections 4.2 4.5).
tell learning procedure use two cuts per clause. seems
quite intuitive constraint since, fact, many classical logic programs
one cut per clause (see subsections 4.1 5.4).

4. Problems

Experiments induction procedure shown many problems arise
learning logic programs containing cut. following, analyze problems,
major contribution present paper. cut cannot evaluated extensionally,
analysis general, depend specific induction method adopted.
possible partial solutions discussed Section 5.

4.1 Problem 1: Intensional Evaluation, Backtracking Cut

learning procedure Section 2 simple, inecient. However,
believe common every intensional method, clauses cannot learned
independently one another. consequence, backtracking cannot avoided
impact complexity learning process. Moreover, cut must
added every trace covering negative examples. constraints force,
range one cut whole trace cut two literals clause
trace. Clearly, number possibilities exponential number literals
trace. Fortunately, number usually much smaller size hypothesis
space, depends depth positive examples.
However, backtracking also advantages; particular, useful search
alternative solutions. alternative programs confronted basis
required characteristic, simplicity eciency. example, using backtracking
discovered version simplify equivalent one given without cut predicate
two recursive calls fourth clause flatten.

4.2 Problem 2: Ordering Clauses Trace

logic program containing cut, mutual position clauses significant, different ordering lead different (perhaps wrong) behavior program. example,
following program intersection:

c1) int(X,S2,Y) :- null(X), null(Y).
c2) int(X,S2,Y) :- head(X,H), tail(X,Tail), member(H,S2), !, int(Tail,S2,S), cons(H,S,Y).
c3) int(X,S2,Y) :- head(X,H), tail(X,Tail), int(Tail,S2,Y).
behaves correctly c2 comes c3. Suppose hypothesis space given input
induction procedure consists three clauses above, c3
97

fiBergadano, Gunetti, & Trinchero

c2. :int([a],[a],[]) given negative example, learning task fails,
clauses c1 c3 derive example.

words, learning program containing cut means learn set
clauses, also specific ordering clauses. terms induction procedure
means every trace covering negative example, must check
every position inserting cuts, also every possible clause ordering trace.
\generate test" behavior dicult implement, dramatically decrease
performance learning task. worst case possible permutations must
generated checked, requires time proportional (md)! trace md
clauses2 .
necessity test different permutations clauses trace primary source
ineciency learning programs cut, probably dicult problem
solve.

4.3 Problem 3: Kinds Given Examples

induction procedure able learn programs traces, i.e. every
clause program used derive least one positive example. learning definite
clauses, problem, derivation monotone, every program P,
complete consistent w.r.t. given examples, program P0P also
complete consistent trace3. hand, learning clauses containing cut, may happen complete consistent program(s) hypothesis
space neither trace, contains subset. derivation longer
monotone case negative example derived set clauses,
superset them, following simple example:
= fsum(A,B,C) :- A>0, !, A-1, sum(M,B,N), C N+1.
sum(A,B,C) :- C B.g
sum pos(0,2,2), sum neg(2,2,2).
two clauses hypothesis space represent complete consistent program
given examples, procedure unable learn it. Observe negative
example derived second clause, trace positive example,
first second together.
problem avoided require that, every negative example, corresponding positive example input given (in case, example
required sum pos(2,2,4)). way, complete program exists hypothesis
space, also trace, learned. made consistent using
cut, order rule derivation negative examples. constraint positive
negative examples seems quite intuitive. fact, writing program,
2. must noted learning programs two different predicates, j k clauses
respectively (that is, md = j +k), consider (j +k)! different programs,
j !+k!. better if, inside program, known non-recursive clauses fixed
position, put recursive clauses.
3. learned program P complete derives given positive examples, consistent
derive given negative examples

98

fiThe Difficulties Learning Logic Programs Cut

programmer usually thinks terms program compute given inputs,
tries avoid wrong computations inputs.

4.4 Problem 4: Ordering Given Examples
learning clauses cut, even order positive examples may significant.
example above, sum pos(2,2,4) comes sum pos(0,2,2) learning task
fails learn correct program sum, cannot find program consistent w.r.t.
first positive example negative one(s).
general, given set positive examples problem remedied
testing different example orderings. Again, worst case k! different orderings set
k positive examples must checked. Moreover, situations favorable ordering
exist. Consider following hypothesis space:

c1) int(X,Y,W) :- head(X,A), tail(X,B), notmember(A,Y), int(B,Y,W).
c2) int(X,Y,W) :- head(X,A), tail(X,B), notmember(A,Y), !, int(B,Y,W).
c3) int(X,Y,Z) :- head(X,A), tail(X,B), int(B,Y,W), cons(A,W,Z).
c4) int(X,Y,Z) :- head(X,A), tail(X,B), !, int(B,Y,W), cons(A,W,Z).
c5) int(X,Y,Z) :- null(Z).
together set examples:

e1 ) int pos([a],[b],[ ]).
e2 ) int pos([a],[a],[a]).
e3 ) int neg([a],[b],[a]).
e4 ) int neg([a],[a],[ ]).
induction procedure able find correct program ordering
two positive examples, even program exist ([c2,c4,c5]). program
union two traces: [c2,c5], covers e1 , [c4,c5], covers e2 . traces
inconsistent, first covers e4 , second covers e3 . problem
remedied positive examples derived check negative
examples done.
However, case loss eciency, inconsistent
traces discarded end. words, would need learn program
covering positive examples, make consistent using cut reordering clauses. Moreover, way make program consistent using cut
reorderings. consequence, time used build program wasted.
example, suppose given following hypothesis space:

c01) int(X,Y,Z) :- head(X,A), tail(X,B), int(B,Y,W), cons(A,W,Z).
c02) int(X,Y,Z) :- null(X), null(Z).
c03) int(X,Y,Z) :- null(Z).
99

fiBergadano, Gunetti, & Trinchero

examples:

e01) int pos([a],[a],[a]).
e02 ) int pos([a,b],[c],[]).
e03 ) int neg([a],[b],[a]).
learn trace [c01,c02] e01 trace [c03] e02 . [c01,c02,c03] covers
e03, way make consistent using cut reordering clauses. fact,
first partial trace responsible inconsistency, hence time used learn
[c03] totally wasted.
also possible understand need attened clauses. Consider following program intersection, equivalent [c2,c4,c5], three clauses
un attened:

u2 ) int([AjB],Y,W) :- notmember(A,Y), !, int(B,Y,W).
u4 ) int([AjB],Y,[AjW]) :- !, int(B,Y,W).
u5 ) int( , ,[]).
Now, program covers int neg([a],[a],[]), i.e. [u2 ,u4,u5 ] ` int([a],[a],[]). fact, clause
u2 fails example member [a]. Clause u4 fails empty
list cannot matched [AjW]. clause u5 succeeds arguments match
negative example. consequence, program would rejected
induction procedure.
problem that, use un attened clauses, may happen clause body
evaluated example match head clause. consequence,
possible cuts clause evaluated cannot uence behavior entire
program. example, cut clause u4 effect output argument
int([a],[a],[]) match [AjW], body u4 evaluated all. u5
fired negative example covered. attened version, clause c4 fails
cons(a,[],[]) reached, point cut force clause c5 cannot activated.
Note program [u2 ,u4,u5] behaves correctly query int([a],[a],X), gives X=[a]
output.

4.5 Problem 5: Ordering Literals

Even relative position literals cut clause significant. Consider
correct program intersection ([c2,c4,c5]), c4 modified putting
cons literal front antecedent:

c04) int(X,Y,Z) :- cons(A,W,Z), head(X,A), tail(X,B), int(B,Y,W).
Then, way get correct program intersection using clause. rule
negative example int neg([a],[a],[]) must put cut cons predicate,
order prevent activation c5. But, then, positive examples longer
covered, int pos([a],[],[]). fact, wrong behavior every time clause c04
100

fiThe Difficulties Learning Logic Programs Cut

called fails, since prevents activation c5 . general, problem cannot
avoided even reordering clauses: put c04 c2 c5 , int neg([a],[a],[])
covered. consequence, also test every possible permutation literals
every clause candidate program.

5. Situations Learning Cut still Practical
analysis, learning cut appears dicult since, general, learning
procedure able backtrack candidate base programs (e.g., traces),
position cut(s) program, order clauses program,
order literals clauses order given positive examples. However,
spotted general conditions learning cut could still practical. Clearly,
conditions cannot final solution learning cut, but, applicable, alleviate
computational problems task.

5.1 Small Hypothesis Space

First all, restricted hypothesis space necessary. clauses cannot learned independently one another, small hypothesis space would help limit backtracking
required candidate traces (problem 1). Moreover, even number clauses trace
would probably smaller, hence also number different permutations
number different positions inserted cuts (problems 2 1). small trace would also
slight positive impact need test different literal orderings clauses
(problem 5).
general, many kinds constraints applied keep hypothesis space small,
ij-determinism (Muggleton & Feng, 1990), rule sets schemata (Kietz & Wrobel,
1991; Bergadano & Gunetti, 1993), determinations (Russell, 1988), locality (Cohen, 1993),
etc (in fact, restrictions others, listed Section 3,
available actual implementation procedure - see Appendix4 ). Moreover,
candidate recursive clauses must designed infinite chains recursive calls
take place (Bergadano & Gunetti, 1993) (otherwise learning task could
non-terminating). general, number possible recursive calls must kept small,
order avoid much backtracking searching possible traces. However, general
constraints may sucient. hypothesis space must designed carefully
beginning, dicult. example learning simplify initial
hypothesis space \only" 8449 clauses obtained specifying set required
predicates, even variables occurring every literal.
clauses cannot learned independently, experiments shown us dramatic improvement learning task obtained generating clauses
hypothesis space recursive clauses, general complex clauses, taken
consideration simpler non-recursive ones. Since simpler non recursive
clauses require less time evaluated, small impact learning time.
Moreover, learning simpler clauses (i.e. shorter) also alleviates problem 5.
4. found constraints particularly useful. using often able restrict hypothesis
space one order magnitude without ruling possible solution.

101

fiBergadano, Gunetti, & Trinchero

Finally, must noted induction procedure necessarily require
hypothesis space possible clauses represented explicitly. learning task could
start empty set implicit description hypothesis space, example
one given Section 3. positive example cannot derived S, new clause
asked clause generator added S. step repeated example
derivable updated S, learning task proceed normally.

5.2 Simple Examples

Another improvement achieved using examples simple possible.
fact, example may involve recursive call potentially responsible
activation corresponding clauses hypothesis space. complex
example, larger number consecutive recursive activations clauses larger
number traces considered backtracking (problem 1). instance, learn
append relation, may sucient use example like append([a],[b],[a,b]) instead
one like append([a,b,c,d],[b],[a,b,c,d,b]). Since simple examples would probably require
smaller number different clauses derived, would result smaller traces,
alleviating problem permutation clauses literals trace (problems 2 5)
decreasing number positions cuts (problem 1).

5.3 Small Number Examples

Since candidate program formed taking union partial traces learned single
examples, want small trace (problems 2 5) must use examples
possible, still completely describing required concept. words,
avoid redundant information. example, want learn program append,
normally sucient use one two positive examples append([a],[b],[a,b])
append([c],[d],[c,d]). Obviously may happen different examples derived
set clauses, case final program change.
check possible orderings set positive examples, small number
examples also solution problem 4. Fortunately, experiments shown normally
positive examples needed learn program, hence corresponding
number different orderings is, case, small number. Moreover, since
method positive example sucient learn clauses necessary derive it,
time complete program learned using one well chosen example.
example found (as case learning task section 3, one
example simplify one remove given), computational problem testing
different example orderings automatically solved.
However, must noted that, general, small number examples may
sucient, except simple programs. fact, want learn logic programs
member, append, reverse on, example involving recursion
sucient. complex programs choice may trivial. example,
procedure able learn quicksort (plus partition) program one \good"
example. one know quicksort partition work, likely
provide example allowing learn partial description partition.
particularly clear example simplify . used positive example
102

fiThe Difficulties Learning Logic Programs Cut

simplify pos([[[],[b,a,a]]],[b,a]) (which close one effectively used), first clause
flatten would learned. words, give examples must give
good examples, often possible mind (at least partially
informal way) target program. Moreover, complex programs, good examples
mean complex examples, contrast previous requirement.
studies learning good examples refer reader work Ling (1991)
Aha, Ling, Matwin Lapointe (1993).

5.4 Constrained Positions Cut Literals

Experiments shown practical allow learning procedure test
possible positions cut trace, even able keep number clauses
trace small. user must able indicate positions cut allowed
occur, e.g., beginning clause body, recursive call. case, many
alternative programs cut automatically ruled thus tested
negative examples. may also useful limit maximum number cuts
per clause per trace. example, time one cut per clause sucient
learn correct program. actual implementation procedure, fact
possible specify exact position cut w.r.t. literal group literals within
clause hypothesis space, information known.
eliminate need test different ordering literals (problem 5), may also
impose particular global order, must maintained every clause hypothesis
space. However requires deep knowledge program want, otherwise
(or even all) solutions lost. Moreover, solution contrast use
constrained positions cut, since solution program particular literal ordering
particular positions cuts may exist.

6. Conclusion

induction procedure based intensional evaluation clauses. Since cut
predicate declarative meaning, believe intensional evaluation clauses
cannot abandoned, independently kind learning method adopted.
decrease performance learning task, compared extensional methods,
examine clauses one time without backtracking. However, computational problems
outlined Section 4 remain even choose learn complete program extensionally,
try make consistent inserting cut. difference
backtracking (problem 1), situation probably worse, since extensional
methods fail learn complete program even exists hypothesis space.
(Bergadano, 1993a).
Even ability learn clauses containing procedural predicates like cut seems
fundamental learning \real" logic programs, particular short ecient programs,
many problems uencing complexity learning task must faced. include
number relative ordering clauses literals hypothesis space, kind
relative ordering given examples. problems seem related need
intensional evaluation clauses general, particular learning method
adopted. Even alleviate problems, seems necessary know lot
103

fiBergadano, Gunetti, & Trinchero

target program. alternative solution simply ignore problems. is,
avoid testing different clause and/or literal and/or example orderings. Clearly,
way learning process become feasible, fail find solution even
exists. However, many ILP systems (such Foil) adopt \incomplete-but-fast"
approach, guided heuristic information.
consequence, view results presented paper as, least partially, negative. problems raised appear computationally dicult, suggest attention
restricted purely declarative logic languages, are, case, suciently
expressive.

Acknowledgements
work part supported BRA ESPRIT project 6020 Inductive Logic Programming.

Appendix
induction procedure Section 2 written C-prolog (interpreted) runs
SUNsparcstation 1. planning translate QUINTUS prolog. Appendix
contains simplified description implementation. preliminary step, order
record trace clauses deriving positive example e+, every clause hypothesis
space5 must numbered modified adding body two literals. first
one, allowed(n,m) used activate clauses must checked
negative examples. second one, marker(n), used remember clause number n
successfully used deriving e+. Hence, general, clause hypothesis
space takes following form:

P (X1 ,: : : ,Xm) :- allowed(n,m), ,marker(n).
actual body clause, n number clause set
number used deal cuts. every clause n, one without cut augmented
allowed(n,0), containing cut somewhere body augmented
allowed(n,1), allowed(n,2), ..., on. Moreover, every augmented clause above,
fact \alt(n,m)." inserted S, order implement enumeration mechanism.
simplified (but running) version learning algorithm reported below.
algorithm, output, any, variable Trace containing list (numbers the)
clauses representing learned program P. using backtracking mechanism Prolog,
one solution (trace) found. assume two predicates listpositive
listnegative build list given positive negative examples, respectively.
consult(file containing set clauses S).
5. assume clauses hypothesis space attened

104

fiThe Difficulties Learning Logic Programs Cut

allowed(X,0).
marker(X) :- assert(trace(X)).
marker(X) :- retract(trace(X)), !, fail.
main :- listpositive(Posexamplelist), tracer([],Posexamplelist,Trace).
tracer(Covered,[ExamplejCdr],Trace) :- Example, /? backtracking point 1 ?/
setof(L,trace(L),Trace1),
notneg(Trace1,[ExamplejCovered],Cdr),
tracer([ExamplejCovered],Cdr,Trace).
tracer( ,[],Trace) :- setof((I,J),allowed(I,J),Trace), asserta((marker(X) :- true, !)).
assertem([]).
assertem([IjCdr]) :- alt(I,J), backassert(allowed(I,J)), assertem(Cdr).
prep(T) :- retract(allowed(X,0)), assertem(T).
backassert(X) :- assert(X).
backassert(X) :- retract(X), !, fail.
resetallowed([]) :- !.
resetallowed( ) :- abolish(allowed,2), assert(allowed(X,0)), !.
notneg(T,Covered,Remaining) :- listnegative([]).
notneg(T,Covered,Remaining) :- listnegative(Negexamplelist),
asserta((marker(X) :- true,!)),
prep(T), /? backtracking point 2 ?/
trypos(Covered), trynegs(Negexamplelist),
resetallowed(Remaining),
retract((marker(X) :- true,!)).
notneg(T,Covered,Remaining) :- resetallowed(Remaining),
retract((marker(X) :- true,!)), !, fail.
trypos([ExamplejCdr]) :- Example, !, trypos(Cdr).
trypos([]) :- !.
trynegs([ExamplejCdr]) :- Example,!,fail.
trynegs([ExamplejCdr]) :- trynegs(Cdr).
trynegs([]) :- !.
Actually, complete implementation complex, also order achieve greater
eciency. behavior learning task quite simple. Initially, set clauses
read Prolog interpreter, together learning algorithm. learning
task started calling predicate main. list positive examples formed
105

fiBergadano, Gunetti, & Trinchero

tracer procedure called list. every positive example, tracer calls
example itself, firing clauses may resolved example.
Observe that, initially, allowed(X,0) predicate asserted database: way
clauses containing cut allowed used (this clauses cut
employed negative example derived). Then, trace, any, (the numbers
associated to) clauses successfully used derivation example built, using
setof predicate.
trace added traces found previous examples, result
checked set negative examples calling notneg procedure. notneg
fail (i.e. negative examples covered trace) new positive
example taken consideration. Otherwise notneg modifies trace cut
tests again. also fails, backtracking occurs new trace current example
(and possibly previous ones) searched for.
notneg procedure works follows. First, clauses trace allowed
checked negative examples, retracting allowed(X,0) clause
asserting allowed(n,0) n-th clause (without cut) trace. done
prep assertem predicates. list negative examples formed
check derived clauses trace. least one negative example
covered, (i.e., trynegs fails) backtrack prep procedure (backtracking point
2) clause trace substituted equivalent one cut inserted
somewhere (or different position). correct program found way
trying possible alternatives (i.e. using cut possible ways), notneg fails,
backtracking backtracking point 1 occurs, another trace searched for. Otherwise,
clauses without cut reactivated asserting allowed(X,0), next
positive example considered. Note trypos used notneg verify modified
trace still derives set positive examples derived initially. possibility substitute
clauses current trace others cut inserted somewhere achieved
alt predicate assertem procedure. Finally, note simplified version
learning procedure able generate test different orderings clauses
trace different ordering literals clause, use different orderings
set positive examples.
order derive positive examples check negative ones
(see subsection 4.4), must change first clause tracer procedure into:
tracer([Pos1, ... ,Posn]):-Pos1, ... ,Posn, setof(L,trace(L),T), notneg(T).
actual implementation induction procedure available ftp.
information contact gunetti@di.unito.it.

References

Aha, D., Ling, C., Matwin, S., & Lapointe, S. (1993). Learning Singly Recursive Relations
Small Datasets. Proceedings IJCAI-93 workshop ILP.
Bergadano, F. (1993a). Inductive database relations. IEEE Transactions Data
Knowledge Engineering, 5 (6).
106

fiThe Difficulties Learning Logic Programs Cut

Bergadano, F. (1993b). Test Case Generation Means Learning Techniques. Proceedings ACM SIGSOFT-93.
Bergadano, F., & Gunetti, D. (1993). interactive system learn functional logic programs. Proceedings IJCAI-93.
Coelho, H., & Cotta, J. C. (1988). Prolog Example: learn teach use it. Berlin:
Springer-Verlag.
Cohen, W. (1993). Rapid Prototyping ILP Systems Using Explicit Bias. Proceedings
IJCAI-93 workshop ILP.
DeRaedt, L., Lavrac, N., & Dzeroski, S. (1993). Multiple predicate learning. Proceedings
IJCAI-93.
Kietz, J. U., & Wrobel, S. (1991). Controlling Complexity Learning Logic
Syntactic Task-Oriented Models. Muggleton, S. (Ed.), Inductive Logic Programming. London: Academic Press.
Lau, K. K., & Clement, T. (Eds.). (1993). Logic Program Synthesis Transformation.
Berlin: Springer-Verlag.
Ling, X. C. (1991). Learning Good Examples. Proceedings IJCAI-91.
Muggleton, S. (Ed.). (1991). Inductive Logic Programming. London: Academic Press.
Muggleton, S., & Feng, C. (1990). Ecient Induction Logic Programs. Proceedings
first conference Algorithmic Learning Theory.
Quinlan, R. (1990). Learning Logical Definitions Relations. Machine Learning, 5,
239{266.
Rouveirol, C. (in press). Flattening: representation change generalization. Machine
Learning.
Russell, S. (1988). Tree-structured bias. Proceedings AAAI-88.
Shapiro, E. Y. (1983). Algorithmic Program Debugging. Cambridge, CA: MIT Press.

107

fiJournal Artificial Intelligence Research 1 (1994) 257-275

Submitted 11/93; published 3/94

Exploring Decision Forest: Empirical Investigation
Occam's Razor Decision Tree Induction
Patrick M. Murphy
Michael J. Pazzani

Department Information & Computer Science
University California, Irvine, CA 92717

pmurphy@ics.uci.edu
pazzani@ics.uci.edu

Abstract

report series experiments decision trees consistent
training data constructed. experiments run gain understanding
properties set consistent decision trees factors affect accuracy
individual trees. particular, investigated relationship size
decision tree consistent training data accuracy tree test data.
experiments performed massively parallel Maspar computer. results
experiments several artificial two real world problems indicate that, many
problems investigated, smaller consistent decision trees average less accurate
average accuracy slightly larger trees.
1. Introduction

top-down induction decision trees approach machine learning
used variety real world tasks. Decision trees well-suited tasks since
scale fairly well number training examples number features,
represent complex concepts representation fairly easy people understand.
Decision tree induction algorithms (Breiman, Friedman, Olshen, & Stone, 1984; Quinlan, 1986; Fayyad & Irani, 1992) typically operate choosing feature partitions
training data according evaluation function (e.g., purity resulting partitions). Partitions partitioned recursively stopping criterion
reached (e.g., partitions contain training examples single class). Nearly decision
tree induction algorithms create single decision tree based upon local information
well feature partitions training data. However, decision tree one set
decision trees consistent training data. paper, experimentally examine
properties set consistent decision trees. call set decision trees
consistent training data decision forest.
experiments run several artificial concepts know correct
answer two naturally occurring databases real world tasks available UCI
Machine Learning Repository (Murphy & Aha, 1994) correct answer
known. goal experiments gain insight factors
size consistent decision tree related error rate classifying unseen test
instances. Decision tree learners, well learners, attempt produce

c 1994 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.

fiMurphy & Pazzani
smallest consistent hypothesis.1 Occam's razor often used justify bias. Here,
experimentally evaluate bias towards simplicity investigating relationship
size consistent decision tree accuracy. average error
decision trees N test nodes less average error decision trees size N +
(for > 0), appropriate bias learner attempting minimize average error would
return smallest decision tree find within resource constraints.
paper, restrict attention decision trees consistent
training data ignore issues pruning trade consistency training
data simplicity hypothesis. purposes paper, consistent
decision tree one correctly classifies every training example.2 also place two
additional constraints decision trees. First, discriminator pass instances
single branch. insures test made decision tree partitions training
data. Second, training instances node class, additional
discriminations made. case, leaf formed class label specified class
instances leaf. two constraints added insure decision
trees analyzed experiments correspond could formed top
decision tree induction algorithms. paper, investigate problems
continuous-valued features missing feature values.
Section 2 (and appendix), report initial exploratory experiments
smallest consistent decision trees tend less accurate average
accuracy slightly larger. Section 3 provides results additional experiments
address issue. Section 4 addresses implication findings policy learner
take deciding many consistent hypotheses prefer. Section
5 relates work previous empirical theoretical research.
2. Initial Experiments

investigate relationship various tree characteristics error. particular, look node cardinality (i.e., number internal nodes tree)
leaf cardinality (i.e., total number leaves tree).
noted even using powerful massively parallel computer,
choice problems severely constrained computational complexity task.
number trees node cardinality might generated O(dc )
number discriminators c node cardinality. Even massively parallel
computer, precluded use problems many features continuous-valued
features.
first experiment considered learning training data 5 boolean
features. concept learned XY Z _ AB . concept chosen
moderate complexity, requiring decision tree least 8 nodes represent correctly.
5 boolean features, smallest concept (e.g., True) would require 0 test nodes
largest (e.g., parity) would require 31.
1. say \attempt produce smallest consistent hypothesis" systems use form
limited look-ahead greedy search. result, smallest consistent tree rarely found.
2. artificial natural problems study consistent training sets.

258

fiExploring Decision Forest

0.6

100

0.5

80

Error

0.4

60

0.3
40

0.2
Error
Trials

0.1

20

0.0

Number Trials

ran 100 trials, creating training set randomly choosing without replacement
20 32 possible training examples using remaining 12 examples test
set. trial, every consistent decision tree created, computed average
error rate made trees node cardinality. Figure 1 plots mean 95%
confidence interval average errors function node cardinality. Figure 1
also plots number trials least one decision tree given node cardinality
consistent training data.

0
0

2

4

6
8 10 12 14
Node Cardinality

16

18

20

Figure 1. average error 100 trials function node cardinality number
trials node cardinality.
node cardinality 7 node cardinality 16, monotonic increase error
increasing node cardinality. range 2 3 nodes, error varied;
however little evidence error values based 2
1 trials, respectively. range node cardinalities 4 7, average error
definitely monotonically increasing function node cardinality. seen curve,
5 node trees average accurate 4 node trees, 7 node trees
average accurate trees 6 nodes. last result somewhat surprising
since one gets impression reading machine learning literature (Muggleton,
Srinivasan, & Bain, 1992) smaller hypothesis (i.e., one provides
compression data (Rissanen, 1978)) likely accurate. explore
issue detail Section 3. Appendix 1 presents data showing result
unique particular concept. final, interesting finding explore
paper large node cardinalities, error begins decrease
node cardinality increases.
Table 1 lists average number consistent trees node cardinality
average number correct trees (i.e., trees consistent training data make
errors unseen test examples). correct trees fewer 8 nodes,
since least 8 nodes required represent concept. Clearly, since many
trees consistent training data, learner needs policy decide tree
return. return issue Section 4.
259

fiMurphy & Pazzani
Nodes

2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19

Number
Number
Consistent Trees Correct Trees
2.0
0.0
4.0
0.0
3.3
0.0
12.3
0.0
27.6
0.0
117.1
0.0
377.0
17.8
879.4
37.8
1799.9
50.2
3097.8
41.6
4383.0
95.4
5068.9
66.6
4828.3
37.7
3631.5
31.3
1910.6
14.8
854.4
4.0
308.6
3.6
113.8
0.0

Table 1. average number trees consistent 20 training examples XY Z_AB
concept.
3. Experimentation

problems studied, found average, smallest decision trees
consistent training data error unseen examples slightly larger
trees. ran additional experiments make sure result artifact
experimental methodology used, reported next sections.
3.1 Representative Train/Test Partitions

One possible explanation finding previous section smaller decision
trees formed unrepresentative samples. example, 11 positive 21
negative examples concept XY Z _ AB . examples training
set negative, small tree may learned would probably poorly
mostly positive test set. insure results caused unrepresentative
training sets, eliminated training data reasonably representative.
11 probability training instance positive, representative
particular, since 32
training set
7 positive instances. Since one standard deviation
q size11 20 would
11
would 20 3 32 3 (1 0 32 ), eliminated analysis training sets greater
8 fewer 5 positive instances. Similarly, 0.5 probability
binary feature takes true value, eliminated analysis training data
feature true greater 13 fewer 7 instances. Figure 2 based
260

fiExploring Decision Forest

0.6

100

0.5

80

Error

0.4

60

0.3
40

0.2
Error
Trials

0.1

20

0.0

Number Trials

69 100 trials XY Z _ AB concept met representative test. Notice
two trials formed 2 3 node trees removed. Even
representative training sets considered, average error trees size 4
greater average error size 5 trees.

0
0

2

4

6
8 10 12 14
Node Cardinality

16

18

20

Figure 2. Error rate consistent trees representative training sets function
node cardinality.
regrouping results 100 trials XY Z _AB concept trials
minimum-sized trees grouped together, set five curves, associated
subgroup, formed (Figure 3). intent grouping allow us determine
whether minimum-sized trees given trial average accurate
larger trees.
0.6
0.5
Error

0.4
0.3
Min. Tree Size = 2
Min. Tree Size = 4
Min. Tree Size = 5
Min. Tree Size = 6
Min. Tree Size = 7

0.2
0.1
0.0
0

2

4

6

8 10 12 14
Node Cardinality

16

18

Figure 3. Error function node cardinality
grouped minimum-sized trees built.

20

XY Z _ AB concept first

Note Figure 3, minimum tree sizes, error monotonically increasing function node cardinality. Furthermore, average error smallest trees found
accurate smallest tree 4 6 nodes. addition, regardless

261

fiMurphy & Pazzani

0.6

100

0.5

80

Error

0.4

60

0.3
40

0.2

Error
Trials

0.1

20

0.0

Number Trials

size smallest tree found, average accuracy trees size 8 (the size
smallest correct tree) rarely minimum average error.
Another interesting finding becomes apparent way viewing data:
average error rates trees training sets allow creation smaller consistent trees
tends higher training sets form larger trees. example,
error rate training sets whose minimum-sized trees 4 nodes higher
error rate trials whose minimum-sized trees 7 nodes.

0
0

2

4

6
8 10 12 14
Node Cardinality

16

18

20

Figure 4. Error rate consistent trees 2 examples per leaf correct 8 node tree
function node cardinality.
definition representative used earlier section used global characteristics training data determine representativeness. Here, consider
detailed view representativeness takes structure correct concept account. unreasonable expect decision tree learner learn accurate concept
examples correspond leaves correct decision tree.
generate training data next experiment, first randomly selected one
72 trees 8 nodes consistent data. Next, leaf tree,
randomly selected two examples (if possible) include training set. leaf
one example, example included training set. Finally, randomly
selected remaining examples 20 training examples 12 test
examples. anticipated representative training sets formed manner,
small consistent trees would rare perhaps error rate would monotonically
increase node cardinality. However, results 100 trials, displayed Figure 4,
indicate general pattern before. particular, average error trees 7
nodes substantially less average error 6 nodes. Another experiment
one randomly selected example per leaf similar results.
3.2 Training Set Size Concept Complexity

minimum-sized decision tree concept XY Z _AB 8 tests 9 leaves. Since
correct tree provide much compression3 set 20 examples used induce
3. exact amount compression provided depends upon particular scheme chosen encoding
training data. See (Quinlan & Rivest, 1989; Wallace & Patrick, 1993) two schemes.

262

fiExploring Decision Forest
tree, one might argue sample used small complex concept.
Therefore, increased number training examples maximum possible. Figure
5 plots average error 32 trials formed decision trees consistent 31
examples. tree evaluated remaining unseen example. Figure 5 shows
smaller trees formed samples size 31 error slightly larger
trees. Since minimum correct decision tree 8 nodes consistent trees classify
31 training examples correctly, decision tree fewer 8 nodes classifies
test example incorrectly.
32
28

Error

0.8

Error
Trials

24
20
16
12
8
4
0

0.6
0.4
0.2
0.0
0

2

4

6

Number Trials

1.0

8 10 12 14 16 18 20 22 24 26
Node Cardinality

Figure 5. Error rate consistent trees leave-one-out testing function node
cardinality.
refute hypothesis results obtained far based using
small training set given concept complexity, considered two less complex
concepts. particular, investigated single attribute discrimination, four
irrelevant features (Figure 6) simple conjunction, AB three irrelevant features
(Figure 7).
0.6

100

Error

0.4

80

0.3
0.2

60
Error
Trials

0.1
0.0

Number Trials

0.5

40
0

2

4

6

8 10 12 14
Node Cardinality

16

18

20

Figure 6. Error function node cardinality single attribute discrimination
concept.

263



fiMurphy & Pazzani

100
80

Error

0.3

60
0.2
40
0.1

Error
Trials

20

0.0

Number Trials

0.4

0
0

2

4

6

8 10 12 14
Node Cardinality

16

18

20

Figure 7. Error function node cardinality simple conjunction

AB concept.

concept, 100 trials run 20 examples used training
remaining 12 testing. simpler concepts, though smallest trees
accurate, error monotonically increasing function node cardinality.
3.3 Training Testing using Probability Distribution.

previous experiments, used methodology typical empirical evaluations
machine learning systems: training data test data disjoint. contrast,
theoretical work PAC model (Valiant, 1984) assumes training
test data generated probability distribution examples.
section, ran experiment training test examples selected
replacement distribution ensure results dependent
particular experimental methodology.
100
80

Error

0.15

60
0.10
40
0.05

Error
Trials

0.00

20

Number Trials

0.20

0
0

2

4

6

8 10 12 14 16 18 20 22
Node Cardinality

Figure 8. Error function node cardinality training test examples
generated distribution XY Z _ AB concept.
again, target concept XY Z _ AB . randomly choosing 31 training
examples replacement set 32 possible instances, average approximately
20 distinct training examples selected. Error estimated randomly choosing 1000
264

fiExploring Decision Forest
examples replacement set possible instances. Figure 8 graphs mean
error (averaged 100 trials) function node cardinality.
testing methodology produces much smaller values proportion test examples misclassified disjoint training test set methodology test
examples also training examples always classified correctly. However,
basic pattern results observed. Error minimum smallest decision trees decision trees 8 nodes (the minimum-sized correct tree). Error
monotonically increases starting trees 7 nodes begins decrease
large node cardinalities. Note trials, possible build decision
trees 21 nodes since training sets contained 22 distinct examples.
3.4 Average Path Length

information gain metric ID3 intended minimize number tests required
classify example. Figure 9 reanalyzes data Figure 1 graphing average error
function average path length XY Z _ AB concept.
100
80
0.3
Error

60
40

0.2
Error
Trials

20

0.1

Number Trials

0.4

0
1.0

2.0

3.0
4.0
Average Path Length

5.0

Figure 9. Error function average path length XY Z _ AB concept.
results similar obtained relating number test nodes
error rate: error monotonically increasing function average path length. Similar
analyses performed similar results obtained concepts
presented Appendix.
4. Minimum-Sized Decision Tree Policy

designer learning algorithm either explicitly implicitly must decide hypothesis prefer multiple hypotheses consistent training data. Table 1
shows, many consistent decision trees. learner always prefer
smallest consistent decision tree? learner adopts strategy said
following minimum-sized decision tree policy.

265

fiMurphy & Pazzani
section, present results additional experiments evaluate policy.
particular, gather evidence address two related questions:



Given two consistent decision trees different node cardinalities,
probability smaller decision tree accurate?



Given minimum-sized decision tree larger consistent decision tree,
probability smallest decision tree accurate?

first question interest current practice decision tree induction
since, eciency reasons, algorithm attempts find smallest consistent decision
tree large data sets. Nonetheless, algorithms biased toward favoring trees
fewer nodes.
0.8

Probability

0.6
Prob(Smaller > Larger)
Prob(Larger > Smaller)
Prob(Smaller = Larger)

0.4
0.2
0.0
0

2
4
6
8
10
12
Difference Node Cardinality

14

16

Number trials

1000
800
600
400
200
0
0

2
4
6
8
10
12
Difference Node Cardinality

14

16

Figure 10. probability accuracy smaller decision tree greater than,
equal to, less accuracy larger tree function difference node
cardinalities XY Z _AB concept (upper). number trials 1000
least 2 trees given difference node cardinality (lower).
address question whether learner prefer smaller two randomly
selected consistent trees, ran 1000 trials learning concept XY Z _ AB 20
training examples. trial, recorded node cardinality accuracy (on
12 test examples) every consistent tree. pair consistent trees (with different
266

fiExploring Decision Forest
node cardinalities), computed difference node cardinality indicated whether
accuracy smaller tree greater than, equal to, less accuracy
larger tree. data, computed observed probability one decision tree
accurate another function difference node cardinalities (see
Figure 10 upper). graph shows concept, probability smaller
two randomly chosen consistent decision trees accurate greater
probability larger tree accurate. Furthermore, probability
smaller tree accurate increases difference node cardinality increases.
exception trend occurs large differences node cardinality. However,
Figure 10 lower shows, exceptions quite rare. Consistent decision trees whose
node cardinalities differed 16 found 6 1000 trials.4 results
experiment indicate average, learner prefers smaller two randomly
selected decision trees higher probability accurate concept
learner selects larger tree.

Probability

0.8
0.6
Prob(Smallest > Larger)
Prob (Larger > Smallest)
Prob(Smallest = Larger)

0.4
0.2
0.0
0

2

4
6
8
10
12
Difference Node Cardinality

14

16

Figure 11. probability accuracy minimum-sized decision greater than,
equal to, less accuracy larger tree function difference node
cardinalities XY Z _ AB concept.
address question whether learner prefer smallest consistent decision randomly selected consistent tree test nodes, reanalyzed data
previous experiment. Figure 11 graphs observed probability consistent
decision tree minimum node cardinality accurate larger tree
function difference node cardinalities two trees. graph shows
learner chooses randomly among consistent decision trees minimum node
cardinalities likely find tree accurate learner randomly
selects among larger trees.5
Figure 11 clearly shows particular concept, preferring minimum-sized
decision tree policy average better policy preferring decision tree
4. Four trials minimum-sized trees 2 nodes maximally sized trees 18 nodes. Two trials
minimum-sized trees 3 nodes maximally sized trees 19 nodes.
5. Except rare case extremely small extremely large decision trees found
trial.

267

fiMurphy & Pazzani
fixed size larger smallest decision tree. However, clear minimumsized decision tree best possible policy concept. Indeed, looking
data Figure 3, apparent better strategy concept would find
minimum-sized tree decide whether return minimum-sized tree tree
different node cardinality function node cardinality minimum-sized
consistent tree. Table 2 shows node cardinality highest probability
accurate function minimally sized tree, together number trials
(out 1000) minimum-sized tree particular node cardinality.
Minimum
Preferred
Number
Node Cardinality Node Cardinality
Trials
2
2
49
3
5
17
4
5
300
5
5
351
6
8
211
7
8
71
8
8
1

Table 2. policy returning larger decision tree function minimum-sized
tree XY Z _ AB concept.
Figure 11 provides data illustrates policy Table 2
perform better preferring minimum-sized decision tree concept. Figure
12 graphs observed probability consistent decision tree minimum node
cardinality 5 (upper), 6 (middle), 7 (lower) accurate larger tree
function difference node cardinalities two trees. graph shows
minimum-sized decision tree 5 nodes, probability larger tree
accurate less probability smaller tree accurate
node cardinalities. particularly interesting shows giving decision
tree learner size correct tree decision tree learner produce
hypothesis size best strategy concept. However, smallest
consistent tree 6 nodes, 0.560 probability randomly chosen tree
8 nodes accurate 0.208 probability tree 8 test nodes
accuracy. addition, minimum-sized tree 7 test nodes,
probability tree 8 nodes accurate 0.345 probability
less accurate 0.312.
Note believe policy Table 2 uniformly superior preferring
minimum-sized decision tree. Rather, probably interaction
complexity concept learned, number training examples, size
smallest consistent decision tree. Furthermore, learner tuned learn
particular concept, perform well variety concepts. Clearly, extremely
simple concepts learned suciently frequently, minimum-sized decision tree
policy better policy Table 2. Indeed, minimum-sized decision tree
268

fiExploring Decision Forest
policy would work well simple concepts AB discussed Section 3.2. However,
simple concepts rarely encountered, may better policies. best policy must
depend upon distribution concepts encountered. Clearly, concept
Minimum Node Cardinality = 5
1.0

Probability

0.8
Prob(Smallest>Larger)
Prob(Larger>Smallest)
Prob(Smallest=Larger)

0.6
0.4
0.2
0.0
0

5
10
Difference Node Cardinality

15

Minimum Node Cardinality = 6
1.0

Probability

0.8
Prob(Smallest>Larger)
Prob(Larger>Smallest)
Prob(Smallest=Larger)

0.6
0.4
0.2
0.0
0

5
10
Difference Node Cardinality

15

Minimum Node Cardinality = 7
1.0

Probability

0.8
Prob(Smallest>Larger)
Prob(Larger>Smallest)
Prob(Smallest=Larger)

0.6
0.4
0.2
0.0
0

5
10
Difference Node Cardinality

15

Figure 12. probability accuracy minimum-sized decision tree greater
than, equal to, less accuracy larger tree function difference
node cardinalities XY Z _ AB concept minimum-sized decision tree 5
(upper), 6 (middle), 7 (lower) test nodes.

269

fiMurphy & Pazzani
learned XY Z _AB , best policy would ignore training data return
decision tree representation XY Z _ AB . may Occam's razor
viewed philosophical statement distribution concepts one likely
encounter. Occam's razor shown guarantee learning
complex concept, simplest hypothesis consistent data likely
accurate randomly-chosen complex hypothesis consistent training
data.
5. Analysis

Schaffer (1992, 1993) presents series experiments overfitting avoidance algorithms.
Overfitting avoidance algorithms prefer simpler decision trees complex ones, even
though simpler decision trees less accurate training data, hopes
trees accurate test data. Schaffer shows overfitting avoidance
algorithms form bias. Rather uniformly improving performance, overfitting
avoidance algorithms improve performance distributions concepts worsen
performance distributions concepts.
results experiments go step Schaffer's. shown
concepts, preference simpler decision trees result increase
predictive accuracy unseen test data, even simple trees consistent
training data. Like Schaffer, dispute theoretical results Occam's
razor (Blumer, Ehrenfeucht, Haussler, & Warmuth, 1987), minimum description length
(Quinlan & Rivest, 1989; Muggleton et al., 1992), minimizing number leaves
decision tree (Fayyad & Irani, 1990). Rather, point variety reasons,
assumptions behind theoretical results mean results apply
experiments reported here. example, (Blumer et al., 1987) indicates one finds
hypothesis suciently small hypothesis space (and simpler hypotheses one example
small hypothesis space) hypothesis consistent suciently large sample
training data, one fairly confident fairly accurate unseen data
drawn distribution examples. However, say average
hypothesis accurate consistent hypotheses small
hypothesis space.
(Fayyad & Irani, 1990) paper explicitly states results minimizing
number leaves decision trees worst case results used make
absolute statements concerning improvements performances. Nonetheless, informal arguments paper state: \This may serve basis provably establishing one
method inducing decision trees better another proving one algorithm
always produces tree smaller number leaves, given training data."
Furthermore, informal arguments imply result probabilistic
existence \pathological training sets." However, shown Figures 2 4
(as well reanalysis mux6 data Appendix), eliminating pathological (i.e.,
unrepresentative) training sets change qualitative result concepts,
smaller trees less accurate predictors slightly larger trees.

270

fiExploring Decision Forest
6. Conclusion

reported series experiments generated decision trees
variety artificial concepts two naturally occurring data sets. found
many concepts, consistent decision trees smaller number nodes
less accurate unseen data slightly larger ones. results contradict
existing theoretical results. Rather, serve remind us cautious informally
using intuitions derived theoretical results problems covered
theorems using intuitions derived worst-case results predict average-case
performance.
stress results purely experimental. Like reader, would
pleased theoretical results indicated, given sample training data,
decision tree likely accurate. However, clear whether
done without knowledge distribution concepts one likely encounter (Schaffer,
1994).
also note results may due small size training sets relative
size correct tree. tried rule possibility using larger training sets
(31 32 possible examples) testing simpler concepts. simpler concepts,
smallest decision trees accurate, error monotonically increase
node cardinality. Since decision tree learners greedily build decision trees
return smallest decision tree, results may practical interest even
simple concepts. future, experiments features examples could
help answer question, considerably complex problems cannot handled
even future generations parallel supercomputers. addition, note
experiments, build decision trees test partition training
data. explains found relatively extremely large decision trees may
explain large trees made errors. knowledge, decision tree algorithms
constraint. However, theoretical work learning make use
information. could rerun experiments without constraint, would
prefer future theoretical work take constraint account.
Although found situations smallest consistent decision tree
average accurate cases greater 0.5 probability
larger decision tree accurate smallest, believe learning algorithms
(and people) relevant knowledge concept information
distribution concepts likely encountered prefer simpler hypotheses.
bias appropriate learning simple concepts. complex concepts,
opposite bias, preferring complex hypotheses, unlikely produce accurate
hypothesis (Blumer et al., 1987) (Fayyad & Irani, 1990) due large number
consistent complex hypotheses. believe way learn complex hypotheses
reliably bias (e.g., prior domain knowledge) favors particular complex
hypotheses combinations existing hypotheses learned inductively OCCAM
(Pazzani, 1990). Indeed, (Valiant, 1984) advocates similar position: \If class
learnable concepts severely limited suggested results, would follow
way teaching complex concepts build simpler
ones."
271

fiMurphy & Pazzani
Acknowledgements

thank Ross Quinlan, Geoffrey Hinton, Michael Cameron-Jones, Cullen Schaffer, Dennis Kibler, Steve Hampson, Jason Catlett, Haym Hirsh, Anselm Blumer, Steve Minton,
Michael Kearns, Tom Dietterich, Pat Langley, David Schulenburg commenting
various aspects research. research reported supported part
NSF infrastructure grant number MIP-9205737, NSF Grant INT-9201842, AFOSR grant
F49620-92-J-0430, AFOSR AASERT grant F49620-93-1-0569.
Appendix A. Experiments Additional Problems

appendix, provide data experiments ran additional problems.
experiments show basic findings paper unique artificial
concept, XY Z _ AB .
Mux6

multiplexor concept consider, mux6, total 8 binary features. Six features
represent functionality multiplexor 2 features irrelevant. minimum sized
tree 7 nodes. particular concept chosen dicult top-down
inductive decision tree learner limited look ahead find small hypothesis (Quinlan,
1993). trial, selected 20 examples randomly tested remaining
examples. Since computational cost building consistent trees larger
node cardinalities primarily interested trees small node cardinalities,
computed consistent trees 10 nodes 10 trials 8 nodes 340
0.45

350
Error
Trials

Error

250
200

0.35

150
100

0.30

50
0.25

Number Trials

300

0.40

0
2

4

6
Node Cardinality

8

10

Figure 13. Error function node cardinality mux6 concept.
trials. Figure 13 presents average error function node cardinality
trials. graph shows average error monotonically increase node
cardinality. Trees 4 nodes average 4% less accurate trees 5 nodes.
272

fiExploring Decision Forest
Lenses

0.7

0.7

0.6

0.6

0.5

0.5

0.4

0.4

Error

Error

lenses domain one 3-valued three binary features, three classes, 24 instances. Since lenses domain one non-binary feature, trees range leaf
cardinalities possible particular node cardinality. minimum-sized tree
6 nodes 9 leaves. Separate analyses leaf node cardinalities performed.
used training set sizes 8, 12, 18 domain, built consistent trees,
measured error rate unseen examples.

0.3
0.2

0.2

Size = 8
Size = 12
Size = 18

0.1

0.3
Size = 8
Size = 12
Size = 18

0.1

0.0

0.0
0

2

4

6 8 10 12
Node Cardinality

14 16 18

0

2

4

6 8 10 12 14 16 18 20
Leaf Cardinality

Figure 14. Error function node cardinality (left) error function leaf
cardinality (right).
Figure 14 (left) shows error function node cardinality 3 training
set sizes averaged 50 trials. curves indicate smallest consistent trees
always accurate. observing larger node cardinalities training
set sizes 12 18, error monotonically decreases increasing node cardinality. Similar
statements said curve Figure 14 (right), relates average error
function leaf cardinality.
Shuttle Landing

shuttle landing domain four binary two 4-valued features, two classes, 277
instances. minimum-sized consistent tree 7 nodes 14 leaves. used training
sets size 20, 50, 100 shuttle domain, generating consistent decision trees
fewer 8, 10, 12 nodes, measured error trees unseen
examples. Figure 15 presents error function leaf cardinality, averaged

273

fiMurphy & Pazzani
10 trials. domain, monotonically increasing relationship node
cardinality error.
0.4

size = 20
size = 50
size = 100

Error

0.3
0.2
0.1
0.0
0

2

4

6
8
10
Node Cardinality

12

14

Figure 15. Error function node cardinality Shuttle concept.
References

Blumer, A., Ehrenfeucht, A., Haussler, D., & Warmuth, M. (1987). Occam's razor. Information Processing Letters, 24, 377{380.
Breiman, L., Friedman, J., Olshen, R., & Stone, C. (1984). Classification Regression
Trees. Pacific Grove, CA: Wadsworth & Brooks.
Fayyad, U., & Irani, K. (1990). minimized decision tree?. Proceedings
Eighth National Conference Artificial Intelligence, AAAI-90.
Fayyad, U., & Irani, K. (1992). attribute selection problem decision tree generation..
Proceedings Tenth National Conference Artificial Intelligence, AAAI-92.
Muggleton, S., Srinivasan, A., & Bain, M. (1992). Compression, significance accuracy.
Machine Learning: Proceedings Ninth International Workshop.
Murphy, P., & Aha, D. (1994). UCI Repository machine learning databases [Machinereadable data repository]. Irvine, CA: University California, Department Information Computer Science.
Pazzani, M. (1990). Creating memory causal relationships: integration empirical
explanation-based learning methods. Hillsdale, NJ: Lawrence Erlbaum Associates.
Quinlan, J. (1986). Induction decision trees. Machine Learning, 1 (1), 81{106.
Quinlan, J. (1993). C4.5 Programs Machine Learning. San Mateo,CA: Morgan Kaufmann.
Quinlan, J., & Rivest, R. (1989). Inferring decision trees using minimum description
length principle. Information Computation, 80, 227{248.
274

fiExploring Decision Forest
Rissanen, J. (1978). Modeling shortest data description. Automatica, 14, 465{471.
Schaffer, C. (1992). Sparse data effect overfitting avoidance decision tree
induction. Proceedings Tenth National Conference Artificial Intelligence,
AAAI-92.
Schaffer, C. (1993). Overfitting avoidance bias. Machine Learning, 10 (2), 153{178.
Schaffer, C. (1994). conservation law generalization performance. Unpublished
Manuscript.
Valiant, L. (1984). theory learnable. Communications ACM, 27 (11), 1134{
1142.
Wallace, C., & Patrick, J. (1993). Coding decision trees. Machine Learning, 11 (1), 7{22.

275

fiJournal Artificial Intelligence Research 1 (1994) 231-255

Submitted 12/93; published 2/94

Substructure Discovery Using Minimum Description
Length Background Knowledge
Diane J. Cook
Lawrence B. Holder

Department Computer Science Engineering
Box 19015
University Texas Arlington
Arlington, TX 76019 USA

cook@cse.uta.edu
holder@cse.uta.edu

Abstract

ability identify interesting repetitive substructures essential component discovering knowledge structural data. describe new version Subdue substructure discovery system based minimum description length principle.
Subdue system discovers substructures compress original data represent
structural concepts data. replacing previously-discovered substructures
data, multiple passes Subdue produce hierarchical description structural regularities data. Subdue uses computationally-bounded inexact graph match
identifies similar, identical, instances substructure finds approximate
measure closeness two substructures computational constraints. addition minimum description length principle, background knowledge used
Subdue guide search towards appropriate substructures. Experiments
variety domains demonstrate Subdue's ability find substructures capable compressing original data discover structural concepts important domain.

1. Introduction
large amount data collected today quickly overwhelming researchers' abilities
interpret data discover interesting patterns within data. response
problem, number researchers developed techniques discovering concepts
databases. techniques work well data expressed non-structural, attributevalue representation, address issues data relevance, missing data, noise uncertainty, utilization domain knowledge. However, recent data acquisition projects
collecting structural data describing relationships among data objects. Correspondingly, exists need techniques analyze discover concepts structural
databases.
One method discovering knowledge structural data identification common substructures within data. motivation process find substructures
capable compressing data identify conceptually interesting substructures
enhance interpretation data. Substructure discovery process identifying
concepts describing interesting repetitive substructures within structural data.
discovered, substructure concept used simplify data replacing instances
substructure pointer newly discovered concept. discovered substructure concepts allow abstraction detailed structure original data provide
c 1994 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.

fiCook & Holder
new, relevant attributes interpreting data. Iteration substructure discovery
replacement process constructs hierarchical description structural data terms
discovered substructures. hierarchy provides varying levels interpretation
accessed based goals data analysis.
describe system called Subdue (Holder, Cook, & Bunke, 1992; Holder & Cook,
1993) discovers interesting substructures structural data based minimum
description length principle. Subdue system discovers substructures compress
original data represent structural concepts data. replacing previouslydiscovered substructures data, multiple passes Subdue produce hierarchical description structural regularities data. Subdue uses computationally-bounded
inexact graph match identifies similar, identical, instances substructure
finds approximate measure closeness two substructures computational
constraints. addition minimum description length principle, background
knowledge used Subdue guide search towards appropriate substructures.
following sections describe approach detail. Section 2 describes process
substructure discovery introduces needed definitions. Section 3 compares Subdue
discovery system work found literature. Section 4 introduces minimum
description length encoding used approach, Section 5 presents inexact
graph match algorithm employed Subdue. Section 6 describes methods incorporating
background knowledge substructure discovery process. experiments detailed
Section 7 demonstrate Subdue's ability find substructures compress data
re-discover known concepts variety domains. Section 8 details hierarchical
discovery process. conclude observations directions future research.

2. Substructure Discovery
substructure discovery system represents structured data labeled graph. Objects
data map vertices small subgraphs graph, relationships
objects map directed undirected edges graph. substructure connected
subgraph within graphical representation. graphical representation serves input
substructure discovery system. Figure 1 shows geometric example input
graph. objects figure (e.g., T1, S1, R1) become labeled vertices graph,
relationships (e.g., on(T1,S1), shape(C1,circle)) become labeled edges graph.
graphical representation substructure discovered Subdue data
also shown Figure 1.
instance substructure input graph set vertices edges
input graph match, graph theoretically, graphical representation
substructure. example, instances substructure Figure 1 shown
Figure 2.
substructure discovery algorithm used Subdue computationally-constrained
beam search. algorithm begins substructure matching single vertex
graph. iteration algorithm selects best substructure expands
instances substructure one neighboring edge possible ways. new unique
generated substructures become candidates expansion. algorithm searches
232

fiSubstructure Discovery

Input Graph

Substructure

T1

pe

S1

triangle


sh

C1
R1

T2

T3

S2

S3



T4

pe

square


sh

S4

Figure 1: Example substructure graph form.
Instance

1

Instance

2

Instance

3

Instance

T1

T2

T3

T4

S1

S2

S3

S4

4

Figure 2: Instances substructure.
best substructure possible substructures considered total
amount computation exceeds given limit. evaluation substructure guided
MDL principle background knowledge provided user.
Typically, description length expanding substructure begins increase,
expansion substructure yield smaller description length.
result, Subdue makes use optional pruning mechanism eliminates substructure
expansions consideration description lengths expansions increases.

3. Related Work
Several approaches substructure discovery developed. Winston's Arch program (Winston, 1975) discovers substructures order deepen hierarchical description
scene group objects general concepts. Arch program searches
two types substructure blocks-world domain. first type involves sequence
objects connected chain similar relations. second type involves set
objects similar relationship \grouping" object. main difference
substructure discovery procedures used Arch program Subdue
Arch program designed specifically blocks-world domain. instance,
sequence discovery method looks supported-by in-front-of relations only.
Subdue's substructure discovery method domain independent, although inclusion
domain-specific knowledge would improve Subdue's performance.
Motivated need construct knowledge base chemical structures, Levinson
(Levinson, 1984) developed system storing labeled graphs individual graphs
233

fiCook & Holder
represented set vertices universal graph. addition, individual graphs
maintained partial ordering defined subgraph-of relation, improves
performance graph comparisons. universal graph representation provides
method compressing set graphs stored knowledge base. Subgraphs
universal graph used several individual graphs suggest common substructure
individual graphs. One difference two approaches Levinson's system
designed incrementally process smaller individual graphs; whereas, Subdue processes
larger graphs once. Also, Levinson's system discovers common substructure
indirect result universal graph construction; whereas, Subdue's main goal
discover output substructure definitions reduce minimum description
length encoding graph. Finally, subgraph-of partial ordering used Levinson's
system included Subdue, maintaining partial ordering would improve
performance graph matching procedure pruning number possible matching
graphs.
Segen (Segen, 1990) describes system storing graphs using probabilistic graph
model represent subsets graph. Alternative models evaluated based minimum description length measure information needed represent stored graphs
using model. addition, Segen's system clusters graphs classes based
minimizing description length graphs according entire clustering. Apart
probabilistic representation, Segen's approach similar Levinson's system
methods take advantage commonalities graphs assist graph storage matching. probabilistic graphs contain information identifying common
substructure exact graphs represent. portion probabilistic graph
high probability defines substructure appears frequently exact graphs.
notion emphasized Segen's work, provides alternative method
substructure discovery clustering subgraphs original input graphs. Levinson's approach, graphs processed incrementally, substructure found across several
graphs, within single graph Subdue.
Labyrinth system (Thompson & Langley, 1991) extends Cobweb incremental
conceptual clustering system (Fisher, 1987) handle structured objects. Labyrinth uses
Cobweb form hierarchical concepts individual objects domain based
primitive attributes. Concepts structured objects formed similar manner
using individual objects attributes. resulting hierarchy represents componential
model structured objects. Cobweb's concepts probabilistic, Labyrinth
produces probabilistic models structured objects, added hierarchical
organization. upper-level components structured-object hierarchy produced
Labyrinth represent substructures common examples. Therefore, although
primary focus, Labyrinth discovering substructure, constrained context
general graph representation used Subdue.
Conklin et al. (Conklin & Glasgow, 1992) developed i-mem system constructing image hierarchy, similar Labyrinth, used discovering common
substructures set images ecient retrieval images similar given image.
Images expressed terms set relations defined user. Specific general
(conceptual) images stored hierarchy based subsumption relation similar
234

fiSubstructure Discovery
Levinson's subgraph-of partial ordering. Image matching utilizes transformational
approach (similar Subdue's inexact graph match) measure image closeness.
approaches Segen Levinson, i-mem designed process individual
images. Therefore, general image concepts appear higher i-mem's hierarchy
represent common substructures across several images. Subdue designed discover
common substructures within single image. Subdue mimic individual approach
systems processing set individual images one disconnected graph.
substructures found common individual images. hierarchy also represents
componential view images. view constructed Subdue using
multiple passes graph replacing portions input graph substructures
discovered previous passes. i-mem performed well simple chess domain
molecular chemistry domains (Conklin & Glasgow, 1992). However, i-mem requires
domain-specific relations expressing images order hierarchy find relevant
substructures image matching ecient. Again, maintaining concepts
(images, graphs) partially-ordered hierarchy improves eciency matching
retrieval, suggests possible improvement Subdue.
CLiP system (Yoshida, Motoda, & Indurkhya, 1993) graph-based induction
similar Subdue previous systems. CLiP iteratively discovers patterns
graphs expanding combining patterns discovered previous iterations. Patterns
grouped views based collective ability compress original input
graph. iteration CLiP uses existing views contract input graph
considers adding views new patterns consisting two vertices edge
contracted graph. compression new proposed views estimated,
best views (according given beam width) retained next iteration.
CLiP discovers substructures (patterns) differently Subdue. First, CLiP produces
set substructures collectively compress input graph; whereas, Subdue produces
single substructures evaluated using principled minimum description length.
CLiP ability grow substructures agglomeratively (i.e., merging two substructures
together); whereas, Subdue always produces new substructures using incremental growth
along one new edge. CLiP initially estimates compression value new views based
compression value parent view; whereas, Subdue performs expensive exact
measurement compression new substructure. Finally, CLiP employs ecient
graph match based graph identity, graph isomorphism Subdue. Graph identity
assumes ordering incident edges vertex consider possible
mappings looking occurrences pattern input graph. differences
CLiP suggest possible enhancements Subdue.
Research pattern recognition begun investigate use graphs graph
grammars underlying representation structural problems (Schalkoff, 1992). Many
results grammatical inference applicable constrained classes graphs (e.g., trees)
(Fu, 1982; Miclet, 1986). approach begins set sample graphs produces
generalized graph grammar capable deriving original sample graphs many others.
production rules general grammar capture regularities (substructures)
sample graphs. Jeltsch Kreowski (Jeltsch & Kreowski, 1991) describe approach
begins maximally-specific grammar iteratively identifies common subgraphs
right-hand sides production rules. common subgraphs used form
235

fiCook & Holder
new, general production rules. Although method address underlying
combinatorial nondeterminism, heuristic approaches could provide feasible method
extracting substructures form graph grammars. Furthermore, graph grammar
production-rule may provide suitable representation background knowledge
substructure discovery process.

4. Minimum Description Length Encoding Graphs

minimum description length principle (MDLP) introduced Rissanen (Rissanen,
1989) states best theory describe set data theory minimizes
description length entire data set. MDL principle used decision
tree induction (Quinlan & Rivest, 1989), image processing (Pednault, 1989; Pentland, 1989;
Leclerc, 1989), concept learning relational data (Derthick, 1991), learning models
non-homogeneous engineering domains (Rao & Lu, 1992).
demonstrate minimum description length principle used discover
substructures complex data. particular, substructure evaluated based well
compress entire dataset using minimum description length. define
minimum description length graph number bits necessary completely
describe graph.
According minimum description length (MDL) principle, theory best
accounts collection data one minimizes (S ) + (GjS ),
discovered substructure, G input graph, (S ) number bits required encode
discovered substructure, (GjS ) number bits required encode input
graph G respect .
graph connectivity represented adjacency matrix. Consider graph
n vertices, numbered 0; 1; : : :; n , 1. n n adjacency matrix
formed entry A[i; j ] set 0 1. A[i; j ] = 0, connection
vertex vertex j . A[i; j ] = 1, least one connection vertex
vertex j . Undirected edges recorded one entry matrix. adjacency
matrix graph Figure 3 shown below.
x 20 1 1 0 0 03
triangle 66 0 0 0 0 0 0 77
666 0 0 0 1 1 0 777
square 66 0 0 0 0 0 0 77
r 40 0 0 0 0 15
rectangle 0 0 0 0 0 0
encoding graph consists following steps. assume decoder
table lu unique labels original graph G.
1. Determine number bits vbits needed encode vertex labels graph.
First, need (lg v ) bits encode number vertices v graph. Then,
encoding labels v vertices requires (v lg lu ) bits. assume vertices
specified order appear adjacency matrix. total number
bits encode vertex labels
vbits = lg v + v lg lu
236

fiSubstructure Discovery

triangle

e

p
ha


x



pe

square


sh




pe

rectangle


sh
r

Figure 3: MDL example graph.
example Figure 3, v = 6, assume lu = 8 unique
labels original graph. number bits needed encode vertices
lg 6 + 6 lg 8 = 20:58 bits.
2. Determine number bits rbits needed encode rows adjacency matrix
A. Typically, large graphs, single vertex edges small percentage
vertices entire graph. Therefore, typical row adjacency matrix
much fewer v 1s, v total number vertices graph.
apply variant coding scheme used (Quinlan & Rivest, 1989) encode bit
strings length n consisting k 1s (n , k) 0s, k (n , k).
case, row (1 v ) represented bit string length v containing ki
1s. let b = maxi ki , ith row adjacency matrix encoded
follows.
(a) Encoding value ki requires lg(b + 1) bits.

(b) Given ki 1s occur row bit string length v , kvi strings
0s 1s
Since strings equal probability
possible.

v
occurrence, lg ki bits needed encode positions 1s row i.
value v known vertex encoding.
Finally, need additional lg(b + 1) bits encode number bits needed
specify value ki row. total encoding length bits adjacency
matrix

rbits = lg(b + 1) +

v
X
i=1

= (v + 1) lg(b + 1)
237



lg(b + 1) + lg kvi
v
X
i=1



lg kvi

fiCook & Holder
example Figure 3, b = 2,


number

bits
needed
encode

6
6
6
6
6
6
adjacency matrix (7 lg 3)+lg 2 +lg 0 +lg 2 +lg 0 +lg 1 +lg 0 = 21:49
bits.
3. Determine number bits ebits needed encode edges represented
entries A[i; j ] = 1 adjacency matrix A. number bits needed encode
entry A[i; j ] (lg m) + e(i; j )[1 + lg lu ], e(i; j ) actual number edges
vertex j graph = maxi;j e(i; j ). (lg m) bits needed
encode number edges vertex j , [1 + lg lu ] bits needed
per edge encode edge label whether edge directed undirected.
addition encoding edges, need encode number bits (lg m) needed
specify number edges per entry. total encoding edges

ebits = lg +

v X
v
X
i=1 j =1

lg + e(i; j )[1 + lg lu ]

= lg + e(1 + lg lu ) +

v X
v
X
i=1 j =1

A[i; j ] lg

= e(1 + lg lu ) + (K + 1) lg
e number edges graph, K number 1s adjacency
matrix A. example Figure 3, e = 5, K = 5, = 1, lu = 8, number
bits needed encode edges 5(1 + lg 8) + 6 lg 1 = 20.
total encoding graph takes (vbits + rbits + ebits) bits. example
Figure 3, value 62:07 bits.
input graph discovered substructure encoded using
scheme. substructure discovered, instance substructure input
graph replaced single vertex representing entire substructure. discovered
substructure represented (S ) bits, graph substructure replacement
represented (GjS ) bits. Subdue searches substructure graph G minimizing
(S ) + (GjS ).

5. Inexact Graph Match

Although exact structure match used find many interesting substructures, many
interesting substructures show slightly different form throughout
data. differences may due noise distortion, may illustrate slight
differences instances general class structures. Consider image
shown Figure 9. pencil cube would make ideal substructures picture,
exact match algorithm may consider strong substructures,
rarely occur form level detail throughout picture.
Given input graph set defined substructures, want find subgraphs
input graph closely resemble given substructures. Furthermore, want
associate distance measure pair graphs consisting given substructure
subgraph input graph. adopt approach inexact graph match given
Bunke Allermann (Bunke & Allermann, 1983).
238

fiSubstructure Discovery

g1

g2

b

B




B

1

2



3

4



b

b
5
B

Figure 4: Two similar graphs g1 g2 .
inexact match approach, distortion graph assigned cost. distortion
described terms basic transformations deletion, insertion, substitution
vertices edges. distortion costs determined user bias match
particular types distortions.
inexact graph match two graphs g1 g2 maps g1 g2 g2
interpreted distorted version g1. Formally, inexact graph match mapping
f : N1 ! N2 [ fg, N1 N2 sets vertices g1 g2, respectively.
vertex v 2 N1 mapped (i.e., f (v ) = ) deleted. is, corresponding
vertex g2. Given set particular distortion costs discussed above, define cost
inexact graph match cost(f ), sum cost individual transformations
resulting f , define matchcost(g1 ; g2) value least-cost function
maps graph g1 onto graph g2.
Given g1 , g2, set distortion costs, actual computation matchcost(g1 ; g2)
determined using tree search procedure. state search tree corresponds
partial match maps subset vertices g1 subset vertices g2.
Initially, start empty mapping root search tree. Expanding state
corresponds adding pair vertices, one g1 one g2, partial mapping
constructed far. final state search tree match maps vertices g1
g2 . complete search tree example Figure 4 shown Figure 5.
example assign value 1 distortion cost. numbers circles
figure represent cost state. eventually interested mapping
minimum cost, state search tree gets assigned cost partial mapping
represents. Thus goal state found tree search procedure
final state minimum cost among final states. Figure 5 conclude
minimum cost inexact graph match g1 g2 given mapping f (1) = 4, f (2) = 3.
cost mapping 4.
Given graphs g1 n vertices g2 vertices, n, complexity
full inexact graph match O(nm+1 ). routine used heavily throughout
239

fiCook & Holder

(1, 3) 1

(1, 5) 1

(1, 4) 0

(1,

)1

(2,4) (2,5) (2, ) (2,3) (2,5) (2, ) (2,3) (2,4) (2, ) (2,3) (2,4) (2,5) (2, )
7

6

10

3

6

9

7

7

10

9

10

9

11

Figure 5: Search tree computing matchcost(g1,g2) Figure 4.
discovery evaluation process, complexity algorithm significantly degrade
performance system.
improve performance inexact graph match algorithm, extend Bunke's
approach applying branch-and-bound search tree. cost root
tree given node computed described above. Nodes considered pairings
order heavily connected vertex least connected, constrains
remaining match. branch-and-bound search guarantees optimal solution,
search ends soon first complete mapping found.
addition, user place limit number search nodes considered
branch-and-bound procedure (defined function size input graphs).
number nodes expanded search tree reaches defined limit, search
resorts hill climbing using cost mapping far measure choosing
best node given level. defining limit, significant speedup realized
expense accuracy computed match cost.
Another approach inexact graph match would encode difference
two graphs using MDL principle. Smaller encodings would indicate lower match cost
two graphs. leave future research direction.

6. Guiding Discovery Process Background Knowledge
Although principle minimum description length useful discovering substructures maximize compression data, scientists may realize benefit
discovery substructures exhibit domain-specific domain-independent characteristics.
make Subdue powerful across wide variety domains, added
ability guide discovery process background knowledge. Although minimum
description length principle still drives discovery process, background knowledge
used input bias toward certain types substructures. background knowledge
encoded form rules evaluating substructures, represent domainindependent domain-dependent rules. time substructure evaluated, input
240

fiSubstructure Discovery
rules used determine value substructure consideration.
most-favored substructures kept expanded, rules bias discovery
process system.
background rule assigned positive, zero, negative weight, biases
procedure toward type substructure, eliminates use rule, biases
procedure away type substructure, respectively. value substructure
defined description length (DL) input graph using substructure multiplied weighted value background rule set rules R applied
substructure.

value(s) = DL(G; s)

jRj

r=1

ruler (s)er

(1)

Three domain-independent heuristics incorporated rules Subdue system compactness, connectivity, coverage. definitions rules,

let G represent input graph, represent substructure graph,
represent set instances substructure G. instance weight w
instance 2 substructure defined
(i; s)
(2)
w(i; s) = 1 , matchcost
size(i) ;
size(i) = #vertices(i) + #edges(i). match cost greater size
larger graph, w(i; s) = 0. instance weights used rules compute
weighted average instances substructure. value 1 added formula
exponential weights used control rule's significance.
first rule, compactness, generalization Wertheimer's Factor Closure,
states human attention drawn closed structures (Wertheimer, 1939). closed
substructure least many edges vertices, whereas non-closed substructure
fewer edges vertices (Prather, 1976). Thus, closed substructures higher
compactness value. Compactness defined weighted average ratio
number edges substructure number vertices substructure.

compactness(s) = 1 + j1I j

X

i2I

edges(i)
w(i; s) ##vertices
(i)

(3)

second rule, connectivity, measures amount external connection instances substructure. connectivity rule variant Wertheimer's Factor
Proximity (Wertheimer, 1939), related earlier numerical clustering techniques
(Zahn, 1971). works demonstrate human preference \isolated" substructures,
is, substructures minimally related adjoining structure. Connectivity measures \isolation" substructure computing inverse average number
external connections weighted instances substructure input graph.
external connection defined edge connects vertex substructure
vertex outside substructure. formula determining connectivity
substructure instances input graph G given below.
241

fiCook & Holder
"

connectivity(s) = 1 + 1

X

jI j i2I w(i; s) num external conns(i)

#,1

(4)

third rule, coverage, measures fraction structure input graph described
substructure. coverage rule motivated research inductive learning
provides concept descriptions describing input examples considered better
(Michalski & Stepp, 1983). Although MDL measures amount structure, coverage
rule includes relevance savings respect size entire input graph.
Coverage defined number unique vertices edges instances
substructure divided total number vertices edges input graph.
formula, unique structure(i) instance number vertices edges
already appeared previous instances summation.

coverage(s) = 1 +

P
i2I w(i; s) unique

size(G)

structure(i)

(5)

Domain-dependent rules also used guide discovery process domain
scientists contribute expertise. example, CAD circuits generally consist
two types components, active passive components. active components
main driving components. Identifying active components first step understanding main function circuit. add knowledge Subdue include
rule assigns higher values substructures (circuit components) representing active
components lower values substructures representing passive components. Since
active components higher scores, expected selected. system
focus attention active components expanded functional
substructures.
Another method biasing discovery process background knowledge let
background rules affect prior probabilities possible substructures. However, choosing
appropriate prior probabilities express desired properties substructures dicult, indicates future direction inclusion background knowledge
substructure discovery process.

7. Experiments
experiments section evaluate Subdue's substructure discovery capability
several domains, including chemical compound analysis, scene analysis, CAD circuit design
analysis, analysis artificially-generated structural database.
Two goals substructure discovery system find substructures reduce
amount information needed describe data, find substructures
considered interesting given database. result, evaluate Subdue system
section along two criteria. First, measure amount compression
Subdue provides across variety databases. Second, use Subdue system
additional background knowledge rules re-discover substructures identified
interesting experts specific domain. Section 7.1 describes domains used
experiments, Section 7.2 presents experimental results.
242

fiSubstructure Discovery

CH 2OH


CH 3

CH 3



C


OH

Figure 6: Cortisone.
CH 3
C
CH
2

CH 3

H

C

C
CH

2

CH

CH

2
C

CH 3

2

CH 3

H

C

C
CH

CH

2

2

CH

CH

2

2

C

C
CH 3

H

H

CH

2

C
CH

2

C
H

Figure 7: Natural rubber (all-cis polyisoprene).

7.1 Domains
7.1.1 Chemical Compound Analysis

Chemical compounds rich structure. Identification common interesting
substructures benefit scientists identifying recurring components, simplying data
description, focusing substructures stand merit additional attention.
Chemical compounds represented graphically mapping individual atoms,
carbon oxygen, labeled vertices graph, mapping bonds
atoms onto labeled edges graph. Figures 6, 7, 8 show graphs representing
chemical compound databases cortisone, rubber, portion DNA molecule.
7.1.2 Scene Analysis

Images scene descriptions provide rich source structure. Images humans
encounter, natural synthesized, many structured subcomponents draw
attention help us interpret data scene.
Discovering common structures scenes useful computer vision system.
First, automatic substructure discovery help system interpret image. Instead
working low-level vertices edges, Subdue provide abstract structured
components, resulting hierarchical view image machine analyze
many levels detail focus, depending goal analysis. Second, substructure
discovery makes use inexact graph match help identify objects 2D image
3D scene noise orientation differences likely exist. object appears often scene, inexact graph match driving Subdue system may capture
slightly different views object. Although object may dicult identify
243

fiCook & Holder


CH2
N

adenine

N
N

N




N

P




H
N

OH



N

CH 3



H
P

HO


N

H

N

H



N

guanine
N

P





CH2



thymine

CH2



H

N

N





N
H

OH

N

cytosine

CH2
CH 3



H

P

HO








CH2
N

thymine
P

N

H

N



N




N
N

CH 3



H

OH

CH2

adenine

N
H


P

HO




Figure 8: Portion DNA molecule.

Figure 9: Scene analysis example.
244



fiSubstructure Discovery

f



k

x

l



p



Figure 10: Possible vertices labels.

l

l
l

l

l

l

l

l



l

l




l







l

l

l

l

l

l

l




l



l



f
l

l



Figure 11: Portion graph representing scene Figure 4.
one 2D picture, Subdue match instances similar objects, differences instances provide additional information identification. Third,
substructure discovery used compress image. Replacing common interesting
substructures single vertex simplifies image description reduces amount
storage necessary represent image.
apply Subdue image data, extract edge information image
construct graph representing scene. graph representation consists eight types
vertices two types arcs (edge space). vertex labels (f , a, l, t, k, x, p,
m) follow Waltz labelings (Waltz, 1975) junctions edges image represent
types vertices shown Figure 10. edge arc represents edge object
image, space arc links non-connecting objects together. edge arcs represent
edge scene connects two vertices, space arcs connect closest vertices
two disjoint neighboring objects. Distance, curve, angle information
included graph representation, added give additional information
scene. Figure 11 shows graph representation portion scene depicted
Figure 9. figure, edge arcs solid space arcs dashed.
245

fiCook & Holder

VCC

ext_pin

drain
drain
gate
n_mosfet

gate
source

source
connect

drain

drain
gate
connect

gate

n_mosfet

source

ext_pin

GND

Figure 12: Amplifier circuit graph representation.
7.1.3 CAD Circuit Analysis

domain, employ Subdue find circuit components CAD circuit data. Discovery substructures circuit data valuable tool engineer attempting
identify common reusable parts circuit layout. Replacing individual components
circuit description larger substructure descriptions also simplify representation
circuit.
data circuit domain obtained National Semiconductor, consists set components making circuit output Cadence Design System.
particular circuit used experiment portion analog-to-digital converter. Figure 12 presents circuit amplifier gives corresponding graph
representation.
7.1.4 Artificial Domain

final domain, artificially generate graphs evaluate Subdue's ability discover
substructures capable compressing graph. Four substructures created varying
sizes randomly-selected vertices edges (see Figure 13). name substructure
ects number vertices edges graph representation. Next, substructures embedded larger graphs whose size 15 times size substructure.
graphs vary across four parameters: number possible vertex edge labels (one
times two times number labels used substructure), connectivity
substructure (1 2 external connections), coverage instances (60% 80%),
246

fiSubstructure Discovery

e1
e2

e3

n4

n1

e1
n3

e2

n2

n4

n3
e3

n2

e3
e6
n7

e3
n5

e1
n2

e4
n5

e6

e3

n1

n6

n3

n1

e9

e3
e5
n3

e2
n3

n1

e2

e3
n1

n7

e8
n2

n4

e6

e1
e7
e8

Figure 13: Four artificial substructures used evaluate Subdue.

amount distortion instances (0, 1 2 distortions). yields total 96
graphs (24 different substructure).

7.2 Experimental Results
7.2.1 Experiment 1: Data compression

first experiment, test Subdue's ability compress structural database. Using
beam width 4 Subdue's pruning mechanism, applied discovery algorithm
databases mentioned above. repeat experiment match thresholds
ranging 0.0 1.0 increments 0.1. Table 1 shows description length (DL)
original graph, description length best substructure discovered Subdue,
graph
value compression. Compression defined DLDLofofcompressed
original graph . Figure 14,
shows actual discovered substructures first four datasets.
seen Table 1, Subdue able reduce database slightly
larger 14 original size best case. average compression value
domains (treating artificial graphs one value) 0.62. results
experiment demonstrate substructure discovered Subdue significantly
reduce amount data needed represent input graph. expect compressing
graph using combinations substructures hierarchies substructures realize
even greater compression databases.
247

fiCook & Holder

Database
DLoriginal Thresholdoptimal DLcompressed Compression
Rubber
371.78
0.1
95.20
0.26
Cortisone
355.03
0.3
173.25
0.49
DNA
2427.93
1.0
2211.87
0.91
Pencils
1592.33
1.0
769.18
0.48
CAD { M1
4095.73
0.7
2148.8
0.52
CAD { S1SegDec
1860.14
0.7
1149.29
0.62
CAD { S1DrvBlk
12715.12
0.7
9070.21
0.71
CAD { BlankSub
8606.69
0.7
6204.74
0.72
CAD { And2
427.73
0.1
324.52
0.76
Artificial (avg. 96 graphs) 1636.25
0.0: : :1.0
1164.02
0.71
Table 1: Graph compression results.

CH 3

H

CH2







C
C

C

C

C

CH

CH
2

2

(a)

C

C

(b)

C
l



(c)



(d)

Figure 14: Best substructure (a) rubber database, (b) cortisone database, (c) DNA
database, (d) image database.

248

fiSubstructure Discovery

Figure 15: Benzene ring discovered Subdue.
7.2.2 Experiment 2: Re-discovery known substructures using background
knowledge

Another way evaluating discovery process evaluate interestingness
discovered substructures. determination value change domain
domain. result, second set experiments test Subdue's ability discover
substructures already labeled important experts domains
consideration.
chemical compound domain, chemists frequently describe compounds terms
building-block components heavily used. example, rubber compound
database shown Figure 7, compound made chain structures
labeled chemists isoprene units. Subdue's ability re-discover structure
exemplified Figure 14a. substructure, discovered using MDL principle
extra background knowledge, represents isoprene unit.
Although Subdue able re-discover isoprene units without extra background
knowledge, substructure affording compression always interesting important substructure database. example, cortisone database
benzene ring consists ring carbons discovered using MDL
principle. However, additional background rules used increase chance
finding interesting substructures domains. case cortisone compound,
know interesting structures exhibit characteristic closure. Therefore,
give strong weight (8.0) compactness background rule use match threshold
0.2 allow deviations benzene ring instances. resulting output, Subdue
finds benzene ring shown Figure 15.
way, use background rules find pencil substructure
image data. image Figure 9 viewed, substructure interest
pencil various forms. However, substructure afforded compression
make entire pencil. know pencils high degree closure
coverage, weights rules set 1.0. weights, Subdue
able find pencil substructure shown Figure 16 tested match thresholds
0.0 1.0.

8. Hierarchical Concept Discovery

substructure discovered, instance substructure input graph
replaced single vertex representing entire substructure. discovery procedure
repeated compressed data set, resulting new interesting substructures.
newly-discovered substructures defined terms existing substructure concepts,
substructure definitions form hierarchy substructure concepts.
249

fiCook & Holder

l

l




l

Figure 16: Pencil substructure discovered Subdue.

Hierarchical concept discovery also adds capability improve Subdue's performance. Subdue applied large input graph, complexity algorithm
prevents consideration larger substructures. Using hierarchical concept discovery, Subdue first discover smaller substructures best compress data. Applying
compression reduces graph manageable size, increasing chance
Subdue find larger substructures subsequent passes database.
Subdue selects substructure, vertices comprise exact instances
substructure replaced graph single vertex representing discovered
substructure. Edges connecting vertices outside instance vertices inside instance
connect new vertex. Edges internal instance removed. discovery
process applied compressed data. hierarchical description concepts
particularly desired, heavier weight given substructures utilize previously
discovered substructures. increased weight ects increased attention substructure. Figure 17 illustrates compressed rubber compound graph using substructure
shown Figure 14a.
demonstrate ability Subdue find hierarchy substructures, let system make multiple passes database represents portion DNA molecule.
Figure 8 shows portion two chains double helix, using three pairs bases
held together hydrogen bonds. Figure 18 shows substructures found Subdue
three passes data. Note that, third pass, Subdue linked
together instances substructure second pass find chains double
helix.
Although replacing portions input graph discovered substructures compresses data provides basis discovering hierarchical concepts data,
substructure replacement procedure becomes complicated concepts inexact
instances discovered. inexact instances discovered concept replaced
single vertex data, distortions graph (differences instance
graph substructure definition) must attached annotations vertex label.
250

fiSubstructure Discovery

Highest-valued substructure

CH 3

H

=
1

C

C
CH

CH

2

2

Compressed graph using discovered substructure

G

S1

=

CH

CH

C
2

C
2

CH

CH

2

2
C

CH 3

CH

H

3

C
CH

S1

S1

CH

H

3

=

S1


1

C

C
CH

CH

2

2

CH

CH

2

2

C

C
CH 3

H

H

3

CH

2

C
H

Figure 17: Compressed graph rubber compound data.

251

C
CH

2

fiCook & Holder

Highest-valued substructure
First Pass

CH2

S1 =




Highest-valued substructure
Second Pass

S1

C

CH2



S2 =

=


P
P


CH2

Highest-valued substructure
Third Pass





S2

P

OH

OH


=

S3 =

CH2



S2

OH



S2

OH




P



OH

CH2




P

OH


Figure 18: Hierarchical discovery DNA data.

252

fiSubstructure Discovery

9. Conclusions

Extracting knowledge structural databases requires identification repetitive substructures data. Substructure discovery identifies interesting repetitive structure
structural data. substructures represent concepts found data means
reducing complexity representation abstracting instances substructure. shown minimum description length (MDL) principle used
perform substructure discovery variety domains. substructure discovery process
also guided background knowledge. use inexact graph match allows
deviation instances substructure. substructure discovered, instances
substructure replaced concept definition, affording compression
data description providing basis discovering hierarchically-defined structures.
Future work combine structural discovery discovery concepts using linearbased representation AutoClass (Cheeseman, Kelly, Self, Stutz, Taylor, & Freeman,
1988). particular, use Subdue compress data fed AutoClass,
let Subdue evaluate interesting structures classes generated AutoClass.
addition, developing parallel implementation AutoClass / Subdue
system enable application substructure discovery larger structural databases.

Acknowledgements

project supported NASA grant NAS5-32337. authors would like thank
Mike Shay National Semiconductor providing circuit data. would also like
thank Surnjani Djoko Tom Lai help project. Thanks also
reviewers numerous insightful comments.

References

Bunke, H., & Allermann, G. (1983). Inexact graph matching structural pattern recognition. Pattern Recognition Letters, 1 (4), 245{253.
Cheeseman, P., Kelly, J., Self, M., Stutz, J., Taylor, W., & Freeman, D. (1988). Autoclass:
bayesian classification system. Proceedings Fifth International Workshop
Machine Learning, pp. 54{64.
Conklin, D., & Glasgow, J. (1992). Spatial analogy subsumption. Proceedings
Ninth International Machine Learning Workshop, pp. 111{116.
Derthick, M. (1991). minimal encoding approach feature discovery. Proceedings
Ninth National Conference Artificial Intelligence, pp. 565{571.
Fisher, D. H. (1987). Knowledge acquisition via incremental conceptual clustering. Machine
Learning, 2 (2), 139{172.
Fu, K. S. (1982). Syntactic Pattern Recognition Applications. Prentice-Hall.
Holder, L. B., Cook, D. J., & Bunke, H. (1992). Fuzzy substructure discovery. Proceedings
Ninth International Machine Learning Conference, pp. 218{223.
253

fiCook & Holder
Holder, L. B., & Cook, D. J. (1993). Discovery inexact concepts structural data.
IEEE Transactions Knowledge Data Engineering, 5 (6), 992{994.
Jeltsch, E., & Kreowski, H. J. (1991). Grammatical inference based hyperedge replacement. Fourth International Workshop Graph Grammars Application
Computer Science, pp. 461{474.
Leclerc, Y. G. (1989). Constructing simple stable descriptions image partitioning. International journal Computer Vision, 3 (1), 73{102.
Levinson, R. (1984). self-organizing retrieval system graphs. Proceedings
Second National Conference Artificial Intelligence, pp. 203{206.
Michalski, R. S., & Stepp, R. E. (1983). Learning observation: Conceptual clustering.
Michalski, R. S., Carbonell, J. G., & Mitchell, T. M. (Eds.), Machine Learning:
Artificial Intelligence Approach, Vol. I, pp. 331{363. Tioga Publishing Company.
Miclet, L. (1986). Structural Methods Pattern Recognition. Chapman Hall.
Pednault, E. P. D. (1989). experiments applying inductive inference principles
surfa ce reconstruction. Proceedings International Joint Conference
Artificial Intelligence, pp. 1603{1609.
Pentland, A. (1989). Part segmentation object recognition. Neural Computation, 1,
82{91.
Prather, R. (1976). Discrete Mathemetical Structures Computer Science. Houghton
Min Company.
Quinlan, J. R., & Rivest, R. L. (1989). Inferring decision trees using minimum description length principle. Information Computation, 80, 227{248.
Rao, R. B., & Lu, S. C. (1992). Learning engineering models minimum description length principle. Proceedings Tenth National Conference Artificial
Intelligence, pp. 717{722.
Rissanen, J. (1989). Stochastic Complexity Statistical Inquiry. World Scientific Publishing
Company.
Schalkoff, R. J. (1992). Pattern Recognition: Statistical, Structural Neural Approaches.
John Wiley & Sons.
Segen, J. (1990). Graph clustering model learning data compression. Proceedings
Seventh International Machine Learning Workshop, pp. 93{101.
Thompson, K., & Langley, P. (1991). Concept formation structured domains. Fisher,
D. H., & Pazzani, M. (Eds.), Concept Formation: Knowledge Experience Unsupervised Learning, chap. 5. Morgan Kaufmann Publishers, Inc.
Waltz, D. (1975). Understanding line drawings scenes shadows. Winston, P. H.
(Ed.), Psychology Computer Vision. McGraw-Hill.
254

fiSubstructure Discovery
Wertheimer, M. (1939). Laws organization perceptual forms. Ellis, W. D. (Ed.),
Sourcebook Gestalt Psychology, pp. 331{363. Harcourt, Brace Company.
Winston, P. H. (1975). Learning structural descriptions examples. Winston, P. H.
(Ed.), Psychology Computer Vision, pp. 157{210. McGraw-Hill.
Yoshida, K., Motoda, H., & Indurkhya, N. (1993). Unifying learning methods colored
digraphs. Proceedings Learning Knowledge Acquisition Workshop
IJCAI-93.
Zahn, C. T. (1971). Graph-theoretical methods detecting describing gestalt clusters.
IEEE Transactions Computers, 20 (1), 68{86.

255

fiJournal Artificial Intelligence Research 1 (1994) 139-158

Submitted 9/93; published 1/94

Teleo-Reactive Programs Agent Control
Nils J. Nilsson

nilsson@cs.stanford.edu

Robotics Laboratory, Department Computer Science
Stanford University, Stanford, CA 94305 USA

Abstract

formalism presented computing organizing actions autonomous agents
dynamic environments. introduce notion teleo-reactive (T-R) programs whose
execution entails construction circuitry continuous computation parameters conditions agent action based. addition continuous feedback,
T-R programs support parameter binding recursion. primary difference
T-R programs many circuit-based systems circuitry T-R programs
compact; constructed run time thus anticipate
contingencies might arise possible runs. addition, T-R programs
intuitive easy write written form compatible automatic
planning learning methods. brie describe experimental applications T-R
programs control simulated actual mobile robots.
1. Introduction

Autonomous agents, mobile robots, typically operate dynamic uncertain
environments. environments sensed imperfectly, effects
always completely predictable, may subject changes agent's
control. Designing agents operate environments presented challenges
standard methods artificial intelligence, based explicit declarative representations reasoning processes. Prominent among alternative approaches
so-called behavior-based, situated, animat methods (Brooks, 1986; Maes, 1989; Kaelbling & Rosenschein, 1990; Wilson, 1991), convert sensory inputs actions
much direct fashion AI systems based representation reasoning. Many
alternative approaches share control theory central notion continuous
feedback environment necessary component effective action.
Perhaps relatively easier control theorists computer scientists
deal continuous feedback control theorists accustomed thinking
controlling mechanisms composed analog electrical circuits physical
systems rather automata discrete read-compute-write cycles. notions
goal-seeking servo-mechanisms, homeostasis, feedback, filtering, stability|so essential
control dynamic environments|were developed analog circuitry mind.
Circuits, nature, continously responsive inputs.
contrast, central ideas computer science, namely sequences, events,
discrete actions, subroutines, seem odds notion continuous feedback.
example, conventional programming one program calls another, calling
program suspended called program returns control. feature awkward
applications called program might encounter unexpected environmental

c 1994 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.

fiNilsson

circumstances designed cope. cases, calling program
regain control interrupts explicitly provided programmer.
sure, attempts blend control theory computer science.
example, work Ramadge Wonham (Ramadge & Wonham, 1989) discrete-event
systems used computer science notions events, grammars, discrete states
study control processes ideas appropriate. book Dean
Wellman (Dean & Wellman, 1991) focusses overlap control theory
artificial intelligence. little effort import fundamental control-theory
ideas computer science. precisely set paper.
propose computational system works differently conventional ones.
formalism call circuit semantics (Nilsson, 1992); program execution produces
(at least conceptually) electrical circuits, circuits used control.
importing control-theory concept continuous feedback, nevertheless want
retain useful ideas computer science. control programs parameters
bound run time passed subordinate routines. hierarchical
organization, recursive. contrast behavior-based
approaches, want programs responsive stored models environment
well immediate sensory inputs.
presentation ideas somewhat informal line belief
formalization best done certain amount experience obtained. Although
preliminary experiments indicate formalism works quite well, work remains
done establish place agent control.
2. Teleo-Reactive Sequences
2.1 Condition-Action Rules

teleo-reactive (T-R) sequence agent control program directs agent toward
goal (hence teleo) manner takes account changing environmental circumstances
(hence reactive). simplest form, consists ordered set production rules:

K1
K2

!
!

a1
a2

111

Ki

!

ai

111

Km

!



Ki conditions (on sensory inputs model world), ai
actions (on world change model). T-R sequence interpreted
manner roughly similar way production systems interpreted.
list rules scanned top first rule whose condition part satisfied,
corresponding action executed. T-R sequences differ substantively conventional
production systems, however. T-R actions durative rather discrete. durative
140

fiTeleo-Reactive Programs

action one continues indefinitely. example, mobile robot capable executing
durative action move, propels robot ahead (say constant speed) indefinitely.
action contrasts discrete one, move forward one meter. T-R
sequence, durative action continues long corresponding condition remains first
true condition. first true condition changes, action changes correspondingly.
Thus, unlike production systems computer science, conditions must continuously
evaluated; action associated currently first true condition always one
executed. action terminates energizing condition ceases
first true condition.
Indeed, rather thinking T-R sequences terms computer science idea
discrete events, appropriate think implemented circuitry.
example, sequence implemented circuit shown figure 1.
Furthermore, imagine conditions, Ki , also continuously computed.
sensors

model

conditioncomputing
circuits

K1

a1


^

K2

a2



K3

^

a3

^





Km

Figure 1: Implementing T-R Sequence Circuitry
actions, ai , T-R sequence either primitive actions, T-R
sequences themselves. Thus, programs written formalism hierarchical (even
recursive, shall see later). case hierarchical programs, important
realize conditions levels hierarchy continuously evaluated;
high level sequence redirect control different path lower level sequences
dictated values conditions various levels.
141

fiNilsson

writing T-R sequence, programmer ordinarily works backward whatever goal
condition sequence designed achieve. condition K1 taken
goal condition, corresponding action, a1, null action. condition K2
weakest condition satisfied (and K1 not), durative execution
a2 (all things equal) eventually achieve K1 . on. non-null
action, ai , supposed achieve condition, Kj , strictly higher list (j < i).
conditions therefore regressions (Nilsson, 1980) higher conditions actions
achieve higher conditions.
Formally, say T-R sequence satisfies regression property condition,
> 1), regression higher condition sequence, Kj (j < i),
action ai . say T-R sequence complete K1 _ 1 1 1 _ Ki _
1 1 1 _ Km tautology. T-R sequence universal satisfies regression property
complete. easy see universal T-R sequence always achieve goal
condition, K1 , sensing execution errors.

Ki (m

Sometimes action effect anticipated agent's designer
(the normal effect), sometimes exogenous events (separate actions
agent) change world unexpected ways. phenomena, course, reason
continuous feedback required. Universal T-R sequences, like universal plans (Schoppers,
1987), robust face occasional deviations normal execution.
also exploit serendipitous effects; may accidentally happen action achieves
condition higher list condition/action rules normally expected. Even
action sometimes achieve normal effect (due occasional sensing execution
errors), nevertheless action executed. long environment
often frustrate achievement normal effects actions, goal condition
universal T-R sequence ultimately achieved.

2.2 Example

following rather simple example make ideas concrete. Consider
simulated robots figure 2. Let's suppose robots move bars around
two-dimensional world. robot right holding bar, want
robot go grab bar marked A. presume robot sense
environment evaluate conditions tell whether already grabbing
bar (is-grabbing), facing toward bar (facing-bar), positioned respect bar
reach grab (at-bar-center), perpendicular bisector bar
(on-bar-midline), facing zone perpendicular bisector bar
would appropriate move toward bar (facing-midline-zone). Let's assume also
conditions appropriate amount hysteresis hunting behavior
dampened. Suppose robot capable executing primitive actions grab-bar, move,
rotate obvious effects. Execution following T-R sequence result
robot grabbing bar A:
142

fibar-midline



bar-center

midline-zone

Figure 2: Robots Bars
Notice properly executed action sequence achieves condition
rule it. way, actions inexorably proceed toward goal. Occasional
setbacks merely cause delays achieving goal long actions usually1 achieve
normal effects.
3. Teleo-Reactive Programs
3.1 Rules Variables

generalize notion T-R sequence permitting rules contain free
variables bound sequence \called." call sequence T-R
program. Additional generality obtained assume variables necessarily
bound constants quantities whose values continuously computed (as
circuitry) environment changes.
simple example involving robot go designated goal location two
dimensions serve illustrate. Suppose goal location given value
variable loc. run time, loc bound pair X; coordinates, although allow
binding change run time. time process, robot's X;
position given value variable position. (We assume robot
kind navigational aid reliably continuously computes value position.)
instantaneous values loc position, robot compute direction
1. choose define usually precisely here, although probabilistic analysis could given.

143

fiNilsson

face proceed straight line toward loc. Let value direction
time given value function course(position, loc). time
process, robot's angular heading given value variable heading. Using
variables, T-R program drive robot loc is:
goto(loc)
equal(position, loc)
equal(heading, course(position, loc))


!
!
!

nil
move
rotate

Implementing goto(loc) circuitry straightforward. single parameter
program loc whose (possibly changing) value specified run time user,
higher level program, circuitry. (global) parameters, position heading,
provided circuitry, assume function course continuously
computed circuitry. Given values parameters, computing action
energize computed circuitry manner figure 1.
3.2 Hierarchical Programs

formalism allows writing hierarchical recursive programs actions
rules T-R programs. example, write recursive navigation
program calls goto. new navigation program requires complex sensory
functions. Imagine function clear-path(place1, place2) value
direct path clear place1 place2. (We assume robot compute
function, continuously, place1 = position, place2 equal target location.)
Also imagine function new-point(place1, place2) computes intermediate position
place1 place2 whenever clear-path value . value newpoint lies appropriately side obstacle determined place1
place2 (so robot heads toward new-point first toward place2,
navigate around obstacle). clear-path new-point continuously computed
perceptual systems endow robot. We'll name new navigation
program amble(loc). code:
amble(loc)
equal(position, loc)
clear-path(position, loc)


!
!
!

nil
goto(loc)
amble(new-point(position, loc))

show figure 3 path robot controlled program might take
navigating around obstacles shown. (The program doesn't necessarily compute shortest
paths; present program simply illustration recursion.) Note
obstacle positions goal location change execution, changes ected
values parameters used program, program execution proceed
manner appropriate changes. particular, clear path ever becomes manifest
144

figoal location

Figure 3: Navigating using amble
continuous computation parameters involved T-R programs ability
high level programs redirect control account great robustness formalism.
formal syntax T-R programs given (Nilsson, 1992).
3.3 Implementational Issues

T-R formalism, implicit assumption continuous computation conditions
parameters, thought fully legitimate \level" hierarchy program
structure controlling agent, regardless level implemented levels below|
computer scientists think list processing level actual operation even though
implemented primitive logical operations below. assume (as do)
pace events agent's environment slow compared amount time
taken perform \continuous" computations required T-R program, T-R
programmer justified assuming \real" continuous sensing s/he writes programs (even
though underlying implentation may involve discrete sampling). recommend
T-R formalism applications assumption justified.
applications, T-R level shields programmer worry
level implemented greatly facilitates program construction.
several different ways T-R programs interpreted lower
level implementations. beyond scope paper point
obvious methods, leave important questions properties methods
subsequent research. One method implementation involves construction actual
simulated circuits according basic scheme figure 1. First, top level conditioncomputing circuits (including circuits computing parameters used conditions)
constructed allowed function. specific action, say ai , energized result. ai
145

fiNilsson

primitive, turned on, keeping circuitry place functioning
top-level action energized, on. ai T-R sequence, circuitry needed
implement constructed (just done top level), action selected,
on|and levels circuitry left functioning. new lower level
circuitry constructed, circuitry longer functioning (that is, circuitry longer
\called" functioning higher level circuitry) garbage collected.
important questions parameter passing timing process
deal here|relying assumption times needed create circuitry circuitry function negligible compared pace events
world. assumption similar synchrony hypothesis ESTEREL programming language (Berry & Gonthier, 1992) assumed program's reaction \. . .
takes time respect external environment, remains invariant [the
reaction]."
Although reason principle circuitry could simulated actually
constructed (using sort programmable network logic gates), also straightforward implement T-R program using standard computational techniques. T-R
programs written LISP cond statements, durative actions simulated
iterating short action increments. example, increment move action
simulated robot might move robot ahead small amount. action
increment, top level LISP cond executed anew, course functions
parameters contains evaluated anew. simulations robots moving
two-dimensional worlds (to discussed below), computations involved suciently
fast effect reasonable pace apparent smooth motion.
implementation method essentially involves sampling environment irregular
intervals. course, questions concerning computation times (and thus
sampling rate) affect real-time aspects agent behavior address
here|again assuming sampling rate short.
Whatever method used interpret T-R programs, care must taken con ate
T-R level levels below. programmer ought think
circuit simulators sampling intervals imagine sensing done continuously
immediately.
3.4 Graphical Representations

goto program represented graph well list rules used earlier.
graphical representation program shown figure 4. nodes labeled
conditions, arcs actions. execute graphical version program,
look shallowest true node (taking goal condition root) execute
action labeling arc leading node.
graph figure 4, action normally achieves condition head arc
(when condition tail arc shallowest true condition).
one action achieve condition, would tree instead single-path
graph. general graph, then, teleo-reactive tree depicted figure 5.
T-R trees executed searching shallowest true node executing action
labeling arc leaving node. Alternatively, could search true node judged
146

fiTeleo-Reactive Programs

equal(position, loc)

move
equal(heading, course(position, loc))

rotate


Figure 4: Graphical Representation goto
path least cost goal, appropriate heuristic measure cost
used. [For simplicity, phrase \shallowest true node" taken mean either
shallowest true node (literally) true node path least cost goal.] Ties
among several equally shallow true nodes broken according fixed tie-breaking rule.
figure 5 see that, particular, least two ways achieve condition K1 .
One way uses action a2 (when K2 shallowest true node), one way uses action a3
(when K3 shallowest true node).
analogy definitions given T-R sequences, T-R tree satisfies regression
property every non-root node regression parent node action linking
parent. T-R tree complete disjunction conditions
tautology. T-R tree universal satisfies regression property
also complete. fixed tie-breaking rule, T-R tree becomes T-R sequence.
T-R tree universal, corresponding T-R sequence.
One might first object method executing T-R tree grounds
sequence actions emerge hop erratically one path another.
tree satisfies regression property, heuristic measuring cost
goal reasonable, (however erratic actions may appear be), successfully
executed action brings agent closer goal.
4. Experiments

carried several preliminary experiments agents programmed language (using LISP cond statements short action increments). One set experiments
uses simulated robots acting two-dimensional space, called Botworld 2, construction
2. original Botworld interface, including primitive perceptual functions actions robots,
designed implemented Jonas Karlsson NeXT computer system (Karlsson, 1990). Sub-

147

fiNilsson

K1
a2

a3

K2

K3

Km -1

Km

Figure 5: T-R Tree
materials, structures made materials, robots. construction materials bars, robots build structures connecting bars various ways.
robot turn move, grab release suitably adjacent bar, turn move
grabbed bar, connect bar bars structures. robots continuously
sense whether holding bar, \see" front (giving
information location bars structures). existence
robots may change world sometimes unexpected ways, important
robot sense certain critical aspects environment continuously.
typical Botworld graphical display shown figure 6.
written various T-R programs cause robots build structures
various kinds (like triangle constructed figure 6). robot controlled one
programs exhibits homeostatic behavior. long main goal (whatever is)
satisfied, robot inactive. Whenever goal (for whatever reason) satisfied,
robot becomes active persists achieves goal. another agent achieves
part goal, robot carries appropriately situation finds
complete process.
experiments, conditions used T-R rules conditions model
environment robot constructs sensory system maintains separately
T-R mechanism. use model permits robot perform actions
response sensory stimuli (past present) used help construct
model. But, T-R actions include direct changes model (in addition
sequently, Patrick Teo implemented version runs X-windows several different workstations (Teo, 1991, 1992). latter version allows simulation several robots simultaneously|
control independently running process.

148

fiTeleo-Reactive Programs

Figure 6: Botworld Display
changes resulting perceived changes environment), potential
undesirable instabilities (as system positive feedback). (The problem
model environment model updated response sensory
data separate major research problem outside scope work reported here.)
experiments, used Nomadic Technologies 100 series mobile robot.
robot equipped ring 16 infrared sensors ring 16 sonar sensors.
controlled via radio modem Macintosh II running Allegro Common Lisp.
implemented robust T-R programs simple oce-environment tasks,
wall-following corridor-following (Galles, 1993). programs initially developed
debugged using Nomadics simulator actual robot; changes
made porting programs simulator robot. performing tasks,
robot highly reactive persistent even face occasional extreme sonar
infrared range errors deliberate attempts confuse it. robot quickly adapts
sudden changes environment, caused people sharing hallways.
writing T-R programs, one need concerned inventing appropriate
predicates using available perceptual functions model database. One need
worry providing interrupts lower level programs higher level ones regain
control. found debugging T-R programs presents challenges, though.
Since designed quite robust face environmental uncertainty,
also sometimes work rather well even though completely debugged.
residual errors might undesirable effects programs used higher
level programs|making higher ones dicult debug.
149

fiNilsson

5. Approaches Specifying Behavior

several formalisms proposed prescribing sensory-directed, real-time
activity dynamic environments. closely related T-R formalism
proposed here. section point major similarities differences T-R
programs representative, though complete, sample closest relatives.
reactive formalisms two types, namely, sample environments
discrete intervals (perhaps rapidly enough suciently reactive),
create circuitry (like T-R programs). discrete-sampling systems abstract
activity higher level environment monitored continuously,
circuitry-creating systems prior run time (unlike T-R programs create
circuitry run time).
5.1 Discrete-Sampling Systems
5.1.1 Production Systems

already mentioned, T-R programs similar production systems (Waterman & Hayes-Roth, 1978). intermediate-level actions (ILAs) used SRI robot
Shakey (Nilsson, 1984) programmed using production rules much like
T-R programs. T-R program also resembles plan represented triangle-table form
constructed STRIPS (Fikes, Hart & Nilsson, 1972). conditions T-R
sequence corresponds triangle table kernel. PLANEX execution system triangle tables, action corresponding highest-numbered satisfied kernel executed.
major difference previous production-system style programs TR programs T-R programs continuously responsive environment
ordinary production systems not.
5.1.2 Reactive Plans

Several researchers adopted approach using current situation index
set pre-arranged action sequences (Georgeff & Lansky, 1987; Schoppers, 1987; Firby,
1987). set either large enough cover substantial number situations
agent likely find cover possible situations. latter
case, plan set said universal. Unlike T-R programs, systems explicitly
sample environments discrete time steps rather continuously. T-R
programs, time-space trade-offs must taken account considering many
different conditions must anticipated providing reactive plans. Ginsberg noted
several domains, number situations likely encountered agent
intractably large agent forced postpone planning run time
situations actually encountered (Ginsberg, 1989). (For discussion
point, see (Selman, 1993).) T-R programs advantage least rudimentary
form planning, namely parameter binding, done run time. PRS system (Georgeff
& Lansky, 1987) capable extensive planning run time well reacting
appropriately current situation.
150

fiTeleo-Reactive Programs

5.1.3 Situated Control Rules

Drummond (Drummond, 1989) introduces notion plan net kind Petri
net (Reisig, 1985) representing effects actions (which executed parallel).
Taking account possible interactions actions, projects effects
possible actions present state horizon. effects represented
structure called plan projection. plan projection analyzed see, state
it, states possibly path goal state. analysis forward version
backward analysis used programmer producing T-R tree. Situated control
rules result analysis; constrain actions might taken
state result state still possibly path goal. Plan
nets Petri nets based discrete events thus continuously responsive
environments way T-R programs are.
5.2 Circuit-Based Systems

Kaelbling proposed formalism called GAPPS (Kaelbling, 1988; Kaelbling & Rosenschein, 1990), involving goal reduction rules, implicitly describing achieve goals.
GAPPS programmer defines activity agent providing sucient goal reduction rules connect agent's goals situations might find itself.
rules compiled circuitry real-time control agent. Rosenschein
Kaelbling (Rosenschein & Kaelbling, 1986) call circuitry situated automata.
collection GAPPS rules achieving goal thought implicit
specification T-R program computations needed construct program
performed rules compiled. GAPPS programmer typically exerts less
specific control agent's activity|leaving work search process
performed GAPPS compiler. example, T-R program achieve goal, p ,
implicitly specified following GAPPS rule:
(defgoalr (ach ?p)
(if ((holds ?p) (do nil))
((holds (regress ?a ?p)) (do ?a))
(T ach (regress ?a ?p)) ))

recursion defined rule bottoms rules form:
(defgoalr (ach )
((holds

) (do

ff)) )

conditions ff specific action.
GAPPS compiles rules circuitry run time, whereas circuit implementation T-R program depends parameters bound run time. systems
result control continuously responsive environment.
implementing system play video game, Chapman (Chapman, 1990) compiles
production-like rules digital circuitry real-time control using approach
calls \arbitration macrology." situated automata, compilation process occurs
prior run time.
Brooks developed behavior language, BL, (Brooks, 1989), writing reactive
robot control programs based \subsumption architecture" (Brooks, 1986). similar
language, ALFA, implemented Gat (Gat, 1991). Programs written
151

fiNilsson

languages compile structures much like circuits. Again, compilation occurs prior
run time. relatively straightforward translate examples subsumptionarchitecture programs T-R programs.
circuit-based systems, pre-run-time compiling means circuitry
must built might needed given run possible contingencies
must anticipated compile time.3 T-R programs, parameters bound run
time, circuitry required specific bindings constructed.
6. Future Work

T-R formalism might easily augmented embody features
discussed paper. Explicit reference time specifying actions might necessary.
example, might want make sure action initiated
time t1 ceases time t2. Time predicates, whose time terms evaluated
using internal clock, may suce purpose.
Also, applications may want control conditions T-R program
actually tested. may be, example, conditions won't checked
truth falsity guessed compelling accuracy.
Simultaneous asynchronous execution multiple actions achieved allowing right-hand side rules contain sets actions. member set
duratively executed asynchronously independently (so long condition
rule sustains set remains highest true condition). course, programmer
must decide conditions appropriate call parallel actions. Future
work related formalisms might reveal ways parallel actions might emerge
interaction program environment rather explicitly
programmed.
Although intend T-R programs agent control written human programmers, also interested methods modifying automatic planning
machine learning. brie discuss preliminary ideas planning
learning here.
T-R trees resemble search trees constructed planning systems work
backwards goal condition. overall goal root tree; non-root
node gi regression parent node, gj action, ak , connecting them.
similarity suggests T-R trees constructed (and modified) automatic
planning system capable regressing conditions durative actions. Indeed triangle
tables (Fikes, Hart & Nilsson, 1972), degenerate form T-R tree consisting
single path, constructed automatic planning system EBL-style generalizer
(Mitchell, Keller & Kedar-Cabelli, 1986).
reader might object reason suppose search trees produced automatic planning process contain nodes whose conditions
agent likely encounter behavior. process incremental modification, however, gradually make constructed trees matched agent's
environment. tree achieving desired goal true nodes certain situation,
3. Agre's \running arguments" construct (Agre, 1989) one example circuit-based system
add circuitry run time needed.

152

fiTeleo-Reactive Programs

search process employed automatic planner yet terminated
subgoal search tree satisfied current state. case,
planning system called upon continue search; is, existing T-R tree
expanded true node produced. Pruning T-R trees accomplished
keeping statistics often nodes satisfied. Portions trees never
seldom used erased. Early unpublished work Scott Benson indicates T-R
programs effectively generated automatic planning methods (Benson, 1993).
considering learning mechanisms, note first T-R sequences related
class Boolean functions Rivest termed k-decision lists (Rivest, 1987; Kohavi &
Benson, 1993). k-decision list ordered list condition-value pairs
condition conjunction Boolean variables length k, value truth
value (T F ). value Boolean function represented k-decision list
value associated highest true condition. Rivest shown functions
polynomially PAC learnable presented supervised learning procedure them.
see T-R sequence whose conditions limited k-length conjunctions
Boolean features slight generalization k-decision lists. difference
T-R sequence two different \values" (that is, actions).
observe T-R sequence (with, say, n different actions) also PAC learnable
since actions encoded log2 n decision lists. George John (John, 1993)
investigated supervised learning mechanism learning T-R sequences.
Typically, conditions used T-R programs conjunctions propositional features robot's world and/or model. linear threshold function implement
conjunctions, one led propose neural net implementation T-R sequence. neural net implementation, turn, evokes ideas possible learning mechanisms. Consider
T-R sequence:

K1
K2

!
!

a1
a2

111

Ki

!

ai

111

Km

!



Suppose stipulate Ki linear threshold functions set propositional
features. ai necessarily distinct; fact assume
k distinct actions. Let denoted b1; 1 1 1 ; bk . network structure figure
7 implements T-R sequence.
propositional features tested conditions grouped n-dimensional
binary (0,1) vector, X called input vector. conditions implemented
threshold elements weighted connections components input vector.
process finding first true condition implemented layer containing appropriate
inhibitory weights units one unit ever output
value 1, unit corresponds first true condition. unique action associated
condition layer binary-valued weights OR-unit associators.
153

fiNilsson

inhibitory weights
1 0 weights

X

K1

V

b1

K2

V

b2

...

...

bi

V

Ki

...

...

Km
input
vector

...
...
bk

V

units

conditions

associators

actions

(OR
units)

Figure 7: Neural Net Implements T-R Sequence
unit connected one one associator non-zero weight. Since
one unit non-zero output, unit's associator non-zero
output. (But associator could connected multiple units.) example,
action bi associated conditions Kj Kl , unit weights
j-th l-th units associator representing action bi zero-valued weights
units associator. action selected execution action
corresponding single associator non-zero output. investigating
various learning methods suggested neural net implementation.
Work must also done question constitutes goal. assumed
goals achievement. mechanisms found continously avoid making certain
conditions true (or false) attempting achieve others? suppose priorities
number possibly mutually contradictory conditions specified; reasonable
methods attending achievable goals highest priorities?
Also, interesting ask sense T-R programs proved correct.
would seem verification would make assumptions dynamics
environment; environments might malevolent agents could never
achieve goals. Even so, verifier equipped model effects actions could
least check see regression property satisfied note lapses.
work remains methods implementing interpreting T-R programs
real-time properties implementations. properties will, course, depend
depth T-R program hierarchy conditions features must
evaluated.
154

fiTeleo-Reactive Programs

Finally, might worthwhile investigate \fuzzy" versions T-R trees. One could
imagine fuzzy predicates would energize actions \strength" depends
degree predicates true. SRI robot, Flakey, uses fuzzy controller
(Saotti, Ruspini & Konolige, 1993).
7. Conclusions

presented formalism specifying actions dynamic uncertain domains. Since
work rests ideas somewhat different conventional computer science,
expect considerably analysis experimentation required T-R
formalism fully evaluated. need robotics control-theoretic ideas
homeostasis, continuous feedback, stability appears suciently strong, however,
seems appropriate candidate formalisms embodying ideas put forward
consideration.
Experiments language produce stock advice write T-R
programs effectively. Already, example, apparent sustaining condition
T-R sequence must carefully specified restrictive really needs
be; overly restrictive condition likely rendered false action
supposed sustain action succeeds making higher condition
sequence true. But, course, overly restrictive conditions won't occur T-R programs
satisfy regression property.
usefully employed, T-R programs (or programs controlling agent action)
need embodied overall agent architecture integrates perceptual processing,
goal selection, action computation, environmental modeling, planning learning
mechanisms. Several architectural schemes suggested, summarize
except say three layers control often delineated. typical example
SSS architecture Connell (Connell, 1993). top (Symbolic) layer overall
goal setting sequencing, middle (Subsumption) level selects specific actions,
lower (Servo) level exerts standard feedback control effectors. believe T-R
programs would appropriately used middle level architectures.
major limitation T-R programs involve much computation
programs check relevant conditions. conditions computed
T-R program selecting action either irrelevant situation hand
values might accurately predicted (if programmer wanted take trouble
so). essentially trading computing time ease programming,
particular trade advantageous certain applications. Among these, think,
mid-level control robots (possibly) software agents.
conclusion, three main features embodied T-R formalism. One
continuous computation parameters conditions action based. TR programs allow continuous feedback still supporting parameter binding
recursion. second feature regression relationship conditions T-R
program. condition regression condition closer goal
action normally achieves closer-to-the-goal condition. regression property
assures robust goal-seeking behavior. Third, conceptual circuitry controlling action
constructed run time, feature permits programs universal still
155

fiNilsson

compact. addition, T-R programs intuitive easy write written
formalism compatible automatic planning learning methods.
Acknowledgements

trace interest reactive, yet purposive, systems early collaborative work
triangle tables ILAs. Several former Stanford students, including Jonas Karlsson, Eric
Ly, Rebecca Moore, Mark Torrance, helped early stages work. also
want thank sabbatical hosts, Prof. Rodney Brooks MIT, Prof. Barbara Grosz
Harvard, people Santa Fe Institute. recently, benefitted
discussions Scott Benson, George John, Ron Kohavi. also thank anonymous
referees helpful suggestions. work performed NASA Grant NCC2494 NSF Grant IRI-9116399.
References

Agre, P. (1989). Dynamic Structure Everyday Life. Tech. rep. TR 1085, AI Lab.,
Massachusetts Institute Technology.
Benson, S. (1993). Unpublished working paper. Robotics Laboratory, Stanford University.
Berry, G., & Gonthier, G. (1992). ESTEREL Synchronous Programming Language.
Science Computer Programming, 19, no. 2, 87-152, November.
Brooks, R. (1986). Robust Layered Control System Mobile Robot. IEEE Journal
Robotics Automation, March.
Brooks, R. (1989). Behavior Language User's Guide. Seymour Implementation Note 2,
AI Lab., Massachusetts Institute Technology.
Chapman, D. (1990). Vision, Instruction Action. Tech. rep. 1204, AI Lab., Massachusetts Institute Technology.
Connell, J. (1993). SSS: Hybrid Architecture Applied Robot Navigation. Research
Report, IBM Research Division, T. J. Watson Research Center, Yorktown Heights,
NY 10598.
Dean, T., & Wellman, M. (1991). Planning Control. San Francisco, CA: Morgan Kaufmann.
Drummond, M. (1989). Situated Control Rules. Proc. First International Conf. Principles Knowledge Representation Reasoning. San Francisco, CA: Morgan Kaufmann.
Fikes, R., Hart, P., & Nilsson, N. (1972). Learning Executing Generalized Robot Plans.
Artificial Intelligence, 3, 251-288.
Firby, R. (1987). Investigation Reactive Planning Complex Domains. Proc.
AAAI-87. San Francisco, CA: Morgan Kaufmann.
156

fiTeleo-Reactive Programs

Galles, D. (1993). Map Building Following Using Teleo-Reactive Trees. Intelligent
Autonomous Systems: IAS-3, Groen, F. C. A., Hirose, S. & Thorpe, C. E. (Eds.),
390-398. Washington: IOS Press.
Gat, E. (1991). ALFA: Language Programming Reactive Robotic Control Systems.
Proceedings 1991 IEEE Robotics Automation Conference.
Georgeff, M., & Lansky, A. (1989). Reactive Reasoning Planning. Proc. AAAI-87.
San Francisco, CA: Morgan Kaufmann.
Ginsberg, M. L. (1989). Universal Planning: (Almost) Universally Bad Idea. AAAI
Magazine, 10, no. 4, 40-44, Winter.
John, G. (1993). `SQUISH: Preprocessing Method Supervised Learning T-R Trees
Solution Paths, (unpublished). Robotics Laboratory, Stanford University.
Kaelbling, L. P. (1988). Goals Parallel Program Specifications. Proceedings AAAI-88,
60-65. Menlo Park, CA: American Association Artificial Intelligence.
Kaelbling, L. P., & Rosenschein, S. J. (1990). Action Planning Embedded Agents.
Robotics Autonomous Systems, 6, nos. 1 2, 35-48, June.
Karlsson, J. (1990). Building Triangle Using Action Nets. Unpublished project paper.
Computer Science Dept., Stanford University. June.
Kohavi, R., & Benson, S. (1993). Research Note Decision Lists. Machine Learning, 13,
131-134.
Maes, P. (1989). Right Thing. Connection Science, 1, no.3, 291-323.
Mitchell, T. M., Keller, R. M., & Kedar-Cabelli, S. T. (1986). Explanation-based Generalization: Unifying View. Machine Learning, 1, 47-80.
Nilsson, N. J. (1980). Principles Artificial Intelligence. San Francisco, CA: Morgan Kaufmann.
Nilsson, N. (Ed.) (1984). Shakey Robot. Tech. Note 323, Artificial Intelligence Center,
SRI International, Menlo Park, CA 94025.
Nilsson, N. (1992). Toward Agent Programs Circuit Semantics. Tech. rep. STAN-CS92-1412, Department Computer Science, Stanford University.
Ramadge, P. J. G., & Wonham, W. M. (1989). Control Discrete Event Systems.
Proceedings IEEE, 77, no. 1, 81-98, January.
Reisig, W. (1985). Petri Nets: Introduction, Springer Verlag.
Rivest, R. L. (1987). Learning Decision Lists. Machine Learning, 2, 229-246.
157

fiNilsson

Rosenschein, S. J. & Kaelbling, L.P. (1986). Synthesis Machines Provable
Epistemic Properties. Proceedings 1986 Conference Theoretical Aspects
Reasoning Knowledge. Halpern, J. (Ed.), 83-98, San Francisco, CA: Morgan
Kaufmann. (Updated version: Technical Note 412, Artificial Intelligence Center, SRI
International, Menlo Park, CA.)
Saotti, A., Ruspini, E., & Konolige, K. (1993). Integrating Reactivity Goaldirectedness Fuzzy Controller. Proc. 2nd Fuzzy-IEEE Conference, San
Francisco, CA.
Schoppers, M. J. (1987). Universal Plans Reactive Robots Unpredictable Domains.
Proceedings IJCAI-87. San Francisco, CA: Morgan Kaufmann.
Selman, B. (1993). Near-Optimal Plans, Tractability, Reactivity. Tech. rep., AI Dept.,
AT&T Bell Laboratories.
Teo, P. C-S. (1991). \Botworld," (unpublished). Robotics Laboratory, Computer Science
Dept., Stanford University, December.
Teo, P. C-S. (1992). Botworld Structures, (unpublished). Robotics Laboratory, Computer
Science Dept., Stanford University, June.
Waterman, D. A. & Hayes-Roth, F. (1978). Overview Pattern-Directed Inference
Systems. Pattern-Directed Inference Systems, Waterman, D. A. & Hayes-Roth, F.
(Eds.), 3-22. New York:Academic Press.
Wilson, S. (1991). Animat Path AI. Animals Animats; Proceedings
First International Conference Simulation Adaptive Behavior, Meyer, J.
A., & Wilson, S. (Eds.). Cambridge, MA: MIT Press/Bradford Books.

158

fiJournal Artificial Intelligence Research 1 (1994) 309-314

Submitted 1/94; published 6/94

Research Note

Applying GSAT Non-Clausal Formulas

Roberto Sebastiani

Mechanized Reasoning Group, DIST, viale Causa 13, 16145 Genova, Italy.
Mechanized Reasoning Group, IRST, loc. Pante, 38050 Povo, Trento, Italy.

rseba@dist.unige.it

Abstract

paper describe modify GSAT applied non-clausal
formulas. idea use particular \score" function gives number clauses
CNF conversion formula false given truth assignment.
value computed linear time, without constructing CNF conversion itself.
proposed methodology applies variants GSAT proposed far.

1. Introduction

GSAT (Selman, Levesque, & Mitchell, 1992; Selman & Kautz, 1993) incomplete
model-finding algorithm clausal propositional formulas performs randomized
local search. GSAT shown solve many \hard" problems much eciently
traditional algorithms like, e.g., DP (Davis & Putnam, 1960). Since GSAT
applies clausal formulas, using find models ordinary propositional formulas
requires previous clausal-form conversion. requires extra computation (which
extremely heavy \standard" clausal conversion used). Much worse, clausal-form
conversion causes either large increase size input formula enlargement
search space.
paper describe modify GSAT applied non-clausal
formulas directly , i.e., previous clausal form conversion. extended version
paper (Sebastiani, 1994) provides proofs theorems detailed description
algorithm introduced.
achievement could enlarge GSAT's application domain. Selman et al. (1992) suggest traditional AI problems formulated model-finding tasks; e.g., visual
interpretation (Reiter & Mackworth, 1989), planning (Kautz & Selman, 1992), generation
\vivid" knowledge representation (Levesque, 1986). often case non-clausal
representations compact problems. instance, rule form
\Vi " gives rise several distinct clauses disjuncts conjunct. automated theorem proving (a.t.p.) applications model-finding
proposed (see, e.g., (Artosi & Governatori, 1994; Klingerbeck, 1994)). instance,
decision procedures decidable subclasses first-order logic iteratively perform nonclausal model-finding propositional instances input formulas (Jeroslow, 1988).
generally, model-guided techniques proof search, like goal deletion (Ballantyne & Bledsoe, 1982), false preference , semantic resolution (Slaney, 1993), seem
applicable non-clausal a.t.p. well.
c 1994 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.

fiSebastiani

procedure GSAT()
j := 1 Max-tries

:= initial()
k := 1 Max- ips

j=
return
else Poss- ips := hill-climb(; )
V := pick(Poss- ips)
:= ip(V,T)
UpdateScores(; V )

end
end
return \no satisfying assignment found".
Figure 1: general schema GSAT.

2. GSAT

clausal propositional formula truth assignment variables
, number clauses falsified called score
(score(T; )). satisfies iff score(T; ) = 0. notion score plays key role
GSAT, considered \distance" truth assignment satisfying one.
schema Figure 2 describes GSAT well many possible variants. use
notation (Gent & Walsh, 1993). GSAT performs iterative search satisfying
truth assignment , starting random assignment provided initial() .
step, successive assignment obtained ipping (inverting) truth value one
single variable V . V chosen minimize score. Let Ti assignment obtained
ipping i-th variable Vi . hill-climb() returns set Poss- ips variables
Vr minimize score(Tr ; ). current values si = score(Ti; ) , score(T; )
stored every variable Vi , hill-climb() simply returns set variables Vr
best sr . pick() chooses randomly one variables. ip() returns V 's
value ipped. ipping, UpdateScores() updates values si , i.
paper exploits observation functions initial() , hill-climb() , pick()
ip() depend structure input formula , computation
scores step input formula required clausal form.
idea thus find suitable notion score non-clausal formulas, ecient
algorithm computing it.

3. extended notion score

Let cnf(') result converting propositional formula ' clausal form
standard method (i.e., applying rules De Morgan). following definition
extends notion score propositional formulas.

Definition 3.1 score truth assignment propositional formula '
number clauses cnf(') falsified .
310

fiApplying GSAT Non-Clausal Formulas

mPP
PP
PP
PP [2,-]
[1,-]
P

[14,-]







" b
"

[7,-]

......
... ....

... ...
......
..

.....
.... ....

.......
.... ....

# @


b
................. "
#
b [2,-]


@
[2,-] #
... .. [4,-]"".....
b
#
@[1,-]


.
... -C
... .
-E B ,

... [1,-]
J [0,-] [1,-] [0,-]


[1,-]

E
... ..
,
J


SS [2,-] ...

E
[1,-]
[2,0]
[2,-]
,
... [2,-]


J
AA

...

[1,-]
[0,1]
...
..
.
-F
-B
... -D
B
B
[1,-] C ...

[1,-]
[1,-]
.
...

B
B






C .
B
C ...
...






B

.
... -A -B C -E -F ... -D -E C F -A -F -B E -C F
[0,-] [1,-] [0,-] [1,-] [0,-]
...[1,-]
. . . . . .[1,-]
. . . . .[0,-]
. . . . . .[1,-]
. . . . . .[1,-]
. . . . . ... [1 , 0][0,1][1 , 0] [0,1] [0,1] [0,-] [1,-] [1,-]





... ...
........





.
......
... ....









.... ...
.......



...
......
... ...

.......
... ...

.
......
... ....

.......
.... ...



... ..
......
..



........
... ...

.
......
... ....

Figure 2: computation tree s(T; ').
cnf() represents \natural" clausal form conversion. cnf(') number
propositional variables ' logically equivalent '. problem cnf()
exponential size growth cnf(') , is, jcnf (')j = O(2j'j). Definition 3.1 overcomes
problem, possible introduce linear-time computable function s(T; ')
gives score formula '. done directly, i.e., without converting '
clausal form. define s(T; ') recursively follows: 1
'
s((T; ')
s(,(T; ')
0 j= '
1 j= '
' literal
1 otherwise
0 otherwise
:V'1
sP, (T; '1)
sQ(T; '1)
, 'k )
'

(
T;
'
)
Wk 'k
Q k s(T; ' k)
Pk ss,((T;
T; 'k)
k
k k
k
k
'1 '2 s, (T; '1) s(T; '2)
s(T; '1) + s, (T; '2)
,
'2)+ (s(T; '1) + s, (T; '2))
'1 '2 ss((T;T;''1))ss,(T;
(T; ' )
(s, (T; ' ) + s(T; ' ))
1

2

1

2

s, (T; 'k) s(T; :'k ). distinction s(T; 'k ) s, (T; 'k) due polarity
current subformula 'k . computation s(T; '), call function
s(T; 'j ) [s, (T; 'j )] invoked iff 'j positive [negative] subformula '.
Example 3.1 Figure 2 represents computation tree score truth assignment
formula ' :
(D

(((

^:

^:

B C ) ( E F )) C (( E ) (C F )))
E B ) (((D A) ( F B ) F ) ((E C F ) B )):
^

:

^

_

_:

^:

_

:

_

^:

:

^

^:

^:

^

_:

:

^

^

^:

^



^:

^

^

_

_:

assigns \true" variables '. information square brackets associated
subformula 'j represents [s(T; 'j ); s, (T; 'j )]. instance, consider small
subtree left Figure 2, score computed following way:
1. Notice definition s(T; ') easily extended formulas involving connectives (e.g.,
nand , , xor , if-then-else , : : : ) complicate boolean functions.

311

fiSebastiani

s(T; ( B C ) ( E F ) ) =
s(T; B C ) s(T; D) s(T; E F ) =
(s(T; A) + s(T; B ) + s(T; C )) s(T; D) (s(T; E ) + s(T; F )) =
(1 + 1 + 0) 1 (1 + 1) = 4:
:

:

^:

^:

^

^

:



:



_:

_

:

:

^:



:



^:

:



:

:

W

Q

; s(T; Vk 'k ) = Pk s(T; 'k )
; s(T; k 'k ) = k s(T; 'k )
; literals



2

Notice cnf (') 360 clauses long.

Theorem 3.1 Let ' propositional formula truth assignment variables
'. function s(T; ') gives score '.

proof follows consideration that, truth assignment , set
false clauses cnf('1 _ '2) cross product two sets false clauses
cnf('1) cnf('2) .
Theorem 3.2 Let ' propositional formula truth assignment variables
'. number operations required calculating s(T; ') grows linearly
size '.
proof follows fact that, Time(s ('i; )) number operations required
computing s(T; 'i) s, (T; 'i), Time(s ('i; )) ai j'ij + bi ,
Time(s ('1 '2; )) maxi (ai) j'1 '2j + 2 maxi (bi) + 6, 2 f^; _; ; g.
number operations required computing score assignment
clausal formula O(jj). = cnf ('), jj = O(2j'j). Thus standard
computation score requires O(2j'j) operations, s(T; ') performs
result directly linear time.

4. GSAT non-clausal formulas

follows Sections 2, 3 extend GSAT non-clausal formulas ' simply
using extended notion score Definition 3.1. Let NC-GSAT (non-clausal GSAT)
new version GSAT scores computed implementation
function s() . follows Theorem 3.1 NC-GSAT(') function hillclimb() always returns sets variables GSAT(cnf(')), NC-GSAT(')
performs ips returns result GSAT(cnf(')). Theorem 3.2 ensures
every score computation performed linear time.
current implementation GSAT (Selman & Kautz, 1993) provides highlyoptimized implementation Updatescores(; V ) , analyzes clauses
last- ipped variable V occurs in. allows strong reduction computational cost.
(Sebastiani, 1994) describe detail analogous optimized version updating
procedure NC-GSAT, called NC-Updatescores('; V ) , prove following properties:
(i) ' clausal form, i.e., ' = cnf ('), NC-UpdateScores('; V )
complexity UpdateScores('; V ) ;
(ii) = cnf ('), NC-UpdateScores('; V ) O(j'j). UpdateScores(; V ) O(2j'j).
latter mirrors complexity issues presented Section 3.
312

fiApplying GSAT Non-Clausal Formulas

idea introduced paper applied variants GSAT. \CSAT"
(Cautious SAT) hill-climb() returns variables cause decrease score;
\DSAT" (Deterministic SAT) function pick() performs deterministic choice;
\RSAT" (Random walk SAT) variable picked randomly among variables;
\MSAT" (Memory SAT) pick() remembers last ipped variable avoids picking it.
variants, proposed (Gent & Walsh, 1992, 1993), transposed NCGSAT well, independent structure input formula. Selman
Kautz (1993) suggest variants improve performance overcome
problems, escaping local minima. strategy \Averaging " suggests
different implementation function initial() : instead random assignment, initial()
returns bitwise average best assignments two latest cycles. independent
form input formula. strategy \random walk " sequence hill-climb()
- pick() substituted probability p simpler choice function: \choose randomly
variable occurring unsatisfied clause". idea transposed NC-GSAT
well: \choose randomly branch passing nodes whose score different
zero, pick variable leaf".
One final observation worth making. order overcome exponential growth
CNF formulas, algorithms proposed (Plaisted & Greenbaum, 1986; de la
Tour, 1990) convert propositional formulas ' polynomial-size clausal formulas .
methods based introduction new variables, representing subformula
original input '. Unfortunately, issue size-polynomiality valid \"
occurs ', number clauses grows exponentially number \"
'. Even worse, introduction k new variables enlarges search space 2k factor
reduces strongly solution ratio. fact, model also model ',
model ' know one 2k extensions model (Plaisted &
Greenbaum, 1986).

Acknowledgements
Fausto Giunchiglia Enrico Giunchiglia given substantial continuous feedback
whole development paper. Toby Walsh provided important feedback
previous version paper. Aaron Noble, Paolo Pecchiari, Luciano Serafini
helped final revision. Bart Selman Henry Kautz thanked assistance
GSAT code.

References

Artosi, A., & Governatori, G. (1994). Labelled Model Modal Logic. Proc. CADE12
Workshop Automated Model Building.

Ballantyne, M., & Bledsoe, W. (1982). Generating Using Examples Proof Discovery. Michie, D. (Ed.), Machines intelligence, Vol. 10, pp. 3{39. Halsted Press.
Davis, M., & Putnam, H. (1960). computing procedure quantification theory. Journal
ACM, 7, 201{215.
313

fiSebastiani

de la Tour, T. B. (1990). Minimizing Number Clauses Renaming. Proc.
10th Conference Automated Deduction, pp. 558{572. Springer-Verlag.
Gent, I. P., & Walsh, T. (1992). Enigma SAT Hill-climbing Procedures. Tech. rep.
605, University Edinburgh, Dept. Artificial Intelligence.
Gent, I. P., & Walsh, T. (1993). Towards Understanding Hill-climbing Procedures
SAT. Proc. 11th National Conference Artificial Intelligence, pp. 28{33.
Jeroslow, R. (1988). Computation-Oriented Reduction Predicate Propositional Logic.
Decision Support System, 4, 183{197.
Kautz, H., & Selman, B. (1992). Planning Satisfiability. Proc. 10th European Conference Artificial Intelligence, pp. 359{363.
Klingerbeck, S. (1994). Generating Finite Counter Examples Semantic Tableaux
Interpretation Revision. Proc. CADE12 Workshop Automated Model Building.

Levesque, H. (1986). Making believers computers. Artificial Intelligence., 30, 81{108.
Plaisted, D., & Greenbaum, S. (1986). Structure-preserving Clause Form Translation.
Journal Symbolic Computation, 2, 293{304.
Reiter, R., & Mackworth, A. (1989). logical framework depiction image interpretation. Artificial Intelligence., 41 (2), 125{155.
Sebastiani, R. (1994). Applying GSAT Non-Clausal Formulas. Tech. rep. 94-0018,
DIST, University Genova, Italy. Available via anonimous ftp mrg.dist.unige.it,
/pub/mrg-ftp/.
Selman, B., & Kautz, H. (1993). Domain-Independent Extension GSAT: Solving Large
Structured Satisfiability Problems. Proc. 13th International Joint Conference
Artificial Intelligence, pp. 290{295.
Selman, B., Levesque, H., & Mitchell, D. (1992). New Method Solving Hard Satisfiability Problems. Proc. 10th National Conference Artificial Intelligence,
pp. 440{446.
Slaney, J. (1993). SCOTT: Model-Guided Theorem Prover. Proc. 13th International Joint Conference Artificial Intelligence, pp. 109{114. Morgan Kaufmann.

314

fiJournal Artificial Intelligence Research 1 (1993) 1-23

Submitted 5/93; published 8/93

Market-Oriented Programming Environment
Application Distributed Multicommodity Flow Problems
Michael P. Wellman

wellman@engin.umich.edu

University Michigan, Dept. Electrical Engineering Computer Science,
Ann Arbor, MI 48109 USA

Abstract

Market price systems constitute well-understood class mechanisms
certain conditions provide effective decentralization decision making minimal communication overhead. market-oriented programming approach distributed problem
solving, derive activities resource allocations set computational agents
computing competitive equilibrium artificial economy. Walras provides basic
constructs defining computational market structures, protocols deriving
corresponding price equilibria. particular realization approach form
multicommodity ow problem, see careful construction decision process according economic principles lead ecient distributed resource allocation,
behavior system meaningfully analyzed economic terms.

1. Distributed Planning Economics
distributed multiagent planning system, plan system whole composite plans produced constituent agents. plans may interact significantly
resources required agents' activities (preconditions) products resulting activities (postconditions). Despite interactions, often
advantageous necessary distribute planning process agents separated
geographically, different information, possess distinct capabilities authority,
designed implemented separately. case, agent limited
competence awareness decisions produced others, sort coordination
required maximize performance overall system. However, allocating resources
via central control extensive communication deemed infeasible, violates whatever
constraints dictated distribution planning task first place.
task facing designer distributed planning system define computationally ecient coordination mechanism realization collection agents.
agent configuration may given, may design parameter. term agent,
refer module acts within mechanism according knowledge
interests. capabilities agents organization overall decision-making
structure determine behavior system whole. concerns collective behavior self-interested decision makers, design decentralized structure
fundamentally exercise economics incentive engineering. problem developing
architectures distributed planning fits within framework mechanism design (Hurwicz, 1977; Reiter, 1986), many ideas results economics directly applicable.
particular, class mechanisms based price systems competition
deeply investigated economists, characterized conditions eciency
c 1993 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.

fiWellman

compatibility features economy. applicable, competitive
mechanism achieves coordination minimal communication requirements (in precise
sense related dimensionality messages transmitted among agents (Reiter, 1986)).
theory general equilibrium (Hildenbrand & Kirman, 1976) provides foundation general approach construction distributed planning systems based
price mechanisms. approach, regard constituent planning agents consumers
producers artificial economy, define individual activities terms production consumption commodities. Interactions among agents cast exchanges,
terms mediated underlying economic mechanism, protocol.
specifying universe commodities, configuration agents, interaction
protocol, achieve variety interesting often effective decentralized behaviors.
Furthermore, apply economic theory analysis alternative architectures,
thus exploit wealth existing knowledge design distributed planners.
use phrase market-oriented programming refer general approach deriving solutions distributed resource allocation problems computing competitive
equilibrium artificial economy.1 following, describe general approach
primitive programming environment supporting specification computational
markets derivation equilibrium prices. example problem distributed transportation planning demonstrates feasibility decentralizing problem nontrivial
interactions, applicability economic principles distributed problem solving.

2. WALRAS: Market-Oriented Programming Environment
explore use market mechanisms coordination distributed planning modules, developed prototype environment specifying simulating computational
markets. system called walras, 19th-century French economist Leon Walras, first envision system interconnected markets price equilibrium.
Walras provides basic mechanisms implementing various sorts agents, auctions,
bidding protocols. specify computational economy, one defines set goods
instantiates collection agents produce consume goods. Depending
context, goods agents may fixed exogenously, example, could correspond real-world goods agents participating planning process. Others might
completely artificial ones invented designer decentralize problem-solving
process particular way. Given market configuration, walras runs agents
determine equilibrium allocation goods activities. distribution goods
activities constitutes market solution planning problem.
1. name inspired Shoham's use agent-oriented programming refer specialization
object-oriented programming entities described terms agent concepts interact
via speech acts (Shoham, 1993). Market-oriented programming analogous specialization,
entities economic agents interact according market concepts production exchange.
phrase also invoked Lavoie, Baetjer, Tulloh (1991) refer real markets software
components.

2

fiMarket-Oriented Programming

2.1 General Equilibrium

walras framework patterned directly general-equilibrium theory. brief exposition, glossing many fine points, follows; elaboration see text microeconomic
theory (e.g., (Varian, 1984)).
start k goods n agents. Agents fall two general classes. Consumers
buy, sell, consume goods, preferences consuming various combinations
bundles goods specified utility function. agent consumer,
utility function, u : <+ ! <, ranks various bundles goods according preference.
Consumers may also start initial allocation goods, termed endowment. Let e denote agent i's endowment good j , x amount good j
ultimately consumes. objective consumer choose feasible bundle goods,
(x 1; : : :; x ) (rendered vector notation x ), maximize utility. bundle
feasible consumer total cost going prices exceed value
i's endowment prices. consumer's choice expressed following
constrained optimization problem:
k



i;j

i;

i;j

i;k



max
u (x ) s.t. p x p e ;
x








(1)



p = (p1; : : :; p ) vector prices k goods.
Agents second type, producers, transform sorts goods
others, according technology. technology specifies feasible combinations
inputs outputs producer. Let us consider special case one
output good, indexed j , remaining goods potential inputs. case,
technology producer described production function,
k

= ,x = f (x 1; : : :; x


i;j



i;

i;j

,1; x +1 ; : : :; x );
i;j

i;k

specifying maximum output producible given inputs. (When good
input production, production function characterizes net output.)
case, producer's objective choose production plan maximizes profits subject
technology going price output input goods. involves choosing
production level, , along levels inputs produce minimum cost.
Let x p denote consumption prices, respectively, input goods.
corresponding constrained optimization problem maximize profits, difference
revenues costs:


i;|



|







max p , min
p x s.t. f (x ) ;
x
yi

equivalently,

j



i;|

|

i;|





min
p x s.t. , x f (x ):
x




i;j



i;|

i;|

(2)

agent acts competitively takes prices given, neglecting impact
behavior prices. formulation implicitly assumes perfect competition,
prices parameters agents' constrained optimization problems. Perfect
competition realistically ects individual rationality numerous agents,
small respect entire economy. Even case, however,
3

fiWellman

implement competitive behavior individual agents choose. implications
restriction perfect competition discussed below.
pair (p; x) price vector vector demands agent constitutes
competitive equilibrium economy if:
1. agent i, x solution constrained optimization problem|(1)
(2)|at prices p,


2. net amount good produced consumed equals total endowment,
n
X

=1



x =

n
X

i;j

=1

e ; j = 1; : : :; k:
i;j

(3)



words, total amount consumed equals total amount produced (counted
negative quantities consumption bundles producers), plus total amount
economy started (the endowments).
certain \classical" assumptions (essentially continuity, monotonicity, concavity utility production functions; see, e.g., (Hildenbrand & Kirman, 1976; Varian,
1984)), competitive equilibria exist, unique given strictness conditions.
perspective mechanism design, competitive equilibria possess several desirable
properties, particular, two fundamental welfare theorems general equilibrium theory: (1) competitive equilibria Pareto optimal (no agent better without
worse), (2) feasible Pareto optimum competitive equilibrium
initial allocation endowments. properties seem offer exactly
need: bound quality solution, plus prospect achieve
desired behavior carefully engineering configuration computational
market. Moreover, equilibrium, prices ect exactly information required
distributed agents optimally evaluate perturbations behavior without resorting
communication reconsideration full set possibilities (Koopmans, 1970).

2.2 Computing Competitive Equilibria

Competitive equilibria also computable, algorithms based fixed-point methods (Scarf, 1984) optimization techniques (Nagurney, 1993) developed.
sorts algorithms effect operate collecting solving simultaneous equilibrium equations (1), (2), (3)). Without expressly distributed formulation, however,
techniques may violate decentralization considerations underlying distributed
problem-solving context. quite acceptable purposes algorithms
originally designed, namely analyze existing decentralized structures, transportation industries even entire economies (Shoven & Whalley, 1992). purpose
implement distributed system, must obey computational distributivity constraints
relevant usual purposes applied general-equilibrium analysis. general, explicitly examining space commodity bundle allocations search equilibrium
undercuts original motive decomposing complex activities consumption
production separate goods.
4

fiMarket-Oriented Programming

Another important constraint internal details agents' state (such utility
production functions bidding policy) considered private order maximize modularity permit inclusion agents designers' direct control.
consequence computationally exploiting global properties arising special features agents would generally permissible purposes. example,
constraint profits zero consequence competitive behavior constantreturns production technology. Since information form technology
bidding policy private producer agents, could considered cheating embed
zero-profit condition equilibrium derivation procedure.
Walras's procedure decentralized relaxation method, akin mechanism
tatonnement originally sketched Leon Walras explain prices might derived.
basic tatonnement method, begin initial vector prices, p0 . agents
determine demands prices (by solving corresponding constrained optimization problems), report quantities demanded \auctioneer". Based
reports, auctioneer iteratively adjusts prices excess
demand supply, respectively. instance, adjustment proportional excess
could modeled difference equation
n
X

p +1 = p + ff( x ,




=1





n
X

=1

e ):




sequence p0 ; p1; : : : converges, excess demand market approaches zero,
result competitive equilibrium. well known, however, tatonnement
processes converge equilibrium general (Scarf, 1984). class economies
tatonnement works so-called stable equilibria (Hicks, 1948). sucient
condition stability gross substitutability (Arrow & Hurwicz, 1977): price
one good rises, net demands goods decrease. Intuitively,
gross substitutability violated complementarities preferences
technologies reduced consumption one good cause reduced consumption
others well (Samuelson, 1974).

2.3 WALRAS Bidding Protocol

method employed walras successively computes equilibrium price separate market, manner detailed below. Like tatonnement, involves iterative adjustment prices based reactions agents market. However, differs
traditional tatonnement procedures (1) agents submit supply demand curves
rather single point quantities particular price, (2) auction adjusts individual prices clear, rather adjusting entire price vector increment
(usually function summary statistics excess demand).2
Walras associates auction distinct good. Agents act market
submitting bids auctions. walras, bids specify correspondence prices
2. general approach called progressive equilibration Dafermos Nagurney (1989), applied
particular transportation network equilibrium problem. Although model market dynamics
appear investigated extensively general-equilibrium theory, seem
match kind price adjustment process envisioned Hicks pioneering study dynamics
stability (Hicks, 1948).

5

fiWellman

quantities good agent offers demand supply. bid particular
good corresponds one dimension agent's optimal demand, parametrized
prices relevant goods. Let x (p) solution equation (1) (2),
appropriate, prices p. walras agent bids good j assumption prices
remaining goods fixed current values, p. Formally, agent i's bid
good j function x : <+ ! <, prices quantities satisfying


|

i;j

x (p ) = x (p ; p) ;
i;j

j



j

|

j

subscript j right-hand side selects quantity demanded good j
overall demand vector. agent computes sends function (encoded
variety formats) auction good j .
Given bids interested agents, auction derives market-clearing price,
quantity demanded balances supplied, within prespecified tolerance.
clearing price simply zero crossing aggregate demand function,
sum demands agents. zero crossing exist long aggregate
demand suciently well-behaved, particular, continuous decreasing price.
Gross substitutability, along classical conditions existence equilibrium,
sucient ensure existence clearing price stage bidding protocol.
Walras calculates zero crossing aggregate demand function via binary search.
aggregate demand well-behaved, result auction may non-clearing
price.
current price clearing respect current bids, say market
commodity equilibrium. say agent equilibrium set
outstanding bids corresponds solution optimization problem going prices.
agents commodity markets equilibrium, allocation goods dictated
auction results competitive equilibrium.
Figure 1 presents schematic view walras bidding process. auction
distinct good, agent, link auctions interest.
also \tote board" current prices, kept up-to-date various auctions.
current implementation tote board global data structure, however, since price
change notifications explicitly transmitted interested agents, central information
could easily dispensed with.
agent maintains agenda bid tasks, specifying markets must
update bid compute new one. Figure 1, agent pending tasks submit
bids auctions G1 , G7, G4. bidding process highly distributed,
agent need communicate directly auctions goods interest (those
domain utility production function, nonzero endowments).
interactions concerns single good; auctions never coordinate
other. Agents need negotiate directly agents, even know other's
existence.
new bids received auction, previously computed clearing price becomes
obsolete. Periodically, auction computes new clearing price (if new updated
bids received) posts tote board. price updated,
may invalidate agent's outstanding bids, since computed
assumption prices remaining goods fixed previous values. finding


6

fiMarket-Oriented Programming

G1

A1

G2

Gk

A2

Ai
Task Agenda
[1], [7], [4]

Figure 1:

Walras's bidding process. G

tote board p1
p2

}


}
pk

denotes auction j th good,
ith trading agent. item [j ] task agenda denotes pending task
compute submit bid good j .
j



price change, agent augments task agenda include potentially affected
bids.
times, walras maintains vector going prices quantities would
exchanged prices. agents nonempty bid agendas auctions new
bids, goods may disequilibrium. auctions clear agendas
exhausted, however, economy competitive equilibrium (up numeric
tolerance). Using recent result Milgrom Roberts (1991, Theorem 12),
shown condition sucient convergence tatonnement|gross substitutability|
also sucient convergence walras's price-adjustment process. key observation
progressive equilibration (synchronous not) price time based
set previous supply demand bids.
Although precise results effect, computational effort required
convergence fixed tolerance seems highly sensitive number goods, much
less number agents. Eydeland Nagurney (1989) analyzed detail
convergence pattern progressive equilibration algorithms related walras particular special cases, found roughly linear growth number agents. However,
general conclusions dicult draw cost computing equilibrium particular computational economy may well depend interconnectedness strength
interactions among agents goods.

2.4 Market-Oriented Programming

described above, walras provides facilities specifying market configurations
computing competitive equilibrium. also view walras programming
environment decentralized resource allocation procedures. environment provides
constructs specifying various sorts agents defining interactions via
7

fiWellman

relations common commodities. setting initial configuration, market
run determine equilibrium level activities distribution resources
throughout economy.
cast distributed planning problem market, one needs identify (1) goods
traded, (2) agents trading, (3) agents' bidding behavior. design steps
serially dependent, definition constitutes exchangeable producible
commodity severely restricts type agents makes sense include.
mentioned above, sometimes take fixed real-world agents goods
presented part problem specification. configuration determined,
might advantageous adjust general parameters bidding protocol. Below,
illustrate design task walras formulation multicommodity ow problem.

2.5 Implementation

Walras implemented Common Lisp Common Lisp Object System (CLOS).

current version provides basic infrastructure running computational economies,
including underlying bidding protocol library CLOS classes implementing
variety agent types. object-oriented implementation supports incremental development market configurations. particular, new types agents often defined
slight variations existing types, example modifying isolated features demand
behavior, bidding strategies (e.g., management task agenda), bid format. Wang
Slagle (1993) present detailed case use object-oriented languages represent
general-equilibrium models. proposed system similar walras respect
formulation, although designed interface conventional model-solving packages,
rather support decentralized computation equilibrium directly.
Although models distributed system, walras runs serially single processor.
Distribution constraints information communication enforced programming
specification conventions rather fundamental mechanisms software environment. Asynchrony simulated randomizing bidding sequences agents
called unpredictably. Indeed, artificial synchronization lead undesirable
oscillation clearing prices, agents collectively overcompensate imbalances
preceding iteration.3
current experimental system runs transportation models sort described below, well abstract exchange production economies parametrized utility
production functions (including expository examples Scarf (1984) Shoven
Whalley (1984)). Customized tuning basic bidding protocol necessary. process getting walras run examples, added
generically useful building blocks class libraries, much required fill
comprehensive taxonomy agents, bidding strategies, auction policies.
3. formal dynamic models (Huberman, 1988; Kephart, Hogg, & Huberman, 1989), homogeneous
agents choose instantaneously optimal policies without accounting others simultaneously
making choice. Since value particular choice varies inversely number agents
choosing it, delayed feedback others' decisions leads systematic errors, hence
oscillation. also observed phenomenon empirically synchronized version WALRAS.
eliminating synchronization, agents tend work different markets one time, hence
suffer much delayed feedback prices.

8

fiMarket-Oriented Programming

3. Example: Multicommodity Flow
simple version multicommodity ow problem, task allocate given
set cargo movements given transportation network. transportation network
collection locations, links (directed edges) identifying feasible transportation
operations. Associated link specification cost moving cargo along it.
suppose cargo homogeneous, amounts cargo arbitrarily
divisible. movement requirement associates amount cargo origin-destination
pair. planning problem determine amount transport link order
move cargo minimum cost. simplification ignores salient aspects real
transportation planning. instance, model completely atemporal, hence
suitable planning steady-state ows planning dynamic movements.
distributed version problem would decentralize responsibility transporting separate cargo elements. example, planning modules corresponding geographically organizationally disparate units might arrange transportation cargo
within respective spheres authority. decision-making activity might decomposed along hierarchical levels abstraction, gross functional characteristics, according
relevant distinction. decentralization might result real distribution
authority within human organization, inherent informational asymmetries
communication barriers, modularity imposed facilitate software engineering.
Consider, example, abstract transportation network Figure 2, taken
Harker (1988). four locations, directed links shown. Consider two movement requirements. first transport cargo location 1 location 4,
second reverse direction. Suppose wish decentralize authority separate
agents (called shippers) decide allocate cargo movement. first shipper decides split cargo units paths 1 ! 2 ! 4 1 ! 2 ! 3 ! 4,
second figures split paths 4 ! 2 ! 1 4 ! 2 ! 3 ! 1. Note
latter paths shipper share common resource: link 2 ! 3.
2

4

1

3

Figure 2: simple network (from Harker (1988)).
overlapping resource demands, shippers' decisions appear
necessarily intertwined. congested network, example, cost transporting
unit cargo link increasing overall usage link. shipper planning
cargo movements user network would thus underestimate
costs potentially misallocate transportation resources.
9

fiWellman

analysis networks this, transportation researchers developed
equilibrium concepts describing collective behavior shippers. system equilibrium, overall transportation cargo proceeds omniscient central
planner directing movement shipment minimize total aggregate
cost meeting requirements. user equilibrium, overall allocation cargo
movements shipper minimizes total cost, sharing proportionately
cost shared resources. system equilibrium thus global optimum,
user equilibrium corresponds composition locally optimal solutions subproblems.
also intermediate possibilities, corresponding game-theoretic equilibrium
concepts Nash equilibrium, shipper behaves optimally given
transportation policies remaining shippers (Harker, 1986).4
perspective designer distributed planner, seek decentralization
mechanism reach system equilibrium, come close possible given
distributed decision-making structure. general, however, cannot expect derive
system equilibrium globally optimal solution without central control. Limits coordination communication may prevent distributed resource allocation exploiting
opportunities inhibiting agents acting cross purposes. certain
conditions decision making indeed decentralized effectively via market mechanisms.
General-equilibrium analysis help us recognize take advantage opportunities.
Note multicommodity ow problem, effective distributed solution
due Gallager (1977). One market structures described effectively mimics
solution, even though Gallager's algorithm formulated expressly market terms.
point crack hitherto unsolved distributed optimization problem (though
would nice), rather illustrate general approach simply described yet
nontrivial task.

4. WALRAS Transportation Market

section, present series three transportation market structures implemented
walras. first simplest model comprises basic transportation goods shipper
agents, augmented succeeding models include agent types. Comparative analysis three market structures reveals qualitatively distinct economic
computational behaviors realized alternate walras configurations.

4.1 Basic Shipper Model

resource primary interest multicommodity ow problem movement cargo.
value cost cargo movement depends location, designate
distinct good capacity origin-destination pair network (see Figure 2).
capture cost input required move cargo, define another good denoting generic
transportation resources. concrete model, might consist vehicles, fuel,
labor, factors contributing transportation.
4. Nash solution, shippers correctly anticipate effect cargo movements average
cost link. resulting equilibrium converges user equilibrium number shippers
increases effect individual's behavior prices diminishes (Haurie & Marcotte, 1985).

10

fiMarket-Oriented Programming

decentralize decision making, identify movement requirement
distinct shipper agent. shippers, consumers, interest moving various
units cargo specified origins destinations.
interconnectedness agents goods defines market configuration. Figure 3
depicts walras configuration basic shipper model corresponding example
network Figure 2. model two shippers, S1 4 S4 1, denotes
shipper requirement move goods origin destination j . Shippers connect
goods might serve objectives: case, movement along links belong
simple path shipper's origin destination. diagram, G denotes
good representing amount cargo moved link ! j . G0 denotes special
transportation resource good. Notice goods interest shippers
G0, endowments, G2 3, transportation link serving
origin-destination pairs.
;

;

i;j

i;j

;

G

G 2,3

G 2,4

S4,1

S1,4

G0

G 1,2

Figure 3:

G 3,1

3,4

G

G

2,1

4,2

Walras basic shipper market configuration example transportation network.

model employ transportation costs based network congestion,
thus exhibiting diseconomies scale. words, marginal average costs (in
terms transportation resources required) increasing level service
link. Using Harker's data, take costs quadratic. quadratic cost model posed
simply concreteness, represent substantive claim transportation
networks. important qualitative feature model (and one necessary
example work) exhibits decreasing returns, defining characteristic
congested networks. Note also Harker's model terms monetary costs, whereas
introduce abstract input good.
Let c (x) denote cost transportation resources (good G0 ) required transport
x units cargo link j . complete cost functions are:
c1 2(x) = c2 1(x) = c2 4(x) = c4 2(x) = x2 + 20x;
c3 1(x) = c2 3(x) = c3 4(x) = 2x2 + 5x:
Finally, shipper's objective transport 10 units cargo origin
destination.
i;j

;

;

;

;

;

;

;

11

fiWellman

basic shipper model, assume shippers pay proportionately (in units
G0 ) total cost link. amounts policy average cost pricing.
take shipper's objective ship much possible (up movement
requirement) least costly manner. Notice objective expressible
terms consumer's optimization problem, equation (1), hence model
technically instance general-equilibrium framework.
Given network prices link, cheapest cargo movement corresponds
shortest path graph, distances equated prices. Thus, given
link, shipper would prefer ship entire quota link shortest path,
zero otherwise. case ties, indifferent among possible allocations.
bid link i; j , shipper derive threshold price determines whether link
shortest path taking difference shortest-path distance networks
link i; j 's distance set zero infinity, respectively.
incrementally changing bids, shipper also consider outstanding bids
current prices. value reserving capacity particular link zero
cannot get service links path. Similarly, already committed
shipping cargo parallel path, gain obtaining capacity (even
lower price) withdraws bids.5 Therefore, actual demand policy
shipper spend uncommitted income potential ow increase (derived
maximum- ow calculations) could obtain purchasing capacity given link.
willing spend threshold value link, described above. determines
one point demand curve. unsatisfied requirement uncommitted
income also indicates willingness pay lower price greater amount capacity.
Boundary points serve bootstrap economy; initial conditions
typically case individual link contributes overall ow shipper's
origin destination. Finally, demand curve completed smoothing operation
points.
Details boundary points smoothing operation rather arbitrary,
make claim particular bidding policy ideal guaranteed work broad
class problems. crude approach appears sucient present example
similar ones, long shippers' policies become accurate prices approach
equilibrium.
Walras successfully computes competitive equilibrium example,
case basic shipper model corresponds user equilibrium (UE)
transportation network. UE example network, shipper sends 2.86 units
cargo shared link 2 ! 3, remaining cargo direct link
location 2 destination. allocation inecient, total cost 1143 resource
5. Even shipper could simultaneously update bids markets, would good idea
here. competitive shipper would send cargo least costly path, neglecting possibility
demand may increase prices longer cheapest. outstanding bids provide
sensitivity effect, functions price. cannot respond changes
many prices once, thus policy updating bids simultaneously lead perpetual
oscillation. example, network considered here, unique competitive equilibrium
shipper splitting cargo two different paths. Policies allocating cargo one path never
lead result, hence convergence competitive equilibrium depends incrementality
bidding behavior.

12

fiMarket-Oriented Programming

units, somewhat greater global minimum-cost solution 1136 units.
economic terms, cause ineciency externality respect usage
shared link. shippers effectively charged average cost|which case
decreasing returns marginal cost|the price face ect full
incremental social cost additional usage resource. effect, incremental usage
resource one agent subsidized other. steeper decreasing returns,
agents incentive overutilize resource.6 simple example
classic tragedy commons.
classical remedy problems internalize externality allocating
ownership shared resource decision maker proper incentives
use eciently. implement solution walras augmenting market
structure another type agent.

4.2 Carrier Agents
extend basic shipper model introducing carriers, agents type producer
capability transport cargo units specified links, given varying amounts
transportation resources. model described here, associate one carrier
available link. production function carrier simply inverse
cost function described above. achieve global movement cargo, shippers obtain
transportation services carriers exchange necessary transportation resources.
Let C denote carrier transports cargo location location j .
carrier C connected auction G , output good, along G0|its input
production process. Shipper agents also connected G0 , endowed
transportation resources exchange transportation services. Figure 4 depicts
walras market structure carriers included economy.
i;j

i;j

i;j

G

C 2,4

Figure 4:

3,4

C 3,4

G 2,4

S1,4

G 1,2

C 1,2

G 2,3

C 2,3

G0

C 3,1

G 3,1

S4,1

G

C

G

4,2

2,1

C 2,1

4,2

Walras market configuration example transportation network economy shippers carriers.

6. Average-cost pricing perhaps common mechanism allocating costs shared resource.
Shenker (1991) points problems scheme|with respect eciency strategic
behavior|in context allocating access congested computer networks, problem analogous
transportation task.

13

fiWellman

case decreasing returns technology, producer's (carrier's) optimization
problem unique solution. optimal level activity maximizes revenues minus costs,
occurs point output price equals marginal cost. Using result,
carriers submit supply bids specifying transportation services function link prices
(with resource price fixed), demand bids specifying required resources function
input prices (for activity level computed output price fixed).
example, consider carrier C1 2. output price p1 2 input price p0 , carrier's
profit
p1 2y , p0c1 2(y);
level service chooses supply. Given cost function above,
expression maximized = (p1 2 , 20p0)=2p0. Taking p0 fixed, carrier submits
supply bid function p1 2. demand side, carrier takes p1 2 fixed
submits demand bid enough good G0 produce , treated function
p0.
revised configuration agent behaviors described, walras derives system equilibrium (SE), is, cargo allocation minimizing overall transportation costs.
derived cargo movements correct within 10% 36 bidding cycles, 1%
72, cycle every agent submits average one bid one auction.
total cost (in units G0 ), division shippers' expenditures carriers' profits,
equilibrium prices presented Table 1. Data UE solution basic shipper model included comparison. decentralized process produces
global optimum perfectly consistent competitive behavior|the carriers price
outputs marginal cost, technologies convex.
;

;

;

;

;

;

;

TC expense profit p1 2 p2 1 p2 3 p2 4 p3 1 p3 4 p4 2
pricing
MC (SE) 1136
1514 378 40.0 35.7 22.1 35.7 13.6 13.6 40.0
1143
0 30.0 27.1 16.3 27.1 10.7 10.7 30.0
AC (UE) 1143
;

;

;

;

;

;

;

Table 1: Equilibria derived walras transportation example. TC, MC, AC
stand total, marginal, average cost, respectively. TC = shipper expense ,
carrier profit.
simple check prices Table 1, verify p2 3 + p3 4 = p2 4
p2 3 + p3 1 = p2 1. relationships must hold equilibrium (assuming links
nonzero movements), else shipper could reduce cost rerouting cargo. Indeed,
simple (small symmetric) example this, easy derive equilibrium
analytically using global equations these. argued above, would improper
exploit relationships implementation truly distributed decision process.
lesson exercise achieve qualitatively distinct results simple variations market configuration agent policies. designers' perspective,
prefer configuration leads transportation-ecient SE. Examination
Table 1 reveals achieve result allowing carriers earn nonzero
profits (economically speaking, really rents fixed factor represented
;

;

;

;

14

;

;

fiMarket-Oriented Programming

congested channel) redistributing profits shippers cover increased
expenditures. (In model general equilibrium production, consumers shares
producers' profits. closes loop value ultimately realized
consumption. specify shares part initial configuration, like
endowment.) example, distribute profits evenly two shippers.

4.3 Arbitrageur Agents

preceding results demonstrate walras indeed implement decentralized
solution multicommodity ow problem. market structure Figure 4
distributed might be, (1) agents connected G0, (2) shippers
need know links potentially serving origin-destination pair. first
concerns easily remedied, choice single transportation resource good
completely arbitrary. example, would straightforward consider collection
resources (e.g., fuel, labor, vehicles), endow shipper subsets these.
second concern also addressed within walras. so, introduce yet
another sort producer agent. new agents, called arbitrageurs, act specialized
middlemen, monitoring isolated pieces network ineciencies. arbitrageur
produces transportation k buying capacity j j k.
production function simply specifies amount output good, G , equal
minimum two inputs, G G . p + p < p , production
profitable. bidding policy walras increment level activity
iteration amount proportional current profitability (or decrement proportional
loss). incremental behavior necessary constant-returns producers
walras, profit maximization problem interior solution linear case.7
incorporate arbitrageurs transportation market structure, first create new
goods corresponding transitive closure transportation network. example
network, leads goods every location pair. Next, add arbitrageur
every triple locations (1) ! j original network, (2) exists
path j k traverse location i. two conditions ensure
arbitrageur every pair i; k connected path one link,
eliminate combinations either redundant clearly unprofitable.
revised market structure running example depicted Figure 5, new
goods agents shaded. goods agents inactive market solution
omitted diagram avoid clutter.
Notice Figure 5 connectivity shippers significantly decreased,
shippers need aware good directly serving origin-destination
pair. dramatically simplifies bidding problem, avoid analysis
price network. structure whole seems distributed, agent concerned
three goods.
i;j;k

i;k

i;j

j;k

i;j

j;k

i;k

i;j;k

i;j;k

7. Without restriction bidding behavior, competitive constant-returns producer would
choose operate level infinity zero, depending whether activity profitable
unprofitable going prices (at break-even, producer indifferent among levels).
would lead perpetual oscillation, problem noticed (and solved) Paul Samuelson 1949
considered use market mechanisms solve linear programming problems (Samuelson, 1966).

15

fiWellman


G 2,4

A2,3,1

2,3,4

G 2,3
C 2,4

A1,2,4

G

3,4

C 3,4

G1,4

G 1,2

C 1,2

C 2,1
C 2,3

G0

S1,4

G2,1

C 3,1

G3,1

4,2,1

C 4,2

G 4,2

G4,1

S4,1

Figure 5: revised walras market configuration arbitrageurs.
Despite simplified shipper behavior, walras still converges SE, optimal
solution, configuration. Although resulting allocation resources identical,
qualitative change market structure corresponds qualitative change
degree decentralization.
fact, behavior walras market configuration arbitrageurs virtually identical standard distributed algorithm (Gallager, 1977) multicommodity
ow (minimum delay communication networks). Gallager's algorithm, distributed
modules expressly differentiate cost function derive marginal cost increasing
ow communication link. Flows adjusted equate marginal
costs along competing subpaths. procedure provably converges optimal solution
long iterative adjustment parameter suciently small. Similarly, convergence
walras model requires arbitrageurs adjust activity levels
quickly response profit opportunities loss situations.

4.4 Summary

preceding sections developed three progressively elaborate market configurations
multicommodity ow problem. Table 2 summarizes size shape configuration transportation network V locations E links, movement
requirements. basic shipper model results user equilibrium,
augmented models produce globally optimal system equilibrium. carrier model requires E new producer agents produce superior result. arbitrageur model adds
O(V E ) producers potentially new goods well, reduces number
goods interest individual agent O(E ) small constant.
market models represent three qualitatively distinct points spectrum
potential configurations. Hybrid models also conceivable, example, partial
set arbitrageurs included, perhaps arranged hierarchy regular
16

fiMarket-Oriented Programming

model
Basic shipper
: : : plus carriers
: : : plus arbitrageurs

goods

shippers

E + 1 [O(E )]
E + 1 [O(E )]
O(V 2) [2]

carriers arbitrageurs
|
|
E [2]
|
E [2] O(V E ) [3]

Table 2: Numbers goods agents three market configurations. type
agent, figure brackets indicates number goods individual
bids.
structure. would expect configurations exhibit behaviors intermediate
specific models studied here, respect equilibrium produced degree
decentralization.

5. Limitations

One serious limitation walras assumption agents act competitively.
mentioned above, behavior rational many agents, small
respect overall economy. However, individual agent large enough affect
prices significantly (i.e., possesses market power), forfeits utility profits failing
take account. two approaches toward alleviating restriction perfect
competition computational economy. First, could simply adopt models imperfect
competition, perhaps based specific forms imperfection (e.g., spatial monopolistic
competition) general game-theoretic models. Second, architects configure
markets promote competitive behavior. example, decreasing agent's grain size
enabling free entry agents enhance degree competition. Perhaps
interestingly, controlling agents' knowledge market structure (via standard
information-encapsulation techniques), degrade ability exploit whatever
market power possess. Uncertainty shown increase competitiveness among
risk-averse agents formal bidding models (McAfee & McMillan, 1987),
computational environment substantial control uncertainty.
existence competitive equilibria ecient market allocations also depends
critically assumption nonincreasing returns scale. Although congestion
real factor transportation networks, example, many modes transport
often economies scale density may lead returns increasing
overall (Harker, 1987). Note strategic interactions, increasing returns, factors
degrading effectiveness market mechanisms also inhibit decentralization general,
would need addressed directly approach.
cast walras general environment distributed planning, natural
ask universal \market-oriented programming" computational paradigm.
characterize computational power model easily enough, correspondence
class convex programming problems represented economies satisfying classical conditions. However, interesting issue well conceptual framework market
17

fiWellman

equilibrium corresponds salient features distributed planning problems. Although
early make definitive assertion this, seems clear many planning
tasks fundamentally problems resource allocation, units distribution
often correspond well units agency. Economics prominent (and
arguably successful) approach modeling resource allocation decentralized
decision making, reasonable suppose concepts economists find useful
social context prove similarly useful analogous computational context.
course, economics ideal analyzing aspects social interaction,
expect many issues organization distributed planning well
accounted-for framework.
Finally, transportation network model presented highly simplified version actual planning problem domain. realistic treatment would
cover multiple commodity types, discrete movements, temporal extent, hierarchical network structure, critical features problem. may captured
incremental extensions simple model, perhaps applying elaborations developed
transportation science community. example, many transportation models (including Harker's elaborate formulation (Harker, 1987)) allow variable supply
demand commodities complex shipper-carrier relationships. Concepts
spatial price equilibrium, based markets commodities location, seem offer
direct approach toward extending transportation model within walras.

6. Related Work
6.1 Distributed Optimization
techniques models described obviously build much work economics,
transportation science, operations research. intended research contribution
fields, rather application construction computational
framework decentralized decision making general. Nevertheless, words
order regarding relation approach described extant methods distributed
optimization.
Although elaborate walras model essentially equivalent existing algorithms distributed multicommodity ow (Bertsekas & Tsitsiklis, 1989; Gallager, 1977),
market framework offers approach toward extensions beyond strict scope
particular optimization problem. example, could reduce number arbitrageurs,
would eliminate guarantees optimality, might still reasonable
expectation graceful degradation. Similarly, could realize conceptual extensions
structure problem, distributed production goods addition transportation, adding new types agents. given extension, may well
customized distributed optimization algorithm would outperform computational
market, coming algorithm would likely involve completely new analysis.
Nevertheless, must stated speculations regarding methodological advantages
market-oriented framework indeed speculations point, relative
exibility applications programming paradigm must ultimately demonstrated
empirically.
18

fiMarket-Oriented Programming

Finally, large literature decomposition methods mathematical programming problems, perhaps common approach distributed optimization.
Many techniques interpreted economic terms, using close
relationship prices Lagrange multipliers. Again, main distinction
approach advocated conceptual. Rather taking global optimization problem decentralizing it, aim provide framework formulating task
distributed manner first place.

6.2 Market-Based Computation
basic idea applying economic mechanisms coordinate distributed problem solving
new AI community. Starting contract net (Davis & Smith, 1983),
many found metaphor markets appealing, built systems organized
around markets market-like mechanisms (Malone, Fikes, Grant, & Howard, 1988).
original contract net actually include economic notions bidding
mechanism, however, recent work Sandholm (1993) shown cost price
incorporated contract net protocol make like true market mechanism. Miller Drexler (Drexler & Miller, 1988; Miller & Drexler, 1988) examined
market-based approach depth, presenting underlying rationale addressing
specific issues salient computational environment. Waldspurger, Hogg, Huberman,
Kephart, Stornetta (1992) investigated concepts actually implementing
market mechanisms allocate computational resources distributed operating system.
Researchers distributed computing (Kurose & Simha, 1989) also applied specialized
algorithms based economic analyses specific resource-allocation problems arising
distributed systems. remarks line work, see (Wellman, 1991).
Recently, Kuwabara Ishida (1992) experimented demand adjustment
methods task similar multicommodity ow problem considered here. One
significant difference method would consider path network
separate resource, whereas market structures manipulate links location
pairs. Although cast system competitive-equilibrium framework,
results congruent obtained walras.
Walras distinct prior efforts two primary respects. First, constructed expressly terms concepts general equilibrium theory, promote mathematical analysis system facilitate application economic principles
architectural design. Second, walras designed serve general programming environment implementing computational economies. Although developed specifically
allocate computational resources, reason could included market structures configured particular application domains. Indeed, idea grounding
measures value computation real-world values (e.g., cargo movements) follows
naturally general-equilibrium view interconnected markets, one
exciting prospects future applications walras distributed problem-solving.
Organizational theorists studied markets mechanisms coordinating activities
allocating resources within firms. example, Malone (1987) models information
requirements, exibility performance characteristics variety market
non-market structures. terminology, walras implements centralized market,
19

fiWellman

allocation good mediated auction. Using models, determine
whether gross form organization advantageous, given information cost
communication, exibility individual modules, related features.
paper, examine greater detail coordination process computational markets,
elaborating criteria designing decentralized allocation mechanisms. take
distributivity constraint exogenously imposed; constraint relaxable,
organizational economic analysis illuminate tradeoffs underlying mechanism
design problem.
Finally, market-oriented programming shares Shoham's agent-oriented programming (Shoham, 1993) view distributed problem-solving modules best designed
understood rational agents. two approaches support different agent operations
(transactions versus speech acts), adopt different rationality criteria, emphasize different agent descriptors, ultimately aimed achieving goal specifying
complex behavior terms agent concepts (e.g., belief, desire, capability) social organizations. Combining individual rationality laws social interaction provides perhaps
natural approach generalizing Newell's \knowledge level analysis" idea (Newell,
1982) distributed computation.

7. Conclusion

summary, walras represents general approach construction analysis
distributed planning systems, based general equilibrium theory competitive mechanisms. approach works deriving competitive equilibrium corresponding
particular configuration agents commodities, specified using walras's basic constructs defining computational market structures. particular realization
approach simplified form distributed transportation planning, see qualitative differences economic structure (e.g., cost-sharing among shippers versus ownership
shared resources profit-maximizing carriers) correspond qualitatively distinct behaviors (user versus system equilibrium). exercise demonstrates careful design
distributed decision structure according economic principles sometimes lead
effective decentralization, behaviors alternative systems meaningfully
analyzed economic terms.
contribution work reported lies idea market-oriented programming, algorithm distributed computation competitive equilibria computational
economies, initial illustration approach simple problem distributed
resource allocation. great deal additional work required understand precise capabilities limitations approach, establish broader methodology
configuration computational economies.

Acknowledgements
paper revised extended version (Wellman, 1992). benefited
discussions computational economies many colleagues, would like thank
particular Jon Doyle, Ed Durfee, Eli Gafni, Daphne Koller, Tracy Mullen, Anna Nagurney,
20

fiMarket-Oriented Programming

Scott Shenker, Yoav Shoham, Hal Varian, Carl Waldspurger, Martin Weitzman,
anonymous reviewers helpful comments suggestions.

References

Arrow, K. J., & Hurwicz, L. (Eds.). (1977). Studies Resource Allocation Processes.
Cambridge University Press, Cambridge.
Bertsekas, D. P., & Tsitsiklis, J. N. (1989). Parallel Distributed Computation. PrenticeHall, Englewood Cliffs, NJ.
Dafermos, S., & Nagurney, A. (1989). Supply demand equilibration algorithms
class market equilibrium problems. Transportation Science, 23, 118{124.
Davis, R., & Smith, R. G. (1983). Negotiation metaphor distributed problem
solving. Artificial Intelligence, 20, 63{109.
Drexler, K. E., & Miller, M. S. (1988). Incentive engineering computational resource
management. Huberman (1988), pp. 231{266.
Eydeland, A., & Nagurney, A. (1989). Progressive equilibration algorithms: case
linear transaction costs. Computer Science Economics Management, 2, 197{
219.
Gallager, R. G. (1977). minimum delay routing algorithm using distributed computation.
IEEE Transactions Communications, 25, 73{85.
Harker, P. T. (1986). Alternative models spatial competition. Operations Research, 34,
410{425.
Harker, P. T. (1987). Predicting Intercity Freight Flows. VNU Science Press, Utrecht,
Netherlands.
Harker, P. T. (1988). Multiple equilibrium behaviors networks. Transportation Science,
22, 39{46.
Haurie, A., & Marcotte, P. (1985). relationship Nash-Cournot Wardrop
equilibria. Networks, 15, 295{308.
Hicks, J. R. (1948). Value Capital (second edition). Oxford University Press, London.
Hildenbrand, W., & Kirman, A. P. (1976). Introduction Equilibrium Analysis: Variations Themes Edgeworth Walras. North-Holland Publishing Company,
Amsterdam.
Huberman, B. A. (Ed.). (1988). Ecology Computation. North-Holland.
Hurwicz, L. (1977). design resource allocation mechanisms. Arrow Hurwicz
(1977), pp. 3{37. Reprinted American Economic Review Papers Proceedings,
1973.
21

fiWellman

Kephart, J. O., Hogg, T., & Huberman, B. A. (1989). Dynamics computational ecosystems. Physical Review A, 40, 404{421.
Koopmans, T. C. (1970). Uses prices. Scientific Papers Tjalling C. Koopmans, pp.
243{257. Springer-Verlag. Originally published Proceedings Conference
Operations Research Production Inventory Control, 1954.
Kurose, J. F., & Simha, R. (1989). microeconomic approach optimal resource allocation
distributed computer systems. IEEE Transactions Computers, 38, 705{717.
Kuwabara, K., & Ishida, T. (1992). Symbiotic approach distributed resource allocation:
Toward coordinated balancing. Pre-Proceedings 4th European Workshop
Modeling Autonomous Agents Multi-Agent World.
Lavoie, D., Baetjer, H., & Tulloh, W. (1991). Coping complexity: OOPS
economists' critique central planning. Hotline Object-Oriented Technology, 3 (1),
6{8.
Malone, T. W., Fikes, R. E., Grant, K. R., & Howard, M. T. (1988). Enterprise: marketlike task scheduler distributed computing environments. Huberman (1988), pp.
177{205.
Malone, T. W. (1987). Modeling coordination organizations markets. Management
Science, 33, 1317{1332.
McAfee, R. P., & McMillan, J. (1987). Auctions bidding. Journal Economic Literature, 25, 699{738.
Milgrom, P., & Roberts, J. (1991). Adaptive sophisticated learning normal form
games. Games Economic Behavior, 3, 82{100.
Miller, M. S., & Drexler, K. E. (1988). Markets computation: Agoric open systems.
Huberman (1988), pp. 133{176.
Nagurney, A. (1993). Network Economics: Variational Inequality Approach. Kluwer
Academic Publishers.
Newell, A. (1982). knowledge level. Artificial Intelligence, 18, 87{127.
Reiter, S. (1986). Information incentive performance (new)2 welfare economics.
Reiter, S. (Ed.), Studies Mathematical Economics. MAA Studies Mathematics.
Samuelson, P. A. (1966). Market mechanisms maximization. Stiglitz, J. E. (Ed.),
Collected Scientific Papers Paul A. Samuelson, Vol. 1, pp. 415{492. MIT Press,
Cambridge, MA. Originally appeared RAND research memoranda, 1949.
Samuelson, P. A. (1974). Complementarity: essay 40th anniversary HicksAllen revolution demand theory. Journal Economic Literature, 12, 1255{1289.
22

fiMarket-Oriented Programming

Sandholm, T. (1993). implementation contract net protocol based marginal
cost calculations. Proceedings National Conference Artificial Intelligence,
pp. 256{262 Washington, DC. AAAI.
Scarf, H. E. (1984). computation equilibrium prices. Scarf, H. E., & Shoven, J. B.
(Eds.), Applied General Equilibrium Analysis, pp. 1{49. Cambridge University Press,
Cambridge.
Shenker, S. (1991). Congestion control computer networks: exercise cost-sharing.
Prepared delivery Annual Meeting American Political Science Association.
Shoham, Y. (1993). Agent-oriented programming. Artificial Intelligence, 60, 51{92.
Shoven, J. B., & Whalley, J. (1984). Applied general-equilibrium models taxation
international trade: introduction survey. Journal Economic Literature, 22,
1007{1051.
Shoven, J. B., & Whalley, J. (1992). Applying General Equilibrium. Cambridge University
Press.
Varian, H. R. (1984). Microeconomic Analysis (second edition). W. W. Norton & Company,
New York.
Waldspurger, C. A., Hogg, T., Huberman, B. A., Kephart, J. O., & Stornetta, S. (1992).
Spawn: distributed computational economy. IEEE Transactions Software Engineering, 18, 103{117.
Wang, Z., & Slagle, J. (1993). object-oriented knowledge-based approach formulating
applied general equilibrium models. Third International Workshop Artificial
Intelligence Economics Management Portland, OR.
Wellman, M. P. (1991). Review Huberman (1988). Artificial Intelligence, 52, 205{218.
Wellman, M. P. (1992). general-equilibrium approach distributed transportation planning. Proceedings National Conference Artificial Intelligence, pp. 282{289
San Jose, CA. AAAI.

23

fiJournal Artificial Intelligence Research 1 (1994) 209-229

Submitted 11/93; published 2/94

Learning Past Tense English Verbs:
Symbolic Pattern Associator vs. Connectionist Models
Charles X. Ling

ling@csd.uwo.ca

Department Computer Science
University Western Ontario
London, Ontario, Canada N6A 5B7

Abstract

Learning past tense English verbs | seemingly minor aspect language acquisition | generated heated debates since 1986, become landmark task
testing adequacy cognitive modeling. Several artificial neural networks (ANNs)
implemented, challenge better symbolic models posed.
paper, present general-purpose Symbolic Pattern Associator (SPA) based upon
decision-tree learning algorithm ID3. conduct extensive head-to-head comparisons
generalization ability ANN models SPA different representations. conclude SPA generalizes past tense unseen verbs better
ANN models wide margin, offer insights case.
also discuss new default strategy decision-tree learning algorithms.

1. Introduction
Learning past tense English verbs, seemingly minor aspect language acquisition,
generated heated debates since first connectionist implementation 1986 (Rumelhart & McClelland, 1986). Based results, Rumelhart McClelland claimed
use acquisition human knowledge language best formulated ANN
(Artificial Neural Network) models without symbol processing postulates existence
explicit symbolic representation rules. Since then, learning past tense become landmark task testing adequacy cognitive modeling. years
number criticisms connectionist modeling appeared (Pinker & Prince, 1988; Lachter &
Bever, 1988; Prasada & Pinker, 1993; Ling, Cherwenka, & Marinov, 1993). criticisms
centered mainly upon issues high error rates low reliability experimental results, inappropriateness training testing procedures, \hidden" features
representation network architecture facilitate learning, well opaque
knowledge representation networks. Several subsequent attempts improving
original results new ANN models made (Plunkett & Marchman, 1991; Cottrell & Plunkett, 1991; MacWhinney & Leinbach, 1991; Daugherty & Seidenberg, 1993).
notably, MacWhinney Leinbach (1991) constructed multilayer neural network
backpropagation (BP), attempted answer early criticisms. hand,
supporters symbolic approach believe symbol structures parse trees,
propositions, etc., rules manipulations, critical cognitive level,
connectionist approach may provide account neural structures
traditional symbol-processing cognitive architecture implemented (Fodor
& Pylyshyn, 1988). Pinker (1991) Prasada Pinker (1993) argue proper

c 1994 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.

fiLing

accounting regular verbs dependent upon production rules, irregular
past-tense ections may generalized ANN-like associative memory.
proper way debating adequacy symbolic connectionist modeling
contrasting competitive implementations. Thus, symbolic implementation needed
compared ANN models. is, fact, challenge posed MacWhinney
Leinbach (1991), assert symbolic methods would work well
model. section titled \Is better symbolic model?" claim:
approach provided even accurate
characterization learning process, might still forced reject
connectionist approach, despite successes. proper way debating conceptualizations contrasting competitive implementations.
present case, would need symbolic implementation could contrasted
current implementation. (MacWhinney & Leinbach, 1991, page 153)
paper, present general-purpose Symbolic Pattern Associator (SPA) based
upon symbolic decision tree learning algorithm ID3 (Quinlan, 1986). shown
(Ling & Marinov, 1993) SPA's results much psychologically realistic
ANN models compared human subjects. issue predictive accuracy,
MacWhinney Leinbach (1991) report important results model unseen
regular verbs. reply criticism, MacWhinney (1993) re-implemented ANN
model, claimed raw generalization power close SPA.
believed case systems learn data set:
good reason equivalent performance two
models. [...] two computationally powerful systems given
set input data, extract every bit data regularity input.
Without processing, much blood squeezed
turnip, systems [SPA ANN] extracted
could. (MacWhinney, 1993, page 295)
show case; obviously reasons one learning
algorithm outperforms another (otherwise study different learning algorithms?).
Occam's Razor Principle | preferring simplest hypothesis complex
ones | creates preference biases learning algorithms. preference bias preference
order among competitive hypotheses hypothesis space. Different learning algorithms,
however, employ different ways measuring simplicity, thus concepts bias
different. well learning program generalizes depends upon degree
regularity data fits bias. study compare raw generalization
ability symbolic ANN models task learning past tense English
verbs. perform extensive head-to-head comparisons ANN SPA, show
effects different representations encodings generalization abilities.
experimental results demonstrate clearly
1. distributed representation, feature connectionists advocating,
lead better generalization compared symbolic representation, arbitrary error-correcting codes proper length;
210

fiLearning Past Tense: Symbolic vs Connectionist Models

2. ANNs cannot learn identity mapping preserves verb stem past
tense well SPA can;
3. new representation suggested MacWhinney (1993) improves predictive accuracy SPA ANN, SPA still outperforms ANN models;
4. sum, SPA generalizes past tense unseen verbs better ANN models
wide margin.
Section 5 discuss reasons SPA better learning model
task English past-tense acquisition. results support view many
rule-governed cognitive processes better modeled symbolic, rather connectionist, systems.

2. Review Previous Work
section, review brie two main connectionist models learning past
tenses English verbs, subsequent criticisms.

2.1 Rumelhart McClelland's Model

Rumelhart McClelland's model based simple perceptron-based pattern associator interfaced input/output encoding/decoding network allows model
associate verb stems past tenses using special Wickelphone/Wickelfeature
phoneme-representation format. learning algorithm classical perceptron convergence procedure. training testing sets mutually disjoint experiments.
errors made model training process broadly follow U-shaped learning curve stages acquisition English past tense exhibited young children.
testing sample consists 86 \unseen" low frequency verbs (14 irregular 72 regular)
randomly chosen. testing sample results 93% error rate
irregulars. regulars fare better 33.3% error rate. Thus, overall error rate
whole testing sample 43% | 37 wrong ambiguous past tense forms 86 tested.
Rumelhart McClelland (1986) claim outcome experiment disconfirms
view exist explicit (though inaccessible) rules underlie human knowledge
language.

2.2 MacWhinney Leinbach's Model

MacWhinney Leinbach (1991) report new connectionist model learning
past tenses English verbs. claim results new simulation far
superior Rumelhart McClelland's results, answer criticisms aimed earlier model. major departure Rumelhart McClelland's
model Wickelphone/Wickelfeature representational format replaced
UNIBET (MacWhinney, 1990) phoneme representational system allows assignment single alphabetic/numerical letter total 36 phonemes. MacWhinney
Leinbach use special templates code phoneme position
word. actual input network created coding individual phonemes sets
211

fiLing

phonetic features way similar coding Wickelphones Wickelfeatures (cf
Section 4.3). network two layers 200 \hidden" units fully connected adjacent
layers. number arrived trial error. addition, network
special-purpose set connections copy input units directly onto output units.
Altogether, 2062 regular irregular English verbs selected experiment
| 1650 used training (1532 regular 118 irregular), 13 low
frequency irregular verbs used testing (MacWhinney & Leinbach, 1991, page 144).
Training network takes 24,000 epochs. end training still 11 errors
irregular pasts. MacWhinney Leinbach believe allow network
run several additional days give additional hidden unit resources, probably
reach complete convergence (MacWhinney & Leinbach, 1991, page 151).
testing error rate reported based small biased test sample 13 unseen
irregular verbs; 9 13 predicted incorrectly. test model
unseen regular verbs: \Unfortunately, test similar set 13 regulars."
(MacWhinney & Leinbach, 1991, page 151).

2.3 Criticism Connectionist Models

Previous current criticisms connectionist models learning past tenses
English verbs center mainly several issues. issues summarized
following subsections.

2.3.1 Error Rates

error rate producing past tenses \unseen" test verbs high
ANN models, important tests carried MacWhinney Leinbach
(1991) model. experimental results indicate neither model reaches level
adult competence. addition, relatively large numbers errors psychologically
realistic since humans rarely make them.

2.3.2 Training Testing Procedures

Rumelhart McClelland's model, MacWhinney Leinbach's model,
generalization ability measured one training/testing sample. Further, testing
sets randomly chosen, small. accuracy testing irregular
verbs vary greatly depending upon particular set testing verbs chosen, thus
multiple runs large testing samples necessary assess true generalization
ability learning model. Therefore, results previous connectionist models
reliable. Section 4, set reliable testing procedure compare connectionist
models symbolic approach. Previous connectionist simulations also
criticized crude training processes (for example, sudden increase regular
verbs training set), create behavior U-shaped learning curves.

2.3.3 Data Representation Network Architecture

past criticisms connectionist models aimed datarepresentation formats employed simulations. Lachter Bever (1988) pointed
212

fiLearning Past Tense: Symbolic vs Connectionist Models

results achieved Rumelhart McClelland's model would impossible without use several TRICS (The Representations Crucially Supposes)
introduced adoption Wickelphone/Wickelfeature representational format.
MacWhinney Leinbach claim improved upon earlier connectionist
model getting rid Wickelphone/Wickelfeature representation format, thus
responded many criticisms format entailed. However, MacWhinney Leinbach also introduce several TRICS data-representation format.
example, instead coding predecessor successor phonemes Wickelphones, introduce special templates code positional information. means
network learn associate patterns phoneme/positions within predetermined consonant/vowel pattern. Further, use restrictive templates gets rid many English
verbs fit chosen template. may bias model favour shorter
verbs, predominantly Anglo-Saxon origin, longer verbs, predominantly composite Latin French origin. Another TRICS introduced phonetic feature
encoding (a distributed representation). clear phonetic features front,
centre, back, high, etc. chosen. represent finer grained \microfeatures"
help capture regularities English past tenses? Section 4.5, show
straightforward symbolic representation leads better generalization
carefully engineered distributed representation. undermines claimed advantages
distributed representation connectionist models.

2.3.4 Knowledge Representation Integration Acquired Knowledge
Pinker Prince (1988), Lachter Bever (1988) point Rumelhart
McClelland try model acquisition production past tense isolation
rest English morphological system. Rumelhart McClelland, well
MacWhinney Leinbach, assume acquisition process establishes direct
mapping phonetic representation stem phonetic representation
past tense form. direct mapping collapses well-established distinctions
lexical item vs. phoneme string, morphological category vs. morpheme. Simply
remaining level phonetic patterns, impossible express new categorical
information first-order (predicate/function/variable) format. One inherent deficits
connectionist implementations thing variable verb
stem, hence way model attain knowledge one could
add sux stem get past tense (Pinker & Prince, 1988, page 124). Since
acquired knowledge networks large weight matrix, usually opaque
human observer, unclear phonological levels processing connectionist
models carry integrated morphological, lexical, syntactical level
processing. Neither Rumelhart McClelland MacWhinney Leinbach address
issue. contrast ANNs whose internal representations entirely opaque,
SPA represent acquired knowledge form production rules, allow
processing, resulting higher-level categories verb stem voiced
consonants, linguistically realistic production rules using new categories regular
verbs, associative templates irregular verbs (Ling & Marinov, 1993).
213

fiLing

3. Symbolic Pattern Associator

take MacWhinney Leinbach's challenge better symbolic model learning
past tense English verbs, present general-purpose Symbolic Pattern Associator
(SPA)1 generalize past tense unseen verbs much accurately
connectionist models section. model symbolic several reasons. First,
input/output representation learning program set phoneme symbols,
basic elements governing past-tense ection. Second, learning
program operates phoneme symbols directly, acquired knowledge
represented form production rules using phoneme symbols well. Third,
production rules phonological level easily generalized firstorder rules use abstract, high-level symbolic categories morphemes
verb stem (Ling & Marinov, 1993). contrast, connectionist models operate
distributed representation (phonetic feature vectors), acquired knowledge
embedded large weight matrix; therefore hard see knowledge
generalized abstract representations categories.

3.1 Architecture Symbolic Pattern Associator

SPA based C4.5 (Quinlan, 1993) improved implementation ID3
learning algorithm (cf. (Quinlan, 1986)). ID3 program inducing classification rules
form decision trees set classified examples. uses information gain ratio
criterion selecting attributes roots subtrees. divide-and-conquer strategy
recursively applied building subtrees remaining examples training set
belong single concept (class); leaf labeled concept. information
gain guides greedy heuristic search locally relevant discriminating attribute
maximally reduces entropy (randomness) divided set examples.
use heuristic usually results building small decision trees instead larger ones
also fit training data.
task learn classify set different patterns single class several
mutually exclusive categories, ID3 shown comparable neural networks
(i.e., within 5% range predictive accuracy) many real-world learning tasks
(cf. (Shavlik, Mooney, & Towell, 1991; Feng, King, Sutherland, & Henery, 1992; Ripley,
1992; Weiss & Kulikowski, 1991)). However, task classify set (input) patterns
(output) patterns many attributes, ID3 cannot applied directly. reason
ID3 treats different output patterns mutually exclusive classes, number
classes would exponentially large and, importantly, generalization individual
output attributes within output patterns would lost.
turn ID3 similar N-to-1 classification system general purpose N-to-M
symbolic pattern associators, SPA applies ID3 output attributes combines
individual decision trees \forest", set trees. similar approach proposed
dealing distributed (binary) encoding multiclass learning tasks NETtalk
(English text-to-speech mapping) (Dietterich, Hild, & Bakiri, 1990). tree takes
input set attributes input patterns, used determine value
1. SPA programs relevant datasets obtained anonymously ftp.csd.uwo.ca
pub/SPA/ .

214

fiLearning Past Tense: Symbolic vs Connectionist Models

one attribute output pattern. specifically, pair input attributes (1 n )
output attributes (!1 !m ) represented as:

1; :::; n ! !1; :::; !m

SPA build total decision trees, one output attribute !i (1
m) taking input attributes 1; :::; n per tree. trees built, SPA
use jointly determine output pattern !1 ; :::; !m input pattern
1; :::; n.

important feature SPA explicit knowledge representation. Decision trees
output attributes easily transformed propositional production rules (Quinlan,
1993). Since entities rules symbols semantic meanings, acquired
knowledge often comprehensible human observer. addition, processing
integration rules yield high-level knowledge (e.g., rules using verb stems)
(Ling & Marinov, 1993). Another feature SPA trees different output
attributes contain identical components (branches subtrees) (Ling & Marinov, 1993).
components similar roles hidden units ANNs since shared
decision trees one output attribute. identical components also
viewed high-level concepts feature combinations created learning program.

3.2 Default Strategies

interesting research issue decision-tree learning algorithms handle default
class. default class class assigned leaves training examples
classified into. call leaves empty leaves. happens attributes
many different values, training set relatively small. cases,
tree construction, branches explored attributes. testing
examples fall empty leaves, default strategy needed assign classes
empty leaves.
easier understanding, use spelling form verbs subsection explain
different default strategies work. (In actual learning experiment verbs
represented phonetic form.) use consecutive left-to-right alphabetic representation,
verb stems past tenses small training set represented follows:
a,f,f,o,r,d,_,_,_,_,_,_,_,_,_
e,a,t,_,_,_,_,_,_,_,_,_,_,_,_
l,a,u,n,c,h,_,_,_,_,_,_,_,_,_
l,e,a,v,e,_,_,_,_,_,_,_,_,_,_

=>
=>
=>
=>

a,f,f,o,r,d,e,d,_,_,_,_,_,_,_
a,t,e,_,_,_,_,_,_,_,_,_,_,_,_
l,a,u,n,c,h,e,d,_,_,_,_,_,_,_
l,e,f,t,_,_,_,_,_,_,_,_,_,_,_

used filler empty space. left-hand 15 columns input patterns
stems verbs; right-hand 15 columns output patterns
corresponding correct past tense forms.
discussed, 15 decision trees constructed, one output attribute.
decision tree first output attribute constructed (see Figure 1 (a))
following 4 examples:
a,f,f,o,r,d,_,_,_,_,_,_,_,_,_ =>
e,a,t,_,_,_,_,_,_,_,_,_,_,_,_ =>
l,a,u,n,c,h,_,_,_,_,_,_,_,_,_ => l

215

fiLing

l,e,a,v,e,_,_,_,_,_,_,_,_,_,_ => l

last column classification first output attribute. However, many
branches (such 1 = c Figure 1 (a)) explored, since training example
attribute value. testing pattern first input attribute equal c,
class assigned to? ID3 uses majority default. is, popular
class whole subtree 1 assigned empty leaves. example above,
either class l chosen since 2 training examples. However,
clearly right strategy task since verb create would output
l...... a......, incorrect. unlikely small training set
variations attribute values, majority default strategy ID3 appropriate
task.

1


e

6
l



c

z

<= Passthrough

__



5
a:1

a:1

l:2

c:0

o:2

z:0

d:20
p

x:n indicates n examples
classified leaf labelled x.
x:0 (boxed) indicates empty leaves.

t:10

Figure 1: (a) Passthrough default

<= Majority

r

d:2

l

d:5

k

t:0

(b) Various default

applications verb past-tense learning, new default heuristic | passthrough
| may suitable. is, classification empty leaf
attribute value branch. example, using passthrough default strategy,
create output c....... passthrough strategy gives decision trees first-order
avor, since production rules empty leaves represented Attribute = X
Class = X X unused attribute values. Passthrough domaindependent heuristic strategy class labels may nothing
attribute values applications.
Applying passthrough strategy alone, however, adequate every output
attribute. endings regular past tenses identical input
patterns, irregular verbs may vowel consonant changes middle
verbs. cases, majority default may suitable passthrough.
order choose right default strategy | majority passthrough | decision
made based upon training data corresponding subtree. SPA first determines
majority class, counts number examples subtrees belong
class. counts number examples subtrees coincide
216

fiLearning Past Tense: Symbolic vs Connectionist Models

passthrough strategy. two numbers compared, default strategy employed
examples chosen. instance, example (see Figure 1 (a)),
majority class l (or a) 2 instances. However, 3 examples coinciding
passthrough default: two l one a. Thus passthrough strategy takes over,
assigns empty leaves level. empty attribute branch c would assigned
class c. Note default strategy empty leaves attribute X depends upon
training examples falling subtree rooted X . localized method ensures
related objects uence calculating default classes. result, SPA
adapt default strategy best suited different levels decision trees.
example, Figure 1 (b), two different default strategies used different levels
tree. use SPA adaptive default strategy throughout remainder
paper. Note new default strategy TRICS data representation;
rather, represents bias learning program. learning algorithm default
strategy independent data representation. effect different data representations
generalization discussed Sections 4.3, 4.5, 4.6. passthrough strategy
imposed ANNs well adding set copy connections input units
twin output units. See Section 4.4 detail.

3.3 Comparisons Default Strategies ID3, SPA, ANN
default strategy neural networks tend take generalizing default classes
compared ID3 SPA? conducted several experiments determine neural
networks' default strategy. assume domain one attribute X
may take values a, b, c, d. class also one a, b, c, d. training
examples attribute values a, b, c | reserved testing default
class. training set contains multiple copies example form certain
majority class. Table 1 shows two sets training/testing examples used test
compare default strategies ID3, SPA neural networks.
Data set 1
Data set 2
Training examples
Training examples
Values X Class # copies Values X Class # copies


10

c
10
b
b
2
b
b
6
c
c
3
c
c
7
Testing example
Testing example

?
1

?
1
Table 1: Two data sets testing default strategies various methods.
classification testing examples ID3 SPA quite easy decide. Since
ID3 takes majority default, output class (with 10 training examples)
first data set, c (with 17 training examples) second data set. SPA,
number examples using passthrough 15 first data set, 13 second
217

fiLing

data set. Therefore, passthrough strategy wins first case output class
d, majority strategy wins second case output class c.
neural networks, various coding methods used represent values attribute X . dense coding, used 00 represent a, 01 b, 10 c 11
d. also tried standard one-per-class encoding, real number encoding (0.2 a,
0.4 b, 0.6 c 0.8 d). networks trained using hidden units
possible case. found cases classification testing example stable; varies different random seeds initialize networks. Table
2 summarises experimental results. ANNs, various classifications obtained 20
different random seeds listed first ones occurring frequently. seems
neural networks consistent default strategy, also
neither majority default ID3 passthrough default SPA. may
explain connectionist models cannot generalize unseen regular verbs well even
training set contains regular verbs (see Section 4.4). networks diculty
(or underconstrained) generalizing identity mapping copies attributes
verb stems past tenses.
classification testing example
Data set 1 Data set 2
ID3

c
SPA

c
ANN, dense coding
b; c
b
ANN, one-per-class
b; c;
c; b
ANN, real numbers
c;
d; c
Table 2: Default strategies ID3, SPA ANN two data sets.

4. Head-to-head Comparisons Symbolic ANN Models

section, perform series extensive head-to-head comparisons using several
different representations encoding methods, demonstrate SPA generalizes
past tense unseen verbs better ANN models wide margin.

4.1 Format data

verb set came MacWhinney's original list verbs. set contains
1400 stem/past tense pairs. Learning based upon phonological UNIBET representation (MacWhinney, 1990), different phonemes represented different
alphabetic/numerical letters. total 36 phonemes. source file transferred
standard format pairs input output patterns. example, verbs
Table 3 represented pairs input output patterns (verb stem => past tense):
6,b,&,n,d,6,n
=>
6,b,&,n,d,6,n,d
I,k,s,E,l,6,r,e,t => I,k,s,E,l,6,r,e,t,I,d

218

fiLearning Past Tense: Symbolic vs Connectionist Models

6,r,3,z => 6,r,o,z
b,I,k,6,m => b,I,k,e,m

See Table 3 (The original verb set available Online Appendix 1). keep one
form past tense among multiple past tenses (such hang-hanged hang-hung)
data set. addition, homophones exist original data set. Consequently,
noise (contradictory data input pattern different output
patterns) training testing examples. Note also information whether
verb regular irregular provided training/testing processes.
base (stem)
UNIBET
b=base
1 = irregular
spelling form phonetic form d= past tense 0 = regular
abandon
6b&nd6n
b
0
abandoned
6b&nd6nd

0
benefit
bEn6fIt
b
0
benefited
bEn6fItId

0
arise
6r3z
b
0
arose
6roz

1
become
bIk6m
b
0
became
bIkem

1
......
Table 3: Source file MacWhinney Leinbach.

4.2 Experiment Setup

guarantee unbiased reliable comparison results, use training testing samples
randomly drawn several independent runs. SPA ANN provided
sets training/testing examples run. allows us achieve reliable
estimate inductive generalization capabilities model task.
neural network program used package called Xerion, developed
University Toronto. several sophisticated search mechanisms
standard steepest gradient descent method momentum. found training
conjugate-gradient method much faster standard backpropagation
algorithm. Using conjugate-gradient method also avoids need search proper
settings parameters learning rate. However, need determine
proper number hidden units. experiments ANNs, first tried various
numbers hidden units chose one produced best predictive accuracy
trial run, use network number hidden units actual runs.
SPA, hand, parameters adjust.
One major difference implementation ANNs SPA SPA take
(symbolic) phoneme letters directly ANNs normally encode phoneme letter
binary bits. (Of course, SPA also apply binary representation). studied
various binary encoding methods compared results SPA using symbolic letter
219

fiLing

representation. Since outputs neural networks real numbers, need decode
network outputs back phoneme letters. used standard method decoding:
phoneme letter minimal real-number Hamming distance (smallest angle)
network outputs chosen. see binary encoding affects generalization,
SPA also trained binary representation. Since SPA's outputs
binary, decoding process may tie several phoneme letters. case, one
chosen randomly. ects probability correct decoding level
phoneme letters. phoneme letters decoded, one letters
incorrect, whole pattern counted incorrect word level.

4.3 Templated, Distributed Representation

set experiments conducted using distributed representation suggested
MacWhinney Leinbach (1991). According MacWhinney Leinbach, output
left-justified template format CCCVVCCCVVCCCVVCCC, C stands
consonant V vowel space holders. input two components: left-justified
template format input, right-justified template format
VVCCC. example, verb bet, represented UNIBET coding bEt, shown
template format follows ( blank phoneme):
INPUT
bEt
template:
OUTPUT
bEt
template:

b__E_t____________
CCCVVCCCVVCCCVVCCC
(left-justified)

_E__t
VVCCC
(right-justified)

b__E_t____________
CCCVVCCCVVCCCVVCCC
(left-justified)

specific distributed representation | set (binary) phonetic features | used
encode phoneme letters connectionist networks. vowel (V
templates) encoded 8 phonetic features (front, centre, back, high, low, middle, round,
diphthong) consonant (C templates) 10 phonetic features
(voiced, labial, dental, palatal, velar, nasal, liquid, trill, fricative interdental). Note
two feature sets vowels consonants identical, templates
needed order decode right type phoneme letters outputs
network.
experimental comparison, decided use right-justified template
(VVCCC) since information redundant. Therefore, used left-justified
template (CCCVVCCCVVCCCVVCCC) input output. (The whole verb set
templated phoneme representation available Online Appendix 1. contains
1320 pairs verb stems past tenses fit template). ease implementation,
added two extra features always assigned 0 vowel phonetic feature
set. Therefore, vowels consonants encoded 10 binary bits. ANN
thus 18 10 = 180 input bits 180 output bits, found one layer 200
hidden units (same MacWhinney (1993) model) reached highest predictive accuracy
trial run. See Figure 2 network architecture used.
220

fiLearning Past Tense: Symbolic vs Connectionist Models

(180 output units)

C

...

...

...

...

......

...

...

...

C

C

V

V

CCCVVCCCVV

C

C

C

(full connection two layers)
......

(200 hidden units)

......

(full connection two layers)

C

...

...

...

...

......

...

...

...

C

C

V

V

CCCVVCCCVV

C

C

C

(180 input units)

Figure 2: architecture network used experiment.
SPA trained tested data sets phoneme letters directly;
is, 18 decision trees built phoneme letters output templates.
see phonetic feature encoding affects generalization, also trained SPA
distributed representation | binary bit patterns 180 input bits
180 output bits | exactly ANN simulation. addition, see
\symbolic" encoding works ANN, also train another neural network (with 120
hidden units) \one-per-class" encoding. is, phoneme letter (total 37;
36 phoneme letters plus one blank) encoded 37 bits, one phoneme letter.
used 500 verb pairs (including regular irregular verbs) training
testing sets. Sampling done randomly without replacement, training testing
sets disjoint. Three runs SPA ANN conducted, SPA ANN
trained tested data set run. Training reached 100% accuracy
SPA around 99% ANN.
Testing accuracy novel verbs produced interesting results. ANN model
SPA using distributed representation similar accuracy, ANN
slightly better. may well caused binary outputs SPA suppress
fine differences prediction. hand, SPA using phoneme letters directly
produces much higher accuracy testing. SPA outperforms neural networks (with
either distributed one-per-class representations) 20 percentage points! testing
results ANN SPA found Table 4. findings clearly indicate
SPA using symbolic representation leads much better generalization ANN models.

4.4 Learning Regular Verbs

Predicting past tense unseen verb, either regular irregular,
easy task. Irregular verbs learned rote traditionally thought since
221

fiLing

Distributed representation
ANN: % Correct
SPA: % Correct
Reg Irrg Comb Reg Irrg Comb
65.3 14.6 60.4 62.2 18.8 58.0
59.7 8.6 53.8 57.9 8.2 52.2
60.0 16.0 55.6 58.0 8.0 53.0
61.7 13.1 56.6 59.4 11.7 54.4

Symbolic representation
ANN: % Correct
SPA: % Correct
Reg Irrg Comb Reg Irrg Comb
63.3 18.8 59.2 83.0 29.2 77.8
58.8 10.3 53.2 83.3 22.4 76.2
58.7 16.0 54.4 80.9 20.0 74.8
60.3 15.0 55.6 82.4 23.9 76.3

Table 4: Comparisons testing accuracy SPA ANN distributed symbolic
representations.
children adults occasionally extend irregular ection irregular-sounding regular
verbs pseudo verbs (such cleef | cleft) (Prasada & Pinker, 1993). similar
novel verb cluster irregular verbs similar phonological patterns,
likely prediction irregular past-tense form. Pinker (1991) Prasada
Pinker (1993) argue regular past tenses governed rules, irregulars may
generated associated memory graded effect irregular past-tense
generalization. would interesting, therefore, compare SPA ANN
past-tense generalization regular verbs only. SPA ANN use same,
position specific, representation, learning regular past tenses would require learning different
suxes2 different positions, learn identity mapping copies verb stem
past tenses verbs different lengths.
used templated representation previous section, training
testing sets contained regular verbs. samples drawn randomly without
replacement. maximize size testing sets, testing sets simply consisted
regular verbs sampled training sets. training testing sets
used following methods compared. see effect adaptive
default strategy (as discussed Section 3.2) generalization, SPA majority
default adaptive default tested. ANN models similar
used previous section (except 160 one-layer hidden units, turned
best predictive accuracy test run). passthrough default strategy
imposed neural networks adding set copy connections connect directly
input units twin output units. MacWhinney Leinbach (1991) used
copy connections simulation. therefore tested networks copy
connection see generalization would improved well.
results predictive accuracy SPA ANNs one run
randomly sampled training testing sets summarized Table 5. see,
SPA adaptive default strategy, combines majority passthrough
default, outperforms SPA majority default strategy used ID3.
2. phonological form three different suxes regular verbs. verb stem ends
(UNIBET phonetic representations), sux Id. example, extend | extended (in
spelling form). verb stem ends unvoiced consonant, sux t. example, talk
| talked. verb stem ends voiced consonant vowel, sux d. example,
solve | solved.

222

fiLearning Past Tense: Symbolic vs Connectionist Models

ANNs copy connections generalize better ones without. However, even
ANN models copy connections lower predictive accuracy SPA (majority). addition, differences predictive accuracy larger smaller sets
training examples. Smaller training sets make difference testing accuracy
evident. training set contains 1000 patterns (out 1184), testing accuracy
becomes similar, would approach asymptotically 100% larger training sets.
Upon examination, errors made ANN models occur identity mapping
(i.e., strange phoneme change drop); verb stems cannot preserved past
tense phonemes previously seen training examples. contradicts
findings Prasada Pinker (1993), show native English speakers generate
regular sux-adding past tenses equally well unfamiliar-sounding verb stems (as long
verb stems sound close irregular verbs). also indicates bias
ANN learning algorithms suitable type task. See discussion
Section 5.
Training
Percent correct testing
size
SPA (adaptive) SPA (majority) ANN (copy con.) ANN (normal)
50
55.4
30.0
14.6
7.3
100
72.9
58.6
34.6
24.9
300
87.0
83.7
59.8
58.2
500
92.5
89.0
82.6
67.9
1000
93.5
92.4
92.0
87.3
Table 5: Predictive accuracy learning past tense regular verbs

4.5 Error Correcting Codes
Dietterich Bakiri (1991) reported increase predictive accuracy errorcorrecting codes large Hamming distances used encode values attributes.
codes larger Hamming distance (d) allow correcting fewer d=2
bits errors. Thus, learning programs allowed make mistakes bit level
without outputs misinterpreted word level.
wanted find performances SPA ANNs improved errorcorrecting codes encoding 36 phonemes. chose error-correcting codes ranging
ones small Hamming distance ones large Hamming distance (using
BHC codes, see Dietterich Bakiri (1991)). number attributes
phoneme large, data representation changed slightly experiment.
Instead 18 phoneme holders templates, 8 consecutive, left-to-right phoneme holders
used. Verbs stems past tenses 8 phonemes removed
training/testing sets. (The whole verb set representation available Online
Appendix 1. contains 1225 pairs verb stems past tenses whose lengths shorter
8). SPA ANN take exactly training/testing sets, contains 500
pairs verb stems past tenses, error-correcting codes encoding phoneme
223

fiLing

letter. Still, training networks 92-bit longer error-correcting codes takes long
run (there 8 92 = 736 input attributes 736 output attributes). Therefore,
two runs 23- 46-bit codes conducted. Consistent Dietterich Bakiri
(1991)'s findings, found testing accuracy generally increases Hamming
distance increases. However, also observed testing accuracy decreases
slightly codes become long. accuracy using 46-bit codes (with Hamming
distance 20) reaches maximum value (77.2%), quite close accuracy
(78.3%) SPA using direct phoneme letter representation. seems trade-off
tolerance errors large Hamming distance diculty learning
longer codes. addition, found testing accuracy ANNs lower one
SPA 23 bit- 46-bit error-correcting codes. results summarized
Table 6.
ANN
Hamming Distance Correct bit level Correct word level
23-bit codes
10
93.5%
65.6%
46-bit codes
20
94.1%
67.4%
SPA
Hamming Distance Correct bit level Correct word level
23-bit codes
10
96.3%
72.4%
46-bit codes
20
96.3%
77.2%
92-bit codes
40
96.1%
75.6%
127-bit codes
54
96.1%
75.4%
Table 6: Comparisons testing accuracy SPA ANNs error-correcting codes
results previous two subsections undermine advantages
distributed representation ANNs, unique feature advocated connectionists.
demonstrated that, task, distributed representation actually allow
adequate generalization. SPA using direct symbolic phoneme letters SPA
error-correcting codes outperform ANNs distributed representation wide margin.
However, neither phoneme symbols bits error-correcting codes encode, implicitly
explicitly, micro-features distributed representation. may
distributed representation used optimally designed. Nevertheless, straightforward
symbolic format requires little representation engineering compared distributed
representation ANNs.

4.6 Right-justified, Isolated Sux Representation

MacWhinney Leinbach (1991) report important results predictive accuracy model unseen regular verbs. reply (MacWhinney, 1993)
paper (Ling & Marinov, 1993), MacWhinney re-implemented ANN model. new
implementation, 1,200 verb stem past-tense pairs training set, among
1081 regular 119 irregular. Training took 4,200 epochs, reached 100%
correct regulars 80% irregulars. testing set consisted 87 regulars 15
irregulars. percent correct testing epoch 4,200 91% regulars 27%
irregulars, combined 80.0% testing set. MacWhinney claimed raw
224

fiLearning Past Tense: Symbolic vs Connectionist Models

generalization power ANN model close SPA. believes
case simply systems trained data set.
realize (via private communication) new representation used MacWhinney's
recent implementation plays critical role improved performance. MacWhinney's
new representation, input (for verb stems) coded right-justified template
CCCVVCCCVVCCCVVCCC. output contains two parts: right-justified template
one input, coda form VVCCC. rightjustified template output used represent past tense without including
sux regular verbs. sux regular past tense always stays coda,
isolated main, right-justified templates. irregular past tense,
coda left empty. example, input output templated patterns past tense
verbs Table 3 represented as:
INPUT
(right-justified)
CCCVVCCCVVCCCVVCCC
___6_b__&_nd_6_n__
b__E_n__6_f__I_t__
________6_r__3_z__
_____b__I_k__6_m__

OUTPUT
(right-justified)
CCCVVCCCVVCCCVVCCC
___6_b__&_nd_6_n__
b__E_n__6_f__I_t__
________6_r__o_z__
_____b__I_k__e_m__

(suffix only)
VVCCC
__d__ (for abandon-abandoned)
I_d__ (for benefit-benefited)
_____ (for arise-arose)
_____ (for become-became)

data representation clearly facilitates learning. regular verbs, output
patterns always identical input patterns. addition, verb-ending phoneme
letters always appear fixed positions (i.e., right VVCCC section
input template) due right-justified, templated representation. Furthermore, sux
always occupies coda, isolated right-justified templates.
performed series experiments see much improvement could accomplish using new representation MacWhinney's recent ANN model
left-justified representation discussed Section 4.3. SPA (with averaged predictive
accuracy 89.0%) outperforms MacWhinney's recent ANN implementation (with predictive accuracy 80.0%) wide margin. addition, predictive accuracy also
improved average 76.3% left-justified representation 82.8%
right-justified, isolated sux one. See results Table 7.

5. General Discussion Conclusions

Two factors contribute generalization ability learning program. first
data representation, bias learning program. Arriving
right, optimal, representation dicult task. argued Prasada Pinker
(1993), regular verbs represented coarse grain terms verb stem
suxes; irregular verbs finer grain terms phonological properties.
Admittedly, SPA works uniformly level phoneme letters, ANNs do. However,
SPA produces simple production rules use phoneme letters directly,
rules generalized first-order rules new representations stems
voiced consonants used across board rule-learning
modules (Ling & Marinov, 1993). one major advantages ANN models.
225

fiLing

Predictive accuracy right-justified, isolated sux representation
SPA
MacWhinney's ANN model
training/testing training/testing
training/testing
500/500
1200/102
1200/102
Run 1
81.3
89.2
Run 2
84.1
90.4
Run 3
83.1
87.4
Average
82.8
89.0
80.0 (one run)
Table 7: Comparisons testing accuracy SPA ANN (with right-justified, isolated
sux representation)
seems quite conceivable children acquire high-level concepts stems
voiced consonants learning noun plurals, verb past tense, verb third-person
singular, comparative adjectives, on. large weight matrix result
learning, hard see knowledge generalized ANN models
shared modules.
Even exactly data representation, exist learning tasks
symbolic methods SPA generalize categorically better ANNs. converse also true. fact ects different inductive biases different learning
algorithms. Occam's Razor Principle | preferring simplest hypothesis
complex ones | creates preference bias, preference choosing certain hypotheses
others hypothesis space. However, different learning algorithms choose different hypotheses use different measurements simplicity. example, among
possible decision trees fit training examples, ID3 SPA induce simple decision
trees instead complicated ones. Simple decision trees converted small sets
production rules. well learning algorithm generalizes depends upon degree
underlying regularities target concept fit bias. words,
underlying regularities represented compactly format hypotheses produced
learning algorithm, data generalized well, even small set training
examples. Otherwise, underlying regularities large hypothesis,
algorithm looking compact ones (as per Occam's Razor Principle), hypotheses inferred accurate. learning algorithm searches hypotheses larger
necessary (i.e., use Occam's Razor Principle) normally \underconstrained"; know, based training examples only, many
competitive hypotheses large size inferred.
also describe bias learning algorithm looking training examples
different classes separated n-dimensional hyperspace n number
attributes. decision node decision tree forms hyperplane described
linear function X = a. hyperplanes perpendicular axis,
also partial-space hyperplanes extend within subregion formed
hyperplanes parents' nodes. Likewise, hidden units threshold function
ANNs viewed forming hyperplanes hyperspace. However, unlike ones
decision trees, need perpendicular axis, full-space
226

fiLearning Past Tense: Symbolic vs Connectionist Models

hyperplanes extend whole space. ID3 applied concepts fit
ANN's bias, especially hyperplanes perpendicular axis, many
zigzag hyperplanes perpendicular axes would needed separate different
classes examples. Hence, large decision tree would needed, fit
ID3's bias. Similarly, ANN learning algorithms applied concepts fit ID3's
bias, especially hyperplanes form many separated, partial-space regions, many
hidden units may needed regions.
Another major difference ANNs ID3 ANNs larger variation
weaker bias (cf. (Geman, Bienenstock, & Doursat, 1992)) ID3. Many
Boolean functions (e.g., linearly separable functions) fit small network (e.g., one
hidden units) small decision tree. sometimes attributed
claimed versatility exibility ANNs; learn (but necessarily predict reliably well) many functions, symbolic methods brittle. However, belief
humans versatile, learning algorithm large variation,
rather set strong-biased learning algorithms, somehow
search bias space add new members set new learning tasks. Symbolic learning algorithms clear semantic components explicit representation,
thus easily construct strong-based algorithms motivated various specific
learning tasks. adaptive default strategy SPA example.
hand, still largely know effectively strengthen bias ANNs many
specific tasks (such identity mapping, k-term DNF, etc.). techniques (such
adding copy connections weight decaying) exist, exact effects biasing
towards classes functions clear.
analyses (Ling & Marinov, 1993), underlying regularities governing
ection past tense English verbs form small set production rules
phoneme letters. especially regular verbs; rules either identity
rules sux-adding rules. example, decision trees converted set
precedence-ordered production rules complicated rules (rules conditions) listed first. example, using consecutive, left-to-right phonetic representation,
typical sux-adding rule verb stems 4 phoneme letters (such talk | talked) is:
4 = k 5 = , !5 =
is, fourth input phoneme k fifth blank (i.e., verb
ending) fifth output phoneme t. hand, identity-mapping rules
one condition. typical identity rule looks like:
3 = l, !3 = l
fact, passthrough default strategy allows identity-mapping rules represented simple first-order format:
3 = X, !3 = X
X phoneme. Clearly, knowledge forming regular past tenses
thus expressed simple, conjunctive rules fit bias SPA (ID3),
therefore, SPA much better generalization ability ANN models.
conclude, demonstrated, via extensive head-to-head comparisons,
SPA realistic better generalization capacity ANNs learning
past tense English verbs. argued symbolic decision-tree/production-rule
learning algorithms outperform ANNs. because, first, domain seems
227

fiLing

governed compact set rules, thus fits bias symbolic learning algorithm;
second, SPA directly manipulates representation better ANNs (i.e.,
symbolic phoneme letters vs. distributed representation); third, SPA able
derive high-level concepts used throughout English morphology. results support
view many high-level, rule-governed cognitive tasks better modeled
symbolic, rather connectionist, systems.

Acknowledgements
gratefully thank Steve Pinker constant encouragement, Marin Marinov, Steve
Cherwenka Huaqing Zeng discussions help implementing SPA.
thank Brian MacWhinney providing verb data used simulation. Discussions
Tom Dietterich, Dave Touretzky Brian MacWhinney, well comments
reviewers, helpful. research conducted support NSERC
Research Grant computing facilities Department.

References

Cottrell, G., & Plunkett, K. (1991). Using recurrent net learn past tense.
Proceedings Cognitive Science Society Conference.
Daugherty, K., & Seidenberg, M. (1993). Beyond rules exceptions: connectionist
modeling approach ectional morphology. Lima, S. (Ed.), Reality
Linguistic Rules. John Benjamins.
Dietterich, T., & Bakiri, G. (1991). Error-correcting output codes: general method
improving multiclass inductive learning programs. AAAI-91 (Proceedings Ninth
National Conference Artificial Intelligence).
Dietterich, T., Hild, H., & Bakiri, G. (1990). comparative study ID3 backpropagation English text-to-speech mapping. Proceedings 7th International
Conference Machine Learning. Morgan Kaufmann.
Feng, C., King, R., Sutherland, A., & Henery, R. (1992). Comparison symbolic, statistical neural network classifiers. Manuscript. Department Computer Science,
University Ottawa.
Fodor, J., & Pylyshyn, Z. (1988). Connectionism cognitive architecture: critical
analysis. Pinker, S., & Mehler, J. (Eds.), Connections Symbols, pp. 3 { 71.
Cambridge, MA: MIT Press.
Geman, S., Bienenstock, E., & Doursat, R. (1992). Neural networks bias/variance
dilemma. Neural Computation, 4, 1 { 58.
Lachter, J., & Bever, T. (1988). relation linguistic structure associative
theories language learning { constructive critique connectionist learning
models. Pinker, S., & Mehler, J. (Eds.), Connections Symbols, pp. 195 { 247.
Cambridge, MA: MIT Press.
228

fiLearning Past Tense: Symbolic vs Connectionist Models

Ling, X., Cherwenka, S., & Marinov, M. (1993). symbolic model learning past
tenses English verbs. Proceedings IJCAI-93 (Thirteenth International Conference Artificial Intelligence), pp. 1143{1149. Morgan Kaufmann Publishers.
Ling, X., & Marinov, M. (1993). Answering connectionist challenge: symbolic model
learning past tense English verbs. Cognition, 49 (3), 235{290.
MacWhinney, B. (1990). CHILDES Project: Tools Analyzing Talk. Hillsdale, NJ:
Erlbaum.
MacWhinney, B. (1993). Connections symbols: closing gap. Cognition, 49 (3),
291{296.
MacWhinney, B., & Leinbach, J. (1991). Implementations conceptualizations: Revising verb model. Cognition, 40, 121 { 157.
Pinker, S. (1991). Rules language. Science, 253, 530 { 535.
Pinker, S., & Prince, A. (1988). language connectionism: Analysis parallel
distributed processing model language acquisition. Pinker, S., & Mehler, J.
(Eds.), Connections Symbols, pp. 73 { 193. Cambridge, MA: MIT Press.
Plunkett, K., & Marchman, V. (1991). U-shaped learning frequency effects multilayered perceptron: Implications child language acquisition. Cognition, 38, 43 {
102.
Prasada, S., & Pinker, S. (1993). Generalization regular irregular morphological
patterns. Language Cognitive Processes, 8 (1), 1 { 56.
Quinlan, J. (1986). Induction decision trees. Machine Learning, 1 (1), 81 { 106.
Quinlan, J. (1993). C4.5 Programs Machine Learning. Morgan Kaufmann: San Mateo,
CA.
Ripley, B. (1992). Statistical aspects neural networks. Invited lectures SemStat
(Seminaire Europeen de Statistique, Sandbjerg, Denmark, 25-30 April 1992).
Rumelhart, D., & McClelland, J. (1986). learning past tenses English verbs.
Rumelhart, D., McClelland, J., & PDP Research Group (Eds.), Parallel Distributed Processing Vol 2, pp. 216 { 271. Cambridge, MA: MIT Press.
Shavlik, J., Mooney, R., & Towell, G. (1991). Symbolic neural learning algorithms:
experimental comparison. Machine Learning, 6 (2), 111 { 144.
Weiss, S., & Kulikowski, C. (1991). Computer Systems Learn: classification prediction methods statistics, neural networks, machine learning, expert systems.
Morgan Kaufmann, San Mateo, CA.

229

fiJournal Artificial Intelligence Research 1 (1993) 47-59

Submitted 6/93; published 9/93

Empirical Analysis Search GSAT
Ian P. Gent

I.P.Gent@edinburgh.ac.uk

Toby Walsh

walsh@loria.fr

Department Artificial Intelligence, University Edinburgh
80 South Bridge, Edinburgh EH1 1HN, United Kingdom
INRIA-Lorraine, 615, rue du Jardin Botanique,
54602 Villers-les-Nancy, France

Abstract

describe extensive study search GSAT, approximation procedure
propositional satisfiability. GSAT performs greedy hill-climbing number satisfied
clauses truth assignment. experiments provide complete picture GSAT's
search previous accounts. describe detail two phases search: rapid hillclimbing followed long plateau search. demonstrate applied randomly
generated 3-SAT problems, simple scaling problem size
mean number satisfied clauses mean branching rate. results allow us
make detailed numerical conjectures length hill-climbingphase, average
gradient phase, conjecture average score average branching
rate decay exponentially plateau search. end showing results
used direct future theoretical analysis. work provides case study
computer experiments used improve understanding theoretical properties
algorithms.

1. Introduction

Mathematicians increasingly recognizing usefulness experiments computers
help advance mathematical theory. surprising therefore one area mathematics
benefitted little empirical results theory algorithms, especially
used AI. Since objects theory abstract descriptions computer programs,
principle able reason programs entirely deductively. However,
theoretical analysis often complex current mathematical tools.
theoretical analysis practical, often limited (unrealistically) simple cases.
example, results presented (Koutsoupias & Papadimitriou, 1992) greedy algorithm
satisfiability apply interesting hard region problems described x3.
addition, actual behaviour real problems sometimes quite different worst
average case analyses. therefore support calls McGeoch (McGeoch, 1986), Hooker
(Hooker, 1993) others development empirical science algorithms.
science, experiments well theory used advance understanding
properties algorithms. One aims paper demonstrate benefits
empirical approach. present surprising experimental results
demonstrate results direct future efforts theoretical analysis.
algorithm studied paper GSAT, randomized hill-climbing procedure
propositional satisfiability (or SAT) (Selman, Levesque, & Mitchell, 1992; Selman & Kautz,
1993a). Propositional satisfiability problem deciding assignment
c 1993 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.

fiGent & Walsh

variables propositional formula makes formula true. Recently,
considerable interest GSAT appears able solve large dicult satisfiability problems beyond range conventional procedures like Davis-Putnam (Selman
et al., 1992). believe results give actually apply larger family
procedures satisfiability called GenSAT (Gent & Walsh, 1993). Understanding
procedures fully considerable practical interest since SAT is, many ways,
archetypical (and intractable) NP-hard problem. addition, many AI problems
encoded quite naturally SAT (eg. constraint satisfaction, diagnosis vision interpretation, refutational theorem proving, planning).
paper structured follows. x2 introduce GSAT, algorithm studied
rest paper. x3 define motivate choice problems used
experiments. experiments described x4. experiments provide
complete picture GSAT's search previous informal accounts. results
experiments analysed closely x5 using powerful statistical tools.
analysis allow us make various experimentally verifiable conjectures GSAT's
search. example, able conjecture: length GSAT's initial hill-climbing
phase; average gradient phase; simple scaling various important features
like score (on hill-climbing performed) branching rate. x6 suggest
results used direct future theoretical analysis. Finally, x7 describe
related work end brief conclusions x8.

2. GSAT

GSAT random greedy hill-climbing procedure. GSAT deals formulae conjunct-

ive normal form (CNF); formula, CNF iff conjunction clauses,
clause disjunction literals. GSAT starts randomly generated truth assignment,
hill-climbs \ ipping" variable assignment gives largest increase
number clauses satisfied (called \score" on). Given choice
several equally good ips, GSAT picks one random. ip increase score,
variable ipped change score (failing that) decreases
score least. Thus GSAT starts random part search space searches
global solution using local information. Despite simplicity, procedure
shown give good performance hard satisfiability problems (Selman et al., 1992).
procedure GSAT()
:= 1 Max-tries
:= random truth assignment
j := 1 Max- ips
satisfies return
else Poss- ips := set vars increase satisfiability
V := random element Poss- ips
:= V's truth assignment ipped
end
end
return

\no satisfying assignment found"
48

fiAn Empirical Analysis Search GSAT

(Gent & Walsh, 1993) describe large number experiments suggest
neither greediness randomness important performance procedure.
experiments also suggest various conjectures. instance, random 3-SAT
problems (see x3) log runtime appears scale less linear dependency
problem size. Conjectures could, noted introduction,
profitably used direct future efforts analyse GSAT theoretically. Indeed,
believe experiments reported suggest various conjectures would
useful proof relationship runtime problem size (see x6
details)

3. Problem Space
able perform experiments algorithm, need source problems
run algorithm. Ideally problems come probability distribution
well-defined properties, contain simple parameters representative
problems occur real situations. Unfortunately, often dicult meet
criteria. practice, one usually forced accept either problems well-defined
distribution simple parameters benchmark set real problems, necessarily
unknown distribution. experiments adopt former approach
use CNF formulae randomly generated according random k-SAT model.
Problems random k-SAT N variables L clauses generated follows:
random subset size k N variables selected clause, variable made positive negative probability 21 . random 3-SAT, phase
transition satisfiable unsatisfiable L approximately 4.3N (Mitchell, Selman,
& Levesque, 1992; Larrabee & Tsuji, 1992; Crawford & Auton, 1993). lower L,
problems generated under-constrained thus satisfiable; higher L, problems generated over-constrained thus unsatisfiable. many NP-complete
problems, problems phase transition typically much dicult solve
problems away transition (Cheeseman, Kanefsky, & Taylor, 1991). region
L=4.3N thus generally considered good source hard SAT problems
focus much recent experimental effort.

4. GSAT's search

GSAT first introduced, noted search try divided two
phases. first phase try, ip increases score. However, phase
relatively short followed second phase ips increase
score, instead sideways moves leave number clauses satisfied.
phase search \plateau" occasional ip increase score.1
One aims paper improve upon informal observations making
quantitative measurements GSAT's search, using measurements make
several experimentally testable predictions.
1. Informal observations effect made Bart Selman presentation (Selman et al.,
1992) AAAI-92. observations enlarged upon (Gent & Walsh, 1992).

49

fiGent & Walsh

experiments, followed three methodological principles (McGeoch, 1986).
First, performed experiments large problem sizes many repetitions, reduce
variance allow emergent properties. Second, sought good views data.
is, looked features performance meaningful predictable
possible. Third, analysed results closely. Suitable analysis data may show
features clear simple presentation. rest paper show
principles enabled us make detailed conjectures GSAT's search.
Many features GSAT's search space graphically illustrated plotting
vary try. obvious feature plot score, number satisfied
clauses. quest good view GSAT's search space, also decided plot \poss ips" ip: is, number equally good ips GSAT randomly
picks. interesting measure since indicates branching rate GSAT's search
space.
begin one try GSAT 500 variable random 3-SAT problem
dicult region L = 4.3N (Figure 1a). Although considerable variation
tries, graph illustrates features common tries. score (in Figure 1a)
poss- ips (in Figure 1b) plotted percentages maximal values, L N
respectively. percentage score starts 87.5%, might seem surprisingly
high.
Theoretically, however, expect random truth assignment k-SAT satisfy
2k ,1 clauses (in instance, 7 ). expected earlier informal description,
8
2k
score climbs rapidly first, attens mount plateau. graph
discrete since positive moves increase score fixed amount,
discreteness lost due small scale. illustrate discreteness, Figure 1b
plot change number satisfied clauses made ip (as exact value,
unscaled). Note x-axis plots Figure 1b same.
Change score

Percentage score
100

6
5

97.5

4
3

95

2
1

92.5

0

% poss-flips

-1
90

20
10

87.5

0
0

40

80

120

160

200

240
flips

0

40

80

120

160

200

240
flips

(a) Score
(b) Change score, poss- ips
Figure 1: GSAT's behaviour one try, N = 500, L = 2150, first 250 ips
behaviour poss- ips considerably complicated score.
easiest first consider poss- ips plateau. start plateau search,
115 ips, coincides large increase poss- ips, corresponding change
50

fiAn Empirical Analysis Search GSAT

region small number ips increase score 1 region
large number ips made leave score unchanged. plateau,
several sharp dips poss- ips. correspond ips increase 1
score effected, seen Figure 1b. seems increase
score plateau, small number ways it. Also,
dominance ips make change score graphically illustrates need
\sideways" ips, need noted (Selman et al., 1992; Gent & Walsh,
1993).
Perhaps fascinating feature initial behaviour poss- ips.
four well defined wedges starting 5, 16, 26, 57 ips, occasional sharp dips.
wedges demonstrate behaviour analogous poss- ips plateau.
plateau spans region ips typically change score: call
region H0 since hill-climbing typically makes zero change score. last wedge
spans region H1 hill-climbing typically increases score 1, seen
clearly Figure 1b. Figure 1b shows next three wedges (reading
right left) span regions H2, H3 , H4 . transition onto plateau,
transition region marked sharp increase poss- ips. Dips
wedges represent unusual ips increase score characteristic
value region, dips poss- ips plateau represent ips
increase score possible. exact correlation seen clearly Figure 1b. Note
experiment, region H change score j + 2 occur,
change score ,1 all. addition, wedge poss- ips appears decay
close linearly. explained facts variable ipped longer
appears poss- ips ( ipping back would decrease score), variables
poss- ips ipped independently other, new variables rarely
added poss- ips consequence earlier ip. plateau, however,
variable ipped change score, remains poss- ips since ipping
back also change score.
determine behaviour typical, generated 500 random 3-SAT problems
N=500 L=4.3N, ran 10 tries GSAT problem. Figure 2a shows
mean percentage score2 Figure 2b presents mean percentage poss- ips together
mean change score ip. (The small discreteness figure due
discreteness Postscript's plotting.)
average percentage score similar behaviour individual run
Figure 1, naturally somewhat smoother. graph average poss- ips seems quite
different, expected neither observe sharply defined dips
poss- ips Figure 1b, sharply defined start wedges, since
happen varying times. remarkable wedges consistent enough
visible averaged 5,000 tries; smoothing wedges start
plateau caused regions starting exactly time try.
Figure 2 distinguish satisfiable unsatisfiable problems.
current technique determining satisfiability 500 variable 3-SAT problems
feasible time. instances able test, believe large
j

2. paper assign score 100% ips performed satisfying truth
assignment already found.

51

fiGent & Walsh

Mean percentage score

Mean change score

100

6
5

97.5

4
3

95

2
1

92.5

0
Mean percent poss-flips

90

-1

20
10

87.5

0
0

40

80

120

160

200

240
flips

0

40

80

120

160

200

240
flips

(a) Mean score
(b) Mean change score, poss- ips
Figure 2: Mean GSAT behaviour, N = 500, L = 4.3N, first 250 ips

differences Figure 2 seen possible plot satisfiable unsatisfiable
problems separately, remains interesting topic investigate future.
Experiments values N ratio clauses variables demonstrated qualitatively similar behaviour. careful analysis shows remarkable fact
behaviour qualitatively similar, quantitatively similar, simple linear dependency N. graphs similar Figure 2 plotted N x-axis
scaled N, behaviour almost identical. illustrate this, Figure 3 shows mean
percentage score, percentage poss- ips, change score, N = 500, 750, 1000,
L = 4.3N first 0.5N ips (250 ips N = 500). Figure 3a Figure 3b
demonstrate closeness scaling, extent may appear contain
one thick line. Figure 3b slight tendency different regions hill-climbing
become better defined increasing N.
figures presented reach early stage plateau search.
investigate along plateau, performed experiments 100, 200, 300, 400,
500 variables 0 2.5N ips.3 Figure 4a shows mean percentage score
case, Figure 4b shows mean percentage poss- ips, magnified -axis
clarity. figures demonstrate closeness scaling plateau.
Figure 4b graphs quite close together Figure 4a. phases hillclimbing become much better defined increasing N. plateau search, although
separate lines distinguishable, difference always considerably less 1%
total number variables.
problems used experiments (random 3-SAT L=4.3N) believed
unusually hard satisfiable probability approximately 12 . Neither
facts appears relevant scaling GSAT's search. check performed
similar range experiments ratio clauses variables 6. Although almost
problems unsatisfiable, observed exactly scaling behaviour. score
3. 100 variables, 2.5N ips close optimal value Max- ips. However, experiments
suggested Max- ips may need vary quadratically larger N (Gent & Walsh, 1993).

52

fiAn Empirical Analysis Search GSAT

Mean change score

Mean percentage score
100

6
5

97.5

4
3

95

2
1

92.5

0
Mean percent poss-flips

90

-1

20
10

87.5

0
0

0.08N 0.16N 0.24N 0.32N 0.40N 0.48N
flips

0.08N 0.16N 0.24N 0.32N 0.40N 0.48N
flips

0

(a) Mean score
(b) Mean change score, poss- ips
Figure 3: Scaling mean GSAT behaviour, N = 500, 750, 1000, first 0.5N ips
Mean percentage score

Mean percentage poss-flips

100

12.5

97.5

10

95

7.5

92.5

5

90

2.5

87.5

0
0

0.4N

0.8N

1.2N

1.6N

2.0N

2.4N
flips

0

0.4N

0.8N

1.2N

1.6N

2.0N

2.4N
flips

(a) mean score, L = 4.3N
(b) mean poss- ips, L = 4.3N
Figure 4: Scaling mean GSAT behaviour, N = 100, 200, 300, 400, 500

reach high value Figure 4a, expected, nevertheless shows
linear scaling. plateau, mean value poss- ips lower before.
observed behaviour L = 3N, almost problems satisfiable.
score approaches 100% faster before, higher value poss- ips reached
plateau, decay value poss- ips seen Figure 4b seem
present.
summarise, shown GSAT's hill-climbing goes several distinct
phases, average behaviour certain important features scale linear fashion
N. results provide considerable advance previous informal descriptions
GSAT's search.
53

fiGent & Walsh

5. Numerical Conjectures
section, show detailed numerical conjectures made data
presented graphically x4 analysed numerically. divide analysis two parts:
first deal plateau search, behaviour relatively simple, analyse
hill-climbing search.
plateau, average score poss- ips seem decay exponentially
simple linear dependency problem size. test this, performed regression analysis
experimental data, using models

(x) = N (B , C e, AxN )
P (x) = N (E + F e, DxN )




(1)
(2)

x represents number ips, (x) average score ip x P (x) average
number possible ips. determine GSAT's behaviour plateau, analysed
data mean score, starting 0.4N ips, time plateau search always appears
started (see x5). experimental data fitted model well. Detailed results
N = 500 given Table 1 three significant figures. values A, B, C change
slightly N, providing evidence scaling GSAT's behaviour. L
= 3N asymptotic mean percentage score close 100% clauses satisfied,
L = 4.3N approximately 99.3% clauses L = 6N approximately
98.2% clauses. good fit also found mean poss- ips behaviour (see Table 2
N = 500), except L = 3N, mean value poss- ips plateau may
constant. seems L = 4.3N asymptotic value poss- ips 10% N
6 5% N.
important note behaviour analysed mean behaviour
satisfiable unsatisfiable problems. likely individual problems exhibit
similar behaviour different asymptotes, expect even satisfiable problems
yield mean score 100% asymptotically. Note N increases small error
percentage terms may correspond large error actual score. result,
predictions asymptotic score may inaccurate large N, large numbers
ips. experimentation necessary examine issues detail.
L/N N

B
C
R2
3 500 0.511 2.997 0.0428 0.995
4.3 500 0.566 4.27 0.0772 0.995
6 500 0.492 5.89 0.112 0.993
Table 1: Regression results average score GSAT.4
4. value R2 number interval [0; 1] indicating well variance data explained
regression formula. 1 , R2 ratio variance data predicted value,
variance data mean data. value R2 close 1 indicates regression
formula fits data well.

54

fiAn Empirical Analysis Search GSAT

L/N N

E
F
R2
4.3 500 0.838 0.100 0.0348 0.996
6 500 0.789 0.0502 0.0373 0.999
Table 2: Regression results average poss- ips GSAT.
also analysed GSAT's behaviour hill-climbing phase. Figure 1b
shows regions ips increase score 4, 3, 2, 1.
Analysis data suggested phase lasts roughly twice length previous
one. motivates following conjectures: GSAT moves sequence regions
H j = :::; 3; 2; 1 majority ips increase score j ,
length region H proportional 2, (except region H0 represents
plateau search).
investigate conjecture, analysed 50 tries 20 different problems
random 3-SAT problems N=500 L=4.3N. rarely observe ips H
increase score less j , define H region first ip
increases score exactly j first ip increases score less
j (unless latter actually appears former, case H empty). One
simple test conjecture compare total time spent H total time
end H ; predict ratio 12 . j = 1 4 mean standard
deviations ratio, length region shown Table 3.5 data
supports conjecture although j increases region slightly longer predicted.
total length hill-climbing N=500 0.22N ips, N=100 0.23N.
consistent scaling behaviour observed x4.
j

j

j

j

j

j

j

j

Region
mean ratio
climbing
|
H1
0.486
H2
0.513
H3
0.564
H4
0.574

s.d. mean length
|
112
0.0510
54.7
0.0672
29.5
0.0959
15.7
0.0161
7.00

s.d.
7.59
7.69
5.12
3.61
2.48

Table 3: Comparative Absolute Lengths hill-climbing phases
conjecture appealing corollary. Namely, non-empty hillclimbing regions, average change score per ip hill-climbing is:
1 1 + 1 2 + 1 3 + 1 4 + + 1 2:
(3)
2
4
8
16
2
follows mean gradient entire hill-climbing phase approximately 2.
N=500, observed mean ratio change score per ip hill-climbing 1.94


5. data \All climbing" length start H0 .

55

fiGent & Walsh

standard deviation 0.1. N=100, ratio 1.95 standard deviation
0.2.
model presented ignores ips H increase score
j . ips seen Figure 1b regions H3 H1. experiment 9.8% ips
H1 size 2 6.3% ips H2 size 3. However, ips size j + 2
rare, forming 0.02% ips H1 H2 . conjectured
exponential decay similar H0 occurs H . is, conjecture
average change number satisfied clauses ip x ip x + 1 H given by:
j

j

j

j+E

x
e, Dj N

(4)
might correspond model GSAT's search certain number
ips size j + 1 region H , probability making j + 1 ip merely
dependent number ips left; rest time, GSAT obliged make
ip size j . data 1000 tries fitted model well, giving values R2 96.8%
H1 97.5% H2 . regression gave estimates parameters of: D1 = 0:045,
E1 = 0:25, D2 = 0:025, E2 = 0:15. surprisingly, since region H3 short,
data noisy obtain better fit model (4) one linear decay.
results support conjecture, experiments larger problems needed
lengthen region H j 3.
j



j

j

6. Theoretical Conjectures

Empirical results like given x5 used direct efforts analyse algorithms
theoretically. example, consider plateau region GSAT's search. model (1)
applies also successful tries, asymptotic score L, giving
(x) = L , C N e, AxN
Differentiating respect x get,
dS (x) = C e, axN = L , (x)
dx


gradient good approximation , average size ip x. Hence,
= L A, SN(x)
experiments suggest downward ips +1 rare
plateau. Thus, good (first order) approximation follows, prob(D = j )
probability ip x size j .




x

x

x

XL

=
x

j

Hence,

=,L

x

j prob(D = j ) = prob(D = 1)
x

prob(D = 1) = L A, SN(x)
x

56

x

fiAn Empirical Analysis Search GSAT

is, plateau probability making ip size +1 may directly proportional L , (x), average number clauses remaining unsatisfied inversely
proportional N, number variables. similar analysis result given
prob(D = j +1) hill-climbing region H , would explain model (4) proposed
x5.
theoretical conjecture correct, used show mean number
ips successful tries proportional N ln N. investigation, experimental theoretical, needed determine accuracy prediction.
conjectures section seen conjectures formal theory
GSAT's search might look like, useful determining results average runtime optimal setting parameter like Max- ips. addition,
develop model GSAT's search prob(D = j ) related number
unsatisfied clauses N equation, experimentally observed
exponential behaviour linear scaling score follow immediately.
x

j

x

7. Related Work
Prior introduction GSAT (Selman et al., 1992), closely related set procedures studied Gu (Gu, 1992). procedures different control structure
GSAT allows them, instance, make sideways moves upwards moves
possible. makes dicult compare results directly. Nevertheless,
confident approach taken would apply equally well procedures,
similar results could expected. Another \greedy algorithm satisfiability"
analysed (Koutsoupias & Papadimitriou, 1992), results directly
applicable because, unlike GSAT, disallows sideways ips.
(Gent & Walsh, 1993) describe empirical study GenSAT, family procedures related GSAT. study focuses importance randomness, greediness
hill-climbing effectiveness procedures. addition, determine
performance depends parameters like Max-tries Max- ips. showed also
certain variants GenSAT could outperform GSAT random problems. would
interesting perform similar analysis given closely related
procedures.
GSAT closely related simulated annealing (van Laarhoven & Aarts, 1987)
Metropolis algorithm, use greedy local search randomised method
allowing non-optimal ips. Theoretical work algorithms applied SAT
problems, example (Jerrum, 1992; Jerrum & Sorkin, 1993), experimental studies
relationship GSAT simulated annealing yet reached tentative
conclusions (Selman & Kautz, 1993b; Spears, 1993).
Procedures like GSAT also successfully applied constraint satisfaction
problems satisfiability. example, (Minton, Johnston, Philips, & Laird, 1990)
proposed greedy local search procedure performed well scheduling observations
Hubble Space Telescope, constraint problems like million-queens,
3-colourability. would interesting see results given map across
new problem domains.
57

fiGent & Walsh

8. Conclusions

described empirical study search GSAT, approximation procedure
satisfiability. performed detailed analysis two basic phases GSAT's search,
initial period fast hill-climbing followed longer period plateau search.
shown hill-climbing phases broken number
distinct phases corresponding progressively slower climbing, phase lasting
twice long last. also shown that, certain well defined problem classes,
average behaviour certain important features GSAT's search (the average score
average branching rate given point) scale remarkably simple way
problem size also demonstrated behaviour features
modelled well simple exponential decay, plateau hill-climbing
phase. Finally, used experiments conjecture various properties (eg. probability
making ip certain size) useful theoretical analysis GSAT.
results illustrate carefully performed experiments used guide theory,
computers increasingly important r^ole play analysis algorithms.

Acknowledgements
research supported SERC Postdoctoral Fellowship first author
HCM Postdoctoral fellowship second. thank Alan Bundy, Ian Green,
members Mathematical Reasoning Group constructive comments
quadrillion CPU cycles donated experiments SERC grant
GR/H/23610. also thank Andrew Bremner, Judith Underwood, reviewers
journal help.

References
Cheeseman, P., Kanefsky, B., & Taylor, W. (1991). really hard problems are.
Proceedings 12th IJCAI, pp. 163{169. International Joint Conference
Artificial Intelligence.
Crawford, J., & Auton, L. (1993). Experimental results crossover point satisfiability problems. Proceedings Eleventh National Conference Artificial
Intelligence, pp. 21{27. AAAI Press/The MIT Press.
Gent, I. P., & Walsh, T. (1993). Towards Understanding Hill-climbing Procedures
SAT. Proceedings Eleventh National Conference Artificial Intelligence,
pp. 28{33. AAAI Press/The MIT Press.
Gent, I. P., & Walsh, T. (1992). enigma SAT hill-climbing procedures. Research
paper 605, Dept. Artificial Intelligence, University Edinburgh.
Gu, J. (1992). Ecient local search large-scale satisfiability problems. SIGART
Bulletin, 3 (1).
58

fiAn Empirical Analysis Search GSAT

Hooker, J. N. (1993). Needed: empirical science algorithms. Tech. rep., Graduate
School Industrial Administration, Carnegie Mellon University, Pittsburgh PA.
Jerrum, M. (1992). Large cliques elude Metropolis process. Random Structures
Algorithms, 3 (4), 347{359.
Jerrum, M., & Sorkin, G. (1993). Simulated annealing graph bisection. Tech. rep.
ECS-LFCS-93-260, Department Computer Science, University Edinburgh.
Koutsoupias, E., & Papadimitriou, C. H. (1992). greedy algorithm satisfiability.
Information Processing Letters, 43, 53{55.
Larrabee, T., & Tsuji, Y. (1992). Evidence Satisfiability Threshold Random 3CNF
Formulas. Tech. rep. UCSC-CRL-92-42, Baskin Center Computer Engineering
Information Sciences, University California, Santa Cruz.
McGeoch, C. (1986). Experimental Analysis Algorithms. Ph.D. thesis, Carnegie Mellon
University. Also available CMU-CS-87-124.
Minton, S., Johnston, M. D., Philips, A. B., & Laird, P. (1990). Solving large-scale constraint satisfaction scheduling problems using heuristic repair method.
AAAI-90, Proceedings Eighth National Conference Artificial Intelligence, pp. 17{
24. AAAI Press/MIT Press.
Mitchell, D., Selman, B., & Levesque, H. (1992). Hard easy distributions SAT
problems. Proceedings, 10th National Conference Artificial Intelligence. AAAI
Press/The MIT Press.
Selman, B., & Kautz, H. (1993a). Domain-independent extensions GSAT: Solving large
structured satisfiability problems. Proceedings, IJCAI-93. International Joint Conference Artificial Intelligence.
Selman, B., & Kautz, H. (1993b). empirical study greedy local search satisfiability
testing. Proceedings Eleventh National Conference Artificial Intelligence,
pp. 46{51. AAAI Press/The MIT Press.
Selman, B., Levesque, H., & Mitchell, D. (1992). new method solving hard satisfiability
problems. Proceedings, 10th National Conference Artificial Intelligence. AAAI
Press/The MIT Press.
Spears, W. M. (1993). Simulated annealing hard satisfiability problems. Tech. rep.
AIC-93-015, AI Center, Naval Research Laboratory.
van Laarhoven, P., & Aarts, E. (1987). Simulated Annealing: Theory Applications. D.
Reidel Publishing Company, Dordrecht, Holland.

59

fiJournal Artificial Intelligence Research 1 (1993) 109-138

Submitted 7/93; published 12/93

Decidable Reasoning Terminological Knowledge
Representation Systems
Martin Buchheit

German Research Center Artificial Intelligence (DFKI)
Stuhlsatzenhausweg 3, D-66123 Saarbrucken, Germany

Francesco M. Donini
Andrea Schaerf

buchheit@dfki.uni-sb.de
donini@assi.dis.uniroma1.it
aschaerf@assi.dis.uniroma1.it

Dipartimento di Informatica e Sistemistica
Universita di Roma \La Sapienza", Via Salaria 113, I-00198 Roma, Italy

Abstract

Terminological knowledge representation systems (TKRSs) tools designing
using knowledge bases make use terminological languages (or concept languages).
analyze theoretical point view TKRS whose capabilities go beyond
ones presently available TKRSs. new features studied, often required practical
applications, summarized three main points. First, consider highly expressive terminological language, called ALCNR, including general complements concepts,
number restrictions role conjunction. Second, allow express inclusion statements general concepts, terminological cycles particular case. Third,
prove decidability number desirable TKRS-deduction services (like satisfiability,
subsumption instance checking) sound, complete terminating calculus
reasoning ALCNR-knowledge bases. calculus extends general technique
constraint systems. byproduct proof, get also result inclusion
statements ALCNR simulated terminological cycles, descriptive semantics
adopted.

1. Introduction
general characteristic many proposed terminological knowledge representation systems
(TKRSs) krypton (Brachman, Pigman Gilbert, & Levesque, 1985), nikl (Kaczmarek, Bates, & Robins, 1986), back (Quantz & Kindermann, 1990), loom (MacGregor &
Bates, 1987), classic (Borgida, Brachman, McGuinness, & Alperin Resnick, 1989), kris
(Baader & Hollunder, 1991), k-rep (Mays, Dionne, & Weida, 1991), others (see Rich,
editor, 1991; Woods & Schmolze, 1992), made two different components. Informally speaking, first general schema concerning classes individuals
represented, general properties mutual relationships, second
(partial) instantiation schema, containing assertions relating either individuals
classes, individuals other. characteristic, mentioned proposals
inherit seminal TKRS kl-one (Brachman & Schmolze, 1985), shared also
several proposals database models Abrial's (1974), candide (Beck, Gala, &
Navathe, 1989), taxis (Mylopoulos, Bernstein, & Wong, 1980).
Retrieving information actual knowledge bases (KBs) built using one systems deductive process involving schema (TBox) instantiation (ABox).
c 1993 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.

fiBuchheit, Donini, & Schaerf

fact, TBox set constraints possible ABoxes, contains intensional
information classes. information taken account answering queries
KB.
realization use KB, TKRS provide mechanical solution
least following problems (from point on, use word concept refer
class):
1. KB-satisfiability : ABox TBox consistent other? is,
KB admit model? positive answer useful validation phase,
negative answer used make inferences refutation-style. latter
precisely approach taken paper.
2. Concept Satisfiability : given KB concept C , exist least one
model KB assigning non-empty extension C ? important
rule meaningless concepts KB design phase, also processing
user's queries, eliminate parts query cannot contribute answer.
3. Subsumption : given KB two concepts C D, C general
model KB? Subsumption detects implicit dependencies among concepts
KB.
4. Instance Checking : given KB, individual concept C , instance
C model KB? Note retrieving individuals described
given concept (a query database lexicon) formulated set parallel
instance checkings.
questions precisely characterized TKRS given semantics
(see next section), defines models KB gives meaning expressions
KB. problems formalized, one start theoretical analysis
them, and|maybe independently|a search reasoning procedures accomplishing
tasks. Completeness correctness procedures judged respect formal
statements problems.
now, proposed systems give incomplete procedures solving
problems 1{4, except kris1. is, inferences missed, cases without
precise semantical characterization ones are. designer user needs
(more) complete reasoning, she/he must either write programs suitable programming
language (as database proposal Abrial, taxis), define appropriate inference rules completing inference capabilities system (as back, loom,
classic). theoretical point view, several systems (e.g., loom) even
known complete procedures ever exist|i.e., decidability corresponding
problems known.
Recent research computational complexity subsumption uence
many TKRSs choice incomplete procedures. Brachman Levesque (1984)
1. Also system classic complete, w.r.t. non-standard semantics treatment
individuals. Complete reasoning w.r.t. standard semantics individuals provided, coNPhard (Lenzerini & Schaerf, 1991).

110

fiDecidable Reasoning Terminological KR Systems

started research analyzing complexity subsumption pure concept expressions, abstracting KBs (we call problem later paper pure subsumption). motivation focusing small problem pure subsumption
fundamental inference TKRS. turned pure subsumption tractable
(i.e., worst-case polynomial-time solvable) simple languages, intractable slight
extensions languages, subsequent research definitely confirmed (Nebel, 1988;
Donini, Lenzerini, Nardi, & Nutt, 1991a, 1991b; Schmidt-Schau & Smolka, 1991; Donini,
Hollunder, Lenzerini, Marchetti Spaccamela, Nardi, & Nutt, 1992). Also, beyond computational complexity, pure subsumption proved undecidable TKRSs U (Schild,
1988), kl-one (Schmidt-Schau, 1989) nikl (Patel-Schneider, 1989).
Note extending language results enhancing expressiveness, therefore
result research could summarized as: TKRS language expressive,
higher computational complexity reasoning language|as Levesque
(1984) first noted. result interpreted two different ways, leading two
different TKRSs design philosophies:
1. `General-purpose languages TKRSs intractable, even undecidable,
tractable languages expressive enough practical interest'. Following interpretation, several TKRSs (such nikl, loom back) incomplete
procedures pure subsumption considered satisfactory (e.g., see (MacGregor &
Brill, 1992) loom). completeness abandoned basic subproblem,
completeness overall reasoning procedures issue anymore; issues
arise, compare incomplete procedures (Heinsohn, Kudenko, Nebel,
& Profitlich, 1992), judge procedure \complete enough" (MacGregor,
1991). practical tool, inference rules used systems achieve
expected behavior KB w.r.t. information contained it.
2. `A TKRS (by definition) general-purpose, hence must provide tractable
complete reasoning user'. Following line, TKRSs (such krypton
classic) provide limited tractable languages expressing concepts, following
\small-can-be-beautiful" approach (see Patel-Schneider, 1984). gap
expressible TKRS language needed expressed
application filled user, (sort of) programming inference rules.
course, usual problems present program development debugging arise
(McGuinness, 1992).
common approaches user must cope incomplete reasoning.
difference former approach, burden regaining useful yet missed
inferences mostly left developers TKRS (and user supposed specify
\complete enough"), latter mainly left user.
perfectly reasonable approaches practical context, incomplete procedures
specialized programs often used deal intractable problems. opinion
incomplete procedures provisional answer problem|the best possible
now. order improve answer, theoretical analysis general problems
1{4 done.
Previous theoretical results deal problems 1{4 full generality.
example, problems studied (Nebel, 1990, Chapter 4), incomplete
111

fiBuchheit, Donini, & Schaerf

procedures given, cycles considered. (Donini, Lenzerini, Nardi, & Schaerf,
1993; Schaerf, 1993a) complexity instance checking analyzed, KBs
without TBox treated. Instance checking also analyzed (Vilain, 1991),
addressing part problem performed parsing.
addition, think expressiveness actual systems enhanced
making terminological cycles (see Nebel, 1990, Chapter 5) available TKRSs.
feature undoubtable practical interest (MacGregor, 1992), yet present TKRSs
approximate cycles, using forward inference rules (as back, classic, loom).
opinion, order make terminological cycles fully available complete TKRSs,
theoretical investigation still needed.
Previous theoretical work cycles done (Baader, 1990a, 1990b; Baader, Burkert,
Hollunder, Nutt, & Siekmann, 1990; Dionne, Mays, & Oles, 1992, 1993; Nebel, 1990, 1991;
Schild, 1991), considering KBs formed TBox alone. Moreover, approaches
deal number restrictions (except Nebel, 1990, Section 5.3.5) |a basic feature
already provided TKRSs| techniques used seem easily extensible
reasoning ABoxes. compare detail several works Section 4.
paper, propose TKRS equipped highly expressive language, including constructors often required practical applications, prove decidability problems
1{4. particular, system uses language ALCNR, supports general complements concepts, number restrictions role conjunction. Moreover, system allows
one express inclusion statements general concepts and, particular case,
terminological cycles. prove decidability means suitable calculus, developed extending well established framework constraint systems (see Donini et al.,
1991a; Schmidt-Schau & Smolka, 1991), thus exploiting uniform approach reasoning
TKRSs. Moreover, calculus easily turned decision procedure.
paper organized follows. Section 2 introduce language,
give Tarski-style extensional semantics, commonly used. Using
semantics, establish relationships problems 1{4 allow us concentrate
KB-satisfiability only. Section 3 provide calculus KB-satisfiability, show
correctness termination calculus. Hence, conclude KB-satisfiability
decidable ALCNR, main result paper. Section 4 compare
approach previous results decidable TKRSs, establish equivalence
general (cyclic) inclusion statements general concept definitions using descriptive
semantics. Finally, discuss detail several practical issues related results
Section 5.

2. Preliminaries

section first present basic notions regarding concept languages.
describe knowledge bases built using concept languages, reasoning services
must provided extracting information knowledge bases.

2.1 Concept Languages

concept languages, concepts represent classes objects domain interest,
roles represent binary relations objects. Complex concepts roles
112

fiDecidable Reasoning Terminological KR Systems

defined means suitable constructors applied concept names role names.
particular, concepts roles ALCNR formed means following syntax
(where Pi (for = 1; : : :; k) denotes role name, C denote arbitrary concepts,
R arbitrary role):

C; ,! j

>j
?j

(C u D) j
(C D) j

:C j
8R.C j
9R.C j
( n R) j ( n R)
R ,! P1 u u Pk

(concept name)
(top concept)
(bottom concept)
(conjunction)
(disjunction)
(complement)
(universal quantification)
(existential quantification)
(number restrictions)
(role conjunction)

confusion arises drop brackets around conjunctions disjunctions.
interpret concepts subsets domain roles binary relations domain.
precisely, interpretation = (I ; ) consists nonempty set (the domain
) function (the extension function ), maps every concept subset
every role subset . interpretation concept names
role names thus restricted AI , P , respectively. Moreover,
interpretation complex concepts roles must satisfy following equations (]fg
denotes cardinality set):

>I =
?I = ;

(C u D)I
(C D)I
(:C )I
(8R.C )I
(9R.C )I
( n R)I
( n R)I
(P1 u u Pk )I

=
=
=
=
=
=
=
=

C \ DI
C [ DI
n C
fd1 2 j 8d2 : (d1; d2) 2 RI ! d2 2 C g
fd1 2 j 9d2 : (d1; d2) 2 RI ^ d2 2 C g
fd1 2 j ]fd2 j (d1; d2) 2 RI g ng
fd1 2 j ]fd2 j (d1; d2) 2 RI g ng
P1I \ \ PkI

2.2 Knowledge Bases

(1)

knowledge base built means concept languages generally formed two components: intensional one, called TBox, extensional one, called ABox.
first turn attention TBox. said before, intensional level specifies properties concepts interest particular application. Syntactically,
properties expressed terms call inclusion statements. inclusion
113

fiBuchheit, Donini, & Schaerf

statement (or simply inclusion) form

CvD
C two arbitrary ALCNR-concepts. Intuitively, statement specifies
every instance C also instance D. precisely, interpretation satisfies
inclusion C v C DI .
TBox finite set inclusions. interpretation model TBox
satisfies inclusions .
general, TKRSs provide user mechanisms stating concept introductions
(e.g., Nebel, 1990, Section 3.2) form =: (concept definition, interpreted set
equality), _ (concept specification, interpreted set inclusion), restrictions
left-hand side concept must concept name, concept name
one introduction allowed, terminological cycles allowed, i.e.,
concept name may occur|neither directly indirectly|within introduction.
restrictions make possible substitute occurrence defined concept
definition.
impose restrictions form inclusions, obtaining statements
syntactically expressive concept introductions. particular, definition
form =: expressed system using pair inclusions v
v specification form _ simply expressed v D.
Conversely, inclusion form C v D, C arbitrary concepts, cannot
expressed concept introductions. Moreover, cyclic inclusions allowed
statements, realizing terminological cycles.
shown (Nebel, 1991), least three types semantics terminological cycles, namely least fixpoint, greatest fixpoint, descriptive semantics.
Fixpoint semantics choose particular models among set interpretations satisfy
statement form =: D. models chosen least greatest fixpoint
equation. descriptive semantics instead considers interpretations
satisfy statement (i.e., fixpoints) models.
However, fixpoint semantics naturally apply fixpoint statements like =: D,
\function" A, i.e., may appear D, obvious way
extend general inclusions. addition, since language includes constructor
complement general concepts, \function" may monotone, therefore
least greatest fixpoints may unique. Whether exists
definitional semantics suitable cyclic definitions expressive languages still
unclear.
Conversely, descriptive semantics interprets statements restricting set
possible models, definitional import. Although completely satisfactory
practical cases (Baader, 1990b; Nebel, 1991), descriptive semantics considered
appropriate one general cyclic statements powerful concept languages.
Hence, seems suitable extended case exactly one
adopted above.
Observe decision put general inclusions TBox standard one.
fact, TKRS like krypton statements put ABox. However, conceive
114

fiDecidable Reasoning Terminological KR Systems

inclusions generalization traditional TBox statements: acyclic concept introductions,
definitional import, perfectly expressed inclusions; cyclic concept
introductions expressed well, descriptive semantics adopted. Therefore,
believe inclusions part TBox.
Notice role conjunction allows one express practical feature subroles.
example, role ADOPTEDCHILD written CHILD u ADOPTEDCHILD0, ADOPTEDCHILD' role name, making subrole CHILD. Following idea, every hierarchy
role names rephrased set role conjunctions, vice versa.
Actual systems usually provide construction hierarchies roles means
role introductions (i.e., statements form P =: R P _ R) TBox. However,
simple language roles, cyclic definitions roles always reduced acyclic
definitions, explained (Nebel, 1990, Sec.5.3.1). role definitions acyclic, one
always substitute every concept role name definition, obtaining
equivalent concept. Therefore, consider role definitions paper,
conceive TBox set concept inclusions.
Even so, worth notice concept inclusions express knowledge roles.
particular, domain range restrictions roles expressed, way similar
one (Catarci & Lenzerini, 1993). Restricting domain role R concept C
range concept done two inclusions

9R.> v C; > v 8R.D
straightforward show interpretation satisfies two inclusions,
RI C .

Combining subroles domain range restrictions also possible partially
express constructor role restriction, present various proposals (e.g.,
language FL Brachman & Levesque, 1984). Role restriction, written R : C ,
defined (R : C )I = f(d1; d2) 2 j (d1; d2) 2 RI ^ d2 2 C g. example
role DAUGHTER, formulated CHILD:Female, partially simulated
CHILD u DAUGHTER0, inclusion > v 8DAUGHTER0.Female. However, simulation
would complete number restrictions: E.g., mother least three daughters,
know least three female children; instead know three
female children cannot infer three daughters.
turn attention extensional level, i.e., ABox. ABox
essentially allows one specify instance-of relations individuals concepts,
pairs individuals roles.
Let alphabet symbols, called individuals. Instance-of relationships expressed terms membership assertions form:

C (a);

R(a; b);

b individuals, C ALCNR-concept, R ALCNR-role. Intuitively, first form states instance C , whereas second form states
related b means role R.
115

fiBuchheit, Donini, & Schaerf

order assign meaning membership assertions, extension function
interpretation extended individuals mapping elements
way aI 6= bI 6= b. property called Unique Name Assumption; ensures
different individuals interpreted different objects.
interpretation satisfies assertion C (a) aI 2 C , satisfies R(a; b)

(a ; bI ) 2 RI . ABox finite set membership assertions. model ABox
satisfies assertions A.
ALCNR-knowledge base pair = hT ; Ai TBox
ABox. interpretation model model model A.
formally define problems 1{4 mentioned introduction. Let
ALCNR-knowledge base.
1. KB-satisfiability : satisfiable, model;
2. Concept Satisfiability : C satisfiable w.r.t , exists model
C 6= ;;
3. Subsumption : C subsumed w.r.t. , C DI every model ;
4. Instance Checking : instance C , written j= C (a), assertion C (a)
satisfied every model .
(Nebel, 1990, Sec.3.3.2) shown ABox plays active role checking
concept satisfiability subsumption. particular, Nebel shows ABox (subject
satisfiability) replaced empty one without affecting result
services. Actually, (Nebel, 1990), property stated language less expressive ALCNR. However, easy show extends ALCNR. important
remark property valid concept languages. fact,
languages include constructors refer individuals concept language, e.g., constructor one-of (Borgida et al., 1989) forms concept set
enumerated individuals. concept language includes constructor individuals
TBox interact individuals ABox, shown (Schaerf, 1993b).
consequence, concept satisfiability subsumption depend also ABox.

Example 2.1 Consider following knowledge base = hT ; Ai:
= f9TEACHES.Course v (Student u 9DEGREE.BS) Prof;
Prof v 9DEGREE.MS;
9DEGREE.MS v 9DEGREE.BS;
MS u BS v ?g
= fTEACHES(john; cs156); ( 1 DEGREE)(john); Course(cs156)g
fragment hypothetical knowledge base describing organization university.
first inclusion, instance, states persons teaching course either graduate
students (students BS degree) professors. easy see satisfiable.
example, following interpretation satisfies inclusions assertions
116

fiDecidable Reasoning Terminological KR Systems

A, therefore model :
= fjohn; cs156; csbg; johnI = john; cs156I = cs156
StudentI = fjohng; ProfI = ;; CourseI = fcs156g; BSI = fcsbg
MSI = ;; TEACHESI = f(john; cs156)g; DEGREEI = f(john; csb)g
described interpretation giving , values
concept names role names. straightforward see values complex
concepts roles uniquely determined imposing must satisfy Equations 1
page 113.
Notice possible draw several non-trivial conclusions . example,
infer j= Student(john). Intuitively shown follows: John teaches
course, thus either student BS professor. can't professor
since professors least two degrees (BS MS) one, therefore
student.
Given previous semantics, problems 1{4 reduced KB-satisfiability
(or complement) linear time. fact, given knowledge base = hT ; Ai, two
concepts C D, individual a, individual b appearing , following
equivalences hold:

C satisfiable w:r:t iff hT ; [ fC (b)gi satisfiable:
C subsumed w:r:t: iff hT ; [ f(C u :D)(b)gi satisfiable:
j= C (a) iff hT ; [ f(:C )(a)gi satisfiable:
slightly different form equivalences given (Hollunder, 1990).
equivalences given straightforward consequence ones given Hollunder.
However, equivalences valid languages including constructors refer
individuals concept language. equivalences reasoning services
languages studied (Schaerf, 1993b).
Based equivalences, next section concentrate KBsatisfiability.

3. Decidability Result

section provide calculus deciding KB-satisfiability. particular, Subsection 3.1 present calculus state correctness. Then, Subsection 3.2,
prove termination calculus. sucient assess decidability
problems 1{4, thanks relationships four problems.

3.1 calculus correctness

method makes use notion constraint system (Donini et al., 1991a; SchmidtSchau & Smolka, 1991; Donini, Lenzerini, Nardi, & Schaerf, 1991c), based
tableaux-like calculus (Fitting, 1990) tries build model logical formula
corresponding KB.
117

fiBuchheit, Donini, & Schaerf

introduce alphabet variable symbols V together well-founded total
ordering `' V . alphabet V disjoint ones defined far.
purpose ordering become clear later. elements V denoted
letters x; y; z; w. point on, use term object abstraction individual
variable (i.e., object element [ V ). Objects denoted symbols
s; and, Section 2, individuals denoted a; b.
constraint syntactic entity one forms:

s: C; sPt;

8x.x: C; =6 : t;

C concept P role name. Concepts assumed simple, i.e.,
complements contain form :A, concept name. Arbitrary
ALCNR-concepts rewritten equivalent simple concepts linear time (Donini
et al., 1991a). constraint system finite nonempty set constraints.
Given interpretation , define -assignment ff function maps every
variable V element , every individual aI (i.e., ff(a) = aI
2 O).
pair (I ; ff) satisfies: constraint s: C ff(s) 2 C , constraint sPt (ff(s); ff(t))
2 P , constraint =6 ff(s) 6= ff(t), finally, constraint 8x.x: C C =
(notice ff play role case). constraint system satisfiable
pair (I ; ff) satisfies every constraint .
ALCNR-knowledge base = hT ; Ai translated constraint system
replacing every inclusion C v 2 constraint 8x.x: :C D, every
membership assertion C (a) constraint a: C , every R(a; b) constraints
aP1 b; : : :; aPk b R = P1 u : : : u Pk , including constraint =
6 : b every pair (a; b)
individuals appearing A. easy see satisfiable
satisfiable.
order check constraint system satisfiability, technique adds constraints
either evident contradiction generated interpretation satisfying
obtained resulting system. Constraints added basis suitable set
so-called propagation rules.
providing rules, need additional definitions. Let constraint
system R = P1 u : : : u Pk (k 1) role. say R-successor
sP1 t; : : :; sPk . say direct successor role R,
R-successor s. call direct predecessor inverse relation direct successor.
clear context omit it. Moreover, denote successor transitive
closure relation direct successor, denote predecessor inverse.
assume variables introduced constraint system according ordering
`'. means, introduced constraint system x variables x
already .
denote [x=s] constraint system obtained replacing occurrence
variable x object s.
say separated constraint =
6 : .
Given constraint system object s, define function (; ) follows:
(S; s) := fC j s: C 2 g. Moreover, say two variables x -equivalent,
118

fiDecidable Reasoning Terminological KR Systems

written x , (S; x) = (S; ). Intuitively, two S-equivalent variables represent
element potential interpretation built rules, unless separated.
propagation rules are:
1. !u fs: C1; s: C2g [
1. s: C1 u C2 ,
2. s: C1 s: C2
2. !t fs: Dg [
1. s: C1 C2 ,
2. neither s: C1 s: C2 ,
3. = C1 = C2
3. !8 ft: C g [
1. s: 8R.C ,
2. R-successor s,
3. t: C
4. !9 fsP1 y; : : :; sPk y; : C g [
1. s: 9R.C ,
2. R = P1 u : : : u Pk ,
3. new variable,
4. R-successor t: C ,
5. variable variable w w w
5. ! fsP1 yi ; : : :; sPk yi j 2 1::ng [ fyi 6=: yj j i; j 2 1::n; 6= j g [
1. s: ( n R) ,
2. R = P1 u : : : u Pk ,
3. y1 ; : : :; yn new variables,
4. exist n pairwise separated R-successors ,
5. variable variable w w w
6. ! [y=t]
1. s: ( n R) ,
2. n R-successors ,
3. y; two R-successors separated
7. !8x fs: C g [
1. 8x.x: C ,
2. appears ,
3. s: C .
call rules !t ! nondeterministic rules, since applied
different ways constraint system (intuitively, correspond branching
rules tableaux). rules called deterministic rules. Moreover, call
rules !9 ! generating rules, since introduce new variables constraint
system. rules called nongenerating ones.
119

fiBuchheit, Donini, & Schaerf

use condition based -equivalence relation generating rules
(condition 5) related goal keeping constraint system finite even presence
potentially infinite chains applications generating rules. role become clearer
later paper.
One verify rules always applied system either presence
given constraint s: C (condition 1), or, case !8x-rule,
presence object . confusion arises, say rule applied
constraint s: C object (instead saying applied constraint
system ).
Proposition 3.1 (Invariance) Let 0 constraint systems. Then:
1. 0 obtained application deterministic rule, satisfiable
0 satisfiable.
2. 0 obtained application nondeterministic rule, satisfiable 0 satisfiable. Conversely, satisfiable nondeterministic rule
applicable object , applied way yields
satisfiable constraint system.
Proof. proof mainly rephrasing typical soundness proofs tableaux methods (e.g., Fitting, 1990, Lemma 6.3.2). non-standard constructors number
restrictions.
1. \(" Considering deterministic rules one directly check subset 0.
obvious satisfiable 0 satisfiable.
\)" order show 0 satisfiable case consider turn
possible deterministic rule application leading 0. assume (I ; ff)
satisfies .
!u -rule applied s: C1 u C2 , 0 = [ fs: C1; s: C2g. Since (I ; ff)
satisfies s: C1 u C2, (I ; ff) satisfies s: C1 s: C2 therefore 0.
!8-rule applied s: 8R.C , must R-successor
0 = [ft: C g. Since (I ; ff) satisfies , holds (ff(s); ff(t)) 2 RI . Since (I ; ff) satisfies
s: 8R.C , holds ff(t) 2 C . (I ; ff) satisfies t: C therefore 0.
!8x-rule applied presence 8x.x: C , 0 =
[ fs: C g. Since (I ; ff) satisfies holds C = . Therefore ff(s) 2 C
(I ; ff) satisfies 0 .
!9 -rule applied s: 9R.C , 0 = [ fsP1 y; : : :; sPk y; : C g. Since (I ; ff)
satisfies , exists (ff(s); d) 2 RI 2 C . define -assignment
ff0 ff0 (y) := ff0(t) := ff(t) 6= . easy show (I ; ff0) satisfies 0.
! -rule applied s: ( n R), 0 = [ fsP1 yi ; : : :; sPk yi j 2 1::ng [
fyi 6=: yj j i; j 2 1::n; 6= j g. Since (I ; ff) satisfies , exist n distinct elements
d1; : : :; dn 2 (ff(s); di) 2 RI . define -assignment ff0 ff0 (yi) := di
2 1::n ff0 (t) := ff(t) 62 fy1 ; : : :; yn g. easy show (I ; ff0) satisfies 0.
2. \(" Assume 0 satisfied (I ; ff0). show also satisfiable. 0
obtained application !t -rule, subset 0 therefore
satisfied (I ; ff0).
120

fiDecidable Reasoning Terminological KR Systems

0 obtained application ! -rule s: ( n R) ,
y; 0 = [y=t]. define -assignment ff ff(y ) := ff0 (t)
ff(v ) := ff0(v ) every object v v 6= y. Obviously (I ; ff) satisfies .
\)" suppose satisfied (I ; ff) nondeterministic rule applicable
object s.
!t -rule applicable s: C1 C2 then, since satisfiable, ff(s) 2 (C1 C2)I .
follows either ff(s) 2 C1I ff(s) 2 C2I (or both). Hence, !t -rule obviously
applied way (I ; ff) satisfies resulting constraint system 0.
! -rule applicable s: ( n R), then|since (I ; ff) satisfies |it holds
ff(s) 2 ( n R)I therefore set fd 2 j (ff(s); d) 2 RI g n elements.
hand, n R-successors R-successor
(ff(s); ff(t)) 2 RI . Thus, conclude Pigeonhole Principle (see e.g.,
Lewis & Papadimitriou, 1981, page 26) exist least :two R-successors t; t0
ff(t) = ff(t0 ). Since (I ; ff) satisfies , constraint 6= t0 . Therefore
one two must variable, let's say t0 = . obviously (I ; ff) satisfies [y=t].
Given constraint system , one rule might applicable it. define
following strategy application rules:
1. apply rule variable rule applicable individuals;
2. apply rule variable x rule applicable variable x;
3. apply generating rules nongenerating rule applicable.
strategy ensures variables processed one time according
ordering `'.
point on, assume rules always applied according strategy
always start constraint system coming ALCNR-knowledge
base . following lemma direct consequence assumptions.

Lemma 3.2 (Stability) Let constraint system x variable . Let

generating rule applicable x according strategy. Let 0 constraint system
derivable sequence (possibly empty) applications rules.
1. rule applicable 0 variable x
2. (S; x) = (S 0; x)
3. variable x variable 0, i.e., variable
substituted another variable constant.
1. contradiction: Suppose S0 ! S1 ! ! Sn 0, 2
ft; u; 9; 8; ; ; 8xg rule applicable variable x 0.
exists minimal i, n, case Si . Note 6= 0;
fact, strategy, rule applicable x rule applicable .
rule applicable variable z z x S0; : : :; Si,1. follows
Si,1 Si rule applied x variable w x w. exhaustive
Proof.

121

fiBuchheit, Donini, & Schaerf

analysis rules see that|whichever rule applied Si,1 Si |no new
constraint form : C yRz added Si,1 , therefore rule applicable
Si , contradicting assumption.
2. contradiction: Suppose (S; x) 6= (S 0; x). Call direct predecessor x,
rule must applied either x itself. Obviously x, therefore
former case cannot point 1. case analysis shows rules
applied x generating ones !8 ! rules.
rules add new constraints direct successors x x
therefore change (; x).
3. follows point 1. strategy.
Lemma 3.2 proves variable x direct successor, (; x) stable,
i.e., change subsequent applications rules. fact, variable
direct successor means generating rule applied it, therefore
(Lemma 3.2.2) point (; x) change.
constraint system complete propagation rule applies it. complete system
derived system also called completion . clash constraint system
one following forms:

fs: ?g
fs: A; s: :Ag, concept name.
fs: ( n R)g [ fsP1: ti ; : : :; sPk ti j 2 1::n + 1g
[ fti =6 tj j i; j 2 1::n + 1; =6 j g,
R = P1 u : : : u Pk .
clash evidently unsatisfiable constraint system. example, last case
represents situation object at-most restriction set Rsuccessors cannot identified (either individuals
created at-least restrictions).
constraint system containing clash obviously unsatisfiable. purpose
calculus generate completions, look presence clashes inside.
completion contains clash, prove always possible construct
model basis . looking technical details proof, let us
consider example application calculus checking satisfiability.

Example 3.3 Consider following knowledge base = hT ; Ai:
= fItalian v 9FRIEND.Italiang
= fFRIEND(peter; susan);
8FRIEND.:Italian(peter);
9FRIEND.Italian(susan)g
corresponding constraint system is:
= f8x.x: :Italian 9FRIEND.Italian;
peterFRIENDsusan

;

122

fiDecidable Reasoning Terminological KR Systems

8
9:

.:
.
g

;

peter: FRIEND Italian
susan: FRIEND Italian
peter = susan

6

sequence applications propagation rules follows:
S1 = [ fsusan: :Italiang (!8-rule)
S2 = S1 [ fpeter: :Italian 9FRIEND.Italiang (!8x-rule)
S3 = S2 [ fsusan: :Italian 9FRIEND.Italiang (!8x-rule)
S4 = S3 [ fpeter: :Italiang (!t -rule)
S5 = S4 [ fsusanFRIENDx; x: Italiang (!9 -rule)
S6 = S5 [ fx: :Italian 9FRIEND.Italiang (!8x-rule)
S7 = S6 [ fx: 9FRIEND.Italiang (!t-rule)
S8 = S7 [ fxFRIENDy; y: Italiang (!9-rule)
S9 = S8 [ fy: :Italian 9FRIEND.Italiang (!8x-rule)
S10 = S9 [ fy: 9FRIEND.Italiang (!t -rule)
One verify S10 complete clash-free constraint system. particular, !9 rule applicable . fact, since x S10 condition 5 satisfied. S10 one
build interpretation , follows (again, give interpretation concept
role names):
= fpeter; susan; x; yg
peterI = peter, susanI = susan, ff(x) = x, ff(y) = y,
ItalianI = fx; yg
FRIENDI = f(peter; susan); (susan; x); (x; y); (y; y)g
easy see indeed model .
order prove always possible obtain interpretation complete
clash-free constraint system need additional notions. Let constraint system
x, w variables . call w witness x three following conditions hold:
1. x w
2. w x
3. variable z z w z satisfies conditions 1. 2., i.e., w
least variable w.r.t. satisfying conditions 1. 2.
say x blocked (by w) x witness (w) . following lemma states
property witnesses.

Lemma 3.4 Let constraint system, x variable . x blocked
1. x direct successor
2. x exactly one witness.
123

fiBuchheit, Donini, & Schaerf

1. contradiction: Suppose x blocked xPy .
completion process leading generating rule must applied x system
0. follows definition rules 0 every variable w x
x6s w. Lemma 3.2 know, constraint system derivable
0 every w x also x6s w. Hence witness x ,
contradicting hypothesis x blocked.
2. follows directly condition 3. witness.
consequence Lemma 3.4, constraint system , w1 witness x w1
cannot witness itself, since relations `' -equivalence transitive.
uniqueness witness blocked variable important defining following
particular interpretation .
Let constraint system. define canonical interpretation canonical -assignment ffS follows:
Proof.

0

1.
2.
3.
4.

:= fs j object g
ffS (s) :=
2 AIS s:
(s; t) 2 P
(a) sPt
(b) blocked variable, w witness wPt .

call (s; t) P-role-pair (s; t) 2 P , call (s; t) role-pair
(s; t) P-role-pair role P . call role-pair explicit comes case
4.(a) definition canonical interpretation call implicit comes
case 4.(b).
Lemma 3.4 obvious role-pair cannot explicit implicit.
Moreover, variable implicit role-pair role-pairs implicit
come exactly one witness, stated following lemma.

Lemma 3.5 Let completion x variable . Let canonical interpretation . x implicit role-pair (x; ),
1. role-pairs x implicit
2. exactly one witness w x roles P P -rolepairs (x,y) x, constraint wPy .

first statement follows Lemma 3.4 (point 1 ). second statement follows
Lemma 3.4 (point 2 ) together definition .
machinery needed prove main theorem subsection.
Proof.

Theorem 3.6 Let complete constraint system. contains clash

satisfiable.

124

fiDecidable Reasoning Terminological KR Systems

Proof. Let ffS canonical interpretation canonical -assignment .
We: prove pair (IS ; ffS ) satisfies every constraint c . c form sPt
6= t, (IS ; ffS ) satisfies definition :and ffS . Considering ! -rule
! -rule see constraint form =
6 . c form
s: C , show induction structure C 2 C .
first consider base cases. C concept name, 2 C definition
. C = >, obviously 2 >IS . case C = ? cannot occur since
clash-free.
Next analyze turn possible complex concept C . C form :C1
C1 concept name since concepts simple. constraint s: C1
since clash-free. 62 C1IS , is, 2 n C1IS . Hence 2 (:C1)IS .
C form C1 u C2 (since complete) s: C1 s: C2 .
induction hypothesis, 2 C1IS 2 C2IS . Hence 2 (C1 u C2)IS .
C form C1 C2 (since complete) either s: C1 s: C2
. induction hypothesis, either 2 C1IS 2 C2IS . Hence 2 (C1 C2)IS .
C form 8R.D, show (s; t) 2 RIS holds
2 DIS . (s; t) 2 RIS , according Lemma 3.5 two cases occur. Either
R-successor blocked witness w R-successor w .
first case t: must also since complete. induction hypothesis
2 DIS . second case definition witness, w: 8R.D
completeness , t: must . induction hypothesis
2 DIS .
C form 9R.D show exists 2 (s; t) 2 RIS
2 DIS . Since complete, either R-successor
t: , variable blocked witness w . first case, induction
hypothesis definition , 2 DIS (s; t) 2 RIS . second case
w: 9R.D . Since w cannot blocked complete,
R-successor w t: . induction hypothesis
2 DIS definition (s; t) 2 RIS .
C form ( n R) show goal contradiction. Assume 62 (
n R)IS . exist atleast n + 1 distinct objects t1 ; : : :; tn+1 (s; ti ) 2 RIS ; 2
1::n + 1. means that, since R = P1 u : : : u Pk , pairs (s; ti) 2 PjIS ,
2 1::n + 1 j 2 1::k. according Lemma 3.5 one two following cases must
occur. Either sPj ti j 2 1::k; 2 1::n + 1 exists witness w
wPiti j 2 1::k 2 1::n + 1 . first case ! -rule
applicable completeness. :This means ti 's pairwise separated,
i.e., contains constraints ti 6= tj ; i; j 2 1::n + 1; 6= j . contradicts fact
clash-free. second case leads analogous contradiction.
C form ( n R) show goal contradiction. Assume 62 (
n R)IS . exist atmost < n (m possibly 0) distinct objects t1; : : :; tm
(s; ti ) 2 RIS ; 2 1::m. consider two cases. First case: blocked
. Since R-successors , ! -rule applicable s.
contradicts fact complete. Second case: blocked witness w .
Since R-successors w , ! -rule applicable w. leads
contradiction.

125

fiBuchheit, Donini, & Schaerf

c form 8x.x: then, since complete, object , t:
|and, previous cases, 2 DIS . Therefore, pair (IS ; ffS ) satisfies 8x.x: D.
Finally, since (IS ; ffS ) satisfies constraints , (IS ; ffS ) satisfies .

Theorem 3.7 (Correctness) constraint system satisfiable exists
least one clash-free completion .

\(" Follows immediately Theorem 3.6. \)" Clearly, system containing
clash unsatisfiable. every completion unsatisfiable, Proposition 3.1
, unsatisfiable.
Proof.

3.2 Termination complexity calculus

Given constraint system , call nS number concepts appearing , including
also concepts appearing substring another concept. Notice nS bounded
length string expressing .

Lemma 3.8 Let constraint system let 0 derived means

propagation rules. set variables 0 including 2nS variables
least two variables x,y x .
0

constraint x: C 2 0 may contain concepts constraint system .
Since nS concepts, given variable x cannot 2nS different
sets constraints x: C 0 .
Proof.

Lemma 3.9 Let constraint system let 0 constraint system derived

applying propagation rules given strategy. Then, 0
2nS non-blocked variables.

Suppose 2nS + 1 non-blocked variables. Lemma 3.8, know
0 least two variables y1 , y2 y1 y2 . Obviously either y1 y2
y2 y1 holds; suppose y1 y2 . definitions witness blocked either y1
witness y2 exists variable y3 y3 y1 y3 witness y2 .
cases y2 blocked, contradicting hypothesis.
Proof.

Theorem 3.10 (Termination space complexity) Let ALCNR-knowledge
base let n size. Every completion finite size O(24n ).

Let completion . Lemma 3.9 follows 2n
non-blocked variables . Therefore 2n total variables ,
maximum number direct successors variable .
Observe bounded number 9R.C concepts (at n) plus sum
numbers appearing number restrictions. Since numbers expressed binary,
sum bounded 2n . Hence, 2n + n. Since number individuals also
bounded n, total number objects (2n + n) (2n + n) (2n + n),
is, O(22n).
Proof.

126

fiDecidable Reasoning Terminological KR Systems

number different constraints form s: C , 8x.x: C object
involved bounded n, constraint size linear n. Hence, total size
constraints bounded n n 22n , O(23n).
number constraints form sPt, =
6 : bounded (22n)2 = 24n,
constraint constant size.
conclusion, size O(24n).
Notice one coarse upper bound, obtained theoretical purposes.
practical cases expect actual size much smaller that. example,
numbers involved number restrictions either expressed unary notation,
limited constant (the latter reasonable restriction practical systems)
argumentation analogous one would lead bound 23n .

Theorem 3.11 (Decidability) Given ALCNR-knowledge base , checking whether
satisfiable decidable problem.

follows Theorems 3.7 3.10 fact satisfiable
satisfiable.
refine theorem, giving tighter bounds time required
decide satisfiability.
Proof.

Theorem 3.12 (Time complexity) Given ALCNR-knowledge base , checking
whether satisfiable done nondeterministic exponential time.

order prove claim sucient show completion obtained
exponential number applications rules. Since number constraints
completion exponential (Theorem 3.10) rule, ! -rule, adds new
constraints constraint system, follows rules applied
exponential number times. Regarding ! -rule, applied object
many times number direct successors. Since number exponential
(if numbers coded binary) w.r.t. size knowledge base, claim follows.
lower bound complexity KB-satisfiability obtained exploiting previous
results language ALC , sublanguage ALCNR include
number restrictions role conjunction. know McAllester (1991), (independently) observation Nutt (1992) KB-satisfiability ALC -knowledge bases
EXPTIME-hard (see (Garey & Johnson, 1979, page 183) definition) hence
hard ALCNR-knowledge bases, too. Hence, expect find algorithm
solving problem polynomial space, unless PSPACE=EXPTIME. Therefore,
expect substantially improve space complexity calculus, already works
exponential space. discuss possible improvements time complexity.
proposed calculus works nondeterministic exponential time, hence improves
one proposed (Buchheit, Donini, & Schaerf, 1993, Sec.4), works deterministic double exponential time. key improvement showed KB
model model exponential size. However, may argued
is, calculus cannot yet turned practical procedure, since procedure would simply simulate nondeterminism second level exponentiality, resulting
Proof.

127

fiBuchheit, Donini, & Schaerf

double exponential time procedure. However, different combinations concepts
exponentially many (this cardinality powerset set concepts). Hence, double exponential time procedure wastes time re-analyzing
objects different names yet (; ), different constraint
systems. could avoided allow variable blocked witness
previously analyzed constraint system. technique would similar one
used (Pratt, 1978), tree-automata technique used (Vardi & Wolper, 1986),
improving simple tableaux methods variants propositional dynamic logics. Since
calculus considers one constraint system time, modification calculus
would necessary accomplish task formal way, outside scope
paper. formal development deterministic exponential time procedure
subject future research.
Notice that, since domain canonical interpretation always finite,
also implicitly proved ALCNR-knowledge bases finite model property,
i.e., satisfiable knowledge base finite model. property extensively
studied modal logics (Hughes & Cresswell, 1984) dynamic logics (Harel, 1984).
particular, technique, called filtration, developed prove finite model
property build finite model satisfiable formula. technique allows one
build finite model infinite one grouping worlds structure equivalence
classes, based set formulae satisfied world. interesting
observe calculus, based witnesses, considered variant filtration
technique equivalence classes determined basis -equivalence
relation. However, number restrictions, variables -equivalent cannot
grouped, since might separated (e.g., might introduced
application ! -rule). Nevertheless, direct successors,
stated point 4.(b) definition canonical interpretation page 124. would
correspond grouping variables infinite model way separations
preserved.

4. Relation previous work
section discuss relation paper previous work reasoning inclusions. particular, first consider previously proposed reasoning techniques deal
inclusions terminological cycles, discuss relation inclusions
terminological cycles.

4.1 Reasoning Techniques
mentioned introduction, previous results obtained Baader et al. (1990),
Baader (1990a, 1990b), Nebel (1990, 1991), Schild (1991) Dionne et al. (1992, 1993).
Nebel (1990, Chapter 5) considers language F , containing concept conjunction,
universal quantification number restrictions, TBoxes containing (possibly cyclic)
concept definitions, role definitions disjointness axioms (stating two concept names
disjoint). Nebel shows subsumption F -concepts w.r.t. TBox decidable.
However, argument uses non-constructive: shows sucient con128

fiDecidable Reasoning Terminological KR Systems

sider finite interpretations size bounded size TBox order decide
subsumption.
(Baader, 1990b) effect three types semantics|descriptive, greatest fixpoint least fixpoint semantics|for language FL0, containing concept conjunction
universal quantification, described help finite automata. Baader reduces
subsumption FL0 -concepts w.r.t. TBox containing (possibly cyclic) definitions
form =: C (which calls terminological axioms) decision problems finite automata.
particular, shows subsumption w.r.t. descriptive semantics decided polynomial space using Buchi automata. Using results (Baader, 1990b), (Nebel, 1991)
characterization subsumption problem w.r.t. descriptive semantics given
help deterministic automata (whereas Buchi automata nondeterministic).
also yields PSPACE-algorithm deciding subsumption.
(Baader et al., 1990) attention restricted language ALC . particular,
paper considers problem checking satisfiability single equation
form C = >, C ALC -concept. problem, called universal satisfiability problem, shown equivalent checking satisfiability ALC -TBox (see
Proposition 4.1).
(Baader, 1990a), extension ALC , called ALC reg , introduced, supports
constructor express transitive closure roles. means transitive closure
roles possible replace cyclic inclusions form v equivalent acyclic
ones. problem checking satisfiability ALC reg -concept solved
paper. also shown using transitive closure possible reduce satisfiability
ALC -concept w.r.t. ALC -TBox = fC1 v D1; : : :; Cn v Dn g concept
satisfiability problem ALC reg (w.r.t. empty TBox). Since problem concept
satisfiability w.r.t. TBox trivially harder checking satisfiability TBox,
paper extends result given (Baader et al., 1990).
technique exploited (Baader et al., 1990) (Baader, 1990a) based
notion concept tree. concept tree generated starting concept C order
check satisfiability (or universal satisfiability). way concept tree generated
concept C similar avor way complete constraint system generated
constraint system fx: C g. However, extension concept tree method
deal number restrictions individuals knowledge base neither obvious,
suggested cited papers; hand, extension calculus based
constraint systems immediate, provided additional features counterpart
First Order Logic.
(Schild, 1991) results general (Baader, 1990a) obtained
considering languages expressive ALC reg dealing concept satisfiability problem languages. results obtained establishing correspondence
concept languages Propositional Dynamic Logics (PDL), reducing
given problem satisfiability problem PDL. approach allows Schild find
several new results exploiting known results PDL framework. However, cannot
used deal every concept language. fact, correspondence cannot established
language includes concept constructors counterpart PDL (e.g.,
number restrictions, individuals ABox).
129

fiBuchheit, Donini, & Schaerf

Recently, algebraic approach cycles proposed (Dionne et al., 1992),
(possibly cyclic) definitions interpreted determining equivalence relation
terms describing concepts. existence uniqueness equivalence relation
derives Aczel's results non-well founded sets. (Dionne et al., 1993)
researchers prove subsumption based approach equivalent subsumption
greatest fixpoint semantics. language analyzed small fragment one used
TKRS k-rep, contains conjunction existential-universal quantifications combined
one construct (hence similar FL0 ). diculty extending results
lies fact clear individuals interpreted algebraic
setting. Moreover, believe constructive approaches like algebraic one, give
counterintuitive results applied non-constructive features concept languages|as
negation number restrictions.
conclusion, approaches, i.e., reduction automata problems, concept trees,
reduction PDL algebraic semantics, deal TBoxes don't seem
suitable deal also ABoxes. hand, constraint system technique, even
though conceived TBox-reasoning, easily extended ABox-reasoning,
also shown (Hollunder, 1990; Baader & Hollunder, 1991; Donini et al., 1993).

4.2 Inclusions versus Concept Definitions
compare expressive power TBoxes defined set inclusions (as done
paper) TBoxes defined set (possibly cyclic) concept introductions
form _ =: D.
Unlike (Baader, 1990a) (Schild, 1991), consider reasoning problems dealing
TBox ABox together. Moreover, use descriptive semantics concept introductions, inclusions. result obtained inclusion statements
concept introductions actually expressive power. detail, show
satisfiability knowledge base = hA; i, set inclusion statements,
reduced satisfiability knowledge base 0 = hA0; 0i 0 set
concept introductions. direction, concept introductions inclusions,
trivial since introductions form =: expressed pair inclusions
v v A, concept name specification _ rewritten
inclusion v (as already mentioned Section 2).
notation, given TBox = fC1 v D1 ; : : :; Cn v Dn g, define concept CT
CT = (:C1 D1) u u (:Cn Dn ). pointed (Baader, 1990a) ALC ,
interpretation satisfies TBox satisfies equation CT = >. result
easily extends ALCNR, stated following proposition.

Proposition 4.1 Given ALCNR-TBox = fC1 v D1; : : :; Cn v Dng, interpretation satisfies satisfies equation CT = >.
interpretation satisfies inclusion C v satisfies equation
:C = >; satisfies set equations :C1 D1 = >,: : : , :Cn Dn = >
satisfies (:C1 D1) u u (:Cn Dn ) = >. claim follows.
Proof.

130

fiDecidable Reasoning Terminological KR Systems

Given knowledge base = hA; concept appearing , define
knowledge base 0 = hA0 ; 0 follows:
A0 = [ fA(b) j b individual g
0 = fA _ CT u 8P1.A u u 8Pn .Ag
P1 ; P2; : : :; Pn role names appearing . Note 0 single
inclusion, could also thought one primitive concept specification.
Theorem 4.2 = hA; satisfiable 0 = hA0; 0i satisfiable.
0 following
Proof. order simplify machinery proof, use
(logically equivalent) form:
0 = fA v CT ; v 8P1.A; : : :; v 8Pn .Ag
(Note use symbol `v' instead `_ ' concept name appears
left-hand side many statements, must consider statements inclusions).
\)" Suppose = hA; satisfiable. Theorem 3.7, exists complete
constraint system without clash, defines canonical interpretation
model . Define constraint system 0 follows:
0 = [ fw: j w object g
call canonical interpretation associated 0. prove model
0 .
First observe every assertion satisfied since equal except
interpretation A, appear A. Therefore, every assertion A0
also satisfied , either assertion A, (if assertion
form A(b)) definition 0.
Regarding 0 , note definition 0, AIS = = ; therefore
sides inclusions form v 8Pi .A (i = 1; : : :; n) interpreted , hence
satisfied . Since appear CT , (CT )IS = (CT )IS .
Moreover, since satisfies , also have, Proposition 4.1, (CT )IS = ,
therefore (CT )IS = (CT )IS = = . follows also sides inclusion
v CT interpreted . conclusion, satisfies 0 .
\(" Suppose 0 = hA0 ; 0 satisfiable. Again, Theorem 3.7, exists
complete constraint system 0 without clash, defines canonical interpretation
model 0. show also model .
First all, assertions satisfied A0 , satisfies every
assertion A0 . prove satisfies , first prove following equation:
AIS =
(2)
Equation 2 proved showing that, every object 2 , AIS . order
that, observe general property constraint systems: Every variable 0 successor
individual. comes definition generating rules, add variables
constraint system direct successors existing objects, beginning
contains individuals.
Then, Equation 2 proved observing following three facts:
0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

131

0

fiBuchheit, Donini, & Schaerf

1. every individual b , b 2 AIS ;
0

0

2. object AIS , satisfies inclusions AIS (8P1.A)IS ; : : :;
AIS (8Pn .A)IS , every direct successor AIS ;
3. successor relation closed direct successor relation
0

0

0

0

0

0

0

Fundamental Theorem Induction (see e.g., Wand, 1980, page 41) conclude every object AIS . proves Equation 2 holds.
Equation 2, fact satisfies inclusion AIS (CT )IS , derive
(CT )IS = , satisfies equation CT = >. Hence, Proposition
4.1, satisfies , completes proof theorem.
machinery present proof new. fact, realizing inclusions
v 8P1 .A; : : :; v 8Pn .A simulate transitive closure roles P1 ; : : :; Pn , one
recognize similarities proofs given Schild (1991) Baader (1990a). difference proofs rely notion connected model (Baader uses equivalent
notion rooted model). contrast, models obtain connected,
individuals knowledge base not. exploit weaker property
every variable model successor individual.
Note reduction strongly relies fact disjunction `t' complement `:' within language. fact, disjunction complement necessary
order express inclusions TBox inside concept CT . Therefore,
proof holds ALC -knowledge bases, hold TKRSs allowing
constructors concepts (e.g., back).
Furthermore, language FL0 introduced Section 4.1, opposite result holds.
fact, McAllester (1991) proves computing subsumption w.r.t. set inclusions
EXPTIME-hard, even small language FL0 . Conversely, Nebel (1991) proves
subsumption w.r.t. set cyclic definitions FL0 done PSPACE. Combining
two results, conclude FL0 subsumption w.r.t. set inclusions
subsumption w.r.t. set definitions different complexity classes, hence (assuming
EXPTIME 6= PSPACE) inclusion statements strictly expressive concept
definitions FL0.
still open whether inclusions definitions equivalent languages whose
expressivity FL0 ALC .
0

0

0

0

0

0

0

0

0

5. Discussion

paper proved decidability main inference services TKRS based
concept language ALCNR. believe result theoretical
importance, bears impact existing TKRSs, complete procedure
easily devised calculus provided Section 3. procedure, one build
ecient (but still complete) ones, described end Section 3.2, also
applying standard optimization techniques described (Baader, Hollunder,
Nebel, Profitlich, & Franconi, 1992). optimized procedure perform well small
sublanguages reasoning tractable, still complete solving
complex tasks. However, complete procedure still take exponential time
132

fiDecidable Reasoning Terminological KR Systems

space worst case, may argued could practical applicability.
comment following point.
Firstly, complete procedure (possibly optimized) offers benchmark comparing
incomplete procedures, terms performance, also terms missed inferences. Let us illustrate point detail, providing blatant paradox: consider
mostly incomplete constant-time procedure, answering always \No" check. Obviously useless procedure outperforms one, missed inferences taken
account. paradox shows incomplete procedures meaningfully compared missed inferences considered. recognize missed inferences large
examples, one needs exactly complete procedure|even ecient one|like ours.
believe fair detection missed inferences would great help even
satisfaction end users primary criterion judging incomplete procedures.
Secondly, complete procedure used \anytime classification", proposed
(MacGregor, 1992). idea use fast, incomplete algorithm first step
analyzing input knowledge, reasoning background.
cited paper, resolution-based theorem provers proposed performing background
reasoning. argue specialized complete procedure perform better
general theorem prover. instance, theorem provers usually specifically designed
deal filtration techniques.
Moreover, calculus easily adapted deal rules. outlined
introduction, rules often used practical TKRSs. Rules behave like one-way concept
inclusions|no contrapositive allowed|and applied known individuals.
result shows rules ALCNR applied also unknown individuals (our
variables constraint system) without endangering decidability. result
compared negative result (Baader & Hollunder, 1992), shown
subsumption becomes undecidable rules applied unknown individuals classic.
Finally, calculus provides new way building incomplete procedures, modifying
propagation rules. Since rules build model, modifications
semantical counterpart gives precise account incomplete procedures
obtained. example, one could limit size canonical model polynomial
size KB. Semantically, would mean consider \small" models,
reasonable intended models KB much bigger size
KB itself. believe way designing incomplete procedures \from above", i.e.,
starting complete set inferences weakening it, dual way incomplete
procedures realized far \from below", i.e., starting already incomplete
inferences adding inference power need.
research still needed address problems issuing practical systems.
example, completely express role restrictions inside number restrictions, qualified number
restrictions (Hollunder & Baader, 1991) taken account. Also, language
resulting addition enumerated sets (called one-of classic), role fillers
ALCNR still studied, although seem endanger filtration
method used. Instead, different method might necessary inverse roles added
ALCNR, since finite model property lost (as shown Schild, 1991). Finally,
addition concrete domains (Baader & Hanschke, 1991) remains open.
133

fiBuchheit, Donini, & Schaerf

Acknowledgements
thank Maurizio Lenzerini inspiration work, well several discussions contributed paper. Werner Nutt pointed us observation mentioned end Section 3, thank Franz Baader helpful comments
earlier drafts. thank also anonymous reviewers, whose stimulating comments
helped us improving submitted version.
research partly done first author visiting Dipartimento di Informatica e Sistemistica, Universita di Roma \La Sapienza". third author also acknowledges Yoav Shoham hospitality Computer Science Department Stanford
University, author developing part research.
work supported ESPRIT Basic Research Action N.6810 (COMPULOG 2) Progetto Finalizzato Sistemi Informatici e Calcolo Parallelo
CNR (Italian Research Council), LdR \Ibridi".

References

Abrial, J. (1974). Data semantics. Klimbie, J., & Koffeman, K. (Eds.), Data Base
Management, pp. 1{59. North-Holland Publ. Co., Amsterdam.
Baader, F. (1990a). Augmenting concept languages transitive closure roles: alternative terminological cycles. Tech. rep. RR-90-13, Deutsches Forschungszentrum
fur Kunstliche Intelligenz (DFKI), Kaiserslautern, Germany. abridged version appeared Proc. 12th Int. Joint Conf. Artificial Intelligence IJCAI-91, pp.
446{451.
Baader, F. (1990b). Terminological cycles KL-ONE-based knowledge representation languages. Tech. rep. RR-90-01, Deutsches Forschungszentrum fur Kunstliche Intelligenz
(DFKI), Kaiserslautern, Germany. abridged version appeared Proc. 8th
Nat. Conf. Artificial Intelligence AAAI-90, pp. 621{626.
Baader, F., Burkert, H.-J., Hollunder, B., Nutt, W., & Siekmann, J. H. (1990). Concept
logics. Lloyd, J. W. (Ed.), Computational Logics, Symposium Proceedings, pp.
177{201. Springer-Verlag.
Baader, F., & Hanschke, P. (1991). schema integrating concrete domains concept
languages. Proc. 12th Int. Joint Conf. Artificial Intelligence IJCAI-91,
pp. 452{457 Sydney.
Baader, F., & Hollunder, B. (1991). terminological knowledge representation system
complete inference algorithm. Proc. Workshop Processing Declarative
Knowledge, PDK-91, Lecture Notes Artificial Intelligence, pp. 67{86. SpringerVerlag.
Baader, F., & Hollunder, B. (1992). Embedding defaults terminological knowledge
representation formalisms. Proc. 3rd Int. Conf. Principles Knowledge
Representation Reasoning KR-92, pp. 306{317. Morgan Kaufmann, Los Altos.
134

fiDecidable Reasoning Terminological KR Systems

Baader, F., Hollunder, B., Nebel, B., Profitlich, H.-J., & Franconi, E. (1992). empirical
analisys optimization techniques terminological representation systems. Proc.
3rd Int. Conf. Principles Knowledge Representation Reasoning KR92, pp. 270{281. Morgan Kaufmann, Los Altos.
Beck, H. W., Gala, S. K., & Navathe, S. B. (1989). Classification query processing
technique CANDIDE semantic data model. Proc. 5th IEEE Int. Conf.
Data Engineering.
Borgida, A., Brachman, R. J., McGuinness, D. L., & Alperin Resnick, L. (1989). CLASSIC:
structural data model objects. Proc. ACM SIGMOD Int. Conf.
Management Data, pp. 59{67.
Brachman, R. J., & Levesque, H. J. (1984). tractability subsumption framebased description languages. Proc. 4th Nat. Conf. Artificial Intelligence
AAAI-84, pp. 34{37.
Brachman, R. J., Pigman Gilbert, V., & Levesque, H. J. (1985). essential hybrid
reasoning system: Knowledge symbol level accounts KRYPTON. Proc.
9th Int. Joint Conf. Artificial Intelligence IJCAI-85, pp. 532{539 Los Angeles.
Brachman, R. J., & Schmolze, J. G. (1985). overview KL-ONE knowledge representation system. Cognitive Science, 9 (2), 171{216.
Buchheit, M., Donini, F. M., & Schaerf, A. (1993). Decidable reasoning terminological
knowledge representation systems. Tech. rep. RR-93-10, Deutsches Forschungszentrum fur Kunstliche Intelligenz (DFKI), Saarbrucken, Germany. abridged version
appeared Proc. 13th Int. Joint Conf. Artificial Intelligence IJCAI-93 pp.
704{709.
Catarci, T., & Lenzerini, M. (1993). Representing using interschema knowledge
cooperative information systems. Journal Intelligent Cooperative Inf. Syst.
appear.
Dionne, R., Mays, E., & Oles, F. J. (1992). non-well-founded approach terminological
cycles. Proc. 10th Nat. Conf. Artificial Intelligence AAAI-92, pp. 761{766.
AAAI Press/The MIT Press.
Dionne, R., Mays, E., & Oles, F. J. (1993). equivalence model theoretic structural
subsumption description logics. Proc. 13th Int. Joint Conf. Artificial
Intelligence IJCAI-93, pp. 710{716 Chambery, France. Morgan Kaufmann, Los Altos.
Donini, F. M., Hollunder, B., Lenzerini, M., Marchetti Spaccamela, A., Nardi, D., & Nutt,
W. (1992). complexity existential quantification concept languages. Artificial
Intelligence, 2{3, 309{327.
Donini, F. M., Lenzerini, M., Nardi, D., & Nutt, W. (1991a). complexity concept
languages. Allen, J., Fikes, R., & Sandewall, E. (Eds.), Proc. 2nd Int.
Conf. Principles Knowledge Representation Reasoning KR-91, pp. 151{162.
Morgan Kaufmann, Los Altos.
135

fiBuchheit, Donini, & Schaerf

Donini, F. M., Lenzerini, M., Nardi, D., & Nutt, W. (1991b). Tractable concept languages.
Proc. 12th Int. Joint Conf. Artificial Intelligence IJCAI-91, pp. 458{463
Sydney.
Donini, F. M., Lenzerini, M., Nardi, D., & Schaerf, A. (1991c). hybrid system integrating
datalog concept languages. Proc. 2nd Conf. Italian Association
Artificial Intelligence, No. 549 Lecture Notes Artificial Intelligence. SpringerVerlag. extended version appeared also Working Notes AAAI Fall
Symposium \Principles Hybrid Reasoning".
Donini, F. M., Lenzerini, M., Nardi, D., & Schaerf, A. (1993). Deduction concept languages: subsumption instance checking. Journal Logic Computation.
appear.
Fitting, M. (1990). First-Order Logic Automated Theorem Proving. Springer-Verlag.
Garey, M., & Johnson, D. (1979). Computers Intractability|A guide NPcompleteness. W.H. Freeman Company, San Francisco.
Harel, D. (1984). Dynamic logic. Handbook Philosophical Logic, Vol. 2, pp. 497{640.
D. Reidel, Dordrecht, Holland.
Heinsohn, J., Kudenko, D., Nebel, B., & Profitlich, H.-J. (1992). empirical analysis
terminological representation systems. Proc. 10th Nat. Conf. Artificial
Intelligence AAAI-92, pp. 767{773. AAAI Press/The MIT Press.
Hollunder, B. (1990). Hybrid inferences KL-ONE-based knowledge representation systems. Proc. German Workshop Artificial Intelligence, pp. 38{47. SpringerVerlag.
Hollunder, B., & Baader, F. (1991). Qualifying number restrictions concept languages.
Tech. rep. RR-91-03, Deutsches Forschungszentrum fur Kunstliche Intelligenz (DFKI),
Kaiserslautern, Germany. abridged version appeared Proc. 2nd Int. Conf.
Principles Knowledge Representation Reasoning KR-91.
Hughes, G. E., & Cresswell, M. J. (1984). Companion Modal Logic. Methuen, London.
Kaczmarek, T. S., Bates, R., & Robins, G. (1986). Recent developments NIKL. Proc.
5th Nat. Conf. Artificial Intelligence AAAI-86, pp. 978{985.
Lenzerini, M., & Schaerf, A. (1991). Concept languages query languages. Proc.
9th Nat. Conf. Artificial Intelligence AAAI-91, pp. 471{476.
Levesque, H. J. (1984). Foundations functional approach knowledge representation.
Artificial Intelligence, 23, 155{212.
Lewis, H. R., & Papadimitriou, C. H. (1981). Elements Theory Computation.
Prentice-Hall, Englewood Cliffs, New Jersey.
MacGregor, R. (1991). Inside LOOM description classifier. SIGART Bulletin, 2 (3),
88{92.
136

fiDecidable Reasoning Terminological KR Systems

MacGregor, R. (1992). What's needed make description logic good KR citizen.
Working Notes AAAI Fall Symposium Issues Description Logics: Users
meet Developers, pp. 53{55.
MacGregor, R., & Bates, R. (1987). Loom knowledge representation language. Tech.
rep. ISI/RS-87-188, University Southern California, Information Science Institute,
Marina del Rey, Cal.
MacGregor, R., & Brill, D. (1992). Recognition algorithms LOOM classifier.
Proc. 10th Nat. Conf. Artificial Intelligence AAAI-92, pp. 774{779. AAAI
Press/The MIT Press.
Mays, E., Dionne, R., & Weida, R. (1991). K-REP system overview. SIGART Bulletin,
2 (3).
McAllester, D. (1991). Unpublished manuscript.
McGuinness, D. L. (1992). Making description logic based knowledge representation systems
usable. Working Notes AAAI Fall Sysmposium Issues Description
Logics: Users meet Developers, pp. 56{58.
Mylopoulos, J., Bernstein, P., & Wong, E. (1980). language facility designing databaseintensive applications. ACM Trans. Database Syst., 5 (2), 185{207.
Nebel, B. (1988). Computational complexity terminological reasoning BACK. Artificial
Intelligence, 34 (3), 371{383.
Nebel, B. (1990). Reasoning Revision Hybrid Representation Systems. Lecture Notes
Artificial Intelligence. Springer-Verlag.
Nebel, B. (1991). Terminological cycles: Semantics computational properties. Sowa,
J. F. (Ed.), Principles Semantic Networks, pp. 331{361. Morgan Kaufmann, Los
Altos.
Nutt, W. (1992). Personal communication.
Patel-Schneider, P. F. (1984). Small beautiful knowledge representation. Proc.
IEEE Workshop Knowledge-Based Systems. extended version appeared
Fairchild Tech. Rep. 660 FLAIR Tech. Rep. 37, October 1984.
Patel-Schneider, P. (1989). Undecidability subsumption NIKL. Artificial Intelligence,
39, 263{272.
Pratt, V. R. (1978). practical decision method propositional dynamic logic. Proc.
10th ACM SIGACT Symp. Theory Computing STOC-78, pp. 326{337.
Quantz, J., & Kindermann, C. (1990). Implementation BACK system version 4. Tech.
rep. KIT-Report 78, FB Informatik, Technische Universitat Berlin, Berlin, Germany.
Rich, editor, C. (1991). SIGART bulletin. Special issue implemented knowledge representation reasoning systems. (2)3.
137

fiBuchheit, Donini, & Schaerf

Schaerf, A. (1993a). complexity instance checking problem concept languages existential quantification. Journal Intelligent Information Systems, 2,
265{278. abridged version appeared Proc. 7th Int. Symp. Methodologies Intelligent Systems ISMIS-93.
Schaerf, A. (1993b). Reasoning individuals concept languages. Tech. rep. 07.93,
Dipartimento di Informatica e Sistemistica, Universita di Roma \La Sapienza".
abridged version appeared Proc. 3rd Conf. Italian Association
Artificial Intelligence AI*IA-93.
Schild, K. (1988). Undecidability subsumption U . Tech. rep. KIT-Report 67, FB
Informatik, Technische Universitat Berlin, Berlin, Germany.
Schild, K. (1991). correspondence theory terminological logics: Preliminary report.
Proc. 12th Int. Joint Conf. Artificial Intelligence IJCAI-91, pp. 466{471
Sydney.
Schmidt-Schau, M. (1989). Subsumption KL-ONE undecidable. Brachman, R. J.,
Levesque, H. J., & Reiter, R. (Eds.), Proc. 1st Int. Conf. Principles
Knowledge Representation Reasoning KR-89, pp. 421{431. Morgan Kaufmann,
Los Altos.
Schmidt-Schau, M., & Smolka, G. (1991). Attributive concept descriptions complements. Artificial Intelligence, 48 (1), 1{26.
Vardi, M., & Wolper, P. (1986). Automata-theoretic techniques modal logics programs. Journal Computer System Science, 32, 183{221. preliminary version
appeared Proc. 16th ACM SIGACT Symp. Theory Computing STOC84.
Vilain, M. (1991). Deduction parsing: Tractable classification KL-ONE framework.
Proc. 9th Nat. Conf. Artificial Intelligence AAAI-91, pp. 464{470.
Wand, M. (1980). Induction, Recursion, Programming. North-Holland Publ. Co.,
Amsterdam.
Woods, W. A., & Schmolze, J. G. (1992). KL-ONE family. Lehmann, F. (Ed.),
Semantic Networks Artificial Intelligence, pp. 133{178. Pergamon Press. Published
special issue Computers & Mathematics Applications, Volume 23, Number
2{9.

138

fiJournal Artificial Intelligence Research 1 (1994) 277{308

Submitted 3/94; published 6/94

Semantics Complete Algorithm
Subsumption CLASSIC Description Logic
Alex Borgida

borgida@cs.rutgers.edu

Department Computer Science
Rutgers University
New Brunswick, NJ 08904 U. S. A.

Peter F. Patel-Schneider

pfps@research.att.com

AT&T Bell Laboratories
600 Mountain Avenue
Murray Hill, NJ 07974 U. S. A.

Abstract

paper analyzes correctness subsumption algorithm used classic,
description logic-based knowledge representation system used practical
applications. order deal eciently individuals classic descriptions, developers use algorithm incomplete respect standard,
model-theoretic semantics description logics. provide variant semantics descriptions respect current implementation complete,
independently motivated. soundness completeness polynomial-time subsumption algorithm established using description graphs, abstracted version
implementation structures used classic, independent interest.

1. Introduction Description Logics

Data knowledge bases models part natural world. models
often built individual objects inter-related relationships grouped
classes capture commonalities among instances. Description logics (DLs),
also known terminological logics, form class languages used build access
models; distinguishing feature classes (usually called concepts) defined
intensionally|in terms descriptions specify properties objects must satisfy
belong concept. descriptions expressed using language allows
construction composite descriptions, including restrictions binary relationships
(usually called roles) connecting objects.
example, consider description
GAME u 4 participants u 8participants:(PERSON u gender : Female):1
description characterizes objects intersection (u) three sub-descriptions:
GAME|objects belong atomic concept; 4 participants|objects least
four fillers participants role; 8participants:(PERSON u gender : Female)|objects
whose participants fillers restricted belong PERSONs,
gender role filled value Female.
1. notation used descriptions standard notation description logic community
(Baader et al., 1991). classic notation used verbose.

c 1994 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.

fiBorgida & Patel-Schneider

key difference DLs standard representation formalisms based
First-Order Logic, e.g., relational deductive databases, DLs provide arena
exploring new sets \logical connectives"|the constructors used form composite
descriptions|that different standard connectives conjunction, universal
quantifiers, etc.. Therefore, DLs provide new space search expressive
yet effectively computable representation languages. Moreover, although possible
translate many aspects DLs currently encountered First Order Logic, reasoning
translation would poor substitute DL-based systems reason
way resemble standard theorem proving (e.g., making use imperative
programming features).
Descriptions one used several ways knowledge base
management system (KBMS) based description logic:
1. state queries: KBMS locate objects satisfy description's
properties.
2. define classify concepts: Identifiers attached descriptions, manner views relational DBMSs. system addition automatically determine
\subclass" relationship pairs concepts based definitions.
example, concept defined description would subsumed
concept defined \games least two participants" (GAME u 2 participants).
3. provide partial information objects: important understand distinct DL descriptions ascribed arbitrary individuals (e.g., \today's game
cards|individual Bgm#467|will exactly two participants following
set three : : : , like tea rum"). Note unlike database systems, DL-based KBMSs require descriptions predefined. provides
considerable power recording partial knowledge objects.
4. detect errors: possible determine whether two descriptions disjoint,
whether description incoherent not, whether ascribing description
individual leads inconsistency.
Quite number KBMSs based description logics built, including classic
(Resnick et al., 1992), loom (MacGregor & Bates, 1987), back (Peltason et al., 1987).
systems used several practical situations, including software information
bases (Devanbu et al., 1991), financial management (Mays et al., 1987), configuration management (Owsnicki-Klewe, 1988; Wright et al., 1993), data exploration. Additional
signs DLs significant subjects study several recent workshops DLs
(Nebel et al., 1991; Peltason et al., 1991; AAAI, 1992).

1.1 Tractability Completeness DL Implementations

fundamental operation descriptions determining whether one description
general, subsumes, another, sense object satisfying latter would also
satisfy conditions former. parallel surge work finding tractable
yet expressive subsets first order logic, DL research community investigating
complexity reasoning various constructors. first result area (Levesque
278

fiSubsumption CLASSIC

& Brachman, 1987) showed even seemingly simple addition small language
lead subsumption determination becoming NP-hard. recent, striking pair
results (Patel-Schneider, 1989b; Schmidt-Schauss, 1989) shows adding ability
represent equalities role compositions makes complexity subsumption problem
leap quadratic undecidable.
three possible responses intractability results:
Provide incomplete implementation DL reasoner, sense
inferences sanctioned standard semantics constructors
performed algorithm. approach, explicitly adopted loom system
implementers (MacGregor & Bates, 1987), advocated users (Doyle &
Patil, 1991), one major diculty: one describe users inferences
actually drawn implementation systems known properties
implemented top KBMS? Two solutions problem suggested: alternative semantic accounts (based weaker, 4-valued logics, example)
(Patel-Schneider, 1989a), proof-theoretic semantics (Borgida, 1992).
Provide complete implementation specific DL reasoner, acknowledging
certain circumstances may take inordinate amount time. approach,
followed systems kris (Baader & Hollunder, 1991), problem
unpredictability: system \go wild blue yonder"?
course, circumstances impossible even attempt since reasoning
problem undecidable.
Carefully devise language limited expressive power reasoning tractable,
provide complete implementation it. approach chosen
designers languages kandor (Patel-Schneider, 1984) krypton
(Brachman et al., 1983), close approach classic (Borgida et al.,
1989).
hidden diculty second third approach produce implementation
correct (\complete") respect semantics. diculty illustrated
discovery, several years later, implementation kandor, well candide
(Beck et al., 1989), fact incomplete, subsumption problem NP-hard (Nebel,
1988), rather polynomial, claimed; happened despite fact Kandor
\small" language comparison DLs, implementation appeared
evidently correct. avoid problems, necessary produce convincing
demonstrations algorithm correct; several proofs fact already appeared DL literature (e.g., (Patel-Schneider, 1987; Hollunder & Nutt, 1990; Donini
et al., 1991)), albeit languages seen use practical applications.

1.2 Outline

classic 12 system reasoner based moderately complicated DL.
used commercial (Wright et al., 1993) prototype applications AT&T, made
available academic researchers AT&T Bell Laboratories.
2. classic 1 first released version classic. new version, classic 2, expressive DL,
recently released.

279

fiBorgida & Patel-Schneider

One purpose paper provide rigorous formal analysis correctness
eciency classic DL subsumption algorithm.3 start presenting
result subset language, call Basic classic. subsumption
algorithm relies transformation descriptions data structure, call
description graphs, generalization A-Kaci's psi-terms (1984).
process normalizing graph canonical form, remove obvious redundancies
explicate certain implicit facts, encoding particular infinite set inferences
drawn so-called \coreference constraints". correctness subsumption
algorithm demonstrated rigorously showing construct (inductively) countermodel case algorithm returns answer \no".
Next, explore effect adding individuals descriptions. show that, using
individuals, one encode disjunctive information leading need examine combinatorially many possibilities. classic implementation fact incomplete respect
standard semantics. second contribution paper well-motivated,
understandable, small change standard semantics alleviates problem.
extend subsumption algorithm proof correctness deal individuals
modified semantics, thereby characterizing sense \incompleteness"
reasoner.
paper therefore illustrates three paradigms described above, albeit nonstandard manner second paradigm, first time realistic
language significant practical use.

2. Basic CLASSIC
Descriptions Basic classic built collection atomic concept names, role
names, attribute names. Roles attributes always atomic descriptions
built using operators/constructors value restrictions number restrictions,
indicate below.
Basic classic incorporates objects host programming language,4 called host
individuals, form distinct group classic individuals; latter
roles attributes own, former restricted role attribute fillers.
denotational semantics classic descriptions starts, usual, domain
values, , subsets extensions descriptions, subsets
extensions roles attributes. domain fact disjointly divided two realms,
host realm, H , containing objects corresponding host language individuals,
classic realm C , containing objects. Every description, except THING,
denotes entire domain extension subset either classic realm
host realm. (NOTHING denotes empty set, therefore classic host
concept.) extension role possible world relation classic realm
entire domain, extension attribute function classic realm
entire domain.
3. empirical tests (Heinsohn et al., 1992), classic emerged fastest current DL
implementations.
4. general scheme incorporating host objects described (Baader & Hanschke, 1991).

280

fiSubsumption CLASSIC

Host descriptions relatively simple: (i) HOST-THING, denoting entire host realm,
H ; (ii) special, pre-defined names corresponding types host programming language; (iii) conjunctions descriptions. descriptions corresponding
host programming language types pre-defined extensions subsumption relationships, mirroring subtype relationship host programming language.
subtype relationship satisfied possible worlds/interpretations. require (i)
host concepts extension either infinite size empty; (ii)
extensions two host concepts overlap, one must subsumed other, i.e.,
types disjoint, unless subtypes other; (iii) host concept
infinite number extra instances child concepts. (These conditions
needed avoid able infer conclusions size host descriptions.)
allows host concepts like INTEGER, REAL, COMPLEX, STRING, BOOLEAN
NON-ZERO-INTEGER .
Non-host (classic) descriptions Basic classic formed according following
syntax:
Syntax
Constructor Name
CLASSIC-THING
E
Atomic Concept Name
CuD
Intersection
8R:C
Role Value Restriction
8A:C
Attribute Value Restriction
n R
Minimum Number Restriction
R
Maximum Number Restriction
A1 : : : Ak = B1 : : : Bh Equality Restriction
E atomic concept name; C classic descriptions; R role; A, Ai ,
Bj attributes; n,k,h positive integers; non-negative integer. set
constructors Basic classic judiciously chosen result language
subsumption easy compute.
denotational semantics descriptions Basic classic recursively built
extensions assigned atomic names possible world:
Definition 1 possible world/interpretation, , consists domain, , interpretation function :I . domain disjointly divided classic realm, C , host
realm, H . interpretation function assigns extensions atomic identifiers follows:
extension atomic concept name E subset EI classic realm.
extension atomic role name R subset RI C .
extension atomic attribute name total function AI C
.
extension CI non-atomic classic description computed follows:
CLASSIC-THINGI = C .
(C u D)I = CI \ DI .
281

fiBorgida & Patel-Schneider

(8p:C)I = fd 2 C j 8x (d; x) 2 pI ) x 2 CI g, i.e., objects C
whose p-role p-attribute fillers extension C;

(n p)I (resp. (n p)I ) objects C least (resp. most) n fillers
role p.

(A1 : : : Ak = B1 : : : Bh )I = fd 2 C j Ak (: : : A1I (d)) = BhI (: : : B1I (d))g, i.e.,

objects C property applying composition extension
Ai composition extension Bj object result
value.5

description, D1, said subsume another, D2 , possible worlds , D2I
D1 .

key interest computation subsumption relationship descriptions
Basic classic. Subsumption computation multi-part process. First, descriptions
turned description graphs. Next, description graphs put canonical form,
certain inferences explicated redundancies reduced combining
nodes edges graph. Finally, subsumption determined description
canonical description graph.
describe detail process, start formal definition notion
description graph (Definition 2), present techniques

translating description description graph (Section 2.2), requires merging
pairs nodes, pairs graphs (Definitions 4 5);

putting description graph canonical form (Section 2.3);
determining whether description subsumes description graph (Algorithm 1).
prove correctness approach, need show first two steps
lead us right direction, i.e., following three questions equivalent: \Does
description subsume description C?", \Does description subsume graph GC ?",
\Does description subsume graph canonical(GC )?". this, need define
formal semantics descriptions graphs (Definitions 1 3), prove
results (Theorems 1 2). prove \completeness" subsumption algorithm,
show algorithm indicate subsumes canonical(GC ),
construct interpretation (\graphical world") object denotation
canonical(GC ) D.

2.1 Description Graphs

One way developing subsumption algorithm first transform descriptions
canonical form, determine subsumption relationships them. Canonical
descriptions normally thought trees since descriptions terms first order
term language. presence equality restrictions classic significantly changes
5. Note attribute chains must definite value, last cannot evaluate
host individuals, since cannot attributes.

282

fiSubsumption CLASSIC

fCLASSIC-THING
g


fTHING
g
:




,


,


captain,
coach



,


participants - fPERSONg


,

fGAMEg

father

[0; 1]

Figure 1: description graph.
handling subsumption introduce relationships different pieces
normal form. significantly, presence equalities, small description,
8friend:TALL u friend = friendfriend, subsumed descriptions arbitrary size,

8friend:(8friend:(: : : (8friend:TALL) : : :)):
order record sets inferences canonical form, resort graphbased representation, suggested semantic-network origins description logics,
work A-Kaci (1984).
Intuitively, description graph labelled, directed multigraph, distinguished
node. Nodes graph correspond descriptions, edges graph correspond
restrictions roles attributes. edges graph labelled role name
minimum maximum number fillers associated edge,
attribute name. nodes graph labelled concept names associated
node concept. example, Figure 1 description graph, which, shall see later,
corresponds description GAME u 8participants: PERSON u coach = (captainfather).
equality restrictions (and hence non-tree portions graph) involve
attributes, edges labelled roles cut-edges, i.e., removal increases one
number connected components graph. restriction important
graph tree form, really difference graphical linear notation,
semantics simple develop. graph general directed acyclic graph,
problem relating semantics generated two different paths
graph share beginning ending nodes. graph contains cycles,
problem developing correct semantics even dicult, simplistic semantics
non-well-founded, sort fixed-point model-preference semantics
required. Fortunately, non-tree parts graphical notation involve attributes
only, attributes functional, job much easier.
result restrictions, possible view description graph
following recursive structure: (i) distinguished node r, \island"
nodes connected edges labelled attributes. (ii) Nodes island may
0 edges labelled roles leaving them, pointing distinguished nodes
description graphs. (iii) graphs share nodes edges common
other, islands them.
283

fiBorgida & Patel-Schneider

recursive structure, easier represent description graphs using
recursive definition, instead usual graph definition. recursive definition similar
recursive definition tree, states tree consists information
(the information root tree) plus set trees (the children root
tree). description graphs complex simple trees, use
two-part definition.

Definition 2 description graph triple, hN; E; ri, consisting set N nodes;

bag E edges (a-edges) labelled attribute names; distinguished node r N .
Elements E written hn1 ; n2; Ai n1 n2 nodes attribute
name.
node description graph pair, hC; H consisting set C concept names
(the atoms node), bag H tuples (the r-edges node). r-edge
tuple, hR; m; M; Gi, role name, R; min, m, non-negative integer; max,
, non-negative integer 1; (recursively nested) description graph G,
representing restriction fillers role. (G often called restriction
graph node.)
Concept names description graph atomic concept names, host concept names,
THING, CLASSIC-THING, HOST-THING.

Descriptions graphs provided extensions starting possible worlds
used descriptions. However, addition need way identifying individuals
related attributes, given function .

Definition 3 Let G = hN; E; ri description graph let possible world.

interpretation GI G, interpretation nI nodes N , recursively (and mutually) defined follows:
element, d, GI , iff function, , N
1. = (r);
2. n 2 N (n) 2 nI ;
3. hn1 ; n2; Ai 2 E h(n1 ); (n2)i 2 AI , (which equivalent (n2 ) =
AI ((n1)), since AI function).
element, d, nI , n = hC; H i, iff
1. C 2 C , 2 CI ;
2. hR; m; M; Gi 2 H ,
(a) elements, d0, domain hd; d0i 2 RI

(b) d0 2 GI d0 hd; d0i 2 RI .
284

fiSubsumption CLASSIC

2.2 Translating Descriptions Description Graphs

Basic classic description turned description graph recursive process,
working \inside out". process, description graphs nodes often
merged.

Definition 4 merge two nodes, n1 n2, new node whose atoms union

atoms two nodes whose r-edges union r-edges two
nodes6.

Definition 5 merge two description graphs, G1 G2, description graph whose

nodes disjoint union7 non-distinguished nodes G1 G2 plus new
distinguished node. edges merged graph union edges G1 G2,
except edges touching distinguished nodes G1 G2 modified touch
new distinguished node. new distinguished node merge two distinguished
nodes G1 G2.

rules translating description C Basic classic description graph GC
follows:
1. description consists concept name turned description graph
one node a-edges. atoms node contains concept name.
node r-edges.
2. description form n R turned description graph one node
a-edges. node atoms CLASSIC-THING single r-edge
role R, min n, max 1, restriction GTHING .
3. description form n R turned description graph one node
a-edges. node atoms CLASSIC-THING single r-edge role
R, min 0, max n, restriction GTHING .
4. description form 8R:C, R role, turned description graph
one node a-edges. node atoms CLASSIC-THING single
r-edge role R, min 0, max 1, restriction GC.
5. turn description form C u description graph, construct GC
GD merge them.
6. turn description form 8A:C, attribute, description graph,
first construct description graph hNC ; EC ; rC C. description graph
8A:C hNC [ ftg; EC [ fht; rC ; Aig; ti, node hfCLASSIC-THINGg; fgi.
7. turn description form A1 : : : = B1 : : : Bm description graph
first create distinguished node, node r, CLASSIC-THING atoms,
node e, THING atoms. 1 n , 1 create node ai , atoms
6. Note duplicate edges, ones joining ni ni , removed, since edges form bag.
7. taking disjoint union two sets, elements one may systematically renamed first make
sure sets non-overlapping.

285

fiBorgida & Patel-Schneider

CLASSIC-THING. 1 j , 1 create node bj , atoms
CLASSIC-THING. None ai bj r-edges.
n = 1, create edge hr; e; A1i; n > 1 create edges hr; a1; A1i, han,1 ; e; i,
hai,1 ; ai; Ai 2 n , 1.
Similarly, = 1, create edge hr; e; B1i; > 1 create edges hr; b1; B1 i,
hbm,1; e; Bmi, hbi,1; bi; Bii 2 , 1.
creates two disjoint paths, one Ai one Bj , distinguished node end node.
Figure 1 presents view description graph constructed fashion
description GAME u 8participants:PERSON u coach = captainfather:
want show process preserves extensions. use merge
operations first show work correctly.

Lemma 1 n1 n2 nodes (n1 n2)I = nI1 \ nI2 . D1 D2 description
graphs (D1 D2)I = D1I \ D2I .
Proof: Since components (atoms r-edges) merged node obtained

unioning components respective nodes, since interpretation node
intersection interpretation components, result obviously true
nodes.
merging graphs, difference root nodes replaced
merger edges, well root. element (D1 D2)I clearly
element D1I D2I . Conversely, since take disjoint union nodes
two graphs, mapping functions 1 2 Definition 3 simply unioned,
element D1I D2I element merged root node, hence
(D1 D2 )I .

Theorem 1 possible worlds, extension description ex-

tension description graph.
Proof: proof structural induction descriptions.
extension concept names, cardinality restrictions, 8-restrictions roles
easily seen agree extension description graphs formed them.
Lemma 1 shows conjunction properly handled. 8-restrictions attributes,
construction correct attributes functional.
equalities A1 : : : = B1 : : : Bm construction forms description graph
two disjoint paths distinguished node end node, one labelled Ai ,
nodes ai , labelled Bj , nodes bj .

2 (A1 : : : = B1 : : : Bm)I = fd 2 C j Ak (: : : A1 (d)) = Bh (: : : B1 (d))g;
defining (ai ) = Ai (: : : A1 (d)) (bj ) = Bj (: : : B1 (d))g, yields mapping

required Definition 3. converse satisfied requirement Definition 3
a-edge hn1 ; n2; Ai 2 E , (n2 ) = AI ((n1 )).
286

fiSubsumption CLASSIC

2.3 Canonical Description Graphs

following sections occasionally refer \marking node incoherent";
consists replacing special node outgoing r-edges, including
atoms NOTHING, always empty interpretation. Marking description
graph incoherent consists replacing description graph consisting
incoherent node. (Incoherent graphs thought representing concepts
empty extension.)
Description graphs transformed canonical form repeating following normalization steps whenever possible description graph descendants.
1. node atoms pre-defined host concept, add HOST-THING
atoms. node atomic concept name atoms, add CLASSIC-THING
atoms. pre-defined host concept atoms node, add
more-general pre-defined host concepts atoms.
2. node HOST-THING CLASSIC-THING atoms, mark
node incoherent. node atoms pair host concepts
related pre-defined subsumption relationship, mark node incoherent, since
intersection empty.
3. node description graph marked incoherent, mark description graph
incoherent. (Reason: Even node root, attributes must always value,
value cannot belong empty set.)
4. r-edge node min greater max, mark node incoherent.
5. r-edge node description graph marked incoherent, change max
0. (Reason: cannot fillers belong empty set.)
6. r-edge node max 0, mark description graph incoherent.
(Reason: normalization step records equivalence 0 R 8R:NOTHING,
used infer concept 8R:C arbitrary C subsumes 0 R.)
7. node two r-edges labelled role, merge two edges,
described below.
8. description graph two a-edges node labelled
attribute, merge two edges.
merge two r-edges node, identical roles, replace one redge. new r-edge role role, maximum two mins min,
minimum two maxs max, merge two description graphs
restriction.
merge two a-edges hn; n1 ; Ai hn; n2; Ai, replace single new edge
hn; n0; Ai, n0 results merging n1 n2, i.e., n0 = n1 n2. (If n1 = n2
n0 = n1.) addition, replace n1 n2 n0 a-edges description graph.
287

fiBorgida & Patel-Schneider

need show transformations canonical form change extension
graph. main diculty showing two edge-merging processes
change extension.

Lemma 2 Let G = hN; E; ri description graph two mergeable a-edges let
G0 = hN 0; E 0; r0i result merging two a-edges. GI = G0I .
Proof: Let two edges hn; n1; Ai hn; n2; Ai new node n0 n1 n2.
Choose 2 GI , let function N domain satisfying conditions

extensions (Definition 3) (r) = d. (n1 ) = (n2 )
equal AI ((n)). Let 0 except 0 (n0 ) = (n1 ) = (n2 ).
0 satisfies Definition 3, part 3, G0, replace n1 n2 n0 everywhere.
Moreover, 0 (n0) = (n1 ) 2 nI1 \ nI2 , which, Lemma 1, equals (n1 n2 )I ; part 2
satisfied too, since n0 = n1 n2 . Finally, root modified merger, i.e., n1
n2 r, say n1, = (n1) = 0 (n0), part 1 definition also satisfied.
Conversely, given arbitrary 2 G0I , let 0 function stipulated Definition 3
0 (r0) = d. Let 0 except (n1 ) = (n0 ) (n2 ) = 0 (n0 ).
argument traversed reverse verify satisfies Definition 3,
2 GI .

Lemma 3 Let n node two mergeable r-edges let n0 node

edges merged. nI = n0I .
Proof: Let two r-edges hR; m1; M1; G1i hR; m2; M2; G2i.
Let 2 nI . m1 (m2) M1 (M2) elements domain, d0,
hd; d0i 2 RI . Therefore maximum m1 m2
minimum M1 M2 elements domain, d0, hd; d0i 2 RI . Also, d0
hd; d0i 2 RI GI1 (GI2 ). Therefore, d0 hd; d0i 2 RI GI1 \ GI2 ,
equals (G1 G2)I Lemma 1. Thus 2 n0I .
Let 2 n0I . maximum m1 m2 minimum
M1 M2 elements domain, d0 , hd; d0i 2 RI . Therefore
m1 (m2) M1 (M2) elements domain, d0, hd; d0i 2 RI . Also, d0
hd; d0i 2 RI (G1 G2 )I = GI1 \ GI2 . Therefore, d0 hd; d0i 2 RI
GI1 (GI2 ). Therefore 2 nI .

dealt issue merging, return desired result: showing
\normalization" affect meaning description graphs.

Theorem 2 possible worlds , extension canonical form description

graph, G, resulting Basic classic description extension
description.
Proof: Steps 1 2 justified since GI subset either H C ,
disjoint.
Step 3 justified fact that, definition description graphs, must
element domain extension node description graph.
Steps 4, 5, 6 easily derived Definition 3.
Steps 7 8 dealt preceding two lemmas.
288

fiSubsumption CLASSIC

2.4 Subsumption Algorithm
final part subsumption process checking see canonical description graph
subsumed description. turns possible carry subsumption
test without expense normalizing candidate subsumer concept.

Algorithm 1 (Subsumption Algorithm) Given description description graph
G = hN; E; ri, subsumes?(D; G) defined true following

conditions hold:

1. description graph G marked incoherent.
2. equivalent THING. (This determined checking first D=THING,
recursively testing whether subsumes canonical description graph GTHING .)
3. concept name element atoms r.
4. n R r-edge r R role min greater equal n.
5. n R r-edge r R role max less equal n.
6. 8R:C r-edge r R role G0 restriction graph
subsumes?(C; G0).
7. 8R:C subsumes?(C; GTHING) r CLASSIC-THING atoms. (Reason: 8R:THING requires possibility R applicable object, absent
host values.)
8. 8A:C a-edge G form hr; r0; Ai, subsumes?(C; hN; E; r0i).
9. 8A:C subsumes?(C; GTHING) r CLASSIC-THING atoms.
10. A1 : : : = B1 : : : Bm paths A1 ; : : :; B1 ; : : :; Bm exist G
starting r end node.
11. A1 : : : = B1 : : : Bm Bm paths A1 ; : : :; An,1
B1 ; : : :; Bm,1 exist G starting r end node,
CLASSIC-THING atoms. (Reason: AiI ( A1 ( )) = Bj ( B1 ( ))
:::



:::



FI (AiI (: : : A1I (d))) = FI (Bj (: : : B1 (d)))

attribute F, long attribute applicable (i.e., value host
domain).)

12. C u E subsumes?(C; G) subsumes?(E; G) true.
289

fiBorgida & Patel-Schneider

2.5 Correctness Subsumption Algorithm

soundness algorithm fairly obvious, shall dwell it. completeness algorithm is, usual, dicult establish. First show
canonical description graph node marked incoherent, possible
world non-empty extension description graph node constructed.
constructive, inductive manner, constructing collection possible worlds, called graphical worlds description graph. graphical world
distinguished domain element extension description graph node.
common operation merge two possible worlds.
Definition 6 Let I1 I2 two possible worlds. merge I1 I2, I1 I2,
possible world classic realm disjoint union classic realm I1
classic realm I2 . extension atomic names I1 I2 disjoint union
extensions I1 I2 .
easy show extension description, description graph, node
I1 I2 union (disjoint union classic realm, regular union host realm)
extensions I1 I2 .
Another operation add new domain elements possible world. new domain
elements must classic realm. extension atomic identifiers remain
except new domain elements belong arbitrary set atomic concept
names arbitrary set fillers (filler) role (attribute). Again,
easy show domain element original world extension original
world iff extension augmented world.
Given node, n, marked incoherent, construct graphical worlds
n follows:
1. atoms n precisely THING, n r-edges,
constructs cause r-edges created also add CLASSIC-THING atoms.
possible world, domain element distinguished domain element,
graphical world n.
2. atoms n include HOST-THING, n r-edges. possible
world, distinguished element domain element extension
atoms n host concepts, graphical world n. (Because
requirements host domain, infinite number domain
elements.)
3. atoms n include CLASSIC-THING, r-edge, hR; m; M; Gi, n,
construct graphical worlds G. done number
> 0 G marked incoherent, G
marked incoherent = 0.
two graphical worlds host domain element
distinguished element. (Again, possible extension host concept
either empty infinite.) merge graphical worlds r-edge
one possible world. Add new domain elements one exactly
290

fiSubsumption CLASSIC

extensions atoms n fillers R exactly distinguished
elements appropriate graphical worlds. domain element
correct number fillers r-edge, disjoint union classic
realms merge process different host domain elements picked
above; therefore extension n. Thus resulting world graphical
world n.
Given description graph, G = hN; E; ri, marked incoherent, construct
graphical worlds G follows: node n 2 N construct graphical world
n. done none marked incoherent. Merge graphical
worlds. Modify resulting world hn1 ; n2; Ai 2 E A-filler
distinguished node graphical world n1 distinguished node graphical
world n2 . easy show distinguished node graphical world r
extension G, making graphical world G.
show final part result.

Theorem 3 subsumption algorithm indicates canonical description
graph G subsumed Basic classic description D, possible world
domain element extension graph extension D.
Therefore G subsumed D.
Proof: proof actually shows subsumption algorithm indicates
canonical description graph, G, subsumed description, D,
graphical worlds G distinguished domain elements
extension D. Remember subsumption algorithm indicates G subsumed
D, G must marked incoherent thus graphical worlds G.
proof proceeds structural induction D. Let G = hN; E; ri.
atomic concept name pre-defined host concept, occur
atoms r. construction, graphical world G distinguished
domain element extension D. Similarly, CLASSIC-THING
HOST-THING, distinguished domain elements wrong realm.
THING, possible subsumption algorithm indicate
non-subsumption. case graphical world G property
distinguished domain element extension D.

form D1 u D2 subsumption algorithm must indicate G

subsumed least one D1 D2 . inductive hypothesis, get
graphical worlds G distinguished domain elements
extension D1 extension D2, thus extension D.

form n R either r-edge r labelled R min less
n r-edge.
former case graphical worlds G distinguished node
n , 1 fillers R, n greater min r-edge R, thus
distinguished node extension D.
291

fiBorgida & Patel-Schneider

latter case, graphical worlds G distinguished node
number fillers R. n , 1 fillers property
distinguished node extension D.

form n R either r-edge r labelled R max greater
n (including 1) r-edge.
former case graphical worlds G distinguished node
n + 1 fillers R, n less max r-edge R, thus
distinguished node extension D.
latter case, graphical worlds G distinguished node
number fillers R. n + 1 fillers property
distinguished node extension D.

form 8R:C, R role, two cases arise.
1. subsumes?(C; GTHING) CLASSIC-THING atoms r.
graphical worlds G whose distinguished element host

realm, thus extension D.
2. Otherwise, either r-edge r role R description graph H
subsumes?(C; H ) false r-edge r role R. Note
extension C entire domain, thus must subset
either host realm classic realm.
former case H marked incoherent (or else subsumption could
false) max r-edge cannot 0. Thus graphical
worlds H whose distinguished element extension C
graphical worlds G use graphical worlds H distinguished
domain element R-fillers. graphical worlds G distinguished element extension D.
latter case, pick graphical worlds G distinguished node
R-filler wrong realm. graphical worlds G distinguished
element extension D.

form 8A:C attribute two cases arise.
1. subsumes?(C; GTHING) CLASSIC-THING atoms r.
graphical worlds G whose distinguished element host
realm, thus extension D.
2. Otherwise, either a-edge r attribute node
r0 subsumes?(C; H ) false, H = hN; E; r0i; a-edge
r attribute A. Note extension C entire domain,
thus must subset either host realm classic realm.
former case H marked incoherent, G marked incoherent. Thus graphical worlds H whose distinguished element
extension C. Given graphical world H , graphical world
G formed simply changing distinguished domain element.
292

fiSubsumption CLASSIC

original graphical world's distinguished element extension C,
new graphical world's distinguished element extension
D, required.
latter case, pick graphical worlds G distinguished node
A-filler wrong realm. graphical worlds G distinguished
element extension D.
form A1 : : : = B1 : : : Bm several cases arise.
1. one paths A1 ; : : :; An,1 B1 ; : : :; Bm,1 exist G starting
r, find end partial path use graphical worlds
domain element node element host domain filler
next attribute path. one full paths filler.
2. paths A1 ; : : :; B1 ; : : :; Bm exist G starting r end
different nodes, use graphical worlds domain elements
two nodes different.
3. one paths A1 ; : : :; B1 ; : : :; Bm exist G starting
r paths A1 ; : : :; An,1 B1; : : :; Bm,1 exist G starting r
end node either CLASSIC-THING atoms
node 6= Bm. former case use graphical worlds domain
element node host realm. latter case use graphical worlds
different fillers Bm domain element node.
4. one paths A1 ; : : :; B1 ; : : :; Bm exist G starting
r paths A1 ; : : :; An,1 B1; : : :; Bm,1 exist G starting r
end different nodes use graphical worlds different fillers
domain elements nodes domain elements
host realm.
cases either one (: : : A1 )(d) BmI (: : : B1 )(d)
exist (: : : A1 )(d) 6= BmI (: : : B1 )(d), distinguished domain element
extension D.

2.6 Implementing subsumption algorithm

section provide comments actual subsumption algorithm
used classic system, including rough analysis complexity.
described it, deciding whether description C subsumes accomplished
three phases:
1. Convert description graph GD .
2. Normalize GD .
3. Verify whether C subsumes GD .
Step 1: Conversion accomplished simple recursive descent parser, takes
advantage fact syntax description logics (i.e., leading term constructor) makes amenable predictive parsing. Clearly, constructing graphs fixed sized
293

fiBorgida & Patel-Schneider

terms (like at-least) constant time (if measure size integer size 1 matter large), time non-recursive terms (like same-as) proportional
length. Finally, recursive terms (like all, and) require fixed amount additional
work, top recursive processing. Therefore, first stage accomplished
time proportional size input description. order speed later processing,
useful maintain various lists, lists atomic concept identifiers,
roles/attributes, sorted order. sorting needs done initially (later, ordering
maintained performing list merges) incurs, worst case quadratic
overhead processing8 . case, total size graph constructed (including
sizes nodes, etc.) proportional size original concept description.
Step 3: Checking whether description C subsumes description graph GD ,
seen run time proportional size subsuming concept, modulo cost
lookups various lists. Since sorted, lookup costs bounded
logarithm size candidate subsumee graph, total cost bounded
O(j C j log j GD j).
Step 2: Normalization accomplished post-order traversal description
graph: processing description graph hN; E; ri, node N normalized first independently (see details below), afterwards attribute edges E normalized.
later task involves identifying multiple identically-labelled attribute edges leaving node
(this done one pass since attribute edges grouped source node, sorted
attribute name), \merging" them. Merging two edges quite easy itself, merging nodes tips, must careful node mergers
may cascade; example, concept form a1 = b1 u a2 = b2 u : : : u = bn u
a1 = a2 u a2 = a3 u : : : u an,1 = original graph 2n + 1 nodes, 2n
collapsed normalization step 8. discover eciently, use version
A-Kaci's algorithm unifying -terms (At-Kaci, 1984; At-Kaci & Nasr, 1986);
algorithm relies UNION-FIND technique identify nodes merged, runs
time slightly linear number nodes N . Therefore cost
non-recursive portion graph normalization roughly linear number nodes
it.
merging two description graph nodes quite similar normalization
single node: atomic concept identifier lists need sorted/merged, duplicates
eliminated y. done time proportional size nodes
themselves, make size node include size various lists it,
atoms. processing role edges leaving node is, again, one identifying merging
identically-labelled edges. (But case mergers labelled edges interact,
single pass role-edge list sucient.) cost non-recursive aspects
merger proportional size local information.
therefore left problem bounding total number procedure calls
NormalizeGraph, NormalizeNode, MergeEdge, MergeNode, bounding
sizes nodes merged.
NormalizeGraph NormalizeNode called exactly every (sub)graph
node original graph, part depth-first traversal, argued above,
8. tend use fancy sorting techniques since lists likely long.

294

fiSubsumption CLASSIC

contribute time proportional total size original graph,
proportional size original description.
number calls MergeEdge MergeNode simply bounded however {
node may merged several times others. However, calls paired,
invocation MergeNode reduces number nodes graph one. Therefore, since number nodes incremented elsewhere, total number calls
MergeEdge MergeNode bounded number nodes original graph.
problem non-recursive cost call MergeNode depends size
argument nodes, call may increase size remaining node
sum sizes two original nodes.
Therefore, original concept size S, graph n nodes, size
vi, worst case cost would result iterative summation sizes:
(vi1 + vi2 ) + (vi1 + vi2 + vi3 ) + (vi1 + vi2 + vi3 + vi4 ) + : : :
= n vi1 + (n , 1) vi2 + : : : + 1 vi
n

Given n vj bounded
, clearly worst case O(S 3).
P
fact, given constraint j =1 nvj = , possible argue worst case
cost occur vj = 1 every j, (i.e., n = ), case cost really
O(S 2).
theoretical improvements could attempted algorithm
(e.g., merging nodes correct order increasing size) well analysis (e.g.,
nodes graphs depth tree merged).
remark like description logics, classic permits identifiers associated complex descriptions identifiers used descriptions
(though recursion allowed). expansion identifiers standard operation
lead exponential growth size certain pathological cases (Nebel, 1990), making
subsumption problem inherently intractable. type system programming language Standard ML, pathological cases encountered practice,
correct algorithm simple, straightforward ecient normal cases (unlike
correct algorithm reasoning set constructor, say).
users rarely ask whether concept subsumes another, rather
interested relationship pairs concepts, classic fact constructs
normalized description graph description given it. suggests might
better check whether one description graph subsumes another one, rather checking
whether description subsumes graph. general, works quite well, except
would verify attribute edges subsumer graph form subgraph
subsumee's attribute edges. Since edges uniquely labelled normalization,
inherently hard, still requires complete traversal (and hence marking/unmarking)
upper graph. therefore found useful encode part description
graph's root same-as restrictions lead construction corresponding aedges; then, subsumption testing, aspect subsumer related same-as
checked list same-as pairs.
Also, description algorithm tried optimize cost normalization, dominates checking single subsumption. overall use
295

fiBorgida & Patel-Schneider

system (e.g., processing individuals), inquiries restrictions roles/attributes
frequent, space usage problem, may practically advantageous
maintain r-edges a-edges node hash table, rather sorted list,
order speed access. (Note merging r-edges, one must however still
way iterating values stored hash table.)

3. Individuals Descriptions

practical applications DLs used, integrity constraint checking,
often useful able specify ranges atomic values roles. common
examples involve integers, e.g., \the year student 1,2,3 4",
called enumerated types Pascal, e.g., \the gender person either F". One way
allow constraints introduce new description constructor, set description,
creates description list individual names, whose obvious extension
set consisting extensions individuals appear list. construct
could used terms like 8year:f1 2 3 4g. Another useful constructor involving individuals
fills restriction, p : I, denotes objects extension individual
one fillers relationship denoted role attribute p. (Note
attribute, q, 8q:fIg q : I.)
Within paradigm DLs, constructors quite useful fact used
express new forms incomplete information. example, know Ringo
early fifties, simply assert Ringo described 8age:f50 51 52 53 54g.
constructors also used ask useful queries. example, find
male persons suces determine instances gender : M.
new constructors interact previous ones, cardinality constraints:
clearly size set upper cardinality bound role restricts. interaction
problematic long individuals set host values, since individuals
properties fixed known ahead time. However, allow classic
individuals members sets, properties individuals might
affect subsumption. simple example, know Ringo instance
concept ROCK-SINGER (which shall write Ringo 2 ROCK-SINGER ) extension
8friends:ROCK-SINGER always superset extension 8friends:fRingog.
disturbing classification hierarchy definitions would change
new facts individuals added knowledge base. Definitions meant
contingent facts current world. Therefore, subsumption usually defined
independent \contingent" assertions. shall see below, use individual
properties description subsumption also leads intractability.

3.1 Complex Subsumption Reasoning: Example

Traditional proofs intractability (e.g. (Levesque & Brachman, 1987)) occasionally
left users DLs puzzled intuitive aspects language make reasoning
dicult. reason present example illustrates complexity reasoning
set description.
Suppose concept JADED-PERSON one wants
visit Arctic and/or Antarctic, wherever penguins:
296

fiSubsumption CLASSIC

JADED-PERSON =: 8wantsToVisit:(fArctic Antarcticg u 8hasPenguins!: fYesg)

Suppose remember Arctic Antarctic; know
South Pole located one two places, penguins there,
North Pole located one two places, penguins there.
Assuming isLocatedIn! hasPenguins! attributes|roles exactly one filler,
record
Southpole 2 8isLocatedIn!:(fArctic Antarcticg u 8hasPenguins!: fYesg)
Northpole 2 8isLocatedIn!:(fArctic Antarcticg u 8hasPenguins!: fNog)

thus unable distinguish exact location Southpole Northpole; however,
since hasPenguins! single filler, exactly one Arctic Antarctic (and fact
must) Yes filler hasPenguins!, therefore exactly one location
Southpole .
result facts, know extension JADED-PERSON must
subset extension 1 wantsToVisit database containing facts
Southpole Northpole.
Observe occasional worse-case behavior, generalized
diculty reasoning set descriptions. subsumption ignores assertions
individuals, (yet) show subsumption per se must perform inferences.
simple transformation, given appendix, establishes fact, converting
recognition individuals question subsumption two descriptions
making individuals involved attribute-fillers new dummy attributes,
descriptions restrictions attributes. result, description non-empty
attribute values must satisfy corresponding restrictions.

3.2 Modified Semantics Individuals

seen two problems individuals appearing descriptions: (1) effect
\mutable facts" extensional relationships \immutable" descriptions, (2)
computational intractability subsumption caused appearance individuals
descriptions.
deal first problem, reasonable restrict computation subsumption cannot access \database facts" individuals, role fillers,
individuals treated like host identifiers. procedural description
aspect reasoning, sense negation-by-failure Prolog. Prolog,
would desirable find semantic account phenomenon.
semantics ignores mutable facts determining subsumption hard
devise|all required two different sets possible worlds corresponding
KB containing concepts individuals. One set consists possible worlds
model information KB; second consists possible worlds
model information concepts (and roles attributes). asking questions individuals, first set possible worlds must considered; asking
subsumption questions, second, larger, set must considered, thus ignoring effects
mutable facts.
297

fiBorgida & Patel-Schneider

However, semantics solve computational problem individuals
descriptions. deal problem, semantics individuals modified
follows: instead mapping individuals separate elements domain, done
standard semantics, individuals mapped disjoint subsets domain, intuitively
representing different possible realizations (Platonic) individual.
Therefore, semantics set constructor stated follows: Domain value
belongs extension fB1 : : : Bn g iff belongs extension one Bi .
associated change notion cardinality required|two elements domain
considered congruent belong extension individual
identical. cardinality set elements domain size set
modulo congruence relationship. means occurrences different identifiers
description(s) guaranteed unequal, distinct occurrences individual
identifier guaranteed denote individual.
two consequences stance:
1. Looking descriptions Southpole Northpole Section 3.1, distinct
occurrences Arctic might satisfied distinct domain elements, different role
fillers. (In greater detail: extension Arctic might include domain elements d1
d2, d1 satisfying condition hasPenguins! : Yes, d2 satisfies hasPenguins! : No.
Southpole located d1, Northpole located d2 , still
satisfying isLocatedIn! : Arctic. Similarly domain elements d3 d4
extension Antarctic. Therefore one could two places visit
penguins, d1 d3.)
2. Even though individual may description includes
isLocatedIn! : Arctic u originatesIn! : Arctic;
need satisfy condition isLocatedIn! = originatesIn!, since equality restriction requires identity domain values.

4. Adding Individuals CLASSIC

Individuals occur classic host descriptions. following constructs create
classic descriptions:
R:I
A:I
fI1 : : : Ing
attribute, R role, name classic individual host value,
collectively called individuals, Ij names classic individuals. New host descriptions
constructed using fI1 : : : g, Ij host values.
interpretation function :I extended individual identifiers, requiring II
non-empty subset C , syntactically recognized host individual,
making II = fIg host values I. stated earlier, interpretations distinct identifiers
must non-overlapping.
interpretation CI non-atomic descriptions modified follows:
298

fiSubsumption CLASSIC

p : II = fd 2 C j 9x (d; x) 2 pI ^ x 2 II g
fI1 : : : IngI = Sk IIk Ik classic individuals; fI1 : : : IngI = fI1 : : : g Ik
host individuals; empty otherwise.

(n p)I (resp. (n p)I ) objects C least (resp. most) n noncongruent fillers role p

development subsumption algorithm Section 2 modified take
account added constructs modified semantics introduced earlier.
First description graphs extended. node description graph given third
field, either finite set individuals special marker denoting \universal"
set. field often called dom node. a-edges r-edges given
extra field, called fillers edge. field finite set individuals.
unspecified, constructions previous sections, dom node universal set
fillers a-edge r-edge empty set.
semantics description graphs Definition 3 extended following:

Definition 7 Let G = hN; E; ri description graph let possible world.

element, d, GI , iff function, , N

1. = (r);
2. n 2 N (n) 2 nI ;
3. hn1 ; n2; A; F 2 E h(n1 ); (n2)i 2 AI , f 2 F , (n2 ) 2 f .
element, d, nI , n = hC; H; i, iff
1. C 2 C , 2 CI ;
2. hR; m; M; G; F 2 H ,
(a)
(b)
(c)

elements, d0, domain hd; d0i 2 RI ;
d0 2 GI d0 hd; d0i 2 RI ;
f 2 F domain element, d0 , hd; d0i 2 RI d0 2 f

3. universal set 9f 2 2 f .

merging nodes, dom sets intersected. Merging description graphs unchanged. merging a-edges r-edges, sets fillers unioned.
translation descriptions description graphs extended following rules:
8. description form R : turned description graph one node
a-edges. node atoms CLASSIC-THING single r-edge role
R, min 0, max 1, fillers fIg. description graph restricting r-edge
GCLASSIC-THING classic individual, GHOST-THING otherwise.
299

fiBorgida & Patel-Schneider

9. description form : turned description graph two nodes
single a-edge them. distinguished node graph source
a-edge. r-edges atoms CLASSIC-THING. node
also r-edges. atoms CLASSIC-THING classic individual,
HOST-THING otherwise. a-edge single filler I.
10. description form fI1 : : : g turned description graph one node.
node dom set containing I1 , r-edges. atoms
node HOST-THING individuals host values, CLASSIC-THING
individuals classic individual names. (Note parser ensures
individuals either must host values must classic individual names.)
short examination shows Theorem 1 true graphs, i.e., extension
description graphs formed using rules extension description
formed.
following transformations added canonicalization algorithm:
9. dom node empty, mark node incoherent.
10. host value dom node atoms node, remove
dom.
11. a-edge one filler, mark description graph incoherent.
12. a-edge filler node end universal dom, make dom
filler.
13. filler a-edge included dom node end, mark
description graph incoherent.
14. node one element dom, make element filler
a-edges pointing it.
15. fillers r-edge subset dom distinguished node
restriction graph edge, mark node r-edge incoherent.
16. min r-edge less cardinality fillers it, let min
cardinality.
17. max r-edge greater cardinality dom distinguished node description graph r-edge, make max edge
cardinality dom.
18. min r-edge greater equal cardinality dom
distinguished node restriction graph r-edge, let fillers edge
union fillers dom above. (If min greater cardinality,
steps 4 17 detect inconsistency.)
300

fiSubsumption CLASSIC

19. max edge equal cardinality fillers edge, let dom
distinguished node description graph r-edge intersection
dom fillers. (If max less cardinality, steps 18 4 detect
inconsistency.)
Note new canonical form a-edges pointing single node
value fillers, empty set, node set
value dom.
proofs Lemmas 3 2 also work extension description graphs.
proof Theorem 2 extended graphs.
subsumption algorithm page 289 extended follows:
13. R : r-edge r role R fillers including I.
14. : a-edge r attribute fillers including I.
15. fI1 : : : g dom r subset fI1 : : : g.
Again, soundness extended algorithm fairly obvious. completeness
proof following additions construction graphical worlds:

extension classic individual names starts empty.
constructing graphical worlds node includes HOST-THING
atoms non-universal dom, pick domain elements corresponding
elements dom.

constructing graphical worlds node includes CLASSIC-THING
atoms non-universal dom, add distinguished domain element
extension one dom elements.

constructing graphical worlds r-edges node, ensure element

fillers r-edge distinguished element least one graphical
worlds extension either adding extension using appropriate
host domain elements. (This done fillers must subset
dom distinguished node graphical world host values must belong
atoms.)

fillers a-edges need considered \pushed" onto nodes
canonicalization process.
proof Theorem 3 extended following cases:

form fI1 : : : Ing dom r subset fI1; : : :; Ing. Thus
graphical worlds G distinguished domain element
extension Ij.

form : either a-edge r labelled
filler a-edge.

301

fiBorgida & Patel-Schneider

former case node pointed a-edge cannot domain
singleton consisting I. Therefore graphical worlds G
distinguished node A-filler extension I, required.
latter case, pick graphical worlds G distinguished node Afiller wrong realm. graphical worlds G distinguished element
extension D.

form R : either r-edge r labelled R
filler r-edge.
former case either cardinality dom distinguished node
description graph r-edge greater min, m, r-edge, dom
include I. dom include I, graphical worlds
node distinguished element extension I, required.
dom include I, least elements dom besides I,
fillers r-edge subset set elements. thus graphical
worlds G use elements, required.
latter case, pick graphical worlds G distinguished node Rfiller wrong realm. graphical worlds G distinguished element
extension D.

shows subsumption algorithm given sound complete
modified semantics presented here.

5. Complete CLASSIC

make final pass deal less problematic aspects classic descriptions
appropriately covered far.
classic allows primitive descriptions form (PRIMITIVE T),
description, symbol. extension arbitrary subset
extension D, extension (PRIMITIVE E T), provided
E subsume other. way one express EMPLOYEE, kind person
must employee number,
(PRIMITIVE (PERSON u 1 employeeNr) employee)
construct removed creating every primitive atomic concept (e.g.,
EMPLOYEEHOOD) replacing definition concept conjunction
necessary conditions atom, case EMPLOYEEHOOD u (PERSON u
1 employeeNr). Care taken use atomic concept equivalent primitives.
classic permits declaration disjoint primitives, essentially allowing one state
extensions various atomic concepts must disjoint possible worlds.
deal declarations, need modify algorithm creating canonical graphs
adding step marks node incoherent whenever atoms contains two identifiers
declared disjoint.
302

fiSubsumption CLASSIC

allow approximate representation ideas cannot encoded using
constructors expressly provided, classic allows use test-defined concepts, using
following syntax:
(TEST [host-language Boolean function])
e.g., (TEST Prime-Number-Testing-Function).9 purposes subsumption,
treated \black-boxes", semantics assigned atomic concepts. (Test concepts
real effect reasoning level individuals, perform constraint
checking.)
simple additions, algorithm sound complete subsumption
algorithm descriptions classic 1, modified semantics introduced
paper.

6. Summary, Related Work, Conclusions
believe paper makes two kinds contributions: First, paper presents abstracted form subsumption algorithm classic description logic, shows
ecient correct modified semantics. significant
previous claims correct ecient subsumption algorithms implemented DLs
kandor (Patel-Schneider, 1984) candide (Beck et al., 1989) turned
unfounded (Nebel, 1988).
tractability proof language like Basic classic claimed exist (but
proven) (Donini et al., 1991), alternate proof technique may found considering restriction (corrected) subsumption algorithm (Hollunder & Nutt, 1990).
Description graphs also turned interest support
theoretical results DLs, concerning learnability (Cohen & Hirsh, 1994; Pitt &
Frazier, 1994)|results would seem harder obtain using standard notation
DLs.
Second, paper investigates effect allowing individuals appear descriptions DLs. independently demonstrated (Lenzerini & Schaerf, 1991), adding
set description introduces yet another source intractability, provided
intuitive example illustrating source diculties. implementers classic
system, like others use refutation/tableaux theorem-proving techniques, chose
perform inferences validated standard semantics,
formal intractability result obvious algorithm apparent, short enumerating possible ways filling roles. subset inferences actually performed
initially described procedurally: \facts" individuals taken account
subsumption algorithm. paper provides denotational semantic account
incomplete set inferences. formal proof correct account corollary
completeness proof subsumption algorithm Section 4, observation
graph construction subsumption algorithms section indeed ignore
9. order deal two realms, classic fact provides two constructors: H-TEST CTEST, host classic descriptions, cause added complications besides
keeping track correct realm.

303

fiBorgida & Patel-Schneider

properties individuals involved. one difference original implementation classic current semantics attribute paths ending
filler used imply equality condition. noted Section 3.2, modified
semantics support inference, taken implementation
classic. significant change standard semantics small, easy explain
users (either procedurally semantically), affects desired aspects
language (i.e., reasoning Basic classic remains exactly before).

Acknowledgments

wish thank Ronald Brachman colleagues classic project
collaboration, JAIR referees excellent suggestions improving
paper. particular, one referees deserves medal thoroughness care
taken locating weaknesses arguments, thankful. remaining
errors course responsibility.

References

At-Kaci, H. (1984). Lattice Theoretic Approach Computation Based Calculus
Partially-Ordered Type Structures. Ph.D. thesis, University Pennsylvania.
At-Kaci, H., & Nasr, R. (1986). LOGIN: logic programming language built-in
inheritance. Journal Logic Programming, 3, 187{215.
American Association Artificial Intelligence (1992). Issues Description Logics: Users
Meet Developers. Working Notes AAAI 1992 Fall Symposium.
Baader, F., Burckert, H.-J., Heinsohn, J., Hollunder, B., Muller, J., Nebel, B., Nutt, W.,
& Profitlich, H.-J. (1991). Terminological knowledge representation: proposal
terminological logic. German Research Center Artificial Intelligence (DFKI).
Baader, F., & Hanschke, P. (1991). scheme integrating concrete domains concept
languages. Proceedings Twelfth International Joint Conference Artificial
Intelligence, pp. 452{457. International Joint Committee Artificial Intelligence.
long version appears Research Report RR-91-10 German Research Center
Artificial Intelligence (DFKI), April 1991.
Baader, F., & Hollunder, B. (1991). KRIS: Knowledge Representation Inference System.
SIGART Bulletin, 2 (2), 8{15.
Beck, H. W., Gala, S. K., & Navathe, S. B. (1989). Classification query processing
technique CANDIDE semantic data model. Proceedings Fifth International Data Engineering Conference, pp. 572{581. Institute Electric Electronic
Engineers.
Borgida, A., Brachman, R. J., McGuinness, D. L., & Resnick, L. A. (1989). CLASSIC:
structural data model objects. Proceedings 1989 ACM SIGMOD International Conference Mangement Data, pp. 59{67. Association Computing
Machinery.
304

fiSubsumption CLASSIC

Borgida, A. (1992). type systems knowledge representation: Natural semantics
specifications description logics. International Journal Intelligent Cooperative Information Systems, 1 (1), 93{126.
Brachman, R. J., Fikes, R. E., & Levesque, H. J. (1983). KRYPTON: functional approach
knowledge representation. IEEE Computer, 16 (10), 67{73.
Cohen, W. W., & Hirsh, H. (forthcoming). Learnability description logics equality
constraints. Machine Learning. preliminary version appears Proceedings
Fourth Annual Workshop Computational Learning Theory.
Devanbu, P., Brachman, R. J., Ballard, B., & Selfridge, P. G. (1991). LaSSIE: knowledgebased software information system. Communications ACM, 34 (5), 35{49.
Donini, F. M., Lenzerini, M., Nardi, D., & Nutt, W. (1991). Tractable concept languages.
Proceedings Twelfth International Joint Conference Artificial Intelligence,
pp. 458{453. International Joint Committee Artificial Intelligence.
Doyle, J., & Patil, R. (1991). Two theses knowledge representation: Language restrictions, taxonomic classification, utility representation services. Artificial
Intelligence, 48 (3), 261{297.
Pitt, L., & Frazier, M. (1994). Classic learning. Proceedings Seventh Annual ACM
Conference Computational Learning Theory New Brunswick, NJ. ACM Press.
Heinsohn, J., Kudenko, D., Nebel, B., & Profitlich, H.-J. (1992). empirical analysis terminological representation systems. Proceedings Tenth National
Conference Artificial Intelligence, pp. 767{773. American Association Artificial
Intelligence.
Hollunder, B., & Nutt, W. (1990). Subsumption algorithms concept languages. Research
report RR-90-04, German Research Center Artificial Intelligence (DFKI).
Lenzerini, M., & Schaerf, A. (1991). Concept languages query languages. Proceedings
Ninth National Conference Artificial Intelligence, pp. 471{476. American
Association Artificial Intelligence.
Levesque, H. J., & Brachman, R. J. (1987). Expressiveness tractability knowledge
representation reasoning. Computational Intelligence, 3 (2), 78{93.
MacGregor, R. M., & Bates, R. (1987). Loom knowledge representation language. Tech.
rep. ISI/RS-87-188, Information Sciences Institute, University Southern California.
Mays, E., Apte, C., Griesmer, J., & Kastner, J. (1987). Organizing knowledge complex
financial domain. IEEE Expert, 2, 61{70.
Nebel, B. (1988). Computational complexity terminological reasoning BACK. Artificial
Intelligence, 34 (3), 371{383.
Nebel, B. (1990). Terminological reasoning inherently intractable. Artificial Intelligence,
43 (2), 235{249.
305

fiBorgida & Patel-Schneider

Nebel, B., Peltason, C., & von Luck, K. (Eds.). (1991). International Workshop Terminological Logics. Document D-91-13, German Research Center Artificial Intelligence
(DFKI).
Owsnicki-Klewe, B. (1988). Configuration consistency maintenance task. Hoeppner, W. (Ed.), Proceedings GWAI-88|the 12th German Workshop Artificial
Intelligence, pp. 77{87. Springer Verlag.
Patel-Schneider, P. F. (1984). Small beautiful knowledge representation.
Proceedings IEEE Workshop Principles Knowledge-Based Systems, pp.
11{16. IEEE Computer Society.
Patel-Schneider, P. F. (1987). Decidable, Logic-Based Knowledge Representation. Ph.D.
thesis, Department Computer Science, University Toronto.
Patel-Schneider, P. F. (1989a). four-valued semantics terminological logics. Artificial
Intelligence, 38 (3), 319{351.
Patel-Schneider, P. F. (1989b). Undecidability subsumption NIKL. Artificial Intelligence, 39 (2), 263{272.
Peltason, C., von Luck, K., & Kindermann, C. (Eds.). (1991). Terminological Logic Users
Workshop. Fachbereich Informatik, Technische Universitat Berlin.
Peltason, C., von Luck, K., Nebel, B., & Schmiedel, A. (1987). user's guide
BACK system. Kit-report 42, Fachbereich Informatik, Technische Universitat Berlin.
Resnick, L. A., Borgida, A., Brachman, R. J., McGuinness, D. L., & Patel-Schneider,
P. F. (1992). CLASSIC description reference manual COMMON LISP
implementation. AI Principles Research Department, AT&T Bell Laboratories.
Schmidt-Schauss, M. (1989). Subsumption KL-ONE undecidable. Proceedings
First International Conference Principles Knowledge Representation
Reasoning, pp. 421{431. Morgan Kaufmann.
Wright, J. R., Weixelbaum, E. S., Brown, K., Vesonder, G. T., Palmer, S. R., Berman,
J. I., & Moore, H. H. (1993). knowledge-based configurator supports sales,
engineering, manufacturing AT&T network systems. Proceedings
Innovative Applications Artificial Intelligence Conference, pp. 183{193. American
Association Artificial Intelligence.

A. Intractability Reasoning ONE-OF

present formal proof subsumption set descriptions fact NP-hard.10
show term language allows set description need
\case analysis" order check whether extension individual belongs
description not; constructor behaves like disjunction elements
10. original result submitted publication 1990. different, independent, proof
result since outlined (Lenzerini & Schaerf, 1991).

306

fiSubsumption CLASSIC

extensions individuals whose membership terms known priori, i.e., nonhost individuals. particular, show encode testing unsatisfiability
formula 3CNF question recognizing individual instance description.
Since problem known NP-hard, strong indication intractability.
Start formula F , 3CNF. Using DeMorgan's laws, construct formula G,
negation F , 3DNF. Testing validity G equivalent checking
unsatisfiability F .
Construct every propositional symbol p used F , two individual names P P^ .
(Here P^ represent negation p.) individual attribute truthValue,
possible fillers True False
P; P^ 2 8truthValue: fTrue Falseg:
make sure P P^ exactly one, opposite, truth values, create two
individual names, Yesp Nop, additional attributes approve deny respectively,
whose fillers need truth value True False respectively:
Yesp 2 8approve:(fP P^ g u 8truthValue: fTrueg)
Nop 2 8deny:(fP P^ g u 8truthValue: fFalseg)
Now, given formula G = C 1 _ C 2 _ : : : _ Cn, create individual names C1, C2,
: : : , Cn, role conjuncts containing propositions conjuncts.
example, C 1 = p ^ :q ^ :r
C1 2 8conjuncts: fP Q^ R^ g u 3 conjuncts:
Finally, construct individual G C1, C2, : : : , Cn possible fillers new role

disjunctsHolding :

G 2 8disjunctsHolding: fC1 C2 : : : Cng:

formula G valid iff always least one disjunct holds.
equivalent membership concept VALID-FORMULAE defined

1 disjunctsHolding u 8disjunctsHolding:(8conjuncts:(8truthValue:fTrueg)):
shows recognizing whether individuals instances descriptions
intractable presence set descriptions, minimum number restrictions, value
restrictions.
convert question concerning subsumption two descriptions
essentially making individuals involved attribute-fillers new dummy attributes,
descriptions restrictions attributes. description nonempty attribute values must satisfy corresponding restrictions.
So, define concept UPPER

8formula:VALID-FORMULAE
define concept LOWER
307

fiBorgida & Patel-Schneider

8dummy1-p:(fPg u [P 0s concept descriptor ]) u
8dummy2-p:(fP^g u [P^ 0s concept descriptor ]) u
8dummy3-p:(fYespg u : : :) u
8dummy4-p:(fNopg u : : :) u
:::
8dummy5-ci:(fCig u : : :) u
:::
8formula:(fGg u : : :)
database state either concept LOWER instances, case
subset extension UPPER, least one instance, case
individual names filling various dummy attributes must properties ascribed
them, whence C VALID-FORMULAE (and hence UPPER subsume LOWER) iff
C valid, completes proof.

308

fiJournal Artificial Intelligence Research 1 (1994) 159-208

Submitted 8/93; published 2/94

Bias-Driven Revision Logical Domain Theories

Moshe Koppel
Ronen Feldman

KOPPEL@BIMACS.CS.BIU.AC.IL
FELDMAN@BIMACS.CS.BIU.AC.IL

Department Mathematics Computer Science, Bar-Ilan University,
Ramat-Gan, Israel

Alberto Maria Segre

SEGRE@CS.CORNELL.EDU

Department Computer Science, Cornell University,
Ithaca, NY 14853, USA

Abstract
theory revision problem problem best go revising deficient
domain theory using information contained examples expose inaccuracies. paper
present approach theory revision problem propositional domain theories.
approach described here, called PTR, uses probabilities associated domain theory elements
numerically track flow proof theory. allows us measure precise
role clause literal allowing preventing (desired undesired) derivation given
example. information used efficiently locate repair flawed elements theory.
PTR proved converge theory correctly classifies examples, shown
experimentally fast accurate even deep theories.

1. Introduction
One main problems building expert systems models elicited experts tend
approximately correct. Although hand-coded models might make good first
approximation real world, typically contain inaccuracies exposed fact
asserted agree empirical observation. theory revision problem
problem best go revising knowledge base basis collection
examples, expose inaccuracies original knowledge base. course,
may many possible revisions sufficiently account observed examples; ideally,
one would find revised knowledge base consistent examples
faithful possible original knowledge base.
Consider, example, following simple propositional domain theory, . theory,
although flawed incomplete, meant recognize situations investor buy
stock soft drink company.
buy-stock increased-demand product-liability
product-liability popular-product unsafe-packaging
increased-demand popular-product established-market
increased-demand new-market superior-flavor.
theory essentially states buying stock company good idea demand
product expected increase company expected face product liability lawsuits.
theory, product liability lawsuits may result product popular (and therefore may
present attractive target sabotage) packaging tamper-proof. Increased
product demand results product popular enjoys large market share,

1994 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.

fiKOPPEL, FELDMAN, & SEGRE

new market opportunities product boasts superior flavor. Using closed world
assumption, buy-stock derivable given set true observable propositions precisely,
say,
{popular-product, established-market, celebrity-endorsement},
{popular-product, established-market, colorful-label}
are, say,
{unsafe-packaging, new-market},
{popular-product, unsafe-packaging, established-market}.
Suppose told various examples whether buy-stock derivable.
example, suppose told set true observable propositions is:
(1)

{popular-product, unsafe-packaging, established-market} buy-stock false,

(2)

{unsafe-packaging, new-market} buy-stock true,

(3)

{popular-product, established-market, celebrity-endorsement} buy-stock true,

(4)

{popular-product, established-market, superior-flavor} buy-stock false,

(5)

{popular-product, established-market, ecologically-correct} buy-stock false,

(6)

{new-market, celebrity-endorsement} buy-stock true.

Observe examples 2, 4, 5 6 misclassified current theory . Assuming
explicitly given information regarding examples correct, question revise
theory examples correctly classified.
1.1. Two Paradigms
One approach problem consists enumerating partial proofs various examples
order find minimal set domain theory elements (i.e., literals clauses) repair
satisfy examples (EITHER, Ourston & Mooney, press). One problem
approach proof enumeration even single example potentially exponential size
theory. Another problem approach unable handle negated internal
literals, restricted situations example must belong one one class.
problems suggest would worthwhile circumvent proof enumeration
employing incremental numerical schemes focusing blame specific elements.
completely different approach revision problem based use neural
networks (KBANN, Towell & Shavlik, 1993). idea transform original domain theory
network form, assigning weights graph according pre-established scheme.
connection weights adjusted accordance observed examples using
standard neural-network backpropagation techniques. resulting network translated
back clausal form. main disadvantage method lacks representational
transparency; neural network representation preserve structure original
knowledge base revising it. result, great deal structural information may lost
translating back forth representations. Moreover, translation imposes
limitations representations; example, since neural networks typically slow
converge, method practical shallow domain theories. Finally, revised domain
theories obtained via translation neural networks tend significantly larger
corresponding original domain theories.
160

fiBIAS DRIVEN REVISION

approaches theory revision much less closely related approach
espouse RTLS (Ginsberg, 1990), KR-FOCL (Pazzani & Brunk, 1991),
ODYSSEUS (Wilkins, 1988).
1.2. Probabilistic Theory Revision
Probabilistic Theory Revision (PTR) new approach theory revision combines
best features two approaches discussed above. starting point PTR
observation method choosing among several possible revisions based
implicit bias, namely priori probability element (clause literal) domain
theory requires revision.
PTR bias made explicit right start. is, element theory
assigned priori probability flawed. probabilities might assigned
expert simply chosen default.
mere existence probabilities solves two central problems once. First,
probabilities naturally define best (i.e., probable) revision given set
possible revisions. Thus, objective well-defined; need impose artificial
syntactic semantic criteria identifying optimal revision. Second, probabilities
adjusted response newly-obtained information. Thus provide framework
incremental revision flawed domain theory.
Briefly, then, PTR algorithm uses set provided examples incrementally
adjust probabilities associated elements possibly-flawed domain theory order
find probable set revisions theory bring accord
examples.1 Like KBANN, PTR incrementally adjusts weights associated domain theory
elements; like EITHER, stages PTR carried within symbolic logic framework
obtained theories probabilistic.
result PTR following features:
(1)

handle broad range theories including negated internal literals
multiple roots.

(2)

linear size theory times number given examples.

(3)

produces relatively small, accurate theories retain much structure
original theory.

(4)

exploit additional user-provided bias.

next section paper formally define theory revision problem discuss
issues data representation. lay foundations future approach theory revision
introducing sharply defined terminology notation. Section 3 propose
efficient algorithm finding flawed elements theory, Section 4 show
revise elements. Section 5 describes two components combined form
PTR algorithm. Section 5, also discuss termination convergence properties PTR
walk simple example PTR action. Section 6 experimentally evaluate
PTR compare theory revision algorithms. Section 7, sum results
1

following section make precise notion probable set revisions.

161

fiKOPPEL, FELDMAN, & SEGRE

indicate directions research.
formal presentation work described is, unfortunately, necessarily dense.
aid casual reader, moved formal proofs three separate appendices.
particular, third appendix prove that, appropriate conditions, PTR converges.
Reading appendices safely postponed rest paper
read. addition, provide Appendix D, quick reference guide notation used
throughout paper. would suggest casual reader might prefer focus
Section 2, followed cursory reading Sections 3 4, thorough reading
Section 5.

2. Representing Problem
propositional domain theory, denoted , stratified set clauses form C : H Bi
C clause label, H proposition (called head C ) Bi set positive
negative literals (called body C ). usual, clause C : H Bi represents
assertion proposition H implied conjunction literals Bi . domain theory
simply conjunction clauses. may convenient think propositional
logic program without facts (but negation allowed).
proposition appear head clause said observable.
proposition appears head clause appear body
clause called root. example, E, truth assignment observable propositions.
convenient think E set true observable propositions.
Let domain theory roots r 1 , . . . , r n . example, E, define vector
(E) = 1 (E), . . . , n (E) (E) = 1 E | r (using resolution) (E) = 0
E |/ r . Intuitively, (E) tells us conclusions r 1 , . . . , r n drawn expert
system given truth assignment E.
Let target domain theory, , domain theory accurately models domain
interest. words, represents correct domain theory. ordered pair, E, (E) ,
called exemplar domain: (E) = 1 exemplar said exemplar
r , (E) = 0 exemplar said exemplar r . Typically,
theory revision, know (E) without knowing .
Let possibly incorrect theory domain turn correctly modeled
target theory . inaccuracies reflected exemplars (E) (E).
exemplars said misclassified . Thus, misclassified exemplar r , false
negative r , (E) = 1 (E) = 0, misclassified exemplar r ,
false positive r , (E) = 0 (E) = 1.2 Typically, theory revision know
(E) without knowing .
Consider, example, domain theory, , example set introduced Section 1.
theory single root, buy-stock. observable propositions mentioned
examples popular-product, unsafe-packaging, established-market, new-market, celebrity2

prefer new terminology IN/OUT standard positive/negative latter often used refer classification example given theory, use IN/OUT
refer specifically actual classification example.

162

fiBIAS DRIVEN REVISION

endorsement,
superior-flavor,

ecologically-correct.


example
E = {unsafe-packaging, new-market} (E) = 1 (E) = 0 . Nevertheless, told
(E) = 1 (E) = 1 . Thus, E = {unsafe-packaging, new-market}, 1

misclassified exemplar root buy-stock.
Now, given misclassified exemplars, four revision operators available use
propositional domain theories:
(1)

add literal existing clause,

(2)

delete existing clause,

(3)

add new clause,

(4)

delete literal existing clause.

negation-free domain theories, first two operations result specializing , since may
allow exemplars become exemplars. latter two operations result
generalizing , since may allow exemplars become exemplars.3
say set revisions adequate set exemplars if, revision
operators applied, exemplars correctly classified revised domain theory .
Note implying identical , rather every exemplar
E, (E) , (E) = (E). Thus, may one adequate revision set. goal
theory revision system, then, find best revision set , adequate
given set exemplars.
2.1. Domain Theories Graphs
order define problem even precisely set stage solution,
show represent domain theory form weighted digraph. begin defining
general version standard ANDOR proof tree, collapses distinction
nodes nodes.
set propositions {P 1 , . . . , P n }, let NAND({P 1 , . . . , P n }) Boolean formula
false {P 1 , . . . , P n } true. domain theory translated
equivalent domain theory consisting NAND equations follows:
(1)

clause C : H Bi , equation C = NAND(Bi ) .

(2)

non-observable proposition P appearing equation P = NAND(C P )
, C P = {C H = P}, i.e., set consisting label clause whose
head P.

(3)

negative literal P appearing , equation P = NAND({P}) .

contains equations these. Observe literals literals
together new literals {C } correspond clauses . important,
equivalent sense literal l assignment E truth values
observable propositions , E | l E | l.
3

event negative literals appear domain theory, consequences applying
operators slightly less obvious. made precise second part section.

163

fiKOPPEL, FELDMAN, & SEGRE

Consider, example, domain theory Section 1. set NAND equations
buy-stock = NAND({C 1 }),
C 1 = NAND({increased-demand, product-liability}),
product-liability = NAND({product-liability}),
increased-demand = NAND({C 3 , C 4 }),
product-liability = NAND({C 2 }),
C 2 = NAND({popular-product, unsafe-packaging}),
C 3 = NAND({popular-product, established-market}),
C 4 = NAND({new-market, superior-flavor}).
Observe buy-stock true precisely truth assignments observables
buy-stock true .
use obtain useful graph representation . equation , let h(i )
refer left side let b(i ) refer set literals appear right side
. words, h(i ) = NAND(b(i )).
Definition: dt-graph domain theory consists set nodes
correspond literals set directed edges corresponding set
ordered pairs { x, x = h(i ), b(i ), }. addition, root
r add edge, er , leading r (from artificial node).
words, consists edges literal antecedents. dtgraph representation shown Figure 1.
Let n e node edge e leads let n e node comes.
n e clause, say e clause edge; n e root, say e root edge;
n e literal n e clause, say e literal edge; n e proposition n e
negation, say e negation edge.
dt-graph much like ANDOR graph . has, however, significant
advantage ANDOR graphs collapses distinction clause edges
literal edges central ANDOR graph representation. fact, even negation edges
(which appear ANDOR representation) distinguished literal edges
clause edges dt-graph representation.
terms dt-graph , two basic revision operators deleting edges adding
edges. effects adding deleting edges ? length every path
root r node n even (odd) n said even (odd) node r . n e even (odd)
r , e said even (odd) r . (Of course possible depth edge
neither even odd.) Deleting even edge r specializes definitions r sense
result deletion, (E) (E) exemplars E, (E) ; likewise,
adding even edge r generalizes definition r sense result
adding edge (E) (E). Analogously, deleting odd edge r generalizes
definition r , adding odd edge r specializes definition r . (Deleting
adding edge neither odd even r might result new definition r
neither strictly general strictly specific.)
understand intuitively, first consider case negation edges
. even edge represents clause , deleting specialization adding
generalization. odd edge represents literal body clause
deleting generalization adding specialization. Now, odd number negation edges
164

fiBIAS DRIVEN REVISION

buy-stock

C1

increased-demand

product-liability

C4

new-market

C3

product-liability

established-market
superior-flavor

C2

popular-product
unsafe-packaging

Figure 1: dt-graph, , theory .

present path r edge role edge reversed.
2.2. Weighted Graphs
weighted dt-graph ordered pair , w dt-graph w assignment
values (0, 1] node edge . edge e, w(e) meant represent
users degree confidence edge e need deleted obtain correct domain
theory. node n, w(n) users degree confidence edge leading node
n need added order obtain correct domain theory. Thus, example, assignment
w(n) = 1 means certain edge need added node n assignment
w(e) means certain e deleted. Observe node n labeled
negative literal observable proposition w(n) = 1 definition, since graphs obtained
adding edges nodes correspond domain theory. Likewise, e rootedge negation-edge, w(e) = 1.
165

fiKOPPEL, FELDMAN, & SEGRE

practical reasons, conflate weight w(e) edge e weight, w(n e ),
node n e , single value, p(e) = w(e) w(n e ), associated edge e. value p(e)
users confidence e need repaired, either deletion dilution via addition
child edges.
many ways values assigned. Ideally, provided
expert actually reflect experts degree confidence element
theory. However, even absence information, values assigned default;
example, elements assigned equal value. sophisticated method assigning
values assign higher values elements greater semantic impact (e.g.,
closer roots). details one method given Appendix A. also,
course, possible expert assign weights rest assigned according
default scheme. example, weighted dt-graph, , p , shown Figure 2,
edges assigned weight near 1 others assigned weights according
simple default scheme.
semantics values associated edges made clear considering
case known correct dt-graph subset given dt-graph, . Consider
probability function space subgraphs . weight edge simply sum
probabilities subgraphs edge appears. Thus weight edge
probability edge indeed appear target dt-graph. easily extend
case target dt-graph necessarily subgraph given one.4
Conversely, given probabilities associated edges assuming deletion
different edges independent events, compute probability subgraph, .
Since p(e) probability e deleted 1 p(e) probability e deleted,
follows
p() =



e

p(e)



e

1 p(e).

Letting = , rewrite
p() =



e

p(e)



e

1 p(e).

use formula basis assigning value dt-graph obtainable via
revision set edges S, even case edge-independence hold even
case subset . simply define
w() =



e

p(e)



e

1 p(e).

(In event uniquely defined, choose w()
maximized.) Note independence holds subgraph ,
4

order avoid confusion emphasized meaning weights associated
edges completely different associated edges Pearls Bayesian networks (1988). us,
weights represent meta-domain-theory concept: probability edge appears unknown target domain theory. Pearl represent conditional probabilities within probabilistic domain theory. Thus, updating method introduce totally unrelated Pearl.

166

fiBIAS DRIVEN REVISION

.999
buy-stock
.99
C1
1.0

.95

increased-demand
.9

product-liabilty
.9

C4
.8
new-market

.9
C3

.8

product-liability
.8

.8

.9

established-market
superior-flavor

C2
.8

.99

popular-product
unsafe-packaging

Figure 2: weighted dt-graph, , p .

w() = p().
2.3. Objectives Theory Revision
formally define proper objective theory revision algorithm:
Given weighted dt-graph , p set exemplars , find dt-graph
correctly classifies every exemplar w() maximal dt-graphs.
Restating terminology information theory, define radicality dt-graph
relative initial weighted dt-graph = , p
Rad () =



e

log( p(e)) +



e

log(1 p(e))

set edges need revised order obtain . Thus given
weighted dt-graph set exemplars , wish find least radical dt-graph relative
167

fiKOPPEL, FELDMAN, & SEGRE

correctly classifies set exemplars .
Note radicality straightforward measure quality revision set neatly
balances syntactic semantic considerations. often noted minimizing syntactic
change alone lead counter-intuitive results giving preference changes near root
radically alter semantics theory. hand, regardless distribution
examples, minimizing semantic change alone results simply appending domain theory
correct classifications given misclassified examples without affecting classification
examples.
Minimizing radicality automatically takes account criteria. Thus, example,
assigning higher initial weights edges greater semantic impact (as default
scheme Appendix A), syntactic advantage revising close root offset
higher cost revisions. example, suppose given theory introduction
single misclassified exemplar
{unsafe-packaging, new-market}, 1 .
several possible revisions would bring accord exemplar.
could, example, add new clause
buy-stock unsafe-packaging new-market,
delete superior-flavor clause C4, delete popular-product established-market clause
C3, delete increased-demand clause C1. Given weights Figure 2, deletion
superior-flavor clause C4 clearly least radical revision.
Observe special case edges assigned identical initial weights,
regardless semantic strength, minimization radicality indeed reduce form
minimization syntactic change. wish point out, however, even case
definition syntactic change differs previous definitions (Wogulis &
Pazzani, 1993). Whereas definitions count number deleted added edges,
count number edges deleted added to. understand preferable, consider
case internal literal, happens large definition, omitted one
clause target theory. Methods count number added edges
strongly biased restoring literal, prefering instead make several different repairs
collectively involve fewer edges make single repair involving edges.
Nevertheless, given assumption probabilities various edges given theory
mistaken equal, far intuitive repair single edge, PTR does. (We
agree, though, edge chosen repair, chosen repair minimal
equally effective repairs.)

3. Finding Flawed Elements
PTR algorithm finds adequate set revisions approximately minimum
radicality. achieves locating flawed edges repairing them. section
give algorithm locating flawed edges; next section show repair them.
underlying principle locating flawed edges process exemplars one time,
case updating weights associated edges accordance information
contained exemplars. measure flow proof (or refutation) edges
graph. edge contributes correct classification example,
weight raised; contributes misclassification example,
168

fiBIAS DRIVEN REVISION

weight lowered. weight edge drops prespecified revision threshold ,
revised.
core algorithm method updating weights. Recall weight
represents probability edge appears target domain theory. natural way
update weights, then, replace probability edge need revised
conditional probability need revised given classification exemplar.
shall see later, computation conditional probabilities ensures many desirable properties
updating ad hoc methods liable miss.
3.1. Processing Single Exemplar
One important results paper certain conditions conditional
probabilities edges graph computed single bottom-up-then-top-down
sweep dt-graph. shall employ method computation even
conditions hold. way, updating performed highly efficient fashion while,
time, retaining relevant desirable properties conditional probabilities.
precisely, algorithm proceeds follows. think nodes
represent observable propositions input nodes, think values assigned
example E observable proposition inputs. Recall assignment weights
edges associated implicit assignment probabilities various dt-graphs obtainable
via revision . dt-graphs, root r provable example E,
others not. wish make bottom-up pass = , p order compute
(or least approximate) root r , probability target domain theory
r true example E. obtained probability compared desired
result, (E), resulting difference used basis adjusting weights, w(e),
edge e.
Let
1 P true E
E(P) =
0 P false E.
say node n true literal labels true. Now, node passes
value true graph either true deleted, i.e., undeleted false.
Thus, edge e n e observable proposition P, value
u E (e) = 1 [ p(e) (1 E(P))] probability value true passed graph
e.5
Now, recalling node represents NAND operation, truth node
independent truth brothers, edge e, probability true
passed graph

5

Note that, principle, updating performed exactly way even 0 < E(P) < 1.
Thus, algorithm extends naturally case uncertainty regarding truth-value
observable propositions.

169

fiKOPPEL, FELDMAN, & SEGRE

u E (e) = 1 p(e)



children(e)

u E (s).

call u E (e) flow E e.
defined flow u E (e) that, appropriate independence conditions,
node n e , u E (e) fact probability n e true given , w E. (For formal proof
this, see Appendix B.) particular, root r , flow u E (er ) is, even absence
independence conditions, good approximation probability target theory
r true given , w E.
second stage updating algorithm, propagate difference
computed value u E (er ) (which lies somewhere 0 1) target value (E)
(which either 0 1) top-down process similar backpropagation neural
networks. proceed, compute new value v E (e) well updated value p(e),
every edge e . new value v E (e) represents updating u E (e) correct
classification, (E), example E taken account.
Thus, begin setting value v E (r ) reflect correct classification
example. Let > 0 small constant6 let

(E) = 0
v E (er ) =
1


(E) = 1.

proceed top , computing v E (e) edge . case
compute v E (e) basis u E (e), is, basis much proof (or refutation)
E flows edge e. precise formula
v E (e) = 1 (1 u E (e))

v E ( f (e))
u E ( f (e))


max[v E ( f (e)), u E ( f (e))]
f (e) parent e 1
greatest. show
min[v
(
f
(e)),
u
(
f
(e))]
E
E


Appendix B formula works.
Finally, compute p new (e), new values p(e), using current value p(e)
values v E (e) u E (e) computed:
p new (e) = 1 (1 p(e))

v E (e)
.
u E (e)

deletion different edges independent events known subgraph
, p new (e) conditional probability edge e appears , given exemplar
E, (E) (see proof Appendix B). Figure 3 gives pseudo code processing single
exemplar.

Strictly speaking, computation conditional probabilities, need use = 0. However,
order ensure convergence algorithm cases, choose > 0 (see Appendix C). experiments reported Section 6, use value = . 01.
6

170

fiBIAS DRIVEN REVISION

function BottomUp( , p : weighted dt-graph, E: exemplar): array real;
begin
; V Leaves();
e Leaves()
begin
e E u(e) 1;
else u(e) 1 p(e);
Merge(S, Parents(e, ));
end

begin
e PopSuitableParent(S, V ); V AddElement(e, V );
u(e) 1 ( p(e)
u(d));
Children(e,)

Merge(S, Parents(e, ));
end
return u;
end

function TopDown( , p : weighted dt-graph, u: array real,
E: exemplar, : real): weighted dt-graph;
begin
; V Roots();
r Roots()
begin
(E) = 1 v(r ) ;
else v(r ) 1 ;
Merge(S, Children(r , ));
end

begin
e PopSuitableChild(S, V ); V AddElement(e, V ); f MostChangedParent(e, );
v( f )
v(e) 1 (1 u(e))
;
u( f )
v(e)
p(e) 1 (1 p(e))
;
u(e)
Merge(S, Children(e, ));
end
return , p ;
end
Figure 3: Pseudo code processing single exemplar. functions BottomUp TopDown
sweep dt-graph. BottomUp returns array edges representing proof flow, TopDown
returns updated weighted dt-graph. assuming dt-graph datastructure defined initialized appropriately. Functions Children, Parents, Roots, Leaves return sets
edges corresponding corresponding graph relation dt-graph. Function Merge AddElement operate sets, functions PopSuitableParent PopSuitableChild return element first argument whose children parents, respectively, already elements
second argument simultaneously deleting element first set, thus guaranteeing
appropriate graph traversal strategy.

171

fiKOPPEL, FELDMAN, & SEGRE

Consider application updating algorithm weighted dt-graph Figure 2.
given exemplar {unsafe-packaging, new-market}, 1 , i.e., example
unsafe-packaging new-market true (and observables false) yield
derivation root buy-stock. weighted dt-graph obtained applying algorithm
shown Figure 4.
example illustrates important general properties method.
(1)

Given exemplar, weight odd edge cannot decrease weight
even edge cannot increase. (The analogous property holds exemplar.)
case negation edge appears , corresponds fact clause
cannot help prevent proof, literals body clause cannot help complete

.998
buy-stock
.999
C1
.94

1.0
increased-demand
.98

product-liability
.91

C4
.8
new-market

1.0
C3

.15

product-liability
.69

.69

.88

established-market
superior-flavor

C2
.96

.99

popular-product
unsafe-packaging

Figure 4: weighted dt-graph
{unsafe-packaging, new-market}, 1 .

Figure

172

2



processing



exemplar

fiBIAS DRIVEN REVISION

proof. Note particular weights edges corresponding literals
popular-product established-market clause C3 dropped amount,
reflecting identical roles played example. However, weight
edge corresponding literal superior-flavor clause C4 drops great deal
edges, reflecting fact deletion superior-flavor alone would allow
proof buy-stock, deletion either popular-product alone establishedmarket alone would allow proof buy-stock.
(2)

edge initial weight 1 immutable; weight remains 1 forever. Thus although
edge weight 1, corresponding literal increased-demand clause
C1, may contribute prevention desired proof, weight diminished since
told possibility literal flawed.

(3)

processed exemplar correctly classified particular edge e revised,
updated probability e approach 0 e immediately revised.7
Thus, example, initial weights edge corresponding establishedmarket popular-product C3 approach 1, weight edge corresponding
superior-flavor C4 would approach 0. Since use weights temporary
device locating flawed elements, property renders updating method
appropriate purposes standard backpropagation techniques adjust
weights gradually ensure convergence.

(4)

computational complexity processing single exemplar linear size
theory . Thus, updating algorithm quite efficient compared revision
techniques rely enumerating proofs root. Note
computation required update weight identical every edge regardless
edge type. Thus, PTR well suited mapping onto fine-grained SIMD machines.

3.2. Processing Multiple Exemplars
stated above, updating method applied iteratively one example time (in random
order) edge drops revision threshold, . complete cycle edge
dropped revision threshold, examples reordered (randomly)
updating continued.8
example, consider weighted dt-graph Figure 2. processing exemplars
{unsafe-packaging, new-market}, 1 ,
{popular-product, established-market, superior-flavor}, 0 ,
{popular-product, established-market, celebrity-endorsement}, 0
obtain dt-graph shown Figure 5. threshold is, say, = . 1, revise
edge corresponding clause C3. reflects fact clause C3 contributed
7

choose = 0 definition v E (er ), updated probability would equal 0.

8

course, processing examples one time abandon pretense algorithm
Bayesian. respect, proceeding spirit connectionist learning algorithms
assumed sequential processing examples random order, actually independent,
approximates collective effect examples.

173

fiKOPPEL, FELDMAN, & SEGRE

.999...
buy-stock
.998
C1
.95

1.0
increased-demand
.98

product-liability
.02

C4
.99
new-market

1.0
product-liability

C3
.15

.69

.69

established-market
superior-flavor

.89
C2
.96

.88

popular-product
unsafe-packaging

Figure 5: weighted dt-graph Figure 2 processing exemplars
{unsafe-packaging, new-market}, 1 ,
{popular-product, established-market, superior-flavor}, 0 ,
{popular-product, established-market, celebrity-endorsement}, 0 .
clause C3 dropped threshold.

substantially misclassification second third examples list
contributing substantially correct classification first.

4. Revising Flawed Edge
edge selected revision, must decide revise it. Recall p(e)
represents product w(e) w(n e ). Thus, drop p(e) indicates either e needs
deleted that, less dramatically, subtree needs appended node n e . Thus, need
determine whether delete edge completely simply weaken adding children;
intuitively, adding edges clause node weakens clause adding conditions body,
174

fiBIAS DRIVEN REVISION

adding edges proposition node weakens propositions refutation power adding
clauses definition. Further, decide add children, need determine
children add.
4.1. Finding Relevant Exemplars
first stage making determination consists establishing, exemplar, role
edge enabling preventing derivation root. specifically,
exemplar, E, (E) , root, r, edge e might play positive role facilitating proof
r, play destructive role preventing proof r, may simply irrelevant proof
r.
sets exemplars e plays positive role destructive role
determined, possible append e appropriate subtree effectively redefines
role e used exemplars plays positive role.9 How,
then, measure role e allowing preventing proof r E?
first glance, would appear sufficient compare graph graph e
results deleting e . E | r E |/ e r (or vice versa) clear e
responsible r provable provable given exemplar E, (E) . But,
criterion rigid. case exemplar, even case E |/ e r, still
necessary modify e event e allowed additional proof r E. And,
case exemplar, even case E | r still necessary modify e
way prevent proof r E, since ultimately proof needed.
Fortunately, weights assigned edges allow us flexibility merely determine
whether proof r E given e also measure numerically flow
E r without e. needed design simple heuristic
captures degree e contributes proof r E.
Let = , p weighted dt-graph revised. Let e = , p p
identical p, except p(e) = 1. Let e = , p p identical p, except
p(e) = 0; is, e obtained deleting edge e.
define root r
1 (E) ue (e )

ri
E

Ri ( E, (E) , e, ) =
.
1 (E) ue (e )

r
E



Ri ( E, (E) , e, ) > 2, say e needed E r
Ri ( E, (E) , e, ) < 1/2 say e destructive E r .
9

PTR strictly incremental sense edge revised role proving refuting exemplar checked. strict incrementality desideratum, PTR slightly modified
edge revised basis exemplars already processed. Moreover,
generally necessary check exemplars relevance. example, e odd edge E
correctly classified exemplar, e neither needed E (since odd edges make
derivations difficult) destructive E (since E correctly classified despite e).

175

fiKOPPEL, FELDMAN, & SEGRE

Intuitively, means, example, edge e needed exemplar, E, r ,
derivation r E passes edge e. simply given formal
definition notion derivation passes e, namely, flow,


u E e (er ), E r without e less half flow, u E e (er ), E r e.
negation-free theories, corresponds case edge e represents clause
critical derivation r E. intuition destructive edges
exemplars analogous. Figure 6 gives pseudo code computing needed destructive
sets given edge e exemplar set .
order understand better, let us return example dt-graph state
left Figure 5. edge corresponding clause C3 dropped
threshold. let us check exemplars edge needed
destructive. Computing R( E, (E) , C3, ) example E obtain following:
R( {popular-product, unsafe-packaging, established-market}, 0 , C3, ) = 0. 8
R( {unsafe-packaging, new-market}, 1 , C3, ) = 1. 0
R( {popular-product, established-market, celebrity-endorsement}, 1 , C3, ) = 136. 1
R( {popular-product, established-market, superior-flavor}, 0 , C3, ) = 0. 1
R( {popular-product, established-market, ecologically-correct}, 0 , C3, ) = 0. 1
R( {new-market, celebrity-endorsement}, 1 , C3, ) = 1. 0
function Relevance( , p : weighted dt-graph , : exemplar set, e: edge): tuple set;
begin
N ;
;
p saved Copy( p);
E
r Roots()

p(e) 1; u BottomUp(, p, E); u E e u(r ); p p saved ;

p(e) 0; u BottomUp(, p, E); u E e u(r ); p p saved ;
e
u
(E) = 1 Ri E e ;
uE

1 uEe
else Ri
;

1 uEe
Ri > 2 N N {E};
1
Ri < {E};
2
end
end
return N , ;
end
Figure 6: Pseudo code computing relevant sets (i.e., needed destructive sets)
given edge e exemplar set . general idea compare proof flow (computed using
function BottomUp) without edge question exemplar exemplar
set. Note original weights saved later restored end computation.

176

fiBIAS DRIVEN REVISION

high value
R( {popular-product, established-market, celebrity-endorsement}, 1 , C3, )
reflects fact without clause C3, scant hope derivation buy-stock
example. (Of course, principle, new-market superior-flavor might still deleted
body clause C4, thus obviating need C3, high weight associated
literal new-market C4 indicates unlikely.) low values
R( {popular-product, established-market, superior-flavor}, 0 , C3, )
R( {popular-product, established-market, ecologically-correct}, 0 , C3, )
reflect fact eliminating clause C3 would greatly diminish currently undesirably
high flow buy-stock (i.e., probability derivation buy-stock)
examples.
interesting case examine
{popular-product, unsafe-packaging, established-market}, 0 .
true elimination C3 helpful preventing unwanted derivation buy-stock
prevents derivation increased-demand necessary buy-stock clause
C1. Nevertheless, R correctly reflects fact clause C3 destructive
exemplar since even presence C3, buy-stock derivable due failure
literal product-liability.
4.2. Appending Subtree
Let N set examples e needed root let set examples
e destructive root (and needed root). found
sets N D, repair e?
point, set non-empty set N empty, simply delete edge
. justify deletion noting exemplars require e, deletion
compromise performance theory. hand, N empty, apply
inductive algorithm10 produce disjunctive normal form (DNF) logical expression constructed
observable propositions true exemplar exemplar N .
reformulate DNF expression conjunction clauses taking single new literal l
head clause, using conjunct DNF expression body one
clauses. set clauses converted dt-graph n l root. suture n e
adding new node t, edge e t, another edge root, l, n .
order understand works, first note important fact (like every
subroutine PTR), method essentially identical whether edge, e, repaired
clause edge, literal edge negation edge. However, translating back dt-graph form
domain theory form, new node interpreted differently depending whether n e
clause literal. n e literal, interpreted clause n e l. n e clause,
10

standard algorithm constructing decision trees positive negative examples
used. implementation PTR uses ID3 (Quinlan, 1986). use inductive component add
new substructure due Ourston Mooney (Ourston & Mooney, press).

177

fiKOPPEL, FELDMAN, & SEGRE

interpreted negative literal l.11
plain exemplars e destructive use graph rooted
overcome effect e. n e literal undesirably excludes E, E get n e
satisfying clause t; n e clause undesirably allows E, E stopped
function Revise( , p : weighted dt-graph , : set exemplars, e: edge, : real): weighted dt-graph;
begin
N , Relevance( , p , , e);

begin
N = p(e) 0;
else
begin
p(e) ;
l NewLiteral();
ID3 = DTGraph(l, DNF-ID3(D, N ));
NewNode(); AddNode(, t);
Clause?(n e ) Label(t) l;
else Label(t) NewClause();
AddEdge(, n e , ); p( n e , ) ;
AddEdge(, t, Root( ID3 ) ); p( t, Root( ID3 ) ) 1;
ID3 ; e ID3 p(e) 1;
end
end
return , p ;
end
Figure 7: Pseudo code performing revision. function Revise takes dt-graph, set exemplars , edge revised e, parameter inputs produces revised dt-graph
output. function DNF-ID3 inductive learning algorithm produces DNF formula
accepts elements N , function DTGraph produces dt-graph
given root given DNF expression described text. sake expository simplicity, shown special cases n e leaf e negation edge, discussed Footnote 11.

11

course, willing sacrifice elegance, could allow separate sub-routines
clause case literal case. would allow us make dt-graphs sutured considerably
compact. particular, n e literal could suture children l n directly n e . n e
clause, could use inductive algorithm find DNF expression excludes examples
includes N (rather way around it). Translating expression dtgraph root l, could suture n simply adding edge clause n e root l.
Moreover, n represents single clause l l 1 , . . . , l simply suture leaf-nodes
l 1 , . . . , l directly n e . Note n e leaf negative literal, inappropriate append child
edges n e . cases, simply replace n e new literal l append l n graph
clause l n e .

178

fiBIAS DRIVEN REVISION

new literal = l.
Whenever graph n sutured , must assign weights edges n . Unlike
original domain theory, however, new substructure really artifact inductive
algorithm used current relevant exemplar set. reason, almost certainly
inadvisable try revise new exemplars encountered. Instead, would prefer
new structure removed replaced appropriate new construct
need arise. ensure replacement instead revision, assign unit certainty factors edges
substructure. Since internal edges new structure weights equal 1,
never revised. Finally, assign default weight substructure root edge n e , ,
connects new component existing reset weight revised edge,
e, value . Figure 7 gives pseudo code performing revision step
described.
Consider example above. repairing clause C3. already found
set consists examples
{popular-product, established-market, superior-flavor}
{popular-product, established-market, ecologically-correct}
set N consists single example
{popular-product, established-market, celebrity-endorsement}.
Using ID3 find formula excludes N includes D, obtain { celebrityendorsement} translates single clause, {l celebrity-endorsement}. Translating
dt-graph form suturing (and simplifying using technique Footnote 11), obtain
dt-graph shown Figure 8.
Observe domain theory represented dt-graph correctly classifies
examples
{popular-product, established-market, superior-flavor}
{popular-product, established-market, ecologically-correct}
misclassified original domain theory .

5. PTR Algorithm
section give details control algorithm puts pieces previous
two sections together determines termination.
5.1. Control
PTR algorithm shown Figure 9. briefly summarize operation follows:
(1)

PTR process exemplars random order, updating weights performing revisions
necessary.

(2)

Whenever revision made, domain theory corresponds newly revised
graph checked exemplars.

(3)

PTR terminates if:
(i) exemplars correctly classified,
(ii) Every edge newly revised graph weight 1.

179

fiKOPPEL, FELDMAN, & SEGRE

.999...
buy-stock
.998
C1
.95

1.0
increased-demand

product-liability
.70

.98

1.0

C4
.99
new-market

C3
.15

.69

.70

product-liability
.69

established-market
celebrity-endorsement
superior-flavor

.89
C2
.96

.88

popular-product
unsafe-packaging

Figure 8: weighted dt-graph Figure 2 revising clause C3 (the graph
slightly simplified accordance remark Footnote 11).

(4)

If, revision made, PTR terminate, continues processing
exemplars random order.

(5)

if, complete cycle exemplars processed, remain misclassified
exemplars,
(i) Increment revision threshold = min[ + , 1],
(ii) Increment value assigned revised edge root edge added
component, = min[ + , 1].

(6)

begin anew, processing exemplars (new) random order.

easy see PTR guaranteed terminate. argument follows. Within
1 1
max , cycles, reach 1. point, every edge weight less

180

fiBIAS DRIVEN REVISION

1 revised either deleted weight reset = 1. Moreover, edges
added revision also assigned certainty factor = 1. Thus edges weight
1 algorithm terminates termination criterion (ii).
Now, wish show PTR terminates, terminates every
exemplar correctly classified. is, wish show that, fact, termination criterion (ii)
never satisfied unless termination criterion (i) satisfied well. call property
convergence. Appendix C prove that, certain general conditions, PTR
guaranteed converge.
5.2. Complete Example
Let us review example considering throughout paper.
begin flawed domain theory set exemplars introduced Section 1.
C1: buy-stock increased-demand product-liability
C2: product-liability popular-product unsafe-packaging
C3: increased-demand popular-product established-market
C4: increased-demand new-market superior-flavor.
translate domain theory weighted dt-graph , p Figure 2, assigning
weights via combination user-provided information default values. example, user
indicated confidence first literal (increased-demand) body clause C1
greater confidence second literal ( product-liability).
function PTR( , p : weighted dt-graph, : set exemplars,
0 , 0 , , , : five tuple real): weighted dt-graph;
begin
0;
0;
E (E) (E)
begin
E RandomlyPermute()
begin
u BottomUp( , p , E);
, p TopDown( , p , u, E, );
e p(e) , p Revise( , p , , , );
e , p(e) = 1 E , (E) = (E) return , p ;
end
max[ + , 1];
max[ + , 1];
end
end
Figure 9: PTR control algorithm. Input algorithm consists weighted dt-graph
, p , set exemplars , five real-valued parameters 0 , 0 , , , . algorithm
produces revised weighted dt-graph whose implicit theory correctly classifies exemplars .

181

fiKOPPEL, FELDMAN, & SEGRE

set revision threshold .1, reset value initially .7 respective
increments . 03. start updating weights edges processing
exemplars random order.
first process exemplar
{unsafe-packaging, new-market}, 1 .
First, leaves dt-graph labeled according presence absence exemplar.
Second, u E (e) values (proof flow) computed edges dt-graph bottom
fashion. Next, v E (er ) values set reflect vector correct classifications example
(E). New values v E (e) computed top fashion edge dt-graph.
values computed, new values p(e) also computed. Processing first
exemplar produces updated dt-graph shown Figure 3.
Processing exemplars continues either edge weight falls (indicating
flawed domain theory element located), cycle (processing known exemplars)
completed, PTR termination conditions met. example, processing
additional exemplars
{popular-product, established-market, superior-flavor}, 0
{popular-product, established-market, ecologically-correct}, 0
weight edge corresponding clause C3 drops (see Figure 5), indicating
edge needs revised.
proceed revision using heuristic Section 4.2 order determine
set exemplars edge question needed destructive. edge
corresponding clause C3 needed
{ {popular-product, established-market, celebrity-endorsement}, 1 }
destructive
{ {popular-product, established-market, ecologically-correct}, 0 ,
{popular-product, established-market, superior-flavor}, 0 }.
Since set edge needed empty, PTR chooses append subtree
weakening clause C3 rather simply deleting clause outright. Using sets input
ID3, determine fact celebrity-endorsement suitably discriminates needed
destructive sets. repair graph obtain weighted dt-graph shown Figure 8.
graph corresponds theory literal celebrity-endorsement added
body C3.
check newly-obtained theory embodied dt-graph Figure 8 (i.e., ignoring
weights) exemplars determine still misclassified exemplars,
namely
{unsafe-packaging, new-market}, 1
{new-market, celebrity-endorsement}, 1 .
Thus, continue processing remaining exemplars original (random) order.
processing exemplars
{popular-product, unsafe-packaging, established-market}, 0 ,
{popular-product, established-market, celebrity-endorsement}, 1 ,
{new-market, celebrity-endorsement}, 1 ,
182

fiBIAS DRIVEN REVISION

weight edge corresponding literal superior-flavor clause C4 drops
revision threshold . determine edge needed exemplar thus
edge simply deleted.
point, misclassified exemplars remain. final domain theory is:
C1: buy-stock increased-demand product-liability
C2: product-liability popular-product unsafe-packaging
C3: increased-demand popular-product established-market celebrity-endorsement
C4: increased-demand new-market.
theory correctly classifies known exemplars PTR terminates.

6. Experimental Evaluation
section examine experimental evidence illustrates several fundamental
hypotheses concerning PTR. wish show that:
(1)

theories produced PTR high quality three respects: low radicality,
reasonable size, provide accurate information regarding exemplars
used training.

(2)

PTR converges rapidly is, requires cycles find adequate set
revisions.

(3)

well-chosen initial weights provided domain expert significantly improve
performance PTR.

precisely, given theory obtained using PTR revise theory basis
set training examplars, test hypotheses follows.
Radicality. claim Rad () typically close minimal theories
correctly classify examples. cases target theory, , known, measure
Rad ()
. value less 1, PTR said done even better
Rad ()
finding target theory sense able correctly classify training examples
using less radical revisions required restore target theory. value greater
1, PTR said over-revised theory.
Cross-validation. perform one hundred repetitions cross-validation using nested sets
training examples. noted actual objective minimize radicality,
often theories less radical target theory also satisfy
training examples. Thus, cross-validation gives indication theory revision
successfully performed, primary objective theory revision.
Theory size. count number clauses literals revised theory merely
demonstrate theories obtained using PTR comprehensible. course, precise size
theory obtained PTR largely artifact choice inductive component.
Complexity. Processing complete cycle exemplars O(n d) n number
edges graph number exemplars. Likewise repairing edge O(n d).
measure number cycles number repairs made convergence. (Recall
1 1
number cycles convergence event bounded max , .

show that, practice, number cycles small even = = 0.
183

fiKOPPEL, FELDMAN, & SEGRE

Utility Bias. wish show user-provided guidance choosing initial weights
leads faster accurate results. cases target theory, , known, let
set edges need revised order restore target theory . Define
1

1

/ S, p (e) = ( p(e)) .
p (e) e S, 1 p (e) = (1 p(e)) e
is, edge needs revised obtain intended theory initial weight
diminished edge need revised obtain intended theory weight
increased. Let = , p . Then, ,
1

Rad () = log( (1 p(e))
e

1

( p(e)) ) =

e
/

1


Rad ().

Here, compare results cross-validation number-of-cycles experiments = 2
unbiased counterparts (i.e., = 1).
6.1. Comparison Methods
order put results perspective compare results obtained
methods.12
(1)

ID3 (Quinlan, 1986) inductive component use PTR. Thus using ID3
equivalent learning directly examples without using initial flawed domain
theory. comparing results obtained using ID3 obtained using PTR
gauge usefulness given theory.

(2)

EITHER (Ourston & Mooney, press) uses enumeration partial proofs order find
minimal set literals, repair satisfy exemplars. Repairs
made using inductive component. EITHER exponential size
theory. cannot handle theories negated internal literals. also cannot handle
theories multiple roots unless roots mutually exclusive.

(3)

KBANN (Towell & Shavlik, 1993) translates symbolic domain theory neural net,
uses backpropagation adjust weights nets edges, translates back
net form partially symbolic form. rules theory output
KBANN might numerical, i.e., strictly symbolic.

(4)

RAPTURE (Mahoney & Mooney, 1993) uses variant backpropagation adjust
certainty factors probabilistic domain theory. necessary, also add clause
root. rules produced RAPTURE numerical. Like EITHER, RAPTURE
cannot handle negated internal literals multiple roots mutually exclusive.

Observe that, relative methods considered here, PTR liberal terms
theories handle, (like KBANN, unlike EITHER RAPTURE) handle
negated literals non-mutually exclusive multiple roots; also strict terms theories
yields (like EITHER, unlike KBANN RAPTURE) produces strictly symbolic
theories.
12

interesting theory revision algorithms, RTLS (Ginsberg, 1990),
comparable data available.

184

fiBIAS DRIVEN REVISION

noted KBANN RAPTURE output numerical rules. case
KBANN, numerical rule one fires sum weights associated satisfied
antecedents exceeds threshold. case RAPTURE, rules probabilistic rules using
certainty factors along lines MYCIN (Buchanan & Shortliffe, 1984). One might ask, then,
extent results obtained theory revision algorithms output numerical rules
merely artifacts use numerical rules? words, separate effects
using numerical rules effects learning?
make concrete, consider following simple method transforming
symbolic domain theory probabilistic domain theory reclassifying examples using
obtained probabilistic theory. Suppose given possibly-flawed domain theory .
Suppose given classification even single example. Assign weight
p(e) edge according default scheme Appendix A. Now, using bottomup subroutine updating algorithm, compute u E (er ) test example E. (Recall
u E (er ) measure close derivation r E is, given weighted dt-graph
, p .) Now, chosen cutoff value 0 n 100, E 0 u E 0 (er ) lies
upper n% set values {u E (er )} conclude true E 0 ; otherwise conclude
false E 0 .
method, purpose discussion call PTR*, use training
examples all. Thus results theory revision systems employ numerical rules
matched PTR* performs learning clear results merely
artifacts use numerical rules.
6.2. Results PROMOTER Theory
first consider PROMOTER theory molecular biology (Murphy & Aha, 1992),
interest solely extensively studied theory revision literature
(Towell & Shavlik, 1993), thus enabling explicit performance comparison algorithms.
PROMOTER theory flawed theory intended recognize promoters DNA nucleotides.
theory recognized none set 106 examples promoters despite fact precisely
half indeed promoters.13
Unfortunately, PROMOTER theory (like many others used theory revision
literature) trivial shallow. Moreover, atypical flawed domains
overly specific overly general. Given shortcomings PROMOTER theory,
also test PTR synthetically-generated theory errors artificially
introduced. synthetic theories significantly deeper used test previous
methods. Moreover, fact intended theory known enable us perform
experiments involving radicality bias.

13

experiments, use default initial weights assigned scheme Appendix A. addition, clause whose head proposition contact treated definition subject revision
deletion whole.

185

fiKOPPEL, FELDMAN, & SEGRE

6.2.1. Cross-validation
Figure 10 compare results cross-validation PROMOTER. distinguish
methods use numerical rules (top plot) purely symbolic
(bottom plot).
lower plot Figure 10 highlights fact that, using value n = 50, PTR* achieves
better accuracy, using training examples, methods considered achieve
using 90 training examples. particular, computing u E (er ) example, obtain
53 highest-ranking examples 50 indeed promoters (and, therefore, 53 lowestranking examples 50 indeed non-promoters). Thus, PTR* achieves 94. 3% accuracy. (In fact,
47 highest-ranking examples promoters 47 lowest-ranking
promoters. Thus, conservative version PTR* classifies the, say, 40% highestranking examples 40% lowest-ranking OUT, would indeed achieve 100%
accuracy examples ventured prediction.)
merely shows original PROMOTER theory accurate provided
given numerical interpretation. Thus conclude success RAPTURE KBANN
domain consequence learning examples rather artifact use
numerical rules.
three methods EITHER, PTR ID3 yield symbolic rules, see
top plot Figure 10 that, reported (Ourston & Mooney, press; Towell &
Shavlik, 1993), methods exploit given flawed theory indeed achieve better
results PROMOTER ID3, exploit theory. Moreover, size
training set grows, performance PTR increasingly better EITHER.14
Finally, wish point interesting fact example set. set 13
106 examples contain information substantially different
rest examples. Experiments show using ten-fold cross-validation 93 good
examples yields 99. 2% accuracy, training 93 examples testing 13
bad examples yields 40% accuracy.
6.2.2. Theory size
size output theory important measure comprehensibility output
theory. Ideally, size theory grow rapidly number training
examples increased, larger theories necessarily harder interpret. observation
holds number clauses theory well average number
antecedents clauses.
Theory sizes theories produced PTR shown Figure 11. striking
aspect numbers measures theory size relatively stable respect
training set size. Naturally, exact values large degree artifact inductive
learning component used. contrast, EITHER, theory size increases training set size
14

readers familiar PROMOTER theory note improvement EITHER consequence PTR repairing one flaw time using sharper relevance criterion.
results PTR always deleting extraneous conformation literal, EITHER occasionallly fails
so, particularly number training exmaple increases.

186

fiBIAS DRIVEN REVISION

60
% Misclassified
50

ID3
EITHER
PTR

40
30
20
10
0
0

20

40

60

60
% Misclassified
50

80
100
# Training Exemplars

RAPTURE
KBANN
PTR*

40
30
20
10
0
0

20

40

60

80
100
# Training Exemplars

Figure 10: PROMOTER: Error rates using nested training sets purely symbolic theories (top
plot) numeric theories (bottom plot). Results EITHER, RAPTURE, KBANN taken
(Mahoney & Mooney, 1993), results ID3 PTR generated using similar experimental procedures. Recall PTR* non-learning numerical rule system; PTR* line
extended horizontally clarity.

187

fiKOPPEL, FELDMAN, & SEGRE

Training
Set Size

Mean
Clauses
Output

Mean
Literals
Output

Original
Theory

14

83

20
40
60
80
100

11
11
11
11
12

39
36
35
32
36

Mean
Revisions
Convergence

Mean
Exemplars
Convergence

10.7
15.2
18.2
22.1
22.0

88
140
186
232
236

Figure 11: PROMOTER: Results. Numbers reported training set size average values
one hundred trials (ten trials ten example partitions).

(Ourston, 1991). example, 20 training examples output theory size (clauses plus
literals) 78, 80 training examples, output theory size 106.
Unfortunately, making direct comparisons KBANN RAPTURE difficult.
case KBANN RAPTURE, allow numerical rules, comparison impossible given
differences underlying representation languages. Nevertheless, clear that,
expected, KBANN produces significantly larger theories PTR. example, using 90
training examples PROMOTER theory, KBANN produces numerical theories with,
average, 10 clauses 102 literals (Towell & Shavlik, 1993). numbers would grow
substantially theory converted strictly symbolic terms. RAPTURE,
hand, change theory size, but, like KBANN, yields numerical rules (Mahoney &
Mooney, 1993).
6.2.3. Complexity
EITHER exponential size theory number training examples.
KBANN, cycle training-by-backpropagation subroutine O(d n) (where
size network n number exemplars), number cycles typically
numbers hundreds even shallow nets.
Like backpropagation, cost processing example PTR linear size
theory. contrast, however, PTR typically converges processing tiny fraction
number examples required standard backpropagation techniques. Figure 11 shows
average number exemplars (not cycles!) processed PTR convergence function
training set size. cost incurred PTR revising theory.
revision O(d n). average number revisions convergence also shown Figure 11.
6.3. Results Synthetic Theories
character PROMOTER theory make less ideal testing theory revision
algorithms. wish consider theories (i) deeper, (ii) make substantial use
negated internal literals (iii) overly general well overly specific. opposed
shallow theories generally easily repaired leaf level, deeper theories often
188

fiBIAS DRIVEN REVISION

require repairs internal levels theory. Therefore, theory revision algorithm may
perform well shallow theories necessarily scale well larger theories. Moreover,
theory size increases, computational complexity algorithm might preclude
application altogether. wish show PTR scales well larger, deeper theories.
Since deeper, propositional, real-world theories scarce, generated
synthetically. added bonus, know target theory perform controlled
experiments bias radicality. (Feldman, 1993) aggregate results experiments
performed collection synthetic theories reported. order avoid dubious
practice averaging results different theories order highlight significant features
particular application PTR, consider one synthetic theory typical studied
(Feldman, 1993).

r A, B
r C,
E, F
p0 , G, p1 , p2 , p3
B p0
B p1 , H
B p4 , p11
C I, J
C p2 , K
C p8 , p9
p10 , p12 , L
p3 , p9 ,
E N , p5 , p6
E O, p7 , p8
F p4
F Q, R
G S, p3 , p8
G p10 , p12
H U, V
H p1 , p2 ; p3 , p4
W
p6
J X, p5
J
K P, p5 , p9
K p6 , p9

L , p1
L p2 , p12 , p16
Z , p17
p18 , p19
N p0 , p1
N p3 , p4 , p6
N p10 , p12
Z p2 , p3
Z p2 , p3 , p17 , p18 , p20
p3 , p4 , p5 , p11 , p12
p13 , p18
p4 , p5 p6
P p6 , p7 , p8
X p7 , p9
Q p0 , p4
Q p3 , p13 , p14 , p15
W p10 , p11
W p3 , p9
R p12 , p13 , p14
V p14 , p15
p3 , p6 , p14 , p15 , p16
U p11 , p12
U p13 , p14 , p15 , p16 , p17
p7
p7 , p8 , p9 , p16 , p17 , p18

Figure 12: synthetic domain theory used experiments Section 6.

189

fiKOPPEL, FELDMAN, & SEGRE

theory shown Figure 12. Observe includes four levels clauses
many negated internal nodes. thus substantially deeper theories considered
testing theory revision algorithms. artificially introduce, succession, 15 errors
theory . errors shown Figure 13. theories, use default initial
weights assigned scheme Appendix A.
Let theory obtained introducing first errors. Figure 14
show radicality, Rad (), relative flawed theories, = 3, 6, 9, 12, 15,
well number examples misclassified theories. Note that, general,
number misclassified examples cannot necessarily assumed increase monotonically
number errors introduced since introducing error may either generalize
specialize theory. example, fourth error introduced undone fifth error.
Nevertheless, case particular set errors, successive theory
radical misclassifies larger number examples respect .
measure radicality accuracy, choose 200 exemplars classified according
. (i = 3, 6, 9, 12, 15), withhold 100 test examples train nested sets
20, 40, 60, 80 100 training examples. choose ten partitions run ten trials
partition.
Rad ()
, theory produced
Figure 15, graph average value
Rad ()
PTR. seen, value consistently 1. indicates revisions found

1
2
3
4
5
6
7
8
9
10
11
12
13
14
15

Added clause p6
Added clause p5
Added clause p8 , p15
Added literal p6 clause B p4 , p11
Deleted clause B p4 , p6 , p11
Added clause p14
Added clause G p12 , p8
Added literal p2 clause E, F
Added clause L p16
Added clause p13 , p7
Deleted clause Q p3 , p13 , p14 , p15
Deleted clause L p2 , p12 , p16
Added clause J p11
Deleted literal p4 clause F p4
Deleted literal p1 clause B p1 , H

Figure 13: errors introduced synthetic theory order produce flawed synthetic theories . Note fifth randomly-generated error obviates fourth.

190

fiBIAS DRIVEN REVISION

3

6

9

Number Errors

3

6

9

Rad()

7.32

12

15

12

15

17.53

22.66

27.15

33.60

Misclassified
Misclassified

0
50

26
45

34
45

34
46

27
64

Initial Accuracy

75%

64.5%

60.5%

60%

54.5%

Figure 14: Descriptive statistics flawed synthetic theories (i = 3, 6, 9, 12, 15).

1
Normalized
Radicality
0.8

0.6

0.4

15
12
9
6
3

0.2

0
20

40

60

80
100
# Training Exemplars

Rad ()
, output theories produced PTR
Rad ()
(i = 3, 6, 9, 12, 15). Error bars reflect 1 standard error.

Figure 15: normalized radicality,

PTR less radical needed restore original . Thus criterion
success PTR set itself, minimizing radicality, PTR better restoring .
expected, larger training set closer value 1. Also note number
errors introduced increases, saving radicality achieved PTR increases well, since
larger number opportunities created parsimonious revision. precisely,
191

fiKOPPEL, FELDMAN, & SEGRE

average number revisions made PTR 3 , 6 , 9 , 12 , 15 100 element training
set 1.4, 4.1, 7.6, 8.3, 10.4, respectively.
example show PTR achieves this. Note Figure 13 errors introduced
3 additions rules:
p6
p5
p8 , p15 .
cases, PTR quickly locates extraneous clause p6 , discovers deleting
results correct classification exemplars training set. fact, change also
results correct classification test examples well. two added rules
affect classification training examples, therefore deleted repaired
PTR. Thus radicality changes made PTR lower required restoring
original theory. minority cases, PTR first deletes clause B p0 deletes
clause p6 . Since literal B higher tree literal S, radicality
changes marginally higher required restore original theory.
Figure 16, graph accuracy test set. expected, accuracy degenerates
somewhat number errors increased. Nevertheless, even 15 , PTR yields theories
generalize accurately.
Figure 17 shows average number exemplars required convergence. expected,
fewer errors theory, fewer exemplars PTR requires convergence. Moreover,

60
% Misclassified
50

15
12
9
6
3

40
30
20
10
0
0

20

40

60

80
100
# Training Exemplars

Figure 16: Error rates output theories produced PTR (i = 3, 6, 9, 12, 15).

192

fiBIAS DRIVEN REVISION

300
Exemplars
Convergence
250

15
12
9
6
3

200
150
100
50
0
0

20

40

60

80
100
# Training Exemplars

Figure 17: Number exemplars processed convergence (i = 3, 6, 9, 12, 15).

number exemplars processed grows less linearly training set size. fact,
case average number examples processed greater 4 times training set size.
comparison, backpropagation typically requires hundreds cycles converges.
Next wish show effects positive bias, i.e., show user-provided guidance
choice initial weights improve speed convergence accuracy cross-validation.
flawed theories 3 15 , compare performance PTR using default
initial weights biased initial weights ( = 2). Figure 18, show cross-validation
accuracy increases bias introduced. Figure 19, show number examples
need processed convergence decreases bias introduced.
Returning example above, see introduction bias allows PTR
immediately find flawed clause p6 delete straight away. fact, PTR never
requires processing 8 exemplars so. Thus, case, introduction
bias speeds revision process results consistent choice optimal
revision.
Moreover, also shown (Feldman, 1993) PTR robust respect
random perturbations initial weights. particular, tests thirty different syntheticallygenerated theories, introducing small random perturbations edge dt-graph
training resulted less 2% test examples classified differently training
performed using original initial weights.

193

fiKOPPEL, FELDMAN, & SEGRE

60
% Misclassified
50

15
3
15 + bias
3 + bias

40
30
20
10
0
0

20

40

60

80
100
# Training Exemplars

Figure 18: Error rates output theories produced PTR (i = 3, 6, 9, 12, 15), using
favorably-biased initial weights.

6.4. Summary
Repairing internal literals clauses natural PTR repairing leaves. Moreover, PTR
converges rapidly. result, PTR scales deep theories without difficulty. Even
badly flawed theories, PTR quickly finds repairs correctly classify known exemplars.
repairs typically less radical restoring original theory close enough
original theory generalize accurately test examples.
Moreover, although PTR robust respect initial weights, user guidance choosing
weights significantly improve speed convergence cross-validation accuracy.

7. Conclusions
paper, presented approach, called PTR, theory revision problem
propositional theories. approach uses probabilities associated domain theory elements
numerically track flow proof theory, allowing us efficiently locate
repair flawed elements theory. prove PTR converges theory correctly
classifies examples, show experimentally PTR fast accurate even deep
theories.
several ways PTR extended.
First-order theories. updating method core PTR assumes provided
exemplars unambiguously assign truth values observable proposition. first-order
theory revision truth observable predicate typically depends variable assignments.
194

fiBIAS DRIVEN REVISION

300
Exemplars
Convergence
250

15
15 + bias
3
3 + bias

200
150
100
50
0
0

20

40

60

80
100
# Training Exemplars

Figure 19: Number exemplars processed convergence using favorably-biased initial
weights.

Thus, order apply PTR first-order theory revision necessary determine optimal
variable assignments basis probabilities updated. One method
discussed (Feldman, 1993).
Inductive bias. PTR uses bias locate flawed elements theory. Another type bias
used determine revision make. example, might known particular
clause might missing literal body circumstances deleted,
certain types literals added clause others. Likewise, might
known particular literal replaceable deletable, etc. shown (Feldman et
al., 1993) modifying inductive component PTR account bias,
convergence speed cross-validation accuracy substantially improved.
Noisy exemplars. assumed domain theory need
revision, exemplars correctly classified. Often case. Thus,
necessary modify PTR take account possibility reclassifying exemplars
basis theory rather vice-versa. PTR* algorithm (Section 6) suggests
misclassed exemplars sometimes detected processing. Briefly, idea
example allows multiple proofs root almost certainly root regardless
classification told. Thus, u E (er ) high, E probably regardless
told; analogously, u E (er ) low. modified version PTR based
observation already successfully implemented (Koppel et al., 1993).
conclusion, believe PTR system marks important contribution domain
theory revision problem. specifically, primary innovations reported are:
195

fiKOPPEL, FELDMAN, & SEGRE

(1)

assigning bias form probability element domain theory
flawed, clearly define objective theory revision algorithm.

(2)

reformulating domain theory weighted dt-graph, numerically trace
flow proof refutation various elements domain theory.

(3)

Proof flow used efficiently update probability element flawed
basis exemplar.

(4)

updating probabilities basis exemplars, efficiently locate flawed
elements theory.

(5)

using proof flow, determine precisely basis exemplars revise
flawed element theory.

Acknowledgments
authors wish thank Hillel Walters Bar-Ilan University significant contributions
content paper. authors also wish thank JAIR reviewers
exceptionally prompt helpful remarks. Support research provided part
Office Naval Research grant N00014-90-J-1542 (AMS, RF) Air Force Office
Scientific Research contract F30602-93-C-0018 (AMS).

196

fiBIAS DRIVEN REVISION

Appendix A: Assigning Initial Weights
appendix give one method assigning initial weights elements domain
theory. method based topology domain theory assumes userprovided information regarding likelihood errors available. information
available, used override values determined method.
method works follows. First, edge e define semantic impact
e, (e). (e) meant signify proportion examples whose classification directly
affected presence e .
One straightforward way formally defining (e) following. Let pair
, assigns root negation edges weight 1 edges
1
weight . Let (e) identical except e ancestor edges assigned
2
weight 1. Let E example observable proposition P , E(P)
priori probability P true randomly selected example.15 particular, typical
1
case observable propositions Boolean example equiprobable, E(P) = .
2
E thought average example. Then, edge one parentedge, formally define semantic significance, (e), edge e follows:


(e) = uE (er ) u E e
(e)

(e)

(er ).

is, (e) difference flow E root r, without edge e.
Note (e) efficiently computed first computing uE (e) every edge e
single bottom-up traversal , computing (e) every edge e single top-down
traversal , follows:


root edge r, (r) = 1 uE (r).


(1)

2(1 uE (e))
, f (e) parent edge e.

uE (e)
edge one parent-edge define (e) edge
using method computation, place ( f (e)) use max ( f (e)).

f


edges, (e) = ( f (e))

(2)

Finally, set, R, edges G, define (R) =



e R

(e).16

Now, computed (e) compute initial weight assignment e, p(e),
following way. Choose large C.17 e define:
15

Although defined example {0, 1} truth assignment observable proposition,
already noted Footnote 4 easily process examples assign observables value interval [0, 1].
16

Observe number examples reclassified result edge-deletion is, fact, superadditive, fact reflected last definition.
17

tested choose C optimally. experiments reported Section 6, value C = 106 used.

197

fiKOPPEL, FELDMAN, & SEGRE

C (e)
.
C (e) + 1
Now, regardless (e) defined, virtue method computing p(e) (e)
following: initial assignment, p, two sets edges , p equal total
strength revision sets equal radicality. means revision sets
equal strength priori equally probable.
p(e) =

set edges , define
1 e
S(e) =
/
0 e
formalized follows:
Theorem A1: R sets elements (R) = (S)
follows Rad(R) = Rad(S).
Proof Theorem A1: Let R sets edges (R) = (S).
Recall
Rad(S) = log



[1 p(e)]S(e) [ p(e)]1S(e) .

e



[1 p(e)]S(e) p(e)1S(e)
exp(Rad(S))
=
exp(Rad(R)) e [1 p(e)] R(e) p(e)1R(e)
=

p(e)1 p(e)
e

=

C (e)


e

R(e)S(e)

R(e)S(e)

= C (R)(S) = 1.
follows immediately Rad(R) = Rad(S).
simple consequence illustrates intuitiveness theorem following:
suppose two possible revisions , entails deleting simple literal.
Suppose one literal, l 1 , deep tree other, l 2 , higher tree
(l 2 ) = 4 (l 1 ). Then, using default initial weights assigned above, radicality
deleting l 2 4 times great radicality deleting l 1 .

198

fiBIAS DRIVEN REVISION

Appendix B: Updated Weights Conditional Probabilities
appendix prove certain limiting conditions, algorithm computes
conditional probabilities edges given classification example.
first assumption purpose appendix correct dt-graph known
subgraph given dt-graph . means every node n , w(n) = 1 (and,
consequently, every edge e , p(e) = w(e)). pair , w property said
deletion-only.
Although informally defined probabilities directly edges, purposes
appendix formally define probability function space subgraphs . is,
elementary events form = . probability e
simply { p( = )|e }.


say deletion-only, weighted dt-graph , p edge-independent
,
p( = ) =



e

p(e)



e
/

1 p(e).

Finally, say tree-like edge e one parent-edge. Observe
dt-graph connected tree-like one root.
prove results deletion-only, edge-independent, tree-like weighted dt-graphs.18
First introduce terminology. Recall every node labeled one
literals definition, literal true children true.
Recall also dt-graph represents sets NAND equations, . literal l
forces parent true, given set equations example E, l appears
false given E. (This follows definition NAND.) Thus say
edge e used E e | E n e .
e used E write N E (e). Note N E (er ) (E) = 1.
Note that, given probabilities elementary events = , probability p(N E (e))
edge e used E target domain theory simply




p( = )|N E (e). ambiguity use N E (e) refer N E (e).



Theorem B1: , w deletion-only, edge-independent, tree-like weighted
dt-graph, every edge e , u E (e) = p(N E (e)).
Proof Theorem B1: use induction distance n e deepest
descendant. n e observable proposition P e used E
precisely e P false E. Thus probability e used E
[1 p(e)] [1 E(P)] = u E (e).

18

Empirical results show algorithm yields reasonable approximations conditional probabilities even conditions hold.

199

fiKOPPEL, FELDMAN, & SEGRE

n e observable proposition | E n e precisely
children true , is, children unused .
p(N E (e)) = p(e) p( |
= p(e)

E



p(N E (s))



u E (s)

children(e)

= p(e)

(edge independence)

n e )

children(e)

(induction hypothesis)

= u E (e).
justifies bottom-up part algorithm. order justify top-down part need
one definition.
Let p(e| E, (E) ) probability e given , p exemplar
E, (E) .
p(e| E, (E) ) =





{ p( = )|e , (E) = (E)}

{ p( = )|(E) = (E)}


.


Theorem B2: , w deletion-only, edge-independent tree-like,
every edge e , p new (e) = p(e| E, (E) ).
order prove theorem need several lemmas:
Lemma B1: every example E every edge e
p( N E (e)) = p( N E (e), N E ( f (e))) = p( N E (e)|N E ( f (e))) p(N E ( f (e))).
follows immediately fact edge, e, used, parent-edge, f (e),
used.
Lemma B2: every example E every edge e ,
p(N E (E)|N E ( f (e)), E, (E) ) = p(N E (e)|N E ( f (e))).
lemma states N E (e) E, (E) conditionally independent given N E ( f (e))
(Pearl, 1988). is, N E ( f (e)) known, E, (E) adds information regarding
N E (e). immediate fact p( E, (E) |N E ( f (e))) expressed terms
probabilities associated non-descendants f (e), p(N E (e)) expressed
terms probabilities associated descendants r(e).
Lemma B3: every example E every edge e ,
v E (e) = p(N E (e)| E, (E) ).
Proof Lemma B3: proof induction depth edge, e.
root edge, er ,

200

fiBIAS DRIVEN REVISION

v E (er ) = (E) = p((E) = 1| E, (E) ) = p(N E (er )| E, (E) ).
Assuming theorem known f (e), show holds e
follows:
v ( f (e))
1 v E (e) = 1 u E (e) E

u E ( f (e))
= p( N E (e))

(definition v)

v E ( f (e))
p(N E ( f (e))

= p(N E (e)| E, (E) )

p( N E (e))
p(N E ( f (e))

(Theorem B1)
(induction hypothesis)

= p(N E (e)| E, (E) ) p( N E (e)|N E ( f (e))

(Lemma B1)

= p(N E (e)| E, (E) )
p( N E (e)|N E ( f (e)), E, (E) )

(Lemma B2)

= p( N E (e), N E ( f (e))| E, (E) )

(Bayes rule)

= p( N E (e)| E, (E) )

(Lemma B1)

= 1 p(N E (e)| E, (E) ).
Let e short event e
/ .
Lemma B4: every example E every edge e ,
p( e) = p( e, N E (e)) = p( e|N E (e)) p(N E (e)).
lemma, analogous Lemma B1, follows fact e deleted, e
unused.
Lemma B5: every example E every edge e ,
p( e| N E (e), E, (E) ) = p( e| N E (e)).
lemma, analogous Lemma B2, states e E, (E) conditionally
independent given N E (e). is, N E (e) known, E, (E) adds information
regarding probability e. immediate fact p( E, (E) | N E (e))
expressed terms probabilities edges e.
pieces prove Theorem B2.
Proof Theorem B2:
v (e)
1 p new (e) = 1 p(e) E

u E (e)
= p( e)

(definition pnew)

v E (e)
p(N E (e))

(Theorem B1)

201

fiKOPPEL, FELDMAN, & SEGRE

= p(N E (e)| E, (E) )

p( e)
p(N E (e))

(Lemma B3)

= p(N E (e)| E, (E) ) p( e|N E (e))

(Lemma B4)

= p(N E (e)| E, (E) ) p( e|N E (e), E, (E)

(Lemma B5)

= p( e, N E (e)| E, (E) )

(Bayes rule)

= p( e| E, (E) )

(Lemma B4)

= 1 p(e| E, (E) ).

202

fiBIAS DRIVEN REVISION

Appendix C: Proof Convergence
seen Section 5 PTR always terminates. wish show does,
exemplars classified correctly. prove domain theories satisfy certain
conditions made precise below. general idea proof following:
definition, algorithm terminates either exemplars correctly classified
edges weight 1. Thus, necessary show possible reach state
edges weight 1 exemplar misclassified. prove
state fails possess property consistency assumed hold initial
weighted dt-graph , preserved times algorithm.
Definition (Consistency): weighted dt-graph = , p consistent
exemplar E, (E) if, every root r , either:
(i) (E) = 1 uE (r ) > 0,
(ii) (E) = 0 uE (r ) < 1.
Recall edge e defined even even depth along every path root
odd odd depth along every path root. domain theory said unambiguous
every edge either odd even. Note negation-free domain theories unambiguous.
prove main theorem unambiguous, single-root domain theories.
Recall operations performed PTR are:
(1)

updating weights,

(2)

deleting even edges,

(3)

deleting odd edges,

(4)

adding subtree beneath even edge,

(5)

adding subtree beneath odd edge.

shall show operations performed way preserve
consistency.
Theorem C1 (Consistency): = , p single-rooted, unambiguous
weighted dt-graph consistent exemplar E, (E)
= , p obtained via single operation performed PTR,
also single-rooted, unambiguous dt-graph consistent E.
prove theorem show easily implies convergence algorithm.
Theorem C2 (Convergence): Given single-rooted, unambiguous weighted dtgraph set exemplars consistent every exemplar
, PTR terminates produces dt-graph classifies every exemplar
correctly.
Proof Theorem C2: PTR terminates prior edge assigned
weight 1, definition, exemplars correctly classified. Suppose
PTR produces weighted dt-graph = , p p(e) = 1 every
e . Assume, contrary theorem, exemplar E, (E)
misclassified root r. Without loss generality, assume
E, (E) exemplar r. Since p(e) = 1 every edge, means
u
E (er ) = 0. impossible since consistency implies
u KE (er ) > 0 thus follows Theorem C1 obtainable form
203

fiKOPPEL, FELDMAN, & SEGRE

, u
E (er ) > 0. contradicts assumption E misclassified .
Let us turn proof Theorem C1. use following four lemmas, slight
variants proved (Feldman, 1993).
Lemma C1: = , p obtained = , p via updating weights,
every edge e 0 < p(e) < 1, 0 < p(e) < 1.19
Lemma C2: Let = , p weighted dt-graph 0 < uE (er ) < 1
let = , p . every edge e 0 < p(e) < 1,
0 < p(e) < 1, follows 0 < u
E (er ) < 1.
Lemma C3: Let = , p weighted dt-graph uE (er ) > 0 let
= , p . The, every edge e , holds either:
(i) p(e) = p(e),
(ii) depth(e) odd u
E (e) > 0,
(iii) depth(e) even u
E (e) < 1
u
E (e) > 0.
analogous lemma holds roles > 0 < 1 reversed.




Lemma C4: e even edge , u E e (er ) uE (er ) u E e (r). addition,


e odd edge , u E e (er ) uE (er ) u E e (r).
prove consistency (Theorem C1). assume, without loss generality,
E, (E) exemplar root r prove one five operations
(updating four revision operators) PTR, obtained operation
uE (er ) > 0, u
E (er ) > 0.
Proof Theorem C1: proof consists five separate cases,
corresponding one operations performed PTR.
Case 1: obtained via updating weights.
Lemma C1, every edge e , 0 < p(e) < 1 0 < p(e) < 1.
Lemma C2, uE (er ) > 0 u
E (er ) > 0.
Case 2: obtained via deletion even edge, e.


Lemma C4(i), u E e (er ) uE (er ) > 0.
Case 3: obtained via deletion odd edge, e.
edge e deleted needed exemplar. Suppose that,
contrary theorem, exemplar E, (E) uE (er ) > 0
u
E (er ) = 0.
19

Recall updating algorithm defined


(E) = 0
v E (er ) =
.
1 (E) = 1
somewhat annoying presence > 0 necessary proof Lemma C1.

204

fiBIAS DRIVEN REVISION

R( E, (E) , e, ) =

=



u E e (er )


u E e (er )


u E e (er )
u
E (er )


u E e (er )
> 2.
0
e needed E, contradicting fact e needed
exemplar.
=

Case 4: obtained via appending subtree beneath even edge, e.
p(e) < 1, result immediate Lemma C2. Otherwise, let f
root edge subtree appended , beneath e. | f = e .
Suppose that, contrary theorem, exemplar E, (E)

uE (er ) > 0

u


Lemma
C4(ii),
E (er ) = 0.
e
|e

u E (er ) = u E (er ) u E (er ) = 0. then,
R( E, (E) , e, ) =




u E e (er )


u E e (er )
0

u E e (er )

= 0.

Thus e destructive E . then, construction , u
E ( f ) = 1.
(e)
=
0
<
1.

result
follows
immediately

Lemma
C3.
Thus, u
E
Case 5: obtained via appending subtree beneath odd edge,
e.
Suppose that, contrary theorem, exemplar E, (E) , uE (er ) > 0
u
E (er ) = 0. Since e = e , follows
R( E, (E) , e, ) =

=



u E e (er )


u E e (er )


u E e (er )


u E e (er )

.

Now, using Lemma C4(ii) numerator denominator,


u E e (er )


u E e (er )

uE (er )u
E (er ) = > 2.

Thus, e needed E . Now, let f root edge appended subtree,
. Then, construction , follows u
E ( f ) < 1 and, therefore
u
(e)
>
0.

result

immediate

Lemma
C3.
E

205

fiKOPPEL, FELDMAN, & SEGRE

completes proof theorem.
instructive note proof Theorem C1 fails restricted
unambiguous single-rooted dt-graphs. case 4 proof Theorem C1, use fact
edge e destructive exemplar E, (E) revision algorithm used
construct subgraph, , appended e u
E ( f ) = 1. However, fact
hold case e simultaneously needed destructive. occur e
descendant two roots E one root another root. also occur
one path e root r even length another path odd length.

206

fiBIAS DRIVEN REVISION

Appendix D: Guide Notation


domain theory consisting set clauses form C : H Bi .

Ci

clause label.

Hi

clause head; consists single positive literal.

Bi

clause body; consists conjunction positive negative literals.

E

example; set observable propositions.

(E)

classification example E ith root according domain
theory .

(E)

correct classification example E ith root.

E, (E)

exemplar, classified example.



set NAND clauses equivalent .



dt-graph representation .

ne

node edge e leads.

n

e

node edge e comes.

p(e)

weight edge e; represents probability edge e
needs deleted edges need appended node n e .

= , p

weighted dt-graph.

e

weight edge e equal 1.

e

edge e deleted.

u E (e)

flow proof example E edge e.

v E (e)

adjusted flow proof e taking account correct
classification example E.

Ri ( E, (E) , e, )

extent (ranging 0 ) edge e weighted dtgraph contributes correct classification example E
ith root. Ri less/more 1, e harmful/helpful; Ri = 1
e irrelevant.



revision threshold; p(e) < e revised.



weight assigned revised edge root appended
component.



revision threshold increment.



revised edge weight increment.

Rad ()

radicality changes required order obtain revised
theory .

207

fiKOPPEL, FELDMAN, & SEGRE

References
Buchanan, B. & Shortliffe, E.H. (1984). Rule-Based Expert Systems: MYCIN Experiments
Stanford Heuristic Programming Project. Reading, MA: Addison Wesley.
Feldman, R. (1993). Probabilistic Revision Logical Domain Theories. Ithaca, NY: Ph.D.
Thesis, Department Computer Science, Cornell University.
Feldman, R., Koppel, M. & Segre, A.M. (August 1993). Relevance Bias Revision
Approximate Domain Theories. Working Notes 1993 IJCAI Workshop Machine
Learning Knowledge Acquisition: Common Issues, Contrasting Methods, Integrated
Approaches, 44-60.
Ginsberg, A. (July 1990). Theory Reduction, Theory Revision, Retranslation. Proceedings
National Conference Artificial Intelligence, 777-782.
Koppel, M., Feldman, R. & Segre, A.M. (December 1993). Theory Revision Using Noisy
Exemplars. Proceedings Tenth Israeli Symposium Artificial Intelligence Computer
Vision, 96-107.
Mahoney, J. & Mooney, R. (1993). Combining Connectionist Symbolic Learning Refine
Certainty-Factor Rule-Bases. Connection Science, 5, 339-364.
Murphy, P.M. & Aha, D.W. (1992). UCI Repository Machine Learning Databases [Machinereadable data repository]. Irvine, CA: Department Information Computer Science,
University California Irvine.
Ourston, D. (August 1991). Using Explanation-Based Empirical Methods Theory
Revision. Austin, TX: Ph.D. Thesis, University Texas Austin.
Ourston, D. & Mooney, R. (in press). Theory Refinement Combining Analytical Empirical
Methods. Artificial Intelligence.
Pazzani, M. & Brunk, C. (June 1991). Detecting Correcting Errors Rule-Based Expert
Systems: Integration Empirical Explanation-Based Learning. Knowledge Acquisition,
3(2), 157-173.
Pearl, J. (1988). Probabilistic Reasoning Intelligent Systems. San Mateo, CA: Morgan
Kaufmann.
Quinlan, J.R. (1986). Induction Decision Trees. Machine Learning, 1(1), 81-106.
Towell, G.G. & Shavlik, J.W. (October 1993). Extracting Refined Rules Knowledge-Based
Neural Networks. Machine Learning, 13(1), 71-102.
Wilkins, D.C. (July 1988). Knowledge Base Refinement Using Apprenticeship Learning
Techniques. Proceedings National Conference Artificial Intelligence, 646-653.
Wogulis, J. & Pazzani, M.J. (August 1993). Methodology Evaluating Theory Revision
Systems: Results Audrey II. Proceedings Thirteenth International Joint Conference
Artificial Intelligence, 1128-1134.

208

fiJournal Artificial Intelligence Research 1 (1993) 6189

Submitted 8/93; published 11/93

Software Agents: Completing Patterns
Constructing User Interfaces
Jeffrey C. Schlimmer
Leonard A. Hermens
School Electrical Engineering & Computer Science,
Washington State University, Pullman, WA 99164-2752, U.S.A.

SCHLIMMER@EECS.WSU.EDU
LHERMENS@EECS.WSU.EDU

Abstract
support goal allowing users record retrieve information, paper
describes interactive note-taking system pen-based computers two distinctive
features. First, actively predicts user going write. Second, automatically
constructs custom, button-box user interface request. system example
learning-apprentice software-agent. machine learning component characterizes
syntax semantics users information. performance system uses learned
information generate completion strings construct user interface.

1. Introduction Motivation
People like record information later consultation. many, media choice
paper. easy use, inexpensive, durable. disadvantage, paper records
scale well. amount information grows, retrieval becomes inefficient, physical storage becomes excessive, duplication distribution become expensive. Digital media
offers better scaling capabilities. indexing sub-linear algorithms, retrieval efficient; using high density devices, storage space minimal; electronic storage
high-speed networks, duplication distribution fast inexpensive. clear
computing environments evolving several vendors beginning market inexpensive, hand-held, highly portable computers convert handwriting text. view
start new paradigm shift traditional digital information gathered used. One obvious change computers embrace paper metaphor,
eliminating need typing. paradigm research inspired, one
primary goals combine best worlds making digital media convenient paper.
document describes interactive note-taking software system computers
pen-based input devices. software two distinctive features: first, actively predicts
user going write provides default user may select; second,
software automatically constructs graphical interface users request. purpose
features speed information entry reduce user errors. Viewed larger
context, interactive note-taking system type self-customizing software.
clarify notion, consider pair dimensions characterizing software.
Figure 1 depicts, one dimension task specificity. Software addresses generic task
(e.g., spreadsheet) lies task independent software (e.g., compiler) task
specific software (e.g., particular companys accounting software). Another dimension
amount user customization required make software useful. Task generic software lies two extremes, requiring modest programming specialized
1993 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.

fiS CHLIMMER & H ERMENS

High

Visual BASIC

User
Customization
Required

Spreadsheets

Self-Customizing

Custom Software

Low
Generic

Low

Task Specificity Product

Development Cost / User

Specific

High

Figure 1: Continuum software development depicting traditional trade-off
development cost per user amount user customization required.
Self-customizing software eliminates need user customization starting
partially-specified software applying machine learning methods complete
remaining customization.
language. Self-customizing software uses machine learning techniques automatically customize task generic software specific user. software learns assist user
watching complete tasks, software also learning apprentice. Similarly,
user explicitly program defaults user interface note
taking system, type software agent. Agents new user interface paradigm
free user explicitly command computer. user record information directly free-form manner. Behind interface, software acting behalf
user, helping capture organize information.
Next introduce performance component note-taking software
detail, describe representations algorithms used learning methods.
also present empirical results, comparing performance seven alternate methods
nine realistic note-taking domains, finally, describe related research identify
systems limitations.

62

fiS OFTWARE GENTS : C OMPLETING P ATTERNS & C ONSTRUCTING U SER NTERFACES

Figure 2: Screen snapshot note-taking software contextual prompting mode
PowerBook note. two triangles lower left scroller buttons.

2. Performance Task
primary function note-taking software improve users speed accuracy
enter notes various domains interest. note short sequence descriptive terms describe single object interest. Example 1 shows note describing particular personal computer (recorded first author Usenet newsgroup
1992):
4096K PowerBook 170, 1.4MB 40MB Int. Drives, 2400/9600 Baud FAX Modem

(Example 1)
Example 2 note describing fabric pattern (recorded first authors wife):
Butterick 3611 Size 10 dress, top

(Example 2)

Tables 5 11 later paper list sample notes drawn seven domains.
user may enter notes different domains convenience may use whatever
syntactic style comes naturally.
users point view, software operates one two modes: contextual
prompting mode, interactive graphical interface mode. first mode, software
continuously predicts likely completion user writes note. offers
default user. location presentation default must balance conflicting
requirements convenient yet unobtrusive. example, hand hide
indicated default user writing. solution small, colored completion button follow left user writing. location, visible
either right- left-handed people write notes. user reposition button another location prefer. default text displayed immediate right
button smaller font. completion button green; text black. completion button saturation ranges 1 (appearing green), software highly confident
predicted value, 0 (appearing white), software lacks confidence. button light gray frame, visible even software prediction. Figure 2
63

fiS CHLIMMER & H ERMENS

Figure 3: Screen snapshot note-taking software button-box mode
PowerBook note.
portrays screen snapshot software operating contextual prompting mode
PowerBook note.
softwares second mode presents interactive graphical interface. Instead
requiring user write text note, software presents radio-button
check-box interface (what call button-box interface). this, user may select
text fragments, portions notes called descriptive terms , tapping radio-buttons
check-boxes pen interface device. selection button-box interface
added current note. Intuitively, check boxes generated depict optional descriptive terms, whereas radio-button panels generated depict alternate, exclusive descriptive terms. user convenience, radio-buttons clustered panels sorted
alphabetically ascending order top bottom. allow user add new descriptive terms button-box panel, additional blank button included bottom each.
user selects radio button item, graphical interface expanded depict additional choices corresponding descriptive terms follow syntactically. software
indicates predictions preselecting corresponding buttons highlighting
green. user may easily override default selection tapping desired button.
Figure 3 portrays screen snapshot software operating interactive graphical
interface mode PowerBook note.
software prompting mode user begins write note. learned syntax domain note sufficiently mature (see Section 6, Constructing ButtonBox Interface), software switch button-box mode. indicate
user, mode switch depicted radio button presented users notice. convenient unobtrusive location switch completion button. keeping
color theme, mode switch also green hue. user taps switch,
written text removed, appropriate radio buttons check boxes inserted.
system automatically selects buttons match user-written text. user makes
additional selections, interface expands include additional buttons. user
finishes note, either mode, software returns prompting mode anticipation
another note.1 interface constructed learned syntax, software

64

fiS OFTWARE GENTS : C OMPLETING P ATTERNS & C ONSTRUCTING U SER NTERFACES

refines representation domains notes, button-box interface also improves.
On-line Appendix 1 demonstration systems operation two modes.

3. Learning Syntax
implement two modes note taking software, system internally learns two
structures. characterize syntax users notes, learns finite-state machines (FSMs).
generate predictions, learns decision tree classifiers situated states within FSMs.
order construct graphical user interface, system converts FSM set
buttons. section describes representation method learning FSMs. next
section discusses learning embedded classifiers.
3.1

Tokenization

Prior learning finite-state machine, users note must first converted
sequence tokens. Useful tokenizers domain independent. However, handcrafted
domain-specific tokenizers lead useful representations. generic tokenizer used
results reported uses normal punctuation, whitespace, alpha-numeric character boundaries token delimiters. example, generic tokenizer splits sample
PowerBook note Example 1 following 16 tokens:
:NULL
"4096"
" K"
" PowerBook"
" 170"
", 1.4"
"MB"
" and"
" 40"
"MB"
" Int."
" Drives"
", 2400/9600"
" Baud"
" FAX"
" Modem" .

token :NULL prepended tokenizer. convention simplifies code
constructing FSM.
3.2

Learning Finite-State Machine

Deterministic finite-state machines (FSMs) one candidate approach describing
syntax users notes well understood relatively expressive. Moreover, Angluin (1982) Berwick Pilato (1987) present straightforward algorithm
learning specific subclass FSMs called k-reversible FSMs. algorithm incremental
1. functionality described here, prototype implements transition button-box contextual prompting. mechanism transition machine dependent germane research.

65

fiS CHLIMMER & H ERMENS

start

start

:NULL

:NULL

:NULL

Butterick

Butterick

Butterick

3035

3035

3611

Size

Size

Size

11/12

11/12

10

dress

dress

dress

terminal

terminal
top

terminal
(a)

(b)

Figure 4: (a) Degenerate finite-state machine processing single fabric pattern
note, (b) prefix tree finite-state machine adding second fabric pattern note
(cf. Example 2).
suffer presentation order effects. Berwick Pilato define k-reversible
FSM as:
regular language k-reversible, k non-negative integer, whenever two
prefixes whose last k words [tokens] match tail common, two prefixes
tails common. words, deterministic finite-state automaton (DFA)
[FSM] k-reversible deterministic lookahead k sets initial
final states swapped arcs [transitions] reversed.

Given list tokens, k-reversible FSM algorithm first constructs prefix tree,
token sequences common k-leaders share k-length path FSM.
example, Figure 4a depicts simple FSM constructed single fabric pattern note.
text users note converted sequence tokens. transition created
token sequence states created link together. One state serves
initial state, another indicates completion sequence. convenience,
latter, terminal state depicted double circle. FSM able find transition
token sequence, arrives terminal state, FSM accepts
token sequence instance language defines. Figure 4b depicts FSM
another path added corresponding second fabric pattern note (Example 2).
FSM accept either note expressed sequence tokens. FSM
trivial prefix tree first state shared two paths.
66

fiS OFTWARE GENTS : C OMPLETING P ATTERNS & C ONSTRUCTING U SER NTERFACES

k-leader defined path length k accepts given state.
Merge two states either following true:
1. Another state transitions states token;
(This enforces determinism.)
2. states common k-leader
a. states accepting states,
b. states transition common state via token.
Table 1: FSM state merging rules (Angluin, 1982).
prefix tree minimal observed token sequences, may general enough
use prediction. (The prefix tree is, essence, expensive method memorizing
token sequenceswhich desired result.) sake prediction, desirable
FSM accept new, previously unseen combinations tokens. prefix
tree automaton converted general FSM merging states.
particular method converts prefix tree k-reversible FSM via Angluins
(1982) algorithm. algorithm merges states similar transitions, creates
FSM accepts token sequences prefix tree, well candidate sequences.
Table 1 lists three rules deciding merge pair states prefix tree form
k-reversible FSM. special case k equals zero, states common kleader, Rule 2a ensures one accepting state.
rules Table 1 must applied pair states FSM,
time pair states merged process must repeated, asymptotic
complexity process O( n3 ), n number states FSM.
Applying rules prefix tree Figure 4b k equal zero results FSM
depicted Figure 5a. Notice first two states merged make FSM
deterministic (Rule 1). accepting states also merged compliance
Rule 2a. resulting FSM fewer states general. accepts two
token sequences originally seen. Extending example, Figure 5b illustrates addition
third fabric pattern note prefix tree path FSM. Reapplying rules results
FSM shown Figure 6. first two states merged action
determinism Rule 1. Note pair latter states also merged
share common zero-leader (true pairs states) transition
common terminal state token "dress".
Figure 7 depicts sophisticated result; shows learned zero-reversible FSM
notes PowerBook computers. example shows model number "100"
never followed specification internal floppy drive, model numbers
are. model may external floppy drive. Note single terminal state.
Whitespace punctuation eliminated clarity figure.
rules listed Table 1 generalization operators allow FSM accept
previously unobserved sequences. Whenever two states merged one,
FSM accept sequences new state tail end transitions one previous states new state head end least one
transition. example, state State 1 Figure 7 merged several
previous states generalizes memory sizes PowerBook models. rules comprise
heuristic bias may conservative. example, Figure 8 depicts FSM notes
67

fiS CHLIMMER & H ERMENS

start

start

:NULL

:NULL

Butterick

:NULL

Butterick

Butterick

3035

3611

3035

3611

3674

Size

Size

Size

Size

Size

11/12

10

11/12

10

10

dress

dress

dress

dress

dress

terminal
top

top

terminal

terminal

(a)

(b)

Figure 5: (a) Finite-state machine processing two fabric pattern notes
applying state merging rules Table 1, (b) prefix tree finite-state machine
adding third fabric pattern note.
fabric patterns. Many states prior accepting state could usefully
merged, using rules listed Table 1, many notes processed
happens. FSM Figure 8 rendered button-box interface, would
reflect little true structure domain fabric patterns. Table 2 lists specializations
Rules 2a 2b additional pair rules developed make FSM generalize
readily. Note parameter k set zero Rule 2 one Rule 3.
Effectively, two states merged Rules 3a 2b' share incoming outgoing
transition. Rule 3b Kleene rule encourages FSM generalize number
times token may appear sequence. one state transition another, merging
result transition loops newly merged state. Figure 9
depicts FSM notes fabric patterns learned using three generalization rules
Table 2. resulting FSM accurately captures syntax users fabric pattern notes
correctly indicates syntactically optional tokens may appear end note.
rendered button-box interface, clearly depicts users syntax (as illustrated
later Figure 12). added generalization rules may marginal effects
systems ability accurately predict completion user writes note (as Table 14
indicates). purpose improve quality custom interface.
Cohen (1988) uses interesting alternative representation learning syntactic form.
goal work guide generation proof structures. Intuitively, representation finite-state machine accepts tree rather sequence, reason
termed tree automaton. Like rules Tables 1 2, tree automatons generalized
68

fiS OFTWARE GENTS : C OMPLETING P ATTERNS & C ONSTRUCTING U SER NTERFACES

start
:NULL

Butterick

3035

3674

3611

Size

Size

Size

11/12

10

10

dress

dress

top

terminal

Figure 6: Sample finite-state machine processing three fabric pattern notes.

Merge two states following true:
1. Another state transitions states token;
(This enforces determinism.)
2'. states common 0-leader
a. states accepting states,
b. states transition common state via token;
3. states common 1-leader
a. states transition common state via token,
b. One transitions via token.
Table 2: Extended FSM state merging rules.
merging states share similar transitions. Oddly enough, one motivation using tree
automatons less likely introduce extraneous loops, opposite
problem original FSM merging rules Table 1. clear map
sequence tokens users notes tree structure, less sequential nature
tree automaton may help alleviate sequencing problems rendering custom user
interface (see Section 9, Observations/Limitations).
3.3

Parsing

use finite-state machine prediction, software needs strategy dealing
novel tokens. example, user takes note PowerBook computer
69

fiS CHLIMMER & H ERMENS

start
:NULL
1
2048

4096

6144

8192

K

PowerBook
2
100

140

145

160

170

3
80

1.4

MB

MB

Int


4



20

40

20

1.4

MB

MB

Int

40

80

120

5
Ext

Drive

Drives



6

terminal

Drives
2xBattery,
Battery,
Case,
Charger,
FPU,
Video Output

14.4

v

1.4

K

32

MB

9.6

9600

2400/4800

2400/9600

4800/9600

Ext

K

Baud

bis

7
FAX

Modem

Figure 7: Zero-reversible FSM characterizing PowerBook notes (cf. Example 1).
70

fiS OFTWARE GENTS : C OMPLETING P ATTERNS & C ONSTRUCTING U SER NTERFACES

start
:NULL

Butterick

McCall's

4198

3722

4352

6171

3674

3035

3611

Size

Sizes

Size

Size

Size

Size

12

8-10-12

12

10

10

11/12

Dress

Jumper

Top

Dress

4864

5057

5377

Suze

Size

10

12

Dress

Dress

Skirt

Simplicity

5906

5424

5465

Size

Size

Size

12

11/12

11/12

Jumper

Dress

Jumper

Skirt

Top

terminal

Figure 8: Zero-reversible finite-state machine characterizing fabric pattern notes
learned using merging rules listed Table 1.
new memory configuration, FSM transition first token. software prompt user, must means deciding novel tokens lie
notes syntaxwhich state predict from. Without mechanism, meaningful
prediction generated novel tokens.
state may transition next token. general, single symptom
three possible causes: (1) novel token inserted, (2) suitable token
omitted next token would accepted subsequent state, (3) token
simply replaced another syntax. example, sequence tokens {:NULL,
"12288", "K", "PB"}, "12288" novel token, familiar memory size omitted,
"PowerBook" replaced "PB".
optimal solution would identify state requiring minimum number insertions,
omissions, replacements necessary parse new sequence. efficient, heuristic
approximation greedy search using special marker. time marked state
FSM transition next token written user, marker moved forward,
prediction generated state. transition next token,
greedy search conducted state (including marked one reachable
it) transition token (including next one following).
state found, marker moved forward state, tokens transitions
skipped states assumed omitted, novel tokens assumed inserted. state past
marker transition remaining tokens, remaining tokens
assumed replacements number likely transitions; marker
moved. user writes subsequent token state transition,
71

fiS CHLIMMER & H ERMENS

start
:NULL

Butterick

3722

4198

4352

6171

3674

McCall's

3035

Sizes

3611

4864

5057

5377

Simplicity

5906

5424

5465

Size

8-10-12

10

11/12

Dress

12

Jumper

terminal
Jumper

Skirt

Top

Figure 9: Finite-state machine characterizing fabric pattern notes learned using
extended rules Table 2. Compare zero-reversible finite-state machine
domain Figure 8.
marker moved described above, syntax users note realigned
learned syntax. Continuing simple PowerBook example, marker moved
State 1 FSM Figure 7 initial state transition first token
:NULL. State 1 doesnt transition next token "12288", greedy search
conducted find nearby state accepts either "12288", "K", "PB". state
State 2 accepts "K", marker moved state. Another greedy search
started find state accepts "PB". one cannot found, heuristic parsing
assumes skip next transition. case one labeled "PowerBook".
Consequently, system generates prediction State 2 prompt user.
3.4

Multiple Finite-State Machines

user decides take notes multiple domains, may necessary learn separate syntax domain. example, single syntax generalized PowerBook fabric pattern notes likely yield confusing predictions unnatural user
interface. Maintenance multiple finite-state machines instance clustering problemdeciding notes clustered together share FSM. Fisher (1987)
discusses, involves trade-off maximizing similarity within cluster minimizing similarity clusters. Without first criteria, notes would put
single cluster. Without second criteria, note would put cluster.
One obvious approach would require user prepend note unique
token identify notes domain. simplifies clustering computation. notes
sharing first token would share FSM. However, scheme, user would
72

fiS OFTWARE GENTS : C OMPLETING P ATTERNS & C ONSTRUCTING U SER NTERFACES

start
terminal

X

Figure 10: Simple finite-state machine one state.
remember identifying token name domain. interface could provide
pop-up list previously used domain identifiers. satisfactory
requires overhead needed taking notes paper.
alternative approach doesnt require extra effort part user. new
note grouped FSM skips fewest tokens. heuristic encourages
within cluster similarity FSM accept new token sequences similar
summarizes. inhibit formation single-note FSMs, new FSM constructed
FSMs skip half new notes tokens. parametrized solution
encourage between-cluster dissimilarity.

4. Learning Embedded Classifiers
Finite-state machines useful representations capturing syntax users notes,
easy learn. predicting notes completion, essential prediction made correct state FSM (as discussed above). also necessary
decide whether terminate (indicating acceptance note) continue prediction, and,
later case, transition predict. facilitate decisions, FSM maintain count many times parsing terminated many times transition
taken. Prediction return option maximum frequency.
Figure 10 depicts FSM method prove insufficient. one
state, accepting state, transition corresponding token "X" optional. (This
corresponds check box interface item.) two problems frequency-based
prediction. First, FSM indicate transition taken once, yet
quite clear user interface. Second, simple frequency-based prediction would
always recommend termination never transition. FSM accepts whether box
checked not, thus frequency termination greater equal frequency
transition. problem arises whenever loop.
Embedding general classifiers FSM alleviate FSMs representational
shortcomings. example, FSM depicted Figure 10, decision tree embedded
state easily tests whether transition already taken advise
repeating it. Moreover, classifier predict based previous transitions rather
frequency current states transitions. Therefore, decision tree embedded
state Figure 10 predict transition taken function other,
earlier tokens sequence. Table 3 lists sample decision trees embedded states
FSM depicted Figure 7. first tree tests token parsed distant state,
effect augmenting FSM representation. relates memory size hard disk capacity
(small amounts memory correlate small hard disk). second tree prevents
optional loop taken second time testing see state yet
visited parse note. processing additional notes, second decision tree
73

fiS CHLIMMER & H ERMENS

Decision tree embedded State 3:
State 1 exited "2048"
predict " 20"
Else "4096"
predict " 40"
Else "6144"
predict " 40"
Else "8192"
predict " 40" .

Decision tree embedded State 7:
State 7 visited
predict " FAX"
Else State 7 exited " FAX"
predict " Modem" .

Table 3: Sample decision trees embedded finite-state machine depicted
Figure 7.
becomes complex system tries predict PowerBooks FAX modems
not.
classifier trained state FSM which: (a) one transition,
(b) marked terminal state also transition. classifiers updated incrementally user finishes note. classifiers training data token sequences
parsed state. class value data transition taken from, termination at,
state token sequences. classifiers whose states used parse
updated. attributes data names states prior one, values
attributes transitions taken states. distinct attribute defined
time state visited given parse, loop transition taken specific
attribute reflects fact. attributes, corresponding state visited
parsing token sequence, attribute special, empty value.
Consider PowerBook FSM shown Figure 7. classifier would embedded
States 1, 2, 3, 4, 5, 6, 7. training example corresponding note Example 1
classifier State 6 would be:
Attributes:
S1
=
S2
=
S3
=
S4
=
S5
=
S6
=
S7
=
S7-1
=
Class:
=

Values:
"4096"
" 170"
NIL
" 40"
" Drives"
", 2400/9600"
" FAX"
" Modem"
:TERMINATE .

Note value State 3, denoting wasnt visited parse
Example 1. Also two attributes State 7 denoting visited twice.
classifier gives informed advice transition take whether terminate. FSM turn gives classifier specific context operation. single
classifier used predict next token, would hard pressed represent different predictions required. domain naturally narrowed FSM therefore
reduces representational demands classifier. Later, present empirical results
74

fiS OFTWARE GENTS : C OMPLETING P ATTERNS & C ONSTRUCTING U SER NTERFACES

comparing single classifier set classifiers embedded FSM. findings
show latter outperforms former, confirming intuition learning
effective situated within narrow context.
classifiers point view, learning task non-stationary. concept
learned changing time structure FSM changing. two states
merged, one two classifiers discarded. embedded different
position FSM, sees different training data. Similarly, states
merged, attributes training data also change. help mitigate effect, new
state takes oldest identifier assigned two merged states. Empirical results
Table 14 illustrate FSM fixed classifier learn
useful information.

5. Contextual Prompting
prompting mode, software continuously predicts likely completion user
writes note. presents default next completion button. buttons
saturation ranges white green proportion confidence prediction.
user taps completion button, prompt text inserted end current note.
completion generated parsing tokens already written user, finding
last state visited FSM, predicting next likely transition (or termination).
process repeated stopping criterion satisfied, discussed below.
last token written user incomplete, matching prefix states transition,
remainder transition predicted. last token matches one
transition, generalized string predicted using special characters indicate type
number characters expected. digit expected, "#" included; letter, "a"
included; either possible, "?" included; transitions tokens longer
others, "" appended end. example, user written
"4096K PowerBook 1", possible values PowerBook models "100", "140",
"160C", "170" generalized, prompt "#0".
simple calculation used compute confidence prediction set
buttons color saturation. simple ratio
f ( prediction )
f ( total ) ( 1 + skipped )

f ( prediction ) frequency predicted arc (or terminate) [i.e., number
times choice taken parsing previously observed notes], f ( total ) total
frequency arcs (and terminate), skipped number tokens skipped
heuristic parsing (cf. Section 3.3, Parsing). Confidence directly proportional simple
likelihood prediction degraded proportion number tokens FSM
skip get point. information used simple way, unclear
sophisticated measures needed.
stopping criterion used determine much prompt offer user.
one extreme, single token predicted. gives user little context may
provide much assistance. extreme, sequence tokens completes
note predicted. may lengthy, user would edit prompt
selected. stopping criterion Table 4 balances two extremes attempts limit
prompts consistent set tokens. particular, Condition 3 stops expanding prompt
75

fiS CHLIMMER & H ERMENS

Stop expanding prompt following true:
1. next prediction terminate;
2. next prediction generalized string;
3. least one token already predicted
a. prediction starts punctuation,
b. confidence prediction lower;
4. next prediction last prediction;
5. 10 tokens already predicted.
Table 4: Stopping criterion contextual prompting.
upon reaching syntactic boundary (leading punctuation) upon reaching semantic
boundary (falling confidence).

6. Constructing Button-Box Interface
button-box mode, software presents interactive graphical interface. Instead
writing note, user may select note fragments tapping buttons. switch
contextual mode button-box mode, green radio button indicator displayed
completion button software confident users syntax. user taps
indicator, existing text removed, corresponding buttons button-box interface selected. user selects additional buttons, interface dynamically expands
reveal additional choices. interface reflects improving syntactic representation, also improves successive notes.
button-box interface direct presentation finite-state machine. user
written token note, software finds FSM best parses
tokens. mode switch presented syntax sufficiently matureif average
number times state used parse earlier notes greater 2. user
selects indicator, FSM incrementally rendered set radio buttons check
boxes.
two user interface item types correspond optional choices (check boxes)
exclusive choices (radio buttons). Mapping FSM two item types proceeds one
state time. Given particular state rendered, transition starts path
branch eventually returns back state rendered check box (a loop).
loop corresponds syntactically optional information. label check box consists transition labels along looping path. non-looping transitions
rendered buttons single radio button panel along extra, unlabeled button.
correspond syntactically exclusive information. label radio button consists
transition label point subsequent branch termination. example,
compare FSM depicted Figure 7 corresponding button-box interface
Figure 3.
transitions different radio buttons lead different parts FSM,
may confuse user render entire FSM once. So, branching state rendered
visited. Initially, first state FSM rendered. Then, radio button
selected, branching state end transition path rendered. Note check
boxes trigger additional rendering branching state end loop

76

fiS OFTWARE GENTS : C OMPLETING P ATTERNS & C ONSTRUCTING U SER NTERFACES

already rendered. interactive process repeated long user selects
radio buttons lead branching states.

7. Empirical Results
tested interactive note taking software notes drawn variety domains.
Tables 5 11 list sample notes seven domains (in addition PowerBook
fabric pattern sample notes listed above).
CVA-62 8/6/63 3/4/64 Mediterranean A-5A AG 60X
CVA-61 8/5/64 5/6/65 Vietnam RA-5C NG 10X

Table 5: Sample notes airwing domain. Listed 2 78 notes
airwing assignments aboard aircraft carriers collected (Grove & Miller,
1989).

B, 81, 5, 151 (2.5), Cyl. 4, 2-bbl., Pontiac
C, 82, X, 173 (2.8), Cyl. 6, 2-bbl., Chevrolet

Table 6: Sample notes engine code domain. Listed 2 20 notes
meaning engine codes stamped automobile identification plates
collected Chiltons Repair & Tune-Up Guide (1985).

90, Mazda MPV, 40K MI, 7 Pass, V6, Auto
ABS, PL/PW, Cruise, Dual Air
87, Grand Caravan, 35K MI, 7 Pass, V6, Auto
Cruise, Air, Tilt, Tinting

Table 7: Sample notes minivan domain. Listed 2 22 notes
minivan automobiles collected first author.

Lorus Disney Oversize Mickey Mouse Watch.
Genuine leather strap.
Seiko Disney Ladies' Minnie Mouse Watch.
Leather strap.

Table 8: Sample notes watch domain. Listed 2 89 notes
personal watches collected Best catalog (a department store).

77

fiS CHLIMMER & H ERMENS

azatadine maleate
Blood: thrombocytopenia.
CNS: disturbed coordination, dizziness, drowsiness, sedation,
vertigo.
CV: palpitations, hypotension.
GI: anorexia, dry mouth throat, nausea, vomiting.
GU: Urinary retention.
Skin: rash, urticaria.
Other: chills, thickening bronchial secretions.
brompheniramine maleate
Blood: aganulocytosis, thrombocytopenia.
CNS: dizziness, insomnia, irritability, tremors.
CV: hypotension, palpitations.
GI: anorexia, dry mouth throat, nausea, vomiting.
GU: urinary retention.
Skin: rash, urticaria.
parenteral administration:
local reaction, sweating, syncope may occur.

Table 9: Sample notes antihistamine domain. Listed 2 17
notes side effects antihistamines collected Nurses Guide Drugs
(1979).

Canon FD f/1.8, 6oz., f/22, 13in.,
good sharpness, poor freedom flare,
better freedom distortion,
focal length marked sides well
front lens
Chinon f/1.7, 6oz., f/22, 9in.,
poor sharpness, good freedom flare,
good freedom distortion,
cannot locked program mode,
problem, course, lens
used program-mode cameras

Table 10: Sample notes lens domain. Listed 2 31 notes
35mm SLR camera normal lenses collected Consumer Reports (1988).

78

fiS OFTWARE GENTS : C OMPLETING P ATTERNS & C ONSTRUCTING U SER NTERFACES

22in. W. 48in.
large falcon. Three color phases occur:
blackish, white, gray-brown.
uniformly colored
Peregrine Falcon, dark
mustaches hood.
16-24in. W. 42in.
Long-winged, long-tailed hawk
white rump, usually seen soaring
unsteadily marshes wings
held shallow 'V'. Male pale
gray back, head, breast. Female
young brown above, streaked
below, young birds rusty tone.

Table 11: Sample notes raptor domain. Listed 2 21 notes
North American birds prey collected (Bull & Farrand, 1977).
Summary characteristics nine domains listed Table 12 together
simple measures indicate prediction difficulty. instance, Column 1 shows number
notes domain. larger number notes, easier accurately
train predictive method. Column 4 shows standard deviation (STD) length
notes domain. likely well-behaved FSM discovered
STD low. successive tables, domains ranked STD. Column 5
presents percentage unique tokens notes. fewer novel tokens note has,
likely successive tokens predicted. measure places upper bound
predictive accuracy. Column 6 shows percentage constant tokens, ones always
appear fixed position. easier predict constant tokens. Finally, Column 7
indicates percentage repeated tokens. fewer tokens repeated verbatim within
note, likely predictive method become confused locale
within note prediction.
first six domains natural interactive note taking task exhibit
regular syntax. last three domains included test softwares ability less
suitable domains. Notes Antihistamine, Lens, Raptor domains contain highlyvariable lists terms natural language sentences. Learned FSMs notes
domains unlikely converge, and, experiments reported here, FSM
Lens data exceeded maturity threshold (average state usage greater 2).
7.1

Contextual Prediction Accuracy

Column 7 Table 13 lists accuracy next-token predictions made software
prompting mode. first nine rows list predictive accuracy tokens notes
nine domains independently processed order collected.
last row lists predictive accuracy tokens notes nine domains collectively processed. simulates user taking notes several domains simultaneously.
put results context, table also lists predictive accuracies several
methods. Column 1 lists accuracy lower bound method. assumes note
shares fixed sequence tokens. Termed common , method initializes structure
79

fiS CHLIMMER & H ERMENS

Domain
Airwing
Pattern
Engine Code
Minivan
PowerBook
Watch
Antihistamine
Lens
Raptor

1
2
3
4
5
6
7
N Notes N Tokens Tokens/Note STD % Unique % Constant % Repeated
78
936
12.0 0.3
18
8
0
13
75
5.8 0.7
21
0
0
20
222
11.1 0.8
0
0
0
22
335
15.2 1.7
9
17
0
95
1238
13.0 2.6
1
31
15
89
832
9.3 5.1
13
0
1
17
421
24.8 9.4
17
8
1
31
1066
34.4 9.6
1
26
19
21
878
41.8 11.5
33
7
22

Table 12: Quantitative properties nine domains used test alternative methods.
first note. removes token sequential structure cannot found
order notes. best, method predict constant, delimiter-like tokens
may appear regularly notes. performance limited percentage constant
tokens reported Column 6 Table 12. performs best PowerBook notes
learns following note syntax:
* :NULL * "K" * " PowerBook" * "MB" * "MB" * " Int." * .

(Example 3)

(The asterisks indicate Kleene star notation.) reads sequence zero
tokens token :NULL, followed zero tokens "K", followed zero
tokens "PowerBook", on. less successful minivan notes
learns simpler syntax:
* :NULL * "K" * " MI" * " Pass" * .

(Example 4)

Columns 2 3 Table 13 list accuracy using classifier directly predict
next token without explicitly learning syntax. paradigm, examples prefixes
token sequences. Attributes last token sequence, second last token,
third last token, on. Class values next token sequencethe one
predicted. Column 2 lists performance simple Bayes classifier, Column 3 lists
performance incremental variant ID3 (Schlimmer & Fisher, 1986). Perhaps
surprisingly, methods perform considerably worse simple conjunctive method.
Without benefit narrow context provided FSM, methods must implicitly
construct representations detect differences similar situations arise within
single note. example, PowerBook notes, classifier-only approach must learn
discriminate first second occurrence "MB" token.
Column 4 Table 13 lists accuracy viable prediction mechanism. Based
simple ideas memorization termed digram, method maintains list tokens
immediately followed observed token. example, fabric pattern
domain, method retains list tokens {"8-10-12", "10", "11/12", "12"}
follow token "Size". list follow tokens kept order least
frequent. predict next token, system looks last token written predicts
80

fiS OFTWARE GENTS : C OMPLETING P ATTERNS & C ONSTRUCTING U SER NTERFACES

Domain
Airwing
Pattern
Engine Code
Minivan
PowerBook
Watch
Antihistamine
Lens
Raptor
Combined

1
2
3
4
5
Common Bayes ID4 Digram FSM
19
8
8
47
62
25
15 16
34
43
18
8
8
59
64
29
6
7
54
46
40
7
8
73
70
21
10 14
44
39
11
4
6
40
24
22
3
3
68
63
9
2
3
11
12


48
46

6
FSM+Bayes
44
43
63
44
76
33
22
60
9
45

7
8
FSM+ID4 Upper
62
79
51
68
69
87
47
80
82
96
42
78
24
68
63
91
12
55
49


Table 13: Percentage tokens correctly predicted function learning
method.
frequent follow token. method nearly effective Table 13,
especially combined task notes domain entered random order.
Laird (1992) describes efficient algorithm maintaining higher-dimensional n-grams,
effect increasing context prediction effectively memorizing longer sequences
tokens. Lairds algorithm builds Markov tree incorporates heuristics keep
size tree growing excessively large. Regrettably, methods unsuitable
interactive note-taking software difficulty using construct
custom user interface. plausible construct panel exclusive choices based directly
set follow tokens, unclear identify optional choices corresponding
loops finite-state machines. Moreover, notes drawn different domains,
domains share even single token, follow set include tokens
different domains. Using follow sets construct user interface unnecessarily
confuse user introducing options one domain time.
Column 5 Table 13 lists accuracy prediction based solely learned FSMs.
Without embedded classifier, method must rely prediction common
transition (or termination) state. prediction based simple counts
(as noted Section 4, Learning Embedded Classifiers), method never predicts optional
transitions.
Columns 6 7 Table 13 list accuracy predicting using FSMs embedded
classifiers. classifiers used simple Bayes incremental ID3, respectively.
latter outperforms either FSM alone FSM embedded Bayes classifiers.
system makes predictions confidence measure greater 0.25, accuracy significantly different Engine Code, Minivan, Lens, Raptor domains,
ranging 10 22 percentage points improvement.
Column 8 Table 13 lists estimate upper-bound predictive accuracy.
calculated assuming prediction errors made first time distinct
token written.

81

fiS CHLIMMER & H ERMENS

1
Domain
Airwing
Pattern
Engine Code
Minivan
PowerBook
Watch
Antihistamine
Lens
Raptor

Norm
62
51
69
47
82
42
24
63
12

2
Diff
Tokens
62
51
71
48
80
42
25
66
11

3
Rules
2a,b
63
53
72
48
83
43
24
64
12

4
5
6
7
8
9
10
Rules

Accept Accept Repeat Drop
New IDs
2ab,3a Restart = 1/4
= 3/4
Atts Classr
62
62
62
62
62
61
63
52
50
51
51
51
51
53
69
43
69
69
69
67
72
47
28
47
47
52
45
48
83
77
82
82
81
80
82
43
28
42
42
42
41
43
24
9
24
24
24
24
24
63
46
63
63
63
63
64
12
11
12
12
12
12
12

Table 14: Percentage tokens correctly predicted function design variations.
7.2

Design Decisions

note taking software embodies number design decisions. Table 14 lists effects
decisions predictive accuracy comparing versions software without design feature. first column lists predictive accuracy softwares
nominal configuration. Column 2 lists accuracy data slightly different generic
tokenizer. Accuracy higher domains, lower others. custom-built tokenizer
one way incorporate knowledge domain. Columns 3 4 show accuracy
system using original two FSM merging rules (cf. Table 1)
last merging rule (cf. Table 2), respectively. decreased structural generality tends
lower predictive accuracy, embedded classifiers help compensate reduced
accuracy. Column 5 lists accuracy FSM heuristically continue
parsing upon encountering token immediate transition. expected,
accuracy suffers considerably domains novel token sequence
completely foils subsequent prediction. Columns 6 7 list accuracy different
values free parameter controlling clustering notes together FSM.
little effect predictive accuracy case. Column 8 shows accuracy
embedded classifiers use information repeated states FSM. Without
information, classifiers cannot predict loop transition taken exactly once.
Surprisingly, elimination feature little effect accuracy. Column 9 lists accuracy embedded classifiers associated pair FSM states discarded
states merged. Finally, Column 10 lists accuracy new FSM state
assigned unique ID rather ID oldest two merged states.
7.3

Sample Button-Box Interfaces

addition Figure 3, Figures 11 15 depict button-box interfaces five
well-behaved note taking domains listed top Table 12. interfaces visual
offer user organized view notes, presenting options natural way.
However, whenever unique tokens involved, current software makes attempt
explicitly generalize tokens. effect reflected tour dates Airwing notes
Figure 11. Note radio button panel consists long series dates, none
likely selected new note.
82

fiS OFTWARE GENTS : C OMPLETING P ATTERNS & C ONSTRUCTING U SER NTERFACES

Figure 11: Screen snapshot note-taking software button-box mode
airwing note.

Figure 12: Screen snapshot note-taking software button-box mode
fabric pattern note.

8. Related Work
Self-customizing software agents several subjective dimensions
evaluated compared:
AnticipationDoes system present alternatives without user
request them?
User interfaceIs system graphical, command-line oriented?
User controlCan user override choose ignore predictive actions?
ModalityIf system number working modes, user work
mode without explicitly selecting one them?
Learning updateIs learning incremental, continuous and/or real-time?
83

fiS CHLIMMER & H ERMENS

Figure 13: Screen snapshot note-taking software button-box mode
engine code note.

Figure 14: Screen snapshot note-taking software button-box mode
minivan note.
User adjustableCan user tune system parameters manually?
describe related systems exhibit properties agent dimensions.
note taking software utilizes anticipation user interface technique pioneered
Eager (Cypher, 1991). Eager non-intrusive system learns perform iterative procedures watching user. such, learning apprentice, software agent,
example programming example demonstration. Situated within HyperCard environment, continuously watches users actions. detects second cycle
iteration, presents execute icon users notice. also visually indicates anticipated next action highlighting appropriate button, menu item, text selection
green. user performs task, verify Eager learned correct
84

fiS OFTWARE GENTS : C OMPLETING P ATTERNS & C ONSTRUCTING U SER NTERFACES

Figure 15: Screen snapshot note-taking software button-box mode
watch note.
procedure comparing anticipations actions. user confident enough,
click execution icon, Eager run iterative procedure completion. Eager highly anticipatory, uses graphical interface, non-obtrusive, non-modal,
learns real-time, user adjustable.
CAP apprenticeship system learns predict default values (Dent, et al., 1992).
domain operation calendar management, learns preferences knowledgable
secretary might. example, professor may prefer hold regular group meeting
particular room particular time day particular durationinformation
secretary would know experience. CAP collects information user manages
calendar, learns previous meetings, uses regularities learns offer default
values meeting location, time, duration. learning system re-run night
recent meeting data, learned rules applied prediction following
day. CAP also designed utilize extensible knowledge base contains calendar
information database personnel information. system continues used
manage individual faculty calendars. Though offering intelligence, CAPs user interface line-oriented based Emacs editor. Questions asked user
meetings presented using command-line dialog, default predictions
displayed one-at-a-time. CAP characterized anticipatory, command-line oriented
modal user control (but user adjustable), learning done batch.
Another related system addresses task learning fill form (Hermens &
Schlimmer, 1993). system recreates paper form on-screen facsimile, allowing
user view pertinent information glance. Input typed user electronic form processed central form-filling module. user completes form
copy, printed, field value form forwarded learning module (a decision tree learning method). learned representations predict default values field
form referring values observed fields previous form copy.
users point view, spreadsheet functions learned
field form. Empirical studies indicate system reduced number keystrokes required user 87% 269 forms processed 8 month period

85

fiS CHLIMMER & H ERMENS

actually used office personnel. system unobtrusive, non-modal
anticipatory, uses graphical interface, updates learning real-time.
Maes Kozierok (1993) addressing problem self-customizing software
much task-independent level. identify three learning opportunities software
agent: observing users actions imitating them, receiving user feedback upon error,
incorporating explicit training user. illustrate generality framework, demonstrate simple learning apprentices help sort users electronic mail
schedule meetings. initial systems use instance-based (case- memory-based)
approach primarily allows efficient update naturally generates
confidence predictions. Users may set thresholds predictions, corresponding minimum confidence agent prompt user (a tell-me
threshold) higher minimum confidence agent act immediately behalf
user (a do-it threshold). framework learning case anticipatory, utilizes
graphical user interface, devoted user control, non-modal, learns real-time,
user adjustable.
system developed Macintosh Common Lisp (MCL) provides word-completion
mechanism word prefixes typed user window. J. Salem A. Ruttenberg
(unpublished) devised MCL methods display word completion status bar
window. user desires add completion window, simply press
CLEAR key. word completion mechanism similar file-name completion
EMACS C-shell UNIX systems, except word displayed user
added. system anticipatory (unlike UNIX file completion), command
line oriented (but displays default completion graphical window), fully
controlled user, non-modal, learns real time, intended user adjustable
(though knowledgeable MCL programmers could easily make changes code).
interactive note taking software devised require user programming. receives implicit user feedback user chooses complete note
different way prompted. mechanisms direct user instruction
threshold tuning. system designed easy use paper, explicit adjustment
may inappropriate. characterize system anticipatory, graphically-oriented,
modal (due switching takes place user wishes display button-box
interface). allows user override default prompts predictions, learns
real-time. included features allow user configure performance
agent.

9. Observations/Limitations
interactive note-taking software designed help users capture information digitally,
speed entry improve accuracy, support longer term goal efficient
retrieval. software incorporates two distinctive features. First, actively predicts
user going write. Second, automatically constructs custom radio-button, checkbox user interface.
research explores extremes FSM learning prediction, system
explicit priori knowledge note domains. tried design system
learn quickly, yet adapt well semantic syntactic changes, without
knowledge store draw. clear knowledge form domain-specific tokenizer would aid FSM learning chunking significant phrases relating similar
notations abbreviations. preliminary work shown that, notes
86

fiS OFTWARE GENTS : C OMPLETING P ATTERNS & C ONSTRUCTING U SER NTERFACES

written, users may create abbreviations instead writing whole words. domainspecific tokenizer would able relate abbreviation whole word
class, therefore allow flexibility note taking. example,
domain-specific tokenizer may recognize "Megabytes", "Meg", "MB", "M" represent token memory sizes. One could imagine framework would allow
domain-specific tokenizers simply plugged in.
prototype built demonstrate ideas implemented conventional,
micro computer keyboard input. consequence, impossible evaluate user
acceptance new interface adaptive agent. newly available computing
devices incorporating pen input handwriting recognition, possible reengineer user interface field test ideas actual users.
One aspect note learning, related tokenization button-box user interface
display, difficulty generalizing numeric strings unique tokens. cardinality
range model numbers, telephone numbers, quantities, sizes, numeric values,
even proper names large note domains. finite-state machine learning
method presented incapable generalizing transitions particular state,
and, consequence, current system problem displaying lengthy
button-box interface list. (A button displayed value encountered syntax
notes, may many choices.) example, large variety pattern numbers may
available fabric pattern note domain. appropriate mechanism desired determine list numeric choices large useful button-box interface.
system generalize expected number, indicating number digits prompt
user: ####, example. may helpful remind user number
expected without presenting overbearing list possibilities.
Another limitation current effort lies choice finite-state machines
represent syntax users notes. Notes may regular expressions
consequence FSMs may become large learning method attempts acquire
syntax. may place unreasonable demand memory lead reduced prompting
effectiveness.
choice finite-state machines also apparently constraints custom user interface.
FSMs branch unpredicable ways, button-box interfaces must rendered incrementally. user indicates particular transition (by selecting button), system
render states reachable transition user. Ideally, user able
select buttons corresponding note fragments order, allowing write
size pattern number, example. construct non-modal user interface,
flexible syntactic representation needed.
Several low-level design decisions employed system crude responses
technical issues. instance, decision render syntax button-box interface
average number times state used parse notes greater 2.
ignores fact parts state machine used frequently parsing
notes parts rarely used. Similarly, particular measure estimating prompting confidence (and setting saturation completion button) simplistic
would benefit sound statistical basis.

Acknowledgments
Anonymous reviewers suggested additional example Section 3, offered refinements user interface, graciously identified limitations work listed
87

fiS CHLIMMER & H ERMENS

Section 9, pointed additional related work. Mike Kibler, Karl Hakimian,
EECS staff provided consistent reliable computing environment. Apple Cambridge
developed supports Macintosh Common Lisp programming environment. Allen
Cypher provided tokenizer code. work supported part National
Science Foundation grant number 92-1290 grant Digital Equipment
Corporation.

References
Angluin, D. (1982). Inference reversible languages. Journal Association
Computing Machinery, 29, 741765.
Berwick, R. C., & Pilato, S. (1987). Learning syntax automata induction. Machine Learning, 2, 938.
Bull, J., & Farrand, J., Jr. (1977). Audubon Society Field Guide North American Birds
(Eastern Edition). NY: Alfred A. Knopf (pp. 401682).
Chiltons Repair & Tune-Up Guide: GM X-Body 1980-1985 (1985). Randor, PA: Chilton
Book (p. 7).
Cohen, W. W. (1988). Generalizing number learning multiple examples explanation based learning. Proceedings Fifth International Conference Machine
Learning (pp. 256269). Ann Arbor, MI: Morgan Kaufmann.
Consumer Reports (1988), 53 (12), 302303. Mount Vernon, NY: Consumers Union.
Cypher, A. (1991). Eager: Programming repetitive tasks example. Proceedings CHI
(pp. 3339). New Orleans, LA: ACM.
Dent, L., Boticario, J., McDermott, J., Mitchell, T., & Zabowski, D. (1992). personal
learning apprentice. Proceedings Tenth National Conference Artificial Intelligence (pp. 96103). San Jose, CA: AAAI Press.
Fisher, D. H. (1987). Knowledge acquisition via incremental conceptual clustering. Machine
Learning, 2, 139172.
Grove, M., & Miller, J. (1989). North American Rockwell A3J/A-5 Vigilante. Arlington, TX:
Aerofax (pp. 1315).
Hermens, L. A., & Schlimmer, J. C. (1993). machine-learning apprentice completion repetitive forms. Proceedings Ninth IEEE Conference Artificial Intelligence Applications. Orlando, FL.
Laird, P. (1992). Discrete sequence prediction applications. Proceedings Tenth
National Conference Artificial Intelligence (pp. 135140). San Jose, CA: AAAI Press.

88

fiS OFTWARE GENTS : C OMPLETING P ATTERNS & C ONSTRUCTING U SER NTERFACES

Maes, P., & Kozierok, R. (1993). Learning interface agents. Proceedings Eleventh
National Conference Artificial Intelligence (pp. 459465). Washington, D. C.: AAAI
Press.
Nurses Guide Drugs (1979). Horsham, PA: Intermed Communications (pp. 454462).
Schlimmer, J. C., & Fisher, D. H. (1986). case study incremental concept induction.
Proceedings Fifth National Conference Artificial Intelligence (pp. 496501).
Philadelphia, PA: AAAI Press.

89

fiJournal Artificial Intelligence Research 1 (1993) 25-46

Submitted 7/93; published 8/93

Dynamic Backtracking
Matthew L. Ginsberg

ginsberg@cs.uoregon.edu

CIRL, University Oregon,
Eugene, 97403-1269 USA

Abstract

occasional need return shallow points search tree, existing
backtracking methods sometimes erase meaningful progress toward solving search
problem. paper, present method backtrack points moved
deeper search space, thereby avoiding diculty. technique developed
variant dependency-directed backtracking uses polynomial space still
providing useful control information retaining completeness guarantees provided
earlier approaches.

1. Introduction
Imagine trying solve constraint-satisfaction problem, csp.
interests definiteness, suppose csp question involves coloring map
United States subject restriction adjacent states colored differently.
Imagine begin coloring states along Mississippi, thereby splitting
remaining problem two. begin color states western half
country, coloring perhaps half dozen deciding likely able
color rest. Suppose also last state colored Arizona.
point, change focus eastern half country. all, can't
color eastern half coloring choices states along Mississippi,
point wasting time completing coloring western states.
successfully color eastern states return west. Unfortunately,
color New Mexico Utah get stuck, unable color (say) Nevada. What's more,
backtracking doesn't help, least sense changing colors New Mexico
Utah alone allow us proceed farther. Depth-first search would
us backtrack eastern states, trying new color (say) New York vain hope
would solve problems West.
obviously pointless; blockade along Mississippi makes impossible
New York impact attempt color Nevada western states.
What's more, likely examine every possible coloring eastern states
addressing problem actually source diculties.
solutions proposed involve finding ways backtrack directly
state might actually allow us make progress, case Arizona earlier.
Dependency-directed backtracking (Stallman & Sussman, 1977) involves direct backtrack
source diculty; backjumping (Gaschnig, 1979) avoids computational overhead technique using syntactic methods estimate point backtrack
necessary.

c 1993 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.

fiGinsberg

cases, however, note although backtrack source problem,
backtrack successful solution half original problem, discarding
solution problem coloring states East. again, problem
worse { recolor Arizona, danger solving East yet
realizing new choice Arizona needs changed all. won't
examine every possible coloring eastern states, danger rediscovering
successful coloring exponential number times.
hardly seems sensible; human problem solver working problem would
simply ignore East possible, returning directly Arizona proceeding.
states along Mississippi needed new colors would East reconsidered { even
new coloring could found Mississippi consistent
eastern solution.
paper formalize technique, presenting modification conventional
search techniques capable backtracking recently expanded
node, also directly node elsewhere search tree. dynamic way
search structured, refer technique dynamic backtracking.
specific outline follows: begin next section introducing
variety notational conventions allow us cast existing work new
ideas uniform computational setting. Section 3 discusses backjumping, intermediate
simple chronological backtracking ideas, presented
Section 4. example dynamic backtracking algorithm use appears Section
5 experimental analysis technique Section 6. summary results
suggestions future work Section 7. proofs deferred appendix
interests continuity exposition.

2. Preliminaries
Definition 2.1 constraint satisfaction problem (I; V; ) mean set vari-

ables; 2 , set Vi possible values variable i. set
constraints, pair (J; P ) J = (j1; . . . ; jk ) ordered subset P
subset Vj1 Vjk .
solution csp set vi values variables vi 2 Vi
every constraint (J; P ) form , (vj1 ; . . . ; vjk ) 2 P .

example introduction, set states Vi set possible
colors state i. constraint, first part constraint pair adjacent
states second part set allowable color combinations states.
basic plan paper present formal versions search algorithms
described introduction, beginning simple depth-first search proceeding
backjumping dynamic backtracking. start, make following definition
partial solution csp:

Definition 2.2 Let (I; V; ) csp. partial solution csp mean ordered
subset J assignment value variable J .
26

fiDynamic Backtracking

denote partial solution tuple ordered pairs, ordered pair

(i; v ) assigns value v variable i. partial solution P , denote P
set variables assigned values P .

Constraint-satisfaction problems solved practice taking partial solutions
extending assigning values new variables. general, course, value
assigned variable inconsistent constraints. therefore
make following definition:

Definition 2.3 Given partial solution P

csp, eliminating explanation
variable pair (v; ) v 2 Vi P . intended meaning
cannot take value v values already assigned P variables .
elimination mechanism csp function accepts arguments partial
solution P , variable 62 P . function returns (possibly empty) set (P; i)
eliminating explanations i.

set E eliminating explanations, denote Eb values
identified eliminated, ignoring reasons given. therefore denote b(P; i) set
values eliminated elements (P; i).
Note definition somewhat exible regard amount work
done elimination mechanism { values violate completed constraints might
eliminated, amount lookahead might done. will, however, make
following assumptions elimination mechanisms:
1. correct. partial solution P , value vi 62 b(P; i), every
constraint (S; ) P [fig satisfied values partial solution
value vi i. constraints complete value vi
assigned i.
2. complete. Suppose P partial solution csp,
solution extends P assigning value v i. P 0 extension P
(v; E ) 2 (P 0 ; i),
E \ (P 0 , P ) 6=
(1)
words, whenever P successfully extended assigning v
P 0 cannot be, least one element P 0 , P identified possible reason
problem.
3. concise. partial solution P , variable eliminated value v ,
single element form (v; E ) 2 (P; i). one reason given
variable cannot value v .

Lemma 2.4 Let complete elimination mechanism csp, let P partial solution csp let 62 P . P successfully extended complete solution
assigning value v , v 62 b(P; i).
apologize swarm definitions, allow us give clean description
depth-first search:
27

fiGinsberg

Algorithm 2.5 (Depth-first search) Given inputs constraint-satisfaction problem

elimination mechanism :
1. Set P = . P partial solution csp. Set Ei = 2 ; Ei
set values eliminated variable i.
2. P = , P assigns value every element , solution
original problem. Return it. Otherwise, select variable 2 , P . Set Ei = b(P; i),
values eliminated possible choices i.
3. Set = Vi , Ei, set remaining possibilities i. nonempty, choose
element v 2 . Add (i; v ) P , thereby setting i's value v , return step 2.
4. empty, let (j; vj ) last entry P ; entry, return failure.
Remove (j; vj ) P , add vj Ej , set = j return step 3.

written algorithm returns single answer csp; modification accumulate answers straightforward.
problem Algorithm 2.5 looks little like conventional depth-first
search, since instead recording unexpanded children particular node,
keeping track failed siblings node. following:

Lemma 2.6 point execution Algorithm 2.5, last element partial
solution P assigns value variable i, unexplored siblings current node
assign values Vi , Ei .
Proposition 2.7 Algorithm 2.5 equivalent depth-first search therefore complete.

remarked, basic difference Algorithm 2.5 conventional description depth-first search inclusion elimination sets Ei.
conventional description expects nodes include pointers back parents; siblings given node found examining children node's parent. Since
reorganizing space search, impractical framework.
might seem natural solution diculty would record
values eliminated variable i, remain considered.
technical reason done much easier maintain
elimination information search progresses. understand intuitive level,
note search backtracks, conclusion implicitly drawn
particular node fails expand solution, opposed conclusion
currently unexplored portion search space. little surprise
ecient way manipulate information recording approximately form.

3. Backjumping

describe dependency-directed backtracking backjumping setting?
cases, partial solution forced backtrack;
sophisticated backtracking mechanisms use information reason failure
identify backtrack points might allow problem addressed. start, need
modify Algorithm 2.5 maintain explanations eliminated values:
28

fiDynamic Backtracking

Algorithm 3.1 Given inputs constraint-satisfaction problem elimination mechanism :
1. Set P = Ei = 2 . Ei set eliminating explanations i.
2. P = , return P . Otherwise, select variable 2 , P . Set Ei = (P; i):
3. Set = Vi , Ebi. nonempty, choose element v 2 . Add (i; v ) P
return step 2.
4. empty, let (j; vj ) last entry P ; entry, return failure.
Remove (j; vj ) P . must Ebi = Vi, every value
eliminated; let E set variables appearing explanations
eliminated value. Add (vj ; E , fj g) Ej , set = j return step 3.

Lemma 3.2 Let P partial solution obtained execution Algorithm 3.1,

let 2 P variable assigned value P . P 0 P successfully
extended complete solution assigning value v (v; E ) 2 Ei , must

E \ (P , P 0) 6=

words, assignment value variable P , P 0 correctly identified
source problem.
Note step 4 algorithm, could added (vj ; E \ P ) instead (vj ; E ,
fj g) Ej ; either way, idea remove E variables longer assigned
values P .
backjumping, simply change backtrack method; instead removing
single entry P returning variable assigned value prior problematic
variable i, return variable actually impact i. words,
return variable set E .

Algorithm 3.3 (Backjumping) Given inputs constraint-satisfaction problem
elimination mechanism :
1. Set P = Ei = 2 .

2. P = , return P . Otherwise, select variable 2 , P . Set Ei = (P; i):
3. Set = Vi , Ebi. nonempty, choose element v 2 . Add (i; v ) P
return step 2.
4. empty, must Ebi = Vi . Let E set variables appearing
explanations eliminated value.
5. E = , return failure. Otherwise, let (j; vj ) last entry P j 2 E .
Remove P entry entry following it. Add (vj ; E \ P ) Ej , set = j
return step 3.
29

fiGinsberg

step 5, add (vj ; E \ P ) Ej , removing E variables longer
assigned values P .

Proposition 3.4 Backjumping complete always expands fewer nodes depthfirst search.

Let us look map-coloring example. partial coloring
P looking specific state i, suppose denote C set colors
obviously illegal con ict color already assigned one i's
neighbors.
One possible elimination mechanism returns (P; i) list (c; P ) color
c 2 C used color neighbor i. reproduces depth-first search, since
gradually try possible colors idea went wrong need
backtrack since every colored state included P . far sensible choice would take
(P; i) list (c; fng) n neighbor already colored c. would
ensure backjump neighbor coloring found.
causes us backjump another state j , add i's neighbors eliminating explanation j 's original color, need backtrack still further,
consider neighbors either j . be, since changing color one
i's neighbors might allow us solve coloring problem reverting original
choice color state j .
also have:

Proposition 3.5 amount space needed backjumping o(i2v), = jI j

number variables problem v number values variable
largest value set Vi .

result contrasts sharply approach csps relies truth-maintenance
techniques maintain list nogoods (de Kleer, 1986). There, number nogoods
found grow linearly time taken analysis, typically
exponential size problem. Backjumping avoids problem resetting
set Ei eliminating explanations step 2 Algorithm 3.3.
description given quite similar developed (Bruynooghe,
1981). explanations somewhat coarser ours, listing variables
involved eliminating explanation particular variable csp,
idea essentially same. Bruynooghe's eliminating explanations stored
o(i2) space (instead o(i2v )), associated loss information makes technique
less effective practice. earlier work also description backjumping only, since
intermediate information erased search proceeds.

4. Dynamic backtracking

finally turn new results. basic problem Algorithm 3.3 backjumps wrong place, needlessly erases great deal work
done thus far. least, retain values selected variables
backjumped over, sense moving backjump variable end partial
30

fiDynamic Backtracking

solution order replace value without modifying values variables
followed it.
additional modification probably clearest return
example introduction. Suppose example, color eastern
states returning western half country. reorder variables order
backtrack Arizona eventually succeed coloring West without disturbing
colors used East.
Unfortunately, return East backtracking required find
needing change coloring eastern states dealt earlier.
ideas presented allow us avoid erasing solution problems
West, search eastern states ecient, need
retain information portion East's search space
eliminated. all, determined New York cannot colored yellow,
changes West reverse conclusion { Mississippi really isolate one
section country other.
machinery needed capture sort reasoning already place.
backjump variable k, retain choice value k, also k's
elimination set. do, however, need remove elimination set entry
involves eventual backtrack variable j , since entries longer valid {
depend assumption j takes old value, assumption false.

Algorithm 4.1 (Dynamic backtracking I) Given inputs constraint-satisfaction problem elimination mechanism :
1. Set P = Ei = 2 .
2. P = , return P . Otherwise, select variable 2 , P . Set Ei = Ei [ (P; i).
3. Set = Vi , Ebi. nonempty, choose element v 2 . Add (i; v ) P
return step 2.
4. empty, must Ebi = Vi ; let E set variables appearing
explanations eliminated value.
5. E = , return failure. Otherwise, let (j; vj ) last entry P j 2 E .
Remove (j; vj ) P and, variable k assigned value j , remove
Ek eliminating explanation involves j . Set

Ej = Ej [ (P; j ) [ f(vj ; E \ P )g
(2)
vj eliminated value j values taken variables
E \ P . inclusion term (P; j ) incorporates new information variables
assigned values since original assignment vj j . set = j
return step 3.

Theorem 4.2 Dynamic backtracking always terminates complete. continues

satisfy Proposition 3.5 expected expand fewer nodes backjumping provided
goal nodes distributed randomly search space.
31

fiGinsberg

essential difference dynamic dependency-directed backtracking
structure eliminating explanations means save nogood information
based current values assigned variables; nogood depends outdated information, drop it. this, avoid need retain exponential amount
nogood information. makes technique valuable (as stated theorem)
termination still guaranteed.
one trivial modification make Algorithm 4.1 quite useful
practice. removing current value backtrack variable j , Algorithm 4.1
immediately replaces another. real reason this; could
instead pick value entirely different variable:

Algorithm 4.3 (Dynamic backtracking) Given inputs constraint-satisfaction problem elimination mechanism :
1. Set P = Ei = 2 .
2. P = , return P . Otherwise, select variable 2 , P . Set Ei = Ei [ (P; i).
3. Set = Vi , Ebi. nonempty, choose element v 2 . Add (i; v ) P
return step 2.
4. empty, must Ebi = Vi ; let E set variables appearing
explanations eliminated value.
5. E = , return failure. Otherwise, let (j; vj ) last entry P binds
variable appearing E . Remove (j; vj ) P and, variable k assigned
value j , remove Ek eliminating explanation involves j . Add
(vj ; E \ P ) Ej return step 2.

5. example
order make Algorithm 4.3 bit clearer, suppose consider small mapcoloring problem detail. map shown Figure 1 consists five countries:
Albania, Bulgaria, Czechoslovakia, Denmark England. assume (wrongly!)
countries border shown figure, countries denoted nodes
border one another arc connecting them.
coloring map, use three colors red, yellow blue. typically
abbreviate country names single letters obvious way.
begin search Albania, deciding (say) color red. look
Bulgaria, colors eliminated Albania Bulgaria share border;
decide color Bulgaria yellow. (This mistake.)
go consider Czechoslovakia; since borders Albania, color red
eliminated. decide color Czechoslovakia blue situation this:
32

fiDynamic Backtracking

Denmark




Czechoslovakia

,,@@
,
@@
,
,
@
,
@@
,
Albanias,
@,sBulgaria
@@
,
,
@@
,
,
@
,
@@ ,
@,s
England

Figure 1: small map-coloring problem
country
color red yellow blue
Albania
red
Bulgaria
yellow
Czechoslovakia blue
Denmark
England
country, indicate current color eliminating explanations mean
cannot colored three colors (when explanations exist). look
Denmark.
Denmark cannot colored red border Albania cannot colored
yellow border Bulgaria; must therefore colored blue.
England cannot colored color borders Albania, Bulgaria
Denmark, therefore need backtrack one three countries.
point, elimination lists follows:
country
color red yellow blue
Albania
red
Bulgaria
yellow
Czechoslovakia blue
Denmark
blue
B
England

B

backtrack Denmark recent three possibilities,
begin removing eliminating explanation involving Denmark table
get:
33

fiGinsberg

color red yellow blue
country
Albania
red
Bulgaria
yellow
Czechoslovakia blue
Denmark

B
England

B
Next, add Denmark's elimination list pair
(blue; fA; B g)
indicates correctly current colors Albania Bulgaria, Denmark cannot colored blue (because subsequent dead end England). Since every
color eliminated, must backtrack country set fA; B g. Changing
Czechoslovakia's color won't help must deal Bulgaria instead. elimination
lists now:
country
color red yellow blue
Albania
red
Bulgaria
Czechoslovakia blue
Denmark

B A,B
England

B
remove eliminating explanations involving Bulgaria also add Bulgaria's elimination list pair
(yellow; A)
indicating correctly Bulgaria cannot colored yellow current choice
color Albania (red).
situation now:
color red yellow blue
country
Albania
red
Czechoslovakia blue
Bulgaria

Denmark

England

moved Bulgaria past Czechoslovakia ect search reordering algorithm. complete problem coloring Bulgaria red, Denmark either yellow
blue, England color used Denmark.
example almost trivially simple, course; thing note
changed color Bulgaria, retained blue color Czechoslovakia
information indicating none Czechoslovakia, Denmark England could red.
complex examples, information may hard-won retaining may
save us great deal subsequent search effort.
Another feature specific example (and example introduction
well) computational benefits dynamic backtracking consequence
34

fiDynamic Backtracking

automatic realization problem splits disjoint subproblems. authors
also discussed idea applying divide-and-conquer techniques csps (Seidel, 1981;
Zabih, 1990), methods suffer disadvantage constrain order
unassigned variables assigned values, perhaps odds common heuristic
assigning values first variables tightly constrained. Dynamic
backtracking also expected use situations problem question
split two disjoint subproblems.1

6. Experimentation

Dynamic backtracking incorporated crossword-puzzle generation program
described (Ginsberg, Frank, Halpin, & Torrance, 1990), leads significant performance improvements restricted domain. specifically, method tested
problem generating 19 puzzles sizes ranging 2 2 13 13; puzzle
attempted 100 times using dynamic backtracking simple backjumping.
dictionary shued solution attempts maximum 1000 backtracks
permitted program deemed failed.
cases, algorithms extended include iterative broadening (Ginsberg
& Harvey, 1992), cheapest-first heuristic forward checking. Cheapest-first
also called \most constrained first" selects instantiation variable
fewest number remaining possibilities (i.e., variable cheapest
enumerate possible values (Smith & Genesereth, 1985)). Forward checking prunes
set possibilities crossing words whenever new word entered constitutes
experimental choice elimination mechanism: point, words legal
crossing word eliminated. ensures word entered crossword
word potential crossing words point. cheapest-first heuristic
would identify problem next step search, forward checking reduces
number backtracks substantially. \least-constraining" heuristic (Ginsberg et al.,
1990) used; heuristic suggests word slot filled word
minimally constrains subsequent search. heuristic used would
invalidate technique shuing dictionary solution attempts order
gather useful statistics.
table Figure 2 indicates number successful solution attempts (out 100)
two methods 19 crossword frames. Dynamic backtracking
successful six cases less successful none.
regard number nodes expanded two methods, consider data
presented Figure 3, graph average number backtracks needed
two methods.2 Although initially comparable, dynamic backtracking provides increasing
computational savings problems become dicult. somewhat broader set
experiments described (Jonsson & Ginsberg, 1993) leads similar conclusions.
examples (Jonsson & Ginsberg, 1993) dynamic backtracking
leads performance degradation, however; typical case appears Figure 4.3
1. indebted David McAllester observations.
2. 17 points shown point plotted backjumping unable solve problem.
3. worst performance degradation observed factor approximately 4.

35

fiGinsberg

Dynamic
Dynamic
Frame backtracking Backjumping Frame backtracking Backjumping
1
100
100
11
100
98
100
100
12
100
100
2
3
100
100
13
100
100
100
100
14
100
100
4
5
100
100
15
99
14
100
100
16
100
26
6
7
100
100
17
100
30
100
100
18
61
0
8
9
100
100
19
10
0
10
100
100
Figure 2: Number problems solved successfully

400
r
r

dynamic 200
backtracking

r
r

r rr
rrr
rr

r
r

rr

200

400
600
backjumping

Figure 3: Number backtracks needed

36

800

1000

fiDynamic Backtracking

Region
1


,,
,
,
,
,
,
B
sa
s,
@@
aaaa
aaa
aaa @@
aaa @
aa@a
@a@s

Region 2

Figure 4: dicult problem dynamic backtracking
figure, first color A, B , countries region 1, get stuck region
2.
presumably backtrack directly B , leaving coloring region 1 alone.
may well mistake { colors region 1 restrict choices B , perhaps
making subproblem consisting A, B region 2 dicult might be.
region 1 easy color, would better erasing even though didn't
need to.
analysis suggests dependency-directed backtracking also fare worse
coloring problems dynamic backtracking trouble, currently
extending experiments (Jonsson & Ginsberg, 1993) confirm this. conjecture
borne out, variety solutions come mind. might, example, record
many backtracks made node B figure, use
determine exibility B important retaining choices made region
1. diculty finding coloring region 1 also determined number
backtracks involved search.

7. Summary
7.1 works
two separate ideas exploited development Algorithm 4.3
others leading it. first, easily important, notion
possible modify variable order way allows us retain
results earlier work backtracking variable assigned value early
search.
37

fiGinsberg

reordering confused work authors suggested
dynamic choice among variables remain assigned values (Dechter & Meiri,
1989; Ginsberg et al., 1990; P. Purdom & Robertson, 1981; Zabih & McAllester, 1988);
instead reordering variables assigned values search thus far.
Another way look idea found way \erase" value given
variable directly opposed backtracking it. idea also explored
Minton et.al. (Minton, Johnston, Philips, & Laird, 1990) Selman et.al.
(Selman, Levesque, & Mitchell, 1992); authors also directly replace values assigned
variables satisfiability problems. Unfortunately, heuristic repair method used
incomplete dependency information retained one state problem
solver next.
third way view well. space examining really
graph, opposed tree; reach point coloring Albania blue
Bulgaria red color opposite order. decide backjump
particular node search space, know need back particular
property node ceases hold { key idea backtracking along
path one node generated, may able backtrack
slightly would otherwise need retreat great deal. observation
interesting may well apply problems csps. Unfortunately,
clear guarantee completeness search discovers node using one path
backtracks using another.
idea less novel. already remarked, use eliminating
explanations quite similar use nogoods atms community; principal
difference attach explanations variables impact drop
cease relevant. (They might become relevant later, course.)
avoids prohibitive space requirements systems permanently cache results
nogood calculations; observation also may extensible beyond domain
csps specifically. Again, ways view { Gashnig's notion backmarking
(Gaschnig, 1979) records similar information reason particular portions
search space known contain solutions.

7.2 Future work
variety ways techniques presented extended;
section, sketch obvious ones.
7.2.1 Backtracking older culprits

One extension work involves lifting restriction Algorithm 4.3 variable
erased always recently assigned member set E .
general, cannot retaining completeness search. Consider
following example:
Imagine csp involves three variables, x, z , take value 0
1. Further, suppose csp solutions, pick two values
x , realize suitable choice z .
38

fiDynamic Backtracking

begin taking x = = 0; realize need backtrack, introduce
nogood
x = 0 6= 0
(3)
replace value = 1.
fails, too, suppose decide backtrack x, introducing
new nogood
= 1 x 6= 0
(4)
change x's value 1 erase (3).
also fails. decide problem change value 0, introducing
nogood
x = 1 6= 1
erasing (4). fails, danger returning x = = 0,
eliminated beginning example. loop may cause modified version
dynamic backtracking algorithm fail terminate.
terms proof Theorem 4.2, nogoods discovered already include information
assigned variables, difference (7) (8). drop
(3) favor (4), longer position recover (3).
deal placing conditions variables choose
backtrack; conditions need defined proof Theorem 4.2 continues
hold.4 Experimentation indicates loops form described extremely
rare practice; may also possible detect directly thereby retain
substantial freedom choice backtrack point.
freedom backtrack raises important question yet addressed
literature: backtracking avoid diculty sort, one
backtrack?
Previous work constrained backtrack recent choice
might impact problem question; decision would incomplete
inecient. Although extension Algorithm 4.3 need operate restriction,
given indication backtrack point selected.
several easily identified factors expected bear choice.
first remains reason expect backtracking chronologically recent
choices effective { choices expected contributed
fewest eliminating explanations, obvious advantage retaining many
eliminating explanations possible one point search next. possible, however, simply identify backtrack point affects fewest number
eliminating explanations use that.
Alternatively, might important backtrack choice point
many new choices possible; extreme example, variable
every value current one already eliminated
reasons, backtracking guaranteed generate another backtrack immediately
probably avoided possible.
4. Another solution appears (McAllester, 1993).

39

fiGinsberg

Finally, measure \directness" variable bears
problem. unable find value particular variable i, probably sensible
backtrack second variable shares constraint itself, opposed
variable affects indirectly.
competing considerations weighed? idea. framework developed interesting allows us work question.
basic terms, \debug" partial solutions csps directly, moving laterally
search space attempt remain close solution possible.
sort lateral movement seems central human solution dicult search problems,
encouraging begin understand formal way.
7.2.2 Dependency pruning

often case one value variable eliminated solving csp,
others eliminated well. example, solving scheduling problem particular
choice time (say = 16) may eliminated task isn't enough
time subsequent task B ; case, later times obviously
eliminated well.
Formalizing subtle; all, later time isn't uniformly worse
earlier time may tasks need precede making later
makes part schedule easier. It's problem B alone forces
earlier; again, analysis depends ability maintain dependency information
search proceeds.
formalize follows. Given csp (I; V; ), suppose value v
assigned 2 . construct new csp (I 0; V 0 ; 0) involving
remaining variables 0 = ,fig, new set V 0 need mention possible values
Vi i, 0 generated modifying constraints indicate
assigned value v . also make following definition:

Definition 7.1 Given csp, suppose variable two possible values u

v. say v stricter u every constraint csp induced assigning
u also constraint csp induced assigning value v.
point, course, v stricter u is, point trying
solution involving v u eliminated. all, finding solution would
involve satisfying constraints v restriction, superset
u restriction, unable satisfy constraints u restriction originally.
example began section generalizes following:

Proposition 7.2 Suppose csp involves set variables,
partial solution assigns values variables subset P . Suppose
extend partial solution assigning value u variable 62 P ,
extension solution entire csp. consider csp involving
variables , P induced choices values variables P . v stricter
u choice value problem, original csp solution
assigns v extends given partial solution P .
40

fiDynamic Backtracking

proposition isn't quite enough; earlier example, choice = 17
stricter = 16 task needs scheduled is.
need record fact B (which longer assigned value) source
diculty. this, need augment dependency information
working.
precisely, say set variables fxi g eliminates value v variable
x, mean search date allowed us conclude
(v1 = x1) ^ ^ (vk = xk ) v 6= x
vi current choices xi . obviously rewrite
(v1 = x1 ) ^ ^ (vk = xk ) ^ (v = x) F
(5)
F indicates csp question solution.
Let's specific still, indicating (5) exactly csp solution:
(v1 = x1 ) ^ ^ (vk = xk ) ^ (v = x) F (I )
(6)
set variables complete csp.
address example began section; csp
known fail expression (6) entire problem, subset it.
example, considering, subproblem involves two tasks B .
general, augment nogoods include information subproblems
fail, measure strictness respect restricted subproblems
only. example, indeed allow us eliminate = 17 consideration
possible time A.
additional information stored nogoods doubles size (we store
second subset variables csp), variable sets involved manipulated
easily search proceeds. cost involved employing technique therefore
strictness computation. may substantial given data structures currently
used represent csps (which typically support need check constraint
violated little more), seems likely compile-time modifications data
structures used make strictness question easier answer. scheduling
problems, preliminary experimental work shows idea important one; here,
too, much done.
basic lesson dynamic backtracking retaining nogoods
still relevant given partial solution working, storage diculties
encountered full dependency-directed methods alleviated. makes
ideas proposed possible { erasing values, selecting alternate backtrack
points, dependency pruning. surely many effective uses practical
dependency maintenance system well.

Acknowledgements
work supported Air Force Oce Scientific Research grant
number 92-0693 DARPA/Rome Labs grant number F30602-91-C-0036.
41

fiGinsberg

would like thank Rina Dechter, Mark Fox, Geddis, Harvey, Vipin Kumar,
Scott Roy Narinder Singh helpful comments ideas. Ari Jonsson
David McAllester provided invaluable assistance experimentation proofs
respectively.

A. Proofs
Lemma 2.4 Let complete elimination mechanism csp, let P partial solution

csp let 62 P . P successfully extended complete solution
assigning value v , v 62 b(P; i).

Proof. Suppose otherwise, (v; E ) 2 (P; i). follows directly completeness


E \ (P , P ) 6=

contradiction.

Lemma 2.6 point execution Algorithm 2.5, last element partial

solution P assigns value variable i, unexplored siblings current node
assign values Vi , Ei .

Proof. first note decide assign value new variable step 2

algorithm, take Ei = b(P; i) Vi , Ei set allowed values
variable. lemma therefore holds case. fact continues hold
repetition loop steps 3 4 simple induction; point,
add Ei node failed possible value assigned i.

Proposition 2.7 Algorithm 2.5 equivalent depth-first search therefore complete.
Proof. easy consequence lemma. Partial solutions correspond nodes

search space.
Lemma 3.2 Let P partial solution obtained execution Algorithm 3.1,
let 2 P variable assigned value P . P 0 P successfully extended
complete solution assigning value v (v; E ) 2 Ei , must

E \ (P , P 0) 6=

Proof. proof Lemma 2.6, show step Algorithm 3.1 cause
Lemma 3.2 become false.
lemma holds step 2, search extended consider new
variable, immediate consequence assumption elimination mechanism
complete.
step 4, add (vj ; E , fj g) set eliminating explanations j ,
simply recording fact search solution j set vj failed
unable extend solution i. consequence inductive hypothesis
long variable E , fj g changes, conclusion remain valid.
Proposition 3.4 Backjumping complete always expands fewer nodes depthfirst search.

42

fiDynamic Backtracking

Proof. fewer nodes examined clear; completeness, follows Lemma
3.2 backtrack element E step 5 always necessary solution
found.
Proposition 3.5 amount space needed backjumping o(i2v), = jI j
number variables problem v number values variable
largest value set Vi .
Proof. amount space needed dominated storage requirements elimination sets Ej ; these. one might refer possible values
particular variable j ; space needed store reason value j eliminated
jI j, since reason simply list variables assigned values.
never two eliminating explanations variable, since concise
never rebind variable value eliminated.
Theorem 4.2 Dynamic backtracking always terminates complete. continues

satisfy Proposition 3.5 expected expand fewer nodes backjumping provided
goal nodes distributed randomly search space.

Proof. four things need show: dynamic backtracking needs o(i2v)

space, complete, expected expand fewer nodes backjumping,
terminates. prove things order.
Space clear; amount space needed continues bounded structure
eliminating explanations.
Completeness also clear, since Lemma 3.2, eliminating explanations
retained algorithm obviously still valid. new explanations added (2)
also obviously correct, since indicate j cannot take value vj backjumping
j also cannot take values eliminated variables backjumped
over.
Eciency see expect expand fewer nodes, suppose subproblem
involving variables jumped solutions total, one given
existing variable assignments. Assuming solutions distributed randomly
search space, least 1=s chance particular solution leads
solution entire csp; so, reordered search { considers solution earlier
{ save expense either assigning new values variables
repeating search led existing choices. reordered search also benefit
information nogoods retained variables jumped
over.
Termination dicult part proof.
work algorithm, generating (and discarding) variety
eliminating explanations. Suppose e explanation, saying j cannot
take value vj values currently taken variables set eV .
denote variables eV x1 ; . . . ; xk current values v1; . . . ; vk .
declarative terms, eliminating explanation telling us
(x1 = v1) ^ ^ (xk = vk ) j 6= vj
43

(7)

fiGinsberg

Dependency-directed backtracking would us accumulate nogoods; dynamic
backtracking allows us drop particular instance (7) antecedent
longer valid.
reason dependency-directed backtracking guaranteed terminate
set accumulated nogoods eliminates monotonically increasing amount search
space. nogood eliminates new section search space nature
search process node examined consistent nogoods
accumulated thus far; process monotonic nogoods retained throughout
search. arguments cannot applied dynamic backtracking, since nogoods
forgotten search proceeds. make analogous argument.
this, suppose discover nogood like (7), record
variables precede variable j partial order, together values currently
assigned variables. Thus eliminating explanation becomes essentially nogood
n form (7) together set variable/value pairs.
define mapping (n; ) changes antecedent (7) include assumptions variables bound , = fsi ; vi g,

(n; ) = [(s1 = v1) ^ ^ (sl = vl) j 6= vj ]

(8)

point execution algorithm, denote N conjunction
modified nogoods form (8).
make following claims:
1. eliminating explanation (n; ), n j= (n; ) (n; ) valid
problem hand.
2. new eliminating explanation (n; ), (n; ) consequence N .
3. deductive consequences N grow monotonically dynamic backtracking
algorithm proceeds.
theorem follow three observations, since know N valid
set conclusions search problem making monotonic
progress toward eliminating entire search space concluding problem
unsolvable.
(n; ) consequence (n; ) clear, since modification used obtain
(8) (7) involves strengthening antecedent (7). also clear (n; )
consequence nogoods already obtained, since added antecedent
conditions hold node search space currently examination.
(n; ) consequence nogoods obtained thus far, node would
considered.
last observation depends following lemma:

Lemma A.1 Suppose x variable assigned value partial solution

x appears antecedent nogood n pair (n; ). 0 set
variables assigned values later x, 0 .
44

fiDynamic Backtracking

Proof. Consider 2 0, suppose . cannot = x, since

would mentioned nogood n therefore . suppose
actually assigned value earlier x is. (n; ) added set
eliminating explanations, must case x assigned value (since
appears antecedent n) not. also know
later time assigned value x not, since precedes x current
partial solution. means x must changed value point (n; )
added set eliminating explanations { (n; ) would deleted
happened. contradiction completes proof.
Returning proof Theorem 4.2, suppose eventually drop (n; )
collection nogoods so, new nogood added (n0; 0).
follows lemma 0 . Since xi = vi clause antecedent (n; ),
follows (n0 ; 0) imply negation antecedent (n; ) therefore
imply (n; ) itself. Although drop (n; ) drop nogood (n; ), (n; )
continues entailed modified set N , consequences seen
growing monotonically.

References

Bruynooghe, M. (1981). Solving combinatorial search problems intelligent backtracking.
Information Processing Letters, 12 (1), 36{39.
de Kleer, J. (1986). assumption-based truth maintenance system. Artificial Intelligence,
28, 127{162.
Dechter, R., & Meiri, I. (1989). Experimental evaluation preprocessing techniques
constraint satisfaction problems. Proceedings Eleventh International Joint
Conference Artificial Intelligence, pp. 271{277.
Gaschnig, J. (1979). Performance measurement analysis certain search algorithms.
Tech. rep. CMU-CS-79-124, Carnegie-Mellon University.
Ginsberg, M. L., Frank, M., Halpin, M. P., & Torrance, M. C. (1990). Search lessons learned
crossword puzzles. Proceedings Eighth National Conference Artificial
Intelligence, pp. 210{215.
Ginsberg, M. L., & Harvey, W. D. (1992). Iterative broadening. Artificial Intelligence, 55,
367{383.
Jonsson, A. K., & Ginsberg, M. L. (1993). Experimenting new systematic nonsystematic search techniques. Proceedings AAAI Spring Symposium AI
NP-Hard Problems Stanford, California.
McAllester, D. A. (1993). Partial order backtracking. Journal Artificial Intelligence
Research, 1. Submitted.
Minton, S., Johnston, M. D., Philips, A. B., & Laird, P. (1990). Solving large-scale constraint satisfaction scheduling problems using heuristic repair method. Proceedings Eighth National Conference Artificial Intelligence, pp. 17{24.
45

fiGinsberg

P. Purdom, C. B., & Robertson, E. (1981). Backtracking multi-level dynamic search
rearrangement. Acta Informatica, 15, 99{114.
Seidel, R. (1981). new method solving constraint satisfaction problems. Proceedings
Seventh International Joint Conference Artificial Intelligence, pp. 338{342.
Selman, B., Levesque, H., & Mitchell, D. (1992). new method solving hard satisfiability
problems. Proceedings Tenth National Conference Artificial Intelligence.
Smith, D. E., & Genesereth, M. R. (1985). Ordering conjunctive queries. Artificial Intelligence, 26 (2), 171{215.
Stallman, R. M., & Sussman, G. J. (1977). Forward reasoning dependency-directed
backtracking system computer-aided circuit analysis. Artificial Intelligence,
9 (2), 135{196.
Zabih, R. (1990). applications graph bandwidth constraint satisfaction problems.
Proceedings Eighth National Conference Artificial Intelligence, pp. 46{51.
Zabih, R., & McAllester, D. A. (1988). rearrangement search strategy determining
propositional satisfiability. Proceedings Seventh National Conference
Artificial Intelligence, pp. 155{160.

46

fi
