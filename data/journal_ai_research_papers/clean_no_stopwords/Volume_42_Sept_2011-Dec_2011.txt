Journal Articial Intelligence Research 42 (2011) 529-573Submitted 08/11; published 11/11Cloning Elections: Finding Possible WinnersEdith Elkindeelkind@ntu.edu.sgSchool Physical Mathematical SciencesNanyang Technological University, SingaporePiotr Faliszewskifaliszew@agh.edu.plAGH University Science TechnologyKrakow, PolandArkadii Slinkoslinko@math.auckland.ac.nzDepartment MathematicsUniversity Auckland, Auckland, New ZealandAbstractconsider problem manipulating elections cloning candidates. model,manipulator replace candidate c several clones, i.e., new candidatessimilar c voter simply replaces c vote block newcandidates, ranked consecutively. outcome resulting election may dependnumber clones well voter orders clones within block.formalize means cloning manipulation successful (which turnssurprisingly delicate issue), and, number common voting rules, characterizepreference proles successful cloning manipulation exists. also considermodel cost associated producing clone, study complexitynding minimum-cost cloning manipulation. Finally, compare cloning tworelated problems: problem control adding candidates problem possible(co)winners new alternatives join.1. Introductionmany real-life elections, candidates may fairly similar positions majorissues, yet disagree best way implement common goals. manyvoting rules, glaringly Plurality voting, candidates run risksplitting vote losing candidate opposing program. phenomenonexploited alter election outcome. instance, New York Times wroteRepublican political operative recruited drifters homeless people onto GreenParty ballot freely admitted candidacies may siphon supportDemocrats therefore help Republicans (Lacey, 2010).scenarios extensively studied (computational) social choice literature (see Section 6 overview). Depending whether manipulation contemplated one candidates external party, issue known strategiccandidacy problem (this term coined Dutta, Jackson, & Le Breton, 2001, 2002)problem control adding candidates.paper address variant problem known cloning.characterized following feature: new candidate must similar oneexisting candidates. form manipulative behavior rst identied studiedc2011AI Access Foundation. rights reserved.fiElkind, Faliszewski & SlinkoTideman (1987), also gave classic example cloning strategy. Tidemanwrote: 12 years old nominated treasurer class school.girl named Michelle also nominated. relished prospect treasurer,made quick calculation nominated Michelles best friend, Charlotte. ensuingelection received 13 votes, Michelle received 12, Charlotte received 11, becametreasurer(Tideman, 1987, p. 1). calculation that, friends, MichelleCharlotte similar electorate split.Tidemans example, cloned alternative lost election. However, one alsoimagine scenarios cloning alternative increase chances winning.example, suppose electronics website runs competition best digital cameraasking consumers vote two favorite models given list. listcontains one model brand, 60% consumers prefer Sony NikonKodak, remaining consumers prefer Kodak Nikon Sony, Nikon wincompetition. hand, Sony represented two similar models,Sony customers likely vote two models Sony, competitionSony camera.general candidate addition scenario, cloning presents opportunityparty interested manipulating outcome preference aggregation procedure,election consumer survey. partymost likely, campaign managerone candidatesmay invest creating clones one alternatives ordermake preferred alternative (or one clones) win election. campaignmanagement strategy certain advantages introducing entirely new candidate:latter case, may hard predict voters rank new candidate,campaign manager would either invest eliciting new candidates rankings,prepared deal rankings dier initial expectations. comparison,outcomes cloning much predictable, therefore manipulation cloningmay easier implement. natural question, then, voting rules resistantmanipulation, whether manipulator compute optimal cloning strategygiven election reasonable amount time.mentioned above, rst study cloning undertaken Tideman (1987),introduced concept independence clones criterion voting rules. Apparentlyunaware Tidemans work, Laond, Laine, Laslier (1996) introduced notioncomposition consistency, analogue independence clones tournamentsolutions (Laslier, 1997), i.e., voting rules dened majority relationcorresponds voters preferences. Later, Laslier (1996, 2000) introduced notioncloning consistency, equivalent independence clones. discussresults detail Section 6.papers, authors concentrated nding whether certain votingrule independent clones constructing new rules property. work,take somewhat dierent perspective: Instead looking cloning manipulativeaction prevented, view cloning campaign management tool.point view raises number questions consideredorconsidered dierent anglein previous work:mean cloning successful? assume campaign manager produce clones existing candidates, voters rank response.530fiCloning Electionsassume clones similar enough ranked group voter;however, order clones groups may dier one voter another.Since campaign manager cannot control predict order clonesvoters ranking, assume order random, i.e., voter ranks clonedcandidates possible order probability; indeed, wouldcase clones indistinguishable. probabilistic model, cloningstrategy succeeds certain probability. Let q real number 01. say manipulation cloning q-successful probability electingdesired candidate p least q. focus two extreme cases: (1) p winspossible ordering clones, (2) p wins least one orderingclones. case (1), cloning 1-successful; case (2), following notationtypically used dealing limits continuous mathematics, saycloning 0+ -successful.instances elections cloning successful? previous workshows many well-known voting rules susceptible cloning, attemptmade characterize elections specic candidate madewinner respect given voting rule means cloning. However,point view campaign manager considers cloning one waysrun campaign, would important know change outcomegiven election cloning manipulation. Thus, paper providecharacterization results several prominent voting rules. Often, candidatessuccessful cloning manipulation exists characterized terms wellknown notions social choice Pareto undominated alternative (a candidatec Pareto undominated every candidate c voter prefers cc ), Condorcet loser (candidate c Condorcet loser every candidatec half voters prefer c c), Uncovered Set (see Section 5.3Miller, 1977; Fishburn, 1977; Laslier, 1997).candidates cloned extent? existing research cloning place restrictions number clones introduced,identities candidates cloned. hand, clearpractical campaign management scenarios issues cannot ignored;candidates cloned, creating clone given candidate may costly.Thus, consider settings clone candidate comes cost,seek least expensive successful cloning strategy. mostly focusstandard model clones come zero cost, unit cost model,clone cost.computational complexity nding cloning strategies? Finally,investigate computational complexity nding successful cloning strategies.practice, sucient know cloning might work: need knowexactly strategy use. believe paper rst considercomputational aspect cloning. Following line work initiated seminalpapers Bartholdi, Tovey, Trick (1989, 1992), seek classify prominent531fiElkind, Faliszewski & Slinkovoting rules according whether admit ecient algorithms nding cloningmanipulation.One might argue real-life elections cloning practical campaign management tool: all, recruiting new candidate suciently similar existingones may dicult, impossible. Nonetheless, natural scenariosmodel cloning practical well-motivated. Below, provide two examples.First, let us consider election parties nominate candidates position,party nominate several candidates. voters, especially followingpolitical scene closely, likely perceive candidates belong partyclones. partys campaign manager might attempt strategically choose numbercandidates nominated party. fact, might even able aect numbercandidates nominated parties (e.g., accusing giving votersenough choice).Second, let us consider environment where, suggested Ephrati Rosenschein(1997), software agents vote choose joint plan (that is, alternatives possiblejoint plans steps possible joint plans). system, agents easily comeminor variations (steps the) plan, eectively creating clones candidates.(A similar example regarding society agents choosing project implementgiven Laslier, 1996).cases reasonable assume clones ranked contiguouslycost creating clone same; moreover, successful, cloning strategyeasy compute. Therefore model provides good scenarios.2. Preliminariesstart presenting brief overview social choice concepts usedpaper; point reader book Arrow, Sen, Suzumura (2002) additionalbackground.Given set alternatives (also called candidates), voters preference R linearorder A, i.e., total transitive antisymmetric binary relation A. election En voters given set alternatives preference prole R = (R1 , . . . , Rn ),Ri preference voter i; write E = (A, R). readability, sometimeswrite place Ri . Sometimes specifying preference order Ri write X ,X two disjoint subsets A. notation means memberX preferred member relative ordering candidates within Xwithin irrelevant discussion (unless specied separately). Also, denote|R| number voters election. Given election E = (A, R), sayalternative c Pareto undominated alternative c A, c = c, least onevoter ranks c ahead c . Given two candidates a, c A, set W (c, a) = |{i | c a}|.say c beats pairwise contest W (c, a) > W (a, c); W (c, a) = W (a, c),pairwise contest c said tied.voting rule F often dened mapping elections xed set alternatives set 2A \ {} nonempty subsets A. However, work,interested situations number alternatives may change. Thus, requirevoting rules dened arbitrary nite sets alternatives preference proles532fiCloning Electionsalternatives. say voting rule F mapping pairs formE = (A, R), nite set R preference prole A, nonemptysubsets A. elements F(E) called winners election E. Thus, allowelection one winner, i.e., work social choice correspondences;model also called non-unique winner model.paper consider following voting rules (for rules described termsscores winners alternatives maximum score):Plurality. Plurality score Sc P (c) candidate c number votersrank c rst.Veto. Veto score Sc V (c) candidate c number voters rankc last.Borda. Given election (A, R)with |R| = n, Borda score Sc B (c) candidatec given Sc B (c) = ni=1 |{a | c a}|.k-Approval. k 1, k-Approval score Sc k (c) candidate cnumber voters rank c top k positions. Plurality simply 1-Approval.Plurality Runo. rst stage, two candidates top two Plurality scores eliminated. Then, run pairwise contest two survivors;winner(s) candidate(s) get least |R|/2 votes stage, i.e.,win tie pairwise contest. may need break tie rst stagetwo candidates maximum Plurality score, one top-scorerseveral candidates second-best Plurality score. end useparallel universes tie-breaking rule (Conitzer, Rognlie, & Xia, 2009): candidate cconsidered winner wins ties runo way breaking tiesrst stage.Maximin. Maximin score Sc (c) candidate c Sc (c) = minaA W (c, a),i.e., number votes c gets worst pairwise contest.Copeland. Copeland score Sc C (c) candidate c |{a | W (c, a) > W (a, c)}||{a | W (a, c) > W (c, a)}|. is, c receives 1 point pairwise contestwins, 0 points tie, 1 point pairwise contest loses.equivalent conventional denition, which, candidate a, c gets1 point wins pairwise contest a, 0.5 points tie, 0loses contest.candidate c Condorcet winner (respectively, Condorcet loser )candidate holds W (c, a) > W (a, c) (respectively, W (c, a) < W (a, c)). Naturally,every election Condorcet winner Condorcet loser. Observe Copelandelection candidates score Condorcet winner 1 scoreCondorcet loser (m 1).Many results paper computational thus assume readerfamiliar standard notions computational complexity classes P NP,many-one reductions, NP-hardness NP-completeness. NP-hardness resultsfollow reductions Exact Cover 3-Sets problem, dened below.533fiElkind, Faliszewski & SlinkoDenition 2.1 (Garey & Johnson, 1979). instance (G, S) Exact Cover 3Sets (X3C) given ground set G = {g1 , . . . , g3K } family = {S1 , . . . , SM }subsets G, |Si | = 3 = 1, . . . , . yes-instancesubfamily S, |S | = K, gi G Sj gi Sj ,no-instance otherwise.3. FrameworkCloning independence clones previously dened Laslier (2000), Tideman(1987), Zavist Tideman (1989). However, need modify denition givenpapers order model manipulators intentions budget constraints.describe model formally.Denition 3.1. Let E = (A, (R1 , . . . , Rn )) election set candidates ={c1 , . . . , cm }. say election E = (A , (R1 , . . . , Rn )) obtained E replac(1)(k)ing candidate cj k clones k > 0 = (A \ {cj }) {cj , . . . , cj }[n], Ri total order \ {cj } [k](s)holds cj cj a.say election E = (A , R ) cloned election E = (A, R)vector nonnegative integers (k1 , . . . , km ) E derived E replacingcj , j = 1, . . . , m, kj clones.Thus, clone candidate c, replace group new candidatesranked together voters preferences. Observe according denition above,(1)cloning candidate cj means simply changing name cj rather producingadditional copy cj . completely intuitive, choice terminology simpliesarguments rest paper.denition essentially equivalent one given Zavist Tideman(1989); main dierence explicitly model cloning one candidate.However, still need introduce two components model: denitionmeans cloning successful, budget.start former, assuming throughout discussion voting rulexed. Observe nal outcome cloning depends relative rankingclones chosen voter, typically manipulators control.1Thus, cloning may succeed orderings clones, others.election authorities may approach issue worst-case perspective, considerunacceptable given cloning succeeds least one ordering clones voters.Alternatively, take average-case perspective, i.e., assume voters rankclones randomly independently, ordering clones equally likely(due similarities among clones), consider acceptable cloning manipulationsucceed probability exceed certain threshold. Similarly,extremely cautious manipulator would view cloning successful succeeds1. general model, and, specically, notion 0+ -successful cloning (to dened paragraphs), captures situation manipulator full control orderingclones voters preferences.534fiCloning Electionsorderings, practically-minded one would happy cloning succeedshigh probability. present denition captures attitudes.Denition 3.2. Given positive real q, 0 < q 1, say manipulationcloning (or simply cloning) q-successful (a) manipulators preferred candidatewinner original election, (b) clone manipulators preferred candidatewinner cloned election probability least q.two worst-case approaches discussed special cases framework.Indeed, cloning succeeds orderings 1-successful. Similarly,succeeds ordering q-successful q > 0 (where q maydepend |A| |R|). latter case, say cloning 0+ -successful;equivalent saying manipulator would succeed could dictate voterorder clones. use equivalent formulation often simpliesproofs.Observe that, according denition, manipulator succeeds long oneclones preferred candidate wins. assumption natural clones representcompany (e.g., Coke Light Coke Zero) political party. However,campaign manager created clone candidate simply recruiting independentcandidate run similar platform, may nd outcome new candidatewins less optimal. could instead dene success victory original candidatec (i.e., clone c(1) ), but, least neutral voting rules, equivalent scalingsuccess threshold q factor k, k number clones preferredcandidate. Indeed, preference prole original candidate winstransformed one clone wins, switching order voterspreferences, c(1) wins probability clone. particular,means denition cloning manipulation 1-successfulclone manipulators preferred candidate.Another issue need address costs associated cloning. Indeed,costs important aspect realistic campaign management, manageralways restricted budget campaign. general way model cloningcosts election initial set candidates = {c1 , . . . , cm } introducingcost function p : [m] Z+ Z+ {0, +}, p(i, j) denotes cost producingj-th copy candidate ci . Note p(i, 1) corresponds producing additional copiesi, require p(i, 1) = 0 [m]. remark natural assumecosts nonnegative (though may equal zero), whereas assumptioncosts integer-valued made computational reasons; real restrictionmonetary values discrete.assume marginal cost introducing additional cloned candidate eventually becomes constant, is, exists > 1 p(i, j) = p(i, t) j > t.ensures cost function nite representation; specically, encodep m-by-t table entries Z+ {0, +}.Denition 3.3. instance q-Cloning problem q {0+ } (0, 1] giveninitial set candidates = {c1 , . . . , cm }, preference prole R |R| = n,manipulators preferred candidate c A, parameter > 1, cost function p : [m] [t]535fiElkind, Faliszewski & SlinkoZ+ {0, +} (with interpretation p(i, j) = p(i, t) = 1, . . . , j > t),budget B, voting rule F. ask exists q-successful cloning respectF costs B.many voting rules consider, easy bound number clonesneeded 0+ -successful 1-successful cloning (if one exists), bound usuallypolynomial n m. Thus, often assumed polynomial n m.focus two natural special cases q-Cloning:1. Zero Cost (ZC): p(i, j) = 0 [m], j Z+ . case would likedecide election manipulable cloning money concern.2. Unit Cost (UC): p(i, j) = 1 [m], j 2. model assumes creatingnew clone xed cost equal candidates.say election E q-manipulable cloning respect voting rule Fadmits q-successful manipulation cloning respect F ZC model.rest paper, characterize q-manipulable elections discusscomplexity q-Cloning problem number well-known voting rules, focusingZC UC models. Clearly, hardness results special cases also imply hardnessresults general cost model. Similarly, hardness results ZC q-Cloning implyhardness results UC q-Cloning; reduce ZC q-Cloning UC q-Cloning sucesset B = +. emphasize whenever say q-Cloning easy, refergeneral cost model; contrast, q-manipulability refers susceptibility cloningmanipulation zero costs and/or unlimited budget.4. Prominent Voting Rules Cloning Easysection study q-Cloning Plurality, Plurality Runo, Veto, Maximin.Surprisingly, four rules exhibit similar behavior respect cloning.4.1 Pluralitystart considering Plurality, arguably simplest voting rule.Theorem 4.1. election 0+ -manipulable cloning respect Pluralitymanipulators preferred candidate c win, ranked rst leastone voter. Moreover, Plurality 0+ -Cloning solved linear time.Proof. Clearly, c rst-place votes, cloning manipulation make winner.Now, assume cs Plurality score Sc P (c) least 1, let C = {a | Sc P (a) >Sc P (c)} denote set candidates whose Plurality score greater c.P (a)C, create ka = ScSc P (c) clones a.Recall show cloning 0+ -successful, need specify orderingclones makes c winner. One ordering obtained follows.C, let Ra denote set orders ranked rst. Split Raka groups, rst ka 1 groups size Sc P (c), last group sizeSc P (a) (ka 1)Sc P (c) Sc P (c). Let voters i-th group rank i-th clone536fiCloning Electionsrst, followed rest clones arbitrary order. orderingclones, Plurality score candidate Sc P (c), c winner, i.e.,cloning 0+ -successful.prove second statement theorem, note above-described algorithmnding 0+ -successful cloning optimal: reduce candidates Plurality scorecloning candidate, candidate score Sc P (a) > Sc P (c) clonedless ka times, least one clones obtain Sc P (c) Plurality votes.Thus, simply need compute cost cloning candidate C exactly ka times,compare budget B.hard strengthen rst statement Theorem 4.1 0+ -manipulabilityq-manipulability q (0, 1).Theorem 4.2. q (0, 1), Plurality election q-manipulable cloningmanipulators preferred candidate c win, ranked rst leastone voter. However, Plurality election 1-manipulable cloning.Proof. Fix q (0, 1). Suppose manipulators preferred candidate c win,Sc P (c) >0. candidate Sc P (a) > Sc P (c), set = Sc P (a)one clonescreate k = 2s m11q clones a. probability11qtop-ranked two times k 2 k2 m1. union bound,probability least q none newly introduced clones gets one vote.hand, none uncloned candidates Plurality votes c, cloningchange that. Therefore, c among winners resulting election. However,obviously manipulator cannot make c winner probability 1: voters orderclones way, popular clone candidatePlurality score original candidate.procedure described proof Theorem 4.2 introduces (m1) n2 m11qclones; number polynomial n constant q. However, numberclones necessarily optimal, i.e., procedure polynomial-time algorithmq-Cloning. fact, complexity Plurality q-Cloning q (0, 1) remains openproblem.4.2 Veto Plurality RunoVeto rule exhibits extreme vulnerability cloning.Theorem 4.3. election manipulators preferred candidate c win1-manipulable cloning respect Veto. Moreover, Veto 0+ -Cloning1-Cloning solved linear time.Proof. Consider prole Veto score manipulators preferred candidatec k. means c ranked last n k times. clone c least n k + 1 times,guaranteed least one clone c never ranked last, among Vetowinners.537fiElkind, Faliszewski & Slinko0+ -Cloning, observe useful clone candidates c. Thus,optimal solution make two copies c ask voters orderway. better clone never ranked last among winners.1-cloning, let Veto score election winner(s), let k Vetoscore c. argued above, benet cloning candidates c,need determine optimal number cs clones. Suppose rst = n. Then,argument above, sucient create n k + 1 clones c. easy seenumber also necessary: n k fewer clones, may rankedlast voter.Now, suppose < n. Let = n , k = n k, set r = k+1 , create r + 1clones c. number clones clearly sucient: r + 1 > k+1 ,clone c ranked last least + 1 times, total number voters rank clast original prole would least ( + 1)(r + 1) > k , contradiction.hand, necessary introduce least r + 1 clones. Indeed, rclones, split voters rank c last r groups, rst r 1 groupssize + 1, last group size k (r 1)( + 1) + 1 (where inequalityfollows r k+1 ), voters i-th group rank i-th clone c last.preference prole, clone c vetoed least + 1 times therefore amongwinners.consider Plurality Runo.Theorem 4.4. election 0+ -manipulable cloning respect PluralityRuno manipulators preferred candidate c current winner,either(1) ScP (c) 2,(2) ScP (c) = 1 c wins ties pairwise contest alternative w whosePlurality score strictly positive.Moreover, Plurality Runo 0+ -Cloning solved polynomial time.Proof. Suppose rst ScP (c) 2. introduce two clones c,denote c(1) c(2) , split voters rank c rst two nonempty groups, askvoters rst group rank c(1) rst, ask voters second group rankc(2) rst. Next, candidate = c create Sc P (a) clones a, ask i-thvoter among rank rst rank i-th clone rst. resulting election,Plurality score c(1) c(2) least 1, Plurality scorecandidate 1. Thus, way break ties rst roundc(1) c(2) progress nal round, one wins. apply paralleluniverses tie-breaking rule, means cloning 0+ -successful.ScP (c) = 1, use strategy previous case, exceptclone c. resulting election Plurality score candidate 1. Let walternative nonzero Plurality score loses ties pairwise election c.easy see clone w also loses ties pairwise election c. Sincews Plurality score original election positive, exists parallel universec clone w meet nal, means c winner resulting election.538fiCloning ElectionsThus, see conditions theorem sucient. shownecessary. First, note c ranked rst voter, cwin irrespective candidates clone. Indeed, cloned electiontwo candidates nonzero Plurality scores, c reach nal, votersrank candidate = c rst, c may reach nal, lose nal. Now,suppose Sc P (c) = 1, alternative w Sc P (w) > 0 beats c pairwisecontest; argued also holds clone w. Since c winner priorcloning, exists least one candidate nonzero Plurality score, thereforeone clone c progress second round; hence, benet cloningc. Moreover, even c reaches second round, face (a clone of) alternativenonzero Plurality score original election, assumption clonewould beat c nal.complete proof theorem, remains give polynomial-time algorithm0+ -Cloning Plurality Runo. suggested discussion above,two ways make c winner: either (1) try clone c (and possiblyalternatives) order ensure clones c go runo, (2) try clonealternatives c only, ensure c goes runo alternativedefeat. algorithm implements options accepts eitherwithin budget.option (1), introduce two clones c, denote c(1) c(2) (clearly,benet creating two clones c). hard seeoptimal strategy ask voters order clones get (almost) identicalPlurality scores, i.e., Plurality scores c(1) c(2) Sc P2 (c) Sc P2 (c) ,respectively. Let k = Sc P2 (c) , let C = {a \ {c} | Sc P (a) > k} denote setcandidates whose Plurality score greater c(2) . candidate C,introduce ka = Sc Pk(a) clones a. nonzero probability, action ensuresPlurality score alternative except c(1) c(2) exceed k, thusparallel universe c(1) competes c(2) runo one wins.easy see strategy gives cheapest way implementing option (1).Option (2) used candidate c wins ties pairwise contestleast one candidate nonzero Plurality score. Let = {a \ {c} |Sc P (a) 1 W (c, a) > W (a, c)}. w compute cost manipulation results c competing w runo one parallel universes;pick cheapest manipulations. remains explain computemanipulation specic w D.Let k = min{Sc P (c), Sc P (w)}, let C = {a \ {c, w} | Sc P (a) > k}. cloned,candidates C prevent c w meeting nal round. Thus,create ka = Sc Pk(a) clones C. easy see manipulationresults nonzero chance c winning cannot produce fewer clonesgiven w D. completes proof.also characterize elections q-manipulable respect PluralityRuno q (0, 1].539fiElkind, Faliszewski & SlinkoTheorem 4.5. q (0, 1), election q-manipulable cloning respectPlurality Runo 0+ -manipulable cloning respect it.However, election 1-manipulable.Proof. immediate Plurality Runo election 1-manipulable:preferred candidate winner cloning voters rank clones identically,preferred candidate still loses.see q (0, 1) election q-manipulable respect PluralityRuno 0+ -manipulable respect it, suces combineproofs Theorems 4.4 4.2. detail, proof Theorem 4.2 explainsclone candidates probability least q Plurality scorescandidates resulting prole R exceed 1. argue wheneverhappens (i.e., probability q) c Plurality Runo winner long satisesconditions Theorem 4.4.Indeed, suppose R Plurality score candidate 1.cs Plurality score original election least 2, case least twoclones c positive Plurality scores R , hence parallel universemeet nal. hand, cs Plurality score original election 1,beats ties candidate w nonzero Plurality score pairwise election,R parallel universe c meets (a clone of) w nal. Thus, cPlurality Runo winner R , proof complete.remark cloning strategy presented proof Proposition 4.5 is,sense, degenerate: operates way irrespective identity preferredcandidate c, eect making eligible candidates Plurality Runowinners. (This seen artifact non-unique winner model,outcome viewed acceptable. interested making c unique PluralityRuno winner, may need sophisticated cloning strategy; however, questionoutside scope paper.) Observe also Plurality Runo cloningused manipulate favor Condorcet loser.2Example 4.6. Let us consider following Plurality Runo election: = {a, b, c, d},17 voters whose preference orders are:cabdabdcbadcdabc8333votersvotersvotersvotersClearly, c Condorcet loser. Further, apply Plurality Runo, c getssecond round, loses there. Yet produce two clones c, possiblereceives four Plurality points, enters runo and, result, onewins election.2. grateful one JAIR referees example.540fiCloning Elections4.3 MaximinSurprisingly, Maximin behaves essentially way Plurality respectcloning, i.e., cloning candidate, reduce Maximin score 1 nonzeroprobability.Consider following election, used constructions throughoutsection. Let E = (A, R) = {a1 , . . . , ak }, R = (R1 , . . . , Rk ), [k]preferences i-th voter given ai ai+1 . . . ak a1 . . . ai1 .refer election obtained E renaming candidatesk-cyclic election. election, assuming a0 = ak , = 1, . . . , k k 1voters prefer ai1 ai 1 voter prefers ai ai1 . Thus, Maximin scorecandidate 1. Further, remains true add arbitrary candidateselection, matter voters rank additional candidates. meanscloning candidate n-voter election n times telling voters order nclones n-cyclic election, reduce Maximin score 1.Theorem 4.7. election 0+ -manipulable cloning respect Maximinmanipulators preferred candidate c win, Pareto undominated.Further, Maximin 0+ -Cloning solved linear time. However, election1-manipulable cloning respect Maximin.Proof. Clearly, voters prefer alternative c, cloning Maximinscore c 0, whereas Maximin score least one alternative positive,hence c cannot win. hand, c undominated, Maximin score least1. Now, use construction described reduce Maximin scorecandidate 1, thus making c winner.algorithm Maximin 0+ -Cloning relies observation waychange Maximin score candidate clone her, thereby reducing score. Now,suppose Sc (c) = s. argue yes-instance 0+ -Cloningbudget allows us introduce ns clones candidateScM (a) > s; clearly, condition checked linear time.Indeed, candidate whose Maximin score exceeds following.create ns clones a, divide voters groups, size rst 1groups ns , last group consists remaining ns voters.rst 1 groups, ask voters rank clones according ns -cyclic election;voters last group vote rst voters ns -cyclic election. Clearly,group, = 1, . . . , ns one voter ranks i-th clone(i 1)-st clone. Thus, resulting election, Maximin score clones, therefore c winner election.converse direction, need show create less ns clones a,Maximin score least one exceed s. Indeed, suppose create< ns clones a; denote clones a(1) , . . . , a(t) . Given arbitrary preferenceprole clones, consider directed graph whose vertices clonesedge a(i) a(j) least ns voters prefer a(i) a(j) . Note Maximinscore clone s, vertex graph must incoming edge.particular, means graph cannot acyclic. argue cycle541fiElkind, Faliszewski & Slinkograph length least ns ; clearly, implies graph contains leastns vertices, contradiction.see this, suppose cycle length r < ns . Relabel clones alongcycle a(1) , . . . , a(r) , i.e., assume = 1, . . . , r least ns voters prefer a(i)a(i+1) (where a(r+1) = a(1) ). induction easy see = 1, . . . , r 1,least n si voters whose preference order satises a(1) . . . a(i+1) .= r 1, implies least n s(r 1) > voters prefer a(1) a(r) , contradictionassumption edge a(r) a(1) . establishesalgorithm 0+ -Cloning correct.Finally, easy see election 1-manipulable respect Maximin.Indeed, way change candidates Maximin score clone him. However,cloning, voters may order clones way, case popularclone Maximin score original alternative.clear one strengthen result Theorem 4.7 q-manipulabilityq (0, 1). amounts following question: Suppose xed n randomlydraw n permutations {1, . . . , k}. Let P (n, k) probability [k]j [k] j precedes least n 1 permutations. case that,k , probability P (n, k) approaches 1?computations show unlikely case.3 (n, k) = (5, 20)one success 106 random trials three (n, k) = (5, 50).(n, k) = (7, 20) (n, k) = (7, 50) single random trial 106 trials successful.means that, even Maximin q-manipulable xed q > 0, numberclones needed would astronomical.5. Three Rules Cloning May Dicultconsider Borda, k-Approval, Copeland rules, cloning-related problemssignicantly dicult.5.1 Borda RuleBorda rule, necessary sucient condition existence 0+ -successfulmanipulation cloning Maximin: manipulators favorite alternativePareto undominated. However, Borda Maximin exhibit dierent behaviorrespect 1-manipulability. Moreover, point view nding minimumcost cloning, Borda appears harder deal Maximin.Theorem 5.1. election 0+ -manipulable cloning respect Bordamanipulators preferred candidate c win, Pareto undominated. Moreover,UC 0+ -Cloning Borda solved linear time.Proof. Note rst create k clones alternative ranked positionj order Ri , Ri contribution scores alternatives rankedincreases k 1, Ri contribution scores alternatives ranked3. grateful Danny Chang help performing experiments.542fiCloning Electionschange, and, nally, top-ranked clone receives k 1 points Riused receive. use observation prove theorem.Suppose rst voters prefer alternative c. Note impliesSc B (a) > Sc B (c). create k clones alternative x = c, a, preferenceordering Ri three possibilities:1. Ri , x ranked c. cloning x change Bordascores c.2. Ri , x ranked c. cloning x increases Borda scorek 1 change score c.3. Ri , x ranked c. cloning x increases Borda scoresc k 1.Thus, single act cloning alternative \ {c, a} (and hence combinationthem) reduce gap scores c. Further, clone and/orc, every ordering Ri clone ranked clone c, hencehigher Borda score. Thus, c cannot made winner cloning.converse direction, let C = {a | Sc B (a) > Sc B (c)}. C, letna number voters prefer c a, i.e., na = W (c, a). Let sa denote scoredierence c, i.e., sa = Sc B (a) Sc B (c). Now, set k = maxaC nsaa ,create k + 1 clones c. Consider preference prole voters rank clonesc way. Let c top-ranked clone c. Observe Borda score cnew prole exceeds original Borda score c kn, n total numbervoters. Now, consider alternative C. order Ri rankedc, Ri contribution score increased k, order Riranked c, Ri contribution score remained same. Thus, scoreincreased k(n na ). Hence, using Sc B (a) Sc B (c ) denote scoresc cloning, choice k Sc B (a) Sc B (c ) = Sc B (a) Sc B (c) kna 0.conclude resulting preference prole Borda score c least highalternative, i.e., cloning 0+ -successful.argue input constitutes yes-instance UC 0+ -CloningmaxaC nsaa + 1 B, B cloning budget, i.e., manipulationconstructed optimal UC model. Indeed, consider alternative Cmaximizes expression nsaa . creating + 1 clones alternative = c,increase distance c orders ranked ct, thus reduce gap c t. Obviously, naorders. order Ri , cloning may increase Ri contribution score a,aect Ri contributions scores c way. Thus, creating + 1 clonesalternative \ {a, c} contribute tna closing gap ca. similar argument applies cloning c a, showing contribution + 1clones either alternatives also bounded tna . Hence, createleast nsaa + 1 clones.possible strengthen Theorem 5.1 q-manipulability constant q (0, 1]?turns Borda questions signicantly dicult rulesconsidered far.543fiElkind, Faliszewski & Slinkorst consider situation manipulator restricted cloningfavorite candidate. remark special case model natural:instance, party may able nominate several candidates, positionforce parties so. case, even number voters, characterizeelections 1-manipulated cloning respect Borda.Let c manipulators preferred candidate. show that, cloning c,deal candidates currently higher Borda score c, longlose c pairwise election. However, careful ensure csBorda score remains higher candidates beat c pairwise election.Formally, letA+ = {a \ {c} | SB (a) > SB (c)},= {a \ {c} | SB (a) SB (c)}.Let sa = |SB (a) SB (c)| \ {c}, setW (c, a) W (a, c) A+ ,na =W (a, c) W (c, a) .+Finally, let r+ = + na 0 A+ r+ = max{ 2sna | } otherwise,let r = min{ 2sna | , na > 0}. ready state criterion.Theorem 5.2. election even number voters 1-manipulated respectBorda cloning manipulators preferred candidate c c winr+ r .Proof. Let n denote number voters. Suppose r+ > r . Consider cloninginvolves c only. Suppose results k clones c, denote c(1) , . . . , c(k) .Let denote original Borda score c. show cloning 1-successful,suces describe ordering clones results clones c losing election.Consider prole rst n2 voters rank clones c(1) c(k) ,remaining n2 voters rank clones opposite order. Clearly, Borda scoreclone + n2 (k 1). consider two cases.Case 1 (r + = +). means alternative na 0, i.e.,preferred c least n2 voters higher Borda score c.cloning increases score least n2 (k 1), nal Borda score leastsB (a) + n2 (k 1) > + n2 (k 1). Thus, cloning, clones c stilllower scores a, i.e., cloning 1-successful.Case 2 (r + < +). case, exists candidate A+ na > 02sar+ = 2sna . Consider candidate b r = na ; nb > 0.2sbcondition r+ > r rewritten 2sna > nb . cloning, Bordan+nbscore sB (a) + nn2 (k 1), bs Borda score sB (b) + 2 (k 1). Thus, cwinner, k must satisfys+n nan(k 1)sB (a) +(k 1);22544s+n + nbn(k 1)sB (b) +(k 1).22fiCloning ElectionsHence, obtainsa = sB (a)na(k 1),2sb = sB (b)nb(k 1).22sbSince k integer, implies r+ = 2sna k 1 nb = r , contradiction.opposite direction, show ordering clones constructedworst possible manipulator. Formally, suppose generate k clonesc k 1. Consider voter gives j points c. hard seevoter gives j + (j + 1) + + (j + k 1) = kj + k(k1)points clones c. Thus,2k(k1)total Borda score clones equal ks + n 2 , Borda score c priorcloning. follows Borda score least one clone + n2 (k 1) higher.Since r+ r , r+ < +. Set k = 1 + r+ , consider arbitraryalternative A+ . r+ < +, na > 0. Therefore, gains nn2 (k 1)2sanpoints cloning. Now, hard see k 1 + na implies + 2 (k 1)SB (a) + nn2 (k 1), means cloning clone c beats a.nish proof, consider candidate b . nb 0, cloning scorek1b SB (b) + n k12 + n 2 , b still loses ties clone c.bhand, nb > 0, cloning increases score b n+n2 (k 1) points.ff2sb2sb.k 1 = r+ rnbnbTherefore, cloning, score bSB (b) +n + nbnk1(k 1) SB (b) + (k 1) + sb = + n,222i.e., bs Borda score exceed clone c.hard see second part proof (the direction) worksodd number voters well. However, direction, argumentgo through. can, however, prove slightly weaker necessary condition. Dener+ = + na 0 A+ r+ = max{ 2snaa1 | A+ } otherwise, letr = min{ 2snaa+1 | , na > 0}.Proposition 5.3. election odd number voters 1-manipulatedrespect Borda cloning manipulators preferred candidate c, r+ r .relegate proof Proposition 5.3 Appendix A. remark clearconverse direction Proposition 5.3 holds: condition r+ r weakerr+ r , unable prove sucient 1-manipulabilityrespect Borda.proof Theorem 5.2 indicates orderings clones problematicmanipulator: orderings grant clone roughly numberpoints. exactly expected outcome orderings generated uniformlyrandom! Thus, proof shows Borda manipulator clones cprepared worst-case scenario.545fiElkind, Faliszewski & SlinkoNote, however, limited cloning c. Indeed, cloning candidatesmight useful respect 1-manipulability. example, suppose c Paretoundominated, and, moreover, original preference prole contains candidate cranked right c voters (one think candidate inferior clonec; however, emphasize present original prole). one showcloning c suciently many times make c winner probability 1. However,cloning c eect voters order clones randomlyadversarially manipulator. illustrated following example.Example 5.4. Let us consider following Borda election. set candidatesC = {a, b, c, d}, four voters, whose preference orders are:R1R2R3R4:acbd:acbd:acbd:dcbaSc B (a) = 9Sc B (b) = 4Sc B (c) = 8Sc B (d) = 3winner 9 points. However, replacing b three clones b1 , b2 , b31-successful manipulation favor c since new score 15, new scorec 16, matter clones ordered. time, cannot make cwinner probability 1 cloning alone. Indeed, split c k + 1 clones,voter orders clones uniformly random, expected score clone c4(2 + k2 ) = 8 + 2k (and, since number voters even, proof Theorem 5.2 givesexplicit ordering clones clone gets 8 + 2k points), whereas score9 + 3k.shows that, general, may need clone several candidates placedc competitors large number votes, determining rightcandidates clone might dicult. Indeed, clear 1-successful manipulationBorda found polynomial time; answering question challenging openproblem.related question answered Theorem 5.1 complexity 0+ -Cloning(and, generally, q-Cloning q {0+ } (0, 1]) general cost model. Notecertain similarity problem 1-manipulability: cases,may suboptimal clone c. Indeed, general costs, prove q-CloningNP-hard q.Theorem 5.5. Borda, q-Cloning general cost model NP-hard rationalq (0, 1] well q = 0+ . Moreover, case even p(i, j) {0, 1, }[m], j Z+ .Proof. provide reduction X3C. Let (G, S) instance X3C, G ={g1 , . . . , g3K } ground set = {S1 , . . . , SM } family 3-element subsets G.Let N = 3K. construct instance problem follows. Let = {t1 , . . . , tM }.let set alternatives = GT {c, u, w}, c manipulators preferredalternative. = 1, . . . , , create two voters preference orders R2i1R2i . preference order R2i1 givenR2i1 : G \ Si c ti Si u w \ {ti },546fiCloning Electionspreference order R2i givenR2i : w Si u c G \ Si T.Further, require candidates G ranked opposite order R2iR2i1 , i.e., j, = 1, . . . , gj 2i g g 2i1 gj . Finally,one voter whose preference order givenR2M +1 : G c u w.cloning costs dened follows. = 1, . . . , , producing one additionalclone ti costs 1, producing clones ti costs 0. Cloning alternativecosts +. Finally, set B = K.easy verify pair votes (R2i1 , R2i )1. c gets (M + 5) + (N 3 + ) = 2M + N + 2 points,2. gj gets (M + N + 2) + = 2M + N + 2 points (this remains true gj Si ),3. tj gets (M + 4) + (M 1) = 2M + 3 points,4. u gets + (M + N 2) = 2M + N 2 points,5. w gets (M 1) + (M + N + 2) = 2M + N + 1 points.Thus, last voter, overall Borda score alternative G exceedsc least 1 N , score alternative lowerc.Note create N + 1 clones ti , cost 1, ensure csscore least high alternatives Si , irrespective voters orderclones. However, cloning ti change dierence scores calternatives G \ Si . Within budget, clone K alternatives , N + 1 timeseach. Thus, cover G size K = N/3, i.e., exact cover, transformed1-successful cloning manipulation instance.Conversely, consider cloning manipulation cost K. Suppose clonesalternatives ti1 , . . . , tis , K. {Si1 , . . . , Sis } cover G, elementgi G covered sj=1 Sij . means cloning manipulationchange dierence scores gi c, i.e., gi still higher Borda scorec. Hence, cloning 0+ -successful. Thus, 0+ -successful cloning costK corresponds cover G.Now, consider q (0, 1]. input instance X3C yes-instance,election constructed admits 1-successful cloning, also q-successfulcloning (as well 0+ -successful cloning). hand, start noinstance X3C, election admit 0+ -successful cloning, hence qsuccessful cloning. Thus, proof complete.Observe cost function used proof Theorem 5.5 natural:candidates cannot cloned all, others, certain upfront cost associatedcreating rst clone (e.g., researching platform and/or identity candidate),subsequent clones created free.547fiElkind, Faliszewski & Slinko5.2 k-Approvaldemonstrate family scoring rules deciding whethergiven election 0+ -manipulable computationally hard. Specically, casek-Approval k 2. proof gives reduction problem Dominating Set,dened below.Denition 5.6. instance Dominating Set problem triple (V, E, s),(V, E) undirected graph integer. ask subset W V(a) |W | (b) v V either v W v connected vertex W .Theorem 5.7. k-Approval rule, NP-hard decide whether given election0+ -manipulable cloning.Proof. First, remark one always make alternative k-Approval winnernonzero probability long ranked rst least one voter. Indeed,simply clone alternatives suciently many times (e.g., kn times, nnumber voters). ensures exists preference prole resulting setalternatives candidate gets one k-Approval point.However, condition necessary. Indeed, candidate k-Approval winnereven voter ranks rst. Thus, hardness reduction, ask whetherhelp candidate never ranked rst.Consider instance (V, E, s) Dominating Set, V = {v1 , . . . , vt }.assume without loss generality graph (V, E) isolated vertices < t.construct election based (V, E, s) follows. candidate vivertex graph, candidate c would like make winner, additionalcandidate w, set dummy candidates. exact number dummy candidates,polynomial size (V, E), become clear describe setvoters. voter, specify nondummy candidates rankstop k positions. Clearly, order candidates ranked positions k + 1 loweraect outcome election. Further, assume dummy candidateranked among top k positions exactly one voter. (Thus, number dummycandidates bounded k times number voters.)= 1, . . . , t, i-th voter places vi rst ranks c position k.next 4t2 voters places w rst ranks c position k. Further, (undirected)edge (vi , vj ) E, 2s voters rank vi rst vj second 2s votersrank vj rst vi second.v1...cvt w.. ... .cw......c c4t2vivivjvjvj...vj...vi...vi...2s2s......Observe based votes constructed far, score c 4t2 s, scorew 4t2 s, score vi , = 1, . . . , t, 4s(t 1) + 1.add polynomially many voters, ranks w candidate V rst (anddummy candidates positions 2, . . . , k), w gets 4t2 2s points total548fiCloning Electionscandidate V gets exactly 4t2 points total (note possible since > s).Clearly, number voters constructed stage polynomially boundedinput size.claim constructed election 0+ -manipulable graph (V, E)dominating set size s. Indeed, suppose rst (V, E) dominatingset W size s. clone candidate W exactly k + 2s(k 1) times. Now,consider following preference prole cloned alternatives. Split clones2s + 1 groups, rst group size k remaining groups size k 1.vi W , order clones follows:1. i-th voter ranks rst group vi clones rst k positions.2. j (vj , vi ) E, -th voter among 2s voters usedrank vj rst vi second ranks ( + 1)-st group vi clones positions2, . . . , k.3. voters order clones arbitrarily.preference prole, c gets 4t2 2s points: pushedtop k slots rst votes, lose points. clonecandidate vi W gets 4t2 2s points, too. Indeed, x vi W .assumption, graph (V, E) isolated vertices. Thus, vertex vjconnected vi , 2s voters (before cloning) rank vj rst positionvi second position. Let us denote set voters Eji . Now, considerprole cloning. rst k clones vi ranked rst k positionsvoter Eji , thus receives 4t2 2s points. consider -thgroup vi clones, = 2, . . . , 2s + 1: clones ranked top k positionsexactly one voter Eji , none rst voters. Thus, clones scores4t2 (2s 1) 1 = 4t2 2s. conclude score clone vi4t2 2s.Now, consider candidate vj V \ W . Since W dominating set (V, E),exists vi W (vi , vj ) E. Since 2s voters used rank vi rstvj second rank clones vi top k positions, vj pushed topk positions least 2s votes. Consequently, k-Approval score 4t2 2s.k-Approval score w 4t2 2s prior cloning aected cloning,conclude cloning c winner election nonzero probability.Conversely, suppose make c winner nonzero probability cloningcandidates. Observe rst could cloned w. Indeed, clonew, c pushed top k positions 4t2 votes, score t.hand, original preferences, vi V ranked rst least 4t times.Therefore, make c winner cloning w, would clone vi V .However, that, cs k-Approval score goes 0, cannot winner.conclude w cloned. w ranked positions 2, . . . , kvotes, therefore cannot pushed out, means ws nal score 4t2 2s,therefore cs nal score must least 4t2 2s. This, turn, meansclone candidates V , cloning candidate reduces cs score 1.hand, need reduce score vi V least s. done549fiElkind, Faliszewski & Slinkoeither cloning vi cloning alternative ranked rst voterranks vi second. means vi V either cloned neighbor (V, E)cloned, i.e., set cloned alternatives forms dominating set (V, E).argued size set s, completes reduction.also show NP-hard decide whether election 1-manipulablerespect k-Approval.Theorem 5.8. given k 2, NP-hard decide whether given election1-manipulable cloning respect k-Approval.Proof. rst present proof k = 2, show generalizeinteger k 2. reduction X3C. Let instance (G, S) X3C givenground set G = {g1 , . . . , g3K } family = {S1 , . . . , SM } subsets G,= 1, . . . , write gi1 , gi2 , gi3 denote members Si . assume withoutloss generality > K > 3. Given instance, construct electionfollows. set alternatives = G {c, w} D, = {t1 , . . . , tM },set dummy candidates. follows, place dummy candidatesappears rst two rows.specify rst two positions vote. = 1, . . . , , i-thvoter ranks ti rst c second. next 2 voters ranks w rst dummyalternative second. also groups 3M voters, i-th group (a)voter ranks ti rst, (b) candidates gi1 , gi2 , gi3 ranked secondexactly voters. Further, G, add Ni = (M + 1 |{j | gi Sj }|) votersrank gi rst dummy candidate second. Finally, add N = 2 + K votersrank c rst dummy candidate second.t1ctMcwwM2tigi1tigi23tigi3giNigicNcprole, score ti 3M + 1, score c 2 + K, score wscore gi 2 + . scores dummy candidates equal 1,number clearly polynomial . K < , set winners proleG, c K points behind. Now, clone candidate gi G, votersmay still rank clones gi order, manipulation relies cloningcandidates G 1-successful. Therefore, bridge gap c candidatesG, need clone candidates . However, cannot cloneK them, since otherwise score c fall score w (while clonew well, voters may still order clones w way, casetop-ranked clone w still gets 2 points). hand, gi G needclone least one tj gi Sj , since otherwise score gi go down.Thus, 1-successful manipulation corresponds cover G size K, i.e.,exact cover. Conversely, cloning set candidates {Sj | tj }exact cover G 1-successful cloning.k > 2, construction modied follows. vote, insert groupnew k 2 dummy candidates rst second position (so2,550fiCloning Electionsvote candidate used ranked second ranked position kdummy candidate ranked top k positions exactly once). easy see proofgoes without change.5.3 Copelandanalyze cloning Copeland rule, need additinal denitions.election E set candidates A, pairwise majority graph directed graph (A, X),X contains edge b half voters prefer b; saybeats b (a, b) X. exactly half voters prefer b, sayb tied (this mean Copeland scores equal). A,denote U (a), D(a) (a) sets alternatives beat a, beaten a,tied a, respectively.odd number voters, graph (A, X) tournament, i.e., pair(a, b) A2 , = b, either (a, b) X (b, a) X. case, makeuse well-known tournament solution concept Uncovered Set (Miller, 1977; Fishburn,1977; Laslier, 1997), dened follows. Given tournament (A, X), candidate saidcover another candidate b beats b well every candidate beaten b.Uncovered Set (A, X) set candidates covered candidates.turns number voters odd, Uncovered Set coincides setcandidates made Copeland winners cloning. contrast previouscharacterization results, holds values q (0, 1] {0+ }.Theorem 5.9. q (0, 1] {0+ }, Copeland election E odd numbervoters q-manipulable cloning manipulators preferred candidate cwin, Uncovered Set pairwise majority graph E.Proof. Consider election E set alternatives odd number voters.Let (A, X) pairwise majority graph. Suppose rst c covered A.case Sc C (c) < Sc C (a). Creating k clones alternative x increases k 1score alternative beats x decreases k 1 score alternativebeaten x. Hence, gap c cannot reduced cloning thirdalternative. Moreover, replace c k clones, score clone cSc C (c) + k 1, score becomes Sc C (a) + k 1. Similarly, replacek clones, scores clone least Sc C (a) (k 1),score c becomes Sc C (c) (k 1). shows cloning c would help either.Thus, matter alternatives clone, cannot close gap c (orhighest-scoring clone).Conversely, suppose c Uncovered Set. Since number candidatesodd, (c) = , since c uncovered, U (c) = \ {c}. Therefore,D(c) = . proceed two stages. First, secure either c clonehigher Copeland score alternative D(c), take carealternatives U (c). stage one create 2m + 1 clones c. lowers scorealternative D(c) 2m raises score alternative U (c) 2m.simple counting argument shows that, ordering clones voters,exists clone c whose score greater equal original score c; denote clone551fiElkind, Faliszewski & Slinkoc . alternative x, let Sc C (x) denote xs score stage one. x D(c)Sc C (c ) Sc C (c) (m 1) > Sc C (x) 2m = Sc C (x),i.e., c higher Copeland score x. hand, x U (c)Sc C (c ) Sc C (c) (m 1) Sc C (x) (2m 2) = Sc C (x) (4m 2).stage two create 4m + 1 clones alternative D(c). increasesscore c 4m|D(c)|. Further, D(c), score clone constructedstage exceeds Sc C (a) 4m|D(c)|. Thus, stage, c higherCopeland score newly-generated clones. Finally, since c covered,candidate U (c) beats candidates D(c); fact, U (c) beatenb D(c). Thus, last step increases score candidate U (c)4m(|D(c)| 1) 4m = 4m(|D(c)| 2). follows c higher Copeland scorecandidate clone c.elections even number voters, situation signicantly complicated. notion Uncovered Set extended pairwise majority graphs arbitraryelections natural way (see, e.g., Brandt & Fischer, 2007): say u covers c ubeats c alternatives beaten c, and, addition, c loses alternatives beatu. particular, means u cover c beaten alternativetied c. denition generalizes one odd number voters. However,even number voters, condition c Uncovered Set turnsnecessary, sucient manipulability cloning.Proposition 5.10. Copeland election E even number votersmanipulators preferred candidate c covered, c cannot made winner cloning.Proof. Suppose c covered u. Copeland score c given |D(c)| |U (c)|.Now, u beats alternatives D(c), alternative beats u necessarily U (c).Thus, u strictly higher Copeland score c. Now, suppose create k + 1 clonesA. increase score c (or one clones) D(c) {c};however, score u also increases k. hand, decreasescore u beats u. However, case score c also decreases k.conclude c cannot made winner cloning.However, converse true, illustrated following example.Example 5.11. Consider election = {a, b, c, u, w}. Suppose beats u, ubeats b, b beats w, w beats a, u w beat c, pair candidates tied.Note McGarveys theorem (1953) voters preferences producepairwise majority graph. election, c undominated. Indeed, beatenu w, tied alternative beats u, namely, a, alternativebeats w, namely, b. However, cs score negative, remain negativecloning. hand, counting argument, election alternativenegative Copeland score, least one alternative positive Copeland score.Hence, c cannot made winner cloning.552fiCloning Electionsu110000111100001110c01b110010wFigure 1: Candidate c undominated, cannot made winner cloningInstead, characterize 0+ -manipulable proles terms propertiesinduced (bipartite) subgraph (A, X) whose vertices are, one hand, candidatestied c, and, hand, candidates beat ccandidates beaten c. However, clear characterization leads polynomialtime algorithm detecting proles.Specically, prole c covered 0+ -manipulable cloningfavor c, following must hold. Let = (c) let Z set candidatesbeat c candidates beaten c. associate candidate z Znumber sz = Sc C (z) Sc C (c). goal assign nonnegative integer q(y) everyz Zfi(y,z)Xq(y)fiq(y) sz .(1)(z,y)XIndeed, linear program integer nonnegative solution (q (y))yY, replace(y)+1 clones. lower score z Zq(y,z)X q (y)(z,y)X q (y) thus ensure cs Copeland score least highcandidate Z. take care rest candidates cloning c (and askingvoters order clones c way) candidates D(c),proof Theorem 5.9. Thus, condition (1) sucient 0+ -manipulability. (We remark,however, additional constraints may needed 1-manipulability, since cloning cmay stronger eect candidates Z average clone c.)Conversely, assignment impossible, way ensurecandidates Z lower Copeland score c. Indeed, cloning c candidatesD(c) help, candidate also beaten candidate Z.hand, cloning candidate U (c) harm c (or clones) least muchharm candidates Z. Thus, way close gap ccandidates Z clone candidates (c), captured integer linear program.Note also linear program (1) admit integer solution, remainscase clone candidates. Indeed, cloning candidates \ (Y Z)change (1). Cloning candidate z Z replaces existing constraint severalidentical ones. Finally, program obtained cloning candidate feasiblesolution, easily transformed feasible solution original program.introduce costs, optimal cloning becomes hard even elections oddnumber voters even UC model.553fiElkind, Faliszewski & SlinkoTheorem 5.12. Copeland, UC q-Cloning NP-hard q {0+ } (0, 1].Proof. give reduction X3C. Let = (G, S) input instance, G ={g1 , . . . , g3K } ground set = {S1 , . . . , SM } family 3-element subsets G.convenient assume 2K; always achieve duplicatingsets S. construct instance Copeland elections preferredcandidate c yes-instance X3C, 1-successful cloningintroduces K clones, and, furthermore, no-instance X3C,exist 0+ -successful cloning introduces K clones.set candidates election = G F {c}, cmanipulators preferred candidate, F = {f1 , . . . , fM }, = {d1 , . . . , d3M +2 }.cloning budget set K. describe voters providing outcomes headto-head contests candidates A. McGarveys theorem (McGarvey, 1953),tournament realized majority relation certain preference prole,computed polynomial time. results head-to-head contestscandidates G F {c} follows:1. c beats fj F .2. gi G beats c.3. gi G Sj S, gi beats fj gi/ Sj .4. remaining contests within G F {c} result tie.limit candidates G F {c}, following scores: (a) c3K points, (b) gi G 1 + 1 points, (c) fj F0 points.Further, set results head-to-head contests candidates G F {c}follows:5. c beats 2M + 2K 3M candidates {d1 , . . . , d3M }.6. gi G beats exactly many candidates {d1 , . . . , d3M } score3M K + 1.7. contests candidates G F {c} resulttie.Finally, set contests within follows: di {d1 , . . . , d3M } loses d3M +1d3M +2 , remaining contests within result tie. Let N = 3M .resulting election following scores:1. c N K points.2. gi G N K + 1 points.3. dN +1 dN +2 N points each.4. Every candidate 0 points.554fiCloning ElectionsConsider nonnegative integer k. Replacing single candidate k+1 clones increasescandidates scores k, score clone diercloned candidate k. result, candidates winnerscloning manipulation cost K G {c, dN +1 , dN +2 }. Thus, followingdiscussion consider scores candidates only.Introducing single clone fj F increases 1 scores c/ Sj . Thus, set J {1, . . . , } |J| = K iJ Si = G,giintroducing single clone candidate {fi | J} ensures c winnerelection. depend voters order introduced clones, i.e.,cloning strategy 1-successful.converse direction, argue 0+ -successful cloningcost K, yes-instance X3C. Let us consider 0+ -successfulcloning. introduce K clones, additional clone increase csscore 1, c trails dN +1 dN +2 K points, cloning clonesdN +1 dN +2 least N points. Consequently, cannot clonecandidates D: cloning di \ {dN +1 , dN +2 } increases scores dN +1 dN +2 ,cloning dN +1 dN +2 increase cs score. Cloning gi G alsoincrease cs score, thus clone members F {c}. arguecloned members F correspond cover G (note impliesexactly K them, cloned exactly once). Indeed, suppose otherwise,let gi element G covered union sets correspondcloned members F . cloning manipulation increases score gi K,new clone contributes increase gi score. hand, cloningwithin budget increase cs score K, c still trails gi , contradictionassumption cloning manipulation 0+ -successful. completesproof.6. Related Workreview several lines research related work. startdiscussing relevant work originates social choice community (Section 6.1),move computational study voting problems. Section 6.2 providedetailed comparison cloning classic problem control adding candidates(Bartholdi et al., 1992), Section 6.3 discuss related work computationalsocial choice.6.1 Cloning Social Choice Literaturerst study cloning undertaken Tideman (1987). started deningsubsets alternative set clones given prole. Specically, denedproper subset contains least two alternatives clone-set voterranks candidate outside members tied memberS. denition reects idea voter nds candidates similar. Now,every prole R denes set clone-sets C(R) 2A . Tideman denes voting ruleindependent clones following two conditions met clonesballot:555fiElkind, Faliszewski & Slinko1. candidate member set clones wins memberset clones wins member set eliminated ballot.2. candidate member set clones wins candidatewins clone eliminated ballot.Tideman considered number well-known voting rules, discovered amongrules STV one satised criterion. However, STV satisfymany important criteria voting rules, Condorcet consistency monotonicity. Thus, Tideman proposed new voting rule, ranked pairs rule,Condorcet consistent independent clones small fraction settings. Subsequently, Zavist Tideman (1989) proposed modication rulecompletely independent clones. Later shown voting rules,Schulzes rule (2003), also independent clones. Tideman considered resistancecloning important normative requirement voting rules, methodranked pairs proposed Zavist showed condition may satised.Another notion related cloning composition consistency, due Laond et al.(1996). dened tournament solution concepts (i.e., social choice correspondencestake tournaments inputs). given alternative set A, let (A) denote settournaments A. non-empty subset C component (A)c, c C \ C holds (a, c) (a, c ) ; componentC said nontrivial 1 < |C| < |A|. tournament said composedleast one nontrivial component. Components tournament natural counterpartsclone-sets preference prole.Let A1 , . . . , AK K disjoint nite sets alternatives, let T1 , . . . , TK K tournaments k = 1, . . . , K holds Tk (Ak ). Moreover, lettournament ([K]), [K] = {1, 2, . . . , K}. composition product tournaments T1 , . . . , TK tournament = (T ; T1 , . . . , TK ) dened = A1 . . . AKfollows. k, k [K] (a, b) Ak Ak tournament containspair (a, b) (i) k = k (k, k ) (ii) k = k (a, b) Tk .tournament solution concept said composition-consistentcomposition product = (T ; T1 , . . . , TK ) (A) holds (T ) = {(Tk ) | k (T )}.property may illustrated following way. Suppose K dierentprojects given society choose implement. Further, project Ak , k [K],nk dierent variants. Composition consistency guarantees choose bestvariant best project irrespectively whether use two-stage procedure rstchooses best project best variant, simply set single tournamentorder choose among variants projects.Laond et al. (1996) Laslier (1996) suggested similar construction social choicecorrespondences (which referred voting rules paper). Given set X, letRn (X) set n-voter proles X. Let A1 , . . . , AK K disjoint nite setsalternatives, consider K preference proles R1 , . . . , RK , Rk = (R1k , . . . , Rnk )prole Rn (Ak ) k [K]. Let R = (R1 , . . . , Rn ) Rn ([K]). composition product(R ; R1 , . . . , RK ) R proles R1 , . . . , RK n-voter prole R = (R1 , . . . , Rn )dened = A1 . . . AK follows. k, k [K] (a, b) Ak Akset Ri b (i) k = k k Ri k (ii) k = k Rik b. social choice556fiCloning Electionscorrespondence said composition-consistent n> 0 composition1Kproduct R = (R ; R , . . . , R ) Rn (A) holds (R) = {(Rk ) | k (R )}.Laond et al. (1996) Laslier (1996) proved number tournament solutionconcepts Banks Set, Uncovered Set, Tournament Equilibrium Set (TEQ),Minimal Covering Set composition-consistent, several tournamentsolution concepts social choice correspondences Top Cycle, Slater rule,Copeland rule, scoring rules composition-consistent.Laslier (2000) also introduced notion cloning consistency. social choice correspondence said cloning-consistent n >product0 composition1KR = (R ; R , . . . , R ) Rn (A), holds (R) = {Ak | k (R )}. requirement says one clone alternative winning, clones alternativemust win well. property useful set alternatives fuzzy, butasauthor acknowledgedterrible number alternatives xed clearlydened.concept composed prole necessarily useful manipulation cloning,relevant one might call decloning. idea decloning revealwhether prole (or, tournament) could obtained result cloningand, possible, identify underlying composition product. Recently, decloning proveduseful preprocessing tool dealing voting rules computationallyhard winner determination problem (Conitzer, 2006; Betzler, Fellows, Guo, Niedermeier, &Rosamond, 2009; Brandt, Brill, & Seedig, 2011). extended abstract current paper, presented Twenty-Fourth AAAI Conference Articial Intelligence(AAAI-2010), initiated complexity-theoretic study decloning voting; topicinvestigated Elkind, Faliszewski, Slinko (2011). However, decloning deservescareful study thus omitted paper.concept resistance cloning appeared also context study selfselectivity social choice functions. Koray Slinko (2008) discovered self-selectivitystronger requirement resistance cloning, even deletion candidates viewedspecial form cloning (one replaces candidate zero clones). partiallyexplains universally self-selective functions necessarily dictatorial, discoveredearlier Koray (2008). Koray Slinko (2008) circumvent impossibility resultrelaxing property self-selectivity: require social choice function select among reasonable social choice functions. concept reasonableinvolves social choice correspondence (for example, one selects Pareto optimalalternatives), essential social choice correspondence resistant cloningessential alternatives (for denition essential alternative see Koray & Slinko,2008).6.2 Comparison Cloning Models Adding Candidatesproblem closely related cloning election control. general, termrefers manipulating result election changing structure (e.g., eitheradding deleting candidates voters). computational study election controlinitiated Bartholdi et al. (1992) who, among issues, considered constructive controladding candidates (CCAC). model, given set registered candidates,557fiElkind, Faliszewski & Slinkoset spoiler candidates, set voters, preferences registeredcandidates spoiler candidates (however, take action, registered candidates participate election). task decide possible selectsubset spoiler candidates candidates registered, preferredcandidate becomes winner. Subsequently, Faliszewski, Hemaspaandra, Hemaspaandra,Rothe (2009) rened model introducing bound number candidatesadded.Formally, use following denition CCAC problem, basedone given Faliszewski et al. (2009).Denition 6.1. Let F voting rule. constructive control adding candidatesproblem (F-CCAC) given election (C A, R), C = , designatedcandidate p C, nonnegative integer t. ask set sizep unique F-winner election (C , R).4denition above, set C corresponds already registered candidates setset spoiler candidates manipulator introduce election.Bartholdi, Tovey, Trick considered two rules, Plurality Condorcets rule(i.e., rule selects Condorcet winner one exists winners otherwise),focused standard worst-case complexity results, classifying control problems eitherNP-complete P. Many researchers followed work studying variousvoting rules (Erdelyi, Nowak, & Rothe, 2009b; Faliszewski et al., 2009; Faliszewski,Hemaspaandra, & Hemaspaandra, 2011) various settings (Liu, Feng, Zhu, &Luan, 2009; Betzler & Uhlmann, 2009; Faliszewski et al., 2011), perhapsprominent destructive control Hemaspaandra, Hemaspaandra, Rothe (2007)control multi-winner elections Meir, Procaccia, Rosenschein, Zohar (2008).point reader recent survey Faliszewski, Hemaspaandra, Hemaspaandra(2010) details election control.q-Cloning (and, particular, UC q-Cloning) CCAC control similardeal adding new candidates, neither problems specialcase other. Indeed, place dierent restrictions candidates addedpositions votes. Specically, q-Cloning new candidates mustclones existing candidates, (especially 0+ -Cloning) freedomarrange new candidates votes. contrast, CCAC control problems,spoiler candidates need adjacent votes, ordercandidates vote predetermined.somewhat dierent model adding candidates recently proposed Chevaleyre, Lang, Maudet, Monnot (2010). paper, authors consider followingscenario. election happening period time candidates may still join in.given point, know candidates registered voters preferences candidates. voter may place new candidates arbitrarilyvote. Given k new candidates may still appear, alreadyregistered ones still chance winning? (Note that, case cloning,addition new candidates may benet original candidates hurt4. Unique-winner model standard control problems.558fiCloning Electionsothers.) Chevaleyre et al. (2010), andin recent follow-up workXia, Lang,Monnot (2011), give computational complexity results problem ndingpossible (co)winners new alternatives join (PcWNA). work diersrequire new candidates clones preexisting ones (in particular,require new candidates ranked consistently, consecutivelyvoters), diers control adding candidates allow introducing arbitrary new candidates (as opposed introducing already-ranked-by-voters candidatespredened set spoilers). Formally, model special case possible winnerproblem, introduced Konczak Lang (2005), studied many researchers (Xia & Conitzer, 2011; Betzler & Dorn, 2010; Bachrach, Betzler, & Faliszewski,2010; Baumeister & Rothe, 2010).Table 1 provides comparison complexity control adding candidates (CCACcontrol), possible co-winner determination new alternatives join (PcWNA),q-Cloning q {0+ , 1} UC model (using UC model analogous countingnumber new candidates CCAC control problems). rst columnTable 1, provide complexity results CCAC control Plurality Runo, kapproval, Borda, Veto, missing existing literature. Sinceresults tangential topic paper, relegate Appendix B.Table 1 shows cloning PcWNA computationally incomparable (assumingP = NP). example, 2-Approval 0+ -Cloning NP-hard, whereas PcWNA P.hand, Maximin 0+ -Cloning P, PcWNA NP-complete.contrast, Table 1 appears indicate CCAC control harder cloning.results entirely surprising: construct contrived instances CCACcontrol placing spoiler candidates way like, facilitate computationalhardness proofs. One may therefore conjecture UC 0+ -Cloning always easierCCAC control. However, turns case.Theorem 6.2. voting rule constructive control adding candidatesP, UC 0+ -Cloning NP-hard.proof Theorem 6.2 given Appendix B; voting rule constructedproof highly articial, demonstrates UC 0+ -Cloning cannot reducedCCAC control (unless P = NP).wrap discussion control adding candidates, mention interestingtwist standard model election control recently studied Faliszewski,Hemaspaandra, Hemaspaandra, Rothe (2011) Brandt, Brill, Hemaspaandra,Hemaspaandra (2010). papers, authors study complexity control (aswell manipulation bribery) single-peaked electorates. main ndingmany control problems known NP-hard unrestricted preferences (andcontrol problems belong category) turn solvable polynomial timepreferences single-peaked. comparison, cloning computationally feasiblemany rules even without assuming special properties electorate. side note,mention cloning candidate may destroy single-peakedness election:voter ranks clones uniformly random, resulting ranking clones unlikelysingle-peaked. problem collapsing minimum number clones ordermake given election single-peaked studied detail Elkind et al. (2011).559fiElkind, Faliszewski & SlinkoVoting rulePluralityMaximinPluralityw/RunoVetoCCAC controlNPC (Bartholdiet al., 1992)NPC (Faliszewskiet al., 2011)NPCPcWNAP (Betzler & Dorn,2010)NPC (Xia et al., 2011)0+ -CloningP1-CloningPP (Xia et al., 2011)PNPCP (Betzler & Dorn,2010)P (Chevaleyre et al.,2010)P (Chevaleyre et al.,2010)NPC(Chevaleyreet al., 2010)?PPP?NP-hardNP-hardNP-hardNP-hardNP-hardNP-hardBordaNPC2-ApprovalNPCk-Approval,k3CopelandNPCNPC (Faliszewskiet al., 2009)Table 1: complexity control via adding candidates (CCAC), possible co-winnerdetermination new alternatives join (PcWNA), q-CloningUC model q {0+ , 1}. Note Plurality, Plurality RunoMaximin 1-successful cloning impossible. results CCAC controlunique-winner model (though also proved non-uniquewinner model), whereas work non-unique winner model. PcWNAresults Plurality Veto follow directly general resultsBetzler Dorn (2010) possible winner problem. Xia et al. (2011) alsogive NP-completeness result variant Copeland rule known Copeland0 ,score candidate simply number head-to-head contestscandidate wins.560fiCloning Elections6.3 Cloning Campaign Managementlarge extent, work cloning motivated applications cloning campaignmanagement. However, campaign management understood multiple wayswell. particular, issue campaign management voting previouslystudied computational perspective Elkind, Faliszewski, Slinko (2009),introduced problem swap bribery. model, voter associatedcertain cost function, describes dicult make local changes voterspreferences. goal campaign manager ensure given candidate becomeswinner smallest possible cost. problem turns NP-hard almostvoting rules, special cases admit polynomial-time solutions. Further, onefocuses variant swap bribery one allowed shift forward preferredcandidate, possible nd eective (approximation) algorithms (Elkind et al., 2009;Elkind & Faliszewski, 2010; Schlotter, Elkind, & Faliszewski, 2011). Going dierentresearch direction, Dorn Schlotter (2010) provide parameterized complexity studyswap bribery. course, standard model bribery (Faliszewski, Hemaspaandra, &Hemaspaandra, 2009), one pay voter change vote arbitrarily, alsointerpreted context campaign management.Also, probabilistic model put forward paper, and, particular, denitionq-successful cloning similar spirit model Erdelyi, Fernau, Goldsmith, Mattei,Raible, Rothe (2009a), voters bribed increase probabilities votingfavor particular alternative.Finally, problem cloning particularly relevant open, anonymous environments,Internet. settings, problem closely related cloning candidatescloning voters. Specically, anonymous environment agent might capablecreating several instances vote multiple times. Voting rules resistantkind manipulation called false-name-proof; studied Conitzer(2008). variant framework which, similarly general model, creating newidentities costly subsequently considered Wagman Conitzer (2008).7. Conclusionsprovided formal model manipulating elections cloning, characterized 0+ manipulable 1-manipulable proles many well-known voting rules, exploredcomplexity nding minimum-cost cloning manipulation. grouping voting rulesaccording susceptibility manipulation diers standard classicationsvoting rules: e.g., scoring rules behave dierently other, Maximinsimilar Plurality Copeland. Future research directions include designingapproximation algorithms minimum-cost cloning voting rulesproblem known NP-hard, extending results voting rules.Acknowledgmentswould like thank anonymous JAIR referees useful feedback. EdithElkind supported NRF (Singapore) Research Fellowship (NRF-RF2009-08)NTU start-up grant. Piotr Faliszewski supported AGH University Technology561fiElkind, Faliszewski & SlinkoGrant no. 11.11.120.865, Polish Ministry Science Higher Education grant N-N206378637, Foundation Polish Sciences program Homing/Powroty. Arkadii Slinkosupported Faculty Science Research Development Fund grant 3624495/9844.Appendix A. Cloning Manipulators Preferred CandidateBorda: Odd Number Voterssection, present proof Proposition 5.3. (We use notation introducedparagraph preceding Theorem 5.2.)Proposition 5.3. election odd number voters 1-manipulatedrespect Borda cloning manipulators preferred candidate c, r+ r .Proof. Let n number voters. Suppose r+ > r . Consider cloninginvolves c only. Suppose results k clones c, denote c(1) , . . . , c(k) .Let denote original Borda score c. show cloning 1-successful,suces describe ordering clones results c losing election. Sincen = 1 cloning successful, assume without loss generality n 3.Suppose rst k odd. Consider prole5 rst voter ranks clonesc(k) c(k2) . . . c(1) c(k1) c(k3) . . . c(2) ,second voter ranks clonesc(k1) c(k3) . . . c(2) c(k) c(k2) . . . c(1) ,third voter ranks clonesc(1) . . . c(k) ,remaining voters split n32 pairs, pair rst voter ranks(k)(1)clones c . . . c , second voter ranks clones c(1) . . . c(k) ..hard see prole Borda score clone + n(k1)2Indeed, let us rst consider c(k) . rst voter ranks k 1 clones c(k) ,(k)second voter ranks k12 clones c , third voter ranks clones3(k1)c(k) , i.e., c(k) gets 2 additional points rst 3 voters. Also, gets k 1additional points.additional point pair remaining voters, i.e., (n3)(k1)2n(k1)Thus, Borda score + 2 . similar calculation shows Borda score(n3)(k1)c(k1) + k3= + n(k1). Now, compare two consecutive2 + (k 1) + 1 +22odd-numbered clones, i.e., c(j) c(j2) j odd, see c(j) rankedc(j2) rst two votes, two positions c(j) third vote, getnumber extra points rst three voters. Since two candidates getnumber votes last n 3 voters, follows c(j) c(j2)Borda scores. argument applies pair consecutive even-numbered clones..Hence, simple inductive argument shows Borda score clone + n(k1)25. grateful Dima Shiryaev suggesting construction.562fiCloning ElectionsNow, k even, set k = k 1, rank rst k clones using constructionodd k given above. place c(k) clones rst n12 votesclones remaining n+1votes.Clearly,scoreclonec(j) , j < k,2n(k 2) n + 1n(k 1) + 1n(k 1);s++=s+=s+2222last equality holds since n odd k even. Moreover, score c(k) + (kn(k1). Thus, values k Borda score clone1) n12 s+2n(k1)+ 2 .show prole c win, consider two cases.Case 1 (r + = +). alternative preferred c least n+12voters higher Borda score c. cloning increases scoren(k1)n+1.least n+12 (k 1), nal Borda score least sB (a) + 2 (k 1) > +2Thus, cloning, clones c still lower scores a, i.e., cloning1-successful.Case 2 (r + < +). case, exist candidates A+ , b. cloning, Borda score sB (a) + nn2snaa1 > 2snb +12 (k 1), bsbbBorda score sB (b) + n+n2 (k 1). Thus, c winner, k must satisfyn(k 1)n nasB (a) +s+(k 1);22n(k1)2n(k1)+1.2sa = sB (a)n + nbn(k 1)sB (b) +s+(k 1).22Thus, rewriting inequalities, obtainna1(k 1) + ,22sb = sB (b)nb1(k 1) .22Since k integer, impliesff2sb + 12sa 1+k1= r ,r =nanbcontradiction.Appendix B. Proofs Section 6.2proof Theorem B.1 proceeds fairly straightforward reduction PluralityCCAC. contrast, remaining proofs section employ reductions X3C,quite technical.Theorem B.1. xed k, k 1, constructive control adding candidatesk-Approval NP-complete.563fiElkind, Faliszewski & SlinkoProof. k = 1, k-Approval simply Plurality Plurality-CCAC shownNP-complete (Bartholdi et al., 1992). Thus, let us assume k 2.Clearly, k-Approval-CCAC NP. prove hardness, give reductionPlurality-CCAC k-Approval-CCAC. Given instance = (C, A, R, p, t) PluralityCCAC R = (R1 , . . . , Rn ) (see Denition 6.1), build instance = (C, A, R, p, t)k-Approval-CCAC follows:1. |R| = 1, solve polynomial time (which easy case) outputxed instance k-Approval-CCAC answer.2. n = |R| > 1, set = {di,j | 1 n, 1 j k 1} let C = C D.= 1, . . . , n, i-th preference order Ri candidates di,1 , . . . , di,k1 rankedpositions 1, . . . , k 1, candidate ranked rst Ri rankedposition k. set R = (R1 , . . . , Rn ).Clearly, n = 1, reduction works correctly. suppose n > 1. A,candidate c C , Plurality score c (C , R)k-Approval score (C , R), k-Approval score (C , R) 1.complete proof, remains observe candidate c unique winnerPlurality election least two voters, c receives least two points.Theorem B.2. Constructive control adding candidates Plurality Runo NPcomplete.Proof. problem clearly NP. hardness reduction X3C. Let = (G, S)input instance X3C, G = {g1 , . . . , g3K } ground set = {S1 , . . . , SM }family 3-element subsets G.construct instance CCAC Plurality Runo follows. letcandidate set C = {p, u, w}, let set spoiler candidates = {a1 , . . . , }.preference prole R consists 6K + 20 preference orders R1 , . . . , R6K+20 , describedfollows. = 1, . . . , 3K, let Ai = {aj | gi Sj }. Preference orders Ri R3K+i ,= 1, . . . , 3K, givenAi u \ Ai p wAi w \ Ai p u,respectively. also 7 voters whose preference order p u w, 7 voterswhose preference order u p w, 6 voters whose preference order wp u. Finally, set = K.claim p become unique winner election (C, R) adding= K spoiler candidates yes-instance X3C.Let us rst consider Plurality scores candidates (C, R). Sc P (u) =3K + 7, Sc P (w) = 3K + 6, Sc P (p) = 7. runo u w, thus pwin.Now, consider subset election (C , R). Let Sc P (c) denotePlurality score candidate c C election (C , R). Sc P (p) = 7,Sc P (u) 7, Sc P (w) = Sc P (u) 1, and, moreover, Sc P (ai ) 6 ai .implies candidate ever participate runo. Thus, dependingparticipating spoiler candidates, following runo scenarios possible:564fiCloning Elections1. Sc P (u) 9. Sc P (w) 8, runo u w.2. Sc P (u) = 8. Sc P (w) = 7, runo u either p w.3. Sc P (u) = 7. Sc P (w) = 6, runo u p.use parallel-universe tie-breaking rule, half voters preferp u, p unique winner election Sc P (u) = 7. is, pmade unique winner election adding candidatespossible choose subset |A | K u receives Plurality pointsrst 6K voters election (C , R). Clearly, set propertyevery preference order among R1 , . . . , R3K member ranked u.|A | K, possible collection = {Si | ai } exact3-cover G.prove CCAC control Borda NP-complete well, need toolconstruct Borda votes conveniently.Lemma B.3. Let C = {c1 , . . . , c2t1 , d}, 2, set candidates let ={a1 , . . . , } setspoiler candidates. Let 1 , . . . , 2t1 sequence nonnegativeintegers, set L = 2t1i=1 . preference prole R = (R1 , . . . , R2L )C Borda scores election (C , R) follows:1. ci C, Sc B (ci ) = L(2|A | + |C| 1) + .2. Sc B (d) = L(2|A | + |C| 1) L.3. ai , Sc B (ai ) L(2|A | + |C| 1) 2L.Moreover, preference prole R computable time polynomial |C| + |A| + L.Proof. = 1, . . . , 2t 1, set e = ci , renumber candidates C \ {d, e}b1 , . . . , b2t2 , consider preference orders R2i1 R2i givenR2i1 : b1 b2 . . . bt1 e bt . . . b2t2 A,R2i : b2t2 b2t3 . . . bt e bt1 . . . b1 A.Let Ri = (R2i1 , R2i ). given A, election (C , Ri ) bi C \ {d, e}receives 2|A | + |C| 1 points, e receives 2|A | + |C| points, receives 2|A | + |C| 2points. Moreover, candidate ai receives 2|A | 2 points.preference prole R copies R2i1 copies R2i = 1, . . . , 2t1. easy see satises condition lemma.Theorem B.4. Constructive control adding candidates Borda NP-complete.Proof. easy see CCAC control problem Borda NP.show problem NP-hard giving reduction X3C.Let (G, S) input instance X3C, G = {g1 , . . . , g3K } ground set= {S1 , . . . , SM } collection 3-element subsets G. assume without lossgenerality K even K > 2; achieved, e.g., duplicating instance.565fiElkind, Faliszewski & Slinkoconstruct instance problem follows. set registered candidatesC {p, d} G (we sometimes refer p g3K+1 ) set spoiler candidates= {a1 , . . . , }. preference prole R consists two parts, R R . rstdescribe R , dene R based number Borda points candidates getR . = 1, . . . , , preference prole R contains exactly one preference order\ {ai } Si p ai G \ Si d.candidate c C, let Sc B (c) number Borda points thatc getsR , assuming candidate participates election. Set = cC Sc B (c).Observe irrespective subset spoiler candidates participates election,spoiler candidate ai gets = (3K + + 1) points R . Also,election set alternatives C , candidate p gets Sc B (p) + |A | points R ,gi G gets Sc B (gi ) + |{aj | aj gi Sj }| points R .= 1, . . . , 3K, set= + Sc B (gi ) 2,p = g3K+1 set3K+1 = + Sc B (p) K.obtain R applying Lemma B.3 candidate set C (where gi takesrole ci p takes role c3K+1 ), spoiler candidate set A, sequence1 , . . . , 3K+1 ; note use assumption K even (and hence |C| even).Finally, set= K.3K+1, set f (A ) = L(2|A | + |C| 1) + + S.Let L = i=1A, election (C , R + R ) candidates following Borda scores:1. Sc B (p) = f (A ) K + |A |.2. gi G, Sc B (gi ) = f (A ) 2 + |{aj | aj gi Sj }|.3. Irrespective choice , ai Sc B (ai ) < Sc B (p)Sc B (d) < Sc B (p).easy see p Borda winner election (C, R + R ). Letus assume subset spoiler candidates |A | K punique winner election (C , R + R ). argument above, non-empty.Now, aj gi Sj Sc B (gi ) f (A ) 1. Therefore, punique winner (C , R + R ), case Sc B (p) f (A ), i.e.,|A | = K, and, furthermore, gi G one aj gi Sj .Hence, collection = {Sj | aj } consists K non-overlapping sets size 3, i.e.,exact cover G. Conversely, easy see exact cover Gsets = {aj | Sj }, p unique winner (C , R + R ).completes proof.remark certain aspects control Borda already studiedRussel (2007); fact, Russel mentions idea cloning work, provideresults cloning CCAC control Borda.566fiCloning ElectionsTheorem B.5. Constructive control adding candidates Veto NP-complete.Proof. problem clearly NP. show NP-hardness, give reduction X3C.Let (G, S) input instance X3C, G = {g1 , . . . , g3K } ground set= {S1 , . . . , SM } family 3-element subsets G. Without loss generalityassume K > 2. = 1, . . . , 3K, let = |{Sj | gi Sj }|.form following instance problem. set registered candidatesC = G {p}, set spoiler candidates = {a1 , . . . , }. preference proleR consists four subproles R1 , R2 , R3 , R4 .R1 : R1 contains 4M preference orders groups four, one group set S.Si = {gi1 , gi2 , gi3 }, i-th group contains following four preference orders:\ {ai } p G \ {gi1 } gi1 ai ,\ {ai } p G \ {gi2 } gi2 ai ,\ {ai } p G \ {gi3 } gi3 ai ,\ {ai } G p ai .consists preferenceR2 : R2 contains 3K groupsvoters, i-thgroup3K(M)=3KM=3M (K 1). =orders, i.e., |R2 | = 3Ki=1i=11, . . . , 3K, preference orders i-th group given p G\{gi }gi .R3 : R3 contains K 2 preference orders form G p.R4 : R4 contains (3K + 1)M 2 preference orders. = 1, . . . , , j = 1, . . . , 3K,preference orders form p G \ {gj } gj \ {ai } ai= 1, . . . , , preference orders form G p \ {ai } ai .Intuitively, R1 models input X3C instance, R2 ensures within R1 R2candidates receive number points (assuming candidates C participate), R3 models constraint added candidates must correspond cover,R4 ensures none spoiler candidates become winner. Let us makeobservations formal calculating scores candidates, assuming setcandidates C A.j = 1, . . . , 3K, let t(A , gj ) number sets Si gj Siai . Candidate gj receives |R1 | j + t(A , gj ) points R1 , |R2 | (M j ) pointsR2 , |R3 | points R3 . Thus, total gj receives4M j + t(A , gj ) + 3M (K 1) (M j ) + (K 2) = 3KM + t(A , gj ) + (K 2)points voters R1 + R2 + R3 . Similarly, p receives 3M + |A | + |R2 | = 3KM + |A |points R1 + R2 + R3 ai receives |R1 | 4 + |R2 | + |R3 | = 4M 4 +3M (K 1) + (K 2) = (3K + 1) + (K 6) points voters R1 + R2 + R3 .remains calculate many points candidate receives R4 . Note(3K + 1)M 2 preference orders R4 ai ranked last least(3K + 1)M them. Thus, ai receives (3K + 1)M 2 (3K + 1)M points567fiElkind, Faliszewski & SlinkoR4 . hand, = , candidate C receives exactly (3K + 1)M 2points R4 , whereas = , candidate C receives 3KM 2 points R4 .set = K, ask whether p made unique winner addingspoiler candidates. easy see = , candidate p loses candidatesG, thus unique winner election. suppose = . SetF = (3K + 1)M 2 + 3KM + K 1. candidates following scores:1. Sc V (p) = F + |A | K + 1,2. gj G, Sc V (gj ) = F 1 + t(A , gj ),3. ai , Sc V (ai ) F 3KM 5.Thus, clearly member winner. Let us assume 0 < |A | K punique winner election. Since t(A , gj ) 1 least one gj G, holdsgj G least F points, therefore score p least F + 1.implies |A | = K. Further, gj G must case t(A , gj ) 1. Since|A | = K, means collection {Si | ai } exact cover G setsS.easy see converse direction also true. Thus, possible ensurep winner election adding k candidates(G, S) yes-instance X3C.Theorem 6.2. voting rule constructive control adding candidatesP, UC 0+ -Cloning NP-hard.Proof. idea proof, common several results type (see, e.g., paperFaliszewski et al., 2009, authors construct voting rule problembribery P, problem manipulation NP-hard), embed NP-completeproblem winner determination procedure newly constructed voting rule.Let L NP-complete language alphabet = {0, 1}. soon provideassumptions regarding L (all easily satised), so, describeelection encode pair strings .Fix election E = (A, R) R = (R1 , . . . , R , R+1 ). assume without lossgenerality = {c1 , . . . , cm } last voter ranks candidates c1 +1c2 +1 +1 cm . say E encodes two length- binary strings, x = x1 . . . x= y1 . . . , following conditions hold:1. > 0 4.2. voter ranks c1 c2 top two positions.3. = 1, . . . , , yi = 0 c1 c2 yi = 1 c2 c1 .4. = 1, . . . , , xi = 0 c3 c4 cm xi = 1cm cm1 c3 .568fiCloning ElectionsOtherwise E encode strings. Note last preference order R+1special, denes roles candidates; also, requiring > 0 explicitly forbidencoding pair two empty strings.denition NP basic properties NP-complete languages, assumelanguage L admits polynomial-time algorithm B every binary string xlength holds x L binary string lengthB(x, y) accepts.6 Further, assume L contain empty stringcontain all-0 strings.dene voting rule, call L. Let E = (A, R) election. Eencodes strings x B(x, y) accepts (that is, x L witnessescase), candidates winners. Otherwise, winnercandidate ranked last last voter.First, claim L-CCAC P. Let = (E, p, t) instance L-CCAC,E = (C A, R), C = {c1 , . . . , cm }, = {a1 , . . . , }, R = (R1 , . . . , Rn ), p Cpreferred candidate, Z+ bound number candidatesadd. p winner prior adding candidates, accept. Note p rankedlast last voter, cannot change adding candidates A. Therefore,make p winner, add candidates inuence strings x, encodedelection move election state encode stringsstate does. However, goal achieved addingcandidates, also achieved adding 4 candidates. Indeed, supposeadd candidates ai1 , . . . , ais , 4 < t, ai1 n ai2 n n aisresulting election encodes strings x y. easy see removecandidates ai5 , . . . , ais , resulting election also encodes strings x y.Thus, test possible make p winner adding candidates A, sucestry adding subsets size 4, and, them, verify whetherresulting election encodes two strings x B(x, y) accepts. Clearly,done polynomial time.hand, UC 0+ -Cloning NP-complete L (in fact, remains trueZC 0+ -Cloning cost model allows adding least one clone). givereduction L. Let x input binary string length ; assume withoutloss generality > 0. create election E = (A , R) = {a, c1 , c2 , c3 }set candidates R = (R1 , . . . , R , R+1 ) preference prole,1. R+1 given +1 c1 +1 c2 +1 c3 .2. = 1, . . . , , xi = 0 Ri given c1 c2 c3 xi = 1Ri given c3 c2 c1 .easy see either election encodes pair strings (0 , 0 )encode strings. pick preferred candidate; note ranked lastlast voter.Suppose x L, i.e., exists string y, |y| = , B(x, y) accepts.clone a(1) a(2) ask voters order clones top two6. Indeed, require length polynomially bounded |x|, condition wouldsimply denition membership NP. requirement x lengtheasily satised appropriate padding.569fiElkind, Faliszewski & Slinkopositions preference orders encode y. Clearly, resulting election candidateswin.Conversely, suppose possible clone candidates makewinner (i.e., candidates winners). Let E election cloning.must case E encodes two strings, x , B(x , ) accepts.happen, voter must rank clones rst two positions clonesc1 , c2 c3 remaining positions. implies x = x. Hence,0+ -successful cloning E, one replaces two clones, a(1) a(2) ,asks voters rank clones encode string propertyB(x, y) accepts.reduction computed polynomial time thus proof complete.ReferencesArrow, K., Sen, A., & Suzumura, K. (Eds.). (2002). Handbook Social Choice Welfare,Volume 1. Elsevier.Bachrach, Y., Betzler, N., & Faliszewski, P. (2010). Probabilistic possible winner determination. Proceedings 24th AAAI Conference Articial Intelligence, pp.697702. AAAI Press.Bartholdi, III, J., Tovey, C., & Trick, M. (1989). computational diculty manipulating election. Social Choice Welfare, 6 (3), 227241.Bartholdi, III, J., Tovey, C., & Trick, M. (1992). hard control election?.Mathematical Computer Modeling, 16 (8/9), 2740.Baumeister, D., & Rothe, J. (2010). Taking nal step full dichotomy possiblewinner problem pure scoring rules. Proceedings 19th European ConferenceArticial Intelligence, pp. 10211022. IOS Press.Betzler, N., & Dorn, B. (2010). Towards dichotomy nding possible winners electionsbased scoring rules. Journal Computer System Sciences, 76 (8), 812836.Betzler, N., Fellows, M., Guo, J., Niedermeier, R., & Rosamond, F. (2009). Fixed-parameteralgorithms Kemeny scores. Theoretical Computer Science, 410 (45), 45544570.Betzler, N., & Uhlmann, J. (2009). Parameterized complexity candidate control elections related digraph problems. Theoretical Computer Science, 410 (52), 4353.Brandt, F., Brill, M., Hemaspaandra, E., & Hemaspaandra, L. (2010). Bypassing combinatorial protections: Polynomial-time algorithms single-peaked electorates. Proceedings 24th AAAI Conference Articial Intelligence, pp. 715722. AAAIPress.Brandt, F., Brill, M., & Seedig, G. (2011). xed-parameter tractabilitycomposition-consistent tournament solutions. Proceedings 22nd InternationalJoint Conference Articial Intelligence, pp. 8590. AAAI Press.Brandt, F., & Fischer, F. (2007). Computational aspects covering dominance graphs.Proceedings 22nd AAAI Conference Articial Intelligence, pp. 694699.AAAI Press.570fiCloning ElectionsChevaleyre, Y., Lang, J., Maudet, N., & Monnot, J. (2010). Possible winners newcandidates added: case scoring rules. Proceedings 24th AAAIConference Articial Intelligence, pp. 762767. AAAI Press.Conitzer, V. (2006). Computing Slater rankings using similarities among candidates.Proceedings 21st National Conference Articial Intelligence, pp. 613619.AAAI Press.Conitzer, V. (2008). Anonymity-proof voting rules. Proceedings 4th InternationalWorkshop Internet Network Economics, pp. 295306. Springer-Verlag LectureNotes Computer Science #5385.Conitzer, V., Rognlie, M., & Xia, L. (2009). Preference functions score rankingsmaximum likelihood estimation. Proceedings 21st International Joint Conference Articial Intelligence, pp. 109115. AAAI Press.Dorn, B., & Schlotter, I. (2010). Multivariate complexity analysis swap bribery.Proceedings 5th International Symposium Parameterized Exact Computation, pp. 107122.Dutta, B., Jackson, M., & Le Breton, M. (2001). Strategic candidacy voting procedures.Econometrica, 69(4), 10131037.Dutta, B., Jackson, M., & Le Breton, M. (2002). Voting successive eliminationstrategic candidacy. Journal Economic Theory, 103, 190218.Elkind, E., & Faliszewski, P. (2010). Approximation algorithms campaign management.Proceedings 6th International Workshop Internet Network Economics,pp. 473482. Springer-Verlag Lecture Notes Computer Science #6484.Elkind, E., Faliszewski, P., & Slinko, A. (2009). Swap bribery. Proceedings 2ndInternational Symposium Algorithmic Game Theory, pp. 299310. Springer-VerlagLecture Notes Computer Science #5814.Elkind, E., Faliszewski, P., & Slinko, A. (2011). Clone structures voters preferences.Tech. rep. arXiv:1110.3939 [cs.GT], arXiv.org.Ephrati, E., & Rosenschein, J. (1997). heuristic technique multi-agent planning.Annals Mathematics Articial Intelligence, 20 (14), 1367.Erdelyi, G., Fernau, H., Goldsmith, J., Mattei, N., Raible, D., & Rothe, J. (2009a).complexity probabilistic lobbying. Proceedings 1st International Conference Algorithmic Decision Theory, pp. 8697. Springer-Verlag Lecture NotesComputer Science #5783.Erdelyi, G., Nowak, M., & Rothe, J. (2009b). Sincere-strategy preference-based approvalvoting fully resists constructive control broadly resists destructive control. Mathematical Logic Quarterly, 55 (4), 425443.Faliszewski, P., Hemaspaandra, E., & Hemaspaandra, L. (2009). hard briberyelections?. Journal Articial Intelligence Research, 35, 485532.Faliszewski, P., Hemaspaandra, E., & Hemaspaandra, L. (2010). Using complexity protectelections. Communications ACM, 53 (11), 7482.571fiElkind, Faliszewski & SlinkoFaliszewski, P., Hemaspaandra, E., & Hemaspaandra, L. (2011). Multimode control attackselections. Journal Articial Intelligence Research, 40, 305351.Faliszewski, P., Hemaspaandra, E., Hemaspaandra, L., & Rothe, J. (2009). LlullCopeland voting computationally resist bribery constructive control. JournalArticial Intelligence Research, 35, 275341.Faliszewski, P., Hemaspaandra, E., Hemaspaandra, L., & Rothe, J. (2011). shieldnever was: Societies single-peaked preferences open manipulationcontrol. Information Computation, 209 (2), 89107.Fishburn, P. (1977). Condorcet social choice functions. SIAM Journal Applied Mathematics, 33 (3), 469489.Hemaspaandra, E., Hemaspaandra, L., & Rothe, J. (2007). Anyone him: complexityprecluding alternative. Articial Intelligence, 171 (56), 255285.Konczak, K., & Lang, J. (2005). Voting procedures incomplete preferences. Proceedins Multidisciplinary IJCAI-05 Worshop Advances Preference Handling,pp. 124129.Koray, S. (2008). Self-selective social choice functions verify Arrow GibbardSatterthwaite theorems. Econometrica, 68 (4), 981995.Koray, S., & Slinko, A. (2008). Self-selective social choice functions. Social ChoiceWelfare, 31 (1), 129149.Lacey, M. (2010). Republican runs street people green ticket. New York Times.Laond, G., Laine, J., & Laslier, J. (1996). Composition consistent tournament solutionssocial choice functions. Social Choice Welfare, 13 (1), 7593.Laslier, J. (1996). Rank-based choice correspondencies. Economics Letters, 52 (3), 279286.Laslier, J. (1997). Tournament Solutions Majority Voting. Springer-Verlag.Laslier, J. (2000). Aggregation preferences variable set alternatives. SocialChoice Welfare, 17 (2), 269282.Liu, H., Feng, H., Zhu, D., & Luan, J. (2009). Parameterized computational complexitycontrol problems voting systems. Theoretical Computer Science, 410 (2729),27462753.McGarvey, D. (1953). theorem construction voting paradoxes. Econometrica,21 (4), 608610.Meir, R., Procaccia, A., Rosenschein, J., & Zohar, A. (2008). complexity strategicbehavior multi-winner elections. Journal Articial Intelligence Research, 33,149178.Miller, N. (1977). Graph theoretical approaches theory voting. American JournalPolitical Science, 21 (4), 769803.Russel, N. (2007). Complexity control Borda count elections. Masters thesis, RochesterInstitute Technology.572fiCloning ElectionsSchlotter, I., Elkind, E., & Faliszewski, P. (2011). Campaign management approvaldriven voting rules. Proceedings 25th AAAI Conference Articial Intelligence, pp. 726731. AAAI Press.Schulze, M. (2003). new monotonic clone-independent single-winner election method.Voting Matters, 17, 919.Tideman, T. (1987). Independence clones criterion voting rules. Social ChoiceWelfare, 4 (3), 185206.Wagman, L., & Conitzer, V. (2008). Optimal false-name-proof voting rules costlyvoting. Proceedings 23rd AAAI Conference Articial Intelligence, pp.190195. AAAI Press.Xia, L., & Conitzer, V. (2011). Determining possible necessary winners given partialorders. Journal Articial Intelligence Research, 41, 2567.Xia, L., Lang, J., & Monnot, J. (2011). Possible winners new alternatives join:New results coming up!. Proceedings 10th International Conference Autonomous Agents Multiagent Systems, pp. 829836. International FoundationAutonomous Agents Multiagent Systems.Zavist, T., & Tideman, T. (1989). Complete independence clones ranked pairsrule. Social Choice Welfare, 64 (2), 167173.573fiJournal Artificial Intelligence Research 42 (2011) 661-687Submitted 05/11; published 12/11Finding Consensus Bayesian Network StructuresJose M. Penajose.m.pena@liu.seADITDepartment Computer Information ScienceLinkoping UniversitySE-58183 LinkopingSwedenAbstractSuppose multiple experts (or learning algorithms) provide us alternativeBayesian network (BN) structures domain, interested combiningsingle consensus BN structure. Specifically, interestedconsensus BN structure represents independences given BN structures agreeupon parameters associated possible. paper, provemay exist several non-equivalent consensus BN structures finding oneNP-hard. Thus, decide resort heuristics find approximatedconsensus BN structure. paper, consider heuristic proposed MatzkevichAbramson, builds upon two algorithms, called Methods B, efficientlyderiving minimal directed independence map BN structure relative given nodeordering. Methods B claimed correct although proof provided (aproof sketched). paper, show Methods B correctpropose correction them.1. IntroductionBayesian networks (BNs) popular graphical formalism representing probability distributions. BN consists structure parameters. structure, directed acyclicgraph (DAG), induces set independencies represented probability distributionsatisfies. parameters specify conditional probability distribution node givenparents structure. BN represents probability distribution resultsproduct conditional probability distributions. Typically, single expert(or learning algorithm) consulted construct BN domain hand. Therefore,risk so-constructed BN accurate could if, instance,expert bias overlooks certain details. One way minimize risk consistsobtaining multiple BNs domain multiple experts and, then, combiningsingle consensus BN. approach received significant attention literature (Matzkevich & Abramson, 1992, 1993b; Maynard-Reid II & Chajewska, 2001; Nielsen& Parsons, 2007; Pennock & Wellman, 1999; Richardson & Domingos, 2003; del Sagrado& Moral, 2003). relevant references probably work PennockWellman (1999), shows even experts agree BN structure,method combining experts BNs produces consensus BN respectsreasonable assumptions whose structure agreed BN structure. Unfortunately,problem often overlooked. avoid it, propose combine experts BNsc2011AI Access Foundation. rights reserved.fiPenatwo steps. First, finding consensus BN structure and, then, finding consensusparameters consensus BN structure. paper focuses first step (webriefly discuss second step Section 8). Specifically, assume multiple expertsprovide us alternative DAG models domain, interested combiningsingle consensus DAG. Specifically, interested consensusDAG represents independences given DAGs agree upon manypossible. words, consensus DAG DAG represents independences among minimal directed independence (MDI) maps intersectionindependence models induced given DAGs.1 knowledge, whetherconsensus DAG cannot found efficiently still open problem. See workMatzkevich Abramson (1992, 1993b) information. paper, redefineconsensus DAG DAG fewest parameters associated amongMDI maps intersection independence models induced given DAGs.definition line finding DAG represent probability distribution p.desired DAG typically defined MDI map p fewest parametersassociated rather MDI map p represents independences. See,instance, work Chickering et al. (2004). number parameters associatedDAG measure complexity DAG, since number parametersrequired specify probability distributions represented DAG.paper, prove may exist several non-equivalent consensus DAGsfinding one NP-hard. Thus, decide resort heuristics findapproximated consensus DAG. paper, consider following heuristic dueMatzkevich Abramson (1992, 1993b). See also work Matzkevich Abramson(1993a) related information. First, let denote ordering nodes givenDAGs, denote G1 , . . . , Gm . Then, find MDI map Gi Gi relative. Finally, let approximated consensus DAG DAG whose arcs exactlyunion arcs G1 , . . . , Gm. mentioned formulationheuristic differs Matzkevich Abramson (1992, 1993b) following twopoints. First, heuristic introduced original definition consensus DAG.justify later heuristic also makes sense definition consensus DAG.Second, originally required consistent one given DAGs. removerequirement. all, key step heuristic finding MDI map GiGi . Since task trivial, Matzkevich Abramson (1993b) present two algorithms,called Methods B, efficiently deriving Gi Gi . Methods B claimedcorrect although proof provided (a proof sketched). paper,show Methods B correct propose correction them.said, first study problem finding consensus DAG. addition works discussed Matzkevich Abramson (1992, 1993b) PennockWellman (1999), works devoted problem Maynard-ReidII Chajewska (2001); Nielsen Parsons (2007); Richardson Domingos (2003);1. worth mentioning term consensus DAG different meaning computational biology(Jackson et al., 2005). There, consensus DAG given set DAGs G1 , . . . , Gm definedDAG contains arcs G1 , . . . , Gm . Therefore, difficulty lies keeping manyarcs possible without creating cycles. Note that, unlike present work, DAG interpretedinducing independence model Jackson et al.662fiFinding Consensus Bayesian Network Structuresdel Sagrado Moral (2003). elaborate differences worksours. Maynard-Reid II Chajewska (2001) propose adapt existing score-based algorithms learning DAGs data case learning data replacedBNs provided experts. approach suffers problem pointed PennockWellman (1999), consists essentially learning consensus DAGcombination given BNs. somehow related approach proposed RichardsonDomingos (2003). Specifically, propose Bayesian approach learning DAGsdata, prior probability distribution DAGs constructed DAGsprovided experts. Since approach requires data combinegiven DAGs single DAG, addresses problem rather different onepaper. Moreover, construction prior probability distribution DAGs ignoresfact given DAGs may different equivalent. is, unlikepresent work, DAG interpreted inducing independence model. workrelatively close del Sagrado Moral (2003). Specifically, showconstruct MDI map intersection union independence modelsinduced DAGs provided experts. However, three main differenceswork ours. First, unlike us, assume given DAGsdefined set nodes. Second, unlike us, assume existsnode ordering consistent given DAGs. Third, goal find MDImap whereas find MDI map fewest parameters associated amongMDI maps, i.e. consensus DAG. Finally, Nielsen Parsons (2007) developgeneral framework construct consensus DAG gradually. framework generalsense tailored particular definition consensus DAG. Instead,relies upon score defined user expert use score differentextensions current partial consensus DAG. individual scores combinedchoose extension perform. Unfortunately, see framework couldapplied definition consensus DAG.worth recalling paper deals combination probability distributions expressed BNs. readers interested combination probability distributions expressed non-graphical numerical forms referred to, instance, workGenest Zidek (1986). Note also interested combinationdata observed. readers interested combination dataobserved expert updated beliefs accordingly referred to, instance,work Ng Abramson (1994). Finally, note also aim combining givenDAGs DAG, consensus DAG. readers interested finding DAGgraphical features (e.g. arcs paths) significant number experts agree upon maywant consult works Friedman Koller (2003); Hartemink et al. (2002); Pena etal. (2004), since works deal similar problem.rest paper organized follows. start reviewing preliminaryconcepts Section 2. analyze complexity finding consensus DAG Section3. discuss heuristic finding approximated consensus DAG detailSection 4. introduce Methods B Section 5 show correct.correct Section 6. analyze complexity corrected MethodsB Section 7 show efficient approach thinksolve problem. close discussion Section 8.663fiPena2. Preliminariessection, review concepts used paper. DAGs, probabilitydistributions independence models paper defined V, unless otherwisestated. B DAG G, say B adjacent G. Moreover,say parent B B child G. denote parents B GP aG (B). node called sink node G children G. routetwo nodes B G sequence nodes starting ending Bevery two consecutive nodes sequence adjacent G. Note nodesroute necessarily distinct. length route number (not necessarilydistinct) arcs route. treat nodes G routes length zero. routeB called descending B arcs route directedtowards B. descending route B, B called descendant A.Note descendant itself, since allow routes length zero. Given subsetX V, node X called maximal G descendant node X \ {A}G. Given route B G route 0 B C G, 0denotes route C G resulting appending 0 .PQnumber parameters associated DAG G BV [ AP aG (B) rA ](rB 1),rA rB numbers states random variables correspondingnode B. arc B G said covered P aG (A) = P aG (B) \ {A}.covering arc B G mean adding G smallest set arcs Bbecomes covered. say node C collider route DAG exist twonodes B C B subroute route. Note B maycoincide. Let X, Z denote three disjoint subsets V. route DAG saidZ-active (i) every collider node route Z, (ii) every non-collider noderoute outside Z. route DAG G node Xnode Z-active, say X separated given Z G denoteX G Y|Z. denote X 6 G Y|Z X G Y|Z hold. definitionseparation equivalent common definitions (Studeny, 1998, Section 5.1).Let X, Y, Z W denote four disjoint subsets V. Let us abbreviate XXY. independence model set statements form X Y|Z, meaningX independent given Z. Given subset U V, denote [M ]Ustatements X, Y, Z U. Given two independence models N ,denote N X Y|Z X N Y|Z. say graphoidsatisfies following properties: symmetry X Y|Z X|Z, decompositionX YW|Z X Y|Z, weak union X YW|Z X Y|ZW, contractionX Y|ZW X W|Z X YW|Z, intersection X Y|ZW XW|ZY X YW|Z. independence model induced probability distribution p,denoted I(p), set probabilistic independences p. independence modelinduced DAG G, denoted I(G), set separation statements X G Y|Z.known I(G) graphoid (Studeny & Bouckaert, 1998, Lemma 3.1). Moreover, I(G)satisfies composition property X G Y|Z X G W|Z X G YW|Z (Chickering &Meek, 2002, Proposition 1). Two DAGs G H called equivalent I(G) = I(H).DAG G directed independence map independence model I(G) .Moreover, G minimal directed independence (MDI) map removing arc664fiFinding Consensus Bayesian Network StructuresG makes cease directed independence map . say Gordering nodes consistent when, every arc B G, precedes Bnode ordering. say DAG G MDI map independence modelrelative node ordering G MDI map G consistent .graphoid, G unique (Pearl, 1988, Thms. 4 9). Specifically, nodeA, P aG (A) smallest subset X predecessors , P (A),P (A) \ X|X.3. Finding Consensus DAG NP-HardRecall defined consensus DAG given set DAGs G1 , . . . , GmDAG fewest parameters associated among MDI mapsi=1 I(G ).sensible way start quest consensus DAG investigating whetherexist several non-equivalent consensus DAGs. following theorem answers question.Theorem 1. exists set DAGs two non-equivalent consensus DAGs.Proof. Consider following two DAGs four random variables numberstates each:KJLKJLfollowing two non-equivalent DAGs consensus DAG two DAGsabove:K&KJL%JLnatural follow-up question investigate whether consensus DAG foundefficiently. Unfortunately, finding consensus DAG NP-hard, prove below. Specifically, prove following decision problem NP-hard:CONSENSUSINSTANCE: set DAGs G1 , . . . , Gm V, positive integer d.QUESTION: exist DAG G V I(G)i=1 I(G )number parameters associated G greater ?Proving CONSENSUS NP-hard implies finding consensus DAG alsoNP-hard, existed efficient algorithm finding consensus DAG,could use solve CONSENSUS efficiently. proof makes use following two665fiPenadecision problems:FEEDBACK ARC SETINSTANCE: directed graph G = (V, A) positive integer k.QUESTION: exist subset B |B| k B leastone arc every directed cycle G ?LEARNINSTANCE: probability distribution p V, positive integer d.QUESTION: exist DAG G V I(G) I(p) numberparameters associated G greater ?FEEDBACK ARC SET NP-complete (Garey & Johnson, 1979). FEEDBACK ARCSET remains NP-complete directed graphs total degree vertexthree (Gavril, 1977). degree-bounded FEEDBACK ARC SET problem usedChickering et al. (2004) prove LEARN NP-hard. proof, Chickeringet al. (2004) use following polynomial reduction instance degree-boundedFEEDBACK ARC SET instance LEARN:Let instance degree-bounded FEEDBACK ARC SET consist directedgraph F = (VF , AF ) positive integer k.Let L denote DAG whose nodes arcs determined F follows.every arc ViF VjF AF , create following nodes arcs L:ViF(9)Aij (9)Bij (2)Cij (3)Hij(2).&Dij (9)Eij (2)Fij (2)GijVjF(9)(9)number parenthesis besides node number states corresponding random variable. Let HL denote nodes Hij L, let VL denoterest nodes L.Specify (join) probability distribution p(HL , VL ) I(p(HL , VL )) = I(L).Let instance LEARN consist (marginal) probability distribution p(VL )positive integer d, computed F k shown workChickering et al. (2004, Equation 2).describe instance LEARN resulting reductionreduced instance CONSENSUS polynomial time:Let C 1 denote DAG VL arcs L whoseendpoints VL .666fiFinding Consensus Bayesian Network StructuresLet C 2 denote DAG VL arcs Bij Cij Fijj.Let C 3 denote DAG VL arcs Cij Fij Eijj.Let instance CONSENSUS consist DAGs C 1 , C 2 C 3 , positiveinteger d.Theorem 2. CONSENSUS NP-hard.Proof. start proving polynomial reduction instance Fdegree-bounded FEEDBACK ARC SET instance C CONSENSUS. First, reduceF instance L LEARN shown work Chickering et al. (2004) and, then,reduce L C shown above.prove solution F iff solution C. Chickering etal. (2004, Thms. 8 9) prove solution F iff solution L.Therefore, remains prove solution L iff solutionC (note parameter L parameter C same). Let Lp(HL , VL ) denote DAG probability distribution constructed reductionF L. Recall I(p(HL , VL )) = I(L). Moreover:Let L1 denote DAG (HL , VL ) arcs L whoseendpoints VL .Let L2 denote DAG (HL , VL ) arcs Bij Cij Hij Fijj.Let L3 denote DAG (HL , VL ) arcs Cij Hij Fij Eijj.Note separation statement holds L also holds L1 , L2 L3 . Then,I(p(HL , VL )) = I(L) 3i=1 I(Li ) and, thus, I(p(VL )) [3i=1 I(Li )]VL = 3i=1 [I(Li )]VL .Let C 1 , C 2 C 3 denote DAGs constructed reduction L C. Note[I(Li )]VL = I(C ) i. Then, I(p(VL )) 3i=1 I(C ) and, thus, solutionL solution C. prove opposite. proof essentiallywork Chickering et al. (2004, Thm. 9). Let us define (Vi , Vj )edge component DAG G VL subgraph G arcsG whose endpoints {Vi , Aij , Bij , Cij , Dij , Eij , Fij , Gij , Vj }. Given solutionC C, create another solution C 0 C follows:Initialize C 0 C 1 .every (Vi , Vj ) edge component C, directed path C ViVj , add C 0 arcs Eij Cij Fij .every (Vi , Vj ) edge component C, directed path C Vi Vj ,add C 0 arcs Bij Fij Cij .667fiPenaNote C 0 acyclic C acyclic. Moreover, I(C 0 ) 3i=1 I(C )I(C 0 ) I(C ) i. order able conclude C 0 solution C,remains prove number parameters associated C 0 greaterd. Specifically, prove C 0 parameters associated C,less parameters associated solution C.seen before, I(C 0 ) I(C 1 ). Likewise, I(C) I(C 1 ) C solution C.Thus, exists sequence (resp. 0 ) covered arc reversals arc additionstransforms C 1 C (resp. C 0 ) (Chickering, 2002, Thm. 4). Note covered arcreversal modify number parameters associated DAG, whereas arcaddition increases (Chickering, 1995, Thm. 3). Thus, 0 monotonically increasenumber parameters associated C 1 transform it. Recall C 1 consistsseries edge components formViF(9)Aij (9)Bij (2)Cij (3)Dij (9)Eij (2)Fij (2)GijVjF(9)(9)number parenthesis besides node number states correspondingrandom variable. Let us study sequences 0 modify edge componentC 1 . 0 simply adds arcs Bij Fij Cij arcs Eij Cij Fij . Noteadding first pair arcs results increase 10 parameters, whereas addingsecond pair arcs results increase 12 parameters. Unlike 0 , may reversearc edge component. case, must cover arc first, impliesincrease least 16 parameters (covering Fij Vj adding Eij Vj impliesincrease exactly 16 parameters, whereas arc covering implies larger increase).Then, implies larger increase number parameters 0 . hand,reverse arc edge component, simply adds arcsC C 1 . Note either Cij Fij Cij Fij C, otherwiseCij C Fij |Z Z VL contradicts fact C solution C sinceCij 6 C 2 Fij |Z. Cij Fij C, either Bij Fij Bij Fij Cotherwise Bij C Fij |Z Z VL Cij Z, contradicts factC solution C since Bij 6 C 2 Fij |Z. Bij Fij would create cycle C, Bij FijC. Therefore, adds arcs Bij Fij Cij and, construction C 0 , 0 alsoadds them. Thus, implies increase least many parameters 0 .hand, Cij Fij C, either Cij Eij Cij Eij C otherwiseCij C Eij |Z Z VL Fij Z, contradicts fact Csolution C since Cij 6 C 3 Eij |Z. Cij Eij would create cycle C, Cij EijC. Therefore, adds arcs Eij Cij Fij and, construction C 0 , 0 adds eitherarcs Eij Cij Fij arcs Bij Fij Cij . case, implies increaseleast many parameters 0 . Consequently, C 0 parametersassociated C.Finally, note I(p(VL )) I(C 0 ) Chickering et al. (2004, Lemma 7). Thus,solution C solution L.668fiFinding Consensus Bayesian Network Structuresworth noting proof contains two restrictions. First, numberDAGs consensuate three. Second, number states random variableVL arbitrary prescribed. first restriction easy relax: proofextended consensuate three DAGs simply letting C DAG VLarcs > 3. However, open question whether CONSENSUS remainsNP-hard number DAGs consensuate two and/or number statesrandom variable VL arbitrary.following theorem strengthens previous one.Theorem 3. CONSENSUS NP-complete.Proof. Theorem 2, remains prove CONSENSUS NP, i.e.verify polynomial time given DAG G solution given instanceCONSENSUS.Let denote node ordering consistent G. causal list G relativeset separation statements G P (A) \ P aG (A)|P aG (A) node A.known I(G) coincides closure respect graphoid propertiescausal list G relative (Pearl, 1988, Corollary 7). Therefore, I(G)i=1 I(G ) iffGi P (A) \ P aG (A)|P aG (A) 1 m,i=1 I(G ) graphoid (delSagrado & Moral, 2003, Corollary 1). Let n, ai denote, respectively, numbernodes G, number arcs G, number arcs Gi . Let b = max1im ai .Checking separation statement Gi takes O(ai ) time (Geiger et al., 1990, p. 530). Then,checking whether I(G)i=1 I(G ) takes O(mnb) time. Finally, note computingnumber parameters associated G takes O(a).4. Finding Approximated Consensus DAGSince finding consensus DAG given DAGs NP-hard, decide resortheuristics find approximated consensus DAG. mean discardexistence fast super-polynomial algorithms. simply means pursuepossibility paper. Specifically, paper consider following heuristicdue Matzkevich Abramson (1992, 1993b). See also work MatzkevichAbramson (1993a) related information. First, let denote ordering nodesgiven DAGs, denote G1 , . . . , Gm . Then, find MDI map GiGi relative . Finally, let approximated consensus DAG DAG whosearcs exactly union arcs G1 , . . . , Gm. following theorem justifies takingunion arcs. Specifically, proves DAG returned heuristicconsensus DAG required consistent .Theorem 4. DAG H returned heuristic DAG fewestparameters associated among MDI mapsi=1 I(G ) relative .Proof. start proving H MDI mapi=1 I(G ). First, showI(H)i=1 I(G ). suffices note I(H) i=1 I(G ) G submgraph H, i=1 I(G ) i=1 I(G ) I(G ) I(G ) i. Now,669fiPenaassume contrary DAG H 0 resulting removing arc B Hsatisfies I(H 0 )i=1 I(G ). construction H, B G i, say= j. Note B H 0 P (B) \ P aH 0 (B)|P aH 0 (B), implies B Gj P (B) \((mi=1 P aGi (B)) \ {A})|(i=1 P aGi (B)) \ {A} P aH 0 (B) = (i=1 P aGi (B)) \ {A}I(H 0 )i=1 I(G ). Note also B Gj P (B) \ P aGj (B)|P aGj (B), implies B Gj P (B) \ P aGj (B)|P aGj (B) I(Gj ) I(Gj ). Therefore, B GjP (B) \ (P aGj (B) \ {A})|P aGj (B) \ {A} intersection. However, contradictsfact Gj MDI map Gj relative . Then, H MDI mapi=1 I(G )relative .Finally, notei=1 I(G ) graphoid (del Sagrado & Moral, 2003, Corollary 1).Consequently, H MDI mapi=1 I(G ) relative .key step heuristic is, course, choosing good node ordering . Unfortunately, fact CONSENSUS NP-hard implies also NP-hard findbest node ordering , i.e. node ordering makes heuristic return MDImapi=1 I(G ) fewest parameters associated. see it, noteexisted efficient algorithm finding best node ordering, Theorem 4 wouldimply could solve CONSENSUS efficiently running heuristic bestnode ordering.last sentence, implicitly assumed heuristic efficient,implies implicitly assumed efficiently find MDI map GiGi . rest paper shows assumption correct.5. Methods B CorrectMatzkevich Abramson (1993b) propose heuristic discussed previous section, also present two algorithms, called Methods B, efficientlyderiving MDI map G DAG G relative node ordering . algorithms workiteratively covering reversing arc G resulting DAG consistent. obvious way working produces directed independence map G.However, order arrive G , arc cover reverse iteration mustcarefully chosen. pseudocode Methods B seen Figure 1. Methodstarts calling Construct derive node ordering consistent Gclose possible (line 6). close possible, meannumber arcs Methods B later cover reverse kept minimum,Methods B use choose arc cover reverse iteration.particular, Method finds leftmost node interchanged leftneighbor (line 2) repeatedly interchanges node left neighbor (lines 3-46-7). interchanges preceded covering reversing corresponding arc G (line 5). Method B essentially identical Method A. differencesword right replaced word left vice versalines 2-4, arcs point opposite directions line 5. Note MethodsB reverse arc once.670fiFinding Consensus Bayesian Network StructuresConstruct (G, )/* Given DAG G node ordering , algorithm returns node orderingconsistent G close possible */123/* 34567891011=G0 = GLet denote sink node G0Let denote rightmost node sink node G0 */Add leftmost nodeLet B denote right neighborB 6=/ P aG (B) right BInterchange BGo line 5Remove incoming arcs G0G0 6= go line 3ReturnMethod A(G, )/* Given DAG G node ordering , algorithm returns G */123456789=Construct (G, )Let denote leftmost node whose left neighbor rightLet Z denote left neighborZ rightZ G cover reverse Z GInterchange ZGo line 36= go line 2Return GMethod B(G, )/* Given DAG G node ordering , algorithm returns G */123456789=Construct (G, )Let denote leftmost node whose right neighbor leftLet Z denote right neighborZ leftZ G cover reverse Z GInterchange ZGo line 36= go line 2Return GFigure 1: Construct , Methods B. correction Construct consists (i)replacing line 3 line comments it, (ii) removing lines 5-8.671fiPenaFigure 2: counterexample correctness Methods B.Methods B claimed correct work Matzkevich Abramson(1993b, Thm. 4 Corollary 2) although proof provided (a proof sketched).following counterexample shows Methods B actually correct. Let GDAG left-hand side Figure 2. Let = (M, I, K, J, L). Then, makeuse characterization introduced Section 2 see G DAG centerFigure 2. However, Methods B return DAG right-hand side Figure2. see it, follow execution Methods B step step. First, MethodsB construct calling Construct , runs follows:1. Initially, = G0 = G.2. Select sink node G0 . Then, = (M ). Remove incoming arcsG0 .3. Select sink node L G0 . Then, = (L, ). interchange performedL P aG (M ). Remove L incoming arcs G0 .4. Select sink node K G0 . Then, = (K, L, ). interchange performedK left L . Remove K incoming arcs G0 .5. Select sink node J G0 . Then, = (J, K, L, ). interchange performedJ P aG (K).6. Select sink node G0 . Then, = (I, J, K, L, ). interchangeperformed left J .Construct ends, Methods B continue follows:672fiFinding Consensus Bayesian Network Structures7. Initially, = (I, J, K, L, ).8. Add arc J reverse arc J K G. Interchange J K .Then, = (I, K, J, L, ).9. Add arc J reverse arc L G. Interchange L .Then, = (I, K, J, M, L).10. Add arcs K , reverse arc J G. Interchange J. Then, = (I, K, M, J, L).11. Reverse arc K G. Interchange K . Then, = (I, M, K, J, L).12. Reverse arc G. Interchange . Then, = (M, I, K, J, L) =.matter fact, one see early step 8 Methods Bfail: One see separated DAG resulting step 8,implies separated DAG returned Methods B,covering reversing arcs never introduces new separation statements. However,separated G .Note constructed selecting first , L, K, J, finally I.However, could selected first K, I, , L, finally J, wouldresulted = (J, L, M, I, K). , Methods B return G . Therefore,makes difference sink node selected line 3 Construct . However, Constructoverlooks detail. propose correcting Construct (i) replacing line 3 Letdenote rightmost node sink node G0 , (ii) removing lines 5-8 sincenever executed. Hereinafter, assume call Construct callcorrected version thereof. rest paper devoted prove MethodsB return G .6. Corrected Methods B Correctproving Methods B correct, introduce auxiliary lemmas.proof found Appendix A. Let us call percolating right-to-leftiterating lines 3-7 Method possible. Let us modify Method replacingline 2 Let denote leftmost node consideredadding check Z 6= line 4. pseudocode resulting algorithm,call Method A2, seen Figure 3. Method A2 percolates right-to-left oneone nodes order appear .Lemma 1. Method A(G, ) Method A2(G, ) return DAG.Lemma 2. Method A2(G, ) Method B(G, ) return DAG.Let us call percolating left-to-right iterating lines 3-7 Method Bpossible. Let us modify Method B replacing line 2 Let denote rightmostnode considered adding check Z 6= line 4.pseudocode resulting algorithm, call Method B2, seen Figure673fiPenaMethod A2(G, )/* Given DAG G node ordering , algorithm returns G */123456789=Construct (G, )Let denote leftmost node consideredLet Z denote left neighborZ 6= Z rightZ G cover reverse Z GInterchange ZGo line 36= go line 2Return GMethod B2(G, )/* Given DAG G node ordering , algorithm returns G */123456789=Construct (G, )Let denote rightmost node consideredLet Z denote right neighborZ 6= Z leftZ G cover reverse Z GInterchange ZGo line 36= go line 2Return GFigure 3: Methods A2 B2.3. Method B2 percolates left-to-right one one nodes reverse orderappear .Lemma 3. Method B(G, ) Method B2(G, ) return DAG.ready prove main result paper.Theorem 5. Let G denote MDI map DAG G relative node ordering . Then,Method A(G, ) Method B(G, ) return G .Proof. Lemmas 1-3, suffices prove Method B2(G, ) returns G . evidentMethod B2 transforms and, thus, halts point. Therefore,Method B2 performs finite sequence n modifications (arc additions covered arcreversals) G. Let Gi denote DAG resulting first modifications G,let G0 = G. Specifically, Method B2 constructs Gi+1 Gi either (i) reversingcovered arc Z, (ii) adding arc X Z X P aGi (Y ) \ P aGi (Z),(iii) adding arc X X P aGi (Z) \ P aGi (Y ). Note I(Gi+1 ) I(Gi )0 < n and, thus, I(Gn ) I(G0 ).674fiFinding Consensus Bayesian Network Structuresstart proving Gi DAG consistent 0 n. Sincetrue G0 due line 1, suffices prove Gi DAG consistentGi+1 0 < n. consider following four cases.Case 1 Method B2 constructs Gi+1 Gi reversing covered arc Z. Then,Gi+1 DAG reversing covered arc create cycle (Chickering,1995, Lemma 1). Moreover, note Z interchanged immediatelycovered arc reversal. Thus, Gi+1 consistent .Case 2 Method B2 constructs Gi+1 Gi adding arc X Z XP aGi (Y ) \ P aGi (Z). Note X left left Z ,Gi consistent . Then, X left Z and, thus, Gi+1DAG consistent .Case 3 Method B2 constructs Gi+1 Gi adding arc X XP aGi (Z) \ P aGi (Y ). Note X left Z Gi consistent, left neighbor Z (recall line 3). Then, X leftand, thus, Gi+1 DAG consistent .Case 4 Note may get modified Method B2 constructs Gi+1 Gi . Specifically, happens Method B2 executes lines 5-6 arcZ Gi . However, fact Gi consistent Zinterchanged fact Z neighbors (recall line 3) implyGi consistent Z interchanged.Since Method B2 transforms , follows result proven GnDAG consistent . order prove theorem, i.e. Gn = G ,remains prove I(G ) I(Gn ). see it, note Gn = G followsI(G ) I(Gn ), I(Gn ) I(G0 ), fact Gn DAG consistent ,fact G unique MDI map G0 relative . Recall G guaranteedunique I(G0 ) graphoid.rest proof devoted prove I(G ) I(Gn ). Specifically, proveI(G ) I(Gi ) I(G ) I(Gi+1 ) 0 < n. Note impliesI(G ) I(Gn ) I(G ) I(G0 ) definition MDI map. First, proveMethod B2 constructs Gi+1 Gi reversing covered arc Z.arc reversed covered implies I(Gi+1 ) = I(Gi ) (Chickering, 1995, Lemma 1). Thus,I(G ) I(Gi+1 ) I(G ) I(Gi ).Now, prove I(G ) I(Gi ) I(G ) I(Gi+1 ) 0 < nMethod B2 constructs Gi+1 Gi adding arc. Specifically, proveS-active route (S V) ABi+1 two nodes B Gi+1 ,S-active route B G . prove result induction numberoccurrences added arc ABi+1 . assume without loss generality addedABarc occurs i+1 fewer times S-active route B2Gi+1 . call minimality property ABi+1 . number occurrences2. difficult show number occurrences added arc ABi+1 two(see Case 2.1 intuition). However, proof theorem simpler ignore fact.675fiPenaFigure 4: Different cases proof Theorem 5. relevant subgraphs Gi+1G depicted. undirected edge two nodes denotes nodesadjacent. curved edge two nodes denotes S-active routetwo nodes. curved edge directed, route descending.grey node denotes node S.ABadded arc ABi+1 zero, i+1 S-active route B Gi and,thus, S-active route B G since I(G ) I(Gi ). Assumeinduction hypothesis result holds k occurrences added arc ABi+1 .prove k + 1 occurrences. consider following two cases. caseillustrated Figure 4.Case 1 Method B2 constructs Gi+1 Gi adding arc X Z X3ABAXZBP aGi (Y )\P aGi (Z). Note X Z occurs ABi+1 . Let i+1 = i+1 X Zi+1 .AXABNote X/ i+1 S-active Gi+1 because, otherwise, i+1 would3. Note maybe = X and/or B = Z.676fiFinding Consensus Bayesian Network StructuresS-active Gi+1 . Then, S-active route AXX GZBinduction hypothesis. Moreover, because, otherwise, AXi+1 X Z i+1would S-active route B Gi+1 would violate minimalityproperty ABi+1 . Note Z G (i) Z adjacentG since I(G ) I(Gi ), (ii) Z left (recall line 4). Notealso X G . see it, note X adjacent G sinceI(G ) I(Gi ). Recall Method B2 percolates left-to-right one onenodes reverse order appear . Method B2 currentlypercolating and, thus, nodes right righttoo. X G X would right and, thus, X wouldright . However, would contradict fact Xleft , follows fact Gi consistent . Thus, XG . consider two cases.Case 1.1 Assume Z/ S. Then, ZBi+1 S-active Gi+1 because, otherwise,ABi+1 would S-active Gi+1 . Then, S-active route ZBZ B G induction hypothesis. Then, AXXZ ZBS-active route B G .WB 4Case 1.2 Assume Z S. Then, ZB/i+1 = Z W i+1 . Note WWBABi+1 S-active Gi+1 because, otherwise, i+1 would S-active Gi+1 .B W B G inductionThen, S-active route Whypothesis. Note W Z adjacent G since I(G ) I(Gi ).fact proven Z G imply W adjacentG because, otherwise, 6 Gi W |U G W |U U VZ U, would contradict I(G ) I(Gi ). fact, WG . see it, recall nodes right righttoo. W G W would right and, thus,W would right too. However, would contradict factW left , follows fact W leftZ Gi consistent , fact left neighborWBZ (recall line 3). Thus, W G . Then, AXX WS-active route B G .Case 2 Method B2 constructs Gi+1 Gi adding arc X X5ABAXYBP aGi (Z)\P aGi (Y ). Note X occurs ABi+1 . Let i+1 = i+1 X i+1 .AXABNote X/ i+1 S-active Gi+1 because, otherwise, i+1 wouldS-active Gi+1 . Then, S-active route AXX Ginduction hypothesis. Note Z G (i) Z adjacentG since I(G ) I(Gi ), (ii) Z left (recall line 4). Note alsoX Z adjacent G since I(G ) I(Gi ). fact ZG imply X adjacent G because, otherwise, X 6 Gi |UX G |U U V Z U, would contradictWB4. Note maybe W = B. Note also W 6= X because, otherwise, AXi+1 X X i+1 wouldS-active route B Gi+1 would violate minimality property ABi+1 .5. Note maybe = X and/or B = .677fiPenaI(G ) I(Gi ). fact, X G . see it, recall Method B2 percolatesleft-to-right one one nodes reverse order appear. Method B2 currently percolating and, thus, nodes rightright too. X G X wouldright and, thus, X would right too. However, wouldcontradict fact X left , follows factX left Z Gi consistent , factleft neighbor Z (recall line 3). Thus, X G . consider threecases.B = X XB . Note XB S-activeCase 2.1 Assume Yi+1i+1i+1ABGi+1 because, otherwise, i+1 would S-active Gi+1 . Then,S-active route XBX B G induction hypothesis.AXThen, X X XBS-active route B G .B = W W B .6 Note WCase 2.2 Assume Yi+1/i+1WBi+1 S-active Gi+1 because, otherwise, ABwouldS-activeGi+1 .i+1B W B G inductionThen, S-active route Whypothesis. Note also W G . see it, note Wadjacent G since I(G ) I(Gi ). Recall nodes rightright too. W G W wouldright and, thus, W would right too.However, would contradict fact W left ,follows fact Gi consistent . Thus, W G . Then,W B S-active route B G .AXX WCase 2.3 Assume/ S. proof case based step 8work Chickering (2002, Lemma 30). Let denote node maximalG set descendants Gi . Note guaranteedunique Chickering (2002, Lemma 29), I(G ) I(Gi ). Note also6= , Z descendant Gi and, shown above, ZG . show descendant Z Gi . consider three cases.Case 2.3.1 Assume = Z. Then, descendant Z Gi .Case 2.3.2 Assume 6= Z descendant Z G0 . RecallMethod B2 percolates left-to-right one one nodesreverse order appear . Method B2 currently percolatingand, thus, yet percolated Z Z left(recall line 4). Therefore, none descendants Z G0 (amongD) left Z . fact consistent Giimply Z node maximal Gi set descendantsZ G0 . Actually, Z node Chickering (2002, Lemma 29),I(Gi ) I(G0 ). Then, descendants Z G0 descendantsZ Gi too. Thus, descendant Z Gi .6. Note maybe W = B. Note also W 6= X, case W = X covered Case2.1.678fiFinding Consensus Bayesian Network StructuresCase 2.3.3 Assume 6= Z descendant Z G0 .shown Case 2.3.2, descendants Z G0 descendants ZGi too. Therefore, none descendants Z G0 leftbecause, otherwise, descendant Z thus Gi wouldleft , would contradict definition D.fact descendant Z G0 imply stillG0 Z became sink node G0 Construct (recall Figure 1).Therefore, Construct added added Z (recall lines 3-4),left Z definition D.7 reason,Method B2 interchanged Z (recall line 4). Thus,currently still left Z , implies left, left neighbor Z (recall line 3). However,contradicts fact Gi consistent , descendantGi . Thus, case never occurs.Bcontinue proof Case 2.3. Note/ implies Yi+1S-active Gi+1 because, otherwise, ABi+1 would S-active Gi+1 . Notealso descendant Z Gi because, otherwise, wouldXY BS-active route XYX Gi and, thus, AXi+1i+1would S-active route B Gi+1 would violateminimality property AB/ because, shown above,i+1 . impliesdescendant Z Gi . also implies S-active descendingZD S-active routeroute ZDZ Gi . Then, AXi+1 X ZZD S-active routeGi+1 . Likewise,i+1 ZB Gi+1 , i+1 denotes route resulting reversingB . Therefore, S-active routes AD BDYi+1B G induction hypothesis.Consider subroute ABi+1 starts arc X continuesdirection arc reaches node E E = B E S.Note E descendant Gi and, thus, E descendant Gdefinition D. Let DEdenote descending route E G .Assume without loss generality G descending routeB node shorter DE. implies E = BDEDES-active G because, shown above,/ S. Thus, ADS-active route B G . hand, E E 6=DE ED DB S-active route/ S. Thus, ADEDB G , DBdenoteroutes resulting reversingBD .DEFinally, show correctness Method B2 leads alternative proofso-called Meeks conjecture (1997). Given two DAGs G H I(H) I(G),Meeks conjecture states transform G H sequence arc additionscovered arc reversals operation sequence G DAG7. Note statement true thanks correction Construct .679fiPenaMethod G2H(G, H)/* Given two DAGs G H I(H) I(G), algorithm transformsG H sequence arc additions covered arc reversalsoperation sequence G DAG I(H) I(G) */123Let denote node ordering consistent HG=Method B2(G, )Add G arcs H GFigure 5: Method G2H.I(H) I(G). importance Meeks conjecture lies allows develop efficientasymptotically correct algorithms learning BNs data mild assumptions(Chickering, 2002; Chickering & Meek, 2002; Meek, 1997; Nielsen et al., 2003). Meeksconjecture proven true work Chickering (2002, Thm. 4) developingalgorithm constructs valid sequence arc additions covered arc reversals.propose alternative algorithm construct sequence. pseudocodealgorithm, called Method G2H, seen Figure 5. following corollary provesMethod G2H correct.Corollary 1. Given two DAGs G H I(H) I(G), Method G2H(G, H)transforms G H sequence arc additions covered arc reversalsoperation sequence G DAG I(H) I(G).Proof. Note Method G2Hs line 1 denotes node ordering consistentH. Let G denote MDI map G relative . Recall G guaranteedunique I(G) graphoid. Note I(H) I(G) implies G subgraphH. see it, note I(H) I(G) implies obtain MDI map G relativeremoving arcs H. However, G MDI map G relative .Then, follows proof Theorem 5 Method G2Hs line 2 transformsG G sequence arc additions covered arc reversals,operation sequence G DAG I(G ) I(G). Thus, operationsequence I(H) I(G) I(H) I(G ) since, shown above, G subgraphH. Moreover, Method G2Hs line 3 transforms G G H sequence arcadditions. course, arc addition G DAG I(H) I(G) Gsubgraph H.7. Corrected Methods B Efficientsection, show Methods B efficient solutionproblem think of. Let n denote, respectively, numbernodes arcs G. Moreover, let us assume hereinafter DAG implemented680fiFinding Consensus Bayesian Network Structuresadjacency matrix, whereas node ordering implemented array entry pernode indicating position node ordering. Since I(G) graphoid, firstsolution think consists applying following characterization G :node A, P aG (A) smallest subset X P (A) G P (A) \ X|X.solution implies evaluating node O(2n ) subsets P (A). Evaluatingsubset implies checking separation statement G, takes O(a) time (Geiger et al.,1990, p. 530). Therefore, overall runtime solution O(an2n ).Since I(G) satisfies composition property addition graphoid properties,efficient solution consists running incremental association Markov boundary(IAMB) algorithm (Pena et al., 2007, Thm. 8) node find P aG (A). IAMBalgorithm first sets P aG (A) = and, then, proceeds following two steps.first step consists iterating following line P aG (A) change:Take node B P (A) \ P aG (A) 6 G B|P aG (A) add P aG (A).second step consists iterating following line P aG (A)change: Take node B P aG (A) consideredG B|P aG (A)\{B}, remove P aG (A). first step IAMB algorithmadd O(n) nodes P aG (A). addition implies evaluating O(n) candidatesaddition, since P (A) O(n) nodes. Evaluating candidate implies checkingseparation statement G, takes O(a) time (Geiger et al., 1990, p. 530). Then,first step IAMB algorithm runs O(an2 ) time. Similarly, second stepIAMB algorithm runs O(an) time. Therefore, IAMB algorithm runs O(an2 ) time.Since IAMB algorithm run n nodes, overall runtimesolution O(an3 ).analyze efficiency Methods B. exact, analyzeMethods A2 B2 (recall Figure 3) rather original Methods B (recallFigure 1), former efficient latter. Methods A2 B2 runO(n3 ) time. First, note Construct runs O(n3 ) time. algorithm iterates ntimes lines 3-10 and, iterations, iterates O(n) times lines5-8. Moreover, line 3 takes O(n2 ) time, line 6 takes O(1) time, line 9 takes O(n) time.Now, note Methods A2 B2 iterate n times lines 2-8 and,iterations, iterate O(n) times lines 3-7. Moreover, line 4 takes O(1) time,line 5 takes O(n) time covering arc implies updating adjacency matrixaccordingly. Consequently, Methods B efficient solutionproblem think of.Finally, analyze complexity Method G2H. Method G2H runs O(n3 ) time:constructed O(n3 ) time calling Construct (H, ) nodeordering, running Method B2 takes O(n3 ) time, adding G arcs HG done O(n2 ) time. Recall Method G2H alternativealgorithm work Chickering (2002). Unfortunately, implementation detailsprovided work Chickering and, thus, comparison runtimealgorithm possible. However, believe algorithm efficient.681fiPena8. Discussionpaper, studied problem combining several given DAGs consensusDAG represents independences given DAGs agree uponparameters associated possible. Although definition consensus DAG reasonable,would like leave number parameters associated focus solelyindependencies represented consensus DAG. words, would like defineconsensus DAG DAG represents independences given DAGsagree upon many possible. currently investigating whetherdefinitions equivalent. paper, proven may exist several nonequivalent consensus DAGs. principle, equally good. ableconclude one represents independencies rest, would preferone. paper, proven finding consensus DAG NP-hard.made us resort heuristics find approximated consensus DAG. meandiscard existence fast super-polynomial algorithms general case,polynomial algorithms constrained cases given DAGs boundedin-degree. question currently investigating. paper,considered heuristic originally proposed Matzkevich Abramson (1992, 1993b).heuristic takes input node ordering, shown finding bestnode ordering heuristic NP-hard. currently investigating applicationmeta-heuristics space node orderings find good node orderingheuristic. preliminary experiments indicate approach highly beneficial,best node ordering almost never coincides node orderingsconsistent given DAGs.said Section 1, aim combining BNs provided multiple experts (orlearning algorithms) single consensus BN robust individualBNs. paper, proposed combine experts BNs two steps avoidproblems discussed Pennock Wellman (1999). First, finding consensus BNstructure and, then, finding consensus parameters consensus BN structure.paper focused first step. currently working secondstep along following lines. Let (G1 , 1 ), . . . , (Gm , ) denote BNs providedexperts. first element pair denotes BN structure whereas second denotesBN parameters. Let p1 , . . . , pm denote probability distributions representedBNs provided experts. Then, call p0 = f (p1 , . . . , pm ) consensus probabilitydistribution, f combination function, e.g. weighted arithmetic geometricmean. Let G denote consensus BN structure obtained G1 , . . . , Gm describedpaper. propose obtain consensus BN parameterizing Gp (A|P aG (A)) = p0 (A|P aG (A)) V, p probability distributionrepresented consensus BN. motivation parameterization minimizesKullback-Leibler divergence p p0 (Koller & Friedman, 2009, Thm. 8.7).hints speed computation parameterization performinginference experts BNs found work Pennock Wellman (1999,Properties 3 4, Section 5). Alternatively, one could first sample p0 and, then,parameterize G p (A|P aG (A)) = p0 (A|P aG (A)) V, p0empirical probability distribution obtained sample. Again, motivation682fiFinding Consensus Bayesian Network Structuresparameterization minimizes Kullback-Leibler divergence p p0(Koller & Friedman, 2009, Thm. 17.1) and, course, p0 p0 sample sufficientlylarge. Note use p0 parameterize G construct G which, discussedSection 1, allows us avoid problems discussed Pennock Wellman (1999).Finally, note present work combines DAGs G1 , . . . , Gm althoughguarantee Gi MDI map I(pi ), i.e. Gi may superfluous arcs.Therefore, one may want check Gi contains superfluous arcs removecombination takes place. general, several MDI maps I(pi ) may exist,may differ number parameters associated them. would interestingstudy number parameters associated MDI map I(pi ) chosen affectsnumber parameters associated consensus DAG obtained methodproposed paper.Acknowledgmentsthank anonymous referees editor thorough review manuscript.thank Dr. Jens D. Nielsen Dag Sonntag proof-reading manuscript.work funded Center Industrial Information Technology (CENIIT) socalled career contract Linkoping University.Appendix A. Proofs Lemmas 1-3Lemma 1. Method A(G, ) Method A2(G, ) return DAG.Proof. evident Methods A2 transform and, thus, haltpoint. prove return DAG. prove resultinduction number times Method executes line 6 halting.evident result holds number executions one, Methods A2share line 1. Assume induction hypothesis result holds k 1 executions.prove k executions. Let Z denote nodes involved firstk executions. Since induction hypothesis applies remaining k 1 executions,run Method summarizedZ G cover reverse Z GInterchange Z= 1 nPercolate right-to-left leftmost node percolatedn number nodes G. Now, assume percolated = j. Notefirst j 1 percolations involve nodes left . Thus, runequivalent683fiPena= 1 j 1Percolate right-to-left leftmost node percolatedZ G cover reverse Z GInterchange ZPercolate right-to-leftPercolate Z right-to-left= j + 2 nPercolate right-to-left leftmost node percolated before.Now, let W denote nodes left Z first k executionsline 6. Note fact Z nodes involved first execution impliesnodes W also left Z . Note also that, Z percolatedlatter run above, nodes left Z exactly W {Y }. Sincenodes W {Y } also left Z , percolation Z latter runperform arc covering reversal node interchange. Thus, latter runequivalent= 1 j 1Percolate right-to-left leftmost node percolatedPercolate Z right-to-leftPercolate right-to-left= j + 2 nPercolate right-to-left leftmost node percolatedexactly run Method A2. Consequently, Methods A2 returnDAG.Lemma 2. Method A2(G, ) Method B(G, ) return DAG.Proof. prove lemma much way Lemma 1. simply needreplace Z vice versa proof Lemma 1.Lemma 3. Method B(G, ) Method B2(G, ) return DAG.Proof. evident Methods B B2 transform and, thus, haltpoint. prove return DAG. prove resultinduction number times Method B executes line 6 halting.evident result holds number executions one, Methods B B2share line 1. Assume induction hypothesis result holds k 1 executions.prove k executions. Let Z denote nodes involved firstk executions. Since induction hypothesis applies remaining k 1 executions,run Method B summarized684fiFinding Consensus Bayesian Network StructuresZ G cover reverse Z GInterchange Z= 1 nPercolate left-to-right rightmost node percolatedn number nodes G. Now, assume j-th rightmost node. Note that, 1 < j, i-th rightmost node Wi rightWi percolated run above. see it, assume contrary Wileft . implies Wi also left Z , Zneighbors . However, contradiction Wi would selectedline 2 instead first execution line 6. Thus, first j 1 percolationsrun involve nodes right Z . Then, run equivalent= 1 j 1Percolate left-to-right rightmost node percolatedZ G cover reverse Z GInterchange Z= j nPercolate left-to-right rightmost node percolatedexactly run Method B2.ReferencesChickering, D. M. Transformational Characterization Equivalent Bayesian NetworkStructures. Proceedings Eleventh Conference Uncertainty Artificial Intelligence, 87-98, 1995.Chickering, D. M. Optimal Structure Identification Greedy Search. Journal MachineLearning Research, 3:507-554, 2002.Chickering, D. M. & Meek, C. Finding Optimal Bayesian Networks. ProceedingsEighteenth Conference Uncertainty Artificial Intelligence, 94-102, 2002.Chickering, D. M., Heckerman, D. & Meek, C. Large-Sample Learning Bayesian NetworksNP-Hard. Journal Machine Learning Research, 5:1287-1330, 2004.Friedman, N. & Koller, D. Bayesian Network Structure. Bayesian ApproachStructure Discovery Bayesian Networks. Machine Learning, 50:95-12, 2003.Gavril, F. NP-Complete Problems Graphs. Proceedings Eleventh Conference Information Sciences Systems, 91-95, 1977.Garey, M. & Johnson, D. Computers Intractability: Guide Theory NPCompleteness. W. H. Freeman, 1979.685fiPenaGeiger, D., Verma, T. & Pearl, J. Identifying Independence Bayesian Networks. Networks,20:507-534, 1990.Genest, C. & Zidek, J. V. Combining Probability Distributions: Critique Annotated Bibliography. Statistical Science, 1:114-148, 1986.Hartemink, A. J., Gifford, D. K., Jaakkola, T. S. & Young, R. A. Combining LocationExpression Data Principled Discovery Genetic Regulatory Network Models.Pacific Symposium Biocomputing 7, 437-449, 2002.Jackson, B. N., Aluru, S. & Schnable, P. S. Consensus Genetic Maps: Graph Theoretic Approach. Proceedings 2005 IEEE Computational Systems BioinformaticsConference, 35-43, 2005.Koller, D. & Friedman, N. Probabilistic Graphical Models: Principles Techniques. MITPress, 2009.Matzkevich, I. & Abramson, B. Topological Fusion Bayes Nets. ProceedingsEight Conference Conference Uncertainty Artificial Intelligence, 191-198, 1992.Matzkevich, I. & Abramson, B. Complexity Considerations CombinationBelief Networks. Proceedings Ninth Conference Conference UncertaintyArtificial Intelligence, 152-158, 1993a.Matzkevich, I. & Abramson, B. Deriving Minimal I-Map Belief Network RelativeTarget Ordering Nodes. Proceedings Ninth Conference ConferenceUncertainty Artificial Intelligence, 159-165, 1993b.Maynard-Reid II, P. & Chajewska, U. Agregating Learned Probabilistic Beliefs. Proceedings Seventeenth Conference Uncertainty Artificial Intelligence, 354-361,2001.Meek, C. Graphical Models: Selecting Causal Statistical Models. PhD thesis, CarnegieMellon Unversity, 1997.Ng, K.-C. & Abramson, B. Probabilistic Multi-Knowledge-Base Systems. Journal AppliedIntelligence, 4:219-236, 1994.Nielsen, J. D., Kocka, T. & Pena, J. M. Local Optima Learning Bayesian Networks.Proceedings Nineteenth Conference Uncertainty Artificial Intelligence,435-442, 2003.Nielsen, S. H. & Parsons, S. Application Formal Argumentation: Fusing BayesianNetworks Multi-Agent Systems. Artificial Intelligence 171:754-775, 2007.Pearl, J. Probabilistic Reasoning Intelligent Systems: Networks Plausible Inference.Morgan Kaufmann, 1988.Pennock, D. M. & Wellman, M. P. Graphical Representations Consensus Belief. Proceedings Fifteenth Conference Uncertainty Artificial Intelligence, 531-540,1999.686fiFinding Consensus Bayesian Network StructuresPena, J. M., Nilsson, R., Bjorkegren, J. & Tegner, J. Towards Scalable Data EfficientLearning Markov Boundaries. International Journal Approximate Reasoning, 45:211232, 2007.Pena, J. M., Kocka, T. & Nielsen, J. D. Featuring Multiple Local Optima Assist UserInterpretation Induced Bayesian Network Models. Proceedings TenthInternational Conference Information Processing Management UncertaintyKnowledge-Based Systems, 1683-1690, 2004.Richardson, M. & Domingos, P. Learning Knowledge Multiple Experts. Proceedings Twentieth International Conference Machine Learning, 624-631, 2003.del Sagrado, J. & Moral, S. Qualitative Combination Bayesian Networks. InternationalJournal Intelligent Systems, 18:237-249, 2003.Studeny, M. Bayesian Networks Point View Chain Graphs. ProceedingsFourteenth Conference Conference Uncertainty Artificial Intelligence, 496-503,1998.Studeny, M. & Bouckaert, R. R. Chain Graph Models Description ConditionalIndependence Structures. Annals Statistics, 26:1434-1495, 1998.687fiJournal Artificial Intelligence Research 42 (2011) 125-180Submitted 03/11; published 10/11First-Order Stable Model SemanticsFirst-Order Loop FormulasJoohyung LeeYunsong Mengjoolee@asu.eduYunsong.Meng@asu.eduSchool Computing, Informatics,Decision Systems EngineeringArizona State UniversityTempe, AZ 85287, USAAbstractLin Zhaos theorem loop formulas states propositional case stablemodel semantics logic program completely characterized propositional loopformulas, result fully carry first-order case. investigateprecise relationship first-order stable model semantics first-order loopformulas, study conditions former represented latter.order facilitate comparison, extend definition first-order loop formulalimited nondisjunctive program, disjunctive program arbitraryfirst-order theory. Based studied relationship extend syntax logic programexplicit quantifiers, allows us reasoning involving non-Herbrand stablemodels using first-order reasoners. programs viewed special class firstorder theories stable model semantics, yields succinct loop formulasgeneral language due restricted syntax.1. IntroductionAccording theorem loop formulas (Lin & Zhao, 2004), stable modelslogic program (Gelfond & Lifschitz, 1988) characterized models logicprogram satisfy loop formulas. idea turned widely applicablerelating stable model semantics propositional logic, resulted efficientmethod computing answer sets using SAT solvers. Since original invention loopformulas nondisjunctive logic programs Lin Zhao (2004), theoremextended general classes logic programs, disjunctive programs (Lee & Lifschitz, 2003), infinite programs programs containing classical negation (Lee, 2005; Lee,Lierler, Lifschitz, & Yang, 2010), arbitrary propositional formulas stable modelsemantics (Ferraris, Lee, & Lifschitz, 2006), programs containing aggregates (Liu &Truszczynski, 2006; & Liu, 2008). theorem also applied nonmonotonic formalisms, nonmonotonic causal theories (Lee, 2004) McCarthyscircumscription (Lee & Lin, 2006). notion loop refined elementary loop (Gebser & Schaub, 2005; Gebser, Lee, & Lierler, 2006, 2011). However,work restricted propositional case. Variables contained programfirst eliminated groundingthe process replaces every variable every objectconstantand loop formulas obtained ground program. result, loopformulas defined formulas propositional logic.c2011AI Access Foundation. rights reserved.fiLee & MengChen, Lin, Wang, Zhangs definition (2006) first-order loop formula differentloop formulas directly obtained non-ground program,first-order logic formulas retain variables. However, since semantics logicprogram refer based grounding, first-order loop formulas simplyunderstood schemas ground loop formulas, Herbrand models loopformulas considered context.stable model semantics involve grounding appeared year later(Ferraris, Lee, & Lifschitz, 2007, 2011). authors define stable models firstorder sentence F models second-order sentence obtained applyingstable model operator SM F . definition SM close definitioncircumscription operator CIRC (McCarthy, 1980, 1986). first-order stable modelsemantics, logic programs viewed special class first-order theories. similardefinition stable model given Lin Zhou (2011), via logic knowledgejustified assumption (Lin & Shoham, 1992). first-order stable model semanticsalso closely related quantified equilibrium logic (Pearce & Valverde, 2005), indeed,Ferraris et al. (2011) showed essentially equivalent.natural question arising first-order loop formulas first-order stablemodel semantics related other. general, first-order stable model semanticsexpressive first-order logic, cannot completely characterizedfirst-order loop formulas. Like circumscription, concept transitive closurerepresented first-order stable model semantics, set first-orderformulas, even set allowed infinite.1 However, show paper,understanding precise relationship gives us insights first-orderstable model semantics computational properties.order facilitate comparison, extend definition first-order loopformula limited nondisjunctive programs, disjunctive programsarbitrary first-order theories. Also present reformulation SM[F ] style loopformulas, includes characterization loop syntactic formula.formulation, derive several conditions, first-order theory stablemodel semantics equivalently rewritten first-order loop formulas.Based relationship first-order stable model semantics first-orderloop formulas, extend syntax logic programs explicit quantifiers, mayuseful overcoming limitations traditional answer set programs reasoningnon-Herbrand models. define semantics extended programs identifyingspecial class first-order theories stable model semantics.programs inherit general language ability handle nonmonotonic reasoningstable model semantics even absence unique name domainclosure assumptions built grounding-based answer set semantics.hand, restricted syntax extended program leads succinct loopformulas. following program 1 simple insurance policy example represented1. Vladimir Lifschitz, personal communication.126fiFirst-Order Stable Model Semantics First-Order Loop Formulassyntax.HasWife(x)HasWife(x)Married (x)w Discount(x, w)Spouse(x, y)Man(x), Married (x)Man(x), HasWife(x)Married (x), z Accident(x, z).second third rules express Married (x) HasWife(x) synonymousx Man. last rule states x eligible discountplan (with name unknown) x married record accident. quantifierfirst rule dropped without affecting meaning, quantifierscannot. say program entails query F (under stable model semantics)every stable model satisfies F . example,1 conjoined 2 = {Man(John)} entails x Married (x)xy Discount(x, y).1 2 conjoined 3 = {y Spouse(John, y)} entails neither x Married (x)xy Discount(x, y), entails x Married (x), xyDiscount(x, y),xy(Discount(x, y) x = John).1 2 3 conjoined 4 = {z Accident(John, z)} entailxy(Discount(x, y) x = John), entails w Discount(John, w).nonmonotonic reasoning kind requires non-Herbrand models since names(or identifiers) discount plans, spouses accident records may unknown. However,traditional answer set semantics limited Herbrand models due referencegrounding. turning program first-order loop formulas automateexample reasoning using first-order theorem prover.paper organized follows. next section reviews first-order stable modelsemantics Ferraris et al. (2007, 2011). Section 3 reviews theorem first-order loopformulas Chen et al. (2006) extends disjunctive programs arbitraryfirst-order sentences, limiting attention Herbrand stable models. Section 4 extendsresults allow non-Herbrand stable models well (possibly allowing functions)certain semantic condition, compare first-order stable model semantics loopformulas reformulating former terms latter. Section 5, present seriessyntactic conditions imply semantic condition Section 4. Section 6 providesextension logic programs contain explicit quantifiers shows query answeringextended programs sometimes reduced entailment checking first-orderlogic via loop formulas. Section 7, results extended distinguishintensional non-intensional predicates. Related work described Section 8, longproofs given Appendix A.article extended version conference paper Lee Meng (2008).2. Review First-Order Stable Model Semanticsreview follows journal paper Ferraris et al. (2011) extends conferencepaper authors (Ferraris et al., 2007) distinguishing intensionalnon-intensional predicates.127fiLee & Mengformula defined first-order logic. signature consists functionconstants predicate constants. Function constants arity 0 called object constants.assume following set primitive propositional connectives quantifiers:(falsity), , , , , .F abbreviation F , symbol > stands , F G stands(F G) (G F ). distinguish atoms atomic formulas follows:atom signature n-ary predicate constant followed list n termsformed function constants (including object constants) objectvariables; atomic formulas atoms , equalities terms ,0-place connective .stable models F relative list predicates p = (p1 , . . . , pn ) defined viastable model operator intensional predicates p, denoted SM[F ; p].2 Let ulist distinct predicate variables u1 , . . . , un length p. u = pdenote conjunction formulas x(ui (x) pi (x)), x list distinct objectvariables length arity pi , = 1, . . . , n. u p denoteconjunction formulas x(ui (x) pi (x)) = 1, . . . , n, u < p stands(u p) (u = p). first-order sentence F , expression SM[F ; p] standssecond-order sentenceF u((u < p) F (u)),(1)F (u) defined recursively:pi (t) = ui (t) list terms;F = F atomic formula F (including equality) containmembers p;(F G) = F G ;(F G) = F G ;(F G) = (F G ) (F G);(xF ) = xF ;(xF ) = xF .(There clause negation here, treat F shorthand F .)model sentence F (in sense first-order logic) called p-stable satisfiesSM[F ; p]. often simply write SM[F ] instead SM[F ; p] p listpredicate constants occurring F , call model SM[F ] simply stable model F .distinguish terms stable models answer sets follows.3 (F )denote signature consisting function predicate constants occurring F .2. intensional predicates p predicates intend characterize F .3. distinction useful first-order setting, stable models longer Herbrand interpretations may represented sets atoms.128fiFirst-Order Stable Model Semantics First-Order Loop FormulasF contains least one object constant, Herbrand interpretation4 (F ) satisfiesSM[F ] called answer set F . answer sets logic program definedanswer sets FOL-representation (i.e., conjunction universal closuresimplications corresponding rules).Example 1 program contains three rulesp(a)q(b)r(x) p(x), q(x)FOL-representation Fp(a) q(b) x((p(x) q(x)) r(x))(2)SM[F ]p(a) q(b) x((p(x) q(x)) r(x))uvw(((u, v, w) < (p, q, r)) u(a) v(b)x(((u(x) (v(x) q(x))) w(x)) ((p(x) q(x)) r(x)))),equivalent first-order sentencex(p(x) x = a) x(q(x) x = b) x(r(x) (p(x) q(x)))(3)(See Example 3 work Ferraris et al., 2007). stable models F firstorder models (3). answer set F Herbrand model {p(a), q(b), r(a)}.3. First-Order Loop Formulas Herbrand Modelsreview definition first-order loop formula nondisjunctive program givenChen et al. (2006) extend disjunctive program arbitrary first-ordersentence.3.1 Review First-Order Loop Formulas Defined Chen et al. (2006)call formula negative every occurrence every predicate constant belongsantecedent implication. instance, formula form F negativeexpression shorthand F . equality t1 = t2 also negativecontains predicate constants.nondisjunctive program finite set rules formB, N,(4)4. Recall Herbrand interpretation signature (containing least one object constant)interpretation universe set ground terms , every ground termrepresents itself. Herbrand interpretation identified set ground atomsassigns value true.129fiLee & Mengatom, B set atoms, N negative formula. rules maycontain function constants positive arity.5say nondisjunctive program normal form if, rules (4) it,form p(x) x list distinct variables. clear every programturned normal form using equality body. instance, p(a, b) q(a)rewritten p(x, y) x = a, = b, q(a).Let nondisjunctive program let Norm() normal form . ()denote signature consisting function predicate constants occurring . Givenfinite set atoms, assume Norm() contain variables , renamingvariables Norm(). (first-order) external support formula , denotedES (Y ), disjunction_z B N:AY^0(t 6= )(5)p(t)Bp(t0 )Yrules (4) Norm(),6 substitution maps variables termsoccurring , z list variables occurB, N.(first-order) loop formula , denoted LF (Y ), universal closure^ES (Y ).(6)V(The expression antecedent stands conjunction elements .)propositional program, LF (Y ) equivalent conjunctive loop formuladefined Ferraris et al. (2006).definition first-order dependency graph definition first-order loopfollows. say atom p(t) depends atom q(t0 ) rule (4) p(t)q(t0 ) B. (first-order) dependency graph infinite directed graph(V, E)V set atoms signature ();7(p(t), q(t0 )) E p(t) depends q(t0 ) rule substitutionmaps variables t0 terms (including variables) ().nonempty subset L V called (first-order) loop subgraphfirst-order dependency graph induced L strongly connected.5. original definition Chen et al. (2006) allow function constants positive arity.6. lists terms = (t1 , . . . , tn ) t0 = (t01 , . . . , t0n ) length, = t0 stands(t1 = t01 ) (tn = t0n ).7. Note V infinite since infinitely many object variables used form atoms.130fiFirst-Order Stable Model Semantics First-Order Loop FormulasExample 2 Let following program:p(x) q(x)q(y) p(y)p(z) r(z).(7)following sets atoms first-order loops (among many others): Y1 = {p(u)}, Y2 ={q(u)}, Y3 = {r(u)}, Y4 = {p(u), q(u)}. loop formulasLF (Y1 )LF (Y2 )LF (Y3 )LF (Y4 )====u(p(u) (q(u) r(u))),u(q(u) p(u)),u(r(u) ),u(p(u) q(u) (q(u) u 6= u) (p(u) u 6= u) r(u)).Example 3 Let one-rule programp(x) p(y).(8)finite first-order loops Yk = {p(x1 ), . . . , p(xk )} k > 0. Formula LF (Yk )(9)x1 . . . xk p(x1 ) . . . p(xk ) y(p(y) (y 6= x1 ) . . . (y 6= xk )) .following reformulation Theorem 1 work Chen et al. (2006).Theorem 1 Let nondisjunctive program contains least one object constantfunction constants positive arity, let Herbrand interpretation ()satisfies .8 following conditions equivalent other:(a) stable model ;(b) every nonempty finite set atoms (), satisfies LF (Y );9(c) every finite first-order loop , satisfies LF (Y ).sets first-order loop formulas considered conditions (b) (c)obvious redundancies. instance, loop formula {p(x)} equivalent loopformula {p(y)}; loop formula {p(x), p(y)} entails loop formula {p(z)}. Following definition Chen et al. (2006), given two sets atoms Y1 Y2 , sayY1 subsumes Y2 substitution maps variables Y1 termsY1 = Y2 .Proposition 1 (Chen et al., 2006, Proposition 7) nondisjunctive programloops Y1 Y2 , Y1 subsumes Y2 , LF (Y1 ) entails LF (Y2 ).Therefore condition (c) Theorem 1, sufficient consider set loopsthat, every loop L , loop L0 subsumes L. Chen et al. (2006)called complete set loops. Example 2, set {Y1 , Y2 , Y3 , Y4 } finite completeset loops program (7). Program (8) Example 3 finite complete set loops.8. say satisfies satisfies FOL-representation .9. Note may contain variables.131fiLee & Meng3.2 Extension Disjunctive Programsdisjunctive program finite set rules formB, N,(10)B sets atoms, N negative formula. Similar nondisjunctiveprogram, say disjunctive program normal form if, rules (10) it,atoms form p(x) x list distinct variables.Let disjunctive program let Norm() normal form . Given finiteset atoms, first rename variables Norm() variables Norm()occur . (first-order) external support formula , denoted ES (Y ),disjunction_^_^z B N(t 6= t0 )p(t)6= t0(11):AY 6=p(t)Bp(t0 )Yp(t)Ap(t0 )Yrules (10) Norm(), substitution maps variables termsoccurring themselves, z list variables occurB, N. (first-order) loop formula , denoted LF (Y ), universalclosure^ES (Y ).Clearly, (11) equivalent (5) nondisjunctive. propositional,LF (Y ) equivalent conjunctive loop formula disjunctive program definedFerraris et al. (2006).Example 4 Let programp(x, y) ; p(y, z) q(x)let = {p(u, v)}. Formula LF (Y ) universal closurep(u, v) z(q(u) (p(v, z) ((v, z) 6= (u, v))))x(q(x) (p(x, u) ((x, u) 6= (u, v)))).Similar nondisjunctive case, say p(t) depends q(t0 )rule (10) p(t) q(t0 ) B. definitions first-orderdependency graph first-order loop extended disjunctive programs straightforward way. Using extended notions, following theorem extends Theorem 1disjunctive program. also generalization main theorem Ferraris et al.(2006) restricted propositional disjunctive program.Theorem 1 Let disjunctive program contains least one object constantfunction constants positive arity, let Herbrand interpretation ()satisfies . following conditions equivalent other:132fiFirst-Order Stable Model Semantics First-Order Loop Formulas(a) stable model ;(b) every nonempty finite set atoms (), satisfies LF (Y );(c) every finite first-order loop , satisfies LF (Y ).3.3 Extension Arbitrary Sentencessection extend definition first-order loop formula arbitrary firstorder sentence.propositional loop formula defined arbitrary propositional theory (Ferraris et al., 2006), convenient introduce formula whose negation close ES .define formula NES F (Y ) (Negation (First-order) External Support Formula), Ffirst-order formula finite set atoms, follows. assumevariables occur F , renaming variables.NES pi (t) (Y ) = pi (t)Vpi (t0 )Y6= t0 ;NES t1 =t2 (Y ) = (t1 = t2 );NES (Y ) = ;NES F G (Y ) = NES F (Y ) NES G (Y );NES F G (Y ) = NES F (Y ) NES G (Y );NES F G (Y ) = (NES F (Y ) NES G (Y )) (F G);NES xG (Y ) = xNES G (Y );NES xG (Y ) = xNES G (Y ).(first-order) loop formula F , denoted LF F (Y ), universal closure^NES F (Y ).(12)Note definition NES looks similar definition F given Section 2.F propositional, LF F (Y ) equivalent conjunctive loop formulapropositional formula defined Ferraris et al. (2006). following lemma tellsus definition loop formula section generalizes definition loopformula disjunctive program previous section.Lemma 1 Let disjunctive program normal form, F FOL-representation, finite set atoms. Formula NES F (Y ) equivalent ES (Y )assumption F .133fiLee & Mengorder extend first-order dependency graph arbitrary formula, introducenotions. say occurrence subformula G formula F positivenumber implications F containing occurrence antecedent even;strictly positive number 0. rule first-order formula F implicationoccurs strictly positively F . say formula rectified variablesbound free, quantifiers formula refer different variables.formula easily rewritten rectified formula renaming bound variables.say atom p(t) depends atom q(t0 ) implication G Hp(t) strictly positive occurrence H,q(t0 ) positive occurrence G belong negative subformulaG.10definition first-order dependency graph extended formulas follows.(first-order) dependency graph rectified formula F infinite directed graph (V, E)V set atoms signature (F );(p(t), q(t0 )) E p(t) depends q(t0 ) rule F substitutionmaps variables t0 terms (F ).Note rectified formula assumption required order distinguishdependency graphs formulasx(p(x) q(x))x p(x) x q(x).definition dependency graph given, loop first-order formuladefined way disjunctive program. Theorem 1 extendedfirst-order sentences using extended notions.Theorem 1 f Let F rectified sentence contains least one object constantfunction constants positive arity, let Herbrand interpretation (F )satisfies F . following conditions equivalent other:(a) stable model F (i.e., satisfies SM[F ]);(b) every nonempty finite set atoms (F ), satisfies LF F (Y );(c) every finite first-order loop F , satisfies LF F (Y ).Example 2 (continued) Consider FOL-representation F program Example 2,{Y1 , Y2 , Y3 , Y4 } complete set loops. assumption F ,10. Recall definition negative formula Section 3.1.134fiFirst-Order Stable Model Semantics First-Order Loop FormulasLF F (Y1 ) equivalent universal closurep(u) x(q(x) p(x) x 6= u) y(p(y) 6= u q(y))z(r(z) p(z) z 6= u) ;LF F (Y2 ) equivalent universal closureq(u) x(q(x) x 6= u p(x)) y(p(y) q(y) 6= u) ;LF F (Y3 ) equivalent universal closurer(u) ;LF F (Y4 ) equivalent universal closurep(u) q(u) x(q(x) x 6= u p(x) x 6= u)y(p(y) 6= u q(y) 6= u) z(r(z) p(z) z 6= u) .Proposition 1 straightforwardly extended arbitrary sentences even withoutrestricting attention loops.Proposition 1 f sentence F nonempty finite sets atoms Y1 Y2(F ), Y1 subsumes Y2 , LF F (Y1 ) entails LF F (Y2 ).Proof. Note LF F (Y1 )z^Y1 NES F (Y1 ) ,(13)z set variables Y1 . Y1 subsumes Y2 , definition,substitution variables Y1 terms Y2 Y1 = Y2 . clear (13)entails^z0Y1 NES F (Y1 ) ,(14)z0 set variables Y1 . (14) exactly LF F (Y2 ).Theorem 2 work Ferraris et al. (2006) special case Theorem 1fF restricted propositional formula.Corollary 1 (Ferraris et al., 2006, Thm. 2) propositional formula F , followingformulas equivalent assumption F .(a) SM[F ];(b) conjunction LF F (Y ) nonempty sets atoms occurring F ;(c) conjunction LF F (Y ) (ground) loops F .135fiLee & Meng4. Comparing First-Order Stable Model Semantics First-Order LoopFormulastheorems previous section restricted Herbrand stable models.section extends results allow non-Herbrand stable models well, compareidea loop formulas SM reformulating latter style loop formulas.4.1 Loop Formulas Relative InterpretationRecall Theorem 1 extensions allow function constants positive aritylimited Herbrand models particular signature obtained giventheory. Indeed, statements become wrong conditions dropped.Example 5 following program contains unary function constant f .p(a)p(x) p(f (x)).loops program singleton sets atoms, loop formulas satisfiedHerbrand model {p(a), p(f (a)), p(f (f (a))), . . . } program, modelstable.Example 3 (continued) mismatch happen even absence function constants positive arity. Consider program Example 3 interpretationuniverse set integers, pI contains integers. Interpretationsatisfies first-order loop formulas (9), stable model.examples suggest mismatch first-order stable model semantics first-order loop formulas related presence infinite pathdependency graph visits infinitely many vertices. following makeidea precise, extend Theorem 1f allow non-Herbrand interpretationscertain condition.First, define dependency graph relative interpretation. Let F rectifiedformula whose signature let interpretation . elementuniverse |I| I, introduce new symbol , called object name. denotesignature obtained adding object names additional object constants.identify interpretation signature extension defined I( ) =(For details, see work Lifschitz, Morgenstern, & Plaisted, 2008).dependency graph F w.r.t. directed graph (V, E)V set atoms form pi ( ) pi belongs (F ) listobject names |I|,(pi ( ), pj ( )) E atoms pi (t), pj (t0 ) pi (t) depends pj (t0 )rule F substitution maps variables t0 objectnames (t)I = (t0 )I = .136fiFirst-Order Stable Model Semantics First-Order Loop Formulascall nonempty subset L V loop F w.r.t. subgraph dependencygraph F w.r.t. induced L strongly connected. say F boundedw.r.t. every infinite path dependency graph F w.r.t. whose verticessatisfied visits finitely many vertices. F bounded w.r.t. I, then, clearly, everyloop L F w.r.t. |= L finite. definition extended non-rectifiedformula first rewriting rectified formula. also applies program syntaxreferring FOL-representation.Theorem 2 Let F rectified sentence signature (possibly containing functionconstants positive arity), let interpretation satisfies F . Fbounded w.r.t. I, following conditions equivalent other:(a) |= SM[F ];(b) every nonempty finite set atoms formed predicate constants (F )object names |I|, satisfies LF F (Y );(c) every finite loop F w.r.t. I, satisfies LF F (Y ).condition F bounded w.r.t. sufficient ensuring equivalence among(a), (b), (c), necessary condition. instance, consider Fx p(x) xy(p(x) p(y))model F whose universe infinite. Formula F bounded w.r.t. I,satisfies every loop formula, well SM[F ].Herbrand model (F ), dependency graph F w.r.t. isomorphic subgraph first-order dependency graph F induced verticescontaining ground atoms. set ground atoms (F ) loop F iff loop Fw.r.t. I. Hence Theorem 2 essentially generalization Theorem 1f .Note programs considered Examples 3 5 bounded w.r.t.interpretations considered there.Clearly, universe finite, F bounded w.r.t. I. fact leadsfollowing corollary.Corollary 2 rectified sentence F model F whose universe finite,conditions (a), (b), (c) Theorem 2 equivalent other.view Proposition 1f Corollary 2, size universe knownfinite number n, sufficient consider 2|p| 1 loop formulas, pset predicate constantsoccurring sentence. loop formula checkexternal support pK {p(x1 ), . . . , p(xnr )} KK nonempty subset p;r arity p xi list variables length r variablesx1 , . . . , xnr pairwise distinct.137fiLee & Menginstance, consider program (8). size universe known 3, sufficientconsider one loop formula (9) k = 3.Theorem 1f essentially follows Corollary 2 Herbrand universe (F )finite F contains function constants positive arity.Another corollary Theorem 2 acquired F trivial loops. sayformula F atomic-tight w.r.t. every path dependency graph F w.r.t.whose vertices satisfied finite. Clearly, special case boundednesscondition, every loop L atomic-tight formula F w.r.t. |= Lsingleton. following corollary Theorem 2, tells us conditionstable models characterized loop formulas singleton loops only.SLF[F ] (loop formulas singletons) denote{LF F ({p(x)}) | p predicate constant (F ), x listdistinct object variables whose length arity p}.(15)Corollary 3 Let F rectified sentence (possibly containing function constants positivearity), let model F . F atomic-tight w.r.t. I, satisfies SM[F ] iffsatisfies SLF[F ].SLF[F ] similar Clarks completion. propositional case, relationshiploop formulas singletons completion studied Lee (2005).describe relationship first-order case. sentence F Clark normal form(Ferraris et al., 2011) conjunction formulas formx(G p(x)),(16)one predicate constant p occurring F , x list distinct variables,G free variables x. completion sentence F Clark normal form,denoted Comp[F ], obtained F replacing conjunctive term (16)x(p(x) G).nondisjunctive program turned Clark normal form (Ferraris et al., 2011,Section 6.1).Corollary 4 Let F FOL-representation nondisjunctive program , let F 0Clark normal form F obtained process described work Ferrariset al. (2011, Section 6.1). F atomic-tight w.r.t. interpretation I, |= SM[F ]iff |= Comp[F 0 ].Proof. Since F atomic-tight w.r.t. I, Corollary 3, |= SM[F ] iff |= F SLF[F ].sufficient show that, predicate constant p occurring F , assumptionF atomic-tight w.r.t. I,_^|= x p(x)z (x = t0 ) B N(t 6= x)(17)p(t0 )B,Np(t)B138fiFirst-Order Stable Model Semantics First-Order Loop Formulasiffz (x = ) B N ,_|= x p(x)0(18)p(t0 )B,Nz list free variables p(x) (x = t0 ), B, N x.Note (17) equivalent saying^_00(t 6= ) .z (x = ) B N|= x p(x)p(t0 )B,N(19)p(t)Bassumption F atomic-tight w.r.t. I, follows that, rule p(t0 )B, N atom p(t) B, |= y(t 6= t0 ), list variablest0 (otherwise find singleton loop self-cycle, contradicts Fatomic tight w.r.t. I). Consequently, (19) equivalent (18).example, let F FOL-representation programp(b) p(a)6= b(20)SLF[p(a) p(b)] x(p(x) x = b p(a) x 6= a), Comp[x(x = b p(a) p(x))]x(p(x) x = b p(a)). additional conjunctive term x 6= droppedconsider model F , aI 6= bI .Corollary 4 enhancement Theorem 11 work Ferraris et al. (2011),states equivalence SM[F ] Comp[F ] tight sentence F Clarknormal form. (Tight sentences defined similar way, terms predicatedependency graph, whose vertices predicate constants instead atoms.) Every tightsentence atomic-tight w.r.t. model sentence. hand, program (20)atomic-tight w.r.t. model program, tight.Theorem 2 tells us one limitations first-order loop formulas that, eveninfinitely many first-order loop formulas considered, cannot ensure externalsupport certain infinite set forms infinite path dependency graph Fw.r.t. I. next section, reformulating SM[F ], show definition SM[F ]essentially encompasses loop formulas, ensuring external support sets atoms,including difficult infinite sets.4.2 Reformulation SMbefore, let F first-order formula signature , let p = (p1 , . . . , pn ) listpredicate constants occurring F , let u v lists predicate variableslength p. define NSES F (u) (Negation Second-Order External SupportFormula) recursively follows.NSES pi (t) (u) = pi (t) ui (t);NSES t1 =t2 (u) = (t1 = t2 );NSES (u) = ;139fiLee & MengNSES F G (u) = NSES F (u) NSES G (u);NSES F G (u) = NSES F (u) NSES G (u);NSES F G (u) = (NSES F (u) NSES G (u)) (F G);NSES xF (u) = xNSES F (u);NSES xF (u) = xNSES F (u).Lemma 2 Let F rectified sentence signature , interpretation , plist predicate constants occurring F , q list predicate names 11 lengthp set atoms formed predicate constants (F ) object namespi ( ) iff |= qi ( ),list object names. finite,|= NSES F (q) iff |= NES F (Y ).Proof. induction F . list case F atom. casesstraightforward. Let F atom pi ( ).iffiffiffiffiff|= NSES F (q)|= pi ( ) qi ( )|= pi ( ) pi ( )/Yp ( ) Y, holds 6=|= pi ( )V|= pi ( ) pi ( )Y 6=|= NES F (Y ).SM[F ] written terms NSES follows. Nonempty(u) denoteformulax1 u1 (x1 ) xn un (xn ),xi list distinct variables whose length arity pi .Proposition 2 sentence F , SM[F ] equivalentF u((u p) Nonempty(u) NSES F (u)).(21)represent notion loop second-order formula. Given rectifiedformula F , EF (v, u) denote_z(vi (t) uj (t0 ) vj (t0 )),(pi (t),pj (t0 )) :pi (t) depends pj (t0 ) rule F11. Like object names, every n > 0, subset |I|n name, n-ary predicate constantunderlying signature.140fiFirst-Order Stable Model Semantics First-Order Loop Formulasz list object variables t0 . Loop F (u) denote second-orderformulaNonempty(u) v((v < u) Nonempty(v) EF (v, u)).(22)Formula (22) represents concept loop without referring notion dependencygraph explicitly. based following observation. Consider finite propositionalprogram . nonempty set U atoms occur loop iff, everynonempty proper subset V U , edge atom V atom U \ Vdependency graph (Gebser et al., 2006).Recall definition dependency graph relative interpretation. Let Frectified sentence signature , let interpretation . followingproposition describes relationship formula (22) loop F w.r.t. I.Proposition 3 Let q list predicate names corresponding p, let setatoms dependency graph F w.r.t.pi ( ) iff |= qi ( ),list object names. |= Loop F (q) iff loop F w.r.t. I.One might expect that, similar equivalence conditions (a) (c)Theorem 2, formula SM[F ] equivalent following formula:F u((u p) Loop F (u) NSES F (u)).(23)However, equivalence hold general, following example illustrates.Example 6 Consider FOL-representation F following programp(x, y) q(x, z)q(x, z) p(y, z),interpretation whose universe set nonnegative integerspI = {(m, m) | nonnegative integer},q = {(m, m+1) | nonnegative integer}.Formula F bounded w.r.t. since dependency graph F w.r.t. containsinfinite pathhp(0 , 0 ), q(0 , 1 ), p(1 , 1 ), q(1 , 2 ), . . .i.(24)interpretation satisfies every loop formula every finite loop F w.r.t. I,stable model.example, distinguishes set{p(0 , 0 ), q(0 , 1 ), p(1 , 1 ), q(1 , 2 ), . . . }(25)loop that, every loop contained (25), outgoing edge dependency graph. instance call unbounded set. Given dependencygraph F w.r.t. I, say nonempty set vertices unbounded w.r.t. if,every subset Z loop, edge vertex Z vertex \ Z.following proposition tells us unbounded set characterizedsecond-order formula.141fiLee & MengProposition 4 Let q list predicate names corresponding p, let setatoms dependency graph F w.r.t.pi ( ) iff |= qi ( ),list object names.|= Nonempty(q) v((v q) Loop F (v) EF (v, q))iff unbounded set F w.r.t. I.order check stability model, need check external support everyloop every unbounded set. extended loop F w.r.t. loop unboundedset F w.r.t. I. define Ext-Loop F (u)Loop F (u) (Nonempty(u) v((v u) Loop F (v) EF (v, u))).(26)Propositions 3 4, follows |= Ext-Loop F (q) iff extended loopF w.r.t. I.replace Loop F (u) Ext-Loop F (u) (23), formula equivalent SM[F ],following theorem states.Theorem 3 rectified sentence F , following sentences equivalentother:(a) SM[F ];(b) F u((u p) Nonempty(u) NSES F (u));(c) F u((u p) Ext-Loop F (u) NSES F (u)).following example use following fact simplify formulas.Proposition 5 negative formula F , formulaNSES F (u) Flogically valid.Example 2 (continued) Consider program (7) Example 2:p(x) q(x)q(y) p(y)p(z) r(z).Let F FOL-representation program:x q(x) p(x) p(y) q(y) z r(z) p(z) .142fiFirst-Order Stable Model Semantics First-Order Loop Formulas1. SM[F ] equivalentF u1 u2 u3 ((u1 , u2 , u3 ) < (p, q, r))x(u2 (x) u1 (x)) y(u1 (y) u2 (y)) z(r(z) u1 (z))).2. Formula Theorem 3 (b):F u(u p Nonempty(u) NSES F (u))equivalentF u1 u2 u3 ((u1 , u2 , u3 ) (p, q, r) (x u1 (x) x u2 (x) x u3 (x))(x[q(x) u2 (x) p(x) u1 (x)]y[p(y) u1 (y) q(y) u2 (y)]z[r(z) p(z) u1 (z)])).(27)3. Formula Theorem 3 (c): Similar (27) exceptx u1 (x) x u2 (x) x u3 (x)(27) replaced Ext-Loop F (u),Loop F (u) [(x u1 (x) x u2 (x) x u3 (x))v1 v2 v3 (((v1 , v2 , v3 ) (u1 , u2 , u3 )) Loop F (v)(x(v1 (x) u2 (x) v2 (x)) y(v2 (y) u1 (y) v1 (y))))],Loop F (u)(x u1 (x) x u2 (x) x u3 (x))v1 v2 v3 (((x v1 (x) x v2 (x) x v3 (x)) (v1 , v2 , v3 ) < (u1 , u2 , u3 ))(x(v1 (x) u2 (x) v2 (x)) y(v2 (y) u1 (y) v1 (y)))).proof Theorem 2 follows Theorem 3 using following lemma.Lemma 3 Let F rectified sentence signature (possibly containing function constants positive arity), let interpretation satisfies F . F boundedw.r.t. I,|= u(u p Ext-Loop F (u) NSES F (u))iff finite loop F w.r.t.^|=NES F (Y ) .5. Representing First-Order Stable Model Semantics First-OrderLoop Formulasnoted previous section sentence bounded w.r.t. model, loopformulas used check stability model. section, providesyntactic counterparts boundedness condition.143fiLee & Meng5.1 Bounded Formulassay rectified formula F bounded every infinite path first-order dependency graph F visits finitely many vertices. F bounded, then, clearly, every loopF finite. Again, definition extended non-rectified formula first rewritingrectified formula. also applies program referring FOL-representation.One might wonder syntactic notion boundedness ensures semantic notionboundedness: is, formula bounded, bounded w.r.t. interpretation.However, following example tells us case general.Example 7 Consider FOL-representation F following programp(a) q(x)q(x) p(b),(28)interpretation whose universe |I| set nonnegative integers, aI = bI = 0,pI = {0} q = |I|. Formula (28) bounded according definition,bounded w.r.t. I: dependency graph F w.r.t. contains infinite pathhp(0 ), q(1 ), p(0 ), q(2 ), . . . i.5.1.1 Bounded Formulas Clarks Equational Theoryhand, relationship holds interpretation satisfies Clarks equationaltheory (1978). Clarks equational theory signature , denoted CET , unionuniversal closures following formulasf (x1 , . . . , xm ) 6= g(y1 , . . . , yn ),(29)pairs distinct function constants f , g,f (x1 , . . . , xn ) = f (y1 , . . . , yn ) (x1 = y1 . . . xn = yn ),(30)function constants f arity > 0,6= x,(31)term contains variable x.Proposition 6 rectified formula F signature bounded, F boundedw.r.t. interpretation satisfies CET .following lemma relates loops loop formulas different notions dependencygraphs.Proposition 7 rectified sentence F signature interpretationsatisfies CET , model{LF F (Y ) | finite first-order loop F }iff model{LF F (Y ) | finite loop F w.r.t. I}.144fiFirst-Order Stable Model Semantics First-Order Loop Formulasfollowing theorem follows Theorem 2, Proposition 6 Proposition 7.Theorem 4 Let F rectified sentence signature (possibly containing functionconstants positive arity), let interpretation satisfies F CET .F bounded, following conditions equivalent other:(a) |= SM[F ];(b) every nonempty finite set atoms (F ), satisfies LF F (Y );(c) every finite first-order loop F , satisfies LF F (Y ).Proof. Proposition 6, F bounded F bounded w.r.t. interpretationsatisfies CET . equivalence (a) (b) follows equivalence(a) (b) Theorem 2. equivalence (a) (c) followsequivalence (a) (c) Theorem 2 Proposition 7.every Herbrand interpretation satisfies CET , Theorem 4 applies Herbrandinterpretations special case.theorem also applies logic programs, since viewed special caseformulas. example, consider following program, bounded.p(f (x)) q(x)q(x) p(x), r(x)p(a)r(a)r(f (a)).(32)set {p(a), p(f (a)), p(f (f (a))), q(a), q(f (a)), r(a), r(f (a))} answer set (32).accordance Theorem 4, also Herbrand interpretation signature obtainedprogram satisfies FOL-representation (32) loop formulas,universal closuresp(z) (q(x) z = f (x)) z =q(z) p(z) r(z)r(z) z = z = f (a).Consider another example program Bonatti (2004), a, . . . , z, nil objectconstants.letter (a)...letter (z)(33)atomic([x]) letter (x)atomic([x|y]) letter (x), atomic(y).expression [x|y] list whose head x whose tail y, stands functioncons(x, y). expression [x] stands cons(x, nil) nil special symbol145fiLee & Mengempty list. program bounded. answer set programHerbrand interpretation FOL-representation (33) universal closuresletter (u) u = . . . u = zatomic(u) v (letter (v) u = cons(v, nil))xy (letter (x) atomic(y) 6= u u = cons(x, y)).fact, definitions standard list processing predicates, member, append,reverse (Bonatti, 2004, Figure 1) bounded, represented first-orderformulas Herbrand interpretations.12say formula F atomic-tight first-order dependency graph Finfinite paths. Every tight sentence atomic-tight, vice versa. example,FOL-representations programs (32) (33) atomic-tight, tight. SimilarProposition 6, F atomic-tight, F atomic-tight w.r.t. interpretationsatisfies CET , following statement derived Corollary 3.Corollary 5 Let F rectified sentence signature (possibly containing functionconstants positive arity), let interpretation satisfies F CET .F atomic-tight, satisfies SM[F ] iff satisfies SLF[F ].statement Corollary 5 restricted interpretations satisfy CET . Indeed,statement becomes wrong restriction dropped. example, program (28)Example 7 atomic-tight, non-stable model considered satisfies loopformulas, including singleton loops.5.1.2 Bounded Formulas Normal FormNormal form another syntactic condition imposed syntactic notionboundedness ensures semantic notion boundedness. say formulanormal form every strictly positive occurrence atom form p(x), xlist distinct variables. clear every formula turned normal formusing equality.Proposition 8 rectified formula F normal form bounded, F bounded w.r.t.interpretation.Proposition 9 rectified sentence F normal form bounded, interpretation I, model{LF F (Y ) | finite first-order loop F }iff model{LF F (Y ) | finite loop F w.r.t. I}.following theorem follows Theorem 2, Proposition 8 Proposition 9.12. actually satisfy stronger condition called finitely recursive (Bonatti, 2004). See Section 8details.146fiFirst-Order Stable Model Semantics First-Order Loop FormulasTheorem 5 Let F rectified sentence normal form (possibly containing functionconstants positive arity). F bounded, following formulas equivalentother:(a) SM[F ];(b) {F } {LF F (Y ) | nonempty finite set atoms (F )};(c) {F } {LF F (Y ) | finite first-order loop F }.Proof. Proposition 8, F bounded F bounded w.r.t. interpretation I.equivalence (a) (b) follows equivalence (a) (b)Theorem 2. equivalence (a) (c) follows equivalence(a) (c) Theorem 2 Proposition 9.Consider program normal formp(x) x = a, q(a)q(y) p(b)(34)interpretation |I| = {1}, aI = bI = 1 pI = q = {1}.interpretation satisfy Clarks equational theory, stable model.accordance Theorem 5, satisfy loop formula loop {p(b), q(a)},p(b) q(a) (b = q(a) 6= a) (p(b) b 6= b).hand, consider another program non-normal formstable models (34):p(a) q(a)(35)q(y) p(b)Program (35) finite complete set loops, {{p(z)}, {q(z)}}; loop formulasuniversal closuresp(z) z = q(a)q(z) p(b)satisfies loop formulas. example illustrates role normal form assumptionTheorem 5 (in place Clarks equational theory Theorem 4).Note normal form conversion may turn bounded sentence non-boundedsentence. instance, normal form bounded program (32)p(y) = f (x), q(x)q(x) p(x), r(x)p(x) x =r(x) x =r(x) x = f (a),(36)bounded.Unlike Corollary 5, program normal form, atomic-tightnessgeneral tightness. difficult check program normal form atomictight iff tight.147fiLee & Meng5.1.3 Decidability Boundedness Finite Complete Set Loopsgeneral, checking whether F bounded decidable, becomes decidable Fcontains function constants positive arity. case checking whetherF atomic-tight.Proposition 10 rectified sentence F (allowing function constants positive arity),(a) checking whether F bounded decidable;(b) checking whether F atomic-tight decidable.F contains function constants positive arity,(c) checking whether F bounded decidable;(d) checking whether F atomic-tight decidable.proof Proposition 10 (c) based following fact straightforwardextension Theorem 2 Chen et al. (2006) first-order formulas, assertschecking F finite complete set loops decidable.Proposition 11 rectified formula F contains function constants positivearity, F bounded iff F finite complete set loops.Note Proposition 11 hold F allowed contain function constantspositive arity. instance,p(x) p(f (x))bounded, finite complete set loops {{p(x)}}.following corollary follows Theorem 4 Proposition 11.Corollary 6 Let F rectified sentence signature function constantspositive arity, let interpretation satisfies F CET . Ffinite complete set loops, conditions (a), (b), (c) Theorem 4 equivalentother.following corollary follows Theorem 5 Proposition 11.Corollary 7 Let F rectified sentence normal form function constantspositive arity. F finite complete set loops, formulas (a), (b), (c)Theorem 5 equivalent other.148fiFirst-Order Stable Model Semantics First-Order Loop Formulas5.2 Semi-Safe FormulasSemi-safety another decidable syntactic condition ensures SM[F ] expressed first-order sentences.assume function constants positive arity. According Lee,Lifschitz, Palla (2009), semi-safe sentence small predicate property:relation represented predicate constants p hold tuple argumentsmember tuple represented object constant occurring F .show semi-safe sentence stable model semantics turnedsentence first-order logic.First, review notion semi-safety Lee et al. (2009).13 preliminary step,assign every formula F set RV(F ) restricted variables follows:atomic formula F ,F equality two variables, RV(F ) = ;otherwise, RV(F ) set variables occurring F ;RV(G H) = RV(G) RV(H);RV(G H) = RV(G) RV(H);RV(G H) = ;RV(QvG) = RV(G) \ {v} Q {, }.say variable x restricted F x RV(F ). rectified formula F semisafe every strictly positive occurrence every variable x belongs subformula G Hx restricted G.sentence strictly positive occurrence variable, obviously semisafe. FOL-representation disjunctive program semi-safe if, rule (10)program, every variable occurring head rule occurs B well.Example 8 FOL-representation (8) semi-safe. Formulap(a) q(b) xy((p(x) q(y)) p(y))semi-safe,p(a) q(b) xy((p(x) q(y)) p(y))(37)semi-safe.finite set c object constants, c (x) stands formula_x = c.cc13. definition slightly general refer prenex form. Instead requireformula rectified.149fiLee & Mengsmall predicate property expressed conjunction sentences^v1 , . . . , vn p(v1 , . . . , vn )inc (vi )i=1,...,npredicate constants p occurring F , v1 , . . . , vn distinct variables.denote conjunction sentences SPP c . c(F ) denote set objectconstants occurring F .Proposition 12 (Lee et al., 2009) semi-safe sentence F , formula SM[F ] entailsSPP c(F ) .example, semi-safe sentence (37), SM[(37)] entailsx p(x) (x = x = b)) x(q(x) (x = x = b) .(38)following proposition tells us semi-safe sentence F , formula SM[F ]equivalently rewritten first-order sentence.Theorem 6 Let F rectified sentence function constants positive arity.F semi-safe, SM[F ] equivalent conjunction F , SPP c(F ) finitenumber first-order loop formulas.Proof. F semi-safe, SM[F ] entails SPP c(F ) . sufficient proveassumption SPP c(F ) , SM[F ] equivalent conjunction F finite numberfirst-order loop formulas. follows |= SPP c(F ) F bounded w.r.t. I. Sinceevery finite loop F w.r.t. represented finite set atoms whose termsobject variables, follows Theorem 2 satisfies SM[F ] iff satisfies loopformulas sets.example, SM[(37)] equivalent conjunction F , (38) universalclosuresp(z) z = (p(x) q(z) z 6= x)q(z) z = bNote condition finite complete set loops Corollaries 6 7,condition semi-safety Theorem 6 entail other. instance, formula (37)semi-safe, finite complete set first-order loops, x p(x) finitecomplete set loops {{p(x)}}, semi-safe. Also program 1 Section 1finite complete set loops, semi-safe due w fourth rule.6. Programs Explicit Quantifiersfollowing extend syntax logic program allowing explicit quantifiers.rule quantifiers formH G,(39)G H first-order formulas every occurrence every implicationG H belongs negative formula. program quantifiers finite set rules150fiFirst-Order Stable Model Semantics First-Order Loop Formulasquantifiers. Program 1 Section 1 example. semantics programdefined identifying program FOL-representation stable modelsemantics. restricting syntax program like one above, comparisonsyntax arbitrary formula, able write succinct loop formulas,show below.Let F formula finite set atoms. FY denote formula obtainedF replacing every occurrenceevery atom p(t) F belongVnegative formula p(t) p(t0 )Y 6= t0 . Let program quantifiers. Givenfinite set atoms (), first rename variables variablesoccur . define formula QES (Y ) (External Support Formula ProgramsQuantifiers) disjunctionz(GY HY )(40)every rule (39) H contains strictly positive occurrence predicate constantoccurs , z list free variables rule occur .loop formula universal closure^QES (Y ).(41)following proposition tells us (41) equivalent (12) notionsapplied program explicit quantifiers. also shows (41) generalizationdefinition loop formula disjunctive program.Proposition 13 Let program quantifiers, F FOL-representation ,finite set atoms. assumption , formula QES (Y ) equivalentNES F (Y ). disjunctive program normal form, QES (Y ) also equivalentES (Y ) assumption .Note size (41) polynomial size given program.case apply (12) FOL-representation program, dueexpansion NES nested implications. hand, syntactic conditionimposed rule quantifiers avoids exponential blow up, followinglemma tells us.Lemma 4 Let F formula every occurrence implication F belongsnegative formula let set atoms. NES F (Y ) equivalent FY .Proof. induction F .Example 2 (continued) First-Order Loop Formula understoodextended program (Using QES (Y )) : assumption ,LF (Y1 ) equivalent universal closurep(u) (x(q(x) (p(x) x 6= u)) z(r(z) (p(z) z 6= u))).151fiLee & MengLF (Y2 ) equivalent universal closureq(u) y(p(y) (q(y) 6= u)).LF (Y3 ) equivalent universal closurer(u) .LF (Y4 ) equivalent universal closure(p(u) q(u)) (x((q(x) x 6= u) (p(x) x 6= u))y((p(y) 6= u) (q(y) 6= u))z(r(z) (p(z) z 6= u))).finite set sentences entails sentence F stable model semantics (symbolically, |=SM F ), every stable model satisfies F .SM[F ] reduced first-order sentence, described Theorem 5 Theorem 6,|=SM F iff |= F,set first-order loop formulas required (and possibly including SPP c(F )Theorem 6 applied). fact allows us use first-order theorem provers reasonquery entailment stable model semantics.Example 9 Consider program 1 Section 1, following finite completeset loops: {Man(u)}, {Spouse(u, v)}, {HasWife(u)}, {Married (u)}, {Accident(u, v)},{Discount(u, v)}, {HasWife(u), Married (u)}. loop formulas 1 2 3equivalent universal closureMan(u) Man(John) John 6= u ;Spouse(u, v) Spouse(John, y) (John, y) 6= (u, v) ;HasWife(u) x Spouse(x, y) (HasWife(x) x 6= u)x Man(x) Married (x) (HasWife(x) x 6= u) ;Married (u) x Man(x) HasWife(x) (Married (x) x 6= u) ;Accident(u, v) ;Discount(u, v)x Married (x) z Accident(x, z) (w(Discount(x, w) (x, w) 6= (u, v))) ;Married (u) HasWife(u)x Spouse(x, y) (HasWife(x) (x 6= u))x Man(x) Married (x) x 6= u (HasWife(x) x 6= u)x Man(x) HasWife(x) x 6= u (Married (x) x 6= u) .152fiFirst-Order Stable Model Semantics First-Order Loop Formulasloop formulas, conjoined FOL-representation 1 2 3 , entailfirst-order logic x Married (x) xy(Discount(x, y) x = John). verifiedanswers using first-order theorem prover Vampire 14 .7. Extension Allow Extensional Predicatesdefinition stable model journal paper Ferraris et al. (2011), reviewedSection 2, general definition conference paper (Ferraris et al., 2007)allows us distinguish intensional non-intensional (a.k.a. extensional) predicates. Similar Datalog, intensional (output) predicates characterizedterms extensional (input) predicates. instance, consider Example 9 again, assume Man Spouse non-intensional. 1 2 3 still entails xyDiscount(x, y)longer entails xy(Discount(x, y) x = John) may personJohn spouse.results earlier sections extended general semantics viewProposition 14 below, characterizes SM[F ; p] terms SM[F ]. pr (F ) denotelist predicate constants occurring F ; Choice(p) denote conjunctionchoice formulas x(p(x) p(x)) predicate constants p p, x listdistinct object variables; False(p) denote conjunction xp(x) predicateconstants p p. sometimes identify list corresponding setconfusion.Proposition 14 list p predicate constants, formula SM[F ; p] equivalentSM[F Choice(pr (F )\p) False(p\pr (F ))](42)SM[F Choice(pr (F )\p) False(p\pr (F ))],(43)F obtained F replacing every atom form q(t) F qbelong p q(t).proposition allows us extend results established SM[F ] SM[F ; p].instance, Theorem 3 extended SM[F ; p] first rewriting form SM[G],GF Choice(pr (F )\p) False(p\pr (F )).(44)next three corollaries, signature, F rectified sentence (possiblycontaining function constants positive arity), p finite list predicate constants, G (44).first corollary follows Theorem 2 Proposition 14.Corollary 8 interpretation satisfies F , G bounded w.r.t. I,following conditions equivalent other:(a) |= SM[F ; p];14. http://www.vampire.fm .153fiLee & Meng(b) every nonempty finite set atoms formed predicate constants pobject names |I|, satisfies LF F (Y );(c) every finite loop G w.r.t. whose predicate constants contained p,satisfies LF F (Y ).next corollary follows Theorem 4 Proposition 14.Corollary 9 G bounded, then, interpretation satisfies F CET ,following conditions equivalent other:(a) |= SM[F ; p];(b) every nonempty finite set atoms (G) whose predicate constants contained p, satisfies LF F (Y );(c) every finite first-order loop G whose predicate constants contained p,satisfies LF F (Y ).last corollary follows Theorem 5 Proposition 14.Corollary 10 G normal form bounded, following formulasequivalent other:(a) SM[F ; p];(b) {F } {LF F (Y ) | nonempty finite set atoms (G) whose predicateconstants contained p};(c) {F } {LF F (Y ) | finite first-order loop G whose predicate constantscontained p}.Example 10 Consider Example 9 again, assuming Man Spouse extensional.Let F FOL-presentation 1 2 3 let G formula (44). loopsG loops F . loop formulas remain exceptfollowing loop formulas Man(u) Spouse(u, v):Man(u) Man(John) John 6= u x (Man(x) x 6= u) Man(x) ;Spouse(u, v) Spouse(John, y) (John, y) 6= (u, v)xy (Spouse(x, y) (x, y) 6= (u, v)) Spouse(x, y) .two formulas tautologies. result, loop formulas loops, conjoinedG, entail xyDiscount(x, y), longer entail xy (Discount(x, y) x = John).general, loops G contain intensional extensional predicates. Also every loop G contains extensional predicate singleton,loop formula loop tautology.154fiFirst-Order Stable Model Semantics First-Order Loop FormulasCorollary 3 extended allow extensional predicates following. SLF[F ; p],denote{LF F ({p(x)}) | p predicate constant p, x listdistinct object variables whose length arity p}.say formula F p-atomic-tight w.r.t. every infinite path dependencygraph F w.r.t. whose vertices satisfied contains atom whose predicateconstant p.Corollary 11 Let F rectified sentence (possibly containing function constants positive arity), let model F . F p-atomic-tight w.r.t. I, satisfiesSM[F ; p] iff satisfies SLF[F ; p].definition semi-safety extended distinguish intensional nonintensional predicates follows. Let F formula function constantspositive arity. every first-order formula F assign set RVp (F ) restricted variablesrelative p follows.atomic formula F (including equality ),F equality two variables, atom whose predicate constantp, RVp (F ) = ;otherwise, RVp (F ) set variables occurring F ;RVp (G H) = RVp (G) RVp (H);RVp (G H) = RVp (G) RVp (H);RVp (G H) = .RVp (QvG) = RVp (G) \ {v} Q {, }.say variable x p-restricted F x RVp (F ). rectified formula Fsemi-safe relative p every strictly positive occurrence every variable x belongssubformula G H, x p-restricted G.small predicate property generalized follows. Formula SPP pc conjunctionsentences^v1 , . . . , vn p(v1 , . . . , vn )inc (vi )i=1,...,npredicate constants p p, v1 , . . . , vn distinct variables.Proposition 15 (Lee et al., 2009) semi-safe sentence F relative p, formulaSM[F ; p] entails SPP pc(F ) .following proposition tells us semi-safe sentence F , formula SM[F ; p]equivalently rewritten first-order sentence.155fiLee & MengTheorem 7 Let F rectified sentence function constants positive arity.F semi-safe relative p, SM[F ; p] equivalent conjunction F , SPP pc(F )finite number first-order loop formulas.Proof. Let F sentence signature . F semi-safe relative p, SM[F ; p]entails SPP pc(F ) , sufficient prove assumption SPP pc(F ) , SM[F ; p]equivalent conjunction F finite number first-order loop formulas.Proposition 14, SM[F ; p] equivalent SM[G], G (44). Consider interpretation satisfies G SPP pc(F ) . Note dependency graph G w.r.t.contains outgoing edges vertex whose predicate constant belong p.Together fact |= SPP pc(F ) , conclude path dependencygraph whose vertices satisfied visits finitely many vertices. Consequently, Gbounded w.r.t. I. Since every finite loop G w.r.t. represented finite setatoms whose terms object variables, follows Theorem 2 satisfies SM[G]iff satisfies loop formulas sets.8. Related Worknotion bounded program related notion finitely recursive programstudied Bonatti (2004), different definition dependency graph considered. atom dependency graph nondisjunctive ground program defined Bonattidirected graph vertices set ground atoms, edges goatom head atoms body every rule, including negative body. program called finitely recursive if, every atom, finitelymany atoms reachable atom dependency graph. clear every finitelyrecursive program bounded, converse hold. instance, programp(x) p(f (x))bounded, finitely recursive infinite paths involve negativeedges. Also programp(a) q(f (x))bounded, finitely recursive infinitely many atoms q(f (a)), q(f (f (a))), . . .reached p(a) atom dependency graph. Like bounded programs, checkingfinitely recursive programs undecidable presence function constants positivearity.Lin Wang (2008) extended answer set semantics functions extendingdefinition reduct, also provided loop formulas programs. providealternative account results considering notions special casesdefinitions presented paper. simplicity, assume non-sorted languages.15Essentially, restricted attention special case non-Herbrand interpretationsobject constants form universe, ground terms object constantsmapped object constants. According Lin Wang, LW-program P consists15. Lin Wang (2008) consider essentially many-sorted languages. result sectionextended case considering many-sorted SM (Kim, Lee, & Palla, 2009).156fiFirst-Order Stable Model Semantics First-Order Loop Formulastype definitions set rules. Type definitions introduce domains many-sortedsignature consisting object constants, includes evaluation functionsymbol positive arity maps list object constants object constant. Sinceassume non-sorted languages, consider single domain (universe). sayinterpretation P -interpretation universe set object constants specifiedP , object constants evaluated itself, ground terms object constantsevaluated conforming type definitions P .Proposition 16 Let P LW-program let F FOL-representation setrules P . following conditions equivalent other:(a) answer set P according Lin Wang (2008);(b) P -interpretation satisfies SM[F ];(c) P -interpretation satisfies F loop formulas loopsF w.r.t. I.equivalence (b) (c) follows Proposition 2 since universefinite. equivalence (a) (c) follows fact LW answer setscharacterized loop formulas defined Lin Wang (2008)loop formulas essentially loop formulas (c).Since proposal first-order stable model semantics, papersfirst-order definability SM[F ]. Zhang Zhou (2010) show that, nondisjunctive program function constants positive arity, first-order stablemodel semantics reformulated progression based semantics. also showedprograms whose answer sets found finite progression exactlyrepresented first-order formulas. researchers paid special attention first-order definability SM[F ] finite structures. Chen, Zhang, Zhou (2010)show game-theoretic characterization first-order indefinability first-order answerset programs finite structures. Asuncion, Lin, Zhang, Zhou (2010) show first-orderdefinability finite structures turning programs modified completion using newpredicates record levels. Chen, Lin, Zhang, Zhou (2011) present condition calledloop-separable, refined finite complete set loopsfinite answer sets program captured first-order sentences. However, likecondition finite complete set loops, condition disjoint semi-safety.following program semi-safe loop-separable:p(x) p(y), q(x, y).However, work limited nondisjunctive programs contain function constants positive arity. work limited finite structures, considers functionconstants positive arity well. Nonetheless papers first-order definabilityclosely related work insights would gained relationshipthem.use first-order theorem provers stable model semantics already investigated Sabuncu Alpaslan (2007), results limited several ways.157fiLee & Mengconsidered nondisjunctive logic programs trivial loops only, case stablemodel semantics equivalent completion semantics. also restricted attentionHerbrand models.9. Conclusionpaper puts first-order loop formulas context first-order reasoning studiesrelated first-order stable model semantics. similarities mismatchesfound paper provide useful insights first-order reasoning stable models.Future work find restrictions make first-order stable model reasoningdecidable computable efficient manner, like conditions imposed finitaryprograms (Bonatti, 2004). Recently, first-order stable model semantics shownused unifying nonmonotonic logic integrating rules ontologies (de Bruijn,Pearce, Polleres, & Valverde, 2010; Lee & Palla, 2011), ontology predicatesidentified extensional predicates. Based studied relationship first-orderstable model semantics first-order loop formulas, one may find restrictionstailored hybrid knowledge bases efficient computation.Acknowledgmentsgrateful Joseph Babb, Michael Bartholomew, Piero Bonatti, Vladimir Lifschitz,Ravi Palla useful discussions, anonymous referees useful comments. authors partially supported National Science FoundationGrant IIS-0916116 IARPA SCIL program.Appendix A. Proofsproofs presented order dependencies. Theorem 3 main theorem.proof Theorem 2 uses Theorem 3. proofs Theorems 4 5 followTheorem 2. proof Lemma 1 follows Proposition 13.following, unless otherwise noted, F rectified first-order sentence, p listdistinct predicate constants p1 , . . . , pn occurring F , symbols u, v lists distinctpredicate variables length p, symbols q, r lists distinct predicatenames length p.A.1 Proof Theorem 3Theorem 3other:rectified sentence F , following sentences equivalent(a) SM[F ];(b) F u((u p) Nonempty(u) NSES F (u));(c) F u((u p) Ext-Loop F (u) NSES F (u)).158fiFirst-Order Stable Model Semantics First-Order Loop Formulasnotation use proof involves predicate expressions (Lifschitz, 1994,Section 3.1) formxF (x),(45)F (x) formula. e (45) G(p) formula containing predicate constantp arity length x G(e) stands result replacingatomic part form p(t) G(p) F (t), renaming bound variables G(p)usual way, necessary. instance, G(p) p(a) p(b) G(y(x = y))x = x = b. Substituting tuple e predicate expressions tuple p predicateconstants defined similar way.Lemma 5 Let v list yi (pi (yi ) ui (yi )). following formulas logicallyvalid:u p (F (u) NSES F (v));u p (F (v) NSES F (u)).Proof. induction.A.1.1 Proof Equivalence (a) (b) Theorem 3sufficient showu(u < p F (u))equivalentv(v p Nonempty(v) NSES F (v)).left right: Take u u < pF (u). Let v list yi (pi (yi ) ui (yi )).Clearly, v p holds.u < p, follows x pi (x) ui (x),Wx vi (x ) follows, Nonempty(v) follows.Lemma 5, NSES F (v) follows u < p F (u).right left: Take v v p Nonempty(v) NSES F (v). Let u listyi (pi (yi ) vi (yi )).Clearly, u p holds. Moreover (u = p) holds. Indeed, u = p, xi vi (xi )follows, contradicts assumption Nonempty(v). Consequently, u < p follows.Lemma 5, F (u) follows v p NSES F (v).159fiLee & MengA.1.2 Proof Proposition 3Lemma 6 Let interpretation contains (F ), let q, r listspredicate names corresponding p. Let Z sets atoms dependency graphF w.r.t.pi ( ) iff |= qi ( )pi ( ) Z iff |= ri ( ),list object names.|= r q EF (r, q)iff Z subset edge atom Z atom \ Zdependency graph F w.r.t. I.Proof. left right: Assume |= r q EF (r, q). fact Z subsetfollows assumption |= r q construction Z . Since_|=z(ri (t) qj (t0 ) rj (t0 )),(pi (t),pj (t0 )) : pi (t) depends pj (t0 )rule Fz list object variables t0 , substitution mapsobject variables t0 object names_|=ri (t) qj (t0 ) rj (t0 ).(pi (t),pj (t0 )) : pi (t) depends pj (t0 )rule FConsequently, atoms pi (t), pj (t0 ) pi (t) depends pj (t0 ) rule F|= ri (t)qj (t0 )rj (t0 ). |= ri (t) construction Z, followspi (((t)I ) ) belongs Z. Also |= qj (t0 ) rj (t0 ), follows pj (((t0 )I ) )belongs \ Z. Therefore, edge atom Z atom \ Zdependency graph F w.r.t. I.right left: Assume Z subset edge atompi ( ) Z atom pj ( ) \ Z dependency graph F w.r.t. I. Clearly,|= r q.assumption pi ( ) Z, pj ( ) \ Z construction Z,follows |= ri ( ) qj ( ) rj ( ). definition dependency graphw.r.t. I, follows pi (t), pj (t0 ) pi (t) depends pj (t0 ) ruleF substitution maps object variables t0 object names(t)I = (t0 )I = .Consequently,_|=ri (t) qj (t0 ) rj (t0 ),(pi (t),pj (t0 )) : pi (t) depends pj (t0 )rule F160fiFirst-Order Stable Model Semantics First-Order Loop Formulasequivalent saying_|=z(ri (t) qj (t0 ) rj (t0 )),(pi (t),pj (t0 )) : pi (t) depends pj (t0 )rule Fz list variables t0 .Lemma 7 graph (V, E) strongly connected iff, nonempty proper subset UV , edge U V \ U .Proof. Follows definition strongly connected graph.Proposition 3 Let q list predicate names corresponding p, let setatoms dependency graph F w.r.t.pi ( ) iff |= qi ( ),list object names. |= Loop F (q) iff loop F w.r.t. I.Proof. left right: Assume |= Loop F (q). |= Nonempty(q),follows nonempty.Take nonempty proper subset Z . Let r list predicate names|= ri ( ) iff pi ( ) Z.clear|= Nonempty(r) r < q.Consequently, |= Loop F (q), follows |= E F (r, q). Lemma 6,edge atom Z atom \ Z. Consequently, Lemma 7, inducesstrongly connected subgraph thus loop F w.r.t. I.right left: Let loop F w.r.t. q list predicate names|= qi ( ) iff pi ( ) Y.Since nonempty, |= Nonempty(q).Consider list predicate names r|= Nonempty(r) r < q.Let Z set vertices dependency graph F w.r.t.pi ( ) Z iff |= ri ( ).Clearly, Z nonempty proper subset . Since induces strongly connected subgraph,Lemma 7, edge atom Z atom \ Z. ConsequentlyLemma 6, |= EF (r, q).161fiLee & MengA.1.3 Proof Proposition 4Proposition 4 Let q list predicate names corresponding p, let setatoms dependency graph F w.r.t.pi ( ) iff |= qi ( ),list object names.|= Nonempty(q) v((v q) Loop F (v) EF (v, q))iff unbounded set F w.r.t. I.Proof. left right: Assume|= Nonempty(q) v(v q Loop F (v) EF (v, q)).(46)Since |= Nonempty(q), clear nonempty.Take subset Z loop F w.r.t. I. Let r list predicate names|= ri ( ) iff pi ( ) Z.Since Z subset , clear |= r q. Since Z loop F w.r.t. I,Proposition 3, |= Loop F (r). Consequently, (46) follows |= E F (r, q).Lemma 6, edge atom Z atom \ Z. Therefore,unbounded set F w.r.t. I.right left: Let unbounded set F w.r.t. I. Since nonempty,clear |= Nonempty(q).Take list predicate names r |= r q Loop F (r). Let Z setvertices dependency graph F w.r.t.pi ( ) Z iff |= ri ( ).Proposition 3, Z loop F w.r.t. I. clear Z subset . Sinceunbounded set F w.r.t. I, edge Z \ Z. Consequently Lemma 6,|= EF (r, q).A.1.4 Proof Proposition 5Proposition 5 negative formula F , formulaNSES F (u) Flogically valid.Proof. proof follows immediately following two lemmas, provedinduction.162fiFirst-Order Stable Model Semantics First-Order Loop FormulasLemma 8 formula F ,NSES F (u) Flogically valid.Lemma 9 Let F formula, let SF set pi (t) strictly positiveoccurrence F . Formula^Fzvi (t) NSES F (v)(47)pi (t)SFlogically valid, z tuple variables free F .A.1.5 Proof Equivalence (b) (c) Theorem 3Lemma 10 Let F rectified formula, let SF+ set atoms pi (t)positive occurrence F belong negative formula, let SF setatoms pi (t) negative occurrence F belong negativeformula.16 following formulas logically valid, z list variablesfree F .V(a) (v u) pi (t)S + z(ui (t) vi (t)) NSES F (v) NSES F (u);FV(b) (v u) pi (t)S z(ui (t) vi (t)) NSES F (u) NSES F (v).FProof. parts proved simultaneously induction F .Case 1: F atom pi (t).Part (a): NSES F (v) entails NSES F (u) assumption^z(ui (t) vi (t)).+pi (t)SFPart (b): NSES F (u) entails NSES F (v) assumption v u.Case 2: F equality. clear since NSES F (v) NSES F (u)F.Case 3: F G H G H. Follows I.H.Case 4: F G H.Part (a): Assume(v u)^z(ui (t) vi (t)).(48)+pi (t)SFneed show(NSES G (v) NSES H (v)) (G H)16. Note distinguish formula negative occurrence negative. Seeend Section 2.163fiLee & Mengentails(NSES G (u) NSES H (u)) (G H).Note^z(ui (t) vi (t))pi (t)SG^z(ui (t) vi (t))+pi (t)SHentailed formula (48). I.H., NSES G (u) entails NSES G (v) NSES H (v) entailsNSES H (u).Part (b): Similar Part (a).Case 5: F x GPart (a): Assume^(v u)z(ui (t) vi (t)) xNSES G (v).+pi (t)SFassumption NSES G (v), G follows Lemma 8. Also^z0 (ui (t) vi (t))+pi (t)SGfollows, z0 list variables free G, I.H. G,NSES G (u) holds assumption. Since x free assumption, xNSES G (u)holds well.Part (b): Similar Part (a).Case 6: F x G.Part (a): Assume^(v u)z(ui (t) vi (t)) xNSES G (v).(49)z(ui (t) vi (t)) NSES G (v).(50)+pi (t)SFTake x(v u)^+pi (t)SFNSES G (v), Lemma 8, G follows. Also^z0 (ui (t) vi (t))+pi (t)SGfollows, z0 list variables free G. I.H. G,NSES G (u) holds assumption (50). Consequently, xNSES G (u) holds164fiFirst-Order Stable Model Semantics First-Order Loop Formulasassumption. Since x free (49), conclude xNSES G (u) holdsassumption (49).Part (b): Similar Part (a).Lemma 11 rectified formula F ,(v u) EF (v, u) NSES F (u) NSES F (v)logically valid.Proof. induction F .Case 1: F atom pi (t). NSES F (u) entails NSES F (v) assumption v u.Case 2: F equality. clear since NSES F (v) NSES F (u) F .Case 3: F G H G H. Follows I.H.Case 4: F G H. Assume(v u) EF (v, u) NSES F (u)NSES G (v). NSES F (u), Lemma 8, conclude G H. NSES G (v),Lemma 8, G follows, consequently H.Assume NSES H (v) sake contradiction. Lemma 9, H NSES H (v),follows_xvi (t)(51)pi (t) : pi (t) occurs strictly positively H, x list variables free H.Since F rectified, variables F partitioned three sets: listvariables x free H, list variables free G,rest. Note EF (v, u) entails^xvi (t) y(uj (t0 ) vj (t0 )) ,(52)(pi (t),pj (t0 )) : pi (t) depends pj (t0 ) rule GH Fpi (t) occurs H,pj (t0 ) occurs Gx list variables free H, list variablest0 free G. (51) (52), conclude^y(uj (t0 ) vj (t0 )).pj (t0 ) : pj (t0 ) occurs positively negative subformula Gthis, together assumption (v u) NSES G (v), Lemma 10 (a),NSES G (u) follows. Thus NSES H (u) follows NSES F (u) NSES G (u). Since E F (v, u)entails E H (v, u), I.H. H, NSES H (v) follows, contradicts assumption.Case 5: F xG xG. Follows I.H.165fiLee & MengLemma 12Nonempty(u) v(v u Ext-Loop F (v) EF (v, u))logically valid.Proof. Take list q predicate names, interpretation satisfies Nonempty(q).Let set vertices dependency graph F w.r.t.pi ( ) iff |= qi ( ).Consider subgraph G dependency graph F w.r.t. induced .unbounded set w.r.t. I, Proposition 4, |= Ext-Loop F (q).|= q q Ext-Loop F (q) EF (q, q).Otherwise, consider graph G0 obtained G collapsing strongly connectedcomponents G, i.e., vertices G0 strongly connected components GG0 edge V V 0 G edge vertex V vertex V 0 . Sinceassumed unbounded set w.r.t. I, exists vertex Z G0outgoing edges. Consider list predicate names r|= ri ( ) iff pi ( ) Z.clear |= r q. Proposition 3, |= Loop F (r) thus |= Ext-Loop F (r). Sinceedge Z \ Z, Lemma 6, |= EF (r, q). Consequently, claimfollows.Proof Equivalence (b) (c) Theorem 3(b) (c):valid.Clear formula Ext-Loop F (u) Nonempty(u) logically(c) (b): AssumeF v(v p Ext-Loop F (v) NSES F (v)).Take u u p Nonempty(u). Lemma 12, follows Nonempty(u)exists v v u Ext-Loop F (v) EF (v, u). clear v pfollows v u u p. follows assumption NSES F (v).Lemma 11, NSES F (u) follows v u EF (v, u).A.2 Proof Theorem 2Lemma 3 Let F rectified sentence signature (possibly containing functionconstants positive arity), let interpretation satisfies F . Fbounded w.r.t. I,|= u(u p Ext-Loop F (u) NSES F (u))166fiFirst-Order Stable Model Semantics First-Order Loop Formulasiff finite loop F w.r.t.^|=NES F (Y ) .Proof. left right: Assume|= q p Ext-Loop F (q) NSES F (q)list predicate names q. Consider set vertices dependencygraph F w.r.t.pi ( ) iff |= qi ( ).Since |= Ext-Loop F (q), Proposition 3 Proposition 4, followsextended loop F w.r.t. I. Since |= qi ( ) pi ( ) |= q p, followssatisfies every atom . Together assumption F bounded w.r.t. I,implies set finite. Since |= NSES F (q) finite, Lemma 2,follows |= NES F (Y ).right left: Consider finite loop F w.r.t. I. Assume^|=NES F (Y ).Let q list predicate names|= qi ( ) iff pi ( ) Y.|= q p follows construction q |=VY.Since loop F w.r.t. I, Proposition 3, |= Loop F (q), consequently,|= Ext-Loop F (q).|= NES F (Y ), Lemma 2, |= NSES F (q).Consequently, |= u(u p Ext-Loop F (u) NSES F (u)).Theorem 2 Let F rectified sentence signature (possibly containing functionconstants positive arity), let interpretation satisfies F . Fbounded w.r.t. I, following conditions equivalent other:(a) satisfies SM[F ];(b) every nonempty finite set atoms formed predicate constants (F )object names |I|, satisfies LF F (Y );(c) every finite loop F w.r.t. I, satisfies LF F (Y ).Proof. (a) (c): Theorem 3 Lemma 3.(b) (c):167fiLee & Meng(b) (c): Clear.(c) (b): Assume satisfies LF F (L) every finite loop L F w.r.t I.Consider nonempty finite set Vatoms formed predicate constants (F )object names |= . Let q list predicate names|= qi ( ) iff pi ( ) Y.Since nonempty, clear Nonempty(q) follows. view Lemma 12,list predicate names r|= r q Ext-Loop F (r) EF (r, q).(53)Consider Z set vertices dependency graph F w.r.t.pi ( ) Z iff |= ri ( ).Since |= Ext-Loop F (r), Proposition3 PropositionV4, Z extended loopVF w.r.t. I. Clearly, |= Z since Z |= . Since F boundedw.r.t. I, Z satisfied I, follows Z finite loop F w.r.t. I.Since |= r q EF (r, q), Z subset and, Lemma 6, edgeZ \ Z dependency graph F w.r.t. I. Since |= LF F (Z),conclude |= NES F (Z), Lemma 2, |= NSES F (r). (53)|= NSES F (r), Lemma 11, |= NSES F (q). Lemma 2 again,|= NES F (Y ). Consequently, |= LF F (Y ).A.3 Proof Proposition 6Proposition 6rectified formula F signature bounded, F boundedw.r.t. interpretation satisfies CET .Lemma 13 terms t1 t2 signature , interpretation satisfiesCET , substitution object variables t1 t2 object names(t1 )I = (t2 )I , Robinsons unification algorithm (Robinson, 1965), applied t1t2 , returns general unifier (mgu) t1 t2(a) t1 = t2 ,(b) every variable x t1 t2 , (x)I = (x)I .Proof. assumptions, Lemma 5.1 work Kunen (1987), t1 t2unifiable, case Robinsons algorithm returns mgu t1 t2 mapsvariables occurring t1 t2 terms. Given this, part (b) proven induction.proof Proposition 6 follows following lemma.168fiFirst-Order Stable Model Semantics First-Order Loop FormulasLemma 14 Let F rectified sentence signature , let interpretationsatisfies CET . pathhp1 ( 1 ), p2 ( 2 ), . . . , pk ( k ), pk+1 ( k+1 )i(54)dependency graph F w.r.t I, pathhp1 (u1 ), p2 (u2 ), . . . , pk (uk ), pk+1 (uk+1 )ifirst-order dependency graph F substitution maps object variablesui object names (ui )I = i.Proof. edge (pi ( ), pi+1 ( i+1 )) (54) obtained pair atoms (pi (ti ), pi+1 (t0i ))substitution pi (ti ) depends pi+1 (t0i ) rule F ,(t1 1 )I = 1 , (t0i )I = (ti+1 i+1 )I = i+1 (1 < k), (t0k k )I = k+1 .(55)simplicity assume pair (pi (ti ), pi+1 (t0i )) considered commonvariables another pair first renaming variables. allows us use one substitution = 1 . . . k place individual rest proof.show induction that, j j {1 . . . k}, substitutionsj(1 j) variables ti t0i terms(a) hp1 (t1 )1j , p2 (t2 )2j , . . . , pj (tj )jj , pj+1 (t0j )jj path first-order dependencygraph F ,(b) (ti ij )I = 1 j, (t0j jj )I = j+1 .j = 1, take ij identity substitution. Clearly, conditions (a) (b)satisfied.Otherwise, I.H. assume that, j {1, . . . , k1}, substitutions1j , . . . , jj conditions (a) (b) satisfied. provesubstitutions ij+1 (1 j +1) variables ti t0i termsj+1j+1(a) hp1 (t1 )1j+1 , p2 (t2 )2j+1 , . . . , pj+1 (tj+1 )j+1, pj+2 (t0j+1 )j+1path first-order dependency graph F ,j+1(b) (ti ij+1 )I = 1 j +1, (t0j+1 j+1) = j+2 .I.H., (t0j jj )I = j+1 (55) (tj+1 )I = j+1 . Lemma 13substitution variables t0j jj tj+1 terms t0j jj = tj+1variable x t0j jj tj+1 ,(x)I = (x)I .define ij+1ij 1 j169(56)fiLee & Meng= j +1.easy check condition (a) satisfied. check condition (b) satisfied,consider variable x set{t1 1j , t2 2j , . . . , tj jj , t0j jj , tj+1 , t0j+1 }.(57)x t0j jj tj+1 , (56), (x)I = (x)I . Otherwise, since changevariables t0j jj tj+1 , (x)I = (x)I . Consequently, variable x(57), get (x)I = (x)I . remains check following.1 j, (ti ij+1 )I = (ti ij )I = (ti ij )I . last one equal I.H.j+1(tj+1 j+1) = (tj+1 )I = (tj+1 )I . last one equal j+1 (55).j+1(t0j+1 j+1) = (t0j+1 )I = (t0j+1 )I . last one equal j+2 (55).A.4 Proof Proposition 7Proposition 7 rectified sentence F signature interpretationsatisfies CET , model{LF F (Y ) | finite first-order loop F }iff model{LF F (Y ) | finite loop F w.r.t. I}.proof follows immediately following fact Lemma 15.Fact 1 Let F rectified sentence signature , let interpretation .first-order loop F substitution maps variables objectnames, 0 = {pi ( ) | pi (t) , tI = } loop F w.r.t. I.Lemma 15 Let F rectified sentence signature , let interpretation. satisfies CET , then, finite loop 0 F w.r.t. I, finiteloop F substitution maps variables object names0 = {pi ( ) | pi (t) Y, (t)I = }.Proof. Without loss generality, consider pathhp1 ( 1 ), p2 ( 2 ), . . . , pk ( k ), p1 ( 1 )i(k 1) dependency graph F w.r.t. consists vertices 0 . Since|= CET , Lemma 14, pathhp1 (u1 ), p2 (u2 ), . . . , pk (uk ), p1 (uk+1 )i170fiFirst-Order Stable Model Semantics First-Order Loop Formulasfirst-order dependency graph F substitution maps variables uiobject names (ui )I = 1 k, (uk+1 )I = 1 . Since(uk+1 )I = (u1 )I , Lemma 13, unifier uk+1 u1 that,variable x uk+1 u1 , (x)I = (x)I . Consequently,{p1 (u1 ), p2 (u2 ), . . . , pk (uk )}induces finite strongly connected subgraph (ui )I = (ui )I = .A.5 Proof Proposition 8Proposition 8 rectified formula F normal form bounded, F boundedw.r.t. interpretation.proof follows following lemma.Lemma 16 Let F rectified sentence signature normal form, letinterpretation . pathhp1 ( 1 ), p2 ( 2 ), . . . , pk ( k ), pk+1 ( k+1 )idependency graph F w.r.t I, exists pathhp1 (u1 ), p2 (u2 ), . . . , pk (uk ), pk+1 (uk+1 )ifirst-order dependency graph F substitution maps object variablesui object names (ui )I = i, u1 list object variables.Proof. proof similar proof Lemma 14 except requiresatisfy CET . Instead, existence unifier t0j jj tj+1 ensuredassumption normal form tj+1 list variables assumption t0j jjcontains none variables (due variable renaming).A.6 Proof Proposition 9Proposition 9 rectified sentence F normal form bounded, interpretation I, model{LF F (Y ) | finite first-order loop F }iff model{LF F (Y ) | finite loop F w.r.t. I}.proof follows Fact 1 following lemma.Lemma 17 rectified sentence F normal form bounded, finite loop0 F w.r.t. I, finite loop F substitution maps variablesobject names 0 = {pi ( ) | pi (t) Y, (t)I = }.171fiLee & MengProof. Let 0 finite loop F w.r.t. I. Without loss generality, pathhp1 ( 1 ), p2 ( 2 ), . . . , pk ( k ), p1 ( 1 )i(k 1) dependency graph F w.r.t. consists vertices 0 . Since Fnormal form, Lemma 16, pathhp1 (u1 ), p2 (u2 ), . . . , pk (uk ), p1 (uk+1 )i(58)first-order dependency graph F , u1 consists object variables only,substitution maps variables ui object names (ui )I =1 k, (uk+1 )I = 1 . two cases consider.Case 1: unifier u1 uk+1 maps variables u1 terms uk+1u1 = uk+1 . follows that, variable x uk+1 u1 , (x)I = (x)I .Consequently,{p1 (u1 ), p2 (u2 ), . . . , pk (uk )}induces finite strongly connected subgraph (ui )I = (ui )I = .Case 2: unifier .Consider another pathhp1 (v1 ), p2 (v2 ), . . . , pk (vk ), p1 (vk+1 )iobtained similar (58) except variables path disjointvariables (58). Clearly, unifier 0 uk+1 v1 mapsvariables v1 terms,hp1 (u1 ), p2 (u2 ), . . . , pk (uk ), p1 (v1 0 ), p2 (v2 0 ), . . . , pk (vk 0 )ianother path first-order dependency graph F . clear usingconstruction repeatedly, form infinite path visits infinitely manyvertices first-order dependency graph. contradicts assumptionF bounded.A.7 Proof Proposition 11use following lemma section next section, extends Theorem 2 work Chen et al. (2006) provides equivalent conditionsprogram finite complete set loops disjunctive program sentence.Lemma 18 (Chen et al., 2006, Thm. 2) formula F contains functionconstants positive arity, following conditions equivalent:(a) F finite complete set loops.172fiFirst-Order Stable Model Semantics First-Order Loop Formulas(b) nonnegative integer N every loop L F , numbervariables L bounded N .(c) loop L F atom A1 A2 L, variables occurring A1identical variables occurring A2 .(d) loop L Ground (F ){c1 ,c2 } (F ) c1 , c2 two new object constants,two atoms A1 A2 L A1 mentions c1 A2A1 mentions c2 A2 not.Proposition 11 rectified formula F contains function constants positivearity, F bounded iff F finite complete set loops.Proof. left right: Assume F bounded. every loop F finite.follows exists nonnegative integer N number variablesloop bounded N . Lemma 18 (b), F finite complete set loops.right left: Assume F finite complete set loops and, sakecontradiction, assume bounded. Without loss generality, infinitepathhp1 (t1 )1 , p2 (t2 )2 , . . .i(59)first-order dependency graph F visits infinitely many vertices, pi (ti )atoms occurring F substitutions.Since F finite string, contains finitely many atoms. followsatom pi (ti ) occurring F arbitrarily many substitutions atoms pi (ti )contained (59). Without loss generality, consider pathhpi (ti )i , pi+1 (ti+1 )i+1 , . . . , pi (ti )kcontained (59), k agree substituting object constants variablesti . Since ti ti k contain function constant, exists substitution 0maps variables ti k terms ti ti k 0 = ti . Consequently,{pi (xi )i 0 , pi+1 (xi+1 )i+1 0 , . . . , pi (xi )k 0 }loop F . Since length path arbitrarily large, arbitrarily manyvariables occurring loop. Lemma 18 (b), follows F finite completeset loops.A.8 Proof Proposition 10Proposition 10arity),rectified sentence F (allowing function constants positive(a) checking whether F bounded decidable;(b) checking whether F atomic-tight decidable.F contains function constants positive arity,(c) checking whether F bounded decidable;(d) checking whether F atomic-tight decidable.173fiLee & MengA.8.1 Proof Part (a) (b)show proof Part (a) first. proof repeats, minor modifications,argument proof Theorem 26 work Bonatti (2004), considersfollowing program simulate deterministic Turing machines M.t(s, L, v, [V | R], C) t(s0 , [v 0 | L], V, R, C +1)t(s, L, v, [ ], C) t(s0 , [v 0 | L], b, [ ], C +1)t(s, [V | L], v, R, C) t(s0 , L, V, [v 0 | R], C +1)t(s, [ ], v, R, C) t(s0 , [ ], b, [v 0 | R], C +1)t(s, L, v, R, C)instr.hs, v, v 0 , s0 , rightiinstr.hs, v, v 0 , s0 , rightiinstr.hs, v, v 0 , s0 , leftiinstr.hs, v, v 0 , s0 , leftifinal states s.Halting problem reduced problem checking bounded formulas.precisely, show bounded iff terminates every configuration.first establish following facts:(i) every non-terminating computation input x, correspondinginfinite path first-order dependency graph visits infinitely manyvertices;(ii) infinite path first-order dependency graph ,infinite path starting legal encoding input correspondsnon-terminating computation M.Fact (i) immediate definition : Note step counter (the lastargument t) ensures dependency graph acyclic. Then, whenever fallscycle, dependency graph contains infinite acyclic path visits infinitely manyvertices hence program bounded.Fact (ii) proven follows. Assume infinite path dependency graph. observe first argument every vertex path must legalstate third argument every vertex must legal tape value. Otherwise,outgoing edge vertices dependency graph . second,fourth fifth arguments contain variables illegal values obtainedsubstitutions variables L, R, V C. case, easily find substitutionsvariables illegal values legal values apply uniformly alongpath, obtain another infinite path starting vertex correctly encodesconfiguration thus corresponding non-terminating computation.claim follows immediately two facts: terminatecomputation, (i), unbounded. unbounded, (ii),terminate.proof works Part (b) well. step counter (the lastargument t) ensures dependency graph acyclic. Consequently, every infinitepath dependency graph visits infinitely many vertices, atomic-tight iffbounded.A.8.2 Proof Part (c)view equivalence (a) (d) Lemma 18, checking whether formulaF containing function constants positive arity finite complete set loops174fiFirst-Order Stable Model Semantics First-Order Loop Formulasdone examining finite number loops finite dependency graph,decidable. Proposition 11, follows checking whether F bounded decidable.A.8.3 Proof Part (d)sentence F function constants positive arity finite set c object constants, Ground c (F ) defined recursively. F atomic formula thenGround c (F )F . function Ground c commutes propositional connectives; quantifiers turnfinite conjunctions disjunctions object constants occurring c.Lemma 19 Let c set consisting object constants occurring F , possibly new object constant F contains object constants. F non-trivial loop iffGround c (F ) non-trivial loop.order check whether F atomic-tight, first check whether F bounded,decidable. F bounded, F atomic-tight. Otherwise, viewLemma 19, checking whether F atomic-tight checking whether Ground c (F )atomic-tight. Since F contains function constants positive arity, dependencygraph Ground c (F ) finite. decidable check whether dependency graphGround c (F ) non-trivial loop.A.9 Proof Proposition 13Lemma 20 Let F formula set atoms. predicate constant occurringoccurs strictly positively F , NES F (Y ) equivalent F .Proof. induction.Proposition 13 Let program quantifiers, F FOL-representation ,finite set atoms. assumption , formula QES (Y ) equivalentNES F (Y ). disjunctive program normal form, QES (Y ) also equivalentES (Y ) assumption .Proof. QES (Y ) NES F (Y ): NES F (Y )^x[(G H) (NES G (Y ) NES H (Y ))].(60)HGassumption F , formula (60) equivalent_x(NES G (Y ) NES H (Y )).(61)HGview Lemma 20, H contain strictly positive occurrence predicateconstant belongs , NES H (Y ) equivalent H. Also, follows Lemma 2Lemma 8 NES G (Y ) implies G. NES G (Y )NES H (Y ) conflicts assumption175fiLee & MengG H H contain strictly positive occurrence predicate constantbelongs . result, assumption F , formula (61) equivalentdisjunctionx(NES G (Y ) NES H (Y ))(62)rules H G, H contains strictly positive occurrence predicate constantbelongs . Note G H formulas every occurrenceimplication G H belongs negative formula. Lemma 4, (62) equivalentQES (Y ).QES (Y ) ES (Y ): disjunctive program, QES (Y ) disjunction^_^z B N(t 6= t0 )(p(t)6= t0 )(63)p(t)Bp(t0 )Yp(t0 )Yp(t)Arules (10) contains predicate constant occurs , zlist variables (10) . hand, ES (Y ) disjunction0z B N^_0(t 6= )p(t)Bp(t0 )Y^(p(t)06= )(64)p(t0 )Yp(t)Arules (10) contains predicate constant occurs AY 6= ,z0 list variables B, N .clear (64) implies (63). prove (63) implies (64), assumeBN^_(t 6= t0 )p(t)Bp(t0 )Y^(p(t)6= t0 )(65)p(t0 )Yp(t)Aconsider two cases.Vp(t0 )Y 6= t0 p(t) A, (65) equivalent^BN(t 6= t0 )p(t)Bp(t0 )Y_p(t)p(t)Acontradicts assumption .Otherwise, exists p(t) p(t0 ) = t0 . Since normal form,exists maps t0 , 6= . Consequently, (65) equivalentB N^p(t)Bp(t0 )Y_(t 6= t0 )p(t)AThus claim follows.(p(t)^6= t0 ) .p(t0 )Y176fiFirst-Order Stable Model Semantics First-Order Loop FormulasA.10 Proof Proposition 16Proposition 16 Let P LW-program let F FOL-representation setrules P . following conditions equivalent other:(a) answer set P according Lin Wang (2008);(b) P -interpretation satisfies SM[F ];(c) P -interpretation satisfies F loop formulas loopsF w.r.t. I.Given program , Norm() normal form Ground () ground programobtained described Lin Wang (2008). proof Proposition 16 followsfollowing lemma. refer readers work Lin Wang definitionES (, , ) defined there.Lemma21 program set ground atoms, ES Norm() (Y ) equivalentWp(c)Y ES (p(c), Y, Ground ()).Proof. definition, ES Norm() (Y )_z B N x =^(t 6= ) ,0(66)q(t)Bq(t0 )Yp(x)B,N,x=t Norm():p(x)Yx list distinct object variables, substitution maps variables xobject constants occurring , z list variables occur rulep(x) B, N , x = t. (66) equivalent_^00z B N = c(t 6= ) ,(67)p(t)B,Np(c)Yq(t)Bq(t0 )Yz0 list variables occur rule p(t) B, N . turn, (67)equivalent_^000(tg 6= ) .(68)B N d=cp(d)B 0 ,N 0 Ground()p(c)Yq(tg )B 0q(t0 )YNote cover c, exists di di mentions constantspre-interpreted functions di evaluated ci independent interpretations. case, = c equivalent . Thus (68) equivalent__^000(tg 6= ) ,(69)B N d=cp(c)Yessentiallyp(d)B 0 ,N 0 Ground()p(d) cover p(c)Wp(c)Yq(tg )B 0q(t0 )YES (p(c), Y, Ground ()).177fiLee & MengReferencesAsuncion, V., Lin, F., Zhang, Y., & Zhou, Y. (2010). Ordered completion first-orderlogic programs finite structures. AAAI, pp. 249254.Bonatti, P. A. (2004). Reasoning infinite stable models. Artificial Intelligence, 156 (1),75111.Chen, Y., Lin, F., Wang, Y., & Zhang, M. (2006). First-order loop formulas normallogic programs. Proceedings International Conference Principles KnowledgeRepresentation Reasoning (KR), pp. 298307.Chen, Y., Lin, F., Zhang, Y., & Zhou, Y. (2011). Loop-separable programs firstorder definability. Artificial Intelligence, 175 (3-4), 890913.Chen, Y., Zhang, Y., & Zhou, Y. (2010). First-order indefinability answer set programsfinite structures. AAAI, pp. 285290.Clark, K. (1978). Negation failure. Gallaire, H., & Minker, J. (Eds.), Logic DataBases, pp. 293322. Plenum Press, New York.de Bruijn, J., Pearce, D., Polleres, A., & Valverde, A. (2010). semantical frameworkhybrid knowledge bases. Knowl. Inf. Syst., 25 (1), 81104.Ferraris, P., Lee, J., & Lifschitz, V. (2006). generalization Lin-Zhao theorem.Annals Mathematics Artificial Intelligence, 47, 79101.Ferraris, P., Lee, J., & Lifschitz, V. (2007). new perspective stable models. Proceedings International Joint Conference Artificial Intelligence (IJCAI), pp. 372379.Ferraris, P., Lee, J., & Lifschitz, V. (2011). Stable models circumscription. ArtificialIntelligence, 175, 236263.Gebser, M., Lee, J., & Lierler, Y. (2006). Elementary sets logic programs. ProceedingsNational Conference Artificial Intelligence (AAAI), pp. 244249.Gebser, M., Lee, J., & Lierler, Y. (2011). elementary loops logic programs. TheoryPractice Logic Programming, appear.Gebser, M., & Schaub, T. (2005). Loops: Relevant redundant?. ProceedingsEighth International Conference Logic Programming Nonmonotonic Reasoning(LPNMR05), pp. 5365.Gelfond, M., & Lifschitz, V. (1988). stable model semantics logic programming.Kowalski, R., & Bowen, K. (Eds.), Proceedings International Logic ProgrammingConference Symposium, pp. 10701080. MIT Press.Kim, T.-W., Lee, J., & Palla, R. (2009). Circumscriptive event calculus answer set programming. Proceedings International Joint Conference Artificial Intelligence(IJCAI), pp. 823829.Kunen, K. (1987). Negation logic programming. Journal Logic Programming,4 (4), 289 308.Lee, J. (2004). Nondefinite vs. definite causal theories. Proceedings 7th Intl ConferenceLogic Programming Nonmonotonic Reasoning, pp. 141153.178fiFirst-Order Stable Model Semantics First-Order Loop FormulasLee, J. (2005). model-theoretic counterpart loop formulas. Proceedings International Joint Conference Artificial Intelligence (IJCAI), pp. 503508.Lee, J., Lierler, Y., Lifschitz, V., & Yang, F. (2010). Representing synonymity causal logiclogic programming. Proceedings International Workshop Nonmonotonic Reasoning (NMR). http://peace.eas.asu.edu/joolee/papers/syn.pdf.Lee, J., & Lifschitz, V. (2003). Loop formulas disjunctive logic programs. ProceedingsInternational Conference Logic Programming (ICLP), pp. 451465.Lee, J., Lifschitz, V., & Palla, R. (2009). Safe formulas general theory stable models.Technical Report. http://peace.eas.asu.edu/joolee/papers/safety.pdf.Lee, J., & Lin, F. (2006). Loop formulas circumscription. Artificial Intelligence, 170 (2),160185.Lee, J., & Meng, Y. (2008). loop formulas variables. Proceedings International Conference Knowledge Representation Reasoning (KR), pp. 444453.Lee, J., & Palla, R. (2011). Integrating rules ontologies first-order stable modelsemantics (preliminary report). Proceedings International Conference LogicProgramming Nonmonotonic Reasoning (LPNMR), pp. 248253.Lifschitz, V. (1994). Circumscription. Gabbay, D., Hogger, C., & Robinson, J. (Eds.),Handbook Logic AI Logic Programming, Vol. 3, pp. 298352. Oxford University Press.Lifschitz, V., Morgenstern, L., & Plaisted, D. (2008). Knowledge representation classicallogic. van Harmelen, F., Lifschitz, V., & Porter, B. (Eds.), Handbook KnowledgeRepresentation, pp. 388. Elsevier.Lin, F., & Shoham, Y. (1992). logic knowledge justified assumptions. ArtificialIntelligence, 57, 271289.Lin, F., & Wang, Y. (2008). Answer set programming functions. Brewka, G., &Lang, J. (Eds.), Proceedings International Conference Principles KnowledgeRepresentation Reasoning (KR), pp. 454465. AAAI Press.Lin, F., & Zhao, Y. (2004). ASSAT: Computing answer sets logic program SATsolvers. Artificial Intelligence, 157, 115137.Lin, F., & Zhou, Y. (2011). answer set logic programming circumscription via logicGK. Artificial Intelligence, 175, 264277.Liu, L., & Truszczynski, M. (2006). Properties applications programs monotoneconvex constraints. J. Artif. Intell. Res. (JAIR), 27, 299334.McCarthy, J. (1980). Circumscriptiona form non-monotonic reasoning. Artificial Intelligence, 13, 2739,171172.McCarthy, J. (1986). Applications circumscription formalizing common sense knowledge. Artificial Intelligence, 26 (3), 89116.Pearce, D., & Valverde, A. (2005). first order nonmonotonic extension constructivelogic. Studia Logica, 80, 323348.179fiLee & MengRobinson, J. A. (1965). machine-oriented logic based resolution principle. J. ACM,12, 2341.Sabuncu, O., & Alpaslan, F. N. (2007). Computing answer sets using model generationtheorem provers. Unpublished Draft.You, J.-H., & Liu, G. (2008). Loop formulas logic programs arbitrary constraintatoms. Proceedings AAAI Conference Artificial Intelligence (AAAI), pp.584589.Zhang, Y., & Zhou, Y. (2010). progression semantics boundedness answerset programs. Proceedings International Conference Principles KnowledgeRepresentation Reasoning (KR), pp. 518526.180fiJournal Artificial Intelligence Research 42 (2011) 393-426Submitted 04/11; published 11/11Making Decisions Using Sets Probabilities:Updating, Time Consistency, CalibrationPeter D. Grunwaldpdg@cwi.nlCWI, P.O. Box 940791090 GB Amsterdam, NetherlandsJoseph Y. Halpernhalpern@cs.cornell.eduComputer Science DepartmentCornell UniversityIthaca, NY 14853, USAAbstractconsider agent update beliefs beliefs representedset P probability distributions, given agent makes decisions using minimaxcriterion, perhaps best-studied commonly-used criterion literature.adopt game-theoretic framework, agent plays bookie, choosesdistribution P. consider two reasonable games differbookie knows makes choice. Anomalies observed before, liketime inconsistency, understood arising different games played,bookies different information. characterize important special casesoptimal decision rules according minimax criterion amount eitherconditioning simply ignoring information. Finally, consider relationshipupdating calibration uncertainty described sets probabilities.results emphasize key role rectangularity condition Epstein Schneider.1. IntroductionSuppose agent models uncertainty domain using set P probabilitydistributions. agent update P light observing random variableX takes value x? Perhaps standard answer condition distribution PX = x (more precisely, condition distributions P give X = x positiveprobability X = x), adopt resulting set conditional distributions P | X = xrepresentation uncertainty. contrast case P singleton,often clear whether conditioning right way update set P. turnsgeneral, single right way update P. Different updating methodssatisfy different desirata, sets P, desiderata satisfiedtime. paper, determine extent conditioning relatedupdate methods satisfy common decision-theoretic optimality properties. main threequestions pose are:1. conditioning right thing minimax criterion, is, leadminimax-optimal decision rules?2. minimax criterion reasonable sense satisfies consistencycriteria time consistency (defined formally below)?c2011AI Access Foundation Morgan Kaufmann Publishers. rights reserved.fiGrunwald & Halpern3. conditioning right thing calibration criterion?show answer first two questions yes P satisfies conditionEpstein Schneider (2003) call rectangularity, answer third questionyes P convex satisfies rectangularity condition.1 Thus, main contributionpaper show that, rectangularity condition, conditioning rightthing wide variety criteria. Apart main conclusion, analysisprovides new insights relation minimax optimality, time consistency,variants conditioning (such ignoring information X = x altogether).discuss contributions detail.1.1 Minimax Criterion, Dilation, Time Inconsistencyagent make decisions based set P distributions? Perhaps best-studiedcommonly-used approach literature use minimax criterion (Wald,1950; Gardenfors & Sahlin, 1982; Gilboa & Schmeidler, 1989). According minimaxcriterion, action a1 preferred action a2 worst-case expected loss a1 (withrespect probability distributions set P consideration) betterworst-case expected loss a2 . Thus, action chosen one best worstcase outcome.pointed several authors, conditioning set P observation X = xsometimes leads phenomenon called dilation (Augustin, 2003; Cozman & Walley, 2001;Herron, Seidenfeld, & Wasserman, 1997; Seidenfeld & Wasserman, 1993): agent maysubstantial knowledge random variable observing X = x,know significantly less conditioning. Walley (1991, p. 299) gives simple exampledilation: suppose fair coin tossed twice, second toss may dependarbitrary way first. (In particular, tosses might guaranteedidentical, guaranteed different.) X represents outcome first tossrepresents outcome second toss, observing X, agent believesprobability heads 1/2, observing X, agent believesprobability heads arbitrary element [0, 1].While, example others provided Walley show, dilation quitereasonable, interacts rather badly minimax criterion, leading anomalousbehavior called time inconsistency (Grunwald & Halpern, 2004; Seidenfeld,2004): minimax-optimal conditional decision rule value X observed(which form X = 0 a1 ; X = 1 a2 ; . . . ) may differentminimax-optimal decision rule conditioning. example, minimax-optimalconditional decision rule may say X = 0 a1 , minimax-optimal decisionrule conditional observing X = 0 may a2 . (See Example 2.1.) uncertaintymodeled using single distribution, time inconsistency cannot arise.1.2 Two Games understand phenomenon better, model decisionproblem game agent bookie (for recent approach similarspirit done independently, see Ozdenoren & Peck, 2008). turnsone possible game considered, depending information1. results proved assumption domain probability measures Pfinite set actions decision maker choosing among finite.394fiMaking Decisions Using Sets Probabilitiesbookie has. focus two (closely related) games here. first game, bookiechooses distribution P agent moves. show Nash equilibriumgame leads minimax decision rule. (Indeed, viewed justificationusing minimax criterion). However, game, conditioning informationalways optimal.2 second game, bookie gets choose distributionvalue X observed. Again, game, Nash equilibrium leads useminimax, conditioning right thing do.P singleton, two games coincide (since one choice bookiemake, agent knows is). surprisingly, conditioning appropriatething case. moral analysis that, uncertainty characterizedset distributions, agent making decision using minimax criterion,right decision depends game played. agent must considertrying protect adversary knows value X = x choosingdistribution one know value X = x.1.3 Rectangularity Time Consistency earlier work (Grunwald & Halpern,2004) (GH on), essentially considered first game, showed that,game, conditioning always right thing using minimax criterion.Indeed, showed sets P games minimax-optimal decision rulesimply ignore information. analysis first game lets us go beyond GHtwo ways. First, provide simple sufficient condition conditioninginformation minimax optimal (Theorem 4.4). Second, provide sufficient conditionminimax optimal ignore information (Theorem 5.1).sufficient condition guaranteeing conditioning minimax optimalviewed providing sufficient condition time consistency. condition essentiallyEpstein Schneiders (2003) rectangularity condition, showed sufficientguarantee called decision theory community dynamic consistency.Roughly speaking, dynamic consistency says if, matter agent learns,prefer decision rule decision rule 0 , prefer 0 learninganything. Dynamic consistency closely related Savages (1954) sure-thing principle.Epstein Schneider show that, agents uncertainty represented using setsprobability distributions, observations possible (in setting, meansprobability distributions agent considers possible assign positive probabilitybasic events form X = x), set distributions satisfies rectangularity condition then, matter agents loss function,3 agent prefers 0making observation, also prefer 0 making observation. Conversely, show agents preferences dynamically consistent,agents uncertainty represented set probability measures satisfiesrectangularity condition, agent viewed making decisions usingminimax criterion.results show observations possible rectangularity conditionholds, then, matter loss function, time consistency holds. Time consistency2. senses words conditioning optimal, conditioning informationalways optimal. discussed Section 7.3. work loss functions paper rather utility functions, since losses seem somewhatstandard literature. However, could trivially restate results terms utility.395fiGrunwald & Halpernholds decision minimax optimal making observation iff optimalmaking observation. Note time consistency considers optimal decision,dynamic consistency considers whole preference order. However, time consistencyiff requirement: decision optimal making observationdecision optimal making observation. way contrast, dynamicconsistency uni-directional: preferred a0 making observation,must still preferred making observation.results show uncertainty represented rectangular set measures,observations possible, minimax criterion used, dynamic consistencytime consistency hold. hand, show Proposition 4.7, generaldynamic consistency time consistency incomparable.1.4 C-conditioning Calibration stated, provide general condition Pconditioning minimax optimal, well general conditionignoring information minimax optimal. Note ignoring information alsoviewed result conditioning; conditioning information, conditioningwhole space. leads us consider generalization conditioning. Let Cpartition set values random variable X, let C(x) elementpartition contains x. Suppose observe x, condition eventX C(x). call variant conditioning C-conditioning; standard conditioningspecial case element C singleton. C-conditioning always minimaxoptimal first game? is, always optimal condition something?show considering variation Monty Hall Problem (Example 5.4),case general.Nevertheless, turns considering C-conditioning useful; underliesanalysis calibration. pointed Dawid (1982), agent updating beliefsmaking decisions basis beliefs also concernedcalibrated. Calibration usually defined terms empirical data. explainmeans connection decision making, consider agent weather forecasterlocal television station. Every night forecaster makes prediction whetherrain next day area live. assertingprobability rain p, p {0, 0.1, . . . , 0.9, 1}. interpretprobabilities? usual interpretation that, long run, daysweather forecaster predict probability p, rain approximately 100p% time.Thus, example, among days predicted 0.1, fraction daysrain close 0.1. weather forecaster property said calibrated.weather forecaster calibrated, make bets which, based probabilisticpredictions, seem favorable, long run cannot lose money.hand, weather forecaster calibrated, exist bets may seem favorableresult loss. clearly close connection calibration decisionmaking.Calibration usually defined relative empirical data singleton distributions.first consider obvious extension sets probabilities, obvious extension turnsweak requirement. therefore define stronger arguablyinteresting variation call sharp calibration. take update rule map set396fiMaking Decisions Using Sets ProbabilitiesP value x new set (P, x) probabilities. Intuitively, (P, x) resultupdating P given observation X = x, according update rule . calibrated updaterule sharply calibrated P rule 0 also calibratedthat, x, 0 (P, x) (P, x), x, inclusion strict. first showP convex, C-conditioning sharply calibrated C; different choicesP require different C. show that, P also satisfies rectangularity condition,standard conditioning sharply calibrated.1.5 Discussion idea representing uncertainty set P distributionshandling decisions worst-case optimal manner may, course, criticized.claim necessarily right best approach,worth pointing two common criticisms are, extent, unjustified.First, since may hard agent determine precise boundaries set P,argued soft boundaries appropriate. soft boundariesmay thought inducing single distribution (X Y), set probabilitydistributions X (with density Pr (X Y) proportional extentPr included set P). single distribution, setting becomesequivalent setting standard Bayesian decision theory. problemcriticism cases, hard boundaries fact natural. example,conditional probabilities may known precisely 0, case Monty Hallgame (Example 5.4). Similarly, use minimax criterion pessimisticoften thought. minimax solution often coincides Bayes-optimal solutionmaximum entropy prior (Grunwald & Dawid, 2004), commonlyassociated overly pessimistic. fact, Monty Hall problem, minimaxoptimal decision rule coincides solution usually advocated, requires makingassumptions P reduce singleton.rest paper organized follows. Section 2, define basic framework.Section 3, formally define two games described show minimaxoptimal decision rule gives Nash equilibrium. Section 4, characterize minimaxoptimal decision rule first game, bookie chooses distributionX observed. Section 5 discuss C-conditioning show that, general,minimax optimal. Section 6, discuss calibration C-conditioning. concludediscussion Section 7. proofs found appendix.2. Notation Definitionspaper, uncertainty represented set P probability distributions. easeexposition, assume throughout paper interested two random variables,X , take values spaces X Y, respectively. P always denotes setdistributions X Y; is, P (X Y), (S) denotes set probabilitydistributions S. ease exposition, assume P closed set; standardassumption literature seems quite natural applications, makesstatement results simpler (otherwise state results using closures).Pr (X Y), let PrX PrY denote marginals Pr X Y, respectively. LetPY = {PrY : Pr P}. E X Y, let P | E = {Pr | E : Pr P, Pr(E) > 0}.397fiGrunwald & HalpernPr | E (often written Pr( | E)) distribution X obtained conditioningE.represesentation uncertainty using sets probability distributions closelyrelated Walleys (1991) use (lower upper) previsions. prevision expectationfunction; is, lower prevision mapping random variables reals satisfyingcertain properties. well known (Huber, 1981) Walley calls coherent lowerprevision (a lower prevision satisfying minimal properties) identifiedlower expectation set probability measures (that is, function EE(X) = inf PrP EPr (X)). Indeed, one-to-one map lower previsionsclosed convex sets probability measures. notion conditioning usingcorresponds Walley calls regular extension lower prevision (see Walley,1991, Appendix J).2.1 Loss Functions GH, interested agent must chooseaction set A, loss action depends value randomvariable . assume paper X , Y, finite, |A| 2,always least two possible choices. (If allowed singleton,results would hold trivial reasons.)assume action value associated lossagent. (The losses negative, amounts gain.) Let L : IRloss function.loss functions arise quite naturally. example, medical setting, takeconsist possible diseases X consist symptoms. set consistspossible courses treatment doctor choose. doctors loss function dependspatients disease course treatment, symptoms. But,general, doctors choice treatment depends symptoms observed.2.3 Decision Problems Decision Settings purposes, decision settingtuple DS = (X , Y, A, P), X , Y, A, P above. decision problemcharacterized tuple DP = (X , Y, A, P, L), L loss function. is,decision problem decision setting together loss function. say decisionproblem (X , Y, A, P, L) based decision setting (X , Y, A, P).2.4 Decision Rules Given decision problem DP = (X , Y, A, P, L), supposeagent observes value variable X. observed X, must performact, quality judged according loss function L. agent must choosedecision rule determines function observations. allowdecision rules randomized. Thus, decision rule function : X (A)chooses distribution actions based agents observations. Let D(X , A)set decision rules. special case deterministic decision rule, assignsprobability 1 particular action. deterministic, sometimes abuse notationwrite (x) action assigned probability 1 distribution (x). Givendecision rule loss function L, let L random variable XPL (x, y) = aA (x)(a)L(y, a). (x)(a) stands probability performingaction according distribution (x) actions adopted x observed.Note special case deterministic decision rule, L (x, y) = L(y, (x)).398fiMaking Decisions Using Sets Probabilitiesalso extend notation randomized actions: (A), let L randomPvariable L (y) = aA (a)L(y, a).decision rule 0 priori minimax optimal decision problem DPmax EPr [L0 ] =PrPminD(X ,A)maxPrP EPr [L ].is, 0 priori minimax optimal 0 gives best worst-case expected lossrespect distributions Pr. write max instead supassumption P closed. ensures Pr P EPr [L0 ]takes maximum value.decision rule 1 posteriori minimax optimal DP if, x XPr(X = x) > 0 Pr P,maxPrP|X=xEPr [L1 ] =minmaxD(X ,A) PrP|X=xEPr [L ].(1)get posteriori minimax-optimal decision rule obvious thing: xobserved, simply condition probability distribution Pr P X = x, chooseaction gives least expected loss (in worst case) respect P | X = x.Since distributions Pr mentioned (1) satisfy Pr(X = x) = 1, minimumD(X , A) depend values (x0 ) x0 6= x; minimum effectivelyrandomized actions rather decision rules.following example, taken GH, shows, priori minimax-optimal decisionrules general different posteriori minimax-optimal decision rules.Example 2.1: Suppose X = = = {0, 1} P = {Pr (X Y) : PrY (Y =1) = 2/3}. Thus, P consists distributions whose marginal gives = 1 probability2/3. think actions predictions value . loss function 0right value predicted 1 otherwise; is, L(i, j) = |i j|. so-called0/1 classification loss. easy see optimal priori decision rule choose1 matter observed (which expected loss 1/3). Intuitively, observing valueX tells us nothing value , best decision predict accordingprior probability = 1. However, probabilities = 1 compatibleobserving either X = 0 X = 1. is, (P | X = 0)Y (P | X = 1)Y consistdistributions Y. Thus, minimax optimal posteriori decision rule randomizes(with equal probability) = 0 = 1.summarize, make decisions according minimax optimality criterion,making observation, predict = 1. However, matter observation make, making observation, randomize (with equal probability)predicting = 0 = 1. Moreover, know even making observation opinion best decision rule change way. (Noteexample time inconsistency dynamic inconsistency.)2.5 Time Dynamic Consistency Formally, decision problem DP time consistent iff, decision rules , priori minimax optimal DP iff posterioriminimax optimal. say DP weakly time consistent every posteriori minimaxoptimal rule DP also priori minimax optimal DP . decision setting DS(weakly) time consistent every decision problem based DS is.399fiGrunwald & HalpernFollowing Epstein Schneider (2003), say decision problem DP dynamically consistent every pair , 0 decision rules, following conditions hold:1. If, x Pr(X = x) > 0 Pr P,maxPr(P|X=x)EPr [L ]maxPr(P|X=x)EPr [L0 ],(2)max EPr [L ] max EPr [L0 ].PrPPrP(3)2. If, x Pr(X = x) > 0 Pr P, strict inequality(2), (3) must hold strict inequality well.Informally, dynamic consistency means whenever preferred 0 accordingminimax criterion posteriori, also preferred 0 according minimaxcriterion priori, whenever posteriori preference strict possibleobservations, priori preference must strict well.decision setting DS dynamically consistent every decision problem based DSis.3. Two Game-Theoretic Interpretations Pmean agents uncertainty characterized set P probabilitydistributions? understand P? give P game-theoretic interpretationhere: namely, adversary gets choose distribution set P.4completely specify game. must also specify adversary makes choice.consider two times adversary choose: first agents observesvalue X , second after. formalize two different games,take adversary bookie.call first game P-game. defined follows:1. bookie chooses distribution Pr P.2. value x X chosen (by nature) according PrX observed bookieagent.3. agent chooses action A.4. value chosen according Pr | X = x.5. agents loss L(y, a); bookies loss L(y, a).zero-sum game; agents loss bookies gain. game, agentsstrategy decision rule, is, function gives distribution actionsobserved value X. bookies strategy distribution distributions P.consider second interpretation P, characterized different gamegives bookie power. Rather choosing distribution observingvalue X, bookie gets choose distribution observing value. callP-X-game. Formally, specified follows:4. interpretation remains meaningful several practical situations explicit adversary;see final paragraph section.400fiMaking Decisions Using Sets Probabilities1. value x X chosen (by nature) according procedure guaranteedend value x Pr(X = x) > 0 Pr P, observedbookie agent.52. bookie chooses distribution Pr P Pr(X = x) > 0.63. agent chooses action A.4. value chosen according Pr | X = x.5. agents loss L(y, a); bookies loss L(y, a).Recall pair strategies (S1 , S2 ) Nash equilibrium neither partybetter unilaterally changing strategies. If, case, (S1 , S2 ) Nash equilibriumzero-sum game, also known saddle point; S1 must minimax strategy,S2 must maximin strategy (Grunwald & Dawid, 2004). following results show,agent must using priori minimax-optimal decision rule Nash equilibriumP-game, posteriori minimax-optimal decision rule Nash equilibriumP-X-game. viewed justification using (a priori posteriori)minimax-optimal decision rules.Theorem 3.1: Fix X , Y, A, L, P (X Y).(a) P-game Nash equilibrium ( , ), distribution Pfinite support.(b) ( , ) Nash equilibrium P-game finite support,(i) every distribution Pr0 P support ,EPr0 [L ] = maxPrP EPr [L ];(ii) Pr = PrP, (Pr)>0 (Pr) Pr (i.e., Pr convex combinationdistributions support , weighted probability according ),PEPr [L ] ====minD(X ,A) EPr [L ]maxPrP minD(X ,A) EPr [L ]minD(X ,A) maxPrP EPr [L ]maxPrP EPr [L ].nature chosen value X P-X-game, regard steps 25P-X-game game bookie agent, bookies strategy characterized distribution P | X = x agents characterized distributionactions. call P-x-game.Theorem 3.2: Fix X , Y, A, L, P (X Y).5. x observed parties, chosen x chosen, procedure naturechooses x irrelevant. could assume definiteness nature chooses uniformly random amongvalues x Pr(x) > 0 Pr P, choice would work equally well.6. consider conditional probability distributions (de Finetti, 1936; Popper, 1968),Pr(Y = | X = x) defined even Pr(X = x) = 0, could drop restriction x chosenPr(X = x) > 0 Pr P.401fiGrunwald & Halpern(a) P-x-game Nash equilibrium ( , (x)), distributionP | X = x finite support.(b) ( , (x)) Nash equilibrium P-x-game finite support,(i) Pr0 support , EPr0 [L ] = maxPrP|X=x EPr [L ];P(ii) Pr = PrP, (Pr)>0 (Pr) Pr,EPr [L ] ====minD(X ,A) EPr [L ]maxPrP|X=x minD(X ,A) EPr [L ]minD(X ,A) maxPrP|X=x EPr [L ]maxPrP|X=x EPr [L ].Since distributions Pr expression minD(X ,A) maxPrP|X=x EPr [L ] part (b)(ii)P | X = x, (1), minimum effectively randomized actions ratherdecision rules.Theorems 3.1 3.2 viewed although, according definition,time inconsistency, viewed properly, real inconsistency here; rather,must careful game played. P-game played,right strategy priori minimax-optimal strategy, valueX observed; similarly, P-X-game played, right strategyposteriori minimax-optimal strategy, value X observed.Indeed, thinking terms games explains apparent time inconsistency.games, agent gains information observing X = x. P-X game,bookie. information may use bookie agent, so,game, agent worse given opportunity learn value X.course, practical situations, agents (robots, statisticians,. . . ) reallyconfronted bookie tries make suffer. Rather, agents mayidea distribution holds, except set P. knowP, decide prepare worst-case play minimax strategy.fact minimax strategy interpreted terms Nash equilibriumgame helps understand differences different forms minimax (suchpriori posteriori minimax). point view, seems strange bookiechoose different distributions P according distribution . However,P convex, replace distribution P single distribution P,consists convex combination distributions support ;distribution Pr Theorems 3.1 3.2. Thus, Theorems 3.1 3.2 hold bookierestricted deterministic strategy.4. Conditioning, Rectangularity, Time Consistencyget posteriori minimax-optimal decision rule obvious thing: xobserved, simply condition probability distribution Pr P X = x, chooseaction gives least expected loss (in worst case) respect P | X = x.might expect priori minimax-optimal decision rulething. is, decision rule says, x observed, choose402fiMaking Decisions Using Sets Probabilitiesaction gives best result (in worst case) respect P | X = x.Example 2.1 shows cannot true general, since cases priorioptimal decision rule condition, ignore observed value X,choose action gives least expected loss (in worst case) respect P,matter value X has. later show cases optimal priorirule neither condition ignore (see Example 5.4). goal sectionshow rectangularity condition Epstein Schneider (2003) suffices guaranteeconditioning optimal.Definition 4.1: Let hPi, hull P, set{Pr (X Y) : PrX PX and, Pr(X = x) 6= 0, (Pr | X = x) (P | X = x)} .Thus, hPi consists distributions Pr whose marginal X marginal Xdistribution P whose conditional observing X = x conditionaldistribution P, x X . Clearly P hPi, converse necessarilytrue, following example shows.Example 4.2: Suppose X = = {0, 1}, Pr1 , Pr2 , Pr3 (X Y) definedfollows:Pr1 (0, 0) = Pr1 (1, 0) = 1/3; Pr1 (0, 1) = Pr1 (1, 1) = 1/6;Pr2 (0, 0) = Pr2 (1, 0) = 1/6; Pr2 (0, 1) = Pr2 (1, 1) = 1/3;Pr3 (0, 0) = Pr3 (1, 1) = 1/3; Pr3 (0, 1) = Pr3 (1, 0) = 1/6.Suppose P = {Pr1 , Pr2 }. Pr3 6 P, easy see Pr3 hPi.(Pr1 )X = (Pr2 )X = (Pr3 )X uniform distribution X , Pr3 | (X = 0) = Pr1 | (X = 0),Pr3 | (X = 1) = Pr2 | (X = 1).Note also P Example 2.1, hPi = (X Y) 6= P. notionhull arises number contexts. language Walley (1991), hullP natural extension marginals PX collection sets conditionalprobabilities P | X = x x X . Thus, P = hPi, reconstruct jointprobability distributions P PX collection sets conditional probabilities.assumption P = hPi closely related set probabilities separatelyspecified, introduced da Rocha Cozman (2002). da Rocha Cozman pointout, assumption makes possible apply ideas Bayesian networks uncertaintyrepresented sets probability distributions.condition P = hPi instance rectangularity condition goes backleast work Sarin Wakker (1998). introduced general formEpstein Schneider (2003). Epstein Schneider define condition sequencerandom variables X1 , . . . , Xt , support Xj necessarily finite.special case = 2, X := X1 := X2 restricted finite support,rectangularity condition exactly equivalent condition P = hPi.403fiGrunwald & HalpernConsidering hPi also gives insight two games considered Section 3. P-X -game, bookie power P-game, since getschoose distribution agent observes x P-X -game, must chooseagent observes x P-game. means agent draw inferencesdistribution bookie chose P-game. inferences cannotdrawn P = hPi. generally, precise sense, agent informationP-X -game hPi-game. Rather making formal (sincesomewhat tangential main concerns), give example show intuition.Example 4.3: Suppose X = = {0, 1}, P = {Pr1 , Pr2 },Pr1 (0, 0) = (1 ), Pr1 (0, 1) = (1 )2 , Pr1 (1, 0) = (1 ), Pr1 (1, 1) = 2 ;Pr2 (0, 0) = (1 ), Pr2 (0, 1) = 2 , Pr2 (1, 0) = (1 ), Pr2 (1, 1) = (1 )2 .P-game, agent observes X = 0, almost certainbookie chose Pr1 , thus almost certain = 1. hand, PX-game, agent observes x, idea whether bookie choose Pr1Pr2 (since bookie makes choice observing x), idea whether0 1. Note P 6= hPi; particular, distribution Pr3 hPi(Pr3 )X = (Pr1 )X (Pr3 ) | (X = 0) = (Pr2 ) | (X = 0). example, take Pr3Pr3 (0, 0) = (1 )2 Pr3 (0, 1) = (1 ) (the values Pr3 (1, 0) Pr3 (1, 1)irrelevant, long sum nonnegative). Thus, observingX = 0 hPi game, agent would idea valueP-X game.key point us P = hPi, conditioning optimal, followingtheorem shows. first need definition. call P conservative Pr Px X , Pr(X = x) > 0.7Theorem 4.4: Given decision setting DS = (X , Y, A, P) P = hPi,decision problems DP based DS, exists priori minimax-optimal rulealso posteriori minimax optimal. Indeed, every posteriori minimax-optimal rulealso priori minimax optimal, DS DP weakly time consistent. Moreover, Pconservative, every decision problem DP based DS, every priori minimaxoptimal rule also posteriori minimax optimal, DS DP time consistent.raises question whether qualification exists Theorem 4.4necessary, whether converse theorem also holds. Example 4.5 showsanswer first question yes; Example 4.6 shows answer secondquestion no.Example 4.5 : x X , exist Pr, Pr0 P Pr(X = x) = 0Pr0 (X = x) > 0, may priori minimax decision ruleposteriori minimax. example, consider decision problem DP = (X , Y, A, P, L)7. notion conservative corresponds Epstein Schneider (2003) call full support condition.404fiMaking Decisions Using Sets ProbabilitiesX = {0, 1}, = = {0, 1, 2}, L classification loss (Example 2.1) P = {Pr1 , Pr2 }.first define Pr1 :Pr1 (X = 1) = 1/2,Pr1 (Y = 0 | X = 0) = Pr1 (Y = 1 | X = 0) = Pr1 (Y = 2 | X = 0) = 1/3,Pr1 (Y = 0 | X = 1) = 1/2,Pr1 (Y = 1 | X = 1) = 2/5,Pr1 (Y = 2 | X = 1) = 1/10.Pr2 defined follows: Pr2 (X = 0) = 1, j Y, Pr2 (Y = j, X = 0) = Pr2 (Y =j | X = 0) := Pr1 (Y = j | X = 0). easy see P = hPi, rectangularitycondition holds.Note (0), decision taken observing X = 0, affect expectedloss; Pr1 | X = 0 Pr2 | X = 0, uniform, expected loss 2/3, regardless (0). implies every decision rule (1) randomized combination{0, 1} priori optimal, worst-case expected loss 2/3, since EPr2 [L ] = 2/3EPr1 [L ] < 2/3. minimax optimal rules (1) = 1 posteriori optimal,since player observes X = 1, knows distribution Pr1 , minimaxloss relative Pr1 1/2 action 0 3/5 action 1.example Example 4.3, observing particular value X givesinformation distribution P bookie chosen. Example 4.3, observingX = 0 implies bookie almost certainly chose Pr1 P-game; presentexample, observing X = 1 implies bookie certainly chose Pr1 P-gameP X game. note, however, observing X = x give informationdistribution chosen bookie P X game exist Pr Pr0P-game Pr(X = x) = 0 Pr0 (X = x) > 0. Pr Pr0 exists,bookie completely free choose Pr P likes x observed,observing x gives information Pr P chosen.exist decision settings P conservative P 6= hPi, although stillweak time consistency. Hence, converse Theorem 4.4 hold general.give example P.Example 4.6: Let X = = = {0, 1} P = {Pr0 , Pr1 } Pr0 (X = 1) = Pr1 (X =1) = 1/2 x {0, 1}, Pr0 (Y = 0 | X = x) = 1 Pr1 (Y = 1 | X = x) = 1. ClearlyP conservative P 6= hPi; example, distribution Pr3 Pr3 (X = 1) =1/2, Pr3 (Y = 0 | X = 0) = 1, Pr3 (Y = 0 | X = 1) = 0 hPi P. Note Xindependent respect Pr0 Pr1 . take arbitrary loss functionL. Since (Pr | X = x)Y contains two distributions, one Pr(Y = 1) = 0 onePr(Y = 1) = 1, minimax posteriori act play (0) = (1) = (1 ) 0 + 1(i.e., act plays 0 probability 1 1 probability ),chosen minimize f () = max{(1 )L(0, 0) + L(0, 1), (1 )L(1, 0) + L(1, 1)}.simplicity, assume unique . (If not, must case[0, 1] minimize expression, easy check L(0, 0) = L(0, 1) = L(1, 0) =L(1, 1), time consistency holds trivially.)405fiGrunwald & Halpernwant show also priori minimax. easy checkmaxPr{Pr0 ,Pr1 }L = f ( ),f above. suffices show decision rule 0 , mustmaxPr{Pr0 ,Pr1 }L0 f ( ),Suppose (x) = (1 x ) 0 + x 1, x {0, 1}.maxPr{Pr0 ,Pr1 } EP r [L0 ]= max{ 21 ((1 0 )L(0, 0) + 0 L(0, 1) + (1 1 )L(0, 0) + 1 L(0, 1)),12 ((1 0 )L(1, 0) + 0 L(1, 1) + (1 1 )L(1, 0) + 1 L(1, 1)}= max{(1 )L(0, 0) + L(0, 1), (1 )L(1, 0) + L(1, 1)}, == f () f ( ).0 +12interesting compare Theorem 4.4 results Epstein Schneider(2003). this, first compare notion time consistency notiondynamic consistency. notions formally defined end Section 2.results summarized Proposition 4.7. First need two definitions: Let P setdistributions X Y. decision problem based P form (X , Y, A, P, L)arbitrary L. decision problem satisfies strong dynamic consistencysatisfies condition (2) definition dynamic consistency satisfies followingstrengthening (3):If, x Pr(X = x) > 0 Pr P, (2) holds, xPr(X = x) > 0,maxPr(P|X=x)EPr [L ] <maxPr(P|X=x)EPr [L0 ],(4)(3) must hold strict inequality.Proposition 4.7:(a) Every dynamically consistent decision problem also weakly time consistent.(b) every dynamically consistent decision problem time consistent.(c) Every strongly dynamically consistent decision problem time consistent.(d) exist weakly time consistent decision problems dynamically consistent.(e) decision problems based P dynamically consistent decisionproblems based P weakly time consistent.406fiMaking Decisions Using Sets ProbabilitiesProposition 4.7(c) shows comparison time consistency dynamic consistency subtle: replacing x x second half definitiondynamic consistency, leads perfectly reasonable requirement, suffices forcetime consistency. Proposition 4.7(e) leads us suspect decision setting weaklytime consistent dynamically consistent. have, however, proofclaim. proof part (e) involves two decision problems based set P,different sets actions, decision problems baseddecision setting. seem straightforward extend result decision settings.Epstein Schneider show, among things, P closed, convex, conservative, rectangular, DS dynamically consistent, hence weakly timeconsistent. remark convexity assumption needed result. easycheck prefered 0 respect P according minimax criterion iffpreferred 0 respect convex closure P according minimax criterion. Proposition 4.7 shows dynamic time consistency closely related. Yet,clear overlap prove Theorem 4.4 Epstein-Schneider(ES on) result, general results incomparable. example,already prove weak time consistency without assuming conservativeness; ES assume conservativeness throughout. hand, ES also show dynamic consistencyholds, agents actions viewed minimax optimal actions relativerectangular convex conservative set; analogous result time consistency.Moreover, contrast ES result, results hold restricted settingtwo time steps, one one making single observation.5. Belief Updates C-conditioningsection define notion belief update rule, belief representedsets probabilities, introduce natural family belief update rules callC-conditioning.motivate notions, recall Example 2.1 shows minimax-optimalpriori decision rule always minimax-optimal posteriori decisionrule. example, minimax-optimal priori decision rule ignores informationobserved. Formally, rule ignores information (x) = (x0 ) x, x0 X .ignores information, define L0 random variable L0 (y) = L (x, y)choice x. well defined, since L (x, y) = L (x0 , y) x, x0 X .following theorem provides general sufficient condition ignoring informationoptimal.Theorem 5.1 : Fix X , Y, L, A, P (X Y). If, PrY PY , P contains distribution Pr0 X independent Pr0 , Pr0Y = PrY ,priori minimax-optimal decision rule ignores information.conditions, priori minimax-optimal decision rule ignores information,essentially optimizes respect marginal ; is, maxPrP EPr [L ] =maxPrY PY EPrY [L0 ].407fiGrunwald & HalpernGH focused case PY singleton (i.e., marginal probabilitydistributions P) x, PY (P | X = x)Y . immediateTheorem 5.1 ignoring information priori minimax optimal case.Standard conditioning ignoring information instances C-conditioning,turn instance update rule. define notions formally.Definition 5.2: belief update rule (or update rule) function : 2(X Y) X2(X Y) {} mapping set P distributions observation x nonempty set(P, x) distributions; intuitively, (P, x) result updating P observationx.case P singleton {Pr}, one update rule conditioning; is,({Pr}, x) = {Pr( | X = x)}. update rules possible, even singledistribution; example, Lewis (1976) considered approach updating calledimaging. even scope considering sets probabilities; example,Walleys (1991) natural extension regular extension provide update rules (assaid, notion conditioning viewed instance Walleys regular extension).Simply ignoring information provides another update rule: (P, x) = P. said above,ignoring information standard conditioning instances C-conditioning.Definition 5.3: Let C = {X1 , . . . , Xk } partition X ; is, Xi 6= = 1, . . . , k;X1 . . . Xk = X ; Xi Xj = 6= j. x X , let C(x) cell containing x;is, unique element Xi C x Xi . C-conditioning belief update rulefunction defined taking (P, x) = P | C(x) (if Pr P, Pr(C(x)) = 0,(P, x) undefined). decision rule based C-conditioning amountsfirst updating set P P | C(x), taking minimax-optimal distributionactions relative (P | C(x))Y . Formally, based C-conditioning if, x XPr(X = x) > 0 Pr P,maxPr(P|XC(x))YEPr [L(x) ] = minmax(A) Pr(P|XC(x))YEPr [L ].Standard conditioning special case C-conditioning, take C consistsingletons; ignoring information also based C-conditioning, C = {X }.earlier results suggest perhaps priori minimax-optimal decision rule must basedC-conditioning C. Monty Hall problem shows conjecturefalse.Example 5.4 : [Monty Hall] (Mosteller, 1965; vos Savant, 1990): startoriginal Monty Hall problem, consider variant it. Suppose youregame show given choice three doors. Behind one car; behind othersgoats. pick door 1. opening door 1, Monty Hall, host (who knowsbehind door) opens one two doors, say, door 3, goat.asks still want take whats behind door 1, take whats behind door 2instead. switch? may assume initially, car equally likelybehind doors.408fiMaking Decisions Using Sets Probabilitiesformalize well-known problem P-game, follows: = {1, 2, 3} representsdoor car behind. X = {G2 , G3 }, where, j {2, 3}, Gj correspondsquizmaster showing goat behind door j. = {1, 2, 3}, actioncorresponds door finally choose, Monty opened door 2 3.loss function classification loss, L(i, j) = 1 6= j, is, choosedoor goat behind it, L(i, j) = 0 = j, is, choose doorcar. P set distributions Pr X satisfyingPrY (Y = 1) = PrY (Y = 2) = PrY (Y = 3) = 13Pr(Y = 2 | X = G2 ) = Pr(Y = 3 | X = G3 ) = 0.Note P satisfy rectangularity condition. example, let Prdistribution Pr (G2 , 1) = Pr (G2 , 3) = 1/3 Pr (G3 , 1) = Pr (G3 , 2) = 1/6.easy see Pr hPi P.well known, easy show, priori minimax-optimal strategy alwaysswitch doors, matter whether Monty opens door 2 door 3. Formally, letdecision rule (G2 ) = 3 (G3 ) = 2. unique priori minimaxoptimal decision rule (and expected loss 1/3). rule also posteriori minimaxoptimal. modify problem small cost, say > 0, associatedswitching. cost associated switching door 2 switchingdoor 3. long sufficiently small, action always switching still uniquelypriori minimax optimal. However, based C-conditioning. existtwo partitions X . corresponding two update rules based C-conditioning amountto, respectively, (1) ignoring X, (2) conditioning X standard way. decisionrule based ignoring information stick door 1, cost associatedswitching. decision rule based conditioning switch doors probability1/(2 + ). see this, consider observation X = G2 , let randomized actionswitching door 3 probability q sticking door 1 probability 1 q. Letm(q) = maxPr(P|X=G2 )Y EP r [L ]. Thus, m(q) = maxp[0,1/2] (qp(1 + ) + (1 q)(1 p)).Again, compute m(q), need consider happens extremesinterval; is, p = 0 p = 1/2, m(q) = max(1 q, (1 + q)/2). Clearly m(q)minimized 1 q = (1 + q)/2, is, q = 1/(2 + ). similar analysis appliesobservation X = G3 . Thus, neither decision rules based conditioningminimax optimal.Although C-conditioning guarantee minimax optimality, turns usefulnotion. show next section, quite relevant consider calibration.6. Calibrationsaid introduction, Dawid (1982) pointed agent updatingbeliefs want calibrated. section, consider effect requiring calibration. now, calibration considered uncertainty characterizedsingle distribution. generalize notion calibration setting,uncertainty characterized set distributions. investigate connection409fiGrunwald & Halperncalibration conditions considered earlier, specificallyconditions P convex P = hPi.8Calibration typically defined respect empirical data. view set Pdistributions describing empirical data, defining agents uncertaintyregarding true distribution. want define calibration setting.case P singleton, already done, example, Vovk, Gammerman,Shafer (2005). 9 Below, first define calibration case P singleton,extend notion general P.Let update rule ({Pr}, x) contains single distributionx X (for example, could ordinary conditioning). Given x X , define[x],P = {x0 : ((P, x0 ))Y = (P, x)Y }. Thus, [x],P consists values x0 that,observed, lead updated marginal distributions x.Definition 6.1 : update rule calibrated relative Pr if, x X ,Pr([x],{Pr} ) 6= 0, Pr( | [x],{Pr} )Y = ({Pr}, x)Y .10words, definition says Pr0 distribution results updatingPr observing x according marginalizing Y, calibrated Pr0also marginal distribution results conditioning Pr set values x0 that,observed, result Pr0 marginal distribution according . Intuitively,x may observed, agent uses produces distribution ({Pr}, x).agent may make decisions predictions based distribution,marginalized Y. consider set P 0 distributions agent may usepredict observing value X. is, Pr0 P 0 iff positive Pr-probabilityagent, observing value X, uses Pr0 predict . set P 0|X | elements. Definition 6.1 says that, Pr0 P 0 , whenever agent predictsPr0 , agent correct sense distribution given agentuses Pr0 indeed Pr0 . Note Definition 6.1, subsequent definitionssection, marginalize Y. discuss end section.straightforward generalize Definition 6.1 sets P probability distributionssingletons, update rules map sets probabilities.Definition 6.2: update rule calibrated relative P if, x X , Pr([x],P ) 6=0 Pr P, (P | [x],P )Y = (P, x)Y .want relate calibration C-conditioning. following result first stepdirection. gives conditions standard conditioning calibrated, alsoshows that, convex P arbitrary C, C-conditioning satisfies one two inclusionsrequired Definition 6.2.8. Recall convexity innocuous assumption context time dynamic consistency.However, show section, far innocuous context calibration.9. Vovk et al.s setting somewhat different ours, interested upper boundson, rather precise values of, probabilities. result, definition validity (as callnotion calibration) somewhat different Definition 6.1, underlying idea same.found definition literature coincides ours.10. usual, X , identify P | P | (A Y).410fiMaking Decisions Using Sets ProbabilitiesTheorem 6.3:(a) C-conditioning partition C X P convex then, x X ,(P | [x],P )Y (P, x)Y .(b) standard conditioning, P = hPi, x X , (P, x)Y (P | [x],P )Y .Corollary 6.4 : P convex P = hPi, standard conditioning calibratedrelative P.corollary significantly strengthened Theorem 6.12 below. general,convexity P = hPi condition necessary Corollary 6.4, following twoexamples show.Example 6.5: Let X = = {0, 1}, let P = {Pr1 , Pr2 , Pr3 , Pr4 }, Pr1 , . . . , Pr4defined sequence four numbers (a, b, c, d), Pri (0, 0) = a, Pri (0, 1) = b,Pri (1, 0) = c, Pri (1, 1) = d):Pr1 = (1/4, 1/4, 1/4, 1/4),Pr2 = (1/8, 3/8, 1/8, 3/8),Pr3 = (1/4, 1/4, 1/8, 3/8),Pr4 = (1/8, 3/8, 1/4, 1/4).Clearly P convex. Note Pr1 (Y = 0 | X = 0) = Pr1 (Y = 0 | X = 1) =1/2, Pr2 (Y = 0 | X = 0) = Pr2 (Y = 0 | X = 1) = 1/4, Pr3 (Y = 0 | X = 0) = 1/2,Pr3 (Y = 0 | X = 1) = 1/4. Since, Pr P, Pr(X = 0) = 1/2, (P | X = 0)Y =(P | X = 1)Y = {Pra , Prb } Pra (Y = 0) = 1/2 Prb (Y = 0) = 1/4,P = hPi. show standard conditioning calibrated relative P. Letstand standard conditioning. x {0, 1},(P, x)Y = (P | X = x)Y = {Pr01 , Pr02 },(5)Pr01 (Y = 0) = 1/2 Pr02 (Y = 0) = 1/4. also follows that, x {0, 1},[x],P = {0, 1} = X ,(P | [x],P )Y = PY .(6)Since PY contains distribution Pr03 Pr03 (Y = 0) = 3/8, (5) (6) together showcalibrated.Example 6.6: Let X = = {0, 1}, let P consist distributions XPr(Y = 1) = 0.5. Clearly P convex. However, P =6 hPi. see this, note P containsdistribution Pr Pr(Y = 0 | X = 0) = 1 distribution Pr0 Pr0 (X = 0) = 1,distribution Pr00 Pr00 (X = 0) = 1 Pr00 (Y = 0 | X = 0) = 1. Let standstandard conditioning. show calibrated. x {0, 1},(P, x)Y = (P | X = x)Y = (Y),411(7)fiGrunwald & Halpernis, conditioning X = 0 X = 1 leads set distributionsY. follows that, x {0, 1}, [x],P = {0, 1} = X ,(P | [x],P )Y = PY = {Pr (Y) | Pr(Y = 1) = 0.5}.(8)Together, (7) (8) show calibrated.Corollary 6.4 gives conditions standard conditioning calibrated. Theorem 6.3(a) gives general conditions C-conditioning satisfies one inclusion required calibration; specifically, (P | [x],P )Y (P, x)Y . Rather trying findconditions inclusion holds, consider strengthening calibration, arguably interesting notion. For, following example shows,calibration arguably weak requirement.Example 6.7: Let X = = {0, 1}, let P = {Pr} consist distributions Xsatisfying Pr(Y = X) = 1. rule ignores X, is, (P, x) = Px {0, 1}, calibrated, even though (a) outputs distributions Y, (b)exists another calibrated rule (standard conditioning) that, upon observing X = x, outputsone distribution Y.Intuitively, fewer distributions P, information P contains.Thus, want restrict sets P small possible, stillcalibrated.Definition 6.8: Update rule 0 narrower update rule relative P if,x X , 0 (P, x)Y (P, x)Y . 0 strictly narrower relative P inclusion strictx. sharply calibrated exists update rule 0 strictly narroweralso calibrated.show P convex, every sharply calibrated update rule must involveC-conditioning. make precise, need following definition.Definition 6.9: generalized conditioning update rule if, convex P, existspartition C (that may depend P) x X , (P, x) = P | C(x).Note that, long P convex, generalized conditioning rule, conditionpartition X , partition may depend set P. example, convexP, rule may ignore value x, whereas convex P, may amountordinary conditioning. Since interested generalized conditioning rulesP convex, behavior nonconvex P irrelevant. Indeed, next result shows that,require P convex (and require P = hPi), C-conditioningcalibrated, indeed, sharply calibrated, C; moreover, every sharply calibratedupdate rule must generalized conditioning rule.Theorem 6.10: Suppose P convex.(a) C-conditioning sharply calibrated relative P partition C.412fiMaking Decisions Using Sets Probabilities(b) sharply calibrated relative P, exists C equivalent C-conditioning P (i.e., (P, x) = | C(x) x X ).Corollary 6.11: exists generalized conditioning update rule sharply calibrated relative convex P. Moreover, every update rule sharply calibrated relativeconvex P generalized conditioning update rule relative set convex P.Theorem 6.10 establishes connection sharp calibration C-conditioning.show conditions make standard conditioning calibrated also makesharply calibrated.Theorem 6.12: P convex P = hPi, standard conditioning sharply calibrated relative P.result shows P = hPi condition Theorem 6.12 relevantensuring time consistency, also ensuring well-behavedness conditioningterms calibration. Note, however, result says nothing C-conditioningarbitrary partitions C. general, C-conditioning may sharply calibrated relativeconvex P P = hPi, relative others. example, P singleton,convex, P = hPi, update rule ignores x sharply calibrated.Example 6.7, P also convex P = hPi, yet ignoring x sharply calibrated.Remark results section based definition calibrationupdated set distributions (P, x) marginalized Y. also possible definecalibration without marginalization. However, found makes lessinteresting notion. example, without marginalizing longer seemsstraightforward way defining sharp calibration, without sharpness, notionquite limited interest. Moreover, seem possible state prove analogueTheorem 6.3 (at least, know it).7. Discussion Related Workexamined update uncertainty represented set probability distributions, motivate updating rules terms minimax criterion. keyinnovation show different approaches understood termsgame bookie agent, bookie picks distribution setagent chooses action making observation. Different approaches updating arise depending whether bookies choice made observation.believe game-theoretic approach prove useful generally understanding different approaches updating. fact, publication conferenceversion paper, learned Ozdenoren Peck (2008) use typeapproach analyzing dynamic situations related Ellsberg (1961) paradox. Like us,Ozdenoren Peck resolve apparent time inconsistency describing decision problemgame agent bookie (called malevolent nature them).do, point different games lead different Nash equilibria, hence differentminimax optimal strategies agent. particular, although precise definitions413fiGrunwald & Halperndiffer, game 1 similar spirit P-game, game 3 spiritP-X-game.(as well Ozdenoren Peck, 2008) prove results assumptionsset possible values X finite, set actions. wouldinterest extend results case sets infinite. extensionseems completely straightforward case set values set actionscountable, consider bounded loss functions (i.e. supyY,aA |L(y, a)| < ).Indeed, believe results go without change case, althoughchecked details. However, allow uncountable set values,subtleties arise. example, P-X game, required nature choose valuex given positive probability Pr P. may xset possible values X interval [0, 1]; measures P may assignindividual points probability 0.conclude paper giving overview senses conditioningoptimal senses not, uncertainty represented setdistributions. established conditioning full set P X = x minimaxoptimal P-x-game, P-game. minimax-optimal decision ruleP-game often instance C-conditioning, generalization conditioning.Monty Hall problem showed, however, always case. hand,instead minimax criterion, insist update rules sharply calibrated,P convex, C-conditioning always right thing all. While, general,C may depend P (Theorem 6.10), P = hPi, take C(x) = {x}, standardconditioning right thing (Theorem 6.12).two senses conditioning right thing do. First, Walley(1991) shows that, sense, conditioning updating rule coherent,according notion coherence. justifies coherence decision theoretically,using minimax criterion. Note minimax criterion puts total orderdecision rules. is, say least good 0max EPr [L ] max EPr [L0 ].PrPPrPway contrast, Walley (1991) puts partial preorder11 decision rules takingleast good 0max EPr [L L0 ] 0.PrPSince maxPrP EPr [L L0 ] maxPrP EPr [L0 L ] may positive, indeedpartial order. use ordering determine optimal decision rule then,Walley shows, conditioning right thing do.Second, paper, interpreted conditioning conditioning full given setdistributions P. conditioning always priori minimax optimal strategyobservation X = x. Alternatively, could first somehow select single Pr P,condition Pr observed X = x, take optimal action relative Pr | X = x.follows Theorem 3.1 minimax-optimal decision rule P-game11. partial order reflexive, transitive, anti-symmetric, x x y, mustx = y. partial preorder reflexive transitive.414fiMaking Decisions Using Sets Probabilitiesunderstood way. defines optimal response distribution Pr (X Y)defined Theorem 3.1(b)(ii). P convex, Pr P. sense, minimaxoptimal decision rule always viewed instance conditioning, singlespecial Pr depends loss function L rather full set P.worth noting Grove Halpern (1998) give axiomatic characterizationconditioning sets probabilities, based axioms given van Fraassen (1987, 1985)characterize conditioning case uncertainty described single probabilitydistribution. Grove Halpern point out, axioms compellingvan Fraassen. would interesting know whether similar axiomatizationused characterize update notions considered here.Acknowledgmentspreliminary version paper appears Uncertainty Artificial Intelligence, Proceedings Eighteenth Conference, 2008, title Game-Theoretic AnalysisUpdating Sets Probabilities. present paper expands conference versionseveral ways. importantly, section calibration entirely rewritten,significant error corrected. would like thank Wouter Koolen, pointederror previous version Definition 5.3, anonymous refereesthoughtful remarks. Peter Grunwald also affiliated Leiden University, Leiden,Netherlands. supported IST Programme European Community, PASCAL Network Excellence, IST-2002-506778. Joseph Halpern supportedpart NSF grants ITR-0325453, IIS-0534064, IIS-0812045, IIS-0911036,AFOSR grant FA9550-05-1-0055 FA9550-08-1-0438, ARO grantW911NF-09-1-0281.Appendix A. Proofsprove Theorems 3.1 Theorem 3.2, need two preliminary observations. firstcharacterization Nash equilibria. P-game, Nash equilibrium saddle pointamounts pair ( , ) distribution P randomized decisionruleE EPr [L ] = minD(X ,A) E [EPr [L ]](9)= maxPrP EPr [L ],E [EPr [L ]] PrP, (Pr)>0 (Pr)EPr [L ]. P-x-game, Nash equilibrium pair ( , ) distribution P | X = x randomizeddecision rule, (9) holds P replaced P | X = x.second observation need following special case Theorem 3.2work Grunwald Dawid (2004), extension Von Neumanns original minimaxtheorem.PTheorem A.1: 0 finite set, P 0 closed convex subset (Y 0 ), A0 closedconvex subset IRk k , L0 : 0 A0 IR bounded functionthat, 0 , L(y, a) continuous function a, exists Pr P 0415fiGrunwald & HalpernA0 that,EPr [L0 (Y 0 , )] = minA0 EPr [L0 (Y 0 , )]= maxPrP 0 EPr [L0 (Y 0 , )].(10)observations, ready prove Theorem 3.1:Theorem 3.1: Fix X , Y, A, L, P (X Y).(a) P-game Nash equilibrium ( , ), distribution Pfinite support.(b) ( , ) Nash equilibrium P-game finite support,(i) every distribution Pr0 P support ,EPr0 [L ] = maxPrP EPr [L ];(ii) Pr = PrP, (Pr)>0 (Pr) Pr (i.e., Pr convex combinationdistributions support , weighted probability according ),EPr [L ] = minD(X ,A) EPr [L ]= maxPrP minD(X ,A) EPr [L ]= minD(X ,A) maxPrP EPr [L ]= maxPrP EPr [L ].PProof: prove part (a), introduce new loss function L0 essentially equivalentL, designed Theorem A.1 applied. Let 0 = X Y, let A0 = D(X , A),define function L0 : 0 A0 IRL0 ((x, y), ) := L (x, y) =X(x)(a)L(y, a).aAObviously L0 equivalent L sense Pr (X Y), D(X , A),EPr [L ] = EPr [L0 ((X, ), )].view A0 = D(X , A) convex subset IR|X |(|A|1) , L0 ((x, y), a) becomescontinuous function A0 . Let P 0 convex closure P. Since Xfinite, P 0 consists distributions Pr (X , Y) form c1 Pr1 + + ck Prkk = |X Y|, Pr1 , . . . , Prk P c1 , . . . , ck nonnegative real coefficientsc1 + + ck = 1. Applying Theorem A.1 L0 P 0 , follows (10) holdsPr P 0 A0 = D(X , A) (that is, (10) ). Thus, mustPdistribution P finite support Pr = PrP, (Pr)>0 (Pr) Pr.easy see two equalities (10) literally two equalities (9). Thus,( , ) Nash equilibrium. proves part (a).prove part (b)(i), suppose first ( , ) Nash equilibrium P-gamefinite support. Let V = maxPrP EPr [L ]. (9),X(Pr)EPr [L ] = V.PrP, (Pr)>0416(11)fiMaking Decisions Using Sets ProbabilitiesTrivially, Pr0 P, must EPr0 [L ] maxPrP EPr [L ]. inequalitystrict Pr0 P support ,X(Pr)EPr [L ] < V,PrP, (Pr)>0contradicting (11). proves part (b)(i).prove part (b)(ii), note straightforward arguments showmaxPrP EPr [L ]minD(X ,A) maxPrP EPr [L ]maxPrP minD(X ,A) EPr [L ]minD(X ,A) EPr [L ].(The second inequality follows because, Pr0 P, minD(X ,A) maxPrP EPr [L ]minD(X ,A) EPr0 [L ].) Since ( , ) Nash equilibrium, part (b)(ii) immediate, usingequalities (9).Theorem 3.2: Fix X , Y, A, L, P (X Y).(a) P-x-game Nash equilibrium ( , (x)), distributionP | X = x finite support.(b) ( , (x)) Nash equilibrium P-x-game finite support,(i) Pr0 support ,EPr0 [L ] = maxPrP|X=x EPr [L ];(ii) Pr =PPrP, (Pr)>0====(Pr) Pr,EPr [L ]minD(X ,A) EPr [L ]maxPrP|X=x minD(X ,A) EPr [L ]minD(X ,A) maxPrP|X=x EPr [L ]maxPrP|X=x EPr [L ].Proof: prove part (a), apply Theorem A.1, setting L0 = L, 0 = Y, A0 = (A),P 0 convex closure P | X = x. Thus, (10) holds A0 , denote(x). proof Theorem 3.1, must distribution P | X = xPfinite support Pr = PrP|X=x, (Pr)>0 (Pr) Pr. remainderargument identical Theorem 3.1.proof part (b) completely analogous proof part (b) Theorem 3.1,thus omitted.Theorem 4.4: Given decision setting DS = (X , Y, A, P) P = hPi,decision probems DP based DS, exists priori minimax-optimal rule417fiGrunwald & Halpernalso posteriori minimax optimal. Indeed, every posteriori minimax-optimal rulealso priori minimax-optimal rule. If, Pr P x X , Pr(X = x) > 0,every decision problem based DS, every priori minimax-optimal rule alsoposteriori minimax optimal.Proof: Let X + = {x X : maxPrP Pr(X = x) > 0}. Let random variableX defined taking (x) = 0 x/ X + , (x) = maxPr0 P|X=x EPr0 [L ] x X + .first show every D(X , A),max EPr [L ] = maxPrPPrPXPrX (X = x)m (x).(12)xXNoteEPr [L ] =====PPr((X, ) = (x, y))L (x, y)P(x,y)XPPrX (X = x) yY Pr(Y = x | X = x)L (x, y){xX:Pr(x)>0}XPPr (X = x)EPr|X=x [L ]P{xX :PrX (x)>0} XPr (X = x) maxPr0 P|X=x EPr0 [L ]P{xX :PrX (x)>0} XPr (X = x)m (x)P{xX :PrX (x)>0} XxXPrX (X = x)m (x).Taking max Pr P, getmax EPr [L ] maxPrPPrPXPrX (X = x)m (x).xXremains show reverse inequality (12). Since P closed, exists Pr PXXmaxPrX (X = x)m (x) =PrX (X = x)m (x).PrPxXxXMoreover, since P | X = x closed, x X + , exists Prx P | X = x(x) = EPrx [L ]. Define Pr (X Y) taking(Pr ((X, ) = (x, y)) =0x/ X+xPrX (X = x) Pr (Y = y) x X + .Clearly PrX = PrX (Pr | X = x) = (Prx | X = x) P | X = x x X + . Thus,definition, Pr hPi. Since, assumption, hPi = P, follows Pr P. addition,easily followsPmaxPrP xX PrX (X = x)m (x)P=PrX (X = x)m (x)PxXP=xX + PrX (X = x)= EPr [L ]maxPrP EPr [L ].yYPr (Y = | X = x)L (x, y)establishes (12).let priori minimax decision rule. Since P-game Nash equilibrium (Theorem 3.1), must exist. Let X 0 set x0 X418fiMaking Decisions Using Sets Probabilitiesminimax optimal Px0 -game, i.e., x0 X 0 iff x X + maxPr0 P|X=x0 EPr0 [L ] >minD(X ,A) maxPr0 P|X=x0 EPr0 [L ]. Define 0 decision rule agreesX \ X 0 minimax optimal P | X = x0 game x0 X 0 ; is, 0 (x) = (x)x/ X 0 and, x X 0 ,(x) argminD(X ,A)maxPr0 P|X=x0EPr0 [L ].construction, m0 (x) (x) x X m0 (x) < (x) x X 0 . Thus,using (12),maxPrP EPr [L0 ]P= maxPrP xX Pr(X = x)m0 (x)P(13)maxPrP xX Pr(X = x)m (x)= maxPrP EPr [L ].Thus, 0 also priori minimax-optimal decision rule. But, construction, 0 alsoposteriori minimax-optimal decision rule, follows exists least onedecision rule (namely, 0 ) priori posteriori minimax optimal.proves first part theorem. prove last part, note Pr(X = x) > 0Pr P x X , X 0 6= , inequality (13) strict. follows X 0empty case, otherwise would priori minimax optimal, contradictingassumptions. But, X 0 empty, must also posteriori minimax optimal.remains show every posteriori minimax-optimal rule also priori minimaxoptimal. x X , define mm(x) = 0 x 6 X + , mm(x) = min (x) x X + .Let set posteriori minimax-optimal rules. already shownleast one element, say 0 , also priori minimax optimal.x X , must (x) = mm(x). (12), follows every ,PmaxPrP EPr [L ] = maxPrP xX PrX (X = x)m (x)P= maxPrP xX PrX (X = x)mm(x).Hence,max EPr [L ] = max EPr [L0 ].PrPPrPSince 0 priori minimax optimal, implies priori minimaxoptimal.Proposition 4.7:(a) Every dynamically consistent decision problem also weakly time consistent.(b) every dynamically consistent decision problem time consistent.(c) Every strongly dynamically consistent decision problem time consistent.(d) exist weakly time consistent decision problems dynamically consistent.(e) decision problems based P dynamically consistent decisionproblems based P weakly time consistent.419fiGrunwald & HalpernProof: Part (a) immediate part 1 definition dynamic consistency. Part(b) follows decision problem Example 4.5 dynamically consistenttime consistent. already showed time consistent. seedynamically consistent, note every decision rule defined domainexample priori minimax optimal, part 1 definition dynamic consistencyholds automatically. Part 2 also holds automatically, since every two decision rules0 , (2) hold strict inequality X = 0.part (c), consider arbitrary decision problem DP strongly dynamicallyconsistent. easy construct posteriori minimax optimal decision rule; call .Since DP strongly dynamically consistent, must priori minimax optimal. Suppose,way contradiction, decision rule 0 priori minimax optimalposteriori minimax. Since posteriori minimax optimal, must case(2) holds, inequality strict x Pr(X = x) > 0Pr P. Thus, strong dynamic consistency, must priori preferred 0 accordingminimax criterion, contradiction assumption 0 priori minimax optimal.part (d), consider Example 2.1 again, time dynamicinconsistency. Randomizing equal probabibility 0 1, matterobserved, posteriori preferred randomized actions,priori minimax optimal. extend example adding additional action 2defining L(0, 2) = L(1, 2) = 1; L(y, a) remains unchanged {0, 1}.priori posteriori minimax optimal act play 2, mattervalue X observed, time consistency holds. Yet dynamic consistency stillhold, observing X = 0 X = 1, randomizing equal probabibility0 1 preferred playing action 1, observing X, decisionrule plays action 1 matter observed strictly preferred randomizing0 1.direction part (e) already follows part (a). direction,suppose, way contradiction, decision problems based P weakly timeconsistent, decision problem based P dynamically consistent.decision problem loss function L, set actions, two decision rules 0preferred posteriori 0 priori; thus, definition dynamicconsistency, (2) holds (3) not. Let Lmax posteriori minimax expected loss. Extend L additional act a0 y, L(y, a0 ) = Lmax .new decision problem action set {a0 } become minimaxoptimal posteriori rule (it one, matter). However,cannot priori minimax optimal, (3) still hold 0 : 0priori strictly better . Hence, weak time consistency newdecision problem. Since still decision problems based P, weaktime consistency decision problems based P, arrived desiredcontradiction.Theorem 5.1: Fix X , Y, L, A, P (X Y). If, PrY PY , P contains distribution Pr0 X independent Pr0 , Pr0Y = PrY ,priori minimax-optimal decision rule ignores information.conditions, priori minimax-optimal decision rule ignores information,420fiMaking Decisions Using Sets Probabilitiesessentially optimizes respect marginal ; is, maxPrP EPr [L ] =maxPrY PY EPrY [L0 ].Proof: Let P 0 subset P distributions X independent.Let D(X , A)0 subset D(X , A) rules ignore information. Let D(X , A)0defined optimal decision rule ignores information relative P 0 , i.e.max EPr [L ] =PrP 0minmax EPr [L ].D(X ,A)0 PrP 0maxPrP EPr [L ]==minD(X ,A) maxPrP EPr [L ]minD(X ,A) maxPrP 0 EPr [L ]minD(X ,A)0 maxPrP 0 EPr [L ] [see below]maxPrP 0 EPr [L ].(14)see equality third fourth line (14) holds, notePr P 0 ,PEPr [L ] =Pr(x, y)L (x, y)P(x,y)XPP=xX Pr(X = x)yY Pr(Y = y)( aA (x)(a)L(y, a))decision rule minimizes expression independent x; distributionactions minimizesXPr(Y = y)(X(a)L(y, a)).aAyYcalculation also shows that, since ignores information, Pr P 0 ,max EPr [L ] = max EPrY [L0 ] = max0 EPr [L ].PrPPrY PYPrP(15)implies first last line (14) equal other, therefore alsoequal second line (14). follows priori minimax optimal. Since everypriori minimax optimal rule ignores information must satisfy (15), second resultfollows. next prove Theorem 6.3. first need three preliminary results.Lemma A.2: P convex X0 X , (P | X0 )Y convex.Proof: Without loss generality, assume (P | X0 )Y nonempty. Given Pr00 , Pr01(P | X0 )Y , let Pr0 = Pr01 +(1 ) Pr00 . show that, [0, 1], Pr0 (P | X0 )Y .Choose Pr0 , Pr1 P Pr0 (X0 ) > 0, Pr1 (X0 ) > 0, (Pr0 | X0 )Y = Pr00 , (Pr1 | X0 )Y =Pr01 . c [0, 1], let Prc = c Pr1 +(1 c) Pr0 . Then, Y,Prc (Y = | X0 ) ===Prc (XX0 ,Y =y)Prc (XX0 )c Pr1 (XX0 ) Pr1 (Y =y|XX0 )+(1c) Pr0 (XX0 ) Pr0 (Y =y|XX0 )c Pr1 (XX0 )+(1c) Pr0 (XX0 )c Pr01 (Y = y) + (1 c ) Pr00 (Y = y),421(16)fiGrunwald & Halpernc = c Pr1 (X0 )/(c Pr1 (X0 ) + (1 c) Pr0 (X0 )). Clearly, c continuous increasingfunction c, 0 = 0 1 = 1. Thus, exists c c = . Sincec independent y, (16) holds (with choice c ), is,(Prc | X0 )Y = Pr00 +(1 ) Pr01 Pr0 . Thus, Pr0 (P | X0 )Y , desired.Lemma A.3: U = {X1 , . . . , Xk } collection nonoverlapping subsets X (i.e.,1 < j k, Xi Xj = ), (P | X1 )Y convex, (P | X1 )Y = (P | X2 )Y = . . . = (P | Xk )Y ,V = ki=1 Xi , j {1, . . . , k}, (P | V)Y (P | Xj )Y .Proof: result immediate (P | V) empty. suppose Pr P Pr(V) > 0.Using Bayes Rule,(Pr | V)Y =XPr(Xi | V)(Pr | Xi )Y .{i:Pr(Xi |V)>0}(P | X1 )Y = . . . = (P | Xk )Y assumption. Thus, Pr(Xi |V) > 0, must exist Pri P (Pr | Xi )Y = (Pri | X1 )Y . Thus,P(Pr | V)Y = {i:Pr(Xi |V)>0} Pr(Xi | V)(Pri | X1 )Y . Since P convex assumption,Lemma A.2, (P | X1 )Y convex well. Thus, write (Pr | V)Y convexcombination elements (P | X1 )Y , follows (Pr | V)Y (P | X1 )Y . Since(P | X1 )Y = . . . = (P | Xk )Y , follows (Pr | V)Y (P | Xj )Y j = 1, . . . , k.Lemma A.4: P = hPi U = {x1 , . . . , xk },Tkj=1 (P| X = xj )Y (P | U)Y .Proof: Let Q kj=1 (P | X = xj )Y . must exist Pr1 , . . . , Prk P that,j = 1, . . . , k, (Prj | X = xj )Y = Q. Clearly Pr1 (x1 ) > 0. Since P = hPi, also existsPr P PrX = (Pr1 )X j {1, . . . , k} Pr1 (xj ) > 0,(Pr | X = xj )Y = (Prj | X = xj )Y = Q. follows (Pr | U)Y = Q, Q (P | U)Y .Theorem 6.3:(a) C-conditioning partition C X P convex then, x X ,(P | [x],P )Y (P, x)Y .(b) standard conditioning, P = hPi, x X , (P, x)Y (P | [x],P )Y .Proof: part (a), since P convex, Lemma A.2, (P | X 0 )Y convex X 0 X .Let U = {C(x0 ) | x0 [x],P }. definition [x],P , x0 [x],P ,(P, x0 ) = P | C(x0 ) = P | C(x) = (P, x).Thus, Lemma A.3, (P | V)Y (P, x)Y , V = U = [x],P C(x0 ). provespart (a).part (b), since standard conditioning, (P | X = x)Y = (P | X =x0 )Y x0 U. assumption, P = hPi. Thus, follows immediately Lemma A.4(taking U = [x],P ) (P, x)Y (P | [x],P )Y , desired.next want prove Theorem 6.10. first need definition preliminaryresult.422fiMaking Decisions Using Sets ProbabilitiesDefinition A.5 : update rule semi-calibrated relative P (P | [x],P )Y(P, x)Y .Note that, Theorem 6.3, P convex, C-conditioning semi-calibrated C.Lemma A.6: semi-calibrated relative P C = {[x],P | x X }, Cpartition X(a) C-conditioning narrower relative P.(b) C-conditioning strictly narrower relative P, equivalentC-conditioning P, calibrated.Proof: Clearly C partition X . part (a), 0 C-conditioning then, definition,0 (P, x) = P | C(x) = P | [x],P . Since semi-calibrated, (P | [x],P )Y ((P, x))Y .Thus, C-conditioning narrower relative P.part (b), C-conditioning (i.e., 0 ) strictly narrower relative P,must (P(, x))Y = (P 0 (, x))Y x X , (P | [x],P )Y = (P, x)Y ,claibrated relative P.Theorem 6.10:(a) C-conditioning sharply calibrated relative P partition C.(b) sharply calibrated relative P, exists C equivalent C-conditioning P (i.e., (P, x) = | C(x) x X ).Proof: place partial order P partitions C taking C1 P C2 C1 conditioning narrower C2 conditioning relative P. Since X finite,finitely many possible partitions X . Thus, must minimal elementsP . claim minimal element P sharply calibrated relative P.suppose C0 minimal relative P . P convex, C0 -conditioningsemi-calibrated (Theorem 6.3) apply Lemma A.6 C0 . C0minimal, C defined Lemma A.6 cannot strictly narrower C0 . followsLemma A.6(b) C0 -conditioning calibrated. show C0 -conditioningfact sharply calibrated, showing exists calibrated update rulestrict narrowing C0 -conditioning. suppose, way contradiction,update rule calibrated strictly narrower C0 relative P.Lemma A.6(a) exists partition C C narrower relative P.C <P C0 , contradicting minimality C0 . proves part (a).part (b), suppose sharply calibrated relative P. Lemma A.6(a),must partition C C-conditioning narrower , relative P.Let C0 minimal element P C0 P C. Part (a) shows C0 -conditioningsharply calibrated relative P. Since C0 -conditioning narrower ,sharply calibrated relative P, must C0 -conditioning strictly narrowerrelative P, hence equivalent C0 -conditioning P.Theorem 6.12: P convex P = hPi, standard conditioning sharplycalibrated relative P.423fiGrunwald & HalpernProof: Corollary 6.4, standard conditioning calibrated relative P statedassumptions P. show sharply calibrated, suppose existsupdate rule 0 narrower standard conditioning, sharply calibratedrelative P. Theorem 6.10, 0 equivalent C-conditioning C relativeP. Thus, x X x0 C(x),(P | C(x))Y (P | x0 )Y ,(P | C(x))Y\(P | x0 )Y .x0 C(x)Lemma A.4, immediate\(P | x0 )Y (P | C(x))Y .x0 C(x)Thus, must\(P | x0 )Y = (P | C(x))Y .(17)x0 C(x)want show that, x0 C(x), (P | C(x))Y = (P | x0 )Y .show C equivalent conditioning, conditioning sharply calibrated.Suppose not, Q (P | x0 )Y P | C(x)Y x0 C(x). Let Q0distribution (P | C(x))Y closest Q. fact distributionQ0 follows fact P closed (recall assume P closed throughoutpaper). (In fact, follows convexity Q0 unique, necessaryargument.) Since Q0 (P | C(x))Y , follows (17) that, x00 C(x),must distribution Prx00 P Prx00 (x00 ) > 0 (Prx00 | x00 )Y = Q. SinceP convex, distribution Pr P Pr (x00 ) > 0 x00 C(x)(indeed, Pr convex combination distributions Prx00 x00 Ccoefficients positive). Since P = hPi, must exist distribution Pr P(Pr)X = (Pr )X (so Pr positive elements C), (Pr | x00 )Y = Q0x00 C(x) x0 , (Pr | x0 )Y = Q. Note (Pr | (C(x) {x0 }))Y = Q0 . Thus,(Pr | C(x)Y = c(Pr | C(x) x0 )Y + (1 c)(Pr | x0 )Y = cQ0 + (1 c)Q,c 0 < c < 1. Clearly cQ0 + (1 c)Q closer Q Q0 is. givesdesired contradiction.ReferencesAugustin, T. (2003). suboptimality generalized Bayes rule robust Bayesianprocedures decision theoretic point view: cautionary note updatingimprecise priors. 3rd International Symposium Imprecise ProbabilitiesApplications, pp. 3145. Available http://www.carleton-scientific.com/isipta/2003toc.html.424fiMaking Decisions Using Sets ProbabilitiesCozman, F. G., & Walley, P. (2001).Graphoid properties epistemic irrelevance independence.2nd International Symposium Imprecise Probabilities Applications, pp. 112121.Availablehttp://www.sipta.org/ isipta01/proceedings/index.html.da Rocha, J. C. F., & Cozman, F. G. (2002). Inference separately specified setsprobabilities credal networks. Proc. Eighteenth Conference UncertaintyArtificial Intelligence (UAI 2002), pp. 430437.Dawid, A. P. (1982). well-calibrated Bayesian. Journal American StatisticalAssociation, 77, 605611. Discussion: pages 611613.de Finetti, B. (1936). Les probabilites nulles. Bulletins des Science Mathematiques (premierepartie), 60, 275288.Ellsberg, D. (1961). Risk, ambiguity, Savage axioms. Quarterly Journal Economics, 75, 643649.Epstein, L. G., & Schneider, M. (2003). Recursive multiple priors. Journal EconomicTheory, 113 (1), 131.Gardenfors, P., & Sahlin, N. (1982). Unreliable probabilities, risk taking, decisionmaking. Synthese, 53, 361386.Gilboa, I., & Schmeidler, D. (1989). Maxmin expected utility non-unique prior.Journal Mathematical Economics, 18, 141153.Grove, A. J., & Halpern, J. Y. (1998). Updating sets probabilities. Proc. FourteenthConference Uncertainty Artificial Intelligence (UAI 98), pp. 173182.Grunwald, P. D., & Dawid, A. P. (2004). Game theory, maximum entropy, minimumdiscrepancy, robust Bayesian decision theory. Annals Statistics, 32 (4),13671433.Grunwald, P. D., & Halpern, J. Y. (2004). ignorance bliss. Proc. TwentiethConference Uncertainty Artificial Intelligence (UAI 2004), pp. 226234.Herron, T., Seidenfeld, T., & Wasserman, L. (1997). Divisive conditioning: resultsdilation. Philosophy Science, 64, 411444.Huber, P. J. (1981). Robust Statistics. Wiley, New York.Hughes, R. I. G., & van Fraassen, B. C. (1985). Symmetry arguments probability kinematics. Kitcher, P., & Asquith, P. (Eds.), PSA 1984, Vol. 2, pp. 851869. PhilosophyScience Association, East Lansing, Michigan.Lewis, D. (1976). Probability conditionals conditional probabilities. PhilosophicalReview, 83 (5), 297315.Mosteller, F. (1965). Fifty Challenging Problems Probability Solutions. AddisonWesley, Reading, Mass.425fiGrunwald & HalpernOzdenoren, E., & Peck, J. (2008). Ambiguity aversion, games nature, dynamicconsistency. Games Economic Behavior, 62 (1), 106115.Popper, K. R. (1968). Logic Scientific Discovery (2nd edition). Hutchison, London.first version book appeared Logik der Forschung, 1934.Sarin, R., & Wakker, P. (1998). Dynamic choice nonexpected utility. Journal RiskUncertainty, 17 (2), 87120.Savage, L. J. (1954). Foundations Statistics. Wiley, New York.Seidenfeld, T. (2004). contrast two decision rules use (convex) setsprobabilities: -maximin versus E-admissibility. Synthese, 140 (12), 6988.Seidenfeld, T., & Wasserman, L. (1993). Dilation convex sets probabilities. AnnalsStatistics, 21, 11391154.van Fraassen, B. C. (1987). Symmetries personal probability kinematics. Rescher, N.(Ed.), Scientific Enquiry Philosophical Perspective, pp. 183223. University PressAmerica, Lanham, Md.vos Savant, M. (Sept. 9, 1990). Ask Marilyn. Parade Magazine, 15. Follow-up articlesappeared Parade Magazine Dec. 2, 1990 (p. 25) Feb. 17, 1991 (p. 12).Vovk, V., Gammerman, A., & Shafer, G. (2005). Algorithmic Learning Random World.Springer, New York.Wald, A. (1950). Statistical Decision Functions. Wiley, New York.Walley, P. (1991). Statistical Reasoning Imprecise Probabilities, Vol. 42 MonographsStatistics Applied Probability. Chapman Hall, London.426fiJournal Artificial Intelligence Research 42 (2011) 575605Submitted 06/11; published 12/11Computing Approximate Nash EquilibriaRobust Best-Responses Using SamplingMarc PonsenSteven de Jong. PONSEN @ MAASTRICHTUNIVERSITY. NLSTEVEN . DEJONG @ MAASTRICHTUNIVERSITY. NLDepartment Knowledge EngineeringMaastricht University, NetherlandsMarc LanctotLANCTOT @ UALBERTA . CADepartment Computer ScienceUniversity Alberta, CanadaAbstractarticle discusses two contributions decision-making complex partially observablestochastic games. First, apply two state-of-the-art search techniques use Monte-Carlo sampling task approximating Nash-Equilibrium (NE) games, namely Monte-CarloTree Search (MCTS) Monte-Carlo Counterfactual Regret Minimization (MCCFR). MCTSproven approximate NE perfect-information games. show algorithm quicklyfinds reasonably strong strategy (but NE) complex imperfect information game, i.e.Poker. MCCFR hand theoretical NE convergence guarantees game.apply MCCFR first time Poker. Based experiments, may conclude MCTSvalid approach one wants learn reasonably strong strategies fast, whereas MCCFRbetter choice quality strategy important.second contribution relates observation NE best responseplayers playing NE. present Monte-Carlo Restricted Nash Response (MCRNR),sample-based algorithm computation restricted Nash strategies. robust bestresponse strategies (1) exploit non-NE opponents playing NE (2)(overly) exploitable strategies. combine advantages two state-of-the-art algorithms, i.e. MCCFR Restricted Nash Response (RNR). MCRNR samples relevant partsgame tree. show MCRNR learns quicker standard RNR smaller games. Alsoshow Poker MCRNR learns robust best-response strategies fast, strategiesexploit opponents playing NE does.1. Introductionarticle investigates decision-making strategic, complex multi-player games.complex test-bed, use game two-player Limit Texas Holdem Poker (henceforth abbreviated Poker full-scale Poker). introduction, first briefly outline researchgames relevant. Then, discuss complexity factors involved games. Finally,outline approach contributions.1.1 Relevance Games-Related ResearchGames attracted scientific attention years now; importance research areagame theory became apparent Second World War (Osborne & Rubinstein, 1994). Nowadays, examples serious games found many real-life endeavors, economics (e.g.,c2011AI Access Foundation. rights reserved.fiP ONSEN , L ANCTOT & E J ONGbuyers sellers stock market goal maximize profit) politics (e.g., politiciansgoal collect sufficient political support cause). Games serve entertainment, puzzles, board-, sports- modern video-games, often abstracted, simpler variantsserious games. example card game Poker. objective Poker differentobjective investors stock market. Players may invest (or risk) money speculate future events may may yield profit. strategies abstract games (suchPoker) easily rapidly evaluated strategies real-life endeavors (such actingstock market), abstract games perfect tool assessing improving strategicdecision-making abilities humans well computers. reason, various complex multiplayer games attracted great deal attention artificial intelligence (AI) community(Schaeffer, 2001).1.2 Complexity Factors GamesGames characterized several complexity factors. briefly mention factorsrelevant work presented article.Number players. Multi-player games generally assumed complexsingle-player games. Within class multi-player games, fully competitive games, alsoknown zero-sum games, games players conflicting goalstherefore deliberately try minimize payoff others.Size state space. size state space (the number different situationsgame may in) varies game game, depending number legal situationsnumber players. Large state spaces produce complex gamescomputational requirements traversing entire state space.Uncertainty. Stochastic games, opposed deterministic games, complexuncertainty effects actions, occurrences (future) events, instancedie rolls involved.Imperfect information. Parts game state may hidden players, e.g., opponentcards card game, probability certain chance outcome. also knownpartial observability.remainder article, deal partially observable stochastic games (Fudenberg &Tirole, 1991), using full-scale Poker game complex test-bed. game multiplayer, competitive, partially observable stochastic game. daunting game humanAI players master.1.3 Contributionsinvestigate two different sampling-based approaches decision-making, namely (1) classicalgame-theoretic approach (2) best-response approach.first approach, apply current state-of-the-art algorithms task computingapproximated Nash-Equilibrium strategy (NES) game Poker. two-player, zerosum game, expected value NES constant, regardless opponent strategyspecific NES. fair games (i.e. players equal chance winning), strategies cannot lose576fiC OMPUTING PPROXIMATE NASH E QUILIBRIA ROBUST B EST-R ESPONSES U SING AMPLINGexpectation may win long run. complex games Poker, NEScomputed introducing abstractions. Also, sampling algorithms may used (relatively)quickly compute approximate NES. use abstractions well sampling work.look two families algorithms, rely Monte-Carlo sampling, namelyMonte-Carlo Tree Search (MCTS), including Upper Confidence Bounds applied Trees (Kocsis& Szepesvari, 2006; Chaslot, Saito, Bouzy, Uiterwijk, & van den Herik, 2006; Coulom, 2006),regret-minimizing algorithm, called Monte-Carlo Counterfactual Regret Minimization (MCCFR)(Lanctot, Waugh, Zinkevich, & Bowling, 2009). first offer comparisontwo algorithms full-scale Poker.1second approach, begin observation NES necessarily profitable strategy NES. all, safe strategy. informationstrategy opponent players, adapt strategy based this, i.e., learning so-calledbest-response strategies. Rather playing safe NES (i.e., play lose), want learntailored counter-strategies based opponent model (i.e., play win). learning good compromise best response equilibrium, combine general technique RestrictedNash Response (RNR) (Johanson, Zinkevich, & Bowling, 2008) Monte-Carlo Counterfactual Regret Minimization (MCCFR) algorithm, leading new algorithm, named Monte-CarloRestricted Nash Response (MCRNR).1.4 Structure Articleremainder article structured follows. Section 2 provides brief overviewbackground knowledge required article, i.e., game-theoretic concepts focussed extensiveform games, discussion games used article. Section 3 contains workcomparison Monte-Carlo Tree Search (MCTS) Monte-Carlo Counterfactual Regret Minimization (MCCFR) full-scale Poker. Section 4 introduces Monte-Carlo Restricted Nash Response(MCRNR) describes set experiments smaller games well Poker. Finally, Section5, conclude article.2. Backgroundcurrent section provide background information. Section 2.1 discuss gametheory (GT) fundamentals, focussing extensive-form games. represent partially observable stochastic games means games (Fudenberg & Tirole, 1991). main test domain,two-player limit Texas Holdem Poker, introduced Section 2.2, along number smallergames also use validate new algorithm experimentally.2.1 Game Theory Extensive Form GamesGame theory (GT) studies strategic decision-making games two players. basic assumptions underlie theory players rational, i.e. self-interestedable optimally maximize payoff, take account knowledge1. note aim join arms race compute closest Nash-Equilibrium (NE) approximationfull-scale Poker. aim contribution comparison two recent promising algorithms. Pokertest-bed chose use complex partially observable stochastic game algorithmsapplied thus far, exist reasonably strong benchmarks test against.577fiP ONSEN , L ANCTOT & E J ONGexpectations decision-makers behavior, i.e. reason strategically (Fudenberg & Tirole,1991; Osborne & Rubinstein, 1994). field originated economics analyze behaviour noncooperative settings, firmly established von Neumann Morgenstern (1944). Nash(1951) introduced known Nash-Equilibrium (NE). current sectionbriefly discuss fundamentals GT extensive-form games.2.1.1 G AMESGames descriptions strategic interaction players. specify set availableactions players payoff combination actions. Game-theoretic tools usedformulate solutions classes games examine properties. Typically, distinctionmade two types game representations, namely normal-form games extensive-formgames. normal-form game usually represented matrix shows players, actions,payoffs. normal-form games presumed players act simultaneously (i.e.information action choice opponents). second representation, extensive-formgame, describes games played time. Previous action sequences stored socalled game-tree, such, information choices players observed.article, focus extensive-form games.2.1.2 E XTENSIVE -F ORM G AMESextensive-form game general model sequential decision-making imperfect information. perfect-information games (such Chess Checkers), extensive-form games consistprimarily game tree nodes represent states game. non-terminal nodeassociated player (possibly chance) makes decision node, terminal node(leaf) associated utilities players. Additionally, game states partitioned information sets Ii . player cannot distinguish states information set. player,therefore, must choose actions policy state information set.strategy player i, , function assigns probability distribution A(Ii )Ii Ii , Ii information set belonging i, A(Ii ) set actionschosen information set. denote set strategies player i,players current strategy. strategy profile, , consists strategy player, 1 , . . . , n .let refer strategies excluding .Valid sequences actions game called histories, denoted h H. historyterminal history, h Z Z H, sequences actions lead root leaf. prefixhistory h v h0 one h0 obtained taking valid sequence actions h.Given h, current player act denoted P (h). information set contains one validhistories. standard assumption perfect recall: information sets defined informationrevealed player course history, assuming infallible memory.Let (h) probability history h occurring players choose actions according. decompose (h) players contribution probability. Here, (h)(h)contribution probability player playing according . Letproduct players contribution (including chance) except player i. Finally, let (h, z) =(h, z) defined similarly. Using(z)/ (h) h v z, zero otherwise. Let (h, z)Pnotation, define expected payoff player ui () = hZ ui (h) (h).578fiC OMPUTING PPROXIMATE NASH E QUILIBRIA ROBUST B EST-R ESPONSES U SING AMPLINGGiven strategy profile, , define players best response strategy maximizesexpected payoff assuming players play according . best-response valueplayer value strategy, bi (i ) = maxi0 ui (i0 , ). -Nash-Equilibrium (NE)approximation best response itself. Formally, -Nash-Equilibrium (NE)strategy profile satisfies:Nui () + maxui (i0 , )0(1)= 0 Nash-Equilibrium (NE): player incentive deviateplaying best responses. game two-player zero-sum, use exploitability metricdetermining close equilibrium, = b1 (2 ) + b2 (1 ).well-known two-player, zero-sum games NE strategies interchangeable. is,(1 , 2 ) (10 , 20 ) different equilibrium profiles 6= i0 , (1 , 20 ) (10 , 2 )also NE profiles. property makes equilibrium strategies class games desireablesince worst-case guarantees preserved regardless opponent plays. propertyeasily extended case > 0, therefore playing NE strategy guaranteeplayer exploitable . details, refer reader work FudenbergTirole (1991) well Osborne Rubinstein (1994).Throughout article, refer player plays NES rational player.player plays rationally also assumes rationality part opponents. Experimentsshown assuming rationality generally correct (e.g. experiments Poker see Billings,Burch, Davidson, Holte, Schaeffer, Schauenberg, & Szafron, 2003); even experienced human players complex games best play approximated rational strategy, frequently play dominatedactions (i.e., actions never chosen all). Moreover, complex gamesChess Poker, even AI algorithms running modern computers great deal processorspeed memory (yet) cope immense complexity required compute NES.Thus, forced either abstract full game selective sampling computeapproximated NE.2.2 Test Domainscurrent section, introduce test domains used throughout article. particulardescribe game Poker, well smaller games, similar Poker.Poker card game played least two players. nutshell, objective gamewin (money) either best card combination end game (i.e. showdown),active player. game includes several betting rounds wherein playersallowed invest money. Players remain active least matching largest investment madeplayers, choose fold (stop investing money forfeit game).case one active player remains, i.e. players chose fold, active playerautomatically wins game. winner receives money invested players. existmany variants game. specifically describe ones used article.Kuhn Poker two-player simple Poker game. three cards (J - Jack, Q - Queen,K - King). two actions, bet pass. event showdown, playerhigher card wins pot (the King highest Jack lowest). deal, first player579fiP ONSEN , L ANCTOT & E J ONGJ/Qpass1-passpass1-1pass1-+11-bet1-21-2pass1pass1-1+11-betpass1-passbetbet1-passpass1+1passpass1-betbet1-K/Qbetpass11K/JpasspassbetbetbetQ/KQ/JJ/Kbet+1pass1+1bet1-+1+2betbet1Player 1 Choice/Leaf Node-1-1+22-1-2+2Player 2 Choice NodeFigure 1: Kuhn Poker game tree (taken work Hoehn, Southey, & Holte, 2005).opportunity bet pass. first player bets round one, round two secondplayer either bet (and go showdown) pass (and forfeit pot). first player passesround one, round two second player bet pass. bet leads third actionfirst player, namely bet (and go showdown) pass (and forfeit pot), whereaspass game immediately proceeds showdown. Figure 1 shows game tree firstplayers value outcome. dominated actions removed tree.include actions betting Queen first action, passing King second player.total seven possible dominated actions made. Nash-Equilibria gamesummarized three parameters (, , ) (each [0, 1]). Kuhn determined setequilibrium strategies first player form (, , ) = (/3, (1 + )/3, ). Thus,continuum Nash-Equilibrium strategies governed single parameter . oneNES second player, namely = 1/3 = 1/3. either player plays NES, firstplayer expects lose rate 1/18 bets (i.e., size ante) per hand. Kuhn Poker thereforebalanced fair game, since first player expected lose players play rationalstrategy.One-Card Poker (abbreviated OCP(N )) (Gordon, 2005) generalization Kuhn Poker.deck contains N cards; Kuhn Poker corresponds N = 3. player must ante single chip,one chip bet with, dealt one card.Goofspiel (abbreviated Goof(N )) bidding card game players hand cards numbered 1 N , take turns secretly bidding top point-valued card point card stack,using cards hands (Ross, 1971). version less informational: players findresult bid cards used bid, player highest total pointswins. also use fixed point card stack strictly decreasing, e.g. (N, N 1, . . . , 1).Bluff(1,1,N) also known Liars Dice Perudo2 , dice-bidding game. version,player rolls single N -sided die looks die without showing opponent.players, alternately, either increase current bid outcome die rolls play, callplayers bluff (claim bid hold). highest value face die2. See e.g. http://www.perudo.com/perudo-history.html.580fiC OMPUTING PPROXIMATE NASH E QUILIBRIA ROBUST B EST-R ESPONSES U SING AMPLINGwild count face value. player calls bluff, win opponents bidincorrect, otherwise lose.Texas Holdem Poker (Sklansky, 2005) complex game investigation here.game includes 4 betting rounds, respectively called preflop, flop, turn river phase.first betting round, players dealt two private cards (i.e. known specific player)full deck consisting 52 cards. encourage betting, two players obliged investsmall amount first round (the so-called small- big-blind). One one, players decidewhether want participate game. indeed want participate,invest least current bet (i.e., big-blind beginning betting round). knowncalling. Players may also decide raise bet. wish participate, players fold,resulting loss money may bet thus far. situation outstanding bet, playersmay choose check (i.e., increase stakes) bet money. size bets raiseseither predetermined (i.e., Limit Poker, used paper), larger sizepot (i.e., Pot-Limit Poker) unrestrained (i.e., No-Limit Poker). remaining three bettingphases, procedure followed. every phase, community cards appear table (threecards flop phase, one card phases). cards apply playersused determine card combinations (e.g., pair three-of-a-kind may formedplayers private cards community cards). showdown, two playersstill active, cards compared, thus ending game.Princess Monster (abbreviated PAM(R, C, H)) (Isaacs, 1965) Poker game; rather,variation pursuit-evasion game graph, neither player ever knowing locationdiscovering moves (pursuit dark room). experiments userandom starting positions 4-connected grid graph R rows C columns. Players taketurns alternately moving adjacent location. game ends monster moveslocation princess, H moves taken total capture. payoffevader number steps uncaptured.next section, use Kuhn Poker (or OCP(3)) two-player Limit Texas Holdem Poker.Section 4, use games mentioned above, except Kuhn Poker; instead Kuhn Poker, uselarger game, OCP(500).3. Computing Approximated Nash-Equilibrium Strategiescontribution section evaluate current promising state-of-the-art search methodscomputing (approximated) Nash-Equilibrium strategies complex domains, specifically Poker. Given size game tree, methods (1) incorporate appropriateabstractions, (2) capable analysing small subsets full game (i.e., sampling).look two families sampling algorithms, namely Upper Confidence Boundsapplied Trees (UCT) based algorithm, called Monte-Carlo Tree Search (MCTS) (Kocsis &Szepesvari, 2006; Chaslot et al., 2006; Coulom, 2006), regret minimizing algorithm calledMonte-Carlo Counterfactual Regret Minimization (MCCFR) (Lanctot et al., 2009). MCTSachieved tremendous success perfect information games, particular game Go(Lee, Wang, Chaslot, Hoock, Rimmel, Teytaud, Tsai, Hsu, & Hong, 2010). games imper-581fiP ONSEN , L ANCTOT & E J ONGfect information, convergence guarantees finding Nash-Equilibria.3 However,reported may nonetheless produce strong players games imperfect information(Sturtevant, 2008). empirically evaluate merits MCTS imperfect informationgame Poker. MCCFR theoretical guarantees convergence Nash-Equilibrium(NE). applied smaller games thus far; first evaluate complexdomain Poker.section structured follows. Sections 3.1 3.2, discuss existing workcomputing Nash-Equilibrium strategies large extensive games provide details twosampling algorithms. Next, analyze algorithms empirically, domain KuhnPoker also larger domain two-player Limit Texas Holdem Poker (Section 3.3).3.1 Non-Sampling Algorithms Computing Approximate Nash Equilibriacurrent subsection, give overview existing non-sampling techniques computingNE approximations extensive form games. large body work exists many domains,focus specifically work domain Poker.conventional method solving extensive form games (such Poker), convertlinear program, solved linear programming solver. Billings et al. (2003)solved abstraction full game two-player Poker using sequence-form linear programming. abstractions three-fold. First, learned models separation differentphases game. Basically, phases considered independent solved isolation. However, state previous phases contain important contextual information criticalmaking appropriate decisions. probability distribution cards players strongly dependspath led decision point. Therefore, provide input (i.e., contextual informationpot size number bets game) models learned later phases. Second,shorten game tree allowing three (instead regular four) bet actions per phase.Third, apply bucketing cards. strategic strength cards (i.e., private cards, possibly combination board cards) reflected numeric value. higher value reflectsstronger cards. Billings (2006) computed so-called Effective Hand Strength (EHS), valuerange 0 1, combines Hand Strength (i.e., current winning probability active opponents) Hand Potential (i.e., probability currently losing/winning cards endwinning/losing appearance new board cards). work Billings (2006), Sections2.5.2.1 2.5.2.3, provides detailed discussion. divide values buckets.example, 10-bucket discretization (equal width), employ paper, EHS valuesrange 0 0.1 grouped together bucket 1, 0.1 0.2 bucket 2, forth. coarserview implies information loss. solution linear program induces distributionactions information set, corresponds mixed behavioral strategy. Poker-playingprogram sample actions mixed strategy. resulting Poker-playing programcompetitive human experts.Counterfactual Regret Minimization (CFR) algorithm (Zinkevich, Johanson, Bowling, &Piccione, 2008) may used compute approximated NE richer abstractionsrequires less computational resources. Poker, Zinkevich et al. (2008) applied abstractioncards capable learn strategies using CFR strong enough defeat3. example, Shafiei, Sturtevant, Schaeffer (2009) provide analysis simultaneous imperfect-informationgames, indicating UCT finds suboptimal solutions games.582fiC OMPUTING PPROXIMATE NASH E QUILIBRIA ROBUST B EST-R ESPONSES U SING AMPLINGhuman experts. Although important step solving complex games, complexityincreased even (as example increasing number buckets), learning timememory requirements become impractical.Another method Hoda et. al. (2010) Sandholm (2010) use Excessive Gap Technique applied relaxed optimization problem linear program describedderived. optimization problem smoothened made differentiable; solutionnew, relaxed problem suboptimal original problem amount 0 . Parametersoptimization problem modified following gradient smooth approximationsobjective functions. iteration i+1 modified parameters give new solution improvedsuboptimality i+1 < . process repeated desired value reached.3.2 Sampling Algorithms Computing Approximate Nash EquilibriaPerforming Monte-Carlo sampling enable algorithms deal highly complex domains.section discuss two algorithms perform Monte-Carlo sampling, namely MonteCarlo Tree Search (MCTS) Monte-Carlo Counterfactual Regret Minimization (MCCFR). Although internal workings techniques different, share general proceduresampling simulated game, determining utilities leaf node (i.e., game state ends game),backpropagating results. underlying idea techniques improve qualitysimulations progressively taking account simulated games previously played.specifically, simulations driven part game tree relevant, assuming players take rational decisions (i.e., choose actions optimize reward). result gamebackpropagated visited path. Progressively, program concentrates search bestactions, leading deeper look-ahead ability.discuss example game Poker, illustrated Figure 2. firststep (moving down), chance nodes action nodes sampled terminal node reached.Chance nodes Poker represent dealing cards. Similarly previous work Poker, alsoapply bucketing cards work. Cards grouped together buckets based strategicstrength. use 10-bucket discretization (equal width), EHS values (see Section 3.1)range 0 0.1 grouped together bucket 1, 0.1 0.2 bucket 2, forth. higherbucket indicates stronger hand. example sampled buckets 5 7 preflop phaserespectively player one two. Again, buckets reflect strategic strength playersprivate cards. appearance new board cards subsequent phases, encounterchance nodes, buckets may change.4assume imperfect recall. imperfect recall previous action chance nodes forgotten, consequence several information sets grouped together. example,work take account current bucket assignment information sets, forget previous ones. way reduce game complexity tremendously, reduces memoryrequirements convergence time. case imperfect recall CFR algorithm loses convergence guarantees NE, even though lose theoretical guarantees, applicationimperfect recall shown practical, specifically Poker (Waugh, Zinkevich, Johanson,Kan, Schnizlein, & Bowling, 2009).4. preflop phase first player weakest hand, appearance board cards player could,example, formed pair bucket therefore increased.583fiP ONSEN , L ANCTOT & E J ONGSelect chance node:p5,7dealing private cardsSelect accordinginformation-set:{bucket=5, hist=p}Update information-set:F1C1B1F2C2B2Select accordinginformation-set:{bucket=7, hist=p-C1}bucket=5, hist=pUpdate information-set:bucket=7, hist=p-C1Select chance node in:{bucket=5,7, hist=p-C1-C2}f6,4dealing board cards flopSelect accordinginformation-set:{bucket=4, hist=p-C1-C2-f}Update information-set:F2C2Continue terminal node,determine utilities:util=8,-8, bucket=9,2, hist=p-B2bucket=4, hist=p-C1-C2-fUpdate information-set:C1C1-C2-f-B2-C1-t-C2-C1-r-B2-C1bucket=9, hist=p-C1-C2-f-B2C1-t-C2-C1-r-B2-C1Figure 2: Illustration Monte-Carlo simulations game Poker. left going down,chancenodes (triangles) action nodes (circles) sampled based statisticsinformation set level. Utilities determined terminal nodes (squares),full information players cards (i.e., buckets). right going up,results simulated game backpropagated along information setsprefix terminal node. Statistics updated information set level, effectivelyaltering strategy.Players select actions based current strategy given information available(i.e., knowing bucket opponent player). letters F, C B, followed player index, respectively correspond fold, call/check bet/raise actionsgame Poker. process continues terminal leaf node encountered, utilitiesdetermined simulated game.second step (moving up), utilities backpropagated along sampled path,statistics stored information set level. Different statistics required either MCCFRMCTS. discuss algorithms detail forthcoming subsections.584fiC OMPUTING PPROXIMATE NASH E QUILIBRIA ROBUST B EST-R ESPONSES U SING AMPLING3.2.1 ONTE -C ARLO REE EARCHMCTS game tree search algorithm based Monte-Carlo simulations. MCTS convergesNE perfect information games, whereas imperfect information case guaranteesgiven. applied successfully several perfect-information games (Lee et al., 2010;Chaslot et al., 2006; Bouzy & Chaslot, 2006; Coulom, 2006). therefore interesting seeMCTS also successfully applied imperfect-information game Poker. Two statisticsnodes important sampling actions MCTS, i.e.:1. value, va action node a. average reward simulated gamesvisited node.2. visit count, na action node a. represents number simulationsnode reached.crucial distinction work used MCTS perfect-information games, assume imperfect information, example opponent cards Poker. result, one reasoninformation sets (see Section 2.1) instead individual nodes. Therefore, part algorithmperformed information sets rather individual nodes. starting state game represented root node, initially node tree. MCTS consists repeatingfollowing four steps (illustrated Figure 3), long time left.1. Selection. Actions set encoded nodes game tree. chosen accordingstored statistics way balances exploitation exploration.exploiting, actions lead highest expected value selected. Less promising actionsstill explored due uncertainty evaluation (exploration). useUpper Confidence Bound applied Trees (UCT) rule select actions (Kocsis & Szepesvari,2006). UCT, set nodes (possible actions) reachable parent node,p. Using following equation, UCT selects child node parent node phighest value.argmaxaAva + Cln npna!.(2)va expected value node a, na visit count a, np visitcount p, parent node a. C coefficient balances exploration exploitation.higher value encourages longer exploration since nodes visited oftenreceive higher value. value usually tweaked preliminary experiments. Again, noteimperfect-information games, expected values visit counts stored updatedper information set.2. Expansion. leaf node selected, one several nodes added tree.tree grows simulated game. Please note tree memory deals gamenodes (assuming full information), information sets (which used selectionbackpropagating part algorithm).585fiP ONSEN , L ANCTOT & E J ONGRepeated X timesSelectionSelectionselection functionappliedTheTheselectionfunctionrecursivelyleafnodeappliedrecursivelyreachedleaf node reachedExpansionExpensionSimulationSimulationmorenodesnodesOneOnecreatedcreatedOne simulatedOnesimulatedgame isisplayedgameplayedBackpropagationBackpropagationTheresultresultgameofthisgamebackpropagated treebackpropagatedtreeFigure 3: Outline Monte-Carlo Tree Search (Chaslot et al., 2008).3. Simulation. newly expanded node, nodes selected according simulationpolicy end game. realistic simulations significant effectcomputed expected values. Examples simulation strategies Poker are: (1) randomsimulations, (2) roll-out simulations (3) on-policy simulations. first simulation strategy, one samples nodes uniformly set A. roll-out simulations, one assumesremaining active players call check end game. words, remaining active players stay active compete pot, stakes raised. Finally,on-policy simulation uses current estimations expected values action probabilitiesselect actions. paper, employ latter. specifically always take actionaccording Equation 2. produces simulations closest actual strategy.4. Backpropagation. reaching terminal node z (i.e., end simulated game),establish reward players (having full information buckets players).update information set contains prefix terminal history. visitcounts increased expected values modified according rewards obtainedterminal node.MCTS algorithm stopped, (potentially mixed) action distribution determinedvisit counts, i.e., actions information sets high visit count larger probabilityselected. perfect-information games, actions selected highest expectedvalue, end leads optimal payoff. imperfect-information games, Poker,potentially mixed strategy distributions required obtaining optimal payoff (e.g., seeNES Kuhn poker described Section 2.2). Therefore, ratio actions selecteddetermines probability distribution.3.2.2 ONTE -C ARLO C OUNTERFACTUAL R EGRET INIMIZATIONdescribe Monte-Carlo Counterfactual Regret Minimization (MCCFR) algorithm,first describe intuition behind Counterfactual Regret Minimization (CFR) algorithm, sinceMCCFR based it.586fiC OMPUTING PPROXIMATE NASH E QUILIBRIA ROBUST B EST-R ESPONSES U SING AMPLINGCFR employs full game-tree traversal self-play, updates player strategies informationsets iteration. Strategy updates based upon regret minimization. Imagine situationplayers playing strategy profile . Players may regret using strategyextent. particular, information set may regret taking particularaction instead following . Let Ia strategy identical except taken I. Let ZIsubset terminal histories prefix history set I; z ZI let z[I]prefix. counterfactual value vi (, I) defined as:vi (, I) =X(z[I]) (z[I], z)ui (z).(3)zZIalgorithm applies no-regret learning policy information set counterfactualvalues (Zinkevich et al., 2008). player starts initial strategy accumulates counterfactual regret action information set r(I, a) = v(Ia , I) v(, I)self-play. Minimizing regret playing information set also minimizes overallexternal regret, average strategies approach NE.MCCFR (Lanctot et al., 2009) avoids traversing entire game tree iteration stillimmediate counterfactual regrets unchanged expectation. Let Q = {Q1 , . . . , Qr }set subsets Z, union spans set Z. Qj referred blocksterminal histories. MCCFR samples one blocks considers terminal historiessampledP probability considering block Qj current iterationP block. Let qj > 0(where rj=1 qj = 1). Let q(z) = j:zQj qj , i.e., q(z) probability considering terminalhistory z current iteration. sampled counterfactual value updating block j is:vi (, I|j) =XzQj ZI1(z[I]) (z[I], z)ui (z)q(z)(4)Selecting set Q along sampling probabilities defines complete sample-based CFR algorithm. example, algorithm uses blocks composed terminal histories whosechance node outcomes equal called chance-sampled CFR. Rather full game-treetraversals algorithm samples one blocks, examines terminal historiesblock.Sampled counterfactual value matches counterfactual value expectation (Lanctot et al., 2009).is, Ejqj [vi (, I|j)] = vi (, I). So, MCCFR samples block information setcontains prefix terminal history block, computes sampled counterfactualregrets action, r(I, a) = vi ((Ia), I) vi ( , I). sampled counterfactual regretsaccumulated, players strategy next iteration determined applying regretmatching rule accumulated regrets (Hart & Mas-Colell, 2000). rule assigns probabilityaction information set. Define rI+ [a] = max{0, rI [a]}. Then:(I, a) =A(I) : rI [a] 01/|A(I)|rI+ [a]P+aA(I) rI [a]0rI [a] > 0(5)otherwise.rI [a] cumulative sampled counterfactual regret taking action I.least one positive regret, action positive regret assigned probability normalized587fiP ONSEN , L ANCTOT & E J ONGpositive regrets actions negative regret assigned probability 0.regrets negative, Equation 5 yields (I, a) = 0 information set. repair this,strategy reset default uniform random strategy.different ways sample parts game tree. focusstraightforward way, outcome sampling, described Algorithm 1. outcome-samplingQ chosen block contains single terminal history, i.e., Q Q, |Q| = 1.iteration one terminal history sampled updated information set alonghistory. sampling probabilities, Pr(Qj ) must specify distribution terminal histories.0specify distribution using sampling profile, 0 , Pr(z)= (z). Note choicesampling policy induce particular distribution block probabilities q(z). longi0 (a|I) > , exists > 0 q(z) > , thus ensuring Equation 4 well-defined.0algorithm works sampling z using policy 0 , storing (z). particular, -greedystrategy used choose successor history: probability choose uniformly randomlyprobability 1 choose based current strategy. single history traversed forward (to compute players probability playing reach prefix history, (h))backward (to compute players probability playing remaining actions history, (h, z)). backward traversal, sampled counterfactual regrets visitedinformation set computed (and added total regret). Here,wI ( (z[I]a, z) (z[I], z)) z[I]a v zr(I, a) =wI (z[I], z)otherwisewI =(z[I])ui (z)i.0(z)(6)algorithm requires tables stored information set; table number entriesequal number actions taken information set. Therefore, denote |Ai |maximum number actions available player information sets,space requirement MCCFR O(|I1 ||A1 | + |I2 ||A2 |). time required MCCFR, usingoutcome sampling, depends regret bounds desired . reach fixed -NE,probability 1 p number iterations required2 |A|M 2p 22smallest probability sampling terminal history histories, |A| maximum available actions information sets, |M | balance factor dependingrelativenumber decisions taken player throughout entire game propertyp|I| |I|. contrast, full CFR algorithm requires O(|A|M 2 /2 ) iterations; however,iterations MCCFR require sampling single history whereas iteration CFR requirestraversing entire game tree worst case. practice, one benefit outcome samplinginformation gained previous iterations quickly leveraged successive iterations.Algorithm 1 shows pseudocode entire algorithm. refer interested readerwork Lanctot et al. (2009), providing in-depth discussion, including convergence proofs.588fiC OMPUTING PPROXIMATE NASH E QUILIBRIA ROBUST B EST-R ESPONSES U SING AMPLINGData: root nodeData: Sampling scheme greedyData: Initialize information set markers: I, cI 0Data: Initialize regret tables: I, rI [a] 0Data: Initialize cumulative strategy tables: I, sI [a] 0Data: Initialize initial strategy: (I, a) = 1/|A(I)|1 = 1, 2, 3 . . .2current node root node3ELECT:4(current node 6= terminal)5P R EGRET ATCHING(rI ),6P G REEDY(P)7current node Select(current node, P )8end9current node P arent(current node)10U PDATE :11(current node 6= root node)12foreach A[I]13r = r(I, a) (sampled counterfactual regret)14rI [a] rI [a] + r15sI [a] sI [a] + (t cI )i (z[I])i (I, a)16end17cI18R EGRET ATCHING(rI )19current node P arent(current node)20end21 endAlgorithm 1: Outcome-sampling Monte-Carlo Counter-Factual Regret Minimization3.2.3 ONTE -C ARLO C OUNTERFACTUAL R EGRET E XAMPLEprovide example Algorithm 1 Kuhn Poker, shown Figure 1. algorithmstarts first iteration, selection phase. root node (a chance node), chanceoutcome K|Q sampled probability 16 . Following node, algorithm loads information set belonging first player received King actionstaken; let us call information set I1 . Since regret collected actions I1 yet, Pset uniform distribution U = ( 12 , 12 ), represent probabilities (pass, bet). Then,sampling distribution obtained P = (1 )P + U . Note regardless value, first iteration action equally likely sampled. action sampled P ;suppose bet. Following action, algorithm loads information set belongingsecond player received queen action made first player bet(I2 ). Similarly, algorithm constructs P P identical distributionsI1 ; suppose pass action sampled time. Finally, action taken terminal589fiP ONSEN , L ANCTOT & E J ONGnode reached. Therefore, terminal history sampled first iteration, z1 ,sequence: (K|Q, bet, pass).update phase, algorithm updates information sets touched nodestraversed sample reverse order. Note notation z1 [I1 ] represents subsequence(K|Q), z1 [I2 ] represents (K|Q, bet). sampled counterfactual regret computedaction I2 . Note u2 (z1 ) = u1 (z1 ) = 1. opponents reaching probability(z1 [I2 ]) =1 11= .6 212probability sampling z10(z1 ) =1 1 11= .6 2 224Therefore, wI2 = 2. two remaining things compute tail probabilities (z1 [I2 ], z) =12 (z1 [I2 ]a, z) = 1, pass action. Finally, equation 6 get1r(I2 , pass) = 2 (1 ) = 1,21r(I2 , bet) = (2 ) = 1.2updates line 13, regret table rI2 = (1, +1). average strategy tableupdated. reaching probability (z1 [I2 ]) product probabilities strategy choicesplayer 2, equal 1 since player 2 acted yet. players strategy currently2 (I2 , pass) = 2 (I2 , bet) = 21 . current iteration = 1 cI2 = 0, therefore averagestrategy updates table sI2 = ( 12 , 21 ). Finally cI2 set 1 (I2 ) = (0, 1) accordingequation 5.algorithm proceeds update tables kept I1 ,110u1 (z1 ) = 1,(z1 [I1 ]) = , (z1 ) = , therefore wI1 = 4.624tail reaching probabilities (z1 [I1 ], z) = 14 , (z1 [I1 ]a, z) =action. leads sampled counterfactual values12,betr(I1 , pass) = 1, r(I1 , bet) = 1.cI1 incremented 1. average strategy table update identical oneapplied I2 . Since previous actions taken player, reaching probability1, players current strategy uniform, I2 . Finally incremented 2entire process restarts.3.3 Experimentscurrent section, empirically evaluate chosen algorithms smaller domainKuhn Poker full-scale Poker. present experimental results Kuhn Poker Section3.3.1. give results Poker Section 3.3.2. Note Kuhn full-scale Pokerexplained Section 2.2.590fiC OMPUTING PPROXIMATE NASH E QUILIBRIA ROBUST B EST-R ESPONSES U SING AMPLINGGame Limit 2-p Poker0UCT MCCFR, E=0.6-0.30821-0.502385-0.27291-0.38137-0.211665-0.35938-0.219625-0.299085-0.201485-0.31999-0.17621-0.315805-0.15521-0.27771-0.17901-0.31643-0.17799-0.2864-0.186585-0.26078-0.15607-0.290925-0.17974-0.29087-0.15528-0.27865-0.14181-0.231025-0.12594-0.285545-0.162695-0.26514-0.159415-0.24142-0.141695-0.26353-0.133745-0.2314-0.18484-0.25223-0.13882-0.24581-0.16769-0.26161-0.136985-0.203455-0.154215-0.236695-0.18157-0.21148-0.152525-0.22165-0.17569-0.213335-0.152255-0.20121-0.151065-0.22558-0.14731-0.197915-0.149325-0.20694-0.138365-0.238875-0.15505-0.176595-0.136595-0.21927-0.144725-0.22413-0.167625-0.20264-0.126125-0.171715-0.1177-0.219025-0.1466-0.1911-0.182245-0.18643-0.10686-0.18665-0.137965-0.195105-0.142795-0.17549-0.12844-0.196955-0.138275-0.18438-0.152245-0.149855-0.11488-0.180895-0.149785-0.18449-0.160885-0.17541-0.154335-0.202345-0.135555-0.176805-0.135585-0.166755-0.172165-0.176525-0.140035-0.15277-0.14462-0.11999-0.13888-0.1564-0.119515-0.18582-0.159195-0.155025-0.12965-0.16708-0.150855-0.16455-0.111345-0.17555-0.132165-0.182095-0.14703-0.149315-0.14222-0.189185-0.144715-0.151055-0.14483-0.180865-0.143565-0.17185-0.14643-0.149485-0.15015-0.137985-0.157835-0.142525-0.166905-0.171325-0.15989-0.184765-0.12237-0.1488-0.13732-0.169455-0.15739-0.144705-0.151765-0.12328-0.14768-0.15946-0.14448-0.13819-0.142815-0.16202-0.14195-0.16011-0.17219-0.13438-0.154565-0.13179-0.14677-0.15241-0.14296-0.164015-0.157345-0.14014-0.13648-0.14606-0.16621-0.152785-0.12989-0.126545-0.18669-0.152755-0.162215-0.11338-0.05-0.1-0.15sb/h-0.2-0.25-0.3-0.35-0.4-0.45MCTS, C=17MCCFR, E=0.6-0.5+07+07+07+081.0E9.1E8.1E+077.1E+07+07+07+07+076.1E5.1E4.1E3.1E2.1E1.1E+06-0.551.0E#iteration100000020000003000000400000050000006000000700000080000009000000100000001100000012000000130000001400000015000000160000001700000018000000190000002000000021000000220000002300000024000000250000002600000027000000280000002900000030000000310000003200000033000000340000003500000036000000370000003800000039000000400000004100000042000000430000004400000045000000460000004700000048000000490000005000000051000000520000005300000054000000550000005600000057000000580000005900000060000000610000006200000063000000640000006500000066000000670000006800000069000000700000007100000072000000730000007400000075000000760000007700000078000000790000008000000081000000820000008300000084000000850000008600000087000000880000008900000090000000# iterationsFigure 4: Experimental results Monte-Carlo Counter-Factual Regret Minimization (MCCFR)Monte-Carlo Tree Search (MCTS) game Kuhn Poker (left) Poker (right).figures x-axis denotes number iterations algorithms ran. y-axisdenotes quality Nash-Equilibrium strategy learned far. experimentsKuhn Poker represented squared error (SQR-E) cumulative dominatederror (DOM-E), Poker use metric named small bets per hand (sb/h).metrics applies value close zero indicates near Nash-Equilibrium strategy.opponent Poker experiments approximated Nash Equilibrium strategy,computed MCCFR.3.3.1 K UHN P OKERran MCCFR MCTS game Kuhn Poker. C-constant MCTStweaked preliminary experiments set 2. suggested Balla & Fern (2009)C-constant set scale payoff range. Also, Auer, Cesa-Bianchi,& Fischer (2002) discuss modified version original Upper Confidence Bound (UCB) algorithm (on Upper Confidence Bound applied Trees (UCT) algorithm based) tunesexploration term. experiments, ran several runs MCTS varying valuesparameter C, took best experimental run. MCCFR used epsilon-greedysampling scheme. suggested earlier work (Lanctot et al., 2009), set relatively highvalue 0.6 cover large area search space.every 104 iterations measured performance current policy. Since equilibria known Kuhn Poker (see Section 2.2) compare strategy theoreticallycorrect one. evaluation compute squared error, simply correct NE probability minus current learned probability squared. also compute cumulative dominatederror, denotes summed probabilities selecting dominated actions.Figure 4 (left) confirm earlier results work Lanctot et al. (2009)Sturtevant (2008), namely MCCFR learns NE MCTS learns balanced situation(necessarily) NE. balanced situation MCTS eventually resides dependsparameter value C. MCCFR obtains squared errors dominated errors close zero,MCTS converged slightly NE playing dominated actions. However, also seeMCTS still unlearning dominated actions. Therefore, unlike MCCFR, MCTS591fiP ONSEN , L ANCTOT & E J ONGlearn perfectly rational strategies, exploitable. However, reasonable jobavoiding dominated mistakes. consequence, lose (much) NES.3.3.2 L ARGER EST OMAIN : P OKERevaluated policies learned MCTS MCCFR game Poker. reduce complexity task finding NES, decreased size game-tree applying bucketdiscretization (Billings, 2006) cards, along imperfect recall (i.e., buckets previousphases forgotten). phase, strategic strength private cards, along zeroboard cards, determines bucket.Learning Precomputed Nash Equilibriumexperiment use 10-bucket discretization MCCFR MCTS. MCCFR uses similarparameter settings compared experiments Kuhn Poker, MCTS change Cconstant 17. Again, value determined preliminary experiments. every 106 iterationsevaluate current policy learned MCTS MCCFR. Policies evaluated small betsper hand (sb/h), describes big blinds per hand average; quantity thusused reflect players playing skill. small bets per hand computed 105 gamespre-learned Nash-Equilibrium strategy (using MCCFR 10-bucket discretization). resultsshown Figure 4 (right). x-axis denotes number iterations, y-axis smallbets per hand. value close zero indicates strategy longer exploitedpre-computed NES, arguably converged (approximated) Nash Equilibrium itself.see MCTS converges fast balanced situation, though necessarilyNE. MCCFR hand converges considerably slower, unlike MCTS continueslearn better NE approximations. Given results, one may conclude MCTS learns reasonablygood strategies fast, MCCFR long run produce better NE approximations.interesting mention single iteration MCTS requires much less computationtime memory single iteration MCCFR. graph Figure 4 (right) plotted computation time performance, rather number iterations required, would seelarger advantage MCTS early phase learning. Clearly, end result would stillsame; certain point, MCCFR surpasses MCTS.Playing Benchmark Poker Botsget good measure strength policies, evaluated policies strongopponent bots provided software tool Poker Academy Pro, namely P OKI PAR B OT.detailed explanation P OKI experiments bot, refer readerwork Billings (2006). PAR B OT bot plays according NE strategy describedBillings et al. (2003). designed solely 2-player Poker, contrast P OKI,designed multi-player games. Since PAR B OT specializes two-player games, significantlyless exploitable two-player game P OKI, stochastic rule-based bot.ran large number offline iterations MCCFR MCTS, froze policies,evaluated them. addition 10-bucket discretization MCTS MCCFR, also usedMCCFR 100-bucket discretization examine effect finer abstraction. clarity,mention number buckets used algorithm name; e.g., MCCFR100 refersMCCFR 100 buckets. results shown Table 1. performed 104 evaluation gamessoftware tool Poker Academy Pro policy, estimated standard deviation0.06sb/h. MCCFR10, great deal iterations, wins small margin P OKI,592fiC OMPUTING PPROXIMATE NASH E QUILIBRIA ROBUST B EST-R ESPONSES U SING AMPLINGOpponentMCTS10MCCFR10MCCFR100P OKIPAR B OT0.077-0.1030.059-0.0910.1910.046Table 1: Experimental results Monte-Carlo Counter-Factual Regret Minimization (MCCFR)Monte-Carlo Tree Search (MCTS) two Poker bots. Outcomes reportedsmall bets per hand (sb/h). numbers behind algorithm names refer numberbuckets used card abstraction.losing small amount PAR B OT. loss may due chosen abstractions (10-bucketimperfect recall), due choice using outcome sampling (Lanctot et al., 2009). LookingMCCFR100, see abstraction level culprit; wins convincingly P OKIPAR B OT. MCTS10 surprisingly, knowing doesnt necessarily learn NES, performs slightlybetter MCCFR10 P OKI, although difference significant. PARBOT,MCTS10 strategy loses slightly MCCFR10, statistical significance.conclude, evaluated two state-of-the-art algorithms extensive-form games. confirmprevious theoretical claims results obtained experiments smaller game (Kuhn Poker),first time apply sampling techniques complex game Poker. MCTS validapproach one wants learn reasonably strong policies fast, necessarily NE,whereas MCCFR better choice quality strategy important learningtime memory constraints. However, techniques produce strategies competitivestrong Poker bots, especially fine abstractions used. sampling techniques showpromise complex domains, exclusively Poker.4. Robust Best-Response Learning via Monte-Carlo Restricted Nash Responsewell-known perfectly rational Nash-Equilibrium strategy (NES) necessarily bestresponse strategy (i.e., best counter-strategy) strategies rational strategy(Osborne & Rubinstein, 1994). opposition employs clearly inferior strategies,exploited best using tailored counter-strategies. resulting best-response strategy wouldprofitable Nash-Equilibrium strategy (NES), designed win instead designed lose. stresses importance opponent modeling games complex fullyanalyze, since expect opposition incapable playing perfectly rational strategy,profit playing best-response strategies. However, want becomeexploitable strategies, opponent model may inaccurate, playersmay switch strategies.section presents Monte-Carlo Restricted Nash Response (MCRNR), sample-based algorithm offline computation restricted Nash strategies complex extensive-form games.restricted Nash strategy essentially robust best-response strategy, i.e., exploits opponentsdegree based opponent model, preventing strategy becomesexploitable. new algorithm described section combines state-of-the-art algorithmgeneral technique, i.e., Monte-Carlo Counterfactual Regret Minimization (MCCFR) (Lanctotet al., 2009) (see Section 3.2.2) Restricted Nash Response (RNR) (Johanson et al., 2008; Jo-593fiP ONSEN , L ANCTOT & E J ONGhanson & Bowling, 2009). Given promising results applying sampling Counterfactual Regret Minimization (CFR), apply original Restricted Nash Response (RNR) technique usingMonte-Carlo Counterfactual Regret Minimization (MCCFR) underlying equilibrium solver.new algorithm, Monte-Carlo Restricted Nash Response (MCRNR), benefits samplingrelevant parts game tree. algorithm therefore able converge quickly robustbest-response strategies given model opponent(s).section structured follows. first outline related work computing bestresponse strategies. Then, introduce new algorithm, Monte-Carlo Restricted Nash Response(MCRNR). Finally, describe experiments validate new algorithm variety games,discussed Section 2.2.4.1 Computing Best-Response StrategiesPoker perfect domain investigating best-response strategies since ability anticipateopponents move highly influences outcome game. mention previousapproaches perform opponent modeling Poker. Then, discuss work Restricted NashResponse (RNR).4.1.1 G ENERAL PPONENT ODELINGOne approach Adaptive Imperfect Information game-tree search algorithm (Billings, 2006),opponent model integrated it. keeps track statistics outcomegame actions opponent decision nodes every possible betting sequence. problemapproach uses little generalization hence frequency counts limitedsmall number situations. general system opponent modeling obtained trainingneural network. Davidson, Billings, Schaeffer, Szafron (2000) use nineteen different parameters input nodes three output nodes representing possible actions. input parametersinclude information players, information betting history informationcommunity cards. Southey et al. (2005) use prior distributions opponents strategy spacecompute posterior using Bayes rule observations opponents decisions. alsoinvestigates several ways play appropriate response distribution.paper also integrate opponent model search technique order learnbest-response strategy. Unlike Billings (2006) learn model generalizes states.work also differs aforementioned studies learn robust best-response strategies,prevents strategy becoming exploitable itself.4.1.2 R ESTRICTED NASH R ESPONSEknown best-response strategy, words strategy maximally exploits opponent, profitable (pessimistic) NES, given model opponent accurate.Experiments Hoehn et al. game Kuhn Poker, validate claim. Johanson et al. (2008)argue best-response strategies sufficiently robust; best-response strategy may exploited strategies strategy current opponent, even opponentopponent model accurate. authors therefore introduce general technique namedRestricted Nash Response (RNR) put test Poker using chance-sampled Counterfactual Regret Minimization (CFR). Unlike Nash-Equilibrium strategies oblivious opponentplay, best-response strategies potentially exploitable, RNR strategies robust best594fiC OMPUTING PPROXIMATE NASH E QUILIBRIA ROBUST B EST-R ESPONSES U SING AMPLING*p**1122Game G**1222R1p2Game GGame GFigure 5: Illustration Restricted Nash Response. RNR technique transforms game;chance node outcome unrevealed (to unrestricted player) addedtop trees. new game, G0 , two subtrees: left subtree GRright subtree G. GR identical G except one player restricted playstrategy f ix . Think initial coin flip moderator either forces restrictedplayer use f ix strategy . opponent knowtwo options forced upon restricted player. causes information setscontaining nodes game merged, unrestricted playercannot tell apart.response strategies given model opponent policies (Johanson et al., 2008). shown RNRstrategies capable exploiting opponents, reasonable performance even modelwrong. RNR technique transforms existing game modified game; equilibriumsolver solves modified game using previously mentioned CFR algorithm, whereinassumed opponent plays according fixed strategy, specified model, certain probability, denoted parameter p. Otherwise, opponent plays according rationalregret-minimizing strategy (see Figure 5).p parameter indication confident model correct; thoughtconfidence value used set trade-off exploitation exploitability,respectively first indicates maximum amount win specific opponent strategy,second indicates maximum amount risk losing playing strategy. Setting p = 0leads unmodified game G (see Figure 5) solved, results game-theoreticsolution. overall solution exploitable (i.e., least break-even), alsomaximally exploit opponents. extreme, namely setting p = 1, result purebest-response strategy fixed strategy denoted opponent model. game GR ,opponent nodes action probabilities drawn opponent model. Focusing595fiP ONSEN , L ANCTOT & E J ONGgame results maximal exploitative strategy opponent model, potentially costbecoming exploitable strategies.5Calculating RNR response requires model opponents strategy, denoted f ix .6Suppose 2-player game, opponent (i.e., restricted) player player 2, f ix 2 .p,Define 2 f ix set mixed strategies form pf ix + (1 p)2 2arbitrary strategy 2 . set restricted best responses 1 1 is:(u2 (1 , 2 ))BRp,f ix (1 ) = argmaxp,2 2f ix(7)(p, f ix ) RNR equilibrium pair strategies (1 , 2 ) 2 BRp,f ix (1 ) 1BRp,f ix (2 ). pair, strategy 1 p-restricted Nash response f ix . counterstrategies f ix , p provides balance exploitation exploitability. fact, givenparticular value p, solving RNR-modified game assures best possible trade-offbest response equilibrium achieved.4.2 Monte-Carlo Restricted Nash Response (MCRNR)extend original RNR algorithm sampling. resulting new algorithm, MCRNR, benefits sampling relevant parts game tree. therefore able converge fastrobust best-response strategies. pseudo-code algorithm provided Algorithm 2.algorithm identical inputs compared MCCFR algorithm (see Algorithm 1),additional two components: (1) opponent model translates fixed strategy f ixso-called restricted player pr , (2) confidence value, p, assign model. learning opponent models, apply standard supervised learning method, namely J48 decisiontree learner Weka datamining tool. Similar work original RNR article (Johansonet al., 2008), use fixed value p.7sample terminal history h Z, either selecting actions based provided opponentmodel, based strategy obtained regret-matching. R EGRET ATCHING routineassigns probability action information set (according Equation 5). -greedysampling routine S() samples action probability1+ (1 )i (I, a).|A(I)|(8)sampling action, recursively call MCRNR routine given extended history,namely history h applying (see line 13). terminal node z, utilitiesdetermined backpropagated z[I] @ z.Regret average strategy updates applied algorithm returns recursivecall, lines 14 18. line 15 add sampled counterfactual regret (according Equation 6; takes input reaching probabilities utility sampled terminal history)5. Note generality RNR technique: since simply modifies extensive-form game, underlying solutiontechnique used solve game independent application RNR. Nonetheless, point referRNR algorithm mean original application RNR technique coupled CFR algorithm.6. refer reader back Section 2.1 overview notations used section.7. learning model data makes sense different values per information set confidencedepends many observations available per information set; counter-strategies using model built datacalled Data-Biased Responses (Johanson & Bowling, 2009).596fiC OMPUTING PPROXIMATE NASH E QUILIBRIA ROBUST B EST-R ESPONSES U SING AMPLING12345678910111213141516171819initialize: Information set markers: I, cI 0initialize: Regret tables: I, rI [a] 0initialize: Strategy tables: I, sI [a] 0initialize: Initial strategy: (I, a) = 1/|A(I)|input : starting history hinput : sampling scheme S() (e.g., -greedy)input : opponent model fixed strategy f ix restricted player prinput : Confidence value pinput : Current iterationMCRNR(h) =h Zreturn (ui (h), (h))elsepi P (h)chance node select chance nodeelse pi = prh prefix terminal history restricted subtree (I) f ix (I)else (I) R EGRET ATCHING(rIi )else(I) R EGRET ATCHING(rIi )Sample S(i (I))(u, ) MCRNR(h+a)foreach A(I)rI [a] rI [a] + r(I, a)sI [a] sI [a] + (t cI )i (I, a)endcIreturn (u, )20Algorithm 2: One iteration Monte-Carlo Restricted Nash Response algorithm.cumulative regret. line 16 average strategy updated using optimistic averaging,assumes nothing changed since last visit information set.8 Finally, strategytables updated new iteration starts. next iteration, another player becomesrestricted player. process repeated number times satisfactory; meanwhile,player assigned restricted player. iteration, average strategy (I, a)obtained normalizing sI . pr = 2 1 = 1 . pr = 1 2 = 2 .time, = (1 , 2 ) approaches RNR equilibrium.98. information update strategies, refer work Lanctot et al. (2009).9. Note Data-Biased Response (DBR) variant (Johanson & Bowling, 2009) works slightly different way.Instead selection restricting player root chance node, doneinformation set hidden restricted player (Johanson & Bowling, 2009). restricted playerforced used mixed strategy based confidence value current information set pConf . Lines 8 9597fiP ONSEN , L ANCTOT & E J ONG4.3 Experimentsperformed experiments smaller games Poker. smaller games performed twotypes experiments; one characterize relationship exploitation exploitabilityevaluating convergence rates sampling versus non-sampling algorithms. Pokerevaluate strength learned strategies benchmark opponent players.4.3.1 MALLER G AMESran two separate sets experiments games OCP (we use deck size N = 500),Goofspiel, Bluff, PAM. first set experiments aims characterize relationship exploitation exploitability different values p. second set experimentscomparison convergence rates RNR MCRNR. cases perfect opponent modelstaken runs MCCFR set 0.6. Results shown Figures 6 7.Results first set experiments may influence choice p. exploitation muchimportant exploitability value 0.9 suggested; hand noticeable boost exploitation achieved small loss exploitability 0.5 p 0.8.every game except Bluff seems region p [0.97, 1] high impact magnitudetrade-off. Results Figure 7 confirm performance benefit sampling since MCRNRproduces better NE approximation less time, especially early iterations. particularly important attempting learn online (i.e. playing, rather beforehand),time might limited.4.3.2 L ARGER EST OMAIN : P OKERevaluated policies learned MCRNR two poker bots, namely P OKI PAR B OT.opponents also used experiments game theoretic (or rational) player Section3. experimental settings well chosen abstractions identical experimentsSection 3.3.2. remind reader PAR B OT bot designed play according NESabstracted game; therefore less exploitable P OKI.MCRNR implementation Poker restricts player information set, essencerepresents MCDBR algorithm (see Section 4.2). However, unlike original DBR paper,experiments pConf global constant value biased data. resulting algorithm therefore mix two algorithms. continue using name MCRNRhere, reader note original RNR algorithm slightly different.10opponent modeling, deliberately chose setup realistically difficult.observed 20K games played P OKI PAR B OT, opposed to, e.g., 1million games used Johanson Bowling (2009) RNR. games used gatheropponent data concerning two bots. Learning opponent model approached patternrecognition task (Bishop, 2006), wherein model learned based experience (in case,previous Poker games players modeled). model used estimatebehavior opponents unseen situations. Since opponent data gathered rather sparsedue 20K games, since frequency count cannot generalize, chose apply standardAlgorithm 2 replaced (I) pConf f ix (I) + (1 pConf )i (I), pConf specific valuep per information set.10. Based experimental results smaller games, noticed difference vanilla RNR MCDBRfixed pConf small algorithms thus similar.598fiC OMPUTING PPROXIMATE NASH E QUILIBRIA ROBUST B EST-R ESPONSES U SING AMPLINGExploitation/Exploitability Trade-offs Goofspiel(5)Exploitation/Exploitability Trade-offs Bluff(1,1,6)0.120.08ExploitationExploitation0.10.060.040.02000.30.60.91.21.51.80.110.10.090.080.070.060.050.040.030.020.0102.100.30.6ExploitabilityExploitation/Exploitability Trade-offs OCP(500)1.21.51.8Exploitation/Exploitability Trade-offs PAM(3,3,8)0.10.120.090.10.08ExploitationExploitation0.9Exploitability0.070.060.050.080.060.040.020.040.03000.030.060.090.120.150.180Exploitability1234567ExploitabilityFigure 6: trade-off exploitation exploitability Monte-Carlo Restricted NashResponse. exploitation value gain payoff using Monte-CarloRestricted Nash Response equilibrium profile compared Nash equilibrium profile, summed pr {1, 2}. exploitability bi (i ) summed =pr {1, 2}. value p used, bottom-left point top-right point, was:0, 0.5, 0.7, 0.8, 0.9, 0.93, 0.97, 1.decision tree induction algorithm (i.e., J48 algorithm Weka data-mining tool) learnopponent model sparse data. provided J48 algorithm five simple features,namely (1) starting seat relative button, (2) sum bets raises game, (3)sum bets raises current phase, (4) sum bets raises modeled playergame, finally (5) bucket modeled player (if observed). specificphase, learn model predicts strategy modeled player. set p fixed value0.75.11 ran offline iterations MCRNR, froze policy, evaluated it. results shownTable 2, including results MCCFR, already presented earlier. performed 104evaluation games player. Again, provide mostly results 10-bucket abstraction(labeled MCRNR10). 100-bucket abstraction (MCRNR100) used well, P OKI,demonstrate effect finer abstraction levels.11. value adapted based experience specific information set, done data-biasedapproach (Johanson & Bowling, 2009).599fiP ONSEN , L ANCTOT & E J ONGConvergence Rates Bluff(1,1,9)1.8RNRMCRNR1.41.210.80.60.40.200500001000001500002000000Total time (seconds)0.255000100001500020000Total time (seconds)Convergence Rates OCP(500)Convergence Rates PAM(3,3,13)18RNRMCRNRRNRMCRNR160.2BR ConvergenceBR ConvergenceRNRMCRNR1.6BR ConvergenceBR ConvergenceConvergence Rates Goof(7)21.81.61.41.210.80.60.40.200.150.10.051412108642000100020003000400050000Total time (seconds)100002000030000Total time (seconds)Figure 7: convergence rates Restricted Nash Response versus Monte-Carlo Restricted NashResponse. Fixed strategy profiles f ix generated using MCCFR runf ix 0.1. data point graphs represent two separate runs average profiles ( r1 , 2 ) ( 1 , r2 ), superscript r represents restricted player.profile interest = ( 1 , 2 ). value y-axis = b1 ( 2 ) + b2 ( 1 ).profile RNR equilibrium minimized. Note necessary approach 0 p > 0; strategies may always somewhat exploitable dueopponent exploitation.expected, MCRNR exploits P OKI considerably MCCFR, namely 0.369 sb/h(using 10-bucket abstraction) 0.482 sb/h (100 buckets). Interestingly, depicted Figure 8,even MCRNR10 learned exploit P OKI 20 million sampled iterations. notesampled iteration, nodes touched (i.e., information sets updated alonghistory sampled terminal node), RNR (and CFR, matter) iterationinformation sets updated. Consequently, 20 million sampled iterations MCRNR (or MCCFR) map far less full-backup iterations RNR (or CFR), require much less computationtime 20 million full backups.PAR B OT, plays better NES approximation, improvement performancealso observed, here, difference significant. surprising, given PAR -600fiC OMPUTING PPROXIMATE NASH E QUILIBRIA ROBUST B EST-R ESPONSES U SING AMPLINGFigure 8: online evaluation MCRNR policy learning P OKI. botplaying 1, 000 online games, approximated 6 million offline iterations MonteCarlo Restricted Nash Response, using 10-bucket abstraction, run.OpponentMCCFR10MCRNR10MCCFR100MCRNR100P OKIPAR B OT0.059-0.0910.369-0.0390.1910.0460.4820.061Table 2: Experimental results MCRNR versus two bots. repeat results Monte-CarloCounter-Factual Regret Minimization (MCCFR) reported Section 3. Outcomessmall bets per hand (sb/h). Numbers behind algorithm names refer abstraction level(number buckets).B OT (extremely) exploitable Poki. Clearly, though, MCRNR performs similarlyPAR B OT MCCFR, implying MCRNR policy plays dominated actions.conclusion, P OKI well PAR B OT, MCRNR finds least equally goodpolicy MCCFR. P OKI, exploitable opponent, benefit algorithm becomes apparent; MCRNR policy earns much MCCFR policy, even coarse abstraction(compare 0.191 sb/h MCCFR100 0.369 sb/h MCRNR10; coarser abstraction).also deliberately limited amount data available opponent model illustrateperformance new algorithm difficult conditions. ideal conditions, i.e.,prominently opponent data, algorithm expected outperformMCCFR terms (simulated) money playing exploitable opponent,outperform RNR MCCFR terms time required find good policy.5. Conclusionarticle highlights two contributions field decision-making complex partiallyobservable stochastic games. first applied two existing recent search techniques use Monte601fiP ONSEN , L ANCTOT & E J ONGCarlo sampling task approximating Nash-Equilibrium strategy (NES), namely MonteCarlo Tree Search (MCTS) Monte-Carlo Counterfactual Regret Minimization (MCCFR).algorithms compared game complex use, namely two-player LimitTexas HoldEm Poker. MCTS used predominantely perfect-information gamesGo. games, algorithm proven compute NES. imperfect-information games, balanced situations learned necessarily Nash-Equilibrium (NE) (Sturtevant, 2008).experiments, confirm finding: algorithm indeed learn reasonably strong policiesPoker, drawback strategies necessarily NE. MCCFR handalready shown converge NE smaller imperfect information games,ones outlined Section 2.2 (Lanctot et al., 2009). apply first time complexgame Poker, show indeed approximate NES. initial convergence MCCFRslower MCTS. may due fact used outcome sampling.sampling schemes, e.g., external sampling (Lanctot et al., 2009), may lead MCCFR convergingfast MCTS (where fast measured number iterations required). mentionedtypical iteration MCCFR takes significantly longer (in actual time) one MCTS,due additional computational complexity involved backpropagation process. MCCFR alsotakes memory statistics required computing strategy distributions.second contribution relates observation Nash-Equilibrium strategies necessarily best deal clearly irrational opposition (i.e., players playing NES). tailoredbest-response strategy yield profit. Pure best-response strategies however may brittleexploitable strategies one trained against. present MonteCarlo Restricted Nash Response (MCRNR), sample-based algorithm computation restricted Nash strategies, essentially robust best-response strategies (1) exploit irrational opponents compared NES (2) (too) exploitable strategies. algorithmcombines advantages two state-of-the-art existing algorithms, i.e., MCCFR RestrictedNash Response (RNR). MCRNR samples relevant parts game tree. therefore ableconverge faster robust best-response strategies RNR. evaluate algorithm varietyimperfect-information games small enough solve yet large enough strategicallyinteresting. empirically show MCRNR learns much quicker standard RNR smallergames. also apply MCRNR large game Poker, deliberately choosing hard settings, i.e.,relatively iterations come policy, relatively little opponent data. Evenhard settings, MCRNR learns exploit strong (yet exploitable) opponent bot P OKI significantlyNES learned MCCFR, performing similarly MCCFR strong(hardly exploitable) opponent bot PAR B OT. MCRNR achieves performance fractioncomputation time required previous algoritms.strong results obtained MCCFR MCRNR complex game two-player Pokerpoint many possible applications (refinements of) algorithms. prominently,see ample opportunity continued work Poker. One first applications interest twoplayer Poker even finer abstractions. show 100-bucket abstraction performs muchbetter 10-bucket one. Indeed, state-of-the-art two-player NE bots use strategies computedextremely fine-grained abstractions. Less abstractions would improve performance considerably opponent bots used article. However, settings, would requireopponent-model data, also need allow iterations learn policies. Second, integrating Data-Biased Response (DBR) approach may lead increased performance. Third,would highly interesting evaluate performance algorithms Poker602fiC OMPUTING PPROXIMATE NASH E QUILIBRIA ROBUST B EST-R ESPONSES U SING AMPLINGtwo players. zero-sum games two players, NES longer guaranteedlose; coalitions players may formed. Nonetheless, first work applying algorithms CFR games two players suggests NES still strongstrategy (Risk & Szafron, 2010). would interesting determine whether MCCFRMCRNR beneficial (for speed convergence quality solution convergedto) three-player games two-player game.Acknowledgmentsauthors thank Michael Johanson extensive commentary article, valuableinput Restricted Nash Response algorithm Poker research University Albertageneral. also thank anonymous reviewers editors valuable input.ReferencesAuer, P., Cesa-Bianchi, N., & Fischer, P. (2002). Finite-time analysis multi-armed banditproblem. Machine Learning, 47(2-3), 235256.Balla, R. K., & Fern, A. (2009). UCT tactical assault planning real-time strategy games.International Joint Conference Artificial Intelligence (IJCAI-2009).Billings, D. (2006). Algorithms Assessment Computer Poker. Ph.D. dissertation. UniversityAlberta.Billings, D., Burch, N., Davidson, A., Holte, R. C., Schaeffer, J., Schauenberg, T., & Szafron, D.(2003). Approximating game-theoretic optimal strategies full-scale poker. Gottlob, G.,& Walsh, T. (Eds.), Proceedings Eighteenth International Joint Conference ArtificialIntelligence (IJCAI-03), pp. 661668. Morgan Kaufmann.Bishop, C. M. (2006). Pattern Recognition Machine Learning. Springer.Bouzy, B., & Chaslot, G. (2006). Monte-carlo go reinforcement learning experiments. IEEE2006 Symposium Computational Intelligence Games, Reno, USA, pp. 187194.Chaslot, G. M. J.-B., Saito, J.-T., Bouzy, B., Uiterwijk, J., & van den Herik, H. (2006). Montecarlo strategies computer go. Schobbens, P.-Y., Vanhoof, W., & Schwanen, G. (Eds.),Proceedings 18th BeNeLux Conference Artificial Intelligence, pp. 8390.Chaslot, G. M. J.-B., Winands, M., Uiterwijk, J., van den Herik, H., & Bouzy, B. (2008). Progressivestrategies monte-carlo tree search. New Mathematics Natural Computation, 4(3),343357.Coulom, R. (2006). Efficient selectivity backup operators monte-carlo tree search. van denHerik, H., Ciancarini, P., & Donkers, H. (Eds.), Proceedings 5th International Conference Computer Games, Vol. 4630 Lecture Notes Computer Science (LNCS), pp.7283. Springer-Verlag, Heidelberg, Germany.Davidson, A., Billings, D., Schaeffer, J., & Szafron, D. (2000). Improved opponent modelingpoker. Proceedings 2000 International Conference Artificial Intelligence(ICAI2000), pp. 14671473.Fudenberg, D., & Tirole, J. (1991). Game Theory. MIT Press, Cambridge, MA.603fiP ONSEN , L ANCTOT & E J ONGGordon, G. J. (2005). No-regret algorithms structured prediction problems. Tech. rep. CMUCALD-05-112, Carnegie Mellon University.Hart, S., & Mas-Colell, A. (2000). simple adaptive procedure leading correlated equilibrium.Econometrica, 68(5), 11271150.Hoda, S., Gilpin, A., Pena, J., & Sandholm, T. (2010). Smoothing techniques computing Nashequilibria sequential games. Mathematics Operations Research, 35(2), 494512.Hoehn, B., Southey, F., & Holte, R. C. (2005). Effective short-term opponent exploitation simplified poker. Proceedings National Conference Artificial Intelligence (AAAI),pp. 783788. AAAI Press.Isaacs, R. (1965). Differential Games: Mathematical Theory Applications WarfarePursuit, Control Optimization. John Wiley & Sons. Research Problem 12.4.1.Johanson, M., & Bowling, M. (2009). Data biased robust counter strategies. ProceedingsTwelfth International Conference Artificial Intelligence Statistics (AISTATS), pp.264271.Johanson, M., Zinkevich, M., & Bowling, M. (2008). Computing robust counter-strategies.Advances Neural Information Processing Systems 20 NIPS.Kocsis, L., & Szepesvari, C. (2006). Bandit Based Monte-Carlo Planning. Furnkranz, J., Scheffer,T., & Spiliopoulou, M. (Eds.), Machine Learning: ECML 2006, Vol. 4212 Lecture NotesArtificial Intelligence, pp. 282293.Kuhn, H. W. (1950). Simplified two-person poker. Contributions Theory Games, 1, 97103.Lanctot, M., Waugh, K., Zinkevich, M., & Bowling, M. (2009). Monte carlo sampling regretminimization extensive games. Advances Neural Information Processing Systems 22(NIPS), pp. 10781086.Lee, C.-S., Wang, M.-H., Chaslot, G.-B., Hoock, J.-B., Rimmel, A., Teytaud, O., Tsai, S.-R., Hsu,S.-C., & Hong, T.-P. (2010). computational intelligence mogo revealed taiwanscomputer go tournaments. IEEE Transactions Computational Intelligence AIgames, 1, 7389.Nash, J. (1951). Non-cooperative games. Annals Mathematics, 54(2), 286295.Osborne, M. J., & Rubinstein, A. (1994). Course Game Theory. MIT Press.Risk, N. A., & Szafron, D. (2010). Using counterfactual regret minimization create competitivemultiplayer poker agents. Proc. 9th Int. Conf. Autonomous Agents MultiagentSystems (AAMAS 2010), pp. 159166.Ross, S. M. (1971). Goofspiel game pure strategy. Journal Applied Probability, 8(3),621625.Sandholm, T. (2010). state solving large incomplete-information games, applicationpoker. AI Magazine, 31(4), 1332.Schaeffer, J. (2001). gamut games. AI Magazine, 22, 2946.Shafiei, M., Sturtevant, N., & Schaeffer, J. (2009). Comparing UCT versus CFR simultaneousgames. GIGA Workshop General Game Playing IJCAI.604fiC OMPUTING PPROXIMATE NASH E QUILIBRIA ROBUST B EST-R ESPONSES U SING AMPLINGSklansky, D. (2005). Theory Poker (Fourth ed. edition). Las Vegas: Two plus two.Southey, F., Bowling, M., Larson, B., Piccione, C., Burch, N., Billings, D., & Rayner, D. C. (2005).Bayes bluff: Opponent modelling poker. Proceedings 21st Conference Uncertainty Artificial Intelligence (UAI 05), pp. 550558.Sturtevant, N. R. (2008). analysis uct multi-player games. Computers Games.von Neumann, J., & Morgenstern, O. (1944). Theory Games Economic Behavior. PrincetonUniversity Press.Waugh, K., Zinkevich, M., Johanson, M., Kan, M., Schnizlein, D., & Bowling, M. (2009). practical use imperfect recall. Proceedings 8th Symposium Abstraction, Reformulation Approximation (SARA).Zinkevich, M., Johanson, M., Bowling, M., & Piccione, C. (2008). Regret minimization gamesincomplete information. Advances Neural Information Processing Systems 20NIPS.605fiJournal Artificial Intelligence Research 42 (2011) 353-392Submitted 5/11; published 11/11Learning Make Predictions Partially ObservableEnvironments Without Generative ModelErik Talvitieerik.talvitie@fandm.eduMathematics Computer ScienceFranklin Marshall CollegeLancaster, PA 17604-3003, USASatinder Singhbaveja@umich.eduComputer Science EngineeringUniversity MichiganAnn Arbor, MI 48109-2121, USAAbstractfaced problem learning model high-dimensional environment,common approach limit model make restricted set predictions, therebysimplifying learning problem. partial models may directly useful makingdecisions may combined together form complete, structured model. However, partially observable (non-Markov) environments, standard model-learning methodslearn generative models, i.e. models provide probability distribution possible futures (such POMDPs). straightforward restrict models makecertain predictions, always simplify learning problem.paper present prediction profile models: non-generative partial models partiallyobservable systems make given set predictions, therefore far simplergenerative models cases. formalize problem learning predictionprofile model transformation original model-learning problem, show empirically one learn prediction profile models make small set importantpredictions even systems complex standard generative models.1. IntroductionLearning model dynamics environment experience critical capability artificial agent. Agents learn make predictions future eventsanticipate consequences actions use predictions planmake better decisions. agents environment complex, however, learning problem pose serious challenges. One common approach dealing complexenvironments learn partial models, focusing model-learning problem makingrestricted set particularly important predictions. Often predictionsneed made, much complexity dynamics modeled safely ignored. Sometimes partial model directly useful making decisions, instancemodel makes predictions agents future rewards (e.g., see McCallum, 1995;Mahmud, 2010). cases, many partial models making restricted predictionscombined form complete model in, instance, factored MDPs (Boutilier,Dean, & Hanks, 1999), factored PSRs (Wolfe, James, & Singh, 2008), collectionslocal models (Talvitie & Singh, 2009b).c2011AI Access Foundation. rights reserved.fiTalvitie & Singhcommon approach learning partial model apply abstraction(whether learned supplied domain expert) filters detail training data irrelevant making important predictions. Model-learning methodsapplied abstract data, typically learning problemtractable result. However, especially case partially observable systems, abstraction alone may sufficiently simplify learning problem, even (as seesubsequent examples) model asked make intuitively simple predictions.counter-intuitive complexity learning partial model partially observable casedirect result fact standard model-learning approaches partially observable systems learn generative models attempt make every possible predictionfuture cannot straightforwardly restricted making particularlyimportant predictions.paper present alternative approach learns non-generative modelsmake specified predictions, conditioned history. following illustrativeexample, see sometimes small set predictions necessarygood control performance learning make predictions high-dimensionalenvironment using standard generative models pose serious challenges. contrastsee exists simple, non-generative model make maintainpredictions form learning target method.1.1 ExampleConsider simple game Three Card Monte. dealer, perhaps crowded street,three cards, one ace. dealer shows location ace, flipscards, mixes swapping two cards every time step. playergame must keep track location ace. Eventually dealer stops mixingcards asks guess. player correctly guesses ace is, winmoney. guess wrong, lose money.Consider artificial agent attempting learn model dynamics gameexperience. takes sequence actions perceives sequence observations.raw data received agent includes rich, high-dimensional scene includingactivities crowd, movement cars, weather, well game (thedealer swapping cards). Clearly, learning model encompasses complexphenomena infeasible unnecessary. order win game, agent needsfocus making predictions cards, need anticipate future behavior city scene around it. particular, agent need make three predictions:flip card 1, ace? corresponding predictions cards 23. One safely ignore much detail agents experience still makeimportant predictions accurately. one filters irrelevant detail, agentsexperience might look like this:bet pos2 watch swap1, 2 watch swap2, 3 . . . ,agent takes bet action, starting game, observes dealer showingcard position 2. agent takes watch action, observes dealer swappingcards 1 2, takes watch action again, observes dealer swapping cards 2 3,354fiLearning Make Predictions Without Generative Modeldealer prompts agent guess (note uncontrolledsystem; watch indeed action agent must select over, say, reachingflipping cards itself, real game Three Card Monte would certainly resultnegative utility!) data reflects movement cards. One could learnmodel using new data set learning problem would far simplersince complex irrelevant phenomena like crowd weather ignored.Markov case, agent directly observes entire state environmenttherefore learn make predictions direct function state. Abstraction simplifiesrepresentation state thereby simplifies learning problem. Note, however,Three Card Monte problem partially observable (non-Markov). agent cannotdirectly observe state environment (the location ace statedealers mind hidden agent). partially observable case, agentmust learn maintain compact representation state well learn dynamicsstate. common methods achieve this, expectation-maximization(EM) learning POMDPs (Baum, Petrie, Soules, & Weiss, 1970), learn generative modelsprovide probability distribution possible futures.Three Card Monte, even irrelevant details ignored datacontains information cards movement, generative model still intractably complex! generative model makes predictions future events.includes predictions model meant make (such whether flipping card 1next time-step reveal ace) also many irrelevant predictions. generativemodel, also predict, instance, whether flipping card 1 10 time-stepsreveal ace whether cards 1 2 swapped next time-step. makepredictions, model must capture dynamics cards alsodealers decision-making process. dealer decides cards swap usingcomplex process (as human dealer might) problem learning generative modelabstract system correspondingly complex.course, Three Card Monte, predicting dealers future behavior entirelyunnecessary win. required maintain aces current location time.such, learning model devotes complexity anticipating dealersdecisions counter-intuitive best. far reasonable model seen Figure 1.states model labeled predictions aces location.transitions labeled observations dealers behavior. agent playsgame, could use model maintain predictions location acetime, taking dealers behavior account, predicting dealers futurebehavior. Note non-generative model. provide distributionpossible futures cannot used simulate worldpredict dealers next move. provides limited set conditional predictionsfuture, given history past actions observations. hand,far simpler generative model would be. model dealersdecision-making process, model 3 states, regardless underlying processused dealer.model Figure 1 example term prediction profile model.paper formalize prediction profile models present algorithm learningdata, assumptions (to specified established necessary355fiTalvitie & SinghFigure 1: Maintaining predictions location ace Three Card Monte. Transitions labeled dealers swaps. States labeled predictedposition special card.terminology). empirically demonstrate partially observable systemsprove complex standard generative model-learning methods, possiblelearn prediction profile model makes small set important predictions allowagent make good decisions. next sections formally describe settingestablish notation terminology formalize general learning problemaddressed. Subsequent sections formally present prediction profile modelsalgorithm learning them, well several relevant theoretical empirical results.1.2 Discrete Dynamical Systemsfocus discrete dynamical systems. agent finite set actionstake environment finite set observations produce. everytime step i, agent chooses action ai environment stochastically emitsobservation oi O.Definition 1. time step i, sequence past actions observations sincebeginning time hi = a1 o1 a2 o2 . . . ai oi called history time i.history time zero, agent taken actions seen observationsh0 , called null history.1.2.1 Predictionsagent uses model make conditional predictions future events, given history actions observations given future behavior. environmentassumed stochastic, predictions probabilities future events. primitivebuilding block used describe future events called test (after Rivest & Schapire, 1994;Littman, Sutton, & Singh, 2002). test simply sequence actions observations356fiLearning Make Predictions Without Generative Modelcould possibly occur, = a1 o1 . . . ak ok . agent actually takes action sequenceobserves observation sequence t, say test succeeded. predictionp(t | h) probability test succeeds history h, assuming agent takesactions test. Essentially, prediction test answer questiontake particular sequence actions, probability would seeparticular sequence observations, given history far? Formally,defp(t | h) = Pr(o1 | h, a1 )Pr(o2 | ha1 o1 , a2 ) . . . Pr(ok | ha1 o1 a2 o2 . . . ak1 ok1 , ak ).(1)Let set tests (that is, set possible action-observation sequenceslengths). set possible histories H set action-observationsequences could possibly occur starting null history, null history itself:defH = {t | p(t | h0 ) > 0} {h0 }.model make prediction p(t | h) h H makeconditional prediction future (Littman et al., 2002). representsprobability distribution futures, model used sampledistribution order simulate world, sample possible future trajectories.such, call model makes predictions generative model.Note use word generative closely related broader sensegeneral density estimation. one attempting represent conditional probabilitydistribution Pr(A | B), generative approach would represent full joint distribution Pr(A, B) conditional probabilities computed Pr(A,B)Pr(B) .say, generative model sense makes predictions even variables wishcondition on. non-generative or, settings, discriminitive approach wouldinstead directly represent conditional distribution, taking value B un-modeledinput. non-generative approach sometimes result significant savings Pr(B)difficult represent/learn, Pr(A | B) relatively simple (so long one trulydisinterested modeling joint distribution).particular setting, generative model one provides probability distribution futures (given agents actions). such, one would use generative model0). fact, Equation 1 onecompute p(t | h) particular h p(ht|hp(h|h0 )see prediction multi-step test computed predictionsone-step tests:p(a1 o1 a2 o2 . . . ak ok | h) = p(a1 o1 | h)p(a2 o2 | ha1 o1 ) . . . p(ak ok | ha1 o1 a2 o2 . . . ak ok ).leads simple definition generative model:Definition 2. model provide predictions p(ao | h) actions A,observations histories h H generative model.non-generative model, then, would make one-step predictions historiesand, consequently, would directly represent prediction p(t | h) history hun-modeled input. would condition given history, necessarily capablecomputing probability history sequence. saw Three Card Monteexample, beneficial making maintaining predictions substantiallysimpler making predictions every possible action-observation sequence.357fiTalvitie & SinghNote test describes specific future event (a sequence specific actionsobservations). many cases one might wish make predictions abstractevents. achieved composing predictions many tests. instance settests (Wingate, Soni, Wolfe, & Singh, 2007) sequence actions set observationsequences. set test succeeds agent takes specified action sequence seesobservation sequence contained within set occur. traditional tests allowagent, instance express question go outside, probability seeexact sequence images? set test express far useful, abstract questiongo outside, probability sunny? grouping togetherobservations sunny day. Even generally, option tests (Wolfe & Singh, 2006; Soni& Singh, 2007) express future events agents behavior described abstractlywell resulting observations. types abstract predictions computedlinear combination set concrete predictions.1.2.2 System Dynamics Matrix Linear Dimensionsometimes useful describe dynamical system using conceptual object calledsystem dynamics matrix (Singh, James, & Rudary, 2004). system dynamics matrixcontains values possible predictions, therefore fully encodes dynamicssystem. Specifically,Definition 3. system dynamics matrix dynamical system infinity-by-infinitymatrix. column corresponding every test . row correspondingevery history h H. ijth entry system dynamics matrix predictionp(tj | hi ) test corresponding column j history corresponding rowentry every history-test pair.Though system dynamics matrix infinitely many entries, many casesfinite rank. rank system dynamics matrix thought measurecomplexity system (Singh et al., 2004).Definition 4. linear dimension dynamical system rank correspondingsystem dynamics matrix.popular modeling representations, linear dimension major factorcomplexity representing learning generative model system. instance,POMDPs, number hidden states required represent system lower-boundedlinear dimension. work adopt linear dimension measurecomplexity dynamical system. say system simpler another,mean lower linear dimension.1.2.3 Markov Propertydynamical system Markov one needs know history order makepredictions future events recent observation.Definition 5. system Markov two histories h h (that may nullhistory), two actions , observation o, test t, p(t | hao) = p(t | h o).358fiLearning Make Predictions Without Generative ModelMarkov case use notational shorthand p(t | o) indicate predictionhistory ends observation o. Markov case, observationscontain information needed make prediction future, oftencalled state (because describe state world). system Markov,partially observable. partially observable systems predictions depend arbitrarilyentire history. focus partially observable case.2. Learning Make Predictionswork assume that, Three Card Monte, though agent may livecomplex environment, small set important predictions make.predictions could identified important designer, learningprocess. address problem identifying predictions made,rather focus problem learning make predictions, identified.general, imagine given finite set = {t1 , t2 , . . . , tm } testsinterest would like model make accurate predictions. termtest construed broadly, possibly including abstract tests addition rawsequences actions observations. tests interest future events modelpredict. instance, Three Card Monte problem, order perform wellagent must predict whether see ace flips card.three one-step tests interest: f lip1 ace, f lip2 ace, f lip3 ace (representingfuture events agent flips card 1, 2, 3, respectively, sees ace).agent learn maintain probability events time, wingame.such, general problem learn function : H [0, 1]mdef(h) = hp(t1 | h), p(t2 | h), . . . , p(tm | h)i,(2)is, function histories predictions test interest (which referpredictions interest) history. Note output necessarilyprobability distribution. tests interest may selected arbitrarily thereforeneed represent mutually exclusive exhaustive events. call particular vectorpredictions tests interest prediction profile.Definition 6. call (h) prediction profile history h.describe two existing general approaches learning : learning direct function history predictions (most common Markov case), learning fullygenerative model maintains finite-dimensional summary history (commonpartially observable case). strengths weaknesses approaches learning. Section 2.3 contrast approach, combines strengthsapproaches.2.1 Direct Function Approximationsystem Markov, learning conceptually straightforward; essentiallyproblem learning function observation (state) predictions. Rather359fiTalvitie & Singhlearning takes histories input, one instead learn function arkov :[0, 1]m , maps observation predictions tests interest resultinghistories end observation. Note that, immediate consequence,discrete Markov systems finite number distinct prediction profiles. fact,distinct prediction profiles observations.number observations number tests interest small enough,arkov represented |O| |T | look-up table, entries estimated usingsample averages1 :p(ti | o) =# times succeeds histories ending.# times acts(t) taken histories ending(3)main challenge learning Markov models arises number observationslarge. becomes necessary generalize across observations, using data gatheredone observation learn many others. Specifically, one may able exploitfact observations associated similar (or identical) predictionprofiles (that is, predictions tests interest) share data amongst them.Restricting models attention predictions afford generalization,learning partial model beneficial Markov setting.Even system partially observable, one still attempt learn directly,typically performing sort regression set features entire histories.instance, U-Tree (McCallum, 1995) takes set history features learns decision treeattempts distinguish histories result different expected asymptotic returnoptimal behavior. Wolfe Barto (2006) apply U-Tree-like algorithm ratherrestricting model predicting future rewards, learn make predictionspre-selected set features next observation (a special casegeneral concept tests interest). Dinculescu Precup (2010) learn expected valuegiven feature future direct function given real-valued feature historyclustering futures histories similar associated values.directly approximate types models make predictionstherefore non-generative (and therefore able, instance, avoid fallingtrap predicting dealers decisions Three Card Monte). Though approachdemonstrated promise, also faces clear pragmatic challenge, especially partiallyobservable setting: feature selection. function history, ever-expandingsequence actions observations, finding reasonable set compactly represented features collectively capture history information needed make predictionsinterest significant challenge. sense, even partially observable setting,type approach takes small step away Markov case. still requiresgood idea priori information extracted history (in formfeatures) order make predictions interest.1. Bowling, McCracken, James, Neufeld, Wilkinson (2006) showed estimator unbiasedcase data collected using blind policy, action selection dependhistory observations provided alternative estimator unbiased policies.simplicitys sake, however, assume throughout data gathering policy blind.360fiLearning Make Predictions Without Generative Model2.2 Generative Modelsone good idea priori features extracted historymake accurate predictions, one faces additional challenge learning summarizerelevant information history compact sufficient statistic.exist methods learn training data maintain finite-dimensionalstatistic history prediction computed. analogy Markovcase, statistic called state vector. Clearly model maintain stateused compute (since make predictions). briefly mention twoexamples approach particularly relevant development analysismethod.POMDPs far popular representation models partially observablesystems partially observable Markov decision process (POMDP) (Monahan, 1982).POMDP posits underlying MDP (Puterman, 1994) set hidden statesagent never observes. given time-step i, system particular hiddenstate si1 (unknown agent). agent takes action ai systemtransitions next state si according transition probability Pr(si | si1 , ai ).observation oi emitted according probability distribution generalmay depend upon si1 , ai , si : Pr(oi | si1 , ai , si ).agent observe hidden states, cannot know hiddenstate system given moment. agent however maintain probabilitydistribution represents agents current beliefs hidden state. probability distribution called belief state. belief state associated history hknown, straightforward compute prediction test t:Xp(t | h) =Pr(s | h)Pr(t | s),sSPr(t | s) computed using transition observation emission probabilities.belief state finite summary history predictionfuture computed. So, belief state state vector POMDP. Giventransition probabilities observation emission probabilities, possible maintainbelief state time using Bayes rule. current history h one knows Pr(s | h)hidden states agent takes action observes observation o, onecompute probability hidden state new history:PPr(s | h)Pr(s | , ai )Pr(oi | , ai , s)PPr(s | hao) = P.(4)Pr(s | h)Pr(s | , ai )Pr(oi | , ai , )parameters POMDP must learned order able maintainstate transition probabilities observation emission probabilities. Givenparameters, belief state corresponding given history recursively computedmodel thereby make prediction history. POMDP parameterstypically learned using Expectation Maximization (EM) algorithm (Baum et al., 1970).Given training data number actions, observations, hidden statesinput, EM essentially performs gradient ascent find transition emission distributions(locally) maximize likelihood provided data.361fiTalvitie & SinghPSRs Another recently introduced modeling representation predictive staterepresentation (PSR) (Littman et al., 2002). Instead hidden states, PSRs defineddirectly terms system dynamics matrix (described Section 1.2.2). Specifically,PSRs find set core tests Q whose corresponding columns system dynamics matrixform basis. Recall system dynamics matrix often finite rank (for instance,matrix associated POMDP finite hidden states finite linear dimension)thus Q finite many systems interest. Since predictions Q basis,prediction test history computed linear combinationpredictions Q history.vector predictions Q called predictive state. belief statestate vector POMDPs, predictive state state vector PSRs. alsomaintained application Bayes rule. Specifically, history h, p(q | h)known core tests q agent takes action observesobservation O, one compute prediction core test q newhistory:Pp(aoq | h)q Q p(q | h)maoq (q )Pp(q | hao) ==,(5)p(ao | h)q Q p(q | h)mao (q )maoq (q ) coefficient p(q | h) linear combination computesprediction p(aoq | h).So, given set core tests, parameters PSR must learned ordermaintain state coefficients mao every action observationcoefficients maoq every action a, observation o, core tests q. Given parameterspredictive state given history recursively computed used makeprediction future. PSRs learned directly estimating system dynamics matrix (James & Singh, 2004; Wolfe, James, & Singh, 2005) or, recently,sub-matrix derived matrix thereof (Boots, Siddiqi, & Gordon, 2010, 2011) using sampleaverages training data. estimated matrix used find set core testsparameters estimated using linear regression.Note types models inherently generative. relyupon maintenance state vector order make predictions and,seen Equations 4 5, state update equations models rely upon accessone-step predictions perform Bayesian update. such, unlike direct functionapproximation approach, one cannot simply choose set predictions modelmake. models necessity make predictions.many reasons desire complete, generative model. makespossible predictions, model used sample possible future trajectoriesuseful capability planning. generative model also, definition, flexiblepredictions used make. hand, many cases complete,generative model may difficult obtain. PSR POMDP training methods scalepoorly linear dimension system learned. linear dimensionlower-bounds number hidden states needed represent system POMDPprecisely number core tests needed represent PSR. learning methodsPOMDPs PSRs rarely successfully applied systems linear dimension362fiLearning Make Predictions Without Generative ModelFigure 2: Size 10 1D Ball Bouncehundred (though work Boots et al. pushing limits further).systems interest several orders magnitude higher linear dimension.Furthermore, complete, generative model overkill problem hand. Recallseek make predictions; focused making particularlyimportant predictions . Even problems learning make predictions mightintractable, still possible make simple important predictions.2.2.1 Abstract Generative Modelsdiscussed earlier, restricted set tests interest, learning problemoften simplified ignoring irrelevant details abstraction. course,abstraction solve problem partial observability. typically doneapply abstraction training data, discarding irrelevant details (asThree Card Monte example) apply model learning methods likeones described abstract data set. Markov setting, casesobservation abstraction greatly simplify learning problem (certainly learningcards Three Card Monte easier learning cards crowdweather on).Ignoring details irrelevant making predictions interest intuitivesignificantly simplify learning problem. hand, generativemodels, abstract POMDP PSR still make abstract predictions. typicallyincludes predictions directly interest. extra predictionsrequire complex model, even abstract generative model intractible learn.true Three Card Monte example (where generative model ends modelingdealer well cards). following another simple example phenomenon.Example. Consider uncontrolled system pictured Figure 2, called 1D BallBounce system. agent observes strip pixels black white.black pixel represents position ball moves around strip. ballcurrent direction every time-step moves one pixel direction. Wheneverreaches edge pixel, current direction changes move away edge. Figure3(a) complete POMDP model 10 pixel version system pictured.k pixels, POMDP 2k 2 hidden states (because ball one 2possible directions one k possible positions, except two ends,one possible direction).say agent wishes predict whether ball position markedx next time step. Clearly prediction made payingattention immediate neighborhood x. details happensball far away matter making predictions. So, one could apply363fiTalvitie & Singh(a)(b)Figure 3: POMDP model size 10 1D Ball Bounce system (a) abstracted1D Ball Bounce system (b).abstraction lumps together observations neighborhood xlooks same. problem abstract generative model system makespredictions x, also pixels surrounding x. Specifically,model still makes predictions whether ball enter neighborhood nearfuture. course depends long since ball left neighborhood.So, POMDP model abstract system (pictured Figure 3(b)) exactlystate diagram original system, though observations changed reflectabstraction. abstract system primitive system linear dimension.order make predictions x, one must condition informationpixels surrounding x. Consequently, generative model also makes predictionspixels. Counterintuitively, abstract models complexity mainly devoted makingpredictions predictions interest. general, learning abstractmodel drastically simplify learning problem ignoring irrelevant details, abstract generative model still learns make predictions details relevant,even directly interest.2.3 Prediction Profile Modelscontribution paper, prediction profile models, seek combine main strengthstwo model-learning approaches discussed above. direct approximation, prediction profile model make predictions interest, others.such, far simpler generative model, typically make manyextraneous predictions. However, learning method prediction profile modelsrequire set history features given priori. leveraging existing generativemodel learning methods, prediction profile models learn maintain state informationnecessary making predictions interest.364fiLearning Make Predictions Without Generative ModelFigure 4: Prediction profile model 1D Ball Bounce systemtypical model learns make predictions future observations emittedsystem. main idea behind prediction profile models instead model valuespredictions change time, conditioned actions chosenagent observations emitted system.already seen example Three Card Monte. prediction profilemodel (shown Figure 1) takes observations dealers behavior input outputspredictions tests interest. predict dealers behavior, takesaccount updating predictions interest. Recall that, though Three CardMonte system arbitrarily complicated (depending dealer), predictionprofile system three states, regardless dealers decision making process.Another example shown Figure 4. prediction profile system 1DBall Bounce system (Figure 2), model must predict whether ball enterposition x next time-step. state prediction profile model labeledprediction pixel x (white black). transitions labeled observations3-pixel neighborhood centered position x. case transitions capture ballentering neighborhood, moving position x, leaving neighborhood, staying awayundetermined amount time, returning again. Recall POMDP modelsystem 2k 2 hidden states, k number pixels, even ignoringpixels irrelevant making predictions pixel x. contrast, prediction profilemodel always three states, regardless number pixels.next section formally describe prediction profile models models dynamical system results transformation original system. Subsequent sectionsdiscuss learn prediction profile models data (by converting dataoriginal system data transformed system learning model converted data set) present results help characterize conditionsprediction profile models best applied.3. Prediction Profile Systemformally describe theoretical dynamical system, defined termsdynamics original system given tests interest. call constructedsystem prediction profile system. prediction profile model, goal365fiTalvitie & Singhconstruct, model prediction profile system (that is, system ideal,theoretical construct, model may imperfect, approximate, etc.). such, analysisproblem learning prediction profile model depend great deal understandingproperties prediction profile system.paper make restrictive assumption that, Markov case,finite number distinct prediction profiles (that is, predictions interest takefinite number distinct values). certainly true partially observablesystems sets tests interest, though true many interesting examples.Formally, assumption requires map histories finite set prediction profiles:Assumption 7. Assume exists finite set prediction profiles P = {1 , 2 , . . . , k }[0, 1]m every history h, (h) P .assumption allows definition prediction profile system (or P P short)discrete dynamical system captures sequence prediction profiles time,given action observation sequence. prediction profile systems actions, observations,dynamics defined terms quantities associated original system:Definition 8. prediction profile system defined set observations, setactions, rule governing dynamics.1. Observations: set prediction profile observations, OP P , defined setdefdistinct prediction profiles. is, OP P = P = {1 , . . . , k }.2. Actions: set prediction profile actions, AP P , defined set actiondefobservation pairs original system. is, AP P = O.3. Dynamics: dynamics prediction profile system deterministically governed . prediction profile history, ha1 , o1 i1 ha2 , o2 i2 . . . haj , oj ij ,next P P -action, haj+1 , oj+1 i, prediction profile system deterministicallyemits P P -observation (a1 o1 a2 o2 . . . aj oj aj+1 oj+1 ).present key facts prediction profile system. Specifically,noted prediction profile system always deterministic. Also, thoughprediction profile system may Markov (as Three Card Monte example),general partially observable.Proposition 9. Even original system stochastic, prediction profile systemalways deterministic.Proof. follows immediately definition: every history corresponds exactlyone prediction profile. P P -history (action-observation-profile sequence) P P action (action-observation pair) fully determine next P P -observation (prediction profile). stochastic observations original system folded unmodeled actions prediction profile system.Proposition 10. original system Markov, prediction profile system Markov.366fiLearning Make Predictions Without Generative ModelProof. definition, original system Markov prediction profile timestep depends recent observation. So, time step t, current profile, agent takes action at+1 observes observation ot+1 , next profile simplyt+1 = arkov (ot+1 ). So, fact, original system Markov, prediction profilesystem satisfies even stronger condition: next P P -observation fully determinedP P -action dependence history whatsoever (including recentP P -observation).Proposition 11. Even original system partially observable, prediction profilesystem may Markov.Proof. Consider Three Card Monte example. original system clearly non-Markov(the recent observation, dealers recent swap, tells one littlelocation ace). However, prediction profile system tests interestregarding location special card (pictured Figure 1) Markov. next profilefully determined current profile P P -action.general, however, P P system may partially observable. Though ThreeCard Monte example current prediction profile next action-observation pairtogether fully determine next prediction profile, general next prediction profiledetermined history action-observation pairs (and prediction profiles).Proposition 12. prediction profile system may partially observable.Proof. Recall 1D Ball Bounce example. corresponding prediction profile systemshown Figure 4. Note two distinct states update graph associatedprediction profile (pixel x white). Given current prediction profile(pixel x white) P P -action (observe ball neighboring pixel leftright), one cannot determine whether ball entering leaving neighborhood,thus cannot uniquely determine next profile. prediction profile systempartially observable.So, general, prediction profile system deterministic, partially-observable dynamical system. model prediction profile system used makepredictions interest. such, one wishes use prediction profile model generativemodel, one must select tests interest carefully. instance:Proposition 13. tests interest include set one-step primitive tests,{ao | A, O} , model prediction profile system usedgenerative model original system.Proof. follows immediately definition generative model.special case prediction profile model complete, generativemodel system, shown Section 5 one desires generative model,essentially never preferable learn prediction profile model traditionalrepresentation. prediction profile model best applied relatively simple makemaintain predictions interest comparison making predictions. general,367fiTalvitie & SinghFigure 5: Flow algorithm.prediction profile model conditions observations, necessarily predictnext observation. such, model prediction profile system cannot typicallyused purposes model-based planning/control like generative model could.experiments Section 6 demonstrate output prediction profile models can,however, useful model-free control methods.4. Learning Prediction Profile Modeldefinition prediction profile system straightforwardly suggests methodlearning prediction profile models (estimate prediction profiles, learn modeldynamics using standard model-learning technique). section presentlearning algorithm, discussing main practical challenges arise.Let training data set trajectories experience original system (actionobservation sequences) let = {t1 , t2 , . . . , tk } set tests interest.algorithm presented section learn model prediction profile systemdata S. algorithm three main steps (pictured Figure 5). First trainingdata used estimate prediction profiles (both number unique profilesvalues). Next, learned set prediction profiles used translate training datatrajectories experience prediction profile system. Finally, applicable modellearning method trained transformed data learn model predictionprofile system. Ultimately, experiments, learned prediction profile modelsevaluated useful predictions features control.4.1 Estimating Prediction ProfilesGiven , first step learning prediction profile model determinemany distinct prediction profiles are, well values. estimated predictiontest interest history h is:p(t | h) =# times succeeds h.# times acts(t) taken hdef(6)One could, point, directly estimate letting (h) = hp(t1 | h), p(t2 | h), . . . , p(tk |h)i. course, due sampling error, unlikely estimated profilesexactly same, even true underlying prediction profiles identical. So,368fiLearning Make Predictions Without Generative Modelestimate number distinct underlying profiles, statistical tests used findhistories significantly different prediction profiles.compare profiles two histories, likelihood-ratio test homogeneity performed counts test interest two histories. statistical testassociated test interest rejects null hypothesis predictionhistories, two histories different prediction profiles.order find set distinct prediction profiles, greedily cluster estimatedprediction profiles. Specifically, initially empty set exemplar histories maintained.algorithm searches histories agents experience, comparing historysestimated profile exemplar histories estimated profiles. candidate historysprofile significantly different profiles exemplar histories, candidateadded new exemplar. end, estimated profiles corresponding exemplarhistories used set prediction profiles. order obtain best estimatespossible, search ordered prioritize histories lots associated data.prediction profile estimation procedure two main sources complexity.first sample complexity estimating prediction profiles. take greatdeal exploration see history enough times obtain good statistics, especiallynumber actions observations large. issue could addressed addinggeneralization estimation procedure, data one sample trajectory couldimprove estimates many similar histories. one experiments Section 6,observation abstraction employed simple form generalization. secondbottleneck computational complexity searching prediction profiles, involves exhaustively enumerating histories agents experience. would valuabledevelop heuristics identify histories likely provide new profiles, orderavoid searching histories. experiments Section 6, simple heuristiclimiting search short histories employed. Long histories tend lessassociated data, therefore less likely provide distinguishably new profiles.4.2 Generating Prediction Profile Trajectoriesgenerated finite set distinct prediction profiles, next step translateagents experience sequences action-observation pairs prediction profiles.trajectories used train model prediction profile system.process translating action-observation sequence prediction profile trajectory straightforward and, apart practical concerns, follows directlyDefinition 8. Recall that, action-observation sequence = a1 o1 a2 o2 . . . ak ok , corresponding P P -action sequence ha1 , o1 iha2 , o2 . . . hak , ok i. corresponding sequenceprofiles (a1 o1 )(a1 o1 a2 o2 ) . . . (a1 o1 . . . ak ok ). Thus, principle, every primitive actionobservation sequence translated action-observation-profile sequence.course available generate sequence prediction profiles. So,necessary use approximation , generated training data. Specifically,estimated predictions tests interest history h (computed using Equation6) compared, using statistical tests, set distinct estimated prediction profilesSection 4.1. one estimated profile statistically significantlydifferent estimated predictions h, let (h) = .369fiTalvitie & SinghGiven sufficient data, statistical tests uniquely identify correct matchhigh probability. practice, however, histories much associateddata. possible case test homogeneity fail reject nullhypothesis two profiles. indicates enough data distinguish multiple possible matches. experiments Section 6, two differentheuristic strategies handling situation employed. first strategy lets (h)matching profile smallest empirical KL-Divergence estimatedpredictions (summed tests interest). heuristic choice may leadnoise prediction profile labeling, could turn affect accuracy learnedmodel. second strategy simply cut trajectory point multiplematches occur, rather risk assigning incorrect labeling. ensures labelsappear prediction profile trajectories reasonable level confidencecorrectness. However, wasteful throw training data way.4.3 Learning Prediction Profile Modeltranslation step produces set trajectories interaction predictionprofile system. Recall prediction profile system deterministic, partially observable, discrete dynamical system trajectories used train modelprediction profile system using, principle, applicable model-learning method.issue faced models prediction profile system presentusual discrete dynamical systems modeling setting. prediction profile labelspresent training data, actually using model available. Saycurrent history h, action a1 taken observation o1 emitted. Together,action-observation pair constitutes P P -action. model prediction profilesystem, prediction profile model identify next profile, . profile usedcompute predictions p(t | ha1 o1 ) tests interest history ha1 o1 .another action a2 observation o2 occur. necessary update PP-modelsstate order obtain next prediction profile. typical dynamical systems modelmakes predictions next observation, able update stateactual observation occurred. prediction profile models observations predictionprofiles themselves, observable interacting world. such,prediction profile model update state prediction profile predicted(). updated, prediction profile model obtain profile follows ha2 , o2gives predictions tests interest new history ha1 o1 a2 o2 .prediction profile model perfect model prediction profile system,poses problems. prediction profile system deterministic, needobserve true prediction profile label; fully determined history. practice,course, model imperfect different modeling representations requiredifferent considerations performing two functions providing predictionstests interest, providing profile sake updating model.4.3.1 PP-POMDPsSince prediction profile system partially observable natural model using POMDP. Unfortunately, even training data deterministic sys370fiLearning Make Predictions Without Generative Modeltem, POMDP training using EM algorithm generally provide deterministicPOMDP. Thus, given history, learned POMDP model prediction profilesystem (PP-POMDP) provide distribution prediction profiles instead deterministically providing one profile associated history. implementationused Section 6 simply takes likely profile distribution profileassociated history uses make predictions tests interest, wellupdate POMDP model.4.3.2 PP-LPSTsAnother natural choice representation prediction profile model looping predictivesuffix tree (LPST) (Holmes & Isbell, 2006). LPSTs specialized deterministic, partiallyobservable systems. such, could used model original system (whichassumed stochastic general), apply prediction profile system(and determinized like POMDP).Briefly, LPST captures parts recent history relevant predicting nextobservation. Every node tree corresponds action-observation pair. nodemay leaf, may children, may loop one ancestors. Every leaftree corresponds history suffix deterministic prediction observationevery action. order predict next observation particular history, onereads history reverse order, following corresponding links tree leafreached, gives prediction. Holmes Isbell provide learning algorithm that,certain conditions training data, guaranteed produce optimal tree.reader referred work Holmes Isbell (2006) details.One weakness LPSTs, however, fail make prediction nextobservation current history lead leaf node tree (or leafnode reached prediction action queried). typically occurshistory suffixes occur training data occur usingmodel. PP-LPST, mean histories model cannot uniquelydetermine corresponding prediction profile. happens implementationused Section 6 simply finds longest suffix current history occurdata. suffix associated multiple prediction profiles (otherwise LPSTwould provided prediction). make predictions tests interest, modelprovides average prediction set profiles. profile used updatemodel picked set uniformly randomly.4.3.3 PP-PSRsApplying PSR learning algorithms prediction profile data poses practical concern.Specifically, methods attempt estimate system dynamics matrix (James & Singh,2004; Wolfe et al., 2005) implicitly presume every action sequence could principletaken every history. action sequences taken historiesothers, matrix undefined entries. poses challenges rankestimation (and, indeed, definition model representation). Unfortunately,case prediction profile system since P P -actions (action-observationpairs) completely agents control; partly selected environ371fiTalvitie & Singhment itself. recent spectral learning algorithms presented Boots et al. (2010) mayable side-step issue, flexibility selecting predictionsestimated use model-learning process, though investigatedpossibility work.Note that, though method learning prediction profile model involves standardmodel-learning methods partially observable environments, result generativemodel original system. prediction profile model generative modelprediction profile system and, such, cannot used make predictionsoriginal system, predictions interest.5. Complexity Prediction Profile Systemlearning algorithm presented evaluated empirically Section 6. First,however, analyze complexity prediction profile system relation complexity original system. give indication difficult learnprediction profile model provide insight appropriate learn predictionprofile model typical generative model approach.many factors affect complexity learning model. sectionlargely focus linear dimension measure complexity, taking view that,generally speaking, systems lower linear dimension easier learn systemslarger linear dimension. discussed Section 1.2.2, generally true POMDPs,linear dimension lower-bounds number hidden states. comparinglinear dimension prediction profile system original system giveidea whether would easier learn PP-POMDP learn standardPOMDP original system. course, model-learning methodscomplexity measures would appropriate (for instance knownprecisely LPSTs interact linear dimension). Extending resultsmeasures complexity may interesting topic future investigation.5.1 Linear Dimension Comparisonsection discuss linear dimension prediction profile system relatesoriginal system. first result proof concept simply statesexist problems prediction profile system vastly simpleoriginal system. fact, problem already presented.Proposition 14. prediction profile system linear dimension arbitrarilylower original system.Proof. Recall Three Card Monte example. Thus far domain describedwithout describing dealers behavior. However, note prediction profile systemtests interest relating location special card (pictured Figure 1)linear dimension 3, regardless dealers swaps chosen. complexdealer chosen, original system high linear dimension, predictionprofile systems linear dimension remain constant. instance, experimentsSection 6, dealer chooses cards swap stochastically, likely choose372fiLearning Make Predictions Without Generative Modelswap selected least often far. Thus, order predict dealersnext decision, one must count many times swap chosen historyresult system effectively infinite linear dimension.hand, prediction profile models panacea. following resultsindicate problems learning prediction profile model wouldadvisable learning standard generative model, linear dimensionprediction profile system far greater original system. Latersection special cases characterized prediction profile models likelyuseful. next result shows linear dimension prediction profile modelinfinite original system finite linear dimension, via lower boundlinear dimension true deterministic dynamical systems.Proposition 15. deterministic dynamical system actions A, observationsO, linear dimension, n log(|A|1)+log(|O|+1).log |A|Proof. See Appendix A.1.Proposition 15 applies deterministic dynamical systems, certainly applies prediction profile system. Though loose bound, basic implicationnumber prediction profiles (the observations P P ) increases comparison number action-observation pairs (the actions P P ), linear dimensionprediction profile system necessarily increases. bound also clearly illustratesimportance assumption finite number distinct prediction profiles.Corollary 16. infinitely many distinct prediction profiles, prediction profilesystem infinite linear dimension.Proof. Clearly |AP P | = |A O| finite long finitely many actionsobservations. So, last result follows immediately number distinctprediction profiles |OP P | approaches infinity, must linear dimensionprediction profile system.Hence, long prediction profile models represented using methods relyfinite linear dimension, critical finitely many prediction profiles.Note fundamental barrier, side effect representational choice.Model learning methods sensitive linear dimension (such designedmodel continuous dynamical systems) may able effectively capture systemsinfinitely many prediction profiles.One conclusion drawn last results knowing linear dimensionoriginal system not, itself, necessarily say much complexityprediction profile system. prediction profile system may far simpler farcomplex original system. Thus may informative turn factorstrying characterize complexity prediction profile system.373fiTalvitie & Singh5.2 Bounding Complexity Prediction Profile Systemresults previous section take account obviously important aspectprediction profile system: predictions asked make. predictionsinterest made simply keeping track little information.predictions rely great deal history information therefore requirecomplex model. next result identifies worst case set tests interestsystem: tests interest whose corresponding prediction profile model highestlinear dimension. Ultimately section present (non-exhaustive) conditionsprediction profile system likely simpler original system.Proposition 17. given system set tests interest, linear dimensioncorresponding prediction profile system greater prediction profilesystem associated set core tests system (as described Section 2.2).Proof. See Appendix A.2.worst case identified, one immediately obtain bounds complexprediction profile system possibly be.Corollary 18. system set tests interest, corresponding predictionprofile system linear dimension greater number distinct predictive statesoriginal system.Proof. prediction profile system set core tests Q deterministic MDPobservations prediction profiles Q (that is, predictive states). is, stateassociated unique prediction profile. linear dimension MDP nevergreater number observations (Singh et al., 2004). Therefore, previousresult prediction profile system set tests interest linear dimensiongreater number predictive states.Corollary 19. original system POMDP, prediction profile system settests interest linear dimension greater number distinct belief states.Proof. follows immediately previous result fact numberdistinct predictive states greater number distinct belief states (Littmanet al., 2002).bounds presented far help explain prediction profile systemcomplex original system. However, focused worst possiblechoice tests interest, little illuminate opposite true. predictionprofile model complex asked perform task generativemodel: keep track much information history necessary make possiblepredictions (or equivalently, predictive state belief state). results indicatethat, generally speaking, one desires generative model, standard approaches wouldpreferable learning prediction profile model.hand, stated goal learn generative model, insteadfocus particular predictions hopefully far simpler makepredictions. examples seen make clear cases, predictions374fiLearning Make Predictions Without Generative Modelmade prediction profile model far simpler generative model originalsystem. general one might expect prediction profile model simplepredictions interest rely small amount state information requiredmaintain generative model. next bound aligns intuitive reasoning.Essentially result points often much hidden state informationPOMDP irrelevant predictions interest. linear dimensionprediction profile system bounded number distinct beliefs relevantparts hidden state, rather number distinct beliefs states overall. idearesult one impose abstraction hidden states POMDP(not observations) still allows predictions interest made accuratelyallows abstract belief states computed accurately, prediction profilesystems linear dimension bounded number abstract belief states.Proposition 20. Consider POMDP hidden states S, actions A, observationsO. Let set tests interest. Let ai action taken time-step i, sihidden state reached taking action ai , oi observation emitted si . Now,consider surjection : mapping hidden states set abstract statesfollowing properties:1. pair primitive states s1 , s2 S, (s1 ) = (s2 ), time-steptest interest , p(t | si = s1 ) = p(t | si = s2 ).2. pair primitive states s1 , s2 S, (s1 ) = (s2 ), time-step i,abstract state , observation O, action A,Pr((si+1 ) = | si = s1 ,ai+1 = a, oi+1 = o) =Pr((si+1 ) = | si = s2 , ai+1 = a, oi+1 = o)., prediction profile system linear dimension greaternumber distinct beliefs abstract states, .Proof. See Appendix A.3things note result. First, surjection always existsdefproperties 1 2. One always define : (s) = s. degeneratecase trivially satisfies requirements Proposition 20 recovers bound givenCorollary 19. However, Proposition 20 applies surjections satisfy conditions.must surjection satisfies conditions results smallest numberbeliefs abstract states. Essentially, one ignores much state informationpossible still allowing predictions interest made accuratelysurjection tightly bounds complexity prediction profile system (evenknown).course, may still large even infinite number distinct beliefs, evenabstract states, factors must come play ensure simple prediction profilesystem. Furthermore, result characterize settings predictionprofile system simple. said, result support intuition375fiTalvitie & Singhprediction profile system tend simple predictions asked makedepend small amounts state information.order build intuition result relates earlier examples, recallThree Card Monte problem. Three Card Monte two sources hidden state:aces unobserved position whatever hidden mechanism dealer uses makedecisions. Clearly agents predictions interest depend first parthidden state. So, case one satisfy Property 1 surjection mapstwo hidden states abstract state ace position, regardlessdealers state. 3 abstract states (one possibleposition), even though might infinitely many true hidden states. Now, differentstates corresponding ace position different distributions acesnext position; distribution does, all, depend upon dealers state. However,Property 2 statement distribution next abstract state givenobservation emitted entering abstract state. one knows currentabstract state observes dealer does, next abstract state fully determined.Property 2 holds well. fact, since aces position known beginninggame, means current abstract state always known absolute certainty, eventhough beliefs dealers state general uncertain. Hence, 3distinct beliefs abstract states (one state). such, prediction profilemodels linear dimension upper-bounded 3, regardless dealers complexity (andcase bound met).5.3 Bounding Number Prediction Profilesprevious section describes conditions prediction profile systemmay lower linear dimension original system. Also concern numberprediction profiles, whether number finite. section briefly discuss(non-exhaustive) cases number prediction profiles bounded.One case already discussed original system Markov.case number prediction profiles bounded number observations (states).course, original system Markov, little need use prediction profilemodels. Another, similar case system partially observable, completelydeterministic (that is, next observation completely determined historyselected action). system deterministic POMDP given historycurrent hidden state known. such, number belief states boundednumber hidden states. Since cannot prediction profiles belief states,number prediction profiles bounded well.One move away determinism different ways. First, note keyproperty deterministic POMDP hidden state fully determined history.possible satisfy property even stochastic systems, long one uniquelydetermine hidden state, given observation emitted arriving there.case, observations emitted stochastically, number belief states (andnumber prediction profiles) still bounded number hidden states.Another step away determinism class systems, introduced Littman (1996),called Det-POMDPs. Det-POMDP POMDP transition function376fiLearning Make Predictions Without Generative Modelobservation function deterministic, initial state distribution maystochastic. Det-POMDP deterministic dynamical system, uncertaintyhidden state. uncertainty, system appears emit observationsstochastically. underlying dynamics deterministic. Littman showedDet-POMDP n hidden states initial state distribution statessupport (n + 1)m 1 distinct belief states. So, bounds numberprediction profiles well.Finally, importantly, hidden state abstracted Proposition 20,properties really need hold abstract beliefs. is, environmentmay complex stochastic arbitrary ways, abstract hidden statedescribed Proposition 20 fully determined history, number predictionprofiles bounded number abstract states (as case Three Card Monte).Similarly, Det-POMDP-like properties imagined abstract hidden states well.cases means cover situations number prediction profilesbounded, seem indicate class problems numberprediction profiles finite quite broad, may contain many interesting examples.6. Experimentssection empirically evaluate prediction profile model learning procedure developed Section 4. experiment agent faces environment generativemodel would challenge learn due high linear dimension. However,problem agent could make good decisions could predictions smallnumber important tests. prediction profile model learned important testsaccuracy learned predictions evaluated.experiments also demonstrate one possible use prediction profile models (andpartial models general) control. generative, prediction profilemodels cannot typically used directly offline, model-based planning methods. However, output may useful model-free methods control. Specifically,experiments, predictions made learned prediction profile models providedfeatures policy gradient algorithm.6.1 Predictive Features Policy GradientPolicy gradient methods (e.g., Williams, 1992; Baxter & Bartlett, 2000; Peters & Schaal,2008) successful viable options model-free control partially observable domains. Though differences various algorithms, commonthread assume parametric form agents policy attemptalter parameters direction gradient respect expected average reward. experiments make use Online GPOMDP Average Reward Baseline(Weaver & Tao, 2001), OLGARB (readers referred original paper details).OLGARB assumes set features history, agents policy takesparametric form:Pr(a | h; w)~ =PeP377wi,a fi (h)Pwi,a fi (h)efiTalvitie & Singhfi (h) ith feature parameter wi,a weight specific featureaction considered.Typically features used policy gradient features directly readhistory (e.g., features recent observations presence/absenceevent history). difficult know priori historical featuresimportant making good control decisions. contrast, idea experimentsprovide values predictions features. predictive features directconsequences control, provide information effects possible behaviorsagent might engage in. such, may easier select set predictive featureslikely informative optimal action take (e.g., agentreach goal state takes action? taking action damageagent?). Furthermore, information may expressed compactly terms predictionwould complex specify purely terms past observations. seendiscussion PSRs Section 2.2, arbitrary-length history fully capturedfinite set short-term predictions. reasons seems reasonable speculatepredictive features, maintained prediction profile model, may particularlyvaluable model-free control methods like policy gradient.6.2 Experimental Setuplearning algorithm applied two example problems. problem predictionprofile models learned various amounts training data (using LPSTsPOMDPs representation using strategies dealing multiple matches,described Section 4.3). prediction accuracy models evaluated, welluseful predictions features control. training data generatedexecuting uniform random policy environment.free parameter learning algorithm significance value statisticaltests, . Given large number contingency tests performeddata set, compound probability false negative, set fairlylow. experiments use = 0.00001, though several reasonable values triedsimilar results. discussed Section 4, also maximum lengthhistories consider search prediction profiles. cutoff allows searchavoid considering long histories, many long histories searchunlikely provide new prediction profiles.prediction profile model learned, predictions evaluated featurespolicy gradient algorithm OLGARB. Specifically, test interest unitinterval split 10 equally-sized bins b binary feature ft,b provided1 prediction lies bin b, 0 otherwise. Also provided binary features fo ,possible observation o. feature fo = 1 recent observation0, otherwise. parameters OLGARB, learning rate discount factor, set0.01 0.95, respectively experiments.evaluate prediction profile model OLGARB run 1,000,000 steps. averagereward obtained root mean squared error (RMSE) predictions testsinterest accrued model along way reported. Prediction performancecompared obtained learning POMDP training data using378fiLearning Make Predictions Without Generative ModelPrediction PerformanceControl Performance0.1Avg. Reward (20 trials)Avg. RMSE (20 Trials)10.80.6Flat POMDP0.4PPLPST(KLD)PPLPST(cut)0.200PPPOMDP(KLD)PPPOMDP(cut)24# Training TrajectoriesTrue0.060.04PPPOMDP(KLD)PPPOMDP(cut)0.02PPLPST(KLD)PPLPST(cut)0Flat POMDP0.020.040.0606Expert0.08SOM246# Training Trajectories x 1044x 10Figure 6: Results Three Card Monte domain.make predictions interest. problems complex feasibly trainPOMDP correct number underlying states, 30-state POMDPs used(stopping EM maximum 50 iterations)2 . Control performance comparedobtained OLGARB using predictions provided learned POMDP modelfeatures, well OLGARB using true predictions features (the best predictionprofile model could hope do), OLGARB using second-order Markov features (the tworecent observations, well action them) predictive featuresall, hand-coded expert policy.6.3 Three Card Montefirst domain Three Card Monte example. agent presented threecards. Initially, card middle (card 2) ace. agent four actionsavailable it: watch, f lip1, f lip2, f lip3. agent chooses flip action, observeswhether card flipped special card. agent chooses watch action,dealer swap positions two cards, case agent observes twocards swapped, dealer ask guess. dealer askedguess, watch results 0 reward flip action results -1 reward. dealerasks guess agent flips special card, agent gets reward 1.agent flips one two cards, doesnt flip card (by selecting watch),gets reward -1. agent three tests interest, take form f lipX ace,card X (that is, flip card X, see ace?).discussed previously, complexity system directly related complexity dealers decision-making process. experiment, agent chooseswatch dealer swaps pair cards swapped least far probability0.5; probability 0.4 chooses uniformly amongst pairs cards; otherwiseasks guess. Since dealer keeping count many times swapmade, process governing dynamics effectively infinite linear dimension.2. Similar results obtained 5, 10, 15, 20, 25 states.379fiTalvitie & Singhprediction profile system, hand, 3 states, regardless dealerscomplexity (see Figure 1).Training trajectories length 10. Figure 6 shows results various amountstraining data, averaged 20 trials. PP-POMDPs PP-LPSTs learned makeaccurate predictions tests interest, eventually achieving zero prediction error.case, PP-POMDPs using less data. likely POMDP modelreadily able take advantage fact prediction profile system ThreeCard Monte Markov. expected, standard POMDP model unable accuratelypredict tests interest.Also compared two different strategies dealing multiple matches discussed Section 4.3. Recall first one (marked KLD graph) picksmatching profile smallest empirical KL-Divergence estimated predictions.second (marked cut graph) simply cuts trajectory pointmultiple match avoid incorrect labels. problem two strategies result almost exactly performance. likely profiles ThreeCard Monte deterministic, therefore quite easy distinguish (making multiplematches unlikely). next experiment stochastic profiles.predictive features provided prediction profile models clearly usefulcontrol, control performance OLGARB using predictions approaches,eventually exactly matches OLGARB using true predictions (marked True).inaccurate predictions provided POMDP useful control; OLGARB using POMDP provided predictions even break even, meaning losesgame often wins. POMDP features did, however, seem containuseful information beyond provided second-order Markov features (markedSOM) which, one might expect, performed poorly.6.4 Shooting Gallerysecond example called Shooting Gallery, pictured Figure 7(a). agentgun aimed fixed position 88 grid (marked X) . target movesdiagonally, bouncing boundaries image 22 obstacles (an exampletrajectory pictured). agents task shoot target. agent two actions:watch shoot. agent chooses watch, gets 0 reward. agent choosesshoot target crosshairs step agent shoots, agent getsreward 10, otherwise gets reward -5. Whenever agent hits target,shooting range resets: agent receives special reset observation, 2 2 squarerange made obstacle probability 0.1, target placed randomposition. also 0.01 probability range reset every time step.difficulty target sticky. Every time step probability 0.7 movescurrent direction, probability 0.3 sticks place. Thus, looking recenthistory, agent may able determine targets current direction. agentneeds know probability target sights next step, clearlysingle test interest is: watch target (that choose watch action,target enter crosshairs?). target far crosshairs, predictiontest 0. target crosshairs, 0.3. target380fiLearning Make Predictions Without Generative Model(a)(b)Figure 7: Shooting Gallery domain. (a) possible arrangement obstacles trajectory target (lighter back time). case targetdefinitely enter agents crosshairs, since bounce obstacle.(b) abstraction applied recent observation.near crosshairs, model must determine whether prediction 0.7 0, basedtargets previous behavior (its direction) configuration nearby obstacles.problem stochastic prediction profiles, expected datarequired differentiate them. Also, due number possible configurationsobstacles positions target, system roughly 4,000,000 observationseven latent states. results large number possible histories,small probability occurring. discussed Section 4, lead large samplecomplexity obtaining good estimates prediction profiles. addressedsimple form generalization: observation abstraction. Two observations treatedtarget position configuration obstaclesimmediate vicinity target same. words, abstract observationcontains information targets position obstacles surroundingtarget, placement obstacles far away target (see Figure 7(b))example. abstraction, abstract observations still provide enough detailmake accurate predictions. is, two histories indeed prediction profileaction sequence observation sequences correspondsequence aggregate observations. enables one sample trajectory improveestimates several histories, though, even abstraction, still2000 action-observation pairs. observation abstraction applied trainingPOMDP model.Training trajectories length 4 search profiles restricted length3 histories. Results shown Figure 8. Perhaps eye-catching featureresults upward trending curve prediction error graph, correspondingPP-POMDP KL-Divergence based matching (labeled PP-POMDP(KLD)).Recall danger KL-divergence based matching strategy may produceincorrect labels training data. Apparently errors severe enoughproblem drastically mislead POMDP model. small amount data obtained381fiTalvitie & SinghPrediction PerformanceControl Performance0.025Avg. Reward (20 Trials)Avg. RMSE (20 Trials)0.250.2PPPOMDP(cut)0.15Flat POMDP0.1PPPOMDP(KLD)0.05PPLPST(cut)PPLPST(KLD)002468# Training Trajectories0.020.0150.01PPLPST(KLD)PPPOMDP(KLD)PPLPST(cut)0.005PPPOMDP(cut)00.0050105x 10ExpertTrueSOMFlat POMDP246810# Training Trajectories x 105Figure 8: Results Shooting Gallery domain.good prediction error, data came misleading labelings,performance suffered. PP-POMDP trained matching method (PPPOMDP(cut)) displays typical learning curve (more data results better error),though takes great deal data begins make reasonable predictions.cutting trajectories multiple matches throws away data mightinformative model. PP-LPSTs generally outperform PP-POMDPsproblem. trajectory cutting method, PP-LPST (PP-LPST(cut))quickly outperforms flat POMDP and, enough data, outperforms versionsPP-POMDP. PP-LPST KL-divergence based matching (PP-LPST(KLD))far best performer, quickly achieving small prediction error. Clearly incorrectlabels training data dramatic effect LPST learning, possiblybecause, suffix tree, LPST mostly makes predictions based recent history,limiting effects labeling errors time-steps.Control performance essentially mirrors prediction performance, interestingexceptions. Note even though PP-POMDP(KLD) obtains roughly predictionerror flat POMDP 1,000,000 training trajectories, predictive features providesstill result substantially better control performance. indicates that, even thoughPP-POMDP making errors exact values predictions, still capturedimportant dynamics predictions flat POMDP has. flat POMDPprovides features roughly useful second-order Markov features,result good performance. Again, OLGARB using features breakeven, meaning wasting bullets target likely enter crosshairs.best-performing prediction profile model, PP-LPST(KLD) approaches performanceOLGARB using true predictions sufficient data.7. Related Workidea modeling aspects observations dynamical systemcertainly raised before. instance, recent example Rudary (2008) learned linear382fiLearning Make Predictions Without Generative ModelGaussian models continuous partially observable environments dimensionsobservation treated unmodeled exogenous input. inputs assumedlinear effect state transition. Along somewhat similar lines, contextmodel minimization (taking given, complete model deriving simpler, abstract modelpreserves value function) Wolfe (2010) constructed abstract modelshadow model predicts observation details ignored abstraction.shadow model takes abstract observations abstract model unmodeled input.Splitting observation modeled un-modeled components learninggenerative model certainly related approach. case, model would makeconditional predictions modeled portion observation, given exogenousinputs (as well actual actions history). Prediction profile models takeextreme, treating entire observation input. Instead predicting future sequencespiece next observation conditioned another piece, prediction profile modelspredict values arbitrary set predictions interest next time step, givenentire action observation. allows significantly freedom choosingpredictions model make (and, importantly, make).One modeling method closely related prediction profiles Causal State SplittingReconstruction (CSSR) (Shalizi & Klinker, 2004). CSSR algorithm learning generative models discrete, partially observable, uncontrolled dynamical systems. basicidea define equivalence relation histories two histories consideredequivalent associated identical distributions possible futures.equivalence classes relation called causal states. CSSR algorithm learnsnumber causal states, distribution next observations associatedcausal state, transitions one causal state next, given observation.straightforward see one-to-one correspondance causal statespredictive states PSR. such, causal state model precisely predictionprofile model set tests interest Q, set core tests. correspondance hand, results Section 5.2 show many cases number causalstates greatly exceed linear dimension original system thereforeCSSR may inadvisable many problems, comparison standard modelingapproaches. possible CSSR algorithm could adapted generalsetting arbitrary sets tests interest, however algorithm rely heavilyfact prediction profile model Q tests interest Markov,generally case sets tests interest.mentioned Section 2, McCallum (1995) presented UTree, suffix-tree-based algorithm learning value functions partially observable environments. UTreelearns value function (a prediction future rewards), makepredictions observations, UTree learn non-generative partial model. WolfeBarto (2006) extend UTree make one-step predictions particular observationfeatures rather limiting predictions value function. learns suffixtree, UTree able operate non-episodic domains (whereas method requires seeinghistories multiple times) required explicitly search distinct prediction profiles. UTree also directly incorporates abstraction learning, learning simultaneouslyobservation features important, history suffix attend them.said, main drawback suffix tree approach tree takes account383fiTalvitie & Singhinformation relatively recent history (a suffix history). cannot rememberimportant information arbitrary number steps recurrent state-based modelcan. Three Card Monte example, instance, access depth-limited suffixhistory would little help. order track ace, one must take accountevery move dealer made since beginning game. UTree would essentiallyforget card games length surpassed depth memory.McCallum (1993) Mahmud (2010) provide methods learning state machinespredict immediate reward resulting given action-observation pair partially observable control tasks (and thus suffer issue finite-depth memorysuffix trees do). Thus, learning problem special case ours,restrict models make one-step predictions immediate reward.cases, simple model incrementally greedily elaborated proposing states splitevaluating results (via statistical tests case McCallum via likelihoodhill-climbing case Mahmud). McCallum expressed concern approachdifficulty extracting long-range dependencies (for instance, learning attend eventappear affect distribution rewards many steps later);clear extent Mahmuds approach addresses issue. methodsadvantages UTree, notably applied non-episodicdomains. said, approach advantages well. re-casting problemlearning non-generative model standard generative model-learning problem,able gain deeper understanding complexity applicability predictionprofile models compared standard generative models. Furthermore, allowed us incorporate standard, well-studied generative model-learning methodslearning algorithm, thereby leveraging strengths non-generative setting.specifically, resulting principled (albeit heuristic) learning algorithm,rely guess-and-check stochastic local search.prediction profile system also similar spirit finite state controllersPOMDPs. Sondik (1978) noted cases, possible represent optimal policy POMDP finite state machine. finite state controllersmuch like prediction profile models take action-observation pairs inputs,instead outputting predictions associated current history, outputoptimal action take. Multiple authors (e.g., Hansen, 1998; Poupart & Boutilier, 2003)provide techniques learning finite state controllers. However, algorithms typicallyrequire access complete POMDP model world begin which, setting,assumed impractical.8. Conclusions Future Directionsstandard methods learning models partially observable environments learngenerative models. one small set predictions interest make (andtherefore require full power generative model), one ignore irrelevantdetail via abstraction simplify learning problem. Even so, generative modelnecessarily make predictions relevant details, even directlyinterest. seen example resulting model counter-intuitivelycomplex, even predictions model asked make quite simple.384fiLearning Make Predictions Without Generative Modelpresented prediction profile models, non-generative models partiallyobservable systems make predictions interest others. main ideaprediction profile models learn model dynamics predictionschange time, rather model dynamics system. learningmethod prediction profile models learns transformation training dataapplies standard methods transformed data (assuming predictions interesttake finite number distinct values). result, retains advantages methodslike EM POMDPs learn information history must maintained ordermake predictions (rather requiring set history features priori). showedprediction profile model far simpler generative model, thoughalso far complex, depending predictions asked make. However,predictions interest depend relatively little state information, prediction profilemodels provide substantial savings standard modeling methods POMDPs.experiments Section 6 demonstrate possible learn predictionprofile models contrived systems complex POMDPs, specific learning algorithm presented likely scale natural domains without modification.critical scaling issues prediction profile models sample complexityestimating prediction profiles, computational complexity searching prediction profiles translating data. cases, critical source complexityessentially many distinct histories training data (more distinct historiesmeans data spread thin amongst estimated profiles searchthrough). such, generalization prediction estimates across many histories wouldkey step toward applying ideas realistic domains. currently developing learning algorithms combine ideas behind prediction profile modelsmethods learning abstractions allow many essentially equivalent historieslumped together purposes estimating predictions interest.Another limitation prediction profile model learning method presentedreliance assumption finite number prediction profiles. assumptionhold many cases, ideal method would able deal gracefully largeinfinite number prediction profiles. One possibility simply cluster predictionsways. instance, one may desire certain level prediction accuracymay therefore willing lump distinct prediction profiles together exchangesimpler prediction profile system. Another idea would learn prediction profile modelusing continuous-valued representations Kalman filters (Kalman, 1960) PLGs(Rudary, Singh, & Wingate, 2005) (or nonlinear variants, e.g., Julier & Uhlmann,1997; Wingate, 2008). representations learning algorithms explicitly dealsystems infinite number observations (prediction profiles case). Evenfinitely many prediction profiles, methods learning non-linear continuousmodels may still able (approximately) capture discrete dynamics.Additionally, though results focused discrete systems, main motivationbehind prediction profile models also purchase continuous setting. Typical methods learning models partially observable systems continuous systems, much likediscrete valued counterparts, learn generative models. such, non-generativeapproach prediction profile models may provide similar benefits continuous settingpredictions need made. setting, prediction profiles might represented385fiTalvitie & Singhparametric form (for instance, mean variance Gaussian). main ideaprediction profile models (though specific method presented here) could stillapplied: learn model dynamics distribution parameters, ratherdynamics system itself.Finally, discussed work tests interest determined, predict selected. Automatically selecting interesting/important predictive features targets partial models would certainlyinteresting research challenge. course, would depend predictionsused for. predictions used features control, doneexperiments, would certainly seem intuitive start predictive featuresregarding reward signal, perhaps observation features strongly correlatereward (as intuitively done hand experiments). may also usefulconsider making predictions predictions style TD Networks (Sutton& Tanner, 2005). instance, one could imagine learning models make predictionsprofile another model emit. way models could chained togethermake predictions extant rewards, rather focusing solely predictingimmediate reward signal (which always particularly good feature temporaldecision problems). Another common use partial models decompose large modelingproblem many small ones, in, instance, factored MDPs (Boutilier et al., 1999),factored PSRs (Wolfe et al., 2008), collections local models (Talvitie & Singh, 2009b).setting, choosing tests interest would example structure learningproblem: decomposing one-step predictions relatively independent componentsassigning different models.AcknowledgmentsErik Talvitie supported NSF GRFP. Satinder Singh supported NSFgrant IIS-0905146. opinions, findings, conclusions recommendations expressedmaterial authors necessarily reflect views NSF.work presented paper extension work presented IJCAI (Talvitie &Singh, 2009a). grateful anonymous reviewers whose helpful commentsimproved presentation work.Appendix A.A.1 Proof Proposition 15result follow straightforwardly general fact dynamical systems. Leth[i...j] sequence actions observations h starting ith time-stepsequence ending jth time-step sequence. conveniences sake,> j let h[i...j] = h0 , null sequence. following two results showtest ever positive probability, must positive probability historylength less linear dimension system.386fiLearning Make Predictions Without Generative ModelFigure 9: matrix constructed Lemma 21 full rank (a contradiction).Lemma 21. linear dimension dynamical system n, testhistory h length(h) = k n p(t | h) > 0, i, j 0 < j 1 kp(t | h[1...i] h[j...k] ) > 0.Proof. Note p(t | h) > 0, p(h[(i+1)...k] | h[1...i] ) = p(t | h)p(h[(i+1)...k] | h[1...i] ) >0 0 k. assume i, j 0 < j 1 k p(h[j...k] | h[1...i] ) =p(t | h[1...i] h[j...k] )p(h[j...k] | h[1...i] ) = 0 seek contradiction. Consider submatrixsystem dynamics matrix. rows submatrix correspond prefixes h: h[1...i]0 k. columns correspond suffixes h pre-pended test t: h[j...k]1 j k + 1. k + 1 k + 1 matrix. assumption,matrix triangular positive entries along diagonal (Figure 9 shows matrixk = 4). such, matrix full rank (rank k + 1). contradiction sincek n submatrix never higher rank matrix contains it.next result follows immediately Lemma 21.Corollary 22. system linear dimension n test history hp(t | h) > 0, exists (possibly non-consecutive) subsequence h hlength(h ) < n p(t | h ) > 0.Proof. Lemma 21, every history h length k n p(t | h) > 0 mustsubsequence h1 length k1 < k p(t | h) > 0. k1 n, h1 mustsubsequence h2 length k2 < k1 . argument repeated subsequencelength less n.consequence Corollary 22 every test ever positive probability,must positive probability following history length less n. facthand, Proposition 15 proven.Proposition 15. deterministic dynamical system actions A, observa.tions O, linear dimension, n log(|A|1)+log(|O|+1)log |A|387fiTalvitie & SinghProof. Since system deterministic, history action correspond exactly oneresulting observation. history sequence actions observations. However, sincesequence observations fully determined sequence actions deterministicsystem, number distinct histories length k simply |A|k . history|A| action choices could result different observation. So, numberobservations could possibly occur histories length k simply |A|k+1 .Corollary 22, linear dimension n, observations must occur history hlength(h) n 1. Thus, number observations possibly follow historieslength less n is:|O|n1X|A|i+1 =i=0|A|n+1 11.|A| 1Solving n yields bound linear dimension terms number actionsnumber observations.A.2 Proof Proposition 17Proposition 17. given system set tests interest, linear dimensioncorresponding prediction profile system greater prediction profilesystem associated set core tests system (as described Section 2.2).Proof. Recall discussion PSRs Section 2.2 set core tests, Q,set tests whose corresponding columns system dynamics matrix constitutebasis. predictions core tests given history form predictive statehistory. So, predictive state precisely prediction profile core tests Q.prediction test computed linear function prediction profileQ. Note prediction profile system Q MDP. shownSection 2.2 compute next predictive state given current predictive stateaction-observation pair.consider set tests interest . predictions Qused compute prediction test, mustfunction maps prediction profiles Q prediction profiles .general, multiple predictive states may map prediction profilesurjection. easy see prediction profile system resultapplying observation abstraction prediction profile system Q. Performingobservation abstraction MDP generally produces POMDP, never increaseslinear dimension (Talvitie, 2010). Hence, prediction profile system set testsinterest linear dimension greater prediction profile systemset core tests, Q.A.3 Proof Proposition 20Proposition 20. Consider POMDP hidden states S, actions A, observationsO. Let set tests interest. Let ai action taken time-step i, sihidden state reached taking action ai , oi observation emitted si . Now,388fiLearning Make Predictions Without Generative Modelconsider surjection : mapping hidden states set abstract statesfollowing properties:1. pair primitive states s1 , s2 S, (s1 ) = (s2 ), time-steptest interest , p(t | si = s1 ) = p(t | si = s2 ).2. pair primitive states s1 , s2 S, (s1 ) = (s2 ), time-step i,abstract state , observation O, action A,Pr((si+1 ) = | si = s1 ,ai+1 = a, oi+1 = o) =Pr((si+1 ) = | si = s2 , ai+1 = a, oi+1 = o).exists, prediction profile system linear dimension greaternumber distinct beliefs abstract states, .Proof. proof follows similar reasoning proof Proposition 17. Note that,Property 1 belief abstract states given history sufficient computeprediction profile. history h test interest :XX Xp(t | h) =Pr(s | h)p(t | s) =Pr(s | h)p(t | s)sS=XSSp(t | S)XSS sSPr(s | h) =Xp(t | S)Pr(S | h),SSsSthird equality follows property 1: , hidden statesassociated probabilities tests interest.Now, consider dynamical system beliefs abstract states observationsaction-observation pairs actions. Call abstract belief system.predictive state, possible compute prediction profileabstract beliefs, prediction profile model seen resultobservation aggregation abstract belief system. result, prediction profilesystem linear dimension greater abstract belief system.rest proof shows that, Property 2, abstract belief systemMDP, therefore linear dimension greater number distinct beliefsabstract states.Given probability distribution abstract states given history h, agenttakes action observes observation o, possible compute probabilityabstract state new history:XX XPr(S | hao) =Pr(s | h)Pr(S | s, a, o) =Pr(s | h)Pr(S | s, a, o)sS=XPr(S | , a, o)XsSPr(s | h) =XPr(S | , a, o)Pr(S | h),sSthird equality follows Property 2: , hidden statesassociated conditional distribution next abstract states, given actionobservation.389fiTalvitie & SinghSo, one compute next abstract beliefs previous abstract beliefs,abstract belief system MDP, therefore linear dimension greaternumber observations (the number distinct abstract beliefs). onecompute prediction profile abstract beliefs, prediction profile systemconstructed applying observation abstraction abstract belief system. Thus,prediction profile system linear dimension greater number distinctabstract beliefs.ReferencesBaum, L. E., Petrie, T., Soules, G., & Weiss, N. (1970). maximization technique occuringstatistical analysis probabilistic functions markov chains. AnnalsMathematical Statistics, 41 (1), 164171.Baxter, J., & Bartlett, P. L. (2000). Reinforcement learning POMDPs via direct gradient ascent. Proceedings Eighteenth International Conference MachineLearning (ICML), pp. 4148.Boots, B., Siddiqi, S., & Gordon, G. (2010). Closing learning-planning loop predictive state representations. Proceedings Robotics: Science Systems, Zaragoza,Spain.Boots, B., Siddiqi, S., & Gordon, G. (2011). online spectral learning algorithmpartially observable nonlinear dynamical systems. Proceedings Twenty-FifthNational Conference Artificial Intelligence (AAAI).Boutilier, C., Dean, T., & Hanks, S. (1999). Decision-theoretic planning: Structural assumptions computational leverage. Journal Artificial Intelligence Research,11, 194.Bowling, M., McCracken, P., James, M., Neufeld, J., & Wilkinson, D. (2006). Learningpredictive state representations using non-blind policies. Proceedings TwentyThird International Conference Machine Learning (ICML), pp. 129136.Dinculescu, M., & Precup, D. (2010). Approximate predictive representations partiallyobservable systems. Proceedings Twenty-Seventh International ConferenceMachine Learning (ICML), pp. 895902.Hansen, E. (1998). Finite-Memory Control Partially Observable Systems. Ph.D. thesis,University Massachussetts, Amherst, MA.Holmes, M., & Isbell, C. (2006). Looping suffix tree-based inference partially observable hidden state. Proceedings Twenty-Third International ConferenceMachine Learning (ICML), pp. 409416.James, M., & Singh, S. (2004). Learning discovery predictive state representationsdynamical systems reset. Proceedings Twenty-First InternationalConference Machine Learning (ICML), pp. 417424.Julier, S. J., & Uhlmann, J. K. (1997). new extension kalman filter nonlinearsystems. Proceedings AeroSense: Eleventh International SymposiumAerospace/Defense Sensing, Simulation Controls, pp. 182193.390fiLearning Make Predictions Without Generative ModelKalman, R. E. (1960). new approach linear filtering prediction problems. Transactions ASME Journal Basic Engineering, 82, 3545.Littman, M., Sutton, R., & Singh, S. (2002). Predictive representations state. AdvancesNeural Information Processing Systems 14 (NIPS), pp. 15551561.Littman, M. L. (1996). Algorithms Sequential Decision Making. Ph.D. thesis, BrownUniversity, Providence, RI.Mahmud, M. M. H. (2010). Constructing states reinforcement learning. ProceedingsTwenty-Seventh International Conference Machine Learning (ICML), pp.727734.McCallum, A. K. (1995). Reinforcement Learning Selective Perception HiddenState. Ph.D. thesis, Rutgers University.McCallum, R. A. (1993). Overcoming incomplete perception utile distinction memory.Proceedings Tenth International Conference Machine Learning (ICML),pp. 190196.Monahan, G. E. (1982). survey partially observable markov decisions processes: Theory,models, algorithms. Management Science, 28 (1), 116.Peters, J., & Schaal, S. (2008). Natural actor-critic. Neurocomputing, 71, 11801190.Poupart, P., & Boutilier, C. (2003). Bounded finite state controllers. Advances NeuralInformation Processing Systems 16 (NIPS).Puterman, M. L. (1994). Markov Decision Processes: Discrete Stochastic Dynamic Programming. John Wiley Sons, New York, NY.Rivest, R. L., & Schapire, R. E. (1994). Diversity-based inference finite automata. JournalAssociation Computing Machinery, 41 (3), 555589.Rudary, M. (2008). Predictive Linear Gaussian Models. Ph.D. thesis, UniversityMichigan.Rudary, M., Singh, S., & Wingate, D. (2005). Predictive linear-gaussian models stochastic dynamical systems. Uncertainty Artificial Intelligence: ProceedingsTwenty-First Conference (UAI), pp. 501508.Shalizi, C. R., & Klinker, K. L. (2004). Blind construction optimal nonlinear recursivepredictors discrete sequences. Proceedings Twentieth ConferenceUncertainty Artificial Intelligence (UAI), pp. 504511.Singh, S., James, M. R., & Rudary, M. R. (2004). Predictive state representations:new theory modeling dynamical systems. Uncertainty Artificial Intelligence:Proceedings Twentieth Conference (UAI), pp. 512519.Sondik, E. J. (1978). optimal control partially observable markov processesinfinite horizon: Discounted costs. Operations Research, 26, 282304.Soni, V., & Singh, S. (2007). Abstraction predictive state representations. ProceedingsTwenty-Second National Conference Artificial Intelligence (AAAI), pp. 639644.391fiTalvitie & SinghSutton, R. S., & Tanner, B. (2005). Temporal-difference networks. Advances NeuralInformation Processing Systems 17 (NIPS), pp. 13771384.Talvitie, E. (2010). Simple Partial Models Complex Dynamical Systems. Ph.D. thesis,University Michigan, Ann Arbor, MI.Talvitie, E., & Singh, S. (2009a). Maintaining predictions time without model.Proceedings Twenty-First International Joint Conference Artificial Intelligence (IJCAI), pp. 12491254.Talvitie, E., & Singh, S. (2009b). Simple local models complex dynamical systems.Advances Neural Information Processing Systems 21 (NIPS), pp. 16171624.Weaver, L., & Tao, N. (2001). optimal reward baseline gradient-based reinforcement learning. Uncertainty Artificial Intelligence: Proceedings SeventeenthConference (UAI), pp. 538545.Williams, R. (1992). Simple statistical gradient-following algorithms connectionist reinforcement learning. Machine Learning, 8, 229256.Wingate, D. (2008). Exponential Family Predictive Representations State. Ph.D. thesis,University Michigan.Wingate, D., Soni, V., Wolfe, B., & Singh, S. (2007). Relational knowledge predictivestate representations. Proceedings Twentieth International Joint ConferenceArtificial Intelligence (IJCAI), pp. 20352040.Wolfe, A. P. (2010). Paying Attention Matters: Observation Abstraction PartiallyObservable Environments. Ph.D. thesis, University Massachussetts, Amherst, MA.Wolfe, A. P., & Barto, A. G. (2006). Decision tree methods finding reusable MDPhomomorphisms. Proceedings Twenty-First National Conference ArtificialIntelligence (AAAI).Wolfe, B., James, M., & Singh, S. (2008). Approximate predictive state representations.Proceedings Seventh Conference Autonomous Agents Multiagent Systems(AAMAS).Wolfe, B., James, M. R., & Singh, S. (2005). Learning predictive state representationsdynamical systems without reset. Proceedings Twenty-Second InternationalConference Machine Learning (ICML), pp. 985992.Wolfe, B., & Singh, S. (2006). Predictive state representations options. Proceedings Twenty-Third International Conference Machine Learning (ICML), pp.10251032.392fiJournal Artificial Intelligence Research 42 (2011) 211-274Submitted 03/11; published 10/11Representing Reasoning Qualitative PreferencesCompositional SystemsGanesh Ram SanthanamSamik BasuVasant Honavargsanthan@cs.iastate.edusbasu@cs.iastate.eduhonavar@cs.iastate.eduDepartment Computer ScienceIowa State UniversityAmes, IA 50011, USAAbstractMany applications, e.g., Web service composition, complex system design, team formation, etc., rely methods identifying collections objects entities satisfyingfunctional requirement. Among collections satisfy functional requirement,often necessary identify one collections optimal respectuser preferences set attributes describe non-functional propertiescollection.develop formalism lets users express relative importance among attributesqualitative preferences valuations attribute. define dominancerelation allows us compare collections objects terms preferences attributes objects make collection. establish key propertiesdominance relation. particular, show dominance relation strict partialorder intra-attribute preference relations strict partial orders relativeimportance preference relation interval order.provide algorithms use dominance relation identify setpreferred collections. show certain conditions, algorithms guaranteedreturn (sound), (complete), least one (weakly complete)preferred collections. present results simulation experiments comparing proposedalgorithms respect (a) quality solutions (number preferred solutions)produced algorithms, (b) performance efficiency. also exploreinteresting conjectures suggested results experiments relateproperties user preferences, dominance relation, algorithms.1. IntroductionMany applications call techniques representing reasoning preferencesset alternatives. settings, preferences alternatives expressedrespect set attributes describe alternatives. preferences eitherqualitative quantitative. great deal work multi-attribute decision theoryfocused reasoning quantitative preferences (Fishburn, 1970a; Keeney & Raiffa,1993). However, many settings natural express preferences qualitativeterms (Doyle & Thomason, 1999) hence, growing interest formalismsrepresenting reasoning qualitative preferences (Brafman & Domshlak, 2009) AI.important problem context representing qualitative preferencesmultiple attributes reasoning find preferred among setc2011AI Access Foundation. rights reserved.fiSanthanam, Basu & Honavaralternatives. Brafman, Domshlak Shimonys seminal work (2006) attempts addressproblem introducing preference networks capture: (a) intra-variable intraattribute preferences specifying preferences domains attributes; (b) relativeimportance among attributes. Preference networks use graphical representationcompactly encode types preferences user, employ ceterisparibus 1 semantics reason preferred alternatives. model,alternative completely described values assigned set attributes.many AI applications planning scheduling, alternatives composite structure, i.e., alternative represents collection composition objects rathersimple objects. settings, typically set user specified functional requirements compositions required satisfy2 . Among possible compositionssatisfy functional requirements, often need choose compositionspreferred respect set user preferences set non-functionalattributes objects make composition. illustrate problemusing following example.1.1 Illustrative ExampleConsider task designing program study (POS) Masters studentComputer Science department. POS consists collection courses chosengiven repository available courses spanning different areas focus computer science.Apart area focus, course also assigned instructor numbercredit hours. repository available courses, areas focus, instructorsnumber credit hours specified Table 1.CourseCS501CS502CS503CS504CS505CS506CS507CS508CS509CS510AreaFormal Methods (FM)Artificial Intelligence (AI)Formal Methods (FM)Artificial Intelligence (AI)Databases (DB)Networks (NW)Computer Architecture (CA)Software Engineering (SE)Theory (TH)Theory (TH)InstructorTomGopalHarryWhiteBobBobWhiteTomJaneTomCredits4323423233Table 1: List courses student chooseexample, POS viewed composition courses. requirementsacceptable Masters POS (i.e., feasible composition) follows.F 1. POS include least 15 credits1. Latin term else equal2. example, planning, valid plan collection actions satisfies goal; scheduling,valid schedule collection task-to-resource assignments respects precedence constraints.212fiRepresenting Reasoning Qualitative PreferencesAIFMTHDBNWSEGopalBobJaneomW hiteCA(a)Harry(b)Figure 1: Intra-attribute preferences Area (A ) Instructor (I ).F 2. POS include two core courses CS509 CS510F 3. courses covering least two breadth areas study (apartarea Theory (TH))Given repository courses (see Table 1; may one acceptableprograms study, i.e., feasible compositions). example:P1 = CS501 CS502 CS503 CS504 CS509 CS510P2 = CS501 CS502 CS505 CS506 CS509 CS510P3 = CS503 CS504 CS507 CS508 CS509 CS510Suppose addition requirements, student preferencescourse attributes area focus, choice instructors difficultylevel terms credit hours. Among several acceptable programs study, studentmay interested programs study that: (a) satisfy minimum requirements(see above) acceptable POS, (b) preferred respecthis/her preferences specified above. preferences student respect courseattributes Area (A) Instructor (I) illustrated Figure 1 (arrows directedtoward preferred area/instructor figure, e.g., AI preferred F Bobpreferred om). addition let us say student prefers POS lessertotal number credits (this specifies C ). Further, let relative importance amongattributes A, C C, i.e., relatively important A,turn relatively important C.1.2 Problem Statement Illustrative Exampleproblems try address paper example are:Given two programs study, namely Pi Pj , determine whether Pi dominates(i.e., preferred to) Pj vice versa respect students preferences;Given repository courses algorithm computing set acceptableprograms study, find preferred, acceptable programs study respectdominance relation.213fiSanthanam, Basu & Honavarexample given Section 1.1, functional requirements correspond threeconditions F 1 F 3, must satisfied collection coursesacceptable POS. Area (A), instructor (I) number credits (C) constitute nonfunctional attributes, user preferences attributes given {A ,, C } C. One envision similar problems several applications,ranging assembling hardware software components embedded system (suchdesigning pacemaker anti-lock braking system) putting together complex piecelegislation (such one reforming health care).general, interested problem (a) reasoning preferences compositions objects, given preferences set non-functional attributes describingobjects; (b) identifying compositions satisfy functional requirementscompositional system, time optimal respect stated preferences non-functional attributes. background, present preferenceformalism set algorithms address problem compositional systems.1.3 Contributionsadopt preference network representation introduced Brafman et al. (2006)specification qualitative preferences3 valuations attribute wellrelative importance among attributes. extend reasoning preferencessingle objects deal preferences collections objects. main contributionspaper follows.1. develop preference formalism allows users specify preferences termsintra-attribute relative importance preferences set attributes,includes mechanisms for:a) Computing valuation composition: respect attribute,define generic aggregation function compute valuation compositionfunction valuations components. also present strict partialorder preference relation comparing two compositions respectaggregated valuations attribute.b) Comparing valuations compositions: introduce dominance relationcompares compositions (in terms aggregated valuations) respectstated preferences, establish key properties. particular,show relation strict partial order whenever intra-attributepreferences strict partial orders relative importance preferenceinterval order.2. develop suite algorithms identify set, subset preferredcomposition(s) respect user preferences. particular, showcertain conditions, algorithms guaranteed return (sound),(complete), least one (weakly complete) preferred compositions.algorithms develop fall two classes:3. deal conditional preferences work.214fiRepresenting Reasoning Qualitative Preferencesa) first compute set feasible compositions using functionalcomposition algorithm black box, proceed find preferredamong using preference relations developed (1);b) algorithm interleaves step execution functional composition algorithm ordering partial solutions respect userpreferences. requires functional composition algorithm able construct composition satisfying functional requirement incrementally, i.e.,iteratively extending partial compositions additional components.analyze key properties algorithms yield specific conditionsstructure preferences, algorithms produce only/at least one/allpreferred solutions.3. present results experiments compare performance algorithmscomputing preferred compositions set simulated compositionproblem instances. results demonstrate feasibility approach practice, compare algorithms respect quality (number goodpreferred) solutions produced algorithms performance (running time) efficiency (the number times invoke functional compositionalgorithm). Based analysis experimental results, also establishpreviously unknown key theoretical properties dominance relation directlyfunction user preferences.formalism generic sense one use aggregation functionappropriately represents valuation composition function valuationsconstituents. particular, show examples aggregation functions computesummation (numeric), minimum/maximum valuation (totally ordered), setworst valuations (partially ordered) constituents composition. formalismalso provides flexibility choosing preference relation compares sets valuationstwo compositions, strict partial order preference relation used.algorithms completely independent various aspects preference formalism, namely, choice aggregation functions, preference relation used compareaggregated valuations single attribute, dominance relation used comparecompositions attributes, except preference relations strict partial orders. theoretical experimental results provide precise conditionsalgorithms produce only/at least one/all preferred solutions. enablesuser choose algorithm his/her choice particular problem instance, dependingquality solutions needed. addition, analysis also allows usertrade quality solutions produced performance efficiency.1.4 Related Workclosest work related paper paper Binshtok, Brafman, Domshlak,Shimony (2009), preferences expressed collections based numberobjects collection satisfy desired property (e.g., least two politicaltwo sports articles choosing articles newspaper publication). contrast,215fiSanthanam, Basu & Honavardevelop formalism considers desirability collection whole basedattributes objects make collection, algorithms identifypreferred collection(s) among satisfy requirement. showproblems solved using formalism due Binshtok et al. also solvedformalism (see Section 7.3.2).recent years, lot work database communityevaluation preference queries (e.g., skyline queries) find preferred subsettuples result set. problem finding preferred set tuples analogousfinding preferred set alternatives, alternative simple object,i.e., tuple described set attributes. problem corresponds findingpreferred set alternatives, alternative turn set tuples satisfyrequirement (e.g., set tuples satisfy set integrity constraints). Moreover,algorithms found database literature mostly address totally weakly orderedpreferences values attributes, address partially ordered preferenceswell. addition, rely maintenance database indexesattributes tuples typically cater large scale, static datatypical setting. however note relevance possible utility techniquesdeveloped databases community problem specific scenarios.refer reader Section 7.3 detailed discussion related work.1.5 Organizationrest paper organized follows. Section 2, define compositional system,discuss types preferences consider, specify problem formalterms. Section 3, present preference formalism including dominance relationanalyze properties. Section 4, present four algorithms identifyingpreferred compositions discuss properties. proofs results sectiongiven Appendix A. Section 5, discuss complexity algorithms.InSection 6, present results experiments performed compare algorithmsterms quality solutions produced, performance efficiency. Section 7,summarize contributions discuss related future work area.2. Preliminariesrecall basic properties definitions concerning binary relations userest paper (see Fishburn, 1985, comprehensive treatment same).2.1 Properties Binary RelationsLet binary relation set S, i.e., S. say equivalence (eq),(strict) partial order (po), interval order (io), weak order (wo) total order (to),defined Table 2.total order also weak order; weak order also interval order; intervalorder also strict partial order.216fiRepresenting Reasoning Qualitative Preferences#1.2.3.4.5.6.7.8.Property relationreflexiveirreflexivesymmetricasymmetrictransitivetotal completenegatively transitiveferrersDefinitionx : x xx : x 6 xx, : x xx, : x 6 xx, y, z : x z x zx, : x 6= x xx, y, z : x x z zx, y, z, w : (x z w)(x w z y)eqXpoiowoXXXXXXXXXXXXXXXXXXXXTable 2: Properties binary relations2.2 Compositional Systemcompositional system consists repository pre-existing componentsinterested assembling compositions satisfy pre-specified functionality. Formally,compositional system tuple hR, , |=i where:R = {W1 , W2 . . . Wr } set available components,denotes composition operator functionally aggregates components encodes functional details composition. binary operation components Wi , Wj repository produces composition Wi Wj .|= satisfaction relation evaluates true composition satisfiespre-specified functional properties.Definition 1 (Compositions, Feasible Compositions Extensions). Given compositional system hR, , |=i, functionality , composition C = Wi1 Wi2 . . . Winarbitrary collection components Wi1 , Wi2 , . . . , Win s.t. j [1, n] : Wij R.i. C feasible composition whenever C |= ;ii. C partial feasible composition whenever Wj1 . . . Wjm R : C Wj1 . . . Wjmfeasible composition;iii. C Wi feasible extension partial feasible composition C whenever C Wifeasible partial feasible composition.Given compositional system hR, , |=i functionality , algorithm produces set feasible compositions (satisfying ) called functional composition algorithm. general class functional composition algorithms considertreated black boxes, simply returning set feasible compositions satisfying single step. functional composition algorithms proceed computing setfeasible extensions partial feasible compositions incrementally.Definition 2 (Incremental Functional Composition Algorithm). functional compositionalgorithm said incremental if, given initial partial feasible composition Cdesired functionality , algorithm computes set feasible extensions C.217fiSanthanam, Basu & Honavarincremental functional composition algorithm used compute feasiblecompositions recursively invoking algorithm partial feasible compositionsproduces starting empty composition (), culminating set feasiblecompositions satisfying . sense, incremental functional composition algorithmssimilar black box counterparts. However, (as later show Section 4.5)contrast black box counterparts, incremental functional composition algorithmsexploited search preferred feasible compositions, interleavingstep functional composition algorithm optimization valuationsnon-functional attributes (with respect user preferences). allows us developalgorithms eliminate partial feasible compositions lead less preferredfeasible compositions consideration early search.Different approaches functional composition, (e.g., Traverso & Pistore, 2004; Lago,Pistore, & Traverso, 2002; Baier, Fritz, Bienvenu, & McIlraith, 2008; Passerone, de Alfaro,Henzinger, & Sangiovanni-Vincentelli, 2002) differ terms (a) languages usedrepresent desired functionality compositions, (b) algorithms usedverify whether composition C satisfies , i.e., C |= . intentionally abstracteddetails functionality represented (e.g., transition systems, logic formulas, plans,etc.) composition tested satisfiability (|=) , primary focuswork orthogonal details specific methods used functional composition.2.3 Preferences Non-functional Attributesturn non-functional aspects compositional systems. addition obtaining functionally feasible compositions, users often concerned non-functionalaspects compositions, e.g., reliability composite Web service. cases,users seek preferred compositions among functionally feasible,respect set non-functional attributes describing components. order computepreferred compositions, necessary user specify his/her preferencesset non-functional attributes X .2.3.1 Notationgeneral, relation P , use notation, i.e., P denote transitiveclosure relation well, 6P P denote complement. listnotations used paper given Table 3.focus strict partial order preference relations, i.e., relationsirreflexive transitive, transitivity natural property rational preferencerelation (von Neumann & Morgenstern, 1944; French, 1986; Mas-Colell, Whinston, & Green,1995), irreflexivity ensures preferences strict.respect strict partial order preference relation P , say two elementsu v indifferent, denoted u P v, whenever u 6P v v 6P u. preferencerelations , , , denote corresponding indifference relation , ,respectively. drop subscripts whenever understoodcontext.Proposition 1. strict partial order preference relation P , corresponding indifference relation P reflexive symmetric.218fiRepresenting Reasoning Qualitative PreferencesNotationP(S)R = {W1 Wr }C, U, V, ZCX = {X1 Xm }= {D1 Dm }ui , vi , ai , bi DiVWiVCiVWi (Xj )VCi (Xj ), XF (Xi )(S)MeaningPower set setSet components repositoryOperation composes components RComposition collectionn4 set components Rset {Ci } compositionsSet non-functional attributesSet possible valuations (domains) attributes X respectivelyValuations attribute domain DiOverall valuation component Wi respect attributesXOverall valuation composition Ci respect attributesXValuation component Wi respect attribute XjValuation composition Ci respect attribute XjIntra-attribute preference valuations Xi X respectively(user input)Relative importance among attributes (user input)Aggregation function computes valuation compositionrespect Xi function valuation componentsRange aggregation function attribute XiDerived preference relation aggregated valuations respectXiDominance relation compares two compositions termsaggregated valuations attributesnon-dominated set elements respectUser specified functionality satisfied feasible compositionTable 3: NotationProof. Follows well-known property strict partial orders due Fishburn (1970b).important note indifference respect strict partial ordernecessarily transitive. instance, X = {(b, c)} strict partial order set {a, b, c}b X a, X c b X c.2.3.2 Representing Multi-Attribute PreferencesFollowing representation scheme introduced Boutilier et al. (2004) Brafman etal. (2006), model users preferences respect multiple attributes two forms:(a) intra-attribute preferences respect non-functional attribute X , (b)relative importance attributes.4. use terms composition collection; component object interchangeably.219fiSanthanam, Basu & HonavarDefinition 3 (Intra-attribute Preference). intra-attribute preference relation, denotedstrict partial order (irreflexive transitive) possible valuationsattribute Xi X . u, v Di : u v iff u preferred v respect Xi .Definition 4 (Relative Importance). relative importance preference relation, denotedstrict partial order (irreflexive transitive) set attributes X .Xi , Xj X : Xi Xj iff Xi relatively important Xj .Given set X attributes, intra-attribute preference relations {i }respective domains, relative importance preference relation X , addressfollowing problems.Given two compositions Cj Ck , determine whether VCj VCk vice versa;Given compositional system hR, , |=i, algorithm computing setfeasible compositions {Cf : Cf |= }, find preferred feasible compositionsrespect dominance relation.3. Preference FormalismGiven compositional system repository components described attributes Xpreferences ({i }, ) them, interested reasoning preferencesdifferent compositions. Note based preferences {i } , one make useexisting formalisms TCP-nets (Brafman et al., 2006) select preferredcomponents. However, problem comparing compositions (as opposed comparingcomponents) respect attribute preferences complicated factvaluation composition function valuations components. approachdeveloping preference formalism follows.First, given composition valuations components respectattributes, obtain aggregated valuation composition respectattribute function valuations components. Next, define preferencerelations compare aggregated valuations two compositions respectattribute. Finally, build dominance preference relation qualitatively comparestwo compositions respect aggregated valuations across attributes.3.1 Aggregating Attribute Valuations across Componentsorder reason preferences compositions, necessary obtain valuation composition respect attribute Xi terms components, usingaggregation function . several ways aggregate preference valuationsattribute-wise across components composition. aggregation function definesvaluation composition respect attribute Xi function valuationscomponents.Remark. compositional systems considered here, assume valuationcomposition respect attributes function valuationscomponents. words, C = W1 W2 . . . Wn , VC function{VW1 , VW2 , . . . , VWn }. However, general setting, aggregation functions220fiRepresenting Reasoning Qualitative Preferencesneed take account, addition valuations components themselves,structural functional details composition encoded (e.g., reliability Webservice composition depends whether service components composed seriesparallel structure).Definition 5 (Aggregation Function). aggregation function multiset5 possiblevaluations (Di ) attribute Xi: M(Di ) F (Xi )F (Xi ) denotes range aggregation function.Aggregation respect attribute Xi amounts devising appropriate aggregation function computes valuation composition terms valuationscomponents Xi . range F (Xi ) depends choice aggregationfunction. examples aggregation functions given below.1. Summation. applicable cases attribute real-valued represents kind cost. example, cost shopping cart sumcosts individual items includes. running example, total numbercredits POS consisting set courses sum creditscourses includes. is, set credit hours (valuations coursesrespect attribute C) courses POS,C (S) := {sS s}2. Minimum/Maximum. Here, valuation composition respect attribute worst, i.e., minimum among valuations components.type aggregation natural one consider composing embedded systemsWeb services. example, putting together several components embedded system, system secure (or safe) least secure (or safe)component.(S) := {minsS s}Analogously, one could choose valuation composition maximum (best)among valuations components. aggregation function may usefulapplications parallel job scheduling, maximum response timeused measure quality schedule.3. Best/Worst Frontier. settings, possible intra-attribute preference values attribute partial order (not necessarily rankingtotal order). Hence, may possible compute valuation composition best worst among valuations components uniquemaximum minimum may exist. example, may useful compute5. multiset generalization set allows multiple copies elements.221fiSanthanam, Basu & Honavarvaluation composition minimal set valuations among valuationscomponents, call worst frontier. worst frontier representsworst possible valuations attribute Xi respect , i.e., minimal set6among set valuations components composition.Definition 6 (Aggregation using Worst Frontier). Given set valuations attribute Xi , worst frontier aggregation function definedDi : (S) := {v : v u : v u}running example (see Section 1.1), user would like avoid coursesinterest area professors comfortable with. is, program studyconsidered good least interesting areas study covers, setprofessors least comfortable with. Hence, worst frontier aggregation functionchosen breadth area instructor attributes.Example. worst possible valuations attributes programstudy (composition) P1 respect {F M, H} {W hite, Harry}respectively. Similarly, P2 valuations attributes {DB, N W }{Jane, om} respectively; P3 valuations attributes{CA, SE} {Harry, W hite} respectively. sets correspond worst frontiers respective attributes. different areas focus covered POS P2{F M, AI, DB, N W, H}, worst frontier set ({F M, AI, DB, N W, H}) ={DB, N W } AI DB, F DB, H N W . Similarly set instructors P2 {T om, Gopal, Bob, Jane}, hence ({T om, Gopal, Bob, Jane}) ={Jane, om} Bob Jane Gopal om. attribute C, aggregationfunction evaluates sum credits constituent courses POS. Therefore, P2C ({4, 3, 4, 2, 3, 3}) = 4 + 3 + 4 + 2 + 3 + 3 = 19.note choices aggregation function accommodatedframework (such average combination best worst frontier sets),representative list choices.Proposition 2 (Indifference Frontier Elements). Consider attribute Xi , whose valuations aggregated using best worst frontier aggregation function. Let F (Xi ).u v u, v A.Proof. Follows Definition 6 (or analogous definition best frontier) wellknown result due work Fishburn (1985).Definition 7 (Valuation Composition Attributes Aggregated using Best/WorstFrontier). Consider attribute Xi , whose valuations aggregated using best worstfrontier aggregation function. valuation component W respect attributeXi denoted VW (Xi ) Di . valuation composition two components W1W2 respect attribute Xi , valuation VW1 (Xi ) VW2 (Xi ) respectively,given6. Note total order, worst frontier represents minimum lowest element setrespect total order.222fiRepresenting Reasoning Qualitative PreferencesVW1 W2 (Xi ) := (VW1 (Xi ) VW2 (Xi ))Example. Consider P2 = CS501 CS502 CS505 CS506 CS509 CS510running example (see Section 1.1).VP2 (I) = (VCS501 (I) VCS502 (I) VCS505 (I) VCS506 (I) VCS509 (I) VCS510 (I))= ({T om} {Gopal} {Bob} {Bob} {Jane} {T om})= ({T om, Gopal, Bob, Jane})= {T om, Jane}must noted VW1 W2 (Xi ) = VW2 W1 (Xi ) according definition,valuations compositions subsets union individual componentvaluations.3.2 Comparing Aggregated Valuationsobtained aggregated valuation respect attribute, next proceeddiscuss compare aggregated valuations attribute-wise. denote preferencerelation used compare aggregated valuations attribute Xi . simplecase aggregation function respect attribute Xi returns valueDi (F (Xi ) = Di ), intra-attribute preference (re)used compare aggregatedvaluations, i.e., =i . choices considered long partialorder. order obtain strict preference relation, require irreflexivity, obtainrational preference relation, require transitivity7 .worst frontier-based aggregation (Definition 6), present preference relationuses following idea: Given two compositions different aggregated valuations (worstfrontiers) A, B respect attribute Xi , say preferred B everyvaluation Xi B, valuation strictly preferred.Definition 8 (Preference Worst Frontiers). Let A, B F (Xi ) two worst frontiersrespect attribute Xi . say valuation preferred B respectXi , denoted B, element B, exists elementpreferred.A, B F (Xi ) : B b B, : bExample. running example (see Section 1.1), {F M, H} {DB, N W }F DB H N W .Given preference relation set elements, several ways obtainingpreference relation subsets elements set (see Barbera, Bossert, & Pattanaik,2004, survey preferences sets). Definition 8 one simple way achievethis. settings, contrast Definition 8, might useful compare7. preference relation, including one compares uncommon elements two setsused, provided irreflexive transitive.223fiSanthanam, Basu & Honavarelements two sets common. settings, suitable irreflexivetransitive preference relation used, asymmetric part preferencerelations developed Brewka et al. (2010) Bouveret et al. (2009). absencetransitivity, transitive closure relation may used compare sets elements,done Brewka et al.discuss properties specific relation introduced Definition 8.Proposition 3 (Irreflexivity ). F (Xi ) 6 A.Proof. a, b A, b(follows P roposition 2)Proposition 4 (Transitivity ). A, B, C F (Xi ), B B C C.Proof. Immediate Definition 8.Definition 9. Let A, B F (Xi ). say valuation least preferred Brespect Xi , denoted iffB = B BProposition 5. reflexive transitive.Proof. Follows facts = reflexive transitive, irreflexivetransitive.Definition 10 (Complete Valuation). complete valuation outcome assignmentcomposition C defined tuple VC := hVC (X1 ), . . . VC (Xm )i, VC (Xi ) F (Xi ).F (Xi ).set possible valuations outcomes denotedi=1Example. case example Section 1.1:VP 1= hA ({F M, AI, H}), ({T om, Gopal, Harry, W hite, Jane}), C ({4, 3, 2, 3, 3, 3})i= h{F M, H}, {W hite, Harry}, {18}iVP 2= hA ({F M, AI, DB, N W, H}), ({T om, Gopal, Bob, Jane}), C ({4, 3, 4, 2, 3, 3})i= h{DB, N W }, {T om, Jane}, {19}iVP 3= hA ({F M, AI, CA, SE, H}), ({Harry, W hite, om, Jane}), C ({2, 3, 3, 2, 3, 3})i= h{CA, SE}, {Harry, W hite}, {16}i3.3 Dominance: Preference Compositionsprevious sections, discussed evaluate compare compositionrespect attributes function components. order identify preferredcompositions, need compare compositions respect aggregated valuationsattributes, based originally specified intra-attribute relative importancepreferences. present specific dominance relation performing comparison.224fiRepresenting Reasoning Qualitative PreferencesU V Xi X : U(Xi ) V(Xi )Xk X : (Xk Xi Xk Xi ) U(Xk ) k V(Xk )Layer 2(Dominance)ComparecompositionsF (Di )i=1F (Di )i=1F (Dm ) F (Dm )Compare1 F (D1 ) F (D1 ) 2 F (D2 ) F (D2 )aggregated valuationsF (D1 )F (D2 )Layer 1(Aggregation)Computeaggregated valuations12P(D1 )UserInputX XX = {X1 , X2 , . . . Xm }F (Dm )...P(D2 )P(Dm )1 D1 D12 D2 D2...Dm DmD1 = {a1 , a2 . . .}D2 = {b1 , b2 . . .}...Dm = {u1 , u2 . . .}Relative ImportanceIntra-attribute preferencesFigure 2: Dominance: Preference compositionsDefinition 11 (Dominance). Dominance binary relation defined follows:F (Xi )U 8 , Vi=1U VXi : U(Xi ) V(Xi )Xk : (Xk Xi Xk Xi ) U(Xk ) k V(Xk )Definition 11, call attribute Xi witness relation. dominancerelation derived respects intra-attribute preferences (i ) wellrelative importance preferences () asserted user. Figure 2 graphically illustratesdominance derived user-specified preferences. First, start userspecified preferences, namely intra-attribute (i ) relative importance () preferences.Next, preferences, valuations compositions respect attributescomputed using aggregation function (i ). intra-attribute preference relationcompare aggregated valuations ( ) derived . Finally, global dominance( ) defined terms .definition dominance states composition U dominates V iff findwitness attribute Xi respect intra-attribute preference ,valuation U dominates V terms , attributes Xk user considersimportant () indifferent () Xi , valuation Xk U leastpreferred ( ) valuation Xk V.8. avoid excessively cluttering notation, given composition C, slightly abuse notationusing C interchangeably VC .225fiSanthanam, Basu & HonavarExample. running example (see Section 1.1), VP2 VP1 witnessVP1 VP3 witness. A, C C VP2 VP1 VP2 VP3witness, VP1 6 VP3 VP3 6 VP1 . P1 preferred P3respect ({F M, H} {CA, SE}); P3 preferred P1 respect C({16} C {18}), neither C relatively important other.3.4 Propertiesproceed analyze properties respect worst-frontier aggregation function. First, show partial feasible composition dominatedrespect extensions. property useful establishingsoundness algorithms compute preferred compositions (see Section 4).Next, observe irreflexive (follows irreflexivity ), proceedidentify conditions transitive. focus transitive preferences many studies considered transitivity key property preference relations(von Neumann & Morgenstern, 1944; French, 1986; Mas-Colell et al., 1995)9 .Proposition 6. Whenever preferences aggregated using worst-frontier based aggregation function, partial feasible composition C, feasible extension C Wdominates it, i.e., VCW 6 VC .Proof. proof proceeds showing respect attribute Xi , VCW (Xi ) 6VC (Xi ), thereby ruling existence witness VCW VC . Supposecontradiction, C W feasible extension C VCW VC . Definition 11,VCW VC requires existence witness attribute Xi X VCW (Xi ) VC (Xi ),i.e.,b VC (Xi ) VCW (Xi ) : b(1)Definition 7, VCW (Xi ) = (VC (Xi ) VW (Xi )). However, Definition 6(VC (Xi ) VW (Xi )) b VC (Xi ) VW (Xi ) : b, contradicts Equation (1).rules existence witness VCW VC . Hence, VCW 6 VC .next proceed show necessarily transitive intra-attributerelative importance preference relations arbitrary strict partial orders.Proposition 7. intra-attribute preferences well relative importance amongattributes arbitrary partial orders, U V V Z ; U ZProof. show counter example compositional system partially ordered {i },compositions U, V, Z U V, V Z U 6 Z.Consider system set attributes X = {X1 , X2 , X3 , X4 }, domainsD1 = {a1 , b1 }, . . . D4 = {a4 , b4 }. Let relative importance relation X intraattribute preferences 1 . . . 4 given = {(X1 , X3 ), (X2 , X4 )} = {(ai , bi )}, =1, 2, 3, 4 respectively (Figure 3). valuations U, V, Z respect attributes Xgiven Table 4.9. studies human decision making argued human preferences necessarilytransitive (Tversky, 1969), others offered evidence contrary (Regenwetter, Dana, & DavisStober, 2011).226fiRepresenting Reasoning Qualitative PreferencesIntra-variable preferencesRelative Importance ()a1 1 b1X2X1a2 2 b2a3 3 b3a4 4 b4X4X3U = h{a1 }, {a2}, {b3}, {b4}iV = h{b1 }, {a2}, {a3}, {b4}iZ = h{b1 }, {b2}, {a3}, {a4 }iFigure 3: Counter exampleComp. (C)VC (X1 )VC (X2 )VC (X3 )VC (X4 )UVZa1b1b1a2a2b2b3a3a3b4b4a4Table 4: Valuations U, V, ZClearly U V X1 witness, V Z X2 witness. addition,note that:Z(X3 ) 3 U(X3 )(2)Z(X4 ) 4 U(X4 )(3)However, observe U 6 Z:a. X1 witness due X4 X1 Equation (3).b. X2 witness due X3 X2 Equation (2).c. X3 witness due Equation (2).d. X4 witness due Equation (3).proposition shows dominance relation transitivearbitrary partial orders, considering worst-frontier based aggregation.transitivity preference necessary condition rational choice (von Neumann227fiSanthanam, Basu & Honavar& Morgenstern, 1944; French, 1986; Mas-Colell et al., 1995), proceed investigatepossibility obtaining dominance relation restricting . later proverestriction necessary sufficient transitivity .Definition 12 (Relative Importance Interval Order). relative importance relationbinary relation reflexive satisfies following axiom.Xi , Xj , Xk , Xl X : (Xi Xj Xk Xl ) (Xi Xl Xk Xj )(4)say Xi relatively important Xj Xi Xj .Proposition 8 (Transitivity see Fishburn, 1985). transitive.Remarks.1. Definition 12 imposes additional restriction structure relative importance relation , strict partial order. strict partial order irreflexivetransitive; however, relative importance relation Definition 12addition satisfy Equation (4), thereby yielding interval order (Fishburn, 1985).2. indifference relation respect , namely transitive. example,three attributes X = {X1 , X2 , X3 }, = {(X1 , X2 )}. satisfiescondition interval order, X1 X3 X3 X2 , X1 6 X2X1 X2 .Propositions 9-12 establish properties dominance relation caserelative importance relation interval order. particular, proveirreflexive (Proposition 9) transitive (Proposition 12), making strict partialorder (Theorem 1).Proposition 9 (Irreflexivity ). UF (Xi ) U 6 U.i=1Proof. Suppose U U contradiction. Xi , s.t. U(Xi ) U(Xi ) definition.contradicts Proposition 3.proposition ensures dominance relation strict compositions. words, composition preferred itself. Next, proceed establishimportant property rational preference relations: transitivity . makeuse two intermediate propositions 10 11 needed task.Proposition 10, prove attribute Xi relatively importantXj , Xi important third attribute Xk implies Xj alsoimportant Xk . help us prove transitivity dominance relation.Figure 4 illustrates cases arise.Proposition10. Xi , Xj , Xk :Xi Xj (Xk Xi Xk Xi ) (Xk Xj Xk Xj )228fiRepresenting Reasoning Qualitative PreferencesXk XiXk XiXkXiXiXjXkXkXiXjXj(a)(b)(c)Figure 4: Xi Xj (Xk Xi Xk Xi )proof follows fact partial order.Proof.1. Xi Xj(Hyp.)2. Xk Xi Xk Xi(Hyp.) Show Xk Xj Xk Xj2.1. Xk Xi Xk Xj transitivity (1.); see Figure 4(a)2.2. Xk Xi Xk Xj Xk Xji. Xk Xi (Hyp.)ii. (Xk Xj ) (Xj Xk ) (Xk Xj ) Always; see Figure 4(b,c)iii. Xj Xk Xi Xk (1.) Contradiction!iv. Xk Xj Xk Xj (2.2.ii., iii.)3. Xi Xj (Xk Xi Xk Xi ) (Xk Xj Xk Xj )(1., 2.1, 2.2)Proposition 11 states attributes Xi , Xj Xi Xj leastone them, Xu respect other, Xv , attribute Xkless important time Xk Xu . result needed establishtransitivity dominance relation.Proposition 11. Xi , Xj , u 6= v, Xi Xj Xu , Xv {Xi , Xj }, Xk : (Xu XkXv Xk )proof makes use fact relative importance interval order relation.Proof. Let Xi Xj , Xi Xj attributes less important Xi Xjrespectively (if any). Figure 5 illustrates cases. Figure 5(a, b, c, d, e) illustratescases one Xi Xj exists, case claim holds trivially.example, cases Figure 5(a, b, c), Xu = Xi ; Xv = Xj Xu = Xj ; Xv = Xisatisfy implication, cases Figure 5(d, e), corresponding satisfactoryassignments Xu Xv shown figure. case Figure 5(f) never arisesinterval order (see Definition 12). Hence, proposition holdscases.229fiSanthanam, Basu & HonavarXiXjXi(a)XiXjXiXjXi(b)XjXiXjXiXj(c)XjXu = XjXv = XiXu = XiXv = Xj(d)(e)XiXjXiXjContradiction!( interval order )(f)Figure 5: Xi Xjproposition reflects interval order property relation,complements result Proposition 7, shown intransitiveinterval order. fact, relative importance defined strict partial orderinstead, proof hold. Given U V witness Xi V Zwitness Xj , proposition guarantees one among Xi Xj chosenpotential witness U Z conditions demonstrated counter exampleProposition 7 avoided. Using propositions 10 11, positionprove transitivity Proposition 12.Proposition 12 (Transitivity ). U, V, ZF (Xi ),i=1U V V Z U Z.proof proceeds considering possible relationships Xi , Xj , respective attributes witnesses dominance U V V Z. Lines 5, 6, 7proof establish dominance U Z cases Xi Xj , Xj Xi Xi Xjrespectively. first two cases, important attribute among Xi Xj shownwitness U Z help Proposition 10; last case makeuse Proposition 11 show least one Xi , Xj witness U Z.Proof.1. U V(Hyp.)2. V Z(Hyp.)3. Xi : U(Xi ) V(Xi ) (1.)4. Xj : V(Xj ) j Z(Xj ) (2.)Three cases arise: Xi Xj (5.), Xj Xi (6.) Xi Xj (7.).230fiRepresenting Reasoning Qualitative Preferences5. Xi Xj U Z5.1.5.2.5.3.5.4.Xi Xj (Hyp.)V(Xi ) Z(Xi ) (2., 5.1.)U(Xi ) Z(Xi ) (3., 5.2.)Xk : (Xk Xi Xk Xi ) U(Xk ) k Z(Xk )i. Let Xk Xi Xk Xi (Hyp.)ii. U(Xk ) k V(Xk ) (1., 5.4.i.)iii. Xk Xj Xk Xj (5.4.i., P roposition 10)iv. V(Xk ) k Z(Xk ) (2., 5.4.iii.)v. U(Xk ) k Z(Xk ) (5.4.ii., 5.4.iv.)5.5. Xi Xj U Z (5.1., 5.3., 5.4.)6. Xj Xi U Z6.1. true symmetry Xi , Xj proof (5.); case, easilyshown U(Xj ) Z(Xj ) Xk : (Xk Xj Xk Xj ) U(Xk ) k Z(Xk ).7. Xi Xj U ZXi Xj (Hyp.)Xu , Xv {Xi , Xj } : Xu 6= Xv Xk : (Xu Xk Xv Xk ) (7.1., P roposition 11)Without loss generality, suppose Xu = Xi , Xv = Xj (Hyp.).V(Xi ) Z(Xi ) (2., 7.1.)U(Xi ) Z(Xi ) (3., 7.4.)Xk : Xk Xi U(Xk ) k Z(Xk ).i. Xk Xi (Hyp.)ii. U(Xk ) k V(Xk ) (1., 7.6.i.)iii. Xk Xj Xk Xj Xj Xk Contradicts (7.1., 7.6.i.)!iv. V(Xk ) k Z(Xk ) (2., 7.6.iii.)v. U(Xk ) k Z(Xk ) (7.6.ii., 7.6.iv.)7.7. Xk : Xk Xi U(Xk ) k Z(Xk )i. Xk Xi (Hyp.)ii. U(Xk ) k V(Xk ) (1., 7.7.i.)iii. Xk Xj Xk Xj Xj Xk Contradicts (7.2., 7.3.)!iv. V(Xk ) k Z(Xk ) (2., 7.7.iii.)v. U(Xk ) k Z(Xk ) (7.7.ii., 7.7.iv.)7.8. Xk : Xk Xi Xk Xi U(Xk ) k Z(Xk ) (7.6., 7.7.)7.9. Xi Xj U Z (7.5., 7.8.)7.1.7.2.7.3.7.4.7.5.7.6.8. (Xi Xj Xj Xi Xi Xj ) U Z9. U V V Z U Z(5., 6., 7.)(1., 2., 8.)Theorem 1. intra-attribute preferences arbitrary strict partial ordersrelative importance interval order, strict partial order.Proof. Follows immediately Propositions 9 12.231fiSanthanam, Basu & HonavarXiXjXiXjFigure 6: 2 2 substructure, Interval Order3.5 Role Interval Order Restriction TransitivityTheorem 1 establishes given partially ordered intra-attribute preferences ,relative importance relation () interval order (Definition 12), transitive.addition, also seen counter example Proposition 7, showstransitivity necessarily hold arbitrary partial order.condition weaker interval order restriction still makestransitive retain intra-attribute preferences arbitrary partial orders dominanceDefinition 11? answer turns no, prove next.proceed prove necessity interval ordered relative importancerelation transitive dominance relation , examine interval ordersclosely. Recall Definition 12 every interval order X partial order,additionally satisfies Ferrers axiom X1 , X2 , X3 , X4 X :(X1 X2 X3 X4 ) (X1 X4 X3 X2 )borrow characterization axiom Fishburn (1970a, 1985)relation interval order 2 2 * , 2 2 relational structureshown Figure 6. words, partial order interval orderrestriction isomorphic partial order structure shown Figure 6.Theorem 2 (Necessity Interval Order). partially ordered intra-attribute preferencesdominance relation Definition 11, transitive relative importanceinterval order.Proof. Assume interval order. true 2 2 .However, showed Proposition 7 case, transitive using counterexample (see Figure 3). Hence, transitive relative importance intervalorder.3.6 Additional Properties Respect Properties {i }present additional properties10 hold certain restrictionsimposed intra-attribute relative importance preference relations.Proposition 13. total order Xi important attribute Xrespect , .10. results section essentially prove conjectures arose analysis resultsexperiments (see Section 6).232fiRepresenting Reasoning Qualitative PreferencesProof. Let Xi (unique) important attribute X . Suppose U(Xi ) V(Xi ),thereby making Xi potential witness U V. Since Xi important attribute,Xk X : Xi Xk , second clause definition U V trivially holds. Hence, Xiwitness U V (see Definition 11).Note proof proposition made use fact XkX : Xi Xk , weaker condition total order. Hence,following general result.Proposition 14. unique important attribute Xi , i.e.,Xi X : Xk X \ {Xi } : Xi Xk , .proceed prove important result gives conditionsweak order.Theorem 3. aggregation function defined Definition 8, well{i } total orders, weak order.Proof. weak order strict partial order negatively transitive.already shown strict partial order Theorem 1, henceleft proving negatively transitive, i.e., U 6 V V 6 Z U 6 Z.First, note since total order, also total order (see Definition 8).U 6 V (Xi : U(Xi ) V(Xi ) Xk : (Xk Xi U(Xk ) 6 k V(Xk ))) (Xk Xipossible total order).(1)Let Xi Xj important attributes s.t. U(Xi ) V(Xi ) V(Xj ) j Z(Xj )respectively.(2)Let Xp Xq important attributes s.t. Xp Xi U(Xp ) 6 p V(Xp )Xq Xj V(Xq ) 6 q Z(Xq ) respectively (such Xp Xq must exist (1)).(3)Case 1 Xi Xj defined (2) exist (cases Xi and/or Xj dont existdealt separately).Three sub-cases arise: Xp Xq , Xq Xp Xp = Xq .Case 1a: Suppose Xp Xq (see Figure 7).(4)(3) know Xp Xi U(Xp ) 6 p V(Xp ), i.e., V(Xp ) p U(Xp ).(5)(3) (4) know V(Xp ) p Z(Xp ), Xq importantattribute also important Xj V(Xq ) 6 q Z(Xq ), Xpimportant Xq (and hence Xj well).(6)Xj important attribute V(Xj ) j Z(Xj ), Xp Xj(since Xq Xj Xp Xq ), V(Xp ) 6 p Z(Xp ) (as Xj importantattribute V(Xj ) j Z(Xj ), using (2)). Along (6), means V(Xp ) =Z(Xp ).(7)(5) (7), Z(Xp ) p U(Xp ).(8)Also, Xk : Xk Xp U(Xk ) = V(Xk ) V(Xk ) = Z(Xk ) (because Xkimportant Xi , Xj Xp , Xq ).(9)233fiSanthanam, Basu & HonavarU (Xk ) = V(Xk )V(Xk ) = Z(Xk )XpU (Xi) V(Xi )XqV(Xj ) j Z(Xj )Figure 7: case Xp Xq(8) (9), Z U Xp witness. Hence, U 6 Z.Case 1b: Suppose Xq Xp . claim holds symmetry.Case 1c: Suppose Xp = Xq .(3) know Xp Xi U(Xp ) 6 p V(Xp ), i.e., V(Xp ) p U(Xp ).Similarly, Z(Xp ) p V(Xp ).Hence, Z(Xp ) p U(Xp ). Moreover, Xk : Xk Xp U(Xk ) = V(Xk ) V(Xk ) =Z(Xk ) (because Xk important Xi , Xj Xp , Xq ).Therefore, Z U Xp witness. Hence, U 6 Z.Case 2 : Xi (say) exist, Xi : U(Xi ) 6 V(Xi ). Let Xpimportant attribute s.t. V(Xp ) p U(Xp ) (if Xp exist, trivially U 6 ZU = V).(10)Case 2a: Suppose Xp Xq . Xk : Xk Xp V(Xk ) = Z(Xk ) (because Xk Xqwell). Moreover, Xp Xq V(Xp ) = Z(Xp ). Hence, Z U Xp witnesstherefore U 6 Z.Case 2b: Suppose Xq Xp . Xk : Xk Xq U(Xk ) = V(Xk ) (because Xk Xpwell). Moreover, Xq Xp U(Xq ) = V(Xq ). Hence, Z U Xq witnesstherefore U 6 Z.Case 2c: Suppose Xp = Xq . Xk : Xk Xp V(Xk ) = Z(Xk ) (because Xk Xqwell) similarly Xk : Xk Xq U(Xk ) = V(Xk ) (because Xk Xp well). Moreover,since V(Xq ) 6 q Z(Xq ) (by (3)), V(Xp ) p U(Xp ) (using (10)) Z(Xp ) p U(Xp ).Hence, Z U Xp witness therefore U 6 Z.Case 3: Xj (say) exist, proof symmetric Case 2.Case 4 : Suppose Xi Xj exist. Then, attribute Xi ,V(Xi ) U(Xi ) Z(Xi ) V(Xi ), i.e., Xi : Z(Xi ) U(Xi ). Hence, witnessU Z, U 6 Z.Cases 1 - 4 exhaustive, case U 6 Z. completes proof.234fiRepresenting Reasoning Qualitative Preferencesconjecture weak order {i } total ordersarbitrary interval order (i.e., conditions general conditionsTheorem 3). leave open problem.Conjecture 1. {i } total orders arbitrary interval order,weak order.Remark.stated, Conjecture 1 Theorem 3 apply whenever {i } totally ordered,using method comparing two aggregated valuations ( ) (see Definition 8).generally, note hold whenever { } total orders, regardless chosenmethod comparing two aggregated valuations, regardless propertiesinput intra-attribute preferences {i }. example, suppose {i } ranked weakorders (i.e., total orders). such, Conjecture 1 Theorem 3 apply. However,attribute Xi define (S) rank number corresponding worstfrontier S, natural total order ranks weak order,consequences Conjecture 1 Theorem 3 hold.summarize theoretical results relating properties dominance relationproperties preference relations { } Table 5.RemarksioiopopowowoTheorem 1Conjecture 1Theorem 3Table 5: Summary results conjectures relating properties respectproperties { }.3.7 Choosing Preferred SolutionsGiven set C = {Ci } compositions preference relation (e.g., ) allowsus compare pair compositions, problem find preferred composition(s). preference relations totally ordered (e.g., ranking) setalternative solutions, rationality choice suggests ordering alternatives respectcomplete preference choosing best alternative, i.e., one rankshighest. However, preference relation strict partial order, e.g., case, every pair solutions (compositions) may comparable. Therefore, solutionpreferred respect preference relation may exist. Hence,use notion non-dominated set solutions defined follows.Definition 13 (Non-dominated Set). non-dominated set elements (alternativessolutions compositions) set C respect (partially ordered) preference relation(e.g., ), denoted (C), subset C none elementspreferred element (C).235fiSanthanam, Basu & Honavar(C) = {Ci C|Cj C : Cj Ci }Note per definition, (C) maximal set elements C respectrelation . also easy observe C 6= (C) 6= .4. Algorithms Computing Preferred Compositionsturn problem identifying set feasible compositions (that satisfypre-specified functionality ()), preferred subset, i.e., non-dominated set.4.1 Computing Maximal/Minimal Subset Respect Partial Orderstraightforward way computing maximal (non-dominated) elements setn elements respect preference relation following algorithm:element si S, check sj : sj si , not, si non-dominatedset. simple compare pairs delete dominated approach involves computingdominance respect O(n2 ) times.Recently Daskalakis, Karp, Mossel, Riesenfeld Verbin (2009) provided algorithmperforms O(wn) pairwise comparisons compute maximal elementsset respect partial order , n = |S| w width partialorder (the size maximal set pairwise incomparable elementsrespect ). algorithm presented Daskalakis et al. finds minimal elements;corresponding algorithm finding maximal elements follows.Let T0 = . Let elements set x1 , x2 , xn . step t( 1):Compare xt elements Tt1 .exists Tt1 xt , nothing.Otherwise, remove Tt1 elements xt put xt Tt .termination, set Tn contains maximal elements S, i.e., non-dominatedsubset respect . make use algorithm compute nondominated (maximal) subsets (namely, ()), original version algorithmgiven Daskalakis (2009) compute worst-frontiers (minimal subsets).4.2 Algorithms Finding Preferred Feasible Compositionsproceed develop algorithms finding preferred feasible compositions, givencompositional system hR, , |=i consisting repository R pre-existing components,user specified functionality , user preferences {i } functional compositionalgorithm f . analyze properties algorithms respect worst-frontierbased aggregation (see Definition 6).Definition 14 (Soundness Completeness). algorithm that, given set Cfeasible compositions, computes set feasible compositions SA (C) saidsound respect C. algorithm complete respect C SA (C).236fiRepresenting Reasoning Qualitative PreferencesAlgorithm 1 ComposeAndFilter(, f, )1. Find set C feasible compositions w.r.t. using f2. return (C)Given compositional system hR, , |=i consisting repository R pre-existing components, user specified functionality , straightforward approach findingpreferred feasible compositions involves: (a) computing set C functionallyfeasible compositions using functional composition algorithm f , (b) choosingnon-dominated set according preferences non-functional attributes.Algorithm 1 follows simple approach produce set (C) non-dominatedfeasible compositions, invoked preference relation , functional composition algorithm f desired functionality . (C) computed usingprocedure described Section 4.1. Algorithm 1 sound complete respectC.4.3 Sound Weakly Complete AlgorithmNote worst case, Algorithm 1 evaluates dominance relationpossible pairs feasible compositions C. However, avoided settlenon-empty subset (C). Note every solution subset guaranteedoptimal respect user preferences . introduce notion weakcompleteness describe algorithm computes set feasible compositions, leastone non-dominated respect .Definition 15 (Weak Completeness). algorithm that, given set C feasible compositions, computes set SA feasible compositions said weakly complete respectC (C) 6= SA (C) 6= .proceed describe sound weakly complete algorithm, i.e., one computes non-empty subset (C). algorithm based following observation:Solutions non-dominated respect relatively most-importantattributes guaranteed include solutions non-dominated overallrespect well. Hence, solutions preferred respectattribute used compute non-empty subset (C). proceedconsidering solutions preferred respect attribute Xi .Definition 16 (Non-dominated solutions w.r.t. attributes). set (C) solutionsnon-dominated respect attribute Xi defined(C) = {U | U C V C : V(Xi ) U(Xi )}.Let X set important attributes respect , i.e., = (X ) ={Xi |Xj X : Xj Xi }. Clearly, 6= always exists non-empty maximalset elements partial order . following proposition states every Xi I,least one solutions (C) also contained (C).Proposition 15. Xi : (C) 6= (C) (C) 6= (See Appendixproof ).237fiSanthanam, Basu & HonavarAlgorithm 2 constructs subset (C), using sets { (C) | Xi I}. First,algorithm computes set important attributes X respect (Line 2).algorithm iteratively computes (C) Xi (Lines 3, 4), identifies subsetsolutions non-dominated respect case, combinesobtain (C).Algorithm 2 WeaklyCompleteCompose({i | Xi X }, , f, )1.2. (X ) = {Xi | Xj : Xj Xi }3. Xi4.(C) ComposeAndFilter( , f, )5.( (C))6. end7. returnTheorem 4 (Soundness Weak Completeness Algorithm 2). Given set attributesX , preference relations , Algorithm 2 generates set feasible compositions(C) (C) 6= 6= (See Appendix proof ).general, Algorithm 2 guaranteed yield complete set solutions, i.e., 6=(C). following example illustrates case.Example. Consider compositional system two attributes X = {X1 , X2 },domains {a1 , a2 , a3 } {b1 , b2 , b3 } respectively. Let intra-attribute preferencestotal orders: a1 1 a2 1 a3 b1 2 b2 2 b3 respectively, let attributesequally important ( = ). Suppose user-specified goal satisfied three feasiblecompositions C1 , C2 , C3 valuations VC1 = h{a1 }, {b3 }i, VC2 = h{a3 }, {b1 }i VC3 =h{a2 }, {b2 }i respectively. Given preferences, 1 (C) = {C1 } 2 (C) = {C2 }.Thus, = {C1 , C2 } However, (C) = {C1 , C2 , C3 } =6 .example shows preferred valuation one attribute (e.g., X1 )result poor valuations one attributes (e.g., X2 ). Algorithm 2 maythus leave solutions like C3 preferred respect one ,nevertheless may correspond good compromise consider multipleimportant attributes. natural question ask minimal conditionsAlgorithm 2 complete. related question whether Algorithm 2guaranteed produce certain minimum number non-dominated solutions (||)specific set conditions. Note general, cardinality dependsuser preferences , , also user specified functionality togetherrepository R determines set C feasible compositions. However, specialcase specifies single attribute Xt relatively importantattributes, show Algorithm 2 complete.Proposition 16. = {Xt } Xk 6= Xt X : Xt Xk , (C) , i.e.,Algorithm 2 complete (See Appendix proof ).remains seen necessary sufficient conditions ensuringcompleteness Algorithm 2, plan address problem future.238fiRepresenting Reasoning Qualitative Preferences4.4 Optimizing Respect One Important Attributessee Section 5, Algorithm 2 high worst case complexity, especiallyset important attributes large. due factimportant attribute Xi I, algorithm computes non-dominated setfeasible compositions respect first, respect , i.e.,( (C)) (Line 4). computation non-dominated set respect ,although expensive, crucial ensuring soundness Algorithm 2.soundness desirable property, may settings requiring faster computation feasible compositions, may acceptable obtain set feasiblecompositions contains least one (whenever exists one) preferredfeasible compositions (one non-dominated feasible compositionrespect ). case, might useful algorithm lower complexity finds set feasible compositions least one preferred (i.e.,weakly complete), opposed one higher complexity finds set feasiblecompositions preferred (i.e., sound).Algorithm 3 AttWeaklyCompleteCompose({i | Xi X }, , f, )1. (X ) = {Xi | Xj : Xj Xi }2. Xi3. (C) = ComposeAndFilter( , f, )4. returnconsider one modification Algorithm 2, namely Algorithm 3, arbitrarilypicks one important attributes Xi (as opposed entire setAlgorithm 2) finds set feasible compositions non-dominatedrespect , i.e., = (C) Algorithm 3.weak completeness Algorithm 3 follows directly Proposition 15.following example, however, show feasible compositions producedAlgorithm 3 may dominated feasible composition respect ,i.e., Algorithm 3 sound.Example. Consider compositional system two attributes X = {X1 , X2 },domains {a1 , a2 } {b1 , b2 } respectively. Let intra-attribute preferences be: a1 1 a2b1 2 b2 respectively, let attributes equally important ( = ; ={X1 , X2 }). Suppose user-specified goal satisfied three feasible compositionsC1 , C2 , C3 valuations VC1 = h{a1 }, {b1 }i, VC2 = h{a2 }, {b1 }i VC3 = h{a1 }, {b2 }irespectively. Given preferences, choose maximize preferencerespect attribute X1 I, = 1 (C) = {C1 , C3 }. choose X2 instead,get = 2 (C) = {C1 , C2 }. However, case (C) = {C1 } =6 .following proposition gives condition Algorithm 3 complete.Proposition 17. |I| = 1, i.e., unique important attribute respect, Algorithm 3 complete (See Appendix proof ).239fiSanthanam, Basu & HonavarAlgorithm 4 InterleaveCompose(L, , f, )1. L =2.return3. end4. = (L)5. =6. C7.C 6|=8.= f (C)9.else10.= {C}11.end12. end13. =14.return15. else16.InterleaveCompose((L \ ) , , f, )17. end4.5 Interleaving Functional Composition Preferential OptimizationAlgorithms 1, 2 3 identify preferred feasible compositions using twostep approach: (a) find feasible compositions C; (b) compute subset Cpreferred respect user preferences. develop algorithm eliminatesintermediate partial feasible compositions consideration based userpreferences. particularly useful settings (such |C| large relative| (C)|), might efficient compute subset C likely(based ) (C).Algorithm 4 requires functional composition algorithm f incremental (seeDefinition 2), i.e., produces set f (C) functionally feasible extensions givenexisting partial feasible composition C. step, Algorithm 4 chooses subsetfeasible extensions produced applying f non-dominated partial feasiblecompositions, based user preferences. Algorithm 4 computes non-dominatedset feasible compositions interleaving execution incremental functionalcomposition algorithm f ordering partial solutions respect preferencesnon-functional attributes.Algorithm 4 initially invoked using parameters L = () 11 , , functionalcomposition algorithm f . algorithm maintains step list L partialfeasible compositions consideration. L empty step, i.e.,partial feasible compositions explored, algorithm terminates11. necessary invoke algorithm L = () (i.e., list L) initially.may functional composition algorithms begin non-empty composition C proceedobtain feasible composition iteratively altering C. instance, one could think randomizedevolutionary algorithms begin random, non-empty composition somehow repeatedlyimproved course composition.240fiRepresenting Reasoning Qualitative Preferencessolution (Lines 1 3); otherwise selects L, subset non-dominatedrespect preference relation (Line 4). partial feasible compositionsalso feasible compositions, algorithm outputs terminates (Lines 1314). Otherwise, replaces partial feasible compositions feasiblecompositions, one-step extensions (Lines 7 8). algorithm continuesrecurse (Line 16), iteration updating dominated set replacingchanges dominated set i.e., = . Note possibleeliminate dominated compositions (L \ ) stage extensions(in later iteration) could result non-dominated compositions.Proposition 18 (Termination Algorithm 4). Given finite repository components,Algorithm 4 terminates finite number steps (See Appendix proof ).next investigate soundness, weak-completeness completeness properties Algorithm 4. Proposition 19 states algorithm general sound respectC, i.e., guaranteed produce feasible compositions non-dominatedrespect . However, discount usefulness algorithm,show sound assumptions (see Theorem 5).Proposition 19 (Unsoundness Algorithm 4). Given functional composition algorithmf user preferences set attributes X , Algorithm 4 guaranteedgenerate set feasible compositions (C) (See Appendixproof ).result implies general, feasible compositions returned Algorithm 4() (C). example shown Figure 8 illustrates problem. timetermination, may exist partial feasible composition B list Ldominated feasible composition E ; however, may possible extend Bfeasible composition B W dominates one compositions F (as illustratedcounter example proof, see Appendix A). words, VB , VF ,VF VB VBW VF .... E F ......B...B WFigure 8: case Algorithm 4 soundAlthough Algorithm 4 sound general, show soundrelation interval order (as opposed arbitrary partial order).Theorem 5 (Soundness Algorithm 4). interval order, given functional composition algorithm f user preferences { }, set attributes X ,241fiSanthanam, Basu & HonavarAlgorithm 4 generates set feasible compositions (C) (See Appendixproof ).Theorem 5 requires interval order, important question arises:conditions interval order? Theorem 3 (see Section 3.6)gives us one condition weak order (i.e., also interval order). nexttwo theorems give conditions Algorithm 4 weakly complete completerespectively.Theorem 6 (Weak Completeness Algorithm 4). interval order, givenfunctional composition algorithm f user preferences { }, set attributes X ,Algorithm 4 produces set feasible compositions (C) 6= (C) 6=(See Appendix proof ).Theorem 7 (Completeness Algorithm 4). weak order, given functional composition algorithm f user preferences { }, set attributes X ,Algorithm 4 generates set feasible compositions (C) (See Appendixproof ).Remark. algorithm explore feasible compositions generated extending feasible compositions (by condition Line 7). Proposition6 shows worst-frontier based aggregation used, extending feasible composition cannot yield preferred feasible composition. guarantees soundnessAlgorithm 4 (Theorem 5). However, aggregation schemes used, mightcase feasible extension feasible composition preferred,case, order ensure soundness Algorithm 4, Line 10 changed= {C} f (C).summary conditions (in terms properties relative importancedominance preference) algorithms sound, complete weak completegiven Table 6.AlgorithmSoundWeakly CompleteCompleteA1A2A3A4popoiopopopoiopo|I| = 1|I| = 1woTable 6: Properties algorithms sound, weakly completecomplete. po stands partial order; io standsinterval order; wo stands weak order; |I| = 1unique important attribute. indicates condition(s)A3 sound remains open problem.242fiRepresenting Reasoning Qualitative Preferences5. Complexitysection, study complexity dominance testing (evaluating , see Section 3.3) well complexity algorithms computing non-dominated setfeasible compositions (see Section 4). express worst case time complexitydominance testing terms size user specified intra-attribute, relative importancepreference relations attribute domains (see Table 7).Relation / SetSymbolCardinalityRemarksAttributesDomain AttributesIntra-attribute preferencesIntra-attribute preferencesRelative ImportanceRelative ImportanceImportant AttributesRepositoryFeasible CompositionsDominance RelationXDiRCnwintkintwrelkrelmIrcwdomNumber attributesNumber possible valuations XiWidth partial orderSize relationWidth partial orderSize relationNumber important attributesNumber components RNumber feasible compositionsWidth dominance relationTable 7: Cardinalities sets relations5.1 Computing Maximal(Non-dominated)/Minimal Subset.Let partial order set S, width w (size maximal set elementspairwise incomparable) n = |S|. algorithm due Daskalakis et al.discussed Section 4.1 finds maximal minimal subset respect withinO(wn) pairwise comparisons. Note maximum width partial order w = n,= . Hence, worst case O(n2 ) comparisons needed.5.2 Complexity Dominance TestingComputing Worst Frontiers (i ). Let Di . Recall Definition 6 worstfrontier set respect attribute Xi (S) := {v : v S, u s.t. v u},i.e., minimal set elements respect preference relation . Usingalgorithm due Daskalakis et al. find minimal set respect partial order(see above), complexity computing (S) O(nwint ).Comparing Worst Frontiers ( ). Let A, B F (Xi ). per Definition 8, Bb B, : b. worst case, computing B would involve checkingwhether b pair a, b, would cost O(kint ). Hence, complexitycomparing worst frontiers B O(n2 kint ).Dominance Testing ( ).U VRecall Definition 11 definition dominance:Xi : U(Xi ) V(Xi )Xk , (Xk Xi Xk Xi ) U(Xk ) k V(Xk )243fiSanthanam, Basu & Honavarcomplexity dominance testing complexity finding witness attributeX U V. attribute Xi , complexity computing first clauseconjunction definition U V O(n2 kint ); computingsecond clause m(n2 kint + krel ) , O(krel ) O(n2 kint ) complexitiesevaluating left right hand sides implication (respectively)Xk X .2k2kHence, complexitydominancetestingn+m(n+k), simplyintintrelm2 (n2 kint + krel ) . use shorthand denote m2 (n2 kint + krel ).5.3 Complexity Algorithmsalgorithms computing non-dominated feasible compositions (presentedSection 4) makes use functional composition algorithm f find feasible compositions.Hence, complexity analysis algorithms needs incorporate complexityfunctional composition algorithm well.Recall Algorithms 1, 2 3 begin computing set feasible compositionssingle shot using functional composition algorithm black box, proceedfind preferred among them. Algorithm 4 instead makes use functionalcomposition algorithm produces set feasible compositions iteratively extending partial feasible compositions. Specifically, interleaves execution functionalcomposition algorithm ordering partial solutions respect preferencesnon-functional attributes.denote O(fe ) O(fg ) respectively, complexity computing setfeasible extensions partial feasible composition respect complexitycomputing set feasible compositions respect .5.4 Complexity Algorithm 1overall complexity finding set non-dominated feasible compositionsO(fg +cwdom d), O(d) complexity evaluating pair compositions.first term fg accounts Line 1 algorithm computes set feasiblecompositions, term cwdom corresponds computation (C) peralgorithm given Section 4.1.5.5 Complexity Algorithm 2complexity identifying important attributes respect (Line 1)O(mwrel krel ). important attribute Xi I, Algorithm 2 (a) invokes Algorithm 1 using derived intra-attribute preference compute (C); (b) identifiessubset (C) non-dominated respect ; (c) adds setsolutions. Hence,complexity Algorithm 2 mwrel krel + mI (fg + cwdom n2 kint )+2mI | (C)| .Since feasible compositions respect given fixed, computingfeasible compositions (during first invocation Algorithm 1 storing them), complexity Algorithm 2 reduced O(fg + mwrel krel +mI cwdom n2 kint + mI | (C)|2 d).244fiRepresenting Reasoning Qualitative Preferences5.6 Complexity Algorithm 3complexity identifying important attributes respect (Line 1)O(mwrel krel ). contrast Algorithm 2, Algorithm 3 invokes Algorithm 1 using derived intra-attribute preference compute (C) exactly one importantattributes, Xi I. Hence, complexity Algorithm 3 fg +mwrel krel +cwdom n2 kint ).5.7 Complexity Algorithm 4consider worst case wherein space partial feasible compositions exploredAlgorithm 4 tree rooted ; let b maximum branching factor (correspondingmaximum number extensions produced functional composition algorithm),h height (corresponding maximum number components used compositionsatisfies ). worst case, iteration Algorithm 4, every element L,list current partial feasible compositions, ends non-dominated set .level tree corresponds one iteration Algorithm 4, lth iterlation, worstcase b nodes L. Hence, complexity lth iterationl2l(b ) + b fe , first term corresponds computing non-dominated setamong current set partial feasible compositions, second term correspondscomputing feasible extensionspartial feasible composition. Hence, overallPhof2l + bl f ) O(b2h + bh f ).complexity Algorithm 4(beel=0conducted experiments algorithms using simulated problem instancesstudy algorithms perform practice, describe next.6. Experiments, Results & Analysisdescribe design results experiments aimed comparing algorithms described Section 4 respect following attributes.a) Quality solutions produced algorithms. measure qualitysolutions produced algorithms follows. First, amongpreferred solutions exist composition problem, measure fractionproduced algorithm. Second, among solutions producedalgorithm, measure fraction solutions preferredcomposition problem.b) Performance efficiency algorithms. performance algorithmmeasured terms response time (time taken return set solutions),efficiency measured terms number times algorithm invokesfunctional composition algorithm.6.1 Experimental Setupdescribe data structure used model search space compositionssimulation parameters used generate compositions experiments.245fiSanthanam, Basu & Honavar6.1.1 Modeling Search Space Compositions using Recursive Treesuniform recursive tree (Smythe & Mahmoud, 1995) serves good choice modelsearch space partial compositions feasible extensions. tree n verticeslabeled 1, 2, . . . n recursive tree node labeled 1 distinguished root,k : 2 k n, labels nodes unique path root nodelabeled k form increasing sequence. uniform recursive tree n nodes (denotedU RT ree(n)) one chosen equal probability space trees.simple growth rule used generate uniform random recursive tree nnodes, given tree n 1 nodes: Given U RT ree(n 1), choose uniformly randomnode U RT ree(n 1), add node labeled n randomly chosen nodeparent obtain U RT ree(n). properties class uniform random recursive treeswell studied literature random data structures (see Smythe & Mahmoud, 1995,survey).rationale behind choosing uniform recursive tree data structure modelsearch space problem growth rule generates recursive tree similarintuition process searching feasible composition. Recall searchspace partial compositions generated recursive application functionalcomposition algorithm f . nodes recursive tree correspond componentsrepository composition problem. tree built starting root nodesearch feasible compositions correspondingly begins . recursive treegrown attaching new nodes existing nodes correspondsextending feasible partial compositions adding (composing) new componentsexisting feasible partial compositions. Finally, leaves recursive tree depthroot correspond (possibly feasible) composition componentsrepository composition problem.show precise correspondence recursive tree data structuresearch space partial compositions.node tree corresponds composition.root node corresponds empty composition ,node level 1 corresponds composition component Wrepository, i.e., W = W, W R,node level corresponds composition component W repository composition associated parent node,leaf node called feasible node composition associated nodesatisfies .purpose experimentally evaluating algorithms finding preferred compositions compare them, generate random recursive trees varyingnumber nodes (or |R|, number components repository). generatedrandom recursive tree, certain fraction (f eas) leaves picked uniformly randomlylabeled feasible compositions. node generated labeled246fiRepresenting Reasoning Qualitative Preferencesrandom recursive tree, valuation attributes X = {Xi } (corresponding partialcomposition represents) randomly generated based respective domains ({Di })12 .6.1.2 User Preferencesgenerate user preferences generating random partial/total ordersrandom interval/total order varying number attributes = |X | domainsize attributes n = |Di |.summary simulation parameters given Table 8.ParameterMeaningRangef easFraction leaves search tree feasible compositionsDomain size preference attributesNumber preference attributesNumber components repository (nodessearch tree)Overhead (in milliseconds) per invocationstep-by-step functional composition algorithm fIntra-attribute preference values XiRelative importance preference X{0.25, 0.5, 0.75, 1.0}|Di ||X ||R|f delay{2, 4, 6, 8, 10}{2, 4, 6, . . . 20}{10, 20, . . . 200}{1, 10, 100, 1000}{po, to}{io, to}Table 8: Simulation parameters ranges6.1.3 Implementation AlgorithmsComputing Dominanceorder check one valuation dominates another respect user preferences{i } , iterate attributes X check exists witnessdominance hold (see Definition 11).Computing preferred solutionsimplemented algorithms A1, A2, A3 A4 Java. Preliminary experiments A2showed algorithm scale large problem instances. particular,number attributes large dominance testing computationally intensive, A2timed due computation non-dominated set multiple timesimportant attributes. Hence proceed run experiments samplesA2. However, able run experiments algorithm A3 arbitrarily picksone important attributes finds preferred solutions respectintra-attribute preferences attribute.algorithms A1 A3 first compute solutions using functional compositionalgorithm (simulated f ), whereas A4, interleave calls f choosing preferred12. Note setup described here, valuations attributes generated randomly node.real applications, valuations nodes may depend valuations parents.247fiSanthanam, Basu & Honavarcompositions (partial solutions) step. step, A4 chooses subsetfeasible extensions current compositions exploration. Table 9 gives briefdescription implemented algorithms.Alg.Name AlgorithmRemarksA1ComposeAndF ilterA2W eaklyCompleteComposeA3AttW eaklyCompleteComposeA4InterleaveComposeFirst identifies functionally feasible compositions; finds non-dominatedset feasible compositions respectFirst identifies functionally feasible compositions; finds non-dominatedset feasible compositions respectimportant attributes{Xi }First identifies functionally feasible compositions; picks arbitrary important attribute Xi finds nondominated set feasible compositionsrespectIdentifies non-dominated set feasible extensions respectstep; recursively identifies feasible extensions non-dominatedfeasible extensions feasible compositionsTable 9: Implemented AlgorithmsTable 10 shows attributes recorded executionalgorithms A1, A3 A4 composition problem.6.2 Resultscompare algorithms A1, A3, A4 respect to:1. Quality solutions produced algorithms, terms SP/P F SP/S2. Performance efficiency terms running time number calls functional composition algorithm f6.2.1 Quality Solutionscompare quality solutions produced algorithms terms followingmeasures.248fiRepresenting Reasoning Qualitative PreferencesAttributeMeaningRemarksFSet solutions (feasible compositions) sampleproblem instanceSet preferred solutions sample probleminstance respect user preferencesdominance relationSet solutions produced composition algorithmSet solutions produced composition algorithm also preferred solutionsrespect user preferences dominancerelationRunning time composition algorithm (ms)Number times algorithm invokes stepby-step functional composition algorithm fF = CPFSPf countP F = (C ) FSP = P FTable 10: Attributes observed execution algorithmSP/P F 13 : Proportion preferred solutions produced algorithm (fractionoptimal solutions produced algorithm). algorithm complete,SP/P F = 1.SP/S: Proportion solutions produced algorithm preferred(fraction solutions produced algorithm, optimal). algorithmsound, SP/S = 1.algorithm A1 exhaustively searches entire space compositions identifyfeasible compositions F , finds preferred among respectuser preferences {i }. computes set (F ), observedA1, SP = P F = S, i.e., sound (finds preferred solutions)complete (finds preferred solutions).next compare algorithms A3 A4 respect SP/P F SP/Svarious types ordering restrictions user preferences {i } . Table 11 reportsresults following combinations: (i) interval order, {i } partial orders;(ii) interval order, {i } total orders; (iii) total order, {i } partialorders; (iv) total order, {i } total orders.Comparison SP/P Fgeneral, preferred solutions found algorithms(see Table 11).13. sake readability, use notation used denote set denote cardinality well,e.g., SP used denote set cardinality (|SP |).249fiSanthanam, Basu & HonavarA3A4ioiopopo77.5071.00100.00100.0083.95100.0085.88100.00Table 11: Comparison SP/P F algorithms A3 A4 respect various orderingrestrictions {i }, . percent problem instances SP/P F = 1shown row respect corresponding ordering restrictionspreference relations {i }. parameters used simulatingproblem instances ranges given Table 8.observe relative importance () total order {i } arbitrarypartial orders, 100% preferred solutions produced A3. Propositions 13 14 (see Section 3.6) obtained based insight.A3A4ioiopopo41.7830.7833.9027.3098.45100.0096.98100.00Table 12: Comparison SP/S algorithms A3 A4 respect various orderingrestrictions {i }, . percent problem instances SP/S = 1shown row respect corresponding ordering restrictionspreference relations {i }. parameters used simulatingproblem instances ranges given Table 8.Comparison SP/Sgeneral, solutions found interleaved algorithm A4preferred solutions (see Table 12). hand, algorithm A3produced many solutions preferred.second (and fourth) row(s) Tables 12 11 suggests intra-attributepreferences ({i }) total orders arbitrary interval order, interleavedalgorithm A4 sound complete, i.e., produces exactly non-dominated setsolutions respect . Conjecture 1 Theorem 3 Section 3.6obtained based insight.250fiRepresenting Reasoning Qualitative Preferences6.2.2 Performance Efficiencycompare performance efficiency A3, A4 terms number timesfunctional composition algorithm f invoked, running time (in milliseconds)algorithms compute solutions.Number calls functional composition fplots Figures 9 10 show results experiments performed probleminstances relative importance preferences interval/total orders intra-attributepreferences partial/total orders, yield following observations.general, experiments show interleaved algorithm A4 makes fewer callsf compared A3. seen Figures 9 10, data pointscorresponding number calls f made A4 (colored red) liecorrespond A3 (colored green) plots (a) (b). A4 explorespreferred subset available feasible extensions stepsearch. hand, A3 exhaustively explores feasible extensionsstep.intra-attribute preferences {i } total orders, difference number calls f made A3 A4 pronounced. observedFigures 9 10, data points corresponding number calls fmade A4 (colored red) lie much closer axis corresponding numberfeasible compositions, comparison A3 (colored green). explainedfact case dominance relation larger, due numberincomparable pairs compositions smaller. Therefore, interleaving stepnon-dominated set computed extension smaller.A3 A4, number calls f decreases fraction feasiblecompositions (f eas) increases. Figures 9 10 show number feasiblecompositions increases, data points corresponding number calls f(for algorithms) gets closer axis corresponding number feasiblecompositions.Running timeobserved running times algorithms A3, A4 depend two key factors:f delay, time taken per execution functional composition stepComplexity dominance testing turn function |Di |, |X |properties {i } . particular, complexity dominance testing dependssize preference relations {i } (see Section 5.2).order understand effect f delay running times algorithms,ran experiments f delay = 10ms f delay = 1000ms problem instancesrelative importance preferences interval/total orders intra-attribute preferencespartial/total orders (see Table 8 parameters used ranges).respective results shown Figures 11 14. results yield following observations.251fiSanthanam, Basu & Honavar!"#$ %&'()"!*+ 3 %*")$! .)/)0 %*" )!,!"" )#12" 3 4!)"#! .)/)fffi!"#$ %&'()"!*+,, - ("! .)/)0 %*" )!,!"" )#12" 3 4!)"#! .)/)fffiFigure 9: comparison algorithms A1, A3 A4 respect numbertimes invoke step-by-step functional composition algorithmexecution. plots (a) (b) correspond results running algorithmssimulated problem instances, intra-attribute preference (i )partial order, relative importance preference () interval totalorder. four distinct bands seen plots correspond various fractionsleaves search tree problem instance feasible compositions:f eas = 0.25, 0.5, 0.75, 1.0.252fiRepresenting Reasoning Qualitative PreferencesEFGHIJKF LMNOPI H]^F _ L] IFPKHG `PaFPb L] PHcHII PJdeIF _ fOI HG `PaFPP655:95:85:75@??>=<;:65g::55gh95g7857565556575ABC8595:55:65Q RSBTUDVS WX ZXTU[UX \TEFGHIJKF LMNOPI H]^F _ fOIHG `PaFPb L] PHcHII PJdeIF _ fOI HG `PaFP655:95:85:75@??>=<;:65g::55gh95g785756555ADC65758595:55:65Q RSBTUDVS WX ZXTU[UX \TFigure 10: comparison algorithms A1, A3 A4 respect numbertimes invoke step-by-step functional composition algorithmexecution. plots (a) (b) correspond results runningalgorithms simulated problem instances, intra-attribute preference(i ) total order, relative importance preference () intervaltotal order. four distinct bands seen plots correspond variousfractions leaves search tree problem instance feasiblecompositions: f eas = 0.25, 0.5, 0.75, 1.0.253fiSanthanam, Basu & Honavargeneral, comparison running time algorithm A4 intraattribute preferences (i ) partial orders, A4 faster total orders.trend observed plots (a) (b) Figure 12 (where intra-attribute preferencestotal orders), data points corresponding running time A4 (coloredred) much closer axis corresponding number feasible compositions,comparison plots (a) (b). similar trend also observed Figures 1314.algorithm A3 almost always outperforms blind search algorithm A1 termsrunning time. A3 computes non-dominated set last steprespect intra-attribute preference valuations one attribute(in place dominance relation used A1).interleaved algorithm A4 sensitive complexity dominanceA1 A3, step A4 computes non-dominated subset extensionsexplore. hand, A1 A3 involve computation dominancelast step. A3 faster A1, A4, computes nondominated set respect intra-attribute preference valuations oneattribute (in place dominance relation used A1 A4).Algorithms A1 A3 sensitive f delay interleaved algorithmA4. step A1 A3 explore feasible extensions, A4explores preferred subset feasible extensions step.overall running times A1, A3 A4 depend relative trade-offs among|Di |, |X |, properties {i }, (those influence complexity dominancetesting) one hand f delay other.7. Summary Discussionsummarize contributions paper.7.1 SummaryMany applications, e.g., planning, Web service composition, embedded system design, etc.,rely methods identifying collections (compositions) objects (components) satisfying functional specification. Among compositions satisfy functionalspecification (feasible compositions), often necessary identify one compositions preferred respect user preferences non-functional attributes.particular interest settings user preferences attributes expressedqualitative rather quantitative terms (Doyle & Thomason, 1999).paper, proposed framework representing reasoning qualitative preferences compositions terms qualitative preferences attributescomponents; developed suite algorithms compute preferred feasible compositions, given algorithm computes functionally feasible compositions.Specifically,254fiRepresenting Reasoning Qualitative Preferencesoiiiiniiii{zwxwtvutsqrmiiiijliiiilkiiiijiiiikioimi|}~pijiijki}mniiimiiiilniii{zwxwtvutsqrliiiijkniiikiiiiljniiijiiiiniii|~kioimipijiijki}Figure 11: comparison algorithms A1, A3 A4 respect runningtimes function number feasible compositions, invocationstep step-by-step functional composition algorithm overhead10 milliseconds. plots (a) (b) correspond results runningalgorithms simulated problem instances, intra-attribute preference(i ) partial order, relative importance preference () intervaltotal order. four distinct bands seen plots correspond variousfractions leaves search tree problem instance feasiblecompositions: f eas = 0.25, 0.5, 0.75, 1.0.255fiSanthanam, Basu & HonavarFigure 12: comparison algorithms A1, A3 A4 respect runningtimes function number feasible compositions, invocationstep step-by-step functional composition algorithm overhead10 milliseconds. plots (a) (b) correspond results runningalgorithms simulated problem instances, intra-attribute preference(i ) total order, relative importance preference () intervaltotal order. four distinct bands seen plots correspond variousfractions leaves search tree problem instance feasiblecompositions: f eas = 0.25, 0.5, 0.75, 1.0.256fiRepresenting Reasoning Qualitative Preferencesfffi fi fifi fi fi fi fififffi ff fifi fi fi fi fifiFigure 13: comparison algorithms A1, A3 A4 respect runningtimes function number feasible compositions, invocationstep step-by-step functional composition algorithm overhead1000 milliseconds. plots (a) (b) correspond results runningalgorithms simulated problem instances, intra-attribute preference(i ) partial order, relative importance preference () intervaltotal order. four distinct bands seen plots correspond variousfractions leaves search tree problem instance feasiblecompositions: f eas = 0.25, 0.5, 0.75, 1.0.257fiSanthanam, Basu & Honavar;<=>?@A< BCDEF?>GH< BG?<FA>= JFK<FL BG? F>M>?? F@NO?< PE?>= JFK<F('$&%$!#"!99:9)*+, -.*/012. 34564/07 048/;<=>?@A< BCDEF?>GH< PE?>= JFK<FL BG? F>M>?? F@NO?< PE?>= JFK<F('$&%$!#"!99:9)1+, -.*/012. 34564/07 048/Figure 14: comparison algorithms A1, A3 A4 respect runningtimes function number feasible compositions, invocationstep step-by-step functional composition algorithm overhead1000 milliseconds. plots (a) (b) correspond results runningalgorithms simulated problem instances, intra-attribute preference(i ) total order, relative importance preference () intervaltotal order. four distinct bands seen plots correspond variousfractions leaves search tree problem instance feasiblecompositions: f eas = 0.25, 0.5, 0.75, 1.0.258fiRepresenting Reasoning Qualitative Preferencesa) defined generic aggregation function compute valuation composition function valuations components. also presentedstrict partial order preference relation comparing two compositions respectaggregated valuations attribute;b) introduced dominance relation comparing compositions based userspecified preferences established key properties. particular,shown dominance relation strict partial order intra-attributepreferences strict partial orders relative importance preferences intervalorders.c) developed four algorithms identifying preferred composition(s)respect user preferences. first three algorithms first computeset feasible compositions (solutions) using functional composition algorithmblack box, proceed find preferred among (1) baseddominance relation (ComposeAndFilter ); (2) based preferred valuations respect important attribute(s) (WeaklyCompleteComposeAttWeaklyCompleteCompose). fourth algorithm interleaves executionfunctional composition algorithm produces set solutions iterativelyextending partial solutions ordering partial solutions respect userpreferences (InterleaveCompose).d) established key properties algorithms. ComposeAndFilterguaranteed return set non-dominated solutions; WeaklyCompleteCompose guaranteed return non-empty subset non-dominated solutions; AttWeaklyCompleteCompose guaranteed return least one non-dominatedsolutions; InterleaveCompose guaranteed return (i) non-empty subsetnon-dominated solutions dominance relation interval order; (ii)entire set non-dominated solutions dominance relation weak order.e) performed simulation experiments compare algorithms respect(i) ratio preferred solutions produced actual set preferredsolutions, ratio preferred solutions produced entire setsolutions produced algorithm; (ii) running times functionsearch space overhead call functional composition algorithm;(iii) number calls algorithm makes functional compositionalgorithm course execution. results showed feasibilityalgorithms composition problems involve 200 components.f) analyzed results experiments obtain additional theoretical properties dominance relation function properties underlyingintra-attribute preference relations relative importance preference relation.particular, obtained non-trivial results consequence analysis experimental results, known apriori, including conditionsdominance relation weak order. conjectures/results significantgive properties dominance relation directly function input259fiSanthanam, Basu & Honavaruser preferences. turn, also throw light soundness, weak-completenessand/or completeness properties algorithms.proposed techniques reasoning preferences non-functional attributesindependent language used express desired functionality composition, method used check whether composition C satisfies desired functionality, i.e., C |= . formalism algorithms may applicable broad rangedomains including Web service composition (see Dustdar & Schreiner, 2005; Pathak, Basu,& Honavar, 2008, surveys), planning (see Hendler, Tate, & Drummond, 1990; Baier &McIlraith, 2008a), team formation (see Lappas, Liu, & Terzi, 2009; Donsbach, Tannenbaum,Alliger, Mathieu, Salas, Goodwin, & Metcalf, 2009) indeed setting callschoosing preferred solutions set candidate solutions, solutionmade multiple components.7.2 Discussionfollowing, discuss alternate choices one could make applyingformalism specific applications.Aggregation Functions. previous work (Santhanam, Basu, & Honavar, 2008),proposed use TCP-net representation ceteris paribus semantics (Brafmanet al., 2006) reasoning preferences addressing problem Web service composition. assumed intra-attribute preferences total orders; however,assumption hold many practical settings involving qualitative preferencesnon-functional attributes. paper, relaxed requirement, allowingintra-attribute preferences strict partial orders.paper demonstrated use summation (e.g., number creditsPOS) worst frontier (e.g., areas study instructors) aggregation functions.scenarios, might necessary consider ways aggregating valuationscomponents, example, using best frontier denoting best possible valuationscomponents (i.e., maximal valuations attribute Xi respect ).aggregation function used formalism, provided preference relationaggregated valuations strict partial order. Otherwise, choice aggregationfunction preference relation compare aggregated valuations may impactproperties resulting dominance relation, result, may also affect soundnesscompleteness properties proposed algorithms.aggregation functions demonstrated paper independentcomponents interact assembled, i.e., structure composition. However,general, may necessary aggregation function take account structure and/or interactions valuations components composition.example, evaluating reliability composition, one needs consider precisestructure composition. reliability composition Ci product relinabilities components ( VWi (Reliability)) components arrangedi=1series configuration (Rausand & Hyland, 2003). hand, setcomponents {Wi } arranged parallel configuration, reliability Ci computed260fiRepresenting Reasoning Qualitative Preferencesn(1 VWi (Reliability))). general, might necessary introduce aggregaas (1i=1tion functions take consideration variety factors including structure,function, well non-functional attributes composition.Comparing Sets Aggregated Valuations. paper, presented preference relation( ) compare sets valuations computed using worst frontier aggregation function(Definition 8). preference relation requires given two sets valuations, everyelement dominated set preferred least one elements dominatingset valuations. choices used well, care takenproperties chosen preference relation may affect properties dominance( ) relation properties algorithms. However, long strict partialorder (irreflexive transitive), dominance relation continues remain strict partialorder (subject interval order), hence properties algorithmshold. provides user wide range preference relations comparing setsvaluations choose (see Barbera et al., 2004, survey preferences sets).Note Definition 8 ignore common elements comparing two setselements. However, settings may require preference relation compareselements two sets common. settings, suitable irreflexivetransitive preference relation used, asymmetric part preferencerelations developed Brewka et al. (2010) Bouveret et al. (2009). absencetransitivity, transitive closure relation may used compare sets elements,done Brewka et al.Dominance Properties. dominance relation ( ) adopted paperstrict partial order intra-attribute preferences arbitrary strict partial ordersrelative importance interval order. would interesting explore alternative notions dominance preserve rationality choice, requiring different setproperties (e.g., satisfy negative-transitivity instead transitivity). wouldalso interest examine relationships alternative dominance relations. results comparing dominance relations proposed authors(Brafman et al., 2006; Wilson, 2004b, 2004a) presented elsewhere (Santhanam,Basu, & Honavar, 2010b, 2009).Implementation. current implementation dominance testing respectbased iteratively searching attributes find witness. would interestingcompare methods dominance testing one proposed oneearlier works (Santhanam, Basu, & Honavar, 2010a) uses efficient model checkingtechniques. would also like use multi-attribute preference formalismsinclude conditional preferences framework compositional systems compareperformance resulting implementation current implementation.7.3 Related WorkTechniques representing reasoning user preferences set alternativesstudied extensively areas decision theory, microeconomics, psychol261fiSanthanam, Basu & Honavarogy, operations research, etc. seminal work von Neumann Morgenstern (1944)models user preferences using utility functions map set possible alternativesnumeric values. recently, models representing reasoning quantitative preferences multiple attributes developed (Fishburn, 1970a; Keeney& Raiffa, 1993; Bacchus & Grove, 1995; Boutilier, Bacchus, & Brafman, 2001).models used address problems identifying preferred tuplesresulting database queries (Agrawal & Wimmers, 2000; Hristidis & Papakonstantinou, 2004; Borzsonyi, Kossmann, & Stocker, 2001), assembling preferred composite Webservices (Zeng, Benatallah, Dumas, Kalagnanam, & Sheng, 2003; Zeng, Benatallah, Ngu,Dumas, Kalagnanam, & Chang, 2004; Yu & Lin, 2005; Berbner, Spahn, Repp, Heckmann,& Steinmetz, 2006), composition problems.However, many applications natural users express preferencesqualitative terms (Doyle & McGeachie, 2003; Doyle & Thomason, 1999; Dubois, Fargier,Prade, & Perny, 2002) hence, growing interest AI formalismsrepresenting reasoning qualitative preferences (Brafman & Domshlak, 2009).proceed place work context recent work representingreasoning qualitative preferences.7.3.1 TCP-netsNotable among qualitative frameworks preferences preference networks (Boutilieret al., 2004; Brafman et al., 2006) deal qualitative conditional preferences.class preference networks, namely Tradeoff-enhanced Conditional Preference networks(TCP-nets) (Brafman et al., 2006) closely related work, proceeddiscuss framework departs adds existing TCP-net framework.TCP-nets provide elegant compact graphical model represent qualitativeintra-attribute relative importance preferences set attributes. addition,TCP-nets also model conditional preferences using dependencies among attributes.TCP-nets allow us represent reason preferences general simpleobjects (each described set attributes), focus work reasonpreferences compositions simple objects (i.e., collection objectssatisfying certain functional properties). example, domain Web services,problem identifying preferred Web services repository available onesbased non-functional attributes, namely Web service selection solved usingTCP-net formalism. hand, addition Web service selection,formalism also address complicated problem identifying preferredcomposite Web services collectively satisfy certain functional requirement, namelyWeb service composition.formalism based intra-attribute relative importance preferencesset attributes describing objects. result, graphical representation schemeTCP-nets still used compactly encode intra-attribute relative importancepreferences users within formalism 14 .14. setting, consider conditional preferences correspond edges denoting conditionaldependencies TCP-nets.262fiRepresenting Reasoning Qualitative Preferencesextended reasoning preferences single objects enable reasoningpreferences collections objects. have: (a) provided aggregation function computing valuation composition function valuationscomponents; (b) defined dominance relation comparing valuations compositionsestablished properties; (c) developed algorithms identifying subsetset preferred composition(s) respect dominance relation.formalism departs TCP-nets interpretation intra-attributerelative importance preferences objects: dominance relation TCP-net definedpartial order relation consistent given preferences attributesobjects, based ceteris-paribus semantics. introduce dominance relation(see Definition 11) allows us reason preferences collections objectsterms sets valuations attributes objects make collection.instance, worst frontier aggregation function returns set worst possible attributevaluations among components.dominance relation applied simpler setting collectionconsists single object, aggregation function attribute reduces identity function, preference relation sets valuations attribute Xireduces intra-attribute preference . recently shown earlier works(Santhanam et al., 2010b, 2009) general, TCP-nets restricted unconditional preferences, dominance relation (when collection consists single object)dominance relation used TCP-nets incomparable; relative importancerestricted interval order, dominance relation general dominance relation used TCP-nets unconditional preferences. latter case,dominance relation computable polynomial time, whereas knownpolynomial time algorithms computing TCP-net dominance (Santhanam et al., 2010b,2009).7.3.2 Preferences Collections ObjectsSeveral authors considered ways extend user preferences obtain rankingcollections objects (see Barbera et al., 2004, survey). works, preferencesspecified individual objects set opposed preferences valuationsattributes objects. preferences objects turn used reasonpreferences collections objects. scenario simulatedframework, introducing single attribute whose valuations correspond objectsdomain.DesJardins et al. (2005) considered problem finding subsets optimalrespect user specified quantitative preferences set attributes termsdesired depth, feature weight diversity attribute. contrast, frameworkfocuses qualitative preferences. setting, depth preferences map attributevaluations relative desirability mapped qualitative intra-attribute preferences feature weights mapped relative importance. Diversity preferencesattributes refer spread (e.g., variance, range, etc.) component valuations respect corresponding attributes. would interesting explore whether suitable263fiSanthanam, Basu & HonavarPropertyDenotedNew AttributeAttribute DomainParty AffiliationViewsExperiencePVEXPXVXE{Re, De}{Li, Co, U l}{Ex, In}Table 13: Properties/Attributes describing senatorsdominance relation defined simultaneously capture frameworkuser preferences respect depth, diversity feature weights.recently, Binshtok et al. (2009) presented language specificationpreferences sets objects. framework, addition intra-attribute relativeimportance preferences attributes, allows users express preferences number(||) elements set satisfy desired property . preference languagecase allows statements Si : || REL n (number elements preferred setproperty REL n), Sj : || REL || (number elements preferredset property REL number elements preferred set property), etc., REL one arithmetic operators >, <, =, , n integer.addition, relative importance various preference statementsSi important Sj well external cardinality constraintsbound number elements preferred set.formalism accommodate preference statements, representing preference statement Si new binary valued attribute compositional system.example, preference statements Si : || n Sj : || || representedformalism creating new binary attributes Xi Xj intra-attribute preferences1 0 1 j 0 respectively. relative importance statements Siimportant Sj directly mapped Xi Xj . external cardinalityconstraints size preferred set encoded setting functional requirements, restrict feasible solutions satisfy cardinalityconstraints.Consider example discussed Binshtok et al. (2009), preferences senatemembers described attributes: Party affiliation (Republican, Democrat ), Views (liberal, conservative, ultra conservative), Experience (experienced, inexperienced).attributes domains listed Table 13. set preferences given by:S1 : h|P = V = Co| 2iS2 : h|E = Ex| 2iS3 : h|V = Li| 1iNote senate members (i.e., individual objects) described three attributes XP , XV , XE representing party affiliation, views experience respectively.valuation function attributes defined obvious manner, e.g., senatorWj republican, VWj (XP ) = Re. introduce three additional boolean attributes264fiRepresenting Reasoning Qualitative PreferencesX1 , X2 , X3 corresponding preference statements S1 , S2 , S3 respectively. valuationfunction new attribute senator Wi defined follows.(1 , Wi |= S1 i.e., VWi (XP ) = VWi (XV ) = CoVWi (X1 ) =0 , otherwise(1 , Wi |= S2 i.e., VWi (XE ) = ExVWi (X2 ) =0 , otherwise(1 , Wi |= S3 i.e., VWi (XV ) = LiVWi (X3 ) =0 , otherwisevaluation collection senators W1 W2 . . . Wn {1, 2, 3} is:VW1 W2 ...Wn (Xi ) = (VW1 , VW2 , . . . VWn ) = VW1 (Xi ) + VW2 (Xi ) + + VWn (Xi )Note aggregation function defined differs worst-frontierbased aggregation function adopted Definition 6. preference relation comparinggroups senators respect new attribute Xi defined basedpreference statement Si . example, case X1 define 1value 2 preferred value < 2, etc. defined aggregation functioncomparison relation new attribute, dominance relation adoptedcompare compositions (arbitrary subsets) respect attributes includingdominance relation used Binshtok et al. (2009).contrast framework Binshtok et al., (2009) formalism focuses collections objects satisfy desired criteria, rather arbitrary subsets. providealgorithms finding preferred compositions satisfy desired criteria.7.3.3 Database Preference QueriesSeveral authors (Borzsonyi et al., 2001; Chomicki, 2003; Kiessling & Kostler, 2002; Kiessling,2002) explored techniques incorporating user specified preferences resultsets relational database queries. instance, Chomickis framework (2003) allows userpreferences attributes relation expressed first order logic formulas. Suppose Sq set tuples match query q. attribute Xi , Sq ,subset Sqi tuples preferred value(s) Xi identified. resultset query q given Sqi . similar framework expressing combining user preferences presented Kiessling (2002) Kiessling Kostler (2002).Brafman Domshlak (2004) pointed semantic difficulties associatedapproaches, considered alternative approach identifying preferredresult set based CP-net (Boutilier et al., 2004) dominance relation.high computational complexity dominance testing CP-nets, Boutilier et al. proposedefficient alternative based ordering operator orders tuples resultset way consistent user preferences. formalism useddatabase setting, similar spirit Brafman Domshlak, considering265fiSanthanam, Basu & Honavartuple Sq collection single object. differences semanticsCP-net dominance dominance relation discussed Section 7.3.1.host algorithms also proposed computing non-dominated resultset response preference queries, especially efficient evaluation skyline queries(Borzsonyi et al., 2001; Chomicki, 2003). skyline query yields non-dominated resultset database, dominance evaluated based notion pareto dominanceconsiders attributes equally important. proposed algorithmscomputing skylines (see Jain, 2009, survey) applicable intraattribute preferences totally weakly ordered. algorithms handlepartially ordered attribute domains (Chan, Eng, & Tan, 2005; Sacharidis, Papadopoulos, &Papadias, 2009; Jung, Han, Yeom, & Kang, 2010) rely creating maintaining indexesattributes database, data structures specifically designed identifyskyline respect pareto dominance. algorithms may consideredparticular problem instance involves large set components already storeddatabase indexed. However, obvious generalize arbitrarynotion dominance one presented here. hand, algorithmsfinding non-dominated set applicable notion dominance, provideduser preferences dominance relation partial order.7.3.4 Planning Preferencesclassical planning problem consists finding sequence actions take systeminitial state one states satisfies user specified goal. Preferencebased planning refers problem finding plans preferred respectset user preferences plans. preferences usually compactly expressedterms preferences properties satisfied plans goal intermediatestates, actions, action sequences (i.e., temporal properties plans).refer interested reader surveys Baier et al. (2008b) Bienvenu et al. (2011)overview qualitative quantitative preference languages used preference basedAI planning, different algorithms computing preferred plans.Preference based planning viewed problem finding preferredcomposition compositional system, components correspond actions,feasible compositions correspond states plans satisfy goalplanning problem. allowed set actions performed givenstate planning problem encoded compositional system termsset functional requirements (or constraints functionality). preferencesvarious actions taken given state plan capturedpreferences components composition extended termsproperties attribute valuations. properties satisfied state planplanning problem captured valuations attributes correspondingcomposition compositional system. Based mapping actions performedgiven state properties resulting state planning problem, aggregationfunctions suitably defined compositional system. addition actionpartial plan planning problem represented compositional systemextension partial composition new component, properties satisfied266fiRepresenting Reasoning Qualitative Preferencesresulting state planning problem correspond valuations attributesextended composition determined aggregation functions. Findingpreferred plans involves finding preferred feasible compositions.algorithms presented paper used find preferred plansrespect user specified preferences actions terms properties satisfiedresulting states, properties satisfied plans goal state. However,planning problems involve preferences orderings states actions plan,e.g., preferences properties hold entire sequence states plan(Baier, Bacchus, & McIlraith, 2009; Bienvenu et al., 2011) cannot handled withinframework.8. AcknowledgmentsAspects work supported part NSF grants CNS0709217, CCF0702758,IIS0711356 CCF1143734. work Vasant Honavar supported NationalScience Foundation, working Foundation. opinion, finding, conclusionscontained article authors necessarily reflect viewsNational Science Foundation.grateful anonymous reviewers thorough review Dr. Ronen Brafmanmany useful suggestions helped improve manuscript.Appendix A. Proofs Propositions Theorems Section 4Proposition 15 Xi : (C) 6= (C) (C) 6= .Proof. Let Xi U (C). two possibilities: U (C) U/(C). U (C), nothing left prove.Suppose U/ (C). show V =6 U V (C) (C)./ (C) V (C) : V U.U (C) UDefinitions 11 16, follows V (C) : V(Xi ) U(Xi ). Hence, Xicannot witness V U. two cases consider.Case 1: U(Xi ) V(Xi ).Let attribute Xj 6= Xi witness V U. Since Xi I, (Xi Xj ) (XiXj ). therefore follows V(Xi ) U(Xi ), contradicts assumptionU(Xi ) V(Xi ). Hence, U(Xi ) 6 V(Xi ).Case 2: U(Xi ) V(Xi ).Let attribute Xj 6= Xi witness V U. Since Xi I, (Xi Xj ) (XiXj ). Definition 11, V U V(Xi ) U(Xi ). assumptionU(Xi ) V(Xi ), must case V(Xi ) = U(Xi ), i.e., V (C). Thus, have:U (C) \ (C) V (C) (C) : V Ucompletes proof.267(5)fiSanthanam, Basu & HonavarTheorem 4 [Soundness Weak Completeness Algorithm 2] Given set attributesX , preference relations , Algorithm 2 generates set feasible compositions(C) (C) 6= 6= .Proof.Soundness: proof proceeds contradiction. Suppose algorithm returnssolution U U/ (C). U , necessary (by Line 5)Xi : U (C) \ (C). Then, Equation (5) proof Proposition 15,V (C) (C) : V U, means U/ ( (C)). However,contradicts Line 5 algorithm. Hence, (C), i.e., Algorithm 2 sound.Weak Completeness: 6= , Line 5 executed algorithm leastXi I. Definition 13, C 6= (C) 6= ( (C)) 6= 6=. Hence, Algorithm 2 weakly complete Definition 15.Proposition 16 = {Xt }Xk 6= Xt X : Xt Xk , (C) , i.e., Algorithm 2complete.Proof. proof proceeds contradiction. Let = {Xt } Xk 6= Xt X : Xt Xk ,suppose V (C) \ (C). Since V/ (C), Definition 13 mustcase U (C) : U(Xt ) V(Xt ). However, U V Definition 11 thuscontradicting assumption V (C).Proposition 17 |I| = 1, i.e., unique important attribute respect, Algorithm 3 complete.Proof. Let = {Xi }. know Proposition 14 . follows(S) (S) set S. Hence, (C) (C) = , i.e., Algorithm 3complete.Proposition 18 [Termination Algorithm 4] Given finite repository components,Algorithm 4 terminates finite number steps.Proof. Given finite repository R components, algorithm f computes feasibleextensions partial feasible compositions15 , due fact Algorithm 4re-visit partial feasible composition, number recursive calls finite.Proposition 19 [Unsoundness Algorithm 4] Given functional composition algorithmf user preferences set attributes X , Algorithm 4 guaranteedgenerate set feasible compositions (C).Proof. provide example wherein Algorithm 4 returns feasible compositiondominated feasible composition. Consider compositional systemsingle attribute X = {X1 }, domain {a1 , a2 , a3 , a4 }. Let intra-attribute preference user values partial order: a4 1 a1 a2 1 a3 (Figure 15).Let R = {W1 , W2 , W3 , W4 } repository components compositional systemVWi (X1 ) = {ai }.15. f terminates set feasible extensions guaranteed decidability .268fiRepresenting Reasoning Qualitative Preferencesa4a2a1a3Figure 15: Intra-attribute preference 1 attribute X1Suppose three feasible compositions C satisfying user specifiedfunctionality , namely C1 = W1 , C2 = W2 , C3 = W3 W4 . respective valuationsare: VC1 = h{a1 }i, VC2 = h{a2 }i VC3 = h{a3 , a4 }i. Clearly, (C) = {C2 , C3 },VC3 VC1 (due fact {a3 , a4 } 1 {a1 }).Iteration 0Iteration 1Iteration 2W1W2W3W3 W4Algorithm terminatesW1 W2 solutionsW2 dominates W3W1 incomparable W3dominates W1 !Figure 16: Execution Algorithm 4suppose exists functional composition algorithm f producesfollowing sequence partial feasible compositions (Figure 16): {}, {W1 , W2 , W3 },{W1 , W2 , W3 W4 }. According Line 13 Algorithm 4, algorithm terminate first invocation f , i.e., set {W1 , W2 , W3 } partial feasible compositionsproduced f . first iteration, = {W1 , W2 }, VW2 VW3 ,W1 W2 feasible compositions. results = {C1 , C2 } 6 (C).Theorem 5 [Soundness Algorithm 4] interval order, given functional composition algorithm f user preferences { }, set attributes X ,Algorithm 4 generates set feasible compositions (C).Proof. Suppose contradiction, F feasible composition C/VC VF . C present list L upon termination algorithm, C, algorithm terminates compositions (L)feasible. implies algorithm terminate L containing C.algorithm keeps track partial feasible compositions extendedL, without discarding termination. Therefore, existencefeasible composition C L time termination must implyexistence partial feasible composition B list (at time termination)extended produce feasible composition C, i.e., B W1 W2 . . . Wn = CB 6|= C |= .B 6|= B/ time termination, therefore E : VB .transitive (by Proposition 12), since VC 6 VB (by Proposition 6), followsVC 6 (otherwise, VC VB VC VB , contradiction). Hence, C must269fiSanthanam, Basu & Honavardominate composition E, say F time termination, i.e.,VC VF . E, F , follows VF , turn implies 6 VC .Therefore, F : VC VF , VF VC (see Figure 17).VDVFVBFigure 17: Dominance relationships violate interval order restrictionVB , VC VF , VF VC 6 VB , follows VC VB (becauseVB VC would otherwise imply VF , contradiction). Finally, must casethat: VB 6 VF , since otherwise would contradict VF ; VF 6 VB , sinceotherwise would contradict VC VB . Therefore, VB VF . Thus, possibledominance relationships among compositions B, C, E, F follows (see Figure 17):VBVC VFHowever, scenario ruled fact interval order. HenceF , C C \ : VC 6 VF , i.e., (C).Theorem 6 [Weak Completeness Algorithm 4] interval order, givenfunctional composition algorithm f user preferences { }, set attributes X ,Algorithm 4 produces set feasible compositions (C) 6= (C) 6=.Proof. Theorem 5, (C) interval order. sufficesshow (C) 6= 6= . algorithm terminates non-dominated setcompositions current list L, i.e., maximal elements L respect .set maximal elements partial order set elements L emptywhenever L empty, set elements L turn empty whenever Cempty. Therefore, (C) 6= C 6= L =6 6= required.Theorem 7 [Completeness Algorithm 4] weak order, given functional composition algorithm f user preferences { }, set attributes X ,Algorithm 4 generates set feasible compositions (C) .Proof. suffices show feasible composition C (C) \ .Suppose contradiction C (C), C/ . means Cpresent list L upon termination algorithm (because otherwise C perLines 4, 6, 13 Algorithm 4). Hence, C must feasible extension partial feasiblecomposition B present L time termination B W1 W2. . . Wk = C.Proposition 6, VC 6 VB . weak order, (a) E: VB ; (b) VC 6 VB VB VC . However, contradictsassumption C (C).270fiRepresenting Reasoning Qualitative PreferencesReferencesAgrawal, R., & Wimmers, E. L. (2000). framework expressing combining preferences. SIGMOD Rec., 29 (2), 297306.Bacchus, F., & Grove, A. J. (1995). Graphical models preference utility. Proceedings Eleventh Annual Conference Uncertainty Artificial Intelligence(UAI-1995), pp. 310.Baier, J. A., Bacchus, F., & McIlraith, S. A. (2009). heuristic search approach planningtemporally extended preferences. Artificial Intelligence, 173 (5-6), 593 618.Baier, J. A., Fritz, C., Bienvenu, M., & McIlraith, S. (2008). Beyond classical planning:Procedural control knowledge preferences state-of-the-art planners. Proceedings 23rd AAAI Conference Artificial Intelligence (AAAI), Nectar Track,pp. 15091512, Chicago, Illinois, USA.Baier, J. A., & McIlraith, S. A. (2008a). Planning preferences. AI Magazine, 29 (4),2536.Baier, J. A., & McIlraith, S. A. (2008b). Planning preferences. AI Magazine, 29 (4),2536.Barbera, S., Bossert, W., & Pattanaik, P. K. (2004). Ranking sets objects. HandbookUtility Theory. Volume II Extensions, chap. 17, pp. 893977. Kluwer AcademicPublishers.Berbner, R., Spahn, M., Repp, N., Heckmann, O., & Steinmetz, R. (2006). Heuristics qosaware web service composition. Proceedings IEEE International ConferenceWeb Services, pp. 7282.Bienvenu, M., Fritz, C., & McIlraith, S. A. (2011). Specifying computing preferredplans. Artificial Intelligence, 175 (7-8), 1308 1345.Binshtok, M., Brafman, R. I., Domshlak, C., & Shimony, S. E. (2009). Generic preferencessubsets structured objects. Journal Artificial Intelligence Research, 34,133164.Borzsonyi, S., Kossmann, D., & Stocker, K. (2001). skyline operator. Proceedings17th International Conference Data Engineering, pp. 421430, Washington,DC, USA. IEEE Computer Society.Boutilier, C., Brafman, R. I., Domshlak, C., Hoos, H. H., & Poole, D. (2004). CP-nets: toolrepresenting reasoning conditional ceteris paribus preference statements.Journal Artificial Intelligence Research, 21, 135191.Boutilier, C., Bacchus, F., & Brafman, R. I. (2001). UCP-networks: directed graphical representation conditional utilities. Proceedings 17th ConferenceUncertainty Artificial Intelligence (UAI-2001), pp. 5664.Bouveret, S., Endriss, U., & Lang, J. (2009). Conditional importance networks: graphicallanguage representing ordinal, monotonic preferences sets goods. IJCAI,pp. 6772.271fiSanthanam, Basu & HonavarBrafman, R. I., Domshlak, C., & Shimony, S. E. (2006). graphical modeling preferenceimportance. Journal Artificial Intelligence Research, 25, 389424.Brafman, R. I., & Domshlak, C. (2004). Database preference queries revisited. Tech. rep.1934, Department Computing Information Science, Cornell University.Brafman, R. I., & Domshlak, C. (2009). Preference handling - introductory tutorial. AImagazine, 30 (1).Brewka, G., Truszczynski, M., & Woltran, S. (2010). Representing preferences among sets.AAAI. AAAI Press.Chan, C.-Y., Eng, P.-K., & Tan, K.-L. (2005). Stratified computation skylinespartially-ordered domains. SIGMOD 05: Proceedings 2005 ACM SIGMODinternational conference Management data, pp. 203214, New York, NY, USA.ACM.Chomicki, J. (2003). Preference formulas relational queries. ACM Trans. Database Syst.,28 (4), 427466.Daskalakis, C., Karp, R. M., Mossel, E., Riesenfeld, S., & Verbin, E. (2009). Sortingselection posets. SODA, pp. 392401.desJardins, M., & Wagstaff, K. (2005). DD-PREF: language expressing preferencessets. AAAI, pp. 620626.Donsbach, J. S., Tannenbaum, S. I., Alliger, G. M., Mathieu, J. E., Salas, E., Goodwin,G. F., & Metcalf, K. A. (2009). Team composition optimization: team optimalprofile system (tops). Tech. rep. ARI TR 1249, U.S. Army Research InstituteBehavioral Social Sciences.Doyle, J., & McGeachie, M. (2003). Exercising qualitative control autonomous adaptivesurvivable systems. Self-Adaptive Software: Applications, chap. 8. Springer BerlinHeidelberg.Doyle, J., & Thomason, R. H. (1999). Background qualitative decision theory. AImagazine, 20, 5568.Dubois, D., Fargier, H., Prade, H., & Perny, P. (2002). Qualitative decision theory:savages axioms nonmonotonic reasoning. Journal ACM, 49 (4), 455495.Dustdar, S., & Schreiner, W. (2005). survey web services composition. InternationalJournal Web Grid Services, 1 (1), 120.Fishburn, P. (1970a). Utility Theory Decision Making. John Wiley Sons.Fishburn, P. (1970b). Utility theory inexact preferences degrees preference.Synthese, 21, 204221. 10.1007/BF00413546.Fishburn, P. (1985). Interval Orders Interval Graphs. J. Wiley, New York.French, S. (1986). Decision theory: introduction mathematics rationality..Hendler, J., Tate, A., & Drummond, M. (1990). AI planning: systems techniques. AIMag., 11 (2), 6177.Hristidis, V., & Papakonstantinou, Y. (2004). Algorithms applications answeringranked queries using ranked views. VLDB Journal, 13 (1), 4970.272fiRepresenting Reasoning Qualitative PreferencesJain, R. (2009). Handling worst case skyline. Masters thesis, York University, DepartmentComputer Science Engineering.Jung, H., Han, H., Yeom, H. Y., & Kang, S. (2010). fast progressive algorithmskyline queries totally- partially-ordered domains. Journal SystemsSoftware, 83 (3), 429 445.Keeney, R. L., & Raiffa, H. (1993). Decisions multiple objectives: Preferencesvalue trade-offs..Kiessling, W. (2002). Foundations preferences database systems. VLDB 02:Proceedings 28th international conference Large Data Bases, pp. 311322. VLDB Endowment.Kiessling, W., & Kostler, G. (2002). Preference sql: design, implementation, experiences.VLDB 02: Proceedings 28th international conference Large DataBases, pp. 9901001. VLDB Endowment.Lago, U. D., Pistore, M., & Traverso, P. (2002). Planning language extendedgoals. Eighteenth national conference Artificial intelligence, pp. 447454, MenloPark, CA, USA. American Association Artificial Intelligence.Lappas, T., Liu, K., & Terzi, E. (2009). Finding team experts social networks.Proceedings 15th ACM SIGKDD international conference Knowledgediscovery data mining (KDD), pp. 467476, New York, NY, USA. ACM.Mas-Colell, A., Whinston, M. D., & Green, J. R. (1995). Microeconomic Theory. OxfordUniversity Press.Passerone, R., de Alfaro, L., Henzinger, T. A., & Sangiovanni-Vincentelli, A. L. (2002). Convertibility verification converter synthesis: two faces coin. ICCAD02: Proceedings 2002 IEEE/ACM international conference Computer-aideddesign, pp. 132139, New York, NY, USA. ACM.Pathak, J., Basu, S., & Honavar, V. (2008). Assembling composite web services autonomous components. Emerging Artificial Intelligence Applications ComputerEngineering, Maglogiannis, I., Karpouzis, K., Soldatos, J. (ed). IOS Press.press.Rausand, M., & Hyland, A. (2003). System Reliability Theory: Models, Statistical MethodsApplications Second Edition. Wiley-Interscience.Regenwetter, M., Dana, J., & Davis-Stober, C. P. (2011). Transitivity preferences. Psychological Review, 118 (1), 42 56.Sacharidis, D., Papadopoulos, S., & Papadias, D. (2009). Topologically sorted skylinespartially ordered domains. ICDE 09: Proceedings 2009 IEEE InternationalConference Data Engineering, pp. 10721083, Washington, DC, USA. IEEE Computer Society.Santhanam, G. R., Basu, S., & Honavar, V. (2008). TCP-compose - TCP-net basedalgorithm efficient composition web services using qualitative preferences.Bouguettaya, A., Krger, I., & Margaria, T. (Eds.), Procceedings Sixth International Conference Service-Oriented Computing, Vol. 5364 Lecture NotesComputer Science, pp. 453467.273fiSanthanam, Basu & HonavarSanthanam, G. R., Basu, S., & Honavar, V. (2009). dominance relation unconditionalmulti-attribute preferences. Tech. rep. 09-24, Department Computer Science, IowaState University.Santhanam, G. R., Basu, S., & Honavar, V. (2010a). Dominance testing via model checking. Proceedings Twenty-Fourth AAAI Conference Artificial Intelligence(AAAI), pp. 357362. AAAI Press.Santhanam, G. R., Basu, S., & Honavar, V. (2010b). Efficient dominance testing unconditional preferences. Proceedings Twelfth International ConferencePrinciples Knowledge Representation Reasoning (KR), pp. 590592. AAAIPress.Smythe, R. T., & Mahmoud, H. M. (1995). survey recursive trees. Theor Prob MathStat, pp. 127.Traverso, P., & Pistore, M. (2004). Automated composition semantic web servicesexecutable processes. Proceedings ISWC 2004, pp. 380394. Springer-Verlag.Tversky, A. (1969). Intransitivity preferences. Psychological Review, 76, 3148.von Neumann, J., & Morgenstern, O. (1944). Theory Games Economic Behavior.Princeton University Press.Wilson, N. (2004a). Consistency constrained optimisation conditional preferences.ECAI, pp. 888894.Wilson, N. (2004b). Extending CP-nets stronger conditional preference statements.AAAI, pp. 735741.Yu, T., & Lin, K. J. (2005). Service selection algorithms composing complex servicesmultiple qos constraints. Service-Oriented Computing - ICSOC 2005, pp.130143. Springer Berlin / Heidelberg.Zeng, L., Benatallah, B., Dumas, M., Kalagnanam, J., & Sheng, Q. Z. (2003). Qualitydriven web services composition. Proceedings 12th International ConferenceWorld Wide Web, pp. 411421. ACM.Zeng, L., Benatallah, B., Ngu, A. H. H., Dumas, M., Kalagnanam, J., & Chang, H. (2004).Qos-aware middleware web services composition. IEEE Transactions SoftwareEngineering, 30 (5), 311327.274fiJournal Artificial Intelligence Research 42 (2011) 487-527Submitted 7/11; published 11/11Unfounded Sets Well-Founded SemanticsAnswer Set Programs AggregatesMario AlvianoFrancesco CalimeriWolfgang FaberNicola LeoneSimona Perrialviano@mat.unical.itcalimeri@mat.unical.itfaber@mat.unical.itleone@mat.unical.itperri@mat.unical.itDepartment MathematicsUniversity CalabriaI-87030 Rende (CS), ItalyAbstractLogic programs aggregates (LPA ) one major linguistic extensionsLogic Programming (LP). work, propose generalization notions unfounded set well-founded semantics programs monotone antimonotoneaggregates (LPAm,a programs). particular, present new notion unfounded setLPm,a programs, sound generalization original definition standard(aggregate-free) LP. basis, define well-founded operator LPAm,a programs,fixpoint called well-founded model (or well-founded semantics) LPAm,aprograms. important properties unfounded sets well-founded semantics standard LP retained generalization, notably existence uniquenesswell-founded model, together strong relationship answer set semantics LPAm,a programs. show one D-well-founded semantics, definedPelov, Denecker, Bruynooghe broader class aggregates using approximatingoperators, coincides well-founded model defined work LPAm,a programs. also discuss complexity issues, importantly give formal prooftractable computation well-founded model LPAm,a programs. Moreover, provegeneral LP programs, may contain aggregates neither monotoneantimonotone, deciding satisfaction aggregate expressions respect partialinterpretations coNP-complete. consequence, well-founded semantics generalLPA programs allows tractable computation unlikely exist, justifiesrestriction LPAm,a programs. Finally, present prototype system extending DLV,supports well-founded semantics LPAm,a programs, time writingimplemented system so. Experiments prototype show significantcomputational advantages aggregate constructs equivalent aggregate-free encodings.1. Introductionuse logical formulas basis knowledge representation language proposed 50 years ago seminal works McCarthy (1959), McCarthyHayes (1969). However, soon realized monotonic nature classical logic(the addition new knowledge may increase set consequences theoryclassical logic) always suited model commonsense reasoning, sometimesintrinsically nonmonotonic (Minsky, 1975). alternative, suggested representc2011AI Access Foundation. rights reserved.fiAlviano, Calimeri, Faber, Leone, & Perricommonsense reasoning using logical languages nonmonotonic consequence relations,better simulate forms human reasoning, allowing new knowledge invalidate previous conclusions. observation opened new importantresearch field, called nonmonotonic reasoning, led definition investigationnew logical formalisms, called nonmonotonic logics. popular nonmonotonic logicscircumscription (McCarthy, 1980, 1986), default logic (Reiter, 1980), nonmonotonicmodal logics (McDermott & Doyle, 1980; McDermott, 1982; Moore, 1985). Later on,cross fertilizations field nonmonotonic logics logic programming,another nonmonotonic language, called Declarative Logic Programming (LP) emerged,incorporating nonmonotonic negation operator denoted not. Declarative Logic Programming gained popularity last years, today widely used formalismknowledge representation reasoning, applications various scientific disciplineseven industry (Ricca, Alviano, Dimasi, Grasso, Ielpa, Iiritano, Manna, & Leone,2010; Ricca, Grasso, Alviano, Manna, Lio, Iiritano, & Leone, 2011; Manna, Ricca, & Terracina, 2011; Manna, Ruffolo, Oro, Alviano, & Leone, 2011). LP problems solvedmeans declarative specifications requirements achieved. ad-hoc algorithmsrequired.Several semantics LP proposed literature, take careinherent non-monotonicity operator programs. well-foundedsemantics (Van Gelder, Ross, & Schlipf, 1991) one prominent among them.associates three-valued model, well-founded model, every logic program. Originally,well-founded semantics defined normal logic programs, is, standardlogic programs nonmonotonic negation. distinguishing property well-foundedsemantics existence uniqueness well-founded model guaranteedlogic programs. Moreover, well-founded semantics computable polynomial timerespect input program propositional case.Even LP declarative programming language, standard LP allowrepresenting properties sets data natural way, relevant aspect many application domains. addressing insufficiency, several extensions LPproposed, relevant introduction aggregate functions (LPA ;Kemp & Stuckey, 1991; Denecker, Pelov, & Bruynooghe, 2001; Dix & Osorio, 1997; Gelfond, 2002; Simons, Niemela, & Soininen, 2002; DellArmi, Faber, Ielpa, Leone, & Pfeifer,2003; Pelov & Truszczynski, 2004; Pelov, Denecker, & Bruynooghe, 2004). Among them,recursive definitions involving aggregate functions (i.e., aggregation aggregateddata depend evaluation aggregate itself) particularly interesting,definition semantics straightforward (Pelov, 2004; Faber, Leone, & Pfeifer,2004; Son & Pontelli, 2007; Liu, Pontelli, Son, & Truszczynski, 2010). Note similarconstruct, referred abstract constraint, introduced literature (Marek& Truszczynski, 2004; Liu & Truszczynski, 2006; Son, Pontelli, & Tu, 2007; Truszczynski,2010; Brewka, 1996). results paper carry also LP abstractconstraints, well-founded semantics knowledge defined far.paper focus fragment LPA allowing monotone antimonotoneaggregate expressions (LPAm,a ; Calimeri, Faber, Leone, & Perri, 2005). LPm,a programsmany interesting properties. Among them, highlight similarities monotoneaggregate expressions positive standard literals, antimonotone aggregate488fiUnfounded Sets Well-Founded Semantics ASP Programs Aggregatesexpressions negative standard literals. particular, take advantage aspectdefining unfounded sets and, based definition, well-founded semanticsLPAm,a fragment. well-founded semantics LPm,a programs obtained wayretains many desirable properties original well-founded semantics LP,extends: LPAm,a program unique well-founded model exists, polynomialtime computable, approximates programs answer sets, coincides answerset stratified LPAm,a programs.Actually turns well-founded semantics thus obtained coincides (on LPAm,aprograms) well-founded semantics proposed Pelov, Denecker, Bruynooghe(2007). Pelov et al. define several semantics logic programs aggregates using various approximating immediate consequence operators. notion logic program adoptedPelov et al. general one considered present work, allowingarbitrary first-order formulas bodies, unrestricted aggregates, non-Herbrand interpretations. equivalence two semantics, properties provedPelov et al. carry work well. applies results well-foundedmodel total stratified programs (Theorem 9), well-founded model containedanswer set (Theorem 16), well-founded model computable polynomial time (Theorem 21). However, framework introduced article considerablydifferent one developed Pelov et al., allows giving alternative proofsresult. Vice versa, article contains many new results, carryframework Pelov et al. LPAm,a programs. particular, provides alternativedefinition well-founded semantics, characterization answer sets means unfounded sets, implemented system computing well-founded semantics,time writing one kind.would like point extensions LPAm,a programs comemind, definition unfounded sets would considerably changed (see instance definition provided Faber, 2005), moreover main desired propertieswell-founded semantics would longer guaranteed. instance, obvious extension, including aggregate expressions neither monotone antimonotonewould likely computable polynomial time: fact, evaluationaggregate expressions respect partial interpretations tractable monotoneantimonotone aggregates, task coNP-complete general aggregate expressions. Also, instance allowing aggregates rule heads would necessarily complicatedefinition unfounded sets, would guarantee existence well-founded modelevery program, would likely guarantee polynomial-time computability.concepts defined paper directly give rise computation methodwell-founded semantics LPAm,a programs. implemented method,best knowledgethe first kind. conducted experimentssystem LPAm,a encodings particular problem domain, comparedencodings using aggregates. latter encodings tested systemprototype derived XSB, state-of-the-art system computingwell-founded model. experiments show clear advantage LPAm,a encodingsrun prototype system.Summarizing, main contributions paper follows.489fiAlviano, Calimeri, Faber, Leone, & Perridefine new notion unfounded set logic programs monotoneantimonotone aggregates (LPAm,a programs). notion sound generalizationconcept unfounded set previously given standard logic programs. showdefinition coincides original definition unfounded sets (Van Gelderet al., 1991) class normal (aggregate-free) programs, sharesdistinguishing properties (such existence greatest unfounded set).define well-founded operator WP logic programs aggregates, extends classical well-founded operator (Van Gelder et al., 1991). total fixpointsWP exactly answer sets P, least fixpoint WP () containedintersection answer sets. also show operator equivalentoperator defined Pelov et al. (2007).provide declarative characterization answer sets terms unfounded sets.particular, prove answer sets LPAm,a program preciselyunfounded-free models.show reasoning aggregates without restrictions may easily increasecomplexity computation. particular, prove deciding truthfalsity aggregate expression respect partial interpretationcoNP-complete problem. However, problem intractable general,polynomial-time solvable monotone antimonotone aggregates.analyze complexity well-founded semantics, confirming extendingresults work Pelov et al. (2007). Importantly, turns WP ()polynomial-time computable propositional LPAm,a programs. non-groundprograms, data-complexity remains polynomial, program complexityrises P EXPTIME, aggregate-free programs.present prototype system supporting well-founded semantics definedarticle. prototype, obtained extending DLV, first system implementingwell-founded semantics (unrestricted) LPAm,a programs.report experimental results implemented prototype. specifically,define Attacks problem, problem inspired classic Win-Lose problemoften considered context well-founded semantics standard logic programs. compare execution times prototype LPAm,a encodingequivalent LP encodings. particular, one tested LP encodings obtained means compilation aggregates standard LP, also brieflypresented paper. obtained results evidence computational advantagesproblem encoding using aggregate expressions without them.presentation organized follows. Section 2 present basicsLPA language and, particular, introduce LPAm,a fragment. fragment,define unfounded sets well-founded semantics Section 3. Relationshipswell-founded semantics answer set semantics discussed Section 4. complexityanalysis well-founded semantics LPAm,a programs reported Section 5.490fiUnfounded Sets Well-Founded Semantics ASP Programs AggregatesSection 6 discuss implemented prototype system experimentation. Finally,related work discussed Section 7, Section 8 draw conclusions.2. LPA LanguageSyntax, instantiation, interpretations models LPA programs introducedsection. Moreover, introduce LPAm,a fragment language, definewell-founded semantics Section 3. additional background standard LP, referliterature (Gelfond & Lifschitz, 1991; Baral, 2003).2.1 Syntaxassume sets variables, constants, predicates given. Similar Prolog,assume variables strings starting uppercase letters constants nonnegative integers strings starting lowercase letters. Predicates strings startinglowercase letters. arity (non-negative integer) associated predicate.Moreover, language allows using built-in predicates (i.e., predicates fixedmeaning) common arithmetic operations positive integers (i.e., =, , , +, ,etc.; written infix notation), interpreted standard mathematical way.2.1.1 Standard Atomterm either variable constant. standard atom expression p(t1 , . . . , tn ),p predicate arity n t1 , . . . , tn terms. atom p(t1 , . . . , tn ) groundt1 , . . . , tn constants.2.1.2 Set Termset term either symbolic set ground set. symbolic set pair {Terms : Conj },Terms list terms (variables constants) Conj conjunction standardatoms, is, Conj form a1 , . . . , ak ai (1 k) standardatom. Intuitively, set term {X : a(X, c), p(X)} stands set X-values makingconjunction a(X, c), p(X) true, i.e., {X | a(X, c) p(X) true}. ground set setpairs form hconsts : conj i, consts list constants conj conjunctionground standard atoms.2.1.3 Aggregate Functionaggregate function form f (S), set term, f aggregatefunction symbol. Intuitively, aggregate function thought (possibly partial)function mapping multisets constants constant. Throughout remainderpaper, adopt notation DLV system (Leone, Pfeifer, Faber, Eiter, Gottlob,Perri, & Scarcello, 2006) representing aggregates.Example 1 common aggregate functions listed below:#min, minimal term, undefined empty set;#max, maximal term, undefined empty set;491fiAlviano, Calimeri, Faber, Leone, & Perri#count, number terms;#sum, sum integers;#times, product integers;#avg, average integers, undefined empty set.2.1.4 Aggregate Atomaggregate atom structure form f (S) , f (S) aggregate function,{<, , >, } comparison operator, term (variable constant).aggregate atom f (S) ground constant ground set.Example 2 following aggregate atoms DLV notation:#max{Z : r(Z), a(Z, V )} >#max{h2 : r(2), a(2, m)i, h2 : r(2), a(2, n)i} > 12.1.5 Literalliteral either (i) standard atom, (ii) standard atom preceded negationfailure symbol not, (iii) aggregate atom. Two standard literals complementaryform a, standard atom a. standard literal ,denote . complement . Abusing notation, L set standard literals,.L denotes set {. | L}.2.1.6 Programrule r construct form: 1 , . . . , .standard atom, 1 , . . . , literals, 0. atom referredhead r, conjunction 1 , . . . , body r. body empty(m = 0), rule called fact. denote head atom H(r) = a, setbody literals B(r) = {1 , . . . , }. Moreover, set positive standard body literalsdenoted B + (r), set negative standard body literals B (r), setaggregate body literals B (r). rule r ground H(r) literals B(r)ground. program set rules. program ground rules ground.2.1.7 Safetylocal variable rule r variable appearing solely sets terms r; variable rlocal global. rule r safe following conditions hold: (i)global variable X r positive standard literal B + (r) X appears; (ii) local variable r appearing symbolic set {Terms : Conj } also appearsConj . Note condition (i) standard safety condition adopted LP guaranteevariables range restricted (Ullman, 1989), condition (ii) specificaggregates. program safe rules safe.492fiUnfounded Sets Well-Founded Semantics ASP Programs AggregatesExample 3 Consider following rules:p(X) : q(X, Y, V ), #max{Z : r(Z), a(Z, V )} > Y.p(X) : q(X, Y, V ), #sum{Z : r(X), a(X, S)} > Y.p(X) : q(X, Y, V ), #min{Z : r(Z), a(Z, V )} > T.first rule safe, second local variable Z violates condition(ii). Also third rule safe, since global variable violates condition (i).2.2 Program Instantiation, Interpretations ModelsSection 3 define well-founded semantics relevant class LPA programs.well-founded semantics defined ground programs, programs variablesassociated equivalent ground programs. section introduce preliminarynotions program instantiation, interpretations models.2.2.1 Universe BaseGiven LPA program P, universe P, denoted , set constantsappearing P. base P, denoted BP , set standard atoms constructiblepredicates P constants .2.2.2 Instantiationsubstitution mapping set variables . Given substitutionLPA object obj (rule, set, etc.), denote obj object obtained replacingvariable X obj (X). substitution set global variables ruler (to ) global substitution r; substitution set local variablesset term (to ) local substitution S. Given set term without global variables= {Terms : Conj }, instantiation following ground set:inst(S) = {hTerms : Conj | local substitution S}.ground instance rule r obtained two steps: First, global substitution rapplied, every set term r replaced instantiation inst(S).instantiation Ground(P) program P set instances rules P.Example 4 Consider following program P1 :q(1) : p(2, 2).p(2, 2) : q(1).q(2) : p(2, 1).p(2, 1) : q(2).t(X) : q(X), #sum{Y : p(X, )} > 1.instantiation Ground(P1 ) P1 following program:q(1) : p(2, 2).p(2, 2) : q(1).q(2) : p(2, 1).p(2, 1) : q(2).t(1) : q(1), #sum{h1 : p(1, 1)i, h2 : p(1, 2)i} > 1.t(2) : q(2), #sum{h1 : p(2, 1)i, h2 : p(2, 2)i} > 1.2.2.3 Aggregate Function DomainXGiven set X, let 2 denote set multisets elements X. domainaggregate function set multisets function defined. Without lossgenerality, assume aggregate functions map Z (the set integers).493fiAlviano, Calimeri, Faber, Leone, & PerriExample 5 Let us look common domains aggregate functions Example 1:UZ#count defined 2 ,P #sum #times 2 , #min, #max #avgZ2 \ {}.2.2.4 Interpretationinterpretation LPA program P consistent set standard ground literals,is, BP .BP .I = . denote + set standardpositive negative literals occurring I, respectively. interpretation total+ .I = BP , otherwise partial. set interpretations P denotedIP . Given interpretation standard literal , evaluation respectdefined follows: (i) I, true respect I; (ii) . I,false respect I; (iii) otherwise, 6 . 6 I, undefinedrespect I. interpretation also provides meaning set terms, aggregate functionsaggregate literals, namely multiset, value, truth value, respectively.first consider total interpretation I. evaluation I(S) set term respectmultiset I(S) defined follows: Let = {ht1 , ..., tn | ht1 , ..., tn : Conjatoms Conj true respect I}; I(S) multiset obtainedprojection tuples SI first constant, is, I(S) = [t1 | ht1 , ..., tn ].evaluation I(f (S)) aggregate function f (S) respect resultapplication f I(S).1 multiset I(S) domain f , I(f (S)) =(where fixed symbol occurring P). ground aggregate atom = f (S) ktrue respect I(f (S)) 6= I(f (S)) k hold; otherwise, false.Example 6 Let I1 total interpretation I1+ = {f (1), g(1, 2), g(1, 3), g(1, 4), g(2, 4),h(2), h(3), h(4)}. Assuming variables local, check that:#count{X : g(X, )} > 2 false; indeed, S1 corresponding ground set,S1I1 = {h1i, h2i}, I1 (S1 ) = [1, 2] #count([1, 2]) = 2.#count{X, : g(X, )} > 2 true; indeed, S2 corresponding ground set,S2I1 = {h1, 2i, h1, 3i, h1, 4i, h2, 4i}, I1 (S2 ) = [1, 1, 1, 2] #count([1, 1, 1, 2]) = 4.#times{Y : f (X), g(X, )} <= 24 true; indeed, S3 corresponding groundset, S3I1 = {h2i, h3i, h4i}, I1 (S3 ) = [2, 3, 4] #times([2, 3, 4]) = 24.#sum{X : g(X, ), h(Y )} <= 3 true; indeed, S4 corresponding ground set,S4I1 = {h1i, h2i}, I1 (S4 ) = [1, 2] #sum([1, 2]) = 3.#sum{X, : g(X, ), h(Y )} <= 3 false; indeed, S5 corresponding groundset, S5I1 = {h1, 2i, h1, 3i, h1, 4i, h2, 4i}, I1 (S5 ) = [1, 1, 1, 2] #sum([1, 1, 1, 2]) =5.;#min{X : f (X), h(X)} >= 2 false; indeed, S6 corresponding ground set,S6I1 = , I1 (S6 ) = , I1 (#min()) = (we recall domain#min).1. paper, consider aggregate functions value polynomial-time computablerespect input multiset.494fiUnfounded Sets Well-Founded Semantics ASP Programs Aggregatesconsider partial interpretation refer interpretation JJ extension I. ground aggregate atom true (resp. false) respecttotal interpretation J extending I, true (resp. false) respect I;otherwise, undefined.Example 7 Let S7 ground set literal 1 = #sum{h1 : p(2, 1)i, h2 : p(2, 2)i} >1, consider partial interpretation I2 = {p(2, 2)}. Since total interpretationextending I2 contains either p(2, 1) p(2, 1), either I2 (S7 ) = [2] I2 (S7 ) =[1, 2]. Thus, application #sum yields either 2 > 1 3 > 1, thus 1 truerespect I2 .Remark 1 Observe definitions interpretation truth values preserve knowledge monotonicity: interpretation J extends (i.e., J), literal truerespect true respect J, literal false respectfalse respect J well.2.2.5 ModelGiven interpretation I, rule r satisfied respect least one followingconditions satisfied: (i) H(r) true respect I; (ii) literal B(r) falserespect I; (iii) H(r) literal B(r) undefined respect I.interpretation model LPA program P rules r Ground(P)satisfied respect .Example 8 Consider program P1 Example 4. Let I3 total interpretationP1 I3+ = {q(2), p(2, 2), t(2)}. I3 minimal model P1 .2.3 LPAm,a Languagedefinition LPAm,a programs, fragment LP analyzed paper, basedfollowing notion monotonicity literals.2.3.1 MonotonicityGiven two interpretations J, say J + J + J .ground literal monotone if, interpretations I, J J, that:(i) true respect implies true respect J, (ii) false respectJ implies false respect I. ground literal antimonotone oppositehappens, is, interpretations I, J J, that: (i) falserespect implies false respect J, (ii) true respect J impliestrue respect I. ground literal nonmonotone neither monotoneantimonotone. Note positive standard literals monotone, whereas negative standardliterals antimonotone. Aggregate literals, instead, may monotone, antimonotonenonmonotone. examples shown complete picturecommon aggregate functions summarized Table 1.Example 9 Let us assume universe numerical constants non-negativeintegers. ground instances following aggregate literals thus monotone:495fiAlviano, Calimeri, Faber, Leone, & PerriTable 1: Character common aggregate literals.Function Domain OperatorCharacter#count>,monotone<,antimonotone#sumN>,monotone<,antimonotoneZ<, , >, nonmonotone#timesN+>,monotone<,antimonotoneN, Z<, , >, nonmonotone#min>,nonmonotone<,monotone#max>,monotone<,nonmonotone#avgN, Z<, , >, nonmonotoneAntimonotone context guarantees set term aggregate never becomes empty.#sum{Z : r(Z)} 10.#count{Z : r(Z)} > 1;Ground instances following literals instead antimonotone:#sum{Z : r(Z)} 10.#count{Z : r(Z)} < 1;2.3.2 LPAm,a ProgramsLet LPAm,a denote fragment LP allowing monotone antimonotone literals.LPAm,a rule r, set monotone antimonotone body literals denotedB (r) B (r), respectively. LPAm,a program P stratified exists function|| ||, called level mapping, set predicates P ordinals,pair a, b predicates, occurring head body rule r P, respectively: (i) bappears antimonotone literal, ||b|| < ||a||, (ii) otherwise ||b|| ||a||. Intuitively,stratification forbids recursion antimonotone literals (for aggregate-free programsdefinition coincides common notion stratification respect negation).Example 10 Consider LPAm,a program consisting following rules:q(X) : p(X), #count{Y : a(Y, X), b(X)} 2.p(X) : q(X), b(X).assume predicates b defined facts, includeexplicitly. program stratified, level mapping ||a|| = ||b|| = 1, ||p|| = ||q|| = 2satisfies required conditions. add rule b(X) : p(X), levelmapping exists, program becomes unstratified.would like note definition LPAm,a could enlarged, formgiven classifies literals independently context (that is, program)496fiUnfounded Sets Well-Founded Semantics ASP Programs Aggregatesoccur. aggregates nonmonotone definition given above, mightmanifest nonmonotone effects given context: one limits interpretationsconsidered violate program literal occurs,interpretation pairs violate monotonicity antimonotonicity may longerpresent. fact, one could refine definition way (considering pairsnon-violating interpretations given context program). modified definition wouldenlarge class LPAm,a programs, retaining results paper,simplicity exposition refrain formally. example, aggregateatom involving #max < operator formally LPAm,a , one considersoccurrences program non-violating interpretation I(S) =(where set term aggregate), aggregate behaves antimonotoneway particular program. noted cases footnote Table 1.3. Unfounded Sets Well-Founded Semanticssection introduce new notion unfounded set LPAm,a programs,extends original definition aggregate-free programs introduced Van Gelder et al.(1991). Unfounded sets used extending well-founded semantics, originallydefined aggregate-free programs Van Gelder et al., LPAm,a programs. alsohighlight number desirable properties semantics. following dealground programs, usually denote P ground program. also usenotation L .L set (L \ L ) .L , L L sets standard groundliterals.Definition 1 (Unfounded Set) set X BP ground atoms unfounded setLPAm,a program P respect (partial) interpretation if, ruler P H(r) X , least one following conditions holds:(1) (antimonotone) literal B (r) false respect I,(2) (monotone) literal B (r) false respect .X .Intuitively, rule head atom belonging unfounded set X alreadysatisfied respect (in case condition (1) holds), satisfiable taking falseatoms unfounded set (in case condition (2) holds). Note that, accordingdefinition above, empty set unfounded set respect every programinterpretation.Example 11 Consider interpretation I4 = {a(1), a(2), a(3)} following programP2 :r1 :r2 :r3 :a(1) : #count{h1 : a(1)i, h2 : a(2)i, h3 : a(3)i} > 2.a(2).a(3) : #count{h1 : a(1)i, h2 : a(2)i, h3 : a(3)i} > 2.X1 = {a(1)} unfounded set P2 respect I4 , since condition (2)Definition 1 holds r1 (the rule head a(1)). Indeed, (monotone) literalappearing B (r1 ) false respect I4 .X1 = {not a(1), a(2), a(3)}. Similarly,{a(3)} {a(1), a(3)} unfounded sets P2 respect I4 . Clearly, alsounfounded set. sets atoms unfounded P2 respect I4 .497fiAlviano, Calimeri, Faber, Leone, & Perriformalized below, Definition 1 generalizes one given Van Gelder et al. (1991)aggregate-free programs: set standard atoms X BP unfounded setprogram P respect interpretation if, rule r PH(r) X , either (i) B(r) .I 6= , (ii) B + (r) X =6 .Theorem 1 aggregate-free program P, Definition 1 equivalent one introduced work Van Gelder et al. (1991).Proof. aggregate-free program P, conditions (1) (2) Definition 1 equivalent (a) B (r) .I 6= (b) B + (r) .(I .X ) 6= , respectively. Condition (b)equivalent B + (r) (.(I \ X ) ..X ) 6= , holds either (b.1)B + (r) .(I \ X ) 6= , (b.2) B + (r) X =6 . Condition (b.2) exactly condition (ii)work Van Gelder et al. Concerning condition (b.1), since B + (r) containspositive literals, ignore negative literals .(I \ X ), is, positive literals\ X . noting negative literals \ X precisely negative literalsI, conclude (b.1) equivalent B + (r) .I 6= . Finally, combiningprevious statement condition (a) above, obtain condition (i) work VanGelder et al.Thus, Definition 1 alternative characterization unfounded sets aggregate-freeprograms. fact, condition (1) Definition 1 exactly cover first oneVan Gelder et al., condition (2) catches cases second work Van Gelderet al. missed condition (1).Theorem 2 X X unfounded sets LPAm,a program P respectinterpretation I, X X unfounded set P respect I.Proof. Let r P H(r) X X . want show either (1)(antimonotone) literal B (r) false respect I, (2) (monotone) literalB (r) false respect J = .(X X ). symmetry, assumeH(r) belongs X . Since X unfounded set respect hypothesis, either(a) (antimonotone) literal B (r) false respect I, (b) (monotone)literal B (r) false respect K = .X . Case (a) equals (1). Thus,remains prove case (b) implies (2). Indeed, J K J + K +J K . Therefore, definition monotonicity, monotone literalfalse respect K false respect J well, done.corollary Theorem 2, union unfounded sets unfounded setwell.Corollary 3 union unfounded sets LPAm,a program P respectinterpretation unfounded set P respect well. refer setgreatest unfounded set P respect I, denoted GU SP (I).important monotonicity property greatest unfounded set.Proposition 4 Let J interpretations LPAm,a program P. J,GU SP (I) GU SP (J).498fiUnfounded Sets Well-Founded Semantics ASP Programs AggregatesProof. Since GU SP (J) union unfounded sets P respect Jdefinition, enough show X = GU SP (I) unfounded set P respectJ. Thus, want show that, rule r P H(r) X , either (1)(antimonotone) literal B (r) false respect J, (2) (monotone) literalB (r) false respect J .X . already know X unfounded set Prespect Corollary 3. Therefore, either (a) (antimonotone) literal B (r)false respect I, (b) (monotone) literal B (r) false respect.X . Since J, J J .X extensions interpretations.X , respectively. Hence, Remark 1, (a) implies (1) (b) implies (2),done.ready extending well-founded operator defined Van Gelder et al.(1991) case LPAm,a programs.Definition 2 Let P LPAm,a program. immediate logical consequence operatorBPTP : IP 2well-founded operator WP : IP 2BP .BP defined follows:TP (I) = { BP | r P H(r) =literals B(r) true respect I}WP (I) = TP (I) .GU SP (I).Intuitively, given interpretation program P, WP derives true setatoms belonging every model extending (by means TP operator). Moreover,WP derives false atoms belonging unfounded set P respect(by means GU SP operator). Note TP (I) GU SP (I) set atoms,WP (I)+ = TP (I) WP (I) = .GU SP (I). following proposition formalizesintuition Definition 2 extends WP operator defined Van Gelder et al. (1991)standard programs LPAm,a programs.Proposition 5 Let P aggregate-free program. WP operator Definition 2coincides WP operator defined Van Gelder et al. (1991).Proof. Since WP equal union TP .GU SP cases,show definitions TP GU SP coincide introduced Van Gelderet al. (1991) aggregate-free programs.two immediate logical consequence operators (TP ) coincide aggregate-freeprogram P. Indeed, rule r P, B(r) standard literals.definition GU SP (I) coincides one Van Gelder et al. (1991)aggregate-free program P interpretation I. Indeed, cases GU SP (I)defined union unfounded sets P respect I, notionunfounded set coincides one work Van Gelder et al. standardprograms Theorem 1.next show fixpoint well-founded operator WP (possibly partial)model.499fiAlviano, Calimeri, Faber, Leone, & Perri{a, b}{a, b}{a}{b}{not a, b} {not a, b}{not b}{not a}Figure 1: meet semilatticeTheorem 6 Let P LPAm,a program (partial) interpretation.fixpoint WP , (partial) model P.Proof. Let us assume WP (M ) = holds. Thus, TP (M ) .GU SP (M )hold. Consider rule r P. literals B(r) true respect ,H(r) TP (M ) . H(r) false respect , H(r) GU SP (M ).Since GU SP (M ) unfounded set P respect Corollary 3, eitherliteral B (r) false respect , literal B (r) false respect.GU SP (M ) = . conclude r satisfied .theorem states WP monotone operator meet semilattice induced IP subset-containment relationship. recall meet semilatticepartially ordered set meet (or greatest lower bound) nonempty finitesubset. example meet semilattice program base {a, b} reportedFigure 1.Theorem 7 Let P LPAm,a program. well-founded operator WP monotoneoperator meet semilattice hIP , i.Proof. Since WP equal union TP .GU SP Definition 2,prove monotonicity operators TP GU SP .first show TP monotone operator, is, pair interpretationsI, J P J, holds TP (I) TP (J). Consider atom TP (I).Definition 2, rule r P H(r) = literals B(r)true respect I. Since J, conclude literals B(r)true respect J well (see Remark 1), H(r) = belongs TP (J)Definition 2.already know GU SP monotone operator Proposition 4:pair interpretations I, J P J, holds GU SP (I) GU SP (J).prove sequence W0 = , Wn+1 = WP (Wn ) well-defined, is,element sequence interpretation.Theorem 8 Let P LPAm,a program. sequence W0 = , Wn+1 = WP (Wn )well-defined.500fiUnfounded Sets Well-Founded Semantics ASP Programs AggregatesProof. use strong induction. base case trivial, since W0 = . order proveconsistency Wn+1 = TP (Wn ).GU SP (Wn ), assume consistency every Wmn. Since WP monotone operator Theorem 7, enough showGU SP (Wn ) Wn+1 = . end, next show set X atomsX Wn+1 6= unfounded set P respect Wn (and containedGU SP (Wn )). Let Wm+1 first element sequence X Wm+1 6= (noten). Consider atom X Wm+1 . definition TP , rule r PH(r) = literals B(r) true respect Wm . Noteatom Wm belong X (for way Wm+1 chosen). Thus,Remark 1, literals B(r) true respect Wn Wn .X (werecall Wn Wm WP monotone). ends proof, neither condition(1) (2) Definition 1 hold .Theorem 8 Theorem 7 imply WP admits least fixpoint (Tarski, 1955),referred well-founded model P. well-founded semantics LPAm,aprogram P given model. state first important propertywell-founded semantics LPAm,a programs.Property 1 every LPAm,a program, well-founded model always exists unique.Another important property well-founded semantics easily follows Proposition 5.Property 2 aggregate-free programs, well founded semantics definedpaper coincides classical well-founded semantics Van Gelder et al. (1991).Although well-founded model, general, might leave atoms undefined,cases WP () total interpretation.Example 12 Consider following program P3 :a(1) : #sum{h1 : a(1)i, h2 : a(2)i} > 2.a(2) : b.b : c.iterated application WP yields following sets:1.2.3.WP () = {not a(1), c};WP ({not a(1), c}) = {not a(1), c, b};WP ({not a(1), c, b}) = {not a(1), c, b, a(2)} = WP ().case, well-founded model total. Indeed, atom BP either true falserespect WP ().totality well-founded model program due stratification,formalized next theorem. Given Corollary 25, equivalent result statedalready Pelov et al. (2007) Theorem 7.2 Corollary 7.1. However, prooflabelled sketch Pelov et al., moreover relies rather different formalismsproof.501fiAlviano, Calimeri, Faber, Leone, & PerriTheorem 9 stratified LPAm,a programs, well-founded model total.Proof. Let P stratified LPAm,a program. order prove WP () total,show (standard) atom BP \WP () false respect WP (). definitionstratification, level mapping || || (standard) predicates P that,pair a, b standard predicates occurring head body rule r P,respectively, following conditions satisfied: (i) b appears antimonotone literal,||b|| < ||a|| holds; (ii) otherwise, b appears monotone literal, ||b|| ||a||holds. order define non-decreasing sequence subsets BP follows:L0 =Li+1 = Li { BP | predicate p ||p|| = i},N.aim show that, N, set Li+1 \WP () contained .WP () .use induction i. base case trivial L0 = holds definition.suppose atoms Li \ WP () false respect WP () order showatoms Li+1 \ WP () false respect WP () well. end,prove Li+1 \ WP () unfounded set P respect WP (). Considerrule r Ground(P) H(r) Li+1 \ WP (). want show either (1)(antimonotone) literal B (r) false respect WP (), (2) (monotone)literal B (r) false respect WP () .(Li+1 \ WP ()). Since H(r) Li+1 ,definition stratification following propositions hold:(a) literal B (r) either negated standard atom belonging Li , aggregateliteral depending atoms Li ;(b) literal B (r) either standard atom belonging Li+1 , aggregateliteral depending atoms Li+1 .Since H(r) 6 WP () (that is, H(r) 6 TP (WP ())), literal B(r)true respect WP () (by definition TP ). antimonotone literal,apply (a) induction hypothesis conclude (1) holds ( cannot undefinedrespect WP (), must false). monotone literal, apply (b)induction hypothesis conclude (2) holds ( cannot undefined respectWP () .(Li+1 \ WP ()) WP () .(Li+1 \ WP ()) WP () holds, mustfalse).4. Answer Set Characterization via Unfounded Setswell-founded semantics three-valued semantics, is, program associated model atoms either true, false undefined. semanticsliterature associate programs two-valued models (i.e., models without undefinedatoms). commonly accepted two-value semantics LP answer set semantics.section present number results concerning unfounded sets answer setsLPAm,a programs. first recall definition answer sets provided Faber, Leone,Pfeifer (2011).502fiUnfounded Sets Well-Founded Semantics ASP Programs AggregatesDefinition 3 (Minimal Model) total model P (subset-)minimal totalmodel N P exists N + + . Note that, definitions, wordsinterpretation model refer possibly partial interpretations, minimal modelalways total interpretation.next provide transformation reduct ground programrespect total interpretation formed. Note definition generalization (Faberet al., 2004) Gelfond-Lifschitz transformation (1991) standard logic programs.Definition 4 (Program Reduct) Given LPA program P total interpretationI, let Ground(P)I denote transformed program obtained Ground(P) deletingrules body literal false respect I, i.e.:Ground(P)I = {r Ground(P) | literals B(r) true respect I}.ready introducing notion answer set LPA programs.Definition 5 (Answer Set LPA Programs) Given LPA program P, total interpretation P answer set P minimal modelGround(P)M .Example 13 Consider two total interpretations I5 = {p(0)} I6 = {not p(0)}following two programs:P4 = {p(0) : #count{X : p(X)} > 0.}P5 = {p(0) : #count{X : p(X)} 0.}obtain following transformed programs:Ground(P4 )I5Ground(P4 )I6Ground(P5 )I5Ground(P5 )I6= Ground(P4 ) = {p(0) : #count{h0 : p(0)i} > 0.}=== Ground(P5 ) = {p(0) : #count{h0 : p(0)i} 0.}Hence, I6 answer set P4 . Indeed, I5 minimal model Ground(P4 )I5 .Moreover, P5 answer sets. Indeed, I5 minimal model Ground(P5 )I5 ,I6 model Ground(P5 )I6 = Ground(P5 ).Note answer set P also total model P Ground(P)MGround(P), rules Ground(P) \ Ground(P)M satisfied respect(by Definition 4, rules must least one body literal falserespect ).language LPAm,a considered work, answer sets defined Definition 5coincide stable models defined Pelov, Denecker, Bruynooghe (2003)hence also defined Pelov et al. (2007) Son et al. (2007). equivalencefollows Propositions 3.7 3.8 Ferraris (2011), respectively state stablemodels Pelov et al. (2003) LPAm,a coincide semantics defined Ferraris (2011),turn coincides Definition 5 larger class programs. meansresults involving answer sets also hold semantics LPAm,a .hand, also implies results (for example Theorem 16) consequencesresults work Pelov et al. (2007) virtue Theorem 24 Section 7.remainder section highlight relevant relationships answer setsunfounded sets. introducing results, let us provide additional definition.503fiAlviano, Calimeri, Faber, Leone, & PerriDefinition 6 (Unfounded-free Interpretation) interpretation LPAm,a program P unfounded-free X = holds unfounded set X Prespect I.total interpretations, equivalent characterization unfounded-free propertygiven below.Lemma 10 total interpretation LPAm,a program P unfounded-free+empty set subset unfounded set P respect I.Proof. () Straightforward: Definition 6, disjoint unfounded setP respect I.() prove contrapositive: unfounded-free, exists non-emptysubset + unfounded set P respect I. Definition 6,unfounded-free, exists unfounded set X P respectX =6 . next show X unfounded set P respect I, i.e.,rule r P H(r) X , either (1) (antimonotone) literal B (r)false respect I, (2) (monotone) literal B (r) false respect.(I X ). Since X unfounded set, Definition 1, either (a) (antimonotone)literal B (r) false respect I, (b) (monotone) literal B (r) falserespect .X . Thus, end proof showing .X = .(I X ).end, observe (i) .X = .(X \ I) .(I X ). Moreover, since total,.(BP \ + ) = , thus (ii) .(X \ I) = .(X \ + ) \ X . using (i).X = (I \ X ) .X simplifying (ii) obtain .X = (I \ X ) .(I X ).conclude observing \ X = \ (I X ), thus .X = .(I X )holds.give another interesting characterization total models LPAm,a programs.Lemma 11 total interpretation (total) model LPAm,a program P.M unfounded set P respect .Proof. start observing rule r P H(r) + satisfied. Thus, show that, rule r P H(r) .M , literalB(r) false respect either (1) (antimonotone) literal B (r)false respect , (2) (monotone) literal B (r) false respect.(.M ). end, enough prove .(.M ) = holds.definition, () .(.M ) = (M \ .M ) ..M . consistency.M disjoint. Moreover, ..M = subset .simplifying () last two sentences, obtain .(.M ) = .give characterizations answer sets LPAm,a programs.Theorem 12 total model answer set LPAm,a program Punfounded-free.504fiUnfounded Sets Well-Founded Semantics ASP Programs AggregatesProof. () prove contrapositive: total model LPAm,a program Punfounded-free, answer set P. Lemma 10, since totalinterpretation unfounded-free, exists unfounded set X Prespect X + X =6 . Therefore, prove answerset P, next show .X model P .X .end, consider rule r P . Definition 4 reduct, literals B(r) truerespect , H(r) + model P P P.consider two cases:1. H(r) 6 X . case, H(r) .X well.2. H(r) X . case, since X unfounded set P respect , either(1) literal B (r) false respect , (2) literal B (r) falserespect .X . previous considerations, since r P , (1) cannot hold,conclude literal B(r) false respect .X .Hence, r satisfied .X either head (in case H(r) 6 X ),body (in case H(r) X ), done.() prove contrapositive: total model LPAm,a program Panswer set P, unfounded-free. Since model P Panswer set P, exists total model N P N + + . next show+ \ N + unfounded set P respect , is, rule r PH(r) + \ N + , either (1) (antimonotone) literal B (r) false respect, (2) (monotone) literal B (r) false respect .(M + \ N + ).start showing .(M + \ N + ) = N . definition, (a) .(M + \ N + ) =(M \ (M + \ N + )) .(M + \ N + ). N + + (b) \ (M + \ N + ) =N + . Moreover, since N total interpretations N + + , (c)N (d) .(M + \ N + ) = N \ . Thus, using (b) (d) (a) obtain.(M + \ N + ) = N + (N \M ), observing (N \M ) = Nholds (c), conclude (e) .(M + \ N + ) = N + N = N .Consider rule r P H(r) + \ N + . deal two cases:1. r P \ P . case, Definition 4, must literal B(r)false respect . antimonotone literal, (1) holds. Otherwise,monotone literal false respect N well, since N ; thus,(2) holds (e).2. r P . case, since N model P H(r) false respect N(because H(r) + \ N + assumption), must literal B(r)false respect N . antimonotone literal, false respectwell, since N , (1) holds. Otherwise, monotone literal(2) holds (e).ready state important connection answer sets unfoundedsets.Theorem 13 total interpretation LPAm,a program P answer set PGU SP (M ) = .M .505fiAlviano, Calimeri, Faber, Leone, & PerriProof. () Let answer set P. Lemma 11, .M unfounded set Prespect , hence GU SP (M ) .M . Theorem 12, unfounded-free,hence GU SP (M ) .M total. sum, GU SP (M ) = .M .() Let total interpretation GU SP (M ) = .M . GU SP (M ) =.M disjoint, unfounded-free. Moreover, Corollary 3, GU SP (M ) =unfounded set P respect so, applying Lemma 11, concludemodel P. order apply Theorem 12 (M unfounded-freemodel P) conclude answer set P.following theorem shows answer sets LPAm,a programs exactly totalfixpoints well-founded operator defined Section 3.Theorem 14 Let total interpretation LPAm,a program P.answer set P fixpoint well-founded operator WP .Proof. () Let answer set P. want show fixpoint WP ,is, WP (M ) = . aim show TP (M ) = + .GU SP (M ) = .Since answer set, applying Theorem 13, obtain GU SP (M ) = .M ,equivalent .GU SP (M ) = . Therefore, remains prove TP (M ) = + :() Consider atom TP (M ). Definition 2, rule r PH(r) = literals B(r) true respect . Thus, + holdsmodel P.() Consider atom + . Since answer set P, apply Theorem 12conclude unfounded-free. Hence, (singleton) set {} +unfounded set P respect . Thus, Definition 1, ruler P H(r) = neither (1) (antimonotone) literal B (r)false respect , (2) (monotone) literal B (r) false respect.{}. Since total interpretation, neither (1) (2) equivalent(i) (antimonotone) literals B (r) true respect , (ii)(monotone) literals B (r) true respect .{}. observing.{} , state (ii) implies (monotone) literalsB (r) true respect well. combining latter statement (i)obtain literals B(r) true respect , TP (M )Definition 2.() Let total fixpoint WP , i.e., WP (M ) = . Thus, = .GU SP (M )Definition 2, answer set P Theorem 13.Observe Theorem 14 generalization Theorem 5.4 Van Gelder et al. (1991)class LPAm,a programs. also worth noting WP (I) extends preservingcorrectness: contained answer set , WP (I) may add literals, never introduces literal would inconsistent .Proposition 15 Let interpretation LPAm,a program P, letanswer set P. , WP (I) .506fiUnfounded Sets Well-Founded Semantics ASP Programs AggregatesProof. trivial consequence monotonicity operator WP (Theorems 7)Theorem 14. Indeed, Theorems 7, WP implies WP (I) WP (M ),WP (M ) = Theorem 14.next show well-founded model LPAm,a program containedanswer sets (if any) P. would like point due Theorem 24 Section 7(showing equivalence well-founded operators defined work onedefined Pelov et al., 2007) Propositions 3.77 3.8 Ferraris (2011; showingequivalence answer sets Faber et al., 2011 stable models Pelov et al., 2007),following results also hold virtue definitions well-founded stablesemantics work Pelov et al., particular due Proposition 7.3 paper.nevertheless also provide proof using concepts defined earlier.Theorem 16 Let P LPAm,a program. answer set P, WP () .Proof. Let answer set P. Note WP () limit sequence W0 = ,Wn = WP (Wn1 ). show Wn induction n. base case triviallytrue since W0 = definition. assume Wn order show Wn+1 .Since Wn+1 = WP (Wn ) definition Wn induction hypothesis, applyProposition 15 conclude Wn+1 .theorem suggests another property well-founded semantics LPAm,a programs.Property 3 well-founded semantics LPAm,a programs approximates answer setsemantics: well-founded model contained intersection answer sets (ifany).combining Theorem 14 Theorem 16, obtain following claim.Corollary 17 Let P LPAm,a program. WP () total interpretation,unique answer set P.Therefore, combining Theorem 9 corollary above, obtain another propertywell-founded semantics LPAm,a programs.Property 4 stratified LPAm,a programs, well-founded model coincidesunique answer set.5. Complexity Well-Founded Semanticscomplexity analysis carried section, consider ground programspolynomial-time computable aggregate functions (note example aggregate functionsappearing paper fall class). However, eventually provide discussionresults change considering non-ground programs. start importantproperty monotone antimonotone aggregate literals.507fiAlviano, Calimeri, Faber, Leone, & PerriLemma 18 Let partial interpretation ground LPAm,a program P. definetwo total interpretations P follows: Imin = .(BP \ I) Imax = (BP \ .I).(ground) aggregate literal occurring P, following statements hold:1. monotone literal, true (resp. false) respecttrue respect Imin (resp. false respect Imax ).2. antimonotone literal, true (resp. false) respecttrue respect Imax (resp. false respect Imin ).Proof. start noting Imin (resp. Imax ) total interpretation extendingstandard atoms undefined respect falserespect Imin (resp. true respect Imax ). Thus, () Imin Imax .monotone true respect Imin (resp. false respect Imax ), true(resp. false) respect (). antimonotone true respectImax (resp. false respect Imin ), true (resp. false) respect(). end proof observing true (resp. false) respectI, true respect Imin Imax definition.ready analyze computational complexity well-founded semanticsLPAm,a programs. analysis lead prove following fundamental property.Property 5 well-founded model ground LPAm,a program efficiently (polynomialtime) computable.Given Corollary 25, property also follows Theorem 7.4 work Pelovet al. (2007). following, provide alternative proof based conceptsdefined earlier paper, also leads several interesting intermediate results.Property 5 trivial aggregates may easily increase complexityevaluation. Indeed, even deciding truth aggregate respect partial interpretation intractable general; similar observation already made Pelov(2004). However, task polynomial-time computable aggregate literals occurring LPAm,a programs.Proposition 19 Deciding whether ground aggregate literal true (resp. false)respect partial interpretation is:(a) co-NP-complete general;(b) polynomial-time computable either monotone antimonotone literal.Proof. (a) membership, consider complementary problem, is,deciding whether ground aggregate literal true (resp. false) respectpartial interpretation I, prove belongs NP. order showtrue (resp. false) respect enough find total interpretation Jextending (that is, J I) false (resp. true) respect J. Thus,guess J check falsity (resp. truth) respect J polynomial508fiUnfounded Sets Well-Founded Semantics ASP Programs Aggregatestime (if aggregate function computed polynomial time respect sizeinput multiset, assuming).hardness, first consider problem checking truth aggregate provide polynomial-time reduction TAUTOLOGY. TAUTOLOGYproblem co-NP-complete stated follow: Given proposition formulavariables X1 , . . . , Xn , truth assignment v variables X1 , . . . , Xn satisfyformula ? Without loss generality, assume 3-DNF formula form= D1 Dm ,disjunct Di conjunction 1i 2i 3i , ji positive negativeliteral (note that, context TAUTOLOGY, term literal denotes variableXk variable preceded negation symbol ). given , considerpartial interpretation = {} construct aggregate literal = #sum{S} 1,contains two groups elements. elements first group represent disjunctsh1 : (1i ), (2i ), (3i )i,= 1, . . . , ,where, = 1, . . . , j = 1, . . . , 3, propositional atom (ji ) definedfollows:jxk positive literal Xk , k {1, . . . , n}.j(i ) =fxk ji negative literal Xk , k {1, . . . , n}.elements second group represent variables follows:h 1,h1,h1,h 1,xk :xk : xtk,xk : xfkxk : xtk , xfkk = 1, . . . , n ,xk xk constants associated variable Xk . Note that, variableXk , two atoms A, xtk xfk . Thus, interpretation J, four casespossible:(1) {not xtk , xfk } J: case, h1, xk : contribute evaluationA, contribution 1;(2) {xtk , xfk } J: case, four elements contribute evaluation A,thus contribution 1 1 + 1 = 1 (note h1, xk : xtk h1, xk : xfkgive total contribution 1 pure set approach);(3) {xtk , xfk } J: case, h1, xk : h1, xk : xtk contribute, giving1 1 = 0;(4) {not xtk , xfk } J: case, h1, xk : h1, xk : xfk contribute, giving1 1 = 0.509fiAlviano, Calimeri, Faber, Leone, & PerriThus, k {1, . . . , n}, total contribution four elements associatedvariable Xk either 0 1. Note also total contribution elements(i.e., first group) either 0 1. Therefore, k {1, . . . , n}either case (1) (2) occurs, interpretation J trivially satisfies A. Otherwise, Jthat, variable k {1, . . . , n}, either (3) (4) occurs. case, sayJ good interpretation.next define one-to-one mapping set assignments setgood interpretations. Let v assignment . good interpretation Iv associatedv Ivf{xtk , xk } Iv v(Xk ) = 1,k = 1, . . . , n .f{not xk , xk } Iv v(Xk ) = 0want show v satisfies true respect Iv . Since Ivgood interpretation, elements second group give total contribution 0,consider elements first group. elements givecontribution 1 {(1i ), (2i ), (3i )} holds least one {1, . . . , n},holds v(Di ) = 1 holds disjunct Di . concludetrue respect Iv v() = 1.Concerning check falsity aggregate, start 3-DNF formulaconstruct aggregate literal = #sum{S} < 1, obtained describedabove. tautology false respect = {}.(b) Let partial interpretation LPAm,a program P aggregate literaloccurring P. want show deciding whether true (resp. false) respectdone polynomial-time size BP . Lemma 18, enough evaluateaggregate respect either Imin = .(BP \ I) Imax = (BP \ .I).end proof observing interpretations Imin Imax constructedpolynomial time, value aggregate function computedpolynomial time respect size input multiset assumption.order prove tractability well-founded semantics need efficientmethod computing greatest unfounded set, part well-founded operatorWP . Hence, next give polynomial-time construction set BP \GU SP (I) meansmonotone operator.Definition 7 Let interpretation LPAm,a program P. operator :BBPPdefined follows:2 2(Y ) = { BP | r P H(r) =(antimonotone) literal B (r) false respect I,(monotone) literals B (r) true respect \ .I }least fixpoint coincides greatest unfounded set P respectI.Theorem 20 Let P LPAm,a program interpretation P. Then:510fiUnfounded Sets Well-Founded Semantics ASP Programs Aggregates1. operator least fixpoint ();2. GU SP (I) = BP \ ().Proof. operator monotonically increasing operator meet semilatticehBP , i, therefore admits least fixpoint () (Tarski, 1955). next proveGU SP (I) = BP \ () two steps:() first observe () computed iteratively, starting empty set,limit sequence F0 = , Fi+1 = (Fi ). Thus, prove inductionGU SP (I) BP \Fi holds. base case trivial, since F0 = definitionGU SP (I) subset BP Definition 1. assume GU SP (I) BP \ Fiorder prove GU SP (I) BP \ Fi+1 . Since GU SP (I) unfounded set Prespect Theorem 2, Definition 1 that, GU SP (I)rule r P H(r) = , either (1) (antimonotone) literalB (r) false respect I, (2) (monotone) literal B (r) falserespect .GU SP (I). want show belong Fi+1 ,is, rule r either (i) (antimonotone) literalB (r) false respect I, (ii) (monotone) literal B (r) truerespect Fi \ .I (recall Fi+1 = (Fi ) definition). Since (1) (i)equals, show (2) implies (ii). end, assume(monotone) literal B (r) false respect .GU SP (I).aim show false respect J = (Fi \ .I ) .(BP \ (Fi \ .I )),since case would true respect Fi \ .I (see Lemma 18).start proving (I .GU SP (I)) = .GU SP (I) subset J .Observe J = .(BP \ (Fi \ .I )) = .(BP \ Fi ) .Isubset BP . Thus, since GU SP (I) BP \ Fi induction hypothesis, obtain(I .GU SP (I)) = .GU SP (I) .(BP \ Fi ) = J . Since J total,(I .GU SP (I)) J implies extension K .GU SP (I)K J K + J (for example, one containing truestandard positive literals undefined respect .GU SP (I)). Sincefalse respect .GU SP (I) assumption K extension.GU SP (I), false respect K Remark 1. Thus, since J Kmonotone, latter implies false respect J well.() prove BP \ () unfounded set P respect I, is,r P H(r) BP \ (), either (1) (antimonotone) literal B (r)false respect I, (2) (monotone) literal B (r) false respect.(BP \ ()). Definition 7, H(r) 6 () implies either (i)(antimonotone) literal B (r) false respect I, (ii) (monotone)literal B (r) true respect () \ .I . Since (i) (1) equals,show (ii) implies (2). end, assume (monotone)literal B (r) true respect () \ .I . Thus,extension () \ .I false, particular must falserespect J = (I () \ .I ) .(BP \ (I () \ .I )) Lemma 18.observe (I .(BP \ ())) = .(BP \I ()) = .(BP \(I ()\.I )) =511fiAlviano, Calimeri, Faber, Leone, & PerriJ holds (because .I BP ), (I .(BP \ ()))+ J + J total.combining last two sentences obtain .(BP \ ()) J. Therefore,since monotone literal false respect J, latter impliesfalse respect .(BP \ ()) well, (2) holds.Eventually, Property 5 consequence following theorem. mentioned earlier,theorem also follows Theorem 7.4 work Pelov et al. (2007)Corollary 25, proof provided differs considerably one Theorem 7.4work Pelov et al.Theorem 21 Given LPAm,a program P:1. greatest unfounded set GU SP (I) P respect given interpretationpolynomial-time computable;2. WP () polynomial-time computable.Proof. (1.) Theorem 20, GU SP (I) = BP \ (). next show ()efficiently computable. fixpoint () limit sequence 0 = , k =(k1 ). limit reached polynomial number applicationsnew element sequence k must add least new atom (otherwise limitalready reached), is, |BP |. show application feasiblepolynomial time, conclude computable polynomial time. stepprocesses rules once, rule checks truth-valuebody literals once. check truth valuation clearly tractable standard(i.e., non-aggregates) literals; tractability check aggregate literals stemsProposition 19, deal monotone antimonotone aggregate atoms only.conclusion, computable polynomial time, GU SP (I) tractable well sinceobtainable BP \ ().(2.) argumentation carried (), show WP () computednumber steps polynomial (actually linear) |BP |. Indeed, steppolynomial-time computable: proved tractability GU SP (I), TPpolynomial-time computable well.result positive impact also computation answer set semanticslogic programs aggregates. Indeed, stated Theorem 16, WP () approximatesintersection answer sets (if any) bottom, therefore usedefficiently prune search space. worthwhile noting computationwell-founded semantics also hard polynomial-time. particular, deciding whether(ground) atom true respect well-founded semantics P-complete,task P-hard even standard well-founded semantics aggregate-free programs (and,Proposition 5, semantics coincides standard well-founded aggregatefree programs).end section briefly addressing complexity non-ground programs.considering data-complexity (i.e., LPAm,a program P fixed input consistsfacts), results propositional programs: Deciding whether (ground) atomtrue respect well-founded semantics non-ground program P-complete,512fiUnfounded Sets Well-Founded Semantics ASP Programs Aggregatesdata-complexity (Van Gelder et al., 1991). However, program complexity (i.e.,LPAm,a program P given input) considered, complexity reasoning rises exponentially. Indeed, non-ground program P reduced, naive instantiation, groundinstance problem, general size Ground(P) single exponentialsize P. complexity reasoning increases accordingly one exponential, PEXPTIME, result derived using complexity upgrading techniques (Eiter,Gottlob, & Mannila, 1997; Gottlob, Leone, & Veith, 1999).6. Compilation Standard LP, Implementation ExperimentalResultswell-founded semantics LPAm,a programs implemented extendingDLV system (Leone et al., 2006). section briefly describe implementedprototype report results experiments aimed assessing efficiency.Note that, even LPAm,a programs replaced equivalent LP programs (forrewriting strategy see Section 6.1 below), experimental results highlight significantperformance advantage LPAm,a encodings.6.1 Compilation Standard Logic Programmingsection briefly present strategy representing #count, #sum #timesstandard constructs.2 compilation spirit one introduced #min#max Alviano, Faber, Leone (2008) defines subprogram computingvalue (possibly recursive) aggregate. compilation takes account specific properties monotone antimonotone aggregate functions, therefore referredmonotone/antimonotone encoding (mae).monotone/antimonotone encoding LPAm,a program P obtained replacingaggregate literal = f (S) new predicate symbol f . Predicate f definedmeans subprogram (i.e., set rules) thought compilationstandard LP. compilation uses total order < elements {},symbol occurring P < u u . assumepresence built-in relation < , = Y1 , . . . , Yn = Y1 , . . . , Ynlists terms. built-in relation < precedeslexicographical order induced <. Moreover, use built-in relation ,true either < = . simplicity, let us assumeform f ({Y : p(Y , Z)}) k, Z lists local variables kinteger constant. aggregate, introduce new predicate symbol faux arity|Y | + 1 rules modeling atom faux (y, s) must true whenever valuef ({Y : p(Y , Z), y}) least s. Thus, use fact representing valueaggregate function empty set, rule increasing value larger sets.lexicographical order induced < used guarantee elements set2. Since considering monotone antimonotone aggregate literals, domains #sum#times assumed N N+ , respectively.513fiAlviano, Calimeri, Faber, Leone, & PerriUser InterfaceDiagnosisFrontendInheritanceFrontendSQL3FrontendPlanningFrontendDLV coreGroundProgramIntelligentGroundingModelCheckerModelGeneratorFileSystemRelationalDatabaseFilteringOutputFigure 2: Prototype system architecture.considered once. particular, following rules introduced:faux (, ).= 0, = + 1 f = #count;= 0, = + Y1 f = #sum;faux (Y , X) : faux (Y , S), p(Y , Z),= 1, = Y1 f = #times.< , X = .{, >}, truth aggregate f ({Y : p(Y , Z)}) k must inferredatom faux (y, s) k true. aspect modeled meansfollowing rules:fk : faux (Y , S), k.f>k : faux (Y , S), > k., instead, truth aggregate f ({Y : p(Y , Z)}) k must inferredatoms faux (y, s) > k false (and similar <). aspectsmodeled means following rules:fk : f>k .f<k : fk .Extending technique aggregate literals global variables quite simple:Global variables added arguments atoms used compilation,new predicate fgroupby used collecting possible substitutions.6.2 System Architecture Usageextended DLV implementing well-founded operator well-foundedsemantics LPAm,a programs described paper. architecture prototype514fiUnfounded Sets Well-Founded Semantics ASP Programs Aggregatesreported Figure 2. detail, modified two modules DLV, Intelligent Groundingmodule Model Generator module. prototype, well-founded semanticsadopted one -wf --well-founded specified command-line. Otherwise,stable model semantics adopted usual. well-founded operator WP introducedSection 3 used semantics. particular, stable model semantics,well-founded model profitably used pruning search space. well-foundedsemantics, well-founded model printed computation least fixpointwell-founded operator. case output system consists two sets,representing true undefined standard atoms well-founded model. binaryprototype available http://www.dlvsystem.com/dlvRecAggr/.6.3 Experimental Resultsknowledge, implemented prototype currently system supportingwell-founded semantics logic programs recursive aggregates. certain specialcases, well-founded model total, well-founded model coincidessemantics answer sets (see Corollary 17) theses cases systems supportingsemantics IDP (Wittocx, Marien, & Denecker, 2008), Smodels (Simons et al.,2002), clasp (Gebser, Kaufmann, Neumann, & Schaub, 2007), used computewell-founded model.however interested systems able compute well-founded modelinput programs. One major systems supporting well-founded semantics,XSB (Swift & Warren, 2010), support aggregates, (apart #min#max) XSB support recursive aggregates (i.e., aggregates occurring recursivedefinitions). Therefore, experiments designed investigating computational behavior aggregate constructs respect equivalent encodings withoutaggregates.specifically, introduce Attacks problem, inspired classicWin-Lose problem often used context well-founded semantics standardlogic programs, study performance it.Definition 8 (Attacks Problem) Attacks problem, set p players positive integer given. player attacks n players. player winswinners attack it. kind problem frequently present turn-based strategygames.Note definition winner recursive and, particular, recursive aggregatenatural way encoding problem.Example 14 instance Attacks problem p = 6, n = 2 = 1 couldfollowing:player attacks players b c;player attacks players b f ;player b attacks players c;player e attacks players c f ;player c attacks players b;player f attacks players e.515fiAlviano, Calimeri, Faber, Leone, & PerribfecFigure 3: instance Attacks problem 6 players, one attacking 2players.graphical representation instance shown Figure 3. Since attackedf , conclude winner. Similarly e. Therefore, f winnerf attacked e, winners. players, namely a, b c,cannot determine winner not.experiments, instances Attacks encoded means predicates max,player attacks representing parameter m, set players attacksplayers, respectively. consider three equivalent encodings Attacks problem.6.3.1 Aggregate-Based Encodingencoding natural representation Attacks problem LPm,a . completeencoding consists single rule, reported below:win(X) : max(M ), player(X), #count{Y : attacks(Y, X), win(Y )} M.6.3.2 Join-Based Encodingequivalent encoding obtained computing number joins proportionalm. tested encoding reported below:win(X) : player(X), lose(X).lose(X) : max(1), attacks(Y1 , X), win(Y1 ),attacks(Y2 , X), win(Y2 ), Y1 < Y2 .lose(X) : max(2), attacks(Y1 , X), win(Y1 ),attacks(Y2 , X), win(Y2 ), Y1 < Y2 ,attacks(Y3 , X), win(Y3 ), Y1 < Y3 , Y2 < Y3 .lose(X) : max(3), . . .Note encoding rule possible value parameter m.However, one rules considered solver program instantiation.fact, rule instantiated, contains instance atom max(m)fact present. rules satisfied false body literal.516fiUnfounded Sets Well-Founded Semantics ASP Programs Aggregates30300DLV-joinDLV2525020200151501010050123456x789 1234567891050012346x(a) 100 players789 1234568910(b) 200 players60060050050040040030030020020010001572345x6789 1234567891010001234x(c) 400 players56789 12345678910(d) 800 playersFigure 4: Attacks: Average execution time DLV running aggregate-based encodingDLV running join-based encoding.6.3.3 Mae-Based Encodingencoding obtained applying compilation presented Section 6.1minor simplifications. full encoding reported below:win(X) : player(X), lose(X).lose(X) : count(X, Y, S), max(M ), > M.count(X, Y, 1) : aux(X, ).count(X, , ) : count(X, Y, S), aux(X, ), < , = + 1.aux(X, ) : attacks(Y, X), win(Y ).Intuitively, atom count(x, y, s) stands least constantsattacks(y , x), win(y ) true. Note rules defining predicate count usenatural order integers guarantee counted once.Example 15 instance shown Figure 3 represented means following facts:player(a).attacks(a, b).attacks(a, c).max(1).player(b).attacks(b, a).attacks(b, c).player(c).attacks(c, a).attacks(c, b).player(d).attacks(d, b).attacks(d, f ).517player(e).attacks(e, c).attacks(e, f ).player(f ).attacks(f, d).attacks(f, e).fiAlviano, Calimeri, Faber, Leone, & Perri810XSB-joinDLV769875645343210123456x789 1234567891021012346x(e) 100 players789 1234568910(f) 200 players9128107685643421015723456x789 12345678910201234x(g) 400 players56789 12345678910(h) 800 playersFigure 5: Attacks: Average execution time DLV running aggregate-based encodingXSB running join-based encoding.encodings, well-founded model restricted win predicate {win(d),win(e), win(f )}. Note win(a), win(b) win(c) neither true false,undefined.6.3.4 Discussionperformed intensive experimentation benchmark varying parametersp, n. combination parameters, measured average executiontime DLV XSB (version 3.2) 3 randomly generated instances. experimentsRRperformed 3GHz IntelXeonprocessor system 4GB RAMDebian 4.0 operating system GNU/Linux 2.6.23 kernel. DLV prototype usedcompiled GCC 4.4.1. every instance, allowed maximum runningtime 600 seconds (10 minutes) maximum memory usage 3GB.results experimentation reported Figures 47. graphs, DLVimplemented prototype aggregate-based encoding, DLV-join DLV-maeimplemented prototype aggregate-free encodings, XSB-join XSB-maeXSB system aggregate-free encodings (as mentioned earlier, XSB support518fiUnfounded Sets Well-Founded Semantics ASP Programs AggregatesDLV-maeDLV61251048362410123456x789 1234567891020123456x(i) 1600 players789 12345678910(j) 3200 players256050204015301020501234x56789 123456789101001234x(k) 6400 players56789 12345678910(l) 12800 playersFigure 6: Attacks: Average execution time DLV running aggregate-based encodingDLV running mae-based encoding.recursive aggregates). XSB system, explicitly set indices tabled predicatesoptimizing computation.graph, number players fixed, parameters (x-axis) n(y-axis) vary. Therefore, size instances grows moving left right alongy-axis, invariant respect x-axis. However, number joinsrequired join-based encoding depends parameter m. matter fact,observe graphs Figures 45 average execution time join-basedencoding increases along x- y-axis (for DLV XSB). Instead,encoding using aggregates, mae-based encoding, average execution timedepends instance sizes, shown graphs Figures 67.join-based encoding, XSB generally faster DLV, consumes muchmemory. Indeed, Figure 5, observe XSB terminates computationseconds smallest instances, rapidly runs memory slightly largerinstances. Considering mae-based encoding, observe significant performancegains DLV XSB (see Figures 67). Indeed, systems complete computation allowed time memory larger instances. Computational advantagesmae-based encoding respect join-based encoding particularly evident519fiAlviano, Calimeri, Faber, Leone, & PerriXSB-maeDLV3.598372.56251.54310.50123456x789 12345678921010123456x(m) 6400 players789 12345678910(n) 12800 players60400350503004025030200150201001234x56789 123456789100105001234x(o) 25600 players56789 12345678910(p) 51200 playersFigure 7: Attacks: Average execution time DLV running aggregate-based encodingXSB running mae-based encoding.XSB, solved tested instances encoding. However, also XSBmae-based encoding outperformed DLV native support aggregate constructs(see Figure 7).sum, experimental results highlight presence aggregate constructssignificantly speed-up computation. Indeed, encoding using recursive aggregatesoutperforms aggregate-free encodings tested instances.7. Related WorkDefining well-founded semantics logic programs aggregates challengemajor interest last years. first attempts, relying notion unfoundedset, defined restricted language. discussed KempStuckey (1991). Another semantics falling class one introduced Van Gelder(1992), subsequently generalized Osorio Jayaraman (1999). main problemsemantics often leave many undefined literals, shown RossSagiv (1997).520fiUnfounded Sets Well-Founded Semantics ASP Programs Aggregatesfirst attempt define well-founded semantics unrestricted LPA doneKemp Stuckey (1991). semantics based notion unfounded sets. AccordingKemp Stuckey, set X standard atoms unfounded set (ground) programP respect interpretation if, rule r P H(r) X , either (a)literal B(r) false respect I, (b) B(r) X =6 . Note standardliterals considered condition (b), aggregates covered it. pointdefinition unfounded set makes semantics inadequate programsrecursive aggregates, even monotone aggregates considered. example,program {a(1):#count{X : a(X)} > 0.}, well-founded model work KempStuckey , reasonable well-founded semantics identify a(1) false.Pelov et al. (2007) defined well-founded semantics based approximating operators,namely D-well-founded semantics, extends standard well-founded semantics; indeed, coincide aggregate-free programs. detail, work aggregatesevaluated one three possible ways. Therefore, family semantics definedPelov et al., ordered precision: precise three-valued aggregates leadprecise semantics. general, higher precision comes price higher computational complexity. authors discuss following three-valued aggregate relationsevaluation aggregate literals: trivial, bound ultimate approximating aggregates, first less precise, last precise. Semantics relyingtrivial approximating aggregates imprecise, still suitable classstratified aggregate programs. trivial bound approximations polynomialcomplexity, ultimate shown intractable nonmonotone aggregatefunctions (Pelov, 2004). detailed comparison results presented Section 7.1.Ferraris (2005) showed semantics Smodels programs positive weightconstraints equal answer sets defined Faber et al. (2004) respectivefragment. Since Theorem 16 WP () approximates answer sets defined Faber et al.,WP () used also approximating operator respective Smodels programs.Indeed, shown AtMost pruning operator Smodels (Simons et al., 2002)special case operator (defined proof Theorem 21).works attempted define stronger notions well-founded semantics (alsoprograms aggregates), like Ultimate Well-Founded Semantics (Denecker et al.,2001), WFS1 WFS2 (Dix & Osorio, 1997). Whether characterizationsemantics terms unfounded sets exist semantics unclear leftfuture research.Concerning compilations LP programs standard LP, transformation provided Van Gelder (1992). compilation presented Section 6.1 differsone introduced Van Gelder several respects. approach uses total orderuniverse input program takes advantage character monotonicity/antimonotonicity aggregate literals input program, transformationdefined Van Gelder uses uninterpreted function symbols representing ground sets,recursive negation checking truth aggregate literals. briefly discuss aspects following. Roughly, aggregate f (S) k, uninterpreted function symbolsused transformation work Van Gelder determining pairs , kground set associated k = f (S ). that, transformation defined Van Gelder checks whether exists pair , k satisfying following521fiAlviano, Calimeri, Faber, Leone, & Perriconditions: (i) every element hconsts : conji , conj true; (ii) k k holds.point Condition (i) requires recursive negation order checked. Indeed,equivalent element hconsts : conji conj true.aspect transformation undesirable side effect: Stratified LPAm,a programsmay partial well-founded models, is, Theorem 9 hold programs compiled transformation introduced Van Gelder. example side effectgiven Van Gelder, shown transformation possibly leads partialwell-founded models instances Company Controls, well-known problemmodeled using monotone recursive aggregates.7.1 Comparison work Pelov et al. (2007)section report detailed comparison well-founded semantics definedpaper one Pelov et al. (2007). recall Pelov et al. defines wellfounded stable semantics least total fixpoints three-valued stablemodel operator extended aggregate programs.start observing evaluation ultimate approximating aggregates coincidesevaluation aggregates defined article; also evaluation bound approximating aggregates coincides monotone antimonotone aggregates (as consequenceLemma 18 paper Proposition 7.16 work Pelov et al., 2007).Let us introduce translation aggregate literal formula standardliterals. (partial) interpretation I, let conj(I) denote conjunction literalsI. translation trm(A) ground aggregate literal defined follows:Wtrm(A) = {conj(I) | subset-minimal interpretationtrue respect I}Note that, (partial) interpretation J, evaluation respect J coincidesevaluation trm(A) respect J (Proposition 2 Proposition 3work Pelov et al., 2003). Moreover, monotone (resp. antimonotone) aggregate literalA, positive (resp. negative) literals appear trm(A).rule r ground LPAm,a program P aggregate literal B(r),translation trm(P, r, A) r program obtained P removing radding rule r H(r ) = H(r) B(r ) = B(r) \ {A} conj,conj trm(A). Therefore, full translation trm(P) P defined recursiveapplication trm(P, r, A) (note order rules aggregates processedrelevant). next show P trm(P) unfounded sets.Lemma 22 set atoms X unfounded set program P respectinterpretation X unfounded set trm(P) respect I.Proof. use induction number aggregate literals P. P aggregateliterals, P = trm(P). consider program P rule r P aggregateliteral B(r). want show set X atoms unfounded set Prespect X unfounded set trm(P, r, A) respect I, sincecase might apply induction hypothesis prove claim. Thus,end proof means following observations: (i) false respect522fiUnfounded Sets Well-Founded Semantics ASP Programs Aggregatesinterpretation J trm(A) false respect J, is,conjunction conj trm(A) literal conj false respectJ; (ii) positive (resp. negative) standard literal monotone(resp. antimonotone).prove well-founded operators P trm(P) coincide.Lemma 23 Let P LPAm,a program interpretation P. WP (I) =Wtrm(P) (I).Proof. show (1) TP (I) = Ttrm(P) (I) (2) GU SP (I) = GU Strm(P) (I).note (2) immediately follows Lemma 22. order prove (1), consideraggregate literal occurring P. previous considerations, truerespect conjunct trm(A) true respectI. Thus, (1) holds.ready relate well-founded operator one provided Pelovet al. (2007).Theorem 24 class LPAm,a programs, well-founded operator herein definedcoincides one Pelov et al. (2007; ultimate bound approximatingaggregate semantics).3Proof. Lemma 23, already know WP (I) = Wtrm(P) (I). alsoWtrm(P) (I) coincides one work Van Gelder et al. (1991) Theorem 1(since trm(P) standard logic program). hand, ultimatebound approximating aggregate semantics, well-founded operators (as defined Pelovet al., 2007) P trm(P) coincide: consequence Theorem 1 workPelov et al. (2003), three-valued immediate consequence operators workPelov et al. (2003) Pelov et al. (2007) coincide (see Definition 7 Pelov et al., 2003Definition 7.5 Pelov et al., 2007). Moreover, well-founded operator Pelov et al.(2007) coincides one work Van Gelder et al. standard logic programs,thereby obtaining equality operators.correspondence two well-founded semantics immediately followstheorem above. Indeed, two well-founded models defined fixpointsrespective well-founded operators.Corollary 25 well-founded model herein defined one Pelov et al. (2007;ultimate bound approximating aggregate semantics) coincide LPAm,aprograms.mentioned also earlier, virtue theorem corollary,results presented paper also follow earlier results literature. particular,Theorem 9, Theorem 16 complexity results follow definitionsresults Pelov (2004) Pelov et al. (2007).3. Note operator referred stable revision operator Pelov et al. (2007).523fiAlviano, Calimeri, Faber, Leone, & Perri8. Conclusionpaper introduced new notion unfounded set LPAm,a programs analyzedwell-founded semantics language based notion. semantics generalizestraditional well-founded semantics aggregate-free programs also coincideswell-founded semantics aggregate programs defined Pelov et al. (2007; latterdefined means notion unfounded set). could also showsemantics main operator WP close ties answer sets defined Faberet al. (2004, 2011), hence serve approximations.proved computing semantics tractable problem. Indeed, semanticsgiven least fixpoint well-founded operator WP . fixpoint reachedpolynomial number applications operator WP (with respect size inputprogram), requiring polynomial time. showing application WPpolynomial-time feasible, proved evaluating monotone antimonotoneaggregate literals remains polynomial-time computable also partial interpretations, sincecase one possibly exponential extensions must checked. monotoneaggregate literal, extension obtained falsifying undefined literal,antimonotone aggregate literal, undefined literal taken true extension.Motivated positive theoretical results, implemented first systemsupporting well-founded semantics unrestricted LPAm,a . Allowing using monotoneantimonotone aggregate literals, implemented prototype ready experimentingLPAm,a framework. experiments conducted Attacks benchmark highlightcomputational gains native implementation aggregate constructs respectequivalent encodings standard LP.AcknowledgmentsPartly supported Regione Calabria EU POR Calabria FESR 2007-2013 withinPIA project DLVSYSTEM s.r.l., MIUR PRIN project LoDeNPON project FRAME proposed Atos Italia S.p.a.; also thankanonymous reviewers valuable comments.ReferencesAlviano, M., Faber, W., & Leone, N. (2008). Compiling minimum maximum aggregatesstandard ASP. Formisano, A. (Ed.), Proceedings 23rd Italian ConferenceComputational Logic (CILC 2008).Baral, C. (2003). Knowledge Representation, Reasoning Declarative Problem Solving.Cambridge University Press.Brewka, G. (1996). Well-Founded Semantics Extended Logic Programs DynamicPreferences. Journal Artificial Intelligence Research, 4, 1936.Calimeri, F., Faber, W., Leone, N., & Perri, S. (2005). Declarative ComputationalProperties Logic Programs Aggregates. Nineteenth International JointConference Artificial Intelligence (IJCAI-05), pp. 406411.524fiUnfounded Sets Well-Founded Semantics ASP Programs AggregatesDellArmi, T., Faber, W., Ielpa, G., Leone, N., & Pfeifer, G. (2003). Aggregate FunctionsDLV. de Vos, M., & Provetti, A. (Eds.), Proceedings ASP03 - Answer SetProgramming: Advances Theory Implementation, pp. 274288, Messina, Italy.Online http://CEUR-WS.org/Vol-78/.Denecker, M., Pelov, N., & Bruynooghe, M. (2001). Ultimate Well-Founded StableModel Semantics Logic Programs Aggregates. Codognet, P. (Ed.), Proceedings 17th International Conference Logic Programming, pp. 212226.Springer Verlag.Dix, J., & Osorio, M. (1997). Well-Behaved Semantics Suitable Aggregation.Proceedings International Logic Programming Symposium (ILPS 97), Port Jefferson, N.Y.Eiter, T., Gottlob, G., & Mannila, H. (1997). Disjunctive Datalog. ACM TransactionsDatabase Systems, 22 (3), 364418.Faber, W. (2005). Unfounded Sets Disjunctive Logic Programs Arbitrary Aggregates. Baral, C., Greco, G., Leone, N., & Terracina, G. (Eds.), Logic Programming Nonmonotonic Reasoning 8th International Conference, LPNMR05,Diamante, Italy, September 2005, Proceedings, Vol. 3662 Lecture Notes Computer Science, pp. 4052. Springer Verlag.Faber, W., Leone, N., & Pfeifer, G. (2004). Recursive aggregates disjunctive logic programs: Semantics complexity. Alferes, J. J., & Leite, J. (Eds.), Proceedings9th European Conference Artificial Intelligence (JELIA 2004), Vol. 3229Lecture Notes AI (LNAI), pp. 200212. Springer Verlag.Faber, W., Leone, N., & Pfeifer, G. (2011). Semantics complexity recursive aggregatesanswer set programming. Artificial Intelligence, 175 (1), 278298. Special Issue:John McCarthys Legacy.Ferraris, P. (2005). Answer Sets Propositional Theories. Baral, C., Greco, G., Leone,N., & Terracina, G. (Eds.), Logic Programming Nonmonotonic Reasoning 8thInternational Conference, LPNMR05, Diamante, Italy, September 2005, Proceedings,Vol. 3662 Lecture Notes Computer Science, pp. 119131. Springer Verlag.Ferraris, P. (2011). Logic programs propositional connectives aggregates. ACMTransactions Computational Logic, 12 (4). press.Gebser, M., Kaufmann, B., Neumann, A., & Schaub, T. (2007). Conflict-driven answerset solving. Twentieth International Joint Conference Artificial Intelligence(IJCAI-07), pp. 386392. Morgan Kaufmann Publishers.Gelfond, M. (2002). Representing Knowledge A-Prolog. Kakas, A. C., & Sadri, F.(Eds.), Computational Logic. Logic Programming Beyond, Vol. 2408 LNCS, pp.413451. Springer.Gelfond, M., & Lifschitz, V. (1991). Classical Negation Logic Programs DisjunctiveDatabases. New Generation Computing, 9, 365385.Gottlob, G., Leone, N., & Veith, H. (1999). Succinctness Source Expression Complexity. Annals Pure Applied Logic, 97 (13), 231260.Kemp, D. B., & Stuckey, P. J. (1991). Semantics Logic Programs Aggregates.Saraswat, V. A., & Ueda, K. (Eds.), Proceedings International SymposiumLogic Programming (ISLP91), pp. 387401. MIT Press.525fiAlviano, Calimeri, Faber, Leone, & PerriLeone, N., Pfeifer, G., Faber, W., Eiter, T., Gottlob, G., Perri, S., & Scarcello, F. (2006).DLV System Knowledge Representation Reasoning. ACM TransactionsComputational Logic, 7 (3), 499562.Liu, L., Pontelli, E., Son, T. C., & Truszczynski, M. (2010). Logic programs abstractconstraint atoms: role computations. Artificial Intelligence, 174 (34), 295315.Liu, L., & Truszczynski, M. (2006). Properties applications programs monotoneconvex constraints. Journal Artificial Intelligence Research, 27, 299334.Manna, M., Ruffolo, M., Oro, E., Alviano, M., & Leone, N. (2011). HiLeX SystemSemantic Information Extraction. Transactions Large-Scale Data KnowledgeCentered Systems. Springer Berlin/Heidelberg, appear.Manna, M., Ricca, F., & Terracina, G. (2011). Consistent Query Answering via ASPDifferent Perspectives: Theory Practice. Theory Practice Logic Programming, appear.Marek, V. W., & Truszczynski, M. (2004). Logic programs abstract constraint atoms.Proceedings Nineteenth National Conference Artificial Intelligence (AAAI2004), pp. 8691. AAAI Press / MIT Press.McCarthy, J. (1959). Programs Common Sense. Proceedings TeddingtonConference Mechanization Thought Processes, pp. 7591. MajestysStationery Office.McCarthy, J. (1980). Circumscription Form Non-Monotonic Reasoning. ArtificialIntelligence, 13 (12), 2739.McCarthy, J. (1986). Applications Circumscription Formalizing Common-SenseKnowledge. Artificial Intelligence, 28 (1), 89116.McCarthy, J. (1990). Formalization Common Sense, papers John McCarthy editedV. Lifschitz. Ablex.McCarthy, J., & Hayes, P. J. (1969). Philosophical Problems StandpointArtificial Intelligence. Meltzer, B., & Michie, D. (Eds.), Machine Intelligence 4,pp. 463502. Edinburgh University Press. reprinted (McCarthy, 1990).McDermott, D. V. (1982). Non-Monotonic Logic II: Nonmonotonic Modal Theories. JournalACM, 29 (1), 3357.McDermott, D. V., & Doyle, J. (1980). Non-Monotonic Logic I. Artificial Intelligence,13 (12), 4172.Minsky, M. (1975). Framework Representing Knowledge. Winston, P. H. (Ed.),Psychology Computer Vision, pp. 211277. McGraw-Hill.Moore, R. C. (1985). Semantical Considerations Nonmonotonic Logic. Artificial Intelligence, 25 (1), 7594.Osorio, M., & Jayaraman, B. (1999). Aggregation Negation-As-Failure. New GenerationComputing, 17 (3), 255284.Pelov, N. (2004). Semantics Logic Programs Aggregates. Ph.D. thesis, KatholiekeUniversiteit Leuven, Leuven, Belgium.Pelov, N., Denecker, M., & Bruynooghe, M. (2003). Translation Aggregate ProgramsNormal Logic Programs. de Vos, M., & Provetti, A. (Eds.), Proceedings ASP03- Answer Set Programming: Advances Theory Implementation, pp. 2942,Messina, Italy. Online http://CEUR-WS.org/Vol-78/.526fiUnfounded Sets Well-Founded Semantics ASP Programs AggregatesPelov, N., Denecker, M., & Bruynooghe, M. (2004). Partial stable models logic programs aggregates. Proceedings 7th International Conference LogicProgramming Non-Monotonic Reasoning (LPNMR-7), Vol. 2923 Lecture NotesAI (LNAI), pp. 207219. Springer.Pelov, N., Denecker, M., & Bruynooghe, M. (2007). Well-founded Stable SemanticsLogic Programs Aggregates. Theory Practice Logic Programming, 7 (3),301353.Pelov, N., & Truszczynski, M. (2004). Semantics disjunctive programs monotoneaggregates - operator-based approach. Proceedings 10th InternationalWorkshop Non-monotonic Reasoning (NMR 2004), Whistler, BC, Canada, pp.327334.Reiter, R. (1980). Logic Default Reasoning. Artificial Intelligence, 13 (12), 81132.Ricca, F., Alviano, M., Dimasi, A., Grasso, G., Ielpa, S. M., Iiritano, S., Manna, M., &Leone, N. (2010). Logic-Based System e-Tourism. Fundamenta Informaticae.IOS Press, 105 (12), 3555.Ricca, F., Grasso, G., Alviano, M., Manna, M., Lio, V., Iiritano, S., & Leone, N. (2011).Team-building Answer Set Programming Gioia-Tauro Seaport. TheoryPractice Logic Programming. Cambridge University Press, appear.Ross, K. A., & Sagiv, Y. (1997). Monotonic Aggregation Deductive Databases. JournalComputer System Sciences, 54 (1), 7997.Simons, P., Niemela, I., & Soininen, T. (2002). Extending Implementing StableModel Semantics. Artificial Intelligence, 138, 181234.Son, T. C., & Pontelli, E. (2007). Constructive semantic characterization aggregatesanswer set programming. Theory Practice Logic Programming, 7, 355375.Son, T. C., Pontelli, E., & Tu, P. H. (2007). Answer Sets Logic Programs ArbitraryAbstract Constraint Atoms. Journal Artificial Intelligence Research, 29, 353389.Swift, T., & Warren, D. S. (2010). XSB: Extending prolog tabled logic programming.Computing Research Repository (CoRR), abs/1012.5123.Tarski, A. (1955). lattice-theoretical fixpoint theorem applications. Pacific J.Math, 5, 285309.Truszczynski, M. (2010). Reducts propositional theories, satisfiability relations,generalizations semantics logic programs. Artificial Intelligence, 174, 12851306.Ullman, J. D. (1989). Principles Database Knowledge Base Systems. ComputerScience Press.Van Gelder, A. (1992). Well-Founded Semantics Aggregation. ProceedingsEleventh Symposium Principles Database Systems (PODS92), pp. 127138.ACM Press.Van Gelder, A., Ross, K. A., & Schlipf, J. S. (1991). Well-Founded SemanticsGeneral Logic Programs. Journal ACM, 38 (3), 620650.Wittocx, J., Marien, M., & Denecker, M. (2008). IDP system: model expansionsystem extension classical logic. Denecker, M. (Ed.), Proceedings2nd Workshop Logic Search, Computation Structures DeclarativeDescriptions (LaSh08), pp. 153165.527fiJournal Artificial Intelligence Research 42 (2011) 1-29Submitted 11/10; published 09/11Hard Manipulation Problems?Toby Walshtoby.walsh@nicta.com.auNICTA UNSWSydneyAustraliaAbstractVoting simple mechanism combine together preferences multiple agents. Unfortunately, agents may try manipulate result mis-reporting preferences. One barriermight exist manipulation computational complexity. particular,shown NP-hard compute manipulate number different voting rules. However, NP-hardness bounds worst-case complexity. Recent theoretical results suggestmanipulation may often easy practice. paper, show empirical studiesuseful improving understanding issue. consider two settings representtwo types complexity results identified area: manipulation unweighted votes single agent, manipulation weighted votes coalition agents.first case, consider Single Transferable Voting (STV), second case, considerveto voting. STV one voting rules used practice NP-hard computesingle agent manipulate result votes unweighted. also appears oneharder voting rules manipulate since involves multiple rounds. hand, vetovoting one simplest representatives voting rules NP-hard computecoalition weighted agents manipulate result. experiments, sample numberdistributions votes including uniform, correlated real world elections. manyelections experiments, easy compute manipulate result provemanipulation impossible. Even able identify situation manipulation hard compute (e.g. votes highly correlated election hung),found computational difficulty computing manipulations somewhat precarious (e.g.hung elections, even single uncorrelated voter enough make manipulationeasy compute).1. IntroductionGibbard-Satterthwaite theorem proves that, weak assumptions like threecandidates absence dictator, voting rules manipulable (Gibbard, 1973; Satterthwaite, 1975). is, may pay agents report preferences truthfully. One appealingescape result proposed Bartholdi, Tovey Trick (1989). Whilst manipulationmay exist, perhaps computationally difficult find. illustrate idea, demonstrated second order Copeland rule NP-hard manipulate. Shortly after, BartholdiOrlin (1991) proved well known Single Transferable Voting (STV) rule NP-hardmanipulate. whole subfield social choice since grown proposal, studyingcomputational complexity manipulation control voting rules. Two good surveysrecently appeared provide many references literature (Faliszewski, Hemaspaandra, &Hemaspaandra, 2010; Faliszewski & Procaccia, 2010). Computational complexity resultsmanipulation voting rules typically vary along five different dimensions.Weighted unweighted votes: votes weighted unweighted? Although many elections involve unweighted votes, weighted votes used number real-world settings likeshareholder meetings, elected assemblies. Weights also useful multi-agent systemsdifferent types agents. Weights interesting computational perspective least two reasons. First, weights increase computational complexity.c2011AI Access Foundation. rights reserved.fiWalshexample, computing manipulate veto rule polynomial unweighted votesNP-hard weighted votes (Conitzer, Sandholm, & Lang, 2007). Second, weighted caseinforms us unweighted case probabilistic information votes.instance, NP-hard compute election manipulated weightedvotes, NP-hard compute probability candidate winninguncertainty unweighted votes cast (Conitzer & Sandholm, 2002a).Bounded unbounded number candidates: (small) fixed number candidates? number candidates allowed grow? example, unweighted votes,computing manipulation STV rule polynomial bound number candidates NP-hard number candidates allowed grow problem size(Bartholdi & Orlin, 1991). Indeed, unweighted votes bounded number candidates, polynomial compute manipulate voting rules (Conitzer et al., 2007).hand, weighted votes, NP-hard compute manipulate manyvoting rules bounded number candidates. example, NP-hard computemanipulation veto rule 3 candidates (Conitzer et al., 2007).One manipulator coalition manipulators: single agent trying manipulateresults coalition agents acting together? single agent unlikely able changeoutcome many elections. coalition, hand, may able manipulateresult. rules, like STV, NP-hard compute single agent needsvote manipulate result prove manipulation single agent impossible(Bartholdi & Orlin, 1991). rules like Borda, may require coalition twoagents manipulation NP-hard compute (Davies, Katsirelos, Narodytska, & Walsh,2011; Betzler, Niedermeier, & Woeginger, 2011). rules like veto, may requirecoalition manipulating agents whose size unbounded (and allowed growproblem size) manipulation NP-hard compute (Conitzer et al., 2007).Complete incomplete information: Many results assume manipulator(s) complete information agents votes. course, may know preciselyagents vote practice. However, several reasons case complete information interesting. First, show computationally intractablecompute manipulate election complete information also intractableincomplete information. Second, complete information case informs caseuncertainty. instance, computationally intractable coalitioncompute manipulate election complete information also intractableindividual compute manipulate election probabilisticinformation votes (Conitzer et al., 2007).Constructive destructive manipulation: manipulator trying make one particularcandidate win (constructive manipulation) prevent one particular candidate winning(destructive manipulation)? Destructive manipulation easier compute constructivemanipulation. instance, constructive manipulation veto rule coalition agentsweighted votes NP-hard destructive manipulation polynomial (Conitzer et al.,2007). However, also rules destructive constructive manipulationcomplexity class. example, constructive destructive manipulationplurality polynomial compute, whilst constructive destructive manipulationplurality runoff weighted votes NP-hard (Conitzer et al., 2007).Figure 1, give representative selection results complexity manipulatingvoting. References many results found work Conitzer et al. (2007).paper, focus two cases cover main types computational complexityresults identified: manipulation STV unweighted votes single agent2fiWhere Hard Manipulation Problems?number candidatespluralityBordavetoSTVplurality runoffCopelandunweighted votes,constructivemanipulationPNP-cPNP-cPNP-c2PPPPPPweighted votes,constructivedestructive3423PPPPNP-c NP-c PPNP-c NP-c PPNP-c NP-c PNP-cNP-c NP-c PNP-cPNP-c PPFigure 1: Computational complexity deciding various voting rules manipulatedagent (unweighted votes) coalition agents (weighted votes). P meansproblem polynomial, NP-c problem NP-complete. example, constructive manipulation veto rule polynomial unweighted votes weightedvotes 2 candidates, NP-hard 3 candidates. hand, destructive manipulation veto rule polynomial weighted votes coalitionmanipulating agents 2 candidates.unbounded number candidates election, manipulation veto votingweighted votes coalition agents 3 candidates election. cases,assume complete information votes agents. two cases thus cover casescomputational complexity associated: unweighted votes, small (bounded) numbermanipulators large (unbounded) number candidates; weighted votes, large (unbounded)number manipulators, small (bounded) number candidates.STV obvious interesting case consider study computational complexity manipulation. STV one voting rules used practice manipulationNP-hard compute votes unweighted. Bartholdi Orlin argued STV onepromising voting rules consider respect:STV apparently unique among voting schemes actual use today computationally resistant manipulation., (Bartholdi & Orlin, 1991, p. 341).STV also appears difficult manipulate many rules. example, Chamberlain(1985) studied four different measures manipulability voting rule: probabilitymanipulation possible, number candidates made win, coalition sizenecessary manipulate, margin-of-error still results successful manipulation.Compared commonly used rules like plurality Borda, results showed STVdifficult manipulate substantial margin. concluded that:[this] superior performance . . . combined rather complex implausible naturestrategies manipulate it, suggest [the STV rule] may quite resistantmanipulation, (Chamberlin, 1985, p. 203).second case considered paper (manipulation veto rule coalition manipulators three candidates) interesting study several reasons. First, veto rulesimple representative voting rules manipulation coalition agents weightedvotes small number candidates NP-hard compute. Second, veto rule easyreason about. Unlike STV, multiple rounds elimination candidatesworry about. fact, show, manipulation veto rule equivalent simple numberpartitioning problem. therefore use efficient number partitioning algorithms compute manipulations. Third, veto rule borderline tractability since constructive manipulation3fiWalshrule coalition weighted agents NP-hard destructive manipulation polynomial(since best way ensure candidate win simply veto candidate) (Conitzeret al., 2007).empirical study considers computational difficulty computing manipulations practice. NP-hardness results describe worst-case. increasing concern computational complexity results like may reflect actual difficulty computing manipulationspractice. instance, number recent theoretical results suggest manipulation mayoften computationally easy (Conitzer & Sandholm, 2006; Procaccia & Rosenschein, 2007b; Xia &Conitzer, 2008a; Friedgut, Kalai, & Nisan, 2008; Xia & Conitzer, 2008b). results demonstrateprofitably study issue empirically. several reasons empirical analysislike undertaken useful. First, theoretical analysis often asymptotic showsize hidden constants. addition, elections typically bounded size. sureasymptotic behaviour relevant finite sized electorates met practice? instance,results suggest easily compute manipulations almost type STV election100 candidates. Second, theoretical analysis often restricted particular distributions(e.g. independent identically distributed votes). Manipulation may different practicedue correlations votes. instance, preferences single-peaked votingrule selects median candidate manipulable. median voting rule,best interests agents state true preferences. thus clear correlationsvotes impact manipulability election. Indeed, number recentresults studied whether manipulation remains computationally hard votes limitedsingle-peaked (Walsh, 2007; Faliszewski, Hemaspaandra, Hemaspaandra, & Rothe, 2009; Brandt,Brill, Hemaspaandra, & Hemaspaandra, 2010). experiments therefore look electionscorrelations votes. Third, many theoretical resultscomputational complexity manipulation hard limited scope.instance, long standing open result recently settled, proving computing manipulationBorda rule coalition manipulators NP-hard (Davies et al., 2011; Betzler et al., 2011).However, proofs require precisely 2 manipulators. remains open computing manipulation Borda rule larger coalition NP-hard. empirical study may quickly suggestwhether result extends larger coalitions. Finally, empirical studies may suggest new avenuestheoretical study. example, experiments reported suggest simple universalform probability coalition agents veto election elect desired candidate.would interesting try derive form theoretically.2. Backgroundgive notation background used throughout rest paper. Letnumber candidates election. vote linear order (a transitive, antisymmetric,total relation) set candidates. Let n number agents voting. profilen-tuple votes. let N (i, j) number agents preferring j profile. votingrule function maps profile unique winning alternative. paper, considernumber common voting rules:Scoring rules: (w1 , . . . , wm ) vector weights, ith candidate total order scores wi ,winner candidate highest total score. plurality rule weight vector(1, 0, . . . , 0), veto rule vector (1, 1, . . . , 1, 0), whilst Borda rule vector(m 1, 2, . . . , 0). veto rule, voter effectively vetoes one candidatecandidate fewest vetoes wins.Single transferable vote (STV): STV proceeds number rounds. Unless one candidatemajority first place votes, eliminate candidate least number first4fiWhere Hard Manipulation Problems?place votes. ballots placing eliminated candidate first place re-assignedsecond place candidate. repeat one candidate majority.Copeland (aka tournament):P candidate highest Copeland score wins. Copelandscore candidate i6=j (N (i, j) > n2 ) (N (i, j) < n2 ). Copeland winner candidate wins pairwise elections. second order Copeland rule,tie, winner candidate whose defeated competitors largest sum Copelandscores.Maximin (aka Simpson): candidate highest maximin score wins. maximinscore candidate mini6=j N (i, j). Simpson winner candidate whose worstperformance pairwise elections best.rules easily modified work weighted votes. vote integer weight wviewed w agents vote identically. voting rules anonymous order votesprofile unimportant. profile therefore thought multi-set n votes. ensurewinner unique, sometimes need break ties (e.g. two candidatesnumber vetoes, two candidates number first place votes). UK,example, election tied, returning officer choose candidates usingrandom method like lots coin toss. typical assumption made literature (andpaper) ties broken favour manipulator. precisely, given choice severalcandidates, tie-break favour candidate preferred manipulator. Supposemanipulator make preferred candidate win assuming ties broken favourties fact broken random. conclude manipulator increasechance getting preferred result. would interesting consider tie-breaking rules.Indeed, tie-breaking even introduce computational complexity manipulation. example,computing manipulate Copeland rule weighted votes polynomial ties scored1 NP-hard scored 0 (Faliszewski, Hemaspaandra, & Schnoor, 2008).consider one agent coalition k agents trying manipulate result election.Manipulation situation manipulators vote differently true preferencesorder improve outcome perspective. common literature, assumemanipulators complete knowledge votes (and, appropriate, completeknowledge weights associated votes). Whilst may unrealistic practiceassume complete knowledge votes, several reasons caseinteresting consider. First, complete information likely special case uncertaintymodel. Hence, computational hardness results complete information directly imply hardnesscorresponding uncertainty model. Second, results hardness manipulationcoalition weighted votes complete information imply hardness manipulationindividual agent unweighted votes incomplete information (Conitzer et al., 2007). Third,assuming complete information, factor complexity coming uncertainty modelfocus instead computing manipulation.addition standard uniform random models votes, considertwo restricted types votes: single-peaked single-troughed votes. single-peaked votes,candidates placed line, agents preference candidate decreases distancesingle preferred candidate. Single-peaked preferences interesting severalperspectives. First, single-peaked preferences likely occur number domains.example, buying house, might optimal price mind preferencehouse decreases distance price increases. Second, single-peaked preferenceseasy elicit. Conitzer (2007, 2009) gives strategy eliciting single-peaked preferenceordering linear number pairwise ranking questions. Third, single-peaked preferences preventcertain problematic situations arising aggregating preferences. particular, preventexistence Condorcet cycles. fact, median candidate single-peaked profile beats5fiWalshothers pairwise comparisons (that is, median candidate Condorcet winner) (Black,1948). single-troughed votes, hand, candidates placed line,agents preference candidate increases distance single least preferred candidate.example, candidates locations build new incinerator, might leastpreferred location (your neighbourhood), preference increases awayincinerator this. Single-troughed votes similar nice properties single-peaked votes(Barbera, Berga, & Moreno, 2009).3. Single Transferable Votingbegin empirical study manipulation STV elections. STV used wide varietyreal-world settings including election Irish presidency, Australian House Representatives, Academy awards, many organisations including American Political ScienceAssociation, International Olympic Committee, British Labour Party. InterestinglyNP-hard compute single agent manipulate STV rule. Indeed, onevoting rules used practice manipulation NP-hard compute setting.precisely, STV NP-hard manipulate single agent number candidates unboundedvotes unweighted (Bartholdi & Orlin, 1991), coalition agents 3candidates votes weighted (Conitzer et al., 2007). Coleman Teague give enumerative method coalition k unweighted agents compute manipulation STV ruleruns O(m!(n + mk)) time n number agents voting numbercandidates (Coleman & Teague, 2007). single manipulator, Conitzer, Sandholm Langgive O(n1.62m ) time algorithm (called CSL on) compute set candidateswin STV election (Conitzer et al., 2007).Figure 2, give modified version CSL algorithm computing manipulationSTV rule. uses similar recursion CSL changes original algorithm severalways take advantage fact want compute one distinguished candidatewin need know candidates possibly win. two mainchanges CSL. First, ignore elections chosen candidate eliminated. Second,terminate search soon manipulation found chosen candidate wins.particular, need explore left branch search tree right branch givessuccessful manipulation.tested modified algorithm simplest possible scenario: electionsvote equally likely. one agent trying manipulate election candidatesn agents vote. Votes drawn uniformly random m! possible votes.Impartial Culture (IC) model. show benefits modifications CSL algorithm,ran simple experiment = n. experiment run CLISP 2.42 3.2 GHzPentium 4 3GB memory running Ubuntu 8.04.3. Table 1 gives mean nodes exploredruntime needed compute manipulation prove none exists. Median percentilesdisplay similar behaviour. see modified method considerably fasteroriginal CSL algorithm. addition, problems get larger, improvement increases. n = 32,method nearly 10 times faster CSL. increases roughly 40 times faster n = 128.improvements reduce time find manipulation largest problems severalhours couple minutes.3.1 Varying Number Agentsnext performed detailed experiments looking phase transition behaviour hard manipulation problems. many NP-hard problem domains, computationally hard instancesshown often associated region parameter spacerapid transition probability solution exists (Cheeseman, Kanefsky, & Taylor, 1991;6fiWhere Hard Manipulation Problems?Manipulate(c, R, (s1 , . . . , sm ), f )1 |R| = 1; one candidate left?2return (R = {c}); chosen candidate?3 f = 0; top manipulators vote currently free?45arg minjR (sj ); currently eliminated?6sd sd + w; Suppose manipulator votes7e arg minjR (sj )8= e; change result?9return10(c 6= d) Manipulate(c, R {d}, Transfer ((s1 , . . . , sm ), d, R), 0)11else return12((c 6= d) Manipulate(c, R {d}, Transfer ((s1 , . . . , sm ), d, R), 0))13((c 6= e) Manipulate(c, R {e}, Transfer ((s1 , . . . , sm ), e, R), d))14else; top manipulators vote fixed15arg minjR (sj ); eliminated?16c =; chosen candidate?17return f alse18= f; manipulator free change result?19return Manipulate(c, R {d}, Transfer ((s1 , . . . , sm ), d, R), 0)20else return Manipulate(c, R {d}, Transfer ((s1 , . . . , sm ), d, R), f )Figure 2: modified algorithm compute agent manipulate STV election.use integers 1 candidates, integers 1 n agents (with nmanipulator), c candidate manipulator wants win, R set un-eliminatedcandidates, sj weight agents ranking candidate j first amongst R, w weightmanipulator, f candidate highly ranked manipulator amongst R (or 0currently constraint highly ranked). function Transfer computesvector new weights agents ranking candidate j first amongst R given candidateeliminated. algorithm initially called R set every candidate, f 0.Mitchell, Selman, & Levesque, 1992). phase transition satisfiable unsatisfiable phase resembles seen statistical physics Ising magnets similar systems.several good surveys area (Dubois, Monasson, Selman, & Zecchina, 2001; Hartmann &Weigt, 2005; Gomes & Walsh, 2006).first experiment varied number agents voting. Figures 3 4, plotprobability manipulator make random agent win, cost computepossible fix number candidates vary number agents STV election.subsequent experiments, tested 1000 problems point. number candidatesagents voting varied powers 2, typically 20 (= 1) 27 (= 128) unless otherwiseindicated.ability agent manipulate election decreases number agents increases.votes candidates significant chance manipulatorable change result. Phase transition behaviour observed many NP-completeproblem domains including propositional satisfiability (Mitchell et al., 1992; Gent & Walsh, 1994,1996b), constraint satisfaction (Prosser, 1994; Smith, 1994; Gent, MacIntyre, Prosser, & Walsh, 1995;Gent, MacIntyre, Prosser, Smith, & Walsh, 2001), graph colouring (Walsh, 1998, 1999, 2001), numberpartitioning (Gent & Walsh, 1996a, 1998; Mertens, 2001) travelling salesperson problem(Zhang & Korf, 1996; Gent & Walsh, 1996c). Unlike domains, probability curve observed7fiWalshCSL algorithmnodestime/s1.460.003.280.0011.800.0059.050.03570.110.6314,676.1733.228,429,800.00 6,538.13n248163264128Modified algorithmnodestime/s1.240.001.590.003.700.0012.620.0155.200.09963.393.00159,221.10 176.68Table 1: Comparison original CSL algorithm modified version computesconstructive manipulation STV election. table gives mean nodes exploredruntime needed compute manipulation prove none exists. Medianpercentiles display similar behaviour. election n agents voting uniformly random n different candidates. Best results row bold.1m=4m=8m=16m=32m=64m=1280.9prob(manipulable)0.80.70.60.50.40.30.20.10110total number agents voting, n+1100Figure 3: Manipulability STV election containing random uniform votes. numbercandidates fixed vary number agents voting. vertical axis measuresprobability single manipulating agent make random candidate win.horizontal axis measures total number agents voting. Note n numberagents voting besides manipulator log scale used horizontalaxis.8fiWhere Hard Manipulation Problems?appear sharpen step function around fixed point. probability curveresembles smooth phase transitions seen polynomial problems like 2-colouring (Achlioptas,1999) 1-in-2 satisfiability (Walsh, 2002). indicated before, assume ties brokenfavour manipulator. reason, probability election manipulable greater1. Finding manipulation proving none possible easy unless large1e+06m=128m=64m=32m=16m=8m=4100000mean nodes100001000100101110100agents, nFigure 4: Search cost compute agent manipulate STV election containing randomuniform votes. number candidates, fixed vary number agents.vertical axis measures mean nodes explored compute single manipulatingagent make random candidate win. horizontal axis measures numberagents voting besides manipulator. Median percentiles similar.number agents large number candidates. However, situation, chancemanipulator change result small.3.2 Varying Number Candidatesnext experiment slices parameter space orthogonal direction, varying numbercandidates election. Figure 5, plot cost compute manipulator makerandom agent win STV election fix number agents vary numbercandidates. probability curve manipulator make random agent win resemblesFigure 3. Whilst cost computing manipulation appears increase exponentiallynumber candidates m, observed scaling much better 1.62m worst case scalingoriginal CSL algorithm. easily compute manipulations 128 candidates. Note1.62m 1026 = 128. Thus, appear far worst case. fittedobserved data function cdm found fit = 1.008 coefficient determinationR2 = 0.95 indicating good fit.3.3 Correlated Votesmany real life situations, votes completely uniform uncorrelated other.happens introduce correlation votes? consider random votes drawnPolya-Eggenberger urn model (Berg, 1985). model, urn containingm! possible votes. draw votes urn random, put back urn9fiWalsh1.62**mn=128n=64n=32n=16n=8n=41e+141e+12mean nodes1e+101e+081e+0610000100120406080100120candidates,Figure 5: Search cost compute agent manipulate STV election containing randomuniform votes. number agents, n fixed vary number candidates.vertical axis measures mean number nodes explored compute manipulationprove none exists. horizontal axis measures m, number candidateselection. Median percentiles similar.additional votes type (where parameter). increases, increasingcorrelation votes. generalises Impartial Culture model (a = 0)votes equally likely Impartial Anonymous Culture (a = 1) model profilesequally likely (McCabe-Dansted & Slinko, 2006). give parameter independent problemsize, consider b = m!. instance, b = 1, 50% chance second votefirst.Figures 6 7, plot probability manipulator make random agent winSTV election, cost compute possible vary number candidateselection votes drawn Polya-Eggenberger urn model. before, abilityagent manipulate election decreases number candidates, increases. searchcost compute manipulation appears increase exponentially number candidatesm. However, easily compute manipulations 128 candidates. fitted observeddata function cdm found fit = 1.001 coefficient determination R2 = 0.99indicating good fit.Figure 8, plot cost compute manipulation fix number candidatesvary number agents. before, ability agent manipulate election decreasesnumber agents increases. votes candidates chancemanipulator succeed. previous experiments, finding manipulation provingnone exists easy even many agents candidates. also observed resultsalmost indistinguishable votes correlated single-peaked (or single-troughed)drawn either uniformly random urn model.10fiWhere Hard Manipulation Problems?1n=64n=32n=16n=8n=40.9prob(manipulable)0.80.70.60.50.40.30.20.10110100candidates,Figure 6: Manipulability STV election containing correlated votes. number agentsfixed vary number candidates, m. n fixed votes drawnPolya-Eggenberger urn model b = 1. vertical axis measures probabilitymanipulator make random candidate win. horizontal axis measuresnumber candidates, election.1.62**mn=64n=32n=16n=8n=41e+141e+12mean nodes1e+101e+081e+0610000100120406080candidates,100120Figure 7: Search cost compute agent manipulate STV election containing correlatedvotes. number agents, n fixed vary number candidates, m.n fixed votes drawn using Polya-Eggenberger urn model b = 1. verticalaxis measures mean number search nodes explored compute manipulationprove none exists. horizontal axis measures number candidates,election. curves different n fit closely top other. Medianpercentiles similar.11fiWalsh1e+06m=64m=32m=16m=8m=4100000mean nodes10000100010010120406080agents, n100120Figure 8: Search cost compute agent manipulate STV election correlated votes.number candidates, fixed vary number agents, n. n fixedvotes drawn using Polya-Eggenberger urn model b = 1. vertical axismeasures mean number search nodes explored compute manipulation provenone exists. horizontal axis measures number agents, n. Medianpercentiles similar.4. Coalition Manipulationalgorithm computing manipulation STV election single agent also usedcompute coalition manipulate STV election members coalition voteunison. ignores complex manipulations members coalition need votedifferent ways. Insisting members coalition vote unison might reasonablewish manipulation low computational communication cost (Slinko & White,2008). Figures 9 10, plot probability coalition voting unison makerandom agent win STV election, cost compute possible vary sizecoalition. Theoretical results due Procaccia Rosenschein (2007a) Xia Conitzer(2008a) suggest critical size coalitionmanipulate election grows n.therefore normalize coalition size n.ability coalition manipulateelection increases size coalitionincreases. coalition n size, probability coalition manipulateelection candidate chosen random wins around 21 . cost computemanipulation (or prove none exists) decreases increase size coalition.easier larger coalition manipulate election smaller one.experiments suggest different behaviour occurs combinatorialproblems like propositional satisfiability graph colouring. instance, see rapidtransition sharpens around fixed point 3-satisfiability. vary coalition size,seetransition probability able manipulate result around coalition sizek = n. However, transition appears smooth seem sharpentowards stepfunction n increases. addition, hard instances occur around k = n. Indeed,hardest instances coalition smaller small chanceable manipulate result.12fiWhere Hard Manipulation Problems?1n=4n=8n=16n=32n=64prob(manipulable)0.80.60.40.2000.511.522.533.54normalized coalition size, k/sqrt(n)Figure 9: Manipulability STV election vary size manipulating coalition.number candidates number non-manipulating agents. n fixedvotes uniformly drawn random n! possible votes. vertical axis measuresprobability coalition make arandom candidate win. horizontal axismeasures coalition size, k normalized n.1e+06n=64n=32n=16n=8n=4100000mean nodes10000100010010100.511.522.53normalized coalition size, k/sqrt(n)3.54Figure 10: Search cost compute coalition manipulate STV election vary coalitionsize. vertical axis measures mean number search nodes explored computemanipulation provenone exists. horizontal axis measures coalition size,k normalized n. Median percentiles similar.13fiWalsh5. Sampling Real ElectionsElections met practice may differ sampled far. might, instance,votes never cast. hand, models studied far every possible votenon-zero probability seen. therefore sampled real voting records.previously studied phase transition behaviour real world problems using similar samplingtechniques (Gent & Walsh, 1995; Gent, Hoos, Prosser, & Walsh, 1999).first experiment uses votes cast 10 teams scientists select one 32 differenttrajectories NASAs Mariner spacecraft (Dyer & Miles, 1976). team ranked differenttrajectories based scientific value. sampled votes. elections 10 feweragents voting, simply took random subset 10 votes. elections 10agents voting, simply sampled 10 votes uniform frequency. elections 32fewer candidates, simply took random subset 32 candidates. Finally elections32 candidates, duplicated candidate assigned ranking.Since STV works total orders, forced agent break ties randomly.agent broke ties independently agent. New candidates introduced wayclones existing candidates. would interesting consider other, perhaps randommethods introducing new candidates. Nevertheless, note clones featurenumber real world elections. Indeed, one way manipulate election introduce clonecandidates opposition, thereby divide vote. example, motivationstudying clones, Tideman (1987) describes successfully vote class treasurersomewhat precocious 12 year old nominating best friend main rival. thereforebelieve may interest consider elections like generated clonespresent.Figures 11 12, plot cost compute manipulator make random agentwin STV election vary number candidates agents. Votes sampledNASA experiment explained earlier. probability manipulator manipulateelection resembles probability curve uniform random votes. search needed computemanipulation appears increase exponentially number candidates m. However,observed scaling much better 1.62m worst-case scaling original CSL algorithm.easily compute manipulations 128 candidates.second experiment, used votes faculty hiring committee UniversityCalifornia Irvine (Dobra, 1983). dataset 10 votes 3 different candidates. sampleddata set ways NASA dataset observed similar results.Results reported Figures 13 14. previous experiments, easy findmanipulation prove none exists. observed scaling much better 1.62mworst-case scaling original CSL algorithm.6. Veto Ruleturn manipulation elections small, bounded number candidates,votes weighted coalition agents trying manipulate result.part empirical study, consider veto rule. recall veto scoring ruleagent gets cast veto one candidate. candidate fewest vetoeswins. next theorem shows, simple number partitioning algorithms used computesuccessful manipulation veto rule. precisely, following theorem demonstrates,manipulation election 3 candidates weighted votes coalition (which NP-hardcompute) directly reduced 2-way number partitioning problem. therefore computemanipulations experiments using efficient number partitioning algorithm like proposedKorf (1995).14fiWhere Hard Manipulation Problems?1.62**mn=128n=64n=32n=16n=8n=41e+141e+12mean nodes1e+101e+081e+0610000100120406080100120candidates,Figure 11: Search cost compute agent manipulate STV election votes sampledNASA experiment. number agents, n fixed vary numbercandidates, m. vertical axis measures mean number search nodes exploredcompute manipulation prove none exists. horizontal axis measuresnumber candidates, m. Median percentiles similar.1e+06m=128m=64m=32m=16m=8m=4100000mean nodes10000100010010120406080agents, n100120Figure 12: Search cost compute agent manipulate STV election votes sampledNASA experiment. number candidates, fixed varynumber agents, n. vertical axis measures mean number search nodesexplored compute manipulation prove none exists. horizontal axismeasures number agents, n. Median percentiles similar.15fiWalsh1.62**mn=64n=32n=16n=8n=41e+141e+12mean nodes1e+101e+081e+0610000100120406080100120candidates,Figure 13: Search cost compute agent manipulate STV election votes sampledfaculty hiring committee. number agents voting, n fixed varynumber candidates, m. vertical axis measures mean number searchnodes explored compute manipulation prove none exists. horizontalaxis measures number candidates, m. Median percentiles similar.1e+06m=48m=24m=12m=6m=3100000mean nodes10000100010010120406080agents, n100120Figure 14: Search cost compute agent manipulate STV election votes sampledfaculty hiring committee. number candidates, fixed varynumber agents voting, n. vertical axis measures mean number searchnodes explored compute manipulation prove none exists. horizontal axismeasures number agents, n. Median percentiles similar.16fiWhere Hard Manipulation Problems?Theorem 1 exists successful manipulation election 3 candidates weightedcoalition using veto rule exists partitioning W {|a Pb|} two bagsdifference two sums less equal + b 2c + iW i, Wmultiset weights manipulating coalition, a, b c weights vetoes assignedthree candidates non-manipulators manipulators wish candidate weightc win.Proof: never helps coalition manipulating veto rule veto candidatewish win. coalition does, however, need decide divide vetoescandidates wish lose. PConsider case b. Suppose partition weightsw /2 w + /2 2w = iW {|ab|} difference two sums.partition vetoes successful manipulation winning candidatevetoes nextPbest candidate. is,Pc b + (w /2). Hence2w + 2b 2c = (a Pb) + 2b 2c + iW = (a + b P2c) + 2 iW i. case, < b(b + 2c) + iW i. Thus + b 2c + iW i. 2STV rule, start analysis uniform votes. first consider casen agents veto uniformly random one 3 possible candidates, vetoes carry weightsdrawn uniformly (0, w]. coalition small size, little weight ablechange result. hand, coalition large size, sure ablemake favoured candidate win. thus transition manipulability problemcoalition size increases (see Figure 15).1prob(elect chosen candidate)0.9n=14^2n=12^2n=10^2n=8^2n=6^20.80.70.60.50.40.30102030manipulators, k4050Figure 15: Manipulability veto election. vertical axis measures probabilitycoalition k agents elect chosen candidate veto election n agentsalready voted. horizontal axis measures number manipulators, k. Vetoesweighted weights uniformly drawn (0, 28 ]. k = 0, 1/3rd chancenon-manipulators already elected candidate.Based work Procaccia Rosenschien(2007a) Xia Conitzer (2008a),expect critical coalition size increase n. Figure16, see phase transitiondisplays simple universal form plotted k/ n. phase transition appearssmooth, probability varying slowlyapproaching step function problemsize increases. obtained good fit 1 32 ek/ n . smooth phase transitionsseen 2-colouring (Achlioptas, 1999), 1-in-2 satisfiability Not-All-Equal 2-satisfiability17fiWalsh1prob(elect chosen candidate)0.9n=14^2n=12^2n=10^2n=8^2n=6^20.80.70.60.50.40.3012345k/sqrt(n)Figure 16: Manipulability veto election rescaled axes. vertical axis measures probability coalition k agents elected chosen candidate veto electionn agents already voted. horizontal axis measures number manipulators,k divided square root number agents already voted. Vetoesweighted andweights uniformly drawn (0, 28 ]. Note horizontal axisscaled 1/ n compared previous figure.(Achlioptas, Chtcherba, Istrate, & Moore, 2001; Walsh, 2002). interesting notedecision problems polynomial.theoretical results mentioned earlier leave open hard compute whether manipulation possible coalition size critical. Figure 17 displays computational costfind manipulation (or prove none exists) using Korfs efficient number partitioning algorithm.Even critical region problems may may manipulable, easy computewhether problem manipulable. problems solved branches. contrastsphase transition behaviour NP-complete problems like propositional satisfiabilitycomplexity classes (Gent & Walsh, 1999; Bailey, Dalmau, & Kolaitis, 2001; Slaney & Walsh, 2002)hardest problems tend occur around phase transition.7. Hard Veto Problems RareBased reduction manipulation problems number partitioning, give aheuristic argument hard manipulation problems become vanishing rare n ; k = ( n). basicidea simple: time coalition large enough able change result, variancescores candidates likely large computing successful manipulationproving none possible easy. argument approximate. example, replace discrete sums continuous integrals, call upon limiting results like Central Limit Theorem.Nevertheless, provides insight manipulations typically easy compute.Suppose n vetoes voted non-manipulators carry weights drawn uniformly [0, w].Suppose also k manipulators also weights drawn uniformly [0, w], wantcandidates B lose C wins, cast vetoes weight a, b cA, B C respectively. Without loss generality suppose b. threecases consider. first case, c b c. easy manipulators make18fiWhere Hard Manipulation Problems?1.05average branches1.04n=14^2n=12^2n=10^2n=8^2n=6^21.031.021.011012345k/sqrt(n)Figure 17: Computational cost Korfs number partitioning algorithm decide coalitionk agents manipulate veto election n agents already voted. Vetoesweighted weights uniformly drawn (0, 2k ]. vertical axis measuresmean number branches used algorithm find manipulation prove noneexists. previous figure, horizontal axis measures number manipulators, k divided square root number agents already voted.note problems solved little search. took single branch solve.took 2 branches.C win since C wins whether veto B. second case, c > b. Again, easymanipulators decide make C win. veto B. successfulmanipulation C wins. third case, < c b < c. manipulatorsmust partition k vetoes B total vetoes received B exceedsC. Let deficit weight C B C. is,= (c a) + (c b) = 2c b. approximate sum n random variables drawnuniformly probability 1/3 [0, 2w] probability 2/3 [w, 0]. variablesmean 0 variance 2w2 /3. Central Limit Theorem, tends normal distributionmean 0, variance t2 = 2nw2 /3. manipulation possible, must lesss, sum weights vetoes manipulators. Central Limit Theorem, alsotends normal distribution mean = kw/2, variance 2 = 2kw2 /3.simple heuristic argument due (Karmarkar, Karp, Lueker, & Odlyzko, 1986) also basedCentralLimit Theorem upper bounds optimal partition difference k numbers[0, w] O(w k/2k ). addition, based phase transition number partitioning (Gent &Walsh, 1998), expect partitioning problems easy unless log2 (w) = (k).Combiningtwo observations, expect hard manipulation problems 0 k constant. probability occurring is:ZZ x(x)21 y221e 22e 2t dy dx22tx k0substituting t, , get:ZZ x2(xkw/2)211y24nw /3 dy dxppe 4kw2 /3e4kw2 /34nw2 /30x k19fiWalshn ; , tends to:Z01p4kw2 /3ek(xkw/2)24kw2 /3p4nw2 /3ex24nw2 /3dxez 1 z > 0, upper bounded by:Z(xkw/2)2k1ppe 4kw2 /3 dx4nw2 /3 04kw2 /3Since integral bounded 1, k = ( n) log2 (w) = (k), upper bound varies as:O(1)k2kThus, expect hard instances manipulation problems exponentially rare. Since evenbrute force manipulation algorithm takes O(2k ) time worst-case, expect hardinstances significant impact average-case n (and thus k) grows. stressheuristic argument. makes many assumptions complexity manipulationproblems (in particular hard instances lie within narrow interval 0 k).assumptions currently supported empirical observation informal argument.However, experimental results reported Figure 17 support conclusions.8. Distributions Vetoestheoretical analyses manipulation due Procaccia Rosenschein (2007a) XiaConitzer (2008a) suggest probability election manipulable largely independentw, size weights attached vetoes. Figure 18 demonstrates indeed appearscase practice. weights varied size 28 216 , probabilityappear change. fact, probability curve fits simple universal form plottedFigure 16. also observed cost computing manipulation proving nonepossible change weights varied size.Similarly, theoretical results typically place assumptions distribution votes.example, results Procaccia Rosenschein(2007a) Xia Conitzer (2008a)critical coalition size increases ( n) hold independent identicallydistributed random votes. Similarly, heuristic argument hard manipulation problemsvanishingly rare depends application Central Limit Theorem. therefore workstypes independent identically distributed random votes.considered therefore another type independent identically distributed vote. particular, study election weights independently drawn normal distribution.Figure 19 shows smooth phase transition manipulability. also plottedFigure 19 top Figures 16 18. curves appear fit simple universal form.uniform weights, computational cost deciding election manipulable smalleven coalition size critical. Finally, varied parameters normal distribution. probability electing chosen candidate well cost computing manipulationappear depend mean variance distribution. reproducefigures look identical previous figures.9. Correlated Vetoesconjecture one place find hard manipulation problems veto voting voteshighly correlated. example, consider hung election n agents veto candidate20fiWhere Hard Manipulation Problems?1prob(elect chosen candidate)0.9log2(w)=16log2(w)=14log2(w)=12log2(w)=10log2(w)=80.80.70.60.50.40.3012345k/sqrt(n)Figure 18: Independence size weights manipulability veto election.vertical axis measures probability coalition k agents elect chosencandidate n agents already voted. previous figure, horizontalaxis measures number manipulators, k divided square root numberagents already voted. Vetoes weighted weights uniformly drawn(0, w].1prob(elect chosen candidate)0.9n=14^2n=12^2n=10^2n=8^2n=6^20.80.70.60.50.40.3012345k/sqrt(n)Figure 19: Manipulability veto election weighted votes taken normal distribution.vertical axis measure probability coalition k agents elect chosencandidate veto election n agents already voted. previous figure,horizontal axis measures number manipulators, k divided square rootnumber agents already voted. Vetoes weighted drawnnormal distribution mean 28 standard deviation 27 .21fiWalshprob(elect chosen candidate)1m=24m=18m=12m=60.80.60.40.2000.51log2(w)/k1.52Figure 20: Manipulability veto election votes highly correlated resulthung. Vetoes manipulators weighted weights uniformly drawn(0, w], agents vetoed candidate manipulators wish win,sum weights manipulators twice non-manipulators.vertical axis measures probability coalition k agents elect chosencandidate. horizontal axis measures log2 (w)/k.100000m=24m=18m=12m=6average branches10000100010010100.511.52log2(w)/kFigure 21: search cost decide hung veto election manipulated. Vetoesmanipulators weighted weights uniformly drawn (0, w],agents vetoed candidate manipulators wish win, sumweights manipulators twice non-manipulators. verticalaxis measures mean number branches explored Korfs algorithm decidecoalition k agents manipulate veto election. horizontal axis measureslog2 (w)/k.22fiWhere Hard Manipulation Problems?manipulators wish win, k manipulators exactly twice weight vetoesn agents. election finely balanced. preferred candidate manipulators winsmanipulators perfectly partition vetoes two candidateswish lose. Note precisely trick used reducing number partitioningmanipulation problem Conitzer et al. (2007). Figure 20, plot probability kmanipulators make preferred candidate win hung election vary sizeweights w. Similar number partitioning (Gent & Walsh, 1998), see rapid transitionmanipulability around log2 (w)/k 1. Figure 21, observe rapid increasecomputationally complexity compute manipulation around point.happens votes less correlated? consider election perfectlyhung except one agent vetoes random one three candidates. Figure 22,plot cost computing manipulation weight single random veto increases.Even one uncorrelated vote enough make manipulation easy magnitudeweight vetoes manipulators. suggests find hard manipulation problemsveto elections votes highly correlated.100000m=24m=18m=12m=6average branches10000100010010100.20.40.6log2(w)/log2(w)0.81Figure 22: impact one random agent manipulability hung veto election. Vetoesmanipulators weighted weights uniformly drawn (0, w], nonmanipulating agents vetoed candidate manipulators wish win,sum weights manipulators twice non-manipulatorsexcept one random non-manipulating agent whose weight uniformly drawn(0, w0 ]. vertical axis measures mean number search branches exploredKorfs algorithm decide coalition k agents manipulate veto election.horizontal axis measures log2 (w0 )/ log2 (w). veto one random agentweight agents, computationally easy decide electionmanipulated.10. Related Workindicated earlier, number theoretical results suggest elections easy manipulatepractice despite worst case NP-hardness results. example, Procaccia Rosenschein provedscoring rules wide variety distributions votes, size23fiWalshcoalitiono( n), probability change result tends 0,( n), probability manipulate result tends 1 (Procaccia & Rosenschein,2007a). also gave simple greedy procedure find manipulation scoring rulepolynomial time probability failure inverse polynomial n (Procaccia &Rosenschein, 2007b). However, treat result caution junta distributionsused work may limited usefulness (Erdelyi, Hemaspaandra, Rothe, & Spakowski, 2009).second example, Xia Conitzer shown large class voting rules includingSTV, number agents grows, either probability coalition manipulate resultsmall (as coalition small), probability easily manipulateresult make alternative win large (Xia & Conitzer, 2008a). left opensmall interval size coalition coalition large enough manipulateobviously large enough manipulate result easily.Friedgut, Kalai Nisan proved voting rule neutral far dictatorial3 candidates exists agent random manipulation succeedsprobability ( n1 ) (Friedgut et al., 2008). were, however, unable extend proof four(or more) candidates. recently, Isaksson, Kindler Mossel proved similar result 4candidates using geometric arguments (Isaksson, Kindler, & Mossel, 2010). Startingdifferent assumptions again, Xia Conitzer showed random manipulation would succeedprobability ( n1 ) 3 candidates STV, 4 candidates scoringrule 5 candidates Copeland (Xia & Conitzer, 2008b).discussed earlier, Coleman Teague proposed algorithms compute manipulationsSTV rule (Coleman & Teague, 2007). also conducted empirical study demonstrated relatively small coalitions needed change elimination order STVrule. observed uniform random elections trivially manipulable usingsimple greedy heuristic. hand, results suggest that, manipulation singleagent, often small amount backtracking needed find manipulation provenone exists.11. Conclusionsstudied empirically whether computational complexity barrier manipulationSTV veto rules manipulating agents complete informationvotes. looked number different distributions votes including uniform randomvotes, correlated votes drawn urn model, votes sampled real world elections.looked manipulation single unweighted agent case STV, coalitionweighted agents case veto voting. many elections experiments, easycompute manipulation prove manipulation possible. situations identifiedmanipulations computationally difficult find depended either electionhundreds candidates election tightly hung. results increase concerncomputational complexity may significant barrier manipulation practice.lessons learnt study? First, whilst focused STVveto rules, similar behavior likely voting rules. would, instance, interestingstudy Borda rule one rules used practice computing manipulationNP-hard unweighted votes (Davies et al., 2011; Betzler et al., 2011). would alsointeresting study voting rules like Copeland, maximin ranked pairs. rules memberssmall set voting rules NP-hard manipulate without weights votes(Xia, Zuckerman, Procaccia, Conitzer, & Rosenschein, 2009). Second, may connectionsmoothness phase transition problem hardness. Sharp phase transitionslike propositional satisfiability associated hard decision problems, whilst smoothtransitions associated easy instances NP-hard problems polynomial problemslike 2-colourability. phase transitions observed appear smooth. Third, given24fiWhere Hard Manipulation Problems?insights provided empirical studies, would interesting consider similar studies relatedproblems. example, computational complexity issue preference elicitation (Conitzer &Sandholm, 2002b; Walsh, 2008; Pini, Rossi, Venable, & Walsh, 2008)? Fourth, assumedmanipulators complete information votes agents. interestingfuture direction determine uncertainty agents voted adds computationalcomplexity manipulation practice (Conitzer & Sandholm, 2002a; Walsh, 2007; Lang, Pini,Rossi, Venable, & Walsh, 2007).AcknowledgmentsNICTA funded Australian Government Department Broadband, Communications Digital Economy Australian Research Council ICT CentreExcellence program. results paper appeared two earlier conference papers(Walsh, 2009, 2010).ReferencesAchlioptas, D. (1999). Threshold phenomena random graph colouring satisfiability. Ph.D.thesis, Department Computer Science, University Toronto.Achlioptas, D., Chtcherba, A., Istrate, G., & Moore, C. (2001). phase transition 1-in-kSAT NAE SAT. Proceedings 12th Annual ACM-SIAM Symposium DiscreteAlgorithms (SODA01), pp. 719720. Society Industrial Applied Mathematics.Bailey, D., Dalmau, V., & Kolaitis, P. (2001). Phase transitions PP-complete satisfiability problems. Nebel, B. (Ed.), Proceedings 17th International Joint Conference ArtificialIntelligence (IJCAI 2001), pp. 183189. International Joint Conference Artificial Intelligence, Morgan Kaufmann.Barbera, S., Berga, D., & Moreno, B. (2009). Single-dipped preferences. UFAE IAE working papers 801.09, Unitat de Fonaments de lAnlisi Econmica (UAB) Institut dAnlisi Econmica(CSIC).Bartholdi, J., & Orlin, J. (1991). Single transferable vote resists strategic voting. Social ChoiceWelfare, 8 (4), 341354.Bartholdi, J., Tovey, C., & Trick, M. (1989). computational difficulty manipulatingelection. Social Choice Welfare, 6 (3), 227241.Berg, S. (1985). Paradox voting urn model: effect homogeneity. Public Choice,47, 377387.Betzler, N., Niedermeier, R., & Woeginger, G. (2011). Unweighted coalitional manipulationBorda rule NP-hard. Walsh, T. (Ed.), Proceedings 22nd International JointConference Artificial Intelligence (IJCAI 2011). International Joint Conference ArtificialIntelligence.Black, D. (1948). rationale group decision-making. Journal Political Economy, 56 (1),2334.Brandt, F., Brill, M., Hemaspaandra, E., & Hemaspaandra, L. (2010). Bypassing combinatorialprotections: Polynomial-time algorithms single-peaked electorates. Fox, M., & Poole,D. (Eds.), Proceedings 24th AAAI Conference Artificial Intelligence (AAAI 2010).AAAI Press.Chamberlin, J. (1985). investigation relative manipulability four voting systems.Behavioral Science, 30, 195203.25fiWalshCheeseman, P., Kanefsky, B., & Taylor, W. (1991). really hard problems are. Mylopoulos, J., & Reiter, R. (Eds.), Proceedings 12th International Joint ConferenceArtificial Intelligence (IJCAI 1991), pp. 331337. International Joint Conference ArtificialIntelligence.Coleman, T., & Teague, V. (2007). complexity manipulating elections. Gudmundsson,J., & Jay, B. (Eds.), Proceedings 13th Australasian Symposium Theory Computing(CATS 07), pp. 2533. Australian Computer Society, Inc.Conitzer, V. (2007). Eliciting single-peaked preferences using comparison queries. Durfee, E.,Yokoo, M., Huhns, M., & Shehory, O. (Eds.), Proceedings 6th International Joint Conference Autonomous Agents Multiagent Systems (AAMAS 2007), pp. 408415. IFAAMAS.Conitzer, V. (2009). Eliciting single-peaked preferences using comparison queries. Journal Artificial Intelligence Research, 35, 161191.Conitzer, V., & Sandholm, T. (2002a). Complexity manipulating elections candidates.Dechter, R., Kearns, M., & Sutton, R. (Eds.), Proceedings 18th National ConferenceArtificial Intelligence (AAAI 2002), pp. 314319. Association Advancement ArtificialIntelligence.Conitzer, V., & Sandholm, T. (2002b). Vote elicitation: Complexity strategy-proofness.Dechter, R., Kearns, M., & Sutton, R. (Eds.), Proceedings 18th National ConferenceArtificial Intelligence (AAAI 2002), pp. 392397. Association Advancement ArtificialIntelligence.Conitzer, V., & Sandholm, T. (2006). Nonexistence voting rules usually hard manipulate. Gil, Y., & Mooney, R. (Eds.), Proceedings 21st National Conference ArtificalIntelligence (AAAI 2006), pp. 627634. Association Advancement Artificial Intelligence.Conitzer, V., Sandholm, T., & Lang, J. (2007). elections candidates hardmanipulate?. Journal Association Computing Machinery, 54 (3). Article 14 (33pages).Davies, J., Katsirelos, G., Narodytska, N., & Walsh, T. (2011). Complexity algorithmsBorda manipulation. Burgard, W., & Roth, D. (Eds.), Proceedings Twenty-FifthAAAI Conference Artificial Intelligence (AAAI 2011). AAAI Press.Dobra, J. (1983). approach empirical studies voting paradoxes: update extension..Public Choice, 41, 241250.Dubois, O., Monasson, R., Selman, B., & Zecchina, R. (2001). Special issue: Phase transitionscombinatorial problems. Theoretical Computer Science, 265 (12), 1306.Dyer, J., & Miles, R. (1976). actual application collective choice theory selectiontrajectories Mariner Jupiter/Saturn 1977 project. Operations Research, 24 (2), 220244.Erdelyi, G., Hemaspaandra, L., Rothe, J., & Spakowski, H. (2009). Generalized Juntas NP-hardsets. Theoretical Computer Science, 410 (38-40), 39954000.Faliszewski, P., Hemaspaandra, E., & Hemaspaandra, L. (2010). Using complexity protect elections. Communications ACM, 53 (11), 7482.Faliszewski, P., Hemaspaandra, E., Hemaspaandra, L., & Rothe, J. (2009). shield neverwas: societies single-peaked preferences open manipulation control.Heifetz, A. (Ed.), Proceedings 12th Conference Theoretical Aspects RationalityKnowledge (TARK-2009), pp. 118127.Faliszewski, P., Hemaspaandra, E., & Schnoor, H. (2008). Copeland voting: ties matter. Padgham,L., Parkes, D., Muller, J., & Parsons, S. (Eds.), 7th International Joint Conference Autonomous Agents Multiagent Systems (AAMAS 2008), pp. 983990.26fiWhere Hard Manipulation Problems?Faliszewski, P., & Procaccia, A. (2010). AIs war manipulation: winning?. AI Magazine,31 (4), 5364.Friedgut, E., Kalai, G., & Nisan, N. (2008). Elections manipulated often. Proceedings49th Annual IEEE Symposium Foundations Computer Science (FOCS 2008), pp.243249. IEEE Computer Society Press.Gent, I., Hoos, H., Prosser, P., & Walsh, T. (1999). Morphing: Combining structure randomness.Hendler, J., & Subramanian, D. (Eds.), Proceedings 16th National ConferenceArtificial Intelligence (AAAI 1999), pp. 654660. Association Advancement ArtificialIntelligence.Gent, I., MacIntyre, E., Prosser, P., Smith, B., & Walsh, T. (2001). Random constraint satisfaction:Flaws structure. Constraints, 6 (4), 345372.Gent, I., MacIntyre, E., Prosser, P., & Walsh, T. (1995). Scaling effects CSP phase transition. Montanari, U., & Rossi, F. (Eds.), Proceedings 1st International ConferencePrinciples Practices Constraint Programming (CP-95), Vol. 976 Lecture NotesComputer Science, pp. 7087. Springer-Verlag.Gent, I., & Walsh, T. (1994). SAT phase transition. Cohn, A. (Ed.), Proceedings 11thEuropean Conference Artificial Intelligence (ECAI-94), pp. 105109. John Wiley & Sons.Gent, I., & Walsh, T. (1995). Phase transitions real computational problems. Proceedings8th International Symposium Artificial Intelligence: Intelligent Systems ApplicationsIndustry Business, pp. 356364.Gent, I., & Walsh, T. (1996a). Phase transitions annealed theories: Number partitioningcase study. Wahlster, W. (Ed.), Proc. 12th European Conference ArtificialIntelligence (ECAI-96), pp. 170174. John Wiley Sons, Chichester.Gent, I., & Walsh, T. (1996b). satisfiability constraint gap. Artificial Intelligence, 81 (12),5980.Gent, I., & Walsh, T. (1996c). TSP phase transition. Artificial Intelligence, 88, 349358.Gent, I., & Walsh, T. (1998). Analysis heuristics number partitioning. Computational Intelligence, 14 (3), 430451.Gent, I., & Walsh, T. (1999). Beyond NP: QSAT phase transition. Hendler, J., & Subramanian,D. (Eds.), Proceedings 16th National Conference AI, pp. 648653. AssociationAdvancement Artificial Intelligence.Gibbard, A. (1973). Manipulation voting schemes: general result. Econometrica, 41, 587601.Gomes, G., & Walsh, T. (2006). Randomness structure. Rossi, F., van Beek, P., & Walsh,T. (Eds.), Handbook Constraint Programming, Foundations Artificial Intelligence, pp.639664. Elsevier.Hartmann, A., & Weigt, M. (2005). Phase Transitions Combinatorial Optimization Problems:Basics, Algorithms Statistical Mechanics. Wiley-VCH, Weinheim.Isaksson, M., Kindler, G., & Mossel, E. (2010). geometry manipulation: quantitative proofGibbard-Satterthwaite theorem. 51th Annual IEEE Symposium FoundationsComputer Science (FOCS 2010), pp. 319328. IEEE Computer Society.Karmarkar, N., Karp, R., Lueker, J., & Odlyzko, A. (1986). Probabilistic analysis optimumpartitioning. Journal Applied Probability, 23, 626645.Korf, R. (1995). approximate optimal solutions: case study number partitioning.Mellish, C. S. (Ed.), Proceedings 14th International Joint Conference Artificial Intelligence (IJCAI 1995), pp. 266272. International Joint Conference Artificial Intelligence.27fiWalshLang, J., Pini, M., Rossi, F., Venable, B., & Walsh, T. (2007). Winner determination sequentialmajority voting. Veloso, M. M. (Ed.), Proceedings 20th International Joint Conference Artificial Itelligence (IJCAI-2007), pp. 13721377. International Joint ConferenceArtificial Intelligence.McCabe-Dansted, J., & Slinko, A. (2006). Exploratory analysis similarities social choicerules. Group Decision Negotiation, 15, 77107.Mertens, S. (2001). physicists approach number partitioning. Theoretical Computer Science,265 (1-2), 79108.Mitchell, D., Selman, B., & Levesque, H. (1992). Hard Easy Distributions SAT Problems.Proceedings 10th National Conference AI, pp. 459465. Association AdvancementArtificial Intelligence.Pini, M., Rossi, F., Venable, K., & Walsh, T. (2008). Dealing incomplete agents preferencesuncertain agenda group decision making via sequential majority voting. Brewka,G., & Lang, J. (Eds.), Principles Knowledge Representation Reasoning: ProceedingsEleventh International Conference (KR 2008), pp. 571578. AAAI Press.Procaccia, A. D., & Rosenschein, J. S. (2007a). Average-case tractability manipulation votingvia fraction manipulators. Durfee, E. H., Yokoo, M., Huhns, M. N., & Shehory, O.(Eds.), Proceedings 6th International Joint Conference Autonomous Agents Multiagent Systems (AAMAS-07), pp. 718720. IFAAMAS.Procaccia, A. D., & Rosenschein, J. S. (2007b). Junta distributions average-case complexitymanipulating elections. Journal Artificial Intelligence Research, 28, 157181.Prosser, P. (1994). Binary constraint satisfaction problems: harder others. Cohn,A. G. (Ed.), Proceedings 11th European Conference Artificial Intelligence, pp. 9599.European Conference Artificial Intelligence, John Wiley Sons.Satterthwaite, M. (1975). Strategy-proofness Arrows conditions: Existence correspondencetheorems voting procedures social welfare functions. Journal Economic Theory, 10,187216.Slaney, J., & Walsh, T. (2002). Phase transition behavior: decision optimization. Proceedings 5th International Symposium Theory Applications SatisfiabilityTesting, SAT 2002.Slinko, A., & White, S. (2008). Non- dictatorial social choice rules safely manipulable.Goldberg, U. E. . P. W. (Ed.), Proceedings 2nd International Workshop ComputationalSocial Choice (COMSOC08), pp. 403413.Smith, B. (1994). phase transition constraint satisfaction problems: closer lookmushy region. Cohn, A. G. (Ed.), Proceedings 11th European Conference ArtificialIntelligence, pp. 100104. European Conference Artificial Intelligence, John Wiley Sons.Tideman, T. (1987). Independence clones criterion voting rules. Social ChoiceWelfare, 4, 185206.Walsh, T. (1998). constrainedness knife-edge. Mostow, J., & Rich, C. (Eds.), Proceedings15th National Conference AI, pp. 406411. Association Advancement ArtificialIntelligence.Walsh, T. (1999). Search small world. Dean, T. (Ed.), Proceedings 16th InternationalJoint Conference Artificial Itelligence (IJCAI-99), pp. 11721177. International Joint Conference Artificial Intelligence, Morgan Kaufmann.Walsh, T. (2001). Search high degree graphs. Nebel, B. (Ed.), Proceedings 17th International Joint Conference Artificial Itelligence (IJCAI-2001), pp. 266274. InternationalJoint Conference Artificial Intelligence, Morgan Kaufmann.28fiWhere Hard Manipulation Problems?Walsh, T. (2002). P NP: COL, XOR, NAE, 1-in-k, Horn SAT. Dechter, R., Kearns,M., & Sutton, R. (Eds.), Proceedings 17th National Conference AI (AAAI 2002), pp.695700. Association Advancement Artificial Intelligence.Walsh, T. (2007). Uncertainty preference elicitation aggregation. Proceedings 22ndNational Conference AI, pp. 38. Association Advancement Artificial Intelligence.Walsh, T. (2008). Complexity terminating preference elicitation. Padgham, L., Parkes, D. C.,Muller, J. P., & Parsons, S. (Eds.), 7th International Joint Conference Autonomous AgentsMultiagent Systems (AAMAS 2008), pp. 967974. IFAAMAS.Walsh, T. (2009). really hard manipulation problems? phase transitionmanipulating veto rule. Boutilier, C. (Ed.), Proceedings 21st International JointConference Artificial Itelligence (IJCAI-2009), pp. 324329. International Joint ConferenceArtificial Intelligence.Walsh, T. (2010). empirical study manipulability single transferable voting. Coelho,H., Studer, R., & Wooldridge, M. (Eds.), Proc. 19th European Conference ArtificialIntelligence (ECAI-2010), Vol. 215 Frontiers Artificial Intelligence Applications, pp.257262. IOS Press.Xia, L., & Conitzer, V. (2008a). Generalized scoring rules frequency coalitional manipulability. Fortnow, L., Riedl, J., & Sandholm, T. (Eds.), EC 08: Proceedings 9th ACMconference Electronic Commerce, pp. 109118. ACM.Xia, L., & Conitzer, V. (2008b). sufficient condition voting rules frequently manipulable.Fortnow, L., Riedl, J., & Sandholm, T. (Eds.), Proceedings 9th ACM conferenceElectronic Commerce (EC 08), pp. 99108. ACM.Xia, L., Zuckerman, M., Procaccia, A., Conitzer, V., & Rosenschein, J. (2009). Complexityunweighted coalitional manipulation common voting rules. Boutilier, C. (Ed.),Proceedings 21st International Joint Conference Artificial Intelligence (IJCAI 2009),pp. 348353. International Joint Conference Artificial Intelligence.Zhang, W., & Korf, R. (1996). study complexity transitions asymmetic traveling salesmanproblem. Artificial Intelligence, 81 (1-2), 223239.29fiJournal Artificial Intelligence Research 42 (2011) 719-764Submitted 03/11; published 12/11Defeasible Inclusions Low-Complexity DLsPiero A. BonattiMarco FaellaLuigi SauroBONATTI @ NA . INFN .MFAELLA @ NA . INFN .SAURO @ NA . INFN .Dipartimento di Scienze Fisiche,Universita di Napoli Federico IIAbstractapplications OWL RDF (e.g. biomedical knowledge representationsemantic policy formulation) call extensions languages nonmonotonic constructsinheritance overriding. Nonmonotonic description logics studied manyyears, however practical knowledge representation languages exist, due combinationsemantic difficulties high computational complexity. Independently, low-complexity description logics DL-lite EL introduced incorporated OWL standard.Therefore, interesting see whether syntactic restrictions characterizing DL-lite ELbring computational benefits nonmonotonic versions, too. paper extensively investigate computational complexity Circumscription knowledge bases formulatedDL-liteR , EL, fragments thereof. identify fragments whose complexity ranges Psecond level polynomial hierarchy, well fragments whose complexity raisesPSPACE beyond.1. Introductionontologies core semantic web well ontology languages RDF, OWL,related Description Logics (DLs) founded fragments first-order logic inheritstrengths weaknesses well-established formalism. Limitations include monotonicity,consequent inability design knowledge bases (KBs) describing prototypes whose generalproperties later refined suitable exceptions. natural, iterative approach commonly used biologists calls extension DLs defeasible inheritance overriding (a mechanism normally supported object-oriented languages). workaroundsdevised particular cases; however, general solutions currently available (Rector, 2004;Stevens, Aranguren, Wolstencroft, Sattler, Drummond, Horridge, & Rector, 2007). Another motivation nonmonotonic DLs stems recent development policy languages based DLs(Uszok, Bradshaw, Jeffers, Suri, Hayes, Breedy, Bunch, Johnson, Kulkarni, & Lott, 2003; Finin,Joshi, Kagal, Niu, Sandhu, Winsborough, & Thuraisingham, 2008; Zhang, Artale, Giunchiglia, &Crispo, 2009; Kolovski, Hendler, & Parsia, 2007). DLs nicely capture role-based policies facilitate integration semantic web policy enforcement reasoning semantic metadata(which typically necessary order check policy conditions). However, order formulatestandard default policies open closed policies,1 support common policy languagefeatures authorization inheritance exceptions (which meant facilitate incremental1. explicit authorization specified given access request, open policy permits accessclosed policy denies it.c2011AI Access Foundation. rights reserved.fiB ONATTI , FAELLA , & AUROpolicy formulation), necessary adopt nonmonotonic semantics; Bonatti Samarati (2003)provide details matter.Given increasing size semantic web ontologies RDF bases, complexity reasoning influential factor may either foster prevent adoption knowledge representation language. Accordingly, OWL2 introduces profiles adopt syntactic restrictions (compatibleapplication requirements) order make reasoning tractable. Two profiles basedfollowing families DLs: DL-lite (Calvanese, De Giacomo, Lembo, Lenzerini, & Rosati,2005), formalizes RDFS, EL (Baader, 2003; Baader, Brandt, & Lutz, 2005), extensively covers important biomedical ontologies GALEN SNOMED. Unfortunately,general, nonmonotonic DL reasoning highly complex reach NExpTimeNP even 3ExpTime (Donini, Nardi, & Rosati, 1997, 2002; Bonatti, Lutz, & Wolter, 2009). natural question,context, whether restrictions adopted DL-lite EL help reducingcomplexity nonmonotonic DL reasoning, too.Answering question main goal paper. extensively investigate complexity reasoning DL-lite EL. nonmonotonic semantics adopted Circumscription(McCarthy, 1980), whose main appealing properties (discriminating Circumscriptionnonmonotonic DL semantics proposed literature) summarized below:1. Circumscription compatible interpretation domains supported classical DLs;need adopting fixed domain standard names;2. circumscribed DLs, nonmonotonic inferences apply individuals, includingdenoted constants implicitly asserted existential quantifiers;3. Circumscription naturally supports priorities among conflicting nonmonotonic axiomseasily simulate specificity-based overriding.attempt simplify usage circumscribed DLs simultaneously remove potentialsources computational complexity, support usage abnormality predicates (McCarthy, 1986) full generality; rather hide within defeasible inclusions (Bonatti,Faella, & Sauro, 2009). Defeasible inclusions expressions C vn whose intuitive meaningis: instance C normally instance D. inclusions prioritized resolveconflicts. Priorities either explicit automatically determined inclusions specificity,i.e. defeasible inclusion C1 vn D1 may override C2 vn D2 C1 classically subsumedC2 . framework, prove restricting syntax DL-lite inclusions sufficesin almostcasesto reduce complexity second level polynomial hierarchy. contrary,circumscribed EL still ExpTime-hard restrictions needed confine complexity within second level polynomial hierarchy. Syntactic restrictions analyzedconjunction semantic parameters, kind priorities adopted (explicitspecificity-based), predicates may may affected Circumscription (i.e., fixedvariable predicates, Circumscriptions jargon).paper organized follows: First, basics low-complexity description logicsextension based circumscription recalled Section 2 Section 3, respectively. Then,reductions used eliminate language features work simpler frameworksillustrated Section 4. undecidability result caused fixed roles (Section 5), paperfocuses variable roles: complexity circumscribed DL-liteR EL/EL investigated720fiD EFEASIBLE NCLUSIONS L OW-C OMPLEXITY DLNameSyntaxinverse roleRnominalnegationconjunctionexistentialrestrictiontopbottom{a}CC uDR.C>Semantics(R ) = {(d, e) | (e, d) RI }{aI }\ CC DI{d | (d, e) RI : e C }>I ==Figure 1: Syntax semantics DL constructs.Section 6 Section 7, respectively. section related work final discussion concludepaper.2. PreliminariesDLs, concepts inductively defined set constructors, starting set NC conceptnames, set NR role names, (possibly) set NI individual names (all countably infinite).use term predicates refer elements NC NR . Hereafter, letters B rangeNC , P range NR , a, b, c range NI . concepts DLs dealtpaper formed using constructors shown Figure 1. There, inverse role constructorrole constructor, whereas remaining constructors concept constructors. LettersC, range concepts letters R, (possibly inverse) roles.semantics concepts defined terms interpretations = (I , ).domain non-empty set individuals interpretation function maps conceptname NC set AI , role name P NR binary relation P ,individual name NI individual aI . extension inverse roles arbitraryconcepts inductively defined shown third column Figure 1. interpretationcalled model concept C C 6= . model C, also say C satisfied I.(strong) knowledge base finite set (i) concept inclusions (CIs) C v Cconcepts, (ii) concept assertions A(a) role assertions P (a, b), a, b individualnames, P NR , NC , (iii) role inclusions (RIs) R v R0 . interpretation satisfies (i) CIC v C DI , (ii) assertion C(a) aI C , (iii) assertion P (a, b) (aI , bI ) P ,(iv) RI R v R0 iff RI R0 . Then, model strong knowledge base iff satisfieselements S. write C vS iff models S, satisfies C v D.Terminologies particular strong knowledge bases consisting definitions, i.e. axiomsC, abbreviate inclusions v C C v A. terminology containsdefinition, say defined C definition A. definedmust unique definition. concept name directly depends B (in ) B occursdefinition; moreover, depends B (in ) chain direct dependenciesleading B. terminology acyclic depends . Terminologiesconservative extensions, concept names defined acyclic terminology721fiB ONATTI , FAELLA , & AUROeliminated unfolding w.r.t. , is, exhaustively replacing concepts defineddefinition. expressions (i.e., concepts inclusions) E, denote unf(E, )unfolding E w.r.t. .logic DL-liteR (Calvanese et al., 2005) restricts concept inclusions expressions CL vCR ,CL ::= | RR ::= P | PCR ::= CL | CL(as usual, R abbreviates R.>).logic EL (Baader, 2003; Baader et al., 2005) restricts knowledge bases assertionsconcept inclusions built following constructs:C ::= | > | C1 u C2 | P.C(note inverse roles supported). extension EL , role hierarchies,nominals (respectively) denoted EL , ELH, ELO. Combinations allowed:example ELHO denotes extension EL supporting role hierarchies nominals. Finally,ELA denotes extension negation applied concept names.3. Defeasible Knowledgegeneral defeasible inclusion (GDI) expression C vn whose intended meaning is: Cselements normally D.Example 3.1 (Bonatti et al., 2009) sentences: humans, heart usually locatedleft-hand side body; humans situs inversus, heart located right-hand sidebody (Rector, 2004; Stevens et al., 2007) formalized EL axioms GDIs:Human vn heart.has position.Left ;Situs Inversus v heart.has position.Right ;heart.has position.Left uheart.has position.Right v .2defeasible knowledge base (DKB) logic DL pair hK, i, K = KS KD , KSstrong DL KB, KD set GDIs C vn C v DL inclusion, strictpartial order (a priority relation) KD . following, C v[n] denote inclusioneither classical defeasible. Moreover, DKB KB = hK , i, (classical)acyclic terminology, denote unf(KB) = hK0 , 0 DKB K0 unfoldinginclusions K w.r.t. , and, DIs , 0 K, relation unf(, ) 0 unf( 0 , ) holds0 .priority relation shall often adopt specificity relation K determinedclassically valid inclusions. Formally, GDIs 1 = (C1 vn D1 ) 2 = (C2 vn D2 ), let1 K 2 iff C1 vKS C2 C2 6vKS C1 .722fiD EFEASIBLE NCLUSIONS L OW-C OMPLEXITY DLExample 3.2 access control policy: Normally users cannot read project files; staff readproject files; blacklisted staff granted access encoded with:Staff v UserBlacklisted v StaffUserRequest v subj.User u target.Proj u op.ReadStaffRequest v subj.Staff u target.Proj u op.ReadUserRequest vn decision.{Deny}StaffRequest vn decision.{Grant}subj.Blacklisted v decision.{Deny}decision.{Grant} u decision.{Deny} v .Staff members cannot simultaneously satisfy two defeasible inclusions (due last inclusionabove). specificity, second defeasible inclusion overrides first one yields intuitive inference non-blacklisted staff members indeed allowed access project files.formally, subsumptionsubj.(Staff u Blacklisted) u target.Proj u op.Read v decision.{Grant}holds models knowledge base (as defined below).2Intuitively, model hK, model KS maximizes set individuals satisfyingdefeasible inclusions KD , resolving conflicts means priority relation wheneverpossible. formalizing notion model, one specify deal predicatesoccurring knowledge base: extension allowed vary order satisfy defeasibleinclusions? discussion effects letting predicates vary vs. fixing extensionfound work Bonatti, Lutz Wolter (2006); conclude appropriate choiceapplication dependent. So, general, set predicates NC NR arbitrarily partitionedtwo sets F V containing fixed varying predicates, respectively; denote semanticsCircF .However, Section 5 shown fixed roles cause undecidability issues,results concern specialized framework role names varying predicates, is,F NC . use notation CircF (rather CircF ) indicate F NC .set F , GDIs KD , priority relation induce strict partial order interpretations. move ordering find interpretations normal w.r.t.KD . = (C vn D) interpretations let set individuals satisfying be:satI () = {x | x 6 C x DI } .Definition 3.3 Let KB = hK, DKB. interpretations J , F NC NR ,let <KB,F J iff:1. = J ;2. aI = aJ , NI ;3. AI = AJ , F NC , P = P J , P F NR ;723fiB ONATTI , FAELLA , & AURO4. KD , satI () 6 satJ () exists 0 KD 0satI ( 0 ) satJ ( 0 ) ;5. exists KD satI () satJ ().subscript KB omitted clear context. model DKB definedmaximally preferred model strong (i.e. classical) part.Definition 3.4 Let KB = hK, F NC NR . interpretation model CircF (KB)iff (classical) model KS models J KS , J 6<F I.Remark 3.5 semantics special case circumscribed DLs introduced Bonatti etal. (2006). correspondence seen (i) introducing GDI C vn fresh atomicconcept Ab, playing role abnormality predicate; (ii) replacing C vn C uAb v D;(iii) minimizing predicates Ab introduced above.order enhance readability, use following notation special casesconcept names varying case fixed: <var Circvar stand< Circ , respectively; <fix Circfix stand respectively <NC CircNC . DKBKB = hKS KD , i, say interpretation classical model KB case modelKS .paper, consider following standard reasoning tasks defeasible DLs:Knowledge base consistency Given DKB KB, decide whether CircF (KB) model.Concept consistency Given concept C DKB KB, check whether C satisfiable w.r.t. KB,is, whether model CircF (KB) exists C 6= .Subsumption Given two concepts C, DKB KB, check whether CircF (KB) |= C v D,is, whether models CircF (KB), C DI .Instance checking Given NI , concept C, DKB KB, check whether CircF (KB) |=C(a), is, whether models CircF (KB), aI C .following example illustrates tasks well main differenceCircvar Circfix .Example 3.6 Consider following simplification Example 3.2:User vn decision.{Grant}Staff v UserStaff vn decision.{Grant}BlacklistedStaff v Staff u decision.{Grant} .Extend knowledge base assertion Staff(John), let priority relation K (i.e.,priorities determined specificity). Denote resulting knowledge base KB. Dueinclusion Staff v User, GDI Staff (third line) higher priority GDI User724fiD EFEASIBLE NCLUSIONS L OW-C OMPLEXITY DL(first line). Therefore, models Circvar (KB), John belongs decision.{Grant}hence following entailments hold:Circvar (KB) |= {John} v decision.{Grant}Circvar (KB) |= decision.{Grant}(John)(subsumption)(instance checking)(1)(2)Interestingly, John belong BlacklistedStaff, way satisfying top-priority GDI Staff. Analogously, models Circvar (KB), Johnmember Staff setting maximizes number individuals satisfying GDIs(as individuals Staff vacuously satisfy GDI Staff values decision).generally, side effect maximization satI (), Circvar induces sort closedworld assumption concepts exceptional properties (w.r.t. larger concept). Consequently, BlacklistedStaff satisfiable w.r.t. KB, following subsumption holds:Circvar (KB) |= Staff v {John} .(3)contrary, Circfix , User Staff may contain number individuals (otherzero) Circfix allowed change extension atomic concept, evenwould satisfy GDIs. Similarly, exist models Circfix (KB) John belongdecision.{Grant} John belongs BlacklistedStaff Circfix allowchange extension satisfy GDIs. consequence, easily verifiedBlacklistedStaff satisfiable w.r.t. Circfix (KB), (1), (2), (3) hold Circvarreplaced Circfix . inferences as:Circfix (KB) |= User u Staff v decision.{Grant} ,(4)Circfix (KB) |= Staff u BlacklistedStaff v decision.{Grant} .(5)2Note Circvar one obtain nominals (cf. Staff (3)) without using nominals explicitlyknowledge base. axioms interfere, assertion A(a) GDI vnsuffice make singleton. idea used reductions later on.next example deals multiple inheritance, particular parent conceptsconflicting properties.Example 3.7 Let KB consist axioms:WhalevMammal u SeaAnimalMammal vn organ.LungsSeaAnimal vn organ.Gillsorgan.Lungsuorgan.Gills v ,priority relation specificity. Note mammals sea animals conflicting defaultproperties. models Circvar (KB) Whale empty, wayGDIs satisfied individuals. let KB 0 = KB {Whale(Moby)}. model725fiB ONATTI , FAELLA , & AUROCircvar (KB 0 ), Moby satisfies many GDIs possible, is, exactly one two GDIs KB 0 .consequence, reasonable inference:2Circvar (KB 0 ) |= {Moby} v organ.Lungs organ.Gills .conflict two default properties inherited Moby settled adding simpleaxiom like Whale v organ.Lungs, overrides property sea animals. specificexample strong axiom appropriate; note, however, corresponding GDI wouldeffect K ; instance, have:Circvar (KB 0 {Whale vn organ.Lungs}) |= {Moby} v organ.Lungs .Consider Circfix now. expected subsumptions Mammal v organ.Lungs SeaAnimal vorgan.Gills entailed Circfix (KB), Lungs Gills emptymodels (as Circfix cannot change extension satisfy GDIs). two GDIs couldenabled forcing Lungs Gills nonempty. done several ways, e.g. viaassertions Lungs(L) inclusions > v aux.Lungs (where aux new auxiliaryrole). Let KB 00 denote extension.Circfix (KB 00 ) |= {Moby} v organ.Lungs organ.Gills ,(similarly, aforementioned expected consequences entailed Circfix (KB 00 )). conflictproperties inherited Mammal SeaAnimal settled discussed above.2impossibility forcing existentials GDIs Circfix , illustrated example,exploited check whether concept always nonempty. suffices introduce fresh roleaux (in order prevent interference axioms knowledge base) GDI> vn aux.C. Clearly, subsumption > v aux.C entailed iff C nonempty modelsCircfix (KB). Similar ideas used rest paper.next example artificial. convenient way illustrating interplay specificitymultiple inheritance.Example 3.8 Let KB following set axioms:A1 v A01(6)A1 vn R1(12)A02(7)A2 vn R2(13)A01A02(14)A2 vBv A1 u A2(8)R1uv(9)R2uR10R20v(10)R1u R2 v(11)vnvnR10R20(15)sets concept names F , models CircF (KB), member x B (if any)satisfies exactly one top priority GDIs (12) (13), conflicting due (11). x2. symbol description logics equivalent disjunction. Formally, (C D)I = C DI .726fiD EFEASIBLE NCLUSIONS L OW-C OMPLEXITY DLsatisfy (12) satisfy conflicting GDI (14); symmetrically, x satisfy (13)x satisfy (15). Consequently, have:Circfix (KB) |= B v (R1 u R20 ) (R2 u R10 ).2last two examples show GDIs disjointness constraints together express disjointunions. Similar techniques used later simulate law excluded middle, negation,3-valued logic.Subsumption, instance checking, complement concept satisfiability reducedother, classical setting:Theorem 3.9 Let DL range DL-liteR EL ; let X = var, fix, F . CircX (DL), subsumption, instance checking, concept unsatisfiability reduced constanttime.proof completely standard, due limited expressiveness DL-liteR EL ,well peculiarities nonmonotonic reasoning.3Proof. First focus Circvar CircF , F consists concept names occurring givenKB.unsatisfiability subsumption. Checking unsatisfiability concept C reducedchecking subsumption C v . DL-liteR support explicitly, however equivalentconcept easily defined inclusion v .subsumption unsatisfiability. Conversely, subsumption C v reducedunsatisfiability C u D. DL-liteR conjunction supported, subsumption mustreduced unsatisfiability fresh variable concept axiomatized v C v D.EL conjunction supported negation not; therefore given subsumption reducedunsatisfiability C u fresh variable concept axiomatized u v .instance checking subsumption. instance checking query C(a) reducedsubsumption follows: Introduce fresh variable concept assert A(a); minimizevn ; models Circvar , AI = {aI }. follows C(a) holds iffsubsumption v C holds.unsatisfiability instance checking. Finally, unsatisfiability concept C equivalent validity instance checking problem C(a), fresh individual constant. EL , C must suitably axiomatized fresh concept name C inclusionsC u C v , > vn C, > vn C (these three axioms entail subsumption > v C C, therebyenforcing law excluded middle). order preserve semantics knowledgebase, > vn C > vn C must given priority strictly smaller prioritydefeasible inclusion KB. ensures new GDIs cannot block applicationoriginal GDIs. Clearly, two new GDIs must priority.3. example, classical logic subsumption C v logical consequence KB iff fresh individual a,D(a) logical consequence KB {C(a)}. approach correct Circumscription. modelsCircF (KB) quite different models CircF (KB {C(a)}); instance, consider examplenonmonotonic reasoning makes Whale empty assertion Whale(Moby) overrides inference.727fiB ONATTI , FAELLA , & AUROcompletes proof Circvar CircF . proof Circfix obtained replacing fresh variable concept names A, C, corresponding (variable) concept R,R fresh role.2Note reductions still apply priorities specificity-based (K ), exceptionreduction concept unsatisfiability instance checking EL . case, one useTheorem 4.6 eliminate general priorities, get reduction Circfix .4. Complexity Preserving Featurescases, nonmonotonic inferences language featurese.g. variable predicates explicit prioritiesdo affect complexity. section several results (and related lemmata)collected; reader warned that, general, may apply reasoning taskslanguage fragments. start observing logics deal enjoy finite modelproperty.Lemma 4.1 Let KB = hK, DKB DL-liteR ELHO, . F NC , CircF (KB)model CircF (KB) finite model whose size exponential size KB.Proof. simple adaptation result ALCIO (Bonatti et al., 2006), taking role hierarchiesaccount.2consequence, logics preserve classical consistency (because descending chainsmodels originating finite model must finite):Theorem 4.2 Let KB = hKD KS , DKB DL-liteR ELHO, . F NC , KS(classically) consistent iff CircF (KB) model.Remark 4.3 Obviously, similar property holds circumscribed DLs finite modelproperty, including ALCIO ALCQO.Since knowledge base consistency equivalent classical version, discussedpaper further.Next, prove mild assumptions, CircF expressive Circfix (whichspecial case former), is, variable concept names increase expressivenesslogic eliminated.4Theorem 4.4 DL description logic fully supporting unqualified existential restrictions( R),5 then, F NC , concept consistency, subsumption, instance checking CircF (DL)reduced linear time concept consistency, subsumption, instance checking (respectively) Circfix (DL).4. standard techniques eliminating variable predicates (Cadoli, Eiter, & Gottlob, 1992) use connectivesfully supported DL-liteR EL, therefore ad-hoc proof needed.5. say DL fully supports unqualified restrictions occur wherever concept name could.728fiD EFEASIBLE NCLUSIONS L OW-C OMPLEXITY DLProof. Let KB given DKB language DL. Introduce new role name RA(variable) concept name 6 F . Then, replace occurrence KB RA callKB 0 resulting KB. Recall Circfix (DL) concept names fixed roles variable. Hence, newly added roles RA behave Circfix (KB 0 ) exactly way concepts6 F CircF (KB). Formally, bijection models CircF (KB)models Circfix (KB 0 ), preserves interpretation role concept names, exceptextension concept names 6 F model CircF (KB) coincides domaincorresponding role RA corresponding model Circfix (KB 0 ). consequence, consistency concept C w.r.t. CircF (KB) equivalent consistency C 0 w.r.t. Circfix (KB 0 ),C 0 obtained C replacing occurrence 6 F corresponding RA .Similarly subsumption instance checking.2Symmetrically, next theorem proves EL fixed predicates eliminated using generalpriorities. reduction adapts classical encoding fixed predicates limited expressiveness EL .Theorem 4.5 F NC , concept consistency, subsumption, instance checkingCircF (EL ) reduced linear time concept consistency, subsumption, instance checking (respectively) Circvar (EL ) general priorities.Proof. Let K = hKS KD , given EL DKB. Fixed predicates removedfollowing transformation. concept name F introduce new concept name(representing A). Let KS set disjointness axioms u v , F . Letset defeasible inclusions > v > v A, F . Finally, let 0KDnnK , 0 . Defineminimal extension KDK0 = hKS KS KD KD, 0 .Claim 1. Let J J 0 two classical models KS KS J 0 <K0 ,var J, satJ 0 () = satJ () (ii) J J 0 agreeF , AJ = AJ . (i) KDF.maximal priority, therefore,Proof Claim 1: definition 0 , members KD0, satJ () satJ (). exists F satJ 0 (> v A) satJ (> v A),KDnn000AJ AJ , hence AJ AJ ; consequently satJ (> vn A) satJ (> vn A) (a0contradiction). Symmetrically, assumption satJ (> vn A) satJ (> vn A) leadscontradiction. proves (i); (ii) straightforward consequence (i).Claim 2. Every model CircF (K) extended model J Circvar (K0 ).prove claim, extend J setting AJ = AI , concept names F .Suppose J model Circvar (K0 ). Since J satisfies KS KS construction, mustJ 0 satisfies KS KS J 0 <K0 ,var J . Claim 1.(ii), J J 0 agreeF ; Claim 1.(i), improvement J 0 J concerns GDIs KD . follows0 <K,F I, 0 restriction J 0 language K. contradicts assumptionmodel CircF (K).Claim 3. models J Circvar (K0 ), restriction J language K modelCircF (K).Let restriction J language K. Clearly satisfies KS . supposemodel CircF (K), means exists 0 satisfying KS 0 <K,F I.729fiB ONATTI , FAELLA , & AURO00Extend 0 J 0 setting AJ = AI , concept names F . Note 0 must,agree F , therefore J J 0 agree them, too. Consequently, KD0satJ () = satJ (). Moreover, 0 improves GDIs KD , therefore J 0 improves JKD , too. follows J 0 <K0 ,var J (a contradiction).Theorem straightforward consequence Claims 2 3.2consider priority relations GDIs. going prove language fragmentsufficiently rich, simulated specificity-based relation K normalizeddefeasible inclusions vn C (whose left-hand side concept name), respectively.Let KB = hK, given DKB EL . First need define new fixed concept Domencodes domain without equivalent >. requires following transformation:= Dom u(R.C) = Dom u R.(C )> = Dom=(C u D) = C u(C v[n] D) = C v[n]Obtain K K transforming inclusions K adding nonemptiness axiom > vaux .Dom (aux fresh role) plus assertion Dom(a) NI occurring K.hard see restrictions Dom classical models K correspond classicalmodels K. precisely, let classical model K , obtain classical modelK setting AI = AI Dom RI = RI (Dom Dom ), concept namerole name R occurring K. Notice necessary Dom non-emptywork. Conversely, given classical model K, sufficient set Dom =aux = make classical model K .remove general priorities GDIs. GDIs = (C vn D) K , addtwo fresh predicates , P replace following axiom schemata:Dom vvn P0 v0P u C v(16)(17)Call new DKB KB 0 = hK0 , K0 i. (16), specificity-based relation K0 prioritizes newGDIs according original priorities. Moreover, (17), defeasible inclusion vn Psatisfied individual individual satisfies corresponding GDI .difficult verify reasoning tasks none new predicatesP occur query yield answer hK , KB 0 . consequencediscussion, combining transformation (16) (17), observingreduction makes use EL constructs only, have:Theorem 4.6 Reasoning Circfix (EL ) explicit priorities GDIs reduced polynomial time reasoning Circfix (EL ) specificity-based priority defeasible inclusions form vn P .Finally, Theorem 4.4, result extended CircF :Corollary 4.7 Reasoning CircF (EL ) explicit priorities GDIs reduced polynomial time reasoning Circfix (EL ) specificity-based priority defeasible inclusions form vn P .730fiD EFEASIBLE NCLUSIONS L OW-C OMPLEXITY DL5. Undecidability EL Fixed RolesCirc concept names roles fixed; however, show section, fixed rolesgeneral make reasoning tasks undecidable. end, model conservative extension problemdefined Lutz Wolter (2010) reduced subsumption problem.6preliminary definitions needed; given signature NC NR two interpretations J , say J coincide = J predicatesX , X = X J . Then, let T1 T2 classical EL TBoxes, T2 model conservative extension T1 every model T1 , exists model J T2 Jcoincide signature T1 .Lutz Wolter (2010) prove (see Lemma 40) exists class C EL TBoxesproblem checking whether TBox C model conservative extension another TBoxC undecidable. Moreover, following property holds.Lemma 5.1 Given two TBoxes T1 T2 C, T2 model conservative extension T1exists model T1 interpretation J T2 J coincidesignature T1 set individuals J violate least one concept inclusion T2finite.DKB KB = hKS KD , interpretation KB, denote ab KB (I) (forabnormal) total number individuals x x 6 satI () KD .Lemma 5.2 Let KB = hKS KD , DKB classical model KB s.t. ab KB (I)finite. F NC NR , either model CircF (KB) exists model JCircF (KB) J <KB,F I.Proof. suffices show <KB,F -chain descending finite. Since DIs incomparable other, step <KB,F -chain must improve least one DI leaveDIs unchanged. Formally, 0 <KB,F exists least DI KDsatI () satI 0 () 0 KD holds satI ( 0 ) satI 0 ( 0 ). Hence, ab KB (I 0 ) < ab KB (I)thesis follows.2Assume T1 , T2 C given, T1 T2 , let signature T1 . Let F =KB = hK, K = T1 {C vn | C v T2 \ T1 }.Lemma 5.3 T1 , T2 C, T2 model conservative extension T1 iff CircF (KB) |= C vD, C v T2 .Proof. [if ] Suppose contradiction T2 model conservative extension T1CircF (KB) |= C v D, C v T2 . Lemma 5.1, consider modelT1 extension J signature T2 , set individuals violate Jleast one inclusion T2 finite. Since J classical model KB ab KB (J ) finite,Lemma 5.2, exists model J 0 CircF (KB) either J 0 = J J 0 <KB,F J . SinceCircF (KB) entails T2 F = , J 0 (classical) model T2 coincides J(absurdum).6. sketch proof kindly provided Frank Wolter personal communication. imprecisionproof due authors.731fiB ONATTI , FAELLA , & AURO[only ] Suppose contradiction T2 model conservative extension T1 ,C v T2 , holds CircF (KB) 6|= C v D. Since CircF (KB) 6|= C v D, exists modelCircF (KB) satI (C vn D) . Since model T1 T2 modelconservative extension T1 , exists interpretation J (i) coincides(ii) model T2 , i.e., defeasible inclusions C vn KB, satJ (C vn D) = J .Therefore, J <KB,F (absurdum).2Since checking whether TBox model conservative extension another one provedundecidable C EL (Lutz & Wolter, 2010), immediately follows subsumptionCircF (EL) undecidable. Moreover, since subsumption reduced concept unsatisfiabilityinstance checking (Theorem 3.9), latter reasoning tasks undecidable well.Theorem 5.4 CircF (EL), subsumption, concept consistency instance checking undecidable.6. Complexity Circumscribed DL-liteRsection focus DL-liteR DKBs. first prove Circvar (DL-liteR ) reasoningtasks complete second level polynomial hierarchy. this, according Theorem 4.4, immediately obtain hardness result Circfix (DL-liteR ) too. Then, membershipCircfix (DL-liteR ) second level polynomial hierarchy shown fragment DKBsleft-fixed defeasible inclusions, i.e. defeasible inclusions type vn C.6.1 Complexity Circvar (DL-liteR )section prove Circvar (DL-liteR ) subsumption, concept unsatisfiability (co-sat)instance checking complete p2 .membership results rely possibility extracting small (polynomial) modelmodel circumscribed DKB.Lemma 6.1 Let KB DL-liteR DKB. models Circvar (KB) xexists model J Circvar (KB) (i) J , (ii) x J , (iii) DL-liteR conceptsC, x C iff x C J (iv) |J | polynomial size KB.Proof. Assume KB = hKS KD , i, model Circvar (KB), x . Let cl(KB)set concepts occurring KB. Choose minimal set containing: (i) x, (ii)aI NI cl(KB), (iii) concept R cl(KB) satisfied I, node yRz RI , (z, yR ) RI .define J follows: (i) J = , (ii) aJ = aI (for NI cl(KB)), (iii) AJ = AI(A NC cl(KB)), (iv) P J = {(z, yP ) | z z P } {(yP , z) | z zP } (P NR ).Note construction, z J C cl(KB), z C J iff z C ;consequently, J classical model S. Moreover, cardinality J linear sizeKB (by construction). left show J <KD ,var -minimal model KB.00Suppose not, consider J 0 <KD ,var J . Define 0 follows: (i) = , (ii) aI =00000aI , (iii) AI = AJ , (iv) P = P J . Note elements \J satisfy left-hand sideDL-liteR inclusion (be classical defeasible), therefore inclusions vacuously satisfied.732fiD EFEASIBLE NCLUSIONS L OW-C OMPLEXITY DL0Moreover, restriction 0 J <KD ,var -smaller corresponding restrictioninterpretation ordering. follows 0 <KD ,var I, hence cannot modelCircvar (KB) (a contradiction).22xQx1CS,1QQQ43CQ6Q46C v QQ vvn578(b) model K.(a) DKB K.78(c) small model extractedmodel Figure 2(b). Dashedarrows denote edgespresent I.Figure 2: Illustrating Lemma 6.1.illustrate Lemma 6.1, consider DKB KB Figure 2(a) model Figure 2(b).Note individuals satisfy defeasible inclusion KB. small model J , depictedFigure 2(c), obtained follows. First, contains designated individual x; then,concept R occurs KB satisfied (where R possibly inverse role), containsrepresentative yR receives role R I. case, assume chosen representatives are:yQ = 6, yQ = 4, yS = 8, yT = 7. Hence, J = {x, 6, 4, 8, 7}. roles J obtainedconnecting individual z satisfies concept P chosen representative yP .instance, since 4 satisfies I, edge (4, 8) J . Moreover, representativeinverse role P connected nodes satisfy concept P I. case, since4 representative Q 6 satisfies Q , edge (4, 6) QJ . Besides, since 4satisfies Q , also (4, 4) QJ . verified inspection J modelCircvar (KB), individuals satisfy classical defeasible inclusions KB.Theorem 6.2 Concept consistency Circvar (DL-liteR ) DKBs p2 . Subsumption instance checking p2 .Proof. Lemma 6.1, suffices guess polynomial size model provides answergiven reasoning problem. Then, NP oracle, possible check model minimalw.r.t. <var .2complexity upper bounds proved Theorem 6.2 fact tight, stated Theorem 6.6.proof hardness based reduction minimal-entailment problem positivedisjunctive logic programs proved p2 -hard (Eiter & Gottlob, 1995).clause formula l1 lh , li literals set propositional variablesP V = {p1 , . . . , pn }. positive disjunctive logic program (PDLP short) set clauses733fiB ONATTI , FAELLA , & AURO= {c1 , . . . , cm } cj contains least one positive literal. truth valuationset P V , containing propositional variables true. truth valuation modelsatisfies clauses S. literal l, write |=min l every minimal7 modelsatisfies l. minimal-entailment problem defined follows: given PDLPliteral l, determine whether |=min l.propositional variable pi , 1 n, introduce two concept names Pi Pi ,latter encodes pi . denote Lj , 1 j 2n, generic Pi Pi . clause cjintroduce concept name Cj . Then, two concept names True False representset true false literals, respectively. employ roles RLi , RTrueCj , RFalse Pi , RTrue Pi ,TLi .following, defeasible inclusions assigned numerical priority h(), intended meaning 1 2 iff h(1 ) < h(2 ).first step consists reifying propositional literals, i.e., wantcorrespond individual. Therefore, introduce axioms:NonEmpty(a)(18)NonEmpty v Li(1 2n)(19)NonEmpty v RLi(1 2n)(20)(1 2n)(21)Li v Lj(1 < j 2n)(22)Li vn Li(1 2n)(23)RLv Li[priority: 0]Axioms (18-21) force literal encodings Li non empty. Axioms (22) make literal encodingspairwise disjoint. Finally, defeasible inclusions (23) used reduce Li singletons.Then, represent set clauses adding clause cj = lj1 ljk , 1 j m,following axioms.Lji v Cj(1 k)(24)Cj vn Cj[priority: 0](25)NonEmpty v RTrueCj(26)RTrueCj(27)v TrueCjTrueCj v True(28)TrueCj v Cj(29)Axioms (2425) ensure (encoding a) clause Cj union literals Lji . Axioms(2629) assure clause contains least one true literal. order model concepts7. respect set inclusion.734fiD EFEASIBLE NCLUSIONS L OW-C OMPLEXITY DLTrue False correct meaning complementary literals add following axioms.True v False(30)TruePi v RFalse Pi(1 n)(31)(1 n)(32)TruePi v Pi(1 n)(33)TruePi v True(1 n)(34)False Pi v False(1 n)(35)False Pi v Pi(1 n)(36)RFalse Piv False Piprevious schemata regard TruePi only; analogous schemata defined FalsePi .following inclusions ensure truth given literal locally visible individual a,auxiliary roles TLi .TrueLi v TL(1 2n)(37)TL(1 2n)(38)(1 2n)(39)TrueLi wTLi v NonEmptyaxioms defined far encode classical semantics S. represent minimal modelsadd following axioms.Pi vn FalsePi(1 n)[priority: 1](40)Pi vn TruePi(1 n)[priority: 2](41)Given PDLP S, call KB defined KB .Given truth assignment P V domain = {a, d1 , . . . , d2n }, define corresponding interpretation, denoted model (S, I, ), whose structure mirrors I. Formally, model (S, I, )interpretation = (, ) that:I. aI = a;II. NonEmpty = {a};III. RLIi = {(a, di )} LIi = {(a, di ) | |= li };IV. 1 2n, LIi = {di };V. 1 j m, CjI = {LIj1 , . . . , LIjh } cj = lj1 ljh ;VI. 1 2n, di TrueLIi (resp. di FalseLIi ) iff |= li (resp. 6 |=li );VII. (X )I = X , X concept name obtained concatenating twoconcept names X (for instance, concept name TrueCj obtained concatenatingconcept names True Cj ); words, juxtaposition represents conjunction;VIII. (R X )I = (X )I .following lemma, proved Appendix, states relationship model (S, I, ).735fiB ONATTI , FAELLA , & AUROLemma 6.3 Given PDLP P V = {p1 , . . . , pn } truth assignment P V ,minimal model iff interpretation model (S, I, ) model Circvar (KB ),domains || = 2n + 1.following result, also proved Appendix, shows model Circvar (KB ) factcorresponds minimal model S.Lemma 6.4 model Circvar (KB ), exist minimal modelpi iff PiI True iff PiI False , = 1, . . . , n.Lemma 6.5 Given PDLP literal l represented concept name L, followingequivalent:(minimal entailment) |=min l;(subsumption) Circvar (KB ) |= L v True;(co-sat) FalseL satisfiable w.r.t Circvar (KB );(instance checking) Circvar (KB ) |= (T L)(a).Proof. three inference problems KB represent fact models Circvar (KB )LI True empty co-sat particular relies fact Circvar (KB )models True False partition individuals belonging literal concepts. Therefore, suffices prove l true minimal models iff LI True 6= modelsCircvar (KB ).Lemma 6.3 establishes bijection minimal models certain models =model (S, I, ) Circvar (KB ), truth literal l corresponds inclusionLI True (see rule VI definition model ). Therefore, right-to-left directionimmediately satisfied. left-to-right direction, assume l true minimal modelslet model Circvar (KB ). Lemma 6.4, minimal modelpi iff PiI True . l = pi , conclude LI True thesis. Similarly, l = pi .2following theorem provides complexity lower-bounds main decision problemsCircvar (DL-liteR ) Circfix (DL-liteR ). result Circvar (DL-liteR ) follows immediatelyLemma 6.5, extends Circfix (DL-liteR ) due Theorem 4.4.Theorem 6.6 Subsumption, co-sat instance checking circumscribed DL-liteR DKBsgeneral priorities p2 -hard.6.2 Upper Bound Circfix (DL-liteR ) Restrictionsdevelop argument used Circvar (DL-liteR ) prove similar upper boundsCircfix (DL-liteR ) DKBs left-fixed DIs (i.e., left-hand side fixed orequivalentlyconcept name) empty priority relations. Whether upper bounds applyCircfix (DL-liteR ) without restriction left open question.736fiD EFEASIBLE NCLUSIONS L OW-C OMPLEXITY DLLemma 6.7 Let KB DL-liteR knowledge base whose DIs left-fixed. modelsCircfix (KB) x exists model J Circfix (KB) (i) J , (ii)x J , (iii) DL-liteR concepts C, x C iff x C J , (iv) |J | polynomialsize KB.Proof. Assume model Circfix (KB), KB = hKS KD , i, x . Letcl(KB) set concepts occurring KB. Choose minimal set containing: (i)x, (ii) aI NI cl(KB), (iii) concept R cl(KB) satisfied I, nodeyR yR (R )I (where P considered equivalent P ), finally (iv)inclusions C v[n] R KB (C u R)I 6= , node z (C u R)I .define J follows: (i) J = , (ii) aJ = aI (for NI cl(KB)), (iii) AJ = AI(A NC cl(KB)), (iv) P J = {(z, yP ) | z z P } {(yP , z) | z zP } (P NR ).Note construction, z J C cl(KB), z C J iff z C ;consequently, J classical model KB. Moreover, cardinality J linear sizeKB (by construction). left show J <fix -minimal model KB.00Suppose not, consider J 0 <fix J . Define 0 follows: (a) = , (b) aI = aI ,0000(c) AI = AI , (d) RI minimal set (d1) RI RJ , (d2) z \ J ,0inclusions C v R C vn R KB z (C u R)I , RJ contains pair00(v, w), (z, w) RI ; finally, (d3) P closed role inclusion axioms KB.Note that, construction,0(*) z \ J , z RI z RI ;000(**) z \ J , z RI exists v J v RJ .prove 0 classical model KB. construction, edges (z, w) introduced(d2) change set existential restrictions satisfied members J ; consequence since J 0 model KB members J satisfy classical CIsKB.consider arbitrary element z \J CI KS . inclusion withoutexistential quantifiers, 0 give interpretation definition, therefore zsatisfies . R v A, R v A, R v S, v R (and considering satisfies0) z fails satisfy R0 {R, S}, z 6 (R0 )I z (R0 )I ; impossible00(*). Next, suppose R v S. z (R)I , (**) exists v J satisfying000(R)J hence (S)J (as J 0 model KS ), therefore z (S)I (by d2). left00consider = v R: z AI = AI , exists wA AJ (by construction )00wA (R)J J 0 model KB. z (R)I (d2). Therefore, possiblecases, z satisfies .proves 0 satisfies strong CIs KB. hard verify 0 satisfiesalso role inclusions KB. Therefore, order derive contradiction, left show0 <fix (which implies model Circfix (KB)). Since assumption J 0 <fix J ,suffices prove following claim: satJ () satJ 0 () (resp. satJ () satJ 0 ()),satI () satI 0 () (resp. satI () satI 0 ()).J , J (resp. 0 J 0 ) satisfy concepts, therefore need showz \ J , z satI () z satI 0 (). cases737fiB ONATTI , FAELLA , & AUROright-hand side R, proof similar proof strong CIs (it exploits (*) factconcept names fixed).Let vn R consider arbitrary z \ J z satI (). Since conceptnames fixed, interesting case z actively satisfies , i.e. z (A u R)I .construction, contains individual v (A u R)J . Since hypothesis satJ () satJ 0 (),00v (A u R)J hence, (d2), z (R)I , z satI 0 ().2prove lemma assumption priority relation empty needpreliminary notions. Given KB KB = hKS KD , i, interpretation individualz , denote KB [z] classical knowledge base:KB [z] = KS C v | (C vn D) KD z satI (C vn D)Then, support concept C I, supp (C), set individuals z that,A, z AI vKB[z] C. z supp (C) say z supports C I.Lemma 6.8 Let KB = hK, DL-liteR knowledge base. models Circfix (KB)x exists model J Circfix (KB) (i) J , (ii) x J , (iii)DL-liteR concepts C, x C iff x C J , (iv) |J | polynomial size KB.Proof. Assume model Circfix (KB) let defined proofLemma 6.7, except case (iv), replaced by: (iv) inclusions C v[n] R KBsupp (R) 6= , node wR supp (R). is, inclusion whose RHSvariable, pick witness support RHS, witness exists.Next, define J proof Lemma 6.7. before, J classical model KBcardinality J linear size KB. left show J <fix -minimal.Suppose not, consider J 0 <fix J . Since priority relation empty, DIs KB,satJ () satJ 0 (). Hence, concepts C holds supp J (C) supp J 0 (C). Define 0proof Lemma 6.7, except case (d2), replaced by: (d2) z \ J ,0inclusions C v[n] R KB z supp (R), RJ contains pair (v, w),0(z, w) RI . prove 0 <fix I, contradicting hypothesis model00Circfix (KB). non-trivial case consists proving individuals \ J satisfy0 inclusions type C v[n] satisfy I.00Assume z \ J satisfies C v[n] I; distinguish two cases. First,0z supp (S), J contains witness wS s.t. wS supp J (S) supp J 0 (S).00Therefore, exists pair (wS , y) J and, (d2), (z, y) . Second, assumez 6 supp (S). Since z satI (C v[n] D), z 6 supp (C). Therefore, C = A,00z 6 AI = AI , whereas C = R, (d2) z 6 (R)I . cases, z vacuouslysatisfies 0 .2Theorem 6.9 Let KB DKB left-fixed DIs empty priority relation. Concept consistency Circfix (KB) p2 . Subsumption instance checking p2 .2Proof. Similar proof Theorem 6.2.738fiD EFEASIBLE NCLUSIONS L OW-C OMPLEXITY DL7. Complexity Circumscribed EL ELRecall reasoning circumscribed EL undecidable roles fixed. analyzecases, F NC .EL, cannot express contradictions, defeasible inclusions cannot possibly blockedCircvar , circumscription collapses classical reasoning:Theorem 7.1 Let KB = hKS KD , EL DKB. model Circvar (KB) iffmodel KS KD , KD = {A v C | (A vn C) KD }.Proof. Let model Circvar (KB), let J interpretation (i) J = ,(ii) NI , aJ = aI , (iii) NC , AJ = J , (iv) P NR , P J =J J . easily verified structural induction EL concepts C, C J = Jhence domain element J satisfies EL inclusions (strong defeasible). Then,clearly, J model Circvar (KB). Consequently, KD , satI () = , otherwiseJ <var (a contradiction). follows classical model KS KD .2results work Baader et al. (2005), follows Circvar (EL), concept satisfiabilitytrivial, subsumption instance checking P.Remark 7.2 Clearly, argument result apply Circvar (ELHO).make EL interesting adding source inconsistency, complexityincreases significantly.Theorem 7.3 Circvar (EL ), concept satisfiability, instance checking, subsumptionExpTime-hard. results still hold knowledge bases contain assertion.8Proof. Let ELA extension EL atomic concepts negated. first reduceTBox satisfiability ELA (which known ExpTime-hard, see Baader et al., 2005)complement subsumption Circvar (EL ). Let TBox (i.e., set CIs) ELA . Firstintroduce concept name occurring fresh concept name whose intended meaningA. Obtain 0 replacing literal A. Let KB = hK, K DKBobtained extending 0 following inclusions, U UA occurringfresh concept names (representing undefined truth values), R fresh role name:u v(42)> vn(46)u UA v(43)> vn(47)u UA v(44)> vn UA(48)UA v U(45)> vn R.UA(49)prove satisfiable iff model Circvar (KB) UA empty, holdsiff Circvar (KB) 6|= > v R.U . Consequently, subsumption Circvar (EL ) ExpTime-hard. Assume satisfiable model domain . define interpretation8. Equivalently, DLs terminology: ABoxes empty.739fiB ONATTI , FAELLA , & AUROJ model Circvar (KB) U J = , thus proving Circvar (KB) 6|= > v R.U .J domain I, concepts roles occurring interpretationI; need define interpretation newly introduced concepts A, UA , U ,role R. set AJ = \ AI UAJ = U J = RJ = .construction J model classical inclusions KB, particular CIs (42)(45).remains prove J minimal w.r.t. <var , i.e., possible improve DI withoutviolating another DI either incomparable , higher priority . Noticedefeasible inclusions (46) (resp., (47)) violated individuals AJ (resp., individualsAJ ). DIs (48) (49) violated individuals. Moreover, notice DIs (46)(49)mutually incomparable according specificity.DI type (46) (47) improved expenses corresponding DItype. Moreover, improving DIs (48) (49) requires setting UAJ 6= , which, duerules (43) (44) would damage incomparable DIs (46) and/or (47). proves Jmodel Circvar (KB), hence Circvar (KB) 6|= > v R.U .Conversely, assume Circvar (KB) 6|= > v R.U , let model Circvar (KB)individual x x 6 (R.U )I . Due rule (45), x 6 (R.UA )I atomicconcepts A. Hence, x violates DIs type (49). exists concept UA (UA )Iempty, model obtained adding R-edge x individual (UA )Ismaller according <var , contradiction. Therefore, concepts UA emptyI.Next, show atomic concepts individuals , either AIAI . Assume contrary, i.e., exists individual belongs neither AIAI . Then, violates DIs (46)(49). Consider interpretation 0 , obtained setting00(UA )I = U = {y}. construction 0 satisfies CIs KB. Compared I, statusDIs same, except 0 individual satisfies (48). Hence, 0 <var I,contradiction. Since individual belongs either AI AI , convert classicalmodel , thus showing satisfiable.Similarly, given NI , satisfiable iff exists model Circvar (KB)aI 6 (R.U )I . Therefore, instance checking Circvar (EL ) ExpTime-hard well.Finally, add fresh concept name B inclusions B u R.UA v ; call newDKB KB 0 . Note satisfiable iff model Circvar (KB) UA empty,holds iff B satisfiable w.r.t. Circvar (KB 0 ). Consequently, concept satisfiability Circvar (EL )ExpTime-hard.2Since Circvar special case CircF , Theorem 4.4, theorem applies CircFCircfix , too:Corollary 7.4 X = F, fix, concept satisfiability checking, instance checking, subsumptionCircX (EL ) ExpTime-hard. results still hold ABoxes empty (i.e. assertionsallowed).Fixed concept names play role similar , proof adaptedCircF (EL).Theorem 7.5 Instance checking subsumption ExpTime-hard CircF (EL)Circfix (EL). holds restriction EL supporting >.740fiD EFEASIBLE NCLUSIONS L OW-C OMPLEXITY DLProof. reduce satisfiability ELA TBox complement subsumption CircF (EL).First introduce new concept name representing > translate concept CELA corresponding C EL, follows:C = C C concept name;C = C (for A, new concept name);C = u R.(C1 u D) C R.C1 ;C = C1 u C2 C C1 u C2 .C1 v C2 translated C1 v C2 . extend translated TBoxfollowing inclusions, Bot (representing ), UA s, Bad new concept names Rnew role name:UAvvv(50)vn UA(58)(51)0(59)(52)0vn R.UA (60)0vn R.Bot (61)vuvBot (53)u UAvBot (54)R.UAvBad(62)u UAvBot (55)R.BotvBad(63)vn(56)vn(57)D(a) (ABox assertion) (64)Let KB = hK, K resulting DKB, set F = {D, Bot}. prove following threeproperties equivalent: (i) satisfiable, (ii) CircF (KB) 6|= v Bad , (iii) CircF (KB) 6|=Bad (a).Let us prove (ii) implies (i). Let model CircF (KB) individual x s.t.x DI x 6 Bad . (62)(63), x 6 (R.UA )I A, x 6 (R.Bad )I . (59),x (D0 )I . Hence, x violates DIs (60) (61). Assume least one concept UA empty(resp., Bot empty I). Then, improved (according <F ) connectingR-edge individual x non-empty concept UA (resp., Bot), adding x Bad(notice Bad variable concept). contradiction, conclude BotUA empty I. Then, prove restriction domain DI model .Inclusions (50)(51) ensure individuals satisfying either DI . DIs (56)(57), together fact UA empty, guarantee individual DI satisfieseither A, concept names A. Rules (53), together fact Bot empty,guarantee individual satisfies A. translation C C completesclaim.Next, show (i) implies (ii). Let model . extend become modelJ CircF (KB) DJ 6 Bad J , DJ 6= Bad J = . A, setAJ = \ AI UAJ = . Then, set DJ = (D0 )J = J = Bot J = Bad J = .easy verify J satisfies CIs KB. remains prove J minimal w.r.t. <F .741fiB ONATTI , FAELLA , & AURONameRestrictionsfull left local (LLf )almost left local (aLL)qualified existentials LHS inclusionsunion LLf KB classical acyclic terminology, s.t. unfoldingformer w.r.t. latter produces LLf KBv[n] P.B A1 u A2 v Bfollowing schemata:P v BP1 v P2 .B(no nesting; conflicts DIs Circfix )v[n] P.B P1 u P2 v P3 .Bfollowing schemata:P v B(no nesting; potential conflicts DIs even Circfix )left local (LL)LL2Figure 3: Fragments EL considered Section 7.Since Bot fixed concept, inclusions (53)(55) ensure A, UA mutually exclusive, concepts A. Hence, DI type (56)(58) improved expensesanother DI incomparable priority, count improvement according <F .DI (61) cannot improved Bot empty fixed. Finally, suppose one tries improveone DIs type (60). so, least one individual x must enter concept UA . Duemutual exclusion property described earlier, x needs exit (resp. A), thus violatingDI (56) (resp., (57)), higher priority (60) due (59).equivalence (i) (iii) proved along similar lines. noticefact (64) makes Bad (a) equivalent inclusion v Bad . thesis Circfix obtainedconsequence Theorem 4.4.2Concept consistency simpler, instead. Call interpretation complete iff NC ,AI = , P NR , P = . hard verify EL conceptsEL inclusions (both classical defeasible) satisfied x , therefore complete modelsalways models CircF (KB), DKBs KB F NC . consequenceconcept consistency trivial:Theorem 7.6 EL concepts C, DKBs KB, F NC , C satisfied modelCircF (KB).7.1 Left Local EL Circvarsubsection next one, prove qualified existentials left-hand sideinclusions responsible higher complexity EL w.r.t. DL-liteR . particular, qualifiedexistentials left-hand side make proof strategy Lemma 6.7 fail: targetedge starts x redirected, individual x may satisfy qualified existential restrictionsatisfy before. so, truth value inclusions may affected. limitingoccurrences qualified existential restrictions left-hand side inclusions, possiblereduce significantly complexity instance checking subsumption circumscribed EL .Figure 3 summarizes syntactic fragments EL consider. start followingclass knowledge bases:Definition 7.7 defeasible knowledge base hK, full left local (LLf ) fragment ELiff left-hand sides inclusions K contain qualified existential restrictions.742fiD EFEASIBLE NCLUSIONS L OW-C OMPLEXITY DLNote restriction rules acyclic terminologies containing qualified existentialrestriction, hence existing ontologies practical interest. Therefore, introducefollowing relaxation LLf EL :Definition 7.8 EL knowledge base KB = hK, almost (aLL short) iff (i) K =KLL Ka , (ii) KLL LLf , (iii) Ka classical acyclic terminology, (iv) concept namedefined Ka occurs left-hand side inclusion KLL , depend (inKa ) qualified existential restriction.words, unfolding KLL respect Ka , obtain LLf knowledge base.Example 7.9 Example 3.1 reformulated EL :Human vn lhs heart ;lhs heart u rhs heart v ;Situs Inversus Human u rhs heart .KLL consists first two axioms Ka consists third axiom. Note that, general,concept name occurring terminology extended default properties meansinclusion vn C following cases: primitive concept (with definition ),concept partially defined one-way inclusion (e.g. Human v Mammal), even conceptcomplete definition , provided depend qualified existentials.Accordingly, example, could add defeasible inclusion like Situs Inversus vn C,would permitted definition situs inversus depended qualified existentialrestrictionsSitus Inversus Human u heart. position. Right .2small model property similar Lemma 6.7 proved Circvar (aLL EL ) providedright-hand side subsumption queries bounded quantifier depth. convenientsplit proof proof LLf EL later extend EL .Since LLf EL RHS inclusion may nested qualified existential restrictions,difficult prove small model property considering entire language. reason,prove indirectly: first show transform knowledge base KB another KByields following properties: (i) nested formulas occur, (ii) defeasible inclusionstype vn B, (iii) every model Circvar (KB) extended model Circvar (KB )domain (iv) every model Circvar (KB ) model Circvar (KB). Then, provesmall model property fragment nesting and, thanks properties (iii) (iv),recover small model property entire language.LLf EL inclusion C v[n] transformed three steps. Note Cs shape is:A1 u . . . u u R1 u . . . u Rm .first step, C replaced fresh concept name F0 (for convenience, later refer F0also FC ) following axioms added:Fi v Ai+1 u . . . u u R1 u . . . u RmAi+1 u Fi+1 v Fi743(0 n 1)(65)(0 n 2)(66)fiB ONATTI , FAELLA , & AURO= 0, i.e., existentials C, add inclusion:v Fn1(67)Otherwise, add following inclusions:u G0 v Fn1(68)Gj v Rj+1 u . . . u Rm (0 j 1)Bj+1 u Gj+1 v Gj(0 j 2)Bm v Gm1(69)(70)(71)Bj v RjRj v Bj(1 j m)(72)(1 j m)(73)Fi , Gj Bj fresh concept names.point, initial inclusion C v[n] replaced FC v[n] D. eliminatenesting D, second step replace fresh concept name FD add inclusionFD v , recursively defined=(74)(C u D) = C u(R.H) = R.FH(75)add FH v H , FH fresh.(76)Finally, third step, inclusions type v D1 u . . . u Dh split v Di ,1 h. resulting knowledge base, denote KB , consists instancesfollowing axiom schemata:v[n] Bv P.BA1 u A2 v BP v Bprove properties (iii) (iv) mentioned above.Lemma 7.10 Every model Circvar (KB) extended model Circvar (KB )domain.Proof. First, note inclusions (65)(73) definitorial, every interpretation KBexactly one extension satisfies them. extension, simplicity continue call I,obtained setting FiI = (Ai+1 u . . . u u R1 u . . . u Rm )I , GIj = (Rj+1 u . . . u Rm )IBjI = (Rj )I .Then, extend recursively setting FHI = H , fresh concept FH introducedstep 2. straightforward see structural induction H (H )I = H , henceinclusions step 2 3 satisfied. Thus, classical model KB, alsoclassical model KB .Assume model Circvar (KB), show minimal alsorespect KB . Suppose not, let J classical model KB J <KB ,var I.structural induction straightforward see C v[n] KB, (D )J DJ . SinceFCJ = C J holds fresh concept names FC occurring LHS rule,inclusion C v[n] KB, satJ (FC v[n] FD ) satJ (C v[n] D) implies J744fiD EFEASIBLE NCLUSIONS L OW-C OMPLEXITY DLclassical model KB. Concerning I, every C v[n] KB, (FC )I = C(FD )I = DI construction, satI (C v[n] D) = satI (FC v[n] FD ).previous arguments entail satI (FC v[n] FD ) satJ (FC v[n] FD ) (respectivelysatI (FC v[n] FD ) satJ (FC v[n] FD )), satI (C v[n] D) satJ (C v[n] D) (resp.satI (C v[n] D) satJ (C v[n] D)). Therefore, would follow J <KB,var I,contradicts hypothesis.2Lemma 7.11 models Circvar (KB ) models Circvar (KB).Proof. proof similar Lemma 7.10, particular already know (i) individualsatisfies inclusion FC v[n] FD KB , satisfies C v[n] D, (ii) classical model JKB extended way satJ (C v[n] D) = satJ (FC v[n] FD ), (possiblydefeasible) inclusion KB. this, every classical model KB classicalmodel KB and, assuming classical model J KB improves (i.e. J <KB,var I),follows J extended classical model KB J <KB ,var I.2following result, whose proof found Appendix, represents small modelproperty LLf EL , uses transformation KB KB .Lemma 7.12 Let KB = hK, K LLf EL knowledge base, C, EL concepts.models Circvar (KB) x C \ DI exists model J Circvar (KB)(i) J , (ii) x C J \DJ , (iii) |J | O((|KB|2 +|C|)d ), = depth(D)+1.extend result EL . First, show conditionsconcept names defined Ka removed unfolding them, using unf operator definedSection 2. proofs following two propositions found Appendix.Proposition 7.13 Let KB = hKLL Ka , EL knowledge base. Every modelCircF (unf(KB)) extended model CircF (KB).converse holds defined predicates variable. reason addingdefinition like P fixed, one fixes expression P , too, thereby changingsemantics.Proposition 7.14 Let KB = hKLL Ka , EL knowledge base supposeconcept names defined Ka variable. Then, models CircF (KB), restrictionprimitive predicates model CircF (unf(KB)).lemmata prove:Lemma 7.15 Let KB = hK, K EL knowledge base (where K = Ka KLL )let C, EL concepts. models Circvar (KB) x C \ DIexists model J Circvar (KB) (i) J , (ii) x C J \ DJ , (iii) |J |O((|KB|2 + |C|)d ), = depth(D) + 1 + |Ka |2 .745fiB ONATTI , FAELLA , & AUROProof. Let Circvar (KB) x C \ DI . Let KB 0 = unf(KB), C 0 = unf(C, Ka ), D0 =unf(D, Ka ). Notice KB 0 LLf knowledge base. Proposition 7.14, restriction 000primitive predicates model Circvar (KB 0 ). particular, holds x (C 0 )I \(D0 )I .applying Lemma 7.12 KB 0 , C 0 , D0 , 0 , obtain exists model J Circvar (KB 0 )0x (C 0 )J \(D0 )J |J | O((|KB 0 |2 +|C 0 |)d ), d0 = depth(D0 )+1.|KB 0 |2 + |C 0 | |KB|2 + |C|, since replacing defined terms definitionsdecreasePtotal number subformulas. Finally, depth(D0 ) depth(D) + (AE)Ka depth(E)depth(D) + |Ka |2 , hence thesis.2Consequently that:Theorem 7.16 Circvar (aLL EL ) concept satisfiability p2 . Moreover, deciding EL subsumptions C v instance checking problems D(a) constant bound quantifierdepth Ds unfolding w.r.t. given DKB p2 .2Proof. Similar proof Theorem 6.2.Currently, know whether bound quantifier nesting necessary uppercomplexity bounds.Next prove p2 p2 upper bounds Circvar tight. Actually, much simplerfragment suffices reach complexity:Definition 7.17 EL knowledge base left local (LL) concept inclusions instancesfollowing schemata:v[n] P.BA1 u A2 v BP v BP1 v P2 .B ,B either concept names . EL concept concept occurinclusions.Schema v[n] B emulated EL inclusions v[n] R, R v BB v R, fresh role R. Note similarity schemata normal form ELinclusions (Baader et al., 2005) that, however, would allow general inclusions P.A v BP1 .A v P2 .B (that forbidden left locality).prove reasoning Circvar (LL EL ) hard (and hence complete) p2 p2 .purpose, provide reduction minimal entailment positive, propositionaldisjunctive logic programs (PDLP), defined Section 6.1. propositional variable pi ,1 n, introduce two concept names Pi Pi latter encodes pi . followingdenote Lj , 1 j 2n, generic Pi Pi . clause cj introduce conceptname Cj . Then, two concept names True False represent set true false literalsrespectively. Finally, concept names Lit Min used model minimal propositionalassignments; need also auxiliary role R.First, literals reified, i.e. modeled individuals, axioms:> v R.LiLi u Lj vLi vn746(1 2n)(77)(1 < j 2n)(78)(1 2n)(79)fiD EFEASIBLE NCLUSIONS L OW-C OMPLEXITY DLfirst axiom makes Li nonempty. Axioms (78) make pairwise disjoint. Finally, axioms(79) minimize concepts Li make singletons. Then, represent addingclause cj = lj1 ljh , 1 j m, axiomsLji v Cj(1 j 1 h)(80)Cj vn(1 j m)(81)> v R.(Cj u True) (1 j m)(82)axioms (80) (81), Cj equals set (encodings of) literals cj . Axioms (82) make sureclause holds.order model concepts True False correct meaning complementaryliterals add axiomsTrue u False v(83)Pi u True v R.(Pi u False) (1 n)(84)Pi u False v R.(Pi u True) (1 n)(85)Pi u True v R.(Pi u False) (1 n)(86)Pi u False v R.(Pi u True) (1 n)(87)axioms defined far encode classical semantics S. minimize models, add following axioms:Min u Pi v False (1 n)(88)Min u Pi v True(1 n)(89)Li v Lit(1 2n)(90)Cj v Lit(1 j m)(91)Lit vn Min(92)(88) (89), Min collects false positive literals true negative literals. (90) (91),Lit contains (representations of) literals clauses. purpose axioms givingdefeasible inclusions (79) (81) higher (specificity-based) priority (92), model minimization cannot cause Li larger singleton, Cj different setliterals cj . (92) prefers models many Pi possible False.following, given PDLP S, let KB Tbox defined above.Lemma 7.18 Given PDLP S, literal l Ss language, encoding L l, followingequivalent:(minimal entailment) |=min l;(subsumption) Circvar (KB ) |= > v R.(True u L);(co-sat) False u L satisfiable w.r.t Circvar (KB );(instance checking) Circvar (KB ) |= (R.(True u L))(a).lemma proved analogy proof Lemma 6.5; details left reader.conjunctions (u) nested easily replaced new atom addingequivalence True u L, encoded EL , have:747fiB ONATTI , FAELLA , & AUROTheorem 7.19 Subsumption instance checking Circvar (LL EL ) p2 -hard; conceptsatisfiability p2 -hard. results hold even three reasoning tasks restrictedEL concepts, priorities specificity-based.7.2 Left Local EL Circfixreduction validity problem quantified Boolean formula, showCircfix (aLL EL ) complex Circvar (aLL EL ), unless polynomial hierarchy collapses. Computing truth quantified Boolean formula= Q1 p1 . . . Qn pn .(where Qi quantifiers) reduced polynomial time subsumption checkingCircfix (aLL EL ) follows. Introduce concept names A0 , . . . , , Ti Fi = 1 . . . n,concept names Eij 1 < j n. Introduce role names R, bad , good , Ui = 1 . . . n.define aLLEL knowledge base hK, K i, K = KLL Ka . left-local part KLLconsists following groups axioms. Notice that, following description, alwaysarbitrary index {1, . . . , n}. First, encode negation normal form . Let Bpi = TiBpi = Fi . subformulas F G introduce new concept name BF G addinclusion BF u BG v BF G . subformulas F G introduce new concept name BF Gadd inclusions BF v BF G BG v BF G .second group axioms KLL constrains Ti Fi avoid inconsistencies. IntuitivelyUi means pi undefined:Ti u Fi v(93)Ti u Ui v(94)Fi u Ui v(95)third group axioms KLL defines tree encodes truth assignments neededevaluate QBF:6= jAi u Aj v(96)s.t. Qi =Ai1 v R.(Ti u Ai ) u R.(Fi u Ai )(97)s.t. Qi =Ai1 v R.Ai(98)fourth group axioms KLL detects misrepresentations forcing role bad pointnodes evaluation tree something going wrong (i.e. truth assignmentincomplete, predicate changes value along branch, false leaf).> vn bad .Ui(99)bad .Eijbad .Eij(101)> vn bad .(B u )(102)> vn> vn(Eij Eij defined Ka below). Finally, good captures absence bad :748(100)fiD EFEASIBLE NCLUSIONS L OW-C OMPLEXITY DLbad u good v .(103)acyclic terminology Ka purpose detecting whether propositional symbolchanges value along path:EijAj1 u Ti u R.(Aj u Fi )(104)EijAj1 u Fi u R.(Aj u Ti ) .(105)Lemma 7.20 Let model Circfix (KB) satisfies A0 u good . = 1 . . . n,individuals contained either TiI FiI .Proof. First, contradiction, assume = 1 . . . n x Ii , x neither FiITiI . Since axioms (93)-(95) prevent x satisfying Ui must minimal w.r.t.axiom (99), entire domain satisfies bad .Ui . However, axiom (103), meansA0 u good unsatisfiable hypothesis.2Lemma 7.21 Let model Circfix (KB) satisfies A0 u good . = 1 . . . n,xi (Ai u Ti )I (respectively, x (Ai u Fi )I ), paths {xi , xi+1 , . . . , xn } xj Aj(xj1 , xj ) RI , < j n, contained TiI (resp., FiI ).Proof. Assume xi (Ai uTi )I {xi , xi+1 , . . . , xn } 6 TiI . means xi 6= xn< j n, xj1 (Aj1 u Ti )I xj (Aj1 u Fi )I . Then, axiom (104), xj1 Eijsince must minimal w.r.t. axiom (100) entire domain satisfies bad .Eij . However,axiom (103), means A0 u good unsatisfiable hypothesis.2Theorem 7.22 Concept satisfiability, subsumption checking, instance checking PSPACEhard Circfix (aLL EL ). result still holds nesting level existential restrictionsbounded constant, priority relation empty.Proof. order prove theorem suffices show QBF true iff A0 u goodsatisfiable w.r.t. KB.[if ] Let model Circfix (KB) satisfies A0 u good . Due axioms (96)-(98), mustcontain DAG starts x (which (A0 u good )I ) and, following R-edges, proceedsconcepts Ai increasing index, . DAG, = 1 . . . nQi = , individuals belonging AIi two successors: one AIi+1 Ti+1. Individuals AI , Q = , one successor, AI . DueAIi+1 Fi+1i+1F .Lemma 7.20, successor either Ti+1i+1Now, consider truth assignment v universally quantified variables . DAG,follow unique path x leaf z , level corresponding Qi =AI F accordance v. Lemma 7.20, = 1 . . . nproceeds AIi+1 Ti+1i+1i+1z either Ti Fi , moreover, Lemma 7.21, membership z Ti Fi consistent v.Therefore, z represents full truth assignment variables extends v.Now, since minimizes set abnormal individuals w.r.t. defeasible inclusion (99)models good bad disjoint, x good implies z 6 BI . then,straightforward conclude truth assignment satisfies .749fiB ONATTI , FAELLA , & AURO[only ]. Assume true. Assume w.l.o.g. odd quantifiers Q1 , Q3 , . . . , Qn1 universal even quantifiers existential. existential quantifier Qi , let fi : {T, F }i/2{T, F } function values v1 , v3 , . . . , vn1 universally quantified variables, (v1 , f2 (v1 ), v3 , f4 (v1 , v3 ), . . . , fn (v1 , v3 , . . . , vn1 )) true.define tree-like model KB satisfies A0 u good . start root individualx, x |=I A0 u good . proceed inductively follows. even (including 0),individual AIi two R-successors 0 , 00 AIi+1 , 0 TiI 00 FiI (seeaxioms (97)). odd i, individual AIi one R-successor 0 AIi+1 (see axioms (98)),0 satisfies either Ti Fi , according value fi applied truth valuesread along path root y. Along R path x0 . . . xi . . . xnconcept Ti Fi assigned xi assigned xj , < j n, indifferently either Ti Fiassigned xh 1 h i. model completed assigning xn (i) BF G ,subformulas F G , F G assigned xn , (ii) BF G , subformulasF G , F G assigned xn .leave reader proof structure defined satisfies classical partKB. Regarding minimality w.r.t. defeasible inclusions KB, remark following.individuals violate inclusions (99). However, due rules (94) (95), situation cannotimproved simply modifying roles. Similarly, individuals violate inclusions (100)(101). However, since Eij empty defeasible inclusions cannot improved.Finally, since leaf z represents truth assignment satisfies , B emptyhence model also minimal w.r.t. inclusion (102).2fragment EL , unlike LLf , fully support unqualified existential. Consequently, Theorem 4.4 cannot used transfer hardness results Theorem 7.19 varfix.9 hardness results hold general framework Circvar (LLf EL )hence, Theorem 4.4,for Circfix (LLf EL ):Proposition 7.23 Subsumption instance checking Circfix (LLf EL ) p2 -hard; concept satisfiability p2 -hard. results hold even queries contain EL concepts,priorities specificity-based.following result, whose proof found Appendix, shows contextlower bounds tight: namely, case priority relation empty (i.e., DIsmutually incomparable) and, subsumption queries C v instance checking queries D(a),quantifier depth bounded constant.Lemma 7.24 Let KB = hKS KD , LLf EL knowledge base, C, EL concepts.models Circfix (KB) x C \ DI exists model J Circfix (KB)(i) J , (ii) x C J \ DJ (iii) |J | O((|KB| + |C|)d ) = depth(D).Going back fragment, following prove Circfix less complex Circvar(unless polynomial hierarchy collapses). particular, show Circfix (LLEL ) tractable.Algorithm 1 takes input knowledgedbase KB two concepts C (we may assumewithout loss generality C = AC u ni=1 Pi .Bi ) checks whether Circfix (KB) |= C v D.9. prove EL , Circfix actually less complex Circvar .750fiD EFEASIBLE NCLUSIONS L OW-C OMPLEXITY DLAlgorithm 1:dnData: C = AC u 1 Pi .Bi , D, KB = hK, i.:= {A vn P.B | C |= A};X := C;6=remove defeasible inclusion vn P.B;SupCls(P.B) SupCls(C) NonEmpty(P.B, KS ) NonEmpty(C, KS )X := X u P.B;return X vKS D;SupCls(H) mean set superclasses concept H, i.e., set B NC {}H vKS B.Given concept H, operator NonEmpty(H, KS ) represents set conceptsforced non empty whenever H is. Note set includes concepts forcednon empty ABox KB, independently H. write H ; iff H vKS R.A+R, denote ; transitive closure ;. Then, NonEmpty(H, KS ) formallydefined follows:NE Kernel = {H} aNI {A | KS |= A(a)} aNI ,RNR {A | KS |= (R.A)(a)}+NonEmpty(H, KS ) = ANE Kernel {A0 | ; A0 }.Roughly speaking, algorithm accumulates RHS defeasible inclusions actively satisfiedwitness C. Then, tries derive D. particular, defeasible inclusion vn R.Bactively satisfied case (i) entail locally concept name subsumedC, (ii) entail globally non-emptiness concept name empty.rationale concept names fixed circumscription cannot change extensionapplication vn R.B could instead require.Lemma 7.25 Circfix (KB) |= C v holds iff Algorithm 1 returns true.Proof. [if ] suffices show models Circfix (KB), X subsumes C, Xformula obtained statement. Assume per absurdum modelindividual x , x C \ XI . means defeasible inclusion n P.B (i) x 6satI (A n P.B) (ii) line 1, SupCls(P.B) SupCls(C) NonEmpty(P.B, KS )NonEmpty(C, KS ).Note that, since NonEmpty(P.B, KS ) NonEmpty(C, KS ), whenever R.B vKS S.Bexists individual yB B . Let 0 interpretation obtained adding(x, yB ). Clearly, adding new arcs set individuals satisfied defeasible inclusion0cannot decrease, therefore KD , satI () satI 0 (). Moreover, since x (R.B)I ,satI (A n P.B) satI 0 (A n P.B) hence 0 <fix I.condition (ii) fact defeasible inclusions conflict other,easy verify 0 also classical model KB, would mean modelCircfix (KB) hypothesis.[only ] Assume Algorithm 1 returns false. Let following interpretation:= {xC } {xA | NonEmpty(C, KS )} {xa | NI };751fiB ONATTI , FAELLA , & AUROB NC , B union of: (i) {xC } B S1 , (ii) set xA , S2 ,|=KS B, (iii) set xa , NI , KS |= B(a);R NR , RI union pairs (i) (xA , xB ) A, B S2 vKS R.B,(ii) (xa , xb ) a, b NI KS |= R(a, b), (iii) (xa , xB ) NI , B S2KS |= R.B(a), (iv) (xC , xB ) B S2 X vKS R.B; arcs relevant.construction (classical) model KS xC C \ DI , hence order proveCircfix (KB) remains show minimal. Note that, since defeasible inclusionscontain nested roles right side, set defeasible inclusions satisfied individualaffect set defeasible inclusions satisfied another individual. Therefore, interpretationimproved point-wise assume w.l.o.g. individuals I, except xC ,cannot improved. Assume exists interpretation J improvesxC , means particular = vn P.B, xC satJ () \ satI ().assumption xC 6 satI () means P.B satisfy condition line 1 and,since concept names fixed, cannot satisfied J .2Theorem 7.26 Circfix (LL EL ) DKBs, EL subsumption, instance checking, conceptconsistency P.Proof. Since SupCls(H) NonEmpty(H, KS ) based classical reasoning,performed polynomial time. Moreover, number iterations Algorithm 1 boundednumber defeasible inclusions. Therefore, due Lemma 7.25, subsumption problemtractable. Theorem 3.9, instance checking concept inconsistency reduced subsumption.2Complexity low Circfix context axioms general enough simulate quantifier nesting conjunctions existential restrictions. Circvar featuressimulated abbreviating compound concepts C concept names using equivalences CC depend qualified existentials (hence restriction preserved).Circfix , equivalences change semantics C whenever C (or contains) existentialrestriction, fixed prevents C varying freely. reintroduce missingfeatures, complexity increases again.Let LL2 EL support schemata:v[n] P.BP1 u P2 v P3 .BP v BOne may easily verify LL2 EL equivalent EL plus schema P1 u P2 v P3 .B.missing axioms reformulated using fresh roles R suitable equivalences R C(that preserve Cs semantics R varying predicate)10 .additional schemata, one create conflicts variable concepts, P1 uP2 v . different defeasible inclusions may block other, thereby creating potentiallyexponential search space.Theorem 7.27 Subsumption instance checking Circfix (LL2 EL ) coNP-hard; concept satisfiability NP-hard. results hold even three reasoning tasks restrictedLL2 EL concepts, priorities specificity-based.10. particular, schema A1 uA2 v B emulated inclusions A1 v R1 , A2 v R2 , B v R3 , R1 v A1 ,R2 v A2 , R3 v B, R1 u R2 v R3 .752fiD EFEASIBLE NCLUSIONS L OW-C OMPLEXITY DLProof. reduction SAT. propositional variable pi introduce concept names Ai , Ai ,role Ui , representing pi truth value (resp. true, false, undefined). alternativesmade mutually inconsistent with:Ai u Ai vAi u Ui vAi u Ui vgiven clause cj = lj,1 lj,n , introduce concept name Cj representing cj falsity,Lj,k representing complement lj,k add Lj,1 u u Lj,n v Cj .Define concept name F representing falsity given set clauses, disjointconcept F with:Cj v F(for input clauses cj )F u F v .Now, defeasible inclusion, Ui forced true individuals satisfy neither AiAi ; moreover, role U detects undefined literals:> vn UiUi v U .Let K set inclusions KB = hK, K i. proved given setclauses unsatisfiable iff Circfix (KB) |= F v U , therefore subsumption checking coNPhard.Similarly, proved unsatisfiable iff Circfix (KB 0 ) |= (U )(a), KB 0 =hK0 , K0 K0 = K {F (a)}; therefore instance checking coNP-hard.Finally, proved satisfiable iff F uOK satisfiable w.r.t. Circfix (KB 00 ),KB 00 = hK00 , K00 K00 = K {U u OK v }; therefore satisfiability checking NP-hard.left remark K easily encoded LL2 EL .2prove bound tight using Algorithm 2. algorithm non-deterministically looksindividual x (in model) satisfies C D. S1 guesses additional fixed conceptnames satisfied x; S2 guesses concept names satisfied somewhere model (notnecessarily x) finally 0 guesses total extension determines application orderGDIs.Similarly Algorithm 1, Algorithm 2 selects defeasible inclusions active xaccumulates formula X RHS blocked, i.e. require changeinterpretation concept names neither locally globally. major differences (i)defeasible inclusions extracted according 0 (ii) line 2 entire accumulated formulaX u P.B used check defeasible inclusion blocked.Finally, note variable part C (i.e. ni=1 Pi .Bi ) introduced X line 8,defeasible inclusions applied, defeasible inclusions influence variablepart (e.g. forcing empty).Lemma 7.28 Circfix (KB) |= C v holds iff runs Algorithm 2 return true.Proof. [if ] Assume per absurdum exists interpretation Circfix (KB) individual x x C \ DI . Let S1 S2 set concept names NCsatisfies respectively locally x globally i.e., individual. Let 0 linearizationcompatible I, i.e. , 0 KD (i) either 0 0 0 0 , (ii) 0 implies 0 0 ,(iii) 0 comparable according ( 6 0 0 6 ) x satI () \ satI ( 0 ),0 0 .753fiB ONATTI , FAELLA , & AUROAlgorithm 2:dnData: C = AC u 1 Pi .Bi , D, KB = hK, i.Guess S1 , S2 NC , uS1 |= AC S1 S2 , linearization 0 ;:= {Avn P.B | uS1 |= A};X := S1 ;6=remove 0 -minimal inclusion vn P.B;SupCls(X u P.B) S1 NonEmpty(X u P.B, KS ) S2X := X u P.B;dnX := X u 1 Pi .Bi ;return SupCls(X) 6 S1 NonEmpty(X, KS ) 6 S2 X vKS D;Let X result running Algorithm 2 guesses S1 , S2 , 0 . straightforwardsee = vn P.B KD P.B occurs X, x satI (). This, togetherfact x C , implies 1) SupCls(X) S1 ; 2) NonEmpty(X, KS ) S2 and, sincex 6 DI , 3) X 6vKS D. means run Algorithm 2 return false.[only ] Assume guess S1 , S2 0 Algorithm 2 returns false. Letdefined Lemma 7.25. similar way proved classical model KSxC C \ DI . Assume improved interpretation J , w.l.o.g. also assume(i) = vn P.B, xC satJ () \ satI () (ii) 0 higher prioritycomparable it, xC satJ ( 0 ) iff xC satI ( 0 ).X0 value X extracted line 2 Algorithm 2, since 0 implies 0 0 ,0 already extracted higher priority comparable . Since (ii) holdsconstruction xC X0I , xC X0J . However, assumption xC 6 satI () means X0 u P.Bsatisfy condition line 2 since concept names fixed cannot satisfied J .2Theorem 7.29 LL2 EL subsumption instance checking Circfix (LL2 EL ) coNP;LL2 EL concept satisfiability NP.Proof. analogous Theorem 7.26 left reader.2verified LL2 fragment support quantifier nesting. quantifier nesting,one would obtain LLf EL (i.e. full LL).8. Related WorkDLs extended nonmonotonic constructs default rules (Straccia, 1993; Baader& Hollunder, 1995a, 1995b), autoepistemic operators (Donini et al., 1997, 2002), circumscription (Cadoli, Donini, & Schaerf, 1990; Bonatti et al., 2009, 2009; Bonatti, Faella, & Sauro, 2010).articulated comparison approaches found work Bonatti, Lutz,Wolter (2009).approaches concern logics whose reasoning tasks complexity lies beyond PH(unless hierarchy collapses). example, logics considered Donini et al. (1997, 2002)range PSPACE 3-ExpTime. circumscribed DLs studied Cadoli et al. (1990) well754fiD EFEASIBLE NCLUSIONS L OW-C OMPLEXITY DLTable 1: Main complexity results. corresponding decision problems classical versionsconsidered logics solvable polynomial time.DL-liteRvar fix(\)conceptsatisfiabilityp2p2ELELvarfixvar()LL2fixLLfp2PNPp2 (#)PSPACEtrivialsubsumption& instancep2 p2P ExpTimep2 ()P co-NPp2 (#)checking() specificity-based priorities; general priorities make var least complex fix() quantifier nesting bounded r.h.s. subsumptions instance checking problems(\) DIs left-fixed priority relation empty(#) membership holds priority relation empty condition () holdsPSPACEBonatti et al. (2009) range NPNExp NExpNP . logics undecidable (Baader &Hollunder, 1995a; Bonatti et al., 2009).pioneering approach low-complexity, circumscribed description logics presentedCadoli et al. (1990). approach applies non-prioritized circumscription fragmentdescription logic ALE. Decidability reasoning shown reduction propositional reasoning Extended Closed World Assumption (ECWA), p2 . bestknowledge, first effective reasoning method nonmonotonic description logic.hybrid Circfix (EL ) closed world assumption proved PTIME (Bonattiet al., 2010). one hand, approach imposes less restrictions structure inclusions;hand, cannot fully extended variable predicates without affecting tractability.recent approach similar spirit circumscription taken Giordano etal. (2008). extend ALC modal operator representing typicality, maximizeextension achieve nonmonotonic inferences. Decidability proved via tableau algorithmalso establishes co-NExpTimeNP upper bound subsumption. matching lower boundsgiven; proved reasoning underlying monotonic logic NP-hard.Finally, approach based rational closures ALC found work CasiniStraccia (2010). appealing feature approach reasoning reduced classicalinference. Complexity increased nonmonotonic reasoning: ranges PSPACEExpTime.9. Discussion Future Workmain complexity results paper summarized Table 1. restricting circumscribedKBs Circvar (DL-liteR ), complexity decreases significantly (from (co)-NExpTimeNP second level PH). complexity upper bounds hold Circfix (DL-liteR ) whenever priority755fiB ONATTI , FAELLA , & AUROrelation empty defeasible inclusions admit concept names LHS. However,general case still open question.contrary, restricting language EL EL general suffice bring complexity within PH. particular, proved reasoning tasks undecidable CircF (EL)(i.e., roles fixed) reasoning Circfix (EL) Circvar (EL ) generalExpTime-hard.main source higher complexity EL family (w.r.t. DL-liteR ) identifiedintroducing restriction called full left locality (LLf ) suffices confine complexity within second level PH Circvar specificity-based priorities, providedquantifier nesting level subsumption queries instance checking queries suitably bounded(no restrictions needed concept satisfiability).Since left locality restriction rules acyclic terminologies (which commonly usedontologies), relaxed almost left local (aLL) knowledge bases, support acyclicterminologies restriction unfolding (i.e., process replacing atoms definedacyclic terminology definition) yield LLf knowledge base. Reasoningbecomes PSPACE-hard, general; however fragment Circvar (andassumptions needed LLf ), reasoning remains complete second level PH. particular,assumption priorities determined specificity essential: Theorem 4.5, generalpriorities make Circvar least complex Circfix , is, PSPACE-hard.also analyzed complexity several fragments lyingCircfix . results provide information complexity sources circumscribed DLs. example, quantifier nesting KB partially responsible complexity(presumably enables conflicts default properties different individuals):particular, removing quantifier nesting (i.e., restricting KBs LL2 fragment) complexity drops first level PH. source complexity, course, due conflictsdefeasible inclusions concerning individual isolation; Circfix (LLEL ) defeasible inclusion never block another inclusion (because fixed predicates prevent this) andasconsequencecomplexity drops within PTIME.also proved fragments fully support unqualified existential restrictions,variable concept names eliminated. Moreover, EL various left local fragments,compound concepts replaced concept names left-hand side defeasible inclusions, without affecting expressiveness. fragments, general priorities simulatedusing specificity-based priorities.leave several interesting questions open: First, clear whether general priorities necessary hardness results DL-liteR ; particular, would interesting establish exact complexity DL-liteR specificity-based priorities. gaps complexitycircumscribed DL-liteR concern complexity Circfix unrestricted GDIs nonemptypriority relations, complexity reasoning fixed roles. next interesting questionwhether bound quantifier nesting queries actually needed confine complexitycircumscribed EL within second level PH. Finally, exact charcterizationcomplexity Circfix (LLf EL ) fragments whose complexity lies beyond PH.fragments belong second level PH, see interesting opportunityencoding reasoning ASP use well-engineered engine DLV (Eiter, Leone,Mateis, Pfeifer, & Scarcello, 1997) test scalability. order evaluate implementations experimentally, necessary set suitable benchmarks that, first stage, must necessarily756fiD EFEASIBLE NCLUSIONS L OW-C OMPLEXITY DLsynthetic problems, since nonmonotonic KBs supported far. course, identifyingmeaningful criteria problem generation nontrivial issue. Therefore, systematic experimentalevaluations still require significant body work.Acknowledgmentsauthors wish thank Frank Wolter granting permission publish undecidabilityproof. Moreover, grateful Frank Wolter Carsten Lutz many stimulating discussions feedback. work carried framework project LoDeN,(very) partially supported Italian Ministry Research.Appendix A. Additional Lemmas ProofsA.1 Proofs Section 6Lemma 6.3. Given PDLP P V = {p1 , . . . , pn } truth assignment P V ,minimal model iff interpretation model (S, I, ) model Circvar (KB ),domains || = 2n + 1.Proof. [only ] Let = model (S, I, ), first show model classical partKB . Since I-V, Abox (18) axioms (20-24) satisfied. Whereas, axioms (33-36)follow directly VII.Since interpretation, VI assures TrueP 6= , False P 6= . TogetherVIII, axioms (31-32) satisfied, whereas together VII, True False reflect truthvalues I; therefore True False = hence axiom (30) satisfied. Moreover,model S, c exists least one literal li occurring c |= li . DueV-VII, CjI True 6= and, due VII VIII (where X = True = Cj ), satisfiesaxioms (26-29).remains prove exists interpretation J J <var I. finite,assume w.l.o.g. J model KB . Assume 1 2n, satI (Li vnLi ) satJ (Li vn Li ), equivalent saying LJLi , since Li singleton,JLi would empty contradicting axioms (18-23). Similarly, satI (Cj vn Cj ) satJ (Cj vnCj ) iff CjJ CjI . Thus, due V axiom Lji v Cj would satisfied J . Thereforedefeasible inclusions highest priority cannot improved.Jassume literal clause concept holds LJ= Li = {di } Cj = Cj .Since reflects truth values I, di included FalseLIi includedTrueLIi . Thus, 1 2n, satI (Pi vn FalsePi ) equal satJ (Pi vn FalsePi )would way J improve defeasible inclusion Pi vn TruePi . Therefore,possibility far J improves instance (40).Note True J False J partition PiJ . Otherwise, could set PiJ withouttruth value (i.e., di 6 TruePiJ FalsePiJ ) FalsePi since classical inclusion jeopardizedwould obtain improvement J according (40), hypothesis J model.Due (31-36), True J False J partition {d1 , . . . , d2n }.Thus, consider propositional assignment J pi J iff PiJ True J .First, clauses cj , since J satisfies axioms (26-29), 1 2nJJJJLJCj True . Li = Li Cj = Cj , ljl occurs cj . means J |= li ,757fiB ONATTI , FAELLA , & AUROhenceJ model S. Finally, said before,intersectionJ |= cj . Thus,Sif JJ <var I,strictly contained intersectionJ . impliesPFalsePFalseJ I, hypothesis minimal model.[if ] Assume = model (S, I, ) model Circvar (KB ). First showmodel S, i.e., cj S, |= cj . satisfies axioms (26-29), 1 2n holdsdi CjI True . Due IV V, di belongs LIi corresponding literal lioccurs cj . According VI, implies |= li , hence |= cj .remains show minimal model. Assume exists model JJ I, without loss generality assume J minimal model. Let J = model (S, J, ),arguments J model KB . Furthermore, satJ () = satI ()JJtypeILi vn LI orSCj Jvn Cj . JFinally, True False reflect truth values J,Pi F alsePi F alse hence J <var due improvement DIs (40). 2Lemma 6.4. model Circvar (KB ), exist minimal modelpi iff PiI True iff PiI False , = 1, . . . , n.Proof. Let model Circvar (KB ). First, show LIi singleton, 1 2n.Assume contrary. Clearly, satisfy (1821), LIi nonempty. Therefore,1 k n, LIk contains least two individuals. show exists interpretation 0improves I.1 2n, let di arbitrary element LIi , let = {d1 , . . . , d2n } {aI }.LIi disjoint (see axioms (22)) NonEmpty disjoint LIi ,|| = 2n + 1.). Let 0PDLP satisfiable, thus exists model S. Let Ib = model (S, I,00interpretation that: (i) = , (ii) roles R, R = , (iii) 0 coincidesIb respect concept names, (iv) individuals \belong concept name. straightforward see 0 satisfies classical part KB .00Furthermore, construction, (a) 1 2n, LIi LIi ; (b) 1 j m, CjI CjI ;0(c) 1 l 2n, LIl LIl . Thus, 0 <var I, due improvement DI (23).argument, LIi = {di }. Define truth valuation = {pi | di True }.remains prove minimal model S. fact model ensuredaxioms (2429). Then, assume contradiction exists model J smaller(i.e., J I), let J = model (S, J, ). J build interpretation J 00J = J 0 classical model KB J 0 <var I, thus contradictinghypothesis model Circvar (KB ). define J 0 copying J properties(concepts roles) individuals J = , leaving individuals \concept role extensions.2A.2 Proofs Section 7Given KB K, interpretation I, individual z, recall definition KB [z] Section 6.2. Redefine notion support follows: supp (C) set individuals z> vKB[z] C holds.Lemma 7.12. Let KB = hK, K LLf EL knowledge base, C, EL concepts.models Circvar (KB) x C \ DI exists model J Circvar (KB)(i) J , (ii) x C J \DJ , (iii) |J | O((|KB|2 +|C|)d ), = depth(D)+1.758fiD EFEASIBLE NCLUSIONS L OW-C OMPLEXITY DLProof. Given two individuals x , distance d(x, y) minimal length role-pathsx y. Let KB knowledge base obtained KB applying transformationpresented Section 7. Notice |KB | |KB|2 .Lemma 7.10, extended model Circvar (KB ), continue callconvenience. define small model J Circvar (KB ) x C J \ DJ . Then,obtain thesis Lemma 7.11.start initial domain J contains (i) x; (ii) aI , NI occurs KB ;(iii) concepts H cl(KB ) cl(C) H 6= , witness yH H ; (iv)concepts H cl(KB ) cl(C) supp (H) 6= , witness wH supp (H).expand J exhaustively applying following rule (where P special case P.HH = >):Let J P.H cl(KB ) cl(C) (P.H)I 6 (P.H)J .d(x, y) < d, add z J (y, z) P J , z (y, z) P z H .Otherwise, add (y, yH ) P J .Finally, concept name A, set AJ = J AI .respect cardinality J , note initially number individuals JO(|KB | + |C|). expansion, individual whose distance x less d,O(|KB | + |C|) new individuals added. means |J | = O((|KB | + |C|)d ) =O((|KB|2 + |C|)d ).construction individual J H cl(KB )cl(C) H , H J .particular, case H = P , also inverse holds, P J , P . previoustwo facts immediately follows J classical model KB x C J . Moreover, sincedistance x, P J contained P , P NR , easy see x 6 DJ .remains show J minimal. Assume contradiction classical model0J KB , holds J 0 <var J , show exists classical model 0 KB0 <var hypothesis Circvar (KB ).distinguish two cases: first cas, individuals wH introduced clause (iv) still satisfycorresponding concept H J 0 ; second case, least one wH satisfy conceptH. define 0 follows. cases, individual names interpreted conceptnames individuals J interpreted J 0 .0first case, individual z \ J satisfies concept name A, z AI ,0z supp (A). Moreover, P NR , P minimal set that:001. P J P ;002. z \ J z supp (P.H), H J (z, y) P .prove 0 classical model KB . Since 0 copy J 0 J J 0classical model, need show individuals z \ J satisfy stronginclusions KS . Note z satisfies 0 LHS H strong inclusion, z supports H0I. definition, z supports also RHS I. RHS concept name B, z B0construction. Otherwise, i.e., RHS P.H, step 2 above, suffices show H Jempty. However, assumption, witness P.H introduced clause (iv) still satisfiesP.H J 0 . Therefore, exists individual satisfying H J 0 .Next, prove 0 <var I. Since J 0 <var J , suffices show individual z\J satisfies 0 defeasible inclusions satisfies I. Assume DI = (A vn B)759fiB ONATTI , FAELLA , & AURO0satisfied z I. z AI , construction z supp (A). Clearly, z supp (A)0z satI (A vn B), z supp (B). Therefore, z B .left prove theorem second case, i.e.: least one wH satisfyconcept H. Clearly, wH support H J 0 anymore. particular, must DIwH satJ () \ satJ 0 (). J 0 <var J , follows must DI 00 K satJ ( 0 ) satJ 0 ( 0 ). Now, 0 safely violate DIs whose priority lower0 , particular DIs whose LHS classically subsumes >. Then, complete definition0 follows. basic concept holds individual z \ J > vKS A.0P NR , P minimal set001. P J P ;002. z \ J , > vKS P.H, H J (z, y) P .easy verify 0 classical model KB . order prove 0 <var I, notefollowing two facts hold.First, individual z \J satisfies DIs whose priority minimal. Assume1 K 2 , DIs 1 2 , means LHS 2 subsumes LHS 1vice versa. Then, LHS 1 subsume > hence, construction, z vacuouslysatisfies 1 .Second, z violates DI 00 = (A vn B), 0 K 00 . before, since 0 K , LHS0subsume >. However, since z violates 00 , z AI hence subsumes >. Therefore,0 K 00 .first fact immediately follows satI ( 0 ) satI 0 ( 0 ). Assume now,00 , satI ( 00 ) 6 satI 0 ( 00 ). exists individual z \ J z satI ( 00 ) \satI 0 ( 00 ), second fact 0 K 00 . Otherwise, must exist individual w Jw satI ( 00 ) \ satI 0 ( 00 ). However, J set DIs individual satisfies(resp. 0 ) set DIs satisfies J (resp. J 0 ). means exists defeasibleinclusion 000 000 K 00 satJ ( 000 ) satJ 0 ( 000 ). Due first fact, 000 satisfied\ J , hence satI ( 000 ) satI 0 ( 000 ).2Proposition 7.13. Let KB = hKLL Ka , EL knowledge base. Every modelCircF (unf(KB)) extended model CircF (KB).Proof. Let Kunf = unf(KB) = hK0 , 0 i. Let model CircF (Kunf ). Extendclassical model J K0 Ka setting AJ = DJ definitions Ka . NoteK0 Ka classically equivalent KLL Ka . suppose J model CircF (KB).Since construction J classical model Ka strong axioms KLL , mustclassical model J 0 axioms J 0 <F J . restricting J 0 primitive predicates(i.e., predicates defined Ka ), obtain classical model 0 K0 . Notedefeasible inclusions KLL , holds satJ 0 () = satJ 0 (unf(, Ka )) = satI 0 (unf(, Ka ))satJ () = satJ (unf(, Ka )) = satI (unf(, Ka )). follows 0 <F I, contradiction.2Proposition 7.14. Let KB = hKLL Ka , EL knowledge base supposeconcept names defined Ka variable. Then, models CircF (KB), restrictionprimitive predicates model CircF (unf(KB)).760fiD EFEASIBLE NCLUSIONS L OW-C OMPLEXITY DLProof. Let Kunf = unf(KB) = hK0 , 0 i. Let J restriction primitive predicates.words, J obtained dropping interpretation concept names definedKa , variable. easily verified J classical model K0 . Supposecontradiction J model CircF (Kunf ); exists classical model J 000K0 J 0 <F J . extend J 0 model 0 KLL Ka setting AI = DIdefinitions Ka . Since predicates defined Ka variable, fixed predicatespreserve extensions across I, J , J 0 , 0 . Moreover, defeasible inclusions KLL ,satI 0 () = satI 0 (unf(, Ka )) = satJ 0 (unf(, Ka )) satI () = satI (unf(, Ka )) =satJ (unf(, Ka )). follows 0 <F I, contradiction.2Given knowledge base KB, interpretation concept D, overridenotion support; supp (D) set zlvKB[z] .zAIClearly, classical model KB z supp (D), z DI .Lemma 7.24. Let KB = hKS KD , LLf EL knowledge base, C, EL concepts.models Circfix (KB) x C \ DI exists model J Circfix (KB)(i) J , (ii) x C J \ DJ (iii) |J | O((|KB| + |C|)d ) = depth(D).Proof. Define small model J proof Lemma 7.12, using new definitionsupport. Regarding size J fact classical model KB, argumentsproof Lemma 7.12 apply. particular, holds |J | = O((|KB| + |C|)d ).remains show J <fix -minimal. Assume contradiction interpretation0J , holds J 0 <fix J ; usual, show exists 0 , 0 <fix I. Let 0 defined0000follows: = ; aI = aI , NI ; AI = AI , NC ; P minimal setthat:00P J P ,000z \ J , J P.H cl(KB) z00supp (P.H), H , (z, y) P (P seen special caseH = >).First, prove 0 classical model KB. particular, suffices show classical00inclusions satisfied \ J . Given classical inclusion C1 v D1 KB, assume0z C1I , recall C1 typeA1 u . . . u u R1 u . . . u Rm .0suffices show exists individual w J satisfies C1 well. construction,R occurring C1 , z supp (R), therefore z supp (C1 ). meansexists witness w supp (C1 ) J . Since concept E, w E implies w E J ,follows w supp J (C1 ). Since priority relation empty, DI KD holdssatJ () satJ 0 (). consequence, concept E holds supp J (E) supp J 0 (E).761fiB ONATTI , FAELLA , & AURO00particular, w supp J 0 (C1 ) hence w C1J w D1J . construction, obtain0z D1I .remains prove 0 improves according <fix . Let = (C1 vn D1 ) defeasible00inclusion KB. Since J 0 <fix J , suffices prove z \ J , z satI ()z satI 0 ().Suppose first z vacuously satisfies (i.e., violates C1 ). Atomic conceptsextension 0 , z satisfies unqualified existential 0 satisfiesexistential I. Hence, z vacuously satisfies 0 well.0Suppose instead z actively satisfies I. z 6 supp (C1 ), z 6 C1I , zvacuously satisfies 0 . Otherwise, z supp (C1 ) z supp (D1 ). construction,00witness w J w supp J (D1 ) supp J 0 (D1 ). implies w D1J and,00considering construction P , z D1J . Therefore, z satJ 0 () obtain thesis. 2ReferencesBaader, F. (2003). instance problem specific concept description logic ELw.r.t. terminological cycles descriptive semantics. Proc. 26th Annual GermanConf. AI, KI 2003, Vol. 2821 LNCS, pp. 6478. Springer.Baader, F., Brandt, S., & Lutz, C. (2005). Pushing EL envelope. Proc. 19th Int. JointConf. Artificial Intelligence, IJCAI-05, pp. 364369. Professional Book Center.Baader, F., & Hollunder, B. (1995a). Embedding defaults terminological knowledge representation formalisms.. J. Autom. Reasoning, 14(1), 149180.Baader, F., & Hollunder, B. (1995b). Priorities defaults prerequisites, applicationtreating specificity terminological default logic.. J. Autom. Reasoning, 15(1), 4168.Bonatti, P. A., Faella, M., & Sauro, L. (2009). Defeasible inclusions low-complexity DLs: Preliminary notes. Boutilier, C. (Ed.), IJCAI, pp. 696701.Bonatti, P. A., Faella, M., & Sauro, L. (2010). EL default attributes overriding. Int.Semantic Web Conf. (ISWC 2010), Vol. 6496 LNCS, pp. 6479. Springer.Bonatti, P. A., Lutz, C., & Wolter, F. (2006). Description logics circumscription. Doherty,P., Mylopoulos, J., & Welty, C. A. (Eds.), KR, pp. 400410. AAAI Press.Bonatti, P. A., Lutz, C., & Wolter, F. (2009). complexity circumscription DLs. J. Artif.Intell. Res. (JAIR), 35, 717773.Bonatti, P. A., & Samarati, P. (2003). Logics authorization security. Logics EmergingApplications Databases, pp. 277323. Springer.Cadoli, M., Donini, F., & Schaerf, M. (1990). Closed world reasoning hybrid systems. Proc.ISMIS90, pp. 474481. Elsevier.Cadoli, M., Eiter, T., & Gottlob, G. (1992). efficient method eliminating varying predicatescircumscription. Artif. Intell., 54(2), 397410.Calvanese, D., De Giacomo, G., Lembo, D., Lenzerini, M., & Rosati, R. (2005). DL-Lite: Tractabledescription logics ontologies. Proc. AAAI 2005, pp. 602607.762fiD EFEASIBLE NCLUSIONS L OW-C OMPLEXITY DLCasini, G., & Straccia, U. (2010). Rational closure defeasible description logics. Janhunen,T., & Niemela, I. (Eds.), JELIA, Vol. 6341 Lecture Notes Computer Science, pp. 7790.Springer.Donini, F. M., Nardi, D., & Rosati, R. (1997). Autoepistemic description logics. IJCAI, pp.136141.Donini, F. M., Nardi, D., & Rosati, R. (2002). Description logics minimal knowledge negation failure. ACM Trans. Comput. Log., 3(2), 177225.Eiter, T., Leone, N., Mateis, C., Pfeifer, G., & Scarcello, F. (1997). deductive system nonmonotonic reasoning. Logic Programming Nonmonotonic Reasoning, 4th International Conference, LPNMR97, Proceedings, Vol. 1265 LNCS, pp. 364375. Springer.Eiter, T., & Gottlob, G. (1995). computational cost disjunctive logic programming: Propositional case. Ann. Math. Artif. Intell., 15(3-4), 289323.Finin, T. W., Joshi, A., Kagal, L., Niu, J., Sandhu, R. S., Winsborough, W. H., & Thuraisingham,B. M. (2008). ROWLBAC: representing role based access control OWL. Ray, I., & Li,N. (Eds.), SACMAT, pp. 7382. ACM.Giordano, L., Gliozzi, V., Olivetti, N., & Pozzato, G. (2008). Reasoning typicality preferential description logics. Proc. Logics Artificial Intelligence, 11th European Conference,JELIA 2008, Vol. 5293 Lecture Notes Computer Science. Springer.Kolovski, V., Hendler, J. A., & Parsia, B. (2007). Analyzing web access control policies.Williamson, C. L., Zurko, M. E., Patel-Schneider, P. F., & Shenoy, P. J. (Eds.), WWW, pp.677686. ACM.Lutz, C., & Wolter, F. (2010). Deciding inseparability conservative extensions descriptionlogic el. J. Symb. Comput., 45(2), 194228.McCarthy, J. (1980). Circumscription - form non-monotonic reasoning. Artif. Intell., 13(1-2),2739.McCarthy, J. (1986). Applications circumscription formalizing common-sense knowledge.Artif. Intell., 28(1), 89116.Rector, A. L. (2004). Defaults, context, knowledge: Alternatives OWL-indexed knowledgebases. Pacific Symposium Biocomputing, pp. 226237. World Scientific.Stevens, R., Aranguren, M. E., Wolstencroft, K., Sattler, U., Drummond, N., Horridge, M., & Rector,A. L. (2007). Using OWL model biological knowledge. International Journal ManMachine Studies, 65(7), 583594.Straccia, U. (1993). Default inheritance reasoning hybrid KL-ONE-style logics.. IJCAI, pp.676681.Uszok, A., Bradshaw, J. M., Jeffers, R., Suri, N., Hayes, P. J., Breedy, M. R., Bunch, L., Johnson, M.,Kulkarni, S., & Lott, J. (2003). KAoS policy domain services: Towards descriptionlogic approach policy representation, deconfliction, enforcement.. 4th IEEE Int.Workshop Policies Distributed Systems Networks (POLICY), pp. 9396. IEEEComputer Soc.763fiB ONATTI , FAELLA , & AUROZhang, R., Artale, A., Giunchiglia, F., & Crispo, B. (2009). Using description logics relationbased access control. Grau, B. C., Horrocks, I., Motik, B., & Sattler, U. (Eds.), DescriptionLogics, Vol. 477 CEUR Workshop Proceedings. CEUR-WS.org.764fiJournal Artificial Intelligence Research 42 (2011) 607-659Submitted 09/11; published 12/11Drake: Efficient Executive TemporalPlans ChoicePatrick R. ConradBrian C. Williamsprconrad@mit.eduwilliams@mit.eduRoom 32-22732 Vassar StCambridge, 02139 USAAbstractwork presents Drake, dynamic executive temporal plans choice. Dynamic plan execution strategies allow autonomous agent react quickly unfoldingevents, improving robustness agent. Prior work developed methods dynamically dispatching Simple Temporal Networks, research enriched expressiveness plans executives could handle, including discrete choices, focuswork. However, approaches date, additional choices induce significantstorage latency requirements make flexible execution possible.Drake designed leverage low latency made possible preprocessing stepcalled compilation, avoiding high memory costs compact representation.leverage concepts labels environments, taken prior work Assumptionbased Truth Maintenance Systems (ATMS), concisely record implicationsdiscrete choices, exploiting structure plan avoid redundant reasoning storage. labeling maintenance scheme, called Labeled Value Set MaintenanceSystem, distinguished focus properties fundamental temporal problems, and,generally, weighted graph algorithms. particular, maintenance system focusesmaintaining minimal representation non-dominated constraints. benchmarkDrakes performance random structured problems, find Drake reduces sizecompiled representation factor 500 large problems, incurringmodest increase run-time latency, compared prior work compiled executivestemporal plans discrete choices.1. IntroductionModel-based executives elevate commanding autonomous systems level goalstates providing guarantees correctness (Williams, Ingham, Chung, & Elliott, 2003).Using model-based executive, user provide specification goal behaviorrobot leave program, executive, determine appropriate courseaction meets goals. Temporal plan executives designed work plansincluding timing requirements.Typically, executive robust disturbances, must able reactoutcomes events fly, otherwise, even seemingly inconsequential variationsoutcomes events may cause failure. Thus, helpful follow strategy leastcommitment delay decision actually time act decision, allowingexecutive act much information possible. case temporal plans,executive following strategy said dynamically dispatch plan (Muscettola,c2011AI Access Foundation. rights reserved.fiConrad & WilliamsMorris, & Tsamardinos, 1998). executive responsible determiningschedule events late possible guaranteeing consistent schedule existsremaining events. external disturbance causes timing requirementviolated, executive discover failure signal soon possible.Making decisions fly requires care, on-line temporal reasoningintroduce latency unacceptable real-time system. Therefore, Muscettola et al.(1998) developed low-latency executive Simple Temporal Networks (STNs),STN comprised set events difference constraints time executionevents. achieve low latency, executive broken two parts, compilerdispatcher. compiler run advance discover explicitly record temporalconstraints cannot quickly inferred on-line, thereby computing dispatchableform plan. dispatcher uses form make real-time decisions using greedystrategy local, low-latency inferences.dynamic scheduling proven effective, robustness improvedmaking additional decision dynamically, assignment activity particular resource. Encoding decisions requires expressive formalism STNs.Consequently, subsequent research developed efficient executives expressiveframeworks, many variants STN. Examples added features includeexplicit modeling uncertainty (Morris, Muscettola, & Vidal, 2001; Rossi, Venable, &Yorke-Smith, 2006; Shah & Williams, 2008), discrete choices (Kim, Williams, & Abramson,2001; Tsamardinos, Pollack, & Ganchev, 2001; Combi & Posenato, 2009; Shah & Williams,2008), preferences (Hiatt, Zimmerman, Smith, & Simmons, 2009; Khatib, Morris, Morris,& Rossi, 2001; Kim et al., 2001), discrete observations (Tsamardinos, Vidal, & Pollack,2003), combinations thereof.work focuses enriching executive simultaneously schedule eventsmake discrete choices execution unfolds. ability make discrete choices greatlyenriches executive offering ability dynamically allocate resources, order activities, choose alternate methods (sub-plans) achieving goals. Although priorworks developed executives type plan, trade-offs performance.example, Tsamardinos, Pollack, Ganchev (2001) presented executive Disjunctive Temporal Networks (DTN), variant STNs include discrete choices.executive extends compilation strategy STNs breaking DTN completeexponential set component STNs compiling dispatching parallel.strategy offers low latency, incurs high storage cost dispatchable plan.Another example, Kirk, executive Temporal Plan Networks (TPNs), extendsSTNs including hierarchical choice sub-plans, developed Kim, Williams,Abramson (2001). Kirk selects set choices performs incremental re-planningwhenever disturbance invalidates choice, leaving small memory footprint, potentially inducing high latency selects new choices. Chaski executive presentedShah Williams (2007) temporal plans resource allocation, whose expressiveness STNs DTNs. Chaski takes approach hybridincremental strategy Kirk compiled approach Tsamardinos et al.:compiled representation base plan set incremental differences, providesbenefits compiled execution improving efficiency exploiting structureplan .608fiDrake: Efficient Executive Temporal Plans Choicedevelop Drake, novel executive temporal plans choice encoded usingexpressive representation DTNs (DTNs dominate TPNs, TCNs, STNs). Drakeachieves low run-time latency compilation, yet requires less storage fullyexponential expansion approach taken Tsamardinos et al. (2001). order accomplish this, Drake works compact representation temporal constraints discretechoices. develop compact representation, begin idea, taken truthmaintenance, labeling consequences inferences minimal set choices imply consequence; minimal set called environment (McDermott, 1983; de Kleer,1986). monotonicity inference, consequence also holds sets choicessuperset minimal environment, thus environment compact encodingdecision contexts consequence holds.ideas directly applicable temporal reasoning problems; Drake extendsleveraging properties fundamental temporal reasoning problems, weighted graphproblems general. specifically, temporal reasoning non-monotonic, senseneed explicitly represent derivable constraints, tightest possible ones, referred non-dominated constraints. Drake uses property throughoutreduce computations storage required. example, inequality 4 8,temporal event, need store constraint 8, tighterinequality makes unnecessary, dominates it. focus non-dominated valuesconstraints central range inference problems, including temporal inference, intervalreasoning, inference weighted graphs.Dechter, Meiri, Pearl (1991) proved STN inference problems reduciblewidely used set inference methods weighted graphs, Single Source ShortestPath All-Pairs Shortest Path Problems. approach develop labeled analoguesweighted graph structures support shortest path algorithms, providingcompact representation Drake. paper, first present new formalism planschoice, Labeled Simple Temporal Network (Labeled STN),expressiveness previous formalisms, shares ideas rest techniques.Second, explain system maintaining deriving compact representations valuesvary choices, called Labeled Value Set Maintenance System. Then, useLabeled Value Sets construct Labeled Distance Graphs, distance graphsedge weights may vary depending discrete choices. Finally, Drakes compilationdispatching algorithms built around techniques. focus paperdispatchable execution, techniques surrounding labeled distance graphs holdpromise extending wide range reasoning methods involving graph algorithmsinclude choice.practical terms, Drakes compact encoding provides reduction size planused dispatcher two orders magnitude problems around 2,000component STNs, compared Tsamardinos et al.s work (2001). size reductioncomes modest increase run-time latency, making Drake useful additionavailable executives.609fiConrad & Williams1.1 Overview ProblemDrake takes input Labeled STN, temporal constraint representationchoices; Section 3 discuss Labeled STNs encode choices subplans, temporal constraints, resource assignment, mappings related frameworks.Drakes output dynamic execution plan, determines real-timeexecute events, end plan execution times consistentevery temporal constraint implied least one complete set choices, barring unforeseendisturbances. outside disturbances make every possible execution inconsistent, Drakesignals failure soon possible solutions rendered inconsistent.Section 3 provides formal definition Labeled STNs; essentially, collectionevents schedule constraints executive must follow. events may constrained simple temporal constraints, limit difference scheduled timestwo events. Furthermore, Labeled STN specifies discrete choices, assignmentschoices may imply additional simple temporal constraints.Throughout paper, use following simple example, includes choicesub-plans.Example 1.1 rover 100 minutes work scheduled contact operators. contact, rover must drive next landmark, taking 3070 minutes. fill remaining time, rover two options: collect samplescharge batteries. Collecting samples consistently takes 50 60 minutes, whereascharging batteries usefully done duration 50 minutes.Always: [0, 100]collecting: CollectSamples, [50, 60]Ccollecting: [0, 0]Always:Drive, [30, 70]Always: [0, 0]Bcharging:Charge [0, 50]EFcharging: [0, 0]Figure 1.1: informal Labeled STN depicts Example 1.1. rover needs drive,either collect samples charge batteries within certain time limit.610fiDrake: Efficient Executive Temporal Plans ChoiceFigure 1.1 shows informal representation Labeled-STN correspondingplan. notation [l, u] edge vertex X means differenceexecution times events lies given interval, expresses constraintl X u. figure text explains temporal constraints impliedchoice; develop precise notation later. two types constraints drawn,always required, required rover either collectingsamples charging.Consider following correct output execution sequence rover problem.example, focus form executives output, deferring presentationdecision-making strategy later.Example 1.2 Drake starts executing plan, arbitrarily denoting starting time= 0. time, instructs system begin drive activity, indicatingdrive take 40 minutes. executive waits system respondsdrive completed, time = 45. Drake selects sample collectionoption, determined before, initiates activity duration50 minutes. = 95, sample collection completes, finishing plan within timelimit 100 minutes.1.2 Approach: Exploiting Shared Structure LabelingDrakes strategy compilation begin Labeled STN, concise statementtemporal constraints choices plan. Then, Drake constructs Labeled Distance Graph associated Labeled STN, yielding single graph structurerepresenting possible choices constraints. Next, Drakes compiler computesdispatchable form problem, also Labeled Distance Graph. compilation performed unified process able exploit similaritieschoices make representation compact. contrast, prior work Tsamardinos etal. (2001), breaks input plan independent STNs, hence compilation strategycannot exploit similarities shared structures choices. pathological cases, every choice completely unrelated, similaritiesDrake exploit. However, expect nearly every real-world human designedplan degree shared structure, plan usually unifying ideachoices designed accomplish. Indeed, expect real planssignificant similarities, allowing Drake perform well. section gives overviewintuition behind representation Drake uses similarities Drake exploit.continue discussing rover example, consider Figure 1.2, depictssmall STN, associated distance graph, dispatchable distance graphresult compilation. set events STN represented verticesdistance graph. Upper bounds STN induce edges forward direction, weightedupper bound, lower bounds induce edges reverse direction weightednegative lower bound. distance graph Figure 1.2b compiled,compiler outputs new distance graph contains representations constraintsneeded dispatcher. dispatchable form Figure 1.2c used dispatcher;execution times propagated edges determine events mayexecuted.611fiConrad & Williams[5, 10]C[3, 3]103[2, 5]C-5-325BB(a) Input STN(b) Associated distance graph8-53C-3B(c) Dispatchable graphFigure 1.2: simple example reformulating STN associated distance graphdispatchable form.rover example single binary choice, hence problem Tsamardinos et al.s(2001) algorithm separates two possible STNs compute associated distancegraphs, shown Figure 1.3. Note repetition certain edges graphs,example, edge F , present throughout compilation dispatchprocess. Plans choices exponential number repetitions,costly, Drake designed eliminate.informal version Labeled Distance Graph associated rover exampleshown Figure 1.4. differing constraints result two possible assignmentschoice distinguished annotations called labels. example, edge (B, C)weight : 60, indicates whenever sampling chosen, edge weight60; value 60 labeled discrete choice, S, implies it. gatherpossible values choices Labeled Value Sets, placededges. example, edge Labeled Value Set exactly one labeled value,although true general. Labeled Distance Graph essentially distancegraph numeric weights replaced Labeled Value Sets. Although developprecise notation later article, version shows intuition behindapproach. Drake capitalizes improvement using compact representationthroughout compilation dispatch, work develops necessary machinery.paper organized follows. Section 2 discusses related work temporal executives provides background truth maintenance. Section 3 defines Labeled STNscorrect dynamic execution, specifying problem Drake solves. Section 4 recalls612fiDrake: Efficient Executive Temporal Plans Choice1000C70-3060-5000BE00F00F(a) Distance graph collecting samples1000C70-30BE05000(b) Distance graph chargingFigure 1.3: Tsamardinos et al. (2001) style distance graphs associatedLabeled-STN Figure 1.1.link STNs distance graphs, provides labeled version distance graphs,Drake uses reasoning. Section 5 presents Labeled Value Set Maintenance System, completing foundation labeled techniques. Section 6 details dispatcherSection 7 develops Drakes compilation algorithm. Finally, Section 8 provides theoretical experimental performance results, Section 9 gives concluding remarks.2. Related Workdeveloping Drake, give overview relevant literature two majorareas Drake draws from: scheduling frameworks truth maintenance.613fiConrad & WilliamsA: 100A: 0CS: 60S: 50A: 70A:30S: 0S: 0BEA: 0A: 0FC: 0C: 0C: 50C: 0Figure 1.4: informal labeled distance graph rover example. A:, S: C:,correspond weights hold always, sampling, charging,respectively.2.1 Scheduling Frameworks Executivesstated introduction, achieve robustness, need executives make decisionsdynamically low latency expressive temporal representations.known methods manipulating reasoning Simple Temporal Networks efficiently,used foundation work temporal executives. Furthermore,numerous efforts formulated developed extensions STNs include usefulproperties, including uncertainty, preferences, discrete choices. briefly reviewefforts. Since work focuses discrete choices, discuss several efforts builddynamic executives plans detail. executives typically use onetwo approaches: reason plans parallel, switch plans incrementally.However, approaches, promising, typically either memory intensivemay high latency.Temporal Constraint Networks (TCNs), formalized Dechter, Meiri Pearl (1991),capture many qualitative metric temporal representations introduced AIcommunity. restricted type TCN, Simple Temporal Network, used throughoutrecent work temporal planning, temporal reasoning, scheduling. Muscettola, Morris,Tsamardinos (1998) proposed framework low-latency dynamic execution: preprocessing step called compilation run-time component called dispatch. Tsamardinos,Muscettola, Morris (1998) later provided faster compilation algorithm. workalso developed efficient methods testing consistency STNs (Xu & Choueiry,2003; Planken, de Weerdt, & van der Krogt, 2008).614fiDrake: Efficient Executive Temporal Plans ChoiceDechter et al. (1991) also proposed Temporal Constraint Satisfaction Problems,include discrete choices alter simple interval constraint particular pairsevents; pair may choice interval constraints, choices pair eventsmust independent. Stergiou Koubarakis (2000) loosened structural restriction,developing Disjunctive Temporal Network (DTN). Tsamardinos, Pollack, Ganchev(2001) presented first dynamic executive DTNs, functions generatingcomponent STNs implied combinations discrete choices compilingindependently, creating exponential growth memory use respect numberchoices.Another important line extension STNs Simple Temporal Network Uncertainty (STNU). Morris, Muscettola, Vidal (2001) proved executive testconsistency STNU compile dispatchable form polynomial time. Morris (2006) described efficient algorithm testing dynamic controllability. Hunsberg(2009, 2010) corrected flaw previous definitions described execution strategyusing efficient dynamic controllability algorithm. Venable Yorke-Smith (2005)added temporal uncertainty DTNs. Tsamardinos (2002) introduced probabilistic formulation uncertainty STNs. Conrad (2010) presents extension Drake DTNsuncertainty.Tsamardinos, Vidal, Pollack (2003) introduced Conditional Temporal Problems(CTP), adding uncontrollable discrete choices. executive cannot control, mayobserve values discrete choices designated parts plan.notation quite similar used Drake, two importantdifferences. First, CTP strictly harder problem, since Drake concerneduncontrollable choices, meaning algorithm work necessarysimpler case. Second, algorithm use compact representation;algorithm consistency checking requires enumerating possible scenarios. openproblem future research adapt general algorithms take advantagecompactness Labeled Distance Graph.Another useful feature added STNs preferences. Khatib, Morris, Morris, Rossi(2001) introduced formulation including preferences event execution times withinsimple interval bounds allowed STN, adding notion quality existing notionconsistency. Rossi, Venable, Yorke-Smith (2006) discuss simultaneous handlinguncertainty preferences.Kim, Williams, Abramson (2001) present Temporal Plan Networks, representationprovides simple temporal constraints durations combined series, parallel,choice, choice specified costs. Effinger (2006) expands simplepreference model, choices activities associated, fixed costs. Kirkdynamic executive TPNs. Kirk performs optimal method selection run-time,assigning discrete choices dispatches resulting component STN.disturbance invalidates STN Kirk chose, Kirk selects new STN consistentexecution thus far. research developed incremental techniques allowKirk re-plan lower latency (Shu, Effinger, & Williams, 2005; Block, Wehowsky, &Williams, 2006).Shah Williams (2008) present Chaski, executive dynamically dispatchesplans task assignment heterogeneous, cooperative agents, represented TCN,615fiConrad & Williamsremoving redundant data structures computations performed Tsamardinoset al.s (2001) algorithm. Shah Williams point component STNs realworld TCNs often differ constraints, allowing compact representation.record component STNs storing single relaxed STN maintaining listmodifications relaxed STN recover original component STNs.avoiding redundant records shared constraints, results show dramatic improvementsperformance. work inspired observation technique, althoughdistinct, bears resemblance environment labeling scheme employedAssumption Based Truth Maintenance System (ATMS). specifically adapted ATMSideas work general problem formulation Chaski, expecting see similarperformance improvements.Combi Posenato (2009, 2010) discuss applications dynamic executives businesswork flows, include flexibility time execution, hierarchical choice executionpaths, temporal uncertainty. formalism plans, Workflow Schemata, closelyrelated DTN, STNU, TPN frameworks, discuss variants compilationdispatching algorithms specialized representations. work describesintriguing notion call history-dependent controllability. model, eventX starts one two sub-plans, executive may invalidate either sub-planexecutes X begins one them. Drake impose similar requirement,requirement certainly useful preserving executives flexibility future choicesexecution unfolds. algorithms testing controllability enumerate possiblechoices, therefore suffers memory growth.Smith, Gallagher, Zimmerman (2007) describe distributed dynamic executivereal world plans C TAEMS language. representation uses STN temporal semantics includes features intended represent cooperative multi-agent plans.language features rich practical notion activity failure present STNs,including potential interruption activities. executive given discrete choicesmethod selection resource allocation, attempts maximize utilityoverall plan. preference model accounts partial total method failures supports different functions accumulating reward, example, summing maxing.executive uses re-planning strategy, similar Kirk, enhanced Hiatt, Zimmerman, Smith, Simmons (2009) type compile-time analysis called strengthening.analysis performs type local repair attempts make plan robustuncertainties activity failures.two central approaches dynamic executives include discrete choices.First, Tsamardinos et al.s (2003) CTPs, Tsamardinos et al.s (2001) DTN dispatcher,Combi et al. (2010) use compile-time analysis compute implied constraints everypossible plan explicitly reason run-time. Second, Kim et al. (2001),Smith et al. (2007) focus single, potentially optimal, assignment choices,becomes infeasible, incrementally re-plan extract new plan. methodsshortcomings, since explicit compilation memory intensive re-planning stepscomputationally intensive, especially executive forced re-plan often. Drake,like Chaski, provides middle ground working compilation strategyreduced memory footprint.616fiDrake: Efficient Executive Temporal Plans Choice2.2 Background ATMSsStallman Sussman (1977) introduced profoundly useful idea tracing dependency deductions computerized aid circuit diagnosis, order focus searchconsistent component mode assignment transistor circuit analysis. dependencies computes solving equations allow rapidly find choicesmight responsible detected failure. generalize approach combinatorial search, introducing dependency-directed backtracking algorithm, ensuresconflict found search backs far enough ensure newlyfound inconsistency actually removed.Doyle (1979) introduced Truth Maintenance Systems (TMSs) domain independentmethod supporting dependency-directed backtracking. TMS represents data,justifications, provides ability revise beliefs assumptions change contradictions arise. example, consider problem solver designed search solutionconstraint satisfaction problem. determining whether particular solutionconsistent, problem solver perform chain inferences, providing TMSjustification step. inconsistency found, problem solver selects newcandidate solution, TMS uses justifications determine inferencesstill hold new candidate must recomputed account new circumstances. TMS continually determines whether particular datum, general termfact arises problem solving, out, is, currently believed true,currently believed.Later work relaxes goal maintaining single, consistent assignment dataout, instead tracks contexts particular facts hold, evencontexts may mutually exclusive. McDermott (1983) uses beads state context,particular set choices assumptions reasoning might rely, providesdata pools specify facts hold context. De Kleer (1986) developsAssumption-based Truth Maintenance System, uses similar idea, changesterminology use environments labels specify contexts. ATMS maintains setminimal inconsistent environments, called conflicts no-goods. conflicts helpsystem avoid performing inferences contexts already known inconsistent,minimality conflict set makes procedure tractable. ATMS designedsimultaneously find logical consequences possible combinations assumptions,contrast TMS, focuses finding one set assumptions solveproblem interest. Hence, ATMS well suited foundation executiveintended consider possible choices simultaneously without incurring latencyswitching choices. Finally, development ideaworking inequalities, ATMS needs keep tightest bounds inequalities,use extensively; concept described Goldstone (1991) hibernation.leave review details ATMS later sections, develop Drakesmachinery depth.3. Dynamic Execution STNs Labeled STNsprepared present formal representation temporal plans Drakeuses. Plans composed actions need performed feasible times,617fiConrad & Williamsdefine feasible times constraints start end times plan activities.work builds upon Simple Temporal Networks, begin explaining STNsconstrain events plan feasible execution. extend definitionsinclude discrete choices, thereby constructing Labeled STNs.3.1 Simple Temporal NetworksSimple Temporal Networks provide framework efficiently reasoning limitedform temporal constraints. simple temporal network defined set events relatedbinary interval constraints, called simple interval constraints (Dechter et al., 1991).Definition 3.1 (Event) event real-valued variable, whose value executiontime event.Definition 3.2 (Simple Interval Constraint) simple interval constraint hA, B, l, uitwo events B requires l B u, denoted, [l, u].convention, u non-negative. lower bound, l may positive strictordering events, negative strict ordering. Positive negativeinfinities may used bounds represent unconstrained relationship.Definition 3.3 (Simple Temporal Network) Simple Temporal Network hV, Cicomprised set events V set simple interval constraints C. scheduleSTN assignment real number event V , representing timeschedule event. Simple Temporal Problem (STP) is, given STN hV, Ci,return consistent schedule possible, else return false. consistent schedule schedulesatisfies every constraint C. least one solution exists, STNconsistent.Definition 3.4 (Dynamic Execution) dynamic execution STN construction consistent schedule STN real-time. executive decides timewhether execute events time t, suitably small . time,longer remaining consistent schedules, return false immediately. executivemay arbitrarily select consistent schedule.3.2 Adding Choice: Labeled STNssection defines key representational concept, Labeled STNs, variant STNsdesigned include discrete choices temporal constraints. Although equivalentexpressiveness Disjunctive Temporal Networks, Labeled STNs provide consistentterminology Drake, corresponding labeled distance graphs make easierextend standard STN weighted graph algorithms include choice. show preciseconnection DTNs Labeled STNs end section. definitionsused throughout compilation dispatching algorithms presented laterwork.input problem needs succinct way state choices input planpossible options executive may select between. accomplishset finite domain variables.618fiDrake: Efficient Executive Temporal Plans ChoiceDefinition 3.5 (Choice Variables) choice associated finite domain variable xi . variables domain size equal number optionschoice. X set variables particular problem. assignmentselection single option choice, represented assignment choicesassociated choice variable.Example 3.6 rover example, single choice two options, leadingsingle variable x {collect, drive}. might assign x = collect represent choicecollecting samples.general, Drake reason implications combinations assignments.specify assignments choice variables, Drake uses environments. Following ATMS, Drake annotates, labels interval constraints edge weightsenvironments specifying entailed.Definition 3.7 (Environment) environment partial assignment choicevariables X, written e = {xi = dij , ...}. environment may one assignmentvariable consistent. complete environment contains assignment everychoice variable X. empty environment provides assignments written {}.denote set possible environments E set complete environmentsEc . length environment number assigned variables, denoted |e|.Example 3.8 problem two choice variables x, {1, 2}, possible environments {}, {x = 1}, {y = 2}, {x = 1, = 2}.Labeled STN, different assignments choice variables entail different temporalconstraints, represent labeled simple interval constraints.Definition 3.9 (Labeled Simple Interval Constraint) labeled simple interval constraint tuple hA, B, l, u, ei pair events B, real valued weights l uenvironment e E. constraint states that, assignments e hold,simple interval constraint hA, B, l, ui entailed.Labeled STN defined analogously STN, extended include choiceslabeled constraints.Definition 3.10 (Labeled Simple Temporal Network) Labeled STN hV, X, Ciset events V , set choice variables X, set labeled simple interval constraintsC. STNs, schedule Labeled STN assignment real numbersevent, indicating time execute event. schedule consistentfull assignment choice variables schedule satisfies every simple intervalconstraint entailed labeled simple interval constraint.Example 3.11 (Rover Problem Labeled STN) rover problem Example1.1 single choice, two options, collecting samples charging batteries.Use single choice variable x {collect, charge} represent choice. networkevents {A, B, C, D, E, F }. labeled simple interval constraints writtene : l B u.619fiConrad & Williams{} : 0 F 100(1){} : 30 B 70(2){} : 0 F E 0(3){x = collect} : 50 C B 60(4){x = collect} : 0 E C 0(5){x = charge} : 0 B 50(6){x = charge} : 0 E 0(7)notation states inequalities lines 1-3 must always hold, lines 4-5 musthold executive decides collect samples, lines 6-7 must hold executivedecides charge batteries. schedule given Example 1.2, = 0, B = 45, C =95, = 45, E = 95, F = 95, consistent full assignment x = collect.constraints lines 1-3 hold choice, necessarily must hold here. Lines 4-5 giveconstraints environments whose assignments given full assignment,simple interval constraints must hold, do. Lines 6-7 give constraintsenvironment include different assignments full assignment, constraintsneed hold schedule consistent.Drake provides dynamic execution Labeled STN, making decisions run-time,late possible.Definition 3.12 (Dynamic execution Labeled STN) dynamic executionLabeled STN simultaneous real-time construction full assignment corresponding consistent schedule. executive decides time whether executeevents time t, suitably small . Possible assignments choices eliminated consideration necessary schedule events. executive may arbitrarilyselect consistent schedule.Example 1.2 gave dynamic execution rover problem dispatcher selected choices scheduling times dynamically, choosing option collect samplesimmediately start sample collection activity.conclude section discussing equivalence DTNs Labeled STNs,allow easier comparison prior work. Recall definition DTNs (Stergiou &Koubarakis, 2000).Definition 3.13 (Disjunctive Temporal Network) Disjunctive Temporal NetworkhV, Ci set events V set disjunctive constraints C. disjunctive constraintCi C formci1 ci2 ... cin ,(8)positive integer n cij simple interval constraint. before, scheduleassignment time event. schedule consistent leastone simple interval constraint cij satisfied every disjunctive constraint Ci . DTNconsistent least one consistent schedule exists.620fiDrake: Efficient Executive Temporal Plans ChoiceDTN Labeled STN definitions analogous, except differencechoices specified. construct Labeled STN equivalent DTN creatingchoice variable disjunctive constraint, one value disjunct. Thus,xi = 1...n. disjunctive constraint DTN, cij labeled environment xi = j.Non-disjunctive constraints labeled {}.Example 3.14 Consider DTN three events, A, B, C. Assume two disjunctive constraints, hA, B, 3, 5i, hB, C, 0, 6i hA, C, 4, 4i. corresponding Labeled STN would one binary choice, represented x {1, 2}. wouldthree labeled simple interval constraints: hA, B, 3, 5, {}i, hB, C, 0, 6, {x = 1}i,hA, C, 4, 4, {x = 2}i.see reverse construction, note DTN specifies set simple intervalconstraint conjunctive normal form. Labeled STNs allow specification somewhatcomplex boolean expressions, boolean expressions reducible conjunctivenormal form, Labeled STNs expressive. mapping DTNsLabeled STNs straightforward construct Labeled STN directly usesconjunctive normal form expression.Example 3.15 Consider rover problem, given Labeled STN Example 3.11.represent constraint 0 F 100 CF,A , identify problemfollowing boolean formCF,A CB,A CF,E ((CC,B CE,C ) (CD,B CE,D ))(9)could expand conjunctive normal formCF,A CB,A CF,E (CC,B CD,B ) (CC,B CE,D ) (CD,B CE,C )form, construct DTN directly.(10)Thus, like DTN, Labeled STNs provide rich notion choice. Given definitionproblem Drake solves section introduction environments,next two sections develop labeled machinery Drake uses efficiently perform temporalreasoning.4. Distance Graphs Temporal ReasoningDechter et al. (1991) showed STN reasoning reformulated shortest pathproblem associated weighted distance graph. connection importantweighted graphs easy manipulate well developed theory efficient algorithms, hence practical algorithms STNs based connection. Drakefollows prior literature, frames temporal reasoning labeled versionshortest path problems. section begins develop formalism Labeled ValueSets Labeled Distance Graphs, allow us compactly represent shortest pathproblems algorithms. begin reviewing transformation STNs.621fiConrad & WilliamsDefinition 4.1 (Distance Graph associated STN) distance graph associated STN pair hV, W vertices V edge weights W . eventassociated vertex V . vertices exactly correspond events STN.weights function V V R. simple temporal constraint l B urepresented edge weights W (B, A) = u W (A, B) = l.Figure 1.2 shows example conversion STN distance graph. Recall STN consistent associated distance graphnegative cycles (Dechter et al., 1991). compilation algorithm STN takesassociated distance graph input outputs another distance graphdispatchable form.Definition 4.2 (Dispatchable form distance graph) weighted distance graphdispatchable form STN executive may dynamically execute STNgreedy fashion construct consistent schedule using local propagations.dispatchable form minimal edges actually needed dispatchercorrect execution.all-pairs shortest path (APSP) graph distance graph associated STNdispatchable form explicitly contains possible constraints STN(Muscettola et al., 1998). minimal form computable performing pruningAPSP graph.begin building labeling formalism defining labeled value pairs.labeled simple temporal constraints environments, labeled values associate valuesenvironments.Definition 4.3 (Labeled Value Pair) Labeled Value Pair pair (a, e),value e E environment. value entailed (usually assignmentinequality bound) environments assignments e hold.compilation dispatch, Drake uses labeled value pairs track real valuedbounds, R. compilation, performing shortest path computations,Drake tracks predecessor vertices, value may pair (b, v) R V .two types values complicates discussion somewhat, necessarycompilation algorithms, allows elegant implementation relaxation algorithmdirected, weighted graphs. ATMS strategy associating environments valueswell founded arbitrary type value, choices sound. Labeled valuepairs always use minimal environments, is, environment specifies smallest setassignments possible implication true. minimality criticallabeling system efficient.Example 4.4 choice variable x {1, 2}, (3, {x = 1}) real valuedlabeled value pair. Similarly, event, ((2, A), {x = 2}) possible predecessorgraph labeled value pair.arrived crucial contribution paper: extending dominationlabeled space. inequality B 4 5, clear need622fiDrake: Efficient Executive Temporal Plans Choicekeep dominant value, four, may discard five. Shortest path algorithmswidely use concept dominance propose many possible paths keeptightest one. applied labeled value pairs, dominance involves ordering twoparts, value environment. Drake, values always ordered using real valuedinequalities, either . paper mostly uses , except reasoning lowerbounds dispatch, explicitly noted. necessary, direct replacementinequality direction suffices extend definitions. Environments orderedconcept subsumption.Definition 4.5 (Subsumption Environments) environment e subsumes e0every assignment xi = dij e, assignment exists e0 , denoted xi = dij e0 .Example 4.6 environment {x = 1, = 2, z = 1} subsumed {x = 1, z = 1}assignments later environment included former.domination labeled value pairs applies orderings simultaneously.Definition 4.7 (Dominated Labeled Value Pair) Let (a, ea ), (b, eb ) two labeledvalue pairs values ordered . (a, ea ) dominates (b, eb ) bea subsumes eb .Example 4.8 B 4 {} also B 4 {x = 1},first inequality non-dominated environment less restrictive. Thus (4, {})dominates (4, {x = 1}). Likewise, B 2 {x = 1}, constraint dominatesconstraint B 4 {x = 1}, first inequality tighter holdswithin every environment second inequality holds, hence (2, {x = 1}) dominates(4, {x = 1}).represent various values bound may have, depending choices executive makes, Drake collects non-dominated labeled value pairs Labeled ValueSet.Definition 4.9 (Labeled Value Set) Labeled Value Set, L set non-dominated labeled value pairs, is, set pairs (ai , ei ). Thus, may write L = {(a1 , e1 ), ...(an , en )}.labeled value pair set dominant another pair set.particular labeled value set, values type, either real valuesvalue/vertex pairs.Example 4.10 Assume single choice variable, x {1, 2}. real valuedvariable, R value 3 x = 1 5 x = 2. represented labeledvalue set, = {(3, {x = 1}), (5, {x = 2})}.Finally, modify distance graphs use Labeled Value Sets instead real valuesweights, leading definition labeled distance graphs.623fiConrad & WilliamsDefinition 4.11 (Labeled Distance Graph) labeled distance graph G tuplehV, E, W, Xi. V set vertices E set directed edges vertices, represented ordered pairs (i, j) V V . W weight function edges realvalued labeled value sets, edge (i, j) E associated labeled value setW (i, j). X description choices variables, defining set environmentsmay appear labeled value sets contained W .Example 4.12 Consider simple graph three vertices, V = {A, B, C}. graphcontains edges E = {(A, B), (A, C), (B, C)}. one choice variable x {1, 2}. Edge(A, B) weight 1 regardless choice. Edge (A, C) 3 x = 1 7 x = 2.Finally, edge (B, C) weight 4 x = 2. labeled distance graph shown Figure4.1.(1, {})B{(3, {x = 1}),(7, {x = 2})}{(4, {x = 2})}CFigure 4.1: simple Labeled Distance Graph one choice variable, x {1, 2}association Labeled STNs labeled distance graphs closely parallelsassociation STNs distance graphs.Definition 4.13 (Labeled Distance Graph Associated Labeled STN)labeled distance graph associated Labeled STN vertex associatedevery event Labeled STN. labeled inequality, denoted e : X w,e E, X, V , w R, edge (X, ) E. labeled value set W (X, ) includeslabeled value pair (w, e) pair dominated another (w0 , e0 ) W (X, ).Example 4.14 Figure 1.4 essentially labeled distance graph rover problemdescribed Example 1.1, except replace informal notation equivalentlabeled value sets. example, edge (B, C) currently weight : 60,replace labeled value set {(60, {x = collect})}.Drake compiles input Labeled STN creating associated labeled distance graphrepresentation constructing new labeled distance graph transformationinput graph.Definition 4.15 (Dispatchable Form Labeled STN) labeled distance graphdispatchable form Labeled STN represents constraints necessaryaccurately perform dispatch greedy strategy, using local propagations.624fiDrake: Efficient Executive Temporal Plans Choicesection constructed labeling structures Drakes uses, beginning labeledvalue pairs building labeled value sets minimal sets labeled pairs. Labeledvalue sets used construct labeled distance graphs, defined constructgraph associated Labeled STN, Drakes compilation algorithms operate.5. Labeled Value Set Maintenance Systemprevious section defines representation labeled distance graphs labeled valuesets; section provides tools manipulating them. primary focus labeled valuesets maintain non-dominated labeled value pairs, makes labeled valuesets compact efficient. section introduces three concepts. First, describeextract values labeled value set, called query, allowing us find dominantvalue implied environment. Second, handle assignments choicesinconsistent, called conflicts. Third, apply functions labeled value sets,allows us perform computations directly.First define query, lets us extract precise dominant value(s)guaranteed hold particular environment.Definition 5.1 (Labeled Value Set Query) query operator A(e) defined labeled value set e E. query returns set values including ai pair(ai , ei ) A, ei subsumes e, pair (aj , ej )ej subsumes e aj < ai . environment ei subsumes e, A(e) returns .introduce convention: using pairs real values verticesvalues labeled value pairs, consider inequalities pairs defined entirelyreal value. Thus, (5, A) < (6, E) (5, A) (5, E).Example 5.2 Assume two choice variables x, {1, 2}, real valuedvariable represented labeled value set, = {(3, {x = 1}), (5, {})}. A({x =1, = 1}) = 3 input environment subsumed environmentslabeled value set, three dominant. A({x = 2, = 2}) = 5 emptyenvironment labeled value set subsumes input environment.Example 5.3 Let labeled value set values pairs real valuesvertices, = {((3, A), {x = 1}), ((5, A), {y = 1}), ((5, B), {})}. A({x = 1, = 2}) ={(3, A)} environments subsumed, (3, A) < (5, A) (3, A) < (5, B).A({x = 2, = 1}) = {(5, A), (5, B)} tighter value applicable neithervalue real part five less other.query operator defines expansion compact form explicit listingvalues environment. Although Drake never performs expansion, usefuldetermining correct behavior Labeled Value Set designing algorithms.Second, consider conflicts, important function ATMS allows trackinconsistent environments. case, inconsistent environment signals inconsistentcomponent STN. standard strategy ATMS keep list minimal conflicts,also referred no-goods (de Kleer, 1986).625fiConrad & WilliamsDefinition 5.4 (Conflict) conflict environment e e subsumes e0 ,e0 inconsistent. conflict e minimal e00 E e00 e,e00 conflict (Williams & Ragno, 2007).Example 5.5 example, compilation process might determine x = 1 = 1contradictory choices, cannot selected together execution. Then,{x = 1, = 1} conflict.Often, reasoning algorithms keep cache conflicts avoid performing work environments previously discovered contain inconsistency. practice, setconflicts become large unwieldy, leading practical systems keep subset conflicts, using principles temporal locality maintain small, useful cache.Since cache conflicts incomplete, cache miss, requiring problem solverre-derive inconsistency, missing cache would never lead incorrectly acceptinginconsistent solution. good example conflict learning widely studiedSAT-solver MiniSAT (En & Srensson, 2004). real-time execution, incompletecache conflicts would require Drake perform non-local propagation re-test inconsistency case cache miss. extra step violates principles dispatchableexecution. Therefore, Drake maintains complete cache known conflicts, allowingDrake verify environment known inconsistent single checkcache. Furthermore, Drake quickly test whether complete environmentsvalid, inconsistencies readily available.known conflict, Drake sometimes needs determine avoid conflict,is, minimal environments ensure conflict possible.Definition 5.6 (Constituent Kernels, Williams et al., 2007) conflict ec associated set constituent kernels, environment specifies singleassignment takes variable assigned conflict assigns different value.Hence, ek constituent kernel, environment e ek subsumes eimplies ec subsume e, hence subject conflict. Thus, saye avoids conflict.Example 5.7 three variables, X, Y, Z {1, 2}, assume {x = 1, = 1} conflict. constituent kernels {x = 2} {y = 2}, complete environmentcontain conflict must assign either x one.final tool needed ability perform temporal graph reasoning labeledvalue sets, principally accomplished computing path lengths propagatinginequality bounds. construct approach denoting inference rule valuesfunction f . Then, build method applying f labeled value setsrule applying labeled value pairs. begin defining union operationenvironments, fundamental operation environments temporalreasoning, ATMS literature (de Kleer, 1986).Definition 5.8 (Union Environments) union environments, denoted e e0union assignments environments. e e0 assign different valuesvariable xi , valid union e e0 = , symbol626fiDrake: Efficient Executive Temporal Plans Choicefalse. e e0 subsumed conflict, e e0 = . value signifiesconsistent environment e e0 hold simultaneously.Example 5.9 commonly, unions used compute dependence new derivedvalues. = 2 {x = 1} B = 3 {y = 2}, C = + B = 5{x = 1} {y = 2} = {x = 1, = 2}.Using notation, inference labeled value pairs involves performinginference values produce new value, unioning environments producenew environment.Lemma 5.10 Consider labeled value pairs (a, ea ), (b, eb ). Applying function fpair yields (f (a, b), ea eb ).Proof environment e, ea subsumes e entailed, eb subsumes eb entailed, definition labeled value pairs. Additionally, ea eb subsumes eea subsumes e eb subsumes e. Therefore, ea eb subsumes e entails valuesa, b, hence allows us compute f (a, b). Thus, (f (a, b), ea eb ) well defined.Note lemma, ea eb may produce , would indicate labeledvalue pair never holds consistent environment may discarded.Example 5.11 Consider computing quantity (3, {x = 1}) + (6, {y = 1}) = (3 + 6, {x =1} {y = 1}) = (9, {x = 1, = 1}).function respects dominance values, may apply entire labeledvalue sets.Definition 5.12 function f (a, b) consistent dominance values a, b, cd, c, b = f (a, b) f (a, d), f (a, b) f (c, b), f (a, b) f (c, d).Lemma 5.13 variables A, B represented labeled value sets f consistentdomination ordering used f , result C = f (A, B) represented labeledvalue set containing non-dominated subset labeled value pairs (f (ai , bj ), ei ej )constructed every pair labeled value pairs (ai , ei ) (bj , ej ) B.Proof lemma follows argument cross product applying flabeled value pairs B produces possible labeled value pairs. Since mustensure labeled value pairs include dominant labeled value pairs C,require f consistent ordering dominant values B,available, sufficient derive dominant labeled value pairs C.conclude section example relaxation labeled distance graph,core rule inference weighted graph algorithms uses pathB C compute possible path weight C. derived path length replacesold path newly derived path length shorter.627fiConrad & WilliamsExample 5.14 Consider labeled distance graph Figure 4.1. compute W (A, B)+W (B, C) = {(1, {})}+{(4, {x = 2})} = {(5, {x = 2})}. Compare existing knownweights W (A, C) = {(3, {x = 1}), (7, {x = 2})}, determine new valuereplaces old value 7. update, W (A, C) = {(3, {x = 1}), (5, {x = 2})}.two fundamental inferences performed labeled value sets: relaxationweighted edges compilation, sums differences edge weights computebounds execution times dispatch. follow framework outlined here,explained detail compilation dispatch sections, respectively.operations complete definition labeled value sets following sections useconstruct compact compilation dispatching algorithms.6. Dispatching Plans ChoiceGiven foundation Labeled STNs, labeled value sets, labeled distance graphs,turn central focus article - dynamic execution Labeled STNs. Recalldispatcher uses local, greedy algorithm make decisions run-time low latency,accuracy approach guaranteed compilation step. begindispatcher low latency execution fundamental goal workbecause, prior work, compiler designed produce output appropriatedispatcher.adapt STN dispatcher developed Muscettola et al. (1998) workdispatchable labeled distance graphs. Essentially, Drakes algorithms substitute real numberbounds execution times, STN dispatcher, labeled value sets. Additionally,adapt Tsamardinos et al.s (2001) approach reasoning multiple possible options,is, allowing dispatcher accept proposed execution time event leastone full assignment choices consistent schedule. present Drakesdispatching algorithms first reviewing standard STN dispatching, adapttechniques handle labels.6.1 STN DispatchingMuscettola et al. (1998) showed given dispatchable form STN, simple greedydispatcher correctly execute network updates performed neighboringevents dispatchable form STN. dispatcher loops non-executedevents time step, selecting event execute possible, else waitingnext time step. process continues either events executed failuredetected.Determining whether event executable relies two tests. First, dispatcher testswhether ordering constraints event satisfied, called testingenablement. simple temporal constraint may imply strict ordering two events,dispatcher must explicitly test ensure event scheduledevent must precede it. Second, dispatcher efficiently tracks consequencessimple temporal constraints event neighbors computing executionwindows event. Execution windows tightest upper lower bounds derivedevent one-step propagations execution times. current time628fiDrake: Efficient Executive Temporal Plans Choiceevents execution window enabled, event may scheduled currenttime.briefly recall derivation two rules executing events. Recallweighted edge distance graph corresponds inequalityB wAB(11)B execution times events l real number bound.select execution time tA event B yet scheduled, rearrangeinequalityB wAB + tA(12)produces new upper bound execution time B. Likewise, yetscheduled select tB execution time B, rearrange inequalitytB wAB .(13)Thus, derive new lower bound A. If, form, wAB < 0, B < A, eventB must precede A, implying enablement constraint.recast rules terms propagations distance graph. eventscheduled time t, propagate outbound edges (A, B) deriveupper bounds B wAB + t, inbound edges (B, A) derive lower boundsB wBA . Event B event predecessor negative weight edge(B, A). usual, dispatching affected dominant upper lower bounds,dispatcher stores dominant constraints.Example 6.1 Consider dispatchable distance graph fragment Figure 6.1. execution windows begin without constraint, B . beginexecution = 0, B executable yet enabled; negative weightededge (B, A) implies must executed first. predecessor constraintszero lies within execution bound, may executed time. Propagating time= 0 allows us derive bounds 2 B 8. B may executed time2 8. dispatcher reached time 9 without executed B, mustsignal failure.8-2BFigure 6.1: dispatchable distance graph fragment.final consideration dispatcher zero-related events. two events constrained executed precisely time, prior work requiresevents collapsed single vertex dispatchable graph. Otherwise, zero-relatedvertices may cause dispatcher make mistakes must occur together, yet629fiConrad & Williamsappear independently schedulable. Equivalently, dispatcher may simulate collapse always executing zero-related vertices set. example, B knownzero-related, dispatcher may schedule together, scheduling events timeexecution windows enablement constraints B satisfied. Notesince zero-related, impossible enablement constraintthem.6.2 Labeled STN DispatchingDrake relies fundamental structures rules STN dispatcher,modifies step consider labels. Since edge weights labeled value sets, executionwindows also labeled value sets, implying upper lower bounds executiontimes events may vary depending assignments choices may vary separately.possible bound enablement constraint, Drakes dispatcher must either enforceconstraint, discard constraint decide select associated environment.Broadly, strategy Tsamardinos et al. (2001), component STNsdispatched parallel, proposed scheduling decisions may acceptedconsistent least one STN.begin considering update propagation rules derive execution windows. STN propagations involve adding edge weights (or negative weights)execution time event. upper bound every event initially {(, {})}every lower bound initially {(, {})}. Upper bounds dominated low values,inequality, lower bounds dominated large values, inequality.following theorem describes propagation execution bounds, labeledimplementation Equations 12 13.Theorem 6.2 event executed time t, consider event B.every (wAB , eAB ) W (A, B), (wAB + t, eAB ) valid upper bound execution timesB every (wBA , eBA ) W (B, A), (t wBA , eBA ) lower bound executiontimes B.Proof rules direct extension STN propagation labeled case usinglabeled operations Definition 5.12. Since execution actually occurred, holdspossible environments, thus give empty environment {}. applyDefinition 5.12, substituting labeled version addition.dispatch, new bounds added labeled value sets Bu Bl ,maintain non-dominated bounds.{(5, {x = 1}), (2, {})}B{(7, {x = 1}), (8, {})}Figure 6.2: dispatchable labeled distance graph fragment.630fiDrake: Efficient Executive Temporal Plans ChoiceExample 6.3 Consider labeled distance graph fragment Figure 6.2. eventexecuted = 2, derive bounds {(7, {x = 1}), (4, {})} B {(9, {x =1}), (10, {})}Since bounds may vary choices, Drake cannot generally expect obeypossible constraints, instead required enforce constraints impliedleast one complete environment.Example 6.4 Assume event lower bounds represented labeled value set{(2, {x = 1}), (0, {})}. implies set choices x = 1, 2,otherwise, 0 sufficient. dispatcher executes = 0, mayselect x = 1. Thus, dispatcher restrict choices includex = 1, leaving consistent options, may execute = 0.remaining consistent full assignments choices require x = 1, dispatchermust wait = 2 executing A.Drake performs reasoning collecting environments boundsparticular execution would violate, determining whether environmentsmade conflicts without making every complete environment inconsistent. completeenvironments would remain consistent, execution performed environmentsmade conflicts; otherwise execution possible, discarded.Finally, Drake simulates collapse zero-related events. time, Drake attempts execute event individually also attempts execute sets zerorelated vertices recorded compiler. noted before, zero-related sets may existenvironments others. zero-related set enforced, member events must executed together, all. Therefore, dispatcher considersexecuting set events strict subset particular zero-related set, leavingleast one member zero-related set, must discard environmentszero-related set implied. Additionally, cannot enablement constraintszero-related events complete environments zero-related groupholds, environments may imply strict orderings events, dispatcher discards executing zero-group simultaneously. Hence, dispatcher mustdiscard associated environments.summarize rules follows, illustrated Example 6.7.Theorem 6.5 set one event set zero-related events Labeled STN,set may executed time least one consistent completeenvironment where:1. every Al lower bound labeled value set S, Al A,every (l, e) Al l > t, e conflict.2. every Au upper bound labeled value set S,Au A, every (u, e) Au u < t, e conflict.3. every pair events, S, B/ S, B yet scheduled, every(w, e) W (A, B) w < 0, e conflict.631fiConrad & Williams4. every zero-related set events Z environment e, Z, e conflict.5. every A1 , A2 S, every (w, e) W (A1 , A2 ) w < 0, e conflict.Proof consistent full environment creating conflicts,necessarily subsumed environments constraints implyevents cannot executed time t. Thus, consistent full environment correspondscomponent STN every constraint holds, events may executed.consistent environment, least one constraints prohibiting proposedexecution exists remaining component STN, execution valid.Similarly STN case, dispatcher must check missed upper boundsevery time step. STN, missed upper bound implies execution failed.Labeled STN, missed upper bounds implies complete environments subsumedenvironment missed upper bound longer valid.Theorem 6.6 event executed time t, upper bound labeled value set Au ,(u, e) Au u < t, e conflict.Proof theorem follows noting upper bound exists every componentSTN corresponding complete environment subsumed e, thus every environmentsubsumed e inconsistent, definition, makes e conflict.possible missed upper bounds could invalidate remaining complete environments, case dispatch failed dispatcher signal errorimmediately.Example 6.7 Consider dispatchable labeled distance graph Figure 6.3, eventsA, B, C, choice variables x, {1, 2}. zero-related set {A, C}environment {x = 1}. Assume current time = 0 eventsexecuted yet. possible complete environments initially consistent. Considerpossible executions consequences.Event C predecessors, restrictions execution window. However,part zero-related set, may executed make {x = 1}conflict, order remove zero-related set possible executions.feasible, may execute C = 0 create conflict. this,ordering inequality implied edge (A, D) necessary consistentexecution, environment cannot made conflict without making completeenvironments inconsistent.Event predecessor {x = 2}, C predecessor {y = 1},part zero-related set {x = 1}. execute = 0, wouldneed make three environments conflicts, would invalidate possiblechoices, may execute = 0.632fiDrake: Efficient Executive Temporal Plans Choicezero-related set {A, C} execution window restrictions eitherC, predecessor {x = 2} edge (A, D). Additionally, edge(A, C) negative weight 1 environment {y = 2}, environmentalso made conflict. Thus, create conflicts {x = 2} {y = 2}execute B = 0.Event B predecessor {y = 1} yet executed, maymake environment conflict execute B. Assume C executed= 0, enablement constraint satisfied, execution B= 3 requires making {y = 1} conflict. Additionally, current time grows= 7 B yet executed, upper bound violated{y = 1} conflict.Event predecessor C environment {}, C yet executed.Since making {} conflict makes complete environments inconsistent, cannotexecuted.{(3, {y = 1})}B{(6, {y = 1})}{(2, {x = 2})}{(0, {x = 1}),(1, {y = 1})}{(0, {x = 1})}{(1, {})}C{(6, {y = 2})}Figure 6.3: dispatchable labeled distance graph.completes presentation Drakes dispatch algorithms. Essentially, makestwo adaptations STN dispatcher: (1) maintain labeled value sets executionwindows events (2) allow dispatcher select choices creating conflicts. next section describes compilation algorithm, computesdispatchable form input Labeled STNs, ensuring local reasoning stepsdispatching algorithm satisfy requirements plan.633fiConrad & Williams7. Compiling Labeled Distance Graphscomplete description Drake compiler, reformulates input Labeled STN form dispatcher guaranteed execute correctly. compilerleverages labeling concepts presented efficiently compute compact dispatchable form input plans. STN compiler takes distance graph inputoutputs another distance graph, minimal dispatchable form input problem. Similarly, Drakes compiler takes labeled distance graph input outputs labeleddistance graph minimal dispatchable form input.Muscettola et al. (1998) introduced initial compilation algorithm STNsoperates two steps. First, computes All-Pairs Shortest Path (APSP) graph associated STN, dispatchable form. Second, compiler prunesedges prove redundant non-pruned edges, dispatchertherefore need make correct decisions. pruned edges dominated,removal significantly reduces size dispatchable graph. compiler testsdominance applying following rule every triangle APSP graph.Theorem 7.1 (Triangle Rule, Muscettola et al., 1998) Consider consistent STNassociated distance graph satisfies triangle inequality; directed graph satisfies triangle inequality every triple vertices (A, B, C) satisfies inequalityW (A, B) + W (B, C) W (A, C).(1) non-negative edge (A, C) upper-dominated another non-negative edge (B, C)W (A, B) + W (B, C) = W (A, C).(2) negative edge (A, C) lower-dominated another negative edge (A, B)W (A, B) + W (B, C) = W (A, C).Although basic concept domination unchanged, dominated constraintsneeded executive, specifics quite different here. Domination withinlabeled value sets refers labeled values make labeled values withinset unnecessary. context edge pruning, one edge could dominate anothertwo edges share start end vertex, both. develop labeled versionedge pruning, labeled value one edge weight labeled value set dominatevalue different edge weight labeled value set, corresponding edges sharestart end vertex.Example 7.2 Consider two weighted graph fragments Figure 7.1. case, edge(A, C) dominated, shown theorem.compiler searches dominated edges removes together.care necessary ensure pair edges AC BC provide justificationpruning other; edges said mutuallydominant. Typically, prunedgraphs number edges closer N log N , N 2 , significant savings.first prototype Drake, Conrad, Shah, Williams (2009) introduced labeled extensionalgorithm. extension used perform task execution ATHLETERover within Mars Yard NASA JPL.Although simple effective, algorithm scale gracefully large problemsuses entire APSP graph intermediate representation, much larger634fiDrake: Efficient Executive Temporal Plans Choice-5-41BC253BC(a)Lowerdominationweighted graph(b)Upperdominationweighted graphFigure 7.1: Examples upper lower dominated edges.final result. resolve this, Tsamardinos, Muscettola, Morris (1998) presentedfast compilation algorithm interleaves APSP step pruning step, avoidsever storing entire APSP graph. algorithm derived Johnsons algorithmcomputing APSP, incrementally builds APSP repeated SSSP computations(Cormen, Leiserson, Rivest, & Stein, 2001). Johnsons algorithm uses Dijkstras algorithminner loop, providing faster performance Floyd-Warshall sparse graphs.Essentially, fast compilation algorithm loops events graph, computesSSSP event, adds non-dominated edges event sourcedispatchable form. Thus, algorithm needs store final dispatchable graphone SSSP, avoiding bloat intermediate representation. Thus, algorithmbetter space time complexity APSP step followed pruning.paper introduces novel extension Drake system adapts fast compilation algorithm labeled graphs order avoid unnecessary storage growthcompilation. fast algorithm requires number steps; section describescomponent original fast algorithm adaptation labeled setting. First,recall Johnsons strategy compute APSP iterated SSSP, presentlabeled adaptation SSSP algorithm. Second, discuss predecessor graphsresult SSSP traverse them. Third, describe interleavepruning repeated SSSP computations. Finally, discuss issues arisingmutual dominance, preprocessing step used resolve them.7.1 Johnsons Algorithm Structure Fast AlgorithmMany shortest path algorithms weighted distance graphs essentially perform repeatedrelaxation graph. Floyd-Warshall loops repeatedly entire graph, relaxingedges computing entire APSP single computation. Johnsons algorithmcomputes APSP one source vertex time, using Dijkstras SSSP algorithminner loop perform relaxations efficiently. Since Dijkstras algorithm workspositively weighted graphs, Johnsons algorithm re-weights graph Dijkstracalls un-weights afterward. Unfortunately, adapting Dijkstras algorithm labeleddistance graphs inefficient re-weighting adds subtracts labeled valuesets, compatible single ordering. Therefore, use BellmanFords SSSP algorithm instead; sacrifice improved run-time fast algorithm,635fiConrad & Williamspreserve lower space overhead. fast STN compilation algorithm copiesessential structure Johnsons algorithm. section illustrates overall algorithmunlabeled case partial example.Example 7.3 Consider one step compilation shown Figure 7.2. input distancegraph shown Figure 7.2a. compute SSSP input source vertexB, output predecessor graph shown 7.2b, depicts shortest distancespaths B. weights vertices indicate complete APSP graphcontain edge B weight 4, B C weight 1, Bweight 0. Furthermore, original graph, shortest path B usesedge B A. shortest path B C either B C B C;equal length. shortest path B B D.However, dispatchable form problem actually need threeedges, compiler deduce predecessor graph SSSP values.Roughly, since lower distance B C, along shortest path C,edge BC necessary. Therefore, two edges inserted dispatchablegraph, depicted Figure 7.2c, edge BC discarded. process repeatedthree vertices.4-48BB0 13 -1B05-1CC-43(a) Input Distance Graph11(b) Predecessor Graph SourceBC(c) Partial dispatchablegraph edgessource vertex BFigure 7.2: single step fast reformulation algorithm STNs7.2 Labeled Bellman-Ford AlgorithmDrake uses Bellman-Ford algorithm central building block variant fastSTN algorithm Drake uses; Bellman-Ford derives tightest possible edge weights,simultaneously deriving predecessor graph. graph provides enough informationprune dominated edges. begin, provide Algorithm 7.1, taken directly (withslightly altered notation) work Cormen et al. (2001). algorithm loopsedges performs relaxations, tests negative cycles ensure resultvalid. value d[v] distance vertex v input source vertex s.value [v] vertex (not necessarily unique) predecessor v forming636fiDrake: Efficient Executive Temporal Plans Choiceshortest path v. Relating Figure 7.2b, corresponds annotations nextvertices, specifies directed edges.Algorithm 7.1 Bellman-Ford Algorithm1: procedure BellmanFord(V, E, W, s)2:InitializeSingleSource(V, W, s)3:{1...|V | 1}4:edge (u, v) E5:Relax(u, v, W )6:end7:end8:edge (u, v) E9:d[v] > d[u] + W (u, v)10:return false11:end12:end13:return true14: end procedure15:16:17:18:19:20:21:22:23:24:25:26:27:. Loop relaxation. Check negative cycles. Fail negative cycle foundprocedure InitializeSingleSource(V, s)vertex v Vd[v][v] nilendd[s] 0end procedureprocedure Relax(u, v, W )d[v] > d[u] + W (u, v)d[v] d[u] + W (u, v)[v] uendend proceduresee next sections, fast compilation algorithm STNs requiresaccess entire predecessor graph, encodes shortest pathsgraph, rather single path. compute entire graph, Drake makes [v]set, Relax determines d[v] = d[u] + W (u, v), pushes u onto d[v].strict inequality holds d[v] updated, [v] set single element set {u}.discuss changes necessary adapt Bellman-Ford algorithm LabeledDistance Graphs. relaxation procedure computes new bound path lengthv, dominates old value, replaces old value. vertex u allowsus derive current dominant value d[v], stored [v]. Drakes use labeledvalue sets store value pairs (d, ) R V allow perform tasks once,one data structure.637fiConrad & Williamssee works, consider example:Example 7.4 Figure 7.3a, edge (A, B) forms snippet labeled distance graph;consider computing SSSP source vertex A. know initialization routineevery choice set d[u] = 0 source vertex d[u] = others,set [u] = nil every vertex. combined notation, initial value weightvertices (0, nil) (, nil), labeled empty environment {}.initial weights shown vertices.relaxation edge allows us derive B distance 8 environment {x = 1}, predecessor A. Hence, add labeled value pair ((8, A), {x = 1})labeled value set weight B. new value tighter value d,hence kept, dominate old value, thus kept. single insertionstep updates distance B predecessor B along shortestpath. result depicted Figure 7.3b.clear elected keep non-identical values numericvalue: labeled value sets hold predecessors target vertices,single predecessor. Algorithm 7.2 shows generalization example. Initializationexactly example, assigns initial values standard algorithmempty environments. relaxation, following Lemma 5.13, potential new pathlengths cross product addition weight u added weight edgeu v, labeled union environments, union validsubsumed known conflicts. Naturally, relaxing u edge v, upredecessor. adding value labeled value set d[v], dominationcriterion used determine new path length non-dominated, prune nondominant path lengths predecessors appropriate.final modification original algorithm test negative cycles;negative cycle detected another relaxation edge would decreasedistance source vertex. labeled case, choices maynegative cycles others may not. begin computation computing relaxationd[u] + W (u, v) labeled addition operator, discard predecessor verticesd[u], thus producing real valued labeled value set. environmentd[v] > d[u] + W (u, v) holds, environment conflict Labeled STN.Finding minimal conflicts practice somewhat convoluted. Consider pairlabeled values (dv , ev ) d[v], (duw , euw ) d[u] + W (u, v) turn. dv > duwmight conflict, however, may environments smaller, dominantvalue d[v] takes precedence dv , thus preventing inequality satisfied.Hence, exists, conflict deduce ev euw modifying union avoidenvironments e0v (d0v , e0v ) d[v] d0v duw . possible conflictscould invalidate possible choices, executive tests for, determiningplan dispatchable.638fiDrake: Efficient Executive Temporal Plans ChoiceExample 7.5 Consider following values inequality test, given two binary choicevariables:d[v] = {(2, {y = 1}), (4, {})}(14)d[u] + W (u, v) = {(3, {x = 1}), (5, {})}(15)(16)must find make conflicts minimal environments imply d[v] > d[u] +W (u, v) holds. side inequality two possible values, considerfour pairs values could satisfy inequality. Three pairs satisfyinequality, thus cause conflict: (2, {y = 1}) < (3, {x = 1}), (2, {y = 1}) < (5, {})(4, {}) < (5, {}). last pair, (4, {}) > (3, {x = 1}), satisfies inequality,pair could imply union corresponding environments, {} {x = 1},conflict. However, reach (4, {}) left hand side, skipped smaller value,(2, {y = 1}) d[v]. correctly address ordering, conflict must also avoidenvironment smaller value. Taking {} {x = 1} avoiding {y = 1} produces oneenvironment, {x = 1, = 2}, valid environment, hence conflict.{((0 , nil) ,{})}{(( , nil) ,{})}B{(8, {x = 1})}(a) Relaxation{((0, nil), {})}{((8, A), {x = 1}), ((, nil), {})}{(8, {x = 1})}B(b) RelaxationFigure 7.3: single labeled relaxation step.7.3 Traversals Labeled Predecessor Graphsfast compilation algorithm STNs performs traversals predecessor graphsproduced SSSP analysis, checks edge along traversal dominance.used reduce graph minimal dispatchable form. unlabeled case,[u] values specify directed graph Figure 7.2b, may use depth-firstexploration enumerate possible paths beginning source vertex SSSPcomputed for. However, labeled case, care necessary.simplest way understand paths valid complete environmentsconsider projection predecessor graph particular complete environmente. Take every labeled value set d[u] query e. result gives shortest pathdistance predecessors, producing standard unlabeled predecessor graph.639fiConrad & WilliamsAlgorithm 7.2 Labeled Bellman-Ford Algorithm1: procedure LabeledBellmanFord(V, E, W, S, s)2:LabeledInitializeSingleSource(V, W, s)3:{1...|V | 1}. Loop relaxations4:edge (u, v) E5:LabeledRelax(u, v, W )6:end7:end8:edge (u, v) E. Test negative cycles9:labeled value pair (dv , ev ) d[v]10:labeled value pair (duw , euw ) d[u] + W (u, v)11:dv > duw12:AddConflict(ev euw , split avoid e0v13:(d0v , e0v ) d[v] d0v duw )14:end15:end16:end17:end18:IsSomeCompleteEnvironmentConsistent?()19: end procedure20:21:22:23:24:25:26:27:28:29:30:31:32:procedure LabeledInitializeSingleSource(V, s)vertex v V \d[v] {((, nil), {})}endd[s] {((0, nil), {})}end procedureprocedure LabeledRelax(u, v, W )labeled value pair ((du , u ), eu ) d[u]labeled value pair ((dw , w ), ew ) W (u, v)AddToLVS(d[v], ((du + dw , u), eu ew ))endendend procedure640fiDrake: Efficient Executive Temporal Plans ChoiceExample 7.6 Consider labeled graph fragment Figure 7.4a, verticeslabeled SSSP weights source vertex A. consider predecessorgraph path lengths implied environment e = {x = 1, = 1}: d[B](e) = (2, A)d[C](e) = (1, A). Hence, vertices B C predecessor,B distance 2 A, C distance 1 A, shown Figure 7.4b. Vertexdistance 6 A, predecessor C. important feature exampleenvironment, C predecessor B, even though pair (7, C) labeled{y = 1}, subsumes e. Predecessors provided dominant path length.{((2, A), {x = 1, = 1}),((7, C), {y = 1}),((, nil), {})}{((0, nil), {})}{(2, {x = 1, = 1})}B{(4, {y = 1})}{(1, {x = 1}), (3, {})}{(5, {y = 1})}C{((6, C), {x = 1, = 1}),((8, C), {y = 1}),((, nil), {})}{((1, A), {x = 1}),((3, A), {})}(a) Relaxed Graph02BC16(b) Predecessor graphe = {x = 1, = 1}Figure 7.4: Extracting predecessor graphs labeled SSSPAlthough instructive consider projection SSSP onto environmentintuitive understanding, implementation based approach efficient spacetime. rest work, Drake directly performs traversals labeledrepresentation. Since paths predecessor graphs may exist environmentsothers, take natural step use minimal environments specify641fiConrad & Williamsparticular path exists. Intuitively, expect environment path simplyunion environments labeled value pairs specified predecessor edgesused. true, require extra step test validity pathenvironment.Consider partial path source vertex S, passes subsetvertices X1 . . . Xn , constructed labeled value pairs ((di , Xi ), ei ) d[Xi+1 ],represent path predecessor graph. path valid if, everyvertex along path, (di , Xi ) d[Xi+1 ](e1 . . . en ), path environment e =e1 . . . en . Essentially, tests labeled value pairs used construct pathactually still entailed union respective environments. pathinvalid, possible extensions also invalid, inconsistency existextensions.Example 7.7 apply criteria determine paths given SSSPFigure 7.4a. Begin source vertex, A, clearly exists environments,assign partial path empty environment. B contains labeled value pair((2, A), {x = 1, = 1}), thus candidate extend path. union twoenvironments {} {x = 1, = 1} = {x = 1, = 1}. queried environment,d[B] returns labeled value pair used propose extension, pathB environment {x = 1, = 1}. B possible extensions.Returning A, possible extension C labeled value pairs((1, A), {x = 1}) ((3, A), {}). First, consider ((1, A), {x = 1}), query d[C]{x = 1} shows path exists, partial path Cenvironment {x = 1}. path potential extension B labeledvalue pair ((8, C), {y = 1}). However, query d[B]({x = 1} {y = 1}) = (2, A) 6= (7, C),extension valid, expected earlier discussion. may instead extendpath D, giving path C environment {x = 1, = 1}. queriesd[C] d[D] give values used generate path, hence pathvalid.Returning A, consider path B, using labeled value pair ((3, A), {}).extension B passes query test, C B provides path length 7{x = 1} {y = 1}. label path label {x = 1}, must take carelater algorithms use imply 7 shortest path length {x = 1, = 1}.Finally, extend path D, giving path B length 8 {y = 1},caveat.Given rule specifying correct extensions partial paths, constructdepth-first search enumerate possible paths acyclic predecessor graph, re-testingstep ensure path valid.7.4 Pruning Dominated Edges SSSPstrategy finding labeled paths labeled predecessor graphs,extension pruning algorithm fast STN compilation algorithm straightforward. Tsamardinos, et al. (1998) provide two theorems relating dominance edgespaths predecessor graph, adjusted slightly notation. following,assumed source vertex SSSP, B C vertices.642fiDrake: Efficient Executive Temporal Plans ChoiceTheorem 7.8 negative edge (A, C) lower-dominated negative edge (A, B)path B C predecessor graph A.Theorem 7.9 non-negative edge (A, C) upper-dominatedvertex B, distinct C, d[B] d[C] path B Cpredecessor graph A.Example 7.10 Figure 7.5 shows two simple examples apply twotheorems. First, Figure 7.5a weighted distance graph Figure 7.5c shows predecessor graph source vertex A, apply Theorem 7.8. Edge (A, C) lowerdominated weight 5 B implies edge (A, B) weight 5,negative theorem requires. Furthermore, predecessor graph path BC predecessor graph A. Therefore, edge (A, C) dominated neededdispatchable form.Figures 7.5a 7.5c similarly exhibit Theorem 7.9. path B Cgraph, d[B] = 2 d[C] = 5, edge (A, C) upper-dominated. Thus, edge (A, C)needed dispatchable form.examples, step derives every possible edge weight edgesdispatchable form source, namely edges (A, B) (A, C), determines(A, B) actually needed.labeled case, particular labeled edge weights dominated conditionshold environments weight holds in.Theorem 7.11 negative labeled edge weight (dC , eC ) d[C] lower-dominatednegative labeled edge weight (dB , eB ) d[B] eB = eC pathB C environment eP predecessor graph eP = eC .Theorem 7.12 non-negative labeled edge weight (dC , eC ) edge d[C] upper-dominatedlabeled edge weight (dB , eB ) d[B], B distinctC, eB subsumes eC , dB d, C, path B C environment ePpredecessor graph eP = eC .practice, Drake searches every path labeled predecessor graphsource vertex start, applies theorems find dominated edges. Specifically,traversal, records smallest vertex weight vertices along path,counting source. value compared vertex weights extensionspath apply domination theorems. Every time vertex weight founddominated path, recorded list. traversals done, everylabeled value vertex weights present list dominated values convertededge output dispatchable graph.two theorems require eP = eC path must hold environments value dC does, also want eP tighter. Recallvertex weights might prune also specify paths. eC tighter eP ,must lower path length one implied eP , else wouldlabeled value set d[C]. Thus, cannot guarantee path shortest pathsource C, path suitable prune it.643fiConrad & Williams-5-41BC253BC(a)Lowerdominationweighted graph(b)Upperdominationweighted graph0-502BBCC-45(c) Lower domination predecessor graph(d) Upper domination predecessor graphFigure 7.5: Simple edge domination examples.Example 7.13 demonstrate application ideas, reconsider Figure 7.4a. Example 7.6 gave possible paths graph. first path B pathenvironment {x = 1, = 1}. reaching B, minimal vertex weight 2,extension path, nothing pruned. general, first stepsource vertex cannot pruned.next step traversal reaches C environment {x = 1}, minimalpath length 1. C cannot pruned. path cannot extended B,extension D, using vertex weight ((6, C), {x = 1, = 1}). path lengthstrictly longer path length 1, environment value equalenvironment path, add pruned list.Next consider path C environment {} path length 3. extensionB using ((7, C), {y = 1}) also prunable. Note path could never usedprune shorter path length ((2, A), {x = 1, = 1}) {x = 1, = 1} =6 {y = 1}.Likewise, extension prunes ((8, C), {y = 1}).Collecting non-pruned edges means algorithm adds edge (A, B)output dispatchable graph weight W (A, B) = {(2, {x = 1, = 1})}, adds edge(A, C) weight W (A, C) = {(1, {x = 1}), (3, {})}. drop infinite weights, allowingimplicitly specified, finite weights pruned,add edge (A, D) all.644fiDrake: Efficient Executive Temporal Plans ChoiceEssentially, pruning algorithm structure unlabeled fast compilation algorithm. major difference values prune environmentspaths predecessor graph exist particular environments. Thus,pruning step must satisfy pruning requirement identical environment prunelabeled value.7.5 Mutual Dominance Rigid ComponentsTsamardinos et al. (1998) showed rigid components distance graph STNcreate mutual dominance, two edges (A, B) (A, C) used evidenceprune other, incorrectly removed algorithm previoussection applied. correct solution perform either pruning, both. Unfortunately, difficult test mutual dominance SSSP pruning step. Instead,present pre-processing step identifies rigid components, updates outputdispatchable graph accordingly, alters input weighted distance graph removerigid components entirely, beginning process computing edges dispatchable form repeated SSSPs. leaves problem mutually dominatededges, thus pruning step prune edges found dominated withoutrisk encountering problem. section adapts Tsamardinos et al.s approachidentifying labeled rigid components uses labeled analogue alteration process.Example 7.14 Consider predecessor graph fragment Figure 7.6. pathB C, d[B] = 1 d[C] = 1, d[B] d[C]. Thus, edge (A, C)pruned. Likewise, path C B allows us prune (A, B)dispatchable graph. result constrained restevents, would allow dispatcher select inconsistent schedule. edgesmutually dominant. algorithm able prune edges pathB C C B, either exist, one pruning would take place.01BC1Figure 7.6: predecessor graph, (A, B) (A, C) mutually dominant.Tsamardinos et al. (1998) show mutual dominance occursrigid components problem, collections events must scheduledfixed difference execution times. Figure 7.6, B C constrainedoccur time, rigidly connected. Rigidly connected components645fiConrad & Williamsconsistent distance graph coincide strongly-connected components predecessorgraph single source shortest path arbitrary connected vertices. Thus, showidentify instances possible mutual dominance finding stronglyconnected components predecessor graphs, remove them.Intuitively, might understand issue input problem less degreesfreedom appears have. two events actually constrained occurinstant, dispatcher one decision, two. compiling, decision looksredundant other, leading incorrect prunings, Example 7.14. solutionremove redundancy replacing entire rigid component single vertex,called leader. prior work actually removes events leaderpreprocessing step, contracting rigid component single vertex. Since workinglabeled distance graphs, rigid components may exist environments,must replicate effect indirectly, two steps: provide information compiledform dispatcher respect rigid component, alter input graphconditions rigid component exists, compilation algorithm reasonsleader.first step preprocessing identify rigid components. Arbitrary graphsmight connected, SSSP arbitrary vertex may reachvertices, thus cannot find rigid components disconnected subgraph. standardstrategy, Johnsons algorithm preprocessing step, introduce extra vertexpreprocessing step, connected every vertex zero weight edge. extravertex connected every vertex, makes ideal source search from, evendisconnected graphs. Furthermore, extra vertex alter rigid componentspredecessor graph. labeled case, equivalent approach introduce newvertex connected every vertex edge weight (0, {}), zeroweight edge applies every environment. Then, SSSP computed addedvertex source. Finally, algorithm searches predecessor graph cycles.simplest, necessarily efficient, method labeled case simply useknowledge finding paths predecessor graph search loops.might expect, rigid components Labeled STNs given labels, since mayexist environments. need find maximal rigid componentsminimal environments. Thus, rigid component {A, B, C}, separatelyidentify {A, B} rigid component. every vertex V , run depth first searchpath back vertex. found, vertices path rigid component,path environment environment rigid component. Note valid path mayvisit vertex twice, example below. search finds rigid components,maintains list maximally sized rigid components minimal environments.Example 7.15 Figure 7.7 shows small labeled distance graph vertices {A, B, C}.Recall opposing pair edges, one negative weight other,implies rigid component, problem obviously some.apply technique, algorithm first adds another vertex X, connectsvertex edge weight (0, {}). Figure 7.7b also shows predecessorgraph computed done. Second, algorithm searches loopsgraph. begins A: path B environment {x = 1}loop, B C B environment {x = 1, = 1}. paths646fiDrake: Efficient Executive Temporal Plans Choiceimply rigid components {A, B} environment {x = 1} {A, B, C} environment{x = 1, = 1}, respectively. Note second path visits B twice. B, findpaths B B environment {x = 1}, equivalent one foundA, B C B environment {y = 1}, new rigid component.paths C re-derive rigid components. Thus, three maximal rigidcomponents, {A, B} environment {x = 1}, {B, C} environment {y = 1},{A, B, C} environment {x = 1, = 1}.two edges B C environment {x = 1} instead {y = 1},would single maximal rigid component {A, B, C} environment{x = 1}. smaller components, {A, B} {x = 1}, would non-maximalneeded.{(5, {y = 1})}{(3, {x = 1})}B{(3, {x = 1})}C{(5, {y = 1})}(a) Labeled distance graph{((, nil), {})}XB{((3, B), {x = 1}),((0, X), {})}{((5, C), {y = 1}),((0, A), {x = 1}),((0, X), {})}C{((0, B), {y = 1}),((, nil), {})}(b) Predecessor graph added vertex X.Figure 7.7: Identifying rigid components labeled distance graphs.completing search rigid components, must process them. firstprocessing step identify leader, first vertex occur, use represententire rigid component. leader vertex lowest distanceadded vertex, queried environment rigid component. Ties may brokenarbitrarily.second processing step update dispatchable form accordingly. Withinrigid component, events rigidly bound together leader executedevent rigid component. Thus, dispatchable form, constrainnon-leader events occur correct, fixed amount time leader. Thus,leader rigid component, B vertex rigid componentenvironment e, output graph labeled edge weight (d[B](e)d[A](e), e) edge (A, B) (d[A](e) d[B](e), e) edge (B, A). eventsrigidly connected way executed time, dispatcher647fiConrad & Williamsneeds listed explicitly, execution window enablement tests aloneguarantee correct execution plans. step may identify maximalgroups events constrained occur time leader,fixed duration leader. example, leader B C followexactly three time units, B C constrained occur time.usual, zero-related vertices recorded label, environmentrigid component.Third, need alter labeled distance graph rigid component longerappears exist, instead totally represented leader vertex. algorithmbegins edges interior rigid component. (A, B) verticesrigid component environment e, algorithm prunes W (A, B) W (B, A)environments subsumed e. (d, ed ) W (A, B), e subsumes ed , algorithmremoves value pair. e subsume ed , replace (d, ed ) labeled values(d, e0d ) e0d avoids e, may require multiple new values. Repeat W (B, A).Finally, need adjust edges enter leave rigid component ensureinput compiler cycles predecessor graphs. idea moveedges leader environments rigid component, removenon-leader. Assume leader rigid component environment e, Banother vertex rigid component, C vertex rigid component.every labeled value (d, ed ) w(B, C) vertex, algorithm puts (d + d[B](e)d[C](e), ed e) W (A, C). Next, replaces (d, ed ) W (B, C) values (d, e0d )possible e0d union ed constituent kernels e. algorithm repeatsW (C, B), putting (d + d[C](e) d[B](e), ed e) W (C, A), replacing (d, ed )(d0 , e0d ) avoiding e. Unfortunately, strategy leads duplication grows linearlydomain size choice variables. practice, though, many problemsrigid components, limited penalty minor. results showoutliers may associated growth, problems affected.Example 7.16 usual, let x, {1, 2} choice variables. Figure 7.8a depicts inputlabeled distance graph fragment. opposing edge weights 1 1, easilyidentify {A, B} rigid component environment {x = 1}. need followprocedure process it.First, always scheduled B, therefore leader. ran SSSPadded vertex, would find d[A]({x = 1}) = 1 d[B]({x = 1}) = 0, provingassertion. Since d[B]({x = 1}) d[A]({x = 1}) = 1, event B follows one timeunit. Therefore, edges inserted output dispatchable form shown Figure 7.8cenforce delay.Next, alter input graph remove rigid component, beginning edgesrigid components vertices. Edge (B, A) one weight it, subsumedenvironment rigid component, exists rigid component does,thus already handled, pruned. Likewise, weight (1, {}) W (A, B)pruned. hand, weight (2, {x = 2}) W (A, B) already avoidsenvironment rigid component, left unchanged.Continue edges enter leave rigid component. (A, C) uses leadervertex, directly require modification. Edge (B, C) needs moved,giving new weight (4 + 1, {x = 1}) W (A, C), already present, requires648fiDrake: Efficient Executive Temporal Plans Choicemodification. Since environment subsumed rigid component environment,(4, {x = 1}) removed w(B, C). Edge (C, B) also needs moved. leadsnew value (2 1, {y = 1} {x = 1}) = (1, {x = 1, = 1}) W (C, A). Since {y = 1}subsumed rigid components environment, must modify value (C, B)avoids environment. Avoiding {x = 1} means {x = 2}, modifyvalue (2, {y = 1}) (2, {x = 2, = 1}). modifications completely remove rigidcomponent provide dispatcher sufficient information correctly executerigid components removed.modifications labeled distance graph guaranteed cyclespredecessor graphs, therefore rigid components. Thus rest fastalgorithm given section correctly compiles dispatchable form. adjustedunlabeled algorithm search labeled rigid components. Additionally, unlabeledalgorithm removes non-leader vertices rigid components, moving modifying edgesnecessary enforce original input constraints. Since vertices may neededenvironments rigid component exist, Drake instead modifies processmoving edges replicate effect removing non-leader vertices.Drakes compilation algorithm designed use labeling concepts compute compactversion dispatchable form plans choice. structure algorithmsimilar unlabeled version, number modifications made within stepreason environments. section completes presentation Drakes algorithms.8. ResultsFinally, explore Drakes performance, theoretical standpoint experimentally. analysis gives justification expect Drakes representationcompact, experimental results give evidence Drake performs intended.8.1 Theoretical Resultsgive brief characterization analytical worst case performance Drakes algorithms. direct enumeration STNs, Tsamardinos et al.s (2001) work, uses oneSTN consistent STN. n choices options each, v vertices,assumecompiled sparse graphs size v log v , compiledsize nd v log v . contrast, Drake store componentSTNs independently,stores distinct values, size kv log v , k nd . worstcase, every single component STN completely different, similaritieschoices exploit, hence Drakes compiled representation size,never worse, constant.strong parallel existing theory tree width general constraintsatisfaction problems. Dechter Mateescu (2007) explain general constraintsatisfaction problem n variables domain size general solved ndsteps, many problems structure. tree width, n n problem representsnumbervariables effectively interact, search completed(n ) time. Similarly, Labeled STNs, choice variables may interact fully,thus effective number choice variables problem often smaller649fiConrad & Williams{(1, {x = 1}), (2, {x = 2})}B{(1, {x = 1})}{(4, {x = 1})}{(5, {x = 1})}{(2, {y = 1})}C(a) Input labeled distance graph{(2, {x = 2})}B{(1, {x = 1, = 1})}{(5, {x = 1})}{(2, {x = 2, = 1})}C(b) Contracted labeled distance graph{(1, {x = 1})}B{(1, {x = 1})}C(c) Dispatchable form rigid componentFigure 7.8: example processing rigid component Labeled Distance Graph.total number. notation, Drakes compiled problems size (n )d n log v .smaller base exponent lead significant savings.650fiDrake: Efficient Executive Temporal Plans Choicecompile time run-time latency difficult characterize, however,overhead labeling operations also grows n. Therefore,attempt analytic analysis.8.2 Experimental Resultssection presents experimental validation Drakes compilation dispatch algorithms randomly generated, structured problems. First, develop suite randomstructured Labeled STNs, derived Stedls (2004) problem generator. compiledispatch suites problems twice, Drake explicitly enumerating component STNs, following techniques developed Tsamardinos et al. (2001).Finally, compare compiled size problems, compilation time, execution latency. Throughout section, plots use number consistent componentSTNs horizontal axis, appears correlate well effective difficultyproblem. metrics, provide results two methods sideside one plot, show ratio performance another one, allow point-wisecomparison difference performance identical problems. problemsconstructed 2-11 binary choices 2-7 ternary choices. 100 problemssizes; problems range 4 consistent component STNs2000. number events ranges 4 22 number component STNsincrease keep consistent ratio constraints events.comparison performed Lisp implementation, run 2.66 GHz machine4 Gb memory. performance related implementation detailsomitted prior sections. example, labeled value sets stored ordered listsreduce insertion query time. Additionally, found memoization subsumptionunion operations dramatically improved performance. implementation aggressivelyprunes values inconsistent environments avoid unnecessary reasoning. STNcompiler dispatcher exercise code Drake support fair comparison,pays small overhead execution speed.first metric comparison size dispatchable form random problems. computed serializing graph representations strings. Since Drakescompilation algorithm derived fast STN compiler, maximum memory footprint compilation dispatch double numbers.Since designed Drake metric mind, expect improvement clearsignificant, Figure 8.1 shows. ratio plot, value multiple improvement Drake STN enumeration. Except small problems, Drakesmemory performance superior, improvement ranges around 700 timessmaller memory footprint largest problems. STN enumeration Tsamardinos etal. (2001) develops uses around 2 MB storage, although insignificantmodern desktop, often significant embedded hardware, especially systemmust store library compiled plans. contrast, Drakes memory footprint 1-10 kBcases, trivial, even large numbers, hardware. halfworse performing examples, fit main band results, correspondternary choices. believe likely corresponds growth caused avoidingenvironments handling complex overlapping rigid components problems.651fiConrad & WilliamsCompiled Size (kB)410DrakeSTN Enumeration310210110010110010123101010Number Consistent Component STNs410(a) size dispatchable labeled distance graphs.Compiled Size Ratio STN/Labeled STN310210110010110010123101010Number Consistent Component STNs410(b) ratio size compiled STN enumeration size size Drakes labeled distance graph.Figure 8.1: size dispatchable form random problems functionnumber component STNs.652fiDrake: Efficient Executive Temporal Plans Choicesecond metric time required compile random problems, shown Figure8.2. Often, Drakes compilation times much better, highly variable.number largest problems, Drake 1000 times faster. However,problems exhibit little improvement, 100 times slower worstcases. problems take less ten minutes methods, Drake takeshours five largest problems. expect higher variability run-timecompilation algorithms loop repeatedly labeled graph, exacerbatingvariability shown compiled size. Thus, surprising problems whosedispatchable form compact, run-time suffers.final metric run-time latency incurred algorithms, shown Figure8.3. Drakes reported latency maximum latency single decision making periodsingle execution entire problem. STN enumeration latency reportedtime required identify, execute, propagate first event consistent,component STN. metrics identical, quite comparable.values reported 103 seconds reported zero Lisps timing features,inflate fit log scale.Although differences compilation time interesting, increases run-time latency far critical Drakes applicability real world. Fortunately,situation looks favorable. systems execute largest problemstenth second, small moderate sized problems around 10 milliseconds.Although Drake slower reasonable fraction problems, margin fairly low;note cluster values ratio less 101 corresponds jumpeffectively zero 10 milliseconds. know real ratio, pointscreate visible cluster 101 may may misleading. Instead, focuslarger problems methods measurable, Drake generally performsquite well. Again, handful problems outliers, taking much time, tensseconds, would acceptable applications. conclude Drakeperform well embedded systems many real world problems, terms memoryusage latency.Overall, results Drake designed achieve. Using compact representation provides smaller memory footprint. Sometimes, exploiting similaritychoices makes reasoning fast, times imposes extra computational burdentease similarities, lack thereof. Enumerating STNs directly quite predictable costs, time space, Drake far variable, dependingprecise nature problem. find results quite promising, must cautionapplications particular problems could better worse, depending factorsknow easily characterize. well illustrated problemsoutliers three metrics. may useful future work investigatesources variability Drakes performance.practical note, tightly regulated number events focus investigationscaling number choices. However, algorithms scale gracefully,similar increases space time costs, plans events. Overall,Drake appears provide noticeably lower memory footprint dispatching problemsdiscrete choices direct enumeration strategy Tsamardinos et al. (2001),suffering mild increase run-time latency.653fiConrad & WilliamsCompile Time (sec)610DrakeSTN Enumeration410210010210010123101010Number Consistent Component STNs410(a) compile time random problems.Compile Time Ratio, STN/Labeled STN410210010210010123101010Number Consistent Component STNs410(b) ratio compile time STN enumeration Drakes compile time.Figure 8.2: compile time random problems function number componentSTNs.654fiDrake: Efficient Executive Temporal Plans ChoiceExecution Latency (sec)110DrakeSTN Enumeration010110210310010123101010Number Consistent Component STNs410(a) execution latency.Execution Latency Ratio STN/Labeled STN210110010110210010123101010Number Consistent Component STNs410(b) ratio execution latency STN enumeration Drakes execution latency.Figure 8.3: execution latency random problems function number component STNs.655fiConrad & Williams9. Summarywork presents Drake, compact, flexible executive plans choice. Drake takesinput plans temporal flexibility discrete choices, Labeled STNs DTNs,selects execution times makes discrete decisions run-time (Dechter et al.,1991). Choices substantially improve expressiveness tasks executivesperform, improve robustness resulting executions. Prior execution approachestypically impose significant memory requirements introduce substantial latencyexecution. goal developing Drake develop dispatching executive lowermemory footprint.Building upon concept labels employed ATMS compactly encodeconsequences set alternative choices, Drake introduces new compact encoding,called labeled distance graphs, encode efficiently reason discrete choices,introduce corresponding maintenance system (de Kleer, 1986). adaptationATMS labeling scheme focuses maintaining non-dominated constraints, allowsDrake exploit structure temporal reasoning, cast shortest path problemdistance graph, provide compact representation. Furthermore, modifying existingunlabeled algorithms account labels change overall structurealgorithms.Drakes compilation algorithm successfully compresses dispatchable solutiontwo orders magnitude relative Tsamardinos, Pollack, Ganchevs (2001) prior work,often reducing compilation time, typically introducing modest increaseexecution latency. Thus, believe Drake successfully realizes initial goals. Withinexperiments, compilation typically takes less ten minutes, occasion takeshours. Although time consuming later case, still acceptable, since compilationperformed off-line, task first defined. summarize, Drakes LabeledSTNs labeled distance graphs enable executive strikes useful balancelatency memory consumed, appropriate real world applications. Drakeslabeling scheme also provides opportunity extend wide range graph algorithmsreason represent choice efficiently.Acknowledgmentsauthors would like thank Julie Shah David Wang many helpful ideasdiscussions, reviewers insightful comments. Patrick Conrad fundedwork Department Defense NDSEG Fellowship.ReferencesBlock, S., Wehowsky, A., & Williams, B. (2006). Robust execution contingent, temporallyflexible plans. Proceedings 21st National Conference Artificial Intelligence,pp. 802808.Combi, C., & Posenato, R. (2009). Controllability temporal conceptual workflowschemata. Dayal, U., Eder, J., Koehler, J., & Reijers, H. (Eds.), Business Process656fiDrake: Efficient Executive Temporal Plans ChoiceManagement, Vol. 5701 Lecture Notes Computer Science, pp. 6479. SpringerBerlin / Heidelberg.Combi, C., & Posenato, R. (2010). Towards temporal controllabilities workflowschemata. Proceedings 17th International Symposium Temporal Representation Reasoning, pp. 129136. IEEE.Conrad, P. R. (2010). Flexible execution plans choice uncertainty. Mastersthesis, Massachusetts Institute Technology.Conrad, P. R., Shah, J. A., & Williams, B. C. (2009). Flexible execution plans choice.Proceedings Nineteenth International Conference Automated PlanningScheduling (ICAPS-09). AAAI Press.Cormen, T., Leiserson, C., Rivest, R., & Stein, C. (2001). Introduction algorithms (Secondedition). MIT Press.de Kleer, J. (1986). assumption-based TMS. Artificial intelligence, 28 (2), 127162.Dechter, R., & Mateescu, R. (2007). AND/OR search spaces graphical models. ArtificialIntelligence, 171 (2-3), 73106.Dechter, R., Meiri, I., & Pearl, J. (1991). Temporal constraint networks. Artificial Intelligence, 49 (1-3), 61 95.Doyle, J. (1979). truth maintenance system* 1. Artificial Intelligence, 12 (3), 231272.Effinger, R. (2006). Optimal Temporal Planning Reactive Time Scales via DynamicBacktracking Branch Bound. Masters thesis, Massachusetts Institute Technology.En, N., & Srensson, N. (2004). extensible sat-solver. Giunchiglia, E., & Tacchella, A.(Eds.), Theory Applications Satisfiability Testing, Vol. 2919 Lecture NotesComputer Science, pp. 333336. Springer Berlin / Heidelberg.Goldstone, D. (1991). Controlling inequality reasoning TMS-based analog diagnosissystem. Proceedings Ninth National Conference Artificial Intelligence,pp. 512517.Hiatt, L., Zimmerman, T., Smith, S., & Simmons, R. (2009). Strengthening schedulesuncertainty analysis. Proceedings International Joint ConferenceArtificial Intelligence, Vol. 2, pp. 53.Hunsberger, L. (2009). Fixing semantics dynamic controllability providingpractical characterization dynamic execution strategies. Proceedings16th International Symposium Temporal Representation Reasoning, pp.155162. IEEE.Hunsberger, L. (2010). Fast Incremental Algorithm Managing Execution Dynamically Controllable Temporal Networks. Proceedings 17th InternationalSymposium Temporal Representation Reasoning, pp. 121128. IEEE.Khatib, L., Morris, P., Morris, R., & Rossi, F. (2001). Temporal constraint reasoningpreferences. Proceedings International Joint Conference ArtificialIntelligence, Vol. 1, pp. 322327.657fiConrad & WilliamsKim, P., Williams, B. C., & Abramson, M. (2001). Executing reactive, model-based programs graph-based temporal planning. Proceedings InternationalJoint Conference Artificial Intelligence, Vol. 17, pp. 487493.McDermott, D. (1983). Contexts data dependencies: synthesis. Pattern AnalysisMachine Intelligence, IEEE Transactions on, PAMI-5 (3), 237246.Morris, P. (2006). structural characterization temporal dynamic controllability. Principles Practice Constraint Programming, 4204, 375389.Morris, P., Muscettola, N., & Vidal, T. (2001). Dynamic control plans temporaluncertainty. Proceedings International Joint Conference Artificial Intelligence, Vol. 17, pp. 494502.Muscettola, N., Morris, P., & Tsamardinos, I. (1998). Reformulating temporal plansefficient execution. Proceedings Principles Knowledge RepresentationReasoning-International Conference, pp. 444452.Planken, L., de Weerdt, M., & van der Krogt, R. (2008). P 3 C: New AlgorithmSimple Temporal Problem. Proceedings Eighteenth International ConferenceAutomated Planning Scheduling (ICAPS-08), pp. 256263. AAAI Press.Rossi, F., Venable, K., & Yorke-Smith, N. (2006). Uncertainty soft temporal constraintproblems: general framework controllability algorithms fuzzy case. Journal Artificial Intelligence Research, 27 (1), 617674.Shah, J., Stedl, J., Williams, B., & Robertson, P. (2007). fast incremental algorithmmaintaining dispatchability partially controllable Plans. Proceedings Seventeenth International Conference Automated Planning Scheduling (ICAPS2007). AAAI Press.Shah, J. A., & Williams, B. C. (2008). Fast Dynamic Scheduling Disjunctive Temporal Constraint Networks Incremental Compilation. ProceedingsNineteenth International Conference Automated Planning Scheduling (ICAPS2008). AAAI Press.Shu, I.-h., Effinger, R., & Williams, B. C. (2005). Enabling Fast Flexible PlanningIncremental Temporal Reasoning Conflict Extraction. ProceedingsFifteenth International Conference Automated Planning Scheduling (ICAPS05), pp. 252261. AAAI Press.Smith, S., Gallagher, A., & Zimmerman, T. (2007). Distributed management flexibletimes schedules. Proceedings 6th International Joint Conference Autonomous Agents Multiagent Systems, pp. 18. ACM.Stallman, R., & Sussman, G. (1977). Forward reasoning dependency-directed backtracking system computer-aided circuit analysis* 1. Artificial Intelligence,9 (2), 135196.Stedl, J. (2004). Managing temporal uncertainty limited communication: formalmodel tight loose team coordination. Masters thesis, Massachusetts InstituteTechnology.658fiDrake: Efficient Executive Temporal Plans ChoiceStergiou, K., & Koubarakis, M. (2000). Backtracking algorithms disjunctions temporalconstraints. Artificial Intelligence, 120 (1), 81117.Tsamardinos, I. (2002). probabilistic approach robust execution temporal plansuncertainty. Methods Applications Artificial Intelligence, 2308, 751751.Tsamardinos, I., Muscettola, N., & Morris, P. (1998). Fast transformation temporalplans efficient execution. Proceedings Fifteenth National ConferenceArtificial Intelligence, pp. 254261.Tsamardinos, I., Pollack, M., & Ganchev, P. (2001). Flexible dispatch disjunctive plans.6th European Conference Planning, pp. 417422.Tsamardinos, I., Vidal, T., & Pollack, M. (2003). Ctp: new constraint-based formalismconditional, temporal planning. Constraints, 8 (4), 365388.Venable, K., & Yorke-Smith, N. (2005). Disjunctive temporal planning uncertainty.Proceedings International Joint Conference Artificial Intelligence, pp.172122. Citeseer.Williams, B., & Ragno, R. (2007). Conflict-directed A* role model-based embedded systems. Discrete Applied Mathematics, 155 (12), 15621595.Williams, B. C., Ingham, M. D., Chung, S. H., & Elliott, P. H. (2003). Model-based programming intelligent embedded systems robotic space explorers. ProceedingsIEEE: Special Issue Modeling Design Embedded Software, 91 (1),212237.Xu, L., & Choueiry, B. (2003). new effcient algorithm solving simple temporalproblem. Proceedings 10th International Symposium Temporal Representation Reasoning Fourth International Conference Temporal Logic, pp.210220.659fiJournal Artificial Intelligence Research 42 (2011) 887916Submitted 04/11; published 12/11Multi-Robot Adversarial Patrolling:Facing Full-Knowledge OpponentNoa Agmonagmon@cs.utexas.eduDepartment Computer ScienceUniversity Texas AustinTX, USAGal KaminkaSarit Krausgalk@cs.biu.ac.ilsarit@cs.biu.ac.ilComputer Science DepartmentBar Ilan UniversityIsraelAbstractproblem adversarial multi-robot patrol gained interest recent years, mainlydue immediate relevance various security applications. problem, robotsrequired repeatedly visit target area way maximizes chancesdetecting adversary trying penetrate patrol path. facing strongadversary knows patrol strategy robots, robots use deterministicpatrol algorithm, many cases easy adversary penetrate undetected(in fact, cases adversary guarantee penetration). Thereforepaper presents non-deterministic patrol framework robots. Assumingstrong adversary take advantage knowledge try penetratepatrols weakest spot, hence optimal algorithm one maximizes chancesdetection point. therefore present polynomial-time algorithm determiningoptimal patrol Markovian strategy assumption robots,probability detecting adversary patrols weakest spot maximized. buildupon framework describe optimal patrol strategy several robotic modelsbased movement abilities (directed undirected) sensing abilities (perfectimperfect), dierent environment models - either patrol around perimeter (closedpolygon) open fence (open polyline).1. Introductionproblem multi-robot patrol gained interest recent years (e.g., Ahmadi & Stone,2006; Chevaleyre, 2004; Elmaliach, Agmon, & Kaminka, 2007; Paruchuri, Tambe, Ordonez,& Kraus, 2007; Amigoni, Gatti, & Ippedico, 2008), mainly due immediate relevancevarious security applications. multi-robot patrol problem, robots requiredrepeatedly visit target area order monitor it. Many researchers focusedfrequency-based approach, guaranteeing point-visit frequency criteria metpatrol algorithm, example maximizing minimal frequency guaranteeing uniform frequency (e.g., refer Elmaliach et al., 2007; Chevaleyre, 2004; Almeida, Ramalho,Santana, Tedesco, Menezes, Corruble, & Chevaleyr, 2004).contrast, advocate approach robots patrol adversarial settings,goal patrol way maximizes chances detecting adversaryc2011AI Access Foundation. rights reserved.fiAgmon, Kaminka & Kraustrying penetrate patrol path. Thus decisions adversary musttaken account. objective is, therefore, develop patrol paths robots,following paths robots maximize chance adversarial detection.problem adversarial planning specically adversarial patrolling wide problem,generally computational tractable results exist. paper presents problemrestrictive environment perimeter patrol set homogenous robots, providingcomputational tractable optimal result.opposed frequency-driven approaches, adversarial settings point-visit frequency criteria becomes less relevant. Consider following scenario. given cyclicfence length 100 meters 4 robots must patrol around fence movingvelocity 1m/sec. Clearly, optimal possible frequency point around fence,terms maximizing minimal frequency, 1/25, i.e., location visitedevery 25 seconds. optimal frequency achieved robots placed uniformlyalong fence (facing direction) move forward without turning around. Assume takes adversary 20 seconds penetrate area fence.robots move deterministic path, adversary knowing patrol algorithmguarantee penetration simply enters position recently visitedpatrolling robot. hand, robots move non-deterministically, i.e.,turn around time time probability greater 0, choicepenetration position becomes less trivial. Moreover, assume adversary maypenetrate time, motivates use nondeterministic patrol behavior indenitely.rst consider problem patrolling around closed polygon, i.e., perimeter.introduce non-deterministic framework patrol rst order Markovian assumption robots strategy, robots choose next move randomprobability p. probability value p characterizes patrol algorithm.model system Markov chain (e.g., Stewart, 1994), using model calculate polynomial time probability penetration detection point alongperimeter function p, i.e., depends choice patrol algorithm.Based functions dening probability penetration detection, nd optimal patrol algorithm robots presence strong adversary, i.e., adversaryfull knowledge patrolling robotstheir algorithm current placement.case, adversary uses knowledge order maximize chances penetratingwithout detected. therefore assumed adversary penetrateweakest spot path, hence goal robots maximize probabilitypenetration detection weakest spot. provide polynomial time algorithm(polynomial input size, depending number robots characteristicsenvironment) nding optimal patrol robots facing full knowledgeadversary. show non-deterministic patrol algorithm advantageous, guarantees lower bound criteria performance robots, i.e., abilityblock adversary.use patrol framework consider additional environment robotic models. Specically, consider case robots required patrol alongopen polyline (fence). show although case inherently dierent patrollingalong perimeter, basic framework still used (with changes) order ndoptimal patrol algorithm robots. investigate also dierent movement models888fiMulti-Robot Adversarial Patrollingrobots, namely robots directionality associated movement (andturning around could cost system time), omnidirectional. addition,model various types sensing capabilities robots, specically, sensing capabilities perfect imperfect, local long-range. cases showbasic framework extended include various models.paper organized follows. Section 2 discuss previous work, relatedresearch. Section 3 describes basic robot environment model. introduceSection 4 framework patrolling robots, describe polynomial-time algorithmdetermining probability penetration detection every point along patrolpath (Section 4.2). show Section 4.3 algorithm dening optimal patrolalgorithm robots, assuming face full-knowledge adversary, Section 4.4provides interesting results implementation algorithms. Section 5show basic framework used order consider various robotic sensingmovement models dierent environment (open fences). Section 6 concludes.2. Related WorkSystems comprising multiple robots cooperate patrol designated areastudied various contexts (e.g., Chevaleyre, 2004; Elmaliach, Agmon, & Kaminka,2009). Theoretical (e.g., Chevaleyre, 2004; Elmaliach et al., 2009; Amigoni et al., 2008)empirical (e.g., see Sak, Wainer, & Goldenstein, 2008; Almeida et al., 2004) solutionsproposed order assure quality patrol. denition quality dependscontext. studies concentrate frequency-based patrolling, optimizesfrequency visits throughout designated area (e.g. refer Elmaliach et al., 2009;Almeida et al., 2004; Chevaleyre, 2004). Ecient patrol, case, patrol guaranteeing high frequency visits parts area. contrast, adversarial patrolling(addressed paper) deals detection moving adversaries attemptingavoid detection. Here, ecient patrol one deals eciently intruders (e.g.,see Sak et al., 2008; Basilico, Gatti, & Amigoni, 2009b; Amigoni et al., 2008).rst theoretical analysis frequency-based multi-robot patrol problemconcentrated frequency optimization presented Chevaleyre (2004). introducednotion idleness, duration point patrolled area visited.work, analyzed two types multi-robot patrol schemes graphs respectidleness criteria: partitioning area subsections, section visitedcontinuously one robot; cyclic scheme patrol path provided alongentire area robots visit parts area, consecutively. provedlatter approach, frequency visiting points area considerably higher.Almeida et al. (2004) oered empirical comparison dierent approaches towardspatrolling regards idleness criteria, shows great advantage cycle basedapproach.Elmaliach et al. (2007, 2009) oered new frequency optimization criteria evaluatingpatrol algorithms. provide algorithm multi-robot patrol continuous areasproven maximal minimal frequency well uniform frequency, i.e.,point area visited highest-possible frequency. work based889fiAgmon, Kaminka & Krauscreating one patrol cycle visits points area minimal time, robotssimply travel equidistantly along patrol path.Sak et al. (2008) considered case multi-agent adversarial patrol general graphs(rather perimeters, work). concentrated empirical evaluation(using simulation) several non-deterministic patrol algorithms roughlydivided two: divide graph patrolling agents,allow agents visit parts graph. considered three types adversaries:random adversary, adversary always chooses penetrate recently-visitednode adversary uses statistical methods predict chances nodevisited soon. concluded patrol method outperformedothers domains checked, optimality depends graphstructure. contrast investigation, provide theoretical proofs optimalitydierent settings.work adversarial multi-robot patrol examined also using game-theoreticapproaches (e.g., see Basilico et al., 2009b; Basilico, Gatti, & Amigoni, 2009a; Pita, Jain,Ordonez, Tambe, Kraus, & Magorii-Cohen, 2009; Paruchuri, Tambe et al., 2007). Notework described herein modeled game theoretic problem: Given twoplayers, robots adversary, possible set actions side, determineoptimal policy robots maximize utility gained adversarialdetection. zero-sum game. Since assume strong (full knowledge) adversarialmodel, adopt minmax approach, namely, minimizing maximal utilityopponent (or case: equivalent maximizing minimal probability detectionrobots). However, work use game theoretic tools ndingequilibrium strategy, use tailored ad-hoc solution nds optimal policyrobots polynomial time, taking account robots possible sensing movementcapabilities.closely related work Amigoni et al. (2008) Basilico et al. (2009b, 2009a)used game-theoretic approach using leader-follower games determining optimalstrategy single patrolling agent. considered environment patrollingrobot move two nodes graph, opposed perimeter modeluse. solution suitable one robot heterogenous environments, i.e., utilityagent adversary changes along vertices graph. formulateproblem mathematical programming problem (either multilinear programmingmixed integer linear programming). Consequently, computation optimal strategyexponential, yet using optimization tools manage get good approximationoptimal solution.Paruchuri, Tambe et al. (2007) considered problem placing stationary securitycheckpoints adversarial environments. Similar assumptions, assumeagents work adversarial environment adversary exploit predictable behavior agents, adversary full knowledge patrollingagents. model system using Stackelberg games, uses policy randomizationagents behavior order maximize rewards. problem formulatedlinear program single agent, yielding optimal solution case. Usingsingle agent policy, present heuristic solution multiple agents,optimal solution intractable. Paruchuri, Pearce et al. (2007) study problem890fiMulti-Robot Adversarial Patrollingcases adversarial model unknown agents, although adversary stillfull knowledge patrol scheme. provide heuristic algorithms optimal strategy selection agents. Pita et al. (2009) continued research considercase adversaries make choices based bounded rationalityuncertainty, rather make optimal game-theoretic choice. considered threedierent types uncertainty adversarys choices, provided new mixed-integerlinear programs Stackelberg games deal types uncertainties.opposed works based using game-theoretic approachesprovide approximate heuristic solutions intractable optimal solutions, workfocus specic characteristics robots environment, provide optimalpolynomial-time algorithms nding optimal patrol strategy multi-robot teamusing minmax approach.Theoretical work based stochastic processes related work catmouse problem (Coppersmith, Doyle, Raghavan, & Snir, 1993), also known predatorprey (Haynes & Sen, 1995) pursuit evasion problem (Vidal, Shakernia, Kim, Shim, &Sastry, 2002). problem, cat attempts catch mouse graphmobile. cat knowledge mouses movement, therefore farcat concerned, mouse travels similarly simple random walk graph.We, hand, worst case assumptions adversary. considerrobotic model, movement cat correlated movementrobot, possible directionality movement, possible cost changing directionspossible sensorial abilities. Moreover, model robots travel around perimeterfence, rather general graph. Thus sense, research concernedpursuit-evasion polyline - open closed.theoretical work Shieh Calvert (1992), based computational geometrysolutions, attempts nd optimal viewpoints patrolling robots. try maximize view robots area, show problem N P-Hard, ndapproximation algorithms problem.3. Robot Environment Modelfollowing section, provide description robotic model, environment modeladversarial model. describe basic model patrolling around perimeter(closed polygon). environments robotic models discussed Section 5.3.1 Environmentconsider patrol circular path around closed polygon P . path around Pdivided N segments length uniform time distance, i.e., robot travelsone segment per cycle sensing (its velocity 1 segment / 1 time cycle).division segments makes possible consider patrols heterogeneous paths.areas, diculty passing terrains varies one terrain another,example driving muddy tracks vs. driving road. addition, riding around cornersrequires vehicle slow down. Figure 1 demonstrates transition given areadiscrete cycle. area, left, given along velocity constraints. pathdivided segments robot travels one segment per time cycle891fiAgmon, Kaminka & Krausmonitoring it, i.e., length segment determined velocityrobot (corresponding time takes travel specic segment)sensorial capabilities robot. path divided segments uniformtravel time, equivalent considering simple cycle appears right Figure1.Note distance robots calculated respect numbersegments them, i.e., distance travel time. example, saydistance R1 R2 7, 7 segments them, R1remained still, would taken R2 7 time cycles reach R1 (assuming R2headed towards right direction).equivalentFigure 1: example creating discrete segments circular path propertyrobots travel one segment per cycle. dierent line structures along perimeter leftcorrelate dierent velocity constraints, converted (in middle gure) N segmentsrobots travel one time cycle. gure equivalent gure right,simple cycle divided N uni-time segments.3.2 Patrolling Robotic Modelconsider system k > 1 homogenous mobile robots R1 , . . . , Rk , requiredpatrol around closed polygon. robots operate cycles, cycle consiststwo stages.1. Compute: Execute given algorithm, resulting goal point, denoted pG ,robot travel.2. Move: Move towards point pG .model synchronous, i.e. robots execute cycle simultaneously. concentrate attention Compute stage, i.e., compute next goal point.assume robots movement model directed pG behind robot,physically turn around. Turning around costly operation, modelcost time, i.e., robot turns around resides segment time units.case movement model directed discussed Section 5.1. Throughoutpaper assume simplicity = 1, unless stated otherwise.key result research (Section 4) optimal patrolling necessitates robotsplaced uniform distance = N/k one another along perimeter. Consequently, require robots coordinated sense robots movedirection, decided turn around simultaneously. requirementguarantees uniform distance maintained throughout execution892fiMulti-Robot Adversarial Patrollingpatrol algorithm. Note tightly-coordinated behavior achievable centralizedsystems, systems communication exists team members. practical implementations may exist (for example uniformly seeding pseudorandom numbergenerator robots), require coordination inside team. Distributedsystems cannot assume reliable communication left future work.3.3 Adversarial Modelbasic assumption system consists adversary tries penetratepatrolling robots path without detected. adversary decides,unknown time, segment penetrate. penetration timeinstantaneous, lasts time units, stays segment.Denition 1. Let si discrete segment perimeter P patrolled one robotmore. Probability Penetration Detection si , ppdi , probabilitypenetrator going si time units detected robot goingsi period time.words, ppdi probability patrol path robot passsegment si time penetration attempted segment, hencecalculated segment respect current location robots giventime (since robots maintain uniform distance throughout execution,relative location remains times). use general acronym ppdreferring general term probability penetration detection (without referencecertain segment).Recall time distance every two consecutive robots around perimeter= N/k. Therefore consider values boundaries d+2 < d. reasontakes robot time units turn, robot adjacent s0probability > 0 arriving every segment si , 0 t, robot adjacentsd probability > 0 arriving segments si , (t ) leqd. Hence segmentst+1 probability > 0 visited (t ) + 1 d+2+1 t, otherwiseleast one segment, st+1 , probability 0 visited timeunits. Therefore adversary full knowledge patrol always managesuccessfully penetrate regardless actions taken patrolling robots. Noteappears equation since inuences number segments reachable robotlocated segment sd+1 turning around (sd , sd1 , . . . , sd/2+ ). hand,segments si ppdi = 1 simply using deterministic algorithm.dene patrol scheme robots1. Number robots, distance current position.2. movement model robots characterization movement.3. robots patrol algorithm.patrol scheme reects knowledge obtained adversary patrolling robotsgiven time (hence necessarily time dependent).893fiAgmon, Kaminka & Krausconsider strong adversarial model adversary full knowledgepatrolling robots. Therefore full knowledge adversary knows patrol scheme,take advantage knowledge order choose penetration spotweakest spot patrol, i.e., segment minimal ppd. solution concept adopted(as stated Section 2) similar game-theoretic minmax strategy, yieldingstrategy equilibrium (none playersrobots adversaryhas initiativediverge strategy). adversary learn patrol scheme observingbehavior robots sucient amount time. Note security applications,strong adversaries exist. applications, adversary models behaviorsystem worst case scenario patrolling robots point view (similarclassical Byzantine fault model distributed systems, see Lynch, 1996).environment, robots responsible detecting penetrationshandling penetration (which requires task-allocation methods). Therefore caseadversary issues multiple penetrations similar handling single penetration,robots detect, report continue monitor rest path, accordingalgorithm.4. Framework Adversarial Patrolling Perimetersenvironment consider linear environment, step robotsdecide either go straight turn around. framework suggest nondeterministicsense time step decision done independently, random,probability p. Formally,{pGo straightProbability next move =1 p Turn aroundSince dierent patrol algorithms consider vary probability p nextstep, assert probability p characterizes patrol algorithm.Assume robot currently located segment si . Therefore robot facingsegment si+1 , probability p go straight probability1 p turn around face segment si1 . Similarly, facing segment si1 ,probability p reach segment si1 probability 1 p facesegment si+1 .Note probability penetration detection segment si , 1 d,determined probability p characterizing patrol algorithm, therefore ppdi functionp, i.e., ppdi (p). However, whenever possible use abbreviation ppdi .denition ppdi , need nd probability si visited time unitsrobot. Assuming perfect detection capabilities robots, ppdi determinedfirst visit robot si , since intruder detected detectionmission successful (specically, segment visited, game over). Noteppdi calculated regardless actions adversary.stated previously, order guarantee optimality patrol algorithm, robotsuniformly distributed along perimeter distance = N/kevery two consecutive robots, coordinated sense894fiMulti-Robot Adversarial Patrollingsupposed turn around, simultaneously. following theorem supporting lemmas prove optimality assumptions full-knowledge adversarialenvironment.Lemma 1 follows directly fact movement robots continuous,thus robot Rl cannot move segment si segment si+j , j > 0, without visitingsegments si+1 , . . . , sj1 between. Note since k > 1 follows numbersegments unvisited Rl greater 2t (otherwise simple deterministic algorithmwould suce detect adversary probability 1). Therefore time unitsRl residing initially segment s0 cannot visit segment si , < t, arrivingdirection perimeter without visiting segments closer current location (s0 )rst (this argument holds segments left right s0 ).Lemma 1. given p, function ppdli : N [0, 1] constant Rl residingsegment s0 monotonic decreasing function, i.e., distance robotsegment increases, probability reaching time units decreases.Lemma 2. distance two consecutive robots along cyclic patrol pathsmaller, ppd segment higher vice versa.Proof. Consider sequence S1 segments s1 , . . . , sw two adjacent robots, RlRr , s1 adjacent current location Rl sw adjacent currentlocation Rr . Let S2 similar sequence, w 1 segments, i.e., distanceRl Rr decreases one segment. Assume robots distancegreater equal w 1 Rl Rr , w 1 < t. Since robot mayinuence ppd segments distance (as probability0 arriving segment greater distance within time units), probabilitypenetration detection, ppd, sequences inuenced possible visits RlRr .Denote probability penetration detection segment si Sj ppdi (j), 1 w,j {1, 2}, probability penetrator detected robot Rx ppdxi (j),x {l, r}. Therefore, segment si Sj , ppdi (j) = ppdli (j) + ppdri (j) ppdli (j)ppdri (j)(either Rl Rr detect adversary, both). Note either ppdli (j), ppdri (j)equal 0. need show ppdi (2) ppdi (1), 1 w,least one segment sm , ppdm (2) > ppdm (1). Specically, sucient showppdli (2) + ppdri (2) ppdli (2)ppdri (2) {ppdli (1) + ppdri (1) ppdli (2)ppdri (2)} 0,inequality strict.every segment si , ppdli (1) = ppdli (2) (there change relative location),hence need prove ppdri (2) ppdri (1) ppdli (2){ppdri (2) ppdri (1)}. Since 0ppdli (2) 1, order inequality hold, left show ppdri (2) ppdri (1) 0.Lemma 1 know ppdri (j) monotonically decreasing, therefore i,ppdri (2) ppdri (1), completes proof inequality.left show = m, ppdrm (2)ppdrm (1) > ppdlm (2){ppdrm (2)ppdrm (1)},i.e., ppdlm (2) = 1, ppdrm (2) > ppdrm (1). Robot Rr may inuenceppd sides - segments located left right currentposition. Denote number inuenced segments right (y may equal0). > 0, ppdrwy+1 (2) > ppdrwy (1). words, Rr probability 0895fiAgmon, Kaminka & Krausreaching segment distance + 1 S1 , S2 segmentsaway it, therefore Rr probability greater 0 reach it. = 0,ppdrw (2) = 1 > ppdrw (1), Rr lies exactly segment sw S2 , ppdrw (1) = 0.Theorem 3. team k mobile robots engaged patrol mission maximizes minimal ppdfollowing conditions satisfied. a. time distance every two consecutiverobots equal b. robots move direction speed.Note condition b means robots move together direction, i.e.,change direction, k robots change direction simultaneously.Proof. Following Lemma 2, sucient show combination conditionsb yield minimal distance two consecutiverobots along cyclic path.(N )Since N segments k robots, k possibilities initial placementrobots along cycle (robots homogenous, regardless order).robots positioned uniformly along cycle, time distance pairconsecutive robots N/k. minimal value reached. Therefore,clearly, condition guarantees minimality.robots coordinated, possible two consecutive robots alongcycle, Ri Ri+1 , move opposite directions. Therefore distanceincrease Nk Nk + 2, Lemma 2 ppd segmentssmaller. Ri Ri+1 move towards one another, distanceNk 2 ppd segments become higher.hand, pair Rj Rj+1 exists distance increases,total sum distances consecutive robots remains N , hence minimal ppdaround cycle become smaller.Therefore way achieving minimal distance (maximal ppd) assuringcondition satised, maintaining achieved satisfying condition b.Since facing full-knowledge adversary, goal robots maximizeminimal ppd along perimeter, following corollary follows.Corollary 4. full-knowledge adversarial model, optimal patrol algorithm mustguarantee robots positioned uniformly along perimeter throughout execution patrol.4.1 Penetration Detection Problemgeneral denition problem follows.Penetration detection (PD) problem: Given circular fence (perimeter) divided N segments, k robots uniformly distributed around perimeter distance= N/k (in time) every two consecutive robots, assume takes timeunits adversary penetrate, adversary known full-knowledgepatrol scheme. Let p probability characterizing patrol algorithmrobots, let ppdi (p), 1 description ppdi function p. Find896fiMulti-Robot Adversarial Patrollingoptimal value p, popt , minimal ppd throughout perimeter maximized.Formally,popt = argmax{ min ppdi (p)}0p11idsummarize model Theorems presented above, optimal algorithmmulti-robot perimeter patrol Markovian strategy assumption robotsfollowing characteristics.robots placed uniformly around perimeter segments everytwo consecutive robots.robots coordinated sense decide turn around,simultaneously.time step, robots continue straight probability p turn aroundprobability 1 p, turn around stay segmenttime units.Note framework (i.e. framework homogenous robots),division perimeter sections segments creates equivalent symmetric environment sense order calculate optimal patrol algorithm sucientconsider one section segments, entire perimeter N segments.due fact section completely equivalent other, remainsthroughout execution.divide goal solving PD problem, i.e., nding optimal patrol algorithmtwo stages.1. Calculating ppdi functions 1 d. determined accordingrobotic movement model (directed undirected), environment model (perimeter/fence) sensorial model (perfect/imperfect, local/extended).2. Given ppdi functions, nd solution PD problem, i.e., maximizeppd segment(s) minimal ppd.two steps independent sense incorporating various dierent roboticmodels change process determining solution PD problem, longresult procedure functions representing ppd values segment.hand, would like consider dierent goal functionsmaximizing minimal ppd (for example maximizing expected ppd), donewithout change rst stage, i.e., determining ppd functions. importantresult framework applied dierent environment roboticmodels (for example fence patrol), dierent goal functions (corresponding dierentadversarial settings).897fiAgmon, Kaminka & Krausrst stage basic model (perimeter patrol, directed movement modelrobots, robots perfect local sensing) described Section 4.2, second stagedescribed Section 4.3. Extensions rst stage dierent robot motion modelssensing models described Section 5.4.2 Determining Probability Penetration Detectionorder nd optimal patrol algorithm, necessary rst determine probabilitypenetration detection segment si (ppdi ), function p (the probabilitycharacterizing patrol algorithm, shown Section 4.1). section presentpolynomial time algorithm determines probability.stated previously, based symmetric nature system, need considerone section segments lie two consecutive robots, without lossgenerality, R1 R2 . use Markov chain order model possible statestransition states system.order calculate probability detection segment along time cycles,use graphic model G illustrated Figure 2. segment si originalpath, 1 d, create two states G: One moving clockwise direction (scw),moving counterclockwise direction (scc).RRreachone12si segments within time units, adversary discovered, i.e.,matter segment visited time units. Thereforewould like calculate probability first arrival segment,done dening state sdt (corresponding s0 s0 ) absorbing states, i.e.,robot passes si once, additional visits segment pathconsidered. edges G follows. One outgoing edge scwsccexistscwprobability 1 p turning around, one outgoing edge si1 existsprobability p continuing straightforward. Similarly, one outgoing edge scccwccsi exists probability 1 p turning around, one outgoing edge si+1 existsprobability p continuing straightforward.ccS0S1S2S3S4S0cc01p pcw1p 0S1R2dtcwp41cwppcwcc3p21p431pccp11pcccc11pcwcccwS3S4S4dt000000000000p1p p00000000p1p 000000cc000001p p00cw000p1p 0000cc00000001p pS4cw00000p1p 00dt000000001S31p2dtccS3cwS2pcwS2S2ccS2cwccS1S1R1cwS1S3S4Figure 2: Conversion initial segments robot locations graphical model,respective stochastic matrix . segment corresponds two states: one going clockwise onegoing counterclockwise. ppdi paths starting scwending sdt .898fiMulti-Robot Adversarial Patrollingfollowing theorem, prove probability detecting adversaryrobot segment si (i.e., probability arriving segment time units)equivalent nding paths size absorbing state starting statescc. Therefore possible use Markov chain representation determining ppdi ,shown Algorithm FindFunc.Theorem 5. Determining probability penetration detection segment si , ppdi ,equivalent finding paths length start scwend sdtMarkov chain described above.Proof. simplicity reasons, proof distinguish sldt srdt ,absorbing state left right Markov chain (respectively), althoughpractically represented state sdt .Clearly, due values considered, ppdi determined visitstwo robots surrounding section segments s1 , . . . , sd , denoted Rl Rr .Recall probability penetration detection segment si dened ppdi =ppdli + ppdri ppdli ppdri , ppdri (ppdli ) probability adversary, penetratingsi , detected Rr (Rl ). claim ppdli equivalent computingrrlpaths starting scwending absorbing state sdt (similarly ppdi state sdt ).rlClearly, claim, since path length cannot reach sdt sdt ,follows ppdli ppdri = 0, theorem follow. prove claim ppdli ,ppdri follows directly.ppdli probability Rl reach si least time units. Therefore,must construct paths starting current location Rl passes si ,take account rst visit segment (everything beyond rst visitresults anyway probability detection = 1). step Rl continues straightprobability p turns around probability 1 p. equivalent keeping Rlplace, moving segments towards Rl probability p switch segmentsdirection probability 1 p. Hence, every path starting state scw(without lossgenerality; computing paths starting sccequivalent,requiresswitchinglocationsRl Rr representation) reaching srdt equivalent path started Rlpassing si . Since srdt set absorbing state, every path passingconsidered again, i.e., rst visit Rl si considered, required.Using Markov chain, dene stochastic matrix describesstate transitions system. Figure 2 illustrates Markov chain correspondingstochastic matrix used computing ppd functions. probability arrivalsegment si time units, hence probability penetration detection segment,cwscc2d+1 + s2d+1 entry result Vi , Vi vector 0s, except1 2i 1th location. formal description algorithm given Algorithm1. Note algorithm makes symbolic calculation, hence result setfunctions p. time complexity Algorithm FindFunc depends calculation time, generally (2d)3 . However, since sparse, methods multiplyingmatrices eciently exist (e.g., see Gustavson, 1978), reducing time complexityt(2d)2 , i.e. O(td2 ). Since bounded 1, time complexity O(d3 ).899fiAgmon, Kaminka & KrausAlgorithm 1 Algorithm FindFunc(d, t)1: Create matrix size (2d + 1)(2d + 1), initialized 0s2: Fill entries follows:3: [2d + 1, 2d + 1] = 14: 1 2d5:[i, max{i + 1, 2d + 1}] = p6:[i, min{1, 2}] = 1 p7: Compute =8: Res = vector size initialized 0s9: 1 locV = vector size 2d + 1 initialized 0s.10:11:V [2loc] 1Res[loc] = V [2d + 1]12:13: Return Res4.2.1 Handling Higher ValuesAlgorithm FindFunc Figure 2 demonstrate case = 1, i.e., robotturns around (with probability 1 p) remains current position one time step.general case, robot turns around, cost turningmodeled timehigher. cases, Markov chain modied represent value .ccwSpecically, segment si , instead two corresponding states (scwsi ),cwccw2( ) states: si si , one set 1 states turning arounddirection (from cw ccw vice versa). probabilities assigned edgesccw1 p rst outgoing edge sccrst intermediate state towards siccwcc1 edge direction, similarly path si si . See Figure3 illustration. matrix lled according new chain, timecomplexity creating matrix grows factor (2d + 1)t (2 + 1)t .However, long constant, total time complexity change.S0S1S2S3S4S0R1R2pcw4pcw3pcw21p1 1p1 1p1 1p1111cw1pdt111dt111cc4p11p111pp11cc3p1pcc2p1pcc1Figure 3: Illustration Markov chain > 1, specically, = 3.900fiMulti-Robot Adversarial Patrolling4.3 Optimal Adversarial Patrol Algorithm Full-Knowledge Adversariescases robots face full knowledge adversary, assumed adversarytake advantage knowledge nd weakest spot patrol, i.e., segmentminimal probability penetration detection. Therefore optimal patrol algorithmhandle adversary one maximizes minimal ppd throughoutperimeter. Hence need nd optimal p, popt , minimal ppd throughoutperimeter maximized.Also here, since environment symmetric, need consider entirepatrol path, section segments two consecutive robots. inputprocedure set ppdi (p) functions calculated previous section(Section 4.2).establishing equations representing probability detection segment,must nd p value maximizes minimal possible value segment,p continuous range p [0, 1]. Denote equations ppdi (p), 1 d.maximal minimal value looking p value yielding maximal value insideintersection integrals ppdi (p). intersection integrals also knownlower envelope functions (Sharir & Agarwal, 1996).Observing problem geometrically, consider vertical sweep line sweepssection [0, 1] intersects curves. seeks point p minimalintersection point sweep line curves, denoted ppd (p), maximal.p maximin point. Since segment [0, 1] functions ppd1 , . . . , ppddcontinuous, sweep line solution cannot implemented. prove followinglemma point either intersection point two curves, local maximaone curve (see Figure 4). See Algorithm 2 formal description Algorithm FindP.Figure 4: illustration two possible maximin points (marked full circle). curves representppdi (p) functions p [0, 1]. left, maximin point created intersection twocurves. right, maximin point local maxima lowest curve.following, prove Algorithm FindP nds point p maximinproperty satised.Lemma 6. point p yields maximin value ppd (p) following two propertiessatisfied.a. ppd (p) ppdi (p) 1 d.901fiAgmon, Kaminka & Krausb. One two following conditions holds: ppd (p) intersection two curves (ormore), ppdi (p) ppdj (p) local maxima curve ppdk (p).Proof. Property a. derived denition maximin point. Thereforelooking maximal point satises property a. must still show point,ppd (p), obtained either intersection two curves local maxima.Clearly, maximal point integral found border integral (the curveitself). area intersections curves lies beneath parts curves,ppdi1 , . . . , ppdim , ppdij minimal curve section two pointsjj j[lj , rj ]j=1 [l , r ] = [0, 1]. nding maximal point section ppdmax =max{f (x), x [lj , rj ]}, choosing maximal them, i.e., max{ppdjmax , 1 jm}, obtain ppd (p). section [lj , rj ] maximal point either insidesection borders section. former case precisely local maximappdij . latter intersection point two curves ppdij1 , ppdij ppdij , ppdij+1 .Lemma 7. point p exists yielding maximin value ppd (p) > 0.Proof. order prove lemma, need show intersection integralsppd1 , . . . , ppdd x section [0, 1], section (0, 1] empty. sucesshow every ppdi , ppdi (x) > 0, 0 < x < 1.function ppdi , 1 represents ppd segment si two robots.requirement d2 + 1 (for = 1), follows models consider,0 < p < 1 ppd = 0. Note p = 0 p = 1, ppd either 0 1,contradict fact point guaranteeing ppd (p) > 0.Algorithm FindP nds point scanning possible points satisfying conditionsgiven Lemma 6, reporting x-value (corresponding p value) y-valuedominated ppdi . input algorithm vector functions ppdi , 1value t. Computing intersections every pair functions costs d2 t2 :d2 pair computation, t2 nding root polynomial using, example,Lindsey-Fox method presented Sitton, Burrus, Fox, Treitel (2003). Computingdominance resulting points respect curves d2 well. Thereforetime complexity Algorithm FindP complexity Algorithm FindFunc, O(( Nk )3 ),additional cost O(t2 d2 ) = O(( Nk )4 ) (the algorithm itself), i.e., jointly O(( Nk )4 ).Theorem 8. Algorithm FindP(F, t) finds point p yielding maximin value ppd.Proof. Algorithm FindP checks intersection points pair curves,points local maxima curves. checks dominance points, i.e.,whether location points lower value compared curves,picks maximal them. Therefore, point found, Lemma 6, pointprecisely maximin point. Moreover, Lemma 7 point exists.4.4 Examplesfully implemented Algorithm FindP order nd optimal maximin p pairsds ts. use following examples illustrate relationreected ppd values. Recall running deterministic patrol algorithm902fiMulti-Robot Adversarial PatrollingAlgorithm 2 Algorithm FindP(d, t)1: F Algorithm FindFunc(d, t).2: Set popt 0.3: Fpivot F1,...,d4:Compute local maxima (pmax , Fpivot (pmax )) Fpivot5:Fi , 16:Compute intersection point pi Fi Fpivot7:Fpivot (pi ) > Fpivot (pmax ) Fpivot (pi ) Fk (pi )k8:popt pi .9:Fpivot (pmax ) > Fpivot (pi ) Fpivot (pi ) Fk (pi )kpopt pmax .10:11: Return (pmax , Fpivot (pmax )).range (0, 1).range (0, 1).scenarios handle, minimal ppd 0. assume robots initially headingclockwise direction.First all, seen minimal ppd achieved running FindP always0. t/d 1, i.e., increases, value maximin ppd increases,vice versa, i.e., t/d 1/2, value maximin ppd decreases. seenclearly Figure 5. case, xed value 8 checked maximinppd 9 15. t/d close 1 (d = 9, = 8) maximin ppd = 0.423,value decreases 0.05 t/d close 1/2 (d = 15, = 8). Similar results seenx value check dierent values t.Figure 5: left, results maximin ppd xed = 8 dierent values d: possiblemaximin ppd decreases increases. right, results maximin ppd xed = 16dierent values t: possible maximin ppd increases increases.Figure 6, present values ppd 16 segments, dierent possiblevalues (9 15). seen clearly, value ppd usually decreasesdistance left robot increases, reaches segment maximin ppd,value rises reaching current location robot right.reason lies fact segments left segment maximin ppdinuenced mostly robot left, segments right pointmostly inuenced robot right. Since ps yielding maximin pointexample value greater 0.8 ts, segment maximinvalue right midpoint.903fiAgmon, Kaminka & KrausFigure 6: ppd values 16 segments values (9 15)5. Accounting Movement Constraints Sensing Uncertaintysection describe various ways basic framework multi-robot patrolused solve problem nding optimal patrol algorithm varioussettings. First, describe case movement model robotsnecessarily directed. discuss various sensing capabilities robots perimeterpatrol: imperfect local sensing, perfect long-range sensing imperfect long-range sensing.Finally, describe case robots travel along open polyline (fence)rather perimeter.5.1 Dierent Movement Modelsbasic assumption robotic framework robots movement model directedsense robot go back visit point behind it, physicallyturn around. directed movement model suitable various robotic types, example dierential drive robots commonly used robotic labs. However, casesrobots movement undirected, example robot travels along train tracks.Wedemonstrate section basic framework used also latter case,i.e., robot movement undirected.examine dierence Markov chain resulting ppd three dierentcases:1. Bidirectional Movement model, denoted BMP. Here, robots movement patternsimilar movement tracks camera going back forth along xed course(omnidirectional robots). model, robots movement directionalitysense switching directionsright left vice versadoes requirephysically changing direction robot (turning around).904fiMulti-Robot Adversarial Patrolling2. Directional Costly-Turn model, denoted DCP, basic framework discussedfar 1. robots movement directed, turning around specialoperation attached cost time. Specically, show results= 1.3. Directional Zero-Cost model, denoted DNCP, special case DCPmodel = 0. robots movement directed, yet turning aroundtake extra time. coherently dierent BMP, step robotgo either right left, straight back (where could eitherright left, depending current heading robot).basic framework used handling three models simply adaptingMarkov chain current model. changes lines 5 6 Algorithm FindFunc.description Markov chains described Figure 7. BMP model, moves onestep right (segment + 1) probability p one step left (segmenti1) probability 1p. model similar random walk. correspondingMarkov chain simple: edges exist si si+1 probability p sisi1 probability 1 p (with related direction). DNCP DCPmodels, assume directionality movement, hence robot continues movementcurrent direction probability p, turns around (rewinds) probability1 p. DCP, robot turns around remain segment (as describedFigure 2). DNCP model, chain similar one above, however edgescccccwexist scwsi+1 si si1 probability 1 p. See Figure 7illustration DNCP, DCP BMP Markov chain.S0S1S2S3S4S0R1R2dtcwp4DCPcw1ppcccccwDNCPcwcc4dtcc3pppp1pcc1cwp2cw1p41p3dt1pcc2cc11pppp1pdt1p21pcccwpp31ppBMPp2pp1p 4cw1p3pdt1p4p31p2dt11pFigure 7: Conversion initial segments robot locations graphical model threemovement models.905fiAgmon, Kaminka & Krausexamined dierence resulting ppd values three modelscase = 16, = 12 (Figure 8). clearly noticeable DCP model yieldsless equal values ppd compared DNCP model throughout segments. reasonturning around, DCP model, operation costs extra cycle,therefore probability arriving segment decreases, compared caseturning around costly. Another interesting phenomena ppd valuesBMP considerably higher (and close 1) values obtained modelssegments closer location righthand side robot. value decreasesdramatically around value increases back again. Recalldirectionality movement, therefore probability going right 0.707 goingleft 1 0.707 = 0.293, explains phenomena. One might expectedp = 0.5 random walk model (BMP), however choosing equal probabilitygoing right left, robots necessarily neglect segments away(the mid segments two consecutive robots), resulting lower minimal ppd.Figure 8: Results maximin ppd values = 16 = 12 three models: DNCP, DCPBMP. maximin ppd values circled.5.2 Perimeter Patrol Imperfect Penetration DetectionUncertainty perception robots taken consideration practicalmulti-robot problems. Therefore consider realistic case robotsimperfect sensorial capabilities. words, even adversary passessensorial range robot, still necessarily detect it.introduce ImpDetect model, robot travels one segment pertime cycle along perimeter monitoring it, imperfect sensing. Denote906fiMulti-Robot Adversarial Patrollingprobability adversary penetrating segment si monitoredrobot R R actually detect pd 1.Note pd < 1, revisiting segment robot could worthwhileit couldincrease probability detecting adversary. Therefore probability detectionsegment si (ppdi ) equivalent probability first arriving si (as illustratedSection 4.2), probability detecting adversary visit si ,0 t. Denote probability yth visit robot segment si wiy .Therefore ppdi dened follows.ppdi = wi1 pd + wi1 (1 pd ) {wi2 pd + wi2 (1 pd ) {. . . {wit pd }}}(1)words, probability detecting penetration probabilitydetected rst visit (wi1 pd ) plus probability detectedthen, later stages. probability detectedsecond visit (wi2 pd ) later stages, on.Note time units, wit = 0 currently unoccupied segments si ,robot resides si , wit precisely (1 pd )t .One building blocks upon optimal patrol algorithms based,assumption probability detection decreases remains distancerobot increases, i.e., monotonic decreasing function. fact usedSection 4 proving order maintain optimal ppd, robots must placeduniformly around perimeter (with uniform time distance), maintain distancecoordinated. order show well, rst prove probabilitydetection monotonically decreases distance location robot.Lemma 9. Let = {st+ , . . . , s1 , s0 , s1 , . . . , st } sequence 2t segments, robotRa resides s0 time 0. 0, ppdi ppdi+1 , 0, ppdi ppdi1 .Proof. First, assume > 0 (positive indexes). Equation 1, need compare1 p + w 1 (1wi1 pd + wi1 (1 pd ) {wi2 pd + wi2 (1 pd ) {. . . {wit pd }}} wi+1i+12 p + w 2 (1 p ) {. . . {wpd ) {wi+1i+1i+1 pd }}}. therefore sucient show, 1 t. prove induction m. base case, considerwim wi+11 . accurately proven Lemma 1, based= 1, i.e., need show wi1 wi+1fact movement robots continuous, therefore order getsegment must visit segments (the formal proof also uses conditionalprobability law).. Denoteassume correctness < m, prove wim wi+1probability robot placed segment si return si within r time units xi (r).symmetric environment, everyj, xi (r) = xj (r). Moreover, r, xi (r)=xi (r 1). Therefore wim described r+ut wim1 (u) xi (r), similarly wi+1m1m1m1wi+1, since xi (r) =r+ut wi+1 (u) xi+1 (r). induction assumption, wixi+1 (r), follows wi wi+1 , proving lemma positive indexes.negative indexes reective image positive indexes, timeunits. Since induction proven values, proof negative indexesdirectly follows.907fiAgmon, Kaminka & Krausfollowing Theorem follows directly Lemma 9. idea behindsince probability penetration detection decreases distance robotsgrow, minimal ppd average ppd maximized distance robotssmall possible. Since patrol path cyclic, achieved distanceevery two consecutive robots uniform, remains uniform. Note Theorem10 generalization Theorem 3 imperfect sensing (based factgeneral structure ppd function remains even robots might benetrevisiting segment, increasing ppd segment).Theorem 10. full knowledge adversarial model, patrol algorithm ImpDetectmodel optimal satisfies two conditions: a. robots placed uniformlyaround perimeter. b. robots coordinated sense turn around,simultaneously. assuring two conditions, robots preserve uniformdistance throughout execution.Algorithm nding ppdi imperfect sensorial detection:Find probability penetration detection pd 1 results dierent Markovchain, hence dierent stochastic matrix . Figure 9 demonstrates new graphicalmodel new resulting stochastic matrix (compared Figure 2, pd = 1).ccdierence algorithm division s0 two states, scw0 s0 ,addition absorbing state sdt represents detected state transitionsstates. ppdi therefore obtained + 1 steps (compared steps)sdt location result vector.time complexity algorithm remains O(d4 ).S0S1S2S3S4S0ccR1R2cw41pcw4p31pccppcw21pcc3p12pcw0pd(1p)(1pd )1pccpcc1p(1pd )cc0pdcccwcccwS4S4S0S0dt0000000000000000cc0001p p000000cw0p1p 00000000cc000001p p0000cw000p1p 000000cc0000001p00S3S4cwS4ccpcwS3pS31ccS31p 0S2dtcwS20S1cw1p pS2ccS2pccS1cwS1p(1pd )cwS1S00p(1pd )0p0000p1p 000000000 (1p)(1p000)pdS0cw0000000 p(1pd ) (1p)(1p)0pddt00000001000Figure 9: Conversion initial segments robot locations graphical model,respective stochastic matrix imperfect sensing model.908fiMulti-Robot Adversarial Patrolling5.3 Improving Sensing Capabilities Perimeter Patrolsection present enhancements considering various sensing capabilitiesrobots. Specically, rst consider case robot sense beyondcurrently visited segment. oer solution case robotsense beyond current position, yet sensing capabilities perfect, changefunction distance current position.5.3.1 Extending (Perfect) Sensing Rangesection consider LRange model, sensorial range robot exceedssection currently resides in. Use L denote number segments robotsenses beyond segment currently occupies. L > 0, refer L segmentsshaded segments. Note location shaded segments depends directionrobot shading them, always direction robot facing.trivial solution dealing situation enlarge size segment,thus enlarge length time unit used base system,force L 0. However, case lose accuracy analysis system,length time cycle small possible also suit velocity robotsvalue t.general, values handled system bounded relation(the distance every two robots along path) - see Section 4. L > 0,changes. Specically, L = 0, possible values considered d+2 1.However, L > 0, possible handle even smaller values t, i.e., evenpenetration time adversary short. Formally, possible values givenfollowing equation.d+LtdL12smaller d+2 L, adversary full knowledge managepenetrate probability 1, i.e., segment (sL+1 ) unreachable withintime units. hand, greater L 1, simple deterministicpatrol algorithm detect penetrations probability 1. assumetime units robot turns around, sense current segment.change sensing model robot reected Markov chain, seencwFigure 10. change add 2L arrows absorbing state sdt , scw1 , . . . , sLccccsd , . . . , sdL+1 . stochastic matrix changes accordingly, probabilitypenetration detection segment si becomes result vector multiplication t+1 Vi ,Vi vector size 2d + 1 entries 0 except entry correspondinglocation scw, holds value 1, similar process described AlgorithmFindFunc (1).5.3.2 Extending Sensorial Range Along Imperfect Detectionmany cases, actual sensorial capabilities robot composed two characteristics described previous sections, i.e., robot sense beyond currentsegment, however sensing ability imperfect. Therefore section introduce909fiAgmon, Kaminka & KrausL=1ccS0S1S2S3S4S0S1cc0cwcccwcwp4cw1pcwpcc3pp21pcc4p31cc1pcc12p1pcc1dtcwcccwS4dt1p p0000000000000010001p p00000p1p 000000000001p p00000p1p 0000cc000000100S4cw00000p1p 00dt000000001S31cwS4S21ccS3S2cwcwS3S1R2ccS2S1R1cwS1S3S4S2Figure 10: illustration L segments shaded robot R. case R facing right, thereforeshaded segments right. Markov chain changes accordingly, therefore also stochasticmatrix .ImpDetLRange sensorial model, combination LRange ImpDetectmodels. robot sense L segments beyond current segment, yet pdsegment varies necessarily 1. therefore describe compute ppdicase, deals realistic form sensorial capabilities (Duarte & Hu,2004): imperfect, long range sensing.information regarding sensorial capabilities robots includes two parameters. rst describes quantity sensing ability, i.e., number segmentsexceeds current segment robot resides, sensing abilities,denoted L. second parameter describes quality sensing segmentsrobot sense. given form vector VS = {v0 , v1 , . . . , vL }, viprobability robot residing s0 detect penetration occurs segment si .assume values VS decrease monotonically, i.e., increases, vi decreasesremains same.Markov chain model, illustrated Figure 11, changes order reectimperfect sensing along long range sensing. absorbing state sdt existaddition states scw0 s0 cc. transition probabilities added 2Lsegments: i, j 0 L; L + 1 j d, transition scws0 probability viccsj s0 probability vdj+1 . addition, transition scwsi cccw probability (1 p)(1 vprobability (1 p)(1 vi ), sccdj+1 ), hencejjcwcwcccctransition probability si si1 p(1 vi ) sj sj+1 p(1 vdj+1 ).probability penetration detection segment si result t+1 multipliedVi location s0 result vector. Note also here, similar solution describedSection 5.2, since added new absorbing state (which takes extra step reach),ppdi result product stochastic matrix Vi location s0 + 1time steps (not t).910fiMulti-Robot Adversarial Patrollingv0<1 v1<1S0S1S2S3S4S0ccR1S1R2ccS1p(1v0 )cwS1v1p41pcw4p31pccpcw21pcc3pp1p(1v1 )cw0(1p)(1v1 )(1p)(1v0 )cccccc2cwp(1v1 )1p(1v0 )0v0v0cwcccwS4S0S0dt0v1) 000000000000 p(1v1 ) v1001p p000000p1p 00000000cc000001p p0000cw000p1p 000000cc00000001pcw00000p1p 00p(1v0 ) 0000000 (1p)(1v0S3S4S4ccv1ccS40S0pcwS30S31ccS30(1p)(1v)10 p(1v(1p)(1v0 )0cwS2cwS2dtccS2ccS2cw0cwS10p0000)v0cwS00000000 p(1v0 ) (1p)(1v0 )0v0dt00000001000Figure 11: illustration L segments shaded robot R, probability detectionnecessarily 1. case R facing right, therefore shaded segments right. Markovchain stochastic matrix changes accordingly.5.4 Multi-Robot Adversarial Patrolling Along Fencesgeneral work, specically previous sections, assumed robots travelaround closed, circular, area. section discuss patrolling along open polyline,also known fence patrol. First, discuss patrol dierent perimeterpatrol. describe algorithm determining ppdi fence patrol assumingrobots perfect sensing capabilities, nally provide algorithmrobots imperfect sensing.5.4.1 Patrolling Along Closed Polyline vs. Open Polylinefollowing, describe patrolling along open polyline challengingpatrolling cyclic environments (closed polyline).rst reason lies fact robots required go back forth alongpart (or parts) open polyline. result, elapsed time two visitsrobot point along line almost twice long elapsed timecircular setting. Figure 12, given two environments: closed polyline (circle) (a)open polyline (b). Note open polylines b. c. equivalent senserobot travels one segment per time step, regardless shapesection. lines a. b. total length l numberrobots (4). circular environment, takes adversary l/4 time unitspenetrate - never able penetrate even robots simply continuously traveluniform distance them. However, robots travel along open polyline(b), maximal time duration two visits roboteven best case,2l/4 2 (Elmaliach, Shiloni, & Kaminka, 2008). Therefore weaker adversary911fiAgmon, Kaminka & Krauspenetration time almost twice long circular fence might still ablepenetrate.a.b.c.Figure 12: Illustration dierence patrolling along line patrolling along circle,dierent polylinesAnother reason added complication analyzing probability penetrationdetection open polyline environments lies asymmetric nature travelingsegments along time. circular environment, robots coordinated switchdirections unison, placement robots symmetric time unit. Therefore segments distance robot (with respect direction)probability penetration detection. Hence order calculate optimal waymovement (in case probability p turning around), sucient considerone section segments, resulted p equivalent throughout execution.open polyline environment case. probability penetration detection diers respect current location direction robot. Thereforealgorithm nds ppd segment, needs calculate ppd functionp segment si possible initial location robot inside section.Therefore results matrix size ppd functions (as opposed vectorfunctions circular fence).5.4.2 Determining ppdi Open Polyline (Fence)Following framework multi-robot patrol along open line proposed Elmaliachet al. (2008), assume robot assigned patrol back forth along one sectionsegments. Given framework, would like compute optimal patrol algorithmrobots along section. Similar perimeter patrol case (Section 4.2), describesystem Markov chain (see Figure 13), relative stochastic matrix . Sincerobots directionality associated movement, create two statessegment: rst traveling segment clockwise direction, secondtraveling counterclockwise direction. probability turning around endsection 1, otherwise robot continue straight probability p,turn around probability 1 p.Note main dierence perimeter patrol calculation ppdi liesnumber resulting ppdi functions. perimeter patrol, due symmetric nature,one ppdi function segment current location robot, representingprobability robot arriving time units. Here, however, ppdi dependscurrent location robot, hence location robot functionsprobability penetration detection, therefore total d2 functions (comparedperimeter patrol).912fiMulti-Robot Adversarial PatrollingDenote probability penetration detection segment si given robotcurrently segment sj ppdji . order calculate ppdji function 1 i, j d,create dierent matrices: M1 , . . . , Md . matrix Mi corresponds calculating ppdji ,i.e., probability penetration detection segment si , calculate ppdjievery current location sj robot (similar done perimeter patrol).Figure 13 demonstrates matrix M2 ppd2i calculated. gure describesgeneral case pd 1, i.e., robot might imperfect sensing.ccS1S2S3S4S1cc0cwS1cw1p4cw3pcw4p(1p)(1p)1pccp(1pd )2cc3cc2p11p(1pd )dt1pcc11cwcccwdtS4S41p p000000100000000cc000)000pdcw0 p(1pd )(1p)(1p) 00000pdcc000001p p00cw000p1p 0000cc00000001pcw00000p1p 000000001S3S3S4S4pdccS3S2cwcwS3S2ccS2S1pdcwS1dtpS2(1p)(1p)p(1pd0pFigure 13: Description system Markov chain, along stochastic matrixcalculating ppd segment s2 .5.4.3 Optimal Algorithm Fence Patrolcase fence patrolling, ppd value depends current location robot.Consequently, optimal p value characterizing patrol robots dierentsegment si , 1 d. Therefore could dierent optimal p valuesrespect location orientation robot (2d values). However, sucientcalculate ppd values times (and 2d times)only one direction,direction reective image rst.order nd maximin point fence patrolling case, use algorithmMaximinFence, nds value p minimal ppd maximized, usingAlgorithm FindP computes point nding maximal point integralintersection curves (ppdi ). complete description algorithm shownAlgorithm 3.Algorithm 3 Procedure MaximinFence(d, t)1: FindFencePPD(d, t)2: 13:OpP [i] FindP(d, t) additional given input [i] vector ppd functions.4: Return OpP913fiAgmon, Kaminka & Kraus6. Summarypaper presents problem multi-robot patrolling strong, full-knowledge, adversarial environments. problem team robots required repeatedly visitpath, basic case perimeter, detect penetrations controlledadversary. assume robots act strong adversarial model, adversaryfull knowledge patrolling robots uses knowledge order penetrateweakest spot patrol. describe framework basic case multirobot patrol around closed polygon, use framework developing, polynomialtime, optimal patrol algorithm, i.e., algorithm strengthens weakest spotpatrol. framework extended order solve problem also openfence environment various movement sensing models robots.paper makes several assumptions allowing computation optimal strategypatrolling robots. One assumption rst order Markovian strategypatrolling robots. Although proving disproving optimality using rst order Markovian strategy hard, could interesting examine case higher order Markovianstrategies compare time complexity performance solution discussedhere. Another direction future work involves non-uniform environments,utility obtained detecting penetrations one hand succeeding penetrationuniform throughout environment. challenges left future workinclude handling heterogenous robots non linear environments.7. AcknowledgmentsPreliminary results appeared Proceedings IEEE International ConferenceRobotics Automation (2008), Proceedings Tenth Conference IntelligentAutonomous Systems (2008) Proceedings IJCAI Workshop Quantitative RiskAnalysis Security Applications (QRASA) (2009). research supported partISF grant #1357/07 #1685/07, grant #3 6797. thank anonymousreviewers constructive comments helpful suggestions, always, thanks K.Ushi.ReferencesAgmon, N., Kaminka, G. A., & Kraus, S. (2008). Multi-robot fence patrol adversarialdomains. Proceedings Tenth Conference Intelligent Autonomous Systems(IAS-10), pp. 193201. IOS Press.Agmon, N., Kraus, S., & Kaminka, G. A. (2008). Multi-robot perimeter patrol adversarial settings. Proceedings IEEE International Conference RoboticsAutomation (ICRA).Agmon, N., Kraus, S., & Kaminka, G. A. (2009). Uncertainties adversarial patrol. Proc.IJCAI 2009 workshop Quantitative Risk Analysis Security Applications(QRASA).914fiMulti-Robot Adversarial PatrollingAhmadi, M., & Stone, P. (2006). multi-robot system continuous area sweeping tasks.Proceedings IEEE International Conference Robotics Automation(ICRA).Almeida, A., Ramalho, G., Santana, H., Tedesco, P., Menezes, T., Corruble, V., & Chevaleyr, Y. (2004). Recent advances multi-agent patrolling. Lecture Notes ComputerScience, 3171, 474483.Amigoni, F., Gatti, N., & Ippedico, A. (2008). Multiagent technology solutions planningambient intelligence. Proceedings Agent Intelligent Technologies (IAT-08).Basilico, N., Gatti, N., & Amigoni, F. (2009a). Extending algorithms mobile robotpatrolling presence adversaries realistic settings. ProceedingsIEEE/WIC/ACM International Conference Intelligent Agent Technology(IAT), pp. 565572.Basilico, N., Gatti, N., & Amigoni, F. (2009b). Leader-follower strategies robotic patrolling environments arbitrary topologies. AAMAS, pp. 5764.Chevaleyre, Y. (2004). Theoretical analysis multi-agent patrolling problem. Proceedings Agent Intelligent Technologies (IAT-04).Coppersmith, D., Doyle, P., Raghavan, P., & Snir, M. (1993). Random walks weightedgraphs applications on-line algorithms. Journal ACM, 40 (3).Duarte, M. F., & Hu, Y. H. (2004). Distance-based decision fusion distributed wirelesssensor network. Telecommunication Systems, 26 (2-4), 339350.Elmaliach, Y., Agmon, N., & Kaminka, G. A. (2007). Multi-robot area patrol frequency constraints. Proceedings IEEE International Conference RoboticsAutomation (ICRA).Elmaliach, Y., Agmon, N., & Kaminka, G. A. (2009). Multi-robot area patrol frequency constraints. Annals Math Artificial Intelligence, 57 (3-4), 293320.Elmaliach, Y., Shiloni, A., & Kaminka, G. A. (2008). realistic model frequencybased multi-robot fence patrolling. Proceedings Seventh International JointConference Autonomous Agents Multi-Agent Systems (AAMAS-08).Gustavson, F. G. (1978). Two fast algorithms sparse matrices: Multiplicationpermuted transposition. ACM Trans. Math. Softw., 4, 250269.Haynes, T., & Sen, S. (1995). Evolving behavioral strategies predators prey. IJCAI95 Workshop Adaptation Learning Multiagent Systems, pp. 3237.Lynch, N. A. (1996). Distributed Algorithms. Morgan Kaufmann.Paruchuri, P., Pearce, J. P., Tambe, M., Ordonez, F., & Kraus, S. (2007). ecientheuristic approach security multiple adversaries. ProceedingsSixth International Joint Conference Autonomous Agents Multi-Agent Systems(AAMAS-08).Paruchuri, P., Tambe, M., Ordonez, F., & Kraus, S. (2007). Security multiagent systemspolicy randomization. Proceedings Sixth International Joint ConferenceAutonomous Agents Multi-Agent Systems (AAMAS-07).915fiAgmon, Kaminka & KrausPita, J., Jain, M., Ordonez, F., Tambe, M., Kraus, S., & Magorii-Cohen, R. (2009). Eective solutions real-world stackelberg games: agents must deal humanuncertainties. Proceedings Eighth International Conference AutonomousAgents Multiagent Systems (AAMAS-09).Sak, T., Wainer, J., & Goldenstein, S. K. (2008). Probabilistic multiagent patrolling.Proc. 19th Brazilian Symposium Artificial Intelligence (SBIA-08), pp. 124133.Sharir, M., & Agarwal, P. K. (1996). Davenport-Schinzel sequences geometricapplications. Cambridge University Press.Shieh, J. S., & Calvert, T. W. (1992). View route planning patrol exploringrobots. Advanced Robotics, 6 (4), 399430.Sitton, G., Burrus, C., Fox, J., & Treitel, S. (2003). Factoring very-high-degree polynomials.Signal Processing Magazine, IEEE, 20 (6), 27 42.Stewart, W. J. (1994). Introduction Numerical Solution Markov Chains. PrincetonUniversity Press.Vidal, R., Shakernia, O., Kim, H. J., Shim, D. H., & Sastry, S. (2002). Probabilistic pursuitevasion games - theory, implementation, experimental evaluation. RoboticsAutomation, IEEE Transactions on, 18 (5), 662669.916fiJournal Artificial Intelligence Research 42 (2011) 765-813Submitted 08/11; published 12/11Theoretical Practical Foundations Large-ScaleAgent-Based Micro-Storage Smart GridPerukrishnen VytelingumThomas D. VoiceSarvapali D. RamchurnAlex RogersNicholas R. Jenningspv@ecs.soton.ac.uktdv@ecs.soton.ac.uksdr@ecs.soton.ac.ukacr@ecs.soton.ac.uknrj@ecs.soton.ac.ukAgents, Interaction Complexity GroupSchool Electronics Computer ScienceUniversity SouthamptonSouthampton, SO17 1BJ, UK.Abstractpaper, present novel decentralised management technique allows electricity micro-storage devices, deployed within individual homes part smart electricitygrid, converge profitable efficient behaviours. Specifically, propose usesoftware agents, residing users smart meters, automate optimise chargingcycle micro-storage devices home minimise costs, present studytheoretical underpinnings implications practical solution, using software agents micro-storage management. First, formalising strategicchoice agent makes deciding charge battery, develop game-theoreticframework within analyse competitive equilibria electricity grid populated agents hence predict best consumption profile populationgiven battery properties individual load profiles. framework also allows uscompute theoretical bounds amount storage adopted population. Second, analyse practical implications micro-storage deployments grid,present novel algorithm agent use optimise battery storage profileorder minimise owners costs. algorithm uses learning strategy allowsadapt price electricity changes real-time, show adoptionstrategies results system converging theoretical equilibria. Finally,empirically evaluate adoption micro-storage management technique withincomplex setting, based UK electricity market, agents may widely varyingload profiles, battery types, learning rates. case, approach yields savings14% energy cost average consumer using storage device capacityless 4.5 kWh 7% reduction carbon emissions resulting electricitygeneration (with domestic consumers adopting micro-storage and, commercialindustrial consumers changing demand). Moreover, corroborating theoreticalbound, equilibrium shown exist 48% households would wishstorage devices social welfare would also improved (yielding overallannual savings nearly 1.5B).1. Introductionvision intelligent electricity delivery network, commonly called smart grid,advocated one main solutions ensuring sustainable energy provisionc!2011AI Access Foundation. rights reserved.fiVytelingum, Voice, Ramchurn, Rogers & Jennings(US Department Energy, 2003; Galvin & Yeager, 2008; DECC, 2009). grids aimreduce inefficiencies energy usage, minimise carbon emissions reduce costs generateelectricity. key element vision consumers able respondcurrent condition grid, shifting reducing use electricity, twoway communication channel actors system (i.e., suppliers,consumers, grid operators). doing, expected peaks demandreduced, which, turn, would reduce need expensive carbon-intensivepeaking plants (i.e., spinning reserve) rely fossil fuels.Two key technical enablers smart grid increased degrees automationability store energy. former case, consumers need able delegatecomplex time-consuming reasoning shifting reducing demand, subjectindividual preference, software agents act behalf (Ramchurn,Vytelingum, Rogers, & Jennings, 2011c). end, smart meters developedprovide consumers agents real-time information homes consumptionstate grid, provide suppliers grid operators consumptiondata homes. Moreover, smart meter roll-outs mandated numbercountries, including France (by 2016), Spain (by 2018) UK (by 2020).information feeds, consumers able improve management energy(e.g., switching devices need rescheduling power-hungry devicestimes). latter case, agents use information decide store electricitytimes overall demand grid low (and generally cheaper) re-useelectricity grid operating close limits (i.e., generators operatingnear capacity transmission lines close overload electricity generallyexpensive). Furthermore, storage devices also used compensate variabilitymany forms renewable electricity generation (e.g., wind, wave, solar) likelyincreasingly prominent component future grid (Bathurst & Strbac, 2003).date, research storage technologies focused designing new low-costlarge-scale storage devices (with capacities order 10-100MWh) ableefficiently store electricity long periods time allow sufficient number charging/discharging cycles without significant degradation performance (Bathurst & Strbac,2003). However, development large variety micro-storage devices (i.e.,capacities order kWh) installed homes1 vehicles2 , futurelarge numbers individual consumers store small amounts electricity orderaccommodate peaks demand variability supply soon possible.are, however, number potential challenges setting. First, consumers decidecharge batteries time, price low, significant peakdemand could well ensue. would, turn, result higher electricity generation costsgreater carbon emissions could overload system already operating closemaximum capacity (resulting brown-out or, worst case, black-out). Indeed, unintended population-wide synchronisation already seen real-world1. See batteries recently developed GS Yuasa (http://lithiumenergy.jp/en/products/) Power Yiile(http://eliiypower.co.jp/english/lithium-ion/).2. Vehicle grid (V2G) technologies enable energy stored batteries electric vehicles (EVs)(e.g., Mini-E Nissan Leaf) plug-in hybrid electric vehicles (PHEVs) (e.g., Toyota Plug-in PriusChevrolet Volt) (Sovacool & Hirsh, 2009; Lund & Kempton, 2008).766fiTheoretical Practical Foundations Agent-Based Micro-Storagedemand-response trials consumers manually react critical pricing periods (Hammerstrom et al., 2008). Second, consumers simply charge batteries ensuresufficient energy cover whole demand across day, may endpaying need to. may cheaper use grid-suppliedelectricity certain times, rather energy already stored battery. Finally,homes system start using storage devices manage reduce peak demand(by optimising battery charging usage costs), electricity prices may become lowerprice stored electricity (including cost battery), thus voiding needmicro-storage breaking market devices.Addressing aforementioned issues formulation conventional closedform solutions (see Section 2 details) challenged fact systemcomposed large numbers distinct stakeholders (typically millions consumerstens market makers network managers) operating completely decentralised fashion individually act satisfy particular objectives constraints(to supply use energy) may conflict (e.g., network managers aim minimisepeaks demand consumers aim minimise costs use devicesconvenient time day). background, agent-based approachused framework analyse properties systems also implementation technology (Exarchakos, Leach, & Exarchakos, 2009; Houwing, Negenborn,Heijnen, Schutter, & Hellendoorn, 2007; van Dam, Houwing, & Bouwmans, 2008; Rogers &Jennings, 2010). particular, game theory used determine propertiessystem multiple self-interested parties interact software agents installedsmart meters optimise usage storage profile house using informationvariety sources (e.g., weather data predict heating needs costs price plandata suppliers). Now, existing approaches applying intelligent agentsstudy individual homes could optimise way store energy storage devices could coordinate renewable energy generation facilities maximise energy usedsources (see Section 2 details). However, doing, ignoreindividual selfish preferences consumer model well real impactagents learning adapt constraints impose system.remedy this, crucial devise approach focuses system dynamicsagents system given freedom buy electricity whenever see fit.paper, take approach provide analyticalpractical solution decentralised control micro-storage devices grid. Specifically, develop game-theoretic framework modelling storage devices large-scalesystems device controlled self-interested agent aims maximisemonetary profits real-time price electricity provided grid. Usingframework, certain reasonable assumptions, able predict equilibriasystem given agent behaves rationally (i.e., always adopts storage profileminimises costs) reacts price signal. Given this, go deviseintelligent agent-based storage strategies learn best storage profile given market prices result aggregate storage consumption profileagents system. Crucially, show agents using strategies achievepredicted equilibria and, building upon this, simulate large populations agentsorder predict system behaviour various conditions.767fiVytelingum, Voice, Ramchurn, Rogers & Jenningssomewhat detail, work advances state art following ways:1. provide novel analytical game-theoretic framework captures synchronousbehaviours consumers micro-storage devices within smart grid. usestudy electricity storage strategies agents might adopt smart gridreal-time pricing. Given typical electricity usage profiles consumers,able compute competitive equilibria describe individualagent going charge device, use stored electricity, use electricitygrid. use analytical solution benchmark decentralised solution.2. provide theoretical bound storage capacity neededpopulation, well bound portion population adopt storage.3. provide new micro-storage strategies enable agents learn best storageprofile adopt, even taking account probable heterogeneitymicro-storage devices adopted consumers across grid (e.g., devicesvary capacity fast charged discharged). practicalstrategies shown converge competitive equilibria predictedanalytical framework come system-wide benefits include reducedcarbon emissions, well cost savings.4. show agents, learnt best storage profile, also learn buyprofitable storage capacity. Given this, using evolutionary game theoreticanalysis, able predict portion population would actuallyacquire storage capacity maximise savings. showentire population. Rather, half them, confirming theoreticalbounds analytical framework predicts.short, first attempt modelling, predicting equilibria building intelligent strategies problem electricity storage large scale. approach alsojustifies provides basis implementation real-time electricity pricingdomestic electricity distribution.rest paper structured follows. Section 2, discuss related workarea electricity storage electricity markets. Section 3 discusses key featuresmarkets lays general assumptions upon build framework.Section 4 presents game-theoretic framework shows competitive equilibriasystem computed and, based equilibria, determines many userslikely adopt micro-storage. Building this, Section 5 describes dynamicsmarket agents given ability learn best storage profile Section 6empirically studies system simulations. Then, Section 7 expands costbenefit analysis storage system given heterogenous population consumersdifferent usage profiles. Finally, Section 8 concludes.2. Backgroundsection, first review current storage technologies illustrate micro-storageevolved date likely potent energy management technology768fiTheoretical Practical Foundations Agent-Based Micro-Storagefuture. follow discussion existing approaches power systems literatureusing storage, including agent-based approaches proposed managegrid general micro-storage particular. Furthermore, motivate needreal-time pricing mechanisms grid order enable responsive demandconsidering response consumers fixed prices time-of-use tariffs.2.1 Energy Storage Technologieslarge scale storage electricity within electricity grid new concept. Manycountries operate pumped-storage power plants store electricity pumping waterhigh reservoir prices low, release water use generateelectricity prices high supply short. example, Dinorwig Power StationUK store approximately 10GWh electricity, supply stored energysix hours, providing 1.8GW power (Williams, 1984).However, increased need storage capacity electricity grids increasingly seekincorporate intermittent renewable sources, wind generation solar power, coupledhigh capital costs pumped storage plants limited number suitable sites construction, mean much recent research focused alternativesmaller storage solutions typically store 10-100MWh electricity. Examples technologies already demonstrated commercially include use undergroundcaverns store electricity compressing releasing air (Swider, 2007) storagelarge chemical flow batteries (Shibata & Sato, 1999).recently, attention turned micro-storage3 20kWh electricitymight installed within homes part smart grid roll-out. interestlargely driven rapidly decreasing cost efficient batteries, lithium-ioncells nickel-zinc alternative, developed use within electric vehicles(den Bossche, Vergels, Mierlo, Matheys, & Autenboer, 2006). Indeed, energy storagecapacity required viable electric vehicle close daily consumption home(e.g., Chevrolet Volt battery capacity 16 kWh Nissan Leaf store24 kWh). Thus, possible envisage micro-storage deviceswidely used short medium term, either dedicated home storage batteries,additional capability electric vehicles.2.2 Agent-Based Systems Griduse software agents, residing smart meters, first envisaged Schweppe,Tabors, Kirtley, Outhred, Pickel, Cox (1980) proposed mechanisms agentsmanage use electricity within single home buy electricity real-timebehalf owner. Since then, number agent-based approaches developedmultiple autonomous agents represent interests different actors grid.example, Ygge, Akkermans, Andersson, Krejic, Boertjes (1999) initiated workabstracting electricity markets multi-commodity markets showed agents trad3. Note average cost micro-storage battery today varies around 300 1000per kWh average start-up cost 200. Note prices indicative giveninnovative nature area investment electric vehicle battery technology, costmicro-storage gradually decreasing (see http://www.pikeresearch.com).769fiVytelingum, Voice, Ramchurn, Rogers & Jenningsing energy different times day, could generate efficient allocations . Moreover,Jennings, Corera, Laresgoiti, Mamdani, Perriolat, Skarek, Varga (1996) developed coordination mechanisms different actors grid manage allocation transmissioncapacity and, recently, Sun Tesfatsion (2007) Li Tesfatsion (2009) developed agent-based electricity market simulations incorporate transmission constraintsdifferent types buyers sellers grid. Kok Venekamp (2010) take similar approach implement agent-based architecture run electricity marketindividual actors represent either generators devices home. Note, however,none approaches consider daily consumption profile consumers,agent might optimise consumption storage electricity maximise ownersbenefit. believe crucial agents profitable users,specific needs lifestyle, order commercially viable. Specifically,agents able provide personalised home energy managementdeployed real world.context, note early work Daryanian, Bohn, Tabors (1989)illustrated individual agents could optimise, iterative algorithms, loadprofile house using electricity storage device. approach was, however, limitedconsidering basic battery properties consider wider issues gridlevel adoption batteries population optimum storage capacityrequired maximum savings. recently, Houwing et al. (2007) provided algorithmsagents optimise storage using small domestic combined heat power (CHP) plants,ignored populations agents would impact grid. hand,Exarchakos et al. (2009) van Dam et al. (2008) studied application storagedevices wider scale. showed using demand-side management techniques,storage profile number homes controlled centrally, increase savingsmade system. Unfortunately, centralised approach automatically introducessingle point failure system take account individual preferencesuser buy, use, turn storage device. hand, Ramchurn,Vytelingum, Rogers, Jennings (2011b) consider supplier retailing large numberagents continuously optimise storage, assume effectlarge-scale optimisation influence wholesale price market usuallycase considering large enough proportion population. Thus,paper, take market-based approach similar Ygge et al. (1999) YggeAkkermans (1999), informationally decentralised (i.e., centre completeperfect information required), therefore robust, agent buys electricityreal-time markets individually controls storage profile associated home,based real-time prices reflect demand (and supply) market.2.3 Electricity Pricing Mechanismsapproaches assume existence control signal dictateshome must store best use stored electricity, thereby reducingload grid peak times (see Figure 1 example average UK demandresult peaks) making saving reductions come monetary rewards. end, Schweppe et al. (1980) proposed use real-time pricing (RTP)770fiTheoretical Practical Foundations Agent-Based Micro-Storagespot pricing electricity better way manage demand conditions gridaccurately reflected price (as set single utility electricity market).Thus, contrary pricing signals traditionally used grid, eitherbased fixed price time-of-use (TOU) price, whereby premium chargedtimes anticipated peak demand, real-time price reflects current continuouslychanging balance supply capacity demand and, even cases, congestionnetwork (e.g., locational marginal pricing approaches pricing electricity differentpoints grid see Harris, 2005). Unfortunately, Schweppe et al.s solution neverfully implemented large scale time proposed. numberreasons. First, properties solution mainly proven analytically,general assumption agents behave similar fashion attemptmodel strategic choices agents may make charging batteries (e.g., alwayscharging times predict cheaper always using batterypredict prices higher charging battery early whole days consumptionavoid price peaks later). Instead, paper, develop game-theoretic frameworkfully captures agents strategic behaviour within context smart gridcomplement approach simulations order evaluate performancesystem highly heterogeneous population agents. Second, Schweppe et al.s designalso came problems associated high communication costs lackautonomous storage management technology. However, recent advances computationalpower make deployment autonomous agents entirely feasible, new information communication technologies wireless broadband internet home energymanagement systems (e.g., AlertMe4 Intels Home energy dashboard5 ) mean realtime pricing domestic sector looks closer realised. Moreover, financialcommitment countries UK (8.6M invested smart metering infrastructuresee DECC, 2009) US (with 57.9 million smart meters planned installation6 )implementation smart metering infrastructure, provides unprecedented supportimplementation RTP.Real-world trials, GridWise alliance US (Hammerstrom et al.,2008) Energy Demand Research Project UK (Smith, 2010), theoreticalwork Ramchurn, Vytelingum, Rogers, Jennings (2011a) showaccurate RTP signals (i.e., representing real costs opposed TOU pricingscheme) allow consumers reduce peak demand (and duration peaks)reacting frequently accurate 30-min-tariff pricing model (ratherpeak off-peak prices TOU). reducing peaks, consumersRTP make significant savings compared TOU pricing. However,generally case (short-duration) peaks exist RTP Fixed-Pricingmodel (see Ramchurn et al., 2011, two long-duration peaks exist morningevening), requiring usage expensive peaking plants short periods.agents predict (based previous days) low price next day4. http://www.alertme.com/.5. http://edc.intel.com/Applications/Energy-Solutions/Home-Energy-Management/.6. http://www.pikeresearch.com/newsroom/57-9-million-smart-meters-currently-planned-for-installation-in-the-united-states771fiVytelingum, Voice, Ramchurn, Rogers & Jennings0.6Power (kW)0.5Morning PeakEvening Peak0.40.30.20.10:00 3:006:009:0012:00 15:00 18:00 21:00 24:00Time DayFigure 1: Average load profile (weekday summer) UK half-hourly periods basedfixed pricing model.certain time, turn devices, results peak demandtime. mechanism rolled large scale, reactive behaviourscause unpredictable significant peaks (compared two predictable ones TOU)demand prices, which, turn, result higher costs individuals greater stressgrid resources (transmission lines reaching thermal limit generators reachingcapacity).Thus, properly managed, storage systems unprofitable consumersadversely impact whole system (Holland, 2009; Williams & Wright, 1991; Bathurst &Strbac, 2003). Hence, setting consider, important know whether microstorage individually beneficial strategies maximise consumers savings.also important understand system-wide effects strategies; particular,quantifying limits usefulness small scale storage grid efficiency pointview determining different types storage (with different costs efficiencies)integrated system. key open questions addressedpaper (see Sections 4 5 respectively).3. Model Descriptionalready noted, paper seek analyse behaviour impact microstorage devices large scale multi-agent systems point view. is, considersituation large numbers autonomous agents control energy storagehome, interact electricity suppliers within market, aim minimising772fiTheoretical Practical Foundations Agent-Based Micro-Storagecosts individual owners. setup allows us make number modellingassumptions, detail section. analysis considers fixed time intervalsconsisting single days, separated = 48 settlement periods half hour.day, agents consume electricity bought suppliers electricity market.market operates time interval day, variations demandtime met. agents autonomously control charging discharging behaviourstorage device order maximise users profit. describe processthoroughly Section 3.1. analysis, market modelled abstractly,following macro-model give details Section 3.2. order measureimpact behaviour energy storage agents wider context, employ numbermetrics grid efficiency described explained Section 3.3. tablenotation definitions used throughout paper, see Table 1.3.1 Agentsconsider set N consumers, A, define self-interested agents alwaysaim minimise individual costs. agent load profile7 !ai ={1, . . . , }, !ai amount electricity required agent for!time intervalday. aggregate load profile system givenaA !i = !i .consider load profile fixed different days (although practiceseasonal variations demand, high degree consistency day day).agent may also storage available it, capacity , efficiencyrunning costs . Here, cost represents ongoing storage costs (for example,battery devices expend energy heating use lose efficiencydepletion chemicals used them). incorporate fixed capitalinvestment stage, costs fixed, running costseffect storage profile profitable. However, fixed capitalinvestments important users decide whether purchase battery,include cost-benefit analysis Section 7. storage efficiency runningcost modelled c amount energy stored, c maydischarged storage cost c.order minimise costs, agent attempt strategise storage profile,bi I, I, bai = cai dai , cai = (bai )+ charging profiledai = (bai ) , discharging profile. Here, throughout paper, use notation()+ denote positive part, is, = (x)+ means = x x > 0, = 0 otherwise.Likewise use (x) denote (x)+ . definitions implicitly assume usercharge discharge storage device single time interval. However,model, prices fixed time interval, discount behaviournever profitable. agent a, feasible storage profile bai mustsatisfy Da bai C , Da maximum discharging rate storage device,7. assume consumers load inelastic and, thus, insensitive price changes. reality,would expect consumers load shows slight elasticity, i.e., consumer reduce demandprice increases likewise increase demand price decreases. However, demand elasticitydomestic consumers generally small, believe results presented paper still providegood guide behaviour real markets.773fiVytelingum, Voice, Ramchurn, Rogers & JenningsNotationNbaicaidai!aiqiaca0CaDaOiabicidi!iqiCOipip+p(), ()()+()LUHUrrUuU (, , )DefinitionNumber agents systemSet agents systemNumber time intervals daySet time intervalsNet charge/discharge storage device agent time periodAmount charged agent time periodAmount discharged agent time periodElectricity used agent time periodElectricity purchased agent time periodEfficiency storage device agentCapacity storage device agentStorage cost agentEnergy agent stored start dayMaximum (per interval) charge agentMaximum (per interval) discharge agentMaximum usable discharge agentNet charge/discharge agentsAmount charged agentsAmount discharged agentsTotal consumer load agentsTotal electricity purchased agentsTotal storage capacity populationHomogeneous storage device efficiencyHomogeneous storage costsMaximum total per interval chargeMaximum total per interval dischargeMaximum total useful dischargeSupply function wholesale marketPrice electricityCharging price pointDischarging price pointEquilibrium price functions time interval (see Definition 1)Positive partNegative partLow-end energy usersHigh-end energy usersAgents strategy adopt storageProbability agent type U {LU, HU } adopting strategy rPayoff agent type U {LU, HU }Table 1: Notation definitions.774fiTheoretical Practical Foundations Agent-Based Micro-StorageUK Wholesale Balancing Market Buy Price (GBP/MWh)250Price DemandMovingaverageUnit Price (GBP/MWh)20015010050022.533.5Total Demand (MW)44.54x 10Figure 2: Half-hourly UK wholesale real-time buy prices (in balancing market) plottedtotal demand August September 2009 illustrating correlationprice demand. dotted line represents average points.C , maximum charging rate. Since attempting model effectwidespread adoption micro-storage devices, assume !ai , C , Da smallcomparison !i (since considering electricity gridlarge number!consisting, net storageconsumers). denote totalstoragecapacity=aA!profile bi bi = aA bai . use qia = bai + !ai ,denote net quantity electricity purchased i, use qi = bi + !idenote net quantity electricity purchased usersaggregate! interval i. The!maximum charging discharging rates defined C = aA C = aA Da .also define maximum usable storage output Oi maximum amount storedelectricity whole population agents able discharge make usetime interval i. agents !use stored electricity satisfy energy needs,Oi = aA min(Da , !ai ) I, agent reasondischarge energy current load. situation mainly focuspaper. However, analysis present also applied case agentssell stored energy back grid, using feed-in tariff. assume agentssell stored energy current grid price, model remains same, exceptvalues Oi set equal D, I. satisfy load profileenergy charging needs, agent must purchase electricity available market,describe next subsection.775fiVytelingum, Voice, Ramchurn, Rogers & Jennings3.2 Macro-Model Electricity Marketorder widespread home energy storage effectively help reduce peak loads improve overall efficiency electricity market, must incentive userscharge storage devices demand low (or renewable energy generatorsrunning cheaply) discharge demand high (or expensive peakingplants used). discussed Section 2.3, TOU RTP pricing plans aim incentivise users optimise demand shifting low demand periods. particular,sending date pricing information, RTP allows electricity suppliers provide consumers prices accurately reflect current levels demand costs generatingelectricity. Hence, analysis, focus use RTP, note competition suppliers provide RTP pricing schemes allow future consumersbuy electricity close current market price (Schweppe, 1988). Although useRTP makes settlement process complex case Fixed TOU pricing(as independent reaction agents), requires interactiveintelligent energy management home, recent advances smart metering technologymeant RTP become plausible attractive possibility future smartelectricity grids (as discussed Section 2.2). Accordingly, assume agents buy electricityRTP scheme price electricity accurately represents market pricepower particular settlement period.end, consider macro-model electricity market abstractsactual market mechanism trading determines real-time price electricity.approach modelling supply side transmission system commonpower system economics literature significantly affect general trendsobserved analysing demand side (Kirschen & Strbac, 2004; Schweppe, 1988).model based observation aggregate demand electricity increases,unit price electricity also increase, since costly means generationmust used satisfy additional demand. example, Figure 2 shows half-hourUK real-time wholesale buy prices (in balancing market) August September2009 plotted aggregate demand.8 numerous anomalies due powerstation outages cause short term price increases, clear large rangedemand, increasing trend relationship unit cost electricitytotal aggregate demand, prices rising rapidly high demand.analysis effect price fluctuations system micro-storage leftfuture work.several countries around world, including UK US, electricity tradedwholesale residential, commercial industrial purposes forward markets (upseveral months advance) balancing market (in real-time). Within setup,role suppliers buy electricity generators wholesale market (e.g.,National Grid runs wholesale market UK PJM runs one eastcoast US) sell retail consumers. UK, retail market dominatedsix large suppliers retail 26 million residential consumers (representing around30% UK energy demand). Now, work, focus exclusively domesticconsumers since constitute significant portion overall energy consumption8. data available www.bmreports.com.776fiTheoretical Practical Foundations Agent-Based Micro-StorageUK. Yet, approach could readily extended commercialindustrial consumers. line main aim show deploymentmicro-storage within large heterogeneous population significant benefits. Thus,demonstrating flatten demand heterogeneous domestic populationimplies similar behaviour achievable across remaining 70%population (with even larger benefits). end, model domestic consumermarket pricing function reflects expected cost supplier (retailingelectricity consumers) would pay wholesale market. severaladvantages supplier aggregate demand fewer peaks domesticconsumers. Specifically, suppliers exposure peak (and typically volatile) wholesaleprices reduced benefit long-term baseload (i.e., long-term flat load)forward contracts (Voice, Vytelingum, Ramchurn, Rogers, & Jennings, 2011). Furthermore,peak load transmission distribution networks may curtailed, reducing needinfrastructure reinforcements, significantly, expensive peaking plant capacity(which may used hours day) also downsized.background, model, real-time price electricity per kWh(/kWh) specified price function s(q) = 0.04 + 0.20(q/0.6N ) qkWhtotal energy required N = |A| consumers half-hour time slot set4 model typical trend (i.e., monotonically rapidly increasing) wholesaledemand prices suppliers purchase electricity. Note longmodelled demand curve monotonically increasing reflect increasing unit costelectricity demand (which incentivises demand response), actual demand curvecritical work.Given function, retail price depends total amount electricity consumedagents, !i , net discharging charging agents storage devices, bi ,total amount electricity bought suppliers time interval qi = !i + bi ,market price given pi = s(qi ). Hence, agent pays pi (!ai + bai )total cost agents pi qi .3.3 Grid Performance Metricskey aim paper study effect storage overall system whetherglobal performance system improves agents adopt it. detail,measure performance considering following standard metrics electricity market(Harris, 2005):load factor (LF) average power divided peak power, periodtime:!iI qiLF =|I| maxiI qiselected period time (e.g., day). Ideally, LFmaximum 1 means aggregate load profile completely flat.LF < 1 suggests variations demand daily period. Hence, storagestrategies effective, LF converge 1 agents able utilisestorage shift consumption peak time periods low demand. LFmeasures aggregate load profile indicate individual777fiVytelingum, Voice, Ramchurn, Rogers & Jenningsagents contribute peaks system (e.g., agents consumingtime agents cause large peaks). better capture behavioursrely following measure, diversity factor.diversity factor (DF) ratio sum individual maximum demandsvarious consumers system maximum demand complete system:!maxiI qiaDF = aAmaxiI qiDF always greater equal 1 higher value, less correlatedpeak demands consumers are. Less correlated peaks result flat aggregateprofile (as peaks interposed), high DF implies users well diversifiedcause large aggregate peaks (by consuming time)system. hand, low DF indicates agents correlatedload profiles could result peaks demand. Now, LF describesaggregate demand, DF describes individual demands compareand, thus, DF give insights LF achieved (i.e.,individual profiles contributing aggregate profiles). example,high LF, high DF suggests well diversified profiles individual consumerpeaks spread across day low DF suggests flatter individual profiles.DF generally useful designing decentralised control mechanismsidentifies individual (rather aggregate) behaviours agents and,thus, potentially provides insights individual behaviour agentmodified.grid carbon intensity amount carbon dioxide emitted order deliverone unit electricity consumer. expressed grams CO2 per kWh and,ideally low possible (in order minimise greenhouse gas emission).carbon intensity UK grid half-hourly periods August September2009 shown Figure 3. market price electricity,clear correlation carbon intensity electricity grid,total demand grid. UK, due use coal-fired powerstations satisfy increasing demand, thus, well reducing total costelectricity consumer, expect use micro-storage reduce totalcarbon emissions reducing overall carbon intensity grid.note pricing model depends aggregate demand domesticsector. Thus, report load factor diversity factor results,domestic sector. However, reality, domestic sector one contributortotal electricity demand; UK, represents, previously mentioned, approximately 30% total demand, remaining 70% commercial industrialconsumption remains unchanged within model. demonstrate potentialdomestic micro-storage reduce UK carbon emissions electricity generation,present results regarding carbon emissions reductions, describe reductioncarbon emissions (as result micro-storage domestic sector) percentage778fiTheoretical Practical Foundations Agent-Based Micro-StorageUK Grid Carbon Intensity (gCO /kWh)25504502Carbon Intensity (gCO /kWh)500Carbon ContentBestFit (linear trend)40035030025020022.533.5Total Demand (MW)44.54x 10Figure 3: Half-hour UK grid carbon intensity plotted total demand AugustSeptember 2009 illustrating correlation carbon intensity demand.current carbon emission sources (i.e., domestic, commercial industrial), assuming micro-storage domestic sector change remaining 70% commercialindustrial daily profiles.4. Game-Theoretic Analysis Micro-Storageset stage application micro-storage smart grid, exploretheoretical underpinnings system. end, apply game-theoreticframework models given characterise resulting equilibria. equilibria important represent stable states systemagent unable increase profitability unilaterally changing strategy. particular, expect selfish agents maintain battery usage strategies maximallyprofitable them, thus, states predict arise naturallymarket prices stabilise. address question endow individual agentsintelligence reach stable equilibrium maximising owners savings laterpaper (see Section 5). now, ensure tractability assume agentshomogeneous efficiency running costs, = =. assumptions allow us obtain closed-formed solutions computingequilibria system, abstract real-world systems agents typically heterogeneous. However, one key achievements work, Section 6show assumptions result significant loss generality that, fact,779fiVytelingum, Voice, Ramchurn, Rogers & Jenningstheoretical results closely approximate empirical results obtain complexenvironments heterogeneous agents.Formally, game consider players coincide agents, A,game describes outcome single 24 hour interval. pay-off agent receives!equal minus total costs experiences purchasing electricity day,iI (pi (!ai + bai ) + cai ). strategy space available agent set feasiblestorage profiles, bai I. approximate space feasible aggregate storage profilesset aggregate profiles lie charging discharging limitstotal amount energy charged less equal total storage capacityavailable agents exactly equal total amount energy discharged dividedefficiency. formallyset! consider!!aggregate storage profiles biOi bi C,iI di =iI ciiI ci , storagecapacity (see Table 1 notation).Requiring total amount charged less total storage capacitystricter constraint simply requiring capacity never exceeded time.However, reasonable model storage capacity limitations day-long time period(given daily-cyclic nature demand), demand typically goes singlecycle low high low, implying storage devices would go corresponding cycle charging discharging charging. Indeed, practice, findequilibria simulations, indeed single charging discharging cycleprices cycle low high. Furthermore, equilibria reached experimentsclosely agree equilibria predicted section (see Subsection 6.3).also making approximation considering aggregate profilessatisfy aggregate capacity, charging discharging constraints. Even aggregateconstraints satisfied, necessarily mean exist feasible strategiesindividual agents give aggregate profile. give example, wouldpoor model agents values C , Da !ai singleagent possession majority storage capacity. consideringset aggregate profiles therefore assuming storage capacity distributedevenly amongst agents, roughly proportion loads charging dischargingcapacities. unreasonable given context situation modelling.proceed characterise competitive equilibria game.4.1 Competitive Equilibria Global Optimisersset competitive equilibria system corresponds set Nash equilibriaassumption individual negligible market power. is, assumeagents electricity consumption negligible effect price electricity,seek situations agent incentive change storage profilereduce cost. choose analyse equilibria capture steady statereal system consisting domestic users owning micro-storage (optimised agent)users consumption minimal effect electricity prices (in UK,user represents one home 26 million).Now, suppose agents chosen strategy profiles, let us consider effectfeasible change strategy one agent. is, agent considers change780fiTheoretical Practical Foundations Agent-Based Micro-StorageI, changing cai cai + cai dai dai + dai , giving net change baibai + bai bai = cai dai . change payoff agent would be:"#$#$s(qi ) s(qi + bai ) (!ai + bai ) + s(qi + bai )bai + cai .(1)iInoted previous section, since examining widespread micro-storage,assume A, !ai , C , Da small comparison !iqi . equivalent assuming agent negligible market power. Thus, s(qi +bai )close s(qi ) first term small. So, changepayoff agent would approximately:"#$s(qi )bai + cai .(2)iIequal dot product gradient times vector changes (c, d),following function, f (), 9 define as,%#$ "# qi$s(x)dx + ci .f {ci , di }aA,iI =(3)iI0Thus, condition agent incentive change strategy approximately equivalent saying A, directional derivative f () positivedirection change leads feasible storage profile. equivalent sayingvector storage profiles local minimum f () set feasible storage profiles. Since s() increasing, f () must convex, since feasible domainclosed convex, local minimums also global minimums domain. Thus,deterministic competitive equilibria game correspond vectors strategy profilesminimise f () set feasible strategy profiles.approximations typically well suited (i.e., result significant lossaccuracy) large systems consider (with millions agents)effect greatly reducing search competitive equilibrium complex multiplayer game relatively straightforward constrained optimisation problemminimising f (). proceed find solutions optimisation problem.4.2 Characterisation Competitive Equilibriacharacterise aggregate storage profiles form optimal solutionsconstrained optimisation problem given above. characterisation given mainresult, Theorem 1. However, theorem may seem somewhat unintuitive first.think equilibrium characterised two prices, p+ p (defined below).equilibrium strategy always charge much possible energy cheap,right point price reaches p+ , always discharge energy priceshigh, right fall p . Thus, interval i, equilibrium, pi < p+ ,agents must maximum charge rates pi > p , agents must9. real world counterpart f (), little intuition definition necessarilyequal total revenue, example. simply tool help characterise global equilibrium.781fiVytelingum, Voice, Ramchurn, Rogers & Jenningsmaximum output rates. If, equilibrium, pi lies strictly p+ p ,energy expensive worth charging, cheap make dischargingprofitable, storage activity occurs time interval.order formally state prove result, must begin definition:Definition 1. storage system described, interval i, let us definefunctions () () be,$#(p) = min C, (s1 (p) !i )+ ,#$(p) = min Oi , (s1 (p) !i ) .is, (p) amount electricity would charged intervali, discharging, order resulting price close p possible.Similarly, (p) amount electricity would discharged intervali, charging, order resulting price close p possible.Oi maximum useful discharge C, maximum daily total charge.define discharging price point, p , maximum unionsolutions to:""(p ) =(p ),iIsolutions to:iI"(p ) = ,iIexist. maximum exists s() continuous strictly increasing.p well defined, also define charging price point, p+ , p"(p ) < ,iIequal minimal solution to:"(p+ ) = ,iIexist, otherwise.!++well definediI (p ) =!Note, +p! p! either+p = piI (p ), iI (p ) = ,(p !) = . latter case, since p+!and iIstrictly greater solutions iI (p ) = iI (p ), since ()functions increasing () functions decreasing, must that:"""(p+ ) = =(p ) <(p ),iIiIiIp+ < p . intuitive understanding equilibrium given above,means that, p p+ chosen total amount discharged equaltotal amount charged times . Furthermore, restriction, either p p+chosen maximise total amount charged else total amount charged equal.782fiTheoretical Practical Foundations Agent-Based Micro-Storage!!Lemma 1. always exists solution iI (p) = iI!i (p). Furthermore,+ = p unlessppp maximal solution p =iI (p) > ,!+case, p maximal solution iI (p ) = , p minimal solution!+iI (p ) = .Proof. s() continuous, strictly increasing function, !i > 0 insiderange time interval i. Thus, p sufficiently small,s1 (p) < !i hence (p) strictly positive and, since p < p,(p ) zero. Likewise p sufficiently larges1 (p) > !i (p) strictly positive ((p + )/) zero. Sincefunctions ()!! decreasing () increasing i, conclude(p)iIiI (p ) continuous decreasing function p negativesufficiently small p and!positive sufficientlylarge p. implies existence!solution p iI (p) = iI (p ). Let p maximal solutionthis.!iI !(p) then, since () functions decreasing,$ > p$ = . Thus, p = p and, so, p+ = p = p .piI (p ) !!reachesiI (p) > then, sinceiI () decreasing function eventually!zero, must cross .!Thus, maximal value p iI (p ) =.since iI (p) > , must exist minimal value p+! Similarly,+iI (p ) = , required.!p maximum solution iI (p ) =!!Although specified< , worth noting two values piI (p ),!ifiI (p )!!!p$ satisfy iI (p) = iI (p ) iI (p$ ) = iI (p$), monotonicity sides equation,mustI,!! $that !$$(p) = (p ) (p) = (p ). Likewise, iI (p) = iI (p ) iI (p) =!$$$iI (p ) I, (p) = (p ) (p) = (p ) respectively. Indeed,observations mind, specifications maximal solutions chosen makesdifference main result, done simply p+ p well defined.state prove main result analysis.Theorem 1. storage system described, < 1 > 0 set competitiveequilibria system precisely set feasible agent strategies where, I,ci = (p+ ) di = (p ). case storage devices perfectly efficientcostless, ( = 1 = 0), set competitive equilibria system preciselyset feasible agent strategies where, I, bi = (p+ ) (p ).Proof. seek find aggregate storage profile, minimises f () where:#$f {ci , di }iI ="#%iI"i +ci di0$s(x)dx + ci .Since set feasible aggregate storage profiles closed bounded, mustleast one minimum f () domain. However, since domain convex,f () convex function, local minima convex set global minima.find optimal allocations, seek feasible aggregate storage profiles783fiVytelingum, Voice, Ramchurn, Rogers & Jenningsderivative f () non-negative every direction leads another feasible allocation.calculate I, f /ci = pi + f /di = pi . Thus remainscharacterise feasible profiles that:"(pi + )ci + pi di 0,iIevery vector small changes lead another feasible aggregate storage profile,is, c, {ci + ci , di + di }iI feasible.suppose storage profile, (c, d), locally minimises f ().time intervals i, j C > ci > 0 C > cj > 0, would feasible increaseci decrease cj equal quantity, (or vice versa), hence must pi = pj .deduce i, j, pi < pj , ci > 0 cj > 0, mustci = C. So, let p+ maximum pj time intervals j cj > 0, getintervals ci > 0, pi p+ , pi < p+ , ci must equal C. Similarly,show p minimum pj time intervals j dj > 0intervals di > 0, pi p , pi > p di = Oi .Furthermore, cannot i, j pi + > pj ci > 0 dj > 0,would feasible profitable decrease ci ci increase djdj = ci . Hence, must p+ + p . particular, p+ p ,inequality strict > 0 < 1, case, intervals oneci di non-zero.interval i, pi > p , di = Oi ci = 0, s1 (pi ) !i = Oithus, s1 (p ) !i < Oi s1 () increasing function. means bi = Oi =(p ). hand, pi = p bi = s1 (p ) !i = (p ). Likewise,interval i, pi < p+ , ci = C di = 0, s1 (pi ) !i = C(p+ ) = C = bi , pi = p+ bi = (p+ ), directly. pi lies strictly pp+ ci di must equal 0, s1 (pi ) !i = 0. Thus, s1 (p ) !i 0s1 (p+ ) !i 0, (p+ ) = (p ) = 0. results show prices,equilibrium must bi = (p+ ) (p ). stated above, < 1 > 0,time interval i, one ci di non-zero, so, case+ ) = (p ).specify,! ci = (p!!+ ) p+ + p , mustSince(p)=(piIiIiI (p )!!!iI ( p ) so, solution iI (p) = iI (p ) must satisfymonotonicity !sides equation.p,p p , !! Furthermore, for!+would iI (p) iI (p ), meaning iI(p)iI (p )!!sinceimplies p p+ . would also!mean that,! iI di= iI (p ) ,capacity!constraint, !must iI (p ) iI (p ). Similarly, must++also iI !(p )(p ).iI !!+iI (p ) < iI (p+ ). would also imply iI (p ) <! Now, suppose1 +iI (p ). Hence, would exist intervals i, j (p ) !i <s1 (p+ ) s1 (p ) !j > s1 (p ). However, would imply that, equilibriumstate, ci = di = 0, dj = cj = 0. Hence would pi < p+ pj > p , meaningpi + < pj would profitable increase ci ci increase djdj = ci . implies contradiction, since small enough change, would leadfeasible storage profile.784fiTheoretical Practical Foundations Agent-Based Micro-Storage!!!!Hence must iI (p+ ) = iI (p+ ) iI (p ) = iI (p ).However, since functions monotonic, must i, (p+ ) = (p+ )(p ) = (p ). Thus, equilibrium must satisfy conditions statementtheorem.Thus, exists least one minimiser f () feasible domain,minimiser f () must satisfy conditions given statement theorem. Furthermore, conditions given statement theorem sufficiently strictspecify f () precisely. Thus, feasible storage profile satisfies conditionsgiven statement theorem must minimise f () feasible domain,required.direct consequence theorem prior observations matterstorage capacity is, aggregate amount charged day bounded by:"(p ),iIp equal solution to:"iI(p) ="iI(p ).storage capacity greater amount, portionused equilibrium. Moreover, since characterise competitive equilibria globalminimisers aggregate costs, agents negligible market power, additionstorage capacity profitable total amount storage lessmaximal value. key result leads us predict given aggregate load profile,either consumers need buy storage optimal battery capacity buyconsumer bounded. particular, bound supportedempirical evaluation UK electricity market subsection populationrequired adopt storage minimise costs (see Section 6).4.3 Idealised Scenariosdetermined existence characterisation charging discharging pricepoints, investigate prices set context two idealisedscenarios micro-storage devices deployed grid large scale.aims identify properties system different parameters tend particularlimits (and understand broad system behaviour). intuitions impactexpressed following corollaries. consider situation agents sellelectricity back grid order simplify results obtain thus make clearerintuition trying provide. Similar results would hold case agentscannot sell, similar-shaped load profiles, storage capacities proportiondaily load.Corollary 1. agents allowed sell electricity back grid current price,if, agents A, C Da sufficiently large, i, p+ pi p .Furthermore, I, p+ < pi < p , bi = 0.785fiVytelingum, Voice, Ramchurn, Rogers & JenningsProof. If, let C Da equal , breaksmallness assumption, and, furthermore, I, well (p ) < Oi (p+ ) <C. i, either bi < 0, case 0 < (p ) < pi = p , else bi > 0,case 0 < (p+ ) < C pi = p+ , or, lastly, could bi = 0,occur (p+ ) = (p ), either p+ = pi = p (p+ ) = (p ) = 0p+ < pi < p . covers possible cases, required.Thus, charge discharge rates sufficiently high, could expect pricesalways lie within p+ p .Corollary 2. agents allowed sell electricity back grid current price,if, agents a, C Da sufficiently large, capacity sufficiently high,= 0 = 1, i, p+ = pi = p .Proof. sufficiently high, must equilibrium p+ = p ,p+ = p . result follows directly previous corollary.Hence, scenario, perfectly efficient, cost free, high capacity storage,would expect market prices time flatten single value.perfect storage capability would allow agents transport energy time intervaltime interval free charge. Thus, different suppliers different time intervalswould compete other, resulting convergence single market price.Even storage devices perfectly efficient, still price flattening effect,though mitigated fact agents would buy energydischarge, meaning would always require price difference chargingdischarging periods. Since prices direct function demand, inferlarge amounts storage effectively bound maximum minimum levelsdemand time period. Thus, expect addition large amountsstorage significant effect grid load factor, size effectdirectly related efficiency storage device. Hence, Section 6, studyimpact storage adoption grid (i.e., terms grid efficiency cost savingspopulation) determine impact micro-storage devices various levelssaturation micro-storage across population. so, however,next section, provide analysis proportion population expected adoptstorage devices (i.e., based individuals profits micro-storage). importantbecause, shown real-time price electricity flatten, aim showprices impact profitability buying micro-storage. analysishelpful determining viability micro-storage deployment projects.4.4 Storage Adoptionmodel shows available storage capacity charging (and discharging) ratesincrease, significant effect prices. Moreover, shows limitmuch storage capacity required, profitable increase capacityavailable storage limit. Finding limits useful applicationanalysis, gives indication level adoption likely occur givencost, efficiency charging discharging rates leading storage technology.786fiTheoretical Practical Foundations Agent-Based Micro-Storagereality, however, practical home users incrementally increasestorage capacity time find optimal level. likely scenariohome user buys storage device, buy enough cover usage requirements.Aggregate storage capacity increase time homes installdevices. Predicting number potential buyers micro-storage devices keyunderstanding (for market makers producers) whether demand large enoughtake advantage economies scale production micro-storage devices (ofhigh efficiency high capacity). respect, crucial study maximal levelstorage adoption batteries. is, percentage homes installelectricity storage devices longer profitable devices installed.consider case home users cannot sell electricity back grid (orneighbours). users sell stored electricity, would possibleusers could purchase extra capacity multiple storage devices way make money.However, devices likely manufactured energy needssingle home mind, analysis still gives useful guide many devicesprofitably deployed throughout populace.Corollary 3. Suppose model population agents subset agentsA$ homogeneous storage devices, |A$ | = |A|, < 1. Supposepopulation agents A$ homogeneous, aggregate load profileagents A$ !i storage devices sufficiently large maximal chargingdischarging rates capacities restrict storage profilesequilibrium. Then, equilibrium, individually profitable increases aggregate benefitagent \ A$ install storage device if:< maxiIp maximal solution to:$1 # 1(p) !i ,!i& #"#$+ "$ 'min !i , s1 (p) !i.s1 (p ) !i =iIiIProof. model scenario setting:Da = C = max !ai ,iI="!ai ,iIA$=== 0 \ A$ . agents A$ , valuesmaximal charging discharging rates capacities sufficiently largecorresponding constraints cannot tight equilibrium.Theorem 1, aggregate storage profile equilibrium be:&# 1$+$ '#(p ) !i min !i , s1 (p ) !iCaCa787fiVytelingum, Voice, Ramchurn, Rogers & Jenningsp maximal solution to:&"#$+ "$ '#s1 (p ) !i =.min !i , s1 (p ) !iiI(4)iIprofitable agent \ A$ get storage device additionstorage device increase total amount energy charged dischargedequilibrium. addition storage device lead increase totalamount energy charged, means profitable agent use storagedevice use it. Thus, agent must obtain profit device.addition storage device would lead increase total amountenergy charged, then, since amount charged is:&"$ '#,min !i , s1 (p ) !iiImeans addition storage device effect p . Hence,circumstance, addition storage device would effect aggregate storageprofile, collection storage profiles agents equilibrium would stillremain equilibrium new device added maximally profitable behaviouragent new device simply use it.I,$#!i < s1 (p ) !i ,then, since addition storage device strictly increase , previous value plonger satisfy (4) p , along total amount energy charged,increase. Otherwise, increasing effect (4), meaning p change,neither aggregate amount energy charged.Let p maximal solution to:& #"#$+ "$ 's1 (p ) !i =.min !i , s1 (p) !iiIiI#$!i < s1 (p ) !ithen, since, inspection p p , must have:#$!i < s1 (p) !i .i, p satisfies:"#iI#$!i s1 (p ) !is1 (p ) !i$+="#$s1 (p ) !i ,iIand, since !i > !i , p satisfies:& #"#$+ "$ '11,min !i , (p ) !i(p ) !i =iIiI788fiTheoretical Practical Foundations Agent-Based Micro-Storageso, p = p and:#$!i s1 (p) !i .Thus, condition additional storage device profitableI,$#!i < s1 (p) !irequired.corollary used give indication level adoption populationrequired see maximal aggregate cost savings use energy storage. Later,Sections 6.6 7, complement result empirical study system-widebenefits micro-storage adoption UK market (where agents use novel storagestrategies) points similar bound level storage adoption.4.5 Rationality Assumptionfar, main results (i.e., Theorem 1 Corollaries 1, 2, 3) give aggregatestorage behaviour game deterministic competitive equilibrium predictextent nature adoption storage devices population. useresults specify limits grid performance benefits market conditions (i.e.,levels adoption equilibrium price electricity) result adopting microstorage. actions selfish profit-motivated agents result stableaggregate behaviour, better outcomes described above.However, using game theory, made implicit assumptions, specificallyagents rational complete information market throughouttime period ability compute optimal strategy given information.reality, information available owning storage devices perfectagents different computational capabilities. Furthermore, even perfectinformation, might apparent automated agent strategies preferable.Instead, agents must adapt time, become aware changesmarket prices, learn storage strategies preferable. difficult problemguaranteed selfish learning behaviour converge. particular, agentsover-react perceived opportunities market, cycles price fluctuations could developstable outcome (as seen Subsection 6.2).looked analytical approach required complete information,next section, provide practical (informationally) decentralised approach addresses lack complete information. Specifically, describe novel adaptive storagestrategy dynamically adapts changes market prices, allowing selfish, profitmotivated agents individually maximise savings using private informationinformation observed market prices. scheme, agents learn changestorage profiles day closer perceived optimal strategy. Section 6,show provided adaptation fast, mechanism converges equilibrium predicted Theorem 1. Moreover, empirical results confirm boundsstorage capacity adoption storage predicted far. Altogether, results show assumptions made theoretical framework reasonable789fiVytelingum, Voice, Ramchurn, Rogers & Jenningsenough model heterogeneous populations agents and, therefore, frameworkgenerally applied large-scale micro-storage analysis.5. Adaptive Storage Strategysection, present novel adaptive strategy agent use decidestore energy use energy stored. Now, system convergetowards equilibrium, need avoid many agents charging batteriestime, turn resulting higher costs everyone. strategy achieveswould good candidate long shown converge equilibrium. Onepossible candidate would allow agents adapt storage profile solely using targetprofile (which would equilibrium profile case) provided supplier (similarexisting TOU pricing schemes which, rather poorly, incentivise charging off-peakhours discharging peak time). However, strategy would require optimisationcentre (i.e., supplier) solution would depend accurately supplierestimate combined charging discharging rate limits storage capacitiesagents storage devices across grid often needs so. Thus,prefer strategy require grid-wide knowledge adapt basedagents private information (i.e., information micro-storage devices)observed market information (i.e., real-time retail prices continuously changeresult changing demand due consumers using storage devices). Indeed, designdecentralised strategy describe detail.strategy based day-ahead best-response storage.10 marketprices unknown priori, calculate storage profile day-ahead basis,best-response predicted market prices (which observed posterioriaggregate demand market known). Now, agents adoptbest-response, resulting effect would simply peaks moving periods highdemand previously low demand empirically demonstrate Subsection6.2. peaks demand moved previously low-demand periods (as peaksmarket prices), agents end paying higher prices charge battery.Thus, agent plays best-response exposed changing peaks. mitigateexposure changes, need ensure agent gradually adapts storagetowards best-response storage instead reacting prices and, doing, avoidagents herding consume lowest predicted price point. section, firstdescribe calculate day-ahead best response storage profile and, second,describe learning mechanism, agent adapts storage.10. strategy unaffected use different time-scales (other day-ahead). performday-ahead optimisation case exists natural cycle consumption similar daysexploit generate load profile distributions simulations reduce number timesoptimisation algorithms run. real-world deployment, finer grained optimisation (atlevel half quarter hours) would probably appropriate agent re-optimises basedup-to-date intra-day half-hourly consumption market prices well current amountstored energy available.790fiTheoretical Practical Foundations Agent-Based Micro-Storage5.1 Day-Ahead Best-Response Storageobjective agent minimise costs storing energy prices lowusing energy prices high.market prices unknown! Now,aggregated load consumers aA !i = !i known, agent needs decidestorage profiles based prediction market prices. Note work,assume market prices move significantly similar days (e.g.,season, weekdays tend similar different week ends) useweighted moving average predict future market prices.11compute storage profile, bai = cai dai every time-slot daysolution optimisation problem (expressed linear program) minimisefollowing cost function given decision variables cai , dai , (representing storagecapacity):12()"(5)arg minpi (cai dai + !ai ) + caibiIsubject following constraints:Constraint 1: Energy conservation"dai =iI"caiiIConstraint 2: Within charging discharging rate limitsdai Da cai CConstraint 3: Energy stored used time-slot&&''!dadai ca0 + i1cjjj=1&''&!cai ca0 + i1j=1 cj djConstraint 4: reselling allowed!ai dai 0last constraint removed system consumers allowed sell powergrid. Note capacity storage known, constrainedneed find , left unconstrained optimisation&calculated 'maximum energy stored (in optimised storage profile), i.e.,!imaxiI c0 + j=1 bj .11. demonstrate later on, central work price movements generallysmall. However, number sophisticated prediction algorithms, regression Gaussianprocesses, could used instead better predictions price movements significant resultvolatile market.12. used IBM ILOG CPLEX 12 implement solve linear program.791fiVytelingum, Voice, Ramchurn, Rogers & Jenningsdescribed earlier, cost using storage set smallwish find best response regardless external factor coststorage. efficiency storage device, C maximum charging rate, Damaximum discharging rate ca0 amount energy stored beginningday equal stored energy end day. next consideragent adapts storage based best-response.5.2 Learning Marketmarket prices move day, agent needs continuously adapt storageprofile reflect changes. One may expect micro-storage incrementally rolledout, agents would able gradually adapt stabilise market prices. However,empirically demonstrate Subsection 6.2, system becomes unstablemany agents attempt optimise time, even use best responseincrementally acquire micro-storage devices. Now, relatively high coststorage (compared savings energy cost see Section 7) assuming effectmicro-storage system change market prices significantly (such optimalcapacity agent requires changing predicted results Section 4.2),necessary agent gradually change much absolute storage capacityactually uses. end, based intuitions drawn analytical resultspoint bound capacity required adaptation charging profiles pricesdifferent times day, develop learning mechanism based Widrow-Hofflearning rule (i.e., gradient descent approach)13 adapts storage profilecapacity micro-storage device used respect changes marketprices.learning mechanism based two-pass approach adapt storage capacityprofile. Initially, agent computes optimal storage capacity requiredminimise costs. precisely, cost-minimising capacity settingunconstrained variable optimisation (see Equation (5)). Now, constitutes desiredcapacity towards agent adapts utilised storage capacity. is, changesstorage capacity uses progressively follow changing trend market prices.actual storage capacity used agent defined Equation (6) (t)follows desired storage capacity that:(t + 1) = (t) + 1 ( (t))(6)(0) = 0 default 1 learning rate storage capacity agenta.14 Given storage capacity, agent computes optimal storage profilefollowing day fixing (t + 1) Equation (5).second pass, given current storage profile, agent adapts storage profilefollows:13. used Widrow-Hoff rule directly engineered optimisation algorithm,relatively minor changes, learning rules (such reinforcement learning Bayesian learning) couldused.14. empirically demonstrate Section 6, choice learning rates determines evolutionary stability system reasonably small ensure convergence.792fiTheoretical Practical Foundations Agent-Based Micro-Storagebai (t + 1) = bai (t) + 2 (ia bai (t))(7)desired storage profile given optimal storage profile subject fixedstorage capacity (t + 1) 2 (0, 1] learning rate strategy. Noteanalyse detail sensitivity learning parameters 1 2 partempirical study system next section.6. Empirical Analysis Micro-Storage UK MarketBased adaptive storage strategies defined previous section, analysismicro-storage present section aims complement theoretical partpaper assumed largely homogeneous population agents (see Section 4). particular, evaluate emergent properties large populations 1000 agents15owning micro-storage different charging discharging rates sizes usinglearning strategy adapt storage profile 500 simulation days 200 runs.beginning simulation day, agent makes prediction load profilemarket prices (using historical data) across 48 time-slots compute bestresponse day-ahead basis. end simulation day, actual market pricescomputed total domestic market demand (i.e., aggregate load storageprofiles) based market macro-model described Subsection 3.2 publishedagents posteriori. frame results within real-world context, simulationsfocus UK electricity grid.16Thus, given macro-model UK electricity retail market (see Section 3.2),initialise individual consumers typical UK load profiles.17 Moreover, learning ratesagents (presented Sections 5.1 5.2), well charging dischargingrates, normally distributed around means drawn charging (and discharging) ratescurrent technologies (see Section 2).18 done represent heterogeneous consumersdifferent types storage devices address realistic scenariogame-theoretic analysis.Given setup, benchmarking purposes first compute competitive equilibrium predicted game-theoretic framework (which assumes complete information15. simulation could readily extended hundreds thousands agents given distributednature computation. Now, given that, average, agents tend similar load profiles,assume 1000 different clusters load profiles among domestic consumerssimulation 1000 agents (rather millions) valid. observed real dataassumption heterogeneity UK domestic population reasonable.16. Note choose UK typical deregulated market. approach nonetheless general enoughframework applied markets, including industrial commercial markets (asopposed residential case consider) well micro-grids national grid countriesbased macro-model electricity market. Thus, results insights presented paperbroadly generalise.17. profile agent based normal distribution mean !mean taken UK, ), !ai 0 = 0.2 approximateaverage profile. formally defined !ai N (!meantypical spiky daily profiles consumers.18. experiments except analyse effect learning rates, draw values learningrates normal distribution N (0.05, 0.02). experimentation, found resultgood system-wide performance (see Section 6.5) small system slow converge.793fiVytelingum, Voice, Ramchurn, Rogers & Jenningsagents load profiles battery capacities) UK electricity grid. Second,study system breaks (in terms average individual costs gridperformance metrics defined Section 3.3) agents gradually adopt storageadaptive mechanism. comparison motivates need adaptive mechanism,and, results, empirically demonstrate market indeed convergecompetitive equilibrium population agents adopt adaptive storagemechanism. Third, perform sensitivity analysis convergence propertiesadaptive mechanism respect learning rates understand impact differentlearning rates cost savings grid performance parametersset. Fourth, evaluate robustness approach agents micro-storageadopt learning mechanism. Finally, evaluate impact different degreessaturation micro-storage (using agent-based micro-storage management)efficiency grid and, doing, study performance grid (see Subsection3.3) consumers adopt technology.6.1 Game-Theoretic SolutionGiven game-theoretic framework outlined Section 4, first calculate competitiveequilibrium based average domestic consumption profile consumer (from UK)using procedure described Subsection 4.2 (i.e., devices perfectly efficientcostless). resulting storage profile shown Figure 4. clearequilibrium behaviour consumer charge off-peak hours (at night) usestored energy peak hours (after working hours) consumers load highest.Furthermore, observed Figure 4, equilibrium, optimised load profile (i.e.,sum aggregate unoptimised load profile storage profile) flattened completelyload factor 1. implies agent-based micro-storage managementtheoretically reduce peaks completely completely efficient. Furthermore, storagecapacity required achieve equilibrium 2.3 kWh, computed maximumcumulative sum storage profile (as micro-storage device charges dischargestime-slot). next subsection, first demonstrate how, practice,system breaks completely without adaptive mechanism motivate needadaptive mechanism and, go show system indeed convergescompetitive equilibrium decentralised adaptive mechanism adopted.6.2 Market without Adaptive Mechanismanalyse market operates without adaptive mechanism, set populationagents playing best-response storage profile every day (i.e., using optimisationalgorithm defined Section 5.1). Moreover, simulate gradual adoption storagedevices consumers, rate adoption, r (i.e., probability r agentadopt storage keep storage device; r = 1 simulates system agentsstorage capabilities beginning). agent storage capability,optimise daily use best-response storage profile. setting, Figure 5(a) showsdeviation competitive equilibrium Figure 5(b) shows load factorgrid different values r. r = 1 (i.e., consumers adopt micro-storage794fiTheoretical Practical Foundations Agent-Based Micro-Storage0.60.5Power (KW)0.40.3Storage profile equilibriumAverage UK load profileLoad profile equilibrium0.20.100.10.20:00 2:305:007:30 10:00 12:30 15:00 17:30 20:00 22:30 24:00Time dayFigure 4: Storage profile load profile competitive equilibrium.devices time), system clearly deviates equilibrium loadfactor jumping immediately 0.66 (without micro-storage) 0.4 (with immediateadoption microstorage), suggesting larger peaks system. smaller values r,system converges beginning (as demand slowly decreases peak timeincreases off-peak time since small proportion agents change demand),break number simulation days ends larger peaks.smaller r is, longer system takes break down, though inevitably so.intuition behind invariably reaches point many agentsadopted micro-storage devices using best-response storage profile.many agents re-optimising storage profiles time, peaksmarket demand moved around aggregate demand profile flattened(inferred non-increasing load factor long-term). next subsection,show adaptive strategy helps remedy results desirable system-wideperformance.6.3 Market Adaptive MechanismHere, study convergence properties adaptive mechanism also showresults corroborate theoretical bound storage capacity suggested Section 4 (givenworst case scenario Subsection 6.2 r = 1). detail, given populationagents using adaptive mechanism 1 N (0.05, 0.02) 2 N (0.05, 0.02)(we show performance varies different learning rates next section),average storage profile found converge rapidly competitive equilibrium795fiMeansquared deviation equilibrium (logscale)Vytelingum, Voice, Ramchurn, Rogers & Jennings010110r=1.050100150r=0.01r=0.005200 250 300Simulation Daysr=0.001350400450500(a) Deviation population without adaptive storage competitive equilibrium.r=1.0r=0.01r=0.005r=0.0010.80.75Load Factor0.70.650.60.550.50.450.40.3550100150200 250 300Simulation Days350400450500(b) Load factor (LF) market adaptive mechanism.Figure 5: Convergence properties system adaptive storage.796fiTheoretical Practical Foundations Agent-Based Micro-Storagegame-theoretic analysis within less 20 simulation days (see Figure 6).19 expected,convergence results agents gradually adapting storage profilesaggregate market demand shifted peak off-peak.Meansquared deviation equilibrium (logscale)010110210310100200300Simulation days400500Figure 6: Convergence average storage profile competitive equilibriumagents adopt adaptive mechanism.system converges competitive equilibrium, also observe gridefficiency (as measured LF DF) improves gradually converges (see Figure7) agents adapt storage profiles system converges competitive equilibrium. detail, Figure 7, observe system LF increases 0.68converges around 0.93, suggesting considerably fewer peaks grid microstorage adopted, indeed, flattened demand.20 coupled DFclose 1 indicates (as discussed Section 3.3) that, even though agents closelycorrelated load profiles, overall, profiles tend reasonably flat.Furthermore, Figure 8, see average storage capacity requiredconverges around 2.3 kWh (which equals storage capacity prescribed analyticalsolution see Section 6.1) several simulation days. implies average19. Given weekdays homogeneous (as opposed Saturdays Sundays), agent learnacross weekdays system would converge within couple weeks.20. results simulation day averaged number simulations. Furthermore,simulation size 200 statistically significant, results figures given error bars95% confidence interval.797fiVytelingum, Voice, Ramchurn, Rogers & JenningsLoad Factor Diversity Factor1.110.90.80.7Load factorDiversity factor0.650100150200250300Simulation Days350400450500Figure 7: Efficiency grid system converges competitive equilibriumagents adopt adaptive mechanism.consumer may buy storage device capacity 3kWh (see maximum storage capacityFigure 8), agent would actually need 2.3kWh capacity minimise costs.6.4 Sensitivity Adaptive MechanismOne assumptions approach agents expected adopt adaptivemechanism. imposed feature smart meter controllingmicro-storage device, exceptionally case smart meter tampereduser programs ignore learning mechanism use bestresponse, i.e., agent always executes optimal behaviour. Thus, subsection,study effect system part population adopt proposedadaptive mechanism, assuming whole population storage capability.Figure 9, observe system particularly robust startsdegrading 60% population adopt adaptive mechanismdeliberately execute best response. proportion population playingbest response increases, load factor slightly increases 0.94 proportionpopulation reaches around 60% load factor rapidly decreases 0.4(suggesting large peaks system) agents adopt best response, i.e.,adaptive behaviour system. agents using best response,agents gradually adapting storage profiles (implicitly adapting impactformer agents best-response profile). system eventually breaks798fiTheoretical Practical Foundations Agent-Based Micro-Storage3.5Storage Capacity (kWh)32.521.510.5050100150200250300Simulation Days350400450500Figure 8: Average storage capacity required typical consumer system convergescompetitive equilibrium.many agents using best response adaptive mechanism. alsonotice small increase load factor result increased diversity among agents,emergent behaviour observe analysing load factor populationdifferent proportions storage capability (see Subsection 6.6 discussion).Note system remains robust upto 60% population saturation micro-storageeven without learning mechanism, mechanism ensures system breakproportion population, observe Subsection 6.6.6.5 Sensitivity Convergence Propertiesguarantee consistency results given different parameter settings, sectionexplore values learning rates21 1 2 affect convergence results.22doing, aim determine fast agent ideally adapt storage profilemaximise savings while, possible, helping improve efficiency grid.Figure 10(a) shows smaller learning rate, efficient system (withhigher load factor). intuition behind small learning rate allowsmarket prices change gradually. higher learning rate, hand, would result21. learning rates intrinsic adaptive mechanism, assume 1 2 sharevalue without loss generality interested fast mechanism adapts ratherspecifically two-part adaptation.22. mean load factors savings Day 400 Day 500 (by time system generallyconverged) recorded averaged 200 runs different learning rates.799fiVytelingum, Voice, Ramchurn, Rogers & Jennings10.9Load Factor0.80.70.60.50.40.300.20.40.60.81Proportion population storage switching bestresponseFigure 9: Grid efficiency consumer switch best-response.agents adopting optimal storage profile quickly rather gradually,clearly results poor savings poor system efficiency peaks cycling system.learning rate increases, load factor quickly decreases 0.59 agentsadopt best-response immediately. individual perspective, agent wouldtypically set learning parameter based savings. Figure 10(b), seethat, likewise, smaller learning parameter is, better average savings23individual agent.Now, infinitely small learning rate infeasible implies infinitelylong time reach equilibrium, trade-off required. Specifically, learningparameters sensitive small, value 0.05 reasonable givendecrease savings would negligible. mentioned Footnote 18, usevalue experiments.Given results, claim adaptive strategy sets benchmarklearning strategy system (i.e., base requirement strategy wouldconvergence). results mainly hold whole population owning storage,important see system performs storage gradually introducedpopulation. enable us identify optimal level adoption storagerequired order maximise grid efficiency. doing, also aim complementanalytical results (see Section 4.4) empirical evidence showing level adoptionstill profitable individual users acquire storage UK market.23. average saving consumer computed difference average costs (after systemconverged) system micro-storage (i.e., system converged) one without.800fiTheoretical Practical Foundations Agent-Based Micro-Storage10.950.9Load Factor0.850.80.750.70.650.60.550.500.20.40.6Learning rate0.810.81(a)0.1Savings agents storage0.0500.050.10.150.20.250.30.350.400.20.40.6Learning Rate(b)Figure 10: sensitivity learning rate, 1 = 2 , system terms (a)load factor (b) savings agents storage.801fiVytelingum, Voice, Ramchurn, Rogers & Jennings6.6 Grid Efficiency Incremental Micro-Storage Adoptionfollowing set experiments, investigate grid performance metrics carbonemission reductions (which one main aims work) achieved mechanismmicro-storage incrementally adopted.24 Figure 11, observe gridefficiency peaks 32% population (rather aggregate storage capacitypopulation 100%). suggests 32% population requiredstorage maximise grid efficiency. proportion increases 0,agents storage capability thus storage profiles adapted flattendemand. aggregate storage profile gradually flattens aggregate load profileload factor increases diversity factor (since agentsstorage profile and, thus, adapted demand profile). Eventually, load factor peaks32%, point, system flattened much could be. agentsacquire storage devices, diversity factor decreases 1 agents use storage,finally settles 1, where, average, (flatter) load profile storageprofile. Furthermore, agents optimising time, load factor alsodecreases slightly many agents trying optimise adapt storageprofiles time. Specifically, agents optimising surplus storage capacityrequired flatten demand grid. seen, diversity factordecreases suggests optimising surplus storage increases correlation amongindividual demand profiles. increased correlation suggests small peakload profiles impact which, average, decreases load factor.Figure 12, also observe significant benefit storage macro-level (i.e.,ignoring individual benefits agents study next section)sufficient proportion (32%) population adopt storage, carbon emissionselectricity market would decrease appreciably peak demands reduced. Indeed,carbon emission UK reduced 7% (from 63 58.3 kilotonnesCO2 per day),25 reaching minimum domestic load factor maximised (sincereducing peaks demand effect reducing carbon intensity suppliedelectricity, turn, reduces total carbon emissions).7. Cost-Benefit Analysis Micro-Storagefar, studied efficiency grid achieved population storagegradually adopted. turn individual consumer principally drivenmuch profit achieve adopting micro-storage (at certain cost). particular,24. Note results describe (i.e., grid efficiency system converges) similargame-theoretic solution given system proportion population storagetranslates model smaller aggregate charging discharging limits see Section4.25. calculate carbon emissions considering reduction carbon intensity electricitysupply domestic load factor reduces (see Figure 3). consider total population 26M UKhouseholds scale results take account fact domestic consumers represent30% total UK demand (as discussed Section 3) remaining 70% consisting commercialindustrial profiles remain unchanged.802fiTheoretical Practical Foundations Agent-Based Micro-Storage1.8Load factorDiversity factorLoad Factor Diversity Factor1.61.41.210.832% population0.600.10.20.30.40.50.60.7Proportion population storage0.80.91Figure 11: Grid efficiency (i.e., load factor diversity factor) different proportions population using storage.Carbon Emissions (kilotonnes CO2 per day)6463626160595807% CO2 reduct ion0.20.40.60.8Proportion population storage1Figure 12: Total daily carbon emissions UK domestic sector different proportions population using storage.803fiVytelingum, Voice, Ramchurn, Rogers & Jenningsquestion wish address that: level adoption storage still profitableagents system?26 Hence, experiments, first assume cost storagevary proportion population storage record cost-savingsachieved parts population adopted micro-storage.results (see Figure 13), first observe agents micro-storage(i.e, close 0%), potential average savings agent close 14%.consumers adopt storage, average saving gradually decreases slightly less 8%(as market prices also flatten agents longer benefit differencelow off-peak prices high peak prices). Interestingly, also observe consumerswithout micro-storage also benefit use consumers. because,empirically demonstrated Section 6, adoption micro-storage flattens peaksdemand system and, thus, market prices. means cheaper electricitydomestic market and, indeed, consumers adopt micro-storage, savingsconsumers adopt it, also increase. reaches point 48%consumers adopt micro-storage savings consumers withouttechnology equal. percentage increases past 48%, savings consumersadopt micro-storage exceed consumers adopt it.consumers micro-storage trying optimise surplus storageargued Section 6.6. implication dynamic consumers incentivisedadopt micro-storage 48% mark reached. point, incentiveconsumers deviate chosen behaviour (i.e., use micro-storage not).27Thus, long term, system converge equilibrium 48%population adopt micro-storage percentage, consumers expect saving9% individual electricity bills (which equates annual saving 60 perhousehold based average annual electricity bill 675). result also pointsslight misalignment optimal level storage grid (in terms gridefficiency) consumers (in terms savings). particular, given resultsprevious section (see Figure 11), note 48% level adoption equatesdomestic load factor 0.91, maximum load factor achievable (assuming controlproportion population adoption storage) 0.94 occurs 32% adoption.suggests proportion adoption system eventually settle at,system slightly suboptimal.next consider dynamic within realistic setting coststorage, typically startup cost hardware installation (e.g., wiring converter)cost actual battery. Based much storage capacity average consumerwould require maximise savings different proportions population, calculate savings minus cost storage (based typical battery costing 200 perkWh 600 per kWh respectively lifetime 10 years fixed startup cost200 both) assuming average cost electricity 675 consumer per26. Note that, respect average consumers savings, set experiments complementSection 6.5 studied cost-savings users learning rate varied.27. Note consumer aware savings without micro-storage computedbased initial load profile demand profile storage profile.804fiTheoretical Practical Foundations Agent-Based Micro-Storage0.14Savings without storageSavings storage (no cost storage)0.12Savings storage (Battery cost = 200/kWh startup cost = 200)Savings storage (Battery cost = 600/kWh startup cost = 200)Normalised Savings0.10.080.060.040.0210%000.148%23%0.20.30.40.50.60.7Proportion population storage0.80.91Figure 13: Savings without storage storage (for different costs storage).year.28 Note savings without storage change independentcost micro-storage. Given setup, results (see Figure 13) showclear first-mover advantage. Thus, maximum saving achieved proportion population micro-storage close zero (i.e., agentspopulation storage). However, storage capacity agents require relativelyhigh 4.5kWh, decreasing rapidly 2.3kWh consumers population adoptmicro-storage (see Figure 14). Moreover, based savings cost storagesavings without storage, observe equilibrium moves 23% cost storagedevice 200 per kWh 10% cost 600 per kWh (given startup cost200). Hence, combining latter results Figure 11, infergrid efficiency quickly drops cost storage increases (as level adoptiondecreases). Thus, cost storage significantly affect benefits derivedusers grid whole.results, however, consider populations agents drawn uniformlyUK average load profile. could therefore argued results may applycircumstances population uniformly distributed and, particular, usersconsume differing amounts energy making savings storage viableconsuming (as able shift energy across day recover highstartup cost system) others consuming less. Given this, next expand28. compare cost storage daily cost electricity calculating daily cost owningrunning storage device, i.e., cost storage device startup costs assume,spread lifetime storage device which, case, 10 years. battery costing200 per kWh 600 per kWh, startup costs 200 equals 1p 3p per kWh perday respectively, while, average, daily cost electricity 180p 8kWh daily electricityconsumption (see Subsection 2.1).805fiVytelingum, Voice, Ramchurn, Rogers & Jennings5Storage Capacity (kWh)4.543.532.5200.20.40.60.8Proportion population storage1Figure 14: Average storage capacity required different proportions populationstorage.cost-benefit analysis consider fundamental distinction users, namely lowend users (typically yearly consumption29 1650 kWh) high-end users (typicallyyearly consumption 4950 kWh). particular, want analyse dynamicsproportion low-end high-end users adopt storage (i.e., given numberagents type, proportion type adopt storage). aiminvestigate type consumers benefit system and, indeed,whether system efficient. end, adopt evolutionary gametheoretic approach suitable analyse dynamics, determine whethersystem eventually settles stable equilibrium behaviours (whetheradopt storage) change. next describe evolutionary game-theoretic frameworkand, thereon, provide cost-benefit analysis low-end high-end users.7.1 Evolutionary Game-Theoretic ModelHere, formulate problem game low-end users adopt mixedstrategy30 rLU (0, 1) (i.e., probability low-end users storage capability)motivated financial gains, high-end users adopt mixed strategy29. data drawn typical consumption data published British Gas UKwww.britishgas.co.uk. Furthermore, assume types consumers normalised daily average load profiles.30. assume agents type share mixed strategy given that, average,load storage profiles thus, expected savings.806fiTheoretical Practical Foundations Agent-Based Micro-StoragerHU (0, 1). analysing rLU rHU evolve payoffs change differentproportions population low-end high-end users storage, want studyproportion population using storage evolves. end, use classicalevolutionary game-theory (EGT) (Weibull, 1995) first compute heuristicaverage payoffs low-end high-end (based simulations) (whether usingusing storage) different mixed strategies rHU rLU , given respectively by:"uLU (r, LU , HU )rLUuLU ( LU , HU ) =rSuHU (LU,HU)="uHU (r, LU , HU )rHUrSuLU (r, LU , HU ) payoff low-end users adopting pure strategy r givenlow-end users mixed strategy LU high-end users mixed strategy LUuHU (r, LU , HU ) corresponding payoff high-end users.use results calculate replicator dynamics, LU HU ,describe dynamics population (i.e., proportions low-end high-endusers evolving), given by:rLU = [uLU (r, LU , HU ) uLU ( LU , HU )]rLU rkHU = [uHU (k, LU , HU ) uHU ( LU , HU )]kHU kLU , HU ), pointsFinally, test whether converges Nash equilibria (nashnashincentives either low-end high-end consumers deviate from.LUHU(nash, nash) = argminLU , HU+"&kS"&rSmax[uLU (r, LU , HU ) uLU ( LU , HU ), 0]max[uHU (k, LU , HU ) uHU ( LU , HU ), 0]'2'2next subsection provide results EGT analysis.7.2 EGT Analysis Micro-Storage Adoption Low- High-end Usersresults EGT analysis given Figure 15 different costs storage device(i.e., 0, 200, 400, 500, 1000 per kWh) assuming typical lifetime 10 yearsbattery startup cost 200. Thus, observe storage completelysubsidised (i.e., cost storage 0), range Nash equilibria (along straightline ( LU = 0.4, HU = 1.0) ( LU = 0.7, HU = 0)). Furthermore, Figure 16,observe Nash equilibria, grid efficiency system high(the load factor higher 0.9).Now, startup cost increases 200 per kWh, single Nash equiLU = 0.07, HU = 1) lower load factor 0.82 (see Figure 16).librium (nashnashimplies system eventually converges Nash equilibrium high-end consumers adopt storage 7% low-end users so. high-endusers overall make savings (than low-end users) cover daily cost storage807fiVytelingum, Voice, Ramchurn, Rogers & Jenningshigh startup costs. However, cost storage device increases 200 perkWh, storage becomes expensive low-end users, Nash equilibriumLU = 0, HU = 1), still economically beneficial high-end users.(nashnashincreasing cost, storage gradually becomes expensive even high-end users,LU , HU ) (0,0.94) (0,0.55)seen change Nash equilibrium (nashnashcost storage device 400 per kWh (0,0.37) cost storagedevice 500 per kWh. Eventually, cost storage device high evenLU = 0, HU = 0).high-end users 1000 per kWh, Nash equilibrium (nashnashconsidering change Nash equilibria cost storage device increases,also observe Figure 16 domestic load factor decreases gradually 0.68micro-storage impact grid, expensive adopted.analysis, gather improve grid efficiency maximise impact microstorage grid, cost storage sufficiently small, subsidising storagewould help improve efficiency grid.8. Conclusionspaper, set explore theoretical practical foundations agentbased micro-storage implementation smart grid. achieve objectives,first developed game-theoretic framework analyse strategic choices agentsmake using micro-storage devices grid. framework allows one predictcompetitive equilibrium system, particular, specify theoretical boundslevel micro-storage adoption capacity micro-storage adoptedlargely homogeneous population.Building upon intuitions generated theoretical results, wentdevise novel micro-storage strategy allows agent optimise storage profilestorage capacity order maximise owners savings. Furthermore, providedadaptive mechanism based predicted market prices allowed agent changestrategy response changing market prices. empirical evaluation mechanismUK electricity grid shown cause average storage profile convergetheoretical competitive equilibrium. point, peak demands reduced, reducingrequirements costly carbon-intensive generation plants. Moreover,analysis grid efficiency equilibrium show that, stable, resultsreduced costs carbon emissions. also shows objective buying storagesave electricity bills generally aligned maximising grid efficiency (i.e.,flattening peaks demand). particular, show that, without burdencost (e.g., storage completely subsidised), population would adopt storageequilibrium 48% population adopting storage reached achievedhigh level domestic load factor (i.e. 0.91). Given this, analysed systemrealistic setting empirically demonstrated costs storagesufficiently low, system converge equilibrium high grid efficiency,costs simply high, incentives even high-end electricityusers adopt micro-storage.808fiBattery cost = 0/kWh startup cost = 20010.80.80.60.6pHUBattery cost = 0/kWh startup cost = 01pHUTheoretical Practical Foundations Agent-Based Micro-Storage0.40.40.20.2000.5p001LUBattery cost = 400/kWh startup cost = 20010.80.80.60.6pHU1pHU1LUBattery cost = 200/kWh startup cost = 2000.40.40.20.2000.5pLU001Battery cost = 500/kWh startup cost = 2000.5pLU1Battery cost = 1000/kWh startup cost = 20010.80.80.60.6pHU1pHU0.5p0.40.40.20.2000.5p001LU0.5p1LUFigure 15: Evolutionary game-theoretic analysis different costs storage. Linestrajectories representing evolution proportion low-end highend users adopting storage. black dots Nash equilibria.809fiVytelingum, Voice, Ramchurn, Rogers & Jennings10.90.90.80.70.85pHU0.60.50.80.40.750.30.20.70.1000.20.40.60.81pLUFigure 16: Load factor different proportions low-end high-end users adoptingstorage.general, theoretical practical results provide fertile ground researchagent-based techniques might applied manage demand smart grid.particular, demand-side management technologies (Hammerstrom et al., 2008), involve loads (e.g., washing machine dishwasher) users home automaticallyscheduled run certain times, present similar properties micro-storageallow energy moved around peak off-peak times order flatten demandreduce costs. Hence, applying similar framework strategies ours, couldexpect analogous theoretical results efficiency gains predicted deploymentstechnologies. Moreover, techniques could used predict demand wouldgenerally vary across day real-time pricing rolled different regions(populated different proportions low-end high-end users), could help betterprepare assets (e.g., spinning reserve strengthening transmission lines).generalise techniques further, intend integrate sophisticated modelselectricity market mechanism work order better capture price fluctuations occur real markets. theoretical analysis, turn stochasticprocesses, commonly used model volatility financial markets. Further,experiments extended generating prices drawing samples suitable distributions, existing data points, even developing simulations include marketclearing strategic bidding energy suppliers consumers. Accordingly, alsointend employ better forecasting models demand supply (e.g., using Gaussian processes regression techniques) predict prices optimisation model. Indeed,far assumed agents predict prices simply previous days pricesindividual settlement periods. shown Wellman, Reeves, Lochner, Vorobeychik810fiTheoretical Practical Foundations Agent-Based Micro-Storage(2004), agents perform significantly differently adopt different approachesprice prediction therefore, improve empirical analysis, interestingsee grid performance individual agents profits affected different agentsadopt different forecasting models. particular, important determinewidespread adoption micro-storage devices affect volatility wholesaleelectricity market.Furthermore, intend explore mechanisms ensure convergence towardsequilibrium. particular, point departure theory strategic behaviourfound Minority Game (Challet & Zhang, 1997), shares similaritiesproblem, using complex pricing mechanism consumers always playbest response (Voice et al., 2011) learning mechanism consumeragent would required. part work, also intend investigate marketefficiency different proportions population adopting micro-storage devices,whether decrease efficiency observed market saturated by-productadaptive mechanism could avoided.Finally, intend consider grid distribution network. peaks differentacross different nodes electricity network, storage capacity might requiredareas others. Thus, investigate whether agent-based micro-storagemanagement approach used flatten peaks locally within node electricitynetwork rather flattening aggregate demand profile grid.Acknowledgmentspaper extends previous work (Vytelingum, Voice, Ramchurn, Rogers, & Jennings,2010). extends game-theoretic framework consider levels micro-storage adoptionexpands empirical evaluation consider sensitivity convergence properties learning rate complex agent populations. work fundediDEaS project (http://www.ideasproject.info).ReferencesBathurst, G. N., & Strbac, G. (2003). Value combining energy storage windshort-term energy balancing markets. Electric Power Systems Research, 67 (1),18.Challet, D., & Zhang, Y. C. (1997). Emergence cooperation organizationevolutionary game. Physica A, Vol. 246(3-4), pp. 407418.Daryanian, B., Bohn, R., & Tabors, R. (1989). Optimal demand-side response electricityspot prices storage-type customers. IEEE Trans. Power Systems, 4 (3), 897903.DECC (2009). Smarter grids: opportunity. Tech. rep., Department EnergyClimate Change (DECC). http://www.decc.gov.uk.den Bossche, P. V., Vergels, F., Mierlo, J. V., Matheys, J., & Autenboer, W. V. (2006).Subat: assessment sustainable battery technology. Journal Power Sources,162 (2), 913 919.811fiVytelingum, Voice, Ramchurn, Rogers & JenningsExarchakos, L., Leach, M., & Exarchakos, G. (2009). Modelling electricity storage systemsmanagement influence demand-side management programmes. International Journal Energy Research, 33 (1), 6276.Galvin, R., & Yeager, K. (2008). Perfect Power: MicroGrid Revolution UnleashCleaner, Greener, Abundant Energy. McGraw-Hill Professional.Hammerstrom, D., et al. (2008). Pacific Northwest GridWise Testbed DemonstrationProjects; Part I. Olympic Peninsula Project. Tech. rep., PNNL-17167, Pacific Northwest National Laboratory (PNNL), Richland, WA (US).Harris, C. (2005). Electricity Markets: Pricing, Structures, Economics. Wiley.Holland, A. (2009). Welfare losses commodity storage games. Proceedings8th International Conference Autonomous Agents Multiagent Systems, pp.12531254, Budapest.Houwing, M., Negenborn, R. R., Heijnen, P. W., Schutter, B. D., & Hellendoorn, H. (2007).Least-cost model predictive control residential energy resources applyingchp. Power Tech, pp. 425430, London, UK.Jennings, N. R., Corera, J., Laresgoiti, I., Mamdani, E. H., Perriolat, F., Skarek, P., & Varga,L. Z. (1996). Using ARCHON develop real-world DAI applications electricitytransportation management particle accelerator control. IEEE Expert Systems,11 (6), 6088.Kirschen, D., & Strbac, G. (2004). Fundamentals power system economics. Wiley.Kok, K., & Venekamp, G. (2010). Market-based control decentralized power systems.Proceedings First International Workshop Agent Technology EnergySystems.Li, H., & Tesfatsion, L. (2009). Development open source software power marketresearch: AMES test bed. Journal Energy Markets, 2 (2), 111128.Lund, H., & Kempton, W. (2008). Integration renewable energy transportelectricity sectors V2G. Energy Policy, 36 (9), 35783587.Ramchurn, S., Vytelingum, P., Rogers, A., & Jennings, N. R. (2011a). Agent-based controldecentralised demand side management smart grid. ProceedingsTenth International Conference Autonomous Agents Multi-Agent Systems, pp.512.Ramchurn, S., Vytelingum, P., Rogers, A., & Jennings, N. R. (2011b). Agent-based homeostatic control green energy smart grid. ACM Trans. Intelligent SystemsTechnology, 2 (4).Ramchurn, S., Vytelingum, P., Rogers, A., & Jennings, N. R. (2011c). Putting smartssmart grid:a grand challenge artificial intelligence. CommunicationACM (to appear).Rogers, A., & Jennings, N. R. (2010). Intelligent agents smart grid. PerAda Magazine, 10.2417/2201005.003002.Schweppe, F., Tabors, R., Kirtley, J., Outhred, H., Pickel, F., & Cox, A. (1980). Homeostaticutility control. IEEE Trans. Power Apparatus Systems, 99 (3), 1151 1163.812fiTheoretical Practical Foundations Agent-Based Micro-StorageSchweppe, F. (1988). Spot pricing electricity. Kluwer academic publishers.Shibata, A., & Sato, K. (1999). Development vanadium redox flow battery electricitystorage. Power Engineering Journal, 13 (3), 130 135.Smith, K. (2010). Energy Demand Research Project - Fifth Progress Report. Tech. rep.,OFGEM, UK. http://www.ofgem.gov.uk/Pages/MoreInformation.aspx?docid\=19\&refer=sustainability/edrp.Sovacool, B. K., & Hirsh, R. F. (2009). Beyond batteries: examination benefitsbarriers plug-in hybrid electric vehicles (phevs) vehicle-to-grid (v2g)transition. Energy Policy, 37 (3), 1095 1103.Sun, J., & Tesfatsion, L. (2007). DC optimal power flow formulation solution usingQuadProgJ. ISU Economics Working Paper No. 06014.Swider, D. (2007). Compressed air energy storage electricity system significantwind power generation. IEEE trans. energy conversion, 22 (1), 95.US Department Energy (2003). Grid 2030: National Vision Electricitys Second100 Years.. http://www.oe.energy.gov/smartgrid.htm.van Dam, K. H., Houwing, M., & Bouwmans, I. (2008). Agent-based control distributedelectricity generation micro combined heat powercross-sectoral learningprocess infrastructure engineers. Computers & Chemical Engineering, 32 (1-2),205 217.Voice, T. D., Vytelingum, P., Ramchurn, S., Rogers, A., & Jennings, N. R. (2011). Decentralised control micro-storage smart grid. Proceedings 25thInternational Conference AI (AAAI).Vytelingum, P., Voice, T. D., Ramchurn, S., Rogers, A., & Jennings, N. R. (2010). Agentbased micro-storage management smart grid. Proceedings NinthInternational Conference Autonomous Agents Multi-Agent Systems, pp. 3946.Weibull, J. W. (1995). Evolutionary Game Theory. MIT Press, Cambridge, MA.Wellman, M., Reeves, D. M., Lochner, K. M., & Vorobeychik, Y. (2004). Price PredictionTrading Agent Competition. Journal Artificial Intelligence Research, 21, 1936.Williams, E. (1984). DINORWIG: Electric Mountain. Central Electricity GeneratingBoard.Williams, J., & Wright, B. (1991). Storage Commodity Markets. UIT, Cambridge.Ygge, F., Akkermans, J. M., Andersson, A., Krejic, M., & Boertjes, E. (1999). HOMEBOTS System Field Test: Multi-Commodity Market Predictive Power LoadManagement. Proceedings Fourth International Conference Practical Application Intelligent Agents Multi-Agent Technology, Vol. 1, pp. 363382.Ygge, F., & Akkermans, H. (1999). Decentralized markets versus central control: comparative study. Journal Artificial Intelligence Research, 11, 301333.813fiJournal Artificial Intelligence Research 42 (2011) 689-718Submitted 06/11; published 12/11Combining Evaluation Metrics via UnanimousImprovement Ratio Application Clustering TasksEnrique AmigoJulio Gonzaloenrique@lsi.uned.esjulio@lsi.uned.esUNED NLP & IR Group, Juan del Rosal 16Madrid 28040, SpainJavier Artilesjavier.artiles@qc.cuny.eduBlender Lab, Queens College (CUNY),65-30 Kissena Blvd, NY 11367, USAFelisa Verdejofelisa@lsi.uned.esUNED NLP & IR Group, Juan del Rosal 16Madrid 28040, SpainAbstractMany Artificial Intelligence tasks cannot evaluated single quality criterionsort weighted combination needed provide system rankings. problemweighted combination measures slight changes relative weights may producesubstantial changes system rankings. paper introduces Unanimous Improvement Ratio (UIR), measure complements standard metric combination criteria(such van Rijsbergens F-measure) indicates robust measured differenceschanges relative weights individual metrics. UIR meant elucidatewhether perceived difference two systems artifact individual metricsweighted.Besides discussing theoretical foundations UIR, paper presents empiricalresults confirm validity usefulness metric Text Clustering problem, tradeoff precision recall based metrics resultsparticularly sensitive weighting scheme used combine them. Remarkably,experiments show UIR used predictor well differencessystems measured given test bed also hold different test bed.1. IntroductionMany Artificial Intelligence tasks cannot evaluated single quality criterion,sort weighted combination needed provide system rankings. Many problems,instance, require considering Precision (P) Recall (R) compare systemsperformance. Perhaps common combining function F-measure (van Rijsbergen, 1974), includes parameter sets relative weight metrics;= 0.5, metrics relative weight F computes harmonic mean.problem weighted combination measures relative weights establishedintuitively given task, time slight change relative weights mayproduce substantial changes system rankings. reason behavioroverall improvement F often derives improvement one individualc2011AI Access Foundation. rights reserved.fiAmigo, Gonzalo, Artiles & Verdejometrics expense decrement other. instance, system improvessystem B precision loss recall, F may say better B viceversa,depending relative weight precision recall (i.e. value).situation common one might expect. Table 1 shows evaluation resultsdifferent tasks extracted ACL 2009 (Su et al., 2009) conference proceedings,P R combined using F-measure. paper consideredthree evaluation results: one maximizes F, presented best resultpaper, baseline, alternative method also considered. Notecases, top ranked system improves baseline according F-measure,cost decreasing one metrics. instance, case paper WordAlignment, average R grows 54.82 72.49, P decreases 72.76 69.19.paper Sentiment Analysis, P increases four points R decreases five points.reasonable assume contrastive system indeed improving baseline?evaluation results alternative approach also controversial: cases,alternative approach improves best system according one metric, improved according other. Therefore, depending relative metric weighting,alternative approach could considered better worse best scored system.conclusion parameter crucial comparing real systems.practice, however, authors set = 0.5 (equal weights precision recall)standard, agnostic choice requires justification. Thus, without notionmuch perceived difference systems depends relative weightsmetrics, interpretation results F combination schememisleading.goal is, therefore, find way estimating extent perceived differenceusing metric combination scheme F robust changes relativeweights assigned individual metric.paper propose novel measure, Unanimity Improvement Ratio (UIR),relies simple observation: system improves system B accordingindividual metrics (the improvement unanimous), better B weightingscheme. Given test collection n test cases, test cases improvementsunanimous, robust perceived difference (average difference Fcombination scheme) be.words, well statistical significance tests provide informationrobustness evaluation across test cases (Is perceived difference two systemsartifact set test cases used test collection? ), UIR meant provideinformation robustness evaluation across variations relative metricweightings (Is perceived difference two systems artifact relative metricweighting chosen evaluation metric? ).experiments clustering test collections show UIR contributes analysisevaluation results two ways:allows detect system improvements biased metric weightingscheme. cases, experimenters carefully justify particular choicerelative weights check whether results swapped vicinity.690fiCombining Evaluation Metrics via Unanimous Improvement RatioSystemsPrecision RecallFTask: Word alignment (Huang 2009)BaselineBM72.7654.82 62.53Max. FLink-Select69.1972.49 70.81Alternative72.6666.17 69.26Task: Opinion Question Answering (Li et al. 2009)BaselineSystem 310.921.617.2Max. FOpHit10.225.620.5AlternativeOpPageRank10.924.220Task: Sentiment Analysis (Kim et al 2009)BaselineBASELINE30.586.645.1Max. FVS-LSA-DTP34.971.947AlternativeVS PMI31.183.345.3Task: Lexical Reference Rule Extraction (Shnarch et al 2009)Baselineexpansion541928Max. FWordnet+Wiki473540Alternative rules + Dice filter493138Table 1: three-way system comparisons taken ACL 2009 Conference Proceedings (Su et al., 2009)increases substantially consistency evaluation results across datasets: resultsupported high Unanimous Improvement Ratio much likely holddifferent test collection. is, perhaps, relevant practical applicationUIR: predictor much result replicable across test collections.Although work presented paper applies research areas,focus clustering task one relevant examples clusteringtasks specially sensitive metric relative weightings. research goals are:1. investigate empirically whether clustering evaluation biased precisionrecall relative weights F. use one recent test collectionsfocused text clustering problem (Artiles, Gonzalo, & Sekine, 2009).2. introduce measure quantifies robustness evaluation results acrossmetric combining criteria, leads us propose UIR measure, derivedConjoint Measurement Theory (Luce & Tukey, 1964).3. analyze empirically UIR F-measure complement other.4. illustrate application UIR comparing systems context sharedtask, measure UIR serves predictor consistency evaluationresults across different test collections.691fiAmigo, Gonzalo, Artiles & VerdejoFigure 1: Evaluation results semantic labeling CoNLL 20042. Combining Functions Evaluation Metricssection briefly review different metrics combination criteria. presentrationale behind metric weighting approach well effects systems ranking.2.1 F-measurefrequent way combining two evaluation metrics F-measure (van Rijsbergen, 1974). originally proposed evaluation Information Retrieval systems(IR), use expanded many tasks. Given two metrics P R (e.g.precision recall, Purity Inverse Purity, etc.), van Rijsbergens F-measure combinessingle measure efficiency follows:F (R, P ) =( P1 )1+ (1 )( R1 )F assumes value set particular evaluation scenario. parameterrepresents relative weight metrics. cases value crucial;particular, metrics correlated. instance, Figure 1 shows precisionrecall levels obtained CoNLL-2004 shared task evaluating Semantic Role Labelingsystems (Carreras & Marquez, 2004). Except one system, every substantial improvementprecision involves also increase recall. case, relative metric weightingsubstantially modify system ranking.cases metrics completely correlated, Decreasing Marginal Effectiveness property (van Rijsbergen, 1974) ensures certain robustness across values. Fsatisfies property, states large decrease one metric cannot compensated large increase metric. Therefore, systems low precisionrecall obtain low F-values value. discussed detail Section 5.1. However, show Section 3.4, cases Decreasing Marginal692fiCombining Evaluation Metrics via Unanimous Improvement RatioEffectiveness property prevent F-measure overly sensitive smallchanges value.Figure 2: example two systems evaluated break-even point2.2 Precision Recall Break-even PointAnother way combining metrics consists evaluating system point onemetric equals (Tao Li & Zhu, 2006). method applicable systemrepresented trade-off metrics, instance, precision/recall curve.method relies idea increasing metrics implies necessarily overallquality increase. instance, assumes obtaining 0.4 precision recallpoint 0.4 better obtaining 0.3 precision recall point 0.3.Actually, break-even point assumes relevance metrics. considersprecision/recall point system distributes efforts equitablymetrics. Indeed, could change relative relevance metrics computingbreak-even point.Figure 2 illustrates idea. continuous curve represents trade-offprecision recall system S1. straight diagonal represents pointsmetrics return score. quality system corresponds thereforeintersection diagonal precision/recall curve. hand,discontinuous curve represents another system S2 achieves increase precisionlow recall levels cost decreasing precision high recall levels. Accordingbreak-even points, second system superior first one.However, could give relevance recall identifying point recall doublesprecision. case, would obtain intersection points Q01 Q02 shownfigure, reverses quality order systems. conclusion, break-evenpoint also assumes arbitrary relative relevance combined metrics.2.3 Area Precision/Recall Curveapproaches average scores every potential parameterization metric combining function. instance, Mean Average Precision (MAP) oriented IR systems,693fiAmigo, Gonzalo, Artiles & Verdejocomputes average precision across number recall levels. Another exampleReceiver Operating Characteristic (ROC) function used evaluate binary classifiers(Cormack & Lynam, 2005). ROC computes probability positive sample receivesconfidence score higher negative sample, independently threshold usedclassify samples. functions related area AUC existsprecision/recall curve (Cormack & Lynam, 2005).MAP ROC low high recall regions relative relevancecomputing area. Again, could change measures order assign differentweights high low recall levels. Indeed (Weng & Poon, 2008) weighted AreaCurve proposed. Something similar would happen average F across differentvalues.Note measures applied certain kinds problem, binaryclassification document retrieval, system output seen ranking,different cutoff points ranking give different precision/recall values.directly applicable, particular, clustering problem focus workhere.3. Combining Metrics Clustering Taskssection present metric combination experiments specific clustering task.results corroborate importance quantifying robustness systems across differentweighting schemes.3.1 Clustering TaskClustering (grouping similar items) applications wide range Artificial Intelligenceproblems. particular, context textual information access, clustering algorithmsemployed Information Retrieval (clustering text documents according contentsimilarity), document summarization (grouping pieces text order detect redundantinformation), topic tracking, opinion mining (e.g. grouping opinions specific topic),etc.scenarios, clustering distributions produced systems usually evaluatedaccording similarity manually produced gold standard (extrinsic evaluation).wide set metrics measure similarity (Amigo, Gonzalo, Artiles, &Verdejo, 2008), rely two quality dimensions: (i) extent itemscluster also belong group gold standard; (ii)extent items different clusters also belong different groups gold standard.wide set extrinsic metrics proposed: Entropy Class Entropy (Steinbach,Karypis, & Kumar, 2000; Ghosh, 2003), Purity Inverse Purity (Zhao & Karypis, 2001),precision recall Bcubed metrics (Bagga & Baldwin, 1998), metrics based countingpairs (Halkidi, Batistakis, & Vazirgiannis, 2001; Meila, 2003), etc.11. See work Amigo et al. (2008) detailed overview.694fiCombining Evaluation Metrics via Unanimous Improvement Ratio3.2 DatasetWePS (Web People Search) campaigns focused task disambiguating personnames Web search results. input systems ranked list web pages retrievedWeb search engine using person name query (e.g. John Smith).challenge correctly estimate number different people sharing namesearch results group documents referring individual. every personname, WePS datasets provide around 100 web pages top search results, usingquoted person name query. order provide different ambiguity scenarios, personnames sampled US Census, Wikipedia, listings Program Committeemembers Computer Science Conferences.Systems evaluated comparing output gold standard: manual groupingdocuments produced two human judges two rounds (first annotated corpusindependently discussed disagreements together). Note singledocument assigned one cluster: Amazon search results list,instance, may refer books written different authors name. WePStask is, therefore, overlapping clustering problem, general case clusteringitems restricted belong one single cluster. WePS datasetsofficial evaluation metrics reflect fact.experiments focused evaluation results obtained WePS-1(Artiles, Gonzalo, & Sekine, 2007) WePS-2 (Artiles et al., 2009) evaluation campaigns.WePS-1 corpus also includes data Web03 test bed (Mann, 2006),used trial purposes follows similar annotation guidelines, although numberdocument per ambiguous name variable. refer corpora WePS-1a(trial), WePS-1b WePS-2 2 .3.3 Thresholds Stopping Criteriaclustering task involves three main aspects determine systems output quality.first one method used measuring similarity documents; secondclustering algorithm (k-neighbors, Hierarchical Agglomerative Clustering, etc.);third aspect considered usually consists couple related variables fixed:similarity threshold two pages considered related stoppingcriterion determines clustering process stops and, consequently, numberclusters produced system.Figure 3 shows Purity Inverse Purity values change different clusteringstopping points, one systems evaluated WePS-1b corpus 3 . Purity focusesfrequency common category cluster (Amigo et al., 2008).C set clusters evaluated, L set categories (reference distribution)2. WePS datasets selected experiments (i) address relevant well-definedclustering task; (ii) use widespread: WePS datasets used hundreds experimentssince first WePS evaluation 2007; (iii) runs submitted participants WePS-1 WePS-2available us, essential experiment different evaluation measures. WePS datasetsfreely available http://nlp.uned.es/weps.3. system based bag words, TF/IDF word weighting, stopword removal, cosine distanceHierarchical Agglomerative Clustering algorithm.695fiAmigo, Gonzalo, Artiles & VerdejoN number clustered items, Purity computed taking weighted averagemaximal precision values:Purity =X |Ci |Nmaxj Precision(Ci , Lj )precision cluster Ci given category Lj defined as:|Ci Lj |Precision(Ci , Lj ) =|Ci |Purity penalizes noise cluster, reward grouping itemscategory together; simply make one cluster per item, reach triviallymaximum purity value. Inverse Purity focuses cluster maximum recallcategory. Inverse Purity defined as:Inverse Purity =X |Li |Nmaxj Precision(Li , Cj )Inverse Purity rewards grouping items together, penalize mixing itemsdifferent categories; reach maximum value Inverse purity making singlecluster items.change stopping point implies increase Purity cost decreaseInverse Purity, viceversa. Therefore, possible value F rewards different stoppingpoints. phenomenon produces high dependency clustering evaluation resultsmetric combining function.Figure 3: example trade-off Purity Inverse Purity optimizinggrouping threshold696fiCombining Evaluation Metrics via Unanimous Improvement Ratio3.4 Robustness Across ValuesDetermining appropriate value given scenario trivial. instance,users point view WePS task, easier discard irrelevant documentsgood cluster (because precision perfect high recall)check additional relevant documents clusters (because precision highrecall not). Therefore, seems Inverse Purity priority Purity,i.e., value 0.5. point view company providingweb people search service, however, situation quite different: priorityhigh precision, mixing profiles of, say, criminal doctor may resultcompany sued. perspective, receive high value.WePS campaign decided agnostic set neutral = 0.5 value.Table 2 shows resulting system ranking WePS-1b according F set 0.50.2. ranking includes two baseline systems: B1 consists grouping documentseparate cluster, B100 consists grouping documents one single cluster.B1 maximizes Purity, B100 maximizes Inverse Purity.B1 B100 may obtain high low F-measure depending value.table shows, = 0.5 B1 outperforms B100 also considerable number systems.reason result that, WePS-1b test set, many singleton clusters(people referred one web page). means default strategymaking one cluster per document achieve maximal Purity, alsoacceptable Inverse Purity (0.45). However, fixed 0.2, B1 goes bottomranking outperformed systems, including baseline B100 .Note outperforming trivial baseline system B1 crucial optimizesystems, given optimization cycle could otherwise lead baseline approach likeB1 . drawback B1 informative (the output dependinput) and, crucially, sensitive variations . words, performancerobust changes metric combination criterion. Remarkably, top scoringsystem, S1 , best values. primary motivation articlequantify robustness across values order complement information giventraditional system ranking.3.5 Robustness Across Test Bedsaverage size clusters gold standard may change one test bedanother. affects Purity Inverse Purity trade-off, clustering systemmay obtain different balance metrics different corpora; mayproduce contradictory evaluation results comparing systems across different corpora,even value.instance, WePS-1b test bed (Artiles et al., 2007), B1 substantially outperformsB100 (0.58 vs. 0.49 using F=0.5 ). WePS-2 data set (Artiles et al., 2009), however,B100 outperforms B1 (0.53 versus 0.34). reason singletons less commonWePS-2. words, comparison B100 B1 depends valueparticular distribution reference cluster sizes test bed.point system improvements robust across values (whichcase B1 B100 ) affected phenomenon. Therefore, estimating697fiAmigo, Gonzalo, Artiles & VerdejoF=0.5Ranked systems F resultS10.78S20.75S30.75S40.67S50.66S60.65S70.62B10.61S80.61S90.58S100.58S110.57S120.53S130.49S140.49S150.48B1000.4S160.4F0.2Ranked systemsS1S3S2S6S5S8S11S7S14S15S12S9S13S4S10B100S16B1F result0.830.780.770.760.730.730.710.670.660.660.650.640.630.620.60.580.560.49Table 2: WePS-1b system ranking according F=0.5 vs F=0.2 using Purity InversePurityrobustness system improvements changes prevent reaching contradictoryresults different test beds. Indeed, evidence presented Section 7.4. Proposalprimary motivation article quantify robustness across valuesorder complement information given traditional system rankings. endintroduce section Unanimous Improvement Ratio.4.1 Unanimous Improvementsproblem combining evaluation metrics closely related theory conjointmeasurement (see Section 5.1 detailed discussion). Van Rijsbergen (1974) arguedpossible determine empirically metric combining functionadequate context Information Retrieval evaluation. However, startingmeasurement theory principles, van Rijsbergen described set properties metriccombining function satisfy. set includes Independence axiom (also calledSingle Cancellation), Monotonicity property derives. Monotonicityproperty states quality system surpasses equals another one accordingmetrics necessarily equal better other. words, one system698fiCombining Evaluation Metrics via Unanimous Improvement Ratiobetter dependence whatsoever relative importancemetric set.define combination procedure metrics, Unanimous Improvement,based property:QX (a) QX (b) x X.Qx (a) Qx (b)QX (a) quality according set metrics X.relationship dependence metrics scaled weighted,degree correlation metric set. Equality (= ) derived directly :unanimous equality implies systems obtain score metrics:QX (a) = QX (b) (QX (a) QX (b)) (QX (b) QX (a))strict unanimous improvement implies one system improves strictlyleast one metric, improved according metric:QX (a) > QX (b) (QX (a) QX (b)) (QX (a) = QX (b))(QX (a) QX (b)) (QX (b) QX (a))Non comparability k also derived here: occurs metrics favor onesystem metrics favor other. refer cases metric-biasedimprovements.QX (a)k QX (b) (QX (a) QX (b)) (QX (b) QX (a))theoretical properties Unanimous Improvement described depthSection 5.2. important property Unanimous Improvementrelational structure depend relative metric weightings, satisfyingIndependence (Monotonicity) axiom. words, claim that: system improvement according metric combining function depend whatsoever metricweightings quality decrease according individual metric.theoretical justification assertion developed Section 5.2.1.4.2 Unanimous Improvement RatioAccording Unanimous Improvement, unique observable test casethree-valued function (unanimous improvement, equality biased improvement). need,however, way quantitatively comparing systems.Given two systems, b, Unanimous Improvement relationship settest cases , samples improves b (QX (a) QX (b)), samples b improves (QX (b) QX (a)) also samples biased improvements (QX (a)k QX (b)).refer sets Ta b , Tb Tak b , respectively. Unanimous Improvement Ratio (UIR) defined according three formal restrictions:699fiAmigo, Gonzalo, Artiles & VerdejoTest cases12345678910PrecisionSystem System B0.50.50.50.50.50.40.60.60.70.60.30.10.40.50.40.60.30.10.20.4RecallSystem System B0.50.50.20.20.20.20.40.30.50.40.50.40.50.60.50.60.50.60.50.3BYESYESYESYESYESYESBYESYESYESYESTable 3: Example experiment input compute UIR1. UIR(a, b) decrease number biased improvements (Tak b ).boundary condition samples biased improvements (Tak b = ),UIR(a, b) 0.2. improves b much b improves (Ta b = Tb ) UIR(a, b) = 0.3. Given fixed number biased improvements (Tak b ), UIR(a, b) proportionalTa b inversely proportional Tb .Given restrictions, propose following UIR definition:UIRX,T (a, b) =|Ta b | |Tb |=|T ||t /QX (a) QX (b)| |t /QX (b) QX (a)||T |alternatively formulated as:UIRX,T (a, b) = P(a b) P(b a)probabilities estimated frequentist manner.UIR range [1, 1] symmetric: UIRX,T (a, b) = UIRX,T (b, a).illustration UIR computed, consider experiment outcome Table 3. SystemsB compared terms precision recall 10 test cases. test case 5,instance, unanimous improvement B: better terms precision(0.7 > 0.6) recall (0.5 > 0.4). table, UIR value is:UIRX,T (A, B) =|TA B | |TB |64== 0.2 = UIRX,T (B, A)|T |10UIR two formal limitations. First, transitive (see Section 5.2). Therefore,possible define linear system ranking based UIR. is, however,700fiCombining Evaluation Metrics via Unanimous Improvement Rationecessary: UIR meant provide ranking, complement ranking providedF-measure (or metric combining function), indicating robust resultschanges . Section 6.4 illustrates UIR integrated insights providedsystem ranking.second limitation UIR consider improvement ranges; therefore,less sensitive F-measure. empirical results, however, show UIRsensitive enough discriminate robust improvements versus metric-biased improvements;Section 8 make empirical comparison non-parametric definition UIRparametric version, results make non-parametric definition preferable.5. Theoretical Foundationssection discuss theoretical foundations Unanimous Improvement Ratioframework Conjoint Measurement Theory. proceed describeformal properties UIR implications point view evaluationmethodology. Readers interested solely practical implications using UIR mayproceed directly Section 6.5.1 Conjoint Measurement Theoryproblem combining evaluation metrics closely related Conjoint Measurement Theory, independently discovered economist Debreu (1959)mathematical psychologist R. Duncan Luce statistician John Tukey (Luce & Tukey,1964). Theory Measurement defines necessary conditions state homomorphism empirical relational structure (e.g. John bigger Bill)numeric relational structure (Johns height 1.79 meters Bills height 1.56 meters).case Conjoint Measurement Theory, relational structure factoredtwo (or more) ordered substructures (e.g. height weight).context, numerical structures given evaluation metric scores (e.g.Purity Inverse Purity). However, empirical quality orderingclustering systems. Different human assessors could assign relevance PurityInverse Purity viceversa. Nevertheless, Conjoint Measurement Theory providemechanisms state kind numerical structures produce homomorphismassuming empirical structure satisfies certain axioms. Van Rijsbergen (1974) usedidea analyze problem combining evaluation metrics. axioms shapeadditive conjoint structure. (R, P ) quality system according two evaluationmetrics R P , axioms are:Connectedness: systems comparable other. Formally: (R, P )(R0 , P 0 ) (R0 , P 0 ) (R, P ).Transitivity: (R, P ) (R0 , P 0 ) (R0 , P 0 ) (R00 , P 00 ) implies (R, P ) (R00 , P 00 ).axioms Transitivity Connectedness shape weak order.Thomsen condition: (R1 , P3 ) (R3 , P2 ) (R3 , P1 ) (R2 , P3 ) imply (R1 , P1 )(R2 , P2 ) (where indicates equal effectiveness).701fiAmigo, Gonzalo, Artiles & VerdejoIndependence: two components contribute effects independently effectiveness. Formally, (R1 , P ) (R2 , P ) implies (R1 , P 0 ) (R2 , P 0 ) P 0 ,(R, P1 ) (R, P2 ) implies (R0 , P2 ) (R0 , P2 ) R0 . property impliesMonotonicity (Narens & Luce, 1986) states improvement metrics necessarily produces improvement according metric combining function.Restricted Solvability: property ... concerned continuitycomponent. makes precise intuitively would expect consideringexistence intermediate levels. Formally: whenever (R1 , P 0 ) (R, P ) (R2 , P 0 )exists R (R0 , P 0 ) = (R, P ).Essential Components: Variation one leaving constant gives variation effectiveness. exists R, R0 P case(R, P ) = (R0 , P ); exists P , P 0 R case(R, P ) = (R, P 0 ).Archimedean Property: merely ensures intervals componentcomparable.F-measure proposed van Rijsbergen (1974) arithmetic mean P,Rsatisfy axioms. According restrictions, indeed, unlimited set acceptable combining functions evaluation metrics defined. F relational structure,however, satisfies another property satisfied functionsarithmetic mean. property Decreasing Marginal Effectiveness. basic ideaincreasing one unit one metric decreasing one unit metricimprove overall quality (i.e. first metric weight combining function), imply great loss one metric compensated greatincrease other. defined as:R, P > 0, n > 0 ((P + n, R n) < (R, P ))According this, high values metrics required obtain high overallimprovement. makes measures observing property - F - robustarbitrary metric weightings.5.2 Formal Properties Unanimous ImprovementUnanimous Improvement x trivially satisfies desirable properties proposed van Rijsbergen (1974) metric combining functions: transitivity, independence,Thomsen condition, Restricted Solvability, Essential Components Decreasing MarginalEffectiveness; exception connectedness property4 . Given non comparability k (biased improvements, see Section 4.1) derived Unanimous Improvement, possible find system pairs neither QX (a) QX (b) QX (b) QX (a)hold. Therefore, Connectedness satisfied.Formally, limitation Unanimous Improvement representweak order, cannot satisfy Transitivity Connectedness simultaneously. Letus elaborate issue.4. sake simplicity, consider combination two metrics (R, P ).702fiCombining Evaluation Metrics via Unanimous Improvement RatioSystemsBCMetric x10.50.60.45Metric x20.50.40.45Table 4: counter sample Transitivity Unanimous Improvementcould satisfy Connectedness considering biased improvements representequivalent system pairs (= ). case, Transitivity would satisfied. See,instance, Table 4. According table:QX (B)k QX (A) QX (C)k QX (B)Therefore, considering k represents equivalence, have:QX (B) QX (A) QX (C) QX (B)QX (C) QX (A)summary, choose satisfy transitivity connectedness, both:Unanimous Improvement derive weak order.5.2.1 Uniqueness Unanimous ImprovementUnanimous Improvement interesting property contradictevaluation result given F-measure, regardless value used F:QX (a) QX (b) F (a) F (b)due fact F-measure (for value) satisfies monotonicityaxiom, Unanimous Improvement grounded. property essentialpurpose checking robustness system improvements across values.crucially, Unanimous Improvement function satisfies property.precisely, Unanimous Improvement relational structure that, satisfyingmonotonicity, contradict Additive Conjoint Structure (see Section 5.1).order prove assertion, need define concept compatibilityadditive conjoint structure. Let add additive conjoint structure let Rrelational structure. say R compatible conjoint structureif:ha, b, add i.(QX (a) R QX (b)) (QX (a) add QX (b))words: R holds, additive conjoint holds. want proveunanimous improvement relation satisfies property; therefore,prove R monotonic compatible relational structure,necessarily matches unanimous improvement definition:703fiAmigo, Gonzalo, Artiles & VerdejoR monotonic compatible = (QX (a) R QX (b) xi (a) xi (b)xi X)split in:(1) R monotonic compatible = (QX (a) R QX (b) xi (a) xi (b)xi X)(2) R monotonic compatible = (QX (a) R QX (b) xi (a) xi (b)xi X)Proving (1) immediate, since rightmost component corresponds monotonicity property definition. Let us prove (2) reductio ad absurdum, assumingexists relational structure that:(o monotonic compatible) (QX (a) QX (b)) (xi X.xi (a) < xi (b))case, could define additive conjoint structure combined measureQ0X (a) = 1 x1 (a)+..i xi (a)..+n xn (a) big enough Q0X (a) < Q0X (b).Q0 additive conjoint structure would contradict . Therefore, would compatible(contradiction). conclusion, predicate (2) true Unanimous Improvement Xmonotonic compatible relational structure.interesting corollary derived analysis. Unanimous Improvement compatible relational structure, formally concludemeasurement system improvements without dependence metric weighting schemesderive weak order (i.e. one satisfies transitivity connectedness).corollary practical implications: possible establish system rankingindependent metric weighting schemes.natural way proceed is, therefore, use unanimous improvement additionstandard F-measure (for suitable value) provides additional informationrobustness system improvements across values.6. F versus UIR: Empirical StudySection perform number empirical studies WePS corpora orderfind UIR behaves practice. First, focus number empirical resultsshow UIR rewards robustness across values, information complementary information provided F. Second, examine extent FUIR correlated.6.1 UIR: Rewarding RobustnessFigure 4 shows three examples system comparisons WePS-1b corpus using metricsPurity Inverse Purity. curve represents F value obtained one systemaccording different values. System S6 (black curves) compared S10, S9S11 (grey curves) three graphs. cases similar quality increaseaccording F=0.5 ; UIR, however, ranges 0.32 0.42, depending robustdifference changes . highest difference UIR (S6,S11) systempair (rightmost graph), systems swap F values value.704fiCombining Evaluation Metrics via Unanimous Improvement Ratio| 4 F=0.5 ||UIR|Improvements(28 system pairs)0.120.53cases(125 system pairs)0.130.14Table 5: UIR F=0.5 increase F increases valuesFigure 4: F-measure vs. UIR: rewarding robustnesssmallest UIR value (S6,S10), S6 better S10 values0.8, worse larger. comparison illustrates UIR captures, similarincrements F, ones less dependent relative weighting schemeprecision recall.Let us consider two-system combinations WePS-1b corpus, dividingtwo sets: (i) system pairs F increases values (i.e. PurityInverse Purity increases), (ii) pairs relative systems performance swapsvalue; i.e. F increases values decreases rest.One would expect average increase F larger system pairsone beats every value. Surprisingly, true: Table 5 showsaverage increments UIR F=0.5 sets. UIR behaves expected: averagevalue substantially larger set different lead contradictory results(0.53 vs. 0.14). average relative increase F=0.5 , however, similarsets (0.12 vs. 0.13).conclusion certain F=0.5 improvement range say anythingwhether Purity Inverse Purity simultaneously improved not.words: matter large measured improvement F is, still extremelydependent weighting individual metrics measurement.conclusion corroborated considering independently metrics (Purity Inverse Purity). According statistical significance improvementsindependent metrics, distinguish three cases:1. Opposite significant improvements: One metrics (Purity Inverse Purity)increases decreases, changes statistically significant.705fiAmigo, Gonzalo, Artiles & Verdejo| 4 F=0.5 ||UIR|Significantconcordantimprovements53 pairs0.110.42Significantoppositeimprovements89 pairs0.150.08Nonsignificantimprovements11 pairs0.050.027Table 6: UIR F=0.5 increases vs. statistical significance tests2. Concordant significant improvements: metrics improve significantly leastone improves significantly decrease significantly.3. Non-significant improvements: statistically significant differencessystems metric.use Wilcoxon test p < 0.05 detect statistical significance. Table 6shows average UIR | 4 F=0.5 | values three cases. Remarkably,F=0.5 average increase even larger opposite improvements set (0.15)concordant improvements set (0.11). According results, would seemF=0.5 rewards individual metric improvements obtained cost (smaller)decreases metric. UIR, hand, sharply different behavior,strongly rewarding concordant improvements set (0.42 versus 0.08).results confirm UIR provides essential information experimentaloutcome two-system comparisons, provided main evaluation metricF .6.2 Correlation F UIRfact UIR F offer different information outcome experimentimply UIR F orthogonal; fact, correlationvalues.Figure 5 represents F=0.5 differences UIR values possible system pairWePS-1 test bed. general trends (i) high UIR values imply positive differenceF (ii) high |4F0,.5 | values imply anything UIR values; (iii) low UIR seemimply anything |4F0,.5 | values. Overall, figure suggest triangle relationship,gives Pearson correlation 0.58.6.2.1 Reflecting improvement rangesconsistent difference two systems values, UIR rewardslarger improvement ranges. Let us illustrate behavior considering three sample systempairs taken WePS-1 test bed.Figure 6 represents F[0,1] values three system pairs. cases, one systemimproves values. However, UIR assigns higher values larger improvements F (larger distance black grey curves). reason706fiCombining Evaluation Metrics via Unanimous Improvement RatioFigure 5: |4F0,.5 | vs UIRFigure 6: F vs. UIR: reflecting improvement rangeslarger average improvement test cases makes less likely cases individual testcases (which ones UIR considers) contradict average result.Another interesting finding that, metrics improved, metricweakest improvement determines behavior UIR. Figure 7 illustratesrelationship ten system pairs largest improvement; Pearson correlationgraph 0.94. words, individual metrics improve, UIR sensitiveweakest improvement.6.2.2 Analysis boundary casesorder better understanding relationship UIR F,examine detail two cases system improvements UIR F produce drasticallydifferent results. two cases marked B Figure 5.point marked case Figure corresponds comparison systemsS1 S15 . exists substantial (and statistically significant) differencesystems according F=0.5 . However, UIR low value, i.e., improvementrobust changes according UIR.707fiAmigo, Gonzalo, Artiles & VerdejoFigure 7: Correlation UIR weakest single metric improvement.Figure 8: Purity Inverse Purity per test case, systems S1 S1 5visual explanation results seen Figure 8. shows PurityInverse Purity results systems S1 , S15 every test case. test cases, S1important advantage Purity cost slight consistent loss InversePurity. Given F=0.5 compares Purity Inverse Purity ranges, statesexists important statistically significant improvement S15 S1 . However,slight consistent decrease Inverse Purity affects UIR, decreasestest cases improvements F metric biased (k notation).Case B (see Figure 9) opposite example: small difference systemsS8 S12 according F=0.5 , differences Purity Inverse Purityalso small. S8, however, gives small consistent improvements Purity InversePurity (all test cases right vertical line figure); unanimousimprovements. Therefore, UIR considers exists robust overall improvementcase.708fiCombining Evaluation Metrics via Unanimous Improvement RatioFigure 9: Purity Inverse Purity per test case, systems S1 2 S8Again, cases show UIR gives additional valuable information comparative behavior systems.6.3 Significance Threshold UIRmentioned earlier UIR parallelism statistical significance tests,typically used Information Retrieval estimate probability p observeddifference two systems obtained chance, i.e., difference artifacttest collection rather true difference systems. computingstatistical significance, useful establish threshold allows binary decision;instance, result often said statistically significant p < 0.05, significantotherwise. Choosing level significance arbitrary, nevertheless helps reportingsummarizing significance tests. Stricter thresholds increase confidence test,run increased risk failing detect significant result.situation applies UIR: would like establish UIR thresholddecides whether observed difference reasonably robust changes . setthreshold? could restrictive decide, instance, improvementsignificantly robust UIR 0.75. condition, however, hard wouldnever satisfied practice, therefore UIR test would informative.hand, set permissive threshold satisfied systempairs and, again, informative. question whether existsthreshold UIR values obtaining UIR threshold guaranteesimprovement robust, and, time, strong satisfied practice.Given set two-system combinations UIR surpasses certain candidatethreshold, think desirable features:1. must able differentiate two types improvements (robust vs. nonrobust); words, one two types usually empty almost empty,threshold informative.709fiAmigo, Gonzalo, Artiles & Verdejo2. robust set contain high ratio two-system combinationsaverage F increases values (F (a) > F (b)).3. robust set contain high ratio significant concordant improvementslow ratio significant opposite improvements (see Section 6.1).4. robust set contain low ratio cases F contradicts UIR (the dotsFigure 5 region |4F0,.5 | < 0).Figure 10: Improvement detected across UIR thresholdsFigure 10 shows conditions met every threshold range [0, 0.8].UIR threshold 0.25 accepts around 30% system pairs, low (4%) ratiosignificant opposite improvements high (80%) ratio significant concordant improvements. threshold, half robust cases F increases values,cases (94%) F=0.5 increases. seems, therefore, UIR 0.25 reasonablethreshold, least clustering task. Note, however, rough rule thumbrevised/adjusted dealing clustering tasks WePS.6.4 UIR System Rankingsresults presented far focused pairwise system comparisons, accordingnature UIR. turn question use UIR componentanalysis results evaluation campaign.order answer question applied UIR results WePS-2evaluation campaign (Artiles et al., 2009). campaign, best runs systemranked according Bcubed precision recall metrics, combined F=0.5 .addition participant systems, three baseline approaches included ranking:710fiCombining Evaluation Metrics via Unanimous Improvement Ratiodocuments one cluster (B100 ), document one cluster (B1 ) union(BCOMB )5 .Table 7 shows results applying UIR WePS-2 participant systems. -robustimprovements represented third column (improved systems): every system,displays set systems improves UIR 0.25. fourth columnreference system, defined follows: given system a, reference systemone improves maximal UIR:Sref (a) = ArgmaxS (UIR(S, a))words, Sref (a) represents system replaced orderrobustly improve results across different values. Finally, last column (UIRreference system) displays UIR system reference (UIR(Sref , Si )).Note UIR adds new insights evaluation process. Let us highlight twointeresting facts:Although three top-scoring systems (S1, S2, S3) similar performanceterms F (0.82, 0.81 0.81), S1 consistently best system according UIR,reference 10 systems (S2, S4, S6, S8, S12, S13, S14, S15,S16 baseline B1 ). contrast, S2 reference S7 only, S3 referenceS11 only. Therefore, F UIR together strongly point towards S1 bestsystem, F alone able discern set three top-scoring systems.Although non-informative baseline B100 (all documents one cluster) betterfive systems according F, improvement robust according UIR.Note UIR signal near-baseline behaviors participant systems lowvalue, receive large F depending nature test collection:average cluster large small, systems tend cluster everythingnothing artificially rewarded. is, opinion, substantial improvementusing F alone.7. UIR Predictor Stability Results across Test Collectionscommon issue evaluating systems deal Natural Language resultsdifferent test collections often contradictory. particular case Text Clustering,factor contributes problem average size clusters vary acrossdifferent test beds, variability modifies optimal balance precisionrecall. system tends favor precision, creating small clusters, may goodresults dataset small average cluster size worse results test collectionlarger average cluster size.Therefore, apply F combine single metrics, reach contradictoryresults different test beds. UIR depend metric weighting criteria,hypothesis high UIR value ensures robustness evaluation results across test beds.5. See work Artiles et al. (2009) extended explanation.711fiAmigo, Gonzalo, Artiles & VerdejoSystemF0.5S1S2S3S4S5S6S7S8S9S10S11S12B100S130,820,810,810,720,710,710,700,700,630,630,570,530,530,520,520,420,410,390,340,33BCOMBS14S15S16B1S17Improved systems(UIR > 0.25)S2 S4 S6 S7 S8 S11..S17 B1S4 S6 S7 S8 S11..S17 B1S2 S4 S7 S8 S11..S17 B1S11 S13..S17S12..S16S4 S7 S11 S13..S17 B1S11 S13..S17S11..S17S4 S12 S14 S16S12..S16S14..S17S14 S16BCOMBS15 S16S16S17-ReferencesystemS1S1S1S2S1S3S1S1B100S1S1S1S1S6UIRreference system0,260,580,350,650,740,680,710,90,650,90,971,000,290,84Table 7: WePS-2 results Bcubed precision recall, F UIR measureswords: given particular test bed, high UIR value good predictorobserved difference two systems still hold test beds.following experiment designed verify hypothesis. implementedfour different systems WePS problem, based agglomerative clustering algorithm (HAC) used best systems WePS-2. system employscertain cluster linkage technique (complete link single link) certain feature extraction criterion (word bigrams unigrams). system experimented 20stopping criteria. Therefore, used 20x4 system variants overall. evaluatedsystems WePS-1a, WePS-1b WePS-2 corpora6 .first observation that, given system pairs, F=0.5 gives consistent resultsthree test beds 18% cases. system pairs, best systemdifferent depending test collection. robust evaluation criterion predict,given single test collection, whether results still hold collections.consider two alternative ways predicting observed difference (systembetter system B) one test-bed still hold three test beds:first using F (A) F (B): larger value reference test bed,likely F (A) F (B) still positive different test collection.6. WEPS-1a originally used training first WePS campaign, WePS-1b used testing.712fiCombining Evaluation Metrics via Unanimous Improvement Ratiosecond using U IR(A, B) instead F: larger UIR is, likelyF (A) F (B) also positive different test bed.summary, want compare F UIR predictors robust resultchange test collection. tested it:1. select reference corpus WePS-1a, WePS-1b WePS-2 test beds.Cref {WePS-1a,WePS-1b,WePS-2}2. system pair reference corpus, compute improvement onesystem respect according F UIR. take system pairsone improves certain threshold t. UIRC (s1 , s2 )UIR results systems s1 s2 test-bed C, FC (s) results Fsystem test-bed C:SU IR,t (C) = {(s1 , s2 )|UIRC (s1 , s2 ) > t}SF,t (C) = {s1 , s2 |(FC (s1 ) FC (s2 )) > t)}every threshold t, SU IR,t SF,t represent set robust improvementspredicted UIR F, respectively.3. Then, consider system pairs one improves according Fthree test collections simultaneously.= {s1 , s2 |FC (s1 ) > FC (s2 )C}gold standard compared predictions SU IR,t SF,t .4. every threshold t, compute precision recall UIR F predictions(SU IR,t (C) SF,t (C)) versus actual set robust results across collections(T ).P recision(SU IR,t (C)) =|SU IR,t (C) ||SU IR,t |P recision(SF,t (C)) =|SF,t (C) ||SF,t (C)|Recall(SU IR,t (C)) =Recall(SF,t (C)) =|SU IR,t (C) ||T ||SF,t (C) ||T |trace precision/recall curve predictors F, UIRcompare results. Figures 11, 12 13, show precision/recall values F (triangles)UIR (rhombi); figure displays results one reference test-beds: WEPS1a,WEPS-1b WePS-27 .Altogether, figures show UIR much effective F predictor.Note F suffers sudden drop performance low recall levels, suggests7. curve parametric UIR refers alternative definition UIR explained Section 8713fiAmigo, Gonzalo, Artiles & VerdejoFigure 11: Predictive power UIR F WePS-1aFigure 12: Predictive power UIR F WePS-1b714fiCombining Evaluation Metrics via Unanimous Improvement RatioFigure 13: Predictive power UIR F WePS-2big improvements F tend due peculiarities test collection ratherreal superiority one system versus other.is, opinion, remarkable result: differences UIR better indicatorsreliability measured difference F amount measured difference.Therefore, UIR useful know stable results changes , alsochanges test collection, i.e., indicator reliable perceived differenceis.Note explicitly tested dependency (and reliability) UIR resultsnumber test cases reference collection. However, workingcollection less 30 test cases unlikely, practical terms usability UIRgranted test collections, least respect number test cases.8. Parametric versus Non-Parametric UIRAccording analysis (see Section 5.2), given two measures P R, relationalstructure pairs hPi , Ri depend weighting criteria unanimousimprovement:b Pa Pb Ra Rbcomparing systems, UIR measure counts unanimous improvement resultsacross test cases:UIRX,T (a, b) =|Ta b | |Tb ||T |Alternatively, formulation expressed terms probabilities:715fiAmigo, Gonzalo, Artiles & VerdejoUIRX,T (a, b) = Prob(a b) Prob(b a)probabilities estimated frequentist manner.said, main drawback unanimous improvement threevalued function consider metric ranges; UIR inherits drawback.consequence, UIR less sensitive combining schemes F measure.order solve drawback, could estimate UIR parametrically. However, resultssection seem indicate best option.One way estimating P rob(a b) P rob(b a) consists assumingmetric differences (P, R) two systems across test cases follow normal bivariatedistribution. estimate distribution case samples providedtest bed. estimating density function P rob(P, R), estimate P rob(ab) as8 :P rob(a b) = P rob(P 0 R 0) =Z P =1,R=1P rob(P, R) dP dRP =0,R=0expression used compute UIRX,T (a, b) = Prob(a b) Prob(b a),leads parametric version UIR.order compare effectiveness parametric UIR versus original UIR,repeated experiment described Section 7, adding UIRparam precision/recallcurves Figures 11, 12 13. squares figures represent resultsparametric version UIR. Note behavior lies somewhere F nonparametric UIR: low levels recall, behaves like original UIR; intermediatelevels, general worse original definition better F;recall high-end, overlaps results F. probably due factparametric UIR estimation considers ranges, becomes sensitive unreliabilityhigh improvements F.9. Conclusionswork addressed practical problem strong dependency (and usuallydegree arbitrariness) relative weights assigned metrics applying metriccombination criteria, F .Based theory measurement, established relevant theoretical results: fundamental one monotonic relational structurecontradict Additive Conjoint Structure, unique relationshiptransitive. implies possible establish ranking (a complete ordering) systems without assuming arbitrary relative metric weighting. transitiverelationship, however, necessary ensure robustness specific pairwise systemcomparisons.Based theoretical analysis, introduced Unanimous Improvement Ratio (UIR), estimates robustness measured system improvements across potentialmetric combining schemes. UIR measure complementary metric combination8. computation employed Matlab tool716fiCombining Evaluation Metrics via Unanimous Improvement Ratioscheme works similarly statistical relevance test, indicating perceived difference two systems reliable biased particular weighting scheme usedevaluate overall performance systems.empirical results text clustering task, particularly sensitiveproblem, confirm UIR indeed useful analysis tool pairwise system comparisons: (i) similar increments F, UIR captures ones less dependentrelative weighting scheme precision recall; (ii) unlike F, UIR rewards systemimprovements corroborated statistical significance tests single measure; (iii) practice, high UIR tends imply large F increase, large increaseF imply high UIR; words, large increase F completelybiased weighting scheme, therefore UIR essential information add F.looking results evaluation campaign, UIR proved useful (i) discernbest system among set systems similar performance according F ;(ii) penalize trivial baseline strategies systems baseline-like behavior.Perhaps relevant result side effect proposed measure defined:UIR good estimator robust result changes test collection.words, given measured increase F test collection, high UIR value makeslikely increase also observed test collections. Remarkably, UIRestimates cross-collection robustness F increases much better absolute valueF increase.limitation present study tested UIR text clusteringproblem. usefulness clustering problems already makes UIR useful analysistool, potential goes well beyond particular problem. Natural Language problems and, general, many problems Artificial Intelligence evaluated termsmany individual measures trivial combine. UIR powerful toolmany scenarios.UIR evaluation package available download http://nlp.uned.es.Acknowledgmentsresearch partially supported Spanish Government (grant Holopedia,TIN2010-21128-C02) Regional Government Madrid Research NetworkMA2VICMR (S2009/TIC-1542).ReferencesAmigo, E., Gonzalo, J., Artiles, J., & Verdejo, F. (2008). comparison extrinsic clusteringevaluation metrics based formal constraints. Information Retrieval, 12 (4), 461486.Artiles, J., Gonzalo, J., & Sekine, S. (2009). WePS-2 Evaluation Campaign: OverviewWeb People Search Clustering Task. Proceedings 2nd Web People SearchEvaluation Workshop (WePS 2009).Artiles, J., Gonzalo, J., & Sekine, S. (2007). SemEval-2007 WePS evaluation: Establishing Benchmark Web People Search Task. Proceedings 4thInternational Workshop Semantic Evaluations, SemEval 07, pp. 6469 Stroudsburg, PA, USA. Association Computational Linguistics.717fiAmigo, Gonzalo, Artiles & VerdejoBagga, A., & Baldwin, B. (1998). Entity-Based Cross-Document Coreferencing UsingVector Space Model. Proceedings 36th Annual Meeting AssociationComputational Linguistics 17th International Conference ComputationalLinguistics (COLING-ACL98), pp. 7985.Carreras, X., & Marquez, L. (2004). Introduction CoNLL-2004 Shared Task: SemanticRole Labeling. Ng, H. T., & Riloff, E. (Eds.), HLT-NAACL 2004 Workshop: EighthConference Computational Natural Language Learning (CoNLL-2004), pp. 8997Boston, Massachusetts, USA. Association Computational Linguistics.Cormack, G. V., & Lynam, T. R. (2005). TREC 2005 Spam Track Overview. Proceedingsfourteenth Text REtrieval Conference (TREC-2005).Debreu, G. (1959). Topological methods cardinal utility theory. Mathematical MethodsSocial Sciences, Stanford University Press, 1 (76), 1626.Ghosh, J. (2003). Scalable clustering methods data mining. Ye, N. (Ed.), HandbookData Mining. Lawrence Erlbaum.Halkidi, M., Batistakis, Y., & Vazirgiannis, M. (2001). Clustering Validation Techniques.Journal Intelligent Information Systems, 17 (2-3), 107145.Luce, R., & Tukey, J. (1964). Simultaneous conjoint measurement: new scale typefundamental measurement. Journal Mathematical Psychology, 1 (1).Mann, G. S. (2006). Multi-Document Statistical Fact Extraction Fusion. Ph.D. thesis,Johns Hopkins University.Meila, M. (2003). Comparing clusterings. Proceedings COLT 03.Narens, L., & Luce, R. D. (1986). Measurement: theory numerical assignments. Psychological Bulletin, 99.Steinbach, M., Karypis, G., & Kumar, V. (2000). comparison document clusteringtechniques. KDD Workshop Text Mining,2000.Su, K.-Y., Su, J., Wiebe, J., & Li, H. (Eds.). (2009). Proceedings Joint Conference47th Annual Meeting ACL 4th International Joint ConferenceNatural Language Processing AFNLP. Association Computational Linguistics, Suntec, Singapore.Tao Li, C. Z., & Zhu, S. (2006). Empirical Studies Multilabel Classification. Proceedings 18th IEEE International Conference Tools Artificial Intelligence(ICTAI 2006).van Rijsbergen, C. J. (1974). Foundation evaluation. Journal Documentation, 30 (4),365373.Weng, C. G., & Poon, J. (2008). New Evaluation Measure Imbalanced Datasets.Roddick, J. F., Li, J., Christen, P., & Kennedy, P. J. (Eds.), Seventh AustralasianData Mining Conference (AusDM 2008), Vol. 87 CRPIT, pp. 2732 Glenelg, SouthAustralia. ACS.Zhao, Y., & Karypis, G. (2001). Criterion functions document clustering: Experimentsanalysis. Technical Report TR 0140, Department Computer Science, University Minnesota, Minneapolis, MN.718fiJournal Artificial Intelligence Research 42 (2011) 851-886Submitted 07/11; published 12/11Dr.Fill: Crosswords ImplementedSolver Singly Weighted CSPsMatthew L. GinsbergTime Systems, Inc.355 Goodpasture Island Road, Suite 200Eugene, Oregon 97401Abstractdescribe Dr.Fill, program solves American-style crossword puzzles.technical perspective, Dr.Fill works converting crosswords weightedcsps, using variety novel techniques find solution. techniquesinclude generally applicable heuristics variable value selection, variantlimited discrepancy search, postprocessing partitioning ideas. Branchbound used, incompatible postprocessing determinedexperimentally little practical value. Dr.Fills performance crosswordsAmerican Crossword Puzzle Tournament suggests ranks among topfifty crossword solvers world.1. Introductionrecent years, interest solving constraint-satisfaction problems, csps,constraints soft satisfaction desirable,strictly required solution. example, construction problem modeledcsp, may possible overutilize particular labor resource paying associatedworkers overtime. cheapest way construct artifact question,corresponding solution certainly viable practice.Soft constraints modeled assigning cost violating constraint,looking solution original csp accumulated costminimized.large, work systems primarily theoretical various techniques solving weighted csps (wcsps) considered evaluated withoutexperimental support underlying implementation real-world problem. Theoretical complexity results obtained, general consensus appearssort branch-and-bound method used solver, cost onepotential solution used bound thereby restrict subsequent search possibleimprovements.goal paper evaluate possible wcsp algorithms practicalsetting, wit, development program (Dr.Fill) designed solve American-stylecrossword puzzles. Based search engine underlying Dr.Fill, basic conclusionsfollows:c2011AI Access Foundation. rights reserved.fiGinsberg1. present specific variable- value-selection heuristics improve effectiveness search enormously.2. effective search technique appears modification limited discrepancysearch (lds) (Harvey & Ginsberg, 1995).3. Branch-and-bound appears terribly effective solution technique leastproblems sort.4. Postprocessing complete candidate solutions improves effectiveness search.complete description crossword domain found Section 2.2;example crosswords appear Figures 1 2. overall view take that, givenspecific crossword clue c possible solution word fill f , associatedscore p(f |c) gives probability fill correct, given clue. Assumingprobabilities independent different clues, probability collectionfills solves puzzle correctly simplyp(fi |ci )(1)fi fill entered response clue ci . Dr.Fills goal find set fillslegal (in intersecting words share letter square intersection)maximizing (1).human solvers, p(f |c) general zero except handful candidate fillsconform full domain knowledge. Thus 1973 nonfiction best seller womanmultiple personalities must Sybil; 3-letter Black Halloween animal mightbat cat, on. Dr.Fill, complete domain knowledge impracticalmuch greater use made crossing words, csp solver exploits hardconstraints problem restrict set candidate solutions.Dr.Fills performance solver comparable (but significantly faster than)best human solvers. solving New York Times crosswords (which increasedifficulty Monday Saturday, large Sunday puzzles comparable Thursdaysdifficulty), Dr.Fill generally solves Monday Wednesday puzzles fairly easily, wellFriday Saturday puzzles, often struggles Thursday Sunday puzzles.puzzles frequently involve sort gimmick clues fillmodified nonstandard way order make puzzle challenging. runpuzzles American Crossword Puzzle Tournament, annual national gatheringtop solvers New York City area, Dr.Fills performance puts top fiftyapproximately six hundred solvers typically attend.outline paper follows. Preliminaries contained next section,formal preliminaries regarding csps Section 2.1 discussion crosswordsSection 2.2. Section 2.3 discusses crosswords csps specifically, including descriptionvariety ways crosswords differ problems typically consideredconstraint satisfaction community.heuristics used Dr.Fill described Section 3, value-selection heuristicstopic Section 3.1 variable-selection heuristics topic Section 3.2.852fiDr.Fill: Crossword Solvertechniques value variable selection applied wcsps generally, althoughclear dependent usefulness crossword-specific features describedSection 2.3.modification lds described Section 4, followed Section 5first discussion experimental performance methods. Algorithmic extensionsinvolving postprocessing discussed Section 6, also discusses reasonsbranch-and-bound techniques likely work well domain. Branch-andbound postprocessing compatible arguments branch-and-bounddeeper that. Section 7 describes utility splitting crossword smallerproblems associated constraint graph disconnects, idea dating back workFreuder Quinn (1985) somewhat different setting provided lds.Section 8 concludes describing related future work, including earlier crosswordsolvers Proverb (Littman, Keim, & Shzaeer, 2002) WebCrow (Ernandes, Angelini,& Gori, 2005), Jeopardy-playing program Watson (Ferrucci, Brown, Chu-Carroll,Fan, Gondek, Kalyanpur, Lally, Murdock, Nyberg, Prager, Schlaefer, & Welty, 2010).2. Preliminariessection, give brief overview constraint satisfaction, crossword puzzles,relationship two.2.1 Constraint Satisfactionconventional constraint-satisfaction problem, csp, goal assign valuesvariables satisfying set constraints. constraints indicate certain valuesone variable, say v1 , inconsistent specific values different variable v2 .Map coloring typical example. particular country colored red, neighboringcountries permitted color.formulate crossword solving associating variable word crossword, value variable associated fill. fact first letterword 1-Across match first letter word 1-Down correspondsconstraint two variables question.basic csp, then, consists set V variables, set domains, onevariable, variables values taken, set constraints.Definition 2.1 Given set domains set V variables, n-ary constraintpair (T, U ) V size n U subset allowed sets valuesvariables V . assignment mapping variable v V elementvs domain. V , restriction , denoted S|T , restrictionmapping set . say satisfies constraint (T, U ) S|T U .constraint simply specifies sets values allowed various variablesinvolved.example, imagine coloring map Europe using four colors red, green, blueyellow. might set {France, Spain} (which share border), would assigndomain {red, green, blue, yellow} variable, U would twelve ordered853fiGinsbergpairs distinct colors four colors available. associated constraint indicatesFrance Spain cannot colored color.remarked, take view variables crossword correspondvarious slots words must entered, valueswords putative dictionary fills taken (but see commentsSection 2.3). two words intersect (e.g., 1-Across 1-Down, typically), binaryconstraint excluding pairs words shared letters differ.Definition 2.2 constraint-satisfaction problem, csp, triple (V, D, ) Vset variables, gives domain variable V , set constraints.|V | called size csp. every constraint either unary binary,csp called binary csp.csp C, denote set variables C VC , domains DC ,constraints C .solution csp assignment satisfies every constraint .map coloring crossword solving described binary csps.extensive literature csps, describing applicability widerange problems various techniques effective solving them.practical repeat literature here, two points particularlysalient.First, csps generally solved using sort backtracking technique. Valuesassigned variables; conflict discovered, backtrack occurs designedcorrect source problem allow search proceed. chronologically based backtracking schemes, well-known heuristics selecting variablesvalued values used, effective backtracking techniques usekind nogood reasoning (Doyle, 1979; Ginsberg, Frank, Halpin, & Torrance, 1990,many others) ensure backtrack able make progress.need formalize slightly.Definition 2.3 Let C csp, suppose v variable VC x valueassociated domain DC . C|v=x denote csp obtained setting v x.words, C|v=x = (VC v, DC , ) consists constraintsconstraint (T, U ) C(T, U ),v 6 ;=(2)(T v, {u U |u(v) = x}|T v ), v .C|v=x called restriction C v = x.notation may intimidating idea simple: Values permitted constraintsnew problem permitted old problem, given decidedset v x. original constraint doesnt mention v (the top line (2)), newconstraint unchanged. v mentioned, see values variablesallowed, given v known take value x.854fiDr.Fill: Crossword SolverDefinition 2.4 Let partial solution csp C, maps variablesVC elements DC . restriction C S, denoted C|S , csp obtainedsuccessively restricting C assignments Definition 2.3.definition well-defined obviously have:Lemma 2.5 restriction defined Definition 2.4 independent orderindividual restrictions taken.2Backtracking csp solvers work selecting variables, trying various values variables selected, recursively solving restricted problems generated settingvariable question value chosen.second general point would like make regarding csp solversimplementations use kind forward checking help maintain consistencysearch proceeds. example, suppose assign value xvariable v, this, every possible value variable v 0eliminated constraints. case, obviously eliminate x value v.worth formalizing bit, although general terms.Definition 2.6 propagation mechanism mapping csps cspschange variables, (V, D, ) = (V, D0 , 0 ) (V, D, ). also requirevariable V , associated domain D0 subset associated domainD, = (T, U ) , must 0 = (T 0 , U 0 ) 0 U 0 U . saysound if, csp C solution C, also solution (C).propagation mechanism strengthens constraints problem, may reducevariable domains well. sound never discards solution originalcsp.wide range propagation mechanisms discussed literature. Simplest,course, simply eliminate variable values shown violate oneconstraints problem. Iterating idea recursively quiescence (Mackworth,1977) leads well known AC-3 algorithm, preserves arc consistency cspsolved.Returning map Europe, Germany borders France, Holland, Poland, Austria(among countries). Holland red, Poland blue, Austria yellow,sufficient cause Germanys live set green (assuming fourcolors available), turn cause Frances live set exclude green, even thoughFrance share direct constraint Holland, Poland Austria.Alternatively, consider crossword showed Figure 1; New York Timescrossword (with solution) March 10, 2011. decide put READING 1Across [Poets performance], live set words 1-Down consists six-letter wordsbeginning R. also entered ASAMI 21-Across [Me, too] REDONDO27-Across, live set 1-Down would words form R...AR.Weighted CSPs Sometimes desirable csp include soft constraints.notion soft constraint indicates set variable values preferredsolution, requirement like pirates code, youd call guidelines855fiGinsbergNY Times, Thu, Mar 10, 2011 Matt Ginsberg / Shortz1234567ACROSSREN G8C9E1. *Poet's1415performanceL B N8. Frequent flooding 1617siteW R P R N U14. Country1819U.S.BB Lgoes war2122232425E"Wag Dog"2728293015. "savedR E NRlife tonight"323334351975 Elton JohnB L ENhit363716. 36- 58D F F E R E NAcross, 38 3940answersP E L LN G E Lstarred clues 41424318. Jacket material,C EG Eshort?4748495051RR19. 1973 nonfiction5253545556best sellerRwoman585960multipleW H E N C P Lpersonalities626320. LadyL N Eknight?646521. "Me, too"BR24. Line ___2011, New York Times26. "The Thin Man"actress58. See 16-Across11. Neighborhood27. ___ Beach, Calif.62. "I'm done12. Flower30. Plunderthis"shares name32. Big name63. "Somehowtentacledcircuseseverything getssea creature35. B, A, D, G E,done"13. might departe.g.64. nothingmidnight36. See 16-Across65. *Like Seattle vis15. Huff38. Say "B-A-D-G-E,"-vis Phoenix17. Japanese bande.g.22. *Not fixed40. Figures23. Like Elgar'sceiling laSymphony No. 11. Seafood lover'sCappella Sistina25.Cloakshangout41. Impersonated28. "What's ___?"2. Nancy Drew'scostume party29. Pharmaceuticalaunt43. Spoilsoils3. One way travel47. Nutritional amt.31.*Shinestudy48. Doughnuts,33. Old World eagle4. Popdanishes34. Burglar5. Connections51. Piecedetective stories6. Cheese ___action36. William7. Player golf52. Gillette offeringplayed Uncle8. Clink54. Bette's "Divine"Charley "My9. Prey wild dogsstage personaThree Sons"crocodiles57. Actress Vardalos10. Furnish10L11L1213RE NN CE2026ELN31PLEEE444546BH R5761ENZEN G ENE R37. Prefixpaganism38. Many signatures39. Noodle dish42. Lots lots44. Battle cry45. FrenchdepartmentPyrenees46. Less lively49. Opportune50. "Whatever ___don't care!"53. Drones, maybe55. Excitement56. ___ Bear59. Inner ear?60. Medieval Frenchlove poem61. keepermay keepcFigure 1: Thursday New York Times crossword. 2011New York Times. Reprintedpermission.856fiDr.Fill: Crossword Solveractual rules. solution found without violating one soft constraints,acceptable return solution violate soft constraint. hard constraints required satisfied case.variety ways formalize this. One simplest simply associatecost soft constraint search overall assignment valuesvariables total cost minimized. take view total costassignment sum costs soft constraints violated,although accumulation functions (e.g., maximum) certainly possible (Bistarelli,Montanari, Rossi, Schiex, Verfaillie, & Fargier, 1999).soft k-ary constraint thus consists mapping c : Dk IR giving cost associatedvarious selections variables valued. cost complete assignmentvalues variables sum costs incurred soft constraint. csp includingcosts form called weighted constraint satisfaction problem, wcsp (Larrosa &Schiex, 2004, many others).Definition 2.7 weighted csp, wcsp, quadruple C = (V, D, , W ) (V, D, )csp W set pairs (U, c) U V set variables c costfunction assigning cost assignment variables U . element w Wcalled weighted constraint. ambiguity arise, abuse notationalso denote w associated cost function c.Given partial solution S, associated cost weighted constraint w = (U, c),denoted c(S, w), minimum cost associated c valuation variablesU extends partial solution S. cost partial solution definedXc(S) =c(S, w)(3)wWInformally, c(S, w) minimum cost charged w solution Cextension S. therefore have:Lemma 2.8 Given wcsp C partial solution S, every solution C extendscost least c(S).2Note Definition 2.7 slightly nonstandard explicitly split hardconstraints soft constraints W . crossworddomain, condition met: soft constraints always unary(although hard constraints not). simply cost associated settingvariable v specific value x. refer problems singly weighted csps,swcsps. algorithmic ideas present paper appliedreasonably easily wcsps fact swcsps, experimental work underlyingDr.Fill clearly reflects performance swcsps specifically.1possible use propagation reduce sizes domains particularcsp, also possible use variety polynomial time algorithms compute lower1. fact, Larrosa Dechter (2000) shown weighted csps recast similarly,form hard binary constraints soft unary constraints.857fiGinsbergbounds c(S) partial solution S. techniques used become increasingly sophisticated recent years, ranging algorithms move costs aroundconstraint graph better compute minimum (Givry & Zytnicki, 2005; Zytnicki, Gaspin,de Givry, & Schiex, 2009) sophisticated approaches solve linear programmingproblems compute accurate bounds (Cooper, de Givry, Sanchez, Schiex, Zytnicki,& Werner, 2010).Finally, note passing every csp dual version rolesvariables constraints exchanged. view crosswords csps variablesword slots values words fill them, constraints requireletters match words cross. could also view crosswords cspsvariables individual letters, values usual Z,constraints indicate every collection letters needs make legal word.discuss likely relative merits two approaches Section 2.3,described crosswords themselves.2.2 CrosswordsSince introduction first word cross Sunday New York World almostcentury ago (December 21, 1913), crosswords become one worlds popularmental pastimes. Shortz, editor crossword New York Times, estimatesfive million people solve puzzle day, including syndication.22.2.1 Features Crosswordstypical New York Times crossword appears Figure 1. assume readerfamiliar basic format, many specific features worth mentioning.Crosswords symmetric. black squares, blocks, preserved 180rotation.3 addition, crosswords almost always square shape, Times dailypuzzles size 15 15 Sundays 21 21.4Multiple words permitted fill. puzzle Figure 1, [Seafoodlovers hangout] cluing RAW BAR 1-Down [Somehow everything gets done] cluingMANAGE 63-Across. indication clue multiword answerexpected.Without clues, crossword solutions unique. many waysfit words particular crossword grid; clues determine legal fillpuzzles solution. makes solving challenging computationalperspective: Failing understand clues (at least level) leaves problemunderconstrained.2. Personal communication.3. rare cases, horizontal symmetry present instead rotational symmetry. rarer cases still,symmetry requirement honored.4. Sunday puzzles used 23 23 occasion, reduction size Times printedmagazine section made larger puzzles impractical.858fiDr.Fill: Crossword SolverPuzzles themed themeless. themeless puzzle contains collectiongenerally unrelated words clues. themed puzzle shared element connects many answers; happens, shared answers generally locatedsymmetrically grid.puzzle Figure 1 themed. (symmetric) entries 1-Across, 65-Across,22-Down 31-Down marked asterisks words pronounceddifferently capitalized. description also appears puzzle using(also symmetric) entries 16-Across, 36-Across 58-Across.5presence theme profound impact solving experience. particular example (which relatively straightforward), two entries (WORDSPRONOUNCED WHENCAPITALIZED) surely appear dictionarysolver using fill grid. also complex relationships among manyentries phrase 16-Across, 36-Across 58-Across, also relationshipphrase entries marked asterisks.themes present challenges. popular themes quippuzzles, famous saying split symmetric pieces inserted grid,rebus puzzles, one letter must put single square. Arguablyfamous themed Times puzzle appeared election day 1996. clue39-Across [Lead story tomorrows newspaper (!), 43-Across]. 43-AcrossELECTED and, depending choices words, 39-Across could eitherCLINTON BOBDOLE. example, 39-Down, three-letter [Black Halloween animal]could CAT (with C CLINTON) BAT (with B BOBDOLE). here,multiple ways insert words legally grid, multiple wayswords match clues provided. (Until winner election decided,course.) two legal solutions identical except CLINTON/BOBDOLEambiguity associated crossing words; known whether puzzleadmits multiple solutions without shared words, conforming usual restrictionssymmetry, number black squares, on.extreme example themed crossword appears Figure 2. clueparticular letter replaced asterisks (so 1-A, example, e [Twinkle]replaced). letter replaced dropped fill, result stillword. 1-A, would normally GLEAM, becomes David Bowie rock genreGLAM.Every word puzzle missing letters fashion. computer (or human)solver unable get foothold kind fails understand gimmick,Dr.Fill fails spectacularly puzzle.Puzzles structural restrictions. Times, daily unthemed puzzle72 words; themed puzzle generally 78. Sunday,140 words limit. 61 squares grid black squares.6information potentially value solver word count often used5. submitted, puzzle also contained asterisk entry 36-Across, breaksymmetry pronounced-differently-when-capitalized entries. Shortz decided manysolvers wouldnt get joke, though, asterisk removed puzzle published.6. Times puzzle fewest words (52) appeared January 21, 2005 Frank Longo.puzzle fewest blocks (18) appeared August 22, 2008 Kevin Der, feat859fiGinsbergNY Times, Sun, May 17, 2009 TAKEAWAY CROSSWORD (see Notepad)Matt Ginsberg / Shortz123456789101112ACROSS1. Twinkl*13145. Ou*look9. "Dani*l Boon*"1617actor192013. Gung-*o [Lat.]14. Sp*tted cats2315. Male chauvini*t,*ay26272816. Playin* slots,3132e.*.17. Minia*ure383940desser*s18. Admonis* [suffix]434419. *iding, sword484921. Neither youngol*52535423. Diat*ibe delive*e*s25. *hief5726. Sergea*t old TV636429. Denta* devices31. Still feelin* sleepy676832. *over34. Mentalist inspired7071"Mandra*e2009, New York TimesMagician"38. Struc*68. Lessons fro*footfables40. Mail origi*ator69. 1960* prote*t [242. Absolutely ama*ewds.]43. *emoves pencil70. S*utma*ks71. Places *o pick45. Big pi*kles?chicks?47. Cat*' warning*72. Likel* rise?48. Apo*tle known a*"the Zealot"50. Dise*se1. Brib*, informallytr*nsmitted[Fr.]cont*min*ted2. Bit *irew*ter3. Asla*'s realm52. Italian po*t?4. Lite*ally, "sac*ed55. Cerea* proteinutte*ances"[Ger.]5. Nothing speci*l57. P*blic sales6. Opposite *on't59. Im*roved one's lot7. M*nhole[hyph.]em*n*tion63. Can*ne restra*nt8. *eatles' Paul64. Sou*hwes*McCartney, e.g.German ci*y9. Made smalle*66. Rea*y ri**en10. *ost67. Roun*e*co*prehensive1518212429222530333441453555586162475156596537424650366066697211. *mall amount,briefly12. Devicere*oves stalks fro*fruit14. Chin*s* cuisin*20. *atchy *ony22. *oting boothfeature24. Big name ba**s26. Pulit*er, e.g. [Fr.]27. *egis*ative routine[Sp.]28. B*ont family30. Speaks gi**erish33. First mo*th,Jua*35. Lesley "60Minu*es"36. Waiti*g o*e's tur*37. Di*dainfulexpre**ion39. LeftMet*oline*41. Core cont*iners44. National parksout*westTennessee46. Turt*esbu**ets49. *mpos*ng house51. Biase*52. Qi*g Dy*astypeople53. A**ow shoote*s54. O*erdo diet56. Street art, *aybe58. Stron* *rowth60. homo*eneous[Lat.]61. "Lo*e Tender"star62. B*rth cert., one65. Rank*escFigure 2: difficult themed crossword. 2009New York Times. Reprintedpermission.860fiDr.Fill: Crossword Solverdetermine whether puzzle theme. (The themed puzzle Figure 170 words, however, really concluded 15 15 puzzle72 words likely themed way.)restrictions well. Two-letter words permitted, everysquare must two words passing (alternatively, one-letter wordspermitted, either). puzzle must connected (in underlying csp graphwell). puzzle singly connected, converting single empty squareblock disconnects it, viewed flaw acceptable one.Fill words may repeated elsewhere puzzle. fill BAT appearsone location puzzle, cannot used elsewhere (including multiword fill).addition, BAT cannot used clue. means words appearing clues(or least, not) appear fill well.Crossword clues must pass substitution test. arguablyimportant requirement solvers perspective. must possible constructsentence clue appears, meaning sentence essentiallyunchanged clue replaced fill. puzzle Figure 1, one mightsay, Ive seen video e.e. cummings giving READING, equivalent (althoughstilted) Ive seen video e.e. cummings giving [poets performance]. One might say,dont keep food houses CELLAR dont want get wet,equivalent dont keep food houses [frequent flooding site] dont wantget wet.fact clues associated fill must pass substitution test meansgenerally possible determine part speech, number (singular vs. plural)tense (present, past, future, etc.) fill clue. Figure 1, fill 1-Asingular noun, on. restricts number possible values wordconsiderably.conventions regarding cluing. clue contains abbreviation,answer abbreviation well. puzzle Figure 1 abbreviationsclued way (a rarity), 62-D Figure 2 [B*rth cert., one]. solutionIDENT, abbreviation identification. course, gets dropped,DENT entered grid. Abbreviations also indicated phrase likeshort clue.Clues ending ? generally indicate sort wordplay involved. Figure 1,example, 18-A: [Jacket material, short?] solution BIO jacketclue refers books jacket, clothing.wordplay often exploits fact first letter clue capitalized.Figure 1, 7-D [Player golf], referring GARY Player. clue [GolfsPlayer], capitalization (not mention phrasing) would made obviousproper name involved. clue written, solver might easily misled.Crossword features Dr.Fill Many features described (e.g.,symmetry) bear directly solving experience, Dr.Fill therefore unawarerepeated August 7, 2010 Joe Krozel. known whether 17-block puzzle reasonablequality exists.861fiGinsbergthem. program look multiple-word fill module designedidentify rebus puzzles. check see fill words repeated elsewhere, sincerare offer little value search. uses fairly straightforward part-of-speechanalysis help substitution test, checks clues abbreviations. Dr.Fillknowledge puns.2.3 Crossword Puzzles SWCSPsGiven this, cast crossword solving csp?view take, roughly speaking, start large dictionarypossible fills, goal enter words grid cross consistentlyword entered match associated clue. dictionary, define Dnsubset consisting words exactly n letters, BAT D3 ,on. also assume scoring function p scores particular word relativegiven clue, interpret probabilistically. Given clue like [Black Halloweenanimal]3 3-letter word potential fill BAT, p(BAT|[Black Halloween animal]3 )probability BAT correct answer word question. goal findoverall fill maximum probability correct.words, ci ith clue fi value entered grid, wantfind fi satisfy constraints problem (crossing words must agree letterfilled crossing square)p(fi |ci )(4)maximized. mentioned introduction, assumes probabilitiesvarious words correct uncorrelated, probably reasonably accuratecompletely correct themed puzzle.define (fi , ci ) = log p(fi |ci ), maximizing (4) equivalent minimizingX(fi , ci )(5)exactly swcsp framework described.dictionary Di must include words length i, also sequences wordscollectively length i. (In words, D15 needs include WHENCAPITALIZED.)actuality, however, even enough. many instances crossword filleven word sequences.may word appear particular dictionary. puzzle2010 American Crossword Puzzle Tournament (acpt) clued MMYY [Credit cardexp. date format] although MMYY word normal sense.example appearance SNOISSIWNOOW Times puzzle 11/11/10, cluedApollo 11 12 [180 degrees]. Rotating entire puzzle 180 degrees readingSNOISSIWNOOW upside produces MOONMISSIONS.Given examples similar ones, virtually letter sequence can, fact, appearparticular puzzle. domain fact consist stringsappropriate length, cost function used encourage use letter strings862fiDr.Fill: Crossword Solverdictionary words (or sequences words) possible. means variabledomains large associated functions must representedfunctionally; computing either dictionaries scores entirety simplyimpractical.fundamental difference problem solved Dr.Fillproblems generally considered AI literature. number variables modest,order 100, domain size variable immense, 265 approximately12 million word length five, 1.7 1018 word length fifteen.One immediate consequence Dr.Fill limited amountforward propagation solves particular puzzle. letter enteredparticular square puzzle, effective see way letter constrainschoices crossing words. appears effective propagaterestriction further. if, puzzle Figure 1, restrict 1-Down wordform R...AR word form dictionary RAW BAR, couldconceivably propagate forward B BAR see impact 18-Across.actuality, however, possibility 1-Down non-dictionary fill causes propagationbeyond simple one-level lookahead negative practical value. sophisticatedpropagation techniques mentioned Section 2.1 appear suitable domain.second consequence unrestricted domain sizes always possibleextend partial solution way honors hard constraints problem.simply entering random letters square puzzle (but one letterper square, horizontal vertical choices agree). random stringlegal, may even correct. reason fills general avoided randomstrings assigned high cost soft constraints formulation.fact partial solutions always extended satisfy hard constraintsdifference problem solved Dr.Fill considered elsewherecsp literature. Here, however, exception. Much work probabilisticanalysis using Markov random fields focuses probabilistic maximization similar ours,environment solving hard constraints easy maximizingscore result hard.popular inference technique Markov setting dual decomposition,roles variables values switched, Lagrange multipliers introduced corresponding variable values values optimized bound qualitysolution original problem (Sontag, Globerson, & Jaakkola, 2011, example).similar csp notion duality, roles variables values alsoexchanged.clear apply idea setting. probabilistic case, variablevalues probabilities selected continuous set real numbers. crosswordcase, domain still impracticably large appear naturalordering notion continuity one string value next.one difference crossword domain standard onesalso important understand. Consider themed crossword called HeadsState 2010 acpt. theme entries puzzle common phrasestwo-letter state abbreviations appended beginning. Thus [Film boastful jerks?]clues VAIN GLOURIOUS BASTERDS, movie title INGLOURIOUS BASTERDS863fiGinsbergtogether two-letter state abbreviation VA. [Origami?] clues PAPER FORMING,PA adjoined PERFORMING, on.multiword fills appear explicitly dictionary score fairly badly.conventional csps, reasonable respond filling associated wordsearlier search. allows better values assigned apparently difficultvariables. general idea underlies Joslin Clements (1999) squeaky wheel optimization virtually every recent variable selection heuristic, Boussemartet. als (2004) notion constraint weighting, dom/wdeg heuristic (Lecoutre, Sas,Tabary, & Vidal, 2009, others).crossword domain, however, words score badly way arguablyfilled later search, opposed earlier. obviously way programDr.Fill, extremely limited domain knowledge. figure 21-letterword [Film boastful jerks?] VAIN GLOURIOUS BASTERDS.hints suggested crossing words essential (as humans well). noneclassic variable selection heuristics applied here, something else entirelyneeded. heuristics use presented Section 3.moving on, two final points make. First, goalfind fill (4) maximized; words, maximize chances solvingentire puzzle correctly. potentially distinct goal entering manycorrect words possible, keeping scoring metric acpt describedSection 5. best human solvers generally solve acpt puzzles perfectly, however,goal win acpt, maximizing chances solving puzzles perfectlyappropriate.Second, designed Dr.Fill could truly exploit power underlyingsearch algorithm. constructing function (5), example, dont requirecorrect solution clue ci specific fill fi (5) minimized,hope correct fi vaguely near top list. intention hardconstraints corresponding requirement filling words mesh workus. many automated game players (Campbell, Hoane, & Hsu, 2002;Ginsberg, 2001; Schaeffer, Treloar, Lu, & Lake, 1993), rely search replaceunderstanding.2.4 Data Resources Used Dr.FillOne important resources available Dr.Fill access varietydatabases constructed online information. briefly describe data sourceshere; summary Table 1. table also includes information sizeanalogous data source used Littmans crossword solving program Proverb (Littmanet al., 2002).2.4.1 PuzzlesDr.Fill access library 47,000 published crosswords. include virtuallymajor published sources, including New York Times, (now defunct) NewYork Sun, Los Angeles Times, USA Today, Washington Post, many others.puzzles early 1990s included.864fiDr.Fill: Crossword Solverdata typepuzzlescluesunique cluessmall dictionarybig dictionaryword rootssynonymsWikipedia titlesWikipedia pairssourcevarioushttp://www.otsys.com/cluehttp://www.otsys.com/cluehttp://www.crossword-compiler.comvarioushttp://wordnet.princeton.eduWordNet onlinehttp://www.wikipedia.orghttp://www.wikipedia.orgquantity47,6933,819,7991,891,6998,4526,063,664154,0361,231,9108,472,58376,886,514quantity (Proverb)5,142350,000250,000655,0002,100,000154,036 (?)unknownTable 1: Data used Dr.FillCollectively, puzzles provide database 3.8 million clues,approximately half unique. contrasted corresponding databaseProverb, contains 5,000 puzzles 250,000 unique clues.clue database available http://www.otsys.com/clue, public-domain cluedatabase used many crossword constructors. underlying data compressed,source code available well enable interested parties decompressdata question.2.4.2 DictionariesProverb, Dr.Fill uses two dictionaries. small dictionary intended containcommon words, larger one intended contain everything. larger dictionary amalgamation many sources, including Moby7 online dictionaries,Wikipedia titles, words ever used crosswords, on.small dictionary basic English dictionary supplied CrosswordCompiler, automated tool used assist construction crosswords.large dictionary much extensive. Every entry large dictionaryalso marked score intended reflect crossword merit. wordsgenerally viewed good fill, others bad. example, BUZZ LIGHTYEARexcellent fill. lively positive connotations. letters interesting (highScrabble score, basically), combination ZZL unusual. TERN acceptable fill;letters mundane word overused crosswords, wordleast well known. ELIS (Yale graduates) poor fill. letters common, wordobscure, awkward plural boot. Crossword merit large dictionaryevaluated hand scoring approximately 50,000 words (100 volunteers, crosswordconstructors, scored 500 words each). words evaluated many criteria(length, Scrabble score, number Google hits,8 appearances online corpora, etc.)linear model built best matched 50,000 hand-scored entries. modelused score remaining words.7. http://icon.shef.ac.uk/Moby/mwords.html8. would like thank Google general Mark Lucovsky particular allowing runapproximately three million Google queries involved here.865fiGinsbergNote scores reflect crossword value words isolation, ignoringclues. Thus cannot use dictionaries alone solve crosswords; indeed,particular crossword, many legal fills actual solution unlikelyanywhere near best fill terms word merit alone.2.4.3 Grammatical Synonym InformationGrammatical information collected data provided part WordNetproject (Fellbaum, 1998; Miller, 1995). includes list 154,000 words alongparts speech roots (e.g., WALKED WALK root). Proverb also citesWordNet source. addition, list 1.2 million synonyms constructedonline thesaurus.2.4.4 WikipediaFinally, limited amount information collected Wikipedia specifically. Dr.Filluses list titles Wikipedia entries source useful names phrases,uses list every pair consecutive words Wikipedia help phrase developmentfill-in-the-blank type clues. approximately 8.5 million Wikipedia titles,Wikipedia contains 77 million distinct word pairs.3. Heuristicshigh level, csps solved using sort depth-first search. Valuesassigned variables procedure called recursively. pseudocode, mighthave:Procedure 3.1 compute solve(C, S), solution csp C extends partialsolution S:123456789assigns value every variable VC , returnv variable VC unassignedDv (C|S )0 (v = d)C 0 propagate(C|S 0 )C 0 6=Q solve(C 0 , 0 )Q 6= , return Qreturnselect unassigned variable, try possible value. value, setvariable given value propagate unspecified way. assumepropagation returns empty set failure marker contradiction discovered,case try next value v. propagation succeeds, try solveresidual problem and, manage so, return result.866fiDr.Fill: Crossword SolverProposition 3.2 Let C csp size n. propagate function sound,value solve(C, ) computed Procedure 3.1 C solutions, solutionC otherwise.Proof. proof induction n. csp size 1, live domain value triedvariable question; one survives propagate construction, solutionreturned recursive call line 1 line 8 well.larger n, csp solvable, every recursive call fail welleventually return line 9. csp solvable, eventually set particularvariable v right value recursive call succeeds solutionreturned.2weighted csps, algorithmic situation complex want returnbest solution, opposed solution. augment Procedure 3.1 also acceptadditional argument that, nonempty, currently best known solution B. needfollowing easy lemma:Lemma 3.3 wcsp costs non-negative, S1 S2 , c(S1 ) c(S2 ).Proof. immediate; costs incurred larger set assignments.Note true wcsps generally, singly weighted csps.2convenience, introduce inconsistent assignment assume c()infinite. modify Procedure 3.1 follows:Procedure 3.4 compute solve(C, S,B), best solution wcsp C extendspartial solution given currently best solution B:12345678c(S) c(B), return Bassigns value every variable VC , returnv variable VC unassignedDv (C|S )0 (v = d)C 0 propagate(C|S 0 )C 0 6= , B solve(C 0 , 0 , B)return Buse B notation beginning procedure indicate B passedreference, B changed line 7, value B used recursivecalls changed well.loop variable values, longer return solution soonfind one; instead, update best known solution appropriate.will, course, dramatically increase number nodes expanded search.offsetting saving comparison line 1; cost partial solutionhigher total cost best known solution, Lemma 3.3 ensures needexpand partial solution further. Note conditions lemma satisfiedDr.Fill, since costs negated logarithms probabilities, probabilitiesassumed exceed one.867fiGinsbergProposition 3.5 Let C csp. value solve(C, , ) computed Procedure 3.4 C solutions, least cost solution C otherwise.Proof. Suppose first drop line 1 replace line 7C 0 6= c(solve(C 0 , 0 , B)) < c(B) B solve(C 0 , 0 , B)(6)result follows easily inductive argument similar proof Proposition 3.1. Every possible solution considered, gradually find leastcost one return.Consider Procedure 3.4 written. return set line 2, mustc(S) < c(B) virtue test line 1. Thus new requirement (6), namelyc(solve(C 0 , 0 , B)) < c(B), always satisfied proof completeshow simply test line 1 never discard best solution. words,need show solution 0 discarded result test line 1,c(S 0 ) c(B). follows directly Lemma 3.3, since c(S 0 ) c(S)c(S) c(B).2Procedure 3.4 historical method choice wcsps. generally referredbranch bound cost best solution B found one branch usedbound searches branches.implement procedure, need specify mechanisms variablesselected line 3 domain ordered line 4. discuss value selection firstvariable selection. described Section 2.3, propagation mechanism usefulcrossword solving considers direct impact word selection crossingwords.3.1 Value Selectionperformance Procedure 3.4 depends critically order values selecteddomain D. sooner find good solutions, earlier use testline 1 prune subsequent search. kind argument remain valid evenreplace Procedure 3.4 algorithms effective practice; alwaysadvantageous order search final solution found earlier, opposedlater.variety elements this. First, note really need line 4Procedure 3.4 function fill(v, n) returns nth element vs live domainDv . pass loop, call fill gradually increasing valuen. Faltings Macho-Gonzalez (2005) take similar approach work openconstraint programming.work open constraint programming, observation allows us dealfact crossword fills appear explicitly dictionary. scoring functionallows non-dictionary words, assumes apparently unrelated string words (orletters) less likely correct word phrase actually appearsdictionary. means fill function evaluate dictionary possibilitiesgenerating multiwords. multiwords generated needed;868fiDr.Fill: Crossword Solvertime needed, letters word generally filled. narrowssearch possible multiwords substantially.9implementation begins scoring every word appropriate length storingresults domain word n. multiwords needed generated,added end domain sets appropriate.approach reduces value selection problem two subproblems. First, needscoring function (fi , ci ) evaluates fill fi given clue ci . Second, need usescoring function produce actual ordering possible words enter; lowest costword may may one wish try first.spend great deal time describing scoring function; detailspredictably fairly intricate ideas simple. Fundamentally, take viewproven successful elsewhere computer game players: importantsystem able search effectively actually terribly good ideadoing. power always search heuristics.overall search-based approach underlies virtually best computer game players(Campbell et al., 2002; Ginsberg, 2001; Schaeffer et al., 1993) search-based algorithmseasily outperformed knowledge-based counterparts (Smith, Nau, & Throop, 1996,example) games direct comparisons made.implement idea scoring system principle quite simplistic. Wordsanalyzed based essentially five criteria:101. match clue itself. clue used before, associated answerpreferred. new clue shares word subphrase existing one, answerscores well also.2. Part speech analysis. possible parse clue determine likely partspeech answer, fill matching desired part speech preferred. partspeech analysis based WordNet dictionary (Fellbaum, 1998; Miller, 1995),used search parse patterns clue database. externalsyntax grammatical mechanisms used.3. Crossword merit discussed Section 2.4.2.4. Abbreviation. Abbreviations dictionary identified assuming wordsgenerally clued using abbreviations abbreviations, describedpreviously. information used scoring possible answer newclue. exactly constitutes abbreviation clue determined recursivelyanalyzing clue database.5. Fill-in-the-blank. clues fill blanks. generally refercommon phrase word missing, 24-A Figure 1, [Line ] clues9. And, remarked earlier, means need value badly scoring variables late searchopposed early.10. Proverb thirty individual scoring modules (Littman et al., 2002), although Littmansuggested (personal communication) value comes modules analogousused Dr.Fill. Proverb analyze clues determine part speechdesired fill.869fiGinsbergITEM. clues analyzed looking phrases appear bodyWikipedia.five criteria combined linearly. determine weights variouscriteria, specific set weights (w1 , . . . , wn ) selected used solvefixed testbed puzzles (the first 100 New York Times puzzles 2010). puzzletestbed, count number words entered search proceduremistake made heuristically chosen word one appearsknown solution puzzle. average number words entered correctlyscore (w1 , . . . , wn ) weights varied maximize score.Given scoring function , order values particular word?dont necessarily want put best values first, since value bestword may force us use extremely suboptimal choices crossing words.precisely, suppose assign value variable v, propagationreduces variable domains new values Di (C|S{v=d} ). argument similarunderlying Lemma 2.8 produces:Proposition 3.6 Let C swcsp partial solution, Du ((C|S{v=f } ))domain u v set f result propagated. minimum costsolution C extends {v = f } leastXmin(x, u).2(7)uxDu ((C|S{v=f } ))order variable values order increasing total cost measured (7), preferringchoices work well word slot question, also minimally increasecost associated crossing words.notion fairly general. wcsp, whenever choose value variable,choice damages solution problem large; amount damagedetermined propagating choice made using whatever mechanism desired (asimplistic approach ours, full arc consistency, Coopers linear relaxation, etc). Costincurred choice made, implied variablespropagation mechanism. (7) says want choose value variable vvalue total global cost minimized, local cost variablevalued.crossword domain, heuristic appears reasonably effective practice.Combined variable selection heuristic described next section, Dr.Fillinserts average almost 60 words Times puzzle making first mistake.3.2 Variable Selectionargued previous section, heuristic use valuing possible fill f wordslot puzzleXXh(f, v) =min(x, u)min (x, u)(8)uxDu ((C|S{v=f } ))870uxDu (C|S )fiDr.Fill: Crossword Solverdomain variable u setting v f Du (C|S ), term right(8) gives lower bound best possible score complete solution v setf (and expression thus independent f ).value term left lower bound best possible score vset f domain u setting v f propagating Du ((C|S{v=f } )).heuristic value setting v f difference two numbers, totaldamage caused commitment use fill f variable v. Given (8), variableselect valuation point search?might seem choose value variable h(f, v) minimized.would cause us fill words could filled without significant impactprojected final score entire puzzle. could define heuristic valueslot v, denote H(v),H(v) = min h(f, v)f(9)apparently attractive idea worked poorly practice, bit investigationrevealed reason. Especially early on, remains great deal flexibilitychoices variables, may multiple candidate fills particularclue, appear attractive h(f, v) small. situation,really strong reason prefer one attractive fills others, using (9)variable selection heuristic force us value variable therefore commitchoice.solution problem choose value variable h(f, v)minimized, variable difference minimum valuesecond-best value maximal. difference indicates confident trulyfill slot correctly decide branch it. define min2(S)second-smallest element set S, variable selection heuristicproposingH(s) = min2 h(f, v) min h(f, v)(10)fflarge values preferred smaller ones.mentioned previously, combination (10) (8) allows Dr.Fill enter,average, initial 59.4 words Times puzzle makes first error.important realize metric 59.4 words inserted correctly averagescoring function accurately places correct word first large fractiontime. Instead, methods benefiting even point anticipationsearch likely develop; heuristics based much glimpsefuture search word values isolation. Indeed, use variableselection described switch value selection heuristic simply prefer best fillword question (without considering impact subsequent search), averagenumber words filled correctly outset search drops 25.3, well halfprevious value.871fiGinsbergr@@rHHHHHHHHHHHHer@@@@@rAerr@@@reAerhrrAhr@@hArr01121223Figure 3: Limited discrepancy search4. Limited Discrepancy SearchGiven Dr.Fill enter nearly sixty correct words crossword makingerror, one would expect strong solver combined branch-and-boundsolving procedure 3.4. Unfortunately, case.reason solving procedure suffers Harvey (1995) calledearly mistakes problem. mistake made, impacts subsequent searchsubstantially mistake never retracted entire associated subspaceexamined. initial mistake depth (say) sixty seems impressive qualitysolution point likely quite poor, unlikely sufficient timeretract original error led problem.One way around problem csps binary domains use limited discrepancysearch, lds (Harvey & Ginsberg, 1995). idea heuristic present,define discrepancy count partial solution number timesviolates heuristic. Figure 3, shown simple binary search tree depththree; assuming heuristic choice always left, labeled fringenode number times heuristic violated reaching it.Lds iterative search method expands tree using depth-first searchorder increasing discrepancy count. first iteration, nodes without discrepancies examined, search pruned node figure singlebullseye. second iteration, single discrepancy permitted nodesdouble bullseyes pruned. hard see iteration n expands O(dn ) nodes,discrepancy limit forms barrier full search tree. iterationalso uses O(d) memory, since expansion individual iteration depth first.work repeated iteration iteration, since bulk workiteration n involves nodes expanded iteration n 1, rework little872fiDr.Fill: Crossword Solverimpact performance. Korf (1996) presents algorithmic improvement addressesissue extent.point lds allows early mistakes avoided without searching largeportions space. figure, example, heuristic wrong roottree, node labeled 1 explored second iteration (with discrepancy limit 1),without need expand left half search space entirety.clear basic intuition underling lds good match searchdifficulties encountered Dr.Fill, clear idea applied. Onenatural approach would order values particular word slot, sayusing second value (as opposed first) incurred one discrepancy, usingthird value incurred two discrepancies, on.doesnt work. Assuming first word list wrong, subsequent wordsmay score quite similarly. believed strongly (and wrongly, apparently)first word best fill mean strong opinionuse backup choice. net result best solution often useswords quite late ordered list; correspond high discrepancy counttherefore unlikely discovered using sort algorithmic approach.alternative idea say discrepancy incurred variable selectedbranching variable suggested variable-selection heuristic (10).avoids problem described previous paragraph, since pick fillcompletely different word slot. Unfortunately, suffers two difficulties.first (and less important) cases, wont want changevariable order all. Perhaps clear first choice and, choiceeliminated, clear second choice among remaining candidate values.instance, would want single discrepancy search choice try second fillinstead first.important fact bad choice likely come back nextnode expansion, consider variable question. wordlooked good discrepancy incurred may well still look good, windused discrepancy really changed area search spaceconsidering.algorithm actually use combines ideas approaches.search proceeds, maintain list P value choices discarded,pitched. element P pair (v, x) indicating value xproposed variable v. pitched choices remain live set, consideredbranch values v forced vs live set becomes singleton.evaluating heuristic expressions (8) (10), pitched values considered.incur discrepancy pitching variable value suggested heuristics. Assuming completely recompute variable chosen branchingvalue used, problems mentioned previous paragraphs neatlysidestepped. continue make choices confidence, since pitchedvalue remains pitched search proceeds, repeat apparent mistake latersearch process.873fiGinsbergFormally, have:Procedure 4.1 Let C wcsp. Let n fixed discrepancy limit supposepartial solution, B best solution known thus far, P set values pitchedsearch. compute solve(C, S, B, n, P ), best solution extendingn discrepancies:123456789c(S) c(B), return Bassigns value every variable VC , returnv variable VC unassignedelement Dv (C|S ) (v, d) 6 P0 (v = d)C 0 propagate(C|S 0 )C 0 6= , B solve(C 0 , 0 , B, n, P )|P | < n, B solve(C, S, B, n, P (v, d))return BProposition 4.2 Let C csp size k. value solve(C, , , n, ) computedProcedure 4.1 C solutions. C solution, n0 k(|D|1)n n0 , solve(C, , , n, ) least cost solution C.Proof. essentially three separate claims proposition, addressindividually.1. C solutions, test line 2 never succeed, B throughoutprocedure therefore return .2. clear space explored larger n superset space exploredsmaller n test line 8 succeed often. Thus nbest solution returned, best solution also returned larger n.3. claim n = k(|D| 1), every solution considered, proveinduction k.k = 1, n = |D| 1. interested particular choice xunique variable problem, |D| 1 iterations line 8, eitherselected x line 4 pitched every value case xselected last iteration.argument inductive case similar. variable v selected line 3,use |D| 1 discrepancies setting v desired value, leavingleast (n 1)(|D| 1) discrepancies handle search subproblem vset.2Proposition 4.3 Let C csp size k. fixed n, number nodeexpansions computing solve(C, , , n, ) (k + 1)n+1 .Proof. Consider Figure 4, shows top lds search tree labels nodesnumber unvalued variables number unused discrepancies point.874fiDr.Fill: Crossword Solver(k, n)HHHHHHHHHH (k, n 1)Hs%%ee%e%e%eess%(k 1, n)s%%e%%%%(k 2, n)eeeees(k 1, n 1)(k 1, n 1)(k, n 2)Figure 4: Limited discrepancy searchroot, therefore, k variables left value n discrepancies available.branch left, assign value variable. branch right, pitch choicestill k variables left value n 1 discrepancies available.follows denote f (d, m) size search tree pointvariables discrepancies,f (d, m) = 1 + f (d, 1) + f (d 1, m)(11)= 1 + f (d, 1) + 1 + f (d 1, 1) + f (d 2, m)(12)= 2 + f (d, 1) + f (d 1, 1) + f (d 2, m)...X= k+f (i, 1) + f (d k, m)(13)i=dk+1= d+Xf (i, 1) + f (0, m)(14)i=1= d+1+Xf (i, 1)(15)i=1+ 1 + (d 1)[f (d, 1) 1] + f (d, 1)(16)= 2 + df (d, 1)](11) follows counting nodes figure. (12) result expandinglast term (11), corresponding expanding node labeled (k 1, n) figure.(13) continues expand corresponding term total k times, (14) (13)k = d. f (0, m) = 1 variables left value, producing (15).(16) follows f (i, 1) f (d, 1) 1 0 < < (in figure, every stepleft side least one node smaller).875fiGinsbergGiven f (d, m) 2 + df (d, 1),f (d, m)2+d1+df (d, 1)f (d, 1)f (d, 0) = d+1 search must progress directly fringe discrepanciesremain. Thus f (d, m) (1 + d)1+m . Taking = n = k root treeproduces desired result.25. Dr.Fill Crossword Solverpoint, described enough Dr.Fills underlying architecture makessense report performance system described thus far.11overall experimental approach follows.First, tune word scoring function . Although five basic contributions value particular clue fill, currently twenty-fourtuning parameters impact five contributions waycombined get overall value . described Section 3, goalmaximize average number words entered correctly beginning solvefirst 100 Times puzzles 2010.tuning process time consuming; Dr.Fill spends approximately one cpu minuteanalyzing clues given puzzle determine value words dictionary.analysis often needs repeated tuning parameters changed; followssingle run testbed 100 puzzles takes hour. clue analysismultithreaded work done 8-processor machine (two 2.8GHz quad-coreXeons), reduces wall clock time considerably, remains impractical samplespace parameter values coarse granularity, parameters mustgeneral tuned independently one another even though variety cross effectsundoubtedly exist.tuning complete, Dr.Fill evaluated puzzles 2010 acpt(American Crossword Puzzle Tournament). set seven puzzles, algorithmic heuristic progress appear translate quite well progress acpt sample.puzzles scored according acpt rules, Dr.Fills total score examineddetermine would ranked competitor.acpt scoring particular puzzle follows:1. 10 points correct word grid,2. 25 bonus points full minute time remaining puzzle completed.bonus reduced 25 points incorrect letter, never negative.3. 150 bonus points puzzle solved correctly.11. Dr.Fill written C++ currently runs MacOS 10.6. needs approximately 3.5 GBfree memory run, multithreaded. multithreading uses posix threads GUIwritten using wxWidgets (www.wxwidgets.org). code underlying data obtained (fornoncommercial use only) contacting author. code expected run virtually unchangedLinux; Windows challenge Windows native support posixthreads.876fiDr.Fill: Crossword Solverversionldspostprocessand/orbest human1128012801280123029251185118516153176517901815193041140116511651355516901690169015656207020702095199571920203020802515total10790112101131012205rank89 (tied)43 (tied)381Table 2: Results 2010 acptSince puzzles timed, Dr.Fill needs sort termination condition. stopswork declares puzzle complete following conditions occur:1. full minute goes improvement cost puzzle currently filled,2. full lds iteration goes improvement cost puzzle currentlyfilled,3. acpt time limit puzzle reached.Results versions Dr.Fill appear Table 2, scores puzzle,total score tournament, ranking Dr.Fill competed. also give scoreshuman (Dan Feyer) event.12 first fourth puzzles generallyeasiest, second fifth puzzles hardest. lds-based Dr.Fill scoredtotal 10,790, good enough 89th place.evaluation complete, attempt generally made improve Dr.Fillsperformance. examine puzzles Times testbed (not acpt puzzles,try keep clean possible) try understand mistakes made.mistakes generally classified one three types:1. Heuristic errors, words entered scored better correct ones eventhough correct fill,2. Search errors, words entered scored worse correct ones Dr.Fillfind better fill discrepancy limit reached,3. Efficiency errors, points lost search took long timecomplete.Heuristic errors generally lead change scoring algorithms way, although generally introduction new scoring modules. Perhaps differentthesaurus used, understanding theme entries changes. Search errors may leadmodifications underlying search algorithm itself, Sections 6 7. Dr.Fillgraphical user interface allows user watch search proceed,often invaluable understanding program performed did. Efficiency issuesalso (sometimes) corrected allowing visual search suggest algorithmic modifications; convinced us worthwhile treat overall csp and/ortree discussed Section 7.12. Feyer went win 2011 well; Tyler Hinman acpt champion 20052009.877fiGinsberg6. Postprocessingexamination Dr.Fills completed puzzles based algorithms presented thusfar reveals many cases single letter wrong, problem searchinstead heuristics. words, replacing given letter right onedecreases total cost puzzles fill. would presumably foundlarger discrepancy limit, discovered practice.suggests Dr.Fill would benefit sort postprocessing. simplest approach simply remove word fill, replace best wordslot question. produces change, process repeated quiescence.6.1 Formalization Algorithmic Integrationformalize process easily follows:Procedure 6.1 Given csp C best solution B, compute post(C, B), resultattempting improve B postprocessing:1 change true2 change3change false4v CV5B 0 B6unset value v B 07B 0 solve(C, B 0 , B 0 )8c(B 0 ) < c(B)9B B 010change true11 return Bwork puzzle, erasing word line 6. re-solve puzzle(line 7), better choice word isolation, found.leads improvement, set flag line 10 repeat entire process. Noteerase one word time, since always begin currently best solutionline 5.AC-3, Procedure 6.1 improved somewhat realizing particular iteration, need examine variables share constraint variablechanged previous iteration. practice, little Dr.Fills time spent postprocessing efficiency concern.Lemma 6.2 csp C solution B, c(post(C, B)) c(B).2combine Procedure 6.1 basic search procedure 4.1 usedDr.Fill itself? obviously postprocess result computed Procedure 4.1returning final answer, postprocessing works effectively, surelypostprocess candidate solutions considered. produces:878fiDr.Fill: Crossword SolverProcedure 6.3 Let C wcsp. Let n fixed discrepancy limit supposepartial solution, B best solution known thus far, P set values pitchedsearch. compute solve(C, S,B, n, P ), best solution extendingn discrepancies:123456789c(S) c(B), return Bassigns value every variable VC , return post(C, S)v variable VC unassignedelement Dv (C|S ) (v, d) 6 P0 (v = d)C 0 propagate(C|S 0 )C 0 6= , B solve(C 0 , 0 , B, n, P )|P | < n, B solve(C, S, B, n, P (v, d))return Bdifference Procedure 4.1 line 2, postprocesssolution returning it.6.2 Interaction Branch Boundthought reveals potential problem approach. Suppose originalprocedure 4.1 first produces solution B1 subsequently produces improvement B2 ,c(B2 ) < c(B1 ). Suppose also postprocessing improves solutions comparably,c(post(B2 )) < c(post(B1 )). finally, suppose postprocessing improvessolutions considerably, much so, fact, c(post(B1 )) < c(B2 ).danger missing B2 , since pruned test line 1Procedure 6.3. B2 allow us find better solution, postprocessing.prune B2 early, never postprocess it, improvement foundlarger discrepancy limit used.suggests return earlier possibility postprocessing finalanswer returned Procedure 4.1, may work, either. Perhaps B1 improvedpostprocessing B2 not; again, best solution may lost.problem branch-and-bound postprocessing fundamentally inconsistent; impossible use effectively. idea branch-and-boundsolution pruned complete cost gets large. ideapostprocessing final cost solution cannot really evaluatedsolution complete postprocess run.solution remove branch bound Dr.Fills search algorithm,producing:879fiGinsbergProcedure 6.4 Let C wcsp. Let n fixed discrepancy limit supposepartial solution, B best solution known thus far, P set values pitchedsearch. compute solve(C, S,B, n, P ), best solution extendingn discrepancies:123456789assigns value every variable VC ,return whichever B post(C, S) lower costv variable VC unassignedelement Dv (C|S ) (v, d) 6 P0 (v = d)C 0 propagate(C|S 0 )C 0 6= , B solve(C 0 , 0 , B, n, P )|P | < n, B solve(C, S, B, n, P (v, d))return BSince test line 2 ensures change best solution Bimprovement found, previous results continue hold. really practicalabandon branch bound mechanism controlling size search?is. One reason size search controlled lds viaProposition 4.3. fixed discrepancy limit n, guarantees numbernodes expanded polynomial size problem solved.important, however, experimentation showed branch-and-boundineffective controlling Dr.Fills search. reason effectiveness (searchanticipating) heuristics used Dr.Fill itself. heuristics designed ensurewords inserted early search incur little cost allow crossingwords incur low cost well. happens practice costs incurred earlyextremely modest. Even mistake made, attention typically changesdifferent part puzzle filling additional word w near mistake beginsconsequences expected cost words crossing w. Eventually, restpuzzle complete algorithm finally begrudgingly returns w costincreases.Thinking this, happens cost eventually increaseerror made, increase deferred bottom search tree, nearlyso. much cost almost invariably accumulating bottom search tree,branch bound simply ineffective pruning tool domain. natureargument suggests wcsps derived real-world problems, goodheuristics may exist branch bound may provide little value practical problemsolving.136.3 Resultsresults Procedure 6.4 appear Table 2. Dr.Fills score improves 11,210,would earned tie 43rd place 2010 tournament.13. said, certainly real-world problems branch-and-bound useful, useMendelSoft solve cattle pedigree problems (Sanchez, de Givry, & Schiex, 2008).880fiDr.Fill: Crossword Solver7. AND/OR Searchone algorithmic improvement part Dr.Fill systemcurrently implemented.watched Dr.Fill complete puzzles, many cases would fillenough puzzle residual problem would split two disjoint subproblems.search would frequently oscillate two subproblems, couldclearly introduce inefficiencies.general observation made many others, probably originatesFreuder Quinn (1985), called variables independent subproblems stablesets. McAllester (1993) calls solution technique polynomial space aggressive backtrackingprocedure solves disjoint subproblems time sum times neededsubproblems independently. recently, Marinescu Dechter (2009) explorenotion context constraint propagation specifically, exploiting structureassociated search spaces and/or graphs.None work directly applicable Dr.Fill needs integratedappropriately lds. integration straightforward:Definition 7.1 Let C csp wcsp. say C splits nonemptyV1 , V2 VC V1 V2 = , V1 V2 = VC , constraint weighted constraintC mentions variables V1 V2 . denote C = C|V1 + C|V2 .Proposition 7.2 Suppose C csp splits V1 V2 . S1solution C|V1 S2 solution C|V2 , S1 S2 solution C, solutionsC constructed fashion.addition, C wcsp, least cost solution C union leastcost solutions C|V1 C|V2 .2Note also check see C splits low order polynomial time checkingsee constraint graph associated C connected. so, C split.constraint graph disconnected, C splits.Procedure 7.3 Let C wcsp. Let n fixed discrepancy limit supposepartial solution, B best solution known thus far, P set values pitchedsearch. compute solve(C, S, B, n, P ), best solution extendingn discrepancies:1234567891011assigns value every variable VC ,return whichever B post(C, S) lower costC splits V W ,return solve(C|V , S|V , B|V , n, P ) solve(C|W , S|W , B|W , n, P )v variable VC unassignedelement Dv (C|S ) (v, d) 6 P0 (v = d)C 0 propagate(C|S 0 )C 0 6= , B solve(C 0 , 0 , B, n, P )|P | < n, B solve(C, S, B, n, P (v, d))return B881fiGinsbergPuzzle1234567totalWords78941187894122144643Letters1852373011872452893731817Words wrong0844001127Dr.FillLetters wrong01122001328Time122211211Score128011851815116516902095208011310FeyerTime Score312304161561930313556156551995825153512205Table 3: Results 2010 acptNote line 4, solve split subproblems discrepancy limit n.(for example) currently n = 3 one discrepancy usedpoint split occurs, allowed two additional discrepancies solvingsubproblem, perhaps allowing five discrepancies total.spite this, node count reduced. variables remainingsplit encountered, solving unsplit problem remaining discrepancies mightexpand (1 + d)1+m nodes (Proposition 4.1), solving split problems expand(1 + d1 )1+m + (1 + d1 )1+m(17)nodes. small amount calculus algebra14 shows (1 +d1 )1+m + (1 + d1 )1+m(1 + d)1+m 1, split search faster even though totaldiscrepancies permitted.change embodied Procedure 7.3 significantly improves performance laterlds iterations, arguable exploit improvement modifyingDr.Fills current strategy terminating search increase lds limitproduce improved solution. Even without modification, increasedspeed solution improves Dr.Fills acpt score 100 points (one minute faster puzzles 3 6, two minutes faster puzzle 7), moving notional 38th place2010 event.Detailed performance final version 2010 puzzles shown Table 3.puzzle, give number words letters filled, number errorsmade Dr.Fill area. also give time required Dr.Fill solveprogram (in minutes taken), along time taken Dan Feyer, human winnercontest. (Feyer made errors seven puzzles.) seen, Dr.Fill27 incorrect words (out 643, 95.8% correct) 28 incorrect letters (out 1817,98.5% correct) course event.14. Differentiating (17) shows worst case split d1 = 1, compare 21+m + d1+m(d + 1)1+m . Multiplying (d + 1)1+m produces d1+m + (1 + m)dm + , 21+m < (1 + m)dm2 1.882fiDr.Fill: Crossword Solver8. Related Future Workwide variety work wcsps academic literature, repeatparticular element work here. distinguishes contribution factdriven results naturally occurring problem: solvingcrossword puzzles. led us following specific innovations relative earlierwork:development value selection heuristic based projected cost assigningvalue currently selected variable variablesvariable shares constraint,development variable selection heuristic compares differenceprojected cost impacts best second-best values, branchesvariable difference maximized,modification limited discrepancy search appears work well weightedcsps large domain sizes,recognition branch-and-bound may effective search techniquewcsps reasonably accurate heuristics exist,development inclusion effective postprocessing algorithm wcsps,recognition postprocessing inconsistent branch-and-boundpruning.know extent observations general, extentconsequence properties crossword csp itself. discussedpreviously, crossword csps relatively small number variables almost unlimiteddomain sizes, variables whose valuations incur significant cost general filledlate opposed early.two existing projects closely relate Dr.Fill Proverb (Littmanet al., 2002), crossword solver developed Littman et. al 1999, Watson (Ferrucci et al., 2010), Jeopardy-playing robot developed ibm 2011. three systems(Watson, Proverb, Dr.Fill) respond natural language queries game-likesetting. three cases, programs seem little idea doing,primarily combining candidate answers variety data sources attemptingdetermine answer best match query consideration. appearsmesh well generally accepted view (Manning & Schuetze, 1999) naturallanguage processing far better accomplished using statistical methodsclassical parse-and-understand approach.domain differences Jeopardy crosswords make problems challengingdifferent ways. one sense, crosswords difficult Jeopardy, onealways welcome simply decline answer particular question. crosswords,entire grid must filled. hand, crossing words crossword restrictanswer way obviously unavailable Jeopardy contestants. Search playskey role Dr.Fills performance way Watson cannot exploit. result,Dr.Fill get relatively limited database computational resources.883fiGinsbergprogram runs 2-core notebook 8 GB memory uses database300 MBytes compressed. Watson needs much more: 2880 cores 16 TBmemory. Watson, like Dr.Fill, stores knowledge memory improve accessspeeds Watson relies much extensive knowledge Dr.Fill.programs probably comparably good respective cognitive tasks. Dr.Filloutperforms best humans crossword filling, terms speed (whereeasily fastest solver world) terms accuracy. Watson, too, outperforms humans easily terms speed; much-ballyhooed victory human Jeopardycompetitors probably due far Watsons mastery button pushingquestion-answering ability. terms underlying cognitive task, Watson appearsyet match best Jeopardy players, general capable answeringvirtually questions without error.Dr.Fill remains work progress. point, found heuristicsearch errors relatively easily examining performance program handfulcrosswords simply seeing went wrong. Dr.Fills performance improved,become difficult. therefore developed automated tools examineerrors made collection puzzles, identify heuristic search issues,report nature errors caused mistakes largest sections fill. resultstools will, hope, guide us improving Dr.Fills performance still further.Acknowledgmentswould like thank Time Systems coworkers useful technical advice assistance, would also like thank crossword solving constructing communities,especially Shortz, warm support years. Daphne Koller, Rich Korf,Michael Littman, Thomas Schiex, Bart Selman, papers anonymous reviewers provided invaluable comments earlier drafts, making paper substantiallystronger result. work described paper relates certain pending issuedUS patent applications, publication ideas intended convey license use patented information processes. Time Systems general grantroyalty-free licenses non-commercial purposes.ReferencesBistarelli, S., Montanari, U., Rossi, F., Schiex, T., Verfaillie, G., & Fargier, H. (1999).Semiring-based CSPs valued CSPs: Frameworks, properties, comparison.Constraints, 4.Boussemart, F., Hemery, F., Lecoutre, C., & Sais, L. (2004). Boosting systematic searchweighting constraints. Proceedings ECAI-2004, pp. 146150.Campbell, M., Hoane, A. J., & Hsu, F. (2002). Deep Blue. Artificial Intelligence, 134,5783.Cooper, M., de Givry, S., Sanchez, M., Schiex, T., Zytnicki, M., & Werner, T. (2010). Softarc consistency revisited. Artificial Intelligence, 174, 449478.Doyle, J. (1979). truth maintenance system. Artificial Intelligence, 12, 231272.884fiDr.Fill: Crossword SolverErnandes, M., Angelini, G., & Gori, M. (2005). WebCrow: WEB-based system CROssWord solving. Proceedings Twentieth National Conference Artificial Intelligence, pp. 14121417.Faltings, B., & Macho-Gonzalez, S. (2005). Open constraint programming. Artificial Intelligence, 161, 181208.Fellbaum, C. (Ed.). (1998). WordNet: Electronic Lexical Database. MIT Press, Cambridge, MA.Ferrucci, D., Brown, E., Chu-Carroll, J., Fan, J., Gondek, D., Kalyanpur, A. A., Lally, A.,Murdock, J. W., Nyberg, E., Prager, J., Schlaefer, N., & Welty, C. (2010). BuildingWatson: overview DeepQA poject. AI Magazine, 31 (3), 5979.Freuder, E. C., & Quinn, M. J. (1985). Taking advantage stable sets variablesconstraint satisfaction problems. Proceedings Ninth International Joint Conference Artificial Intelligence, pp. 224229.Ginsberg, M. L. (2001). GIB: Steps toward expert-level bridge-playing program. JournalArtificial Intelligence Research, 14, 313368.Ginsberg, M. L., Frank, M., Halpin, M. P., & Torrance, M. C. (1990). Search lessons learnedcrossword puzzles. Proceedings Eighth National Conference ArtificialIntelligence, pp. 210215.Givry, S. D., & Zytnicki, M. (2005). Existential arc consistency: Getting closer full arcconsistency weighted CSPs. Proceedings Nineteenth International JointConference Artificial Intelligence, pp. 8489.Harvey, W. D. (1995). Nonsystematic Backtracking Search. Ph.D. thesis, Stanford University, Stanford, CA.Harvey, W. D., & Ginsberg, M. L. (1995). Limited discrepancy search. ProceedingsFourteenth International Joint Conference Artificial Intelligence, pp. 607613.Joslin, D. E., & Clements, D. P. (1999). Squeaky wheel optimization. Journal ArtificialIntelligence Research, 10, 353373.Korf, R. E. (1996). Improved limited discrepancy search. Proceedings ThirteenthNational Conference Artificial Intelligence, pp. 286291.Larrosa, J., & Dechter, R. (2000). dual representation non-binary semiring-basedCSPs. Proceedings SOFT-2000.Larrosa, J., & Schiex, T. (2004). Solving weighted CSP maintaining arc consistency.Artificial Intelligence, 159, 126.Lecoutre, C., Sas, L., Tabary, S., & Vidal, V. (2009). Reasoning last conflict(s)constraint programming. Artificial Intelligence, 173, 15921614.Littman, M. L., Keim, G. A., & Shzaeer, N. (2002). probabilistic approach solvingcrossword puzzles. Artificial Intelligence, 134, 2355.Mackworth, A. K. (1977). Consistency networks relations. Artificial Intelligence, 8,99118.885fiGinsbergManning, C. D., & Schuetze, H. (1999). Foundations Statistical Natural Language Processing. MIT Press.Marinescu, R., & Dechter, R. (2009). AND/OR branch-and-bound search combinatorialoptimization graphical models. Artificial Intelligence, 173, 14571491.McAllester, D. A. (1993). Partial order backtracking. Unpublished technical report, MIT.Miller, G. A. (1995). WordNet: lexical database English. CommunicationsACM, 38 (11), 3941.Sanchez, M., de Givry, S., & Schiex, T. (2008). Mendelian error detection complexpedigrees using weighted constraint satisfaction techniques. Constraints, 13.Schaeffer, J., Treloar, N., Lu, P., & Lake, R. (1993). Man versus machine worldcheckers championship. AI Magazine, 14 (2), 2835.Smith, S. J., Nau, D. S., & Throop, T. (1996). Total-order multi-agent task-network planning contract bridge. Proceedings Thirteenth National ConferenceArtificial Intelligence, Stanford, California.Sontag, D., Globerson, A., & Jaakkola, T. (2011). Introduction dual decompositioninference. Sra, S., Nowozin, S., & Wright, S. J. (Eds.), Optimization MachineLearning, pp. 219254. MIT Press.Zytnicki, M., Gaspin, C., de Givry, S., & Schiex, T. (2009). Bounds arc consistencyweighted CSPs. Journal Artificial Intelligence Research, 35, 593621.886fiJournal Artificial Intelligence Research 42 (2011) 815-850Submitted 07/11; published 12/11Stochastic Enforced Hill-ClimbingJia-Hong WuJW @ ALUMNI . PURDUE . EDUInstitute Statistical Science,Academia Sinica, Taipei 115, Taiwan ROCRajesh KalyanamRobert GivanRKALYANA @ PURDUE . EDUGIVAN @ PURDUE . EDUElectrical Computer Engineering,Purdue University, W. Lafayette, 47907, USAAbstractEnforced hill-climbing effective deterministic hill-climbing technique deals local optima using breadth-first search (a process called basin flooding). propose evaluatestochastic generalization enforced hill-climbing online use goal-oriented probabilistic planning problems. assume provided heuristic function estimating expected costgoal flaws local optima plateaus thwart straightforward greedy action choice.breadth-first search effective exploring basins around local optima deterministic problems, stochastic problems dynamically build solve heuristic-based Markov decisionprocess (MDP) model basin order find good escape policy exiting local optimum.note building model involves integrating heuristic MDP problemlocal goal improve heuristic.evaluate proposal twenty-four recent probabilistic planning-competition benchmarkdomains twelve probabilistically interesting problems recent literature. evaluation,show stochastic enforced hill-climbing (SEH) produces better policies greedy heuristicfollowing value/cost functions derived two different ways: one type derived usingdeterministic heuristics deterministic relaxation second type derived automatic learning Bellman-error features domain-specific experience. Using first type heuristic,SEH shown generally outperform planners first three international probabilisticplanning competitions.1. IntroductionHeuristic estimates distance-to-the-goal long used deterministic search deterministic planning. estimates typically flaws local extrema plateaus limitutility. Methods simulated annealing (Kirkpatrick, Gelatt, & Vecchi, 1983; Cerny,1985) A* (Nilsson, 1980) search developed handling flaws heuristics.recently, excellent practical results obtained flooding local optima using breadth-firstsearch. method called enforced hill-climbing (Hoffmann & Nebel, 2001).Deterministic enforced hill-climbing (DEH) proposed work Hoffmann Nebel(2001) core element successful deterministic planner Fast-Forward (FF). DEHextension basic hill-climbing approach simply selecting actions greedily lookingahead one action step, terminating reaching local optimum. DEH extends basic hillclimbing replacing termination local optima breadth-first search find successor statestrictly better heuristic value. planner moves descendant repeatsc2011AI Access Foundation. rights reserved.fiW U , K ALYANAM , & G IVANprocess. DEH guaranteed find path goal problem deadend-free (soevery state path). relatively weak guarantee applies independent qualityheuristic function, intent DEH remediate flaws generally accurate heuristicorder leverage heuristic finding short paths goal. domains basinsize (search depth needed escape optimum) bounded, DEH provide polynomial-timesolution method (Hoffmann, 2005).Enforced hill-climbing defined probabilistic problems, due stochastic outcomesactions. presence stochastic outcomes, finding descendants better values longerimplies existence policy reaches descendants high probability. One may argue FF-Replan (Yoon, Fern, & Givan, 2007)a top performer recent probabilistic planningbenchmarksuses enforced hill-climbing call FF. However, enforced hill-climbingprocess used determinized problem, FF-Replan use form hill climbingdirectly stochastic problem. fact, FF-Replan consider outcome probabilitiesall.One problem consider generalizing enforced hill-climbing stochastic domainssolution deterministic problem typically concise, sequential plan. contrast, solutionstochastic problem policy (action choice) possibly reached states. essentialmotivation hill-climbing avoid storing exponential information search, evenexplicit solution stochastic problem cannot directly stored respecting motivation.reason, limit consideration online setting, solution problemlocal policy around current state. local policy committed executedlocal region exited, planner new online problem solve (possibly retaininginformation previous solution). approach generalizes directly constructionoffline policies situations space store policies available. Note that, contrast,deterministic enforced hill-climbing easily implemented offline solution technique.propose novel tool stochastic planning generalizing enforced hill-climbing goalbased stochastic domains. Rather seeking sequence actions deterministically leadingbetter state, method uses finite-horizon MDP analysis around current state seek policyexpects improve heuristic value current state. Critical process directincorporation probabilistic model heuristic function finding desired policy.Therefore, finite-horizon analysis, heuristic function integrated MDP problemorder represent temporary, greedy goal improving current heuristic value.integration done building novel heuristic-based MDP state new exitaction available terminates execution cost equal heuristic estimate state,action costs removed1 . heuristic-based MDP, finite-horizon policies restrictedrequirement horizon one, exit action must selected (but also selectedhorizons). heuristic-based MDP, cost policy state expectedvalue heuristic upon exit (or horizon) executed s.Thus, find desired local policy using value iteration heuristic-based MDP aroundcurrent state, deepening horizon, policy found cost improving heuristicestimate current state. restriction selecting exit action horizon one correspondsinitializing value iteration provided heuristic function. policy found,1. motivation removal action costs heuristic-based MDP discussed Section 3.2.816fiS TOCHASTIC E NFORCED H ILL -C LIMBINGmethod executes policy exiting action indicated (or horizon used computingpolicy).resulting method, stochastic enforced hill-climbing (SEH), simply generalizes depth-kbreadth-first search state improved heuristic value (from DEH) k-horizon value iteration computation seeking policy expects improvement heuristic value. Note althoughstochastic enforced hill-climbing explicit statespace technique, suitable use astronomically large statespaces heuristic used informative enough limit effective sizehorizon k needed find expected heuristic improvement. empirical results workdemonstrate behavior successfully.1.1 Applicability LimitationsStochastic enforced hill-climbing (SEH) applied heuristic function. However,applicability (and likewise limitations) SEH greatly depends characteristicsheuristic function. SEH appropriate goal-oriented problem given strong enough heuristicfunction, demonstrate empirically SEH generally outperforms greedy followingheuristic variety heuristics variety domains, even presence probabilistically interesting features (Little & Thiebaux, 2007) deadends. SEH rely upon heuristicfunction identification dead-ends appropriate handling probabilistically interesting features require non-local analysisSEH simply provides local search often correctflaws heuristic function. SEH thus intended possible improvement stochasticsolution methods construct cost-to-go (cost) function follow greedily usingconstructed cost function search heuristic. Many methods constructing value/cost functionsproposed evaluated literature, potentially improvedgoal-based domains using SEH place greedy following (Sutton, 1988; Fahlman & Lebiere,1990; Bertsekas, 1995; Gordon, 1995; Mahadevan & Maggioni, 2007; Sanner & Boutilier, 2009)2 .prove correctness SEH Section 3.4 showing deadend-free domains, SEHfinds goal probability one (i.e. SEH get stuck local optima).SEH search technique leverages heuristic estimate distance go, mustemphasized that, unlike many search techniques, SEH makes promisesoptimality solution path found. SEH greedy, local technique promiserepeatedly find policy reduces heuristic value, possible. such,SEH inappropriate technique use optimal solutions required.Stochastic enforced hill-climbing ineffective presence huge plateaus valleysheuristic functions, due extreme resource consumption finding desired local policies.Heuristic functions huge plateaus result methods failed find useful information problem state regions. SEH inappropriate tool solvingstochastic planning problemother tools needed construct useful heuristic functionmanages deadends avoids huge plateaus. weakness mirrors weakness enforced hillclimbing deterministic domains. SEH also fail find goals avoidable dead-endspresent recognized early enough heuristic. fact, effective dead-end detectioncentral goal heuristic design greedy technique applied heuristic.2. applicability SEH, cost function must non-negative must identify goals assigning zero stategoal state; however, general value/cost functions normalized satisfy requirements.817fiW U , K ALYANAM , & G IVANinsight usefulness SEH gained comparison recent determinizing replanners. mentioned above, one way exploit deterministic planning techniquesDEH stochastic problems determinize planning problem use deterministic planner select action sequence. Executing action sequence problem guaranteedreach goal due determinization approximation, replanning needed augmenttechnique. paper, call stochastic planners use technique determinizing replanners. Determinizing replanners using determinization (called outcomes) retainspossible state transitions shown reach goal probability one absencedead-end states.contrast determinizing replanners, SEH point relies determinizationproblem, instead analyzes increasing-size local probabilistic approximations problem.SEH conducts full probabilistic analysis within horizon, seeking objective reducingprovided heuristic, using value iteration. way, SEH leverages probabilistic parametersignored determinizing replanners, well provided heuristic function,based upon substantial probabilistic analysis. result, SEH successfully handles probabilisticproblem aspects cause major problems determinizing replanners. However, point,theoretical results characterizing gains determinizing replanners. Instead,extensive empirical evaluation showing advantages FF-Replan (Yoon et al., 2007)RFF (Teichteil-Konigsbuch, Kuter, & Infantes, 2010) (two determinizing replanners), wellsubstantial gains compared greedy following heuristic (which also uses transitionprobability parameters).1.2 Evaluationtest SEH broad range domains first three international probabilistic planningcompetitions (as well probabilistically interesting domains Little & Thiebaux, 2007),using two different methods generate heuristic functions. First, test SEH heuristic function based ideas successful re-planner FF-Replan (Yoon et al., 2007).new controlled-randomness FF (CR-FF) heuristic deterministic FF heuristic (Hoffmann& Nebel, 2001) computed simple determinization probabilistic problem makesavailable deterministic transition wherever probabilistic transition possible. noteFF-Replan use (or any) heuristic function stochastic problem. Instead, FFReplan relies FF construct plan deterministic problem, calls FF turn usedeterministic enforced hill-climbing exactly heuristic. Here, consider performanceheuristic directly stochastic problem, comparing greedy heuristic-following SEHbased search around heuristic. latter method using SEH constitutes novel methodcombining determinization (that removes probabilistic parameters) probabilistic reasoning.experiments show new method substantially outperforms FF-Replan across broadevaluation.also performed second evaluation technique heuristic functions learneddomain-specific experience relational feature-learning method presented workWu Givan (2007, 2010). heuristic functions already shown give goodperformance used construct simple greedy policy, improved SEH.SEH technique seen perform well domain-by-domain analysis acrossbroad set competition planning domains, full domain-by-domain results available818fiS TOCHASTIC E NFORCED H ILL -C LIMBINGonline appendix. However, compress summarize extensive per-problem results,divided evaluation domains experimenter-defined categories aggregated performance measurement within problem category. categories single domains,generally, multiple closely related domains may aggregated within single category.example, multiple domains competitions variants blocks world,problems domains aggregated B LOCKSWORLD category.order fairly compare SEH FF-based planners (such RFF, described TeichteilKonigsbuch et al., 2010, FF-Replan) exploit blocksworld-targeted planning heuristicsadded goal deletion goal agenda, provided heuristics extensions SEH.resulting planner called SEH+ , described detail Section 3.6. results show SEH+performs nearly identically SEH non-blocksworld categories using CR-FF heuristic.employ extensions comparing SEH CR-FF heuristic planners.Using experimenter-defined categories, able show SEH exploits heuristicfunctions effectively greedy following heuristic. SEH statistically significantlyoutperforms greedy following thirteen seventeen categories using CR-FF heuristicslosing one category. SEH also outperforms greedy following six seven categories using learned heuristics. (In cases, categories showed similar performancecompared planners.)show SEH+ , using CR-FF heuristics, outperforms FF-Replan tenfifteen categories, similar performance two categories, losing three categories.aggregate results show SEH+ (using CR-FF heuristics) particularly strong performance advantage FF-Replan probabilistically interesting categories (Little & Thiebaux,2007).Finally, compare performance SEH+ RFF-BG (Teichteil-Konigsbuchet al., 2010), one winner fully-observable track third international probabilistic planning competition. SEH+ outperforms RFF-BG twelve fifteen categories, similarperformance one category, losing two categories.summary, empirical work demonstrates SEH provides novel automatic techniqueimproving heuristic function using limited searches, simply applying SEHreasonable heuristic functions produces state-of-the-art planner.2. Technical Background: Markov Decision Processesgive brief review Markov decision processes (MDPs) specialized goal-region objectives.detail MDPs, see work Bertsekas (1995), Puterman (2005), Sutton Barto(1998).2.1 Goal-Oriented Markov Decision ProcessesMarkov decision process (MDP) tuple (S, A, C, T, sinit ). Here, finite state spacecontaining initial state sinit , selects non-empty finite available action set A(s) stateS. action-cost function C assigns non-negative real action-cost state-action-statetriple (s, a, ) action enabled state s, i.e., A(s). transition probabilityfunction maps state-action pairs (s, a) probability distributions S, P(S),A(s).819fiW U , K ALYANAM , & G IVANrepresent goal, include zero-cost absorbing state , i.e., C(, a, s) =0 (, a, ) = 1 A(). Goal-oriented MDPs MDPssubset G statespace, containing , that: (1) C(g, a, ) zero whenever g Gone otherwise, (2) (g, a, ) one g G A(g). set G thustaken define action-cost function C, well constrain transition probabilities .(stochastic) policy MDP : N P(A) specifies distribution actionsstate finite horizon. cost-to-go function J (s, k) gives expected cumulativecost k steps execution starting state selecting actions according () stateencountered. horizon k, least one (deterministic) optimal policy (, k)J (s, k), abbreviated J (s, k), greater J (s, k) every state s,policy . following Q function evaluates action using provided cost-to-go functionJ estimate value action applied,XQ(s, a, J) =(s, a, )[C(s, a, ) + J(s )].Recursive Bellman equations use Q() describe J J follows:J (s, k) = E [Q(s, (s, k), J (, k 1))]J (s, k) = min Q(s, a, J (, k 1)),aA(s)taking expectation random choice made possibly stochastic policy (s, k).cases, zero step cost-to-go function zero everywhere, J (s, 0) = J (s, 0) = 0s. Value iteration computes J (s, k) k increasing order starting zero. Notepolicy cost function depend k, may drop k argument list.Also using Q(), select action greedily relative cost function. policyGreedy(J) selects, state horizon k, uniformly randomly selected actionargminaA(s) Q(s, a, J(, k 1)).goal-based MDP problems directly specified above, may also specifiedexponentially compactly using planning languages PPDDL (Younes, Littman, Weissman, & Asmuth, 2005), used experiments. technique avoids convertingentire PPDDL problem explicitly form, resource reasons, instead constructssequence smaller problems explicit MDP form modeling heuristic flaws.dead-end state state every policy zero probability reaching goalhorizon. say policy reaches region states probability one following policyhorizon k probability entering region point converges one k goesinfinity. say dead-ends unavoidable problem whenever policy sinitreaches goal region probability one. (We say domain unavoidable dead-endsproblem domain unavoidable dead-ends.) note greedy techniqueshill-climbing expected perform poorly domains dead-end states attractiveheuristic values. Application SEH thus leaves responsibility detecting avoiding deadend states design heuristic function.heuristic h : R may provided, intended estimate cost function J largehorizons, h(s) = 0 G, h(s) > 0 otherwise. heuristic may indicate dead-endstates returning large positive value V assume selected experimenterexceed expected steps goal state reach goal. experiments,820fiS TOCHASTIC E NFORCED H ILL -C LIMBINGadd trivial, incomplete dead-end detection (described Section 5.2) heuristic functionevaluate.note domains evaluated paper contain unavoidable deadends,may policy success ratio one. choice large value used recognizeddead-end states effects trade-off optimizing success ratio optimizing expected costincurred goal successful.2.2 Determinizing Stochastic Planning Problemsstochastic planners heuristic computation techniques, including used experiments, rely computing deterministic approximations stochastic problems. One planner,all-outcomes FF-Replan (Yoon et al., 2007), determinizes stochastic planning probleminvokes deterministic planner FF (Hoffmann & Nebel, 2001) determinized problem.determinization used FF-Replan constructed creating new deterministic actionpossible outcome stochastic action ignoring probability outcome happening. effectively allows planner control randomness executing actions, makingdeterminization kind relaxation problem. Section 5.2, define domainindependent heuristic function, controlled-randomness FF heuristic (CR-FF), deterministic FF heuristic (Hoffmann & Nebel, 2001) computed all-outcomes FF-Replan determinization probabilistic problem3 . variety relaxations previously combinedvariety deterministic heuristics order apply deterministic planning techniques stochastic problems (Bonet & Geffner, 2005). generally, deterministic relaxations provide generaltechnique transferring techniques deterministic planning use solution stochasticproblems.3. Stochastic Enforced Hill-ClimbingDeterministic enforced hill-climbing (DEH) (Hoffmann & Nebel, 2001) searches successorstate strictly better heuristic value returns path current state successor.path action sequence guarantees reaching desired successor. illustratebehavior DEH compared greedy policy using example Figure 1. stochasticenvironment, may single better descendant reached probability one,since actions may multiple stochastic outcomes. simply use breadth-first searchDEH find single better descendant ignore possible outcomes, might endselecting action low probability actually leading state better heuristic value,illustrated Figure 2. shown figure, algorithm, stochastic enforced hill-climbing(SEH), accurately analyzes probabilistic dynamics problem improving heuristicvalue.section, give details SEH. note DEH, local breadth-first searchgives local policy state region surrounding current state deterministic environment.value following policy heuristic value improved descendant foundbreadth-first search. SEH, implement ideas stochastic setting.3. deterministic FF heuristic, described work Hoffmann Nebel (2001), FF planner version 2.3available http://www.loria.fr/hoffmanj/ff.html, efficiently computes greedy plan length problem relaxationstate facts never deleted. plan found relaxed problem referred relaxed planproblem.821fiW U , K ALYANAM , & G IVANh=7h=7h=5h=5h=7h=8h=0h=7h=8h=8h=0h=6h=8h=6h = 10h = 10(a) Behavior greedy policy.(b) Behavior DEH.Figure 1: Comparison behavior DEH greedy policy local optimumencountered. solid black circle represents current state, shaded circle representsgoal state (with heuristic value zero). (a) greedy policy keeps selecting actions indicatedwide arrow cannot reach goal state. hand, DEH uses breadth-first searchfinds goal state two steps away current state, shown (b).h=7h=5h=7h=8h=7p =0.2p =0.8h=6h=5h=2h = 10p =0.2h=7h=0p =0.8h=8(a) Behavior DEH stochastic environments.h=6h=2h=0h = 10(b) Behavior SEH stochastic environments.Figure 2: Comparison behavior SEH DEH stochastic example. assumeDEH first determinizes problem, creating one deterministic action possible stochasticoutcome. solid black circle represents current state, shaded circle representsgoal state (with heuristic value zero). (a) DEH looks one step ahead selects action drawndouble lines, one outcomes leads state h = 2, better currentstate. However, action choice higher probability going state h = 10one h = 2. (b) SEH first decides policy better value 5horizon MDP includes states reachable current state one step. SEHextends horizon two states considered. selects actions indicatedwide arrows lead goal state.822fiS TOCHASTIC E NFORCED H ILL -C LIMBINGOnline Planning using Local Planner1. Repeat2.current state3.local Find-Local-Policy(s,h)4.Follow local selected5. goal reachedTable 1: Pseudo-code online planning framework. policy local may non-stationary,case local planner also returns initial horizon execution policy termination line 4 also happen reaching specified horizon.present SEH two steps. First, present simple general framework online planning repeatedly calls local planner selects policy around current state. Second,present local planner based enforced hill-climbing idea. online planningframework instantiated local planner, resulting algorithm SEH. combinationtwo steps constitute central algorithmic contribution paper. Finally, presentanalytical properties algorithm.3.1 Simple Online Planning Frameworkfamiliar direct approach online planning call planner current stateplanner select action. action executed environment, resulting new currentstate. process repeated.Here, present simple generalization approach allows planner selectone action call, action executed. idea planner makesplan local context surrounding current state, plan executed localcontext exited. local context exited, new current state processrepeated.formally, augment action space new terminate action (called ), indicating planned-for local context exited. define local policy around statepartial mapping states augmented action space defined everystate reachable policy4 . online planner built repeatedly seekingexecuting local policy around current state using planning subroutine. local policyexecuted terminate action called (which effect state), pointnew local policy must sought. ideas reflected pseudo-code shown Table 1.note notion local context discussion informal precisenotion given use terminate action. local policy executed selectsterminate action. Find-Local-Policy routine free use method decide stateassigned terminate action. Previously published envelope methods (Dean, Kaelbling,Kirman, & Nicholson, 1995) provide one way address issue, terminationassigned every state outside envelope states. However, framework generalenvelope methods, allows local policies selected based upon pre-existing4. local policy returned non-stationary finite horizon, must select terminate actionfinal stage, reachable states.823fiW U , K ALYANAM , & G IVANenvelopes states (though always, post-planning, interpret set reachable statesenvelope). general intuition selecting action current states may involveanalysis sufficient select actions many surrounding states, framework allowsFind-Local-Policy routine return policy specifying action selections.Also, note online planning framework includes recent re-planners FFReplan (Yoon et al., 2007) RFF (Teichteil-Konigsbuch et al., 2010). However, replanningcurrent plan failed (e.g. determinization used generate naive)quite different character SEH, constructs plans improve heuristic value,replans time plan terminates. Thus, SEH uses heuristic function define subgoalsplan original goal incrementally.remains present local planner combine online planning frameworkdefine stochastic enforced hill climbing. local planner analyzes MDP problem aroundcurrent state, heuristic function integrated problem embody subgoalimproving heuristic value current state. describe simple integrationheuristic function problem next, discuss local planner based integration.3.2 Heuristic-Based Markov Decision Processesmethod relies finite horizon analyses transformed MDP problem, increasing horizons. transform MDP problem novel heuristic achievement transform analysisorder represent goal finding executing policy expects improve initial(current) states heuristic value.heuristic achievement transform straightforward, applies goal-orientedMDP problem. First, action costs removed problem. Second, terminate actionassigned action cost h(s) transitions deterministically absorbing state .policy executed, selection action state result replanning, discussedonline planning framework presented. actions thought heuristicachievement actions, allowing immediate achievement value promised heuristicfunction.Analyzing MDP transformed heuristic achievement transform finite horizonaround s0 represents problem finding policy improving heuristic value s0without regard cost achieving improvement heuristic. Allowing heuristicachievement action selected point state reflects greedy nature goal:planner forced look improvement found, long policyinitial state expects see improvement.Formally, given MDP = (S, A, C, T, s0 ) non-negative heuristic function h : R,heuristic achievement transform h, written Mh , given (S, , C , , s0 ),, C , follows. Let s, s1 , s2 arbitrary states S. define (s)A(s) {a }, take C (s1 , a, s2 ) = 0 (s1 , a, s2 ) = (s1 , a, s2 ) A(s1 ).Finally, define (s, , ) = 1 C (s, , ) = h(s).transformed MDP zero-cost policies states, immediate use. However, policies required select final action (at horizon one)represent policies seeking get regions low heuristic value, whatever cost.increasing-horizon search policies corresponds roughly breadth-first searchimproved heuristic value deterministic enforced hill-climbing. Formally, define class824fiS TOCHASTIC E NFORCED H ILL -C LIMBINGheuristic-achievement policies H class policies (s, k) satisfy (s, 1) = s.define Jh (s, k) value minH J (s, k) heuristic transform MDP h hpolicy achieves value. note that, due zeroing non-terminal action costs,Jh (s, k) represents expected heuristic value achieved next execution ,required horizon k before. Formally, define random variable stateh first executes trajectory s, Jh (s, k) = E[h(s )].rough motivation setting action costs zero analysis heuristic-basedMDP actions considered method remediate flawed heuristic.cumulative action cost required reach state improved heuristic value measuremagnitude flaw heuristic. Here, remove cost analysis orderdirectly express subgoal reaching state lower heuristic value. Including action costsmight, example, lead preferring cheap paths higher heuristic values (i.e., states worses0 ) expensive paths lower heuristic values found. basic motivationenforced hill climbing strongly seek improved heuristic values. Instead dilutingsubgoal adding action costs, methods seek shortest path heuristic improvementanalyzing heuristic-based MDP iteratively deepened finite horizon, discussednext subsection. approach reasonable settings actioncost, finite-horizon value iteration stochastic-setting analogue uniform cost search.settings varying action cost, future work needed adapt SEH usefully considercost without excessively diluting focus improving heuristic.3.2.1 H EURISTIC ACHIEVEMENT VALUE TERATIONFollowing formalism value iteration Section 2.1, compute Jh (s, k) heuristicachievement value iteration follows:Jh (s, 1) = h(s),Jh (s, k) = min Q(s, a, Jh (, k 1)) k 2.aA (s)non-stationary policy achieving cost-to-go given Jh (, k) also computed usingfollowing definition:h (s, 1) = ,h (s, k) = argminaA (s) Q(s, a, Jh (, k 1)) k 2.Note Q() computed heuristic-achievement transformed MDP Mh equations.technical reasons arise zero-cost loops present, require tie breakingargmin h (s, k) favors action selected h (s, k 1) whenever one options.prevent selection looping actions shorter, direct routes value.3.3 Local Plannerconsider method stochastic enforced hill-climbing uses online planning framework, presented Table 1, together local policy selection method solvesheuristic-achievement MDP (exactly, approximately, heuristically). Here, describe onestraightforward method local policy selection defining SEH-find-local-policy using finitehorizon value iteration. method generalizes breadth-first search used deterministic825fiW U , K ALYANAM , & G IVANenforced hill-climbing, seeks expected heuristic improvement rather deterministicpath improved heuristic value. sophisticated heuristic methods finite-horizonvalue iteration considered implementation presented finds local MDP problems intractable. analytical results Section 3.4 apply method exactly solvesheuristic-achievement MDP, method presented Table 2; experimental resultsconducted using implementation Table 2 well.present pseudo-code SEH-Find-Local-Policy Table 2. heuristic function h respectsgoals h(s) = 0 iff G. algorithm assumes non-negative heuristic function h : Rrespects goals, input. SEH-Find-Local-Policy(s0 ,h) returns policy h horizon k.policy computed states horizons needed order execute h s0 usinghorizon k policy terminates.Thus, lines 5 11 Table 2 , heuristic-achievement value iteration conducted increasing horizons around s0 , seeking policy improving h(s0 ). Note given horizon k + 1,states reachable within k steps need included value iteration.3.3.1 E ARLY ERMINATIONprimary termination condition repeated local policy construction discovery policyimproving heuristic estimate initial state. discussed Proposition 1,domains without deadends, SEH-Find-Local-Policy always find policy improving h(s0 ),given sufficient resources.However, badly flawed heuristic functions large enough horizons analyzedSEH-Find-Local-Policy may unacceptably large given resource constraints. Moreover, domains unavoidable deadends, may horizon, however large, policy improvingheuristic initial state. reasons, practice, algorithm stops enlarginghorizon heuristic-based MDP analysis user-specified resource limits exceeded.horizon-limited analysis heuristic-transform MDP construction yielddesired results inexpensively, biased random walk used seek new initial state. example, consider problem provided heuristic labels states reachable k stepscost-to-go estimates similar, forming large plateau. analysis largeplateau exceeds resources available, biased random walk indicated, lack useful heuristicguidance.So, horizon k found Jh (s0 , k) < h(s0 ), system executes h s0horizon k terminate action selected. resource limit exceeded withoutfinding horizon, system executes biased random walk length , terminatingaction imposed states reachable biased random walk h(s) < h(s0 ).additional biased random walk allows method retain beneficial propertiesrandom exploration domains heuristic flaws large MDP analysis. resourceconsumption threshold random walk triggered viewed parameter controllingblend random walk MDP-based search used overcoming heuristic flaws.currently principled way analyzing tradeoff resource consumptioncost switching biased random walk, determining switching. Instead,use domain-independent resource limits described Section 5.1, determinedexperimentation.826fiS TOCHASTIC E NFORCED H ILL -C LIMBINGSEH-Find-Local-Policy(s0 ,h)//s0 current state.//h : {} R heuristic function, extended h() = 0.//assume global variable Mh heuristic-achievementtransform original problem h.//seek policy problem Mh achieving cost less h(s0 ).1. k = 12. Repeat3.k =k+14.// Compute Jh (s0 , k) Mh using value iteration5.Jh (, 1) = h(), h (, 1) = , n = 16.Repeat7.n=n+18.reachable s0 Mh using k n steps9.Jh (s, n) = minaA (s) Q(s, a, Jh (, n 1))10.h (s, n) = argminaA (s) Q(s, a, Jh (, n 1))11.n = k12. Jh (s0 , k) < h(s0 ) resource consumption exceeds user-set limits13. Jh (s0 , k) < h(s0 )14.15.Return h horizon k16.else17.// Return -step biased random walk policy18.// Note: implementations compute lazily online19.n = 120.state21.h(s) < h(s0 )22.23.(s, n) selects probability one24.else25.(s, n) selects action A(s) probability26.PeQ(s,a,h)ai A(s) (eQ(s,ai ,h) )Return horizonTable 2: Pseudo-code local planner used implement stochastic enforced hill-climbing.827fiW U , K ALYANAM , & G IVANHorizon-limited analysis heuristic-transform MDP may also terminate without findinghorizon k Jh (s0 , k) < h(s0 ) entire reachable statespace explored,presence deadends. may happen without exceeding available resources,case fall back fixed number iterations standard VI original MDP model(including action costs without heuristic transform) reachable states.3.4 Analytical Properties Stochastic Enforced Hill-Climbingdeterministic settings, given sufficient resources dead-ends, enforced hill-climbingguarantee finding deterministic path improved heuristic value (if nothing else, goal statesuffice). Given finite state space, guarantee implies guarantee repeated enforcedhill-climbing find goal.situation subtle stochastic settings. problem dead-ends, everystate optimal policy reaches goal probability one. follows problems,h assigning zero every goal state, every state real value > 0, horizonk Jh (s, k) < . (Recall Jh analyzes heuristic transform MDP wherein action costsdropped except h() must realized horizon one.) SEH-Find-Local-Policy(s,h)considers k turn Jh (s, k) < h(s) have:Proposition 1. Given non-goal state s, dead-ends, non-negative heuristic functionh : R respecting goals, sufficient resources, routine SEH-Find-Localpolicy(s,h) returns policy h horizon k expected return Jh (s, k) strictlyless h(s).However, unlike deterministic setting, policy found routine SEH-Find-Local-Policyexpects improvement heuristic value. particular executions policycurrent state may result degraded heuristic value.Here, prove even stochastic settings, spite possibility poor resultsone iteration, SEH reach goal region probability one, absence dead-end statessufficient resources. practice, provision sufficient resources serious hurdle,must addressed providing base heuristic modest-sized flaws.Theorem 1. dead-end free domains, unbounded memory resources, SEH reaches goal region probability one.Proof. Let x0 , x1 , x2 , . . . , xm , . . . random variables representing sequencestates assigned line 2 Table 1 execute SEH planning problem,x0 initial state sinit . algorithm achieves x G ,thus terminates, take xj+1 = xj j . (Note result xj G impliesxj+1 G, G goal region states.)show arbitrary > 0 probability xm goal regionh(sinit )least 1, real value > 0 defined below. expression goes one828fiS TOCHASTIC E NFORCED H ILL -C LIMBINGgoes infinity, conclude SEH reaches goal regionprobability one.Proposition 1, non-goal state s, absent dead-ends sufficientresources, one iteration SEH guaranteed return policy finite horizonks value Jh (s, ks ) improving h(s). Let = h(s) Jh (s, ks ) > 0 valueimprovement horizon ks . finitely many non-goalstates, exists = minsSG > 0 improvement h(s) Jh (s, ks )least . Consider arbitrary xi/ G. Noting Jh (xi , kxi ) =E[h(xi+1 )] due zero action costs Mh , follows immediately E[h(xi )h(xi+1 )|xi/ G] , G goal region states. Using xi G impliesxi+1 G h(xi ) = h(xi+1 ) = 0, writeE[h(xi ) h(xi+1 )]=E[h(xi ) h(xi+1 )|xi/ G]Qi+ E[h(xi ) h(xi+1 )|xi G](1 Qi )(1)Qi , > 0,defining Qj probability xj/ G.Now, lower-bound expected heuristic improvement E[h(x0 ) h(xm )] calls SEH-Find-Local-Policy, > 0. decompose expectedimprovement calls SEH-Find-Local-Policy sum expected improvements individual calls. Then, lower-bounding sum using smallestterm, getE[h(x0 ) h(xm )]=m1Xi=0m1XE[h(xi ) h(xi+1 )](2)Qi (from Inequality 1)i=0mQm ,Qm non-increasing, since xm1 G implies xm G.Next, combine lower bound natural upper bound h(sinit ), since hassumed non-negative (so E[h(x0 ) h(xm )] h(sinit )) x0 = sinit . Thus,h(sinit ) Qm m.h(s)init , converging zeroTherefore probability Qm xm/ Glarge SEH reaches goal probability one.theorem assumes absence dead-ends, problems dead-ends covered theorem well dead-ends avoidable identified heuristic.Specifically, may require heuristic function assigns statepolicy reach goal state probability one. case, problemconverted form required theorem simply removing states assignedconsideration (either pre-processing local MDP construction).829fiW U , K ALYANAM , & G IVAN3.5 Variants Extensions SEHSEH based finite-horizon analysis MDP transformed heuristic-achievement transform around current state s0 . particular heuristic-achievement transform describecourse option incorporating heuristic local search around s0 .already considered number related alternatives arriving choice describe,options considered future research. One notable restriction transformremoval action costs, discussed Section 3.2. important methodretain actual heuristic value analysis trade large, small, positivenegative changes heuristic value according probabilities arising. reason,heuristic transform abstract away value simply assign rewards 10 according whether state improves h(s0 ). choice remove action costs localexpansion lead poor performance domains flawed heuristics interacting badlyhigh variations action costs. subject future research method.Also, MDP models describe paper limited obvious ways.limitations include state space discrete finite, problem setting lacks discounting,objective goal-oriented. yet implement extension relax limitations,leave consideration issues arise future work. note would appearmethod fundamentally goal-oriented, given goal repeatedly reducing heuristic valuecurrent state. However, possible contemplate infinite-horizon discounted non-goaloriented variants seek policies maintain current heuristic estimate.3.6 Incorporating FF Goal-Ordering Techniques SEHplanner FF contains heuristic elements inspired ordering issues arise blocksworldproblems (Hoffmann & Nebel, 2001). heuristic elements improve performance blocksworld problems significantly. assist fair comparison SEH FF-Replan,implemented two heuristic elements, namely goal agenda added goal deletion, variantSEH call SEH+ .implementation SEH+ follows. stochastic planning problem first determinized using outcomes determinization described Section 2.2. goal-agenda technique FF invoked determinized problem extract sequence temporary goalsG1 , . . . , Gm , Gi set goal facts Gm original problem goal. SEHstochastic version added goal deletion, described next subsection, invoked repeatedly compute sequence states s0 , . . . , sm , s0 initial state > 0 sidefined state reached invoking SEH state si1 goal Gi (thus satisfying Gi ).Added goal deletion idea pruning state search space avoiding repetitive additiondeletion goal fact along searched paths. FF, search state s, goal factachieved action arriving s, deleted action relaxed plan found s,expanded (Hoffmann & Nebel, 2001).stochastic adaptation added goal deletion, define set facts addedstate transition (s, a, ) facts true represent set differences. Then, set added goal facts transition added facts also truecurrent temporary goal Gi , i.e., (s s) Gi . prune state transition (s, a, ) wheneverrelaxed plan computed current temporary goal Gi contains action deletesadded goal facts. transition (s, a, ) pruned modifying Bellman update830fiS TOCHASTIC E NFORCED H ILL -C LIMBINGstate contributes dead-end state value (V ) Q-value s, weightedtransition probability (instead contributing cost-to-go ). formally, definemodified Q-function using added goal deletion, Qagd (s, a, J) follows:(1, f (s s) Gi deleted action relaxed plan(s ,Gi )5I(s ) =0, otherwiseXQagd (s, a, J) =(s, a, )[I(s )V + (1 I(s ))J(s )]Qagd () replaces Q() definition cost-to-go function Jh () Section 3.2. Also,reachability line 8 Table 2 use pruned transitions.problems, subsequent deletion newly added goals unavoidable valid plan.Added goal deletion prunes routes leading goal region problems even thoughactual deadend present. Hence, incomplete technique discussed workHoffmann Nebel (2001). FF falls back best-first search DEH able find validplan due pruning. Similarly, unable find improved policy, SEH falls back eithervalue iteration biased random walk described Section 3.3.Preliminary exploration incorporating stochastic variants FFs helpful action pruning(Hoffmann & Nebel, 2001) SEH improve performance, much like effect addedgoal deletion domains except blocksworld6 . result, report helpfulaction-pruning methods here.4. Related Worksection discuss planning techniques close work one dimensions.4.1 Fast-Foward (FF) Planner Deterministic Enforced Hill-Climbingintroduction deterministic enforced hill-climbing (DEH) relation technique,please see Section 3. Here, additionally note several lines work directlyextend FF planner allow planning numeric state-variables (Hoffmann, 2003) planning uncertainty (Hoffmann & Brafman, 2006, 2005; Domshlak & Hoffmann, 2007). Althoughtechniques involve significant changes computation relaxed-plan heuristicpossible addition use belief states handle uncertainty, enforced hill-climbing stillprimary search technique used lines work. note although work Domshlak Hoffmann actions probabilistic outcome handled, planner (Probabilistic-FF)designed probabilistic planning observability, whereas planner designedprobabilistic planning full observability.4.2 Envelope-Based Planning TechniquesStochastic enforced hill-climbing dynamically constructs local MDPs find local policy leadingheuristically better state regions. concept forming local MDPs, envelopes, using5. relaxed plan(s ,Gi ) computes relaxed plan states Gi defined work HoffmannNebel (2001) using all-outcomes problem determinization defined Section 2.2.6. explored ideas based defining helpfulness action expectation helpfulnessdeterministic outcomes.831fiW U , K ALYANAM , & G IVANfacilitate probabilistic planning used previous research work BonetGeffner (2006), Dean et al. (1995), briefly review here.envelope-based methods work Dean et al. (1995) Gardiol Kaelbling (2003)start partial policy restricted area problem (the envelope), iteratively improves solution quality extending envelope recomputing partial policy.typical assumption implementing method planner initial trajectorystarting state goal, generated stochastic planner, use initial envelope.Another line work, including RTDP (Barto, Bradtke, & Singh, 1995), LAO* (Hansen &Zilberstein, 2001), LDFS (Bonet & Geffner, 2006), starts envelope containinginitial state, iteratively expands envelope expanding states. States expandedaccording state values dynamic programming methods used backup state valuesnewly added states, convergence criterion reached. Stochastic enforced hill-climbingviewed repeatedly deploying envelope method goal, time, improvingheuristic estimate distance-to-go. good h function, invocations result trivialone-step envelopes. However, local optima plateaus encountered, envelope mayneed grow locate stochastically reachable set exits.referenced previous search methods constructed envelopes seeking highquality policy goal rather far limited relatively inexpensive goal basinescape. results derive online greedy exploitation heuristic ratherexpensive offline computation converged values proving overall (near) optimality. LDFS,example, compute/check values least states reachable optimal policy (evengiven J input) possibly vastly many others well computation.previous methods able exploit properties (such admissibility)heuristic function guarantee avoiding state expansions regions state space. Clearly,SEH exploits heuristic function way avoid expanding regions statespace.However, point conducted theoretical analysis regions guaranteed unexpanded particular kinds heuristic, analyses may quite difficult.4.3 Policy Rollouttechnique policy rollout (Tesauro & Galperin, 1996; Bertsekas & Tsitsiklis, 1996) usesprovided base policy make online decisions. technique follows policy Greedy(Vf ),Vf computed online sampling simulations policy .computation optimal heuristic-transform policy h SEH similarities policyrollout: case, online decisions made local probabilistic analysis leverages provided information manage longer-range aspects local choice. SEH, heuristic functionprovided while, policy rollout, base policy provided. view, policy rollout localanalysis assumption non-local execution use base policy , whereas SEHlocal analysis assumption non-local execution achieve base heuristiccost estimate h.fact, goal-oriented setting, provided heuristic function h stochastic (a simple generalization describe paper), equal sampled-simulation evaluationV policy , SEH executes policy policy rollout, assuming uniformaction costs sufficient sampling correctly order action choices. claim follows h = V always action yield expected improvement h one step,832fiS TOCHASTIC E NFORCED H ILL -C LIMBINGgoal-oriented setting. need uniform action costs claim may relaxedvariant SEH developed retains action costs heuristic transform.policy rollout, horizon-one greedy use sampled heuristic needed, mainsubstance SEH enable repair use heuristic functions flaws cannotrepaired horizon one. Thus central differences techniques reflectedability SEH leverage arbitrary heuristic functions repair flaws functions largerhorizons.Policy rollout provides elegant guarantee online policy selected improves basepolicy, given sufficient sampling. result follows intuitively computed policypolicy-iteration improvement base policy. Unfortunately, similar guarantee knownapply SEH arbitrary heuristic function. However, policy rollout cannot used improvearbitrary heuristic function either.4.4 Local Search OptimizationStochastic enforced hill-climbing regarded one many local-search techniques designedimprove greedy one-step lookahead, naive form local search optimization.briefly discuss connections method simulated annealing, one large family relatedlocal search techniques. detail, please see work Aarts Lenstra (1997).Simulated annealing (Kirkpatrick et al., 1983; Cerny, 1985) allows selection actionsinferior expected outcome probability monotone action q-value. probabilityinferior action selected often starts high decreases time according cooling schedule. ability select inferior actions leads non-zero probability escaping localoptima. However, method systematically search policy so. contrast,stochastic enforced hill-climbing analyzes heuristic-based MDP increasing horizons systematically search policies give improved expected value (hence leaving local extrema).substantial preliminary experiments, could find successful parameter settings controlsimulated annealing effective application online action selection goal-directed stochasticplanning. knowledge, simulated annealing otherwise tested direct forwardsearch action selection planning, although variants applied successplanning-as-search settings (Selman, Kautz, & Cohen, 1993; Kautz & Selman, 1992; Gerevini &Serina, 2003) planning via Boolean satisfiability search.5. Setup Empirical EvaluationHere, describe parameters used evaluating method, heuristics testmethod on, problem categories tests conducted, random variablesaggregated evaluation, issues arising interpreting results statistical significance.run experiments Intel Xeon 2.8GHz machines 533 MHz bus speed 512KBcache.5.1 Implementation Detailshorizon increase new states reachable, implementation SEH simply switchesexplicit statespace method solve MDP formed reachable states. specifically,833fiW U , K ALYANAM , & G IVANincrease k line 3 Table 2 lead new reachable states line 8, triggervalue iteration states reachable s0 .Throughout experiments, thresholds used terminate local planning line 12 Table 2set 1.5 105 states one minute. set biased random walk length ten. workmakes assumption heuristic functions used assign large values easily recognized deadends, hill-climbing works poorly presence dead-end attractor states. enforcerequirement simple dead-end detection front-end heuristic function(described next Section 5.2 heuristic) assigning value 1.0 105 recognizeddead-end states.denote implementation running heuristic h SEH(h).5.2 Heuristics Evaluateddescribe two different types heuristic functions used evaluation associateddead-end detection mechanisms.5.2.1 C ONTROLLED -R ANDOMNESS FF H EURISTICuse evaluations, define domain-independent heuristic function, controlledrandomness FF heuristic (CR-FF). define CR-FF state FF distance-to-goalestimate (Hoffmann & Nebel, 2001) computed all-outcomes determinization describedSection 2.2. denote resulting heuristic function F . computing CR-FF heuristic,use reachability analysis built FF planner detection deadends.5.2.2 L EARNED H EURISTICSalso test stochastic enforced hill-climbing automatically generated heuristic functionswork Wu Givan (2010), perform state-of-the-art usedconstruct greedy policy. shift heuristic functions fit non-negative range requirement h discussed previously. learned heuristic functions currently availableseven test categories, tested categories.note heuristics learned discounted setting without action costsdirect fit distance-to-go formalization adopted here. still able getsignificant improvements applying technique. denote heuristics L. statesvalid action choice available labeled deadends applying SEH learnedheuristics.5.3 Goals Evaluationprimary empirical goal show stochastic enforced hill-climbing generally improvessignificantly upon greedy following heuristic (using policy Greedy(h) describedtechnical background above). show true heuristics definedSection 5.2. show empirically applicability limitation SEH discussed Section 1.1,different types problems including probabilistically interesting ones (Little & Thiebaux, 2007).secondary goal evaluation show base heuristics resulting performance strong comparison deterministic replanners FF-Replan (Yoon et al., 2007)RFF (Teichteil-Konigsbuch et al., 2010). FF-Replan RFF use Fast-Forward (FF)834fiS TOCHASTIC E NFORCED H ILL -C LIMBINGbase planner, RFF uses most-probable-outcome determinization contrast all-outcomesdeterminization used FF-Replan. primary difference RFF FF-Replanexecuting plan, RFF grows policy trees minimize probabilityreplan, FF-Replan not.5.4 Adapting IPPC Domains Experimentsconduct empirical evaluation using problems first three international probabilistic planning competitions (IPPCs) well twelve probabilistically interesting problemswork Little Thiebaux (2007). omit particular problems domainsparticular comparisons several practical reasons, detailed online appendix.enforced hill-climbing nature goal-oriented technique SEH formulatedgoal-oriented setting, ignore reward structure (including action goal rewards)evaluated problems assume uniform action cost one problems,transforming reward-oriented problem description goal-oriented one.provide detailed per-problem results online appendix planner evaluatedwork. However, support main conclusions, limit presentation aggregationscomparing pairs planners sets related problems. purpose, define seventeenproblem categories aggregate within problem category. categories singledomains, generally, multiple closely related domains may aggregated within single category. example, blocksworld category aggregates blocksworld problems threecompetitions, even though action definitions exactly every problem.paired comparisons, aggregated results problems labeled constructedprobabilistically interesting IPPC3 organizers work Little Thiebaux(2007) combined category PI PROBLEMS.Table 3, list evaluated categories (including combined category PI PROBLEMS),well planning competitions literature problems category from.evaluated problems category identified online appendix.reward-oriented YSADMIN domain IPPC3 stochastic longest-path problembest performance required avoiding goal continue accumulating reward longpossible (Bryce & Buffet, 2008). (Note contrary organizers report, domains goalcondition servers rather servers down.) goal-oriented adaptation removeslongest-path aspect domain, converting domain goal getservers up.B LOCKSWORLD problems IPPC2 contain flawed definitions may lead blockstacking top itself. Nevertheless, goal problems well defined achievableusing valid actions, hence problems included B LOCKSWORLD category.discovered five rectangle-tireworld problems (p11 p15 IPPC3 2T IREWORLD) apparent bugno requirement remain alive included goal condition. domain design provides powerful teleport action non-alive agents intendedincrease branching factor (Buffet, 2011). However, lacking requirement alive goal,domain easily solved deliberately becoming non-alive teleporting goal.modified problems require predicate alive goal region. mergedmodified rectangle-tireworld problems triangle-tireworld problems IPPC3835fiW U , K ALYANAM , & G IVANCategoryProblem Source(s)B LOCKSWORLDIPPC1, IPPC2, IPPC3B OXWORLDIPPC1, IPPC3B USFARELittle Thiebaux (2007)RIVEIPPC2E LEVATORIPPC2E XPLODING B LOCKSWORLDIPPC1, IPPC2, IPPC3F ILEWORLDIPPC1P ITCHCATCHIPPC2R ANDOMIPPC2R IVERLittle Thiebaux (2007)CHEDULEIPPC2, IPPC3EARCH R ESCUEIPPC3YSADMINIPPC3YSTEMATIC - TIRETriangle-tireworld (IPPC3 2-Tireworld P1 P10, Little Thiebaux (2007)),Rectangle-tireworld (IPPC3 2-Tireworld P11 P15) bug fixedIREWORLDIPPC1, IPPC2OWERS H ANOIIPPC1Z ENOTRAVELIPPC1, IPPC2PI PROBLEMSB USFARE, RIVE, E XPLODING B LOCKSWORLDP ITCHCATCH, R IVER, CHEDULE, YSTEMATIC - TIRE, IREWORLDTable 3: List categories planning competitions literature problemscategory taken.836fiS TOCHASTIC E NFORCED H ILL -C LIMBINGwork Little Thiebaux (2007) category YSTEMATIC - TIRE, problemssystematically constructed emphasize PI features.5.5 Aggregating Performance Measurementsexperiments, designed repeatable aggregate measurements samplemany times order evaluate statistical significance. define random variables representing aggregate measurements describe sampling process, well methodevaluating statistical significance.5.5.1 EFINING AMPLING AGGREGATE -M EASUREMENT R ANDOM VARIABLESpair compared planners, define four random variables representing aggregate performance comparisons problems category. random variable based uponsampling process runs planner five times problems category, aggregatesper-problem result computing mean. use five-trial runs reduce incidence lowsuccess planners failing generate plan length comparison. mean value five-trial runsample value respective random variable.First, per-problem success ratio (SR) fraction five runs succeedproblem. success ratio random variable category planner mean SRacross problems category.Second, per-problem successful plan length (SLen) mean plan length successfulruns among five runs. order compare two planners plan length, define perproblem ratio jointly successful plan lengths (JSLEN-RATIO) two compared plannersfollows. planners positive SR among five trials problem, JSLEN-RATIOratio SLen values two planners; otherwise, JSLEN-RATIO undefinedproblem. use ratio lengths emphasize small plan length differences short solutionslong solutions, decrease sensitivity granularity action definitions.mean JSLEN-RATIO random variable category pair plannersgeometric mean JSLEN-RATIO across problems category JSLEN-RATIOwell defined. manner ensure two planners compared exactly setproblems. Note that, unlike SR, JSLEN-RATIO depends pair compared planners,rather measurement single planner; ratio successful plan lengthjointly solved problems two planners.Similarly, per-problem ratio jointly successful runtimes (JSTIME-RATIO) definedmanner used comparing plan lengths. mean JSTIME-RATIO computedgeometric mean well-defined per-problem JSTIME-RATIO values.JSLEN-RATIO JSTIME-RATIO ratios two measurements, use geometric mean aggregate per-problem results generate sample value, whereas use arithmeticmean SR variables. Note geometric mean desired property planners tied overall (so geometric mean one), mean insensitive plannergiven denominator ratio.Thus, draw single sample four aggregate random variables (SR planner,JSLEN-RATIO, JSTIME-RATIO) comparing two planners, run two plannersproblem five times, computing per-problem values four variables, take (arith837fiW U , K ALYANAM , & G IVANmetic geometric) means per-problem variables get one sample aggregate variable. process used repeatedly draw many samples needed get significant results.use plan-length cutoff 2000 attempt. attempt given time limit 30minutes.5.5.2 IGNIFICANCE P ERFORMANCE IFFERENCES B ETWEEN P LANNERSgeneral goal order pairs planners overall performance category problem.this, must trade success rate plan length. take position significantadvantage success rate primary goal, plan length used determine preferenceamong planners success rate differences found significant.determine significance three performance measurements (SR, JSLENRATIO, JSTIME-RATIO) using t-tests, ascribing significance results p-valueless 0.05. exact hypothesis tested form t-test used depends performancemeasurement, follows:1. SR use paired one-sided t-test hypothesis difference true meanslarger 0.02.2. JSLEN-RATIO use one-sample one-sided t-test hypothesis true geometric mean JSLEN-RATIO exceeds 1.05 (log true mean JSLEN-RATIO exceedslog(1.05)).3. JSTIME-RATIO use one-sample one-sided t-test hypothesis truegeometric mean JSTIME-RATIO exceeds 1.05 (log true mean JSTIME-RATIOexceeds log(1.05)).stop sampling performance variables achieved one following criteria, representing SR winner determined SR appears tied:1. Thirty samples drawn p-value SR difference 0.05 0.5.2. Sixty samples drawn p-value SR difference 0.05 0.1.3. One hundred fifty samples drawn.experiments present next, stopping rule leads 30 samples drawnunless otherwise mentioned. Upon stopping, conclude ranking planners (namingwinner) either SR difference JSLEN-RATIO p-value 0.05, significantSR differences used first determine winner. neither measure significant uponstopping, deem experiment inconclusive.Combining categories evaluations, aggregate results across multiple categories problem, e.g., combined category PI PROBLEMS. cases, effectivelydefined one larger category, techniques defining performance measurements determining statistical significance Section 5.5. However, actually re-runplanners combined-category measurements. Instead, re-use planner runs usedsingle-category experiments. Rather use stopping rule described, computemaximum number runs available combined categories use many samples838fiS TOCHASTIC E NFORCED H ILL -C LIMBINGcombined-category performance measurements. avoid double counting problem results,treat combined categories separately analyzing results counting wins losses.6. Empirical Resultspresent performance evaluation stochastic enforced hill-climbing (SEH) section.experiments underlying results presented involve 169,850 planner runs 17 categories.6.1 Summary Comparisonresults Table 4 show that, CR-FF heuristic, SEH goal-ordering addedgoal-deletion enhancements (SEH+ (F )) improves significantly baseline SEH technique(SEH(F )) category B LOCKSWORLD, show significant changes aggregatedperformance non-blocksworld problems7 . remainder experiments involving CRFF, evaluate SEH+ (F ), noting comparison planners (FF-Replan RFF)benefit goal-ordering added-goal-deletion enhancements base planner, FFplan.results present next SEH+ (F ) show:SEH+ (F ) significantly outperforms Greedy(F ) 13 categories, outperformedGreedy(F ) CHEDULE. three categories comparison inconclusive (B USFARE, R IVER IREWORLD). See Table 5 details.FF-Replan inapplicable two categories (IPPC3 EARCH - -R ESCUE IPPC3YSADMIN). SEH+ (F ) significantly outperforms FF-Replan 10 categories, outperformed FF-Replan three categories (E XPLODING B LOCKSWORLD, P ITCHCATCH,Z ENOTRAVEL). two categories comparison inconclusive (F ILE WORLD R IVER ). SEH+ (F ) also significantly outperforms FF-Replan combinedcategory PI PROBLEMS, although winner varied aggregated categories. SeeTable 6 details.RFF-BG inapplicable two categories (B USFARE IPPC1 F ILEWORLD). SEH+ (F )significantly outperforms RFF-BG 12 categories, outperformed RFF-BG twocategories (E XPLODING B LOCKSWORLD YSTEMATIC - TIRE). one categorycomparison inconclusive (S YSADMIN). SEH+ (F ) also significantly outperforms RFF-BG combined category PI PROBLEMS, although winner variedaggregated categories. See Table 7 details.learned heuristic work Wu Givan (2010) computedsubset domains, hence seven categories applicable evaluation usinglearned heuristic (see online appendix details). results present next SEHlearned heuristic, SEH(L), show:SEH(L) significantly outperforms Greedy(L) six categories. one category(T IREWORLD) comparison inconclusive. See Table 8 details.7. show p-values rounded two decimal places. example, show p=0.00 value p rounded twodecimal places 0.839fiW U , K ALYANAM , & G IVANSRSRSEH+ (F ) SEH(F )CategoryJSLENRATIO(SEH/SEH+ )JSTIMERATIO(SEH/SEH+ )SRDifferenceSignificant?(p-value)JSLENRATIOSignificant?(p-value)WinnerB LOCKSWORLD0.930.721.582.85YES(p=0.00)YES(p=0.00)SEH+ (F )N - BLOCKSWORLD0.690.691.010.97(p=1.00)(p=1.00)InconclusiveTable 4: Aggregated comparison SEH+ (F ) SEH(F ).SEH(L) significantly outperforms FF-Replan five categories, outperformed FFReplan two categories (E XPLODING B LOCKSWORLD Z ENOTRAVEL). See Table 9details.6.2 Discussiondiscuss results comparisons pairs planners, including SEH versus greedyheuristic-following, SEH versus FF-Replan, SEH versus RFF-BG.6.2.1 SEH/SEH+ V ERSUS G REEDYprimary evaluation goal show stochastic enforced hill-climbing generally improvessignificantly upon greedy following heuristic (using policy Greedy(h) describedtechnical background above). demonstrated evaluating SEH two differentheuristics Tables 5 8, SEH(h) significantly outperforms Greedy(h) nineteentwenty-four heuristic/category pairs, losing CHEDULE SEH+ (F ) Greedy(F ).discuss category Greedy outperforms SEH techniques significantly.CHEDULE, multiple classes network packets different arrival rates. Packets deadlines, packet served deadline, agent encounters classdependent risk death well delay packet cleaned up. reach goalserving packet every class, agent must minimize dropping-related risk dyingwaiting arrival low-arrival-rate class. all-outcomes determinization underlyingCR-FF heuristic gives deterministic domain definition dying optional (never chosen)unlikely packet arrivals happen choice, leading optimistic heuristic value.using optimistic heuristic value, basic local goal SEH, improvecurrent state heuristic, leads building large local MDPs analysis. presencedead-ends (death, above), even arbitrarily large local MDPs may able achieve localimprovement, CHEDULE, SEH+ typically hit resource limit MDP sizeevery action step.contrast, greedy local decision making well suited packet scheduling. Many well knownpacket scheduling policies (e.g. earliest deadline first static priority work Liu &Layland, 1973) make greedy local decisions practically quite effective. experiments,Greedy policy applied CR-FF benefits locally seeking avoid incidental delaysdropped-packet cleanup: even though heuristic sees risk-of-dying cost dropping, stillrecognizes delay cleaning lost dropped packets. Thus, Greedy(F ) class-insensitive840fiS TOCHASTIC E NFORCED H ILL -C LIMBINGJSLENSRRATIOSRSEH+ (F ) Greedy(F ) (Greedy/SEH+ )CategoryJSTIMERATIO(Greedy/SEH+ )SRDifferenceSignificant?(p-value)JSLENRATIOSignificant?(p-value)WinnerB LOCKSWORLD0.930.351.400.63YES(p=0.00)YES(p=0.00)SEH+ (F )B OXWORLD0.990.051.181.12YES(p=0.00)YES(p=0.00)SEH+ (F )B USFARE1.000.990.850.86(p=0.97)(p=0.21)InconclusiveRIVE0.690.351.601.41YES(p=0.00)YES(p=0.00)SEH+ (F )E LEVATOR1.000.401.821.81YES(p=0.00)YES(p=0.00)SEH+ (F )E XPLODINGB LOCKSWORLD0.440.181.010.63YES(p=0.00)(p=0.93)SEH+ (F )F ILEWORLD1.000.211.030.24YES(p=0.00)(p=1.00)SEH+ (F )P ITCHCATCH0.450.00YES(p=0.00)R ANDOM0.990.941.760.59YES(p=0.00)YES(p=0.00)SEH+ (F )R IVER0.660.670.970.98(p=0.60)(p=0.75)InconclusiveCHEDULE0.540.601.180.32YES(p=0.00)YES(p=0.01)Greedy(F )EARCHR ESCUE1.001.001.231.08(p=1.00)YES(p=0.00)SEH+ (F )YSADMIN0.270.271.211.23(p=1.00)YES(p=0.00)SEH+ (F )YSTEMATIC- TIRE0.290.211.030.72YES(p=0.00)(p=0.86)SEH+ (F )IREWORLD0.910.900.960.79(p=0.93)(p=0.74)InconclusiveOWERSH ANOI0.530.00YES(p=0.00)0.900.201.310.74YES(p=0.00)Z ENOTRAVELYES(p=0.00)SEH+ (F )SEH+ (F )SEH+ (F )Table 5: Aggregated comparison SEH+ (F ) Greedy(F ). R IVER domain evaluation required extending sampling 60 samples per experimental protocol described Section 5.5.2. values p-values JSLEN-RATIO JSTIME-RATIO P ITCHCATCHOWERS H ANOI available due zero success ratio Greedy(F ) categories.841fiW U , K ALYANAM , & G IVANJSLENSRSRRATIOSEH+ (F ) FF-Replan (FFR/SEH+ (F ))CategoryJSTIMERATIO(FFR/SEH+ (F ))SRDifferenceSignificant?(p-value)JSLENRATIOSignificant?(p-value)WinnerB LOCKSWORLD0.930.871.331.17YES(p=0.00)YES(p=0.00)SEH+ (F )B OXWORLD0.990.883.931.57YES(p=0.00)YES(p=0.00)SEH+ (F )B USFARE1.000.010.000.00YES(p=0.00)RIVE0.690.541.262.42YES(p=0.00)YES(p=0.00)SEH+ (F )E LEVATOR1.000.930.950.93YES(p=0.00)(p=0.36)SEH+ (F )E XPLODINGB LOCKSWORLD0.440.440.850.56(p=0.96)YES(p=0.00)FF-ReplanF ILEWORLD1.001.000.970.57(p=1.00)(p=1.00)InconclusiveP ITCHCATCH0.450.512.780.21YES(p=0.00)YES(p=0.00)FF-ReplanR ANDOM0.990.961.370.19YES(p=0.00)YES(p=0.00)SEH+ (F )R IVER0.660.650.940.93(p=0.60)(p=0.33)InconclusiveCHEDULE0.540.481.040.10YES(p=0.00)(p=0.59)SEH+ (F )YSTEMATIC- TIRE0.290.070.360.38YES(p=0.00)YES(p=0.00)SEH+ (F )IREWORLD0.910.690.690.57YES(p=0.00)YES(p=0.00)SEH+ (F )OWERSH ANOI0.590.500.640.06YES(p=0.00)YES(p=0.00)SEH+ (F )Z ENOTRAVEL0.901.000.700.10YES(p=0.00)YES(p=0.00)FF-ReplanPIP ROBLEMS0.550.451.020.54YES(p=0.00)(p=1.00)SEH+ (F )SEH+ (F )Table 6: Aggregated comparison SEH+ (F ) FF-Replan (FFR). R ANDOM R IVERdomains required extending sampling 60 samples OWERS H ANOI domain requiredextending sampling 150 samples per experimental protocol described Section 5.5.2.p-value JSLEN-RATIO B USFARE available extremely low success rateFFR leads one sample JSLEN gathered 30 attempts, yielding estimatedvariance.842fiS TOCHASTIC E NFORCED H ILL -C LIMBINGSRSRSEH+ (F ) RFF-BGCategoryJSLENRATIO(RFF-BG/SEH+ (F ))JSTIMERATIO(RFF-BG/SEH+ (F ))SRDifferenceSignificant?(p-value)JSLENRATIOSignificant?(p-value)WinnerB LOCKSWORLD0.930.770.790.22YES(p=0.00)YES(p=0.00)SEH+ (F )B OXWORLD0.990.891.033.70YES(p=0.00)(p=1.00)SEH+ (F )RIVE0.690.611.071.24YES(p=0.00)(p=0.08)SEH+ (F )E LEVATOR1.001.001.270.15(p=1.00)YES(p=0.00)SEH+ (F )E XPLODINGB LOCKSWORLD0.440.430.840.56(p=0.92)YES(p=0.00)RFF-BGP ITCHCATCH0.450.00YES(p=0.00)R ANDOM0.990.741.260.56YES(p=0.00)YES(p=0.00)SEH+ (F )R IVER0.660.510.770.21YES(p=0.00)YES(p=0.00)SEH+ (F )CHEDULE0.540.431.060.08YES(p=0.00)(p=0.40)SEH+ (F )EARCHR ESCUE1.000.012.990.86YES(p=0.00)YES(p=0.00)SEH+ (F )YSADMIN0.270.271.109.31(p=1.00)(p=0.05)InconclusiveYSTEMATIC- TIRE0.290.811.224.49YES(p=0.00)YES(p=0.00)RFF-BGIREWORLD0.910.710.680.21YES(p=0.00)YES(p=0.00)SEH+ (F )OWERSH ANOI0.580.480.640.01YES(p=0.03)YES(p=0.00)SEH+ (F )Z ENOTRAVEL0.900.021.200.04YES(p=0.00)(p=0.27)SEH+ (F )PIP ROBLEMS0.550.510.910.50YES(p=0.00)YES(p=0.00)SEH+ (F )SEH+ (F )Table 7: Aggregated comparison SEH+ (F ) RFF-BG. R IVER OWERSH ANOI domains required extending sampling 60 samples per experimental protocol described Section 5.5.2. values p-values JSLEN-RATIO JSTIME-RATIO P ITCH CATCH available due zero success ratio RFF-BG category.843fiW U , K ALYANAM , & G IVANSRSEH(L)CategoryJSLENSRRATIOGreedy(L) (Greedy/SEH)JSTIMERATIO(Greedy/SEH)SRDifferenceSignificant?(p-value)JSLENRATIOSignificant?(p-value)WinnerB LOCKSWORLD1.001.007.003.69(p=1.00)YES(p=0.00)SEH(L)B OXWORLD0.890.895.000.55(p=1.00)YES(p=0.00)SEH(L)E XPLODINGB LOCKSWORLD0.100.021.091.00YES(p=0.00)(p=0.31)SEH(L)YSTEMATIC- TIRE0.340.140.750.39YES(p=0.00)YES(p=0.00)SEH(L)IREWORLD0.900.891.051.05(p=0.92)(p=0.60)InconclusiveOWERSH ANOI0.600.00YES(p=0.00)0.580.0313.255.66YES(p=0.00)Z ENOTRAVELYES(p=0.00)SEH(L)SEH(L)Table 8: Aggregated comparison SEH(L) Greedy(L). values JSLEN-RATIOJSTIME-RATIO p-value JSLEN-RATIO OWERS H ANOI available duezero success ratio Greedy(L) category.SRSEH(L)CategoryJSLENSRRATIOFF-Replan (FFR/SEH(L))JSTIMERATIO(FFR/SEH(L))SRDifferenceSignificant?(p-value)JSLENRATIOSignificant?(p-value)WinnerB LOCKSWORLD1.000.830.992.06YES(p=0.00)(p=1.00)SEH(L)B OXWORLD0.890.883.610.54(p=0.97)YES(p=0.00)SEH(L)E XPLODINGB LOCKSWORLD0.100.460.710.73YES(p=0.00)YES(p=0.00)FF-ReplanYSTEMATIC- TIRE0.340.100.280.18YES(p=0.00)YES(p=0.00)SEH(L)IREWORLD0.900.700.660.51YES(p=0.00)YES(p=0.00)SEH(L)OWERSH ANOI0.600.420.644.76YES(p=0.00)YES(p=0.00)SEH(L)0.581.000.580.03YES(p=0.00)YES(p=0.00)FF-ReplanZ ENOTRAVELTable 9: Aggregated comparison SEH(L) FF-Replan (FFR).844fiS TOCHASTIC E NFORCED H ILL -C LIMBINGpolicy greedily seeks avoid dropping, similar earliest deadline first. problemsSEH encounters evaluation CHEDULE suggest future work automatically recognizingdomains large MDP construction proving futile automatically reducing MDP sizelimits adapt performance towards behavior greedy policy. note across testedbenchmark domains heuristics, one domain/heuristic combinationphenomenon arose practice.6.2.2 SEH/SEH+ V ERSUS FF-R EPLANRFF-BGalso demonstrated performance improvement SEH+ (F ) best performing planners first three international probabilistic planning competitions, outperforming FF-Replanten fifteen categories losing three (E XPLODING B LOCKSWORLD, P ITCHCATCH,Z ENOTRAVEL), outperforming RFF-BG 12 15 categories losing E XPLODINGB LOCKSWORLD YSTEMATIC - TIRE. Additionally, SEH(L) outperforms FF-Replan fiveseven categories losing E XPLODING B LOCKSWORLD Z ENOTRAVEL. sectiondiscuss categories SEH+ (F ) SEH(L) lose FF-Replan RFF-BG.Z ENOTRAVEL logistics domain people transported cities via airplanesload/unload/fly action non-zero probability effect. result, takesuncertain number attempts complete task. domains probabilistic effect choice change change, all-outcome determinization leadssafe determinized plan FF-Replanone replanning needed reach goal.domains, including Z ENOTRAVEL, all-outcomes determinization provide effectiveway employ deterministic enforced hill-climbing problem. note though though,determinization still ignores probabilities action outcomes, lead badchoices domains (not Z ENOTRAVEL). deterministic stochastic enforcedhill-climbing must climb large basins Z ENOTRAVEL, substantial overhead stochastic backup computations basin expansion leads least constant factor advantage deterministic expansion. extension SEH might address problem successfully futureresearch would detect domains stochastic choice change non-change,handle domains emphasis determinization.E XPLODING B LOCKSWORLD variant blocks world two new predicates detonated destroyed. block detonate once, put-down, probability,destroying object placed upon. state resulting action depicted Figure 3 delete-relaxed path goal, actual path, state dead-end attractordelete-relaxation heuristics CR-FF. FF-Replan RFF-BG never select actionpath goal including action. SEH+ (F ) weak dead-end detection used experiments select dead action shown, resulting poor performancesituation arises. would possible use all-outcomes determinization improveddead-end detector conjunction SEH+ (F ) order avoid selecting actions.dead-end detection would carefully implemented managed control run-timecosts incurred SEH relies critically able expand sufficiently large local MDP regionsonline action selection.P ITCHCATCH, unavoidable dead-end states (used domain designers simulate cost penalties). However, CR-FF heuristic, based all-outcomes determinization, assigns optimistic values correspond assumed avoidance dead-end states.845fiW U , K ALYANAM , & G IVANCurrentStateb3b5b4b1b2b5b3b2b4Goal StatePathDestroyed TablePick table b3b3b5b4b1b2Destroyed TableFigure 3: illustration critical action choice SEH+ (F ) E XPLODING B LOCKSWORLDproblem (IPPC2 P1). middle state actual path goal delete-relaxed pathgoal. Due table exploded, block placed onto table, resultingmiddle state dead-end state. middle state dead-end attractive heuristicvalue without regard whether blocks shown remaining explosive charge not,state feature shown.result, local search SEH+ (F ) unable find expected improvement CR-FF values,falls back biased random walk domain. domain suggests, domains SEH+ (F ) performs weakly, work needed managing domainsunavoidable deadend states.two categories SEH(L) loses FF-Replan (E XPLODING B LOCKSWORLDZ ENOTRAVEL) also categories SEH+ (F ) loses FF-Replan. Greedily followinglearned heuristics two categories leads lower success ratio greedily following CRFF, suggesting significant flaws learned heuristics CR-FF. Although SEH ablegive least five-fold improvement greedy following, success ratio two categories, improvement large enough SEH(L) match performance SEH+ (F )FF-Replan, based relaxed-plan heuristic FF.SEH+ loses RFF YSTEMATIC - TIRE due weak performance Triangle Tireworld problems. Triangle Tireworld provides map connected locations arranged singlesafe path source destination, exponentially many shorter unsafe paths8 .Determinizing heuristics detect risk unsafe paths greedy followingheuristics lead planners (such SEH+ ) take unsafe paths, lowering success rate.results show SEH+ often repair flawed heuristic, Triangle Tireworld domain heuristic attracts SEH+ apparent improvements actually dead-ends.contrast, RFF designed increase robustness determinized plans high probability failure. RFF continue planning avoid failure rather relying replanningfailure. initial determinized plan high probability failure (relative RFFs8. safe path drawn following two sides triangular map, many unsafe paths interiortriangle. Safety domain represented presence spare tires repair flat tire 50%chance occurring every step.846fiS TOCHASTIC E NFORCED H ILL -C LIMBINGJSLENRATIO(FFR/SEH+ )JSTIMERATIO(FFR/SEH+ )SRDifferenceSignificant?(p-value)JSLENRATIOSignificant?(p-value)SRSEH+ (F )SRFFReplanB LOCKSWORLD0.700.370.720.88YES(p=0.00)YES(p=0.00)SEH+ (F )B OXWORLD0.670.345.020.98YES(p=0.00)YES(p=0.00)SEH+ (F )CategoryWinnerTable 10: Aggregated comparison SEH+ (F ) FF-Replan scaled-up problems.CategorySRSEH+ (F )SRRFFBGJSLENRATIO(RFFBG/SEH+ )JSTIMERATIO(RFFBG/SEH+ )SRDifferenceSignificant?(p-value)B LOCKSWORLD0.700.330.460.14YES(p=0.00)B OXWORLD0.670.000.8810.81YES(p=0.00)JSLENRATIOSignificant?(p-value)YES(p=0.00)WinnerSEH+ (F )SEH+ (F )Table 11: Aggregated comparison SEH+ (F ) RFF-BG scaled-up problems.threshold), RFF extends plan execution often detect need use longer,safe route.6.2.3 P ERFORMANCE L ARGE P ROBLEMSorder demonstrate advantages SEH emphasized problem size grows,present aggregated performance SEH+ (F ) additional large-sized problems generated using generators provided first IPPC. scaling experiments computationallyexpensive, run two domains widely evaluated planning literature: B LOCKSWORLD B OXWORLD (which stochastic version logistics).B LOCKSWORLD, generated 15 problems 25- 30-block problems. B OXWORLD,generated 15 problems size 20 cities 20 boxes. (Only one problem across threecompetitions reached size B OXWORLD, problem unsolved competitionwinner, RFF.) aggregated results FF-Replan RFF-BG presented Tables 1011. experiments scaled-up problems consumed 3,265 hours CPU timeshow SEH+ (F ) successfully completed majority attempts FF-Replan RFFsucceeded substantially less often9 .Note although FF heuristic good B OXWORLD logistics domains,failure all-outcomes determinization take account probabilities action outcomesquite damaging FFR B OXWORLD, leading planner often select action hoping9. statistical protocol requires 30 samples random variable averaging performance 5 solution attempts,planner problem. 45 problems 3 planners, yields 30*5*45*3=20,250 solution attempts,taking approximately 10 CPU minutes large problems.847fiW U , K ALYANAM , & G IVANlow-probability error outcome. note RFF uses most-probable-outcome determinizationsuffer issues FFR boxworld. Given high accuracyFF heuristic boxworld, believe ideas RFF likely re-implemented and/ortuned achieve better scalability boxworld problems. leave possibility directionfuture work understanding scalability RFF.7. Summaryproposed evaluated stochastic enforced hill-climbing, novel generalizationdeterministic enforced hill-climbing method used planner FF (Hoffmann & Nebel, 2001).Generalizing deterministic search descendant strictly better current stateheuristic value, analyze heuristic-based MDP around local optimum plateau reachedincreasing horizons seek policy expects exit MDP better valued state.demonstrated approach provides substantial improvement greedy hill-climbingheuristics created using two different styles heuristic definition. also demonstratedone resulting planner substantial improvement FF-Replan (Yoon et al., 2007)RFF (Teichteil-Konigsbuch et al., 2010) experiments.find runtime stochastic enforced hill-climbing concern domains.One reason long runtime number size local optima basins plateaus maylarge. Currently, long runtime managed primarily reducing biased random walkresource consumption exceeds user-set thresholds. possible future research direction regardingissue prune search space automatically state action pruning.Acknowledgmentsmaterial based upon work supported part National Science Foundation, UnitedStates Grant No. 0905372 National Science Council, Republic China (98-2811M-001-149 99-2811-M-001-067).ReferencesAarts, E., & Lenstra, J. (Eds.). (1997). Local Search Combinatorial Optimization. John Wiley &Sons, Inc.Barto, A. G., Bradtke, S. J., & Singh, S. P. (1995). Learning act using real-time dynamic programming. Artificial Intelligence, 72, 81138.Bertsekas, D. P. (1995). Dynamic Programming Optimal Control. Athena Scientific.Bertsekas, D. P., & Tsitsiklis, J. N. (1996). Neuro-Dynamic Programming. Athena Scientific.Bonet, B., & Geffner, H. (2005). mGPT: probabilistic planner based heuristic search. JournalArtificial Intelligence Research, 24, 933944.Bonet, B., & Geffner, H. (2006). Learning depth-first search: unified approach heuristic searchdeterministic non-deterministic settings, application MDPs. ProceedingsSixteenth International Conference Automated Planning Scheduling, pp. 142151.848fiS TOCHASTIC E NFORCED H ILL -C LIMBINGBryce, D., & Buffet, O. (2008). International planning competition uncertainty part: Benchmarksresults.. http://ippc-2008.loria.fr/wiki/images/0/03/Results.pdf.Buffet, O. (2011) Personal communication.Cerny, V. (1985). Thermodynamical approach traveling salesman problem: efficient simulation algorithm. J. Optim. Theory Appl., 45, 4151.Dean, T., Kaelbling, L. P., Kirman, J., & Nicholson, A. (1995). Planning time constraintsstochastic domains. Artificial Intelligence, 76, 3574.Domshlak, C., & Hoffmann, J. (2007). Probabilistic planning via heuristic forward searchweighted model counting. Journal Artificial Intelligence Research, 30, 565620.Fahlman, S., & Lebiere, C. (1990). cascade-correlation learning architecture. AdvancesNeural Information Processing Systems 2, pp. 524 532.Gardiol, N. H., & Kaelbling, L. P. (2003). Envelope-based planning relational MDPs. Proceedings Seventeenth Annual Conference Advances Neural Information ProcessingSystems.Gerevini, A., & Serina, I. (2003). Planning propositional CSP: Walksat local searchtechniques action graphs. Constraints, 8(4), 389413.Gordon, G. (1995). Stable function approximation dynamic programming. ProceedingsTwelfth International Conference Machine Learning, pp. 261268.Hansen, E., & Zilberstein, S. (2001). LAO*: heuristic search algorithm finds solutionsloops. Artificial Intelligence, 129, 3562.Hoffmann, J. (2003). Metric-FF planning system: Translating ignoring delete lists numericstate variables. Journal Artificial Intelligence Research, 20, 291341.Hoffmann, J., & Brafman, R. (2005). Contingent planning via heuristic forward search implicitbelief states. Proceedings 15th International Conference Automated PlanningScheduling.Hoffmann, J., & Brafman, R. (2006). Conformant planning via heuristic forward search: newapproach. Artificial Intelligence, 170(6-7), 507 541.Hoffmann, J. (2005). ignoring delete lists works: Local search topology planning benchmarks. Journal Artificial Intelligence Research, 24, 685758.Hoffmann, J., & Nebel, B. (2001). FF planning system: Fast plan generation heuristicsearch. Journal Artificial Intelligence Research, 14, 253302.Kautz, H., & Selman, B. (1992). Planning satisfiability. Proceedings Tenth EuropeanConference Artificial Intelligence (ECAI92).Kirkpatrick, S., Gelatt, Jr, C., & Vecchi, M. (1983). Optimization simulated annealing. Science,220, 671680.Little, I., & Thiebaux, S. (2007). Probabilistic planning vs replanning. Workshop InternationalPlanning Competition: Past, Present Future (ICAPS).Liu, C., & Layland, J. (1973). Scheduling algorithms multiprogramming hard-real-timeenvironment. Journal Association Computing Machinery, 20, 4661.849fiW U , K ALYANAM , & G IVANMahadevan, S., & Maggioni, M. (2007). Proto-value functions: Laplacian framework learning representation control Markov decision processes. Journal Machine LearningResearch, 8, 21692231.Nilsson, N. (1980). Principles Artificial Intelligence. Tioga Publishing, Palo Alto, CA.Puterman, M. L. (2005). Markov Decision Processes: Discrete Stochastic Dynamic Programming.John Wiley & Sons, Inc.Sanner, S., & Boutilier, C. (2009). Practical solution techniques first-order MDPs. ArtificialIntelligence, 173(5-6), 748788.Selman, B., Kautz, H., & Cohen, B. (1993). Local search strategies satisfiability testing.DIMACS Series Discrete Mathematics Theoretical Computer Science, pp. 521532.Sutton, R. S. (1988). Learning predict methods temporal differences. Machine Learning,3, 944.Sutton, R. S., & Barto, A. G. (1998). Reinforcement Learning: Introduction. MIT Press.Teichteil-Konigsbuch, F., Kuter, U., & Infantes, G. (2010). Incremental plan aggregation generating policies MDPs. Proceedings Ninth International Conference AutonomousAgents Multiagent Systems (AAMAS 2010), pp. 12311238.Tesauro, G., & Galperin, G. (1996). On-line policy improvement using Monte-Carlo search.NIPS.Wu, J., & Givan, R. (2007). Discovering relational domain features probabilistic planning.Proceedings Seventeenth International Conference Automated PlanningScheduling, pp. 344351.Wu, J., & Givan, R. (2010). Automatic induction Bellman-Error features probabilistic planning. Journal Artificial Intelligence Research, 38, 687755.Yoon, S., Fern, A., & Givan, R. (2007). FF-Replan: baseline probabilistic planning. Proceedings Seventeenth International Conference Automated Planning Scheduling, pp. 352358.Younes, H., Littman, M., Weissman, D., & Asmuth, J. (2005). first probabilistic trackinternational planning competition. Journal Artificial Intelligence Research, 24, 851887.850fiJournal Artificial Intelligence Research 42 (2011) 309-352Submitted 02/11; published 11/11Relevant Explanation Bayesian NetworksChanghe Yuancyuan@cse.msstate.eduDepartment Computer Science EngineeringMississippi State UniversityMississippi State, MS 39762Heejin Limhlim@ai.kaist.ac.krDepartment Computer ScienceKorea Advanced Institute Science TechnologyDaejeon, South Korea 305-701Tsai-Ching Lutlu@hrl.comHRL Laboratories LLCMalibu, CA 90265Abstractmajor inference task Bayesian networks explaining variables observed particular states using set target variables. Existing methods solvingproblem often generate explanations either simple (underspecified)complex (overspecified). paper, introduce method called Relevant Explanation (MRE) finds partial instantiation target variables maximizesgeneralized Bayes factor (GBF) best explanation given evidence. studyshows GBF several theoretical properties enable MRE automatically identify relevant target variables forming explanation. particular, conditionalBayes factor (CBF), defined GBF new explanation conditioned existingexplanation, provides soft measure degree relevance variables newexplanation explaining evidence given existing explanation. result, MREable automatically prune less relevant variables explanation. also showCBF able capture well explaining-away phenomenon often representedBayesian networks. Moreover, define two dominance relations candidatesolutions use relations generalize MRE find set top explanationsdiverse representative. Case studies several benchmark diagnostic Bayesiannetworks show MRE often able find explanatory hypothesesprecise also concise.1. IntroductionOne essential quality human experts ability explain reasoningpeople. comparison, computer expert systems still lack capability regard.Early medical decision-support systems MYCIN (Buchanan & Shortliffe, 1984)shown empirically comparable even better diagnostic accuracies domainexperts. However, physicians still reluctant use systems daily clinicalsettings. One major reason expert systems lack capability clearly explainadvice; physicians uncomfortable following piece advicefully understand (Teach & Shortliffe, 1981). capability explanation thus criticalsuccess decision-support system.c2011AI Access Foundation. rights reserved.fiYuan, Lim, & LuBayesian networks (Pearl, 1988) offer compact intuitive graphical representationsuncertain relations among random variables domain become basismany probabilistic expert systems (Heckerman, Mamdani, & Wellman, 1995b). Bayesiannetworks provide principled approaches finding explanations given evidence, e.g.,belief updating, Maximum Posteriori assignment (MAP), Probable Explanation(MPE) (Pearl, 1988). However, methods may generate explanations eithersimple (underspecified) complex (overspecified). Take medical diagnostic systemexample. system may contain dozens even hundreds potentially dependentdiseases target variables. Target variables defined variables diagnosticexplanatory interest. Belief updating finds singleton explanations ignoringcompound effect multiple diseases. MAP MPE consider effect findingfull configuration target variables, explanations often contain manyvariables. Although patient may one disease, almost neverdiseases one time long delay treatments long.desirable find explanations contain relevant diseases. diseasesexcluded medical tests treatments.paper, introduce method called Relevant Explanation (MRE)finds partial instantiation target variables maximizes generalized Bayesfactor (GBF) best explanation given evidence. study shows GBFseveral theoretical properties enable MRE automatically identify relevanttarget variables forming explanation. particular, conditional Bayes factor (CBF),defined GBF new explanation conditioned existing explanation, providessoft measure degree relevance variables new explanation explainingevidence given existing explanation. result, MRE able automatically pruneless relevant variables explanation. also show CBF able capture wellexplaining-away phenomenon often represented Bayesian networks. Moreover,define two dominance relations candidate solutions use relationsgeneralize MRE find set top explanations diverse representative.case studies show MRE performed well explanation tasks set benchmarkBayesian networks.remainder paper structured follows. Section 2 provides brief overviewliterature explanation, including scientific explanation, explanation artificialintelligence, relation causation explanation. Section 3 providesintroduction explanation Bayesian networks, especially methods explaining evidence. Section 4 introduces formulation Relevant Explanation discussestheoretical properties. section also discusses generalize MRE find settop explanations. Section 5 presents case studies MRE set benchmarkBayesian networks. Finally, Section 6 concludes paper.2. ExplanationExplanation topic full debate; fact, commonly accepted definitionexplanation yet. section provides brief overview major developmentsexplanation philosophy science artificial intelligence. brief discussionrelation causation explanation also included.310fiMost Relevant Explanation Bayesian Networks2.1 Scientific ExplanationExplanation focal subject philosophy science long time. goalexplanation simply describe world is, develop fundamentalscientific understanding world (Woodward, 2003) answer questionshappen? field hence named scientific explanation.One earliest model scientific explanation Deductive-Nomological (D-N)model (Hempel & Oppenheim, 1948). According D-N model, scientific explanationconsists explanandum, phenomenon explained, explanation (orexplanans), facts used explain explanandum. explanation successfullyexplain explanandum explanation true, explanation logically entailsexplanandum.However, every phenomenon expressed terms deterministic logic rules.Many phenomena inherently uncertain. Hempel (1965) modified D-N modelintroduced inductive-statistical (I-S) model. I-S model similar D-N modelexcept assumes probability logic rule capturing uncertaintylinking initial conditions phenomenon explained.D-N I-S models limitation allowing inclusion irrelevantfacts explanation, facts affect correctness rules (Suermondt, 1992). address shortcoming, Salmon (1970) introduced statisticalrelevance (S-R) model. S-R model requires explanation consistfacts statistically relevant explanandum. fact statistically relevantexplaining explanandum posterior probability fact observingexplanandum different prior probability. intuition behind S-R modelstatistically irrelevant facts, even though may high probabilities,constitute good explanation.Salmon (1984) introduced Causal-Mechanical (C-M) model explanation takeaccount causation. basic idea behind C-M model process explanation involves fitting explanandum causal structure domain tracingcauses may lead explanandum.many approaches well. Ketcher (1989) believes scientific explanation provide unified account natural phenomena world. VanFraassen (1980) believes explanation favor explanandum, i.e., explanation either increases probability explanandum decreases probabilitynearest competitor explanandum. Several mathematical theories explanatorypower also proposed Jeffreys (1935), Good (1977), Gardenfors (1988).2.2 Explanation Artificial Intelligencecomparison scientific explanation, researchers area artificial intelligencetaken much broader view explanation. Early development decision-support systems made clear decision-support systems intended replace humanexperts, rather provide advice second opinion expertsbetter performance. necessary decision-support systems capabilityexplain conclusions made conclusions appropriatedomain experts understand possibly follow advice (Dannenberg, Shapiro,311fiYuan, Lim, & Lu& Fries, 1979). decision-support system, presentation help users understanding conclusions system regarded explanation (Suermondt, 1992).example, explanation trace reasoning process system reachingconclusions (Suermondt, 1992), canned textual explanation abstract reasoningprocess (Bleich, 1972), verbal translation inference rules (Buchanan & Shortliffe,1984), visual display certain elements system helps user understandresults (Lacave, Luque, & Diez, 2007).Nevertheless, important form explanation artificial intelligence forming explanatory hypotheses observed facts, often called abductive inference (Peirce,1948). Many issues need consideration abductive inference. One issue defineexplain. every observation needs explanation. According Pierce (1948), common trigger abductive inference surprising fact observed, is, newlyobserved information conflict already known currently believed.words, requires explanation something causes someones cognitive dissonance explanandum rest belief (Gardenfors, 1988). alsoargued observations serve part explanation (Chajewska & Halpern,1997; Nielsen, Pellet, & Elisseeff, 2008). Suppose observe grass wet,rained. need explain rained. fact rained actuallyexcellent explanation grass wet (Nielsen et al., 2008). Therefore,potential distinction explanandum, i.e., observations explained,observations. Deciding explanandum may nontrivial task.explanandum decided, task reduces finding explanatory hypothesisexplanandum. issue define good explanation is. good explanation able provide sort cognitive relief, is, explanationdecrease surprise value caused observation explanandum. Intuitively,value explanation degree explanation decreases surprisevalue. Many different criteria used existing explanation methods, includingweight evidence (Good, 1985), probability (Pearl, 1988), explanatory power (Gardenfors,1988), likelihood evidence (de Campos, Gamez, & Moral, 2001), causal informationflow (Nielsen et al., 2008). One goal paper study compare propertiesmeasures.Moreover, quality explanation also highly goal-dependent. resultingexplanations may vary level specificity scope depending objectivesexplanation task (Leake, 1995). example, explaining symptoms patient,doctor either find explanation constitutes diagnosis, i.e., explainingdiseases patient may have, provide explanation risk factors maycaused symptoms. Defining goal explanation task thus important.general overview explanation artificial intelligence. Section 3,provide detailed review one particular topic area: explanationBayesian networks.2.3 Causation Explanationagreed upon causation plays important role explanation helps generateintuitive explanations (Chajewska & Halpern, 1997; Halpern & Pearl, 2005; Nielsen et al.,312fiMost Relevant Explanation Bayesian Networks2008). However, considerable disagreement among researchers whether explanations causal distinction causal non-causal explanationsis. believe completely subsuming explanation causation typicallybroader view explanation. following arguments beliefexplanation tasks require causal meanings.First all, explanation much broader meaning AI. explanation tasksAI require causal meanings. example, verbal visual explanations oftenused decision-support systems illustrate concepts, knowledge, reasoning processes;seem causal meanings. insisted explanationscausal, explanation tasks may disallowed.Furthermore, many domains clear understandings causal relationsyet established. statistical relevance information. relevance information insufficient fully capture causal relations. Again, explanation maydisallowed altogether domains insist explanationscausal.Moreover, situation complicated fact still considerabledisagreement definition causation. Causal claims also vary drasticallyextent explanatorily deep enough (Woodward, 2003). some,sufficient causal explanation say rock broke window. others,merely descriptive statement; necessary resort deeper Newtonian mechanicsexplain rock broke window.Finally, legitimate why-questions causal require causal explanations.example, difference explanation belief explanationfact (Chajewska & Halpern, 1997). someone tells rained last nightask why, may give explanation grass wet. Another examplevariety physical explanations geometrical rather causalexplain phenomena using structure spacetime rather using forces energytransfer (Nerlich, 1979).goal paper take tall task settling debaterelation causation explanation. methods propose paperaimed general enough applicable causal non-causalsettings.3. Explanation Bayesian NetworksBayesian network directed acyclic graph (DAG) nodes denote random/chance variables, arcs lack denote qualitative relations amongvariables. dependence relations variables quantifiedconditional probability distributions, one variable conditioned parents. Figure 1(b) shows example Bayesian network. Bayesian network essentially encodesjoint probability distribution random variables domain serveprobabilistic expert system answer various queries domain.Unlike many machine learning methods mostly predictive methods, Bayesiannetwork used prediction explanation deep representationdomain. Explanation tasks Bayesian networks classified three categories;313fiYuan, Lim, & Luexplanation reasoning, explanation model, explanation evidence (Lacave &Diez, 2002). goal explanation reasoning Bayesian networks explainreasoning process used produce results credibility resultsestablished. reasoning Bayesian networks follows normative approach,explanation reasoning difficult explanation methods try imitatehuman reasoning (Druzdzel, 1996; Lacave & Diez, 2002). goal explanation modelpresent knowledge encoded Bayesian network easily understandable formsvisual aids experts users examine even update knowledge.example, graphical modeling tools GeNIe (Druzdzel, 1999), Elvira (Lacaveet al., 2007), SamIam (AR Group, UCLA, 2010) functionalities visualizingstrength probabilistic relations variables domain. goalexplanation evidence explain observed variables particularstates using variables domain. focus explanation evidenceresearch. Next review major methods explaining evidence Bayesiannetworks discuss limitations.3.1 Explanation EvidenceNumerous methods developed explain evidence Bayesian networks.methods make simplifying assumptions focus singleton explanations.example, often assumed fault variables mutually exclusive collectivelyexhaustive, conditional independence evidence given hypothesis (Heckerman, Breese, & Rommelse, 1995a; Jensen & Liang, 1994; Kalagnanam & Henrion, 1988).However, singleton explanations may underspecified unable fully explaingiven evidence evidence compound effect multiple causes.domain multiple dependent target variables, multivariate explanationsoften appropriate explaining given evidence. Maximum Posteriori assignment (MAP) finds complete instantiation set target variables maximizesjoint posterior probability given partial evidence variables. ProbableExplanation (MPE) (Pearl, 1988) similar MAP except MPE defines targetvariables unobserved variables. common drawback methodsoften produce hypotheses overspecified may contain irrelevant variablesexplaining given evidence.Everyday explanations necessarily partial explanations (Leake, 1995). difficultalso unnecessary account potential factors may relatedoccurrence event; desirable find relevant contributing factors. Variouspruning techniques used avoid overly complex explanations. methodsgrouped two categories: pre-pruning post-pruning. Pre-pruning methodsuse context-specific independence relations represented Bayesian networks pruneirrelevant variables (Pearl, 1988; Shimony, 1993; van der Gaag & Wessels, 1993, 1995)applying methods MAP generate explanations. example, Shimony (1993)defines explanation probable independence-based assignment completeconsistent respect evidence nodes. Roughly speaking, explanationtruth assignment variables relevant evidence nodes. ancestorsevidence nodes relevant. ancestor given node irrelevant independent314fiMost Relevant Explanation Bayesian Networksnode given values ancestors. However, independence relationsstrict unable prune marginally loosely relevant target variables.contrast, post-pruning methods first generate explanations using methodsMAP MPE prune variables important. example methodproposed de Campos et al. (2001). method first finds K probable explanations (K-MPE) given evidence, K user-specified parameter,simplify explanations removing unimportant variables one time. variableregarded unimportant removal reduce likelihood explanation.pointed Shimonys partial explanations necessarily concise (Chajewska & Halpern, 1997). explanation must include assignment nodesleast one path variable root, since relevant node, least oneparents must relevant. method de Campos et al. prune conditionallyindependent variables well. limitations methods addressed usingthresholding method allow pruning marginally relevant variables (Shimony, 1996;de Campos et al., 2001). However, modified methods involve manual settingtunable parameters, rather arbitrary subject human errors.Several methods use likelihood evidence measure explanatory powerexplanation (Gardenfors, 1988). Chajewska Halpern (1997) extend approachuse value pair <likelihood, prior probability> order explanations,forcing users make decisions clear order two explanations. Sincelikelihood measure allows comparing explanations contain different numbersvariables, potentially find concise explanations. practice methodsoften fail prune irrelevant variables, adding variables typicallyaffect likelihood.Henrion Druzdzel (1991) assume system set pre-defined explanationscenarios organized tree; use scenario highest posterior probabilityexplanation. method also allows comparing explanations different numbersvariables requires explanation scenarios specified advance.Flores et al. (2005) propose automatically create explanation tree greedilybranching informative variable step maintaining probabilitybranch tree certain threshold. pointed Flores et al.sapproach adds variables order informative remaining targetvariables, informative explanandum (Nielsen et al., 2008).results paper provide evidence drawback well. Moreover, criterionuse choose best explanation probability explanation givenevidence, makes ranking explanations extremely sensitive user-specifiedthreshold bounding probabilities branches. Nielsen et al. developed anothermethod uses causal information flow (Ay & Polani, 2008) select variablesexpand explanation tree. However, inherits drawback explanation tree-basedmethods essence greedy search methods; even though identify importantindividual variables, may fail recognize compound effect multiple variables.Furthermore, method also tunable parameters may subject human errors.Finally, since explanation explanation tree contain full branch startingroot, explanations may still contain redundant variables.315fiYuan, Lim, & LuInputBCOutput B(0.016)OutputInputC (0.15)Output COutputOutputB (0.1)Total Output(0.1)(a)(b)Figure 1: (a) electric circuit (b) corresponding diagnostic Bayesian network3.2 Explanation Two Benchmark Modelssection uses couple examples illustrate methods reviewedlast section work practice.3.2.1 Circuitfirst consider electric circuit Figure 1(a) (Poole & Provan, 1991). Gates A, B, C,defective closed. prior probabilities gates defective0.016, 0.1, 0.15, 0.1 respectively. also assume connectionsgates may fail small probabilities. circuit modeled diagnosticBayesian network shown Figure 1(b). Nodes A, B, C, correspond gatescircuit two states each: defective ok. others input outputnodes two states well: current noCurr. probabilitiesoutput nodes A, B, C, state current given parent nodesparameterized follows.P (Output B = current|B = def ective, Input = current) = 0.99;P (Output = current|A = def ective, Input = current) = 0.999;P (Output C = current|C = def ective, Output B = current) = 0.985;P (Output = current|D = def ective, Output B = current) = 0.995.Otherwise parent state current, output nodes statenoCurr probability 1.0. Finally, conditional probability table Total Outputnoisy-or gate (Pearl, 1988), means parent node state currentcauses Total Output state current independently parents.parent node state current, probability Total Outputstate current 0.0. individual effect parent nodes Total Outputparameterized follows.P (T otal Output = current|Output = current) = 0.9;316fiMost Relevant Explanation Bayesian NetworksP (T otal Output = current|Output C = current) = 0.99;P (T otal Output = current|Output = current) = 0.995.Suppose observe electric current flows circuit, meansnodes Input otal Output state current. Nodes A, B, C,logical choices target variables model. task find best explanatoryhypothesis explain observation electric current circuit. Domain knowledgesuggests three basic scenarios likely lead observation: (1)defective; (2) B C defective; (3) B defective.Given observation electric current, posterior probabilities A, B, C,defective 0.391, 0.649, 0.446, 0.301 respectively. Therefore, explanation(B) best single-fault explanation, B means B defective. However,B alone fully explain evidence; C involved. Actually,restrict defective states, (D) best singleton explanationprobability 0.699, clearly useful explanation evidence.MAP finds (A, B, C, D) best explanation. Given B C defective,arguable okay irrelevant explaining evidence. MAPintrinsic capability indicate part explanation important. SinceMPE assumes unobserved variables target variables, explanationeven redundancy.pre-pruning techniques unable prune target variable model context-specific independence target variables given evidence. method simplifying K-MPE solutions requires intermediate output nodesincluded explanatory variables. Since typically necessary considertarget variables, adapt method slightly simplify top K MAP solutionsinstead, refer K-MAP simplification method hereafter. best explanation found method (B, D). good explanation, although arguelater (B, C) better explanation.methods based likelihood evidence overfit choose (A, B, C, D)best explanation, probability evidence given targetvariables defective almost 1.0.explanation tree methods find (A) best explanation. (A) goodexplanation, (B, C) better explanation argue later.3.2.2 VacationConsider another example (Shimony, 1993). Mr. Smith considering taking strenuoushiking trips. decision go hiking depends health status. healthy,go hiking; otherwise, would rather stay home. Mr. Smith subject differentrisks dying depending health status spends vacation.relations variables best represented using Bayesian network Figure 2.conditional probabilities model parameterized follows:P (healthy) = 0.8;P (home|healthy) = 0.8;P (home|healthy) = 0.1;317fiYuan, Lim, & LuHealthyVacationlocationAliveFigure 2: Bayesian network vacation problem.P (alive|healthy, V acation location = ) = 0.99;P (alive|healthy, home) = 0.9;P (alive|healthy, hiking) = 0.1,* means value matter. totally 100 similar hikingtrails Mr. Smith choose from. model 100 hiking trips either differentstates variable Vacation location, one state named hiking. casehiking trails modeled different states, conditional probability given healthstatus distributed evenly across states. Shimony (1993) showed modelingchoice one-state vs. multi-state significantly affects best explanation MAP. GivenMr. Smith alive vacation, best explanation target variableset {Healthy, V acation location} changes (healthy, hiking) one-state model(healthy, home) multi-state model. rather undesirableexplanation totally change simply model refined.examine methods affected modeling choice.explanation tree method finds (hiking) explanation one-state model(healthy, home) multi-state model. explanations seem counterintuitive.causal explanation tree K-MAP simplification methods find (healthy)explanation two models.Mr. Smith died afterwards? interesting explanation taskoutcome surprising given low prior probability dying problem. MAPs explanation changed (healthy, hiking) one-state model (healthy, home)multi-state model. explanation tree method finds (hiking) one-state model(home) multi-state model, perplexing explanations. causal explanation tree method finds (healthy, hiking) one-state model (healthy, trip)multi-state model; K-MAP simplification method. causal explanation tree K-MAP simplification methods quite robust face refinementmodel; explanations also seem plausible. However, since 100 hiking tripsidentical multi-state model, hiking trip plugged explanation.means 100 equally good explanations. debatable whether specifichiking trip necessary detail needs included.318fiMost Relevant Explanation Bayesian Networksresults show existing explanation methods Bayesian networksoften generate explanations either underspecified overspecified. fail findright explanations contain relevant target variables.4. Relevant Explanation Bayesian NetworksUsers want accurate explanations want burdened unnecessary details.Bayesian network real-world domain may contain many target variables, typically target variables relevant explaining given evidence.goal research develop explanation method able automaticallyidentify relevant target variables forming explanation.first state several basic assumptions behind research. First, explanationtypically depends agents epistemic state (Gardenfors, 1988). assumeknowledge encoded Bayesian network constitutes complete epistemic stateexplainer. Second, assume explanandum specified observed statesset evidence variables explanation task. Third, assume Bayesiannetwork annotated set target variables clearly defined. setting,able focus important issue evaluate select bestexplanation. believe, however, proposed methodologies easily generalizedgeneral settings.4.1 Good Explanation?consider good explanation two basic properties: precise concise.Precise means explanation decrease surprise value explanandummuch possible. Many concepts used refer property,including confirmative (Carnap, 1948), sufficient (Khan, Poupart, & Black, 2009),relevant (Shimony, 1993). also regard high explanatory power (Gardenfors, 1988)referring preciseness explanation. Concise means explanationcontain relevant variables explaining evidence. similar anotherconcept called minimal (Khan et al., 2009).attempts capture preciseness conciseness single concept,including consistent (Pearl, 1988) coherent (Ng & Mooney, 1990). Pearl (1988) arguesexplanation needs internally consistent, taking sets factslikely true given evidence may produce reasonable results. However,putting consistent facts together necessarily lead either preciseness conciseness. example, two perfectly correlated facts consistent, necessarilyrelevant explaining evidence, adding explanation likely leadsredundancy. Ng Mooney (1990) define coherence metric measures wellexplanation ties various observations together. definition also seems likelylead simple explanations. However, definition based Horn-clause axiomscannot generalized probabilistic systems easily.addition, explanation method Bayesian networks able captureexplaining-away phenomenon often represented Bayesian networks. explaining-awayphenomenon refers situation effect multiple causes, observingeffect one causes reduces likelihood presence causes.319fiYuan, Lim, & Luexplaining-away phenomenon represented using collider structure (Pearl,1988), i.e., V structure single node multiple parents. desirable capturephenomenon order find explanations precise concise.4.2 Definition Explanation Evidencenote definition explanation full instantiation target variablesused MAP MPE quite restrictive. fundamentally limits capabilitymethods find concise explanations. approach define explanation follows.Definition 1 Given set target variables Bayesian network partial evidencee remaining variables, explanation evidence joint instantiation xnon-empty subset X target variables, i.e., X M.definition allows explanation partial instantiation target variables. Therefore, provides explanation method freedom choose targetvariables include.One key difference definition many existing methodsexisting definitions often built-in relevance measure optimized,definition treats partial instantiation target variables explanation.believe deciding relevance measure separate issue defining explanation.separation two issues allows us compare quality differentexplanations also generalize method find multiple top explanations.Note disallow disjunctives definition. agree HalpernPearl (2005) allowing disjunctive explanations causes technical philosophical problems. example explaining-away situation, effect may multiplepotential causes. Let number causes n. causes good explanation itself. allow disjunctives causes, totally 2n disjunctives.really difficult consider disjunctives. Philosophically, one causespresent, disjunctive includes cause part true well. uncleardisjunctive choose explanation. Besides, disjunctive multiplecauses seems equivalent claiming cause potential explanation. Separatingcauses individual explanations allows comparing explanations. unclearbenefits allow disjunctives.4.3 Relevance Measuresneed relevance measure evaluate quality explanation. measureable evaluate explanatory power explanation also favorconcise explanations relevant variables included explanation.Since dealing probabilistic expert systems, measure basedprobabilistic relations explanation explanandum (Chajewska &Halpern, 1997). also desirable probabilistic relation summarizedsingle number (Suermondt, 1992). Next discuss several popular relevance measuresorder motivate choice.One commonly used measure probability explanation given evidence,used MAP MPE find likely configuration set target variables.320fiMost Relevant Explanation Bayesian Networksrelying posterior probability, however, explanation may contain independentmarginally relevant events high probability. Methods use probabilityrelevance measure intrinsic capability prune less relevant facts.may argue variables selected target variables explanationfirst place. requires important task selecting relevant variablesrest shoulders users. explanation method effective,perform user task extracting essential knowledge simplepossible (Druzdzel, 1996). Moreover, shown earlier probability measurequite sensitive modeling choices; simply refining model dramatically changebest explanation.Another commonly used measure likelihood evidence variations.likelihood measure undesirable property called irrelevant conjunction (Chajewska &Halpern, 1997; Rosenkrantz, 1994), is, adding irrelevant fact valid explanationchange likelihood. property limits capability method basedmeasure find concise explanations. Another common drawback probabilitylikelihood measures focus measuring preciseness explanation;intrinsic mechanism achieve conciseness explanation. measureachieve preciseness conciseness time highly desirable.According Salmon (1984), order construct satisfactory statistical explanation,necessary factor prior posterior probabilities either explanandumexplanation. explanation result comparison priorposterior probabilities. comparative view explanation generates set possibilities.One form comparison difference prior posterior probabilities.However, inappropriate relevance measure according Good (1985). Considerincrease probability 1/2 3/4, 3/4 1. cases differenceprobabilities 1/4, degree relevance entirely different.Another possibility belief update ratio, define follows.Definition 2 Assuming P (x) 6= 0, belief update ratio x given e, r(x; e), definedP (x|e).(1)r(x; e)P (x)trivial mathematical derivation shows following also true.r(x; e) =P (e|x).P (e)(2)Therefore, belief update ratio equivalent ratio posterior priorprobabilities explanandum given explanation. clear ratiosproportional likelihood measure P (e|x) constant. therefore sharedrawbacks likelihood measure.Suermondt (1992) uses cross entropy prior posterior probabilitydistributions target variable measure influence evidence variabletarget variable. Cross entropy assigns large penalty incorrect statements certaintynear-certainty. However, measure used select influential evidencevariables, select specific states target variables explanation. Furthermore,321fiYuan, Lim, & Lupointed cross-entropy ideal measure symmetric;necessary keep track distribution represents origin comparisontimes.1935 paper (Jeffreys, 1935) book Theory Probability (Jeffreys, 1961),measure called Bayes factor proposed quantifying evidence favor scientifictheory. Bayes factor ratio likelihoods hypothesis alternativehypothesis. alternative hypothesis also simple statistical hypothesis, measuresimply likelihood ratio. cases either hypothesis unknown parameters,Bayes factor still form likelihood ratio, likelihoods obtainedintegrating parameter space (Kass & Raftery, 1995). logarithmBayes factor defined weight evidence independently Good (1950)Minsky Selfridge (1961). Similar cross-entropy, Bayes factor (or weightevidence) also assigns large values probabilities close certainty. drawbackBayes factor, however, difficult use measure compare twohypotheses (Suermondt, 1992); necessary pairwise comparisons multiplehypotheses.4.4 Generalized Bayes Factorslight modification, generalize Bayes factor compare multiple hypotheses. define generalized Bayes factor (GBF) following.Definition 3 generalized Bayes factor (GBF) explanation x given evidencee definedP (e|x),(3)GBF (x; e)P (e|x)x denotes set alternative hypotheses x.one hypothesis x X contains single binary variable. Otherwise,x catches alternative hypotheses x. catch-all form Bayes factorpreviously introduced Fitelson (2001). next sections, show GBFseveral desirable theoretical properties enable automatically identifyrelevant variables finding explanation. properties possessedsimple form Bayes factor prompt us give GBF new name emphasizeimportance.Note really need compute P (e|x) directly calculating GBF (x; e).trivial mathematical derivation showsP (x|e)(1 P (x)).(4)GBF (x; e) =P (x)(1 P (x|e))Therefore, GBF longer measure comparing different hypotheses, simplymeasure compares posterior prior probabilities single hypothesis. GBFhence able overcome drawback Bayes factor pairwise comparisonsmultiple hypotheses.Using x definition GBF catch alternative hypotheses enables GBFcapture property call symmetry explanatory power. Consider two complementary simple hypotheses H H following two distinct cases. first case,322fiMost Relevant Explanation Bayesian NetworksP (H) increases 0.7 0.8. increase goes hand hand decrease P (H)0.3 0.2. second case, P (H) increases 0.2 0.3, also goes handhand decrease P (H) 0.8 0.7. two cases completely symmetricother, indicates two Hs amount explanatorypower. GBF assigns score H cases. many relevance measuresprobability likelihood measure assign totally different scores.Besides Equation 4, GBF expressed forms, one following.P (x|e)/P (x|e).(5)GBF (x; e)P (x)/P (x)Essentially, GBF equal ratio posterior odds ratio x given eprior odds ratio x (Good, 1985). Therefore, GBF measures degree changeodds ratio explanation.GBF also calculated ratio belief update ratios xalternative explanations x given e, i.e.,GBF (x; e) =P (x|e)/P (x).P (x|e)/P (x)(6)multiple pieces evidence, GBF also calculated using chainrule similar joint probability distribution multiple variables. first defineconditional Bayes factor follows.Definition 4 conditional Bayes factor (CBF) explanation given evidence econditioned explanation x definedGBF (y; e|x)P (e|y, x).P (e|y, x)(7)Then, easy show following chain rule calculating GBFexplanation given set evidence true.GBF (x; e1 , e2 , ..., en ) = GBF (x; e1 )nGBF (x; ei |e1 , e2 , ..., ei1 ).(8)i=2chain rule especially useful multiple pieces evidence obtainedincrementally.4.4.1 Handling Extreme ValuesGBF assigns much weight probabilities ranges close 0 1. weightingconsistent decision-theoretic interpretation subjective probability 01 (Suermondt, 1992). belief probability event equal 1 meansone absolutely sure event occur. One probably would bet anything, includinglife, occurrence event. rather strong statement. Therefore,increase probability less one one decrease non-zero zeroextremely significant, matter small change is.323fiYuan, Lim, & LufffiFigure 3: GBF function prior probability given fixed increaseposterior probability prior. different curves correspond differentprobability increases. example, +0.01 means differenceposterior prior probabilities 0.01.following several special cases computing GBF face extreme probabilities.P (x) = 0.0, P (x|e) must equal zero well, yields ratiotwo zeros. commonly done, define ratio two zeros zero. Intuitively,impossible explanation never useful explaining evidence.P (x) = 1.0 P (x|e) = 1.0, ratio two zeros. Sinceexplanation true matter evidence is, useful explainingevidence either. case actually used counterexample using probabilityrelevance measure, fact explanation high posterior probabilitymay simply due high prior probability.P (x) < 1.0 P (x|e) = 1.0, GBF score equal infinity. factexplanation initially uncertainty becomes certainly true observing evidencewarrants explanation large GBF score.4.4.2 Monotonicity GBFstudy monotonicity GBF regard two relevance measures.first measure difference posterior prior probabilities. commonlybelieved amount difference probability ranges close zero onemuch significant ranges. prominent measure able capturebelief K-L divergence (Kullback & Leibler, 1951). measure explanatorypower also capture belief ranking explanations. Figure 3 shows plotGBF prior probability difference posterior priorprobabilities fixed. example, +0.01 means difference posterior324fiMost Relevant Explanation Bayesian NetworksfiffFigure 4: GBF function prior probability belief update ratiofixed. different curves correspond different belief update ratios.prior probabilities 0.01. figure clearly shows GBF assigns much higher scoresprobability changes close zero one.also study monotonicity GBF regard another measure, beliefupdate ratio defined Equation 1. Recall belief update ratio proportionallikelihood measure constant. likelihood measure, typically togetherpenalty term complexity model, popular metric used model selection. AICBIC (Schwartz, 1979) prominent examples. Next show GBF providesdiscriminant power belief update ratio (hence, also likelihood measureratio posterior prior probabilities evidence). followingtheorem. proofs theorems corollaries paper foundappendix.Theorem 1 explanation x fixed belief update ratio r(x; e) greater 1.0,GBF (x; e) monotonically increasing prior probability P (x) increases.Figure 4 plots GBF function prior probability fixing belief updateratio. different curves correspond different belief update ratios. GBF automaticallytakes account relative magnitude probabilities measuring qualityexplanation. prior probability explanation increases, ratio probability increase becomes significant. Therefore, explanations cannotdistinguished likelihood measure ranked using GBF. Since lower-dimensionalexplanations typically higher probabilities, GBF intrinsic capability penalize complex explanations. value pair <likelihood, prior probability> usedChajewska Halpern (1997) able produce partial orderings among explanations. sense, GBF addresses limitation integrating two valuessingle value produce complete ordering among explanations. Usersburden define complete ordering anymore.325fiYuan, Lim, & Lu4.4.3 Achieving Conciseness Explanationsection discusses several theoretical properties GBF. key property GBFable weigh relative importance multiple variables includerelevant variables explaining given evidence. following theorem.Theorem 2 Let conditional Bayes factor (CBF) explanation given explanation xless equal inverse belief update ratio alternative explanationsx, i.e.,1GBF (y; e|x),(9)r(x; e)GBF (x, y; e) GBF (x; e).(10)conditional independence relations Bayesian networks provide hard measure relevance explanation regard another explanation x; answereither yes no. contrast, GBF (y; e|x) able provide soft measure relevance explaining e given x. GBF also encodes decision boundary, inversebelief update ratio alternative explanations x given e. ratio used decideimportant remaining variables order included explanation.1, important enough included. Otherwise,GBF (y; e|x) greater r(x;e)excluded explanation. Simply dependent enough variableincluded explanation.Theorem 2 several intuitive desirable corollaries. first corollary states that,explanation x belief update ratio greater 1.0, adding independentvariable explanation decrease GBF score.Corollary 1 Let x explanation r(x; e) > 1.0, X, E, state,GBF (x, y; e) < GBF (x; e).(11)Therefore, adding irrelevant variable dilute explanatory power existingexplanation. GBF able automatically prune variables explanation.Note focus explanations belief update ratio greater 1.0.explanation whose probability change even decreases given evidenceseem able relieve cognitive dissonance explanandumrest beliefs. According Chajewska Halpern (1997), fact potentialexplanation equally less likely posteriori priori cause suspicion.philosophical literature, also often required posterior probabilityexplanandum least greater unconditional probability, learningexplanation increases probability explanandum (Gardenfors, 1988; Carnap,1948).Corollary 1 requires variable independent X E.assumption rather strong. following corollary shows result holdsconditionally independent E given x.326fiMost Relevant Explanation Bayesian NetworksCorollary 2 Let x explanation r(x; e) > 1.0, E|x, state,GBF (x, y; e) < GBF (x; e).(12)Corollary 2 general result Corollary 1 captures intuitionconditionally independent variables add additional information explanation explaining evidence. Note properties relative existing explanation.possible variable independent evidence given one explanation, becomes dependent evidence given another explanation. Therefore, selecting variablesone one greedily guarantee find explanation highest GBF.results relaxed accommodate cases posteriorprobability given e smaller prior conditioned x, i.e.,Corollary 3 Let x explanation r(x; e) > 1.0, state variableP (y|x, e) < P (y|x),GBF (x, y; e) < GBF (x; e).(13)intuitive result; state variable whose posterior probability decreasesgiven evidence part explanation evidence.applied GBF rank candidate explanations circuit example introducedSection 3. following shows partial ranking explanations highestGBF scores.GBF (B, C; e) > GBF (B, C, A; e), GBF (B, C, D; e) > GBF (B, C, A, D; e)(B, C) highest GBF score also conciseexplanations, indicates variables relevant explainingevidence (B, C) observed. results indicate GBF intrinsiccapability penalize higher-dimensional explanations prune less relevant variables,match theoretical properties well.4.5 Relevant Explanationtheoretical properties presented previous section show GBF plausiblerelevance measure explanatory power explanation. particular, showGBF able automatically identify relevant target variables findingexplanation. hence propose method called Relevant Explanation (MRE)relies GBF finding explanations given evidence Bayesian networks.Definition 5 Let set target variables, e partial evidenceremaining variables Bayesian network. Relevant Explanation problemfinding explanation x e maximum generalized Bayes factor scoreGBF (x; e), i.e.,RE(M; e) arg maxx,XM GBF (x; e) .(14)327fiYuan, Lim, & LuAlthough MRE general enough applied probabilistic distribution model,MREs properties make especially suitable Bayesian networks. Bayesian networksinvented model conditional independence relations random variablesdomain obtain concise representation domain alsoefficient algorithms reasoning relations variables. conciserepresentation Bayesian network also beneficial MRE following ways.First, MRE utilize conditional independence relations modeled Bayesiannetwork find explanations efficiently. example, Corollaries 1 2 usedprune independent conditionally independent target variablespartial instantiations target variables need considered searchsolution. independence relations identified graphical structureBayesian network may significantly improve efficiency searchexplanation.Second, similar chain rule Bayesian networks, chain rule GBF Equation 7 also simplified using conditional independence relations. computing GBF (x; ei |e1 , e2 , ..., ei1 ), may need condition subset evidence(e1 , e2 , ..., ei1 ). Conditioning fewer evidence variables allows reasoning algorithmsinvolve smaller part Bayesian network computing GBF score (Lin & Druzdzel,1998). One extreme case that, evidence variables independent givenexplanation, GBF explanation given evidence simply productindividual GBFs given individual piece evidence.GBF (x; e1 , e2 , ..., en ) =nGBF (x; ei ).(15)i=1Finally, MRE able capture well unique explaining-away phenomenonoften represented Bayesian networks. Wellman Henrion (1993) characterized explaining away negative influence two parents induced observationchild Bayesian network. Let B predecessors C graphical modelG. C observed equal c. Let x denote assignment Cs predecessors,denote assignment Bs predecessors. negative influence Bconditioned C = c meansP (B|A, c, x, y) P (B|c, x, y) P (B|A, c, x, y).(16)MRE captures explaining-away phenomenon well CBF. CBF provides measure relevant new variables explaining evidence conditionedexisting explanation. explaining-away situation, one causes already presentexplanation, causes typically receive high CBFs. fact, CBFcapture Equation 16 equivalent way shown following theorem.Theorem 3 Let B predecessors C Bayesian network. C observedequal c. Let x denote assignment Cs predecessors, denoteassignment Bs predecessors,P (B|A, c, x, y) P (B|c, x, y) P (B|A, c, x, y)GBF (B; c|A, x, y) GBF (B; c|x, y) GBF (B; c|A, x, y) .328(17)(18)fiMost Relevant Explanation Bayesian NetworksBayes factor<11 33 1010 3030 100>100Strength evidenceNegativeBarely worth mentioningSubstantialStrongstrongDecisiveTable 1: Bayes factor.consider circuit example, (B, C) (A) good explanationsevidence themselves; GBF scores (B, C) (A) given e42.62 39.44 respectively. Jeffreys (1961) recommends using Table 1 guidancedetermining significance Bayes factor value. use table judge GBFs,(B, C) (A) strong explanations. However, (B, C) alreadyobserved, GBF (A; e|B, C) equal 1.03, barely worth mentioning.results indicate GBF able capture explaining-away phenomenoncircuit example.4.6 K-MREmany decision making problems, decision makers typically would like multiple competingoptions choose from. Outputting best solution hence best practice.especially true multiple top solutions almost equally good.case, want know solution best, also much bettersolutions. difference first second best solutionslarge, gives decision makers confidence quality best solution. Moreover,finding multiple top solutions used sensitivity analysis method provide insightsensitive best explanations changes model parameters.naive approach finding top K MRE solutions select explanationshighest GBF scores. However, strategy may find explanations supersetstop explanations. consider circuit example. Table 2 listsexplanations highest GBF scores. Simply relying scores producefollowing rather similar top four explanations: (B, C), (A, B, C), (B, C, D),(A, B, C, D). explanations essentially cover basic scenarioB C defective. search list findingtwo basic scenarios: defective, B defective.often critical achieve diversity goal find multiple solutions.example, argued diversity important recommender systems (Smyth & McClave, 2001). rather similar set recommendations give users useful setalternatives choose from. believe holds finding explanations.order find set top explanations diverse representative, definetwo dominance relations among candidate solutions MRE. first relation strongdominance.329fiYuan, Lim, & LuExplanations(B, C)(A, B, C)(B, C, D)(A, B, C, D)(A)(A, B)(A, C)(B, D)GBF42.6242.1539.9339.5639.4436.9835.9935.88Table 2: explanations highest GBF scores Circuit network. explanations boldface top minimal explanations.Definition 6 explanation x strongly dominates another explanationx GBF (x) GBF (y).x strongly dominates y, x clearly better explanation y,higher equal explanatory score also concise. need includex top explanation set. second relation weak dominance.Definition 7 explanation x weakly dominates another explanationx GBF (x) > GBF (y).case, x larger GBF score y, concise. possibleinclude let decision maker decide whether prefersconciseness higher score. However, believe need include x,higher GBF score indicates extra variables X importantexplaining given evidence.Based two kinds dominance relations, define concept minimal.Definition 8 explanation minimal neither strongly weakly dominatedexplanation.new K-MRE approach defined minimal explanationsincluded top set. circuit network, since (A, B, C), (B, C, D),(A, B, C, D) strongly dominated (B, C), need consider (B, C)among them. Similarly, (A, B) (A, C) strongly dominated (A), (A)included top set. Finally, get set top explanations shown boldfaceTable 2. clearly diverse representative original set containsdominated explanations.dominance relations defined restricted GBF; also applicablerelevance measures. example, potentially help methods basedlikelihood measure find concise explanations.330fiMost Relevant Explanation Bayesian Networks5. Case Studiestested MRE explanation tasks set benchmark Bayesian networksliterature, including Circuit (Poole & Provan, 1991), Vacation (Shimony, 1993), Academe(Flores et al., 2005), Asia (Lauritzen & Spiegelhalter, 1988), Circuit2 (Darwiche, 2009).networks annotated variables classified three categories:target, observation, auxiliary. target node, also named fault, usually representsdiagnostic interest (e.g., health status engine). observation node usuallyrepresents symptom (e.g., observing excessive smoking engine exhaust), built-inerror message (e.g., status power supply), test (e.g., measuring voltagebattery). node neither target observation classified auxiliary node.compared K-MRE several existing explanation methods, including K-MAP(Pearl, 1988), explanation tree (ET) (Flores et al., 2005), causal explanation tree (CET)(Nielsen et al., 2008), K-MAP simplification (K-SIMP) (de Campos et al., 2001). Several methods tunable parameters. explanation tree (ET) method twoparameters controlling growth explanation tree. One parameter thresholdvalue deciding whether target variable significant enough used expandbranch explanation tree; variable used average mutual information target variable unused target variables conditioned currentbranch larger equal threshold. parameter threshold valueprobability branch explanation tree. branch expandedprobability branch less threshold. set two parameters0.05 0 respectively. branch explanation tree marked posteriorprobability.causal explanation tree (CET) method one parameter, lower-boundthreshold causal information flow variable evidence conditionedcurrent branch. causal information flow larger equal threshold,variable used expand branch further. set threshold 0.01.branch causal explanation tree marked using log ratio posterior priorprobabilities evidence given branch.K-MAP simplification (K-SIMP) method also threshold value boundsreduction likelihood evidence simplifying explanation. deletingvariable reduces likelihood explanation within factor boundedthreshold, simplification allowed. set threshold value 0.05. keeptrack explanations highest likelihood values simplification.parameters methods set allow much expansion simplification possible. even so, ET CET methods may fail find significantvariable create even root explanation tree. happens, forcetwo methods generate least root node ignoring thresholds.5.1 Circuitcircuit network introduced Section 3, Table 3 lists top explanations foundK-MRE, K-MAP, K-SIMP. set K 3 throughout case studies. Figure 5shows explanation trees found ET CET methods.331fiYuan, Lim, & LuCircuitK-MREK-MAPK-SIMPExplanations(B, C)(A)(B, D)(A, B, C, D)(A, B, C, D)(A, B, C, D)(B, D)(B, C)(A)Scores42.6239.4535.880.01280.00990.00820.98180.96830.9014Table 3: Top explanations found K-MRE, K-MAP, K-SIMP Circuit networkgiven observation electric current. Note scores methodsfollowing different meanings: GBF MRE, probability MAP,likelihood evidence K-SIMP.K-MRE able find intuitive explanations Circuit network. (B, C)better explanation (A) (B, D), larger posterior probability two explanations (the posterior probabilities 0.394, 0.391,0.266 respectively), prior probabilities explanations 0.015, 0.016,0.01 respectively.explanations found K-MAP mostly consistent K-MRE found,although K-MAP solutions supersets K-MRE solutions. surprisingMAP find complete assignments target variables. MAP abilityindicate parts explanations important, believefundamental drawback MAP. Users burdened task identifyingimportant parts explanations.K-SIMP method first finds top K MAP solutions simplifiesdeleting variables reduce likelihood evidence much, any. settop solutions found K-SIMP K-MRE. results indicatesimplification method helped prune less relevant target variables Circuitnetwork. However, K-SIMPs ranking explanations different. (B, D) bestexplanation. number variables explanation also considered rankingcriterion explanations (de Campos et al., 2001), (A) becomes bestexplanation.ET method selects node root explanation tree. importantwhether closed significantly affects likelihood evidence. However, ET method selects variable second important variable,lead good explanation. Moreover, easy way extract top explanations explanation tree. ET method relies probability rankingexplanations. seems consider partial paths solutions.example, (A) higher probability (A) clearly good explanation.consider full paths root leaves, (A) best explanation.332fiMost Relevant Explanation Bayesian Networksok0.609def0.391def0.262ok-0.692defC4.610okdef0.3471.391(a)ok-1.913(b)Figure 5: (a) Explanation tree (b) causal explanation tree Circuit networkgiven observation electric current.Although (A, D) probability slightly smaller (A), goodexplanation all. Moreover, using probability rank explanations inevitably makesthreshold value bounding probabilities branches significant effectranking, believe fundamental flaw ET method.CET method also selects node root explanation tree. However,selects C second important variable, lead good explanation either. Since branches causal explanation tree marked log ratioposterior prior probabilities evidence, makes sense considerpartial branches explanations. top two explanations according CET method(A) (A, C), (A, C) clearly good explanation.explanation tree methods failed find either (B, C) (B, D) topexplanation. main reason greedy search methods. may goodidentifying individual variables important, often fail identifycompound effect multiple variables. Even though variable B may largeeffect A, forms excellent explanations together C D. explanation treemethods failed find variable pairs consider one variable time.5.2 VacationTwo versions vacation network introduced Section 3. One version modelspossible hiking trips one state named hiking, version models100 hiking trips separate identical states. networks, first considerscenario Mr. Smith alive vacation. Table 4 shows top explanationsK-MRE, K-MAP, K-SIMP, Figure 6 shows explanation trees ETCET methods.333fiYuan, Lim, & LuVacationK-MREK-MAPK-SIMPOne-state modelExplanationsScores(healthy)1.3378(home)1.0078(healthy, hiking) 0.6336(healthy, home)0.1584(healthy, home) 0.1440(healthy)0.9900(home)0.9450Multi-state modelExplanationsScores(healthy)1.3378(any trip)1.0034(healthy, home)0.1440(healthy, home)0.0792(healthy, trip) 0.0071(healthy)0.9900(home)0.9300Table 4: Top explanations found K-MRE, K-MAP, K-SIMP two Vacationnetworks given Mr. Smith alive vacation.K-MRE found two top explanations model explanationsGBFs less equal 1.0. (healthy) best explanation models.fact, explanation score models. Vacation location treatedK-MRE irrelevant probability staying alive regardlessMr. Smith decides spend vacation. Although second best explanation changed(home) (any tip), note explanations GBF scores close 1.0barely worth mentioning according Table 1. Actually best explanations alsoGBFs slightly 1.0 interesting explanations either. reasonMr. Smiths alive vacation surprising event; realneed explaining observation.K-MAP extremely sensitive modeling choice. best explanation change (healthy, hiking) (healthy, home), also highest probabilitydecreased significantly 0.6336 0.1440. (healthy, home) ranked third onestate model, became best explanation multi-state model.Although K-SIMP method started simplifying top three explanationsK-MAP, ended two explanations models. simplification method resulted duplicate solutions. Otherwise, simplification methodquite robust face modeling choice; (healthy) best explanationmodels.ET method produced similar trees models. However, selects Vacationlocation important variable. counterintuitive Vacation locationeven affect probability Mr. Smith alive healthy. resultindicates mutual information target variables good indicatorrelevance explaining evidence. Also, unclear explanationsextract tree. rely probability selecting full branches,select (hiking) one-state model (healthy, home) multi-state model.Neither good explanation Mr. Smiths alive vacation.causal explanation tree method also robust face modeling choice.selects Healthy important variable. also finds (healthy) bestexplanation models.334fiMost Relevant Explanation Bayesian NetworksHealthyVacation location-0.345homehiking0.3220.075Vacation location0.678Healthyhome hikingyes-0.0630.1690.153yes(a) ET one-state model-3.233(b) CET one-state modelHealthyVacation location-0.345hometrip0.2370.153Vacation location0.008Healthy0.075home tripyes-0.0630.084(c) ET multi-state modelyes-3.233(d) CET multi-state modelFigure 6: Explanation trees (ET) causal explanation trees (CET) Vacationnetworks give Mr. Smith alive vacation.Next consider scenario Mr. Smith died vacation. Table 5Figure 7 show explanations found various methods observation.MRE finds (healthy, hiking) best explanation one-state model(healthy) multi-state model. rather intuitive result. one-statemodel, hiking likely event significantly increases chance Mr. Smiths deathunhealthy. multi-state model, however, hiking trails modeledindividual states, rather low prior posterior probabilities. result, MRE considered individual hiking trips unimportant details excludedbest explanation. may argue individual hiking tripeffect hiking state one-state model. However, reasoning ignores priorprobabilities explanations essentially supports use likelihood measure335fiYuan, Lim, & LuVacationK-MREK-MAPK-SIMPOne-state modelExplanationsScores(healthy, hiking)36.00(healthy, hiking)(healthy, home)(healthy, hiking)(healthy, hiking)(healthy)(hiking)0.03600.01600.00640.90000.26000.0624Multi-state modelExplanationsScores(healthy)26.0000(home)1.2310(healthy, home)0.0160(healthy, home)0.0008(healthy, trip)0.0004(healthy, trip)0.9000(healthy)0.2600(home)0.0700Table 5: Top explanations found K-MRE, K-MAP, K-SIMP two Vacationnetworks given Mr. Smith died vacation.select explanations. already discussed earlier, likelihood measuresignificant drawbacks.K-MAP shown sensitive modeling choice. best explanationchanged (healthy, hiking) one-state model (healthy, home) multistate model. (healthy, home) good explanation staying home reduceslikelihood Mr. Smiths death vacation.K-SIMP method selects (healthy, hiking) one-state model (healthy,trip) multi-state model. Therefore, 100 best explanations exactlyscore according method.ET method creates simple trees root models. However,variable chosen method counterintuitive. Vacation locationimportant variable explaining Mr. Smiths death.CET method made good choice selecting Healthy important variable. Similar K-SIMP, CET also included detailed vacation locations partexplanations, 100 best explanations score.5.3 AcademeFigure 8 shows Academe network introduced Flores et al. (2005) discussexplanation tree method. prior probability distributions four target variablesTheory, Practice, Extra, OtherFactors parameterized follows.P (T heory) < good, average, bad > = < 0.4, 0.3, 0.3 >;P (P ractice) < good, average, bad > = < 0.6, 0.25, 0.15 >;P (Extra) < yes, > = < 0.3, 0.7 >;P (OtherF actors) < plus, minus > = < 0.8, 0.2 >;conditional probabilities MarkTP, GlobalMark, FinalMark given parents parameterized follows.P (M arkT P = pass|T heory = bad P ractice = bad) = 0.0;336fiMost Relevant Explanation Bayesian NetworksHealthy2.115home hikinghome hiking0.2930.7370.707(a) ET one-state model-2.585Vacation locationVacation locationyes3.907(b) CET one-state modelHealthy2.115Vacation locationVacation location0.7370.007(c) ET multi-state model-2.585home triphome trip0.280yes3.907(d) CET multi-state modelFigure 7: Explanation trees (ET) causal explanation trees (CET) Vacationnetworks given Mr. Smith died vacation.P (M arkT P = pass|T heory = good, P ractice = good) = 1.0;P (M arkT P = pass|T heory = good, P ractice = average) = 0.85;P (M arkT P = pass|T heory = average, P ractice = good) = 0.9;P (M arkT P = pass|T heory = average, P ractice = average) = 0.2;P (GlobalM ark = pass|M arkT P = pass, Extra = ) = 1.0;P (GlobalM ark = pass|M arkT P = f ail, Extra = yes) = 0.25;P (GlobalM ark = pass|M arkT P = f ail, Extra = no) = 0.0;P (F inalM ark = pass|GlobalM ark = pass, OtherF actors = plus) = 1.0;P (F inalM ark = pass|GlobalM ark = pass, OtherF actors = minus) = 0.7;337fiYuan, Lim, & LuPracticeTheoryExtraMarkTPOtherFactorsGlobalMarkFinalMarkFigure 8: Academe network.AcademeK-MREK-MAPK-SIMPExplanations(bad theory)(bad practice, extra)(good theory, bad practice, minus otherF actors)(bad theory, good practice, extra, plus otherF actors)(bad theory, average practice, extra, plus otherF actors)(average theory, bad practice, extra, plus otherF actors)(bad theory, extra)(average theory, bad practice)Scores3.02052.29862.02090.09580.03990.03990.96000.7260Table 6: Top explanations found K-MRE, K-MAP, K-SIMP Academe network given FinalMark fail.P (F inalM ark = pass|GlobalM ark = f ail, OtherF actors = plus) = 0.05;P (F inalM ark = pass|GlobalM ark = f ail, OtherF actors = minus) = 0.0.consider problem finding explanations observation FinalMarkfail using target variable set {T heory, P ractice, Extra, OtherF actors}. Table 6Figure 9 show explanations found various methods observation.K-MRE selects (bad theory) best explanation failing final grade.good explanations contain bad theory part, (bad theory) dominatesexplanations. (bad practice) good explanation, combinationbad practice extra preparation turns better explanation.top three explanations found K-MAP probabilities smaller 0.1.general, highly domain-dependent probabilities mean good explanationsmean bad explanations. comparison, GBFs likelihood evidenceconsistent across different domains. Note claiming topexplanations ranked probability necessarily bad; believe probability maygood measure explanatory power explanation.K-SIMP method selects (bad theory, extra) best explanation. explanation good explanation itself. However, really explanation highest338fiMost Relevant Explanation Bayesian NetworksTheorygood-1.135Practiceaverage-1.360goodaverage-0.242Practicegoodaverage-1.728badbad0.911badPracticeOtherFactors-2.984good0.423Theoryaverage0.295plus-1.848Extra0.0300.054good average0.3390.0390.6130.911plusminus-2.433minus0.282Theorygood average badOtherFactors0.911bad0.115badyes0.141-2.151(a)Extra-0.257-1.736-0.380yes-2.736-2.321(b)Figure 9: (a) Explanation tree (b) causal explanation tree Academe networkFinalMark fail.likelihood. example, likelihood failing grade given (bad theory, bad practice,extra, minus otherF actors) equal 1.0, K-SIMP limited top solutionsfound K-MAP. Also, method ended two explanations,top two MAP solutions simplified explanation.ET method incorrectly selects Practice important variable; Theoryhigher impact final mark according model. Again, ETmethod measures importance target variable using mutual informationtarget variables, evidence variable. Recall made bad choicesAcademe Vacation networks well.CET method made sensible choice selecting Theory importantvariable. three equally good explanations according method: (bad theory),(average theory, bad practice), (good theory, bad practice). reasonmethod cannot distinguish explanations marks branches using logratio posterior prior probabilities evidence, proportionallikelihood measure.5.4 AsiaAsia network first introduced Lauritzen Spiegelhalter (1988) usedNielsen et al. (2008) discuss CET method. probabilities networkparameterized follows.P (V isitT oAsia = yes) = 0.01;P (Smoking = yes) = 0.5;P (T uberculosis = yes|V isitT oAsia = yes) = 0.05;339fiYuan, Lim, & LuVisitToAsiaTuberculosisLung_CancerSmokingDyspneaBronchitisTborCaX_RayFigure 10: Asia network.P (T uberculosis = yes|V isitT oAsia = no) = 0.01;P (LungCancer = yes|Smoking = yes) = 0.1;P (LungCancer = yes|Smoking = no) = 0.01;P (Bronchitis = yes|Smoking = yes) = 0.6;P (Bronchitis = yes|Smoking = no) = 0.3;P (T borCa = yes|T uberculois = yes LungCancer = yes) = 1.0;P (T borCa = yes|T uberculois = no, LungCancer = no) = 0.0;P (Dyspnea = yes|T borCa = yes, Bronchitis = yes) = 0.9;P (Dyspnea = yes|T borCa = yes, Bronchitis = no) = 0.7;P (Dyspnea = yes|T borCa = no, Bronchitis = yes) = 0.8;P (Dyspnea = yes|T borCa = no, Bronchitis = no) = 0.1;P (X ray = abnormal|T borCa = yes) = 0.98;P (X ray = abnormal|T borCa = no) = 0.05;consider two different observations Asia network: Dyspnea present, X-rayabnormal. Table 7 Figure 11 show explanations found various methodstwo observations using target variable set {Bronchitis, LungCancer, uberculosis}.interesting K-MRE obtained quite intuitive concise top explanationsobservations: (Bronchitis), (LungCancer), (T uberculosis). use disease nameBronchitis denote presence disease negation Bronchitisdenote absence disease. ranking explanations, however, different. first observation, (Bronchitis) better explanation Dyspnea(T uberculosis) (LungCancer) conditional probabilities show presence Bronchitis larger effect Dyspnea. second observation, TuberculosisLungCancer ancestors X-ray, Bronchitis direct effect X-rayreceives small GBF. reason (Bronchitis)s GBF still greater 1.0Bronchitis increases likelihood Smoking, turn increases likelihoodabnormal X-ray.K-MAP identified Bronchitis part best explanation first observation,included Bronchitis LungCancer part best explanationsecond observation, even though Bronchitis direct contributor abnormal340fiMost Relevant Explanation Bayesian NetworksAsiaK-MREK-MAPK-SIMPK-MREK-MAPK-SIMPExplanationsScoresDyspnea present(Bronchitis)(LungCancer)(T uberculosis)(LungCancer, uberculosis, Bronchitis)(LungCancer, uberculosis, Bronchitis)(LungCancer, uberculosis, Bronchitis)(LungCancer, Bronchitis)(Bronchitis)(T uberculosis)Abnormal X-ray(LungCancer)(T uberculosis)(Bronchitis)(LungCancer, uberculosis, Bronchitis)(LungCancer, uberculosis, Bronchitis)(LungCancer, uberculosis, Bronchitis)(LungCancer)(T uberculosis)6.13911.96781.82760.33130.05210.05210.90000.80800.432316.42319.68861.25350.03050.02610.02280.98000.1012Table 7: Top explanations found K-MRE, K-MAP, K-SIMP Asia networkgiven two different observations.X-ray. second best explanation first observation claims none diseasespresent, clearly good explanation.K-SIMP method found quite perplexing explanations observations. bestexplanation (LungCancer, Bronchitis) first observation (LungCancer)second observation. reason K-SIMP find good explanationsnetwork K-SIMP restricted solutions found K-MAP. methodstill able find (Bronchitis) second best explanation first observation,missed altogether second observation.ET method able find important variables explaining observations, fell short recognizing importance Tuberculosis explainingsecond observation. expanded LungCancer explaining first observation.CET method able find intuitive explanations. best explanations(Bronchitis) Dyspnea (LungCancer) abnormal X-ray. However, one drawbackexplanation tree tree structure requires explanation startroot. example, one explanations explaining Dyspnea (Bronchitis, LungCancer, uberculosis). arguable (T uberculosis) good explanationexplaining Dyspnea; really necessary include Bronchitis LungCancerpart explanation. believe another common drawback twoexplanation tree methods caused tree representation use.341fiYuan, Lim, & LuBronchitis-1.650yesBronchitis0.887LungCancer0.166yesLungCancer0.834yes-2.037yes0.683Tuberculosisyes0.1280.0380.683(a) ET Dyspnea-2.124(b) CET DyspneaLungCanceryesLungCanceryes0.4893.151-0.886Tuberculosisyes0.511(c) ET abnormal X-ray3.151-1.141(d) CET abnormal X-rayFigure 11: Explanation trees (ET) causal explanation trees (CET) found Asianetwork given two different observations.5.5 Circuit2Model-based diagnosis application abductive inference Horn-clause logic theories (Peirce, 1948; de Kleer & Williams, 1987), tries find minimal set assumptions that, together background knowledge, logically entail observations needexplanation. However, methods model-based diagnosis developed based logictheories. Entailment either true false logic systems. methods cannoteasily generalized probabilistic expert systems Bayesian networks. contrast,342fiMost Relevant Explanation Bayesian NetworksB12CBOK_1OK_2OK_3C3EE(a)(b)Figure 12: (a) digital circuit Darwiche (2009) (b) corresponding Bayesiannetwork.Circuit Figure 12K-MREK-MAPK-SIMPExplanations(OK3 )(OK1 , OK2 )(OK1 , OK2 , OK3 )(OK1 , OK2 , OK3 )(OK1 , OK2 , OK3 )(OK3 )(OK1 , OK2 )Scores4.00002.00000.12500.12500.12501.00001.0000Table 8: Top explanations found K-MRE, K-MAP, K-SIMP Circuit2 networkgiven output observed low.MRE easily applied model-based diagnostic systems faulty behaviorscomponents also specified.consider digital circuit Figure 12(a) used Darwiche (2009) discussmethods model-based diagnosis. Gates 1 2 inverters, gate 3gate. prior probability gates abnormal 0.5. inverterabnormal, outputs low input low, outputs high probability 0.5input high. gate abnormal, always outputs low. digitalcircuit modeled Bayesian network Figure 12(b). consider caseoutput E observed low. two kernel model-based diagnoses (OK1 , OK2 )(OK3 ). Table 8 Figure 13 show explanations found various methodsobservation using target variable set {OK1 , OK2 , OK3 }.K-MRE able find two kernel diagnoses top two explanations,(OK3 ) receives higher GBF (OK1 , OK2 ). higher GBF score due(OK3 )s higher prior posterior probabilities (OK1 , OK2 ). comparison,methods model-based diagnosis typically treat two explanations equally good.343fiYuan, Lim, & LuOK_2yes0.600OK_30.400yes0.400OK_10.200OK_20.200yes-0.3220.2630.200(a)yes(b)Figure 13: (a) Explanation tree (b) causal explanation tree Circuit2 networkgiven output observed low.K-MAP able single two kernel diagnoses. fact, many MAP solutionsposterior probability, including explanation gatesdefective.K-SIMP method found two explanations K-MRE. Therefore, simplification method helped simplifying explanations network. However, K-SIMPable rank two explanations either.two explanation tree methods completely misfired network. unclearmake sense explanation tree ET method Figure 13(a). causalexplanation tree Figure 13(b) expanded variable OK 2 failed findkernel diagnoses. Again, explanation tree methods greedy searchmethods cannot recognize compound effect multiple variables.5.6 Summary Case Studiescase studies show K-MRE able identify relevant target variablesfind concise intuitive explanations methods. GBF seemsplausible measure explanatory power achieve preciseness concisenessexplanations time. Another advantage GBF use Table 1general guidance determining significance explanations found K-MRE.contrast, probability seems good measure explanatory power. Methods344fiMost Relevant Explanation Bayesian Networksbased probability, K-MAP, quite sensitive modeling choices; alsolack capability indicate important parts explanations. K-MAPsimplification method shown often able simplify solutions K-MAPget concise explanations. fundamental drawback restrictedsolutions found K-MAP may able find best explanations. Also,may reduce multiple top MAP solutions explanation. ET methoduses mutual information target variables criterion select targetvariables explain evidence. criterion shown effective. Also,using probability rank explanations makes ET method sensitiveuser-specified threshold value bounding probabilities branches. CETmethod good identifying individual target variables important, oftenfails recognize significant compound effect multiple variables.CET method, well ET method, based greedy search considersone variable time. Another common drawback explanation tree methodstree representation fundamentally limits capability methods find conciseexplanations.6. Concluding Remarkspaper, introduced Relevant Explanation (MRE) method findingexplanations given evidence Bayesian networks. study shows MREseveral desirable theoretical properties enable MRE automatically identifyrelevant target variables find explanation evidence. MRE also ablecapture unique explaining-away phenomenon often represented Bayesian networks.defined two dominance relations among MRE solutions used developK-MRE method find set top MRE solutions diverse representative.results case studies set benchmark Bayesian networks agree quite welltheoretical understandings MRE. Another contribution researchalso made clear properties drawbacks several existing relevance measuresexplanation methods.Acknowledgmentsresearch supported National Science Foundation grants IIS-0842480, IIS0953723, EPS-0903787. Part research previously presented DX07 (Yuan & Lu, 2007), AAAI-08 (Yuan & Lu, 2008), UAI-09 (Yuan, Liu, Lu, & Lim, 2009),ExaCt-09 (Yuan, 2009). thank editors anonymous reviewersconstructive comments.Appendix A. Proofsfollowing proofs theorems corollaries.345fiYuan, Lim, & LuA.1 Proof Theorem 1Proof: likelihood measure expressedP (e|x) =P (x|e)P (e)= r(x; e)P (e).P (x)Therefore, fixed likelihood P (e|x) indicates belief update ratio r(x; e) remainsconstant prior posterior probabilities may vary. Furthermore, GBFexpressed follows.GBF (x; e) = 1 +r(x; e) 1.1 r(x; e)P (x)Therefore, GBF monotonically non-decreasing fixed belief update ratio r(x; e)greater equal 1.0 prior posterior probabilities increase.2A.2 Proof Theorem 2Proof:GBF (x, y; e) ===P (x, y|e)(1 P (x, y))P (x, y)(1 P (x, y|e))P (x|e)P (y|x, e)(1 P (y|x)P (x))P (x)P (y|x)(1 P (y|x, e)P (x|e))1P (x|e) 1 P (x) + P (y|x) 1P (x) 1 P (x|e) +1P (y|x,e)1equation less equal GBF (x; e)1P (y|x) 11P (y|x,e) 1P (y|x, e)(1 P (y|x))P (y|x)(1 P (y|x, e))CBF (y; e|x)1 P (x)1 P (x|e)P (x)P (x|e)1.r(x; e)2A.3 Proof Corollary 1Proof: corollary follows Theorem 2. present another way prove it.GBF (x, y; e) ===P (x, y|e)(1 P (x, y))P (x, y)(1 P (x, y|e))P (x|e)P (y)(1 P (y)P (x))P (x)P (y)(1 P (y)P (x|e))P (x|e)(1 P (y)P (x)).P (x)(1 P (y)P (x|e))346fiMost Relevant Explanation Bayesian NetworksP (x|e) > P (x),GBF (x, y; e) ==<=P (x|e)(1 P (y)P (x))P (x)(1 P (y)P (x|e))P (x|e)(1 P (x) + (1 P (y))P (x))P (x)(1 P (x|e) + (1 P (y))P (x|e))P (x|e)(1 P (x) + (1 P (y))P (x))P (x)(1 P (x|e) + (1 P (y))P (x))P (x|e)(1 P (x))P (x)(1 P (x|e))GBF (x; e) .2A.4 Proof Corollary 2Proof: corollary proved similar way Corollary 1.GBF (x, y; e) ====P (x, y|e)(1 P (x, y))P (x, y)(1 P (x, y|e))P (x|e)P (y|x, e)(1 P (y|x)P (x))P (x)P (y|x)(1 P (y|x, e)P (x|e))P (x|e)P (y|x)(1 P (y|x)P (x))P (x)P (y|x)(1 P (y|x)P (x|e))P (x|e)(1 P (y|x)P (x)).P (x)(1 P (y|x)P (x|e))P (x|e) > P (x),GBF (x, y; e) ==<=P (x|e)(1 P (y|x)P (x))P (x)(1 P (y|x)P (x|e))P (x|e)(1 P (x) + (1 p(y|x))P (x))P (x)(1 P (x|e) + (1 p(y|x))P (x|e))P (x|e)(1 P (x) + (1 p(y|x))P (x))P (x)(1 P (x|e) + (1 p(y|x))P (x))P (x|e)(1 P (x))P (x)(1 P (x|e))GBF (x; e) .2A.5 Proof Corollary 3Proof:GBF (x, y; e) =P (x|e)P (y|x, e)(1 P (y|x)P (x))P (x, y|e)(1 P (x, y))=.P (x, y)(1 P (x, y|e))P (x)P (y|x)(1 P (y|x, e)P (x|e))347fiYuan, Lim, & LuP (y|x, e) P (y|x),GBF (x, y; e)P (x|e)(1 P (y|x)P (x))P (x|e)P (y|x)(1 P (y|x)P (x))=.P (x)P (y|x)(1 P (y|x)P (x|e))P (x)(1 P (y|x)P (x|e))P (x|e) > P (x),GBF (x, y; e) ==<=P (x|e)(1 P (y|x)P (x))P (x)(1 P (y|x)P (x|e))P (x|e)(1 P (x) + (1 p(y|x))P (x))P (x)(1 P (x|e) + (1 p(y|x))P (x|e))P (x|e)(1 P (x) + (1 p(y|x))P (x))P (x)(1 P (x|e) + (1 p(y|x))P (x))P (x|e)(1 P (x))P (x)(1 P (x|e))GBF (x; e) .2A.6 Proof Theorem 3Proof:C observed, following equality.P (B|A, x, y) = P (B|x, y) = P (B|A, x, y) = P (B|y).(19)Therefore,P (B|A, c, x, y) P (B|c, x, y) P (B|A, c, x, y)1 P (B|A, c, x, y) 1 P (B|c, x, y) 1 P (B|A, c, x, y)P (B|A,c,x,y)1P (B|A,c,x,y)P (B|A,c,x,y) 1P (B|A,x,y)1P (B|A,c,x,y) P (B|A,x,y)P (B|c,x,y)1P (B|c,x,y)P (B|A,c,x,y)1P (B|A,c,x,y)P (B|c,x,y) 1P (B|x,y)1P (B|c,x,y) P (B|x,y)P (B|A,c,x,y) 1P (B|A,x,y)1P (B|A,c,x,y) P (B|A,x,y)GBF (B; c|A, x, y) GBF (B; c|x, y) GBF (B; c|A, x, y).2ReferencesAR Group, UCLA (2010). Samiam: Sensitivity analysis, modeling, inference more..http://reasoning.cs.ucla.edu/samiam/index.php.Ay, N., & Polani, D. (2008). Information flows causal networks. Advances ComplexSystems (ACS), 11 (01), 1741.Bleich, H. L. (1972). Computer-based consultation: Electrolyte acid-base disorders.American Journal Medicine, 53 (3), 285 291.348fiMost Relevant Explanation Bayesian NetworksBuchanan, B., & Shortliffe, E. (Eds.). (1984). Rule-Based Expert Systems: MYCIN Experiments Stanford Heuristic Programming Project. Addison-Wesley, Reading,MA.Carnap, R. (1948). Logical Foundations Probability. 2nd ed. University Chicago Press,Chicago, IL.Chajewska, U., & Halpern, J. Y. (1997). Defining explanation probabilistic systems.Proceedings Thirteenth Annual Conference Uncertainty Artificial Intelligence (UAI97), pp. 6271, San Francisco, CA. Morgan Kaufmann Publishers.Dannenberg, A., Shapiro, A., & Fries, J. (1979). Enhancement clinical predictive abilitycomputer consultation. Methods Inf Med, 18 (1), 1014.Darwiche, P. A. (2009). Modeling Reasoning Bayesian Networks (1st edition).Cambridge University Press, New York, NY, USA.de Campos, L. M., Gamez, J. A., & Moral, S. (2001). Simplifying explanations Bayesianbelief networks. International Journal Uncertainty, Fuzziness Knowledge-BasedSystems, 9 (4), 461489.de Kleer, J., & Williams, B. C. (1987). Diagnosing multiple faults. Artificial Intelligence,32 (1), 97130.Druzdzel, M. J. (1996). Explanation probabilistic systems: feasible? work?.Proceedings Fifth International Workshop Intelligent Information Systems(WIS-96), pp. 1224, Deblin, Poland.Druzdzel, M. J. (1999). GeNIe: development environment graphical decision-analyticmodels. Proceedings 1999 Annual Symposium American MedicalInformatics Association (AMIA1999), p. 1206, Washington, D.C.Fitelson, B. (2001). Studies Bayesian Confirmation Theory. Ph.D. thesis, UniversityWisconsin, Madison, Philosophy Department.Flores, J., Gamez, J. A., & Moral, S. (2005). Abductive inference Bayesian networks:finding partition explanation space. Eighth European Conference Symbolic Quantitative Approaches Reasoning Uncertainty, ECSQARU05, pp.6375. Springer Verlag.Gardenfors, P. (1988). Knowledge Flux: Modeling Dynamics Epistemic States.MIT Press.Good, I. J. (1950). Probability Weighing Evidence. Griffin, London.Good, I. J. (1977). Explicativity: mathematical theory explanation statisticalapplications. Proceedings Explicativity: Mathematical Theory ExplanationStatistical Applications, Series A. Vol. 354, No. 1678, pp. 303330.Good, I. J. (1985). Weight evidence: brief survey. Bayesian Statistics, 2, 249270.349fiYuan, Lim, & LuHalpern, J. Y., & Pearl, J. (2005). Causes Explanations: Structural-Model Approach.Part II: Explanations. British Journal Philosophy Science, 56 (4), 889911.Heckerman, D., Breese, J., & Rommelse, K. (1995a). Decision-theoretic troubleshooting.Communications ACM, 38, 4957.Heckerman, D., Mamdani, E. H., & Wellman, M. P. (1995b). Real-world applicationsBayesian networks - introduction. Commun. ACM, 38 (3), 2426.Hempel, C. G. (1965). Aspects Scientific Explanation Essays PhilosophyScience. Free Press, New York, NY.Hempel, C. G., & Oppenheim, P. (1948). Studies logic explanation. Bobbs-Merrill,Indianapolis, IN.Henrion, M., & Druzdzel, M. J. (1991). Qualitative propagation scenario-based schemesexplaining probabilistic reasoning. Bonissone, P., Henrion, M., Kanal, L., &Lemmer, J. (Eds.), Uncertainty Artificial Intelligence 6, pp. 1732. Elsevier SciencePublishing Company, Inc., New York, N. Y.Jeffreys, H. (1935). Contribution discussion Fisher. Journal Royal StatisticalSociety, 98, 7072.Jeffreys, H. (1961). Theory Probability. Oxford University Press.Jensen, F. V., & Liang, J. (1994). drHugin: system value information Bayesiannetworks. Proceedings 1994 Conference Information Processing Management Uncertainty Knowledge-Based Systems, pp. 178183.Kalagnanam, J., & Henrion, M. (1988). comparison decision analysis expert rulessequential diagnosis. Proceedings 4th Annual Conference UncertaintyArtificial Intelligence (UAI-88), pp. 253270, New York, NY. Elsevier Science.Kass, R. E., & Raftery, A. E. (1995). Bayes factors. Journal American StatisticalAssociation, pp. 773795.Khan, O. Z., Poupart, P., & Black, J. P. (2009). Minimal sufficient explanations factoredmarkov decision processes. Proceedings Nineteenth International ConferenceAutomated Planning Scheduling, pp. 194200.Kitcher, P., & Salmon, W. (1989). Explanatory unification causal structureworld, pp. 410505. University Minnesota Press, Minneapolis, MN.Kullback, S., & Leibler, R. (1951). information sufficiency. Annals MathematicalStatistics, 22(1), 7986.Lacave, C., & Diez, F. (2002). review explanation methods Bayesian networks.Knowledge Engineering Review, 17, 107127.350fiMost Relevant Explanation Bayesian NetworksLacave, C., Luque, M., & Diez, F. (2007). Explanation Bayesian networks influencediagrams elvira. IEEE Transactions Systems, Man, Cybernetics, Part B:Cybernetics, 37 (4), 952 965.Lauritzen, S. L., & Spiegelhalter, D. J. (1988). Local computations probabilitiesgraphical structures application expert systems. Journal RoyalStatistical Society, Series B (Methodological), 50 (2), 157224.Leake, D. B. (1995). Abduction, experience, goals: model everyday abductiveexplanation. Journal Experimental Theoretical Artificial Intelligence, 7,407428.Lin, Y., & Druzdzel, M. J. (1998). Relevance-based sequential evidence processingBayesian networks. Proceedings Uncertain Reasoning Artificial Intelligencetrack Eleventh International Florida Artificial Intelligence Research Symposium(FLAIRS98), pp. 446450, Menlo Park, CA. AAAI Press/The MIT Press.Minsky, M., & Selfridge, O. (1961). Learning random nets. Addison-Wesley, Butterworth,London.Nerlich, G. (1979). Time direction conditionship. Australasian JournalPhilosoph, 57 (1), 314.Ng, H. T., & Mooney, R. J. (1990). role coherence abductive explanation.Proceedings Eighth National Conference Artificial Intelligence (AAAI-90),pp. 337342, Boston, MA.Nielsen, U., Pellet, J.-P., & Elisseeff, A. (2008). Explanation trees causal Bayesiannetworks. Proceedings 24th Annual Conference Uncertainty ArtificialIntelligence (UAI-08), pp. 427434.Pearl, J. (1988). Probabilistic Reasoning Intelligent Systems: Networks PlausibleInference. Morgan Kaufmann Publishers, Inc., San Mateo, CA.Peirce, C. (1948). Philosophy Peirce: Selected Writings, chap. Abduction induction. Harcourt, Brace Company, New York.Poole, D., & Provan, G. M. (1991). likely diagnosis?. Bonissone, P.,Henrion, M., Kanal, L., & Lemmer, J. (Eds.), Uncertainty Artificial Intelligence 6,pp. 89105. Elsevier Science Publishing Company, Inc., New York, N. Y.Rosenkrantz, R. D. (1994). Bayesian confirmation: Paradise regained. British JournalPhilosophy Science, 45(2), 467476.Salmon, W. (1970). Statistical explanation, pp. 2987. University Pittsburgh Press,Pittsburgh, PA.Salmon, W. (1984). Explanation Causal Structure World. Princeton University Press, Princeton, NJ.351fiYuan, Lim, & LuSchwartz, G. (1979). Estimating dimensions model. Ann. Stat., 6, 461464.Shimony, S. (1993). role relevance explanation I: Irrelevance statistical independence. International Journal Approximate Reasoning, 8 (4), 281324.Shimony, S. (1996). role relevance explanation II: Disjunctive assignmentsapproximate independence. International Journal Approximate Reasoning, 14 (1),2554.Smyth, B., & McClave, P. (2001). Similarity vs. diversity. Proceedings InternationalConference Case-based Reasoning (ICCBR-01), pp. 347361.Suermondt, H. (1992). Explanation Bayesian Belief Networks. Ph.D. thesis, StanfordUniversity, Palo Alto, California.Teach, R. L., & Shortliffe, E. H. (1981). analysis physician attitudes regardingcomputer-based clinical consultation systems. Computers biomedical research,international journal, 14 (6), 542558.van der Gaag, L., & Wessels, M. (1993). Selective evidence gathering diagnostic beliefnetworks. AISB Quarterly, pp. 2334.van der Gaag, L., & Wessels, M. (1995). Efficient multiple-disorder diagnosis strategicfocusing, pp. 187204. UCL Press, London.van Fraassen, B. (1980). Scientific Image. Oxford University Press, Oxford.Wellman, M., & Henrion, M. (1993). Explaining explaining away. IEEE TransactionsPattern Analysis Machine Intelligence, 15, 287291.Woodward, J. (2003). Scientific explanation. Zalta, E. N. (Ed.), Stanford Encyclopedia Philosophy (Winter 2003 Edition).Yuan, C. (2009). properties Relevant Explanation. Proceedings 21stInternational Joint Conference Artificial Intelligence ExaCt Workshop (ExaCt-09),pp. 118126, Pasadena, CA.Yuan, C., Liu, X., Lu, T.-C., & Lim, H. (2009). Relevant Explanation: Properties,algorithms, evaluations. Proceedings 25th Conference UncertaintyArtificial Intelligence (UAI-09), pp. 631638, Montreal, Canada.Yuan, C., & Lu, T.-C. (2007). Finding explanations Bayesian networks. Proceedings18th International Workshop Principles Diagnosis (DX-07), pp. 414419.Yuan, C., & Lu, T.-C. (2008). general framework generating multivariate explanationsBayesian networks. Proceedings Twenty-Third National ConferenceArtificial Intelligence (AAAI-08), pp. 11191124.352fiJournal Artificial Intelligence Research 42 (2011) 5590Submitted 04/11; published 09/11APP: Scalable Multi-Agent Path Planning AlgorithmTractability Completeness GuaranteesKo-Hsin Cindy WangAdi BoteaC INDY.WANG @ RSISE . ANU . EDU . AUDI .B OTEA @ NICTA . COM . AUNICTA & Australian National University,Canberra, AustraliaAbstractMulti-agent path planning challenging problem numerous real-life applications. Running centralized search A* combined state space units completecost-optimal, scales poorly, state space size exponential number mobile units.Traditional decentralized approaches, FAR W HCA *, faster scalable,based problem decomposition. However, methods incomplete provide guarantees respect running time solution quality. necessarily able tellreasonable time whether would succeed finding solution given instance.introduce APP, tractable algorithm multi-agent path planning undirected graphs.present basic version several extensions. low-polynomial worst-case upperbounds running time, memory requirements, length solutions. Even thoughalgorithmic versions incomplete general case, provides formal guaranteesproblems solve. version, discuss algorithms completeness respectclearly defined subclasses instances.Experiments run realistic game grid maps. APP solved 99.86% mobile units,1822% better percentage FAR W HCA *. APP marked 98.82%units provably solvable first stage plan computation. Parts APPs computationre-used across instances map. Speed-wise, APP competitive significantlyfaster W HCA *, depending whether APP performs computations scratch.data APP re-use preprocessed offline readily available, APP slowerfast FAR algorithm factor 2.18 average. APPs solutions average 20%longer FARs solutions 731% longer W HCA *s solutions.1. IntroductionPath planning important many real-life problems, including robotics, military operations, disaster rescue, logistics, commercial games. Single-agent path planning, size statespace bounded size map, tackled search algorithm A* (Hart,Nilsson, & Raphael, 1968). However, many units moving simultaneously insideshared space, problem becomes much harder. centralized search initial state goalstate difficult problem even inside fully known, two-dimensional environment representedweighted graph, one node occupied exactly one unit time. Assumingunits size, unit moves synchronously adjacent unoccupied node onetime step, problems state space grows exponentially number mobile units. Existinghardness results shown NP-complete decide solution k moves exists (Ratner & Warmuth, 1986), optimize solution makespan (Surynek, 2010b). versionproblem one robot movable obstacles several nodes, either robotc2011AI Access Foundation. rights reserved.fiWANG & B OTEAobstacle move adjacent vacant node per step, also NP-complete (Papadimitriou,Raghavan, Sudan, & Tamaki, 1994). Yet another version problem, determining solution exists moving two-dimensional rectangles different sizes inside box, shownPSPACE-hard, even without requiring optimality (Hopcroft, Schwartz, & Sharir, 1984). Despite completeness solution optimality guarantees, centralized A* search little practicalvalue multi-agent path planning problem, intractable even relatively small mapscollections mobile units.Scalability larger problems achieved decentralized approaches, decomposeglobal search series smaller searches significantly reduce computation. However,existing decentralized methods FAR (Wang & Botea, 2008) W HCA * (Silver, 2006)incomplete, provide formal criteria distinguish problem instancessuccessfully solved instances. Further, guarantees given respect runningtime quality computed solutions.work present algorithm combines strengths worlds: working wellpractice featuring theoretical tractability partial completeness guarantees. introduceAPP, tractable multi-agent path planning algorithm undirected graphs. problem instance, APP systematically identifies set units, contain units instance,guaranteed solved within low-polynomial time. sake clarity distinguishbasic version extended versions APP. APP provides formal guaranteesproblems solve. Basic APP algorithm complete class problems, calledLIDABLE, define Section 3. Extended versions algorithm enlarge completeness range, discussed Section 7, improve solution length, discussed Section 8.also evaluate version attempts solve units, provably solvable ones.Given problem graph nodes n mobile units, APPs worst case performancerunning time O(m2 n2 ), even smaller (e.g., O(max(mn2 , m2 log m))), dependingassumptions input instance. worst-case memory requirements within O(m2 n)even O(mn). upper bound solution length, measured total number moves,order O(m2 n2 ) even O(mn2 ). See Section 6 detailed discussion.APP keeps running costs low eliminating need replanning. path (u)unit u computed beginning. replanning required runtime. blank travelidea, inspired way blank moves around sliding tile puzzles, centerualgorithm. unit u progress current location liu next location li+1pathu(u) blank located (i.e., li+1 empty). Intuitively, next location currentlyoccupied another unit, APP tries bring blank along alternate path, outlined bolduuli+1without passing liu . possible, blankFigure 1, connects li1ubrought li+1 shifting units along alternate path, blank travels sliding tilepuzzle. ability bring blank next location key guarantee units progress. Formaldetails provided Section 5.performed detailed experiments, evaluating different versions APP comparingAPP fast incomplete methods FAR W HCA * grid maps. resultspresented Section 9. benchmark data (Wang & Botea, 2008) consist 100 2000 mobileunits uniformly randomly generated 10 game maps, 10 scenario instances per numberunits map. conclude extended APP significantly better success ratioscalability state-of-the-art incomplete decentralized algorithms. particular, APP solveshigher percentage units even crowded instances. Despite APPs incompleteness56fiM APP : CALABLE ULTI -AGENT PATH P LANNINGbulucbcFigure 1: left, unit u blocked a. blank found location l along alternatepath, marked bold contour. right: sliding b alongu . sake clarity simplicity,alternate path, blank brought li+1illustrate examples four-connected grid world.general case, algorithm marks 98.82% units provably solvable first stageplan computation. attempting solve units, provably solvable ones, APPsucceeds 99.86% units. comparison, FAR solved 81.87% units. W HCA * solved77.84% (with diagonal moves allowed) 80.87% (with diagonal moves) units. Evenchallenging instances 2,000 mobile units maps, 92% 99.7% mobile units testdata fall within APPs completeness range (i.e., provably solvable). terms percentage fully solved instances, version APP attempts solve units,provably solvable, successful 84.5% instances. significantly betterFAR (70.6%), W HCA * diagonal moves (58.3%), W HCA * diagonals (71.25%).Parts APPs computation re-used across instances map. instancessolved algorithms, APP competitive speed significantly faster W HCA *, depending whether APP performs computations scratch. re-usable dataavailable, APP slower fast FAR algorithm factor 2.18 average. APPssolutions reported average 20% longer FARs solutions 731% longerW HCA *s solutions.Parts work reported shorter conference papers follows. theoreticaldescription Basic APP, experiments, provided earlier paper (Wang & Botea,2009). brief overview APP extensions brief summary initial results topictwo-page paper (Wang & Botea, 2010). New material added current paper includes detailedalgorithmic description enhancements Basic APP formal proofs algorithmsproperties. also provide comprehensive empirical analysis enhanced APP, severaladditional experiments.rest paper structured follows. Next briefly overview related work. Then,state problem definition Section 3. Sections 46 focus Basic APP. Sections 78 cover enhancements Basic APP algorithm, extending completeness range (Section 7),57fiWANG & B OTEAimproving quality plans also running time (Section 8). empirical evaluationtopic Section 9. last part contains conclusions future work ideas.2. Related WorkFinding shortest path connects single pair start-target points known, finite mapoptimally solved A* algorithm (Hart et al., 1968). extension path planningmultiple simultaneously moving units, distinct start target positions, introduces potentialcollisions due physical constraint one location occupied one unittime. Units interact share information units path planning, makingproblem complex.multi-agent path planning, centralized A* performs single global search combinedstate space L1 L2 Ln n units, Li set possible locations unit i.Centralized A* plans paths units simultaneously, finding joint plan containing unitsactions (waits well moves). retains optimality completeness guarantees A*,prohibitively large state space O(mn ) states, n units graph nodes. Moreover,search nodes generated unpromising, taking units farther goal (Standley,2010). poses strong limiting factor problems centralized A* solve practice.hand, purely decentralized method, Local Repair A* (L RA *) (Stout, 1996) firstplans units path independently A*. Then, execution, L RA * replans additionalindependent A* searches every time collision occurs. good case, L RA * significantlyreduce computations O(mn). However, also generate cycles units, unableprevent bottlenecks. problems discussed Silver (2005), Bulitko, Sturtevant, Lu,Yau (2007), Pottinger (1999), Zelinsky (1992). cases, L RA * exhibits significantincrease running time may terminate. Therefore, straightforward extensionssingle-agent A* outlined strong limitations practice.Traditionally, multi-agent path planning took centralised decentralised approach (Latombe,1991; Choset et al., 2005). centralized approach plans globally, sharing information centrally,using potential field (Barraquand, Langlois, & Latombe, 1991). contrast, decentralized approach decomposes problem series smaller subproblems, typically first computing units paths individually, ignoring units, handling interactions online.Examples robotics include computing velocity profiles avoid collisions units (Kant& Zucker, 1986), pre-assigning priorities process robots one one (Erdmann & LozanoPerez, 1986). Recent algorithms also use combination two approaches. instance,Biased Cost Pathfinding (BCP) technique (Geramifard, Chubak, & Bulitko, 2006) generalisednotion centralized planning central decision maker resolves collision points pathspre-computed independently per unit, replanning colliding units around highestpriority unit. avoid excessively long (or even potentially unbounded) conflict resolutions, limitplanning time set. BCP returns paths fewest collisions within time. algorithmshown work well small-scale gridworld scenarios, complete optimalgeneral case. Standleys (2010) algorithm, hand, improved standard centralizedsearch whilst preserving optimality completeness. new state space representation incorporates next move assignments every unit state, decomposes timestepadvancing units advancing units one one fixed ordering. Thus branching factorreduced 9n 9, increasing depth search factor n. technique gen58fiM APP : CALABLE ULTI -AGENT PATH P LANNINGerates 9nt state nodes perfect heuristic (t number timestepsoptimal solution). practice, operator decomposition technique (OD) still often intractable,producing lower exponential search space standard joint search space. Recognisingmuch cheaper perform several independent searches one global search, Standley alsodecoupled planning non-interfering subgroups units independence detection (ID).group solved centrally optimality overall solution still guaranteed.fully developed hybrid algorithm, OD+ID, uses operator decomposition improve centralized planning non-independent subproblems. Nonetheless, optimality requirement costlypractice. Planning time still dominated largest subgroup units. numberunits increases, less likely independent paths unavoidably overlap,subgroups expected increase size too. Standleys (2010) experiments showed incomplete algorithm HCA* (Silver, 2005) actually solved instances. Furthermore,relatively small problems compared experiments (Wang & Botea, 2008, 2010),least 2 orders magnitude fewer agents (between 260 units), much smaller maps, 1 2orders magnitude fewer tiles (approximately 819 tiles).Therefore, methods tackling larger problems take decentralized approach, usually suboptimal nature. general, giving optimality reduces computation significantly. Decentralized path planning often much faster, scales much larger problems, yieldssuboptimal solutions provides completeness guarantees. Recent work grid maps includeW HCA * (Silver, 2006), uses 3-dimensional temporal-spatial reservation table performsseries windowed forward searches unit, based true distance heuristic obtainedinitial backward A* search target. FAR algorithm (Wang & Botea, 2008),units follow flow annotation map planning moving, repairing plans locally usingheuristic procedures break deadlocks. flow related ideas include Jansen Sturtevants(2008) direction map sharing information units directions travel, later unitsfollow movement earlier ones, improved coherence leading reduced collisions.Methods scale instances number units well beyond capabilitiescentralized search. However, mentioned earlier, methods known formal characterizations running time, memory requirements, quality solutions worstcase. lack ability answer reasonable bounded time whether given problem wouldsuccessfully solved, always important case incomplete algorithms.practice, traditional approaches multi-agent pathfinding serious drawbacks,inherent trade-off scalability, optimality completeness. Recently, body workbegun bridge gap two, addressing completeness tractability issueshand hand, bounded suboptimal approach. Ryan (2008) introduced complete methodcombines multi-agent path planning hierarchical planning search graphs specific substructures stacks, halls, cliques rings. example, stack narrow corridorone entrance, placed one end stack. Many maps, including game mapsused experiments, seem allow efficient decomposition stacks, halls, cliquesrings. B IBOX (Surynek, 2009b) solves problems least 2 unoccupied vertices biconnected graph. worst case, number steps cubic number nodes. B IBOXlater extended work 1 unoccupied vertex necessary (Surynek, 2009a).densely populated problems algorithm designed for, Surynek (2010a) expressedB IBOX target computer game scenarios, normally lot fewer unitslocations map. B IBOX suited multi-robot scenarios automatic packages59fiWANG & B OTEAinside warehouse (Surynek, 2010c). Bibox- (Surynek, 2009a), requires 1 unoccupiednode, shown run significantly faster significantly shorter solutions Kornhauser,Miller, Spirakiss (1984) algorithm related pebble coordination game. performedquick evaluation B IBOX using code obtained author. found that, graphsorder magnitude smaller game maps, B IBOX exhibits fast-growing runtime (e.g.,10 minutes graph 2500 locations) long solutions, millions moves.Part explanation B IBOX builds instances crowded. understanding,B IBOX designed solve crowded instances, necessarily efficiently solve instancessignificantly fewer units locations.3. Problem Statementinstance characterized graph representation map, non-empty collectionmobile units U . Units homogeneous speed size. unit u U associated starttarget pair (su , tu ). units distinct starting target positions. objective navigateunits start positions targets avoiding fixed mobile obstacles. statecontains positions units given time. work assumes undirected weighted graphsunit occupies exactly one node time, move unoccupied neighbournode. time discretized one units move synchronously time step.Travelling along edge depend interfere rest problem, excepttwo nodes connected edge.Several methods exist abstract problem map search graph, including navigationmeshes (Tozour, 2002), visibility points (Rabin, 2000), quadtrees (Samet, 1988). However,graph abstraction generates nodes, visibility graph, may render multi-agentpathfinding problem unsolvable, even though works single agent case. hand,search graph obtained imposing regular grid contains nodes, covering locationstraversable space, offers path options avoid collisions units. Hence,grid maps, besides popular easy implement, suitable multi-agentproblems. clarity practicality, focus grid maps examples experiments.Nonetheless, conditions algorithmic definitions APP, introduce nextsections, specific regular grid maps. illustrated examples, assumestraight moves four cardinal directions performed (4 connected grid). Restrictingmovements 8 directions (cardinal + diagonals) 4 cardinal directions negative impactcompleteness. Since standard practice allow diagonal move equivalent (butlonger) two-move path exists, every solution allows diagonal moves, solutioncardinal moves. Therefore, problem diagonal moves reduced problemstraight moves, price possibly taking longer paths. Introducing diagonal moves couldreduce path length, potential drawback blocking units often straightmoves crowded maps. Whether enough clearance make diagonal move dependstwo adjacent nodes (i.e., two tiles sharing common corner grid), sincephysically impossible squeeze two units.4. LIDABLE Class Instancesintroduce subclass instances Basic APP shown complete.60fiM APP : CALABLE ULTI -AGENT PATH P LANNINGi+1u(u)i-1u lu (denoted 1Figure 2: example alternate path, , connecting locations li1i+1+ 1 picture) belong precomputed path (u) unit u.Definition 1 (S LIDABLE unit LIDABLE instance). mobile unit u LIDABLE iff pathuu(u) = (l0u , l1u , . . . , l|(u)|) nodes exists, l0u = su , l|(u)|= tu , followingconditions met:u , lu , lu (u), except1. Alternate connectivity. three consecutive locations li1i+1last triple ending tu , i.e. 0 < < |(u)| 1, alternate path ui existsu lu go lu . See Figure 2 example.li1i+12. Initial blank. initial state, l1u blank (i.e. unoccupied).3. Target isolation. target interferes -paths units. formally,following hold tu :(a) (v U \ {u}) : tu/ (v);(b) (v U, {1, . . . , |(v)| 1}) : tu/ vi .instance belongs class LIDABLE iff units u U LIDABLE.three conditions verified polynomial time. verification includes attemptingcompute paths unit. Since state space A* explore linearm, A* search time polynomial m. checks blank location first step,passing targets, trivial. process checks LIDABLE conditionsserves important additional purpose. time checks succeed instance knownbelong LIDABLE, completed search needed solve instance.remaining part algorithm simply tell units wait, move forward,move backwards along already computed paths.Notice three conditions restricted grid maps only. work standardassumption one graph node occupied one unit time, moving alongedge neither depends interferes parts graph except two nodes endsedge.61fiWANG & B OTEAAlgorithm 1 Overview APP.1: u U2:compute (u) (as needed) su tu3:LIDABLE conditions hold4:mark u LIDABLE5: initialize set LIDABLE units {optional: make units active, discussed text}6: 6=7:progression step8:repositioning step needed5. Basic APPpresent basic version APP algorithm, complete LIDABLE classproblems. main feature Basic APP (and extensions presented Sections 7 8)deadlock-free cycle-free, due total ordering active units. Units lower priorityinterfere ability higher priority units advance.illustrated Algorithm 1, problem instance, APP starts computing path (u)unit u target (goal), constructing caching alternate paths along way. Notepaths alternate paths need satisfy conditions Definition 1. looplines 14 succeeds units, APP tell instance hand belongs LIDABLE,APP complete.subset units marked LIDABLE, APP guaranteed solve them.equivalent solving smaller instance LIDABLE. Optionally, APP attemptsolve remaining units well, adding set active units giving lowerpriority LIDABLE units. important stress that, remaining part paper,implicit assumption APP attempts solve provably solvable units, unlessexplicitly state opposite. experiments section, however, discuss options.set LIDABLE units partitioned subset solved units already reachedtargets, subset active units. Initially, units active. LIDABLE class,becoming solved, units interfere rest problem (as ensured targetisolation condition). shown later, Basic APP solved units never become active again,considered remaining part solving process.Definition 2. advancing condition active unit u satisfied iff current position, pos(u),belongs path (u) next location path blank.Definition 3. state well positioned iff active units advancing condition satisfied.Lines 68 Algorithm 1 describe series two-step iterations. progression step advancesactive units towards targets. shown later, progression step brings least one activeunit target, shrinking active set ensuring algorithm terminates, reachingstate units solved. progression could result breaking advancing conditionone active units, remain. objective repositioning step ensureactive unit advancing condition satisfied starting next progression step. Noterepositioning step necessary every progression step except last.62fiM APP : CALABLE ULTI -AGENT PATH P LANNINGbbbbbbbiibiiibivvFigure 3: Example APP works.5.1 Examplesimple example APP works illustrated Figure 3. two units, b.APP uses total ordering active units progression step (Section 5.3). Here,higher priority b. targets b drawn stars. Figure 3 (i), b progresstowards targets, becomes blocked b. (ii), blank brought front slidingb ai (outlined bold); side effect, b pushed path. end currentprogression step (iii), reaches target. repositioning step (iv), since already solved,moves ignored. Repositioning undoes bs moves b back path blankfront it. bs advancing condition restored therefore global state examplewell positioned. next progression step (v), b reaches target. algorithm terminates.5.2 Path Computationproblem instance, compute path (u) individually. paths (u) fixedthroughout solving process. ensure paths satisfy alternate connectivity condition(Definition 1), modify standard A* algorithm follows. expanding node x0 ,neighbour x00 added open list alternate path x00 x, parentx0 . process compute path (u) family alternate paths simultaneously.give neighbour x00 node x0 chance added open list, node x0 mightexpanded three times, per possible parent x. Therefore, O(m) node expansionsrequired A* search find path, number locations map.Equivalently, computing path could also seen standard A* search extended spacepairs neighbouring nodes (at four nodes created extended space originalnode).Since alternate paths depend triple locations, unit, re-use information planning paths units problem. means alternate pathset three adjacent tiles map computed per problem instance,cached later use. Given location l grid map, eight locations couldpath two moves away four-connect grid. shown Figure 4a, eight locationsform diamond shape around l. four locations straight line l63fiWANG & B OTEA1812l7683742lii63455bFigure 4: (a) eight locations two moves away l. (b) Two two-move paths l location2 go ii.(locations 1, 3, 5, 7), precompute alternate path avoids in-between locationtargets. four locations (labeled 2, 4, 6, 8), need compute (at most) twoalternate paths. example, two possible paths l 2 two moves long:ii (Figure 4b). need one alternate path avoid intermediate location,ii. summary, precompute 12 paths l. locations map,need 12m2 = 6m alternate paths (only one computation triple, since alternatepath connects two endpoints ways).possible optimization reuse alternate paths across LIDABLE instances map.Alternate paths overlap targets new instance need re-computed. discussoption experiments section.5.3 ProgressionAlgorithm 2 shows progression step pseudocode. iteration outer loop, activeunits attempt progress one move towards targets. processed order (line 2).unit v processed unit w, say v higher priority write v < w. orderingfixed inside progression step, may change one progression step another. actualordering affects neither correctness completeness method, may impactspeed solution length. ordering units chosen heuristically, e.g. giving higherpriority units closer target. Thus, units could get target quickly,solved way remaining units problem.ensure lower priority units harm ability higher priority units progress,introduce notion private zone. see Algorithm 2 unit cannot causemoves occupy private zone higher-priority unit.1 Given unit u, let pos(u)ucurrent position, let int((u)) = {l1u , . . . , l|(u)|1} interior precomputed path(u). shown Algorithm 2, unit u might get pushed precomputed path, casepos(u)/ (u).u , lu } pos(u) = lu int((u)).Definition 4. private zone, (u), unit u (u) = {li1Otherwise, (u) = {pos(u)}. words, private zone includes current location1. move caused unit u either move u along (u) path, move different unit w,pushed around u side effect blank travel.64fiM APP : CALABLE ULTI -AGENT PATH P LANNINGAlgorithm 2 Progression step.1: changes occur2:u order3:pos(u)/ (u)4:nothing {u pushed track result blank travel}u current progression step5:else u already visited li+16:nothingu , belongs private zone higher priority unit, i.e.7:else next location, li+1uv < u : li+1 (v)u released v}8:nothing {wait li+1u blank9:else li+1u10:move u li+1u11:else bring blank li+1u12:bring blank li+1u13:move u li+114:else15:nothingunit. addition, unit pre-computed path start position, locationbehind unit belongs private zone well.Lines 315 Algorithm 2 show processing u, active unit hand. u pushedprecomputed path, action taken (lines 34). Lines 5 6 cover situationunit u pushed around (via blank travel) higher-priority units back location (u)already visited current progression step. case, u doesnt attempt travelpreviously traversed portion path, ensuring bounds total travelled distanceuintroduced later hold. u path next location li+1currently blocked higheru available, upriority unit v, action taken (lines 78). Otherwise, next location li+1umoves (lines 910). Finally, li+1 occupied smaller-priority unit, attempt madeufirst bring blank li+1u move (lines 1113). u moves newuu target location u.location li+1 (lines 10 13), test performed check li+1case, u marked solved removing adding S, set solvedunits.uBringing blank li+1(lines 11 12) illustrated Figure 1. discussprocess detail. location l ui sought following properties: (1) l blank,u (inclusive) along u belongs private zone higher(2) none locations l li+1upriority unit, (3) l closest (along ui ) li+1property. location lufound, test line 11 succeeds. actual travel blank l li+1along ui(line 12) identical movement tiles sliding-tile puzzle. Figure 1 shows exampleublank traveling. intuition behind seeking blank along ui that, often, li1u lu test line 11remains blank time interval u advances li1performed. guaranteed always hold case active unit highest priority,call master unit.Let us introduce characterize behaviour master unit formally. beginning progression step, one master unit u selected. unit highest priority among65fiWANG & B OTEAunits active beginning progression step. status master unitpreserved entire progression step, even u becomes solved. beginningnext progression step, new master unit selected among remaining active units.Lemma 5. master unit u always bring blank front, needs one.u , belongs private zone, (u), unitProof. Since us previous location, li1u .move private zone highest priority unit, u guaranteed always find blank li1u lu belong private zone higher priorityMoreover, location along ui li1i+1unit since units higher priority. Note also ui free physical obstaclesu lu .construction. must possible blank travel li1i+1Lemma 6. master unit u never pushed -path.Proof. u pushed (u) blank travelling performed another unit, contradicts uhighest priority unit.Theorem 7. long master unit u solved, guaranteed advance along (u)iteration outer (while) loop Algorithm 2. end current progressionstep, least u reached target.Proof. Using previous two lemmas, easy check u never enters nothing lineAlgorithm 2. Similar Lemma 6, u never pushed cannot revisit previous location. Also,since u highest priority, next location cannot held private zone another unit.Hence, us progress target guaranteed.following result useful ensure progression step always terminates, eitherstate units solved state remaining active units stuck.Theorem 8. Algorithm 2 generates cycles (i.e., repetitions global state).Proof. show proof contradiction. Assume cycles. Consider cycleactive unit u cycle highest priority. Since unit cycle dominates u,means movements u cannot part blank travel triggered higher priority unit.Therefore, movements u result either line 10 line 13. is, us movesalong path (u). Since (u) contains cycles, u cannot run cycle.5.4 Repositioningend progression step, remaining active units (if left)advancing condition broken. Recall happens unit u either pos(u)/ (u) uplaced precomputed path next location path blank. repositioningstep ensures well positioned state reached (i.e., active units advancing conditionsatisfied) starting next progression step.simple computationally efficient method perform repositioning undo blockrecent moves performed preceding progression step. Undoing move means carryingreverse move. Solved units affected. remaining active units, undomoves, reverse global order, well positioned state encountered. call strategyreverse repositioning. example provided Section 5.1.66fiM APP : CALABLE ULTI -AGENT PATH P LANNINGProposition 9. reverse repositioning strategy used line 7 Algorithm 1 (when needed),progression steps start well positioned state.Proof. lemma proven induction iteration number j Algorithm 1. Sinceinitial state well positioned (this follows easily Definitions 1 3), proof j = 1trivial. Assume repositioning step performed starting iteration j + 1.worst case, reverse repositioning undoes moves remaining active units (butmoves units become solved), back original positions beginning j-thprogression step. words, reach state similar state s0 beginningprevious progression step, except units targets s. Since s0 wellpositioned (according induction step), follows easily well positioned too.6. Worst-case Best-case Analysisgive bounds runtime, memory usage, solution length APP algorithmproblem LIDABLE n units map traversable tiles. examine worst casescenario case, also discuss best-case scenario end.introduce additional parameter, , measure maximal length alternate paths .worst case, grows linearly m. However, many practical situations, small constant,since ends path close other. analysis discusses scenarios.Theorem 10. Algorithm 1 worst-case running time O(max(n2 m, m2 log m))constant, O(n2 m2 ) grows linearly m.Proof. outlined Section 5.2, single-agent A* search consistent heuristic 2 expandsO(m) nodes. Hence, assuming open list implemented priority queue, A* searchtakes O(m log m) time. Note that, graphs edges cost, log factorcould principle eliminated using breadth-first search find optimal path. Grid mapscardinal moves fit category. However, simplicity, assume logfactor present.Hence, worst case, searches -paths take O(nm log m) time n units.A* searches take O(m2 log m) time.single progression step, outlined Algorithm 2, suppose blank travel required nunits, every move along way except first last moves. Since length pathsbounded length alternate paths bounded , total number movesprogression step O(nm), running time Algorithm 2.Clearly, complexity repositioning step cannot exceed complexity previousprogression step. Hence complexity iteration Algorithm 1 (lines 57) O(nm).number iterations n, since size reduces least one iteration.APP takes O(max(nm log m, m2 log m, n2 m)) time run, O(max(n2 m, m2 log m))constant O(n2 m2 ) grows linearly m.Theorem 11. maximum memory required execute APP O(nm) constant,O(nm2 ) grows linearly m.2. well known Manhattan heuristic, used implementation, consistent. proofeasy, direct result 1) definition consistency 2) way Manhattan distance computed (bypretending obstacles map).67fiWANG & B OTEAProof. Caching possible paths entire problem described Section 5.2 takes O(m)memory. A* searches paths performed one time. search, storedcache, memory used open closed lists released. A* working memorytakes O(m) space, storing paths takes O(nm) space. Overall, path computationacross units requires O(nm + m) space.Then, lines 57 Algorithm 1, memory required store stack moves performedone progression step, used repositioning. shown proof Theorem 10,number moves progression step within O(nm). So, overall maximum memoryrequired execute program O(nm), O(nm) constant O(nm2 )grows linearly m.Theorem 12. total distance travelled units O(n2 m) constant,O(n2 m2 ) grows linearly m.Proof. shown previously, number moves progression step within O(nm).number moves repositioning step strictly smaller number moves previousprogression step. n progression steps (followed repositioning steps). Hence,total travelled distance within O(n2 m).Corollary 13. Storing global solution takes O(n2 m) memory constant, O(n2 m2 )grows linearly m.discuss best case scenario. APP computes optimal solutions number movespaths optimal units reach targets without blank traveling (i.e., unitstravel along paths ). obvious example paths disjoint. case,solutions makespan optimal too. well preserving optimality best case, searcheffort APP also smaller spent centralised A* search, n single-agentm!O(m) searches, compared searching combined state space n units, (mn)!states.7. Extending Completeness Rangeextend APPs completeness beyond class LIDABLE, evaluated impactthree LIDABLE conditions preliminary experiment. ran Basic APP dataset also used main experiments (the data set main experiments describedSection 9). preliminary experiment, switched one LIDABLE condition timecounted many units satisfy remaining two conditions. larger increase numbersolvable units suggests relaxing definition condition hand could providesignificant increase completeness range.initial experimental evaluation indicates Basic APP three LIDABLE conditions solves 70.57% units (basic case). alternate connectivity requirement switched off,87.06% units satisfy remaining two conditions. Switching target isolation makes 85.05%units satisfy remaining two conditions. However, ignoring blank availability conditionsmall impact, increasing percentage slightly, 70.57% basic case 70.73%.results suggest alternate connectivity target isolation conditions restrictive blank availability condition. Thus, focus relaxing two conditions.68fiM APP : CALABLE ULTI -AGENT PATH P LANNINGtarget isolation, extension allows unit plan path targets,still guarantee clearly identified set units reach targets. topicSection 7.1. extend alternate connectivity, developed technique allows pathsplanned regions alternate paths, tunnels. blank travelling operationtunnel-crossing unit uses blank positions ahead unit, along remainingpre-computed path, describe detail Section 7.2. empirical analysisfeatures provided Section 9.7.1 Relaxing Target Isolation Conditionseveral targets close other, target isolation condition, forbidding pathspass targets, make targets behave virtual wall, disconnecting two areasmap. result, Basic APP report many units non-S LIDABLE.extension introduce allows unit u plan path target another unit v,subsequently v never assigned higher priority u. specifically, partial orderingdefined, u v iff target v belongs -path upath along usu 2ui ). Every-path. Written formally, u v iff tv (u), (u) = ((u) ki=1time mention refer transitive closure. show section that, pathsplanned way (possibly empty) relation creates cycles type u u,instance solved slight modification Basic APP.Units plan paths foreign target choice.achieve strategy, A* searches assign high cost graph search edges adjacentforeign target. desirable outcome reducing interactions caused targetisolation relaxation. particular, way original LIDABLE units compute pathspreserved, foreign targets crossed cases. words, instances LIDABLEcharacterized empty relation.Definition 14. instance belongs class I-S LIDABLE iff every unit u exists path (u)satisfying alternate connectivity initial blank condition definition LIDABLE(Definition 1). Furthermore, cycles allowed relation.Assume moment (possibly empty) relation without cycles available. Aspectsrelated obtaining one discussed later section.Definition 15. solving I-S LIDABLE instances, extended algorithm, APP, twosmall modifications original algorithm:1. total ordering < inside progression step stays consistent : u v u < v.2. u v, v cannot marked solved (i.e. moved S) unless u alreadymarked solved.extra conditions hand, ensure even unit x arrives target txunits clear tx -paths, units get past x performing normal blanktravel. Following that, x undo moves back tx repositioning step, Basic APP.prove APP terminates, first prove following two lemmas hold highestpriority unit, u, progression step:69fiWANG & B OTEALemma 16. unit visit target u, tu , current progression step.Proof. Since u master unit, follows u < v active unit v. Accordingpoint 1 Definition 15, follows u v. Relation cycles, means v u.Therefore, applying definition , follows tu/ (v). completes proof,APP movements performed along paths.Since repositioning step undo moves made previous progression step, unitsrevisit locations visited progression step. So, following direct resultLemma 16:Corollary 17. unit visit tu repositioning step follows.Corollary 18. u solved, cannot interfere rest problem.Theorem 19. APP terminates.Proof. Showing least highest priority unit u reaches target given progression stepvirtually identical proof Lemma 7. Corollary 18 guarantees that, solving u,interfere rest problem. Hence, number active units strictly decreasesprogression step, algorithm eventually terminates.Let us get back question provide cycle-free relation. Testing whetherunits plan paths way cycle introduced might end expensive.unit u cant possibly avoid targets, might choose crossingtarget v crossing target w. One option might lead cycle whereas mightavoid cycles. Therefore, systematic search might required seek cycle-free relation .Rather searching systematically, APP takes cheaper, greedy approach.cycles, mark number units I-S LIDABLE. selected wayunits remain cycle-free (we call I-S LIDABLE units). I-S LIDABLE unitsguaranteed solved.result greedy approach, APP complete class I-S LIDABLE. Still,complete superset LIDABLE able identify many units (often all)provably solved.Finally, wrap discussion extension concluding upper boundsAPP, given Section 6, still apply APP. proof identical makeworst-case assumptions before: master unit gets solved progression step,every move along units path requires blank travel. Moreover, note additional steppath pre-computation topologically sorting partial order, , linear priority order <,done cheaply time linear number units (Tarjan, 1976).7.2 Relaxing Alternate Connectivity Conditionshow Section 9, previous extension target isolation significantly improvesAPPs success ratio (i.e., percentage solvable units). Yet, significant roomimprovement. particular, maps single-width tunnels still showed bottleneck termssuccess ratio. Tunnels make alternate connectivity condition connecting two endsconsecutive triple locations without going middle harder even impossible70fiM APP : CALABLE ULTI -AGENT PATH P LANNINGsatisfy. single-width tunnel bridges two otherwise disjoint regions, shown Figure 5,versions APP presented far fail find path two regions, alternateconnectivity broken triples inside tunnel.Figure 5: example units targets side, waycross single-width bridge. Units drawn circles, corresponding targetssquares shade.section introduce buffer zone extension, solution relaxing alternateconnectivity condition. allows many paths, corresponding many units, cross singlewidth tunnel. intuition simple. Often, plenty blank positions ahead unit, alongremaining locations precomputed -path corresponding paths along it.tunnel-crossing operation essentially generalisation blank travelling, blank positionsought path ahead, instead alternate path current location triple.Definition 20. precomputed path (u) crosses tunnels, define following:buffer zone, ((u)), portion (u) target endlast tunnel (at theSj-th move (u)), together corresponding alternate paths:((u)) ={liu } ui .i{j+2,...,ku 1}dynamic counter, ((u)), keeps track many positions buffer zone blank.counter initialized beginning appropriate value, incrementeddecremented necessary later on.threshold ((u)) set length(t) + 2, longest tunnel crossedunit u. threshold acts minimal value ((u)) guarantees u crosstunnels safely.71fiWANG & B OTEAunit u attempts cross tunnel, push units lower priorities closest blanklocations buffer zone, u exits tunnel. tunnel-crossing operationpossible, enough blanks available buffer zone. analyse new extendedalgorithm detail, introduce extended class AC LIDABLE, whose definition includesunits meeting new buffer zone extension.Definition 21. relaxing alternate connectivity condition, allow (u) go onesingle-width tunnels iff enough blanks us buffer zone, least ((u)) blanklocations ((u)) initial state, i.e., ((u)) ((u)). before, alternate paths stillneeded locations outside tunnels.Definition 22. unit u U belongs extended class, call AC LIDABLE, iffpath (u) meeting initial blank target isolation conditions given definitionLIDABLE (Definition 1), relaxed alternate connectivity condition (Definition 21 above).AC APP modified Basic APP following two ways integrate bufferzone technique relaxing alternate connectivity condition. Firstly, repositioning step cannotfinish counter () value threshold (). words, need ensureenough blanks available buffer zone progression step begins. followingnew advancing condition, updated Definition 2 adding extra, aforementioned condition.Definition 23. advancing condition active, tunnel-crossing unit u satisfied iff currentposition belongs path (u) next location path blank (as given Definition 2),also ((u)) ((u)).Secondly, need preserve one Basic APPs main features, units lower prioritynever block units higher priority, ensuring APP run cycles deadlocks.Hence, unit u lower priority v cannot cause moves bring ((v))threshold (i.e., ((v)) ((v)) 1). Recall move caused u either moveu along (u) path (checked lines 7-8 Algorithm 4), move different unitw, pushed around u side effect blank travel (checked lines 7-11Algorithm 3). Thus buffer zone u acts generalised private zone, u holds least((u)) locations accessible units lower priorities.extensions AC APP maintain following properties Basic APP.Lemma 24. long master unit u solved, guaranteed advance along (u)iteration outer (while) loop Algorithm 4. end current progressionstep, least u reached target.Proof. result follows directly proof Lemma 7. parts newAlgorithm 4 compared Algorithm 2 (the progression step Basic APP) checklines 7-8 modified blank travelling operation (lines 13-15). Since u highest prioritycurrent progression step, cause moves affecting buffer zone every unit,unit move buffer zone u would bring number blanksthreshold, i.e. ((u)) < ((u)). Hence u guaranteed enough blanks crosstunnel (u).proof Lemma 25 similar Lemma 8 Section 5.3.72fiM APP : CALABLE ULTI -AGENT PATH P LANNINGu )Algorithm 3 AC APP canBringBlank( unit u, location li+11: u outside tunnels2:look nearest blank b along ui3: else u inside tunnel4:look nearest blank b ((u))5: b found6:return falseu } {segment along u ((u)) above}7: location l {b, . . . , li+18:v < u : l (v) {check causing another unit move private zonehigher priority unit, v}9:return false10:else v < u : l ((v)) & ((v)) ((v)) {check causing another unitmove buffer zone higher priority unit, v}11:return false12: return trueAlgorithm 4 AC APP Progression step.1: changes occur2:u order3:pos(u)/ (u)4:nothingu5:else v < u : li+1(v)6:nothingu7:else v < u : li+1((v)) & ((v)) ((v)) {check movingbuffer zone higher priority unit}8:nothing {wait v blanks buffer zone}u current progression step9:else u already visited li+110:nothingu blank11:else li+1u12:move u li+1u ) {Algorithm 3}13:else canBringBlank( u, li+1u14:bring blank li+1u15:move u li+116:else17:nothingLemma 25. Algorithm 4 generates cycles (i.e., repetitions global state).Theorem 26. AC APP terminates.Proof. follows Lemmas 24 25 number active units strictly decreasessuccessive iterations Algorithm 4. Hence, algorithm AC APP eventually terminates.Since shown algorithm AC APP guaranteed solve class AC LID completeness result shown follows directly.ABLE ,73fiWANG & B OTEACorollary 27. AC APP complete class AC LIDABLE.AC APP extension preserves upper bounds running time, memory usage, solution length given Section 6. Here, introduce max denote maximal length tunnelsunits cross. worst case analysis, units initiate blank travelling every move alongway, involves tunnels. So, depending whether max , maximal lengthpaths, longer, AC APP runs O(n2 mmax ) O(n2 m) time. Since parametersoften constant practice, grow worst linear m, running time O(n2 m) O(n2 m2 ),before. bounds total travel distance global solution follow directly. Lastly,virtually additional memory required storing buffer zones, except one counter onethreshold variable, per unit.7.3 Combining Target Isolation Alternate Connectivity Relaxationsshow two extensions LIDABLE class combined.Definition 28. instance belongs extended class, I+AC LIDABLE, iff every unit uexists path (u) meeting initial blank condition given Definition 1, relaxedalternate connectivity condition Definition 22. Furthermore, (possibly empty) relationintroduced result target isolation relaxation cycle-free, Definition 14.obtain extended algorithm, I+AC APP, combining APP (Definition 15)AC APP (Algorithms 3 4).Theorem 29. I+AC APP terminates.Proof. proof Lemma 24, show least highest priority unit u reachestarget progression step, follows. Definition 21, u guaranteed enough blanksclear single-width tunnels along path. Definitions 14 15 guarantee that,outside tunnels, u always bring blank needed, stated Lemma 5. Furthermore,progression step generates cycles. proved cases Lemmas 25 8.also know solved unit u interfere rest problem,results Lemmas 16 18, Corollary 17. Note tricky cases unitstargets inside single-width tunnels excluded extended class I+AC LIDABLE,zero buffer capacity according defined Definition 20.Since iteration algorithm solves least one unit, I+AC APP terminates.8. Improving Solution Lengthmentioned before, avoid replanning, units pushed off-track blank travelling unitsundo moves get back -paths immediate repositioning step.observed that, practice, reverse repositioning strategy (defined Section 5.4) introducemany unnecessary moves, increase solution length, increase running time, mayhurt visual quality solutions.Recall that, standard reverse repositioning step, new moves added solutionbuilt. moves undo, reverse order, moves active units (i.e., solvedyet) made previous progression step. process continues well positioned state74fiM APP : CALABLE ULTI -AGENT PATH P LANNINGu(v)u(v)vv(u)(u)Figure 6: Two examples global checking well positioned state.reached, means active units advancing condition satisfied (i.e., everyactive unit -path blank front).undo move, well-positioned check performed globally. words, BasicAPP checks advancing condition active units, unit affectedrecent undo move. global checking guarantees eventually reach well-positioned state,proved Proposition 9, but, mentioned earlier, often create many unnecessary moves.provide two simple examples Figure 6, illustrate one case global checkinguseful, one case global checking strong condition, adding unnecessary moves.First, consider two units, u v, undoing one move global moves stack places uback path, blank front. Assume us current position way vsfuture undo moves, shown left Figure 6. Therefore, even us advancing conditionsatisfied, u needs additional undo moves, make room undo moves units, v,order reach globally well positioned state. case, global checking useful. secondexample, imagine u vs moves recent progression step independentother, possibly even two map areas far away other. simple case shownright Figure 6. recent progression, vs last move (when v derailed) followedsequence us moves. final move u pushed track, whereas precedingmoves along us -path, (u). Reverse repositioning would undo moves reverse globalorder, means undoing us moves undoing vs last move. However, one undomove u one undo move v sufficient restore units well positioned state.illustrated, global checking advancing condition could strong, whereaslocal checking could insufficient. solution introduce section,called repositioning counting, finds middle ground two extremes, improvesnumber moves still maintains guarantee reaching well-positioned state. Intuitively,undo moves unit u stop soon (a) us advancing condition satisfied, (b)current position cannot possibly interfere future undo moves units, (c) unitperforming repositioning possibly stop blank position front u us -path,75fiWANG & B OTEA(d) u doesnt stop initial second location another active unit v. initial secondlocation unit v position ahead v beginning recent progression step.fourth condition ensures units blank front end, worst caserevert back initial position beginning recent progression step.3Definition 30. location l path, keep counter, c(l), that:beginning progression step, counter c(l) reset 0, l empty, 1,l occupied.Every time l visited progression step, c(l) incremented.Every time unit leaves l result undo move repositioning step, c(l)decremented.Following directly definition c(l) given above, formulate following tworesults c(l) repositioning time:Lemma 31. c(l) = 0, unit pass l remaining part currentrepositioning step.Lemma 32. given active unit u, current position pos(u), c(pos(u)) = 1,progression moves location pos(u) already undone. words,unit remainder repositioning step pass pos(u).introduce new enhancement APP, aimed eliminating many useless undomoves repositioning steps.Definition 33. enhanced algorithm, R C APP, uses repositioning counting strategyline 7 Algorithm 1. means active unit u stops undoing moves currentrepositioning step, soon meets following conditions:(a) advancing condition u satisfied according Definition 2, plus extension Definition 23.(b) us current location, pos(u), c(pos(u)) = 1u , c(lu ) = 0(c) location front u, li+1i+1(d) current location initial second location another active unit.Theorem 34. repositioning steps R C APP end well-positioned state.3. Condition d) ignored without invalidating algorithms ability make progress towards goal state. Evenunits could possibly end state without blank front, guaranteed least one unit (i.e.,one finishes repositioning first) blank front. guarantees least one unitsolved next progression step.76fiM APP : CALABLE ULTI -AGENT PATH P LANNINGProof. Recall moves made progression step kept totally ordered list.prove directly repositioning counting, undoing subset moves, reaches wellpositioned state. Since counter c(l) incremented decremented according Definition 30,unit u satisfying three conditions Definition 33 restored advancing condition.Furthermore, combined results Lemmas 31 32 guarantee units laterget us way, u way units repositioning moves.Theorem 34, applying R C repositioning steps extended algorithm I+AC APPnegative impact completeness.9. Experimental Resultssection present empirical evaluation APP algorithm. first pointimpact newly added feature. put I+AC+R C enhanced APP testcomparison existing state-of-the-art decoupled, incomplete methods. Specifically,benchmarks FAR (Wang & Botea, 2008), extended version Silvers (2005) W HCA *algorithm Sturtevant Buro (2006), called W HCA *(w,a), applies abstractionexpensive initial backward A* searches. APP, algorithms tested ratherlarge problems, terms map size number units. aware programsscale well FAR W HCA *. strengths two methods potential abilityfind solution quickly, weakness cannot tell whether would ablesolve given instance.implemented APP scratch integrated Hierarchical Open Graph4 (HOG)framework. source code extended W HCA * algorithm, W HCA *(w, a) (Sturtevant &Buro, 2006), extra features spatial abstraction diagonal moves (but without prioritysystem unit replanning), obtained Nathan Sturtevant. FAR algorithmimplementation used previous experiments (Wang & Botea, 2008).Experiments run data set randomly generated instances used previously published work (Wang & Botea, 2008). input grid maps5 10 largest game Baldurs Gate6 , range 13765 51586 traversable tiles size, listed Table 1.game maps quite challenging, containing different configurations obstacles forming differentshapes rooms, corridors, narrow tunnels. test map 100 2000 mobile unitsincrements 100. 10-minute timeout per instance set. W HCA *(w, a) experiments,set window size, w, 8, use first level abstraction (a = 1). seemsgood parameter setting work Sturtevant Buro (2006), experiments comparingW HCA *(20,1) show W HCA *(8,1) work better data set. Abstraction allows W HCA *build heuristic graph smaller actual graph movement takesplace. FAR, units make reservations k = 2 steps ahead, recommended setting.experiments run 2.8 GHz Intel Core 2 Duo iMac 2GB RAM.77fiWANG & B OTEABasic MAPPNumber SLIDABLE2000700414400500300204602411603307150010005000050010001500Total number agents2000TI MAPP414400204500411300700602603307150010005000AC MAPP20000Number AC-SLIDABLENumber TI-SLIDABLE200050010001500Total number agents2000700500300400414204602411603307150010005000050010001500Total number agents2000TI + AC MAPPNumber TI+AC-SLIDABLE2000700300500414400602204603411307150010005000050010001500Total number agents2000Figure 7: MAPPs widened completeness range relaxation: graph line representsnumber units solved problem instances map. Here, provably solvableunits counted.78fiM APP : CALABLE ULTI -AGENT PATH P LANNINGFARNumber agents solved2000414204400411700500300602603307150010005000050010001500Total number agents2000WHCA* diagonalsNumber agents solved2000400204414411700500300603602307150010005000050010001500Total number agents2000WHCA* diagonalsNumber agents solved2000204414400411700500300603602307150010005000050010001500Total number agents2000Figure 8: success ratios (averaged 10 trials) FAR, W HCA *(8,1), withoutdiagonals, set problem instances. timeout set 10 minutes perinstance 3 incomplete algorithms.79fiWANG & B OTEAMap IDAR0700SRAR0500SRAR0300SRAR0400SRAR0602SRAR0414SRAR0204SRAR0307SRAR0411SRAR0603SRShort ID700500300400602414204307411603# nodes51586291602695024945233142284115899149011409813765Table 1: 10 maps descending order, terms number nodes.9.1 Scalability Percentage Solved Unitscompare FAR, W HCA *(8,1) four versions APP: Basic APP original LID ABLE definitions; APP , version target isolation relaxation switched on; ACAPP, based relaxing alternate connectivity condition; +AC APP, relaxingtarget isolation condition, alternate connectivity condition. measure success ratio,defined percentage solved units. Note repositioning counting (R C)considered section, since impact success ratio, designedimprove solution length.APP versions used section attempt solve units provably solvable(i.e., units marked LIDABLE, LIDABLE, AC LIDABLE, I+AC LIDABLE respectively).reason want evaluate many units fall subclasses practice.next section show data obtained version APP attempts solve units.Figure 7 summarizes success ratio data version APP algorithmmaps. closer curve top diagonal line (being total number units), bettersuccess ratio map. Basic APP exhibits mixed behaviour, greater success ratiosix maps. four challenging maps (602, 411, 603, 307), success ratio gets often50% number mobile units increases. maps common feature containinglong narrow corridors even single-width tunnels, connecting wider, open regionsmap. Thus surprising that, mentioned Section 7, alternate path target isolationconditions identified greatest causes failing find LIDABLE path.Relaxing target isolation condition (T APP) significantly improves success ratiomaps. good success ratio (93% higher) achieved 7 maps across entirerange number mobile units. 3 maps contain high proportion narrowcorridors, also single-width tunnels.Relaxing alternate connectivity well (T +AC APP) yields excellent success ratiounit numbers maps. example, scenarios 2000 units,4. http://webdocs.cs.ualberta.ca/nathanst/hog.html5. experimental maps viewed online, at: http://users.cecs.anu.edu.au/cwang/gamemaps6. http://www.bioware.com/games/baldurs_gate/80fiM APP : CALABLE ULTI -AGENT PATH P LANNINGchallenging according Figures 7 8, smallest success ratio 92% (map 307) largestone 99.7%. scenarios fewer mobile units, I+AC APP even better success ratios.Next compare success ratio I+AC APP (bottom plot Figure 7) FAR(top plot Figure 8) W HCA *(8,1) (middle bottom Figure 8, without diagonals,respectively). Extended APP clear winner terms scalability. FAR W HCA * suffernumber units increased. incomplete algorithms often time even scenariossignificantly fewer units 2000. 2000 units, FAR solves 17.5% units,W HCA * solves 16.7% (no diagonal moves) 12.3% (with diagonal moves)units. entire data set, I+AC APP solved 98.82% units, FAR solved81.87% units, 77.84% 80.87% solved W HCA * without diagonal movesallowed, respectively.9.2 Scalability Attempting Solve Unitsprevious section, compare FAR, W HCA * APP. I+AC APP versionused attempts solve units, provably solvable ones (attempt-all feature).mentioned earlier, achieved marking units active beginning. Active unitspartitioned three categories: i) provably solvable units reach target; ii)units reached target; iii) units reached target location,still active units still cross location. total ordering <active units must respect conditions units category i) higher priority unitscategory ii), higher priority units category iii).attempt-all feature turned on, I+AC APPs percentage solved units increases98.82% (Section 9.1) 99.86%.Next focus number solved instances. instance considered solved iffunits solved. APP successful 84.5% instances. significantly better FAR(70.6%), W HCA * diagonal moves (58.3%), W HCA * diagonals (71.25%).attempt-all feature massive impact percentage fully solved instances, improving 34% 84.5%. might seem counter-intuitive attempt-all featuresmall impact percentage solved units great impact percentage solved instances. explanation following. APP fails instance,small percentage units remain unsolved. Often, one twounsolved units failed instance. Managing solve remaining units wellattempt-all feature result whole instance changing label failed solved, eventhough change overall percentage solved units small.remaining sections use attempt-all feature well. reason increasesnumber solved instances therefore obtain larger set data analyse.9.3 Total Travel DistanceFactors may impact length plans lengths initial paths, extra movements caused blank travel repositioning. experiments, length precomputedpaths virtually negative impact travel distance. Even APPs pathssatisfy additional constraints, avoiding targets possible, similarlength normal unconstrained shortest paths, 1.4% longer average.81fiWANG & B OTEARC-Improved Travel Distance (Map 400)800000MAPP totalRC MAPP totalMAPP Pre-Computed PiMAPP undosRC MAPP undosDistance (moves)70000060000050000040000030000020000010000000246 8 10 12 14 16 18 20Number agents (100s)Figure 9: typical case improved distances R C APP normal APP. Note precomputed -paths affected R C enhancement.section, first evaluate improvement repositioning counting (R C)standard reverse repositioning. compare total distance travelled R C APPFAR W HCA *.9.3.1 R EDUCING U NDO OVESidentified excessive undoing moves repositioning bottleneck Basic APP. Figure 9 shows benefits repositioning counting (R C), enhancement described Section 8. figure compares total travelled distance, well number undo moves,R C+T I+AC APP (shown R C APP short) I+AC APP (M APP short) average case. shown, repositioning counting turns quite effective, eliminating manyunnecessary undo moves (that help reach globally restored state). Averagedentire data set, R C APP 59.7% shorter undo distance APP standard reverserepositioning, results reducing total travelled distance 30.4% average.9.3.2 C OMPARING OTAL ISTANCE FAR W HCA *(8,1)evaluate solution length attempt-all R C+T I+AC APP compared FARW HCA *(8,1). plot total travel distance averaged subset input instancesalgorithms considered fully solve.Figures 10 11 show average results maps. APP, show lengthprecomputed paths, number undo (repositioning) moves, total travelled distance.According performance criterion, set maps roughly partitioned three subsets.good case, map 307, APP performs better W HCA *(8,1) without diagonalsterms total travel distance, even comparable FAR. average case, APPs travel82fiM APP : CALABLE ULTI -AGENT PATH P LANNINGTotal Travel Distance: Good Case (307)90000WHCA*(8,1) noDFARMAPP TotalWHCA*(8,1)MAPP PiMAPP Undos700006000050000250000Distance80000DistanceTotal Distance Travelled: Average Case (411)3000004000030000200000WHCA* noDMAPP TotalFARWHCA*(8,1)MAPP PiMAPP Undos1500001000002000050000100000100200300400 500 600Number agents7008000900200Total Distance Travelled (603)160000Distance140000120000100000WHCA* noDMAPP TotalWHCA*FARMAPP PiMAPP Undos2500008000060000200000MAPP TotalWHCA* noDFARMAPP PiWHCA*MAPP Undos1500001000004000050000200000100600 800 1000 1200 1400 1600Number agentsTotal Distance Travelled (602)300000Distance180000400200300400 500 600 700Number agents80009002004006008001000Number agents1200Figure 10: Distance travelled plotted averaged instances fully solved algorithms.distance roughly comparable W HCA * without diagonals. Maps 603, 411, 602 belongcategory. Finally, harder case, APPs total distance increases faster rateothers, direct result increasingly larger number undo moves. harder casesinclude maps 204, 414, 700, 400, 300, 500. Upon inspection, cases typically involvehigh number turns corners. APPs case, results high degree path overlapping,units keep close edge rounding corner, obtain shorter -paths.summarise overall results, APPs travel distance ranges 18.5% shorter W HCA *without diagonal moves, 132% longer, 7% longer average. Comparedversion W HCA * diagonal moves enabled, APPs total distance 31% longer average,varying 5.8% shorter 154% longer. Compared FAR, APPs solutions range4.8% shorter 153% longer, 20% longer average.closer look results reveals that, even repositioning counting use, APPstill make unnecessary undo moves. useless undo move counts double final solutionlength, since undo matched new forward move next progression step.Improving solution length promising direction future work.9.4 Running Time Analysiscase travel distance analysis, meaningful runtime comparison, also restrictanalysis subset instances completed algorithms (FAR, W HCA * versions,83fiWANG & B OTEATotal Travel Distance: Harder Case (700)300000Distance250000200000MAPP TotalWHCA*(8,1) noDFARMAPP PiWHCA*MAPP Undos150000Total Distance Travelled (300)400000350000300000Distance350000250000200000150000100000100000500005000002004000600 800 1000 1200 1400Number agentsMAPP TotalWHCA* noDFARMAPP PiWHCA*MAPP Undos200MAPP TotalWHCA* noDFARMAPP PiWHCA*MAPP Undos250000200000MAPP TotalWHCA*(8,1) noDFARMAPP PiWHCA*(8,1)MAPP Undos150000100000500000200 400 600 800 1000 1200 1400 1600 1800 2000Number agents200 400 600 800 1000 1200 1400 1600 1800 2000Number agentsTotal Distance Travelled (414)300000Distance250000200000MAPP TotalWHCA* noDFARMAPP PiWHCA*MAPP Undos150000Total Distance Travelled (500)300000250000Distance350000200000MAPP TotalWHCA* noDFARMAPP PiWHCA*MAPP Undos15000010000010000050000500000600 800 1000 1200 1400Number agentsTotal Travel Distance (204)300000DistanceDistanceTotal Distance Travelled (400)5000004500004000003500003000002500002000001500001000005000004000200 400 600 800 1000 1200 1400 1600 1800 2000Number agents200400600 800 1000 1200 1400Number agentsFigure 11: Distance travelled continued: remaining six maps.I+AC+R C APP attempt-all feature turned on). show overall summary data,Tables 2 3, charts 10 maps, Figures 12 13.implementation APP builds scratch required paths, including -paths.However, -paths re-used instances map. -pathscontain target current instance might recomputed. small percentage-paths, since number targets typically much smaller map size.evidence strongly supports taking -path computations offline map pre-processing stepimprove APPs running time. Hence, distinguish case APP performscomputations scratch, case alternate paths (i.e., paths) alreadyavailable (e.g., previous instances map hand, result preprocessing). Note84fiM APP : CALABLE ULTI -AGENT PATH P LANNINGTime ratio:AverageMinMaxvs FAR10.142.9060.46vs W HCA *0.960.084.57vs W HCA *+d0.930.114.92Table 2: APPs runtime divided runtime FAR, W HCA *, W HCA *+d. table,assume APP performs computations, including alternate-path search,scratch.Time ratio:AverageMinMaxvs FAR2.180.567.00vs W HCA *0.210.010.99vs W HCA *+d0.190.010.70Table 3: APPs runtime divided runtime FAR, W HCA *, W HCA *+d. table,time compute alternate paths omitted, could re-used instancesmap.FAR W HCA *, computation depends every units start target locations,therefore cannot easily taken map pre-processing step (since storing entire search treestake much memory practical).Table 2 shows that, APP performs computations scratch, comparablespeed W HCA *, actually slightly faster average. However, version APP10 times slower FAR average. paths already available, APPs speedimproves significantly, -path computation expensive part APP. seenTable 3, APPs speed ratio vs FAR reduces 2.18. APP also becomes 4.85.2 times fasterW HCA *(with without diagonals) average.Figure 12 shows detailed runtime data 8 10 maps. Even computation scratch, APP faster W HCA *+d (i.e., diagonal moves enabled). alsooften faster, least comparable, W HCA * without diagonals. APP offline preprocessing reasonably close FAR, even though FAR consistently faster least comparableAPP. remaining two maps, represent difficult cases APP, presentedFigure 13. map 700 especially, largest data set, also significantly largerrest (almost 24 times larger), APP significantly higher total time, shown topright Figure 13.break APPs total running time (shown bottom Figure 13 map 700)consistently shows search time dominates. Furthermore, node expansions, nodeexpansions generally several times greater node expansions, resulting majoritypath computation time spent searching -paths.85fiWANG & B OTEATotal Running Times (411)400WHCA*(8,1) noDWHCA*(8,1)MAPP totalMAPP preprocessingFAR300250120100Time (s)350Time (s)Total Running Times (307)14020015080604010020500WHCA*(8,1) noDWHCA*(8,1)MAPP totalMAPP preprocessingFAR2004000100600 800 1000 1200 1400 1600Number agents2004009003001007008000900200 400 600 800 1000 1200 1400 1600 1800 2000Number agentsTotal Running Times (602)400WHCA*(8,1) noDWHCA*(8,1)MAPP totalMAPP preprocessingFAR350300Time (s)Time (s)400800200WHCA*(8,1)WHCA*(8,1) noDMAPP totalMAPP preprocessingFAR500700WHCA*(8,1)MAPP totalWHCA*(8,1) noDMAPP preprocessingFAR500Total Running Times (414)600400 500 600Number agentsTotal Running Times (204)600Time (s)Time (s)Total Running Times (603)500WHCA*(8,1) noD450WHCA*(8,1)MAPP total400350 MAPP preprocessingFAR300250200150100500100 200 300 400 500 600Number agents3003002002502001501001000500200 400 600 800 1000 1200 1400 1600 1800 2000Number agentsTotal Running Times (300)300400350300Time (s)Time (s)200150100600800Number agents10001200MAPP totalWHCA*(8,1) noDWHCA*(8,1)MAPP preprocessingFAR250200150100500400Total Running Times (400)450WHCA*(8,1) noDWHCA*(8,1)MAPP totalMAPP preprocessingFAR25020050200400600800 1000Number agents120001400200 400 600 800 1000 1200 1400 1600 1800 2000Number agentsFigure 12: Runtime data averaged fully completed instances algorithms. Map IDsdisplayed shorthand brackets. APP preprocessing stands versioncomputes alternate paths.86fiM APP : CALABLE ULTI -AGENT PATH P LANNINGTotal Running Times (500)140Time (s)120100Total Running Times: Worst Case (700)350WHCA*(8,1)MAPP totalWHCA*(8,1) noDMAPP preprocessingFARMAPP totalWHCA*(8,1)WHCA*(8,1) noD250 MAPP preprocessingFAR200300Time (s)16080601504010020500200400600800 1000Number agents120001400200400600800 1000Number agents12001400MAPP Times Breakdown (700)350Total RuntimeTotal SearchOmega SearchRepositioning300Time (s)250200150100500200400600800 1000Number agents12001400Figure 13: Top: hard cases I+AC+R C APPs total runtime. Bottom: time breakdown, showing -path computation takes majority APPs search time.10. ConclusionTraditional multi-agent path planning methods trade optimality, completeness, scalability. centralised method typically preserves optimality (theoretical) completeness,decentralised method achieve significantly greater scalability efficiency. hand,approaches shortcomings. former faces exponentially growing state spacenumber units. latter gives optimality offers guarantees respect completeness, running time solution length. new approach, aimed bridging missing links,identifies classes multi-agent path planning problems solved polynomial time.also introduced algorithm, APP, solve problems classes, low polynomial upperbounds time, space solution length.performed detailed empirical evaluation APP. extended APPs completenessrange reaches 92%99.7%, even challenging scenarios 2000 mobile units.completeness range even better scenarios fewer units. data set, APP significantly better percentage solved units (98.82% provably solvable, 99.86% attempt-allmode) FAR (81.87%) W HCA * (77.84% 80.87%, without diagonal moves).attempt-all version APP solves 1326% instances benchmark algorithms.87fiWANG & B OTEAinstances solved algorithms, APP significantly faster variants W HCA *,slower fast FAR algorithm factor 2.18 average, alternatepaths needed instance readily available. performing computations scratch,APPs speed comparable W HCA *. APPs solutions reported average 20% longerFARs solutions 731% longer W HCA *s solutions. However, unlike algorithmsFAR W HCA *, APP offer partial completeness guarantees low-polynomial boundsruntime, memory solution length. Thus, APP combines strengths two traditionalapproaches, providing formal completeness upper-bound guarantees, well scalableefficient practice.findings presented open avenues future research large-scale multi-agentpathfinding. long term, APP part algorithm portfolio, since cheaplydetect guaranteed solve instance. Thus worthwhile investigate tractableclasses, subclasses FAR complete. APP improved run faster,compute better solutions, cover instances. Solution quality measuredtotal travel distance, also terms makespan (i.e., total duration actions runparallel) total number actions (including move wait actions). far, workedrelaxing two original LIDABLE conditions: target isolation alternate connectivity. Futurework could address initial blank condition. Moreover, initially non-S LIDABLE unitsproblem could become LIDABLE later on, LIDABLE units getting solved.Extending APP instances units heterogeneous size speed another promisingdirection.AcknowledgmentsNICTA funded Australian Governments Department Communications, InformationTechnology, Arts Australian Research Council Backing Australias AbilityICT Research Centre Excellence programs.Many thanks Nathan Sturtevant providing HOG framework, helpunderstanding program. Thanks also Philip Kilby, Jussi Rintanen, Nick Haymany helpful comments. thank anonymous reviewers valuable feedback.ReferencesBarraquand, J., Langlois, B., & Latombe, J.-C. (1991). Numerical potential field techniquesrobot path planning. International Conference Advanced Robotics (ICAR), Vol. 2, pp.10121017.Bulitko, V., Sturtevant, N., Lu, J., & Yau, T. (2007). Graph Abstraction Real-time HeuristicSearch. Journal Artificial Intelligence Research (JAIR), 30, 51100.Choset, H., Lynch, K., Hutchinson, S., Kantor, G., Burgard, W., Kavaraki, L., & Thrun, S. (2005).Principles Robot Motion: Theory, Algorithms, Implementation. MIT Press.Erdmann, M., & Lozano-Perez, T. (1986). Multiple Moving Objects. IEEE InternationalConference Robotics Automation (ICRA), pp. 14191424.Geramifard, A., Chubak, P., & Bulitko, V. (2006). Biased Cost Pathfinding. Artificial IntelligenceInteractive Digital Entertainment conference (AIIDE), pp. 112114.88fiM APP : CALABLE ULTI -AGENT PATH P LANNINGHart, P., Nilsson, N., & Raphael, B. (1968). Formal Basis Heuristic DeterminationMinimum Cost Paths. IEEE Transactions Systems Science Cybernetics, 4(2), 100107.Hopcroft, J. E., Schwartz, J. T., & Sharir, M. (1984). complexity motion planningmultiple independent objects: PSPACE-hardness warehousemans problem. International Journal Robotics Research (IJRR), 3(4), 7688.Jansen, R., & Sturtevant, N. (2008). New Approach Cooperative Pathfinding. InternationalConference Autonomous Agents Multiagent Systems (AAMAS), pp. 14011404.Kant, K., & Zucker, S. W. (1986). Toward Efficient Trajectory Planning: Path-Velocity Decomposition. International Journal Robotics Research (IJRR), 5(3), 7289.Kornhauser, D., Miller, G., & Spirakis, P. (1984). Coordinating pebble motion graphs, diameter permutation groups, applications. Proceedings 25th Annual SymposiumFoundations Computer Science (FOCS), pp. 241250.Latombe, J.-C. (1991). Robot Motion Planning. Kluwer Academic Publishers.Papadimitriou, C., Raghavan, P., Sudan, M., & Tamaki, H. (1994). Motion planning graph.35th Annual Symposium Foundations Computer Science, pp. 511520.Pottinger, D. (1999). Coordinated Unit Movement. http://www.gamasutra.com/view/feature/3313/coordinated_unit_movement.php.Rabin, S. (2000). A* Speed Optimizations. Deloura, M. (Ed.), Game Programming Gems, pp.272287. Charles River Media.Ratner, D., & Warmuth, M. (1986). Finding shortest solution N N extension 15puzzle intractable. Proceedings AAAI National Conference Artificial Intelligence(AAAI-86), pp. 168172.Ryan, M. R. K. (2008). Exploiting Subgraph Structure Multi-Robot Path Planning. JournalArtificial Intelligence Research (JAIR), 31, 497542.Samet, H. (1988). Overview Quadtrees, Octrees, Related Hierarchical Data Structures.NATO ASI Series, Vol. F40.Silver, D. (2005). Cooperative Pathfinding. Artificial Intelligence Interactive Digital Entertainment conference (AIIDE), pp. 117122.Silver, D. (2006). Cooperative pathfinding. AI Programming Wisdom, 3, 99111.Standley, T. (2010). Finding Optimal Solutions Cooperative Pathfinding Problems. Proceedings Twenty-Fourth AAAI Conference Artificial Intelligence (AAAI-10), pp. 173178.Stout, B. (1996). Smart Moves: Intelligent Pathfinding. Game Developer Magazine.Sturtevant, N. R., & Buro, M. (2006). Improving collaborative pathfinding using map abstraction..Artificial Intelligence Interactive Digital Entertainment (AIIDE), pp. 8085.Surynek, P. (2009a). Application Pebble Motion Graphs Abstract Multi-robot Path Planning. Proceedings 21st International Conference Tools Artificial Intelligence(ICTAI), pp. 151158.Surynek, P. (2009b). novel approach path planning multiple robots bi-connected graphs.IEEE International Conference Robotics Automation (ICRA), pp. 36133619.89fiWANG & B OTEASurynek, P. (2010a) personal communication.Surynek, P. (2010b). Optimization Variant Multi-Robot Path Planning Intractable.Proceedings 24th AAAI Conference Artificial Intelligence (AAAI-10), pp. 12611263.Surynek, P. (2010c). Multi-robot Path Planning, pp. 267290. InTech - Open Access Publisher.Tarjan, R. E. (1976). Edge-disjoint spanning trees depth-first search. Acta Informatica, 6(2),171185.Tozour, P. (2002). Building Near-Optimal Navigation Mesh. Rabin, S. (Ed.), AI Game Programming Wisdom, pp. 171185. Charles River Media.Wang, K.-H. C., & Botea, A. (2008). Fast Memory-Efficient Multi-Agent Pathfinding. Proceedings International Conference Automated Planning Scheduling (ICAPS),pp. 380387.Wang, K.-H. C., & Botea, A. (2009). Tractable Multi-Agent Path Planning Grid Maps. Proceedings International Joint Conference Artificial Intelligence (IJCAI), pp. 18701875.Wang, K.-H. C., & Botea, A. (2010). Scalable Multi-Agent Pathfinding Grid MapsTractability Completeness Guarantees. Proceedings European ConferenceArtificial Intelligence (ECAI), pp. 977978.Zelinsky, A. (1992). mobile robot navigation exploration algorithm. IEEE TransactionsRobotics Automation, 8(6), 707717.90fiJournal Artificial Intelligence Research 42 (2011) 917-943Submitted 03/11; published 12/11Interpolable Formulas Equilibrium LogicAnswer Set ProgrammingDov Gabbaydov.gabbay@kcl.ac.ukBar Ilan University Israel, Kings College LondonUniversity Luxembourg.David Pearcedavid.pearce@upm.esAI Dept, Universidad Politecnica de Madrid, Spain.Agustn Valverdevalverde@ctima.uma.esDept Applied Mathematics, Universidad de Malaga, Spain.AbstractInterpolation important property classical many non-classical logicsshown interesting applications computer science AI. studyInterpolation Property non-monotonic system equilibrium logic, establishing weaker stronger forms interpolation depending precise interpretationinference relation. results also yield form interpolation ground logicprograms answer sets semantics. disjunctive logic programs also studyproperty uniform interpolation closely related concept variable forgetting. first-order version equilibrium logic analogous Interpolation propertieswhenever collection equilibrium models (first-order) definable. Sincecase so-called safe programs theories, applies usual situations arisepractical answer set programming.1. Introductioninterpolation property important much discussed topic logical systems,classical non-classical (Gabbay & Maksimova, 2005). importance computerscience also becoming recognised nowadays. interpolation property appliedvarious areas computer science, example software specification (Diaconescu,Goguen, & Stefaneas, 1993; Bicarregui, Dimitrakos, Gabbay, & Maibaum, 2001),construction formal ontologies (Kontchakov, Wolter, & Zakharyaschev, 2008)model checking related subareas (McMillan, 2005). first two areas interpolationimportant metatheoretical property, particular may provide basis modular composition decomposition theories; instance, Kontchakov et al. (2008)plays key role study modular decomposition ontologies.cases, interpolants play role special formulas applied automated deduction (McMillan, 2005).date interpolation received much less attention systems non-monotonicreasoning logic programming, despite importance AI computer science.note study interpolation property system nonmonotonic reasoningknown equilibrium logic (Pearce, 2006). Since turn regarded logicalfoundation stable model reasoning answer set programming (ASP), resultstransfer immediately sphere ASP. shall focus mainly interpolationc2011AI Access Foundation. rights reserved.fiGabbay, Pearce, & Valverdemetatheoretical property primary interest establishing property certaincases interest. Although Section 8 consider case interpolant (actuallyuniform interpolant) explicitly constructed, mainly concerned pureexistence theorems. Discussion complexity issues well possible applicationsinterpolation property ASP left future work. However, seems likely that,case studies involving formal ontologies (Konev, Walther, & Wolter, 2009), interpolationmay useful property applications ASP knowledge representation. previouspaper (Pearce & Valverde, 2012), interpolation Beth properties underlying,monotonic logic ASP used characterise strong kinds intertheory relations.capture weaker kinds intertheory relations may important able relyinterpolation holding extended, non-monotonic logic. plan explore avenuefuture.introduce property interpolation, let us start notation terminology. Let us assume syntax first-order logic formulas denoted lower caseGreek letters predicates lower case Latin letters.Let monotonic inference relation suppose . interpolant(, ) formula&(1)contains predicate constant symbols belong . logic Linference relation L said interpolation property interpolant existsevery pair formulas (, ) L . well-known, classical logic wellmany non-classical logics possess interpolation.Suppose deal non-monotonic logical system inference relation |.express idea formula interpolant generally suffice simplyreplace | (1). One problem that, since | non-monotonic, generaltransitive. Instead, following idea Gabbay Maksimova (2005), modifycondition (1) proceed two-stage fashion. make use fact nonmonotonic consequence defined terms minimal models monotoniclogical system, say consequence relation | appropriately captured meansminimal models logic L consequence relation |=L . suppose | .interpolant (, ) look formula| & |=L(2)predicate constant symbols occur . Since |defined via subclass minimal L-models, already assume |=L |. Moreoverassume L well-behaved sublogic sense L-equivalentformulas |-consequences L-consequences |-consequences|-consequences (so e.g. (2) derive | ). non-monotonicreasoning last two properties known left right absorption, respectively.Given conditions, follows (2) formula languageL-equivalent also interpolant (, ). Likewise interpolant(, ) |=L | interpolant (, ).Now, find interpolant (, ) satisfying (2), prove one always exists,proceed follows. look L-formula say, precisely L-defines918fiInterpolable Formulas Equilibrium Logic Answer Set Programmingminimal models . Since | follows |=L . Now, L interpolationproperty defined earlier, apply theorem obtain infer existenceL-interpolant sense (1) ( , ). Hence (2) follows.Notice two-stage procedure relies three key features: (i) identifysuitable monotonic sublogic L |, (ii) formulas minimal models L-definable,(iii) L interpolation property. conditions prima facie independent. shall see, may (i) (iii) lack (ii). situation respectequilibrium logic follows. propositional case three conditions met,establish interpolation property general case. situation quantifiedequilibrium logic complicated. general case, lack condition (ii).precisely, appropriate monotonic sublogic L logic interpolationproperty, equilibrium models formula need first-order definable L.procedure outlined yield interpolants cases. However recent results generalised concept (first-order) stable model imply interestingclasses interpolable formulas: shall consider detail one class, safeformulas. particular, safe formula | , exists interpolant(2) holds. classes interpolable formulas so-called tight formulas,formulas possessing finite, complete set called loops.Safety, tightness loop formulas studied length answer set programming (ASP). implications results ASP summarised follows.case (finite) ground programs interpolation property holds. first-ordernon-ground case, interpolation holds finite, safe programs without function symbols,hence practically finite programs currently admitted answer set solvers. Moreover,since safety defined arbitrary formulas function-free language, classsafe formulas sense goes beyond class expressions normally admitted ASP,even auxiliary concepts like weight constraints aggregates included.2. Logical Preliminarieswork standard propositional predicate languages, latter maygeneral case contain constant function symbols. Propositional languages basedset V propositional variables, formulas built-up usual way usinglogical constants , , , , standing respectively conjunction, disjunction, implicationnegation. propositional formula, denote V () set propositionalvariables appearing .first-order language L = hC, F, P consists set constants C, function symbolsF predicate symbols P ; function symbol f F predicate symbol p Passigned arity. Moreover, assume fixed countably infinite set variables,symbols , , , , , , auxiliary parentheses (, ). Atoms, termsformulas constructed usual; closed formulas, sentences,variable bound quantifier. (first-order) formula, L() denoteslanguage associated , i.e. set constants, function predicate symbols occuringit.make use following notation terminology. Boldface x stands tuplevariables, x = (x1 , . . . , xn ), (x) = (x1 , . . . , xn ) formula whose free variables919fiGabbay, Pearce, & Valverdex1 ,. . . , xn , x = x1 . . . xn . ti terms, = (t1 , . . . , tn ) denotes vectorterms. theory set sentences. Variable-free terms, atoms, formulas, theoriesalso called ground.usual symbols |=, possibly subscripts, used denote logicalinference consequence relations, respectively. logic L said monotonicinference relation L satisfies monotonicity property:L & Ldistinguish non-monotonic monotonic inference relations, use | symboliseformer. cases non-monotonic logic understood terms inferencerelation extends suitable monotonic logic. extension well-behavedsay monotonic logic forms deductive base 1 (Pearce, 2006) it.made precise follows.Definition 1 Let | nonmonotonic inference relation. say logic Lmonotonic inference relation L deductive base | iff (i) L |; (ii) 1 L 21 2 ; (iii) | L , | .L denotes ordinary logical equivalence L, denotes non-monotonic equivalence, i.e. 1 2 means 1 2 non-monotonic consequences.Furthermore, say deductive base strong satisfies additional condition:1 6L 2exists 1 6 2 .terms nonmonotonic consequence operations, (ii) (iii) correspond conditionsknown left absorption right absorption respectively (Makinson, 1994).2.1 Interpolationturn interpolation property.Definition 2 logic L inference relation L said interpolation propertywheneverLexists sentence (the interpolant)L & Lpredicate, function constant symbols contained ,i.e. L() L() L(). case propositional logic, requirement V ()V () V ().explained introduction, non-monotonic logics consider two formsinterpolation, one weaker one stronger. stronger form makes use underlyingmonotonic logic.1. close concept fully absorbing inferential frame used Dietrich (1994).920fiInterpolable Formulas Equilibrium Logic Answer Set ProgrammingDefinition 3 Suppose | . (|, L ) interpolant (, ) formula| & L(3)L deductive base | contains predicate, function constantsymbols belong . non-monotonic logic inference relation |said (|, ) interpolation property suitable deductive base logic L(|, L ) interpolant exists every pair formulas (, ) | .requirement L form deductive base ensures desirable propertiesinterpolation met.Proposition 1 Let (|, L ) interpolant (, ).(a) L , (|, L ) interpolant (, ).(b) L , L , (|, L )interpolant ( , ).property deductive base also guarantees (|, L ) relation transitivesense (3) holds , , , also | . last property necessarilyhold second, weaker form interpolation call (|, |) interpolation.Definition 4 Suppose | . (|, |) interpolant (, ) formula| & |(4)contains predicate, function constant symbols belong .case propositional logic, requirement V () V () V ().Analogous previous case, say non-monotonic logic inference relation | (|, |) interpolation property (|, |) interpolant exists every pairformulas (, ) | . Notice (|, ) stronger form interpolationlogic (|, ) interpolation must also (|, |) interpolation,consequence deductive base requirement (first clause).Evidently properties expressed Proposition 1 directly applicablesecond form interpolation refer underlying base logic. Neverthelessimportant feature interpolation properties shall establishformulate prove analogous properties even (|, |) interpolation.also consider restricted variants interpolation property holdscertain types formulas, words, interpolant (, ) given| whenever belong specific syntactic classes. cases referinterpolable formulas. Later shall consider kinds restrictions, belongsspecific class alternatively does.2.2 Review Logic Here-and-ThereEquilibrium logic based nonclassical logic here-and-there, denoteHT propositional case. quantified first-order case denote logicQHT, subscripts/superscripts denote specific variants.921fiGabbay, Pearce, & Valverdepropositional quantified cases logic based axioms rulesintuitionistic logic captured usual Kripke semantics intuitionistic logic (vanDalen, 1997). However additional axioms HT QHT mean usesimple kinds Kripke structures. first-order case regard structuressets atoms built arbitrary non-empty domains D; denote At(D, F, P ) setatomic sentences hD, F, P (if = C, obtain set atomic sentencelanguage L = hC, F, P i);2 denote (D, F ) set ground terms hD, F, P i.L = hC, F, P L = hC , F , P i, write L L C C , F F P P .L-interpretation set mean subset At(D, F, P ). classical Lstructure regarded tuple = h(D, I), L-interpretation: (C D, F ) D, called assignment, verifies I(d) =recursively defined.3 = (C, F ) = id, known Herbrand structure.hand, here-and-there L-structure static domains, QHTs (L)-structure,tuple = h(D, I), h , h(D, I), h h(D, I), classical L-structuresh .Thus think here-and-there structure similar first-order classicalmodel, two parts, components, h correspond two different pointsworlds, there, sense Kripke semantics intuitionistic logic,worlds ordered h t. world w {h, t} one verifies set atoms wexpanded language domain D. call model static, since, contrastsay intuitionistic logic, domain serves worlds. Since h < t, whateververified h remains true t. satisfaction relation defined reflecttwo different components, write I, w |= denote true respectw component. Although need define satisfaction relation L = hC, P i,recursive definition forces us consider formulas hC D, F, P i. particular,p(t1 , . . . , tn ) At(C D, F, P ) I, w |= p(t1 , . . . , tn ) iff p(I(t1 ), . . . , I(tn )) wevery t1 , . . . , tn (C D, F ). |= extended recursively follows4 :I, w |= iff I, w |= I, w |= .I, w |= iff I, w |= I, w |= .I, |= iff I, 6|= I, |= .I, h |= iff I, |= I, h 6|= I, h |= .I, w |= iff I, 6|= .I, |= x(x) iff I, |= (d) D.I, h |= x(x) iff I, |= x(x) I, h |= (d) D.I, w |= x(x) iff I, w |= (d) D.2. think objects additional constants; approach allow us use simplifiednotation objects distinguished names.3. is, every C, I(a) every f F arity n, mapping f : Dn defined;recursive definition given I(f (t1 , . . . , tn )) = f (I(t1 ), . . . , I(tn )).4. following corresponds usual Kripke semantics intuitionistic logic given assumptionstwo worlds h single domain D,922fiInterpolable Formulas Equilibrium Logic Answer Set ProgrammingTruth sentence model defined follows: |= iff I, w |=w {h, t}. sentence valid true models, denoted |= . sentenceconsequence set sentences , denoted |= , every model model .resulting logic called Quantified Here-and-There Logic static domains (Lifschitz, Pearce, & Valverde, 2007) denoted QHTs . terms satisfiability validitylogic equivalent logic introduced Pearce Valverde (2005).complete axiomatisation QHTs obtained follows (Lifschitz et al., 2007).take axioms rules first-order intuitionistic logic add axiom Hosoi( ( ))(5)determines 2-element here-and-there models propositional case, togetheraxiom:x((x) x(x))..also consider equality predicate, =6 P , interpreted following conditionevery w {h, t}.I, w |= t1 = t2 iff I(t1 ) = I(t2 ).obtain complete axiomatisation, need add axiom decidible equality..xy(x = x =6 y).denote resulting logic QHTs= (Lifschitz et al., 2007) inference relation. compactness strong form completeness established |=.context logic programs, following assumptions often play role. caseclassical QHTs= models, say parameter names assumption (PNA)applies case I|T (C,F ) surjective, i.e. unnamed individuals D; uniquenames assumption (UNA) applies case I|T (C,F ) injective; case PNAUNA apply, standard names assumption (SNA) applies, i.e. I|T (C,F ) bijection.usual first order logic, satisfiability validity independent signature.= h(D, I), h , L -structure L L, denote I|L restrictionsublanguage L:I|L = h(D, I|L ), h |L , |LProposition 2 Suppose L L, theory L L -model .M|L L-model .Proposition 3 Suppose L L L. valid (resp. satisfiable)QHTs= (L) valid (resp. satisfiable) QHTs= (L ).proposition allows us omit reference signature logicdenoted simply QHTs= .simplify notation also symbolise QHTs= structure = h(D, I), h ,hU, H, i, U = (D, I) universe, H, respectively sets atomsh , . case propositional HT logic, Kripke structures regarded pairshH, set atoms obvious way. (strongly) complete axiomatisation HTobtained intuitionistic logic adding Hosoi axiom (5).923fiGabbay, Pearce, & Valverde2.3 Interpolation Logic Here-and-Thereimportant useful property HT fact strongest propositionalintermediate logic (i.e. strengthening intuitionistic logic) properly containedclassical logic. Moreover turn properly contains intermediate logics.addition HT one precisely seven superintuitionistic propositional logics possessinginterpolation property (Maksimova, 1977; Gabbay & Maksimova, 2005).languages without function symbols Ono showed interpolation holdslogic QHTs quantified here-and-there constant domains (Ono, 1983).5 addition,Maksimova (1997, 1998) showed adding pure equality axioms, e.g. decidible equality axiom, superintuitionistic logic preserves interpolation property (Gabbay &Maksimova, 2005). conclude thereforeProposition 4 logic QHTs= possesses interpolation property.Note strong completeness theorem QHTs= work equivalently|=.make observation interpolation continues hold languages include function symbols. established using following property.Proposition 5 every formula , possible build formula , ,atoms one following types:.x = C,.f (x1 , . . . xn ) = f F (where every xi variables),p(t1 , . . . , tm ) (where every xi variables).Theorem 1 Let L language containing function symbols. QHTs= (L)interpolation property.Proof sketch: Let us assume ; previous proposition, assume,without loss generality, function symbols atoms type.f (x1 , . . . xn ) = y. Now, consider language L obtained L replacing everyfunction symbol f fresh predicate symbol, Pf , Arity(Pf ) = 1 + Arity(f ).Let formulas L build respectivelly, replacing every atom.f (x1 , . . . xn ) = Pf (x1 , . . . xn , y). Trivially, and, interpolation propertyQHTs= (L ), exists interpolant : , . replace.predicates Pf (t1 , . . . , tn , tn+1 ) atoms f (t1 , . . . tn ) = tn+1 obtain interpolantinitial pair formulas.5. Onos axiomatisation QHTs uses constant domains axiom x((x) ) (x(x) ), wellalternative axioms propositional here-and-there, viz. p (p (q q)) (p q) (q p) (pq). However, axioms given equivalent Onos.924fiInterpolable Formulas Equilibrium Logic Answer Set Programming2.4 Equilibrium LogicEquilibrium logic non-monotonic logic based certain kinds minimal modelsQHTs= HT. give definition QHTs= ; propositional version easilyobtained it.Definition 5 Among quantified here-and-there structures define order E follows:h(D, I), h , E h(D , J), J h , J= , = J, = J , h J h .subset relation holds strictly, write .Definition 6 (Equilibrium model) Let theory = h(D, I), h , model.1. said total h = .2. said equilibrium model (or short, say: equilibrium)minimal E among models , total.words, equilibrium models total models smaller non-totalmodel. Evidently total QHTs= model theory equivalently regardedclassical first order model ; follows make tacit use equivalence.propositional case, equilibrium models defined way,ordering propositional HT models. usual way formula theory saidconsistent QHTs= model additionally say coherentequilibrium model.following definition give preliminary notion equilibrium entailment,agrees standard versions equilibrium logic (Pearce, 2006).Definition 7 relation |, called equilibrium entailment, defined follows. Letset formulas.1. non-empty coherent (has equilibrium models), | every equilibrium model model QHTs= (respectively HT).2. either empty equilibrium models, | .Notice unless need distinguish propositional first-order reasoning usesymbols |, |= either version.words may help explain concept equilibrium entailment. First,define basic notion entailment truth every intended (equilibrium) model.nonmonotonic reasoning common approach sometimes called skepticalcautious notion entailment inference; counterpart brave reasoning definedvia truth intended model. Since equilibrium logic intended provide logicalfoundation answer set semantics logic programs, cautious variant entailmentnatural one choose: standard consequence relation associated answersets given truth answer sets program. Note however ASPprogramming paradigm answer set may correspond particular solutionproblem modelled therefore interest right.925fiGabbay, Pearce, & ValverdeSecondly, useful nonmonotonic consequence entailment relationnon-trivially defined consistent theories. shall see below, however,theories possess equilibrium models. cases natural use monotonic consequence entailment relation. particular propositional case HT maximallogic property logically equivalent theories equilibrium models.Evidently situation 2 also handles correctly cases empty inconsistent.Despite qualifications, remains ambiguity concept equilibriumentailment need settle. Suppose L L, theory Lsentence L (i.e. L = L()). understand expression | ?Evidently, fix language advance, say language L , simplyconsider equilibrium models L . represents knowledge base logicprogram, instance, may also take view L() appropriate signaturework with. case, query fully interpreted containsterms theory language L().language L theory whose language contained L, let EML ()collection equilibrium models QHTs= (L). consider following twovariants entailment.Definition 8 (Equilibrium entailment) Assume theory L, non-emptyequilibrium models, then:(i) Let us write |cw |= EML (), L = LL():(ii) let us write |ow |= EML () L() ,general EML () L denotes collection expansions elements EML ()models L L , i.e. vocabulary L \ L interpreted arbitrarily.(iii) either empty equilibrium models, |cw iff |ow iff .simple example illustrate difference |cw |ow . LetL-sentence let q(x) predicate L. Let constant L let Llanguage L {q}. first method |cw (q(a) q(a)). factstronger entailment |cw q(a). reason form equilibriummodels L , q(a) false effect taking minimal models.hand, expand equilibrium models QHTs= (L) QHTs= (L ), newpredicate q receives arbitrary interpretation QHTs= (L ). Since logic 3-valuedobtain |ow q(a) q(a).standard, monotonic logics, difference two forms entailment. Definition 8 replace everywhere equilibrium model simply model (inQHTs= ), variants (i) (ii) give result.context logic programming deductive databases orthodox viewreasoning based closed world assumption (CWA). Accordingly ground atomicquery like q(a)?, predicate q belong language programdatabase, would simply assigned value false. also case first kindequilibrium entailment use label |cw since variant appears closerclosed world form reasoning. hand, may legitimate caseswant apply CWA unknown values assigned atomexpressed theory language. second form entailment, |ow ,926fiInterpolable Formulas Equilibrium Logic Answer Set Programmingnearer open world reasoning, may appropriate. present purposes, however,suffices cw ow thought merely mnemonic labels.thorough analysis closed world versus open world reasoning context wouldlead us consider assumptions UNA SNA outside scope paper.However, observed logic programming use CWA leadcertain apparent anomalies. Notably occurs programs unsafe (see Section5 below), following, formulated traditional notation logic programs:6q(x, y) : p(x, y).p(x, x).Given restrictions SNA Herbrand models, query? q(a, z).yields answer z cannot satisfied models single domainelement a, query? q(a, b).satisfiable, given new constant b. logic programming, restrictionsusually assumed, different solutions problem proposed (Gelder, Ross,& Schlipf, 1991; Kunen, 1987; Maher, 1988). would like pointequilibrium logic generally speaking kind program theory createspecial difficulties. Neither query? q(a, z).understood zq(a, z), query? q(a, b).true equilibrium models. particular, equilibrium model whose domainsingleton element, even q(a, b) need true; evidently general case UNAinstance apply. hand answer set programming, UNA oftenassumed, also typically assumed programs safe. safety conditionprogram excluded variables appearing head rule appearpositive body makes answer sets sensitive set constants appearinglanguage used grounding program. paper,application interpolation ASP concerned, restrict attention safe programstheories complying generalised form safety (Section 5 below).3. Interpolation Propositional Equilibrium Logicsection deal interpolation propositional equilibrium logic. clearsemantic construction propositional equilibrium logic HT deductive base.base actually maximal.Proposition 6 HT strong maximal deductive base (propositional) equilibriumentailment.first property precisely strong equivalence theorem Lifschitz, PearceValverde (2001). Maximality follows fact logic strictly strongerHT would contain classical logic easily seen deductive base,e.g. violating condition (ii) Definition 1. have:6. grateful anonymous referee raising point example.927fiGabbay, Pearce, & ValverdeLemma 1 Let coherent HT-formula EM () set equilibrium models.formula HT v() defines EM () sense EM ()|= .Proof. Suppose coherent. letM1 = hT1 , T1 i, M2 = hT2 , T2 i, . . . , Mn = hTn , Tnenumeration equilibrium models. show define EM (). SupposeTi , ki elements denote Ai1 , . . . , Aij , . . . , Aiki . Let Ti complementTi ; list members Aik1 +1 , . . . Ail . . . , Ai|v()| . Set=^j=1,...,kiAij (_Ail ),l=ki+1 ,...,|v()|=_i=1,...,nclaim |= = Mi = 1, . . . , n, i.e. modelsprecisely M1 , . . . , Mn . verify claim, note Mi |= Mi |= .Conversely, suppose |= . semantics HT clear |= iff|= |= , particular |= implies |= = 1, . . . , n. However,defines complete theory whose models total. follows |= ,= Mi . establishes claim.Although shall demonstrate interpolation (|, |) form relation |cw , actually establish stronger result. One consequenceconcerned |ow entailment (|, ) form interpolation actually holds.Proposition 7 (|, |-Interpolation) Let , formulas set v = v() v()v = v() \ v() suppose B1 , . . . Bn enumeration v . |cw ,formula v() v() v(), | , B1 . . . Bn |= . Henceparticular |cw .Proof. Let , v, v statement proposition, suppose |cw .holds equilibrium models language v. Case (i): supposecoherent form set equilibrium models, EMv ().equilibrium construction easy see model EMv ()atom Bi false, = 1, n. Construct formulas formula exactlyproof Lemma 1. consider formula (B1 . . . Bn ) . Clearly formuladefines set equilibrium models HT(v). Consequently, (B1 . . .Bn ) |=(B1 . . . Bn ) . apply interpolation theorem HTinfer formula (B1 . . . Bn ) ,v() v( ) v() hence v() v() v(). Since HT deductive base,conclude| & B1 . . . Bn .Now, since v() v() v(), Bi 6 v() = 1, n. follows HT(v()), Bifalse every equilibrium model . model satisfies (B1 . . . Bn ).7Since also satisfies , |cw .7. Notice case adding sentence (B1 . . . Bn ) change set equilibriummodels.928fiInterpolable Formulas Equilibrium Logic Answer Set ProgrammingCase (ii). equilibrium models hypothesis .case simply choose interpolant (, ).Corollary 1 (|, -Interpolation) Let , formulas |cw v()v(). formula v() v() v() |cw .Proof. Immediate Proposition 7 fact v() \ v() = .Proposition 8 (|, -Interpolation) Let , formulas set v = v() v()v = v() \ v(). |ow , formula v() v() v(), | ,.Proof. Let , v, v statement proposition suppose |ow .holds expansions elements EMv() () language v. Case (i): supposecoherent consider EMv() ().construct formulas formula exactly proof Lemma 1.consider defines set EMv() (). holds expansions modelsv. Hence |= therefore apply interpolationtheorem HT infer formula ,v() v( ) v() hence v() v() v(). Since |ow HT deductivebase conclude|ow & .Case (ii). equilibrium models, choose interpolant (, ).4. Interpolation Quantified Equilibrium Logicturn first-order logic. Given inferences form | , key elementproofs Propositions 7 8 existence formula defines collectionEMv() () equilibrium models. propositional case seen existenceestablished. first-order case, hand, needexist. words, EML() () need first-order definable arbitrary .fact hard show. Ferraris et al. (2007) pointed out, general formanswer set programming first-order formulas allowed, fortiori quantifiedequilibrium logic, property transitive closure expressible. Yet propertydefinable classical first-order logic therefore also cannot defined QHTs= .usual way say collection K QHTs= (L) models (QHTs= ) definableL-sentence, , K |= . easy see wheneverclass EML() () first-order definable QHTs= obtain first-order analogsPropositions 7 8. method proof essentially before.completeness outline main steps case (|, |)-interpolation.Proposition 9 (|, |-Interpolation) Let , formulas collection equilibrium models QHTs= - definable. Set L = L() L() L = L() \ L(). Let{pi : = 1, n} (finite, possibly empty) set predicates L suppose929fiGabbay, Pearce, & Valverdepi arity ki . |cw , formula L() L() L(), | ,^xpi (x) |=i=1,nHence particular |cw .Proof. Assume hypotheses. holds equilibrium models languageL. treat case coherent non-empty collection equilibriummodels, EML() (). assumption collection definable QHTs= (L())-sentence,, say. consider equilibrium models expanded language L, i.e.collection EML (). equilibrium construction claim EML () |= xpi (x),= 1, n. Since working first-order semantics, let us rehearsebriefly argument this. true would model hU, T, EML (),predicate symbol pi L tuple elements domain hU, T, i,hU, T, |= pi (a), ie pi (a) . However, since refer relationpi , structure hU, H, H = \ pi (a) must Valso model , contradictinghU, T, equilibrium.EML () |= i=1,n xpi (x) since definesVEML() () clearly i=1,n xpi (x) defines EML ().Vproceed propositional case. i=1,n xpi (x) ,^xpi (x) .i=1,ninterpolationtheorem QHTs= formula L() L() L(),Vi=1,n xpi (x) . Consequently also^xpi (x)| &i=1,ntoken propositional case, infer |cw .case (|, )-interpolation |ow analogous state main propertywithout proof.Proposition 10 (|, -Interpolation) Let , formulas collectionequilibrium models QHTs= - definable. |ow , formulaL() L() L(), | .5. Illustration: Interpolation Safe Formulasrestrictive definability assumption? often met practice? Actuallymainstream answer set programming, whose language equilibrium logic captures extends (see next section), non-definable classes answers sets play significant role.reason query answering existing solvers rely grounders instantiateparts program computing intended models solutions. groundingprocess essentially eliminates variables reduces original program propositionalform. practical cases, then, collection stable equilibrium modelsdefinable.930fiInterpolable Formulas Equilibrium Logic Answer Set Programmingcomputational approach work general, syntactic restrictions needimposed admissible programs theories. common form restriction calledsafety. standard types logic programs based rules one regards rule safeevery variable appearing rules head also appears body. complexformulas admitted equilibrium logic general approach answer sets (Ferrariset al., 2007; Ferraris, 2008), new concepts safety need devised. Proposals suitablesafety concepts made Lee, Lifschitz Palla (2008b) general first-order formulasBria, Faber Leone (2008) restricted syntactic class. recentlyCabalar, Pearce Valverde (2009) generalised approaches suggestedsafety concept arbitrary function-free formulas equilibrium logic. Since newconcept safety defines quite broad class interpolable formulas, let us reviewmain features. following section mention kinds interpolableformulas may arise answer set programming.5.1 General Concept Safetyremainder section assume languages function-free. usualsentence said prenex form following shape, n 0:Q 1 x1 . . . Q n xnQi quantifier-free. sentence said universalprenex form quantifiers universal. universal theory set universalsentences. safety concept defined prenex formulas provide normal formQHTs= (Pearce & Valverde, 2005).first introduce concept called semi-safety. main property semi-safety formulas equilibrium models refer objects language. Noteremainder section use fact negation treateddefined operator, , consider additional semantic clausesnegation.Definition 9 (Semi-safety) quantifier free formula semi-safe nonsemi-safe variable; is, NSS() = , NSS operator recursively definedfollows:atom, NSS() set variables ;NSS(1 2 ) = NSS(1 ) NSS(2 );NSS(1 2 ) = NSS(1 ) NSS(2 );NSS(1 2 ) = NSS(2 ) r RV(1 ),operator RV computes restricted variables follows:atomic , equality two variables RV() = ; otherwise,RV() set variables occurring ;RV() = ;931fiGabbay, Pearce, & ValverdeRV(1 2 ) = RV(1 ) RV(2 );RV(1 2 ) = RV(1 ) RV(2 );RV(1 2 ) = .definition semi-safe formulas introduced Cabalar, Pearce Valverde (2009)generalises former definition Lee, Lifschitz Palla (2008b). short, variable x semi-safe every occurrence inside subformula that,either x RV() x semi-safe .examples semi-safe formulas are, instance:p(x) (q(x) r(x))p(x) q r(x)(6)Note (6), x restricted p(x) q consequent r(x) semi-safethus formula itself. contrary, following formulas semi-safe:p(x) q r(x)p(x) r(x) q(x)following results set previously referred property semi-safe formulas:equilibrium models include objects language.Proposition 11 (Cabalar et al., 2009)function free, semi-safe, h(D, I), T, |= , h(D, I), |C , |= .Theorem 2 (Cabalar et al., 2009) function free, semi-safe, h(D, I), T,equilibrium model , |C = .equilibrium models semi-safe formulas refer objects language,however model could equilibrium depending considered domain.guarantee independence domain, need additional property semisafety. Specifically, need analyse whether unnamed elements could modifyinterpretation formula. that, use assignments Kleenes threevalued logic; three-valued interpretation : {0, 1/2, 1}, extended evaluatearbitrary formulas () follows:( ) = min((), ())( ) = max((), ())() = 0( ) = max(1 (), ())every variable x, going use Kleenes interpretations x , defined follows:x () = 0 x occurs atom x () = 1/2 otherwise. Intuitively, x () fixesatoms containing variable x 0 (falsity) leaving rest undefinedevaluates using Kleenes three-valued operators, nothing else exploitingdefined values 1 (true) 0 (false) much possible.occurrence variable x Qx weakly-restricted occurs subformulathat:932fiInterpolable Formulas Equilibrium Logic Answer Set ProgrammingQ = , positive8 x () = 1Q = , negative x () = 0Q = , positive x () = 0Q = , negative x () = 1cases, say makes ocurrence weakly restricted . propertyadded semi-safety condition complete definition safety.Definition 10 semi-safe sentence said safe positive occurrencesuniversally quantified variables, negative occurrences existentially quantifiedvariables weakly restricted.instance, formula = x(q(x) (r p(x))) safe: occurrence xp(x) negative, whereas occurrence q(x) inside positive subformula, itself,x weakly-restricted, since x () = 0 ( 1/2 0) = 1. Another example safeformula x((p(x) q(x)) r).Proposition 12 (Cabalar et al., 2009) function free, safe, prenex formula,then: h(D, I), T, equilibrium model equilibrium modelGrC () (the grounding C).5.2 Interpolationbasis Proposition 12 could already establish interpolation theorems safeformulas prenex form, essentially replacing formulas ground versionsworking propositional logic. However, also apply Propositions 9 10 directlynoting property shown Cabalar et al. (2009) safe prenex formulas definableclasses equilibrium models.Theorem 3 (interpolation safe formulas)Safe formulas prenex formQHTs= -definable classes equilibrium models. Therefore formulas (|, |)-interpolation |cw inference holds Proposition 9 (|, )-interpolation holds |owinference Proposition 10.6. Interpolation Answer Set SemanticsAnswer set programming (ASP) become established form declarative, logic-basedprogramming basic ideas well-known. textbook treatment readerreferred Barals book (2003). also well-known, origins ASP liestable model answer set semantics logic programs introduced Gelfond Lifschitz (1988, 1990, 1991). semantics made use fixpoint condition involving certainreduct operator. Subsequent extensions concept cover general kinds rules8. Recall subexpression formula said positive number implicationscontain subexpression antecedent even, negative odd. also considerdefined .933fiGabbay, Pearce, & Valverdealso relied reduct operator similar sort. original definitions, readerreferred various papers cited.correspondence answer set semantics equilibrium logic also wellestablished discussed many publications, beginning Pearce (1997),first showed answer sets disjunctive programs regarded equilibriummodels (Lifschitz et al., 2001, 2007; Ferraris et al., 2007; Pearce & Valverde, 2005, 2006,2008). purposes suffice recall two important syntactic classesprograms main features correspondence equilibrium logic.one extreme ground, disjunctive logic programs; treat withoutstrong negation, answer sets simply collections atoms. programs consistsets ground rules formK1 . . . Kk L1 , . . . Lm , notLm+1 , . . . , notLn(7)Li Kj atoms. translation syntax programs HTpropositional formulas trivial one, viz. (7) corresponds HT sentenceL1 . . . Lm Lm+1 . . . Ln K1 . . . Kk(8)translation correspondence answer sets equilibriummodels ground disjunctive programs also direct one:Proposition 13 Let disjunctive logic program. hT, equilibrium modelanswer set .first shown Pearce (1997) basic equivalence later shown holdgeneral classes programs Pearce, P. de Guzman Valverde (2000).also common treat non-ground rules form (7) variables may appear.variables thought universally quantified, corresponding translation logical formula would simply universal closure formula (8).extreme, Ferraris, Lee Lifschitz (2007) provided new definitionstable model arbitrary first-order formulas. case property stablemodel defined syntactically via second-order condition resembles parallel circumscription. However also showed new notion stable model equivalentequilibrium model defined first-order languages. sequel paper,Lee, Lifschitz Palla (2008a) applied new definition made following refinements. stable models formula defined Ferraris et al. (2007) were,answer sets formula Herbrand models formula stablesense Ferraris et al. Using new terminology, follows general stablemodels equilibrium models coincide, answer sets equivalent SNA-QHTmodels equilibrium models.two extremes many syntactically different kinds programsconsidered several variations concept answer set proposed.However main varieties display similar correspondence equilibrium logic.merely necessary cases restrict attention specific kinds equilibrium models, e.g. Herbrand models, UNA-models SNA-models. important notice alsocorrespondence extends many additional constructs introduced934fiInterpolable Formulas Equilibrium Logic Answer Set ProgrammingASP, cardinality weight constraints even general forms aggregates (Lee& Meng, 2009). accommodated equilibrium logic translationlogical formulas.ASP main emphasis finding answer sets answerset solvers compute. Less attention placed implementing non-monotonic inferencerelation query answering mechanism. However standard, skeptical conceptinference entailment associated answer set semantics. notion entailmentconsequence programs answer set semantics query Q entailedprogram Q true answer sets (Balduccini, Gelfond, & Nogueira, 2000).Let us denote entailment consequence relation |AS . Evidently atoms trueanswer set belong it. Conjunctions disjunctions handledobvious way (Lifschitz, Tang, & Turner, 1999; Balduccini et al., 2000). Sometimes,queries form a, logical notation a, explicitly dealt (Balducciniet al., 2000). However seems keeping semantics regard formulaform true answer set true. Another wayexpress would say answer set satisfies violateconstraint { }, understanding constraint violation Lifschitz, Tang Turner (1999).9way would say |AS answer set contains A. Similarly,interpretation queries containing quantifiers answer set semantics also conformequilibrium logic, taking account specific restrictions, Herbrandmodels, might imposed.therefore transfer interpolation properties equilibrium logic answer setsemantics ASP. remains consider whether |AS best identified closedworld version inference, |cw , open world version, |ow . Again, since ASPsolvers generally implement inference engines, difference largely theoretical one. traditional logic programming, however, query belonglanguage program usually answered false. also seems quite natural ASPcontext that, given program query Q, one consider stable modelslanguage L() L(Q) even proper extension language .10general |cw seems natural choice answer set inference. hand,contexts answer set semantics used open world setting, examplesetting hybrid knowledge bases (Rosati, 2005) non-monotonic rules combinedontologies formalised description logics. systems semantics termsequilibrium logic provided de Bruijn, Pearce, Polleres Valverde (2007).entailment relation style |ow might sometimes appropriate.general answer set semantics defined coherent programs theories.these, identifying |AS |cw , apply Proposition 9 directly:Corollary 2 coherent formulas , (|, |)-interpolation form Proposition 9holds entailment |AS answer set semantics.9. logical terms constraint would written .10. Notice Proposition 12 program consists safe formulas, atomic query q(a) automaticallyfalse belong language program (even q does), simply groundingprogram constants sufficient generate answer sets.935fiGabbay, Pearce, & Valverde7. Application InterpolationInterpolation property applied various areas computer science, notablysoftware specification (Bicarregui et al., 2001) construction formal ontologies (Lutz & Wolter, 2010). areas relevant modularity issues.discuss simple application related concept described Lutz Wolteradapt case nonmonotonic logic programs.One way compare two theories via nonmonotonic consequence relations.two theories produce answers given query language, call inseparable; term used mathematical logic also study formal ontologies (Lutz& Wolter, 2010).Let us say therefore 1 2 L-inseparable V () L,1 | 2 | .Proposition 14 Let 1 2 L-inseparable theories V (1 ) = V (2 ) = V ,say. L L V L L, 1 2 L -inseparable.Proof. Assume 1 2 L-inseparable L extension LV L L. Suppose 1 | , V () = L . Suppose L \ V = {B1 , . . . Bn }.Proposition 7 interpolant (1 , ) |= B1 . . .Bn . Since1 | V () L, L-inseparability 2 | . right absorption therefore2 | B1 . . . Bn . However clear B1 , . . . Bn false equilibriummodels 2 , 2 | . Repeating argument 1 2 interchanged showstheories L -inseparable.proof similar argument given Lutz Wolter (2010) Theorem 7 paper, applied TBoxes description logics. property describedcalled robustness signature extensions. Notice however that, since |general transitive cannot immediately infer 2 | | also 2 | .highlights added strength using explicitly set {B1 , . . . Bn } propertyHT forms deductive basis |.study modularity logical relations programs ASP,common compare sets answer sets rather consequence classes. Howeverturns notion inseparability close concept alreadystudied ASP. Two theories programs said projectively equivalentprojections answer sets onto common sublanguage agree (Eiter, Tompits,& Woltran, 2005). Formally, let 1 , 2 theories L signature LV (1 ) V (2 ). 1 2 said projectively equivalent relative LE(1 )L = E(2 )L , class models K, KL = {ML : K}.Proposition 15 Let 1 , 2 theories L signature L V (1 ) V (2 ).1 2 projectively equivalent relative L L-inseparable.words two concepts agree whenever L common sublanguage 1 , 2 .main advantage L-inseparability seems natural one usewant consider signatures extend language either program theory.936fiInterpolable Formulas Equilibrium Logic Answer Set Programming8. Uniform Interpolation Forgettingstronger form interpolation known uniform interpolation also important certainapplications computer science (Konev et al., 2009). usual, given , ,interested interpolants&(9)contains predicate constant symbols belong .difference said uniform interpolant (9) holdssignature . logic said uniform interpolation propertyuniform interpolants exist , .classical propositional logic, uniform interpolation holds, however fails firstorder classical logic many non-classical logics. may hold certain restrictionsplaced theory language formulated query languagecontaining . example shown hold description logics (Kontchakovet al., 2008) syntactic restrictions apply. Even ASP turns formuniform interpolation holds restricted query language, essentially one allowsinstance retrieval. show using known results ASPconcept forgetting (Eiter & Wang, 2008) quite closely related interpolation.Variable forgetting, studied Eiter Wang (2008), concerned followingproblem. Given disjunctive logic program certain atom occurring , constructnew program, denoted forget(, a), contain whose answersets respects close possible . precise notioncloseness reader referred paper Eiter Wang, however consequencesevident shortly. Eiter Wang define forget(, a) (as generic term), showprograms exist whenever coherent, provide different algorithms computeprograms.Given coherent , results forget(, a), forgetting maydifferent always answer set equivalent. Moreover purposes satisfyfollowing key property, coherent, a, b distinct atoms usual |denotes nonmonotonic consequence,| bforget(, a) | b.(10)showing indeed answer sets forget(, a) closely related.establish version uniform interpolation case disjunctive programssimple, atomic queries, need show always find = forget(, a)| . examine first algorithm Eiter Wang computingforget(, a); also simplest three algorithms presented. Let coherentprogram rules form (7) write formulas form (8) let atom. method constructing = forget(, a) follows.1. Compute equilibrium models E().2. Let E result removing E().3. Remove E model non-minimal form E (= {A1 , . . . , }, say).937fiGabbay, Pearce, & Valverde4. Construct program whose answer sets precisely {A1 , . . . , } follows:Ai , set = {Ai : Ai }, Ai = V () \ Ai .Set = 1 . . . .verify desired property. Let L simple query language composedconjunctions literals.Proposition 16 equilibrium logic (or answer set programming) uniform interpolationholds (coherent) disjunctive programs queries L(V ()).Proof. prove claim shall show following. Let coherent disjunctiveprogram let L = L(V ) V V (). programV ( ) = V L,| ( | & | )begin, let | . Let X = {a1 , . . . , } = V () \ V .choose result forgetting X , defined Eiter Wang (2008)follows:forget(, X) := forget(forget(forget(, a1 ), a2 ), . . . , ),shown order atoms X matter. know(10) atom V = 1, n,| forget(, ai ) | a,(11)| forget(, X) | a.(12)thereforeLet forget(, X) determined algorithm 1 Eiter Wang (2008) describedabove. easy see (11) semantics | (12) continues holdreplaced negated atom b therefore also conjunction literals sinceconjunction entailed element holds every equilibrium model.11 remainsshow | . Again, suffice show entailment one membersequence forget(, ai ) since order irrelevant wlog choose first elementforget(, a1 ) show | forget(, a1 ). compute programs 1 , . . . ,algorithm. need check | = 1, n, i.e.E(), |= {Ai : Ai }.Consider E() = hT, i. distinguish two cases. (i) Ai .|= Ai . follows |= Ai Ai|= {Ai : Ai }. Case (ii) Ai 6 . Ai incomparable.particular cannot Ai minimality property Ai obtained step 3.Hence Ai 6= . Choose Ai . |= , 6|= hence 6|= Ai .Consequently, , |= Ai |= {Ai : Ai }. followsi, | construction | , establishes proposition.11. Eiter Wang (2008) point out, atom b true answer set forget(, a),must also true answer set , showing (12) holds literals.938fiInterpolable Formulas Equilibrium Logic Answer Set Programming8.1 Extending Query Languageestablish uniform interpolation ASP using method forgetting, definedEiter Wang (2008), seems clear cannot extend non-trivial wayexpressive power query language L. Since method forgetting removesnon-minimal sets E() (once removed), atom b might trueequilibrium model equilibrium model forget(, a). Hence mightdisjunction, say b, derivable forget(, a). Likewise,consider programs variables first-order setting, cannot general extend Linclude existential queries.hand, property uniform interpolation certainly holds L(V )even without condition V V (). Suppose | V () \ V () 6= ,say V () \ V () = {b1 , . . . , bk }. b1 , . . . , bk false equilibrium models .Trivially, b V () regard result forgetting b .repeat proof Proposition 16, setting X = {V () \ V } {V \ V ()}.relevant properties continue hold.interesting open question whether extend theory language includegeneral kinds program rules allowing negation head. Accommodating kinds formulas would constitute important generalisation sinceamount normal form equilibrium logic. However, answer sets programssatisfy minimality property holds answer sets disjunctive programs,clear definition forgetting would need appropriately modified -task attempt here.9. Literature Related Workinterpolation theorem classical logic due Craig (1957); extended intutionistic logic Schutte (1962). Maksimova (1977) characterised super-intuitionisticpropositional logics possessing interpolation. modern, comprehensive treatment interpolation modal intuitionistic logics found monograph GabbayMaksimova (2005).non-monotonic logics, interpolation received little attention. notable exceptionarticle (Amir, 2002) establishing interpolation properties circumscriptiondefault logic. well-known relation answer sets disjunctive programsextensions corresponding default theories, also derives form interpolationASP. regard answer set semantics, approach Amir quite differentours. Since founded analysis default logic, uses classical logic underlyingbase. Amirs version interpolation form (3) L classical logic;requirement L form well-behaved sublogic |, e.g. deductive base. Amirremarks, one cannot deduce general property (4) | . However L classicallogic one cannot even deduce | (3). generally, counterpartProposition 1 case. Another difference respect approachAmir discuss nature | relation ASP detail, particularunderstand | case contains atoms present program . fact,interpret |AS Section 6 above, easy refute (|, L )-interpolation Lclassical logic. Let program B q query B C. clearly939fiGabbay, Pearce, & Valverde|AS q, formula vocabulary B would classically entail C.interpretation answer set inference atoms programregarded false, (|, L )-interpolation would refuted.10. Conclusionsdiscussed two kinds interpolation properties non-monotonic inference relations shown properties hold turn two different inference relationsassociate propositional equilibrium logic. case use factcollection equilibrium models definable logic HT here-and-therelogic possesses usual form interpolation. One forms inference studiedseems many cases appropriate concept associate answer set programming, although general ASP systems tailored query answering deduction.Using results Eiter Wang (2008) variable forgetting ASP, could also showproperty uniform interpolation holds disjunctive programs restrictedquery language.also discussed interpolation property first-order equilibrium logic basedquantified version QHT logic here-and-there, obtaining analogous resultspropositional case whenever collection equilibrium models definable.positive results transfer answer set programming assumption usually madeASP systems programs safe therefore definable collections answer sets.saw, notion safety quite generally defined theories limitednormal disjunctive programs.AcknowledgmentsDavid Pearce partially supported MEC projects TIN2009-14562-C05-02 CSD200700022. Agustn Valverde partially supported MEC project TIN2009-14562-C05-01,Junta de Andalucia projects P09-FQM-05233 TIC-115. authors gratefulanonymous referees helpful comments.ReferencesAmir, E. (2002). Interpolation theorems nonmonotonic reasoning systems.. Proceedings NMR02, pp. 4150.Balduccini, M., Gelfond, M., & Nogueira, M. (2000). A-prolog tool declarativeprogramming. Proc. SEKE 2000).Baral, C. (2003). Knowledge Representation, Reasoning Declarative Problem Solving.Cambridge University Press.Bicarregui, J., Dimitrakos, T., Gabbay, D. M., & Maibaum, T. S. E. (2001). Interpolationpractical formal development. Logic Journal IGPL, 9 (2).Bria, A., Faber, W., & Leone, N. (2008). Normal form nested programs. Holldobler, S.,Lutz, C., & Wansing, H. (Eds.), Proc. JELIA08, Vol. 5293 LNCS, pp. 7688.Springer.940fiInterpolable Formulas Equilibrium Logic Answer Set ProgrammingCabalar, P., Pearce, D., & Valverde, A. (2009). revised concept safety general answerset programs. Erdem, E., Lin, F., & Schaub, T. (Eds.), Proc. LPNMR09, Vol.5753 LNCS, pp. 5870. Springer.Craig, W. (1957). Linear reasoning. new form herbrand-gentzen theorem.. J. Symb.Logic, 22, 250268.de Bruijn, J., Pearce, D., Polleres, A., & Valverde, A. (2007). Quantified equilibrium logichybrid rules. Marchiori, M., Pan, J. Z., & de Sainte Marie, C. (Eds.), Proc.RR07, Vol. 4524 LNCS, pp. 5872. Springer.Diaconescu, R., Goguen, J., & Stefaneas, P. (1993). Logical support modularisation.Logical Environments, pp. 83130. Cambridge University Press.Dietrich, J. (1994). Deductive bases nonmonononic inference operations. Ntz report,University Leipzig.Eiter, T., Tompits, H., & Woltran, S. (2005). solution correspondences answer-setprogramming.. Kaelbling, L. P., & Saffiotti, A. (Eds.), Proc. IJCAI05, pp.97102. Professional Book Center.Eiter, T., & Wang, K. (2008). Semantic forgetting answer set programming. ArtificialIntelligence, 172 (14), 16441672.Ferraris, P. (2008). Logic programs propositional connectives aggregates. CoRR,abs/0812.1462.Ferraris, P., Lee, J., & Lifschitz, V. (2007). new perspective stable models. Veloso,M. M. (Ed.), Proc. IJCAI07, pp. 372379.Gabbay, D. M., & Maksimova, L. (2005). Interpolation Definability: Modal Intuitionistic Logic. Oxford University Press, USA.Gelder, A. V., Ross, K. A., & Schlipf, J. S. (1991). well-founded semantics generallogic programs. Journal ACM, 38 (3), 620650.Gelfond, M., & Lifschitz, V. (1988). stable model semantics logic programming.Kowalski, R. A., & Bowen, K. (Eds.), Proc. ICLP88, pp. 10701080. MITPress.Gelfond, M., & Lifschitz, V. (1990). Logic programs classical negation. Warren,David H.D.; Szerdei, P. (Ed.), Proc. ICLP90, pp. 579597. MIT Press.Gelfond, M., & Lifschitz, V. (1991). Classical negation logic programs disjunctivedatabases. New Generation Computing, 9, 365385.Konev, B., Walther, D., & Wolter, F. (2009). Forgetting uniform interpolation largescale description logic terminologies. Boutilier, C. (Ed.), Proc. IJCAI09, pp.830835.Kontchakov, R., Wolter, F., & Zakharyaschev, M. (2008). tell differencedl-lite ontologies?. Brewka, G., & Lang, J. (Eds.), Principles KnowledgeRepresentation Reasoning: Proc. KR08, pp. 285295. AAAI Press.Kunen, K. (1987). Negation logic programming. Journal Logic Programming, 4 (4),289308.941fiGabbay, Pearce, & ValverdeLee, J., Lifschitz, V., & Palla, R. (2008a). reductive semantics counting choiceanswer set programming. Fox, D., & Gomes, C. P. (Eds.), Proc. AAAI08, pp.472479. AAAI Press.Lee, J., Lifschitz, V., & Palla, R. (2008b). Safe formulas general theory stablemodels (preliminary report). de la Banda, M. G., & Pontelli, E. (Eds.), Proc.ICLP08, Vol. 5366 LNCS, pp. 672676. Springer.Lee, J., & Meng, Y. (2009). reductive semantics aggregates answer set programming. Erdem, E., Lin, F., & Schaub, T. (Eds.), Proc. LPNMR09, Vol. 5753LNCS, pp. 182195. Springer.Lifschitz, V., Pearce, D., & Valverde, A. (2001). Strongly equivalent logic programs. ACMTransactions Computational Logic, 2 (4), 526541.Lifschitz, V., Pearce, D., & Valverde, A. (2007). characterization strong equivalencelogic programs variables. Baral, C., Brewka, G., & Schlipf, J. S. (Eds.),Proc. LPNMR07, Vol. 4483 LNCS, pp. 188200. Springer.Lifschitz, V., Tang, L. R., & Turner, H. (1999). Nested expressions logic programs. AnnalsMathematics Artificial Intelligence, 25 (34), 369389.Lutz, C., & Wolter, F. (2010). Deciding inseparability conservative extensionsdescription logic el. Journal Symbolic Computation, 45 (2), 194228.Maher, M. J. (1988). Equivalences logic programs. Foundations Deductive DatabasesLogic Programming., pp. 627658. Morgan Kaufmann.Makinson, D. (1994). General patterns nonmonotonic reasoning, pp. 35110. OxfordUniversity Press, Inc.Maksimova, L. (1997). Interpolation superintuitionistic predicate logics equality.Algebra Logic, 36, 543561.Maksimova, L. (1998). Interpolation superintuitionistic modal predicate logicsequality. M.Kracht, de Rijke, M., Wansing, H., & Zakharyaschev, M. (Eds.), Advances Modal Logic, Vol. I, pp. 133141. CSLI Publications.Maksimova, L. (1977). Craigs interpolation theorem amalgamable varieties. DokladyAkademii Nauk SSSR, 237 (6), 12811284.McMillan, K. L. (2005). Applications craig interpolants model checking. Halbwachs,N., & Zuck, L. D. (Eds.), Proc. TACAS05, Vol. 3440 LNCS, pp. 112. Springer.Ono, H. (1983). Model extension theorem craigs interpolation theorem intermediatepredicate logics. Reports Mathematical Logic, 15, 4158.Pearce, D. (1997). new logical characterization stable models answer sets. Dix,J., Pereira, L. M., & Przymusinski, T. C. (Eds.), Proc. NMELP96, Vol. 1216LNCS, pp. 5770. Springer.Pearce, D. (2006). Equilibrium logic. Annals Mathematics Artificial Intelligence,47 (1-2), 341.Pearce, D., de Guzman, I. P., & Valverde, A. (2000). Computing equilibrium models usingsigned formulas. Proc. CL2000, Vol. 1861 LNCS, pp. 688703. Springer.942fiInterpolable Formulas Equilibrium Logic Answer Set ProgrammingPearce, D., & Valverde, A. (2005). first order nonmonotonic extension constructivelogic. Studia Logica, 80 (2-3), 321346.Pearce, D., & Valverde, A. (2006). Quantified equilibrium logic. Technical report, Universidad Rey Juan Carlos. (http://www.matap.uma.es/investigacion/tr/ma06_02.pdf).Pearce, D., & Valverde, A. (2008). Quantified equilibrium logic foundations answerset programs. de la Banda, M. G., & Pontelli, E. (Eds.), Proc. ICLP08, Vol.5366 LNCS, pp. 546560. Springer.Pearce, D., & Valverde, A. (2012). Synonymous theories knowledge representationsanswer set programming. Journal Computer System Sciences, 78, 86104.Rosati, R. (2005). Semantic computational advantages safe integration ontologies rules. Fages, F., & Soliman, S. (Eds.), Proc. PPSWR05, Vol. 3703LNCS, pp. 5064. Springer.Schutte, K. (1962). Der interpolationsatz der intuitionistischen pradikatenlogik.. Math.Ann., 148, 192200.van Dalen, D. (1997). Logic Structure (3th edition). Springer.943fiJournal Artificial Intelligence Research 42 (2011) 181-209Submitted 5/11; published 10/11Topological Value Iteration AlgorithmsPeng DaiDAIPENG @ CS . WASHINGTON . EDUGoogle Inc.1600 Amphitheatre PkwyMountain View, CA 94043USAMausamDaniel S. WeldMAUSAM @ CS . WASHINGTON . EDUWELD @ CS . WASHINGTON . EDUDepartment Computer Science EngineeringUniversity WashingtonSeattle, WA 98195USAJudy GoldsmithGOLDSMIT @ CS . UKY. EDUDepartment Computer ScienceUniversity KentuckyLexington, KY 40508USAAbstractValue iteration powerful yet inefficient algorithm Markov decision processes (MDPs)puts majority effort backing entire state space, turnsunnecessary many cases. order overcome problem, many approachesproposed. Among them, ILAO* variants RTDP state-of-the-art ones. methodsuse reachability analysis heuristic search avoid unnecessary backups. However, noneapproaches build graphical structure state transitions pre-processing stepuse structural information systematically decompose problem, whereby generatingintelligent backup sequence state space. paper, present two optimal MDP algorithms. first algorithm, topological value iteration (TVI), detects structure MDPsbacks states based topological sequences. (1) divides MDP strongly-connectedcomponents (SCCs), (2) solves components sequentially. TVI outperforms VIstate-of-the-art algorithms vastly MDP multiple, close-to-equal-sized SCCs. second algorithm, focused topological value iteration (FTVI), extension TVI. FTVI restrictsattention connected components relevant solving MDP. Specifically, usessmall amount heuristic search eliminate provably sub-optimal actions; pruning allowsFTVI find smaller connected components, thus running faster. demonstrate FTVI outperforms TVI order magnitude, averaged across several domains. Surprisingly, FTVIalso significantly outperforms popular heuristically-informed MDP algorithms ILAO*,LRTDP, BRTDP Bayesian-RTDP many domains, sometimes much two ordersmagnitude. Finally, characterize type domains FTVI excels suggesting wayinformed choice solver.1. IntroductionMarkov Decision Processes (MDPs) (Bellman, 1957) powerful widely-adopted formulation modeling autonomous decision making uncertainty. instance, NASA researchersc2011AI Access Foundation. rights reserved.fiDAI , AUSAM , W ELD , & G OLDSMITHuse MDPs model next-generation Mars rover planning problems (Bresina, Dearden, Meuleau,Ramkrishnan, Smith, & Washington, 2002; Feng & Zilberstein, 2004; Mausam, Benazera, Brafman,Meuleau, & Hansen, 2005; Meuleau, Benazera, Brafman, Hansen, & Mausam, 2009). MDPsalso used formulate military operations planning (Aberdeen, Thiebaux, & Zhang, 2004)coordinated multi-agent planning (Musliner, Carciofini, Goldman, E. H. Durfee, & Boddy, 2007),etc.Classical dynamic programming algorithms, value iteration (VI), solve MDP optimally iteratively updating value every state fixed order, one state per iteration.inefficient, since overlooks graphical structure problem, providevast information state dependencies.past decade researchers developed heuristic search algorithms use reachability information heuristic functions avoid unnecessary backups. approaches,improved LAO* (ILAO*) (Hansen & Zilberstein, 2001), LRTDP (Bonet & Geffner, 2003b),HDP (Bonet & Geffner, 2003a), BRTDP (McMahan, Likhachev, & Gordon, 2005) BayesianRTDP (Sanner, Goetschalckx, Driessens, & Shani, 2009), frequently outperform value iteration.problems, however, heuristic search algorithms offer little benefit difficult predict excel. raises important, open question, attributes problemsproblem domains make best suited heuristic search algorithms?paper present two algorithms solve MDPs optimally speed convergence value iteration: topological value iteration (TVI) (Dai & Goldsmith, 2007) focusedtopological value iteration (FTVI) (Dai, Mausam, & Weld, 2009b). TVI makes use graphicalstructure MDP. performs Bellman backups intelligent order performingadditional topological analysis MDP state space. TVI first divides MDP strongly connected components (SCCs) solves component sequentially topological order. Experimental results demonstrate significant performance gains VI and, surprisingly, heuristic search algorithms (despite TVI using reachability information itself) specific kinddomain one multiple, close-to-equal-sized SCCs.TVI general, independent assumptions start state findoptimal value function entire state space. However, many benchmark problems cannotbroken roughly equal-sized SCCs, leaving TVIs performance better (or often worse, dueoverhead generating SCCs) MDP algorithms. instance, many domains (e.g.,Blocksworld) reversible actions. Problems domains statesconnected reversible actions end one (large) SCC, thus, eliminating benefitTVI.FTVI addresses weaknesses TVI. first performs phase heuristic search eliminates provably sub-optimal actions found search. builds informativegraphical structure based remaining actions. find short phase heuristicsearch often able eliminate many actions leading MDP structure amenableefficient, topology-based solutions.evaluate FTVI across several benchmark domains find FTVI outperforms TVIsignificant margins. Surprisingly, also find FTVI outperforms state-of-the-art heuristicsearch algorithms domains. unexpected, since common wisdom dictatesheuristic-guided search much faster all-state dynamic programming. better understandbig improvement, study convergence speed algorithms problem features.discover two important features problems hard heuristic search algorithms: smaller182fiT OPOLOGICAL VALUE TERATION LGORITHMSnumber goal states long search distance goal. features commonly foundmany domains, e.g., Mountain car (Wingate & Seppi, 2005) Drive (Bonet, 2006). show that,domains, FTVI outperforms heuristic search convergence speed order magnitudeaverage, sometimes even two orders magnitude.Comparing previous conference versions (Dai & Goldsmith, 2007; Dai et al., 2009b),paper makes several significant improvements: (1) add convergence test modulesearch phase FTVI. module, FTVI works good best heuristic search algorithmsdomains used significantly outperformed. (2) perform extensive empirical studyTVI (Figures 2 3 new) FTVI (Figure 5 new, added Blocksworlddomain). (3) describe TVI FTVI consistent way improve pesudo-codes. (4)add convergence proof TVI (Theorem 2).outline rest paper follows: Section 2 formally defines MDPs, reviewsalgorithms solve MDPs. Section 3 describes topological value iteration algorithm,compares empirically algorithms special MDP domain. Section 4 introducesfocused topological value iteration algorithm provides thorough empirical evaluation.present related work Section 5 conclude Section 6.2. Backgroundprovide overview Markov decision process (MDP) dynamic programming algorithmssolve MDP.2.1 Markov Decision Processes PlanningAI researchers typically use MDPs formulate fully-observable probabilistic planning problems.MDP defined five-tuple hS, A, Ap, T, Ci,finite set discrete states.finite set applicable actions.Ap : P(A) applicability function. Ap(s) denotes set actionsapplied state s. P(A) power set set actions.: [0, 1] transition function describing effect action execution.C : R+ cost executing action state.agent executes actions discrete time steps. step, system one distinctstate S. agent execute action set applicable actions Ap(s) A, incurring cost C(s, a). action takes system new state s0 stochastically, probabilityTa (s0 |s).horizon MDP number steps costs accumulated. concentratespecial set MDPs called stochastic shortest path (SSP) problems. Despite simplicity, SSPgeneral MDP representation. infinite-horizon, discounted-reward MDP easily converted SSP problem (Bertsekas & Tsitsiklis, 1996). horizon MDP indefinite,i.e., finite unbounded, costs accumulated discounting. twocomponents SSP:183fiDAI , AUSAM , W ELD , & G OLDSMITHs0 initial state.G set sink goal states. Reaching one g G terminates execution.cost execution sum costs along path s0 first goal stateencountered.assume full observability, i.e., executing action transitioning stochasticallynext state governed , agent full knowledge state. policy, : A,MDP mapping state space action space, indicating action executestate. solve MDP need find optimal policy ( : A), probabilisticexecution plan reaches goal state minimum expected cost. evaluate policyvalue function, set values satisfy following equation:V (s) = C(s, (s)) +XT(s) (s0 |s)V (s0 ).(1)s0optimal policy must satisfy following system Bellman equations:V (s) = 0 G, else"V (s) =min#XC(s, a) +aAp(s)Ta (s0 |s)V (s0 ) .(2)s0corresponding optimal policy extracted value function:"#X(s) = argminaAp(s) C(s, a) +Ta (s0 |s)V (s0 ) , G.(3)s0Given implicit optimal policy form optimal value function V (), Q-valuestate-action pair (s, a) defined value state s, immediate action performed,followed afterwards. concretely,XQ (s, a) = C(s, a) +Ta (s0 |s)V (s0 ).(4)s0Therefore, optimal value function expressed by:V (s) = minaAp(s) Q (s, a).2.2 Dynamic Programmingoptimal MDP algorithms based dynamic programming, whose utility first provedsimple yet powerful algorithm named value iteration (Bellman, 1957). Value iteration firstinitializes value function arbitrarily, example zero. Then, values updated iterativelyusing operator called Bellman backup (Line 7 Algorithm 1) create successively betterapproximations state per iteration. define Bellman residual stateabsolute difference state value Bellman backup. Value iteration stopsvalue function converges. implementation, typically signaled Bellman error,184fiT OPOLOGICAL VALUE TERATION LGORITHMSAlgorithm 1 (Gauss-Seidel) Value Iteration1: Input: MDP = hS, A, Ap, T, Ci, : threshold value2: initialize V arbitrarily3: true4:Bellman error 05:state6:oldV V (s)P7:V (s) minaAp(s) C(s, a) + s0 Ta (s0 |s)V (s0 )8:Bellman residual(s) |V (s) oldV |9:Bellman error max(Bellman error, Bellman residual(s))10:Bellman error <11:return Vlargest Bellman residual states, becomes less pre-defined threshold, . callBellman backup contraction operation (Bertsekas, 2001), every state, Bellman residualnever increase iteration number.Value iteration converges optimal value function time polynomial |S| (Littman, Dean,& Kaelbling, 1995; Bonet, 2007), yet practice usually inefficient, since blindly performsbackups state space iteratively, often introducing many unnecessary backups.2.2.1 H EURISTIC EARCHimprove efficiency dynamic programming, researchers explored various ideastraditional heuristic-guided search, consistently demonstrated usefulness MDPs(Barto, Bradtke, & Singh, 1995; Hansen & Zilberstein, 2001; Bonet & Geffner, 2003b, 2006;McMahan et al., 2005; Smith & Simmons, 2006; Sanner et al., 2009). basic idea heuristic search consider action necessary, leads conservative backupstrategy. strategy helps save lot unnecessary backups.define heuristic function h : R+ , h(s) estimate V (s). heuristicfunction h admissible never over-estimates value state,h(s) V (s), S.(5)also interchangeably write admissible heuristic function Vl , emphasize Vl (s)lower bound V (s).Definition greedy policy best policy one-step lookahead given current valuefunction, V :"#X(s) = argminaAp(s) C(s, a) +Ta (s0 |s)V (s0 ) , G.(6)s0policy graph, G = (V, E), MDP set states policy directed,connected graph vertices V S, s0 V, S, V iff reachables0 policy . Furthermore, s, s0 V, hs, s0 E (the edges policy graph) iffT(s) (s0 |s) > 0.185fiDAI , AUSAM , W ELD , & G OLDSMITHHeuristic search algorithms two main features: (1) search limited statesreachable initial state. Given heuristic value, heuristic search algorithm generatesrunning greedy policy, well policy graph. algorithm performs series heuristicsearches, states greedy policy graph converge. search typically startsinitial state, successor states explored best-first manner. Visited states valuesbacked search. (2) Since heuristic search algorithms fewer backups valueiteration, require special care guarantee final optimality. values state spaceinitialized admissible heuristic function. Note value iteration also take advantageinitial heuristic values informative starting point, require heuristicsadmissible guarantee optimality.Different heuristic search algorithms use different search strategies therefore perform Bellman backups different orders.AO* algorithm (Nilson, 1980) solves acyclic MDPs, applicable general MDPs.LAO* (Hansen & Zilberstein, 2001) extension AO* algorithm handle MDPsloops. Improved LAO* (ILAO*) (Hansen & Zilberstein, 2001) efficient variant LAO*.iteratively performs complete searches discover running greedy policy graph. detail,greedy policy graph contains initial state s0 search starts. New states addedgraph means expansions frontier state depth-first manner,states added. state expansion, one greedy actions chosen, actionssuccessor states added graph. States expanded yet contain successorscalled frontier states. Later, states greedy policy graph backed postorder visited. search iteration performs |S| backups, practicenumber typically much smaller. ILAO* terminates states current greedy policygraph Bellman residual less given .Real-time dynamic programming (RTDP) (Barto et al., 1995) another popular algorithmMDPs. interleaves dynamic programming search plan execution trials. executiontrial path originates s0 ends goal state bounded-step cutoff.execution step simulates result one-step plan execution. agent greedily picks actioncurrent state s, mimics state transition new current state s0 , chosen stochasticallybased transition probabilities action, i.e., s0 Ta (s0 |s). Dynamic programminghappens states backed immediately visited. RTDP good findinggood sub-optimal policy relatively quickly. However, order RTDP converge, statesoptimal policy backed sufficiently, convergence usually slow. overcomeslow convergence problem RTDP, researchers later proposed several heuristic search variantsalgorithm.Bonet Geffner (2003b) introduced smart labeling technique RTDP extension namedlabeled RTDP (LRTDP). label state solved every state reachable applyinggreedy policy either goal state, solved, Bellman residual greaterthreshold . States labeled solved longer get backed future search. Labelinghelps speed convergence avoids many unnecessary backups states alreadyconverged. execution trial, LRTDP tries label every unsolved state reverse ordervisit. label state s, LRTDP initiates DFS s0 checks states reachablegreedy policy rooted solved, back up, otherwise. LRTDP terminatesstates current policy graph solved. Bonet Geffner also applied labeling techniqueanother algorithm called HDP (Bonet & Geffner, 2003a). HDP uses Tarjans algorithm find186fiT OPOLOGICAL VALUE TERATION LGORITHMSstrongly connected component MDP help label solved states implicitly controlorder states backed search trial.McMahan et al. (2005) proposed another extension named bounded RTDP (BRTDP),uses lower bound heuristic value function Vl , also upper bound Vu . BRTDPtwo key differences original RTDP algorithm. First, BRTDP backs states, updates lower bound upper bound. Second, choosing next state s0 ,difference two bounds, Vu (s0 ) Vl (s0 ), also taken consideration. concretely,s0 Ta (s0 |s)[Vu (s0 ) Vl (s0 )], focuses search states less likely converged.One feature BRTDP adaptive trial termination criterion, helpful practice.Smith Simmons (2006) introduced similar algorithm named focused RTDP (FRTDP).define occupancy intuitive measure expected number times state visitedexecution termination. Therefore occupancy state indicates relevance policy. SimilarBRTDP, FRTDP also keeps two bounds state. FRTDP uses product states occupancydifference bounds picking next state. Also, FRTDP assumes discounted costsetting, immediately applicable SSP problems.Recently Sanner et al. (2009) described another advanced RTDP variant named Bayesian RTDP,also uses two value bounds. basic motivation Bayesian RTDP anytime performance sub-optimal policies important, finding optimal policy timeconsuming. especially true sub-optimal policy performs close optimal one,much faster generate. key assumption true value function state s, V (s),uniformly distributed interval [Vl (s), Vu (s)]. Therefore, probability density function1V (s) 1v[Vl (s),Vu (s)] [ Vu (s)V], E[V (s)] = 21 [Vl (s) + Vu (s)]. evaluate importantl (s)pick state s0 next state, refers notion value perfect information (VPI),intuitively tells expected Q-value difference current state-action pair, Q(s, a),without knowledge V (s0 ). choose s0 , Bayesian RTDP uses metric combinesBRTDP metric VPI value.2.3 Limitation Previous SolversValue iteration backs states iteratively based fixed order. Heuristic search backsstates dynamic, informed order, implied visited search. statebacked pre-order (when first visited, e.g., variants RTDP), post-order (whensearches back track, e.g., ILAO*). None algorithms use MDPs graphical structure,intrinsic property governs complexity solving problem (Littman et al., 1995), waydecide order states solved.Consider PhD program Finance department. Figure 1 shows MDP describesprogress PhD student. simplicity reasons, omit action nodes, transitionprobabilities, cost functions. goal state set singleton G = {g}, indicatesstudent gets PhD degree. directed edge two states means head state onesuccessor state tail state least one action. initial state, s0 , describes statusentry-level student. first pass qualifying exam, consists findingsupervisor passing exam. passing exam one choose work differentsupervisor (back state s0 figure). State s1 indicates student found supervisor.works proposal, consists written document oral exam.187fiDAI , AUSAM , W ELD , & G OLDSMITHs0s1s3s2s4gs4Figure 1: simple MDP example. action nodes, transition probabilities, cost functionsomitted. goal state set singleton G = {g}. directed edge two states meanshead state one successor state tail state action.pass two consecutive quarters; otherwise back state s2 . passing proposal,state s4 , needs defend thesis, passing reaches goal state g.Observing MDP, find optimal order back states s4 , s2 s3 , tillconverge, followed s0 s1 . reason value s4 dependvalues non-goal states. Similarly, values s2 s3 depend valueseither s0 s1 . Value iteration well heuristic search algorithms take advantagegraphical structure apply backup order, contain intelligent subroutinediscovers graphical structure, use information dynamic programming step.intuition new approaches discover intrinsic complexity solving MDPstudying graphical structure, later contributes intelligent backup order.3. Topological Value Iterationdescribe topological value iteration (TVI) algorithm (Dai & Goldsmith, 2007).First observe value state depends values successors. example,suppose state s2 successor state s1 action (Ta (s2 |s1 ) > 0). Bellman equationsV (s1 ) dependent V (s2 ). case, define state s1 causally depends state s2 . Notecausal dependence relationship transitive. find causally dependent statesimplicitly building reachability graph GR MDP. set vertices GR equals setstates reachable s0 . directed edge vertex s1 s2 means existsleast action Ap(s1 ), Ta (s2 |s1 ) > 0. causal relationship transitive,directed path state s1 sk GR means s1 causally dependent sk , V (s1 ) dependsV (sk ). Also note two vertices causally dependent other, call mutualcausal dependence.Due causal dependence, usually efficient back s2 ahead s1 .observation, following theorem.Theorem 1 Optimal Backup Order (Bertsekas, 2001): MDP acyclic, existsoptimal backup order. applying optimal order, optimal value function foundstate needing one backup.theorem easy prove and, furthermore, optimal backup order topological ordervertices GR . However, general, MDPs contain cycles common one statemutually causally depend another.two states mutually causally dependent, best order back unclear.hand, neither state causally dependent other, order backup matter.Finally, one state causally dependent (and vice versa), better order188fiT OPOLOGICAL VALUE TERATION LGORITHMSbackups state causally dependent updated later. apply ideagroup together states mutually causally dependent make meta-state. makenew directed graph GM directed edge two meta-states X existsexists two states s1 s2 action Ap(s1 ) s1 X , s2Ta (s2 |s1 ) > 0. clear GM acyclic, otherwise states cycle mutuallycausally dependent, construction rule belong meta-state.case, back states GM topological order. Theorem 1, staterequires one meta-backup. called meta-backup since meta-state may contain multiplestates. perform meta-backup, apply dynamic programming algorithm, valueiteration, states belonging corresponding meta-state.pseudo-code TVI shown Algorithm 2. first apply Kosarajus algorithm (Cormen,Leiserson, Rivest, & Stein, 2001) find set strongly connected components (SCCs, metastates) causality graph GR , topological order. (id[s] indicates topological orderSCC state belongs to.) based fact reversing edges GR ,resulting graph, G0R , strongly connected components original. usingthat, get SCCs forward traversal find ordering vertices, followedtraversal reverse graph order generated first traversal. Kosarajus algorithmefficient, time complexity linear number states. state space large,running algorithm leads unavoidable yet acceptable overhead. many cases overheadwell compensated computational gain. use value iteration solve SCC C (asmeta-backup) topological order.Algorithm 2 Topological Value Iteration1: Input: MDP = hS, A, Ap, T, Ci, : threshold value2: SCC(M )3: 1 cpntnum4:0 set states id[s] =5:0 hS 0 , A, Ap, T, Ci6:VI(M 0 , )7:Function SCC(M )construct GR10: construct graph G0R reverses head tail vertices every edge GR11: {call Kosarajus algorithm (Cormen et al., 2001). inputs GR G0R outputs cpntnum,total number SCCs, id : [1, cpntnum], id SCC state belongs to,topological order.}12: return (cpntnum, id)8:9:3.1 ConvergenceBellman operator contraction operation (Bertsekas, 2001), have:Theorem 2 Topological Value Iteration guaranteed converge value function Bellman error greater .189fiDAI , AUSAM , W ELD , & G OLDSMITHProof first prove TVI guaranteed terminate finite time. Since MDP containsfinite number states, contains finite number connected components. solvingcomponents, TVI uses value iteration. value iteration guaranteed convergefinite time (given finite ), TVI, essentially finite number value iterations, terminatesfinite time.prove TVI guaranteed converge optimal value function Bellman error. prove induction.First, MDP contains one SCC, TVI coincides VI, optimal algorithm.contraction property Bellman backups, VI converges, Bellman error statespace .Now, consider case MDP contains multiple SCCs. point, TVI workingone component C. know optimal value every state C, V (s), dependsoptimal values states descendants s. also know descendant s0must belong either C, component C 0 topologically later C. meanseither value computed VI batch (s0 C), state s0 already converged(s0 C 0 ). latter case, value convex combination states error . Insidemaximization operation Bellman equation affine combination values totalweight 1, leads overall convex combination error . Therefore,VI finishes solving C, value must converge Bellman residual . Also notevalues states belong component earlier C dependstates component C. result, component C converges, Bellman residual statescomponents remain unchanged thus . Combining results concludeTVI terminates, Bellman residuals states . means Bellmanerror state space .high-level perspective, TVI decomposes MDP sub-problems findsvalue state space batch manner, component component. component converged, states safely treated sink states, values depend valuesstates belonging later components.3.2 Implementationmade two optimizations implementing TVI. first one uninformed reachability analysis. TVI depend initial state information. However, given information,TVI able mark reachable components later ignore unreachable ones dynamicprogramming step. reachable state space found depth-first search starting s0 ,overhead linear |S| |A|. extremely useful small portionstate space reachable (e.g., domains International Planning Competition 2006,see Bonet, 2006).second optimization use heuristic values Vl () starting point. used hmin(Bonet & Geffner, 2003b), admissible heuristic:hmin (s) = 0 G, elsehmin (s) =min C(s, a) + mins0 :Ta (s0 |s)>0 hmin (s0 ) .aAp(s)(7)implement it, first construct new deterministic problem. action successorpair original MDP, add new problem deterministic action cost190fiT OPOLOGICAL VALUE TERATION LGORITHMSsame, deterministic successor. solve new problem single, backward,breadth-first search set goal states. Values deterministic problem hmin .3.3 Experimentsaddress following questions experiments: (1) TVI compare VIheuristic search algorithms MDPs contain multiple SCCs? (2) favorableproblem features TVI?compared TVI several optimal algorithms, including VI (Bellman, 1957), ILAO*(Hansen & Zilberstein, 2001), LRTDP (Bonet & Geffner, 2003b), BRTDP (McMahan et al., 2005),Bayesian RTDP (Sanner et al., 2009) (BaRTDP), HDP (Bonet & Geffner, 2003a)1 . usedfully optimized C code ILAO* provided Eric A. Hansen additionally implementedrest algorithms framework. performed experiments 2.5GHzDual-Core AMD Opteron(tm) Processor 2GB memory. Recall BRTDP BaRTDP useupper bounds. used upper bounds described Section 4.2. used = 2 106= 10 BRTDP BaRTDP.2 BaRTDP, used probabilistic termination conditionAlgorithm 3 Sanner et al. (2009). 3compared algorithms running time, time algorithm starts solving problem generating policy Bellman error (= 106 ). terminated algorithm find policy within five minutes. Note performancemeasures anytime performance (the original motivation BaRTDP) space consumption, main motivation TVI decrease convergence time. expect TVIsteep anytime performance curve, postpones backing initial state till startsworking SCC initial state belongs to. Space, hand, less interestingin-memory MDPs algorithms requires MDP model stored main memory dynamic programming apply. Therefore, share space limit. workovercoming space limitation, see, example work Dai et al. (2008, 2009a).tested algorithms set artificially-generated layered MDPs. MDPstate size |S|, partition state space evenly number nl layers, labeled integers1, . . . , nl . allow states higher numbered layers successors states lower numbered layers, vice versa, state limited set allowable successor states,named succ(s). layered MDP parameterized two variables: number actionsper state, na , maximum number successor states per action, ns . generatingtransition function state-action pair (s, a), draw integer k uniformly [1, ns ].k distinct successors uniformly sampled succ(s) random transition probabilities.pick one state layer nl goal state. One property layered MDP containsleast nl connected components.1. Notice comparison somewhat unfair TVI, since heuristic search algorithms may expand portionsstate space, sub-optimality proved. Still, make comparison understand practicalbenefits TVI v.s. known optimal MDP algorithms2. termination threshold BRTDP (it terminates vu (s0 ) Vl (s0 ) < ). indicates stoppingcondition heuristic search trial. detailed discussions two parameters, please refer workMcMahanet al. (2005). carefully tuned parameters.3. termination condition may result sub-optimal policies, reported times BaRTDP paperlower bounds. Note BaRTDP mainly aims improving anytime performance RTDP, orthogonalconvergence time. report convergence speed thorough investigation purposes.191fiRunning time (seconds)DAI , AUSAM , W ELD , & G OLDSMITH100VIILAO*LRTDP10TVIBRTDP1110100Number layers1000BaRTDPFigure 2: Running times algorithms different number layers nl random layered MDPs|S| = 50000, na = 10, ns = 10. Note two coordinates log-scaled.nl > 10 TVI outperforms VI, also state-of-the-art heuristic search algorithms.several planning domains lead multi-layered MDPs. example gameBejeweled, game difficulty levels: level least one layer. consider chessvariant without pawn promotions, played stochastic opponent. set piecescould appear board together leads least one strongly connected component.know multi-layered standard MDP benchmarks. Therefore, compare, section,artificial problems study TVIs performance across controlled parameters, nl |S|.Next section contains comprehensive experiments benchmark problems.generated problems different parameter configurations ran algorithmsset problems. running times, process converged within cut-off, reportedFigures 2 3. element table represents median convergence time running10 MDPs configuration.4 Note varying |S|, nl , na , ns yields many MDPconfigurations. tried combinations representative ones reported. found HDPmuch slower algorithms, include performance.first experiment, fixed |S| 50,000 varied nl 1 1,000. ObservingFigure 2 first find that, one layer, performance TVI slightly worseVI, MDP probably contains SCC contains majority state space,defeats benefit TVI. TVI consistently outperforms VI nl > 1. nl 10,TVI equals beats ILAO*, fastest heuristic search algorithm set problems.nl > 10, TVI outperforms algorithms cases visible margin. Also note that,number layers increases running times algorithms decrease.4. picked median instead mean avoid unexpected hard problem, takes long time solve,thereby dominating performance.192fiRunning time (seconds)OPOLOGICAL VALUE TERATION LGORITHMS162.316050403020100VIILAO*LRTDPTVIBRTDP050000State space size100000BaRTDPFigure 3: Running times algorithms different state space size |S| fixed nl = 100, na = 10,ns = 10. TVI outperforms VI, also state-of-the-art heuristic search algorithms.relative performance TVI improves |S| increases.MDPs become structured, therefore simpler solve. running time TVI decreasessecond fastest LRTDP. LRTDP slow nl = 1 running time dropsdramatically nl increases 1 20. TVI spends nearly constant time generatingtopological order SCCs, fast convergence mainly due fact VI muchefficient solving many small (and roughly equal-sized) problems large problem whose sizesum small ones. experiment shows TVI good solving MDPsmany SCCs.second experiment, fixed nl 100 varied |S| 10,000 100,000.find that, state space 10,000 TVI outperforms VI, BRTDP BaRTDP, slightlyunderperforms ILAO* LRTDP. However, problem size grows TVI soon takes lead.outperforms algorithms state space 20,000 larger. state spacegrows 100,000, TVI solves problem 6 times fast VI, 4 times fast ILAO*, 2 timesfast LRTDP, 21 times fast BRTDP, 3 times fast BaRTDP. experiment showsTVI even efficient problem space larger.4. Focused Topological Value IterationTopological value iteration improves performance value iteration significantlyMDP many equal-sized strongly connected components. However, also observe manyMDPs evenly distributed connected components. due following reason:state many actions, sub-optimal. sub-optimal actions, althoughpart optimal policy, may lead connectivity lot states. example, domainslike Blocksworld reversible actions. Due actions states mutually causally193fiDAI , AUSAM , W ELD , & G OLDSMITHs4a7a5C13 a6s1a3s5s3C111a4C1s2C12a12 s7C21a2a9a8a11a10s6C22C2Figure 4: graphical representation MDP set strongly connected components (beforeknowledge sub-optimal actions). Arcs represent probabilistic transitions, e.g.,a7 two probabilistic successors s5 s7 .dependent. result, states connected reversible actions end forming large connectedcomponent, making TVI slow.hand, heuristic search powerful solution technique, successfully concentrates computation, form backups, states transitions likelypart optimal policy. However, heuristic search uses backup strategy problems,thus missing potential savings knowing graphical structure information.knew existence action optimal policy, could eliminate restactions outgoing state, thus breaking connectivity. course, information neveravailable. However, little help heuristic search, eliminate sub-optimal actionsproblem leading reduced connectivity hopefully, smaller sizes strongly connectedcomponents.Figure 4 shows graphical representation part one simple MDP 7 states12 actions. figure, successors probabilistic actions connected arc.simplicity, transition probabilities Ta , costs C(s, a), initial state goal states omitted. UsingTVI, divide MDP two SCCs C1 C2 . However, suppose givenadditional information a5 a12 sub-optimal. Based remaining actions, C1 C2sub-divided three two smaller components respectively (as shown figure).Dynamic programming greatly benefit new graphical structure, since solving smallercomponents much easier large one.4.1 FTVI Algorithmkey insight novel algorithm break big components smaller parts, removing actions proven suboptimal current problem hand. exploitsknowledge current initial state goal, TVI mostly ignores. call newalgorithm focused topological value iteration (FTVI) (Dai et al., 2009b). pseudo-code shownAlgorithm 3.core, FTVI makes use action elimination theorem, states:194fiT OPOLOGICAL VALUE TERATION LGORITHMSTheorem 3 Action Elimination (Bertsekas, 2001): lower bound Q (s, a) greaterupper bound V (s) action cannot optimal action state s.gives us template eliminate actions, except need compute lower boundQ upper bound V . FTVI keeps two bounds V simultaneously: lowerbound Vl () upper bound Vu (). Vl () initialized via admissible heuristic. notetwo properties Vl : (1) Ql (s, a) computed one-step lookahead given current lower boundvalue Vl () (Line 30, Algorithm 3) lower bound Q (s, a), (2) V values remainlower bounds throughout algorithm execution process, initialized admissibleheuristic. So, lets us easily compute lower bound Q , also improves backupsperformed.Similar properties hold Vu , upper bound V , i.e., initialize Vu upper boundperform backups based Vu successive value estimate remains upper bound.later implementation section lists exact procedure compute lower upper boundsdomain-independent manner. note employ action elimination use lowerupper bounds, domain informative, domain-dependent bounds available,easily plugged FTVI.FTVI contains two sequential steps. first step, call search step, FTVIperforms small number heuristic searches similar ILAO*, i.e., backs stateper iteration. makes searches FTVI fast, still useful enough eliminate sub-optimalactions. two main differences common heuristic search search phase FTVI.First, backup, update upper bound manner lower bound.reminiscent backups BRTDP (McMahan et al., 2005). Second, also check eliminatesub-optimal actions using action elimination (Lines 3032).second step, computation step, FTVI generates directed graph GSRmanner TVI generates GR , based remaining actions. concretely, directededge vertex s1 s2 exists uneliminated action Ta (s2 |s1 ) > 0.easy see graph GSR generated always sub-graph GR . FTVI findsconnected components GSR , topological order, solves component sequentiallytopological order.state following theorem FTVI.Theorem 4 FTVI guaranteed converge optimal value function.correctness theorem based two facts: (1) action elimination preserves soundness,(2) TVI optimal planning algorithm (Theorem 2).4.2 Implementationseveral interesting questions answer implementation. calculate initialupper lower bounds? many search iterations need perform search step?possible FTVI converges search step? still remains large componenteven action elimination?used lower bound Vl TVI (see Section 3.2). upper bound, startedsimple upper bound:195fiDAI , AUSAM , W ELD , & G OLDSMITHAlgorithm 3 Focused Topological Value Iteration1: Input: MDP hS, A, Ap, T, Ci, x: number search iterations batch, y: lower bound2:3:4:5:6:7:8:9:10:11:12:13:14:15:16:17:18:19:20:21:22:23:24:25:26:27:28:29:30:31:32:33:34:35:percentage change initial state value new batch search iterations, : thresholdvalue{step 1: search}trueold value Vl (s0 )iter 1 xBellman error 0every statemark every state unvisiteds0Search(s)Bellman error < {The value function converges}return Vlold value/Vl (s0 ) > (100 y)%break{step 2: computation}hS, A, Ap, T, CiTVI(M , ) {by applying backup operator action elimination}Function Search(s)/ Gmark visitedargmina Q(s, a)every unvisited successor s0 actionSearch(s0 )Bellman error max(Bellman error, Back up(s))Function Back up(s)actionPQ(s, a) C(s, a) + s0 Ta0 (s0 |s)Vl (s0 )Ql (s, a) > Vu (s)eliminate Ap(s)oldVl Vl (s)Vl (s) minaAp(s) Q(s, a)PVu (s) minaAp(s) [C(s, a) + s0 Ta0 (s0 |s)Vu (s0 )]36: return |Vl (s) oldVl |Vu (s) = 0 G, else Vu (s) = .(8)initialization gives us global yet loose upper bound. improve tightness,performed backward best-first search set goal states. States visited Vu valuesupdated Algorithm 3, Line 35. iteratively get tighter tighter boundsbackward searches performed.time spent search significant impact FTVI. search iterationsmight eliminate enough sub-optimal actions. However, many search iterations turn196fiT OPOLOGICAL VALUE TERATION LGORITHMS504030201001101001000Heuristic search trial #10000Running time (seconds)Running time (seconds)FTVI heuristic search algorithm trade advantage FTVI. control experiment varying total number heuristic search trials two problems. Figure 5 showsperformance Wet-floor problem matches hypothesis perfectly. Drive problem,number search trials affect convergence speed much, many searchtrials turn harmful.1510501101001000Heuristic search trial #10000Figure 5: Running times FTVI different number initial search trials (left) Wet-floor problem(right) Drive problem. trials sometimes less helpful eliminating enoughsup-optimal actions, many trials harmful.Considering tradeoff, let algorithm automatically determine number searchiterations. FTVI incrementally performs batch x search iterations. batch, computesamount change Vl (s0 ) value. change greater y%, new batch searchperformed. Otherwise, search phase considered complete. implementation, usex = 100, = 3.interesting case occurs optimal value found search step. AlthoughFTVI performs limited number search iterations, possible problem optimally solvedwithin search step. helpful keep track optimality information search step,FTVI potentially skip unnecessary search iterations entire computation step.this, need maintain Bellman error current search iteration, terminateFTVI error smaller threshold (Lines 1112). experiment, find simpleoptimization extremely helpful promoting performance FTVI.Sometimes cases GSR still contains large connected components.caused two reasons (1) optimal policy indeed large components, (2) connectivity caused many suboptimal actions successfully eliminated search. try decompose large components, let FTVI perform additional intra-component heuristicsearches. intra-component heuristic search takes place inside particular component.purpose find new, sub-optimal actions, might help decompose component. Givencomponent C GSR , define SourceC set states none incoming transitions states C. words, states SourceC incoming bridge statesC rest MDP. intra-component heuristic search C originates state SourceC .search branch terminates state outside C encountered.experiments compared performance FTVI without additionalintra-component search problems four domains, namely Wet-floor (Bonet & Geffner, 2006),197fiDAI , AUSAM , W ELD , & G OLDSMITHSingle-arm pendulum (Wingate & Seppi, 2005), Drive, Elevator (Bonet, 2006). resultsshow additional intra-component search provided limited gains Wet-floor problems,helped decrease size largest components approximately 50% average,sped convergence 10% best. However, intra-component search turned harmfuldomains, provide new graphical information (no smaller componentsgenerated). contrary, search introduced lot unnecessary overhead.used version perform additional intra-component search throughout restexperiments.4.3 Experimentsaddress following two questions experiments: (1) FTVI comparealgorithms broad range domain problems? (2) specific kind domainsFTVI preferred heuristic search?implemented FTVI framework Section 3.3, used cut-off time5 minutes algorithm per problem. investigate helpfulness action elimination,also implemented VI variant applies action elimination backups. usedthreshold value = 106 , ran BRTDP BaRTDP upper bound FTVI.4.3.1 R ELATIVE PEED FTVIProblemMCar100MCar300MCar700SAP100SAP300SAP500WF200WF400DAP10DAP20DriveDriveDriveElevator (IPPC p13)Elevator (IPPC p15)Tireworld (IPPC p5)Tireworld (IPPC p6)Blocksworld (IPPC p4)Blocksworld (IPPC p5)VI1.4026.12278.162.3042.61174.7119.95105.790.7721.412.0020.58236.9133.8847.8817.6914.19VI (w/ a.e.)0.7413.40124.341.0619.9077.9913.7198.970.6717.621.3914.20133.8016.4623.0417.6914.19ILAO*1.9111.91101.651.8132.40131.1711.2273.881.0132.681.6096.09227.5327.350.000.000.020.00LRTDP1.23229.702.5851.450.69273.370.140.160.260.11BRTDP2.81117.23216.019.3922.0897.733.04144.127.85163.910.010.011.930.66BaRTDP63.55 (*)180.64 (*)262.92 (*)111.59 (*)1.99 (*)103.87 (*)222.33 (*)4.17 (*)4.17 (*)3.94 (*)0.030.04-TVI0.6823.22233.982.3744.220.58100.780.7521.951.2313.0374.7058.4614.592.2648.8154.3554.34FTVI0.222.3513.060.172.969.568.8174.240.5917.491.0710.6341.9354.1112.110.000.000.020.00Table 1: Total running times different algorithms problems various domains. FTVI outperformsalgorithms vast margins. (Fastest times bolded. - Time means algorithmfailed solve problem within 5 minutes. *s mean algorithm terminated suboptimal solutions.)198fiT OPOLOGICAL VALUE TERATION LGORITHMSProblemMCar100MCar300MCar700SAP100SAP300SAP500WF200WF400DAP10DAP20DriveDriveDriveElevator (IPPC p13)Elevator (IPPC p15)Tireworld (IPPC p5)Tireworld (IPPC p6)Blocksworld (IPPC p4)Blocksworld (IPPC p5)Reachable |S|10,00090,000490,00010,00090,000250,00040,000160,00010,000160,0004,56329,40375,840539,136539,136671,687724,933103,121103,121TVIBC sizeime7,7990.6871,75123.22390,191 233.989,9992.3789,99944.239,99920.58159,999 100.789,4540.75150,48921.954,5601.2329,40013.0375,84074.701,05358.461,05314.59232.26618,44848.81103,10454.35103,20454.34BC size111n/an/an/a15,039141,671n/an/a4,56029,40075,8401,0531,053n/an/an/an/aFTVITsearch0.202.2212.290.172.969.563.3014.270.5917.490.110.150.180.010.010.000.000.020.00Tgen0.010.130.76n/an/an/a0.120.36n/an/a0.020.150.401.731.60n/an/an/an/aime0.222.3513.060.172.969.568.8174.240.5917.491.0710.6341.9354.1112.110.000.000.020.00Table 2: Detailed performance statistics TVI FTVI. (BC size means size biggest connectedcomponent. n/a means FTVI converged search step skipped computation step.running times seconds. Tsearch represents time used search step, Tgentime spent generating graphical structure. Fastest times bolded. - Time meansalgorithm failed solve problem within 5 minutes.)evaluated various algorithms problems eight domains Mountain Car, SingleDouble Arm Pendulum (Wingate & Seppi, 2005), Wet-floor (Bonet & Geffner, 2006)5 ,four domains International Planning Competition 2006 Drive, Elevators, TireWorldBlocksworld. mountain car problem usually many source states.6 chose source stateinitial state, averaged statistics per problem. Table 1 lists running timesvarious algorithms. FTVI, additionally report (in Table 2) time used searches(Tsearch ), time spent generating graphical structure (Tgen ), problem solvedsearch phase, leftover time spent solving SCCs. also comparedsize biggest component (BC size) generated TVI FTVI.Overall find FTVI outperforms five algorithms domains.FTVI outperforms TVI domains. Notice MCar problems, FTVI establishesfavorable graphical structures (strongly connected components size one) search step.7graphical structure makes second step FTVI trivial. TVI solve much biggercomponents, runs much slower. Drive domain, even find informedgraphical structure, advanced backup action elimination enables FTVI converge faster.5. Note used probability wet cells, p = 0.5.6. source state state incoming transitions.7. allow FTVI perform computation step opposed stop search step problem solved,find similar structures Tireworld Blocksworld problems.199fiDAI , AUSAM , W ELD , & G OLDSMITHFTVI outperforms heuristic search algorithms significantly domains MCar, SAPDrive. faster ILAO* order magnitude. shows extreme effectivenessFTVIs decomposing problem small sub-problems using advanced graphical informationsolving sub-problems sequentially. three RTDP algorithms competitivealgorithms domains, fail return solution cutoff time manyproblems. FTVI shows limited speedup heuristic search domains Wet-floor, DAP,Elevator. FTVI par ILAO*, vastly outperforms TVI Tireworld Blocksworlddomains, converges within search step. convergence speed value iteration typicallyslow, backs states iteratively fixed order. Adding action elimination Bellman backupsincreases convergence speed VI two times, especially Mountain Car, Single ArmPendulum, Elevator domains, convergence speed usually least one magnitude slowerFTVI.4.3.2 FACTORS ETERMINING P ERFORMANCEshown FTVI faster heuristic search algorithms many domains, relativespeedup domain-dependent. find domain features particularly beneficialFTVI worse heuristic search algorithms? evaluation performed control experimentsvarying domains across different features study effect planning time variousalgorithms.make initial prediction three features.1. number goals domain: number goal states small, search may takelong time discovers path goal. Therefore, many sub-optimal policies mightevaluated heuristic search algorithm.2. Search depth initial state goal state: depth lower bound lengthexecution trial also size policy graph. greater depth impliessearch steps per iteration, might make evaluating policy time-consuming.3. Heuristic informativeness: performance heuristic search algorithm depends lotquality initial heuristic function. expect win FTVI increaseheuristic less informed.Number Goals. far know, suitable domain specifytotal number goal states arbitrarily, used artificial domain. domainstate two applicable actions, action two random successors. testedalgorithms domains two sizes, 10,000 (Figure 6(left)) 50,000 (Figure 6(right)).problem size, fixed shortest goal distance varied number goal states, |G|.concretely, generating state transitions, performed BFS initial state,randomly picked goal states search depth. |G| value, generated 10 problems,reported median running time four algorithms (LRTDP BaRTDP slowdomain). observe algorithms take time solve problem smaller numbergoal states larger number. However, beyond point (|G| > 20 experiments),running times become stable. FTVI runs marginally slower |G| small, suggestingperformance less dependent number goal states. BRTDP second besthandling small goal sets, runs nearly fast FTVI goal set large. Even though200fi1.41.210.80.60.40.20ILAO*Running time (seconds)Running time (seconds)OPOLOGICAL VALUE TERATION LGORITHMSTVIFTVIBRTDP020406080Number goal states10076543210ILAO*TVIFTVIBRTDP020406080Number goal states100Figure 6: Running times algorithms different number goal states problem size (left) |S| =10, 000 (right) |S| = 50, 000 random MDPs. FTVI TVI slow least significantlynumber goal states small.TVI runs slowest among four algorithms, performance shows less severe dependencenumber goal states. runs almost fast ILAO* goal set size 1. contrast,ILAO* runs twice fast TVI goal set size greater 20.Search Depth. experiment, studied search depth goal initialstate influences performance various algorithms. chose Mountain car problemSingle-arm pendulum problem. randomly picked 100 initial states state space8measured shallowest search depth, or, shortest distance, d, goal state. running timesFigure 7 ordered d. BaRTDP terminate optimal policy many instances,performance shown. BRTDP biggest variance performance includedclarity purposes.see, FTVI fastest algorithm suite experiments. convergesquickly initial states (usually around one two seconds Mcar300, less 10 seconds SAP300). TVIs performance unaffected search depth, expected, sincevariant value iteration search component. MCar300 problem,find strong evidence running time algorithm depends search depth. FTVI runsorder magnitude faster TVI, ILAO*, BRTDP two orders magnitude fasterLRTDP. SAP300 problems, running times algorithms except TVI increasesearch depth increases. LRTDP runs fast relatively small, slows considerablyunable solve many problems becomes larger. ILAO*s convergence speed variesbit distance small. increases, running time also increases. BRTDPs performance (not included) close ILAO* small, becomes slower performssimilar LRTDP large. problem, heuristic search algorithms unanimously suffersignificantly increase search depth, running times increase least twoorders magnitude small large values. hand, FTVI slows oneorder magnitude, makes converge one order magnitude faster ILAO*, one twoorders magnitude faster BRTDP TVI, two orders magnitude faster LRTDPlarge depths.8. Note problems well-defined initial states. picked initial states arbitrarily S.201fiDAI , AUSAM , W ELD , & G OLDSMITH1000TVI100FTVI1010.102000.010.001Running time (seconds)Running time (seconds)1000FTVI1010100200Running time (seconds)Running time (seconds)FTVI10.102000.01Shortest goal distance1000TVI1000.01LRTDP100.001Shortest goal distance10000.1ILAO*100LRTDP10FTVI10.10.01Shortest goal distanceILAO*1000100200Shortest goal distanceFigure 7: Running times algorithms different shortest distance goal (top) mountain car300 300 (MCar300), (bottom) single-arm pendulum 300 300 (SAP300) problems, (left) comparison FTVI TVI, (right) comparison FTVI heuristic search algorithms. Heuristic search algorithms slow massively (note log scale) search depth large.Heuristic Quality. Finally studied effect heuristic informativeness algorithms. conducted two sets experiments, based two sets consistent heuristics. foundBRTDP slower algorithms problems BaRTDP comparable (about 50%slower LRTDP) Wet100 problem, include running times.first experiment, pre-computed optimal value function problem using value iteration,used fraction optimal value initial heuristic. Given fraction f (0, 1],calculated h(s) = f V (s). Figure 8 plots running times different algorithms fthree problems. Note f = 1 means initial heuristic already optimal, problem trivialalgorithms, TVI overhead building topological structure. FTVI, however,able detect convergence search step circumvent overhead, fast. LRTDPslow Wet100 problem, running times problem omitted figure.figure shows f increases (i.e. heuristic becomes informative) running timesalgorithms decrease almost linearly. true even TVI, heuristic-guidedalgorithm, takes less time, probably initial values affect number iterationsrequired convergence.thoroughly study influence heuristics, conducted second set experiments.experiment, used fractional Vl value initial heuristic. Recall Vl lowerbound V computed value deterministic problem. calculated initial heuristic202fiILAO*LRTDP0.5TVIFTVI000.5f132.521.510.50ILAO*LRTDPTVIFTVI00.5f1543ILAO*2TVI1FTVI000.5f1Running time (seconds)1Running time (seconds)1.5Running time (seconds)Running time (seconds)Running time (seconds)Running time (seconds)OPOLOGICAL VALUE TERATION LGORITHMS86ILAO*4LRTDP2TVI0FTVI00.5f132.521.510.50ILAO*LRTDPTVIFTVI00.5f1543ILAO*2TVI1FTVI000.5f1Figure 8: Running times algorithms different initial heuristic (top) mountain car 100 100(MCar100), (middle) single-arm pendulum 100100 (SAP100), (bottom) wet-floor 100100(WF100)problems.sensitivePP algorithms equallyPP heuristic informativeness. (left) f= sS h(s)/ sS V (s) (right) f = sS h(s)/ sS Vl (s).h(s) = f Vl (s). included algorithms show similar smooth decrease running timef increases. BRTDP, however, shows strong dependence heuristics Wet100 problem.running time decreases sharply 96.91 seconds 0.54 seconds 99.81 seconds6.21 seconds f = 0.02 f = 1 two experiments. Stable changes twoexperiments suggests following algorithms except BRTDP. (1) algorithm particularlyvulnerable less informed heuristic function; (2) extremely informative heuristics (when fclose 1) necessarily lead extra fast convergence. result in-line resultsdeterministic domains (Helmert & Roger, 2008).203fiDAI , AUSAM , W ELD , & G OLDSMITH4.3.3 ISCUSSIONexperiments, learn FTVI vastly better domains whose problems smallnumber goal states long search depth initial state goal (such MCar, SAPDrive). convergence control module FTVI helps successfully matching performance FTVI fastest heuristic search algorithm. addition, FTVI displays limitedadvantage heuristic search two intermediate cases problem (1) many goalstates long search depth (Elevator), (2) short depth fewer goal states (DAP). conclusion, FTVI algorithm choice whenever problem either small number goal stateslong search depth.5. Related WorkBesides TVI several researchers proposed decomposing MDP sub-problemscombining solutions final policy, e.g., work Hauskrecht et al. (1998) Parr(1998). However, approaches typically assume additional structure problem,either known hierarchies, known decomposition weakly coupled sub-MDPs, etc., whereasFTVI assumes additional structure.BRTDP (McMahan et al., 2005), Bayesian RTDP (Sanner et al., 2009) Focused RTDP(Smith & Simmons, 2006) (FRTDP) also keep upper bound value function. However,algorithms use upper bound purely judge close state convergence, comparingdifference upper lower bound values. example, BRTDP tries makesearches focus states whose two bounds larger differences, intuitively, states whosevalues less converged. Unlike FTVI, three algorithms perform action elimination,use connected component information solve MDP. performance BRTDP(and similarly Bayesian RTDP) highly dependent quality heuristics. Furthermore,FRTDP works discounted setting, thus immediately applicable stochasticshortest path problems.HDP similar TVI sense uses Tarjans algorithm (slightly differentKosarajus algorithm) find strongly connected components greedy graph. computesSCCs multiple times dynamically depth-first searches HDP tries labelsolved states. find topological order SCCs decompose problemuse topological order sequentially solve SCC.Prioritized sweeping (Moore & Atkeson, 1993) extensions, focussed dynamic programming (Ferguson & Stentz, 2004) improved prioritized sweeping (McMahan & Gordon, 2005),order backups intelligently help priority queue. state queue prioritizedbased potential improvement value backup state. Dai Hansen (2007)demonstrate algorithms large overhead maintaining priority queueoutperformed simple backward search algorithm, implicitly prioritizes backups withoutpriority queue. Moreover, prioritized sweeping improved prioritized sweeping find optimalvalue entire state space MDP, use initial state information. Focusseddynamic programming, however, able make use initial state information,optimal algorithm. three algorithms massively outperformed LAO* variant (Dai &Hansen, 2007).MDP large solved optimally, another thread work solves MDPs approximately. typical way use deterministic relaxations MDP and/or basis204fiT OPOLOGICAL VALUE TERATION LGORITHMSfunctions (Guestrin, Koller, Parr, & Venkataraman, 2003; Poupart, Boutilier, Patrascu, & Schuurmans, 2002; Patrascu, Poupart, Schuurmans, Boutilier, & Guestrin, 2002; Yoon, Fern, & Givan,2007; Kolobov, Mausam, & Weld, 2009, 2010a, 2010b). techniques algorithmsorthogonal ones FTVI, interesting future direction approximate FTVIapplying basis functions.MDP maintains logical representation, another type algorithm aggregates groupsstates MDP features, represents factored MDP using algebraic Boolean decision diagrams (ADDs BDDs) solves factored MDP using ADD BDD operations;SPUDD (Hoey, St-Aubin, Hu, & Boutilier, 1999), sLAO* (Feng & Hansen, 2002), sRTDP (Feng,Hansen, & Zilberstein, 2003) examples. factored representation exponentially simpler flat MDP, computation efficiency problem-dependent. idea algorithms orthogonal (F)TVI. Exploring ways combining ideas (F)TVIcompact logical representation achieve performance improvements remains future work.Action elimination originally proposed Bertsekas (2001). provedhelpful RTDP factored MDP setting (Kuter & Hu, 2007), cost actiondepends state variables. Action elimination also useful temporal planning(Mausam & Weld, 2008). extended combo-elimination, rule prune irrelevantaction combinations setting multiple actions executed time.idea finding topological order strongly connected components MDPextended solving partially-observable MDPs (POMDPs). POMDP problem typicallymuch harder MDP problem since decision agent partial informationcurrent state (Littman et al., 1995). topological order-based planner (POT) (Dibangoye, Shani,Chaib-draa, & Mouaddib, 2009) uses topological order information underlying MDPshelp solve POMDP problem faster. believe idea extended help solve even harderproblems, decentralized POMDP (Bernstein, Givan, Immerman, & Zilberstein, 2002),future.6. Conclusionswork makes several contributions. First, present two new optimal algorithms solveMDPs, topological value iteration (TVI) focused topological value iteration (FTVI). TVI studiesgraphical structure MDP breaking strongly connected components solvesMDP based topological order components. FTVI extends topological value iterationalgorithm focusing construction strongly connected components transitions likelybelong optimal policy. FTVI using small amount heuristic search eliminateprovably suboptimal actions. contrast TVI, care goal-state information,FTVI removes transitions determines irrelevant optimal policy reachinggoal. sense, FTVI builds much informative topological structure TVI.Second, show empirically TVI outperforms VI state-of-the-art algorithmsMDP contains many strongly connected components. find TVI advantageous problems multiple equal-sized components.Third, show empirically FTVI outperforms TVI VI large number domains,usually order magnitude. performance due success informedgraphical structure, since sizes connected components found FTVI vastly smallerconstructed TVIs.205fiDAI , AUSAM , W ELD , & G OLDSMITHFourth, find surprisingly many domains FTVI massively outperforms popular heuristic search algorithms convergence speed, ILAO*, LRTDP, BRTDP BaRTDP.analyzing performance algorithms different problems, find smaller number goal states long search depth goal two key features problems especiallyhard heuristic search handle. results show FTVI outperforms heuristic searchdomains order magnitude.Finally, by-product also compare ILAO*, LRTDP, BRTDP BaRTDP (four popular,state-of-the-art heuristic search algorithms) find strength algorithm usuallydomain-specific. Generally, ILAO* faster convergence algorithms. BRTDPBaRTDP slow domains probably due fact vulnerable problems lack informed upper bounds.Acknowledgmentswork conducted Peng Dai student University Washington. worksupported Office Naval Research grant N00014-06-1-0147, National Science FoundationIIS-1016465, ITR-0325063 WRF / TJ Cable Professorship. thank Eric A. Hansensharing code ILAO*, anonymous reviewers excellent suggestions improvingmanuscript.ReferencesAberdeen, D., Thiebaux, S., & Zhang, L. (2004). Decision-Theoretic Military Operations Planning. Proc. 14th International Conference Automated Planning Scheduling(ICAPS-04), pp. 402412.Barto, A., Bradtke, S., & Singh, S. (1995). Learning act using real-time dynamic programming.Artificial Intelligence J., 72, 81138.Bellman, R. (1957). Dynamic Programming. Princeton University Press, Princeton, NJ.Bernstein, D. S., Givan, R., Immerman, N., & Zilberstein, S. (2002). Complexity Decentralized Control Markov Decision Processes. Mathematics Opererations Research, 27(4),819840.Bertsekas, D. P. (2000-2001). Dynamic Programming Optimal Control, Vol. 2. Athena Scientific.Bertsekas, D. P., & Tsitsiklis, J. N. (1996). Neuro-Dynamic Programming. Athena Scientific,Belmont, MA.Bonet, B., & Geffner, H. (2003a). Faster Heuristic Search Algorithms Planning UncertaintyFull Feedback. Proc. 18th International Joint Conf. Artificial Intelligence (IJCAI03), pp. 12331238. Morgan Kaufmann.Bonet, B., & Geffner, H. (2003b). Labeled RTDP: Improving Convergence Real-time Dynamic Programming. Proc. 13th International Conference Automated PlanningScheduling (ICAPS-03), pp. 1221.206fiT OPOLOGICAL VALUE TERATION LGORITHMSBonet, B. (2006). Non-Deterministic Planning Track 2006 International Planning Competition.. http://www.ldc.usb.ve/bonet/ipc5/.Bonet, B. (2007). Speed Convergence Value Iteration Stochastic Shortest-PathProblems. Mathematics Operations Research, 32(2), 365373.Bonet, B., & Geffner, H. (2006). Learning Depth-First Search: Unified Approach HeuristicSearch Deterministic Non-deterministic Settings, Applications MDPs. Proc.16th International Conference Automated Planning Scheduling (ICAPS-06), pp.142151.Bresina, J. L., Dearden, R., Meuleau, N., Ramkrishnan, S., Smith, D. E., & Washington, R. (2002).Planning Continuous Time Resource Uncertainty: Challenge AI. Proc.18th Conf. Uncertainty AI (UAI-02), pp. 7784.Cormen, T. H., Leiserson, C. E., Rivest, R. L., & Stein, C. (2001). Introduction Algorithms,Second Edition. MIT Press.Dai, P., & Goldsmith, J. (2007). Topological Value Iteration Algorithm Markov Decision Processes. Proc. IJCAI, pp. 18601865.Dai, P., & Hansen, E. A. (2007). Prioritizing Bellman Backups Without Priority Queue. Proc.17th International Conference Automated Planning Scheduling (ICAPS-07), pp.113119.Dai, P., Mausam, & Weld, D. S. (2008). Partitioned External-Memory Value Iteration. AAAI, pp.898904.Dai, P., Mausam, & Weld, D. S. (2009a). Domain-Independent, Automatic Partitioning Probabilistic Planning. IJCAI, pp. 16771683.Dai, P., Mausam, & Weld, D. S. (2009b). Focused Topological Value Iteration. Proc. ICAPS,pp. 8289.Dibangoye, J. S., Shani, G., Chaib-draa, B., & Mouaddib, A.-I. (2009). Topological Order PlannerPOMDPs. Proc. IJCAI, pp. 16841689.Feng, Z., & Hansen, E. A. (2002). Symbolic Heuristic Search Factored Markov Decision Processes. Proc. 17th National Conference Artificial Intelligence (AAAI-05).Feng, Z., Hansen, E. A., & Zilberstein, S. (2003). Symbolic Generalization On-line Planning.Proc. 19th Conference Uncertainty Artificial Intelligence (UAI-03), pp. 209216.Feng, Z., & Zilberstein, S. (2004). Region-Based Incremental Pruning POMDPs. Proc.UAI, pp. 146153.Ferguson, D., & Stentz, A. (2004). Focussed Dynamic Programming: Extensive Comparative Results. Tech. rep. CMU-RI-TR-04-13, Carnegie Mellon University, Pittsburgh, PA.Guestrin, C., Koller, D., Parr, R., & Venkataraman, S. (2003). Efficient Solution AlgorithmsFactored MDPs. J. Artificial Intelligence Research, 19, 399468.207fiDAI , AUSAM , W ELD , & G OLDSMITHHansen, E. A., & Zilberstein, S. (2001). LAO*: heuristic search algorithm finds solutionsloops. Artificial Intelligence J., 129, 3562.Hauskrecht, M., Meuleau, N., Kaelbling, L. P., Dean, T., & Boutilier, C. (1998). HierarchicalSolution Markov Decision Processes using Macro-actions. Proc. UAI, pp. 220229.Helmert, M., & Roger, G. (2008). Good Almost Perfect?. Proc. AAAI, pp. 944949.Hoey, J., St-Aubin, R., Hu, A., & Boutilier, C. (1999). SPUDD: Stochastic Planning using DecisionDiagrams. Proc. 15th Conference Uncertainty Artificial Intelligence (UAI-95),pp. 279288.Kolobov, A., Mausam, & Weld, D. S. (2009). ReTrASE: Intergating Paradigms ApproximateProbabilistic Planning. Proc. IJCAI, pp. 17461753.Kolobov, A., Mausam, & Weld, D. S. (2010a). Classical Planning MDP Heuristics: LittleHelp Generalization. Proc. ICAPS, pp. 97104.Kolobov, A., Mausam, & Weld, D. S. (2010b). SixthSense: Fast Reliable Recognition DeadEnds MDPs. Proc. AAAI.Kuter, U., & Hu, J. (2007). Computing Using Lower Upper Bounds Action EliminationMDP Planning. SARA, pp. 243257.Littman, M. L., Dean, T., & Kaelbling, L. P. (1995). Complexity Solving Markov DecisionProblems. Proc. 11th Annual Conference Uncertainty Artificial Intelligence(UAI-95), pp. 394402 Montreal, Quebec, Canada.Mausam, Benazera, E., Brafman, R. I., Meuleau, N., & Hansen, E. A. (2005). PlanningContinuous Resources Stochastic Domains. Proc. IJCAI, pp. 12441251.Mausam, & Weld, D. S. (2008). Planning Durative Actions Stochastic Domains. J.Artificial Intelligence Research (JAIR), 31, 3382.McMahan, H. B., & Gordon, G. J. (2005). Fast Exact Planning Markov Decision Processes.Proc. 15th International Conference Automated Planning Scheduling (ICAPS05).McMahan, H. B., Likhachev, M., & Gordon, G. J. (2005). Bounded real-time dynamic programming: RTDP monotone upper bounds performance guarantees. Proceedings22nd international conference Machine learning (ICML-05), pp. 569576.Meuleau, N., Benazera, E., Brafman, R. I., Hansen, E. A., & Mausam (2009). Heuristic SearchApproach Planning Continuous Resources Stochastic Domains. J. ArtificialIntellegence Research (JAIR), 34, 2759.Moore, A., & Atkeson, C. (1993). Prioritized Sweeping: Reinforcement Learning Less DataLess Real Time. Machine Learning, 13, 103130.208fiT OPOLOGICAL VALUE TERATION LGORITHMSMusliner, D. J., Carciofini, J., Goldman, R. P., E. H. Durfee, J. W., & Boddy, M. S. (2007). FlexiblyIntegrating Deliberation Execution Decision-Theoretic Agents. ICAPS WorkshopPlanning Plan-Execution Real-World Systems.Nilson, N. J. (1980). Principles Artificial Intelligence. Tioga Publishing Company, Palo Alto,Ca.Parr, R. (1998). Flexible Decomposition Algorithms Weakly Coupled Markov Decision Problems. Proc. UAI, pp. 422430.Patrascu, R., Poupart, P., Schuurmans, D., Boutilier, C., & Guestrin, C. (2002). Greedy LinearValue-Approximation Factored Markov Decision Processes. Proc. 17th NationalConference Artificial Intelligence (AAAI-02), pp. 285291.Poupart, P., Boutilier, C., Patrascu, R., & Schuurmans, D. (2002). Piecewise Linear Value FunctionApproximation Factored MDPs. Proc. 18th National Conference ArtificialIntelligence (AAAI-02), pp. 292299.Sanner, S., Goetschalckx, R., Driessens, K., & Shani, G. (2009). Bayesian Real-Time DynamicProgramming. Proc. IJCAI, pp. 17841789.Smith, T., & Simmons, R. G. (2006). Focused Real-Time Dynamic Programming MDPs:Squeezing Heuristic. Proc. 21th National Conference ArtificialIntelligence (AAAI-06).Wingate, D., & Seppi, K. D. (2005). Prioritization Methods Accelerating MDP Solvers. J.Machine Learning Research, 6, 851881.Yoon, S., Fern, A., & Givan, R. (2007). FF-Replan: Baseline Probabilistic Planning. Proc.17th International Conference Automated Planning Scheduling (ICAPS-07), pp.352359.209fiJournal Artificial Intelligence Research 42 (2011) 427-486Submitted 1/11; published 11/11Adaptive Submodularity: Theory Applications Active LearningStochastic OptimizationDaniel GolovinDGOLOVIN @ CALTECH . EDUCalifornia Institute TechnologyPasadena, CA 91125, USAAndreas KrauseKRAUSEA @ ETHZ . CHSwiss Federal Institute Technology8092 Zurich, SwitzerlandAbstractMany problems artificial intelligence require adaptively making sequence decisionsuncertain outcomes partial observability. Solving stochastic optimization problemsfundamental notoriously difficult challenge. paper, introduce conceptadaptive submodularity, generalizing submodular set functions adaptive policies. proveproblem satisfies property, simple adaptive greedy algorithm guaranteedcompetitive optimal policy. addition providing performance guaranteesstochastic maximization coverage, adaptive submodularity exploited drastically speedgreedy algorithm using lazy evaluations. illustrate usefulness conceptgiving several examples adaptive submodular objectives arising diverse AI applicationsincluding management sensing resources, viral marketing active learning. Proving adaptivesubmodularity problems allows us recover existing results applicationsspecial cases, improve approximation guarantees handle natural generalizations.1. Introductionmany problems arising artificial intelligence one needs adaptively make sequence decisions, taking account observations outcomes past decisions. Often outcomesuncertain, one may know probability distribution them. Finding optimal policiesdecision making partially observable stochastic optimization problems notoriously intractable (see, e.g. Littman, Goldsmith, & Mundhenk, 1998). fundamental challenge identifyclasses planning problems simple solutions obtain (near-) optimal performance.paper, introduce concept adaptive submodularity, prove partiallyobservable stochastic optimization problem satisfies property, simple adaptive greedy algorithm guaranteed obtain near-optimal solutions. fact, reasonable complexity-theoreticassumptions, polynomial time algorithm able obtain better solutions general. Adaptivesubmodularity generalizes classical notion submodularity1 , successfully useddevelop approximation algorithms variety non-adaptive optimization problems. Submodularity, informally, intuitive notion diminishing returns, states adding elementsmall set helps adding element larger (super-) set. celebrated resultwork Nemhauser, Wolsey, Fisher (1978) guarantees submodular functions,simple greedy algorithm, adds element maximally increases objective value,1. extensive treatment submodularity, see books Fujishige (2005) Schrijver (2003).c2011AI Access Foundation. rights reserved.fiG OLOVIN & K RAUSEselects near-optimal set k elements. Similarly, guaranteed find set near-minimalcost achieves desired quota utility (Wolsey, 1982), using near-minimum average time(Streeter & Golovin, 2008). Besides guaranteeing theoretical performance bounds, submodularity allows us speed algorithms without loss solution quality using lazy evaluations (Minoux, 1978), often leading performance improvements several orders magnitude (Leskovec,Krause, Guestrin, Faloutsos, VanBriesen, & Glance, 2007). Submodularity shownuseful variety problems artificial intelligence (Krause & Guestrin, 2009a).challenge generalizing submodularity adaptive planning action takenstep depends information obtained previous steps feasible solutionspolicies (decision trees conditional plans) instead subsets. propose natural generalization diminishing returns property adaptive problems, reduces classicalcharacterization submodular set functions deterministic distributions. showresults Nemhauser et al. (1978), Wolsey (1982), Streeter Golovin (2008), Minoux (1978)generalize adaptive setting. Hence, demonstrate adaptive submodular optimizationproblems enjoy theoretical practical benefits similar classical, nonadaptive submodular problems. demonstrate usefulness generality concept showingcaptures known results stochastic optimization active learning special cases, admitstighter performance bounds, leads natural generalizations allows us solve new problemsperformance guarantees known.first example, consider problem deploying (or controlling) collection sensorsmonitor spatial phenomenon. sensor cover region depending sensing range.Suppose would like find best subset k locations place sensors. application,intuitively, adding sensor helps placed sensors far helps lessalready placed many sensors. formalize diminishing returns property using notionsubmodularity total area covered sensors submodular function definedsets locations. Krause Guestrin (2007) show many realistic utility functionssensor placement (such improvement prediction accuracy w.r.t. probabilistic model)submodular well. consider following stochastic variant: Instead deploying fixedset sensors, deploy one sensor time. certain probability, deployed sensors fail,goal maximize area covered functioning sensors. Thus, deployingnext sensor, need take account sensors deployed past failed.problem studied Asadpour, Nazerzadeh, Saberi (2008) casesensor fails independently random. paper, show coverage objectiveadaptive submodular, use concept handle much general settings (where, e.g., ratherall-or-nothing failures different types sensor failures varying severity). alsoconsider related problem goal place minimum number sensors achievemaximum possible sensor coverage (i.e., coverage obtained deploying sensors everywhere),generally goal may achieve fixed percentage maximum possible sensorcoverage. first goal, problem equivalent one studied Goemans Vondrak(2006), generalizes problem studied Liu, Parthasarathy, Ranganathan, Yang (2008).maximum coverage version, adaptive submodularity allows us recover generalizeprevious results.another example, consider viral marketing problem, given social network,want influence many people possible network buy product.giving product free subset people, hope convince friends428fiA DAPTIVE UBMODULARITY: HEORY PPLICATIONSbuy product well. Formally, graph, edge e labeled number0 pe 1. influence subset nodes graph, influenced node,neighbors get randomly influenced according probability annotated edge connectingnodes. process repeats node gets influenced. Kempe, Kleinberg,Tardos (2003) show set function quantifies expected number nodes influencedsubmodular. natural stochastic variant problem pick node, get seenodes influenced, adaptively pick next node based observationson. show large class adaptive influence maximization problems satisfies adaptivesubmodularity.third application active learning, given unlabeled data set,would like adaptively pick small set examples whose labels imply labels.problem arises automated diagnosis, hypotheses state system (e.g.,illness patient has), would like perform tests identify correct hypothesis.domains want pick examples / tests shrink remaining version space (the set consistenthypotheses) quickly possible. Here, show reduction version space probabilitymass adaptive submodular, use observation prove adaptive greedy algorithmnear-optimal querying policy, recovering generalizing results Kosaraju, Przytycka,Borgstrom (1999) Dasgupta (2004). results active learning automated diagnosisalso related recent results Guillory Bilmes (2010, 2011) study generalizationssubmodular set cover interactive setting. contrast approach however, GuilloryBilmes analyze worst-case costs, use rather different technical definitions proof techniques.summarize main contributions below, provide technical summary Table 1.high level, main contributions are:consider particular class partially observable adaptive stochastic optimization problems, prove hard approximate general.introduce concept adaptive submodularity, prove problem instance satisfies property, simple adaptive greedy policy performs near-optimally, adaptivestochastic maximization coverage, also natural min-sum objective.show adaptive submodularity exploited allowing use acceleratedadaptive greedy algorithm using lazy evaluations, obtain data-dependentbounds optimum.illustrate adaptive submodularity several realistic problems, including Stochastic Maximum Coverage, Stochastic Submodular Coverage, Adaptive Viral Marketing, ActiveLearning. applications, adaptive submodularity allows us recover known resultsprove natural generalizations.1.1 Organizationarticle organized follows. 2 (page 430) set notation formally define relevant adaptive optimization problems general objective functions. readers convenience,also provided reference table important symbols page 480. 3 (page 433) review classical notion submodularity introduce novel adaptive submodularity property.429fiG OLOVIN & K RAUSENameA.S. MaximizationNew ResultsTight (1 1/e)-approx. A.M.S. objectivesA.S. Min Cost CoverageTight logarithmic approx. A.M.S. objectivesA.S. Min Sum CoverTight 4-approx. A.M.S. objectivesData Dependent BoundsGeneralization A.M.S. functionsAccelerated GreedyStochastic SubmodularMaximizationStochastic Set CoverGeneralization lazy evaluations adaptive settingGeneralization previous (1 1/e)-approx.arbitrary peritem set distributions, item costsGeneralization previous (ln(n) + 1)-approx.arbitrary per-item set distributions, item costsAdaptive analog previous (1 1/e)-approx. nonadaptive viral marketing, general rewardfunctions; tight logarithmic approx. adaptive mincost cover versionImproved approx. factor generalized binary searchapproximate versions without item costs(|E|1 )-approximation hardness A.S. Maximization, Min Cost Coverage, Min-Sum Cover, fadaptive submodular.Adaptive ViralMarketingActive LearningHardness absenceAdapt. SubmodularityLocation5.1,page 4385.2,page 4405.3,page 4435.1,page 4384, page 4366, page 4457, page 4468, page 4489, page 45412,page 464Table 1: Summary theoretical results. A.S. shorthand adaptive stochastic, A.M.S.shorthand adaptive monotone submodular.4 (page 436) introduce adaptive greedy policy, well accelerated variant. 5(page 438) discuss theoretical guarantees adaptive greedy policy enjoys appliedproblems adaptive submodular objectives. Sections 6 9 provide examplesapply adaptive submodular framework various applications, namely Stochastic SubmodularMaximization (6, page 445), Stochastic Submodular Coverage (7, page 446), Adaptive Viral Marketing (8, page 448), Active Learning (9, page 454). 10 (page 459) report empiricalresults two sensor selection problems. 11 (page 462) discuss adaptivity gapproblems consider, 12 (page 464) prove hardness results indicating problemsadaptive submodular extremely inapproximable reasonable complexityassumptions. review related work 13 (page 465) provide concluding remarks 14(page 467). Appendix (page 468) gives details incorporate item costs includesproofs omitted main text.2. Adaptive Stochastic Optimizationstart introducing notation defining general class adaptive optimization problemsaddress paper. sake clarity, illustrate notation using sensorplacement application mentioned 1. give examples applications 6, 7, 8, 9.430fiA DAPTIVE UBMODULARITY: HEORY PPLICATIONS2.1 Items RealizationsLet E finite set items (e.g., sensor locations). item e E particular (initiallyunknown) state set possible states (describing whether sensor placed location ewould malfunction not). represent item states using function : E O, calledrealization (of states items ground set). Thus, say (e) state erealization . use denote random realization. take Bayesian approachassume known prior probability distribution p () := P [ = ] realizations (e.g.,modeling sensors fail independently failure probability), compute posteriordistributions2 . consider problems sequentially pick item e E, get seestate (e), pick next item, get see state, (e.g., place sensor, see whetherfails, on). pick, observations far represented partial realization, function subset E (i.e., set items already picked) states(e.g., encodes placed sensors failed). notational convenience,sometimes represent relation, E equals {(e, o) : (e) = o}. usenotation dom() = {e : o.(e, o) } refer domain (i.e., set items observed). partial realization consistent realization equal everywheredomain . case write . 0 consistent ,dom() dom( 0 ), say subrealization 0 . Equivalently, subrealization 0if, viewed relations, 0 .Partial realizations similar notion belief states Partially Observable MarkovDecision Problems (POMDPs), encode effect actions taken (items selected)observations made, determine posterior belief state world (i.e., stateitems e yet selected, p ( | ) := P [ = | ]).2.2 Policiesencode adaptive strategy picking items policy , function setpartial realizations E, specifying item pick next particular set observations(e.g., chooses next sensor location given placed sensors far, whetherfailed not). also allow randomized policies functions set partial realizationsdistributions E, though emphasis primarily deterministic policies.domain , policy terminates (stops picking items) upon observation . use dom()denote domain . Technically, require dom() closed subrealizations.is, 0 dom() subrealization 0 dom(). use notationE(, ) refer set items selected realization . deterministic policyassociated decision tree natural way (see Fig. 1 illustration). Here,adopt policy-centric view admits concise notation, though find decision tree viewvaluable conceptually.Since partial realizations similar POMDP belief states, definition policies similarnotion policies POMDPs, usually defined functions belief statesactions. discuss relationship stochastic optimization problemsconsidered paper POMDPs Section 13.2. situations, may exact knowledge prior p (). Obtaining algorithms robustincorrect priors remains interesting source open problems. briefly discuss robustness guaranteesalgorithm 4 page 437.431fiG OLOVIN & K RAUSEFigure 1: Illustration policy , corresponding decision tree representation, decisiontree representation [2] , level 2 truncation (as defined 5.1).2.3 Adaptive Stochastic Maximization, Coverage, Min-Sum Coveragewish maximize, subject constraints, utility function f : 2E OE R0depends items pick state item (e.g., modeling total areacovered working sensors). Based notation, expected utility policyfavg () := E [f (E(, ), )] expectation taken respect p (). goalAdaptive Stochastic Maximization problem find policyarg max favg () subject |E(, )| k ,(2.1)k budget many items picked (e.g., would like adaptively choose ksensor locations working sensors provide much information possible expectation).Alternatively, specify quota Q utility would like obtain, try findcheapest policy achieving quota (e.g., would like achieve certain amount information,cheaply possible expectation). Formally, define average cost cavg () policyexpected number items picks, cavg () := E [|E(, )|]. goal findarg min cavg () f (E(, ), ) Q ,(2.2)i.e., policy minimizes expected number items picked possiblerealizations, least utility Q achieved. call Problem 2.2 Adaptive Stochastic MinimumCost Cover problem. also consider problem want minimize worst-casecost cwc () := max |E(, )|. worst-case cost cwc () cost incurred adversariallychosen realizations, equivalently depth deepest leaf , decision tree associated.Yet another important variant minimize average time required policy obtainutility. Formally, let u(, t) expected utility obtained steps3 , let Q =E [f (E, )] maximumpossible expected utility, define min-sum cost c ()Ppolicy c () := t=0 (Q u(, t)). define Adaptive Stochastic Min-Sum Coverproblem searcharg min c () .(2.3)3. formal definition u(, t), see A.5 page 478.432fiA DAPTIVE UBMODULARITY: HEORY PPLICATIONSP Unfortunately, show 12, even linear functions f , i.e., f (A, ) =eA we, simply sum weights (depending realization ), Problems (2.1), (2.2),(2.3) hard approximate reasonable complexity theoretic assumptions. Despitehardness general problems, following sections identify conditionssufficient allow us approximately solve them.2.4 Incorporating Item CostsInstead quantifying cost set E(, ) number elements |E(, )|, alsoconsidercase item e E cost c(e), cost set E c(S) =Pc(e).consider variants Problems (2.1), (2.2), (2.3) |E(, )|eSreplaced c(E(, )). clarity presentation, focus unit cost case, i.e., c(e) = 1e, explain results generalize non-uniform case Appendix.3. Adaptive Submodularityfirst review classical notion submodular set functions, introduce novel notionadaptive submodularity.3.1 Background SubmodularityLet us first consider special case p () deterministic or, equivalently, |O| = 1(e.g., sensor placement applications, sensors never fail). case, realizationknown decision maker advance, thus benefit adaptive selection. Givenrealization , Problem (2.1) equivalent finding set Earg max f (A, ) |A| k.(3.1)AEinteresting classes utility functions f , NP-hard optimization problem. However, many practical problems, mentioned 1, f (A) = f (A, ) satisfies submodularity. set function f : 2E R called submodular if, whenever B E e E \ Bholdsf (A {e}) f (A) f (B {e}) f (B),(3.2)i.e., adding e smaller set increases f least much adding e superset B.Furthermore, f called monotone, if, whenever B holds f (A) f (B) (e.g., addingsensor never reduce amount information obtained). celebrated result Nemhauseret al. (1978) states monotone submodular functions f () = 0, simple greedy algorithm starts empty set, A0 = choosesAi+1 = Ai {arg max f (Ai {e})}(3.3)eE\Aiguarantees f (Ak ) (1 1/e) max|A|k f (A). Thus, greedy set Ak obtains least (11/e) fraction optimal value achievable using k elements. Furthermore, Feige (1998) showsresult tight P 6= NP; assumption polynomial time algorithm strictlybetter greedy algorithm, i.e., achieve (1 1/e + )-approximation constant > 0,even special case Maximum k-Cover f (A) cardinality union sets433fiG OLOVIN & K RAUSEindexed A. Similarly, Wolsey (1982) shows greedy algorithm also near-optimallysolves deterministic case Problem (2.2), called Minimum Submodular Cover problem:arg min |A| f (A) Q.(3.4)AEPick first set A` constructed greedy algorithm f (A` ) Q. Then, integervalued submodular functions, ` |A |(1 + log maxe f (e)), i.e., greedy setlogarithmic factor larger smallest set achieving quota Q. special case Set Cover,f (A) cardinality union sets indexed A, result matches lower boundFeige (1998): Unless NP DTIME(nO(log log n) ), Set Cover hard approximate factorbetter (1 ) ln Q, Q number elements covered.let us relax assumption p () deterministic. case, may still wantfind non-adaptive solution (i.e., constant policy always picks set independently) maximizing favg (A ). f pointwise submodular, i.e., f (A, ) submodularfixed , function f (A) = favg (A ) submodular, since nonnegative linear combinationssubmodular functions remain submodular. Thus, greedy algorithm allows us find nearoptimal non-adaptive policy. is, sensor placement example, willing commitlocations finding whether sensors fail not, greedy algorithm providegood solution non-adaptive problem.However, practice, may interested obtaining non-constant policy ,adaptively chooses items based previous observations (e.g., takes account sensorsworking placing next sensor). many settings, selecting items adaptively offers hugeadvantages, analogous advantage binary search sequential (linear) search4 . Thus,question whether natural extension submodularity policies. following,develop notion adaptive submodularity.3.2 Adaptive Monotonicity Submodularitykey challenge find appropriate generalizations monotonicity diminishingreturns condition (3.2). begin considering special case p () deterministic, policies non-adaptive. case policy simply specifies sequence items (e1 , e2 , . . . , er ) selects order. Monotonicity contextcharacterized property marginal benefit selecting item always nonnegative, meaning sequences (e1 , e2 , . . . , er ), items e 1 r holdsf ({ej : j i} {e}) f ({ej : j i}) 0. Similarly, submodularity viewedproperty selecting item later never increases marginal benefit, meaningsequences (e1 , e2 , . . . , er ), items e, r, f ({ej : j i} {e}) f ({ej : j i})f ({ej : j r} {e}) f ({ej : j r}).take views monotonicity submodularity defining adaptive analogues,using appropriate generalization marginal benefit. moving general adaptivesetting, challenge items states random revealed upon selection.natural approach thus condition observations (i.e., partial realizations selected items),take expectation respect items consider selecting. Hence, define4. provide wellknown example active learning illustrates phenomenon crisply 9; see Fig. 4page 454. consider general question magnitude potential benefits adaptivity 11 page 462.434fiA DAPTIVE UBMODULARITY: HEORY PPLICATIONSadaptive monotonicity submodularity properties terms conditional expected marginalbenefit item.Definition 3.1 (Conditional Expected Marginal Benefit). Given partial realizationitem e, conditional expected marginal benefit e conditioned observed , denoted(e | ),fififi(e | ) := E f (dom() {e} , ) f (dom(), ) fi(3.5)expectation computed respect p ( | ) = P [ = | ]. Similarly,conditional expected marginal benefit policyfififi( | ) := E f (dom() E(, ), ) f (dom(), ) fi .(3.6)sensor placement example, (e | ) quantifies expected amount additional area covered placing sensor location e, expectation posterior distribution p(e) (o) :=P [(e) = | ] whether sensor fail not, taking account area covered placed working sensors encoded . Note benefit accrued uponobserving (and hence selected items dom()) E [f (dom(), ) | ],benefit term subtracted Eq. (3.5) Eq. (3.6). Similarly, expected totalbenefit obtained observing selecting e E [f (dom() {e} , ) | ].corresponding benefit running observing slightly complex. realization, final cumulative benefit f (dom() E(, ), ). Taking expectationrespect p ( | ) subtracting benefit already obtained dom() yieldsconditional expected marginal benefit .ready introduce generalizations monotonicity submodularityadaptive setting:Definition 3.2 (Adaptive Monotonicity). function f : 2E OE R0 adaptive monotonerespect distribution p () conditional expected marginal benefit item nonnegative,i.e., P [ ] > 0 e E(e | ) 0.(3.7)Definition 3.3 (Adaptive Submodularity). function f : 2E OE R0 adaptive submodularrespect distribution p () conditional expected marginal benefit fixed itemincrease items selected states observed. Formally, f adaptivesubmodular w.r.t. p () 0 subrealization 0 (i.e., 0 ),e E \ dom( 0 ),(e | ) e | 0 .(3.8)decision tree perspective, condition (e | ) (e | 0 ) amounts sayingdecision tree , node v selects item e, compare expectedmarginal benefit e selected v expected marginal benefit e would obtainedselected ancestor v , latter must smaller former. Notecomparing two expected marginal benefits, difference set435fiG OLOVIN & K RAUSEitems previously selected (i.e., dom() vs. dom( 0 )) distribution realizations (i.e.,p ( | ) vs. p ( | 0 )). also worth emphasizing adaptive submodularity defined relativedistribution p () realizations; possible f adaptive submodular respectone distribution, respect another.give concrete examples adaptive monotone adaptive submodular functionsarise applications introduced 1 6, 7, 8, 9. Appendix, explainnotion adaptive submodularity extended handle non-uniform costs (since, e.g.,cost placing sensor easily accessible location may smaller locationhard get to).3.3 Properties Adaptive Submodular Functionsseen adaptive monotonicity adaptive submodularity enjoy similar closure properties monotone submodular functions. particular, w1 , . . . , wm P0 f1 , . . . , fmadaptive monotone submodular w.r.t. distribution p (), f (A, ) =i=1 wi fi (A, ) adaptive monotone submodular w.r.t. p (). Similarly, fixed constant c 0 adaptive monotonesubmodular function f , function g(E, ) = min(f (E, ), c) adaptive monotone submodular. Thus, adaptive monotone submodularity preserved nonnegative linear combinationstruncation. Adaptive monotone submodularity also preserved restriction,f : 2E OE R0 adaptive monotone submodular w.r.t. p (), e E, function g : 2E\{e} OE R0 defined g(A, ) := f (A, ) E \ {e} alsoadaptive submodular w.r.t. p (). Finally, f : 2E OE R0 adaptive monotone submodularw.r.t. p () partial realization conditional function g(A, ) := f (Adom(), )adaptive monotone submodular w.r.t. p ( | ) := P [ = | ].3.4 Problem Characteristics Suggest Adaptive Submodularity?Adaptive submodularity diminishing returns property policies. Speaking informally,applied situations objective function optimized feature synergies benefits items conditioned observations. cases, primary objective mightproperty, suitably chosen proxy does, case active learningpersistent noise (Golovin, Krause, & Ray, 2010; Bellala & Scott, 2010). give example applications 6 9. also worth mentioning adaptive submodularity directlyapplicable. extreme example synergistic effects items conditioned observationsclass treasure hunting instances used prove Theorem 12.1 page 464, (binary) state certain groups items encode treasures location complex manner. Anotherproblem feature adaptive submodularity directly address possibility itemsselection alter underlying realization , case problem optimizing policiesgeneral POMDPs.4. Adaptive Greedy Policyclassical non-adaptive greedy algorithm (3.3) natural generalization adaptive setting. greedy policy greedy tries, iteration, myopically increase expected objectivevalue, given current observations. is, suppose f : 2E OE R0 objective,partial realization indicating states items selected far. greedy policy436fiA DAPTIVE UBMODULARITY: HEORY PPLICATIONSselect item e maximizing expected increase value, conditioned observed statesitems already selected (i.e., conditioned ). is, select e maximizeconditional expected marginal benefit (e | ) defined Eq. (3.5). Pseudocode adaptivegreedy algorithm given Algorithm 1. difference classic, non-adaptive greedyalgorithm studied Nemhauser et al. (1978), Line 6, observation (e ) selecteditem e obtained. Note algorithms section presented Adaptive StochasticMaximization. coverage objectives, simply keep selecting items prescribed greedyachieving quota objective value (for min-cost objective) selectedevery item (for min-sum objective).4.1 Incorporating Item Costsadaptive greedy algorithm naturally modified handle non-uniform item costs replacing selection rule(e | )e arg max.c(e)efollowing, focus uniform cost case (c 1), defer analysis costsAppendix.4.2 Approximate Greedy Selectionapplications, finding item maximizing (e | ) may computationally intractable,best find -approximation best greedy selection. means finde01e0 | max (e | ) .ecall policy always selects item -approximate greedy policy.123456Input: Budget k; ground set E; distribution p (); function f .Output: Set E size kbegin; ;= 1 kforeach e E \ compute (e | ) = E [f (A {e} , ) f (A, ) | ] ;Select e arg maxe (e | );Set {e };Observe (e ); Set {(e , (e ))};endAlgorithm 1: adaptive greedy algorithm, implements greedy policy.4.3 Robustness & Approximate Greedy Selectionshow, -approximate greedy policies performance guarantees several problems.fact performance guarantees greedy policies robust approximate greedyselection suggests particular robustness guarantee incorrect priors p (). Specifically,incorrect prior p0 evaluate (e | ) err multiplicative factor437fiG OLOVIN & K RAUSE, compute greedy policy respect p0 actually implementing-approximate greedy policy (with respect true prior), hence obtain correspondingguarantees. example, sufficient condition erring multiplicative factorexists c 1 1 = d/c c p () p0 () p () ,p true prior.4.4 Lazy Evaluations Accelerated Adaptive Greedy Algorithmdefinition adaptive submodularity allows us implement accelerated versionadaptive greedy algorithm using lazy evaluations marginal benefits originally suggestednon-adaptive case Minoux (1978). idea follows. Suppose run greedyfixed realization , select items e1 , e2 , . . . , ek . Let := {(ej , (ej ) : j i)}partial realizations observed run greedy . adaptive greedy algorithm computes(e | ) e E 0 < k, unless e dom( ). Naively, algorithm thus needscompute (|E|k) marginal benefits (which expensive compute). key insight7 (e | ) nonincreasing e E, adaptive submodularityobjective. Hence, deciding item select ei know (e0 | j ) (e | )items e0 e j < i, may conclude (e0 | ) (e | ) hence eliminateneed compute (e0 | ). accelerated version adaptive greedy algorithm exploitsobservation principled manner, computing (e | ) items e decreasing orderupper bounds known them, finds item whose value least great upperbounds items. Pseudocode version adaptive greedy algorithm givenAlgorithm 2.non-adaptive setting, use lazy evaluations shown significantly reducerunning times practice (Leskovec et al., 2007). evaluated naive accelerated implementations adaptive greedy algorithm two sensor selection problems, obtained speedupfactors range roughly 4 40 problems. See 10 page 459 details.5. Guarantees Greedy Policysection show objective function adaptive submodular respectprobabilistic model environment operate, greedy policy inherits precisely performance guarantees greedy algorithm classic (non-adaptive) submodularmaximization submodular coverage problems, Maximum k-Cover Minimum SetCover, well min-sum submodular coverage problems, Min-Sum Set Cover. fact,show holds true generally: approximate greedy policies inherit preciselyperformance guarantees approximate greedy algorithms classic problems.guarantees suggest adaptive submodularity appropriate generalization submodularitypolicies. section focus unit cost case (i.e., every item cost).Appendix provide proofs omitted section, show results extendnon-uniform item costs greedily maximize expected benefit/cost ratio.5.1 Maximum Coverage Objectivesection consider maximum coverage objective, goal select k itemsadaptively maximize expected value. task maximizing expected value subject438fiA DAPTIVE UBMODULARITY: HEORY PPLICATIONSInput: Budget k; ground set E; distribution p (); function f .Output: Set E size kbegin; ; Priority Queue Q EMPTY QUEUE;12foreach e E Q. insert(e, +);3= 1 k4max ; emax NULL;5max < Q. maxPriority( )6e Q. pop( );7(e | ) = E [f (A {e} , ) f (A, ) | ];8Q. insert(e, );9max <10max ; emax e;11{emax }; Q. remove(emax );12Observe (emax ); Set {(emax , (emax ))};endAlgorithm 2: accelerated version adaptive greedy algorithm. Here, Q. insert(e, )inserts e priority , Q. pop( ) removes returns item greatest priority,Q. maxPriority( ) returns maximum priority elements Q, Q. remove(e)deletes e Q.complex constraints, matroid constraints intersections matroid constraints,considered work Golovin Krause (2011). stating result, requirefollowing definition.Definition 5.1 (Policy Truncation). policy , define level-k-truncation [k]policy obtained running terminates selects k items, terminating.Formally, dom([k] ) = { dom() : || < k}, [k] () = () dom([k] ).following result, generalizes classic result work Nemhauser et al.(1978) greedy algorithm achieves (1 1/e)-approximation problem maximizingmonotone submodular functions cardinality constraint. setting ` = k = 1Theorem 5.2, see greedy policy selects k items adaptively obtains least (11/e)value optimal policy selects k items adaptively, measured respect favg .proof see Theorem A.10 Appendix A.3, generalizes Theorem 5.2 nonuniform item costs.Theorem 5.2. Fix 1. f adaptive monotone adaptive submodular respectdistribution p (), -approximate greedy policy, policies positiveintegers ` k,favg ([`] ) > 1 e`/k favg ([k]).particular, ` = k implies -approximate greedy policy achieves 1 e1/approximation expected reward best policy, terminated runningequal number steps.greedy rule implemented small absolute error rather small relativeerror, i.e., (e0 | ) maxe (e | ) , argument similar used prove Theorem 5.2439fiG OLOVIN & K RAUSEshows) `.favg ([`] ) 1 e`/k favg ([k]important, since small absolute error always achieved (with high probability) whenever f evaluated efficiently, sampling p ( | ) efficient. case, approximateN1 X(e | )f (dom() {e} , ) f (dom(), ) ,Ni=1sampled i.i.d. p ( | ).5.1.1 DATA EPENDENT B OUNDSmaximum coverage objective, adaptive submodular functions another attractive feature:allow us obtain data dependent bounds optimum, manner similar boundsnon-adaptive case (Minoux, 1978). Consider non-adaptive problem maximizingmonotone submodular function f : 2A R0 subject constraint |A| k. Letoptimal solution, fix E.Xf (A ) f (A) + max(f (A {e}) f (A))(5.1)B:|B|keBPsetting B = f (A ) f (A B) f (A) + eBP(f (A {e}) f (A)). Noteunlike original objective, easily compute maxB:|B|k eB (f (A {e}) f (A))computing (e) := f (A {e}) f (A) e, summing k largest values. Hencequickly compute upper bound distance optimal value, f (A ) f (A).practice, data-dependent bounds much tighter problem-independent performance guarantees Nemhauser et al. (1978) greedy algorithm (Leskovec et al., 2007).note bounds hold set A, sets selected greedy algorithm.data dependent bounds following analogue adaptive monotone submodularfunctions. See Appendix A.2 proof.Lemma 5.3 (The Adaptive Data Dependent Bound). Suppose made observationsselecting dom(). Let policy |E( , )| k . adaptivemonotone submodular fX( | )max(e | ) .(5.2)AE,|A|keAThus, running policy , efficiently compute bound additional benefitoptimal solution could obtain beyond reward . computingconditional expected marginal benefits elements e, summing k largest them. Notebounds computed fly running greedy algorithm, similarmanner discussed Leskovec et al. (2007) non-adaptive setting.5.2 Min Cost Cover ObjectiveAnother natural objective minimize number items selected ensuring sufficientlevel value obtained. leads Adaptive Stochastic Minimum Cost Coverage problemdescribed 2, namely arg min cavg () f (E(, ), ) Q . Recall440fiA DAPTIVE UBMODULARITY: HEORY PPLICATIONScavg () expected cost , unit cost case equals expected number itemsselected , i.e., cavg () := E [|E(, )|]. objective adaptive monotone submodular,adaptive version Minimum Submodular Cover problem (described line (3.4)3.1). Recall greedy algorithm known give (ln(Q) + 1)-approximation MinimumSubmodular Cover assuming coverage function integer-valued addition monotonesubmodular (Wolsey, 1982). Adaptive Stochastic Minimum Cost Coverage also related(Noisy) Interactive Submodular Set Cover problem studied Guillory Bilmes (2010, 2011),considers worst-case setting (i.e., distribution states; instead statesrealized adversarial manner). Similar results active learning proved Kosarajuet al. (1999) Dasgupta (2004), discuss detail 9.assume throughout section exists quality threshold Q f (E, ) = Q, E , f (S, ) Q. Note that, discussed Section 3,replace f (S, ) new function g(S, ) = min(f (S, ), Q0 ) constant Q0 , gadaptive submodular f is. Thus, f (E, ) varies across realizations, instead usegreedy algorithm function truncated threshold Q0 min f (E, ) achievablerealizations.contrast Adaptive Stochastic Maximization, coverage problem additional subtletiesarise. particular, enough policy achieves value Q true realization; orderterminate, also requires proof fact. Formally, require covers f :Definition 5.4 (Coverage). Let = (, ) partial realization encoding states observedexecution realization . Given f : 2E OE R, say policy coversrespect f f (dom(), 0 ) = f (E, 0 ) 0 . say covers f coversevery realization respect f .Coverage defined way upon terminating, might know realizationtrue one, guaranteed achieved maximum reward every possible case(i.e., every realization consistent observations). obtain results averageworst-case cost objectives.5.2.1 INIMIZING AVERAGE C OSTpresenting approximation guarantee Adaptive Stochastic Minimum Cost Coverage, introduce special class instances, called selfcertifying instances. makedistinction greedy policy stronger performance guarantees selfcertifying instances, instances arise naturally applications. example, Stochastic SubmodularCover Stochastic Set Cover instances 7, Adaptive Viral Marketing instances 8,Pool-Based Active Learning instances 9 selfcertifying.Definition 5.5 (SelfCertifying Instances). instance Adaptive Stochastic Minimum Cost Coverage selfcertifying whenever policy achieves maximum possible value truerealization immediately proof fact. Formally, instance (f, p ()) selfcertifying, 0 , 0 , f (dom(), ) = f (E, )f (dom(), 0 ) = f (E, 0 ).One class selfcertifying instances commonly arise f (A, ) dependsstate items A, uniform maximum amount rewardobtained across realizations. Formally, following observation.441fiG OLOVIN & K RAUSEProposition 5.6. Fix instance (f, p ()). exists Q f (E, ) = Qexists g : 2EO R0 f (A, ) = g ({(e, (e)) : e A}) ,(f, p ()) selfcertifying.Proof. Fix , 0 , 0 . Assuming existence g treatingrelation, f (dom(), ) = g() = f (dom(), 0 ). Hence f (dom(), ) = Q = f (E, )f (dom(), 0 ) = Q = f (E, 0 ).results minimum cost coverage, also need stronger monotonicity condition:Definition 5.7 (Strong Adaptive Monotonicity). function f : 2E OE R strongly adaptivemonotone respect p () if, informally selecting items never hurts respectexpected reward. Formally, , e/ dom(), possible outcomesP [(e) = | ] > 0, requireE [f (dom(), ) | ] E [f (dom() {e} , ) | , (e) = o] .(5.3)Strong adaptive monotonicity implies adaptive monotonicity, latter means selectingitems never hurts expectation, i.e.,E [f (dom(), ) | ] E [f (dom() {e} , ) | ] .state main result average case cost cavg ():Theorem 5.8. Suppose f : 2E OE R0 adaptive submodular strongly adaptive monotone respect p () exists Q f (E, ) = Q . Let valuef (S, ) > Q implies f (S, ) = Q . Let = min p () mini optimal policy minimizing expected numbermum probability realization. Let avgitems selected guarantee every realization covered. Let -approximate greedy policy.generalQcavg () cavg (avg ) ln+1selfcertifying instancescavg ()cavg (avg)lnQ+1 .Note range(f ) Z, = 1 valid choice, general selfcertifying) (ln(Q/) + 1) cinstances cavg () cavg (avgavg () cavg (avg ) (ln(Q) + 1),respectively.5.2.2 INIMIZING W ORST-C ASE C OSTworst-case cost cwc () := max |E(, )|, strong adaptive monotonicity required;adaptive monotonicity suffices. obtain following result.Theorem 5.9. Suppose f : 2E OE R0 adaptive monotone adaptive submodularrespect p (), let value f (S, ) > f (E, ) implies f (S, ) = f (E, ). Let = min p () minimum probability realization. Let wc442fiA DAPTIVE UBMODULARITY: HEORY PPLICATIONSoptimal policy minimizing worst-case number queries guarantee every realizationcovered. Let -approximate greedy policy. Finally, let Q := E [f (E, )] maximumpossible expected reward.Q+1 .cwc () cwc (wc ) lnproofs Theorems 5.8 5.9 given Appendix A.4.Thus, even though adaptive submodularity defined w.r.t. particular distribution, perhapssurprisingly, adaptive greedy algorithm competitive even case adversarially chosenrealizations, policy optimized minimize worst-case cost. Theorem 5.9 thereforesuggests strong prior, obtain strongest guarantees choosedistribution uniform possible (i.e., maximizes ) still guaranteeing adaptivesubmodularity.5.2.3 ISCUSSIONNote approximation factor selfcertifying instances Theorem 5.8 reduces(ln(Q) + 1)-approximation guarantee greedy algorithm Set Cover instances Qelements, case deterministic distribution p (). Moreover, deterministic distribution p () distinction average-case worst-case cost. Hence, immediate corollary result Feige (1998) mentioned 3 every constant > 0polynomial time (1 ) ln (Q/) approximation algorithm selfcertifying instancesAdaptive Stochastic Min Cost Cover, either cavg () cwc () objective, unlessNP DTIME(nO(log log n) ). remains open determine whether Adaptive StochasticMin Cost Cover worst-case cost objective admits ln (Q/) + 1 approximation selfcertifying instances via polynomial time algorithm, particular whether greedy policy approximation guarantee. However, Lemma A.14 show Feiges resultalso implies (1 ) ln (Q/) polynomial time approximation algorithm general(non self-certifying) instances Adaptive Stochastic Min Cost Cover either objective, unlessNP DTIME(nO(log log n) ). sense, three results comprising Theorem 5.8Theorem 5.9 best-possible reasonable complexity-theoretic assumptions. showSection 9, result average-case cost greedy policies selfcertifying instancesalso matches (up constant factors) results hardness approximating optimal policyspecial case active learning, also known Optimal Decision Tree problem.5.3 Min-Sum Cover ObjectiveYet another natural objective min-sum objective, unrealized reward x incurscost x time step, goal minimize total cost incurred.5.3.1 BACKGROUND N - ADAPTIVE -S UM C P ROBLEMnon-adaptive setting, perhaps simplest form coverage problem objectiveMin-Sum Set Cover problem (Feige, Lovasz, & Tetali, 2004) input set system(U, S), output permutation sets hS1 , S2 , . . . , Sm i, goal minimize sumelement coverage times, coverage time u index first set contains(e.g., j u Sj u/ Si < j). problem generalizations443fiG OLOVIN & K RAUSEmin-sum objective useful modeling processing costs certain applications, exampleordering diagnostic tests identify disease cheaply (Kaplan, Kushilevitz, & Mansour, 2005),ordering multiple filters applied database records processing query (Munagala,Babu, Motwani, Widom, & Thomas, 2005), ordering multiple heuristics run booleansatisfiability instances means solve faster practice (Streeter & Golovin, 2008).particularly expressive generalization min-sum set cover studied names MinSum Submodular Cover (Streeter & Golovin, 2008) L1 -Submodular Set Cover (Golovin, Gupta,Kumar, & Tangwongsan, 2008). former paper extends greedy algorithm natural onlinevariant problem, latter studies parameterized family Lp -Submodular Set Coverproblems objective analogous minimizing Lp norm coverage timesMin-Sum Set Cover instances. Min-Sum Submodular Cover problem, monotonesubmodular function f : 2E R0 defining reward obtained collection elements5 .integral cost c(e) element, output sequence elements= he1 , e2 , . . . , en i. R0 , define set elements sequence withinbudget t:X[t] := ei :c(ej ) .jicost wish minimizec () :=Xf (E) f ([t] ) .(5.4)t=0Feige et al. (2004) proved Min-Sum Set cover, greedy algorithm achieves 4-approximationminimum cost, also optimal sense polynomial time algorithmachieve (4 )-approximation, > 0, unless P = NP. Interestingly, greedy algorithm also achieves 4-approximation general Min-Sum Submodular Cover problemwell (Streeter & Golovin, 2008; Golovin et al., 2008).5.3.2 DAPTIVE TOCHASTIC -S UM C P ROBLEMarticle, extend result Streeter Golovin (2008) Golovin et al. (2008)adaptive version Min-Sum Submodular Cover. claritys sake consider unit-costcase (i.e., c(e) = 1 e); show extend adaptive submodularity handle generalcosts Appendix. adaptive version problem, [t] plays role [t] , favgplays role f . goal find policy minimizingc () :=Xt=0XXE [f (E, )] favg ([t] ) =p ()f (E, ) f (E([t] , ), ) .(5.5)t=0call problem Adaptive Stochastic Min-Sum Cover problem. key differenceobjective minimum cost cover objective here, cost stepfractional extent covered true realization, whereas minimum cost coverobjective charged full step completely covered true realization5. encode Min-Sum Set Cover instance (U, S), let E := f (A) := | eA e|, e E subsetelements U .444fiA DAPTIVE UBMODULARITY: HEORY PPLICATIONS(according Definition 5.4). prove following result Adaptive Stochastic Min-SumCover problem arbitrary item costs Appendix A.5.Theorem 5.10. Fix 1. f adaptive monotone adaptive submodular respectdistribution p (), -approximate greedy policy respect item costs,policy, c () 4 c ( ).6. Application: Stochastic Submodular Maximizationfirst application, consider sensor placement problem introduced 1. Supposewould like monitor spatial phenomenon temperature building. discretizeenvironment set E locations. would like pick subset E k locationsinformative, use set function f(A) quantify informativeness placementA. Krause Guestrin (2007) show many natural objective functions (such reductionpredictive uncertainty measured terms Shannon entropy conditionally independentobservations) monotone submodular.consider problem, informativeness sensor unknown deployment (e.g., deploying cameras surveillance, location objects associatedocclusions may known advance, varying amounts noise may reduce sensingrange). model extension assigning state (e) possible location, indicating extent sensor placed location e working. quantify valueset sensor deployments realization indicating extent various sensorsworking, first define (e, o) e E O, represents placementsensor location e state o. suppose function f : 2EO R0quantifies informativeness set sensor deployments arbitrary states. (Note fset function taking set (sensor deployment, state) pairs input.) utility f (A, ) placingsensors locations realizationf (A, ) := f({(e, (e)) : e A}).aim adaptively place k sensors maximize expected utility. Qassume sensorfailures location independent other, i.e., P [ = ] = eE P [(e) = (e)] ,P [(e) = o] probability sensor placed location e state o. Asadpouret al. (2008) studied special case problem, sensors either fail completely (incase contribute value all) work perfectly, name Stochastic Submodular Maximization. proved adaptive greedy algorithm obtains (1 1/e) approximationoptimal adaptive policy, provided f monotone submodular. extend result multipletypes failures showing f (A, ) adaptive submodular respect distribution p ()invoking Theorem 5.2. Fig. 2 illustrates instance Stochastic Submodular Maximization f (A, ) cardinality union sets index parameterized .QTheorem 6.1. Fix prior P [ = ] = eE P [(e) = (e)] integer k, letobjective function f : 2EO R0 monotone submodular. Let -approximategreedy policy attempting maximize f , let policy. positive integers `,favg ([`] ) 1 e`/k favg ([k]).).particular, greedy policy (i.e., = 1) ` = k, favg ([k] ) 1 1e favg ([k]445fiG OLOVIN & K RAUSEProof. prove Theorem 6.1 first proving f adaptive monotone adaptive submodularmodel, applying Theorem 5.2. Adaptive monotonicity readily proved observingf (, ) monotone . Moving adaptive submodularity, fix , 00 e/ dom( 0 ). aim show (e | 0 ) (e | ). Intuitively, clear,(e | 0 ) expected marginal benefit adding e larger base set case(e | ), namely dom( 0 ) compared dom(), realizations independent. proverigorously, define coupled distribution pairs realizations0 0Q(e0 ) = 0 (e0 ) e0/ dom( 0 ). Formally, (, 0 ) = eE\dom() P [(e) = (e)]000, , (e ) = 0 (e0 ) e0/ dom( 0 ); otherwise (, 0 ) = 0. (Note000(, 0 ) > 0 implies (e0 ) = 0 (e0 )sinceP e 0dom() as0 well,P ,0 ,00.) Also note p ( | ) =0 (, ) p ( | ) =(, ). Calculating(e | 0 ) (e | ) using , see (, 0 ) support ,f (dom( 0 ) {e} , 0 ) f (dom( 0 ), 0 ) = f( 0 (e, 0 (e)) ) f( 0 ))f( {(e, (e))}) f())= f (dom() {e} , ) f (dom(), )submodularity f. HenceP00000(e | 0 ) =(,0 ) (, ) (f (dom( ) {e} , ) f (dom( ), ))P0= (e | )(,0 ) (, ) (f (dom() {e} , ) f (dom(), ))completes proof.7. Application: Stochastic Submodular CoverageSuppose instead wishing adaptively place k unreliable sensors maximize utilityinformation obtained, discussed 6, quota utility wish adaptively placeminimum number unreliable sensors achieve quota. amounts minimum-costcoverage version Stochastic Submodular Maximization problem introduced 6,call Stochastic Submodular Coverage.6, Stochastic Submodular Coverage problem suppose functionf : 2EO R0 quantifies utility set sensorsarbitrary states. Also,Qstates sensor independent, P [ = ] = eE P [(e) = (e)]. goalobtainquota Q utilitynminimum cost. Thus, define objective f (A, ) :=min Q, f ({(e, (e)) : e A}) , want find policy covering every realization minimizing cavg () := E [|E(, )|]. additionally assume quota always obtainedusing sufficiently many sensor placements; formally, amounts f (E, ) = Q .obtain following result, whose proof defer end section.QTheorem 7.1. Fix prior independent sensor states P [ = ] = eE P [(e) = (e)],EO R0 monotone submodular function. Fix Q R0 f (A, ) :=letf :2min Q, f({(e, (e)) : e A}) satisfies f (E, ) = Q . Let valuef (S, ) > Q implies f (S, ) = Q . Finally, let -approximate greedy446fiA DAPTIVE UBMODULARITY: HEORY PPLICATIONSFigure 2: Illustration part Stochastic Set Cover instance. Shown supports twodistributions sets, indexed items e (marked blue) e0 (yellow).policy maximizing f , let policy.Qcavg () cavg ( ) ln+1 .7.1 Special Case: Stochastic Set Coverage ProblemStochastic Submodular Coverage problem generalization Stochastic Set Coverageproblem (Goemans & Vondrak, 2006). Stochastic Set Coverage underlying submodular objective f number elements covered input set system. words,ground set U n elements covered, items E item e associateddistribution subsets U . item selected, set sampled distribution,illustrated Fig. 2. problem adaptively select items elements U coveredsampled sets, minimizing expected number items selected. Like us, GoemansVondrak also assume subsets sampled independently item, every elementU covered every realization, f (E, ) = |U | .Goemans Vondrak primarily investigated adaptivity gap (quantifying much adaptivepolicies outperform non-adaptive policies) Stochastic Set Coverage, variantsitems repeatedly selected not, prove adaptivity gaps (log n) former case,(n) O(n2 ) latter. also provide n-approximation algorithm.recently, Liu et al. (2008) considered special case Stochastic Set Coverage itemmay one two states. motivated streaming database problem,collection queries sharing common filters must evaluated stream element.transform problem Stochastic Set Coverage instance (filter, query) pairscovered filter evaluations; pairs covered filter depends (binary) outcomeevaluating stream element. resulting instances satisfy assumption everyelement U covered every realization. study, among algorithms, adaptivegreedy algorithm specialized thisQsetting, show subsets arePsampled independentlyitem, P [ = ] = e P [(e) = (e)], Hn := nx=1 x1 approximation.(Recall ln(n) Hn ln(n) + 1 n 1.) Moreover, Liu et al. report empiricallyoutperforms number algorithms experiments.447fiG OLOVIN & K RAUSEadaptive submodularity framework allows us recover Liu et al.s result, generalizericher item distributions subsets U , corollary Theorem 7.1. Specifically,obtain (ln(n)+1)-approximation Stochastic Set Coverage problem, n := |U |,matches approximation ratio greedy algorithm classical Set Cover Stochastic SetCoverage generalizes. Like Liu et al.s result, result tight NP * DTIME(nO(log log n) ),since matches Feiges lower bound (1 ) ln n approximability Set Coverassumption (Feige, 1998).model Stochastic Set Coverage problem letting (e) U indicate randomsetsampledes distribution. Since sampled sets independent P [ = ] =QP[(e)=(e)]. E let f (A, ) := | eA (e)| number elements Uecovered sets sampled items A. previous work mentioned above, assumef (E, ) = n . Therefore may set Q = n. Since range f includes integers,may set = 1. Applying Theorem 7.1 yields following result.Corollary 7.2. adaptive greedy algorithm achieves (ln(n) + 1)-approximation StochasticSet Coverage, n := |U | size ground set.provide proof Theorem 7.1.Proof Theorem 7.1: ultimately prove Theorem 7.1 applying bound Theorem 5.8 selfcertifying instances. proof mostly consists justifying final step.Withoutn lossgenerality may assume f truncated Q, otherwise may use g(S) =min Q, f(S) lieu f. removes need truncate f . Since established adaptivesubmodularity f proof Theorem 6.1, assumption f (E, ) = Q , applyTheorem 5.8 need show f strongly adaptive monotone, instancesconsideration selfcertifying.begin showing strong adaptive monotonicity f . Fix partial realization , iteme/ dom() state o. Let 0 = {(e, o)}. treating 0 subsets E O,using monotonicity f, obtainE [f (dom(), ) | ] = f() f( 0 ) E f (dom( 0 ), ) | 0 ,equivalent strong adaptive monotonicity condition.Next prove instances selfcertifying. Consider , 0 consistent.f (dom(), ) = f() = f (dom(), 0 ).Since f (E, ) = f (E, 0 ) = Q assumption, follows f (dom(), ) = f (E, ) ifff (dom(), 0 ) = f (E, 0 ), instance selfcertifying.shown f p () satisfy assumptions Theorem 5.8 selfcertifyinginstance. Hence may apply obtain claimed approximation guarantee.8. Application: Adaptive Viral Marketingnext application, consider following scenario. Suppose would like generate demand genuinely novel product. Potential customers realize valuable newproduct them, conventional advertisements failing convince try it.448fiA DAPTIVE UBMODULARITY: HEORY PPLICATIONSFigure 3: Illustration Adaptive Viral Marketing problem. Left: underlying social network.Middle: people influenced observations obtained one person selected.case, may try spur demand offering special promotional deal select people,hope demand builds virally, propagating social network people recommendproduct friends associates. Supposing know something structuresocial networks people inhabit, ideas, innovation, new product adoption diffusethem, begs question: initial set people offer promotionaldeal, order spur maximum demand product?This, broadly, viral marketing problem. problem arises context spreading technological, cultural, intellectual innovations, broadly construed. interest unifiedterminology follow Kempe et al. (2003) talk spreading influence social network, say people active adopted idea innovation question,inactive otherwise, influences b convinces b adopt idea innovation question.many ways model diffusion dynamics governing spread influencesocial network. consider basic well-studied model, independent cascade model,described detail below. model Kempe et al. (2003) obtain interesting result;show eventual spread influence f (i.e., ultimate number customers demandproduct) monotone submodular function seed set people initially selected. This,conjunction results Nemhauser et al. (1978) implies greedy algorithm obtainsleast 1 1e value best feasible seed set size k, i.e., arg maxS:|S|k f (S),interpret k budget promotional campaign. Though Kempe et al. considermaximum coverage version viral marketing problem, result conjunctionWolsey (1982) also implies greedy algorithm obtain quota Q value costln(Q) + 1 times cost optimal set arg minS {c(S) : f (S) Q} f takesintegral values.8.1 Adaptive Viral Marketingviral marketing problem natural adaptive analog. Instead selecting fixed setpeople advance, may select person offer promotion to, make observations449fiG OLOVIN & K RAUSEresulting spread demand product, repeat. See Fig. 3 illustration. 8.2,use idea adaptive submodularity obtain results analogous Kempe et al.(2003)adaptive setting. Specifically, show greedy policy obtains least 1 1evalue best policy. Moreover, extend result achieving guaranteecase reward simply number influenced people, also (nonnegative)monotone submodular function set people influenced. 8.3 consider minimumcost cover objective, show greedy policy obtains logarithmic approximation it.knowledge, approximation results adaptive variant viral marketing problemknown.8.1.1 NDEPENDENT C ASCADE ODELmodel, social network directed graph G = (V, A) vertex Vperson, edge (u, v) associated binary random variable Xuv indicating uinfluence v. is, Xuv = 1 u influence v influenced, Xuv = 0otherwise. random variables Xuv independent, known means puv := E [Xuv ].call edge (u, v) Xuv = 1 live edge edge Xuv = 0 dead edge.node u activated, edges Xuv neighbor v u sampled, v activated (u, v)live. Influence spread us neighbors neighbors, on, accordingprocess. active, nodes remain active throughout process, however Kempe et al.(2003) show assumption without loss generality, removed.8.1.2 F EEDBACK ODELAdaptive Viral Marketing problem independent cascades model, items correspond people activate offering promotional deal. define states(u) depends information obtain result activating u. Given naturediffusion process, activating u wide-ranging effects, state (u)state social network whole u particular. Specifically, model(u) function u : {0, 1, ?}, u ((u, v)) = 0 means activating u revealed (u, v) dead, u ((u, v)) = 1 means activating u revealed (u, v) live,u ((u, v)) = ? means activating u revealed status (u, v) (i.e., valueXuv ). require realization consistent complete. Consistency means edgedeclared live dead two states. is, u, v V A,(u (a), v (a))/ {(0, 1), (1, 0)}. Completeness means status edge revealedactivation. is, exists u V u (a) {0, 1}. consistentcomplete realization thus encodes Xuv edge (u, v). Let A() denote live edgesencoded . several candidates edge sets allowed observeactivating node u. consider call Full-Adoption Feedback Model: activating u get see status (live dead) edges exiting v, nodes v reachableu via live edges (i.e., reachable u (V, A()), true realization. illustratefull-adoption feedback model Fig. 3.8.1.3 BJECTIVE F UNCTIONsimplest case, reward influencing set U V nodes f(U ) := |U |. Kempe et al.(2003) obtain 1 1e -approximation slightly general case node u450fiA DAPTIVE UBMODULARITY: HEORY PPLICATIONSPweight wu indicating importance, reward f(U ) := uU wu . generalizeresult further, include arbitrary nonnegative monotone submodular reward functions f.allows us, example, encode value associated diversity set nodes influenced, notion better achieve 20% market penetration five different (equallyimportant) demographic segments 100% market penetration one 0% others.8.2 Guarantees Maximum Coverage Objectiveready formally state result maximum coverage objective.Theorem 8.1. greedy policy greedy obtains least 1 1e value best policyAdaptive Viral Marketing problem arbitrary monotone submodular reward functions,independent cascade full-adoption feedback models discussed above. is, (S, )set activated nodes seed set activated nodes realization,f : 2V R0 arbitrary monotone submodular function indicating reward influencingset, objective function f (S, ) := f((S, )), policies k N1greedyfavg ([k] ) 1favg ([k] ).e).generally, -approximate greedy policy ` N, favg ([`] ) 1 e`/k favg ([k]Proof. Adaptive monotonicity follows immediately fact f (, ) monotonic. thus suffices prove f adaptive submodular respect probability distributionrealizations p (), invoke Theorem 5.2 complete proof.say observed edge (u, v) know status, i.e., live dead.Fix , 0 0 v/ dom( 0 ). must show (v | 0 ) (v | ).prove rigorously, define coupled distribution pairs realizations0 0 . Note given feedback model, realization function random variables {Xuw : (u, w) A} indicating status edge. conciseness use notationX = {Xuw : (u, w) A}. define implicitly terms joint distribution X X0 ,= (X) 0 = 0 (X0 ) realizations induced two distinct sets randomedge statuses, respectively. Hence ((X), (X0 )) = (X, X0 ). Next, let us say partial realization observes edge e w dom() revealed status live dead.edges (u, w) observed , random variable Xuw deterministically set status observed0 deterministically set. Similarly, edges (u, w) observed 0 , random variable Xuwstatus observed 0 . Note since 0 , state edges observed0 . (X, X0 ) support() properties. Additionally,construct status edges unobserved 0 X0 edges (u, w), else (X, X0 ) = 0.X0 , meaning Xuw = Xuwconstraints leave us following degrees freedom: may select Xuw(u, w) unobserved . select independently, E [Xuw ] = puwprior p (). Hence (X, X0 ) satisfying constraints,1Xuwuw(X, X0 ) =pX,uw (1 puw )(u,w) unobserved451fiG OLOVIN & K RAUSEotherwise (X, X0 ) = 0. Note p ( | ) =next claim (, 0 ) support()P0(, 0 ) p (0 | 0 ) =0(, ).Pf (dom( 0 ) {v} , 0 ) f (dom( 0 ), 0 ) f (dom() {v} , ) f (dom(), ). (8.1)Recall f (S, ) := f((S, )), (S, ) set activated nodes seed setactivated nodes realization. Let B = (dom(), ) C = (dom() {v} , )denote active nodes selecting v dom() realizations , similarlydefine B 0 C 0 respect 0 0 . Let := C \ B, D0 := C 0 \ B 0 . Eq. (8.1)equivalent f(B 0 D0 ) f(B 0 ) f(B D) f(B). submodularity f, sufficesshow B B 0 D0 prove inequality, do.start proving B B 0 . Fix w B. exists path u dom()w (V, A()). Moreover, every edge path live also observed live,definition feedback model. Since (, 0 ) support(), implies every edgepath also live 0 , edges observed must status0 . follows path u w (V, A(0 )). Since u clearly also dom( 0 ),conclude w B 0 , hence B B 0 .Next show D0 D. Fix w D0 suppose way contradiction w/ D.Hence exists path P v w (V, A(0 )) path exists (V, A()).edges P live 0 , least one must dead . Let (u, u0 ) edgeP . status edge differs 0 , (, 0 ) support(), must(u, u0 ) observed 0 observed . observed 0 , feedbackmodel must u active dom( 0 ) selected, i.e., u B 0 . However, impliesnodes reachable u via edges P also active dom( 0 ) selected, sinceedges P live. Hence nodes, including w, B 0 . Since D0 B 0 disjoint,implies w/ D0 , contradiction.proved Eq. (8.1), proceed use show (v | 0 ) (v | ) 6.P00000(v | 0 ) =(,0 ) (, ) (f (dom( ) {v} , ) f (dom( ), ))P0= (v | )(,0 ) (, ) (f (dom() {v} , ) f (dom(), ))completes proof.8.2.1 C OMPARISON TOCHASTIC UBMODULAR AXIMIZATIONworth contrasting Adaptive Viral Marketing problem Stochastic Submodular Maximization problem 6. latter problem, think items random independently distributed sets. Adaptive Viral Marketing contrast, random sets (of nodesinfluenced fixed node selected) depend random status ofthe edges, hence maycorrelated them. Nevertheless, obtain 1 1e approximation factorproblems.8.3 Minimum Cost Cover Objectivemay also wish adaptively run campaign certain level market penetrationachieved, e.g., certain number people adopted product. formalize452fiA DAPTIVE UBMODULARITY: HEORY PPLICATIONSgoal using minimum cost cover objective. objective, instance AdaptiveStochastic Minimum Cost Cover, given quota Q f(V ) (quantifying desiredlevel market penetration) must adaptively select nodes activate set activenodes satisfies f(S) Q. obtain following result.Theorem 8.2. Fix monotone submodular function f : 2V R0 indicating thenreward influoencing set, quota Q f(V ). Suppose objective f (S, ) := min Q, f((S, )) ,(S, ) set activated nodes seed set activated nodesrealization. Let value f(S) > Q implies f(S)QforS. -approximate greedy policy average costs ln Q+ 1 timesaverage cost best policy obtaining Q reward Adaptive Viral Marketing problem independentmodel full-adoption feedback described above. is,cascadeQcavg () ln + 1 cavg ( ) covers every realization.Proof. prove Theorem 8.2 recourse Theorem 5.8. already established fadaptive submodular, proof Theorem 8.1. remains show f strongly adaptivemonotone, instances selfcertifying, Q equal corresponding termsstatement Theorem 5.8.start strong adaptive monotonicity. Fix , e/ dom(), O. must showE [f (dom(), ) | ] E [f (dom() {e} , ) | , (e) = o] .(8.2)Let V + () denote active nodes selecting dom() observing . definitionfull adoption feedback model, V + () consists precisely nodes v exists path Puv u dom() v via exclusively live edges. edges whose status observe consist edges exiting nodes V + (). follows every pathu V + () v V \ V + () contains least one edge observeddead. Hence, every , set nodes activated selecting dom() same. Therefore E [f (dom(), ) | ] = f(V + ()). Similarly, define 0 := {(e, o)},E [f (dom() {e} , ) | , (e) = o] = f(V + ( 0 )). Note activated, nodes neverbecome inactive. Hence, 0 implies V + () V + ( 0 ). Since f monotone assumption,means f(V + ()) f(V + ( 0 )) implies Eq. (8.2) strong adaptive monotonicity.Next establishthatothese instances selfcertifying. Note everynf (V, ) = min Q, f(V ) = Q. earlier remarks, know f (dom(), ) =f(V + ()) every . Hence , 0 consistent , f (dom(), ) =f (dom(), 0 ) f (dom(), ) = Q f (dom(), 0 ) = Q, provesinstance selfcertifying.Finally show Q equal corresponding terms statement Theorem 5.8.noted earlier, f (V, ) = Q . ndefinedvalueosuch f(S) > Q impliesnf(S) Q S. Since range(f ) = min Q, f(S) : V , follows cannotf (S, ) (Q , Q) , satisfies requirements corresponding termTheorem 5.8. Hence may apply Theorem 5.8 selfcertifying instance Qobtain claimed result.453fiG OLOVIN & K RAUSE9. Application: Automated Diagnosis Active Learningimportant problem AI automated diagnosis. example, suppose different hypotheses state patient, run medical tests rule inconsistent hypotheses.goal adaptively choose tests infer state patient quickly possible.similar problem arises active learning. Obtaining labeled data train classifier typicallyexpensive, often involves asking expert. active learning (c.f., Cohn, Gharamani, & Jordan,1996; McCallum & Nigam, 1998), key idea labels informative others:labeling unlabeled examples imply labels many unlabeled examples, thuscost obtaining labels expert avoided. standard, assumegiven set hypotheses H, set unlabeled data points X x Xindependently drawn distribution D. Let L set possible labels. Classicallearning theory yields probably approximately correct (PAC) bounds, bounding number nexamples drawn i.i.d. needed output hypothesis h expected errorprobability least 1 , fixed , > 0. is, h target hypothesis (withzero error), error(h) := PxD [h(x) 6= h (x)] error h, require P [error(h) ]1 . latter probability taken respect D(X); learned hypothesis h thuserror(h) depend it. key challenge active learning avoid bias: actively selected exampleslonger i.i.d., thus sample complexity bounds passive learning longer apply. onecareful, active learning may require samples passive learning achievegeneralization error. One natural approach active learning guaranteed perform leastwell passive learning pool-based active learning (McCallum & Nigam, 1998): ideadraw n unlabeled examples i.i.d. However, instead obtaining labels, labels adaptivelyrequested labels unlabeled examples implied obtained labels.obtained n labeled examples drawn i.i.d., classical PAC bounds still apply. key questionrequest labels pool infer remaining labels quickly possible.case binary labels (or test outcomes) L = {1, 1}, various authors consideredgreedy policies generalize binary search (Garey & Graham, 1974; Loveland, 1985; Arkin,Meijer, Mitchell, Rappaport, & Skiena, 1993; Kosaraju et al., 1999; Dasgupta, 2004; Guillory &Bilmes, 2009; Nowak, 2009). simplest these, called generalized binary search (GBS)splitting algorithm, works follows. Define version space V set hypotheses consistent observed labels (here assumefiPfino label noise). worst-case setting,fifiGBS selects query x X minimizeshV h(x) . Bayesian setting assumegiven prior pHfi hypotheses; case GBS selects query x X minimizesfiarefiPfihV pH (h) h(x) . Intuitively policies myopically attempt shrink measure version space (i.e., cardinality probability mass) quickly possible. former providesO(log |H|)-approximation worst-case number queries (Arkin et al., 1993),latter provides O(log minh 1pH (h) )-approximation expected number queries (Kosarajuet al., 1999; Dasgupta, 2004) natural generalization GBS obtains guaranteeslarger set labels (Guillory& Bilmes, 2009). Kosarajuet al. also prove running GBS02modified prior pH (h) max pH (h), 1/|H| log |H| sufficient obtain O(log |H|)approximation.Viewed perspective previous sections, shrinking version space amountscovering false hypotheses stochastic sets (i.e., queries), query x covers hypotheses disagree target hypothesis h x. is, x covers {h : h(x) 6= h (x)}. 8,454fiA DAPTIVE UBMODULARITY: HEORY PPLICATIONSFigure 4: Illustration Active Learning problem, simple special case one-dimensionaldata binary threshold hypotheses H = {h : R}, h (x) = 1 x0 otherwise.sets may correlated complex ways determined set possible hypotheses.show, reduction version space mass adaptive submodular, allows us obtainnew analysis GBS using adaptive submodularity, arguably amenable extensionsgeneralizations previous analyses. new analysis allows us improve1previous best bound approximation factor GBS (Dasgupta, 2004) 4 ln minh pH (h)ln minh 1pH (h) + 1. also show apply GBS modified prior distribution,approximation factor improved O(ln |H|). result matches lower bound (ln |H|)Chakaravarthy, Pandit, Roy, Awasthi, Mohania (2007) constant factors.Theorem 9.1. Bayesian setting aprior pH ona finiteset hypotheses H,generalized binary search algorithm makes OPT ln minh 1pH (h) + 1 queries expectationidentify hypothesis drawn pH , OPT minimum expected number queriesmade policy.minh pH (h) sufficiently small, running algorithm modified priorp0H (h) max pH (h), 1/|H|2 improves approximation factor O(ln |H|).devote better part remainder section proof Theorem 9.1,several components. first address important special case uniform prior hypotheses,i.e., pH (h) = 1/|H| h H, reduce case general prior uniformprior. wish appeal Theorem 5.8, convert problem Adaptive StochasticMin Cost Cover problem.9.1 Reduction Adaptive Stochastic Min Cost CoverDefine realization h hypothesis h H. ground set E = X, outcomesbinary; define = {1, 1} instead using {0, 1} consistent earlier exposition.h H set h h, meaning h (x) = h(x) x X. define objectivefunction, first need notation. Given observed labels X O, let V () denoteversion space, i.e., set hypotheses h(x) = (x) x dom(). See Fig. 4illustration activePlearning problem case indicator hypotheses. sethypotheses V , let pH (V ) := hV pH (h) denote total prior probability. Finally, let (S, h) ={(x, h(x)) : x S} function domain agrees h S. define objective455fiG OLOVIN & K RAUSEfunctionf (S, h ) := 1 pH (V ((S, h))) = pHh0 : x S, h0 (x) 6= h(x)use p (h ) = pH (h) = 1/|H| h. Let optimal policy Adaptive StochasticMin Cost Cover instance. Note exact correspondence policiesoriginal problem finding target hypothesis problem covering true realization;h identified target hypothesis version space reduced {h }occurs h covered. Hence cavg ( ) = OPT. Note assumeduniform prior hypotheses, f (X, h ) = 1 1/|H| h. Furthermore, instancesselfcertifying.Lemma 9.2. instances described selfcertifying arbitrary priors pH .Proof. Intuitively, theses instances selfcertifying cover h policy must identifyh . formally, instances selfcertifying h h ,f (dom(), h ) = f (X, h ) implies V () = {h}. turn means hrealization consistent , trivially implies realization 0 alsof (dom(), 0 ) = f (X, 0 ); hence instance selfcertifying.9.2 Uniform Priornext prove instances generated adaptive submodular strongly adaptive monotoneuniform prior.Lemma 9.3. instances described above, f strongly adaptive monotone adaptive submodular respect uniform prior pH .Proof. Demonstrating strong adaptive monotonicity uniform prior amounts provingadding labels cannot grow version space, clear model. is, query xeliminates subset hypotheses, queries performed, subset hypotheseseliminated x cannot grow. Moving adaptive submodularity, consider expected marginalcontribution x two partial realizations , 0 subrealization 0 (i.e.,0 ), x/ dom( 0 ). Let [x/o] partial realization domain dom() {x}agrees domain, maps x o. O, let ao := pH (V ([x/o])), bo :=pH (V ( 0 [x/o])). Since hypothesis eliminated version space cannot later appearversion space, ao bo o. Next, note expected reduction version space mass(and hence expected marginal contribution) due selecting x given partial realizationPPX o0 6=o ao0Xo6=o0 ao ao0P(x | ) =ao P [(x) 6= | ] =ao= P.(9.1)o0 ao0o0 ao0oOcorresponding quantity 0 bo substituted ao Eq. (9.1), O. proveadaptive submodularity must show (x | ) (x | 0 ) soit suffices showPPP/zo 0 ~z ~c [0, 1]O : co > 0 , (~z ) :=o6=o0 zo zo0 / ( o0 zo0 )functional form expression (x | ) Eq. (9.1). /zo 0implies growing version space manner cannot decrease expected456fiA DAPTIVE UBMODULARITY: HEORY PPLICATIONSmarginal benefit query x, hence shrinking manner cannot increase expectedmarginal benefit x. indeed case /zo 0 o. specifically, holdsPP2b6=a zb +(b,c):b6=c,b6=a,c6=a zb zc=0,Pza( b zb )2derived elementary calculus.Hence apply Theorem 5.8 selfcertifying instance maximum reward threshold Q = 11/|H|, minimum gap = 1/|H|, obtain upper bound OPT (ln (|H| 1) + 1)number queries made generalized binary search algorithm (which corresponds exactly greedy policy Adaptive Stochastic Min Cost Cover) assumptionuniform prior H.9.3 Arbitrary Priorsconsider general priors H. construct Adaptive Stochastic Min Cost Cover instancebefore, change objective functionf (S, h ) := 1 pH (V ((S, h))) + pH (h).(9.2)First note instances remain selfcertifying. proof Lemma 9.2 goes completely unchanged modification f . proceed show adaptive submodularity strongadaptive monotonicity.Lemma 9.4. objective function f described Eq. (9.2) strongly adaptive monotoneadaptive submodular respect arbitrary priors pH .Proof. modified objective still adaptive submodular, (S, h ) 7 pH (h) clearly so,adaptive submodularity defined via linear inequalities preserved takingnonnegative linear combinations. Note f (X, h ) = 1 h .Showing f strongly adaptive monotone requires slightly work before. Fix , x/dom(), O. must showE [f (dom(), ) | ] E [f (dom() {x} , ) | , (x) = o] .(9.3)Plugging definition f , inequality wish prove may simplifiedE [pH () | ] E [pH () | [x/o]] pH (V ()) pH (V ([x/o])).(9.4)random realization hypothesis, pH (h ) = pH (h) h. Let Velim :=V () V ([x/o]) set hypotheses eliminated version space observationh(x) = o. Rewriting Eq. (9.4), getXhV ()pH (h)2pH (V ())XhV ([x/o])pH (h)2pH (Velim ).pH (V ([x/o]))457(9.5)fiG OLOVIN & K RAUSELet LHS9.5 denote left hand side Eq. (9.5). prove Eq. (9.5) follows.P2LHS9.5[since pH (V ([x/o])) pH (V ())]hVelim pH (h) /pH (V ())PhVelim pH (h) pH (V ())/pH (V ()) [since h V () pH (h) pH (V ())]= pH (Velim )conclude f adaptive submodular strongly adaptive monotone.Hence apply Theorem 5.8 selfcertifying instance maximum reward threshold Q = 1, minimum gap = 1/ minh pH (h). result obtain upper boundOPT (ln (1/ minh pH (h)) + 1) number queries made generalized binary searcharbitrary priors, completing proof Theorem 9.1.9.4 Improving Approximation Factor Highly Nonuniform Priorsimprove O(log |H|)-approximation event minh pH (h) extremely smallusing observation Kosaraju et al. (1999), call policy progressive ifit eliminates leastone hypothesis version spaceLet p0H (h) = max pH (h), 1/|H|2 /Zquery.P0modified prior, Z := h0 max pH (h ), 1/|H|2 normalizingPconstant. Letc(, h) cost (i.e., # queries) target h. cavg (, p) :=h c(, h)p(h)expected cost prior p. show cavg (, p0H ) good approximation cavg (, pH ). Call h rare pH (h) < 1/|H|2 , common otherwise. First, noteP02 1 + 1/|H|, p0 (h) |H| p (h), h. Hence ,h0 max pH (h ), 1/|H|H|H|+1 H|H|cavg (, pH ). Next, show cavg (, p0H ) cavg (, pH ) + 1. Considercavg (, p0H ) |H|+1Pquantity cavg (, p0H ) cavg (, pH ) = h c(, h) (p0H (h) pH (h)). positive contributionsmust come rare hypotheses. However, total probability mass p0H1/|H|, since progressivec(, h) |H| h, hence difference costs1one. Let := ln minh p0 (h) + 1 ln |H|2 + |H| + 1 approximation factor generalHized binary search run p0H . Let policy generalized binary search, letoptimal policy prior pH .|H| + 1|H| + 1|H| + 1cavg (, p0H )cavg ( , p0H )cavg ( , pH ) + 1 .|H||H||H|algebra, derive cavg (, pH ) cavg ( , pH ) + 1 ln 2e|H|2 . Thusgeneral prior simple modification GBS yields O(log |H|)-approximation.cavg (, pH )9.5 Extensions Arbitrary Costs, Multiple Classes, Approximate Greedy Policiesresult easily generalizes handle setting multiple classes / test outcomes (i.e., |O| 2),-approximate greedy policies, lose factor approximation factor.describe Appendix, generalize adaptive submodularity incorporate costs items,allows us extend result handle query costs well. therefore recoverextensions GuilloryBilmes(2009), improving approximation factor GBS1item costs ln minh pH (h) + 1. Guillory Bilmes also showed extend technique458fiA DAPTIVE UBMODULARITY: HEORY PPLICATIONSx c(x)-approximation costs usingKosaraju et al. (1999) obtain log |H| maxminx c(x)greedy policy, may combined tighter analysis well give similar resultimproved leading constant. Recently, Gupta, Krishnaswamy, Nagarajan, Ravi (2010)showed simultaneously remove dependence costs probabilitiesapproximation ratio. Specifically, within context studying adaptive travelling salesmanproblem investigated Optimal Decision Tree problem, equivalent activelearning problem consider here. Using clever, complex algorithm adaptive greedy,achieve (log |H|)-approximation case non-uniform costs general priors.9.6 Extensions Active Learning Noisy ObservationsTheorem 9.1 extensions mentioned far noise free case, i.e., result query xobserves h (x), h target hypothesis. Many practical problems may noisy observations. Nowak (2009) considered case outcomes binary, i.e., = {1, 1},query may asked multiple times, instance query noise independent. case gives performance guarantees generalized binary search.setting may appropriate noise due measurement error, applications noisepersistent, i.e., query x asked several times, observation always same. Recently,Golovin et al. (2010) Bellala Scott (2010) used adaptive submodularity framework obtain first algorithms provable (logarithmic) approximation guarantees activelearning persistent noise.10. ExperimentsGreedy algorithms often straightforward develop implement, explains popular use practical applications, Bayesian experimental design Active Learning,discussed 9 (also see excellent introduction Nowak, 2009) Adaptive Stochastic SetCover, e.g., filter design streaming databases discussed 7. Besides allowing us proveapproximation guarantees algorithms, adaptive submodularity provides following immediate practical benefits:1. ability use lazy evaluations speed execution.2. ability generate data-dependent bounds optimal value.section, empirically evaluate benefits within sensor selection application,setting similar one described Deshpande, Guestrin, Madden, Hellerstein, Hong (2004).application, deployed network V wireless sensors, e.g., monitor temperaturebuilding traffic road network. Since sensors battery constrained, must adaptivelyselect k sensors, then, given sensor readings, predict, e.g., temperature remaininglocations. prediction possible since temperature measurements typically correlatedacross space. Here, consider case sensors fail report measurements duehardware failures, environmental conditions interference.10.1 Sensor Selection Problem Unreliable Sensorsformally, imagine every location v V associated random variable Xv describingtemperature location, joint probability distribution p (xV ) := P [XV = xV ]models correlation temperature values. Here, XV = [X1 , . . . , Xn ] random459fiG OLOVIN & K RAUSEvector temperature values. follow Deshpande et al. (2004) assume jointdistribution sensors multivariate Gaussian. sensor v make noisy observation Yv =Xv + v , v zero mean Gaussian noise known variance 2 . measurementsYA = yA obtained subset locations, conditional distribution p (xV | yA ) :=P [XV = xV | YA = yA ] allows predictions unobserved locations, e.g., predicting E[XV |YA = yA ] (which minimizes mean squared error). Furthermore, conditional distributionquantifies uncertainty prediction: Intuitively, would like select sensors minimizepredictive uncertainty. One way quantify predictive uncertainty use remainingShannon entropyH (XV | YA = yA ) := E [ log2 (p (XV | yA ))] .would like adaptively select k sensors, maximize expected reduction Shannon entropy (c.f., Sebastiani & Wynn, 2000; Krause & Guestrin, 2009b). However, practice, sensorsoften unreliable, might fail report measurements. assume selecting sensor, find whether failed deciding sensor select next. supposesensor associated probability pfail (v) failure, case reading reported,sensor failures independent ambient temperature v. Thusinstance Stochastic Maximization problem E := V , := {working, failed},f (A, ) := H (XV ) H XV | y{v : (v)=working} .(10.1)multivariate normal distributions, entropy givenfifi11fifiH (XV | YA = yA ) = ln(2e)n fiV AA + 2AV fi ,2sets B, AB denotes covariance (matrix) random vectors XA XB .Note predictive covariance depend actual observations yA , setchosen locations. Thus,H (XV | YA = yA ) = H (XV | YA ) ,usual, H (XV | YA ) = E [H (XV | YA = yA )]. Krause Guestrin (2005) show,functiong(A) := (XV ; YA ) = H (XV ) H (XV | YA )(10.2)monotone submodular, whenever observations YV conditionally independent given XV .insight allows us apply result 6 show objective f defined Eq. (10.1)adaptive monotone submodular, using f(S) := g({v : (v, working) S}) E O.10.1.1 DATA E XPERIMENTAL ETUPfirst data set consists temperature measurements network 46 sensors deployedIntel Research Berkeley, sampled 30 second intervals 5 consecutive days (startingFeb. 28th , 2004). define objective function respect empirical covariance estimateddata.also use data traffic sensors deployed along highway I-880 South California.use traffic speed data working days 6 11 one month, 357sensors. goal predict speed 357 road segments. estimate empiricalcovariance matrix.460fiA DAPTIVE UBMODULARITY: HEORY PPLICATIONS10.1.2 B ENEFITS L AZY E VALUATIONdata sets, run adaptive greedy algorithm, using naive implementation (Algorithm 1) accelerated version using lazy evaluations (Algorithm 2). vary probabilitysensor failure, evaluate execution time number evaluations function g(defined Eq. (10.2)) algorithm makes. Figures 5(a) 5(b) plot execution time given50% sensor failure rate, computer 2.26 GHz dual core processor 4 GB RAM.applications, function evaluations bottleneck computation, numberserves machine-independent proxy running time. Figures 5(c) 5(d) showperformance ratio terms proxy. temperature data set, lazy evaluations speedcomputation factor roughly 3.5 7, depending failure probability.larger traffic data set, obtain speedup factors 30 38. find benefitlazy evaluations increases problem size failure probability. dependenceproblem size must ultimately explained terms structural properties instances,also benefit nonadaptive accelerated greedy algorithm. dependence failure probabilitysimpler explanation. Note applications, accelerated greedy algorithm selects v, fails, need make additional function evaluations selectnext sensor. Contrast naive greedy algorithm, makes function evaluationsensor selected far.10.1.3 B ENEFITS DATA EPENDENT B OUNDadaptive submodularity allows us prove worst-case performance guarantees adaptive greedy algorithm, many practical applications expected bounds quiteloose. sensor selection application, use data dependent bounds Lemma 5.3compute upper bound avg max favg ([k] ) described below, compare performance guarantee Theorem 5.2. accelerated greedy algorithm, use upper boundsmarginal benefits stored priority queue instead recomputing marginal benefits,thus expect somewhat looser bounds. find application, bounds tighterworst case bounds. also find lazy data dependent bounds almost tighteager bounds using eagerly recomputed marginal benefits (e | ) latest greatest , though former slightly higher variance. Figures 5(e) 5(f) show performancegreedy algorithm well three bounds optimal value.Two subtleties arise using data-dependent bounds bound max favg ([k] ).P|first Lemma 5.3 tells us [k]maxAE,|A|keA (e | ), whereaswould like bound differenceh optimal reward algorithms currentexpectedreward, conditioned seeing , i.e., E f (E([k] , ), ) f (dom(), ) | . However,applications f strongly adaptive monotone, strong adaptive monotonicity implieshE f (E([k], ), ) f (dom(), ) | [k]| .(10.3)Hence, let OPT() := max E f (E([k] , ), ) | , Lemma 5.3 impliesOPT() E [f (dom(), ) | ] +461maxAE,|A|kXeA(e | ) .(10.4)fiG OLOVIN & K RAUSEsecond subtlety obtain sequence bounds Eq. (10.4). consider(random) sequence partial realizations observed adaptive greedy algorithm, = 01 k ,Pobtain k + 1 bounds 0 , . . . , k , := E [f (dom( ), ) | ] +maxAE,|A|keA (e | ). Taking expectation , note , i,favg ([k] ) E [OPT( )] E [i ] .Therefore 0 k , random variable whose expectation upper boundoptimal expected reward policy. point may tempted use minimumthese, i.e., min := mini {i } ultimate bound. However, collection random variablesX0 , . . . , Xk E [Xi ] not, general, satisfy mini {Xi } .possible case, independent sensor failures, use concentration inequalities boundmini {i } mini {E [i ]} high probability, thus add appropriate term obtain trueupper bound min , take different approach; simply use average bound avg :=1 Pki=0 . course, depending application, particular bound (chosen independentlyk+1sequence 0 , 1 , . . . , k ) may superior. example, g modular, 0 best,whereas g exhibits strong diminishing returns, bounds larger values maysignificantly tighter.11. Adaptivity Gapimportant question adaptive optimization much better adaptive policies performcompared non-adaptive policies. quantified adaptivity gap,worst-case ratio, problem instances, performance optimal adaptive policyoptimal non-adaptive solution. Asadpour et al. (2008) show Stochastic SubmodularMaximization problem independent failures (as considered 6), expected valueoptimal non-adaptive policy constant factor 1 1/e worse expected valueoptimal adaptive policy. currently lower bounds adaptivitygap general Adaptive Stochastic Maximization problem (2.1), show evencase adaptive submodular functions, min-cost cover min-sum cover versions largeadaptivity gaps, thus large benefit using adaptive algorithms. cases,adaptivity gap defined worst-case ratio expected cost optimal non-adaptivepolicy divided expected cost optimal adaptive policy. Adaptive StochasticMinimum Cost Coverage problem (2.2), Goemans Vondrak (2006) show special caseStochastic Set Coverage without multiplicities adaptivity gap (|E|). exhibitadaptive stochastic optimization instance adaptivity gap (|E|/ log |E|) AdaptiveStochastic Min-Sum Cover problem (2.3), also happens adaptivity gapAdaptive Stochastic Minimum Cost Coverage.Theorem 11.1. Even adaptive submodular functions, adaptivity gap Adaptive StochasticMin-Sum Cover (n/ log n), n = |E|.Proof. Suppose E = {1, . . . , n}. Consider active learning problem hypothesesh : E {1, 1} threshold functions, i.e., h(e) = 1 e ` h(e) = 1 e < `threshold `. uniform distribution thresholds ` {1, . . . , n + 1}.order identify correct hypothesis threshold `, policy must observe least one` 1 ` (and 1 < ` n). Let optimal non-adaptive policy462fiA DAPTIVE UBMODULARITY: HEORY PPLICATIONSTime Standard Accelerated Adaptive Greedy0.450.4Time Standard Accelerated Adaptive Greedy4035Adaptive Greedy0.35Adaptive Greedy300.3250.25200.2150.15Accelerated Adaptive Greedy100.150.050051015202530354045050Accelerated Adaptive Greedy050100150200250300350(a) Temperature Data: Execution time (sec)naive vs accelerated implementations adaptive greedy vs. budget k number sensorsselected, pfail (v) = 0.5 v, plottedstandard errors.(b) Traffic Data: Execution time (sec)naive vs accelerated implementations adaptive greedy vs. budget k number sensors selected, pfail (v) = 0.5 v,plotted standard errors.845Redu ction Function Evaluations vs. Pr[failure]7654Reduction Function Evaluations vs . Pr [failur e]4090%80%70%60%50%40%30%20%10%75%3550%25%302520153102510102030400050100200300400(c) Temperature Data: ratio function evaluations made naive vs accelerated implementations adaptive greedy vs. budget knumber sensors selected, various failurerates. Averaged 100 runs.(d) Traffic Data: ratio function evaluationsmade naive vs accelerated implementationsadaptive greedy vs. budget k numbersensors selected, various failure rates. Averaged 10 runs.Reward Adaptive Greedy, DataDependent BoundsReward Adaptive Greedy, DataDependent Bounds10015090Standard BoundLazy Adaptive BoundAdaptive BoundStandard BoundLazy Adaptive BoundAdaptive Bound80701006050405030Adaptive GreedyAdaptive Greedy20100051015202530354045050(e) Temperature Data: Rewards & boundsoptimal value pfail (v) = 0.5 v vs.budget k number sensors selected, plottedstandard errors.050100150200250300350400(f) Traffic Data: Rewards & bounds optimal value pfail (v) = 0.5 v vs.budget k number sensors selected, plottedstandard errors.Figure 5: Experimental results.463fiG OLOVIN & K RAUSEproblem. Note represented permutation E, observing elementmultiple times increase cost providing benefit observing once,element must eventually selected guarantee coverage. min-sum cover objective,consider playing n/4 time steps. P [` observed n/4 steps] = n/4(n + 1). LikewiseP [` 1 observed n/4 steps] = n/4(n + 1). Since least one events must occuridentify correct hypothesis, union boundP [ identifies correct hypothesis n/4 steps]n2(n + 1)1/2.Thus lower bound expected cost n/8, since n/4 time steps cost least1/2 incurred. Thus, min-cost min-sum cover objectives cost optimalnon-adaptive policy (n).example adaptive policy, implement natural binary search strategy,guaranteed identify correct hypothesis O(log n) steps, thus incurring cost O(log n),proving adaptivity gap (n/ log n).12. Hardness Approximationpaper, developed notion adaptive submodularity, characterizescertain adaptive stochastic optimization problems well-behaved sense simple greedypolicy obtains constant factor logarithmic factor approximation best policy.contrast, also show without adaptive submodularity, adaptive stochastic optimization problems (2.1), (2.2), (2.3) extremely inapproximable, even (pointwise)modular objective functions (i.e., , f : 2E OE R modular/linearfirst argument): cannot hope achieve O(|E|1 ) approximation ratio problems, unless polynomial hierarchy collapses P2 .Theorem 12.1. (possibly non-constant) 1, polynomial time algorithm AdaptiveStochastic Maximization budget k items approximate reward optimal policybudget k items within multiplicative factor O(|E|1 /) > 0, unlessPH = P2 . holds even pointwise modular f .provide proof Theorem 12.1 Appendix A.7. Note setting = 1,obtain O(|E|1 ) hardness Adaptive Stochastic Maximization. turns instancedistribution construct proof Theorem 12.1 optimal policy covers every realization(i.e., always finds treasure) using budget k = O(|E|/2 ) items. Hence PH 6= P2randomized polynomial time algorithm wishing cover instance must budget= (|E|1 ) times larger optimal policy, order ensure ratio rewards,(|E|1 /), equals one. yields following corollary.Corollary 12.2. polynomial time algorithm Adaptive Stochastic Min Cost Coverageapproximate cost optimal policy within multiplicative factor O(|E|1 )> 0, unless PH = P2 . holds even pointwise modular f .Furthermore, since instance distribution construct optimal policy covers everyrealization using budget k, c ( ) k. Moreover, since showncomplexity theoretic assumptions, polynomial time randomized policy budget k464fiA DAPTIVE UBMODULARITY: HEORY PPLICATIONSachieves o(/|E|1 ) (unit) value obtained optimal policy budget k,follows c () = (k). Since require = (|E|1 ) cover set realizationsconstituting, e.g., half probability mass, obtain following corollary.Corollary 12.3. polynomial time algorithm Adaptive Stochastic Min-Sum Cover approximate cost optimal policy within multiplicative factor O(|E|1 ) > 0,unless PH = P2 . holds even pointwise modular f .13. Related Worklarge literature adaptive optimization partial observability relates adaptive submodularity, broadly organized several different categories. Here,review relevant related work already discussed elsewhere manuscript.13.1 Adaptive Versions Classic Non-adaptive Optimization ProblemsMany approaches consider stochastic generalizations specific classic non-adaptive optimizationproblems, Set Cover (Goemans & Vondrak, 2006; Liu et al., 2008), Knapsack (Dean, Goemans, & Vondrak, 2008, 2005) Traveling Salesman (Gupta et al., 2010). contrast,paper goal introduce general problem structure adaptive submodularity unifiesnumber adaptive optimization problems. similar classic notion submodularity unifies various optimization problems Set Cover, Facility Location, nonadaptiveBayesian Experimental Design, etc.13.2 Competitive Online OptimizationAnother active area research sequential optimization study competitive online algorithms. particularly relevant example Online Set Cover (Alon, Awerbuch, Azar, Buchbinder,& Naor, 2009), known set system, arbitrary sequence elements presentedalgorithm, algorithm must irrevocably select sets purchase timespurchased sets cover elements appeared far. Alon et al. (2009) obtainpolylogarithmic approximation problem, via online primaldual frameworkprofitably applied many problems. Buchbinder Naor (2009) provide detailedtreatment framework. Note competitive analysis focuses worstcase scenarios.contrast, assume probabilistic information world optimize average case.13.3 (Noisy) Interactive Submodular Set CoverRecent work Guillory Bilmes (2010, 2011) considers class adaptive optimization problems family monotone submodular objectives {fh : h H}. problem, one mustcover monotone submodular objective fh depends (initially unknown) target hypothesis h H, adaptively issuing queries getting responses. Unlike traditional pool-basedactive learning, query may generate response set valid responses dependingtarget hypothesis. reward calculated evaluating fh set (query, response) pairsobserved, goal obtain threshold Q objective value minimum total query cost,queries may nonuniform costs. noisy variant problem (Guillory & Bilmes,2011), set (query, response) pairs observed need consistent hypothesis H,465fiG OLOVIN & K RAUSEgoal obtain Q value hypotheses close consistentobservations. variants, Guillory Bilmes consider worst-case policy cost, provide greedy algorithms optimizing clever hybrid objective functions. prove approximationguarantee ln(Q|H|) + 1 integer valued objective functions {fh }hH noisefree case,similar logarithmic approximation guarantees noisy case.similar spirit work, several significant differences two.Guillory Bilmes focus worst-case policy cost, focus mainly average-case policycost. structure adaptive submodularity depends prior p (), whereasdependence Interactive Submodular Set Cover. dependence turn allows us obtainresults, Theorem 5.8 selfcertifying instances, whose approximation guaranteedepend number realizations way guarantees Interactive Submodular SetCover depend |H|. Guillory Bilmes prove, latter dependence fundamentalreasonable complexity-theoretic assumptions6 . interesting open problem within adaptivesubmodularity framework highlighted work Interactive Submodular Set Coveridentify useful instance-specific properties sufficient improve upon worst-caseapproximation guarantee Theorem 5.9.13.4 Greedy Frameworks Adaptive Optimizationpaper perhaps closest spirit work one Stochastic Depletion problemsChan Farias (2009), also identify general class adaptive optimization problemsnear-optimally solved using greedy algorithms (which setting give factor2 approximation). However, similarity mainly conceptual level: problemsapproaches, well example applications considered, quite different.13.5 Stochastic Optimization Recourseclass adaptive optimization problems studied extensively operations research (since Dantzig,1955) area stochastic optimization recourse. Here, optimization problem,Set Cover, Steiner Tree Facility Location, presented multiple stages. stage,information revealed, costs actions increase. key difference problems studiedpaper problems, information gets revealed independently actions takenalgorithm. general efficient, sampling based (approximate) reductions multi-stageoptimization deterministic setting (see, e.g., Gupta, Pal, Ravi, & Sinha, 2005).13.6 Bayesian Global OptimizationAdaptive Stochastic Optimization also related problem Bayesian Global Optimization(c.f., Brochu, Cora, & de Freitas, 2009, recent survey area). Bayesian Global Optimization, goal adaptively select inputs order maximize unknown functionexpensive evaluate (and possibly evaluated using noisy observations). common approach successful many applications (c.f., Lizotte, Wang, Bowling, & Schuurmans,2007, recent application machine learning), assume prior distribution, Gaus6. reduce Set Cover use result Feige (1998), requires assumption NP *DTIME(nO(log log n) ), suffices assume P 6= NP using Set Cover approximation hardness resultRaz Safra (1997) instead.466fiA DAPTIVE UBMODULARITY: HEORY PPLICATIONSsian process, unknown objective function. Several criteria selecting inputsdeveloped, Expected Improvement (Jones, Schonlau, & Welch, 1998) criterion. However, recently performance guarantees obtained no-regret setting (Grunewalder,Audibert, Opper, & Shawe-Taylor, 2010; Srinivas, Krause, Kakade, & Seeger, 2010),aware approximation guarantees Bayesian Global Optimization.13.7 Probabilistic Planningproblem decision making partial observability also extensively studiedstochastic optimal control. particular, Partially Observable Markov Decision Processes (POMDPs,Smallwood & Sondik, 1973) general framework captures many adaptive optimizationproblems partial observability. Unfortunately, solving POMDPs PSPACE hard (Papadimitriou & Tsitsiklis, 1987), thus typically heuristic algorithms approximation guaranteesapplied (Pineau, Gordon, & Thrun, 2006; Ross, Pineau, Paquet, & Chaib-draa, 2008).special instances POMDPs related Multi-armed Bandit problems, (near-)optimal policiesfound. include (optimal) Gittins-index policy classic Multi-armed Bandit problem (Gittins & Jones, 1979) approximate policies Multi-armed Bandit problemmetric switching costs (Guha & Munagala, 2009) special cases Restless Bandit problem (Guha, Munagala, & Shi, 2009). problems considered paper formalizedPOMDPs, albeit exponentially large state space (where world state represents selecteditems state/outcome item). Thus results interpreted widening classpartially observable planning problems efficiently approximately solved.13.8 Previous Work Authors & Subsequent Developmentsmanuscript extended version paper appeared Conference LearningTheory (COLT; Golovin & Krause, 2010). recently, Golovin Krause (2011) proved performance guarantees greedy policy problem maximizing expected valuepolicy constraints complex simply selecting k items. include matroid constraints, policy select independent sets items greedy policyobtains 1/2approximation adaptive monotone submodular objectives, generallyp-independence system constraints, greedy policy obtains 1/(p + 1)approximation.Golovin et al. (2010) and, shortly thereafter, Bellala Scott (2010), used adaptive submodularity framework obtain first algorithms provable (logarithmic) approximation guaranteesdifficult fundamental problem active learning persistent noise. Finally, Golovin,Krause, Gardner, Converse, Morey (2011) used adaptive submodularity contextdynamic conservation planning, obtain competitiveness guarantees ecological reservedesign problem.14. ConclusionsPlanning partial observability central notoriously difficult problem artificial intelligence. paper, identified novel, general class adaptive optimization problemsuncertainty amenable efficient, greedy (approximate) solution. particular, introduced concept adaptive submodularity, generalizing submodular set functions adaptivepolicies. generalization based natural adaptive analog diminishing returns prop-467fiG OLOVIN & K RAUSEerty well understood set functions. special case deterministic distributions, adaptivesubmodularity reduces classical notion submodular set functions. proved severalguarantees carried non-adaptive greedy algorithm submodular set functions generalizenatural adaptive greedy algorithm case adaptive submodular functions, constrainedmaximization certain natural coverage problems minimum cost minimum sumobjectives. also showed adaptive greedy algorithm accelerated using lazy evaluations, one compute data-dependent bounds optimal solution. illustratedusefulness concept giving several examples adaptive submodular objectives arisingdiverse AI applications including sensor placement, viral marketing, automated diagnosispool-based active learning. Proving adaptive submodularity problems allowed us recover existing results applications special cases lead natural generalizations.experiments real data indicate adaptive submodularity provide practical benefits,significant speed ups tighter data-dependent bounds. believe results provideinteresting step direction exploiting structure solve complex stochastic optimizationplanning problems partial observability.Acknowledgmentsextended abstract work appeared COLT 2010 (Golovin & Krause, 2010). wishthank anonymous referees helpful suggestions. research partially supportedONR grant N00014-09-1-1044, NSF grant CNS-0932392, NSF grant IIS-0953413, DARPA MSEEgrant FA8650-11-1-7156, gift Microsoft Corporation, Okawa Foundation Research Grant,Caltech Center Mathematics Information.Appendix A. Additional Proofs Incorporating Item Costsappendix provide proofs omitted main text. results 5,first explaining results generalize case items costs,proving generalizations incorporate item costs.A.1 Incorporating Costs: Preliminariessection provide preliminaries required define analyze versions problems non-uniform item costs. suppose itemP e E cost c(e), costset E given modular function c(S) = eS c(e). define generalizationsproblems (2.1), (2.2), (2.3) A.3, A.4, A.5, respectively.results respect greedy policy greedy -approximate greedy policies.costs, greedy policy selects item maximizing (e | ) /c(e), currentpartial realization.Definition A.1 (Approximate Greedy Policy Costs). policy -approximate greedypolicy exists e E (e | ) > 0,(e | )1(e0 | )() e :max,c(e)e0c(e0 )terminates upon observing (e | ) 0 e E. is, approximate greedy policy always obtains least (1/) maximum possible ratio condi468fiA DAPTIVE UBMODULARITY: HEORY PPLICATIONStional expected marginal benefit cost, terminates benefit obtainedexpectation. greedy policy 1-approximate greedy policy.convenient imagine policy executing time, policy selectsitem e, starts run e, finishes running e c(e) units time. next generalizedefinition policy truncation. Actually require three generalizations,equivalent unit cost case.Definition A.2 (Strict Policy Truncation). strict level truncation policy , denoted[t] , obtained running time units, unselecting items whose runs finnPished time t. Formally, [t] domain dom() : c(()) + edom() c(e) ,agrees everywhere domain.Definition A.3 (Lax Policy Truncation). lax level truncation policy , denoted [t] ,obtained running time units, selecting items running time t. Formally, [t]nPc(e)<, agrees everywhere domain.domain dom() :edom()Definition A.4 (Policy Truncation Costs). level-t-truncation policy , denoted[t] , randomized policy obtained running time units, item erunning 0 < c(e) time time t, selecting e independently probability /c(e). Formally, [t] randomized policy agrees everywhere domain, dom([t] )dom([t] ) dom([t] ) certainty, includes dom([t] ) \ dom([t] )Pdomain independently probability edom() c(e) /c(()).proofs follow, need notion conditional expected cost policy,well alternate characterization adaptive monotonicity, based notion policy concatenation. prove equivalence two adaptive monotonicity conditions Lemma A.8.Definition A.5 (Conditional Policy Cost). conditional policy cost conditioned , denoted c ( | ), expected cost items selects p ( | ). is, c ( | ) :=E [c(E(, )) | ].Definition A.6 (Policy Concatenation). Given two policies 1 2 define 1 @2 policyobtained running 1 completion, running policy 2 fresh start, ignoringinformation gathered7 running 1 .Definition A.7 (Adaptive Monotonicity (Alternate Version)). function f : 2E OE R0adaptive monotone respect distribution p () policies 0 , holdsfavg () favg ( 0 @), favg () := E [f (E(, ), )] defined w.r.t. p ().Lemma A.8 (Adaptive Monotonicity Equivalence). Fix function f : 2E OE R0 .(e | ) 0 P [ ] > 0 e E policies 0 ,favg () favg ( 0 @).7. Technically, realization policy 2 selects item 1 previously selected, 1 @2 cannotwritten function set partial realizations E, i.e., policy. amended allowingpartial realizations multisets elements E O, that, e.g., e played twice (e, (e)) appearstwice . However, interest readability avoid cumbersome multiset formalism, abusenotation slightly calling 1 @2 policy. issue arises whenever run policy run anotherfresh start.469fiG OLOVIN & K RAUSEProof. Fix policies 0 . begin proving favg ( 0 @) = favg (@ 0 ). Fix noteE( 0 @, ) = E( 0 , ) E(, ) = E(@ 0 , ). Hencefavg ( 0 @) = E f (E( 0 @, ), ) = E f (E(@ 0 , ), ) = favg (@ 0 ).Therefore favg () favg ( 0 @) holds favg () favg (@ 0 ).first prove forward direction. Suppose (e | ) 0 e E. Noteexpression favg (@ 0 ) favg () written conicalP combination (nonnegative) (e0| )0terms, i.e., 0, favg (@ ) favg () = ,e (,e) (e | ). Hence favg (@ )favg () 0 favg () favg (@ 0 ) = favg ( 0 @).next prove backward direction, contrapositive form. Suppose (e | ) < 0P [ ] > 0 e E. Let e1 , . . . , er items dom() define policies0 follows. = 1, 2, . . . , r, 0 select ei observe (ei ). either policyobserves (ei ) 6= (ei ) immediately terminates, otherwise continues. succeeds selectingdom() terminates. 0 succeeds selecting dom() selects eterminates. claim favg (@ 0 ) favg () < 0. Note E(@ 0 , ) = E(, ) unless ,E(@ 0 , ) = E(, ) {e} also E(, ) = dom(). Hencefavg (@ 0 ) favg () = E f (E(@ 0 , ), ) f (E(, ), )= E f (E(@ 0 , ), ) f (E(, ), ) | P [ ]= E [f (dom() {e} , ) f (dom(), ) | ] P [ ]= (e | ) P [ ]last term negative, P [ ] > 0 (e | ) < 0 assumption. Therefore favg () >favg (@ 0 ) = favg ( 0 @), completes proof.A.2 Adaptive Data Dependent Bounds Costsadaptive data dependent bound following generalization costs.Lemma A.9 (The Adaptive Data Dependent Bound Costs). Suppose made observations selecting dom(). Let policy. adaptive monotone submodularf : 2E OE R0(e | )( | ) Z c ( | ) max(A.1)ec(e)PP| ) e E, 0 w 1 .w(e|):c(e)wc(Z = maxweeeeEeProof. Order items dom() arbitrarily, consider policy e dom()order selects e, terminating (e) 6= (e) proceeding otherwise, and, succeedselecting dom() without terminating (which occurs iff ), proceeds runfresh start, forgetting observations . construction expected marginalbenefit running portion conditioned equals ( | ). e E, letw(e) = P [e E(, ) | ] probability e selected running , conditioned. Whenever e E \ dom() selected , current partial realization0 contains subrealization; hence adaptive submodularity implies (e | 0 ) (e | ).470fiA DAPTIVE UBMODULARITY: HEORY PPLICATIONSfollows total contribution e ( | ) upperPbounded w(e) (e | ). Summinge E \ dom(), get bound ( | )eE\dom() w(e)(e | ). Next, notew(e)c(e) cost c ( | ). Hence must caseP e E \ dom() contributeseE\dom() w(e)c(e)P c ( | ). Obviously, w(e) [0, 1] e, since w(e) probability.Hence ( | ) eE\dom() w(e)(e | ) Z setting = w(e) feasiblelinear program Z optimal value.show Z c ( | ) maxe ((e | ) /c(e)), consider feasible solution w linearprogram defining Z. attains objective valueXX(e | ) X(e | )(e | )(e | )c(e)c ( | ) maxc(e) maxeEeEc(e)c(e)c(e)eEeEeEPsince eE c(e) c ( | ) feasibility w.simple greedy algorithm used compute Z; provide pseudocode Algorithm 3. correctness algorithm readily discerned upon rewriting linearprogram using variables xe = c(e)we obtain()XXZ = maxxe ((e | ) /c(e)) :xe c ( | ) e E, 0 xe c(e) .xeEeIntuitively, clear optimize x shiftvariables highestPmass towards(e | ) /c(e) ratio. Clearly, optimal solution e xe = c ( | ). Moreover, optimal solution, (e | ) /c(e) > (e0 | ) /c(e0 ) implies xe = c(e) xe0 = 0, since otherwisewould possible shift mass xe0 xe obtain increase objective value.(e | ) /c(e) values distinct distinct items, unique solution satisfyingconstraints, Algorithm 3 compute. Otherwise, imagine perturbing (e | )independent random quantities e drawn uniformly [0, ] make distinct. changesoptimum valuePby |E|, vanishes let tend towards zero. Hence solution satisfying e xe = c ( | ) (e | ) /c(e) > (e0 | ) /c(e0 ) implies xe = c(e)xe0 = 0 optimal. Since Algorithm 3 outputs value solution, correct.A.3 Max-Cover Objectiveitem costs, Adaptive Stochastic Maximization problem becomes one findingarg max favg ([k] )(A.2)k budget cost selected items, define favg () randomized policyfavg () := E [f (E(, ), )] before, expectation internal randomness determines E(, ) . prove following generalizationTheorem 5.2.Theorem A.10. Fix 1 item costs c : E N. f adaptive monotone adaptivesubmodular respect distribution p (), -approximate greedy policy,policies positive integers ` kfavg ([`] ) > 1 e`/k favg ([k]).471fiG OLOVIN & K RAUSEInput: Groundset E; Partial realization ; Costs c : E N; Budget C = c ( | );Conditional expected marginal benefits (e | ) e E.Output: Z = PPmaxweE (e | ) :e c(e)we c ( | ) e E, 0 1begin(e2 | )(en | )1 | )Sort E (e | ) /c(e), (ec(e1 ) c(e2 ) . . . c(en ) ;Set w 0; 0; 0; z 0; e NULL;< C+ 1; e ei ;min {1, C a};+ c(e)we ; z z + (e | );Output z;endAlgorithm 3: Algorithm compute data dependent bound Z Lemma A.9.Proof. proof goes along lines performance analysis greedy algorithmmaximizing submodular function subject cardinality constraint Nemhauser et al. (1978).extension analysis -approximate greedy algorithms, analogousnonadaptive case, shown Goundan Schulz (2007). brevity, assume. i, 0 < `without loss generality = [`] = [k]favg ( ) favg ([i] @ ) favg ([i] ) + k favg ([i+1] ) favg ([i] ) .(A.3)first inequality due adaptive monotonicity f Lemma A.8, mayinfer favg (2 ) favg (1 @2 ) 1 2 . second inequalitymay obtained corollary Lemma A.9 follows. Fix partial realization form (e, (e)) : e E([i] , ). Consider ( | ), equals expected marginal benefit portion[i] @ conditioned . Lemma A.9 allows us boundE [( | )] E [c ( | )] max ((e | ) /c(e)) ,eexpectations taken internal randomness , any. Note since0 0 know , E [c(E( , ))] k, expectationform [k]taken internal randomness . Hence E [c ( | )] k . followsE [( | )] k maxe ((e | ) /c(e)). definition -approximate greedy policy,obtains least (1/) maxe ((e | ) /c(e)) E [( | )] /k expected marginal benefit perunit cost step immediately following observation . Next take appropriate convex combination previous inequalitydifferent values . Letrandom partialrealization distributed p () := P = | . = (e, (e)) : e E([i] , )1(e | )favg ([i+1] ) favg ([i] ) Emaxec(e)E [( | )]Ekfavg ([i] @ ) favg ([i] )=k472fiA DAPTIVE UBMODULARITY: HEORY PPLICATIONSsimple rearrangement terms yields second inequality (A.3).define := favg ( ) favg ([i] ), (A.3) implies k(i i+1 ),11 `infer i+1 1 khence ` 1 k0 < e`/k 0 ,xlast inequality used fact 1 x < e x > 0. Thus favg ( ) favg ([`] ) <e`/k favg ( ) favg ([0] ) e`/k favg ( ) favg () > (1 e`/k )favg ( ).A.4 Min-Cost-Cover Objectivesection, provide arbitrary item cost generalizations Theorem 5.8 Theorem 5.9.item costs Adaptive Stochastic Minimum Cost Cover problem becomes one finding,quota utility Q,arg min cavg () f (E(, ), ) Q ,(A.4)cavg () := E [c(E(, ))]. Without loss generality, may take truncated version f ,namely (A, ) 7 min {Q, f (A, )}, rephrase Problem (A.4) findingarg min cavg () covers .(A.5)Hereby, recall covers E [f (E(, ), )] = f (E, ), expectationinternal randomness . consider Problem (A.5) remainder. also considerworst-case variant problem, replace expected cost cavg () objectiveworst-case cost cwc () := max c(E(, )).definition coverage (Definition 5.4 5.2 page 441) requires modification handle item costs. Note, however, coverage all-or-nothing sense covering realizationprobability less one count covering it. corollary itemswhose runs finished help coverage, whereas currently running items not. simpleexample, consider case E = {e}, c(e) = 2, f (A, ) = |A|, policy selectse terminates. [1] randomized policy probability 12 ,empty policy probability 12 , E [f (E(, ), )] = 12 < 1 = f (E, ) . Hence, eventhough half time [1] covers realizations, counted covering any.begin approximation guarantee average-case policy cost arbitrary itemcosts.Theorem A.11. Suppose f : 2E OE R0 adaptive submodular strongly adaptivemonotone respect p () exists Q f (E, ) = Q . Letvalue f (S, ) > Q implies f (S, ) = Q . Let = min p ()optimal policy minimizing expectedminimum probability realization. Let avgnumber items selected guarantee every realization covered. Let -approximategreedy policy respect item costs. generalQcavg () cavg (avg ) ln+1473fiG OLOVIN & K RAUSEselfcertifying instancesQ+1 .cavg () cavg (avg) lnNote range(f ) Z, = 1 valid choice, general selfcertifying ) (ln(Q/) + 1) cstances cavg () cavg (avgavg () cavg (avg ) (ln(Q) + 1),respectively.Proof. Consider running -approximate greedy policy completion, i.e., covers truerealization. starts v0 := E [f (, )] 0 reward expectation, terminates Qreward. Along way go sequence partial realizations specifying currentobservations, 0 1 ` , dom( ) \ dom( i1 ) consists precisely ithitem selected . call sequence trace = () . realization x R0 ,define (, x) partial realization seen achieved x reward expectation. Formally,(, x) arg max {| dom()| : (), E [f (dom(), ) | ] < x} .(A.6)Note (, x) exists x (v0 , Q], exists unique since two elementstrace equally large domains. Also note strong adaptive monotonicity f ,function 7 E [f (dom( ), ) | ] must nondecreasing trace 0 , 1 , . . . , ` .overall strategy bound expected cost cavg () bounding price paysper unit expected reward gained runs,integratingrun. Note Lemma A.9| /c | . -approximate greedytells us maxe ((e | ) /c(e)) avgavgpolicy obtains least 1/ rate. Hence may bound price, denote ,() c avg| / avg| .(A.7)Rather try bound expected price progresses time, bound expectedprice progresses expected reward obtains, measured E [f (dom(),) | ]| (, x) Q xcurrent partial realization. next claim avgx. Note E [f (dom( (, x)), ) | (, x)] < x definition (, x),, ), ) = Q since covers every realization. Since Q maximum possiblef (E(avgavg| (, x) < Q x generate violation strong adaptive monoreward, avg, 0 ), selecting dom( (, x))tonicity fixing 0 (, x), selecting E(avg| (, x) Q x, inferreduce expected reward. Thus avg| (, x)| (, x)c avgc avg( (, x)).(A.8)| (, x)QxavgNext, take expectation . Let (x) := E [( (, x))]. Let x1 , . . . , xr possiblevalues (, x). {{ : xi } : = 1, 2, . . . , r} partitions set realizations,rXXE c avg| (, x)=P [ xi ]p ( | xi ) c avg|i=1=X(A.9)p () cavg|(A.10)= cavg (avg)474(A.11)fiA DAPTIVE UBMODULARITY: HEORY PPLICATIONSfollows(x))cavg (avg.Qx(A.12)Let cavg (, Q0 ) denote expected cost obtain expected reward Q0 . bound cavg (, Q0 )Z Q0Z Q0cavg ( )Qcavg (, Q0 ) =(x)dxdx = cavg ( ) ln.(A.13)QxQ Q0x=0x=0use slightly different analyses general instances selfcertifying instances.begin general instances. these, set Q0 = Q use refined argumentbound cost getting remaining expected reward. Fix dom() 0 .say covers 0 covers 0 time observes . definition , 0covered Q E [f (dom(), ) | ] . Hence last item selects, sayupon observing , must increase conditional expected value E [f (dom(), ) | ]Q Q. Eq. (A.8), follows x [Q , Q],| (, x)| (, x)c avgc avg( (, x)).| (, x)avg)/ x [Qbefore, may take expectation obtain (x) cavg (avg, Q]. fact together Eq. (A.13) yieldcavg () cavg (, Q) = cavg (, Q ) +RQx=Qcavg ( ) ln (Q/) +E [(x)] dxRQx=Qcavg ( )dx= cavg ( ) (ln (Q/) + 1)completes proof general instances.selfcertifying instances use similar argument. instances set Q0 = Q ,argue last item selects must increase conditional expected valueQ Q. suppose currently observes , achieved conditional value Q,i.e., E [f (dom(), ) | ] < Q. uncovered. Since instance selfcertifying, every f (dom(), ) < f (E, ) = Q. definition ,f (dom(), ) Q , implies E [f (dom(), ) | ]Q . Reasoning analogously general instances, may derive (x)R)/ x [Q , Q]. Computing c () = c (, Q0 ) + Qcavg (avgavgavgx=Q0 E [(x)] dxgives us claimed approximation ratio selfcertifying instances, completesproof.Next consider worst-case cost. generalize Theorem 5.9 incorporating arbitrary itemcosts.Theorem A.12. Suppose f : 2E OE R0 adaptive monotone adaptive submodularrespect p (), let value f (S, ) > f (E, ) implies f (S, ) = f (E, ). Let = min p () minimum probability realization. Let wcoptimal policy minimizing worst-case cost cwc () guaranteeing every realization475fiG OLOVIN & K RAUSEcovered. Let -approximate greedy policy respect item costs. Finally, letQ := E [f (E, )] maximum possible expected reward.Q+1 .cwc () cwc (wc ) ln), let ` = k ln (Q/),Proof. Let -approximate greedy policy. Let k = cwc (wcapply Theorem A.10 parameters yield`/kfavg ([`] ) > 1 efavg (wc ) = 1favg (wc).(A.14)Qcovers every realization assumption, f ( ) = E [f (E, )] = Q, rearrangingSince wcavg wcterms Eq. (A.14) yields Q favg ([`] ) < . Since favg ([`] ) favg ([`] ) adaptivemonotonicity f , follows Q favg ([`] ) < . definition ,covered [`] Q favg ([`] ) . Thus Q favg ([`] ) < implies Q favg ([`] ) =0, meaning [`] covers every realization.next claim [`] worst-case cost ` + k. sufficient showfinal item executed [`] cost k realization. prove, followscovers every realization costfacts -approximate greedy policy wck. data dependent bound, Lemma A.9 page 470, guarantees| )| )(e | )(wc(wcmax.(A.15)| )ec(e)c (wck| ). SupposingSuppose dom(). would like say maxe (e | ) (wc| ) /k, hencetrue, item e cost c(e) > k must (e | ) /c(e) < (wccannot selected -approximate greedy policy upon observing Eq. (A.15), thusfinal item executed [`] cost k realization. next show| ). Towards end, note Lemma A.13 impliesmaxe (e | ) (wcmax (e | ) E [f (E, ) | ] E [f (dom(), ) | ] .e(A.16)| ) suffices showprove maxe (e | ) (wcE [f (E, ) | ] E [f (E(wc, ) dom(), ) | ] .(A.17)Proving Eq. (A.17) quite straightforward f strongly adaptive monotone. Given fadaptive monotone, requires additional effort. fix E let nonadaptive policy selects items arbitrary order. Let P := { : dom() = A}.P obtainApply Lemma A.13 0 = @wcE [f (E(wc, ) A, ) | ] E [f (E, ) | ] .(A.18)P, ) A, ) | ] = f ( @ ) f ( ) =Note P P [ ] E [f (E(wcavgavg wcwcPE [f (E, )]. Since know E [f (E, )] = P P [ ] E [f (E, ) | ], averagingargument together Eq. (A.18) implies PE [f (E(wc, ) A, ) | ] = E [f (E, ) | ] .476(A.19)fiA DAPTIVE UBMODULARITY: HEORY PPLICATIONSSince arbitrary partial realization dom() = A, E arbitrary,fix dom() let = dom(). settings, Eq. (A.19) implies Eq. (A.17),| ), thus -approximate greedy policy never selectthus maxe (e | ) (wc). Hence c (item cost exceeding k, k = cwc (wcwc [`] ) cwc ([`] ) k,cwc ([`] ) ` + k. completes proof.Lemma A.13. Fix adaptive monotone submodular objective f . policydom()E [f (E(, ), ) | ] E [f (E, ) | ] .Proof. Augment new policy 0 follows. Run completion, let 0 partialrealization consisting states observed. 0 , proceed selectremaining items E order. Otherwise, * 0 terminate.E [f (E(, ), ) | ] E f (E( 0 , ), ) | = E [f (E, ) | ] (A.20)inequality repeated application adaptive monotonicity f , equalityconstruction.5.2 described result Feige (1998) implies polynomial time(1 ) ln (Q/) approximation algorithm selfcertifying instances Adaptive Stochastic MinCost Cover, unless NP DTIME(nO(log log n) ). show related result general instances.Lemma A.14. every constant > 0, (1 ) ln (Q/) polynomial time approximation algorithm general instances Adaptive Stochastic Min Cost Cover, either averagecase objective cavg () worst-case objective cwc (), unless NP DTIME(nO(log log n) ).Proof. offer reduction Set Cover problem. Fix Set Cover instance groundset U sets {S1 , S2 , . . . , Sm } 2U unit-cost sets. Fix Q, 1/QQ/ positive integers,= |U |. Let E := {S1 , S2 , . . . , Sm }, set costitem one. Partition U 1/ disjoint, equally sized subsets U1 , U2 , . . . , U1/ . Constructrealization Ui . Let set states = {NULL}. Hence (e) = NULLe, knowledge true realization revealed selecting items. useuniform distribution realizations, i.e., p (i ) = i. Finally, objective f (C, ) :=| SC (S Ui )|, i.e., number elements Ui cover sets C. Since |O| = 1,every realization consistent every possible partial realization . Hence ,E [f (dom(), ) | ] = f(dom()), f(C) = | SC S| objective functionoriginal set cover instance. Since f submodular, f adaptive submodular. Likewise, sincef monotone, |O| = 1, f strongly adaptive monotone. Now, cover realization,must obtain maximum possible value realizations, means selecting collectionsets C SC = U . Conversely, C SC = U clearly covers f .Hence instance Adaptive Stochastic Min Cost Cover, either average case objectivecavg () worst-case objective cwc (), equivalent original Set Cover instance. Therefore,result Feige (1998) implies polynomial time algorithm obtaining(1 ) ln |U | = (1 ) ln (Q/) approximation Adaptive Stochastic Min Cost Cover unlessNP DTIME(nO(log log n) ).477fiG OLOVIN & K RAUSEA.5 Min-Sum Objectivesection prove Theorem 5.10, appears page 445, case itemsarbitrary costs. proof resembles analogous proof Streeter Golovin (2007)non-adaptive min-sum submodular cover problem, and, like proof, ultimately derivesextremely elegant performance analysis greedy algorithm min-sum set cover due Feigeet al. (2004).objective function c () generalized arbitrary cost items uses strict truncation8 [t]place [t] unit-cost definition:c () :=XXXE [f (E, )] favg ([t] ) =p ()f (E, ) f (E([t] , ), ) .t=0t=0(A.21)prove -approximate greedy policy achieves 4-approximation minsum objective, i.e., c () 4 c ( ) policies . so, require followinglemma.Lemma A.15. Fix -approximate greedy policyadaptive monotone submodularfunction f let si := favg ([i+1] ) favg ([i] ) . policy nonnegative integers)fk, favg ([k]avg ([i] ) + k si .) f (Proof. Fix , , i, k. adaptive monotonicity favg ([k]avg [i] @[k] ). next aimprovefavg ([i] @[k]) favg ([i] ) + k si(A.22)sufficient complete proof. Towards end,fix partial realization| , equals expectedform (e, (e)) : e E([i] , ) . Consider [k]portionmarginal benefit [k][i] @[k] conditioned . Lemma A.9 allows usboundhh(e | )E [k] |E c [k] | max,ec(e)expectationsh takeninternal randomness , any. Note, )) k, expectation taken internal, E c(E([k]hh. Hence E c ||randomness [k]k . follows E [k][k]k maxe ((e | ) /c(e)). definition -approximate greedy policy, obtains leasth(1/) max ((e | ) /c(e)) E [k]| /k(A.23)eexpected marginal benefit per unit cost step immediately following observation . Nexttake appropriate convex combination previous inequality differentvalues .Let random partial realization distributed (e, (e)) : e E([i] , ) . taking8. See Definition A.2 page 469.478fiA DAPTIVE UBMODULARITY: HEORY PPLICATIONSFigure 6: illustration inequalityRx=0 h(x)dxPi0 xi (yiyi+1 ).expectation Eq. (A.23) yieldsh|) f (E [k]favg ([i] @[k]avg [i] )favg ([i+1] ) favg ([i] ) E=.kk(A.24)Multiplying Eq. (A.24) k, substituting si = favg ([i+1] ) favg ([i] ) , conclude)f (ksi favg ([i] @[k]avg [i] ) immediately yields Eq. (A.22) concludes proof.Using Lemma A.15, together geometric argument developed Feige et al. (2004),prove Theorem 5.10.Proof Theorem 5.10: Let Q := E [f (E, )] maximum possible expected reward,expectationgreedy policy. Define Ri :=taken w.r.t. p (). Let-approximatePiQ favg [i] define Pi := Q favg [i] . Let xi := 2s,let yi := R2i , let h(x) :=). claim fQ favg ([x]avg [i] favg [i] Pi Ri . clearly holds [i]empty policy, otherwise always select item contributes zero marginal benefit,namely item already played previously. Hence -approximate greedypolicynever select items negative expected marginal benefit, favg [i] favg [i] .Lemma A.15, favg [xfavg [i] + xi si . Thereforei]PiRih(xi ) Q favg ([i] ) xi si = Pi= yi(A.25)22similar reasons favg [i] favg [i] , favg [i1] favg [i] ,sequence hy1 , y2 , . . .i non-increasing. adaptive monotonicity adaptive submodular ) >ity f imply h(x) non-increasing. Informally, otherwise, favg ([x]favg ([x+1]) x, optimal policy must sacrificing immediate rewards time xexchange greater returns later, shown strategy optimal,adaptivesubmodularitycannot hold. Eq. (A.25) monotonicity h 7 yi implyRPh(x)dxx(yi yi+1 ) (see Figure 6). left hand side lower bound c ( ),i0x=01 P1si = (Ri Ri+1 ) right hand side simplifies 4i0 Pi = 4 c (), provingc () 4 c ( ).479fiG OLOVIN & K RAUSEA.6 Symbol TableE, e EO,,pp( | )E(, )(e | )( | )[e/o]k[k][k][k]@ 0ffavgccavgcwccc ( | )Q1PGround set items, individual item.States item may in, outcomes selecting item, individualstate/outcome.realization, i.e., function items states.partial realization, typically encoding current set observations;E partial mapping items states.random realization random partial realization, respectively.consistency relation: means (e) = (e) e dom().probability distribution realizations.conditional distribution realizations: p( | ) := P [ = | ].policy, maps partial realizations items.set items selected run realization .conditional expected marginal benefit e conditioned :(e | ) := E [f (dom() {e} , ) f (dom(), ) | ].conditional expected marginal benefit policy conditioned :( | ) := E [f (dom() E(, ), ) f (dom(), ) | ].Shorthand {(e, o)}.Budget cost selected item sets.truncated policy. See Definition 5.1 page 439 (unit costs) Definition A.4page 469.strictly truncated policy. See Definition A.2 page 469.laxly truncated policy. See Definition A.3 page 469.Policies 0 concatenated together. See Definition A.6 page 469.objective function, type f : 2E OE R0 unless stated otherwise.Average benefit: favg () := E [f (E(, ), )].PItem costs c : E N. Extended sets via c(S) := eS c(e).Average cost policy: cavg () := E [c(E(, ))].Worst-case cost policy: cwc () := max c(E(, )).PMin-sum cost policy: c () :=t=0 E [f (E, )] favg ([t] ) .Conditional average policy cost: c ( | ) := E [c(E(, )) | ].Approximation factor greedy optimization -approximate greedy policy.Benefit quota. Often Q = E [f (E, )].Coverage gap: = sup { 0 : f (S, ) > Q 0 implies f (S, ) Q S, }.indicator proposition P , equals one P true zero P false.Table 2: Important symbols notations used article480fiA DAPTIVE UBMODULARITY: HEORY PPLICATIONSA.7 Proof Approximation Hardness Absence Adaptive Submodularityprovide proof Theorem 12.1 whose statement appears page 464 12.Proof Theorem 12.1: construct hard instance based following intuition. makealgorithm go treasure hunting. set locations {0, 1, , . . . , 1}, treasureone locations, algorithm gets unit reward finds it, zero reward otherwise.maps, consisting cluster bits, purporting indicatetreasure is, map stored (weak) secret-sharing way, querying bitsmap reveals nothing says treasure is. Moreover, one mapsfake, puzzle indicating map correct one indicating treasures location.Formally, fake map one probabilistically independent location treasure,conditioned puzzle.instance three types items, E = ET ] EM ] EP , |ET | = encodestreasure is, |EM | = ms encodes maps, |EP | = n3 encodes puzzle,m, t, n specified below. outcomes binary, = {0, 1}, identifyitems bit indices. Accordingly say (e) value bit e. e EM EP ,P [(e) = 1] = .5 independently. conditional distribution (ET ) given (EM EP )deterministic specified below. objective function f linear, defined follows:f (A, ) = |{e ET : (e) = 1}|.` suitWe describe puzzle, compute i(P ) := (perm(P ) mod p) Pmod 2Qable random matrix P , suitable prime p integer `, perm(P ) = Sn ni=1 Pi(i)permanent P . exploit Theorem 1.9 Feige Lund (1997) showexist constants , > 0 randomized polynomial time algorithm compute(perm(P ) mod p) mod 2` correctly probability 2` (1+1/n ), P drawn uniformlyrandom {0, 1, 2, . . . , p 1}nn , p prime superpolynomial n, ` p 12 ,PH = = P2 . encode puzzle, fix prime p [2n2 , 2n1 ] use n3 bits(EP ) sample P = P () (nearly) uniformlyrandom {0, 1, 2, . . . , p 1}nn follows.Pmatrix P Znn , let rep(P ) := ij Pij p(i1)n+(j1) define base p representationP . Note rep() one-to-one n n matrices entries Zp , define inverse3rep1 (). encodingP () kinterprets bits (EP ) integer x [2n ], computes = xj2322mod (pn ). x 2n /pn pn , P = rep1 (y). Otherwise, P zero matrix.232latter event occurs probability pn /2n 2n , case simply suppose2algorithm consideration finds treasure gets unit reward. adds 2nexpected reward. let us assumeU P drawn uniformly random.Next consider maps. Partition EM =i=1 Mi maps Mi , consistingitems. map Mi , partition items s/ log2 groups log2 bits each, bitsgroup encode log2 bit binary string. Let vi {0, 1, . . . , 1} XORs/ log2 binary strings, interpreted integer (using fixed encoding). say Mi pointsvi location treasure. priori, vi uniformly distributed {0, ..., 1}.particular realization (EP EM ), define v() := vi(P ()) . set v() locationtreasure realization , i.e., label ET = {e0 , e1 , . . . , et1 } ensure (ej ) = 1j = vi(P ()) , (e) = 0 e ET . Note random variable v = v() distributeduniformly random {0, 1, . . . , 1}. Note still holds condition realizations481fiG OLOVIN & K RAUSEset s/ log2 1 items map, case still least one group whosebits remain completely unobserved.consider optimal policy budget k = n3 + + 1 items pick. Clearly,reward 1. However, given budget k, computationally unconstrained policyexhaustively sample EP , solve puzzle (i.e., compute i(P )), read correct map (i.e., exhaustively sample Mi(P ) ), decode map (i.e., compute v = vi(P ) ), get treasure (i.e., pick ev )thereby obtaining reward one.give upper bound expected reward R randomized polynomial timealgorithm budget k items, assuming P2 6= PH. Fix small constant > 0, set= n3 = = n1/ . suppose give realizations (EM ) free. also replacebudget k items budget k specifically map items EM additionalbudget k specifically treasure locations ET . Obviously, help it.noted, selects less s/ log2 bits map Mi(P ) indicated P , distributionvi(P ) conditioned realizations still uniform. course, knowledge vi 6= i(P )useless getting reward. Hence try k log2 (t)/s = o(k) maps attemptfind Mi(P ) . Note randomized algorithm given random P drawn{0, 1, 2, . . . , p 1}nn always outputs set integers size P [i(P ) S] q,use construct randomized algorithm that, given P , outputs integer xP [i(P ) = x] q/, simply running first algorithm selecting random item S.find Mi(P ) , distribution treasures location uniform given knowledge.Hence budget k treasure locations earn expected reward k/t. Armedobservations Theorem 1.9 work Feige Lund (1997) complexity2theoretic assumptions, infer E [R] o(k) 2` (1 + 1/n ) + k/t + 2n . Since = n3= = n1/ = (1) = 1 ` = log2 k = n3 + + 1 = 2n3 + 1,E [R]k(1 + o(1)) = 2n31/ (1 + o(1)).Next note |E| = + ms + n3 = n3+1/ (1 + o(1)). Straightforward algebra showsorder ensure E [R] = o(/|E|1 ), suffices choose /6. Thus, complexitytheoretic assumptions, polynomial time randomized algorithm budget k achieveso(/|E|1 ) value obtained optimal policy budget k, approximationratio (|E|1 /).ReferencesAlon, N., Awerbuch, B., Azar, Y., Buchbinder, N., & Naor, J. S. (2009). online set coverproblem. SIAM Journal Computing, 39, 361370.Arkin, E. M., Meijer, H., Mitchell, J. S. B., Rappaport, D., & Skiena, S. S. (1993). Decision treesgeometric models. Proceedings Symposium Computational Geometry, pp. 369378,New York, NY, USA. ACM.Asadpour, A., Nazerzadeh, H., & Saberi, A. (2008). Stochastic submodular maximization. WINE08: Proceedings 4th International Workshop Internet Network Economics, pp.477489, Berlin, Heidelberg. Springer-Verlag.Bellala, G., & Scott, C. (2010). Modified group generalized binary search near-optimal performance guarantees. Tech. rep., University Michigan.482fiA DAPTIVE UBMODULARITY: HEORY PPLICATIONSBrochu, E., Cora, M., & de Freitas, N. (2009). tutorial Bayesian optimization expensive costfunctions, application active user modeling hierarchical reinforcement learning.Tech. rep. TR-2009-23, Department Computer Science, University British Columbia.Buchbinder, N., & Naor, J. S. (2009). design competitive online algorithms via primaldualapproach. Foundations Trends Theoretical Computer Science, 3, 93263.Chakaravarthy, V. T., Pandit, V., Roy, S., Awasthi, P., & Mohania, M. (2007). Decision treesentity identification: Approximation algorithms hardness results. ProceedingsACM-SIGMOD Symposium Principles Database Systems.Chan, C. W., & Farias, V. F. (2009). Stochastic depletion problems: Effective myopic policiesclass dynamic optimization problems. Mathematics Operations Research, 34(2), 333350.Cohn, D. A., Gharamani, Z., & Jordan, M. I. (1996). Active learning statistical models. JournalArtificial Intelligence Research (JAIR), 4, 129145.Dantzig, G. B. (1955). Linear programming uncertainty. Management Science, 1, 197206.Dasgupta, S. (2004). Analysis greedy active learning strategy. NIPS: Advances NeuralInformation Processing Systems 17, pp. 337344. MIT Press.Dean, B., Goemans, M., & Vondrak, J. (2005). Adaptivity approximation stochastic packingproblems. Proceedings 16th ACM-SIAM Symposium Discrete Algorithms,, pp.395404.Dean, B., Goemans, M., & Vondrak, J. (2008). Approximating stochastic knapsack problem:benefit adaptivity. Mathematics Operations Research, 33, 945964.Deshpande, A., Guestrin, C., Madden, S., Hellerstein, J., & Hong, W. (2004). Model-driven dataacquisition sensor networks. Proceedings International Conference LargeData Bases (VLDB), pp. 588599.Feige, U. (1998). threshold ln n approximating set cover. Journal ACM, 45(4), 634652.Feige, U., Lovasz, L., & Tetali, P. (2004). Approximating min sum set cover. Algorithmica, 40(4),219234.Feige, U., & Lund, C. (1997). hardness computing permanent random matrices.Computational Complexity, 6(2), 101132.Fujishige, S. (2005). Submodular functions optimization (2nd edition)., Vol. 58. AnnalsDiscrete Mathematics, North Holland, Amsterdam.Garey, M. R., & Graham, R. L. (1974). Performance bounds splitting algorithm binarytesting. Acta Informatica, 3, 347355.Gittins, J. C., & Jones, D. M. (1979). dynamic allocation index discounted multiarmedbandit problem. Biometrika, 66(3), 561565.Goemans, M. X., & Vondrak, J. (2006). Stochastic covering adaptivity. Proceedings 7thInternational Latin American Symposium Theoretical Informatics, pp. 532543.483fiG OLOVIN & K RAUSEGolovin, D., Gupta, A., Kumar, A., & Tangwongsan, K. (2008). All-norms all-Lp -normsapproximation algorithms. Hariharan, R., Mukund, M., & Vinay, V. (Eds.), IARCS Annual Conference Foundations Software Technology Theoretical Computer Science(FSTTCS 2008), Dagstuhl, Germany. Schloss Dagstuhl - Leibniz-Zentrum fuer Informatik,Germany.Golovin, D., & Krause, A. (2010). Adaptive submodularity: new approach active learningstochastic optimization. 23rd Annual Conference Learning Theory, pp. 333345.Golovin, D., & Krause, A. (2011). Adaptive submodular optimization matroid constraints.CoRR, abs/1101.4450.Golovin, D., Krause, A., Gardner, B., Converse, S. J., & Morey, S. (2011). Dynamic resourceallocation conservation planning. AAAI 11: Proceedings TwentyFifth AAAIConference Artificial Intelligence, pp. 13311336. AAAI Press.Golovin, D., Krause, A., & Ray, D. (2010). Near-optimal Bayesian active learning noisyobservations. NIPS: Advances Neural Information Processing Systems 23, pp. 766774.Goundan, P. R., & Schulz, A. S. (2007). Revisiting greedy approach submodular set functionmaximization. Tech. rep., Massachusetts Institute Technology.Grunewalder, S., Audibert, J.-Y., Opper, M., & Shawe-Taylor, J. (2010). Regret bounds Gaussianprocess bandit problems. Proceedings 13th International Conference ArtificialIntelligence Statistics.Guha, S., & Munagala, K. (2009). Multi-armed bandits metric switching costs. ProceedingsInternational Colloquium Automata, Languages Programming (ICALP).Guha, S., Munagala, K., & Shi, P. (2009). Approximation algorithms restless bandit problems.Tech. rep. 0711.3861v5, arXiv.Guillory, A., & Bilmes, J. (2009). Average-case active learning costs. 20th InternationalConference Algorithmic Learning Theory, University Porto, Portugal.Guillory, A., & Bilmes, J. (2010). Interactive submodular set cover. Proceedings International Conference Machine Learning (ICML), No. UWEETR-2010-0001, Haifa, Israel.Guillory, A., & Bilmes, J. A. (2011). Simultaneous learning covering adversarial noise.International Conference Machine Learning (ICML), Bellevue, Washington.Gupta, A., Krishnaswamy, R., Nagarajan, V., & Ravi, R. (2010). Approximation algorithmsoptimal decision trees adaptive TSP problems. Proceedings International Colloquium Automata, Languages Programming (ICALP), Vol. 6198 Lecture NotesComputer Science, pp. 690701. Springer.Gupta, A., Pal, M., Ravi, R., & Sinha, A. (2005). Wednesday? Approximation algorithms multistage stochastic optimization. Proceedings 8th International Workshop Approximation Algorithms Combinatorial Optimization Problems (APPROX).Jones, D. R., Schonlau, M., & Welch, W. J. (1998). Efficient global optimization expensiveblack-box functions. Journal Global Optimization, 13, 455492.Kaplan, H., Kushilevitz, E., & Mansour, Y. (2005). Learning attribute costs. Proceedings37th ACM Symposium Theory Computing, pp. 356365.484fiA DAPTIVE UBMODULARITY: HEORY PPLICATIONSKempe, D., Kleinberg, J., & Tardos, E. (2003). Maximizing spread influence socialnetwork. KDD 03: Proceedings ninth ACM SIGKDD international conferenceKnowledge discovery data mining, pp. 137146, New York, NY, USA. ACM.Kosaraju, S. R., Przytycka, T. M., & Borgstrom, R. S. (1999). optimal split tree problem.Proceedings 6th International Workshop Algorithms Data Structures, pp.157168, London, UK. Springer-Verlag.Krause, A., & Guestrin, C. (2005). Near-optimal nonmyopic value information graphicalmodels. Proceedings Uncertainty Artificial Intelligence (UAI).Krause, A., & Guestrin, C. (2007). Near-optimal observation selection using submodular functions.Conference Artificial Intelligence (AAAI) Nectar track, pp. 16501654.Krause, A., & Guestrin, C. (2009a). Intelligent information gathering submodular functionoptimization. Tutorial International Joint Conference Artificial Intelligence.Krause, A., & Guestrin, C. (2009b). Optimal value information graphical models. JournalArtificial Intelligence Research (JAIR), 35, 557591.Leskovec, J., Krause, A., Guestrin, C., Faloutsos, C., VanBriesen, J., & Glance, N. (2007). Costeffective outbreak detection networks. KDD 07: Proceedings 13th ACM SIGKDDinternational conference Knowledge discovery data mining, pp. 420429, New York,NY, USA. ACM.Littman, M., Goldsmith, J., & Mundhenk, M. (1998). computational complexity probabilisticplanning. Journal Artificial Intelligence Research, 9, 136.Liu, Z., Parthasarathy, S., Ranganathan, A., & Yang, H. (2008). Near-optimal algorithms sharedfilter evaluation data stream systems. SIGMOD 08: Proceedings 2008 ACMSIGMOD international conference Management data, pp. 133146, New York, NY,USA. ACM.Lizotte, D., Wang, T., Bowling, M., & Schuurmans, D. (2007). Automatic gait optimizationGaussian process regression. Proceedings Twentieth International Joint ConferenceArtificial Intelligence (IJCAI), pp. 944949.Loveland, D. W. (1985). Performance bounds binary testing arbitrary weights. Acta Informatica, 22(1), 101114.McCallum, A., & Nigam, K. (1998). Employing EM pool-based active learning text classification. Proceedings International Conference Machine Learning (ICML), pp.350358.Minoux, M. (1978). Accelerated greedy algorithms maximizing submodular set functions.Proceedings 8th IFIP Conference Optimization Techniques, pp. 234243. Springer.Munagala, K., Babu, S., Motwani, R., Widom, J., & Thomas, E. (2005). pipelined set coverproblem. Proceedings Intl. Conf. Database Theory, pp. 8398.Nemhauser, G. L., Wolsey, L. A., & Fisher, M. L. (1978). analysis approximations maximizing submodular set functions - I. Mathematical Programming, 14(1), 265294.Nowak, R. (2009). Noisy generalized binary search. NIPS: Advances Neural InformationProcessing Systems 22, pp. 13661374.485fiG OLOVIN & K RAUSEPapadimitriou, C. H., & Tsitsiklis, J. N. (1987). complexity Markov decision processses.Mathematics Operations Research, 12(3), 441450.Pineau, J., Gordon, G., & Thrun, S. (2006). Anytime point-based approximations largePOMDPs. Journal Artificial Intelligence Research (JAIR), 27, 335380.Raz, R., & Safra, S. (1997). sub-constant errorprobability lowdegree test, subconstanterror-probability PCP characterization NP. STOC 97: Proceedings twenty-ninthannual ACM Symposium Theory Computing, pp. 475484, New York, NY, USA. ACM.Ross, S., Pineau, J., Paquet, S., & Chaib-draa, B. (2008). Online planning algorithms POMDPs.Journal Artificial Intelligence Research, 32, 663704.Schrijver, A. (2003). Combinatorial optimization : polyhedra efficiency. Volume B, Part IV,Chapters 39-49. Springer.Sebastiani, P., & Wynn, H. P. (2000). Maximum entropy sampling optimal Bayesian experimental design. Journal Royal Statistical Society, Series B, 62(1), 145157.Smallwood, R., & Sondik, E. (1973). optimal control partially observable Markov decisionprocesses finite horizon. Operations Research, 21, 10711088.Srinivas, N., Krause, A., Kakade, S., & Seeger, M. (2010). Gaussian process optimizationbandit setting: regret experimental design. Proceedings International Conference Machine Learning (ICML).Streeter, M., & Golovin, D. (2007). online algorithm maximizing submodular functions.Tech. rep. CMU-CS-07-171, Carnegie Mellon University.Streeter, M., & Golovin, D. (2008). online algorithm maximizing submodular functions.NIPS: Advances Neural Information Processing Systems 21, pp. 15771584.Wolsey, L. A. (1982). analysis greedy algorithm submodular set covering problem.Combinatorica, 2(4), 385393.486fiJournal Artificial Intelligence Research 42 (2011) 275-308Submitted 05/11; published 11/11Revisiting Centrality-as-Relevance:Support Sets Similarity Geometric ProximityRicardo Ribeiroricardo.ribeiro@inesc-id.ptInstituto Universitario de Lisboa (ISCTE-IUL)Av. das Forcas Armadas, 1649-026 Lisboa, PortugalL2F - INESC ID LisboaRua Alves Redol, 9, 1000-029 Lisboa, PortugalDavid Martins de Matosdavid.matos@inesc-id.ptInstituto Superior Tecnico, Universidade Tecnica de LisboaAv. Rovisco Pais, 1049-001 Lisboa, PortugalL2F - INESC ID LisboaRua Alves Redol, 9, 1000-029 Lisboa, PortugalAbstractautomatic summarization, centrality-as-relevance means importantcontent information source, collection information sources, correspondscentral passages, considering representation notion makes sense(graph, spatial, etc.). assess main paradigms, introduce new centrality-basedrelevance model automatic summarization relies use support setsbetter estimate relevant content. Geometric proximity used compute semanticrelatedness. Centrality (relevance) determined considering whole input source(and local information), taking account existence minor topicslateral subjects information sources summarized. method consistscreating, passage input source, support set consistingsemantically related passages. Then, determination relevant contentachieved selecting passages occur largest number support sets.model produces extractive summaries generic, language- domainindependent. Thorough automatic evaluation shows method achieves state-of-theart performance, written text, automatically transcribed speech summarization,including compared considerably complex approaches.1. Introductionsummary conveys end user relevant content one informationsources, concise comprehensible manner. Several difficulties arise addressingproblem, one utmost importance assess significant content. Usually, approaches vary complexity processing text speech. text summarization, up-to-date systems make use complex information, syntactic (Vanderwende,Suzuki, Brockett, & Nenkova, 2007), semantic (Tucker & Sparck Jones, 2005), discourseinformation (Harabagiu & Lacatusu, 2005; Uzeda, Pardo, & Nunes, 2010), either assessrelevance reduce length output, common approaches speech summarizationtry cope speech-related issues using speech-specific information (for example,prosodic features, Maskey & Hirschberg, 2005, recognition confidence scores, Zechner& Waibel, 2000) improving intelligibility output automatic speechc2011AI Access Foundation. rights reserved.fiRibeiro & de Matosrecognition system (by using related information, Ribeiro & de Matos, 2008a). fact,spoken language summarization often considered much harder task text summarization (McKeown, Hirschberg, Galley, & Maskey, 2005; Furui, 2007): problems like speechrecognition errors, disfluencies, accurate identification sentence boundariesincrease difficulty determining salient information, also constrainapplicability text summarization techniques speech summarization (althoughpresence planned speech, partly happens broadcast news domain, portability feasible, Christensen, Gotoh, Kolluru, & Renals, 2003). Nonetheless, shallowtext summarization approaches Latent Semantic Analysis (LSA) (Landauer, Foltz,& Laham, 1998; Gong & Liu, 2001) Maximal Marginal Relevance (MMR) (Carbonell& Goldstein, 1998) seem achieve performances comparable ones using specificspeech-related features (Penn & Zhu, 2008).Following determination relevant content, summary must composedpresented user. identified content consists passages found inputsource glued together form summary, summary usually designatedextract; hand, important content devised series conceptsfused smaller set used generate new, concise, informative text, presence abstract. extraction concept-to-textgeneration, especially text summarization, text-to-text generation methods, relytext rewritingparaphrasing, sentence compression major representative, becoming up-to-date subject (Cohn & Lapata, 2009). Given hardnessabstraction, bulk work area consists extractive summarization.common family approaches identification relevant contentcentrality family. methods base detection salient passagesidentification central passages input source(s). One main representatives family centroid-based summarization. Centroid-based methods buildidea pseudo-passage represents central topic input source (the centroid )selecting passages (x) included summary ones close centroid. Pioneer work (on multi-document summarization) Radev, Hatzivassiloglou,McKeown (1999) Radev, Jing, Budzikowska (2000) creates clusters documentsrepresenting document tf-idf vector; centroid cluster also definedtf-idf vector, coordinates corresponding weighted average tf-idfvalues documents cluster; finally, sentences contain words centroids presumably best representatives topic cluster, thusbest candidates belonging summary.centrality(x) = similarity(x, centroid)(1)Another approach centrality estimation compare candidate passage everypassage (y) select ones higher scores (the ones closer everypassage). One simple way represent passages vectors usingweighting scheme like aforementioned tf-idf ; then, passage similarity assessedusing, instance, cosine, assigning passage centrality score definedEq. 2.1 Xcentrality(x) =similarity(x, y)(2)N276fiRevisiting Centrality-as-Relevancescores used create sentence ranking: sentences highest scoresselected create summary.major problem relevance paradigm taking account entireinput source manner, either estimate centroids average distances input sourcepassages, may selecting extracts central input source are, however,relevant ones. cognitive terms, information reduction techniquessummarization process quite close discourse understanding process (EndresNiggemeyer, 1998), which, certain level, works applying rules help uncoveringmacrostructure discourse. One rules, deletion, used eliminateunderstanding process propositions relevant interpretationsubsequent ones. means common find, input sourcessummarized, lateral issues considerations relevant devise salientinformation (discourse structure-based summarization based relevance nucleartext segments, Marcu, 2000; Uzeda et al., 2010), may affect centrality-basedsummarization methods inducing inadequate centroids decreasing scoressuitable sentences.argued previous work (Gong & Liu, 2001; Steyvers & Griffiths, 2007), alsoassume input sources mixtures topics, propose address aspect usinginput source guidance. associating passage input sourcesupport set consisting semantically related passages inputsource, groups related passages uncovered, one constituting latent topic (theunion supports sets whose intersection empty). creation supportsets, semantic relatedness assessed geometric proximity. Moreover, similar workusually explores different weighting schemes address specific issues taskresearch (Orasan, Pekar, & Hasler, 2004; Murray & Renals, 2007; Ribeiro & de Matos,2008b), explore different geometric distances similarity measures, analyzingperformance context (the impact different metrics theoretical empiricalperspectives clustering setting shown Aggarwal, Hinneburg, & Keim, 2001).build summary, select sentences occur largest number support setshence, central sentences, without problem affects previous centrality-basedsummarization.method produces generic, language- domain-independent summaries, lowcomputational requirements. test approach speech text data. empirical evaluation model text data, used experimental setup previously usedpublished work (Mihalcea & Tarau, 2005; Antiqueira, Oliveira Jr., da Fontoura Costa, &Nunes, 2009), enabled informative comparison existing approaches.concerns speech experiments, also used corpus collected previous work (Ribeiro& de Matos, 2008a), well published results. allowed us compare modelstate-of-the-art work.rest document structured follows: Section 2, analyze representative models centrality-as-relevance approachespassage-to-centroid similarity-basedcentrality pair-wise passage similarity-based centrality; Section 3 describes supportsets-based relevance model; evaluation model presented Section 4,compare performance centrality-as-relevance models discussachieved results; final remarks conclude document.277fiRibeiro & de Matos2. Centrality-as-Relevancetwo main approaches centrality-based summarization: passage-to-centroidsimilarity pair-wise passage similarity.2.1 Passage-to-Centroid Similarity-based Centralitycentroid-based summarization, passage centrality defined similaritypassage pseudo-passage that, considering geometrical representation inputsource, center space defined passages input source, centroid.work multi-document summarization Radev et al. (1999, 2000) Radev, Jing,Stys, Tam (2004) work developed Lin Hovy (2000) examplesapproach.Radev et al. present centroid-based multi-document summarizer (MEAD)input cluster documents. Associated cluster documents centroid.Documents represented vectors tf-idf weights centroid clusterconsists vector coordinates weighted averages tf-idf valuesdocuments cluster, pre-defined threshold. Thus, centroid clusterdocuments is, case, pseudo-document composed terms statisticallyrelevant. Given cluster documents segmented sentences , {s1 , s2 , . . . , sN },centroid C, compression rate, summarization done selecting appropriatenumber (according compression rate) sentences highest scores assignedlinear function (Eq. 3) following features: centroid value (Ci ), position value(Pi ), first-sentence overlap value (Fi ).score(si ) = wc Ci + wp Pi + wf Fi ,1iN(3)Pcentroid value, defined Ci = tsi Ct,i , establishes sentences closercentroid (the ones contain terms centroid) higher scores. Position value (Pi ) scores sentences according position encompassing document.Finally, first-sentence overlap value (Fi ) scores sentences according similarityfirst sentence document.Lin Hovy (2000) designate centroid topic signature define setrelated terms: , {topic, < (t1 , w1 ), . . . , (tT , wT ) >}, ti represents term relatedtopic topic wi associated weight represents degree correlationti topic. Topic signatures computed corpus documents, previouslyclassified relevant non-relevant given topic, using log-likelihood-ratio-basedquantity 2log(). quantity, due asymptotic relation 2 distributionwell adequacy log-likelihood-ratio sparse data, used rank termsdefine signature, select cut-off value establish numberterms signature. Summarization carried ranking sentences accordingtopic signature score selecting top ranked ones. topic signature score(tss) computed similar manner MEADs centroid value: given input source, {p1 , p2 , . . . , pN }, pi , ht1 , . . . , tM i, relevant passages oneswords topic (Eq. 4).278fiRevisiting Centrality-as-Relevancetss(pi ) =Xwj , wj weight tj defined topic signature(4)j=12.2 Pair-wise Passage Similarity-based Centralitypair-wise passage similarity-based summarization, passage centrality definedsimilarity passage every passage. work presented ErkanRadev (2004), well work developed Mihalcea Tarau (2005), examplesapproach.Erkan Radev (2004) propose three graph-based approaches pair-wise passagesimilarity-based summarization similar performance: degree centrality, LexRank,continuous LexRank. Degree centrality based degree vertex. Pair-wise sentence similarity used build graph representation input source: verticessentences edges connect vertices corresponding sentences similargiven threshold. Sentences similar large number sentences consideredcentral (relevant) ones. Degree centrality similar model propose. However, model propose, introduce concept support set allow usedifferent threshold sentence. improves representation sentence,leading creation better summaries.LexRank, based Googles PageRank (Brin & Page, 1998), builds degree centrality(degree) making centrality sentence influenced similar sentences,adjacent ones graph representation (Eq. 5).X centralityScore(t)degree(t)centralityScore(s) =(5)tadj[s]ranking model similar PageRank except concerns similarity (adjacency)graph, that, case, undirected (Eq. 6, damping factor N numbersentences).X centrality(t)centrality(s) =+ (1 d)(6)Ndegree(t)tadj[s]Continuous LexRank weighted version LexRank (it uses Eq. 7 instead Eq. 5).centralityScore(s) =Xsim(s, t)centralityScore(t)uadj[t] sim(u, t)Ptadj[s](7)Mihalcea Tarau (2005), addition Googles PageRank, also explore HITSalgorithm (Kleinberg, 1999) perform graph-based extractive text summarization: again,documents represented networks sentences networks used globallydetermine importance sentence. happens models proposedErkan Radev, sentences vertices (V ) edges (w) vertices establishedpassage similarity. TextRank (Mihalcea & Tarau, 2004)how model basedPageRank designated main contributionformalization similar ContinuousLexRank (see Eq. 8), although Mihalcea Tarau also explore directed graphs279fiRibeiro & de Matosrepresentation text12 . summarization, best results obtained usingbackward directed graph: orientation edges vertex representing sentencevertices representing previous sentences input source.Xw(Vt , Vs )PextRank(Vs ) = (1 d) +extRank(Vt )(8)Vu Out[Vt ] w(Vt , Vu )Vt In[Vs ]Passage similarity based content overlap3 defined Eq. 9. Given two setsP , p1 , p2 , ..., pn Q , q1 , q2 , ..., qn , corresponding passage, similarity consistscardinality intersection sum logarithms cardinalityset.|{t : P Q}|w(VP , VQ ) = sim(P, Q) =(9)log(|P |) + log(|Q|)similar graph-based approach described Antiqueira et al. (2009). workuses complex networks perform extractive text summarization. Documents alsorepresented networks, sentences nodes connectionsnodes established sentences sharing common meaningful nouns.2.3 Beyond Automatic SummarizationApart summarization, considering PageRank HITS stem areaInformation Retrieval, centrality-based methods similar ones previously describedsuccessfully applied re-rank sets documents returned retrieval methods.Kurland Lee (2005, 2010) present set graph-based algorithms, named influx,similar model, reorder previously retrieved collection documents (C).method starts defining k -nearest-neighbor (k NN) graph initial collectionbased generation links defined Eq. 10 (KL, Kullback-Leibler divergence; LE,maximum-likelihood estimate; , smoothing-parameter Dirichlet-smoothed versionp(); s, documents).fifififi []LE(s),expKLp()p()(10)pKL,fifiCentrality determined defined Eq. 11. Edges weighted (weight givenpKL,(s)) (weight 1). Edges corresponding generation probabilities khighest ones considered.XcentralityScore(d) ,wt(o d)(11)oC1. Language Independent Algorithm Single Multiple Document Summarization (Mihalcea& Tarau, 2005), weighted PageRank equation minor difference one TextRank:Bringing Order Texts (Mihalcea & Tarau, 2004). latter presents correct equation.2. Although LexRank TextRank based PageRank, different equations usedformalization. equation used TextRank formalization PageRank original publication, however PageRank authors observe PageRanks form probability distribution Webpages, sum Web pages PageRanks one. indicates need normalizationfactor observed LexRank formalization currently assumed correct PageRankformalization.3. metric proposed Mihalcea Tarau (2004) unresolved issue: denominator 0comparing two equal sentences length one (something happen processing speechtranscriptions). Instead, Jaccard similarity coefficient (1901) could used.280fiRevisiting Centrality-as-Relevancealso recursive versions centrality model, similar PageRank/LexRank Continuous LexRank.3. Support Sets Geometric Proximitywork, hypothesize input sources summarized comprehend differenttopics (lateral issues beyond main topic), model idea defining support set,based semantic relatedness, every passage input source. Semantic relatednessestimated within geometric framework, explore several distance metricscompute proximity. relevant content determined computingcentral passages given collection support sets. proposed model estimatessalient passages input source, based exclusively information drawnused input source.3.1 Modelleading concept model concept support set: first step methodassess relevant content create support set passage input sourcecomputing similarity passage remaining ones, selectingclosest passages belong support set. relevant passages onesoccur largest number support sets.Given segmented information source , p1 , p2 , ..., pN , support sets Si associatedpassage pi defined indicated Eq. 12 (sim() similarity function,threshold).Si , {s : sim(s, pi ) > 6= pi }(12)relevant segments given selecting passages satisfy Eq. 13.fifiarg max fi{Si : Si }fi(13)sni=1 Simajor difference previous centrality models main reason introducesupport sets allowing different thresholds set (i ), let centralityinfluenced latent topics emerge groups related passages.degenerate case equal, fall degree centrality model proposedErkan Radev (2004). using, instance, nave approach dynamicthresholds (i ) set limiting cardinality support sets (a k NN approach), centrality changed support set semantically related passagespassage. graph theory perspective, means underlying representation undirected, support set interpreted passages recommendedpassage associated support set. contrasts LexRank models,based undirected graphs. hand, models proposed Mihalcea Tarau (2005) closer work sense explore directedgraphs, although simple way (graphs directed forward backward).Nonetheless, semantic relatedness (content overlap) centrality assessment (performedgraph ranking algorithms HITS PageRank) quite different proposal.concerns work Kurland Lee (2005, 2010), considering k NN281fiRibeiro & de Matosapproach definition support set size, similar ideias, althoughaddressing automatic summarization, neighborhood definition strategy different ours: Kurland Lee base neighborhood definition generation probabilities(Eq. 10), explore geometric proximity. Nevertheless, perspectivemodel, k NN approach support set definition possible strategy (othersused): model seen generalization k NN NN approaches, sincepropose use differentiated thresholds (i ) support set (Eq. 12).3.2 Semantic Spacerepresent input source term passages matrix A, matrix elementaij = f (ti , pj ) function relates occurrences term ti within passagepj (T number different terms; N number passages).a1,1 . . . a1,N= ...aT,1 . . . aT,N(14)concerns definition weighting function f (ti , pj ), several term weightingschemes explored literaturefor analysis impact differentweighting schemes either text speech summarization see work Orasan et al.(2004), Murray Renals (2007) Ribeiro de Matos (2008b), respectively. Sinceexact nature weighting function, although relevant, central work,opted normalized frequency simplicity, defined Eq. 15, ni,j numberoccurrences term ti passage pj .ni,jf (ti , pj ) = tfi = Pk nk,j(15)Nevertheless, line work Sahlgren (2006) shows several tasksconcerning term semantic relatedness, one effective weighting schemes smallcontexts binary term weighting scheme (Eq. 16), alongside raw dampened counts,is, weighting schemes, based frequency, use global weights (notealso small contexts, words frequency 1, normalizedsimilar binary weighting scheme).(1 ti pjf (ti , pj ) =(16)0 ti/ pj3.3 Semantic Relatednessindicated Sahlgren (2006), meanings-are-locations metaphor completely vacuous without similarity-is-proximity metaphor. sense, explore prevalentdistance measures found literature, based general Minkowski distance (Eq. 17).distminkowski (x, y) =nXi=1282|xi yi |N1N(17)fiRevisiting Centrality-as-RelevanceSemantic relatedness computed using Manhattan distance (N = 1, Eq. 19),Euclidean distance (N = 2, Eq. 20), Chebyshev distance (N , Eq. 21),fractional distance metrics (we experimented N = 0.1, N = 0.5, N = 0.75,N = 1.(3). Note that, 0 < N < 1, Eq. 17 represent metric, sincetriangle inequality hold (Koosis, 1998, page 70). case, common usevariation defined Eq. 18.distN (x, y) =nX|xi yi |N , 0 < N < 1(18)i=1Moreover, also experiment general Minkowski equation, using tuple dimension N .nXdistmanhattan (x, y) =|xi yi |(19)i=1vu nuX(xi yi )2disteuclidean (x, y) =(20)i=1distchebyshev (x, y) = limNnX|xi yi |Ni=11N= max (|xi yi |)(21)cosine similarity (Eq. 22), since one used similarity metrics, especiallyusing spatial metaphors computing semantic relatedness, also partexperiments.Pnx yixysimcos (x, y) =(22)= qP i=1qPnnkxkkyk22xi=1i=1Grounding semantic relatedness geometric proximity enables solid analysisvarious similarity metrics. instance, using Euclidean distance (Eq. 20), differences tuple coordinate values less 1 make passages closer, valuesgreater 1 make passages distant; Chebyshevs distance (Eq. 21) takesaccount one coordinate: one greatest difference two passages; and,Manhattan distance (Eq. 19) considers coordinates evenly. cosine similarity(Eq. 22), tuples representing passages vectors angle form establishesrelatedness. contrast, Mihalcea Tarau (2005) Antiqueira et al. (2009) definepassage similarity content overlap. Figure 1 (N ranges 0.1, almost imperceptible graphical representation, N , square) shows unit circleaffected several geometric distances (Manhattan, N = 1, Euclidean, N = 2,highlighted).Although geometric proximity enables solid analysis effects using specificmetric, mainly relies lexical overlap. metrics could used, although coststerms required resources would increase. Examples corpus-based vector spacemodels semantics (Turney & Pantel, 2010), like LSA (Landauer et al., 1998), HyperspaceAnalogue Language (Lund, Burgess, & Atchley, 1995), Random Indexing (Kanerva,Kristoferson, & Holst, 2000; Kanerva & Sahlgren, 2001), similarity metrics basedknowledge-rich semantic resources, WordNet (Fellbaum, 1998).283fiRibeiro & de Matos10.750.50.25-1-0.75-0.5-0.2500.250.50.751-0.25-0.5-0.75-1Figure 1: Unit circles using various fractional distance metrics (N equals 0.1, 0.5, 0.75,1.(3)), Manhattan distance (N = 1), Euclidean distance (N = 2),Chebyshevs distance (N ).3.4 Threshold Estimationpreviously mentioned, simple approach threshold estimation define fixedcardinality support sets, k NN approach. means thresholds, althoughunknown, different support set.simple heuristic allows automatically set per passage thresholds selectmembers support set passages distance passage associatedsupport set construction smaller average distance. next sections,explore several heuristics inspired nature problem usedpossibly better approaches threshold estimation. However, subject meritsstudy.3.4.1 Heuristics Based Distance Progression AnalysisOne possible approach analyze progression distance valuespassage remaining ones creation respective support set. typeheuristics uses sorted permutation, di1 di2 diN 1 , distancespassages, sk , passage pi (corresponding support set construction),dik = dist(sk , pi ), 1 k N 1, N number passages.284fiRevisiting Centrality-as-Relevanceexplore three approaches: standard deviation-based approach, givenEq. 23, parameter controls width interval around average distancerelation standard deviation; approach based diminishing differencesconsecutive distances, dik+2 dik+1 < dik+1 dik , 1 k N 3, = dik+2 ,k largest one 1jk+1 j : dij+2 dij+1 < dij+1 dij ; and, approach basedaverage difference consecutive distances,dik+1 dikPN 2<l=1(dil+1 dil ),1N 2P= dik+1 , k largest one 1jk j : dij+1 dij <= ,vuN11u 1 NX1 X=dk , =(dik )2N 1N 1k=1k N 2,N 2l=1 (dl+1 dl )N 2.(23)k=13.4.2 Heuristics Based Passage Orderestimation specific thresholds aims defining support sets containingimportant passages passage analysis. sense, set heuristicsexplore structure input source partition candidate passagessupport set two subsets: ones closer passage associated support setconstruction, ones appart.heuristics use permutation, di1 , di2 , , diN 1 , distances passages, sk ,passage, pi , related support set construction, dik = dist(sk , pi ), 1k N 1, corresponding order occurrence passages sk input source.Algorithm 1 describes generic procedure.3.4.3 Heuristics Based Weighted Graph Creation Techniquesseveral ways define weighted graph, given dataset. main ideiasimilar nodes must connected edge large weight. set heuristics,explore two weight functions (Zhu, 2005) (Eqs. 24 25) considering returnedvalue given threshold, , passage sk belongs support set passage pi ,dik = dist(sk , pi ).exp((diktanh((dikmin (dij ))2 /2 ) >1jN 1N 11 Xdj )) + 1 /2 >N 1(24)(25)j=13.5 Integrating Additional Informationargued Wan, Yang, Xiao (2007) Ribeiro de Matos (2008a), useadditional related information helps build better understanding given subject, thusimproving summarization performance. Wan et al. propose graph-based ranking modeluses several documents given topic summarize single one them. Ribeirode Matos, using LSA framework, present method combines input source285fiRibeiro & de MatosInput: Two values r1 r2 , representative subset, set passagessk corresponding distances dik passage associated support setconstructionOutput: support set passage analysisR1 , R2 ;k 1 N 1|r1 dik | < |r2 dik |r1 (r1 + dik )/2;R1 R1 {sik };elser2 (r2 + dik )/2;R2 R2 {sik };endendl arg min1kN 1 (dik );sl R1return R1 ;elsereturn R2 ;endAlgorithm 1: Generic passage order-based heuristic.consisting spoken document, related textual background information, copedifficulties speech-to-text summarization.model propose may easily expanded integrate additional information.using information source , p1 , p2 , ..., pN source additional relevantinformation B, may redefine Eq. 12 shown Eq. 26 integrate additionalinformation.Si , {s B : sim(s, pi ) > 6= pi }(26)Matrix (from Eq. 14) redefined indicated Eq. 27, aidk representsjweight term ti , 1 (T number terms), passage pdk , 1 k (Djnumber documents used additional information) dk1 dkj dks , documentdk ; ainl , 1 l s, elements associated input source summarized.a1d1 ... a1d1s1...A=d11 ... d1s...a1dD ... a1dD1... dD ... dD1a1n1 ... a1nsn1 ... ns(27)Given new definition support set common representation additionalinformation, relevant content still assessed using Eq. 13.line thought applied extend model multi-document summarization.286fiRevisiting Centrality-as-Relevance4. EvaluationSummary evaluation research subject itself. Several evaluation models putforward last decade: beyond long-established precision recall (mostly usefulevaluating extractive summarization using also extractive summaries models), literature filled metrics (some automatic, others manual) like Relative utility (Radevet al., 2000; Radev & Tam, 2003), SummACCY (Hori, Hori, & Furui, 2003), ROUGE (Lin,2004), VERT (de Oliveira, Torrens, Cidral, Schossland, & Bittencourt, 2008), Pyramid method (Nenkova, Passonneau, & McKeown, 2007). comprehensive analysisevaluation field see work Nenkova (2006) Nenkova et al. (2007).Despite number approaches summary evaluation, widely used metricstill ROUGE one use study. chose ROUGE owingwide adoption, also one data sets used evaluationused published studies, allowing us easily compare performance modelknown systems.PPS{Reference Summaries}gramN countmatch (gramN )PROUGE-N = P(28)S{Reference Summaries}gramN count(gramN )Namely, use ROUGE-1 score, known correlate well human judgment (Lin,2004). ROUGE-N defined Eq. 28. Moreover, estimate confidence intervals usingnon-parametric bootstrap 1000 resamplings (Mooney & Duval, 1993).Since proposing generic summarization model, conducted experimentstext speech data.4.1 Experiment 1: Textsection, describe experiments performed analyze corresponding resultsusing input source written text.4.1.1 Dataused corpus, known TeMario, consists 100 newspaper articles Brazilian Portuguese (Pardo & Rino, 2003). Although model general language-independent,corpus used several published studies, allowing us perform informed comparison results. articles corpus cover several domains, world,politics, foreign affairs. 100 newspaper articles, referencehuman-produced summary. text tokenized punctuation removed, maintainingsentence boundary information. Table 1 sumarizes properties data set.4.1.2 Evaluation Setupcompare performance model input affected speech-relatedphenomena, use previously published state-of-the-art results text summarization.However, since information available kind preprocessingprevious studies, could guarantee fair comparison results previousones, without definition adequate methodology comparisons.following systems evaluated using TeMario dataset:287fiRibeiro & de Matos#Words#SentencesAverageMinimumMaximumNews Story (NS)NS SentenceSummary (S)Sentence608211922142111201131510034587News StorySummary2991256818Table 1: Corpus characterization.set graph-based summarizers presented Mihalcea Tarau (2005), namelyPageRank Backward, HITSA Backward HITSH Forward;SuPor-v2 (Leite, Rino, Pardo, & Nunes, 2007), classifier-based system usesfeatures like occurrence proper nouns, lexical chaining, ontology;two modified versions Mihalceas PageRank Undirected, called TextRank + Thesaurus TextRank + Stem + StopwordsRem(oval) presented Leite et al. (2007);and,several complex networks summarizers proposed Antiqueira et al. (2009).Considering preprocessing step applied corpus observed differencespublished results, found important evaluate systemsconditions. Thus, implemented following centrality models:Uniform Influx (corresponds non-recursive, unweighted version model),proposed Kurland Lee (2005, 2010) re-ranking document retrieval (weexperimented several k graph definition, sames used support set cardinality kNN strategy, 10, 20, 50, 100, 200, 500, 1000, 2000, 5000,10000, present best results);PageRank, proposed Mihalcea Tarau (2004, 2005) Erkan Radev(2004) (passage similarity metrics differ Mihalcea Tarau also explore directedgraphs);Degree centrality proposed Erkan Radev (2004) (we experimentedseveral thresholds , ranging 0.01 0.09, show best results); and,Baseline, ranking defined order sentences newsarticle, relevance decreasing begining end.Table 2 discriminates PageRank-based models. PageRank directed forwardgraph performs consistently worse (Mihalcea & Tarau, 2005) undirecteddirected backward graphs, included trials. Degree ContinuousLexRank bound performance LexRank model, ones use288fiRevisiting Centrality-as-RelevanceProposed modelGeneric designationSimilarity metricContinuous LexRankTextRank UndirectedTextRank BackwardPageRank UndirectedPageRank UndirectedPageRank BackwardCosineContent overlapContent overlapTable 2: Models based PageRank.evaluation. Moreover, assess influence similarity metrics graphbased centrality models, tested best-performing metric model, Manhattandistance, PageRank model. Additionally, given models proposed ErkanRadev (2004) use idf, present results (clearly identified) using weightingschemes: using using idf.Concerning summary size, number words generated summaries directlydepends number words reference abstracts, consisted compressinginput sources 25-30% original size.4.1.3 ResultsTable 3 illustrates comparison previously proposed models model.table, model identified boldface distance name, conditionsused particular instance. Every time best performance achieved instanceusing supports sets whose cardinality specified absolute terms (15), also presentbest performance using support sets whose cardinality specified relative terms(10%90% input source). fractional metrics, also present value NEq. 17, N 1, Eq. 18, 0 < N < 1. automatically set thresholds,identify heuristic produced best results using following notation: H0 meansheuristic based average distance; H1 means heuristics based analysisdistances progression, H1.1 corresponding one based standarddeviation, H1.2 corresponding one based diminishing differencesconsecutive distances, H1.3 corresponding one based average differenceconsecutive distances; H2 means heuristics based passage order, H2.1 usingr1 minimum distance, r2 average distances, H2.2 using r1minimum distance, r2 maximum distance, H2.3, using r1 distancefirst passage r2 distance second passage, according requiredpermutation defined Section 3.4.2; H3 means heuristics based weighted graph creationtechniques, H3.1 based Eq. 24, H3.2 based Eq. 25.best overall results obtained support sets-based centrality model usingFractional, N = 1.(3) using idf, Manhattan distance. nextbest-performing variants model Cosine, Minkowski (N defined dimensionsemantic space), Euclidean, over-performing TextRank UndirectedUniform Influx model. best PageRank variant, using backward directed graphcosine similarity idf, achieved performance similar Cosine (SSC = 4,idf ) Minkowski (SSC = 2) variants model. TextRank Undirected, UniformInflux, Continuous LexRank (idf ) obtained performances similar Euclidean (SSC289fiRibeiro & de MatosSystemsROUGE-1Confidence IntervalFractional (N = 1.(3), idf, H1.3)Manhattan (SSC = 2)Manhattan (10%)Manhattan (idf, H2.1)Cosine (idf, SSC = 4)PageRank Backward Cosine (idf )Minkowski (SSC = 2)Minkowski (H2.1)Cosine (idf, H0)Manhattan (H1.2)Euclidean (idf, SSC = 5)TextRank UndirectedUniform Influx (10%NN, = 10000)Cosine (90%)Continuous LexRank (idf )Fractional (N = 1.(3), H1.3)Fractional (N = 1.(3), SSC = 1)PageRank Backward CosineDegree ( = 0.02, idf )TextRank BackwardMinkowski (10%)Euclidean (H2.3)Cosine (H1.3)Fractional (N = 1.(3), 80%)Chebyshev (H1.2)PageRank Backward ManhattanEuclidean (10%)Chebyshev (SSC = 2)Chebyshev (10%)Continuous LexRankPageRank Undirected Manhattan0.4420.4420.4400.4390.4390.4390.4390.4370.4370.4370.4360.4360.4360.4360.4360.4350.4350.4350.4350.4340.4340.4340.4320.4320.4320.4320.4310.4290.4290.4280.428[0.430,[0.430,[0.429,[0.428,[0.428,[0.427,[0.427,[0.426,[0.425,[0.425,[0.424,[0.424,[0.422,[0.423,[0.424,[0.422,[0.423,[0.423,[0.423,[0.423,[0.422,[0.422,[0.420,[0.420,[0.419,[0.419,[0.418,[0.417,[0.417,[0.415,[0.415,0.455]0.454]0.453]0.451]0.451]0.451]0.452]0.450]0.449]0.450]0.448]0.448]0.449]0.448]0.448]0.447]0.448]0.447]0.447]0.446]0.447]0.448]0.444]0.445]0.444]0.442]0.444]0.442]0.442]0.441]0.440]Baseline0.427[0.415, 0.440]Fractional (N = 0.1, H1.1)Degree ( = 0.06)Fractional (N = 0.5, H1.1)Fractional (N = 0.75, H1.1)Fractional (N = 0.75, 10%)Fractional (N = 0.1, 90%)Fractional (N = 0.5, 90%)0.4270.4260.4220.4210.4170.4170.413[0.414,[0.414,[0.409,[0.410,[0.404,[0.405,[0.403,0.439]0.439]0.434]0.433]0.429]0.429]0.425]Table 3: ROUGE-1 scores text experiment (SSC stands Support Set Cardinality).290fiRevisiting Centrality-as-Relevance= 5, idf ) Cosine (90%) variants. Notice although exhaustively analyzingeffects term weighting, use idf clearly benefits metrics: see, instance,Cosine Fractional N = 1.(3) variants model, PageRank variants basedcosine similarity, Degree. relevant note model, lowcomputational requirements, achieves results comparable graph-based state-of-the-artsystems (Ceylan, Mihalcea, Ozertem, Lloret, & Palomar, 2010; Antiqueira et al., 2009).Notice although estimated confidence intervals overlap, performanceManhattan SCC=2 variant significantly better, using directional Wilcoxon signedrank test continuity correction, ones TextRank Undirected, (W = 2584,p < 0.05), Uniform Influx (W = 2740, p < 0.05), also Continuous LexRank (W =2381.5, p < 0.1).4 variants model perform baselineFractional variants N < 1. Fractional distances N < 1, seeneffect metric unit circle (Figure 1), increase distance passages,negatively influencing construction support sets and, consequently estimationrelevant content.Concerning automatically set per passage thresholds, possible observebest overall performance achieved metric, Fractional N = 1.(3), idf, usingheuristic based average difference consecutive distances. Cosine,Manhattan, Euclidean, Minkowski variants, heuristic based average distance(Cosine) heuristics based passage order achieved results comparable bestperforming kNN approaches. Chebyshev Fractional (with N < 1) variants bestresults obtained using heuristics based analysis progressiondistances.Figure 2 shows improvements baseline previous best-performingsystem. possible perceive greatest performance jumps introducedEuclidean (10%) Euclidean (H2.3), Minkowski (SSC=2), best-performing Manhattan, instances support sets-based relevance model. Additionally, importantnotice improvement CN-Voting baseline (computed conditions CN-Voting) 1%, performance worse poorest TextRankversion improvement baseline 1.6%. concerns linguistic knowledge-based systems (SuPor-2 enriched versions TextRank Undirected),cannot make informed assessment performance since cannot substantiateused baseline, taken work Mihalcea Tarau (2005). Nonetheless, usingbaseline, clear linguistic information improves performance extractivesummarizers beyond achieved model: improvements baselinerange 9% 17.5%. Notice however, would possible enrich modellinguistic information, manner TextRank.Regarding effect similarity metric PageRank-based systems, possible observe PageRank Undirected based Content Overlap (TextRank Undirected)better performance similarity based geometric metriceither Manhattan Cosine (Continuous LexRank). However, happen considering results obtained several variants PageRank Backward. Although useContent Overlap, fact, leads better performance using Manhattan-based4. Statistical tests computed using R (R Development Core Team, 2009).291fiRibeiro & de MatosPageRank Undirected ManhattanContinuous LexRankChebyshev (10%)Chebyshev (SSC = 2)Euclidean (10%)PageRank Backward ManhattanChebyshev (H1.2)Fractional (N=1.(3), 80%)Cosine (H1.3)Euclidean (H2.3)Minkowski (10%)TextRank BackwardDegree (! = 0.02, idf)PageRank Backward CosineFractional (N = 1.(3), SSC = 1)Fractional (N = 1.(3), H1.3)Continuous LexRank (idf)Cosine (90%)Uniform Influx (10%NN, =10000)TextRank UndirectedEuclidean (SSC = 5, idf)Manhattan (H1.2)Cosine (idf, H0)Minkowski (H2.1)Minkowski (SSC = 2)PageRank Backward Cosine (idf)Cosine (SSC = 4, idf)Manhattan (idf, H2.1)Manhattan (10%)Manhattan (SSC = 2)Fractional (N = 1.(3), idf, H1.3)0.00% 0.50% 1.00% 1.50% 2.00% 2.50% 3.00% 3.50% 4.00%Improvement previous systemImprovement baselineFigure 2: Analysis increase performance model.similarity metric, use cosine similarity results performance comparableone using Content Overlap metric. Manhattan-based similarity metricdefined Eq. 29.simmanhattan (x, y) =11 + distmanhattan (x, y)(29)4.2 Experiment 2: Speechsection, describe experiments performed analyze corresponding resultsusing input source automatically transcribed speech.292fiRevisiting Centrality-as-Relevance4.2.1 Dataevaluate ideas speech processing setting, used data Ribeirode Matos (2008a): automatic transcriptions 15 broadcast news stories EuropeanPortuguese, part news program. Subject areas include society, politics, sports,among others. Table 4 details corpus composition. news story,human-produced reference summary, abstract. average word recognitionerror rate 19.5% automatic sentence segmentation attained slot error rate (SER,commonly used evaluate kind task) 90.2%. possible observe Table 4,important distinguish notion sentence written textsentence-like unit (SU) speech data. Note, particular, difference averagenumber words per sentence summary versus average number words per SUnews story. According Liu, Shriberg, Stolcke, Hillard, Ostendorf, Harper (2006),concept SU different concept sentence written text, since, althoughsemantically complete, SUs smaller sentence. corroborated factpossible find news stories SUs length 1 (this corpus 8 SUs length1). Beyond definition SU, note SER 90.2% high value: currently,automatic punctuation module responsible delimiting SUs achieves SER 62.2%,using prosodic information (Batista, Moniz, Trancoso, Meinedo, Mata, & Mamede, 2010).#Words#SUs#SetencesAverageMinimumMaximumNews Story (NS)NS SUSummary (S)Sentence28711332074198512917233News StorySummary27261514Table 4: Corpus characterization.4.2.2 Evaluation SetupRegarding speech summarization, even considering difficulties concerning applicability text summarization methods spoken documents, shallow approaches like LSAMMR seem achieve performances comparable ones using specific speech-relatedfeatures (Penn & Zhu, 2008), especially unsupervised approaches. Given implementedmodels, experiment compare support sets relevance model followingsystems:LSA baseline.following graph-based methods: Uniform Influx (Kurland & Lee, 2005, 2010),Continuous LexRank Degree centrality (Erkan & Radev, 2004), TextRank (Mihalcea & Tarau, 2004, 2005).293fiRibeiro & de Matosmethod proposed Ribeiro de Matos (2008a), explores useadditional related information, less prone speech-related errors (e.g. onlinenewspapers), improve speech summarization (Mixed-Source).Two human summarizers (extractive) using source automatic speech transcriptions news stories (Human Extractive).analyzing results, important examine human performance. Onerelevant issues assessed level agreement two humansummarizers: accomplished using kappa coefficient (Carletta, 1996),obtained value 0.425, considered fair moderate/good agreement (Landis& Kosh, 1977; Fleiss, 1981). Concerning selected sentences, Figure 3 shows humansummarizer H2 consistently selected first n sentences, H1 choicesalso noticeable preference first sentences news story.1Sentence position23H14H25Remaining sentences05101520Number times selectedFigure 3: Human sentence selection patterns.able perform good assessment automatic models, conducted twoexperiments: first one, number SUs extracted compose automaticsummaries defined accordance number sentences reference humanabstracts (which consisted compressing input source 10% originalsize); second experiment, number extracted SUs automatic summariesdetermined size shortest corresponding human extractive summary. NoticeMixed-Source human summaries experiments.4.2.3 ResultsTable 5 shows ROUGE-1 scores obtained, speech experiments. table,possible find one instance models, since sometimes bestperforming variant using summary size size abstracts differentone using summary size size human extracts.294fiRevisiting Centrality-as-RelevanceSystemsUsing Summary Size ReferenceHuman Abstracts Shortest Human ExtractsHuman Extractive 1Human Extractive 2Cosine (idf, H2.3)PageRank Backward CosineTextRank BackwardPageRank Backward Cosine (idf )First SentencesPageRank Backward ManhattanChebyshev (H2.3)Chebyshev (10%)Cosine (H2.3)Minkowski (H2.3)Cosine (40%)Euclidean (H2.3)Mixed-SourceCosine (idf, 40%)Minkowski (40%)Fractional (N = 1.(3), idf, H2.3)Manhattan (H3.1)Fractional (N = 1.(3), SSC=4)Cosine (80%)Fractional (N = 1.(3), H3.2)Degree ( = 0.06)Fractional (N = 1.(3), 20%)Manhattan (10%)Euclidean (20%)Euclidean (10%)Euclidean (SSC=3)Fractional (N = 1.(3), 10%)Fractional (N = 1.(3), SSC=3)TextRank UndirectedDegree ( = 0.03, idf )Uniform Influx (10%NN, = 500)0.5440.5140.4770.4730.4700.4670.4620.4620.4580.4430.4100.4070.4040.4010.3920.3890.3810.3800.3730.3710.3650.3610.3510.3470.3460.3440.3370.3360.3360.3330.3320.3280.314LSA Baseline0.308 [0.239, 0.407]0.338 [0.260, 0.432]Continuous LexRank (idf )Fractional (N = 0.1, 90%)Continuous LexRankPageRank Undirected ManhattanFractional (N = 0.5, 90%)Fractional (N = 0.75, 90%)0.3030.3010.2790.2340.2240.2080.3620.3680.3350.3280.2840.235[0.452,[0.392,[0.374,[0.363,[0.360,[0.360,[0.360,[0.355,[0.351,[0.329,[0.306,[0.316,[0.306,[0.310,[0.340,[0.287,[0.288,[0.274,[0.276,[0.279,[0.290,[0.268,[0.247,[0.280,[0.246,[0.277,[0.262,[0.262,[0.263,[0.256,[0.242,[0.232,[0.211,[0.215,[0.191,[0.212,[0.163,[0.133,[0.149,0.640]0.637]0.580]0.583]0.580]0.571]0.572]0.577]0.571]0.576]0.520]0.509]0.512]0.504]0.452]0.500]0.495]0.496]0.494]0.483]0.458]0.469]0.463]0.432]0.478]0.418]0.432]0.430]0.429]0.442]0.423]0.428]0.427]0.402]0.438]0.343]0.295]0.336]0.281]0.5440.5140.5050.5100.5050.5160.5140.5140.5060.4830.4460.4490.4400.4400.3920.4640.4350.4510.4310.4020.4430.4310.3830.3740.4120.3710.4040.4050.4050.4070.3610.3690.382[0.455,[0.402,[0.405,[0.399,[0.391,[0.393,[0.390,[0.392,[0.388,[0.356,[0.329,[0.349,[0.344,[0.341,[0.339,[0.355,[0.325,[0.354,[0.343,[0.303,[0.345,[0.316,[0.276,[0.292,[0.311,[0.288,[0.296,[0.300,[0.305,[0.308,[0.262,[0.260,[0.258,[0.263,[0.252,[0.246,[0.240,[0.176,[0.165,0.650]0.652]0.619]0.628]0.625]0.646]0.637]0.648]0.618]0.615]0.562]0.571]0.547]0.547]0.449]0.577]0.554]0.556]0.533]0.526]0.555]0.563]0.499]0.467]0.532]0.474]0.524]0.519]0.529]0.530]0.464]0.476]0.511]0.471]0.498]0.441]0.432]0.412]0.302]Table 5: ROUGE-1 scores, 95% confidence intervals computed using bootstrap statistics, speech experiment (SSC stands Support Set Cardinality; sortedusing scores human abstracts).295fiRibeiro & de Matosfirst observation concerns particular aspect corpus: seen, especiallyexperiment using reference size size shortest human extracts, Human 2 First Sentences summarizers attained ROUGE-1 scores (thishappen experiment using abstracts size only, due fact First Sentencessummaries shorter, adapted experiment required size, ones Human2, changed). fact, summaries equal, shows consistentbias indicating relevant sentences tend occur beginning newsstories. bias, although surprising, since corpus composed broadcast newsstories, also common seen previous work (Ribeiro & de Matos,2007; Lin, Yeh, & Chen, 2010). Second, interesting notice performancePageRank-based models: text observable trend concerning directionality graph, LexRank versions performed baseline, speechbackward versions achieved good performance (the four undirected versions performed around baseline, LexRank obtaining results LSA baseline,exception experiment using extracts size idf ). models perspective,considering performance backward versions text speech, usebackward directionality seems main reason good performance speech,input sources consist transcriptions broadcast news stories news program.fact, mentioned before, kind input source usually short (cf. Table 4)main information given opening news story. suggests directionality introduces position information model, relevant specific typesinput source (this also discussed Mihalcea & Tarau, 2005). Moreover, noteContinuous LexRank performance close LSA Baseline, impliesmodel quite susceptible referred bias, noisy input, both. Takingconsideration model based pair-wise passage similarity onebest-performing support sets-based instance Cosine, similarity metric usedLexRank, seems model able account structure input sources data set. fact, Degree centrality, also based cosine similarityperformed better PageRank Undirected models. Influx model performed closeDegree centrality, far best performing approaches, which, case, suggestsmethod generating graph, generation probabilities, affectednoisy input, especially considering small contexts like passages. Approaches basedgeneration probabilities seem adequate larger contexts, documents (Kurland& Lee, 2005, 2010; Erkan, 2006a). Erkan (2006b) mentions results query-based summarization using generation probabilities worse ones obtained LexRankgeneric summarization.Concerning overall results, performance varies according size summaries. using abstracts size, best-performing instance Cosine idfusing heuristic based passage order; using reference extracts size,best performance achieved backward PageRank model, followed Chebyshev variant also using heuristic based passage order Cosine variant.variants achieved better results TextRank Backward. Given successheuristic H2.3 experiments, seems heuristic may also introducingposition information model. Although achieving best performanceexperiment using extracts size, significant difference best sup296fiRevisiting Centrality-as-Relevanceport sets-based relevance model instance, Chebyshev variant using heuristic basedpassage order, ones achieved human summarizers: applying directionalWilcoxon signed rank test continuity correction, test values using shortest human extracts size W = 53, p = 0.5. means state-of-the-art performanceexperiment using abstracts size, comparable human (results similar FirstSentence, similar Human Extractive 2) using shortest human extractssize. fact, Chebyshev (10%), avoid influence possible position information,also significantly different Human Extractive 2 (W = 11, p = 0.2092). Cosineidf using H2.3 better performance statistical significance Degree= 0.06 (W = 53.5, p < 0.005 using abstracts size; W = 54, p < 0.005using shortest human extracts size), TextRank Undirected (W = 92.5, p < 0.05using abstracts size; W = 96, p < 0.05 using shortest human extractssize), Uniform Influx (W = 60, p < 0.01 using abstracts size; W = 51,p < 0.06 using shortest human extracts size), using statistical test.obtained results, speech transcriptions written text, suggest modelrobust, able detect relevant content without specific informationfound performing well presence noisy input. Moreover, cosinesimilarity seems good metric use proposed model, performing amongtop ranking variants, written spoken language.Fractional variants N < 1 were, again, worst performing approaches (weinclude values automatically set per passage thresholds Table 5, sinceworse simple kNN approach) effect similarity assessmentboosts influence recognition errors. hand, Chebyshev seemsimune influence: single use maximal difference dimensionsmakes less prone noise (recognition errors). happens variant usinggeneric Minkowski distance N equal number dimensions semanticspace.Figures 4 5 shows performance variation introduced different approaches.Notice that, speech experiments, performance increments magnitude highercompared ones written text. Overall, Chebyshev variant supportsets-based relevance model introduces highest relative gains, close 10% experiment using abstracts size, close 5% experiment using extracts size.experiment using extracts size, TextRank Undirected also achieves relative gainsnear 10% previous best-performing system, LSA baseline. Similar relativeimprovements introduced human summarizers experiment using abstracts size. expected, increasing size summaries increases coveragehuman abstracts (bottom Figure 5).Further, comparing model complex (not centrality-based), state-of-the-artmodels like one presented Lin et al. (2010) suggests least similar performanceattained: relative performance increment model LexRank 57.4%39.8% (both speech experiments), whereas relative gain best variant modelproposed Lin et al. LexRank 39.6%. Note takenindicative, since accurate comparison possible data sets differ, Lin et al.explicit variant LexRank used, address statistical significance.297fiRibeiro & de MatosSummary Size Determined Human AbstractsContinuous LexRank (idf)LSA BaselineUniform Influx (10%NN, =500)Degree (! = 0.03, idf)TextRank UndirectedFractional (N=1.(3), SSC=3)Fractional (N=1.(3), 10%)Euclidean (SSC=3)Euclidean (10%)Euclidean (20%)Manhattan (10%)Fractional (N=1.(3), 20%)Degree (! = 0.06)Fractional (N=1.(3), H3.2)Cosine (80%)Fractional (N=1.(3), SSC=4)Manhattan (H3.1)Fractional (N=1.(3), idf, H2.3)Minkowski (40%)Cosine (idf, 40%)Mixed-SourceEuclidean (H2.3)Cosine (40%)Minkowski (H2.3)Cosine (H2.3)Chebyshev (10%)Chebyshev (H2.3)PageRank Backward ManhattanFirst SentencesPageRank Backward Cosine (idf)TextRank BackwardPageRank Backward CosineCosine (idf, H2.3)Human Extractive 2Human Extractive 1-10%0%10%20%Improvement previous system30%40%50%60%70%80%Improvement baselineFigure 4: Analysis increase performance model (Experiment usingabstracts size).4.3 Influence Size Support Sets Assessment Relevancepropose method determining optimum size support sets. Nonetheless, analyze influence support set size assessment relevantcontent, text speech.Figure 6 depicts behavior model variants performance baseline written text, Figure 7 illustrates variants conditions298fiRevisiting Centrality-as-RelevanceSummary Size Determined Shortest Human ExtractsTextRank UndirectedContinuous LexRank (idf)Degree (! = 0.03, idf)Euclidean (20%)Fractional (N=1.(3), 20%)Uniform Influx (10%NN, =500)Degree (! = 0.06)Mixed-SourceFractional (N=1.(3), SSC=4)Euclidean (10%)Fractional (N=1.(3), 10%)Euclidean (SSC=3)Fractional (N=1.(3), SSC=3)Manhattan (10%)Fractional (N=1.(3), H3.2)Manhattan (H3.1)Minkowski (40%)Euclidean (H2.3)Cosine (40%)Cosine (80%)Cosine (H2.3)Minkowski (H2.3)Fractional (N=1.(3), idf, H2.3)Cosine (idf, 40%)Chebyshev (10%)TextRank BackwardCosine (idf, H2.3)Chebyshev (H2.3)PageRank Backward CosinePageRank Backward ManhattanFirst SentencesHuman Extractive 2PageRank Backward Cosine (idf)Human Extractive 1-10%0%10%20%Improvement previous system30%40%50%60%70%80%Improvement baselineFigure 5: Analysis increase performance model (Experiment usingabstracts size).automatic speech transcriptions (in case, error bars omitted clarity). analyze general performance variants, considering support set size numberpassages input source 10% increments. Given average size input source,written text (Table 1), speech transcriptions (Table 4), absolute cardinalities(SSC) ranging 1 5 passages broadly cover possible sizes interval 0-10%.first observation concerns fact varying cardinality support setsinput sources consist written text smooth effect performance.allows analysis generic tendencies. contrast, processing automatic299fiRibeiro & de MatosCosineManhattan (N=1)Fractional (N=1.(3))90%80%70%60%50%40%90%80%70%60%50%40%30%20%10%SSC=5SSC=3SSC=4SSC=20.39SSC=10.40.3930%0.410.420%0.420.4110%0.430.42SSC=50.43SSC=30.44SSC=40.450.44SSC=20.460.45SSC=10.46Euclidean (N=2)70%80%90%80%90%60%50%70%Minkowski (variable N)40%90%80%70%60%50%40%30%20%10%SSC=5SSC=4SSC=3SSC=20.39SSC=10.40.3930%0.410.420%0.420.4110%0.430.42SSC=50.43SSC=40.44SSC=30.450.44SSC=20.460.45SSC=10.46Chebyshev (N!!)60%50%40%90%80%70%60%50%40%30%20%10%SSC=5SSC=4SSC=3SSC=20.39SSC=10.40.3930%0.410.420%0.420.4110%0.430.42SSC=50.43SSC=40.44SSC=30.450.44SSC=20.460.45SSC=10.46Figure 6: Analysis impact cardinality support sets text summarization. axes ROUGE-1 scores X axes support sets cardinalities(absolute relative length input source, terms passages).speech transcriptions, possible perceive several irregularities. irregularitiestwo different causes: intrinsic characteristics speech transcriptionsrecognition errors, sentence boundary detection errors, type discourse; or,specificities data setin particular, global size corpus specificnews story structure. However, considering performance metrics textspeech, irregularities seem mainly caused intrinsic properties speechtranscriptions specific structure news story.300fiRevisiting Centrality-as-Relevance90%80%60%50%40%70%70%80%90%70%80%90%60%50%40%30%60%50%40%30%20%90%80%70%60%50%40%30%20%10%SSC=5SSC=40.2SSC=30.2SSC=20.30.25SSC=10.30.2510%0.40.35SSC=50.40.35SSC=40.50.45SSC=30.50.45SSC=2Chebyshev (N!!)SSC=1Minkowski (variable N)20%90%80%70%60%50%40%30%20%10%SSC=5SSC=40.2SSC=30.2SSC=20.30.25SSC=10.30.2510%0.40.35SSC=50.40.35SSC=40.50.45SSC=30.50.45SSC=2Euclidean (N=2)SSC=1Fractional (N=1.(3))30%90%80%70%60%50%40%30%20%10%SSC=5SSC=30.2SSC=40.2SSC=20.25SSC=10.30.2520%0.350.310%0.35SSC=50.4SSC=30.450.4SSC=40.45SSC=2Manhattan (N=1)0.5SSC=1Cosine0.5Figure 7: Analysis impact cardinality support sets speech-to-textsummarization. axes ROUGE-1 scores X axes support sets cardinalities (absolute relative length input source terms passages).Lines square marks correspond experiment using summary sizesize human abstracts; lines circle marks correspond experimentusing summary size size shortest human extracts. Horizontal linescorrespond baselines.301fiRibeiro & de MatosConcerning performance itself, written text, best performances achieved usinglow cardinalities (absolute cardinalities 2 3 passages, 10% passagesinput source). Moreover, increase size support sets leads decayresults (except using cosine similarity). processing automatic speechtranscriptions, difficult find clear definition best results achieved.Considering absolute cardinalities, exception Manhattan distance, everyvariant peak using support sets 4 passages. However, possibleextend line thought relative sizes due previously referred irregularities.Nonetheless, higher cardinalities (70%90%) lead worse results, expected givennature model (again exception using cosine similarity).addition, note increasing size summaries improves distinctionbaseline (summaries based size shortest human extracts longerones based size human abstracts). means model robustneeds regarding summary size, continuing select good content even larger summaries.5. Conclusionsnumber up-to-date examples work automatic summarization using centralitybased relevance models significant (Garg, Favre, Reidhammer, & Hakkani-Tur, 2009;Antiqueira et al., 2009; Ceylan et al., 2010; Wan, Li, & Xiao, 2010). work,assessed main approaches centrality-as-relevance paradigm, introducednew centrality-based relevance model automatic summarization. model uses supportsets better characterize information sources summarized, leading betterestimation relevant content. fact, assume input sources comprehendseveral topics uncovered associating passage support set composedsemantically related passages. Building ideas Ruge (1992), [...]model semantic space relative position two terms determines semanticsimilarity better fits imagination human intuition [about] semantic similarity [...],semantic relatedness computed geometric proximity. explore several metricsanalyze impact proposed model well (to certain extent) relatedwork. Centrality (relevance) determined taking account whole input source,local information, using support sets-based representation. Moreover,although formally analyzed, notice proposed model low computationalrequirements.conducted thorough automatic evaluation, experimenting model written text transcribed speech summarization. obtained results suggestmodel robust, able detect relevant content without specific informationfound performing well presence noisy input,automatic speech transcriptions. However, must taken considerationuse ROUGE summary evaluation, although generalized, allowing easily compareresults replicate experiments, ideal scenario, consequently, resultscorroborated perceptual evaluation. outcome performed trials showproposed model achieves state-of-the-art performance text speech summarization, including compared considerably complex approaches. Nonetheless,identified limitations. First, although grounding semantic similarity geometric302fiRevisiting Centrality-as-Relevanceproximity, current experiments rely mainly lexical overlap. maintainingsemantic approach, use complex methods (Turney & Pantel, 2010) may improve assessment semantic similarity. Second, address specific procedureestimating optimum thresholds, leaving future research. Nonetheless, exploredseveral heuristics achieved top ranking performance. Moreover, carrieddocument analysis provides clues adequate dimension supportsets, analytical analysis performed.Acknowledgmentswould like thank anonymous reviewers insightful comments. worksupported FCT (INESC-ID multiannual funding) PIDDAC Programfunds.ReferencesAggarwal, C. C., Hinneburg, A., & Keim, D. A. (2001). Surprising BehaviorDistance Metrics High Dimensional Space. den Bussche, J. V., & Vianu, V.(Eds.), Database Theory ICDT 2001, 8th International Conference London, UK,January 46, 2001 Proceedings, Vol. 1973 Lecture Notes Computer Science, pp.420434. Springer.Antiqueira, L., Oliveira Jr., O. N., da Fontoura Costa, L., & Nunes, M. G. V. (2009).complex network approach text summarization. Information Sciences, 179 (5),584599.Batista, F., Moniz, H., Trancoso, I., Meinedo, H., Mata, A. I., & Mamede, N. J. (2010).Extending punctuation module European Portuguese. Proceedings11th Annual Conference International Speech Communication Association (INTERSPEECH 2010), pp. 15091512. ISCA.Brin, S., & Page, L. (1998). anatomy large-scale hypertextual Web search engine.Computer Networks ISDN Systems, 30, 107117.Carbonell, J., & Goldstein, J. (1998). Use MMR, Diversity-Based RerankingReordering Documents Producing Summaries. SIGIR 1998: Proceedings21st Annual International ACM SIGIR Conference Research DevelopmentInformation Retrieval, pp. 335336. ACM.Carletta, J. (1996). Assessing agreement classification tasks: kappa statistic. Computational Linguistics, 22 (2), 249254.Ceylan, H., Mihalcea, R., Ozertem, U., Lloret, E., & Palomar, M. (2010). QuantifyingLimits Success Extractive Summarization Systems Across Domains. HumanLanguage Technologies: 2010 Annual Conference North American ChapterACL, pp. 903911. Association Computational Linguistics.Christensen, H., Gotoh, Y., Kolluru, B., & Renals, S. (2003). Extractive Text Summarisation Techniques Portable Broadcast News?. Proceedings IEEE Work303fiRibeiro & de Matosshop Automatic Speech Recognition Understanding (ASRU 03), pp. 489494.IEEE.Cohn, T., & Lapata, M. (2009). Sentence Compression Tree Transduction. JournalArtificial Intelligence Research, 34, 637674.de Oliveira, P. C. F., Torrens, E. W., Cidral, A., Schossland, S., & Bittencourt, E. (2008).Evaluating Summaries Automatically system proposal. Proceedings SixthInternational Language Resources Evaluation (LREC08), pp. 474479. ELRA.Endres-Niggemeyer, B. (1998). Summarizing Information. Springer.Erkan, G. (2006a). Language Model-Based Document Clustering Using Random Walks.Proceedings Human Language Technology Conference North AmericanChapter ACL, pp. 479486. Association Computational Linguistics.Erkan, G. (2006b). Using Biased Random Walks Focused Summarization. ProceedingsDocument Understanding Conference.Erkan, G., & Radev, D. R. (2004). LexRank: Graph-based Centrality Salience TextSummarization. Journal Artificial Intelligence Research, 22, 457479.Fellbaum, C. (Ed.). (1998). WordNet: Electronic Lexical Database. MIT Press.Fleiss, J. L. (1981). Statistical methods rates proportions (2nd edition). John Wiley.Furui, S. (2007). Recent Advances Automatic Speech Summarization. Proceedings8th Conference Recherche dInformation Assistee par Ordinateur (RIAO).Centre des Hautes Etudes Internationales dInformatique Documentaire.Garg, N., Favre, B., Reidhammer, K., & Hakkani-Tur, D. (2009). ClusterRank: GraphBased Method Meeting Summarization. Proceedings 10th Annual Conference International Speech Communication Association (INTERSPEECH 2009),pp. 14991502. ISCA.Gong, Y., & Liu, X. (2001). Generic Text Summarization Using Relevance Measure Latent Semantic Analysis. SIGIR 2001: Proceedings 24st Annual InternationalACM SIGIR Conference Research Development Information Retrieval, pp.1925. ACM.Harabagiu, S., & Lacatusu, F. (2005). Topic Themes Multi-Document Summarization.SIGIR 2005: Proceedings 28th Annual International ACM SIGIR ConferenceResearch Development Information Retrieval, pp. 202209. ACM.Hori, C., Hori, T., & Furui, S. (2003). Evaluation Method Automatic Speech Summarization. Proceedings 8th EUROSPEECH - INTERSPEECH 2003, pp.28252828. ISCA.Jaccard, P. (1901). Etude comparative de la distribution florale dans une portion des Alpeset des Jura. Bulletin del la Societe Vaudoise des Sciences Naturelles, 37, 547579.Kanerva, P., Kristoferson, J., & Holst, A. (2000). Random Indexing text samplesLatent Semantic Analysis. Gleitman, L. R., & Joshi, A. K. (Eds.), Proceedings22nd annual conference Cognitive Science Society, p. 1036. PsychologyPress.304fiRevisiting Centrality-as-RelevanceKanerva, P., & Sahlgren, M. (2001). Foundations real-world intelligence, chap.words understanding, pp. 294311. No. 26. Center Study LanguageInformation.Kleinberg, J. M. (1999). Authoritative Sources Hyperlinked Environment. JournalACM, 46 (5), 604632.Koosis, P. (1998). Introduction Hp Spaces. Cambridge Universisty Press.Kurland, O., & Lee, L. (2005). PageRank without Hyperlinks: Structural Re-Ranking usingLinks Induced Language Models. SIGIR 2005: Proceedings 28th AnnualInternational ACM SIGIR Conference Research Development InformationRetrieval, pp. 306313. ACM.Kurland, O., & Lee, L. (2010). PageRank without Hyperlinks: Structural Reranking usingLinks Induced Language Models. ACM Transactions Information Systems,28 (4), 138.Landauer, T. K., Foltz, P. W., & Laham, D. (1998). Introduction Latent SemanticAnalysis. Discourse Processes, 25 (2), 259284.Landis, J. R., & Kosh, G. G. (1977). Measurement Observer Agreement Categorical Data. Biometrics, 33, 159174.Leite, D. S., Rino, L. H. M., Pardo, T. A. S., & Nunes, M. G. V. (2007). Extractive Automatic Summarization: linguitic knowledge make difference?. Proceedings Second Workshop TextGraphs: Graph-based Algorithms NaturalLanguage Processing, pp. 1724. Association Computational Linguistics.Lin, C.-Y. (2004). ROUGE: Package Automatic Evaluation Summaries. Moens,M.-F., & Szpakowicz, S. (Eds.), Text Summarization Branches Out: ProceedingsACL-04 Workshop, pp. 7481. Association Computational Linguistics.Lin, C.-Y., & Hovy, E. (2000). Automated Acquisition Topic Signatures TextSummarization. Coling 2000: 18th International Conference ComputationalLinguistics, Vol. 1, pp. 495501. Association Computational Linguistics.Lin, S.-H., Yeh, Y.-M., & Chen, B. (2010). Extractive Speech SummarizationView Decision Theory. Proceedings 11th Annual ConferenceInternational Speech Communication Association (INTERSPEECH 2010), pp. 16841687. ISCA.Liu, Y., Shriberg, E., Stolcke, A., Hillard, D., Ostendorf, M., & Harper, M. (2006). Enriching Speech Recognition Automatic Detection Sentence BoundariesDisfluencies. IEEE Transactions Speech Audio Processing, 14 (5), 15261540.Lund, K., Burgess, C., & Atchley, R. A. (1995). Semantic associative priming highdimensional semantic space. Moore, J. D., & Lehman, J. F. (Eds.), Proceedings17th annual conference Cognitive Science Society, pp. 660665. PsychologyPress.Marcu, D. (2000). Theory Practice Discourse Parsing Summarization.MIT Press.305fiRibeiro & de MatosMaskey, S. R., & Hirschberg, J. (2005). Comparing Lexical, Acoustic/Prosodic, StrucuralDiscourse Features Speech Summarization. Proceedings 9th EUROSPEECH - INTERSPEECH 2005.McKeown, K. R., Hirschberg, J., Galley, M., & Maskey, S. R. (2005). Text SpeechSummarization. 2005 IEEE International Conference Acoustics, Speech,Signal Processing. Proceedings, Vol. V, pp. 9971000. IEEE.Mihalcea, R., & Tarau, P. (2004). TextRank: Bringing Order Texts. Proceedings2004 Conference Empirical Methods Natural Language Processing, pp.404411. Association Computational Linguistics.Mihalcea, R., & Tarau, P. (2005). Language Independent Algorithm SingleMultiple Document Summarization. Proceedings Second International JointConference Natural Language Processing: Companion Volume ProceedingsConference including Posters/Demos Tutorial Abstracts, pp. 1924. Asian Federation Natural Language Processing.Mooney, C. Z., & Duval, R. D. (1993). Bootstrapping : nonparametric approach statistical inference. Sage Publications.Murray, G., & Renals, S. (2007). Term-Weighting Summarization Multi-Party SpokenDialogues. Popescu-Belis, A., Renals, S., & Bourlard, H. (Eds.), Machine LearningMultimodal Interaction IV, Vol. 4892 Lecture Notes Computer Science, pp.155166. Springer.Nenkova, A. (2006). Summarization Evaluation Text Speech: Issues Approaches.Proceedings INTERSPEECH 2006 - ICSLP, pp. 15271530. ISCA.Nenkova, A., Passonneau, R., & McKeown, K. (2007). pyramid method: incorporatinghuman content selection variation summarization evaluation. ACM TransactionsSpeech Language Processing, 4 (2).Orasan, C., Pekar, V., & Hasler, L. (2004). comparison summarisation methods basedterm specificity estimation. Proceedings Fourth International LanguageResources Evaluation (LREC04), pp. 10371041. ELRA.Pardo, T. A. S., & Rino, L. H. M. (2003). TeMario: corpus automatic text summarization. Tech. rep. NILC-TR-03-09, Nucleo Interinstitucional de Lingustica Computacional (NILC), Sao Carlos, Brazil.Penn, G., & Zhu, X. (2008). Critical Reassessment Evaluation Baselines SpeechSummarization. Proceeding ACL-08: HLT, pp. 470478. Association Computational Linguistics.R Development Core Team (2009). R: Language Environment Statistical Computing. R Foundation Statistical Computing, Vienna, Austria. ISBN 3-900051-07-0.Radev, D. R., Hatzivassiloglou, V., & McKeown, K. R. (1999). Description CIDRSystem Used TDT-2. Proceedings DARPA Broadcast News Workshop.Radev, D. R., Jing, H., & Budzikowska, M. (2000). Centroid-based summarization multiple documents: sentence extraction, utility-based evaluation, user studies.306fiRevisiting Centrality-as-RelevanceNAACL-ANLP 2000 Workshop: Automatic Summarization, pp. 2130. AssociationComputational Linguistics.Radev, D. R., Jing, H., Stys, M., & Tam, D. (2004). Centroid-based summarizationmultiple documents. Information Processing Management, 40, 919938.Radev, D. R., & Tam, D. (2003). Summarization Evaluation using Relative Utility.Proceedings 12th international conference Information Knowledge Management, pp. 508511. ACM.Ribeiro, R., & de Matos, D. M. (2007). Extractive Summarization Broadcast News: Comparing Strategies European Portuguese. Matousek, V., & Mautner, P. (Eds.),Text, Speech Dialogue 10th International Conference, TSD 2007, Pilsen, CzechRepublic, September 3-7, 2007. Proceedings, Vol. 4629 Lecture Notes ComputerScience (Subseries LNAI), pp. 115122. Springer.Ribeiro, R., & de Matos, D. M. (2008a). Mixed-Source Multi-Document Speech-to-TextSummarization. Coling 2008: Proceedings 2nd workshop Multi-sourceMultilingual Information Extraction Summarization, pp. 3340. Coling 2008 Organizing Committee.Ribeiro, R., & de Matos, D. M. (2008b). Using Prior Knowledge Assess RelevanceSpeech Summarization. 2008 IEEE Workshop Spoken Language Technology,pp. 169172. IEEE.Ruge, G. (1992). Experiments linguistically-based term associations. Information Processing Management, 28 (3), 317332.Sahlgren, M. (2006). Word-Space Model: Using distributional analysis represent syntagmatic paradigmatic relations words high-dimensional vector spaces.Ph.D. thesis, Stockholm University.Steyvers, M., & Griffiths, T. (2007). Handbook Latent Semantic Analysis, chap. Probabilistic Topic Models, pp. 427448. Lawrence Erlbaum Associates.Tucker, R. I., & Sparck Jones, K. (2005). shallow deep: experiment automatic summarising. Tech. rep. 632, University Cambridge Computer Laboratory.Turney, P. D., & Pantel, P. (2010). Frequency Meaning: Vector Space ModelsSemantics. Journal Artificial Intelligence Research, 37, 141188.Uzeda, V. R., Pardo, T. A. S., & Nunes, M. G. V. (2010). comprehensive comparativeevaluation RST-based summarization methods. ACM Transactions SpeechLanguage Processing, 6 (4), 120.Vanderwende, L., Suzuki, H., Brockett, C., & Nenkova, A. (2007). Beyond SumBasic:Task-focused summarization lexical expansion. Information Processing Management, 43, 16061618.Wan, X., Li, H., & Xiao, J. (2010). EUSUM: Extracting Easy-to-Understand English Summaries Non-Native Readers. SIGIR 2010: Proceedings 33th Annual International ACM SIGIR Conference Research Development InformationRetrieval, pp. 491498. ACM.307fiRibeiro & de MatosWan, X., Yang, J., & Xiao, J. (2007). CollabSum: Exploiting Multiple Document ClusteringCollaborative Single Document Summarizations. SIGIR 2007: Proceedings30th Annual International ACM SIGIR Conference Research DevelopmentInformation Retrieval, pp. 143150. ACM.Zechner, K., & Waibel, A. (2000). Minimizing Word Error Rate Textual SummariesSpoken Language. Proceedings 1st conference North American chapterACL, pp. 186193. Morgan Kaufmann.Zhu, X. (2005). Semi-Supervised Learning Graphs. Ph.D. thesis, Language TechnologiesInstitute, School Computer Science, Carnegie Mellon University.308fiJournal Artificial Intelligence Research 42 (2011) 91-124Submitted 5/11; published 10/11Scheduling Bipartite TournamentsMinimize Total Travel DistanceRichard HoshinoKen-ichi Kawarabayashirichard.hoshino@gmail.comk keniti@nii.ac.jpNational Institute Informatics,2-1-2 Hitotsubashi, Chiyoda-ku, Tokyo 101-8430, JapanAbstractmany professional sports leagues, teams opposing leagues/conferences competeone another, playing inter-league games. example bipartite tournament. paper, consider problem reducing total travel distancebipartite tournaments, analyzing inter-league scheduling perspective discrete optimization. research natural applications sports scheduling, especiallyleagues National Basketball Association (NBA) teams must travellong distances across North America play games, thus consuming much time,money, greenhouse gas emissions.introduce Bipartite Traveling Tournament Problem (BTTP), inter-leaguevariant well-studied Traveling Tournament Problem. prove 2n-teamBTTP NP-complete, small values n, distance-optimal inter-league schedulegenerated algorithm based minimum-weight 4-cycle-covers. applytheoretical results 12-team Nippon Professional Baseball (NPB) league Japan,producing provably-optimal schedule requiring 42950 kilometres total team travel,16% reduction compared actual distance traveled teams 2010NPB season. also develop nearly-optimal inter-league tournament 30-teamNBA league, 3.8% higher trivial theoretical lower bound.1. IntroductionConsider tournament involving two teams X , n players. bipartitetournament, players team X compete players team , goaldetermining superior team. Labeling players {x1 , x2 , . . . , xn } {y1 , y2 , . . . , yn },represent match ordered pair (xi , yj ), indices i, j {1, 2, . . . , n}.Davis Cup example bipartite tournament, country fieldstennis squad consisting two singles players doubles team. five matchesplayed two countries, doubles teams squaring Day 2, sandwichedsingles matches (x1 , y1 ), (x2 , y2 ) Day 1, (x1 , y2 ), (x2 , y1 ) Day 3.Another example biennial Ryder Cup championship, United StatesEurope field teams consisting top twelve male golfers. competition culminatestwelve head-to-head matches last day, ith ranked golfer UnitedStates facing ith ranked golfer Europe.single round-robin (SRR) bipartite tournament, player X competesevery player once, everyone playing one match time slot.produces tournament n2 matches spread n time slots. double roundc2011AI Access Foundation. rights reserved.fiHoshino & Kawarabayashirobin (DRR) bipartite tournament, pair plays twice, thus producing tournament2n2 matches spread 2n time slots. SRR bipartite tournaments commontennis ping-pong, DRR bipartite tournaments used chess, xi playsyj twice, one game white one game black. aforementionedRyder Cup example partial bipartite tournament, player X playsproper subset players .much research conducted theory bipartite tournaments(Kendall, Knust, Ribeiro, & Urrutia, 2010), previous papers dealt feasibilityfairness, specifically constructing balanced tournament designs minimizing carryover effects (Easton, Nemhauser, & Trick, 2004) ensure competitive balanceplayers team.replacing words team player league team, respectively,view X two n-team sports leagues, bipartite tournamentX represents inter-league play. example, Major League Baseball (MLB) holdsfour weeks inter-league games season, every American League team playing 18games half-dozen teams National League. MLB inter-league playexample partial bipartite tournament, some/many scheduled gamesbased historical rivalry geographic proximity.light, consider problem minimizing total travel distance bipartitetournaments. chess tennis, issue travel irrelevant tournament matchestake place venue. However, case inter-league play professionalbaseball, teams must travel long distances play games across North America,finding schedule reduces total travel distance important, economicenvironmental reasons.answer question creating distance-optimal inter-league schedule, introduce variant Traveling Tournament Problem (TTP), every pair teamsplays twice, one game teams home stadium. output optimal schedule minimizes sum total distances traveled teams move citycity, subject several natural constraints ensure balance fairness. UnlikeTTP models double round-robin intra-league tournament, variant, Bipartite Traveling Tournament Problem (BTTP), seeks best possible double round-robininter-league tournament.Since introduction (Easton, Nemhauser, & Trick, 2001), TTP emergedpopular area study within operations research community (Kendall et al., 2010)due incredible complexity, challenging benchmark problems remain unsolved.Research TTP led development powerful techniques integer programming, constraint programming, well advanced heuristics simulated annealing (Anagnostopoulos, Michel, Hentenryck, & Vergados, 2006) hill-climbing (Lim,Rodrigues, & Zhang, 2006). importantly, TTP direct applications scheduling optimization, aid professional sports leagues make regular seasonschedules efficient, saving time money, well reducing greenhouse gas emissions.purpose paper consider problem creating distance-optimal interleague tournaments, thus connecting techniques methods sports schedulingtheory bipartite tournaments, producing new directions research scheduling op92fiScheduling Bipartite Tournaments Minimize Total Travel Distancetimization. Optimizing inter-league tournaments natural next step field sportsscheduling, especially since introduction inter-league play professional sports.example, Major League Baseball, inter-league play began 1997, six decadesfirst proposed. Japan, Nippon Professional Baseball (NPB) league formed1950, yet NPB inter-league play commence 2005.authors motivated analyze Japanese NPB schedule, due puzzlinginefficiencies regular season schedule believed could improved. developed multi-round generalization TTP (Hoshino & Kawarabayashi, 2011c) basedDijkstras shortest path algorithm create distance-optimal intra-league schedulereduced total travel distance 60000 kilometres compared 2010 NPBschedule. elaborated intricacies intra-league scheduling journalpaper (Hoshino & Kawarabayashi, 2011d). Inspired success analyzing intra-leaguescheduling, asked whether techniques methods could extended inter-leagueplay, wondering whether 2010 NPB schedule requiring 51134 kilometres total teamtravel could minimized optimality. answered question presenting Bipartite Traveling Tournament Problem (Hoshino & Kawarabayashi, 2011b), providingrigorous analysis BTTP NPB distance matrix, producing provably-optimal interleague schedule requiring 42950 kilometres total team travel (Hoshino & Kawarabayashi,2011a).purpose paper expand upon two inter-league conference papersprovide thorough discussion BTTP properties. present rigorous prooflemma omitted due space constraints (Hoshino & Kawarabayashi, 2011b),key proving NP-completeness BTTP. also present application BTTPbeyond Japanese baseball, considering problem optimizing inter-league scheduling30-team National Basketball Association (NBA) North America. brieflyalluded NBA inter-league problem (Hoshino & Kawarabayashi, 2011b), ableprovide full analysis paper.Section 2, formally define BTTP discuss uniform non-uniform schedules.Section 3, prove BTTP 2n teams NP-complete obtaining reduction3-SAT, well-known NP-complete problem boolean satisfiability (Garey & Johnson, 1979). Despite computational intractability general n, present simple yetpowerful heuristic involving minimum-weight 4-cycle-covers apply 12-teamNPB league Japan, well 30-team NBA.Section 4, solve BTTP NPB, producing optimal schedule whose totaltravel distance 42950 kilometres 16% less 51134 kilometres traveledteams five weeks inter-league play 2010 season. Section 5, producenearly-optimal solution BTTP NBA, developing bipartite tournament schedulewhose total travel distance 537791 miles 3.8% higher trivial theoreticallower bound. Section 6, conclude paper several open problems presentdirections future research.2. DefinitionsLet 2n teams, n teams league. Let X two leagues,X = {x1 , x2 , . . . , xn } = {y1 , y2 , . . . , yn }. Let 2n 2n distance matrix,93fiHoshino & Kawarabayashientry Dp,q distance home stadiums teams p q. definition,Dp,q = Dq,p p, q X , diagonal entries Dp,p zero. Similar originalTTP, require compact double round-robin bipartite tournament schedule satisfyingfollowing conditions:(a) at-most-three: team may home stand road trip lasting threegames.(b) no-repeat: team cannot play opponent two consecutive games.(c) each-venue: 1 i, j n, teams xi yj play twice, othershome venue.x1x2x3y1y2y31y1y2y3x1x2x32y2y3y1x3x1x23y3y1y2x2x3x14y1y2y3x1x2x35y2y3y1x3x1x26y3y1y2x2x3x1x1x2x3y1y2y31y3y1y2x2x3x12y2y3y1x3x1x23y1y2y3x1x2x34y3y1y2x2x3x15y1y2y3x1x2x36y2y3y1x3x1x2Table 1: Two feasible inter-league tournaments n = 3.illustrate, Table 1 provides two feasible tournaments satisfying conditions case n = 3. table, schedules subsequentlypresented, home games marked bold.Following convention TTP, whenever team scheduled road tripconsisting multiple away games, team doesnt return home city ratherproceeds directly next away venue. Furthermore, assume every team beginstournament home, returns home playing last away game. example,Table 1, team x1 would travel distance Dx1 ,y1 + Dy1 ,y2 + Dy2 ,y3 + Dy3 ,x1 playingschedule left distance Dx1 ,y3 + Dy3 ,y2 + Dy2 ,x1 + Dx1 ,y1 + Dy1 ,x1playing schedule right. desired solution BTTP tournament scheduleminimizes total distance traveled 2n teams subject given conditions.Define trip pair consecutive games occurring city, i.e.,situation team doesnt play location time slots + 1,therefore travel one venue another. Table 1, schedule left24 total trips, schedule right 32 trips. One may conjecturetotal distance schedule S1 lower total distance schedule S2 iff S1 fewertrips S2 .see actually case, let teams x1 , x3 , y1 , y2 located(0, 0) let x2 y3 located (1, 0). schedule left totaldistance 16 schedule right total distance 12. minimizing tripscorrelate minimizing total travel distance; former trivial problem,latter extremely difficult, even case n = 3.six teams x1 , x2 , x3 , y1 , y2 , y3 located Cartesian planedistance-optimal solution occurs via schedule 27 trips, although majoritycases, distance-optimal schedule consists 24 trips, fewest number possible.94fiScheduling Bipartite Tournaments Minimize Total Travel Distanceinspires several interesting open problems present conclusionpaper. provide example 27 trips, locate six teams x1 = (8, 0), x2 = (9, 0),x3 = (0, 4), y1 = (6, 1), y2 = (0, 7), y3 = (3, 5). computer search provesminimal distance18 + 16 5 + 16 2 + 3 13 + 5 10 + 2 130 + 61 133.646,equality iff inter-league schedule one two appearing Table 2. Note27-trip distance-optimal schedules mirror image other.x1x2x3y1y2y31y1y2y3x1x2x32y2y3y1x3x1x23y3y1y2x2x3x14y1y2y3x1x2x35y2y3y1x3x1x26y3y1y2x2x3x1x1x2x3y1y2y31y3y1y2x2x3x12y2y3y1x3x1x23y1y2y3x1x2x34y3y1y2x2x3x15y2y3y1x3x1x26y1y2y3x1x2x3Table 2: 27-trip distance-optimal schedules special selection 6 points.Let BTTP* restriction BTTP set tournament schedulesgiven time slot, teams league either play home, play road.example, left schedule Table 1 feasible solution BTTP BTTP*. sayschedules uniform. uniformity constraint significantly reducesnumber potential tournaments, allows us quickly generate approximate solutionBTTP algorithm based minimum-weight 4-cycle-covers.prove BTTP BTTP* NP-complete obtaining reduction3-SAT, well-known NP-complete problem deciding whether boolean formulaconjunctive normal form three literals per clause admits satisfying assignment(Garey & Johnson, 1979).3. Theoretical Resultsestablish reduction, first express BTTP decision form:INSTANCE:(a) 2n teams, n teams belong league X n teams belong league .(b) 2n 2n distance matrix whose entries distances pairteams X .(c) integer 0.QUESTION: exist double round-robin bipartite tournament which:(a) at-most-three, no-repeat, each-venue conditions satisfied.(b) sum distances traveled 2n teams .95fiHoshino & KawarabayashiSimilarly, express BTTP* decision form, adding uniformity constraint (i.e., given time slot, team plays home iff every team leaguealso plays home). reduce two problems 3-SAT.Let = C1 C2 . . . Cm conjunction clauses three literalsvariables {u1 , u2 , . . . , ul }. S, define sets XS YS representing teamsleagues X . set |XS | + |YS | vertices, describe polynomialtime algorithm constructs complete graph assigns edge weights producedistance matrix DS . prove existence integer = (m)solutions BTTP BTTP* total travel distance iff satisfiable.establish desired polynomial-time reductions.assume literals ui ui occur equally often 1 l.see why, assume without loss ui occurs less frequently ui . repeated additiontautological clause (ui ui+1 ui+1 ), affect satisfiability S,ensure number occurrences ui matches ui .Let r(i) denote number occurrences ui S. Figure 1, present gadgetvariable ui , vertices ui,r ui,r correspond respectively r thoccurrence ui ui S, vertex ai,r adjacent ui,r1 ui,r , vertex bi,radjacent ui,r ui,r . (Note: ui,0 := ui,r(i) i.)Figure 1: Gadget 3-SAT reduction.gadget used establish NP-completeness deciding whether undirected graph contains given number vertex-disjoint s-t paths specified length (Itai,Perl, & Shiloach, 1982) prove original TTP NP-complete (Thielen &Westphal, 2010).l gadgets, one ui , = 1, 2, . . . , l. define gadget graph GS .create vertices cj dj 1 j m, one pair clause S. Join cj dj .connect cj vertex ui,r iff clause Cj contains r th occurrence ui S. Similarly,connect cj vertex ui,r iff clause Cj contains r th occurrence ui S.illustrate, let = C1 C2 C3 C4 C5 C6 C7 C8 , C1 = (u1 u2 u3 ),C2 = (u1 u2 u3 ), C3 = (u1 u2 u4 ), C4 = (u2 u3 u4 ), C5 = (u1 u3 u4 ),C6 = (u1 u2 u4 ), C7 = (u2 u3 u4 ), C8 = (u1 u3 u4 ). definition,instance 3-SAT. gadget graph GS given Figure 2.Since literal occurs often negation, clause three literals,number clauses must even. Hence, = 2k integer k 1.instance S, define set XS 18k vertices corresponding teams leagueX. define another set YS , 3 vertices (labelled p, q, r), place96fiScheduling Bipartite Tournaments Minimize Total Travel DistanceFigure 2: gadget graph GS instance S.6k teams three vertices. create 36k-team league, 18k teamsX . weight edge correspond distanceteams located vertices. Using gadget graph GS , define edgeweights way satisfiable iff solutions BTTP BTTP* totaldistance = (k) = 96k2 (2900k2 + 375k + 11). establish desiredpolynomial-time reductions 3-SAT.first define XS . Let C = {c1 , c2 , . . . , c2k } = {d1 , d2 , . . . , d2k },set vertices corresponding gadget graph GS . Let U set 6kvertices form ui,r ui,r appear GS , let B respectively setvertices form ai,r bi,r appear GS . Finally, present two additionalsets, E = {e1 , e2 , . . . , ek } F = {f1 , f2 , . . . , fk }, matched verticesU cycle cover.define XS = B C E F U . Hence, |XS | = |A| + |B| + |C| + |D| + |E| +|F | + |U | = 3k + 3k + 2k + 2k + k + k + 6k = 18k.defined XS , define edge weights connecting pair verticesXS , thus producing complete graph 18k vertices. weight edgefunction k. readability, express weight function z,z := 20k + 1. edge complete graph, assign weight set{z 2 , z 2 + z, 2z 2 1} follows:(1) weight z 2 given every edge appears gadget graph GS , 6k2edges U E, k edges connecting ei fi (for 1 k).(2) weight z 2 + z given 6k2 edges U F , 6k edges connectingB common neighbour U , 6k edges connecting Ucommon neighbour C.(3) weight 2z 2 1 given every edge.create inter-league tournament 36k total teams. First, assign18k teams league X 18k vertices graph XS , distance97fiHoshino & Kawarabayashihome venues two teams edge weight corresponding two verticescomplete graph.Let YS = {p, q, r}. define 18k teams league follows: place 6k teamspoint p, 6k teams point q, 6k teams point r.Therefore, |XS YS | = 18k + 3. extend complete graph 18k verticesinclude three additional vertices. assign edge weight connecting pairinter-league vertices, read matrix given Table 3.aAbBcCdDeEf FuUp YSz2z222z 1z222z 1z22z +zq YSz2 + z2z 2 1z222z 1z2 + zz22z + 2zr YS2z 2 1z2 + zz2 + zz2z22z 2 1z 2 + 2zTable 3: Weights edges connecting XS YS .example, edge ci p given weight 2z 2 1, = 1, 2, . . . , 2k.repeat process 7 3 = 21 pairs connecting vertex XS =B C E F U vertex YS = {p, q, r}.Finally, let weights edges pq, pr, qr 2z 2 1. result,created complete graph vertex set XS YS , assigned weightedge. Moreover, weight edge appears set {z 2 , z 2 + z, z 2 + 2z, 2z 2 1},z = 20k + 1. versions TTP require teams located pointssatisfying Triangle Inequality, chosen weights inter-league variantBTTP ensure Triangle Inequality holds triplet points XS YS .partition 18k vertices XS groups cardinality threeattach {p, q, r} = YS produce union cycles length 4.formally, define following:Definition 1. YS , y-rooted 4-cycle-cover union cycles length4, every cycle contains y, cycle contains vertex YS \{y}, everyvertex XS appears exactly one cycle.Figure 3: p-rooted 4-cycle-cover 18 vertices set XS .98fiScheduling Bipartite Tournaments Minimize Total Travel Distanceillustrate, Figure 3 gives p-rooted 4-cycle-cover |XS | = 18. definitionmotivated tournament construction, show total travel distanceminimized creating uniform schedule team takes maximum numberthree-game road trips play 18k away games. case 6k teams YSlocated vertex p, 6k three-game road trips correspond 6k 4-cyclesminimum weight p-rooted 4-cycle-cover. example, p-u1,1 -c5 -d5 -p appears one6k cycles, team YS located vertex p play three consecutive road gamestournament teams XS located u1,1 , c5 , d5 .total distance traveled team YS bounded sumedge weights minimum weight y-rooted 4-cycle-cover.Definition 2. define three special types cycles may appear p-rooted 4-cyclecover.(1) (p, a, u, b, p)-cycle 4-cycle vertices p, a, u, b order, p YS ,A, u U , b B, au ub edges gadget graph GS .(2) (p, u, c, d, p)-cycle 4-cycle vertices p, u, c, order, p YS ,u U , c C, D, uc cd edges gadget graph GS .(3) (p, u, e, f, p)-cycle 4-cycle vertices p, u, e, f order, p YS ,u U , e E, f F , e f index (i.e., ei fi1 k.)example, instance whose gadget graph illustrated Figure 2, p-a1,2 u1,1 -b1,1 -p (p, a, u, b, p)-cycle, p-a1,2 -u1,1 -b4,2 -p not. Similarly, p-u4,3 -c8 -d8 -p(p, u, c, d, p)-cycle, p-u4,3 -c7 -d7 -p not.Following convention TTP (Easton, Nemhauser, & Trick, 2002), defineILBt individual lower bound team t. value represents minimumpossible distance traveled team order complete gamesconstraints BTTP, independent teams schedules. definition,team located YS , value ILBt minimum weight y-rooted4-cycle-cover.Similarly, define league lower bound LLBT minimum possible distancetraveled teams league , tournament lower bound LBminimum possible distance traveled teams leagues. note followingtrivial inequalities:LLBXLB LLBX + LLBYXXILBt , LLBYILBt .tXtYdefinition, solution BTTP tournament schedule whose total travel distanceLB.definitions need complete proof NP-completenessBTTP BTTP*. create inter-league tournament 18k teamsXS 18k teams YS (with one-third teams vertex YS ),99fiHoshino & Kawarabayashishow exists distance-optimal uniform tournament total distance(k) = 96k2 (2900k2 + 375k + 11) iff satisfiable. establish polynomialtime reduction 3-SAT, since transformations construction clearlypolynomial.desired result follow next four lemmas. lemma, let KScomplete graph 18k + 3 vertices XS YS , edge weights describedconstruction. interested reader, proofs three lemmas appearAppendix A.Lemma 1. following statements equivalent:(i) = C1 C2 . . . C2k satisfiable.(ii) exists p-rooted 4-cycle-cover KS exactly 3k (p, a, u, b, p)-cycles, 2k(p, u, c, d, p)-cycles, k (p, u, e, f, p)-cycles.Lemma 2. following statements equivalent:(i) p-rooted 4-cycle-cover KS exactly 3k (p, a, u, b, p)-cycles, 2k (p, u, c, d, p)cycles, k (p, u, e, f, p)-cycles.(ii) p-rooted 4-cycle-cover KS total edge weight k(24z 2 + 3z).Lemma 3. Let ILBy minimum total edge weight y-rooted 4-cycle-cover KS .= pk(24z 2 + 3z)ILBy =k(24z 2 + 20z)= qk(24z 2 + 19z)= rLet us illustrate three lemmas specific example. Let = C1 C2 C3C4 C5 C6 C7 C8 instance 3-SAT whose gadget graph GS presentedFigure 2. Recall defined C1 = (u1 u2 u3 ), C2 = (u1 u2 u3 ), C3 = (u1 u2 u4 ),C4 = (u2 u3 u4 ), C5 = (u1 u3 u4 ), C6 = (u1 u2 u4 ), C7 = (u2 u3 u4 ),C8 = (u1 u3 u4 ).Suppose satisfiable, i.e., function : {u1 , u2 , u3 , u4 } {TRUE, FALSE}clause Ci evaluates TRUE 1 8. symmetry, mayassume without loss (u4 ) TRUE. clauses C6 , C7 , C8 , see1 3, (ui ) must TRUE FALSE. former, clause C2 FALSE,latter, clause C1 FALSE. Therefore, satisfiable.Since satisfiable, Lemma 1, exist p-rooted 4-cycle-coverKS 12 (p, a, u, b, p)-cycles, 8 (p, u, c, d, p)-cycles, 4 (p, u, e, f, p)-cycles.Lemma 2 Lemma 3, minimum weight p-rooted 4-cycle-cover KS strictlylarger 4(24z 2 + 3z).show (non-satisfiable) instance cannot yield graph KS formingdistance-optimal inter-league tournament, satisfiable instance indeed does.defined special 4-cycles rooted p (e.g. (p, a, u, b, p)-cycles), similarly define 4-cycles rooted q r. Lemma 3, lower bound ILBq occursq-rooted 4-cycle-cover consists 3k (q, u, b, a, q)-cycles, 2k (q, c, d, u, q)-cycles, k100fiScheduling Bipartite Tournaments Minimize Total Travel Distance(q, f, u, e, q)-cycles, total edge weight 3k(4z 2 + 4z) + 2k(4z 2 + 3z) + k(4z 2 + 2z) =k(24z 2 + 20z). lower bound ILBr occurs r-rooted 4-cycle-cover consists 3k(r, b, a, u, r)-cycles, 2k (r, d, u, c, r)-cycles, k (r, e, f, u, r)-cycles, total edge weight3k(4z 2 + 4z) + 2k(4z 2 + 2z) + k(4z 2 + 3z) = k(24z 2 + 19z). apply informationfollowing lemma constructing distance-optimal bipartite tournament.Lemma 4. satisfiable, exists uniformschedule (i.e., solutionPBTTP well BTTP*) whose total travel distanceILBt = k2 (696z 2 + 408z 48) =2296k (2900k + 375k + 11).Proof. Lemma 1, satisfiable, exists p-rooted 4-cycle-cover KSexactly 3k (p, a, u, b, p)-cycles, 2k (p, u, c, d, p)-cycles, k (p, u, e, f, p)-cycles. Considerp-rooted 4-cycle-cover. relabel teams XS follows:First let {x0 , x1 , x2 }, {x3 , x4 , x5 }, . . . , {x9k3 , x9k2 , x9k1 } vertices 3k(p, a, u, b, p)-cycles, x3i A, x3i+1 U , x3i+2 B 0 3k 1.let {x9k , x9k+1 , x9k+2 }, {x9k+3 , x9k+4 , x9k+5 }, . . . , {x15k3 , x15k2 , x15k1 }vertices 2k (p, u, c, d, p)-cycles, x3i U , x3i+1 C, x3i+23k 5k 1.Finally, let {x15k , x15k+1 , x15k+2 }, {x15k+3 , x15k+4 , x15k+5 }, . . . , {x18k3 , x18k2 , x18k1 }vertices k (p, u, e, f, p)-cycles, x3i U , x3i+1 E, x3i+2 F5k 6k 1.explain proof clearly, use relabeling teams XS , letting vertex xi 0 18k 1. also relabel teams YS ,{p0 , p1 , . . . , p6k1 } teams p, {q0 , q1 , . . . , q6k1 } teams q,{r0 , r1 , . . . , r6k1 } teams r.Since every team plays two games 18k teams league,tournament 36k time slots. build double round-robin bipartite tournamentteams league play home games slots (i.e., scheduleuniform.) Specifically, team XS play three consecutive home games followedthree consecutive road games repeat pattern 6k times. Similarly, teamYS play three consecutive road games followed three consecutive home gamesrepeat pattern end tournament. Given way constructededge weights, natural way construct distance-optimal tournament,team takes trips possible.Lemma 3, determined value ILBv v YS = P Q R.ILBpi = k(24z 2 + 3z), ILBqi = k(24z 2 + 20z), ILBri = k(24z 2 + 19z),0 6k 1. Therefore, LLBYS 6k2 (24z 2 + 3z) + 6k2 (24z 2 + 20z) + 6k2 (24z 2 + 19z) =6k2 (72z 2 + 42z).determine value ILBt XS = B C E F U . Everyteam XS plays road game 18k teams YS , 6k teams locatedpoints p, q, r. Team must make least 6k3 = 2k trips p, q, r, sincemaximum length road trip three games. Therefore, ILBt 2k(Dt,p +Dt,q +Dt,r ),Dt,v distance XS YS choices y. Note equalityoccur, specifically road trips team scheduled efficient way,trip consisting three consecutive games three teams locatedpoint.101fiHoshino & KawarabayashiTable 3, determine ILBt = 2k(Dt,p + Dt,q + Dt,r ) = 4k(4z 2 + z 1)B C E. Similarly, ILBt = 4k(4z 2 1) F , ILBt = 4k(3z 2 + 5z)U . Thus,LLBXS4k(4z 2 + z 1)(|A| + |B| + |C| + |E|) + 4k(4z 2 1)(|D| + |F |) + 4k(3z 2 + 5z)(|U |)= 4k(4z 2 + z 1)(3k + 3k + 2k + k) + 4k(4z 2 1)(2k + k) + 4k(3z 2 + 5z)(6k)= 36k2 (4z 2 + z 1) + 12k2 (4z 2 1) + 24k2 (3z 2 + 5z)= k2 (264z 2 + 156z 48).PTherefore, LB LLBXS + LLBYSILBt = k2 (264z 2 + 156z 48) + 6k2 (72z 2 +2242z) = k (696z + 408z 48). complete proof, suffices construct tournamentteamsdistance matches individual lower bound.P total travelprove LB =ILBt = k2 (696z 2 + 408z 48).0 6k 1 0 j 6k 1, determine opponent teams pi , qi ,ri time slots 6j + 1, 6j + 2, 6j + 3, 6j + 4, 6j + 5, 6j + 6. Table 4, provideschedule games slots 6j + 1, 6j + 2, 6j + 3, teams XS play hometeams YS play road. table, function f (i, j) always reducedmodulo 18k, x18k+z := xz 0 z 18k 1.Gamepiqiri6j + 1x3(i+j)+0x3(i+j)+1x3(i+j)+26j + 2x3(i+j)+1x3(i+j)+2x3(i+j)+06j + 3x3(i+j)+2x3(i+j)+0x3(i+j)+1Gamepiqiri6j + 1x3(i+j)+0x3(i+j)+2x3(i+j)+16j + 2x3(i+j)+1x3(i+j)+0x3(i+j)+26j + 3x3(i+j)+2x3(i+j)+1x3(i+j)+0Table 4: left table lists schedule matches j satisfy + j{0, 1, . . . , 5k 1} (mod 6k), right table lists schedule jsatisfy + j {5k, 5k + 1, . . . , 6k 1} (mod 6k).Fix i. construction, team pi , qi , ri play {x0 , x1 , . . . , x18k1 }road exactly once. fix j. time slot 6j + k (with 1 k 3), team XSappears exactly once, playing unique opponent YS . teams schedule correspondsrooted 4-cycle-cover. labeling scheme, 4-cycle-cover team pi consists3k (p, a, u, b, p)-cycles, 2k (p, u, c, d, p)-cycles k (p, u, e, f, p)-cycles. Similarly,4-cycle-cover team qi consists 3k (q, u, b, a, q)-cycles, 2k (q, c, d, u, q)-cycles,k (q, f, u, e, q)-cycles. Finally, 4-cycle-cover team ri consists 3k (r, b, a, u, r)cycles, 2k (r, d, u, c, r)-cycles, k (r, e, f, u, r)-cycles. Therefore, team YS plays6k road trips total travel distance equal minimum weight4-cycle-cover rooted vertex, definition equal teams individuallower bound. Thus, constructed schedule LLBYS = 6k2 (72z 2 + 42z).construct half schedule, teams YS play hometeams XS play road. much simpler construction. example,one way build half schedule match triplet teams XS (e.g.{x0 , x1 , x2 }) triplet teams vertex YS (e.g. {p0 , p1 , p2 }),three consecutive slots games two triplets home venues102fiScheduling Bipartite Tournaments Minimize Total Travel Distanceteams league YS . Repeating process, ensure 6k tripletsXS play 6k triplets YS via three-game road trips. Thus, schedule satisfiesLLBXS = k2 (264z 2 + 156z 48).required putting schedules together ensure no-repeat rule,simple matter given flexibility constructing halftournament schedule.Therefore, completedbipartite tournamentPour proof. 2If satisfiable,2teams XS YS LB = ILBt = k (696z +408z48). Recalling z = 20k+1,conclude LB = 96k2 (2900k2 + 375k + 11).illustrate preceding proof, Table 5 gives distance-optimal schedule casek = 1, 18 teams league. present schedule teams YS sinceimmediately derive schedule teams XS table. always,home games marked bold.Gamep0q0r0p1q1r1...p5q5r51x0x1x2x3x4x5...x15x17x162x1x2x0x4x5x3...x16x15x173x2x0x1x5x3x4...x17x16x154x0x6x12x1x7x13...x5x11x175x2x8x14x0x6x12...x4x10x166x1x7x13x2x8x14...x3x9x157x3x4x5x6x7x8...x0x1x28x4x5x3x7x8x6...x1x2x09x5x3x4x8x6x7...x2x0x110x3x9x15x4x10x16...x1x7x1311x5x11x17x3x9x15...x2x8x1412x4x10x16x5x11x17...x0x6x12..................................................................31x15x17x16x0x1x2...x12x13x1432x16x15x17x1x2x0...x13x14x1233x17x16x15x12x0x1...x14x12x1334x9x15x3x10x16x4...x7x13x135x11x17x5x9x15x3...x8x14x236x10x16x4x11x17x5...x6x12x0Table 5: distance-optimal inter-league tournament 18 teams league.provided lemmas, prove main theorem paper.Theorem 1. BTTP BTTP* NP-complete.Proof. Let instance 3-SAT 2k clauses, create sets XS YS , edgeweights described construction. Consider inter-league tournament18k teams XS 18k teams YS (with one-third teams vertexYS ).Lemma 4, satisfiable, exists uniform double round-robin bipartitetournament total distance 96k2 (2900k2 + 375k + 11). definition,tournament feasible solution BTTP BTTP*. prove converse.Let (k) = 96k2 (2900k2 + 375k + 11). Consider inter-league tournament P36k teams total travel distance (k). Lemma 4, (k) =ILBt .Hence, every team XS YS must travel shortest possible distance ILBt playgames. Lemma 3, implies every team located p YS must traveldistance ILBp = k(24z 2 + 3z).Lemma 2, team p YS travels distance k(24z 2 + 3z), graph KSmust contain exactly 3k (p, a, u, b, p)-cycles, 2k (p, u, c, d, p)-cycles, k (p, u, e, f, p)-cycles.Lemma 1, occurs iff satisfiable.Therefore, constructed double round-robin bipartite tournament KS 36kteams distance matrix DS solutions BTTP BTTP* total103fiHoshino & Kawarabayashidistance (k) iff instance 2k clauses satisfiable. establishes desiredpolynomial-time reduction 3-SAT, proving NP-hardness BTTP BTTP*.Finally, note problems clearly NP, since distance traveledteams calculated polynomial time. Therefore, conclude BTTP BTTP*NP-complete.illustrate difference BTTP BTTP*, provide concrete illustration case n = 3. Let teams X = {x1 , x2 , x3 } = {y1 , y2 , y3 }.Figure 4, teams located Cartesian plane, x1 x2 representpoint, y1 y2 represent point, non-negative distances a, b, c satisfyPythagorean equation a2 + b2 = c2 .Figure 4: Illustration BTTP case n = 3.straightforward show ILBx1 = ILBx2 = ILBx3 = + b + c, ILBy1 =ILBy2 = 4a ILBy3 = 2a + 2c. Hence, LB LLBX + LLBY (3a + 3b + 3c) + (10a +2c) = 13a + 3b + 5c.order LB = 13a + 3b + 5c, teams X must play three-gameroad stand consecutive games y1 y2 , teams mustplay three-game road stand consecutive games x1 x2 . One quicklyshow scenario impossible, nearly-best schedule achievedmaking either y1 y2 take extra trip, adding 2a total distance. Hence,solution BTTP must distance least 15a + 3b + 5c.BTTP*, LB 16a + 4b + 4c since LLBX = 4a + 4b + 2c LLBY =12a + 2c uniform schedule. problems, justify optimality presentingfeasible tournament satisfying stated tournament lower bounds. presentedTable 6.Teamx1x2x3y1y2y31y1y2y3x1x2x32y2y3y1x3x1x23y3y1y2x2x3x14y1y2y3x1x2x35y2y3y1x3x1x26y3y1y2x2x3x1Teamx1x2x3y1y2y31y1y2y3x1x2x32y3y1y2x2x3x13y2y3y1x3x1x24y1y2y3x1x2x35y3y1y2x2x3x16y2y3y1x3x1x2Table 6: Solutions BTTP* BTTP, total distance 16a+4b+4c 15a+3b+5c,respectively.104fiScheduling Bipartite Tournaments Minimize Total Travel Distanceexample, solution BTTP requires 25 trips, one trip solutionBTTP*, yet tournament lower bound reduced + b c > 0. seeconcluding section, many examples solution n = 3 BTTPrequires 24 trips.illustrate example case n = 6, consider 12-team league sixteams X . Place three points A, B, C equally spaced around unit circle,4ABC equilateral. Place {x1 , x2 } A, {x3 , x4 } B, {x5 , x6 } C.place {y1 , y2 , . . . , y6 } centre circle. best lower bound ILByj = 6occurs yj plays two-game road trips {x1 , x2 }, {x3 , x4 }, {x5 , x6 } pairs ratherthree-game road trips {x1 , x2 , x3 } {x4 , x5 , x6 }, total distance4 + 2 3 > 6. clearly best lower bound ILBxi = 4 occurs xi plays three-gameroad trips teams , making two trips centre circle.Table 7 provides distance-optimal schedule uniform, thus provingsimple example, solution BTTP BTTP*. However, noteunlike proof Theorem 1, 12-team scenario, best schedule requires 102 totaltrips, six fewest possible number total trips.x1x2x3x4x5x6y1y2y3y4y5y61y1y2y3y4y5y6x1x2x3x4x5x62y2y1y4y3y6y5x2x1x4x3x6x53y1y2y3y4y5y6x1x2x3x4x5x64y2y3y1y5y6y4x3x1x2x6x4x55y3y1y2y6y4y5x2x3x1x5x6x46y4y3y6y5y2y1x6x5x2x1x4x37y3y4y5y6y1y2x5x6x1x2x3x48y4y5y6y1y2y3x4x5x6x1x2x39y5y6y4y2y3y1x6x4x5x3x1x210y6y4y5y3y1y2x5x6x4x2x3x111y5y6y1y2y3y4x3x4x5x6x1x212y6y5y2y1y4y3x4x3x6x5x2x1Table 7: Solution BTTP BTTP* scenario n = 6.provided simple illustrations n = 3 n = 6, analyze BTTP twoprofessional sports leagues, namely Nippon Professional Baseball league (with n = 6)National Basketball Association (with n = 15).4. Japanese BaseballNippon Professional Baseball (NPB) Japans largest professional sports league.NPB, teams split two leagues six teams, team playing 120 intraleague 24 inter-league games regular season. intra-league problemanalyzed recently authors (Hoshino & Kawarabayashi, 2011c), developedmulti-round generalization TTP based Dijkstras shortest path algorithmapplied produce distance-optimal schedule reducing total travel distance60000 kilometres (a 25% reduction) compared 2010 NPB intra-league schedule(Hoshino & Kawarabayashi, 2011d). Given Japan small island country, 60000kilometre reduction represents significant amount.105fiHoshino & Kawarabayashiconsider inter-league problem, six teams NPB PacificLeague play four games six teams NPB Central League, onetwo-game set played home Pacific League team, two-game setplayed home Central League team. inter-league games take placefive-week stretch mid-May mid-June, intra-league games occurringperiod. Thus, NPB inter-league scheduling problem precisely BTTP,case n = 6.Figure 5: Location 12 teams NPB.locations teams home stadium marked Figure 5. readability,label team follows: Pacific League teams p1 (Fukuoka), p2 (Orix), p3(Saitama), p4 (Chiba), p5 (Tohoku), p6 (Hokkaido), Central League teams c1(Hiroshima), c2 (Hanshin), c3 (Chunichi), c4 (Yokohama), c5 (Yomiuri), c6 (Yakult).actual 12 12 NPB distance matrix provided Appendix B.solve BTTP NPB, producing inter-league schedule requiring 42950kilometres total travel, representing 16% reduction compared 51134 kilometrestraveled teams 2010 inter-league schedule (Hoshino & Kawarabayashi,2011a). accomplish this, present two powerful reduction heuristics. motivateheuristics, first require several key definitions.X , let St set possible schedules played teamsatisfying at-most-three each-venue constraints. Let St possible scheduleteam t. , list opponents six road sets, ignore homesets, since determine total distance traveled team road sets.give example, feasible schedule x1 Sx1 case n = 6:x11y12y6345y36y57y4891011y212following team schedule x1 , represents home set played x1unique opponent . Note x1 satisfies at-most-three each-venue constraints.Let = (x1 , x2 , . . . , xn , y1 , y2 , . . . , yn ), St X . Sinceroad sets X correspond home sets vice-versa, suffices list timeslots opponents n road sets , since uniquely determinefull schedule 2n sets every team X , thus producing inter-league tournament106fiScheduling Bipartite Tournaments Minimize Total Travel Distanceschedule . note feasible solution BTTP iff team plays uniqueopponent every time slot, team schedule violates no-repeat constraint.section, frequently refer team schedules tournament schedules .context clear whether schedule individual team X ,2n teams X .before, define ILBt individual lower bound team t, minimum possibledistance traveled team order complete 2n sets.St , let d(t ) integer d(t )+ILBt equals total distancetraveled team playing schedule . definition, d(t ) 0.= (x1 , . . . , xn , y1 , . . . , yn ), defineXd() =d(t ).tXYPSinceILBt fixed, optimal solution BTTP schedule d()minimized. motivation function d().subset St St , define lower bound functionB(St ) = min d(t ).StSt = St , B(St ) = 0 definition ILBt . subset St , define |St |cardinality.example, consider n = 6 instance Table 7, located six teamsleague X two teams assigned vertex equilateral triangle.mentioned end Section 3, ILBy1 = 6, equality occurring iff y1 playstwo-set road trips {x1 , x2 }, {x3 , x4 }, {x5 , x6 }. let Sy1 restrictionSy1 subset schedules y1 starts three consecutive roadsetsteams x1 , x2 , x3.schedule must total distance 4+ 2 3, implyingB(Sy1 ) = 4 + 2 3 ILBy1 = 2 3 2 > 0.n multiple 3, define team set R3t subset schedulesSt n road sets occur n3 blocks three (i.e., team takes n3 three-set roadtrips). example, Table 5 (which n = 18), every team plays schedule R3t .Finally, define global constraint fixes subset matches, Stsubset schedules St consistent global constraint.example, simple constraint forces y2 play x1 home time slot3, Sx1 would consist team schedules slot 3 road set y2 .much complex global constraint (e.g. number fixed matcheslarge), |St | significantly less |St |.illustrate concept, consider n = 6 instance global constrainty1 starts three consecutive road sets teams x1 , x2 , x3 (inorder). One show 34 valid home-road patterns Sy1 , includingRRR-HHH-RRR-HHH RRR-H-R-HH-R-HH-R-H. home-road pattern,3! = 6 ways assign {x4 , x5 , x6 } last three road sets. Thus, |Sy1 | = 343! = 204,significantly less |Sy1 | shown equal 616 6! = 443520.simple notion global constraints inspires first result, powerful reductionheuristic drastically cuts computation time.107fiHoshino & KawarabayashiProposition 1. Let fixed positive integer. global constraint , defineX ,()XZt = St : d(t ) + B(St )B(Su ) .uXY= (x1 , . . . , xn , y1 , . . . , yn ) feasible tournament schedule consistentd() , X , team ts schedule appears Zt .Proof. Consider tournament schedules consistent . d() ,prove. assume. LettingP schedule satisfiesP d()P nothing),), d() =d()B(SQ =B(SuuuuXYuXYuXYQ.Zt , Zt St implying d(t ) B(St ). suppose existsv X v/ Zv . Since v consistent , v Sv d(v ) >+ B(Sv ) Q B(Sv ). contradiction,Xd() = d(v ) +d(u )uXY,u6=v> (M + B(Sv ) Q) += (M +B(Sv )XB(Su )uXY,u6=vQ) + (Q B(Sv )) = M.Hence, = (x1 , . . . , xn , y1 , . . . , yn ) feasible tournament schedule consistentd() , Zt X .Proposition 1 shows perform reduction prior propagation, mayapplicable problems. apply proposition, reduce BTTP kscenarios scenario six home sets four Pacific League teamspre-determined. Expressing scenarios global constraints 1 , 2 , . . . , k ,fixes 24 72 total matches.every , determine Zcj Central League teams setting lowthreshold , show |Zcj | considerably smaller |Scj |, thus reducingsearch space amount quickly analyzed. there, run simplesix-loop generates 6-tuples (c1 , c2 , c3 , c4 , c5 , c6 ) appear feasibleschedule d() . Proposition 1, cj Zcj 1 j 6. listpossible 6-tuples, quickly find optimal schedule correspondssolution BTTP.present result works case n = 6, two teams oneleague located quite far 10 teams, forcing distance-optimal scheduleparticular structure.Proposition 2. Let fixed positive integer, define St = {t St : d(t ) }.xSuppose exist two teams xi , xj X = {x1 , x2 , . . . , x6 } Sxi R3xi , Sxj R3 j ,team yk , every schedule Syk property yk plays roadsets xi xj two consecutive time slots. = (x1 , . . . , x6 , y1 , . . . , y6 )feasible tournament schedule d() St , team schedules108fiScheduling Bipartite Tournaments Minimize Total Travel Distancexi xj home-road pattern HH-RRR-HH-RRR-HH; moreover, teamssix home slots must following structure permutation (a, b, c, d, e, f ){1, 2, 3, 4, 5, 6}:xixj1yayb2ybya3456ycyd7ydyc891011yeyf12yfyeProof. first note xi xj structure, satisfy givenxconditions since xi R3xi , xj R3 j , every team yk plays road sets xixj two consecutive time slots. example, yd plays road sets xj slot 6xi slot 7. prove xi xj must structure.team xt X time slot [1, 12], define O(xt , s) opponentteam xt set s. define O(xt , s) xt playing home; sets xtplays road, O(xt , s) undefined.Since xi Sxi Sxi R3xi , four possible cases consider:(1) xi plays set 1 home, sets 2 4 road.(2) xi plays sets 1 2 home, sets 3 5 road.(3) xi plays sets 1 3 home, sets 4 6 road.(4) xi plays sets 1 3 road, set 4 home.examine cases one one. each, suppose exists feasible schedulesatisfying given conditions. finish case (2).(1), let O(xi , 1) = ya . O(xj , 2) = ya , since ya must play road sets xixxj consecutive time slots. Since xj R3 j xj plays home set 2, xj mustalso play home set 1. Thus, O(xj , 1) = yb yb , forces O(xi , 2) = yb .contradiction xi plays set 2 road.(3), let O(xi , 1) = ya , O(xi , 2) = yb , O(xi , 3) = yc . O(xj , 2) = yaO(xj , 4) = yc . Either O(xj , 1) = yb O(xj , 3) = yb . either case, violate at-mostxthree constraint condition xj R3 j .(4), team xi starts three-set road trip. order satisfy at-most-threeconstraint, xi must pattern RRR-HHH-RRR-HHH. reduces case(3), read schedule backwards, letting O(xi , 12) = ya , O(xi , 11) = yb ,O(xi , 10) = yc , applying argument previous paragraph.(2), let O(xi , 1) = ya O(xi , 2) = yb . O(xj , 2) = ya O(xj , 1) = yb .O(xj , 3) = yc yc , O(xi , 4) = yc , forcing xi play single road set slot 3.Thus, xj must play road set 3, therefore also sets 4 5. Hence,xi xj start two home sets followed three road sets. Since caseremaining, symmetry xi xj must end two home sets preceded three roadsets. Thus, two teams must pattern HH-RRR-HH-RRR-HH.order yk play road sets xi xj two consecutive timeslots, must O(xi , 6) = O(xj , 7), O(xi , 7) = O(xj , 6), O(xi , 11) = O(xj , 12),O(xi , 12) = O(xj , 11). completes proof.109fiHoshino & Kawarabayashiuse Proposition 2 solve BTTP, since teams p5 p6 located quite farten teams (see Figure 5). heuristic isolating two teams findingcommon structure significantly reduces search space enables us solve BTTP12-team NPB hours rather weeks.applying results, require weeks computation time multipleprocessors. two heuristics, BTTP solved less ten hourssingle laptop. code written Maple compiled using Maplesoft 13 usingsingle Toshiba laptop Windows single 2.10 GHz processor 2.75 GBRAM.Table 8 presents inter-league tournament schedule solution BTTPd() = (0 + 4 + 0 + 0 + 1 + 1) + (51 + 9 + 31 + 58 + 19 + 13) = 187.p1p2p3p4p5p6c1c2c3c4c5c61c3c5c4c2c1c6p5p4p1p3p2p62c5c3c2c4c6c1p6p3p2p4p1p53c1c2c6c5c4c3p1p2p6p5p4p34c3c1c5c4c6c2p2p6p1p4p3p55c2c3c4c6c5c1p6p1p2p3p5p46c1c6c3c5c2c4p1p5p3p6p4p27c6c1c5c3c4c2p2p6p4p5p3p18c2c4c1c6c3c5p3p1p5p2p6p49c4c5c3c1c2c6p4p5p3p1p2p610c5c6c2c3c1c4p5p3p4p6p1p211c6c4c1c2c5c3p3p4p6p2p5p112c4c2c6c1c3c5p4p2p5p1p6p3Table 8: Solution BTTP total distance 42950 km.Table 8, see seven twelve teams satisfy R3t , namely c1six Pacific League teams. However, every Central League team scheduleplays road sets p5 p6 consecutive time slots. explains d(cj )small.Pclaim optimal solution, total distance d() + ILBt = 187 +42763 = 42950. prove this, set = 187. Define St = {t St : d(t ) },determine Sp5 R3p5 Sp6 R3p6 .Define Tci Sci subset schedules ci play road setsp5 p6 two consecutive time slots. this, show B(Tc3 ) = 153,B(Tcj ) > = 187 j {1, 2, 4, 5, 6}. claim satisfies d() 187,cj/ Tcj 1 j 6.suffices prove claim j = 3. 144 schedules Tc3 ,belong set R3c3 . example, one schedule c3c31p2p23p14p65p6p7p8p39p410p511p12pSuppose exists tournament schedule d() 187 c3 Tc3 .nine possible home-road patterns p5 R3p5 (e.g. HHH-RRR-H-RRR-HH H-RRRHHH-RRR-HH), gives rise 6! = 720 possible orderings six home110fiScheduling Bipartite Tournaments Minimize Total Travel Distancesets. Thus, 9 720 = 6480 ways select time slots opponentssix home sets p5 . Similarly, 6480 ways p6 . simple Maplesoftprocedure shows 140 64802 possible pairs (p5 , p6 ) consistentleast one c3 Tc3 .140 cases, define global constraints 1 , 2 , . . . , 140 , obtainedfixing twelve home sets {p5 , p6 }. k , define j {1, 2, 4, 5, 6}set Zcj = {cj Scjk : d(cj ) B(Tc3 ) = 34}. run six-loop computepossible 6-tuples (c1 , c2 , . . . , c6 ) satisfying given conditions c3 Tc3cj Zcj j 6= 3. Within twenty minutes, Maplesoft solves 140 cases returnsfeasible 6-tuples appear schedule d() 187.Therefore, , cj must play road sets p5 p6 consecutive time slots.Thus, teams p5 p6 satisfy conditions Proposition 2. Hence, home-road patternp5 p6 must HH-RRR-HH-RRR-HH.Without loss, assume p5 plays home set c1 within first six time slots;otherwise read schedule backwards symmetry. Thus, 6!2 = 360ways assign opponents six home sets p5 . Proposition 2, 360arrangements uniquely determines six home sets p6 .short calculation shows order d() = 187, teams p1 p3 must alsoplay six road sets two blocks three. words, p1 R3p1 p3 R3p3 .mentioned earlier, 9 6! possible ways select six home sets p1p3 .Thus, 360 (9 6!) (9 6!) ways select 24 home sets playedteams {p1 , p3 , p5 , p6 }. eliminate scenarios pi pj playck time slot. possibilities remain, create globalconstraint apply Proposition 1.Let {1 , 2 , . . . , k } complete set global constraints derivedprocess, fixes 24 72 matches, corresponding home sets{p1 , p3 , p5 , p6 }. reduction heuristic Proposition 1 allows us quickly verifyexistence feasible tournament schedules consistent d() .explain procedure, let us illustrate inter-league schedule Table 8. Letconstraint fixes 24 home sets teams p1 , p3 , p5 , p6 table.Sc5 , defined subset schedules Sc5 consistent , consists teamschedules c5 c5 plays road sets p1 slot 2, p3 slot 7, p5 slot 11,p6 slot 12.find 11 schedules c5 Sc5 d(c5 ) consistent. Furthermore, d(c5 ) {19, 41, 46, 48}, implying B(Sc5 ) = 19. Similarly,calculate values B(Scj ).PPfind 6j=1 B(Spj ) = 0 6j=1 B(Scj ) = 51 + 9 + 31 + 58 + 19 + 13 = 181,implying Zc5 = {c5 Sc5 : d(c5 ) 187 + 19 181 = 25}. Hence, Zc5 reducestwo schedules d(c5 ) = 19, including team schedule c5 Table 8.Proposition 1, schedule consistent satisfying d() mustproperty Zt team t. Since |Zcj | small, calculation extremelyfast. course, |Zcj | = 0, schedule exist.algorithm, based Propositions 1 2, runs 34716 seconds Maplesoft (just10 hours). Maplesoft generates zero inter-league schedules d() < 187 14111fiHoshino & Kawarabayashiinter-league schedules d() = 187, including schedule given Table 8. Sincemade assumption p5 plays home set c1 within first six time slots,actually twice many distance-optimal schedules reading schedulebackwards.28 distance-optimal schedules , find (d(p1 ), d(p2 ), . . . , d(p6 )) =(0, 4, 0, 0, 1, 1) (d(c1 ), d(c2 ), . . . , d(c6 )) = (51, 9, 31, 58, 19, 13).Therefore, proven Table 8 optimal inter-league schedule NPB,reducing total travel distance 8184 kilometres, 16.0%, compared 2010 NPBschedule.5. American BasketballNational Basketball Association (NBA) one worlds lucrative sportsleagues, four billion dollars annual revenue, average franchise value400 million dollars. 15 teams Western Conference 15 teamsEastern Conference. Every NBA team plays 82 regular-season games, 30inter-league (with one home game one away game 15 teamsconference.) geographic location team provided Figure 6.Figure 6: Map NBAs 15 Western Conference teams 15 Eastern Conferenceteams.Given NBA teams play inter-league games, consider BTTP league,attempt find distance-optimal inter-league tournament. theoreticalproblem, assume inter-league games take place consecutive stretchregular season, done currently Japanese NPB. also enforceconstraints BTTP, including team home stand road trip lasting3 games. note strict conditions part NBA scheduling requirement, evidenced San Antonio Spurs playing 6 consecutive home games followedimmediately 8 consecutive road games 2009-10 regular season. Furthermore,require inter-league schedule compact, i.e., team play onegame time slot. course, compactness condition part typical NBAschedule, one team might play five games time another team played two.112fiScheduling Bipartite Tournaments Minimize Total Travel Distancedetermine 30 30 NBA distance matrix online website1 listsflight distance (in statute miles) pair major cities North America.matrix found Appendix B.Unlike 12-team NPB could solve BTTP, appears highly unlikelysolve problem 30-team NBA. Nonetheless, generateinter-leaguePtournament whose total distance close trivial lower boundILBt , groupingleagues fifteen teams five triplets travel distance teamextremely close ILBt , minimum weight t-rooted 4-cycle-cover. this,construct uniform tournament, i.e., feasible solution BTTP*, WesternConference team alternates playing three away games followed three home games.Given geographic location 30 teams, easy show teams ILBtoccurs playing fifteen away games five groups three. notealways case; give concrete example, consider variant scenario presentedend Section 3. Let points X, Y, Z equally spaced around unit circle,4XY Z equilateral. Place {e1 , e2 } X, {e3 , e4 } , {e5 , e6 } Z. place{w, e7 , e8 , . . . , e15 } centre circle. best lower bound ILBw = 6occurs w plays two-game road trips {e1 , . . . , e6 } pairs ratherthreegame road trips like {e1 , e2 , e3 } {e4 , e5 , e6 }, total distance 4 + 2 3 > 6.However, NBA distance matrix, teams ILBt occurs team fiveroad trips, trip team plays three opponents located close other.Thus, team wi , exists permutation lower boundILBwi attained playing away games fifteen Eastern Conference teamsorder e(1) , e(2) , . . . , e(15) . Note permutation, total distance traveledwiILBwi =5X{Dwi ,e(3j2) + De(3j2) ,e(3j1) + De(3j1) ,c(3j) + De(3j) ,wi }.j=1five triplets {{e(3j2) , e(3j1) , e(3j) } : j = 1, 2, . . . , 5} permuted 5! wayswithout changing total distance. Also, within triplet, change orderfirst third element retaining total. Thus, compute ILBwi15!simple enumeration 5!25 cases, done minutes using Maplesoft.Pthis, calculate PILBt team t, giving LLBW tW ILBt = 251795. Similarly,LLBE tE ILBt = 266137, LB LLBW + LLBE 517932.nearly every case, bounds ILBwi ILBei attained selecting roadtrips indicated Figure 7, corresponding minimum-weight triangle packingleague. example, minimum-weight triangle packing, every Eastern Conference team makes one trip northwest, play Portland, Golden State,Sacramento order. Similarly, every Western Conference team makes one tripsoutheast, play Atlanta, Orlando, Miami order. note naturalconnection minimum-weight triangle packings minimum-weight 4-cycle-covers,remarking former generates approximation latter.Re-label fifteen Western Conference teams five triplets occur side-by-side (i.e.,w1 Portland, w2 Golden State, w3 Sacramento), similarly re-label Eastern1. http://www.savvy-discounts.com/discount-travel/JavaAirportCalc.html113fiHoshino & KawarabayashiFigure 7: minimum-weight triangle packing 30 NBA teams.Conference teams. Similar construction Table 5, build tournament5 5 = 25 pairs inter-league triplets, team one triplet plays threeteams triplet three consecutive time slots (e.g., e1 plays {w1 , w2 , w3 }, e2plays {w2 , w3 , w1 } e3 plays {w3 , w1 , w2 }.) construction produces scheduleEastern Conference teams travel 286683 miles Western Conference teams travel258443 miles, total 545126 miles.improve bound slightly noting away teams forcedtravel according triplets given Figure 7. Specifically, suppose consideringroad trips Eastern Conference. Let triplets {{e(3j2) , e(3j1) , e(3j) } : j =1, 2, . . . , 5}, permutation . triplet {e(3j2) , e(3j1) , e(3j) } travels westthree-game road trips {w1 , w2 , w3 }, {w4 , w5 , w6 }, . . . , {w13 , w14 , w15 }. Ex15!amining 5!25 non-equivalent possibilities , show best permutation= (1, 6, 12, 2, 8, 13, 3, 7, 11, 4, 10, 14, 5, 9, 15), teams {e1 , e6 , e12 } playfirst three games road {w1 , w2 , w3 }, teams {e2 , e8 , e13 } playfirst three games road {w4 , w5 , w6 }, on. optimalschedule, Eastern Conference teams travel total 280294 miles. Similarly, bestpossible case, Western Conference teams travel total 257497 miles.this, produce Table 9, uniform inter-league tournament total Pdistance280294 + 257497 = 537791 miles, 3.8% trivial lower boundILBt .labeling 30 teams (e.g. PT = Portland Trailblazers, MB = Milwaukee Bucks)given Appendix B.Pcertain trivial lower boundILBt cannot achievedeither BTTP BTTP*, conjecture 3.8% figure reduced usingsophisticated techniques. close get? leave challengeinterested reader.Problem 1. Determine better (best?) bounds BTTP BTTP*, 30 30 NBAdistance matrix.114fiScheduling Bipartite Tournaments Minimize Total Travel DistancePTGWSKLCPSUJDNOTSSDMHRMTMGNH1MBTRNKIPWWBCOMCCAHCUDPPSCBNNMH2IPCCNNCUCBNKMHDPOMMBTRWWPSBCAH3CUDPBCMBPSNNAHTRMHIPCCCBWWNKOM4MBCCCBNNTRMHDPOMIPBCWWAHPSCUNK5CBMBCCMHNNTRPSDPWWIPBCNKOMAHCUPTGWSKLCPSUJDNOTSSDMHRMTMGNH16BCWWIPNKCUAHMBCOTRNNMHOMCCDPPS17IPBCWWAHNKCUCCMBMHTRNNPSCOOMDP18WWIPBCCUAHNKCOCCNNMHTRDPMBPSOM19NKPSAHNNMBMHCCCODPBCWWIPCUOMTR20NNWWOMBCCUAHDPPSTRNKCOMBIPMHCC6CCCBMBTRMHNNOMPSBCWWIPCUDPNKAH21BCCOMHNKIPOMTRWWCCNNPSCUMBAHDP7AHMBTROMNKCCPSIPWWMHCUBCNNDPCB22DPPSOMIPBCWWCUAHMBCCCOMHNKTRNN8OMIPCCMHNNDPWWCUCBAHMBNKBCTRPS9MHCUDPAHBCTRCBMBPSOMIPNNNKCCWW10CUNKAHCCMBCBTRMHDPPSOMWWNNIPBC11AHCUNKCBCCMBNNTROMDPPSBCMHWWIP23OMDPPSWWIPBCNKCUCOMBCCNNAHMHTR24PSOMDPBCWWIPAHNKCCCOMBTRCUNNMH25TRNNWWDPOMPSCUBCMBCCNKAHMHCOIP26CCNKCOTRMHWWIPNNCUDPBCOMAHPSMB12NKAHCUMBCBCCMHNNPSOMDPIPTRBCWW27DPBCPSCCAHCOMBNKIPTRNNMHOMWWCU13WWMHMBCBTRIPBCOMNKPSAHDPCCCUNN28TRNNMHDPPSOMBCIPCUNKAHCOWWMBCC14CBOMIPPSCCCUNKAHNNWWMHTRDPMBBC15PSAHCUWWDPMBNNMHBCCBOMCCTRIPNK29MHTRNNOMDPPSWWBCAHCUNKCCIPCOMB30NNMHTRPSOMDPIPWWNKAHCUMBBCCCCOTable 9: close-to-optimal solution NBA BTTP*.6. Conclusionpaper, introduced Bipartite Traveling Tournament Problem appliedtwo professional sports leagues Japan North America, illustrating richnesscomplexity bipartite tournament scheduling.Section 4, introduced two heuristics enabled us solve BTTP n = 6NPB. Proposition 2 applicable certain 12-team configurations satisfyingspecific geometric property, note Proposition 1 general techniqueapplied scheduling problems. method reduction prior propagationbreaks complex problem large number scenarios, sets scenarioglobal constraint reduce search space. confident Proposition 1applied complicated problems sports scheduling.Section 5, determined algorithm produced approximate solutionBTTP n = 15 NBA. finding minimum-weight rooted 4-cycle-covers, determined trivial lower bound BTTP, method creating uniform schedulebased minimum-weight triangle packing generated close-to-optimal feasible solution. NBA inter-league problem, process produced optimality gap3.8%. hopeful ideas abstracted refined further, leadingpowerful tools tackle even harder problem instances.115fiHoshino & KawarabayashiPerhaps sports leagues BTTP applicable, professional hockey football. also expand analysis model tripartitemultipartite tournament scheduling, league divided three conferences. specific example newly-created Super 15 Rugby League, consistingfive teams South Africa, Australia, New Zealand. addition intra-countrygames, team plays four games (two home two away) teamstwo countries. would interesting see whether determinedistance-optimal tripartite tournament schedule using methods developed paper.conclude motivating several interesting questions, including dealinggeometric probability extremal combinatorics, leave open problemsinterested reader.solution non-uniform BTTP required 10 hours computations. Furthermore,able solve BTTP applying Proposition 2, whose requirements wouldhold randomly-selected 12 12 distance matrix. result, requiresophisticated technique improves upon two heuristics, perhaps using methodsconstraint programming integer programming, hybrid CP/IP. wonderexists general algorithm would solve BTTP given distance matrix,small values n n = 6, n = 7, n = 8. pose open problem.Problem 2. Develop computational procedure (or algorithm) routinely solveBTTP BTTP* instances n 6.end Section 3, presented simple example (see Figure 4) illustratedifference BTTP BTTP* case n = 3. located six pointsform two sets Pythagorean triangles, showed solutions two problemstotal distance 15a + 3b + 5c 16a + 4b + 4c, respectively. (a, b, c) = (3, 4, 5),tournament lower bounds 82 84, respectively. words, relaxinguniformity requirement, reduce optimal travel distance 84 82,improvement 2.38%. Using elementary calculus, show particularchoice six points, percentage reduction function 2.39%, equality iff5+3 5b. However, selected different set six points, could achieve better=8percentage reduction? motivates following question:Problem 3. Consider six points X = {x1 , x2 , x3 } = {y1 , y2 , y3 } Cartesianplane. Let tournament lower bounds BTTP* BTTP, respectively.Determine smallest constant c c possible selections sixpoints X .One may conjecture order minimize tournament lower bound, mustminimize total number trips taken 2n teams. saw Table 6,conjecture false n = 3, located six points solution BTTP*requires 24 trips, solution BTTP requires 25 trips. However, numerousexamples (e.g. scenario Table 7) 2n points locatedsolution BTTP* matches BTTP. motivates following question: givenrandom selection 2n points, probability solutions BTTP*BTTP identical?116fiScheduling Bipartite Tournaments Minimize Total Travel Distanceillustrate, consider case n = 3. quickly show exist 60 29 =30720 feasible inter-league tournaments, 60 23 = 480 uniform. runsimulation Maplesoft, scenario, randomly select six points (x, y)Cartesian plane, calculate 15 1 column vector pairwise distances, applyset feasible inter-league tournaments determine distance-optimal schedule.run simulation 100000 times, scenario, note number trips takenoptimal solution. results appear Table 10.TripsScenarios2455800253307726109672743280290Table 10: Results simulation: number trips distance-optimal tournament.note sum total 100000, 113 scenarios endedtie (e.g. two tournaments, one 24 trips another 26 trips,equal total distance rounding two decimal places.)expected, majority scenarios, six points X propertydistance-optimal bipartite tournament involved 24 trips, team played threeconsecutive road games. Without much difficulty, one show (Hoshino & Kawarabayashi,2011a) forces home game slots uniform, i.e., teams leaguemust play home games time, team X plays three consecutivehome games followed three consecutive road games, vice-versa. Therefore, 55.8%randomly-selected scenarios, solution BTTP* identical solutionBTTP.simulation motivates interesting question geometric probability. Given2n points X chosen random, probability tournamentlower bound achieved schedule consisting trips? formally definequestion present open problem reader.Problem 4. Let 2n points X = {x1 , x2 , . . . , xn } = {y1 , y2 , . . . , yn } randomlyselected Cartesian plane. Let number trips taken distance-optimalsolution BTTP, teams located X . Determine value Pn (t)t, Pn (t) represents probability distance-optimal tournament involves2n teams taking exactly trips.case n = 3, appears Pn (t) = 0 23 28.trivial show must least 24 trips, formal proofcannot exist selection six points X plane solution BTTP27 trips. could prove n, number total tripsdistance-optimal solution bounded function f (n), would enableus solve BTTP without enumerate feasible schedules, i.e., small fractionwould suffice. result would certainly aid solving BTTP larger n, fullenumeration feasible tournament schedules computationally laborious.motivates final problem.Problem 5. Consider 2n-team bipartite tournament, teams located X ={x1 , x2 , . . . , xn } = {y1 , y2 , . . . , yn }. n, determine smallest integer f (n)117fiHoshino & Kawarabayashisolution BTTP involves teams taking f (n) trips, regardless2n teams located.Acknowledgmentsresearch partially supported Japan Society Promotion Science(Grant-in-Aid Scientific Research), C & C Foundation, Kayamori Foundation,Inoue Research Award Young Scientists.Appendix A.provide proof three lemmas (from Section 3), beginning Lemma 1.Proof. First, prove (i) (ii).satisfiable, exists function valid truth assignment, i.e.,function (ui ) {TRUE, FALSE} 1 l ensuresclause Cj evaluates TRUE 1 j 2k. , build p-rooted 4-cycle-coverKS exactly 3k (p, a, u, b, p)-cycles, 2k (p, u, c, d, p)-cycles, k (p, u, e, f, p)-cycles.first identify 3k (p, a, u, b, p)-cycles. 1 l, (ui ) FALSE,select 4-cycles form p-ai,r -ui,r -bi,r -p, r = 1, 2, . . . , r(i).(ui ) TRUE, select 4-cycles form p-ai,r+1 -ui,r -bi,r -p, r (whereai,r(i)+1 = ai,1 ). Repeating construction i, produce 3k (p, a, u, b, p)-cycles,covering 6k vertices B, well 3k vertices U .consider clause Cj . Since valid truth assignment, least onethree literals Cj evaluates TRUE. words, must exist indexui Cj (ui ) TRUE, ui Cj (ui ) FALSE.former case, ui Cj (ui ) TRUE, exists index rui,r -cj edge gadget graph GS . p-ui,r -cj -dj -p (p, u, c, d, p)-cycle.Note ui,r previously selected (p, a, u, b, p)-cycle since (ui ) TRUE(and vertices ui,1 , ui,2 , . . . , ui,r(i) covered earlier.)latter case, ui Cj (ui ) FALSE, exists index rui,r -cj edge gadget graph GS . p-ui,r -cj -dj -p (p, u, c, d, p)-cycle.Note ui,r previously selected (p, a, u, b, p)-cycle since (ui ) FALSE(and vertices ui,1 , ui,2 , . . . , ui,r(i) covered earlier.)Repeating construction j, produce 2k (p, u, c, d, p)-cycles, covering 4kvertices C D. Note u U chosen twice since vertex U adjacentone vertex C. Thus, 2k cycles cover set 6k vertices XS , completelydisjoint 9k vertices covered previously-constructed 3k (p, a, u, b, p)-cycles.result, left 3k vertices XS still covered, specifically k verticesU , E, F . vertices trivially partitioned k (p, u, e, f, p)-cyclesensuring ej fj belong cycle 1 j k. processcomplete, p-rooted 4-cycle-cover KS contain exactly 3k (p, a, u, b, p)-cycles, 2k(p, u, c, d, p)-cycles, k (p, u, e, f, p)-cycles.established first direction, prove (ii) (i).118fiScheduling Bipartite Tournaments Minimize Total Travel DistanceConsider p-rooted 4-cycle-cover KS containing exactly 3k (p, a, u, b, p)-cycles, 2k(p, u, c, d, p)-cycles, k (p, u, e, f, p)-cycles. prove exists functionsatisfying truth assignment S, (ui ) {TRUE, FALSE} 1 l.Define a-b path path three vertices whose endpoints ai,j bi,k ,indices i, j, k. Consider problem maximizing number vertex-disjoint a-bpaths ith gadget. One quickly see maximum packing a-b paths occursiff r(i) paths chosen one following trivial ways:(a) Taking paths form ai,r , ui,r , bi,r r = 1, 2, . . . , r(i).(b) Taking paths form ai,r+1 , ui,r , bi,r r = 1, 2, . . . , r(i).ai,r(i)+1 = ai,1 .)(Note:order us cover vertices B, gadget must select a-bpaths either vertically (a) diagonally (b). Thus, p-rooted 4-cycle-cover containing3k (p, a, u, b, p)-cycles, one following scenarios must hold true ith gadget:(1) r = 1, 2, . . . , r(i), vertex ui,r appears (p, a, u, b, p)-cycle,vertex ui,r appears (p, a, u, b, p)-cycle.(2) r = 1, 2, . . . , r(i), vertex ui,r appears (p, a, u, b, p)-cycle,vertex ui,r appears (p, a, u, b, p)-cycle.given p-rooted 4-cycle-cover KS , define (ui ) = FALSE scenario(1) define (ui ) = TRUE scenario (2). claim desired function .prove this, consider 2k (p, u, c, d, p)-cycles 4-cycle-cover. 1 j2k, (p, u, c, d, p)-cycle containing cj also contains vertex U . vertexeither ui,r ui,r , indices r.former case, ui,r cj appear (p, u, c, d, p)-cycle, implying ui,r cj edge gadget graph GS , ui literal clause Cj . Since ui,r appears(p, u, c, d, p)-cycle therefore (p, a, u, b, p)-cycle, implies scenario(2) above. Since (ui ) = TRUE ui Cj , clause Cj evaluates TRUE.latter case, ui,r cj appear (p, u, c, d, p)-cycle, implying ui,r -cjedge gadget graph GS , ui literal clause Cj . Since ui,r appears(p, u, c, d, p)-cycle therefore (p, a, u, b, p)-cycle, implies scenario(1) above. Since (ui ) = FALSE ui Cj , clause Cj evaluates TRUE.Since Cj evaluates TRUE 1 j 2k, implies valid truthassignment. conclude = C1 C2 . . . C2k satisfiable.prove Lemma 2.Proof. First, prove (i) (ii).(p, a, u, b, p)-cycle, edges au ub appear gadget graph GS . Therefore,edge weights au ub z 2 . Table 3, see (p, a, u, b, p)-cycleedge weight z 2 + z 2 + z 2 + z 2 = 4z 2 . Similarly, (p, u, c, d, p)-cycle edge weight(z 2 +z)+z 2 +z 2 +z 2 = 4z 2 +z, (p, u, e, f, p)-cycle edge weight (z 2 +z)+z 2 +z 2 +z 2 =4z 2 + z.119fiHoshino & Kawarabayaship-rooted 4-cycle-cover KS exactly 3k (p, a, u, b, p)-cycles, 2k (p, u, c, d, p)cycles, k (p, u, e, f, p)-cycles, total edge weight exactly 3k(4z 2 ) + 2k(4z 2 +z) + k(4z 2 + z) = k(24z 2 + 3z).established first direction, prove (ii) (i).Let R p-rooted 4-cycle-cover KS union r cycles, total edgeweight k(24z 2 + 3z). Since 18k vertices XS covered exactly one cycleR, number edges R |XS | + r = 18k + r. Since cycle length greater4, r 18k3 = 6k. suppose r 6k + 1. least 24k + 1 edgesR, weight least z 2 given construction complete graph KS .Hence, total edge weight R least (24k +1)z 2 = 24kz 2 +z 2 = 24kz 2 +z(20k +1) >24kz 2 + 3zk = k(24z 2 + 3z), contradiction.follows r = 6k, R must union 6k cycles length 4. Recallweight edge appears set {z 2 , z 2 + z, z 2 + 2z, 2z 2 1}. Supposeone 24k edges weight 2z 2 1. total edge weight R least(24k1)z 2 +(2z 2 1) = 24kz 2 +z 2 1 = 24kz 2 +z(20k+1)1 > 24kz 2 +3zk = k(24z 2 +3z),contradiction. Hence, edges R must weight z 2 , z 2 + z, z 2 + 2z.Table 3, see edges p-c p-e appear 4-cycle-cover R, sinceedges p C E weight 2z 2 1. follows must exist 2k 4-cyclesform p-?-ci -?-p k 4-cycles form p-?-ei -?-p, 2k + k = 3k4-cycles containing unique element C E. blank space (denoted questionmark) filled vertex D, F , U , weights edges ca, cb, ea,eb 2z 2 1 A, b B, c C, e E.Since edge p-u weight z 2 + z, vertex u U chosen appear one3k 4-cycles, adds edge weight z 2 + z, producing 4-cycle weight least4z 2 + z. vertices u U chosen replace blank spaces, cyclesmust form p-dj -ci -dk -p p-fj -ei -fk -p, lead additionleast one edge weight 2z 2 1 (since cannot simultaneously = j, = k,j 6= k). follows 2k + k = 3k 4-cycles containing vertices C E mustweight least 4z 2 + z, thus contributing least k(12z 2 + 3z) total distancep-rooted 4-cycle-cover R.Since given 4-cycle-cover R weight k(24z 2 + 3z), implies rest3k 4-cycles must weight exactly 4z 2 , 2k cycles formp-?-ci -?-p k cycles form p-?-ei -?-p, total edge weight must exactly 4z 2 + zensure total edge weight R exceed k(24z 2 + 3z). impliestwo scenarios, cannot replace two blank spaces two distinct verticesU , would create cycle weight 4z 2 + 2z. follows R must 2k(p, u, c, d, p)-cycles k (p, u, e, f, p)-cycles.left 3k vertices A, B, U form remaining 3k4-cycles. order total edge weight R exceed k(24z 2 + 3z) = 3k(4z 2 + z) +12kz 2 , remaining 12k edges must weight z 2 . Since edge p-u weightz 2 + z u U , 3k remaining vertices U must appear unique 4-cycle,none adjacent root vertex p. follows remaining 3k 4-cycles R must(p, a, u, b, p)-cycles.120fiScheduling Bipartite Tournaments Minimize Total Travel Distanceprove Lemma 3.Proof. proof Lemma 2, see ILBp = k(24z 2 + 3z), handlescase = p. consider case = q.Let R q-rooted 4-cycle-cover KS union r cycles. Supposecontrary exists R total edge weight less k(24z 2 + 20z).derive contradiction.Since 18k vertices XS covered exactly one cycle R, numberedges R |XS |+r = 18k+r. previous proof, r 6k. r 6k+1, totaledge weight R least (24k + 1)z 2 = 24kz 2 + z 2 = 24kz 2 + z(20k + 1) > k(24z 2 + 20z),contradiction.Hence, r = 6k, R must union 6k cycles length 4. supposeone 24k edges weight 2z 2 1. total edge weight R least(24k 1)z 2 + (2z 2 1) = 24kz 2 + z 2 1 = 24kz 2 + z(20k + 1) 1 > k(24z 2 + 20z), anothercontradiction.Therefore, edges q-b q-d appear 4-cycle-cover R, since edgesp B weight 2z 2 1. follows must exist 3k 4-cycles formq-?-bi -?-q 2k 4-cycles form q-?-di -?-q. blank space (denoted questionmark) filled vertex E F since weights edges be, bf , de, df2z 2 1 b B, D, e E, f F .follows k remaining 4-cycles must include k + k = 2k verticesE F . 4-cycles contains three elements E F (e.g. cycle q-ei -fj ek -q cycle q-ei -ej -fk -q), creates least one edge weight 2z 2 1,contradiction. Thus, must exactly two vertices E F 4-cycles.Moreover, since weights edges ae, af , ce, cf 2z 2 1 A, c C,follows final vertex remaining k 4-cycles must element U , thusproducing 4-cycle q-ui,r -ej -fk -q q-fi -uj,r -fk . Table 3, see everyvalid cycle edge weight 4z 2 + 2z.Hence, must k 4-cycles cycle cover R, containing 2k vertices E Fk vertices U , contributing total weight k(4z 2 + 2z). 3k 4-cyclesform q-?-bi -?-q, vertex C appear, otherwise would edge weight2z 2 1. Similarly, 2k 4-cycles form q-?-di -?-q, vertex appear.Thus, 3k 4-cycles containing bi , two vertices must selectedU . Table 3, see every 4-cycle edge weight 4z 2 + 4z.2k 4-cycles containing di , two vertices must selected C U .Also Table 3, see every 4-cycle edge weight 4z 2 + 3z.Therefore, q-rooted 4-cycle-cover KS total edge weight k(4z 2 + 2z) +3k(4z 2 + 4z) + 2k(4z 2 + 3z) = k(24z 2 + 20z), establishing desired contradiction.conclude ILBq = k(24z 2 + 20z).proof r-rooted 4-cycle-cover identical. apply mapping{a, b, c, d, e, f, u} {b, a, e, f, c, d, u} vertices preceding paragraphs reachconclusion. case, ILBr = k(4z 2 +3z)+3k(4z 2 +4z)+2k(4z 2 +2z) =k(24z 2 + 19z).121fiHoshino & KawarabayashiAppendix B.provide 12 12 distance matrix NPB league (from Section 4),30 30 distance matrix NBA (from Section 5).mentioned Section 4, Pacific League teams p1 (Fukuoka), p2 (Orix), p3(Saitama), p4 (Chiba), p5 (Tohoku), p6 (Hokkaido), Central League teams c1(Hiroshima), c2 (Hanshin), c3 (Chunichi), c4 (Yokohama), c5 (Yomiuri), c6 (Yakult).Table 11, provide Dci ,cj Dpi ,pj < j since case > j equivalentsymmetry.Teamc1c2c3c4c5c6p1p2p3p4p5p6c10c23230c34881950c48085153340c5827534353370c68295363553570p12585777429169269230p2341272135335525545950p38705773966351489585950p4857564383583739934582860p589565451136433133311006703743610p612881099984886896893146611159289045800Table 11: Distance Matrix Japanese NPB League.calculate entry distance matrix, determined teams travelone stadium another, taking account actual mode(s) transportation.example, distance Dc2 ,c5 = 534 found adding travel distancecomponent trip Hanshins home stadium Yomiuris home stadium, namely15 km bus ride Koshien Stadium Shin-Osaka Station, 515 km bullet-trainride Tokyo Station, followed 4 km bus ride Tokyo Dome.rigorous approach simply calculating flight distance airports OsakaTokyo. Noting teams travel airplane, bullet train, bus, repeatanalysis 122 = 66 pairs cities produce matrix Table 11.Finally, provide 30 30 distance matrix NBA, well labeling30 teams Table 9. fifteen teams Western Conference, namelyPortland Trailblazers (PT), Golden State Warriors (GW), Sacramento Kings (SK),Los Angeles Clippers (LC), Los Angeles Lakers (LL), Phoenix Suns (PS), Utah Jazz (UJ),Denver Nuggets (DN), Oklahoma Thunder (OT), San Antonio Spurs (SS), Dallas Mavericks(DM), Houston Rockets (HR), Minnesota Timberwolves (MT), Memphis Grizzlies (MG),New Orleans Hornets (NH).fifteen teams Eastern Conference, namely Milwaukee Bucks (MB),Chicago Bulls (CU), Indiana Pacers (IP), Detroit Pistons (DP), Toronto Raptors (TR),Cleveland Cavaliers (CC), Boston Celtics (BC), New York Knicks (NK), New Jersey Nets(NN), Philadelphia Sixers (PS), Washington Wizards (WW), Charlotte Bobcats (CB), Atlanta Hawks (AH), Orlando Magic (OM), Miami Heat (MH). Note two teams(Chicago Bulls Charlotte Bobcats) initials, thus represented former CU latter CB avoid ambiguity.122fiScheduling Bipartite Tournaments Minimize Total Travel DistanceTeamPTGWSKLCPSUJDNOTSSDMHRMTMGNHPT0GW5360SK473750LC824333368082433336800PS9976366373653650UJ6205805245825825010DN9699318848378375823750OT146213531320116911698208524930SS1691145514411192119283110727854020DM160214451420122712278669856451782440HR1799160515861358135899411788533911872150MT140315551494151415141258976683686108484310230MG18261770173315941594124412428674256174174626920NH2020187518501645164512811408105255948643030010273450Table 12: Distance Matrix NBA Western Conference (intra-league).TeamMBCUIPDPTRCCBCNKNNPSWWCBAHOMMHMB0CU660IP2351750DP2482492490TR4144304331900CC323310257901910BC8478538056054395530NK7347286554863614181840NN714708634466343398198200PS68066757843434235727693800WW6025804683723412844072252091330CB6425914225025824257185345224423170AH6615994276027315489337497356575262240OM1047985811950103687711019269198447424563920MH12441183100911431220106812431077107410029116435891980Table 13: Distance Matrix NBA Eastern Conference (intra-league).TeamMBCUIPDPTRCCBCNKNNPSWWCBAHOMMHPT169017111848193420642014249724152395236822912247214024912661GW180618071903205222142117265125352515247223722251209723972540SK175017531855199821572064259424822461241923202209206023672514LC173017181786196721432022257224372417236522522092191721812307173017181786196721432022257224372417236522522092191721812307PS143914181466166518481711226521202100240319261747156218171942UJ122712301333147416341540207219581937189517991700156518972058DN894886973113513071194173916121592154414411327119015261692OT72668367890810989341482132413051242111892674910491206SS1082102897312201406122417391564154714741342108086110231126DM84078774599011771001153213621344127511479127109551094HR97391583410831264107715751397138013061173899680839950MT2923304955316676121106101299296589491789412861483MG5504853766248016141123950932861731503327668849NH89382769993510979061349116611511074942642419540665Table 14: Distance Matrix two NBA Conferences (inter-league).readability, 30 30 distance matrix broken 15 15 matrices, providingintra-league inter-league distances. remark Los Angeles ClippersLos Angeles Lakers play games arena, explains distancezero. entry Tables 12 14 expressed miles, unlike NPB distancematrix expressed kilometres.123fiHoshino & KawarabayashiReferencesAnagnostopoulos, A., Michel, L., Hentenryck, P. V., & Vergados, Y. (2006). simulatedannealing approach traveling tournament problem. Journal Scheduling, 9,177193.Easton, K., Nemhauser, G., & Trick, M. (2001). traveling tournament problem: description benchmarks. Proceedings 7th International Conference PrinciplesPractice Constraint Programming, 580584.Easton, K., Nemhauser, G., & Trick, M. (2002). Solving travelling tournament problem:combined integer programming constraint programming approach. Proceedings 4th International Conference Practice Theory AutomatedTimetabling, 319330.Easton, K., Nemhauser, G., & Trick, M. (2004). Sports scheduling. Leung, J. T. (Ed.),Handbook Scheduling, chap. 52, pp. 119. CRC Press.Garey, M., & Johnson, D. (1979). Computers Intractability: guide theoryNP-completeness. W.H. Freeman, New York.Hoshino, R., & Kawarabayashi, K. (2011a). distance-optimal inter-league scheduleJapanese pro baseball. Proceedings ICAPS 2011 Workshop ConstraintSatisfaction Techniques Planning Scheduling Problems (COPLAS), 7178.Hoshino, R., & Kawarabayashi, K. (2011b). inter-league extension travelingtournament problem application sports scheduling. Proceedings 25thAAAI Conference Artificial Intelligence, appear.Hoshino, R., & Kawarabayashi, K. (2011c). multi-round balanced traveling tournamentproblem. Proceedings 21st International Conference Automated PlanningScheduling (ICAPS), 106113.Hoshino, R., & Kawarabayashi, K. (2011d). multi-round generalization travelingtournament problem application Japanese baseball. European JournalOperational Research, doi: 10.1016/j.ejor.2011.06.014.Itai, A., Perl, Y., & Shiloach, Y. (1982). complexity finding maximum disjoint pathslength constraints. Networks, 12, 278286.Kendall, G., Knust, S., Ribeiro, C., & Urrutia, S. (2010). Scheduling sports: annotatedbibliography. Computers Operations Research, 37, 119.Lim, A., Rodrigues, B., & Zhang, X. (2006). simulated annealing hill-climbingalgorithm traveling tournament problem. European Journal OperationalResearch, 174, 14591478.Thielen, C., & Westphal, S. (2010). Complexity traveling tournament problem.Theoretical Computer Science, 412, 345351.124fiJournal Artificial Intelligence Research 42 (2011) 31-53Submitted 4/11; published 9/11Link Partial Meet, Kernel,Infra Contraction Application Horn LogicRichard Boothrichard.booth@uni.luUniversite du LuxembourgLuxembourgThomas Meyertommie.meyer@meraka.org.zaCentre Artificial Intelligence ResearchUniversity KwaZulu-Natal CSIR Meraka InstituteSouth AfricaIvan Varzinczakivan.varzinczak@meraka.org.zaCentre Artificial Intelligence ResearchUniversity KwaZulu-Natal CSIR Meraka InstituteSouth AfricaRenata Wassermannrenata@ime.usp.brUniversidade de Sao PauloBrazilAbstractStandard belief change assumes underlying logic containing full classical propositional logic. However, good reasons considering belief change less expressivelogics well. paper build recent investigations Delgrande contractionHorn logic. show standard basic form contraction, partial meet,strong Horn case. result stands contrast Delgrandes conjectureorderly maxichoice appropriate form contraction Horn logic. defineappropriate notion basic contraction Horn case, influenced convexityproperty holding full propositional logic refer infra contraction.main contribution work result shows construction methodHorn contraction belief sets based infra remainder sets corresponds exactlyHanssons classical kernel contraction belief sets, restricted Horn logic.result obtained via detour contraction belief bases. prove kernelcontraction belief bases produces precisely results belief base versioninfra contraction. use belief bases obtain result provides evidenceconjecture Horn belief change best viewed hybrid version belief set changebelief base change. One consequences link base contractionprovision representation result Horn contraction belief sets versionCore-retainment postulate features.1. Introductionseminal paper, Delgrande (2008) shed light theoretical underpinningsbelief change weakening usual assumption belief change community, namelyunderlying logical formalism least strong (full) classical propositional logic (Gardenfors, 1988). Delgrande investigated contraction functions beliefsets (sets sentences closed logical consequence) restricted Horn formuc2011AI Access Foundation. rights reserved.fiBooth, Meyer, Varzinczak, & Wassermannlas (1951). Delgrandes main contributions essentially threefold. Firstly, showedmove Horn logic leads two different types contraction functions, referredentailment-based contraction (e-contraction) inconsistency-based contraction (icontraction), coincide full propositional case. Secondly, showed Horncontraction belief sets satisfy controversial Recovery postulate, exhibitscharacteristics usually associated contraction belief bases (arbitrary sets sentences). finally, Delgrande made tentative conjecture versionHorn contraction usually referred orderly maxichoice contraction appropriatemethod contraction Horn theories.Delgrandes partial meet constructions appropriate choices contractionHorn logic, show constitute appropriate forms Horn contraction. Moreover, referred above, although Horn contraction defined Horn beliefsets, related ways contraction belief bases, aspect yetexplored properly literature.paper continue investigation contraction Horn logic, addressissues mentioned above, well others. Focusing Delgrandes entailmentbased contraction, start providing fine-grained construction belief setcontraction refer paper infra contraction. bringpicture construction method contraction first introduced Hansson (1994), knownkernel contraction. Although kernel contraction usually associated belief basecontraction, applied belief sets well. main contribution resultshows infra contraction corresponds exactly Hanssons kernel contraction beliefsets, restricted Horn logic. order prove this, first take close lookcontraction belief bases, defining base version infra contraction provingconstruction equivalent kernel contraction Horn belief bases. Since Horn beliefsets closed classical logical consequence, seen hybridbelief sets belief bases. justifies use belief bases obtain results beliefset Horn contraction.Horn logic found extensive use Artificial Intelligence, particular logic programming, truth maintenance systems, deductive databases. explains, part,interest belief change Horn logic. (Despite interest Horn formulas,worth noting work consider logic programming explicitlyuse negation failure all.) Another reason focusing topicapplication debugging repairing ontologies description logics (Baader, Calvanese,McGuinness, Nardi, & Patel-Schneider, 2007). particular, Horn logic seenbackbone EL family description logics (Baader, Brandt, & Lutz, 2005),therefore proper understanding belief change Horn logic important findingsolutions similar problems expressible EL family.remainder present paper organized follows: logical preliminaries (Section 2), give background belief set contraction (Section 3) beliefbase contraction (Section 4) necessary core section paper (Section 5).prove kernel contraction infra contraction equivalent levelbelief bases. enables us prove kernel contraction infra contractionequivalent Horn belief set level well. led provide characterization infra contraction Horn belief sets version Core-retainment32fiPartial Meet, Kernel, Infra Contraction Horn Logicpostulate (Hansson, 1994) bases features. provides even evidencehybrid aspect Horn belief change. results stated entailment-basedcontraction (e-contraction). Section 6, discuss related work, also mentionsimilar results Delgrandes i-contraction another relevant type Horn contraction,namely Booth et als (2009) package contraction. conclude summary contributions well discussion future directions investigation. Proofs newresults found Appendix A.2. Preliminarieswork finitely generated propositional language set propositional atoms P,together distinguished atom > (true), standard model-theoreticsemantics. Atoms denoted p, q, . . ., possibly subscripts. formulaslanguage denoted , , . . . recursively defined follows:::= p | > | |connectives (, , , . . . ) special atom (false) defined termsusual way. LP denote set formulas language.Classical logical consequence logical equivalence denoted |= respectively. X LP , set sentences logically entailed X denoted Cn(X).belief set logically closed set, i.e., belief set K, K = Cn(K). usually denotebelief sets K, possibly decorated primes. P(X) denotes power set (set subsets) X. displaying belief sets sometimes follow convention displayingone representative equivalence class modulo logical equivalence, droppingrepresentative tautologies. example, LP generated two atoms pq, set Cn({p}) represented {p, p q, p q}.Horn clause sentence form p1 p2 . . . pn q n 0, pi , q P1 n (recall pi q may one > well). n = 0 writeq instead q. Horn formula conjunction Horn clauses. Horn set setHorn formulas.Given propositional language LP , Horn language LH generated LP simplyset Horn formulas occurring LP . Horn logic obtained LHsemantics propositional logic obtained LP , restricted Horn formulas.Hence, |=, , related notions defined relative logicworking in. use |=PL CnPL (.) denote classical entailment consequencepropositional logic. Horn logic, define CnHL (.) follows: CnHL (X) =def CnPL (X)LH X LH . define |=HL follows: X LH LH , X |=HLX |=PL .consequence operator CnHL (.) Tarskian consequence operator sensesatisfies following properties Horn sets X, X 0 :X CnHL (X)(Inclusion)CnHL (X) = CnHL (CnHL (X))(Idempotency)X X 0 , CnHL (X) CnHL (X 0 )(Monotonicity)33fiBooth, Meyer, Varzinczak, & WassermannHorn belief set, usually denoted H (possibly primes), Horn set closedoperator CnHL (.), i.e., H = CnHL (H). shall dispense subscriptswhenever context makes clear logic dealing with.AI tradition, given set formulas underlying logical language calledknowledge base, simply set beliefs. Belief change deals situationsagent modify beliefs world, usually due new previously unknownincoming information, also represented formulas language. Common operationsinterest belief change expansion (Gardenfors, 1988) agents current beliefs Xgiven formula (usually denoted X + ), basic idea add regardlessconsequences, revision (Gardenfors, 1988) current beliefs (denotedX ? ), intuition incorporate current beliefs wayensuring consistency resulting theory time. Perhaps basicoperation belief change contraction (Alchourron, Gardenfors, & Makinson,1985; Gardenfors, 1988), intended represent situations agentgive current stock beliefs (denoted X ). Indeed revision operationdefined terms contraction simple expansion via Levi identity (Levi,1977). Therefore, contraction focus present paper follows shallinvestigate detail. Throughout Sections 3 4 assume work languagefull propositional logic LP .3. Belief Set Contractioncommence discussion belief set contraction, aim describecontraction knowledge level (Gardenfors, 1988), i.e., independently beliefsrepresented syntactically. Thus, contraction defined belief sets.Definition 1 (Belief Set Contraction) belief set contraction belief set Kfunction LP P(LP ).principle categorical matching (Gardenfors & Rott, 1995) contractionbelief set sentence expected yield new belief set.One standard approaches constructing belief contraction operators basednotion remainder set set K respect formula : maximal subsetK entailing (Alchourron et al., 1985). define belief sets,known literature basic principle applied belief bases well(we shall recall Section 4).Definition 2 (Remainder Sets) Given belief set K formula LP , X KX K;X 6|= ;every X 0 X X 0 K, X 0 |= .call elements K remainder sets K respect .34fiPartial Meet, Kernel, Infra Contraction Horn Logiceasy verify K = |= (Gardenfors, 1988).Since unique method choosing possibly different remainder sets,presupposition existence suitable selection function so:Definition 3 (Selection Functions) selection function set K (partial)function P(P(LP )) P(P(LP ))(K) = {K} K = ;(K) K otherwise.Selection functions provide mechanism identifying remainder sets judgedappropriate. resulting contraction obtained taking intersectionchosen remainder sets.Definition 4 (Partial Meet Contraction) selection function, belief set conTtraction operator generated defined K =def (K) partial meetcontraction.Two subclasses belief set partial meet deserve special mention:Definition 5 (Maxichoice Full Meet) Given selection function , maxichoice contraction (K) always singleton set. full meet contraction (K) = K whenever K 6= .worth mentioning belief set full meet contraction unique, belief setmaxichoice contraction usually not.Kernel contraction introduced Hansson (1994) generalization safe contraction (Alchourron & Makinson, 1985). Instead looking maximal subsets implyinggiven formula, kernel operations based minimal subsets imply it.Definition 6 (Kernel) belief set K, X KX K;X |= ;every X 0 X 0 X, X 0 6|= .K called kernel set K respect elements K called-kernels belief set K.result kernel contraction obtained removing least one elementevery (non-empty) -kernel K, using incision function.Definition 7 (Incision Functions) incision function set K functionset kernel sets K P(LP )35fiBooth, Meyer, Varzinczak, & Wassermann(K)(K);=6 X K, X (K ) 6= .Given belief set K incision function K, ideally would want kernelcontraction K generated defined as:K =def K \ (K )(1)turns belief set K, contraction operator (1) respectprinciple categorical matching. because, belief set input, kernelcontraction (1) necessarily produce belief set result: Kgeneral closed logical consequence, shown following example.Example 1 Let K = Cn({p q, q r}) assume want contract p rK. K(p r) = {{p r}, {p q, q r}, {p q, p q r}}.incision function defined (K (p r)) = {p r, p q, p q r},applying operator (1) gives us K 0 K 0 |= p q r, obviouslypq r/ K 0.course, possible ensure one obtains belief set closing resultobtained operator logical consequence.Definition 8 (Belief Set Kernel Contraction) Given belief set K incisionfunction K, belief set contraction operator K generated definedK =def Cn(K ) belief set kernel contraction.shall see Section 4 belief set kernel contraction closely related versionbelief base contraction referred saturated base kernel contraction (Hansson, 1999).Belief set contraction defined terms partial meet contraction corresponds exactlyperhaps best-known approach belief change: so-called AGM approach (Alchourron et al., 1985). AGM requires (basic) belief set contraction characterizedfollowing set postulates:(K 1) K = Cn(K )(Closure)(K 2) K K(Inclusion)(K 3)/ K, K = K(Vacuity)(K 4) 6|= ,/ K(Success)(K 5) , K = K(Extensionality)(K 6) K, Cn((K ) {}) = K36(Recovery)fiPartial Meet, Kernel, Infra Contraction Horn LogicFull AGM contraction involves two extended postulates addition basic postulatesgiven above. shall elaborate detail intuition postulates.refer reader book Gardenfors (1988) handbook Hansson (1999).Alchourron et al. (1985) shown postulates characterize belief set partialmeet contraction exactly, shown following result:Theorem 1 (Alchourron et al., 1985) Every belief set partial meet contraction satisfies Postulates (K 1)(K 6). Conversely, every belief set contraction satisfiesPostulates (K 1)(K 6) belief set partial meet contraction.Hansson (1994) shown Postulates (K 1)(K 6) also characterize kernelcontraction belief sets:Theorem 2 (Hansson, 1994) Every belief set kernel contraction satisfies Postulates(K 1)(K 6). Conversely, every belief set contraction satisfies Postulates (K 1)(K 6) belief set kernel contraction.conclude section important new observation whose usefulness become apparent Section 5.Theorem 3 (Convexity) Let K belief set, let mc (belief set) maxichoice contraction, let fm denote (belief set) full meet contraction. every LP everybelief set X K fm X K mc , (belief set) partial meetcontraction pm K pm = X .result shows every belief set results obtained full meetcontraction maxichoice contraction also obtained partial meetcontraction. So, possible define version belief set contraction based sets.Definition 9 (Infra Remainder Sets) Given formula LP ,belief sets K0000K , K K K K ( K) K 0 K 00 .refer elements K infra remainder sets K respect .easy see K = |= . Note definition set infraremainder sets belief set K required belief sets themselves.remainder sets respect formula also infra remainder sets respect, intersection set remainder sets respect . Indeed,intersection set infra remainder sets respect also infra remainderset respect . set infra remainder sets respect contains beliefsets remainder set respect intersection remaindersets respect . explains infra contraction definedintersection infra remainder sets (cf. Definition 4).Definition 10 (Infra Contraction) Let K belief set. infra selection functionK (partial) function P(P(LP )) P(LP ) (K ) = K wheneverK = , (K ) K otherwise. belief set contraction operator beliefset infra contraction K = (K ).37fiBooth, Meyer, Varzinczak, & Wassermannsense, then, infra contraction closer maxichoice contraction partial meetcontraction, since chooses single element set infra remainder sets, muchlike maxichoice contraction chooses single element set remainder sets.One immediate consequence Theorem 3 Definition 10 following:Corollary 1 Infra contraction partial meet contraction coincide belief sets.4. Belief Base Contractionturn attention belief base contraction, agents beliefs represented(usually finite) set sentences necessarily closed logical consequence, alsoknown base. usually denote bases B, possibly decorated primes.Definition 11 (Belief Base Contraction) base contraction base B function LP P(LP ).Intuitively idea that, fixed belief base B, contraction formula Bproduces new base B .Given construction methods belief set contraction already discussed Section 3,two obvious ways define belief base contraction consider partial meet contraction kernel contraction bases. present cases.definitions required partial meet base case analogous givenbelief set case Section 3. readers convenience, state explicitly here:Definition 12 (Base Remainder Sets) Given base B formula , X BX B;X 6|= ;every X 0 X X 0 B, X 0 |= .call elements B base remainder sets B respect .Similarly belief set case, easy verify B = |= .Definition 13 (Selection Functions) selection function base B (partial)function P(P(LP )) P(P(LP ))(B) = {B} B = ;(B) B otherwise.Definition 14 (Base Partial Meet Contraction) selection function, beliefbase contraction operator generated defined B =def (B)base partial meet contraction.38fiPartial Meet, Kernel, Infra Contraction Horn LogicDefinition 15 (Base Maxichoice Full Meet) Given selection function ,base maxichoice contraction (B) always singleton set. basefull meet contraction (B) = B whenever B 6= .belief set case, checked belief base full meet contraction unique,base maxichoice contraction usually not.Hansson (1992) showed belief base partial meet contraction characterizedfollowing postulates:(B 1) 6|= , B 6|=(Success)(B 2) B B(Inclusion)(B 3) B 0 |= B 0 |= B 0 B, B = B (Uniformity)(B 4) (B \ (B )), B 0(B ) B 0 B B 0 6|= , B 0 {} |=(Relevance)Again, shall elaborate detail intuition postulates.refer reader handbook Hansson (1999).Theorem 4 (Hansson, 1992) Every base partial meet contraction operator satisfies Postulates (B 1)(B 4). Conversely, every base contraction satisfies (B 1)(B 4)base partial meet contraction.One question arises whether following belief base version convexityprinciple Theorem 3 holds:(Base Convexity) belief base B, let mc base maxichoice contraction,let fm denote base full meet contraction. every set X B fmX B mc , base partial meet contraction pm B pm = X.belief set case, principle simply states every set resultsobtained base full meet contraction base maxichoice contractionobtained belief base partial meet contraction. following example showshold.Example 2 Let B = {p q, q r, pq r, pr q} consider contraction p r.easily verified base maxichoice gives either B (p r) = B 0 = {p q, p r q}B(p r) = B 00 = {q r, pq r, pr q}. Therefore result obtainedbase partial meet contraction provided base full meet contraction:B (p r) = B 000 = {p r q}. observe even though caseB 000 X B 00 X = {p q r, p r q}, X equal B 0 , B 00 , B 000 .shall come back issue end section.give definitions kernel contraction belief base case. Again,analogous given belief set case previous section, readersconvenience state explicitly here.39fiBooth, Meyer, Varzinczak, & WassermannDefinition 16 (Base Kernels) belief base B formula , X BX B;X |= ;every X 0 X 0 X, X 0 6|= .B called kernel set B respect , elements B called-kernels B.result base kernel contraction obtained removing least one elementevery (non-empty) -kernel B, using incision function.Definition 17 (Incision Functions Bases) incision function base Bfunction set kernel sets B P(LP )(B) (B);=6 X B, X (B ) 6= .refer incision function minimal every , every incisionfunction 0 , (B) 0 (B).(unique) maximum incision function definedfollows: every , (B) = (B ).worthy mention minimal incision functions always exist.Definition 18 (Base Kernel Contraction) Given incision function base B,base kernel contraction B generated defined as: B = B \ (B ).Base kernel contraction characterized postulates base partial meetcontraction, except Relevance replaced Core-retainment postulate below:(B 5) (B \ (B )),B 0 B B 0 6|= B 0 {} |=(Core-retainment)Theorem 5 (Hansson, 1994) Every base kernel contraction satisfies Postulates (B 1)(B 3) (B 5). Conversely, every base contraction satisfies Postulates (B 1)(B 3) (B 5) base kernel contraction.Clearly, Core-retainment slightly weaker Relevance. indeed, thus followsbase partial meet contractions base kernel contractions, followingexample Hansson (1999) shows, base kernel contractions base partialmeet contractions.Example 3 Let B = {p, p q, p q}. B (p q) = {{p, p q}, {p q, p q}}.incision function B (B (p q)) = {p q, p q},B (p q) = {p}. hand, B(p q) = {{p, p q}, {p q}},follows base partial meet contraction B (p q) yields either {p, p q}, {p q},{p, p q} {p q} = , none equal B (p q) = {p}.40fiPartial Meet, Kernel, Infra Contraction Horn Logicbriefly pointed Definition 8, definition kernel contraction beliefsets closely related version belief base contraction Hansson (1999) referssaturated base kernel contraction:Definition 19 (Saturated Base Kernel Contraction) Given belief base Bincision function B, base contraction B generated definedB =def B Cn(B ) saturated base kernel contraction.easily shown (Hansson, 1994) set B definition saturated basekernel contraction belief set, two notions coincide.Observation 1 belief set K incision function K, saturated basekernel contraction belief set kernel contraction identical.saturated base kernel contractions general base partial meet contractions (Hansson, 1999, p. 91), distinction disappears considering belief sets only:Theorem 6 (Hansson, 1994) Let K belief set. belief set contraction saturated base kernel contraction belief set partial meet contraction.result Observation 1 Theorem 6 immediately following corollary:Corollary 2 Let K belief set. belief set contraction belief set kernel contraction belief set partial meet contraction.Thanks Theorem 3 (Convexity) extend Corollary 2 show kernel contraction, partial meet contraction, infra contraction coincide belief sets.Corollary 3 Let K belief set. belief set contraction belief set kernel contraction belief set partial meet contraction belief setinfra contraction.far considered remainder sets bases kernel sets bases, infraremainder sets bases (cf. end Section 3). conclude section discussioncommencing definition base infra remainder sets.Definition 20 (Base Infra Remainder Sets) Given formula, bases B B 0 ,000B B B B ( B) B 0 B 00 . referelements B base infra remainder sets B respect .Observe definition base infra remainder sets infra remaindersets, differing deals belief bases belief sets. Note particularelements required belief sets themselves. Base infra remainder setsused define form base contraction way similar definition(belief set) infra contraction (cf. Definition 10).41fiBooth, Meyer, Varzinczak, & WassermannDefinition 21 (Base Infra Contraction) base infra selection function (partial)function P(P(LP )) P(LP ) (B ) = B whenever B = ,(B ) B otherwise. belief base contraction operator generateddefined B =def (B ) base infra contraction.natural question ask base infra contraction compares base partial meetcontraction base kernel contraction. following result, plays central rolepaper, shows base infra contraction corresponds exactly base kernel contraction.Theorem 7 base contraction belief base B belief base kernel contraction Bbase infra contraction B.Example 3 know base kernel contraction general base partialmeet contraction: every base partial meet contraction also base kernel contraction,converse hold. Theorem 7 following result thus follows.Observation 2 Base infra contraction general base partial meet contraction.Theorem 7 number interesting consequences well. philosophicalnote, provides evidence contention kernel contraction approachappropriate partial meet approach. mentioned earlier, well-knownkernel contraction partial meet contraction coincide belief sets, differ beliefbases (kernel contraction general partial meet contraction case).importance Theorem 7 shows new seemingly different approachcontraction (infra contraction) identical kernel contraction belief setsbelief bases, different partial meet contraction belief bases, thereby tiltingscales evidence towards kernel contraction. shall see next section, Theorem 7also instrumental lifting result level Horn belief sets.5. Horn Belief Set Contractionprevious sections recalled several results belief change literaturestated new ones, connecting different constructions sets rationality postulates.important note although examples literature assumeunderlying logic contains classical propositional logic, results usually validbroader set languages. discussed different contexts HanssonWassermann (2002), Flouris et al. (2006), Ribeiro Wassermann (2009a, 2009b, 2010),Varzinczak (2008, 2010), Wassermann (2011), among others. belief bases,shown Hansson Wassermann (2002) order keep representation theoremspartial meet kernel contraction, logic needs compact monotonic.means results transfer directly Horn logics. However, belief setsrepresentation theorems demand restrictions logic. shown Flouris etal. (2006), contraction operation satisfying basic AGM postulates existslogic decomposable.Definition 22 (Flouris et al., 2006) logic called decomposablesets formulas X, X 0 , Cn() Cn(X 0 ) Cn(X), exists set formulasX 00 Cn(X 00 ) Cn(X) Cn(X) = Cn(X 0 X 00 ).42fiPartial Meet, Kernel, Infra Contraction Horn Logicshown Ribeiro (2010) Horn logic decomposable. Therefore, newconstructions sets postulates needed deal contraction Horn belief sets.Delgrande (2008) investigated two distinct classes contraction functions Hornbelief sets: entailment-based contraction (e-contraction), removing unwanted consequence; inconsistency-based contraction (i-contraction), removing formulas leadinginconsistency; Booth et al. (2009) subsequently extended work Delgrandeproviding fine-grained versions constructions. focus papere-contraction, although Delgrande, well Booth et al., also consider i-contraction.Recall use H, sometimes decorated primes, denote Horn belief set.Definition 23 (e-Contraction) e-contraction Horn belief set H functionLH P(LH ).Delgrandes method construction e-contraction terms partial meet contraction. definitions remainder sets (Definition 2), selection functions (Definition 3),partial meet contraction (Definition 4), well maxichoice full meet contraction (Definition 5) carry e-contraction, set K case replacedHorn belief set H, refer e-remainder sets (denoted ), e-selectionfunctions, partial meet e-contraction, maxichoice e-contraction full meet e-contractionrespectively (we leave reference term Horn, since roomambiguity here). full propositional case, easy verify e-remaindersets also Horn belief sets, partial meet e-contractions (and thereforemaxichoice e-contractions, well full meet e-contraction) produce Horn belief sets.Although Delgrande defines discusses partial meet e-contraction, arguesmaxichoice e-contraction appropriate approach e-contraction. precise,version maxichoice e-contraction Delgrande advocates actually restricted version maxichoice e-contraction refer orderly maxichoice e-contraction. (ThisHorn case maxichoice contraction operators satisfying AGM postulates, including supplementary ones). Whereas (ordinary) maxichoice e-contractionconstructed setting, every LH , H equal element H, orderlymaxichoice e-contraction systematicSin nature. Associated every orderly maxichoice e-contraction linear order LH (H), union e-remainder setsH respect sentencesS LH . Intuitively, higher linear order,plausible element LH (H) intended be. orderly maxichoicee-contraction generated obtained follows: every LH , Kselected plausible e-remainder set H respect (the onehighest order ).argue although partial meet e-contractions appropriate choicese-contraction, make set appropriate e-contractions. words,Delgrandes approach complete. argument appropriate e-contractionspartial meet e-contraction based observation convexity result fullpropositional logic Theorem 3 hold Horn logic.Example 4 Let H = CnHL ({p q, q r}). e-contraction p r H, maxi1 = Cn ({p q}) H 2 = Cn ({q r, p r q}), whereas fullchoice yields either HmcHLHLmc43fiBooth, Meyer, Varzinczak, & Wassermannmeet yields Hf = CnHL ({p r q}). three partial meet e-contractions.consider Horn belief set H 0 = CnHL ({p q r, p r q}). clear2 , partial meet e-contraction yielding H 0 .Hf H 0 Hmcorder rectify situation, propose e-contraction extendedinclude cases H 0 above. argument follows: Since full meet e-contractiondeemed appropriate, stands reason belief set H 0 biggeralso seen appropriate, provided H 0 contain irrelevant additions.since H 0 contained maxichoice e-contraction, H 0 cannot contain irrelevantadditions. all, maxichoice Horn e-contraction contains relevant additions,since appropriate form contraction. Hence H 0 also appropriate resulte-contraction.summary, every Horn belief set full meet maxichoice e-contractionought seen appropriate candidate e-contraction. captureddefinition below.Definition 24 (Infra e-Remainder Sets) Hornbelief sets H H 0 , H 0 H eH 00 ( ) H 0 H 00 . referelements H e infra e-remainder sets H respect .case full propositional logic (cf. Definition 9), e-remainder sets also infrae-remainder sets, intersection set e-remainder sets. Similarly,intersection set infra e-remainder sets also infra e-remainder set,set infra e-remainder sets contains Horn belief sets e-remainder setintersection e-remainder sets. full propositional case, explainse-contraction defined intersection infra e-remainder sets (cf. Definition 4).Definition 25 (Horn e-Contraction) Let H Horn belief set LH Hornformula. infra e-selection function (partial) function P(P(LH )) P(LH )(H e ) = H whenever H e = ;(H e ) H e otherwise.e-contraction infra e-contraction H = (H e ).results kernel contraction, partial meet contraction infra contractioncompare base case (kernel contraction infra contraction identical,general partial meet contraction) invite question whether similar resultshold Horn belief sets. provide answer this, need suitable versionkernel contraction Horn belief sets.Definition 26 (Horn kernel e-contraction) Given Horn belief set H incision function H, Horn kernel e-contraction H, abbreviated kernel econtraction H, defined H e =def CnHL (H ), belief basekernel contraction obtained .44fiPartial Meet, Kernel, Infra Contraction Horn Logicturns infra e-contraction kernel e-contraction coincide, followingresult shows.Theorem 8 e-contraction Horn belief set H infra e-contraction Hkernel e-contraction H.Theorem 8 Example 4 follows partial meet e-contractionrestrictive kernel e-contraction. comes Horn belief sets, thereforeexactly pattern belief bases: kernel contraction infra contractioncoincide, strictly permissive partial meet contraction. Contrastcase belief sets full propositional logic infra contraction, partialmeet contraction kernel contraction coincide.One conclusion drawn restriction Horn case producescurious hybrid belief sets belief bases full propositional logic. onehand, Horn contraction deals sets logically closed. hand,results Horn logic obtained terms construction methods close obtainedbelief base contraction.Either way, new results belief base contraction prove quite usefulinvestigation contraction Horn belief sets. conclude section providingrepresentation result Horn contraction inspired new results belief basecontraction paper.Theorem 9 Every infra e-contraction satisfies (K 1), (K 2), (K 4), (K 5)Core-retainment. Conversely, every e-contraction satisfies (K 1), (K 2), (K 4),(K 5), Core-retainment infra e-contraction.result inspired Theorem 7 shows base kernel base infracontraction coincide. Given Core-retainment used characterizing base kernelcontraction, Theorem 7 shows link Core-retainment base infracontraction, raises question whether link Core-retainmentinfra e-contraction. answer, seen Theorem 9, yes. result providesevidence hybrid nature contraction Horn belief sets. caseconnection base contraction strengthened.6. Related Workknowledge, first formal proposal taking non-maximal remainder setscontraction following AGM principles made Restall Slaney (1995).construction appears context different ours: use four-valued logicshow dropping Recovery postulate, obtain representation resultpartial-meet non-maximal remainders. Note restrictionremainder sets containing minimal core, made infra remainders, resultpostulate associated kind minimal change.work revision Horn formulas (Eiter & Gottlob, 1992;Liberatore, 2000; Langlois, Sloan, Szorenyi, & Turan, 2008), recently attentionpaid contraction Horn logic. Apart work Delgrande (2008)45fiBooth, Meyer, Varzinczak, & Wassermanndiscussed, recent work obtaining semantic characterisationHorn contraction using system spheres Fotinopoulos Papadopoulos (2009),via epistemic entrenchment Zhuang Pagnucco (2010).Billington et al. (1999) considered revision contraction defeasible logicquite different Horn logic many respects, nevertheless rule-like flavoursimilarity Horn logic.present paper extension work Booth et al. (2009)show infra e-contraction captured precisely six AGM postulates belief setcontraction, except Recovery replaced following (weaker) postulate (H e 6)together Failure postulate:(H e 6) H \ (H ),exists X (He ) X H X 6|= , X {} |=(H e 7) |= , H e = H(Failure)Theorem 10 (Booth et al., 2009) Every infra e-contraction operator satisfies Postulates (K 1)(K 5), (H e 6) (H e 7). Conversely, every e-contractionsatisfies (K 1)(K 5), (H e 6) (H e 7) infra e-contraction.Postulate (H e 6) bears resemblance Relevance postulate base contraction states sentences removed H -contraction mustremoved reason: adding brings back . Postulate (H e 7) simplystates contracting tautology leaves initial belief set unchanged.worth noting (H e 6) somewhat unusual postulate refersdirectly construction method intended characterize, i.e., e-remainder sets.provided elegant characterization infra e-contraction takingdetour base contraction. Firstly, replaced (H e 6) Core-retainmentpostulate used characterization base kernel contraction. turnsVacuity postulate (K 3) Failure postulate (H e 7) followCore-retainment Inclusion postulate (K 2), obtainedcharacterization infra e-contraction.addition e-contraction, Delgrande also investigated version Horn contractionrefers inconsistency-based contraction (or i-contraction) purposemodify agents Horn belief set way avoid inconsistency sentenceprovided input. is, i-contraction (H ) {} 6|=.HLaddition e- i-contraction, Booth et al. (2009) considered package contraction (or p-contraction), version contraction studied Fuhrmann Hansson (1994)classical case (i.e., logics containing full propositional logic). Given setformulas X, goal make sure none sentences X result obtained p-contraction. full propositional logic similar contractingdisjunction sentences X. Horn logic, full disjunction,package contraction interesting. Although seems new results presentedpaper applied i-contraction p-contraction, stillverified detail.46fiPartial Meet, Kernel, Infra Contraction Horn LogicRecent work Delgrande Wassermann (2010) draws inspiration semanticrepresentation remainder sets. classical AGM approach, remainder setobtained semantically adding models belief set H counter-modelformula contraction. Horn clauses, construction necessarily leadsets correspond remainder sets. because, known Horn logic, giventwo models m1 , m2 Horn belief set H, model m1 u m2 also model H,m1 u m2 denotes model atoms true precisely atomstrue m1 m2 . illustrate this, consider following example:Example 5 (Delgrande & Wassermann, 2010) Let P = {p, q, r} let Horn belief set H = CnHL (p q). Consider candidates H (p q). three e-remaindersets, given Horn closures p (r q), q (r p), (p q) (q p) (rp) (r q). infra e-remainder set contains closure (r p) (r q).Example 5, unique model set {p, q, r} countermodel p q. addmodels H close u result represents Horn belief set,obtain set models formula p, cannot e-remainder set,e-remainder set (CnHL (p (r q))) containing it. means approachbased e-remainder sets cannot contraction operators behaviourclassical ones.Delgrande Wassermann propose mimic semantic construction classicalremainders: weak-remainder H formed intersecting H maximalconsistent Horn theory containing . Equivalently, weak-remainders semantically characterized taking closure intersection models H togethersingle counter-model . Representation results contraction based weakremainders provided.Concerning connection partial meet contraction kernel contractionbases, Falappa et al. (2006) shown construct partial meet contractionkernel contraction, always possible, construct kernel contractionpartial meet contraction, possible. results generalizedapply base infra contraction base kernel contraction. is,possible construct base infra contraction every base kernel contraction, wellbase kernel contraction every base infra contraction.7. Concluding Remarksbringing Hanssons kernel contraction picture, made meaningful contributions investigation contraction Horn logic. main contributionspresent paper follows: (i) result shows infra contraction kernelcontraction belief base case coincide; (ii) Lifting previous results Hornbelief sets show infra contraction kernel contraction Horn belief sets coincide.investigation base contraction also allowed us improve rather unsatisfactory representation result proved Booth et al. infra contraction, reliespostulate referring directly construction method intended characterize.obtained elegant representation result replacing postulate introduced47fiBooth, Meyer, Varzinczak, & WassermannBooth et al. well-known Core-retainment postulate, usually associatedbase contraction. presence Core-retainment enforces hybridnature Horn belief change, lying somewhere belief set change base change.seen kernel e-contraction infra e-contraction generalpartial meet e-contraction. also evidence even forms Horn contraction may sufficient obtain meaningful answers. Consider, example,Horn belief set example CnHL ({p q, q r}) encountered Example 4. view basicHorn clauses (clauses exactly one atom head body) representativearcs graph, style old inheritance networks, case maderegarding three arcs p q, q r, p r, basic information usedgenerate belief set. one possible desirable outcome contraction p rCnHL (q r). However, seen Example 4, outcome supportedinfra e-contraction (and therefore kernel e-contraction either). Ideally, trulycomprehensive e-contraction approach Horn logic would able accountcases well.focus basic Horn contraction. future work plan investigateHorn contraction full AGM contraction, obtained adding extended postulates.Another interesting question investigation whether Theorem 9 generalized logics, notably extensions (full) propositional logic.Finally, mentioned earlier, one reasons focusing topicapplication debugging repairing ontologies description logics. particular,Horn logic seen backbone EL family description logics (Baader et al.,2005), therefore proper understanding belief change Horn logic importantfinding solutions similar problems expressible EL family. currentlyinvestigating possibilities.Acknowledgmentspaper extends work Booth, Meyer Varzinczak appeared IJCAI (Boothet al., 2009), work Booth, Meyer, Varzinczak Wassermann appearedNMR (Booth et al., 2010a) ECAI (Booth et al., 2010b).authors grateful anonymous referees constructive usefulremarks, helped improving quality presentation work. would alsolike thank Eduardo Ferme provided important hints connection infrakernel contraction.work Richard Booth supported FNR INTER project DynamicsArgumentation. work Thomas Meyer Ivan Varzinczak supportedNational Research Foundation Grant number 65152. work Renata Wassermann supported CNPq, Brazilian National Research Council, grants304043/2010-9 471666/2010-6.Appendix A. Proofs Main Theoremsproofs Lemma A.1 Theorem 3 need model-theoretic notions.denote W set valuations LP [] set models , i.e., set48fiPartial Meet, Kernel, Infra Contraction Horn Logicvaluations satisfy . set sentences X, denote [X] set modelsX, i.e., set valuations satisfy sentences X. V W, leth(V ) = { LP | V []}.results Lemma A.1 well-known model-theoretic descriptions fullmeet, partial meet, maxichoice contraction, first presented Katsuno & Mendelzon (1991). results, stated below, stated directly Katsuno & Mendelzon,follow easy consequences Theorem 3.3.Lemma A.1 (Katsuno & Mendelzon, 1991) Let K belief set.1. Let fm (belief set) full meet contraction. every LP , K fm =Th([K] []);2. Let mc (belief set) maxichoice contraction. every LP , w []K mc = Th([K] {w});3. Given LP , let V [] V 6= . (belief set) partial meetcontraction pm every LP , K pm = Th([K] V ).Theorem 3 (Convexity) Let K belief set, let mc (belief set) maxichoice contraction, let fm denote (belief set) full meet contraction. every LP , let Xbelief set (K fm ) X K mc . (belief set) partial meetcontraction pm every LP , K pm = X .Proof:cases |=/ K hold easily, suppose 6|= K. Now, pickbelief set X K fm X K mc . Points (1) (2) Lemma A.1means w [] [K] {w} [X ] K [].follows [X ] = [K] [V ] V []. Point (3) Lemma A.1follows partial meet contraction pm that, every LP ,K pm = X = h([K] V ).[qed]Lemma A.2 (Falappa et al., 2006) Every base kernel contraction defined minimalincision function base maxichoice contraction.Lemma A.3 base kernel contraction defined maximal incision functionfull meet base contraction.Proof:need prove B \ (B) = (B). |= B 6|= result followsimmediately. suppose6|= B |= . left-to-right direction, supposeB/ (B), assume base remainder set Brespect , say X,/ X.S must case contained-kernel B. (B ): contradiction. right-to-leftdirection, supposeevery base remainder set BSwith respect , assume/ B \ (B). Since B follows (B ). is,-kernel B. least one minimal incision function (B ).49fiBooth, Meyer, Varzinczak, & WassermannNow, Lemma A.2 follows base remainder set B respect ,say , = B \ (B)./ , contradicts suppositionevery base remainder set B respect .[qed]Theorem 7 base contraction belief base B belief base kernel contraction Bbase infra contraction B.Proof:part, let base kernel contraction B, let incision functionB generates , pick LP . |= B 6|=T result holds easily,suppose 6|= B |= . remainsshown (B) B B 00B B. Observe firstlyTthat B \ (B ) B \(B ) = B . Lemma A.30follows directly (B) B. Next, pick minimal incision function0 (B) (B) ( 0 clearly exists). B = B \ (B ) B \ 0 (B )Lemma A.2 follows B \ 0 (B ) = B 0 B 0 B.part, let base infra contraction B. construct incisionfunction base kernel contraction generates exactly . Pick LPsuppose 6|= B |= (for remaining cases result easily holds). Let(B ) = B \(B ). SinceB B B = B \(B ). First needshow(B)(B). so, observesince B B , follows(B) B . Therefore B \ (B ) B \ (B).Lemma A.3construction (B ) = B \ (B ) B \ (B) = (B ).remains shown every B , (B ) 6= .Pick B, assume (B ) = . mustcase B . |= therefore B |= , contradiction.[qed]Theorem 8 e-contraction Horn belief set H infra e-contraction Hkernel e-contraction H.Proof:Consider belief base B formula . Theorem 7 follows set baseinfra remainder sets B respect (i.e., set B ) equal set resultsobtained base kernel contraction B , call KCB . let Bset Horn formulas closed Horn consequence (a Horn belief set) Hornformula. elements KCB necessarily closed Horn consequence,close them, obtain exactly set results obtained kernel e-contractioncontracting B (by definition kernel e-contraction). Let us referlatter set CnHL (KCB ), i.e., CnHL (KCB ) = {CnHL (X) | X KCB }. Also, elementsB closed Horn consequence, close resultingset (refer set CnHL (B )) contains exactly infra e-remainder sets Brespect , i.e., CnHL (B ) = B e . see why, observe since B closedHorn consequence, (base) remainder sets B respect (i.e., elementsB) also closed Horn consequence. theTelements B sets (notnecessarily closed Horn consequence) (B) element B.Therefore elements CnHL (B ) elements B closedHorn consequence, i.e., CnHL (B ) = B e claimed. since B = KCB ,also case CnHL (B ) = CnHL (KCB ), therefore CnHL (KCB ) = B e . [qed]50fiPartial Meet, Kernel, Infra Contraction Horn LogicTheorem 9 Every infra e-contraction satisfies (K 1), (K 2), (K 4), (K 5)Core-retainment. Conversely, every e-contraction satisfies (K 1), (K 2), (K 4),(K 5), Core-retainment infra e-contraction.Proof:Let H Horn belief set, let infra e-contraction. H = H,(K 1), (K 2), (K 4), (K 5) Core-retainment trivially satisfied. SupposeH 6= H. H = X X H e . Then, definition, HHorn belief set, hence H = CnHL (H ) (Postulate (K 1)). Moreover,X 0 X X 0 . Since X 0 H, also follows X H,H H (Postulate (K 2)). (K 4) also satisfied definition H emonotonicity classical logic. (K 5) follows straightforwardly factworking Horn belief sets. Finally, Core-retainment, suppose H/ H . assume H 0 {} 6|=every H 0 H H 0 6|=.HLHL00particular then, every H , H {}T6|=HL . follows H 0every H 0 , therefore (He ).H , contradicts supposition.Conversely, let H Horn belief set let e-contraction satisfiesPostulate (K 1), (K 2), (K 4), (K 5), Core-retainment. need showevery LH , H H e . Observe firstly satisfies (K 3). see why, noteCore-retainment follows/ H H \ (H ) = , thereforeH H . (K 2) follows H = H ./ H follows directly (K 3) H H e . |=follows directlyHL(K 2) Core-retainment H = H, therefore H H e .So, suppose H 6|=. show HH e , need showHLH Horn belief set (from Postulate (K 1)) (He ) H H 0H 0 . Observe firstly that, since H H (by Postulate (K 2))00/ H (by (K 4)),H H H . Finally,assume (He )/ H . Core-retainment follows0000H H H 6|=H 00 {} |=. followsHLHLHorn belief set X H 00 X X 6|=HLX {} |=HL .X ,/ X, contradicts assumption (He ). thereforefollows (H) H .[qed]ReferencesAlchourron, C., Gardenfors, P., & Makinson, D. (1985). logic theory change:Partial meet contraction revision functions. Journal Symbolic Logic, 50, 510530.Alchourron, C., & Makinson, D. (1985). logic theory change: safe contraction.Studia Logica, 44, 405422.Baader, F., Brandt, S., & Lutz, C. (2005). Pushing EL envelope. Kaelbling, L., & Saffiotti, A. (Eds.), Proceedings 19th International Joint Conference ArtificialIntelligence (IJCAI), pp. 364369. Morgan Kaufmann Publishers.51fiBooth, Meyer, Varzinczak, & WassermannBaader, F., Calvanese, D., McGuinness, D., Nardi, D., & Patel-Schneider, P. (Eds.). (2007).Description Logic Handbook: Theory, Implementation Applications (2 edition). Cambridge University Press.Billington, D., Antoniou, G., Governatori, G., & Maher, M. (1999). Revising nonmonotonictheories: case defeasible logic. Proceedings 23rd Annual GermanConference Artificial Intelligence, No. 1701 LNAI, pp. 101112. Springer-Verlag.Booth, R., Meyer, T., & Varzinczak, I. (2009). Next steps propositional Horn contraction. Boutilier, C. (Ed.), Proceedings 21st International Joint ConferenceArtificial Intelligence (IJCAI), pp. 702707. AAAI Press.Booth, R., Meyer, T., Varzinczak, I., & Wassermann, R. (2010a). contraction core Hornbelief change: Preliminary report. 13th International Workshop NonmonotonicReasoning (NMR).Booth, R., Meyer, T., Varzinczak, I., & Wassermann, R. (2010b). Horn belief change:contraction core. Proceedings 19th European Conference ArtificialIntelligence (ECAI), pp. 10651066.Delgrande, J. (2008). Horn clause belief change: Contraction functions. Lang, J., &Brewka, G. (Eds.), Proceedings 11th International Conference PrinciplesKnowledge Representation Reasoning (KR), pp. 156165. AAAI Press/MITPress.Delgrande, J., & Wassermann, R. (2010). Horn clause contraction functions: Belief setbelief base approaches. Proceedings 12th International ConferencePrinciples Knowledge Representation Reasoning (KR). AAAI Press.Eiter, T., & Gottlob, G. (1992). complexity propositional knowledge base revision,updates, counterfactuals. Artificial Intelligence, 57 (23), 227270.Falappa, M., Ferme, E., & Kern-Isberner, G. (2006). logic theory change: Relations incision selection functions. Brewka, G., Coradeschi, S., Perini,A., & Traverso, P. (Eds.), Proceedings 17th European Conference ArtificialIntelligence (ECAI), pp. 402406. IOS Press.Flouris, G., Plexousakis, D., & Antoniou, G. (2006). generalizing AGM postulates.Proceedings 3rd Starting AI Researchers Symposium, pp. 132143.Fotinopoulos, A., & Papadopoulos, V. (2009). Semantics Horn contraction. 7thPanHellenic Logic Symposium, pp. 4247.Fuhrmann, A., & Hansson, S. (1994). survey multiple contractions. Journal Logic,Language Information, 3, 3976.Gardenfors, P. (1988). Knowledge Flux: Modeling Dynamics Epistemic States.MIT Press.Gardenfors, P., & Rott, H. (1995). Belief revision. Handbook Logic ArtificialIntelligence Logic Programming, Vol. 4, pp. 35132. Clarendon Press.Hansson, S. (1992). dyadic representation belief. Belief Revision, Vol. 29 Cambridge Tracts Theoretical Computer Science, pp. 89121. Cambridge UniversityPress.52fiPartial Meet, Kernel, Infra Contraction Horn LogicHansson, S. (1994). Kernel contraction. Journal Symbolic Logic, 59 (3), 845859.Hansson, S. (1999). Textbook Belief Dynamics: Theory Change Database Updating.Kluwer Academic Publishers.Hansson, S., & Wassermann, R. (2002). Local change. Studia Logica, 70 (1), 4976.Horn, A. (1951). sentences true direct unions algebras. JournalSymbolic Logic, 16, 1421.Katsuno, H., & Mendelzon, A. (1991). Propositional knowledge base revision minimalchange. Artificial Intelligence, 3 (52), 263294.Langlois, M., Sloan, R., Szorenyi, B., & Turan, G. (2008). Horn complements: TowardsHorn-to-Horn belief revision. Fox, D., & Gomes, C. (Eds.), Proceedings 23rdNational Conference Artificial Intelligence (AAAI), pp. 466471. AAAI Press.Levi, I. (1977). Subjunctives, dispositions chances. Synthese, 34, 423455.Liberatore, P. (2000). framework belief update. Proceedings 7th EuropeanConference Logics Artificial Intelligence (JELIA), pp. 361375.Restall, G., & Slaney, J. (1995). Realistic belief revision. Proceedings Second WorldConference Foundations Artificial Intelligence (WOCFAI), pp. 367378.Ribeiro, M. (2010). Belief Revision Description Logics Non-Classical Logics.Ph.D. thesis, University Sao Paulo.Ribeiro, M., & Wassermann, R. (2009a). AGM revision description logics. WorkshopAutomated Reasoning Context Ontology Evolution (ARCOE).Ribeiro, M., & Wassermann, R. (2009b). Base revision ontology debugging. JournalLogic Computation, 19 (5), 721743.Ribeiro, M., & Wassermann, R. (2010). AGM revision description logics.Workshop Automated Reasoning Context Ontology Evolution (ARCOE).Varzinczak, I. (2008). Action theory contraction minimal change. Lang, J., &Brewka, G. (Eds.), Proceedings 11th International Conference PrinciplesKnowledge Representation Reasoning (KR), pp. 651661. AAAI Press/MITPress.Varzinczak, I. (2010). action theory change. Journal Artificial Intelligence Research,37, 189246.Wassermann, R. (2011). AGM non-classical logics. Journal Philosophical Logic,40 (1), 124.Zhuang, Z., & Pagnucco, M. (2010). Horn contraction via epistemic entrenchment.Janhunen, T., & Niemela, I. (Eds.), Proceedings 12th European ConferenceLogics Artificial Intelligence (JELIA), No. 6341 LNCS, pp. 339351. SpringerVerlag.53fi