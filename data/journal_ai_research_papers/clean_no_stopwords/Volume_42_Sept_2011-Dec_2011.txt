Journal Articial Intelligence Research 42 (2011) 529-573

Submitted 08/11; published 11/11

Cloning Elections: Finding Possible Winners
Edith Elkind

eelkind@ntu.edu.sg

School Physical Mathematical Sciences
Nanyang Technological University, Singapore

Piotr Faliszewski

faliszew@agh.edu.pl

AGH University Science Technology
Krakow, Poland

Arkadii Slinko

slinko@math.auckland.ac.nz

Department Mathematics
University Auckland, Auckland, New Zealand

Abstract
consider problem manipulating elections cloning candidates. model,
manipulator replace candidate c several clones, i.e., new candidates
similar c voter simply replaces c vote block new
candidates, ranked consecutively. outcome resulting election may depend
number clones well voter orders clones within block.
formalize means cloning manipulation successful (which turns
surprisingly delicate issue), and, number common voting rules, characterize
preference proles successful cloning manipulation exists. also consider
model cost associated producing clone, study complexity
nding minimum-cost cloning manipulation. Finally, compare cloning two
related problems: problem control adding candidates problem possible
(co)winners new alternatives join.

1. Introduction
many real-life elections, candidates may fairly similar positions major
issues, yet disagree best way implement common goals. many
voting rules, glaringly Plurality voting, candidates run risk
splitting vote losing candidate opposing program. phenomenon
exploited alter election outcome. instance, New York Times wrote
Republican political operative recruited drifters homeless people onto Green
Party ballot freely admitted candidacies may siphon support
Democrats therefore help Republicans (Lacey, 2010).
scenarios extensively studied (computational) social choice literature (see Section 6 overview). Depending whether manipulation contemplated one candidates external party, issue known strategic
candidacy problem (this term coined Dutta, Jackson, & Le Breton, 2001, 2002)
problem control adding candidates.
paper address variant problem known cloning.
characterized following feature: new candidate must similar one
existing candidates. form manipulative behavior rst identied studied
c
2011
AI Access Foundation. rights reserved.

fiElkind, Faliszewski & Slinko

Tideman (1987), also gave classic example cloning strategy. Tideman
wrote: 12 years old nominated treasurer class school.
girl named Michelle also nominated. relished prospect treasurer,
made quick calculation nominated Michelles best friend, Charlotte. ensuing
election received 13 votes, Michelle received 12, Charlotte received 11, became
treasurer(Tideman, 1987, p. 1). calculation that, friends, Michelle
Charlotte similar electorate split.
Tidemans example, cloned alternative lost election. However, one also
imagine scenarios cloning alternative increase chances winning.
example, suppose electronics website runs competition best digital camera
asking consumers vote two favorite models given list. list
contains one model brand, 60% consumers prefer Sony Nikon
Kodak, remaining consumers prefer Kodak Nikon Sony, Nikon win
competition. hand, Sony represented two similar models,
Sony customers likely vote two models Sony, competition
Sony camera.
general candidate addition scenario, cloning presents opportunity
party interested manipulating outcome preference aggregation procedure,
election consumer survey. partymost likely, campaign manager
one candidatesmay invest creating clones one alternatives order
make preferred alternative (or one clones) win election. campaign
management strategy certain advantages introducing entirely new candidate:
latter case, may hard predict voters rank new candidate,
campaign manager would either invest eliciting new candidates rankings,
prepared deal rankings dier initial expectations. comparison,
outcomes cloning much predictable, therefore manipulation cloning
may easier implement. natural question, then, voting rules resistant
manipulation, whether manipulator compute optimal cloning strategy
given election reasonable amount time.
mentioned above, rst study cloning undertaken Tideman (1987),
introduced concept independence clones criterion voting rules. Apparently
unaware Tidemans work, Laond, Laine, Laslier (1996) introduced notion
composition consistency, analogue independence clones tournament
solutions (Laslier, 1997), i.e., voting rules dened majority relation
corresponds voters preferences. Later, Laslier (1996, 2000) introduced notion
cloning consistency, equivalent independence clones. discuss
results detail Section 6.
papers, authors concentrated nding whether certain voting
rule independent clones constructing new rules property. work,
take somewhat dierent perspective: Instead looking cloning manipulative
action prevented, view cloning campaign management tool.
point view raises number questions consideredor
considered dierent anglein previous work:
mean cloning successful? assume campaign manager produce clones existing candidates, voters rank response.
530

fiCloning Elections

assume clones similar enough ranked group voter;
however, order clones groups may dier one voter another.
Since campaign manager cannot control predict order clones
voters ranking, assume order random, i.e., voter ranks cloned
candidates possible order probability; indeed, would
case clones indistinguishable. probabilistic model, cloning
strategy succeeds certain probability. Let q real number 0
1. say manipulation cloning q-successful probability electing
desired candidate p least q. focus two extreme cases: (1) p wins
possible ordering clones, (2) p wins least one ordering
clones. case (1), cloning 1-successful; case (2), following notation
typically used dealing limits continuous mathematics, say
cloning 0+ -successful.
instances elections cloning successful? previous work
shows many well-known voting rules susceptible cloning, attempt
made characterize elections specic candidate made
winner respect given voting rule means cloning. However,
point view campaign manager considers cloning one ways
run campaign, would important know change outcome
given election cloning manipulation. Thus, paper provide
characterization results several prominent voting rules. Often, candidates
successful cloning manipulation exists characterized terms wellknown notions social choice Pareto undominated alternative (a candidate
c Pareto undominated every candidate c voter prefers c
c ), Condorcet loser (candidate c Condorcet loser every candidate
c half voters prefer c c), Uncovered Set (see Section 5.3
Miller, 1977; Fishburn, 1977; Laslier, 1997).
candidates cloned extent? existing research cloning place restrictions number clones introduced,
identities candidates cloned. hand, clear
practical campaign management scenarios issues cannot ignored;
candidates cloned, creating clone given candidate may costly.
Thus, consider settings clone candidate comes cost,
seek least expensive successful cloning strategy. mostly focus
standard model clones come zero cost, unit cost model,
clone cost.
computational complexity nding cloning strategies? Finally,
investigate computational complexity nding successful cloning strategies.
practice, sucient know cloning might work: need know
exactly strategy use. believe paper rst consider
computational aspect cloning. Following line work initiated seminal
papers Bartholdi, Tovey, Trick (1989, 1992), seek classify prominent
531

fiElkind, Faliszewski & Slinko

voting rules according whether admit ecient algorithms nding cloning
manipulation.
One might argue real-life elections cloning practical campaign management tool: all, recruiting new candidate suciently similar existing
ones may dicult, impossible. Nonetheless, natural scenarios
model cloning practical well-motivated. Below, provide two examples.
First, let us consider election parties nominate candidates position,
party nominate several candidates. voters, especially following
political scene closely, likely perceive candidates belong party
clones. partys campaign manager might attempt strategically choose number
candidates nominated party. fact, might even able aect number
candidates nominated parties (e.g., accusing giving voters
enough choice).
Second, let us consider environment where, suggested Ephrati Rosenschein
(1997), software agents vote choose joint plan (that is, alternatives possible
joint plans steps possible joint plans). system, agents easily come
minor variations (steps the) plan, eectively creating clones candidates.
(A similar example regarding society agents choosing project implement
given Laslier, 1996).
cases reasonable assume clones ranked contiguously
cost creating clone same; moreover, successful, cloning strategy
easy compute. Therefore model provides good scenarios.

2. Preliminaries
start presenting brief overview social choice concepts used
paper; point reader book Arrow, Sen, Suzumura (2002) additional
background.
Given set alternatives (also called candidates), voters preference R linear
order A, i.e., total transitive antisymmetric binary relation A. election E
n voters given set alternatives preference prole R = (R1 , . . . , Rn ),
Ri preference voter i; write E = (A, R). readability, sometimes
write place Ri . Sometimes specifying preference order Ri write X ,
X two disjoint subsets A. notation means member
X preferred member relative ordering candidates within X
within irrelevant discussion (unless specied separately). Also, denote
|R| number voters election. Given election E = (A, R), say
alternative c Pareto undominated alternative c A, c = c, least one
voter ranks c ahead c . Given two candidates a, c A, set W (c, a) = |{i | c a}|.
say c beats pairwise contest W (c, a) > W (a, c); W (c, a) = W (a, c),
pairwise contest c said tied.
voting rule F often dened mapping elections xed set alternatives set 2A \ {} nonempty subsets A. However, work,
interested situations number alternatives may change. Thus, require
voting rules dened arbitrary nite sets alternatives preference proles
532

fiCloning Elections

alternatives. say voting rule F mapping pairs form
E = (A, R), nite set R preference prole A, nonempty
subsets A. elements F(E) called winners election E. Thus, allow
election one winner, i.e., work social choice correspondences;
model also called non-unique winner model.
paper consider following voting rules (for rules described terms
scores winners alternatives maximum score):
Plurality. Plurality score Sc P (c) candidate c number voters
rank c rst.
Veto. Veto score Sc V (c) candidate c number voters rank
c last.
Borda. Given election (A, R)with |R| = n, Borda score Sc B (c) candidate
c given Sc B (c) = ni=1 |{a | c a}|.
k-Approval. k 1, k-Approval score Sc k (c) candidate c
number voters rank c top k positions. Plurality simply 1-Approval.
Plurality Runo. rst stage, two candidates top two Plurality scores eliminated. Then, run pairwise contest two survivors;
winner(s) candidate(s) get least |R|/2 votes stage, i.e.,
win tie pairwise contest. may need break tie rst stage
two candidates maximum Plurality score, one top-scorer
several candidates second-best Plurality score. end use
parallel universes tie-breaking rule (Conitzer, Rognlie, & Xia, 2009): candidate c
considered winner wins ties runo way breaking ties
rst stage.
Maximin. Maximin score Sc (c) candidate c Sc (c) = minaA W (c, a),
i.e., number votes c gets worst pairwise contest.
Copeland. Copeland score Sc C (c) candidate c |{a | W (c, a) > W (a, c)}|
|{a | W (a, c) > W (c, a)}|. is, c receives 1 point pairwise contest
wins, 0 points tie, 1 point pairwise contest loses.
equivalent conventional denition, which, candidate a, c gets
1 point wins pairwise contest a, 0.5 points tie, 0
loses contest.
candidate c Condorcet winner (respectively, Condorcet loser )
candidate holds W (c, a) > W (a, c) (respectively, W (c, a) < W (a, c)). Naturally,
every election Condorcet winner Condorcet loser. Observe Copeland
election candidates score Condorcet winner 1 score
Condorcet loser (m 1).
Many results paper computational thus assume reader
familiar standard notions computational complexity classes P NP,
many-one reductions, NP-hardness NP-completeness. NP-hardness results
follow reductions Exact Cover 3-Sets problem, dened below.
533

fiElkind, Faliszewski & Slinko

Denition 2.1 (Garey & Johnson, 1979). instance (G, S) Exact Cover 3Sets (X3C) given ground set G = {g1 , . . . , g3K } family = {S1 , . . . , SM }
subsets G, |Si | = 3 = 1, . . . , . yes-instance
subfamily S, |S | = K, gi G Sj gi Sj ,
no-instance otherwise.

3. Framework
Cloning independence clones previously dened Laslier (2000), Tideman
(1987), Zavist Tideman (1989). However, need modify denition given
papers order model manipulators intentions budget constraints.
describe model formally.
Denition 3.1. Let E = (A, (R1 , . . . , Rn )) election set candidates =
{c1 , . . . , cm }. say election E = (A , (R1 , . . . , Rn )) obtained E replac(1)
(k)
ing candidate cj k clones k > 0 = (A \ {cj }) {cj , . . . , cj }
[n], Ri total order \ {cj } [k]
(s)
holds cj cj a.
say election E = (A , R ) cloned election E = (A, R)
vector nonnegative integers (k1 , . . . , km ) E derived E replacing
cj , j = 1, . . . , m, kj clones.
Thus, clone candidate c, replace group new candidates
ranked together voters preferences. Observe according denition above,
(1)
cloning candidate cj means simply changing name cj rather producing
additional copy cj . completely intuitive, choice terminology simplies
arguments rest paper.
denition essentially equivalent one given Zavist Tideman
(1989); main dierence explicitly model cloning one candidate.
However, still need introduce two components model: denition
means cloning successful, budget.
start former, assuming throughout discussion voting rule
xed. Observe nal outcome cloning depends relative ranking
clones chosen voter, typically manipulators control.1
Thus, cloning may succeed orderings clones, others.
election authorities may approach issue worst-case perspective, consider
unacceptable given cloning succeeds least one ordering clones voters.
Alternatively, take average-case perspective, i.e., assume voters rank
clones randomly independently, ordering clones equally likely
(due similarities among clones), consider acceptable cloning manipulation
succeed probability exceed certain threshold. Similarly,
extremely cautious manipulator would view cloning successful succeeds
1. general model, and, specically, notion 0+ -successful cloning (to dened paragraphs), captures situation manipulator full control ordering
clones voters preferences.

534

fiCloning Elections

orderings, practically-minded one would happy cloning succeeds
high probability. present denition captures attitudes.
Denition 3.2. Given positive real q, 0 < q 1, say manipulation
cloning (or simply cloning) q-successful (a) manipulators preferred candidate
winner original election, (b) clone manipulators preferred candidate
winner cloned election probability least q.
two worst-case approaches discussed special cases framework.
Indeed, cloning succeeds orderings 1-successful. Similarly,
succeeds ordering q-successful q > 0 (where q may
depend |A| |R|). latter case, say cloning 0+ -successful;
equivalent saying manipulator would succeed could dictate voter
order clones. use equivalent formulation often simplies
proofs.
Observe that, according denition, manipulator succeeds long one
clones preferred candidate wins. assumption natural clones represent
company (e.g., Coke Light Coke Zero) political party. However,
campaign manager created clone candidate simply recruiting independent
candidate run similar platform, may nd outcome new candidate
wins less optimal. could instead dene success victory original candidate
c (i.e., clone c(1) ), but, least neutral voting rules, equivalent scaling
success threshold q factor k, k number clones preferred
candidate. Indeed, preference prole original candidate wins
transformed one clone wins, switching order voters
preferences, c(1) wins probability clone. particular,
means denition cloning manipulation 1-successful
clone manipulators preferred candidate.
Another issue need address costs associated cloning. Indeed,
costs important aspect realistic campaign management, manager
always restricted budget campaign. general way model cloning
costs election initial set candidates = {c1 , . . . , cm } introducing
cost function p : [m] Z+ Z+ {0, +}, p(i, j) denotes cost producing
j-th copy candidate ci . Note p(i, 1) corresponds producing additional copies
i, require p(i, 1) = 0 [m]. remark natural assume
costs nonnegative (though may equal zero), whereas assumption
costs integer-valued made computational reasons; real restriction
monetary values discrete.
assume marginal cost introducing additional cloned candidate eventually becomes constant, is, exists > 1 p(i, j) = p(i, t) j > t.
ensures cost function nite representation; specically, encode
p m-by-t table entries Z+ {0, +}.
Denition 3.3. instance q-Cloning problem q {0+ } (0, 1] given
initial set candidates = {c1 , . . . , cm }, preference prole R |R| = n,
manipulators preferred candidate c A, parameter > 1, cost function p : [m] [t]
535

fiElkind, Faliszewski & Slinko

Z+ {0, +} (with interpretation p(i, j) = p(i, t) = 1, . . . , j > t),
budget B, voting rule F. ask exists q-successful cloning respect
F costs B.
many voting rules consider, easy bound number clones
needed 0+ -successful 1-successful cloning (if one exists), bound usually
polynomial n m. Thus, often assumed polynomial n m.
focus two natural special cases q-Cloning:
1. Zero Cost (ZC): p(i, j) = 0 [m], j Z+ . case would like
decide election manipulable cloning money concern.
2. Unit Cost (UC): p(i, j) = 1 [m], j 2. model assumes creating
new clone xed cost equal candidates.
say election E q-manipulable cloning respect voting rule F
admits q-successful manipulation cloning respect F ZC model.
rest paper, characterize q-manipulable elections discuss
complexity q-Cloning problem number well-known voting rules, focusing
ZC UC models. Clearly, hardness results special cases also imply hardness
results general cost model. Similarly, hardness results ZC q-Cloning imply
hardness results UC q-Cloning; reduce ZC q-Cloning UC q-Cloning suces
set B = +. emphasize whenever say q-Cloning easy, refer
general cost model; contrast, q-manipulability refers susceptibility cloning
manipulation zero costs and/or unlimited budget.

4. Prominent Voting Rules Cloning Easy
section study q-Cloning Plurality, Plurality Runo, Veto, Maximin.
Surprisingly, four rules exhibit similar behavior respect cloning.
4.1 Plurality
start considering Plurality, arguably simplest voting rule.
Theorem 4.1. election 0+ -manipulable cloning respect Plurality
manipulators preferred candidate c win, ranked rst least
one voter. Moreover, Plurality 0+ -Cloning solved linear time.
Proof. Clearly, c rst-place votes, cloning manipulation make winner.
Now, assume cs Plurality score Sc P (c) least 1, let C = {a | Sc P (a) >
Sc P (c)} denote set candidates whose Plurality score greater c.
P (a)
C, create ka = Sc
Sc P (c) clones a.
Recall show cloning 0+ -successful, need specify ordering
clones makes c winner. One ordering obtained follows.
C, let Ra denote set orders ranked rst. Split Ra
ka groups, rst ka 1 groups size Sc P (c), last group size
Sc P (a) (ka 1)Sc P (c) Sc P (c). Let voters i-th group rank i-th clone
536

fiCloning Elections

rst, followed rest clones arbitrary order. ordering
clones, Plurality score candidate Sc P (c), c winner, i.e.,
cloning 0+ -successful.
prove second statement theorem, note above-described algorithm
nding 0+ -successful cloning optimal: reduce candidates Plurality score
cloning candidate, candidate score Sc P (a) > Sc P (c) cloned
less ka times, least one clones obtain Sc P (c) Plurality votes.
Thus, simply need compute cost cloning candidate C exactly ka times,
compare budget B.
hard strengthen rst statement Theorem 4.1 0+ -manipulability
q-manipulability q (0, 1).
Theorem 4.2. q (0, 1), Plurality election q-manipulable cloning
manipulators preferred candidate c win, ranked rst least
one voter. However, Plurality election 1-manipulable cloning.
Proof. Fix q (0, 1). Suppose manipulators preferred candidate c win,
Sc P (c) >0. candidate Sc P (a) > Sc P (c), set = Sc P (a)
one clones
create k = 2s m1
1q clones a. probability
1
1q
top-ranked two times k 2 k2 m1
. union bound,
probability least q none newly introduced clones gets one vote.
hand, none uncloned candidates Plurality votes c, cloning
change that. Therefore, c among winners resulting election. However,
obviously manipulator cannot make c winner probability 1: voters order
clones way, popular clone candidate
Plurality score original candidate.

procedure described proof Theorem 4.2 introduces (m1) n2 m1
1q
clones; number polynomial n constant q. However, number
clones necessarily optimal, i.e., procedure polynomial-time algorithm
q-Cloning. fact, complexity Plurality q-Cloning q (0, 1) remains open
problem.
4.2 Veto Plurality Runo
Veto rule exhibits extreme vulnerability cloning.
Theorem 4.3. election manipulators preferred candidate c win
1-manipulable cloning respect Veto. Moreover, Veto 0+ -Cloning
1-Cloning solved linear time.
Proof. Consider prole Veto score manipulators preferred candidate
c k. means c ranked last n k times. clone c least n k + 1 times,
guaranteed least one clone c never ranked last, among Veto
winners.
537

fiElkind, Faliszewski & Slinko

0+ -Cloning, observe useful clone candidates c. Thus,
optimal solution make two copies c ask voters order
way. better clone never ranked last among winners.
1-cloning, let Veto score election winner(s), let k Veto
score c. argued above, benet cloning candidates c,
need determine optimal number cs clones. Suppose rst = n. Then,
argument above, sucient create n k + 1 clones c. easy see
number also necessary: n k fewer clones, may ranked
last voter.

Now, suppose < n. Let = n , k = n k, set r = k+1 , create r + 1

clones c. number clones clearly sucient: r + 1 > k+1 ,
clone c ranked last least + 1 times, total number voters rank c
last original prole would least ( + 1)(r + 1) > k , contradiction.
hand, necessary introduce least r + 1 clones. Indeed, r
clones, split voters rank c last r groups, rst r 1 groups
size + 1, last group size k (r 1)( + 1) + 1 (where inequality

follows r k+1 ), voters i-th group rank i-th clone c last.
preference prole, clone c vetoed least + 1 times therefore among
winners.
consider Plurality Runo.
Theorem 4.4. election 0+ -manipulable cloning respect Plurality
Runo manipulators preferred candidate c current winner,
either
(1) ScP (c) 2,
(2) ScP (c) = 1 c wins ties pairwise contest alternative w whose
Plurality score strictly positive.
Moreover, Plurality Runo 0+ -Cloning solved polynomial time.
Proof. Suppose rst ScP (c) 2. introduce two clones c,
denote c(1) c(2) , split voters rank c rst two nonempty groups, ask
voters rst group rank c(1) rst, ask voters second group rank
c(2) rst. Next, candidate = c create Sc P (a) clones a, ask i-th
voter among rank rst rank i-th clone rst. resulting election,
Plurality score c(1) c(2) least 1, Plurality score
candidate 1. Thus, way break ties rst round
c(1) c(2) progress nal round, one wins. apply parallel
universes tie-breaking rule, means cloning 0+ -successful.
ScP (c) = 1, use strategy previous case, except
clone c. resulting election Plurality score candidate 1. Let w
alternative nonzero Plurality score loses ties pairwise election c.
easy see clone w also loses ties pairwise election c. Since
ws Plurality score original election positive, exists parallel universe
c clone w meet nal, means c winner resulting election.
538

fiCloning Elections

Thus, see conditions theorem sucient. show
necessary. First, note c ranked rst voter, c
win irrespective candidates clone. Indeed, cloned election
two candidates nonzero Plurality scores, c reach nal, voters
rank candidate = c rst, c may reach nal, lose nal. Now,
suppose Sc P (c) = 1, alternative w Sc P (w) > 0 beats c pairwise
contest; argued also holds clone w. Since c winner prior
cloning, exists least one candidate nonzero Plurality score, therefore
one clone c progress second round; hence, benet cloning
c. Moreover, even c reaches second round, face (a clone of) alternative
nonzero Plurality score original election, assumption clone
would beat c nal.
complete proof theorem, remains give polynomial-time algorithm
0+ -Cloning Plurality Runo. suggested discussion above,
two ways make c winner: either (1) try clone c (and possibly
alternatives) order ensure clones c go runo, (2) try clone
alternatives c only, ensure c goes runo alternative
defeat. algorithm implements options accepts either
within budget.
option (1), introduce two clones c, denote c(1) c(2) (clearly,
benet creating two clones c). hard see
optimal strategy ask voters order clones get (almost) identical
Plurality scores, i.e., Plurality scores c(1) c(2) Sc P2 (c) Sc P2 (c) ,
respectively. Let k = Sc P2 (c) , let C = {a \ {c} | Sc P (a) > k} denote set
candidates whose Plurality score greater c(2) . candidate C,
introduce ka = Sc Pk(a) clones a. nonzero probability, action ensures
Plurality score alternative except c(1) c(2) exceed k, thus
parallel universe c(1) competes c(2) runo one wins.
easy see strategy gives cheapest way implementing option (1).
Option (2) used candidate c wins ties pairwise contest
least one candidate nonzero Plurality score. Let = {a \ {c} |
Sc P (a) 1 W (c, a) > W (a, c)}. w compute cost manipulation results c competing w runo one parallel universes;
pick cheapest manipulations. remains explain compute
manipulation specic w D.
Let k = min{Sc P (c), Sc P (w)}, let C = {a \ {c, w} | Sc P (a) > k}. cloned,
candidates C prevent c w meeting nal round. Thus,
create ka = Sc Pk(a) clones C. easy see manipulation
results nonzero chance c winning cannot produce fewer clones
given w D. completes proof.
also characterize elections q-manipulable respect Plurality
Runo q (0, 1].

539

fiElkind, Faliszewski & Slinko

Theorem 4.5. q (0, 1), election q-manipulable cloning respect
Plurality Runo 0+ -manipulable cloning respect it.
However, election 1-manipulable.
Proof. immediate Plurality Runo election 1-manipulable:
preferred candidate winner cloning voters rank clones identically,
preferred candidate still loses.
see q (0, 1) election q-manipulable respect Plurality
Runo 0+ -manipulable respect it, suces combine
proofs Theorems 4.4 4.2. detail, proof Theorem 4.2 explains
clone candidates probability least q Plurality scores
candidates resulting prole R exceed 1. argue whenever
happens (i.e., probability q) c Plurality Runo winner long satises
conditions Theorem 4.4.
Indeed, suppose R Plurality score candidate 1.
cs Plurality score original election least 2, case least two
clones c positive Plurality scores R , hence parallel universe
meet nal. hand, cs Plurality score original election 1,
beats ties candidate w nonzero Plurality score pairwise election,
R parallel universe c meets (a clone of) w nal. Thus, c
Plurality Runo winner R , proof complete.
remark cloning strategy presented proof Proposition 4.5 is,
sense, degenerate: operates way irrespective identity preferred
candidate c, eect making eligible candidates Plurality Runo
winners. (This seen artifact non-unique winner model,
outcome viewed acceptable. interested making c unique Plurality
Runo winner, may need sophisticated cloning strategy; however, question
outside scope paper.) Observe also Plurality Runo cloning
used manipulate favor Condorcet loser.2
Example 4.6. Let us consider following Plurality Runo election: = {a, b, c, d},
17 voters whose preference orders are:
cabd
abdc
badc
dabc

8
3
3
3

voters
voters
voters
voters

Clearly, c Condorcet loser. Further, apply Plurality Runo, c gets
second round, loses there. Yet produce two clones c, possible
receives four Plurality points, enters runo and, result, one
wins election.
2. grateful one JAIR referees example.

540

fiCloning Elections

4.3 Maximin
Surprisingly, Maximin behaves essentially way Plurality respect
cloning, i.e., cloning candidate, reduce Maximin score 1 nonzero
probability.
Consider following election, used constructions throughout
section. Let E = (A, R) = {a1 , . . . , ak }, R = (R1 , . . . , Rk ), [k]
preferences i-th voter given ai ai+1 . . . ak a1 . . . ai1 .
refer election obtained E renaming candidates
k-cyclic election. election, assuming a0 = ak , = 1, . . . , k k 1
voters prefer ai1 ai 1 voter prefers ai ai1 . Thus, Maximin score
candidate 1. Further, remains true add arbitrary candidates
election, matter voters rank additional candidates. means
cloning candidate n-voter election n times telling voters order n
clones n-cyclic election, reduce Maximin score 1.
Theorem 4.7. election 0+ -manipulable cloning respect Maximin
manipulators preferred candidate c win, Pareto undominated.
Further, Maximin 0+ -Cloning solved linear time. However, election
1-manipulable cloning respect Maximin.
Proof. Clearly, voters prefer alternative c, cloning Maximin
score c 0, whereas Maximin score least one alternative positive,
hence c cannot win. hand, c undominated, Maximin score least
1. Now, use construction described reduce Maximin score
candidate 1, thus making c winner.
algorithm Maximin 0+ -Cloning relies observation way
change Maximin score candidate clone her, thereby reducing score. Now,
suppose Sc (c) = s. argue yes-instance 0+ -Cloning
budget allows us introduce ns clones candidate
ScM (a) > s; clearly, condition checked linear time.
Indeed, candidate whose Maximin score exceeds following.
create ns clones a, divide voters groups, size rst 1
groups ns , last group consists remaining ns voters.
rst 1 groups, ask voters rank clones according ns -cyclic election;
voters last group vote rst voters ns -cyclic election. Clearly,
group, = 1, . . . , ns one voter ranks i-th clone
(i 1)-st clone. Thus, resulting election, Maximin score clone
s, therefore c winner election.
converse direction, need show create less ns clones a,
Maximin score least one exceed s. Indeed, suppose create
< ns clones a; denote clones a(1) , . . . , a(t) . Given arbitrary preference
prole clones, consider directed graph whose vertices clones
edge a(i) a(j) least ns voters prefer a(i) a(j) . Note Maximin
score clone s, vertex graph must incoming edge.
particular, means graph cannot acyclic. argue cycle
541

fiElkind, Faliszewski & Slinko

graph length least ns ; clearly, implies graph contains least
ns vertices, contradiction.
see this, suppose cycle length r < ns . Relabel clones along
cycle a(1) , . . . , a(r) , i.e., assume = 1, . . . , r least ns voters prefer a(i)
a(i+1) (where a(r+1) = a(1) ). induction easy see = 1, . . . , r 1,
least n si voters whose preference order satises a(1) . . . a(i+1) .
= r 1, implies least n s(r 1) > voters prefer a(1) a(r) , contradiction
assumption edge a(r) a(1) . establishes
algorithm 0+ -Cloning correct.
Finally, easy see election 1-manipulable respect Maximin.
Indeed, way change candidates Maximin score clone him. However,
cloning, voters may order clones way, case popular
clone Maximin score original alternative.
clear one strengthen result Theorem 4.7 q-manipulability
q (0, 1). amounts following question: Suppose xed n randomly
draw n permutations {1, . . . , k}. Let P (n, k) probability [k]
j [k] j precedes least n 1 permutations. case that,
k , probability P (n, k) approaches 1?
computations show unlikely case.3 (n, k) = (5, 20)
one success 106 random trials three (n, k) = (5, 50).
(n, k) = (7, 20) (n, k) = (7, 50) single random trial 106 trials successful.
means that, even Maximin q-manipulable xed q > 0, number
clones needed would astronomical.

5. Three Rules Cloning May Dicult
consider Borda, k-Approval, Copeland rules, cloning-related problems
signicantly dicult.
5.1 Borda Rule
Borda rule, necessary sucient condition existence 0+ -successful
manipulation cloning Maximin: manipulators favorite alternative
Pareto undominated. However, Borda Maximin exhibit dierent behavior
respect 1-manipulability. Moreover, point view nding minimumcost cloning, Borda appears harder deal Maximin.
Theorem 5.1. election 0+ -manipulable cloning respect Borda
manipulators preferred candidate c win, Pareto undominated. Moreover,
UC 0+ -Cloning Borda solved linear time.
Proof. Note rst create k clones alternative ranked position
j order Ri , Ri contribution scores alternatives ranked
increases k 1, Ri contribution scores alternatives ranked
3. grateful Danny Chang help performing experiments.

542

fiCloning Elections

change, and, nally, top-ranked clone receives k 1 points Ri
used receive. use observation prove theorem.
Suppose rst voters prefer alternative c. Note implies
Sc B (a) > Sc B (c). create k clones alternative x = c, a, preference
ordering Ri three possibilities:
1. Ri , x ranked c. cloning x change Borda
scores c.
2. Ri , x ranked c. cloning x increases Borda score
k 1 change score c.
3. Ri , x ranked c. cloning x increases Borda scores
c k 1.
Thus, single act cloning alternative \ {c, a} (and hence combination
them) reduce gap scores c. Further, clone and/or
c, every ordering Ri clone ranked clone c, hence
higher Borda score. Thus, c cannot made winner cloning.
converse direction, let C = {a | Sc B (a) > Sc B (c)}. C, let
na number voters prefer c a, i.e., na = W (c, a). Let sa denote score
dierence c, i.e., sa = Sc B (a) Sc B (c). Now, set k = maxaC nsaa ,
create k + 1 clones c. Consider preference prole voters rank clones
c way. Let c top-ranked clone c. Observe Borda score c
new prole exceeds original Borda score c kn, n total number
voters. Now, consider alternative C. order Ri ranked
c, Ri contribution score increased k, order Ri
ranked c, Ri contribution score remained same. Thus, score
increased k(n na ). Hence, using Sc B (a) Sc B (c ) denote scores
c cloning, choice k Sc B (a) Sc B (c ) = Sc B (a) Sc B (c) kna 0.
conclude resulting preference prole Borda score c least high
alternative, i.e., cloning 0+ -successful.
argue input constitutes yes-instance UC 0+ -Cloning
maxaC nsaa + 1 B, B cloning budget, i.e., manipulation
constructed optimal UC model. Indeed, consider alternative C
maximizes expression nsaa . creating + 1 clones alternative = c,
increase distance c orders ranked c
t, thus reduce gap c t. Obviously, na
orders. order Ri , cloning may increase Ri contribution score a,
aect Ri contributions scores c way. Thus, creating + 1 clones
alternative \ {a, c} contribute tna closing gap c
a. similar argument applies cloning c a, showing contribution + 1
clones either alternatives also bounded tna . Hence, create
least nsaa + 1 clones.
possible strengthen Theorem 5.1 q-manipulability constant q (0, 1]?
turns Borda questions signicantly dicult rules
considered far.
543

fiElkind, Faliszewski & Slinko

rst consider situation manipulator restricted cloning
favorite candidate. remark special case model natural:
instance, party may able nominate several candidates, position
force parties so. case, even number voters, characterize
elections 1-manipulated cloning respect Borda.
Let c manipulators preferred candidate. show that, cloning c,
deal candidates currently higher Borda score c, long
lose c pairwise election. However, careful ensure cs
Borda score remains higher candidates beat c pairwise election.
Formally, let
A+ = {a \ {c} | SB (a) > SB (c)},

= {a \ {c} | SB (a) SB (c)}.

Let sa = |SB (a) SB (c)| \ {c}, set

W (c, a) W (a, c) A+ ,
na =
W (a, c) W (c, a) .
+

Finally, let r+ = + na 0 A+ r+ = max{ 2s
na | } otherwise,


let r = min{ 2s
na | , na > 0}. ready state criterion.

Theorem 5.2. election even number voters 1-manipulated respect
Borda cloning manipulators preferred candidate c c win
r+ r .
Proof. Let n denote number voters. Suppose r+ > r . Consider cloning
involves c only. Suppose results k clones c, denote c(1) , . . . , c(k) .
Let denote original Borda score c. show cloning 1-successful,
suces describe ordering clones results clones c losing election.
Consider prole rst n2 voters rank clones c(1) c(k) ,
remaining n2 voters rank clones opposite order. Clearly, Borda score
clone + n2 (k 1). consider two cases.
Case 1 (r + = +). means alternative na 0, i.e.,
preferred c least n2 voters higher Borda score c.
cloning increases score least n2 (k 1), nal Borda score least
sB (a) + n2 (k 1) > + n2 (k 1). Thus, cloning, clones c still
lower scores a, i.e., cloning 1-successful.
Case 2 (r + < +). case, exists candidate A+ na > 0
2sa



r+ = 2s
na . Consider candidate b r = na ; nb > 0.
2sb

condition r+ > r rewritten 2s
na > nb . cloning, Borda
n+nb

score sB (a) + nn
2 (k 1), bs Borda score sB (b) + 2 (k 1). Thus, c
winner, k must satisfy
s+

n na
n(k 1)
sB (a) +
(k 1);
2
2
544

s+

n + nb
n(k 1)
sB (b) +
(k 1).
2
2

fiCloning Elections

Hence, obtain
sa = sB (a)

na
(k 1),
2

sb = sB (b)

nb
(k 1).
2

2sb


Since k integer, implies r+ = 2s
na k 1 nb = r , contradiction.

opposite direction, show ordering clones constructed
worst possible manipulator. Formally, suppose generate k clones
c k 1. Consider voter gives j points c. hard see
voter gives j + (j + 1) + + (j + k 1) = kj + k(k1)
points clones c. Thus,
2
k(k1)
total Borda score clones equal ks + n 2 , Borda score c prior
cloning. follows Borda score least one clone + n2 (k 1) higher.
Since r+ r , r+ < +. Set k = 1 + r+ , consider arbitrary

alternative A+ . r+ < +, na > 0. Therefore, gains nn
2 (k 1)
2sa
n
points cloning. Now, hard see k 1 + na implies + 2 (k 1)

SB (a) + nn
2 (k 1), means cloning clone c beats a.
nish proof, consider candidate b . nb 0, cloning score
k1
b SB (b) + n k1
2 + n 2 , b still loses ties clone c.
b
hand, nb > 0, cloning increases score b n+n
2 (k 1) points.

ff



2sb
2sb

.
k 1 = r+ r
nb
nb
Therefore, cloning, score b
SB (b) +

n + nb
n
k1
(k 1) SB (b) + (k 1) + sb = + n
,
2
2
2

i.e., bs Borda score exceed clone c.
hard see second part proof (the direction) works
odd number voters well. However, direction, argument
go through. can, however, prove slightly weaker necessary condition. Dene
r+ = + na 0 A+ r+ = max{ 2snaa1 | A+ } otherwise, let
r = min{ 2snaa+1 | , na > 0}.
Proposition 5.3. election odd number voters 1-manipulated
respect Borda cloning manipulators preferred candidate c, r+ r .
relegate proof Proposition 5.3 Appendix A. remark clear
converse direction Proposition 5.3 holds: condition r+ r weaker
r+ r , unable prove sucient 1-manipulability
respect Borda.
proof Theorem 5.2 indicates orderings clones problematic
manipulator: orderings grant clone roughly number
points. exactly expected outcome orderings generated uniformly
random! Thus, proof shows Borda manipulator clones c
prepared worst-case scenario.
545

fiElkind, Faliszewski & Slinko

Note, however, limited cloning c. Indeed, cloning candidates
might useful respect 1-manipulability. example, suppose c Pareto
undominated, and, moreover, original preference prole contains candidate c
ranked right c voters (one think candidate inferior clone
c; however, emphasize present original prole). one show
cloning c suciently many times make c winner probability 1. However,
cloning c eect voters order clones randomly
adversarially manipulator. illustrated following example.
Example 5.4. Let us consider following Borda election. set candidates
C = {a, b, c, d}, four voters, whose preference orders are:
R1
R2
R3
R4

:acbd
:acbd
:acbd
:dcba

Sc B (a) = 9
Sc B (b) = 4
Sc B (c) = 8
Sc B (d) = 3

winner 9 points. However, replacing b three clones b1 , b2 , b3
1-successful manipulation favor c since new score 15, new score
c 16, matter clones ordered. time, cannot make c
winner probability 1 cloning alone. Indeed, split c k + 1 clones,
voter orders clones uniformly random, expected score clone c
4(2 + k2 ) = 8 + 2k (and, since number voters even, proof Theorem 5.2 gives
explicit ordering clones clone gets 8 + 2k points), whereas score
9 + 3k.
shows that, general, may need clone several candidates placed
c competitors large number votes, determining right
candidates clone might dicult. Indeed, clear 1-successful manipulation
Borda found polynomial time; answering question challenging open
problem.
related question answered Theorem 5.1 complexity 0+ -Cloning
(and, generally, q-Cloning q {0+ } (0, 1]) general cost model. Note
certain similarity problem 1-manipulability: cases,
may suboptimal clone c. Indeed, general costs, prove q-Cloning
NP-hard q.
Theorem 5.5. Borda, q-Cloning general cost model NP-hard rational
q (0, 1] well q = 0+ . Moreover, case even p(i, j) {0, 1, }
[m], j Z+ .
Proof. provide reduction X3C. Let (G, S) instance X3C, G =
{g1 , . . . , g3K } ground set = {S1 , . . . , SM } family 3-element subsets G.
Let N = 3K. construct instance problem follows. Let = {t1 , . . . , tM }.
let set alternatives = GT {c, u, w}, c manipulators preferred
alternative. = 1, . . . , , create two voters preference orders R2i1
R2i . preference order R2i1 given
R2i1 : G \ Si c ti Si u w \ {ti },
546

fiCloning Elections

preference order R2i given
R2i : w Si u c G \ Si T.
Further, require candidates G ranked opposite order R2i
R2i1 , i.e., j, = 1, . . . , gj 2i g g 2i1 gj . Finally,
one voter whose preference order given
R2M +1 : G c u w.
cloning costs dened follows. = 1, . . . , , producing one additional
clone ti costs 1, producing clones ti costs 0. Cloning alternative
costs +. Finally, set B = K.
easy verify pair votes (R2i1 , R2i )
1. c gets (M + 5) + (N 3 + ) = 2M + N + 2 points,
2. gj gets (M + N + 2) + = 2M + N + 2 points (this remains true gj Si ),
3. tj gets (M + 4) + (M 1) = 2M + 3 points,
4. u gets + (M + N 2) = 2M + N 2 points,
5. w gets (M 1) + (M + N + 2) = 2M + N + 1 points.
Thus, last voter, overall Borda score alternative G exceeds
c least 1 N , score alternative lower
c.
Note create N + 1 clones ti , cost 1, ensure cs
score least high alternatives Si , irrespective voters order
clones. However, cloning ti change dierence scores c
alternatives G \ Si . Within budget, clone K alternatives , N + 1 times
each. Thus, cover G size K = N/3, i.e., exact cover, transformed
1-successful cloning manipulation instance.
Conversely, consider cloning manipulation cost K. Suppose clones
alternatives ti1 , . . . , tis , K. {Si1 , . . . , Sis } cover G, element
gi G covered sj=1 Sij . means cloning manipulation
change dierence scores gi c, i.e., gi still higher Borda score
c. Hence, cloning 0+ -successful. Thus, 0+ -successful cloning cost
K corresponds cover G.
Now, consider q (0, 1]. input instance X3C yes-instance,
election constructed admits 1-successful cloning, also q-successful
cloning (as well 0+ -successful cloning). hand, start noinstance X3C, election admit 0+ -successful cloning, hence qsuccessful cloning. Thus, proof complete.
Observe cost function used proof Theorem 5.5 natural:
candidates cannot cloned all, others, certain upfront cost associated
creating rst clone (e.g., researching platform and/or identity candidate),
subsequent clones created free.
547

fiElkind, Faliszewski & Slinko

5.2 k-Approval
demonstrate family scoring rules deciding whether
given election 0+ -manipulable computationally hard. Specically, case
k-Approval k 2. proof gives reduction problem Dominating Set,
dened below.
Denition 5.6. instance Dominating Set problem triple (V, E, s),
(V, E) undirected graph integer. ask subset W V
(a) |W | (b) v V either v W v connected vertex W .
Theorem 5.7. k-Approval rule, NP-hard decide whether given election
0+ -manipulable cloning.
Proof. First, remark one always make alternative k-Approval winner
nonzero probability long ranked rst least one voter. Indeed,
simply clone alternatives suciently many times (e.g., kn times, n
number voters). ensures exists preference prole resulting set
alternatives candidate gets one k-Approval point.
However, condition necessary. Indeed, candidate k-Approval winner
even voter ranks rst. Thus, hardness reduction, ask whether
help candidate never ranked rst.
Consider instance (V, E, s) Dominating Set, V = {v1 , . . . , vt }.
assume without loss generality graph (V, E) isolated vertices < t.
construct election based (V, E, s) follows. candidate vi
vertex graph, candidate c would like make winner, additional
candidate w, set dummy candidates. exact number dummy candidates,
polynomial size (V, E), become clear describe set
voters. voter, specify nondummy candidates ranks
top k positions. Clearly, order candidates ranked positions k + 1 lower
aect outcome election. Further, assume dummy candidate
ranked among top k positions exactly one voter. (Thus, number dummy
candidates bounded k times number voters.)
= 1, . . . , t, i-th voter places vi rst ranks c position k.
next 4t2 voters places w rst ranks c position k. Further, (undirected)
edge (vi , vj ) E, 2s voters rank vi rst vj second 2s voters
rank vj rst vi second.
v1
..
.
c




vt w
.. ..
. .
c

w
..
..
.
.

c c
4t2

vi



vi

vj



vj

vj
..
.



vj
..
.

vi
..
.



vi
..
.


2s


2s


..
.
..
.

Observe based votes constructed far, score c 4t2 s, score
w 4t2 s, score vi , = 1, . . . , t, 4s(t 1) + 1.
add polynomially many voters, ranks w candidate V rst (and
dummy candidates positions 2, . . . , k), w gets 4t2 2s points total
548

fiCloning Elections

candidate V gets exactly 4t2 points total (note possible since > s).
Clearly, number voters constructed stage polynomially bounded
input size.
claim constructed election 0+ -manipulable graph (V, E)
dominating set size s. Indeed, suppose rst (V, E) dominating
set W size s. clone candidate W exactly k + 2s(k 1) times. Now,
consider following preference prole cloned alternatives. Split clones
2s + 1 groups, rst group size k remaining groups size k 1.
vi W , order clones follows:
1. i-th voter ranks rst group vi clones rst k positions.
2. j (vj , vi ) E, -th voter among 2s voters used
rank vj rst vi second ranks ( + 1)-st group vi clones positions
2, . . . , k.
3. voters order clones arbitrarily.
preference prole, c gets 4t2 2s points: pushed
top k slots rst votes, lose points. clone
candidate vi W gets 4t2 2s points, too. Indeed, x vi W .
assumption, graph (V, E) isolated vertices. Thus, vertex vj
connected vi , 2s voters (before cloning) rank vj rst position
vi second position. Let us denote set voters Eji . Now, consider
prole cloning. rst k clones vi ranked rst k positions
voter Eji , thus receives 4t2 2s points. consider -th
group vi clones, = 2, . . . , 2s + 1: clones ranked top k positions
exactly one voter Eji , none rst voters. Thus, clones scores
4t2 (2s 1) 1 = 4t2 2s. conclude score clone vi
4t2 2s.
Now, consider candidate vj V \ W . Since W dominating set (V, E),
exists vi W (vi , vj ) E. Since 2s voters used rank vi rst
vj second rank clones vi top k positions, vj pushed top
k positions least 2s votes. Consequently, k-Approval score 4t2 2s.
k-Approval score w 4t2 2s prior cloning aected cloning,
conclude cloning c winner election nonzero probability.
Conversely, suppose make c winner nonzero probability cloning
candidates. Observe rst could cloned w. Indeed, clone
w, c pushed top k positions 4t2 votes, score t.
hand, original preferences, vi V ranked rst least 4t times.
Therefore, make c winner cloning w, would clone vi V .
However, that, cs k-Approval score goes 0, cannot winner.
conclude w cloned. w ranked positions 2, . . . , k
votes, therefore cannot pushed out, means ws nal score 4t2 2s,
therefore cs nal score must least 4t2 2s. This, turn, means
clone candidates V , cloning candidate reduces cs score 1.
hand, need reduce score vi V least s. done
549

fiElkind, Faliszewski & Slinko

either cloning vi cloning alternative ranked rst voter
ranks vi second. means vi V either cloned neighbor (V, E)
cloned, i.e., set cloned alternatives forms dominating set (V, E).
argued size set s, completes reduction.
also show NP-hard decide whether election 1-manipulable
respect k-Approval.
Theorem 5.8. given k 2, NP-hard decide whether given election
1-manipulable cloning respect k-Approval.
Proof. rst present proof k = 2, show generalize
integer k 2. reduction X3C. Let instance (G, S) X3C given
ground set G = {g1 , . . . , g3K } family = {S1 , . . . , SM } subsets G,
= 1, . . . , write gi1 , gi2 , gi3 denote members Si . assume without
loss generality > K > 3. Given instance, construct election
follows. set alternatives = G {c, w} D, = {t1 , . . . , tM },
set dummy candidates. follows, place dummy candidates
appears rst two rows.
specify rst two positions vote. = 1, . . . , , i-th
voter ranks ti rst c second. next 2 voters ranks w rst dummy
alternative second. also groups 3M voters, i-th group (a)
voter ranks ti rst, (b) candidates gi1 , gi2 , gi3 ranked second
exactly voters. Further, G, add Ni = (M + 1 |{j | gi Sj }|) voters
rank gi rst dummy candidate second. Finally, add N = 2 + K voters
rank c rst dummy candidate second.
t1
c


tM
c

w


w

M2




ti
gi1

ti
gi2
3

ti
gi3




gi




Ni

gi





c




N

c


prole, score ti 3M + 1, score c 2 + K, score w
score gi 2 + . scores dummy candidates equal 1,
number clearly polynomial . K < , set winners prole
G, c K points behind. Now, clone candidate gi G, voters
may still rank clones gi order, manipulation relies cloning
candidates G 1-successful. Therefore, bridge gap c candidates
G, need clone candidates . However, cannot clone
K them, since otherwise score c fall score w (while clone
w well, voters may still order clones w way, case
top-ranked clone w still gets 2 points). hand, gi G need
clone least one tj gi Sj , since otherwise score gi go down.
Thus, 1-successful manipulation corresponds cover G size K, i.e.,
exact cover. Conversely, cloning set candidates {Sj | tj }
exact cover G 1-successful cloning.
k > 2, construction modied follows. vote, insert group
new k 2 dummy candidates rst second position (so
2,

550

fiCloning Elections

vote candidate used ranked second ranked position k
dummy candidate ranked top k positions exactly once). easy see proof
goes without change.
5.3 Copeland
analyze cloning Copeland rule, need additinal denitions.
election E set candidates A, pairwise majority graph directed graph (A, X),
X contains edge b half voters prefer b; say
beats b (a, b) X. exactly half voters prefer b, say
b tied (this mean Copeland scores equal). A,
denote U (a), D(a) (a) sets alternatives beat a, beaten a,
tied a, respectively.
odd number voters, graph (A, X) tournament, i.e., pair
(a, b) A2 , = b, either (a, b) X (b, a) X. case, make
use well-known tournament solution concept Uncovered Set (Miller, 1977; Fishburn,
1977; Laslier, 1997), dened follows. Given tournament (A, X), candidate said
cover another candidate b beats b well every candidate beaten b.
Uncovered Set (A, X) set candidates covered candidates.
turns number voters odd, Uncovered Set coincides set
candidates made Copeland winners cloning. contrast previous
characterization results, holds values q (0, 1] {0+ }.
Theorem 5.9. q (0, 1] {0+ }, Copeland election E odd number
voters q-manipulable cloning manipulators preferred candidate c
win, Uncovered Set pairwise majority graph E.
Proof. Consider election E set alternatives odd number voters.
Let (A, X) pairwise majority graph. Suppose rst c covered A.
case Sc C (c) < Sc C (a). Creating k clones alternative x increases k 1
score alternative beats x decreases k 1 score alternative
beaten x. Hence, gap c cannot reduced cloning third
alternative. Moreover, replace c k clones, score clone c
Sc C (c) + k 1, score becomes Sc C (a) + k 1. Similarly, replace
k clones, scores clone least Sc C (a) (k 1),
score c becomes Sc C (c) (k 1). shows cloning c would help either.
Thus, matter alternatives clone, cannot close gap c (or
highest-scoring clone).
Conversely, suppose c Uncovered Set. Since number candidates
odd, (c) = , since c uncovered, U (c) = \ {c}. Therefore,
D(c) = . proceed two stages. First, secure either c clone
higher Copeland score alternative D(c), take care
alternatives U (c). stage one create 2m + 1 clones c. lowers score
alternative D(c) 2m raises score alternative U (c) 2m.
simple counting argument shows that, ordering clones voters,
exists clone c whose score greater equal original score c; denote clone
551

fiElkind, Faliszewski & Slinko

c . alternative x, let Sc C (x) denote xs score stage one. x D(c)

Sc C (c ) Sc C (c) (m 1) > Sc C (x) 2m = Sc C (x),
i.e., c higher Copeland score x. hand, x U (c)
Sc C (c ) Sc C (c) (m 1) Sc C (x) (2m 2) = Sc C (x) (4m 2).
stage two create 4m + 1 clones alternative D(c). increases
score c 4m|D(c)|. Further, D(c), score clone constructed
stage exceeds Sc C (a) 4m|D(c)|. Thus, stage, c higher
Copeland score newly-generated clones. Finally, since c covered,
candidate U (c) beats candidates D(c); fact, U (c) beaten
b D(c). Thus, last step increases score candidate U (c)
4m(|D(c)| 1) 4m = 4m(|D(c)| 2). follows c higher Copeland score
candidate clone c.
elections even number voters, situation signicantly complicated. notion Uncovered Set extended pairwise majority graphs arbitrary
elections natural way (see, e.g., Brandt & Fischer, 2007): say u covers c u
beats c alternatives beaten c, and, addition, c loses alternatives beat
u. particular, means u cover c beaten alternative
tied c. denition generalizes one odd number voters. However,
even number voters, condition c Uncovered Set turns
necessary, sucient manipulability cloning.
Proposition 5.10. Copeland election E even number voters
manipulators preferred candidate c covered, c cannot made winner cloning.
Proof. Suppose c covered u. Copeland score c given |D(c)| |U (c)|.
Now, u beats alternatives D(c), alternative beats u necessarily U (c).
Thus, u strictly higher Copeland score c. Now, suppose create k + 1 clones
A. increase score c (or one clones) D(c) {c};
however, score u also increases k. hand, decrease
score u beats u. However, case score c also decreases k.
conclude c cannot made winner cloning.
However, converse true, illustrated following example.
Example 5.11. Consider election = {a, b, c, u, w}. Suppose beats u, u
beats b, b beats w, w beats a, u w beat c, pair candidates tied.
Note McGarveys theorem (1953) voters preferences produce
pairwise majority graph. election, c undominated. Indeed, beaten
u w, tied alternative beats u, namely, a, alternative
beats w, namely, b. However, cs score negative, remain negative
cloning. hand, counting argument, election alternative
negative Copeland score, least one alternative positive Copeland score.
Hence, c cannot made winner cloning.
552

fiCloning Elections

u
11
00
00
11

11
00

00
11

1
0
c
0
1

b
11
00

1
0

w

Figure 1: Candidate c undominated, cannot made winner cloning
Instead, characterize 0+ -manipulable proles terms properties
induced (bipartite) subgraph (A, X) whose vertices are, one hand, candidates
tied c, and, hand, candidates beat c
candidates beaten c. However, clear characterization leads polynomialtime algorithm detecting proles.
Specically, prole c covered 0+ -manipulable cloning
favor c, following must hold. Let = (c) let Z set candidates
beat c candidates beaten c. associate candidate z Z
number sz = Sc C (z) Sc C (c). goal assign nonnegative integer q(y) every
z Z
fi
(y,z)X

q(y)

fi

q(y) sz .

(1)

(z,y)X

Indeed, linear program integer nonnegative solution (q (y))yY
, replace
(y)+1 clones. lower score z Z






q
(y,z)X q (y)


(z,y)X q (y) thus ensure cs Copeland score least high
candidate Z. take care rest candidates cloning c (and asking
voters order clones c way) candidates D(c),
proof Theorem 5.9. Thus, condition (1) sucient 0+ -manipulability. (We remark,
however, additional constraints may needed 1-manipulability, since cloning c
may stronger eect candidates Z average clone c.)
Conversely, assignment impossible, way ensure
candidates Z lower Copeland score c. Indeed, cloning c candidates
D(c) help, candidate also beaten candidate Z.
hand, cloning candidate U (c) harm c (or clones) least much
harm candidates Z. Thus, way close gap c
candidates Z clone candidates (c), captured integer linear program.
Note also linear program (1) admit integer solution, remains
case clone candidates. Indeed, cloning candidates \ (Y Z)
change (1). Cloning candidate z Z replaces existing constraint several
identical ones. Finally, program obtained cloning candidate feasible
solution, easily transformed feasible solution original program.
introduce costs, optimal cloning becomes hard even elections odd
number voters even UC model.
553

fiElkind, Faliszewski & Slinko

Theorem 5.12. Copeland, UC q-Cloning NP-hard q {0+ } (0, 1].
Proof. give reduction X3C. Let = (G, S) input instance, G =
{g1 , . . . , g3K } ground set = {S1 , . . . , SM } family 3-element subsets G.
convenient assume 2K; always achieve duplicating
sets S. construct instance Copeland elections preferred
candidate c yes-instance X3C, 1-successful cloning
introduces K clones, and, furthermore, no-instance X3C,
exist 0+ -successful cloning introduces K clones.
set candidates election = G F {c}, c
manipulators preferred candidate, F = {f1 , . . . , fM }, = {d1 , . . . , d3M +2 }.
cloning budget set K. describe voters providing outcomes headto-head contests candidates A. McGarveys theorem (McGarvey, 1953),
tournament realized majority relation certain preference prole,
computed polynomial time. results head-to-head contests
candidates G F {c} follows:
1. c beats fj F .
2. gi G beats c.
3. gi G Sj S, gi beats fj gi
/ Sj .
4. remaining contests within G F {c} result tie.
limit candidates G F {c}, following scores: (a) c
3K points, (b) gi G 1 + 1 points, (c) fj F
0 points.
Further, set results head-to-head contests candidates G F {c}
follows:
5. c beats 2M + 2K 3M candidates {d1 , . . . , d3M }.
6. gi G beats exactly many candidates {d1 , . . . , d3M } score
3M K + 1.
7. contests candidates G F {c} result
tie.
Finally, set contests within follows: di {d1 , . . . , d3M } loses d3M +1
d3M +2 , remaining contests within result tie. Let N = 3M .
resulting election following scores:
1. c N K points.
2. gi G N K + 1 points.
3. dN +1 dN +2 N points each.
4. Every candidate 0 points.
554

fiCloning Elections

Consider nonnegative integer k. Replacing single candidate k+1 clones increases
candidates scores k, score clone dier
cloned candidate k. result, candidates winners
cloning manipulation cost K G {c, dN +1 , dN +2 }. Thus, following
discussion consider scores candidates only.
Introducing single clone fj F increases 1 scores c
/ Sj . Thus, set J {1, . . . , } |J| = K iJ Si = G,
gi
introducing single clone candidate {fi | J} ensures c winner
election. depend voters order introduced clones, i.e.,
cloning strategy 1-successful.
converse direction, argue 0+ -successful cloning
cost K, yes-instance X3C. Let us consider 0+ -successful
cloning. introduce K clones, additional clone increase cs
score 1, c trails dN +1 dN +2 K points, cloning clones
dN +1 dN +2 least N points. Consequently, cannot clone
candidates D: cloning di \ {dN +1 , dN +2 } increases scores dN +1 dN +2 ,
cloning dN +1 dN +2 increase cs score. Cloning gi G also
increase cs score, thus clone members F {c}. argue
cloned members F correspond cover G (note implies
exactly K them, cloned exactly once). Indeed, suppose otherwise,
let gi element G covered union sets correspond
cloned members F . cloning manipulation increases score gi K,
new clone contributes increase gi score. hand, cloning
within budget increase cs score K, c still trails gi , contradiction
assumption cloning manipulation 0+ -successful. completes
proof.

6. Related Work
review several lines research related work. start
discussing relevant work originates social choice community (Section 6.1),
move computational study voting problems. Section 6.2 provide
detailed comparison cloning classic problem control adding candidates
(Bartholdi et al., 1992), Section 6.3 discuss related work computational
social choice.
6.1 Cloning Social Choice Literature
rst study cloning undertaken Tideman (1987). started dening
subsets alternative set clones given prole. Specically, dened
proper subset contains least two alternatives clone-set voter
ranks candidate outside members tied member
S. denition reects idea voter nds candidates similar. Now,
every prole R denes set clone-sets C(R) 2A . Tideman denes voting rule
independent clones following two conditions met clones
ballot:
555

fiElkind, Faliszewski & Slinko

1. candidate member set clones wins member
set clones wins member set eliminated ballot.
2. candidate member set clones wins candidate
wins clone eliminated ballot.
Tideman considered number well-known voting rules, discovered among
rules STV one satised criterion. However, STV satisfy
many important criteria voting rules, Condorcet consistency monotonicity. Thus, Tideman proposed new voting rule, ranked pairs rule,
Condorcet consistent independent clones small fraction settings. Subsequently, Zavist Tideman (1989) proposed modication rule
completely independent clones. Later shown voting rules,
Schulzes rule (2003), also independent clones. Tideman considered resistance
cloning important normative requirement voting rules, method
ranked pairs proposed Zavist showed condition may satised.
Another notion related cloning composition consistency, due Laond et al.
(1996). dened tournament solution concepts (i.e., social choice correspondences
take tournaments inputs). given alternative set A, let (A) denote set
tournaments A. non-empty subset C component (A)
c, c C \ C holds (a, c) (a, c ) ; component
C said nontrivial 1 < |C| < |A|. tournament said composed
least one nontrivial component. Components tournament natural counterparts
clone-sets preference prole.
Let A1 , . . . , AK K disjoint nite sets alternatives, let T1 , . . . , TK K tournaments k = 1, . . . , K holds Tk (Ak ). Moreover, let
tournament ([K]), [K] = {1, 2, . . . , K}. composition product tournaments T1 , . . . , TK tournament = (T ; T1 , . . . , TK ) dened = A1 . . . AK
follows. k, k [K] (a, b) Ak Ak tournament contains
pair (a, b) (i) k = k (k, k ) (ii) k = k (a, b) Tk .
tournament solution concept said composition-consistent
composition product = (T ; T1 , . . . , TK ) (A) holds (T ) = {(Tk ) | k (T )}.
property may illustrated following way. Suppose K dierent
projects given society choose implement. Further, project Ak , k [K],
nk dierent variants. Composition consistency guarantees choose best
variant best project irrespectively whether use two-stage procedure rst
chooses best project best variant, simply set single tournament
order choose among variants projects.
Laond et al. (1996) Laslier (1996) suggested similar construction social choice
correspondences (which referred voting rules paper). Given set X, let
Rn (X) set n-voter proles X. Let A1 , . . . , AK K disjoint nite sets
alternatives, consider K preference proles R1 , . . . , RK , Rk = (R1k , . . . , Rnk )
prole Rn (Ak ) k [K]. Let R = (R1 , . . . , Rn ) Rn ([K]). composition product
(R ; R1 , . . . , RK ) R proles R1 , . . . , RK n-voter prole R = (R1 , . . . , Rn )
dened = A1 . . . AK follows. k, k [K] (a, b) Ak Ak
set Ri b (i) k = k k Ri k (ii) k = k Rik b. social choice
556

fiCloning Elections

correspondence said composition-consistent n
> 0 composition

1
K
product R = (R ; R , . . . , R ) Rn (A) holds (R) = {(Rk ) | k (R )}.
Laond et al. (1996) Laslier (1996) proved number tournament solution
concepts Banks Set, Uncovered Set, Tournament Equilibrium Set (TEQ),
Minimal Covering Set composition-consistent, several tournament
solution concepts social choice correspondences Top Cycle, Slater rule,
Copeland rule, scoring rules composition-consistent.
Laslier (2000) also introduced notion cloning consistency. social choice correspondence said cloning-consistent n >
product
0 composition

1
K

R = (R ; R , . . . , R ) Rn (A), holds (R) = {Ak | k (R )}. requirement says one clone alternative winning, clones alternative
must win well. property useful set alternatives fuzzy, butas
author acknowledgedterrible number alternatives xed clearly
dened.
concept composed prole necessarily useful manipulation cloning,
relevant one might call decloning. idea decloning reveal
whether prole (or, tournament) could obtained result cloning
and, possible, identify underlying composition product. Recently, decloning proved
useful preprocessing tool dealing voting rules computationally
hard winner determination problem (Conitzer, 2006; Betzler, Fellows, Guo, Niedermeier, &
Rosamond, 2009; Brandt, Brill, & Seedig, 2011). extended abstract current paper, presented Twenty-Fourth AAAI Conference Articial Intelligence
(AAAI-2010), initiated complexity-theoretic study decloning voting; topic
investigated Elkind, Faliszewski, Slinko (2011). However, decloning deserves
careful study thus omitted paper.
concept resistance cloning appeared also context study selfselectivity social choice functions. Koray Slinko (2008) discovered self-selectivity
stronger requirement resistance cloning, even deletion candidates viewed
special form cloning (one replaces candidate zero clones). partially
explains universally self-selective functions necessarily dictatorial, discovered
earlier Koray (2008). Koray Slinko (2008) circumvent impossibility result
relaxing property self-selectivity: require social choice function select among reasonable social choice functions. concept reasonable
involves social choice correspondence (for example, one selects Pareto optimal
alternatives), essential social choice correspondence resistant cloning
essential alternatives (for denition essential alternative see Koray & Slinko,
2008).
6.2 Comparison Cloning Models Adding Candidates
problem closely related cloning election control. general, term
refers manipulating result election changing structure (e.g., either
adding deleting candidates voters). computational study election control
initiated Bartholdi et al. (1992) who, among issues, considered constructive control
adding candidates (CCAC). model, given set registered candidates,
557

fiElkind, Faliszewski & Slinko

set spoiler candidates, set voters, preferences registered
candidates spoiler candidates (however, take action, registered candidates participate election). task decide possible select
subset spoiler candidates candidates registered, preferred
candidate becomes winner. Subsequently, Faliszewski, Hemaspaandra, Hemaspaandra,
Rothe (2009) rened model introducing bound number candidates
added.
Formally, use following denition CCAC problem, based
one given Faliszewski et al. (2009).
Denition 6.1. Let F voting rule. constructive control adding candidates
problem (F-CCAC) given election (C A, R), C = , designated
candidate p C, nonnegative integer t. ask set size
p unique F-winner election (C , R).4
denition above, set C corresponds already registered candidates set
set spoiler candidates manipulator introduce election.
Bartholdi, Tovey, Trick considered two rules, Plurality Condorcets rule
(i.e., rule selects Condorcet winner one exists winners otherwise),
focused standard worst-case complexity results, classifying control problems either
NP-complete P. Many researchers followed work studying various
voting rules (Erdelyi, Nowak, & Rothe, 2009b; Faliszewski et al., 2009; Faliszewski,
Hemaspaandra, & Hemaspaandra, 2011) various settings (Liu, Feng, Zhu, &
Luan, 2009; Betzler & Uhlmann, 2009; Faliszewski et al., 2011), perhaps
prominent destructive control Hemaspaandra, Hemaspaandra, Rothe (2007)
control multi-winner elections Meir, Procaccia, Rosenschein, Zohar (2008).
point reader recent survey Faliszewski, Hemaspaandra, Hemaspaandra
(2010) details election control.
q-Cloning (and, particular, UC q-Cloning) CCAC control similar
deal adding new candidates, neither problems special
case other. Indeed, place dierent restrictions candidates added
positions votes. Specically, q-Cloning new candidates must
clones existing candidates, (especially 0+ -Cloning) freedom
arrange new candidates votes. contrast, CCAC control problems,
spoiler candidates need adjacent votes, order
candidates vote predetermined.
somewhat dierent model adding candidates recently proposed Chevaleyre, Lang, Maudet, Monnot (2010). paper, authors consider following
scenario. election happening period time candidates may still join in.
given point, know candidates registered voters preferences candidates. voter may place new candidates arbitrarily
vote. Given k new candidates may still appear, already
registered ones still chance winning? (Note that, case cloning,
addition new candidates may benet original candidates hurt
4. Unique-winner model standard control problems.

558

fiCloning Elections

others.) Chevaleyre et al. (2010), andin recent follow-up workXia, Lang,
Monnot (2011), give computational complexity results problem nding
possible (co)winners new alternatives join (PcWNA). work diers
require new candidates clones preexisting ones (in particular,
require new candidates ranked consistently, consecutively
voters), diers control adding candidates allow introducing arbitrary new candidates (as opposed introducing already-ranked-by-voters candidates
predened set spoilers). Formally, model special case possible winner
problem, introduced Konczak Lang (2005), studied many researchers (Xia & Conitzer, 2011; Betzler & Dorn, 2010; Bachrach, Betzler, & Faliszewski,
2010; Baumeister & Rothe, 2010).
Table 1 provides comparison complexity control adding candidates (CCAC
control), possible co-winner determination new alternatives join (PcWNA),
q-Cloning q {0+ , 1} UC model (using UC model analogous counting
number new candidates CCAC control problems). rst column
Table 1, provide complexity results CCAC control Plurality Runo, kapproval, Borda, Veto, missing existing literature. Since
results tangential topic paper, relegate Appendix B.
Table 1 shows cloning PcWNA computationally incomparable (assuming
P = NP). example, 2-Approval 0+ -Cloning NP-hard, whereas PcWNA P.
hand, Maximin 0+ -Cloning P, PcWNA NP-complete.
contrast, Table 1 appears indicate CCAC control harder cloning.
results entirely surprising: construct contrived instances CCAC
control placing spoiler candidates way like, facilitate computational
hardness proofs. One may therefore conjecture UC 0+ -Cloning always easier
CCAC control. However, turns case.
Theorem 6.2. voting rule constructive control adding candidates
P, UC 0+ -Cloning NP-hard.
proof Theorem 6.2 given Appendix B; voting rule constructed
proof highly articial, demonstrates UC 0+ -Cloning cannot reduced
CCAC control (unless P = NP).
wrap discussion control adding candidates, mention interesting
twist standard model election control recently studied Faliszewski,
Hemaspaandra, Hemaspaandra, Rothe (2011) Brandt, Brill, Hemaspaandra,
Hemaspaandra (2010). papers, authors study complexity control (as
well manipulation bribery) single-peaked electorates. main nding
many control problems known NP-hard unrestricted preferences (and
control problems belong category) turn solvable polynomial time
preferences single-peaked. comparison, cloning computationally feasible
many rules even without assuming special properties electorate. side note,
mention cloning candidate may destroy single-peakedness election:
voter ranks clones uniformly random, resulting ranking clones unlikely
single-peaked. problem collapsing minimum number clones order
make given election single-peaked studied detail Elkind et al. (2011).
559

fiElkind, Faliszewski & Slinko

Voting rule
Plurality
Maximin
Plurality
w/Runo
Veto

CCAC control
NPC (Bartholdi
et al., 1992)
NPC (Faliszewski
et al., 2011)
NPC

PcWNA
P (Betzler & Dorn,
2010)
NPC (Xia et al., 2011)

0+ -Cloning
P

1-Cloning


P



P (Xia et al., 2011)

P



NPC

P (Betzler & Dorn,
2010)
P (Chevaleyre et al.,
2010)
P (Chevaleyre et al.,
2010)
NPC
(Chevaleyre
et al., 2010)
?

P

P

P

?

NP-hard

NP-hard

NP-hard

NP-hard

NP-hard

NP-hard

Borda

NPC

2-Approval

NPC

k-Approval,
k3
Copeland

NPC
NPC (Faliszewski
et al., 2009)

Table 1: complexity control via adding candidates (CCAC), possible co-winner
determination new alternatives join (PcWNA), q-Cloning
UC model q {0+ , 1}. Note Plurality, Plurality Runo
Maximin 1-successful cloning impossible. results CCAC control
unique-winner model (though also proved non-unique
winner model), whereas work non-unique winner model. PcWNA
results Plurality Veto follow directly general results
Betzler Dorn (2010) possible winner problem. Xia et al. (2011) also
give NP-completeness result variant Copeland rule known Copeland0 ,
score candidate simply number head-to-head contests
candidate wins.

560

fiCloning Elections

6.3 Cloning Campaign Management
large extent, work cloning motivated applications cloning campaign
management. However, campaign management understood multiple ways
well. particular, issue campaign management voting previously
studied computational perspective Elkind, Faliszewski, Slinko (2009),
introduced problem swap bribery. model, voter associated
certain cost function, describes dicult make local changes voters
preferences. goal campaign manager ensure given candidate becomes
winner smallest possible cost. problem turns NP-hard almost
voting rules, special cases admit polynomial-time solutions. Further, one
focuses variant swap bribery one allowed shift forward preferred
candidate, possible nd eective (approximation) algorithms (Elkind et al., 2009;
Elkind & Faliszewski, 2010; Schlotter, Elkind, & Faliszewski, 2011). Going dierent
research direction, Dorn Schlotter (2010) provide parameterized complexity study
swap bribery. course, standard model bribery (Faliszewski, Hemaspaandra, &
Hemaspaandra, 2009), one pay voter change vote arbitrarily, also
interpreted context campaign management.
Also, probabilistic model put forward paper, and, particular, denition
q-successful cloning similar spirit model Erdelyi, Fernau, Goldsmith, Mattei,
Raible, Rothe (2009a), voters bribed increase probabilities voting
favor particular alternative.
Finally, problem cloning particularly relevant open, anonymous environments,
Internet. settings, problem closely related cloning candidates
cloning voters. Specically, anonymous environment agent might capable
creating several instances vote multiple times. Voting rules resistant
kind manipulation called false-name-proof; studied Conitzer
(2008). variant framework which, similarly general model, creating new
identities costly subsequently considered Wagman Conitzer (2008).

7. Conclusions
provided formal model manipulating elections cloning, characterized 0+ manipulable 1-manipulable proles many well-known voting rules, explored
complexity nding minimum-cost cloning manipulation. grouping voting rules
according susceptibility manipulation diers standard classications
voting rules: e.g., scoring rules behave dierently other, Maximin
similar Plurality Copeland. Future research directions include designing
approximation algorithms minimum-cost cloning voting rules
problem known NP-hard, extending results voting rules.

Acknowledgments
would like thank anonymous JAIR referees useful feedback. Edith
Elkind supported NRF (Singapore) Research Fellowship (NRF-RF2009-08)
NTU start-up grant. Piotr Faliszewski supported AGH University Technology
561

fiElkind, Faliszewski & Slinko

Grant no. 11.11.120.865, Polish Ministry Science Higher Education grant N-N206378637, Foundation Polish Sciences program Homing/Powroty. Arkadii Slinko
supported Faculty Science Research Development Fund grant 3624495/9844.

Appendix A. Cloning Manipulators Preferred Candidate
Borda: Odd Number Voters
section, present proof Proposition 5.3. (We use notation introduced
paragraph preceding Theorem 5.2.)
Proposition 5.3. election odd number voters 1-manipulated
respect Borda cloning manipulators preferred candidate c, r+ r .
Proof. Let n number voters. Suppose r+ > r . Consider cloning
involves c only. Suppose results k clones c, denote c(1) , . . . , c(k) .
Let denote original Borda score c. show cloning 1-successful,
suces describe ordering clones results c losing election. Since
n = 1 cloning successful, assume without loss generality n 3.
Suppose rst k odd. Consider prole5 rst voter ranks clones

c(k) c(k2) . . . c(1) c(k1) c(k3) . . . c(2) ,
second voter ranks clones
c(k1) c(k3) . . . c(2) c(k) c(k2) . . . c(1) ,
third voter ranks clones
c(1) . . . c(k) ,
remaining voters split n3
2 pairs, pair rst voter ranks
(k)
(1)
clones c . . . c , second voter ranks clones c(1) . . . c(k) .
.
hard see prole Borda score clone + n(k1)
2
Indeed, let us rst consider c(k) . rst voter ranks k 1 clones c(k) ,
(k)
second voter ranks k1
2 clones c , third voter ranks clones
3(k1)
c(k) , i.e., c(k) gets 2 additional points rst 3 voters. Also, gets k 1
additional points.
additional point pair remaining voters, i.e., (n3)(k1)
2
n(k1)
Thus, Borda score + 2 . similar calculation shows Borda score
(n3)(k1)
c(k1) + k3
= + n(k1)
. Now, compare two consecutive
2 + (k 1) + 1 +
2
2
odd-numbered clones, i.e., c(j) c(j2) j odd, see c(j) ranked
c(j2) rst two votes, two positions c(j) third vote, get
number extra points rst three voters. Since two candidates get
number votes last n 3 voters, follows c(j) c(j2)
Borda scores. argument applies pair consecutive even-numbered clones.
.
Hence, simple inductive argument shows Borda score clone + n(k1)
2
5. grateful Dima Shiryaev suggesting construction.

562

fiCloning Elections

Now, k even, set k = k 1, rank rst k clones using construction
odd k given above. place c(k) clones rst n1
2 votes
clones remaining n+1
votes.
Clearly,

score


clone
c(j) , j < k,
2



n(k 2) n + 1
n(k 1) + 1
n(k 1)
;
s+
+
=s+
=s+
2
2
2
2
last equality holds since n odd k even. Moreover, score c(k) + (k
n(k1)
. Thus, values k Borda score clone
1) n1
2 s+
2
n(k1)
+ 2 .
show prole c win, consider two cases.
Case 1 (r + = +). alternative preferred c least n+1
2
voters higher Borda score c. cloning increases score
n(k1)
n+1
.
least n+1
2 (k 1), nal Borda score least sB (a) + 2 (k 1) > +
2
Thus, cloning, clones c still lower scores a, i.e., cloning
1-successful.
Case 2 (r + < +). case, exist candidates A+ , b

. cloning, Borda score sB (a) + nn
2snaa1 > 2snb +1
2 (k 1), bs
b
b
Borda score sB (b) + n+n
2 (k 1). Thus, c winner, k must satisfy

n(k 1)
n na
sB (a) +
s+
(k 1);
2
2



n(k1)
2

n(k1)+1
.
2

sa = sB (a)


n + nb
n(k 1)
sB (b) +
s+
(k 1).
2
2


Thus, rewriting inequalities, obtain

na
1
(k 1) + ,
2
2

sb = sB (b)

nb
1
(k 1) .
2
2

Since k integer, implies
ff




2sb + 1
2sa 1
+
k1
= r ,
r =
na
nb
contradiction.

Appendix B. Proofs Section 6.2
proof Theorem B.1 proceeds fairly straightforward reduction PluralityCCAC. contrast, remaining proofs section employ reductions X3C,
quite technical.
Theorem B.1. xed k, k 1, constructive control adding candidates
k-Approval NP-complete.
563

fiElkind, Faliszewski & Slinko

Proof. k = 1, k-Approval simply Plurality Plurality-CCAC shown
NP-complete (Bartholdi et al., 1992). Thus, let us assume k 2.
Clearly, k-Approval-CCAC NP. prove hardness, give reduction
Plurality-CCAC k-Approval-CCAC. Given instance = (C, A, R, p, t) PluralityCCAC R = (R1 , . . . , Rn ) (see Denition 6.1), build instance = (C, A, R, p, t)
k-Approval-CCAC follows:
1. |R| = 1, solve polynomial time (which easy case) output
xed instance k-Approval-CCAC answer.
2. n = |R| > 1, set = {di,j | 1 n, 1 j k 1} let C = C D.
= 1, . . . , n, i-th preference order Ri candidates di,1 , . . . , di,k1 ranked
positions 1, . . . , k 1, candidate ranked rst Ri ranked
position k. set R = (R1 , . . . , Rn ).
Clearly, n = 1, reduction works correctly. suppose n > 1. A,
candidate c C , Plurality score c (C , R)
k-Approval score (C , R), k-Approval score (C , R) 1.
complete proof, remains observe candidate c unique winner
Plurality election least two voters, c receives least two points.
Theorem B.2. Constructive control adding candidates Plurality Runo NPcomplete.
Proof. problem clearly NP. hardness reduction X3C. Let = (G, S)
input instance X3C, G = {g1 , . . . , g3K } ground set = {S1 , . . . , SM }
family 3-element subsets G.
construct instance CCAC Plurality Runo follows. let
candidate set C = {p, u, w}, let set spoiler candidates = {a1 , . . . , }.
preference prole R consists 6K + 20 preference orders R1 , . . . , R6K+20 , described
follows. = 1, . . . , 3K, let Ai = {aj | gi Sj }. Preference orders Ri R3K+i ,
= 1, . . . , 3K, given
Ai u \ Ai p w



Ai w \ Ai p u,

respectively. also 7 voters whose preference order p u w, 7 voters
whose preference order u p w, 6 voters whose preference order w
p u. Finally, set = K.
claim p become unique winner election (C, R) adding
= K spoiler candidates yes-instance X3C.
Let us rst consider Plurality scores candidates (C, R). Sc P (u) =
3K + 7, Sc P (w) = 3K + 6, Sc P (p) = 7. runo u w, thus p
win.
Now, consider subset election (C , R). Let Sc P (c) denote
Plurality score candidate c C election (C , R). Sc P (p) = 7,
Sc P (u) 7, Sc P (w) = Sc P (u) 1, and, moreover, Sc P (ai ) 6 ai .
implies candidate ever participate runo. Thus, depending
participating spoiler candidates, following runo scenarios possible:
564

fiCloning Elections

1. Sc P (u) 9. Sc P (w) 8, runo u w.
2. Sc P (u) = 8. Sc P (w) = 7, runo u either p w.
3. Sc P (u) = 7. Sc P (w) = 6, runo u p.
use parallel-universe tie-breaking rule, half voters prefer
p u, p unique winner election Sc P (u) = 7. is, p
made unique winner election adding candidates
possible choose subset |A | K u receives Plurality points
rst 6K voters election (C , R). Clearly, set property
every preference order among R1 , . . . , R3K member ranked u.
|A | K, possible collection = {Si | ai } exact
3-cover G.
prove CCAC control Borda NP-complete well, need tool
construct Borda votes conveniently.
Lemma B.3. Let C = {c1 , . . . , c2t1 , d}, 2, set candidates let =
{a1 , . . . , } set
spoiler candidates. Let 1 , . . . , 2t1 sequence nonnegative
integers, set L = 2t1
i=1 . preference prole R = (R1 , . . . , R2L )
C Borda scores election (C , R) follows:
1. ci C, Sc B (ci ) = L(2|A | + |C| 1) + .
2. Sc B (d) = L(2|A | + |C| 1) L.
3. ai , Sc B (ai ) L(2|A | + |C| 1) 2L.
Moreover, preference prole R computable time polynomial |C| + |A| + L.
Proof. = 1, . . . , 2t 1, set e = ci , renumber candidates C \ {d, e}
b1 , . . . , b2t2 , consider preference orders R2i1 R2i given
R2i1 : b1 b2 . . . bt1 e bt . . . b2t2 A,
R2i : b2t2 b2t3 . . . bt e bt1 . . . b1 A.
Let Ri = (R2i1 , R2i ). given A, election (C , Ri ) bi C \ {d, e}
receives 2|A | + |C| 1 points, e receives 2|A | + |C| points, receives 2|A | + |C| 2
points. Moreover, candidate ai receives 2|A | 2 points.
preference prole R copies R2i1 copies R2i = 1, . . . , 2t
1. easy see satises condition lemma.
Theorem B.4. Constructive control adding candidates Borda NP-complete.
Proof. easy see CCAC control problem Borda NP.
show problem NP-hard giving reduction X3C.
Let (G, S) input instance X3C, G = {g1 , . . . , g3K } ground set
= {S1 , . . . , SM } collection 3-element subsets G. assume without loss
generality K even K > 2; achieved, e.g., duplicating instance.
565

fiElkind, Faliszewski & Slinko

construct instance problem follows. set registered candidates
C {p, d} G (we sometimes refer p g3K+1 ) set spoiler candidates
= {a1 , . . . , }. preference prole R consists two parts, R R . rst
describe R , dene R based number Borda points candidates get
R . = 1, . . . , , preference prole R contains exactly one preference order
\ {ai } Si p ai G \ Si d.
candidate c C, let Sc B (c) number Borda points thatc gets
R , assuming candidate participates election. Set = cC Sc B (c).
Observe irrespective subset spoiler candidates participates election,
spoiler candidate ai gets = (3K + + 1) points R . Also,
election set alternatives C , candidate p gets Sc B (p) + |A | points R ,
gi G gets Sc B (gi ) + |{aj | aj gi Sj }| points R .
= 1, . . . , 3K, set
= + Sc B (gi ) 2,
p = g3K+1 set

3K+1 = + Sc B (p) K.

obtain R applying Lemma B.3 candidate set C (where gi takes
role ci p takes role c3K+1 ), spoiler candidate set A, sequence
1 , . . . , 3K+1 ; note use assumption K even (and hence |C| even).
Finally, set
= K.
3K+1
, set f (A ) = L(2|A | + |C| 1) + + S.
Let L = i=1
A, election (C , R + R ) candidates following Borda scores:
1. Sc B (p) = f (A ) K + |A |.
2. gi G, Sc B (gi ) = f (A ) 2 + |{aj | aj gi Sj }|.
3. Irrespective choice , ai Sc B (ai ) < Sc B (p)
Sc B (d) < Sc B (p).
easy see p Borda winner election (C, R + R ). Let
us assume subset spoiler candidates |A | K p
unique winner election (C , R + R ). argument above, non-empty.
Now, aj gi Sj Sc B (gi ) f (A ) 1. Therefore, p
unique winner (C , R + R ), case Sc B (p) f (A ), i.e.,
|A | = K, and, furthermore, gi G one aj gi Sj .
Hence, collection = {Sj | aj } consists K non-overlapping sets size 3, i.e.,
exact cover G. Conversely, easy see exact cover G
sets = {aj | Sj }, p unique winner (C , R + R ).
completes proof.
remark certain aspects control Borda already studied
Russel (2007); fact, Russel mentions idea cloning work, provide
results cloning CCAC control Borda.
566

fiCloning Elections

Theorem B.5. Constructive control adding candidates Veto NP-complete.
Proof. problem clearly NP. show NP-hardness, give reduction X3C.
Let (G, S) input instance X3C, G = {g1 , . . . , g3K } ground set
= {S1 , . . . , SM } family 3-element subsets G. Without loss generality
assume K > 2. = 1, . . . , 3K, let = |{Sj | gi Sj }|.
form following instance problem. set registered candidates
C = G {p}, set spoiler candidates = {a1 , . . . , }. preference prole
R consists four subproles R1 , R2 , R3 , R4 .
R1 : R1 contains 4M preference orders groups four, one group set S.
Si = {gi1 , gi2 , gi3 }, i-th group contains following four preference orders:
\ {ai } p G \ {gi1 } gi1 ai ,
\ {ai } p G \ {gi2 } gi2 ai ,
\ {ai } p G \ {gi3 } gi3 ai ,
\ {ai } G p ai .
consists preference
R2 : R2 contains 3K groups
voters, i-th
group
3K
(M


)
=
3KM


=
3M (K 1). =
orders, i.e., |R2 | = 3K


i=1
i=1
1, . . . , 3K, preference orders i-th group given p G\{gi }
gi .
R3 : R3 contains K 2 preference orders form G p.
R4 : R4 contains (3K + 1)M 2 preference orders. = 1, . . . , , j = 1, . . . , 3K,
preference orders form p G \ {gj } gj \ {ai } ai
= 1, . . . , , preference orders form G p \ {ai } ai .
Intuitively, R1 models input X3C instance, R2 ensures within R1 R2
candidates receive number points (assuming candidates C participate), R3 models constraint added candidates must correspond cover,
R4 ensures none spoiler candidates become winner. Let us make
observations formal calculating scores candidates, assuming set
candidates C A.
j = 1, . . . , 3K, let t(A , gj ) number sets Si gj Si
ai . Candidate gj receives |R1 | j + t(A , gj ) points R1 , |R2 | (M j ) points
R2 , |R3 | points R3 . Thus, total gj receives
4M j + t(A , gj ) + 3M (K 1) (M j ) + (K 2) = 3KM + t(A , gj ) + (K 2)
points voters R1 + R2 + R3 . Similarly, p receives 3M + |A | + |R2 | = 3KM + |A |
points R1 + R2 + R3 ai receives |R1 | 4 + |R2 | + |R3 | = 4M 4 +
3M (K 1) + (K 2) = (3K + 1) + (K 6) points voters R1 + R2 + R3 .
remains calculate many points candidate receives R4 . Note
(3K + 1)M 2 preference orders R4 ai ranked last least
(3K + 1)M them. Thus, ai receives (3K + 1)M 2 (3K + 1)M points
567

fiElkind, Faliszewski & Slinko

R4 . hand, = , candidate C receives exactly (3K + 1)M 2
points R4 , whereas = , candidate C receives 3KM 2 points R4 .
set = K, ask whether p made unique winner adding
spoiler candidates. easy see = , candidate p loses candidates
G, thus unique winner election. suppose = . Set
F = (3K + 1)M 2 + 3KM + K 1. candidates following scores:
1. Sc V (p) = F + |A | K + 1,
2. gj G, Sc V (gj ) = F 1 + t(A , gj ),
3. ai , Sc V (ai ) F 3KM 5.
Thus, clearly member winner. Let us assume 0 < |A | K p
unique winner election. Since t(A , gj ) 1 least one gj G, holds
gj G least F points, therefore score p least F + 1.
implies |A | = K. Further, gj G must case t(A , gj ) 1. Since
|A | = K, means collection {Si | ai } exact cover G sets
S.
easy see converse direction also true. Thus, possible ensure
p winner election adding k candidates
(G, S) yes-instance X3C.
Theorem 6.2. voting rule constructive control adding candidates
P, UC 0+ -Cloning NP-hard.
Proof. idea proof, common several results type (see, e.g., paper
Faliszewski et al., 2009, authors construct voting rule problem
bribery P, problem manipulation NP-hard), embed NP-complete
problem winner determination procedure newly constructed voting rule.
Let L NP-complete language alphabet = {0, 1}. soon provide
assumptions regarding L (all easily satised), so, describe
election encode pair strings .
Fix election E = (A, R) R = (R1 , . . . , R , R+1 ). assume without loss
generality = {c1 , . . . , cm } last voter ranks candidates c1 +1
c2 +1 +1 cm . say E encodes two length- binary strings, x = x1 . . . x
= y1 . . . , following conditions hold:
1. > 0 4.
2. voter ranks c1 c2 top two positions.
3. = 1, . . . , , yi = 0 c1 c2 yi = 1 c2 c1 .
4. = 1, . . . , , xi = 0 c3 c4 cm xi = 1
cm cm1 c3 .
568

fiCloning Elections

Otherwise E encode strings. Note last preference order R+1
special, denes roles candidates; also, requiring > 0 explicitly forbid
encoding pair two empty strings.
denition NP basic properties NP-complete languages, assume
language L admits polynomial-time algorithm B every binary string x
length holds x L binary string length
B(x, y) accepts.6 Further, assume L contain empty string
contain all-0 strings.
dene voting rule, call L. Let E = (A, R) election. E
encodes strings x B(x, y) accepts (that is, x L witnesses
case), candidates winners. Otherwise, winner
candidate ranked last last voter.
First, claim L-CCAC P. Let = (E, p, t) instance L-CCAC,
E = (C A, R), C = {c1 , . . . , cm }, = {a1 , . . . , }, R = (R1 , . . . , Rn ), p C
preferred candidate, Z+ bound number candidates
add. p winner prior adding candidates, accept. Note p ranked
last last voter, cannot change adding candidates A. Therefore,
make p winner, add candidates inuence strings x, encoded
election move election state encode strings
state does. However, goal achieved adding
candidates, also achieved adding 4 candidates. Indeed, suppose
add candidates ai1 , . . . , ais , 4 < t, ai1 n ai2 n n ais
resulting election encodes strings x y. easy see remove
candidates ai5 , . . . , ais , resulting election also encodes strings x y.
Thus, test possible make p winner adding candidates A, suces
try adding subsets size 4, and, them, verify whether
resulting election encodes two strings x B(x, y) accepts. Clearly,
done polynomial time.
hand, UC 0+ -Cloning NP-complete L (in fact, remains true
ZC 0+ -Cloning cost model allows adding least one clone). give
reduction L. Let x input binary string length ; assume without
loss generality > 0. create election E = (A , R) = {a, c1 , c2 , c3 }
set candidates R = (R1 , . . . , R , R+1 ) preference prole,
1. R+1 given +1 c1 +1 c2 +1 c3 .
2. = 1, . . . , , xi = 0 Ri given c1 c2 c3 xi = 1
Ri given c3 c2 c1 .
easy see either election encodes pair strings (0 , 0 )
encode strings. pick preferred candidate; note ranked last
last voter.
Suppose x L, i.e., exists string y, |y| = , B(x, y) accepts.
clone a(1) a(2) ask voters order clones top two
6. Indeed, require length polynomially bounded |x|, condition would
simply denition membership NP. requirement x length
easily satised appropriate padding.

569

fiElkind, Faliszewski & Slinko

positions preference orders encode y. Clearly, resulting election candidates
win.
Conversely, suppose possible clone candidates make
winner (i.e., candidates winners). Let E election cloning.
must case E encodes two strings, x , B(x , ) accepts.
happen, voter must rank clones rst two positions clones
c1 , c2 c3 remaining positions. implies x = x. Hence,
0+ -successful cloning E, one replaces two clones, a(1) a(2) ,
asks voters rank clones encode string property
B(x, y) accepts.
reduction computed polynomial time thus proof complete.

References
Arrow, K., Sen, A., & Suzumura, K. (Eds.). (2002). Handbook Social Choice Welfare,
Volume 1. Elsevier.
Bachrach, Y., Betzler, N., & Faliszewski, P. (2010). Probabilistic possible winner determination. Proceedings 24th AAAI Conference Articial Intelligence, pp.
697702. AAAI Press.
Bartholdi, III, J., Tovey, C., & Trick, M. (1989). computational diculty manipulating election. Social Choice Welfare, 6 (3), 227241.
Bartholdi, III, J., Tovey, C., & Trick, M. (1992). hard control election?.
Mathematical Computer Modeling, 16 (8/9), 2740.
Baumeister, D., & Rothe, J. (2010). Taking nal step full dichotomy possible
winner problem pure scoring rules. Proceedings 19th European Conference
Articial Intelligence, pp. 10211022. IOS Press.
Betzler, N., & Dorn, B. (2010). Towards dichotomy nding possible winners elections
based scoring rules. Journal Computer System Sciences, 76 (8), 812836.
Betzler, N., Fellows, M., Guo, J., Niedermeier, R., & Rosamond, F. (2009). Fixed-parameter
algorithms Kemeny scores. Theoretical Computer Science, 410 (45), 45544570.
Betzler, N., & Uhlmann, J. (2009). Parameterized complexity candidate control elections related digraph problems. Theoretical Computer Science, 410 (52), 4353.
Brandt, F., Brill, M., Hemaspaandra, E., & Hemaspaandra, L. (2010). Bypassing combinatorial protections: Polynomial-time algorithms single-peaked electorates. Proceedings 24th AAAI Conference Articial Intelligence, pp. 715722. AAAI
Press.
Brandt, F., Brill, M., & Seedig, G. (2011). xed-parameter tractability
composition-consistent tournament solutions. Proceedings 22nd International
Joint Conference Articial Intelligence, pp. 8590. AAAI Press.
Brandt, F., & Fischer, F. (2007). Computational aspects covering dominance graphs.
Proceedings 22nd AAAI Conference Articial Intelligence, pp. 694699.
AAAI Press.
570

fiCloning Elections

Chevaleyre, Y., Lang, J., Maudet, N., & Monnot, J. (2010). Possible winners new
candidates added: case scoring rules. Proceedings 24th AAAI
Conference Articial Intelligence, pp. 762767. AAAI Press.
Conitzer, V. (2006). Computing Slater rankings using similarities among candidates.
Proceedings 21st National Conference Articial Intelligence, pp. 613619.
AAAI Press.
Conitzer, V. (2008). Anonymity-proof voting rules. Proceedings 4th International
Workshop Internet Network Economics, pp. 295306. Springer-Verlag Lecture
Notes Computer Science #5385.
Conitzer, V., Rognlie, M., & Xia, L. (2009). Preference functions score rankings
maximum likelihood estimation. Proceedings 21st International Joint Conference Articial Intelligence, pp. 109115. AAAI Press.
Dorn, B., & Schlotter, I. (2010). Multivariate complexity analysis swap bribery.
Proceedings 5th International Symposium Parameterized Exact Computation, pp. 107122.
Dutta, B., Jackson, M., & Le Breton, M. (2001). Strategic candidacy voting procedures.
Econometrica, 69(4), 10131037.
Dutta, B., Jackson, M., & Le Breton, M. (2002). Voting successive elimination
strategic candidacy. Journal Economic Theory, 103, 190218.
Elkind, E., & Faliszewski, P. (2010). Approximation algorithms campaign management.
Proceedings 6th International Workshop Internet Network Economics,
pp. 473482. Springer-Verlag Lecture Notes Computer Science #6484.
Elkind, E., Faliszewski, P., & Slinko, A. (2009). Swap bribery. Proceedings 2nd
International Symposium Algorithmic Game Theory, pp. 299310. Springer-Verlag
Lecture Notes Computer Science #5814.
Elkind, E., Faliszewski, P., & Slinko, A. (2011). Clone structures voters preferences.
Tech. rep. arXiv:1110.3939 [cs.GT], arXiv.org.
Ephrati, E., & Rosenschein, J. (1997). heuristic technique multi-agent planning.
Annals Mathematics Articial Intelligence, 20 (14), 1367.
Erdelyi, G., Fernau, H., Goldsmith, J., Mattei, N., Raible, D., & Rothe, J. (2009a).
complexity probabilistic lobbying. Proceedings 1st International Conference Algorithmic Decision Theory, pp. 8697. Springer-Verlag Lecture Notes
Computer Science #5783.
Erdelyi, G., Nowak, M., & Rothe, J. (2009b). Sincere-strategy preference-based approval
voting fully resists constructive control broadly resists destructive control. Mathematical Logic Quarterly, 55 (4), 425443.
Faliszewski, P., Hemaspaandra, E., & Hemaspaandra, L. (2009). hard bribery
elections?. Journal Articial Intelligence Research, 35, 485532.
Faliszewski, P., Hemaspaandra, E., & Hemaspaandra, L. (2010). Using complexity protect
elections. Communications ACM, 53 (11), 7482.
571

fiElkind, Faliszewski & Slinko

Faliszewski, P., Hemaspaandra, E., & Hemaspaandra, L. (2011). Multimode control attacks
elections. Journal Articial Intelligence Research, 40, 305351.
Faliszewski, P., Hemaspaandra, E., Hemaspaandra, L., & Rothe, J. (2009). Llull
Copeland voting computationally resist bribery constructive control. Journal
Articial Intelligence Research, 35, 275341.
Faliszewski, P., Hemaspaandra, E., Hemaspaandra, L., & Rothe, J. (2011). shield
never was: Societies single-peaked preferences open manipulation
control. Information Computation, 209 (2), 89107.
Fishburn, P. (1977). Condorcet social choice functions. SIAM Journal Applied Mathematics, 33 (3), 469489.
Hemaspaandra, E., Hemaspaandra, L., & Rothe, J. (2007). Anyone him: complexity
precluding alternative. Articial Intelligence, 171 (56), 255285.
Konczak, K., & Lang, J. (2005). Voting procedures incomplete preferences. Proceedins Multidisciplinary IJCAI-05 Worshop Advances Preference Handling,
pp. 124129.
Koray, S. (2008). Self-selective social choice functions verify Arrow GibbardSatterthwaite theorems. Econometrica, 68 (4), 981995.
Koray, S., & Slinko, A. (2008). Self-selective social choice functions. Social Choice
Welfare, 31 (1), 129149.
Lacey, M. (2010). Republican runs street people green ticket. New York Times.
Laond, G., Laine, J., & Laslier, J. (1996). Composition consistent tournament solutions
social choice functions. Social Choice Welfare, 13 (1), 7593.
Laslier, J. (1996). Rank-based choice correspondencies. Economics Letters, 52 (3), 279286.
Laslier, J. (1997). Tournament Solutions Majority Voting. Springer-Verlag.
Laslier, J. (2000). Aggregation preferences variable set alternatives. Social
Choice Welfare, 17 (2), 269282.
Liu, H., Feng, H., Zhu, D., & Luan, J. (2009). Parameterized computational complexity
control problems voting systems. Theoretical Computer Science, 410 (2729),
27462753.
McGarvey, D. (1953). theorem construction voting paradoxes. Econometrica,
21 (4), 608610.
Meir, R., Procaccia, A., Rosenschein, J., & Zohar, A. (2008). complexity strategic
behavior multi-winner elections. Journal Articial Intelligence Research, 33,
149178.
Miller, N. (1977). Graph theoretical approaches theory voting. American Journal
Political Science, 21 (4), 769803.
Russel, N. (2007). Complexity control Borda count elections. Masters thesis, Rochester
Institute Technology.
572

fiCloning Elections

Schlotter, I., Elkind, E., & Faliszewski, P. (2011). Campaign management approvaldriven voting rules. Proceedings 25th AAAI Conference Articial Intelligence, pp. 726731. AAAI Press.
Schulze, M. (2003). new monotonic clone-independent single-winner election method.
Voting Matters, 17, 919.
Tideman, T. (1987). Independence clones criterion voting rules. Social Choice
Welfare, 4 (3), 185206.
Wagman, L., & Conitzer, V. (2008). Optimal false-name-proof voting rules costly
voting. Proceedings 23rd AAAI Conference Articial Intelligence, pp.
190195. AAAI Press.
Xia, L., & Conitzer, V. (2011). Determining possible necessary winners given partial
orders. Journal Articial Intelligence Research, 41, 2567.
Xia, L., Lang, J., & Monnot, J. (2011). Possible winners new alternatives join:
New results coming up!. Proceedings 10th International Conference Autonomous Agents Multiagent Systems, pp. 829836. International Foundation
Autonomous Agents Multiagent Systems.
Zavist, T., & Tideman, T. (1989). Complete independence clones ranked pairs
rule. Social Choice Welfare, 64 (2), 167173.

573

fiJournal Artificial Intelligence Research 42 (2011) 661-687

Submitted 05/11; published 12/11

Finding Consensus Bayesian Network Structures
Jose M. Pena

jose.m.pena@liu.se

ADIT
Department Computer Information Science
Linkoping University
SE-58183 Linkoping
Sweden

Abstract
Suppose multiple experts (or learning algorithms) provide us alternative
Bayesian network (BN) structures domain, interested combining
single consensus BN structure. Specifically, interested
consensus BN structure represents independences given BN structures agree
upon parameters associated possible. paper, prove
may exist several non-equivalent consensus BN structures finding one
NP-hard. Thus, decide resort heuristics find approximated
consensus BN structure. paper, consider heuristic proposed Matzkevich
Abramson, builds upon two algorithms, called Methods B, efficiently
deriving minimal directed independence map BN structure relative given node
ordering. Methods B claimed correct although proof provided (a
proof sketched). paper, show Methods B correct
propose correction them.

1. Introduction
Bayesian networks (BNs) popular graphical formalism representing probability distributions. BN consists structure parameters. structure, directed acyclic
graph (DAG), induces set independencies represented probability distribution
satisfies. parameters specify conditional probability distribution node given
parents structure. BN represents probability distribution results
product conditional probability distributions. Typically, single expert
(or learning algorithm) consulted construct BN domain hand. Therefore,
risk so-constructed BN accurate could if, instance,
expert bias overlooks certain details. One way minimize risk consists
obtaining multiple BNs domain multiple experts and, then, combining
single consensus BN. approach received significant attention literature (Matzkevich & Abramson, 1992, 1993b; Maynard-Reid II & Chajewska, 2001; Nielsen
& Parsons, 2007; Pennock & Wellman, 1999; Richardson & Domingos, 2003; del Sagrado
& Moral, 2003). relevant references probably work Pennock
Wellman (1999), shows even experts agree BN structure,
method combining experts BNs produces consensus BN respects
reasonable assumptions whose structure agreed BN structure. Unfortunately,
problem often overlooked. avoid it, propose combine experts BNs
c
2011
AI Access Foundation. rights reserved.

fiPena

two steps. First, finding consensus BN structure and, then, finding consensus
parameters consensus BN structure. paper focuses first step (we
briefly discuss second step Section 8). Specifically, assume multiple experts
provide us alternative DAG models domain, interested combining
single consensus DAG. Specifically, interested consensus
DAG represents independences given DAGs agree upon many
possible. words, consensus DAG DAG represents independences among minimal directed independence (MDI) maps intersection
independence models induced given DAGs.1 knowledge, whether
consensus DAG cannot found efficiently still open problem. See work
Matzkevich Abramson (1992, 1993b) information. paper, redefine
consensus DAG DAG fewest parameters associated among
MDI maps intersection independence models induced given DAGs.
definition line finding DAG represent probability distribution p.
desired DAG typically defined MDI map p fewest parameters
associated rather MDI map p represents independences. See,
instance, work Chickering et al. (2004). number parameters associated
DAG measure complexity DAG, since number parameters
required specify probability distributions represented DAG.
paper, prove may exist several non-equivalent consensus DAGs
finding one NP-hard. Thus, decide resort heuristics find
approximated consensus DAG. paper, consider following heuristic due
Matzkevich Abramson (1992, 1993b). See also work Matzkevich Abramson
(1993a) related information. First, let denote ordering nodes given
DAGs, denote G1 , . . . , Gm . Then, find MDI map Gi Gi relative
. Finally, let approximated consensus DAG DAG whose arcs exactly
union arcs G1 , . . . , Gm
. mentioned formulation
heuristic differs Matzkevich Abramson (1992, 1993b) following two
points. First, heuristic introduced original definition consensus DAG.
justify later heuristic also makes sense definition consensus DAG.
Second, originally required consistent one given DAGs. remove
requirement. all, key step heuristic finding MDI map Gi
Gi . Since task trivial, Matzkevich Abramson (1993b) present two algorithms,
called Methods B, efficiently deriving Gi Gi . Methods B claimed
correct although proof provided (a proof sketched). paper,
show Methods B correct propose correction them.
said, first study problem finding consensus DAG. addition works discussed Matzkevich Abramson (1992, 1993b) Pennock
Wellman (1999), works devoted problem Maynard-Reid
II Chajewska (2001); Nielsen Parsons (2007); Richardson Domingos (2003);
1. worth mentioning term consensus DAG different meaning computational biology
(Jackson et al., 2005). There, consensus DAG given set DAGs G1 , . . . , Gm defined
DAG contains arcs G1 , . . . , Gm . Therefore, difficulty lies keeping many
arcs possible without creating cycles. Note that, unlike present work, DAG interpreted
inducing independence model Jackson et al.

662

fiFinding Consensus Bayesian Network Structures

del Sagrado Moral (2003). elaborate differences works
ours. Maynard-Reid II Chajewska (2001) propose adapt existing score-based algorithms learning DAGs data case learning data replaced
BNs provided experts. approach suffers problem pointed Pennock
Wellman (1999), consists essentially learning consensus DAG
combination given BNs. somehow related approach proposed Richardson
Domingos (2003). Specifically, propose Bayesian approach learning DAGs
data, prior probability distribution DAGs constructed DAGs
provided experts. Since approach requires data combine
given DAGs single DAG, addresses problem rather different one
paper. Moreover, construction prior probability distribution DAGs ignores
fact given DAGs may different equivalent. is, unlike
present work, DAG interpreted inducing independence model. work
relatively close del Sagrado Moral (2003). Specifically, show
construct MDI map intersection union independence models
induced DAGs provided experts. However, three main differences
work ours. First, unlike us, assume given DAGs
defined set nodes. Second, unlike us, assume exists
node ordering consistent given DAGs. Third, goal find MDI
map whereas find MDI map fewest parameters associated among
MDI maps, i.e. consensus DAG. Finally, Nielsen Parsons (2007) develop
general framework construct consensus DAG gradually. framework general
sense tailored particular definition consensus DAG. Instead,
relies upon score defined user expert use score different
extensions current partial consensus DAG. individual scores combined
choose extension perform. Unfortunately, see framework could
applied definition consensus DAG.
worth recalling paper deals combination probability distributions expressed BNs. readers interested combination probability distributions expressed non-graphical numerical forms referred to, instance, work
Genest Zidek (1986). Note also interested combination
data observed. readers interested combination data
observed expert updated beliefs accordingly referred to, instance,
work Ng Abramson (1994). Finally, note also aim combining given
DAGs DAG, consensus DAG. readers interested finding DAG
graphical features (e.g. arcs paths) significant number experts agree upon may
want consult works Friedman Koller (2003); Hartemink et al. (2002); Pena et
al. (2004), since works deal similar problem.
rest paper organized follows. start reviewing preliminary
concepts Section 2. analyze complexity finding consensus DAG Section
3. discuss heuristic finding approximated consensus DAG detail
Section 4. introduce Methods B Section 5 show correct.
correct Section 6. analyze complexity corrected Methods
B Section 7 show efficient approach think
solve problem. close discussion Section 8.
663

fiPena

2. Preliminaries
section, review concepts used paper. DAGs, probability
distributions independence models paper defined V, unless otherwise
stated. B DAG G, say B adjacent G. Moreover,
say parent B B child G. denote parents B G
P aG (B). node called sink node G children G. route
two nodes B G sequence nodes starting ending B
every two consecutive nodes sequence adjacent G. Note nodes
route necessarily distinct. length route number (not necessarily
distinct) arcs route. treat nodes G routes length zero. route
B called descending B arcs route directed
towards B. descending route B, B called descendant A.
Note descendant itself, since allow routes length zero. Given subset
X V, node X called maximal G descendant node X \ {A}
G. Given route B G route 0 B C G, 0
denotes route C G resulting appending 0 .
P
Q
number parameters associated DAG G BV [ AP aG (B) rA ](rB 1),
rA rB numbers states random variables corresponding
node B. arc B G said covered P aG (A) = P aG (B) \ {A}.
covering arc B G mean adding G smallest set arcs B
becomes covered. say node C collider route DAG exist two
nodes B C B subroute route. Note B may
coincide. Let X, Z denote three disjoint subsets V. route DAG said
Z-active (i) every collider node route Z, (ii) every non-collider node
route outside Z. route DAG G node X
node Z-active, say X separated given Z G denote
X G Y|Z. denote X 6 G Y|Z X G Y|Z hold. definition
separation equivalent common definitions (Studeny, 1998, Section 5.1).
Let X, Y, Z W denote four disjoint subsets V. Let us abbreviate X
XY. independence model set statements form X Y|Z, meaning
X independent given Z. Given subset U V, denote [M ]U
statements X, Y, Z U. Given two independence models N ,
denote N X Y|Z X N Y|Z. say graphoid
satisfies following properties: symmetry X Y|Z X|Z, decomposition
X YW|Z X Y|Z, weak union X YW|Z X Y|ZW, contraction
X Y|ZW X W|Z X YW|Z, intersection X Y|ZW X
W|ZY X YW|Z. independence model induced probability distribution p,
denoted I(p), set probabilistic independences p. independence model
induced DAG G, denoted I(G), set separation statements X G Y|Z.
known I(G) graphoid (Studeny & Bouckaert, 1998, Lemma 3.1). Moreover, I(G)
satisfies composition property X G Y|Z X G W|Z X G YW|Z (Chickering &
Meek, 2002, Proposition 1). Two DAGs G H called equivalent I(G) = I(H).
DAG G directed independence map independence model I(G) .
Moreover, G minimal directed independence (MDI) map removing arc
664

fiFinding Consensus Bayesian Network Structures

G makes cease directed independence map . say G
ordering nodes consistent when, every arc B G, precedes B
node ordering. say DAG G MDI map independence model
relative node ordering G MDI map G consistent .
graphoid, G unique (Pearl, 1988, Thms. 4 9). Specifically, node
A, P aG (A) smallest subset X predecessors , P (A),
P (A) \ X|X.

3. Finding Consensus DAG NP-Hard
Recall defined consensus DAG given set DAGs G1 , . . . , Gm

DAG fewest parameters associated among MDI maps
i=1 I(G ).
sensible way start quest consensus DAG investigating whether
exist several non-equivalent consensus DAGs. following theorem answers question.
Theorem 1. exists set DAGs two non-equivalent consensus DAGs.
Proof. Consider following two DAGs four random variables number
states each:


K



J







L

K



J

L

following two non-equivalent DAGs consensus DAG two DAGs
above:


K


&




K

J

L


%


J

L

natural follow-up question investigate whether consensus DAG found
efficiently. Unfortunately, finding consensus DAG NP-hard, prove below. Specifically, prove following decision problem NP-hard:
CONSENSUS
INSTANCE: set DAGs G1 , . . . , Gm V, positive integer d.

QUESTION: exist DAG G V I(G)
i=1 I(G )
number parameters associated G greater ?

Proving CONSENSUS NP-hard implies finding consensus DAG also
NP-hard, existed efficient algorithm finding consensus DAG,
could use solve CONSENSUS efficiently. proof makes use following two
665

fiPena

decision problems:
FEEDBACK ARC SET
INSTANCE: directed graph G = (V, A) positive integer k.
QUESTION: exist subset B |B| k B least
one arc every directed cycle G ?
LEARN
INSTANCE: probability distribution p V, positive integer d.
QUESTION: exist DAG G V I(G) I(p) number
parameters associated G greater ?
FEEDBACK ARC SET NP-complete (Garey & Johnson, 1979). FEEDBACK ARC
SET remains NP-complete directed graphs total degree vertex
three (Gavril, 1977). degree-bounded FEEDBACK ARC SET problem used
Chickering et al. (2004) prove LEARN NP-hard. proof, Chickering
et al. (2004) use following polynomial reduction instance degree-bounded
FEEDBACK ARC SET instance LEARN:
Let instance degree-bounded FEEDBACK ARC SET consist directed
graph F = (VF , AF ) positive integer k.
Let L denote DAG whose nodes arcs determined F follows.
every arc ViF VjF AF , create following nodes arcs L:

ViF(9)



Aij (9)

Bij (2)

Cij (3)

Hij

(2)

.

&

Dij (9)

Eij (2)

Fij (2)



Gij



VjF(9)

(9)

number parenthesis besides node number states corresponding random variable. Let HL denote nodes Hij L, let VL denote
rest nodes L.
Specify (join) probability distribution p(HL , VL ) I(p(HL , VL )) = I(L).
Let instance LEARN consist (marginal) probability distribution p(VL )
positive integer d, computed F k shown work
Chickering et al. (2004, Equation 2).
describe instance LEARN resulting reduction
reduced instance CONSENSUS polynomial time:
Let C 1 denote DAG VL arcs L whose
endpoints VL .
666

fiFinding Consensus Bayesian Network Structures

Let C 2 denote DAG VL arcs Bij Cij Fij
j.
Let C 3 denote DAG VL arcs Cij Fij Eij
j.
Let instance CONSENSUS consist DAGs C 1 , C 2 C 3 , positive
integer d.
Theorem 2. CONSENSUS NP-hard.
Proof. start proving polynomial reduction instance F
degree-bounded FEEDBACK ARC SET instance C CONSENSUS. First, reduce
F instance L LEARN shown work Chickering et al. (2004) and, then,
reduce L C shown above.
prove solution F iff solution C. Chickering et
al. (2004, Thms. 8 9) prove solution F iff solution L.
Therefore, remains prove solution L iff solution
C (note parameter L parameter C same). Let L
p(HL , VL ) denote DAG probability distribution constructed reduction
F L. Recall I(p(HL , VL )) = I(L). Moreover:
Let L1 denote DAG (HL , VL ) arcs L whose
endpoints VL .
Let L2 denote DAG (HL , VL ) arcs Bij Cij Hij Fij
j.
Let L3 denote DAG (HL , VL ) arcs Cij Hij Fij Eij
j.
Note separation statement holds L also holds L1 , L2 L3 . Then,
I(p(HL , VL )) = I(L) 3i=1 I(Li ) and, thus, I(p(VL )) [3i=1 I(Li )]VL = 3i=1 [I(Li )]VL .
Let C 1 , C 2 C 3 denote DAGs constructed reduction L C. Note
[I(Li )]VL = I(C ) i. Then, I(p(VL )) 3i=1 I(C ) and, thus, solution
L solution C. prove opposite. proof essentially
work Chickering et al. (2004, Thm. 9). Let us define (Vi , Vj )
edge component DAG G VL subgraph G arcs
G whose endpoints {Vi , Aij , Bij , Cij , Dij , Eij , Fij , Gij , Vj }. Given solution
C C, create another solution C 0 C follows:
Initialize C 0 C 1 .
every (Vi , Vj ) edge component C, directed path C Vi
Vj , add C 0 arcs Eij Cij Fij .
every (Vi , Vj ) edge component C, directed path C Vi Vj ,
add C 0 arcs Bij Fij Cij .
667

fiPena

Note C 0 acyclic C acyclic. Moreover, I(C 0 ) 3i=1 I(C )
I(C 0 ) I(C ) i. order able conclude C 0 solution C,
remains prove number parameters associated C 0 greater
d. Specifically, prove C 0 parameters associated C,
less parameters associated solution C.
seen before, I(C 0 ) I(C 1 ). Likewise, I(C) I(C 1 ) C solution C.
Thus, exists sequence (resp. 0 ) covered arc reversals arc additions
transforms C 1 C (resp. C 0 ) (Chickering, 2002, Thm. 4). Note covered arc
reversal modify number parameters associated DAG, whereas arc
addition increases (Chickering, 1995, Thm. 3). Thus, 0 monotonically increase
number parameters associated C 1 transform it. Recall C 1 consists
series edge components form

ViF(9)



Aij (9)

Bij (2)

Cij (3)

Dij (9)

Eij (2)

Fij (2)



Gij



VjF(9)

(9)

number parenthesis besides node number states corresponding
random variable. Let us study sequences 0 modify edge component
C 1 . 0 simply adds arcs Bij Fij Cij arcs Eij Cij Fij . Note
adding first pair arcs results increase 10 parameters, whereas adding
second pair arcs results increase 12 parameters. Unlike 0 , may reverse
arc edge component. case, must cover arc first, implies
increase least 16 parameters (covering Fij Vj adding Eij Vj implies
increase exactly 16 parameters, whereas arc covering implies larger increase).
Then, implies larger increase number parameters 0 . hand,
reverse arc edge component, simply adds arcs
C C 1 . Note either Cij Fij Cij Fij C, otherwise
Cij C Fij |Z Z VL contradicts fact C solution C since
Cij 6 C 2 Fij |Z. Cij Fij C, either Bij Fij Bij Fij C
otherwise Bij C Fij |Z Z VL Cij Z, contradicts fact
C solution C since Bij 6 C 2 Fij |Z. Bij Fij would create cycle C, Bij Fij
C. Therefore, adds arcs Bij Fij Cij and, construction C 0 , 0 also
adds them. Thus, implies increase least many parameters 0 .
hand, Cij Fij C, either Cij Eij Cij Eij C otherwise
Cij C Eij |Z Z VL Fij Z, contradicts fact C
solution C since Cij 6 C 3 Eij |Z. Cij Eij would create cycle C, Cij Eij
C. Therefore, adds arcs Eij Cij Fij and, construction C 0 , 0 adds either
arcs Eij Cij Fij arcs Bij Fij Cij . case, implies increase
least many parameters 0 . Consequently, C 0 parameters
associated C.
Finally, note I(p(VL )) I(C 0 ) Chickering et al. (2004, Lemma 7). Thus,
solution C solution L.
668

fiFinding Consensus Bayesian Network Structures

worth noting proof contains two restrictions. First, number
DAGs consensuate three. Second, number states random variable
VL arbitrary prescribed. first restriction easy relax: proof
extended consensuate three DAGs simply letting C DAG VL
arcs > 3. However, open question whether CONSENSUS remains
NP-hard number DAGs consensuate two and/or number states
random variable VL arbitrary.
following theorem strengthens previous one.
Theorem 3. CONSENSUS NP-complete.
Proof. Theorem 2, remains prove CONSENSUS NP, i.e.
verify polynomial time given DAG G solution given instance
CONSENSUS.
Let denote node ordering consistent G. causal list G relative
set separation statements G P (A) \ P aG (A)|P aG (A) node A.
known I(G) coincides closure respect graphoid properties

causal list G relative (Pearl, 1988, Corollary 7). Therefore, I(G)
i=1 I(G ) iff

Gi P (A) \ P aG (A)|P aG (A) 1 m,
i=1 I(G ) graphoid (del
Sagrado & Moral, 2003, Corollary 1). Let n, ai denote, respectively, number
nodes G, number arcs G, number arcs Gi . Let b = max1im ai .
Checking separation statement Gi takes O(ai ) time (Geiger et al., 1990, p. 530). Then,

checking whether I(G)
i=1 I(G ) takes O(mnb) time. Finally, note computing
number parameters associated G takes O(a).

4. Finding Approximated Consensus DAG
Since finding consensus DAG given DAGs NP-hard, decide resort
heuristics find approximated consensus DAG. mean discard
existence fast super-polynomial algorithms. simply means pursue
possibility paper. Specifically, paper consider following heuristic
due Matzkevich Abramson (1992, 1993b). See also work Matzkevich
Abramson (1993a) related information. First, let denote ordering nodes
given DAGs, denote G1 , . . . , Gm . Then, find MDI map Gi
Gi relative . Finally, let approximated consensus DAG DAG whose
arcs exactly union arcs G1 , . . . , Gm
. following theorem justifies taking
union arcs. Specifically, proves DAG returned heuristic
consensus DAG required consistent .
Theorem 4. DAG H returned heuristic DAG fewest

parameters associated among MDI maps
i=1 I(G ) relative .

Proof. start proving H MDI map
i=1 I(G ). First, show




I(H)
i=1 I(G ). suffices note I(H) i=1 I(G ) G subm





graph H, i=1 I(G ) i=1 I(G ) I(G ) I(G ) i. Now,

669

fiPena

assume contrary DAG H 0 resulting removing arc B H


satisfies I(H 0 )
i=1 I(G ). construction H, B G i, say
= j. Note B H 0 P (B) \ P aH 0 (B)|P aH 0 (B), implies B Gj P (B) \


((m
i=1 P aGi (B)) \ {A})|(i=1 P aGi (B)) \ {A} P aH 0 (B) = (i=1 P aGi (B)) \ {A}

I(H 0 )
i=1 I(G ). Note also B Gj P (B) \ P aGj (B)|P aGj (B), implies B Gj P (B) \ P aGj (B)|P aGj (B) I(Gj ) I(Gj ). Therefore, B Gj


P (B) \ (P aGj (B) \ {A})|P aGj (B) \ {A} intersection. However, contradicts



fact Gj MDI map Gj relative . Then, H MDI map
i=1 I(G )
relative .

Finally, note
i=1 I(G ) graphoid (del Sagrado & Moral, 2003, Corollary 1).

Consequently, H MDI map
i=1 I(G ) relative .

key step heuristic is, course, choosing good node ordering . Unfortunately, fact CONSENSUS NP-hard implies also NP-hard find
best node ordering , i.e. node ordering makes heuristic return MDI

map
i=1 I(G ) fewest parameters associated. see it, note
existed efficient algorithm finding best node ordering, Theorem 4 would
imply could solve CONSENSUS efficiently running heuristic best
node ordering.
last sentence, implicitly assumed heuristic efficient,
implies implicitly assumed efficiently find MDI map Gi
Gi . rest paper shows assumption correct.

5. Methods B Correct
Matzkevich Abramson (1993b) propose heuristic discussed previous section, also present two algorithms, called Methods B, efficiently
deriving MDI map G DAG G relative node ordering . algorithms work
iteratively covering reversing arc G resulting DAG consistent
. obvious way working produces directed independence map G.
However, order arrive G , arc cover reverse iteration must
carefully chosen. pseudocode Methods B seen Figure 1. Method
starts calling Construct derive node ordering consistent G
close possible (line 6). close possible, mean
number arcs Methods B later cover reverse kept minimum,
Methods B use choose arc cover reverse iteration.
particular, Method finds leftmost node interchanged left
neighbor (line 2) repeatedly interchanges node left neighbor (lines 3-4
6-7). interchanges preceded covering reversing corresponding arc G (line 5). Method B essentially identical Method A. differences
word right replaced word left vice versa
lines 2-4, arcs point opposite directions line 5. Note Methods
B reverse arc once.
670

fiFinding Consensus Bayesian Network Structures

Construct (G, )
/* Given DAG G node ordering , algorithm returns node ordering
consistent G close possible */
1
2
3
/* 3
4
5
6
7
8
9
10
11

=
G0 = G
Let denote sink node G0
Let denote rightmost node sink node G0 */
Add leftmost node
Let B denote right neighbor
B 6=
/ P aG (B) right B
Interchange B
Go line 5
Remove incoming arcs G0
G0 6= go line 3
Return
Method A(G, )
/* Given DAG G node ordering , algorithm returns G */

1
2
3
4
5
6
7
8
9

=Construct (G, )
Let denote leftmost node whose left neighbor right
Let Z denote left neighbor
Z right
Z G cover reverse Z G
Interchange Z
Go line 3
6= go line 2
Return G
Method B(G, )
/* Given DAG G node ordering , algorithm returns G */

1
2
3
4
5
6
7
8
9

=Construct (G, )
Let denote leftmost node whose right neighbor left
Let Z denote right neighbor
Z left
Z G cover reverse Z G
Interchange Z
Go line 3
6= go line 2
Return G

Figure 1: Construct , Methods B. correction Construct consists (i)
replacing line 3 line comments it, (ii) removing lines 5-8.
671

fiPena

Figure 2: counterexample correctness Methods B.
Methods B claimed correct work Matzkevich Abramson
(1993b, Thm. 4 Corollary 2) although proof provided (a proof sketched).
following counterexample shows Methods B actually correct. Let G
DAG left-hand side Figure 2. Let = (M, I, K, J, L). Then, make
use characterization introduced Section 2 see G DAG center
Figure 2. However, Methods B return DAG right-hand side Figure
2. see it, follow execution Methods B step step. First, Methods
B construct calling Construct , runs follows:
1. Initially, = G0 = G.
2. Select sink node G0 . Then, = (M ). Remove incoming arcs
G0 .
3. Select sink node L G0 . Then, = (L, ). interchange performed
L P aG (M ). Remove L incoming arcs G0 .
4. Select sink node K G0 . Then, = (K, L, ). interchange performed
K left L . Remove K incoming arcs G0 .
5. Select sink node J G0 . Then, = (J, K, L, ). interchange performed
J P aG (K).
6. Select sink node G0 . Then, = (I, J, K, L, ). interchange
performed left J .
Construct ends, Methods B continue follows:
672

fiFinding Consensus Bayesian Network Structures

7. Initially, = (I, J, K, L, ).
8. Add arc J reverse arc J K G. Interchange J K .
Then, = (I, K, J, L, ).
9. Add arc J reverse arc L G. Interchange L .
Then, = (I, K, J, M, L).
10. Add arcs K , reverse arc J G. Interchange J
. Then, = (I, K, M, J, L).
11. Reverse arc K G. Interchange K . Then, = (I, M, K, J, L).
12. Reverse arc G. Interchange . Then, = (M, I, K, J, L) =
.
matter fact, one see early step 8 Methods B
fail: One see separated DAG resulting step 8,
implies separated DAG returned Methods B,
covering reversing arcs never introduces new separation statements. However,
separated G .
Note constructed selecting first , L, K, J, finally I.
However, could selected first K, I, , L, finally J, would
resulted = (J, L, M, I, K). , Methods B return G . Therefore,
makes difference sink node selected line 3 Construct . However, Construct
overlooks detail. propose correcting Construct (i) replacing line 3 Let
denote rightmost node sink node G0 , (ii) removing lines 5-8 since
never executed. Hereinafter, assume call Construct call
corrected version thereof. rest paper devoted prove Methods
B return G .

6. Corrected Methods B Correct
proving Methods B correct, introduce auxiliary lemmas.
proof found Appendix A. Let us call percolating right-to-left
iterating lines 3-7 Method possible. Let us modify Method replacing
line 2 Let denote leftmost node considered
adding check Z 6= line 4. pseudocode resulting algorithm,
call Method A2, seen Figure 3. Method A2 percolates right-to-left one
one nodes order appear .
Lemma 1. Method A(G, ) Method A2(G, ) return DAG.
Lemma 2. Method A2(G, ) Method B(G, ) return DAG.
Let us call percolating left-to-right iterating lines 3-7 Method B
possible. Let us modify Method B replacing line 2 Let denote rightmost
node considered adding check Z 6= line 4.
pseudocode resulting algorithm, call Method B2, seen Figure
673

fiPena

Method A2(G, )
/* Given DAG G node ordering , algorithm returns G */
1
2
3
4
5
6
7
8
9

=Construct (G, )
Let denote leftmost node considered
Let Z denote left neighbor
Z 6= Z right
Z G cover reverse Z G
Interchange Z
Go line 3
6= go line 2
Return G
Method B2(G, )
/* Given DAG G node ordering , algorithm returns G */

1
2
3
4
5
6
7
8
9

=Construct (G, )
Let denote rightmost node considered
Let Z denote right neighbor
Z 6= Z left
Z G cover reverse Z G
Interchange Z
Go line 3
6= go line 2
Return G

Figure 3: Methods A2 B2.
3. Method B2 percolates left-to-right one one nodes reverse order
appear .
Lemma 3. Method B(G, ) Method B2(G, ) return DAG.
ready prove main result paper.
Theorem 5. Let G denote MDI map DAG G relative node ordering . Then,
Method A(G, ) Method B(G, ) return G .
Proof. Lemmas 1-3, suffices prove Method B2(G, ) returns G . evident
Method B2 transforms and, thus, halts point. Therefore,
Method B2 performs finite sequence n modifications (arc additions covered arc
reversals) G. Let Gi denote DAG resulting first modifications G,
let G0 = G. Specifically, Method B2 constructs Gi+1 Gi either (i) reversing
covered arc Z, (ii) adding arc X Z X P aGi (Y ) \ P aGi (Z),
(iii) adding arc X X P aGi (Z) \ P aGi (Y ). Note I(Gi+1 ) I(Gi )
0 < n and, thus, I(Gn ) I(G0 ).
674

fiFinding Consensus Bayesian Network Structures

start proving Gi DAG consistent 0 n. Since
true G0 due line 1, suffices prove Gi DAG consistent
Gi+1 0 < n. consider following four cases.
Case 1 Method B2 constructs Gi+1 Gi reversing covered arc Z. Then,
Gi+1 DAG reversing covered arc create cycle (Chickering,
1995, Lemma 1). Moreover, note Z interchanged immediately
covered arc reversal. Thus, Gi+1 consistent .
Case 2 Method B2 constructs Gi+1 Gi adding arc X Z X
P aGi (Y ) \ P aGi (Z). Note X left left Z ,
Gi consistent . Then, X left Z and, thus, Gi+1
DAG consistent .
Case 3 Method B2 constructs Gi+1 Gi adding arc X X
P aGi (Z) \ P aGi (Y ). Note X left Z Gi consistent
, left neighbor Z (recall line 3). Then, X left
and, thus, Gi+1 DAG consistent .
Case 4 Note may get modified Method B2 constructs Gi+1 Gi . Specifically, happens Method B2 executes lines 5-6 arc
Z Gi . However, fact Gi consistent Z
interchanged fact Z neighbors (recall line 3) imply
Gi consistent Z interchanged.
Since Method B2 transforms , follows result proven Gn
DAG consistent . order prove theorem, i.e. Gn = G ,
remains prove I(G ) I(Gn ). see it, note Gn = G follows
I(G ) I(Gn ), I(Gn ) I(G0 ), fact Gn DAG consistent ,
fact G unique MDI map G0 relative . Recall G guaranteed
unique I(G0 ) graphoid.
rest proof devoted prove I(G ) I(Gn ). Specifically, prove
I(G ) I(Gi ) I(G ) I(Gi+1 ) 0 < n. Note implies
I(G ) I(Gn ) I(G ) I(G0 ) definition MDI map. First, prove
Method B2 constructs Gi+1 Gi reversing covered arc Z.
arc reversed covered implies I(Gi+1 ) = I(Gi ) (Chickering, 1995, Lemma 1). Thus,
I(G ) I(Gi+1 ) I(G ) I(Gi ).
Now, prove I(G ) I(Gi ) I(G ) I(Gi+1 ) 0 < n
Method B2 constructs Gi+1 Gi adding arc. Specifically, prove
S-active route (S V) AB
i+1 two nodes B Gi+1 ,
S-active route B G . prove result induction number
occurrences added arc AB
i+1 . assume without loss generality added
AB
arc occurs i+1 fewer times S-active route B
2
Gi+1 . call minimality property AB
i+1 . number occurrences
2. difficult show number occurrences added arc AB
i+1 two
(see Case 2.1 intuition). However, proof theorem simpler ignore fact.

675

fiPena

Figure 4: Different cases proof Theorem 5. relevant subgraphs Gi+1
G depicted. undirected edge two nodes denotes nodes
adjacent. curved edge two nodes denotes S-active route
two nodes. curved edge directed, route descending.
grey node denotes node S.

AB
added arc AB
i+1 zero, i+1 S-active route B Gi and,
thus, S-active route B G since I(G ) I(Gi ). Assume
induction hypothesis result holds k occurrences added arc AB
i+1 .
prove k + 1 occurrences. consider following two cases. case
illustrated Figure 4.

Case 1 Method B2 constructs Gi+1 Gi adding arc X Z X
3
AB
AX
ZB
P aGi (Y )\P aGi (Z). Note X Z occurs AB
i+1 . Let i+1 = i+1 X Zi+1 .
AX
AB
Note X
/ i+1 S-active Gi+1 because, otherwise, i+1 would
3. Note maybe = X and/or B = Z.

676

fiFinding Consensus Bayesian Network Structures

S-active Gi+1 . Then, S-active route AX
X G

ZB
induction hypothesis. Moreover, because, otherwise, AX
i+1 X Z i+1
would S-active route B Gi+1 would violate minimality
property AB
i+1 . Note Z G (i) Z adjacent
G since I(G ) I(Gi ), (ii) Z left (recall line 4). Note
also X G . see it, note X adjacent G since
I(G ) I(Gi ). Recall Method B2 percolates left-to-right one one
nodes reverse order appear . Method B2 currently
percolating and, thus, nodes right right
too. X G X would right and, thus, X would
right . However, would contradict fact X
left , follows fact Gi consistent . Thus, X
G . consider two cases.
Case 1.1 Assume Z
/ S. Then, ZB
i+1 S-active Gi+1 because, otherwise,
AB
i+1 would S-active Gi+1 . Then, S-active route ZB

Z B G induction hypothesis. Then, AX

X



Z ZB


S-active route B G .
WB 4
Case 1.2 Assume Z S. Then, ZB
/
i+1 = Z W i+1 . Note W
W
B
AB
i+1 S-active Gi+1 because, otherwise, i+1 would S-active Gi+1 .
B W B G induction
Then, S-active route W


hypothesis. Note W Z adjacent G since I(G ) I(Gi ).
fact proven Z G imply W adjacent
G because, otherwise, 6 Gi W |U G W |U U V
Z U, would contradict I(G ) I(Gi ). fact, W
G . see it, recall nodes right right
too. W G W would right and, thus,
W would right too. However, would contradict fact
W left , follows fact W left
Z Gi consistent , fact left neighbor
WB
Z (recall line 3). Thus, W G . Then, AX
X W
S-active route B G .

Case 2 Method B2 constructs Gi+1 Gi adding arc X X
5
AB
AX
YB
P aGi (Z)\P aGi (Y ). Note X occurs AB
i+1 . Let i+1 = i+1 X i+1 .
AX
AB
Note X
/ i+1 S-active Gi+1 because, otherwise, i+1 would
S-active Gi+1 . Then, S-active route AX
X G

induction hypothesis. Note Z G (i) Z adjacent
G since I(G ) I(Gi ), (ii) Z left (recall line 4). Note also
X Z adjacent G since I(G ) I(Gi ). fact Z
G imply X adjacent G because, otherwise, X 6 Gi |U
X G |U U V Z U, would contradict
WB
4. Note maybe W = B. Note also W 6= X because, otherwise, AX
i+1 X X i+1 would
S-active route B Gi+1 would violate minimality property AB
i+1 .
5. Note maybe = X and/or B = .

677

fiPena

I(G ) I(Gi ). fact, X G . see it, recall Method B2 percolates
left-to-right one one nodes reverse order appear
. Method B2 currently percolating and, thus, nodes right
right too. X G X would
right and, thus, X would right too. However, would
contradict fact X left , follows fact
X left Z Gi consistent , fact
left neighbor Z (recall line 3). Thus, X G . consider three
cases.
B = X XB . Note XB S-active
Case 2.1 Assume Yi+1
i+1
i+1
AB
Gi+1 because, otherwise, i+1 would S-active Gi+1 . Then,
S-active route XB
X B G induction hypothesis.

AX
Then, X X XB
S-active route B G .

B = W W B .6 Note W
Case 2.2 Assume Yi+1
/
i+1
W
B
i+1 S-active Gi+1 because, otherwise, AB
would


S-active
Gi+1 .
i+1
B W B G induction
Then, S-active route W


hypothesis. Note also W G . see it, note W
adjacent G since I(G ) I(Gi ). Recall nodes right
right too. W G W would
right and, thus, W would right too.
However, would contradict fact W left ,
follows fact Gi consistent . Thus, W G . Then,
W B S-active route B G .
AX

X W

Case 2.3 Assume
/ S. proof case based step 8
work Chickering (2002, Lemma 30). Let denote node maximal
G set descendants Gi . Note guaranteed
unique Chickering (2002, Lemma 29), I(G ) I(Gi ). Note also
6= , Z descendant Gi and, shown above, Z
G . show descendant Z Gi . consider three cases.
Case 2.3.1 Assume = Z. Then, descendant Z Gi .
Case 2.3.2 Assume 6= Z descendant Z G0 . Recall
Method B2 percolates left-to-right one one nodes
reverse order appear . Method B2 currently percolating
and, thus, yet percolated Z Z left
(recall line 4). Therefore, none descendants Z G0 (among
D) left Z . fact consistent Gi
imply Z node maximal Gi set descendants
Z G0 . Actually, Z node Chickering (2002, Lemma 29),
I(Gi ) I(G0 ). Then, descendants Z G0 descendants
Z Gi too. Thus, descendant Z Gi .
6. Note maybe W = B. Note also W 6= X, case W = X covered Case
2.1.

678

fiFinding Consensus Bayesian Network Structures

Case 2.3.3 Assume 6= Z descendant Z G0 .
shown Case 2.3.2, descendants Z G0 descendants Z
Gi too. Therefore, none descendants Z G0 left
because, otherwise, descendant Z thus Gi would
left , would contradict definition D.
fact descendant Z G0 imply still
G0 Z became sink node G0 Construct (recall Figure 1).
Therefore, Construct added added Z (recall lines 3-4),
left Z definition D.7 reason,
Method B2 interchanged Z (recall line 4). Thus,
currently still left Z , implies left
, left neighbor Z (recall line 3). However,
contradicts fact Gi consistent , descendant
Gi . Thus, case never occurs.
B
continue proof Case 2.3. Note
/ implies Yi+1
S-active Gi+1 because, otherwise, AB
i+1 would S-active Gi+1 . Note
also descendant Z Gi because, otherwise, would
XY B
S-active route XY
X Gi and, thus, AX

i+1
i+1
would S-active route B Gi+1 would violate
minimality property AB
/ because, shown above,
i+1 . implies
descendant Z Gi . also implies S-active descending
ZD S-active route
route ZD
Z Gi . Then, AX

i+1 X Z
ZD S-active route
Gi+1 . Likewise,
i+1 Z

B Gi+1 , i+1 denotes route resulting reversing
B . Therefore, S-active routes AD BD
Yi+1


B G induction hypothesis.
Consider subroute AB
i+1 starts arc X continues
direction arc reaches node E E = B E S.
Note E descendant Gi and, thus, E descendant G
definition D. Let DE
denote descending route E G .

Assume without loss generality G descending route
B node shorter DE
. implies E = B
DE
DE
S-active G because, shown above,
/ S. Thus, AD

S-active route B G . hand, E E 6=
DE ED DB S-active route

/ S. Thus, AD



ED
B G , DB
denote

routes resulting reversing

BD .
DE





Finally, show correctness Method B2 leads alternative proof
so-called Meeks conjecture (1997). Given two DAGs G H I(H) I(G),
Meeks conjecture states transform G H sequence arc additions
covered arc reversals operation sequence G DAG
7. Note statement true thanks correction Construct .

679

fiPena

Method G2H(G, H)
/* Given two DAGs G H I(H) I(G), algorithm transforms
G H sequence arc additions covered arc reversals
operation sequence G DAG I(H) I(G) */
1
2
3

Let denote node ordering consistent H
G=Method B2(G, )
Add G arcs H G

Figure 5: Method G2H.
I(H) I(G). importance Meeks conjecture lies allows develop efficient
asymptotically correct algorithms learning BNs data mild assumptions
(Chickering, 2002; Chickering & Meek, 2002; Meek, 1997; Nielsen et al., 2003). Meeks
conjecture proven true work Chickering (2002, Thm. 4) developing
algorithm constructs valid sequence arc additions covered arc reversals.
propose alternative algorithm construct sequence. pseudocode
algorithm, called Method G2H, seen Figure 5. following corollary proves
Method G2H correct.
Corollary 1. Given two DAGs G H I(H) I(G), Method G2H(G, H)
transforms G H sequence arc additions covered arc reversals
operation sequence G DAG I(H) I(G).
Proof. Note Method G2Hs line 1 denotes node ordering consistent
H. Let G denote MDI map G relative . Recall G guaranteed
unique I(G) graphoid. Note I(H) I(G) implies G subgraph
H. see it, note I(H) I(G) implies obtain MDI map G relative
removing arcs H. However, G MDI map G relative .
Then, follows proof Theorem 5 Method G2Hs line 2 transforms
G G sequence arc additions covered arc reversals,
operation sequence G DAG I(G ) I(G). Thus, operation
sequence I(H) I(G) I(H) I(G ) since, shown above, G subgraph
H. Moreover, Method G2Hs line 3 transforms G G H sequence arc
additions. course, arc addition G DAG I(H) I(G) G
subgraph H.

7. Corrected Methods B Efficient
section, show Methods B efficient solution
problem think of. Let n denote, respectively, number
nodes arcs G. Moreover, let us assume hereinafter DAG implemented
680

fiFinding Consensus Bayesian Network Structures

adjacency matrix, whereas node ordering implemented array entry per
node indicating position node ordering. Since I(G) graphoid, first
solution think consists applying following characterization G :
node A, P aG (A) smallest subset X P (A) G P (A) \ X|X.
solution implies evaluating node O(2n ) subsets P (A). Evaluating
subset implies checking separation statement G, takes O(a) time (Geiger et al.,
1990, p. 530). Therefore, overall runtime solution O(an2n ).
Since I(G) satisfies composition property addition graphoid properties,
efficient solution consists running incremental association Markov boundary
(IAMB) algorithm (Pena et al., 2007, Thm. 8) node find P aG (A). IAMB
algorithm first sets P aG (A) = and, then, proceeds following two steps.
first step consists iterating following line P aG (A) change:
Take node B P (A) \ P aG (A) 6 G B|P aG (A) add P aG (A).
second step consists iterating following line P aG (A)
change: Take node B P aG (A) considered
G B|P aG (A)\{B}, remove P aG (A). first step IAMB algorithm
add O(n) nodes P aG (A). addition implies evaluating O(n) candidates
addition, since P (A) O(n) nodes. Evaluating candidate implies checking
separation statement G, takes O(a) time (Geiger et al., 1990, p. 530). Then,
first step IAMB algorithm runs O(an2 ) time. Similarly, second step
IAMB algorithm runs O(an) time. Therefore, IAMB algorithm runs O(an2 ) time.
Since IAMB algorithm run n nodes, overall runtime
solution O(an3 ).
analyze efficiency Methods B. exact, analyze
Methods A2 B2 (recall Figure 3) rather original Methods B (recall
Figure 1), former efficient latter. Methods A2 B2 run
O(n3 ) time. First, note Construct runs O(n3 ) time. algorithm iterates n
times lines 3-10 and, iterations, iterates O(n) times lines
5-8. Moreover, line 3 takes O(n2 ) time, line 6 takes O(1) time, line 9 takes O(n) time.
Now, note Methods A2 B2 iterate n times lines 2-8 and,
iterations, iterate O(n) times lines 3-7. Moreover, line 4 takes O(1) time,
line 5 takes O(n) time covering arc implies updating adjacency matrix
accordingly. Consequently, Methods B efficient solution
problem think of.
Finally, analyze complexity Method G2H. Method G2H runs O(n3 ) time:
constructed O(n3 ) time calling Construct (H, ) node
ordering, running Method B2 takes O(n3 ) time, adding G arcs H
G done O(n2 ) time. Recall Method G2H alternative
algorithm work Chickering (2002). Unfortunately, implementation details
provided work Chickering and, thus, comparison runtime
algorithm possible. However, believe algorithm efficient.
681

fiPena

8. Discussion
paper, studied problem combining several given DAGs consensus
DAG represents independences given DAGs agree upon
parameters associated possible. Although definition consensus DAG reasonable,
would like leave number parameters associated focus solely
independencies represented consensus DAG. words, would like define
consensus DAG DAG represents independences given DAGs
agree upon many possible. currently investigating whether
definitions equivalent. paper, proven may exist several nonequivalent consensus DAGs. principle, equally good. able
conclude one represents independencies rest, would prefer
one. paper, proven finding consensus DAG NP-hard.
made us resort heuristics find approximated consensus DAG. mean
discard existence fast super-polynomial algorithms general case,
polynomial algorithms constrained cases given DAGs bounded
in-degree. question currently investigating. paper,
considered heuristic originally proposed Matzkevich Abramson (1992, 1993b).
heuristic takes input node ordering, shown finding best
node ordering heuristic NP-hard. currently investigating application
meta-heuristics space node orderings find good node ordering
heuristic. preliminary experiments indicate approach highly beneficial,
best node ordering almost never coincides node orderings
consistent given DAGs.
said Section 1, aim combining BNs provided multiple experts (or
learning algorithms) single consensus BN robust individual
BNs. paper, proposed combine experts BNs two steps avoid
problems discussed Pennock Wellman (1999). First, finding consensus BN
structure and, then, finding consensus parameters consensus BN structure.
paper focused first step. currently working second
step along following lines. Let (G1 , 1 ), . . . , (Gm , ) denote BNs provided
experts. first element pair denotes BN structure whereas second denotes
BN parameters. Let p1 , . . . , pm denote probability distributions represented
BNs provided experts. Then, call p0 = f (p1 , . . . , pm ) consensus probability
distribution, f combination function, e.g. weighted arithmetic geometric
mean. Let G denote consensus BN structure obtained G1 , . . . , Gm described
paper. propose obtain consensus BN parameterizing G
p (A|P aG (A)) = p0 (A|P aG (A)) V, p probability distribution
represented consensus BN. motivation parameterization minimizes
Kullback-Leibler divergence p p0 (Koller & Friedman, 2009, Thm. 8.7).
hints speed computation parameterization performing
inference experts BNs found work Pennock Wellman (1999,
Properties 3 4, Section 5). Alternatively, one could first sample p0 and, then,
parameterize G p (A|P aG (A)) = p0 (A|P aG (A)) V, p0
empirical probability distribution obtained sample. Again, motivation
682

fiFinding Consensus Bayesian Network Structures

parameterization minimizes Kullback-Leibler divergence p p0
(Koller & Friedman, 2009, Thm. 17.1) and, course, p0 p0 sample sufficiently
large. Note use p0 parameterize G construct G which, discussed
Section 1, allows us avoid problems discussed Pennock Wellman (1999).
Finally, note present work combines DAGs G1 , . . . , Gm although
guarantee Gi MDI map I(pi ), i.e. Gi may superfluous arcs.
Therefore, one may want check Gi contains superfluous arcs remove
combination takes place. general, several MDI maps I(pi ) may exist,
may differ number parameters associated them. would interesting
study number parameters associated MDI map I(pi ) chosen affects
number parameters associated consensus DAG obtained method
proposed paper.

Acknowledgments
thank anonymous referees editor thorough review manuscript.
thank Dr. Jens D. Nielsen Dag Sonntag proof-reading manuscript.
work funded Center Industrial Information Technology (CENIIT) socalled career contract Linkoping University.

Appendix A. Proofs Lemmas 1-3
Lemma 1. Method A(G, ) Method A2(G, ) return DAG.

Proof. evident Methods A2 transform and, thus, halt
point. prove return DAG. prove result
induction number times Method executes line 6 halting.
evident result holds number executions one, Methods A2
share line 1. Assume induction hypothesis result holds k 1 executions.
prove k executions. Let Z denote nodes involved first
k executions. Since induction hypothesis applies remaining k 1 executions,
run Method summarized

Z G cover reverse Z G
Interchange Z
= 1 n
Percolate right-to-left leftmost node percolated

n number nodes G. Now, assume percolated = j. Note
first j 1 percolations involve nodes left . Thus, run
equivalent
683

fiPena

= 1 j 1
Percolate right-to-left leftmost node percolated
Z G cover reverse Z G
Interchange Z
Percolate right-to-left
Percolate Z right-to-left
= j + 2 n
Percolate right-to-left leftmost node percolated before.
Now, let W denote nodes left Z first k executions
line 6. Note fact Z nodes involved first execution implies
nodes W also left Z . Note also that, Z percolated
latter run above, nodes left Z exactly W {Y }. Since
nodes W {Y } also left Z , percolation Z latter run
perform arc covering reversal node interchange. Thus, latter run
equivalent
= 1 j 1
Percolate right-to-left leftmost node percolated
Percolate Z right-to-left
Percolate right-to-left
= j + 2 n
Percolate right-to-left leftmost node percolated
exactly run Method A2. Consequently, Methods A2 return
DAG.

Lemma 2. Method A2(G, ) Method B(G, ) return DAG.
Proof. prove lemma much way Lemma 1. simply need
replace Z vice versa proof Lemma 1.

Lemma 3. Method B(G, ) Method B2(G, ) return DAG.
Proof. evident Methods B B2 transform and, thus, halt
point. prove return DAG. prove result
induction number times Method B executes line 6 halting.
evident result holds number executions one, Methods B B2
share line 1. Assume induction hypothesis result holds k 1 executions.
prove k executions. Let Z denote nodes involved first
k executions. Since induction hypothesis applies remaining k 1 executions,
run Method B summarized
684

fiFinding Consensus Bayesian Network Structures

Z G cover reverse Z G
Interchange Z
= 1 n
Percolate left-to-right rightmost node percolated
n number nodes G. Now, assume j-th rightmost node
. Note that, 1 < j, i-th rightmost node Wi right
Wi percolated run above. see it, assume contrary Wi
left . implies Wi also left Z , Z
neighbors . However, contradiction Wi would selected
line 2 instead first execution line 6. Thus, first j 1 percolations
run involve nodes right Z . Then, run equivalent
= 1 j 1
Percolate left-to-right rightmost node percolated
Z G cover reverse Z G
Interchange Z
= j n
Percolate left-to-right rightmost node percolated
exactly run Method B2.

References
Chickering, D. M. Transformational Characterization Equivalent Bayesian Network
Structures. Proceedings Eleventh Conference Uncertainty Artificial Intelligence, 87-98, 1995.
Chickering, D. M. Optimal Structure Identification Greedy Search. Journal Machine
Learning Research, 3:507-554, 2002.
Chickering, D. M. & Meek, C. Finding Optimal Bayesian Networks. Proceedings
Eighteenth Conference Uncertainty Artificial Intelligence, 94-102, 2002.
Chickering, D. M., Heckerman, D. & Meek, C. Large-Sample Learning Bayesian Networks
NP-Hard. Journal Machine Learning Research, 5:1287-1330, 2004.
Friedman, N. & Koller, D. Bayesian Network Structure. Bayesian Approach
Structure Discovery Bayesian Networks. Machine Learning, 50:95-12, 2003.
Gavril, F. NP-Complete Problems Graphs. Proceedings Eleventh Conference Information Sciences Systems, 91-95, 1977.
Garey, M. & Johnson, D. Computers Intractability: Guide Theory NPCompleteness. W. H. Freeman, 1979.
685

fiPena

Geiger, D., Verma, T. & Pearl, J. Identifying Independence Bayesian Networks. Networks,
20:507-534, 1990.
Genest, C. & Zidek, J. V. Combining Probability Distributions: Critique Annotated Bibliography. Statistical Science, 1:114-148, 1986.
Hartemink, A. J., Gifford, D. K., Jaakkola, T. S. & Young, R. A. Combining Location
Expression Data Principled Discovery Genetic Regulatory Network Models.
Pacific Symposium Biocomputing 7, 437-449, 2002.
Jackson, B. N., Aluru, S. & Schnable, P. S. Consensus Genetic Maps: Graph Theoretic Approach. Proceedings 2005 IEEE Computational Systems Bioinformatics
Conference, 35-43, 2005.
Koller, D. & Friedman, N. Probabilistic Graphical Models: Principles Techniques. MIT
Press, 2009.
Matzkevich, I. & Abramson, B. Topological Fusion Bayes Nets. Proceedings
Eight Conference Conference Uncertainty Artificial Intelligence, 191-198, 1992.
Matzkevich, I. & Abramson, B. Complexity Considerations Combination
Belief Networks. Proceedings Ninth Conference Conference Uncertainty
Artificial Intelligence, 152-158, 1993a.
Matzkevich, I. & Abramson, B. Deriving Minimal I-Map Belief Network Relative
Target Ordering Nodes. Proceedings Ninth Conference Conference
Uncertainty Artificial Intelligence, 159-165, 1993b.
Maynard-Reid II, P. & Chajewska, U. Agregating Learned Probabilistic Beliefs. Proceedings Seventeenth Conference Uncertainty Artificial Intelligence, 354-361,
2001.
Meek, C. Graphical Models: Selecting Causal Statistical Models. PhD thesis, Carnegie
Mellon Unversity, 1997.
Ng, K.-C. & Abramson, B. Probabilistic Multi-Knowledge-Base Systems. Journal Applied
Intelligence, 4:219-236, 1994.
Nielsen, J. D., Kocka, T. & Pena, J. M. Local Optima Learning Bayesian Networks.
Proceedings Nineteenth Conference Uncertainty Artificial Intelligence,
435-442, 2003.
Nielsen, S. H. & Parsons, S. Application Formal Argumentation: Fusing Bayesian
Networks Multi-Agent Systems. Artificial Intelligence 171:754-775, 2007.
Pearl, J. Probabilistic Reasoning Intelligent Systems: Networks Plausible Inference.
Morgan Kaufmann, 1988.
Pennock, D. M. & Wellman, M. P. Graphical Representations Consensus Belief. Proceedings Fifteenth Conference Uncertainty Artificial Intelligence, 531-540,
1999.
686

fiFinding Consensus Bayesian Network Structures

Pena, J. M., Nilsson, R., Bjorkegren, J. & Tegner, J. Towards Scalable Data Efficient
Learning Markov Boundaries. International Journal Approximate Reasoning, 45:211232, 2007.
Pena, J. M., Kocka, T. & Nielsen, J. D. Featuring Multiple Local Optima Assist User
Interpretation Induced Bayesian Network Models. Proceedings Tenth
International Conference Information Processing Management Uncertainty
Knowledge-Based Systems, 1683-1690, 2004.
Richardson, M. & Domingos, P. Learning Knowledge Multiple Experts. Proceedings Twentieth International Conference Machine Learning, 624-631, 2003.
del Sagrado, J. & Moral, S. Qualitative Combination Bayesian Networks. International
Journal Intelligent Systems, 18:237-249, 2003.
Studeny, M. Bayesian Networks Point View Chain Graphs. Proceedings
Fourteenth Conference Conference Uncertainty Artificial Intelligence, 496-503,
1998.
Studeny, M. & Bouckaert, R. R. Chain Graph Models Description Conditional
Independence Structures. Annals Statistics, 26:1434-1495, 1998.

687

fiJournal Artificial Intelligence Research 42 (2011) 125-180

Submitted 03/11; published 10/11

First-Order Stable Model Semantics
First-Order Loop Formulas
Joohyung Lee
Yunsong Meng

joolee@asu.edu
Yunsong.Meng@asu.edu

School Computing, Informatics,
Decision Systems Engineering
Arizona State University
Tempe, AZ 85287, USA

Abstract
Lin Zhaos theorem loop formulas states propositional case stable
model semantics logic program completely characterized propositional loop
formulas, result fully carry first-order case. investigate
precise relationship first-order stable model semantics first-order loop
formulas, study conditions former represented latter.
order facilitate comparison, extend definition first-order loop formula
limited nondisjunctive program, disjunctive program arbitrary
first-order theory. Based studied relationship extend syntax logic program
explicit quantifiers, allows us reasoning involving non-Herbrand stable
models using first-order reasoners. programs viewed special class firstorder theories stable model semantics, yields succinct loop formulas
general language due restricted syntax.

1. Introduction
According theorem loop formulas (Lin & Zhao, 2004), stable models
logic program (Gelfond & Lifschitz, 1988) characterized models logic
program satisfy loop formulas. idea turned widely applicable
relating stable model semantics propositional logic, resulted efficient
method computing answer sets using SAT solvers. Since original invention loop
formulas nondisjunctive logic programs Lin Zhao (2004), theorem
extended general classes logic programs, disjunctive programs (Lee & Lifschitz, 2003), infinite programs programs containing classical negation (Lee, 2005; Lee,
Lierler, Lifschitz, & Yang, 2010), arbitrary propositional formulas stable model
semantics (Ferraris, Lee, & Lifschitz, 2006), programs containing aggregates (Liu &
Truszczynski, 2006; & Liu, 2008). theorem also applied nonmonotonic formalisms, nonmonotonic causal theories (Lee, 2004) McCarthys
circumscription (Lee & Lin, 2006). notion loop refined elementary loop (Gebser & Schaub, 2005; Gebser, Lee, & Lierler, 2006, 2011). However,
work restricted propositional case. Variables contained program
first eliminated groundingthe process replaces every variable every object
constantand loop formulas obtained ground program. result, loop
formulas defined formulas propositional logic.
c
2011
AI Access Foundation. rights reserved.

fiLee & Meng

Chen, Lin, Wang, Zhangs definition (2006) first-order loop formula different
loop formulas directly obtained non-ground program,
first-order logic formulas retain variables. However, since semantics logic
program refer based grounding, first-order loop formulas simply
understood schemas ground loop formulas, Herbrand models loop
formulas considered context.
stable model semantics involve grounding appeared year later
(Ferraris, Lee, & Lifschitz, 2007, 2011). authors define stable models firstorder sentence F models second-order sentence obtained applying
stable model operator SM F . definition SM close definition
circumscription operator CIRC (McCarthy, 1980, 1986). first-order stable model
semantics, logic programs viewed special class first-order theories. similar
definition stable model given Lin Zhou (2011), via logic knowledge
justified assumption (Lin & Shoham, 1992). first-order stable model semantics
also closely related quantified equilibrium logic (Pearce & Valverde, 2005), indeed,
Ferraris et al. (2011) showed essentially equivalent.
natural question arising first-order loop formulas first-order stable
model semantics related other. general, first-order stable model semantics
expressive first-order logic, cannot completely characterized
first-order loop formulas. Like circumscription, concept transitive closure
represented first-order stable model semantics, set first-order
formulas, even set allowed infinite.1 However, show paper,
understanding precise relationship gives us insights first-order
stable model semantics computational properties.
order facilitate comparison, extend definition first-order loop
formula limited nondisjunctive programs, disjunctive programs
arbitrary first-order theories. Also present reformulation SM[F ] style loop
formulas, includes characterization loop syntactic formula.
formulation, derive several conditions, first-order theory stable
model semantics equivalently rewritten first-order loop formulas.
Based relationship first-order stable model semantics first-order
loop formulas, extend syntax logic programs explicit quantifiers, may
useful overcoming limitations traditional answer set programs reasoning
non-Herbrand models. define semantics extended programs identifying
special class first-order theories stable model semantics.
programs inherit general language ability handle nonmonotonic reasoning
stable model semantics even absence unique name domain
closure assumptions built grounding-based answer set semantics.
hand, restricted syntax extended program leads succinct loop
formulas. following program 1 simple insurance policy example represented

1. Vladimir Lifschitz, personal communication.

126

fiFirst-Order Stable Model Semantics First-Order Loop Formulas

syntax.
HasWife(x)
HasWife(x)
Married (x)
w Discount(x, w)






Spouse(x, y)
Man(x), Married (x)
Man(x), HasWife(x)
Married (x), z Accident(x, z).

second third rules express Married (x) HasWife(x) synonymous
x Man. last rule states x eligible discount
plan (with name unknown) x married record accident. quantifier
first rule dropped without affecting meaning, quantifiers
cannot. say program entails query F (under stable model semantics)
every stable model satisfies F . example,
1 conjoined 2 = {Man(John)} entails x Married (x)
xy Discount(x, y).
1 2 conjoined 3 = {y Spouse(John, y)} entails neither x Married (x)
xy Discount(x, y), entails x Married (x), xyDiscount(x, y),
xy(Discount(x, y) x = John).
1 2 3 conjoined 4 = {z Accident(John, z)} entail
xy(Discount(x, y) x = John), entails w Discount(John, w).
nonmonotonic reasoning kind requires non-Herbrand models since names
(or identifiers) discount plans, spouses accident records may unknown. However,
traditional answer set semantics limited Herbrand models due reference
grounding. turning program first-order loop formulas automate
example reasoning using first-order theorem prover.
paper organized follows. next section reviews first-order stable model
semantics Ferraris et al. (2007, 2011). Section 3 reviews theorem first-order loop
formulas Chen et al. (2006) extends disjunctive programs arbitrary
first-order sentences, limiting attention Herbrand stable models. Section 4 extends
results allow non-Herbrand stable models well (possibly allowing functions)
certain semantic condition, compare first-order stable model semantics loop
formulas reformulating former terms latter. Section 5, present series
syntactic conditions imply semantic condition Section 4. Section 6 provides
extension logic programs contain explicit quantifiers shows query answering
extended programs sometimes reduced entailment checking first-order
logic via loop formulas. Section 7, results extended distinguish
intensional non-intensional predicates. Related work described Section 8, long
proofs given Appendix A.
article extended version conference paper Lee Meng (2008).

2. Review First-Order Stable Model Semantics
review follows journal paper Ferraris et al. (2011) extends conference
paper authors (Ferraris et al., 2007) distinguishing intensional
non-intensional predicates.
127

fiLee & Meng

formula defined first-order logic. signature consists function
constants predicate constants. Function constants arity 0 called object constants.
assume following set primitive propositional connectives quantifiers:
(falsity), , , , , .
F abbreviation F , symbol > stands , F G stands
(F G) (G F ). distinguish atoms atomic formulas follows:
atom signature n-ary predicate constant followed list n terms
formed function constants (including object constants) object
variables; atomic formulas atoms , equalities terms ,
0-place connective .
stable models F relative list predicates p = (p1 , . . . , pn ) defined via
stable model operator intensional predicates p, denoted SM[F ; p].2 Let u
list distinct predicate variables u1 , . . . , un length p. u = p
denote conjunction formulas x(ui (x) pi (x)), x list distinct object
variables length arity pi , = 1, . . . , n. u p denote
conjunction formulas x(ui (x) pi (x)) = 1, . . . , n, u < p stands
(u p) (u = p). first-order sentence F , expression SM[F ; p] stands
second-order sentence
F u((u < p) F (u)),
(1)
F (u) defined recursively:
pi (t) = ui (t) list terms;
F = F atomic formula F (including equality) contain
members p;
(F G) = F G ;
(F G) = F G ;
(F G) = (F G ) (F G);
(xF ) = xF ;
(xF ) = xF .
(There clause negation here, treat F shorthand F .)
model sentence F (in sense first-order logic) called p-stable satisfies
SM[F ; p]. often simply write SM[F ] instead SM[F ; p] p list
predicate constants occurring F , call model SM[F ] simply stable model F .
distinguish terms stable models answer sets follows.3 (F )
denote signature consisting function predicate constants occurring F .
2. intensional predicates p predicates intend characterize F .
3. distinction useful first-order setting, stable models longer Herbrand interpretations may represented sets atoms.

128

fiFirst-Order Stable Model Semantics First-Order Loop Formulas

F contains least one object constant, Herbrand interpretation4 (F ) satisfies
SM[F ] called answer set F . answer sets logic program defined
answer sets FOL-representation (i.e., conjunction universal closures
implications corresponding rules).
Example 1 program contains three rules
p(a)
q(b)
r(x) p(x), q(x)
FOL-representation F
p(a) q(b) x((p(x) q(x)) r(x))

(2)

SM[F ]
p(a) q(b) x((p(x) q(x)) r(x))
uvw(((u, v, w) < (p, q, r)) u(a) v(b)
x(((u(x) (v(x) q(x))) w(x)) ((p(x) q(x)) r(x)))),
equivalent first-order sentence
x(p(x) x = a) x(q(x) x = b) x(r(x) (p(x) q(x)))

(3)

(See Example 3 work Ferraris et al., 2007). stable models F firstorder models (3). answer set F Herbrand model {p(a), q(b), r(a)}.

3. First-Order Loop Formulas Herbrand Models
review definition first-order loop formula nondisjunctive program given
Chen et al. (2006) extend disjunctive program arbitrary first-order
sentence.
3.1 Review First-Order Loop Formulas Defined Chen et al. (2006)
call formula negative every occurrence every predicate constant belongs
antecedent implication. instance, formula form F negative
expression shorthand F . equality t1 = t2 also negative
contains predicate constants.
nondisjunctive program finite set rules form
B, N,

(4)

4. Recall Herbrand interpretation signature (containing least one object constant)
interpretation universe set ground terms , every ground term
represents itself. Herbrand interpretation identified set ground atoms
assigns value true.

129

fiLee & Meng

atom, B set atoms, N negative formula. rules may
contain function constants positive arity.5
say nondisjunctive program normal form if, rules (4) it,
form p(x) x list distinct variables. clear every program
turned normal form using equality body. instance, p(a, b) q(a)
rewritten p(x, y) x = a, = b, q(a).
Let nondisjunctive program let Norm() normal form . ()
denote signature consisting function predicate constants occurring . Given
finite set atoms, assume Norm() contain variables , renaming
variables Norm(). (first-order) external support formula , denoted
ES (Y ), disjunction
_


z B N

:AY

^

0

(t 6= )


(5)

p(t)B
p(t0 )Y

rules (4) Norm(),6 substitution maps variables terms
occurring , z list variables occur
B, N
.
(first-order) loop formula , denoted LF (Y ), universal closure

^
ES (Y ).
(6)
V
(The expression antecedent stands conjunction elements .)
propositional program, LF (Y ) equivalent conjunctive loop formula
defined Ferraris et al. (2006).
definition first-order dependency graph definition first-order loop
follows. say atom p(t) depends atom q(t0 ) rule (4) p(t)
q(t0 ) B. (first-order) dependency graph infinite directed graph
(V, E)
V set atoms signature ();7
(p(t), q(t0 )) E p(t) depends q(t0 ) rule substitution
maps variables t0 terms (including variables) ().
nonempty subset L V called (first-order) loop subgraph
first-order dependency graph induced L strongly connected.

5. original definition Chen et al. (2006) allow function constants positive arity.
6. lists terms = (t1 , . . . , tn ) t0 = (t01 , . . . , t0n ) length, = t0 stands
(t1 = t01 ) (tn = t0n ).
7. Note V infinite since infinitely many object variables used form atoms.

130

fiFirst-Order Stable Model Semantics First-Order Loop Formulas

Example 2 Let following program:
p(x) q(x)
q(y) p(y)
p(z) r(z).

(7)

following sets atoms first-order loops (among many others): Y1 = {p(u)}, Y2 =
{q(u)}, Y3 = {r(u)}, Y4 = {p(u), q(u)}. loop formulas
LF (Y1 )
LF (Y2 )
LF (Y3 )
LF (Y4 )

=
=
=
=

u(p(u) (q(u) r(u))),
u(q(u) p(u)),
u(r(u) ),
u(p(u) q(u) (q(u) u 6= u) (p(u) u 6= u) r(u)).

Example 3 Let one-rule program
p(x) p(y).

(8)

finite first-order loops Yk = {p(x1 ), . . . , p(xk )} k > 0. Formula LF (Yk )


(9)
x1 . . . xk p(x1 ) . . . p(xk ) y(p(y) (y 6= x1 ) . . . (y 6= xk )) .
following reformulation Theorem 1 work Chen et al. (2006).
Theorem 1 Let nondisjunctive program contains least one object constant
function constants positive arity, let Herbrand interpretation ()
satisfies .8 following conditions equivalent other:
(a) stable model ;
(b) every nonempty finite set atoms (), satisfies LF (Y );

9

(c) every finite first-order loop , satisfies LF (Y ).
sets first-order loop formulas considered conditions (b) (c)
obvious redundancies. instance, loop formula {p(x)} equivalent loop
formula {p(y)}; loop formula {p(x), p(y)} entails loop formula {p(z)}. Following definition Chen et al. (2006), given two sets atoms Y1 Y2 , say
Y1 subsumes Y2 substitution maps variables Y1 terms
Y1 = Y2 .
Proposition 1 (Chen et al., 2006, Proposition 7) nondisjunctive program
loops Y1 Y2 , Y1 subsumes Y2 , LF (Y1 ) entails LF (Y2 ).
Therefore condition (c) Theorem 1, sufficient consider set loops
that, every loop L , loop L0 subsumes L. Chen et al. (2006)
called complete set loops. Example 2, set {Y1 , Y2 , Y3 , Y4 } finite complete
set loops program (7). Program (8) Example 3 finite complete set loops.
8. say satisfies satisfies FOL-representation .
9. Note may contain variables.

131

fiLee & Meng

3.2 Extension Disjunctive Programs
disjunctive program finite set rules form
B, N,

(10)

B sets atoms, N negative formula. Similar nondisjunctive
program, say disjunctive program normal form if, rules (10) it,
atoms form p(x) x list distinct variables.
Let disjunctive program let Norm() normal form . Given finite
set atoms, first rename variables Norm() variables Norm()
occur . (first-order) external support formula , denoted ES (Y ),
disjunction

_
^
_
^

z B N
(t 6= t0 )
p(t)
6= t0
(11)
:AY 6=

p(t)B
p(t0 )Y

p(t)A

p(t0 )Y

rules (10) Norm(), substitution maps variables terms
occurring themselves, z list variables occur
B, N
. (first-order) loop formula , denoted LF (Y ), universal
closure
^
ES (Y ).
Clearly, (11) equivalent (5) nondisjunctive. propositional,
LF (Y ) equivalent conjunctive loop formula disjunctive program defined
Ferraris et al. (2006).
Example 4 Let program
p(x, y) ; p(y, z) q(x)
let = {p(u, v)}. Formula LF (Y ) universal closure
p(u, v) z(q(u) (p(v, z) ((v, z) 6= (u, v))))
x(q(x) (p(x, u) ((x, u) 6= (u, v)))).
Similar nondisjunctive case, say p(t) depends q(t0 )
rule (10) p(t) q(t0 ) B. definitions first-order
dependency graph first-order loop extended disjunctive programs straightforward way. Using extended notions, following theorem extends Theorem 1
disjunctive program. also generalization main theorem Ferraris et al.
(2006) restricted propositional disjunctive program.
Theorem 1 Let disjunctive program contains least one object constant
function constants positive arity, let Herbrand interpretation ()
satisfies . following conditions equivalent other:
132

fiFirst-Order Stable Model Semantics First-Order Loop Formulas

(a) stable model ;
(b) every nonempty finite set atoms (), satisfies LF (Y );
(c) every finite first-order loop , satisfies LF (Y ).

3.3 Extension Arbitrary Sentences
section extend definition first-order loop formula arbitrary firstorder sentence.
propositional loop formula defined arbitrary propositional theory (Ferraris et al., 2006), convenient introduce formula whose negation close ES .
define formula NES F (Y ) (Negation (First-order) External Support Formula), F
first-order formula finite set atoms, follows. assume
variables occur F , renaming variables.
NES pi (t) (Y ) = pi (t)

V

pi (t0 )Y

6= t0 ;

NES t1 =t2 (Y ) = (t1 = t2 );
NES (Y ) = ;
NES F G (Y ) = NES F (Y ) NES G (Y );
NES F G (Y ) = NES F (Y ) NES G (Y );
NES F G (Y ) = (NES F (Y ) NES G (Y )) (F G);
NES xG (Y ) = xNES G (Y );
NES xG (Y ) = xNES G (Y ).
(first-order) loop formula F , denoted LF F (Y ), universal closure

^

NES F (Y ).

(12)

Note definition NES looks similar definition F given Section 2.
F propositional, LF F (Y ) equivalent conjunctive loop formula
propositional formula defined Ferraris et al. (2006). following lemma tells
us definition loop formula section generalizes definition loop
formula disjunctive program previous section.
Lemma 1 Let disjunctive program normal form, F FOL-representation
, finite set atoms. Formula NES F (Y ) equivalent ES (Y )
assumption F .
133

fiLee & Meng

order extend first-order dependency graph arbitrary formula, introduce
notions. say occurrence subformula G formula F positive
number implications F containing occurrence antecedent even;
strictly positive number 0. rule first-order formula F implication
occurs strictly positively F . say formula rectified variables
bound free, quantifiers formula refer different variables.
formula easily rewritten rectified formula renaming bound variables.
say atom p(t) depends atom q(t0 ) implication G H
p(t) strictly positive occurrence H,
q(t0 ) positive occurrence G belong negative subformula
G.10
definition first-order dependency graph extended formulas follows.
(first-order) dependency graph rectified formula F infinite directed graph (V, E)

V set atoms signature (F );
(p(t), q(t0 )) E p(t) depends q(t0 ) rule F substitution
maps variables t0 terms (F ).
Note rectified formula assumption required order distinguish
dependency graphs formulas
x(p(x) q(x))

x p(x) x q(x).
definition dependency graph given, loop first-order formula
defined way disjunctive program. Theorem 1 extended
first-order sentences using extended notions.

Theorem 1 f Let F rectified sentence contains least one object constant
function constants positive arity, let Herbrand interpretation (F )
satisfies F . following conditions equivalent other:
(a) stable model F (i.e., satisfies SM[F ]);
(b) every nonempty finite set atoms (F ), satisfies LF F (Y );
(c) every finite first-order loop F , satisfies LF F (Y ).
Example 2 (continued) Consider FOL-representation F program Example 2,
{Y1 , Y2 , Y3 , Y4 } complete set loops. assumption F ,
10. Recall definition negative formula Section 3.1.

134

fiFirst-Order Stable Model Semantics First-Order Loop Formulas

LF F (Y1 ) equivalent universal closure

p(u) x(q(x) p(x) x 6= u) y(p(y) 6= u q(y))

z(r(z) p(z) z 6= u) ;
LF F (Y2 ) equivalent universal closure


q(u) x(q(x) x 6= u p(x)) y(p(y) q(y) 6= u) ;
LF F (Y3 ) equivalent universal closure
r(u) ;
LF F (Y4 ) equivalent universal closure

p(u) q(u) x(q(x) x 6= u p(x) x 6= u)

y(p(y) 6= u q(y) 6= u) z(r(z) p(z) z 6= u) .

Proposition 1 straightforwardly extended arbitrary sentences even without
restricting attention loops.
Proposition 1 f sentence F nonempty finite sets atoms Y1 Y2
(F ), Y1 subsumes Y2 , LF F (Y1 ) entails LF F (Y2 ).
Proof. Note LF F (Y1 )
z

^


Y1 NES F (Y1 ) ,

(13)

z set variables Y1 . Y1 subsumes Y2 , definition,
substitution variables Y1 terms Y2 Y1 = Y2 . clear (13)
entails
^

z0
Y1 NES F (Y1 ) ,
(14)
z0 set variables Y1 . (14) exactly LF F (Y2 ).



Theorem 2 work Ferraris et al. (2006) special case Theorem 1f
F restricted propositional formula.
Corollary 1 (Ferraris et al., 2006, Thm. 2) propositional formula F , following
formulas equivalent assumption F .
(a) SM[F ];
(b) conjunction LF F (Y ) nonempty sets atoms occurring F ;
(c) conjunction LF F (Y ) (ground) loops F .
135

fiLee & Meng

4. Comparing First-Order Stable Model Semantics First-Order Loop
Formulas
theorems previous section restricted Herbrand stable models.
section extends results allow non-Herbrand stable models well, compare
idea loop formulas SM reformulating latter style loop formulas.
4.1 Loop Formulas Relative Interpretation
Recall Theorem 1 extensions allow function constants positive arity
limited Herbrand models particular signature obtained given
theory. Indeed, statements become wrong conditions dropped.
Example 5 following program contains unary function constant f .
p(a)
p(x) p(f (x)).
loops program singleton sets atoms, loop formulas satisfied
Herbrand model {p(a), p(f (a)), p(f (f (a))), . . . } program, model
stable.

Example 3 (continued) mismatch happen even absence function constants positive arity. Consider program Example 3 interpretation
universe set integers, pI contains integers. Interpretation
satisfies first-order loop formulas (9), stable model.
examples suggest mismatch first-order stable model semantics first-order loop formulas related presence infinite path
dependency graph visits infinitely many vertices. following make
idea precise, extend Theorem 1f allow non-Herbrand interpretations
certain condition.
First, define dependency graph relative interpretation. Let F rectified
formula whose signature let interpretation . element
universe |I| I, introduce new symbol , called object name. denote
signature obtained adding object names additional object constants.
identify interpretation signature extension defined I( ) =
(For details, see work Lifschitz, Morgenstern, & Plaisted, 2008).
dependency graph F w.r.t. directed graph (V, E)
V set atoms form pi ( ) pi belongs (F ) list
object names |I|,
(pi ( ), pj ( )) E atoms pi (t), pj (t0 ) pi (t) depends pj (t0 )
rule F substitution maps variables t0 object
names (t)I = (t0 )I = .
136

fiFirst-Order Stable Model Semantics First-Order Loop Formulas

call nonempty subset L V loop F w.r.t. subgraph dependency
graph F w.r.t. induced L strongly connected. say F bounded
w.r.t. every infinite path dependency graph F w.r.t. whose vertices
satisfied visits finitely many vertices. F bounded w.r.t. I, then, clearly, every
loop L F w.r.t. |= L finite. definition extended non-rectified
formula first rewriting rectified formula. also applies program syntax
referring FOL-representation.
Theorem 2 Let F rectified sentence signature (possibly containing function
constants positive arity), let interpretation satisfies F . F
bounded w.r.t. I, following conditions equivalent other:
(a) |= SM[F ];
(b) every nonempty finite set atoms formed predicate constants (F )
object names |I|, satisfies LF F (Y );
(c) every finite loop F w.r.t. I, satisfies LF F (Y ).
condition F bounded w.r.t. sufficient ensuring equivalence among
(a), (b), (c), necessary condition. instance, consider F
x p(x) xy(p(x) p(y))
model F whose universe infinite. Formula F bounded w.r.t. I,
satisfies every loop formula, well SM[F ].
Herbrand model (F ), dependency graph F w.r.t. isomorphic subgraph first-order dependency graph F induced vertices
containing ground atoms. set ground atoms (F ) loop F iff loop F
w.r.t. I. Hence Theorem 2 essentially generalization Theorem 1f .
Note programs considered Examples 3 5 bounded w.r.t.
interpretations considered there.
Clearly, universe finite, F bounded w.r.t. I. fact leads
following corollary.
Corollary 2 rectified sentence F model F whose universe finite,
conditions (a), (b), (c) Theorem 2 equivalent other.
view Proposition 1f Corollary 2, size universe known
finite number n, sufficient consider 2|p| 1 loop formulas, p
set predicate constants
occurring sentence. loop formula check

external support pK {p(x1 ), . . . , p(xnr )} K
K nonempty subset p;
r arity p xi list variables length r variables
x1 , . . . , xnr pairwise distinct.
137

fiLee & Meng

instance, consider program (8). size universe known 3, sufficient
consider one loop formula (9) k = 3.
Theorem 1f essentially follows Corollary 2 Herbrand universe (F )
finite F contains function constants positive arity.
Another corollary Theorem 2 acquired F trivial loops. say
formula F atomic-tight w.r.t. every path dependency graph F w.r.t.
whose vertices satisfied finite. Clearly, special case boundedness
condition, every loop L atomic-tight formula F w.r.t. |= L
singleton. following corollary Theorem 2, tells us condition
stable models characterized loop formulas singleton loops only.
SLF[F ] (loop formulas singletons) denote
{LF F ({p(x)}) | p predicate constant (F ), x list
distinct object variables whose length arity p}.

(15)

Corollary 3 Let F rectified sentence (possibly containing function constants positive
arity), let model F . F atomic-tight w.r.t. I, satisfies SM[F ] iff
satisfies SLF[F ].
SLF[F ] similar Clarks completion. propositional case, relationship
loop formulas singletons completion studied Lee (2005).
describe relationship first-order case. sentence F Clark normal form
(Ferraris et al., 2011) conjunction formulas form
x(G p(x)),

(16)

one predicate constant p occurring F , x list distinct variables,
G free variables x. completion sentence F Clark normal form,
denoted Comp[F ], obtained F replacing conjunctive term (16)
x(p(x) G).
nondisjunctive program turned Clark normal form (Ferraris et al., 2011,
Section 6.1).
Corollary 4 Let F FOL-representation nondisjunctive program , let F 0
Clark normal form F obtained process described work Ferraris
et al. (2011, Section 6.1). F atomic-tight w.r.t. interpretation I, |= SM[F ]
iff |= Comp[F 0 ].
Proof. Since F atomic-tight w.r.t. I, Corollary 3, |= SM[F ] iff |= F SLF[F ].
sufficient show that, predicate constant p occurring F , assumption
F atomic-tight w.r.t. I,


_
^

|= x p(x)
z (x = t0 ) B N
(t 6= x)
(17)
p(t0 )B,N

p(t)B

138

fiFirst-Order Stable Model Semantics First-Order Loop Formulas

iff




z (x = ) B N ,

_

|= x p(x)

0



(18)

p(t0 )B,N

z list free variables p(x) (x = t0 ), B, N x.
Note (17) equivalent saying


^
_

0
0
(t 6= ) .
z (x = ) B N
|= x p(x)
p(t0 )B,N

(19)

p(t)B

assumption F atomic-tight w.r.t. I, follows that, rule p(t0 )
B, N atom p(t) B, |= y(t 6= t0 ), list variables
t0 (otherwise find singleton loop self-cycle, contradicts F
atomic tight w.r.t. I). Consequently, (19) equivalent (18).

example, let F FOL-representation program
p(b) p(a)
6= b

(20)

SLF[p(a) p(b)] x(p(x) x = b p(a) x 6= a), Comp[x(x = b p(a) p(x))]
x(p(x) x = b p(a)). additional conjunctive term x 6= dropped
consider model F , aI 6= bI .
Corollary 4 enhancement Theorem 11 work Ferraris et al. (2011),
states equivalence SM[F ] Comp[F ] tight sentence F Clark
normal form. (Tight sentences defined similar way, terms predicate
dependency graph, whose vertices predicate constants instead atoms.) Every tight
sentence atomic-tight w.r.t. model sentence. hand, program (20)
atomic-tight w.r.t. model program, tight.
Theorem 2 tells us one limitations first-order loop formulas that, even
infinitely many first-order loop formulas considered, cannot ensure external
support certain infinite set forms infinite path dependency graph F
w.r.t. I. next section, reformulating SM[F ], show definition SM[F ]
essentially encompasses loop formulas, ensuring external support sets atoms,
including difficult infinite sets.
4.2 Reformulation SM
before, let F first-order formula signature , let p = (p1 , . . . , pn ) list
predicate constants occurring F , let u v lists predicate variables
length p. define NSES F (u) (Negation Second-Order External Support
Formula) recursively follows.
NSES pi (t) (u) = pi (t) ui (t);
NSES t1 =t2 (u) = (t1 = t2 );
NSES (u) = ;
139

fiLee & Meng

NSES F G (u) = NSES F (u) NSES G (u);
NSES F G (u) = NSES F (u) NSES G (u);
NSES F G (u) = (NSES F (u) NSES G (u)) (F G);
NSES xF (u) = xNSES F (u);
NSES xF (u) = xNSES F (u).
Lemma 2 Let F rectified sentence signature , interpretation , p
list predicate constants occurring F , q list predicate names 11 length
p set atoms formed predicate constants (F ) object names

pi ( ) iff |= qi ( ),
list object names. finite,
|= NSES F (q) iff |= NES F (Y ).
Proof. induction F . list case F atom. cases
straightforward. Let F atom pi ( ).
iff
iff
iff
iff
iff

|= NSES F (q)
|= pi ( ) qi ( )
|= pi ( ) pi ( )
/Y
p ( ) Y, holds 6=
|= pi ( )




V
|= pi ( ) pi ( )Y 6=
|= NES F (Y ).


SM[F ] written terms NSES follows. Nonempty(u) denote
formula
x1 u1 (x1 ) xn un (xn ),
xi list distinct variables whose length arity pi .
Proposition 2 sentence F , SM[F ] equivalent
F u((u p) Nonempty(u) NSES F (u)).

(21)

represent notion loop second-order formula. Given rectified
formula F , EF (v, u) denote
_
z(vi (t) uj (t0 ) vj (t0 )),
(pi (t),pj (t0 )) :
pi (t) depends pj (t0 ) rule F

11. Like object names, every n > 0, subset |I|n name, n-ary predicate constant
underlying signature.

140

fiFirst-Order Stable Model Semantics First-Order Loop Formulas

z list object variables t0 . Loop F (u) denote second-order
formula
Nonempty(u) v((v < u) Nonempty(v) EF (v, u)).
(22)
Formula (22) represents concept loop without referring notion dependency
graph explicitly. based following observation. Consider finite propositional
program . nonempty set U atoms occur loop iff, every
nonempty proper subset V U , edge atom V atom U \ V
dependency graph (Gebser et al., 2006).
Recall definition dependency graph relative interpretation. Let F
rectified sentence signature , let interpretation . following
proposition describes relationship formula (22) loop F w.r.t. I.
Proposition 3 Let q list predicate names corresponding p, let set
atoms dependency graph F w.r.t.
pi ( ) iff |= qi ( ),
list object names. |= Loop F (q) iff loop F w.r.t. I.
One might expect that, similar equivalence conditions (a) (c)
Theorem 2, formula SM[F ] equivalent following formula:
F u((u p) Loop F (u) NSES F (u)).

(23)

However, equivalence hold general, following example illustrates.
Example 6 Consider FOL-representation F following program
p(x, y) q(x, z)
q(x, z) p(y, z),
interpretation whose universe set nonnegative integers
pI = {(m, m) | nonnegative integer},
q = {(m, m+1) | nonnegative integer}.
Formula F bounded w.r.t. since dependency graph F w.r.t. contains
infinite path
hp(0 , 0 ), q(0 , 1 ), p(1 , 1 ), q(1 , 2 ), . . .i.

(24)

interpretation satisfies every loop formula every finite loop F w.r.t. I,
stable model.
example, distinguishes set
{p(0 , 0 ), q(0 , 1 ), p(1 , 1 ), q(1 , 2 ), . . . }

(25)

loop that, every loop contained (25), outgoing edge dependency graph. instance call unbounded set. Given dependency
graph F w.r.t. I, say nonempty set vertices unbounded w.r.t. if,
every subset Z loop, edge vertex Z vertex \ Z.
following proposition tells us unbounded set characterized
second-order formula.
141

fiLee & Meng

Proposition 4 Let q list predicate names corresponding p, let set
atoms dependency graph F w.r.t.
pi ( ) iff |= qi ( ),
list object names.
|= Nonempty(q) v((v q) Loop F (v) EF (v, q))
iff unbounded set F w.r.t. I.
order check stability model, need check external support every
loop every unbounded set. extended loop F w.r.t. loop unbounded
set F w.r.t. I. define Ext-Loop F (u)
Loop F (u) (Nonempty(u) v((v u) Loop F (v) EF (v, u))).

(26)

Propositions 3 4, follows |= Ext-Loop F (q) iff extended loop
F w.r.t. I.
replace Loop F (u) Ext-Loop F (u) (23), formula equivalent SM[F ],
following theorem states.
Theorem 3 rectified sentence F , following sentences equivalent
other:
(a) SM[F ];
(b) F u((u p) Nonempty(u) NSES F (u));
(c) F u((u p) Ext-Loop F (u) NSES F (u)).
following example use following fact simplify formulas.
Proposition 5 negative formula F , formula
NSES F (u) F
logically valid.
Example 2 (continued) Consider program (7) Example 2:
p(x) q(x)
q(y) p(y)
p(z) r(z).
Let F FOL-representation program:



x q(x) p(x) p(y) q(y) z r(z) p(z) .
142

fiFirst-Order Stable Model Semantics First-Order Loop Formulas

1. SM[F ] equivalent
F u1 u2 u3 ((u1 , u2 , u3 ) < (p, q, r))
x(u2 (x) u1 (x)) y(u1 (y) u2 (y)) z(r(z) u1 (z))).
2. Formula Theorem 3 (b):
F u(u p Nonempty(u) NSES F (u))
equivalent
F u1 u2 u3 ((u1 , u2 , u3 ) (p, q, r) (x u1 (x) x u2 (x) x u3 (x))
(x[q(x) u2 (x) p(x) u1 (x)]
y[p(y) u1 (y) q(y) u2 (y)]
z[r(z) p(z) u1 (z)])).

(27)

3. Formula Theorem 3 (c): Similar (27) except
x u1 (x) x u2 (x) x u3 (x)
(27) replaced Ext-Loop F (u),
Loop F (u) [(x u1 (x) x u2 (x) x u3 (x))
v1 v2 v3 (((v1 , v2 , v3 ) (u1 , u2 , u3 )) Loop F (v)
(x(v1 (x) u2 (x) v2 (x)) y(v2 (y) u1 (y) v1 (y))))],
Loop F (u)
(x u1 (x) x u2 (x) x u3 (x))
v1 v2 v3 (((x v1 (x) x v2 (x) x v3 (x)) (v1 , v2 , v3 ) < (u1 , u2 , u3 ))
(x(v1 (x) u2 (x) v2 (x)) y(v2 (y) u1 (y) v1 (y)))).
proof Theorem 2 follows Theorem 3 using following lemma.
Lemma 3 Let F rectified sentence signature (possibly containing function constants positive arity), let interpretation satisfies F . F bounded
w.r.t. I,
|= u(u p Ext-Loop F (u) NSES F (u))
iff finite loop F w.r.t.
^

|=
NES F (Y ) .

5. Representing First-Order Stable Model Semantics First-Order
Loop Formulas
noted previous section sentence bounded w.r.t. model, loop
formulas used check stability model. section, provide
syntactic counterparts boundedness condition.
143

fiLee & Meng

5.1 Bounded Formulas
say rectified formula F bounded every infinite path first-order dependency graph F visits finitely many vertices. F bounded, then, clearly, every loop
F finite. Again, definition extended non-rectified formula first rewriting
rectified formula. also applies program referring FOL-representation.
One might wonder syntactic notion boundedness ensures semantic notion
boundedness: is, formula bounded, bounded w.r.t. interpretation.
However, following example tells us case general.
Example 7 Consider FOL-representation F following program
p(a) q(x)
q(x) p(b),

(28)

interpretation whose universe |I| set nonnegative integers, aI = bI = 0,
pI = {0} q = |I|. Formula (28) bounded according definition,
bounded w.r.t. I: dependency graph F w.r.t. contains infinite path
hp(0 ), q(1 ), p(0 ), q(2 ), . . . i.
5.1.1 Bounded Formulas Clarks Equational Theory
hand, relationship holds interpretation satisfies Clarks equational
theory (1978). Clarks equational theory signature , denoted CET , union
universal closures following formulas
f (x1 , . . . , xm ) 6= g(y1 , . . . , yn ),

(29)

pairs distinct function constants f , g,
f (x1 , . . . , xn ) = f (y1 , . . . , yn ) (x1 = y1 . . . xn = yn ),

(30)

function constants f arity > 0,
6= x,

(31)

term contains variable x.
Proposition 6 rectified formula F signature bounded, F bounded
w.r.t. interpretation satisfies CET .
following lemma relates loops loop formulas different notions dependency
graphs.
Proposition 7 rectified sentence F signature interpretation
satisfies CET , model
{LF F (Y ) | finite first-order loop F }
iff model
{LF F (Y ) | finite loop F w.r.t. I}.
144

fiFirst-Order Stable Model Semantics First-Order Loop Formulas

following theorem follows Theorem 2, Proposition 6 Proposition 7.
Theorem 4 Let F rectified sentence signature (possibly containing function
constants positive arity), let interpretation satisfies F CET .
F bounded, following conditions equivalent other:
(a) |= SM[F ];
(b) every nonempty finite set atoms (F ), satisfies LF F (Y );
(c) every finite first-order loop F , satisfies LF F (Y ).
Proof. Proposition 6, F bounded F bounded w.r.t. interpretation
satisfies CET . equivalence (a) (b) follows equivalence
(a) (b) Theorem 2. equivalence (a) (c) follows
equivalence (a) (c) Theorem 2 Proposition 7.

every Herbrand interpretation satisfies CET , Theorem 4 applies Herbrand
interpretations special case.
theorem also applies logic programs, since viewed special case
formulas. example, consider following program, bounded.
p(f (x)) q(x)
q(x) p(x), r(x)
p(a)
r(a)
r(f (a)).

(32)

set {p(a), p(f (a)), p(f (f (a))), q(a), q(f (a)), r(a), r(f (a))} answer set (32).
accordance Theorem 4, also Herbrand interpretation signature obtained
program satisfies FOL-representation (32) loop formulas,
universal closures
p(z) (q(x) z = f (x)) z =
q(z) p(z) r(z)
r(z) z = z = f (a).
Consider another example program Bonatti (2004), a, . . . , z, nil object
constants.
letter (a)
...
letter (z)
(33)
atomic([x]) letter (x)
atomic([x|y]) letter (x), atomic(y).
expression [x|y] list whose head x whose tail y, stands function
cons(x, y). expression [x] stands cons(x, nil) nil special symbol
145

fiLee & Meng

empty list. program bounded. answer set program
Herbrand interpretation FOL-representation (33) universal closures
letter (u) u = . . . u = z
atomic(u) v (letter (v) u = cons(v, nil))
xy (letter (x) atomic(y) 6= u u = cons(x, y)).
fact, definitions standard list processing predicates, member, append,
reverse (Bonatti, 2004, Figure 1) bounded, represented first-order
formulas Herbrand interpretations.12
say formula F atomic-tight first-order dependency graph F
infinite paths. Every tight sentence atomic-tight, vice versa. example,
FOL-representations programs (32) (33) atomic-tight, tight. Similar
Proposition 6, F atomic-tight, F atomic-tight w.r.t. interpretation
satisfies CET , following statement derived Corollary 3.
Corollary 5 Let F rectified sentence signature (possibly containing function
constants positive arity), let interpretation satisfies F CET .
F atomic-tight, satisfies SM[F ] iff satisfies SLF[F ].
statement Corollary 5 restricted interpretations satisfy CET . Indeed,
statement becomes wrong restriction dropped. example, program (28)
Example 7 atomic-tight, non-stable model considered satisfies loop
formulas, including singleton loops.
5.1.2 Bounded Formulas Normal Form
Normal form another syntactic condition imposed syntactic notion
boundedness ensures semantic notion boundedness. say formula
normal form every strictly positive occurrence atom form p(x), x
list distinct variables. clear every formula turned normal form
using equality.
Proposition 8 rectified formula F normal form bounded, F bounded w.r.t.
interpretation.
Proposition 9 rectified sentence F normal form bounded, interpretation I, model
{LF F (Y ) | finite first-order loop F }
iff model
{LF F (Y ) | finite loop F w.r.t. I}.
following theorem follows Theorem 2, Proposition 8 Proposition 9.
12. actually satisfy stronger condition called finitely recursive (Bonatti, 2004). See Section 8
details.

146

fiFirst-Order Stable Model Semantics First-Order Loop Formulas

Theorem 5 Let F rectified sentence normal form (possibly containing function
constants positive arity). F bounded, following formulas equivalent
other:
(a) SM[F ];
(b) {F } {LF F (Y ) | nonempty finite set atoms (F )};
(c) {F } {LF F (Y ) | finite first-order loop F }.
Proof. Proposition 8, F bounded F bounded w.r.t. interpretation I.
equivalence (a) (b) follows equivalence (a) (b)
Theorem 2. equivalence (a) (c) follows equivalence
(a) (c) Theorem 2 Proposition 9.

Consider program normal form
p(x) x = a, q(a)
q(y) p(b)

(34)

interpretation |I| = {1}, aI = bI = 1 pI = q = {1}.
interpretation satisfy Clarks equational theory, stable model.
accordance Theorem 5, satisfy loop formula loop {p(b), q(a)},

p(b) q(a) (b = q(a) 6= a) (p(b) b 6= b).
hand, consider another program non-normal form
stable models (34):
p(a) q(a)
(35)
q(y) p(b)
Program (35) finite complete set loops, {{p(z)}, {q(z)}}; loop formulas
universal closures
p(z) z = q(a)
q(z) p(b)
satisfies loop formulas. example illustrates role normal form assumption
Theorem 5 (in place Clarks equational theory Theorem 4).
Note normal form conversion may turn bounded sentence non-bounded
sentence. instance, normal form bounded program (32)
p(y) = f (x), q(x)
q(x) p(x), r(x)
p(x) x =
r(x) x =
r(x) x = f (a),

(36)

bounded.
Unlike Corollary 5, program normal form, atomic-tightness
general tightness. difficult check program normal form atomictight iff tight.
147

fiLee & Meng

5.1.3 Decidability Boundedness Finite Complete Set Loops
general, checking whether F bounded decidable, becomes decidable F
contains function constants positive arity. case checking whether
F atomic-tight.
Proposition 10 rectified sentence F (allowing function constants positive arity),
(a) checking whether F bounded decidable;
(b) checking whether F atomic-tight decidable.
F contains function constants positive arity,
(c) checking whether F bounded decidable;
(d) checking whether F atomic-tight decidable.
proof Proposition 10 (c) based following fact straightforward
extension Theorem 2 Chen et al. (2006) first-order formulas, asserts
checking F finite complete set loops decidable.
Proposition 11 rectified formula F contains function constants positive
arity, F bounded iff F finite complete set loops.
Note Proposition 11 hold F allowed contain function constants
positive arity. instance,
p(x) p(f (x))
bounded, finite complete set loops {{p(x)}}.
following corollary follows Theorem 4 Proposition 11.
Corollary 6 Let F rectified sentence signature function constants
positive arity, let interpretation satisfies F CET . F
finite complete set loops, conditions (a), (b), (c) Theorem 4 equivalent
other.
following corollary follows Theorem 5 Proposition 11.
Corollary 7 Let F rectified sentence normal form function constants
positive arity. F finite complete set loops, formulas (a), (b), (c)
Theorem 5 equivalent other.
148

fiFirst-Order Stable Model Semantics First-Order Loop Formulas

5.2 Semi-Safe Formulas
Semi-safety another decidable syntactic condition ensures SM[F ] expressed first-order sentences.
assume function constants positive arity. According Lee,
Lifschitz, Palla (2009), semi-safe sentence small predicate property:
relation represented predicate constants p hold tuple arguments
member tuple represented object constant occurring F .
show semi-safe sentence stable model semantics turned
sentence first-order logic.
First, review notion semi-safety Lee et al. (2009).13 preliminary step,
assign every formula F set RV(F ) restricted variables follows:
atomic formula F ,
F equality two variables, RV(F ) = ;
otherwise, RV(F ) set variables occurring F ;
RV(G H) = RV(G) RV(H);
RV(G H) = RV(G) RV(H);
RV(G H) = ;
RV(QvG) = RV(G) \ {v} Q {, }.
say variable x restricted F x RV(F ). rectified formula F semisafe every strictly positive occurrence every variable x belongs subformula G H
x restricted G.
sentence strictly positive occurrence variable, obviously semisafe. FOL-representation disjunctive program semi-safe if, rule (10)
program, every variable occurring head rule occurs B well.
Example 8 FOL-representation (8) semi-safe. Formula
p(a) q(b) xy((p(x) q(y)) p(y))
semi-safe,
p(a) q(b) xy((p(x) q(y)) p(y))

(37)

semi-safe.
finite set c object constants, c (x) stands formula
_
x = c.
cc

13. definition slightly general refer prenex form. Instead require
formula rectified.

149

fiLee & Meng

small predicate property expressed conjunction sentences


^
v1 , . . . , vn p(v1 , . . . , vn )
inc (vi )
i=1,...,n

predicate constants p occurring F , v1 , . . . , vn distinct variables.
denote conjunction sentences SPP c . c(F ) denote set object
constants occurring F .
Proposition 12 (Lee et al., 2009) semi-safe sentence F , formula SM[F ] entails
SPP c(F ) .
example, semi-safe sentence (37), SM[(37)] entails


x p(x) (x = x = b)) x(q(x) (x = x = b) .

(38)

following proposition tells us semi-safe sentence F , formula SM[F ]
equivalently rewritten first-order sentence.
Theorem 6 Let F rectified sentence function constants positive arity.
F semi-safe, SM[F ] equivalent conjunction F , SPP c(F ) finite
number first-order loop formulas.
Proof. F semi-safe, SM[F ] entails SPP c(F ) . sufficient prove
assumption SPP c(F ) , SM[F ] equivalent conjunction F finite number
first-order loop formulas. follows |= SPP c(F ) F bounded w.r.t. I. Since
every finite loop F w.r.t. represented finite set atoms whose terms
object variables, follows Theorem 2 satisfies SM[F ] iff satisfies loop
formulas sets.

example, SM[(37)] equivalent conjunction F , (38) universal
closures
p(z) z = (p(x) q(z) z 6= x)
q(z) z = b
Note condition finite complete set loops Corollaries 6 7,
condition semi-safety Theorem 6 entail other. instance, formula (37)
semi-safe, finite complete set first-order loops, x p(x) finite
complete set loops {{p(x)}}, semi-safe. Also program 1 Section 1
finite complete set loops, semi-safe due w fourth rule.

6. Programs Explicit Quantifiers
following extend syntax logic program allowing explicit quantifiers.
rule quantifiers form
H G,
(39)
G H first-order formulas every occurrence every implication
G H belongs negative formula. program quantifiers finite set rules
150

fiFirst-Order Stable Model Semantics First-Order Loop Formulas

quantifiers. Program 1 Section 1 example. semantics program
defined identifying program FOL-representation stable model
semantics. restricting syntax program like one above, comparison
syntax arbitrary formula, able write succinct loop formulas,
show below.
Let F formula finite set atoms. FY denote formula obtained
F replacing every occurrence
every atom p(t) F belong
V
negative formula p(t) p(t0 )Y 6= t0 . Let program quantifiers. Given
finite set atoms (), first rename variables variables
occur . define formula QES (Y ) (External Support Formula Programs
Quantifiers) disjunction
z(GY HY )

(40)

every rule (39) H contains strictly positive occurrence predicate constant
occurs , z list free variables rule occur .
loop formula universal closure
^
QES (Y ).
(41)
following proposition tells us (41) equivalent (12) notions
applied program explicit quantifiers. also shows (41) generalization
definition loop formula disjunctive program.
Proposition 13 Let program quantifiers, F FOL-representation ,
finite set atoms. assumption , formula QES (Y ) equivalent
NES F (Y ). disjunctive program normal form, QES (Y ) also equivalent
ES (Y ) assumption .
Note size (41) polynomial size given program.
case apply (12) FOL-representation program, due
expansion NES nested implications. hand, syntactic condition
imposed rule quantifiers avoids exponential blow up, following
lemma tells us.
Lemma 4 Let F formula every occurrence implication F belongs
negative formula let set atoms. NES F (Y ) equivalent FY .
Proof. induction F .



Example 2 (continued) First-Order Loop Formula understood
extended program (Using QES (Y )) : assumption ,
LF (Y1 ) equivalent universal closure
p(u) (x(q(x) (p(x) x 6= u)) z(r(z) (p(z) z 6= u))).
151

fiLee & Meng

LF (Y2 ) equivalent universal closure
q(u) y(p(y) (q(y) 6= u)).
LF (Y3 ) equivalent universal closure
r(u) .
LF (Y4 ) equivalent universal closure
(p(u) q(u)) (x((q(x) x 6= u) (p(x) x 6= u))
y((p(y) 6= u) (q(y) 6= u))
z(r(z) (p(z) z 6= u))).

finite set sentences entails sentence F stable model semantics (symbolically, |=SM F ), every stable model satisfies F .
SM[F ] reduced first-order sentence, described Theorem 5 Theorem 6,
|=SM F iff |= F,
set first-order loop formulas required (and possibly including SPP c(F )
Theorem 6 applied). fact allows us use first-order theorem provers reason
query entailment stable model semantics.
Example 9 Consider program 1 Section 1, following finite complete
set loops: {Man(u)}, {Spouse(u, v)}, {HasWife(u)}, {Married (u)}, {Accident(u, v)},
{Discount(u, v)}, {HasWife(u), Married (u)}. loop formulas 1 2 3
equivalent universal closure

Man(u) Man(John) John 6= u ;

Spouse(u, v) Spouse(John, y) (John, y) 6= (u, v) ;

HasWife(u) x Spouse(x, y) (HasWife(x) x 6= u)

x Man(x) Married (x) (HasWife(x) x 6= u) ;

Married (u) x Man(x) HasWife(x) (Married (x) x 6= u) ;
Accident(u, v) ;
Discount(u, v)

x Married (x) z Accident(x, z) (w(Discount(x, w) (x, w) 6= (u, v))) ;
Married (u) HasWife(u)

x Spouse(x, y) (HasWife(x) (x 6= u))

x Man(x) Married (x) x 6= u (HasWife(x) x 6= u)
x Man(x) HasWife(x) x 6= u (Married (x) x 6= u) .
152

fiFirst-Order Stable Model Semantics First-Order Loop Formulas

loop formulas, conjoined FOL-representation 1 2 3 , entail
first-order logic x Married (x) xy(Discount(x, y) x = John). verified
answers using first-order theorem prover Vampire 14 .

7. Extension Allow Extensional Predicates
definition stable model journal paper Ferraris et al. (2011), reviewed
Section 2, general definition conference paper (Ferraris et al., 2007)
allows us distinguish intensional non-intensional (a.k.a. extensional) predicates. Similar Datalog, intensional (output) predicates characterized
terms extensional (input) predicates. instance, consider Example 9 again, assume Man Spouse non-intensional. 1 2 3 still entails xyDiscount(x, y)
longer entails xy(Discount(x, y) x = John) may person
John spouse.
results earlier sections extended general semantics view
Proposition 14 below, characterizes SM[F ; p] terms SM[F ]. pr (F ) denote
list predicate constants occurring F ; Choice(p) denote conjunction
choice formulas x(p(x) p(x)) predicate constants p p, x list
distinct object variables; False(p) denote conjunction xp(x) predicate
constants p p. sometimes identify list corresponding set
confusion.
Proposition 14 list p predicate constants, formula SM[F ; p] equivalent
SM[F Choice(pr (F )\p) False(p\pr (F ))]

(42)

SM[F Choice(pr (F )\p) False(p\pr (F ))],

(43)


F obtained F replacing every atom form q(t) F q
belong p q(t).
proposition allows us extend results established SM[F ] SM[F ; p].
instance, Theorem 3 extended SM[F ; p] first rewriting form SM[G],
G
F Choice(pr (F )\p) False(p\pr (F )).
(44)
next three corollaries, signature, F rectified sentence (possibly
containing function constants positive arity), p finite list predicate constants
, G (44).
first corollary follows Theorem 2 Proposition 14.
Corollary 8 interpretation satisfies F , G bounded w.r.t. I,
following conditions equivalent other:
(a) |= SM[F ; p];
14. http://www.vampire.fm .

153

fiLee & Meng

(b) every nonempty finite set atoms formed predicate constants p
object names |I|, satisfies LF F (Y );
(c) every finite loop G w.r.t. whose predicate constants contained p,
satisfies LF F (Y ).
next corollary follows Theorem 4 Proposition 14.
Corollary 9 G bounded, then, interpretation satisfies F CET ,
following conditions equivalent other:
(a) |= SM[F ; p];
(b) every nonempty finite set atoms (G) whose predicate constants contained p, satisfies LF F (Y );
(c) every finite first-order loop G whose predicate constants contained p,
satisfies LF F (Y ).
last corollary follows Theorem 5 Proposition 14.
Corollary 10 G normal form bounded, following formulas
equivalent other:
(a) SM[F ; p];
(b) {F } {LF F (Y ) | nonempty finite set atoms (G) whose predicate
constants contained p};
(c) {F } {LF F (Y ) | finite first-order loop G whose predicate constants
contained p}.
Example 10 Consider Example 9 again, assuming Man Spouse extensional.
Let F FOL-presentation 1 2 3 let G formula (44). loops
G loops F . loop formulas remain except
following loop formulas Man(u) Spouse(u, v):


Man(u) Man(John) John 6= u x (Man(x) x 6= u) Man(x) ;

Spouse(u, v) Spouse(John, y) (John, y) 6= (u, v)

xy (Spouse(x, y) (x, y) 6= (u, v)) Spouse(x, y) .
two formulas tautologies. result, loop formulas loops, conjoined
G, entail xyDiscount(x, y), longer entail xy (Discount(x, y) x = John).
general, loops G contain intensional extensional predicates. Also every loop G contains extensional predicate singleton,
loop formula loop tautology.
154

fiFirst-Order Stable Model Semantics First-Order Loop Formulas

Corollary 3 extended allow extensional predicates following. SLF[F ; p],
denote
{LF F ({p(x)}) | p predicate constant p, x list
distinct object variables whose length arity p}.
say formula F p-atomic-tight w.r.t. every infinite path dependency
graph F w.r.t. whose vertices satisfied contains atom whose predicate
constant p.
Corollary 11 Let F rectified sentence (possibly containing function constants positive arity), let model F . F p-atomic-tight w.r.t. I, satisfies
SM[F ; p] iff satisfies SLF[F ; p].
definition semi-safety extended distinguish intensional nonintensional predicates follows. Let F formula function constants
positive arity. every first-order formula F assign set RVp (F ) restricted variables
relative p follows.
atomic formula F (including equality ),
F equality two variables, atom whose predicate constant
p, RVp (F ) = ;
otherwise, RVp (F ) set variables occurring F ;
RVp (G H) = RVp (G) RVp (H);
RVp (G H) = RVp (G) RVp (H);
RVp (G H) = .
RVp (QvG) = RVp (G) \ {v} Q {, }.
say variable x p-restricted F x RVp (F ). rectified formula F
semi-safe relative p every strictly positive occurrence every variable x belongs
subformula G H, x p-restricted G.
small predicate property generalized follows. Formula SPP pc conjunction
sentences


^
v1 , . . . , vn p(v1 , . . . , vn )
inc (vi )
i=1,...,n

predicate constants p p, v1 , . . . , vn distinct variables.
Proposition 15 (Lee et al., 2009) semi-safe sentence F relative p, formula
SM[F ; p] entails SPP pc(F ) .
following proposition tells us semi-safe sentence F , formula SM[F ; p]
equivalently rewritten first-order sentence.
155

fiLee & Meng

Theorem 7 Let F rectified sentence function constants positive arity.
F semi-safe relative p, SM[F ; p] equivalent conjunction F , SPP pc(F )
finite number first-order loop formulas.
Proof. Let F sentence signature . F semi-safe relative p, SM[F ; p]
entails SPP pc(F ) , sufficient prove assumption SPP pc(F ) , SM[F ; p]
equivalent conjunction F finite number first-order loop formulas.
Proposition 14, SM[F ; p] equivalent SM[G], G (44). Consider interpretation satisfies G SPP pc(F ) . Note dependency graph G w.r.t.
contains outgoing edges vertex whose predicate constant belong p.
Together fact |= SPP pc(F ) , conclude path dependency
graph whose vertices satisfied visits finitely many vertices. Consequently, G
bounded w.r.t. I. Since every finite loop G w.r.t. represented finite set
atoms whose terms object variables, follows Theorem 2 satisfies SM[G]
iff satisfies loop formulas sets.


8. Related Work
notion bounded program related notion finitely recursive program
studied Bonatti (2004), different definition dependency graph considered. atom dependency graph nondisjunctive ground program defined Bonatti
directed graph vertices set ground atoms, edges go
atom head atoms body every rule, including negative body. program called finitely recursive if, every atom, finitely
many atoms reachable atom dependency graph. clear every finitely
recursive program bounded, converse hold. instance, program
p(x) p(f (x))
bounded, finitely recursive infinite paths involve negative
edges. Also program
p(a) q(f (x))
bounded, finitely recursive infinitely many atoms q(f (a)), q(f (f (a))), . . .
reached p(a) atom dependency graph. Like bounded programs, checking
finitely recursive programs undecidable presence function constants positive
arity.
Lin Wang (2008) extended answer set semantics functions extending
definition reduct, also provided loop formulas programs. provide
alternative account results considering notions special cases
definitions presented paper. simplicity, assume non-sorted languages.15
Essentially, restricted attention special case non-Herbrand interpretations
object constants form universe, ground terms object constants
mapped object constants. According Lin Wang, LW-program P consists
15. Lin Wang (2008) consider essentially many-sorted languages. result section
extended case considering many-sorted SM (Kim, Lee, & Palla, 2009).

156

fiFirst-Order Stable Model Semantics First-Order Loop Formulas

type definitions set rules. Type definitions introduce domains many-sorted
signature consisting object constants, includes evaluation function
symbol positive arity maps list object constants object constant. Since
assume non-sorted languages, consider single domain (universe). say
interpretation P -interpretation universe set object constants specified
P , object constants evaluated itself, ground terms object constants
evaluated conforming type definitions P .
Proposition 16 Let P LW-program let F FOL-representation set
rules P . following conditions equivalent other:
(a) answer set P according Lin Wang (2008);
(b) P -interpretation satisfies SM[F ];
(c) P -interpretation satisfies F loop formulas loops
F w.r.t. I.
equivalence (b) (c) follows Proposition 2 since universe
finite. equivalence (a) (c) follows fact LW answer sets
characterized loop formulas defined Lin Wang (2008)
loop formulas essentially loop formulas (c).
Since proposal first-order stable model semantics, papers
first-order definability SM[F ]. Zhang Zhou (2010) show that, nondisjunctive program function constants positive arity, first-order stable
model semantics reformulated progression based semantics. also showed
programs whose answer sets found finite progression exactly
represented first-order formulas. researchers paid special attention first-order definability SM[F ] finite structures. Chen, Zhang, Zhou (2010)
show game-theoretic characterization first-order indefinability first-order answer
set programs finite structures. Asuncion, Lin, Zhang, Zhou (2010) show first-order
definability finite structures turning programs modified completion using new
predicates record levels. Chen, Lin, Zhang, Zhou (2011) present condition called
loop-separable, refined finite complete set loops
finite answer sets program captured first-order sentences. However, like
condition finite complete set loops, condition disjoint semi-safety.
following program semi-safe loop-separable:
p(x) p(y), q(x, y).
However, work limited nondisjunctive programs contain function constants positive arity. work limited finite structures, considers function
constants positive arity well. Nonetheless papers first-order definability
closely related work insights would gained relationship
them.
use first-order theorem provers stable model semantics already investigated Sabuncu Alpaslan (2007), results limited several ways.
157

fiLee & Meng

considered nondisjunctive logic programs trivial loops only, case stable
model semantics equivalent completion semantics. also restricted attention
Herbrand models.

9. Conclusion
paper puts first-order loop formulas context first-order reasoning studies
related first-order stable model semantics. similarities mismatches
found paper provide useful insights first-order reasoning stable models.
Future work find restrictions make first-order stable model reasoning
decidable computable efficient manner, like conditions imposed finitary
programs (Bonatti, 2004). Recently, first-order stable model semantics shown
used unifying nonmonotonic logic integrating rules ontologies (de Bruijn,
Pearce, Polleres, & Valverde, 2010; Lee & Palla, 2011), ontology predicates
identified extensional predicates. Based studied relationship first-order
stable model semantics first-order loop formulas, one may find restrictions
tailored hybrid knowledge bases efficient computation.

Acknowledgments
grateful Joseph Babb, Michael Bartholomew, Piero Bonatti, Vladimir Lifschitz,
Ravi Palla useful discussions, anonymous referees useful comments. authors partially supported National Science Foundation
Grant IIS-0916116 IARPA SCIL program.

Appendix A. Proofs
proofs presented order dependencies. Theorem 3 main theorem.
proof Theorem 2 uses Theorem 3. proofs Theorems 4 5 follow
Theorem 2. proof Lemma 1 follows Proposition 13.
following, unless otherwise noted, F rectified first-order sentence, p list
distinct predicate constants p1 , . . . , pn occurring F , symbols u, v lists distinct
predicate variables length p, symbols q, r lists distinct predicate
names length p.
A.1 Proof Theorem 3
Theorem 3
other:

rectified sentence F , following sentences equivalent

(a) SM[F ];
(b) F u((u p) Nonempty(u) NSES F (u));
(c) F u((u p) Ext-Loop F (u) NSES F (u)).
158

fiFirst-Order Stable Model Semantics First-Order Loop Formulas

notation use proof involves predicate expressions (Lifschitz, 1994,
Section 3.1) form
xF (x),
(45)
F (x) formula. e (45) G(p) formula containing predicate constant
p arity length x G(e) stands result replacing
atomic part form p(t) G(p) F (t), renaming bound variables G(p)
usual way, necessary. instance, G(p) p(a) p(b) G(y(x = y))
x = x = b. Substituting tuple e predicate expressions tuple p predicate
constants defined similar way.
Lemma 5 Let v list yi (pi (yi ) ui (yi )). following formulas logically
valid:
u p (F (u) NSES F (v));
u p (F (v) NSES F (u)).
Proof. induction.
A.1.1 Proof Equivalence (a) (b) Theorem 3
sufficient show
u(u < p F (u))
equivalent
v(v p Nonempty(v) NSES F (v)).
left right: Take u u < pF (u). Let v list yi (pi (yi ) ui (yi )).
Clearly, v p holds.

u < p, follows x pi (x) ui (x),
W


x vi (x ) follows, Nonempty(v) follows.
Lemma 5, NSES F (v) follows u < p F (u).
right left: Take v v p Nonempty(v) NSES F (v). Let u list
yi (pi (yi ) vi (yi )).
Clearly, u p holds. Moreover (u = p) holds. Indeed, u = p, xi vi (xi )
follows, contradicts assumption Nonempty(v). Consequently, u < p follows.
Lemma 5, F (u) follows v p NSES F (v).

159

fiLee & Meng

A.1.2 Proof Proposition 3
Lemma 6 Let interpretation contains (F ), let q, r lists
predicate names corresponding p. Let Z sets atoms dependency graph
F w.r.t.
pi ( ) iff |= qi ( )

pi ( ) Z iff |= ri ( ),
list object names.
|= r q EF (r, q)
iff Z subset edge atom Z atom \ Z
dependency graph F w.r.t. I.
Proof. left right: Assume |= r q EF (r, q). fact Z subset
follows assumption |= r q construction Z . Since
_
|=
z(ri (t) qj (t0 ) rj (t0 )),
(pi (t),pj (t0 )) : pi (t) depends pj (t0 )
rule F

z list object variables t0 , substitution maps
object variables t0 object names
_
|=
ri (t) qj (t0 ) rj (t0 ).
(pi (t),pj (t0 )) : pi (t) depends pj (t0 )
rule F

Consequently, atoms pi (t), pj (t0 ) pi (t) depends pj (t0 ) rule F
|= ri (t)qj (t0 )rj (t0 ). |= ri (t) construction Z, follows
pi (((t)I ) ) belongs Z. Also |= qj (t0 ) rj (t0 ), follows pj (((t0 )I ) )
belongs \ Z. Therefore, edge atom Z atom \ Z
dependency graph F w.r.t. I.
right left: Assume Z subset edge atom
pi ( ) Z atom pj ( ) \ Z dependency graph F w.r.t. I. Clearly,
|= r q.
assumption pi ( ) Z, pj ( ) \ Z construction Z,
follows |= ri ( ) qj ( ) rj ( ). definition dependency graph
w.r.t. I, follows pi (t), pj (t0 ) pi (t) depends pj (t0 ) rule
F substitution maps object variables t0 object names
(t)I = (t0 )I = .
Consequently,
_
|=
ri (t) qj (t0 ) rj (t0 ),
(pi (t),pj (t0 )) : pi (t) depends pj (t0 )
rule F

160

fiFirst-Order Stable Model Semantics First-Order Loop Formulas

equivalent saying
_
|=

z(ri (t) qj (t0 ) rj (t0 )),

(pi (t),pj (t0 )) : pi (t) depends pj (t0 )
rule F

z list variables t0 .



Lemma 7 graph (V, E) strongly connected iff, nonempty proper subset U
V , edge U V \ U .
Proof. Follows definition strongly connected graph.



Proposition 3 Let q list predicate names corresponding p, let set
atoms dependency graph F w.r.t.
pi ( ) iff |= qi ( ),
list object names. |= Loop F (q) iff loop F w.r.t. I.
Proof. left right: Assume |= Loop F (q). |= Nonempty(q),
follows nonempty.
Take nonempty proper subset Z . Let r list predicate names

|= ri ( ) iff pi ( ) Z.
clear
|= Nonempty(r) r < q.
Consequently, |= Loop F (q), follows |= E F (r, q). Lemma 6,
edge atom Z atom \ Z. Consequently, Lemma 7, induces
strongly connected subgraph thus loop F w.r.t. I.
right left: Let loop F w.r.t. q list predicate names
|= qi ( ) iff pi ( ) Y.
Since nonempty, |= Nonempty(q).
Consider list predicate names r
|= Nonempty(r) r < q.
Let Z set vertices dependency graph F w.r.t.
pi ( ) Z iff |= ri ( ).
Clearly, Z nonempty proper subset . Since induces strongly connected subgraph,
Lemma 7, edge atom Z atom \ Z. Consequently
Lemma 6, |= EF (r, q).


161

fiLee & Meng

A.1.3 Proof Proposition 4
Proposition 4 Let q list predicate names corresponding p, let set
atoms dependency graph F w.r.t.
pi ( ) iff |= qi ( ),
list object names.
|= Nonempty(q) v((v q) Loop F (v) EF (v, q))
iff unbounded set F w.r.t. I.
Proof. left right: Assume
|= Nonempty(q) v(v q Loop F (v) EF (v, q)).

(46)

Since |= Nonempty(q), clear nonempty.
Take subset Z loop F w.r.t. I. Let r list predicate names

|= ri ( ) iff pi ( ) Z.
Since Z subset , clear |= r q. Since Z loop F w.r.t. I,
Proposition 3, |= Loop F (r). Consequently, (46) follows |= E F (r, q).
Lemma 6, edge atom Z atom \ Z. Therefore,
unbounded set F w.r.t. I.
right left: Let unbounded set F w.r.t. I. Since nonempty,
clear |= Nonempty(q).
Take list predicate names r |= r q Loop F (r). Let Z set
vertices dependency graph F w.r.t.
pi ( ) Z iff |= ri ( ).
Proposition 3, Z loop F w.r.t. I. clear Z subset . Since
unbounded set F w.r.t. I, edge Z \ Z. Consequently Lemma 6,
|= EF (r, q).

A.1.4 Proof Proposition 5
Proposition 5 negative formula F , formula
NSES F (u) F
logically valid.
Proof. proof follows immediately following two lemmas, proved
induction.


162

fiFirst-Order Stable Model Semantics First-Order Loop Formulas

Lemma 8 formula F ,
NSES F (u) F
logically valid.
Lemma 9 Let F formula, let SF set pi (t) strictly positive
occurrence F . Formula
^
F
zvi (t) NSES F (v)
(47)
pi (t)SF

logically valid, z tuple variables free F .
A.1.5 Proof Equivalence (b) (c) Theorem 3
Lemma 10 Let F rectified formula, let SF+ set atoms pi (t)
positive occurrence F belong negative formula, let SF set
atoms pi (t) negative occurrence F belong negative
formula.16 following formulas logically valid, z list variables
free F .
V
(a) (v u) pi (t)S + z(ui (t) vi (t)) NSES F (v) NSES F (u);
F
V
(b) (v u) pi (t)S z(ui (t) vi (t)) NSES F (u) NSES F (v).
F

Proof. parts proved simultaneously induction F .
Case 1: F atom pi (t).
Part (a): NSES F (v) entails NSES F (u) assumption
^
z(ui (t) vi (t)).
+
pi (t)SF

Part (b): NSES F (u) entails NSES F (v) assumption v u.
Case 2: F equality. clear since NSES F (v) NSES F (u)
F.
Case 3: F G H G H. Follows I.H.
Case 4: F G H.
Part (a): Assume
(v u)

^

z(ui (t) vi (t)).

(48)

+
pi (t)SF

need show
(NSES G (v) NSES H (v)) (G H)
16. Note distinguish formula negative occurrence negative. See
end Section 2.

163

fiLee & Meng

entails
(NSES G (u) NSES H (u)) (G H).
Note
^

z(ui (t) vi (t))


pi (t)SG


^

z(ui (t) vi (t))

+
pi (t)SH

entailed formula (48). I.H., NSES G (u) entails NSES G (v) NSES H (v) entails
NSES H (u).
Part (b): Similar Part (a).
Case 5: F x G
Part (a): Assume
^

(v u)

z(ui (t) vi (t)) xNSES G (v).

+
pi (t)SF

assumption NSES G (v), G follows Lemma 8. Also
^
z0 (ui (t) vi (t))
+
pi (t)SG

follows, z0 list variables free G, I.H. G,
NSES G (u) holds assumption. Since x free assumption, xNSES G (u)
holds well.
Part (b): Similar Part (a).
Case 6: F x G.
Part (a): Assume
^

(v u)

z(ui (t) vi (t)) xNSES G (v).

(49)

z(ui (t) vi (t)) NSES G (v).

(50)

+
pi (t)SF

Take x
(v u)

^
+
pi (t)SF

NSES G (v), Lemma 8, G follows. Also
^
z0 (ui (t) vi (t))
+
pi (t)SG

follows, z0 list variables free G. I.H. G,
NSES G (u) holds assumption (50). Consequently, xNSES G (u) holds
164

fiFirst-Order Stable Model Semantics First-Order Loop Formulas

assumption. Since x free (49), conclude xNSES G (u) holds
assumption (49).
Part (b): Similar Part (a).



Lemma 11 rectified formula F ,
(v u) EF (v, u) NSES F (u) NSES F (v)
logically valid.
Proof. induction F .
Case 1: F atom pi (t). NSES F (u) entails NSES F (v) assumption v u.
Case 2: F equality. clear since NSES F (v) NSES F (u) F .
Case 3: F G H G H. Follows I.H.
Case 4: F G H. Assume
(v u) EF (v, u) NSES F (u)
NSES G (v). NSES F (u), Lemma 8, conclude G H. NSES G (v),
Lemma 8, G follows, consequently H.
Assume NSES H (v) sake contradiction. Lemma 9, H NSES H (v),
follows
_
xvi (t)
(51)
pi (t) : pi (t) occurs strictly positively H

, x list variables free H.
Since F rectified, variables F partitioned three sets: list
variables x free H, list variables free G,
rest. Note EF (v, u) entails


^
xvi (t) y(uj (t0 ) vj (t0 )) ,
(52)
(pi (t),pj (t0 )) : pi (t) depends pj (t0 ) rule GH F
pi (t) occurs H,pj (t0 ) occurs G

x list variables free H, list variables
t0 free G. (51) (52), conclude
^
y(uj (t0 ) vj (t0 )).
pj (t0 ) : pj (t0 ) occurs positively negative subformula G

this, together assumption (v u) NSES G (v), Lemma 10 (a),
NSES G (u) follows. Thus NSES H (u) follows NSES F (u) NSES G (u). Since E F (v, u)
entails E H (v, u), I.H. H, NSES H (v) follows, contradicts assumption.
Case 5: F xG xG. Follows I.H.
165



fiLee & Meng

Lemma 12
Nonempty(u) v(v u Ext-Loop F (v) EF (v, u))
logically valid.
Proof. Take list q predicate names, interpretation satisfies Nonempty(q).
Let set vertices dependency graph F w.r.t.
pi ( ) iff |= qi ( ).
Consider subgraph G dependency graph F w.r.t. induced .
unbounded set w.r.t. I, Proposition 4, |= Ext-Loop F (q).
|= q q Ext-Loop F (q) EF (q, q).
Otherwise, consider graph G0 obtained G collapsing strongly connected
components G, i.e., vertices G0 strongly connected components G
G0 edge V V 0 G edge vertex V vertex V 0 . Since
assumed unbounded set w.r.t. I, exists vertex Z G0
outgoing edges. Consider list predicate names r
|= ri ( ) iff pi ( ) Z.
clear |= r q. Proposition 3, |= Loop F (r) thus |= Ext-Loop F (r). Since
edge Z \ Z, Lemma 6, |= EF (r, q). Consequently, claim
follows.

Proof Equivalence (b) (c) Theorem 3
(b) (c):
valid.

Clear formula Ext-Loop F (u) Nonempty(u) logically

(c) (b): Assume
F v(v p Ext-Loop F (v) NSES F (v)).
Take u u p Nonempty(u). Lemma 12, follows Nonempty(u)
exists v v u Ext-Loop F (v) EF (v, u). clear v p
follows v u u p. follows assumption NSES F (v).
Lemma 11, NSES F (u) follows v u EF (v, u).

A.2 Proof Theorem 2
Lemma 3 Let F rectified sentence signature (possibly containing function
constants positive arity), let interpretation satisfies F . F
bounded w.r.t. I,
|= u(u p Ext-Loop F (u) NSES F (u))
166

fiFirst-Order Stable Model Semantics First-Order Loop Formulas

iff finite loop F w.r.t.
^

|=
NES F (Y ) .
Proof. left right: Assume
|= q p Ext-Loop F (q) NSES F (q)
list predicate names q. Consider set vertices dependency
graph F w.r.t.
pi ( ) iff |= qi ( ).
Since |= Ext-Loop F (q), Proposition 3 Proposition 4, follows
extended loop F w.r.t. I. Since |= qi ( ) pi ( ) |= q p, follows
satisfies every atom . Together assumption F bounded w.r.t. I,
implies set finite. Since |= NSES F (q) finite, Lemma 2,
follows |= NES F (Y ).
right left: Consider finite loop F w.r.t. I. Assume
^
|=
NES F (Y ).
Let q list predicate names
|= qi ( ) iff pi ( ) Y.
|= q p follows construction q |=

V

Y.

Since loop F w.r.t. I, Proposition 3, |= Loop F (q), consequently,
|= Ext-Loop F (q).
|= NES F (Y ), Lemma 2, |= NSES F (q).
Consequently, |= u(u p Ext-Loop F (u) NSES F (u)).



Theorem 2 Let F rectified sentence signature (possibly containing function
constants positive arity), let interpretation satisfies F . F
bounded w.r.t. I, following conditions equivalent other:
(a) satisfies SM[F ];
(b) every nonempty finite set atoms formed predicate constants (F )
object names |I|, satisfies LF F (Y );
(c) every finite loop F w.r.t. I, satisfies LF F (Y ).
Proof. (a) (c): Theorem 3 Lemma 3.
(b) (c):
167

fiLee & Meng

(b) (c): Clear.
(c) (b): Assume satisfies LF F (L) every finite loop L F w.r.t I.
Consider nonempty finite set V
atoms formed predicate constants (F )
object names |= . Let q list predicate names
|= qi ( ) iff pi ( ) Y.
Since nonempty, clear Nonempty(q) follows. view Lemma 12,
list predicate names r
|= r q Ext-Loop F (r) EF (r, q).

(53)

Consider Z set vertices dependency graph F w.r.t.
pi ( ) Z iff |= ri ( ).
Since |= Ext-Loop F (r), Proposition
3 PropositionV4, Z extended loop
V
F w.r.t. I. Clearly, |= Z since Z |= . Since F bounded
w.r.t. I, Z satisfied I, follows Z finite loop F w.r.t. I.
Since |= r q EF (r, q), Z subset and, Lemma 6, edge
Z \ Z dependency graph F w.r.t. I. Since |= LF F (Z),
conclude |= NES F (Z), Lemma 2, |= NSES F (r). (53)
|= NSES F (r), Lemma 11, |= NSES F (q). Lemma 2 again,
|= NES F (Y ). Consequently, |= LF F (Y ).

A.3 Proof Proposition 6
Proposition 6
rectified formula F signature bounded, F bounded
w.r.t. interpretation satisfies CET .
Lemma 13 terms t1 t2 signature , interpretation satisfies
CET , substitution object variables t1 t2 object names
(t1 )I = (t2 )I , Robinsons unification algorithm (Robinson, 1965), applied t1
t2 , returns general unifier (mgu) t1 t2
(a) t1 = t2 ,
(b) every variable x t1 t2 , (x)I = (x)I .
Proof. assumptions, Lemma 5.1 work Kunen (1987), t1 t2
unifiable, case Robinsons algorithm returns mgu t1 t2 maps
variables occurring t1 t2 terms. Given this, part (b) proven induction.

proof Proposition 6 follows following lemma.
168

fiFirst-Order Stable Model Semantics First-Order Loop Formulas

Lemma 14 Let F rectified sentence signature , let interpretation
satisfies CET . path
hp1 ( 1 ), p2 ( 2 ), . . . , pk ( k ), pk+1 ( k+1 )i

(54)

dependency graph F w.r.t I, path
hp1 (u1 ), p2 (u2 ), . . . , pk (uk ), pk+1 (uk+1 )i
first-order dependency graph F substitution maps object variables
ui object names (ui )I = i.
Proof. edge (pi ( ), pi+1 ( i+1 )) (54) obtained pair atoms (pi (ti ), pi+1 (t0i ))
substitution pi (ti ) depends pi+1 (t0i ) rule F ,
(t1 1 )I = 1 , (t0i )I = (ti+1 i+1 )I = i+1 (1 < k), (t0k k )I = k+1 .

(55)

simplicity assume pair (pi (ti ), pi+1 (t0i )) considered common
variables another pair first renaming variables. allows us use one substitution = 1 . . . k place individual rest proof.
show induction that, j j {1 . . . k}, substitutions
j
(1 j) variables ti t0i terms
(a) hp1 (t1 )1j , p2 (t2 )2j , . . . , pj (tj )jj , pj+1 (t0j )jj path first-order dependency
graph F ,
(b) (ti ij )I = 1 j, (t0j jj )I = j+1 .
j = 1, take ij identity substitution. Clearly, conditions (a) (b)
satisfied.
Otherwise, I.H. assume that, j {1, . . . , k1}, substitutions
1j , . . . , jj conditions (a) (b) satisfied. prove
substitutions ij+1 (1 j +1) variables ti t0i terms
j+1
j+1
(a) hp1 (t1 )1j+1 , p2 (t2 )2j+1 , . . . , pj+1 (tj+1 )j+1
, pj+2 (t0j+1 )j+1
path first-order dependency graph F ,
j+1
(b) (ti ij+1 )I = 1 j +1, (t0j+1 j+1
) = j+2 .

I.H., (t0j jj )I = j+1 (55) (tj+1 )I = j+1 . Lemma 13
substitution variables t0j jj tj+1 terms t0j jj = tj+1
variable x t0j jj tj+1 ,
(x)I = (x)I .
define ij+1
ij 1 j
169

(56)

fiLee & Meng

= j +1.
easy check condition (a) satisfied. check condition (b) satisfied,
consider variable x set
{t1 1j , t2 2j , . . . , tj jj , t0j jj , tj+1 , t0j+1 }.

(57)

x t0j jj tj+1 , (56), (x)I = (x)I . Otherwise, since change
variables t0j jj tj+1 , (x)I = (x)I . Consequently, variable x
(57), get (x)I = (x)I . remains check following.
1 j, (ti ij+1 )I = (ti ij )I = (ti ij )I . last one equal I.H.
j+1
(tj+1 j+1
) = (tj+1 )I = (tj+1 )I . last one equal j+1 (55).
j+1
(t0j+1 j+1
) = (t0j+1 )I = (t0j+1 )I . last one equal j+2 (55).


A.4 Proof Proposition 7
Proposition 7 rectified sentence F signature interpretation
satisfies CET , model
{LF F (Y ) | finite first-order loop F }
iff model
{LF F (Y ) | finite loop F w.r.t. I}.

proof follows immediately following fact Lemma 15.
Fact 1 Let F rectified sentence signature , let interpretation .
first-order loop F substitution maps variables object
names, 0 = {pi ( ) | pi (t) , tI = } loop F w.r.t. I.
Lemma 15 Let F rectified sentence signature , let interpretation
. satisfies CET , then, finite loop 0 F w.r.t. I, finite
loop F substitution maps variables object names
0 = {pi ( ) | pi (t) Y, (t)I = }.
Proof. Without loss generality, consider path
hp1 ( 1 ), p2 ( 2 ), . . . , pk ( k ), p1 ( 1 )i
(k 1) dependency graph F w.r.t. consists vertices 0 . Since
|= CET , Lemma 14, path
hp1 (u1 ), p2 (u2 ), . . . , pk (uk ), p1 (uk+1 )i
170

fiFirst-Order Stable Model Semantics First-Order Loop Formulas

first-order dependency graph F substitution maps variables ui
object names (ui )I = 1 k, (uk+1 )I = 1 . Since
(uk+1 )I = (u1 )I , Lemma 13, unifier uk+1 u1 that,
variable x uk+1 u1 , (x)I = (x)I . Consequently,
{p1 (u1 ), p2 (u2 ), . . . , pk (uk )}
induces finite strongly connected subgraph (ui )I = (ui )I = .



A.5 Proof Proposition 8
Proposition 8 rectified formula F normal form bounded, F bounded
w.r.t. interpretation.
proof follows following lemma.
Lemma 16 Let F rectified sentence signature normal form, let
interpretation . path
hp1 ( 1 ), p2 ( 2 ), . . . , pk ( k ), pk+1 ( k+1 )i
dependency graph F w.r.t I, exists path
hp1 (u1 ), p2 (u2 ), . . . , pk (uk ), pk+1 (uk+1 )i
first-order dependency graph F substitution maps object variables
ui object names (ui )I = i, u1 list object variables.
Proof. proof similar proof Lemma 14 except require
satisfy CET . Instead, existence unifier t0j jj tj+1 ensured
assumption normal form tj+1 list variables assumption t0j jj
contains none variables (due variable renaming).
A.6 Proof Proposition 9
Proposition 9 rectified sentence F normal form bounded, interpretation I, model
{LF F (Y ) | finite first-order loop F }
iff model
{LF F (Y ) | finite loop F w.r.t. I}.

proof follows Fact 1 following lemma.
Lemma 17 rectified sentence F normal form bounded, finite loop
0 F w.r.t. I, finite loop F substitution maps variables
object names 0 = {pi ( ) | pi (t) Y, (t)I = }.
171

fiLee & Meng

Proof. Let 0 finite loop F w.r.t. I. Without loss generality, path
hp1 ( 1 ), p2 ( 2 ), . . . , pk ( k ), p1 ( 1 )i
(k 1) dependency graph F w.r.t. consists vertices 0 . Since F
normal form, Lemma 16, path
hp1 (u1 ), p2 (u2 ), . . . , pk (uk ), p1 (uk+1 )i

(58)

first-order dependency graph F , u1 consists object variables only,
substitution maps variables ui object names (ui )I =
1 k, (uk+1 )I = 1 . two cases consider.
Case 1: unifier u1 uk+1 maps variables u1 terms uk+1
u1 = uk+1 . follows that, variable x uk+1 u1 , (x)I = (x)I .
Consequently,
{p1 (u1 ), p2 (u2 ), . . . , pk (uk )}
induces finite strongly connected subgraph (ui )I = (ui )I = .
Case 2: unifier .
Consider another path
hp1 (v1 ), p2 (v2 ), . . . , pk (vk ), p1 (vk+1 )i
obtained similar (58) except variables path disjoint
variables (58). Clearly, unifier 0 uk+1 v1 maps
variables v1 terms,
hp1 (u1 ), p2 (u2 ), . . . , pk (uk ), p1 (v1 0 ), p2 (v2 0 ), . . . , pk (vk 0 )i
another path first-order dependency graph F . clear using
construction repeatedly, form infinite path visits infinitely many
vertices first-order dependency graph. contradicts assumption
F bounded.

A.7 Proof Proposition 11
use following lemma section next section, extends Theorem 2 work Chen et al. (2006) provides equivalent conditions
program finite complete set loops disjunctive program sentence.
Lemma 18 (Chen et al., 2006, Thm. 2) formula F contains function
constants positive arity, following conditions equivalent:
(a) F finite complete set loops.
172

fiFirst-Order Stable Model Semantics First-Order Loop Formulas

(b) nonnegative integer N every loop L F , number
variables L bounded N .
(c) loop L F atom A1 A2 L, variables occurring A1
identical variables occurring A2 .
(d) loop L Ground (F ){c1 ,c2 } (F ) c1 , c2 two new object constants,
two atoms A1 A2 L A1 mentions c1 A2
A1 mentions c2 A2 not.
Proposition 11 rectified formula F contains function constants positive
arity, F bounded iff F finite complete set loops.
Proof. left right: Assume F bounded. every loop F finite.
follows exists nonnegative integer N number variables
loop bounded N . Lemma 18 (b), F finite complete set loops.
right left: Assume F finite complete set loops and, sake
contradiction, assume bounded. Without loss generality, infinite
path
hp1 (t1 )1 , p2 (t2 )2 , . . .i
(59)
first-order dependency graph F visits infinitely many vertices, pi (ti )
atoms occurring F substitutions.
Since F finite string, contains finitely many atoms. follows
atom pi (ti ) occurring F arbitrarily many substitutions atoms pi (ti )
contained (59). Without loss generality, consider path
hpi (ti )i , pi+1 (ti+1 )i+1 , . . . , pi (ti )k
contained (59), k agree substituting object constants variables
ti . Since ti ti k contain function constant, exists substitution 0
maps variables ti k terms ti ti k 0 = ti . Consequently,
{pi (xi )i 0 , pi+1 (xi+1 )i+1 0 , . . . , pi (xi )k 0 }
loop F . Since length path arbitrarily large, arbitrarily many
variables occurring loop. Lemma 18 (b), follows F finite complete
set loops.

A.8 Proof Proposition 10
Proposition 10
arity),

rectified sentence F (allowing function constants positive

(a) checking whether F bounded decidable;
(b) checking whether F atomic-tight decidable.
F contains function constants positive arity,
(c) checking whether F bounded decidable;
(d) checking whether F atomic-tight decidable.
173

fiLee & Meng

A.8.1 Proof Part (a) (b)
show proof Part (a) first. proof repeats, minor modifications,
argument proof Theorem 26 work Bonatti (2004), considers
following program simulate deterministic Turing machines M.
t(s, L, v, [V | R], C) t(s0 , [v 0 | L], V, R, C +1)
t(s, L, v, [ ], C) t(s0 , [v 0 | L], b, [ ], C +1)
t(s, [V | L], v, R, C) t(s0 , L, V, [v 0 | R], C +1)
t(s, [ ], v, R, C) t(s0 , [ ], b, [v 0 | R], C +1)
t(s, L, v, R, C)













instr.hs, v, v 0 , s0 , righti
instr.hs, v, v 0 , s0 , righti
instr.hs, v, v 0 , s0 , lefti
instr.hs, v, v 0 , s0 , lefti
final states s.

Halting problem reduced problem checking bounded formulas.
precisely, show bounded iff terminates every configuration.
first establish following facts:
(i) every non-terminating computation input x, corresponding
infinite path first-order dependency graph visits infinitely many
vertices;
(ii) infinite path first-order dependency graph ,
infinite path starting legal encoding input corresponds
non-terminating computation M.
Fact (i) immediate definition : Note step counter (the last
argument t) ensures dependency graph acyclic. Then, whenever falls
cycle, dependency graph contains infinite acyclic path visits infinitely many
vertices hence program bounded.
Fact (ii) proven follows. Assume infinite path dependency graph. observe first argument every vertex path must legal
state third argument every vertex must legal tape value. Otherwise,
outgoing edge vertices dependency graph . second,
fourth fifth arguments contain variables illegal values obtained
substitutions variables L, R, V C. case, easily find substitutions
variables illegal values legal values apply uniformly along
path, obtain another infinite path starting vertex correctly encodes
configuration thus corresponding non-terminating computation.
claim follows immediately two facts: terminate
computation, (i), unbounded. unbounded, (ii),
terminate.
proof works Part (b) well. step counter (the last
argument t) ensures dependency graph acyclic. Consequently, every infinite
path dependency graph visits infinitely many vertices, atomic-tight iff
bounded.

A.8.2 Proof Part (c)
view equivalence (a) (d) Lemma 18, checking whether formula
F containing function constants positive arity finite complete set loops
174

fiFirst-Order Stable Model Semantics First-Order Loop Formulas

done examining finite number loops finite dependency graph,
decidable. Proposition 11, follows checking whether F bounded decidable.

A.8.3 Proof Part (d)
sentence F function constants positive arity finite set c object constants, Ground c (F ) defined recursively. F atomic formula thenGround c (F )
F . function Ground c commutes propositional connectives; quantifiers turn
finite conjunctions disjunctions object constants occurring c.
Lemma 19 Let c set consisting object constants occurring F , possibly new object constant F contains object constants. F non-trivial loop iff
Ground c (F ) non-trivial loop.
order check whether F atomic-tight, first check whether F bounded,
decidable. F bounded, F atomic-tight. Otherwise, view
Lemma 19, checking whether F atomic-tight checking whether Ground c (F )
atomic-tight. Since F contains function constants positive arity, dependency
graph Ground c (F ) finite. decidable check whether dependency graph
Ground c (F ) non-trivial loop.

A.9 Proof Proposition 13
Lemma 20 Let F formula set atoms. predicate constant occurring
occurs strictly positively F , NES F (Y ) equivalent F .
Proof. induction.



Proposition 13 Let program quantifiers, F FOL-representation ,
finite set atoms. assumption , formula QES (Y ) equivalent
NES F (Y ). disjunctive program normal form, QES (Y ) also equivalent
ES (Y ) assumption .
Proof. QES (Y ) NES F (Y ): NES F (Y )
^

x[(G H) (NES G (Y ) NES H (Y ))].

(60)

HG

assumption F , formula (60) equivalent
_
x(NES G (Y ) NES H (Y )).

(61)

HG

view Lemma 20, H contain strictly positive occurrence predicate
constant belongs , NES H (Y ) equivalent H. Also, follows Lemma 2
Lemma 8 NES G (Y ) implies G. NES G (Y )NES H (Y ) conflicts assumption
175

fiLee & Meng

G H H contain strictly positive occurrence predicate constant
belongs . result, assumption F , formula (61) equivalent
disjunction
x(NES G (Y ) NES H (Y ))
(62)
rules H G, H contains strictly positive occurrence predicate constant
belongs . Note G H formulas every occurrence
implication G H belongs negative formula. Lemma 4, (62) equivalent
QES (Y ).
QES (Y ) ES (Y ): disjunctive program, QES (Y ) disjunction


^
_
^

z B N
(t 6= t0 )
(p(t)
6= t0 )
(63)
p(t)B
p(t0 )Y

p(t0 )Y

p(t)A

rules (10) contains predicate constant occurs , z
list variables (10) . hand, ES (Y ) disjunction
0



z B N

^

_

0

(t 6= )

p(t)B
p(t0 )Y

^

(p(t)

0

6= )




(64)

p(t0 )Y

p(t)A

rules (10) contains predicate constant occurs AY 6= ,
z0 list variables B, N .
clear (64) implies (63). prove (63) implies (64), assume
BN

^

_

(t 6= t0 )

p(t)B
p(t0 )Y

^

(p(t)


6= t0 )

(65)

p(t0 )Y

p(t)A

consider two cases.
V
p(t0 )Y 6= t0 p(t) A, (65) equivalent
^

BN

(t 6= t0 )

p(t)B
p(t0 )Y

_

p(t)

p(t)A

contradicts assumption .
Otherwise, exists p(t) p(t0 ) = t0 . Since normal form,
exists maps t0 , 6= . Consequently, (65) equivalent
B N

^
p(t)B
p(t0 )Y

_

(t 6= t0 )

p(t)A

Thus claim follows.

(p(t)

^


6= t0 ) .

p(t0 )Y


176

fiFirst-Order Stable Model Semantics First-Order Loop Formulas

A.10 Proof Proposition 16
Proposition 16 Let P LW-program let F FOL-representation set
rules P . following conditions equivalent other:
(a) answer set P according Lin Wang (2008);
(b) P -interpretation satisfies SM[F ];
(c) P -interpretation satisfies F loop formulas loops
F w.r.t. I.
Given program , Norm() normal form Ground () ground program
obtained described Lin Wang (2008). proof Proposition 16 follows
following lemma. refer readers work Lin Wang definition
ES (, , ) defined there.
Lemma
21 program set ground atoms, ES Norm() (Y ) equivalent
W
p(c)Y ES (p(c), Y, Ground ()).
Proof. definition, ES Norm() (Y )

_
z B N x =

^


(t 6= ) ,
0

(66)

q(t)B
q(t0 )Y

p(x)B,N,x=t Norm()
:p(x)Y

x list distinct object variables, substitution maps variables x
object constants occurring , z list variables occur rule
p(x) B, N , x = t. (66) equivalent


_
^
0
0
z B N = c
(t 6= ) ,
(67)
p(t)B,N
p(c)Y

q(t)B
q(t0 )Y

z0 list variables occur rule p(t) B, N . turn, (67)
equivalent


_
^
0
0
0
(tg 6= ) .
(68)
B N d=c
p(d)B 0 ,N 0 Ground()
p(c)Y

q(tg )B 0
q(t0 )Y

Note cover c, exists di di mentions constants
pre-interpreted functions di evaluated ci independent interpretations. case, = c equivalent . Thus (68) equivalent


_
_
^
0
0
0
(tg 6= ) ,
(69)
B N d=c
p(c)Y

essentially

p(d)B 0 ,N 0 Ground()
p(d) cover p(c)

W

p(c)Y

q(tg )B 0
q(t0 )Y

ES (p(c), Y, Ground ()).

177



fiLee & Meng

References
Asuncion, V., Lin, F., Zhang, Y., & Zhou, Y. (2010). Ordered completion first-order
logic programs finite structures. AAAI, pp. 249254.
Bonatti, P. A. (2004). Reasoning infinite stable models. Artificial Intelligence, 156 (1),
75111.
Chen, Y., Lin, F., Wang, Y., & Zhang, M. (2006). First-order loop formulas normal
logic programs. Proceedings International Conference Principles Knowledge
Representation Reasoning (KR), pp. 298307.
Chen, Y., Lin, F., Zhang, Y., & Zhou, Y. (2011). Loop-separable programs firstorder definability. Artificial Intelligence, 175 (3-4), 890913.
Chen, Y., Zhang, Y., & Zhou, Y. (2010). First-order indefinability answer set programs
finite structures. AAAI, pp. 285290.
Clark, K. (1978). Negation failure. Gallaire, H., & Minker, J. (Eds.), Logic Data
Bases, pp. 293322. Plenum Press, New York.
de Bruijn, J., Pearce, D., Polleres, A., & Valverde, A. (2010). semantical framework
hybrid knowledge bases. Knowl. Inf. Syst., 25 (1), 81104.
Ferraris, P., Lee, J., & Lifschitz, V. (2006). generalization Lin-Zhao theorem.
Annals Mathematics Artificial Intelligence, 47, 79101.
Ferraris, P., Lee, J., & Lifschitz, V. (2007). new perspective stable models. Proceedings International Joint Conference Artificial Intelligence (IJCAI), pp. 372379.
Ferraris, P., Lee, J., & Lifschitz, V. (2011). Stable models circumscription. Artificial
Intelligence, 175, 236263.
Gebser, M., Lee, J., & Lierler, Y. (2006). Elementary sets logic programs. Proceedings
National Conference Artificial Intelligence (AAAI), pp. 244249.
Gebser, M., Lee, J., & Lierler, Y. (2011). elementary loops logic programs. Theory
Practice Logic Programming, appear.
Gebser, M., & Schaub, T. (2005). Loops: Relevant redundant?. Proceedings
Eighth International Conference Logic Programming Nonmonotonic Reasoning
(LPNMR05), pp. 5365.
Gelfond, M., & Lifschitz, V. (1988). stable model semantics logic programming.
Kowalski, R., & Bowen, K. (Eds.), Proceedings International Logic Programming
Conference Symposium, pp. 10701080. MIT Press.
Kim, T.-W., Lee, J., & Palla, R. (2009). Circumscriptive event calculus answer set programming. Proceedings International Joint Conference Artificial Intelligence
(IJCAI), pp. 823829.
Kunen, K. (1987). Negation logic programming. Journal Logic Programming,
4 (4), 289 308.
Lee, J. (2004). Nondefinite vs. definite causal theories. Proceedings 7th Intl Conference
Logic Programming Nonmonotonic Reasoning, pp. 141153.
178

fiFirst-Order Stable Model Semantics First-Order Loop Formulas

Lee, J. (2005). model-theoretic counterpart loop formulas. Proceedings International Joint Conference Artificial Intelligence (IJCAI), pp. 503508.
Lee, J., Lierler, Y., Lifschitz, V., & Yang, F. (2010). Representing synonymity causal logic
logic programming. Proceedings International Workshop Nonmonotonic Reasoning (NMR). http://peace.eas.asu.edu/joolee/papers/syn.pdf.
Lee, J., & Lifschitz, V. (2003). Loop formulas disjunctive logic programs. Proceedings
International Conference Logic Programming (ICLP), pp. 451465.
Lee, J., Lifschitz, V., & Palla, R. (2009). Safe formulas general theory stable models.
Technical Report. http://peace.eas.asu.edu/joolee/papers/safety.pdf.
Lee, J., & Lin, F. (2006). Loop formulas circumscription. Artificial Intelligence, 170 (2),
160185.
Lee, J., & Meng, Y. (2008). loop formulas variables. Proceedings International Conference Knowledge Representation Reasoning (KR), pp. 444453.
Lee, J., & Palla, R. (2011). Integrating rules ontologies first-order stable model
semantics (preliminary report). Proceedings International Conference Logic
Programming Nonmonotonic Reasoning (LPNMR), pp. 248253.
Lifschitz, V. (1994). Circumscription. Gabbay, D., Hogger, C., & Robinson, J. (Eds.),
Handbook Logic AI Logic Programming, Vol. 3, pp. 298352. Oxford University Press.
Lifschitz, V., Morgenstern, L., & Plaisted, D. (2008). Knowledge representation classical
logic. van Harmelen, F., Lifschitz, V., & Porter, B. (Eds.), Handbook Knowledge
Representation, pp. 388. Elsevier.
Lin, F., & Shoham, Y. (1992). logic knowledge justified assumptions. Artificial
Intelligence, 57, 271289.
Lin, F., & Wang, Y. (2008). Answer set programming functions. Brewka, G., &
Lang, J. (Eds.), Proceedings International Conference Principles Knowledge
Representation Reasoning (KR), pp. 454465. AAAI Press.
Lin, F., & Zhao, Y. (2004). ASSAT: Computing answer sets logic program SAT
solvers. Artificial Intelligence, 157, 115137.
Lin, F., & Zhou, Y. (2011). answer set logic programming circumscription via logic
GK. Artificial Intelligence, 175, 264277.
Liu, L., & Truszczynski, M. (2006). Properties applications programs monotone
convex constraints. J. Artif. Intell. Res. (JAIR), 27, 299334.
McCarthy, J. (1980). Circumscriptiona form non-monotonic reasoning. Artificial Intelligence, 13, 2739,171172.
McCarthy, J. (1986). Applications circumscription formalizing common sense knowledge. Artificial Intelligence, 26 (3), 89116.
Pearce, D., & Valverde, A. (2005). first order nonmonotonic extension constructive
logic. Studia Logica, 80, 323348.
179

fiLee & Meng

Robinson, J. A. (1965). machine-oriented logic based resolution principle. J. ACM,
12, 2341.
Sabuncu, O., & Alpaslan, F. N. (2007). Computing answer sets using model generation
theorem provers. Unpublished Draft.
You, J.-H., & Liu, G. (2008). Loop formulas logic programs arbitrary constraint
atoms. Proceedings AAAI Conference Artificial Intelligence (AAAI), pp.
584589.
Zhang, Y., & Zhou, Y. (2010). progression semantics boundedness answer
set programs. Proceedings International Conference Principles Knowledge
Representation Reasoning (KR), pp. 518526.

180

fiJournal Artificial Intelligence Research 42 (2011) 393-426

Submitted 04/11; published 11/11

Making Decisions Using Sets Probabilities:
Updating, Time Consistency, Calibration
Peter D. Grunwald

pdg@cwi.nl

CWI, P.O. Box 94079
1090 GB Amsterdam, Netherlands

Joseph Y. Halpern

halpern@cs.cornell.edu

Computer Science Department
Cornell University
Ithaca, NY 14853, USA

Abstract
consider agent update beliefs beliefs represented
set P probability distributions, given agent makes decisions using minimax
criterion, perhaps best-studied commonly-used criterion literature.
adopt game-theoretic framework, agent plays bookie, chooses
distribution P. consider two reasonable games differ
bookie knows makes choice. Anomalies observed before, like
time inconsistency, understood arising different games played,
bookies different information. characterize important special cases
optimal decision rules according minimax criterion amount either
conditioning simply ignoring information. Finally, consider relationship
updating calibration uncertainty described sets probabilities.
results emphasize key role rectangularity condition Epstein Schneider.

1. Introduction
Suppose agent models uncertainty domain using set P probability
distributions. agent update P light observing random variable
X takes value x? Perhaps standard answer condition distribution P
X = x (more precisely, condition distributions P give X = x positive
probability X = x), adopt resulting set conditional distributions P | X = x
representation uncertainty. contrast case P singleton,
often clear whether conditioning right way update set P. turns
general, single right way update P. Different updating methods
satisfy different desirata, sets P, desiderata satisfied
time. paper, determine extent conditioning related
update methods satisfy common decision-theoretic optimality properties. main three
questions pose are:
1. conditioning right thing minimax criterion, is, lead
minimax-optimal decision rules?
2. minimax criterion reasonable sense satisfies consistency
criteria time consistency (defined formally below)?
c
2011
AI Access Foundation Morgan Kaufmann Publishers. rights reserved.

fiGrunwald & Halpern

3. conditioning right thing calibration criterion?
show answer first two questions yes P satisfies condition
Epstein Schneider (2003) call rectangularity, answer third question
yes P convex satisfies rectangularity condition.1 Thus, main contribution
paper show that, rectangularity condition, conditioning right
thing wide variety criteria. Apart main conclusion, analysis
provides new insights relation minimax optimality, time consistency,
variants conditioning (such ignoring information X = x altogether).
discuss contributions detail.
1.1 Minimax Criterion, Dilation, Time Inconsistency
agent make decisions based set P distributions? Perhaps best-studied
commonly-used approach literature use minimax criterion (Wald,
1950; Gardenfors & Sahlin, 1982; Gilboa & Schmeidler, 1989). According minimax
criterion, action a1 preferred action a2 worst-case expected loss a1 (with
respect probability distributions set P consideration) better
worst-case expected loss a2 . Thus, action chosen one best worstcase outcome.
pointed several authors, conditioning set P observation X = x
sometimes leads phenomenon called dilation (Augustin, 2003; Cozman & Walley, 2001;
Herron, Seidenfeld, & Wasserman, 1997; Seidenfeld & Wasserman, 1993): agent may
substantial knowledge random variable observing X = x,
know significantly less conditioning. Walley (1991, p. 299) gives simple example
dilation: suppose fair coin tossed twice, second toss may depend
arbitrary way first. (In particular, tosses might guaranteed
identical, guaranteed different.) X represents outcome first toss
represents outcome second toss, observing X, agent believes
probability heads 1/2, observing X, agent believes
probability heads arbitrary element [0, 1].
While, example others provided Walley show, dilation quite
reasonable, interacts rather badly minimax criterion, leading anomalous
behavior called time inconsistency (Grunwald & Halpern, 2004; Seidenfeld,
2004): minimax-optimal conditional decision rule value X observed
(which form X = 0 a1 ; X = 1 a2 ; . . . ) may different
minimax-optimal decision rule conditioning. example, minimax-optimal
conditional decision rule may say X = 0 a1 , minimax-optimal decision
rule conditional observing X = 0 may a2 . (See Example 2.1.) uncertainty
modeled using single distribution, time inconsistency cannot arise.
1.2 Two Games understand phenomenon better, model decision
problem game agent bookie (for recent approach similar
spirit done independently, see Ozdenoren & Peck, 2008). turns
one possible game considered, depending information
1. results proved assumption domain probability measures P
finite set actions decision maker choosing among finite.

394

fiMaking Decisions Using Sets Probabilities

bookie has. focus two (closely related) games here. first game, bookie
chooses distribution P agent moves. show Nash equilibrium
game leads minimax decision rule. (Indeed, viewed justification
using minimax criterion). However, game, conditioning information
always optimal.2 second game, bookie gets choose distribution
value X observed. Again, game, Nash equilibrium leads use
minimax, conditioning right thing do.
P singleton, two games coincide (since one choice bookie
make, agent knows is). surprisingly, conditioning appropriate
thing case. moral analysis that, uncertainty characterized
set distributions, agent making decision using minimax criterion,
right decision depends game played. agent must consider
trying protect adversary knows value X = x choosing
distribution one know value X = x.
1.3 Rectangularity Time Consistency earlier work (Grunwald & Halpern,
2004) (GH on), essentially considered first game, showed that,
game, conditioning always right thing using minimax criterion.
Indeed, showed sets P games minimax-optimal decision rule
simply ignore information. analysis first game lets us go beyond GH
two ways. First, provide simple sufficient condition conditioning
information minimax optimal (Theorem 4.4). Second, provide sufficient condition
minimax optimal ignore information (Theorem 5.1).
sufficient condition guaranteeing conditioning minimax optimal
viewed providing sufficient condition time consistency. condition essentially
Epstein Schneiders (2003) rectangularity condition, showed sufficient
guarantee called decision theory community dynamic consistency.
Roughly speaking, dynamic consistency says if, matter agent learns,
prefer decision rule decision rule 0 , prefer 0 learning
anything. Dynamic consistency closely related Savages (1954) sure-thing principle.
Epstein Schneider show that, agents uncertainty represented using sets
probability distributions, observations possible (in setting, means
probability distributions agent considers possible assign positive probability
basic events form X = x), set distributions satisfies rectangularity condition then, matter agents loss function,3 agent prefers 0
making observation, also prefer 0 making observation. Conversely, show agents preferences dynamically consistent,
agents uncertainty represented set probability measures satisfies
rectangularity condition, agent viewed making decisions using
minimax criterion.
results show observations possible rectangularity condition
holds, then, matter loss function, time consistency holds. Time consistency
2. senses words conditioning optimal, conditioning information
always optimal. discussed Section 7.
3. work loss functions paper rather utility functions, since losses seem somewhat
standard literature. However, could trivially restate results terms utility.

395

fiGrunwald & Halpern

holds decision minimax optimal making observation iff optimal
making observation. Note time consistency considers optimal decision,
dynamic consistency considers whole preference order. However, time consistency
iff requirement: decision optimal making observation
decision optimal making observation. way contrast, dynamic
consistency uni-directional: preferred a0 making observation,
must still preferred making observation.
results show uncertainty represented rectangular set measures,
observations possible, minimax criterion used, dynamic consistency
time consistency hold. hand, show Proposition 4.7, general
dynamic consistency time consistency incomparable.
1.4 C-conditioning Calibration stated, provide general condition P
conditioning minimax optimal, well general condition
ignoring information minimax optimal. Note ignoring information also
viewed result conditioning; conditioning information, conditioning
whole space. leads us consider generalization conditioning. Let C
partition set values random variable X, let C(x) element
partition contains x. Suppose observe x, condition event
X C(x). call variant conditioning C-conditioning; standard conditioning
special case element C singleton. C-conditioning always minimax
optimal first game? is, always optimal condition something?
show considering variation Monty Hall Problem (Example 5.4),
case general.
Nevertheless, turns considering C-conditioning useful; underlies
analysis calibration. pointed Dawid (1982), agent updating beliefs
making decisions basis beliefs also concerned
calibrated. Calibration usually defined terms empirical data. explain
means connection decision making, consider agent weather forecaster
local television station. Every night forecaster makes prediction whether
rain next day area live. asserting
probability rain p, p {0, 0.1, . . . , 0.9, 1}. interpret
probabilities? usual interpretation that, long run, days
weather forecaster predict probability p, rain approximately 100p% time.
Thus, example, among days predicted 0.1, fraction days
rain close 0.1. weather forecaster property said calibrated.
weather forecaster calibrated, make bets which, based probabilistic
predictions, seem favorable, long run cannot lose money.
hand, weather forecaster calibrated, exist bets may seem favorable
result loss. clearly close connection calibration decision
making.
Calibration usually defined relative empirical data singleton distributions.
first consider obvious extension sets probabilities, obvious extension turns
weak requirement. therefore define stronger arguably
interesting variation call sharp calibration. take update rule map set
396

fiMaking Decisions Using Sets Probabilities

P value x new set (P, x) probabilities. Intuitively, (P, x) result
updating P given observation X = x, according update rule . calibrated update
rule sharply calibrated P rule 0 also calibrated
that, x, 0 (P, x) (P, x), x, inclusion strict. first show
P convex, C-conditioning sharply calibrated C; different choices
P require different C. show that, P also satisfies rectangularity condition,
standard conditioning sharply calibrated.
1.5 Discussion idea representing uncertainty set P distributions
handling decisions worst-case optimal manner may, course, criticized.
claim necessarily right best approach,
worth pointing two common criticisms are, extent, unjustified.
First, since may hard agent determine precise boundaries set P,
argued soft boundaries appropriate. soft boundaries
may thought inducing single distribution (X Y), set probability
distributions X (with density Pr (X Y) proportional extent
Pr included set P). single distribution, setting becomes
equivalent setting standard Bayesian decision theory. problem
criticism cases, hard boundaries fact natural. example,
conditional probabilities may known precisely 0, case Monty Hall
game (Example 5.4). Similarly, use minimax criterion pessimistic
often thought. minimax solution often coincides Bayes-optimal solution
maximum entropy prior (Grunwald & Dawid, 2004), commonly
associated overly pessimistic. fact, Monty Hall problem, minimaxoptimal decision rule coincides solution usually advocated, requires making
assumptions P reduce singleton.
rest paper organized follows. Section 2, define basic framework.
Section 3, formally define two games described show minimaxoptimal decision rule gives Nash equilibrium. Section 4, characterize minimaxoptimal decision rule first game, bookie chooses distribution
X observed. Section 5 discuss C-conditioning show that, general,
minimax optimal. Section 6, discuss calibration C-conditioning. conclude
discussion Section 7. proofs found appendix.

2. Notation Definitions
paper, uncertainty represented set P probability distributions. ease
exposition, assume throughout paper interested two random variables,
X , take values spaces X Y, respectively. P always denotes set
distributions X Y; is, P (X Y), (S) denotes set probability
distributions S. ease exposition, assume P closed set; standard
assumption literature seems quite natural applications, makes
statement results simpler (otherwise state results using closures).
Pr (X Y), let PrX PrY denote marginals Pr X Y, respectively. Let
PY = {PrY : Pr P}. E X Y, let P | E = {Pr | E : Pr P, Pr(E) > 0}.
397

fiGrunwald & Halpern

Pr | E (often written Pr( | E)) distribution X obtained conditioning
E.
represesentation uncertainty using sets probability distributions closely
related Walleys (1991) use (lower upper) previsions. prevision expectation
function; is, lower prevision mapping random variables reals satisfying
certain properties. well known (Huber, 1981) Walley calls coherent lower
prevision (a lower prevision satisfying minimal properties) identified
lower expectation set probability measures (that is, function E
E(X) = inf PrP EPr (X)). Indeed, one-to-one map lower previsions
closed convex sets probability measures. notion conditioning using
corresponds Walley calls regular extension lower prevision (see Walley,
1991, Appendix J).
2.1 Loss Functions GH, interested agent must choose
action set A, loss action depends value random
variable . assume paper X , Y, finite, |A| 2,
always least two possible choices. (If allowed singleton,
results would hold trivial reasons.)
assume action value associated loss
agent. (The losses negative, amounts gain.) Let L : IR
loss function.
loss functions arise quite naturally. example, medical setting, take
consist possible diseases X consist symptoms. set consists
possible courses treatment doctor choose. doctors loss function depends
patients disease course treatment, symptoms. But,
general, doctors choice treatment depends symptoms observed.
2.3 Decision Problems Decision Settings purposes, decision setting
tuple DS = (X , Y, A, P), X , Y, A, P above. decision problem
characterized tuple DP = (X , Y, A, P, L), L loss function. is,
decision problem decision setting together loss function. say decision
problem (X , Y, A, P, L) based decision setting (X , Y, A, P).
2.4 Decision Rules Given decision problem DP = (X , Y, A, P, L), suppose
agent observes value variable X. observed X, must perform
act, quality judged according loss function L. agent must choose
decision rule determines function observations. allow
decision rules randomized. Thus, decision rule function : X (A)
chooses distribution actions based agents observations. Let D(X , A)
set decision rules. special case deterministic decision rule, assigns
probability 1 particular action. deterministic, sometimes abuse notation
write (x) action assigned probability 1 distribution (x). Given
decision rule loss function L, let L random variable X
P
L (x, y) = aA (x)(a)L(y, a). (x)(a) stands probability performing
action according distribution (x) actions adopted x observed.
Note special case deterministic decision rule, L (x, y) = L(y, (x)).
398

fiMaking Decisions Using Sets Probabilities

also extend notation randomized actions: (A), let L random
P
variable L (y) = aA (a)L(y, a).
decision rule 0 priori minimax optimal decision problem DP
max EPr [L0 ] =

PrP

min

D(X ,A)

maxPrP EPr [L ].

is, 0 priori minimax optimal 0 gives best worst-case expected loss
respect distributions Pr. write max instead sup
assumption P closed. ensures Pr P EPr [L0 ]
takes maximum value.
decision rule 1 posteriori minimax optimal DP if, x X
Pr(X = x) > 0 Pr P,
max

PrP|X=x

EPr [L1 ] =

min

max

D(X ,A) PrP|X=x

EPr [L ].

(1)

get posteriori minimax-optimal decision rule obvious thing: x
observed, simply condition probability distribution Pr P X = x, choose
action gives least expected loss (in worst case) respect P | X = x.
Since distributions Pr mentioned (1) satisfy Pr(X = x) = 1, minimum
D(X , A) depend values (x0 ) x0 6= x; minimum effectively
randomized actions rather decision rules.
following example, taken GH, shows, priori minimax-optimal decision
rules general different posteriori minimax-optimal decision rules.
Example 2.1: Suppose X = = = {0, 1} P = {Pr (X Y) : PrY (Y =
1) = 2/3}. Thus, P consists distributions whose marginal gives = 1 probability
2/3. think actions predictions value . loss function 0
right value predicted 1 otherwise; is, L(i, j) = |i j|. so-called
0/1 classification loss. easy see optimal priori decision rule choose
1 matter observed (which expected loss 1/3). Intuitively, observing value
X tells us nothing value , best decision predict according
prior probability = 1. However, probabilities = 1 compatible
observing either X = 0 X = 1. is, (P | X = 0)Y (P | X = 1)Y consist
distributions Y. Thus, minimax optimal posteriori decision rule randomizes
(with equal probability) = 0 = 1.
summarize, make decisions according minimax optimality criterion,
making observation, predict = 1. However, matter observation make, making observation, randomize (with equal probability)
predicting = 0 = 1. Moreover, know even making observation opinion best decision rule change way. (Note
example time inconsistency dynamic inconsistency.)
2.5 Time Dynamic Consistency Formally, decision problem DP time consistent iff, decision rules , priori minimax optimal DP iff posteriori
minimax optimal. say DP weakly time consistent every posteriori minimax
optimal rule DP also priori minimax optimal DP . decision setting DS
(weakly) time consistent every decision problem based DS is.
399

fiGrunwald & Halpern

Following Epstein Schneider (2003), say decision problem DP dynamically consistent every pair , 0 decision rules, following conditions hold:
1. If, x Pr(X = x) > 0 Pr P,
max

Pr(P|X=x)

EPr [L ]

max

Pr(P|X=x)

EPr [L0 ],

(2)


max EPr [L ] max EPr [L0 ].

PrP

PrP

(3)

2. If, x Pr(X = x) > 0 Pr P, strict inequality
(2), (3) must hold strict inequality well.
Informally, dynamic consistency means whenever preferred 0 according
minimax criterion posteriori, also preferred 0 according minimax
criterion priori, whenever posteriori preference strict possible
observations, priori preference must strict well.
decision setting DS dynamically consistent every decision problem based DS
is.

3. Two Game-Theoretic Interpretations P
mean agents uncertainty characterized set P probability
distributions? understand P? give P game-theoretic interpretation
here: namely, adversary gets choose distribution set P.4
completely specify game. must also specify adversary makes choice.
consider two times adversary choose: first agents observes
value X , second after. formalize two different games,
take adversary bookie.
call first game P-game. defined follows:
1. bookie chooses distribution Pr P.
2. value x X chosen (by nature) according PrX observed bookie
agent.
3. agent chooses action A.
4. value chosen according Pr | X = x.
5. agents loss L(y, a); bookies loss L(y, a).
zero-sum game; agents loss bookies gain. game, agents
strategy decision rule, is, function gives distribution actions
observed value X. bookies strategy distribution distributions P.
consider second interpretation P, characterized different game
gives bookie power. Rather choosing distribution observing
value X, bookie gets choose distribution observing value. call
P-X-game. Formally, specified follows:
4. interpretation remains meaningful several practical situations explicit adversary;
see final paragraph section.

400

fiMaking Decisions Using Sets Probabilities

1. value x X chosen (by nature) according procedure guaranteed
end value x Pr(X = x) > 0 Pr P, observed
bookie agent.5
2. bookie chooses distribution Pr P Pr(X = x) > 0.6
3. agent chooses action A.
4. value chosen according Pr | X = x.
5. agents loss L(y, a); bookies loss L(y, a).
Recall pair strategies (S1 , S2 ) Nash equilibrium neither party
better unilaterally changing strategies. If, case, (S1 , S2 ) Nash equilibrium
zero-sum game, also known saddle point; S1 must minimax strategy,
S2 must maximin strategy (Grunwald & Dawid, 2004). following results show,
agent must using priori minimax-optimal decision rule Nash equilibrium
P-game, posteriori minimax-optimal decision rule Nash equilibrium
P-X-game. viewed justification using (a priori posteriori)
minimax-optimal decision rules.
Theorem 3.1: Fix X , Y, A, L, P (X Y).
(a) P-game Nash equilibrium ( , ), distribution P
finite support.
(b) ( , ) Nash equilibrium P-game finite support,
(i) every distribution Pr0 P support ,
EPr0 [L ] = maxPrP EPr [L ];
(ii) Pr = PrP, (Pr)>0 (Pr) Pr (i.e., Pr convex combination
distributions support , weighted probability according ),

P

EPr [L ] =
=
=
=

minD(X ,A) EPr [L ]
maxPrP minD(X ,A) EPr [L ]
minD(X ,A) maxPrP EPr [L ]
maxPrP EPr [L ].

nature chosen value X P-X-game, regard steps 25
P-X-game game bookie agent, bookies strategy characterized distribution P | X = x agents characterized distribution
actions. call P-x-game.
Theorem 3.2: Fix X , Y, A, L, P (X Y).
5. x observed parties, chosen x chosen, procedure nature
chooses x irrelevant. could assume definiteness nature chooses uniformly random among
values x Pr(x) > 0 Pr P, choice would work equally well.
6. consider conditional probability distributions (de Finetti, 1936; Popper, 1968),
Pr(Y = | X = x) defined even Pr(X = x) = 0, could drop restriction x chosen
Pr(X = x) > 0 Pr P.

401

fiGrunwald & Halpern

(a) P-x-game Nash equilibrium ( , (x)), distribution
P | X = x finite support.
(b) ( , (x)) Nash equilibrium P-x-game finite support,

(i) Pr0 support , EPr0 [L ] = maxPrP|X=x EPr [L ];
P
(ii) Pr = PrP, (Pr)>0 (Pr) Pr,
EPr [L ] =
=
=
=

minD(X ,A) EPr [L ]
maxPrP|X=x minD(X ,A) EPr [L ]
minD(X ,A) maxPrP|X=x EPr [L ]
maxPrP|X=x EPr [L ].

Since distributions Pr expression minD(X ,A) maxPrP|X=x EPr [L ] part (b)(ii)
P | X = x, (1), minimum effectively randomized actions rather
decision rules.
Theorems 3.1 3.2 viewed although, according definition,
time inconsistency, viewed properly, real inconsistency here; rather,
must careful game played. P-game played,
right strategy priori minimax-optimal strategy, value
X observed; similarly, P-X-game played, right strategy
posteriori minimax-optimal strategy, value X observed.
Indeed, thinking terms games explains apparent time inconsistency.
games, agent gains information observing X = x. P-X game,
bookie. information may use bookie agent, so,
game, agent worse given opportunity learn value X.
course, practical situations, agents (robots, statisticians,. . . ) really
confronted bookie tries make suffer. Rather, agents may
idea distribution holds, except set P. know
P, decide prepare worst-case play minimax strategy.
fact minimax strategy interpreted terms Nash equilibrium
game helps understand differences different forms minimax (such
priori posteriori minimax). point view, seems strange bookie
choose different distributions P according distribution . However,
P convex, replace distribution P single distribution P,
consists convex combination distributions support ;
distribution Pr Theorems 3.1 3.2. Thus, Theorems 3.1 3.2 hold bookie
restricted deterministic strategy.

4. Conditioning, Rectangularity, Time Consistency
get posteriori minimax-optimal decision rule obvious thing: x
observed, simply condition probability distribution Pr P X = x, choose
action gives least expected loss (in worst case) respect P | X = x.
might expect priori minimax-optimal decision rule
thing. is, decision rule says, x observed, choose
402

fiMaking Decisions Using Sets Probabilities

action gives best result (in worst case) respect P | X = x.
Example 2.1 shows cannot true general, since cases priori
optimal decision rule condition, ignore observed value X,
choose action gives least expected loss (in worst case) respect P,
matter value X has. later show cases optimal priori
rule neither condition ignore (see Example 5.4). goal section
show rectangularity condition Epstein Schneider (2003) suffices guarantee
conditioning optimal.
Definition 4.1: Let hPi, hull P, set
{Pr (X Y) : PrX PX and, Pr(X = x) 6= 0, (Pr | X = x) (P | X = x)} .

Thus, hPi consists distributions Pr whose marginal X marginal X
distribution P whose conditional observing X = x conditional
distribution P, x X . Clearly P hPi, converse necessarily
true, following example shows.
Example 4.2: Suppose X = = {0, 1}, Pr1 , Pr2 , Pr3 (X Y) defined
follows:
Pr1 (0, 0) = Pr1 (1, 0) = 1/3; Pr1 (0, 1) = Pr1 (1, 1) = 1/6;
Pr2 (0, 0) = Pr2 (1, 0) = 1/6; Pr2 (0, 1) = Pr2 (1, 1) = 1/3;
Pr3 (0, 0) = Pr3 (1, 1) = 1/3; Pr3 (0, 1) = Pr3 (1, 0) = 1/6.
Suppose P = {Pr1 , Pr2 }. Pr3 6 P, easy see Pr3 hPi.
(Pr1 )X = (Pr2 )X = (Pr3 )X uniform distribution X , Pr3 | (X = 0) = Pr1 | (X = 0),
Pr3 | (X = 1) = Pr2 | (X = 1).
Note also P Example 2.1, hPi = (X Y) 6= P. notion
hull arises number contexts. language Walley (1991), hull
P natural extension marginals PX collection sets conditional
probabilities P | X = x x X . Thus, P = hPi, reconstruct joint
probability distributions P PX collection sets conditional probabilities.
assumption P = hPi closely related set probabilities separately
specified, introduced da Rocha Cozman (2002). da Rocha Cozman point
out, assumption makes possible apply ideas Bayesian networks uncertainty
represented sets probability distributions.
condition P = hPi instance rectangularity condition goes back
least work Sarin Wakker (1998). introduced general form
Epstein Schneider (2003). Epstein Schneider define condition sequence
random variables X1 , . . . , Xt , support Xj necessarily finite.
special case = 2, X := X1 := X2 restricted finite support,
rectangularity condition exactly equivalent condition P = hPi.
403

fiGrunwald & Halpern

Considering hPi also gives insight two games considered Section 3. P-X -game, bookie power P-game, since gets
choose distribution agent observes x P-X -game, must choose
agent observes x P-game. means agent draw inferences
distribution bookie chose P-game. inferences cannot
drawn P = hPi. generally, precise sense, agent information
P-X -game hPi-game. Rather making formal (since
somewhat tangential main concerns), give example show intuition.
Example 4.3: Suppose X = = {0, 1}, P = {Pr1 , Pr2 },
Pr1 (0, 0) = (1 ), Pr1 (0, 1) = (1 )2 , Pr1 (1, 0) = (1 ), Pr1 (1, 1) = 2 ;
Pr2 (0, 0) = (1 ), Pr2 (0, 1) = 2 , Pr2 (1, 0) = (1 ), Pr2 (1, 1) = (1 )2 .
P-game, agent observes X = 0, almost certain
bookie chose Pr1 , thus almost certain = 1. hand, PX-game, agent observes x, idea whether bookie choose Pr1
Pr2 (since bookie makes choice observing x), idea whether
0 1. Note P 6= hPi; particular, distribution Pr3 hPi
(Pr3 )X = (Pr1 )X (Pr3 ) | (X = 0) = (Pr2 ) | (X = 0). example, take Pr3
Pr3 (0, 0) = (1 )2 Pr3 (0, 1) = (1 ) (the values Pr3 (1, 0) Pr3 (1, 1)
irrelevant, long sum nonnegative). Thus, observing
X = 0 hPi game, agent would idea value
P-X game.
key point us P = hPi, conditioning optimal, following
theorem shows. first need definition. call P conservative Pr P
x X , Pr(X = x) > 0.7
Theorem 4.4: Given decision setting DS = (X , Y, A, P) P = hPi,
decision problems DP based DS, exists priori minimax-optimal rule
also posteriori minimax optimal. Indeed, every posteriori minimax-optimal rule
also priori minimax optimal, DS DP weakly time consistent. Moreover, P
conservative, every decision problem DP based DS, every priori minimaxoptimal rule also posteriori minimax optimal, DS DP time consistent.
raises question whether qualification exists Theorem 4.4
necessary, whether converse theorem also holds. Example 4.5 shows
answer first question yes; Example 4.6 shows answer second
question no.
Example 4.5 : x X , exist Pr, Pr0 P Pr(X = x) = 0
Pr0 (X = x) > 0, may priori minimax decision rule
posteriori minimax. example, consider decision problem DP = (X , Y, A, P, L)
7. notion conservative corresponds Epstein Schneider (2003) call full support condition.

404

fiMaking Decisions Using Sets Probabilities

X = {0, 1}, = = {0, 1, 2}, L classification loss (Example 2.1) P = {Pr1 , Pr2 }.
first define Pr1 :
Pr1 (X = 1) = 1/2,
Pr1 (Y = 0 | X = 0) = Pr1 (Y = 1 | X = 0) = Pr1 (Y = 2 | X = 0) = 1/3,
Pr1 (Y = 0 | X = 1) = 1/2,
Pr1 (Y = 1 | X = 1) = 2/5,
Pr1 (Y = 2 | X = 1) = 1/10.
Pr2 defined follows: Pr2 (X = 0) = 1, j Y, Pr2 (Y = j, X = 0) = Pr2 (Y =
j | X = 0) := Pr1 (Y = j | X = 0). easy see P = hPi, rectangularity
condition holds.
Note (0), decision taken observing X = 0, affect expected
loss; Pr1 | X = 0 Pr2 | X = 0, uniform, expected loss 2/3, regardless (0). implies every decision rule (1) randomized combination
{0, 1} priori optimal, worst-case expected loss 2/3, since EPr2 [L ] = 2/3
EPr1 [L ] < 2/3. minimax optimal rules (1) = 1 posteriori optimal,
since player observes X = 1, knows distribution Pr1 , minimax
loss relative Pr1 1/2 action 0 3/5 action 1.
example Example 4.3, observing particular value X gives
information distribution P bookie chosen. Example 4.3, observing
X = 0 implies bookie almost certainly chose Pr1 P-game; present
example, observing X = 1 implies bookie certainly chose Pr1 P-game
P X game. note, however, observing X = x give information
distribution chosen bookie P X game exist Pr Pr0
P-game Pr(X = x) = 0 Pr0 (X = x) > 0. Pr Pr0 exists,
bookie completely free choose Pr P likes x observed,
observing x gives information Pr P chosen.
exist decision settings P conservative P 6= hPi, although still
weak time consistency. Hence, converse Theorem 4.4 hold general.
give example P.
Example 4.6: Let X = = = {0, 1} P = {Pr0 , Pr1 } Pr0 (X = 1) = Pr1 (X =
1) = 1/2 x {0, 1}, Pr0 (Y = 0 | X = x) = 1 Pr1 (Y = 1 | X = x) = 1. Clearly
P conservative P 6= hPi; example, distribution Pr3 Pr3 (X = 1) =
1/2, Pr3 (Y = 0 | X = 0) = 1, Pr3 (Y = 0 | X = 1) = 0 hPi P. Note X
independent respect Pr0 Pr1 . take arbitrary loss function
L. Since (Pr | X = x)Y contains two distributions, one Pr(Y = 1) = 0 one
Pr(Y = 1) = 1, minimax posteriori act play (0) = (1) = (1 ) 0 + 1
(i.e., act plays 0 probability 1 1 probability ),
chosen minimize f () = max{(1 )L(0, 0) + L(0, 1), (1 )L(1, 0) + L(1, 1)}.
simplicity, assume unique . (If not, must case
[0, 1] minimize expression, easy check L(0, 0) = L(0, 1) = L(1, 0) =
L(1, 1), time consistency holds trivially.)
405

fiGrunwald & Halpern

want show also priori minimax. easy check
max

Pr{Pr0 ,Pr1 }

L = f ( ),

f above. suffices show decision rule 0 , must
max

Pr{Pr0 ,Pr1 }

L0 f ( ),

Suppose (x) = (1 x ) 0 + x 1, x {0, 1}.
maxPr{Pr0 ,Pr1 } EP r [L0 ]
= max{ 21 ((1 0 )L(0, 0) + 0 L(0, 1) + (1 1 )L(0, 0) + 1 L(0, 1)),
1
2 ((1 0 )L(1, 0) + 0 L(1, 1) + (1 1 )L(1, 0) + 1 L(1, 1)}
= max{(1 )L(0, 0) + L(0, 1), (1 )L(1, 0) + L(1, 1)}, =
= f () f ( ).

0 +1
2

interesting compare Theorem 4.4 results Epstein Schneider
(2003). this, first compare notion time consistency notion
dynamic consistency. notions formally defined end Section 2.
results summarized Proposition 4.7. First need two definitions: Let P set
distributions X Y. decision problem based P form (X , Y, A, P, L)
arbitrary L. decision problem satisfies strong dynamic consistency
satisfies condition (2) definition dynamic consistency satisfies following
strengthening (3):
If, x Pr(X = x) > 0 Pr P, (2) holds, x
Pr(X = x) > 0,
max

Pr(P|X=x)

EPr [L ] <

max

Pr(P|X=x)

EPr [L0 ],

(4)

(3) must hold strict inequality.
Proposition 4.7:
(a) Every dynamically consistent decision problem also weakly time consistent.
(b) every dynamically consistent decision problem time consistent.
(c) Every strongly dynamically consistent decision problem time consistent.
(d) exist weakly time consistent decision problems dynamically consistent.
(e) decision problems based P dynamically consistent decision
problems based P weakly time consistent.
406

fiMaking Decisions Using Sets Probabilities

Proposition 4.7(c) shows comparison time consistency dynamic consistency subtle: replacing x x second half definition
dynamic consistency, leads perfectly reasonable requirement, suffices force
time consistency. Proposition 4.7(e) leads us suspect decision setting weakly
time consistent dynamically consistent. have, however, proof
claim. proof part (e) involves two decision problems based set P,
different sets actions, decision problems based
decision setting. seem straightforward extend result decision settings.
Epstein Schneider show, among things, P closed, convex, conservative, rectangular, DS dynamically consistent, hence weakly time
consistent. remark convexity assumption needed result. easy
check prefered 0 respect P according minimax criterion iff
preferred 0 respect convex closure P according minimax criterion. Proposition 4.7 shows dynamic time consistency closely related. Yet,
clear overlap prove Theorem 4.4 Epstein-Schneider
(ES on) result, general results incomparable. example,
already prove weak time consistency without assuming conservativeness; ES assume conservativeness throughout. hand, ES also show dynamic consistency
holds, agents actions viewed minimax optimal actions relative
rectangular convex conservative set; analogous result time consistency.
Moreover, contrast ES result, results hold restricted setting
two time steps, one one making single observation.

5. Belief Updates C-conditioning
section define notion belief update rule, belief represented
sets probabilities, introduce natural family belief update rules call
C-conditioning.
motivate notions, recall Example 2.1 shows minimax-optimal
priori decision rule always minimax-optimal posteriori decision
rule. example, minimax-optimal priori decision rule ignores information
observed. Formally, rule ignores information (x) = (x0 ) x, x0 X .
ignores information, define L0 random variable L0 (y) = L (x, y)
choice x. well defined, since L (x, y) = L (x0 , y) x, x0 X .
following theorem provides general sufficient condition ignoring information
optimal.

Theorem 5.1 : Fix X , Y, L, A, P (X Y). If, PrY PY , P contains distribution Pr0 X independent Pr0 , Pr0Y = PrY ,
priori minimax-optimal decision rule ignores information.
conditions, priori minimax-optimal decision rule ignores information,
essentially optimizes respect marginal ; is, maxPrP EPr [L ] =
maxPrY PY EPrY [L0 ].
407

fiGrunwald & Halpern

GH focused case PY singleton (i.e., marginal probability
distributions P) x, PY (P | X = x)Y . immediate
Theorem 5.1 ignoring information priori minimax optimal case.
Standard conditioning ignoring information instances C-conditioning,
turn instance update rule. define notions formally.
Definition 5.2: belief update rule (or update rule) function : 2(X Y) X
2(X Y) {} mapping set P distributions observation x nonempty set
(P, x) distributions; intuitively, (P, x) result updating P observation
x.
case P singleton {Pr}, one update rule conditioning; is,
({Pr}, x) = {Pr( | X = x)}. update rules possible, even single
distribution; example, Lewis (1976) considered approach updating called
imaging. even scope considering sets probabilities; example,
Walleys (1991) natural extension regular extension provide update rules (as
said, notion conditioning viewed instance Walleys regular extension).
Simply ignoring information provides another update rule: (P, x) = P. said above,
ignoring information standard conditioning instances C-conditioning.
Definition 5.3: Let C = {X1 , . . . , Xk } partition X ; is, Xi 6= = 1, . . . , k;
X1 . . . Xk = X ; Xi Xj = 6= j. x X , let C(x) cell containing x;
is, unique element Xi C x Xi . C-conditioning belief update rule
function defined taking (P, x) = P | C(x) (if Pr P, Pr(C(x)) = 0,
(P, x) undefined). decision rule based C-conditioning amounts
first updating set P P | C(x), taking minimax-optimal distribution
actions relative (P | C(x))Y . Formally, based C-conditioning if, x X
Pr(X = x) > 0 Pr P,
max

Pr(P|XC(x))Y

EPr [L(x) ] = min

max

(A) Pr(P|XC(x))Y

EPr [L ].

Standard conditioning special case C-conditioning, take C consist
singletons; ignoring information also based C-conditioning, C = {X }.
earlier results suggest perhaps priori minimax-optimal decision rule must based
C-conditioning C. Monty Hall problem shows conjecture
false.
Example 5.4 : [Monty Hall] (Mosteller, 1965; vos Savant, 1990): start
original Monty Hall problem, consider variant it. Suppose youre
game show given choice three doors. Behind one car; behind others
goats. pick door 1. opening door 1, Monty Hall, host (who knows
behind door) opens one two doors, say, door 3, goat.
asks still want take whats behind door 1, take whats behind door 2
instead. switch? may assume initially, car equally likely
behind doors.
408

fiMaking Decisions Using Sets Probabilities

formalize well-known problem P-game, follows: = {1, 2, 3} represents
door car behind. X = {G2 , G3 }, where, j {2, 3}, Gj corresponds
quizmaster showing goat behind door j. = {1, 2, 3}, action
corresponds door finally choose, Monty opened door 2 3.
loss function classification loss, L(i, j) = 1 6= j, is, choose
door goat behind it, L(i, j) = 0 = j, is, choose door
car. P set distributions Pr X satisfying
PrY (Y = 1) = PrY (Y = 2) = PrY (Y = 3) = 13
Pr(Y = 2 | X = G2 ) = Pr(Y = 3 | X = G3 ) = 0.
Note P satisfy rectangularity condition. example, let Pr
distribution Pr (G2 , 1) = Pr (G2 , 3) = 1/3 Pr (G3 , 1) = Pr (G3 , 2) = 1/6.
easy see Pr hPi P.
well known, easy show, priori minimax-optimal strategy always
switch doors, matter whether Monty opens door 2 door 3. Formally, let
decision rule (G2 ) = 3 (G3 ) = 2. unique priori minimaxoptimal decision rule (and expected loss 1/3). rule also posteriori minimax
optimal. modify problem small cost, say > 0, associated
switching. cost associated switching door 2 switching
door 3. long sufficiently small, action always switching still uniquely
priori minimax optimal. However, based C-conditioning. exist
two partitions X . corresponding two update rules based C-conditioning amount
to, respectively, (1) ignoring X, (2) conditioning X standard way. decision
rule based ignoring information stick door 1, cost associated
switching. decision rule based conditioning switch doors probability
1/(2 + ). see this, consider observation X = G2 , let randomized action
switching door 3 probability q sticking door 1 probability 1 q. Let
m(q) = maxPr(P|X=G2 )Y EP r [L ]. Thus, m(q) = maxp[0,1/2] (qp(1 + ) + (1 q)(1 p)).
Again, compute m(q), need consider happens extremes
interval; is, p = 0 p = 1/2, m(q) = max(1 q, (1 + q)/2). Clearly m(q)
minimized 1 q = (1 + q)/2, is, q = 1/(2 + ). similar analysis applies
observation X = G3 . Thus, neither decision rules based conditioning
minimax optimal.
Although C-conditioning guarantee minimax optimality, turns useful
notion. show next section, quite relevant consider calibration.

6. Calibration
said introduction, Dawid (1982) pointed agent updating
beliefs want calibrated. section, consider effect requiring calibration. now, calibration considered uncertainty characterized
single distribution. generalize notion calibration setting,
uncertainty characterized set distributions. investigate connection
409

fiGrunwald & Halpern

calibration conditions considered earlier, specifically
conditions P convex P = hPi.8
Calibration typically defined respect empirical data. view set P
distributions describing empirical data, defining agents uncertainty
regarding true distribution. want define calibration setting.
case P singleton, already done, example, Vovk, Gammerman,
Shafer (2005). 9 Below, first define calibration case P singleton,
extend notion general P.
Let update rule ({Pr}, x) contains single distribution
x X (for example, could ordinary conditioning). Given x X , define
[x],P = {x0 : ((P, x0 ))Y = (P, x)Y }. Thus, [x],P consists values x0 that,
observed, lead updated marginal distributions x.
Definition 6.1 : update rule calibrated relative Pr if, x X ,
Pr([x],{Pr} ) 6= 0, Pr( | [x],{Pr} )Y = ({Pr}, x)Y .10
words, definition says Pr0 distribution results updating
Pr observing x according marginalizing Y, calibrated Pr0
also marginal distribution results conditioning Pr set values x0 that,
observed, result Pr0 marginal distribution according . Intuitively,
x may observed, agent uses produces distribution ({Pr}, x).
agent may make decisions predictions based distribution,
marginalized Y. consider set P 0 distributions agent may use
predict observing value X. is, Pr0 P 0 iff positive Pr-probability
agent, observing value X, uses Pr0 predict . set P 0
|X | elements. Definition 6.1 says that, Pr0 P 0 , whenever agent predicts
Pr0 , agent correct sense distribution given agent
uses Pr0 indeed Pr0 . Note Definition 6.1, subsequent definitions
section, marginalize Y. discuss end section.
straightforward generalize Definition 6.1 sets P probability distributions
singletons, update rules map sets probabilities.
Definition 6.2: update rule calibrated relative P if, x X , Pr([x],P ) 6=
0 Pr P, (P | [x],P )Y = (P, x)Y .
want relate calibration C-conditioning. following result first step
direction. gives conditions standard conditioning calibrated, also
shows that, convex P arbitrary C, C-conditioning satisfies one two inclusions
required Definition 6.2.
8. Recall convexity innocuous assumption context time dynamic consistency.
However, show section, far innocuous context calibration.
9. Vovk et al.s setting somewhat different ours, interested upper bounds
on, rather precise values of, probabilities. result, definition validity (as call
notion calibration) somewhat different Definition 6.1, underlying idea same.
found definition literature coincides ours.
10. usual, X , identify P | P | (A Y).

410

fiMaking Decisions Using Sets Probabilities

Theorem 6.3:
(a) C-conditioning partition C X P convex then, x X ,
(P | [x],P )Y (P, x)Y .
(b) standard conditioning, P = hPi, x X , (P, x)Y (P | [x],P )Y .
Corollary 6.4 : P convex P = hPi, standard conditioning calibrated
relative P.
corollary significantly strengthened Theorem 6.12 below. general,
convexity P = hPi condition necessary Corollary 6.4, following two
examples show.
Example 6.5: Let X = = {0, 1}, let P = {Pr1 , Pr2 , Pr3 , Pr4 }, Pr1 , . . . , Pr4
defined sequence four numbers (a, b, c, d), Pri (0, 0) = a, Pri (0, 1) = b,
Pri (1, 0) = c, Pri (1, 1) = d):
Pr1 = (1/4, 1/4, 1/4, 1/4),
Pr2 = (1/8, 3/8, 1/8, 3/8),
Pr3 = (1/4, 1/4, 1/8, 3/8),
Pr4 = (1/8, 3/8, 1/4, 1/4).
Clearly P convex. Note Pr1 (Y = 0 | X = 0) = Pr1 (Y = 0 | X = 1) =
1/2, Pr2 (Y = 0 | X = 0) = Pr2 (Y = 0 | X = 1) = 1/4, Pr3 (Y = 0 | X = 0) = 1/2,
Pr3 (Y = 0 | X = 1) = 1/4. Since, Pr P, Pr(X = 0) = 1/2, (P | X = 0)Y =
(P | X = 1)Y = {Pra , Prb } Pra (Y = 0) = 1/2 Prb (Y = 0) = 1/4,
P = hPi. show standard conditioning calibrated relative P. Let
stand standard conditioning. x {0, 1},
(P, x)Y = (P | X = x)Y = {Pr01 , Pr02 },

(5)

Pr01 (Y = 0) = 1/2 Pr02 (Y = 0) = 1/4. also follows that, x {0, 1},
[x],P = {0, 1} = X ,
(P | [x],P )Y = PY .
(6)
Since PY contains distribution Pr03 Pr03 (Y = 0) = 3/8, (5) (6) together show
calibrated.
Example 6.6: Let X = = {0, 1}, let P consist distributions X
Pr(Y = 1) = 0.5. Clearly P convex. However, P =
6 hPi. see this, note P contains
distribution Pr Pr(Y = 0 | X = 0) = 1 distribution Pr0 Pr0 (X = 0) = 1,
distribution Pr00 Pr00 (X = 0) = 1 Pr00 (Y = 0 | X = 0) = 1. Let stand
standard conditioning. show calibrated. x {0, 1},
(P, x)Y = (P | X = x)Y = (Y),
411

(7)

fiGrunwald & Halpern

is, conditioning X = 0 X = 1 leads set distributions
Y. follows that, x {0, 1}, [x],P = {0, 1} = X ,
(P | [x],P )Y = PY = {Pr (Y) | Pr(Y = 1) = 0.5}.

(8)

Together, (7) (8) show calibrated.
Corollary 6.4 gives conditions standard conditioning calibrated. Theorem 6.3(a) gives general conditions C-conditioning satisfies one inclusion required calibration; specifically, (P | [x],P )Y (P, x)Y . Rather trying find
conditions inclusion holds, consider strengthening calibration, arguably interesting notion. For, following example shows,
calibration arguably weak requirement.
Example 6.7: Let X = = {0, 1}, let P = {Pr} consist distributions X
satisfying Pr(Y = X) = 1. rule ignores X, is, (P, x) = P
x {0, 1}, calibrated, even though (a) outputs distributions Y, (b)
exists another calibrated rule (standard conditioning) that, upon observing X = x, outputs
one distribution Y.
Intuitively, fewer distributions P, information P contains.
Thus, want restrict sets P small possible, still
calibrated.
Definition 6.8: Update rule 0 narrower update rule relative P if,
x X , 0 (P, x)Y (P, x)Y . 0 strictly narrower relative P inclusion strict
x. sharply calibrated exists update rule 0 strictly narrower
also calibrated.
show P convex, every sharply calibrated update rule must involve
C-conditioning. make precise, need following definition.
Definition 6.9: generalized conditioning update rule if, convex P, exists
partition C (that may depend P) x X , (P, x) = P | C(x).
Note that, long P convex, generalized conditioning rule, condition
partition X , partition may depend set P. example, convex
P, rule may ignore value x, whereas convex P, may amount
ordinary conditioning. Since interested generalized conditioning rules
P convex, behavior nonconvex P irrelevant. Indeed, next result shows that,
require P convex (and require P = hPi), C-conditioning
calibrated, indeed, sharply calibrated, C; moreover, every sharply calibrated
update rule must generalized conditioning rule.
Theorem 6.10: Suppose P convex.
(a) C-conditioning sharply calibrated relative P partition C.
412

fiMaking Decisions Using Sets Probabilities

(b) sharply calibrated relative P, exists C equivalent C-conditioning P (i.e., (P, x) = | C(x) x X ).
Corollary 6.11: exists generalized conditioning update rule sharply calibrated relative convex P. Moreover, every update rule sharply calibrated relative
convex P generalized conditioning update rule relative set convex P.
Theorem 6.10 establishes connection sharp calibration C-conditioning.
show conditions make standard conditioning calibrated also make
sharply calibrated.
Theorem 6.12: P convex P = hPi, standard conditioning sharply calibrated relative P.
result shows P = hPi condition Theorem 6.12 relevant
ensuring time consistency, also ensuring well-behavedness conditioning
terms calibration. Note, however, result says nothing C-conditioning
arbitrary partitions C. general, C-conditioning may sharply calibrated relative
convex P P = hPi, relative others. example, P singleton,
convex, P = hPi, update rule ignores x sharply calibrated.
Example 6.7, P also convex P = hPi, yet ignoring x sharply calibrated.
Remark results section based definition calibration
updated set distributions (P, x) marginalized Y. also possible define
calibration without marginalization. However, found makes less
interesting notion. example, without marginalizing longer seems
straightforward way defining sharp calibration, without sharpness, notion
quite limited interest. Moreover, seem possible state prove analogue
Theorem 6.3 (at least, know it).

7. Discussion Related Work
examined update uncertainty represented set probability distributions, motivate updating rules terms minimax criterion. key
innovation show different approaches understood terms
game bookie agent, bookie picks distribution set
agent chooses action making observation. Different approaches updating arise depending whether bookies choice made observation.
believe game-theoretic approach prove useful generally understanding different approaches updating. fact, publication conference
version paper, learned Ozdenoren Peck (2008) use type
approach analyzing dynamic situations related Ellsberg (1961) paradox. Like us,
Ozdenoren Peck resolve apparent time inconsistency describing decision problem
game agent bookie (called malevolent nature them).
do, point different games lead different Nash equilibria, hence different
minimax optimal strategies agent. particular, although precise definitions
413

fiGrunwald & Halpern

differ, game 1 similar spirit P-game, game 3 spirit
P-X-game.
(as well Ozdenoren Peck, 2008) prove results assumptions
set possible values X finite, set actions. would
interest extend results case sets infinite. extension
seems completely straightforward case set values set actions
countable, consider bounded loss functions (i.e. supyY,aA |L(y, a)| < ).
Indeed, believe results go without change case, although
checked details. However, allow uncountable set values,
subtleties arise. example, P-X game, required nature choose value
x given positive probability Pr P. may x
set possible values X interval [0, 1]; measures P may assign
individual points probability 0.
conclude paper giving overview senses conditioning
optimal senses not, uncertainty represented set
distributions. established conditioning full set P X = x minimax
optimal P-x-game, P-game. minimax-optimal decision rule
P-game often instance C-conditioning, generalization conditioning.
Monty Hall problem showed, however, always case. hand,
instead minimax criterion, insist update rules sharply calibrated,
P convex, C-conditioning always right thing all. While, general,
C may depend P (Theorem 6.10), P = hPi, take C(x) = {x}, standard
conditioning right thing (Theorem 6.12).
two senses conditioning right thing do. First, Walley
(1991) shows that, sense, conditioning updating rule coherent,
according notion coherence. justifies coherence decision theoretically,
using minimax criterion. Note minimax criterion puts total order
decision rules. is, say least good 0
max EPr [L ] max EPr [L0 ].

PrP

PrP

way contrast, Walley (1991) puts partial preorder11 decision rules taking
least good 0
max EPr [L L0 ] 0.
PrP

Since maxPrP EPr [L L0 ] maxPrP EPr [L0 L ] may positive, indeed
partial order. use ordering determine optimal decision rule then,
Walley shows, conditioning right thing do.
Second, paper, interpreted conditioning conditioning full given set
distributions P. conditioning always priori minimax optimal strategy
observation X = x. Alternatively, could first somehow select single Pr P,
condition Pr observed X = x, take optimal action relative Pr | X = x.
follows Theorem 3.1 minimax-optimal decision rule P-game
11. partial order reflexive, transitive, anti-symmetric, x x y, must
x = y. partial preorder reflexive transitive.

414

fiMaking Decisions Using Sets Probabilities

understood way. defines optimal response distribution Pr (X Y)
defined Theorem 3.1(b)(ii). P convex, Pr P. sense, minimaxoptimal decision rule always viewed instance conditioning, single
special Pr depends loss function L rather full set P.
worth noting Grove Halpern (1998) give axiomatic characterization
conditioning sets probabilities, based axioms given van Fraassen (1987, 1985)
characterize conditioning case uncertainty described single probability
distribution. Grove Halpern point out, axioms compelling
van Fraassen. would interesting know whether similar axiomatization
used characterize update notions considered here.

Acknowledgments
preliminary version paper appears Uncertainty Artificial Intelligence, Proceedings Eighteenth Conference, 2008, title Game-Theoretic Analysis
Updating Sets Probabilities. present paper expands conference version
several ways. importantly, section calibration entirely rewritten,
significant error corrected. would like thank Wouter Koolen, pointed
error previous version Definition 5.3, anonymous referees
thoughtful remarks. Peter Grunwald also affiliated Leiden University, Leiden,
Netherlands. supported IST Programme European Community, PASCAL Network Excellence, IST-2002-506778. Joseph Halpern supported
part NSF grants ITR-0325453, IIS-0534064, IIS-0812045, IIS-0911036,
AFOSR grant FA9550-05-1-0055 FA9550-08-1-0438, ARO grant
W911NF-09-1-0281.

Appendix A. Proofs
prove Theorems 3.1 Theorem 3.2, need two preliminary observations. first
characterization Nash equilibria. P-game, Nash equilibrium saddle point
amounts pair ( , ) distribution P randomized decision
rule
E EPr [L ] = minD(X ,A) E [EPr [L ]]
(9)
= maxPrP EPr [L ],
E [EPr [L ]] PrP, (Pr)>0 (Pr)EPr [L ]. P-x-game, Nash equilibrium pair ( , ) distribution P | X = x randomized
decision rule, (9) holds P replaced P | X = x.
second observation need following special case Theorem 3.2
work Grunwald Dawid (2004), extension Von Neumanns original minimax
theorem.
P

Theorem A.1: 0 finite set, P 0 closed convex subset (Y 0 ), A0 closed
convex subset IRk k , L0 : 0 A0 IR bounded function
that, 0 , L(y, a) continuous function a, exists Pr P 0
415

fiGrunwald & Halpern

A0 that,
EPr [L0 (Y 0 , )] = minA0 EPr [L0 (Y 0 , )]
= maxPrP 0 EPr [L0 (Y 0 , )].

(10)

observations, ready prove Theorem 3.1:
Theorem 3.1: Fix X , Y, A, L, P (X Y).
(a) P-game Nash equilibrium ( , ), distribution P
finite support.
(b) ( , ) Nash equilibrium P-game finite support,
(i) every distribution Pr0 P support ,
EPr0 [L ] = maxPrP EPr [L ];
(ii) Pr = PrP, (Pr)>0 (Pr) Pr (i.e., Pr convex combination
distributions support , weighted probability according ),

EPr [L ] = minD(X ,A) EPr [L ]
= maxPrP minD(X ,A) EPr [L ]
= minD(X ,A) maxPrP EPr [L ]
= maxPrP EPr [L ].
P

Proof: prove part (a), introduce new loss function L0 essentially equivalent
L, designed Theorem A.1 applied. Let 0 = X Y, let A0 = D(X , A),
define function L0 : 0 A0 IR
L0 ((x, y), ) := L (x, y) =

X

(x)(a)L(y, a).

aA

Obviously L0 equivalent L sense Pr (X Y), D(X , A),
EPr [L ] = EPr [L0 ((X, ), )].
view A0 = D(X , A) convex subset IR|X |(|A|1) , L0 ((x, y), a) becomes
continuous function A0 . Let P 0 convex closure P. Since X
finite, P 0 consists distributions Pr (X , Y) form c1 Pr1 + + ck Prk
k = |X Y|, Pr1 , . . . , Prk P c1 , . . . , ck nonnegative real coefficients
c1 + + ck = 1. Applying Theorem A.1 L0 P 0 , follows (10) holds
Pr P 0 A0 = D(X , A) (that is, (10) ). Thus, must
P
distribution P finite support Pr = PrP, (Pr)>0 (Pr) Pr.
easy see two equalities (10) literally two equalities (9). Thus,
( , ) Nash equilibrium. proves part (a).
prove part (b)(i), suppose first ( , ) Nash equilibrium P-game
finite support. Let V = maxPrP EPr [L ]. (9),
X

(Pr)EPr [L ] = V.

PrP, (Pr)>0

416

(11)

fiMaking Decisions Using Sets Probabilities

Trivially, Pr0 P, must EPr0 [L ] maxPrP EPr [L ]. inequality
strict Pr0 P support ,
X

(Pr)EPr [L ] < V,

PrP, (Pr)>0

contradicting (11). proves part (b)(i).
prove part (b)(ii), note straightforward arguments show
maxPrP EPr [L ]
minD(X ,A) maxPrP EPr [L ]
maxPrP minD(X ,A) EPr [L ]
minD(X ,A) EPr [L ].
(The second inequality follows because, Pr0 P, minD(X ,A) maxPrP EPr [L ]
minD(X ,A) EPr0 [L ].) Since ( , ) Nash equilibrium, part (b)(ii) immediate, using
equalities (9).
Theorem 3.2: Fix X , Y, A, L, P (X Y).
(a) P-x-game Nash equilibrium ( , (x)), distribution
P | X = x finite support.
(b) ( , (x)) Nash equilibrium P-x-game finite support,

(i) Pr0 support ,
EPr0 [L ] = maxPrP|X=x EPr [L ];
(ii) Pr =

P

PrP, (Pr)>0

=
=
=
=

(Pr) Pr,



EPr [L ]
minD(X ,A) EPr [L ]
maxPrP|X=x minD(X ,A) EPr [L ]
minD(X ,A) maxPrP|X=x EPr [L ]
maxPrP|X=x EPr [L ].

Proof: prove part (a), apply Theorem A.1, setting L0 = L, 0 = Y, A0 = (A),
P 0 convex closure P | X = x. Thus, (10) holds A0 , denote
(x). proof Theorem 3.1, must distribution P | X = x
P
finite support Pr = PrP|X=x, (Pr)>0 (Pr) Pr. remainder
argument identical Theorem 3.1.
proof part (b) completely analogous proof part (b) Theorem 3.1,
thus omitted.
Theorem 4.4: Given decision setting DS = (X , Y, A, P) P = hPi,
decision probems DP based DS, exists priori minimax-optimal rule
417

fiGrunwald & Halpern

also posteriori minimax optimal. Indeed, every posteriori minimax-optimal rule
also priori minimax-optimal rule. If, Pr P x X , Pr(X = x) > 0,
every decision problem based DS, every priori minimax-optimal rule also
posteriori minimax optimal.
Proof: Let X + = {x X : maxPrP Pr(X = x) > 0}. Let random variable
X defined taking (x) = 0 x
/ X + , (x) = maxPr0 P|X=x EPr0 [L ] x X + .
first show every D(X , A),
max EPr [L ] = max

PrP

PrP

X

PrX (X = x)m (x).

(12)

xX

Note
EPr [L ] =
=
=

=
=

P
Pr((X, ) = (x, y))L (x, y)
P(x,y)X
P
PrX (X = x) yY Pr(Y = x | X = x)L (x, y)
{xX
:Pr
(x)>0}
X
P
Pr (X = x)EPr|X=x [L ]
P{xX :PrX (x)>0} X
Pr (X = x) maxPr0 P|X=x EPr0 [L ]
P{xX :PrX (x)>0} X
Pr (X = x)m (x)
P{xX :PrX (x)>0} X
xX

PrX (X = x)m (x).

Taking max Pr P, get
max EPr [L ] max

PrP

PrP

X

PrX (X = x)m (x).

xX

remains show reverse inequality (12). Since P closed, exists Pr P

X
X
max
PrX (X = x)m (x) =
PrX (X = x)m (x).
PrP

xX

xX

Moreover, since P | X = x closed, x X + , exists Prx P | X = x
(x) = EPrx [L ]. Define Pr (X Y) taking
(

Pr ((X, ) = (x, y)) =

0
x
/ X+

x
PrX (X = x) Pr (Y = y) x X + .

Clearly PrX = PrX (Pr | X = x) = (Prx | X = x) P | X = x x X + . Thus,
definition, Pr hPi. Since, assumption, hPi = P, follows Pr P. addition,
easily follows
P
maxPrP xX PrX (X = x)m (x)
P
=
PrX (X = x)m (x)
PxX
P



=
xX + PrX (X = x)
= EPr [L ]
maxPrP EPr [L ].

yY

Pr (Y = | X = x)L (x, y)

establishes (12).
let priori minimax decision rule. Since P-game Nash equilibrium (Theorem 3.1), must exist. Let X 0 set x0 X
418

fiMaking Decisions Using Sets Probabilities

minimax optimal Px0 -game, i.e., x0 X 0 iff x X + maxPr0 P|X=x0 EPr0 [L ] >
minD(X ,A) maxPr0 P|X=x0 EPr0 [L ]. Define 0 decision rule agrees
X \ X 0 minimax optimal P | X = x0 game x0 X 0 ; is, 0 (x) = (x)
x
/ X 0 and, x X 0 ,
(x) argminD(X ,A)

max

Pr0 P|X=x0

EPr0 [L ].

construction, m0 (x) (x) x X m0 (x) < (x) x X 0 . Thus,
using (12),
maxPrP EPr [L0 ]
P
= maxPrP xX Pr(X = x)m0 (x)
P
(13)
maxPrP xX Pr(X = x)m (x)
= maxPrP EPr [L ].
Thus, 0 also priori minimax-optimal decision rule. But, construction, 0 also
posteriori minimax-optimal decision rule, follows exists least one
decision rule (namely, 0 ) priori posteriori minimax optimal.
proves first part theorem. prove last part, note Pr(X = x) > 0
Pr P x X , X 0 6= , inequality (13) strict. follows X 0
empty case, otherwise would priori minimax optimal, contradicting
assumptions. But, X 0 empty, must also posteriori minimax optimal.
remains show every posteriori minimax-optimal rule also priori minimax
optimal. x X , define mm(x) = 0 x 6 X + , mm(x) = min (x) x X + .
Let set posteriori minimax-optimal rules. already shown
least one element, say 0 , also priori minimax optimal.
x X , must (x) = mm(x). (12), follows every ,
P

maxPrP EPr [L ] = maxPrP xX PrX (X = x)m (x)
P
= maxPrP xX PrX (X = x)mm(x).
Hence,
max EPr [L ] = max EPr [L0 ].

PrP

PrP

Since 0 priori minimax optimal, implies priori minimax
optimal.
Proposition 4.7:
(a) Every dynamically consistent decision problem also weakly time consistent.
(b) every dynamically consistent decision problem time consistent.
(c) Every strongly dynamically consistent decision problem time consistent.
(d) exist weakly time consistent decision problems dynamically consistent.
(e) decision problems based P dynamically consistent decision
problems based P weakly time consistent.
419

fiGrunwald & Halpern

Proof: Part (a) immediate part 1 definition dynamic consistency. Part
(b) follows decision problem Example 4.5 dynamically consistent
time consistent. already showed time consistent. see
dynamically consistent, note every decision rule defined domain
example priori minimax optimal, part 1 definition dynamic consistency
holds automatically. Part 2 also holds automatically, since every two decision rules
0 , (2) hold strict inequality X = 0.
part (c), consider arbitrary decision problem DP strongly dynamically
consistent. easy construct posteriori minimax optimal decision rule; call .
Since DP strongly dynamically consistent, must priori minimax optimal. Suppose,
way contradiction, decision rule 0 priori minimax optimal
posteriori minimax. Since posteriori minimax optimal, must case
(2) holds, inequality strict x Pr(X = x) > 0
Pr P. Thus, strong dynamic consistency, must priori preferred 0 according
minimax criterion, contradiction assumption 0 priori minimax optimal.
part (d), consider Example 2.1 again, time dynamic
inconsistency. Randomizing equal probabibility 0 1, matter
observed, posteriori preferred randomized actions,
priori minimax optimal. extend example adding additional action 2
defining L(0, 2) = L(1, 2) = 1; L(y, a) remains unchanged {0, 1}.
priori posteriori minimax optimal act play 2, matter
value X observed, time consistency holds. Yet dynamic consistency still
hold, observing X = 0 X = 1, randomizing equal probabibility
0 1 preferred playing action 1, observing X, decision
rule plays action 1 matter observed strictly preferred randomizing
0 1.
direction part (e) already follows part (a). direction,
suppose, way contradiction, decision problems based P weakly time
consistent, decision problem based P dynamically consistent.
decision problem loss function L, set actions, two decision rules 0
preferred posteriori 0 priori; thus, definition dynamic
consistency, (2) holds (3) not. Let Lmax posteriori minimax expected loss
. Extend L additional act a0 y, L(y, a0 ) = Lmax .
new decision problem action set {a0 } become minimax
optimal posteriori rule (it one, matter). However,
cannot priori minimax optimal, (3) still hold 0 : 0
priori strictly better . Hence, weak time consistency new
decision problem. Since still decision problems based P, weak
time consistency decision problems based P, arrived desired
contradiction.
Theorem 5.1: Fix X , Y, L, A, P (X Y). If, PrY PY , P contains distribution Pr0 X independent Pr0 , Pr0Y = PrY ,
priori minimax-optimal decision rule ignores information.
conditions, priori minimax-optimal decision rule ignores information,
420

fiMaking Decisions Using Sets Probabilities

essentially optimizes respect marginal ; is, maxPrP EPr [L ] =
maxPrY PY EPrY [L0 ].
Proof: Let P 0 subset P distributions X independent.
Let D(X , A)0 subset D(X , A) rules ignore information. Let D(X , A)0
defined optimal decision rule ignores information relative P 0 , i.e.
max EPr [L ] =

PrP 0

min

max EPr [L ].

D(X ,A)0 PrP 0


maxPrP EPr [L ]

=
=

minD(X ,A) maxPrP EPr [L ]
minD(X ,A) maxPrP 0 EPr [L ]
minD(X ,A)0 maxPrP 0 EPr [L ] [see below]
maxPrP 0 EPr [L ].

(14)

see equality third fourth line (14) holds, note
Pr P 0 ,
P

EPr [L ] =
Pr(x, y)L (x, y)
P(x,y)X
P
P
=
xX Pr(X = x)
yY Pr(Y = y)( aA (x)(a)L(y, a))
decision rule minimizes expression independent x; distribution
actions minimizes
X

Pr(Y = y)(

X

(a)L(y, a)).

aA

yY

calculation also shows that, since ignores information, Pr P 0 ,
max EPr [L ] = max EPrY [L0 ] = max0 EPr [L ].

PrP

PrY PY

PrP

(15)

implies first last line (14) equal other, therefore also
equal second line (14). follows priori minimax optimal. Since every
priori minimax optimal rule ignores information must satisfy (15), second result
follows. next prove Theorem 6.3. first need three preliminary results.
Lemma A.2: P convex X0 X , (P | X0 )Y convex.
Proof: Without loss generality, assume (P | X0 )Y nonempty. Given Pr00 , Pr01
(P | X0 )Y , let Pr0 = Pr01 +(1 ) Pr00 . show that, [0, 1], Pr0 (P | X0 )Y .
Choose Pr0 , Pr1 P Pr0 (X0 ) > 0, Pr1 (X0 ) > 0, (Pr0 | X0 )Y = Pr00 , (Pr1 | X0 )Y =
Pr01 . c [0, 1], let Prc = c Pr1 +(1 c) Pr0 . Then, Y,
Prc (Y = | X0 ) =
=
=

Prc (XX0 ,Y =y)
Prc (XX0 )
c Pr1 (XX0 ) Pr1 (Y =y|XX0 )+(1c) Pr0 (XX0 ) Pr0 (Y =y|XX0 )
c Pr1 (XX0 )+(1c) Pr0 (XX0 )
c Pr01 (Y = y) + (1 c ) Pr00 (Y = y),

421

(16)

fiGrunwald & Halpern

c = c Pr1 (X0 )/(c Pr1 (X0 ) + (1 c) Pr0 (X0 )). Clearly, c continuous increasing
function c, 0 = 0 1 = 1. Thus, exists c c = . Since
c independent y, (16) holds (with choice c ), is,
(Prc | X0 )Y = Pr00 +(1 ) Pr01 Pr0 . Thus, Pr0 (P | X0 )Y , desired.
Lemma A.3: U = {X1 , . . . , Xk } collection nonoverlapping subsets X (i.e.,
1 < j k, Xi Xj = ), (P | X1 )Y convex, (P | X1 )Y = (P | X2 )Y = . . . = (P | Xk )Y ,

V = ki=1 Xi , j {1, . . . , k}, (P | V)Y (P | Xj )Y .
Proof: result immediate (P | V) empty. suppose Pr P Pr(V) > 0.
Using Bayes Rule,
(Pr | V)Y =

X

Pr(Xi | V)(Pr | Xi )Y .

{i:Pr(Xi |V)>0}

(P | X1 )Y = . . . = (P | Xk )Y assumption. Thus, Pr(Xi |
V) > 0, must exist Pri P (Pr | Xi )Y = (Pri | X1 )Y . Thus,
P
(Pr | V)Y = {i:Pr(Xi |V)>0} Pr(Xi | V)(Pri | X1 )Y . Since P convex assumption,
Lemma A.2, (P | X1 )Y convex well. Thus, write (Pr | V)Y convex
combination elements (P | X1 )Y , follows (Pr | V)Y (P | X1 )Y . Since
(P | X1 )Y = . . . = (P | Xk )Y , follows (Pr | V)Y (P | Xj )Y j = 1, . . . , k.
Lemma A.4: P = hPi U = {x1 , . . . , xk },

Tk

j=1 (P

| X = xj )Y (P | U)Y .

Proof: Let Q kj=1 (P | X = xj )Y . must exist Pr1 , . . . , Prk P that,
j = 1, . . . , k, (Prj | X = xj )Y = Q. Clearly Pr1 (x1 ) > 0. Since P = hPi, also exists
Pr P PrX = (Pr1 )X j {1, . . . , k} Pr1 (xj ) > 0,
(Pr | X = xj )Y = (Prj | X = xj )Y = Q. follows (Pr | U)Y = Q, Q (P | U)Y .


Theorem 6.3:
(a) C-conditioning partition C X P convex then, x X ,
(P | [x],P )Y (P, x)Y .
(b) standard conditioning, P = hPi, x X , (P, x)Y (P | [x],P )Y .
Proof: part (a), since P convex, Lemma A.2, (P | X 0 )Y convex X 0 X .
Let U = {C(x0 ) | x0 [x],P }. definition [x],P , x0 [x],P ,
(P, x0 ) = P | C(x0 ) = P | C(x) = (P, x).
Thus, Lemma A.3, (P | V)Y (P, x)Y , V = U = [x],P C(x0 ). proves
part (a).
part (b), since standard conditioning, (P | X = x)Y = (P | X =
x0 )Y x0 U. assumption, P = hPi. Thus, follows immediately Lemma A.4
(taking U = [x],P ) (P, x)Y (P | [x],P )Y , desired.


next want prove Theorem 6.10. first need definition preliminary
result.
422

fiMaking Decisions Using Sets Probabilities

Definition A.5 : update rule semi-calibrated relative P (P | [x],P )Y
(P, x)Y .
Note that, Theorem 6.3, P convex, C-conditioning semi-calibrated C.
Lemma A.6: semi-calibrated relative P C = {[x],P | x X }, C
partition X
(a) C-conditioning narrower relative P.
(b) C-conditioning strictly narrower relative P, equivalent
C-conditioning P, calibrated.
Proof: Clearly C partition X . part (a), 0 C-conditioning then, definition,
0 (P, x) = P | C(x) = P | [x],P . Since semi-calibrated, (P | [x],P )Y ((P, x))Y .
Thus, C-conditioning narrower relative P.
part (b), C-conditioning (i.e., 0 ) strictly narrower relative P,
must (P(, x))Y = (P 0 (, x))Y x X , (P | [x],P )Y = (P, x)Y ,
claibrated relative P.
Theorem 6.10:
(a) C-conditioning sharply calibrated relative P partition C.
(b) sharply calibrated relative P, exists C equivalent C-conditioning P (i.e., (P, x) = | C(x) x X ).
Proof: place partial order P partitions C taking C1 P C2 C1 conditioning narrower C2 conditioning relative P. Since X finite,
finitely many possible partitions X . Thus, must minimal elements
P . claim minimal element P sharply calibrated relative P.
suppose C0 minimal relative P . P convex, C0 -conditioning
semi-calibrated (Theorem 6.3) apply Lemma A.6 C0 . C0
minimal, C defined Lemma A.6 cannot strictly narrower C0 . follows
Lemma A.6(b) C0 -conditioning calibrated. show C0 -conditioning
fact sharply calibrated, showing exists calibrated update rule
strict narrowing C0 -conditioning. suppose, way contradiction,
update rule calibrated strictly narrower C0 relative P.
Lemma A.6(a) exists partition C C narrower relative P.
C <P C0 , contradicting minimality C0 . proves part (a).
part (b), suppose sharply calibrated relative P. Lemma A.6(a),
must partition C C-conditioning narrower , relative P.
Let C0 minimal element P C0 P C. Part (a) shows C0 -conditioning
sharply calibrated relative P. Since C0 -conditioning narrower ,
sharply calibrated relative P, must C0 -conditioning strictly narrower
relative P, hence equivalent C0 -conditioning P.
Theorem 6.12: P convex P = hPi, standard conditioning sharply
calibrated relative P.
423

fiGrunwald & Halpern

Proof: Corollary 6.4, standard conditioning calibrated relative P stated
assumptions P. show sharply calibrated, suppose exists
update rule 0 narrower standard conditioning, sharply calibrated
relative P. Theorem 6.10, 0 equivalent C-conditioning C relative
P. Thus, x X x0 C(x),
(P | C(x))Y (P | x0 )Y ,

(P | C(x))Y

\

(P | x0 )Y .

x0 C(x)

Lemma A.4, immediate
\

(P | x0 )Y (P | C(x))Y .

x0 C(x)

Thus, must
\

(P | x0 )Y = (P | C(x))Y .

(17)

x0 C(x)

want show that, x0 C(x), (P | C(x))Y = (P | x0 )Y .
show C equivalent conditioning, conditioning sharply calibrated.
Suppose not, Q (P | x0 )Y P | C(x)Y x0 C(x). Let Q0
distribution (P | C(x))Y closest Q. fact distribution
Q0 follows fact P closed (recall assume P closed throughout
paper). (In fact, follows convexity Q0 unique, necessary
argument.) Since Q0 (P | C(x))Y , follows (17) that, x00 C(x),
must distribution Prx00 P Prx00 (x00 ) > 0 (Prx00 | x00 )Y = Q. Since
P convex, distribution Pr P Pr (x00 ) > 0 x00 C(x)
(indeed, Pr convex combination distributions Prx00 x00 C
coefficients positive). Since P = hPi, must exist distribution Pr P
(Pr)X = (Pr )X (so Pr positive elements C), (Pr | x00 )Y = Q0
x00 C(x) x0 , (Pr | x0 )Y = Q. Note (Pr | (C(x) {x0 }))Y = Q0 . Thus,
(Pr | C(x)Y = c(Pr | C(x) x0 )Y + (1 c)(Pr | x0 )Y = cQ0 + (1 c)Q,
c 0 < c < 1. Clearly cQ0 + (1 c)Q closer Q Q0 is. gives
desired contradiction.

References
Augustin, T. (2003). suboptimality generalized Bayes rule robust Bayesian
procedures decision theoretic point view: cautionary note updating
imprecise priors. 3rd International Symposium Imprecise Probabilities
Applications, pp. 3145. Available http://www.carleton-scientific.com/isipta/2003toc.html.
424

fiMaking Decisions Using Sets Probabilities

Cozman, F. G., & Walley, P. (2001).
Graphoid properties epistemic irrelevance independence.
2nd International Symposium Imprecise Probabilities Applications, pp. 112121.
Available
http://www.sipta.org/ isipta01/proceedings/index.html.
da Rocha, J. C. F., & Cozman, F. G. (2002). Inference separately specified sets
probabilities credal networks. Proc. Eighteenth Conference Uncertainty
Artificial Intelligence (UAI 2002), pp. 430437.
Dawid, A. P. (1982). well-calibrated Bayesian. Journal American Statistical
Association, 77, 605611. Discussion: pages 611613.
de Finetti, B. (1936). Les probabilites nulles. Bulletins des Science Mathematiques (premiere
partie), 60, 275288.
Ellsberg, D. (1961). Risk, ambiguity, Savage axioms. Quarterly Journal Economics, 75, 643649.
Epstein, L. G., & Schneider, M. (2003). Recursive multiple priors. Journal Economic
Theory, 113 (1), 131.
Gardenfors, P., & Sahlin, N. (1982). Unreliable probabilities, risk taking, decision
making. Synthese, 53, 361386.
Gilboa, I., & Schmeidler, D. (1989). Maxmin expected utility non-unique prior.
Journal Mathematical Economics, 18, 141153.
Grove, A. J., & Halpern, J. Y. (1998). Updating sets probabilities. Proc. Fourteenth
Conference Uncertainty Artificial Intelligence (UAI 98), pp. 173182.
Grunwald, P. D., & Dawid, A. P. (2004). Game theory, maximum entropy, minimum
discrepancy, robust Bayesian decision theory. Annals Statistics, 32 (4),
13671433.
Grunwald, P. D., & Halpern, J. Y. (2004). ignorance bliss. Proc. Twentieth
Conference Uncertainty Artificial Intelligence (UAI 2004), pp. 226234.
Herron, T., Seidenfeld, T., & Wasserman, L. (1997). Divisive conditioning: results
dilation. Philosophy Science, 64, 411444.
Huber, P. J. (1981). Robust Statistics. Wiley, New York.
Hughes, R. I. G., & van Fraassen, B. C. (1985). Symmetry arguments probability kinematics. Kitcher, P., & Asquith, P. (Eds.), PSA 1984, Vol. 2, pp. 851869. Philosophy
Science Association, East Lansing, Michigan.
Lewis, D. (1976). Probability conditionals conditional probabilities. Philosophical
Review, 83 (5), 297315.
Mosteller, F. (1965). Fifty Challenging Problems Probability Solutions. AddisonWesley, Reading, Mass.
425

fiGrunwald & Halpern

Ozdenoren, E., & Peck, J. (2008). Ambiguity aversion, games nature, dynamic
consistency. Games Economic Behavior, 62 (1), 106115.
Popper, K. R. (1968). Logic Scientific Discovery (2nd edition). Hutchison, London.
first version book appeared Logik der Forschung, 1934.
Sarin, R., & Wakker, P. (1998). Dynamic choice nonexpected utility. Journal Risk
Uncertainty, 17 (2), 87120.
Savage, L. J. (1954). Foundations Statistics. Wiley, New York.
Seidenfeld, T. (2004). contrast two decision rules use (convex) sets
probabilities: -maximin versus E-admissibility. Synthese, 140 (12), 6988.
Seidenfeld, T., & Wasserman, L. (1993). Dilation convex sets probabilities. Annals
Statistics, 21, 11391154.
van Fraassen, B. C. (1987). Symmetries personal probability kinematics. Rescher, N.
(Ed.), Scientific Enquiry Philosophical Perspective, pp. 183223. University Press
America, Lanham, Md.
vos Savant, M. (Sept. 9, 1990). Ask Marilyn. Parade Magazine, 15. Follow-up articles
appeared Parade Magazine Dec. 2, 1990 (p. 25) Feb. 17, 1991 (p. 12).
Vovk, V., Gammerman, A., & Shafer, G. (2005). Algorithmic Learning Random World.
Springer, New York.
Wald, A. (1950). Statistical Decision Functions. Wiley, New York.
Walley, P. (1991). Statistical Reasoning Imprecise Probabilities, Vol. 42 Monographs
Statistics Applied Probability. Chapman Hall, London.

426

fiJournal Artificial Intelligence Research 42 (2011) 575605

Submitted 06/11; published 12/11

Computing Approximate Nash Equilibria
Robust Best-Responses Using Sampling
Marc Ponsen
Steven de Jong

. PONSEN @ MAASTRICHTUNIVERSITY. NL
STEVEN . DEJONG @ MAASTRICHTUNIVERSITY. NL

Department Knowledge Engineering
Maastricht University, Netherlands

Marc Lanctot

LANCTOT @ UALBERTA . CA

Department Computer Science
University Alberta, Canada

Abstract
article discusses two contributions decision-making complex partially observable
stochastic games. First, apply two state-of-the-art search techniques use Monte-Carlo sampling task approximating Nash-Equilibrium (NE) games, namely Monte-Carlo
Tree Search (MCTS) Monte-Carlo Counterfactual Regret Minimization (MCCFR). MCTS
proven approximate NE perfect-information games. show algorithm quickly
finds reasonably strong strategy (but NE) complex imperfect information game, i.e.
Poker. MCCFR hand theoretical NE convergence guarantees game.
apply MCCFR first time Poker. Based experiments, may conclude MCTS
valid approach one wants learn reasonably strong strategies fast, whereas MCCFR
better choice quality strategy important.
second contribution relates observation NE best response
players playing NE. present Monte-Carlo Restricted Nash Response (MCRNR),
sample-based algorithm computation restricted Nash strategies. robust bestresponse strategies (1) exploit non-NE opponents playing NE (2)
(overly) exploitable strategies. combine advantages two state-of-the-art algorithms, i.e. MCCFR Restricted Nash Response (RNR). MCRNR samples relevant parts
game tree. show MCRNR learns quicker standard RNR smaller games. Also
show Poker MCRNR learns robust best-response strategies fast, strategies
exploit opponents playing NE does.

1. Introduction
article investigates decision-making strategic, complex multi-player games.
complex test-bed, use game two-player Limit Texas Holdem Poker (henceforth abbreviated Poker full-scale Poker). introduction, first briefly outline research
games relevant. Then, discuss complexity factors involved games. Finally,
outline approach contributions.
1.1 Relevance Games-Related Research
Games attracted scientific attention years now; importance research area
game theory became apparent Second World War (Osborne & Rubinstein, 1994). Nowadays, examples serious games found many real-life endeavors, economics (e.g.,

c
2011
AI Access Foundation. rights reserved.

fiP ONSEN , L ANCTOT & E J ONG

buyers sellers stock market goal maximize profit) politics (e.g., politicians
goal collect sufficient political support cause). Games serve entertainment, puzzles, board-, sports- modern video-games, often abstracted, simpler variants
serious games. example card game Poker. objective Poker different
objective investors stock market. Players may invest (or risk) money speculate future events may may yield profit. strategies abstract games (such
Poker) easily rapidly evaluated strategies real-life endeavors (such acting
stock market), abstract games perfect tool assessing improving strategic
decision-making abilities humans well computers. reason, various complex multiplayer games attracted great deal attention artificial intelligence (AI) community
(Schaeffer, 2001).
1.2 Complexity Factors Games
Games characterized several complexity factors. briefly mention factors
relevant work presented article.
Number players. Multi-player games generally assumed complex
single-player games. Within class multi-player games, fully competitive games, also
known zero-sum games, games players conflicting goals
therefore deliberately try minimize payoff others.
Size state space. size state space (the number different situations
game may in) varies game game, depending number legal situations
number players. Large state spaces produce complex games
computational requirements traversing entire state space.
Uncertainty. Stochastic games, opposed deterministic games, complex
uncertainty effects actions, occurrences (future) events, instance
die rolls involved.
Imperfect information. Parts game state may hidden players, e.g., opponent
cards card game, probability certain chance outcome. also known
partial observability.
remainder article, deal partially observable stochastic games (Fudenberg &
Tirole, 1991), using full-scale Poker game complex test-bed. game multiplayer, competitive, partially observable stochastic game. daunting game human
AI players master.
1.3 Contributions
investigate two different sampling-based approaches decision-making, namely (1) classical
game-theoretic approach (2) best-response approach.
first approach, apply current state-of-the-art algorithms task computing
approximated Nash-Equilibrium strategy (NES) game Poker. two-player, zerosum game, expected value NES constant, regardless opponent strategy
specific NES. fair games (i.e. players equal chance winning), strategies cannot lose
576

fiC OMPUTING PPROXIMATE NASH E QUILIBRIA ROBUST B EST-R ESPONSES U SING AMPLING

expectation may win long run. complex games Poker, NES
computed introducing abstractions. Also, sampling algorithms may used (relatively)
quickly compute approximate NES. use abstractions well sampling work.
look two families algorithms, rely Monte-Carlo sampling, namely
Monte-Carlo Tree Search (MCTS), including Upper Confidence Bounds applied Trees (Kocsis
& Szepesvari, 2006; Chaslot, Saito, Bouzy, Uiterwijk, & van den Herik, 2006; Coulom, 2006),
regret-minimizing algorithm, called Monte-Carlo Counterfactual Regret Minimization (MCCFR)
(Lanctot, Waugh, Zinkevich, & Bowling, 2009). first offer comparison
two algorithms full-scale Poker.1
second approach, begin observation NES necessarily profitable strategy NES. all, safe strategy. information
strategy opponent players, adapt strategy based this, i.e., learning so-called
best-response strategies. Rather playing safe NES (i.e., play lose), want learn
tailored counter-strategies based opponent model (i.e., play win). learning good compromise best response equilibrium, combine general technique Restricted
Nash Response (RNR) (Johanson, Zinkevich, & Bowling, 2008) Monte-Carlo Counterfactual Regret Minimization (MCCFR) algorithm, leading new algorithm, named Monte-Carlo
Restricted Nash Response (MCRNR).
1.4 Structure Article
remainder article structured follows. Section 2 provides brief overview
background knowledge required article, i.e., game-theoretic concepts focussed extensiveform games, discussion games used article. Section 3 contains work
comparison Monte-Carlo Tree Search (MCTS) Monte-Carlo Counterfactual Regret Minimization (MCCFR) full-scale Poker. Section 4 introduces Monte-Carlo Restricted Nash Response
(MCRNR) describes set experiments smaller games well Poker. Finally, Section
5, conclude article.

2. Background
current section provide background information. Section 2.1 discuss game
theory (GT) fundamentals, focussing extensive-form games. represent partially observable stochastic games means games (Fudenberg & Tirole, 1991). main test domain,
two-player limit Texas Holdem Poker, introduced Section 2.2, along number smaller
games also use validate new algorithm experimentally.
2.1 Game Theory Extensive Form Games
Game theory (GT) studies strategic decision-making games two players. basic assumptions underlie theory players rational, i.e. self-interested
able optimally maximize payoff, take account knowledge
1. note aim join arms race compute closest Nash-Equilibrium (NE) approximation
full-scale Poker. aim contribution comparison two recent promising algorithms. Poker
test-bed chose use complex partially observable stochastic game algorithms
applied thus far, exist reasonably strong benchmarks test against.

577

fiP ONSEN , L ANCTOT & E J ONG

expectations decision-makers behavior, i.e. reason strategically (Fudenberg & Tirole,
1991; Osborne & Rubinstein, 1994). field originated economics analyze behaviour noncooperative settings, firmly established von Neumann Morgenstern (1944). Nash
(1951) introduced known Nash-Equilibrium (NE). current section
briefly discuss fundamentals GT extensive-form games.
2.1.1 G AMES
Games descriptions strategic interaction players. specify set available
actions players payoff combination actions. Game-theoretic tools used
formulate solutions classes games examine properties. Typically, distinction
made two types game representations, namely normal-form games extensive-form
games. normal-form game usually represented matrix shows players, actions,
payoffs. normal-form games presumed players act simultaneously (i.e.
information action choice opponents). second representation, extensive-form
game, describes games played time. Previous action sequences stored socalled game-tree, such, information choices players observed.
article, focus extensive-form games.
2.1.2 E XTENSIVE -F ORM G AMES
extensive-form game general model sequential decision-making imperfect information. perfect-information games (such Chess Checkers), extensive-form games consist
primarily game tree nodes represent states game. non-terminal node
associated player (possibly chance) makes decision node, terminal node
(leaf) associated utilities players. Additionally, game states partitioned information sets Ii . player cannot distinguish states information set. player,
therefore, must choose actions policy state information set.
strategy player i, , function assigns probability distribution A(Ii )
Ii Ii , Ii information set belonging i, A(Ii ) set actions
chosen information set. denote set strategies player i,
players current strategy. strategy profile, , consists strategy player, 1 , . . . , n .
let refer strategies excluding .
Valid sequences actions game called histories, denoted h H. history
terminal history, h Z Z H, sequences actions lead root leaf. prefix
history h v h0 one h0 obtained taking valid sequence actions h.
Given h, current player act denoted P (h). information set contains one valid
histories. standard assumption perfect recall: information sets defined information
revealed player course history, assuming infallible memory.
Let (h) probability history h occurring players choose actions according
. decompose (h) players contribution probability. Here, (h)
(h)
contribution probability player playing according . Let
product players contribution (including chance) except player i. Finally, let (h, z) =
(h, z) defined similarly. Using
(z)/ (h) h v z, zero otherwise. Let (h, z)
P
notation, define expected payoff player ui () = hZ ui (h) (h).

578

fiC OMPUTING PPROXIMATE NASH E QUILIBRIA ROBUST B EST-R ESPONSES U SING AMPLING

Given strategy profile, , define players best response strategy maximizes
expected payoff assuming players play according . best-response value
player value strategy, bi (i ) = maxi0 ui (i0 , ). -Nash-Equilibrium (NE)
approximation best response itself. Formally, -Nash-Equilibrium (NE)
strategy profile satisfies:

N

ui () + max
ui (i0 , )
0


(1)

= 0 Nash-Equilibrium (NE): player incentive deviate
playing best responses. game two-player zero-sum, use exploitability metric
determining close equilibrium, = b1 (2 ) + b2 (1 ).
well-known two-player, zero-sum games NE strategies interchangeable. is,
(1 , 2 ) (10 , 20 ) different equilibrium profiles 6= i0 , (1 , 20 ) (10 , 2 )
also NE profiles. property makes equilibrium strategies class games desireable
since worst-case guarantees preserved regardless opponent plays. property
easily extended case > 0, therefore playing NE strategy guarantee
player exploitable . details, refer reader work Fudenberg
Tirole (1991) well Osborne Rubinstein (1994).
Throughout article, refer player plays NES rational player.
player plays rationally also assumes rationality part opponents. Experiments
shown assuming rationality generally correct (e.g. experiments Poker see Billings,
Burch, Davidson, Holte, Schaeffer, Schauenberg, & Szafron, 2003); even experienced human players complex games best play approximated rational strategy, frequently play dominated
actions (i.e., actions never chosen all). Moreover, complex games
Chess Poker, even AI algorithms running modern computers great deal processor
speed memory (yet) cope immense complexity required compute NES.
Thus, forced either abstract full game selective sampling compute
approximated NE.
2.2 Test Domains
current section, introduce test domains used throughout article. particular
describe game Poker, well smaller games, similar Poker.
Poker card game played least two players. nutshell, objective game
win (money) either best card combination end game (i.e. showdown),
active player. game includes several betting rounds wherein players
allowed invest money. Players remain active least matching largest investment made
players, choose fold (stop investing money forfeit game).
case one active player remains, i.e. players chose fold, active player
automatically wins game. winner receives money invested players. exist
many variants game. specifically describe ones used article.
Kuhn Poker two-player simple Poker game. three cards (J - Jack, Q - Queen,
K - King). two actions, bet pass. event showdown, player
higher card wins pot (the King highest Jack lowest). deal, first player
579

fiP ONSEN , L ANCTOT & E J ONG

J/Q
pass
1-

pass



pass

1

-1

pass

1-

+1

1-



bet

1

-2

1

-2

pass



1

pass

1-

1

+1

1-

bet

pass



1-

pass


bet

bet

1-

pass

pass



1

+1
pass

pass

1-

bet

bet

1-

K/Q
bet

pass
1

1



K/J

pass

pass

bet

bet

bet

Q/K

Q/J

J/K
bet

+1



pass

1

+1

bet

1-

+1



+2

bet

bet


1
Player 1 Choice/Leaf Node

-1

-1

+2
2

-1

-2

+2

Player 2 Choice Node

Figure 1: Kuhn Poker game tree (taken work Hoehn, Southey, & Holte, 2005).
opportunity bet pass. first player bets round one, round two second
player either bet (and go showdown) pass (and forfeit pot). first player passes
round one, round two second player bet pass. bet leads third action
first player, namely bet (and go showdown) pass (and forfeit pot), whereas
pass game immediately proceeds showdown. Figure 1 shows game tree first
players value outcome. dominated actions removed tree.
include actions betting Queen first action, passing King second player.
total seven possible dominated actions made. Nash-Equilibria game
summarized three parameters (, , ) (each [0, 1]). Kuhn determined set
equilibrium strategies first player form (, , ) = (/3, (1 + )/3, ). Thus,
continuum Nash-Equilibrium strategies governed single parameter . one
NES second player, namely = 1/3 = 1/3. either player plays NES, first
player expects lose rate 1/18 bets (i.e., size ante) per hand. Kuhn Poker therefore
balanced fair game, since first player expected lose players play rational
strategy.
One-Card Poker (abbreviated OCP(N )) (Gordon, 2005) generalization Kuhn Poker.
deck contains N cards; Kuhn Poker corresponds N = 3. player must ante single chip,
one chip bet with, dealt one card.
Goofspiel (abbreviated Goof(N )) bidding card game players hand cards numbered 1 N , take turns secretly bidding top point-valued card point card stack,
using cards hands (Ross, 1971). version less informational: players find
result bid cards used bid, player highest total points
wins. also use fixed point card stack strictly decreasing, e.g. (N, N 1, . . . , 1).
Bluff(1,1,N) also known Liars Dice Perudo2 , dice-bidding game. version,
player rolls single N -sided die looks die without showing opponent.
players, alternately, either increase current bid outcome die rolls play, call
players bluff (claim bid hold). highest value face die
2. See e.g. http://www.perudo.com/perudo-history.html.

580

fiC OMPUTING PPROXIMATE NASH E QUILIBRIA ROBUST B EST-R ESPONSES U SING AMPLING

wild count face value. player calls bluff, win opponents bid
incorrect, otherwise lose.
Texas Holdem Poker (Sklansky, 2005) complex game investigation here.
game includes 4 betting rounds, respectively called preflop, flop, turn river phase.
first betting round, players dealt two private cards (i.e. known specific player)
full deck consisting 52 cards. encourage betting, two players obliged invest
small amount first round (the so-called small- big-blind). One one, players decide
whether want participate game. indeed want participate,
invest least current bet (i.e., big-blind beginning betting round). known
calling. Players may also decide raise bet. wish participate, players fold,
resulting loss money may bet thus far. situation outstanding bet, players
may choose check (i.e., increase stakes) bet money. size bets raises
either predetermined (i.e., Limit Poker, used paper), larger size
pot (i.e., Pot-Limit Poker) unrestrained (i.e., No-Limit Poker). remaining three betting
phases, procedure followed. every phase, community cards appear table (three
cards flop phase, one card phases). cards apply players
used determine card combinations (e.g., pair three-of-a-kind may formed
players private cards community cards). showdown, two players
still active, cards compared, thus ending game.
Princess Monster (abbreviated PAM(R, C, H)) (Isaacs, 1965) Poker game; rather,
variation pursuit-evasion game graph, neither player ever knowing location
discovering moves (pursuit dark room). experiments use
random starting positions 4-connected grid graph R rows C columns. Players take
turns alternately moving adjacent location. game ends monster moves
location princess, H moves taken total capture. payoff
evader number steps uncaptured.
next section, use Kuhn Poker (or OCP(3)) two-player Limit Texas Holdem Poker.
Section 4, use games mentioned above, except Kuhn Poker; instead Kuhn Poker, use
larger game, OCP(500).

3. Computing Approximated Nash-Equilibrium Strategies
contribution section evaluate current promising state-of-the-art search methods
computing (approximated) Nash-Equilibrium strategies complex domains, specifically Poker. Given size game tree, methods (1) incorporate appropriate
abstractions, (2) capable analysing small subsets full game (i.e., sampling).
look two families sampling algorithms, namely Upper Confidence Bounds
applied Trees (UCT) based algorithm, called Monte-Carlo Tree Search (MCTS) (Kocsis &
Szepesvari, 2006; Chaslot et al., 2006; Coulom, 2006), regret minimizing algorithm called
Monte-Carlo Counterfactual Regret Minimization (MCCFR) (Lanctot et al., 2009). MCTS
achieved tremendous success perfect information games, particular game Go
(Lee, Wang, Chaslot, Hoock, Rimmel, Teytaud, Tsai, Hsu, & Hong, 2010). games imper-

581

fiP ONSEN , L ANCTOT & E J ONG

fect information, convergence guarantees finding Nash-Equilibria.3 However,
reported may nonetheless produce strong players games imperfect information
(Sturtevant, 2008). empirically evaluate merits MCTS imperfect information
game Poker. MCCFR theoretical guarantees convergence Nash-Equilibrium
(NE). applied smaller games thus far; first evaluate complex
domain Poker.
section structured follows. Sections 3.1 3.2, discuss existing work
computing Nash-Equilibrium strategies large extensive games provide details two
sampling algorithms. Next, analyze algorithms empirically, domain Kuhn
Poker also larger domain two-player Limit Texas Holdem Poker (Section 3.3).
3.1 Non-Sampling Algorithms Computing Approximate Nash Equilibria
current subsection, give overview existing non-sampling techniques computing
NE approximations extensive form games. large body work exists many domains,
focus specifically work domain Poker.
conventional method solving extensive form games (such Poker), convert
linear program, solved linear programming solver. Billings et al. (2003)
solved abstraction full game two-player Poker using sequence-form linear programming. abstractions three-fold. First, learned models separation different
phases game. Basically, phases considered independent solved isolation. However, state previous phases contain important contextual information critical
making appropriate decisions. probability distribution cards players strongly depends
path led decision point. Therefore, provide input (i.e., contextual information
pot size number bets game) models learned later phases. Second,
shorten game tree allowing three (instead regular four) bet actions per phase.
Third, apply bucketing cards. strategic strength cards (i.e., private cards, possibly combination board cards) reflected numeric value. higher value reflects
stronger cards. Billings (2006) computed so-called Effective Hand Strength (EHS), value
range 0 1, combines Hand Strength (i.e., current winning probability active opponents) Hand Potential (i.e., probability currently losing/winning cards end
winning/losing appearance new board cards). work Billings (2006), Sections
2.5.2.1 2.5.2.3, provides detailed discussion. divide values buckets.
example, 10-bucket discretization (equal width), employ paper, EHS values
range 0 0.1 grouped together bucket 1, 0.1 0.2 bucket 2, forth. coarser
view implies information loss. solution linear program induces distribution
actions information set, corresponds mixed behavioral strategy. Poker-playing
program sample actions mixed strategy. resulting Poker-playing program
competitive human experts.
Counterfactual Regret Minimization (CFR) algorithm (Zinkevich, Johanson, Bowling, &
Piccione, 2008) may used compute approximated NE richer abstractions
requires less computational resources. Poker, Zinkevich et al. (2008) applied abstraction
cards capable learn strategies using CFR strong enough defeat
3. example, Shafiei, Sturtevant, Schaeffer (2009) provide analysis simultaneous imperfect-information
games, indicating UCT finds suboptimal solutions games.

582

fiC OMPUTING PPROXIMATE NASH E QUILIBRIA ROBUST B EST-R ESPONSES U SING AMPLING

human experts. Although important step solving complex games, complexity
increased even (as example increasing number buckets), learning time
memory requirements become impractical.
Another method Hoda et. al. (2010) Sandholm (2010) use Excessive Gap Technique applied relaxed optimization problem linear program described
derived. optimization problem smoothened made differentiable; solution
new, relaxed problem suboptimal original problem amount 0 . Parameters
optimization problem modified following gradient smooth approximations
objective functions. iteration i+1 modified parameters give new solution improved
suboptimality i+1 < . process repeated desired value reached.
3.2 Sampling Algorithms Computing Approximate Nash Equilibria
Performing Monte-Carlo sampling enable algorithms deal highly complex domains.
section discuss two algorithms perform Monte-Carlo sampling, namely MonteCarlo Tree Search (MCTS) Monte-Carlo Counterfactual Regret Minimization (MCCFR). Although internal workings techniques different, share general procedure
sampling simulated game, determining utilities leaf node (i.e., game state ends game),
backpropagating results. underlying idea techniques improve quality
simulations progressively taking account simulated games previously played.
specifically, simulations driven part game tree relevant, assuming players take rational decisions (i.e., choose actions optimize reward). result game
backpropagated visited path. Progressively, program concentrates search best
actions, leading deeper look-ahead ability.
discuss example game Poker, illustrated Figure 2. first
step (moving down), chance nodes action nodes sampled terminal node reached.
Chance nodes Poker represent dealing cards. Similarly previous work Poker, also
apply bucketing cards work. Cards grouped together buckets based strategic
strength. use 10-bucket discretization (equal width), EHS values (see Section 3.1)
range 0 0.1 grouped together bucket 1, 0.1 0.2 bucket 2, forth. higher
bucket indicates stronger hand. example sampled buckets 5 7 preflop phase
respectively player one two. Again, buckets reflect strategic strength players
private cards. appearance new board cards subsequent phases, encounter
chance nodes, buckets may change.4
assume imperfect recall. imperfect recall previous action chance nodes forgotten, consequence several information sets grouped together. example,
work take account current bucket assignment information sets, forget previous ones. way reduce game complexity tremendously, reduces memory
requirements convergence time. case imperfect recall CFR algorithm loses convergence guarantees NE, even though lose theoretical guarantees, application
imperfect recall shown practical, specifically Poker (Waugh, Zinkevich, Johanson,
Kan, Schnizlein, & Bowling, 2009).
4. preflop phase first player weakest hand, appearance board cards player could,
example, formed pair bucket therefore increased.

583

fiP ONSEN , L ANCTOT & E J ONG

Select chance node:

p
5,7

dealing private cards

Select according
information-set:
{bucket=5, hist=p}

Update information-set:

F1

C1

B1

F2

C2

B2

Select according
information-set:
{bucket=7, hist=p-C1}

bucket=5, hist=p

Update information-set:

bucket=7, hist=p-C1

Select chance node in:
{bucket=5,7, hist=p-C1-C2}

f
6,4

dealing board cards flop

Select according
information-set:
{bucket=4, hist=p-C1-C2-f}

Update information-set:

F2

C2

Continue terminal node,
determine utilities:
util=8,-8, bucket=9,2, hist=p-

B2

bucket=4, hist=p-C1-C2-f

Update information-set:

C1

C1-C2-f-B2-C1-t-C2-C1-r-B2-C1

bucket=9, hist=p-C1-C2-f-B2C1-t-C2-C1-r-B2-C1

Figure 2: Illustration Monte-Carlo simulations game Poker. left going down,
chancenodes (triangles) action nodes (circles) sampled based statistics
information set level. Utilities determined terminal nodes (squares),
full information players cards (i.e., buckets). right going up,
results simulated game backpropagated along information sets
prefix terminal node. Statistics updated information set level, effectively
altering strategy.

Players select actions based current strategy given information available
(i.e., knowing bucket opponent player). letters F, C B, followed player index, respectively correspond fold, call/check bet/raise actions
game Poker. process continues terminal leaf node encountered, utilities
determined simulated game.
second step (moving up), utilities backpropagated along sampled path,
statistics stored information set level. Different statistics required either MCCFR
MCTS. discuss algorithms detail forthcoming subsections.

584

fiC OMPUTING PPROXIMATE NASH E QUILIBRIA ROBUST B EST-R ESPONSES U SING AMPLING

3.2.1 ONTE -C ARLO REE EARCH
MCTS game tree search algorithm based Monte-Carlo simulations. MCTS converges
NE perfect information games, whereas imperfect information case guarantees
given. applied successfully several perfect-information games (Lee et al., 2010;
Chaslot et al., 2006; Bouzy & Chaslot, 2006; Coulom, 2006). therefore interesting see
MCTS also successfully applied imperfect-information game Poker. Two statistics
nodes important sampling actions MCTS, i.e.:
1. value, va action node a. average reward simulated games
visited node.
2. visit count, na action node a. represents number simulations
node reached.
crucial distinction work used MCTS perfect-information games, assume imperfect information, example opponent cards Poker. result, one reason
information sets (see Section 2.1) instead individual nodes. Therefore, part algorithm
performed information sets rather individual nodes. starting state game represented root node, initially node tree. MCTS consists repeating
following four steps (illustrated Figure 3), long time left.
1. Selection. Actions set encoded nodes game tree. chosen according
stored statistics way balances exploitation exploration.
exploiting, actions lead highest expected value selected. Less promising actions
still explored due uncertainty evaluation (exploration). use
Upper Confidence Bound applied Trees (UCT) rule select actions (Kocsis & Szepesvari,
2006). UCT, set nodes (possible actions) reachable parent node,
p. Using following equation, UCT selects child node parent node p
highest value.

argmaxaA

va + C

ln np
na

!
.

(2)

va expected value node a, na visit count a, np visit
count p, parent node a. C coefficient balances exploration exploitation.
higher value encourages longer exploration since nodes visited often
receive higher value. value usually tweaked preliminary experiments. Again, note
imperfect-information games, expected values visit counts stored updated
per information set.
2. Expansion. leaf node selected, one several nodes added tree.
tree grows simulated game. Please note tree memory deals game
nodes (assuming full information), information sets (which used selection
backpropagating part algorithm).

585

fiP ONSEN , L ANCTOT & E J ONG

Repeated X times

Selection
Selection

selection function
applied
TheThe
selection
function

recursively
leaf
node
applied
recursively

reached
leaf node reached

Expansion
Expension

Simulation
Simulation

morenodes
nodes
OneOne

created

created

One simulated
One
simulated
game isisplayed
game
played

Backpropagation
Backpropagation

Theresult
result
game


ofthis

game
backpropagated tree
backpropagated
tree

Figure 3: Outline Monte-Carlo Tree Search (Chaslot et al., 2008).

3. Simulation. newly expanded node, nodes selected according simulation
policy end game. realistic simulations significant effect
computed expected values. Examples simulation strategies Poker are: (1) random
simulations, (2) roll-out simulations (3) on-policy simulations. first simulation strategy, one samples nodes uniformly set A. roll-out simulations, one assumes
remaining active players call check end game. words, remaining active players stay active compete pot, stakes raised. Finally,
on-policy simulation uses current estimations expected values action probabilities
select actions. paper, employ latter. specifically always take action
according Equation 2. produces simulations closest actual strategy.
4. Backpropagation. reaching terminal node z (i.e., end simulated game),
establish reward players (having full information buckets players).
update information set contains prefix terminal history. visit
counts increased expected values modified according rewards obtained
terminal node.
MCTS algorithm stopped, (potentially mixed) action distribution determined
visit counts, i.e., actions information sets high visit count larger probability
selected. perfect-information games, actions selected highest expected
value, end leads optimal payoff. imperfect-information games, Poker,
potentially mixed strategy distributions required obtaining optimal payoff (e.g., see
NES Kuhn poker described Section 2.2). Therefore, ratio actions selected
determines probability distribution.
3.2.2 ONTE -C ARLO C OUNTERFACTUAL R EGRET INIMIZATION
describe Monte-Carlo Counterfactual Regret Minimization (MCCFR) algorithm,
first describe intuition behind Counterfactual Regret Minimization (CFR) algorithm, since
MCCFR based it.
586

fiC OMPUTING PPROXIMATE NASH E QUILIBRIA ROBUST B EST-R ESPONSES U SING AMPLING

CFR employs full game-tree traversal self-play, updates player strategies information
sets iteration. Strategy updates based upon regret minimization. Imagine situation
players playing strategy profile . Players may regret using strategy
extent. particular, information set may regret taking particular
action instead following . Let Ia strategy identical except taken I. Let ZI
subset terminal histories prefix history set I; z ZI let z[I]
prefix. counterfactual value vi (, I) defined as:
vi (, I) =

X



(z[I]) (z[I], z)ui (z).

(3)

zZI

algorithm applies no-regret learning policy information set counterfactual
values (Zinkevich et al., 2008). player starts initial strategy accumulates counterfactual regret action information set r(I, a) = v(Ia , I) v(, I)
self-play. Minimizing regret playing information set also minimizes overall
external regret, average strategies approach NE.
MCCFR (Lanctot et al., 2009) avoids traversing entire game tree iteration still
immediate counterfactual regrets unchanged expectation. Let Q = {Q1 , . . . , Qr }
set subsets Z, union spans set Z. Qj referred blocks
terminal histories. MCCFR samples one blocks considers terminal histories
sampled
P probability considering block Qj current iteration
P block. Let qj > 0
(where rj=1 qj = 1). Let q(z) = j:zQj qj , i.e., q(z) probability considering terminal
history z current iteration. sampled counterfactual value updating block j is:
vi (, I|j) =

X
zQj ZI

1
(z[I]) (z[I], z)ui (z)
q(z)

(4)

Selecting set Q along sampling probabilities defines complete sample-based CFR algorithm. example, algorithm uses blocks composed terminal histories whose
chance node outcomes equal called chance-sampled CFR. Rather full game-tree
traversals algorithm samples one blocks, examines terminal histories
block.
Sampled counterfactual value matches counterfactual value expectation (Lanctot et al., 2009).
is, Ejqj [vi (, I|j)] = vi (, I). So, MCCFR samples block information set
contains prefix terminal history block, computes sampled counterfactual

regrets action, r(I, a) = vi ((Ia)
, I) vi ( , I). sampled counterfactual regrets
accumulated, players strategy next iteration determined applying regretmatching rule accumulated regrets (Hart & Mas-Colell, 2000). rule assigns probability
action information set. Define rI+ [a] = max{0, rI [a]}. Then:

(I, a) =







A(I) : rI [a] 0

1/|A(I)|
rI+ [a]
P
+
aA(I) rI [a]

0

rI [a] > 0

(5)

otherwise.

rI [a] cumulative sampled counterfactual regret taking action I.
least one positive regret, action positive regret assigned probability normalized
587

fiP ONSEN , L ANCTOT & E J ONG

positive regrets actions negative regret assigned probability 0.
regrets negative, Equation 5 yields (I, a) = 0 information set. repair this,
strategy reset default uniform random strategy.
different ways sample parts game tree. focus
straightforward way, outcome sampling, described Algorithm 1. outcome-sampling
Q chosen block contains single terminal history, i.e., Q Q, |Q| = 1.
iteration one terminal history sampled updated information set along
history. sampling probabilities, Pr(Qj ) must specify distribution terminal histories.
0
specify distribution using sampling profile, 0 , Pr(z)= (z). Note choice
sampling policy induce particular distribution block probabilities q(z). long
i0 (a|I) > , exists > 0 q(z) > , thus ensuring Equation 4 well-defined.
0
algorithm works sampling z using policy 0 , storing (z). particular, -greedy
strategy used choose successor history: probability choose uniformly randomly
probability 1 choose based current strategy. single history traversed forward (to compute players probability playing reach prefix history, (h))
backward (to compute players probability playing remaining actions history, (h, z)). backward traversal, sampled counterfactual regrets visited
information set computed (and added total regret). Here,

wI ( (z[I]a, z) (z[I], z)) z[I]a v z
r(I, a) =
wI (z[I], z)
otherwise
wI =

(z[I])
ui (z)i
.
0
(z)

(6)

algorithm requires tables stored information set; table number entries
equal number actions taken information set. Therefore, denote |Ai |
maximum number actions available player information sets,
space requirement MCCFR O(|I1 ||A1 | + |I2 ||A2 |). time required MCCFR, using
outcome sampling, depends regret bounds desired . reach fixed -NE,
probability 1 p number iterations required


2 |A|M 2


p 2
2
smallest probability sampling terminal history histories, |A| maximum available actions information sets, |M | balance factor depending
relative
number decisions taken player throughout entire game property
p
|I| |I|. contrast, full CFR algorithm requires O(|A|M 2 /2 ) iterations; however,
iterations MCCFR require sampling single history whereas iteration CFR requires
traversing entire game tree worst case. practice, one benefit outcome sampling
information gained previous iterations quickly leveraged successive iterations.
Algorithm 1 shows pseudocode entire algorithm. refer interested reader
work Lanctot et al. (2009), providing in-depth discussion, including convergence proofs.

588

fiC OMPUTING PPROXIMATE NASH E QUILIBRIA ROBUST B EST-R ESPONSES U SING AMPLING

Data: root node
Data: Sampling scheme greedy
Data: Initialize information set markers: I, cI 0
Data: Initialize regret tables: I, rI [a] 0
Data: Initialize cumulative strategy tables: I, sI [a] 0
Data: Initialize initial strategy: (I, a) = 1/|A(I)|
1 = 1, 2, 3 . . .
2
current node root node
3
ELECT:
4
(current node 6= terminal)
5
P R EGRET ATCHING(rI ),
6
P G REEDY(P)
7
current node Select(current node, P )
8
end
9
current node P arent(current node)
10
U PDATE :
11
(current node 6= root node)
12
foreach A[I]
13
r = r(I, a) (sampled counterfactual regret)
14
rI [a] rI [a] + r
15
sI [a] sI [a] + (t cI )i (z[I])i (I, a)
16
end
17
cI
18
R EGRET ATCHING(rI )
19
current node P arent(current node)
20
end
21 end
Algorithm 1: Outcome-sampling Monte-Carlo Counter-Factual Regret Minimization
3.2.3 ONTE -C ARLO C OUNTERFACTUAL R EGRET E XAMPLE
provide example Algorithm 1 Kuhn Poker, shown Figure 1. algorithm
starts first iteration, selection phase. root node (a chance node), chance
outcome K|Q sampled probability 16 . Following node, algorithm loads information set belonging first player received King actions
taken; let us call information set I1 . Since regret collected actions I1 yet, P
set uniform distribution U = ( 12 , 12 ), represent probabilities (pass, bet). Then,
sampling distribution obtained P = (1 )P + U . Note regardless value
, first iteration action equally likely sampled. action sampled P ;
suppose bet. Following action, algorithm loads information set belonging
second player received queen action made first player bet
(I2 ). Similarly, algorithm constructs P P identical distributions
I1 ; suppose pass action sampled time. Finally, action taken terminal

589

fiP ONSEN , L ANCTOT & E J ONG

node reached. Therefore, terminal history sampled first iteration, z1 ,
sequence: (K|Q, bet, pass).
update phase, algorithm updates information sets touched nodes
traversed sample reverse order. Note notation z1 [I1 ] represents subsequence
(K|Q), z1 [I2 ] represents (K|Q, bet). sampled counterfactual regret computed
action I2 . Note u2 (z1 ) = u1 (z1 ) = 1. opponents reaching probability


(z1 [I2 ]) =

1 1
1
= .
6 2
12

probability sampling z1
0

(z1 ) =

1 1 1
1
= .
6 2 2
24

Therefore, wI2 = 2. two remaining things compute tail probabilities (z1 [I2 ], z) =
1

2 (z1 [I2 ]a, z) = 1, pass action. Finally, equation 6 get
1
r(I2 , pass) = 2 (1 ) = 1,
2


1
r(I2 , bet) = (2 ) = 1.
2
updates line 13, regret table rI2 = (1, +1). average strategy table
updated. reaching probability (z1 [I2 ]) product probabilities strategy choices
player 2, equal 1 since player 2 acted yet. players strategy currently
2 (I2 , pass) = 2 (I2 , bet) = 21 . current iteration = 1 cI2 = 0, therefore average
strategy updates table sI2 = ( 12 , 21 ). Finally cI2 set 1 (I2 ) = (0, 1) according
equation 5.
algorithm proceeds update tables kept I1 ,
1
1
0

u1 (z1 ) = 1,
(z1 [I1 ]) = , (z1 ) = , therefore wI1 = 4.
6
24

tail reaching probabilities (z1 [I1 ], z) = 14 , (z1 [I1 ]a, z) =
action. leads sampled counterfactual values

1
2,

bet

r(I1 , pass) = 1, r(I1 , bet) = 1.
cI1 incremented 1. average strategy table update identical one
applied I2 . Since previous actions taken player, reaching probability
1, players current strategy uniform, I2 . Finally incremented 2
entire process restarts.
3.3 Experiments
current section, empirically evaluate chosen algorithms smaller domain
Kuhn Poker full-scale Poker. present experimental results Kuhn Poker Section
3.3.1. give results Poker Section 3.3.2. Note Kuhn full-scale Poker
explained Section 2.2.
590

fiC OMPUTING PPROXIMATE NASH E QUILIBRIA ROBUST B EST-R ESPONSES U SING AMPLING

Game Limit 2-p Poker

0
UCT MCCFR, E=0.6
-0.30821
-0.502385
-0.27291
-0.38137
-0.211665
-0.35938
-0.219625
-0.299085
-0.201485
-0.31999
-0.17621
-0.315805
-0.15521
-0.27771
-0.17901
-0.31643
-0.17799
-0.2864
-0.186585
-0.26078
-0.15607
-0.290925
-0.17974
-0.29087
-0.15528
-0.27865
-0.14181
-0.231025
-0.12594
-0.285545
-0.162695
-0.26514
-0.159415
-0.24142
-0.141695
-0.26353
-0.133745
-0.2314
-0.18484
-0.25223
-0.13882
-0.24581
-0.16769
-0.26161
-0.136985
-0.203455
-0.154215
-0.236695
-0.18157
-0.21148
-0.152525
-0.22165
-0.17569
-0.213335
-0.152255
-0.20121
-0.151065
-0.22558
-0.14731
-0.197915
-0.149325
-0.20694
-0.138365
-0.238875
-0.15505
-0.176595
-0.136595
-0.21927
-0.144725
-0.22413
-0.167625
-0.20264
-0.126125
-0.171715
-0.1177
-0.219025
-0.1466
-0.1911
-0.182245
-0.18643
-0.10686
-0.18665
-0.137965
-0.195105
-0.142795
-0.17549
-0.12844
-0.196955
-0.138275
-0.18438
-0.152245
-0.149855
-0.11488
-0.180895
-0.149785
-0.18449
-0.160885
-0.17541
-0.154335
-0.202345
-0.135555
-0.176805
-0.135585
-0.166755
-0.172165
-0.176525
-0.140035
-0.15277
-0.14462
-0.11999
-0.13888
-0.1564
-0.119515
-0.18582
-0.159195
-0.155025
-0.12965
-0.16708
-0.150855
-0.16455
-0.111345
-0.17555
-0.132165
-0.182095
-0.14703
-0.149315
-0.14222
-0.189185
-0.144715
-0.151055
-0.14483
-0.180865
-0.143565
-0.17185
-0.14643
-0.149485
-0.15015
-0.137985
-0.157835
-0.142525
-0.166905
-0.171325
-0.15989
-0.184765
-0.12237
-0.1488
-0.13732
-0.169455
-0.15739
-0.144705
-0.151765
-0.12328
-0.14768
-0.15946
-0.14448
-0.13819
-0.142815
-0.16202
-0.14195
-0.16011
-0.17219
-0.13438
-0.154565
-0.13179
-0.14677
-0.15241
-0.14296
-0.164015
-0.157345
-0.14014
-0.13648
-0.14606
-0.16621
-0.152785
-0.12989
-0.126545
-0.18669
-0.152755
-0.162215
-0.11338

-0.05
-0.1
-0.15

sb/h

-0.2
-0.25
-0.3
-0.35
-0.4
-0.45

MCTS, C=17
MCCFR, E=0.6

-0.5

+0
7

+0
7

+0
7

+0
8
1.
0E

9.
1E

8.
1E

+0
7

7.
1E

+0
7

+0
7

+0
7

+0
7

+0
7

6.
1E

5.
1E

4.
1E

3.
1E

2.
1E

1.
1E

+0
6

-0.55
1.
0E

#iteration
1000000
2000000
3000000
4000000
5000000
6000000
7000000
8000000
9000000
10000000
11000000
12000000
13000000
14000000
15000000
16000000
17000000
18000000
19000000
20000000
21000000
22000000
23000000
24000000
25000000
26000000
27000000
28000000
29000000
30000000
31000000
32000000
33000000
34000000
35000000
36000000
37000000
38000000
39000000
40000000
41000000
42000000
43000000
44000000
45000000
46000000
47000000
48000000
49000000
50000000
51000000
52000000
53000000
54000000
55000000
56000000
57000000
58000000
59000000
60000000
61000000
62000000
63000000
64000000
65000000
66000000
67000000
68000000
69000000
70000000
71000000
72000000
73000000
74000000
75000000
76000000
77000000
78000000
79000000
80000000
81000000
82000000
83000000
84000000
85000000
86000000
87000000
88000000
89000000
90000000

# iterations

Figure 4: Experimental results Monte-Carlo Counter-Factual Regret Minimization (MCCFR)
Monte-Carlo Tree Search (MCTS) game Kuhn Poker (left) Poker (right).
figures x-axis denotes number iterations algorithms ran. y-axis
denotes quality Nash-Equilibrium strategy learned far. experiments
Kuhn Poker represented squared error (SQR-E) cumulative dominated
error (DOM-E), Poker use metric named small bets per hand (sb/h).
metrics applies value close zero indicates near Nash-Equilibrium strategy.
opponent Poker experiments approximated Nash Equilibrium strategy,
computed MCCFR.

3.3.1 K UHN P OKER

ran MCCFR MCTS game Kuhn Poker. C-constant MCTS
tweaked preliminary experiments set 2. suggested Balla & Fern (2009)
C-constant set scale payoff range. Also, Auer, Cesa-Bianchi,
& Fischer (2002) discuss modified version original Upper Confidence Bound (UCB) algorithm (on Upper Confidence Bound applied Trees (UCT) algorithm based) tunes
exploration term. experiments, ran several runs MCTS varying values
parameter C, took best experimental run. MCCFR used epsilon-greedy
sampling scheme. suggested earlier work (Lanctot et al., 2009), set relatively high
value 0.6 cover large area search space.
every 104 iterations measured performance current policy. Since equilibria known Kuhn Poker (see Section 2.2) compare strategy theoretically
correct one. evaluation compute squared error, simply correct NE probability minus current learned probability squared. also compute cumulative dominated
error, denotes summed probabilities selecting dominated actions.
Figure 4 (left) confirm earlier results work Lanctot et al. (2009)
Sturtevant (2008), namely MCCFR learns NE MCTS learns balanced situation
(necessarily) NE. balanced situation MCTS eventually resides depends
parameter value C. MCCFR obtains squared errors dominated errors close zero,
MCTS converged slightly NE playing dominated actions. However, also see
MCTS still unlearning dominated actions. Therefore, unlike MCCFR, MCTS

591

fiP ONSEN , L ANCTOT & E J ONG

learn perfectly rational strategies, exploitable. However, reasonable job
avoiding dominated mistakes. consequence, lose (much) NES.
3.3.2 L ARGER EST OMAIN : P OKER
evaluated policies learned MCTS MCCFR game Poker. reduce complexity task finding NES, decreased size game-tree applying bucket
discretization (Billings, 2006) cards, along imperfect recall (i.e., buckets previous
phases forgotten). phase, strategic strength private cards, along zero
board cards, determines bucket.
Learning Precomputed Nash Equilibrium
experiment use 10-bucket discretization MCCFR MCTS. MCCFR uses similar
parameter settings compared experiments Kuhn Poker, MCTS change Cconstant 17. Again, value determined preliminary experiments. every 106 iterations
evaluate current policy learned MCTS MCCFR. Policies evaluated small bets
per hand (sb/h), describes big blinds per hand average; quantity thus
used reflect players playing skill. small bets per hand computed 105 games
pre-learned Nash-Equilibrium strategy (using MCCFR 10-bucket discretization). results
shown Figure 4 (right). x-axis denotes number iterations, y-axis small
bets per hand. value close zero indicates strategy longer exploited
pre-computed NES, arguably converged (approximated) Nash Equilibrium itself.
see MCTS converges fast balanced situation, though necessarily
NE. MCCFR hand converges considerably slower, unlike MCTS continues
learn better NE approximations. Given results, one may conclude MCTS learns reasonably
good strategies fast, MCCFR long run produce better NE approximations.
interesting mention single iteration MCTS requires much less computation
time memory single iteration MCCFR. graph Figure 4 (right) plotted computation time performance, rather number iterations required, would see
larger advantage MCTS early phase learning. Clearly, end result would still
same; certain point, MCCFR surpasses MCTS.
Playing Benchmark Poker Bots
get good measure strength policies, evaluated policies strong
opponent bots provided software tool Poker Academy Pro, namely P OKI PAR B OT.
detailed explanation P OKI experiments bot, refer reader
work Billings (2006). PAR B OT bot plays according NE strategy described
Billings et al. (2003). designed solely 2-player Poker, contrast P OKI,
designed multi-player games. Since PAR B OT specializes two-player games, significantly
less exploitable two-player game P OKI, stochastic rule-based bot.
ran large number offline iterations MCCFR MCTS, froze policies,
evaluated them. addition 10-bucket discretization MCTS MCCFR, also used
MCCFR 100-bucket discretization examine effect finer abstraction. clarity,
mention number buckets used algorithm name; e.g., MCCFR100 refers
MCCFR 100 buckets. results shown Table 1. performed 104 evaluation games
software tool Poker Academy Pro policy, estimated standard deviation
0.06sb/h. MCCFR10, great deal iterations, wins small margin P OKI,
592

fiC OMPUTING PPROXIMATE NASH E QUILIBRIA ROBUST B EST-R ESPONSES U SING AMPLING

Opponent

MCTS10

MCCFR10

MCCFR100

P OKI
PAR B OT

0.077
-0.103

0.059
-0.091

0.191
0.046

Table 1: Experimental results Monte-Carlo Counter-Factual Regret Minimization (MCCFR)
Monte-Carlo Tree Search (MCTS) two Poker bots. Outcomes reported
small bets per hand (sb/h). numbers behind algorithm names refer number
buckets used card abstraction.
losing small amount PAR B OT. loss may due chosen abstractions (10-bucket
imperfect recall), due choice using outcome sampling (Lanctot et al., 2009). Looking
MCCFR100, see abstraction level culprit; wins convincingly P OKI
PAR B OT. MCTS10 surprisingly, knowing doesnt necessarily learn NES, performs slightly
better MCCFR10 P OKI, although difference significant. PARBOT,
MCTS10 strategy loses slightly MCCFR10, statistical significance.
conclude, evaluated two state-of-the-art algorithms extensive-form games. confirm
previous theoretical claims results obtained experiments smaller game (Kuhn Poker),
first time apply sampling techniques complex game Poker. MCTS valid
approach one wants learn reasonably strong policies fast, necessarily NE,
whereas MCCFR better choice quality strategy important learning
time memory constraints. However, techniques produce strategies competitive
strong Poker bots, especially fine abstractions used. sampling techniques show
promise complex domains, exclusively Poker.

4. Robust Best-Response Learning via Monte-Carlo Restricted Nash Response
well-known perfectly rational Nash-Equilibrium strategy (NES) necessarily bestresponse strategy (i.e., best counter-strategy) strategies rational strategy
(Osborne & Rubinstein, 1994). opposition employs clearly inferior strategies,
exploited best using tailored counter-strategies. resulting best-response strategy would
profitable Nash-Equilibrium strategy (NES), designed win instead designed lose. stresses importance opponent modeling games complex fully
analyze, since expect opposition incapable playing perfectly rational strategy,
profit playing best-response strategies. However, want become
exploitable strategies, opponent model may inaccurate, players
may switch strategies.
section presents Monte-Carlo Restricted Nash Response (MCRNR), sample-based algorithm offline computation restricted Nash strategies complex extensive-form games.
restricted Nash strategy essentially robust best-response strategy, i.e., exploits opponents
degree based opponent model, preventing strategy becomes
exploitable. new algorithm described section combines state-of-the-art algorithm
general technique, i.e., Monte-Carlo Counterfactual Regret Minimization (MCCFR) (Lanctot
et al., 2009) (see Section 3.2.2) Restricted Nash Response (RNR) (Johanson et al., 2008; Jo-

593

fiP ONSEN , L ANCTOT & E J ONG

hanson & Bowling, 2009). Given promising results applying sampling Counterfactual Regret Minimization (CFR), apply original Restricted Nash Response (RNR) technique using
Monte-Carlo Counterfactual Regret Minimization (MCCFR) underlying equilibrium solver.
new algorithm, Monte-Carlo Restricted Nash Response (MCRNR), benefits sampling
relevant parts game tree. algorithm therefore able converge quickly robust
best-response strategies given model opponent(s).
section structured follows. first outline related work computing bestresponse strategies. Then, introduce new algorithm, Monte-Carlo Restricted Nash Response
(MCRNR). Finally, describe experiments validate new algorithm variety games,
discussed Section 2.2.
4.1 Computing Best-Response Strategies
Poker perfect domain investigating best-response strategies since ability anticipate
opponents move highly influences outcome game. mention previous
approaches perform opponent modeling Poker. Then, discuss work Restricted Nash
Response (RNR).
4.1.1 G ENERAL PPONENT ODELING
One approach Adaptive Imperfect Information game-tree search algorithm (Billings, 2006),
opponent model integrated it. keeps track statistics outcome
game actions opponent decision nodes every possible betting sequence. problem
approach uses little generalization hence frequency counts limited
small number situations. general system opponent modeling obtained training
neural network. Davidson, Billings, Schaeffer, Szafron (2000) use nineteen different parameters input nodes three output nodes representing possible actions. input parameters
include information players, information betting history information
community cards. Southey et al. (2005) use prior distributions opponents strategy space
compute posterior using Bayes rule observations opponents decisions. also
investigates several ways play appropriate response distribution.
paper also integrate opponent model search technique order learn
best-response strategy. Unlike Billings (2006) learn model generalizes states.
work also differs aforementioned studies learn robust best-response strategies,
prevents strategy becoming exploitable itself.
4.1.2 R ESTRICTED NASH R ESPONSE
known best-response strategy, words strategy maximally exploits opponent, profitable (pessimistic) NES, given model opponent accurate.
Experiments Hoehn et al. game Kuhn Poker, validate claim. Johanson et al. (2008)
argue best-response strategies sufficiently robust; best-response strategy may exploited strategies strategy current opponent, even opponent
opponent model accurate. authors therefore introduce general technique named
Restricted Nash Response (RNR) put test Poker using chance-sampled Counterfactual Regret Minimization (CFR). Unlike Nash-Equilibrium strategies oblivious opponent
play, best-response strategies potentially exploitable, RNR strategies robust best594

fiC OMPUTING PPROXIMATE NASH E QUILIBRIA ROBUST B EST-R ESPONSES U SING AMPLING

*

p
*

*

1

1
2

2

Game G

*

*
1

2

2

2

R

1p

2

Game G

Game G

Figure 5: Illustration Restricted Nash Response. RNR technique transforms game;
chance node outcome unrevealed (to unrestricted player) added
top trees. new game, G0 , two subtrees: left subtree GR
right subtree G. GR identical G except one player restricted play
strategy f ix . Think initial coin flip moderator either forces restricted
player use f ix strategy . opponent know
two options forced upon restricted player. causes information sets
containing nodes game merged, unrestricted player
cannot tell apart.

response strategies given model opponent policies (Johanson et al., 2008). shown RNR
strategies capable exploiting opponents, reasonable performance even model
wrong. RNR technique transforms existing game modified game; equilibrium
solver solves modified game using previously mentioned CFR algorithm, wherein
assumed opponent plays according fixed strategy, specified model, certain probability, denoted parameter p. Otherwise, opponent plays according rational
regret-minimizing strategy (see Figure 5).
p parameter indication confident model correct; thought
confidence value used set trade-off exploitation exploitability,
respectively first indicates maximum amount win specific opponent strategy,
second indicates maximum amount risk losing playing strategy. Setting p = 0
leads unmodified game G (see Figure 5) solved, results game-theoretic
solution. overall solution exploitable (i.e., least break-even), also
maximally exploit opponents. extreme, namely setting p = 1, result pure
best-response strategy fixed strategy denoted opponent model. game GR ,
opponent nodes action probabilities drawn opponent model. Focusing

595

fiP ONSEN , L ANCTOT & E J ONG

game results maximal exploitative strategy opponent model, potentially cost
becoming exploitable strategies.5
Calculating RNR response requires model opponents strategy, denoted f ix .6
Suppose 2-player game, opponent (i.e., restricted) player player 2, f ix 2 .
p,
Define 2 f ix set mixed strategies form pf ix + (1 p)2 2
arbitrary strategy 2 . set restricted best responses 1 1 is:
(u2 (1 , 2 ))
BRp,f ix (1 ) = argmax
p,
2 2

f ix

(7)

(p, f ix ) RNR equilibrium pair strategies (1 , 2 ) 2 BRp,f ix (1 ) 1
BRp,f ix (2 ). pair, strategy 1 p-restricted Nash response f ix . counterstrategies f ix , p provides balance exploitation exploitability. fact, given
particular value p, solving RNR-modified game assures best possible trade-off
best response equilibrium achieved.
4.2 Monte-Carlo Restricted Nash Response (MCRNR)
extend original RNR algorithm sampling. resulting new algorithm, MCRNR, benefits sampling relevant parts game tree. therefore able converge fast
robust best-response strategies. pseudo-code algorithm provided Algorithm 2.
algorithm identical inputs compared MCCFR algorithm (see Algorithm 1),
additional two components: (1) opponent model translates fixed strategy f ix
so-called restricted player pr , (2) confidence value, p, assign model. learning opponent models, apply standard supervised learning method, namely J48 decision
tree learner Weka datamining tool. Similar work original RNR article (Johanson
et al., 2008), use fixed value p.7
sample terminal history h Z, either selecting actions based provided opponent
model, based strategy obtained regret-matching. R EGRET ATCHING routine
assigns probability action information set (according Equation 5). -greedy
sampling routine S() samples action probability


1
+ (1 )i (I, a).
|A(I)|

(8)

sampling action, recursively call MCRNR routine given extended history,
namely history h applying (see line 13). terminal node z, utilities
determined backpropagated z[I] @ z.
Regret average strategy updates applied algorithm returns recursive
call, lines 14 18. line 15 add sampled counterfactual regret (according Equation 6; takes input reaching probabilities utility sampled terminal history)
5. Note generality RNR technique: since simply modifies extensive-form game, underlying solution
technique used solve game independent application RNR. Nonetheless, point refer
RNR algorithm mean original application RNR technique coupled CFR algorithm.
6. refer reader back Section 2.1 overview notations used section.
7. learning model data makes sense different values per information set confidence
depends many observations available per information set; counter-strategies using model built data
called Data-Biased Responses (Johanson & Bowling, 2009).

596

fiC OMPUTING PPROXIMATE NASH E QUILIBRIA ROBUST B EST-R ESPONSES U SING AMPLING

1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19

initialize: Information set markers: I, cI 0
initialize: Regret tables: I, rI [a] 0
initialize: Strategy tables: I, sI [a] 0
initialize: Initial strategy: (I, a) = 1/|A(I)|
input : starting history h
input : sampling scheme S() (e.g., -greedy)
input : opponent model fixed strategy f ix restricted player pr
input : Confidence value p
input : Current iteration
MCRNR(h) =
h Z
return (ui (h), (h))
else
pi P (h)
chance node select chance node
else pi = pr
h prefix terminal history restricted subtree (I) f ix (I)
else (I) R EGRET ATCHING(rIi )
else
(I) R EGRET ATCHING(rIi )
Sample S(i (I))
(u, ) MCRNR(h+a)
foreach A(I)
rI [a] rI [a] + r(I, a)
sI [a] sI [a] + (t cI )i (I, a)
end
cI
return (u, )

20

Algorithm 2: One iteration Monte-Carlo Restricted Nash Response algorithm.
cumulative regret. line 16 average strategy updated using optimistic averaging,
assumes nothing changed since last visit information set.8 Finally, strategy
tables updated new iteration starts. next iteration, another player becomes
restricted player. process repeated number times satisfactory; meanwhile,
player assigned restricted player. iteration, average strategy (I, a)
obtained normalizing sI . pr = 2 1 = 1 . pr = 1 2 = 2 .
time, = (1 , 2 ) approaches RNR equilibrium.9
8. information update strategies, refer work Lanctot et al. (2009).
9. Note Data-Biased Response (DBR) variant (Johanson & Bowling, 2009) works slightly different way.
Instead selection restricting player root chance node, done
information set hidden restricted player (Johanson & Bowling, 2009). restricted player
forced used mixed strategy based confidence value current information set pConf . Lines 8 9

597

fiP ONSEN , L ANCTOT & E J ONG

4.3 Experiments
performed experiments smaller games Poker. smaller games performed two
types experiments; one characterize relationship exploitation exploitability
evaluating convergence rates sampling versus non-sampling algorithms. Poker
evaluate strength learned strategies benchmark opponent players.
4.3.1 MALLER G AMES
ran two separate sets experiments games OCP (we use deck size N = 500),
Goofspiel, Bluff, PAM. first set experiments aims characterize relationship exploitation exploitability different values p. second set experiments
comparison convergence rates RNR MCRNR. cases perfect opponent models
taken runs MCCFR set 0.6. Results shown Figures 6 7.
Results first set experiments may influence choice p. exploitation much
important exploitability value 0.9 suggested; hand noticeable boost exploitation achieved small loss exploitability 0.5 p 0.8.
every game except Bluff seems region p [0.97, 1] high impact magnitude
trade-off. Results Figure 7 confirm performance benefit sampling since MCRNR
produces better NE approximation less time, especially early iterations. particularly important attempting learn online (i.e. playing, rather beforehand),
time might limited.
4.3.2 L ARGER EST OMAIN : P OKER
evaluated policies learned MCRNR two poker bots, namely P OKI PAR B OT.
opponents also used experiments game theoretic (or rational) player Section
3. experimental settings well chosen abstractions identical experiments
Section 3.3.2. remind reader PAR B OT bot designed play according NES
abstracted game; therefore less exploitable P OKI.
MCRNR implementation Poker restricts player information set, essence
represents MCDBR algorithm (see Section 4.2). However, unlike original DBR paper,
experiments pConf global constant value biased data. resulting algorithm therefore mix two algorithms. continue using name MCRNR
here, reader note original RNR algorithm slightly different.10
opponent modeling, deliberately chose setup realistically difficult.
observed 20K games played P OKI PAR B OT, opposed to, e.g., 1
million games used Johanson Bowling (2009) RNR. games used gather
opponent data concerning two bots. Learning opponent model approached pattern
recognition task (Bishop, 2006), wherein model learned based experience (in case,
previous Poker games players modeled). model used estimate
behavior opponents unseen situations. Since opponent data gathered rather sparse
due 20K games, since frequency count cannot generalize, chose apply standard
Algorithm 2 replaced (I) pConf f ix (I) + (1 pConf )i (I), pConf specific value
p per information set.
10. Based experimental results smaller games, noticed difference vanilla RNR MCDBR
fixed pConf small algorithms thus similar.

598

fiC OMPUTING PPROXIMATE NASH E QUILIBRIA ROBUST B EST-R ESPONSES U SING AMPLING

Exploitation/Exploitability Trade-offs Goofspiel(5)

Exploitation/Exploitability Trade-offs Bluff(1,1,6)

0.12

0.08

Exploitation

Exploitation

0.1

0.06
0.04
0.02
0
0

0.3

0.6

0.9

1.2

1.5

1.8

0.11
0.1
0.09
0.08
0.07
0.06
0.05
0.04
0.03
0.02
0.01
0

2.1

0

0.3

0.6

Exploitability
Exploitation/Exploitability Trade-offs OCP(500)

1.2

1.5

1.8

Exploitation/Exploitability Trade-offs PAM(3,3,8)

0.1

0.12

0.09

0.1

0.08

Exploitation

Exploitation

0.9

Exploitability

0.07
0.06
0.05

0.08
0.06
0.04
0.02

0.04
0.03

0
0

0.03

0.06

0.09

0.12

0.15

0.18

0

Exploitability

1

2

3

4

5

6

7

Exploitability

Figure 6: trade-off exploitation exploitability Monte-Carlo Restricted Nash
Response. exploitation value gain payoff using Monte-Carlo
Restricted Nash Response equilibrium profile compared Nash equilibrium profile, summed pr {1, 2}. exploitability bi (i ) summed =
pr {1, 2}. value p used, bottom-left point top-right point, was:
0, 0.5, 0.7, 0.8, 0.9, 0.93, 0.97, 1.

decision tree induction algorithm (i.e., J48 algorithm Weka data-mining tool) learn
opponent model sparse data. provided J48 algorithm five simple features,
namely (1) starting seat relative button, (2) sum bets raises game, (3)
sum bets raises current phase, (4) sum bets raises modeled player
game, finally (5) bucket modeled player (if observed). specific
phase, learn model predicts strategy modeled player. set p fixed value
0.75.11 ran offline iterations MCRNR, froze policy, evaluated it. results shown
Table 2, including results MCCFR, already presented earlier. performed 104
evaluation games player. Again, provide mostly results 10-bucket abstraction
(labeled MCRNR10). 100-bucket abstraction (MCRNR100) used well, P OKI,
demonstrate effect finer abstraction levels.
11. value adapted based experience specific information set, done data-biased
approach (Johanson & Bowling, 2009).

599

fiP ONSEN , L ANCTOT & E J ONG

Convergence Rates Bluff(1,1,9)
1.8

RNR
MCRNR

1.4
1.2
1
0.8
0.6
0.4
0.2
0

0

50000

100000

150000

200000

0

Total time (seconds)

0.25

5000

10000

15000

20000

Total time (seconds)

Convergence Rates OCP(500)

Convergence Rates PAM(3,3,13)
18

RNR
MCRNR

RNR
MCRNR

16

0.2

BR Convergence

BR Convergence

RNR
MCRNR

1.6
BR Convergence

BR Convergence

Convergence Rates Goof(7)
2
1.8
1.6
1.4
1.2
1
0.8
0.6
0.4
0.2
0

0.15
0.1
0.05

14
12
10
8
6
4
2

0

0
0

1000

2000

3000

4000

5000

0

Total time (seconds)

10000

20000

30000

Total time (seconds)

Figure 7: convergence rates Restricted Nash Response versus Monte-Carlo Restricted Nash
Response. Fixed strategy profiles f ix generated using MCCFR run
f ix 0.1. data point graphs represent two separate runs average profiles ( r1 , 2 ) ( 1 , r2 ), superscript r represents restricted player.
profile interest = ( 1 , 2 ). value y-axis = b1 ( 2 ) + b2 ( 1 ).
profile RNR equilibrium minimized. Note necessary approach 0 p > 0; strategies may always somewhat exploitable due
opponent exploitation.

expected, MCRNR exploits P OKI considerably MCCFR, namely 0.369 sb/h
(using 10-bucket abstraction) 0.482 sb/h (100 buckets). Interestingly, depicted Figure 8,
even MCRNR10 learned exploit P OKI 20 million sampled iterations. note
sampled iteration, nodes touched (i.e., information sets updated along
history sampled terminal node), RNR (and CFR, matter) iteration
information sets updated. Consequently, 20 million sampled iterations MCRNR (or MCCFR) map far less full-backup iterations RNR (or CFR), require much less computation
time 20 million full backups.
PAR B OT, plays better NES approximation, improvement performance
also observed, here, difference significant. surprising, given PAR -

600

fiC OMPUTING PPROXIMATE NASH E QUILIBRIA ROBUST B EST-R ESPONSES U SING AMPLING

Figure 8: online evaluation MCRNR policy learning P OKI. bot
playing 1, 000 online games, approximated 6 million offline iterations MonteCarlo Restricted Nash Response, using 10-bucket abstraction, run.

Opponent

MCCFR10

MCRNR10

MCCFR100

MCRNR100

P OKI
PAR B OT

0.059
-0.091

0.369
-0.039

0.191
0.046

0.482
0.061

Table 2: Experimental results MCRNR versus two bots. repeat results Monte-Carlo
Counter-Factual Regret Minimization (MCCFR) reported Section 3. Outcomes
small bets per hand (sb/h). Numbers behind algorithm names refer abstraction level
(number buckets).

B OT (extremely) exploitable Poki. Clearly, though, MCRNR performs similarly
PAR B OT MCCFR, implying MCRNR policy plays dominated actions.
conclusion, P OKI well PAR B OT, MCRNR finds least equally good
policy MCCFR. P OKI, exploitable opponent, benefit algorithm becomes apparent; MCRNR policy earns much MCCFR policy, even coarse abstraction
(compare 0.191 sb/h MCCFR100 0.369 sb/h MCRNR10; coarser abstraction).
also deliberately limited amount data available opponent model illustrate
performance new algorithm difficult conditions. ideal conditions, i.e.,
prominently opponent data, algorithm expected outperform
MCCFR terms (simulated) money playing exploitable opponent,
outperform RNR MCCFR terms time required find good policy.

5. Conclusion
article highlights two contributions field decision-making complex partially
observable stochastic games. first applied two existing recent search techniques use Monte601

fiP ONSEN , L ANCTOT & E J ONG

Carlo sampling task approximating Nash-Equilibrium strategy (NES), namely MonteCarlo Tree Search (MCTS) Monte-Carlo Counterfactual Regret Minimization (MCCFR).
algorithms compared game complex use, namely two-player Limit
Texas HoldEm Poker. MCTS used predominantely perfect-information games
Go. games, algorithm proven compute NES. imperfect-information games, balanced situations learned necessarily Nash-Equilibrium (NE) (Sturtevant, 2008).
experiments, confirm finding: algorithm indeed learn reasonably strong policies
Poker, drawback strategies necessarily NE. MCCFR hand
already shown converge NE smaller imperfect information games,
ones outlined Section 2.2 (Lanctot et al., 2009). apply first time complex
game Poker, show indeed approximate NES. initial convergence MCCFR
slower MCTS. may due fact used outcome sampling.
sampling schemes, e.g., external sampling (Lanctot et al., 2009), may lead MCCFR converging
fast MCTS (where fast measured number iterations required). mentioned
typical iteration MCCFR takes significantly longer (in actual time) one MCTS,
due additional computational complexity involved backpropagation process. MCCFR also
takes memory statistics required computing strategy distributions.
second contribution relates observation Nash-Equilibrium strategies necessarily best deal clearly irrational opposition (i.e., players playing NES). tailored
best-response strategy yield profit. Pure best-response strategies however may brittle
exploitable strategies one trained against. present MonteCarlo Restricted Nash Response (MCRNR), sample-based algorithm computation restricted Nash strategies, essentially robust best-response strategies (1) exploit irrational opponents compared NES (2) (too) exploitable strategies. algorithm
combines advantages two state-of-the-art existing algorithms, i.e., MCCFR Restricted
Nash Response (RNR). MCRNR samples relevant parts game tree. therefore able
converge faster robust best-response strategies RNR. evaluate algorithm variety
imperfect-information games small enough solve yet large enough strategically
interesting. empirically show MCRNR learns much quicker standard RNR smaller
games. also apply MCRNR large game Poker, deliberately choosing hard settings, i.e.,
relatively iterations come policy, relatively little opponent data. Even
hard settings, MCRNR learns exploit strong (yet exploitable) opponent bot P OKI significantly
NES learned MCCFR, performing similarly MCCFR strong
(hardly exploitable) opponent bot PAR B OT. MCRNR achieves performance fraction
computation time required previous algoritms.
strong results obtained MCCFR MCRNR complex game two-player Poker
point many possible applications (refinements of) algorithms. prominently,
see ample opportunity continued work Poker. One first applications interest twoplayer Poker even finer abstractions. show 100-bucket abstraction performs much
better 10-bucket one. Indeed, state-of-the-art two-player NE bots use strategies computed
extremely fine-grained abstractions. Less abstractions would improve performance considerably opponent bots used article. However, settings, would require
opponent-model data, also need allow iterations learn policies. Second, integrating Data-Biased Response (DBR) approach may lead increased performance. Third,
would highly interesting evaluate performance algorithms Poker
602

fiC OMPUTING PPROXIMATE NASH E QUILIBRIA ROBUST B EST-R ESPONSES U SING AMPLING

two players. zero-sum games two players, NES longer guaranteed
lose; coalitions players may formed. Nonetheless, first work applying algorithms CFR games two players suggests NES still strong
strategy (Risk & Szafron, 2010). would interesting determine whether MCCFR
MCRNR beneficial (for speed convergence quality solution converged
to) three-player games two-player game.

Acknowledgments
authors thank Michael Johanson extensive commentary article, valuable
input Restricted Nash Response algorithm Poker research University Alberta
general. also thank anonymous reviewers editors valuable input.

References
Auer, P., Cesa-Bianchi, N., & Fischer, P. (2002). Finite-time analysis multi-armed bandit
problem. Machine Learning, 47(2-3), 235256.
Balla, R. K., & Fern, A. (2009). UCT tactical assault planning real-time strategy games.
International Joint Conference Artificial Intelligence (IJCAI-2009).
Billings, D. (2006). Algorithms Assessment Computer Poker. Ph.D. dissertation. University
Alberta.
Billings, D., Burch, N., Davidson, A., Holte, R. C., Schaeffer, J., Schauenberg, T., & Szafron, D.
(2003). Approximating game-theoretic optimal strategies full-scale poker. Gottlob, G.,
& Walsh, T. (Eds.), Proceedings Eighteenth International Joint Conference Artificial
Intelligence (IJCAI-03), pp. 661668. Morgan Kaufmann.
Bishop, C. M. (2006). Pattern Recognition Machine Learning. Springer.
Bouzy, B., & Chaslot, G. (2006). Monte-carlo go reinforcement learning experiments. IEEE
2006 Symposium Computational Intelligence Games, Reno, USA, pp. 187194.
Chaslot, G. M. J.-B., Saito, J.-T., Bouzy, B., Uiterwijk, J., & van den Herik, H. (2006). Montecarlo strategies computer go. Schobbens, P.-Y., Vanhoof, W., & Schwanen, G. (Eds.),
Proceedings 18th BeNeLux Conference Artificial Intelligence, pp. 8390.
Chaslot, G. M. J.-B., Winands, M., Uiterwijk, J., van den Herik, H., & Bouzy, B. (2008). Progressive
strategies monte-carlo tree search. New Mathematics Natural Computation, 4(3),
343357.
Coulom, R. (2006). Efficient selectivity backup operators monte-carlo tree search. van den
Herik, H., Ciancarini, P., & Donkers, H. (Eds.), Proceedings 5th International Conference Computer Games, Vol. 4630 Lecture Notes Computer Science (LNCS), pp.
7283. Springer-Verlag, Heidelberg, Germany.
Davidson, A., Billings, D., Schaeffer, J., & Szafron, D. (2000). Improved opponent modeling
poker. Proceedings 2000 International Conference Artificial Intelligence
(ICAI2000), pp. 14671473.
Fudenberg, D., & Tirole, J. (1991). Game Theory. MIT Press, Cambridge, MA.
603

fiP ONSEN , L ANCTOT & E J ONG

Gordon, G. J. (2005). No-regret algorithms structured prediction problems. Tech. rep. CMUCALD-05-112, Carnegie Mellon University.
Hart, S., & Mas-Colell, A. (2000). simple adaptive procedure leading correlated equilibrium.
Econometrica, 68(5), 11271150.
Hoda, S., Gilpin, A., Pena, J., & Sandholm, T. (2010). Smoothing techniques computing Nash
equilibria sequential games. Mathematics Operations Research, 35(2), 494512.
Hoehn, B., Southey, F., & Holte, R. C. (2005). Effective short-term opponent exploitation simplified poker. Proceedings National Conference Artificial Intelligence (AAAI),
pp. 783788. AAAI Press.
Isaacs, R. (1965). Differential Games: Mathematical Theory Applications Warfare
Pursuit, Control Optimization. John Wiley & Sons. Research Problem 12.4.1.
Johanson, M., & Bowling, M. (2009). Data biased robust counter strategies. Proceedings
Twelfth International Conference Artificial Intelligence Statistics (AISTATS), pp.
264271.
Johanson, M., Zinkevich, M., & Bowling, M. (2008). Computing robust counter-strategies.
Advances Neural Information Processing Systems 20 NIPS.
Kocsis, L., & Szepesvari, C. (2006). Bandit Based Monte-Carlo Planning. Furnkranz, J., Scheffer,
T., & Spiliopoulou, M. (Eds.), Machine Learning: ECML 2006, Vol. 4212 Lecture Notes
Artificial Intelligence, pp. 282293.
Kuhn, H. W. (1950). Simplified two-person poker. Contributions Theory Games, 1, 97103.
Lanctot, M., Waugh, K., Zinkevich, M., & Bowling, M. (2009). Monte carlo sampling regret
minimization extensive games. Advances Neural Information Processing Systems 22
(NIPS), pp. 10781086.
Lee, C.-S., Wang, M.-H., Chaslot, G.-B., Hoock, J.-B., Rimmel, A., Teytaud, O., Tsai, S.-R., Hsu,
S.-C., & Hong, T.-P. (2010). computational intelligence mogo revealed taiwans
computer go tournaments. IEEE Transactions Computational Intelligence AI
games, 1, 7389.
Nash, J. (1951). Non-cooperative games. Annals Mathematics, 54(2), 286295.
Osborne, M. J., & Rubinstein, A. (1994). Course Game Theory. MIT Press.
Risk, N. A., & Szafron, D. (2010). Using counterfactual regret minimization create competitive
multiplayer poker agents. Proc. 9th Int. Conf. Autonomous Agents Multiagent
Systems (AAMAS 2010), pp. 159166.
Ross, S. M. (1971). Goofspiel game pure strategy. Journal Applied Probability, 8(3),
621625.
Sandholm, T. (2010). state solving large incomplete-information games, application
poker. AI Magazine, 31(4), 1332.
Schaeffer, J. (2001). gamut games. AI Magazine, 22, 2946.
Shafiei, M., Sturtevant, N., & Schaeffer, J. (2009). Comparing UCT versus CFR simultaneous
games. GIGA Workshop General Game Playing IJCAI.

604

fiC OMPUTING PPROXIMATE NASH E QUILIBRIA ROBUST B EST-R ESPONSES U SING AMPLING

Sklansky, D. (2005). Theory Poker (Fourth ed. edition). Las Vegas: Two plus two.
Southey, F., Bowling, M., Larson, B., Piccione, C., Burch, N., Billings, D., & Rayner, D. C. (2005).
Bayes bluff: Opponent modelling poker. Proceedings 21st Conference Uncertainty Artificial Intelligence (UAI 05), pp. 550558.
Sturtevant, N. R. (2008). analysis uct multi-player games. Computers Games.
von Neumann, J., & Morgenstern, O. (1944). Theory Games Economic Behavior. Princeton
University Press.
Waugh, K., Zinkevich, M., Johanson, M., Kan, M., Schnizlein, D., & Bowling, M. (2009). practical use imperfect recall. Proceedings 8th Symposium Abstraction, Reformulation Approximation (SARA).
Zinkevich, M., Johanson, M., Bowling, M., & Piccione, C. (2008). Regret minimization games
incomplete information. Advances Neural Information Processing Systems 20
NIPS.

605

fiJournal Artificial Intelligence Research 42 (2011) 353-392

Submitted 5/11; published 11/11

Learning Make Predictions Partially Observable
Environments Without Generative Model
Erik Talvitie

erik.talvitie@fandm.edu

Mathematics Computer Science
Franklin Marshall College
Lancaster, PA 17604-3003, USA

Satinder Singh

baveja@umich.edu

Computer Science Engineering
University Michigan
Ann Arbor, MI 48109-2121, USA

Abstract
faced problem learning model high-dimensional environment,
common approach limit model make restricted set predictions, thereby
simplifying learning problem. partial models may directly useful making
decisions may combined together form complete, structured model. However, partially observable (non-Markov) environments, standard model-learning methods
learn generative models, i.e. models provide probability distribution possible futures (such POMDPs). straightforward restrict models make
certain predictions, always simplify learning problem.
paper present prediction profile models: non-generative partial models partially
observable systems make given set predictions, therefore far simpler
generative models cases. formalize problem learning prediction
profile model transformation original model-learning problem, show empirically one learn prediction profile models make small set important
predictions even systems complex standard generative models.

1. Introduction
Learning model dynamics environment experience critical capability artificial agent. Agents learn make predictions future events
anticipate consequences actions use predictions plan
make better decisions. agents environment complex, however, learning problem pose serious challenges. One common approach dealing complex
environments learn partial models, focusing model-learning problem making
restricted set particularly important predictions. Often predictions
need made, much complexity dynamics modeled safely ignored. Sometimes partial model directly useful making decisions, instance
model makes predictions agents future rewards (e.g., see McCallum, 1995;
Mahmud, 2010). cases, many partial models making restricted predictions
combined form complete model in, instance, factored MDPs (Boutilier,
Dean, & Hanks, 1999), factored PSRs (Wolfe, James, & Singh, 2008), collections
local models (Talvitie & Singh, 2009b).
c
2011
AI Access Foundation. rights reserved.

fiTalvitie & Singh

common approach learning partial model apply abstraction
(whether learned supplied domain expert) filters detail training data irrelevant making important predictions. Model-learning methods
applied abstract data, typically learning problem
tractable result. However, especially case partially observable systems, abstraction alone may sufficiently simplify learning problem, even (as see
subsequent examples) model asked make intuitively simple predictions.
counter-intuitive complexity learning partial model partially observable case
direct result fact standard model-learning approaches partially observable systems learn generative models attempt make every possible prediction
future cannot straightforwardly restricted making particularly
important predictions.
paper present alternative approach learns non-generative models
make specified predictions, conditioned history. following illustrative
example, see sometimes small set predictions necessary
good control performance learning make predictions high-dimensional
environment using standard generative models pose serious challenges. contrast
see exists simple, non-generative model make maintain
predictions form learning target method.
1.1 Example
Consider simple game Three Card Monte. dealer, perhaps crowded street,
three cards, one ace. dealer shows location ace, flips
cards, mixes swapping two cards every time step. player
game must keep track location ace. Eventually dealer stops mixing
cards asks guess. player correctly guesses ace is, win
money. guess wrong, lose money.
Consider artificial agent attempting learn model dynamics game
experience. takes sequence actions perceives sequence observations.
raw data received agent includes rich, high-dimensional scene including
activities crowd, movement cars, weather, well game (the
dealer swapping cards). Clearly, learning model encompasses complex
phenomena infeasible unnecessary. order win game, agent needs
focus making predictions cards, need anticipate future behavior city scene around it. particular, agent need make three predictions:
flip card 1, ace? corresponding predictions cards 2
3. One safely ignore much detail agents experience still make
important predictions accurately. one filters irrelevant detail, agents
experience might look like this:
bet pos2 watch swap1, 2 watch swap2, 3 . . . ,
agent takes bet action, starting game, observes dealer showing
card position 2. agent takes watch action, observes dealer swapping
cards 1 2, takes watch action again, observes dealer swapping cards 2 3,
354

fiLearning Make Predictions Without Generative Model

dealer prompts agent guess (note uncontrolled
system; watch indeed action agent must select over, say, reaching
flipping cards itself, real game Three Card Monte would certainly result
negative utility!) data reflects movement cards. One could learn
model using new data set learning problem would far simpler
since complex irrelevant phenomena like crowd weather ignored.
Markov case, agent directly observes entire state environment
therefore learn make predictions direct function state. Abstraction simplifies
representation state thereby simplifies learning problem. Note, however,
Three Card Monte problem partially observable (non-Markov). agent cannot
directly observe state environment (the location ace state
dealers mind hidden agent). partially observable case, agent
must learn maintain compact representation state well learn dynamics
state. common methods achieve this, expectation-maximization
(EM) learning POMDPs (Baum, Petrie, Soules, & Weiss, 1970), learn generative models
provide probability distribution possible futures.
Three Card Monte, even irrelevant details ignored data
contains information cards movement, generative model still intractably complex! generative model makes predictions future events.
includes predictions model meant make (such whether flipping card 1
next time-step reveal ace) also many irrelevant predictions. generative
model, also predict, instance, whether flipping card 1 10 time-steps
reveal ace whether cards 1 2 swapped next time-step. make
predictions, model must capture dynamics cards also
dealers decision-making process. dealer decides cards swap using
complex process (as human dealer might) problem learning generative model
abstract system correspondingly complex.
course, Three Card Monte, predicting dealers future behavior entirely
unnecessary win. required maintain aces current location time.
such, learning model devotes complexity anticipating dealers
decisions counter-intuitive best. far reasonable model seen Figure 1.
states model labeled predictions aces location.
transitions labeled observations dealers behavior. agent plays
game, could use model maintain predictions location ace
time, taking dealers behavior account, predicting dealers future
behavior. Note non-generative model. provide distribution
possible futures cannot used simulate world
predict dealers next move. provides limited set conditional predictions
future, given history past actions observations. hand,
far simpler generative model would be. model dealers
decision-making process, model 3 states, regardless underlying process
used dealer.
model Figure 1 example term prediction profile model.
paper formalize prediction profile models present algorithm learning
data, assumptions (to specified established necessary
355

fiTalvitie & Singh

Figure 1: Maintaining predictions location ace Three Card Monte. Transitions labeled dealers swaps. States labeled predicted
position special card.

terminology). empirically demonstrate partially observable systems
prove complex standard generative model-learning methods, possible
learn prediction profile model makes small set important predictions allow
agent make good decisions. next sections formally describe setting
establish notation terminology formalize general learning problem
addressed. Subsequent sections formally present prediction profile models
algorithm learning them, well several relevant theoretical empirical results.
1.2 Discrete Dynamical Systems
focus discrete dynamical systems. agent finite set actions
take environment finite set observations produce. every
time step i, agent chooses action ai environment stochastically emits
observation oi O.
Definition 1. time step i, sequence past actions observations since
beginning time hi = a1 o1 a2 o2 . . . ai oi called history time i.
history time zero, agent taken actions seen observations
h0 , called null history.
1.2.1 Predictions
agent uses model make conditional predictions future events, given history actions observations given future behavior. environment
assumed stochastic, predictions probabilities future events. primitive
building block used describe future events called test (after Rivest & Schapire, 1994;
Littman, Sutton, & Singh, 2002). test simply sequence actions observations
356

fiLearning Make Predictions Without Generative Model

could possibly occur, = a1 o1 . . . ak ok . agent actually takes action sequence
observes observation sequence t, say test succeeded. prediction
p(t | h) probability test succeeds history h, assuming agent takes
actions test. Essentially, prediction test answer question
take particular sequence actions, probability would see
particular sequence observations, given history far? Formally,
def

p(t | h) = Pr(o1 | h, a1 )Pr(o2 | ha1 o1 , a2 ) . . . Pr(ok | ha1 o1 a2 o2 . . . ak1 ok1 , ak ).

(1)

Let set tests (that is, set possible action-observation sequences
lengths). set possible histories H set action-observation
sequences could possibly occur starting null history, null history itself:
def
H = {t | p(t | h0 ) > 0} {h0 }.
model make prediction p(t | h) h H make
conditional prediction future (Littman et al., 2002). represents
probability distribution futures, model used sample
distribution order simulate world, sample possible future trajectories.
such, call model makes predictions generative model.
Note use word generative closely related broader sense
general density estimation. one attempting represent conditional probability
distribution Pr(A | B), generative approach would represent full joint distribution Pr(A, B) conditional probabilities computed Pr(A,B)
Pr(B) .
say, generative model sense makes predictions even variables wish
condition on. non-generative or, settings, discriminitive approach would
instead directly represent conditional distribution, taking value B un-modeled
input. non-generative approach sometimes result significant savings Pr(B)
difficult represent/learn, Pr(A | B) relatively simple (so long one truly
disinterested modeling joint distribution).
particular setting, generative model one provides probability distribution futures (given agents actions). such, one would use generative model
0)
. fact, Equation 1 one
compute p(t | h) particular h p(ht|h
p(h|h0 )
see prediction multi-step test computed predictions
one-step tests:
p(a1 o1 a2 o2 . . . ak ok | h) = p(a1 o1 | h)p(a2 o2 | ha1 o1 ) . . . p(ak ok | ha1 o1 a2 o2 . . . ak ok ).
leads simple definition generative model:
Definition 2. model provide predictions p(ao | h) actions A,
observations histories h H generative model.
non-generative model, then, would make one-step predictions histories
and, consequently, would directly represent prediction p(t | h) history h
un-modeled input. would condition given history, necessarily capable
computing probability history sequence. saw Three Card Monte
example, beneficial making maintaining predictions substantially
simpler making predictions every possible action-observation sequence.
357

fiTalvitie & Singh

Note test describes specific future event (a sequence specific actions
observations). many cases one might wish make predictions abstract
events. achieved composing predictions many tests. instance set
tests (Wingate, Soni, Wolfe, & Singh, 2007) sequence actions set observation
sequences. set test succeeds agent takes specified action sequence sees
observation sequence contained within set occur. traditional tests allow
agent, instance express question go outside, probability see
exact sequence images? set test express far useful, abstract question
go outside, probability sunny? grouping together
observations sunny day. Even generally, option tests (Wolfe & Singh, 2006; Soni
& Singh, 2007) express future events agents behavior described abstractly
well resulting observations. types abstract predictions computed
linear combination set concrete predictions.
1.2.2 System Dynamics Matrix Linear Dimension
sometimes useful describe dynamical system using conceptual object called
system dynamics matrix (Singh, James, & Rudary, 2004). system dynamics matrix
contains values possible predictions, therefore fully encodes dynamics
system. Specifically,
Definition 3. system dynamics matrix dynamical system infinity-by-infinity
matrix. column corresponding every test . row corresponding
every history h H. ijth entry system dynamics matrix prediction
p(tj | hi ) test corresponding column j history corresponding row
entry every history-test pair.
Though system dynamics matrix infinitely many entries, many cases
finite rank. rank system dynamics matrix thought measure
complexity system (Singh et al., 2004).
Definition 4. linear dimension dynamical system rank corresponding
system dynamics matrix.
popular modeling representations, linear dimension major factor
complexity representing learning generative model system. instance,
POMDPs, number hidden states required represent system lower-bounded
linear dimension. work adopt linear dimension measure
complexity dynamical system. say system simpler another,
mean lower linear dimension.
1.2.3 Markov Property
dynamical system Markov one needs know history order make
predictions future events recent observation.
Definition 5. system Markov two histories h h (that may null
history), two actions , observation o, test t, p(t | hao) = p(t | h o).
358

fiLearning Make Predictions Without Generative Model

Markov case use notational shorthand p(t | o) indicate prediction
history ends observation o. Markov case, observations
contain information needed make prediction future, often
called state (because describe state world). system Markov,
partially observable. partially observable systems predictions depend arbitrarily
entire history. focus partially observable case.

2. Learning Make Predictions
work assume that, Three Card Monte, though agent may live
complex environment, small set important predictions make.
predictions could identified important designer, learning
process. address problem identifying predictions made,
rather focus problem learning make predictions, identified.
general, imagine given finite set = {t1 , t2 , . . . , tm } tests
interest would like model make accurate predictions. term
test construed broadly, possibly including abstract tests addition raw
sequences actions observations. tests interest future events model
predict. instance, Three Card Monte problem, order perform well
agent must predict whether see ace flips card.
three one-step tests interest: f lip1 ace, f lip2 ace, f lip3 ace (representing
future events agent flips card 1, 2, 3, respectively, sees ace).
agent learn maintain probability events time, win
game.
such, general problem learn function : H [0, 1]m
def

(h) = hp(t1 | h), p(t2 | h), . . . , p(tm | h)i,

(2)

is, function histories predictions test interest (which refer
predictions interest) history. Note output necessarily
probability distribution. tests interest may selected arbitrarily therefore
need represent mutually exclusive exhaustive events. call particular vector
predictions tests interest prediction profile.
Definition 6. call (h) prediction profile history h.
describe two existing general approaches learning : learning direct function history predictions (most common Markov case), learning fully
generative model maintains finite-dimensional summary history (common
partially observable case). strengths weaknesses approaches learning
. Section 2.3 contrast approach, combines strengths
approaches.
2.1 Direct Function Approximation
system Markov, learning conceptually straightforward; essentially
problem learning function observation (state) predictions. Rather
359

fiTalvitie & Singh

learning takes histories input, one instead learn function arkov :
[0, 1]m , maps observation predictions tests interest resulting
histories end observation. Note that, immediate consequence,
discrete Markov systems finite number distinct prediction profiles. fact,
distinct prediction profiles observations.
number observations number tests interest small enough,
arkov represented |O| |T | look-up table, entries estimated using
sample averages1 :
p(ti | o) =

# times succeeds histories ending
.
# times acts(t) taken histories ending

(3)

main challenge learning Markov models arises number observations
large. becomes necessary generalize across observations, using data gathered
one observation learn many others. Specifically, one may able exploit
fact observations associated similar (or identical) prediction
profiles (that is, predictions tests interest) share data amongst them.
Restricting models attention predictions afford generalization,
learning partial model beneficial Markov setting.
Even system partially observable, one still attempt learn directly,
typically performing sort regression set features entire histories.
instance, U-Tree (McCallum, 1995) takes set history features learns decision tree
attempts distinguish histories result different expected asymptotic return
optimal behavior. Wolfe Barto (2006) apply U-Tree-like algorithm rather
restricting model predicting future rewards, learn make predictions
pre-selected set features next observation (a special case
general concept tests interest). Dinculescu Precup (2010) learn expected value
given feature future direct function given real-valued feature history
clustering futures histories similar associated values.
directly approximate types models make predictions
therefore non-generative (and therefore able, instance, avoid falling
trap predicting dealers decisions Three Card Monte). Though approach
demonstrated promise, also faces clear pragmatic challenge, especially partially
observable setting: feature selection. function history, ever-expanding
sequence actions observations, finding reasonable set compactly represented features collectively capture history information needed make predictions
interest significant challenge. sense, even partially observable setting,
type approach takes small step away Markov case. still requires
good idea priori information extracted history (in form
features) order make predictions interest.
1. Bowling, McCracken, James, Neufeld, Wilkinson (2006) showed estimator unbiased
case data collected using blind policy, action selection depend
history observations provided alternative estimator unbiased policies.
simplicitys sake, however, assume throughout data gathering policy blind.

360

fiLearning Make Predictions Without Generative Model

2.2 Generative Models
one good idea priori features extracted history
make accurate predictions, one faces additional challenge learning summarize
relevant information history compact sufficient statistic.
exist methods learn training data maintain finite-dimensional
statistic history prediction computed. analogy Markov
case, statistic called state vector. Clearly model maintain state
used compute (since make predictions). briefly mention two
examples approach particularly relevant development analysis
method.
POMDPs far popular representation models partially observable
systems partially observable Markov decision process (POMDP) (Monahan, 1982).
POMDP posits underlying MDP (Puterman, 1994) set hidden states
agent never observes. given time-step i, system particular hidden
state si1 (unknown agent). agent takes action ai system
transitions next state si according transition probability Pr(si | si1 , ai ).
observation oi emitted according probability distribution general
may depend upon si1 , ai , si : Pr(oi | si1 , ai , si ).
agent observe hidden states, cannot know hidden
state system given moment. agent however maintain probability
distribution represents agents current beliefs hidden state. probability distribution called belief state. belief state associated history h
known, straightforward compute prediction test t:
X
p(t | h) =
Pr(s | h)Pr(t | s),
sS

Pr(t | s) computed using transition observation emission probabilities.
belief state finite summary history prediction
future computed. So, belief state state vector POMDP. Given
transition probabilities observation emission probabilities, possible maintain
belief state time using Bayes rule. current history h one knows Pr(s | h)
hidden states agent takes action observes observation o, one
compute probability hidden state new history:
P



Pr(s | h)Pr(s | , ai )Pr(oi | , ai , s)
P
Pr(s | hao) = P
.
(4)






Pr(s | h)Pr(s | , ai )Pr(oi | , ai , )
parameters POMDP must learned order able maintain
state transition probabilities observation emission probabilities. Given
parameters, belief state corresponding given history recursively computed
model thereby make prediction history. POMDP parameters
typically learned using Expectation Maximization (EM) algorithm (Baum et al., 1970).
Given training data number actions, observations, hidden states
input, EM essentially performs gradient ascent find transition emission distributions
(locally) maximize likelihood provided data.
361

fiTalvitie & Singh

PSRs Another recently introduced modeling representation predictive state
representation (PSR) (Littman et al., 2002). Instead hidden states, PSRs defined
directly terms system dynamics matrix (described Section 1.2.2). Specifically,
PSRs find set core tests Q whose corresponding columns system dynamics matrix
form basis. Recall system dynamics matrix often finite rank (for instance,
matrix associated POMDP finite hidden states finite linear dimension)
thus Q finite many systems interest. Since predictions Q basis,
prediction test history computed linear combination
predictions Q history.
vector predictions Q called predictive state. belief state
state vector POMDPs, predictive state state vector PSRs. also
maintained application Bayes rule. Specifically, history h, p(q | h)
known core tests q agent takes action observes
observation O, one compute prediction core test q new
history:
P


p(aoq | h)
q Q p(q | h)maoq (q )
P
p(q | hao) =
=
,
(5)


p(ao | h)
q Q p(q | h)mao (q )
maoq (q ) coefficient p(q | h) linear combination computes
prediction p(aoq | h).
So, given set core tests, parameters PSR must learned order
maintain state coefficients mao every action observation
coefficients maoq every action a, observation o, core tests q. Given parameters
predictive state given history recursively computed used make
prediction future. PSRs learned directly estimating system dynamics matrix (James & Singh, 2004; Wolfe, James, & Singh, 2005) or, recently,
sub-matrix derived matrix thereof (Boots, Siddiqi, & Gordon, 2010, 2011) using sample
averages training data. estimated matrix used find set core tests
parameters estimated using linear regression.
Note types models inherently generative. rely
upon maintenance state vector order make predictions and,
seen Equations 4 5, state update equations models rely upon access
one-step predictions perform Bayesian update. such, unlike direct function
approximation approach, one cannot simply choose set predictions model
make. models necessity make predictions.
many reasons desire complete, generative model. makes
possible predictions, model used sample possible future trajectories
useful capability planning. generative model also, definition, flexible
predictions used make. hand, many cases complete,
generative model may difficult obtain. PSR POMDP training methods scale
poorly linear dimension system learned. linear dimension
lower-bounds number hidden states needed represent system POMDP
precisely number core tests needed represent PSR. learning methods
POMDPs PSRs rarely successfully applied systems linear dimension
362

fiLearning Make Predictions Without Generative Model

Figure 2: Size 10 1D Ball Bounce
hundred (though work Boots et al. pushing limits further).
systems interest several orders magnitude higher linear dimension.
Furthermore, complete, generative model overkill problem hand. Recall
seek make predictions; focused making particularly
important predictions . Even problems learning make predictions might
intractable, still possible make simple important predictions.
2.2.1 Abstract Generative Models
discussed earlier, restricted set tests interest, learning problem
often simplified ignoring irrelevant details abstraction. course,
abstraction solve problem partial observability. typically done
apply abstraction training data, discarding irrelevant details (as
Three Card Monte example) apply model learning methods like
ones described abstract data set. Markov setting, cases
observation abstraction greatly simplify learning problem (certainly learning
cards Three Card Monte easier learning cards crowd
weather on).
Ignoring details irrelevant making predictions interest intuitive
significantly simplify learning problem. hand, generative
models, abstract POMDP PSR still make abstract predictions. typically
includes predictions directly interest. extra predictions
require complex model, even abstract generative model intractible learn.
true Three Card Monte example (where generative model ends modeling
dealer well cards). following another simple example phenomenon.
Example. Consider uncontrolled system pictured Figure 2, called 1D Ball
Bounce system. agent observes strip pixels black white.
black pixel represents position ball moves around strip. ball
current direction every time-step moves one pixel direction. Whenever
reaches edge pixel, current direction changes move away edge. Figure
3(a) complete POMDP model 10 pixel version system pictured.
k pixels, POMDP 2k 2 hidden states (because ball one 2
possible directions one k possible positions, except two ends,
one possible direction).
say agent wishes predict whether ball position marked
x next time step. Clearly prediction made paying
attention immediate neighborhood x. details happens
ball far away matter making predictions. So, one could apply
363

fiTalvitie & Singh

(a)

(b)

Figure 3: POMDP model size 10 1D Ball Bounce system (a) abstracted
1D Ball Bounce system (b).

abstraction lumps together observations neighborhood x
looks same. problem abstract generative model system makes
predictions x, also pixels surrounding x. Specifically,
model still makes predictions whether ball enter neighborhood near
future. course depends long since ball left neighborhood.
So, POMDP model abstract system (pictured Figure 3(b)) exactly
state diagram original system, though observations changed reflect
abstraction. abstract system primitive system linear dimension.
order make predictions x, one must condition information
pixels surrounding x. Consequently, generative model also makes predictions
pixels. Counterintuitively, abstract models complexity mainly devoted making
predictions predictions interest. general, learning abstract
model drastically simplify learning problem ignoring irrelevant details, abstract generative model still learns make predictions details relevant,
even directly interest.

2.3 Prediction Profile Models
contribution paper, prediction profile models, seek combine main strengths
two model-learning approaches discussed above. direct approximation
, prediction profile model make predictions interest, others.
such, far simpler generative model, typically make many
extraneous predictions. However, learning method prediction profile models
require set history features given priori. leveraging existing generative
model learning methods, prediction profile models learn maintain state information
necessary making predictions interest.
364

fiLearning Make Predictions Without Generative Model

Figure 4: Prediction profile model 1D Ball Bounce system
typical model learns make predictions future observations emitted
system. main idea behind prediction profile models instead model values
predictions change time, conditioned actions chosen
agent observations emitted system.
already seen example Three Card Monte. prediction profile
model (shown Figure 1) takes observations dealers behavior input outputs
predictions tests interest. predict dealers behavior, takes
account updating predictions interest. Recall that, though Three Card
Monte system arbitrarily complicated (depending dealer), prediction
profile system three states, regardless dealers decision making process.
Another example shown Figure 4. prediction profile system 1D
Ball Bounce system (Figure 2), model must predict whether ball enter
position x next time-step. state prediction profile model labeled
prediction pixel x (white black). transitions labeled observations
3-pixel neighborhood centered position x. case transitions capture ball
entering neighborhood, moving position x, leaving neighborhood, staying away
undetermined amount time, returning again. Recall POMDP model
system 2k 2 hidden states, k number pixels, even ignoring
pixels irrelevant making predictions pixel x. contrast, prediction profile
model always three states, regardless number pixels.
next section formally describe prediction profile models models dynamical system results transformation original system. Subsequent sections
discuss learn prediction profile models data (by converting data
original system data transformed system learning model converted data set) present results help characterize conditions
prediction profile models best applied.

3. Prediction Profile System
formally describe theoretical dynamical system, defined terms
dynamics original system given tests interest. call constructed
system prediction profile system. prediction profile model, goal
365

fiTalvitie & Singh

construct, model prediction profile system (that is, system ideal,
theoretical construct, model may imperfect, approximate, etc.). such, analysis
problem learning prediction profile model depend great deal understanding
properties prediction profile system.
paper make restrictive assumption that, Markov case,
finite number distinct prediction profiles (that is, predictions interest take
finite number distinct values). certainly true partially observable
systems sets tests interest, though true many interesting examples.
Formally, assumption requires map histories finite set prediction profiles:
Assumption 7. Assume exists finite set prediction profiles P = {1 , 2 , . . . , k }
[0, 1]m every history h, (h) P .
assumption allows definition prediction profile system (or P P short)
discrete dynamical system captures sequence prediction profiles time,
given action observation sequence. prediction profile systems actions, observations,
dynamics defined terms quantities associated original system:
Definition 8. prediction profile system defined set observations, set
actions, rule governing dynamics.
1. Observations: set prediction profile observations, OP P , defined set
def
distinct prediction profiles. is, OP P = P = {1 , . . . , k }.
2. Actions: set prediction profile actions, AP P , defined set actiondef
observation pairs original system. is, AP P = O.
3. Dynamics: dynamics prediction profile system deterministically governed . prediction profile history, ha1 , o1 i1 ha2 , o2 i2 . . . haj , oj ij ,
next P P -action, haj+1 , oj+1 i, prediction profile system deterministically
emits P P -observation (a1 o1 a2 o2 . . . aj oj aj+1 oj+1 ).
present key facts prediction profile system. Specifically,
noted prediction profile system always deterministic. Also, though
prediction profile system may Markov (as Three Card Monte example),
general partially observable.
Proposition 9. Even original system stochastic, prediction profile system
always deterministic.
Proof. follows immediately definition: every history corresponds exactly
one prediction profile. P P -history (action-observation-profile sequence) P P action (action-observation pair) fully determine next P P -observation (prediction profile). stochastic observations original system folded unmodeled actions prediction profile system.
Proposition 10. original system Markov, prediction profile system Markov.
366

fiLearning Make Predictions Without Generative Model

Proof. definition, original system Markov prediction profile time
step depends recent observation. So, time step t, current profile
, agent takes action at+1 observes observation ot+1 , next profile simply
t+1 = arkov (ot+1 ). So, fact, original system Markov, prediction profile
system satisfies even stronger condition: next P P -observation fully determined
P P -action dependence history whatsoever (including recent
P P -observation).
Proposition 11. Even original system partially observable, prediction profile
system may Markov.
Proof. Consider Three Card Monte example. original system clearly non-Markov
(the recent observation, dealers recent swap, tells one little
location ace). However, prediction profile system tests interest
regarding location special card (pictured Figure 1) Markov. next profile
fully determined current profile P P -action.
general, however, P P system may partially observable. Though Three
Card Monte example current prediction profile next action-observation pair
together fully determine next prediction profile, general next prediction profile
determined history action-observation pairs (and prediction profiles).
Proposition 12. prediction profile system may partially observable.
Proof. Recall 1D Ball Bounce example. corresponding prediction profile system
shown Figure 4. Note two distinct states update graph associated
prediction profile (pixel x white). Given current prediction profile
(pixel x white) P P -action (observe ball neighboring pixel left
right), one cannot determine whether ball entering leaving neighborhood,
thus cannot uniquely determine next profile. prediction profile system
partially observable.
So, general, prediction profile system deterministic, partially-observable dynamical system. model prediction profile system used make
predictions interest. such, one wishes use prediction profile model generative
model, one must select tests interest carefully. instance:
Proposition 13. tests interest include set one-step primitive tests,
{ao | A, O} , model prediction profile system used
generative model original system.
Proof. follows immediately definition generative model.
special case prediction profile model complete, generative
model system, shown Section 5 one desires generative model,
essentially never preferable learn prediction profile model traditional
representation. prediction profile model best applied relatively simple make
maintain predictions interest comparison making predictions. general,
367

fiTalvitie & Singh

Figure 5: Flow algorithm.
prediction profile model conditions observations, necessarily predict
next observation. such, model prediction profile system cannot typically
used purposes model-based planning/control like generative model could.
experiments Section 6 demonstrate output prediction profile models can,
however, useful model-free control methods.

4. Learning Prediction Profile Model
definition prediction profile system straightforwardly suggests method
learning prediction profile models (estimate prediction profiles, learn model
dynamics using standard model-learning technique). section present
learning algorithm, discussing main practical challenges arise.
Let training data set trajectories experience original system (actionobservation sequences) let = {t1 , t2 , . . . , tk } set tests interest.
algorithm presented section learn model prediction profile system
data S. algorithm three main steps (pictured Figure 5). First training
data used estimate prediction profiles (both number unique profiles
values). Next, learned set prediction profiles used translate training data
trajectories experience prediction profile system. Finally, applicable model
learning method trained transformed data learn model prediction
profile system. Ultimately, experiments, learned prediction profile models
evaluated useful predictions features control.
4.1 Estimating Prediction Profiles
Given , first step learning prediction profile model determine
many distinct prediction profiles are, well values. estimated prediction
test interest history h is:
p(t | h) =

# times succeeds h
.
# times acts(t) taken h
def

(6)

One could, point, directly estimate letting (h) = hp(t1 | h), p(t2 | h), . . . , p(tk |
h)i. course, due sampling error, unlikely estimated profiles
exactly same, even true underlying prediction profiles identical. So,
368

fiLearning Make Predictions Without Generative Model

estimate number distinct underlying profiles, statistical tests used find
histories significantly different prediction profiles.
compare profiles two histories, likelihood-ratio test homogeneity performed counts test interest two histories. statistical test
associated test interest rejects null hypothesis prediction
histories, two histories different prediction profiles.
order find set distinct prediction profiles, greedily cluster estimated
prediction profiles. Specifically, initially empty set exemplar histories maintained.
algorithm searches histories agents experience, comparing historys
estimated profile exemplar histories estimated profiles. candidate historys
profile significantly different profiles exemplar histories, candidate
added new exemplar. end, estimated profiles corresponding exemplar
histories used set prediction profiles. order obtain best estimates
possible, search ordered prioritize histories lots associated data.
prediction profile estimation procedure two main sources complexity.
first sample complexity estimating prediction profiles. take great
deal exploration see history enough times obtain good statistics, especially
number actions observations large. issue could addressed adding
generalization estimation procedure, data one sample trajectory could
improve estimates many similar histories. one experiments Section 6,
observation abstraction employed simple form generalization. second
bottleneck computational complexity searching prediction profiles, involves exhaustively enumerating histories agents experience. would valuable
develop heuristics identify histories likely provide new profiles, order
avoid searching histories. experiments Section 6, simple heuristic
limiting search short histories employed. Long histories tend less
associated data, therefore less likely provide distinguishably new profiles.
4.2 Generating Prediction Profile Trajectories
generated finite set distinct prediction profiles, next step translate
agents experience sequences action-observation pairs prediction profiles.
trajectories used train model prediction profile system.
process translating action-observation sequence prediction profile trajectory straightforward and, apart practical concerns, follows directly
Definition 8. Recall that, action-observation sequence = a1 o1 a2 o2 . . . ak ok , corresponding P P -action sequence ha1 , o1 iha2 , o2 . . . hak , ok i. corresponding sequence
profiles (a1 o1 )(a1 o1 a2 o2 ) . . . (a1 o1 . . . ak ok ). Thus, principle, every primitive actionobservation sequence translated action-observation-profile sequence.
course available generate sequence prediction profiles. So,
necessary use approximation , generated training data. Specifically,
estimated predictions tests interest history h (computed using Equation
6) compared, using statistical tests, set distinct estimated prediction profiles
Section 4.1. one estimated profile statistically significantly
different estimated predictions h, let (h) = .
369

fiTalvitie & Singh

Given sufficient data, statistical tests uniquely identify correct match
high probability. practice, however, histories much associated
data. possible case test homogeneity fail reject null
hypothesis two profiles. indicates enough data distinguish multiple possible matches. experiments Section 6, two different
heuristic strategies handling situation employed. first strategy lets (h)
matching profile smallest empirical KL-Divergence estimated
predictions (summed tests interest). heuristic choice may lead
noise prediction profile labeling, could turn affect accuracy learned
model. second strategy simply cut trajectory point multiple
matches occur, rather risk assigning incorrect labeling. ensures labels
appear prediction profile trajectories reasonable level confidence
correctness. However, wasteful throw training data way.
4.3 Learning Prediction Profile Model
translation step produces set trajectories interaction prediction
profile system. Recall prediction profile system deterministic, partially observable, discrete dynamical system trajectories used train model
prediction profile system using, principle, applicable model-learning method.
issue faced models prediction profile system present
usual discrete dynamical systems modeling setting. prediction profile labels
present training data, actually using model available. Say
current history h, action a1 taken observation o1 emitted. Together,
action-observation pair constitutes P P -action. model prediction profile
system, prediction profile model identify next profile, . profile used
compute predictions p(t | ha1 o1 ) tests interest history ha1 o1 .
another action a2 observation o2 occur. necessary update PP-models
state order obtain next prediction profile. typical dynamical systems model
makes predictions next observation, able update state
actual observation occurred. prediction profile models observations prediction
profiles themselves, observable interacting world. such,
prediction profile model update state prediction profile predicted
(). updated, prediction profile model obtain profile follows ha2 , o2
gives predictions tests interest new history ha1 o1 a2 o2 .
prediction profile model perfect model prediction profile system,
poses problems. prediction profile system deterministic, need
observe true prediction profile label; fully determined history. practice,
course, model imperfect different modeling representations require
different considerations performing two functions providing predictions
tests interest, providing profile sake updating model.
4.3.1 PP-POMDPs
Since prediction profile system partially observable natural model using POMDP. Unfortunately, even training data deterministic sys370

fiLearning Make Predictions Without Generative Model

tem, POMDP training using EM algorithm generally provide deterministic
POMDP. Thus, given history, learned POMDP model prediction profile
system (PP-POMDP) provide distribution prediction profiles instead deterministically providing one profile associated history. implementation
used Section 6 simply takes likely profile distribution profile
associated history uses make predictions tests interest, well
update POMDP model.
4.3.2 PP-LPSTs
Another natural choice representation prediction profile model looping predictive
suffix tree (LPST) (Holmes & Isbell, 2006). LPSTs specialized deterministic, partially
observable systems. such, could used model original system (which
assumed stochastic general), apply prediction profile system
(and determinized like POMDP).
Briefly, LPST captures parts recent history relevant predicting next
observation. Every node tree corresponds action-observation pair. node
may leaf, may children, may loop one ancestors. Every leaf
tree corresponds history suffix deterministic prediction observation
every action. order predict next observation particular history, one
reads history reverse order, following corresponding links tree leaf
reached, gives prediction. Holmes Isbell provide learning algorithm that,
certain conditions training data, guaranteed produce optimal tree.
reader referred work Holmes Isbell (2006) details.
One weakness LPSTs, however, fail make prediction next
observation current history lead leaf node tree (or leaf
node reached prediction action queried). typically occurs
history suffixes occur training data occur using
model. PP-LPST, mean histories model cannot uniquely
determine corresponding prediction profile. happens implementation
used Section 6 simply finds longest suffix current history occur
data. suffix associated multiple prediction profiles (otherwise LPST
would provided prediction). make predictions tests interest, model
provides average prediction set profiles. profile used update
model picked set uniformly randomly.
4.3.3 PP-PSRs
Applying PSR learning algorithms prediction profile data poses practical concern.
Specifically, methods attempt estimate system dynamics matrix (James & Singh,
2004; Wolfe et al., 2005) implicitly presume every action sequence could principle
taken every history. action sequences taken histories
others, matrix undefined entries. poses challenges rank
estimation (and, indeed, definition model representation). Unfortunately,
case prediction profile system since P P -actions (action-observation
pairs) completely agents control; partly selected environ371

fiTalvitie & Singh

ment itself. recent spectral learning algorithms presented Boots et al. (2010) may
able side-step issue, flexibility selecting predictions
estimated use model-learning process, though investigated
possibility work.
Note that, though method learning prediction profile model involves standard
model-learning methods partially observable environments, result generative
model original system. prediction profile model generative model
prediction profile system and, such, cannot used make predictions
original system, predictions interest.

5. Complexity Prediction Profile System
learning algorithm presented evaluated empirically Section 6. First,
however, analyze complexity prediction profile system relation complexity original system. give indication difficult learn
prediction profile model provide insight appropriate learn prediction
profile model typical generative model approach.
many factors affect complexity learning model. section
largely focus linear dimension measure complexity, taking view that,
generally speaking, systems lower linear dimension easier learn systems
larger linear dimension. discussed Section 1.2.2, generally true POMDPs,
linear dimension lower-bounds number hidden states. comparing
linear dimension prediction profile system original system give
idea whether would easier learn PP-POMDP learn standard
POMDP original system. course, model-learning methods
complexity measures would appropriate (for instance known
precisely LPSTs interact linear dimension). Extending results
measures complexity may interesting topic future investigation.
5.1 Linear Dimension Comparison
section discuss linear dimension prediction profile system relates
original system. first result proof concept simply states
exist problems prediction profile system vastly simple
original system. fact, problem already presented.
Proposition 14. prediction profile system linear dimension arbitrarily
lower original system.
Proof. Recall Three Card Monte example. Thus far domain described
without describing dealers behavior. However, note prediction profile system
tests interest relating location special card (pictured Figure 1)
linear dimension 3, regardless dealers swaps chosen. complex
dealer chosen, original system high linear dimension, prediction
profile systems linear dimension remain constant. instance, experiments
Section 6, dealer chooses cards swap stochastically, likely choose
372

fiLearning Make Predictions Without Generative Model

swap selected least often far. Thus, order predict dealers
next decision, one must count many times swap chosen history
result system effectively infinite linear dimension.
hand, prediction profile models panacea. following results
indicate problems learning prediction profile model would
advisable learning standard generative model, linear dimension
prediction profile system far greater original system. Later
section special cases characterized prediction profile models likely
useful. next result shows linear dimension prediction profile model
infinite original system finite linear dimension, via lower bound
linear dimension true deterministic dynamical systems.
Proposition 15. deterministic dynamical system actions A, observations
O, linear dimension, n log(|A|1)+log(|O|+1)
.
log |A|
Proof. See Appendix A.1.
Proposition 15 applies deterministic dynamical systems, certainly applies prediction profile system. Though loose bound, basic implication
number prediction profiles (the observations P P ) increases comparison number action-observation pairs (the actions P P ), linear dimension
prediction profile system necessarily increases. bound also clearly illustrates
importance assumption finite number distinct prediction profiles.
Corollary 16. infinitely many distinct prediction profiles, prediction profile
system infinite linear dimension.
Proof. Clearly |AP P | = |A O| finite long finitely many actions
observations. So, last result follows immediately number distinct
prediction profiles |OP P | approaches infinity, must linear dimension
prediction profile system.
Hence, long prediction profile models represented using methods rely
finite linear dimension, critical finitely many prediction profiles.
Note fundamental barrier, side effect representational choice.
Model learning methods sensitive linear dimension (such designed
model continuous dynamical systems) may able effectively capture systems
infinitely many prediction profiles.
One conclusion drawn last results knowing linear dimension
original system not, itself, necessarily say much complexity
prediction profile system. prediction profile system may far simpler far
complex original system. Thus may informative turn factors
trying characterize complexity prediction profile system.
373

fiTalvitie & Singh

5.2 Bounding Complexity Prediction Profile System
results previous section take account obviously important aspect
prediction profile system: predictions asked make. predictions
interest made simply keeping track little information.
predictions rely great deal history information therefore require
complex model. next result identifies worst case set tests interest
system: tests interest whose corresponding prediction profile model highest
linear dimension. Ultimately section present (non-exhaustive) conditions
prediction profile system likely simpler original system.
Proposition 17. given system set tests interest, linear dimension
corresponding prediction profile system greater prediction profile
system associated set core tests system (as described Section 2.2).
Proof. See Appendix A.2.
worst case identified, one immediately obtain bounds complex
prediction profile system possibly be.
Corollary 18. system set tests interest, corresponding prediction
profile system linear dimension greater number distinct predictive states
original system.
Proof. prediction profile system set core tests Q deterministic MDP
observations prediction profiles Q (that is, predictive states). is, state
associated unique prediction profile. linear dimension MDP never
greater number observations (Singh et al., 2004). Therefore, previous
result prediction profile system set tests interest linear dimension
greater number predictive states.
Corollary 19. original system POMDP, prediction profile system set
tests interest linear dimension greater number distinct belief states.
Proof. follows immediately previous result fact number
distinct predictive states greater number distinct belief states (Littman
et al., 2002).
bounds presented far help explain prediction profile system
complex original system. However, focused worst possible
choice tests interest, little illuminate opposite true. prediction
profile model complex asked perform task generative
model: keep track much information history necessary make possible
predictions (or equivalently, predictive state belief state). results indicate
that, generally speaking, one desires generative model, standard approaches would
preferable learning prediction profile model.
hand, stated goal learn generative model, instead
focus particular predictions hopefully far simpler make
predictions. examples seen make clear cases, predictions
374

fiLearning Make Predictions Without Generative Model

made prediction profile model far simpler generative model original
system. general one might expect prediction profile model simple
predictions interest rely small amount state information required
maintain generative model. next bound aligns intuitive reasoning.
Essentially result points often much hidden state information
POMDP irrelevant predictions interest. linear dimension
prediction profile system bounded number distinct beliefs relevant
parts hidden state, rather number distinct beliefs states overall. idea
result one impose abstraction hidden states POMDP
(not observations) still allows predictions interest made accurately
allows abstract belief states computed accurately, prediction profile
systems linear dimension bounded number abstract belief states.
Proposition 20. Consider POMDP hidden states S, actions A, observations
O. Let set tests interest. Let ai action taken time-step i, si
hidden state reached taking action ai , oi observation emitted si . Now,
consider surjection : mapping hidden states set abstract states
following properties:
1. pair primitive states s1 , s2 S, (s1 ) = (s2 ), time-step
test interest , p(t | si = s1 ) = p(t | si = s2 ).
2. pair primitive states s1 , s2 S, (s1 ) = (s2 ), time-step i,
abstract state , observation O, action A,
Pr((si+1 ) = | si = s1 ,ai+1 = a, oi+1 = o) =
Pr((si+1 ) = | si = s2 , ai+1 = a, oi+1 = o).
, prediction profile system linear dimension greater
number distinct beliefs abstract states, .
Proof. See Appendix A.3
things note result. First, surjection always exists
def
properties 1 2. One always define : (s) = s. degenerate
case trivially satisfies requirements Proposition 20 recovers bound given
Corollary 19. However, Proposition 20 applies surjections satisfy conditions.
must surjection satisfies conditions results smallest number
beliefs abstract states. Essentially, one ignores much state information
possible still allowing predictions interest made accurately
surjection tightly bounds complexity prediction profile system (even
known).
course, may still large even infinite number distinct beliefs, even
abstract states, factors must come play ensure simple prediction profile
system. Furthermore, result characterize settings prediction
profile system simple. said, result support intuition
375

fiTalvitie & Singh

prediction profile system tend simple predictions asked make
depend small amounts state information.
order build intuition result relates earlier examples, recall
Three Card Monte problem. Three Card Monte two sources hidden state:
aces unobserved position whatever hidden mechanism dealer uses make
decisions. Clearly agents predictions interest depend first part
hidden state. So, case one satisfy Property 1 surjection maps
two hidden states abstract state ace position, regardless
dealers state. 3 abstract states (one possible
position), even though might infinitely many true hidden states. Now, different
states corresponding ace position different distributions aces
next position; distribution does, all, depend upon dealers state. However,
Property 2 statement distribution next abstract state given
observation emitted entering abstract state. one knows current
abstract state observes dealer does, next abstract state fully determined.
Property 2 holds well. fact, since aces position known beginning
game, means current abstract state always known absolute certainty, even
though beliefs dealers state general uncertain. Hence, 3
distinct beliefs abstract states (one state). such, prediction profile
models linear dimension upper-bounded 3, regardless dealers complexity (and
case bound met).
5.3 Bounding Number Prediction Profiles
previous section describes conditions prediction profile system
may lower linear dimension original system. Also concern number
prediction profiles, whether number finite. section briefly discuss
(non-exhaustive) cases number prediction profiles bounded.
One case already discussed original system Markov.
case number prediction profiles bounded number observations (states).
course, original system Markov, little need use prediction profile
models. Another, similar case system partially observable, completely
deterministic (that is, next observation completely determined history
selected action). system deterministic POMDP given history
current hidden state known. such, number belief states bounded
number hidden states. Since cannot prediction profiles belief states,
number prediction profiles bounded well.
One move away determinism different ways. First, note key
property deterministic POMDP hidden state fully determined history.
possible satisfy property even stochastic systems, long one uniquely
determine hidden state, given observation emitted arriving there.
case, observations emitted stochastically, number belief states (and
number prediction profiles) still bounded number hidden states.
Another step away determinism class systems, introduced Littman (1996),
called Det-POMDPs. Det-POMDP POMDP transition function
376

fiLearning Make Predictions Without Generative Model

observation function deterministic, initial state distribution may
stochastic. Det-POMDP deterministic dynamical system, uncertainty
hidden state. uncertainty, system appears emit observations
stochastically. underlying dynamics deterministic. Littman showed
Det-POMDP n hidden states initial state distribution states
support (n + 1)m 1 distinct belief states. So, bounds number
prediction profiles well.
Finally, importantly, hidden state abstracted Proposition 20,
properties really need hold abstract beliefs. is, environment
may complex stochastic arbitrary ways, abstract hidden state
described Proposition 20 fully determined history, number prediction
profiles bounded number abstract states (as case Three Card Monte).
Similarly, Det-POMDP-like properties imagined abstract hidden states well.
cases means cover situations number prediction profiles
bounded, seem indicate class problems number
prediction profiles finite quite broad, may contain many interesting examples.

6. Experiments
section empirically evaluate prediction profile model learning procedure developed Section 4. experiment agent faces environment generative
model would challenge learn due high linear dimension. However,
problem agent could make good decisions could predictions small
number important tests. prediction profile model learned important tests
accuracy learned predictions evaluated.
experiments also demonstrate one possible use prediction profile models (and
partial models general) control. generative, prediction profile
models cannot typically used directly offline, model-based planning methods. However, output may useful model-free methods control. Specifically,
experiments, predictions made learned prediction profile models provided
features policy gradient algorithm.
6.1 Predictive Features Policy Gradient
Policy gradient methods (e.g., Williams, 1992; Baxter & Bartlett, 2000; Peters & Schaal,
2008) successful viable options model-free control partially observable domains. Though differences various algorithms, common
thread assume parametric form agents policy attempt
alter parameters direction gradient respect expected average reward. experiments make use Online GPOMDP Average Reward Baseline
(Weaver & Tao, 2001), OLGARB (readers referred original paper details).
OLGARB assumes set features history, agents policy takes
parametric form:
Pr(a | h; w)
~ =P

e

P



377

wi,a fi (h)
P
wi,a fi (h)



e

fiTalvitie & Singh

fi (h) ith feature parameter wi,a weight specific feature
action considered.
Typically features used policy gradient features directly read
history (e.g., features recent observations presence/absence
event history). difficult know priori historical features
important making good control decisions. contrast, idea experiments
provide values predictions features. predictive features direct
consequences control, provide information effects possible behaviors
agent might engage in. such, may easier select set predictive features
likely informative optimal action take (e.g., agent
reach goal state takes action? taking action damage
agent?). Furthermore, information may expressed compactly terms prediction
would complex specify purely terms past observations. seen
discussion PSRs Section 2.2, arbitrary-length history fully captured
finite set short-term predictions. reasons seems reasonable speculate
predictive features, maintained prediction profile model, may particularly
valuable model-free control methods like policy gradient.
6.2 Experimental Setup
learning algorithm applied two example problems. problem prediction
profile models learned various amounts training data (using LPSTs
POMDPs representation using strategies dealing multiple matches,
described Section 4.3). prediction accuracy models evaluated, well
useful predictions features control. training data generated
executing uniform random policy environment.
free parameter learning algorithm significance value statistical
tests, . Given large number contingency tests performed
data set, compound probability false negative, set fairly
low. experiments use = 0.00001, though several reasonable values tried
similar results. discussed Section 4, also maximum length
histories consider search prediction profiles. cutoff allows search
avoid considering long histories, many long histories search
unlikely provide new prediction profiles.
prediction profile model learned, predictions evaluated features
policy gradient algorithm OLGARB. Specifically, test interest unit
interval split 10 equally-sized bins b binary feature ft,b provided
1 prediction lies bin b, 0 otherwise. Also provided binary features fo ,
possible observation o. feature fo = 1 recent observation
0, otherwise. parameters OLGARB, learning rate discount factor, set
0.01 0.95, respectively experiments.
evaluate prediction profile model OLGARB run 1,000,000 steps. average
reward obtained root mean squared error (RMSE) predictions tests
interest accrued model along way reported. Prediction performance
compared obtained learning POMDP training data using
378

fiLearning Make Predictions Without Generative Model

Prediction Performance

Control Performance
0.1

Avg. Reward (20 trials)

Avg. RMSE (20 Trials)

1
0.8
0.6
Flat POMDP

0.4
PPLPST(KLD)
PPLPST(cut)

0.2
0
0

PPPOMDP(KLD)
PPPOMDP(cut)

2

4

# Training Trajectories

True

0.06
0.04

PPPOMDP(KLD)
PPPOMDP(cut)

0.02

PPLPST(KLD)
PPLPST(cut)

0
Flat POMDP

0.02
0.04
0.06
0

6

Expert

0.08

SOM

2

4

6

# Training Trajectories x 104

4

x 10

Figure 6: Results Three Card Monte domain.
make predictions interest. problems complex feasibly train
POMDP correct number underlying states, 30-state POMDPs used
(stopping EM maximum 50 iterations)2 . Control performance compared
obtained OLGARB using predictions provided learned POMDP model
features, well OLGARB using true predictions features (the best prediction
profile model could hope do), OLGARB using second-order Markov features (the two
recent observations, well action them) predictive features
all, hand-coded expert policy.
6.3 Three Card Monte
first domain Three Card Monte example. agent presented three
cards. Initially, card middle (card 2) ace. agent four actions
available it: watch, f lip1, f lip2, f lip3. agent chooses flip action, observes
whether card flipped special card. agent chooses watch action,
dealer swap positions two cards, case agent observes two
cards swapped, dealer ask guess. dealer asked
guess, watch results 0 reward flip action results -1 reward. dealer
asks guess agent flips special card, agent gets reward 1.
agent flips one two cards, doesnt flip card (by selecting watch),
gets reward -1. agent three tests interest, take form f lipX ace,
card X (that is, flip card X, see ace?).
discussed previously, complexity system directly related complexity dealers decision-making process. experiment, agent chooses
watch dealer swaps pair cards swapped least far probability
0.5; probability 0.4 chooses uniformly amongst pairs cards; otherwise
asks guess. Since dealer keeping count many times swap
made, process governing dynamics effectively infinite linear dimension.
2. Similar results obtained 5, 10, 15, 20, 25 states.

379

fiTalvitie & Singh

prediction profile system, hand, 3 states, regardless dealers
complexity (see Figure 1).
Training trajectories length 10. Figure 6 shows results various amounts
training data, averaged 20 trials. PP-POMDPs PP-LPSTs learned make
accurate predictions tests interest, eventually achieving zero prediction error.
case, PP-POMDPs using less data. likely POMDP model
readily able take advantage fact prediction profile system Three
Card Monte Markov. expected, standard POMDP model unable accurately
predict tests interest.
Also compared two different strategies dealing multiple matches discussed Section 4.3. Recall first one (marked KLD graph) picks
matching profile smallest empirical KL-Divergence estimated predictions.
second (marked cut graph) simply cuts trajectory point
multiple match avoid incorrect labels. problem two strategies result almost exactly performance. likely profiles Three
Card Monte deterministic, therefore quite easy distinguish (making multiple
matches unlikely). next experiment stochastic profiles.
predictive features provided prediction profile models clearly useful
control, control performance OLGARB using predictions approaches,
eventually exactly matches OLGARB using true predictions (marked True).
inaccurate predictions provided POMDP useful control; OLGARB using POMDP provided predictions even break even, meaning loses
game often wins. POMDP features did, however, seem contain
useful information beyond provided second-order Markov features (marked
SOM) which, one might expect, performed poorly.
6.4 Shooting Gallery
second example called Shooting Gallery, pictured Figure 7(a). agent
gun aimed fixed position 88 grid (marked X) . target moves
diagonally, bouncing boundaries image 22 obstacles (an example
trajectory pictured). agents task shoot target. agent two actions:
watch shoot. agent chooses watch, gets 0 reward. agent chooses
shoot target crosshairs step agent shoots, agent gets
reward 10, otherwise gets reward -5. Whenever agent hits target,
shooting range resets: agent receives special reset observation, 2 2 square
range made obstacle probability 0.1, target placed random
position. also 0.01 probability range reset every time step.
difficulty target sticky. Every time step probability 0.7 moves
current direction, probability 0.3 sticks place. Thus, looking recent
history, agent may able determine targets current direction. agent
needs know probability target sights next step, clearly
single test interest is: watch target (that choose watch action,
target enter crosshairs?). target far crosshairs, prediction
test 0. target crosshairs, 0.3. target
380

fiLearning Make Predictions Without Generative Model

(a)

(b)

Figure 7: Shooting Gallery domain. (a) possible arrangement obstacles trajectory target (lighter back time). case target
definitely enter agents crosshairs, since bounce obstacle.
(b) abstraction applied recent observation.

near crosshairs, model must determine whether prediction 0.7 0, based
targets previous behavior (its direction) configuration nearby obstacles.
problem stochastic prediction profiles, expected data
required differentiate them. Also, due number possible configurations
obstacles positions target, system roughly 4,000,000 observations
even latent states. results large number possible histories,
small probability occurring. discussed Section 4, lead large sample
complexity obtaining good estimates prediction profiles. addressed
simple form generalization: observation abstraction. Two observations treated
target position configuration obstacles
immediate vicinity target same. words, abstract observation
contains information targets position obstacles surrounding
target, placement obstacles far away target (see Figure 7(b))
example. abstraction, abstract observations still provide enough detail
make accurate predictions. is, two histories indeed prediction profile
action sequence observation sequences correspond
sequence aggregate observations. enables one sample trajectory improve
estimates several histories, though, even abstraction, still
2000 action-observation pairs. observation abstraction applied training
POMDP model.
Training trajectories length 4 search profiles restricted length
3 histories. Results shown Figure 8. Perhaps eye-catching feature
results upward trending curve prediction error graph, corresponding
PP-POMDP KL-Divergence based matching (labeled PP-POMDP(KLD)).
Recall danger KL-divergence based matching strategy may produce
incorrect labels training data. Apparently errors severe enough
problem drastically mislead POMDP model. small amount data obtained
381

fiTalvitie & Singh

Prediction Performance

Control Performance
0.025

Avg. Reward (20 Trials)

Avg. RMSE (20 Trials)

0.25
0.2
PPPOMDP(cut)

0.15
Flat POMDP

0.1

PPPOMDP(KLD)

0.05

PPLPST(cut)
PPLPST(KLD)

0
0

2

4

6

8

# Training Trajectories

0.02
0.015
0.01

PPLPST(KLD)
PPPOMDP(KLD)

PPLPST(cut)

0.005
PPPOMDP(cut)

0
0.005
0

10
5
x 10

Expert
True

SOM
Flat POMDP

2

4

6

8

10

# Training Trajectories x 105

Figure 8: Results Shooting Gallery domain.
good prediction error, data came misleading labelings,
performance suffered. PP-POMDP trained matching method (PPPOMDP(cut)) displays typical learning curve (more data results better error),
though takes great deal data begins make reasonable predictions.
cutting trajectories multiple matches throws away data might
informative model. PP-LPSTs generally outperform PP-POMDPs
problem. trajectory cutting method, PP-LPST (PP-LPST(cut))
quickly outperforms flat POMDP and, enough data, outperforms versions
PP-POMDP. PP-LPST KL-divergence based matching (PP-LPST(KLD))
far best performer, quickly achieving small prediction error. Clearly incorrect
labels training data dramatic effect LPST learning, possibly
because, suffix tree, LPST mostly makes predictions based recent history,
limiting effects labeling errors time-steps.
Control performance essentially mirrors prediction performance, interesting
exceptions. Note even though PP-POMDP(KLD) obtains roughly prediction
error flat POMDP 1,000,000 training trajectories, predictive features provides
still result substantially better control performance. indicates that, even though
PP-POMDP making errors exact values predictions, still captured
important dynamics predictions flat POMDP has. flat POMDP
provides features roughly useful second-order Markov features,
result good performance. Again, OLGARB using features break
even, meaning wasting bullets target likely enter crosshairs.
best-performing prediction profile model, PP-LPST(KLD) approaches performance
OLGARB using true predictions sufficient data.

7. Related Work
idea modeling aspects observations dynamical system
certainly raised before. instance, recent example Rudary (2008) learned linear382

fiLearning Make Predictions Without Generative Model

Gaussian models continuous partially observable environments dimensions
observation treated unmodeled exogenous input. inputs assumed
linear effect state transition. Along somewhat similar lines, context
model minimization (taking given, complete model deriving simpler, abstract model
preserves value function) Wolfe (2010) constructed abstract model
shadow model predicts observation details ignored abstraction.
shadow model takes abstract observations abstract model unmodeled input.
Splitting observation modeled un-modeled components learning
generative model certainly related approach. case, model would make
conditional predictions modeled portion observation, given exogenous
inputs (as well actual actions history). Prediction profile models take
extreme, treating entire observation input. Instead predicting future sequences
piece next observation conditioned another piece, prediction profile models
predict values arbitrary set predictions interest next time step, given
entire action observation. allows significantly freedom choosing
predictions model make (and, importantly, make).
One modeling method closely related prediction profiles Causal State Splitting
Reconstruction (CSSR) (Shalizi & Klinker, 2004). CSSR algorithm learning generative models discrete, partially observable, uncontrolled dynamical systems. basic
idea define equivalence relation histories two histories considered
equivalent associated identical distributions possible futures.
equivalence classes relation called causal states. CSSR algorithm learns
number causal states, distribution next observations associated
causal state, transitions one causal state next, given observation.
straightforward see one-to-one correspondance causal states
predictive states PSR. such, causal state model precisely prediction
profile model set tests interest Q, set core tests. correspondance hand, results Section 5.2 show many cases number causal
states greatly exceed linear dimension original system therefore
CSSR may inadvisable many problems, comparison standard modeling
approaches. possible CSSR algorithm could adapted general
setting arbitrary sets tests interest, however algorithm rely heavily
fact prediction profile model Q tests interest Markov,
generally case sets tests interest.
mentioned Section 2, McCallum (1995) presented UTree, suffix-tree-based algorithm learning value functions partially observable environments. UTree
learns value function (a prediction future rewards), make
predictions observations, UTree learn non-generative partial model. Wolfe
Barto (2006) extend UTree make one-step predictions particular observation
features rather limiting predictions value function. learns suffix
tree, UTree able operate non-episodic domains (whereas method requires seeing
histories multiple times) required explicitly search distinct prediction profiles. UTree also directly incorporates abstraction learning, learning simultaneously
observation features important, history suffix attend them.
said, main drawback suffix tree approach tree takes account
383

fiTalvitie & Singh

information relatively recent history (a suffix history). cannot remember
important information arbitrary number steps recurrent state-based model
can. Three Card Monte example, instance, access depth-limited suffix
history would little help. order track ace, one must take account
every move dealer made since beginning game. UTree would essentially
forget card games length surpassed depth memory.
McCallum (1993) Mahmud (2010) provide methods learning state machines
predict immediate reward resulting given action-observation pair partially observable control tasks (and thus suffer issue finite-depth memory
suffix trees do). Thus, learning problem special case ours,
restrict models make one-step predictions immediate reward.
cases, simple model incrementally greedily elaborated proposing states split
evaluating results (via statistical tests case McCallum via likelihood
hill-climbing case Mahmud). McCallum expressed concern approach
difficulty extracting long-range dependencies (for instance, learning attend event
appear affect distribution rewards many steps later);
clear extent Mahmuds approach addresses issue. methods
advantages UTree, notably applied non-episodic
domains. said, approach advantages well. re-casting problem
learning non-generative model standard generative model-learning problem,
able gain deeper understanding complexity applicability prediction
profile models compared standard generative models. Furthermore, allowed us incorporate standard, well-studied generative model-learning methods
learning algorithm, thereby leveraging strengths non-generative setting.
specifically, resulting principled (albeit heuristic) learning algorithm,
rely guess-and-check stochastic local search.
prediction profile system also similar spirit finite state controllers
POMDPs. Sondik (1978) noted cases, possible represent optimal policy POMDP finite state machine. finite state controllers
much like prediction profile models take action-observation pairs inputs,
instead outputting predictions associated current history, output
optimal action take. Multiple authors (e.g., Hansen, 1998; Poupart & Boutilier, 2003)
provide techniques learning finite state controllers. However, algorithms typically
require access complete POMDP model world begin which, setting,
assumed impractical.

8. Conclusions Future Directions
standard methods learning models partially observable environments learn
generative models. one small set predictions interest make (and
therefore require full power generative model), one ignore irrelevant
detail via abstraction simplify learning problem. Even so, generative model
necessarily make predictions relevant details, even directly
interest. seen example resulting model counter-intuitively
complex, even predictions model asked make quite simple.
384

fiLearning Make Predictions Without Generative Model

presented prediction profile models, non-generative models partially
observable systems make predictions interest others. main idea
prediction profile models learn model dynamics predictions
change time, rather model dynamics system. learning
method prediction profile models learns transformation training data
applies standard methods transformed data (assuming predictions interest
take finite number distinct values). result, retains advantages methods
like EM POMDPs learn information history must maintained order
make predictions (rather requiring set history features priori). showed
prediction profile model far simpler generative model, though
also far complex, depending predictions asked make. However,
predictions interest depend relatively little state information, prediction profile
models provide substantial savings standard modeling methods POMDPs.
experiments Section 6 demonstrate possible learn prediction
profile models contrived systems complex POMDPs, specific learning algorithm presented likely scale natural domains without modification.
critical scaling issues prediction profile models sample complexity
estimating prediction profiles, computational complexity searching prediction profiles translating data. cases, critical source complexity
essentially many distinct histories training data (more distinct histories
means data spread thin amongst estimated profiles search
through). such, generalization prediction estimates across many histories would
key step toward applying ideas realistic domains. currently developing learning algorithms combine ideas behind prediction profile models
methods learning abstractions allow many essentially equivalent histories
lumped together purposes estimating predictions interest.
Another limitation prediction profile model learning method presented
reliance assumption finite number prediction profiles. assumption
hold many cases, ideal method would able deal gracefully large
infinite number prediction profiles. One possibility simply cluster predictions
ways. instance, one may desire certain level prediction accuracy
may therefore willing lump distinct prediction profiles together exchange
simpler prediction profile system. Another idea would learn prediction profile model
using continuous-valued representations Kalman filters (Kalman, 1960) PLGs
(Rudary, Singh, & Wingate, 2005) (or nonlinear variants, e.g., Julier & Uhlmann,
1997; Wingate, 2008). representations learning algorithms explicitly deal
systems infinite number observations (prediction profiles case). Even
finitely many prediction profiles, methods learning non-linear continuous
models may still able (approximately) capture discrete dynamics.
Additionally, though results focused discrete systems, main motivation
behind prediction profile models also purchase continuous setting. Typical methods learning models partially observable systems continuous systems, much like
discrete valued counterparts, learn generative models. such, non-generative
approach prediction profile models may provide similar benefits continuous setting
predictions need made. setting, prediction profiles might represented
385

fiTalvitie & Singh

parametric form (for instance, mean variance Gaussian). main idea
prediction profile models (though specific method presented here) could still
applied: learn model dynamics distribution parameters, rather
dynamics system itself.
Finally, discussed work tests interest determined, predict selected. Automatically selecting interesting/important predictive features targets partial models would certainly
interesting research challenge. course, would depend predictions
used for. predictions used features control, done
experiments, would certainly seem intuitive start predictive features
regarding reward signal, perhaps observation features strongly correlate
reward (as intuitively done hand experiments). may also useful
consider making predictions predictions style TD Networks (Sutton
& Tanner, 2005). instance, one could imagine learning models make predictions
profile another model emit. way models could chained together
make predictions extant rewards, rather focusing solely predicting
immediate reward signal (which always particularly good feature temporal
decision problems). Another common use partial models decompose large modeling
problem many small ones, in, instance, factored MDPs (Boutilier et al., 1999),
factored PSRs (Wolfe et al., 2008), collections local models (Talvitie & Singh, 2009b).
setting, choosing tests interest would example structure learning
problem: decomposing one-step predictions relatively independent components
assigning different models.

Acknowledgments
Erik Talvitie supported NSF GRFP. Satinder Singh supported NSF
grant IIS-0905146. opinions, findings, conclusions recommendations expressed
material authors necessarily reflect views NSF.
work presented paper extension work presented IJCAI (Talvitie &
Singh, 2009a). grateful anonymous reviewers whose helpful comments
improved presentation work.

Appendix A.
A.1 Proof Proposition 15
result follow straightforwardly general fact dynamical systems. Let
h[i...j] sequence actions observations h starting ith time-step
sequence ending jth time-step sequence. conveniences sake,
> j let h[i...j] = h0 , null sequence. following two results show
test ever positive probability, must positive probability history
length less linear dimension system.

386

fiLearning Make Predictions Without Generative Model

Figure 9: matrix constructed Lemma 21 full rank (a contradiction).
Lemma 21. linear dimension dynamical system n, test
history h length(h) = k n p(t | h) > 0, i, j 0 < j 1 k
p(t | h[1...i] h[j...k] ) > 0.
Proof. Note p(t | h) > 0, p(h[(i+1)...k] | h[1...i] ) = p(t | h)p(h[(i+1)...k] | h[1...i] ) >
0 0 k. assume i, j 0 < j 1 k p(h[j...k] | h[1...i] ) =
p(t | h[1...i] h[j...k] )p(h[j...k] | h[1...i] ) = 0 seek contradiction. Consider submatrix
system dynamics matrix. rows submatrix correspond prefixes h: h[1...i]
0 k. columns correspond suffixes h pre-pended test t: h[j...k]
1 j k + 1. k + 1 k + 1 matrix. assumption,
matrix triangular positive entries along diagonal (Figure 9 shows matrix
k = 4). such, matrix full rank (rank k + 1). contradiction since
k n submatrix never higher rank matrix contains it.
next result follows immediately Lemma 21.
Corollary 22. system linear dimension n test history h
p(t | h) > 0, exists (possibly non-consecutive) subsequence h h
length(h ) < n p(t | h ) > 0.
Proof. Lemma 21, every history h length k n p(t | h) > 0 must
subsequence h1 length k1 < k p(t | h) > 0. k1 n, h1 must
subsequence h2 length k2 < k1 . argument repeated subsequence
length less n.
consequence Corollary 22 every test ever positive probability,
must positive probability following history length less n. fact
hand, Proposition 15 proven.
Proposition 15. deterministic dynamical system actions A, observa.
tions O, linear dimension, n log(|A|1)+log(|O|+1)
log |A|
387

fiTalvitie & Singh

Proof. Since system deterministic, history action correspond exactly one
resulting observation. history sequence actions observations. However, since
sequence observations fully determined sequence actions deterministic
system, number distinct histories length k simply |A|k . history
|A| action choices could result different observation. So, number
observations could possibly occur histories length k simply |A|k+1 .
Corollary 22, linear dimension n, observations must occur history h
length(h) n 1. Thus, number observations possibly follow histories
length less n is:
|O|

n1
X

|A|i+1 =

i=0

|A|n+1 1
1.
|A| 1

Solving n yields bound linear dimension terms number actions
number observations.
A.2 Proof Proposition 17
Proposition 17. given system set tests interest, linear dimension
corresponding prediction profile system greater prediction profile
system associated set core tests system (as described Section 2.2).
Proof. Recall discussion PSRs Section 2.2 set core tests, Q,
set tests whose corresponding columns system dynamics matrix constitute
basis. predictions core tests given history form predictive state
history. So, predictive state precisely prediction profile core tests Q.
prediction test computed linear function prediction profile
Q. Note prediction profile system Q MDP. shown
Section 2.2 compute next predictive state given current predictive state
action-observation pair.
consider set tests interest . predictions Q
used compute prediction test, must
function maps prediction profiles Q prediction profiles .
general, multiple predictive states may map prediction profile
surjection. easy see prediction profile system result
applying observation abstraction prediction profile system Q. Performing
observation abstraction MDP generally produces POMDP, never increases
linear dimension (Talvitie, 2010). Hence, prediction profile system set tests
interest linear dimension greater prediction profile system
set core tests, Q.
A.3 Proof Proposition 20
Proposition 20. Consider POMDP hidden states S, actions A, observations
O. Let set tests interest. Let ai action taken time-step i, si
hidden state reached taking action ai , oi observation emitted si . Now,
388

fiLearning Make Predictions Without Generative Model

consider surjection : mapping hidden states set abstract states
following properties:
1. pair primitive states s1 , s2 S, (s1 ) = (s2 ), time-step
test interest , p(t | si = s1 ) = p(t | si = s2 ).
2. pair primitive states s1 , s2 S, (s1 ) = (s2 ), time-step i,
abstract state , observation O, action A,
Pr((si+1 ) = | si = s1 ,ai+1 = a, oi+1 = o) =
Pr((si+1 ) = | si = s2 , ai+1 = a, oi+1 = o).
exists, prediction profile system linear dimension greater
number distinct beliefs abstract states, .
Proof. proof follows similar reasoning proof Proposition 17. Note that,
Property 1 belief abstract states given history sufficient compute
prediction profile. history h test interest :
X
X X
p(t | h) =
Pr(s | h)p(t | s) =
Pr(s | h)p(t | s)
sS

=

X

SS

p(t | S)

X

SS sS

Pr(s | h) =

X

p(t | S)Pr(S | h),

SS

sS

third equality follows property 1: , hidden states
associated probabilities tests interest.
Now, consider dynamical system beliefs abstract states observations
action-observation pairs actions. Call abstract belief system.
predictive state, possible compute prediction profile
abstract beliefs, prediction profile model seen result
observation aggregation abstract belief system. result, prediction profile
system linear dimension greater abstract belief system.
rest proof shows that, Property 2, abstract belief system
MDP, therefore linear dimension greater number distinct beliefs
abstract states.
Given probability distribution abstract states given history h, agent
takes action observes observation o, possible compute probability
abstract state new history:
X
X X
Pr(S | hao) =
Pr(s | h)Pr(S | s, a, o) =
Pr(s | h)Pr(S | s, a, o)
sS

=

X



Pr(S | , a, o)

X

sS

Pr(s | h) =

X

Pr(S | , a, o)Pr(S | h),



sS

third equality follows Property 2: , hidden states
associated conditional distribution next abstract states, given action
observation.
389

fiTalvitie & Singh

So, one compute next abstract beliefs previous abstract beliefs,
abstract belief system MDP, therefore linear dimension greater
number observations (the number distinct abstract beliefs). one
compute prediction profile abstract beliefs, prediction profile system
constructed applying observation abstraction abstract belief system. Thus,
prediction profile system linear dimension greater number distinct
abstract beliefs.

References
Baum, L. E., Petrie, T., Soules, G., & Weiss, N. (1970). maximization technique occuring
statistical analysis probabilistic functions markov chains. Annals
Mathematical Statistics, 41 (1), 164171.
Baxter, J., & Bartlett, P. L. (2000). Reinforcement learning POMDPs via direct gradient ascent. Proceedings Eighteenth International Conference Machine
Learning (ICML), pp. 4148.
Boots, B., Siddiqi, S., & Gordon, G. (2010). Closing learning-planning loop predictive state representations. Proceedings Robotics: Science Systems, Zaragoza,
Spain.
Boots, B., Siddiqi, S., & Gordon, G. (2011). online spectral learning algorithm
partially observable nonlinear dynamical systems. Proceedings Twenty-Fifth
National Conference Artificial Intelligence (AAAI).
Boutilier, C., Dean, T., & Hanks, S. (1999). Decision-theoretic planning: Structural assumptions computational leverage. Journal Artificial Intelligence Research,
11, 194.
Bowling, M., McCracken, P., James, M., Neufeld, J., & Wilkinson, D. (2006). Learning
predictive state representations using non-blind policies. Proceedings TwentyThird International Conference Machine Learning (ICML), pp. 129136.
Dinculescu, M., & Precup, D. (2010). Approximate predictive representations partially
observable systems. Proceedings Twenty-Seventh International Conference
Machine Learning (ICML), pp. 895902.
Hansen, E. (1998). Finite-Memory Control Partially Observable Systems. Ph.D. thesis,
University Massachussetts, Amherst, MA.
Holmes, M., & Isbell, C. (2006). Looping suffix tree-based inference partially observable hidden state. Proceedings Twenty-Third International Conference
Machine Learning (ICML), pp. 409416.
James, M., & Singh, S. (2004). Learning discovery predictive state representations
dynamical systems reset. Proceedings Twenty-First International
Conference Machine Learning (ICML), pp. 417424.
Julier, S. J., & Uhlmann, J. K. (1997). new extension kalman filter nonlinear
systems. Proceedings AeroSense: Eleventh International Symposium
Aerospace/Defense Sensing, Simulation Controls, pp. 182193.
390

fiLearning Make Predictions Without Generative Model

Kalman, R. E. (1960). new approach linear filtering prediction problems. Transactions ASME Journal Basic Engineering, 82, 3545.
Littman, M., Sutton, R., & Singh, S. (2002). Predictive representations state. Advances
Neural Information Processing Systems 14 (NIPS), pp. 15551561.
Littman, M. L. (1996). Algorithms Sequential Decision Making. Ph.D. thesis, Brown
University, Providence, RI.
Mahmud, M. M. H. (2010). Constructing states reinforcement learning. Proceedings
Twenty-Seventh International Conference Machine Learning (ICML), pp.
727734.
McCallum, A. K. (1995). Reinforcement Learning Selective Perception Hidden
State. Ph.D. thesis, Rutgers University.
McCallum, R. A. (1993). Overcoming incomplete perception utile distinction memory.
Proceedings Tenth International Conference Machine Learning (ICML),
pp. 190196.
Monahan, G. E. (1982). survey partially observable markov decisions processes: Theory,
models, algorithms. Management Science, 28 (1), 116.
Peters, J., & Schaal, S. (2008). Natural actor-critic. Neurocomputing, 71, 11801190.
Poupart, P., & Boutilier, C. (2003). Bounded finite state controllers. Advances Neural
Information Processing Systems 16 (NIPS).
Puterman, M. L. (1994). Markov Decision Processes: Discrete Stochastic Dynamic Programming. John Wiley Sons, New York, NY.
Rivest, R. L., & Schapire, R. E. (1994). Diversity-based inference finite automata. Journal
Association Computing Machinery, 41 (3), 555589.
Rudary, M. (2008). Predictive Linear Gaussian Models. Ph.D. thesis, University
Michigan.
Rudary, M., Singh, S., & Wingate, D. (2005). Predictive linear-gaussian models stochastic dynamical systems. Uncertainty Artificial Intelligence: Proceedings
Twenty-First Conference (UAI), pp. 501508.
Shalizi, C. R., & Klinker, K. L. (2004). Blind construction optimal nonlinear recursive
predictors discrete sequences. Proceedings Twentieth Conference
Uncertainty Artificial Intelligence (UAI), pp. 504511.
Singh, S., James, M. R., & Rudary, M. R. (2004). Predictive state representations:
new theory modeling dynamical systems. Uncertainty Artificial Intelligence:
Proceedings Twentieth Conference (UAI), pp. 512519.
Sondik, E. J. (1978). optimal control partially observable markov processes
infinite horizon: Discounted costs. Operations Research, 26, 282304.
Soni, V., & Singh, S. (2007). Abstraction predictive state representations. Proceedings
Twenty-Second National Conference Artificial Intelligence (AAAI), pp. 639
644.
391

fiTalvitie & Singh

Sutton, R. S., & Tanner, B. (2005). Temporal-difference networks. Advances Neural
Information Processing Systems 17 (NIPS), pp. 13771384.
Talvitie, E. (2010). Simple Partial Models Complex Dynamical Systems. Ph.D. thesis,
University Michigan, Ann Arbor, MI.
Talvitie, E., & Singh, S. (2009a). Maintaining predictions time without model.
Proceedings Twenty-First International Joint Conference Artificial Intelligence (IJCAI), pp. 12491254.
Talvitie, E., & Singh, S. (2009b). Simple local models complex dynamical systems.
Advances Neural Information Processing Systems 21 (NIPS), pp. 16171624.
Weaver, L., & Tao, N. (2001). optimal reward baseline gradient-based reinforcement learning. Uncertainty Artificial Intelligence: Proceedings Seventeenth
Conference (UAI), pp. 538545.
Williams, R. (1992). Simple statistical gradient-following algorithms connectionist reinforcement learning. Machine Learning, 8, 229256.
Wingate, D. (2008). Exponential Family Predictive Representations State. Ph.D. thesis,
University Michigan.
Wingate, D., Soni, V., Wolfe, B., & Singh, S. (2007). Relational knowledge predictive
state representations. Proceedings Twentieth International Joint Conference
Artificial Intelligence (IJCAI), pp. 20352040.
Wolfe, A. P. (2010). Paying Attention Matters: Observation Abstraction Partially
Observable Environments. Ph.D. thesis, University Massachussetts, Amherst, MA.
Wolfe, A. P., & Barto, A. G. (2006). Decision tree methods finding reusable MDP
homomorphisms. Proceedings Twenty-First National Conference Artificial
Intelligence (AAAI).
Wolfe, B., James, M., & Singh, S. (2008). Approximate predictive state representations.
Proceedings Seventh Conference Autonomous Agents Multiagent Systems
(AAMAS).
Wolfe, B., James, M. R., & Singh, S. (2005). Learning predictive state representations
dynamical systems without reset. Proceedings Twenty-Second International
Conference Machine Learning (ICML), pp. 985992.
Wolfe, B., & Singh, S. (2006). Predictive state representations options. Proceedings Twenty-Third International Conference Machine Learning (ICML), pp.
10251032.

392

fiJournal Artificial Intelligence Research 42 (2011) 211-274

Submitted 03/11; published 10/11

Representing Reasoning Qualitative Preferences
Compositional Systems
Ganesh Ram Santhanam
Samik Basu
Vasant Honavar

gsanthan@cs.iastate.edu
sbasu@cs.iastate.edu
honavar@cs.iastate.edu

Department Computer Science
Iowa State University
Ames, IA 50011, USA

Abstract
Many applications, e.g., Web service composition, complex system design, team formation, etc., rely methods identifying collections objects entities satisfying
functional requirement. Among collections satisfy functional requirement,
often necessary identify one collections optimal respect
user preferences set attributes describe non-functional properties
collection.
develop formalism lets users express relative importance among attributes
qualitative preferences valuations attribute. define dominance
relation allows us compare collections objects terms preferences attributes objects make collection. establish key properties
dominance relation. particular, show dominance relation strict partial
order intra-attribute preference relations strict partial orders relative
importance preference relation interval order.
provide algorithms use dominance relation identify set
preferred collections. show certain conditions, algorithms guaranteed
return (sound), (complete), least one (weakly complete)
preferred collections. present results simulation experiments comparing proposed
algorithms respect (a) quality solutions (number preferred solutions)
produced algorithms, (b) performance efficiency. also explore
interesting conjectures suggested results experiments relate
properties user preferences, dominance relation, algorithms.

1. Introduction
Many applications call techniques representing reasoning preferences
set alternatives. settings, preferences alternatives expressed
respect set attributes describe alternatives. preferences either
qualitative quantitative. great deal work multi-attribute decision theory
focused reasoning quantitative preferences (Fishburn, 1970a; Keeney & Raiffa,
1993). However, many settings natural express preferences qualitative
terms (Doyle & Thomason, 1999) hence, growing interest formalisms
representing reasoning qualitative preferences (Brafman & Domshlak, 2009) AI.
important problem context representing qualitative preferences
multiple attributes reasoning find preferred among set
c
2011
AI Access Foundation. rights reserved.

fiSanthanam, Basu & Honavar

alternatives. Brafman, Domshlak Shimonys seminal work (2006) attempts address
problem introducing preference networks capture: (a) intra-variable intraattribute preferences specifying preferences domains attributes; (b) relative
importance among attributes. Preference networks use graphical representation
compactly encode types preferences user, employ ceteris
paribus 1 semantics reason preferred alternatives. model,
alternative completely described values assigned set attributes.
many AI applications planning scheduling, alternatives composite structure, i.e., alternative represents collection composition objects rather
simple objects. settings, typically set user specified functional requirements compositions required satisfy2 . Among possible compositions
satisfy functional requirements, often need choose compositions
preferred respect set user preferences set non-functional
attributes objects make composition. illustrate problem
using following example.
1.1 Illustrative Example
Consider task designing program study (POS) Masters student
Computer Science department. POS consists collection courses chosen
given repository available courses spanning different areas focus computer science.
Apart area focus, course also assigned instructor number
credit hours. repository available courses, areas focus, instructors
number credit hours specified Table 1.
Course
CS501
CS502
CS503
CS504
CS505
CS506
CS507
CS508
CS509
CS510

Area
Formal Methods (FM)
Artificial Intelligence (AI)
Formal Methods (FM)
Artificial Intelligence (AI)
Databases (DB)
Networks (NW)
Computer Architecture (CA)
Software Engineering (SE)
Theory (TH)
Theory (TH)

Instructor
Tom
Gopal
Harry
White
Bob
Bob
White
Tom
Jane
Tom

Credits
4
3
2
3
4
2
3
2
3
3

Table 1: List courses student choose
example, POS viewed composition courses. requirements
acceptable Masters POS (i.e., feasible composition) follows.
F 1. POS include least 15 credits
1. Latin term else equal
2. example, planning, valid plan collection actions satisfies goal; scheduling,
valid schedule collection task-to-resource assignments respects precedence constraints.

212

fiRepresenting Reasoning Qualitative Preferences

AI
FM

TH

DB

NW

SE

Gopal

Bob
Jane

om

W hite

CA
(a)

Harry
(b)

Figure 1: Intra-attribute preferences Area (A ) Instructor (I ).
F 2. POS include two core courses CS509 CS510
F 3. courses covering least two breadth areas study (apart
area Theory (TH))
Given repository courses (see Table 1; may one acceptable
programs study, i.e., feasible compositions). example:
P1 = CS501 CS502 CS503 CS504 CS509 CS510
P2 = CS501 CS502 CS505 CS506 CS509 CS510
P3 = CS503 CS504 CS507 CS508 CS509 CS510
Suppose addition requirements, student preferences
course attributes area focus, choice instructors difficulty
level terms credit hours. Among several acceptable programs study, student
may interested programs study that: (a) satisfy minimum requirements
(see above) acceptable POS, (b) preferred respect
his/her preferences specified above. preferences student respect course
attributes Area (A) Instructor (I) illustrated Figure 1 (arrows directed
toward preferred area/instructor figure, e.g., AI preferred F Bob
preferred om). addition let us say student prefers POS lesser
total number credits (this specifies C ). Further, let relative importance among
attributes A, C C, i.e., relatively important A,
turn relatively important C.
1.2 Problem Statement Illustrative Example
problems try address paper example are:
Given two programs study, namely Pi Pj , determine whether Pi dominates
(i.e., preferred to) Pj vice versa respect students preferences;
Given repository courses algorithm computing set acceptable
programs study, find preferred, acceptable programs study respect
dominance relation.
213

fiSanthanam, Basu & Honavar

example given Section 1.1, functional requirements correspond three
conditions F 1 F 3, must satisfied collection courses
acceptable POS. Area (A), instructor (I) number credits (C) constitute nonfunctional attributes, user preferences attributes given {A ,
, C } C. One envision similar problems several applications,
ranging assembling hardware software components embedded system (such
designing pacemaker anti-lock braking system) putting together complex piece
legislation (such one reforming health care).
general, interested problem (a) reasoning preferences compositions objects, given preferences set non-functional attributes describing
objects; (b) identifying compositions satisfy functional requirements
compositional system, time optimal respect stated preferences non-functional attributes. background, present preference
formalism set algorithms address problem compositional systems.
1.3 Contributions
adopt preference network representation introduced Brafman et al. (2006)
specification qualitative preferences3 valuations attribute well
relative importance among attributes. extend reasoning preferences
single objects deal preferences collections objects. main contributions
paper follows.
1. develop preference formalism allows users specify preferences terms
intra-attribute relative importance preferences set attributes,
includes mechanisms for:
a) Computing valuation composition: respect attribute,
define generic aggregation function compute valuation composition
function valuations components. also present strict partial
order preference relation comparing two compositions respect
aggregated valuations attribute.
b) Comparing valuations compositions: introduce dominance relation
compares compositions (in terms aggregated valuations) respect
stated preferences, establish key properties. particular,
show relation strict partial order whenever intra-attribute
preferences strict partial orders relative importance preference
interval order.
2. develop suite algorithms identify set, subset preferred
composition(s) respect user preferences. particular, show
certain conditions, algorithms guaranteed return (sound),
(complete), least one (weakly complete) preferred compositions.
algorithms develop fall two classes:
3. deal conditional preferences work.

214

fiRepresenting Reasoning Qualitative Preferences

a) first compute set feasible compositions using functional
composition algorithm black box, proceed find preferred
among using preference relations developed (1);
b) algorithm interleaves step execution functional composition algorithm ordering partial solutions respect user
preferences. requires functional composition algorithm able construct composition satisfying functional requirement incrementally, i.e.,
iteratively extending partial compositions additional components.
analyze key properties algorithms yield specific conditions
structure preferences, algorithms produce only/at least one/all
preferred solutions.
3. present results experiments compare performance algorithms
computing preferred compositions set simulated composition
problem instances. results demonstrate feasibility approach practice, compare algorithms respect quality (number good
preferred) solutions produced algorithms performance (running time) efficiency (the number times invoke functional composition
algorithm). Based analysis experimental results, also establish
previously unknown key theoretical properties dominance relation directly
function user preferences.
formalism generic sense one use aggregation function
appropriately represents valuation composition function valuations
constituents. particular, show examples aggregation functions compute
summation (numeric), minimum/maximum valuation (totally ordered), set
worst valuations (partially ordered) constituents composition. formalism
also provides flexibility choosing preference relation compares sets valuations
two compositions, strict partial order preference relation used.
algorithms completely independent various aspects preference formalism, namely, choice aggregation functions, preference relation used compare
aggregated valuations single attribute, dominance relation used compare
compositions attributes, except preference relations strict partial orders. theoretical experimental results provide precise conditions
algorithms produce only/at least one/all preferred solutions. enables
user choose algorithm his/her choice particular problem instance, depending
quality solutions needed. addition, analysis also allows user
trade quality solutions produced performance efficiency.
1.4 Related Work
closest work related paper paper Binshtok, Brafman, Domshlak,
Shimony (2009), preferences expressed collections based number
objects collection satisfy desired property (e.g., least two political
two sports articles choosing articles newspaper publication). contrast,
215

fiSanthanam, Basu & Honavar

develop formalism considers desirability collection whole based
attributes objects make collection, algorithms identify
preferred collection(s) among satisfy requirement. show
problems solved using formalism due Binshtok et al. also solved
formalism (see Section 7.3.2).
recent years, lot work database community
evaluation preference queries (e.g., skyline queries) find preferred subset
tuples result set. problem finding preferred set tuples analogous
finding preferred set alternatives, alternative simple object,
i.e., tuple described set attributes. problem corresponds finding
preferred set alternatives, alternative turn set tuples satisfy
requirement (e.g., set tuples satisfy set integrity constraints). Moreover,
algorithms found database literature mostly address totally weakly ordered
preferences values attributes, address partially ordered preferences
well. addition, rely maintenance database indexes
attributes tuples typically cater large scale, static data
typical setting. however note relevance possible utility techniques
developed databases community problem specific scenarios.
refer reader Section 7.3 detailed discussion related work.
1.5 Organization
rest paper organized follows. Section 2, define compositional system,
discuss types preferences consider, specify problem formal
terms. Section 3, present preference formalism including dominance relation
analyze properties. Section 4, present four algorithms identifying
preferred compositions discuss properties. proofs results section
given Appendix A. Section 5, discuss complexity algorithms.In
Section 6, present results experiments performed compare algorithms
terms quality solutions produced, performance efficiency. Section 7,
summarize contributions discuss related future work area.

2. Preliminaries
recall basic properties definitions concerning binary relations use
rest paper (see Fishburn, 1985, comprehensive treatment same).
2.1 Properties Binary Relations
Let binary relation set S, i.e., S. say equivalence (eq),
(strict) partial order (po), interval order (io), weak order (wo) total order (to),
defined Table 2.
total order also weak order; weak order also interval order; interval
order also strict partial order.
216

fiRepresenting Reasoning Qualitative Preferences

#
1.
2.
3.
4.
5.
6.
7.
8.

Property relation
reflexive
irreflexive
symmetric
asymmetric
transitive
total complete
negatively transitive
ferrers

Definition
x : x x
x : x 6 x
x, : x x
x, : x 6 x
x, y, z : x z x z
x, : x 6= x x
x, y, z : x x z z
x, y, z, w : (x z w)
(x w z y)

eq
X

po

io

wo



X

X

X

X

X
X

X
X

X
X

X

X
X

X
X
X
X
X

X
X

Table 2: Properties binary relations
2.2 Compositional System
compositional system consists repository pre-existing components
interested assembling compositions satisfy pre-specified functionality. Formally,
compositional system tuple hR, , |=i where:
R = {W1 , W2 . . . Wr } set available components,
denotes composition operator functionally aggregates components encodes functional details composition. binary operation components Wi , Wj repository produces composition Wi Wj .
|= satisfaction relation evaluates true composition satisfies
pre-specified functional properties.
Definition 1 (Compositions, Feasible Compositions Extensions). Given compositional system hR, , |=i, functionality , composition C = Wi1 Wi2 . . . Win
arbitrary collection components Wi1 , Wi2 , . . . , Win s.t. j [1, n] : Wij R.
i. C feasible composition whenever C |= ;
ii. C partial feasible composition whenever Wj1 . . . Wjm R : C Wj1 . . . Wjm
feasible composition;
iii. C Wi feasible extension partial feasible composition C whenever C Wi
feasible partial feasible composition.
Given compositional system hR, , |=i functionality , algorithm produces set feasible compositions (satisfying ) called functional composition algorithm. general class functional composition algorithms consider
treated black boxes, simply returning set feasible compositions satisfying single step. functional composition algorithms proceed computing set
feasible extensions partial feasible compositions incrementally.
Definition 2 (Incremental Functional Composition Algorithm). functional composition
algorithm said incremental if, given initial partial feasible composition C
desired functionality , algorithm computes set feasible extensions C.
217

fiSanthanam, Basu & Honavar

incremental functional composition algorithm used compute feasible
compositions recursively invoking algorithm partial feasible compositions
produces starting empty composition (), culminating set feasible
compositions satisfying . sense, incremental functional composition algorithms
similar black box counterparts. However, (as later show Section 4.5)
contrast black box counterparts, incremental functional composition algorithms
exploited search preferred feasible compositions, interleaving
step functional composition algorithm optimization valuations
non-functional attributes (with respect user preferences). allows us develop
algorithms eliminate partial feasible compositions lead less preferred
feasible compositions consideration early search.
Different approaches functional composition, (e.g., Traverso & Pistore, 2004; Lago,
Pistore, & Traverso, 2002; Baier, Fritz, Bienvenu, & McIlraith, 2008; Passerone, de Alfaro,
Henzinger, & Sangiovanni-Vincentelli, 2002) differ terms (a) languages used
represent desired functionality compositions, (b) algorithms used
verify whether composition C satisfies , i.e., C |= . intentionally abstracted
details functionality represented (e.g., transition systems, logic formulas, plans,
etc.) composition tested satisfiability (|=) , primary focus
work orthogonal details specific methods used functional composition.
2.3 Preferences Non-functional Attributes
turn non-functional aspects compositional systems. addition obtaining functionally feasible compositions, users often concerned non-functional
aspects compositions, e.g., reliability composite Web service. cases,
users seek preferred compositions among functionally feasible,
respect set non-functional attributes describing components. order compute
preferred compositions, necessary user specify his/her preferences
set non-functional attributes X .
2.3.1 Notation
general, relation P , use notation, i.e., P denote transitive
closure relation well, 6P P denote complement. list
notations used paper given Table 3.
focus strict partial order preference relations, i.e., relations
irreflexive transitive, transitivity natural property rational preference
relation (von Neumann & Morgenstern, 1944; French, 1986; Mas-Colell, Whinston, & Green,
1995), irreflexivity ensures preferences strict.
respect strict partial order preference relation P , say two elements
u v indifferent, denoted u P v, whenever u 6P v v 6P u. preference
relations , , , denote corresponding indifference relation , ,
respectively. drop subscripts whenever understood
context.
Proposition 1. strict partial order preference relation P , corresponding indifference relation P reflexive symmetric.
218

fiRepresenting Reasoning Qualitative Preferences

Notation
P(S)
R = {W1 Wr }

C, U, V, Z
C
X = {X1 Xm }
= {D1 Dm }
ui , vi , ai , bi Di
VWi
VCi
VWi (Xj )
VCi (Xj )
, X


F (Xi )


(S)


Meaning
Power set set
Set components repository
Operation composes components R
Composition collectionn4 set components R
set {Ci } compositions
Set non-functional attributes
Set possible valuations (domains) attributes X respectively
Valuations attribute domain Di
Overall valuation component Wi respect attributes
X
Overall valuation composition Ci respect attributes
X
Valuation component Wi respect attribute Xj
Valuation composition Ci respect attribute Xj
Intra-attribute preference valuations Xi X respectively
(user input)
Relative importance among attributes (user input)
Aggregation function computes valuation composition
respect Xi function valuation components
Range aggregation function attribute Xi
Derived preference relation aggregated valuations respect
Xi
Dominance relation compares two compositions terms
aggregated valuations attributes
non-dominated set elements respect
User specified functionality satisfied feasible composition
Table 3: Notation

Proof. Follows well-known property strict partial orders due Fishburn (1970b).

important note indifference respect strict partial order
necessarily transitive. instance, X = {(b, c)} strict partial order set {a, b, c}
b X a, X c b X c.
2.3.2 Representing Multi-Attribute Preferences
Following representation scheme introduced Boutilier et al. (2004) Brafman et
al. (2006), model users preferences respect multiple attributes two forms:
(a) intra-attribute preferences respect non-functional attribute X , (b)
relative importance attributes.
4. use terms composition collection; component object interchangeably.

219

fiSanthanam, Basu & Honavar

Definition 3 (Intra-attribute Preference). intra-attribute preference relation, denoted
strict partial order (irreflexive transitive) possible valuations
attribute Xi X . u, v Di : u v iff u preferred v respect Xi .
Definition 4 (Relative Importance). relative importance preference relation, denoted
strict partial order (irreflexive transitive) set attributes X .
Xi , Xj X : Xi Xj iff Xi relatively important Xj .
Given set X attributes, intra-attribute preference relations {i }
respective domains, relative importance preference relation X , address
following problems.
Given two compositions Cj Ck , determine whether VCj VCk vice versa;
Given compositional system hR, , |=i, algorithm computing set
feasible compositions {Cf : Cf |= }, find preferred feasible compositions
respect dominance relation.

3. Preference Formalism
Given compositional system repository components described attributes X
preferences ({i }, ) them, interested reasoning preferences
different compositions. Note based preferences {i } , one make use
existing formalisms TCP-nets (Brafman et al., 2006) select preferred
components. However, problem comparing compositions (as opposed comparing
components) respect attribute preferences complicated fact
valuation composition function valuations components. approach
developing preference formalism follows.
First, given composition valuations components respect
attributes, obtain aggregated valuation composition respect
attribute function valuations components. Next, define preference
relations compare aggregated valuations two compositions respect
attribute. Finally, build dominance preference relation qualitatively compares
two compositions respect aggregated valuations across attributes.
3.1 Aggregating Attribute Valuations across Components
order reason preferences compositions, necessary obtain valuation composition respect attribute Xi terms components, using
aggregation function . several ways aggregate preference valuations
attribute-wise across components composition. aggregation function defines
valuation composition respect attribute Xi function valuations
components.
Remark. compositional systems considered here, assume valuation
composition respect attributes function valuations
components. words, C = W1 W2 . . . Wn , VC function
{VW1 , VW2 , . . . , VWn }. However, general setting, aggregation functions
220

fiRepresenting Reasoning Qualitative Preferences

need take account, addition valuations components themselves,
structural functional details composition encoded (e.g., reliability Web
service composition depends whether service components composed series
parallel structure).
Definition 5 (Aggregation Function). aggregation function multiset5 possible
valuations (Di ) attribute Xi
: M(Di ) F (Xi )
F (Xi ) denotes range aggregation function.
Aggregation respect attribute Xi amounts devising appropriate aggregation function computes valuation composition terms valuations
components Xi . range F (Xi ) depends choice aggregation
function. examples aggregation functions given below.
1. Summation. applicable cases attribute real-valued represents kind cost. example, cost shopping cart sum
costs individual items includes. running example, total number
credits POS consisting set courses sum credits
courses includes. is, set credit hours (valuations courses
respect attribute C) courses POS,
C (S) := {sS s}
2. Minimum/Maximum. Here, valuation composition respect attribute worst, i.e., minimum among valuations components.
type aggregation natural one consider composing embedded systems
Web services. example, putting together several components embedded system, system secure (or safe) least secure (or safe)
component.
(S) := {minsS s}
Analogously, one could choose valuation composition maximum (best)
among valuations components. aggregation function may useful
applications parallel job scheduling, maximum response time
used measure quality schedule.
3. Best/Worst Frontier. settings, possible intra-attribute preference values attribute partial order (not necessarily ranking
total order). Hence, may possible compute valuation composition best worst among valuations components unique
maximum minimum may exist. example, may useful compute
5. multiset generalization set allows multiple copies elements.

221

fiSanthanam, Basu & Honavar

valuation composition minimal set valuations among valuations
components, call worst frontier. worst frontier represents
worst possible valuations attribute Xi respect , i.e., minimal set6
among set valuations components composition.
Definition 6 (Aggregation using Worst Frontier). Given set valuations attribute Xi , worst frontier aggregation function defined
Di : (S) := {v : v u : v u}
running example (see Section 1.1), user would like avoid courses
interest area professors comfortable with. is, program study
considered good least interesting areas study covers, set
professors least comfortable with. Hence, worst frontier aggregation function
chosen breadth area instructor attributes.
Example. worst possible valuations attributes program
study (composition) P1 respect {F M, H} {W hite, Harry}
respectively. Similarly, P2 valuations attributes {DB, N W }
{Jane, om} respectively; P3 valuations attributes
{CA, SE} {Harry, W hite} respectively. sets correspond worst frontiers respective attributes. different areas focus covered POS P2
{F M, AI, DB, N W, H}, worst frontier set ({F M, AI, DB, N W, H}) =
{DB, N W } AI DB, F DB, H N W . Similarly set instructors P2 {T om, Gopal, Bob, Jane}, hence ({T om, Gopal, Bob, Jane}) =
{Jane, om} Bob Jane Gopal om. attribute C, aggregation
function evaluates sum credits constituent courses POS. Therefore, P2
C ({4, 3, 4, 2, 3, 3}) = 4 + 3 + 4 + 2 + 3 + 3 = 19.

note choices aggregation function accommodated
framework (such average combination best worst frontier sets),
representative list choices.
Proposition 2 (Indifference Frontier Elements). Consider attribute Xi , whose valuations aggregated using best worst frontier aggregation function. Let F (Xi ).
u v u, v A.
Proof. Follows Definition 6 (or analogous definition best frontier) wellknown result due work Fishburn (1985).
Definition 7 (Valuation Composition Attributes Aggregated using Best/Worst
Frontier). Consider attribute Xi , whose valuations aggregated using best worst
frontier aggregation function. valuation component W respect attribute
Xi denoted VW (Xi ) Di . valuation composition two components W1
W2 respect attribute Xi , valuation VW1 (Xi ) VW2 (Xi ) respectively,
given
6. Note total order, worst frontier represents minimum lowest element set
respect total order.

222

fiRepresenting Reasoning Qualitative Preferences

VW1 W2 (Xi ) := (VW1 (Xi ) VW2 (Xi ))
Example. Consider P2 = CS501 CS502 CS505 CS506 CS509 CS510
running example (see Section 1.1).
VP2 (I) = (VCS501 (I) VCS502 (I) VCS505 (I) VCS506 (I) VCS509 (I) VCS510 (I))
= ({T om} {Gopal} {Bob} {Bob} {Jane} {T om})
= ({T om, Gopal, Bob, Jane})
= {T om, Jane}

must noted VW1 W2 (Xi ) = VW2 W1 (Xi ) according definition,
valuations compositions subsets union individual component
valuations.
3.2 Comparing Aggregated Valuations
obtained aggregated valuation respect attribute, next proceed
discuss compare aggregated valuations attribute-wise. denote preference
relation used compare aggregated valuations attribute Xi . simple
case aggregation function respect attribute Xi returns value
Di (F (Xi ) = Di ), intra-attribute preference (re)used compare aggregated
valuations, i.e., =i . choices considered long partial
order. order obtain strict preference relation, require irreflexivity, obtain
rational preference relation, require transitivity7 .
worst frontier-based aggregation (Definition 6), present preference relation
uses following idea: Given two compositions different aggregated valuations (worst
frontiers) A, B respect attribute Xi , say preferred B every
valuation Xi B, valuation strictly preferred.
Definition 8 (Preference Worst Frontiers). Let A, B F (Xi ) two worst frontiers
respect attribute Xi . say valuation preferred B respect
Xi , denoted B, element B, exists element
preferred.
A, B F (Xi ) : B b B, : b
Example. running example (see Section 1.1), {F M, H} {DB, N W }
F DB H N W .

Given preference relation set elements, several ways obtaining
preference relation subsets elements set (see Barbera, Bossert, & Pattanaik,
2004, survey preferences sets). Definition 8 one simple way achieve
this. settings, contrast Definition 8, might useful compare
7. preference relation, including one compares uncommon elements two sets
used, provided irreflexive transitive.

223

fiSanthanam, Basu & Honavar

elements two sets common. settings, suitable irreflexive
transitive preference relation used, asymmetric part preference
relations developed Brewka et al. (2010) Bouveret et al. (2009). absence
transitivity, transitive closure relation may used compare sets elements,
done Brewka et al.
discuss properties specific relation introduced Definition 8.
Proposition 3 (Irreflexivity ). F (Xi ) 6 A.
Proof. a, b A, b

(follows P roposition 2)

Proposition 4 (Transitivity ). A, B, C F (Xi ), B B C C.
Proof. Immediate Definition 8.
Definition 9. Let A, B F (Xi ). say valuation least preferred B
respect Xi , denoted iff
B = B B
Proposition 5. reflexive transitive.
Proof. Follows facts = reflexive transitive, irreflexive
transitive.
Definition 10 (Complete Valuation). complete valuation outcome assignment
composition C defined tuple VC := hVC (X1 ), . . . VC (Xm )i, VC (Xi ) F (Xi ).


F (Xi ).
set possible valuations outcomes denoted
i=1

Example. case example Section 1.1:
VP 1

= hA ({F M, AI, H}), ({T om, Gopal, Harry, W hite, Jane}), C ({4, 3, 2, 3, 3, 3})i
= h{F M, H}, {W hite, Harry}, {18}i

VP 2

= hA ({F M, AI, DB, N W, H}), ({T om, Gopal, Bob, Jane}), C ({4, 3, 4, 2, 3, 3})i
= h{DB, N W }, {T om, Jane}, {19}i

VP 3

= hA ({F M, AI, CA, SE, H}), ({Harry, W hite, om, Jane}), C ({2, 3, 3, 2, 3, 3})i
= h{CA, SE}, {Harry, W hite}, {16}i


3.3 Dominance: Preference Compositions
previous sections, discussed evaluate compare composition
respect attributes function components. order identify preferred
compositions, need compare compositions respect aggregated valuations
attributes, based originally specified intra-attribute relative importance
preferences. present specific dominance relation performing comparison.
224

fiRepresenting Reasoning Qualitative Preferences

U V Xi X : U(Xi ) V(Xi )
Xk X : (Xk Xi Xk Xi ) U(Xk ) k V(Xk )

Layer 2
(Dominance)

Compare
compositions






F (Di )

i=1

F (Di )

i=1

F (Dm ) F (Dm )

Compare
1 F (D1 ) F (D1 ) 2 F (D2 ) F (D2 )
aggregated valuations
F (D1 )
F (D2 )

Layer 1
(Aggregation)

Compute
aggregated valuations

1

2

P(D1 )

User
Input




X X
X = {X1 , X2 , . . . Xm }

F (Dm )
...

P(D2 )


P(Dm )

1 D1 D1

2 D2 D2

...

Dm Dm

D1 = {a1 , a2 . . .}

D2 = {b1 , b2 . . .}

...

Dm = {u1 , u2 . . .}

Relative Importance

Intra-attribute preferences

Figure 2: Dominance: Preference compositions
Definition 11 (Dominance). Dominance binary relation defined follows:


F (Xi )
U 8 , V
i=1

U V

Xi : U(Xi ) V(Xi )
Xk : (Xk Xi Xk Xi ) U(Xk ) k V(Xk )

Definition 11, call attribute Xi witness relation. dominance
relation derived respects intra-attribute preferences (i ) well
relative importance preferences () asserted user. Figure 2 graphically illustrates
dominance derived user-specified preferences. First, start user
specified preferences, namely intra-attribute (i ) relative importance () preferences.
Next, preferences, valuations compositions respect attributes
computed using aggregation function (i ). intra-attribute preference relation
compare aggregated valuations ( ) derived . Finally, global dominance
( ) defined terms .
definition dominance states composition U dominates V iff find
witness attribute Xi respect intra-attribute preference ,
valuation U dominates V terms , attributes Xk user considers
important () indifferent () Xi , valuation Xk U least
preferred ( ) valuation Xk V.
8. avoid excessively cluttering notation, given composition C, slightly abuse notation
using C interchangeably VC .

225

fiSanthanam, Basu & Honavar

Example. running example (see Section 1.1), VP2 VP1 witness
VP1 VP3 witness. A, C C VP2 VP1 VP2 VP3
witness, VP1 6 VP3 VP3 6 VP1 . P1 preferred P3
respect ({F M, H} {CA, SE}); P3 preferred P1 respect C
({16} C {18}), neither C relatively important other.

3.4 Properties
proceed analyze properties respect worst-frontier aggregation function. First, show partial feasible composition dominated
respect extensions. property useful establishing
soundness algorithms compute preferred compositions (see Section 4).
Next, observe irreflexive (follows irreflexivity ), proceed
identify conditions transitive. focus transitive preferences many studies considered transitivity key property preference relations
(von Neumann & Morgenstern, 1944; French, 1986; Mas-Colell et al., 1995)9 .
Proposition 6. Whenever preferences aggregated using worst-frontier based aggregation function, partial feasible composition C, feasible extension C W
dominates it, i.e., VCW 6 VC .
Proof. proof proceeds showing respect attribute Xi , VCW (Xi ) 6
VC (Xi ), thereby ruling existence witness VCW VC . Suppose
contradiction, C W feasible extension C VCW VC . Definition 11,
VCW VC requires existence witness attribute Xi X VCW (Xi ) VC (Xi ),
i.e.,
b VC (Xi ) VCW (Xi ) : b
(1)
Definition 7, VCW (Xi ) = (VC (Xi ) VW (Xi )). However, Definition 6
(VC (Xi ) VW (Xi )) b VC (Xi ) VW (Xi ) : b, contradicts Equation (1).
rules existence witness VCW VC . Hence, VCW 6 VC .
next proceed show necessarily transitive intra-attribute
relative importance preference relations arbitrary strict partial orders.
Proposition 7. intra-attribute preferences well relative importance among
attributes arbitrary partial orders, U V V Z ; U Z
Proof. show counter example compositional system partially ordered {i },
compositions U, V, Z U V, V Z U 6 Z.
Consider system set attributes X = {X1 , X2 , X3 , X4 }, domains
D1 = {a1 , b1 }, . . . D4 = {a4 , b4 }. Let relative importance relation X intraattribute preferences 1 . . . 4 given = {(X1 , X3 ), (X2 , X4 )} = {(ai , bi )}, =
1, 2, 3, 4 respectively (Figure 3). valuations U, V, Z respect attributes X
given Table 4.
9. studies human decision making argued human preferences necessarily
transitive (Tversky, 1969), others offered evidence contrary (Regenwetter, Dana, & DavisStober, 2011).

226

fiRepresenting Reasoning Qualitative Preferences

Intra-variable preferences

Relative Importance ()

a1 1 b1

X2

X1

a2 2 b2
a3 3 b3
a4 4 b4

X4

X3

U = h{a1 }, {a2}, {b3}, {b4}i

V = h{b1 }, {a2}, {a3}, {b4}i

Z = h{b1 }, {b2}, {a3}, {a4 }i
Figure 3: Counter example
Comp. (C)

VC (X1 )

VC (X2 )

VC (X3 )

VC (X4 )

U
V
Z

a1
b1
b1

a2
a2
b2

b3
a3
a3

b4
b4
a4

Table 4: Valuations U, V, Z

Clearly U V X1 witness, V Z X2 witness. addition,
note that:
Z(X3 ) 3 U(X3 )

(2)

Z(X4 ) 4 U(X4 )

(3)

However, observe U 6 Z:
a. X1 witness due X4 X1 Equation (3).
b. X2 witness due X3 X2 Equation (2).
c. X3 witness due Equation (2).
d. X4 witness due Equation (3).
proposition shows dominance relation transitive
arbitrary partial orders, considering worst-frontier based aggregation.
transitivity preference necessary condition rational choice (von Neumann
227

fiSanthanam, Basu & Honavar

& Morgenstern, 1944; French, 1986; Mas-Colell et al., 1995), proceed investigate
possibility obtaining dominance relation restricting . later prove
restriction necessary sufficient transitivity .
Definition 12 (Relative Importance Interval Order). relative importance relation
binary relation reflexive satisfies following axiom.
Xi , Xj , Xk , Xl X : (Xi Xj Xk Xl ) (Xi Xl Xk Xj )

(4)

say Xi relatively important Xj Xi Xj .
Proposition 8 (Transitivity see Fishburn, 1985). transitive.

Remarks.
1. Definition 12 imposes additional restriction structure relative importance relation , strict partial order. strict partial order irreflexive
transitive; however, relative importance relation Definition 12
addition satisfy Equation (4), thereby yielding interval order (Fishburn, 1985).
2. indifference relation respect , namely transitive. example,
three attributes X = {X1 , X2 , X3 }, = {(X1 , X2 )}. satisfies
condition interval order, X1 X3 X3 X2 , X1 6 X2
X1 X2 .
Propositions 9-12 establish properties dominance relation case
relative importance relation interval order. particular, prove
irreflexive (Proposition 9) transitive (Proposition 12), making strict partial
order (Theorem 1).
Proposition 9 (Irreflexivity ). U




F (Xi ) U 6 U.

i=1

Proof. Suppose U U contradiction. Xi , s.t. U(Xi ) U(Xi ) definition.
contradicts Proposition 3.
proposition ensures dominance relation strict compositions. words, composition preferred itself. Next, proceed establish
important property rational preference relations: transitivity . make
use two intermediate propositions 10 11 needed task.
Proposition 10, prove attribute Xi relatively important
Xj , Xi important third attribute Xk implies Xj also
important Xk . help us prove transitivity dominance relation.
Figure 4 illustrates cases arise.
Proposition
10. Xi , Xj , Xk :

Xi Xj (Xk Xi Xk Xi ) (Xk Xj Xk Xj )
228

fiRepresenting Reasoning Qualitative Preferences

Xk Xi

Xk Xi
Xk

Xi

Xi

Xj

Xk

Xk

Xi
Xj

Xj
(a)

(b)

(c)

Figure 4: Xi Xj (Xk Xi Xk Xi )
proof follows fact partial order.
Proof.
1. Xi Xj

(Hyp.)

2. Xk Xi Xk Xi

(Hyp.) Show Xk Xj Xk Xj

2.1. Xk Xi Xk Xj transitivity (1.); see Figure 4(a)
2.2. Xk Xi Xk Xj Xk Xj
i. Xk Xi (Hyp.)
ii. (Xk Xj ) (Xj Xk ) (Xk Xj ) Always; see Figure 4(b,c)
iii. Xj Xk Xi Xk (1.) Contradiction!
iv. Xk Xj Xk Xj (2.2.ii., iii.)


3. Xi Xj (Xk Xi Xk Xi ) (Xk Xj Xk Xj )
(1., 2.1, 2.2)

Proposition 11 states attributes Xi , Xj Xi Xj least
one them, Xu respect other, Xv , attribute Xk
less important time Xk Xu . result needed establish
transitivity dominance relation.
Proposition 11. Xi , Xj , u 6= v, Xi Xj Xu , Xv {Xi , Xj }, Xk : (Xu Xk
Xv Xk )
proof makes use fact relative importance interval order relation.
Proof. Let Xi Xj , Xi Xj attributes less important Xi Xj
respectively (if any). Figure 5 illustrates cases. Figure 5(a, b, c, d, e) illustrates
cases one Xi Xj exists, case claim holds trivially.
example, cases Figure 5(a, b, c), Xu = Xi ; Xv = Xj Xu = Xj ; Xv = Xi
satisfy implication, cases Figure 5(d, e), corresponding satisfactory
assignments Xu Xv shown figure. case Figure 5(f) never arises
interval order (see Definition 12). Hence, proposition holds
cases.
229

fiSanthanam, Basu & Honavar

Xi

Xj

Xi

(a)
Xi

Xj

Xi

Xj

Xi

(b)

Xj

Xi

Xj

Xi

Xj

(c)

Xj

Xu = Xj
Xv = Xi

Xu = Xi
Xv = Xj

(d)

(e)

Xi

Xj

Xi

Xj

Contradiction!
( interval order )
(f)

Figure 5: Xi Xj
proposition reflects interval order property relation,
complements result Proposition 7, shown intransitive
interval order. fact, relative importance defined strict partial order
instead, proof hold. Given U V witness Xi V Z
witness Xj , proposition guarantees one among Xi Xj chosen
potential witness U Z conditions demonstrated counter example
Proposition 7 avoided. Using propositions 10 11, position
prove transitivity Proposition 12.
Proposition 12 (Transitivity ). U, V, Z




F (Xi ),

i=1

U V V Z U Z.

proof proceeds considering possible relationships Xi , Xj , respective attributes witnesses dominance U V V Z. Lines 5, 6, 7
proof establish dominance U Z cases Xi Xj , Xj Xi Xi Xj
respectively. first two cases, important attribute among Xi Xj shown
witness U Z help Proposition 10; last case make
use Proposition 11 show least one Xi , Xj witness U Z.
Proof.
1. U V

(Hyp.)

2. V Z

(Hyp.)

3. Xi : U(Xi ) V(Xi ) (1.)
4. Xj : V(Xj ) j Z(Xj ) (2.)
Three cases arise: Xi Xj (5.), Xj Xi (6.) Xi Xj (7.).
230

fiRepresenting Reasoning Qualitative Preferences

5. Xi Xj U Z
5.1.
5.2.
5.3.
5.4.

Xi Xj (Hyp.)
V(Xi ) Z(Xi ) (2., 5.1.)
U(Xi ) Z(Xi ) (3., 5.2.)
Xk : (Xk Xi Xk Xi ) U(Xk ) k Z(Xk )
i. Let Xk Xi Xk Xi (Hyp.)
ii. U(Xk ) k V(Xk ) (1., 5.4.i.)
iii. Xk Xj Xk Xj (5.4.i., P roposition 10)
iv. V(Xk ) k Z(Xk ) (2., 5.4.iii.)
v. U(Xk ) k Z(Xk ) (5.4.ii., 5.4.iv.)
5.5. Xi Xj U Z (5.1., 5.3., 5.4.)
6. Xj Xi U Z
6.1. true symmetry Xi , Xj proof (5.); case, easily
shown U(Xj ) Z(Xj ) Xk : (Xk Xj Xk Xj ) U(Xk ) k Z(Xk ).
7. Xi Xj U Z
Xi Xj (Hyp.)
Xu , Xv {Xi , Xj } : Xu 6= Xv Xk : (Xu Xk Xv Xk ) (7.1., P roposition 11)
Without loss generality, suppose Xu = Xi , Xv = Xj (Hyp.).
V(Xi ) Z(Xi ) (2., 7.1.)
U(Xi ) Z(Xi ) (3., 7.4.)
Xk : Xk Xi U(Xk ) k Z(Xk ).
i. Xk Xi (Hyp.)
ii. U(Xk ) k V(Xk ) (1., 7.6.i.)
iii. Xk Xj Xk Xj Xj Xk Contradicts (7.1., 7.6.i.)!
iv. V(Xk ) k Z(Xk ) (2., 7.6.iii.)
v. U(Xk ) k Z(Xk ) (7.6.ii., 7.6.iv.)
7.7. Xk : Xk Xi U(Xk ) k Z(Xk )
i. Xk Xi (Hyp.)
ii. U(Xk ) k V(Xk ) (1., 7.7.i.)
iii. Xk Xj Xk Xj Xj Xk Contradicts (7.2., 7.3.)!
iv. V(Xk ) k Z(Xk ) (2., 7.7.iii.)
v. U(Xk ) k Z(Xk ) (7.7.ii., 7.7.iv.)
7.8. Xk : Xk Xi Xk Xi U(Xk ) k Z(Xk ) (7.6., 7.7.)
7.9. Xi Xj U Z (7.5., 7.8.)
7.1.
7.2.
7.3.
7.4.
7.5.
7.6.

8. (Xi Xj Xj Xi Xi Xj ) U Z
9. U V V Z U Z

(5., 6., 7.)

(1., 2., 8.)

Theorem 1. intra-attribute preferences arbitrary strict partial orders
relative importance interval order, strict partial order.
Proof. Follows immediately Propositions 9 12.
231

fiSanthanam, Basu & Honavar

Xi

Xj

Xi

Xj

Figure 6: 2 2 substructure, Interval Order
3.5 Role Interval Order Restriction Transitivity
Theorem 1 establishes given partially ordered intra-attribute preferences ,
relative importance relation () interval order (Definition 12), transitive.
addition, also seen counter example Proposition 7, shows
transitivity necessarily hold arbitrary partial order.
condition weaker interval order restriction still makes
transitive retain intra-attribute preferences arbitrary partial orders dominance
Definition 11? answer turns no, prove next.
proceed prove necessity interval ordered relative importance
relation transitive dominance relation , examine interval orders
closely. Recall Definition 12 every interval order X partial order,
additionally satisfies Ferrers axiom X1 , X2 , X3 , X4 X :
(X1 X2 X3 X4 ) (X1 X4 X3 X2 )
borrow characterization axiom Fishburn (1970a, 1985)
relation interval order 2 2 * , 2 2 relational structure
shown Figure 6. words, partial order interval order
restriction isomorphic partial order structure shown Figure 6.
Theorem 2 (Necessity Interval Order). partially ordered intra-attribute preferences
dominance relation Definition 11, transitive relative importance
interval order.
Proof. Assume interval order. true 2 2 .
However, showed Proposition 7 case, transitive using counter
example (see Figure 3). Hence, transitive relative importance interval
order.
3.6 Additional Properties Respect Properties {i }
present additional properties10 hold certain restrictions
imposed intra-attribute relative importance preference relations.
Proposition 13. total order Xi important attribute X
respect , .
10. results section essentially prove conjectures arose analysis results
experiments (see Section 6).

232

fiRepresenting Reasoning Qualitative Preferences

Proof. Let Xi (unique) important attribute X . Suppose U(Xi ) V(Xi ),
thereby making Xi potential witness U V. Since Xi important attribute,
Xk X : Xi Xk , second clause definition U V trivially holds. Hence, Xi
witness U V (see Definition 11).
Note proof proposition made use fact Xk
X : Xi Xk , weaker condition total order. Hence,
following general result.
Proposition 14. unique important attribute Xi , i.e.,
Xi X : Xk X \ {Xi } : Xi Xk , .
proceed prove important result gives conditions
weak order.
Theorem 3. aggregation function defined Definition 8, well
{i } total orders, weak order.
Proof. weak order strict partial order negatively transitive.
already shown strict partial order Theorem 1, hence
left proving negatively transitive, i.e., U 6 V V 6 Z U 6 Z.
First, note since total order, also total order (see Definition 8).
U 6 V (Xi : U(Xi ) V(Xi ) Xk : (Xk Xi U(Xk ) 6 k V(Xk ))) (Xk Xi
possible total order).
(1)
Let Xi Xj important attributes s.t. U(Xi ) V(Xi ) V(Xj ) j Z(Xj )
respectively.
(2)

Let Xp Xq important attributes s.t. Xp Xi U(Xp ) 6 p V(Xp )
Xq Xj V(Xq ) 6 q Z(Xq ) respectively (such Xp Xq must exist (1)).
(3)
Case 1 Xi Xj defined (2) exist (cases Xi and/or Xj dont exist
dealt separately).
Three sub-cases arise: Xp Xq , Xq Xp Xp = Xq .
Case 1a: Suppose Xp Xq (see Figure 7).
(4)
(3) know Xp Xi U(Xp ) 6 p V(Xp ), i.e., V(Xp ) p U(Xp ).

(5)

(3) (4) know V(Xp ) p Z(Xp ), Xq important
attribute also important Xj V(Xq ) 6 q Z(Xq ), Xp
important Xq (and hence Xj well).
(6)
Xj important attribute V(Xj ) j Z(Xj ), Xp Xj
(since Xq Xj Xp Xq ), V(Xp ) 6 p Z(Xp ) (as Xj important
attribute V(Xj ) j Z(Xj ), using (2)). Along (6), means V(Xp ) =
Z(Xp ).
(7)
(5) (7), Z(Xp ) p U(Xp ).

(8)

Also, Xk : Xk Xp U(Xk ) = V(Xk ) V(Xk ) = Z(Xk ) (because Xk
important Xi , Xj Xp , Xq ).
(9)
233

fiSanthanam, Basu & Honavar

U (Xk ) = V(Xk )

V(Xk ) = Z(Xk )
Xp

U (Xi) V(Xi )
Xq
V(Xj ) j Z(Xj )

Figure 7: case Xp Xq
(8) (9), Z U Xp witness. Hence, U 6 Z.
Case 1b: Suppose Xq Xp . claim holds symmetry.
Case 1c: Suppose Xp = Xq .
(3) know Xp Xi U(Xp ) 6 p V(Xp ), i.e., V(Xp ) p U(Xp ).
Similarly, Z(Xp ) p V(Xp ).
Hence, Z(Xp ) p U(Xp ). Moreover, Xk : Xk Xp U(Xk ) = V(Xk ) V(Xk ) =
Z(Xk ) (because Xk important Xi , Xj Xp , Xq ).
Therefore, Z U Xp witness. Hence, U 6 Z.
Case 2 : Xi (say) exist, Xi : U(Xi ) 6 V(Xi ). Let Xp
important attribute s.t. V(Xp ) p U(Xp ) (if Xp exist, trivially U 6 Z
U = V).
(10)
Case 2a: Suppose Xp Xq . Xk : Xk Xp V(Xk ) = Z(Xk ) (because Xk Xq
well). Moreover, Xp Xq V(Xp ) = Z(Xp ). Hence, Z U Xp witness
therefore U 6 Z.
Case 2b: Suppose Xq Xp . Xk : Xk Xq U(Xk ) = V(Xk ) (because Xk Xp
well). Moreover, Xq Xp U(Xq ) = V(Xq ). Hence, Z U Xq witness
therefore U 6 Z.
Case 2c: Suppose Xp = Xq . Xk : Xk Xp V(Xk ) = Z(Xk ) (because Xk Xq
well) similarly Xk : Xk Xq U(Xk ) = V(Xk ) (because Xk Xp well). Moreover,
since V(Xq ) 6 q Z(Xq ) (by (3)), V(Xp ) p U(Xp ) (using (10)) Z(Xp ) p U(Xp ).
Hence, Z U Xp witness therefore U 6 Z.
Case 3

: Xj (say) exist, proof symmetric Case 2.

Case 4 : Suppose Xi Xj exist. Then, attribute Xi ,
V(Xi ) U(Xi ) Z(Xi ) V(Xi ), i.e., Xi : Z(Xi ) U(Xi ). Hence, witness
U Z, U 6 Z.
Cases 1 - 4 exhaustive, case U 6 Z. completes proof.
234

fiRepresenting Reasoning Qualitative Preferences

conjecture weak order {i } total orders
arbitrary interval order (i.e., conditions general conditions
Theorem 3). leave open problem.
Conjecture 1. {i } total orders arbitrary interval order,
weak order.
Remark.
stated, Conjecture 1 Theorem 3 apply whenever {i } totally ordered,
using method comparing two aggregated valuations ( ) (see Definition 8).
generally, note hold whenever { } total orders, regardless chosen
method comparing two aggregated valuations, regardless properties
input intra-attribute preferences {i }. example, suppose {i } ranked weak
orders (i.e., total orders). such, Conjecture 1 Theorem 3 apply. However,
attribute Xi define (S) rank number corresponding worst
frontier S, natural total order ranks weak order,
consequences Conjecture 1 Theorem 3 hold.
summarize theoretical results relating properties dominance relation
properties preference relations { } Table 5.






Remarks

io
io


po



po
wo
wo

Theorem 1
Conjecture 1
Theorem 3

Table 5: Summary results conjectures relating properties respect
properties { }.

3.7 Choosing Preferred Solutions
Given set C = {Ci } compositions preference relation (e.g., ) allows
us compare pair compositions, problem find preferred composition(s). preference relations totally ordered (e.g., ranking) set
alternative solutions, rationality choice suggests ordering alternatives respect
complete preference choosing best alternative, i.e., one ranks
highest. However, preference relation strict partial order, e.g., case
, every pair solutions (compositions) may comparable. Therefore, solution
preferred respect preference relation may exist. Hence,
use notion non-dominated set solutions defined follows.
Definition 13 (Non-dominated Set). non-dominated set elements (alternatives
solutions compositions) set C respect (partially ordered) preference relation
(e.g., ), denoted (C), subset C none elements
preferred element (C).
235

fiSanthanam, Basu & Honavar

(C) = {Ci C|Cj C : Cj Ci }
Note per definition, (C) maximal set elements C respect
relation . also easy observe C 6= (C) 6= .

4. Algorithms Computing Preferred Compositions
turn problem identifying set feasible compositions (that satisfy
pre-specified functionality ()), preferred subset, i.e., non-dominated set.
4.1 Computing Maximal/Minimal Subset Respect Partial Order
straightforward way computing maximal (non-dominated) elements set
n elements respect preference relation following algorithm:
element si S, check sj : sj si , not, si non-dominated
set. simple compare pairs delete dominated approach involves computing
dominance respect O(n2 ) times.
Recently Daskalakis, Karp, Mossel, Riesenfeld Verbin (2009) provided algorithm
performs O(wn) pairwise comparisons compute maximal elements
set respect partial order , n = |S| w width partial
order (the size maximal set pairwise incomparable elements
respect ). algorithm presented Daskalakis et al. finds minimal elements;
corresponding algorithm finding maximal elements follows.
Let T0 = . Let elements set x1 , x2 , xn . step t( 1):
Compare xt elements Tt1 .
exists Tt1 xt , nothing.
Otherwise, remove Tt1 elements xt put xt Tt .
termination, set Tn contains maximal elements S, i.e., non-dominated
subset respect . make use algorithm compute nondominated (maximal) subsets (namely, ()), original version algorithm
given Daskalakis (2009) compute worst-frontiers (minimal subsets).
4.2 Algorithms Finding Preferred Feasible Compositions
proceed develop algorithms finding preferred feasible compositions, given
compositional system hR, , |=i consisting repository R pre-existing components,
user specified functionality , user preferences {i } functional composition
algorithm f . analyze properties algorithms respect worst-frontier
based aggregation (see Definition 6).
Definition 14 (Soundness Completeness). algorithm that, given set C
feasible compositions, computes set feasible compositions SA (C) said
sound respect C. algorithm complete respect C SA (C).
236

fiRepresenting Reasoning Qualitative Preferences

Algorithm 1 ComposeAndFilter(, f, )
1. Find set C feasible compositions w.r.t. using f
2. return (C)
Given compositional system hR, , |=i consisting repository R pre-existing components, user specified functionality , straightforward approach finding
preferred feasible compositions involves: (a) computing set C functionally
feasible compositions using functional composition algorithm f , (b) choosing
non-dominated set according preferences non-functional attributes.
Algorithm 1 follows simple approach produce set (C) non-dominated
feasible compositions, invoked preference relation , functional composition algorithm f desired functionality . (C) computed using
procedure described Section 4.1. Algorithm 1 sound complete respect
C.
4.3 Sound Weakly Complete Algorithm
Note worst case, Algorithm 1 evaluates dominance relation
possible pairs feasible compositions C. However, avoided settle
non-empty subset (C). Note every solution subset guaranteed
optimal respect user preferences . introduce notion weak
completeness describe algorithm computes set feasible compositions, least
one non-dominated respect .
Definition 15 (Weak Completeness). algorithm that, given set C feasible compositions, computes set SA feasible compositions said weakly complete respect
C (C) 6= SA (C) 6= .
proceed describe sound weakly complete algorithm, i.e., one computes non-empty subset (C). algorithm based following observation:
Solutions non-dominated respect relatively most-important
attributes guaranteed include solutions non-dominated overall
respect well. Hence, solutions preferred respect
attribute used compute non-empty subset (C). proceed
considering solutions preferred respect attribute Xi .
Definition 16 (Non-dominated solutions w.r.t. attributes). set (C) solutions
non-dominated respect attribute Xi defined
(C) = {U | U C V C : V(Xi ) U(Xi )}.
Let X set important attributes respect , i.e., = (X ) =
{Xi |Xj X : Xj Xi }. Clearly, 6= always exists non-empty maximal
set elements partial order . following proposition states every Xi I,
least one solutions (C) also contained (C).
Proposition 15. Xi : (C) 6= (C) (C) 6= (See Appendix
proof ).
237

fiSanthanam, Basu & Honavar

Algorithm 2 constructs subset (C), using sets { (C) | Xi I}. First,
algorithm computes set important attributes X respect (Line 2).
algorithm iteratively computes (C) Xi (Lines 3, 4), identifies subset
solutions non-dominated respect case, combines
obtain (C).
Algorithm 2 WeaklyCompleteCompose({i | Xi X }, , f, )
1.
2. (X ) = {Xi | Xj : Xj Xi }
3. Xi
4.
(C) ComposeAndFilter( , f, )
5.
( (C))
6. end
7. return
Theorem 4 (Soundness Weak Completeness Algorithm 2). Given set attributes
X , preference relations , Algorithm 2 generates set feasible compositions
(C) (C) 6= 6= (See Appendix proof ).
general, Algorithm 2 guaranteed yield complete set solutions, i.e., 6=
(C). following example illustrates case.
Example. Consider compositional system two attributes X = {X1 , X2 },
domains {a1 , a2 , a3 } {b1 , b2 , b3 } respectively. Let intra-attribute preferences
total orders: a1 1 a2 1 a3 b1 2 b2 2 b3 respectively, let attributes
equally important ( = ). Suppose user-specified goal satisfied three feasible
compositions C1 , C2 , C3 valuations VC1 = h{a1 }, {b3 }i, VC2 = h{a3 }, {b1 }i VC3 =
h{a2 }, {b2 }i respectively. Given preferences, 1 (C) = {C1 } 2 (C) = {C2 }.
Thus, = {C1 , C2 } However, (C) = {C1 , C2 , C3 } =
6 .

example shows preferred valuation one attribute (e.g., X1 )
result poor valuations one attributes (e.g., X2 ). Algorithm 2 may
thus leave solutions like C3 preferred respect one ,
nevertheless may correspond good compromise consider multiple
important attributes. natural question ask minimal conditions
Algorithm 2 complete. related question whether Algorithm 2
guaranteed produce certain minimum number non-dominated solutions (||)
specific set conditions. Note general, cardinality depends
user preferences , , also user specified functionality together
repository R determines set C feasible compositions. However, special
case specifies single attribute Xt relatively important
attributes, show Algorithm 2 complete.
Proposition 16. = {Xt } Xk 6= Xt X : Xt Xk , (C) , i.e.,
Algorithm 2 complete (See Appendix proof ).
remains seen necessary sufficient conditions ensuring
completeness Algorithm 2, plan address problem future.
238

fiRepresenting Reasoning Qualitative Preferences

4.4 Optimizing Respect One Important Attributes
see Section 5, Algorithm 2 high worst case complexity, especially
set important attributes large. due fact
important attribute Xi I, algorithm computes non-dominated set
feasible compositions respect first, respect , i.e.,
( (C)) (Line 4). computation non-dominated set respect ,
although expensive, crucial ensuring soundness Algorithm 2.
soundness desirable property, may settings requiring faster computation feasible compositions, may acceptable obtain set feasible
compositions contains least one (whenever exists one) preferred
feasible compositions (one non-dominated feasible composition
respect ). case, might useful algorithm lower complexity finds set feasible compositions least one preferred (i.e.,
weakly complete), opposed one higher complexity finds set feasible
compositions preferred (i.e., sound).
Algorithm 3 AttWeaklyCompleteCompose({i | Xi X }, , f, )
1. (X ) = {Xi | Xj : Xj Xi }
2. Xi
3. (C) = ComposeAndFilter( , f, )
4. return
consider one modification Algorithm 2, namely Algorithm 3, arbitrarily
picks one important attributes Xi (as opposed entire set
Algorithm 2) finds set feasible compositions non-dominated
respect , i.e., = (C) Algorithm 3.
weak completeness Algorithm 3 follows directly Proposition 15.
following example, however, show feasible compositions produced
Algorithm 3 may dominated feasible composition respect ,
i.e., Algorithm 3 sound.
Example. Consider compositional system two attributes X = {X1 , X2 },
domains {a1 , a2 } {b1 , b2 } respectively. Let intra-attribute preferences be: a1 1 a2
b1 2 b2 respectively, let attributes equally important ( = ; =
{X1 , X2 }). Suppose user-specified goal satisfied three feasible compositions
C1 , C2 , C3 valuations VC1 = h{a1 }, {b1 }i, VC2 = h{a2 }, {b1 }i VC3 = h{a1 }, {b2 }i
respectively. Given preferences, choose maximize preference
respect attribute X1 I, = 1 (C) = {C1 , C3 }. choose X2 instead,
get = 2 (C) = {C1 , C2 }. However, case (C) = {C1 } =
6 .

following proposition gives condition Algorithm 3 complete.
Proposition 17. |I| = 1, i.e., unique important attribute respect
, Algorithm 3 complete (See Appendix proof ).
239

fiSanthanam, Basu & Honavar

Algorithm 4 InterleaveCompose(L, , f, )
1. L =
2.
return
3. end
4. = (L)
5. =
6. C
7.
C 6|=
8.
= f (C)
9.
else
10.
= {C}
11.
end
12. end
13. =
14.
return
15. else
16.
InterleaveCompose((L \ ) , , f, )
17. end
4.5 Interleaving Functional Composition Preferential Optimization
Algorithms 1, 2 3 identify preferred feasible compositions using two
step approach: (a) find feasible compositions C; (b) compute subset C
preferred respect user preferences. develop algorithm eliminates
intermediate partial feasible compositions consideration based user
preferences. particularly useful settings (such |C| large relative
| (C)|), might efficient compute subset C likely
(based ) (C).
Algorithm 4 requires functional composition algorithm f incremental (see
Definition 2), i.e., produces set f (C) functionally feasible extensions given
existing partial feasible composition C. step, Algorithm 4 chooses subset
feasible extensions produced applying f non-dominated partial feasible
compositions, based user preferences. Algorithm 4 computes non-dominated
set feasible compositions interleaving execution incremental functional
composition algorithm f ordering partial solutions respect preferences
non-functional attributes.
Algorithm 4 initially invoked using parameters L = () 11 , , functional
composition algorithm f . algorithm maintains step list L partial
feasible compositions consideration. L empty step, i.e.,
partial feasible compositions explored, algorithm terminates
11. necessary invoke algorithm L = () (i.e., list L) initially.
may functional composition algorithms begin non-empty composition C proceed
obtain feasible composition iteratively altering C. instance, one could think randomized
evolutionary algorithms begin random, non-empty composition somehow repeatedly
improved course composition.

240

fiRepresenting Reasoning Qualitative Preferences

solution (Lines 1 3); otherwise selects L, subset non-dominated
respect preference relation (Line 4). partial feasible compositions
also feasible compositions, algorithm outputs terminates (Lines 13
14). Otherwise, replaces partial feasible compositions feasible
compositions, one-step extensions (Lines 7 8). algorithm continues
recurse (Line 16), iteration updating dominated set replacing
changes dominated set i.e., = . Note possible
eliminate dominated compositions (L \ ) stage extensions
(in later iteration) could result non-dominated compositions.
Proposition 18 (Termination Algorithm 4). Given finite repository components,
Algorithm 4 terminates finite number steps (See Appendix proof ).
next investigate soundness, weak-completeness completeness properties Algorithm 4. Proposition 19 states algorithm general sound respect
C, i.e., guaranteed produce feasible compositions non-dominated
respect . However, discount usefulness algorithm,
show sound assumptions (see Theorem 5).
Proposition 19 (Unsoundness Algorithm 4). Given functional composition algorithm
f user preferences set attributes X , Algorithm 4 guaranteed
generate set feasible compositions (C) (See Appendix
proof ).
result implies general, feasible compositions returned Algorithm 4
() (C). example shown Figure 8 illustrates problem. time
termination, may exist partial feasible composition B list L
dominated feasible composition E ; however, may possible extend B
feasible composition B W dominates one compositions F (as illustrated
counter example proof, see Appendix A). words, VB , VF ,
VF VB VBW VF .

... E F ...

...

B

...



B W

Figure 8: case Algorithm 4 sound

Although Algorithm 4 sound general, show sound
relation interval order (as opposed arbitrary partial order).
Theorem 5 (Soundness Algorithm 4). interval order, given functional composition algorithm f user preferences { }, set attributes X ,
241

fiSanthanam, Basu & Honavar

Algorithm 4 generates set feasible compositions (C) (See Appendix
proof ).
Theorem 5 requires interval order, important question arises:
conditions interval order? Theorem 3 (see Section 3.6)
gives us one condition weak order (i.e., also interval order). next
two theorems give conditions Algorithm 4 weakly complete complete
respectively.
Theorem 6 (Weak Completeness Algorithm 4). interval order, given
functional composition algorithm f user preferences { }, set attributes X ,
Algorithm 4 produces set feasible compositions (C) 6= (C) 6=
(See Appendix proof ).
Theorem 7 (Completeness Algorithm 4). weak order, given functional composition algorithm f user preferences { }, set attributes X ,
Algorithm 4 generates set feasible compositions (C) (See Appendix
proof ).

Remark. algorithm explore feasible compositions generated extending feasible compositions (by condition Line 7). Proposition
6 shows worst-frontier based aggregation used, extending feasible composition cannot yield preferred feasible composition. guarantees soundness
Algorithm 4 (Theorem 5). However, aggregation schemes used, might
case feasible extension feasible composition preferred,
case, order ensure soundness Algorithm 4, Line 10 changed
= {C} f (C).
summary conditions (in terms properties relative importance
dominance preference) algorithms sound, complete weak complete
given Table 6.
Algorithm

Sound

Weakly Complete

Complete

A1
A2
A3
A4

po
po

io

po
po
po
io

po
|I| = 1
|I| = 1
wo

Table 6: Properties algorithms sound, weakly complete
complete. po stands partial order; io stands
interval order; wo stands weak order; |I| = 1
unique important attribute. indicates condition(s)
A3 sound remains open problem.

242

fiRepresenting Reasoning Qualitative Preferences

5. Complexity
section, study complexity dominance testing (evaluating , see Section 3.3) well complexity algorithms computing non-dominated set
feasible compositions (see Section 4). express worst case time complexity
dominance testing terms size user specified intra-attribute, relative importance
preference relations attribute domains (see Table 7).
Relation / Set

Symbol

Cardinality

Remarks

Attributes
Domain Attributes
Intra-attribute preferences
Intra-attribute preferences
Relative Importance
Relative Importance
Important Attributes
Repository
Feasible Compositions
Dominance Relation

X
Di





R
C



n
wint
kint
wrel
krel
mI
r
c
wdom

Number attributes
Number possible valuations Xi
Width partial order
Size relation
Width partial order
Size relation
Number important attributes
Number components R
Number feasible compositions
Width dominance relation

Table 7: Cardinalities sets relations
5.1 Computing Maximal(Non-dominated)/Minimal Subset.
Let partial order set S, width w (size maximal set elements
pairwise incomparable) n = |S|. algorithm due Daskalakis et al.
discussed Section 4.1 finds maximal minimal subset respect within
O(wn) pairwise comparisons. Note maximum width partial order w = n,
= . Hence, worst case O(n2 ) comparisons needed.
5.2 Complexity Dominance Testing
Computing Worst Frontiers (i ). Let Di . Recall Definition 6 worst
frontier set respect attribute Xi (S) := {v : v S, u s.t. v u},
i.e., minimal set elements respect preference relation . Using
algorithm due Daskalakis et al. find minimal set respect partial order
(see above), complexity computing (S) O(nwint ).
Comparing Worst Frontiers ( ). Let A, B F (Xi ). per Definition 8, B
b B, : b. worst case, computing B would involve checking
whether b pair a, b, would cost O(kint ). Hence, complexity
comparing worst frontiers B O(n2 kint ).
Dominance Testing ( ).
U V

Recall Definition 11 definition dominance:

Xi : U(Xi ) V(Xi )
Xk , (Xk Xi Xk Xi ) U(Xk ) k V(Xk )
243

fiSanthanam, Basu & Honavar

complexity dominance testing complexity finding witness attribute
X U V. attribute Xi , complexity computing first clause
conjunction definition U V O(n2 kint ); computing
second clause m(n2 kint + krel ) , O(krel ) O(n2 kint ) complexities
evaluating left right hand sides implication (respectively)
Xk X .
2k
2k
Hence, complexity

dominance
testing



n
+
m(n
+
k
)
, simply
int
int
rel

m2 (n2 kint + krel ) . use shorthand denote m2 (n2 kint + krel ).
5.3 Complexity Algorithms

algorithms computing non-dominated feasible compositions (presented
Section 4) makes use functional composition algorithm f find feasible compositions.
Hence, complexity analysis algorithms needs incorporate complexity
functional composition algorithm well.
Recall Algorithms 1, 2 3 begin computing set feasible compositions
single shot using functional composition algorithm black box, proceed
find preferred among them. Algorithm 4 instead makes use functional
composition algorithm produces set feasible compositions iteratively extending partial feasible compositions. Specifically, interleaves execution functional
composition algorithm ordering partial solutions respect preferences
non-functional attributes.
denote O(fe ) O(fg ) respectively, complexity computing set
feasible extensions partial feasible composition respect complexity
computing set feasible compositions respect .
5.4 Complexity Algorithm 1
overall complexity finding set non-dominated feasible compositions
O(fg +cwdom d), O(d) complexity evaluating pair compositions.
first term fg accounts Line 1 algorithm computes set feasible
compositions, term cwdom corresponds computation (C) per
algorithm given Section 4.1.
5.5 Complexity Algorithm 2
complexity identifying important attributes respect (Line 1)
O(mwrel krel ). important attribute Xi I, Algorithm 2 (a) invokes Algorithm 1 using derived intra-attribute preference compute (C); (b) identifies
subset (C) non-dominated respect ; (c) adds set
solutions. Hence,
complexity Algorithm 2 mwrel krel + mI (fg + cwdom n2 kint )+

2
mI | (C)| .
Since feasible compositions respect given fixed, computing
feasible compositions (during first invocation Algorithm 1 storing them), complexity Algorithm 2 reduced O(fg + mwrel krel +
mI cwdom n2 kint + mI | (C)|2 d).
244

fiRepresenting Reasoning Qualitative Preferences

5.6 Complexity Algorithm 3
complexity identifying important attributes respect (Line 1)
O(mwrel krel ). contrast Algorithm 2, Algorithm 3 invokes Algorithm 1 using derived intra-attribute preference compute (C) exactly one important
attributes, Xi I. Hence, complexity Algorithm 3 fg +mwrel krel +cwdom n2 kint ).
5.7 Complexity Algorithm 4
consider worst case wherein space partial feasible compositions explored
Algorithm 4 tree rooted ; let b maximum branching factor (corresponding
maximum number extensions produced functional composition algorithm),
h height (corresponding maximum number components used composition
satisfies ). worst case, iteration Algorithm 4, every element L,
list current partial feasible compositions, ends non-dominated set .
level tree corresponds one iteration Algorithm 4, lth iterl
ation, worst
case b nodes L. Hence, complexity lth iteration
l
2
l
(b ) + b fe , first term corresponds computing non-dominated set
among current set partial feasible compositions, second term corresponds
computing feasible extensions
partial feasible composition. Hence, overall
Phof
2l + bl f ) O(b2h + bh f ).
complexity Algorithm 4
(b
e
e
l=0
conducted experiments algorithms using simulated problem instances
study algorithms perform practice, describe next.

6. Experiments, Results & Analysis
describe design results experiments aimed comparing algorithms described Section 4 respect following attributes.
a) Quality solutions produced algorithms. measure quality
solutions produced algorithms follows. First, among
preferred solutions exist composition problem, measure fraction
produced algorithm. Second, among solutions produced
algorithm, measure fraction solutions preferred
composition problem.
b) Performance efficiency algorithms. performance algorithm
measured terms response time (time taken return set solutions),
efficiency measured terms number times algorithm invokes
functional composition algorithm.
6.1 Experimental Setup
describe data structure used model search space compositions
simulation parameters used generate compositions experiments.
245

fiSanthanam, Basu & Honavar

6.1.1 Modeling Search Space Compositions using Recursive Trees
uniform recursive tree (Smythe & Mahmoud, 1995) serves good choice model
search space partial compositions feasible extensions. tree n vertices
labeled 1, 2, . . . n recursive tree node labeled 1 distinguished root,
k : 2 k n, labels nodes unique path root node
labeled k form increasing sequence. uniform recursive tree n nodes (denoted
U RT ree(n)) one chosen equal probability space trees.
simple growth rule used generate uniform random recursive tree n
nodes, given tree n 1 nodes: Given U RT ree(n 1), choose uniformly random
node U RT ree(n 1), add node labeled n randomly chosen node
parent obtain U RT ree(n). properties class uniform random recursive trees
well studied literature random data structures (see Smythe & Mahmoud, 1995,
survey).
rationale behind choosing uniform recursive tree data structure model
search space problem growth rule generates recursive tree similar
intuition process searching feasible composition. Recall search
space partial compositions generated recursive application functional
composition algorithm f . nodes recursive tree correspond components
repository composition problem. tree built starting root node
search feasible compositions correspondingly begins . recursive tree
grown attaching new nodes existing nodes corresponds
extending feasible partial compositions adding (composing) new components
existing feasible partial compositions. Finally, leaves recursive tree depth
root correspond (possibly feasible) composition components
repository composition problem.
show precise correspondence recursive tree data structure
search space partial compositions.
node tree corresponds composition.
root node corresponds empty composition ,
node level 1 corresponds composition component W
repository, i.e., W = W, W R,
node level corresponds composition component W repository composition associated parent node,
leaf node called feasible node composition associated node
satisfies .
purpose experimentally evaluating algorithms finding preferred compositions compare them, generate random recursive trees varying
number nodes (or |R|, number components repository). generated
random recursive tree, certain fraction (f eas) leaves picked uniformly randomly
labeled feasible compositions. node generated labeled
246

fiRepresenting Reasoning Qualitative Preferences

random recursive tree, valuation attributes X = {Xi } (corresponding partial
composition represents) randomly generated based respective domains ({Di })12 .
6.1.2 User Preferences
generate user preferences generating random partial/total orders
random interval/total order varying number attributes = |X | domain
size attributes n = |Di |.
summary simulation parameters given Table 8.
Parameter

Meaning

Range

f eas

Fraction leaves search tree feasible compositions
Domain size preference attributes
Number preference attributes
Number components repository (nodes
search tree)
Overhead (in milliseconds) per invocation
step-by-step functional composition algorithm f
Intra-attribute preference values Xi
Relative importance preference X

{0.25, 0.5, 0.75, 1.0}

|Di |
|X |
|R|
f delay



{2, 4, 6, 8, 10}
{2, 4, 6, . . . 20}
{10, 20, . . . 200}
{1, 10, 100, 1000}
{po, to}
{io, to}

Table 8: Simulation parameters ranges

6.1.3 Implementation Algorithms
Computing Dominance
order check one valuation dominates another respect user preferences
{i } , iterate attributes X check exists witness
dominance hold (see Definition 11).
Computing preferred solutions
implemented algorithms A1, A2, A3 A4 Java. Preliminary experiments A2
showed algorithm scale large problem instances. particular,
number attributes large dominance testing computationally intensive, A2
timed due computation non-dominated set multiple times
important attributes. Hence proceed run experiments samples
A2. However, able run experiments algorithm A3 arbitrarily picks
one important attributes finds preferred solutions respect
intra-attribute preferences attribute.
algorithms A1 A3 first compute solutions using functional composition
algorithm (simulated f ), whereas A4, interleave calls f choosing preferred
12. Note setup described here, valuations attributes generated randomly node.
real applications, valuations nodes may depend valuations parents.

247

fiSanthanam, Basu & Honavar

compositions (partial solutions) step. step, A4 chooses subset
feasible extensions current compositions exploration. Table 9 gives brief
description implemented algorithms.
Alg.

Name Algorithm

Remarks

A1

ComposeAndF ilter

A2

W eaklyCompleteCompose

A3

AttW eaklyCompleteCompose

A4

InterleaveCompose

First identifies functionally feasible compositions; finds non-dominated
set feasible compositions respect

First identifies functionally feasible compositions; finds non-dominated
set feasible compositions respect
important attributes
{Xi }
First identifies functionally feasible compositions; picks arbitrary important attribute Xi finds nondominated set feasible compositions
respect
Identifies non-dominated set feasible extensions respect
step; recursively identifies feasible extensions non-dominated
feasible extensions feasible compositions

Table 9: Implemented Algorithms
Table 10 shows attributes recorded execution
algorithms A1, A3 A4 composition problem.
6.2 Results
compare algorithms A1, A3, A4 respect to:
1. Quality solutions produced algorithms, terms SP/P F SP/S
2. Performance efficiency terms running time number calls functional composition algorithm f
6.2.1 Quality Solutions
compare quality solutions produced algorithms terms following
measures.
248

fiRepresenting Reasoning Qualitative Preferences

Attribute

Meaning

Remarks

F

Set solutions (feasible compositions) sample
problem instance
Set preferred solutions sample problem
instance respect user preferences
dominance relation
Set solutions produced composition algorithm
Set solutions produced composition algorithm also preferred solutions
respect user preferences dominance
relation
Running time composition algorithm (ms)
Number times algorithm invokes stepby-step functional composition algorithm f

F = C

PF


SP


f count

P F = (C ) F

SP = P F

Table 10: Attributes observed execution algorithm
SP/P F 13 : Proportion preferred solutions produced algorithm (fraction
optimal solutions produced algorithm). algorithm complete,
SP/P F = 1.
SP/S: Proportion solutions produced algorithm preferred
(fraction solutions produced algorithm, optimal). algorithm
sound, SP/S = 1.
algorithm A1 exhaustively searches entire space compositions identify
feasible compositions F , finds preferred among respect
user preferences {i }. computes set (F ), observed
A1, SP = P F = S, i.e., sound (finds preferred solutions)
complete (finds preferred solutions).
next compare algorithms A3 A4 respect SP/P F SP/S
various types ordering restrictions user preferences {i } . Table 11 reports
results following combinations: (i) interval order, {i } partial orders;
(ii) interval order, {i } total orders; (iii) total order, {i } partial
orders; (iv) total order, {i } total orders.
Comparison SP/P F
general, preferred solutions found algorithms
(see Table 11).
13. sake readability, use notation used denote set denote cardinality well,
e.g., SP used denote set cardinality (|SP |).

249

fiSanthanam, Basu & Honavar





A3

A4

io
io



po

po


77.50
71.00
100.00
100.00

83.95
100.00
85.88
100.00

Table 11: Comparison SP/P F algorithms A3 A4 respect various ordering
restrictions {i }, . percent problem instances SP/P F = 1
shown row respect corresponding ordering restrictions
preference relations {i }. parameters used simulating
problem instances ranges given Table 8.

observe relative importance () total order {i } arbitrary
partial orders, 100% preferred solutions produced A3. Propositions 13 14 (see Section 3.6) obtained based insight.





A3

A4

io
io



po

po


41.78
30.78
33.90
27.30

98.45
100.00
96.98
100.00

Table 12: Comparison SP/S algorithms A3 A4 respect various ordering
restrictions {i }, . percent problem instances SP/S = 1
shown row respect corresponding ordering restrictions
preference relations {i }. parameters used simulating
problem instances ranges given Table 8.

Comparison SP/S
general, solutions found interleaved algorithm A4
preferred solutions (see Table 12). hand, algorithm A3
produced many solutions preferred.
second (and fourth) row(s) Tables 12 11 suggests intra-attribute
preferences ({i }) total orders arbitrary interval order, interleaved
algorithm A4 sound complete, i.e., produces exactly non-dominated set
solutions respect . Conjecture 1 Theorem 3 Section 3.6
obtained based insight.
250

fiRepresenting Reasoning Qualitative Preferences

6.2.2 Performance Efficiency
compare performance efficiency A3, A4 terms number times
functional composition algorithm f invoked, running time (in milliseconds)
algorithms compute solutions.
Number calls functional composition f
plots Figures 9 10 show results experiments performed problem
instances relative importance preferences interval/total orders intra-attribute
preferences partial/total orders, yield following observations.
general, experiments show interleaved algorithm A4 makes fewer calls
f compared A3. seen Figures 9 10, data points
corresponding number calls f made A4 (colored red) lie
correspond A3 (colored green) plots (a) (b). A4 explores
preferred subset available feasible extensions step
search. hand, A3 exhaustively explores feasible extensions
step.
intra-attribute preferences {i } total orders, difference number calls f made A3 A4 pronounced. observed
Figures 9 10, data points corresponding number calls f
made A4 (colored red) lie much closer axis corresponding number
feasible compositions, comparison A3 (colored green). explained
fact case dominance relation larger, due number
incomparable pairs compositions smaller. Therefore, interleaving step
non-dominated set computed extension smaller.
A3 A4, number calls f decreases fraction feasible
compositions (f eas) increases. Figures 9 10 show number feasible
compositions increases, data points corresponding number calls f
(for algorithms) gets closer axis corresponding number feasible
compositions.
Running time
observed running times algorithms A3, A4 depend two key factors:
f delay, time taken per execution functional composition step
Complexity dominance testing turn function |Di |, |X |
properties {i } . particular, complexity dominance testing depends
size preference relations {i } (see Section 5.2).
order understand effect f delay running times algorithms,
ran experiments f delay = 10ms f delay = 1000ms problem instances
relative importance preferences interval/total orders intra-attribute preferences
partial/total orders (see Table 8 parameters used ranges).
respective results shown Figures 11 14. results yield following observations.
251

fiSanthanam, Basu & Honavar

!"#$ %&'()"!*+ 3 %*")$! .)/)0 %*" )!,!"" )#12" 3 4!)"#! .)/)




ff




























fi








!"#$ %&'()"!*+,, - ("! .)/)0 %*" )!,!"" )#12" 3 4!)"#! .)/)






ff




















fi













Figure 9: comparison algorithms A1, A3 A4 respect number
times invoke step-by-step functional composition algorithm
execution. plots (a) (b) correspond results running algorithms
simulated problem instances, intra-attribute preference (i )
partial order, relative importance preference () interval total
order. four distinct bands seen plots correspond various fractions
leaves search tree problem instance feasible compositions:
f eas = 0.25, 0.5, 0.75, 1.0.

252

fiRepresenting Reasoning Qualitative Preferences

EFGHIJKF LMNOPI H]^F _ L] IFPKHG `PaFPb L] PHcHII PJdeIF _ fOI HG `PaFPP
655
:95
:85
:75
@
??>
=
<
;

:65

g:

:55

gh

95

g7

85
75
65
5
5

65

75

ABC

85

95

:55

:65

Q RSBTUDVS WX ZXTU[UX \T

EFGHIJKF LMNOPI H]^F _ fOIHG `PaFPb L] PHcHII PJdeIF _ fOI HG `PaFP
655
:95
:85
:75
@
??>
=
<
;

:65

g:

:55

gh

95

g7

85
75
65
5
5
ADC

65

75

85

95

:55

:65

Q RSBTUDVS WX ZXTU[UX \T

Figure 10: comparison algorithms A1, A3 A4 respect number
times invoke step-by-step functional composition algorithm
execution. plots (a) (b) correspond results running
algorithms simulated problem instances, intra-attribute preference
(i ) total order, relative importance preference () interval
total order. four distinct bands seen plots correspond various
fractions leaves search tree problem instance feasible
compositions: f eas = 0.25, 0.5, 0.75, 1.0.

253

fiSanthanam, Basu & Honavar

general, comparison running time algorithm A4 intraattribute preferences (i ) partial orders, A4 faster total orders.
trend observed plots (a) (b) Figure 12 (where intra-attribute preferences
total orders), data points corresponding running time A4 (colored
red) much closer axis corresponding number feasible compositions,
comparison plots (a) (b). similar trend also observed Figures 13
14.
algorithm A3 almost always outperforms blind search algorithm A1 terms
running time. A3 computes non-dominated set last step
respect intra-attribute preference valuations one attribute
(in place dominance relation used A1).
interleaved algorithm A4 sensitive complexity dominance
A1 A3, step A4 computes non-dominated subset extensions
explore. hand, A1 A3 involve computation dominance
last step. A3 faster A1, A4, computes nondominated set respect intra-attribute preference valuations one
attribute (in place dominance relation used A1 A4).
Algorithms A1 A3 sensitive f delay interleaved algorithm
A4. step A1 A3 explore feasible extensions, A4
explores preferred subset feasible extensions step.
overall running times A1, A3 A4 depend relative trade-offs among
|Di |, |X |, properties {i }, (those influence complexity dominance
testing) one hand f delay other.

7. Summary Discussion
summarize contributions paper.
7.1 Summary
Many applications, e.g., planning, Web service composition, embedded system design, etc.,
rely methods identifying collections (compositions) objects (components) satisfying functional specification. Among compositions satisfy functional
specification (feasible compositions), often necessary identify one compositions preferred respect user preferences non-functional attributes.
particular interest settings user preferences attributes expressed
qualitative rather quantitative terms (Doyle & Thomason, 1999).
paper, proposed framework representing reasoning qualitative preferences compositions terms qualitative preferences attributes
components; developed suite algorithms compute preferred feasible compositions, given algorithm computes functionally feasible compositions.
Specifically,
254

fiRepresenting Reasoning Qualitative Preferences


oiiii
niiii
{z
w

x
w
tv
u

ts

qr

miiii
j
liiii

l

kiiii



jiiii



ki

oi

mi

|}~

pi

jii

jki

}

mniii
miiii
lniii

{z
w

x
w
tv
u

ts

qr

liiii
j

kniii
kiiii

l

jniii



jiiii
niii


|~

ki

oi

mi

pi

jii

jki

}

Figure 11: comparison algorithms A1, A3 A4 respect running
times function number feasible compositions, invocation
step step-by-step functional composition algorithm overhead
10 milliseconds. plots (a) (b) correspond results running
algorithms simulated problem instances, intra-attribute preference
(i ) partial order, relative importance preference () interval
total order. four distinct bands seen plots correspond various
fractions leaves search tree problem instance feasible
compositions: f eas = 0.25, 0.5, 0.75, 1.0.

255

fiSanthanam, Basu & Honavar
























































































Figure 12: comparison algorithms A1, A3 A4 respect running
times function number feasible compositions, invocation
step step-by-step functional composition algorithm overhead
10 milliseconds. plots (a) (b) correspond results running
algorithms simulated problem instances, intra-attribute preference
(i ) total order, relative importance preference () interval
total order. four distinct bands seen plots correspond various
fractions leaves search tree problem instance feasible
compositions: f eas = 0.25, 0.5, 0.75, 1.0.

256

fiRepresenting Reasoning Qualitative Preferences




fffi fi fifi fi fi fi fifi



















































fffi ff fifi fi fi fi fifi


















































Figure 13: comparison algorithms A1, A3 A4 respect running
times function number feasible compositions, invocation
step step-by-step functional composition algorithm overhead
1000 milliseconds. plots (a) (b) correspond results running
algorithms simulated problem instances, intra-attribute preference
(i ) partial order, relative importance preference () interval
total order. four distinct bands seen plots correspond various
fractions leaves search tree problem instance feasible
compositions: f eas = 0.25, 0.5, 0.75, 1.0.

257

fiSanthanam, Basu & Honavar

;<=>?@A< BCDEF?>GH< BG?<FA>= JFK<FL BG? F>M>?? F@NO?< PE?>= JFK<F



('
$
&
%
$
!#
"
!





9



9:



9













)*+







, -.*/012. 34564/07 048/

;<=>?@A< BCDEF?>GH< PE?>= JFK<FL BG? F>M>?? F@NO?< PE?>= JFK<F



('
$
&
%
$
!#
"
!





9



9:



9







)1+













, -.*/012. 34564/07 048/

Figure 14: comparison algorithms A1, A3 A4 respect running
times function number feasible compositions, invocation
step step-by-step functional composition algorithm overhead
1000 milliseconds. plots (a) (b) correspond results running
algorithms simulated problem instances, intra-attribute preference
(i ) total order, relative importance preference () interval
total order. four distinct bands seen plots correspond various
fractions leaves search tree problem instance feasible
compositions: f eas = 0.25, 0.5, 0.75, 1.0.

258

fiRepresenting Reasoning Qualitative Preferences

a) defined generic aggregation function compute valuation composition function valuations components. also presented
strict partial order preference relation comparing two compositions respect
aggregated valuations attribute;
b) introduced dominance relation comparing compositions based user
specified preferences established key properties. particular,
shown dominance relation strict partial order intra-attribute
preferences strict partial orders relative importance preferences interval
orders.
c) developed four algorithms identifying preferred composition(s)
respect user preferences. first three algorithms first compute
set feasible compositions (solutions) using functional composition algorithm
black box, proceed find preferred among (1) based
dominance relation (ComposeAndFilter ); (2) based preferred valuations respect important attribute(s) (WeaklyCompleteCompose
AttWeaklyCompleteCompose). fourth algorithm interleaves execution
functional composition algorithm produces set solutions iteratively
extending partial solutions ordering partial solutions respect user
preferences (InterleaveCompose).
d) established key properties algorithms. ComposeAndFilter
guaranteed return set non-dominated solutions; WeaklyCompleteCompose guaranteed return non-empty subset non-dominated solutions; AttWeaklyCompleteCompose guaranteed return least one non-dominated
solutions; InterleaveCompose guaranteed return (i) non-empty subset
non-dominated solutions dominance relation interval order; (ii)
entire set non-dominated solutions dominance relation weak order.
e) performed simulation experiments compare algorithms respect
(i) ratio preferred solutions produced actual set preferred
solutions, ratio preferred solutions produced entire set
solutions produced algorithm; (ii) running times function
search space overhead call functional composition algorithm;
(iii) number calls algorithm makes functional composition
algorithm course execution. results showed feasibility
algorithms composition problems involve 200 components.
f) analyzed results experiments obtain additional theoretical properties dominance relation function properties underlying
intra-attribute preference relations relative importance preference relation.
particular, obtained non-trivial results consequence analysis experimental results, known apriori, including conditions
dominance relation weak order. conjectures/results significant
give properties dominance relation directly function input
259

fiSanthanam, Basu & Honavar

user preferences. turn, also throw light soundness, weak-completeness
and/or completeness properties algorithms.
proposed techniques reasoning preferences non-functional attributes
independent language used express desired functionality composition, method used check whether composition C satisfies desired functionality, i.e., C |= . formalism algorithms may applicable broad range
domains including Web service composition (see Dustdar & Schreiner, 2005; Pathak, Basu,
& Honavar, 2008, surveys), planning (see Hendler, Tate, & Drummond, 1990; Baier &
McIlraith, 2008a), team formation (see Lappas, Liu, & Terzi, 2009; Donsbach, Tannenbaum,
Alliger, Mathieu, Salas, Goodwin, & Metcalf, 2009) indeed setting calls
choosing preferred solutions set candidate solutions, solution
made multiple components.
7.2 Discussion
following, discuss alternate choices one could make applying
formalism specific applications.
Aggregation Functions. previous work (Santhanam, Basu, & Honavar, 2008),
proposed use TCP-net representation ceteris paribus semantics (Brafman
et al., 2006) reasoning preferences addressing problem Web service composition. assumed intra-attribute preferences total orders; however,
assumption hold many practical settings involving qualitative preferences
non-functional attributes. paper, relaxed requirement, allowing
intra-attribute preferences strict partial orders.
paper demonstrated use summation (e.g., number credits
POS) worst frontier (e.g., areas study instructors) aggregation functions.
scenarios, might necessary consider ways aggregating valuations
components, example, using best frontier denoting best possible valuations
components (i.e., maximal valuations attribute Xi respect ).
aggregation function used formalism, provided preference relation
aggregated valuations strict partial order. Otherwise, choice aggregation
function preference relation compare aggregated valuations may impact
properties resulting dominance relation, result, may also affect soundness
completeness properties proposed algorithms.
aggregation functions demonstrated paper independent
components interact assembled, i.e., structure composition. However,
general, may necessary aggregation function take account structure and/or interactions valuations components composition.
example, evaluating reliability composition, one needs consider precise
structure composition. reliability composition Ci product relin

abilities components ( VWi (Reliability)) components arranged
i=1

series configuration (Rausand & Hyland, 2003). hand, set
components {Wi } arranged parallel configuration, reliability Ci computed
260

fiRepresenting Reasoning Qualitative Preferences

n

(1 VWi (Reliability))). general, might necessary introduce aggregaas (1
i=1

tion functions take consideration variety factors including structure,
function, well non-functional attributes composition.
Comparing Sets Aggregated Valuations. paper, presented preference relation
( ) compare sets valuations computed using worst frontier aggregation function
(Definition 8). preference relation requires given two sets valuations, every
element dominated set preferred least one elements dominating
set valuations. choices used well, care taken
properties chosen preference relation may affect properties dominance
( ) relation properties algorithms. However, long strict partial
order (irreflexive transitive), dominance relation continues remain strict partial
order (subject interval order), hence properties algorithms
hold. provides user wide range preference relations comparing sets
valuations choose (see Barbera et al., 2004, survey preferences sets).
Note Definition 8 ignore common elements comparing two sets
elements. However, settings may require preference relation compares
elements two sets common. settings, suitable irreflexive
transitive preference relation used, asymmetric part preference
relations developed Brewka et al. (2010) Bouveret et al. (2009). absence
transitivity, transitive closure relation may used compare sets elements,
done Brewka et al.
Dominance Properties. dominance relation ( ) adopted paper
strict partial order intra-attribute preferences arbitrary strict partial orders
relative importance interval order. would interesting explore alternative notions dominance preserve rationality choice, requiring different set
properties (e.g., satisfy negative-transitivity instead transitivity). would
also interest examine relationships alternative dominance relations. results comparing dominance relations proposed authors
(Brafman et al., 2006; Wilson, 2004b, 2004a) presented elsewhere (Santhanam,
Basu, & Honavar, 2010b, 2009).
Implementation. current implementation dominance testing respect
based iteratively searching attributes find witness. would interesting
compare methods dominance testing one proposed one
earlier works (Santhanam, Basu, & Honavar, 2010a) uses efficient model checking
techniques. would also like use multi-attribute preference formalisms
include conditional preferences framework compositional systems compare
performance resulting implementation current implementation.
7.3 Related Work
Techniques representing reasoning user preferences set alternatives
studied extensively areas decision theory, microeconomics, psychol261

fiSanthanam, Basu & Honavar

ogy, operations research, etc. seminal work von Neumann Morgenstern (1944)
models user preferences using utility functions map set possible alternatives
numeric values. recently, models representing reasoning quantitative preferences multiple attributes developed (Fishburn, 1970a; Keeney
& Raiffa, 1993; Bacchus & Grove, 1995; Boutilier, Bacchus, & Brafman, 2001).
models used address problems identifying preferred tuples
resulting database queries (Agrawal & Wimmers, 2000; Hristidis & Papakonstantinou, 2004; Borzsonyi, Kossmann, & Stocker, 2001), assembling preferred composite Web
services (Zeng, Benatallah, Dumas, Kalagnanam, & Sheng, 2003; Zeng, Benatallah, Ngu,
Dumas, Kalagnanam, & Chang, 2004; Yu & Lin, 2005; Berbner, Spahn, Repp, Heckmann,
& Steinmetz, 2006), composition problems.
However, many applications natural users express preferences
qualitative terms (Doyle & McGeachie, 2003; Doyle & Thomason, 1999; Dubois, Fargier,
Prade, & Perny, 2002) hence, growing interest AI formalisms
representing reasoning qualitative preferences (Brafman & Domshlak, 2009).
proceed place work context recent work representing
reasoning qualitative preferences.
7.3.1 TCP-nets
Notable among qualitative frameworks preferences preference networks (Boutilier
et al., 2004; Brafman et al., 2006) deal qualitative conditional preferences.
class preference networks, namely Tradeoff-enhanced Conditional Preference networks
(TCP-nets) (Brafman et al., 2006) closely related work, proceed
discuss framework departs adds existing TCP-net framework.
TCP-nets provide elegant compact graphical model represent qualitative
intra-attribute relative importance preferences set attributes. addition,
TCP-nets also model conditional preferences using dependencies among attributes.
TCP-nets allow us represent reason preferences general simple
objects (each described set attributes), focus work reason
preferences compositions simple objects (i.e., collection objects
satisfying certain functional properties). example, domain Web services,
problem identifying preferred Web services repository available ones
based non-functional attributes, namely Web service selection solved using
TCP-net formalism. hand, addition Web service selection,
formalism also address complicated problem identifying preferred
composite Web services collectively satisfy certain functional requirement, namely
Web service composition.
formalism based intra-attribute relative importance preferences
set attributes describing objects. result, graphical representation scheme
TCP-nets still used compactly encode intra-attribute relative importance
preferences users within formalism 14 .
14. setting, consider conditional preferences correspond edges denoting conditional
dependencies TCP-nets.

262

fiRepresenting Reasoning Qualitative Preferences

extended reasoning preferences single objects enable reasoning
preferences collections objects. have: (a) provided aggregation function computing valuation composition function valuations
components; (b) defined dominance relation comparing valuations compositions
established properties; (c) developed algorithms identifying subset
set preferred composition(s) respect dominance relation.
formalism departs TCP-nets interpretation intra-attribute
relative importance preferences objects: dominance relation TCP-net defined
partial order relation consistent given preferences attributes
objects, based ceteris-paribus semantics. introduce dominance relation
(see Definition 11) allows us reason preferences collections objects
terms sets valuations attributes objects make collection.
instance, worst frontier aggregation function returns set worst possible attribute
valuations among components.
dominance relation applied simpler setting collection
consists single object, aggregation function attribute reduces identity function, preference relation sets valuations attribute Xi
reduces intra-attribute preference . recently shown earlier works
(Santhanam et al., 2010b, 2009) general, TCP-nets restricted unconditional preferences, dominance relation (when collection consists single object)
dominance relation used TCP-nets incomparable; relative importance
restricted interval order, dominance relation general dominance relation used TCP-nets unconditional preferences. latter case,
dominance relation computable polynomial time, whereas known
polynomial time algorithms computing TCP-net dominance (Santhanam et al., 2010b,
2009).
7.3.2 Preferences Collections Objects
Several authors considered ways extend user preferences obtain ranking
collections objects (see Barbera et al., 2004, survey). works, preferences
specified individual objects set opposed preferences valuations
attributes objects. preferences objects turn used reason
preferences collections objects. scenario simulated
framework, introducing single attribute whose valuations correspond objects
domain.
DesJardins et al. (2005) considered problem finding subsets optimal
respect user specified quantitative preferences set attributes terms
desired depth, feature weight diversity attribute. contrast, framework
focuses qualitative preferences. setting, depth preferences map attribute
valuations relative desirability mapped qualitative intra-attribute preferences feature weights mapped relative importance. Diversity preferences
attributes refer spread (e.g., variance, range, etc.) component valuations respect corresponding attributes. would interesting explore whether suitable
263

fiSanthanam, Basu & Honavar

Property

Denoted

New Attribute

Attribute Domain

Party Affiliation
Views
Experience

P
V
E

XP
XV
XE

{Re, De}
{Li, Co, U l}
{Ex, In}

Table 13: Properties/Attributes describing senators
dominance relation defined simultaneously capture framework
user preferences respect depth, diversity feature weights.
recently, Binshtok et al. (2009) presented language specification
preferences sets objects. framework, addition intra-attribute relative
importance preferences attributes, allows users express preferences number
(||) elements set satisfy desired property . preference language
case allows statements Si : || REL n (number elements preferred set
property REL n), Sj : || REL || (number elements preferred
set property REL number elements preferred set property
), etc., REL one arithmetic operators >, <, =, , n integer.
addition, relative importance various preference statements
Si important Sj well external cardinality constraints
bound number elements preferred set.
formalism accommodate preference statements, representing preference statement Si new binary valued attribute compositional system.
example, preference statements Si : || n Sj : || || represented
formalism creating new binary attributes Xi Xj intra-attribute preferences
1 0 1 j 0 respectively. relative importance statements Si
important Sj directly mapped Xi Xj . external cardinality
constraints size preferred set encoded setting functional requirements, restrict feasible solutions satisfy cardinality
constraints.
Consider example discussed Binshtok et al. (2009), preferences senate
members described attributes: Party affiliation (Republican, Democrat ), Views (liberal, conservative, ultra conservative), Experience (experienced, inexperienced).
attributes domains listed Table 13. set preferences given by:
S1 : h|P = V = Co| 2i
S2 : h|E = Ex| 2i
S3 : h|V = Li| 1i
Note senate members (i.e., individual objects) described three attributes XP , XV , XE representing party affiliation, views experience respectively.
valuation function attributes defined obvious manner, e.g., senator
Wj republican, VWj (XP ) = Re. introduce three additional boolean attributes
264

fiRepresenting Reasoning Qualitative Preferences

X1 , X2 , X3 corresponding preference statements S1 , S2 , S3 respectively. valuation
function new attribute senator Wi defined follows.
(
1 , Wi |= S1 i.e., VWi (XP ) = VWi (XV ) = Co
VWi (X1 ) =
0 , otherwise
(
1 , Wi |= S2 i.e., VWi (XE ) = Ex
VWi (X2 ) =
0 , otherwise
(
1 , Wi |= S3 i.e., VWi (XV ) = Li
VWi (X3 ) =
0 , otherwise
valuation collection senators W1 W2 . . . Wn {1, 2, 3} is:
VW1 W2 ...Wn (Xi ) = (VW1 , VW2 , . . . VWn ) = VW1 (Xi ) + VW2 (Xi ) + + VWn (Xi )
Note aggregation function defined differs worst-frontier
based aggregation function adopted Definition 6. preference relation comparing
groups senators respect new attribute Xi defined based
preference statement Si . example, case X1 define 1
value 2 preferred value < 2, etc. defined aggregation function
comparison relation new attribute, dominance relation adopted
compare compositions (arbitrary subsets) respect attributes including
dominance relation used Binshtok et al. (2009).
contrast framework Binshtok et al., (2009) formalism focuses collections objects satisfy desired criteria, rather arbitrary subsets. provide
algorithms finding preferred compositions satisfy desired criteria.
7.3.3 Database Preference Queries
Several authors (Borzsonyi et al., 2001; Chomicki, 2003; Kiessling & Kostler, 2002; Kiessling,
2002) explored techniques incorporating user specified preferences result
sets relational database queries. instance, Chomickis framework (2003) allows user
preferences attributes relation expressed first order logic formulas. Suppose Sq set tuples match query q. attribute Xi , Sq ,
subset Sqi tuples preferred value(s) Xi identified. result
set query q given Sqi . similar framework expressing combining user preferences presented Kiessling (2002) Kiessling Kostler (2002).
Brafman Domshlak (2004) pointed semantic difficulties associated
approaches, considered alternative approach identifying preferred
result set based CP-net (Boutilier et al., 2004) dominance relation.
high computational complexity dominance testing CP-nets, Boutilier et al. proposed
efficient alternative based ordering operator orders tuples result
set way consistent user preferences. formalism used
database setting, similar spirit Brafman Domshlak, considering
265

fiSanthanam, Basu & Honavar

tuple Sq collection single object. differences semantics
CP-net dominance dominance relation discussed Section 7.3.1.
host algorithms also proposed computing non-dominated result
set response preference queries, especially efficient evaluation skyline queries
(Borzsonyi et al., 2001; Chomicki, 2003). skyline query yields non-dominated result
set database, dominance evaluated based notion pareto dominance
considers attributes equally important. proposed algorithms
computing skylines (see Jain, 2009, survey) applicable intraattribute preferences totally weakly ordered. algorithms handle
partially ordered attribute domains (Chan, Eng, & Tan, 2005; Sacharidis, Papadopoulos, &
Papadias, 2009; Jung, Han, Yeom, & Kang, 2010) rely creating maintaining indexes
attributes database, data structures specifically designed identify
skyline respect pareto dominance. algorithms may considered
particular problem instance involves large set components already stored
database indexed. However, obvious generalize arbitrary
notion dominance one presented here. hand, algorithms
finding non-dominated set applicable notion dominance, provided
user preferences dominance relation partial order.
7.3.4 Planning Preferences
classical planning problem consists finding sequence actions take system
initial state one states satisfies user specified goal. Preference
based planning refers problem finding plans preferred respect
set user preferences plans. preferences usually compactly expressed
terms preferences properties satisfied plans goal intermediate
states, actions, action sequences (i.e., temporal properties plans).
refer interested reader surveys Baier et al. (2008b) Bienvenu et al. (2011)
overview qualitative quantitative preference languages used preference based
AI planning, different algorithms computing preferred plans.
Preference based planning viewed problem finding preferred
composition compositional system, components correspond actions,
feasible compositions correspond states plans satisfy goal
planning problem. allowed set actions performed given
state planning problem encoded compositional system terms
set functional requirements (or constraints functionality). preferences
various actions taken given state plan captured
preferences components composition extended terms
properties attribute valuations. properties satisfied state plan
planning problem captured valuations attributes corresponding
composition compositional system. Based mapping actions performed
given state properties resulting state planning problem, aggregation
functions suitably defined compositional system. addition action
partial plan planning problem represented compositional system
extension partial composition new component, properties satisfied
266

fiRepresenting Reasoning Qualitative Preferences

resulting state planning problem correspond valuations attributes
extended composition determined aggregation functions. Finding
preferred plans involves finding preferred feasible compositions.
algorithms presented paper used find preferred plans
respect user specified preferences actions terms properties satisfied
resulting states, properties satisfied plans goal state. However,
planning problems involve preferences orderings states actions plan,
e.g., preferences properties hold entire sequence states plan
(Baier, Bacchus, & McIlraith, 2009; Bienvenu et al., 2011) cannot handled within
framework.

8. Acknowledgments
Aspects work supported part NSF grants CNS0709217, CCF0702758,
IIS0711356 CCF1143734. work Vasant Honavar supported National
Science Foundation, working Foundation. opinion, finding, conclusions
contained article authors necessarily reflect views
National Science Foundation.
grateful anonymous reviewers thorough review Dr. Ronen Brafman
many useful suggestions helped improve manuscript.

Appendix A. Proofs Propositions Theorems Section 4
Proposition 15 Xi : (C) 6= (C) (C) 6= .
Proof. Let Xi U (C). two possibilities: U (C) U
/
(C). U (C), nothing left prove.
Suppose U
/ (C). show V =
6 U V (C) (C).
/ (C) V (C) : V U.
U (C) U
Definitions 11 16, follows V (C) : V(Xi ) U(Xi ). Hence, Xi
cannot witness V U. two cases consider.
Case 1: U(Xi ) V(Xi ).
Let attribute Xj 6= Xi witness V U. Since Xi I, (Xi Xj ) (Xi
Xj ). therefore follows V(Xi ) U(Xi ), contradicts assumption
U(Xi ) V(Xi ). Hence, U(Xi ) 6 V(Xi ).
Case 2: U(Xi ) V(Xi ).
Let attribute Xj 6= Xi witness V U. Since Xi I, (Xi Xj ) (Xi
Xj ). Definition 11, V U V(Xi ) U(Xi ). assumption
U(Xi ) V(Xi ), must case V(Xi ) = U(Xi ), i.e., V (C). Thus, have:
U (C) \ (C) V (C) (C) : V U
completes proof.
267

(5)

fiSanthanam, Basu & Honavar

Theorem 4 [Soundness Weak Completeness Algorithm 2] Given set attributes
X , preference relations , Algorithm 2 generates set feasible compositions
(C) (C) 6= 6= .
Proof.
Soundness: proof proceeds contradiction. Suppose algorithm returns
solution U U
/ (C). U , necessary (by Line 5)
Xi : U (C) \ (C). Then, Equation (5) proof Proposition 15,
V (C) (C) : V U, means U
/ ( (C)). However,
contradicts Line 5 algorithm. Hence, (C), i.e., Algorithm 2 sound.
Weak Completeness: 6= , Line 5 executed algorithm least
Xi I. Definition 13, C 6= (C) 6= ( (C)) 6= 6=
. Hence, Algorithm 2 weakly complete Definition 15.
Proposition 16 = {Xt }Xk 6= Xt X : Xt Xk , (C) , i.e., Algorithm 2
complete.
Proof. proof proceeds contradiction. Let = {Xt } Xk 6= Xt X : Xt Xk ,
suppose V (C) \ (C). Since V
/ (C), Definition 13 must

case U (C) : U(Xt ) V(Xt ). However, U V Definition 11 thus
contradicting assumption V (C).
Proposition 17 |I| = 1, i.e., unique important attribute respect
, Algorithm 3 complete.
Proof. Let = {Xi }. know Proposition 14 . follows
(S) (S) set S. Hence, (C) (C) = , i.e., Algorithm 3
complete.
Proposition 18 [Termination Algorithm 4] Given finite repository components,
Algorithm 4 terminates finite number steps.
Proof. Given finite repository R components, algorithm f computes feasible
extensions partial feasible compositions15 , due fact Algorithm 4
re-visit partial feasible composition, number recursive calls finite.
Proposition 19 [Unsoundness Algorithm 4] Given functional composition algorithm
f user preferences set attributes X , Algorithm 4 guaranteed
generate set feasible compositions (C).
Proof. provide example wherein Algorithm 4 returns feasible composition
dominated feasible composition. Consider compositional system
single attribute X = {X1 }, domain {a1 , a2 , a3 , a4 }. Let intra-attribute preference user values partial order: a4 1 a1 a2 1 a3 (Figure 15).
Let R = {W1 , W2 , W3 , W4 } repository components compositional system
VWi (X1 ) = {ai }.
15. f terminates set feasible extensions guaranteed decidability .

268

fiRepresenting Reasoning Qualitative Preferences

a4

a2

a1

a3

Figure 15: Intra-attribute preference 1 attribute X1
Suppose three feasible compositions C satisfying user specified
functionality , namely C1 = W1 , C2 = W2 , C3 = W3 W4 . respective valuations
are: VC1 = h{a1 }i, VC2 = h{a2 }i VC3 = h{a3 , a4 }i. Clearly, (C) = {C2 , C3 },
VC3 VC1 (due fact {a3 , a4 } 1 {a1 }).


Iteration 0

Iteration 1

Iteration 2

W1

W2

W3

W3 W4

Algorithm terminates
W1 W2 solutions
W2 dominates W3
W1 incomparable W3
dominates W1 !

Figure 16: Execution Algorithm 4
suppose exists functional composition algorithm f produces
following sequence partial feasible compositions (Figure 16): {}, {W1 , W2 , W3 },
{W1 , W2 , W3 W4 }. According Line 13 Algorithm 4, algorithm terminate first invocation f , i.e., set {W1 , W2 , W3 } partial feasible compositions
produced f . first iteration, = {W1 , W2 }, VW2 VW3 ,
W1 W2 feasible compositions. results = {C1 , C2 } 6 (C).
Theorem 5 [Soundness Algorithm 4] interval order, given functional composition algorithm f user preferences { }, set attributes X ,
Algorithm 4 generates set feasible compositions (C).
Proof. Suppose contradiction, F feasible composition C
/
VC VF . C present list L upon termination algorithm, C
, algorithm terminates compositions (L)
feasible. implies algorithm terminate L containing C.
algorithm keeps track partial feasible compositions extended
L, without discarding termination. Therefore, existence
feasible composition C L time termination must imply
existence partial feasible composition B list (at time termination)
extended produce feasible composition C, i.e., B W1 W2 . . . Wn = C
B 6|= C |= .
B 6|= B
/ time termination, therefore E : VB .
transitive (by Proposition 12), since VC 6 VB (by Proposition 6), follows
VC 6 (otherwise, VC VB VC VB , contradiction). Hence, C must
269

fiSanthanam, Basu & Honavar

dominate composition E, say F time termination, i.e.,
VC VF . E, F , follows VF , turn implies 6 VC .
Therefore, F : VC VF , VF VC (see Figure 17).
VD



VF

VB

Figure 17: Dominance relationships violate interval order restriction
VB , VC VF , VF VC 6 VB , follows VC VB (because
VB VC would otherwise imply VF , contradiction). Finally, must case
that: VB 6 VF , since otherwise would contradict VF ; VF 6 VB , since
otherwise would contradict VC VB . Therefore, VB VF . Thus, possible
dominance relationships among compositions B, C, E, F follows (see Figure 17):
VB
VC VF
However, scenario ruled fact interval order. Hence
F , C C \ : VC 6 VF , i.e., (C).
Theorem 6 [Weak Completeness Algorithm 4] interval order, given
functional composition algorithm f user preferences { }, set attributes X ,
Algorithm 4 produces set feasible compositions (C) 6= (C) 6=
.
Proof. Theorem 5, (C) interval order. suffices
show (C) 6= 6= . algorithm terminates non-dominated set
compositions current list L, i.e., maximal elements L respect .
set maximal elements partial order set elements L empty
whenever L empty, set elements L turn empty whenever C
empty. Therefore, (C) 6= C 6= L =
6 6= required.
Theorem 7 [Completeness Algorithm 4] weak order, given functional composition algorithm f user preferences { }, set attributes X ,
Algorithm 4 generates set feasible compositions (C) .
Proof. suffices show feasible composition C (C) \ .
Suppose contradiction C (C), C
/ . means C
present list L upon termination algorithm (because otherwise C per
Lines 4, 6, 13 Algorithm 4). Hence, C must feasible extension partial feasible
composition B present L time termination B W1 W2
. . . Wk = C.
Proposition 6, VC 6 VB . weak order, (a) E
: VB ; (b) VC 6 VB VB VC . However, contradicts
assumption C (C).
270

fiRepresenting Reasoning Qualitative Preferences

References
Agrawal, R., & Wimmers, E. L. (2000). framework expressing combining preferences. SIGMOD Rec., 29 (2), 297306.
Bacchus, F., & Grove, A. J. (1995). Graphical models preference utility. Proceedings Eleventh Annual Conference Uncertainty Artificial Intelligence
(UAI-1995), pp. 310.
Baier, J. A., Bacchus, F., & McIlraith, S. A. (2009). heuristic search approach planning
temporally extended preferences. Artificial Intelligence, 173 (5-6), 593 618.
Baier, J. A., Fritz, C., Bienvenu, M., & McIlraith, S. (2008). Beyond classical planning:
Procedural control knowledge preferences state-of-the-art planners. Proceedings 23rd AAAI Conference Artificial Intelligence (AAAI), Nectar Track,
pp. 15091512, Chicago, Illinois, USA.
Baier, J. A., & McIlraith, S. A. (2008a). Planning preferences. AI Magazine, 29 (4),
2536.
Baier, J. A., & McIlraith, S. A. (2008b). Planning preferences. AI Magazine, 29 (4),
2536.
Barbera, S., Bossert, W., & Pattanaik, P. K. (2004). Ranking sets objects. Handbook
Utility Theory. Volume II Extensions, chap. 17, pp. 893977. Kluwer Academic
Publishers.
Berbner, R., Spahn, M., Repp, N., Heckmann, O., & Steinmetz, R. (2006). Heuristics qosaware web service composition. Proceedings IEEE International Conference
Web Services, pp. 7282.
Bienvenu, M., Fritz, C., & McIlraith, S. A. (2011). Specifying computing preferred
plans. Artificial Intelligence, 175 (7-8), 1308 1345.
Binshtok, M., Brafman, R. I., Domshlak, C., & Shimony, S. E. (2009). Generic preferences
subsets structured objects. Journal Artificial Intelligence Research, 34,
133164.
Borzsonyi, S., Kossmann, D., & Stocker, K. (2001). skyline operator. Proceedings
17th International Conference Data Engineering, pp. 421430, Washington,
DC, USA. IEEE Computer Society.
Boutilier, C., Brafman, R. I., Domshlak, C., Hoos, H. H., & Poole, D. (2004). CP-nets: tool
representing reasoning conditional ceteris paribus preference statements.
Journal Artificial Intelligence Research, 21, 135191.
Boutilier, C., Bacchus, F., & Brafman, R. I. (2001). UCP-networks: directed graphical representation conditional utilities. Proceedings 17th Conference
Uncertainty Artificial Intelligence (UAI-2001), pp. 5664.
Bouveret, S., Endriss, U., & Lang, J. (2009). Conditional importance networks: graphical
language representing ordinal, monotonic preferences sets goods. IJCAI,
pp. 6772.
271

fiSanthanam, Basu & Honavar

Brafman, R. I., Domshlak, C., & Shimony, S. E. (2006). graphical modeling preference
importance. Journal Artificial Intelligence Research, 25, 389424.
Brafman, R. I., & Domshlak, C. (2004). Database preference queries revisited. Tech. rep.
1934, Department Computing Information Science, Cornell University.
Brafman, R. I., & Domshlak, C. (2009). Preference handling - introductory tutorial. AI
magazine, 30 (1).
Brewka, G., Truszczynski, M., & Woltran, S. (2010). Representing preferences among sets.
AAAI. AAAI Press.
Chan, C.-Y., Eng, P.-K., & Tan, K.-L. (2005). Stratified computation skylines
partially-ordered domains. SIGMOD 05: Proceedings 2005 ACM SIGMOD
international conference Management data, pp. 203214, New York, NY, USA.
ACM.
Chomicki, J. (2003). Preference formulas relational queries. ACM Trans. Database Syst.,
28 (4), 427466.
Daskalakis, C., Karp, R. M., Mossel, E., Riesenfeld, S., & Verbin, E. (2009). Sorting
selection posets. SODA, pp. 392401.
desJardins, M., & Wagstaff, K. (2005). DD-PREF: language expressing preferences
sets. AAAI, pp. 620626.
Donsbach, J. S., Tannenbaum, S. I., Alliger, G. M., Mathieu, J. E., Salas, E., Goodwin,
G. F., & Metcalf, K. A. (2009). Team composition optimization: team optimal
profile system (tops). Tech. rep. ARI TR 1249, U.S. Army Research Institute
Behavioral Social Sciences.
Doyle, J., & McGeachie, M. (2003). Exercising qualitative control autonomous adaptive
survivable systems. Self-Adaptive Software: Applications, chap. 8. Springer Berlin
Heidelberg.
Doyle, J., & Thomason, R. H. (1999). Background qualitative decision theory. AI
magazine, 20, 5568.
Dubois, D., Fargier, H., Prade, H., & Perny, P. (2002). Qualitative decision theory:
savages axioms nonmonotonic reasoning. Journal ACM, 49 (4), 455495.
Dustdar, S., & Schreiner, W. (2005). survey web services composition. International
Journal Web Grid Services, 1 (1), 120.
Fishburn, P. (1970a). Utility Theory Decision Making. John Wiley Sons.
Fishburn, P. (1970b). Utility theory inexact preferences degrees preference.
Synthese, 21, 204221. 10.1007/BF00413546.
Fishburn, P. (1985). Interval Orders Interval Graphs. J. Wiley, New York.
French, S. (1986). Decision theory: introduction mathematics rationality..
Hendler, J., Tate, A., & Drummond, M. (1990). AI planning: systems techniques. AI
Mag., 11 (2), 6177.
Hristidis, V., & Papakonstantinou, Y. (2004). Algorithms applications answering
ranked queries using ranked views. VLDB Journal, 13 (1), 4970.
272

fiRepresenting Reasoning Qualitative Preferences

Jain, R. (2009). Handling worst case skyline. Masters thesis, York University, Department
Computer Science Engineering.
Jung, H., Han, H., Yeom, H. Y., & Kang, S. (2010). fast progressive algorithm
skyline queries totally- partially-ordered domains. Journal Systems
Software, 83 (3), 429 445.
Keeney, R. L., & Raiffa, H. (1993). Decisions multiple objectives: Preferences
value trade-offs..
Kiessling, W. (2002). Foundations preferences database systems. VLDB 02:
Proceedings 28th international conference Large Data Bases, pp. 311
322. VLDB Endowment.
Kiessling, W., & Kostler, G. (2002). Preference sql: design, implementation, experiences.
VLDB 02: Proceedings 28th international conference Large Data
Bases, pp. 9901001. VLDB Endowment.
Lago, U. D., Pistore, M., & Traverso, P. (2002). Planning language extended
goals. Eighteenth national conference Artificial intelligence, pp. 447454, Menlo
Park, CA, USA. American Association Artificial Intelligence.
Lappas, T., Liu, K., & Terzi, E. (2009). Finding team experts social networks.
Proceedings 15th ACM SIGKDD international conference Knowledge
discovery data mining (KDD), pp. 467476, New York, NY, USA. ACM.
Mas-Colell, A., Whinston, M. D., & Green, J. R. (1995). Microeconomic Theory. Oxford
University Press.
Passerone, R., de Alfaro, L., Henzinger, T. A., & Sangiovanni-Vincentelli, A. L. (2002). Convertibility verification converter synthesis: two faces coin. ICCAD
02: Proceedings 2002 IEEE/ACM international conference Computer-aided
design, pp. 132139, New York, NY, USA. ACM.
Pathak, J., Basu, S., & Honavar, V. (2008). Assembling composite web services autonomous components. Emerging Artificial Intelligence Applications Computer
Engineering, Maglogiannis, I., Karpouzis, K., Soldatos, J. (ed). IOS Press.
press.
Rausand, M., & Hyland, A. (2003). System Reliability Theory: Models, Statistical Methods
Applications Second Edition. Wiley-Interscience.
Regenwetter, M., Dana, J., & Davis-Stober, C. P. (2011). Transitivity preferences. Psychological Review, 118 (1), 42 56.
Sacharidis, D., Papadopoulos, S., & Papadias, D. (2009). Topologically sorted skylines
partially ordered domains. ICDE 09: Proceedings 2009 IEEE International
Conference Data Engineering, pp. 10721083, Washington, DC, USA. IEEE Computer Society.
Santhanam, G. R., Basu, S., & Honavar, V. (2008). TCP-compose - TCP-net based
algorithm efficient composition web services using qualitative preferences.
Bouguettaya, A., Krger, I., & Margaria, T. (Eds.), Procceedings Sixth International Conference Service-Oriented Computing, Vol. 5364 Lecture Notes
Computer Science, pp. 453467.
273

fiSanthanam, Basu & Honavar

Santhanam, G. R., Basu, S., & Honavar, V. (2009). dominance relation unconditional
multi-attribute preferences. Tech. rep. 09-24, Department Computer Science, Iowa
State University.
Santhanam, G. R., Basu, S., & Honavar, V. (2010a). Dominance testing via model checking. Proceedings Twenty-Fourth AAAI Conference Artificial Intelligence
(AAAI), pp. 357362. AAAI Press.
Santhanam, G. R., Basu, S., & Honavar, V. (2010b). Efficient dominance testing unconditional preferences. Proceedings Twelfth International Conference
Principles Knowledge Representation Reasoning (KR), pp. 590592. AAAI
Press.
Smythe, R. T., & Mahmoud, H. M. (1995). survey recursive trees. Theor Prob Math
Stat, pp. 127.
Traverso, P., & Pistore, M. (2004). Automated composition semantic web services
executable processes. Proceedings ISWC 2004, pp. 380394. Springer-Verlag.
Tversky, A. (1969). Intransitivity preferences. Psychological Review, 76, 3148.
von Neumann, J., & Morgenstern, O. (1944). Theory Games Economic Behavior.
Princeton University Press.
Wilson, N. (2004a). Consistency constrained optimisation conditional preferences.
ECAI, pp. 888894.
Wilson, N. (2004b). Extending CP-nets stronger conditional preference statements.
AAAI, pp. 735741.
Yu, T., & Lin, K. J. (2005). Service selection algorithms composing complex services
multiple qos constraints. Service-Oriented Computing - ICSOC 2005, pp.
130143. Springer Berlin / Heidelberg.
Zeng, L., Benatallah, B., Dumas, M., Kalagnanam, J., & Sheng, Q. Z. (2003). Quality
driven web services composition. Proceedings 12th International Conference
World Wide Web, pp. 411421. ACM.
Zeng, L., Benatallah, B., Ngu, A. H. H., Dumas, M., Kalagnanam, J., & Chang, H. (2004).
Qos-aware middleware web services composition. IEEE Transactions Software
Engineering, 30 (5), 311327.

274

fiJournal Artificial Intelligence Research 42 (2011) 487-527

Submitted 7/11; published 11/11

Unfounded Sets Well-Founded Semantics
Answer Set Programs Aggregates
Mario Alviano
Francesco Calimeri
Wolfgang Faber
Nicola Leone
Simona Perri

alviano@mat.unical.it
calimeri@mat.unical.it
faber@mat.unical.it
leone@mat.unical.it
perri@mat.unical.it

Department Mathematics
University Calabria
I-87030 Rende (CS), Italy

Abstract
Logic programs aggregates (LPA ) one major linguistic extensions
Logic Programming (LP). work, propose generalization notions unfounded set well-founded semantics programs monotone antimonotone
aggregates (LPA
m,a programs). particular, present new notion unfounded set

LPm,a programs, sound generalization original definition standard
(aggregate-free) LP. basis, define well-founded operator LPA
m,a programs,
fixpoint called well-founded model (or well-founded semantics) LPA
m,a
programs. important properties unfounded sets well-founded semantics standard LP retained generalization, notably existence uniqueness
well-founded model, together strong relationship answer set semantics LPA
m,a programs. show one D-well-founded semantics, defined
Pelov, Denecker, Bruynooghe broader class aggregates using approximating
operators, coincides well-founded model defined work LPA
m,a programs. also discuss complexity issues, importantly give formal proof
tractable computation well-founded model LPA
m,a programs. Moreover, prove

general LP programs, may contain aggregates neither monotone
antimonotone, deciding satisfaction aggregate expressions respect partial
interpretations coNP-complete. consequence, well-founded semantics general
LPA programs allows tractable computation unlikely exist, justifies
restriction LPA
m,a programs. Finally, present prototype system extending DLV,
supports well-founded semantics LPA
m,a programs, time writing
implemented system so. Experiments prototype show significant
computational advantages aggregate constructs equivalent aggregate-free encodings.

1. Introduction
use logical formulas basis knowledge representation language proposed 50 years ago seminal works McCarthy (1959), McCarthy
Hayes (1969). However, soon realized monotonic nature classical logic
(the addition new knowledge may increase set consequences theory
classical logic) always suited model commonsense reasoning, sometimes
intrinsically nonmonotonic (Minsky, 1975). alternative, suggested represent
c
2011
AI Access Foundation. rights reserved.

fiAlviano, Calimeri, Faber, Leone, & Perri

commonsense reasoning using logical languages nonmonotonic consequence relations,
better simulate forms human reasoning, allowing new knowledge invalidate previous conclusions. observation opened new important
research field, called nonmonotonic reasoning, led definition investigation
new logical formalisms, called nonmonotonic logics. popular nonmonotonic logics
circumscription (McCarthy, 1980, 1986), default logic (Reiter, 1980), nonmonotonic
modal logics (McDermott & Doyle, 1980; McDermott, 1982; Moore, 1985). Later on,
cross fertilizations field nonmonotonic logics logic programming,
another nonmonotonic language, called Declarative Logic Programming (LP) emerged,
incorporating nonmonotonic negation operator denoted not. Declarative Logic Programming gained popularity last years, today widely used formalism
knowledge representation reasoning, applications various scientific disciplines
even industry (Ricca, Alviano, Dimasi, Grasso, Ielpa, Iiritano, Manna, & Leone,
2010; Ricca, Grasso, Alviano, Manna, Lio, Iiritano, & Leone, 2011; Manna, Ricca, & Terracina, 2011; Manna, Ruffolo, Oro, Alviano, & Leone, 2011). LP problems solved
means declarative specifications requirements achieved. ad-hoc algorithms
required.
Several semantics LP proposed literature, take care
inherent non-monotonicity operator programs. well-founded
semantics (Van Gelder, Ross, & Schlipf, 1991) one prominent among them.
associates three-valued model, well-founded model, every logic program. Originally,
well-founded semantics defined normal logic programs, is, standard
logic programs nonmonotonic negation. distinguishing property well-founded
semantics existence uniqueness well-founded model guaranteed
logic programs. Moreover, well-founded semantics computable polynomial time
respect input program propositional case.
Even LP declarative programming language, standard LP allow
representing properties sets data natural way, relevant aspect many application domains. addressing insufficiency, several extensions LP
proposed, relevant introduction aggregate functions (LPA ;
Kemp & Stuckey, 1991; Denecker, Pelov, & Bruynooghe, 2001; Dix & Osorio, 1997; Gelfond, 2002; Simons, Niemela, & Soininen, 2002; DellArmi, Faber, Ielpa, Leone, & Pfeifer,
2003; Pelov & Truszczynski, 2004; Pelov, Denecker, & Bruynooghe, 2004). Among them,
recursive definitions involving aggregate functions (i.e., aggregation aggregated
data depend evaluation aggregate itself) particularly interesting,
definition semantics straightforward (Pelov, 2004; Faber, Leone, & Pfeifer,
2004; Son & Pontelli, 2007; Liu, Pontelli, Son, & Truszczynski, 2010). Note similar
construct, referred abstract constraint, introduced literature (Marek
& Truszczynski, 2004; Liu & Truszczynski, 2006; Son, Pontelli, & Tu, 2007; Truszczynski,
2010; Brewka, 1996). results paper carry also LP abstract
constraints, well-founded semantics knowledge defined far.
paper focus fragment LPA allowing monotone antimonotone

aggregate expressions (LPA
m,a ; Calimeri, Faber, Leone, & Perri, 2005). LPm,a programs
many interesting properties. Among them, highlight similarities monotone
aggregate expressions positive standard literals, antimonotone aggregate
488

fiUnfounded Sets Well-Founded Semantics ASP Programs Aggregates

expressions negative standard literals. particular, take advantage aspect
defining unfounded sets and, based definition, well-founded semantics

LPA
m,a fragment. well-founded semantics LPm,a programs obtained way
retains many desirable properties original well-founded semantics LP,
extends: LPA
m,a program unique well-founded model exists, polynomialtime computable, approximates programs answer sets, coincides answer
set stratified LPA
m,a programs.
Actually turns well-founded semantics thus obtained coincides (on LPA
m,a
programs) well-founded semantics proposed Pelov, Denecker, Bruynooghe
(2007). Pelov et al. define several semantics logic programs aggregates using various approximating immediate consequence operators. notion logic program adopted
Pelov et al. general one considered present work, allowing
arbitrary first-order formulas bodies, unrestricted aggregates, non-Herbrand interpretations. equivalence two semantics, properties proved
Pelov et al. carry work well. applies results well-founded
model total stratified programs (Theorem 9), well-founded model contained
answer set (Theorem 16), well-founded model computable polynomial time (Theorem 21). However, framework introduced article considerably
different one developed Pelov et al., allows giving alternative proofs
result. Vice versa, article contains many new results, carry
framework Pelov et al. LPA
m,a programs. particular, provides alternative
definition well-founded semantics, characterization answer sets means unfounded sets, implemented system computing well-founded semantics,
time writing one kind.
would like point extensions LPA
m,a programs come
mind, definition unfounded sets would considerably changed (see instance definition provided Faber, 2005), moreover main desired properties
well-founded semantics would longer guaranteed. instance, obvious extension, including aggregate expressions neither monotone antimonotone
would likely computable polynomial time: fact, evaluation
aggregate expressions respect partial interpretations tractable monotone
antimonotone aggregates, task coNP-complete general aggregate expressions. Also, instance allowing aggregates rule heads would necessarily complicate
definition unfounded sets, would guarantee existence well-founded model
every program, would likely guarantee polynomial-time computability.
concepts defined paper directly give rise computation method
well-founded semantics LPA
m,a programs. implemented method,
best knowledgethe first kind. conducted experiments
system LPA
m,a encodings particular problem domain, compared
encodings using aggregates. latter encodings tested system
prototype derived XSB, state-of-the-art system computing
well-founded model. experiments show clear advantage LPA
m,a encodings
run prototype system.
Summarizing, main contributions paper follows.
489

fiAlviano, Calimeri, Faber, Leone, & Perri

define new notion unfounded set logic programs monotone
antimonotone aggregates (LPA
m,a programs). notion sound generalization
concept unfounded set previously given standard logic programs. show
definition coincides original definition unfounded sets (Van Gelder
et al., 1991) class normal (aggregate-free) programs, shares
distinguishing properties (such existence greatest unfounded set).
define well-founded operator WP logic programs aggregates, extends classical well-founded operator (Van Gelder et al., 1991). total fixpoints
WP exactly answer sets P, least fixpoint WP () contained
intersection answer sets. also show operator equivalent
operator defined Pelov et al. (2007).
provide declarative characterization answer sets terms unfounded sets.
particular, prove answer sets LPA
m,a program precisely
unfounded-free models.
show reasoning aggregates without restrictions may easily increase
complexity computation. particular, prove deciding truth
falsity aggregate expression respect partial interpretation
coNP-complete problem. However, problem intractable general,
polynomial-time solvable monotone antimonotone aggregates.
analyze complexity well-founded semantics, confirming extending
results work Pelov et al. (2007). Importantly, turns WP ()
polynomial-time computable propositional LPA
m,a programs. non-ground
programs, data-complexity remains polynomial, program complexity
rises P EXPTIME, aggregate-free programs.
present prototype system supporting well-founded semantics defined
article. prototype, obtained extending DLV, first system implementing
well-founded semantics (unrestricted) LPA
m,a programs.
report experimental results implemented prototype. specifically,
define Attacks problem, problem inspired classic Win-Lose problem
often considered context well-founded semantics standard logic programs. compare execution times prototype LPA
m,a encoding
equivalent LP encodings. particular, one tested LP encodings obtained means compilation aggregates standard LP, also briefly
presented paper. obtained results evidence computational advantages
problem encoding using aggregate expressions without them.
presentation organized follows. Section 2 present basics
LPA language and, particular, introduce LPA
m,a fragment. fragment,
define unfounded sets well-founded semantics Section 3. Relationships
well-founded semantics answer set semantics discussed Section 4. complexity
analysis well-founded semantics LPA
m,a programs reported Section 5.
490

fiUnfounded Sets Well-Founded Semantics ASP Programs Aggregates

Section 6 discuss implemented prototype system experimentation. Finally,
related work discussed Section 7, Section 8 draw conclusions.

2. LPA Language
Syntax, instantiation, interpretations models LPA programs introduced
section. Moreover, introduce LPA
m,a fragment language, define
well-founded semantics Section 3. additional background standard LP, refer
literature (Gelfond & Lifschitz, 1991; Baral, 2003).
2.1 Syntax
assume sets variables, constants, predicates given. Similar Prolog,
assume variables strings starting uppercase letters constants nonnegative integers strings starting lowercase letters. Predicates strings starting
lowercase letters. arity (non-negative integer) associated predicate.
Moreover, language allows using built-in predicates (i.e., predicates fixed
meaning) common arithmetic operations positive integers (i.e., =, , , +, ,
etc.; written infix notation), interpreted standard mathematical way.
2.1.1 Standard Atom
term either variable constant. standard atom expression p(t1 , . . . , tn ),
p predicate arity n t1 , . . . , tn terms. atom p(t1 , . . . , tn ) ground
t1 , . . . , tn constants.
2.1.2 Set Term
set term either symbolic set ground set. symbolic set pair {Terms : Conj },
Terms list terms (variables constants) Conj conjunction standard
atoms, is, Conj form a1 , . . . , ak ai (1 k) standard
atom. Intuitively, set term {X : a(X, c), p(X)} stands set X-values making
conjunction a(X, c), p(X) true, i.e., {X | a(X, c) p(X) true}. ground set set
pairs form hconsts : conj i, consts list constants conj conjunction
ground standard atoms.
2.1.3 Aggregate Function
aggregate function form f (S), set term, f aggregate
function symbol. Intuitively, aggregate function thought (possibly partial)
function mapping multisets constants constant. Throughout remainder
paper, adopt notation DLV system (Leone, Pfeifer, Faber, Eiter, Gottlob,
Perri, & Scarcello, 2006) representing aggregates.
Example 1 common aggregate functions listed below:
#min, minimal term, undefined empty set;
#max, maximal term, undefined empty set;
491

fiAlviano, Calimeri, Faber, Leone, & Perri

#count, number terms;
#sum, sum integers;
#times, product integers;
#avg, average integers, undefined empty set.
2.1.4 Aggregate Atom
aggregate atom structure form f (S) , f (S) aggregate function,
{<, , >, } comparison operator, term (variable constant).
aggregate atom f (S) ground constant ground set.
Example 2 following aggregate atoms DLV notation:
#max{Z : r(Z), a(Z, V )} >
#max{h2 : r(2), a(2, m)i, h2 : r(2), a(2, n)i} > 1

2.1.5 Literal
literal either (i) standard atom, (ii) standard atom preceded negation
failure symbol not, (iii) aggregate atom. Two standard literals complementary
form a, standard atom a. standard literal ,
denote . complement . Abusing notation, L set standard literals,
.L denotes set {. | L}.
2.1.6 Program
rule r construct form
: 1 , . . . , .

standard atom, 1 , . . . , literals, 0. atom referred
head r, conjunction 1 , . . . , body r. body empty
(m = 0), rule called fact. denote head atom H(r) = a, set
body literals B(r) = {1 , . . . , }. Moreover, set positive standard body literals
denoted B + (r), set negative standard body literals B (r), set
aggregate body literals B (r). rule r ground H(r) literals B(r)
ground. program set rules. program ground rules ground.
2.1.7 Safety
local variable rule r variable appearing solely sets terms r; variable r
local global. rule r safe following conditions hold: (i)
global variable X r positive standard literal B + (r) X appears
; (ii) local variable r appearing symbolic set {Terms : Conj } also appears
Conj . Note condition (i) standard safety condition adopted LP guarantee
variables range restricted (Ullman, 1989), condition (ii) specific
aggregates. program safe rules safe.
492

fiUnfounded Sets Well-Founded Semantics ASP Programs Aggregates

Example 3 Consider following rules:
p(X) : q(X, Y, V ), #max{Z : r(Z), a(Z, V )} > Y.
p(X) : q(X, Y, V ), #sum{Z : r(X), a(X, S)} > Y.
p(X) : q(X, Y, V ), #min{Z : r(Z), a(Z, V )} > T.

first rule safe, second local variable Z violates condition
(ii). Also third rule safe, since global variable violates condition (i).
2.2 Program Instantiation, Interpretations Models
Section 3 define well-founded semantics relevant class LPA programs.
well-founded semantics defined ground programs, programs variables
associated equivalent ground programs. section introduce preliminary
notions program instantiation, interpretations models.
2.2.1 Universe Base
Given LPA program P, universe P, denoted , set constants
appearing P. base P, denoted BP , set standard atoms constructible
predicates P constants .
2.2.2 Instantiation
substitution mapping set variables . Given substitution
LPA object obj (rule, set, etc.), denote obj object obtained replacing
variable X obj (X). substitution set global variables rule
r (to ) global substitution r; substitution set local variables
set term (to ) local substitution S. Given set term without global variables
= {Terms : Conj }, instantiation following ground set:
inst(S) = {hTerms : Conj | local substitution S}.
ground instance rule r obtained two steps: First, global substitution r
applied, every set term r replaced instantiation inst(S).
instantiation Ground(P) program P set instances rules P.
Example 4 Consider following program P1 :
q(1) : p(2, 2).
p(2, 2) : q(1).

q(2) : p(2, 1).
p(2, 1) : q(2).

t(X) : q(X), #sum{Y : p(X, )} > 1.

instantiation Ground(P1 ) P1 following program:
q(1) : p(2, 2).
p(2, 2) : q(1).

q(2) : p(2, 1).
p(2, 1) : q(2).

t(1) : q(1), #sum{h1 : p(1, 1)i, h2 : p(1, 2)i} > 1.
t(2) : q(2), #sum{h1 : p(2, 1)i, h2 : p(2, 2)i} > 1.

2.2.3 Aggregate Function Domain
X

Given set X, let 2 denote set multisets elements X. domain
aggregate function set multisets function defined. Without loss
generality, assume aggregate functions map Z (the set integers).
493

fiAlviano, Calimeri, Faber, Leone, & Perri

Example 5 Let us look common domains aggregate functions Example 1:
U
Z
#count defined 2 ,P #sum #times 2 , #min, #max #avg
Z
2 \ {}.
2.2.4 Interpretation
interpretation LPA program P consistent set standard ground literals,
is, BP .BP .I = . denote + set standard
positive negative literals occurring I, respectively. interpretation total
+ .I = BP , otherwise partial. set interpretations P denoted
IP . Given interpretation standard literal , evaluation respect
defined follows: (i) I, true respect I; (ii) . I,
false respect I; (iii) otherwise, 6 . 6 I, undefined
respect I. interpretation also provides meaning set terms, aggregate functions
aggregate literals, namely multiset, value, truth value, respectively.
first consider total interpretation I. evaluation I(S) set term respect
multiset I(S) defined follows: Let = {ht1 , ..., tn | ht1 , ..., tn : Conj
atoms Conj true respect I}; I(S) multiset obtained
projection tuples SI first constant, is, I(S) = [t1 | ht1 , ..., tn ].
evaluation I(f (S)) aggregate function f (S) respect result
application f I(S).1 multiset I(S) domain f , I(f (S)) =
(where fixed symbol occurring P). ground aggregate atom = f (S) k
true respect I(f (S)) 6= I(f (S)) k hold; otherwise, false.
Example 6 Let I1 total interpretation I1+ = {f (1), g(1, 2), g(1, 3), g(1, 4), g(2, 4),
h(2), h(3), h(4)}. Assuming variables local, check that:
#count{X : g(X, )} > 2 false; indeed, S1 corresponding ground set,
S1I1 = {h1i, h2i}, I1 (S1 ) = [1, 2] #count([1, 2]) = 2.
#count{X, : g(X, )} > 2 true; indeed, S2 corresponding ground set,
S2I1 = {h1, 2i, h1, 3i, h1, 4i, h2, 4i}, I1 (S2 ) = [1, 1, 1, 2] #count([1, 1, 1, 2]) = 4.
#times{Y : f (X), g(X, )} <= 24 true; indeed, S3 corresponding ground
set, S3I1 = {h2i, h3i, h4i}, I1 (S3 ) = [2, 3, 4] #times([2, 3, 4]) = 24.
#sum{X : g(X, ), h(Y )} <= 3 true; indeed, S4 corresponding ground set,
S4I1 = {h1i, h2i}, I1 (S4 ) = [1, 2] #sum([1, 2]) = 3.
#sum{X, : g(X, ), h(Y )} <= 3 false; indeed, S5 corresponding ground
set, S5I1 = {h1, 2i, h1, 3i, h1, 4i, h2, 4i}, I1 (S5 ) = [1, 1, 1, 2] #sum([1, 1, 1, 2]) =
5.;
#min{X : f (X), h(X)} >= 2 false; indeed, S6 corresponding ground set,
S6I1 = , I1 (S6 ) = , I1 (#min()) = (we recall domain
#min).
1. paper, consider aggregate functions value polynomial-time computable
respect input multiset.

494

fiUnfounded Sets Well-Founded Semantics ASP Programs Aggregates

consider partial interpretation refer interpretation J
J extension I. ground aggregate atom true (resp. false) respect
total interpretation J extending I, true (resp. false) respect I;
otherwise, undefined.
Example 7 Let S7 ground set literal 1 = #sum{h1 : p(2, 1)i, h2 : p(2, 2)i} >
1, consider partial interpretation I2 = {p(2, 2)}. Since total interpretation
extending I2 contains either p(2, 1) p(2, 1), either I2 (S7 ) = [2] I2 (S7 ) =
[1, 2]. Thus, application #sum yields either 2 > 1 3 > 1, thus 1 true
respect I2 .
Remark 1 Observe definitions interpretation truth values preserve knowledge monotonicity: interpretation J extends (i.e., J), literal true
respect true respect J, literal false respect
false respect J well.
2.2.5 Model
Given interpretation I, rule r satisfied respect least one following
conditions satisfied: (i) H(r) true respect I; (ii) literal B(r) false
respect I; (iii) H(r) literal B(r) undefined respect I.
interpretation model LPA program P rules r Ground(P)
satisfied respect .
Example 8 Consider program P1 Example 4. Let I3 total interpretation
P1 I3+ = {q(2), p(2, 2), t(2)}. I3 minimal model P1 .
2.3 LPA
m,a Language

definition LPA
m,a programs, fragment LP analyzed paper, based
following notion monotonicity literals.

2.3.1 Monotonicity
Given two interpretations J, say J + J + J .
ground literal monotone if, interpretations I, J J, that:
(i) true respect implies true respect J, (ii) false respect
J implies false respect I. ground literal antimonotone opposite
happens, is, interpretations I, J J, that: (i) false
respect implies false respect J, (ii) true respect J implies
true respect I. ground literal nonmonotone neither monotone
antimonotone. Note positive standard literals monotone, whereas negative standard
literals antimonotone. Aggregate literals, instead, may monotone, antimonotone
nonmonotone. examples shown complete picture
common aggregate functions summarized Table 1.
Example 9 Let us assume universe numerical constants non-negative
integers. ground instances following aggregate literals thus monotone:
495

fiAlviano, Calimeri, Faber, Leone, & Perri

Table 1: Character common aggregate literals.
Function Domain Operator
Character
#count

>,
monotone
<,
antimonotone
#sum
N
>,
monotone
<,
antimonotone
Z
<, , >, nonmonotone
#times
N+
>,
monotone
<,
antimonotone
N, Z
<, , >, nonmonotone
#min

>,
nonmonotone
<,
monotone
#max

>,
monotone
<,
nonmonotone
#avg
N, Z
<, , >, nonmonotone


Antimonotone context guarantees set term aggregate never becomes empty.

#sum{Z : r(Z)} 10.

#count{Z : r(Z)} > 1;

Ground instances following literals instead antimonotone:
#sum{Z : r(Z)} 10.

#count{Z : r(Z)} < 1;

2.3.2 LPA
m,a Programs

Let LPA
m,a denote fragment LP allowing monotone antimonotone literals.
LPA
m,a rule r, set monotone antimonotone body literals denoted

B (r) B (r), respectively. LPA
m,a program P stratified exists function
|| ||, called level mapping, set predicates P ordinals,
pair a, b predicates, occurring head body rule r P, respectively: (i) b
appears antimonotone literal, ||b|| < ||a||, (ii) otherwise ||b|| ||a||. Intuitively,
stratification forbids recursion antimonotone literals (for aggregate-free programs
definition coincides common notion stratification respect negation).

Example 10 Consider LPA
m,a program consisting following rules:
q(X) : p(X), #count{Y : a(Y, X), b(X)} 2.
p(X) : q(X), b(X).

assume predicates b defined facts, include
explicitly. program stratified, level mapping ||a|| = ||b|| = 1, ||p|| = ||q|| = 2
satisfies required conditions. add rule b(X) : p(X), levelmapping exists, program becomes unstratified.
would like note definition LPA
m,a could enlarged, form
given classifies literals independently context (that is, program)
496

fiUnfounded Sets Well-Founded Semantics ASP Programs Aggregates

occur. aggregates nonmonotone definition given above, might
manifest nonmonotone effects given context: one limits interpretations
considered violate program literal occurs,
interpretation pairs violate monotonicity antimonotonicity may longer
present. fact, one could refine definition way (considering pairs
non-violating interpretations given context program). modified definition would
enlarge class LPA
m,a programs, retaining results paper,
simplicity exposition refrain formally. example, aggregate
atom involving #max < operator formally LPA
m,a , one considers
occurrences program non-violating interpretation I(S) =
(where set term aggregate), aggregate behaves antimonotone
way particular program. noted cases footnote Table 1.

3. Unfounded Sets Well-Founded Semantics
section introduce new notion unfounded set LPA
m,a programs,
extends original definition aggregate-free programs introduced Van Gelder et al.
(1991). Unfounded sets used extending well-founded semantics, originally
defined aggregate-free programs Van Gelder et al., LPA
m,a programs. also
highlight number desirable properties semantics. following deal
ground programs, usually denote P ground program. also use
notation L .L set (L \ L ) .L , L L sets standard ground
literals.
Definition 1 (Unfounded Set) set X BP ground atoms unfounded set
LPA
m,a program P respect (partial) interpretation if, rule
r P H(r) X , least one following conditions holds:
(1) (antimonotone) literal B (r) false respect I,
(2) (monotone) literal B (r) false respect .X .
Intuitively, rule head atom belonging unfounded set X already
satisfied respect (in case condition (1) holds), satisfiable taking false
atoms unfounded set (in case condition (2) holds). Note that, according
definition above, empty set unfounded set respect every program
interpretation.
Example 11 Consider interpretation I4 = {a(1), a(2), a(3)} following program
P2 :
r1 :
r2 :
r3 :

a(1) : #count{h1 : a(1)i, h2 : a(2)i, h3 : a(3)i} > 2.
a(2).
a(3) : #count{h1 : a(1)i, h2 : a(2)i, h3 : a(3)i} > 2.

X1 = {a(1)} unfounded set P2 respect I4 , since condition (2)
Definition 1 holds r1 (the rule head a(1)). Indeed, (monotone) literal
appearing B (r1 ) false respect I4 .X1 = {not a(1), a(2), a(3)}. Similarly,
{a(3)} {a(1), a(3)} unfounded sets P2 respect I4 . Clearly, also
unfounded set. sets atoms unfounded P2 respect I4 .
497

fiAlviano, Calimeri, Faber, Leone, & Perri

formalized below, Definition 1 generalizes one given Van Gelder et al. (1991)
aggregate-free programs: set standard atoms X BP unfounded set
program P respect interpretation if, rule r P
H(r) X , either (i) B(r) .I 6= , (ii) B + (r) X =
6 .
Theorem 1 aggregate-free program P, Definition 1 equivalent one introduced work Van Gelder et al. (1991).
Proof. aggregate-free program P, conditions (1) (2) Definition 1 equivalent (a) B (r) .I 6= (b) B + (r) .(I .X ) 6= , respectively. Condition (b)
equivalent B + (r) (.(I \ X ) ..X ) 6= , holds either (b.1)
B + (r) .(I \ X ) 6= , (b.2) B + (r) X =
6 . Condition (b.2) exactly condition (ii)
work Van Gelder et al. Concerning condition (b.1), since B + (r) contains
positive literals, ignore negative literals .(I \ X ), is, positive literals
\ X . noting negative literals \ X precisely negative literals
I, conclude (b.1) equivalent B + (r) .I 6= . Finally, combining
previous statement condition (a) above, obtain condition (i) work Van
Gelder et al.

Thus, Definition 1 alternative characterization unfounded sets aggregate-free
programs. fact, condition (1) Definition 1 exactly cover first one
Van Gelder et al., condition (2) catches cases second work Van Gelder
et al. missed condition (1).
Theorem 2 X X unfounded sets LPA
m,a program P respect

interpretation I, X X unfounded set P respect I.
Proof. Let r P H(r) X X . want show either (1)
(antimonotone) literal B (r) false respect I, (2) (monotone) literal
B (r) false respect J = .(X X ). symmetry, assume
H(r) belongs X . Since X unfounded set respect hypothesis, either
(a) (antimonotone) literal B (r) false respect I, (b) (monotone)
literal B (r) false respect K = .X . Case (a) equals (1). Thus,
remains prove case (b) implies (2). Indeed, J K J + K +
J K . Therefore, definition monotonicity, monotone literal
false respect K false respect J well, done.

corollary Theorem 2, union unfounded sets unfounded set
well.
Corollary 3 union unfounded sets LPA
m,a program P respect
interpretation unfounded set P respect well. refer set
greatest unfounded set P respect I, denoted GU SP (I).
important monotonicity property greatest unfounded set.
Proposition 4 Let J interpretations LPA
m,a program P. J,
GU SP (I) GU SP (J).
498

fiUnfounded Sets Well-Founded Semantics ASP Programs Aggregates

Proof. Since GU SP (J) union unfounded sets P respect J
definition, enough show X = GU SP (I) unfounded set P respect
J. Thus, want show that, rule r P H(r) X , either (1)
(antimonotone) literal B (r) false respect J, (2) (monotone) literal
B (r) false respect J .X . already know X unfounded set P
respect Corollary 3. Therefore, either (a) (antimonotone) literal B (r)
false respect I, (b) (monotone) literal B (r) false respect
.X . Since J, J J .X extensions interpretations
.X , respectively. Hence, Remark 1, (a) implies (1) (b) implies (2),
done.

ready extending well-founded operator defined Van Gelder et al.
(1991) case LPA
m,a programs.
Definition 2 Let P LPA
m,a program. immediate logical consequence operator
B
P
TP : IP 2
well-founded operator WP : IP 2BP .BP defined follows:
TP (I) = { BP | r P H(r) =
literals B(r) true respect I}
WP (I) = TP (I) .GU SP (I).
Intuitively, given interpretation program P, WP derives true set
atoms belonging every model extending (by means TP operator). Moreover,
WP derives false atoms belonging unfounded set P respect
(by means GU SP operator). Note TP (I) GU SP (I) set atoms,
WP (I)+ = TP (I) WP (I) = .GU SP (I). following proposition formalizes
intuition Definition 2 extends WP operator defined Van Gelder et al. (1991)
standard programs LPA
m,a programs.
Proposition 5 Let P aggregate-free program. WP operator Definition 2
coincides WP operator defined Van Gelder et al. (1991).
Proof. Since WP equal union TP .GU SP cases,
show definitions TP GU SP coincide introduced Van Gelder
et al. (1991) aggregate-free programs.
two immediate logical consequence operators (TP ) coincide aggregate-free
program P. Indeed, rule r P, B(r) standard literals.
definition GU SP (I) coincides one Van Gelder et al. (1991)
aggregate-free program P interpretation I. Indeed, cases GU SP (I)
defined union unfounded sets P respect I, notion
unfounded set coincides one work Van Gelder et al. standard
programs Theorem 1.

next show fixpoint well-founded operator WP (possibly partial)
model.
499

fiAlviano, Calimeri, Faber, Leone, & Perri

{a, b}

{a, b}

{a}

{b}

{not a, b} {not a, b}

{not b}

{not a}


Figure 1: meet semilattice
Theorem 6 Let P LPA
m,a program (partial) interpretation.
fixpoint WP , (partial) model P.
Proof. Let us assume WP (M ) = holds. Thus, TP (M ) .GU SP (M )
hold. Consider rule r P. literals B(r) true respect ,
H(r) TP (M ) . H(r) false respect , H(r) GU SP (M ).
Since GU SP (M ) unfounded set P respect Corollary 3, either
literal B (r) false respect , literal B (r) false respect
.GU SP (M ) = . conclude r satisfied .

theorem states WP monotone operator meet semilattice induced IP subset-containment relationship. recall meet semilattice
partially ordered set meet (or greatest lower bound) nonempty finite
subset. example meet semilattice program base {a, b} reported
Figure 1.
Theorem 7 Let P LPA
m,a program. well-founded operator WP monotone
operator meet semilattice hIP , i.
Proof. Since WP equal union TP .GU SP Definition 2,
prove monotonicity operators TP GU SP .
first show TP monotone operator, is, pair interpretations
I, J P J, holds TP (I) TP (J). Consider atom TP (I).
Definition 2, rule r P H(r) = literals B(r)
true respect I. Since J, conclude literals B(r)
true respect J well (see Remark 1), H(r) = belongs TP (J)
Definition 2.
already know GU SP monotone operator Proposition 4:
pair interpretations I, J P J, holds GU SP (I) GU SP (J).

prove sequence W0 = , Wn+1 = WP (Wn ) well-defined, is,
element sequence interpretation.
Theorem 8 Let P LPA
m,a program. sequence W0 = , Wn+1 = WP (Wn )
well-defined.
500

fiUnfounded Sets Well-Founded Semantics ASP Programs Aggregates

Proof. use strong induction. base case trivial, since W0 = . order prove
consistency Wn+1 = TP (Wn ).GU SP (Wn ), assume consistency every Wm
n. Since WP monotone operator Theorem 7, enough show
GU SP (Wn ) Wn+1 = . end, next show set X atoms
X Wn+1 6= unfounded set P respect Wn (and contained
GU SP (Wn )). Let Wm+1 first element sequence X Wm+1 6= (note
n). Consider atom X Wm+1 . definition TP , rule r P
H(r) = literals B(r) true respect Wm . Note
atom Wm belong X (for way Wm+1 chosen). Thus,
Remark 1, literals B(r) true respect Wn Wn .X (we
recall Wn Wm WP monotone). ends proof, neither condition
(1) (2) Definition 1 hold .

Theorem 8 Theorem 7 imply WP admits least fixpoint (Tarski, 1955),
referred well-founded model P. well-founded semantics LPA
m,a
program P given model. state first important property
well-founded semantics LPA
m,a programs.
Property 1 every LPA
m,a program, well-founded model always exists unique.
Another important property well-founded semantics easily follows Proposition 5.
Property 2 aggregate-free programs, well founded semantics defined
paper coincides classical well-founded semantics Van Gelder et al. (1991).
Although well-founded model, general, might leave atoms undefined,
cases WP () total interpretation.
Example 12 Consider following program P3 :
a(1) : #sum{h1 : a(1)i, h2 : a(2)i} > 2.
a(2) : b.
b : c.

iterated application WP yields following sets:
1.
2.
3.

WP () = {not a(1), c};
WP ({not a(1), c}) = {not a(1), c, b};
WP ({not a(1), c, b}) = {not a(1), c, b, a(2)} = WP ().

case, well-founded model total. Indeed, atom BP either true false
respect WP ().
totality well-founded model program due stratification,
formalized next theorem. Given Corollary 25, equivalent result stated
already Pelov et al. (2007) Theorem 7.2 Corollary 7.1. However, proof
labelled sketch Pelov et al., moreover relies rather different formalisms
proof.
501

fiAlviano, Calimeri, Faber, Leone, & Perri

Theorem 9 stratified LPA
m,a programs, well-founded model total.

Proof. Let P stratified LPA
m,a program. order prove WP () total,
show (standard) atom BP \WP () false respect WP (). definition
stratification, level mapping || || (standard) predicates P that,
pair a, b standard predicates occurring head body rule r P,
respectively, following conditions satisfied: (i) b appears antimonotone literal,
||b|| < ||a|| holds; (ii) otherwise, b appears monotone literal, ||b|| ||a||
holds. order define non-decreasing sequence subsets BP follows:

L0 =
Li+1 = Li { BP | predicate p ||p|| = i},

N.

aim show that, N, set Li+1 \WP () contained .WP () .
use induction i. base case trivial L0 = holds definition.
suppose atoms Li \ WP () false respect WP () order show
atoms Li+1 \ WP () false respect WP () well. end,
prove Li+1 \ WP () unfounded set P respect WP (). Consider
rule r Ground(P) H(r) Li+1 \ WP (). want show either (1)
(antimonotone) literal B (r) false respect WP (), (2) (monotone)
literal B (r) false respect WP () .(Li+1 \ WP ()). Since H(r) Li+1 ,
definition stratification following propositions hold:
(a) literal B (r) either negated standard atom belonging Li , aggregate
literal depending atoms Li ;
(b) literal B (r) either standard atom belonging Li+1 , aggregate
literal depending atoms Li+1 .
Since H(r) 6 WP () (that is, H(r) 6 TP (WP ())), literal B(r)
true respect WP () (by definition TP ). antimonotone literal,
apply (a) induction hypothesis conclude (1) holds ( cannot undefined
respect WP (), must false). monotone literal, apply (b)
induction hypothesis conclude (2) holds ( cannot undefined respect
WP () .(Li+1 \ WP ()) WP () .(Li+1 \ WP ()) WP () holds, must
false).


4. Answer Set Characterization via Unfounded Sets
well-founded semantics three-valued semantics, is, program associated model atoms either true, false undefined. semantics
literature associate programs two-valued models (i.e., models without undefined
atoms). commonly accepted two-value semantics LP answer set semantics.
section present number results concerning unfounded sets answer sets
LPA
m,a programs. first recall definition answer sets provided Faber, Leone,
Pfeifer (2011).
502

fiUnfounded Sets Well-Founded Semantics ASP Programs Aggregates

Definition 3 (Minimal Model) total model P (subset-)minimal total
model N P exists N + + . Note that, definitions, words
interpretation model refer possibly partial interpretations, minimal model
always total interpretation.
next provide transformation reduct ground program
respect total interpretation formed. Note definition generalization (Faber
et al., 2004) Gelfond-Lifschitz transformation (1991) standard logic programs.
Definition 4 (Program Reduct) Given LPA program P total interpretation
I, let Ground(P)I denote transformed program obtained Ground(P) deleting
rules body literal false respect I, i.e.:
Ground(P)I = {r Ground(P) | literals B(r) true respect I}.
ready introducing notion answer set LPA programs.
Definition 5 (Answer Set LPA Programs) Given LPA program P, total interpretation P answer set P minimal model
Ground(P)M .
Example 13 Consider two total interpretations I5 = {p(0)} I6 = {not p(0)}
following two programs:
P4 = {p(0) : #count{X : p(X)} > 0.}
P5 = {p(0) : #count{X : p(X)} 0.}

obtain following transformed programs:
Ground(P4 )I5
Ground(P4 )I6
Ground(P5 )I5
Ground(P5 )I6

= Ground(P4 ) = {p(0) : #count{h0 : p(0)i} > 0.}
=
=
= Ground(P5 ) = {p(0) : #count{h0 : p(0)i} 0.}

Hence, I6 answer set P4 . Indeed, I5 minimal model Ground(P4 )I5 .
Moreover, P5 answer sets. Indeed, I5 minimal model Ground(P5 )I5 ,
I6 model Ground(P5 )I6 = Ground(P5 ).
Note answer set P also total model P Ground(P)M
Ground(P), rules Ground(P) \ Ground(P)M satisfied respect
(by Definition 4, rules must least one body literal false
respect ).
language LPA
m,a considered work, answer sets defined Definition 5
coincide stable models defined Pelov, Denecker, Bruynooghe (2003)
hence also defined Pelov et al. (2007) Son et al. (2007). equivalence
follows Propositions 3.7 3.8 Ferraris (2011), respectively state stable
models Pelov et al. (2003) LPA
m,a coincide semantics defined Ferraris (2011),
turn coincides Definition 5 larger class programs. means
results involving answer sets also hold semantics LPA
m,a .
hand, also implies results (for example Theorem 16) consequences
results work Pelov et al. (2007) virtue Theorem 24 Section 7.
remainder section highlight relevant relationships answer sets
unfounded sets. introducing results, let us provide additional definition.
503

fiAlviano, Calimeri, Faber, Leone, & Perri

Definition 6 (Unfounded-free Interpretation) interpretation LPA
m,a program P unfounded-free X = holds unfounded set X P
respect I.
total interpretations, equivalent characterization unfounded-free property
given below.
Lemma 10 total interpretation LPA
m,a program P unfounded-free
+
empty set subset unfounded set P respect I.
Proof. () Straightforward: Definition 6, disjoint unfounded set
P respect I.
() prove contrapositive: unfounded-free, exists non-empty
subset + unfounded set P respect I. Definition 6,
unfounded-free, exists unfounded set X P respect
X =
6 . next show X unfounded set P respect I, i.e.,
rule r P H(r) X , either (1) (antimonotone) literal B (r)
false respect I, (2) (monotone) literal B (r) false respect
.(I X ). Since X unfounded set, Definition 1, either (a) (antimonotone)
literal B (r) false respect I, (b) (monotone) literal B (r) false
respect .X . Thus, end proof showing .X = .(I X ).
end, observe (i) .X = .(X \ I) .(I X ). Moreover, since total,
.(BP \ + ) = , thus (ii) .(X \ I) = .(X \ + ) \ X . using (i)
.X = (I \ X ) .X simplifying (ii) obtain .X = (I \ X ) .(I X ).
conclude observing \ X = \ (I X ), thus .X = .(I X )
holds.

give another interesting characterization total models LPA
m,a programs.
Lemma 11 total interpretation (total) model LPA
m,a program P
.M unfounded set P respect .
Proof. start observing rule r P H(r) + satisfied
. Thus, show that, rule r P H(r) .M , literal
B(r) false respect either (1) (antimonotone) literal B (r)
false respect , (2) (monotone) literal B (r) false respect
.(.M ). end, enough prove .(.M ) = holds.
definition, () .(.M ) = (M \ .M ) ..M . consistency
.M disjoint. Moreover, ..M = subset .
simplifying () last two sentences, obtain .(.M ) = .

give characterizations answer sets LPA
m,a programs.
Theorem 12 total model answer set LPA
m,a program P
unfounded-free.
504

fiUnfounded Sets Well-Founded Semantics ASP Programs Aggregates

Proof. () prove contrapositive: total model LPA
m,a program P
unfounded-free, answer set P. Lemma 10, since total
interpretation unfounded-free, exists unfounded set X P
respect X + X =
6 . Therefore, prove answer

set P, next show .X model P .X .
end, consider rule r P . Definition 4 reduct, literals B(r) true
respect , H(r) + model P P P.
consider two cases:
1. H(r) 6 X . case, H(r) .X well.
2. H(r) X . case, since X unfounded set P respect , either
(1) literal B (r) false respect , (2) literal B (r) false
respect .X . previous considerations, since r P , (1) cannot hold,
conclude literal B(r) false respect .X .
Hence, r satisfied .X either head (in case H(r) 6 X ),
body (in case H(r) X ), done.
() prove contrapositive: total model LPA
m,a program P
answer set P, unfounded-free. Since model P P
answer set P, exists total model N P N + + . next show
+ \ N + unfounded set P respect , is, rule r P
H(r) + \ N + , either (1) (antimonotone) literal B (r) false respect
, (2) (monotone) literal B (r) false respect .(M + \ N + ).
start showing .(M + \ N + ) = N . definition, (a) .(M + \ N + ) =
(M \ (M + \ N + )) .(M + \ N + ). N + + (b) \ (M + \ N + ) =
N + . Moreover, since N total interpretations N + + , (c)
N (d) .(M + \ N + ) = N \ . Thus, using (b) (d) (a) obtain
.(M + \ N + ) = N + (N \M ), observing (N \M ) = N
holds (c), conclude (e) .(M + \ N + ) = N + N = N .
Consider rule r P H(r) + \ N + . deal two cases:
1. r P \ P . case, Definition 4, must literal B(r)
false respect . antimonotone literal, (1) holds. Otherwise,
monotone literal false respect N well, since N ; thus,
(2) holds (e).
2. r P . case, since N model P H(r) false respect N
(because H(r) + \ N + assumption), must literal B(r)
false respect N . antimonotone literal, false respect
well, since N , (1) holds. Otherwise, monotone literal
(2) holds (e).

ready state important connection answer sets unfounded
sets.
Theorem 13 total interpretation LPA
m,a program P answer set P
GU SP (M ) = .M .
505

fiAlviano, Calimeri, Faber, Leone, & Perri

Proof. () Let answer set P. Lemma 11, .M unfounded set P
respect , hence GU SP (M ) .M . Theorem 12, unfounded-free,
hence GU SP (M ) .M total. sum, GU SP (M ) = .M .
() Let total interpretation GU SP (M ) = .M . GU SP (M ) =
.M disjoint, unfounded-free. Moreover, Corollary 3, GU SP (M ) =
unfounded set P respect so, applying Lemma 11, conclude
model P. order apply Theorem 12 (M unfounded-free
model P) conclude answer set P.

following theorem shows answer sets LPA
m,a programs exactly total
fixpoints well-founded operator defined Section 3.
Theorem 14 Let total interpretation LPA
m,a program P.
answer set P fixpoint well-founded operator WP .
Proof. () Let answer set P. want show fixpoint WP ,
is, WP (M ) = . aim show TP (M ) = + .GU SP (M ) = .
Since answer set, applying Theorem 13, obtain GU SP (M ) = .M ,
equivalent .GU SP (M ) = . Therefore, remains prove TP (M ) = + :
() Consider atom TP (M ). Definition 2, rule r P
H(r) = literals B(r) true respect . Thus, + holds
model P.
() Consider atom + . Since answer set P, apply Theorem 12
conclude unfounded-free. Hence, (singleton) set {} +
unfounded set P respect . Thus, Definition 1, rule
r P H(r) = neither (1) (antimonotone) literal B (r)
false respect , (2) (monotone) literal B (r) false respect
.{}. Since total interpretation, neither (1) (2) equivalent
(i) (antimonotone) literals B (r) true respect , (ii)
(monotone) literals B (r) true respect .{}. observing
.{} , state (ii) implies (monotone) literals
B (r) true respect well. combining latter statement (i)
obtain literals B(r) true respect , TP (M )
Definition 2.
() Let total fixpoint WP , i.e., WP (M ) = . Thus, = .GU SP (M )
Definition 2, answer set P Theorem 13.

Observe Theorem 14 generalization Theorem 5.4 Van Gelder et al. (1991)
class LPA
m,a programs. also worth noting WP (I) extends preserving
correctness: contained answer set , WP (I) may add literals
, never introduces literal would inconsistent .
Proposition 15 Let interpretation LPA
m,a program P, let
answer set P. , WP (I) .
506

fiUnfounded Sets Well-Founded Semantics ASP Programs Aggregates

Proof. trivial consequence monotonicity operator WP (Theorems 7)
Theorem 14. Indeed, Theorems 7, WP implies WP (I) WP (M ),
WP (M ) = Theorem 14.

next show well-founded model LPA
m,a program contained
answer sets (if any) P. would like point due Theorem 24 Section 7
(showing equivalence well-founded operators defined work one
defined Pelov et al., 2007) Propositions 3.77 3.8 Ferraris (2011; showing
equivalence answer sets Faber et al., 2011 stable models Pelov et al., 2007),
following results also hold virtue definitions well-founded stable
semantics work Pelov et al., particular due Proposition 7.3 paper.
nevertheless also provide proof using concepts defined earlier.

Theorem 16 Let P LPA
m,a program. answer set P, WP () .

Proof. Let answer set P. Note WP () limit sequence W0 = ,
Wn = WP (Wn1 ). show Wn induction n. base case trivially
true since W0 = definition. assume Wn order show Wn+1 .
Since Wn+1 = WP (Wn ) definition Wn induction hypothesis, apply
Proposition 15 conclude Wn+1 .

theorem suggests another property well-founded semantics LPA
m,a programs.
Property 3 well-founded semantics LPA
m,a programs approximates answer set
semantics: well-founded model contained intersection answer sets (if
any).
combining Theorem 14 Theorem 16, obtain following claim.

Corollary 17 Let P LPA
m,a program. WP () total interpretation,
unique answer set P.

Therefore, combining Theorem 9 corollary above, obtain another property
well-founded semantics LPA
m,a programs.
Property 4 stratified LPA
m,a programs, well-founded model coincides
unique answer set.

5. Complexity Well-Founded Semantics
complexity analysis carried section, consider ground programs
polynomial-time computable aggregate functions (note example aggregate functions
appearing paper fall class). However, eventually provide discussion
results change considering non-ground programs. start important
property monotone antimonotone aggregate literals.
507

fiAlviano, Calimeri, Faber, Leone, & Perri

Lemma 18 Let partial interpretation ground LPA
m,a program P. define
two total interpretations P follows: Imin = .(BP \ I) Imax = (BP \ .I).
(ground) aggregate literal occurring P, following statements hold:
1. monotone literal, true (resp. false) respect
true respect Imin (resp. false respect Imax ).
2. antimonotone literal, true (resp. false) respect
true respect Imax (resp. false respect Imin ).
Proof. start noting Imin (resp. Imax ) total interpretation extending
standard atoms undefined respect false
respect Imin (resp. true respect Imax ). Thus, () Imin Imax .
monotone true respect Imin (resp. false respect Imax ), true
(resp. false) respect (). antimonotone true respect
Imax (resp. false respect Imin ), true (resp. false) respect
(). end proof observing true (resp. false) respect
I, true respect Imin Imax definition.

ready analyze computational complexity well-founded semantics
LPA
m,a programs. analysis lead prove following fundamental property.
Property 5 well-founded model ground LPA
m,a program efficiently (polynomialtime) computable.
Given Corollary 25, property also follows Theorem 7.4 work Pelov
et al. (2007). following, provide alternative proof based concepts
defined earlier paper, also leads several interesting intermediate results.
Property 5 trivial aggregates may easily increase complexity
evaluation. Indeed, even deciding truth aggregate respect partial interpretation intractable general; similar observation already made Pelov
(2004). However, task polynomial-time computable aggregate literals occurring LPA
m,a programs.
Proposition 19 Deciding whether ground aggregate literal true (resp. false)
respect partial interpretation is:
(a) co-NP-complete general;
(b) polynomial-time computable either monotone antimonotone literal.
Proof. (a) membership, consider complementary problem, is,
deciding whether ground aggregate literal true (resp. false) respect
partial interpretation I, prove belongs NP. order show
true (resp. false) respect enough find total interpretation J
extending (that is, J I) false (resp. true) respect J. Thus,
guess J check falsity (resp. truth) respect J polynomial
508

fiUnfounded Sets Well-Founded Semantics ASP Programs Aggregates

time (if aggregate function computed polynomial time respect size
input multiset, assuming).
hardness, first consider problem checking truth aggregate provide polynomial-time reduction TAUTOLOGY. TAUTOLOGY
problem co-NP-complete stated follow: Given proposition formula
variables X1 , . . . , Xn , truth assignment v variables X1 , . . . , Xn satisfy
formula ? Without loss generality, assume 3-DNF formula form
= D1 Dm ,

disjunct Di conjunction 1i 2i 3i , ji positive negative
literal (note that, context TAUTOLOGY, term literal denotes variable
Xk variable preceded negation symbol ). given , consider
partial interpretation = {} construct aggregate literal = #sum{S} 1,
contains two groups elements. elements first group represent disjuncts

h1 : (1i ), (2i ), (3i )i,
= 1, . . . , ,
where, = 1, . . . , j = 1, . . . , 3, propositional atom (ji ) defined
follows:

j
xk positive literal Xk , k {1, . . . , n}.
j
(i ) =
f
xk ji negative literal Xk , k {1, . . . , n}.
elements second group represent variables follows:

h 1,


h1,
h1,



h 1,

xk :
xk : xtk
,
xk : xfk
xk : xtk , xfk

k = 1, . . . , n ,

xk xk constants associated variable Xk . Note that, variable
Xk , two atoms A, xtk xfk . Thus, interpretation J, four cases
possible:
(1) {not xtk , xfk } J: case, h1, xk : contribute evaluation
A, contribution 1;
(2) {xtk , xfk } J: case, four elements contribute evaluation A,
thus contribution 1 1 + 1 = 1 (note h1, xk : xtk h1, xk : xfk
give total contribution 1 pure set approach);
(3) {xtk , xfk } J: case, h1, xk : h1, xk : xtk contribute, giving
1 1 = 0;
(4) {not xtk , xfk } J: case, h1, xk : h1, xk : xfk contribute, giving
1 1 = 0.
509

fiAlviano, Calimeri, Faber, Leone, & Perri

Thus, k {1, . . . , n}, total contribution four elements associated
variable Xk either 0 1. Note also total contribution elements
(i.e., first group) either 0 1. Therefore, k {1, . . . , n}
either case (1) (2) occurs, interpretation J trivially satisfies A. Otherwise, J
that, variable k {1, . . . , n}, either (3) (4) occurs. case, say
J good interpretation.
next define one-to-one mapping set assignments set
good interpretations. Let v assignment . good interpretation Iv associated
v Iv

f
{xtk , xk } Iv v(Xk ) = 1
,
k = 1, . . . , n .

f

{not xk , xk } Iv v(Xk ) = 0
want show v satisfies true respect Iv . Since Iv
good interpretation, elements second group give total contribution 0,
consider elements first group. elements give
contribution 1 {(1i ), (2i ), (3i )} holds least one {1, . . . , n},
holds v(Di ) = 1 holds disjunct Di . conclude
true respect Iv v() = 1.
Concerning check falsity aggregate, start 3-DNF formula
construct aggregate literal = #sum{S} < 1, obtained described
above. tautology false respect = {}.
(b) Let partial interpretation LPA
m,a program P aggregate literal
occurring P. want show deciding whether true (resp. false) respect
done polynomial-time size BP . Lemma 18, enough evaluate
aggregate respect either Imin = .(BP \ I) Imax = (BP \ .I).
end proof observing interpretations Imin Imax constructed
polynomial time, value aggregate function computed
polynomial time respect size input multiset assumption.

order prove tractability well-founded semantics need efficient
method computing greatest unfounded set, part well-founded operator
WP . Hence, next give polynomial-time construction set BP \GU SP (I) means
monotone operator.
Definition 7 Let interpretation LPA
m,a program P. operator :
B
B
P
P
defined follows:
2 2
(Y ) = { BP | r P H(r) =
(antimonotone) literal B (r) false respect I,
(monotone) literals B (r) true respect \ .I }
least fixpoint coincides greatest unfounded set P respect
I.
Theorem 20 Let P LPA
m,a program interpretation P. Then:
510

fiUnfounded Sets Well-Founded Semantics ASP Programs Aggregates

1. operator least fixpoint ();
2. GU SP (I) = BP \ ().
Proof. operator monotonically increasing operator meet semilattice
hBP , i, therefore admits least fixpoint () (Tarski, 1955). next prove
GU SP (I) = BP \ () two steps:
() first observe () computed iteratively, starting empty set,
limit sequence F0 = , Fi+1 = (Fi ). Thus, prove induction
GU SP (I) BP \Fi holds. base case trivial, since F0 = definition
GU SP (I) subset BP Definition 1. assume GU SP (I) BP \ Fi
order prove GU SP (I) BP \ Fi+1 . Since GU SP (I) unfounded set P
respect Theorem 2, Definition 1 that, GU SP (I)
rule r P H(r) = , either (1) (antimonotone) literal
B (r) false respect I, (2) (monotone) literal B (r) false
respect .GU SP (I). want show belong Fi+1 ,
is, rule r either (i) (antimonotone) literal
B (r) false respect I, (ii) (monotone) literal B (r) true
respect Fi \ .I (recall Fi+1 = (Fi ) definition). Since (1) (i)
equals, show (2) implies (ii). end, assume
(monotone) literal B (r) false respect .GU SP (I).
aim show false respect J = (Fi \ .I ) .(BP \ (Fi \ .I )),
since case would true respect Fi \ .I (see Lemma 18).
start proving (I .GU SP (I)) = .GU SP (I) subset J .
Observe J = .(BP \ (Fi \ .I )) = .(BP \ Fi ) .I
subset BP . Thus, since GU SP (I) BP \ Fi induction hypothesis, obtain
(I .GU SP (I)) = .GU SP (I) .(BP \ Fi ) = J . Since J total,
(I .GU SP (I)) J implies extension K .GU SP (I)
K J K + J (for example, one containing true
standard positive literals undefined respect .GU SP (I)). Since
false respect .GU SP (I) assumption K extension
.GU SP (I), false respect K Remark 1. Thus, since J K
monotone, latter implies false respect J well.
() prove BP \ () unfounded set P respect I, is,
r P H(r) BP \ (), either (1) (antimonotone) literal B (r)
false respect I, (2) (monotone) literal B (r) false respect
.(BP \ ()). Definition 7, H(r) 6 () implies either (i)
(antimonotone) literal B (r) false respect I, (ii) (monotone)
literal B (r) true respect () \ .I . Since (i) (1) equals,
show (ii) implies (2). end, assume (monotone)
literal B (r) true respect () \ .I . Thus,
extension () \ .I false, particular must false
respect J = (I () \ .I ) .(BP \ (I () \ .I )) Lemma 18.
observe (I .(BP \ ())) = .(BP \I ()) = .(BP \(I ()\.I )) =
511

fiAlviano, Calimeri, Faber, Leone, & Perri

J holds (because .I BP ), (I .(BP \ ()))+ J + J total.
combining last two sentences obtain .(BP \ ()) J. Therefore,
since monotone literal false respect J, latter implies
false respect .(BP \ ()) well, (2) holds.

Eventually, Property 5 consequence following theorem. mentioned earlier,
theorem also follows Theorem 7.4 work Pelov et al. (2007)
Corollary 25, proof provided differs considerably one Theorem 7.4
work Pelov et al.
Theorem 21 Given LPA
m,a program P:
1. greatest unfounded set GU SP (I) P respect given interpretation
polynomial-time computable;
2. WP () polynomial-time computable.
Proof. (1.) Theorem 20, GU SP (I) = BP \ (). next show ()
efficiently computable. fixpoint () limit sequence 0 = , k =
(k1 ). limit reached polynomial number applications
new element sequence k must add least new atom (otherwise limit
already reached), is, |BP |. show application feasible
polynomial time, conclude computable polynomial time. step
processes rules once, rule checks truth-value
body literals once. check truth valuation clearly tractable standard
(i.e., non-aggregates) literals; tractability check aggregate literals stems
Proposition 19, deal monotone antimonotone aggregate atoms only.
conclusion, computable polynomial time, GU SP (I) tractable well since
obtainable BP \ ().
(2.) argumentation carried (), show WP () computed
number steps polynomial (actually linear) |BP |. Indeed, step
polynomial-time computable: proved tractability GU SP (I), TP
polynomial-time computable well.

result positive impact also computation answer set semantics
logic programs aggregates. Indeed, stated Theorem 16, WP () approximates
intersection answer sets (if any) bottom, therefore used
efficiently prune search space. worthwhile noting computation
well-founded semantics also hard polynomial-time. particular, deciding whether
(ground) atom true respect well-founded semantics P-complete,
task P-hard even standard well-founded semantics aggregate-free programs (and,
Proposition 5, semantics coincides standard well-founded aggregatefree programs).
end section briefly addressing complexity non-ground programs.
considering data-complexity (i.e., LPA
m,a program P fixed input consists
facts), results propositional programs: Deciding whether (ground) atom
true respect well-founded semantics non-ground program P-complete,
512

fiUnfounded Sets Well-Founded Semantics ASP Programs Aggregates

data-complexity (Van Gelder et al., 1991). However, program complexity (i.e.,
LPA
m,a program P given input) considered, complexity reasoning rises exponentially. Indeed, non-ground program P reduced, naive instantiation, ground
instance problem, general size Ground(P) single exponential
size P. complexity reasoning increases accordingly one exponential, P
EXPTIME, result derived using complexity upgrading techniques (Eiter,
Gottlob, & Mannila, 1997; Gottlob, Leone, & Veith, 1999).

6. Compilation Standard LP, Implementation Experimental
Results
well-founded semantics LPA
m,a programs implemented extending
DLV system (Leone et al., 2006). section briefly describe implemented
prototype report results experiments aimed assessing efficiency.
Note that, even LPA
m,a programs replaced equivalent LP programs (for
rewriting strategy see Section 6.1 below), experimental results highlight significant
performance advantage LPA
m,a encodings.
6.1 Compilation Standard Logic Programming
section briefly present strategy representing #count, #sum #times
standard constructs.2 compilation spirit one introduced #min
#max Alviano, Faber, Leone (2008) defines subprogram computing
value (possibly recursive) aggregate. compilation takes account specific properties monotone antimonotone aggregate functions, therefore referred
monotone/antimonotone encoding (mae).
monotone/antimonotone encoding LPA
m,a program P obtained replacing
aggregate literal = f (S) new predicate symbol f . Predicate f defined
means subprogram (i.e., set rules) thought compilation
standard LP. compilation uses total order < elements {},
symbol occurring P < u u . assume
presence built-in relation < , = Y1 , . . . , Yn = Y1 , . . . , Yn
lists terms. built-in relation < precedes
lexicographical order induced <. Moreover, use built-in relation ,
true either < = . simplicity, let us assume
form f ({Y : p(Y , Z)}) k, Z lists local variables k
integer constant. aggregate, introduce new predicate symbol faux arity
|Y | + 1 rules modeling atom faux (y, s) must true whenever value
f ({Y : p(Y , Z), y}) least s. Thus, use fact representing value
aggregate function empty set, rule increasing value larger sets.
lexicographical order induced < used guarantee elements set
2. Since considering monotone antimonotone aggregate literals, domains #sum
#times assumed N N+ , respectively.

513

fiAlviano, Calimeri, Faber, Leone, & Perri

User Interface

Diagnosis
Frontend

Inheritance
Frontend

SQL3
Frontend

Planning
Frontend

DLV core
Ground
Program

Intelligent
Grounding

Model
Checker

Model
Generator

File
System

Relational
Database

Filtering

Output

Figure 2: Prototype system architecture.
considered once. particular, following rules introduced:

faux (, ).
= 0, = + 1 f = #count;
= 0, = + Y1 f = #sum;

faux (Y , X) : faux (Y , S), p(Y , Z),

= 1, = Y1 f = #times.
< , X = .
{, >}, truth aggregate f ({Y : p(Y , Z)}) k must inferred
atom faux (y, s) k true. aspect modeled means
following rules:
fk : faux (Y , S), k.

f>k : faux (Y , S), > k.

, instead, truth aggregate f ({Y : p(Y , Z)}) k must inferred
atoms faux (y, s) > k false (and similar <). aspects
modeled means following rules:
fk : f>k .

f<k : fk .

Extending technique aggregate literals global variables quite simple:
Global variables added arguments atoms used compilation,
new predicate fgroupby used collecting possible substitutions.
6.2 System Architecture Usage
extended DLV implementing well-founded operator well-founded
semantics LPA
m,a programs described paper. architecture prototype
514

fiUnfounded Sets Well-Founded Semantics ASP Programs Aggregates

reported Figure 2. detail, modified two modules DLV, Intelligent Grounding
module Model Generator module. prototype, well-founded semantics
adopted one -wf --well-founded specified command-line. Otherwise,
stable model semantics adopted usual. well-founded operator WP introduced
Section 3 used semantics. particular, stable model semantics,
well-founded model profitably used pruning search space. well-founded
semantics, well-founded model printed computation least fixpoint
well-founded operator. case output system consists two sets,
representing true undefined standard atoms well-founded model. binary
prototype available http://www.dlvsystem.com/dlvRecAggr/.
6.3 Experimental Results
knowledge, implemented prototype currently system supporting
well-founded semantics logic programs recursive aggregates. certain special
cases, well-founded model total, well-founded model coincides
semantics answer sets (see Corollary 17) theses cases systems supporting
semantics IDP (Wittocx, Marien, & Denecker, 2008), Smodels (Simons et al.,
2002), clasp (Gebser, Kaufmann, Neumann, & Schaub, 2007), used compute
well-founded model.
however interested systems able compute well-founded model
input programs. One major systems supporting well-founded semantics,
XSB (Swift & Warren, 2010), support aggregates, (apart #min
#max) XSB support recursive aggregates (i.e., aggregates occurring recursive
definitions). Therefore, experiments designed investigating computational behavior aggregate constructs respect equivalent encodings without
aggregates.
specifically, introduce Attacks problem, inspired classic
Win-Lose problem often used context well-founded semantics standard
logic programs, study performance it.
Definition 8 (Attacks Problem) Attacks problem, set p players positive integer given. player attacks n players. player wins
winners attack it. kind problem frequently present turn-based strategy
games.
Note definition winner recursive and, particular, recursive aggregate
natural way encoding problem.
Example 14 instance Attacks problem p = 6, n = 2 = 1 could
following:
player attacks players b c;

player attacks players b f ;

player b attacks players c;

player e attacks players c f ;

player c attacks players b;

player f attacks players e.

515

fiAlviano, Calimeri, Faber, Leone, & Perri

b





f

e

c

Figure 3: instance Attacks problem 6 players, one attacking 2
players.

graphical representation instance shown Figure 3. Since attacked
f , conclude winner. Similarly e. Therefore, f winner
f attacked e, winners. players, namely a, b c,
cannot determine winner not.
experiments, instances Attacks encoded means predicates max,
player attacks representing parameter m, set players attacks
players, respectively. consider three equivalent encodings Attacks problem.
6.3.1 Aggregate-Based Encoding
encoding natural representation Attacks problem LP
m,a . complete
encoding consists single rule, reported below:
win(X) : max(M ), player(X), #count{Y : attacks(Y, X), win(Y )} M.

6.3.2 Join-Based Encoding
equivalent encoding obtained computing number joins proportional
m. tested encoding reported below:
win(X) : player(X), lose(X).
lose(X) : max(1), attacks(Y1 , X), win(Y1 ),
attacks(Y2 , X), win(Y2 ), Y1 < Y2 .
lose(X) : max(2), attacks(Y1 , X), win(Y1 ),
attacks(Y2 , X), win(Y2 ), Y1 < Y2 ,
attacks(Y3 , X), win(Y3 ), Y1 < Y3 , Y2 < Y3 .
lose(X) : max(3), . . .

Note encoding rule possible value parameter m.
However, one rules considered solver program instantiation.
fact, rule instantiated, contains instance atom max(m)
fact present. rules satisfied false body literal.
516

fiUnfounded Sets Well-Founded Semantics ASP Programs Aggregates

30

300

DLV-join

DLV

25

250

20

200

15

150

10

100

5
01

2

3

4

5

6

x

7

8

9 1

2

3

4

5

6

7

8

9

10

50
01



2

3

4

6

x

(a) 100 players

7

8

9 1

2

3

4

5

6

8

9

10



(b) 200 players

600

600

500

500

400

400

300

300

200

200

100
01

5

7

2

3

4

5

x

6

7

8

9 1

2

3

4

5

6

7

8

9

10

100
01



2

3

4
x

(c) 400 players

5

6

7

8

9 1

2

3

4

5

6

7

8

9

10



(d) 800 players

Figure 4: Attacks: Average execution time DLV running aggregate-based encoding
DLV running join-based encoding.

6.3.3 Mae-Based Encoding
encoding obtained applying compilation presented Section 6.1
minor simplifications. full encoding reported below:
win(X) : player(X), lose(X).
lose(X) : count(X, Y, S), max(M ), > M.
count(X, Y, 1) : aux(X, ).
count(X, , ) : count(X, Y, S), aux(X, ), < , = + 1.
aux(X, ) : attacks(Y, X), win(Y ).

Intuitively, atom count(x, y, s) stands least constants
attacks(y , x), win(y ) true. Note rules defining predicate count use
natural order integers guarantee counted once.
Example 15 instance shown Figure 3 represented means following facts:
player(a).
attacks(a, b).
attacks(a, c).
max(1).

player(b).
attacks(b, a).
attacks(b, c).

player(c).
attacks(c, a).
attacks(c, b).

player(d).
attacks(d, b).
attacks(d, f ).

517

player(e).
attacks(e, c).
attacks(e, f ).

player(f ).
attacks(f, d).
attacks(f, e).

fiAlviano, Calimeri, Faber, Leone, & Perri

8

10

XSB-join

DLV

7
6

9
8
7

5

6

4

5

3

4
3

2
1
01

2

3

4

5

6

x

7

8

9 1

2

3

4

5

6

7

8

9

10

2
1
01



2

3

4

6

x

(e) 100 players

7

8

9 1

2

3

4

5

6

8

9

10



(f) 200 players

9

12

8

10

7
6

8

5

6

4
3

4

2
1
01

5

7

2

3

4

5

6

x

7

8

9 1

2

3

4

5

6

7

8

9

10

2
01



2

3

4
x

(g) 400 players

5

6

7

8

9 1

2

3

4

5

6

7

8

9

10



(h) 800 players

Figure 5: Attacks: Average execution time DLV running aggregate-based encoding
XSB running join-based encoding.

encodings, well-founded model restricted win predicate {win(d),
win(e), win(f )}. Note win(a), win(b) win(c) neither true false,
undefined.
6.3.4 Discussion
performed intensive experimentation benchmark varying parameters
p, n. combination parameters, measured average execution
time DLV XSB (version 3.2) 3 randomly generated instances. experiments
R
R
performed 3GHz Intel
Xeon
processor system 4GB RAM
Debian 4.0 operating system GNU/Linux 2.6.23 kernel. DLV prototype used
compiled GCC 4.4.1. every instance, allowed maximum running
time 600 seconds (10 minutes) maximum memory usage 3GB.
results experimentation reported Figures 47. graphs, DLV
implemented prototype aggregate-based encoding, DLV-join DLV-mae
implemented prototype aggregate-free encodings, XSB-join XSB-mae
XSB system aggregate-free encodings (as mentioned earlier, XSB support
518

fiUnfounded Sets Well-Founded Semantics ASP Programs Aggregates

DLV-mae

DLV
6

12

5

10

4

8

3

6

2

4

1
01

2

3

4

5

6

x

7

8

9 1

2

3

4

5

6

7

8

9

10

2
01



2

3

4

5

6

x

(i) 1600 players

7

8

9 1

2

3

4

5

6

7

8

9

10



(j) 3200 players

25

60
50

20

40
15
30
10
20
5
01

2

3

4
x

5

6

7

8

9 1

2

3

4

5

6

7

8

9

10

10
01



2

3

4
x

(k) 6400 players

5

6

7

8

9 1

2

3

4

5

6

7

8

9

10



(l) 12800 players

Figure 6: Attacks: Average execution time DLV running aggregate-based encoding
DLV running mae-based encoding.

recursive aggregates). XSB system, explicitly set indices tabled predicates
optimizing computation.
graph, number players fixed, parameters (x-axis) n
(y-axis) vary. Therefore, size instances grows moving left right along
y-axis, invariant respect x-axis. However, number joins
required join-based encoding depends parameter m. matter fact,
observe graphs Figures 45 average execution time join-based
encoding increases along x- y-axis (for DLV XSB). Instead,
encoding using aggregates, mae-based encoding, average execution time
depends instance sizes, shown graphs Figures 67.
join-based encoding, XSB generally faster DLV, consumes much
memory. Indeed, Figure 5, observe XSB terminates computation
seconds smallest instances, rapidly runs memory slightly larger
instances. Considering mae-based encoding, observe significant performance
gains DLV XSB (see Figures 67). Indeed, systems complete computation allowed time memory larger instances. Computational advantages
mae-based encoding respect join-based encoding particularly evident
519

fiAlviano, Calimeri, Faber, Leone, & Perri

XSB-mae

DLV
3.5

9
8

3

7
2.5

6

2

5

1.5

4
3

1
0.5
01

2

3

4

5

6

x

7

8

9 1

2

3

4

5

6

7

8

9

2

10

1
01



2

3

4

5

6

x

(m) 6400 players

7

8

9 1

2

3

4

5

6

7

8

9

10



(n) 12800 players

60

400
350

50

300
40

250

30

200
150

20
10
01

2

3

4
x

5

6

7

8

9 1

2

3

4

5

6

7

8

9

100

10

50
01



2

3

4
x

(o) 25600 players

5

6

7

8

9 1

2

3

4

5

6

7

8

9

10



(p) 51200 players

Figure 7: Attacks: Average execution time DLV running aggregate-based encoding
XSB running mae-based encoding.

XSB, solved tested instances encoding. However, also XSB
mae-based encoding outperformed DLV native support aggregate constructs
(see Figure 7).
sum, experimental results highlight presence aggregate constructs
significantly speed-up computation. Indeed, encoding using recursive aggregates
outperforms aggregate-free encodings tested instances.

7. Related Work
Defining well-founded semantics logic programs aggregates challenge
major interest last years. first attempts, relying notion unfounded
set, defined restricted language. discussed Kemp
Stuckey (1991). Another semantics falling class one introduced Van Gelder
(1992), subsequently generalized Osorio Jayaraman (1999). main problem
semantics often leave many undefined literals, shown Ross
Sagiv (1997).
520

fiUnfounded Sets Well-Founded Semantics ASP Programs Aggregates

first attempt define well-founded semantics unrestricted LPA done
Kemp Stuckey (1991). semantics based notion unfounded sets. According
Kemp Stuckey, set X standard atoms unfounded set (ground) program
P respect interpretation if, rule r P H(r) X , either (a)
literal B(r) false respect I, (b) B(r) X =
6 . Note standard
literals considered condition (b), aggregates covered it. point
definition unfounded set makes semantics inadequate programs
recursive aggregates, even monotone aggregates considered. example,
program {a(1):#count{X : a(X)} > 0.}, well-founded model work Kemp
Stuckey , reasonable well-founded semantics identify a(1) false.
Pelov et al. (2007) defined well-founded semantics based approximating operators,
namely D-well-founded semantics, extends standard well-founded semantics; indeed, coincide aggregate-free programs. detail, work aggregates
evaluated one three possible ways. Therefore, family semantics defined
Pelov et al., ordered precision: precise three-valued aggregates lead
precise semantics. general, higher precision comes price higher computational complexity. authors discuss following three-valued aggregate relations
evaluation aggregate literals: trivial, bound ultimate approximating aggregates, first less precise, last precise. Semantics relying
trivial approximating aggregates imprecise, still suitable class
stratified aggregate programs. trivial bound approximations polynomial
complexity, ultimate shown intractable nonmonotone aggregate
functions (Pelov, 2004). detailed comparison results presented Section 7.1.
Ferraris (2005) showed semantics Smodels programs positive weight
constraints equal answer sets defined Faber et al. (2004) respective
fragment. Since Theorem 16 WP () approximates answer sets defined Faber et al.,
WP () used also approximating operator respective Smodels programs.
Indeed, shown AtMost pruning operator Smodels (Simons et al., 2002)
special case operator (defined proof Theorem 21).
works attempted define stronger notions well-founded semantics (also
programs aggregates), like Ultimate Well-Founded Semantics (Denecker et al.,
2001), WFS1 WFS2 (Dix & Osorio, 1997). Whether characterization
semantics terms unfounded sets exist semantics unclear left
future research.
Concerning compilations LP programs standard LP, transformation provided Van Gelder (1992). compilation presented Section 6.1 differs
one introduced Van Gelder several respects. approach uses total order
universe input program takes advantage character monotonicity/antimonotonicity aggregate literals input program, transformation
defined Van Gelder uses uninterpreted function symbols representing ground sets,
recursive negation checking truth aggregate literals. briefly discuss aspects following. Roughly, aggregate f (S) k, uninterpreted function symbols
used transformation work Van Gelder determining pairs , k
ground set associated k = f (S ). that, transformation defined Van Gelder checks whether exists pair , k satisfying following
521

fiAlviano, Calimeri, Faber, Leone, & Perri

conditions: (i) every element hconsts : conji , conj true; (ii) k k holds.
point Condition (i) requires recursive negation order checked. Indeed,
equivalent element hconsts : conji conj true.
aspect transformation undesirable side effect: Stratified LPA
m,a programs
may partial well-founded models, is, Theorem 9 hold programs compiled transformation introduced Van Gelder. example side effect
given Van Gelder, shown transformation possibly leads partial
well-founded models instances Company Controls, well-known problem
modeled using monotone recursive aggregates.
7.1 Comparison work Pelov et al. (2007)
section report detailed comparison well-founded semantics defined
paper one Pelov et al. (2007). recall Pelov et al. defines wellfounded stable semantics least total fixpoints three-valued stable
model operator extended aggregate programs.
start observing evaluation ultimate approximating aggregates coincides
evaluation aggregates defined article; also evaluation bound approximating aggregates coincides monotone antimonotone aggregates (as consequence
Lemma 18 paper Proposition 7.16 work Pelov et al., 2007).
Let us introduce translation aggregate literal formula standard
literals. (partial) interpretation I, let conj(I) denote conjunction literals
I. translation trm(A) ground aggregate literal defined follows:
W
trm(A) = {conj(I) | subset-minimal interpretation
true respect I}
Note that, (partial) interpretation J, evaluation respect J coincides
evaluation trm(A) respect J (Proposition 2 Proposition 3
work Pelov et al., 2003). Moreover, monotone (resp. antimonotone) aggregate literal
A, positive (resp. negative) literals appear trm(A).
rule r ground LPA
m,a program P aggregate literal B(r),
translation trm(P, r, A) r program obtained P removing r
adding rule r H(r ) = H(r) B(r ) = B(r) \ {A} conj,
conj trm(A). Therefore, full translation trm(P) P defined recursive
application trm(P, r, A) (note order rules aggregates processed
relevant). next show P trm(P) unfounded sets.
Lemma 22 set atoms X unfounded set program P respect
interpretation X unfounded set trm(P) respect I.
Proof. use induction number aggregate literals P. P aggregate
literals, P = trm(P). consider program P rule r P aggregate
literal B(r). want show set X atoms unfounded set P
respect X unfounded set trm(P, r, A) respect I, since
case might apply induction hypothesis prove claim. Thus,
end proof means following observations: (i) false respect
522

fiUnfounded Sets Well-Founded Semantics ASP Programs Aggregates

interpretation J trm(A) false respect J, is,
conjunction conj trm(A) literal conj false respect
J; (ii) positive (resp. negative) standard literal monotone
(resp. antimonotone).

prove well-founded operators P trm(P) coincide.
Lemma 23 Let P LPA
m,a program interpretation P. WP (I) =
Wtrm(P) (I).
Proof. show (1) TP (I) = Ttrm(P) (I) (2) GU SP (I) = GU Strm(P) (I).
note (2) immediately follows Lemma 22. order prove (1), consider
aggregate literal occurring P. previous considerations, true
respect conjunct trm(A) true respect
I. Thus, (1) holds.

ready relate well-founded operator one provided Pelov
et al. (2007).
Theorem 24 class LPA
m,a programs, well-founded operator herein defined
coincides one Pelov et al. (2007; ultimate bound approximating
aggregate semantics).3
Proof. Lemma 23, already know WP (I) = Wtrm(P) (I). also
Wtrm(P) (I) coincides one work Van Gelder et al. (1991) Theorem 1
(since trm(P) standard logic program). hand, ultimate
bound approximating aggregate semantics, well-founded operators (as defined Pelov
et al., 2007) P trm(P) coincide: consequence Theorem 1 work
Pelov et al. (2003), three-valued immediate consequence operators work
Pelov et al. (2003) Pelov et al. (2007) coincide (see Definition 7 Pelov et al., 2003
Definition 7.5 Pelov et al., 2007). Moreover, well-founded operator Pelov et al.
(2007) coincides one work Van Gelder et al. standard logic programs,
thereby obtaining equality operators.

correspondence two well-founded semantics immediately follows
theorem above. Indeed, two well-founded models defined fixpoints
respective well-founded operators.
Corollary 25 well-founded model herein defined one Pelov et al. (2007;
ultimate bound approximating aggregate semantics) coincide LPA
m,a
programs.
mentioned also earlier, virtue theorem corollary,
results presented paper also follow earlier results literature. particular,
Theorem 9, Theorem 16 complexity results follow definitions
results Pelov (2004) Pelov et al. (2007).
3. Note operator referred stable revision operator Pelov et al. (2007).

523

fiAlviano, Calimeri, Faber, Leone, & Perri

8. Conclusion
paper introduced new notion unfounded set LPA
m,a programs analyzed
well-founded semantics language based notion. semantics generalizes
traditional well-founded semantics aggregate-free programs also coincides
well-founded semantics aggregate programs defined Pelov et al. (2007; latter
defined means notion unfounded set). could also show
semantics main operator WP close ties answer sets defined Faber
et al. (2004, 2011), hence serve approximations.
proved computing semantics tractable problem. Indeed, semantics
given least fixpoint well-founded operator WP . fixpoint reached
polynomial number applications operator WP (with respect size input
program), requiring polynomial time. showing application WP
polynomial-time feasible, proved evaluating monotone antimonotone
aggregate literals remains polynomial-time computable also partial interpretations, since
case one possibly exponential extensions must checked. monotone
aggregate literal, extension obtained falsifying undefined literal,
antimonotone aggregate literal, undefined literal taken true extension.
Motivated positive theoretical results, implemented first system
supporting well-founded semantics unrestricted LPA
m,a . Allowing using monotone
antimonotone aggregate literals, implemented prototype ready experimenting
LPA
m,a framework. experiments conducted Attacks benchmark highlight
computational gains native implementation aggregate constructs respect
equivalent encodings standard LP.

Acknowledgments
Partly supported Regione Calabria EU POR Calabria FESR 2007-2013 within
PIA project DLVSYSTEM s.r.l., MIUR PRIN project LoDeN
PON project FRAME proposed Atos Italia S.p.a.; also thank
anonymous reviewers valuable comments.

References
Alviano, M., Faber, W., & Leone, N. (2008). Compiling minimum maximum aggregates
standard ASP. Formisano, A. (Ed.), Proceedings 23rd Italian Conference
Computational Logic (CILC 2008).
Baral, C. (2003). Knowledge Representation, Reasoning Declarative Problem Solving.
Cambridge University Press.
Brewka, G. (1996). Well-Founded Semantics Extended Logic Programs Dynamic
Preferences. Journal Artificial Intelligence Research, 4, 1936.
Calimeri, F., Faber, W., Leone, N., & Perri, S. (2005). Declarative Computational
Properties Logic Programs Aggregates. Nineteenth International Joint
Conference Artificial Intelligence (IJCAI-05), pp. 406411.
524

fiUnfounded Sets Well-Founded Semantics ASP Programs Aggregates

DellArmi, T., Faber, W., Ielpa, G., Leone, N., & Pfeifer, G. (2003). Aggregate Functions
DLV. de Vos, M., & Provetti, A. (Eds.), Proceedings ASP03 - Answer Set
Programming: Advances Theory Implementation, pp. 274288, Messina, Italy.
Online http://CEUR-WS.org/Vol-78/.
Denecker, M., Pelov, N., & Bruynooghe, M. (2001). Ultimate Well-Founded Stable
Model Semantics Logic Programs Aggregates. Codognet, P. (Ed.), Proceedings 17th International Conference Logic Programming, pp. 212226.
Springer Verlag.
Dix, J., & Osorio, M. (1997). Well-Behaved Semantics Suitable Aggregation.
Proceedings International Logic Programming Symposium (ILPS 97), Port Jefferson, N.Y.
Eiter, T., Gottlob, G., & Mannila, H. (1997). Disjunctive Datalog. ACM Transactions
Database Systems, 22 (3), 364418.
Faber, W. (2005). Unfounded Sets Disjunctive Logic Programs Arbitrary Aggregates. Baral, C., Greco, G., Leone, N., & Terracina, G. (Eds.), Logic Programming Nonmonotonic Reasoning 8th International Conference, LPNMR05,
Diamante, Italy, September 2005, Proceedings, Vol. 3662 Lecture Notes Computer Science, pp. 4052. Springer Verlag.
Faber, W., Leone, N., & Pfeifer, G. (2004). Recursive aggregates disjunctive logic programs: Semantics complexity. Alferes, J. J., & Leite, J. (Eds.), Proceedings
9th European Conference Artificial Intelligence (JELIA 2004), Vol. 3229
Lecture Notes AI (LNAI), pp. 200212. Springer Verlag.
Faber, W., Leone, N., & Pfeifer, G. (2011). Semantics complexity recursive aggregates
answer set programming. Artificial Intelligence, 175 (1), 278298. Special Issue:
John McCarthys Legacy.
Ferraris, P. (2005). Answer Sets Propositional Theories. Baral, C., Greco, G., Leone,
N., & Terracina, G. (Eds.), Logic Programming Nonmonotonic Reasoning 8th
International Conference, LPNMR05, Diamante, Italy, September 2005, Proceedings,
Vol. 3662 Lecture Notes Computer Science, pp. 119131. Springer Verlag.
Ferraris, P. (2011). Logic programs propositional connectives aggregates. ACM
Transactions Computational Logic, 12 (4). press.
Gebser, M., Kaufmann, B., Neumann, A., & Schaub, T. (2007). Conflict-driven answer
set solving. Twentieth International Joint Conference Artificial Intelligence
(IJCAI-07), pp. 386392. Morgan Kaufmann Publishers.
Gelfond, M. (2002). Representing Knowledge A-Prolog. Kakas, A. C., & Sadri, F.
(Eds.), Computational Logic. Logic Programming Beyond, Vol. 2408 LNCS, pp.
413451. Springer.
Gelfond, M., & Lifschitz, V. (1991). Classical Negation Logic Programs Disjunctive
Databases. New Generation Computing, 9, 365385.
Gottlob, G., Leone, N., & Veith, H. (1999). Succinctness Source Expression Complexity. Annals Pure Applied Logic, 97 (13), 231260.
Kemp, D. B., & Stuckey, P. J. (1991). Semantics Logic Programs Aggregates.
Saraswat, V. A., & Ueda, K. (Eds.), Proceedings International Symposium
Logic Programming (ISLP91), pp. 387401. MIT Press.
525

fiAlviano, Calimeri, Faber, Leone, & Perri

Leone, N., Pfeifer, G., Faber, W., Eiter, T., Gottlob, G., Perri, S., & Scarcello, F. (2006).
DLV System Knowledge Representation Reasoning. ACM Transactions
Computational Logic, 7 (3), 499562.
Liu, L., Pontelli, E., Son, T. C., & Truszczynski, M. (2010). Logic programs abstract
constraint atoms: role computations. Artificial Intelligence, 174 (34), 295315.
Liu, L., & Truszczynski, M. (2006). Properties applications programs monotone
convex constraints. Journal Artificial Intelligence Research, 27, 299334.
Manna, M., Ruffolo, M., Oro, E., Alviano, M., & Leone, N. (2011). HiLeX System
Semantic Information Extraction. Transactions Large-Scale Data KnowledgeCentered Systems. Springer Berlin/Heidelberg, appear.
Manna, M., Ricca, F., & Terracina, G. (2011). Consistent Query Answering via ASP
Different Perspectives: Theory Practice. Theory Practice Logic Programming, appear.
Marek, V. W., & Truszczynski, M. (2004). Logic programs abstract constraint atoms.
Proceedings Nineteenth National Conference Artificial Intelligence (AAAI
2004), pp. 8691. AAAI Press / MIT Press.
McCarthy, J. (1959). Programs Common Sense. Proceedings Teddington
Conference Mechanization Thought Processes, pp. 7591. Majestys
Stationery Office.
McCarthy, J. (1980). Circumscription Form Non-Monotonic Reasoning. Artificial
Intelligence, 13 (12), 2739.
McCarthy, J. (1986). Applications Circumscription Formalizing Common-Sense
Knowledge. Artificial Intelligence, 28 (1), 89116.
McCarthy, J. (1990). Formalization Common Sense, papers John McCarthy edited
V. Lifschitz. Ablex.
McCarthy, J., & Hayes, P. J. (1969). Philosophical Problems Standpoint
Artificial Intelligence. Meltzer, B., & Michie, D. (Eds.), Machine Intelligence 4,
pp. 463502. Edinburgh University Press. reprinted (McCarthy, 1990).
McDermott, D. V. (1982). Non-Monotonic Logic II: Nonmonotonic Modal Theories. Journal
ACM, 29 (1), 3357.
McDermott, D. V., & Doyle, J. (1980). Non-Monotonic Logic I. Artificial Intelligence,
13 (12), 4172.
Minsky, M. (1975). Framework Representing Knowledge. Winston, P. H. (Ed.),
Psychology Computer Vision, pp. 211277. McGraw-Hill.
Moore, R. C. (1985). Semantical Considerations Nonmonotonic Logic. Artificial Intelligence, 25 (1), 7594.
Osorio, M., & Jayaraman, B. (1999). Aggregation Negation-As-Failure. New Generation
Computing, 17 (3), 255284.
Pelov, N. (2004). Semantics Logic Programs Aggregates. Ph.D. thesis, Katholieke
Universiteit Leuven, Leuven, Belgium.
Pelov, N., Denecker, M., & Bruynooghe, M. (2003). Translation Aggregate Programs
Normal Logic Programs. de Vos, M., & Provetti, A. (Eds.), Proceedings ASP03
- Answer Set Programming: Advances Theory Implementation, pp. 2942,
Messina, Italy. Online http://CEUR-WS.org/Vol-78/.
526

fiUnfounded Sets Well-Founded Semantics ASP Programs Aggregates

Pelov, N., Denecker, M., & Bruynooghe, M. (2004). Partial stable models logic programs aggregates. Proceedings 7th International Conference Logic
Programming Non-Monotonic Reasoning (LPNMR-7), Vol. 2923 Lecture Notes
AI (LNAI), pp. 207219. Springer.
Pelov, N., Denecker, M., & Bruynooghe, M. (2007). Well-founded Stable Semantics
Logic Programs Aggregates. Theory Practice Logic Programming, 7 (3),
301353.
Pelov, N., & Truszczynski, M. (2004). Semantics disjunctive programs monotone
aggregates - operator-based approach. Proceedings 10th International
Workshop Non-monotonic Reasoning (NMR 2004), Whistler, BC, Canada, pp.
327334.
Reiter, R. (1980). Logic Default Reasoning. Artificial Intelligence, 13 (12), 81132.
Ricca, F., Alviano, M., Dimasi, A., Grasso, G., Ielpa, S. M., Iiritano, S., Manna, M., &
Leone, N. (2010). Logic-Based System e-Tourism. Fundamenta Informaticae.
IOS Press, 105 (12), 3555.
Ricca, F., Grasso, G., Alviano, M., Manna, M., Lio, V., Iiritano, S., & Leone, N. (2011).
Team-building Answer Set Programming Gioia-Tauro Seaport. Theory
Practice Logic Programming. Cambridge University Press, appear.
Ross, K. A., & Sagiv, Y. (1997). Monotonic Aggregation Deductive Databases. Journal
Computer System Sciences, 54 (1), 7997.
Simons, P., Niemela, I., & Soininen, T. (2002). Extending Implementing Stable
Model Semantics. Artificial Intelligence, 138, 181234.
Son, T. C., & Pontelli, E. (2007). Constructive semantic characterization aggregates
answer set programming. Theory Practice Logic Programming, 7, 355375.
Son, T. C., Pontelli, E., & Tu, P. H. (2007). Answer Sets Logic Programs Arbitrary
Abstract Constraint Atoms. Journal Artificial Intelligence Research, 29, 353389.
Swift, T., & Warren, D. S. (2010). XSB: Extending prolog tabled logic programming.
Computing Research Repository (CoRR), abs/1012.5123.
Tarski, A. (1955). lattice-theoretical fixpoint theorem applications. Pacific J.
Math, 5, 285309.
Truszczynski, M. (2010). Reducts propositional theories, satisfiability relations,
generalizations semantics logic programs. Artificial Intelligence, 174, 12851306.
Ullman, J. D. (1989). Principles Database Knowledge Base Systems. Computer
Science Press.
Van Gelder, A. (1992). Well-Founded Semantics Aggregation. Proceedings
Eleventh Symposium Principles Database Systems (PODS92), pp. 127138.
ACM Press.
Van Gelder, A., Ross, K. A., & Schlipf, J. S. (1991). Well-Founded Semantics
General Logic Programs. Journal ACM, 38 (3), 620650.
Wittocx, J., Marien, M., & Denecker, M. (2008). IDP system: model expansion
system extension classical logic. Denecker, M. (Ed.), Proceedings
2nd Workshop Logic Search, Computation Structures Declarative
Descriptions (LaSh08), pp. 153165.

527

fiJournal Artificial Intelligence Research 42 (2011) 1-29

Submitted 11/10; published 09/11

Hard Manipulation Problems?
Toby Walsh

toby.walsh@nicta.com.au

NICTA UNSW
Sydney
Australia

Abstract
Voting simple mechanism combine together preferences multiple agents. Unfortunately, agents may try manipulate result mis-reporting preferences. One barrier
might exist manipulation computational complexity. particular,
shown NP-hard compute manipulate number different voting rules. However, NP-hardness bounds worst-case complexity. Recent theoretical results suggest
manipulation may often easy practice. paper, show empirical studies
useful improving understanding issue. consider two settings represent
two types complexity results identified area: manipulation unweighted votes single agent, manipulation weighted votes coalition agents.
first case, consider Single Transferable Voting (STV), second case, consider
veto voting. STV one voting rules used practice NP-hard compute
single agent manipulate result votes unweighted. also appears one
harder voting rules manipulate since involves multiple rounds. hand, veto
voting one simplest representatives voting rules NP-hard compute
coalition weighted agents manipulate result. experiments, sample number
distributions votes including uniform, correlated real world elections. many
elections experiments, easy compute manipulate result prove
manipulation impossible. Even able identify situation manipulation hard compute (e.g. votes highly correlated election hung),
found computational difficulty computing manipulations somewhat precarious (e.g.
hung elections, even single uncorrelated voter enough make manipulation
easy compute).

1. Introduction
Gibbard-Satterthwaite theorem proves that, weak assumptions like three
candidates absence dictator, voting rules manipulable (Gibbard, 1973; Satterthwaite, 1975). is, may pay agents report preferences truthfully. One appealing
escape result proposed Bartholdi, Tovey Trick (1989). Whilst manipulation
may exist, perhaps computationally difficult find. illustrate idea, demonstrated second order Copeland rule NP-hard manipulate. Shortly after, Bartholdi
Orlin (1991) proved well known Single Transferable Voting (STV) rule NP-hard
manipulate. whole subfield social choice since grown proposal, studying
computational complexity manipulation control voting rules. Two good surveys
recently appeared provide many references literature (Faliszewski, Hemaspaandra, &
Hemaspaandra, 2010; Faliszewski & Procaccia, 2010). Computational complexity results
manipulation voting rules typically vary along five different dimensions.
Weighted unweighted votes: votes weighted unweighted? Although many elections involve unweighted votes, weighted votes used number real-world settings like
shareholder meetings, elected assemblies. Weights also useful multi-agent systems
different types agents. Weights interesting computational perspective least two reasons. First, weights increase computational complexity.
c
2011
AI Access Foundation. rights reserved.

fiWalsh

example, computing manipulate veto rule polynomial unweighted votes
NP-hard weighted votes (Conitzer, Sandholm, & Lang, 2007). Second, weighted case
informs us unweighted case probabilistic information votes.
instance, NP-hard compute election manipulated weighted
votes, NP-hard compute probability candidate winning
uncertainty unweighted votes cast (Conitzer & Sandholm, 2002a).
Bounded unbounded number candidates: (small) fixed number candidates? number candidates allowed grow? example, unweighted votes,
computing manipulation STV rule polynomial bound number candidates NP-hard number candidates allowed grow problem size
(Bartholdi & Orlin, 1991). Indeed, unweighted votes bounded number candidates, polynomial compute manipulate voting rules (Conitzer et al., 2007).
hand, weighted votes, NP-hard compute manipulate many
voting rules bounded number candidates. example, NP-hard compute
manipulation veto rule 3 candidates (Conitzer et al., 2007).
One manipulator coalition manipulators: single agent trying manipulate
results coalition agents acting together? single agent unlikely able change
outcome many elections. coalition, hand, may able manipulate
result. rules, like STV, NP-hard compute single agent needs
vote manipulate result prove manipulation single agent impossible
(Bartholdi & Orlin, 1991). rules like Borda, may require coalition two
agents manipulation NP-hard compute (Davies, Katsirelos, Narodytska, & Walsh,
2011; Betzler, Niedermeier, & Woeginger, 2011). rules like veto, may require
coalition manipulating agents whose size unbounded (and allowed grow
problem size) manipulation NP-hard compute (Conitzer et al., 2007).
Complete incomplete information: Many results assume manipulator(s) complete information agents votes. course, may know precisely
agents vote practice. However, several reasons case complete information interesting. First, show computationally intractable
compute manipulate election complete information also intractable
incomplete information. Second, complete information case informs case
uncertainty. instance, computationally intractable coalition
compute manipulate election complete information also intractable
individual compute manipulate election probabilistic
information votes (Conitzer et al., 2007).
Constructive destructive manipulation: manipulator trying make one particular
candidate win (constructive manipulation) prevent one particular candidate winning
(destructive manipulation)? Destructive manipulation easier compute constructive
manipulation. instance, constructive manipulation veto rule coalition agents
weighted votes NP-hard destructive manipulation polynomial (Conitzer et al.,
2007). However, also rules destructive constructive manipulation
complexity class. example, constructive destructive manipulation
plurality polynomial compute, whilst constructive destructive manipulation
plurality runoff weighted votes NP-hard (Conitzer et al., 2007).
Figure 1, give representative selection results complexity manipulating
voting. References many results found work Conitzer et al. (2007).
paper, focus two cases cover main types computational complexity
results identified: manipulation STV unweighted votes single agent
2

fiWhere Hard Manipulation Problems?

number candidates
plurality
Borda
veto
STV
plurality runoff
Copeland

unweighted votes,
constructive
manipulation
P
NP-c
P
NP-c
P
NP-c

2
P
P
P
P
P
P

weighted votes,
constructive
destructive
3
4
2
3
P
P
P
P
NP-c NP-c P
P
NP-c NP-c P
P
NP-c NP-c P
NP-c
NP-c NP-c P
NP-c
P
NP-c P
P

Figure 1: Computational complexity deciding various voting rules manipulated
agent (unweighted votes) coalition agents (weighted votes). P means
problem polynomial, NP-c problem NP-complete. example, constructive manipulation veto rule polynomial unweighted votes weighted
votes 2 candidates, NP-hard 3 candidates. hand, destructive manipulation veto rule polynomial weighted votes coalition
manipulating agents 2 candidates.

unbounded number candidates election, manipulation veto voting
weighted votes coalition agents 3 candidates election. cases,
assume complete information votes agents. two cases thus cover cases
computational complexity associated: unweighted votes, small (bounded) number
manipulators large (unbounded) number candidates; weighted votes, large (unbounded)
number manipulators, small (bounded) number candidates.
STV obvious interesting case consider study computational complexity manipulation. STV one voting rules used practice manipulation
NP-hard compute votes unweighted. Bartholdi Orlin argued STV one
promising voting rules consider respect:
STV apparently unique among voting schemes actual use today computationally resistant manipulation., (Bartholdi & Orlin, 1991, p. 341).
STV also appears difficult manipulate many rules. example, Chamberlain
(1985) studied four different measures manipulability voting rule: probability
manipulation possible, number candidates made win, coalition size
necessary manipulate, margin-of-error still results successful manipulation.
Compared commonly used rules like plurality Borda, results showed STV
difficult manipulate substantial margin. concluded that:
[this] superior performance . . . combined rather complex implausible nature
strategies manipulate it, suggest [the STV rule] may quite resistant
manipulation, (Chamberlin, 1985, p. 203).
second case considered paper (manipulation veto rule coalition manipulators three candidates) interesting study several reasons. First, veto rule
simple representative voting rules manipulation coalition agents weighted
votes small number candidates NP-hard compute. Second, veto rule easy
reason about. Unlike STV, multiple rounds elimination candidates
worry about. fact, show, manipulation veto rule equivalent simple number
partitioning problem. therefore use efficient number partitioning algorithms compute manipulations. Third, veto rule borderline tractability since constructive manipulation
3

fiWalsh

rule coalition weighted agents NP-hard destructive manipulation polynomial
(since best way ensure candidate win simply veto candidate) (Conitzer
et al., 2007).
empirical study considers computational difficulty computing manipulations practice. NP-hardness results describe worst-case. increasing concern computational complexity results like may reflect actual difficulty computing manipulations
practice. instance, number recent theoretical results suggest manipulation may
often computationally easy (Conitzer & Sandholm, 2006; Procaccia & Rosenschein, 2007b; Xia &
Conitzer, 2008a; Friedgut, Kalai, & Nisan, 2008; Xia & Conitzer, 2008b). results demonstrate
profitably study issue empirically. several reasons empirical analysis
like undertaken useful. First, theoretical analysis often asymptotic show
size hidden constants. addition, elections typically bounded size. sure
asymptotic behaviour relevant finite sized electorates met practice? instance,
results suggest easily compute manipulations almost type STV election
100 candidates. Second, theoretical analysis often restricted particular distributions
(e.g. independent identically distributed votes). Manipulation may different practice
due correlations votes. instance, preferences single-peaked voting
rule selects median candidate manipulable. median voting rule,
best interests agents state true preferences. thus clear correlations
votes impact manipulability election. Indeed, number recent
results studied whether manipulation remains computationally hard votes limited
single-peaked (Walsh, 2007; Faliszewski, Hemaspaandra, Hemaspaandra, & Rothe, 2009; Brandt,
Brill, Hemaspaandra, & Hemaspaandra, 2010). experiments therefore look elections
correlations votes. Third, many theoretical results
computational complexity manipulation hard limited scope.
instance, long standing open result recently settled, proving computing manipulation
Borda rule coalition manipulators NP-hard (Davies et al., 2011; Betzler et al., 2011).
However, proofs require precisely 2 manipulators. remains open computing manipulation Borda rule larger coalition NP-hard. empirical study may quickly suggest
whether result extends larger coalitions. Finally, empirical studies may suggest new avenues
theoretical study. example, experiments reported suggest simple universal
form probability coalition agents veto election elect desired candidate.
would interesting try derive form theoretically.

2. Background
give notation background used throughout rest paper. Let
number candidates election. vote linear order (a transitive, antisymmetric,
total relation) set candidates. Let n number agents voting. profile
n-tuple votes. let N (i, j) number agents preferring j profile. voting
rule function maps profile unique winning alternative. paper, consider
number common voting rules:
Scoring rules: (w1 , . . . , wm ) vector weights, ith candidate total order scores wi ,
winner candidate highest total score. plurality rule weight vector
(1, 0, . . . , 0), veto rule vector (1, 1, . . . , 1, 0), whilst Borda rule vector
(m 1, 2, . . . , 0). veto rule, voter effectively vetoes one candidate
candidate fewest vetoes wins.
Single transferable vote (STV): STV proceeds number rounds. Unless one candidate
majority first place votes, eliminate candidate least number first

4

fiWhere Hard Manipulation Problems?

place votes. ballots placing eliminated candidate first place re-assigned
second place candidate. repeat one candidate majority.
Copeland (aka tournament):
P candidate highest Copeland score wins. Copeland
score candidate i6=j (N (i, j) > n2 ) (N (i, j) < n2 ). Copeland winner candidate wins pairwise elections. second order Copeland rule,
tie, winner candidate whose defeated competitors largest sum Copeland
scores.
Maximin (aka Simpson): candidate highest maximin score wins. maximin
score candidate mini6=j N (i, j). Simpson winner candidate whose worst
performance pairwise elections best.
rules easily modified work weighted votes. vote integer weight w
viewed w agents vote identically. voting rules anonymous order votes
profile unimportant. profile therefore thought multi-set n votes. ensure
winner unique, sometimes need break ties (e.g. two candidates
number vetoes, two candidates number first place votes). UK,
example, election tied, returning officer choose candidates using
random method like lots coin toss. typical assumption made literature (and
paper) ties broken favour manipulator. precisely, given choice several
candidates, tie-break favour candidate preferred manipulator. Suppose
manipulator make preferred candidate win assuming ties broken favour
ties fact broken random. conclude manipulator increase
chance getting preferred result. would interesting consider tie-breaking rules.
Indeed, tie-breaking even introduce computational complexity manipulation. example,
computing manipulate Copeland rule weighted votes polynomial ties scored
1 NP-hard scored 0 (Faliszewski, Hemaspaandra, & Schnoor, 2008).
consider one agent coalition k agents trying manipulate result election.
Manipulation situation manipulators vote differently true preferences
order improve outcome perspective. common literature, assume
manipulators complete knowledge votes (and, appropriate, complete
knowledge weights associated votes). Whilst may unrealistic practice
assume complete knowledge votes, several reasons case
interesting consider. First, complete information likely special case uncertainty
model. Hence, computational hardness results complete information directly imply hardness
corresponding uncertainty model. Second, results hardness manipulation
coalition weighted votes complete information imply hardness manipulation
individual agent unweighted votes incomplete information (Conitzer et al., 2007). Third,
assuming complete information, factor complexity coming uncertainty model
focus instead computing manipulation.
addition standard uniform random models votes, consider
two restricted types votes: single-peaked single-troughed votes. single-peaked votes,
candidates placed line, agents preference candidate decreases distance
single preferred candidate. Single-peaked preferences interesting several
perspectives. First, single-peaked preferences likely occur number domains.
example, buying house, might optimal price mind preference
house decreases distance price increases. Second, single-peaked preferences
easy elicit. Conitzer (2007, 2009) gives strategy eliciting single-peaked preference
ordering linear number pairwise ranking questions. Third, single-peaked preferences prevent
certain problematic situations arising aggregating preferences. particular, prevent
existence Condorcet cycles. fact, median candidate single-peaked profile beats

5

fiWalsh

others pairwise comparisons (that is, median candidate Condorcet winner) (Black,
1948). single-troughed votes, hand, candidates placed line,
agents preference candidate increases distance single least preferred candidate.
example, candidates locations build new incinerator, might least
preferred location (your neighbourhood), preference increases away
incinerator this. Single-troughed votes similar nice properties single-peaked votes
(Barbera, Berga, & Moreno, 2009).

3. Single Transferable Voting
begin empirical study manipulation STV elections. STV used wide variety
real-world settings including election Irish presidency, Australian House Representatives, Academy awards, many organisations including American Political Science
Association, International Olympic Committee, British Labour Party. Interestingly
NP-hard compute single agent manipulate STV rule. Indeed, one
voting rules used practice manipulation NP-hard compute setting.
precisely, STV NP-hard manipulate single agent number candidates unbounded
votes unweighted (Bartholdi & Orlin, 1991), coalition agents 3
candidates votes weighted (Conitzer et al., 2007). Coleman Teague give enumerative method coalition k unweighted agents compute manipulation STV rule
runs O(m!(n + mk)) time n number agents voting number
candidates (Coleman & Teague, 2007). single manipulator, Conitzer, Sandholm Lang
give O(n1.62m ) time algorithm (called CSL on) compute set candidates
win STV election (Conitzer et al., 2007).
Figure 2, give modified version CSL algorithm computing manipulation
STV rule. uses similar recursion CSL changes original algorithm several
ways take advantage fact want compute one distinguished candidate
win need know candidates possibly win. two main
changes CSL. First, ignore elections chosen candidate eliminated. Second,
terminate search soon manipulation found chosen candidate wins.
particular, need explore left branch search tree right branch gives
successful manipulation.
tested modified algorithm simplest possible scenario: elections
vote equally likely. one agent trying manipulate election candidates
n agents vote. Votes drawn uniformly random m! possible votes.
Impartial Culture (IC) model. show benefits modifications CSL algorithm,
ran simple experiment = n. experiment run CLISP 2.42 3.2 GHz
Pentium 4 3GB memory running Ubuntu 8.04.3. Table 1 gives mean nodes explored
runtime needed compute manipulation prove none exists. Median percentiles
display similar behaviour. see modified method considerably faster
original CSL algorithm. addition, problems get larger, improvement increases. n = 32,
method nearly 10 times faster CSL. increases roughly 40 times faster n = 128.
improvements reduce time find manipulation largest problems several
hours couple minutes.
3.1 Varying Number Agents
next performed detailed experiments looking phase transition behaviour hard manipulation problems. many NP-hard problem domains, computationally hard instances
shown often associated region parameter space
rapid transition probability solution exists (Cheeseman, Kanefsky, & Taylor, 1991;

6

fiWhere Hard Manipulation Problems?

Manipulate(c, R, (s1 , . . . , sm ), f )
1 |R| = 1
; one candidate left?
2
return (R = {c})
; chosen candidate?
3 f = 0
; top manipulators vote currently free?
4

5
arg minjR (sj )
; currently eliminated?
6
sd sd + w
; Suppose manipulator votes
7
e arg minjR (sj )
8
= e
; change result?
9
return
10
(c 6= d) Manipulate(c, R {d}, Transfer ((s1 , . . . , sm ), d, R), 0)
11
else return
12
((c 6= d) Manipulate(c, R {d}, Transfer ((s1 , . . . , sm ), d, R), 0))
13
((c 6= e) Manipulate(c, R {e}, Transfer ((s1 , . . . , sm ), e, R), d))
14
else
; top manipulators vote fixed
15
arg minjR (sj )
; eliminated?
16
c =
; chosen candidate?
17
return f alse
18
= f
; manipulator free change result?
19
return Manipulate(c, R {d}, Transfer ((s1 , . . . , sm ), d, R), 0)
20
else return Manipulate(c, R {d}, Transfer ((s1 , . . . , sm ), d, R), f )

Figure 2: modified algorithm compute agent manipulate STV election.
use integers 1 candidates, integers 1 n agents (with n
manipulator), c candidate manipulator wants win, R set un-eliminated
candidates, sj weight agents ranking candidate j first amongst R, w weight
manipulator, f candidate highly ranked manipulator amongst R (or 0
currently constraint highly ranked). function Transfer computes
vector new weights agents ranking candidate j first amongst R given candidate
eliminated. algorithm initially called R set every candidate, f 0.
Mitchell, Selman, & Levesque, 1992). phase transition satisfiable unsatisfiable phase resembles seen statistical physics Ising magnets similar systems.
several good surveys area (Dubois, Monasson, Selman, & Zecchina, 2001; Hartmann &
Weigt, 2005; Gomes & Walsh, 2006).
first experiment varied number agents voting. Figures 3 4, plot
probability manipulator make random agent win, cost compute
possible fix number candidates vary number agents STV election.
subsequent experiments, tested 1000 problems point. number candidates
agents voting varied powers 2, typically 20 (= 1) 27 (= 128) unless otherwise
indicated.
ability agent manipulate election decreases number agents increases.
votes candidates significant chance manipulator
able change result. Phase transition behaviour observed many NP-complete
problem domains including propositional satisfiability (Mitchell et al., 1992; Gent & Walsh, 1994,
1996b), constraint satisfaction (Prosser, 1994; Smith, 1994; Gent, MacIntyre, Prosser, & Walsh, 1995;
Gent, MacIntyre, Prosser, Smith, & Walsh, 2001), graph colouring (Walsh, 1998, 1999, 2001), number
partitioning (Gent & Walsh, 1996a, 1998; Mertens, 2001) travelling salesperson problem
(Zhang & Korf, 1996; Gent & Walsh, 1996c). Unlike domains, probability curve observed
7

fiWalsh

CSL algorithm
nodes
time/s
1.46
0.00
3.28
0.00
11.80
0.00
59.05
0.03
570.11
0.63
14,676.17
33.22
8,429,800.00 6,538.13

n
2
4
8
16
32
64
128

Modified algorithm
nodes
time/s
1.24
0.00
1.59
0.00
3.70
0.00
12.62
0.01
55.20
0.09
963.39
3.00
159,221.10 176.68

Table 1: Comparison original CSL algorithm modified version computes
constructive manipulation STV election. table gives mean nodes explored
runtime needed compute manipulation prove none exists. Median
percentiles display similar behaviour. election n agents voting uniformly random n different candidates. Best results row bold.

1

m=4
m=8
m=16
m=32
m=64
m=128

0.9

prob(manipulable)

0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0
1

10
total number agents voting, n+1

100

Figure 3: Manipulability STV election containing random uniform votes. number
candidates fixed vary number agents voting. vertical axis measures
probability single manipulating agent make random candidate win.
horizontal axis measures total number agents voting. Note n number
agents voting besides manipulator log scale used horizontal
axis.

8

fiWhere Hard Manipulation Problems?

appear sharpen step function around fixed point. probability curve
resembles smooth phase transitions seen polynomial problems like 2-colouring (Achlioptas,
1999) 1-in-2 satisfiability (Walsh, 2002). indicated before, assume ties broken
favour manipulator. reason, probability election manipulable greater
1
. Finding manipulation proving none possible easy unless large

1e+06
m=128
m=64
m=32
m=16
m=8
m=4

100000

mean nodes

10000

1000

100

10

1
1

10

100

agents, n

Figure 4: Search cost compute agent manipulate STV election containing random
uniform votes. number candidates, fixed vary number agents.
vertical axis measures mean nodes explored compute single manipulating
agent make random candidate win. horizontal axis measures number
agents voting besides manipulator. Median percentiles similar.
number agents large number candidates. However, situation, chance
manipulator change result small.
3.2 Varying Number Candidates
next experiment slices parameter space orthogonal direction, varying number
candidates election. Figure 5, plot cost compute manipulator make
random agent win STV election fix number agents vary number
candidates. probability curve manipulator make random agent win resembles
Figure 3. Whilst cost computing manipulation appears increase exponentially
number candidates m, observed scaling much better 1.62m worst case scaling
original CSL algorithm. easily compute manipulations 128 candidates. Note
1.62m 1026 = 128. Thus, appear far worst case. fitted
observed data function cdm found fit = 1.008 coefficient determination
R2 = 0.95 indicating good fit.
3.3 Correlated Votes
many real life situations, votes completely uniform uncorrelated other.
happens introduce correlation votes? consider random votes drawn
Polya-Eggenberger urn model (Berg, 1985). model, urn containing
m! possible votes. draw votes urn random, put back urn
9

fiWalsh

1.62**m
n=128
n=64
n=32
n=16
n=8
n=4

1e+14
1e+12

mean nodes

1e+10
1e+08
1e+06
10000
100
1
20

40

60

80

100

120

candidates,

Figure 5: Search cost compute agent manipulate STV election containing random
uniform votes. number agents, n fixed vary number candidates.
vertical axis measures mean number nodes explored compute manipulation
prove none exists. horizontal axis measures m, number candidates
election. Median percentiles similar.

additional votes type (where parameter). increases, increasing
correlation votes. generalises Impartial Culture model (a = 0)
votes equally likely Impartial Anonymous Culture (a = 1) model profiles
equally likely (McCabe-Dansted & Slinko, 2006). give parameter independent problem

size, consider b = m!
. instance, b = 1, 50% chance second vote
first.
Figures 6 7, plot probability manipulator make random agent win
STV election, cost compute possible vary number candidates
election votes drawn Polya-Eggenberger urn model. before, ability
agent manipulate election decreases number candidates, increases. search
cost compute manipulation appears increase exponentially number candidates
m. However, easily compute manipulations 128 candidates. fitted observed
data function cdm found fit = 1.001 coefficient determination R2 = 0.99
indicating good fit.
Figure 8, plot cost compute manipulation fix number candidates
vary number agents. before, ability agent manipulate election decreases
number agents increases. votes candidates chance
manipulator succeed. previous experiments, finding manipulation proving
none exists easy even many agents candidates. also observed results
almost indistinguishable votes correlated single-peaked (or single-troughed)
drawn either uniformly random urn model.

10

fiWhere Hard Manipulation Problems?

1

n=64
n=32
n=16
n=8
n=4

0.9

prob(manipulable)

0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0
1

10

100

candidates,

Figure 6: Manipulability STV election containing correlated votes. number agents
fixed vary number candidates, m. n fixed votes drawn
Polya-Eggenberger urn model b = 1. vertical axis measures probability
manipulator make random candidate win. horizontal axis measures
number candidates, election.

1.62**m
n=64
n=32
n=16
n=8
n=4

1e+14
1e+12

mean nodes

1e+10
1e+08
1e+06
10000
100
1
20

40

60
80
candidates,

100

120

Figure 7: Search cost compute agent manipulate STV election containing correlated
votes. number agents, n fixed vary number candidates, m.
n fixed votes drawn using Polya-Eggenberger urn model b = 1. vertical
axis measures mean number search nodes explored compute manipulation
prove none exists. horizontal axis measures number candidates,
election. curves different n fit closely top other. Median
percentiles similar.

11

fiWalsh

1e+06

m=64
m=32
m=16
m=8
m=4

100000

mean nodes

10000

1000

100

10

1
20

40

60
80
agents, n

100

120

Figure 8: Search cost compute agent manipulate STV election correlated votes.
number candidates, fixed vary number agents, n. n fixed
votes drawn using Polya-Eggenberger urn model b = 1. vertical axis
measures mean number search nodes explored compute manipulation prove
none exists. horizontal axis measures number agents, n. Median
percentiles similar.

4. Coalition Manipulation
algorithm computing manipulation STV election single agent also used
compute coalition manipulate STV election members coalition vote
unison. ignores complex manipulations members coalition need vote
different ways. Insisting members coalition vote unison might reasonable
wish manipulation low computational communication cost (Slinko & White,
2008). Figures 9 10, plot probability coalition voting unison make
random agent win STV election, cost compute possible vary size
coalition. Theoretical results due Procaccia Rosenschein (2007a) Xia Conitzer

(2008a) suggest critical size coalition
manipulate election grows n.

therefore normalize coalition size n.
ability coalition manipulate
election increases size coalition

increases. coalition n size, probability coalition manipulate
election candidate chosen random wins around 21 . cost compute
manipulation (or prove none exists) decreases increase size coalition.
easier larger coalition manipulate election smaller one.
experiments suggest different behaviour occurs combinatorial
problems like propositional satisfiability graph colouring. instance, see rapid
transition sharpens around fixed point 3-satisfiability. vary coalition size,
see
transition probability able manipulate result around coalition size
k = n. However, transition appears smooth seem sharpen
towards step
function n increases. addition, hard instances occur around k = n. Indeed,
hardest instances coalition smaller small chance
able manipulate result.

12

fiWhere Hard Manipulation Problems?

1
n=4
n=8
n=16
n=32
n=64

prob(manipulable)

0.8

0.6

0.4

0.2

0
0

0.5

1

1.5

2

2.5

3

3.5

4

normalized coalition size, k/sqrt(n)

Figure 9: Manipulability STV election vary size manipulating coalition.
number candidates number non-manipulating agents. n fixed
votes uniformly drawn random n! possible votes. vertical axis measures
probability coalition make arandom candidate win. horizontal axis
measures coalition size, k normalized n.

1e+06

n=64
n=32
n=16
n=8
n=4

100000

mean nodes

10000

1000

100

10

1
0

0.5

1
1.5
2
2.5
3
normalized coalition size, k/sqrt(n)

3.5

4

Figure 10: Search cost compute coalition manipulate STV election vary coalition
size. vertical axis measures mean number search nodes explored compute
manipulation prove
none exists. horizontal axis measures coalition size,

k normalized n. Median percentiles similar.

13

fiWalsh

5. Sampling Real Elections
Elections met practice may differ sampled far. might, instance,
votes never cast. hand, models studied far every possible vote
non-zero probability seen. therefore sampled real voting records.
previously studied phase transition behaviour real world problems using similar sampling
techniques (Gent & Walsh, 1995; Gent, Hoos, Prosser, & Walsh, 1999).
first experiment uses votes cast 10 teams scientists select one 32 different
trajectories NASAs Mariner spacecraft (Dyer & Miles, 1976). team ranked different
trajectories based scientific value. sampled votes. elections 10 fewer
agents voting, simply took random subset 10 votes. elections 10
agents voting, simply sampled 10 votes uniform frequency. elections 32
fewer candidates, simply took random subset 32 candidates. Finally elections
32 candidates, duplicated candidate assigned ranking.
Since STV works total orders, forced agent break ties randomly.
agent broke ties independently agent. New candidates introduced way
clones existing candidates. would interesting consider other, perhaps random
methods introducing new candidates. Nevertheless, note clones feature
number real world elections. Indeed, one way manipulate election introduce clone
candidates opposition, thereby divide vote. example, motivation
studying clones, Tideman (1987) describes successfully vote class treasurer
somewhat precocious 12 year old nominating best friend main rival. therefore
believe may interest consider elections like generated clones
present.
Figures 11 12, plot cost compute manipulator make random agent
win STV election vary number candidates agents. Votes sampled
NASA experiment explained earlier. probability manipulator manipulate
election resembles probability curve uniform random votes. search needed compute
manipulation appears increase exponentially number candidates m. However,
observed scaling much better 1.62m worst-case scaling original CSL algorithm.
easily compute manipulations 128 candidates.
second experiment, used votes faculty hiring committee University
California Irvine (Dobra, 1983). dataset 10 votes 3 different candidates. sampled
data set ways NASA dataset observed similar results.
Results reported Figures 13 14. previous experiments, easy find
manipulation prove none exists. observed scaling much better 1.62m
worst-case scaling original CSL algorithm.

6. Veto Rule
turn manipulation elections small, bounded number candidates,
votes weighted coalition agents trying manipulate result.
part empirical study, consider veto rule. recall veto scoring rule
agent gets cast veto one candidate. candidate fewest vetoes
wins. next theorem shows, simple number partitioning algorithms used compute
successful manipulation veto rule. precisely, following theorem demonstrates,
manipulation election 3 candidates weighted votes coalition (which NP-hard
compute) directly reduced 2-way number partitioning problem. therefore compute
manipulations experiments using efficient number partitioning algorithm like proposed
Korf (1995).

14

fiWhere Hard Manipulation Problems?

1.62**m
n=128
n=64
n=32
n=16
n=8
n=4

1e+14
1e+12

mean nodes

1e+10
1e+08
1e+06
10000
100
1
20

40

60

80

100

120

candidates,

Figure 11: Search cost compute agent manipulate STV election votes sampled
NASA experiment. number agents, n fixed vary number
candidates, m. vertical axis measures mean number search nodes explored
compute manipulation prove none exists. horizontal axis measures
number candidates, m. Median percentiles similar.

1e+06

m=128
m=64
m=32
m=16
m=8
m=4

100000

mean nodes

10000

1000

100

10

1
20

40

60
80
agents, n

100

120

Figure 12: Search cost compute agent manipulate STV election votes sampled
NASA experiment. number candidates, fixed vary
number agents, n. vertical axis measures mean number search nodes
explored compute manipulation prove none exists. horizontal axis
measures number agents, n. Median percentiles similar.

15

fiWalsh

1.62**m
n=64
n=32
n=16
n=8
n=4

1e+14
1e+12

mean nodes

1e+10
1e+08
1e+06
10000
100
1
20

40

60

80

100

120

candidates,

Figure 13: Search cost compute agent manipulate STV election votes sampled
faculty hiring committee. number agents voting, n fixed vary
number candidates, m. vertical axis measures mean number search
nodes explored compute manipulation prove none exists. horizontal
axis measures number candidates, m. Median percentiles similar.

1e+06

m=48
m=24
m=12
m=6
m=3

100000

mean nodes

10000

1000

100

10

1
20

40

60
80
agents, n

100

120

Figure 14: Search cost compute agent manipulate STV election votes sampled
faculty hiring committee. number candidates, fixed vary
number agents voting, n. vertical axis measures mean number search
nodes explored compute manipulation prove none exists. horizontal axis
measures number agents, n. Median percentiles similar.

16

fiWhere Hard Manipulation Problems?

Theorem 1 exists successful manipulation election 3 candidates weighted
coalition using veto rule exists partitioning W {|a P
b|} two bags
difference two sums less equal + b 2c + iW i, W
multiset weights manipulating coalition, a, b c weights vetoes assigned
three candidates non-manipulators manipulators wish candidate weight
c win.
Proof: never helps coalition manipulating veto rule veto candidate
wish win. coalition does, however, need decide divide vetoes
candidates wish lose. P
Consider case b. Suppose partition weights
w /2 w + /2 2w = iW {|ab|} difference two sums.
partition vetoes successful manipulation winning candidate
vetoes nextPbest candidate. is,Pc b + (w /2). Hence
2w + 2b 2c = (a P
b) + 2b 2c + iW = (a + b P
2c) + 2 iW i. case, < b
(b + 2c) + iW i. Thus + b 2c + iW i. 2
STV rule, start analysis uniform votes. first consider case
n agents veto uniformly random one 3 possible candidates, vetoes carry weights
drawn uniformly (0, w]. coalition small size, little weight able
change result. hand, coalition large size, sure able
make favoured candidate win. thus transition manipulability problem
coalition size increases (see Figure 15).
1

prob(elect chosen candidate)

0.9

n=14^2
n=12^2
n=10^2
n=8^2
n=6^2

0.8
0.7
0.6
0.5
0.4
0.3
0

10

20
30
manipulators, k

40

50

Figure 15: Manipulability veto election. vertical axis measures probability
coalition k agents elect chosen candidate veto election n agents
already voted. horizontal axis measures number manipulators, k. Vetoes
weighted weights uniformly drawn (0, 28 ]. k = 0, 1/3rd chance
non-manipulators already elected candidate.
Based work Procaccia Rosenschien
(2007a) Xia Conitzer (2008a),

expect critical coalition size increase n. Figure16, see phase transition
displays simple universal form plotted k/ n. phase transition appears
smooth, probability varying slowly
approaching step function problem
size increases. obtained good fit 1 32 ek/ n . smooth phase transitions
seen 2-colouring (Achlioptas, 1999), 1-in-2 satisfiability Not-All-Equal 2-satisfiability
17

fiWalsh

1

prob(elect chosen candidate)

0.9

n=14^2
n=12^2
n=10^2
n=8^2
n=6^2

0.8
0.7
0.6
0.5
0.4
0.3
0

1

2

3

4

5

k/sqrt(n)

Figure 16: Manipulability veto election rescaled axes. vertical axis measures probability coalition k agents elected chosen candidate veto election
n agents already voted. horizontal axis measures number manipulators,
k divided square root number agents already voted. Vetoes
weighted andweights uniformly drawn (0, 28 ]. Note horizontal axis
scaled 1/ n compared previous figure.

(Achlioptas, Chtcherba, Istrate, & Moore, 2001; Walsh, 2002). interesting note
decision problems polynomial.
theoretical results mentioned earlier leave open hard compute whether manipulation possible coalition size critical. Figure 17 displays computational cost
find manipulation (or prove none exists) using Korfs efficient number partitioning algorithm.
Even critical region problems may may manipulable, easy compute
whether problem manipulable. problems solved branches. contrasts
phase transition behaviour NP-complete problems like propositional satisfiability
complexity classes (Gent & Walsh, 1999; Bailey, Dalmau, & Kolaitis, 2001; Slaney & Walsh, 2002)
hardest problems tend occur around phase transition.

7. Hard Veto Problems Rare
Based reduction manipulation problems number partitioning, give aheuristic argument hard manipulation problems become vanishing rare n ; k = ( n). basic
idea simple: time coalition large enough able change result, variance
scores candidates likely large computing successful manipulation
proving none possible easy. argument approximate. example, replace discrete sums continuous integrals, call upon limiting results like Central Limit Theorem.
Nevertheless, provides insight manipulations typically easy compute.
Suppose n vetoes voted non-manipulators carry weights drawn uniformly [0, w].
Suppose also k manipulators also weights drawn uniformly [0, w], want
candidates B lose C wins, cast vetoes weight a, b c
A, B C respectively. Without loss generality suppose b. three
cases consider. first case, c b c. easy manipulators make

18

fiWhere Hard Manipulation Problems?

1.05

average branches

1.04

n=14^2
n=12^2
n=10^2
n=8^2
n=6^2

1.03

1.02

1.01

1
0

1

2

3

4

5

k/sqrt(n)

Figure 17: Computational cost Korfs number partitioning algorithm decide coalition
k agents manipulate veto election n agents already voted. Vetoes
weighted weights uniformly drawn (0, 2k ]. vertical axis measures
mean number branches used algorithm find manipulation prove none
exists. previous figure, horizontal axis measures number manipulators, k divided square root number agents already voted.
note problems solved little search. took single branch solve.
took 2 branches.

C win since C wins whether veto B. second case, c > b. Again, easy
manipulators decide make C win. veto B. successful
manipulation C wins. third case, < c b < c. manipulators
must partition k vetoes B total vetoes received B exceeds
C. Let deficit weight C B C. is,
= (c a) + (c b) = 2c b. approximate sum n random variables drawn
uniformly probability 1/3 [0, 2w] probability 2/3 [w, 0]. variables
mean 0 variance 2w2 /3. Central Limit Theorem, tends normal distribution
mean 0, variance t2 = 2nw2 /3. manipulation possible, must less
s, sum weights vetoes manipulators. Central Limit Theorem, also
tends normal distribution mean = kw/2, variance 2 = 2kw2 /3.
simple heuristic argument due (Karmarkar, Karp, Lueker, & Odlyzko, 1986) also based
Central
Limit Theorem upper bounds optimal partition difference k numbers
[0, w] O(w k/2k ). addition, based phase transition number partitioning (Gent &
Walsh, 1998), expect partitioning problems easy unless log2 (w) = (k).
Combining
two observations, expect hard manipulation problems 0 k constant
. probability occurring is:
Z
Z x
(x)2
1 y22
1

e 22
e 2t dy dx

2
2t
x k
0
substituting t, , get:
Z
Z x
2
(xkw/2)2
1
1

y2
4nw /3 dy dx
p
p
e 4kw2 /3
e

4kw2 /3
4nw2 /3
0
x k
19

fiWalsh

n ; , tends to:
Z
0

1
p

4kw2 /3

e




k

(xkw/2)2
4kw2 /3

p

4nw2 /3

e



x2
4nw2 /3

dx

ez 1 z > 0, upper bounded by:

Z
(xkw/2)2
k
1

p
p
e 4kw2 /3 dx
4nw2 /3 0
4kw2 /3

Since integral bounded 1, k = ( n) log2 (w) = (k), upper bound varies as:
O(

1
)
k2k

Thus, expect hard instances manipulation problems exponentially rare. Since even
brute force manipulation algorithm takes O(2k ) time worst-case, expect hard
instances significant impact average-case n (and thus k) grows. stress
heuristic argument. makes many assumptions complexity manipulation

problems (in particular hard instances lie within narrow interval 0 k).
assumptions currently supported empirical observation informal argument.
However, experimental results reported Figure 17 support conclusions.

8. Distributions Vetoes
theoretical analyses manipulation due Procaccia Rosenschein (2007a) Xia
Conitzer (2008a) suggest probability election manipulable largely independent
w, size weights attached vetoes. Figure 18 demonstrates indeed appears
case practice. weights varied size 28 216 , probability
appear change. fact, probability curve fits simple universal form plotted
Figure 16. also observed cost computing manipulation proving none
possible change weights varied size.
Similarly, theoretical results typically place assumptions distribution votes.
example, results Procaccia Rosenschein
(2007a) Xia Conitzer (2008a)
critical coalition size increases ( n) hold independent identically
distributed random votes. Similarly, heuristic argument hard manipulation problems
vanishingly rare depends application Central Limit Theorem. therefore works
types independent identically distributed random votes.
considered therefore another type independent identically distributed vote. particular, study election weights independently drawn normal distribution.
Figure 19 shows smooth phase transition manipulability. also plotted
Figure 19 top Figures 16 18. curves appear fit simple universal form.
uniform weights, computational cost deciding election manipulable small
even coalition size critical. Finally, varied parameters normal distribution. probability electing chosen candidate well cost computing manipulation
appear depend mean variance distribution. reproduce
figures look identical previous figures.

9. Correlated Vetoes
conjecture one place find hard manipulation problems veto voting votes
highly correlated. example, consider hung election n agents veto candidate
20

fiWhere Hard Manipulation Problems?

1

prob(elect chosen candidate)

0.9

log2(w)=16
log2(w)=14
log2(w)=12
log2(w)=10
log2(w)=8

0.8
0.7
0.6
0.5
0.4
0.3
0

1

2

3

4

5

k/sqrt(n)

Figure 18: Independence size weights manipulability veto election.
vertical axis measures probability coalition k agents elect chosen
candidate n agents already voted. previous figure, horizontal
axis measures number manipulators, k divided square root number
agents already voted. Vetoes weighted weights uniformly drawn
(0, w].

1

prob(elect chosen candidate)

0.9

n=14^2
n=12^2
n=10^2
n=8^2
n=6^2

0.8
0.7
0.6
0.5
0.4
0.3

0

1

2

3

4

5

k/sqrt(n)

Figure 19: Manipulability veto election weighted votes taken normal distribution.
vertical axis measure probability coalition k agents elect chosen
candidate veto election n agents already voted. previous figure,
horizontal axis measures number manipulators, k divided square root
number agents already voted. Vetoes weighted drawn
normal distribution mean 28 standard deviation 27 .

21

fiWalsh

prob(elect chosen candidate)

1
m=24
m=18
m=12
m=6

0.8

0.6

0.4

0.2

0
0

0.5

1
log2(w)/k

1.5

2

Figure 20: Manipulability veto election votes highly correlated result
hung. Vetoes manipulators weighted weights uniformly drawn
(0, w], agents vetoed candidate manipulators wish win,
sum weights manipulators twice non-manipulators.
vertical axis measures probability coalition k agents elect chosen
candidate. horizontal axis measures log2 (w)/k.

100000
m=24
m=18
m=12
m=6

average branches

10000

1000

100

10

1

0

0.5

1

1.5

2

log2(w)/k

Figure 21: search cost decide hung veto election manipulated. Vetoes
manipulators weighted weights uniformly drawn (0, w],
agents vetoed candidate manipulators wish win, sum
weights manipulators twice non-manipulators. vertical
axis measures mean number branches explored Korfs algorithm decide
coalition k agents manipulate veto election. horizontal axis measures
log2 (w)/k.

22

fiWhere Hard Manipulation Problems?

manipulators wish win, k manipulators exactly twice weight vetoes
n agents. election finely balanced. preferred candidate manipulators wins
manipulators perfectly partition vetoes two candidates
wish lose. Note precisely trick used reducing number partitioning
manipulation problem Conitzer et al. (2007). Figure 20, plot probability k
manipulators make preferred candidate win hung election vary size
weights w. Similar number partitioning (Gent & Walsh, 1998), see rapid transition
manipulability around log2 (w)/k 1. Figure 21, observe rapid increase
computationally complexity compute manipulation around point.
happens votes less correlated? consider election perfectly
hung except one agent vetoes random one three candidates. Figure 22,
plot cost computing manipulation weight single random veto increases.
Even one uncorrelated vote enough make manipulation easy magnitude
weight vetoes manipulators. suggests find hard manipulation problems
veto elections votes highly correlated.
100000
m=24
m=18
m=12
m=6

average branches

10000

1000

100

10

1

0

0.2

0.4
0.6
log2(w)/log2(w)

0.8

1

Figure 22: impact one random agent manipulability hung veto election. Vetoes
manipulators weighted weights uniformly drawn (0, w], nonmanipulating agents vetoed candidate manipulators wish win,
sum weights manipulators twice non-manipulators
except one random non-manipulating agent whose weight uniformly drawn
(0, w0 ]. vertical axis measures mean number search branches explored
Korfs algorithm decide coalition k agents manipulate veto election.
horizontal axis measures log2 (w0 )/ log2 (w). veto one random agent
weight agents, computationally easy decide election
manipulated.

10. Related Work
indicated earlier, number theoretical results suggest elections easy manipulate
practice despite worst case NP-hardness results. example, Procaccia Rosenschein proved
scoring rules wide variety distributions votes, size

23

fiWalsh


coalition
o( n), probability change result tends 0,

( n), probability manipulate result tends 1 (Procaccia & Rosenschein,
2007a). also gave simple greedy procedure find manipulation scoring rule
polynomial time probability failure inverse polynomial n (Procaccia &
Rosenschein, 2007b). However, treat result caution junta distributions
used work may limited usefulness (Erdelyi, Hemaspaandra, Rothe, & Spakowski, 2009).
second example, Xia Conitzer shown large class voting rules including
STV, number agents grows, either probability coalition manipulate result
small (as coalition small), probability easily manipulate
result make alternative win large (Xia & Conitzer, 2008a). left open
small interval size coalition coalition large enough manipulate
obviously large enough manipulate result easily.
Friedgut, Kalai Nisan proved voting rule neutral far dictatorial
3 candidates exists agent random manipulation succeeds
probability ( n1 ) (Friedgut et al., 2008). were, however, unable extend proof four
(or more) candidates. recently, Isaksson, Kindler Mossel proved similar result 4
candidates using geometric arguments (Isaksson, Kindler, & Mossel, 2010). Starting
different assumptions again, Xia Conitzer showed random manipulation would succeed
probability ( n1 ) 3 candidates STV, 4 candidates scoring
rule 5 candidates Copeland (Xia & Conitzer, 2008b).
discussed earlier, Coleman Teague proposed algorithms compute manipulations
STV rule (Coleman & Teague, 2007). also conducted empirical study demonstrated relatively small coalitions needed change elimination order STV
rule. observed uniform random elections trivially manipulable using
simple greedy heuristic. hand, results suggest that, manipulation single
agent, often small amount backtracking needed find manipulation prove
none exists.

11. Conclusions
studied empirically whether computational complexity barrier manipulation
STV veto rules manipulating agents complete information
votes. looked number different distributions votes including uniform random
votes, correlated votes drawn urn model, votes sampled real world elections.
looked manipulation single unweighted agent case STV, coalition
weighted agents case veto voting. many elections experiments, easy
compute manipulation prove manipulation possible. situations identified
manipulations computationally difficult find depended either election
hundreds candidates election tightly hung. results increase concern
computational complexity may significant barrier manipulation practice.
lessons learnt study? First, whilst focused STV
veto rules, similar behavior likely voting rules. would, instance, interesting
study Borda rule one rules used practice computing manipulation
NP-hard unweighted votes (Davies et al., 2011; Betzler et al., 2011). would also
interesting study voting rules like Copeland, maximin ranked pairs. rules members
small set voting rules NP-hard manipulate without weights votes
(Xia, Zuckerman, Procaccia, Conitzer, & Rosenschein, 2009). Second, may connection
smoothness phase transition problem hardness. Sharp phase transitions
like propositional satisfiability associated hard decision problems, whilst smooth
transitions associated easy instances NP-hard problems polynomial problems
like 2-colourability. phase transitions observed appear smooth. Third, given
24

fiWhere Hard Manipulation Problems?

insights provided empirical studies, would interesting consider similar studies related
problems. example, computational complexity issue preference elicitation (Conitzer &
Sandholm, 2002b; Walsh, 2008; Pini, Rossi, Venable, & Walsh, 2008)? Fourth, assumed
manipulators complete information votes agents. interesting
future direction determine uncertainty agents voted adds computational
complexity manipulation practice (Conitzer & Sandholm, 2002a; Walsh, 2007; Lang, Pini,
Rossi, Venable, & Walsh, 2007).

Acknowledgments
NICTA funded Australian Government Department Broadband, Communications Digital Economy Australian Research Council ICT Centre
Excellence program. results paper appeared two earlier conference papers
(Walsh, 2009, 2010).

References
Achlioptas, D. (1999). Threshold phenomena random graph colouring satisfiability. Ph.D.
thesis, Department Computer Science, University Toronto.
Achlioptas, D., Chtcherba, A., Istrate, G., & Moore, C. (2001). phase transition 1-in-k
SAT NAE SAT. Proceedings 12th Annual ACM-SIAM Symposium Discrete
Algorithms (SODA01), pp. 719720. Society Industrial Applied Mathematics.
Bailey, D., Dalmau, V., & Kolaitis, P. (2001). Phase transitions PP-complete satisfiability problems. Nebel, B. (Ed.), Proceedings 17th International Joint Conference Artificial
Intelligence (IJCAI 2001), pp. 183189. International Joint Conference Artificial Intelligence, Morgan Kaufmann.
Barbera, S., Berga, D., & Moreno, B. (2009). Single-dipped preferences. UFAE IAE working papers 801.09, Unitat de Fonaments de lAnlisi Econmica (UAB) Institut dAnlisi Econmica
(CSIC).
Bartholdi, J., & Orlin, J. (1991). Single transferable vote resists strategic voting. Social Choice
Welfare, 8 (4), 341354.
Bartholdi, J., Tovey, C., & Trick, M. (1989). computational difficulty manipulating
election. Social Choice Welfare, 6 (3), 227241.
Berg, S. (1985). Paradox voting urn model: effect homogeneity. Public Choice,
47, 377387.
Betzler, N., Niedermeier, R., & Woeginger, G. (2011). Unweighted coalitional manipulation
Borda rule NP-hard. Walsh, T. (Ed.), Proceedings 22nd International Joint
Conference Artificial Intelligence (IJCAI 2011). International Joint Conference Artificial
Intelligence.
Black, D. (1948). rationale group decision-making. Journal Political Economy, 56 (1),
2334.
Brandt, F., Brill, M., Hemaspaandra, E., & Hemaspaandra, L. (2010). Bypassing combinatorial
protections: Polynomial-time algorithms single-peaked electorates. Fox, M., & Poole,
D. (Eds.), Proceedings 24th AAAI Conference Artificial Intelligence (AAAI 2010).
AAAI Press.
Chamberlin, J. (1985). investigation relative manipulability four voting systems.
Behavioral Science, 30, 195203.
25

fiWalsh

Cheeseman, P., Kanefsky, B., & Taylor, W. (1991). really hard problems are. Mylopoulos, J., & Reiter, R. (Eds.), Proceedings 12th International Joint Conference
Artificial Intelligence (IJCAI 1991), pp. 331337. International Joint Conference Artificial
Intelligence.
Coleman, T., & Teague, V. (2007). complexity manipulating elections. Gudmundsson,
J., & Jay, B. (Eds.), Proceedings 13th Australasian Symposium Theory Computing
(CATS 07), pp. 2533. Australian Computer Society, Inc.
Conitzer, V. (2007). Eliciting single-peaked preferences using comparison queries. Durfee, E.,
Yokoo, M., Huhns, M., & Shehory, O. (Eds.), Proceedings 6th International Joint Conference Autonomous Agents Multiagent Systems (AAMAS 2007), pp. 408415. IFAAMAS.
Conitzer, V. (2009). Eliciting single-peaked preferences using comparison queries. Journal Artificial Intelligence Research, 35, 161191.
Conitzer, V., & Sandholm, T. (2002a). Complexity manipulating elections candidates.
Dechter, R., Kearns, M., & Sutton, R. (Eds.), Proceedings 18th National Conference
Artificial Intelligence (AAAI 2002), pp. 314319. Association Advancement Artificial
Intelligence.
Conitzer, V., & Sandholm, T. (2002b). Vote elicitation: Complexity strategy-proofness.
Dechter, R., Kearns, M., & Sutton, R. (Eds.), Proceedings 18th National Conference
Artificial Intelligence (AAAI 2002), pp. 392397. Association Advancement Artificial
Intelligence.
Conitzer, V., & Sandholm, T. (2006). Nonexistence voting rules usually hard manipulate. Gil, Y., & Mooney, R. (Eds.), Proceedings 21st National Conference Artifical
Intelligence (AAAI 2006), pp. 627634. Association Advancement Artificial Intelligence.
Conitzer, V., Sandholm, T., & Lang, J. (2007). elections candidates hard
manipulate?. Journal Association Computing Machinery, 54 (3). Article 14 (33
pages).
Davies, J., Katsirelos, G., Narodytska, N., & Walsh, T. (2011). Complexity algorithms
Borda manipulation. Burgard, W., & Roth, D. (Eds.), Proceedings Twenty-Fifth
AAAI Conference Artificial Intelligence (AAAI 2011). AAAI Press.
Dobra, J. (1983). approach empirical studies voting paradoxes: update extension..
Public Choice, 41, 241250.
Dubois, O., Monasson, R., Selman, B., & Zecchina, R. (2001). Special issue: Phase transitions
combinatorial problems. Theoretical Computer Science, 265 (12), 1306.
Dyer, J., & Miles, R. (1976). actual application collective choice theory selection
trajectories Mariner Jupiter/Saturn 1977 project. Operations Research, 24 (2), 220244.
Erdelyi, G., Hemaspaandra, L., Rothe, J., & Spakowski, H. (2009). Generalized Juntas NP-hard
sets. Theoretical Computer Science, 410 (38-40), 39954000.
Faliszewski, P., Hemaspaandra, E., & Hemaspaandra, L. (2010). Using complexity protect elections. Communications ACM, 53 (11), 7482.
Faliszewski, P., Hemaspaandra, E., Hemaspaandra, L., & Rothe, J. (2009). shield never
was: societies single-peaked preferences open manipulation control.
Heifetz, A. (Ed.), Proceedings 12th Conference Theoretical Aspects Rationality
Knowledge (TARK-2009), pp. 118127.
Faliszewski, P., Hemaspaandra, E., & Schnoor, H. (2008). Copeland voting: ties matter. Padgham,
L., Parkes, D., Muller, J., & Parsons, S. (Eds.), 7th International Joint Conference Autonomous Agents Multiagent Systems (AAMAS 2008), pp. 983990.

26

fiWhere Hard Manipulation Problems?

Faliszewski, P., & Procaccia, A. (2010). AIs war manipulation: winning?. AI Magazine,
31 (4), 5364.
Friedgut, E., Kalai, G., & Nisan, N. (2008). Elections manipulated often. Proceedings
49th Annual IEEE Symposium Foundations Computer Science (FOCS 2008), pp.
243249. IEEE Computer Society Press.
Gent, I., Hoos, H., Prosser, P., & Walsh, T. (1999). Morphing: Combining structure randomness.
Hendler, J., & Subramanian, D. (Eds.), Proceedings 16th National Conference
Artificial Intelligence (AAAI 1999), pp. 654660. Association Advancement Artificial
Intelligence.
Gent, I., MacIntyre, E., Prosser, P., Smith, B., & Walsh, T. (2001). Random constraint satisfaction:
Flaws structure. Constraints, 6 (4), 345372.
Gent, I., MacIntyre, E., Prosser, P., & Walsh, T. (1995). Scaling effects CSP phase transition. Montanari, U., & Rossi, F. (Eds.), Proceedings 1st International Conference
Principles Practices Constraint Programming (CP-95), Vol. 976 Lecture Notes
Computer Science, pp. 7087. Springer-Verlag.
Gent, I., & Walsh, T. (1994). SAT phase transition. Cohn, A. (Ed.), Proceedings 11th
European Conference Artificial Intelligence (ECAI-94), pp. 105109. John Wiley & Sons.
Gent, I., & Walsh, T. (1995). Phase transitions real computational problems. Proceedings
8th International Symposium Artificial Intelligence: Intelligent Systems Applications
Industry Business, pp. 356364.
Gent, I., & Walsh, T. (1996a). Phase transitions annealed theories: Number partitioning
case study. Wahlster, W. (Ed.), Proc. 12th European Conference Artificial
Intelligence (ECAI-96), pp. 170174. John Wiley Sons, Chichester.
Gent, I., & Walsh, T. (1996b). satisfiability constraint gap. Artificial Intelligence, 81 (12),
5980.
Gent, I., & Walsh, T. (1996c). TSP phase transition. Artificial Intelligence, 88, 349358.
Gent, I., & Walsh, T. (1998). Analysis heuristics number partitioning. Computational Intelligence, 14 (3), 430451.
Gent, I., & Walsh, T. (1999). Beyond NP: QSAT phase transition. Hendler, J., & Subramanian,
D. (Eds.), Proceedings 16th National Conference AI, pp. 648653. Association
Advancement Artificial Intelligence.
Gibbard, A. (1973). Manipulation voting schemes: general result. Econometrica, 41, 587601.
Gomes, G., & Walsh, T. (2006). Randomness structure. Rossi, F., van Beek, P., & Walsh,
T. (Eds.), Handbook Constraint Programming, Foundations Artificial Intelligence, pp.
639664. Elsevier.
Hartmann, A., & Weigt, M. (2005). Phase Transitions Combinatorial Optimization Problems:
Basics, Algorithms Statistical Mechanics. Wiley-VCH, Weinheim.
Isaksson, M., Kindler, G., & Mossel, E. (2010). geometry manipulation: quantitative proof
Gibbard-Satterthwaite theorem. 51th Annual IEEE Symposium Foundations
Computer Science (FOCS 2010), pp. 319328. IEEE Computer Society.
Karmarkar, N., Karp, R., Lueker, J., & Odlyzko, A. (1986). Probabilistic analysis optimum
partitioning. Journal Applied Probability, 23, 626645.
Korf, R. (1995). approximate optimal solutions: case study number partitioning.
Mellish, C. S. (Ed.), Proceedings 14th International Joint Conference Artificial Intelligence (IJCAI 1995), pp. 266272. International Joint Conference Artificial Intelligence.

27

fiWalsh

Lang, J., Pini, M., Rossi, F., Venable, B., & Walsh, T. (2007). Winner determination sequential
majority voting. Veloso, M. M. (Ed.), Proceedings 20th International Joint Conference Artificial Itelligence (IJCAI-2007), pp. 13721377. International Joint Conference
Artificial Intelligence.
McCabe-Dansted, J., & Slinko, A. (2006). Exploratory analysis similarities social choice
rules. Group Decision Negotiation, 15, 77107.
Mertens, S. (2001). physicists approach number partitioning. Theoretical Computer Science,
265 (1-2), 79108.
Mitchell, D., Selman, B., & Levesque, H. (1992). Hard Easy Distributions SAT Problems.
Proceedings 10th National Conference AI, pp. 459465. Association Advancement
Artificial Intelligence.
Pini, M., Rossi, F., Venable, K., & Walsh, T. (2008). Dealing incomplete agents preferences
uncertain agenda group decision making via sequential majority voting. Brewka,
G., & Lang, J. (Eds.), Principles Knowledge Representation Reasoning: Proceedings
Eleventh International Conference (KR 2008), pp. 571578. AAAI Press.
Procaccia, A. D., & Rosenschein, J. S. (2007a). Average-case tractability manipulation voting
via fraction manipulators. Durfee, E. H., Yokoo, M., Huhns, M. N., & Shehory, O.
(Eds.), Proceedings 6th International Joint Conference Autonomous Agents Multiagent Systems (AAMAS-07), pp. 718720. IFAAMAS.
Procaccia, A. D., & Rosenschein, J. S. (2007b). Junta distributions average-case complexity
manipulating elections. Journal Artificial Intelligence Research, 28, 157181.
Prosser, P. (1994). Binary constraint satisfaction problems: harder others. Cohn,
A. G. (Ed.), Proceedings 11th European Conference Artificial Intelligence, pp. 9599.
European Conference Artificial Intelligence, John Wiley Sons.
Satterthwaite, M. (1975). Strategy-proofness Arrows conditions: Existence correspondence
theorems voting procedures social welfare functions. Journal Economic Theory, 10,
187216.
Slaney, J., & Walsh, T. (2002). Phase transition behavior: decision optimization. Proceedings 5th International Symposium Theory Applications Satisfiability
Testing, SAT 2002.
Slinko, A., & White, S. (2008). Non- dictatorial social choice rules safely manipulable.
Goldberg, U. E. . P. W. (Ed.), Proceedings 2nd International Workshop Computational
Social Choice (COMSOC08), pp. 403413.
Smith, B. (1994). phase transition constraint satisfaction problems: closer look
mushy region. Cohn, A. G. (Ed.), Proceedings 11th European Conference Artificial
Intelligence, pp. 100104. European Conference Artificial Intelligence, John Wiley Sons.
Tideman, T. (1987). Independence clones criterion voting rules. Social Choice
Welfare, 4, 185206.
Walsh, T. (1998). constrainedness knife-edge. Mostow, J., & Rich, C. (Eds.), Proceedings
15th National Conference AI, pp. 406411. Association Advancement Artificial
Intelligence.
Walsh, T. (1999). Search small world. Dean, T. (Ed.), Proceedings 16th International
Joint Conference Artificial Itelligence (IJCAI-99), pp. 11721177. International Joint Conference Artificial Intelligence, Morgan Kaufmann.
Walsh, T. (2001). Search high degree graphs. Nebel, B. (Ed.), Proceedings 17th International Joint Conference Artificial Itelligence (IJCAI-2001), pp. 266274. International
Joint Conference Artificial Intelligence, Morgan Kaufmann.
28

fiWhere Hard Manipulation Problems?

Walsh, T. (2002). P NP: COL, XOR, NAE, 1-in-k, Horn SAT. Dechter, R., Kearns,
M., & Sutton, R. (Eds.), Proceedings 17th National Conference AI (AAAI 2002), pp.
695700. Association Advancement Artificial Intelligence.
Walsh, T. (2007). Uncertainty preference elicitation aggregation. Proceedings 22nd
National Conference AI, pp. 38. Association Advancement Artificial Intelligence.
Walsh, T. (2008). Complexity terminating preference elicitation. Padgham, L., Parkes, D. C.,
Muller, J. P., & Parsons, S. (Eds.), 7th International Joint Conference Autonomous Agents
Multiagent Systems (AAMAS 2008), pp. 967974. IFAAMAS.
Walsh, T. (2009). really hard manipulation problems? phase transition
manipulating veto rule. Boutilier, C. (Ed.), Proceedings 21st International Joint
Conference Artificial Itelligence (IJCAI-2009), pp. 324329. International Joint Conference
Artificial Intelligence.
Walsh, T. (2010). empirical study manipulability single transferable voting. Coelho,
H., Studer, R., & Wooldridge, M. (Eds.), Proc. 19th European Conference Artificial
Intelligence (ECAI-2010), Vol. 215 Frontiers Artificial Intelligence Applications, pp.
257262. IOS Press.
Xia, L., & Conitzer, V. (2008a). Generalized scoring rules frequency coalitional manipulability. Fortnow, L., Riedl, J., & Sandholm, T. (Eds.), EC 08: Proceedings 9th ACM
conference Electronic Commerce, pp. 109118. ACM.
Xia, L., & Conitzer, V. (2008b). sufficient condition voting rules frequently manipulable.
Fortnow, L., Riedl, J., & Sandholm, T. (Eds.), Proceedings 9th ACM conference
Electronic Commerce (EC 08), pp. 99108. ACM.
Xia, L., Zuckerman, M., Procaccia, A., Conitzer, V., & Rosenschein, J. (2009). Complexity
unweighted coalitional manipulation common voting rules. Boutilier, C. (Ed.),
Proceedings 21st International Joint Conference Artificial Intelligence (IJCAI 2009),
pp. 348353. International Joint Conference Artificial Intelligence.
Zhang, W., & Korf, R. (1996). study complexity transitions asymmetic traveling salesman
problem. Artificial Intelligence, 81 (1-2), 223239.

29

fiJournal Artificial Intelligence Research 42 (2011) 719-764

Submitted 03/11; published 12/11

Defeasible Inclusions Low-Complexity DLs
Piero A. Bonatti
Marco Faella
Luigi Sauro

BONATTI @ NA . INFN .
MFAELLA @ NA . INFN .
SAURO @ NA . INFN .

Dipartimento di Scienze Fisiche,
Universita di Napoli Federico II

Abstract
applications OWL RDF (e.g. biomedical knowledge representation
semantic policy formulation) call extensions languages nonmonotonic constructs
inheritance overriding. Nonmonotonic description logics studied many
years, however practical knowledge representation languages exist, due combination
semantic difficulties high computational complexity. Independently, low-complexity description logics DL-lite EL introduced incorporated OWL standard.
Therefore, interesting see whether syntactic restrictions characterizing DL-lite EL
bring computational benefits nonmonotonic versions, too. paper extensively investigate computational complexity Circumscription knowledge bases formulated
DL-liteR , EL, fragments thereof. identify fragments whose complexity ranges P
second level polynomial hierarchy, well fragments whose complexity raises
PSPACE beyond.

1. Introduction
ontologies core semantic web well ontology languages RDF, OWL,
related Description Logics (DLs) founded fragments first-order logic inherit
strengths weaknesses well-established formalism. Limitations include monotonicity,
consequent inability design knowledge bases (KBs) describing prototypes whose general
properties later refined suitable exceptions. natural, iterative approach commonly used biologists calls extension DLs defeasible inheritance overriding (a mechanism normally supported object-oriented languages). workarounds
devised particular cases; however, general solutions currently available (Rector, 2004;
Stevens, Aranguren, Wolstencroft, Sattler, Drummond, Horridge, & Rector, 2007). Another motivation nonmonotonic DLs stems recent development policy languages based DLs
(Uszok, Bradshaw, Jeffers, Suri, Hayes, Breedy, Bunch, Johnson, Kulkarni, & Lott, 2003; Finin,
Joshi, Kagal, Niu, Sandhu, Winsborough, & Thuraisingham, 2008; Zhang, Artale, Giunchiglia, &
Crispo, 2009; Kolovski, Hendler, & Parsia, 2007). DLs nicely capture role-based policies facilitate integration semantic web policy enforcement reasoning semantic metadata
(which typically necessary order check policy conditions). However, order formulate
standard default policies open closed policies,1 support common policy language
features authorization inheritance exceptions (which meant facilitate incremental
1. explicit authorization specified given access request, open policy permits access
closed policy denies it.
c
2011
AI Access Foundation. rights reserved.

fiB ONATTI , FAELLA , & AURO

policy formulation), necessary adopt nonmonotonic semantics; Bonatti Samarati (2003)
provide details matter.
Given increasing size semantic web ontologies RDF bases, complexity reasoning influential factor may either foster prevent adoption knowledge representation language. Accordingly, OWL2 introduces profiles adopt syntactic restrictions (compatible
application requirements) order make reasoning tractable. Two profiles based
following families DLs: DL-lite (Calvanese, De Giacomo, Lembo, Lenzerini, & Rosati,
2005), formalizes RDFS, EL (Baader, 2003; Baader, Brandt, & Lutz, 2005), extensively covers important biomedical ontologies GALEN SNOMED. Unfortunately,
general, nonmonotonic DL reasoning highly complex reach NExpTimeNP even 3ExpTime (Donini, Nardi, & Rosati, 1997, 2002; Bonatti, Lutz, & Wolter, 2009). natural question,
context, whether restrictions adopted DL-lite EL help reducing
complexity nonmonotonic DL reasoning, too.
Answering question main goal paper. extensively investigate complexity reasoning DL-lite EL. nonmonotonic semantics adopted Circumscription
(McCarthy, 1980), whose main appealing properties (discriminating Circumscription
nonmonotonic DL semantics proposed literature) summarized below:
1. Circumscription compatible interpretation domains supported classical DLs;
need adopting fixed domain standard names;
2. circumscribed DLs, nonmonotonic inferences apply individuals, including
denoted constants implicitly asserted existential quantifiers;
3. Circumscription naturally supports priorities among conflicting nonmonotonic axioms
easily simulate specificity-based overriding.
attempt simplify usage circumscribed DLs simultaneously remove potential
sources computational complexity, support usage abnormality predicates (McCarthy, 1986) full generality; rather hide within defeasible inclusions (Bonatti,
Faella, & Sauro, 2009). Defeasible inclusions expressions C vn whose intuitive meaning
is: instance C normally instance D. inclusions prioritized resolve
conflicts. Priorities either explicit automatically determined inclusions specificity,
i.e. defeasible inclusion C1 vn D1 may override C2 vn D2 C1 classically subsumed
C2 . framework, prove restricting syntax DL-lite inclusions sufficesin almost
casesto reduce complexity second level polynomial hierarchy. contrary,
circumscribed EL still ExpTime-hard restrictions needed confine complexity within second level polynomial hierarchy. Syntactic restrictions analyzed
conjunction semantic parameters, kind priorities adopted (explicit
specificity-based), predicates may may affected Circumscription (i.e., fixed
variable predicates, Circumscriptions jargon).
paper organized follows: First, basics low-complexity description logics
extension based circumscription recalled Section 2 Section 3, respectively. Then,
reductions used eliminate language features work simpler frameworks
illustrated Section 4. undecidability result caused fixed roles (Section 5), paper
focuses variable roles: complexity circumscribed DL-liteR EL/EL investigated
720

fiD EFEASIBLE NCLUSIONS L OW-C OMPLEXITY DL

Name

Syntax

inverse role

R

nominal
negation
conjunction
existential
restriction
top
bottom

{a}
C
C uD
R.C
>


Semantics


(R ) = {(d, e) | (e, d) RI }
{aI }
\ C
C DI
{d | (d, e) RI : e C }
>I =
=

Figure 1: Syntax semantics DL constructs.

Section 6 Section 7, respectively. section related work final discussion conclude
paper.

2. Preliminaries
DLs, concepts inductively defined set constructors, starting set NC concept
names, set NR role names, (possibly) set NI individual names (all countably infinite).
use term predicates refer elements NC NR . Hereafter, letters B range
NC , P range NR , a, b, c range NI . concepts DLs dealt
paper formed using constructors shown Figure 1. There, inverse role constructor
role constructor, whereas remaining constructors concept constructors. Letters
C, range concepts letters R, (possibly inverse) roles.
semantics concepts defined terms interpretations = (I , ).
domain non-empty set individuals interpretation function maps concept
name NC set AI , role name P NR binary relation P ,
individual name NI individual aI . extension inverse roles arbitrary
concepts inductively defined shown third column Figure 1. interpretation
called model concept C C 6= . model C, also say C satisfied I.
(strong) knowledge base finite set (i) concept inclusions (CIs) C v C
concepts, (ii) concept assertions A(a) role assertions P (a, b), a, b individual
names, P NR , NC , (iii) role inclusions (RIs) R v R0 . interpretation satisfies (i) CI
C v C DI , (ii) assertion C(a) aI C , (iii) assertion P (a, b) (aI , bI ) P ,
(iv) RI R v R0 iff RI R0 . Then, model strong knowledge base iff satisfies
elements S. write C vS iff models S, satisfies C v D.
Terminologies particular strong knowledge bases consisting definitions, i.e. axioms
C, abbreviate inclusions v C C v A. terminology contains
definition, say defined C definition A. defined
must unique definition. concept name directly depends B (in ) B occurs
definition; moreover, depends B (in ) chain direct dependencies
leading B. terminology acyclic depends . Terminologies
conservative extensions, concept names defined acyclic terminology
721

fiB ONATTI , FAELLA , & AURO

eliminated unfolding w.r.t. , is, exhaustively replacing concepts defined
definition. expressions (i.e., concepts inclusions) E, denote unf(E, )
unfolding E w.r.t. .
logic DL-liteR (Calvanese et al., 2005) restricts concept inclusions expressions CL v
CR ,
CL ::= | R

R ::= P | P

CR ::= CL | CL

(as usual, R abbreviates R.>).
logic EL (Baader, 2003; Baader et al., 2005) restricts knowledge bases assertions
concept inclusions built following constructs:
C ::= | > | C1 u C2 | P.C
(note inverse roles supported). extension EL , role hierarchies,
nominals (respectively) denoted EL , ELH, ELO. Combinations allowed:
example ELHO denotes extension EL supporting role hierarchies nominals. Finally,
ELA denotes extension negation applied concept names.

3. Defeasible Knowledge
general defeasible inclusion (GDI) expression C vn whose intended meaning is: Cs
elements normally D.
Example 3.1 (Bonatti et al., 2009) sentences: humans, heart usually located
left-hand side body; humans situs inversus, heart located right-hand side
body (Rector, 2004; Stevens et al., 2007) formalized EL axioms GDIs:
Human vn heart.has position.Left ;
Situs Inversus v heart.has position.Right ;
heart.has position.Left u
heart.has position.Right v .

2

defeasible knowledge base (DKB) logic DL pair hK, i, K = KS KD , KS
strong DL KB, KD set GDIs C vn C v DL inclusion, strict
partial order (a priority relation) KD . following, C v[n] denote inclusion
either classical defeasible. Moreover, DKB KB = hK , i, (classical)
acyclic terminology, denote unf(KB) = hK0 , 0 DKB K0 unfolding
inclusions K w.r.t. , and, DIs , 0 K, relation unf(, ) 0 unf( 0 , ) holds
0 .
priority relation shall often adopt specificity relation K determined
classically valid inclusions. Formally, GDIs 1 = (C1 vn D1 ) 2 = (C2 vn D2 ), let
1 K 2 iff C1 vKS C2 C2 6vKS C1 .
722

fiD EFEASIBLE NCLUSIONS L OW-C OMPLEXITY DL

Example 3.2 access control policy: Normally users cannot read project files; staff read
project files; blacklisted staff granted access encoded with:
Staff v User
Blacklisted v Staff
UserRequest v subj.User u target.Proj u op.Read
StaffRequest v subj.Staff u target.Proj u op.Read
UserRequest vn decision.{Deny}
StaffRequest vn decision.{Grant}
subj.Blacklisted v decision.{Deny}
decision.{Grant} u decision.{Deny} v .
Staff members cannot simultaneously satisfy two defeasible inclusions (due last inclusion
above). specificity, second defeasible inclusion overrides first one yields intuitive inference non-blacklisted staff members indeed allowed access project files.
formally, subsumption
subj.(Staff u Blacklisted) u target.Proj u op.Read v decision.{Grant}
holds models knowledge base (as defined below).

2

Intuitively, model hK, model KS maximizes set individuals satisfying
defeasible inclusions KD , resolving conflicts means priority relation whenever
possible. formalizing notion model, one specify deal predicates
occurring knowledge base: extension allowed vary order satisfy defeasible
inclusions? discussion effects letting predicates vary vs. fixing extension
found work Bonatti, Lutz Wolter (2006); conclude appropriate choice
application dependent. So, general, set predicates NC NR arbitrarily partitioned
two sets F V containing fixed varying predicates, respectively; denote semantics
CircF .
However, Section 5 shown fixed roles cause undecidability issues,
results concern specialized framework role names varying predicates, is,
F NC . use notation CircF (rather CircF ) indicate F NC .
set F , GDIs KD , priority relation induce strict partial order interpretations. move ordering find interpretations normal w.r.t.
KD . = (C vn D) interpretations let set individuals satisfying be:
satI () = {x | x 6 C x DI } .
Definition 3.3 Let KB = hK, DKB. interpretations J , F NC NR ,
let <KB,F J iff:
1. = J ;
2. aI = aJ , NI ;
3. AI = AJ , F NC , P = P J , P F NR ;
723

fiB ONATTI , FAELLA , & AURO

4. KD , satI () 6 satJ () exists 0 KD 0
satI ( 0 ) satJ ( 0 ) ;
5. exists KD satI () satJ ().
subscript KB omitted clear context. model DKB defined
maximally preferred model strong (i.e. classical) part.
Definition 3.4 Let KB = hK, F NC NR . interpretation model CircF (KB)
iff (classical) model KS models J KS , J 6<F I.
Remark 3.5 semantics special case circumscribed DLs introduced Bonatti et
al. (2006). correspondence seen (i) introducing GDI C vn fresh atomic
concept Ab, playing role abnormality predicate; (ii) replacing C vn C uAb v D;
(iii) minimizing predicates Ab introduced above.
order enhance readability, use following notation special cases
concept names varying case fixed: <var Circvar stand
< Circ , respectively; <fix Circfix stand respectively <NC CircNC . DKB
KB = hKS KD , i, say interpretation classical model KB case model
KS .
paper, consider following standard reasoning tasks defeasible DLs:
Knowledge base consistency Given DKB KB, decide whether CircF (KB) model.
Concept consistency Given concept C DKB KB, check whether C satisfiable w.r.t. KB,
is, whether model CircF (KB) exists C 6= .
Subsumption Given two concepts C, DKB KB, check whether CircF (KB) |= C v D,
is, whether models CircF (KB), C DI .
Instance checking Given NI , concept C, DKB KB, check whether CircF (KB) |=
C(a), is, whether models CircF (KB), aI C .
following example illustrates tasks well main difference
Circvar Circfix .
Example 3.6 Consider following simplification Example 3.2:
User vn decision.{Grant}
Staff v User
Staff vn decision.{Grant}
BlacklistedStaff v Staff u decision.{Grant} .
Extend knowledge base assertion Staff(John), let priority relation K (i.e.,
priorities determined specificity). Denote resulting knowledge base KB. Due
inclusion Staff v User, GDI Staff (third line) higher priority GDI User
724

fiD EFEASIBLE NCLUSIONS L OW-C OMPLEXITY DL

(first line). Therefore, models Circvar (KB), John belongs decision.{Grant}
hence following entailments hold:
Circvar (KB) |= {John} v decision.{Grant}
Circvar (KB) |= decision.{Grant}(John)

(subsumption)

(instance checking)

(1)
(2)

Interestingly, John belong BlacklistedStaff, way satisfying top-priority GDI Staff. Analogously, models Circvar (KB), John
member Staff setting maximizes number individuals satisfying GDIs
(as individuals Staff vacuously satisfy GDI Staff values decision).
generally, side effect maximization satI (), Circvar induces sort closedworld assumption concepts exceptional properties (w.r.t. larger concept). Consequently, BlacklistedStaff satisfiable w.r.t. KB, following subsumption holds:
Circvar (KB) |= Staff v {John} .

(3)

contrary, Circfix , User Staff may contain number individuals (other
zero) Circfix allowed change extension atomic concept, even
would satisfy GDIs. Similarly, exist models Circfix (KB) John belong
decision.{Grant} John belongs BlacklistedStaff Circfix allow
change extension satisfy GDIs. consequence, easily verified
BlacklistedStaff satisfiable w.r.t. Circfix (KB), (1), (2), (3) hold Circvar
replaced Circfix . inferences as:
Circfix (KB) |= User u Staff v decision.{Grant} ,

(4)

Circfix (KB) |= Staff u BlacklistedStaff v decision.{Grant} .

(5)
2

Note Circvar one obtain nominals (cf. Staff (3)) without using nominals explicitly
knowledge base. axioms interfere, assertion A(a) GDI vn
suffice make singleton. idea used reductions later on.
next example deals multiple inheritance, particular parent concepts
conflicting properties.
Example 3.7 Let KB consist axioms:
Whale

v

Mammal u SeaAnimal

Mammal vn organ.Lungs
SeaAnimal vn organ.Gills
organ.Lungs

u

organ.Gills v ,

priority relation specificity. Note mammals sea animals conflicting default
properties. models Circvar (KB) Whale empty, way
GDIs satisfied individuals. let KB 0 = KB {Whale(Moby)}. model
725

fiB ONATTI , FAELLA , & AURO

Circvar (KB 0 ), Moby satisfies many GDIs possible, is, exactly one two GDIs KB 0 .
consequence, reasonable inference:2
Circvar (KB 0 ) |= {Moby} v organ.Lungs organ.Gills .
conflict two default properties inherited Moby settled adding simple
axiom like Whale v organ.Lungs, overrides property sea animals. specific
example strong axiom appropriate; note, however, corresponding GDI would
effect K ; instance, have:
Circvar (KB 0 {Whale vn organ.Lungs}) |= {Moby} v organ.Lungs .
Consider Circfix now. expected subsumptions Mammal v organ.Lungs SeaAnimal v
organ.Gills entailed Circfix (KB), Lungs Gills empty
models (as Circfix cannot change extension satisfy GDIs). two GDIs could
enabled forcing Lungs Gills nonempty. done several ways, e.g. via
assertions Lungs(L) inclusions > v aux.Lungs (where aux new auxiliary
role). Let KB 00 denote extension.
Circfix (KB 00 ) |= {Moby} v organ.Lungs organ.Gills ,
(similarly, aforementioned expected consequences entailed Circfix (KB 00 )). conflict
properties inherited Mammal SeaAnimal settled discussed above.
2
impossibility forcing existentials GDIs Circfix , illustrated example,
exploited check whether concept always nonempty. suffices introduce fresh role
aux (in order prevent interference axioms knowledge base) GDI
> vn aux.C. Clearly, subsumption > v aux.C entailed iff C nonempty models
Circfix (KB). Similar ideas used rest paper.
next example artificial. convenient way illustrating interplay specificity
multiple inheritance.
Example 3.8 Let KB following set axioms:
A1 v A01

(6)

A1 vn R1

(12)

A02

(7)

A2 vn R2

(13)

A01
A02

(14)

A2 v
B

v A1 u A2

(8)

R1

u

v

(9)

R2

u

R10
R20

v

(10)

R1

u R2 v

(11)

vn
vn

R10
R20

(15)

sets concept names F , models CircF (KB), member x B (if any)
satisfies exactly one top priority GDIs (12) (13), conflicting due (11). x
2. symbol description logics equivalent disjunction. Formally, (C D)I = C DI .

726

fiD EFEASIBLE NCLUSIONS L OW-C OMPLEXITY DL

satisfy (12) satisfy conflicting GDI (14); symmetrically, x satisfy (13)
x satisfy (15). Consequently, have:
Circfix (KB) |= B v (R1 u R20 ) (R2 u R10 ).
2
last two examples show GDIs disjointness constraints together express disjoint
unions. Similar techniques used later simulate law excluded middle, negation,
3-valued logic.
Subsumption, instance checking, complement concept satisfiability reduced
other, classical setting:
Theorem 3.9 Let DL range DL-liteR EL ; let X = var, fix, F . CircX (DL), subsumption, instance checking, concept unsatisfiability reduced constant
time.
proof completely standard, due limited expressiveness DL-liteR EL ,
well peculiarities nonmonotonic reasoning.3
Proof. First focus Circvar CircF , F consists concept names occurring given
KB.
unsatisfiability subsumption. Checking unsatisfiability concept C reduced
checking subsumption C v . DL-liteR support explicitly, however equivalent
concept easily defined inclusion v .
subsumption unsatisfiability. Conversely, subsumption C v reduced
unsatisfiability C u D. DL-liteR conjunction supported, subsumption must
reduced unsatisfiability fresh variable concept axiomatized v C v D.
EL conjunction supported negation not; therefore given subsumption reduced
unsatisfiability C u fresh variable concept axiomatized u v .
instance checking subsumption. instance checking query C(a) reduced
subsumption follows: Introduce fresh variable concept assert A(a); minimize
vn ; models Circvar , AI = {aI }. follows C(a) holds iff
subsumption v C holds.
unsatisfiability instance checking. Finally, unsatisfiability concept C equivalent validity instance checking problem C(a), fresh individual constant. EL , C must suitably axiomatized fresh concept name C inclusions
C u C v , > vn C, > vn C (these three axioms entail subsumption > v C C, thereby
enforcing law excluded middle). order preserve semantics knowledge
base, > vn C > vn C must given priority strictly smaller priority
defeasible inclusion KB. ensures new GDIs cannot block application
original GDIs. Clearly, two new GDIs must priority.
3. example, classical logic subsumption C v logical consequence KB iff fresh individual a,
D(a) logical consequence KB {C(a)}. approach correct Circumscription. models
CircF (KB) quite different models CircF (KB {C(a)}); instance, consider example
nonmonotonic reasoning makes Whale empty assertion Whale(Moby) overrides inference.

727

fiB ONATTI , FAELLA , & AURO

completes proof Circvar CircF . proof Circfix obtained replacing fresh variable concept names A, C, corresponding (variable) concept R,
R fresh role.
2
Note reductions still apply priorities specificity-based (K ), exception
reduction concept unsatisfiability instance checking EL . case, one use
Theorem 4.6 eliminate general priorities, get reduction Circfix .

4. Complexity Preserving Features
cases, nonmonotonic inferences language featurese.g. variable predicates explicit prioritiesdo affect complexity. section several results (and related lemmata)
collected; reader warned that, general, may apply reasoning tasks
language fragments. start observing logics deal enjoy finite model
property.
Lemma 4.1 Let KB = hK, DKB DL-liteR ELHO, . F NC , CircF (KB)
model CircF (KB) finite model whose size exponential size KB.
Proof. simple adaptation result ALCIO (Bonatti et al., 2006), taking role hierarchies
account.
2
consequence, logics preserve classical consistency (because descending chains
models originating finite model must finite):
Theorem 4.2 Let KB = hKD KS , DKB DL-liteR ELHO, . F NC , KS
(classically) consistent iff CircF (KB) model.
Remark 4.3 Obviously, similar property holds circumscribed DLs finite model
property, including ALCIO ALCQO.
Since knowledge base consistency equivalent classical version, discussed
paper further.
Next, prove mild assumptions, CircF expressive Circfix (which
special case former), is, variable concept names increase expressiveness
logic eliminated.4
Theorem 4.4 DL description logic fully supporting unqualified existential restrictions
( R),5 then, F NC , concept consistency, subsumption, instance checking CircF (DL)
reduced linear time concept consistency, subsumption, instance checking (respectively) Circfix (DL).
4. standard techniques eliminating variable predicates (Cadoli, Eiter, & Gottlob, 1992) use connectives
fully supported DL-liteR EL, therefore ad-hoc proof needed.
5. say DL fully supports unqualified restrictions occur wherever concept name could.

728

fiD EFEASIBLE NCLUSIONS L OW-C OMPLEXITY DL

Proof. Let KB given DKB language DL. Introduce new role name RA
(variable) concept name 6 F . Then, replace occurrence KB RA call
KB 0 resulting KB. Recall Circfix (DL) concept names fixed roles variable. Hence, newly added roles RA behave Circfix (KB 0 ) exactly way concepts
6 F CircF (KB). Formally, bijection models CircF (KB)
models Circfix (KB 0 ), preserves interpretation role concept names, except
extension concept names 6 F model CircF (KB) coincides domain
corresponding role RA corresponding model Circfix (KB 0 ). consequence, consistency concept C w.r.t. CircF (KB) equivalent consistency C 0 w.r.t. Circfix (KB 0 ),
C 0 obtained C replacing occurrence 6 F corresponding RA .
Similarly subsumption instance checking.
2
Symmetrically, next theorem proves EL fixed predicates eliminated using general
priorities. reduction adapts classical encoding fixed predicates limited expressiveness EL .
Theorem 4.5 F NC , concept consistency, subsumption, instance checking
CircF (EL ) reduced linear time concept consistency, subsumption, instance checking (respectively) Circvar (EL ) general priorities.
Proof. Let K = hKS KD , given EL DKB. Fixed predicates removed
following transformation. concept name F introduce new concept name
(representing A). Let KS set disjointness axioms u v , F . Let
set defeasible inclusions > v > v A, F . Finally, let 0
KD
n
n
K , 0 . Define
minimal extension KD


K0 = hKS KS KD KD
, 0 .

Claim 1. Let J J 0 two classical models KS KS J 0 <K0 ,var J
, satJ 0 () = satJ () (ii) J J 0 agree
F , AJ = AJ . (i) KD
F.
maximal priority, therefore,
Proof Claim 1: definition 0 , members KD
0
, satJ () satJ (). exists F satJ 0 (> v A) satJ (> v A),
KD
n
n
0
0
0
AJ AJ , hence AJ AJ ; consequently satJ (> vn A) satJ (> vn A) (a
0
contradiction). Symmetrically, assumption satJ (> vn A) satJ (> vn A) leads
contradiction. proves (i); (ii) straightforward consequence (i).
Claim 2. Every model CircF (K) extended model J Circvar (K0 ).
prove claim, extend J setting AJ = AI , concept names F .
Suppose J model Circvar (K0 ). Since J satisfies KS KS construction, must
J 0 satisfies KS KS J 0 <K0 ,var J . Claim 1.(ii), J J 0 agree
F ; Claim 1.(i), improvement J 0 J concerns GDIs KD . follows
0 <K,F I, 0 restriction J 0 language K. contradicts assumption
model CircF (K).
Claim 3. models J Circvar (K0 ), restriction J language K model
CircF (K).
Let restriction J language K. Clearly satisfies KS . suppose
model CircF (K), means exists 0 satisfying KS 0 <K,F I.
729

fiB ONATTI , FAELLA , & AURO

0

0

Extend 0 J 0 setting AJ = AI , concept names F . Note 0 must
,
agree F , therefore J J 0 agree them, too. Consequently, KD
0
satJ () = satJ (). Moreover, 0 improves GDIs KD , therefore J 0 improves J
KD , too. follows J 0 <K0 ,var J (a contradiction).
Theorem straightforward consequence Claims 2 3.
2
consider priority relations GDIs. going prove language fragment
sufficiently rich, simulated specificity-based relation K normalized
defeasible inclusions vn C (whose left-hand side concept name), respectively.
Let KB = hK, given DKB EL . First need define new fixed concept Dom
encodes domain without equivalent >. requires following transformation:
= Dom u

(R.C) = Dom u R.(C )

> = Dom
=

(C u D) = C u
(C v[n] D) = C v[n]

Obtain K K transforming inclusions K adding nonemptiness axiom > v
aux .Dom (aux fresh role) plus assertion Dom(a) NI occurring K.
hard see restrictions Dom classical models K correspond classical
models K. precisely, let classical model K , obtain classical model





K setting AI = AI Dom RI = RI (Dom Dom ), concept name

role name R occurring K. Notice necessary Dom non-empty
work. Conversely, given classical model K, sufficient set Dom =
aux = make classical model K .
remove general priorities GDIs. GDIs = (C vn D) K , add
two fresh predicates , P replace following axiom schemata:
Dom v
vn P

0 v

0

P u C v

(16)
(17)

Call new DKB KB 0 = hK0 , K0 i. (16), specificity-based relation K0 prioritizes new
GDIs according original priorities. Moreover, (17), defeasible inclusion vn P
satisfied individual individual satisfies corresponding GDI .
difficult verify reasoning tasks none new predicates
P occur query yield answer hK , KB 0 . consequence
discussion, combining transformation (16) (17), observing
reduction makes use EL constructs only, have:
Theorem 4.6 Reasoning Circfix (EL ) explicit priorities GDIs reduced polynomial time reasoning Circfix (EL ) specificity-based priority defeasible inclusions form vn P .
Finally, Theorem 4.4, result extended CircF :
Corollary 4.7 Reasoning CircF (EL ) explicit priorities GDIs reduced polynomial time reasoning Circfix (EL ) specificity-based priority defeasible inclusions form vn P .
730

fiD EFEASIBLE NCLUSIONS L OW-C OMPLEXITY DL

5. Undecidability EL Fixed Roles
Circ concept names roles fixed; however, show section, fixed roles
general make reasoning tasks undecidable. end, model conservative extension problem
defined Lutz Wolter (2010) reduced subsumption problem.6
preliminary definitions needed; given signature NC NR two interpretations J , say J coincide = J predicates
X , X = X J . Then, let T1 T2 classical EL TBoxes, T2 model conservative extension T1 every model T1 , exists model J T2 J
coincide signature T1 .
Lutz Wolter (2010) prove (see Lemma 40) exists class C EL TBoxes
problem checking whether TBox C model conservative extension another TBox
C undecidable. Moreover, following property holds.
Lemma 5.1 Given two TBoxes T1 T2 C, T2 model conservative extension T1
exists model T1 interpretation J T2 J coincide
signature T1 set individuals J violate least one concept inclusion T2
finite.
DKB KB = hKS KD , interpretation KB, denote ab KB (I) (for
abnormal) total number individuals x x 6 satI () KD .
Lemma 5.2 Let KB = hKS KD , DKB classical model KB s.t. ab KB (I)
finite. F NC NR , either model CircF (KB) exists model J
CircF (KB) J <KB,F I.
Proof. suffices show <KB,F -chain descending finite. Since DIs incomparable other, step <KB,F -chain must improve least one DI leave
DIs unchanged. Formally, 0 <KB,F exists least DI KD
satI () satI 0 () 0 KD holds satI ( 0 ) satI 0 ( 0 ). Hence, ab KB (I 0 ) < ab KB (I)
thesis follows.
2
Assume T1 , T2 C given, T1 T2 , let signature T1 . Let F =
KB = hK, K = T1 {C vn | C v T2 \ T1 }.
Lemma 5.3 T1 , T2 C, T2 model conservative extension T1 iff CircF (KB) |= C v
D, C v T2 .
Proof. [if ] Suppose contradiction T2 model conservative extension T1
CircF (KB) |= C v D, C v T2 . Lemma 5.1, consider model
T1 extension J signature T2 , set individuals violate J
least one inclusion T2 finite. Since J classical model KB ab KB (J ) finite,
Lemma 5.2, exists model J 0 CircF (KB) either J 0 = J J 0 <KB,F J . Since
CircF (KB) entails T2 F = , J 0 (classical) model T2 coincides J
(absurdum).
6. sketch proof kindly provided Frank Wolter personal communication. imprecision
proof due authors.

731

fiB ONATTI , FAELLA , & AURO

[only ] Suppose contradiction T2 model conservative extension T1 ,
C v T2 , holds CircF (KB) 6|= C v D. Since CircF (KB) 6|= C v D, exists model
CircF (KB) satI (C vn D) . Since model T1 T2 model
conservative extension T1 , exists interpretation J (i) coincides
(ii) model T2 , i.e., defeasible inclusions C vn KB, satJ (C vn D) = J .
Therefore, J <KB,F (absurdum).
2
Since checking whether TBox model conservative extension another one proved
undecidable C EL (Lutz & Wolter, 2010), immediately follows subsumption
CircF (EL) undecidable. Moreover, since subsumption reduced concept unsatisfiability
instance checking (Theorem 3.9), latter reasoning tasks undecidable well.
Theorem 5.4 CircF (EL), subsumption, concept consistency instance checking undecidable.

6. Complexity Circumscribed DL-liteR
section focus DL-liteR DKBs. first prove Circvar (DL-liteR ) reasoning
tasks complete second level polynomial hierarchy. this, according Theorem 4.4, immediately obtain hardness result Circfix (DL-liteR ) too. Then, membership
Circfix (DL-liteR ) second level polynomial hierarchy shown fragment DKBs
left-fixed defeasible inclusions, i.e. defeasible inclusions type vn C.
6.1 Complexity Circvar (DL-liteR )
section prove Circvar (DL-liteR ) subsumption, concept unsatisfiability (co-sat)
instance checking complete p2 .
membership results rely possibility extracting small (polynomial) model
model circumscribed DKB.
Lemma 6.1 Let KB DL-liteR DKB. models Circvar (KB) x
exists model J Circvar (KB) (i) J , (ii) x J , (iii) DL-liteR concepts
C, x C iff x C J (iv) |J | polynomial size KB.
Proof. Assume KB = hKS KD , i, model Circvar (KB), x . Let cl(KB)
set concepts occurring KB. Choose minimal set containing: (i) x, (ii)
aI NI cl(KB), (iii) concept R cl(KB) satisfied I, node yR
z RI , (z, yR ) RI .
define J follows: (i) J = , (ii) aJ = aI (for NI cl(KB)), (iii) AJ = AI
(A NC cl(KB)), (iv) P J = {(z, yP ) | z z P } {(yP , z) | z z

P } (P NR ).
Note construction, z J C cl(KB), z C J iff z C ;
consequently, J classical model S. Moreover, cardinality J linear size
KB (by construction). left show J <KD ,var -minimal model KB.
0
0
Suppose not, consider J 0 <KD ,var J . Define 0 follows: (i) = , (ii) aI =
0
0
0
0
0
aI , (iii) AI = AJ , (iv) P = P J . Note elements \J satisfy left-hand side
DL-liteR inclusion (be classical defeasible), therefore inclusions vacuously satisfied.
732

fiD EFEASIBLE NCLUSIONS L OW-C OMPLEXITY DL

0

Moreover, restriction 0 J <KD ,var -smaller corresponding restriction
interpretation ordering. follows 0 <KD ,var I, hence cannot model
Circvar (KB) (a contradiction).
2

2

x

Q

x
1

C

S,

1
Q

Q

Q
4

3

C

Q

6






Q

4





6




C v Q
Q v
vn

5

7

8

(b) model K.

(a) DKB K.

7

8

(c) small model extracted
model Figure 2(b). Dashed
arrows denote edges
present I.

Figure 2: Illustrating Lemma 6.1.
illustrate Lemma 6.1, consider DKB KB Figure 2(a) model Figure 2(b).
Note individuals satisfy defeasible inclusion KB. small model J , depicted
Figure 2(c), obtained follows. First, contains designated individual x; then,
concept R occurs KB satisfied (where R possibly inverse role), contains
representative yR receives role R I. case, assume chosen representatives are:
yQ = 6, yQ = 4, yS = 8, yT = 7. Hence, J = {x, 6, 4, 8, 7}. roles J obtained
connecting individual z satisfies concept P chosen representative yP .
instance, since 4 satisfies I, edge (4, 8) J . Moreover, representative
inverse role P connected nodes satisfy concept P I. case, since
4 representative Q 6 satisfies Q , edge (4, 6) QJ . Besides, since 4
satisfies Q , also (4, 4) QJ . verified inspection J model
Circvar (KB), individuals satisfy classical defeasible inclusions KB.
Theorem 6.2 Concept consistency Circvar (DL-liteR ) DKBs p2 . Subsumption instance checking p2 .
Proof. Lemma 6.1, suffices guess polynomial size model provides answer
given reasoning problem. Then, NP oracle, possible check model minimal
w.r.t. <var .
2
complexity upper bounds proved Theorem 6.2 fact tight, stated Theorem 6.6.
proof hardness based reduction minimal-entailment problem positive
disjunctive logic programs proved p2 -hard (Eiter & Gottlob, 1995).
clause formula l1 lh , li literals set propositional variables
P V = {p1 , . . . , pn }. positive disjunctive logic program (PDLP short) set clauses
733

fiB ONATTI , FAELLA , & AURO

= {c1 , . . . , cm } cj contains least one positive literal. truth valuation
set P V , containing propositional variables true. truth valuation model
satisfies clauses S. literal l, write |=min l every minimal7 model
satisfies l. minimal-entailment problem defined follows: given PDLP
literal l, determine whether |=min l.
propositional variable pi , 1 n, introduce two concept names Pi Pi ,
latter encodes pi . denote Lj , 1 j 2n, generic Pi Pi . clause cj
introduce concept name Cj . Then, two concept names True False represent
set true false literals, respectively. employ roles RLi , RTrueCj , RFalse Pi , RTrue Pi ,
TLi .
following, defeasible inclusions assigned numerical priority h(), intended meaning 1 2 iff h(1 ) < h(2 ).
first step consists reifying propositional literals, i.e., want
correspond individual. Therefore, introduce axioms:

NonEmpty(a)

(18)

NonEmpty v Li

(1 2n)

(19)

NonEmpty v RLi

(1 2n)

(20)

(1 2n)

(21)

Li v Lj

(1 < j 2n)

(22)

Li vn Li

(1 2n)

(23)

RL


v Li

[priority: 0]

Axioms (18-21) force literal encodings Li non empty. Axioms (22) make literal encodings
pairwise disjoint. Finally, defeasible inclusions (23) used reduce Li singletons.
Then, represent set clauses adding clause cj = lj1 ljk , 1 j m,
following axioms.

Lji v Cj

(1 k)

(24)

Cj vn Cj

[priority: 0]

(25)

NonEmpty v RTrueCj

(26)

RTrueCj

(27)

v TrueCj

TrueCj v True

(28)

TrueCj v Cj

(29)

Axioms (2425) ensure (encoding a) clause Cj union literals Lji . Axioms
(2629) assure clause contains least one true literal. order model concepts

7. respect set inclusion.

734

fiD EFEASIBLE NCLUSIONS L OW-C OMPLEXITY DL

True False correct meaning complementary literals add following axioms.
True v False

(30)

TruePi v RFalse Pi

(1 n)

(31)

(1 n)

(32)

TruePi v Pi

(1 n)

(33)

TruePi v True

(1 n)

(34)

False Pi v False

(1 n)

(35)

False Pi v Pi

(1 n)

(36)

RFalse Pi

v False Pi

previous schemata regard TruePi only; analogous schemata defined FalsePi .
following inclusions ensure truth given literal locally visible individual a,
auxiliary roles TLi .
TrueLi v TL


(1 2n)

(37)

TL


(1 2n)

(38)

(1 2n)

(39)

TrueLi w

TLi v NonEmpty

axioms defined far encode classical semantics S. represent minimal models
add following axioms.
Pi vn FalsePi

(1 n)

[priority: 1]

(40)

Pi vn TruePi

(1 n)

[priority: 2]

(41)

Given PDLP S, call KB defined KB .
Given truth assignment P V domain = {a, d1 , . . . , d2n }, define corresponding interpretation, denoted model (S, I, ), whose structure mirrors I. Formally, model (S, I, )
interpretation = (, ) that:
I. aI = a;
II. NonEmpty = {a};
III. RLIi = {(a, di )} LIi = {(a, di ) | |= li };
IV. 1 2n, LIi = {di };
V. 1 j m, CjI = {LIj1 , . . . , LIjh } cj = lj1 ljh ;
VI. 1 2n, di TrueLIi (resp. di FalseLIi ) iff |= li (resp. 6 |=li );
VII. (X )I = X , X concept name obtained concatenating two
concept names X (for instance, concept name TrueCj obtained concatenating
concept names True Cj ); words, juxtaposition represents conjunction;
VIII. (R X )I = (X )I .
following lemma, proved Appendix, states relationship model (S, I, ).
735

fiB ONATTI , FAELLA , & AURO

Lemma 6.3 Given PDLP P V = {p1 , . . . , pn } truth assignment P V ,
minimal model iff interpretation model (S, I, ) model Circvar (KB ),
domains || = 2n + 1.
following result, also proved Appendix, shows model Circvar (KB ) fact
corresponds minimal model S.
Lemma 6.4 model Circvar (KB ), exist minimal model
pi iff PiI True iff PiI False , = 1, . . . , n.
Lemma 6.5 Given PDLP literal l represented concept name L, following
equivalent:
(minimal entailment) |=min l;
(subsumption) Circvar (KB ) |= L v True;
(co-sat) FalseL satisfiable w.r.t Circvar (KB );
(instance checking) Circvar (KB ) |= (T L)(a).
Proof. three inference problems KB represent fact models Circvar (KB )
LI True empty co-sat particular relies fact Circvar (KB )
models True False partition individuals belonging literal concepts. Therefore, suffices prove l true minimal models iff LI True 6= models
Circvar (KB ).
Lemma 6.3 establishes bijection minimal models certain models =
model (S, I, ) Circvar (KB ), truth literal l corresponds inclusion
LI True (see rule VI definition model ). Therefore, right-to-left direction
immediately satisfied. left-to-right direction, assume l true minimal models
let model Circvar (KB ). Lemma 6.4, minimal model
pi iff PiI True . l = pi , conclude LI True thesis. Similarly, l = pi .
2
following theorem provides complexity lower-bounds main decision problems
Circvar (DL-liteR ) Circfix (DL-liteR ). result Circvar (DL-liteR ) follows immediately
Lemma 6.5, extends Circfix (DL-liteR ) due Theorem 4.4.
Theorem 6.6 Subsumption, co-sat instance checking circumscribed DL-liteR DKBs
general priorities p2 -hard.
6.2 Upper Bound Circfix (DL-liteR ) Restrictions
develop argument used Circvar (DL-liteR ) prove similar upper bounds
Circfix (DL-liteR ) DKBs left-fixed DIs (i.e., left-hand side fixed orequivalently
concept name) empty priority relations. Whether upper bounds apply
Circfix (DL-liteR ) without restriction left open question.
736

fiD EFEASIBLE NCLUSIONS L OW-C OMPLEXITY DL

Lemma 6.7 Let KB DL-liteR knowledge base whose DIs left-fixed. models
Circfix (KB) x exists model J Circfix (KB) (i) J , (ii)
x J , (iii) DL-liteR concepts C, x C iff x C J , (iv) |J | polynomial
size KB.
Proof. Assume model Circfix (KB), KB = hKS KD , i, x . Let
cl(KB) set concepts occurring KB. Choose minimal set containing: (i)
x, (ii) aI NI cl(KB), (iii) concept R cl(KB) satisfied I, node
yR yR (R )I (where P considered equivalent P ), finally (iv)
inclusions C v[n] R KB (C u R)I 6= , node z (C u R)I .
define J follows: (i) J = , (ii) aJ = aI (for NI cl(KB)), (iii) AJ = AI
(A NC cl(KB)), (iv) P J = {(z, yP ) | z z P } {(yP , z) | z z

P } (P NR ).
Note construction, z J C cl(KB), z C J iff z C ;
consequently, J classical model KB. Moreover, cardinality J linear size
KB (by construction). left show J <fix -minimal model KB.
0
0
Suppose not, consider J 0 <fix J . Define 0 follows: (a) = , (b) aI = aI ,
0
0
0
0
(c) AI = AI , (d) RI minimal set (d1) RI RJ , (d2) z \ J ,
0
inclusions C v R C vn R KB z (C u R)I , RJ contains pair
0
0
(v, w), (z, w) RI ; finally, (d3) P closed role inclusion axioms KB.
Note that, construction,
0

(*) z \ J , z RI z RI ;
0

0

0

(**) z \ J , z RI exists v J v RJ .
prove 0 classical model KB. construction, edges (z, w) introduced
(d2) change set existential restrictions satisfied members J ; consequence since J 0 model KB members J satisfy classical CIs
KB.
consider arbitrary element z \J CI KS . inclusion without
existential quantifiers, 0 give interpretation definition, therefore z
satisfies . R v A, R v A, R v S, v R (and considering satisfies
0
) z fails satisfy R0 {R, S}, z 6 (R0 )I z (R0 )I ; impossible
0
0
(*). Next, suppose R v S. z (R)I , (**) exists v J satisfying
0
0
0
(R)J hence (S)J (as J 0 model KS ), therefore z (S)I (by d2). left
0
0
consider = v R: z AI = AI , exists wA AJ (by construction )
0
0
wA (R)J J 0 model KB. z (R)I (d2). Therefore, possible
cases, z satisfies .
proves 0 satisfies strong CIs KB. hard verify 0 satisfies
also role inclusions KB. Therefore, order derive contradiction, left show
0 <fix (which implies model Circfix (KB)). Since assumption J 0 <fix J ,
suffices prove following claim: satJ () satJ 0 () (resp. satJ () satJ 0 ()),
satI () satI 0 () (resp. satI () satI 0 ()).
J , J (resp. 0 J 0 ) satisfy concepts, therefore need show
z \ J , z satI () z satI 0 (). cases
737

fiB ONATTI , FAELLA , & AURO

right-hand side R, proof similar proof strong CIs (it exploits (*) fact
concept names fixed).
Let vn R consider arbitrary z \ J z satI (). Since concept
names fixed, interesting case z actively satisfies , i.e. z (A u R)I .
construction, contains individual v (A u R)J . Since hypothesis satJ () satJ 0 (),
0
0
v (A u R)J hence, (d2), z (R)I , z satI 0 ().
2
prove lemma assumption priority relation empty need
preliminary notions. Given KB KB = hKS KD , i, interpretation individual
z , denote KB [z] classical knowledge base:


KB [z] = KS C v | (C vn D) KD z satI (C vn D)
Then, support concept C I, supp (C), set individuals z that,
A, z AI vKB[z] C. z supp (C) say z supports C I.
Lemma 6.8 Let KB = hK, DL-liteR knowledge base. models Circfix (KB)
x exists model J Circfix (KB) (i) J , (ii) x J , (iii)
DL-liteR concepts C, x C iff x C J , (iv) |J | polynomial size KB.
Proof. Assume model Circfix (KB) let defined proof
Lemma 6.7, except case (iv), replaced by: (iv) inclusions C v[n] R KB
supp (R) 6= , node wR supp (R). is, inclusion whose RHS
variable, pick witness support RHS, witness exists.
Next, define J proof Lemma 6.7. before, J classical model KB
cardinality J linear size KB. left show J <fix -minimal.
Suppose not, consider J 0 <fix J . Since priority relation empty, DIs KB,
satJ () satJ 0 (). Hence, concepts C holds supp J (C) supp J 0 (C). Define 0
proof Lemma 6.7, except case (d2), replaced by: (d2) z \ J ,
0
inclusions C v[n] R KB z supp (R), RJ contains pair (v, w),
0
(z, w) RI . prove 0 <fix I, contradicting hypothesis model
0
0
Circfix (KB). non-trivial case consists proving individuals \ J satisfy
0 inclusions type C v[n] satisfy I.
0
0
Assume z \ J satisfies C v[n] I; distinguish two cases. First,
0
z supp (S), J contains witness wS s.t. wS supp J (S) supp J 0 (S).
0
0
Therefore, exists pair (wS , y) J and, (d2), (z, y) . Second, assume
z 6 supp (S). Since z satI (C v[n] D), z 6 supp (C). Therefore, C = A,
0
0
z 6 AI = AI , whereas C = R, (d2) z 6 (R)I . cases, z vacuously
satisfies 0 .
2
Theorem 6.9 Let KB DKB left-fixed DIs empty priority relation. Concept consistency Circfix (KB) p2 . Subsumption instance checking p2 .
2

Proof. Similar proof Theorem 6.2.
738

fiD EFEASIBLE NCLUSIONS L OW-C OMPLEXITY DL

7. Complexity Circumscribed EL EL
Recall reasoning circumscribed EL undecidable roles fixed. analyze
cases, F NC .
EL, cannot express contradictions, defeasible inclusions cannot possibly blocked
Circvar , circumscription collapses classical reasoning:
Theorem 7.1 Let KB = hKS KD , EL DKB. model Circvar (KB) iff
model KS KD , KD = {A v C | (A vn C) KD }.
Proof. Let model Circvar (KB), let J interpretation (i) J = ,
(ii) NI , aJ = aI , (iii) NC , AJ = J , (iv) P NR , P J =
J J . easily verified structural induction EL concepts C, C J = J
hence domain element J satisfies EL inclusions (strong defeasible). Then,
clearly, J model Circvar (KB). Consequently, KD , satI () = , otherwise
J <var (a contradiction). follows classical model KS KD .
2
results work Baader et al. (2005), follows Circvar (EL), concept satisfiability
trivial, subsumption instance checking P.
Remark 7.2 Clearly, argument result apply Circvar (ELHO).
make EL interesting adding source inconsistency, complexity
increases significantly.
Theorem 7.3 Circvar (EL ), concept satisfiability, instance checking, subsumption
ExpTime-hard. results still hold knowledge bases contain assertion.8
Proof. Let ELA extension EL atomic concepts negated. first reduce
TBox satisfiability ELA (which known ExpTime-hard, see Baader et al., 2005)
complement subsumption Circvar (EL ). Let TBox (i.e., set CIs) ELA . First
introduce concept name occurring fresh concept name whose intended meaning
A. Obtain 0 replacing literal A. Let KB = hK, K DKB
obtained extending 0 following inclusions, U UA occurring
fresh concept names (representing undefined truth values), R fresh role name:
u v

(42)

> vn

(46)

u UA v

(43)

> vn

(47)

u UA v

(44)

> vn UA

(48)

UA v U

(45)

> vn R.UA

(49)

prove satisfiable iff model Circvar (KB) UA empty, holds
iff Circvar (KB) 6|= > v R.U . Consequently, subsumption Circvar (EL ) ExpTime-hard. Assume satisfiable model domain . define interpretation
8. Equivalently, DLs terminology: ABoxes empty.

739

fiB ONATTI , FAELLA , & AURO

J model Circvar (KB) U J = , thus proving Circvar (KB) 6|= > v R.U .
J domain I, concepts roles occurring interpretation
I; need define interpretation newly introduced concepts A, UA , U ,
role R. set AJ = \ AI UAJ = U J = RJ = .
construction J model classical inclusions KB, particular CIs (42)(45).
remains prove J minimal w.r.t. <var , i.e., possible improve DI without
violating another DI either incomparable , higher priority . Notice
defeasible inclusions (46) (resp., (47)) violated individuals AJ (resp., individuals
AJ ). DIs (48) (49) violated individuals. Moreover, notice DIs (46)(49)
mutually incomparable according specificity.
DI type (46) (47) improved expenses corresponding DI
type. Moreover, improving DIs (48) (49) requires setting UAJ 6= , which, due
rules (43) (44) would damage incomparable DIs (46) and/or (47). proves J
model Circvar (KB), hence Circvar (KB) 6|= > v R.U .
Conversely, assume Circvar (KB) 6|= > v R.U , let model Circvar (KB)
individual x x 6 (R.U )I . Due rule (45), x 6 (R.UA )I atomic
concepts A. Hence, x violates DIs type (49). exists concept UA (UA )I
empty, model obtained adding R-edge x individual (UA )I
smaller according <var , contradiction. Therefore, concepts UA empty
I.
Next, show atomic concepts individuals , either AI
AI . Assume contrary, i.e., exists individual belongs neither AI
AI . Then, violates DIs (46)(49). Consider interpretation 0 , obtained setting
0
0
(UA )I = U = {y}. construction 0 satisfies CIs KB. Compared I, status
DIs same, except 0 individual satisfies (48). Hence, 0 <var I,
contradiction. Since individual belongs either AI AI , convert classical
model , thus showing satisfiable.
Similarly, given NI , satisfiable iff exists model Circvar (KB)
aI 6 (R.U )I . Therefore, instance checking Circvar (EL ) ExpTime-hard well.
Finally, add fresh concept name B inclusions B u R.UA v ; call new
DKB KB 0 . Note satisfiable iff model Circvar (KB) UA empty,
holds iff B satisfiable w.r.t. Circvar (KB 0 ). Consequently, concept satisfiability Circvar (EL )
ExpTime-hard.
2
Since Circvar special case CircF , Theorem 4.4, theorem applies CircF
Circfix , too:
Corollary 7.4 X = F, fix, concept satisfiability checking, instance checking, subsumption
CircX (EL ) ExpTime-hard. results still hold ABoxes empty (i.e. assertions
allowed).
Fixed concept names play role similar , proof adapted
CircF (EL).
Theorem 7.5 Instance checking subsumption ExpTime-hard CircF (EL)
Circfix (EL). holds restriction EL supporting >.
740

fiD EFEASIBLE NCLUSIONS L OW-C OMPLEXITY DL

Proof. reduce satisfiability ELA TBox complement subsumption CircF (EL).
First introduce new concept name representing > translate concept C
ELA corresponding C EL, follows:
C = C C concept name;
C = C (for A, new concept name);
C = u R.(C1 u D) C R.C1 ;
C = C1 u C2 C C1 u C2 .
C1 v C2 translated C1 v C2 . extend translated TBox
following inclusions, Bot (representing ), UA s, Bad new concept names R
new role name:


UA

v
v
v





(50)

vn UA

(58)

(51)



0

(59)

(52)



0

vn R.UA (60)

0

vn R.Bot (61)

v



u

v

Bot (53)



u UA

v

Bot (54)

R.UA

v

Bad

(62)

u UA

v

Bot (55)

R.Bot

v

Bad

(63)

vn

(56)

vn

(57)

D(a) (ABox assertion) (64)

Let KB = hK, K resulting DKB, set F = {D, Bot}. prove following three
properties equivalent: (i) satisfiable, (ii) CircF (KB) 6|= v Bad , (iii) CircF (KB) 6|=
Bad (a).
Let us prove (ii) implies (i). Let model CircF (KB) individual x s.t.
x DI x 6 Bad . (62)(63), x 6 (R.UA )I A, x 6 (R.Bad )I . (59),
x (D0 )I . Hence, x violates DIs (60) (61). Assume least one concept UA empty
(resp., Bot empty I). Then, improved (according <F ) connecting
R-edge individual x non-empty concept UA (resp., Bot), adding x Bad
(notice Bad variable concept). contradiction, conclude Bot
UA empty I. Then, prove restriction domain DI model .
Inclusions (50)(51) ensure individuals satisfying either DI . DIs (56)
(57), together fact UA empty, guarantee individual DI satisfies
either A, concept names A. Rules (53), together fact Bot empty,
guarantee individual satisfies A. translation C C completes
claim.
Next, show (i) implies (ii). Let model . extend become model
J CircF (KB) DJ 6 Bad J , DJ 6= Bad J = . A, set
AJ = \ AI UAJ = . Then, set DJ = (D0 )J = J = Bot J = Bad J = .
easy verify J satisfies CIs KB. remains prove J minimal w.r.t. <F .
741

fiB ONATTI , FAELLA , & AURO

Name

Restrictions

full left local (LLf )
almost left local (aLL)

qualified existentials LHS inclusions
union LLf KB classical acyclic terminology, s.t. unfolding
former w.r.t. latter produces LLf KB
v[n] P.B A1 u A2 v B
following schemata:
P v B
P1 v P2 .B
(no nesting; conflicts DIs Circfix )
v[n] P.B P1 u P2 v P3 .B
following schemata:
P v B
(no nesting; potential conflicts DIs even Circfix )

left local (LL)

LL2

Figure 3: Fragments EL considered Section 7.

Since Bot fixed concept, inclusions (53)(55) ensure A, UA mutually exclusive, concepts A. Hence, DI type (56)(58) improved expenses
another DI incomparable priority, count improvement according <F .
DI (61) cannot improved Bot empty fixed. Finally, suppose one tries improve
one DIs type (60). so, least one individual x must enter concept UA . Due
mutual exclusion property described earlier, x needs exit (resp. A), thus violating
DI (56) (resp., (57)), higher priority (60) due (59).
equivalence (i) (iii) proved along similar lines. notice
fact (64) makes Bad (a) equivalent inclusion v Bad . thesis Circfix obtained
consequence Theorem 4.4.
2
Concept consistency simpler, instead. Call interpretation complete iff NC ,
AI = , P NR , P = . hard verify EL concepts
EL inclusions (both classical defeasible) satisfied x , therefore complete models
always models CircF (KB), DKBs KB F NC . consequence
concept consistency trivial:
Theorem 7.6 EL concepts C, DKBs KB, F NC , C satisfied model
CircF (KB).
7.1 Left Local EL Circvar
subsection next one, prove qualified existentials left-hand side
inclusions responsible higher complexity EL w.r.t. DL-liteR . particular, qualified
existentials left-hand side make proof strategy Lemma 6.7 fail: target
edge starts x redirected, individual x may satisfy qualified existential restriction
satisfy before. so, truth value inclusions may affected. limiting
occurrences qualified existential restrictions left-hand side inclusions, possible
reduce significantly complexity instance checking subsumption circumscribed EL .
Figure 3 summarizes syntactic fragments EL consider. start following
class knowledge bases:
Definition 7.7 defeasible knowledge base hK, full left local (LLf ) fragment EL
iff left-hand sides inclusions K contain qualified existential restrictions.
742

fiD EFEASIBLE NCLUSIONS L OW-C OMPLEXITY DL

Note restriction rules acyclic terminologies containing qualified existential
restriction, hence existing ontologies practical interest. Therefore, introduce
following relaxation LLf EL :
Definition 7.8 EL knowledge base KB = hK, almost (aLL short) iff (i) K =
KLL Ka , (ii) KLL LLf , (iii) Ka classical acyclic terminology, (iv) concept name
defined Ka occurs left-hand side inclusion KLL , depend (in
Ka ) qualified existential restriction.
words, unfolding KLL respect Ka , obtain LLf knowledge base.
Example 7.9 Example 3.1 reformulated EL :
Human vn lhs heart ;
lhs heart u rhs heart v ;
Situs Inversus Human u rhs heart .
KLL consists first two axioms Ka consists third axiom. Note that, general,
concept name occurring terminology extended default properties means
inclusion vn C following cases: primitive concept (with definition ),
concept partially defined one-way inclusion (e.g. Human v Mammal), even concept
complete definition , provided depend qualified existentials.
Accordingly, example, could add defeasible inclusion like Situs Inversus vn C,
would permitted definition situs inversus depended qualified existential
restrictions
Situs Inversus Human u heart. position. Right .

2

small model property similar Lemma 6.7 proved Circvar (aLL EL ) provided
right-hand side subsumption queries bounded quantifier depth. convenient
split proof proof LLf EL later extend EL .
Since LLf EL RHS inclusion may nested qualified existential restrictions,
difficult prove small model property considering entire language. reason,
prove indirectly: first show transform knowledge base KB another KB
yields following properties: (i) nested formulas occur, (ii) defeasible inclusions
type vn B, (iii) every model Circvar (KB) extended model Circvar (KB )
domain (iv) every model Circvar (KB ) model Circvar (KB). Then, prove
small model property fragment nesting and, thanks properties (iii) (iv),
recover small model property entire language.
LLf EL inclusion C v[n] transformed three steps. Note Cs shape is:
A1 u . . . u u R1 u . . . u Rm .
first step, C replaced fresh concept name F0 (for convenience, later refer F0
also FC ) following axioms added:
Fi v Ai+1 u . . . u u R1 u . . . u Rm
Ai+1 u Fi+1 v Fi
743

(0 n 1)

(65)

(0 n 2)

(66)

fiB ONATTI , FAELLA , & AURO

= 0, i.e., existentials C, add inclusion:
v Fn1

(67)

Otherwise, add following inclusions:
u G0 v Fn1

(68)

Gj v Rj+1 u . . . u Rm (0 j 1)
Bj+1 u Gj+1 v Gj

(0 j 2)

Bm v Gm1

(69)
(70)
(71)

Bj v Rj
Rj v Bj

(1 j m)

(72)

(1 j m)

(73)

Fi , Gj Bj fresh concept names.
point, initial inclusion C v[n] replaced FC v[n] D. eliminate
nesting D, second step replace fresh concept name FD add inclusion
FD v , recursively defined
=


(74)


(C u D) = C u


(R.H) = R.FH



(75)


add FH v H , FH fresh.

(76)

Finally, third step, inclusions type v D1 u . . . u Dh split v Di ,
1 h. resulting knowledge base, denote KB , consists instances
following axiom schemata:
v[n] B

v P.B

A1 u A2 v B

P v B

prove properties (iii) (iv) mentioned above.
Lemma 7.10 Every model Circvar (KB) extended model Circvar (KB )
domain.
Proof. First, note inclusions (65)(73) definitorial, every interpretation KB
exactly one extension satisfies them. extension, simplicity continue call I,
obtained setting FiI = (Ai+1 u . . . u u R1 u . . . u Rm )I , GIj = (Rj+1 u . . . u Rm )I
BjI = (Rj )I .
Then, extend recursively setting FHI = H , fresh concept FH introduced
step 2. straightforward see structural induction H (H )I = H , hence
inclusions step 2 3 satisfied. Thus, classical model KB, also
classical model KB .
Assume model Circvar (KB), show minimal also
respect KB . Suppose not, let J classical model KB J <KB ,var I.
structural induction straightforward see C v[n] KB, (D )J DJ . Since
FCJ = C J holds fresh concept names FC occurring LHS rule,
inclusion C v[n] KB, satJ (FC v[n] FD ) satJ (C v[n] D) implies J
744

fiD EFEASIBLE NCLUSIONS L OW-C OMPLEXITY DL

classical model KB. Concerning I, every C v[n] KB, (FC )I = C
(FD )I = DI construction, satI (C v[n] D) = satI (FC v[n] FD ).
previous arguments entail satI (FC v[n] FD ) satJ (FC v[n] FD ) (respectively
satI (FC v[n] FD ) satJ (FC v[n] FD )), satI (C v[n] D) satJ (C v[n] D) (resp.
satI (C v[n] D) satJ (C v[n] D)). Therefore, would follow J <KB,var I,
contradicts hypothesis.
2
Lemma 7.11 models Circvar (KB ) models Circvar (KB).
Proof. proof similar Lemma 7.10, particular already know (i) individual
satisfies inclusion FC v[n] FD KB , satisfies C v[n] D, (ii) classical model J
KB extended way satJ (C v[n] D) = satJ (FC v[n] FD ), (possibly
defeasible) inclusion KB. this, every classical model KB classical
model KB and, assuming classical model J KB improves (i.e. J <KB,var I),
follows J extended classical model KB J <KB ,var I.
2
following result, whose proof found Appendix, represents small model
property LLf EL , uses transformation KB KB .
Lemma 7.12 Let KB = hK, K LLf EL knowledge base, C, EL concepts.
models Circvar (KB) x C \ DI exists model J Circvar (KB)
(i) J , (ii) x C J \DJ , (iii) |J | O((|KB|2 +|C|)d ), = depth(D)+1.
extend result EL . First, show conditions
concept names defined Ka removed unfolding them, using unf operator defined
Section 2. proofs following two propositions found Appendix.
Proposition 7.13 Let KB = hKLL Ka , EL knowledge base. Every model
CircF (unf(KB)) extended model CircF (KB).
converse holds defined predicates variable. reason adding
definition like P fixed, one fixes expression P , too, thereby changing
semantics.
Proposition 7.14 Let KB = hKLL Ka , EL knowledge base suppose
concept names defined Ka variable. Then, models CircF (KB), restriction
primitive predicates model CircF (unf(KB)).
lemmata prove:
Lemma 7.15 Let KB = hK, K EL knowledge base (where K = Ka KLL )
let C, EL concepts. models Circvar (KB) x C \ DI
exists model J Circvar (KB) (i) J , (ii) x C J \ DJ , (iii) |J |
O((|KB|2 + |C|)d ), = depth(D) + 1 + |Ka |2 .
745

fiB ONATTI , FAELLA , & AURO

Proof. Let Circvar (KB) x C \ DI . Let KB 0 = unf(KB), C 0 = unf(C, Ka ), D0 =
unf(D, Ka ). Notice KB 0 LLf knowledge base. Proposition 7.14, restriction 0
0
0
primitive predicates model Circvar (KB 0 ). particular, holds x (C 0 )I \(D0 )I .
applying Lemma 7.12 KB 0 , C 0 , D0 , 0 , obtain exists model J Circvar (KB 0 )
0
x (C 0 )J \(D0 )J |J | O((|KB 0 |2 +|C 0 |)d ), d0 = depth(D0 )+1.
|KB 0 |2 + |C 0 | |KB|2 + |C|, since replacing defined terms definitions
decrease
P
total number subformulas. Finally, depth(D0 ) depth(D) + (AE)Ka depth(E)
depth(D) + |Ka |2 , hence thesis.
2
Consequently that:
Theorem 7.16 Circvar (aLL EL ) concept satisfiability p2 . Moreover, deciding EL subsumptions C v instance checking problems D(a) constant bound quantifier
depth Ds unfolding w.r.t. given DKB p2 .
2

Proof. Similar proof Theorem 6.2.

Currently, know whether bound quantifier nesting necessary upper
complexity bounds.
Next prove p2 p2 upper bounds Circvar tight. Actually, much simpler
fragment suffices reach complexity:
Definition 7.17 EL knowledge base left local (LL) concept inclusions instances
following schemata:
v[n] P.B

A1 u A2 v B

P v B

P1 v P2 .B ,

B either concept names . EL concept concept occur
inclusions.
Schema v[n] B emulated EL inclusions v[n] R, R v B
B v R, fresh role R. Note similarity schemata normal form EL
inclusions (Baader et al., 2005) that, however, would allow general inclusions P.A v B
P1 .A v P2 .B (that forbidden left locality).
prove reasoning Circvar (LL EL ) hard (and hence complete) p2 p2 .
purpose, provide reduction minimal entailment positive, propositional
disjunctive logic programs (PDLP), defined Section 6.1. propositional variable pi ,
1 n, introduce two concept names Pi Pi latter encodes pi . following
denote Lj , 1 j 2n, generic Pi Pi . clause cj introduce concept
name Cj . Then, two concept names True False represent set true false literals
respectively. Finally, concept names Lit Min used model minimal propositional
assignments; need also auxiliary role R.
First, literals reified, i.e. modeled individuals, axioms:
> v R.Li
Li u Lj v
Li vn
746

(1 2n)

(77)

(1 < j 2n)

(78)

(1 2n)

(79)

fiD EFEASIBLE NCLUSIONS L OW-C OMPLEXITY DL

first axiom makes Li nonempty. Axioms (78) make pairwise disjoint. Finally, axioms
(79) minimize concepts Li make singletons. Then, represent adding
clause cj = lj1 ljh , 1 j m, axioms
Lji v Cj

(1 j 1 h)

(80)

Cj vn

(1 j m)

(81)

> v R.(Cj u True) (1 j m)

(82)

axioms (80) (81), Cj equals set (encodings of) literals cj . Axioms (82) make sure
clause holds.
order model concepts True False correct meaning complementary
literals add axioms
True u False v

(83)

Pi u True v R.(Pi u False) (1 n)

(84)

Pi u False v R.(Pi u True) (1 n)

(85)

Pi u True v R.(Pi u False) (1 n)

(86)

Pi u False v R.(Pi u True) (1 n)

(87)

axioms defined far encode classical semantics S. minimize models, add following axioms:
Min u Pi v False (1 n)

(88)

Min u Pi v True

(1 n)

(89)

Li v Lit

(1 2n)

(90)

Cj v Lit

(1 j m)

(91)

Lit vn Min

(92)

(88) (89), Min collects false positive literals true negative literals. (90) (91),
Lit contains (representations of) literals clauses. purpose axioms giving
defeasible inclusions (79) (81) higher (specificity-based) priority (92), model minimization cannot cause Li larger singleton, Cj different set
literals cj . (92) prefers models many Pi possible False.
following, given PDLP S, let KB Tbox defined above.
Lemma 7.18 Given PDLP S, literal l Ss language, encoding L l, following
equivalent:
(minimal entailment) |=min l;
(subsumption) Circvar (KB ) |= > v R.(True u L);
(co-sat) False u L satisfiable w.r.t Circvar (KB );
(instance checking) Circvar (KB ) |= (R.(True u L))(a).

lemma proved analogy proof Lemma 6.5; details left reader.
conjunctions (u) nested easily replaced new atom adding
equivalence True u L, encoded EL , have:
747

fiB ONATTI , FAELLA , & AURO

Theorem 7.19 Subsumption instance checking Circvar (LL EL ) p2 -hard; concept
satisfiability p2 -hard. results hold even three reasoning tasks restricted
EL concepts, priorities specificity-based.
7.2 Left Local EL Circfix
reduction validity problem quantified Boolean formula, show
Circfix (aLL EL ) complex Circvar (aLL EL ), unless polynomial hierarchy collapses. Computing truth quantified Boolean formula
= Q1 p1 . . . Qn pn .
(where Qi quantifiers) reduced polynomial time subsumption checking
Circfix (aLL EL ) follows. Introduce concept names A0 , . . . , , Ti Fi = 1 . . . n,
concept names Eij 1 < j n. Introduce role names R, bad , good , Ui = 1 . . . n.
define aLLEL knowledge base hK, K i, K = KLL Ka . left-local part KLL
consists following groups axioms. Notice that, following description, always
arbitrary index {1, . . . , n}. First, encode negation normal form . Let Bpi = Ti
Bpi = Fi . subformulas F G introduce new concept name BF G add
inclusion BF u BG v BF G . subformulas F G introduce new concept name BF G
add inclusions BF v BF G BG v BF G .
second group axioms KLL constrains Ti Fi avoid inconsistencies. Intuitively
Ui means pi undefined:
Ti u Fi v

(93)

Ti u Ui v

(94)

Fi u Ui v

(95)

third group axioms KLL defines tree encodes truth assignments needed
evaluate QBF:
6= j

Ai u Aj v

(96)

s.t. Qi =

Ai1 v R.(Ti u Ai ) u R.(Fi u Ai )

(97)

s.t. Qi =

Ai1 v R.Ai

(98)

fourth group axioms KLL detects misrepresentations forcing role bad point
nodes evaluation tree something going wrong (i.e. truth assignment
incomplete, predicate changes value along branch, false leaf).

> vn bad .Ui

(99)

bad .Eij
bad .Eij

(101)

> vn bad .(B u )

(102)

> vn
> vn

(Eij Eij defined Ka below). Finally, good captures absence bad :
748

(100)

fiD EFEASIBLE NCLUSIONS L OW-C OMPLEXITY DL

bad u good v .

(103)

acyclic terminology Ka purpose detecting whether propositional symbol
changes value along path:
Eij

Aj1 u Ti u R.(Aj u Fi )

(104)

Eij

Aj1 u Fi u R.(Aj u Ti ) .

(105)

Lemma 7.20 Let model Circfix (KB) satisfies A0 u good . = 1 . . . n,
individuals contained either TiI FiI .
Proof. First, contradiction, assume = 1 . . . n x Ii , x neither FiI
TiI . Since axioms (93)-(95) prevent x satisfying Ui must minimal w.r.t.
axiom (99), entire domain satisfies bad .Ui . However, axiom (103), means
A0 u good unsatisfiable hypothesis.
2
Lemma 7.21 Let model Circfix (KB) satisfies A0 u good . = 1 . . . n,
xi (Ai u Ti )I (respectively, x (Ai u Fi )I ), paths {xi , xi+1 , . . . , xn } xj Aj
(xj1 , xj ) RI , < j n, contained TiI (resp., FiI ).
Proof. Assume xi (Ai uTi )I {xi , xi+1 , . . . , xn } 6 TiI . means xi 6= xn
< j n, xj1 (Aj1 u Ti )I xj (Aj1 u Fi )I . Then, axiom (104), xj1 Eij
since must minimal w.r.t. axiom (100) entire domain satisfies bad .Eij . However,
axiom (103), means A0 u good unsatisfiable hypothesis.
2
Theorem 7.22 Concept satisfiability, subsumption checking, instance checking PSPACEhard Circfix (aLL EL ). result still holds nesting level existential restrictions
bounded constant, priority relation empty.
Proof. order prove theorem suffices show QBF true iff A0 u good
satisfiable w.r.t. KB.
[if ] Let model Circfix (KB) satisfies A0 u good . Due axioms (96)-(98), must
contain DAG starts x (which (A0 u good )I ) and, following R-edges, proceeds
concepts Ai increasing index, . DAG, = 1 . . . n

Qi = , individuals belonging AIi two successors: one AIi+1 Ti+1
. Individuals AI , Q = , one successor, AI . Due
AIi+1 Fi+1


i+1
F .
Lemma 7.20, successor either Ti+1
i+1
Now, consider truth assignment v universally quantified variables . DAG,
follow unique path x leaf z , level corresponding Qi =
AI F accordance v. Lemma 7.20, = 1 . . . n
proceeds AIi+1 Ti+1
i+1
i+1
z either Ti Fi , moreover, Lemma 7.21, membership z Ti Fi consistent v.
Therefore, z represents full truth assignment variables extends v.
Now, since minimizes set abnormal individuals w.r.t. defeasible inclusion (99)
models good bad disjoint, x good implies z 6 BI . then,
straightforward conclude truth assignment satisfies .
749

fiB ONATTI , FAELLA , & AURO

[only ]. Assume true. Assume w.l.o.g. odd quantifiers Q1 , Q3 , . . . , Qn1 universal even quantifiers existential. existential quantifier Qi , let fi : {T, F }i/2
{T, F } function values v1 , v3 , . . . , vn1 universally quantified variables, (v1 , f2 (v1 ), v3 , f4 (v1 , v3 ), . . . , fn (v1 , v3 , . . . , vn1 )) true.
define tree-like model KB satisfies A0 u good . start root individual
x, x |=I A0 u good . proceed inductively follows. even (including 0),
individual AIi two R-successors 0 , 00 AIi+1 , 0 TiI 00 FiI (see
axioms (97)). odd i, individual AIi one R-successor 0 AIi+1 (see axioms (98)),
0 satisfies either Ti Fi , according value fi applied truth values
read along path root y. Along R path x0 . . . xi . . . xn
concept Ti Fi assigned xi assigned xj , < j n, indifferently either Ti Fi
assigned xh 1 h i. model completed assigning xn (i) BF G ,
subformulas F G , F G assigned xn , (ii) BF G , subformulas
F G , F G assigned xn .
leave reader proof structure defined satisfies classical part
KB. Regarding minimality w.r.t. defeasible inclusions KB, remark following.
individuals violate inclusions (99). However, due rules (94) (95), situation cannot
improved simply modifying roles. Similarly, individuals violate inclusions (100)(101). However, since Eij empty defeasible inclusions cannot improved.
Finally, since leaf z represents truth assignment satisfies , B empty
hence model also minimal w.r.t. inclusion (102).
2
fragment EL , unlike LLf , fully support unqualified existential. Consequently, Theorem 4.4 cannot used transfer hardness results Theorem 7.19 var
fix.9 hardness results hold general framework Circvar (LLf EL )
hence, Theorem 4.4,for Circfix (LLf EL ):
Proposition 7.23 Subsumption instance checking Circfix (LLf EL ) p2 -hard; concept satisfiability p2 -hard. results hold even queries contain EL concepts,
priorities specificity-based.
following result, whose proof found Appendix, shows context
lower bounds tight: namely, case priority relation empty (i.e., DIs
mutually incomparable) and, subsumption queries C v instance checking queries D(a),
quantifier depth bounded constant.
Lemma 7.24 Let KB = hKS KD , LLf EL knowledge base, C, EL concepts.
models Circfix (KB) x C \ DI exists model J Circfix (KB)
(i) J , (ii) x C J \ DJ (iii) |J | O((|KB| + |C|)d ) = depth(D).
Going back fragment, following prove Circfix less complex Circvar
(unless polynomial hierarchy collapses). particular, show Circfix (LLEL ) tractable.
Algorithm 1 takes input knowledgedbase KB two concepts C (we may assume
without loss generality C = AC u ni=1 Pi .Bi ) checks whether Circfix (KB) |= C v D.
9. prove EL , Circfix actually less complex Circvar .

750

fiD EFEASIBLE NCLUSIONS L OW-C OMPLEXITY DL

Algorithm 1:
dn
Data: C = AC u 1 Pi .Bi , D, KB = hK, i.
:= {A vn P.B | C |= A};
X := C;
6=
remove defeasible inclusion vn P.B;
SupCls(P.B) SupCls(C) NonEmpty(P.B, KS ) NonEmpty(C, KS )
X := X u P.B;
return X vKS D;

SupCls(H) mean set superclasses concept H, i.e., set B NC {}
H vKS B.
Given concept H, operator NonEmpty(H, KS ) represents set concepts
forced non empty whenever H is. Note set includes concepts forced
non empty ABox KB, independently H. write H ; iff H vKS R.A
+
R, denote ; transitive closure ;. Then, NonEmpty(H, KS ) formally
defined follows:


NE Kernel = {H} aNI {A | KS |= A(a)} aNI ,RNR {A | KS |= (R.A)(a)}

+
NonEmpty(H, KS ) = ANE Kernel {A0 | ; A0 }.
Roughly speaking, algorithm accumulates RHS defeasible inclusions actively satisfied
witness C. Then, tries derive D. particular, defeasible inclusion vn R.B
actively satisfied case (i) entail locally concept name subsumed
C, (ii) entail globally non-emptiness concept name empty.
rationale concept names fixed circumscription cannot change extension
application vn R.B could instead require.
Lemma 7.25 Circfix (KB) |= C v holds iff Algorithm 1 returns true.
Proof. [if ] suffices show models Circfix (KB), X subsumes C, X
formula obtained statement. Assume per absurdum model
individual x , x C \ XI . means defeasible inclusion n P.B (i) x 6
satI (A n P.B) (ii) line 1, SupCls(P.B) SupCls(C) NonEmpty(P.B, KS )
NonEmpty(C, KS ).
Note that, since NonEmpty(P.B, KS ) NonEmpty(C, KS ), whenever R.B vKS S.B
exists individual yB B . Let 0 interpretation obtained adding
(x, yB ). Clearly, adding new arcs set individuals satisfied defeasible inclusion
0
cannot decrease, therefore KD , satI () satI 0 (). Moreover, since x (R.B)I ,
satI (A n P.B) satI 0 (A n P.B) hence 0 <fix I.
condition (ii) fact defeasible inclusions conflict other,
easy verify 0 also classical model KB, would mean model
Circfix (KB) hypothesis.
[only ] Assume Algorithm 1 returns false. Let following interpretation:
= {xC } {xA | NonEmpty(C, KS )} {xa | NI };
751

fiB ONATTI , FAELLA , & AURO

B NC , B union of: (i) {xC } B S1 , (ii) set xA , S2 ,
|=KS B, (iii) set xa , NI , KS |= B(a);
R NR , RI union pairs (i) (xA , xB ) A, B S2 vKS R.B,
(ii) (xa , xb ) a, b NI KS |= R(a, b), (iii) (xa , xB ) NI , B S2
KS |= R.B(a), (iv) (xC , xB ) B S2 X vKS R.B; arcs relevant.
construction (classical) model KS xC C \ DI , hence order prove
Circfix (KB) remains show minimal. Note that, since defeasible inclusions
contain nested roles right side, set defeasible inclusions satisfied individual
affect set defeasible inclusions satisfied another individual. Therefore, interpretation
improved point-wise assume w.l.o.g. individuals I, except xC ,
cannot improved. Assume exists interpretation J improves
xC , means particular = vn P.B, xC satJ () \ satI ().
assumption xC 6 satI () means P.B satisfy condition line 1 and,
since concept names fixed, cannot satisfied J .
2
Theorem 7.26 Circfix (LL EL ) DKBs, EL subsumption, instance checking, concept
consistency P.
Proof. Since SupCls(H) NonEmpty(H, KS ) based classical reasoning,
performed polynomial time. Moreover, number iterations Algorithm 1 bounded
number defeasible inclusions. Therefore, due Lemma 7.25, subsumption problem
tractable. Theorem 3.9, instance checking concept inconsistency reduced subsumption.
2
Complexity low Circfix context axioms general enough simulate quantifier nesting conjunctions existential restrictions. Circvar features
simulated abbreviating compound concepts C concept names using equivalences C
C depend qualified existentials (hence restriction preserved).
Circfix , equivalences change semantics C whenever C (or contains) existential
restriction, fixed prevents C varying freely. reintroduce missing
features, complexity increases again.
Let LL2 EL support schemata:
v[n] P.B

P1 u P2 v P3 .B

P v B

One may easily verify LL2 EL equivalent EL plus schema P1 u P2 v P3 .B.
missing axioms reformulated using fresh roles R suitable equivalences R C
(that preserve Cs semantics R varying predicate)10 .
additional schemata, one create conflicts variable concepts, P1 u
P2 v . different defeasible inclusions may block other, thereby creating potentially
exponential search space.
Theorem 7.27 Subsumption instance checking Circfix (LL2 EL ) coNP-hard; concept satisfiability NP-hard. results hold even three reasoning tasks restricted
LL2 EL concepts, priorities specificity-based.
10. particular, schema A1 uA2 v B emulated inclusions A1 v R1 , A2 v R2 , B v R3 , R1 v A1 ,
R2 v A2 , R3 v B, R1 u R2 v R3 .

752

fiD EFEASIBLE NCLUSIONS L OW-C OMPLEXITY DL

Proof. reduction SAT. propositional variable pi introduce concept names Ai , Ai ,
role Ui , representing pi truth value (resp. true, false, undefined). alternatives
made mutually inconsistent with:
Ai u Ai v

Ai u Ui v

Ai u Ui v

given clause cj = lj,1 lj,n , introduce concept name Cj representing cj falsity,
Lj,k representing complement lj,k add Lj,1 u u Lj,n v Cj .
Define concept name F representing falsity given set clauses, disjoint
concept F with:
Cj v F

(for input clauses cj )

F u F v .

Now, defeasible inclusion, Ui forced true individuals satisfy neither Ai
Ai ; moreover, role U detects undefined literals:
> vn Ui

Ui v U .

Let K set inclusions KB = hK, K i. proved given set
clauses unsatisfiable iff Circfix (KB) |= F v U , therefore subsumption checking coNPhard.
Similarly, proved unsatisfiable iff Circfix (KB 0 ) |= (U )(a), KB 0 =
hK0 , K0 K0 = K {F (a)}; therefore instance checking coNP-hard.
Finally, proved satisfiable iff F uOK satisfiable w.r.t. Circfix (KB 00 ),
KB 00 = hK00 , K00 K00 = K {U u OK v }; therefore satisfiability checking NP-hard.
left remark K easily encoded LL2 EL .
2
prove bound tight using Algorithm 2. algorithm non-deterministically looks
individual x (in model) satisfies C D. S1 guesses additional fixed concept
names satisfied x; S2 guesses concept names satisfied somewhere model (not
necessarily x) finally 0 guesses total extension determines application order
GDIs.
Similarly Algorithm 1, Algorithm 2 selects defeasible inclusions active x
accumulates formula X RHS blocked, i.e. require change
interpretation concept names neither locally globally. major differences (i)
defeasible inclusions extracted according 0 (ii) line 2 entire accumulated formula
X u P.B used check defeasible inclusion blocked.

Finally, note variable part C (i.e. ni=1 Pi .Bi ) introduced X line 8,
defeasible inclusions applied, defeasible inclusions influence variable
part (e.g. forcing empty).
Lemma 7.28 Circfix (KB) |= C v holds iff runs Algorithm 2 return true.
Proof. [if ] Assume per absurdum exists interpretation Circfix (KB) individual x x C \ DI . Let S1 S2 set concept names NC
satisfies respectively locally x globally i.e., individual. Let 0 linearization
compatible I, i.e. , 0 KD (i) either 0 0 0 0 , (ii) 0 implies 0 0 ,
(iii) 0 comparable according ( 6 0 0 6 ) x satI () \ satI ( 0 ),
0 0 .
753

fiB ONATTI , FAELLA , & AURO

Algorithm 2:
dn
Data: C = AC u 1 Pi .Bi , D, KB = hK, i.
Guess S1 , S2 NC , uS1 |= AC S1 S2 , linearization 0 ;
:= {A
vn P.B | uS1 |= A};
X := S1 ;
6=
remove 0 -minimal inclusion vn P.B;
SupCls(X u P.B) S1 NonEmpty(X u P.B, KS ) S2
X := X u P.B;
dn
X := X u 1 Pi .Bi ;
return SupCls(X) 6 S1 NonEmpty(X, KS ) 6 S2 X vKS D;

Let X result running Algorithm 2 guesses S1 , S2 , 0 . straightforward
see = vn P.B KD P.B occurs X, x satI (). This, together
fact x C , implies 1) SupCls(X) S1 ; 2) NonEmpty(X, KS ) S2 and, since
x 6 DI , 3) X 6vKS D. means run Algorithm 2 return false.
[only ] Assume guess S1 , S2 0 Algorithm 2 returns false. Let
defined Lemma 7.25. similar way proved classical model KS
xC C \ DI . Assume improved interpretation J , w.l.o.g. also assume
(i) = vn P.B, xC satJ () \ satI () (ii) 0 higher priority
comparable it, xC satJ ( 0 ) iff xC satI ( 0 ).
X0 value X extracted line 2 Algorithm 2, since 0 implies 0 0 ,
0 already extracted higher priority comparable . Since (ii) holds
construction xC X0I , xC X0J . However, assumption xC 6 satI () means X0 u P.B
satisfy condition line 2 since concept names fixed cannot satisfied J .
2
Theorem 7.29 LL2 EL subsumption instance checking Circfix (LL2 EL ) coNP;
LL2 EL concept satisfiability NP.
Proof. analogous Theorem 7.26 left reader.

2

verified LL2 fragment support quantifier nesting. quantifier nesting,
one would obtain LLf EL (i.e. full LL).

8. Related Work
DLs extended nonmonotonic constructs default rules (Straccia, 1993; Baader
& Hollunder, 1995a, 1995b), autoepistemic operators (Donini et al., 1997, 2002), circumscription (Cadoli, Donini, & Schaerf, 1990; Bonatti et al., 2009, 2009; Bonatti, Faella, & Sauro, 2010).
articulated comparison approaches found work Bonatti, Lutz,
Wolter (2009).
approaches concern logics whose reasoning tasks complexity lies beyond PH
(unless hierarchy collapses). example, logics considered Donini et al. (1997, 2002)
range PSPACE 3-ExpTime. circumscribed DLs studied Cadoli et al. (1990) well
754

fiD EFEASIBLE NCLUSIONS L OW-C OMPLEXITY DL

Table 1: Main complexity results. corresponding decision problems classical versions
considered logics solvable polynomial time.

DL-liteR
var fix(\)
concept
satisfiability

p2

p2

EL

EL
var

fix

var
()



LL2

fix
LLf



p2

P

NP

p2 (#)

PSPACE

trivial

subsumption
& instance
p2 p2
P ExpTime
p2 ()
P co-NP
p2 (#)
checking
() specificity-based priorities; general priorities make var least complex fix
() quantifier nesting bounded r.h.s. subsumptions instance checking problems
(\) DIs left-fixed priority relation empty
(#) membership holds priority relation empty condition () holds

PSPACE

Bonatti et al. (2009) range NPNExp NExpNP . logics undecidable (Baader &
Hollunder, 1995a; Bonatti et al., 2009).
pioneering approach low-complexity, circumscribed description logics presented
Cadoli et al. (1990). approach applies non-prioritized circumscription fragment
description logic ALE. Decidability reasoning shown reduction propositional reasoning Extended Closed World Assumption (ECWA), p2 . best
knowledge, first effective reasoning method nonmonotonic description logic.
hybrid Circfix (EL ) closed world assumption proved PTIME (Bonatti
et al., 2010). one hand, approach imposes less restrictions structure inclusions;
hand, cannot fully extended variable predicates without affecting tractability.
recent approach similar spirit circumscription taken Giordano et
al. (2008). extend ALC modal operator representing typicality, maximize
extension achieve nonmonotonic inferences. Decidability proved via tableau algorithm
also establishes co-NExpTimeNP upper bound subsumption. matching lower bounds
given; proved reasoning underlying monotonic logic NP-hard.
Finally, approach based rational closures ALC found work Casini
Straccia (2010). appealing feature approach reasoning reduced classical
inference. Complexity increased nonmonotonic reasoning: ranges PSPACE
ExpTime.

9. Discussion Future Work
main complexity results paper summarized Table 1. restricting circumscribed
KBs Circvar (DL-liteR ), complexity decreases significantly (from (co)-NExpTimeNP second level PH). complexity upper bounds hold Circfix (DL-liteR ) whenever priority
755

fiB ONATTI , FAELLA , & AURO

relation empty defeasible inclusions admit concept names LHS. However,
general case still open question.
contrary, restricting language EL EL general suffice bring complexity within PH. particular, proved reasoning tasks undecidable CircF (EL)
(i.e., roles fixed) reasoning Circfix (EL) Circvar (EL ) general
ExpTime-hard.
main source higher complexity EL family (w.r.t. DL-liteR ) identified
introducing restriction called full left locality (LLf ) suffices confine complexity within second level PH Circvar specificity-based priorities, provided
quantifier nesting level subsumption queries instance checking queries suitably bounded
(no restrictions needed concept satisfiability).
Since left locality restriction rules acyclic terminologies (which commonly used
ontologies), relaxed almost left local (aLL) knowledge bases, support acyclic
terminologies restriction unfolding (i.e., process replacing atoms defined
acyclic terminology definition) yield LLf knowledge base. Reasoning
becomes PSPACE-hard, general; however fragment Circvar (and
assumptions needed LLf ), reasoning remains complete second level PH. particular,
assumption priorities determined specificity essential: Theorem 4.5, general
priorities make Circvar least complex Circfix , is, PSPACE-hard.
also analyzed complexity several fragments lying
Circfix . results provide information complexity sources circumscribed DLs. example, quantifier nesting KB partially responsible complexity
(presumably enables conflicts default properties different individuals):
particular, removing quantifier nesting (i.e., restricting KBs LL2 fragment) complexity drops first level PH. source complexity, course, due conflicts
defeasible inclusions concerning individual isolation; Circfix (LLEL ) defeasible inclusion never block another inclusion (because fixed predicates prevent this) andas
consequencecomplexity drops within PTIME.
also proved fragments fully support unqualified existential restrictions,
variable concept names eliminated. Moreover, EL various left local fragments,
compound concepts replaced concept names left-hand side defeasible inclusions, without affecting expressiveness. fragments, general priorities simulated
using specificity-based priorities.
leave several interesting questions open: First, clear whether general priorities necessary hardness results DL-liteR ; particular, would interesting establish exact complexity DL-liteR specificity-based priorities. gaps complexity
circumscribed DL-liteR concern complexity Circfix unrestricted GDIs nonempty
priority relations, complexity reasoning fixed roles. next interesting question
whether bound quantifier nesting queries actually needed confine complexity
circumscribed EL within second level PH. Finally, exact charcterization
complexity Circfix (LLf EL ) fragments whose complexity lies beyond PH.
fragments belong second level PH, see interesting opportunity
encoding reasoning ASP use well-engineered engine DLV (Eiter, Leone,
Mateis, Pfeifer, & Scarcello, 1997) test scalability. order evaluate implementations experimentally, necessary set suitable benchmarks that, first stage, must necessarily
756

fiD EFEASIBLE NCLUSIONS L OW-C OMPLEXITY DL

synthetic problems, since nonmonotonic KBs supported far. course, identifying
meaningful criteria problem generation nontrivial issue. Therefore, systematic experimental
evaluations still require significant body work.

Acknowledgments
authors wish thank Frank Wolter granting permission publish undecidability
proof. Moreover, grateful Frank Wolter Carsten Lutz many stimulating discussions feedback. work carried framework project LoDeN,
(very) partially supported Italian Ministry Research.

Appendix A. Additional Lemmas Proofs
A.1 Proofs Section 6
Lemma 6.3. Given PDLP P V = {p1 , . . . , pn } truth assignment P V ,
minimal model iff interpretation model (S, I, ) model Circvar (KB ),
domains || = 2n + 1.
Proof. [only ] Let = model (S, I, ), first show model classical part
KB . Since I-V, Abox (18) axioms (20-24) satisfied. Whereas, axioms (33-36)
follow directly VII.
Since interpretation, VI assures TrueP 6= , False P 6= . Together
VIII, axioms (31-32) satisfied, whereas together VII, True False reflect truth
values I; therefore True False = hence axiom (30) satisfied. Moreover,
model S, c exists least one literal li occurring c |= li . Due
V-VII, CjI True 6= and, due VII VIII (where X = True = Cj ), satisfies
axioms (26-29).
remains prove exists interpretation J J <var I. finite,
assume w.l.o.g. J model KB . Assume 1 2n, satI (Li vn


Li ) satJ (Li vn Li ), equivalent saying LJ
Li , since Li singleton,
J
Li would empty contradicting axioms (18-23). Similarly, satI (Cj vn Cj ) satJ (Cj vn
Cj ) iff CjJ CjI . Thus, due V axiom Lji v Cj would satisfied J . Therefore
defeasible inclusions highest priority cannot improved.
J


assume literal clause concept holds LJ
= Li = {di } Cj = Cj .
Since reflects truth values I, di included FalseLIi included
TrueLIi . Thus, 1 2n, satI (Pi vn FalsePi ) equal satJ (Pi vn FalsePi )
would way J improve defeasible inclusion Pi vn TruePi . Therefore,
possibility far J improves instance (40).

Note True J False J partition PiJ . Otherwise, could set PiJ without
truth value (i.e., di 6 TruePiJ FalsePiJ ) FalsePi since classical inclusion jeopardized
would obtain improvement J according (40), hypothesis J model.
Due (31-36), True J False J partition {d1 , . . . , d2n }.
Thus, consider propositional assignment J pi J iff PiJ True J .
First, clauses cj , since J satisfies axioms (26-29), 1 2n
J
J
J
J


LJ
Cj True . Li = Li Cj = Cj , ljl occurs cj . means J |= li ,
757

fiB ONATTI , FAELLA , & AURO

hence
J model S. Finally, said before,
intersection
J |= cj . Thus,
Sif JJ <var I,
strictly contained intersection
J . implies
P

False
P

False


J I, hypothesis minimal model.
[if ] Assume = model (S, I, ) model Circvar (KB ). First show
model S, i.e., cj S, |= cj . satisfies axioms (26-29), 1 2n holds
di CjI True . Due IV V, di belongs LIi corresponding literal li
occurs cj . According VI, implies |= li , hence |= cj .
remains show minimal model. Assume exists model J
J I, without loss generality assume J minimal model. Let J = model (S, J, ),
arguments J model KB . Furthermore, satJ () = satI ()
J
J
type
ILi vn LI orSCj Jvn Cj . JFinally, True False reflect truth values J,
Pi F alse
Pi F alse hence J <var due improvement DIs (40). 2
Lemma 6.4. model Circvar (KB ), exist minimal model
pi iff PiI True iff PiI False , = 1, . . . , n.
Proof. Let model Circvar (KB ). First, show LIi singleton, 1 2n.
Assume contrary. Clearly, satisfy (1821), LIi nonempty. Therefore,
1 k n, LIk contains least two individuals. show exists interpretation 0
improves I.
1 2n, let di arbitrary element LIi , let = {d1 , . . . , d2n } {aI }.
LIi disjoint (see axioms (22)) NonEmpty disjoint LIi ,
|| = 2n + 1.
). Let 0
PDLP satisfiable, thus exists model S. Let Ib = model (S, I,
0
0





interpretation that: (i) = , (ii) roles R, R = , (iii) 0 coincides
Ib respect concept names, (iv) individuals \
belong concept name. straightforward see 0 satisfies classical part KB .
0
0
Furthermore, construction, (a) 1 2n, LIi LIi ; (b) 1 j m, CjI CjI ;
0
(c) 1 l 2n, LIl LIl . Thus, 0 <var I, due improvement DI (23).
argument, LIi = {di }. Define truth valuation = {pi | di True }.
remains prove minimal model S. fact model ensured
axioms (2429). Then, assume contradiction exists model J smaller
(i.e., J I), let J = model (S, J, ). J build interpretation J 0
0
J = J 0 classical model KB J 0 <var I, thus contradicting
hypothesis model Circvar (KB ). define J 0 copying J properties
(concepts roles) individuals J = , leaving individuals \
concept role extensions.
2
A.2 Proofs Section 7
Given KB K, interpretation I, individual z, recall definition KB [z] Section 6.2. Redefine notion support follows: supp (C) set individuals z
> vKB[z] C holds.
Lemma 7.12. Let KB = hK, K LLf EL knowledge base, C, EL concepts.
models Circvar (KB) x C \ DI exists model J Circvar (KB)
(i) J , (ii) x C J \DJ , (iii) |J | O((|KB|2 +|C|)d ), = depth(D)+1.
758

fiD EFEASIBLE NCLUSIONS L OW-C OMPLEXITY DL

Proof. Given two individuals x , distance d(x, y) minimal length role-paths
x y. Let KB knowledge base obtained KB applying transformation
presented Section 7. Notice |KB | |KB|2 .
Lemma 7.10, extended model Circvar (KB ), continue call
convenience. define small model J Circvar (KB ) x C J \ DJ . Then,
obtain thesis Lemma 7.11.
start initial domain J contains (i) x; (ii) aI , NI occurs KB ;
(iii) concepts H cl(KB ) cl(C) H 6= , witness yH H ; (iv)
concepts H cl(KB ) cl(C) supp (H) 6= , witness wH supp (H).
expand J exhaustively applying following rule (where P special case P.H
H = >):
Let J P.H cl(KB ) cl(C) (P.H)I 6 (P.H)J .
d(x, y) < d, add z J (y, z) P J , z (y, z) P z H .
Otherwise, add (y, yH ) P J .
Finally, concept name A, set AJ = J AI .
respect cardinality J , note initially number individuals J
O(|KB | + |C|). expansion, individual whose distance x less d,
O(|KB | + |C|) new individuals added. means |J | = O((|KB | + |C|)d ) =
O((|KB|2 + |C|)d ).
construction individual J H cl(KB )cl(C) H , H J .
particular, case H = P , also inverse holds, P J , P . previous
two facts immediately follows J classical model KB x C J . Moreover, since
distance x, P J contained P , P NR , easy see x 6 DJ .
remains show J minimal. Assume contradiction classical model
0
J KB , holds J 0 <var J , show exists classical model 0 KB
0 <var hypothesis Circvar (KB ).
distinguish two cases: first cas, individuals wH introduced clause (iv) still satisfy
corresponding concept H J 0 ; second case, least one wH satisfy concept
H. define 0 follows. cases, individual names interpreted concept
names individuals J interpreted J 0 .
0
first case, individual z \ J satisfies concept name A, z AI ,
0
z supp (A). Moreover, P NR , P minimal set that:
0

0

1. P J P ;
0

0

2. z \ J z supp (P.H), H J (z, y) P .
prove 0 classical model KB . Since 0 copy J 0 J J 0
classical model, need show individuals z \ J satisfy strong
inclusions KS . Note z satisfies 0 LHS H strong inclusion, z supports H
0
I. definition, z supports also RHS I. RHS concept name B, z B
0
construction. Otherwise, i.e., RHS P.H, step 2 above, suffices show H J
empty. However, assumption, witness P.H introduced clause (iv) still satisfies
P.H J 0 . Therefore, exists individual satisfying H J 0 .
Next, prove 0 <var I. Since J 0 <var J , suffices show individual z

\J satisfies 0 defeasible inclusions satisfies I. Assume DI = (A vn B)
759

fiB ONATTI , FAELLA , & AURO

0

satisfied z I. z AI , construction z supp (A). Clearly, z supp (A)
0
z satI (A vn B), z supp (B). Therefore, z B .
left prove theorem second case, i.e.: least one wH satisfy
concept H. Clearly, wH support H J 0 anymore. particular, must DI
wH satJ () \ satJ 0 (). J 0 <var J , follows must DI 0
0 K satJ ( 0 ) satJ 0 ( 0 ). Now, 0 safely violate DIs whose priority lower
0 , particular DIs whose LHS classically subsumes >. Then, complete definition
0 follows. basic concept holds individual z \ J > vKS A.
0
P NR , P minimal set
0

0

1. P J P ;
0

0

2. z \ J , > vKS P.H, H J (z, y) P .
easy verify 0 classical model KB . order prove 0 <var I, note
following two facts hold.
First, individual z \J satisfies DIs whose priority minimal. Assume
1 K 2 , DIs 1 2 , means LHS 2 subsumes LHS 1
vice versa. Then, LHS 1 subsume > hence, construction, z vacuously
satisfies 1 .
Second, z violates DI 00 = (A vn B), 0 K 00 . before, since 0 K , LHS
0
subsume >. However, since z violates 00 , z AI hence subsumes >. Therefore,
0 K 00 .
first fact immediately follows satI ( 0 ) satI 0 ( 0 ). Assume now,
00 , satI ( 00 ) 6 satI 0 ( 00 ). exists individual z \ J z satI ( 00 ) \
satI 0 ( 00 ), second fact 0 K 00 . Otherwise, must exist individual w J
w satI ( 00 ) \ satI 0 ( 00 ). However, J set DIs individual satisfies
(resp. 0 ) set DIs satisfies J (resp. J 0 ). means exists defeasible
inclusion 000 000 K 00 satJ ( 000 ) satJ 0 ( 000 ). Due first fact, 000 satisfied
\ J , hence satI ( 000 ) satI 0 ( 000 ).
2
Proposition 7.13. Let KB = hKLL Ka , EL knowledge base. Every model
CircF (unf(KB)) extended model CircF (KB).
Proof. Let Kunf = unf(KB) = hK0 , 0 i. Let model CircF (Kunf ). Extend
classical model J K0 Ka setting AJ = DJ definitions Ka . Note
K0 Ka classically equivalent KLL Ka . suppose J model CircF (KB).
Since construction J classical model Ka strong axioms KLL , must
classical model J 0 axioms J 0 <F J . restricting J 0 primitive predicates
(i.e., predicates defined Ka ), obtain classical model 0 K0 . Note
defeasible inclusions KLL , holds satJ 0 () = satJ 0 (unf(, Ka )) = satI 0 (unf(, Ka ))
satJ () = satJ (unf(, Ka )) = satI (unf(, Ka )). follows 0 <F I, contradiction.
2
Proposition 7.14. Let KB = hKLL Ka , EL knowledge base suppose
concept names defined Ka variable. Then, models CircF (KB), restriction
primitive predicates model CircF (unf(KB)).
760

fiD EFEASIBLE NCLUSIONS L OW-C OMPLEXITY DL

Proof. Let Kunf = unf(KB) = hK0 , 0 i. Let J restriction primitive predicates.
words, J obtained dropping interpretation concept names defined
Ka , variable. easily verified J classical model K0 . Suppose
contradiction J model CircF (Kunf ); exists classical model J 0
0
0
K0 J 0 <F J . extend J 0 model 0 KLL Ka setting AI = DI
definitions Ka . Since predicates defined Ka variable, fixed predicates
preserve extensions across I, J , J 0 , 0 . Moreover, defeasible inclusions KLL ,
satI 0 () = satI 0 (unf(, Ka )) = satJ 0 (unf(, Ka )) satI () = satI (unf(, Ka )) =
satJ (unf(, Ka )). follows 0 <F I, contradiction.
2
Given knowledge base KB, interpretation concept D, override
notion support; supp (D) set z
l
vKB[z] .
zAI

Clearly, classical model KB z supp (D), z DI .
Lemma 7.24. Let KB = hKS KD , LLf EL knowledge base, C, EL concepts.
models Circfix (KB) x C \ DI exists model J Circfix (KB)
(i) J , (ii) x C J \ DJ (iii) |J | O((|KB| + |C|)d ) = depth(D).
Proof. Define small model J proof Lemma 7.12, using new definition
support. Regarding size J fact classical model KB, arguments
proof Lemma 7.12 apply. particular, holds |J | = O((|KB| + |C|)d ).
remains show J <fix -minimal. Assume contradiction interpretation
0
J , holds J 0 <fix J ; usual, show exists 0 , 0 <fix I. Let 0 defined
0
0
0
0
follows: = ; aI = aI , NI ; AI = AI , NC ; P minimal set
that:
0

0

P J P ,
0

0

0

z \ J , J P.H cl(KB) z
0
0
supp (P.H), H , (z, y) P (P seen special case
H = >).
First, prove 0 classical model KB. particular, suffices show classical
0
0
inclusions satisfied \ J . Given classical inclusion C1 v D1 KB, assume
0
z C1I , recall C1 type
A1 u . . . u u R1 u . . . u Rm .
0

suffices show exists individual w J satisfies C1 well. construction,
R occurring C1 , z supp (R), therefore z supp (C1 ). means
exists witness w supp (C1 ) J . Since concept E, w E implies w E J ,
follows w supp J (C1 ). Since priority relation empty, DI KD holds
satJ () satJ 0 (). consequence, concept E holds supp J (E) supp J 0 (E).
761

fiB ONATTI , FAELLA , & AURO

0

0

particular, w supp J 0 (C1 ) hence w C1J w D1J . construction, obtain
0
z D1I .
remains prove 0 improves according <fix . Let = (C1 vn D1 ) defeasible
0
0
inclusion KB. Since J 0 <fix J , suffices prove z \ J , z satI ()
z satI 0 ().
Suppose first z vacuously satisfies (i.e., violates C1 ). Atomic concepts
extension 0 , z satisfies unqualified existential 0 satisfies
existential I. Hence, z vacuously satisfies 0 well.
0
Suppose instead z actively satisfies I. z 6 supp (C1 ), z 6 C1I , z
vacuously satisfies 0 . Otherwise, z supp (C1 ) z supp (D1 ). construction,
0
0
witness w J w supp J (D1 ) supp J 0 (D1 ). implies w D1J and,
0
0
considering construction P , z D1J . Therefore, z satJ 0 () obtain thesis. 2

References
Baader, F. (2003). instance problem specific concept description logic EL
w.r.t. terminological cycles descriptive semantics. Proc. 26th Annual German
Conf. AI, KI 2003, Vol. 2821 LNCS, pp. 6478. Springer.
Baader, F., Brandt, S., & Lutz, C. (2005). Pushing EL envelope. Proc. 19th Int. Joint
Conf. Artificial Intelligence, IJCAI-05, pp. 364369. Professional Book Center.
Baader, F., & Hollunder, B. (1995a). Embedding defaults terminological knowledge representation formalisms.. J. Autom. Reasoning, 14(1), 149180.
Baader, F., & Hollunder, B. (1995b). Priorities defaults prerequisites, application
treating specificity terminological default logic.. J. Autom. Reasoning, 15(1), 4168.
Bonatti, P. A., Faella, M., & Sauro, L. (2009). Defeasible inclusions low-complexity DLs: Preliminary notes. Boutilier, C. (Ed.), IJCAI, pp. 696701.
Bonatti, P. A., Faella, M., & Sauro, L. (2010). EL default attributes overriding. Int.
Semantic Web Conf. (ISWC 2010), Vol. 6496 LNCS, pp. 6479. Springer.
Bonatti, P. A., Lutz, C., & Wolter, F. (2006). Description logics circumscription. Doherty,
P., Mylopoulos, J., & Welty, C. A. (Eds.), KR, pp. 400410. AAAI Press.
Bonatti, P. A., Lutz, C., & Wolter, F. (2009). complexity circumscription DLs. J. Artif.
Intell. Res. (JAIR), 35, 717773.
Bonatti, P. A., & Samarati, P. (2003). Logics authorization security. Logics Emerging
Applications Databases, pp. 277323. Springer.
Cadoli, M., Donini, F., & Schaerf, M. (1990). Closed world reasoning hybrid systems. Proc.
ISMIS90, pp. 474481. Elsevier.
Cadoli, M., Eiter, T., & Gottlob, G. (1992). efficient method eliminating varying predicates
circumscription. Artif. Intell., 54(2), 397410.
Calvanese, D., De Giacomo, G., Lembo, D., Lenzerini, M., & Rosati, R. (2005). DL-Lite: Tractable
description logics ontologies. Proc. AAAI 2005, pp. 602607.
762

fiD EFEASIBLE NCLUSIONS L OW-C OMPLEXITY DL

Casini, G., & Straccia, U. (2010). Rational closure defeasible description logics. Janhunen,
T., & Niemela, I. (Eds.), JELIA, Vol. 6341 Lecture Notes Computer Science, pp. 7790.
Springer.
Donini, F. M., Nardi, D., & Rosati, R. (1997). Autoepistemic description logics. IJCAI, pp.
136141.
Donini, F. M., Nardi, D., & Rosati, R. (2002). Description logics minimal knowledge negation failure. ACM Trans. Comput. Log., 3(2), 177225.
Eiter, T., Leone, N., Mateis, C., Pfeifer, G., & Scarcello, F. (1997). deductive system nonmonotonic reasoning. Logic Programming Nonmonotonic Reasoning, 4th International Conference, LPNMR97, Proceedings, Vol. 1265 LNCS, pp. 364375. Springer.
Eiter, T., & Gottlob, G. (1995). computational cost disjunctive logic programming: Propositional case. Ann. Math. Artif. Intell., 15(3-4), 289323.
Finin, T. W., Joshi, A., Kagal, L., Niu, J., Sandhu, R. S., Winsborough, W. H., & Thuraisingham,
B. M. (2008). ROWLBAC: representing role based access control OWL. Ray, I., & Li,
N. (Eds.), SACMAT, pp. 7382. ACM.
Giordano, L., Gliozzi, V., Olivetti, N., & Pozzato, G. (2008). Reasoning typicality preferential description logics. Proc. Logics Artificial Intelligence, 11th European Conference,
JELIA 2008, Vol. 5293 Lecture Notes Computer Science. Springer.
Kolovski, V., Hendler, J. A., & Parsia, B. (2007). Analyzing web access control policies.
Williamson, C. L., Zurko, M. E., Patel-Schneider, P. F., & Shenoy, P. J. (Eds.), WWW, pp.
677686. ACM.
Lutz, C., & Wolter, F. (2010). Deciding inseparability conservative extensions description
logic el. J. Symb. Comput., 45(2), 194228.
McCarthy, J. (1980). Circumscription - form non-monotonic reasoning. Artif. Intell., 13(1-2),
2739.
McCarthy, J. (1986). Applications circumscription formalizing common-sense knowledge.
Artif. Intell., 28(1), 89116.
Rector, A. L. (2004). Defaults, context, knowledge: Alternatives OWL-indexed knowledge
bases. Pacific Symposium Biocomputing, pp. 226237. World Scientific.
Stevens, R., Aranguren, M. E., Wolstencroft, K., Sattler, U., Drummond, N., Horridge, M., & Rector,
A. L. (2007). Using OWL model biological knowledge. International Journal ManMachine Studies, 65(7), 583594.
Straccia, U. (1993). Default inheritance reasoning hybrid KL-ONE-style logics.. IJCAI, pp.
676681.
Uszok, A., Bradshaw, J. M., Jeffers, R., Suri, N., Hayes, P. J., Breedy, M. R., Bunch, L., Johnson, M.,
Kulkarni, S., & Lott, J. (2003). KAoS policy domain services: Towards descriptionlogic approach policy representation, deconfliction, enforcement.. 4th IEEE Int.
Workshop Policies Distributed Systems Networks (POLICY), pp. 9396. IEEE
Computer Soc.
763

fiB ONATTI , FAELLA , & AURO

Zhang, R., Artale, A., Giunchiglia, F., & Crispo, B. (2009). Using description logics relation
based access control. Grau, B. C., Horrocks, I., Motik, B., & Sattler, U. (Eds.), Description
Logics, Vol. 477 CEUR Workshop Proceedings. CEUR-WS.org.

764

fiJournal Artificial Intelligence Research 42 (2011) 607-659

Submitted 09/11; published 12/11

Drake: Efficient Executive Temporal
Plans Choice
Patrick R. Conrad
Brian C. Williams

prconrad@mit.edu
williams@mit.edu

Room 32-227
32 Vassar St
Cambridge, 02139 USA

Abstract
work presents Drake, dynamic executive temporal plans choice. Dynamic plan execution strategies allow autonomous agent react quickly unfolding
events, improving robustness agent. Prior work developed methods dynamically dispatching Simple Temporal Networks, research enriched expressiveness plans executives could handle, including discrete choices, focus
work. However, approaches date, additional choices induce significant
storage latency requirements make flexible execution possible.
Drake designed leverage low latency made possible preprocessing step
called compilation, avoiding high memory costs compact representation.
leverage concepts labels environments, taken prior work Assumptionbased Truth Maintenance Systems (ATMS), concisely record implications
discrete choices, exploiting structure plan avoid redundant reasoning storage. labeling maintenance scheme, called Labeled Value Set Maintenance
System, distinguished focus properties fundamental temporal problems, and,
generally, weighted graph algorithms. particular, maintenance system focuses
maintaining minimal representation non-dominated constraints. benchmark
Drakes performance random structured problems, find Drake reduces size
compiled representation factor 500 large problems, incurring
modest increase run-time latency, compared prior work compiled executives
temporal plans discrete choices.

1. Introduction
Model-based executives elevate commanding autonomous systems level goal
states providing guarantees correctness (Williams, Ingham, Chung, & Elliott, 2003).
Using model-based executive, user provide specification goal behavior
robot leave program, executive, determine appropriate course
action meets goals. Temporal plan executives designed work plans
including timing requirements.
Typically, executive robust disturbances, must able react
outcomes events fly, otherwise, even seemingly inconsequential variations
outcomes events may cause failure. Thus, helpful follow strategy least
commitment delay decision actually time act decision, allowing
executive act much information possible. case temporal plans,
executive following strategy said dynamically dispatch plan (Muscettola,
c
2011
AI Access Foundation. rights reserved.

fiConrad & Williams

Morris, & Tsamardinos, 1998). executive responsible determining
schedule events late possible guaranteeing consistent schedule exists
remaining events. external disturbance causes timing requirement
violated, executive discover failure signal soon possible.
Making decisions fly requires care, on-line temporal reasoning
introduce latency unacceptable real-time system. Therefore, Muscettola et al.
(1998) developed low-latency executive Simple Temporal Networks (STNs),
STN comprised set events difference constraints time execution
events. achieve low latency, executive broken two parts, compiler
dispatcher. compiler run advance discover explicitly record temporal
constraints cannot quickly inferred on-line, thereby computing dispatchable
form plan. dispatcher uses form make real-time decisions using greedy
strategy local, low-latency inferences.
dynamic scheduling proven effective, robustness improved
making additional decision dynamically, assignment activity particular resource. Encoding decisions requires expressive formalism STNs.
Consequently, subsequent research developed efficient executives expressive
frameworks, many variants STN. Examples added features include
explicit modeling uncertainty (Morris, Muscettola, & Vidal, 2001; Rossi, Venable, &
Yorke-Smith, 2006; Shah & Williams, 2008), discrete choices (Kim, Williams, & Abramson,
2001; Tsamardinos, Pollack, & Ganchev, 2001; Combi & Posenato, 2009; Shah & Williams,
2008), preferences (Hiatt, Zimmerman, Smith, & Simmons, 2009; Khatib, Morris, Morris,
& Rossi, 2001; Kim et al., 2001), discrete observations (Tsamardinos, Vidal, & Pollack,
2003), combinations thereof.
work focuses enriching executive simultaneously schedule events
make discrete choices execution unfolds. ability make discrete choices greatly
enriches executive offering ability dynamically allocate resources, order activities, choose alternate methods (sub-plans) achieving goals. Although prior
works developed executives type plan, trade-offs performance.
example, Tsamardinos, Pollack, Ganchev (2001) presented executive Disjunctive Temporal Networks (DTN), variant STNs include discrete choices.
executive extends compilation strategy STNs breaking DTN complete
exponential set component STNs compiling dispatching parallel.
strategy offers low latency, incurs high storage cost dispatchable plan.
Another example, Kirk, executive Temporal Plan Networks (TPNs), extends
STNs including hierarchical choice sub-plans, developed Kim, Williams,
Abramson (2001). Kirk selects set choices performs incremental re-planning
whenever disturbance invalidates choice, leaving small memory footprint, potentially inducing high latency selects new choices. Chaski executive presented
Shah Williams (2007) temporal plans resource allocation, whose expressiveness STNs DTNs. Chaski takes approach hybrid
incremental strategy Kirk compiled approach Tsamardinos et al.:
compiled representation base plan set incremental differences, provides
benefits compiled execution improving efficiency exploiting structure
plan .
608

fiDrake: Efficient Executive Temporal Plans Choice

develop Drake, novel executive temporal plans choice encoded using
expressive representation DTNs (DTNs dominate TPNs, TCNs, STNs). Drake
achieves low run-time latency compilation, yet requires less storage fully
exponential expansion approach taken Tsamardinos et al. (2001). order accomplish this, Drake works compact representation temporal constraints discrete
choices. develop compact representation, begin idea, taken truth
maintenance, labeling consequences inferences minimal set choices imply consequence; minimal set called environment (McDermott, 1983; de Kleer,
1986). monotonicity inference, consequence also holds sets choices
superset minimal environment, thus environment compact encoding
decision contexts consequence holds.
ideas directly applicable temporal reasoning problems; Drake extends
leveraging properties fundamental temporal reasoning problems, weighted graph
problems general. specifically, temporal reasoning non-monotonic, sense
need explicitly represent derivable constraints, tightest possible ones, referred non-dominated constraints. Drake uses property throughout
reduce computations storage required. example, inequality 4 8,
temporal event, need store constraint 8, tighter
inequality makes unnecessary, dominates it. focus non-dominated values
constraints central range inference problems, including temporal inference, interval
reasoning, inference weighted graphs.
Dechter, Meiri, Pearl (1991) proved STN inference problems reducible
widely used set inference methods weighted graphs, Single Source Shortest
Path All-Pairs Shortest Path Problems. approach develop labeled analogues
weighted graph structures support shortest path algorithms, providing
compact representation Drake. paper, first present new formalism plans
choice, Labeled Simple Temporal Network (Labeled STN),
expressiveness previous formalisms, shares ideas rest techniques.
Second, explain system maintaining deriving compact representations values
vary choices, called Labeled Value Set Maintenance System. Then, use
Labeled Value Sets construct Labeled Distance Graphs, distance graphs
edge weights may vary depending discrete choices. Finally, Drakes compilation
dispatching algorithms built around techniques. focus paper
dispatchable execution, techniques surrounding labeled distance graphs hold
promise extending wide range reasoning methods involving graph algorithms
include choice.
practical terms, Drakes compact encoding provides reduction size plan
used dispatcher two orders magnitude problems around 2,000
component STNs, compared Tsamardinos et al.s work (2001). size reduction
comes modest increase run-time latency, making Drake useful addition
available executives.
609

fiConrad & Williams

1.1 Overview Problem
Drake takes input Labeled STN, temporal constraint representation
choices; Section 3 discuss Labeled STNs encode choices subplans, temporal constraints, resource assignment, mappings related frameworks.
Drakes output dynamic execution plan, determines real-time
execute events, end plan execution times consistent
every temporal constraint implied least one complete set choices, barring unforeseen
disturbances. outside disturbances make every possible execution inconsistent, Drake
signals failure soon possible solutions rendered inconsistent.
Section 3 provides formal definition Labeled STNs; essentially, collection
events schedule constraints executive must follow. events may constrained simple temporal constraints, limit difference scheduled times
two events. Furthermore, Labeled STN specifies discrete choices, assignments
choices may imply additional simple temporal constraints.
Throughout paper, use following simple example, includes choice
sub-plans.
Example 1.1 rover 100 minutes work scheduled contact operators. contact, rover must drive next landmark, taking 30
70 minutes. fill remaining time, rover two options: collect samples
charge batteries. Collecting samples consistently takes 50 60 minutes, whereas
charging batteries usefully done duration 50 minutes.


Always: [0, 100]

collecting: Collect
Samples, [50, 60]

C

collecting: [0, 0]

Always:
Drive, [30, 70]


Always: [0, 0]
B

charging:
Charge [0, 50]

E



F

charging: [0, 0]

Figure 1.1: informal Labeled STN depicts Example 1.1. rover needs drive,
either collect samples charge batteries within certain time limit.

610

fiDrake: Efficient Executive Temporal Plans Choice

Figure 1.1 shows informal representation Labeled-STN corresponding
plan. notation [l, u] edge vertex X means difference
execution times events lies given interval, expresses constraint
l X u. figure text explains temporal constraints implied
choice; develop precise notation later. two types constraints drawn,
always required, required rover either collecting
samples charging.
Consider following correct output execution sequence rover problem.
example, focus form executives output, deferring presentation
decision-making strategy later.
Example 1.2 Drake starts executing plan, arbitrarily denoting starting time
= 0. time, instructs system begin drive activity, indicating
drive take 40 minutes. executive waits system responds
drive completed, time = 45. Drake selects sample collection
option, determined before, initiates activity duration
50 minutes. = 95, sample collection completes, finishing plan within time
limit 100 minutes.

1.2 Approach: Exploiting Shared Structure Labeling
Drakes strategy compilation begin Labeled STN, concise statement
temporal constraints choices plan. Then, Drake constructs Labeled Distance Graph associated Labeled STN, yielding single graph structure
representing possible choices constraints. Next, Drakes compiler computes
dispatchable form problem, also Labeled Distance Graph. compilation performed unified process able exploit similarities
choices make representation compact. contrast, prior work Tsamardinos et
al. (2001), breaks input plan independent STNs, hence compilation strategy
cannot exploit similarities shared structures choices. pathological cases, every choice completely unrelated, similarities
Drake exploit. However, expect nearly every real-world human designed
plan degree shared structure, plan usually unifying idea
choices designed accomplish. Indeed, expect real plans
significant similarities, allowing Drake perform well. section gives overview
intuition behind representation Drake uses similarities Drake exploit.
continue discussing rover example, consider Figure 1.2, depicts
small STN, associated distance graph, dispatchable distance graph
result compilation. set events STN represented vertices
distance graph. Upper bounds STN induce edges forward direction, weighted
upper bound, lower bounds induce edges reverse direction weighted
negative lower bound. distance graph Figure 1.2b compiled,
compiler outputs new distance graph contains representations constraints
needed dispatcher. dispatchable form Figure 1.2c used dispatcher;
execution times propagated edges determine events may
executed.
611

fiConrad & Williams

[5, 10]


C

[3, 3]

10



3

[2, 5]

C

-5
-3

2

5

B

B

(a) Input STN

(b) Associated distance graph

8



-5
3

C

-3

B
(c) Dispatchable graph

Figure 1.2: simple example reformulating STN associated distance graph
dispatchable form.

rover example single binary choice, hence problem Tsamardinos et al.s
(2001) algorithm separates two possible STNs compute associated distance
graphs, shown Figure 1.3. Note repetition certain edges graphs,
example, edge F , present throughout compilation dispatch
process. Plans choices exponential number repetitions,
costly, Drake designed eliminate.
informal version Labeled Distance Graph associated rover example
shown Figure 1.4. differing constraints result two possible assignments
choice distinguished annotations called labels. example, edge (B, C)
weight : 60, indicates whenever sampling chosen, edge weight
60; value 60 labeled discrete choice, S, implies it. gather
possible values choices Labeled Value Sets, placed
edges. example, edge Labeled Value Set exactly one labeled value,
although true general. Labeled Distance Graph essentially distance
graph numeric weights replaced Labeled Value Sets. Although develop
precise notation later article, version shows intuition behind
approach. Drake capitalizes improvement using compact representation
throughout compilation dispatch, work develops necessary machinery.
paper organized follows. Section 2 discusses related work temporal executives provides background truth maintenance. Section 3 defines Labeled STNs
correct dynamic execution, specifying problem Drake solves. Section 4 recalls
612

fiDrake: Efficient Executive Temporal Plans Choice

100
0

C


70
-30

60
-50

0
0

B

E

0
0

F

0
0

F


(a) Distance graph collecting samples

100
0

C


70
-30

B

E
0

50
0

0


(b) Distance graph charging

Figure 1.3: Tsamardinos et al. (2001) style distance graphs associated
Labeled-STN Figure 1.1.

link STNs distance graphs, provides labeled version distance graphs,
Drake uses reasoning. Section 5 presents Labeled Value Set Maintenance System, completing foundation labeled techniques. Section 6 details dispatcher
Section 7 develops Drakes compilation algorithm. Finally, Section 8 provides theoretical experimental performance results, Section 9 gives concluding remarks.

2. Related Work
developing Drake, give overview relevant literature two major
areas Drake draws from: scheduling frameworks truth maintenance.
613

fiConrad & Williams

A: 100
A: 0

C
S: 60
S: 50


A: 70
A:30

S: 0
S: 0

B

E

A: 0
A: 0

F

C: 0
C: 0

C: 50
C: 0


Figure 1.4: informal labeled distance graph rover example. A:, S: C:,
correspond weights hold always, sampling, charging,
respectively.

2.1 Scheduling Frameworks Executives
stated introduction, achieve robustness, need executives make decisions
dynamically low latency expressive temporal representations.
known methods manipulating reasoning Simple Temporal Networks efficiently,
used foundation work temporal executives. Furthermore,
numerous efforts formulated developed extensions STNs include useful
properties, including uncertainty, preferences, discrete choices. briefly review
efforts. Since work focuses discrete choices, discuss several efforts build
dynamic executives plans detail. executives typically use one
two approaches: reason plans parallel, switch plans incrementally.
However, approaches, promising, typically either memory intensive
may high latency.
Temporal Constraint Networks (TCNs), formalized Dechter, Meiri Pearl (1991),
capture many qualitative metric temporal representations introduced AI
community. restricted type TCN, Simple Temporal Network, used throughout
recent work temporal planning, temporal reasoning, scheduling. Muscettola, Morris,
Tsamardinos (1998) proposed framework low-latency dynamic execution: preprocessing step called compilation run-time component called dispatch. Tsamardinos,
Muscettola, Morris (1998) later provided faster compilation algorithm. work
also developed efficient methods testing consistency STNs (Xu & Choueiry,
2003; Planken, de Weerdt, & van der Krogt, 2008).
614

fiDrake: Efficient Executive Temporal Plans Choice

Dechter et al. (1991) also proposed Temporal Constraint Satisfaction Problems,
include discrete choices alter simple interval constraint particular pairs
events; pair may choice interval constraints, choices pair events
must independent. Stergiou Koubarakis (2000) loosened structural restriction,
developing Disjunctive Temporal Network (DTN). Tsamardinos, Pollack, Ganchev
(2001) presented first dynamic executive DTNs, functions generating
component STNs implied combinations discrete choices compiling
independently, creating exponential growth memory use respect number
choices.
Another important line extension STNs Simple Temporal Network Uncertainty (STNU). Morris, Muscettola, Vidal (2001) proved executive test
consistency STNU compile dispatchable form polynomial time. Morris (2006) described efficient algorithm testing dynamic controllability. Hunsberg
(2009, 2010) corrected flaw previous definitions described execution strategy
using efficient dynamic controllability algorithm. Venable Yorke-Smith (2005)
added temporal uncertainty DTNs. Tsamardinos (2002) introduced probabilistic formulation uncertainty STNs. Conrad (2010) presents extension Drake DTNs
uncertainty.
Tsamardinos, Vidal, Pollack (2003) introduced Conditional Temporal Problems
(CTP), adding uncontrollable discrete choices. executive cannot control, may
observe values discrete choices designated parts plan.
notation quite similar used Drake, two important
differences. First, CTP strictly harder problem, since Drake concerned
uncontrollable choices, meaning algorithm work necessary
simpler case. Second, algorithm use compact representation;
algorithm consistency checking requires enumerating possible scenarios. open
problem future research adapt general algorithms take advantage
compactness Labeled Distance Graph.
Another useful feature added STNs preferences. Khatib, Morris, Morris, Rossi
(2001) introduced formulation including preferences event execution times within
simple interval bounds allowed STN, adding notion quality existing notion
consistency. Rossi, Venable, Yorke-Smith (2006) discuss simultaneous handling
uncertainty preferences.
Kim, Williams, Abramson (2001) present Temporal Plan Networks, representation
provides simple temporal constraints durations combined series, parallel,
choice, choice specified costs. Effinger (2006) expands simple
preference model, choices activities associated, fixed costs. Kirk
dynamic executive TPNs. Kirk performs optimal method selection run-time,
assigning discrete choices dispatches resulting component STN.
disturbance invalidates STN Kirk chose, Kirk selects new STN consistent
execution thus far. research developed incremental techniques allow
Kirk re-plan lower latency (Shu, Effinger, & Williams, 2005; Block, Wehowsky, &
Williams, 2006).
Shah Williams (2008) present Chaski, executive dynamically dispatches
plans task assignment heterogeneous, cooperative agents, represented TCN,
615

fiConrad & Williams

removing redundant data structures computations performed Tsamardinos
et al.s (2001) algorithm. Shah Williams point component STNs realworld TCNs often differ constraints, allowing compact representation.
record component STNs storing single relaxed STN maintaining list
modifications relaxed STN recover original component STNs.
avoiding redundant records shared constraints, results show dramatic improvements
performance. work inspired observation technique, although
distinct, bears resemblance environment labeling scheme employed
Assumption Based Truth Maintenance System (ATMS). specifically adapted ATMS
ideas work general problem formulation Chaski, expecting see similar
performance improvements.
Combi Posenato (2009, 2010) discuss applications dynamic executives business
work flows, include flexibility time execution, hierarchical choice execution
paths, temporal uncertainty. formalism plans, Workflow Schemata, closely
related DTN, STNU, TPN frameworks, discuss variants compilation
dispatching algorithms specialized representations. work describes
intriguing notion call history-dependent controllability. model, event
X starts one two sub-plans, executive may invalidate either sub-plan
executes X begins one them. Drake impose similar requirement,
requirement certainly useful preserving executives flexibility future choices
execution unfolds. algorithms testing controllability enumerate possible
choices, therefore suffers memory growth.
Smith, Gallagher, Zimmerman (2007) describe distributed dynamic executive
real world plans C TAEMS language. representation uses STN temporal semantics includes features intended represent cooperative multi-agent plans.
language features rich practical notion activity failure present STNs,
including potential interruption activities. executive given discrete choices
method selection resource allocation, attempts maximize utility
overall plan. preference model accounts partial total method failures supports different functions accumulating reward, example, summing maxing.
executive uses re-planning strategy, similar Kirk, enhanced Hiatt, Zimmerman, Smith, Simmons (2009) type compile-time analysis called strengthening.
analysis performs type local repair attempts make plan robust
uncertainties activity failures.
two central approaches dynamic executives include discrete choices.
First, Tsamardinos et al.s (2003) CTPs, Tsamardinos et al.s (2001) DTN dispatcher,
Combi et al. (2010) use compile-time analysis compute implied constraints every
possible plan explicitly reason run-time. Second, Kim et al. (2001),
Smith et al. (2007) focus single, potentially optimal, assignment choices,
becomes infeasible, incrementally re-plan extract new plan. methods
shortcomings, since explicit compilation memory intensive re-planning steps
computationally intensive, especially executive forced re-plan often. Drake,
like Chaski, provides middle ground working compilation strategy
reduced memory footprint.
616

fiDrake: Efficient Executive Temporal Plans Choice

2.2 Background ATMSs
Stallman Sussman (1977) introduced profoundly useful idea tracing dependency deductions computerized aid circuit diagnosis, order focus search
consistent component mode assignment transistor circuit analysis. dependencies computes solving equations allow rapidly find choices
might responsible detected failure. generalize approach combinatorial search, introducing dependency-directed backtracking algorithm, ensures
conflict found search backs far enough ensure newly
found inconsistency actually removed.
Doyle (1979) introduced Truth Maintenance Systems (TMSs) domain independent
method supporting dependency-directed backtracking. TMS represents data,
justifications, provides ability revise beliefs assumptions change contradictions arise. example, consider problem solver designed search solution
constraint satisfaction problem. determining whether particular solution
consistent, problem solver perform chain inferences, providing TMS
justification step. inconsistency found, problem solver selects new
candidate solution, TMS uses justifications determine inferences
still hold new candidate must recomputed account new circumstances. TMS continually determines whether particular datum, general term
fact arises problem solving, out, is, currently believed true,
currently believed.
Later work relaxes goal maintaining single, consistent assignment data
out, instead tracks contexts particular facts hold, even
contexts may mutually exclusive. McDermott (1983) uses beads state context,
particular set choices assumptions reasoning might rely, provides
data pools specify facts hold context. De Kleer (1986) develops
Assumption-based Truth Maintenance System, uses similar idea, changes
terminology use environments labels specify contexts. ATMS maintains set
minimal inconsistent environments, called conflicts no-goods. conflicts help
system avoid performing inferences contexts already known inconsistent,
minimality conflict set makes procedure tractable. ATMS designed
simultaneously find logical consequences possible combinations assumptions,
contrast TMS, focuses finding one set assumptions solve
problem interest. Hence, ATMS well suited foundation executive
intended consider possible choices simultaneously without incurring latency
switching choices. Finally, development idea
working inequalities, ATMS needs keep tightest bounds inequalities,
use extensively; concept described Goldstone (1991) hibernation.
leave review details ATMS later sections, develop Drakes
machinery depth.

3. Dynamic Execution STNs Labeled STNs
prepared present formal representation temporal plans Drake
uses. Plans composed actions need performed feasible times,
617

fiConrad & Williams

define feasible times constraints start end times plan activities.
work builds upon Simple Temporal Networks, begin explaining STNs
constrain events plan feasible execution. extend definitions
include discrete choices, thereby constructing Labeled STNs.
3.1 Simple Temporal Networks
Simple Temporal Networks provide framework efficiently reasoning limited
form temporal constraints. simple temporal network defined set events related
binary interval constraints, called simple interval constraints (Dechter et al., 1991).
Definition 3.1 (Event) event real-valued variable, whose value execution
time event.

Definition 3.2 (Simple Interval Constraint) simple interval constraint hA, B, l, ui
two events B requires l B u, denoted, [l, u].

convention, u non-negative. lower bound, l may positive strict
ordering events, negative strict ordering. Positive negative
infinities may used bounds represent unconstrained relationship.
Definition 3.3 (Simple Temporal Network) Simple Temporal Network hV, Ci
comprised set events V set simple interval constraints C. schedule
STN assignment real number event V , representing time
schedule event. Simple Temporal Problem (STP) is, given STN hV, Ci,
return consistent schedule possible, else return false. consistent schedule schedule
satisfies every constraint C. least one solution exists, STN
consistent.

Definition 3.4 (Dynamic Execution) dynamic execution STN construction consistent schedule STN real-time. executive decides time
whether execute events time t, suitably small . time,
longer remaining consistent schedules, return false immediately. executive
may arbitrarily select consistent schedule.

3.2 Adding Choice: Labeled STNs
section defines key representational concept, Labeled STNs, variant STNs
designed include discrete choices temporal constraints. Although equivalent
expressiveness Disjunctive Temporal Networks, Labeled STNs provide consistent
terminology Drake, corresponding labeled distance graphs make easier
extend standard STN weighted graph algorithms include choice. show precise
connection DTNs Labeled STNs end section. definitions
used throughout compilation dispatching algorithms presented later
work.
input problem needs succinct way state choices input plan
possible options executive may select between. accomplish
set finite domain variables.
618

fiDrake: Efficient Executive Temporal Plans Choice

Definition 3.5 (Choice Variables) choice associated finite domain variable xi . variables domain size equal number options
choice. X set variables particular problem. assignment
selection single option choice, represented assignment choices
associated choice variable.

Example 3.6 rover example, single choice two options, leading
single variable x {collect, drive}. might assign x = collect represent choice
collecting samples.

general, Drake reason implications combinations assignments.
specify assignments choice variables, Drake uses environments. Following ATMS, Drake annotates, labels interval constraints edge weights
environments specifying entailed.
Definition 3.7 (Environment) environment partial assignment choice
variables X, written e = {xi = dij , ...}. environment may one assignment
variable consistent. complete environment contains assignment every
choice variable X. empty environment provides assignments written {}.
denote set possible environments E set complete environments
Ec . length environment number assigned variables, denoted |e|.

Example 3.8 problem two choice variables x, {1, 2}, possible environments {}, {x = 1}, {y = 2}, {x = 1, = 2}.

Labeled STN, different assignments choice variables entail different temporal
constraints, represent labeled simple interval constraints.
Definition 3.9 (Labeled Simple Interval Constraint) labeled simple interval constraint tuple hA, B, l, u, ei pair events B, real valued weights l u
environment e E. constraint states that, assignments e hold,
simple interval constraint hA, B, l, ui entailed.

Labeled STN defined analogously STN, extended include choices
labeled constraints.
Definition 3.10 (Labeled Simple Temporal Network) Labeled STN hV, X, Ci
set events V , set choice variables X, set labeled simple interval constraints
C. STNs, schedule Labeled STN assignment real numbers
event, indicating time execute event. schedule consistent
full assignment choice variables schedule satisfies every simple interval
constraint entailed labeled simple interval constraint.

Example 3.11 (Rover Problem Labeled STN) rover problem Example
1.1 single choice, two options, collecting samples charging batteries.
Use single choice variable x {collect, charge} represent choice. network
events {A, B, C, D, E, F }. labeled simple interval constraints written
e : l B u.
619

fiConrad & Williams

{} : 0 F 100

(1)

{} : 30 B 70

(2)

{} : 0 F E 0

(3)

{x = collect} : 50 C B 60

(4)

{x = collect} : 0 E C 0

(5)

{x = charge} : 0 B 50

(6)

{x = charge} : 0 E 0

(7)

notation states inequalities lines 1-3 must always hold, lines 4-5 must
hold executive decides collect samples, lines 6-7 must hold executive
decides charge batteries. schedule given Example 1.2, = 0, B = 45, C =
95, = 45, E = 95, F = 95, consistent full assignment x = collect.
constraints lines 1-3 hold choice, necessarily must hold here. Lines 4-5 give
constraints environments whose assignments given full assignment,
simple interval constraints must hold, do. Lines 6-7 give constraints
environment include different assignments full assignment, constraints
need hold schedule consistent.

Drake provides dynamic execution Labeled STN, making decisions run-time,
late possible.
Definition 3.12 (Dynamic execution Labeled STN) dynamic execution
Labeled STN simultaneous real-time construction full assignment corresponding consistent schedule. executive decides time whether execute
events time t, suitably small . Possible assignments choices eliminated consideration necessary schedule events. executive may arbitrarily
select consistent schedule.

Example 1.2 gave dynamic execution rover problem dispatcher selected choices scheduling times dynamically, choosing option collect samples
immediately start sample collection activity.
conclude section discussing equivalence DTNs Labeled STNs,
allow easier comparison prior work. Recall definition DTNs (Stergiou &
Koubarakis, 2000).
Definition 3.13 (Disjunctive Temporal Network) Disjunctive Temporal Network
hV, Ci set events V set disjunctive constraints C. disjunctive constraint
Ci C form
ci1 ci2 ... cin ,
(8)
positive integer n cij simple interval constraint. before, schedule
assignment time event. schedule consistent least
one simple interval constraint cij satisfied every disjunctive constraint Ci . DTN
consistent least one consistent schedule exists.

620

fiDrake: Efficient Executive Temporal Plans Choice

DTN Labeled STN definitions analogous, except difference
choices specified. construct Labeled STN equivalent DTN creating
choice variable disjunctive constraint, one value disjunct. Thus,
xi = 1...n. disjunctive constraint DTN, cij labeled environment xi = j.
Non-disjunctive constraints labeled {}.
Example 3.14 Consider DTN three events, A, B, C. Assume two disjunctive constraints, hA, B, 3, 5i, hB, C, 0, 6i hA, C, 4, 4i. corresponding Labeled STN would one binary choice, represented x {1, 2}. would
three labeled simple interval constraints: hA, B, 3, 5, {}i, hB, C, 0, 6, {x = 1}i,
hA, C, 4, 4, {x = 2}i.

see reverse construction, note DTN specifies set simple interval
constraint conjunctive normal form. Labeled STNs allow specification somewhat
complex boolean expressions, boolean expressions reducible conjunctive
normal form, Labeled STNs expressive. mapping DTNs
Labeled STNs straightforward construct Labeled STN directly uses
conjunctive normal form expression.
Example 3.15 Consider rover problem, given Labeled STN Example 3.11.
represent constraint 0 F 100 CF,A , identify problem
following boolean form
CF,A CB,A CF,E ((CC,B CE,C ) (CD,B CE,D ))

(9)

could expand conjunctive normal form
CF,A CB,A CF,E (CC,B CD,B ) (CC,B CE,D ) (CD,B CE,C )
form, construct DTN directly.

(10)


Thus, like DTN, Labeled STNs provide rich notion choice. Given definition
problem Drake solves section introduction environments,
next two sections develop labeled machinery Drake uses efficiently perform temporal
reasoning.

4. Distance Graphs Temporal Reasoning
Dechter et al. (1991) showed STN reasoning reformulated shortest path
problem associated weighted distance graph. connection important
weighted graphs easy manipulate well developed theory efficient algorithms, hence practical algorithms STNs based connection. Drake
follows prior literature, frames temporal reasoning labeled version
shortest path problems. section begins develop formalism Labeled Value
Sets Labeled Distance Graphs, allow us compactly represent shortest path
problems algorithms. begin reviewing transformation STNs.
621

fiConrad & Williams

Definition 4.1 (Distance Graph associated STN) distance graph associated STN pair hV, W vertices V edge weights W . event
associated vertex V . vertices exactly correspond events STN.
weights function V V R. simple temporal constraint l B u
represented edge weights W (B, A) = u W (A, B) = l.

Figure 1.2 shows example conversion STN distance graph. Recall STN consistent associated distance graph
negative cycles (Dechter et al., 1991). compilation algorithm STN takes
associated distance graph input outputs another distance graph
dispatchable form.
Definition 4.2 (Dispatchable form distance graph) weighted distance graph
dispatchable form STN executive may dynamically execute STN
greedy fashion construct consistent schedule using local propagations.
dispatchable form minimal edges actually needed dispatcher
correct execution.

all-pairs shortest path (APSP) graph distance graph associated STN
dispatchable form explicitly contains possible constraints STN
(Muscettola et al., 1998). minimal form computable performing pruning
APSP graph.
begin building labeling formalism defining labeled value pairs.
labeled simple temporal constraints environments, labeled values associate values
environments.
Definition 4.3 (Labeled Value Pair) Labeled Value Pair pair (a, e),
value e E environment. value entailed (usually assignment
inequality bound) environments assignments e hold.

compilation dispatch, Drake uses labeled value pairs track real valued
bounds, R. compilation, performing shortest path computations,
Drake tracks predecessor vertices, value may pair (b, v) R V .
two types values complicates discussion somewhat, necessary
compilation algorithms, allows elegant implementation relaxation algorithm
directed, weighted graphs. ATMS strategy associating environments values
well founded arbitrary type value, choices sound. Labeled value
pairs always use minimal environments, is, environment specifies smallest set
assignments possible implication true. minimality critical
labeling system efficient.
Example 4.4 choice variable x {1, 2}, (3, {x = 1}) real valued
labeled value pair. Similarly, event, ((2, A), {x = 2}) possible predecessor
graph labeled value pair.

arrived crucial contribution paper: extending domination
labeled space. inequality B 4 5, clear need
622

fiDrake: Efficient Executive Temporal Plans Choice

keep dominant value, four, may discard five. Shortest path algorithms
widely use concept dominance propose many possible paths keep
tightest one. applied labeled value pairs, dominance involves ordering two
parts, value environment. Drake, values always ordered using real valued
inequalities, either . paper mostly uses , except reasoning lower
bounds dispatch, explicitly noted. necessary, direct replacement
inequality direction suffices extend definitions. Environments ordered
concept subsumption.
Definition 4.5 (Subsumption Environments) environment e subsumes e0
every assignment xi = dij e, assignment exists e0 , denoted xi = dij e0 .
Example 4.6 environment {x = 1, = 2, z = 1} subsumed {x = 1, z = 1}
assignments later environment included former.

domination labeled value pairs applies orderings simultaneously.
Definition 4.7 (Dominated Labeled Value Pair) Let (a, ea ), (b, eb ) two labeled
value pairs values ordered . (a, ea ) dominates (b, eb ) b
ea subsumes eb .

Example 4.8 B 4 {} also B 4 {x = 1},
first inequality non-dominated environment less restrictive. Thus (4, {})
dominates (4, {x = 1}). Likewise, B 2 {x = 1}, constraint dominates
constraint B 4 {x = 1}, first inequality tighter holds
within every environment second inequality holds, hence (2, {x = 1}) dominates
(4, {x = 1}).

represent various values bound may have, depending choices executive makes, Drake collects non-dominated labeled value pairs Labeled Value
Set.
Definition 4.9 (Labeled Value Set) Labeled Value Set, L set non-dominated labeled value pairs, is, set pairs (ai , ei ). Thus, may write L = {(a1 , e1 ), ...(an , en )}.
labeled value pair set dominant another pair set.

particular labeled value set, values type, either real values
value/vertex pairs.
Example 4.10 Assume single choice variable, x {1, 2}. real valued
variable, R value 3 x = 1 5 x = 2. represented labeled
value set, = {(3, {x = 1}), (5, {x = 2})}.

Finally, modify distance graphs use Labeled Value Sets instead real values
weights, leading definition labeled distance graphs.
623

fiConrad & Williams

Definition 4.11 (Labeled Distance Graph) labeled distance graph G tuple
hV, E, W, Xi. V set vertices E set directed edges vertices, represented ordered pairs (i, j) V V . W weight function edges real
valued labeled value sets, edge (i, j) E associated labeled value set
W (i, j). X description choices variables, defining set environments
may appear labeled value sets contained W .

Example 4.12 Consider simple graph three vertices, V = {A, B, C}. graph
contains edges E = {(A, B), (A, C), (B, C)}. one choice variable x {1, 2}. Edge
(A, B) weight 1 regardless choice. Edge (A, C) 3 x = 1 7 x = 2.
Finally, edge (B, C) weight 4 x = 2. labeled distance graph shown Figure
4.1.

(1, {})


B

{(3, {x = 1}),
(7, {x = 2})}

{(4, {x = 2})}
C

Figure 4.1: simple Labeled Distance Graph one choice variable, x {1, 2}
association Labeled STNs labeled distance graphs closely parallels
association STNs distance graphs.
Definition 4.13 (Labeled Distance Graph Associated Labeled STN)
labeled distance graph associated Labeled STN vertex associated
every event Labeled STN. labeled inequality, denoted e : X w,
e E, X, V , w R, edge (X, ) E. labeled value set W (X, ) includes
labeled value pair (w, e) pair dominated another (w0 , e0 ) W (X, ).
Example 4.14 Figure 1.4 essentially labeled distance graph rover problem
described Example 1.1, except replace informal notation equivalent
labeled value sets. example, edge (B, C) currently weight : 60,
replace labeled value set {(60, {x = collect})}.

Drake compiles input Labeled STN creating associated labeled distance graph
representation constructing new labeled distance graph transformation
input graph.
Definition 4.15 (Dispatchable Form Labeled STN) labeled distance graph
dispatchable form Labeled STN represents constraints necessary
accurately perform dispatch greedy strategy, using local propagations.

624

fiDrake: Efficient Executive Temporal Plans Choice

section constructed labeling structures Drakes uses, beginning labeled
value pairs building labeled value sets minimal sets labeled pairs. Labeled
value sets used construct labeled distance graphs, defined construct
graph associated Labeled STN, Drakes compilation algorithms operate.

5. Labeled Value Set Maintenance System
previous section defines representation labeled distance graphs labeled value
sets; section provides tools manipulating them. primary focus labeled value
sets maintain non-dominated labeled value pairs, makes labeled value
sets compact efficient. section introduces three concepts. First, describe
extract values labeled value set, called query, allowing us find dominant
value implied environment. Second, handle assignments choices
inconsistent, called conflicts. Third, apply functions labeled value sets,
allows us perform computations directly.
First define query, lets us extract precise dominant value(s)
guaranteed hold particular environment.
Definition 5.1 (Labeled Value Set Query) query operator A(e) defined labeled value set e E. query returns set values including ai pair
(ai , ei ) A, ei subsumes e, pair (aj , ej )
ej subsumes e aj < ai . environment ei subsumes e, A(e) returns .

introduce convention: using pairs real values vertices
values labeled value pairs, consider inequalities pairs defined entirely
real value. Thus, (5, A) < (6, E) (5, A) (5, E).
Example 5.2 Assume two choice variables x, {1, 2}, real valued
variable represented labeled value set, = {(3, {x = 1}), (5, {})}. A({x =
1, = 1}) = 3 input environment subsumed environments
labeled value set, three dominant. A({x = 2, = 2}) = 5 empty
environment labeled value set subsumes input environment.

Example 5.3 Let labeled value set values pairs real values
vertices, = {((3, A), {x = 1}), ((5, A), {y = 1}), ((5, B), {})}. A({x = 1, = 2}) =
{(3, A)} environments subsumed, (3, A) < (5, A) (3, A) < (5, B).
A({x = 2, = 1}) = {(5, A), (5, B)} tighter value applicable neither
value real part five less other.

query operator defines expansion compact form explicit listing
values environment. Although Drake never performs expansion, useful
determining correct behavior Labeled Value Set designing algorithms.
Second, consider conflicts, important function ATMS allows track
inconsistent environments. case, inconsistent environment signals inconsistent
component STN. standard strategy ATMS keep list minimal conflicts,
also referred no-goods (de Kleer, 1986).
625

fiConrad & Williams

Definition 5.4 (Conflict) conflict environment e e subsumes e0 ,
e0 inconsistent. conflict e minimal e00 E e00 e,
e00 conflict (Williams & Ragno, 2007).

Example 5.5 example, compilation process might determine x = 1 = 1
contradictory choices, cannot selected together execution. Then,
{x = 1, = 1} conflict.

Often, reasoning algorithms keep cache conflicts avoid performing work environments previously discovered contain inconsistency. practice, set
conflicts become large unwieldy, leading practical systems keep subset conflicts, using principles temporal locality maintain small, useful cache.
Since cache conflicts incomplete, cache miss, requiring problem solver
re-derive inconsistency, missing cache would never lead incorrectly accepting
inconsistent solution. good example conflict learning widely studied
SAT-solver MiniSAT (En & Srensson, 2004). real-time execution, incomplete
cache conflicts would require Drake perform non-local propagation re-test inconsistency case cache miss. extra step violates principles dispatchable
execution. Therefore, Drake maintains complete cache known conflicts, allowing
Drake verify environment known inconsistent single check
cache. Furthermore, Drake quickly test whether complete environments
valid, inconsistencies readily available.
known conflict, Drake sometimes needs determine avoid conflict,
is, minimal environments ensure conflict possible.
Definition 5.6 (Constituent Kernels, Williams et al., 2007) conflict ec associated set constituent kernels, environment specifies single
assignment takes variable assigned conflict assigns different value.
Hence, ek constituent kernel, environment e ek subsumes e
implies ec subsume e, hence subject conflict. Thus, say
e avoids conflict.

Example 5.7 three variables, X, Y, Z {1, 2}, assume {x = 1, = 1} conflict. constituent kernels {x = 2} {y = 2}, complete environment
contain conflict must assign either x one.

final tool needed ability perform temporal graph reasoning labeled
value sets, principally accomplished computing path lengths propagating
inequality bounds. construct approach denoting inference rule values
function f . Then, build method applying f labeled value sets
rule applying labeled value pairs. begin defining union operation
environments, fundamental operation environments temporal
reasoning, ATMS literature (de Kleer, 1986).
Definition 5.8 (Union Environments) union environments, denoted e e0
union assignments environments. e e0 assign different values
variable xi , valid union e e0 = , symbol
626

fiDrake: Efficient Executive Temporal Plans Choice

false. e e0 subsumed conflict, e e0 = . value signifies
consistent environment e e0 hold simultaneously.

Example 5.9 commonly, unions used compute dependence new derived
values. = 2 {x = 1} B = 3 {y = 2}, C = + B = 5
{x = 1} {y = 2} = {x = 1, = 2}.

Using notation, inference labeled value pairs involves performing
inference values produce new value, unioning environments produce
new environment.
Lemma 5.10 Consider labeled value pairs (a, ea ), (b, eb ). Applying function f
pair yields (f (a, b), ea eb ).

Proof environment e, ea subsumes e entailed, eb subsumes e
b entailed, definition labeled value pairs. Additionally, ea eb subsumes e
ea subsumes e eb subsumes e. Therefore, ea eb subsumes e entails values
a, b, hence allows us compute f (a, b). Thus, (f (a, b), ea eb ) well defined.

Note lemma, ea eb may produce , would indicate labeled
value pair never holds consistent environment may discarded.
Example 5.11 Consider computing quantity (3, {x = 1}) + (6, {y = 1}) = (3 + 6, {x =
1} {y = 1}) = (9, {x = 1, = 1}).

function respects dominance values, may apply entire labeled
value sets.
Definition 5.12 function f (a, b) consistent dominance values a, b, c
d, c, b = f (a, b) f (a, d), f (a, b) f (c, b), f (a, b) f (c, d).

Lemma 5.13 variables A, B represented labeled value sets f consistent
domination ordering used f , result C = f (A, B) represented labeled
value set containing non-dominated subset labeled value pairs (f (ai , bj ), ei ej )
constructed every pair labeled value pairs (ai , ei ) (bj , ej ) B.

Proof lemma follows argument cross product applying f
labeled value pairs B produces possible labeled value pairs. Since must
ensure labeled value pairs include dominant labeled value pairs C,
require f consistent ordering dominant values B,
available, sufficient derive dominant labeled value pairs C.
conclude section example relaxation labeled distance graph,
core rule inference weighted graph algorithms uses path
B C compute possible path weight C. derived path length replaces
old path newly derived path length shorter.
627

fiConrad & Williams

Example 5.14 Consider labeled distance graph Figure 4.1. compute W (A, B)+
W (B, C) = {(1, {})}+{(4, {x = 2})} = {(5, {x = 2})}. Compare existing known
weights W (A, C) = {(3, {x = 1}), (7, {x = 2})}, determine new value
replaces old value 7. update, W (A, C) = {(3, {x = 1}), (5, {x = 2})}.

two fundamental inferences performed labeled value sets: relaxation
weighted edges compilation, sums differences edge weights compute
bounds execution times dispatch. follow framework outlined here,
explained detail compilation dispatch sections, respectively.
operations complete definition labeled value sets following sections use
construct compact compilation dispatching algorithms.

6. Dispatching Plans Choice
Given foundation Labeled STNs, labeled value sets, labeled distance graphs,
turn central focus article - dynamic execution Labeled STNs. Recall
dispatcher uses local, greedy algorithm make decisions run-time low latency,
accuracy approach guaranteed compilation step. begin
dispatcher low latency execution fundamental goal work
because, prior work, compiler designed produce output appropriate
dispatcher.
adapt STN dispatcher developed Muscettola et al. (1998) work
dispatchable labeled distance graphs. Essentially, Drakes algorithms substitute real number
bounds execution times, STN dispatcher, labeled value sets. Additionally,
adapt Tsamardinos et al.s (2001) approach reasoning multiple possible options,
is, allowing dispatcher accept proposed execution time event least
one full assignment choices consistent schedule. present Drakes
dispatching algorithms first reviewing standard STN dispatching, adapt
techniques handle labels.
6.1 STN Dispatching
Muscettola et al. (1998) showed given dispatchable form STN, simple greedy
dispatcher correctly execute network updates performed neighboring
events dispatchable form STN. dispatcher loops non-executed
events time step, selecting event execute possible, else waiting
next time step. process continues either events executed failure
detected.
Determining whether event executable relies two tests. First, dispatcher tests
whether ordering constraints event satisfied, called testing
enablement. simple temporal constraint may imply strict ordering two events,
dispatcher must explicitly test ensure event scheduled
event must precede it. Second, dispatcher efficiently tracks consequences
simple temporal constraints event neighbors computing execution
windows event. Execution windows tightest upper lower bounds derived
event one-step propagations execution times. current time
628

fiDrake: Efficient Executive Temporal Plans Choice

events execution window enabled, event may scheduled current
time.
briefly recall derivation two rules executing events. Recall
weighted edge distance graph corresponds inequality
B wAB

(11)

B execution times events l real number bound.
select execution time tA event B yet scheduled, rearrange
inequality
B wAB + tA

(12)

produces new upper bound execution time B. Likewise, yet
scheduled select tB execution time B, rearrange inequality

tB wAB .

(13)

Thus, derive new lower bound A. If, form, wAB < 0, B < A, event
B must precede A, implying enablement constraint.
recast rules terms propagations distance graph. event
scheduled time t, propagate outbound edges (A, B) derive
upper bounds B wAB + t, inbound edges (B, A) derive lower bounds
B wBA . Event B event predecessor negative weight edge
(B, A). usual, dispatching affected dominant upper lower bounds,
dispatcher stores dominant constraints.
Example 6.1 Consider dispatchable distance graph fragment Figure 6.1. execution windows begin without constraint, B . begin
execution = 0, B executable yet enabled; negative weighted
edge (B, A) implies must executed first. predecessor constraints
zero lies within execution bound, may executed time. Propagating time
= 0 allows us derive bounds 2 B 8. B may executed time
2 8. dispatcher reached time 9 without executed B, must
signal failure.




8
-2

B

Figure 6.1: dispatchable distance graph fragment.
final consideration dispatcher zero-related events. two events constrained executed precisely time, prior work requires
events collapsed single vertex dispatchable graph. Otherwise, zero-related
vertices may cause dispatcher make mistakes must occur together, yet
629

fiConrad & Williams

appear independently schedulable. Equivalently, dispatcher may simulate collapse always executing zero-related vertices set. example, B known
zero-related, dispatcher may schedule together, scheduling events time
execution windows enablement constraints B satisfied. Note
since zero-related, impossible enablement constraint
them.
6.2 Labeled STN Dispatching
Drake relies fundamental structures rules STN dispatcher,
modifies step consider labels. Since edge weights labeled value sets, execution
windows also labeled value sets, implying upper lower bounds execution
times events may vary depending assignments choices may vary separately.
possible bound enablement constraint, Drakes dispatcher must either enforce
constraint, discard constraint decide select associated environment.
Broadly, strategy Tsamardinos et al. (2001), component STNs
dispatched parallel, proposed scheduling decisions may accepted
consistent least one STN.
begin considering update propagation rules derive execution windows. STN propagations involve adding edge weights (or negative weights)
execution time event. upper bound every event initially {(, {})}
every lower bound initially {(, {})}. Upper bounds dominated low values,
inequality, lower bounds dominated large values, inequality.
following theorem describes propagation execution bounds, labeled
implementation Equations 12 13.
Theorem 6.2 event executed time t, consider event B.
every (wAB , eAB ) W (A, B), (wAB + t, eAB ) valid upper bound execution times
B every (wBA , eBA ) W (B, A), (t wBA , eBA ) lower bound execution
times B.

Proof rules direct extension STN propagation labeled case using
labeled operations Definition 5.12. Since execution actually occurred, holds
possible environments, thus give empty environment {}. apply
Definition 5.12, substituting labeled version addition.

dispatch, new bounds added labeled value sets Bu Bl ,
maintain non-dominated bounds.
{(5, {x = 1}), (2, {})}


B
{(7, {x = 1}), (8, {})}

Figure 6.2: dispatchable labeled distance graph fragment.

630

fiDrake: Efficient Executive Temporal Plans Choice

Example 6.3 Consider labeled distance graph fragment Figure 6.2. event
executed = 2, derive bounds {(7, {x = 1}), (4, {})} B {(9, {x =
1}), (10, {})}

Since bounds may vary choices, Drake cannot generally expect obey
possible constraints, instead required enforce constraints implied
least one complete environment.
Example 6.4 Assume event lower bounds represented labeled value set
{(2, {x = 1}), (0, {})}. implies set choices x = 1, 2,
otherwise, 0 sufficient. dispatcher executes = 0, may
select x = 1. Thus, dispatcher restrict choices include
x = 1, leaving consistent options, may execute = 0.
remaining consistent full assignments choices require x = 1, dispatcher
must wait = 2 executing A.

Drake performs reasoning collecting environments bounds
particular execution would violate, determining whether environments
made conflicts without making every complete environment inconsistent. complete
environments would remain consistent, execution performed environments
made conflicts; otherwise execution possible, discarded.
Finally, Drake simulates collapse zero-related events. time, Drake attempts execute event individually also attempts execute sets zerorelated vertices recorded compiler. noted before, zero-related sets may exist
environments others. zero-related set enforced, member events must executed together, all. Therefore, dispatcher considers
executing set events strict subset particular zero-related set, leaving
least one member zero-related set, must discard environments
zero-related set implied. Additionally, cannot enablement constraints
zero-related events complete environments zero-related group
holds, environments may imply strict orderings events, dispatcher discards executing zero-group simultaneously. Hence, dispatcher must
discard associated environments.
summarize rules follows, illustrated Example 6.7.
Theorem 6.5 set one event set zero-related events Labeled STN,
set may executed time least one consistent complete
environment where:
1. every Al lower bound labeled value set S, Al A,
every (l, e) Al l > t, e conflict.
2. every Au upper bound labeled value set S,
Au A, every (u, e) Au u < t, e conflict.
3. every pair events, S, B
/ S, B yet scheduled, every
(w, e) W (A, B) w < 0, e conflict.
631

fiConrad & Williams

4. every zero-related set events Z environment e, Z, e conflict.
5. every A1 , A2 S, every (w, e) W (A1 , A2 ) w < 0, e conflict.
Proof consistent full environment creating conflicts,
necessarily subsumed environments constraints imply
events cannot executed time t. Thus, consistent full environment corresponds
component STN every constraint holds, events may executed.
consistent environment, least one constraints prohibiting proposed
execution exists remaining component STN, execution valid.

Similarly STN case, dispatcher must check missed upper bounds
every time step. STN, missed upper bound implies execution failed.
Labeled STN, missed upper bounds implies complete environments subsumed
environment missed upper bound longer valid.
Theorem 6.6 event executed time t, upper bound labeled value set Au ,
(u, e) Au u < t, e conflict.

Proof theorem follows noting upper bound exists every component
STN corresponding complete environment subsumed e, thus every environment
subsumed e inconsistent, definition, makes e conflict.

possible missed upper bounds could invalidate remaining complete environments, case dispatch failed dispatcher signal error
immediately.
Example 6.7 Consider dispatchable labeled distance graph Figure 6.3, events
A, B, C, choice variables x, {1, 2}. zero-related set {A, C}
environment {x = 1}. Assume current time = 0 events
executed yet. possible complete environments initially consistent. Consider
possible executions consequences.
Event C predecessors, restrictions execution window. However,
part zero-related set, may executed make {x = 1}
conflict, order remove zero-related set possible executions.
feasible, may execute C = 0 create conflict. this,
ordering inequality implied edge (A, D) necessary consistent
execution, environment cannot made conflict without making complete
environments inconsistent.
Event predecessor {x = 2}, C predecessor {y = 1},
part zero-related set {x = 1}. execute = 0, would
need make three environments conflicts, would invalidate possible
choices, may execute = 0.
632

fiDrake: Efficient Executive Temporal Plans Choice

zero-related set {A, C} execution window restrictions either
C, predecessor {x = 2} edge (A, D). Additionally, edge
(A, C) negative weight 1 environment {y = 2}, environment
also made conflict. Thus, create conflicts {x = 2} {y = 2}
execute B = 0.
Event B predecessor {y = 1} yet executed, may
make environment conflict execute B. Assume C executed
= 0, enablement constraint satisfied, execution B
= 3 requires making {y = 1} conflict. Additionally, current time grows
= 7 B yet executed, upper bound violated
{y = 1} conflict.
Event predecessor C environment {}, C yet executed.
Since making {} conflict makes complete environments inconsistent, cannot
executed.

{(3, {y = 1})}


B
{(6, {y = 1})}

{(2, {x = 2})}
{(0, {x = 1}),
(1, {y = 1})}

{(0, {x = 1})}

{(1, {})}
C


{(6, {y = 2})}

Figure 6.3: dispatchable labeled distance graph.
completes presentation Drakes dispatch algorithms. Essentially, makes
two adaptations STN dispatcher: (1) maintain labeled value sets execution
windows events (2) allow dispatcher select choices creating conflicts. next section describes compilation algorithm, computes
dispatchable form input Labeled STNs, ensuring local reasoning steps
dispatching algorithm satisfy requirements plan.
633

fiConrad & Williams

7. Compiling Labeled Distance Graphs
complete description Drake compiler, reformulates input Labeled STN form dispatcher guaranteed execute correctly. compiler
leverages labeling concepts presented efficiently compute compact dispatchable form input plans. STN compiler takes distance graph input
outputs another distance graph, minimal dispatchable form input problem. Similarly, Drakes compiler takes labeled distance graph input outputs labeled
distance graph minimal dispatchable form input.
Muscettola et al. (1998) introduced initial compilation algorithm STNs
operates two steps. First, computes All-Pairs Shortest Path (APSP) graph associated STN, dispatchable form. Second, compiler prunes
edges prove redundant non-pruned edges, dispatcher
therefore need make correct decisions. pruned edges dominated,
removal significantly reduces size dispatchable graph. compiler tests
dominance applying following rule every triangle APSP graph.
Theorem 7.1 (Triangle Rule, Muscettola et al., 1998) Consider consistent STN
associated distance graph satisfies triangle inequality; directed graph satisfies triangle inequality every triple vertices (A, B, C) satisfies inequality
W (A, B) + W (B, C) W (A, C).
(1) non-negative edge (A, C) upper-dominated another non-negative edge (B, C)
W (A, B) + W (B, C) = W (A, C).
(2) negative edge (A, C) lower-dominated another negative edge (A, B)
W (A, B) + W (B, C) = W (A, C).

Although basic concept domination unchanged, dominated constraints
needed executive, specifics quite different here. Domination within
labeled value sets refers labeled values make labeled values within
set unnecessary. context edge pruning, one edge could dominate another
two edges share start end vertex, both. develop labeled version
edge pruning, labeled value one edge weight labeled value set dominate
value different edge weight labeled value set, corresponding edges share
start end vertex.
Example 7.2 Consider two weighted graph fragments Figure 7.1. case, edge
(A, C) dominated, shown theorem.

compiler searches dominated edges removes together.
care necessary ensure pair edges AC BC provide justification
pruning other; edges said mutually
dominant. Typically, pruned

graphs number edges closer N log N , N 2 , significant savings.
first prototype Drake, Conrad, Shah, Williams (2009) introduced labeled extension
algorithm. extension used perform task execution ATHLETE
Rover within Mars Yard NASA JPL.
Although simple effective, algorithm scale gracefully large problems
uses entire APSP graph intermediate representation, much larger
634

fiDrake: Efficient Executive Temporal Plans Choice



-5

-4

1

B

C



2

5

3

B

C

(a)
Lower
domination
weighted graph

(b)
Upper
domination
weighted graph

Figure 7.1: Examples upper lower dominated edges.
final result. resolve this, Tsamardinos, Muscettola, Morris (1998) presented
fast compilation algorithm interleaves APSP step pruning step, avoids
ever storing entire APSP graph. algorithm derived Johnsons algorithm
computing APSP, incrementally builds APSP repeated SSSP computations
(Cormen, Leiserson, Rivest, & Stein, 2001). Johnsons algorithm uses Dijkstras algorithm
inner loop, providing faster performance Floyd-Warshall sparse graphs.
Essentially, fast compilation algorithm loops events graph, computes
SSSP event, adds non-dominated edges event source
dispatchable form. Thus, algorithm needs store final dispatchable graph
one SSSP, avoiding bloat intermediate representation. Thus, algorithm
better space time complexity APSP step followed pruning.
paper introduces novel extension Drake system adapts fast compilation algorithm labeled graphs order avoid unnecessary storage growth
compilation. fast algorithm requires number steps; section describes
component original fast algorithm adaptation labeled setting. First,
recall Johnsons strategy compute APSP iterated SSSP, present
labeled adaptation SSSP algorithm. Second, discuss predecessor graphs
result SSSP traverse them. Third, describe interleave
pruning repeated SSSP computations. Finally, discuss issues arising
mutual dominance, preprocessing step used resolve them.
7.1 Johnsons Algorithm Structure Fast Algorithm
Many shortest path algorithms weighted distance graphs essentially perform repeated
relaxation graph. Floyd-Warshall loops repeatedly entire graph, relaxing
edges computing entire APSP single computation. Johnsons algorithm
computes APSP one source vertex time, using Dijkstras SSSP algorithm
inner loop perform relaxations efficiently. Since Dijkstras algorithm works
positively weighted graphs, Johnsons algorithm re-weights graph Dijkstra
calls un-weights afterward. Unfortunately, adapting Dijkstras algorithm labeled
distance graphs inefficient re-weighting adds subtracts labeled value
sets, compatible single ordering. Therefore, use BellmanFords SSSP algorithm instead; sacrifice improved run-time fast algorithm,
635

fiConrad & Williams

preserve lower space overhead. fast STN compilation algorithm copies
essential structure Johnsons algorithm. section illustrates overall algorithm
unlabeled case partial example.
Example 7.3 Consider one step compilation shown Figure 7.2. input distance
graph shown Figure 7.2a. compute SSSP input source vertex
B, output predecessor graph shown 7.2b, depicts shortest distances
paths B. weights vertices indicate complete APSP graph
contain edge B weight 4, B C weight 1, B
weight 0. Furthermore, original graph, shortest path B uses
edge B A. shortest path B C either B C B C;
equal length. shortest path B B D.
However, dispatchable form problem actually need three
edges, compiler deduce predecessor graph SSSP values.
Roughly, since lower distance B C, along shortest path C,
edge BC necessary. Therefore, two edges inserted dispatchable
graph, depicted Figure 7.2c, edge BC discarded. process repeated
three vertices.


4


-4
8



B

B



0 1

3 -1

B

0

5

-1

C
C

-4

3



(a) Input Distance Graph



1

1

(b) Predecessor Graph Source
B

C



(c) Partial dispatchable
graph edges
source vertex B

Figure 7.2: single step fast reformulation algorithm STNs

7.2 Labeled Bellman-Ford Algorithm
Drake uses Bellman-Ford algorithm central building block variant fast
STN algorithm Drake uses; Bellman-Ford derives tightest possible edge weights,
simultaneously deriving predecessor graph. graph provides enough information
prune dominated edges. begin, provide Algorithm 7.1, taken directly (with
slightly altered notation) work Cormen et al. (2001). algorithm loops
edges performs relaxations, tests negative cycles ensure result
valid. value d[v] distance vertex v input source vertex s.
value [v] vertex (not necessarily unique) predecessor v forming
636

fiDrake: Efficient Executive Temporal Plans Choice

shortest path v. Relating Figure 7.2b, corresponds annotations next
vertices, specifies directed edges.
Algorithm 7.1 Bellman-Ford Algorithm
1: procedure BellmanFord(V, E, W, s)
2:
InitializeSingleSource(V, W, s)
3:
{1...|V | 1}
4:
edge (u, v) E
5:
Relax(u, v, W )
6:
end
7:
end
8:
edge (u, v) E
9:
d[v] > d[u] + W (u, v)
10:
return false
11:
end
12:
end
13:
return true
14: end procedure
15:
16:
17:
18:
19:
20:
21:
22:
23:
24:
25:
26:
27:

. Loop relaxation

. Check negative cycles
. Fail negative cycle found

procedure InitializeSingleSource(V, s)
vertex v V
d[v]
[v] nil
end
d[s] 0
end procedure
procedure Relax(u, v, W )
d[v] > d[u] + W (u, v)
d[v] d[u] + W (u, v)
[v] u
end
end procedure

see next sections, fast compilation algorithm STNs requires
access entire predecessor graph, encodes shortest paths
graph, rather single path. compute entire graph, Drake makes [v]
set, Relax determines d[v] = d[u] + W (u, v), pushes u onto d[v].
strict inequality holds d[v] updated, [v] set single element set {u}.
discuss changes necessary adapt Bellman-Ford algorithm Labeled
Distance Graphs. relaxation procedure computes new bound path length
v, dominates old value, replaces old value. vertex u allows
us derive current dominant value d[v], stored [v]. Drakes use labeled
value sets store value pairs (d, ) R V allow perform tasks once,
one data structure.
637

fiConrad & Williams

see works, consider example:
Example 7.4 Figure 7.3a, edge (A, B) forms snippet labeled distance graph;
consider computing SSSP source vertex A. know initialization routine
every choice set d[u] = 0 source vertex d[u] = others,
set [u] = nil every vertex. combined notation, initial value weight
vertices (0, nil) (, nil), labeled empty environment {}.
initial weights shown vertices.
relaxation edge allows us derive B distance 8 environment {x = 1}, predecessor A. Hence, add labeled value pair ((8, A), {x = 1})
labeled value set weight B. new value tighter value d,
hence kept, dominate old value, thus kept. single insertion
step updates distance B predecessor B along shortest
path. result depicted Figure 7.3b.


clear elected keep non-identical values numeric
value: labeled value sets hold predecessors target vertices,
single predecessor. Algorithm 7.2 shows generalization example. Initialization
exactly example, assigns initial values standard algorithm
empty environments. relaxation, following Lemma 5.13, potential new path
lengths cross product addition weight u added weight edge
u v, labeled union environments, union valid
subsumed known conflicts. Naturally, relaxing u edge v, u
predecessor. adding value labeled value set d[v], domination
criterion used determine new path length non-dominated, prune nondominant path lengths predecessors appropriate.
final modification original algorithm test negative cycles;
negative cycle detected another relaxation edge would decrease
distance source vertex. labeled case, choices may
negative cycles others may not. begin computation computing relaxation
d[u] + W (u, v) labeled addition operator, discard predecessor vertices
d[u], thus producing real valued labeled value set. environment
d[v] > d[u] + W (u, v) holds, environment conflict Labeled STN.
Finding minimal conflicts practice somewhat convoluted. Consider pair
labeled values (dv , ev ) d[v], (duw , euw ) d[u] + W (u, v) turn. dv > duw
might conflict, however, may environments smaller, dominant
value d[v] takes precedence dv , thus preventing inequality satisfied.
Hence, exists, conflict deduce ev euw modifying union avoid
environments e0v (d0v , e0v ) d[v] d0v duw . possible conflicts
could invalidate possible choices, executive tests for, determining
plan dispatchable.

638

fiDrake: Efficient Executive Temporal Plans Choice

Example 7.5 Consider following values inequality test, given two binary choice
variables:
d[v] = {(2, {y = 1}), (4, {})}

(14)

d[u] + W (u, v) = {(3, {x = 1}), (5, {})}

(15)
(16)

must find make conflicts minimal environments imply d[v] > d[u] +
W (u, v) holds. side inequality two possible values, consider
four pairs values could satisfy inequality. Three pairs satisfy
inequality, thus cause conflict: (2, {y = 1}) < (3, {x = 1}), (2, {y = 1}) < (5, {})
(4, {}) < (5, {}). last pair, (4, {}) > (3, {x = 1}), satisfies inequality,
pair could imply union corresponding environments, {} {x = 1},
conflict. However, reach (4, {}) left hand side, skipped smaller value,
(2, {y = 1}) d[v]. correctly address ordering, conflict must also avoid
environment smaller value. Taking {} {x = 1} avoiding {y = 1} produces one
environment, {x = 1, = 2}, valid environment, hence conflict.


{((0 , nil) ,{})}

{(( , nil) ,{})}



B

{(8, {x = 1})}
(a) Relaxation

{((0, nil), {})}


{((8, A), {x = 1}), ((, nil), {})}
{(8, {x = 1})}

B

(b) Relaxation

Figure 7.3: single labeled relaxation step.

7.3 Traversals Labeled Predecessor Graphs
fast compilation algorithm STNs performs traversals predecessor graphs
produced SSSP analysis, checks edge along traversal dominance.
used reduce graph minimal dispatchable form. unlabeled case,
[u] values specify directed graph Figure 7.2b, may use depth-first
exploration enumerate possible paths beginning source vertex SSSP
computed for. However, labeled case, care necessary.
simplest way understand paths valid complete environments
consider projection predecessor graph particular complete environment
e. Take every labeled value set d[u] query e. result gives shortest path
distance predecessors, producing standard unlabeled predecessor graph.

639

fiConrad & Williams

Algorithm 7.2 Labeled Bellman-Ford Algorithm
1: procedure LabeledBellmanFord(V, E, W, S, s)
2:
LabeledInitializeSingleSource(V, W, s)
3:
{1...|V | 1}
. Loop relaxations
4:
edge (u, v) E
5:
LabeledRelax(u, v, W )
6:
end
7:
end
8:
edge (u, v) E
. Test negative cycles
9:
labeled value pair (dv , ev ) d[v]
10:
labeled value pair (duw , euw ) d[u] + W (u, v)
11:
dv > duw
12:
AddConflict(ev euw , split avoid e0v
13:
(d0v , e0v ) d[v] d0v duw )
14:
end
15:
end
16:
end
17:
end
18:
IsSomeCompleteEnvironmentConsistent?()
19: end procedure
20:
21:
22:
23:
24:
25:
26:
27:
28:
29:
30:
31:
32:

procedure LabeledInitializeSingleSource(V, s)
vertex v V \
d[v] {((, nil), {})}
end
d[s] {((0, nil), {})}
end procedure
procedure LabeledRelax(u, v, W )
labeled value pair ((du , u ), eu ) d[u]
labeled value pair ((dw , w ), ew ) W (u, v)
AddToLVS(d[v], ((du + dw , u), eu ew ))
end
end
end procedure

640

fiDrake: Efficient Executive Temporal Plans Choice

Example 7.6 Consider labeled graph fragment Figure 7.4a, vertices
labeled SSSP weights source vertex A. consider predecessor
graph path lengths implied environment e = {x = 1, = 1}: d[B](e) = (2, A)
d[C](e) = (1, A). Hence, vertices B C predecessor,
B distance 2 A, C distance 1 A, shown Figure 7.4b. Vertex
distance 6 A, predecessor C. important feature example
environment, C predecessor B, even though pair (7, C) labeled
{y = 1}, subsumes e. Predecessors provided dominant path length.

{((2, A), {x = 1, = 1}),
((7, C), {y = 1}),
((, nil), {})}

{((0, nil), {})}

{(2, {x = 1, = 1})}


B
{(4, {y = 1})}

{(1, {x = 1}), (3, {})}

{(5, {y = 1})}
C


{((6, C), {x = 1, = 1}),
((8, C), {y = 1}),
((, nil), {})}

{((1, A), {x = 1}),
((3, A), {})}

(a) Relaxed Graph

0

2



B

C



1

6

(b) Predecessor graph
e = {x = 1, = 1}

Figure 7.4: Extracting predecessor graphs labeled SSSP
Although instructive consider projection SSSP onto environment
intuitive understanding, implementation based approach efficient space
time. rest work, Drake directly performs traversals labeled
representation. Since paths predecessor graphs may exist environments
others, take natural step use minimal environments specify
641

fiConrad & Williams

particular path exists. Intuitively, expect environment path simply
union environments labeled value pairs specified predecessor edges
used. true, require extra step test validity path
environment.
Consider partial path source vertex S, passes subset
vertices X1 . . . Xn , constructed labeled value pairs ((di , Xi ), ei ) d[Xi+1 ],
represent path predecessor graph. path valid if, every
vertex along path, (di , Xi ) d[Xi+1 ](e1 . . . en ), path environment e =
e1 . . . en . Essentially, tests labeled value pairs used construct path
actually still entailed union respective environments. path
invalid, possible extensions also invalid, inconsistency exist
extensions.
Example 7.7 apply criteria determine paths given SSSP
Figure 7.4a. Begin source vertex, A, clearly exists environments,
assign partial path empty environment. B contains labeled value pair
((2, A), {x = 1, = 1}), thus candidate extend path. union two
environments {} {x = 1, = 1} = {x = 1, = 1}. queried environment,
d[B] returns labeled value pair used propose extension, path
B environment {x = 1, = 1}. B possible extensions.
Returning A, possible extension C labeled value pairs
((1, A), {x = 1}) ((3, A), {}). First, consider ((1, A), {x = 1}), query d[C]
{x = 1} shows path exists, partial path C
environment {x = 1}. path potential extension B labeled
value pair ((8, C), {y = 1}). However, query d[B]({x = 1} {y = 1}) = (2, A) 6= (7, C),
extension valid, expected earlier discussion. may instead extend
path D, giving path C environment {x = 1, = 1}. queries
d[C] d[D] give values used generate path, hence path
valid.
Returning A, consider path B, using labeled value pair ((3, A), {}).
extension B passes query test, C B provides path length 7
{x = 1} {y = 1}. label path label {x = 1}, must take care
later algorithms use imply 7 shortest path length {x = 1, = 1}.
Finally, extend path D, giving path B length 8 {y = 1},
caveat.

Given rule specifying correct extensions partial paths, construct
depth-first search enumerate possible paths acyclic predecessor graph, re-testing
step ensure path valid.
7.4 Pruning Dominated Edges SSSP
strategy finding labeled paths labeled predecessor graphs,
extension pruning algorithm fast STN compilation algorithm straightforward. Tsamardinos, et al. (1998) provide two theorems relating dominance edges
paths predecessor graph, adjusted slightly notation. following,
assumed source vertex SSSP, B C vertices.
642

fiDrake: Efficient Executive Temporal Plans Choice

Theorem 7.8 negative edge (A, C) lower-dominated negative edge (A, B)
path B C predecessor graph A.

Theorem 7.9 non-negative edge (A, C) upper-dominated
vertex B, distinct C, d[B] d[C] path B C
predecessor graph A.

Example 7.10 Figure 7.5 shows two simple examples apply two
theorems. First, Figure 7.5a weighted distance graph Figure 7.5c shows predecessor graph source vertex A, apply Theorem 7.8. Edge (A, C) lower
dominated weight 5 B implies edge (A, B) weight 5,
negative theorem requires. Furthermore, predecessor graph path B
C predecessor graph A. Therefore, edge (A, C) dominated needed
dispatchable form.
Figures 7.5a 7.5c similarly exhibit Theorem 7.9. path B C
graph, d[B] = 2 d[C] = 5, edge (A, C) upper-dominated. Thus, edge (A, C)
needed dispatchable form.
examples, step derives every possible edge weight edges
dispatchable form source, namely edges (A, B) (A, C), determines
(A, B) actually needed.

labeled case, particular labeled edge weights dominated conditions
hold environments weight holds in.
Theorem 7.11 negative labeled edge weight (dC , eC ) d[C] lower-dominated
negative labeled edge weight (dB , eB ) d[B] eB = eC path
B C environment eP predecessor graph eP = eC .

Theorem 7.12 non-negative labeled edge weight (dC , eC ) edge d[C] upper-dominated
labeled edge weight (dB , eB ) d[B], B distinct
C, eB subsumes eC , dB d, C, path B C environment eP
predecessor graph eP = eC .

practice, Drake searches every path labeled predecessor graph
source vertex start, applies theorems find dominated edges. Specifically,
traversal, records smallest vertex weight vertices along path,
counting source. value compared vertex weights extensions
path apply domination theorems. Every time vertex weight found
dominated path, recorded list. traversals done, every
labeled value vertex weights present list dominated values converted
edge output dispatchable graph.
two theorems require eP = eC path must hold environments value dC does, also want eP tighter. Recall
vertex weights might prune also specify paths. eC tighter eP ,
must lower path length one implied eP , else would
labeled value set d[C]. Thus, cannot guarantee path shortest path
source C, path suitable prune it.
643

fiConrad & Williams



-5

-4

1

B

C



2

5

3

B

C

(a)
Lower
domination
weighted graph

(b)
Upper
domination
weighted graph

0

-5

0

2



B



B

C

C

-4

5

(c) Lower domination predecessor graph

(d) Upper domination predecessor graph

Figure 7.5: Simple edge domination examples.
Example 7.13 demonstrate application ideas, reconsider Figure 7.4a. Example 7.6 gave possible paths graph. first path B path
environment {x = 1, = 1}. reaching B, minimal vertex weight 2,
extension path, nothing pruned. general, first step
source vertex cannot pruned.
next step traversal reaches C environment {x = 1}, minimal
path length 1. C cannot pruned. path cannot extended B,
extension D, using vertex weight ((6, C), {x = 1, = 1}). path length
strictly longer path length 1, environment value equal
environment path, add pruned list.
Next consider path C environment {} path length 3. extension
B using ((7, C), {y = 1}) also prunable. Note path could never used
prune shorter path length ((2, A), {x = 1, = 1}) {x = 1, = 1} =
6 {y = 1}.
Likewise, extension prunes ((8, C), {y = 1}).
Collecting non-pruned edges means algorithm adds edge (A, B)
output dispatchable graph weight W (A, B) = {(2, {x = 1, = 1})}, adds edge
(A, C) weight W (A, C) = {(1, {x = 1}), (3, {})}. drop infinite weights, allowing
implicitly specified, finite weights pruned,
add edge (A, D) all.

644

fiDrake: Efficient Executive Temporal Plans Choice

Essentially, pruning algorithm structure unlabeled fast compilation algorithm. major difference values prune environments
paths predecessor graph exist particular environments. Thus,
pruning step must satisfy pruning requirement identical environment prune
labeled value.
7.5 Mutual Dominance Rigid Components
Tsamardinos et al. (1998) showed rigid components distance graph STN
create mutual dominance, two edges (A, B) (A, C) used evidence
prune other, incorrectly removed algorithm previous
section applied. correct solution perform either pruning, both. Unfortunately, difficult test mutual dominance SSSP pruning step. Instead,
present pre-processing step identifies rigid components, updates output
dispatchable graph accordingly, alters input weighted distance graph remove
rigid components entirely, beginning process computing edges dispatchable form repeated SSSPs. leaves problem mutually dominated
edges, thus pruning step prune edges found dominated without
risk encountering problem. section adapts Tsamardinos et al.s approach
identifying labeled rigid components uses labeled analogue alteration process.
Example 7.14 Consider predecessor graph fragment Figure 7.6. path
B C, d[B] = 1 d[C] = 1, d[B] d[C]. Thus, edge (A, C)
pruned. Likewise, path C B allows us prune (A, B)
dispatchable graph. result constrained rest
events, would allow dispatcher select inconsistent schedule. edges
mutually dominant. algorithm able prune edges path
B C C B, either exist, one pruning would take place.


0

1



B

C
1
Figure 7.6: predecessor graph, (A, B) (A, C) mutually dominant.
Tsamardinos et al. (1998) show mutual dominance occurs
rigid components problem, collections events must scheduled
fixed difference execution times. Figure 7.6, B C constrained
occur time, rigidly connected. Rigidly connected components
645

fiConrad & Williams

consistent distance graph coincide strongly-connected components predecessor
graph single source shortest path arbitrary connected vertices. Thus, show
identify instances possible mutual dominance finding stronglyconnected components predecessor graphs, remove them.
Intuitively, might understand issue input problem less degrees
freedom appears have. two events actually constrained occur
instant, dispatcher one decision, two. compiling, decision looks
redundant other, leading incorrect prunings, Example 7.14. solution
remove redundancy replacing entire rigid component single vertex,
called leader. prior work actually removes events leader
preprocessing step, contracting rigid component single vertex. Since working
labeled distance graphs, rigid components may exist environments,
must replicate effect indirectly, two steps: provide information compiled
form dispatcher respect rigid component, alter input graph
conditions rigid component exists, compilation algorithm reasons
leader.
first step preprocessing identify rigid components. Arbitrary graphs
might connected, SSSP arbitrary vertex may reach
vertices, thus cannot find rigid components disconnected subgraph. standard
strategy, Johnsons algorithm preprocessing step, introduce extra vertex
preprocessing step, connected every vertex zero weight edge. extra
vertex connected every vertex, makes ideal source search from, even
disconnected graphs. Furthermore, extra vertex alter rigid components
predecessor graph. labeled case, equivalent approach introduce new
vertex connected every vertex edge weight (0, {}), zero
weight edge applies every environment. Then, SSSP computed added
vertex source. Finally, algorithm searches predecessor graph cycles.
simplest, necessarily efficient, method labeled case simply use
knowledge finding paths predecessor graph search loops.
might expect, rigid components Labeled STNs given labels, since may
exist environments. need find maximal rigid components
minimal environments. Thus, rigid component {A, B, C}, separately
identify {A, B} rigid component. every vertex V , run depth first search
path back vertex. found, vertices path rigid component,
path environment environment rigid component. Note valid path may
visit vertex twice, example below. search finds rigid components,
maintains list maximally sized rigid components minimal environments.
Example 7.15 Figure 7.7 shows small labeled distance graph vertices {A, B, C}.
Recall opposing pair edges, one negative weight other,
implies rigid component, problem obviously some.
apply technique, algorithm first adds another vertex X, connects
vertex edge weight (0, {}). Figure 7.7b also shows predecessor
graph computed done. Second, algorithm searches loops
graph. begins A: path B environment {x = 1}
loop, B C B environment {x = 1, = 1}. paths
646

fiDrake: Efficient Executive Temporal Plans Choice

imply rigid components {A, B} environment {x = 1} {A, B, C} environment
{x = 1, = 1}, respectively. Note second path visits B twice. B, find
paths B B environment {x = 1}, equivalent one found
A, B C B environment {y = 1}, new rigid component.
paths C re-derive rigid components. Thus, three maximal rigid
components, {A, B} environment {x = 1}, {B, C} environment {y = 1},
{A, B, C} environment {x = 1, = 1}.
two edges B C environment {x = 1} instead {y = 1},
would single maximal rigid component {A, B, C} environment
{x = 1}. smaller components, {A, B} {x = 1}, would non-maximal
needed.

{(5, {y = 1})}

{(3, {x = 1})}


B
{(3, {x = 1})}

C
{(5, {y = 1})}

(a) Labeled distance graph

{((, nil), {})}
X



B

{((3, B), {x = 1}),
((0, X), {})}

{((5, C), {y = 1}),
((0, A), {x = 1}),
((0, X), {})}

C
{((0, B), {y = 1}),
((, nil), {})}

(b) Predecessor graph added vertex X.

Figure 7.7: Identifying rigid components labeled distance graphs.
completing search rigid components, must process them. first
processing step identify leader, first vertex occur, use represent
entire rigid component. leader vertex lowest distance
added vertex, queried environment rigid component. Ties may broken
arbitrarily.
second processing step update dispatchable form accordingly. Within
rigid component, events rigidly bound together leader executed
event rigid component. Thus, dispatchable form, constrain
non-leader events occur correct, fixed amount time leader. Thus,
leader rigid component, B vertex rigid component
environment e, output graph labeled edge weight (d[B](e)
d[A](e), e) edge (A, B) (d[A](e) d[B](e), e) edge (B, A). events
rigidly connected way executed time, dispatcher
647

fiConrad & Williams

needs listed explicitly, execution window enablement tests alone
guarantee correct execution plans. step may identify maximal
groups events constrained occur time leader,
fixed duration leader. example, leader B C follow
exactly three time units, B C constrained occur time.
usual, zero-related vertices recorded label, environment
rigid component.
Third, need alter labeled distance graph rigid component longer
appears exist, instead totally represented leader vertex. algorithm
begins edges interior rigid component. (A, B) vertices
rigid component environment e, algorithm prunes W (A, B) W (B, A)
environments subsumed e. (d, ed ) W (A, B), e subsumes ed , algorithm
removes value pair. e subsume ed , replace (d, ed ) labeled values
(d, e0d ) e0d avoids e, may require multiple new values. Repeat W (B, A).
Finally, need adjust edges enter leave rigid component ensure
input compiler cycles predecessor graphs. idea move
edges leader environments rigid component, remove
non-leader. Assume leader rigid component environment e, B
another vertex rigid component, C vertex rigid component.
every labeled value (d, ed ) w(B, C) vertex, algorithm puts (d + d[B](e)
d[C](e), ed e) W (A, C). Next, replaces (d, ed ) W (B, C) values (d, e0d )
possible e0d union ed constituent kernels e. algorithm repeats
W (C, B), putting (d + d[C](e) d[B](e), ed e) W (C, A), replacing (d, ed )
(d0 , e0d ) avoiding e. Unfortunately, strategy leads duplication grows linearly
domain size choice variables. practice, though, many problems
rigid components, limited penalty minor. results show
outliers may associated growth, problems affected.
Example 7.16 usual, let x, {1, 2} choice variables. Figure 7.8a depicts input
labeled distance graph fragment. opposing edge weights 1 1, easily
identify {A, B} rigid component environment {x = 1}. need follow
procedure process it.
First, always scheduled B, therefore leader. ran SSSP
added vertex, would find d[A]({x = 1}) = 1 d[B]({x = 1}) = 0, proving
assertion. Since d[B]({x = 1}) d[A]({x = 1}) = 1, event B follows one time
unit. Therefore, edges inserted output dispatchable form shown Figure 7.8c
enforce delay.
Next, alter input graph remove rigid component, beginning edges
rigid components vertices. Edge (B, A) one weight it, subsumed
environment rigid component, exists rigid component does,
thus already handled, pruned. Likewise, weight (1, {}) W (A, B)
pruned. hand, weight (2, {x = 2}) W (A, B) already avoids
environment rigid component, left unchanged.
Continue edges enter leave rigid component. (A, C) uses leader
vertex, directly require modification. Edge (B, C) needs moved,
giving new weight (4 + 1, {x = 1}) W (A, C), already present, requires
648

fiDrake: Efficient Executive Temporal Plans Choice

modification. Since environment subsumed rigid component environment,
(4, {x = 1}) removed w(B, C). Edge (C, B) also needs moved. leads
new value (2 1, {y = 1} {x = 1}) = (1, {x = 1, = 1}) W (C, A). Since {y = 1}
subsumed rigid components environment, must modify value (C, B)
avoids environment. Avoiding {x = 1} means {x = 2}, modify
value (2, {y = 1}) (2, {x = 2, = 1}). modifications completely remove rigid
component provide dispatcher sufficient information correctly execute
rigid components removed.

modifications labeled distance graph guaranteed cycles
predecessor graphs, therefore rigid components. Thus rest fast
algorithm given section correctly compiles dispatchable form. adjusted
unlabeled algorithm search labeled rigid components. Additionally, unlabeled
algorithm removes non-leader vertices rigid components, moving modifying edges
necessary enforce original input constraints. Since vertices may needed
environments rigid component exist, Drake instead modifies process
moving edges replicate effect removing non-leader vertices.
Drakes compilation algorithm designed use labeling concepts compute compact
version dispatchable form plans choice. structure algorithm
similar unlabeled version, number modifications made within step
reason environments. section completes presentation Drakes algorithms.

8. Results
Finally, explore Drakes performance, theoretical standpoint experimentally. analysis gives justification expect Drakes representation
compact, experimental results give evidence Drake performs intended.
8.1 Theoretical Results
give brief characterization analytical worst case performance Drakes algorithms. direct enumeration STNs, Tsamardinos et al.s (2001) work, uses one
STN consistent STN. n choices options each, v vertices,
assume
compiled sparse graphs size v log v , compiled
size nd v log v . contrast, Drake store component
STNs independently,

stores distinct values, size kv log v , k nd . worst
case, every single component STN completely different, similarities
choices exploit, hence Drakes compiled representation size,
never worse, constant.
strong parallel existing theory tree width general constraint
satisfaction problems. Dechter Mateescu (2007) explain general constraint
satisfaction problem n variables domain size general solved nd
steps, many problems structure. tree width, n n problem represents
number
variables effectively interact, search completed



(n ) time. Similarly, Labeled STNs, choice variables may interact fully,
thus effective number choice variables problem often smaller
649

fiConrad & Williams

{(1, {x = 1}), (2, {x = 2})}


B
{(1, {x = 1})}
{(4, {x = 1})}

{(5, {x = 1})}

{(2, {y = 1})}
C
(a) Input labeled distance graph

{(2, {x = 2})}


B

{(1, {x = 1, = 1})}

{(5, {x = 1})}

{(2, {x = 2, = 1})}
C
(b) Contracted labeled distance graph

{(1, {x = 1})}


B
{(1, {x = 1})}

C
(c) Dispatchable form rigid component

Figure 7.8: example processing rigid component Labeled Distance Graph.


total number. notation, Drakes compiled problems size (n )d n log v .
smaller base exponent lead significant savings.
650

fiDrake: Efficient Executive Temporal Plans Choice

compile time run-time latency difficult characterize, however,
overhead labeling operations also grows n. Therefore,
attempt analytic analysis.
8.2 Experimental Results
section presents experimental validation Drakes compilation dispatch algorithms randomly generated, structured problems. First, develop suite random
structured Labeled STNs, derived Stedls (2004) problem generator. compile
dispatch suites problems twice, Drake explicitly enumerating component STNs, following techniques developed Tsamardinos et al. (2001).
Finally, compare compiled size problems, compilation time, execution latency. Throughout section, plots use number consistent component
STNs horizontal axis, appears correlate well effective difficulty
problem. metrics, provide results two methods side
side one plot, show ratio performance another one, allow point-wise
comparison difference performance identical problems. problems
constructed 2-11 binary choices 2-7 ternary choices. 100 problems
sizes; problems range 4 consistent component STNs
2000. number events ranges 4 22 number component STNs
increase keep consistent ratio constraints events.
comparison performed Lisp implementation, run 2.66 GHz machine
4 Gb memory. performance related implementation details
omitted prior sections. example, labeled value sets stored ordered lists
reduce insertion query time. Additionally, found memoization subsumption
union operations dramatically improved performance. implementation aggressively
prunes values inconsistent environments avoid unnecessary reasoning. STN
compiler dispatcher exercise code Drake support fair comparison,
pays small overhead execution speed.
first metric comparison size dispatchable form random problems. computed serializing graph representations strings. Since Drakes
compilation algorithm derived fast STN compiler, maximum memory footprint compilation dispatch double numbers.
Since designed Drake metric mind, expect improvement clear
significant, Figure 8.1 shows. ratio plot, value multiple improvement Drake STN enumeration. Except small problems, Drakes
memory performance superior, improvement ranges around 700 times
smaller memory footprint largest problems. STN enumeration Tsamardinos et
al. (2001) develops uses around 2 MB storage, although insignificant
modern desktop, often significant embedded hardware, especially system
must store library compiled plans. contrast, Drakes memory footprint 1-10 kB
cases, trivial, even large numbers, hardware. half
worse performing examples, fit main band results, correspond
ternary choices. believe likely corresponds growth caused avoiding
environments handling complex overlapping rigid components problems.
651

fiConrad & Williams

Compiled Size (kB)
4

10

Drake
STN Enumeration

3

10

2

10

1

10

0

10

1

10

0

10

1

2

3

10
10
10
Number Consistent Component STNs

4

10

(a) size dispatchable labeled distance graphs.

Compiled Size Ratio STN/Labeled STN
3

10

2

10

1

10

0

10

1

10

0

10

1

2

3

10
10
10
Number Consistent Component STNs

4

10

(b) ratio size compiled STN enumeration size size Drakes labeled distance graph.

Figure 8.1: size dispatchable form random problems function
number component STNs.

652

fiDrake: Efficient Executive Temporal Plans Choice

second metric time required compile random problems, shown Figure
8.2. Often, Drakes compilation times much better, highly variable.
number largest problems, Drake 1000 times faster. However,
problems exhibit little improvement, 100 times slower worst
cases. problems take less ten minutes methods, Drake takes
hours five largest problems. expect higher variability run-time
compilation algorithms loop repeatedly labeled graph, exacerbating
variability shown compiled size. Thus, surprising problems whose
dispatchable form compact, run-time suffers.
final metric run-time latency incurred algorithms, shown Figure
8.3. Drakes reported latency maximum latency single decision making period
single execution entire problem. STN enumeration latency reported
time required identify, execute, propagate first event consistent,
component STN. metrics identical, quite comparable.
values reported 103 seconds reported zero Lisps timing features,
inflate fit log scale.
Although differences compilation time interesting, increases run-time latency far critical Drakes applicability real world. Fortunately,
situation looks favorable. systems execute largest problems
tenth second, small moderate sized problems around 10 milliseconds.
Although Drake slower reasonable fraction problems, margin fairly low;
note cluster values ratio less 101 corresponds jump
effectively zero 10 milliseconds. know real ratio, points
create visible cluster 101 may may misleading. Instead, focus
larger problems methods measurable, Drake generally performs
quite well. Again, handful problems outliers, taking much time, tens
seconds, would acceptable applications. conclude Drake
perform well embedded systems many real world problems, terms memory
usage latency.
Overall, results Drake designed achieve. Using compact representation provides smaller memory footprint. Sometimes, exploiting similarity
choices makes reasoning fast, times imposes extra computational burden
tease similarities, lack thereof. Enumerating STNs directly quite predictable costs, time space, Drake far variable, depending
precise nature problem. find results quite promising, must caution
applications particular problems could better worse, depending factors
know easily characterize. well illustrated problems
outliers three metrics. may useful future work investigate
sources variability Drakes performance.
practical note, tightly regulated number events focus investigation
scaling number choices. However, algorithms scale gracefully,
similar increases space time costs, plans events. Overall,
Drake appears provide noticeably lower memory footprint dispatching problems
discrete choices direct enumeration strategy Tsamardinos et al. (2001),
suffering mild increase run-time latency.
653

fiConrad & Williams

Compile Time (sec)
6
10
Drake
STN Enumeration
4

10

2

10

0

10

2

10

0

10

1

2

3

10
10
10
Number Consistent Component STNs

4

10

(a) compile time random problems.

Compile Time Ratio, STN/Labeled STN
4
10

2

10

0

10

2

10

0

10

1

2

3

10
10
10
Number Consistent Component STNs

4

10

(b) ratio compile time STN enumeration Drakes compile time.

Figure 8.2: compile time random problems function number component
STNs.

654

fiDrake: Efficient Executive Temporal Plans Choice

Execution Latency (sec)
1

10

Drake
STN Enumeration
0

10

1

10

2

10

3

10

0

10

1

2

3

10
10
10
Number Consistent Component STNs

4

10

(a) execution latency.

Execution Latency Ratio STN/Labeled STN
2

10

1

10

0

10

1

10

2

10

0

10

1

2

3

10
10
10
Number Consistent Component STNs

4

10

(b) ratio execution latency STN enumeration Drakes execution latency.

Figure 8.3: execution latency random problems function number component STNs.

655

fiConrad & Williams

9. Summary
work presents Drake, compact, flexible executive plans choice. Drake takes
input plans temporal flexibility discrete choices, Labeled STNs DTNs,
selects execution times makes discrete decisions run-time (Dechter et al.,
1991). Choices substantially improve expressiveness tasks executives
perform, improve robustness resulting executions. Prior execution approaches
typically impose significant memory requirements introduce substantial latency
execution. goal developing Drake develop dispatching executive lower
memory footprint.
Building upon concept labels employed ATMS compactly encode
consequences set alternative choices, Drake introduces new compact encoding,
called labeled distance graphs, encode efficiently reason discrete choices,
introduce corresponding maintenance system (de Kleer, 1986). adaptation
ATMS labeling scheme focuses maintaining non-dominated constraints, allows
Drake exploit structure temporal reasoning, cast shortest path problem
distance graph, provide compact representation. Furthermore, modifying existing
unlabeled algorithms account labels change overall structure
algorithms.
Drakes compilation algorithm successfully compresses dispatchable solution
two orders magnitude relative Tsamardinos, Pollack, Ganchevs (2001) prior work,
often reducing compilation time, typically introducing modest increase
execution latency. Thus, believe Drake successfully realizes initial goals. Within
experiments, compilation typically takes less ten minutes, occasion takes
hours. Although time consuming later case, still acceptable, since compilation
performed off-line, task first defined. summarize, Drakes Labeled
STNs labeled distance graphs enable executive strikes useful balance
latency memory consumed, appropriate real world applications. Drakes
labeling scheme also provides opportunity extend wide range graph algorithms
reason represent choice efficiently.

Acknowledgments
authors would like thank Julie Shah David Wang many helpful ideas
discussions, reviewers insightful comments. Patrick Conrad funded
work Department Defense NDSEG Fellowship.

References
Block, S., Wehowsky, A., & Williams, B. (2006). Robust execution contingent, temporally
flexible plans. Proceedings 21st National Conference Artificial Intelligence,
pp. 802808.
Combi, C., & Posenato, R. (2009). Controllability temporal conceptual workflow
schemata. Dayal, U., Eder, J., Koehler, J., & Reijers, H. (Eds.), Business Process
656

fiDrake: Efficient Executive Temporal Plans Choice

Management, Vol. 5701 Lecture Notes Computer Science, pp. 6479. Springer
Berlin / Heidelberg.
Combi, C., & Posenato, R. (2010). Towards temporal controllabilities workflow
schemata. Proceedings 17th International Symposium Temporal Representation Reasoning, pp. 129136. IEEE.
Conrad, P. R. (2010). Flexible execution plans choice uncertainty. Masters
thesis, Massachusetts Institute Technology.
Conrad, P. R., Shah, J. A., & Williams, B. C. (2009). Flexible execution plans choice.
Proceedings Nineteenth International Conference Automated Planning
Scheduling (ICAPS-09). AAAI Press.
Cormen, T., Leiserson, C., Rivest, R., & Stein, C. (2001). Introduction algorithms (Second
edition). MIT Press.
de Kleer, J. (1986). assumption-based TMS. Artificial intelligence, 28 (2), 127162.
Dechter, R., & Mateescu, R. (2007). AND/OR search spaces graphical models. Artificial
Intelligence, 171 (2-3), 73106.
Dechter, R., Meiri, I., & Pearl, J. (1991). Temporal constraint networks. Artificial Intelligence, 49 (1-3), 61 95.
Doyle, J. (1979). truth maintenance system* 1. Artificial Intelligence, 12 (3), 231272.
Effinger, R. (2006). Optimal Temporal Planning Reactive Time Scales via Dynamic
Backtracking Branch Bound. Masters thesis, Massachusetts Institute Technology.
En, N., & Srensson, N. (2004). extensible sat-solver. Giunchiglia, E., & Tacchella, A.
(Eds.), Theory Applications Satisfiability Testing, Vol. 2919 Lecture Notes
Computer Science, pp. 333336. Springer Berlin / Heidelberg.
Goldstone, D. (1991). Controlling inequality reasoning TMS-based analog diagnosis
system. Proceedings Ninth National Conference Artificial Intelligence,
pp. 512517.
Hiatt, L., Zimmerman, T., Smith, S., & Simmons, R. (2009). Strengthening schedules
uncertainty analysis. Proceedings International Joint Conference
Artificial Intelligence, Vol. 2, pp. 53.
Hunsberger, L. (2009). Fixing semantics dynamic controllability providing
practical characterization dynamic execution strategies. Proceedings
16th International Symposium Temporal Representation Reasoning, pp.
155162. IEEE.
Hunsberger, L. (2010). Fast Incremental Algorithm Managing Execution Dynamically Controllable Temporal Networks. Proceedings 17th International
Symposium Temporal Representation Reasoning, pp. 121128. IEEE.
Khatib, L., Morris, P., Morris, R., & Rossi, F. (2001). Temporal constraint reasoning
preferences. Proceedings International Joint Conference Artificial
Intelligence, Vol. 1, pp. 322327.
657

fiConrad & Williams

Kim, P., Williams, B. C., & Abramson, M. (2001). Executing reactive, model-based programs graph-based temporal planning. Proceedings International
Joint Conference Artificial Intelligence, Vol. 17, pp. 487493.
McDermott, D. (1983). Contexts data dependencies: synthesis. Pattern Analysis
Machine Intelligence, IEEE Transactions on, PAMI-5 (3), 237246.
Morris, P. (2006). structural characterization temporal dynamic controllability. Principles Practice Constraint Programming, 4204, 375389.
Morris, P., Muscettola, N., & Vidal, T. (2001). Dynamic control plans temporal
uncertainty. Proceedings International Joint Conference Artificial Intelligence, Vol. 17, pp. 494502.
Muscettola, N., Morris, P., & Tsamardinos, I. (1998). Reformulating temporal plans
efficient execution. Proceedings Principles Knowledge Representation
Reasoning-International Conference, pp. 444452.
Planken, L., de Weerdt, M., & van der Krogt, R. (2008). P 3 C: New Algorithm
Simple Temporal Problem. Proceedings Eighteenth International Conference
Automated Planning Scheduling (ICAPS-08), pp. 256263. AAAI Press.
Rossi, F., Venable, K., & Yorke-Smith, N. (2006). Uncertainty soft temporal constraint
problems: general framework controllability algorithms fuzzy case. Journal Artificial Intelligence Research, 27 (1), 617674.
Shah, J., Stedl, J., Williams, B., & Robertson, P. (2007). fast incremental algorithm
maintaining dispatchability partially controllable Plans. Proceedings Seventeenth International Conference Automated Planning Scheduling (ICAPS2007). AAAI Press.
Shah, J. A., & Williams, B. C. (2008). Fast Dynamic Scheduling Disjunctive Temporal Constraint Networks Incremental Compilation. Proceedings
Nineteenth International Conference Automated Planning Scheduling (ICAPS2008). AAAI Press.
Shu, I.-h., Effinger, R., & Williams, B. C. (2005). Enabling Fast Flexible Planning
Incremental Temporal Reasoning Conflict Extraction. Proceedings
Fifteenth International Conference Automated Planning Scheduling (ICAPS05), pp. 252261. AAAI Press.
Smith, S., Gallagher, A., & Zimmerman, T. (2007). Distributed management flexible
times schedules. Proceedings 6th International Joint Conference Autonomous Agents Multiagent Systems, pp. 18. ACM.
Stallman, R., & Sussman, G. (1977). Forward reasoning dependency-directed backtracking system computer-aided circuit analysis* 1. Artificial Intelligence,
9 (2), 135196.
Stedl, J. (2004). Managing temporal uncertainty limited communication: formal
model tight loose team coordination. Masters thesis, Massachusetts Institute
Technology.
658

fiDrake: Efficient Executive Temporal Plans Choice

Stergiou, K., & Koubarakis, M. (2000). Backtracking algorithms disjunctions temporal
constraints. Artificial Intelligence, 120 (1), 81117.
Tsamardinos, I. (2002). probabilistic approach robust execution temporal plans
uncertainty. Methods Applications Artificial Intelligence, 2308, 751751.
Tsamardinos, I., Muscettola, N., & Morris, P. (1998). Fast transformation temporal
plans efficient execution. Proceedings Fifteenth National Conference
Artificial Intelligence, pp. 254261.
Tsamardinos, I., Pollack, M., & Ganchev, P. (2001). Flexible dispatch disjunctive plans.
6th European Conference Planning, pp. 417422.
Tsamardinos, I., Vidal, T., & Pollack, M. (2003). Ctp: new constraint-based formalism
conditional, temporal planning. Constraints, 8 (4), 365388.
Venable, K., & Yorke-Smith, N. (2005). Disjunctive temporal planning uncertainty.
Proceedings International Joint Conference Artificial Intelligence, pp.
172122. Citeseer.
Williams, B., & Ragno, R. (2007). Conflict-directed A* role model-based embedded systems. Discrete Applied Mathematics, 155 (12), 15621595.
Williams, B. C., Ingham, M. D., Chung, S. H., & Elliott, P. H. (2003). Model-based programming intelligent embedded systems robotic space explorers. Proceedings
IEEE: Special Issue Modeling Design Embedded Software, 91 (1),
212237.
Xu, L., & Choueiry, B. (2003). new effcient algorithm solving simple temporal
problem. Proceedings 10th International Symposium Temporal Representation Reasoning Fourth International Conference Temporal Logic, pp.
210220.

659

fiJournal Artificial Intelligence Research 42 (2011) 887916

Submitted 04/11; published 12/11

Multi-Robot Adversarial Patrolling:
Facing Full-Knowledge Opponent
Noa Agmon

agmon@cs.utexas.edu

Department Computer Science
University Texas Austin
TX, USA

Gal Kaminka
Sarit Kraus

galk@cs.biu.ac.il
sarit@cs.biu.ac.il

Computer Science Department
Bar Ilan University
Israel

Abstract
problem adversarial multi-robot patrol gained interest recent years, mainly
due immediate relevance various security applications. problem, robots
required repeatedly visit target area way maximizes chances
detecting adversary trying penetrate patrol path. facing strong
adversary knows patrol strategy robots, robots use deterministic
patrol algorithm, many cases easy adversary penetrate undetected
(in fact, cases adversary guarantee penetration). Therefore
paper presents non-deterministic patrol framework robots. Assuming
strong adversary take advantage knowledge try penetrate
patrols weakest spot, hence optimal algorithm one maximizes chances
detection point. therefore present polynomial-time algorithm determining
optimal patrol Markovian strategy assumption robots,
probability detecting adversary patrols weakest spot maximized. build
upon framework describe optimal patrol strategy several robotic models
based movement abilities (directed undirected) sensing abilities (perfect
imperfect), dierent environment models - either patrol around perimeter (closed
polygon) open fence (open polyline).

1. Introduction
problem multi-robot patrol gained interest recent years (e.g., Ahmadi & Stone,
2006; Chevaleyre, 2004; Elmaliach, Agmon, & Kaminka, 2007; Paruchuri, Tambe, Ordonez,
& Kraus, 2007; Amigoni, Gatti, & Ippedico, 2008), mainly due immediate relevance
various security applications. multi-robot patrol problem, robots required
repeatedly visit target area order monitor it. Many researchers focused
frequency-based approach, guaranteeing point-visit frequency criteria met
patrol algorithm, example maximizing minimal frequency guaranteeing uniform frequency (e.g., refer Elmaliach et al., 2007; Chevaleyre, 2004; Almeida, Ramalho,
Santana, Tedesco, Menezes, Corruble, & Chevaleyr, 2004).
contrast, advocate approach robots patrol adversarial settings,
goal patrol way maximizes chances detecting adversary
c
2011
AI Access Foundation. rights reserved.

fiAgmon, Kaminka & Kraus

trying penetrate patrol path. Thus decisions adversary must
taken account. objective is, therefore, develop patrol paths robots,
following paths robots maximize chance adversarial detection.
problem adversarial planning specically adversarial patrolling wide problem,
generally computational tractable results exist. paper presents problem
restrictive environment perimeter patrol set homogenous robots, providing
computational tractable optimal result.
opposed frequency-driven approaches, adversarial settings point-visit frequency criteria becomes less relevant. Consider following scenario. given cyclic
fence length 100 meters 4 robots must patrol around fence moving
velocity 1m/sec. Clearly, optimal possible frequency point around fence,
terms maximizing minimal frequency, 1/25, i.e., location visited
every 25 seconds. optimal frequency achieved robots placed uniformly
along fence (facing direction) move forward without turning around. Assume takes adversary 20 seconds penetrate area fence.
robots move deterministic path, adversary knowing patrol algorithm
guarantee penetration simply enters position recently visited
patrolling robot. hand, robots move non-deterministically, i.e.,
turn around time time probability greater 0, choice
penetration position becomes less trivial. Moreover, assume adversary may
penetrate time, motivates use nondeterministic patrol behavior indenitely.
rst consider problem patrolling around closed polygon, i.e., perimeter.
introduce non-deterministic framework patrol rst order Markovian assumption robots strategy, robots choose next move random
probability p. probability value p characterizes patrol algorithm.
model system Markov chain (e.g., Stewart, 1994), using model calculate polynomial time probability penetration detection point along
perimeter function p, i.e., depends choice patrol algorithm.
Based functions dening probability penetration detection, nd optimal patrol algorithm robots presence strong adversary, i.e., adversary
full knowledge patrolling robotstheir algorithm current placement.
case, adversary uses knowledge order maximize chances penetrating
without detected. therefore assumed adversary penetrate
weakest spot path, hence goal robots maximize probability
penetration detection weakest spot. provide polynomial time algorithm
(polynomial input size, depending number robots characteristics
environment) nding optimal patrol robots facing full knowledge
adversary. show non-deterministic patrol algorithm advantageous, guarantees lower bound criteria performance robots, i.e., ability
block adversary.
use patrol framework consider additional environment robotic models. Specically, consider case robots required patrol along
open polyline (fence). show although case inherently dierent patrolling
along perimeter, basic framework still used (with changes) order nd
optimal patrol algorithm robots. investigate also dierent movement models
888

fiMulti-Robot Adversarial Patrolling

robots, namely robots directionality associated movement (and
turning around could cost system time), omnidirectional. addition,
model various types sensing capabilities robots, specically, sensing capabilities perfect imperfect, local long-range. cases show
basic framework extended include various models.
paper organized follows. Section 2 discuss previous work, related
research. Section 3 describes basic robot environment model. introduce
Section 4 framework patrolling robots, describe polynomial-time algorithm
determining probability penetration detection every point along patrol
path (Section 4.2). show Section 4.3 algorithm dening optimal patrol
algorithm robots, assuming face full-knowledge adversary, Section 4.4
provides interesting results implementation algorithms. Section 5
show basic framework used order consider various robotic sensing
movement models dierent environment (open fences). Section 6 concludes.

2. Related Work
Systems comprising multiple robots cooperate patrol designated area
studied various contexts (e.g., Chevaleyre, 2004; Elmaliach, Agmon, & Kaminka,
2009). Theoretical (e.g., Chevaleyre, 2004; Elmaliach et al., 2009; Amigoni et al., 2008)
empirical (e.g., see Sak, Wainer, & Goldenstein, 2008; Almeida et al., 2004) solutions
proposed order assure quality patrol. denition quality depends
context. studies concentrate frequency-based patrolling, optimizes
frequency visits throughout designated area (e.g. refer Elmaliach et al., 2009;
Almeida et al., 2004; Chevaleyre, 2004). Ecient patrol, case, patrol guaranteeing high frequency visits parts area. contrast, adversarial patrolling
(addressed paper) deals detection moving adversaries attempting
avoid detection. Here, ecient patrol one deals eciently intruders (e.g.,
see Sak et al., 2008; Basilico, Gatti, & Amigoni, 2009b; Amigoni et al., 2008).
rst theoretical analysis frequency-based multi-robot patrol problem
concentrated frequency optimization presented Chevaleyre (2004). introduced
notion idleness, duration point patrolled area visited.
work, analyzed two types multi-robot patrol schemes graphs respect
idleness criteria: partitioning area subsections, section visited
continuously one robot; cyclic scheme patrol path provided along
entire area robots visit parts area, consecutively. proved
latter approach, frequency visiting points area considerably higher.
Almeida et al. (2004) oered empirical comparison dierent approaches towards
patrolling regards idleness criteria, shows great advantage cycle based
approach.
Elmaliach et al. (2007, 2009) oered new frequency optimization criteria evaluating
patrol algorithms. provide algorithm multi-robot patrol continuous areas
proven maximal minimal frequency well uniform frequency, i.e.,
point area visited highest-possible frequency. work based

889

fiAgmon, Kaminka & Kraus

creating one patrol cycle visits points area minimal time, robots
simply travel equidistantly along patrol path.
Sak et al. (2008) considered case multi-agent adversarial patrol general graphs
(rather perimeters, work). concentrated empirical evaluation
(using simulation) several non-deterministic patrol algorithms roughly
divided two: divide graph patrolling agents,
allow agents visit parts graph. considered three types adversaries:
random adversary, adversary always chooses penetrate recently-visited
node adversary uses statistical methods predict chances node
visited soon. concluded patrol method outperformed
others domains checked, optimality depends graph
structure. contrast investigation, provide theoretical proofs optimality
dierent settings.
work adversarial multi-robot patrol examined also using game-theoretic
approaches (e.g., see Basilico et al., 2009b; Basilico, Gatti, & Amigoni, 2009a; Pita, Jain,
Ordonez, Tambe, Kraus, & Magorii-Cohen, 2009; Paruchuri, Tambe et al., 2007). Note
work described herein modeled game theoretic problem: Given two
players, robots adversary, possible set actions side, determine
optimal policy robots maximize utility gained adversarial
detection. zero-sum game. Since assume strong (full knowledge) adversarial
model, adopt minmax approach, namely, minimizing maximal utility
opponent (or case: equivalent maximizing minimal probability detection
robots). However, work use game theoretic tools nding
equilibrium strategy, use tailored ad-hoc solution nds optimal policy
robots polynomial time, taking account robots possible sensing movement
capabilities.
closely related work Amigoni et al. (2008) Basilico et al. (2009b, 2009a)
used game-theoretic approach using leader-follower games determining optimal
strategy single patrolling agent. considered environment patrolling
robot move two nodes graph, opposed perimeter model
use. solution suitable one robot heterogenous environments, i.e., utility
agent adversary changes along vertices graph. formulate
problem mathematical programming problem (either multilinear programming
mixed integer linear programming). Consequently, computation optimal strategy
exponential, yet using optimization tools manage get good approximation
optimal solution.
Paruchuri, Tambe et al. (2007) considered problem placing stationary security
checkpoints adversarial environments. Similar assumptions, assume
agents work adversarial environment adversary exploit predictable behavior agents, adversary full knowledge patrolling
agents. model system using Stackelberg games, uses policy randomization
agents behavior order maximize rewards. problem formulated
linear program single agent, yielding optimal solution case. Using
single agent policy, present heuristic solution multiple agents,
optimal solution intractable. Paruchuri, Pearce et al. (2007) study problem
890

fiMulti-Robot Adversarial Patrolling

cases adversarial model unknown agents, although adversary still
full knowledge patrol scheme. provide heuristic algorithms optimal strategy selection agents. Pita et al. (2009) continued research consider
case adversaries make choices based bounded rationality
uncertainty, rather make optimal game-theoretic choice. considered three
dierent types uncertainty adversarys choices, provided new mixed-integer
linear programs Stackelberg games deal types uncertainties.
opposed works based using game-theoretic approaches
provide approximate heuristic solutions intractable optimal solutions, work
focus specic characteristics robots environment, provide optimal
polynomial-time algorithms nding optimal patrol strategy multi-robot team
using minmax approach.
Theoretical work based stochastic processes related work cat
mouse problem (Coppersmith, Doyle, Raghavan, & Snir, 1993), also known predatorprey (Haynes & Sen, 1995) pursuit evasion problem (Vidal, Shakernia, Kim, Shim, &
Sastry, 2002). problem, cat attempts catch mouse graph
mobile. cat knowledge mouses movement, therefore far
cat concerned, mouse travels similarly simple random walk graph.
We, hand, worst case assumptions adversary. consider
robotic model, movement cat correlated movement
robot, possible directionality movement, possible cost changing directions
possible sensorial abilities. Moreover, model robots travel around perimeter
fence, rather general graph. Thus sense, research concerned
pursuit-evasion polyline - open closed.
theoretical work Shieh Calvert (1992), based computational geometry
solutions, attempts nd optimal viewpoints patrolling robots. try maximize view robots area, show problem N P-Hard, nd
approximation algorithms problem.

3. Robot Environment Model
following section, provide description robotic model, environment model
adversarial model. describe basic model patrolling around perimeter
(closed polygon). environments robotic models discussed Section 5.
3.1 Environment
consider patrol circular path around closed polygon P . path around P
divided N segments length uniform time distance, i.e., robot travels
one segment per cycle sensing (its velocity 1 segment / 1 time cycle).
division segments makes possible consider patrols heterogeneous paths.
areas, diculty passing terrains varies one terrain another,
example driving muddy tracks vs. driving road. addition, riding around corners
requires vehicle slow down. Figure 1 demonstrates transition given area
discrete cycle. area, left, given along velocity constraints. path
divided segments robot travels one segment per time cycle
891

fiAgmon, Kaminka & Kraus

monitoring it, i.e., length segment determined velocity
robot (corresponding time takes travel specic segment)
sensorial capabilities robot. path divided segments uniform
travel time, equivalent considering simple cycle appears right Figure
1.
Note distance robots calculated respect number
segments them, i.e., distance travel time. example, say
distance R1 R2 7, 7 segments them, R1
remained still, would taken R2 7 time cycles reach R1 (assuming R2
headed towards right direction).

equivalent
Figure 1: example creating discrete segments circular path property
robots travel one segment per cycle. dierent line structures along perimeter left
correlate dierent velocity constraints, converted (in middle gure) N segments
robots travel one time cycle. gure equivalent gure right,
simple cycle divided N uni-time segments.

3.2 Patrolling Robotic Model
consider system k > 1 homogenous mobile robots R1 , . . . , Rk , required
patrol around closed polygon. robots operate cycles, cycle consists
two stages.
1. Compute: Execute given algorithm, resulting goal point, denoted pG ,
robot travel.
2. Move: Move towards point pG .
model synchronous, i.e. robots execute cycle simultaneously. concentrate attention Compute stage, i.e., compute next goal point.
assume robots movement model directed pG behind robot,
physically turn around. Turning around costly operation, model
cost time, i.e., robot turns around resides segment time units.
case movement model directed discussed Section 5.1. Throughout
paper assume simplicity = 1, unless stated otherwise.
key result research (Section 4) optimal patrolling necessitates robots
placed uniform distance = N/k one another along perimeter. Consequently, require robots coordinated sense robots move
direction, decided turn around simultaneously. requirement
guarantees uniform distance maintained throughout execution
892

fiMulti-Robot Adversarial Patrolling

patrol algorithm. Note tightly-coordinated behavior achievable centralized
systems, systems communication exists team members. practical implementations may exist (for example uniformly seeding pseudorandom number
generator robots), require coordination inside team. Distributed
systems cannot assume reliable communication left future work.
3.3 Adversarial Model
basic assumption system consists adversary tries penetrate
patrolling robots path without detected. adversary decides,
unknown time, segment penetrate. penetration time
instantaneous, lasts time units, stays segment.
Denition 1. Let si discrete segment perimeter P patrolled one robot
more. Probability Penetration Detection si , ppdi , probability
penetrator going si time units detected robot going
si period time.
words, ppdi probability patrol path robot pass
segment si time penetration attempted segment, hence
calculated segment respect current location robots given
time (since robots maintain uniform distance throughout execution,
relative location remains times). use general acronym ppd
referring general term probability penetration detection (without reference
certain segment).
Recall time distance every two consecutive robots around perimeter
= N/k. Therefore consider values boundaries d+
2 < d. reason
takes robot time units turn, robot adjacent s0
probability > 0 arriving every segment si , 0 t, robot adjacent
sd probability > 0 arriving segments si , (t ) leqd. Hence segment
st+1 probability > 0 visited (t ) + 1 d+2+1 t, otherwise
least one segment, st+1 , probability 0 visited time
units. Therefore adversary full knowledge patrol always manage
successfully penetrate regardless actions taken patrolling robots. Note
appears equation since inuences number segments reachable robot
located segment sd+1 turning around (sd , sd1 , . . . , sd/2+ ). hand,
segments si ppdi = 1 simply using deterministic algorithm.
dene patrol scheme robots
1. Number robots, distance current position.
2. movement model robots characterization movement.
3. robots patrol algorithm.
patrol scheme reects knowledge obtained adversary patrolling robots
given time (hence necessarily time dependent).

893

fiAgmon, Kaminka & Kraus

consider strong adversarial model adversary full knowledge
patrolling robots. Therefore full knowledge adversary knows patrol scheme,
take advantage knowledge order choose penetration spot
weakest spot patrol, i.e., segment minimal ppd. solution concept adopted
(as stated Section 2) similar game-theoretic minmax strategy, yielding
strategy equilibrium (none playersrobots adversaryhas initiative
diverge strategy). adversary learn patrol scheme observing
behavior robots sucient amount time. Note security applications,
strong adversaries exist. applications, adversary models behavior
system worst case scenario patrolling robots point view (similar
classical Byzantine fault model distributed systems, see Lynch, 1996).
environment, robots responsible detecting penetrations
handling penetration (which requires task-allocation methods). Therefore case
adversary issues multiple penetrations similar handling single penetration,
robots detect, report continue monitor rest path, according
algorithm.

4. Framework Adversarial Patrolling Perimeters
environment consider linear environment, step robots
decide either go straight turn around. framework suggest nondeterministic
sense time step decision done independently, random,
probability p. Formally,
{
p
Go straight
Probability next move =
1 p Turn around
Since dierent patrol algorithms consider vary probability p next
step, assert probability p characterizes patrol algorithm.
Assume robot currently located segment si . Therefore robot facing
segment si+1 , probability p go straight probability
1 p turn around face segment si1 . Similarly, facing segment si1 ,
probability p reach segment si1 probability 1 p face
segment si+1 .
Note probability penetration detection segment si , 1 d,
determined probability p characterizing patrol algorithm, therefore ppdi function
p, i.e., ppdi (p). However, whenever possible use abbreviation ppdi .
denition ppdi , need nd probability si visited time units
robot. Assuming perfect detection capabilities robots, ppdi determined
first visit robot si , since intruder detected detection
mission successful (specically, segment visited, game over). Note
ppdi calculated regardless actions adversary.
stated previously, order guarantee optimality patrol algorithm, robots
uniformly distributed along perimeter distance = N/k
every two consecutive robots, coordinated sense

894

fiMulti-Robot Adversarial Patrolling

supposed turn around, simultaneously. following theorem supporting lemmas prove optimality assumptions full-knowledge adversarial
environment.
Lemma 1 follows directly fact movement robots continuous,
thus robot Rl cannot move segment si segment si+j , j > 0, without visiting
segments si+1 , . . . , sj1 between. Note since k > 1 follows number
segments unvisited Rl greater 2t (otherwise simple deterministic algorithm
would suce detect adversary probability 1). Therefore time units
Rl residing initially segment s0 cannot visit segment si , < t, arriving
direction perimeter without visiting segments closer current location (s0 )
rst (this argument holds segments left right s0 ).
Lemma 1. given p, function ppdli : N [0, 1] constant Rl residing
segment s0 monotonic decreasing function, i.e., distance robot
segment increases, probability reaching time units decreases.
Lemma 2. distance two consecutive robots along cyclic patrol path
smaller, ppd segment higher vice versa.
Proof. Consider sequence S1 segments s1 , . . . , sw two adjacent robots, Rl
Rr , s1 adjacent current location Rl sw adjacent current
location Rr . Let S2 similar sequence, w 1 segments, i.e., distance
Rl Rr decreases one segment. Assume robots distance
greater equal w 1 Rl Rr , w 1 < t. Since robot may
inuence ppd segments distance (as probability
0 arriving segment greater distance within time units), probability
penetration detection, ppd, sequences inuenced possible visits Rl
Rr .
Denote probability penetration detection segment si Sj ppdi (j), 1 w,
j {1, 2}, probability penetrator detected robot Rx ppdxi (j),
x {l, r}. Therefore, segment si Sj , ppdi (j) = ppdli (j) + ppdri (j) ppdli (j)ppdri (j)
(either Rl Rr detect adversary, both). Note either ppdli (j), ppdri (j)
equal 0. need show ppdi (2) ppdi (1), 1 w,
least one segment sm , ppdm (2) > ppdm (1). Specically, sucient show
ppdli (2) + ppdri (2) ppdli (2)ppdri (2) {ppdli (1) + ppdri (1) ppdli (2)ppdri (2)} 0,
inequality strict.
every segment si , ppdli (1) = ppdli (2) (there change relative location),
hence need prove ppdri (2) ppdri (1) ppdli (2){ppdri (2) ppdri (1)}. Since 0
ppdli (2) 1, order inequality hold, left show ppdri (2) ppdri (1) 0.
Lemma 1 know ppdri (j) monotonically decreasing, therefore i,
ppdri (2) ppdri (1), completes proof inequality.
left show = m, ppdrm (2)ppdrm (1) > ppdlm (2){ppdrm (2)ppdrm (1)},
i.e., ppdlm (2) = 1, ppdrm (2) > ppdrm (1). Robot Rr may inuence
ppd sides - segments located left right current
position. Denote number inuenced segments right (y may equal
0). > 0, ppdrwy+1 (2) > ppdrwy (1). words, Rr probability 0
895

fiAgmon, Kaminka & Kraus

reaching segment distance + 1 S1 , S2 segments
away it, therefore Rr probability greater 0 reach it. = 0,
ppdrw (2) = 1 > ppdrw (1), Rr lies exactly segment sw S2 , ppdrw (1) = 0.
Theorem 3. team k mobile robots engaged patrol mission maximizes minimal ppd
following conditions satisfied. a. time distance every two consecutive
robots equal b. robots move direction speed.
Note condition b means robots move together direction, i.e.,
change direction, k robots change direction simultaneously.
Proof. Following Lemma 2, sucient show combination conditions
b yield minimal distance two consecutive
robots along cyclic path.
(N )
Since N segments k robots, k possibilities initial placement
robots along cycle (robots homogenous, regardless order).
robots positioned uniformly along cycle, time distance pair
consecutive robots N/k. minimal value reached. Therefore,
clearly, condition guarantees minimality.
robots coordinated, possible two consecutive robots along
cycle, Ri Ri+1 , move opposite directions. Therefore distance
increase Nk Nk + 2, Lemma 2 ppd segments
smaller. Ri Ri+1 move towards one another, distance
Nk 2 ppd segments become higher.
hand, pair Rj Rj+1 exists distance increases,
total sum distances consecutive robots remains N , hence minimal ppd
around cycle become smaller.
Therefore way achieving minimal distance (maximal ppd) assuring
condition satised, maintaining achieved satisfying condition b.
Since facing full-knowledge adversary, goal robots maximize
minimal ppd along perimeter, following corollary follows.
Corollary 4. full-knowledge adversarial model, optimal patrol algorithm must
guarantee robots positioned uniformly along perimeter throughout execution patrol.
4.1 Penetration Detection Problem
general denition problem follows.
Penetration detection (PD) problem: Given circular fence (perimeter) divided N segments, k robots uniformly distributed around perimeter distance
= N/k (in time) every two consecutive robots, assume takes time
units adversary penetrate, adversary known full-knowledge
patrol scheme. Let p probability characterizing patrol algorithm
robots, let ppdi (p), 1 description ppdi function p. Find

896

fiMulti-Robot Adversarial Patrolling

optimal value p, popt , minimal ppd throughout perimeter maximized.
Formally,
popt = argmax{ min ppdi (p)}
0p1

1id

summarize model Theorems presented above, optimal algorithm
multi-robot perimeter patrol Markovian strategy assumption robots
following characteristics.

robots placed uniformly around perimeter segments every
two consecutive robots.
robots coordinated sense decide turn around,
simultaneously.
time step, robots continue straight probability p turn around
probability 1 p, turn around stay segment
time units.

Note framework (i.e. framework homogenous robots),
division perimeter sections segments creates equivalent symmetric environment sense order calculate optimal patrol algorithm sucient
consider one section segments, entire perimeter N segments.
due fact section completely equivalent other, remains
throughout execution.
divide goal solving PD problem, i.e., nding optimal patrol algorithm
two stages.
1. Calculating ppdi functions 1 d. determined according
robotic movement model (directed undirected), environment model (perimeter/fence) sensorial model (perfect/imperfect, local/extended).
2. Given ppdi functions, nd solution PD problem, i.e., maximize
ppd segment(s) minimal ppd.
two steps independent sense incorporating various dierent robotic
models change process determining solution PD problem, long
result procedure functions representing ppd values segment.
hand, would like consider dierent goal functions
maximizing minimal ppd (for example maximizing expected ppd), done
without change rst stage, i.e., determining ppd functions. important
result framework applied dierent environment robotic
models (for example fence patrol), dierent goal functions (corresponding dierent
adversarial settings).
897

fiAgmon, Kaminka & Kraus

rst stage basic model (perimeter patrol, directed movement model
robots, robots perfect local sensing) described Section 4.2, second stage
described Section 4.3. Extensions rst stage dierent robot motion models
sensing models described Section 5.
4.2 Determining Probability Penetration Detection
order nd optimal patrol algorithm, necessary rst determine probability
penetration detection segment si (ppdi ), function p (the probability
characterizing patrol algorithm, shown Section 4.1). section present
polynomial time algorithm determines probability.
stated previously, based symmetric nature system, need consider
one section segments lie two consecutive robots, without loss
generality, R1 R2 . use Markov chain order model possible states
transition states system.
order calculate probability detection segment along time cycles,
use graphic model G illustrated Figure 2. segment si original
path, 1 d, create two states G: One moving clockwise direction (scw
),
moving counterclockwise direction (scc
).

R

R
reach
one
1
2

si segments within time units, adversary discovered, i.e.,
matter segment visited time units. Therefore
would like calculate probability first arrival segment,
done dening state sdt (corresponding s0 s0 ) absorbing states, i.e.,
robot passes si once, additional visits segment path
considered. edges G follows. One outgoing edge scw
scc

exists
cw
probability 1 p turning around, one outgoing edge si1 exists
probability p continuing straightforward. Similarly, one outgoing edge scc

cw
cc
si exists probability 1 p turning around, one outgoing edge si+1 exists
probability p continuing straightforward.
cc

S0

S1

S2

S3

S4

S0

cc

0

1p p

cw

1p 0

S1

R2


dt

cw

p



4

1

cw

p



p

cw

cc

3

p



2

1p



4



3

1p
cc

p

1

1p



cc

cc

1

1

p

cw

cc

cw

S3

S4

S4

dt

0

0

0

0

0

0

0

0

0

0

0

0

p

1p p

0

0

0

0

0

0

0

0

p

1p 0

0

0

0

0

0

cc

0

0

0

0

0

1p p

0

0

cw

0

0

0

p

1p 0

0

0

0

cc

0

0

0

0

0

0

0

1p p

S4

cw

0

0

0

0

0

p

1p 0

0

dt

0

0

0

0

0

0

0

0

1

S3

1p



2

dt

cc

S3

cw

S2
p

cw

S2

S2

cc

S2

cw

cc

S1

S1

R1

cw

S1

S3
S4

Figure 2: Conversion initial segments robot locations graphical model,
respective stochastic matrix . segment corresponds two states: one going clockwise one
going counterclockwise. ppdi paths starting scw
ending sdt .


898

fiMulti-Robot Adversarial Patrolling

following theorem, prove probability detecting adversary
robot segment si (i.e., probability arriving segment time units)
equivalent nding paths size absorbing state starting state
scc
. Therefore possible use Markov chain representation determining ppdi ,
shown Algorithm FindFunc.
Theorem 5. Determining probability penetration detection segment si , ppdi ,
equivalent finding paths length start scw
end sdt

Markov chain described above.
Proof. simplicity reasons, proof distinguish sldt srdt ,
absorbing state left right Markov chain (respectively), although
practically represented state sdt .
Clearly, due values considered, ppdi determined visits
two robots surrounding section segments s1 , . . . , sd , denoted Rl Rr .
Recall probability penetration detection segment si dened ppdi =
ppdli + ppdri ppdli ppdri , ppdri (ppdli ) probability adversary, penetrating
si , detected Rr (Rl ). claim ppdli equivalent computing
r
r
l
paths starting scw
ending absorbing state sdt (similarly ppdi state sdt ).
r
l
Clearly, claim, since path length cannot reach sdt sdt ,
follows ppdli ppdri = 0, theorem follow. prove claim ppdli ,
ppdri follows directly.
ppdli probability Rl reach si least time units. Therefore,
must construct paths starting current location Rl passes si ,
take account rst visit segment (everything beyond rst visit
results anyway probability detection = 1). step Rl continues straight
probability p turns around probability 1 p. equivalent keeping Rl
place, moving segments towards Rl probability p switch segments
direction probability 1 p. Hence, every path starting state scw
(without loss
generality; computing paths starting scc

equivalent,

requires
switching
locations

Rl Rr representation) reaching srdt equivalent path started Rl
passing si . Since srdt set absorbing state, every path passing
considered again, i.e., rst visit Rl si considered, required.
Using Markov chain, dene stochastic matrix describes
state transitions system. Figure 2 illustrates Markov chain corresponding
stochastic matrix used computing ppd functions. probability arrival
segment si time units, hence probability penetration detection segment,

cw
scc
2d+1 + s2d+1 entry result Vi , Vi vector 0s, except
1 2i 1th location. formal description algorithm given Algorithm
1. Note algorithm makes symbolic calculation, hence result set
functions p. time complexity Algorithm FindFunc depends calculation time
, generally (2d)3 . However, since sparse, methods multiplying
matrices eciently exist (e.g., see Gustavson, 1978), reducing time complexity
t(2d)2 , i.e. O(td2 ). Since bounded 1, time complexity O(d3 ).

899

fiAgmon, Kaminka & Kraus

Algorithm 1 Algorithm FindFunc(d, t)
1: Create matrix size (2d + 1)(2d + 1), initialized 0s
2: Fill entries follows:
3: [2d + 1, 2d + 1] = 1
4: 1 2d
5:
[i, max{i + 1, 2d + 1}] = p
6:
[i, min{1, 2}] = 1 p
7: Compute =
8: Res = vector size initialized 0s
9: 1 loc
V = vector size 2d + 1 initialized 0s.
10:
11:
V [2loc] 1
Res[loc] = V [2d + 1]
12:
13: Return Res
4.2.1 Handling Higher Values
Algorithm FindFunc Figure 2 demonstrate case = 1, i.e., robot
turns around (with probability 1 p) remains current position one time step.
general case, robot turns around, cost turningmodeled time
higher. cases, Markov chain modied represent value .
ccw
Specically, segment si , instead two corresponding states (scw
si ),
cw
ccw
2( ) states: si si , one set 1 states turning around
direction (from cw ccw vice versa). probabilities assigned edges
ccw
1 p rst outgoing edge scc
rst intermediate state towards si
ccw
cc
1 edge direction, similarly path si si . See Figure
3 illustration. matrix lled according new chain, time
complexity creating matrix grows factor (2d + 1)t (2 + 1)t .
However, long constant, total time complexity change.
S0

S1

S2

S3

S4

S0

R1

R2


p

cw



4

p

cw



3

p

cw



2

1p

1 1p

1 1p

1 1p

1

1

1

1

cw

1

p

dt

1
1

1

dt

1

1
1



cc

4

p

1

1p



1

1

1p
p

1

1
cc

3

p

1p



cc

2

p

1p



cc

1

Figure 3: Illustration Markov chain > 1, specically, = 3.

900

fiMulti-Robot Adversarial Patrolling

4.3 Optimal Adversarial Patrol Algorithm Full-Knowledge Adversaries
cases robots face full knowledge adversary, assumed adversary
take advantage knowledge nd weakest spot patrol, i.e., segment
minimal probability penetration detection. Therefore optimal patrol algorithm
handle adversary one maximizes minimal ppd throughout
perimeter. Hence need nd optimal p, popt , minimal ppd throughout
perimeter maximized.
Also here, since environment symmetric, need consider entire
patrol path, section segments two consecutive robots. input
procedure set ppdi (p) functions calculated previous section
(Section 4.2).
establishing equations representing probability detection segment,
must nd p value maximizes minimal possible value segment,
p continuous range p [0, 1]. Denote equations ppdi (p), 1 d.
maximal minimal value looking p value yielding maximal value inside
intersection integrals ppdi (p). intersection integrals also known
lower envelope functions (Sharir & Agarwal, 1996).
Observing problem geometrically, consider vertical sweep line sweeps
section [0, 1] intersects curves. seeks point p minimal
intersection point sweep line curves, denoted ppd (p), maximal.
p maximin point. Since segment [0, 1] functions ppd1 , . . . , ppdd
continuous, sweep line solution cannot implemented. prove following
lemma point either intersection point two curves, local maxima
one curve (see Figure 4). See Algorithm 2 formal description Algorithm FindP.

Figure 4: illustration two possible maximin points (marked full circle). curves represent
ppdi (p) functions p [0, 1]. left, maximin point created intersection two
curves. right, maximin point local maxima lowest curve.

following, prove Algorithm FindP nds point p maximin
property satised.
Lemma 6. point p yields maximin value ppd (p) following two properties
satisfied.
a. ppd (p) ppdi (p) 1 d.

901

fiAgmon, Kaminka & Kraus

b. One two following conditions holds: ppd (p) intersection two curves (or
more), ppdi (p) ppdj (p) local maxima curve ppdk (p).
Proof. Property a. derived denition maximin point. Therefore
looking maximal point satises property a. must still show point,
ppd (p), obtained either intersection two curves local maxima.
Clearly, maximal point integral found border integral (the curve
itself). area intersections curves lies beneath parts curves,
ppdi1 , . . . , ppdim , ppdij minimal curve section two points

j
j j
[lj , rj ]
j=1 [l , r ] = [0, 1]. nding maximal point section ppdmax =
max{f (x), x [lj , rj ]}, choosing maximal them, i.e., max{ppdjmax , 1 j
m}, obtain ppd (p). section [lj , rj ] maximal point either inside
section borders section. former case precisely local maxima
ppdij . latter intersection point two curves ppdij1 , ppdij ppdij , ppdij+1 .
Lemma 7. point p exists yielding maximin value ppd (p) > 0.
Proof. order prove lemma, need show intersection integrals
ppd1 , . . . , ppdd x section [0, 1], section (0, 1] empty. suces
show every ppdi , ppdi (x) > 0, 0 < x < 1.
function ppdi , 1 represents ppd segment si two robots.
requirement d2 + 1 (for = 1), follows models consider,
0 < p < 1 ppd = 0. Note p = 0 p = 1, ppd either 0 1,
contradict fact point guaranteeing ppd (p) > 0.
Algorithm FindP nds point scanning possible points satisfying conditions
given Lemma 6, reporting x-value (corresponding p value) y-value
dominated ppdi . input algorithm vector functions ppdi , 1
value t. Computing intersections every pair functions costs d2 t2 :
d2 pair computation, t2 nding root polynomial using, example,
Lindsey-Fox method presented Sitton, Burrus, Fox, Treitel (2003). Computing
dominance resulting points respect curves d2 well. Therefore
time complexity Algorithm FindP complexity Algorithm FindFunc, O(( Nk )3 ),
additional cost O(t2 d2 ) = O(( Nk )4 ) (the algorithm itself), i.e., jointly O(( Nk )4 ).
Theorem 8. Algorithm FindP(F, t) finds point p yielding maximin value ppd.
Proof. Algorithm FindP checks intersection points pair curves,
points local maxima curves. checks dominance points, i.e.,
whether location points lower value compared curves,
picks maximal them. Therefore, point found, Lemma 6, point
precisely maximin point. Moreover, Lemma 7 point exists.
4.4 Examples
fully implemented Algorithm FindP order nd optimal maximin p pairs
ds ts. use following examples illustrate relation
reected ppd values. Recall running deterministic patrol algorithm
902

fiMulti-Robot Adversarial Patrolling

Algorithm 2 Algorithm FindP(d, t)
1: F Algorithm FindFunc(d, t).
2: Set popt 0.
3: Fpivot F1,...,d
4:
Compute local maxima (pmax , Fpivot (pmax )) Fpivot
5:
Fi , 1
6:
Compute intersection point pi Fi Fpivot
7:
Fpivot (pi ) > Fpivot (pmax ) Fpivot (pi ) Fk (pi )k
8:
popt pi .
9:
Fpivot (pmax ) > Fpivot (pi ) Fpivot (pi ) Fk (pi )k
popt pmax .
10:
11: Return (pmax , Fpivot (pmax )).

range (0, 1).
range (0, 1).



scenarios handle, minimal ppd 0. assume robots initially heading
clockwise direction.
First all, seen minimal ppd achieved running FindP always
0. t/d 1, i.e., increases, value maximin ppd increases,
vice versa, i.e., t/d 1/2, value maximin ppd decreases. seen
clearly Figure 5. case, xed value 8 checked maximin
ppd 9 15. t/d close 1 (d = 9, = 8) maximin ppd = 0.423,
value decreases 0.05 t/d close 1/2 (d = 15, = 8). Similar results seen
x value check dierent values t.

Figure 5: left, results maximin ppd xed = 8 dierent values d: possible
maximin ppd decreases increases. right, results maximin ppd xed = 16
dierent values t: possible maximin ppd increases increases.

Figure 6, present values ppd 16 segments, dierent possible
values (9 15). seen clearly, value ppd usually decreases
distance left robot increases, reaches segment maximin ppd,
value rises reaching current location robot right.
reason lies fact segments left segment maximin ppd
inuenced mostly robot left, segments right point
mostly inuenced robot right. Since ps yielding maximin point
example value greater 0.8 ts, segment maximin
value right midpoint.
903

fiAgmon, Kaminka & Kraus

Figure 6: ppd values 16 segments values (9 15)

5. Accounting Movement Constraints Sensing Uncertainty
section describe various ways basic framework multi-robot patrol
used solve problem nding optimal patrol algorithm various
settings. First, describe case movement model robots
necessarily directed. discuss various sensing capabilities robots perimeter
patrol: imperfect local sensing, perfect long-range sensing imperfect long-range sensing.
Finally, describe case robots travel along open polyline (fence)
rather perimeter.
5.1 Dierent Movement Models
basic assumption robotic framework robots movement model directed
sense robot go back visit point behind it, physically
turn around. directed movement model suitable various robotic types, example dierential drive robots commonly used robotic labs. However, cases
robots movement undirected, example robot travels along train tracks.We
demonstrate section basic framework used also latter case,
i.e., robot movement undirected.
examine dierence Markov chain resulting ppd three dierent
cases:
1. Bidirectional Movement model, denoted BMP. Here, robots movement pattern
similar movement tracks camera going back forth along xed course
(omnidirectional robots). model, robots movement directionality
sense switching directionsright left vice versadoes require
physically changing direction robot (turning around).

904

fiMulti-Robot Adversarial Patrolling

2. Directional Costly-Turn model, denoted DCP, basic framework discussed
far 1. robots movement directed, turning around special
operation attached cost time. Specically, show results
= 1.
3. Directional Zero-Cost model, denoted DNCP, special case DCP
model = 0. robots movement directed, yet turning around
take extra time. coherently dierent BMP, step robot
go either right left, straight back (where could either
right left, depending current heading robot).
basic framework used handling three models simply adapting
Markov chain current model. changes lines 5 6 Algorithm FindFunc.
description Markov chains described Figure 7. BMP model, moves one
step right (segment + 1) probability p one step left (segment
i1) probability 1p. model similar random walk. corresponding
Markov chain simple: edges exist si si+1 probability p si
si1 probability 1 p (with related direction). DNCP DCP
models, assume directionality movement, hence robot continues movement
current direction probability p, turns around (rewinds) probability
1 p. DCP, robot turns around remain segment (as described
Figure 2). DNCP model, chain similar one above, however edges
cc
cc
cw
exist scw
si+1 si si1 probability 1 p. See Figure 7
illustration DNCP, DCP BMP Markov chain.
S0

S1

S2

S3

S4

S0

R1

R2


dt

cw

p



4

DCP

cw

1p
p



cc

cc

cw

DNCP

cw



cc



4

dt





cc



3

p

p

p

p

1

p

cc

1

cw

p



2

cw

1

p





4

1p

3

dt

1p

cc



2

cc

1

1p

p
p
p

1p

dt

1p



2

1p

cc

cw

p

p

3

1p
p

BMP



p

2

p

p

1p 4

cw

1p



3

p

dt


1p



4

p

3


1p



2

dt

1

1p

Figure 7: Conversion initial segments robot locations graphical model three
movement models.

905

fiAgmon, Kaminka & Kraus

examined dierence resulting ppd values three models
case = 16, = 12 (Figure 8). clearly noticeable DCP model yields
less equal values ppd compared DNCP model throughout segments. reason
turning around, DCP model, operation costs extra cycle,
therefore probability arriving segment decreases, compared case
turning around costly. Another interesting phenomena ppd values
BMP considerably higher (and close 1) values obtained models
segments closer location righthand side robot. value decreases
dramatically around value increases back again. Recall
directionality movement, therefore probability going right 0.707 going
left 1 0.707 = 0.293, explains phenomena. One might expected
p = 0.5 random walk model (BMP), however choosing equal probability
going right left, robots necessarily neglect segments away
(the mid segments two consecutive robots), resulting lower minimal ppd.

Figure 8: Results maximin ppd values = 16 = 12 three models: DNCP, DCP
BMP. maximin ppd values circled.

5.2 Perimeter Patrol Imperfect Penetration Detection
Uncertainty perception robots taken consideration practical
multi-robot problems. Therefore consider realistic case robots
imperfect sensorial capabilities. words, even adversary passes
sensorial range robot, still necessarily detect it.
introduce ImpDetect model, robot travels one segment per
time cycle along perimeter monitoring it, imperfect sensing. Denote

906

fiMulti-Robot Adversarial Patrolling

probability adversary penetrating segment si monitored
robot R R actually detect pd 1.
Note pd < 1, revisiting segment robot could worthwhileit could
increase probability detecting adversary. Therefore probability detection
segment si (ppdi ) equivalent probability first arriving si (as illustrated
Section 4.2), probability detecting adversary visit si ,
0 t. Denote probability yth visit robot segment si wiy .
Therefore ppdi dened follows.
ppdi = wi1 pd + wi1 (1 pd ) {wi2 pd + wi2 (1 pd ) {. . . {wit pd }}}

(1)

words, probability detecting penetration probability
detected rst visit (wi1 pd ) plus probability detected
then, later stages. probability detected
second visit (wi2 pd ) later stages, on.
Note time units, wit = 0 currently unoccupied segments si ,
robot resides si , wit precisely (1 pd )t .
One building blocks upon optimal patrol algorithms based,
assumption probability detection decreases remains distance
robot increases, i.e., monotonic decreasing function. fact used
Section 4 proving order maintain optimal ppd, robots must placed
uniformly around perimeter (with uniform time distance), maintain distance
coordinated. order show well, rst prove probability
detection monotonically decreases distance location robot.
Lemma 9. Let = {st+ , . . . , s1 , s0 , s1 , . . . , st } sequence 2t segments, robot
Ra resides s0 time 0. 0, ppdi ppdi+1 , 0, ppdi ppdi1 .
Proof. First, assume > 0 (positive indexes). Equation 1, need compare
1 p + w 1 (1
wi1 pd + wi1 (1 pd ) {wi2 pd + wi2 (1 pd ) {. . . {wit pd }}} wi+1

i+1
2 p + w 2 (1 p ) {. . . {w
pd ) {wi+1


i+1
i+1 pd }}}. therefore sucient show
, 1 t. prove induction m. base case, consider
wim wi+1
1 . accurately proven Lemma 1, based
= 1, i.e., need show wi1 wi+1
fact movement robots continuous, therefore order get
segment must visit segments (the formal proof also uses conditional
probability law).
. Denote
assume correctness < m, prove wim wi+1
probability robot placed segment si return si within r time units xi (r).
symmetric environment, every
j, xi (r) = xj (r). Moreover, r, xi (r)
=
xi (r 1). Therefore wim described r+ut wim1 (u) xi (r), similarly wi+1

m1
m1
m1
wi+1
, since xi (r) =
r+ut wi+1 (u) xi+1 (r). induction assumption, wi


xi+1 (r), follows wi wi+1 , proving lemma positive indexes.
negative indexes reective image positive indexes, time
units. Since induction proven values, proof negative indexes
directly follows.

907

fiAgmon, Kaminka & Kraus

following Theorem follows directly Lemma 9. idea behind
since probability penetration detection decreases distance robots
grow, minimal ppd average ppd maximized distance robots
small possible. Since patrol path cyclic, achieved distance
every two consecutive robots uniform, remains uniform. Note Theorem
10 generalization Theorem 3 imperfect sensing (based fact
general structure ppd function remains even robots might benet
revisiting segment, increasing ppd segment).
Theorem 10. full knowledge adversarial model, patrol algorithm ImpDetect
model optimal satisfies two conditions: a. robots placed uniformly
around perimeter. b. robots coordinated sense turn around,
simultaneously. assuring two conditions, robots preserve uniform
distance throughout execution.
Algorithm nding ppdi imperfect sensorial detection:
Find probability penetration detection pd 1 results dierent Markov
chain, hence dierent stochastic matrix . Figure 9 demonstrates new graphical
model new resulting stochastic matrix (compared Figure 2, pd = 1).
cc
dierence algorithm division s0 two states, scw
0 s0 ,
addition absorbing state sdt represents detected state transitions
states. ppdi therefore obtained + 1 steps (compared steps)
sdt location result vector.
time complexity algorithm remains O(d4 ).
S0

S1

S2

S3

S4

S0
cc

R1

R2



cw



4

1p

cw



4

p



3

1p
cc

p

p

cw



2

1p



cc

3

p

1



2

p



cw

0

pd

(1p)(1pd )

1p
cc

p



cc

1

p(1pd )



cc

0

pd

cc

cw

cc

cw

S4

S4

S0

S0

dt

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

cc

0

0

0

1p p

0

0

0

0

0

0

cw

0

p

1p 0

0

0

0

0

0

0

0

cc

0

0

0

0

0

1p p

0

0

0

0

cw

0

0

0

p

1p 0

0

0

0

0

0

cc

0

0

0

0

0

0

1p

0

0

S3
S4

cw

S4

cc

p

cw

S3

p

S3
1

cc

S3

1p 0

S2

dt

cw

S2

0

S1

cw

1p p

S2

cc

S2
p

cc

S1

cw

S1
p(1pd )

cw

S1

S0

0
p(1pd )

0

p

0

0

0

0

p

1p 0

0

0

0

0

0

0

0

0 (1p)(1p


0

0

0
)

pd

S0

cw

0

0

0

0

0

0

0 p(1pd ) (1p)(1p
)0

pd

dt

0

0

0

0

0

0

0

1

0

0

0

Figure 9: Conversion initial segments robot locations graphical model,
respective stochastic matrix imperfect sensing model.

908

fiMulti-Robot Adversarial Patrolling

5.3 Improving Sensing Capabilities Perimeter Patrol
section present enhancements considering various sensing capabilities
robots. Specically, rst consider case robot sense beyond
currently visited segment. oer solution case robot
sense beyond current position, yet sensing capabilities perfect, change
function distance current position.
5.3.1 Extending (Perfect) Sensing Range
section consider LRange model, sensorial range robot exceeds
section currently resides in. Use L denote number segments robot
senses beyond segment currently occupies. L > 0, refer L segments
shaded segments. Note location shaded segments depends direction
robot shading them, always direction robot facing.
trivial solution dealing situation enlarge size segment,
thus enlarge length time unit used base system,
force L 0. However, case lose accuracy analysis system,
length time cycle small possible also suit velocity robots
value t.
general, values handled system bounded relation
(the distance every two robots along path) - see Section 4. L > 0,
changes. Specically, L = 0, possible values considered d+
2 1.
However, L > 0, possible handle even smaller values t, i.e., even
penetration time adversary short. Formally, possible values given
following equation.
d+
LtdL1
2
smaller d+
2 L, adversary full knowledge manage
penetrate probability 1, i.e., segment (sL+1 ) unreachable within
time units. hand, greater L 1, simple deterministic
patrol algorithm detect penetrations probability 1. assume
time units robot turns around, sense current segment.
change sensing model robot reected Markov chain, seen
cw
Figure 10. change add 2L arrows absorbing state sdt , scw
1 , . . . , sL
cc
cc
sd , . . . , sdL+1 . stochastic matrix changes accordingly, probability
penetration detection segment si becomes result vector multiplication t+1 Vi ,
Vi vector size 2d + 1 entries 0 except entry corresponding
location scw
, holds value 1, similar process described Algorithm
FindFunc (1).
5.3.2 Extending Sensorial Range Along Imperfect Detection
many cases, actual sensorial capabilities robot composed two characteristics described previous sections, i.e., robot sense beyond current
segment, however sensing ability imperfect. Therefore section introduce
909

fiAgmon, Kaminka & Kraus

L=1
cc

S0

S1

S2

S3

S4

S0

S1

cc

0

cw

cc
cw



cw

p



4

cw

1p





cw

p



cc

3

p

p



2

1p

cc

4

p

3

1

cc

1p



cc

1

2

p

1p



cc

1

dt

cw

cc

cw

S4

dt

1p p

0

0

0

0

0

0

0

0

0

0

0

0

0

0

1

0

0

0

1p p

0

0

0

0

0

p

1p 0

0

0

0

0

0

0

0

0

0

0

1p p

0

0

0

0

0

p

1p 0

0

0

0

cc

0

0

0

0

0

0

1

0

0

S4

cw

0

0

0

0

0

p

1p 0

0

dt

0

0

0

0

0

0

0

0

1

S3
1

cw

S4

S2
1

cc

S3

S2

cw

cw

S3

S1

R2

cc

S2

S1

R1

cw

S1

S3
S4

S2

Figure 10: illustration L segments shaded robot R. case R facing right, therefore
shaded segments right. Markov chain changes accordingly, therefore also stochastic
matrix .

ImpDetLRange sensorial model, combination LRange ImpDetect
models. robot sense L segments beyond current segment, yet pd
segment varies necessarily 1. therefore describe compute ppdi
case, deals realistic form sensorial capabilities (Duarte & Hu,
2004): imperfect, long range sensing.
information regarding sensorial capabilities robots includes two parameters. rst describes quantity sensing ability, i.e., number segments
exceeds current segment robot resides, sensing abilities,
denoted L. second parameter describes quality sensing segments
robot sense. given form vector VS = {v0 , v1 , . . . , vL }, vi
probability robot residing s0 detect penetration occurs segment si .
assume values VS decrease monotonically, i.e., increases, vi decreases
remains same.
Markov chain model, illustrated Figure 11, changes order reect
imperfect sensing along long range sensing. absorbing state sdt exist
addition states scw
0 s0 cc. transition probabilities added 2L
segments: i, j 0 L; L + 1 j d, transition scw
s0 probability vi
cc
sj s0 probability vdj+1 . addition, transition scw
si cc
cw probability (1 p)(1 v
probability (1 p)(1 vi ), scc


dj+1 ), hence
j
j
cw
cw
cc
cc
transition probability si si1 p(1 vi ) sj sj+1 p(1 vdj+1 ).
probability penetration detection segment si result t+1 multiplied
Vi location s0 result vector. Note also here, similar solution described
Section 5.2, since added new absorbing state (which takes extra step reach),
ppdi result product stochastic matrix Vi location s0 + 1
time steps (not t).

910

fiMulti-Robot Adversarial Patrolling

v0<1 v1<1
S0

S1

S2

S3

S4

S0
cc

R1

S1

R2

cc

S1
p(1v0 )

cw

S1

v1



p



4

1p

cw



4

p



3

1p
cc

p

cw

2

1p



cc

3

p



p

1

p(1v1 )



cw

0

(1p)(1v
1 )

(1p)(1v0 )

cc

cc

cc

2



cw



p(1v1 )

1

p(1v0 )



0

v0

v0

cw

cc

cw

S4

S0

S0

dt

0

v1

) 0

0

0

0

0

0

0

0

0

0

0

0 p(1v1 ) v1

0

0

1p p

0

0

0

0

0

0

p

1p 0

0

0

0

0

0

0

0

cc

0

0

0

0

0

1p p

0

0

0

0

cw

0

0

0

p

1p 0

0

0

0

0

0

cc

0

0

0

0

0

0

0

1p

cw

0

0

0

0

0

p

1p 0

0

p(1v0 ) 0

0

0

0

0

0

0 (1p)(1v
0

S3
S4
S4

cc

v1

cc

S4

0

S0

p

cw

S3

0

S3
1

cc

S3

0

(1p)(1v
)
1
0 p(1v

(1p)(1v
0 )0

cw

S2

cw

S2

dt

cc

S2

cc

S2
cw

0

cw

S1

0

p

0

0

0

0
)

v0

cw

S0

0

0

0

0

0

0

0 p(1v0 ) (1p)(1v
0 )0

v0

dt

0

0

0

0

0

0

0

1

0

0

0

Figure 11: illustration L segments shaded robot R, probability detection
necessarily 1. case R facing right, therefore shaded segments right. Markov
chain stochastic matrix changes accordingly.

5.4 Multi-Robot Adversarial Patrolling Along Fences
general work, specically previous sections, assumed robots travel
around closed, circular, area. section discuss patrolling along open polyline,
also known fence patrol. First, discuss patrol dierent perimeter
patrol. describe algorithm determining ppdi fence patrol assuming
robots perfect sensing capabilities, nally provide algorithm
robots imperfect sensing.
5.4.1 Patrolling Along Closed Polyline vs. Open Polyline
following, describe patrolling along open polyline challenging
patrolling cyclic environments (closed polyline).
rst reason lies fact robots required go back forth along
part (or parts) open polyline. result, elapsed time two visits
robot point along line almost twice long elapsed time
circular setting. Figure 12, given two environments: closed polyline (circle) (a)
open polyline (b). Note open polylines b. c. equivalent sense
robot travels one segment per time step, regardless shape
section. lines a. b. total length l number
robots (4). circular environment, takes adversary l/4 time units
penetrate - never able penetrate even robots simply continuously travel
uniform distance them. However, robots travel along open polyline
(b), maximal time duration two visits roboteven best case,
2l/4 2 (Elmaliach, Shiloni, & Kaminka, 2008). Therefore weaker adversary

911

fiAgmon, Kaminka & Kraus

penetration time almost twice long circular fence might still able
penetrate.

a.

b.

c.

Figure 12: Illustration dierence patrolling along line patrolling along circle,
dierent polylines

Another reason added complication analyzing probability penetration
detection open polyline environments lies asymmetric nature traveling
segments along time. circular environment, robots coordinated switch
directions unison, placement robots symmetric time unit. Therefore segments distance robot (with respect direction)
probability penetration detection. Hence order calculate optimal way
movement (in case probability p turning around), sucient consider
one section segments, resulted p equivalent throughout execution.
open polyline environment case. probability penetration detection diers respect current location direction robot. Therefore
algorithm nds ppd segment, needs calculate ppd function
p segment si possible initial location robot inside section.
Therefore results matrix size ppd functions (as opposed vector
functions circular fence).
5.4.2 Determining ppdi Open Polyline (Fence)
Following framework multi-robot patrol along open line proposed Elmaliach
et al. (2008), assume robot assigned patrol back forth along one section
segments. Given framework, would like compute optimal patrol algorithm
robots along section. Similar perimeter patrol case (Section 4.2), describe
system Markov chain (see Figure 13), relative stochastic matrix . Since
robots directionality associated movement, create two states
segment: rst traveling segment clockwise direction, second
traveling counterclockwise direction. probability turning around end
section 1, otherwise robot continue straight probability p,
turn around probability 1 p.
Note main dierence perimeter patrol calculation ppdi lies
number resulting ppdi functions. perimeter patrol, due symmetric nature,
one ppdi function segment current location robot, representing
probability robot arriving time units. Here, however, ppdi depends
current location robot, hence location robot functions
probability penetration detection, therefore total d2 functions (compared
perimeter patrol).
912

fiMulti-Robot Adversarial Patrolling

Denote probability penetration detection segment si given robot
currently segment sj ppdji . order calculate ppdji function 1 i, j d,
create dierent matrices: M1 , . . . , Md . matrix Mi corresponds calculating ppdji ,
i.e., probability penetration detection segment si , calculate ppdji
every current location sj robot (similar done perimeter patrol).
Figure 13 demonstrates matrix M2 ppd2i calculated. gure describes
general case pd 1, i.e., robot might imperfect sensing.
cc

S1

S2

S3

S4

S1

cc

0

cw

S1

cw

1



p



4

cw

3

p



cw

4

p



(1p)(1p
)

1p

cc

p(1pd )

2



cc

3



cc

2

p

1

1



p(1pd )

dt
1p

cc

1

1

cw

cc

cw

dt

S4

S4

1p p

0

0

0

0

0

0

1

0

0

0

0

0

0

0

0

cc

0

0

0

)0

0

0

pd

cw

0 p(1pd )(1p)(1p
) 0

0

0

0

0

pd

cc

0

0

0

0

0

1p p

0

0

cw

0

0

0

p

1p 0

0

0

0

cc

0

0

0

0

0

0

0

1p

cw

0

0

0

0

0

p

1p 0

0

0

0

0

0

0

0

1

S3
S3
S4
S4

pd

cc

S3

S2

cw

cw

S3

S2



cc

S2

S1
pd

cw

S1

dt

p

S2

(1p)(1p
)p(1pd

0

p

Figure 13: Description system Markov chain, along stochastic matrix
calculating ppd segment s2 .

5.4.3 Optimal Algorithm Fence Patrol
case fence patrolling, ppd value depends current location robot.
Consequently, optimal p value characterizing patrol robots dierent
segment si , 1 d. Therefore could dierent optimal p values
respect location orientation robot (2d values). However, sucient
calculate ppd values times (and 2d times)only one direction,
direction reective image rst.
order nd maximin point fence patrolling case, use algorithm
MaximinFence, nds value p minimal ppd maximized, using
Algorithm FindP computes point nding maximal point integral
intersection curves (ppdi ). complete description algorithm shown
Algorithm 3.
Algorithm 3 Procedure MaximinFence(d, t)
1: FindFencePPD(d, t)
2: 1
3:
OpP [i] FindP(d, t) additional given input [i] vector ppd functions.
4: Return OpP

913

fiAgmon, Kaminka & Kraus

6. Summary
paper presents problem multi-robot patrolling strong, full-knowledge, adversarial environments. problem team robots required repeatedly visit
path, basic case perimeter, detect penetrations controlled
adversary. assume robots act strong adversarial model, adversary
full knowledge patrolling robots uses knowledge order penetrate
weakest spot patrol. describe framework basic case multirobot patrol around closed polygon, use framework developing, polynomial
time, optimal patrol algorithm, i.e., algorithm strengthens weakest spot
patrol. framework extended order solve problem also open
fence environment various movement sensing models robots.
paper makes several assumptions allowing computation optimal strategy
patrolling robots. One assumption rst order Markovian strategy
patrolling robots. Although proving disproving optimality using rst order Markovian strategy hard, could interesting examine case higher order Markovian
strategies compare time complexity performance solution discussed
here. Another direction future work involves non-uniform environments,
utility obtained detecting penetrations one hand succeeding penetration
uniform throughout environment. challenges left future work
include handling heterogenous robots non linear environments.

7. Acknowledgments
Preliminary results appeared Proceedings IEEE International Conference
Robotics Automation (2008), Proceedings Tenth Conference Intelligent
Autonomous Systems (2008) Proceedings IJCAI Workshop Quantitative Risk
Analysis Security Applications (QRASA) (2009). research supported part
ISF grant #1357/07 #1685/07, grant #3 6797. thank anonymous
reviewers constructive comments helpful suggestions, always, thanks K.
Ushi.

References
Agmon, N., Kaminka, G. A., & Kraus, S. (2008). Multi-robot fence patrol adversarial
domains. Proceedings Tenth Conference Intelligent Autonomous Systems
(IAS-10), pp. 193201. IOS Press.
Agmon, N., Kraus, S., & Kaminka, G. A. (2008). Multi-robot perimeter patrol adversarial settings. Proceedings IEEE International Conference Robotics
Automation (ICRA).
Agmon, N., Kraus, S., & Kaminka, G. A. (2009). Uncertainties adversarial patrol. Proc.
IJCAI 2009 workshop Quantitative Risk Analysis Security Applications
(QRASA).

914

fiMulti-Robot Adversarial Patrolling

Ahmadi, M., & Stone, P. (2006). multi-robot system continuous area sweeping tasks.
Proceedings IEEE International Conference Robotics Automation
(ICRA).
Almeida, A., Ramalho, G., Santana, H., Tedesco, P., Menezes, T., Corruble, V., & Chevaleyr, Y. (2004). Recent advances multi-agent patrolling. Lecture Notes Computer
Science, 3171, 474483.
Amigoni, F., Gatti, N., & Ippedico, A. (2008). Multiagent technology solutions planning
ambient intelligence. Proceedings Agent Intelligent Technologies (IAT-08).
Basilico, N., Gatti, N., & Amigoni, F. (2009a). Extending algorithms mobile robot
patrolling presence adversaries realistic settings. Proceedings
IEEE/WIC/ACM International Conference Intelligent Agent Technology
(IAT), pp. 565572.
Basilico, N., Gatti, N., & Amigoni, F. (2009b). Leader-follower strategies robotic patrolling environments arbitrary topologies. AAMAS, pp. 5764.
Chevaleyre, Y. (2004). Theoretical analysis multi-agent patrolling problem. Proceedings Agent Intelligent Technologies (IAT-04).
Coppersmith, D., Doyle, P., Raghavan, P., & Snir, M. (1993). Random walks weighted
graphs applications on-line algorithms. Journal ACM, 40 (3).
Duarte, M. F., & Hu, Y. H. (2004). Distance-based decision fusion distributed wireless
sensor network. Telecommunication Systems, 26 (2-4), 339350.
Elmaliach, Y., Agmon, N., & Kaminka, G. A. (2007). Multi-robot area patrol frequency constraints. Proceedings IEEE International Conference Robotics
Automation (ICRA).
Elmaliach, Y., Agmon, N., & Kaminka, G. A. (2009). Multi-robot area patrol frequency constraints. Annals Math Artificial Intelligence, 57 (3-4), 293320.
Elmaliach, Y., Shiloni, A., & Kaminka, G. A. (2008). realistic model frequencybased multi-robot fence patrolling. Proceedings Seventh International Joint
Conference Autonomous Agents Multi-Agent Systems (AAMAS-08).
Gustavson, F. G. (1978). Two fast algorithms sparse matrices: Multiplication
permuted transposition. ACM Trans. Math. Softw., 4, 250269.
Haynes, T., & Sen, S. (1995). Evolving behavioral strategies predators prey. IJCAI95 Workshop Adaptation Learning Multiagent Systems, pp. 3237.
Lynch, N. A. (1996). Distributed Algorithms. Morgan Kaufmann.
Paruchuri, P., Pearce, J. P., Tambe, M., Ordonez, F., & Kraus, S. (2007). ecient
heuristic approach security multiple adversaries. Proceedings
Sixth International Joint Conference Autonomous Agents Multi-Agent Systems
(AAMAS-08).
Paruchuri, P., Tambe, M., Ordonez, F., & Kraus, S. (2007). Security multiagent systems
policy randomization. Proceedings Sixth International Joint Conference
Autonomous Agents Multi-Agent Systems (AAMAS-07).
915

fiAgmon, Kaminka & Kraus

Pita, J., Jain, M., Ordonez, F., Tambe, M., Kraus, S., & Magorii-Cohen, R. (2009). Eective solutions real-world stackelberg games: agents must deal human
uncertainties. Proceedings Eighth International Conference Autonomous
Agents Multiagent Systems (AAMAS-09).
Sak, T., Wainer, J., & Goldenstein, S. K. (2008). Probabilistic multiagent patrolling.
Proc. 19th Brazilian Symposium Artificial Intelligence (SBIA-08), pp. 124
133.
Sharir, M., & Agarwal, P. K. (1996). Davenport-Schinzel sequences geometric
applications. Cambridge University Press.
Shieh, J. S., & Calvert, T. W. (1992). View route planning patrol exploring
robots. Advanced Robotics, 6 (4), 399430.
Sitton, G., Burrus, C., Fox, J., & Treitel, S. (2003). Factoring very-high-degree polynomials.
Signal Processing Magazine, IEEE, 20 (6), 27 42.
Stewart, W. J. (1994). Introduction Numerical Solution Markov Chains. Princeton
University Press.
Vidal, R., Shakernia, O., Kim, H. J., Shim, D. H., & Sastry, S. (2002). Probabilistic pursuitevasion games - theory, implementation, experimental evaluation. Robotics
Automation, IEEE Transactions on, 18 (5), 662669.

916

fiJournal Artificial Intelligence Research 42 (2011) 765-813

Submitted 08/11; published 12/11

Theoretical Practical Foundations Large-Scale
Agent-Based Micro-Storage Smart Grid
Perukrishnen Vytelingum
Thomas D. Voice
Sarvapali D. Ramchurn
Alex Rogers
Nicholas R. Jennings

pv@ecs.soton.ac.uk
tdv@ecs.soton.ac.uk
sdr@ecs.soton.ac.uk
acr@ecs.soton.ac.uk
nrj@ecs.soton.ac.uk

Agents, Interaction Complexity Group
School Electronics Computer Science
University Southampton
Southampton, SO17 1BJ, UK.

Abstract
paper, present novel decentralised management technique allows electricity micro-storage devices, deployed within individual homes part smart electricity
grid, converge profitable efficient behaviours. Specifically, propose use
software agents, residing users smart meters, automate optimise charging
cycle micro-storage devices home minimise costs, present study
theoretical underpinnings implications practical solution, using software agents micro-storage management. First, formalising strategic
choice agent makes deciding charge battery, develop game-theoretic
framework within analyse competitive equilibria electricity grid populated agents hence predict best consumption profile population
given battery properties individual load profiles. framework also allows us
compute theoretical bounds amount storage adopted population. Second, analyse practical implications micro-storage deployments grid,
present novel algorithm agent use optimise battery storage profile
order minimise owners costs. algorithm uses learning strategy allows
adapt price electricity changes real-time, show adoption
strategies results system converging theoretical equilibria. Finally,
empirically evaluate adoption micro-storage management technique within
complex setting, based UK electricity market, agents may widely varying
load profiles, battery types, learning rates. case, approach yields savings
14% energy cost average consumer using storage device capacity
less 4.5 kWh 7% reduction carbon emissions resulting electricity
generation (with domestic consumers adopting micro-storage and, commercial
industrial consumers changing demand). Moreover, corroborating theoretical
bound, equilibrium shown exist 48% households would wish
storage devices social welfare would also improved (yielding overall
annual savings nearly 1.5B).

1. Introduction
vision intelligent electricity delivery network, commonly called smart grid,
advocated one main solutions ensuring sustainable energy provision
c
!2011
AI Access Foundation. rights reserved.

fiVytelingum, Voice, Ramchurn, Rogers & Jennings

(US Department Energy, 2003; Galvin & Yeager, 2008; DECC, 2009). grids aim
reduce inefficiencies energy usage, minimise carbon emissions reduce costs generate
electricity. key element vision consumers able respond
current condition grid, shifting reducing use electricity, twoway communication channel actors system (i.e., suppliers,
consumers, grid operators). doing, expected peaks demand
reduced, which, turn, would reduce need expensive carbon-intensive
peaking plants (i.e., spinning reserve) rely fossil fuels.
Two key technical enablers smart grid increased degrees automation
ability store energy. former case, consumers need able delegate
complex time-consuming reasoning shifting reducing demand, subject
individual preference, software agents act behalf (Ramchurn,
Vytelingum, Rogers, & Jennings, 2011c). end, smart meters developed
provide consumers agents real-time information homes consumption
state grid, provide suppliers grid operators consumption
data homes. Moreover, smart meter roll-outs mandated number
countries, including France (by 2016), Spain (by 2018) UK (by 2020).
information feeds, consumers able improve management energy
(e.g., switching devices need rescheduling power-hungry devices
times). latter case, agents use information decide store electricity
times overall demand grid low (and generally cheaper) re-use
electricity grid operating close limits (i.e., generators operating
near capacity transmission lines close overload electricity generally
expensive). Furthermore, storage devices also used compensate variability
many forms renewable electricity generation (e.g., wind, wave, solar) likely
increasingly prominent component future grid (Bathurst & Strbac, 2003).
date, research storage technologies focused designing new low-cost
large-scale storage devices (with capacities order 10-100MWh) able
efficiently store electricity long periods time allow sufficient number charging/discharging cycles without significant degradation performance (Bathurst & Strbac,
2003). However, development large variety micro-storage devices (i.e.,
capacities order kWh) installed homes1 vehicles2 , future
large numbers individual consumers store small amounts electricity order
accommodate peaks demand variability supply soon possible.
are, however, number potential challenges setting. First, consumers decide
charge batteries time, price low, significant peak
demand could well ensue. would, turn, result higher electricity generation costs
greater carbon emissions could overload system already operating close
maximum capacity (resulting brown-out or, worst case, black-out). Indeed, unintended population-wide synchronisation already seen real-world
1. See batteries recently developed GS Yuasa (http://lithiumenergy.jp/en/products/) Power Yiile
(http://eliiypower.co.jp/english/lithium-ion/).
2. Vehicle grid (V2G) technologies enable energy stored batteries electric vehicles (EVs)
(e.g., Mini-E Nissan Leaf) plug-in hybrid electric vehicles (PHEVs) (e.g., Toyota Plug-in Prius
Chevrolet Volt) (Sovacool & Hirsh, 2009; Lund & Kempton, 2008).

766

fiTheoretical Practical Foundations Agent-Based Micro-Storage

demand-response trials consumers manually react critical pricing periods (Hammerstrom et al., 2008). Second, consumers simply charge batteries ensure
sufficient energy cover whole demand across day, may end
paying need to. may cheaper use grid-supplied
electricity certain times, rather energy already stored battery. Finally,
homes system start using storage devices manage reduce peak demand
(by optimising battery charging usage costs), electricity prices may become lower
price stored electricity (including cost battery), thus voiding need
micro-storage breaking market devices.
Addressing aforementioned issues formulation conventional closedform solutions (see Section 2 details) challenged fact system
composed large numbers distinct stakeholders (typically millions consumers
tens market makers network managers) operating completely decentralised fashion individually act satisfy particular objectives constraints
(to supply use energy) may conflict (e.g., network managers aim minimise
peaks demand consumers aim minimise costs use devices
convenient time day). background, agent-based approach
used framework analyse properties systems also implementation technology (Exarchakos, Leach, & Exarchakos, 2009; Houwing, Negenborn,
Heijnen, Schutter, & Hellendoorn, 2007; van Dam, Houwing, & Bouwmans, 2008; Rogers &
Jennings, 2010). particular, game theory used determine properties
system multiple self-interested parties interact software agents installed
smart meters optimise usage storage profile house using information
variety sources (e.g., weather data predict heating needs costs price plan
data suppliers). Now, existing approaches applying intelligent agents
study individual homes could optimise way store energy storage devices could coordinate renewable energy generation facilities maximise energy used
sources (see Section 2 details). However, doing, ignore
individual selfish preferences consumer model well real impact
agents learning adapt constraints impose system.
remedy this, crucial devise approach focuses system dynamics
agents system given freedom buy electricity whenever see fit.
paper, take approach provide analytical
practical solution decentralised control micro-storage devices grid. Specifically, develop game-theoretic framework modelling storage devices large-scale
systems device controlled self-interested agent aims maximise
monetary profits real-time price electricity provided grid. Using
framework, certain reasonable assumptions, able predict equilibria
system given agent behaves rationally (i.e., always adopts storage profile
minimises costs) reacts price signal. Given this, go devise
intelligent agent-based storage strategies learn best storage profile given market prices result aggregate storage consumption profile
agents system. Crucially, show agents using strategies achieve
predicted equilibria and, building upon this, simulate large populations agents
order predict system behaviour various conditions.
767

fiVytelingum, Voice, Ramchurn, Rogers & Jennings

somewhat detail, work advances state art following ways:
1. provide novel analytical game-theoretic framework captures synchronous
behaviours consumers micro-storage devices within smart grid. use
study electricity storage strategies agents might adopt smart grid
real-time pricing. Given typical electricity usage profiles consumers,
able compute competitive equilibria describe individual
agent going charge device, use stored electricity, use electricity
grid. use analytical solution benchmark decentralised solution.
2. provide theoretical bound storage capacity needed
population, well bound portion population adopt storage.
3. provide new micro-storage strategies enable agents learn best storage
profile adopt, even taking account probable heterogeneity
micro-storage devices adopted consumers across grid (e.g., devices
vary capacity fast charged discharged). practical
strategies shown converge competitive equilibria predicted
analytical framework come system-wide benefits include reduced
carbon emissions, well cost savings.
4. show agents, learnt best storage profile, also learn buy
profitable storage capacity. Given this, using evolutionary game theoretic
analysis, able predict portion population would actually
acquire storage capacity maximise savings. show
entire population. Rather, half them, confirming theoretical
bounds analytical framework predicts.
short, first attempt modelling, predicting equilibria building intelligent strategies problem electricity storage large scale. approach also
justifies provides basis implementation real-time electricity pricing
domestic electricity distribution.
rest paper structured follows. Section 2, discuss related work
area electricity storage electricity markets. Section 3 discusses key features
markets lays general assumptions upon build framework.
Section 4 presents game-theoretic framework shows competitive equilibria
system computed and, based equilibria, determines many users
likely adopt micro-storage. Building this, Section 5 describes dynamics
market agents given ability learn best storage profile Section 6
empirically studies system simulations. Then, Section 7 expands costbenefit analysis storage system given heterogenous population consumers
different usage profiles. Finally, Section 8 concludes.

2. Background
section, first review current storage technologies illustrate micro-storage
evolved date likely potent energy management technology
768

fiTheoretical Practical Foundations Agent-Based Micro-Storage

future. follow discussion existing approaches power systems literature
using storage, including agent-based approaches proposed manage
grid general micro-storage particular. Furthermore, motivate need
real-time pricing mechanisms grid order enable responsive demand
considering response consumers fixed prices time-of-use tariffs.
2.1 Energy Storage Technologies
large scale storage electricity within electricity grid new concept. Many
countries operate pumped-storage power plants store electricity pumping water
high reservoir prices low, release water use generate
electricity prices high supply short. example, Dinorwig Power Station
UK store approximately 10GWh electricity, supply stored energy
six hours, providing 1.8GW power (Williams, 1984).
However, increased need storage capacity electricity grids increasingly seek
incorporate intermittent renewable sources, wind generation solar power, coupled
high capital costs pumped storage plants limited number suitable sites construction, mean much recent research focused alternative
smaller storage solutions typically store 10-100MWh electricity. Examples technologies already demonstrated commercially include use underground
caverns store electricity compressing releasing air (Swider, 2007) storage
large chemical flow batteries (Shibata & Sato, 1999).
recently, attention turned micro-storage3 20kWh electricity
might installed within homes part smart grid roll-out. interest
largely driven rapidly decreasing cost efficient batteries, lithium-ion
cells nickel-zinc alternative, developed use within electric vehicles
(den Bossche, Vergels, Mierlo, Matheys, & Autenboer, 2006). Indeed, energy storage
capacity required viable electric vehicle close daily consumption home
(e.g., Chevrolet Volt battery capacity 16 kWh Nissan Leaf store
24 kWh). Thus, possible envisage micro-storage devices
widely used short medium term, either dedicated home storage batteries,
additional capability electric vehicles.
2.2 Agent-Based Systems Grid
use software agents, residing smart meters, first envisaged Schweppe,
Tabors, Kirtley, Outhred, Pickel, Cox (1980) proposed mechanisms agents
manage use electricity within single home buy electricity real-time
behalf owner. Since then, number agent-based approaches developed
multiple autonomous agents represent interests different actors grid.
example, Ygge, Akkermans, Andersson, Krejic, Boertjes (1999) initiated work
abstracting electricity markets multi-commodity markets showed agents trad3. Note average cost micro-storage battery today varies around 300 1000
per kWh average start-up cost 200. Note prices indicative given
innovative nature area investment electric vehicle battery technology, cost
micro-storage gradually decreasing (see http://www.pikeresearch.com).

769

fiVytelingum, Voice, Ramchurn, Rogers & Jennings

ing energy different times day, could generate efficient allocations . Moreover,
Jennings, Corera, Laresgoiti, Mamdani, Perriolat, Skarek, Varga (1996) developed coordination mechanisms different actors grid manage allocation transmission
capacity and, recently, Sun Tesfatsion (2007) Li Tesfatsion (2009) developed agent-based electricity market simulations incorporate transmission constraints
different types buyers sellers grid. Kok Venekamp (2010) take similar approach implement agent-based architecture run electricity market
individual actors represent either generators devices home. Note, however,
none approaches consider daily consumption profile consumers,
agent might optimise consumption storage electricity maximise owners
benefit. believe crucial agents profitable users,
specific needs lifestyle, order commercially viable. Specifically,
agents able provide personalised home energy management
deployed real world.
context, note early work Daryanian, Bohn, Tabors (1989)
illustrated individual agents could optimise, iterative algorithms, load
profile house using electricity storage device. approach was, however, limited
considering basic battery properties consider wider issues grid
level adoption batteries population optimum storage capacity
required maximum savings. recently, Houwing et al. (2007) provided algorithms
agents optimise storage using small domestic combined heat power (CHP) plants,
ignored populations agents would impact grid. hand,
Exarchakos et al. (2009) van Dam et al. (2008) studied application storage
devices wider scale. showed using demand-side management techniques,
storage profile number homes controlled centrally, increase savings
made system. Unfortunately, centralised approach automatically introduces
single point failure system take account individual preferences
user buy, use, turn storage device. hand, Ramchurn,
Vytelingum, Rogers, Jennings (2011b) consider supplier retailing large number
agents continuously optimise storage, assume effect
large-scale optimisation influence wholesale price market usually
case considering large enough proportion population. Thus,
paper, take market-based approach similar Ygge et al. (1999) Ygge
Akkermans (1999), informationally decentralised (i.e., centre complete
perfect information required), therefore robust, agent buys electricity
real-time markets individually controls storage profile associated home,
based real-time prices reflect demand (and supply) market.
2.3 Electricity Pricing Mechanisms
approaches assume existence control signal dictates
home must store best use stored electricity, thereby reducing
load grid peak times (see Figure 1 example average UK demand
result peaks) making saving reductions come monetary rewards. end, Schweppe et al. (1980) proposed use real-time pricing (RTP)
770

fiTheoretical Practical Foundations Agent-Based Micro-Storage

spot pricing electricity better way manage demand conditions grid
accurately reflected price (as set single utility electricity market).
Thus, contrary pricing signals traditionally used grid, either
based fixed price time-of-use (TOU) price, whereby premium charged
times anticipated peak demand, real-time price reflects current continuously
changing balance supply capacity demand and, even cases, congestion
network (e.g., locational marginal pricing approaches pricing electricity different
points grid see Harris, 2005). Unfortunately, Schweppe et al.s solution never
fully implemented large scale time proposed. number
reasons. First, properties solution mainly proven analytically,
general assumption agents behave similar fashion attempt
model strategic choices agents may make charging batteries (e.g., always
charging times predict cheaper always using battery
predict prices higher charging battery early whole days consumption
avoid price peaks later). Instead, paper, develop game-theoretic framework
fully captures agents strategic behaviour within context smart grid
complement approach simulations order evaluate performance
system highly heterogeneous population agents. Second, Schweppe et al.s design
also came problems associated high communication costs lack
autonomous storage management technology. However, recent advances computational
power make deployment autonomous agents entirely feasible, new information communication technologies wireless broadband internet home energy
management systems (e.g., AlertMe4 Intels Home energy dashboard5 ) mean realtime pricing domestic sector looks closer realised. Moreover, financial
commitment countries UK (8.6M invested smart metering infrastructure
see DECC, 2009) US (with 57.9 million smart meters planned installation6 )
implementation smart metering infrastructure, provides unprecedented support
implementation RTP.
Real-world trials, GridWise alliance US (Hammerstrom et al.,
2008) Energy Demand Research Project UK (Smith, 2010), theoretical
work Ramchurn, Vytelingum, Rogers, Jennings (2011a) show
accurate RTP signals (i.e., representing real costs opposed TOU pricing
scheme) allow consumers reduce peak demand (and duration peaks)
reacting frequently accurate 30-min-tariff pricing model (rather
peak off-peak prices TOU). reducing peaks, consumers
RTP make significant savings compared TOU pricing. However,
generally case (short-duration) peaks exist RTP Fixed-Pricing
model (see Ramchurn et al., 2011, two long-duration peaks exist morning
evening), requiring usage expensive peaking plants short periods.
agents predict (based previous days) low price next day
4. http://www.alertme.com/.
5. http://edc.intel.com/Applications/Energy-Solutions/Home-Energy-Management/.
6. http://www.pikeresearch.com/newsroom/
57-9-million-smart-meters-currently-planned-for-installation-in-the-united-states

771

fiVytelingum, Voice, Ramchurn, Rogers & Jennings

0.6

Power (kW)

0.5

Morning Peak
Evening Peak

0.4
0.3
0.2
0.1
0:00 3:00

6:00

9:00

12:00 15:00 18:00 21:00 24:00
Time Day

Figure 1: Average load profile (weekday summer) UK half-hourly periods based
fixed pricing model.

certain time, turn devices, results peak demand
time. mechanism rolled large scale, reactive behaviours
cause unpredictable significant peaks (compared two predictable ones TOU)
demand prices, which, turn, result higher costs individuals greater stress
grid resources (transmission lines reaching thermal limit generators reaching
capacity).
Thus, properly managed, storage systems unprofitable consumers
adversely impact whole system (Holland, 2009; Williams & Wright, 1991; Bathurst &
Strbac, 2003). Hence, setting consider, important know whether microstorage individually beneficial strategies maximise consumers savings.
also important understand system-wide effects strategies; particular,
quantifying limits usefulness small scale storage grid efficiency point
view determining different types storage (with different costs efficiencies)
integrated system. key open questions addressed
paper (see Sections 4 5 respectively).

3. Model Description
already noted, paper seek analyse behaviour impact microstorage devices large scale multi-agent systems point view. is, consider
situation large numbers autonomous agents control energy storage
home, interact electricity suppliers within market, aim minimising
772

fiTheoretical Practical Foundations Agent-Based Micro-Storage

costs individual owners. setup allows us make number modelling
assumptions, detail section. analysis considers fixed time intervals
consisting single days, separated = 48 settlement periods half hour.
day, agents consume electricity bought suppliers electricity market.
market operates time interval day, variations demand
time met. agents autonomously control charging discharging behaviour
storage device order maximise users profit. describe process
thoroughly Section 3.1. analysis, market modelled abstractly,
following macro-model give details Section 3.2. order measure
impact behaviour energy storage agents wider context, employ number
metrics grid efficiency described explained Section 3.3. table
notation definitions used throughout paper, see Table 1.
3.1 Agents
consider set N consumers, A, define self-interested agents always
aim minimise individual costs. agent load profile7 !ai =
{1, . . . , }, !ai amount electricity required agent for!time interval

day. aggregate load profile system given
aA !i = !i .
consider load profile fixed different days (although practice
seasonal variations demand, high degree consistency day day).
agent may also storage available it, capacity , efficiency
running costs . Here, cost represents ongoing storage costs (for example,
battery devices expend energy heating use lose efficiency
depletion chemicals used them). incorporate fixed capital
investment stage, costs fixed, running costs
effect storage profile profitable. However, fixed capital
investments important users decide whether purchase battery,
include cost-benefit analysis Section 7. storage efficiency running
cost modelled c amount energy stored, c may
discharged storage cost c.
order minimise costs, agent attempt strategise storage profile,

bi I, I, bai = cai dai , cai = (bai )+ charging profile
dai = (bai ) , discharging profile. Here, throughout paper, use notation
()+ denote positive part, is, = (x)+ means = x x > 0, = 0 otherwise.
Likewise use (x) denote (x)+ . definitions implicitly assume user
charge discharge storage device single time interval. However,
model, prices fixed time interval, discount behaviour
never profitable. agent a, feasible storage profile bai must
satisfy Da bai C , Da maximum discharging rate storage device,
7. assume consumers load inelastic and, thus, insensitive price changes. reality,
would expect consumers load shows slight elasticity, i.e., consumer reduce demand
price increases likewise increase demand price decreases. However, demand elasticity
domestic consumers generally small, believe results presented paper still provide
good guide behaviour real markets.

773

fiVytelingum, Voice, Ramchurn, Rogers & Jennings

Notation
N



bai
cai
dai
!ai
qia



ca0
Ca
Da
Oia
bi
ci
di
!i
qi



C

Oi

pi
p+
p
(), ()
()+
()
LU
HU
r
rU
uU (, , )

Definition
Number agents system
Set agents system
Number time intervals day
Set time intervals
Net charge/discharge storage device agent time period
Amount charged agent time period
Amount discharged agent time period
Electricity used agent time period
Electricity purchased agent time period
Efficiency storage device agent
Capacity storage device agent
Storage cost agent
Energy agent stored start day
Maximum (per interval) charge agent
Maximum (per interval) discharge agent
Maximum usable discharge agent
Net charge/discharge agents
Amount charged agents
Amount discharged agents
Total consumer load agents
Total electricity purchased agents
Total storage capacity population
Homogeneous storage device efficiency
Homogeneous storage costs
Maximum total per interval charge
Maximum total per interval discharge
Maximum total useful discharge
Supply function wholesale market
Price electricity
Charging price point
Discharging price point
Equilibrium price functions time interval (see Definition 1)
Positive part
Negative part
Low-end energy users
High-end energy users
Agents strategy adopt storage
Probability agent type U {LU, HU } adopting strategy r
Payoff agent type U {LU, HU }
Table 1: Notation definitions.

774

fiTheoretical Practical Foundations Agent-Based Micro-Storage

UK Wholesale Balancing Market Buy Price (GBP/MWh)
250
Price Demand
Movingaverage

Unit Price (GBP/MWh)

200

150

100

50

0
2

2.5

3
3.5
Total Demand (MW)

4

4.5
4

x 10

Figure 2: Half-hourly UK wholesale real-time buy prices (in balancing market) plotted
total demand August September 2009 illustrating correlation
price demand. dotted line represents average points.

C , maximum charging rate. Since attempting model effect
widespread adoption micro-storage devices, assume !ai , C , Da small
comparison !i (since considering electricity grid
large number
!consisting
, net storage
consumers). denote total
storage
capacity


=

aA
!
profile bi bi = aA bai . use qia = bai + !ai ,
denote net quantity electricity purchased i, use qi = bi + !i
denote net quantity electricity purchased users
aggregate
! interval i. The!
maximum charging discharging rates defined C = aA C = aA Da .
also define maximum usable storage output Oi maximum amount stored
electricity whole population agents able discharge make use
time interval i. agents !
use stored electricity satisfy energy needs,
Oi = aA min(Da , !ai ) I, agent reason
discharge energy current load. situation mainly focus
paper. However, analysis present also applied case agents
sell stored energy back grid, using feed-in tariff. assume agents
sell stored energy current grid price, model remains same, except
values Oi set equal D, I. satisfy load profile
energy charging needs, agent must purchase electricity available market,
describe next subsection.
775

fiVytelingum, Voice, Ramchurn, Rogers & Jennings

3.2 Macro-Model Electricity Market
order widespread home energy storage effectively help reduce peak loads improve overall efficiency electricity market, must incentive users
charge storage devices demand low (or renewable energy generators
running cheaply) discharge demand high (or expensive peaking
plants used). discussed Section 2.3, TOU RTP pricing plans aim incentivise users optimise demand shifting low demand periods. particular,
sending date pricing information, RTP allows electricity suppliers provide consumers prices accurately reflect current levels demand costs generating
electricity. Hence, analysis, focus use RTP, note competition suppliers provide RTP pricing schemes allow future consumers
buy electricity close current market price (Schweppe, 1988). Although use
RTP makes settlement process complex case Fixed TOU pricing
(as independent reaction agents), requires interactive
intelligent energy management home, recent advances smart metering technology
meant RTP become plausible attractive possibility future smart
electricity grids (as discussed Section 2.2). Accordingly, assume agents buy electricity
RTP scheme price electricity accurately represents market price
power particular settlement period.
end, consider macro-model electricity market abstracts
actual market mechanism trading determines real-time price electricity.
approach modelling supply side transmission system common
power system economics literature significantly affect general trends
observed analysing demand side (Kirschen & Strbac, 2004; Schweppe, 1988).
model based observation aggregate demand electricity increases,
unit price electricity also increase, since costly means generation
must used satisfy additional demand. example, Figure 2 shows half-hour
UK real-time wholesale buy prices (in balancing market) August September
2009 plotted aggregate demand.8 numerous anomalies due power
station outages cause short term price increases, clear large range
demand, increasing trend relationship unit cost electricity
total aggregate demand, prices rising rapidly high demand.
analysis effect price fluctuations system micro-storage left
future work.
several countries around world, including UK US, electricity traded
wholesale residential, commercial industrial purposes forward markets (up
several months advance) balancing market (in real-time). Within setup,
role suppliers buy electricity generators wholesale market (e.g.,
National Grid runs wholesale market UK PJM runs one east
coast US) sell retail consumers. UK, retail market dominated
six large suppliers retail 26 million residential consumers (representing around
30% UK energy demand). Now, work, focus exclusively domestic
consumers since constitute significant portion overall energy consumption
8. data available www.bmreports.com.

776

fiTheoretical Practical Foundations Agent-Based Micro-Storage

UK. Yet, approach could readily extended commercial
industrial consumers. line main aim show deployment
micro-storage within large heterogeneous population significant benefits. Thus,
demonstrating flatten demand heterogeneous domestic population
implies similar behaviour achievable across remaining 70%
population (with even larger benefits). end, model domestic consumer
market pricing function reflects expected cost supplier (retailing
electricity consumers) would pay wholesale market. several
advantages supplier aggregate demand fewer peaks domestic
consumers. Specifically, suppliers exposure peak (and typically volatile) wholesale
prices reduced benefit long-term baseload (i.e., long-term flat load)
forward contracts (Voice, Vytelingum, Ramchurn, Rogers, & Jennings, 2011). Furthermore,
peak load transmission distribution networks may curtailed, reducing need
infrastructure reinforcements, significantly, expensive peaking plant capacity
(which may used hours day) also downsized.
background, model, real-time price electricity per kWh
(/kWh) specified price function s(q) = 0.04 + 0.20(q/0.6N ) qkWh
total energy required N = |A| consumers half-hour time slot set
4 model typical trend (i.e., monotonically rapidly increasing) wholesale
demand prices suppliers purchase electricity. Note long
modelled demand curve monotonically increasing reflect increasing unit cost
electricity demand (which incentivises demand response), actual demand curve
critical work.
Given function, retail price depends total amount electricity consumed
agents, !i , net discharging charging agents storage devices, bi ,
total amount electricity bought suppliers time interval qi = !i + bi ,
market price given pi = s(qi ). Hence, agent pays pi (!ai + bai )
total cost agents pi qi .
3.3 Grid Performance Metrics
key aim paper study effect storage overall system whether
global performance system improves agents adopt it. detail,
measure performance considering following standard metrics electricity market
(Harris, 2005):
load factor (LF) average power divided peak power, period
time:
!
iI qi
LF =
|I| maxiI qi

selected period time (e.g., day). Ideally, LF
maximum 1 means aggregate load profile completely flat.
LF < 1 suggests variations demand daily period. Hence, storage
strategies effective, LF converge 1 agents able utilise
storage shift consumption peak time periods low demand. LF
measures aggregate load profile indicate individual
777

fiVytelingum, Voice, Ramchurn, Rogers & Jennings

agents contribute peaks system (e.g., agents consuming
time agents cause large peaks). better capture behaviours
rely following measure, diversity factor.
diversity factor (DF) ratio sum individual maximum demands
various consumers system maximum demand complete system:
!
maxiI qia
DF = aA
maxiI qi
DF always greater equal 1 higher value, less correlated
peak demands consumers are. Less correlated peaks result flat aggregate
profile (as peaks interposed), high DF implies users well diversified
cause large aggregate peaks (by consuming time)
system. hand, low DF indicates agents correlated
load profiles could result peaks demand. Now, LF describes
aggregate demand, DF describes individual demands compare
and, thus, DF give insights LF achieved (i.e.,
individual profiles contributing aggregate profiles). example,
high LF, high DF suggests well diversified profiles individual consumer
peaks spread across day low DF suggests flatter individual profiles.
DF generally useful designing decentralised control mechanisms
identifies individual (rather aggregate) behaviours agents and,
thus, potentially provides insights individual behaviour agent
modified.
grid carbon intensity amount carbon dioxide emitted order deliver
one unit electricity consumer. expressed grams CO2 per kWh and,
ideally low possible (in order minimise greenhouse gas emission).
carbon intensity UK grid half-hourly periods August September
2009 shown Figure 3. market price electricity,
clear correlation carbon intensity electricity grid,
total demand grid. UK, due use coal-fired power
stations satisfy increasing demand, thus, well reducing total cost
electricity consumer, expect use micro-storage reduce total
carbon emissions reducing overall carbon intensity grid.
note pricing model depends aggregate demand domestic
sector. Thus, report load factor diversity factor results,
domestic sector. However, reality, domestic sector one contributor
total electricity demand; UK, represents, previously mentioned, approximately 30% total demand, remaining 70% commercial industrial
consumption remains unchanged within model. demonstrate potential
domestic micro-storage reduce UK carbon emissions electricity generation,
present results regarding carbon emissions reductions, describe reduction
carbon emissions (as result micro-storage domestic sector) percentage
778

fiTheoretical Practical Foundations Agent-Based Micro-Storage

UK Grid Carbon Intensity (gCO /kWh)
2

550

450

2

Carbon Intensity (gCO /kWh)

500

Carbon Content
BestFit (linear trend)

400
350
300
250
200
2

2.5

3
3.5
Total Demand (MW)

4

4.5
4

x 10

Figure 3: Half-hour UK grid carbon intensity plotted total demand August
September 2009 illustrating correlation carbon intensity demand.

current carbon emission sources (i.e., domestic, commercial industrial), assuming micro-storage domestic sector change remaining 70% commercial
industrial daily profiles.

4. Game-Theoretic Analysis Micro-Storage
set stage application micro-storage smart grid, explore
theoretical underpinnings system. end, apply game-theoretic
framework models given characterise resulting equilibria. equilibria important represent stable states system
agent unable increase profitability unilaterally changing strategy. particular, expect selfish agents maintain battery usage strategies maximally
profitable them, thus, states predict arise naturally
market prices stabilise. address question endow individual agents
intelligence reach stable equilibrium maximising owners savings later
paper (see Section 5). now, ensure tractability assume agents
homogeneous efficiency running costs, = =
. assumptions allow us obtain closed-formed solutions computing
equilibria system, abstract real-world systems agents typically heterogeneous. However, one key achievements work, Section 6
show assumptions result significant loss generality that, fact,
779

fiVytelingum, Voice, Ramchurn, Rogers & Jennings

theoretical results closely approximate empirical results obtain complex
environments heterogeneous agents.
Formally, game consider players coincide agents, A,
game describes outcome single 24 hour interval. pay-off agent receives
!
equal minus total costs experiences purchasing electricity day,
iI (pi (!ai + bai ) + cai ). strategy space available agent set feasible
storage profiles, bai I. approximate space feasible aggregate storage profiles
set aggregate profiles lie charging discharging limits
total amount energy charged less equal total storage capacity
available agents exactly equal total amount energy discharged divided
efficiency. formally
set
! consider
!
!aggregate storage profiles bi
Oi bi C,
iI di =
iI ci
iI ci , storage
capacity (see Table 1 notation).
Requiring total amount charged less total storage capacity
stricter constraint simply requiring capacity never exceeded time.
However, reasonable model storage capacity limitations day-long time period
(given daily-cyclic nature demand), demand typically goes single
cycle low high low, implying storage devices would go corresponding cycle charging discharging charging. Indeed, practice, find
equilibria simulations, indeed single charging discharging cycle
prices cycle low high. Furthermore, equilibria reached experiments
closely agree equilibria predicted section (see Subsection 6.3).
also making approximation considering aggregate profiles
satisfy aggregate capacity, charging discharging constraints. Even aggregate
constraints satisfied, necessarily mean exist feasible strategies
individual agents give aggregate profile. give example, would
poor model agents values C , Da !ai single
agent possession majority storage capacity. considering
set aggregate profiles therefore assuming storage capacity distributed
evenly amongst agents, roughly proportion loads charging discharging
capacities. unreasonable given context situation modelling.
proceed characterise competitive equilibria game.
4.1 Competitive Equilibria Global Optimisers
set competitive equilibria system corresponds set Nash equilibria
assumption individual negligible market power. is, assume
agents electricity consumption negligible effect price electricity,
seek situations agent incentive change storage profile
reduce cost. choose analyse equilibria capture steady state
real system consisting domestic users owning micro-storage (optimised agent)
users consumption minimal effect electricity prices (in UK,
user represents one home 26 million).
Now, suppose agents chosen strategy profiles, let us consider effect
feasible change strategy one agent. is, agent considers change
780

fiTheoretical Practical Foundations Agent-Based Micro-Storage

I, changing cai cai + cai dai dai + dai , giving net change bai
bai + bai bai = cai dai . change payoff agent would be:
"#
$
#
$
s(qi ) s(qi + bai ) (!ai + bai ) + s(qi + bai )bai + cai .
(1)
iI

noted previous section, since examining widespread micro-storage,
assume A, !ai , C , Da small comparison !i
qi . equivalent assuming agent negligible market power. Thus, s(qi +bai )
close s(qi ) first term small. So, change
payoff agent would approximately:
"#
$
s(qi )bai + cai .
(2)
iI

equal dot product gradient times vector changes (c, d),
following function, f (), 9 define as,
%
#
$ "# qi
$
s(x)dx + ci .
f {ci , di }aA,iI =
(3)
iI

0

Thus, condition agent incentive change strategy approximately equivalent saying A, directional derivative f () positive
direction change leads feasible storage profile. equivalent saying
vector storage profiles local minimum f () set feasible storage profiles. Since s() increasing, f () must convex, since feasible domain
closed convex, local minimums also global minimums domain. Thus,
deterministic competitive equilibria game correspond vectors strategy profiles
minimise f () set feasible strategy profiles.
approximations typically well suited (i.e., result significant loss
accuracy) large systems consider (with millions agents)
effect greatly reducing search competitive equilibrium complex multiplayer game relatively straightforward constrained optimisation problem
minimising f (). proceed find solutions optimisation problem.
4.2 Characterisation Competitive Equilibria
characterise aggregate storage profiles form optimal solutions
constrained optimisation problem given above. characterisation given main
result, Theorem 1. However, theorem may seem somewhat unintuitive first.
think equilibrium characterised two prices, p+ p (defined below).
equilibrium strategy always charge much possible energy cheap,
right point price reaches p+ , always discharge energy prices
high, right fall p . Thus, interval i, equilibrium, pi < p+ ,
agents must maximum charge rates pi > p , agents must
9. real world counterpart f (), little intuition definition necessarily
equal total revenue, example. simply tool help characterise global equilibrium.

781

fiVytelingum, Voice, Ramchurn, Rogers & Jennings

maximum output rates. If, equilibrium, pi lies strictly p+ p ,
energy expensive worth charging, cheap make discharging
profitable, storage activity occurs time interval.
order formally state prove result, must begin definition:
Definition 1. storage system described, interval i, let us define
functions () () be,
$
#
(p) = min C, (s1 (p) !i )+ ,
#
$
(p) = min Oi , (s1 (p) !i ) .
is, (p) amount electricity would charged interval
i, discharging, order resulting price close p possible.
Similarly, (p) amount electricity would discharged interval
i, charging, order resulting price close p possible.
Oi maximum useful discharge C, maximum daily total charge.
define discharging price point, p , maximum union
solutions to:
"
"
(p ) =
(p ),
iI

solutions to:

iI

"

(p ) = ,

iI

exist. maximum exists s() continuous strictly increasing.
p well defined, also define charging price point, p+ , p
"
(p ) < ,
iI

equal minimal solution to:
"

(p+ ) = ,

iI

exist, otherwise.
!

+
+


well defined
iI (p ) =
!Note, +p
! p
! either+p = p
iI (p ), iI (p ) = ,
(p !
) = . latter case, since p+
!and iI
strictly greater solutions iI (p ) = iI (p ), since ()
functions increasing () functions decreasing, must that:
"
"
"

(p+ ) = =
(p ) <
(p ),
iI

iI

iI

p+ < p . intuitive understanding equilibrium given above,
means that, p p+ chosen total amount discharged equal
total amount charged times . Furthermore, restriction, either p p+
chosen maximise total amount charged else total amount charged equal
.
782

fiTheoretical Practical Foundations Agent-Based Micro-Storage

!
!
Lemma 1. always exists solution iI (p) = iI
!i (p). Furthermore,
+ = p unless
p

p
p maximal solution p =
iI (p) > ,
!


+
case, p maximal solution iI (p ) = , p minimal solution
!
+
iI (p ) = .

Proof. s() continuous, strictly increasing function, !i > 0 inside
range time interval i. Thus, p sufficiently small,
s1 (p) < !i hence (p) strictly positive and, since p < p,
(p ) zero. Likewise p sufficiently large
s1 (p) > !i (p) strictly positive ((p + )/) zero. Since
functions ()
!
! decreasing () increasing i, conclude

(p)



iI
iI (p ) continuous decreasing function p negative
sufficiently small p and!positive sufficiently
large p. implies existence
!
solution p iI (p) = iI (p ). Let p maximal solution
this.
!
iI !
(p) then, since () functions decreasing,
$ > p
$ = . Thus, p = p and, so, p+ = p = p .
p
iI (p ) !
!
reaches
iI (p) > then, since
iI () decreasing function eventually
!

zero, must cross .!Thus, maximal value p iI (p ) =
.
since iI (p) > , must exist minimal value p+
! Similarly,
+
iI (p ) = , required.
!
p maximum solution iI (p ) =
!
!Although specified
< , worth noting two values p
iI (p ),!if
iI (p )!
!
!
p$ satisfy iI (p) = iI (p ) iI (p$ ) = iI (p$
), monotonicity sides equation,
must
I,
!
! $that !
$
$
(p) = (p ) (p) = (p ). Likewise, iI (p) = iI (p ) iI (p) =
!
$
$
$
iI (p ) I, (p) = (p ) (p) = (p ) respectively. Indeed,
observations mind, specifications maximal solutions chosen makes
difference main result, done simply p+ p well defined.
state prove main result analysis.
Theorem 1. storage system described, < 1 > 0 set competitive
equilibria system precisely set feasible agent strategies where, I,
ci = (p+ ) di = (p ). case storage devices perfectly efficient
costless, ( = 1 = 0), set competitive equilibria system precisely
set feasible agent strategies where, I, bi = (p+ ) (p ).
Proof. seek find aggregate storage profile, minimises f () where:
#

$

f {ci , di }iI =

"#%
iI

"i +ci di
0

$
s(x)dx + ci .

Since set feasible aggregate storage profiles closed bounded, must
least one minimum f () domain. However, since domain convex,
f () convex function, local minima convex set global minima.
find optimal allocations, seek feasible aggregate storage profiles
783

fiVytelingum, Voice, Ramchurn, Rogers & Jennings

derivative f () non-negative every direction leads another feasible allocation.
calculate I, f /ci = pi + f /di = pi . Thus remains
characterise feasible profiles that:
"
(pi + )ci + pi di 0,
iI

every vector small changes lead another feasible aggregate storage profile,
is, c, {ci + ci , di + di }iI feasible.
suppose storage profile, (c, d), locally minimises f ().
time intervals i, j C > ci > 0 C > cj > 0, would feasible increase
ci decrease cj equal quantity, (or vice versa), hence must pi = pj .
deduce i, j, pi < pj , ci > 0 cj > 0, must
ci = C. So, let p+ maximum pj time intervals j cj > 0, get
intervals ci > 0, pi p+ , pi < p+ , ci must equal C. Similarly,
show p minimum pj time intervals j dj > 0
intervals di > 0, pi p , pi > p di = Oi .
Furthermore, cannot i, j pi + > pj ci > 0 dj > 0,
would feasible profitable decrease ci ci increase dj
dj = ci . Hence, must p+ + p . particular, p+ p ,
inequality strict > 0 < 1, case, intervals one
ci di non-zero.
interval i, pi > p , di = Oi ci = 0, s1 (pi ) !i = Oi
thus, s1 (p ) !i < Oi s1 () increasing function. means bi = Oi =
(p ). hand, pi = p bi = s1 (p ) !i = (p ). Likewise,
interval i, pi < p+ , ci = C di = 0, s1 (pi ) !i = C
(p+ ) = C = bi , pi = p+ bi = (p+ ), directly. pi lies strictly p
p+ ci di must equal 0, s1 (pi ) !i = 0. Thus, s1 (p ) !i 0
s1 (p+ ) !i 0, (p+ ) = (p ) = 0. results show prices,
equilibrium must bi = (p+ ) (p ). stated above, < 1 > 0,
time interval i, one ci di non-zero, so, case
+ ) = (p ).
specify,

! ci = (p
!
!

+ ) p+ + p , must

Since

(p
)
=


(p


iI
iI
iI (p )
!
!
!
iI ( p ) so, solution iI (p) = iI (p ) must satisfy
monotonicity !
sides equation.
p,
p p , !
! Furthermore, for!
+
would iI (p) iI (p ), meaning iI

(p

)


iI (p )
!
!

since
implies p p+ . would also
!mean that,
! iI di= iI (p ) ,

capacity!constraint, !
must iI (p ) iI (p ). Similarly, must
+
+
also iI !
(p )
(p ).
iI !
!
+
iI (p ) < iI (p+ ). would also imply iI (p ) <
! Now, suppose

1 +
iI (p ). Hence, would exist intervals i, j (p ) !i <
s1 (p+ ) s1 (p ) !j > s1 (p ). However, would imply that, equilibrium
state, ci = di = 0, dj = cj = 0. Hence would pi < p+ pj > p , meaning
pi + < pj would profitable increase ci ci increase dj
dj = ci . implies contradiction, since small enough change, would lead
feasible storage profile.
784

fiTheoretical Practical Foundations Agent-Based Micro-Storage

!
!
!
!
Hence must iI (p+ ) = iI (p+ ) iI (p ) = iI (p ).
However, since functions monotonic, must i, (p+ ) = (p+ )
(p ) = (p ). Thus, equilibrium must satisfy conditions statement
theorem.
Thus, exists least one minimiser f () feasible domain,
minimiser f () must satisfy conditions given statement theorem. Furthermore, conditions given statement theorem sufficiently strict
specify f () precisely. Thus, feasible storage profile satisfies conditions
given statement theorem must minimise f () feasible domain,
required.
direct consequence theorem prior observations matter
storage capacity is, aggregate amount charged day bounded by:
"
(p ),
iI

p equal solution to:
"
iI

(p) =

"
iI

(p ).

storage capacity greater amount, portion
used equilibrium. Moreover, since characterise competitive equilibria global
minimisers aggregate costs, agents negligible market power, addition
storage capacity profitable total amount storage less
maximal value. key result leads us predict given aggregate load profile,
either consumers need buy storage optimal battery capacity buy
consumer bounded. particular, bound supported
empirical evaluation UK electricity market subsection population
required adopt storage minimise costs (see Section 6).
4.3 Idealised Scenarios
determined existence characterisation charging discharging price
points, investigate prices set context two idealised
scenarios micro-storage devices deployed grid large scale.
aims identify properties system different parameters tend particular
limits (and understand broad system behaviour). intuitions impact
expressed following corollaries. consider situation agents sell
electricity back grid order simplify results obtain thus make clearer
intuition trying provide. Similar results would hold case agents
cannot sell, similar-shaped load profiles, storage capacities proportion
daily load.
Corollary 1. agents allowed sell electricity back grid current price,
if, agents A, C Da sufficiently large, i, p+ pi p .
Furthermore, I, p+ < pi < p , bi = 0.
785

fiVytelingum, Voice, Ramchurn, Rogers & Jennings

Proof. If, let C Da equal , break
smallness assumption, and, furthermore, I, well (p ) < Oi (p+ ) <
C. i, either bi < 0, case 0 < (p ) < pi = p , else bi > 0,
case 0 < (p+ ) < C pi = p+ , or, lastly, could bi = 0,
occur (p+ ) = (p ), either p+ = pi = p (p+ ) = (p ) = 0
p+ < pi < p . covers possible cases, required.
Thus, charge discharge rates sufficiently high, could expect prices
always lie within p+ p .
Corollary 2. agents allowed sell electricity back grid current price,
if, agents a, C Da sufficiently large, capacity sufficiently high,
= 0 = 1, i, p+ = pi = p .
Proof. sufficiently high, must equilibrium p+ = p ,
p+ = p . result follows directly previous corollary.
Hence, scenario, perfectly efficient, cost free, high capacity storage,
would expect market prices time flatten single value.
perfect storage capability would allow agents transport energy time interval
time interval free charge. Thus, different suppliers different time intervals
would compete other, resulting convergence single market price.
Even storage devices perfectly efficient, still price flattening effect,
though mitigated fact agents would buy energy
discharge, meaning would always require price difference charging
discharging periods. Since prices direct function demand, infer
large amounts storage effectively bound maximum minimum levels
demand time period. Thus, expect addition large amounts
storage significant effect grid load factor, size effect
directly related efficiency storage device. Hence, Section 6, study
impact storage adoption grid (i.e., terms grid efficiency cost savings
population) determine impact micro-storage devices various levels
saturation micro-storage across population. so, however,
next section, provide analysis proportion population expected adopt
storage devices (i.e., based individuals profits micro-storage). important
because, shown real-time price electricity flatten, aim show
prices impact profitability buying micro-storage. analysis
helpful determining viability micro-storage deployment projects.
4.4 Storage Adoption
model shows available storage capacity charging (and discharging) rates
increase, significant effect prices. Moreover, shows limit
much storage capacity required, profitable increase capacity
available storage limit. Finding limits useful application
analysis, gives indication level adoption likely occur given
cost, efficiency charging discharging rates leading storage technology.
786

fiTheoretical Practical Foundations Agent-Based Micro-Storage

reality, however, practical home users incrementally increase
storage capacity time find optimal level. likely scenario
home user buys storage device, buy enough cover usage requirements.
Aggregate storage capacity increase time homes install
devices. Predicting number potential buyers micro-storage devices key
understanding (for market makers producers) whether demand large enough
take advantage economies scale production micro-storage devices (of
high efficiency high capacity). respect, crucial study maximal level
storage adoption batteries. is, percentage homes install
electricity storage devices longer profitable devices installed.
consider case home users cannot sell electricity back grid (or
neighbours). users sell stored electricity, would possible
users could purchase extra capacity multiple storage devices way make money.
However, devices likely manufactured energy needs
single home mind, analysis still gives useful guide many devices
profitably deployed throughout populace.
Corollary 3. Suppose model population agents subset agents
A$ homogeneous storage devices, |A$ | = |A|, < 1. Suppose
population agents A$ homogeneous, aggregate load profile
agents A$ !i storage devices sufficiently large maximal charging
discharging rates capacities restrict storage profiles
equilibrium. Then, equilibrium, individually profitable increases aggregate benefit
agent \ A$ install storage device if:
< max
iI

p maximal solution to:

$
1 # 1
(p) !i ,
!i

& #
"#
$+ "
$ '
min !i , s1 (p) !i
.
s1 (p ) !i =
iI

iI

Proof. model scenario setting:
Da = C = max !ai ,
iI


=

"

!ai ,

iI

A$



=
=
= 0 \ A$ . agents A$ , values
maximal charging discharging rates capacities sufficiently large
corresponding constraints cannot tight equilibrium.
Theorem 1, aggregate storage profile equilibrium be:
&
# 1
$+
$ '
#
(p ) !i min !i , s1 (p ) !i
Ca

Ca



787

fiVytelingum, Voice, Ramchurn, Rogers & Jennings

p maximal solution to:
&
"#
$+ "
$ '
#
s1 (p ) !i =
.
min !i , s1 (p ) !i
iI

(4)

iI

profitable agent \ A$ get storage device addition
storage device increase total amount energy charged discharged
equilibrium. addition storage device lead increase total
amount energy charged, means profitable agent use storage
device use it. Thus, agent must obtain profit device.
addition storage device would lead increase total amount
energy charged, then, since amount charged is:
&
"
$ '
#
,
min !i , s1 (p ) !i
iI

means addition storage device effect p . Hence,
circumstance, addition storage device would effect aggregate storage
profile, collection storage profiles agents equilibrium would still
remain equilibrium new device added maximally profitable behaviour
agent new device simply use it.
I,
$
#
!i < s1 (p ) !i ,

then, since addition storage device strictly increase , previous value p
longer satisfy (4) p , along total amount energy charged,
increase. Otherwise, increasing effect (4), meaning p change,
neither aggregate amount energy charged.
Let p maximal solution to:
& #
"#
$+ "
$ '
s1 (p ) !i =
.
min !i , s1 (p) !i
iI

iI



#
$
!i < s1 (p ) !i

then, since, inspection p p , must have:
#
$
!i < s1 (p) !i .


i, p satisfies:
"#
iI

#
$
!i s1 (p ) !i

s1 (p ) !i

$+

=

"#
$
s1 (p ) !i ,
iI

and, since !i > !i , p satisfies:
& #
"#
$+ "
$ '
1

1
,
min !i , (p ) !i
(p ) !i =
iI

iI

788

fiTheoretical Practical Foundations Agent-Based Micro-Storage

so, p = p and:

#
$
!i s1 (p) !i .

Thus, condition additional storage device profitable
I,
$
#
!i < s1 (p) !i
required.

corollary used give indication level adoption population
required see maximal aggregate cost savings use energy storage. Later,
Sections 6.6 7, complement result empirical study system-wide
benefits micro-storage adoption UK market (where agents use novel storage
strategies) points similar bound level storage adoption.
4.5 Rationality Assumption
far, main results (i.e., Theorem 1 Corollaries 1, 2, 3) give aggregate
storage behaviour game deterministic competitive equilibrium predict
extent nature adoption storage devices population. use
results specify limits grid performance benefits market conditions (i.e.,
levels adoption equilibrium price electricity) result adopting microstorage. actions selfish profit-motivated agents result stable
aggregate behaviour, better outcomes described above.
However, using game theory, made implicit assumptions, specifically
agents rational complete information market throughout
time period ability compute optimal strategy given information.
reality, information available owning storage devices perfect
agents different computational capabilities. Furthermore, even perfect
information, might apparent automated agent strategies preferable.
Instead, agents must adapt time, become aware changes
market prices, learn storage strategies preferable. difficult problem
guaranteed selfish learning behaviour converge. particular, agents
over-react perceived opportunities market, cycles price fluctuations could develop
stable outcome (as seen Subsection 6.2).
looked analytical approach required complete information,
next section, provide practical (informationally) decentralised approach addresses lack complete information. Specifically, describe novel adaptive storage
strategy dynamically adapts changes market prices, allowing selfish, profitmotivated agents individually maximise savings using private information
information observed market prices. scheme, agents learn change
storage profiles day closer perceived optimal strategy. Section 6,
show provided adaptation fast, mechanism converges equilibrium predicted Theorem 1. Moreover, empirical results confirm bounds
storage capacity adoption storage predicted far. Altogether, results show assumptions made theoretical framework reasonable
789

fiVytelingum, Voice, Ramchurn, Rogers & Jennings

enough model heterogeneous populations agents and, therefore, framework
generally applied large-scale micro-storage analysis.

5. Adaptive Storage Strategy
section, present novel adaptive strategy agent use decide
store energy use energy stored. Now, system converge
towards equilibrium, need avoid many agents charging batteries
time, turn resulting higher costs everyone. strategy achieves
would good candidate long shown converge equilibrium. One
possible candidate would allow agents adapt storage profile solely using target
profile (which would equilibrium profile case) provided supplier (similar
existing TOU pricing schemes which, rather poorly, incentivise charging off-peak
hours discharging peak time). However, strategy would require optimisation
centre (i.e., supplier) solution would depend accurately supplier
estimate combined charging discharging rate limits storage capacities
agents storage devices across grid often needs so. Thus,
prefer strategy require grid-wide knowledge adapt based
agents private information (i.e., information micro-storage devices)
observed market information (i.e., real-time retail prices continuously change
result changing demand due consumers using storage devices). Indeed, design
decentralised strategy describe detail.
strategy based day-ahead best-response storage.10 market
prices unknown priori, calculate storage profile day-ahead basis,
best-response predicted market prices (which observed posteriori
aggregate demand market known). Now, agents adopt
best-response, resulting effect would simply peaks moving periods high
demand previously low demand empirically demonstrate Subsection
6.2. peaks demand moved previously low-demand periods (as peaks
market prices), agents end paying higher prices charge battery.
Thus, agent plays best-response exposed changing peaks. mitigate
exposure changes, need ensure agent gradually adapts storage
towards best-response storage instead reacting prices and, doing, avoid
agents herding consume lowest predicted price point. section, first
describe calculate day-ahead best response storage profile and, second,
describe learning mechanism, agent adapts storage.

10. strategy unaffected use different time-scales (other day-ahead). perform
day-ahead optimisation case exists natural cycle consumption similar days
exploit generate load profile distributions simulations reduce number times
optimisation algorithms run. real-world deployment, finer grained optimisation (at
level half quarter hours) would probably appropriate agent re-optimises based
up-to-date intra-day half-hourly consumption market prices well current amount
stored energy available.

790

fiTheoretical Practical Foundations Agent-Based Micro-Storage

5.1 Day-Ahead Best-Response Storage
objective agent minimise costs storing energy prices low
using energy prices high.
market prices unknown
! Now,

aggregated load consumers aA !i = !i known, agent needs decide
storage profiles based prediction market prices. Note work,
assume market prices move significantly similar days (e.g.,
season, weekdays tend similar different week ends) use
weighted moving average predict future market prices.11
compute storage profile, bai = cai dai every time-slot day
solution optimisation problem (expressed linear program) minimise
following cost function given decision variables cai , dai , (representing storage
capacity):12
(
)
"
(5)
arg min
pi (cai dai + !ai ) + cai

b

iI

subject following constraints:

Constraint 1: Energy conservation
"

dai =

iI

"

cai

iI

Constraint 2: Within charging discharging rate limits
dai Da cai C
Constraint 3: Energy stored used time-slot
&
&
''
!
da
dai ca0 + i1
c

j
j
j=1
&
''
&
!



cai ca0 + i1
j=1 cj dj

Constraint 4: reselling allowed

!ai dai 0
last constraint removed system consumers allowed sell power
grid. Note capacity storage known, constrained
need find , left unconstrained optimisation
&calculated '
maximum energy stored (in optimised storage profile), i.e.,
!i


maxiI c0 + j=1 bj .

11. demonstrate later on, central work price movements generally
small. However, number sophisticated prediction algorithms, regression Gaussian
processes, could used instead better predictions price movements significant result
volatile market.
12. used IBM ILOG CPLEX 12 implement solve linear program.

791

fiVytelingum, Voice, Ramchurn, Rogers & Jennings

described earlier, cost using storage set small
wish find best response regardless external factor cost
storage. efficiency storage device, C maximum charging rate, Da
maximum discharging rate ca0 amount energy stored beginning
day equal stored energy end day. next consider
agent adapts storage based best-response.
5.2 Learning Market
market prices move day, agent needs continuously adapt storage
profile reflect changes. One may expect micro-storage incrementally rolled
out, agents would able gradually adapt stabilise market prices. However,
empirically demonstrate Subsection 6.2, system becomes unstable
many agents attempt optimise time, even use best response
incrementally acquire micro-storage devices. Now, relatively high cost
storage (compared savings energy cost see Section 7) assuming effect
micro-storage system change market prices significantly (such optimal
capacity agent requires changing predicted results Section 4.2),
necessary agent gradually change much absolute storage capacity
actually uses. end, based intuitions drawn analytical results
point bound capacity required adaptation charging profiles prices
different times day, develop learning mechanism based Widrow-Hoff
learning rule (i.e., gradient descent approach)13 adapts storage profile
capacity micro-storage device used respect changes market
prices.
learning mechanism based two-pass approach adapt storage capacity
profile. Initially, agent computes optimal storage capacity required
minimise costs. precisely, cost-minimising capacity setting
unconstrained variable optimisation (see Equation (5)). Now, constitutes desired
capacity towards agent adapts utilised storage capacity. is, changes
storage capacity uses progressively follow changing trend market prices.
actual storage capacity used agent defined Equation (6) (t)
follows desired storage capacity that:
(t + 1) = (t) + 1 ( (t))

(6)

(0) = 0 default 1 learning rate storage capacity agent
a.14 Given storage capacity, agent computes optimal storage profile
following day fixing (t + 1) Equation (5).
second pass, given current storage profile, agent adapts storage profile
follows:
13. used Widrow-Hoff rule directly engineered optimisation algorithm,
relatively minor changes, learning rules (such reinforcement learning Bayesian learning) could
used.
14. empirically demonstrate Section 6, choice learning rates determines evolutionary stability system reasonably small ensure convergence.

792

fiTheoretical Practical Foundations Agent-Based Micro-Storage

bai (t + 1) = bai (t) + 2 (ia bai (t))

(7)

desired storage profile given optimal storage profile subject fixed
storage capacity (t + 1) 2 (0, 1] learning rate strategy. Note
analyse detail sensitivity learning parameters 1 2 part
empirical study system next section.

6. Empirical Analysis Micro-Storage UK Market
Based adaptive storage strategies defined previous section, analysis
micro-storage present section aims complement theoretical part
paper assumed largely homogeneous population agents (see Section 4). particular, evaluate emergent properties large populations 1000 agents15
owning micro-storage different charging discharging rates sizes using
learning strategy adapt storage profile 500 simulation days 200 runs.
beginning simulation day, agent makes prediction load profile
market prices (using historical data) across 48 time-slots compute best
response day-ahead basis. end simulation day, actual market prices
computed total domestic market demand (i.e., aggregate load storage
profiles) based market macro-model described Subsection 3.2 published
agents posteriori. frame results within real-world context, simulations
focus UK electricity grid.16
Thus, given macro-model UK electricity retail market (see Section 3.2),
initialise individual consumers typical UK load profiles.17 Moreover, learning rates
agents (presented Sections 5.1 5.2), well charging discharging
rates, normally distributed around means drawn charging (and discharging) rates
current technologies (see Section 2).18 done represent heterogeneous consumers
different types storage devices address realistic scenario
game-theoretic analysis.
Given setup, benchmarking purposes first compute competitive equilibrium predicted game-theoretic framework (which assumes complete information
15. simulation could readily extended hundreds thousands agents given distributed
nature computation. Now, given that, average, agents tend similar load profiles,
assume 1000 different clusters load profiles among domestic consumers
simulation 1000 agents (rather millions) valid. observed real data
assumption heterogeneity UK domestic population reasonable.
16. Note choose UK typical deregulated market. approach nonetheless general enough
framework applied markets, including industrial commercial markets (as
opposed residential case consider) well micro-grids national grid countries
based macro-model electricity market. Thus, results insights presented paper
broadly generalise.
17. profile agent based normal distribution mean !mean taken UK
, ), !ai 0 = 0.2 approximate
average profile. formally defined !ai N (!mean

typical spiky daily profiles consumers.
18. experiments except analyse effect learning rates, draw values learning
rates normal distribution N (0.05, 0.02). experimentation, found result
good system-wide performance (see Section 6.5) small system slow converge.

793

fiVytelingum, Voice, Ramchurn, Rogers & Jennings

agents load profiles battery capacities) UK electricity grid. Second,
study system breaks (in terms average individual costs grid
performance metrics defined Section 3.3) agents gradually adopt storage
adaptive mechanism. comparison motivates need adaptive mechanism,
and, results, empirically demonstrate market indeed converge
competitive equilibrium population agents adopt adaptive storage
mechanism. Third, perform sensitivity analysis convergence properties
adaptive mechanism respect learning rates understand impact different
learning rates cost savings grid performance parameters
set. Fourth, evaluate robustness approach agents micro-storage
adopt learning mechanism. Finally, evaluate impact different degrees
saturation micro-storage (using agent-based micro-storage management)
efficiency grid and, doing, study performance grid (see Subsection
3.3) consumers adopt technology.
6.1 Game-Theoretic Solution
Given game-theoretic framework outlined Section 4, first calculate competitive
equilibrium based average domestic consumption profile consumer (from UK)
using procedure described Subsection 4.2 (i.e., devices perfectly efficient
costless). resulting storage profile shown Figure 4. clear
equilibrium behaviour consumer charge off-peak hours (at night) use
stored energy peak hours (after working hours) consumers load highest.
Furthermore, observed Figure 4, equilibrium, optimised load profile (i.e.,
sum aggregate unoptimised load profile storage profile) flattened completely
load factor 1. implies agent-based micro-storage management
theoretically reduce peaks completely completely efficient. Furthermore, storage
capacity required achieve equilibrium 2.3 kWh, computed maximum
cumulative sum storage profile (as micro-storage device charges discharges
time-slot). next subsection, first demonstrate how, practice,
system breaks completely without adaptive mechanism motivate need
adaptive mechanism and, go show system indeed converges
competitive equilibrium decentralised adaptive mechanism adopted.
6.2 Market without Adaptive Mechanism
analyse market operates without adaptive mechanism, set population
agents playing best-response storage profile every day (i.e., using optimisation
algorithm defined Section 5.1). Moreover, simulate gradual adoption storage
devices consumers, rate adoption, r (i.e., probability r agent
adopt storage keep storage device; r = 1 simulates system agents
storage capabilities beginning). agent storage capability,
optimise daily use best-response storage profile. setting, Figure 5(a) shows
deviation competitive equilibrium Figure 5(b) shows load factor
grid different values r. r = 1 (i.e., consumers adopt micro-storage
794

fiTheoretical Practical Foundations Agent-Based Micro-Storage

0.6
0.5

Power (KW)

0.4
0.3
Storage profile equilibrium
Average UK load profile
Load profile equilibrium

0.2
0.1
0
0.1
0.2
0:00 2:30

5:00

7:30 10:00 12:30 15:00 17:30 20:00 22:30 24:00
Time day

Figure 4: Storage profile load profile competitive equilibrium.

devices time), system clearly deviates equilibrium load
factor jumping immediately 0.66 (without micro-storage) 0.4 (with immediate
adoption microstorage), suggesting larger peaks system. smaller values r,
system converges beginning (as demand slowly decreases peak time
increases off-peak time since small proportion agents change demand),
break number simulation days ends larger peaks.
smaller r is, longer system takes break down, though inevitably so.
intuition behind invariably reaches point many agents
adopted micro-storage devices using best-response storage profile.
many agents re-optimising storage profiles time, peaks
market demand moved around aggregate demand profile flattened
(inferred non-increasing load factor long-term). next subsection,
show adaptive strategy helps remedy results desirable system-wide
performance.
6.3 Market Adaptive Mechanism
Here, study convergence properties adaptive mechanism also show
results corroborate theoretical bound storage capacity suggested Section 4 (given
worst case scenario Subsection 6.2 r = 1). detail, given population
agents using adaptive mechanism 1 N (0.05, 0.02) 2 N (0.05, 0.02)
(we show performance varies different learning rates next section),
average storage profile found converge rapidly competitive equilibrium
795

fiMeansquared deviation equilibrium (logscale)

Vytelingum, Voice, Ramchurn, Rogers & Jennings

0

10

1

10

r=1.0
50

100

150

r=0.01

r=0.005

200 250 300
Simulation Days

r=0.001
350

400

450

500

(a) Deviation population without adaptive storage competitive equilibrium.

r=1.0

r=0.01

r=0.005

r=0.001

0.8
0.75

Load Factor

0.7
0.65
0.6
0.55
0.5
0.45
0.4
0.35

50

100

150

200 250 300
Simulation Days

350

400

450

500

(b) Load factor (LF) market adaptive mechanism.

Figure 5: Convergence properties system adaptive storage.

796

fiTheoretical Practical Foundations Agent-Based Micro-Storage

game-theoretic analysis within less 20 simulation days (see Figure 6).19 expected,
convergence results agents gradually adapting storage profiles
aggregate market demand shifted peak off-peak.

Meansquared deviation equilibrium (logscale)

0

10

1

10

2

10

3

10

100

200
300
Simulation days

400

500

Figure 6: Convergence average storage profile competitive equilibrium
agents adopt adaptive mechanism.

system converges competitive equilibrium, also observe grid
efficiency (as measured LF DF) improves gradually converges (see Figure
7) agents adapt storage profiles system converges competitive equilibrium. detail, Figure 7, observe system LF increases 0.68
converges around 0.93, suggesting considerably fewer peaks grid microstorage adopted, indeed, flattened demand.20 coupled DF
close 1 indicates (as discussed Section 3.3) that, even though agents closely
correlated load profiles, overall, profiles tend reasonably flat.
Furthermore, Figure 8, see average storage capacity required
converges around 2.3 kWh (which equals storage capacity prescribed analytical
solution see Section 6.1) several simulation days. implies average
19. Given weekdays homogeneous (as opposed Saturdays Sundays), agent learn
across weekdays system would converge within couple weeks.
20. results simulation day averaged number simulations. Furthermore,
simulation size 200 statistically significant, results figures given error bars
95% confidence interval.

797

fiVytelingum, Voice, Ramchurn, Rogers & Jennings

Load Factor Diversity Factor

1.1

1

0.9

0.8

0.7
Load factor
Diversity factor
0.6

50

100

150

200
250
300
Simulation Days

350

400

450

500

Figure 7: Efficiency grid system converges competitive equilibrium
agents adopt adaptive mechanism.

consumer may buy storage device capacity 3kWh (see maximum storage capacity
Figure 8), agent would actually need 2.3kWh capacity minimise costs.
6.4 Sensitivity Adaptive Mechanism
One assumptions approach agents expected adopt adaptive
mechanism. imposed feature smart meter controlling
micro-storage device, exceptionally case smart meter tampered
user programs ignore learning mechanism use best
response, i.e., agent always executes optimal behaviour. Thus, subsection,
study effect system part population adopt proposed
adaptive mechanism, assuming whole population storage capability.
Figure 9, observe system particularly robust starts
degrading 60% population adopt adaptive mechanism
deliberately execute best response. proportion population playing
best response increases, load factor slightly increases 0.94 proportion
population reaches around 60% load factor rapidly decreases 0.4
(suggesting large peaks system) agents adopt best response, i.e.,
adaptive behaviour system. agents using best response,
agents gradually adapting storage profiles (implicitly adapting impact
former agents best-response profile). system eventually breaks
798

fiTheoretical Practical Foundations Agent-Based Micro-Storage

3.5

Storage Capacity (kWh)

3

2.5

2

1.5

1

0.5

0

50

100

150

200
250
300
Simulation Days

350

400

450

500

Figure 8: Average storage capacity required typical consumer system converges
competitive equilibrium.

many agents using best response adaptive mechanism. also
notice small increase load factor result increased diversity among agents,
emergent behaviour observe analysing load factor population
different proportions storage capability (see Subsection 6.6 discussion).
Note system remains robust upto 60% population saturation micro-storage
even without learning mechanism, mechanism ensures system break
proportion population, observe Subsection 6.6.
6.5 Sensitivity Convergence Properties
guarantee consistency results given different parameter settings, section
explore values learning rates21 1 2 affect convergence results.22
doing, aim determine fast agent ideally adapt storage profile
maximise savings while, possible, helping improve efficiency grid.
Figure 10(a) shows smaller learning rate, efficient system (with
higher load factor). intuition behind small learning rate allows
market prices change gradually. higher learning rate, hand, would result
21. learning rates intrinsic adaptive mechanism, assume 1 2 share
value without loss generality interested fast mechanism adapts rather
specifically two-part adaptation.
22. mean load factors savings Day 400 Day 500 (by time system generally
converged) recorded averaged 200 runs different learning rates.

799

fiVytelingum, Voice, Ramchurn, Rogers & Jennings

1

0.9

Load Factor

0.8

0.7

0.6

0.5

0.4

0.3
0

0.2

0.4

0.6

0.8

1

Proportion population storage switching bestresponse

Figure 9: Grid efficiency consumer switch best-response.

agents adopting optimal storage profile quickly rather gradually,
clearly results poor savings poor system efficiency peaks cycling system.
learning rate increases, load factor quickly decreases 0.59 agents
adopt best-response immediately. individual perspective, agent would
typically set learning parameter based savings. Figure 10(b), see
that, likewise, smaller learning parameter is, better average savings23
individual agent.
Now, infinitely small learning rate infeasible implies infinitely
long time reach equilibrium, trade-off required. Specifically, learning
parameters sensitive small, value 0.05 reasonable given
decrease savings would negligible. mentioned Footnote 18, use
value experiments.
Given results, claim adaptive strategy sets benchmark
learning strategy system (i.e., base requirement strategy would
convergence). results mainly hold whole population owning storage,
important see system performs storage gradually introduced
population. enable us identify optimal level adoption storage
required order maximise grid efficiency. doing, also aim complement
analytical results (see Section 4.4) empirical evidence showing level adoption
still profitable individual users acquire storage UK market.
23. average saving consumer computed difference average costs (after system
converged) system micro-storage (i.e., system converged) one without.

800

fiTheoretical Practical Foundations Agent-Based Micro-Storage

1
0.95
0.9

Load Factor

0.85
0.8
0.75
0.7
0.65
0.6
0.55
0.5
0

0.2

0.4
0.6
Learning rate

0.8

1

0.8

1

(a)
0.1

Savings agents storage

0.05
0
0.05
0.1
0.15
0.2
0.25
0.3
0.35
0.4
0

0.2

0.4
0.6
Learning Rate

(b)

Figure 10: sensitivity learning rate, 1 = 2 , system terms (a)
load factor (b) savings agents storage.

801

fiVytelingum, Voice, Ramchurn, Rogers & Jennings

6.6 Grid Efficiency Incremental Micro-Storage Adoption
following set experiments, investigate grid performance metrics carbon
emission reductions (which one main aims work) achieved mechanism
micro-storage incrementally adopted.24 Figure 11, observe grid
efficiency peaks 32% population (rather aggregate storage capacity
population 100%). suggests 32% population required
storage maximise grid efficiency. proportion increases 0,
agents storage capability thus storage profiles adapted flatten
demand. aggregate storage profile gradually flattens aggregate load profile
load factor increases diversity factor (since agents
storage profile and, thus, adapted demand profile). Eventually, load factor peaks
32%, point, system flattened much could be. agents
acquire storage devices, diversity factor decreases 1 agents use storage,
finally settles 1, where, average, (flatter) load profile storage
profile. Furthermore, agents optimising time, load factor also
decreases slightly many agents trying optimise adapt storage
profiles time. Specifically, agents optimising surplus storage capacity
required flatten demand grid. seen, diversity factor
decreases suggests optimising surplus storage increases correlation among
individual demand profiles. increased correlation suggests small peak
load profiles impact which, average, decreases load factor.
Figure 12, also observe significant benefit storage macro-level (i.e.,
ignoring individual benefits agents study next section)
sufficient proportion (32%) population adopt storage, carbon emissions
electricity market would decrease appreciably peak demands reduced. Indeed,
carbon emission UK reduced 7% (from 63 58.3 kilotonnes
CO2 per day),25 reaching minimum domestic load factor maximised (since
reducing peaks demand effect reducing carbon intensity supplied
electricity, turn, reduces total carbon emissions).

7. Cost-Benefit Analysis Micro-Storage
far, studied efficiency grid achieved population storage
gradually adopted. turn individual consumer principally driven
much profit achieve adopting micro-storage (at certain cost). particular,
24. Note results describe (i.e., grid efficiency system converges) similar
game-theoretic solution given system proportion population storage
translates model smaller aggregate charging discharging limits see Section
4.
25. calculate carbon emissions considering reduction carbon intensity electricity
supply domestic load factor reduces (see Figure 3). consider total population 26M UK
households scale results take account fact domestic consumers represent
30% total UK demand (as discussed Section 3) remaining 70% consisting commercial
industrial profiles remain unchanged.

802

fiTheoretical Practical Foundations Agent-Based Micro-Storage

1.8

Load factor
Diversity factor

Load Factor Diversity Factor

1.6

1.4

1.2

1

0.8

32% population
0.6
0

0.1

0.2

0.3

0.4

0.5

0.6

0.7

Proportion population storage

0.8

0.9

1

Figure 11: Grid efficiency (i.e., load factor diversity factor) different proportions population using storage.

Carbon Emissions (kilotonnes CO2 per day)

64

63

62

61

60

59

58
0

7% CO2 reduct ion

0.2

0.4
0.6
0.8
Proportion population storage

1

Figure 12: Total daily carbon emissions UK domestic sector different proportions population using storage.

803

fiVytelingum, Voice, Ramchurn, Rogers & Jennings

question wish address that: level adoption storage still profitable
agents system?26 Hence, experiments, first assume cost storage
vary proportion population storage record cost-savings
achieved parts population adopted micro-storage.
results (see Figure 13), first observe agents micro-storage
(i.e, close 0%), potential average savings agent close 14%.
consumers adopt storage, average saving gradually decreases slightly less 8%
(as market prices also flatten agents longer benefit difference
low off-peak prices high peak prices). Interestingly, also observe consumers
without micro-storage also benefit use consumers. because,
empirically demonstrated Section 6, adoption micro-storage flattens peaks
demand system and, thus, market prices. means cheaper electricity
domestic market and, indeed, consumers adopt micro-storage, savings
consumers adopt it, also increase. reaches point 48%
consumers adopt micro-storage savings consumers without
technology equal. percentage increases past 48%, savings consumers
adopt micro-storage exceed consumers adopt it.
consumers micro-storage trying optimise surplus storage
argued Section 6.6. implication dynamic consumers incentivised
adopt micro-storage 48% mark reached. point, incentive
consumers deviate chosen behaviour (i.e., use micro-storage not).27
Thus, long term, system converge equilibrium 48%
population adopt micro-storage percentage, consumers expect saving
9% individual electricity bills (which equates annual saving 60 per
household based average annual electricity bill 675). result also points
slight misalignment optimal level storage grid (in terms grid
efficiency) consumers (in terms savings). particular, given results
previous section (see Figure 11), note 48% level adoption equates
domestic load factor 0.91, maximum load factor achievable (assuming control
proportion population adoption storage) 0.94 occurs 32% adoption.
suggests proportion adoption system eventually settle at,
system slightly suboptimal.
next consider dynamic within realistic setting cost
storage, typically startup cost hardware installation (e.g., wiring converter)
cost actual battery. Based much storage capacity average consumer
would require maximise savings different proportions population, calculate savings minus cost storage (based typical battery costing 200 per
kWh 600 per kWh respectively lifetime 10 years fixed startup cost
200 both) assuming average cost electricity 675 consumer per

26. Note that, respect average consumers savings, set experiments complement
Section 6.5 studied cost-savings users learning rate varied.
27. Note consumer aware savings without micro-storage computed
based initial load profile demand profile storage profile.

804

fiTheoretical Practical Foundations Agent-Based Micro-Storage

0.14
Savings without storage

Savings storage (no cost storage)

0.12

Savings storage (Battery cost = 200/kWh startup cost = 200)
Savings storage (Battery cost = 600/kWh startup cost = 200)

Normalised Savings

0.1
0.08
0.06
0.04
0.02
10%

0
0

0.1

48%

23%

0.2

0.3

0.4
0.5
0.6
0.7
Proportion population storage

0.8

0.9

1

Figure 13: Savings without storage storage (for different costs storage).

year.28 Note savings without storage change independent
cost micro-storage. Given setup, results (see Figure 13) show
clear first-mover advantage. Thus, maximum saving achieved proportion population micro-storage close zero (i.e., agents
population storage). However, storage capacity agents require relatively
high 4.5kWh, decreasing rapidly 2.3kWh consumers population adopt
micro-storage (see Figure 14). Moreover, based savings cost storage
savings without storage, observe equilibrium moves 23% cost storage
device 200 per kWh 10% cost 600 per kWh (given startup cost
200). Hence, combining latter results Figure 11, infer
grid efficiency quickly drops cost storage increases (as level adoption
decreases). Thus, cost storage significantly affect benefits derived
users grid whole.
results, however, consider populations agents drawn uniformly
UK average load profile. could therefore argued results may apply
circumstances population uniformly distributed and, particular, users
consume differing amounts energy making savings storage viable
consuming (as able shift energy across day recover high
startup cost system) others consuming less. Given this, next expand
28. compare cost storage daily cost electricity calculating daily cost owning
running storage device, i.e., cost storage device startup costs assume,
spread lifetime storage device which, case, 10 years. battery costing
200 per kWh 600 per kWh, startup costs 200 equals 1p 3p per kWh per
day respectively, while, average, daily cost electricity 180p 8kWh daily electricity
consumption (see Subsection 2.1).

805

fiVytelingum, Voice, Ramchurn, Rogers & Jennings

5

Storage Capacity (kWh)

4.5

4

3.5

3

2.5

2
0

0.2

0.4
0.6
0.8
Proportion population storage

1

Figure 14: Average storage capacity required different proportions population
storage.

cost-benefit analysis consider fundamental distinction users, namely lowend users (typically yearly consumption29 1650 kWh) high-end users (typically
yearly consumption 4950 kWh). particular, want analyse dynamics
proportion low-end high-end users adopt storage (i.e., given number
agents type, proportion type adopt storage). aim
investigate type consumers benefit system and, indeed,
whether system efficient. end, adopt evolutionary game
theoretic approach suitable analyse dynamics, determine whether
system eventually settles stable equilibrium behaviours (whether
adopt storage) change. next describe evolutionary game-theoretic framework
and, thereon, provide cost-benefit analysis low-end high-end users.
7.1 Evolutionary Game-Theoretic Model
Here, formulate problem game low-end users adopt mixed
strategy30 rLU (0, 1) (i.e., probability low-end users storage capability)
motivated financial gains, high-end users adopt mixed strategy
29. data drawn typical consumption data published British Gas UK
www.britishgas.co.uk. Furthermore, assume types consumers normalised daily average load profiles.
30. assume agents type share mixed strategy given that, average,
load storage profiles thus, expected savings.

806

fiTheoretical Practical Foundations Agent-Based Micro-Storage

rHU (0, 1). analysing rLU rHU evolve payoffs change different
proportions population low-end high-end users storage, want study
proportion population using storage evolves. end, use classical
evolutionary game-theory (EGT) (Weibull, 1995) first compute heuristic
average payoffs low-end high-end (based simulations) (whether using
using storage) different mixed strategies rHU rLU , given respectively by:
"
uLU (r, LU , HU )rLU
uLU ( LU , HU ) =
rS

uHU (

LU

,

HU

)=

"

uHU (r, LU , HU )rHU

rS

uLU (r, LU , HU ) payoff low-end users adopting pure strategy r given
low-end users mixed strategy LU high-end users mixed strategy LU
uHU (r, LU , HU ) corresponding payoff high-end users.
use results calculate replicator dynamics, LU HU ,
describe dynamics population (i.e., proportions low-end high-end
users evolving), given by:
rLU = [uLU (r, LU , HU ) uLU ( LU , HU )]rLU r

kHU = [uHU (k, LU , HU ) uHU ( LU , HU )]kHU k
LU , HU ), points
Finally, test whether converges Nash equilibria (nash
nash
incentives either low-end high-end consumers deviate from.
LU
HU
(nash
, nash
) = arg

min

LU , HU

+

"&

kS

"&
rS

max[uLU (r, LU , HU ) uLU ( LU , HU ), 0]

max[uHU (k, LU , HU ) uHU ( LU , HU ), 0]

'2

'2

next subsection provide results EGT analysis.
7.2 EGT Analysis Micro-Storage Adoption Low- High-end Users
results EGT analysis given Figure 15 different costs storage device
(i.e., 0, 200, 400, 500, 1000 per kWh) assuming typical lifetime 10 years
battery startup cost 200. Thus, observe storage completely
subsidised (i.e., cost storage 0), range Nash equilibria (along straight
line ( LU = 0.4, HU = 1.0) ( LU = 0.7, HU = 0)). Furthermore, Figure 16,
observe Nash equilibria, grid efficiency system high
(the load factor higher 0.9).
Now, startup cost increases 200 per kWh, single Nash equiLU = 0.07, HU = 1) lower load factor 0.82 (see Figure 16).
librium (nash
nash
implies system eventually converges Nash equilibrium high-end consumers adopt storage 7% low-end users so. high-end
users overall make savings (than low-end users) cover daily cost storage
807

fiVytelingum, Voice, Ramchurn, Rogers & Jennings

high startup costs. However, cost storage device increases 200 per
kWh, storage becomes expensive low-end users, Nash equilibrium
LU = 0, HU = 1), still economically beneficial high-end users.
(nash
nash
increasing cost, storage gradually becomes expensive even high-end users,
LU , HU ) (0,0.94) (0,0.55)
seen change Nash equilibrium (nash
nash
cost storage device 400 per kWh (0,0.37) cost storage
device 500 per kWh. Eventually, cost storage device high even
LU = 0, HU = 0).
high-end users 1000 per kWh, Nash equilibrium (nash
nash
considering change Nash equilibria cost storage device increases,
also observe Figure 16 domestic load factor decreases gradually 0.68
micro-storage impact grid, expensive adopted.
analysis, gather improve grid efficiency maximise impact microstorage grid, cost storage sufficiently small, subsidising storage
would help improve efficiency grid.

8. Conclusions
paper, set explore theoretical practical foundations agentbased micro-storage implementation smart grid. achieve objectives,
first developed game-theoretic framework analyse strategic choices agents
make using micro-storage devices grid. framework allows one predict
competitive equilibrium system, particular, specify theoretical bounds
level micro-storage adoption capacity micro-storage adopted
largely homogeneous population.
Building upon intuitions generated theoretical results, went
devise novel micro-storage strategy allows agent optimise storage profile
storage capacity order maximise owners savings. Furthermore, provided
adaptive mechanism based predicted market prices allowed agent change
strategy response changing market prices. empirical evaluation mechanism
UK electricity grid shown cause average storage profile converge
theoretical competitive equilibrium. point, peak demands reduced, reducing
requirements costly carbon-intensive generation plants. Moreover,
analysis grid efficiency equilibrium show that, stable, results
reduced costs carbon emissions. also shows objective buying storage
save electricity bills generally aligned maximising grid efficiency (i.e.,
flattening peaks demand). particular, show that, without burden
cost (e.g., storage completely subsidised), population would adopt storage
equilibrium 48% population adopting storage reached achieved
high level domestic load factor (i.e. 0.91). Given this, analysed system
realistic setting empirically demonstrated costs storage
sufficiently low, system converge equilibrium high grid efficiency,
costs simply high, incentives even high-end electricity
users adopt micro-storage.
808

fiBattery cost = 0/kWh startup cost = 200

1

0.8

0.8

0.6

0.6

p

HU

Battery cost = 0/kWh startup cost = 0

1

p

HU

Theoretical Practical Foundations Agent-Based Micro-Storage

0.4

0.4

0.2

0.2

0
0

0.5
p

0
0

1

LU

Battery cost = 400/kWh startup cost = 200

1

0.8

0.8

0.6

0.6

p

HU

1

p

HU

1

LU

Battery cost = 200/kWh startup cost = 200

0.4

0.4

0.2

0.2

0
0

0.5
pLU

0
0

1

Battery cost = 500/kWh startup cost = 200

0.5
pLU

1

Battery cost = 1000/kWh startup cost = 200

1

0.8

0.8

0.6

0.6

p

HU

1

p

HU

0.5
p

0.4

0.4

0.2

0.2

0
0

0.5
p

0
0

1

LU

0.5
p

1

LU

Figure 15: Evolutionary game-theoretic analysis different costs storage. Lines
trajectories representing evolution proportion low-end highend users adopting storage. black dots Nash equilibria.

809

fiVytelingum, Voice, Ramchurn, Rogers & Jennings

1
0.9
0.9
0.8
0.7

0.85

p

HU

0.6
0.5

0.8

0.4
0.75

0.3
0.2

0.7

0.1
0
0

0.2

0.4

0.6

0.8

1

pLU

Figure 16: Load factor different proportions low-end high-end users adopting
storage.
general, theoretical practical results provide fertile ground research
agent-based techniques might applied manage demand smart grid.
particular, demand-side management technologies (Hammerstrom et al., 2008), involve loads (e.g., washing machine dishwasher) users home automatically
scheduled run certain times, present similar properties micro-storage
allow energy moved around peak off-peak times order flatten demand
reduce costs. Hence, applying similar framework strategies ours, could
expect analogous theoretical results efficiency gains predicted deployments
technologies. Moreover, techniques could used predict demand would
generally vary across day real-time pricing rolled different regions
(populated different proportions low-end high-end users), could help better
prepare assets (e.g., spinning reserve strengthening transmission lines).
generalise techniques further, intend integrate sophisticated models
electricity market mechanism work order better capture price fluctuations occur real markets. theoretical analysis, turn stochastic
processes, commonly used model volatility financial markets. Further,
experiments extended generating prices drawing samples suitable distributions, existing data points, even developing simulations include market
clearing strategic bidding energy suppliers consumers. Accordingly, also
intend employ better forecasting models demand supply (e.g., using Gaussian processes regression techniques) predict prices optimisation model. Indeed,
far assumed agents predict prices simply previous days prices
individual settlement periods. shown Wellman, Reeves, Lochner, Vorobeychik
810

fiTheoretical Practical Foundations Agent-Based Micro-Storage

(2004), agents perform significantly differently adopt different approaches
price prediction therefore, improve empirical analysis, interesting
see grid performance individual agents profits affected different agents
adopt different forecasting models. particular, important determine
widespread adoption micro-storage devices affect volatility wholesale
electricity market.
Furthermore, intend explore mechanisms ensure convergence towards
equilibrium. particular, point departure theory strategic behaviour
found Minority Game (Challet & Zhang, 1997), shares similarities
problem, using complex pricing mechanism consumers always play
best response (Voice et al., 2011) learning mechanism consumer
agent would required. part work, also intend investigate market
efficiency different proportions population adopting micro-storage devices,
whether decrease efficiency observed market saturated by-product
adaptive mechanism could avoided.
Finally, intend consider grid distribution network. peaks different
across different nodes electricity network, storage capacity might required
areas others. Thus, investigate whether agent-based micro-storage
management approach used flatten peaks locally within node electricity
network rather flattening aggregate demand profile grid.

Acknowledgments
paper extends previous work (Vytelingum, Voice, Ramchurn, Rogers, & Jennings,
2010). extends game-theoretic framework consider levels micro-storage adoption
expands empirical evaluation consider sensitivity convergence properties learning rate complex agent populations. work funded
iDEaS project (http://www.ideasproject.info).

References
Bathurst, G. N., & Strbac, G. (2003). Value combining energy storage wind
short-term energy balancing markets. Electric Power Systems Research, 67 (1),
18.
Challet, D., & Zhang, Y. C. (1997). Emergence cooperation organization
evolutionary game. Physica A, Vol. 246(3-4), pp. 407418.
Daryanian, B., Bohn, R., & Tabors, R. (1989). Optimal demand-side response electricity
spot prices storage-type customers. IEEE Trans. Power Systems, 4 (3), 897903.
DECC (2009). Smarter grids: opportunity. Tech. rep., Department Energy
Climate Change (DECC). http://www.decc.gov.uk.
den Bossche, P. V., Vergels, F., Mierlo, J. V., Matheys, J., & Autenboer, W. V. (2006).
Subat: assessment sustainable battery technology. Journal Power Sources,
162 (2), 913 919.
811

fiVytelingum, Voice, Ramchurn, Rogers & Jennings

Exarchakos, L., Leach, M., & Exarchakos, G. (2009). Modelling electricity storage systems
management influence demand-side management programmes. International Journal Energy Research, 33 (1), 6276.
Galvin, R., & Yeager, K. (2008). Perfect Power: MicroGrid Revolution Unleash
Cleaner, Greener, Abundant Energy. McGraw-Hill Professional.
Hammerstrom, D., et al. (2008). Pacific Northwest GridWise Testbed Demonstration
Projects; Part I. Olympic Peninsula Project. Tech. rep., PNNL-17167, Pacific Northwest National Laboratory (PNNL), Richland, WA (US).
Harris, C. (2005). Electricity Markets: Pricing, Structures, Economics. Wiley.
Holland, A. (2009). Welfare losses commodity storage games. Proceedings
8th International Conference Autonomous Agents Multiagent Systems, pp.
12531254, Budapest.
Houwing, M., Negenborn, R. R., Heijnen, P. W., Schutter, B. D., & Hellendoorn, H. (2007).
Least-cost model predictive control residential energy resources applying
chp. Power Tech, pp. 425430, London, UK.
Jennings, N. R., Corera, J., Laresgoiti, I., Mamdani, E. H., Perriolat, F., Skarek, P., & Varga,
L. Z. (1996). Using ARCHON develop real-world DAI applications electricity
transportation management particle accelerator control. IEEE Expert Systems,
11 (6), 6088.
Kirschen, D., & Strbac, G. (2004). Fundamentals power system economics. Wiley.
Kok, K., & Venekamp, G. (2010). Market-based control decentralized power systems.
Proceedings First International Workshop Agent Technology Energy
Systems.
Li, H., & Tesfatsion, L. (2009). Development open source software power market
research: AMES test bed. Journal Energy Markets, 2 (2), 111128.
Lund, H., & Kempton, W. (2008). Integration renewable energy transport
electricity sectors V2G. Energy Policy, 36 (9), 35783587.
Ramchurn, S., Vytelingum, P., Rogers, A., & Jennings, N. R. (2011a). Agent-based control
decentralised demand side management smart grid. Proceedings
Tenth International Conference Autonomous Agents Multi-Agent Systems, pp.
512.
Ramchurn, S., Vytelingum, P., Rogers, A., & Jennings, N. R. (2011b). Agent-based homeostatic control green energy smart grid. ACM Trans. Intelligent Systems
Technology, 2 (4).
Ramchurn, S., Vytelingum, P., Rogers, A., & Jennings, N. R. (2011c). Putting smarts
smart grid:a grand challenge artificial intelligence. Communication
ACM (to appear).
Rogers, A., & Jennings, N. R. (2010). Intelligent agents smart grid. PerAda Magazine, 10.2417/2201005.003002.
Schweppe, F., Tabors, R., Kirtley, J., Outhred, H., Pickel, F., & Cox, A. (1980). Homeostatic
utility control. IEEE Trans. Power Apparatus Systems, 99 (3), 1151 1163.
812

fiTheoretical Practical Foundations Agent-Based Micro-Storage

Schweppe, F. (1988). Spot pricing electricity. Kluwer academic publishers.
Shibata, A., & Sato, K. (1999). Development vanadium redox flow battery electricity
storage. Power Engineering Journal, 13 (3), 130 135.
Smith, K. (2010). Energy Demand Research Project - Fifth Progress Report. Tech. rep.,
OFGEM, UK. http://www.ofgem.gov.uk/Pages/MoreInformation.aspx?docid\
=19\&refer=sustainability/edrp.
Sovacool, B. K., & Hirsh, R. F. (2009). Beyond batteries: examination benefits
barriers plug-in hybrid electric vehicles (phevs) vehicle-to-grid (v2g)
transition. Energy Policy, 37 (3), 1095 1103.
Sun, J., & Tesfatsion, L. (2007). DC optimal power flow formulation solution using
QuadProgJ. ISU Economics Working Paper No. 06014.
Swider, D. (2007). Compressed air energy storage electricity system significant
wind power generation. IEEE trans. energy conversion, 22 (1), 95.
US Department Energy (2003). Grid 2030: National Vision Electricitys Second
100 Years.. http://www.oe.energy.gov/smartgrid.htm.
van Dam, K. H., Houwing, M., & Bouwmans, I. (2008). Agent-based control distributed
electricity generation micro combined heat powercross-sectoral learning
process infrastructure engineers. Computers & Chemical Engineering, 32 (1-2),
205 217.
Voice, T. D., Vytelingum, P., Ramchurn, S., Rogers, A., & Jennings, N. R. (2011). Decentralised control micro-storage smart grid. Proceedings 25th
International Conference AI (AAAI).
Vytelingum, P., Voice, T. D., Ramchurn, S., Rogers, A., & Jennings, N. R. (2010). Agentbased micro-storage management smart grid. Proceedings Ninth
International Conference Autonomous Agents Multi-Agent Systems, pp. 39
46.
Weibull, J. W. (1995). Evolutionary Game Theory. MIT Press, Cambridge, MA.
Wellman, M., Reeves, D. M., Lochner, K. M., & Vorobeychik, Y. (2004). Price Prediction
Trading Agent Competition. Journal Artificial Intelligence Research, 21, 1936.
Williams, E. (1984). DINORWIG: Electric Mountain. Central Electricity Generating
Board.
Williams, J., & Wright, B. (1991). Storage Commodity Markets. UIT, Cambridge.
Ygge, F., Akkermans, J. M., Andersson, A., Krejic, M., & Boertjes, E. (1999). HOMEBOTS System Field Test: Multi-Commodity Market Predictive Power Load
Management. Proceedings Fourth International Conference Practical Application Intelligent Agents Multi-Agent Technology, Vol. 1, pp. 363382.
Ygge, F., & Akkermans, H. (1999). Decentralized markets versus central control: comparative study. Journal Artificial Intelligence Research, 11, 301333.

813

fiJournal Artificial Intelligence Research 42 (2011) 689-718

Submitted 06/11; published 12/11

Combining Evaluation Metrics via Unanimous
Improvement Ratio Application Clustering Tasks
Enrique Amigo
Julio Gonzalo

enrique@lsi.uned.es
julio@lsi.uned.es

UNED NLP & IR Group, Juan del Rosal 16
Madrid 28040, Spain

Javier Artiles

javier.artiles@qc.cuny.edu

Blender Lab, Queens College (CUNY),
65-30 Kissena Blvd, NY 11367, USA

Felisa Verdejo

felisa@lsi.uned.es

UNED NLP & IR Group, Juan del Rosal 16
Madrid 28040, Spain

Abstract
Many Artificial Intelligence tasks cannot evaluated single quality criterion
sort weighted combination needed provide system rankings. problem
weighted combination measures slight changes relative weights may produce
substantial changes system rankings. paper introduces Unanimous Improvement Ratio (UIR), measure complements standard metric combination criteria
(such van Rijsbergens F-measure) indicates robust measured differences
changes relative weights individual metrics. UIR meant elucidate
whether perceived difference two systems artifact individual metrics
weighted.
Besides discussing theoretical foundations UIR, paper presents empirical
results confirm validity usefulness metric Text Clustering problem, tradeoff precision recall based metrics results
particularly sensitive weighting scheme used combine them. Remarkably,
experiments show UIR used predictor well differences
systems measured given test bed also hold different test bed.

1. Introduction
Many Artificial Intelligence tasks cannot evaluated single quality criterion,
sort weighted combination needed provide system rankings. Many problems,
instance, require considering Precision (P) Recall (R) compare systems
performance. Perhaps common combining function F-measure (van Rijsbergen, 1974), includes parameter sets relative weight metrics;
= 0.5, metrics relative weight F computes harmonic mean.
problem weighted combination measures relative weights established
intuitively given task, time slight change relative weights may
produce substantial changes system rankings. reason behavior
overall improvement F often derives improvement one individual
c
2011
AI Access Foundation. rights reserved.

fiAmigo, Gonzalo, Artiles & Verdejo

metrics expense decrement other. instance, system improves
system B precision loss recall, F may say better B viceversa,
depending relative weight precision recall (i.e. value).
situation common one might expect. Table 1 shows evaluation results
different tasks extracted ACL 2009 (Su et al., 2009) conference proceedings,
P R combined using F-measure. paper considered
three evaluation results: one maximizes F, presented best result
paper, baseline, alternative method also considered. Note
cases, top ranked system improves baseline according F-measure,
cost decreasing one metrics. instance, case paper Word
Alignment, average R grows 54.82 72.49, P decreases 72.76 69.19.
paper Sentiment Analysis, P increases four points R decreases five points.
reasonable assume contrastive system indeed improving baseline?
evaluation results alternative approach also controversial: cases,
alternative approach improves best system according one metric, improved according other. Therefore, depending relative metric weighting,
alternative approach could considered better worse best scored system.
conclusion parameter crucial comparing real systems.
practice, however, authors set = 0.5 (equal weights precision recall)
standard, agnostic choice requires justification. Thus, without notion
much perceived difference systems depends relative weights
metrics, interpretation results F combination scheme
misleading.
goal is, therefore, find way estimating extent perceived difference
using metric combination scheme F robust changes relative
weights assigned individual metric.
paper propose novel measure, Unanimity Improvement Ratio (UIR),
relies simple observation: system improves system B according
individual metrics (the improvement unanimous), better B weighting
scheme. Given test collection n test cases, test cases improvements
unanimous, robust perceived difference (average difference F
combination scheme) be.
words, well statistical significance tests provide information
robustness evaluation across test cases (Is perceived difference two systems
artifact set test cases used test collection? ), UIR meant provide
information robustness evaluation across variations relative metric
weightings (Is perceived difference two systems artifact relative metric
weighting chosen evaluation metric? ).
experiments clustering test collections show UIR contributes analysis
evaluation results two ways:
allows detect system improvements biased metric weighting
scheme. cases, experimenters carefully justify particular choice
relative weights check whether results swapped vicinity.
690

fiCombining Evaluation Metrics via Unanimous Improvement Ratio

Systems
Precision Recall
F
Task: Word alignment (Huang 2009)
Baseline
BM
72.76
54.82 62.53
Max. F
Link-Select
69.19
72.49 70.81
Alternative

72.66
66.17 69.26
Task: Opinion Question Answering (Li et al. 2009)
Baseline
System 3
10.9
21.6
17.2
Max. F
OpHit
10.2
25.6
20.5
Alternative
OpPageRank
10.9
24.2
20
Task: Sentiment Analysis (Kim et al 2009)
Baseline
BASELINE
30.5
86.6
45.1
Max. F
VS-LSA-DTP
34.9
71.9
47
Alternative
VS PMI
31.1
83.3
45.3
Task: Lexical Reference Rule Extraction (Shnarch et al 2009)
Baseline
expansion
54
19
28
Max. F
Wordnet+Wiki
47
35
40
Alternative rules + Dice filter
49
31
38
Table 1: three-way system comparisons taken ACL 2009 Conference Proceedings (Su et al., 2009)

increases substantially consistency evaluation results across datasets: result
supported high Unanimous Improvement Ratio much likely hold
different test collection. is, perhaps, relevant practical application
UIR: predictor much result replicable across test collections.
Although work presented paper applies research areas,
focus clustering task one relevant examples clustering
tasks specially sensitive metric relative weightings. research goals are:
1. investigate empirically whether clustering evaluation biased precision
recall relative weights F. use one recent test collections
focused text clustering problem (Artiles, Gonzalo, & Sekine, 2009).
2. introduce measure quantifies robustness evaluation results across
metric combining criteria, leads us propose UIR measure, derived
Conjoint Measurement Theory (Luce & Tukey, 1964).
3. analyze empirically UIR F-measure complement other.
4. illustrate application UIR comparing systems context shared
task, measure UIR serves predictor consistency evaluation
results across different test collections.

691

fiAmigo, Gonzalo, Artiles & Verdejo

Figure 1: Evaluation results semantic labeling CoNLL 2004

2. Combining Functions Evaluation Metrics
section briefly review different metrics combination criteria. present
rationale behind metric weighting approach well effects systems ranking.
2.1 F-measure
frequent way combining two evaluation metrics F-measure (van Rijsbergen, 1974). originally proposed evaluation Information Retrieval systems
(IR), use expanded many tasks. Given two metrics P R (e.g.
precision recall, Purity Inverse Purity, etc.), van Rijsbergens F-measure combines
single measure efficiency follows:
F (R, P ) =

( P1 )

1
+ (1 )( R1 )

F assumes value set particular evaluation scenario. parameter
represents relative weight metrics. cases value crucial;
particular, metrics correlated. instance, Figure 1 shows precision
recall levels obtained CoNLL-2004 shared task evaluating Semantic Role Labeling
systems (Carreras & Marquez, 2004). Except one system, every substantial improvement
precision involves also increase recall. case, relative metric weighting
substantially modify system ranking.
cases metrics completely correlated, Decreasing Marginal Effectiveness property (van Rijsbergen, 1974) ensures certain robustness across values. F
satisfies property, states large decrease one metric cannot compensated large increase metric. Therefore, systems low precision
recall obtain low F-values value. discussed detail Section 5.1. However, show Section 3.4, cases Decreasing Marginal
692

fiCombining Evaluation Metrics via Unanimous Improvement Ratio

Effectiveness property prevent F-measure overly sensitive small
changes value.

Figure 2: example two systems evaluated break-even point

2.2 Precision Recall Break-even Point
Another way combining metrics consists evaluating system point one
metric equals (Tao Li & Zhu, 2006). method applicable system
represented trade-off metrics, instance, precision/recall curve.
method relies idea increasing metrics implies necessarily overall
quality increase. instance, assumes obtaining 0.4 precision recall
point 0.4 better obtaining 0.3 precision recall point 0.3.
Actually, break-even point assumes relevance metrics. considers
precision/recall point system distributes efforts equitably
metrics. Indeed, could change relative relevance metrics computing
break-even point.
Figure 2 illustrates idea. continuous curve represents trade-off
precision recall system S1. straight diagonal represents points
metrics return score. quality system corresponds therefore
intersection diagonal precision/recall curve. hand,
discontinuous curve represents another system S2 achieves increase precision
low recall levels cost decreasing precision high recall levels. According
break-even points, second system superior first one.
However, could give relevance recall identifying point recall doubles
precision. case, would obtain intersection points Q01 Q02 shown
figure, reverses quality order systems. conclusion, break-even
point also assumes arbitrary relative relevance combined metrics.
2.3 Area Precision/Recall Curve
approaches average scores every potential parameterization metric combining function. instance, Mean Average Precision (MAP) oriented IR systems,
693

fiAmigo, Gonzalo, Artiles & Verdejo

computes average precision across number recall levels. Another example
Receiver Operating Characteristic (ROC) function used evaluate binary classifiers
(Cormack & Lynam, 2005). ROC computes probability positive sample receives
confidence score higher negative sample, independently threshold used
classify samples. functions related area AUC exists
precision/recall curve (Cormack & Lynam, 2005).
MAP ROC low high recall regions relative relevance
computing area. Again, could change measures order assign different
weights high low recall levels. Indeed (Weng & Poon, 2008) weighted Area
Curve proposed. Something similar would happen average F across different
values.
Note measures applied certain kinds problem, binary
classification document retrieval, system output seen ranking,
different cutoff points ranking give different precision/recall values.
directly applicable, particular, clustering problem focus work
here.

3. Combining Metrics Clustering Tasks
section present metric combination experiments specific clustering task.
results corroborate importance quantifying robustness systems across different
weighting schemes.
3.1 Clustering Task
Clustering (grouping similar items) applications wide range Artificial Intelligence
problems. particular, context textual information access, clustering algorithms
employed Information Retrieval (clustering text documents according content
similarity), document summarization (grouping pieces text order detect redundant
information), topic tracking, opinion mining (e.g. grouping opinions specific topic),
etc.
scenarios, clustering distributions produced systems usually evaluated
according similarity manually produced gold standard (extrinsic evaluation).
wide set metrics measure similarity (Amigo, Gonzalo, Artiles, &
Verdejo, 2008), rely two quality dimensions: (i) extent items
cluster also belong group gold standard; (ii)
extent items different clusters also belong different groups gold standard.
wide set extrinsic metrics proposed: Entropy Class Entropy (Steinbach,
Karypis, & Kumar, 2000; Ghosh, 2003), Purity Inverse Purity (Zhao & Karypis, 2001),
precision recall Bcubed metrics (Bagga & Baldwin, 1998), metrics based counting
pairs (Halkidi, Batistakis, & Vazirgiannis, 2001; Meila, 2003), etc.1

1. See work Amigo et al. (2008) detailed overview.

694

fiCombining Evaluation Metrics via Unanimous Improvement Ratio

3.2 Dataset
WePS (Web People Search) campaigns focused task disambiguating person
names Web search results. input systems ranked list web pages retrieved
Web search engine using person name query (e.g. John Smith).
challenge correctly estimate number different people sharing name
search results group documents referring individual. every person
name, WePS datasets provide around 100 web pages top search results, using
quoted person name query. order provide different ambiguity scenarios, person
names sampled US Census, Wikipedia, listings Program Committee
members Computer Science Conferences.
Systems evaluated comparing output gold standard: manual grouping
documents produced two human judges two rounds (first annotated corpus
independently discussed disagreements together). Note single
document assigned one cluster: Amazon search results list,
instance, may refer books written different authors name. WePS
task is, therefore, overlapping clustering problem, general case clustering
items restricted belong one single cluster. WePS datasets
official evaluation metrics reflect fact.
experiments focused evaluation results obtained WePS-1
(Artiles, Gonzalo, & Sekine, 2007) WePS-2 (Artiles et al., 2009) evaluation campaigns.
WePS-1 corpus also includes data Web03 test bed (Mann, 2006),
used trial purposes follows similar annotation guidelines, although number
document per ambiguous name variable. refer corpora WePS-1a
(trial), WePS-1b WePS-2 2 .
3.3 Thresholds Stopping Criteria
clustering task involves three main aspects determine systems output quality.
first one method used measuring similarity documents; second
clustering algorithm (k-neighbors, Hierarchical Agglomerative Clustering, etc.);
third aspect considered usually consists couple related variables fixed:
similarity threshold two pages considered related stopping
criterion determines clustering process stops and, consequently, number
clusters produced system.
Figure 3 shows Purity Inverse Purity values change different clustering
stopping points, one systems evaluated WePS-1b corpus 3 . Purity focuses
frequency common category cluster (Amigo et al., 2008).
C set clusters evaluated, L set categories (reference distribution)
2. WePS datasets selected experiments (i) address relevant well-defined
clustering task; (ii) use widespread: WePS datasets used hundreds experiments
since first WePS evaluation 2007; (iii) runs submitted participants WePS-1 WePS-2
available us, essential experiment different evaluation measures. WePS datasets
freely available http://nlp.uned.es/weps.
3. system based bag words, TF/IDF word weighting, stopword removal, cosine distance
Hierarchical Agglomerative Clustering algorithm.

695

fiAmigo, Gonzalo, Artiles & Verdejo

N number clustered items, Purity computed taking weighted average
maximal precision values:
Purity =

X |Ci |


N

maxj Precision(Ci , Lj )

precision cluster Ci given category Lj defined as:
|Ci Lj |
Precision(Ci , Lj ) =
|Ci |


Purity penalizes noise cluster, reward grouping items
category together; simply make one cluster per item, reach trivially
maximum purity value. Inverse Purity focuses cluster maximum recall
category. Inverse Purity defined as:
Inverse Purity =

X |Li |


N

maxj Precision(Li , Cj )

Inverse Purity rewards grouping items together, penalize mixing items
different categories; reach maximum value Inverse purity making single
cluster items.
change stopping point implies increase Purity cost decrease
Inverse Purity, viceversa. Therefore, possible value F rewards different stopping
points. phenomenon produces high dependency clustering evaluation results
metric combining function.

Figure 3: example trade-off Purity Inverse Purity optimizing
grouping threshold

696

fiCombining Evaluation Metrics via Unanimous Improvement Ratio

3.4 Robustness Across Values
Determining appropriate value given scenario trivial. instance,
users point view WePS task, easier discard irrelevant documents
good cluster (because precision perfect high recall)
check additional relevant documents clusters (because precision high
recall not). Therefore, seems Inverse Purity priority Purity,
i.e., value 0.5. point view company providing
web people search service, however, situation quite different: priority
high precision, mixing profiles of, say, criminal doctor may result
company sued. perspective, receive high value.
WePS campaign decided agnostic set neutral = 0.5 value.
Table 2 shows resulting system ranking WePS-1b according F set 0.5
0.2. ranking includes two baseline systems: B1 consists grouping document
separate cluster, B100 consists grouping documents one single cluster.
B1 maximizes Purity, B100 maximizes Inverse Purity.
B1 B100 may obtain high low F-measure depending value.
table shows, = 0.5 B1 outperforms B100 also considerable number systems.
reason result that, WePS-1b test set, many singleton clusters
(people referred one web page). means default strategy
making one cluster per document achieve maximal Purity, also
acceptable Inverse Purity (0.45). However, fixed 0.2, B1 goes bottom
ranking outperformed systems, including baseline B100 .
Note outperforming trivial baseline system B1 crucial optimize
systems, given optimization cycle could otherwise lead baseline approach like
B1 . drawback B1 informative (the output depend
input) and, crucially, sensitive variations . words, performance
robust changes metric combination criterion. Remarkably, top scoring
system, S1 , best values. primary motivation article
quantify robustness across values order complement information given
traditional system ranking.
3.5 Robustness Across Test Beds
average size clusters gold standard may change one test bed
another. affects Purity Inverse Purity trade-off, clustering system
may obtain different balance metrics different corpora; may
produce contradictory evaluation results comparing systems across different corpora,
even value.
instance, WePS-1b test bed (Artiles et al., 2007), B1 substantially outperforms
B100 (0.58 vs. 0.49 using F=0.5 ). WePS-2 data set (Artiles et al., 2009), however,
B100 outperforms B1 (0.53 versus 0.34). reason singletons less common
WePS-2. words, comparison B100 B1 depends value
particular distribution reference cluster sizes test bed.
point system improvements robust across values (which
case B1 B100 ) affected phenomenon. Therefore, estimating
697

fiAmigo, Gonzalo, Artiles & Verdejo

F=0.5
Ranked systems F result
S1
0.78
S2
0.75
S3
0.75
S4
0.67
S5
0.66
S6
0.65
S7
0.62
B1
0.61
S8
0.61
S9
0.58
S10
0.58
S11
0.57
S12
0.53
S13
0.49
S14
0.49
S15
0.48
B100
0.4
S16
0.4

F0.2
Ranked systems
S1
S3
S2
S6
S5
S8
S11
S7
S14
S15
S12
S9
S13
S4
S10
B100
S16
B1

F result
0.83
0.78
0.77
0.76
0.73
0.73
0.71
0.67
0.66
0.66
0.65
0.64
0.63
0.62
0.6
0.58
0.56
0.49

Table 2: WePS-1b system ranking according F=0.5 vs F=0.2 using Purity Inverse
Purity

robustness system improvements changes prevent reaching contradictory
results different test beds. Indeed, evidence presented Section 7.

4. Proposal
primary motivation article quantify robustness across values
order complement information given traditional system rankings. end
introduce section Unanimous Improvement Ratio.
4.1 Unanimous Improvements
problem combining evaluation metrics closely related theory conjoint
measurement (see Section 5.1 detailed discussion). Van Rijsbergen (1974) argued
possible determine empirically metric combining function
adequate context Information Retrieval evaluation. However, starting
measurement theory principles, van Rijsbergen described set properties metric
combining function satisfy. set includes Independence axiom (also called
Single Cancellation), Monotonicity property derives. Monotonicity
property states quality system surpasses equals another one according
metrics necessarily equal better other. words, one system
698

fiCombining Evaluation Metrics via Unanimous Improvement Ratio

better dependence whatsoever relative importance
metric set.
define combination procedure metrics, Unanimous Improvement,
based property:
QX (a) QX (b) x X.Qx (a) Qx (b)
QX (a) quality according set metrics X.
relationship dependence metrics scaled weighted,
degree correlation metric set. Equality (= ) derived directly :
unanimous equality implies systems obtain score metrics:
QX (a) = QX (b) (QX (a) QX (b)) (QX (b) QX (a))

strict unanimous improvement implies one system improves strictly
least one metric, improved according metric:
QX (a) > QX (b) (QX (a) QX (b)) (QX (a) = QX (b))
(QX (a) QX (b)) (QX (b) QX (a))

Non comparability k also derived here: occurs metrics favor one
system metrics favor other. refer cases metric-biased
improvements.
QX (a)k QX (b) (QX (a) QX (b)) (QX (b) QX (a))

theoretical properties Unanimous Improvement described depth
Section 5.2. important property Unanimous Improvement
relational structure depend relative metric weightings, satisfying
Independence (Monotonicity) axiom. words, claim that: system improvement according metric combining function depend whatsoever metric
weightings quality decrease according individual metric.
theoretical justification assertion developed Section 5.2.1.
4.2 Unanimous Improvement Ratio
According Unanimous Improvement, unique observable test case
three-valued function (unanimous improvement, equality biased improvement). need,
however, way quantitatively comparing systems.
Given two systems, b, Unanimous Improvement relationship set
test cases , samples improves b (QX (a) QX (b)), samples b improves (QX (b) QX (a)) also samples biased improvements (QX (a)k QX (b)).
refer sets Ta b , Tb Tak b , respectively. Unanimous Improvement Ratio (UIR) defined according three formal restrictions:
699

fiAmigo, Gonzalo, Artiles & Verdejo

Test cases
1
2
3
4
5
6
7
8
9
10

Precision
System System B
0.5
0.5
0.5
0.5
0.5
0.4
0.6
0.6
0.7
0.6
0.3
0.1
0.4
0.5
0.4
0.6
0.3
0.1
0.2
0.4

Recall
System System B
0.5
0.5
0.2
0.2
0.2
0.2
0.4
0.3
0.5
0.4
0.5
0.4
0.5
0.6
0.5
0.6
0.5
0.6
0.5
0.3

B
YES
YES
YES
YES
YES
YES





B
YES
YES




YES
YES



Table 3: Example experiment input compute UIR
1. UIR(a, b) decrease number biased improvements (Tak b ).
boundary condition samples biased improvements (Tak b = ),
UIR(a, b) 0.
2. improves b much b improves (Ta b = Tb ) UIR(a, b) = 0.
3. Given fixed number biased improvements (Tak b ), UIR(a, b) proportional
Ta b inversely proportional Tb .
Given restrictions, propose following UIR definition:
UIRX,T (a, b) =

|Ta b | |Tb |
=
|T |

|t /QX (a) QX (b)| |t /QX (b) QX (a)|
|T |
alternatively formulated as:
UIRX,T (a, b) = P(a b) P(b a)
probabilities estimated frequentist manner.
UIR range [1, 1] symmetric: UIRX,T (a, b) = UIRX,T (b, a).
illustration UIR computed, consider experiment outcome Table 3. Systems
B compared terms precision recall 10 test cases. test case 5,
instance, unanimous improvement B: better terms precision
(0.7 > 0.6) recall (0.5 > 0.4). table, UIR value is:
UIRX,T (A, B) =

|TA B | |TB |
64
=
= 0.2 = UIRX,T (B, A)
|T |
10

UIR two formal limitations. First, transitive (see Section 5.2). Therefore,
possible define linear system ranking based UIR. is, however,
700

fiCombining Evaluation Metrics via Unanimous Improvement Ratio

necessary: UIR meant provide ranking, complement ranking provided
F-measure (or metric combining function), indicating robust results
changes . Section 6.4 illustrates UIR integrated insights provided
system ranking.
second limitation UIR consider improvement ranges; therefore,
less sensitive F-measure. empirical results, however, show UIR
sensitive enough discriminate robust improvements versus metric-biased improvements;
Section 8 make empirical comparison non-parametric definition UIR
parametric version, results make non-parametric definition preferable.

5. Theoretical Foundations
section discuss theoretical foundations Unanimous Improvement Ratio
framework Conjoint Measurement Theory. proceed describe
formal properties UIR implications point view evaluation
methodology. Readers interested solely practical implications using UIR may
proceed directly Section 6.
5.1 Conjoint Measurement Theory
problem combining evaluation metrics closely related Conjoint Measurement Theory, independently discovered economist Debreu (1959)
mathematical psychologist R. Duncan Luce statistician John Tukey (Luce & Tukey,
1964). Theory Measurement defines necessary conditions state homomorphism empirical relational structure (e.g. John bigger Bill)
numeric relational structure (Johns height 1.79 meters Bills height 1.56 meters).
case Conjoint Measurement Theory, relational structure factored
two (or more) ordered substructures (e.g. height weight).
context, numerical structures given evaluation metric scores (e.g.
Purity Inverse Purity). However, empirical quality ordering
clustering systems. Different human assessors could assign relevance Purity
Inverse Purity viceversa. Nevertheless, Conjoint Measurement Theory provide
mechanisms state kind numerical structures produce homomorphism
assuming empirical structure satisfies certain axioms. Van Rijsbergen (1974) used
idea analyze problem combining evaluation metrics. axioms shape
additive conjoint structure. (R, P ) quality system according two evaluation
metrics R P , axioms are:
Connectedness: systems comparable other. Formally: (R, P )
(R0 , P 0 ) (R0 , P 0 ) (R, P ).
Transitivity: (R, P ) (R0 , P 0 ) (R0 , P 0 ) (R00 , P 00 ) implies (R, P ) (R00 , P 00 ).
axioms Transitivity Connectedness shape weak order.
Thomsen condition: (R1 , P3 ) (R3 , P2 ) (R3 , P1 ) (R2 , P3 ) imply (R1 , P1 )
(R2 , P2 ) (where indicates equal effectiveness).
701

fiAmigo, Gonzalo, Artiles & Verdejo

Independence: two components contribute effects independently effectiveness. Formally, (R1 , P ) (R2 , P ) implies (R1 , P 0 ) (R2 , P 0 ) P 0 ,
(R, P1 ) (R, P2 ) implies (R0 , P2 ) (R0 , P2 ) R0 . property implies
Monotonicity (Narens & Luce, 1986) states improvement metrics necessarily produces improvement according metric combining function.
Restricted Solvability: property ... concerned continuity
component. makes precise intuitively would expect considering
existence intermediate levels. Formally: whenever (R1 , P 0 ) (R, P ) (R2 , P 0 )
exists R (R0 , P 0 ) = (R, P ).
Essential Components: Variation one leaving constant gives variation effectiveness. exists R, R0 P case
(R, P ) = (R0 , P ); exists P , P 0 R case
(R, P ) = (R, P 0 ).
Archimedean Property: merely ensures intervals component
comparable.
F-measure proposed van Rijsbergen (1974) arithmetic mean P,R
satisfy axioms. According restrictions, indeed, unlimited set acceptable combining functions evaluation metrics defined. F relational structure,
however, satisfies another property satisfied functions
arithmetic mean. property Decreasing Marginal Effectiveness. basic idea
increasing one unit one metric decreasing one unit metric
improve overall quality (i.e. first metric weight combining function), imply great loss one metric compensated great
increase other. defined as:
R, P > 0, n > 0 ((P + n, R n) < (R, P ))
According this, high values metrics required obtain high overall
improvement. makes measures observing property - F - robust
arbitrary metric weightings.
5.2 Formal Properties Unanimous Improvement
Unanimous Improvement x trivially satisfies desirable properties proposed van Rijsbergen (1974) metric combining functions: transitivity, independence,
Thomsen condition, Restricted Solvability, Essential Components Decreasing Marginal
Effectiveness; exception connectedness property4 . Given non comparability k (biased improvements, see Section 4.1) derived Unanimous Improvement, possible find system pairs neither QX (a) QX (b) QX (b) QX (a)
hold. Therefore, Connectedness satisfied.
Formally, limitation Unanimous Improvement represent
weak order, cannot satisfy Transitivity Connectedness simultaneously. Let
us elaborate issue.
4. sake simplicity, consider combination two metrics (R, P ).

702

fiCombining Evaluation Metrics via Unanimous Improvement Ratio

Systems

B
C

Metric x1
0.5
0.6
0.45

Metric x2
0.5
0.4
0.45

Table 4: counter sample Transitivity Unanimous Improvement
could satisfy Connectedness considering biased improvements represent
equivalent system pairs (= ). case, Transitivity would satisfied. See,
instance, Table 4. According table:
QX (B)k QX (A) QX (C)k QX (B)
Therefore, considering k represents equivalence, have:
QX (B) QX (A) QX (C) QX (B)

QX (C) QX (A)
summary, choose satisfy transitivity connectedness, both:
Unanimous Improvement derive weak order.
5.2.1 Uniqueness Unanimous Improvement
Unanimous Improvement interesting property contradict
evaluation result given F-measure, regardless value used F:
QX (a) QX (b) F (a) F (b)
due fact F-measure (for value) satisfies monotonicity
axiom, Unanimous Improvement grounded. property essential
purpose checking robustness system improvements across values.
crucially, Unanimous Improvement function satisfies property.
precisely, Unanimous Improvement relational structure that, satisfying
monotonicity, contradict Additive Conjoint Structure (see Section 5.1).
order prove assertion, need define concept compatibility
additive conjoint structure. Let add additive conjoint structure let R
relational structure. say R compatible conjoint structure
if:
ha, b, add i.(QX (a) R QX (b)) (QX (a) add QX (b))
words: R holds, additive conjoint holds. want prove
unanimous improvement relation satisfies property; therefore,
prove R monotonic compatible relational structure,
necessarily matches unanimous improvement definition:
703

fiAmigo, Gonzalo, Artiles & Verdejo

R monotonic compatible = (QX (a) R QX (b) xi (a) xi (b)xi X)
split in:
(1) R monotonic compatible = (QX (a) R QX (b) xi (a) xi (b)xi X)
(2) R monotonic compatible = (QX (a) R QX (b) xi (a) xi (b)xi X)
Proving (1) immediate, since rightmost component corresponds monotonicity property definition. Let us prove (2) reductio ad absurdum, assuming
exists relational structure that:
(o monotonic compatible) (QX (a) QX (b)) (xi X.xi (a) < xi (b))
case, could define additive conjoint structure combined measure
Q0X (a) = 1 x1 (a)+..i xi (a)..+n xn (a) big enough Q0X (a) < Q0X (b).
Q0 additive conjoint structure would contradict . Therefore, would compatible
(contradiction). conclusion, predicate (2) true Unanimous Improvement X
monotonic compatible relational structure.
interesting corollary derived analysis. Unanimous Improvement compatible relational structure, formally conclude
measurement system improvements without dependence metric weighting schemes
derive weak order (i.e. one satisfies transitivity connectedness).
corollary practical implications: possible establish system ranking
independent metric weighting schemes.
natural way proceed is, therefore, use unanimous improvement addition
standard F-measure (for suitable value) provides additional information
robustness system improvements across values.

6. F versus UIR: Empirical Study
Section perform number empirical studies WePS corpora order
find UIR behaves practice. First, focus number empirical results
show UIR rewards robustness across values, information complementary information provided F. Second, examine extent F
UIR correlated.
6.1 UIR: Rewarding Robustness
Figure 4 shows three examples system comparisons WePS-1b corpus using metrics
Purity Inverse Purity. curve represents F value obtained one system
according different values. System S6 (black curves) compared S10, S9
S11 (grey curves) three graphs. cases similar quality increase
according F=0.5 ; UIR, however, ranges 0.32 0.42, depending robust
difference changes . highest difference UIR (S6,S11) system
pair (rightmost graph), systems swap F values value.
704

fiCombining Evaluation Metrics via Unanimous Improvement Ratio

| 4 F=0.5 |
|UIR|

Improvements

(28 system pairs)
0.12
0.53

cases
(125 system pairs)
0.13
0.14

Table 5: UIR F=0.5 increase F increases values

Figure 4: F-measure vs. UIR: rewarding robustness
smallest UIR value (S6,S10), S6 better S10 values
0.8, worse larger. comparison illustrates UIR captures, similar
increments F, ones less dependent relative weighting scheme
precision recall.
Let us consider two-system combinations WePS-1b corpus, dividing
two sets: (i) system pairs F increases values (i.e. Purity
Inverse Purity increases), (ii) pairs relative systems performance swaps
value; i.e. F increases values decreases rest.
One would expect average increase F larger system pairs
one beats every value. Surprisingly, true: Table 5 shows
average increments UIR F=0.5 sets. UIR behaves expected: average
value substantially larger set different lead contradictory results
(0.53 vs. 0.14). average relative increase F=0.5 , however, similar
sets (0.12 vs. 0.13).
conclusion certain F=0.5 improvement range say anything
whether Purity Inverse Purity simultaneously improved not.
words: matter large measured improvement F is, still extremely
dependent weighting individual metrics measurement.
conclusion corroborated considering independently metrics (Purity Inverse Purity). According statistical significance improvements
independent metrics, distinguish three cases:
1. Opposite significant improvements: One metrics (Purity Inverse Purity)
increases decreases, changes statistically significant.
705

fiAmigo, Gonzalo, Artiles & Verdejo

| 4 F=0.5 |
|UIR|

Significant
concordant
improvements
53 pairs
0.11
0.42

Significant
opposite
improvements
89 pairs
0.15
0.08

Non
significant
improvements
11 pairs
0.05
0.027

Table 6: UIR F=0.5 increases vs. statistical significance tests
2. Concordant significant improvements: metrics improve significantly least
one improves significantly decrease significantly.
3. Non-significant improvements: statistically significant differences
systems metric.
use Wilcoxon test p < 0.05 detect statistical significance. Table 6
shows average UIR | 4 F=0.5 | values three cases. Remarkably,
F=0.5 average increase even larger opposite improvements set (0.15)
concordant improvements set (0.11). According results, would seem
F=0.5 rewards individual metric improvements obtained cost (smaller)
decreases metric. UIR, hand, sharply different behavior,
strongly rewarding concordant improvements set (0.42 versus 0.08).
results confirm UIR provides essential information experimental
outcome two-system comparisons, provided main evaluation metric
F .
6.2 Correlation F UIR
fact UIR F offer different information outcome experiment
imply UIR F orthogonal; fact, correlation
values.
Figure 5 represents F=0.5 differences UIR values possible system pair
WePS-1 test bed. general trends (i) high UIR values imply positive difference
F (ii) high |4F0,.5 | values imply anything UIR values; (iii) low UIR seem
imply anything |4F0,.5 | values. Overall, figure suggest triangle relationship,
gives Pearson correlation 0.58.
6.2.1 Reflecting improvement ranges
consistent difference two systems values, UIR rewards
larger improvement ranges. Let us illustrate behavior considering three sample system
pairs taken WePS-1 test bed.
Figure 6 represents F[0,1] values three system pairs. cases, one system
improves values. However, UIR assigns higher values larger improvements F (larger distance black grey curves). reason
706

fiCombining Evaluation Metrics via Unanimous Improvement Ratio

Figure 5: |4F0,.5 | vs UIR

Figure 6: F vs. UIR: reflecting improvement ranges
larger average improvement test cases makes less likely cases individual test
cases (which ones UIR considers) contradict average result.
Another interesting finding that, metrics improved, metric
weakest improvement determines behavior UIR. Figure 7 illustrates
relationship ten system pairs largest improvement; Pearson correlation
graph 0.94. words, individual metrics improve, UIR sensitive
weakest improvement.
6.2.2 Analysis boundary cases
order better understanding relationship UIR F,
examine detail two cases system improvements UIR F produce drastically
different results. two cases marked B Figure 5.
point marked case Figure corresponds comparison systems
S1 S15 . exists substantial (and statistically significant) difference
systems according F=0.5 . However, UIR low value, i.e., improvement
robust changes according UIR.
707

fiAmigo, Gonzalo, Artiles & Verdejo

Figure 7: Correlation UIR weakest single metric improvement.

Figure 8: Purity Inverse Purity per test case, systems S1 S1 5
visual explanation results seen Figure 8. shows Purity
Inverse Purity results systems S1 , S15 every test case. test cases, S1
important advantage Purity cost slight consistent loss Inverse
Purity. Given F=0.5 compares Purity Inverse Purity ranges, states
exists important statistically significant improvement S15 S1 . However,
slight consistent decrease Inverse Purity affects UIR, decreases
test cases improvements F metric biased (k notation).
Case B (see Figure 9) opposite example: small difference systems
S8 S12 according F=0.5 , differences Purity Inverse Purity
also small. S8, however, gives small consistent improvements Purity Inverse
Purity (all test cases right vertical line figure); unanimous
improvements. Therefore, UIR considers exists robust overall improvement
case.
708

fiCombining Evaluation Metrics via Unanimous Improvement Ratio

Figure 9: Purity Inverse Purity per test case, systems S1 2 S8
Again, cases show UIR gives additional valuable information comparative behavior systems.
6.3 Significance Threshold UIR
mentioned earlier UIR parallelism statistical significance tests,
typically used Information Retrieval estimate probability p observed
difference two systems obtained chance, i.e., difference artifact
test collection rather true difference systems. computing
statistical significance, useful establish threshold allows binary decision;
instance, result often said statistically significant p < 0.05, significant
otherwise. Choosing level significance arbitrary, nevertheless helps reporting
summarizing significance tests. Stricter thresholds increase confidence test,
run increased risk failing detect significant result.
situation applies UIR: would like establish UIR threshold
decides whether observed difference reasonably robust changes . set
threshold? could restrictive decide, instance, improvement
significantly robust UIR 0.75. condition, however, hard would
never satisfied practice, therefore UIR test would informative.
hand, set permissive threshold satisfied system
pairs and, again, informative. question whether exists
threshold UIR values obtaining UIR threshold guarantees
improvement robust, and, time, strong satisfied practice.
Given set two-system combinations UIR surpasses certain candidate
threshold, think desirable features:
1. must able differentiate two types improvements (robust vs. nonrobust); words, one two types usually empty almost empty,
threshold informative.
709

fiAmigo, Gonzalo, Artiles & Verdejo

2. robust set contain high ratio two-system combinations
average F increases values (F (a) > F (b)).
3. robust set contain high ratio significant concordant improvements
low ratio significant opposite improvements (see Section 6.1).
4. robust set contain low ratio cases F contradicts UIR (the dots
Figure 5 region |4F0,.5 | < 0).

Figure 10: Improvement detected across UIR thresholds
Figure 10 shows conditions met every threshold range [0, 0.8].
UIR threshold 0.25 accepts around 30% system pairs, low (4%) ratio
significant opposite improvements high (80%) ratio significant concordant improvements. threshold, half robust cases F increases values,
cases (94%) F=0.5 increases. seems, therefore, UIR 0.25 reasonable
threshold, least clustering task. Note, however, rough rule thumb
revised/adjusted dealing clustering tasks WePS.
6.4 UIR System Rankings
results presented far focused pairwise system comparisons, according
nature UIR. turn question use UIR component
analysis results evaluation campaign.
order answer question applied UIR results WePS-2
evaluation campaign (Artiles et al., 2009). campaign, best runs system
ranked according Bcubed precision recall metrics, combined F=0.5 .
addition participant systems, three baseline approaches included ranking:
710

fiCombining Evaluation Metrics via Unanimous Improvement Ratio

documents one cluster (B100 ), document one cluster (B1 ) union
(BCOMB )5 .
Table 7 shows results applying UIR WePS-2 participant systems. -robust
improvements represented third column (improved systems): every system,
displays set systems improves UIR 0.25. fourth column
reference system, defined follows: given system a, reference system
one improves maximal UIR:
Sref (a) = ArgmaxS (UIR(S, a))
words, Sref (a) represents system replaced order
robustly improve results across different values. Finally, last column (UIR
reference system) displays UIR system reference (UIR(Sref , Si )).
Note UIR adds new insights evaluation process. Let us highlight two
interesting facts:
Although three top-scoring systems (S1, S2, S3) similar performance
terms F (0.82, 0.81 0.81), S1 consistently best system according UIR,
reference 10 systems (S2, S4, S6, S8, S12, S13, S14, S15,
S16 baseline B1 ). contrast, S2 reference S7 only, S3 reference
S11 only. Therefore, F UIR together strongly point towards S1 best
system, F alone able discern set three top-scoring systems.
Although non-informative baseline B100 (all documents one cluster) better
five systems according F, improvement robust according UIR.
Note UIR signal near-baseline behaviors participant systems low
value, receive large F depending nature test collection:
average cluster large small, systems tend cluster everything
nothing artificially rewarded. is, opinion, substantial improvement
using F alone.

7. UIR Predictor Stability Results across Test Collections
common issue evaluating systems deal Natural Language results
different test collections often contradictory. particular case Text Clustering,
factor contributes problem average size clusters vary across
different test beds, variability modifies optimal balance precision
recall. system tends favor precision, creating small clusters, may good
results dataset small average cluster size worse results test collection
larger average cluster size.
Therefore, apply F combine single metrics, reach contradictory
results different test beds. UIR depend metric weighting criteria,
hypothesis high UIR value ensures robustness evaluation results across test beds.
5. See work Artiles et al. (2009) extended explanation.

711

fiAmigo, Gonzalo, Artiles & Verdejo

System

F0.5

S1
S2
S3
S4
S5
S6
S7
S8
S9
S10
S11
S12
B100
S13

0,82
0,81
0,81
0,72
0,71
0,71
0,70
0,70
0,63
0,63
0,57
0,53
0,53
0,52
0,52
0,42
0,41
0,39
0,34
0,33

BCOMB
S14
S15
S16
B1
S17

Improved systems
(UIR > 0.25)
S2 S4 S6 S7 S8 S11..S17 B1
S4 S6 S7 S8 S11..S17 B1
S2 S4 S7 S8 S11..S17 B1
S11 S13..S17
S12..S16
S4 S7 S11 S13..S17 B1
S11 S13..S17
S11..S17
S4 S12 S14 S16
S12..S16
S14..S17
S14 S16
BCOMB
S15 S16
S16
S17
-

Reference
system
S1
S1
S1
S2
S1
S3
S1
S1
B100
S1
S1
S1
S1
S6

UIR
reference system
0,26
0,58
0,35
0,65
0,74
0,68
0,71
0,9
0,65
0,9
0,97
1,00
0,29
0,84

Table 7: WePS-2 results Bcubed precision recall, F UIR measures
words: given particular test bed, high UIR value good predictor
observed difference two systems still hold test beds.
following experiment designed verify hypothesis. implemented
four different systems WePS problem, based agglomerative clustering algorithm (HAC) used best systems WePS-2. system employs
certain cluster linkage technique (complete link single link) certain feature extraction criterion (word bigrams unigrams). system experimented 20
stopping criteria. Therefore, used 20x4 system variants overall. evaluated
systems WePS-1a, WePS-1b WePS-2 corpora6 .
first observation that, given system pairs, F=0.5 gives consistent results
three test beds 18% cases. system pairs, best system
different depending test collection. robust evaluation criterion predict,
given single test collection, whether results still hold collections.
consider two alternative ways predicting observed difference (system
better system B) one test-bed still hold three test beds:
first using F (A) F (B): larger value reference test bed,
likely F (A) F (B) still positive different test collection.
6. WEPS-1a originally used training first WePS campaign, WePS-1b used testing.

712

fiCombining Evaluation Metrics via Unanimous Improvement Ratio

second using U IR(A, B) instead F: larger UIR is, likely
F (A) F (B) also positive different test bed.
summary, want compare F UIR predictors robust result
change test collection. tested it:
1. select reference corpus WePS-1a, WePS-1b WePS-2 test beds.
Cref {WePS-1a,WePS-1b,WePS-2}
2. system pair reference corpus, compute improvement one
system respect according F UIR. take system pairs
one improves certain threshold t. UIRC (s1 , s2 )
UIR results systems s1 s2 test-bed C, FC (s) results F
system test-bed C:
SU IR,t (C) = {(s1 , s2 )|UIRC (s1 , s2 ) > t}
SF,t (C) = {s1 , s2 |(FC (s1 ) FC (s2 )) > t)}
every threshold t, SU IR,t SF,t represent set robust improvements
predicted UIR F, respectively.
3. Then, consider system pairs one improves according F
three test collections simultaneously.
= {s1 , s2 |FC (s1 ) > FC (s2 )C}
gold standard compared predictions SU IR,t SF,t .
4. every threshold t, compute precision recall UIR F predictions
(SU IR,t (C) SF,t (C)) versus actual set robust results across collections
(T ).
P recision(SU IR,t (C)) =

|SU IR,t (C) |
|SU IR,t |

P recision(SF,t (C)) =

|SF,t (C) |
|SF,t (C)|

Recall(SU IR,t (C)) =

Recall(SF,t (C)) =

|SU IR,t (C) |
|T |

|SF,t (C) |
|T |

trace precision/recall curve predictors F, UIR
compare results. Figures 11, 12 13, show precision/recall values F (triangles)
UIR (rhombi); figure displays results one reference test-beds: WEPS1a,WEPS-1b WePS-27 .
Altogether, figures show UIR much effective F predictor.
Note F suffers sudden drop performance low recall levels, suggests
7. curve parametric UIR refers alternative definition UIR explained Section 8

713

fiAmigo, Gonzalo, Artiles & Verdejo

Figure 11: Predictive power UIR F WePS-1a

Figure 12: Predictive power UIR F WePS-1b

714

fiCombining Evaluation Metrics via Unanimous Improvement Ratio

Figure 13: Predictive power UIR F WePS-2
big improvements F tend due peculiarities test collection rather
real superiority one system versus other.
is, opinion, remarkable result: differences UIR better indicators
reliability measured difference F amount measured difference.
Therefore, UIR useful know stable results changes , also
changes test collection, i.e., indicator reliable perceived difference
is.
Note explicitly tested dependency (and reliability) UIR results
number test cases reference collection. However, working
collection less 30 test cases unlikely, practical terms usability UIR
granted test collections, least respect number test cases.

8. Parametric versus Non-Parametric UIR
According analysis (see Section 5.2), given two measures P R, relational
structure pairs hPi , Ri depend weighting criteria unanimous
improvement:
b Pa Pb Ra Rb
comparing systems, UIR measure counts unanimous improvement results
across test cases:
UIRX,T (a, b) =

|Ta b | |Tb |
|T |

Alternatively, formulation expressed terms probabilities:
715

fiAmigo, Gonzalo, Artiles & Verdejo

UIRX,T (a, b) = Prob(a b) Prob(b a)
probabilities estimated frequentist manner.
said, main drawback unanimous improvement threevalued function consider metric ranges; UIR inherits drawback.
consequence, UIR less sensitive combining schemes F measure.
order solve drawback, could estimate UIR parametrically. However, results
section seem indicate best option.
One way estimating P rob(a b) P rob(b a) consists assuming
metric differences (P, R) two systems across test cases follow normal bivariate
distribution. estimate distribution case samples provided
test bed. estimating density function P rob(P, R), estimate P rob(a
b) as8 :
P rob(a b) = P rob(P 0 R 0) =

Z P =1,R=1

P rob(P, R) dP dR
P =0,R=0

expression used compute UIRX,T (a, b) = Prob(a b) Prob(b a),
leads parametric version UIR.
order compare effectiveness parametric UIR versus original UIR,
repeated experiment described Section 7, adding UIRparam precision/recall
curves Figures 11, 12 13. squares figures represent results
parametric version UIR. Note behavior lies somewhere F nonparametric UIR: low levels recall, behaves like original UIR; intermediate
levels, general worse original definition better F;
recall high-end, overlaps results F. probably due fact
parametric UIR estimation considers ranges, becomes sensitive unreliability
high improvements F.

9. Conclusions
work addressed practical problem strong dependency (and usually
degree arbitrariness) relative weights assigned metrics applying metric
combination criteria, F .
Based theory measurement, established relevant theoretical results: fundamental one monotonic relational structure
contradict Additive Conjoint Structure, unique relationship
transitive. implies possible establish ranking (a complete ordering) systems without assuming arbitrary relative metric weighting. transitive
relationship, however, necessary ensure robustness specific pairwise system
comparisons.
Based theoretical analysis, introduced Unanimous Improvement Ratio (UIR), estimates robustness measured system improvements across potential
metric combining schemes. UIR measure complementary metric combination
8. computation employed Matlab tool

716

fiCombining Evaluation Metrics via Unanimous Improvement Ratio

scheme works similarly statistical relevance test, indicating perceived difference two systems reliable biased particular weighting scheme used
evaluate overall performance systems.
empirical results text clustering task, particularly sensitive
problem, confirm UIR indeed useful analysis tool pairwise system comparisons: (i) similar increments F, UIR captures ones less dependent
relative weighting scheme precision recall; (ii) unlike F, UIR rewards system
improvements corroborated statistical significance tests single measure; (iii) practice, high UIR tends imply large F increase, large increase
F imply high UIR; words, large increase F completely
biased weighting scheme, therefore UIR essential information add F.
looking results evaluation campaign, UIR proved useful (i) discern
best system among set systems similar performance according F ;
(ii) penalize trivial baseline strategies systems baseline-like behavior.
Perhaps relevant result side effect proposed measure defined:
UIR good estimator robust result changes test collection.
words, given measured increase F test collection, high UIR value makes
likely increase also observed test collections. Remarkably, UIR
estimates cross-collection robustness F increases much better absolute value
F increase.
limitation present study tested UIR text clustering
problem. usefulness clustering problems already makes UIR useful analysis
tool, potential goes well beyond particular problem. Natural Language problems and, general, many problems Artificial Intelligence evaluated terms
many individual measures trivial combine. UIR powerful tool
many scenarios.
UIR evaluation package available download http://nlp.uned.es.

Acknowledgments
research partially supported Spanish Government (grant Holopedia,
TIN2010-21128-C02) Regional Government Madrid Research Network
MA2VICMR (S2009/TIC-1542).

References
Amigo, E., Gonzalo, J., Artiles, J., & Verdejo, F. (2008). comparison extrinsic clustering
evaluation metrics based formal constraints. Information Retrieval, 12 (4), 461486.
Artiles, J., Gonzalo, J., & Sekine, S. (2009). WePS-2 Evaluation Campaign: Overview
Web People Search Clustering Task. Proceedings 2nd Web People Search
Evaluation Workshop (WePS 2009).
Artiles, J., Gonzalo, J., & Sekine, S. (2007). SemEval-2007 WePS evaluation: Establishing Benchmark Web People Search Task. Proceedings 4th
International Workshop Semantic Evaluations, SemEval 07, pp. 6469 Stroudsburg, PA, USA. Association Computational Linguistics.
717

fiAmigo, Gonzalo, Artiles & Verdejo

Bagga, A., & Baldwin, B. (1998). Entity-Based Cross-Document Coreferencing Using
Vector Space Model. Proceedings 36th Annual Meeting Association
Computational Linguistics 17th International Conference Computational
Linguistics (COLING-ACL98), pp. 7985.
Carreras, X., & Marquez, L. (2004). Introduction CoNLL-2004 Shared Task: Semantic
Role Labeling. Ng, H. T., & Riloff, E. (Eds.), HLT-NAACL 2004 Workshop: Eighth
Conference Computational Natural Language Learning (CoNLL-2004), pp. 8997
Boston, Massachusetts, USA. Association Computational Linguistics.
Cormack, G. V., & Lynam, T. R. (2005). TREC 2005 Spam Track Overview. Proceedings
fourteenth Text REtrieval Conference (TREC-2005).
Debreu, G. (1959). Topological methods cardinal utility theory. Mathematical Methods
Social Sciences, Stanford University Press, 1 (76), 1626.
Ghosh, J. (2003). Scalable clustering methods data mining. Ye, N. (Ed.), Handbook
Data Mining. Lawrence Erlbaum.
Halkidi, M., Batistakis, Y., & Vazirgiannis, M. (2001). Clustering Validation Techniques.
Journal Intelligent Information Systems, 17 (2-3), 107145.
Luce, R., & Tukey, J. (1964). Simultaneous conjoint measurement: new scale type
fundamental measurement. Journal Mathematical Psychology, 1 (1).
Mann, G. S. (2006). Multi-Document Statistical Fact Extraction Fusion. Ph.D. thesis,
Johns Hopkins University.
Meila, M. (2003). Comparing clusterings. Proceedings COLT 03.
Narens, L., & Luce, R. D. (1986). Measurement: theory numerical assignments. Psychological Bulletin, 99.
Steinbach, M., Karypis, G., & Kumar, V. (2000). comparison document clustering
techniques. KDD Workshop Text Mining,2000.
Su, K.-Y., Su, J., Wiebe, J., & Li, H. (Eds.). (2009). Proceedings Joint Conference
47th Annual Meeting ACL 4th International Joint Conference
Natural Language Processing AFNLP. Association Computational Linguistics, Suntec, Singapore.
Tao Li, C. Z., & Zhu, S. (2006). Empirical Studies Multilabel Classification. Proceedings 18th IEEE International Conference Tools Artificial Intelligence
(ICTAI 2006).
van Rijsbergen, C. J. (1974). Foundation evaluation. Journal Documentation, 30 (4),
365373.
Weng, C. G., & Poon, J. (2008). New Evaluation Measure Imbalanced Datasets.
Roddick, J. F., Li, J., Christen, P., & Kennedy, P. J. (Eds.), Seventh Australasian
Data Mining Conference (AusDM 2008), Vol. 87 CRPIT, pp. 2732 Glenelg, South
Australia. ACS.
Zhao, Y., & Karypis, G. (2001). Criterion functions document clustering: Experiments
analysis. Technical Report TR 0140, Department Computer Science, University Minnesota, Minneapolis, MN.
718

fiJournal Artificial Intelligence Research 42 (2011) 851-886

Submitted 07/11; published 12/11

Dr.Fill: Crosswords Implemented
Solver Singly Weighted CSPs
Matthew L. Ginsberg
Time Systems, Inc.
355 Goodpasture Island Road, Suite 200
Eugene, Oregon 97401

Abstract
describe Dr.Fill, program solves American-style crossword puzzles.
technical perspective, Dr.Fill works converting crosswords weighted
csps, using variety novel techniques find solution. techniques
include generally applicable heuristics variable value selection, variant
limited discrepancy search, postprocessing partitioning ideas. Branch
bound used, incompatible postprocessing determined
experimentally little practical value. Dr.Fills performance crosswords
American Crossword Puzzle Tournament suggests ranks among top
fifty crossword solvers world.

1. Introduction
recent years, interest solving constraint-satisfaction problems, csps,
constraints soft satisfaction desirable,
strictly required solution. example, construction problem modeled
csp, may possible overutilize particular labor resource paying associated
workers overtime. cheapest way construct artifact question,
corresponding solution certainly viable practice.
Soft constraints modeled assigning cost violating constraint,
looking solution original csp accumulated cost
minimized.
large, work systems primarily theoretical various techniques solving weighted csps (wcsps) considered evaluated without
experimental support underlying implementation real-world problem. Theoretical complexity results obtained, general consensus appears
sort branch-and-bound method used solver, cost one
potential solution used bound thereby restrict subsequent search possible
improvements.
goal paper evaluate possible wcsp algorithms practical
setting, wit, development program (Dr.Fill) designed solve American-style
crossword puzzles. Based search engine underlying Dr.Fill, basic conclusions
follows:

c
2011
AI Access Foundation. rights reserved.

fiGinsberg

1. present specific variable- value-selection heuristics improve effectiveness search enormously.
2. effective search technique appears modification limited discrepancy
search (lds) (Harvey & Ginsberg, 1995).
3. Branch-and-bound appears terribly effective solution technique least
problems sort.
4. Postprocessing complete candidate solutions improves effectiveness search.
complete description crossword domain found Section 2.2;
example crosswords appear Figures 1 2. overall view take that, given
specific crossword clue c possible solution word fill f , associated
score p(f |c) gives probability fill correct, given clue. Assuming
probabilities independent different clues, probability collection
fills solves puzzle correctly simply

p(fi |ci )
(1)


fi fill entered response clue ci . Dr.Fills goal find set fills
legal (in intersecting words share letter square intersection)
maximizing (1).
human solvers, p(f |c) general zero except handful candidate fills
conform full domain knowledge. Thus 1973 nonfiction best seller woman
multiple personalities must Sybil; 3-letter Black Halloween animal might
bat cat, on. Dr.Fill, complete domain knowledge impractical
much greater use made crossing words, csp solver exploits hard
constraints problem restrict set candidate solutions.
Dr.Fills performance solver comparable (but significantly faster than)
best human solvers. solving New York Times crosswords (which increase
difficulty Monday Saturday, large Sunday puzzles comparable Thursdays
difficulty), Dr.Fill generally solves Monday Wednesday puzzles fairly easily, well
Friday Saturday puzzles, often struggles Thursday Sunday puzzles.
puzzles frequently involve sort gimmick clues fill
modified nonstandard way order make puzzle challenging. run
puzzles American Crossword Puzzle Tournament, annual national gathering
top solvers New York City area, Dr.Fills performance puts top fifty
approximately six hundred solvers typically attend.
outline paper follows. Preliminaries contained next section,
formal preliminaries regarding csps Section 2.1 discussion crosswords
Section 2.2. Section 2.3 discusses crosswords csps specifically, including description
variety ways crosswords differ problems typically considered
constraint satisfaction community.
heuristics used Dr.Fill described Section 3, value-selection heuristics
topic Section 3.1 variable-selection heuristics topic Section 3.2.
852

fiDr.Fill: Crossword Solver

techniques value variable selection applied wcsps generally, although
clear dependent usefulness crossword-specific features described
Section 2.3.
modification lds described Section 4, followed Section 5
first discussion experimental performance methods. Algorithmic extensions
involving postprocessing discussed Section 6, also discusses reasons
branch-and-bound techniques likely work well domain. Branch-andbound postprocessing compatible arguments branch-and-bound
deeper that. Section 7 describes utility splitting crossword smaller
problems associated constraint graph disconnects, idea dating back work
Freuder Quinn (1985) somewhat different setting provided lds.
Section 8 concludes describing related future work, including earlier crossword
solvers Proverb (Littman, Keim, & Shzaeer, 2002) WebCrow (Ernandes, Angelini,
& Gori, 2005), Jeopardy-playing program Watson (Ferrucci, Brown, Chu-Carroll,
Fan, Gondek, Kalyanpur, Lally, Murdock, Nyberg, Prager, Schlaefer, & Welty, 2010).

2. Preliminaries
section, give brief overview constraint satisfaction, crossword puzzles,
relationship two.
2.1 Constraint Satisfaction
conventional constraint-satisfaction problem, csp, goal assign values
variables satisfying set constraints. constraints indicate certain values
one variable, say v1 , inconsistent specific values different variable v2 .
Map coloring typical example. particular country colored red, neighboring
countries permitted color.
formulate crossword solving associating variable word crossword, value variable associated fill. fact first letter
word 1-Across match first letter word 1-Down corresponds
constraint two variables question.
basic csp, then, consists set V variables, set domains, one
variable, variables values taken, set constraints.
Definition 2.1 Given set domains set V variables, n-ary constraint
pair (T, U ) V size n U subset allowed sets values
variables V . assignment mapping variable v V element
vs domain. V , restriction , denoted S|T , restriction
mapping set . say satisfies constraint (T, U ) S|T U .
constraint simply specifies sets values allowed various variables
involved.
example, imagine coloring map Europe using four colors red, green, blue
yellow. might set {France, Spain} (which share border), would assign
domain {red, green, blue, yellow} variable, U would twelve ordered
853

fiGinsberg

pairs distinct colors four colors available. associated constraint indicates
France Spain cannot colored color.
remarked, take view variables crossword correspond
various slots words must entered, values
words putative dictionary fills taken (but see comments
Section 2.3). two words intersect (e.g., 1-Across 1-Down, typically), binary
constraint excluding pairs words shared letters differ.
Definition 2.2 constraint-satisfaction problem, csp, triple (V, D, ) V
set variables, gives domain variable V , set constraints.
|V | called size csp. every constraint either unary binary,
csp called binary csp.
csp C, denote set variables C VC , domains DC ,
constraints C .
solution csp assignment satisfies every constraint .
map coloring crossword solving described binary csps.
extensive literature csps, describing applicability wide
range problems various techniques effective solving them.
practical repeat literature here, two points particularly
salient.
First, csps generally solved using sort backtracking technique. Values
assigned variables; conflict discovered, backtrack occurs designed
correct source problem allow search proceed. chronologically based backtracking schemes, well-known heuristics selecting variables
valued values used, effective backtracking techniques use
kind nogood reasoning (Doyle, 1979; Ginsberg, Frank, Halpin, & Torrance, 1990,
many others) ensure backtrack able make progress.
need formalize slightly.
Definition 2.3 Let C csp, suppose v variable VC x value
associated domain DC . C|v=x denote csp obtained setting v x.
words, C|v=x = (VC v, DC , ) consists constraints
constraint (T, U ) C

(T, U ),
v 6 ;
=
(2)
(T v, {u U |u(v) = x}|T v ), v .
C|v=x called restriction C v = x.
notation may intimidating idea simple: Values permitted constraints
new problem permitted old problem, given decided
set v x. original constraint doesnt mention v (the top line (2)), new
constraint unchanged. v mentioned, see values variables
allowed, given v known take value x.

854

fiDr.Fill: Crossword Solver

Definition 2.4 Let partial solution csp C, maps variables
VC elements DC . restriction C S, denoted C|S , csp obtained
successively restricting C assignments Definition 2.3.
definition well-defined obviously have:
Lemma 2.5 restriction defined Definition 2.4 independent order
individual restrictions taken.
2
Backtracking csp solvers work selecting variables, trying various values variables selected, recursively solving restricted problems generated setting
variable question value chosen.
second general point would like make regarding csp solvers
implementations use kind forward checking help maintain consistency
search proceeds. example, suppose assign value x
variable v, this, every possible value variable v 0
eliminated constraints. case, obviously eliminate x value v.
worth formalizing bit, although general terms.
Definition 2.6 propagation mechanism mapping csps csps
change variables, (V, D, ) = (V, D0 , 0 ) (V, D, ). also require
variable V , associated domain D0 subset associated domain
D, = (T, U ) , must 0 = (T 0 , U 0 ) 0 U 0 U . say
sound if, csp C solution C, also solution (C).
propagation mechanism strengthens constraints problem, may reduce
variable domains well. sound never discards solution original
csp.
wide range propagation mechanisms discussed literature. Simplest,
course, simply eliminate variable values shown violate one
constraints problem. Iterating idea recursively quiescence (Mackworth,
1977) leads well known AC-3 algorithm, preserves arc consistency csp
solved.
Returning map Europe, Germany borders France, Holland, Poland, Austria
(among countries). Holland red, Poland blue, Austria yellow,
sufficient cause Germanys live set green (assuming four
colors available), turn cause Frances live set exclude green, even though
France share direct constraint Holland, Poland Austria.
Alternatively, consider crossword showed Figure 1; New York Times
crossword (with solution) March 10, 2011. decide put READING 1Across [Poets performance], live set words 1-Down consists six-letter words
beginning R. also entered ASAMI 21-Across [Me, too] REDONDO
27-Across, live set 1-Down would words form R...AR.
Weighted CSPs Sometimes desirable csp include soft constraints.
notion soft constraint indicates set variable values preferred
solution, requirement like pirates code, youd call guidelines
855

fiGinsberg

NY Times, Thu, Mar 10, 2011 Matt Ginsberg / Shortz
1
2
3
4
5
6
7
ACROSS

R

E



N G

8

C

9

E

1. *Poet's
14
15
performance
L B N

8. Frequent flooding 16
17
site
W R P R N U
14. Country
18
19
U.S.
B
B L
goes war
21
22
23
24
25

E
"Wag Dog"
27
28
29
30
15. "saved
R E N
R
life tonight"
32
33
34
35
1975 Elton John
B L E
N
hit
36
37
16. 36- 58D F F E R E N
Across, 38 39
40
answers
P E L L
N G E L
starred clues 41
42
43
18. Jacket material,
C E
G E
short?
47
48
49
50
51
R
R

19. 1973 nonfiction
52
53
54
55
56
best seller
R

woman
58
59
60
multiple
W H E N C P L
personalities
62
63
20. Lady
L N E

knight?
64
65
21. "Me, too"
B
R
24. Line ___
2011, New York Times
26. "The Thin Man"
actress
58. See 16-Across
11. Neighborhood
27. ___ Beach, Calif.
62. "I'm done
12. Flower
30. Plunder
this"
shares name
32. Big name
63. "Somehow
tentacled
circuses
everything gets
sea creature
35. B, A, D, G E,
done"
13. might depart
e.g.
64. nothing
midnight
36. See 16-Across
65. *Like Seattle vis15. Huff
38. Say "B-A-D-G-E,"
-vis Phoenix
17. Japanese band
e.g.
22. *Not fixed
40. Figures
23. Like Elgar's

ceiling la
Symphony No. 1
1. Seafood lover's
Cappella Sistina
25.
Cloaks
hangout
41. Impersonated
28. "What's ___?"
2. Nancy Drew's
costume party
29. Pharmaceutical
aunt
43. Spoils
oils
3. One way travel
47. Nutritional amt.
31.
*Shine
study
48. Doughnuts,
33. Old World eagle
4. Pop
danishes
34. Burglar
5. Connections
51. Piece
detective stories
6. Cheese ___
action
36. William
7. Player golf
52. Gillette offering
played Uncle
8. Clink
54. Bette's "Divine"
Charley "My
9. Prey wild dogs
stage persona
Three Sons"
crocodiles
57. Actress Vardalos
10. Furnish

10

L

11

L

12

13

R

E N
N C

E

20


26

E

L





N

31

P


L

E

E

E






44

45

46

B

H R
57
61



E

N





Z

E

N G E
N



E R

37. Prefix
paganism
38. Many signatures
39. Noodle dish
42. Lots lots
44. Battle cry
45. French
department
Pyrenees
46. Less lively
49. Opportune
50. "Whatever ___
don't care!"
53. Drones, maybe
55. Excitement
56. ___ Bear
59. Inner ear?
60. Medieval French
love poem
61. keeper
may keep

c
Figure 1: Thursday New York Times crossword. 2011
New York Times. Reprinted
permission.
856

fiDr.Fill: Crossword Solver

actual rules. solution found without violating one soft constraints,
acceptable return solution violate soft constraint. hard constraints required satisfied case.
variety ways formalize this. One simplest simply associate
cost soft constraint search overall assignment values
variables total cost minimized. take view total cost
assignment sum costs soft constraints violated,
although accumulation functions (e.g., maximum) certainly possible (Bistarelli,
Montanari, Rossi, Schiex, Verfaillie, & Fargier, 1999).
soft k-ary constraint thus consists mapping c : Dk IR giving cost associated
various selections variables valued. cost complete assignment
values variables sum costs incurred soft constraint. csp including
costs form called weighted constraint satisfaction problem, wcsp (Larrosa &
Schiex, 2004, many others).
Definition 2.7 weighted csp, wcsp, quadruple C = (V, D, , W ) (V, D, )
csp W set pairs (U, c) U V set variables c cost
function assigning cost assignment variables U . element w W
called weighted constraint. ambiguity arise, abuse notation
also denote w associated cost function c.
Given partial solution S, associated cost weighted constraint w = (U, c),
denoted c(S, w), minimum cost associated c valuation variables
U extends partial solution S. cost partial solution defined
X
c(S) =
c(S, w)
(3)
wW

Informally, c(S, w) minimum cost charged w solution C
extension S. therefore have:
Lemma 2.8 Given wcsp C partial solution S, every solution C extends
cost least c(S).
2
Note Definition 2.7 slightly nonstandard explicitly split hard
constraints soft constraints W . crossword
domain, condition met: soft constraints always unary
(although hard constraints not). simply cost associated setting
variable v specific value x. refer problems singly weighted csps,
swcsps. algorithmic ideas present paper applied
reasonably easily wcsps fact swcsps, experimental work underlying
Dr.Fill clearly reflects performance swcsps specifically.1
possible use propagation reduce sizes domains particular
csp, also possible use variety polynomial time algorithms compute lower
1. fact, Larrosa Dechter (2000) shown weighted csps recast similarly,
form hard binary constraints soft unary constraints.

857

fiGinsberg

bounds c(S) partial solution S. techniques used become increasingly sophisticated recent years, ranging algorithms move costs around
constraint graph better compute minimum (Givry & Zytnicki, 2005; Zytnicki, Gaspin,
de Givry, & Schiex, 2009) sophisticated approaches solve linear programming
problems compute accurate bounds (Cooper, de Givry, Sanchez, Schiex, Zytnicki,
& Werner, 2010).
Finally, note passing every csp dual version roles
variables constraints exchanged. view crosswords csps variables
word slots values words fill them, constraints require
letters match words cross. could also view crosswords csps
variables individual letters, values usual Z,
constraints indicate every collection letters needs make legal word.
discuss likely relative merits two approaches Section 2.3,
described crosswords themselves.
2.2 Crosswords
Since introduction first word cross Sunday New York World almost
century ago (December 21, 1913), crosswords become one worlds popular
mental pastimes. Shortz, editor crossword New York Times, estimates
five million people solve puzzle day, including syndication.2
2.2.1 Features Crosswords
typical New York Times crossword appears Figure 1. assume reader
familiar basic format, many specific features worth mentioning.
Crosswords symmetric. black squares, blocks, preserved 180
rotation.3 addition, crosswords almost always square shape, Times daily
puzzles size 15 15 Sundays 21 21.4
Multiple words permitted fill. puzzle Figure 1, [Seafood
lovers hangout] cluing RAW BAR 1-Down [Somehow everything gets done] cluing
MANAGE 63-Across. indication clue multiword answer
expected.
Without clues, crossword solutions unique. many ways
fit words particular crossword grid; clues determine legal fill
puzzles solution. makes solving challenging computational
perspective: Failing understand clues (at least level) leaves problem
underconstrained.
2. Personal communication.
3. rare cases, horizontal symmetry present instead rotational symmetry. rarer cases still,
symmetry requirement honored.
4. Sunday puzzles used 23 23 occasion, reduction size Times printed
magazine section made larger puzzles impractical.

858

fiDr.Fill: Crossword Solver

Puzzles themed themeless. themeless puzzle contains collection
generally unrelated words clues. themed puzzle shared element connects many answers; happens, shared answers generally located
symmetrically grid.
puzzle Figure 1 themed. (symmetric) entries 1-Across, 65-Across,
22-Down 31-Down marked asterisks words pronounced
differently capitalized. description also appears puzzle using
(also symmetric) entries 16-Across, 36-Across 58-Across.5
presence theme profound impact solving experience. particular example (which relatively straightforward), two entries (WORDSPRONOUNCED WHENCAPITALIZED) surely appear dictionary
solver using fill grid. also complex relationships among many
entries phrase 16-Across, 36-Across 58-Across, also relationship
phrase entries marked asterisks.
themes present challenges. popular themes quip
puzzles, famous saying split symmetric pieces inserted grid,
rebus puzzles, one letter must put single square. Arguably
famous themed Times puzzle appeared election day 1996. clue
39-Across [Lead story tomorrows newspaper (!), 43-Across]. 43-Across
ELECTED and, depending choices words, 39-Across could either
CLINTON BOBDOLE. example, 39-Down, three-letter [Black Halloween animal]
could CAT (with C CLINTON) BAT (with B BOBDOLE). here,
multiple ways insert words legally grid, multiple ways
words match clues provided. (Until winner election decided,
course.) two legal solutions identical except CLINTON/BOBDOLE
ambiguity associated crossing words; known whether puzzle
admits multiple solutions without shared words, conforming usual restrictions
symmetry, number black squares, on.
extreme example themed crossword appears Figure 2. clue
particular letter replaced asterisks (so 1-A, example, e [Twinkle]
replaced). letter replaced dropped fill, result still
word. 1-A, would normally GLEAM, becomes David Bowie rock genre
GLAM.
Every word puzzle missing letters fashion. computer (or human)
solver unable get foothold kind fails understand gimmick,
Dr.Fill fails spectacularly puzzle.
Puzzles structural restrictions. Times, daily unthemed puzzle
72 words; themed puzzle generally 78. Sunday,
140 words limit. 61 squares grid black squares.6
information potentially value solver word count often used
5. submitted, puzzle also contained asterisk entry 36-Across, break
symmetry pronounced-differently-when-capitalized entries. Shortz decided many
solvers wouldnt get joke, though, asterisk removed puzzle published.
6. Times puzzle fewest words (52) appeared January 21, 2005 Frank Longo.
puzzle fewest blocks (18) appeared August 22, 2008 Kevin Der, feat

859

fiGinsberg

NY Times, Sun, May 17, 2009 TAKEAWAY CROSSWORD (see Notepad)Matt Ginsberg / Shortz
1
2
3
4
5
6
7
8
9
10
11
12
ACROSS
1. Twinkl*
13
14
5. Ou*look
9. "Dani*l Boon*"
16
17
actor
19
20
13. Gung-*o [Lat.]
14. Sp*tted cats
23
15. Male chauvini*t,
*ay
26
27
28
16. Playin* slots,
31
32
e.*.
17. Minia*ure
38
39
40
desser*s
18. Admonis* [suffix]
43
44
19. *iding, sword
48
49
21. Neither young
ol*
52
53
54
23. Diat*ibe delive*e*s
25. *hief
57
26. Sergea*t old TV
63
64
29. Denta* devices
31. Still feelin* sleepy
67
68
32. *over
34. Mentalist inspired
70
71
"Mandra*e
2009, New York Times
Magician"
38. Struc*
68. Lessons fro*
foot
fables
40. Mail origi*ator
69. 1960* prote*t [2
42. Absolutely ama*e
wds.]
43. *emoves pencil
70. S*ut
ma*ks
71. Places *o pick
45. Big pi*kles?
chicks?
47. Cat*' warning*
72. Likel* rise?
48. Apo*tle known a*
"the Zealot"

50. Dise*se
1. Brib*, informally
tr*nsmitted
[Fr.]
cont*min*ted
2. Bit *ire
w*ter
3. Asla*'s realm
52. Italian po*t?
4. Lite*ally, "sac*ed
55. Cerea* protein
utte*ances"
[Ger.]
5. Nothing speci*l
57. P*blic sales
6. Opposite *on't
59. Im*roved one's lot
7. M*nhole
[hyph.]
em*n*tion
63. Can*ne restra*nt
8. *eatles' Paul
64. Sou*hwes*
McCartney, e.g.
German ci*y
9. Made smalle*
66. Rea*y ri**en
10. *ost
67. Roun*e*
co*prehensive

15
18
21
24
29

22
25

30

33

34
41

45

35

55
58

61

62

47
51

56
59

65

37

42
46

50

36

60
66
69
72

11. *mall amount,
briefly
12. Device
re*oves stalks fro*
fruit
14. Chin*s* cuisin*
20. *atchy *ony
22. *oting booth
feature
24. Big name ba**s
26. Pulit*er, e.g. [Fr.]
27. *egis*ative routine
[Sp.]
28. B*ont family
30. Speaks gi**erish
33. First mo*th,
Jua*
35. Lesley "60
Minu*es"
36. Waiti*g o*e's tur*
37. Di*dainful
expre**ion
39. Left
Met*oline*
41. Core cont*iners

44. National park
sout*west
Tennessee
46. Turt*es
bu**ets

49. *mpos*ng house
51. Biase*
52. Qi*g Dy*asty
people
53. A**ow shoote*s
54. O*erdo diet
56. Street art, *aybe
58. Stron* *rowth
60. homo*eneous
[Lat.]
61. "Lo*e Tender"
star
62. B*rth cert., one
65. Rank*es

c
Figure 2: difficult themed crossword. 2009
New York Times. Reprinted
permission.

860

fiDr.Fill: Crossword Solver

determine whether puzzle theme. (The themed puzzle Figure 1
70 words, however, really concluded 15 15 puzzle
72 words likely themed way.)
restrictions well. Two-letter words permitted, every
square must two words passing (alternatively, one-letter words
permitted, either). puzzle must connected (in underlying csp graph
well). puzzle singly connected, converting single empty square
block disconnects it, viewed flaw acceptable one.
Fill words may repeated elsewhere puzzle. fill BAT appears
one location puzzle, cannot used elsewhere (including multiword fill).
addition, BAT cannot used clue. means words appearing clues
(or least, not) appear fill well.
Crossword clues must pass substitution test. arguably
important requirement solvers perspective. must possible construct
sentence clue appears, meaning sentence essentially
unchanged clue replaced fill. puzzle Figure 1, one might
say, Ive seen video e.e. cummings giving READING, equivalent (although
stilted) Ive seen video e.e. cummings giving [poets performance]. One might say,
dont keep food houses CELLAR dont want get wet,
equivalent dont keep food houses [frequent flooding site] dont want
get wet.
fact clues associated fill must pass substitution test means
generally possible determine part speech, number (singular vs. plural)
tense (present, past, future, etc.) fill clue. Figure 1, fill 1-A
singular noun, on. restricts number possible values word
considerably.
conventions regarding cluing. clue contains abbreviation,
answer abbreviation well. puzzle Figure 1 abbreviations
clued way (a rarity), 62-D Figure 2 [B*rth cert., one]. solution
IDENT, abbreviation identification. course, gets dropped,
DENT entered grid. Abbreviations also indicated phrase like
short clue.
Clues ending ? generally indicate sort wordplay involved. Figure 1,
example, 18-A: [Jacket material, short?] solution BIO jacket
clue refers books jacket, clothing.
wordplay often exploits fact first letter clue capitalized.
Figure 1, 7-D [Player golf], referring GARY Player. clue [Golfs
Player], capitalization (not mention phrasing) would made obvious
proper name involved. clue written, solver might easily misled.
Crossword features Dr.Fill Many features described (e.g.,
symmetry) bear directly solving experience, Dr.Fill therefore unaware
repeated August 7, 2010 Joe Krozel. known whether 17-block puzzle reasonable
quality exists.

861

fiGinsberg

them. program look multiple-word fill module designed
identify rebus puzzles. check see fill words repeated elsewhere, since
rare offer little value search. uses fairly straightforward part-of-speech
analysis help substitution test, checks clues abbreviations. Dr.Fill
knowledge puns.
2.3 Crossword Puzzles SWCSPs
Given this, cast crossword solving csp?
view take, roughly speaking, start large dictionary
possible fills, goal enter words grid cross consistently
word entered match associated clue. dictionary, define Dn
subset consisting words exactly n letters, BAT D3 ,
on. also assume scoring function p scores particular word relative
given clue, interpret probabilistically. Given clue like [Black Halloween
animal]3 3-letter word potential fill BAT, p(BAT|[Black Halloween animal]3 )
probability BAT correct answer word question. goal find
overall fill maximum probability correct.
words, ci ith clue fi value entered grid, want
find fi satisfy constraints problem (crossing words must agree letter
filled crossing square)

p(fi |ci )
(4)


maximized. mentioned introduction, assumes probabilities
various words correct uncorrelated, probably reasonably accurate
completely correct themed puzzle.
define (fi , ci ) = log p(fi |ci ), maximizing (4) equivalent minimizing
X
(fi , ci )
(5)


exactly swcsp framework described.
dictionary Di must include words length i, also sequences words
collectively length i. (In words, D15 needs include WHENCAPITALIZED.)
actuality, however, even enough. many instances crossword fill
even word sequences.
may word appear particular dictionary. puzzle
2010 American Crossword Puzzle Tournament (acpt) clued MMYY [Credit card
exp. date format] although MMYY word normal sense.
example appearance SNOISSIWNOOW Times puzzle 11/11/10, clued
Apollo 11 12 [180 degrees]. Rotating entire puzzle 180 degrees reading
SNOISSIWNOOW upside produces MOONMISSIONS.
Given examples similar ones, virtually letter sequence can, fact, appear
particular puzzle. domain fact consist strings
appropriate length, cost function used encourage use letter strings
862

fiDr.Fill: Crossword Solver

dictionary words (or sequences words) possible. means variable
domains large associated functions must represented
functionally; computing either dictionaries scores entirety simply
impractical.
fundamental difference problem solved Dr.Fill
problems generally considered AI literature. number variables modest,
order 100, domain size variable immense, 265 approximately
12 million word length five, 1.7 1018 word length fifteen.
One immediate consequence Dr.Fill limited amount
forward propagation solves particular puzzle. letter entered
particular square puzzle, effective see way letter constrains
choices crossing words. appears effective propagate
restriction further. if, puzzle Figure 1, restrict 1-Down word
form R...AR word form dictionary RAW BAR, could
conceivably propagate forward B BAR see impact 18-Across.
actuality, however, possibility 1-Down non-dictionary fill causes propagation
beyond simple one-level lookahead negative practical value. sophisticated
propagation techniques mentioned Section 2.1 appear suitable domain.
second consequence unrestricted domain sizes always possible
extend partial solution way honors hard constraints problem.
simply entering random letters square puzzle (but one letter
per square, horizontal vertical choices agree). random string
legal, may even correct. reason fills general avoided random
strings assigned high cost soft constraints formulation.
fact partial solutions always extended satisfy hard constraints
difference problem solved Dr.Fill considered elsewhere
csp literature. Here, however, exception. Much work probabilistic
analysis using Markov random fields focuses probabilistic maximization similar ours,
environment solving hard constraints easy maximizing
score result hard.
popular inference technique Markov setting dual decomposition,
roles variables values switched, Lagrange multipliers introduced corresponding variable values values optimized bound quality
solution original problem (Sontag, Globerson, & Jaakkola, 2011, example).
similar csp notion duality, roles variables values also
exchanged.
clear apply idea setting. probabilistic case, variable
values probabilities selected continuous set real numbers. crossword
case, domain still impracticably large appear natural
ordering notion continuity one string value next.
one difference crossword domain standard ones
also important understand. Consider themed crossword called Heads
State 2010 acpt. theme entries puzzle common phrases
two-letter state abbreviations appended beginning. Thus [Film boastful jerks?]
clues VAIN GLOURIOUS BASTERDS, movie title INGLOURIOUS BASTERDS
863

fiGinsberg

together two-letter state abbreviation VA. [Origami?] clues PAPER FORMING,
PA adjoined PERFORMING, on.
multiword fills appear explicitly dictionary score fairly badly.
conventional csps, reasonable respond filling associated words
earlier search. allows better values assigned apparently difficult
variables. general idea underlies Joslin Clements (1999) squeaky wheel optimization virtually every recent variable selection heuristic, Boussemart
et. als (2004) notion constraint weighting, dom/wdeg heuristic (Lecoutre, Sas,
Tabary, & Vidal, 2009, others).
crossword domain, however, words score badly way arguably
filled later search, opposed earlier. obviously way program
Dr.Fill, extremely limited domain knowledge. figure 21-letter
word [Film boastful jerks?] VAIN GLOURIOUS BASTERDS.
hints suggested crossing words essential (as humans well). none
classic variable selection heuristics applied here, something else entirely
needed. heuristics use presented Section 3.
moving on, two final points make. First, goal
find fill (4) maximized; words, maximize chances solving
entire puzzle correctly. potentially distinct goal entering many
correct words possible, keeping scoring metric acpt described
Section 5. best human solvers generally solve acpt puzzles perfectly, however,
goal win acpt, maximizing chances solving puzzles perfectly
appropriate.
Second, designed Dr.Fill could truly exploit power underlying
search algorithm. constructing function (5), example, dont require
correct solution clue ci specific fill fi (5) minimized,
hope correct fi vaguely near top list. intention hard
constraints corresponding requirement filling words mesh work
us. many automated game players (Campbell, Hoane, & Hsu, 2002;
Ginsberg, 2001; Schaeffer, Treloar, Lu, & Lake, 1993), rely search replace
understanding.
2.4 Data Resources Used Dr.Fill
One important resources available Dr.Fill access variety
databases constructed online information. briefly describe data sources
here; summary Table 1. table also includes information size
analogous data source used Littmans crossword solving program Proverb (Littman
et al., 2002).
2.4.1 Puzzles
Dr.Fill access library 47,000 published crosswords. include virtually
major published sources, including New York Times, (now defunct) New
York Sun, Los Angeles Times, USA Today, Washington Post, many others.
puzzles early 1990s included.

864

fiDr.Fill: Crossword Solver

data type
puzzles
clues
unique clues
small dictionary
big dictionary
word roots
synonyms
Wikipedia titles
Wikipedia pairs

source
various
http://www.otsys.com/clue
http://www.otsys.com/clue
http://www.crossword-compiler.com
various
http://wordnet.princeton.edu
WordNet online
http://www.wikipedia.org
http://www.wikipedia.org

quantity
47,693
3,819,799
1,891,699
8,452
6,063,664
154,036
1,231,910
8,472,583
76,886,514

quantity (Proverb)
5,142
350,000
250,000
655,000
2,100,000
154,036 (?)
unknown



Table 1: Data used Dr.Fill
Collectively, puzzles provide database 3.8 million clues,
approximately half unique. contrasted corresponding database
Proverb, contains 5,000 puzzles 250,000 unique clues.
clue database available http://www.otsys.com/clue, public-domain clue
database used many crossword constructors. underlying data compressed,
source code available well enable interested parties decompress
data question.
2.4.2 Dictionaries
Proverb, Dr.Fill uses two dictionaries. small dictionary intended contain
common words, larger one intended contain everything. larger dictionary amalgamation many sources, including Moby7 online dictionaries,
Wikipedia titles, words ever used crosswords, on.
small dictionary basic English dictionary supplied Crossword
Compiler, automated tool used assist construction crosswords.
large dictionary much extensive. Every entry large dictionary
also marked score intended reflect crossword merit. words
generally viewed good fill, others bad. example, BUZZ LIGHTYEAR
excellent fill. lively positive connotations. letters interesting (high
Scrabble score, basically), combination ZZL unusual. TERN acceptable fill;
letters mundane word overused crosswords, word
least well known. ELIS (Yale graduates) poor fill. letters common, word
obscure, awkward plural boot. Crossword merit large dictionary
evaluated hand scoring approximately 50,000 words (100 volunteers, crossword
constructors, scored 500 words each). words evaluated many criteria
(length, Scrabble score, number Google hits,8 appearances online corpora, etc.)
linear model built best matched 50,000 hand-scored entries. model
used score remaining words.
7. http://icon.shef.ac.uk/Moby/mwords.html
8. would like thank Google general Mark Lucovsky particular allowing run
approximately three million Google queries involved here.

865

fiGinsberg

Note scores reflect crossword value words isolation, ignoring
clues. Thus cannot use dictionaries alone solve crosswords; indeed,
particular crossword, many legal fills actual solution unlikely
anywhere near best fill terms word merit alone.
2.4.3 Grammatical Synonym Information
Grammatical information collected data provided part WordNet
project (Fellbaum, 1998; Miller, 1995). includes list 154,000 words along
parts speech roots (e.g., WALKED WALK root). Proverb also cites
WordNet source. addition, list 1.2 million synonyms constructed
online thesaurus.
2.4.4 Wikipedia
Finally, limited amount information collected Wikipedia specifically. Dr.Fill
uses list titles Wikipedia entries source useful names phrases,
uses list every pair consecutive words Wikipedia help phrase development
fill-in-the-blank type clues. approximately 8.5 million Wikipedia titles,
Wikipedia contains 77 million distinct word pairs.

3. Heuristics
high level, csps solved using sort depth-first search. Values
assigned variables procedure called recursively. pseudocode, might
have:
Procedure 3.1 compute solve(C, S), solution csp C extends partial
solution S:
1
2
3
4
5
6
7
8
9

assigns value every variable VC , return
v variable VC unassigned
Dv (C|S )
0 (v = d)
C 0 propagate(C|S 0 )
C 0 6=
Q solve(C 0 , 0 )
Q 6= , return Q
return

select unassigned variable, try possible value. value, set
variable given value propagate unspecified way. assume
propagation returns empty set failure marker contradiction discovered,
case try next value v. propagation succeeds, try solve
residual problem and, manage so, return result.

866

fiDr.Fill: Crossword Solver

Proposition 3.2 Let C csp size n. propagate function sound,
value solve(C, ) computed Procedure 3.1 C solutions, solution
C otherwise.
Proof. proof induction n. csp size 1, live domain value tried
variable question; one survives propagate construction, solution
returned recursive call line 1 line 8 well.
larger n, csp solvable, every recursive call fail well
eventually return line 9. csp solvable, eventually set particular
variable v right value recursive call succeeds solution
returned.
2
weighted csps, algorithmic situation complex want return
best solution, opposed solution. augment Procedure 3.1 also accept
additional argument that, nonempty, currently best known solution B. need
following easy lemma:
Lemma 3.3 wcsp costs non-negative, S1 S2 , c(S1 ) c(S2 ).
Proof. immediate; costs incurred larger set assignments.
Note true wcsps generally, singly weighted csps.
2
convenience, introduce inconsistent assignment assume c()
infinite. modify Procedure 3.1 follows:
Procedure 3.4 compute solve(C, S,B), best solution wcsp C extends
partial solution given currently best solution B:
1
2
3
4
5
6
7
8

c(S) c(B), return B
assigns value every variable VC , return
v variable VC unassigned
Dv (C|S )
0 (v = d)
C 0 propagate(C|S 0 )
C 0 6= , B solve(C 0 , 0 , B)
return B

use B notation beginning procedure indicate B passed
reference, B changed line 7, value B used recursive
calls changed well.
loop variable values, longer return solution soon
find one; instead, update best known solution appropriate.
will, course, dramatically increase number nodes expanded search.
offsetting saving comparison line 1; cost partial solution
higher total cost best known solution, Lemma 3.3 ensures need
expand partial solution further. Note conditions lemma satisfied
Dr.Fill, since costs negated logarithms probabilities, probabilities
assumed exceed one.
867

fiGinsberg

Proposition 3.5 Let C csp. value solve(C, , ) computed Procedure 3.4 C solutions, least cost solution C otherwise.
Proof. Suppose first drop line 1 replace line 7
C 0 6= c(solve(C 0 , 0 , B)) < c(B) B solve(C 0 , 0 , B)

(6)

result follows easily inductive argument similar proof Proposition 3.1. Every possible solution considered, gradually find least
cost one return.
Consider Procedure 3.4 written. return set line 2, must
c(S) < c(B) virtue test line 1. Thus new requirement (6), namely
c(solve(C 0 , 0 , B)) < c(B), always satisfied proof complete
show simply test line 1 never discard best solution. words,
need show solution 0 discarded result test line 1,
c(S 0 ) c(B). follows directly Lemma 3.3, since c(S 0 ) c(S)
c(S) c(B).
2
Procedure 3.4 historical method choice wcsps. generally referred
branch bound cost best solution B found one branch used
bound searches branches.
implement procedure, need specify mechanisms variables
selected line 3 domain ordered line 4. discuss value selection first
variable selection. described Section 2.3, propagation mechanism useful
crossword solving considers direct impact word selection crossing
words.
3.1 Value Selection
performance Procedure 3.4 depends critically order values selected
domain D. sooner find good solutions, earlier use test
line 1 prune subsequent search. kind argument remain valid even
replace Procedure 3.4 algorithms effective practice; always
advantageous order search final solution found earlier, opposed
later.
variety elements this. First, note really need line 4
Procedure 3.4 function fill(v, n) returns nth element vs live domain
Dv . pass loop, call fill gradually increasing value
n. Faltings Macho-Gonzalez (2005) take similar approach work open
constraint programming.
work open constraint programming, observation allows us deal
fact crossword fills appear explicitly dictionary. scoring function
allows non-dictionary words, assumes apparently unrelated string words (or
letters) less likely correct word phrase actually appears
dictionary. means fill function evaluate dictionary possibilities
generating multiwords. multiwords generated needed;

868

fiDr.Fill: Crossword Solver

time needed, letters word generally filled. narrows
search possible multiwords substantially.9
implementation begins scoring every word appropriate length storing
results domain word n. multiwords needed generated,
added end domain sets appropriate.
approach reduces value selection problem two subproblems. First, need
scoring function (fi , ci ) evaluates fill fi given clue ci . Second, need use
scoring function produce actual ordering possible words enter; lowest cost
word may may one wish try first.
spend great deal time describing scoring function; details
predictably fairly intricate ideas simple. Fundamentally, take view
proven successful elsewhere computer game players: important
system able search effectively actually terribly good idea
doing. power always search heuristics.
overall search-based approach underlies virtually best computer game players
(Campbell et al., 2002; Ginsberg, 2001; Schaeffer et al., 1993) search-based algorithms
easily outperformed knowledge-based counterparts (Smith, Nau, & Throop, 1996,
example) games direct comparisons made.
implement idea scoring system principle quite simplistic. Words
analyzed based essentially five criteria:10
1. match clue itself. clue used before, associated answer
preferred. new clue shares word subphrase existing one, answer
scores well also.
2. Part speech analysis. possible parse clue determine likely part
speech answer, fill matching desired part speech preferred. part
speech analysis based WordNet dictionary (Fellbaum, 1998; Miller, 1995),
used search parse patterns clue database. external
syntax grammatical mechanisms used.
3. Crossword merit discussed Section 2.4.2.
4. Abbreviation. Abbreviations dictionary identified assuming words
generally clued using abbreviations abbreviations, described
previously. information used scoring possible answer new
clue. exactly constitutes abbreviation clue determined recursively
analyzing clue database.
5. Fill-in-the-blank. clues fill blanks. generally refer
common phrase word missing, 24-A Figure 1, [Line ] clues
9. And, remarked earlier, means need value badly scoring variables late search
opposed early.
10. Proverb thirty individual scoring modules (Littman et al., 2002), although Littman
suggested (personal communication) value comes modules analogous
used Dr.Fill. Proverb analyze clues determine part speech
desired fill.

869

fiGinsberg

ITEM. clues analyzed looking phrases appear body
Wikipedia.
five criteria combined linearly. determine weights various
criteria, specific set weights (w1 , . . . , wn ) selected used solve
fixed testbed puzzles (the first 100 New York Times puzzles 2010). puzzle
testbed, count number words entered search procedure
mistake made heuristically chosen word one appears
known solution puzzle. average number words entered correctly
score (w1 , . . . , wn ) weights varied maximize score.
Given scoring function , order values particular word?
dont necessarily want put best values first, since value best
word may force us use extremely suboptimal choices crossing words.
precisely, suppose assign value variable v, propagation
reduces variable domains new values Di (C|S{v=d} ). argument similar
underlying Lemma 2.8 produces:
Proposition 3.6 Let C swcsp partial solution, Du ((C|S{v=f } ))
domain u v set f result propagated. minimum cost
solution C extends {v = f } least
X
min
(x, u).
2
(7)
u

xDu ((C|S{v=f } ))

order variable values order increasing total cost measured (7), preferring
choices work well word slot question, also minimally increase
cost associated crossing words.
notion fairly general. wcsp, whenever choose value variable,
choice damages solution problem large; amount damage
determined propagating choice made using whatever mechanism desired (a
simplistic approach ours, full arc consistency, Coopers linear relaxation, etc). Cost
incurred choice made, implied variables
propagation mechanism. (7) says want choose value variable v
value total global cost minimized, local cost variable
valued.
crossword domain, heuristic appears reasonably effective practice.
Combined variable selection heuristic described next section, Dr.Fill
inserts average almost 60 words Times puzzle making first mistake.
3.2 Variable Selection
argued previous section, heuristic use valuing possible fill f word
slot puzzle
X
X
h(f, v) =
min
(x, u)
min (x, u)
(8)
u

xDu ((C|S{v=f } ))

870

u

xDu (C|S )

fiDr.Fill: Crossword Solver

domain variable u setting v f Du (C|S ), term right
(8) gives lower bound best possible score complete solution v set
f (and expression thus independent f ).
value term left lower bound best possible score v
set f domain u setting v f propagating Du ((C|S{v=f } )).
heuristic value setting v f difference two numbers, total
damage caused commitment use fill f variable v. Given (8), variable
select valuation point search?
might seem choose value variable h(f, v) minimized.
would cause us fill words could filled without significant impact
projected final score entire puzzle. could define heuristic value
slot v, denote H(v),
H(v) = min h(f, v)
f

(9)

apparently attractive idea worked poorly practice, bit investigation
revealed reason. Especially early on, remains great deal flexibility
choices variables, may multiple candidate fills particular
clue, appear attractive h(f, v) small. situation,
really strong reason prefer one attractive fills others, using (9)
variable selection heuristic force us value variable therefore commit
choice.
solution problem choose value variable h(f, v)
minimized, variable difference minimum value
second-best value maximal. difference indicates confident truly
fill slot correctly decide branch it. define min2(S)
second-smallest element set S, variable selection heuristic
proposing
H(s) = min2 h(f, v) min h(f, v)
(10)
f

f

large values preferred smaller ones.
mentioned previously, combination (10) (8) allows Dr.Fill enter,
average, initial 59.4 words Times puzzle makes first error.
important realize metric 59.4 words inserted correctly average
scoring function accurately places correct word first large fraction
time. Instead, methods benefiting even point anticipation
search likely develop; heuristics based much glimpse
future search word values isolation. Indeed, use variable
selection described switch value selection heuristic simply prefer best fill
word question (without considering impact subsequent search), average
number words filled correctly outset search drops 25.3, well half
previous value.

871

fiGinsberg

r
@
@







r
HH

HH


H
HH

H
HH
HHe
r
@
@
@
@

@
r








Ae
r
r

@
@
@re








Ae
r
h
r

r








Ah

r

@
@h









Ar
r

0

1

1

2

1

2

2

3

Figure 3: Limited discrepancy search

4. Limited Discrepancy Search
Given Dr.Fill enter nearly sixty correct words crossword making
error, one would expect strong solver combined branch-and-bound
solving procedure 3.4. Unfortunately, case.
reason solving procedure suffers Harvey (1995) called
early mistakes problem. mistake made, impacts subsequent search
substantially mistake never retracted entire associated subspace
examined. initial mistake depth (say) sixty seems impressive quality
solution point likely quite poor, unlikely sufficient time
retract original error led problem.
One way around problem csps binary domains use limited discrepancy
search, lds (Harvey & Ginsberg, 1995). idea heuristic present,
define discrepancy count partial solution number times
violates heuristic. Figure 3, shown simple binary search tree depth
three; assuming heuristic choice always left, labeled fringe
node number times heuristic violated reaching it.
Lds iterative search method expands tree using depth-first search
order increasing discrepancy count. first iteration, nodes without discrepancies examined, search pruned node figure single
bullseye. second iteration, single discrepancy permitted nodes
double bullseyes pruned. hard see iteration n expands O(dn ) nodes,
discrepancy limit forms barrier full search tree. iteration
also uses O(d) memory, since expansion individual iteration depth first.
work repeated iteration iteration, since bulk work
iteration n involves nodes expanded iteration n 1, rework little

872

fiDr.Fill: Crossword Solver

impact performance. Korf (1996) presents algorithmic improvement addresses
issue extent.
point lds allows early mistakes avoided without searching large
portions space. figure, example, heuristic wrong root
tree, node labeled 1 explored second iteration (with discrepancy limit 1),
without need expand left half search space entirety.
clear basic intuition underling lds good match search
difficulties encountered Dr.Fill, clear idea applied. One
natural approach would order values particular word slot, say
using second value (as opposed first) incurred one discrepancy, using
third value incurred two discrepancies, on.
doesnt work. Assuming first word list wrong, subsequent words
may score quite similarly. believed strongly (and wrongly, apparently)
first word best fill mean strong opinion
use backup choice. net result best solution often uses
words quite late ordered list; correspond high discrepancy count
therefore unlikely discovered using sort algorithmic approach.
alternative idea say discrepancy incurred variable selected
branching variable suggested variable-selection heuristic (10).
avoids problem described previous paragraph, since pick fill
completely different word slot. Unfortunately, suffers two difficulties.
first (and less important) cases, wont want change
variable order all. Perhaps clear first choice and, choice
eliminated, clear second choice among remaining candidate values.
instance, would want single discrepancy search choice try second fill
instead first.
important fact bad choice likely come back next
node expansion, consider variable question. word
looked good discrepancy incurred may well still look good, wind
used discrepancy really changed area search space
considering.
algorithm actually use combines ideas approaches.
search proceeds, maintain list P value choices discarded,
pitched. element P pair (v, x) indicating value x
proposed variable v. pitched choices remain live set, considered
branch values v forced vs live set becomes singleton.
evaluating heuristic expressions (8) (10), pitched values considered.
incur discrepancy pitching variable value suggested heuristics. Assuming completely recompute variable chosen branching
value used, problems mentioned previous paragraphs neatly
sidestepped. continue make choices confidence, since pitched
value remains pitched search proceeds, repeat apparent mistake later
search process.

873

fiGinsberg

Formally, have:
Procedure 4.1 Let C wcsp. Let n fixed discrepancy limit suppose
partial solution, B best solution known thus far, P set values pitched
search. compute solve(C, S, B, n, P ), best solution extending
n discrepancies:
1
2
3
4
5
6
7
8
9

c(S) c(B), return B
assigns value every variable VC , return
v variable VC unassigned
element Dv (C|S ) (v, d) 6 P
0 (v = d)
C 0 propagate(C|S 0 )
C 0 6= , B solve(C 0 , 0 , B, n, P )
|P | < n, B solve(C, S, B, n, P (v, d))
return B

Proposition 4.2 Let C csp size k. value solve(C, , , n, ) computed
Procedure 4.1 C solutions. C solution, n0 k(|D|1)
n n0 , solve(C, , , n, ) least cost solution C.
Proof. essentially three separate claims proposition, address
individually.
1. C solutions, test line 2 never succeed, B throughout
procedure therefore return .
2. clear space explored larger n superset space explored
smaller n test line 8 succeed often. Thus n
best solution returned, best solution also returned larger n.
3. claim n = k(|D| 1), every solution considered, prove
induction k.
k = 1, n = |D| 1. interested particular choice x
unique variable problem, |D| 1 iterations line 8, either
selected x line 4 pitched every value case x
selected last iteration.
argument inductive case similar. variable v selected line 3,
use |D| 1 discrepancies setting v desired value, leaving
least (n 1)(|D| 1) discrepancies handle search subproblem v
set.
2
Proposition 4.3 Let C csp size k. fixed n, number node
expansions computing solve(C, , , n, ) (k + 1)n+1 .
Proof. Consider Figure 4, shows top lds search tree labels nodes
number unvalued variables number unused discrepancies point.
874

fiDr.Fill: Crossword Solver



(k, n)
HH

HH


H
HH


H
HH (k, n 1)
Hs
%%e
e
%
e
%
e
%
ees
s%

(k 1, n)s
%%e
%
%

%

%

(k 2, n)

e
e
e
ees

(k 1, n 1)

(k 1, n 1)

(k, n 2)

Figure 4: Limited discrepancy search
root, therefore, k variables left value n discrepancies available.
branch left, assign value variable. branch right, pitch choice
still k variables left value n 1 discrepancies available.
follows denote f (d, m) size search tree point
variables discrepancies,

f (d, m) = 1 + f (d, 1) + f (d 1, m)

(11)

= 1 + f (d, 1) + 1 + f (d 1, 1) + f (d 2, m)

(12)

= 2 + f (d, 1) + f (d 1, 1) + f (d 2, m)
..
.

X
= k+
f (i, 1) + f (d k, m)

(13)

i=dk+1

= d+


X

f (i, 1) + f (0, m)

(14)

i=1

= d+1+


X

f (i, 1)

(15)

i=1

+ 1 + (d 1)[f (d, 1) 1] + f (d, 1)

(16)

= 2 + df (d, 1)]
(11) follows counting nodes figure. (12) result expanding
last term (11), corresponding expanding node labeled (k 1, n) figure.
(13) continues expand corresponding term total k times, (14) (13)
k = d. f (0, m) = 1 variables left value, producing (15).
(16) follows f (i, 1) f (d, 1) 1 0 < < (in figure, every step
left side least one node smaller).

875

fiGinsberg

Given f (d, m) 2 + df (d, 1),
f (d, m)
2

+d1+d
f (d, 1)
f (d, 1)
f (d, 0) = d+1 search must progress directly fringe discrepancies
remain. Thus f (d, m) (1 + d)1+m . Taking = n = k root tree
produces desired result.
2

5. Dr.Fill Crossword Solver
point, described enough Dr.Fills underlying architecture makes
sense report performance system described thus far.11
overall experimental approach follows.
First, tune word scoring function . Although five basic contributions value particular clue fill, currently twenty-four
tuning parameters impact five contributions way
combined get overall value . described Section 3, goal
maximize average number words entered correctly beginning solve
first 100 Times puzzles 2010.
tuning process time consuming; Dr.Fill spends approximately one cpu minute
analyzing clues given puzzle determine value words dictionary.
analysis often needs repeated tuning parameters changed; follows
single run testbed 100 puzzles takes hour. clue analysis
multithreaded work done 8-processor machine (two 2.8GHz quad-core
Xeons), reduces wall clock time considerably, remains impractical sample
space parameter values coarse granularity, parameters must
general tuned independently one another even though variety cross effects
undoubtedly exist.
tuning complete, Dr.Fill evaluated puzzles 2010 acpt
(American Crossword Puzzle Tournament). set seven puzzles, algorithmic heuristic progress appear translate quite well progress acpt sample.
puzzles scored according acpt rules, Dr.Fills total score examined
determine would ranked competitor.
acpt scoring particular puzzle follows:
1. 10 points correct word grid,
2. 25 bonus points full minute time remaining puzzle completed.
bonus reduced 25 points incorrect letter, never negative.
3. 150 bonus points puzzle solved correctly.
11. Dr.Fill written C++ currently runs MacOS 10.6. needs approximately 3.5 GB
free memory run, multithreaded. multithreading uses posix threads GUI
written using wxWidgets (www.wxwidgets.org). code underlying data obtained (for
noncommercial use only) contacting author. code expected run virtually unchanged
Linux; Windows challenge Windows native support posix
threads.

876

fiDr.Fill: Crossword Solver

version
lds
postprocess
and/or
best human

1
1280
1280
1280
1230

2
925
1185
1185
1615

3
1765
1790
1815
1930

4
1140
1165
1165
1355

5
1690
1690
1690
1565

6
2070
2070
2095
1995

7
1920
2030
2080
2515

total
10790
11210
11310
12205

rank
89 (tied)
43 (tied)
38
1

Table 2: Results 2010 acpt
Since puzzles timed, Dr.Fill needs sort termination condition. stops
work declares puzzle complete following conditions occur:
1. full minute goes improvement cost puzzle currently filled,
2. full lds iteration goes improvement cost puzzle currently
filled,
3. acpt time limit puzzle reached.
Results versions Dr.Fill appear Table 2, scores puzzle,
total score tournament, ranking Dr.Fill competed. also give scores
human (Dan Feyer) event.12 first fourth puzzles generally
easiest, second fifth puzzles hardest. lds-based Dr.Fill scored
total 10,790, good enough 89th place.
evaluation complete, attempt generally made improve Dr.Fills
performance. examine puzzles Times testbed (not acpt puzzles,
try keep clean possible) try understand mistakes made.
mistakes generally classified one three types:
1. Heuristic errors, words entered scored better correct ones even
though correct fill,
2. Search errors, words entered scored worse correct ones Dr.Fill
find better fill discrepancy limit reached,
3. Efficiency errors, points lost search took long time
complete.
Heuristic errors generally lead change scoring algorithms way, although generally introduction new scoring modules. Perhaps different
thesaurus used, understanding theme entries changes. Search errors may lead
modifications underlying search algorithm itself, Sections 6 7. Dr.Fill
graphical user interface allows user watch search proceed,
often invaluable understanding program performed did. Efficiency issues
also (sometimes) corrected allowing visual search suggest algorithmic modifications; convinced us worthwhile treat overall csp and/or
tree discussed Section 7.
12. Feyer went win 2011 well; Tyler Hinman acpt champion 20052009.

877

fiGinsberg

6. Postprocessing
examination Dr.Fills completed puzzles based algorithms presented thus
far reveals many cases single letter wrong, problem search
instead heuristics. words, replacing given letter right one
decreases total cost puzzles fill. would presumably found
larger discrepancy limit, discovered practice.
suggests Dr.Fill would benefit sort postprocessing. simplest approach simply remove word fill, replace best word
slot question. produces change, process repeated quiescence.
6.1 Formalization Algorithmic Integration
formalize process easily follows:
Procedure 6.1 Given csp C best solution B, compute post(C, B), result
attempting improve B postprocessing:
1 change true
2 change
3
change false
4
v CV
5
B 0 B
6
unset value v B 0
7
B 0 solve(C, B 0 , B 0 )
8
c(B 0 ) < c(B)
9
B B 0
10
change true
11 return B
work puzzle, erasing word line 6. re-solve puzzle
(line 7), better choice word isolation, found.
leads improvement, set flag line 10 repeat entire process. Note
erase one word time, since always begin currently best solution
line 5.
AC-3, Procedure 6.1 improved somewhat realizing particular iteration, need examine variables share constraint variable
changed previous iteration. practice, little Dr.Fills time spent postprocessing efficiency concern.
Lemma 6.2 csp C solution B, c(post(C, B)) c(B).

2

combine Procedure 6.1 basic search procedure 4.1 used
Dr.Fill itself? obviously postprocess result computed Procedure 4.1
returning final answer, postprocessing works effectively, surely
postprocess candidate solutions considered. produces:
878

fiDr.Fill: Crossword Solver

Procedure 6.3 Let C wcsp. Let n fixed discrepancy limit suppose
partial solution, B best solution known thus far, P set values pitched
search. compute solve(C, S,B, n, P ), best solution extending
n discrepancies:
1
2
3
4
5
6
7
8
9

c(S) c(B), return B
assigns value every variable VC , return post(C, S)
v variable VC unassigned
element Dv (C|S ) (v, d) 6 P
0 (v = d)
C 0 propagate(C|S 0 )
C 0 6= , B solve(C 0 , 0 , B, n, P )
|P | < n, B solve(C, S, B, n, P (v, d))
return B

difference Procedure 4.1 line 2, postprocess
solution returning it.
6.2 Interaction Branch Bound
thought reveals potential problem approach. Suppose original
procedure 4.1 first produces solution B1 subsequently produces improvement B2 ,
c(B2 ) < c(B1 ). Suppose also postprocessing improves solutions comparably,
c(post(B2 )) < c(post(B1 )). finally, suppose postprocessing improves
solutions considerably, much so, fact, c(post(B1 )) < c(B2 ).
danger missing B2 , since pruned test line 1
Procedure 6.3. B2 allow us find better solution, postprocessing.
prune B2 early, never postprocess it, improvement found
larger discrepancy limit used.
suggests return earlier possibility postprocessing final
answer returned Procedure 4.1, may work, either. Perhaps B1 improved
postprocessing B2 not; again, best solution may lost.
problem branch-and-bound postprocessing fundamentally inconsistent; impossible use effectively. idea branch-and-bound
solution pruned complete cost gets large. idea
postprocessing final cost solution cannot really evaluated
solution complete postprocess run.
solution remove branch bound Dr.Fills search algorithm,
producing:

879

fiGinsberg

Procedure 6.4 Let C wcsp. Let n fixed discrepancy limit suppose
partial solution, B best solution known thus far, P set values pitched
search. compute solve(C, S,B, n, P ), best solution extending
n discrepancies:
1
2
3
4
5
6
7
8
9

assigns value every variable VC ,
return whichever B post(C, S) lower cost
v variable VC unassigned
element Dv (C|S ) (v, d) 6 P
0 (v = d)
C 0 propagate(C|S 0 )
C 0 6= , B solve(C 0 , 0 , B, n, P )
|P | < n, B solve(C, S, B, n, P (v, d))
return B

Since test line 2 ensures change best solution B
improvement found, previous results continue hold. really practical
abandon branch bound mechanism controlling size search?
is. One reason size search controlled lds via
Proposition 4.3. fixed discrepancy limit n, guarantees number
nodes expanded polynomial size problem solved.
important, however, experimentation showed branch-and-bound
ineffective controlling Dr.Fills search. reason effectiveness (searchanticipating) heuristics used Dr.Fill itself. heuristics designed ensure
words inserted early search incur little cost allow crossing
words incur low cost well. happens practice costs incurred early
extremely modest. Even mistake made, attention typically changes
different part puzzle filling additional word w near mistake begins
consequences expected cost words crossing w. Eventually, rest
puzzle complete algorithm finally begrudgingly returns w cost
increases.
Thinking this, happens cost eventually increase
error made, increase deferred bottom search tree, nearly
so. much cost almost invariably accumulating bottom search tree,
branch bound simply ineffective pruning tool domain. nature
argument suggests wcsps derived real-world problems, good
heuristics may exist branch bound may provide little value practical problem
solving.13
6.3 Results
results Procedure 6.4 appear Table 2. Dr.Fills score improves 11,210,
would earned tie 43rd place 2010 tournament.
13. said, certainly real-world problems branch-and-bound useful, use
MendelSoft solve cattle pedigree problems (Sanchez, de Givry, & Schiex, 2008).

880

fiDr.Fill: Crossword Solver

7. AND/OR Search
one algorithmic improvement part Dr.Fill system
currently implemented.
watched Dr.Fill complete puzzles, many cases would fill
enough puzzle residual problem would split two disjoint subproblems.
search would frequently oscillate two subproblems, could
clearly introduce inefficiencies.
general observation made many others, probably originates
Freuder Quinn (1985), called variables independent subproblems stable
sets. McAllester (1993) calls solution technique polynomial space aggressive backtracking
procedure solves disjoint subproblems time sum times needed
subproblems independently. recently, Marinescu Dechter (2009) explore
notion context constraint propagation specifically, exploiting structure
associated search spaces and/or graphs.
None work directly applicable Dr.Fill needs integrated
appropriately lds. integration straightforward:
Definition 7.1 Let C csp wcsp. say C splits nonempty
V1 , V2 VC V1 V2 = , V1 V2 = VC , constraint weighted constraint
C mentions variables V1 V2 . denote C = C|V1 + C|V2 .
Proposition 7.2 Suppose C csp splits V1 V2 . S1
solution C|V1 S2 solution C|V2 , S1 S2 solution C, solutions
C constructed fashion.
addition, C wcsp, least cost solution C union least
cost solutions C|V1 C|V2 .
2
Note also check see C splits low order polynomial time checking
see constraint graph associated C connected. so, C split.
constraint graph disconnected, C splits.
Procedure 7.3 Let C wcsp. Let n fixed discrepancy limit suppose
partial solution, B best solution known thus far, P set values pitched
search. compute solve(C, S, B, n, P ), best solution extending
n discrepancies:
1
2
3
4
5
6
7
8
9
10
11

assigns value every variable VC ,
return whichever B post(C, S) lower cost
C splits V W ,
return solve(C|V , S|V , B|V , n, P ) solve(C|W , S|W , B|W , n, P )
v variable VC unassigned
element Dv (C|S ) (v, d) 6 P
0 (v = d)
C 0 propagate(C|S 0 )
C 0 6= , B solve(C 0 , 0 , B, n, P )
|P | < n, B solve(C, S, B, n, P (v, d))
return B
881

fiGinsberg

Puzzle
1
2
3
4
5
6
7
total

Words
78
94
118
78
94
122
144
643

Letters
185
237
301
187
245
289
373
1817

Words wrong
0
8
4
4
0
0
11
27

Dr.Fill
Letters wrong
0
11
2
2
0
0
13
28

Time
1
2
2
2
1
1
2
11

Score
1280
1185
1815
1165
1690
2095
2080
11310

Feyer
Time Score
3
1230
4
1615
6
1930
3
1355
6
1565
5
1995
8
2515
35
12205

Table 3: Results 2010 acpt
Note line 4, solve split subproblems discrepancy limit n.
(for example) currently n = 3 one discrepancy used
point split occurs, allowed two additional discrepancies solving
subproblem, perhaps allowing five discrepancies total.
spite this, node count reduced. variables remaining
split encountered, solving unsplit problem remaining discrepancies might
expand (1 + d)1+m nodes (Proposition 4.1), solving split problems expand

(1 + d1 )1+m + (1 + d1 )1+m
(17)
nodes. small amount calculus algebra14 shows (1 +d1 )1+m + (1 + d1 )1+m
(1 + d)1+m 1, split search faster even though total
discrepancies permitted.
change embodied Procedure 7.3 significantly improves performance later
lds iterations, arguable exploit improvement modifying
Dr.Fills current strategy terminating search increase lds limit
produce improved solution. Even without modification, increased
speed solution improves Dr.Fills acpt score 100 points (one minute faster puzzles 3 6, two minutes faster puzzle 7), moving notional 38th place
2010 event.
Detailed performance final version 2010 puzzles shown Table 3.
puzzle, give number words letters filled, number errors
made Dr.Fill area. also give time required Dr.Fill solve
program (in minutes taken), along time taken Dan Feyer, human winner
contest. (Feyer made errors seven puzzles.) seen, Dr.Fill
27 incorrect words (out 643, 95.8% correct) 28 incorrect letters (out 1817,
98.5% correct) course event.
14. Differentiating (17) shows worst case split d1 = 1, compare 21+m + d1+m
(d + 1)1+m . Multiplying (d + 1)1+m produces d1+m + (1 + m)dm + , 21+m < (1 + m)dm
2 1.

882

fiDr.Fill: Crossword Solver

8. Related Future Work
wide variety work wcsps academic literature, repeat
particular element work here. distinguishes contribution fact
driven results naturally occurring problem: solving
crossword puzzles. led us following specific innovations relative earlier
work:
development value selection heuristic based projected cost assigning
value currently selected variable variables
variable shares constraint,
development variable selection heuristic compares difference
projected cost impacts best second-best values, branches
variable difference maximized,
modification limited discrepancy search appears work well weighted
csps large domain sizes,
recognition branch-and-bound may effective search technique
wcsps reasonably accurate heuristics exist,
development inclusion effective postprocessing algorithm wcsps,
recognition postprocessing inconsistent branch-and-bound
pruning.
know extent observations general, extent
consequence properties crossword csp itself. discussed
previously, crossword csps relatively small number variables almost unlimited
domain sizes, variables whose valuations incur significant cost general filled
late opposed early.
two existing projects closely relate Dr.Fill Proverb (Littman
et al., 2002), crossword solver developed Littman et. al 1999, Watson (Ferrucci et al., 2010), Jeopardy-playing robot developed ibm 2011. three systems
(Watson, Proverb, Dr.Fill) respond natural language queries game-like
setting. three cases, programs seem little idea doing,
primarily combining candidate answers variety data sources attempting
determine answer best match query consideration. appears
mesh well generally accepted view (Manning & Schuetze, 1999) natural
language processing far better accomplished using statistical methods
classical parse-and-understand approach.
domain differences Jeopardy crosswords make problems challenging
different ways. one sense, crosswords difficult Jeopardy, one
always welcome simply decline answer particular question. crosswords,
entire grid must filled. hand, crossing words crossword restrict
answer way obviously unavailable Jeopardy contestants. Search plays
key role Dr.Fills performance way Watson cannot exploit. result,
Dr.Fill get relatively limited database computational resources.
883

fiGinsberg

program runs 2-core notebook 8 GB memory uses database
300 MBytes compressed. Watson needs much more: 2880 cores 16 TB
memory. Watson, like Dr.Fill, stores knowledge memory improve access
speeds Watson relies much extensive knowledge Dr.Fill.
programs probably comparably good respective cognitive tasks. Dr.Fill
outperforms best humans crossword filling, terms speed (where
easily fastest solver world) terms accuracy. Watson, too, outperforms humans easily terms speed; much-ballyhooed victory human Jeopardy
competitors probably due far Watsons mastery button pushing
question-answering ability. terms underlying cognitive task, Watson appears
yet match best Jeopardy players, general capable answering
virtually questions without error.
Dr.Fill remains work progress. point, found heuristic
search errors relatively easily examining performance program handful
crosswords simply seeing went wrong. Dr.Fills performance improved,
become difficult. therefore developed automated tools examine
errors made collection puzzles, identify heuristic search issues,
report nature errors caused mistakes largest sections fill. results
tools will, hope, guide us improving Dr.Fills performance still further.
Acknowledgments
would like thank Time Systems coworkers useful technical advice assistance, would also like thank crossword solving constructing communities,
especially Shortz, warm support years. Daphne Koller, Rich Korf,
Michael Littman, Thomas Schiex, Bart Selman, papers anonymous reviewers provided invaluable comments earlier drafts, making paper substantially
stronger result. work described paper relates certain pending issued
US patent applications, publication ideas intended convey license use patented information processes. Time Systems general grant
royalty-free licenses non-commercial purposes.

References
Bistarelli, S., Montanari, U., Rossi, F., Schiex, T., Verfaillie, G., & Fargier, H. (1999).
Semiring-based CSPs valued CSPs: Frameworks, properties, comparison.
Constraints, 4.
Boussemart, F., Hemery, F., Lecoutre, C., & Sais, L. (2004). Boosting systematic search
weighting constraints. Proceedings ECAI-2004, pp. 146150.
Campbell, M., Hoane, A. J., & Hsu, F. (2002). Deep Blue. Artificial Intelligence, 134,
5783.
Cooper, M., de Givry, S., Sanchez, M., Schiex, T., Zytnicki, M., & Werner, T. (2010). Soft
arc consistency revisited. Artificial Intelligence, 174, 449478.
Doyle, J. (1979). truth maintenance system. Artificial Intelligence, 12, 231272.

884

fiDr.Fill: Crossword Solver

Ernandes, M., Angelini, G., & Gori, M. (2005). WebCrow: WEB-based system CROssWord solving. Proceedings Twentieth National Conference Artificial Intelligence, pp. 14121417.
Faltings, B., & Macho-Gonzalez, S. (2005). Open constraint programming. Artificial Intelligence, 161, 181208.
Fellbaum, C. (Ed.). (1998). WordNet: Electronic Lexical Database. MIT Press, Cambridge, MA.
Ferrucci, D., Brown, E., Chu-Carroll, J., Fan, J., Gondek, D., Kalyanpur, A. A., Lally, A.,
Murdock, J. W., Nyberg, E., Prager, J., Schlaefer, N., & Welty, C. (2010). Building
Watson: overview DeepQA poject. AI Magazine, 31 (3), 5979.
Freuder, E. C., & Quinn, M. J. (1985). Taking advantage stable sets variables
constraint satisfaction problems. Proceedings Ninth International Joint Conference Artificial Intelligence, pp. 224229.
Ginsberg, M. L. (2001). GIB: Steps toward expert-level bridge-playing program. Journal
Artificial Intelligence Research, 14, 313368.
Ginsberg, M. L., Frank, M., Halpin, M. P., & Torrance, M. C. (1990). Search lessons learned
crossword puzzles. Proceedings Eighth National Conference Artificial
Intelligence, pp. 210215.
Givry, S. D., & Zytnicki, M. (2005). Existential arc consistency: Getting closer full arc
consistency weighted CSPs. Proceedings Nineteenth International Joint
Conference Artificial Intelligence, pp. 8489.
Harvey, W. D. (1995). Nonsystematic Backtracking Search. Ph.D. thesis, Stanford University, Stanford, CA.
Harvey, W. D., & Ginsberg, M. L. (1995). Limited discrepancy search. Proceedings
Fourteenth International Joint Conference Artificial Intelligence, pp. 607613.
Joslin, D. E., & Clements, D. P. (1999). Squeaky wheel optimization. Journal Artificial
Intelligence Research, 10, 353373.
Korf, R. E. (1996). Improved limited discrepancy search. Proceedings Thirteenth
National Conference Artificial Intelligence, pp. 286291.
Larrosa, J., & Dechter, R. (2000). dual representation non-binary semiring-based
CSPs. Proceedings SOFT-2000.
Larrosa, J., & Schiex, T. (2004). Solving weighted CSP maintaining arc consistency.
Artificial Intelligence, 159, 126.
Lecoutre, C., Sas, L., Tabary, S., & Vidal, V. (2009). Reasoning last conflict(s)
constraint programming. Artificial Intelligence, 173, 15921614.
Littman, M. L., Keim, G. A., & Shzaeer, N. (2002). probabilistic approach solving
crossword puzzles. Artificial Intelligence, 134, 2355.
Mackworth, A. K. (1977). Consistency networks relations. Artificial Intelligence, 8,
99118.

885

fiGinsberg

Manning, C. D., & Schuetze, H. (1999). Foundations Statistical Natural Language Processing. MIT Press.
Marinescu, R., & Dechter, R. (2009). AND/OR branch-and-bound search combinatorial
optimization graphical models. Artificial Intelligence, 173, 14571491.
McAllester, D. A. (1993). Partial order backtracking. Unpublished technical report, MIT.
Miller, G. A. (1995). WordNet: lexical database English. Communications
ACM, 38 (11), 3941.
Sanchez, M., de Givry, S., & Schiex, T. (2008). Mendelian error detection complex
pedigrees using weighted constraint satisfaction techniques. Constraints, 13.
Schaeffer, J., Treloar, N., Lu, P., & Lake, R. (1993). Man versus machine world
checkers championship. AI Magazine, 14 (2), 2835.
Smith, S. J., Nau, D. S., & Throop, T. (1996). Total-order multi-agent task-network planning contract bridge. Proceedings Thirteenth National Conference
Artificial Intelligence, Stanford, California.
Sontag, D., Globerson, A., & Jaakkola, T. (2011). Introduction dual decomposition
inference. Sra, S., Nowozin, S., & Wright, S. J. (Eds.), Optimization Machine
Learning, pp. 219254. MIT Press.
Zytnicki, M., Gaspin, C., de Givry, S., & Schiex, T. (2009). Bounds arc consistency
weighted CSPs. Journal Artificial Intelligence Research, 35, 593621.

886

fiJournal Artificial Intelligence Research 42 (2011) 815-850

Submitted 07/11; published 12/11

Stochastic Enforced Hill-Climbing
Jia-Hong Wu

JW @ ALUMNI . PURDUE . EDU

Institute Statistical Science,
Academia Sinica, Taipei 115, Taiwan ROC

Rajesh Kalyanam
Robert Givan

RKALYANA @ PURDUE . EDU
GIVAN @ PURDUE . EDU

Electrical Computer Engineering,
Purdue University, W. Lafayette, 47907, USA

Abstract
Enforced hill-climbing effective deterministic hill-climbing technique deals local optima using breadth-first search (a process called basin flooding). propose evaluate
stochastic generalization enforced hill-climbing online use goal-oriented probabilistic planning problems. assume provided heuristic function estimating expected cost
goal flaws local optima plateaus thwart straightforward greedy action choice.
breadth-first search effective exploring basins around local optima deterministic problems, stochastic problems dynamically build solve heuristic-based Markov decision
process (MDP) model basin order find good escape policy exiting local optimum.
note building model involves integrating heuristic MDP problem
local goal improve heuristic.
evaluate proposal twenty-four recent probabilistic planning-competition benchmark
domains twelve probabilistically interesting problems recent literature. evaluation,
show stochastic enforced hill-climbing (SEH) produces better policies greedy heuristic
following value/cost functions derived two different ways: one type derived using
deterministic heuristics deterministic relaxation second type derived automatic learning Bellman-error features domain-specific experience. Using first type heuristic,
SEH shown generally outperform planners first three international probabilistic
planning competitions.

1. Introduction
Heuristic estimates distance-to-the-goal long used deterministic search deterministic planning. estimates typically flaws local extrema plateaus limit
utility. Methods simulated annealing (Kirkpatrick, Gelatt, & Vecchi, 1983; Cerny,
1985) A* (Nilsson, 1980) search developed handling flaws heuristics.
recently, excellent practical results obtained flooding local optima using breadth-first
search. method called enforced hill-climbing (Hoffmann & Nebel, 2001).
Deterministic enforced hill-climbing (DEH) proposed work Hoffmann Nebel
(2001) core element successful deterministic planner Fast-Forward (FF). DEH
extension basic hill-climbing approach simply selecting actions greedily looking
ahead one action step, terminating reaching local optimum. DEH extends basic hillclimbing replacing termination local optima breadth-first search find successor state
strictly better heuristic value. planner moves descendant repeats
c
2011
AI Access Foundation. rights reserved.

fiW U , K ALYANAM , & G IVAN

process. DEH guaranteed find path goal problem deadend-free (so
every state path). relatively weak guarantee applies independent quality
heuristic function, intent DEH remediate flaws generally accurate heuristic
order leverage heuristic finding short paths goal. domains basin
size (search depth needed escape optimum) bounded, DEH provide polynomial-time
solution method (Hoffmann, 2005).
Enforced hill-climbing defined probabilistic problems, due stochastic outcomes
actions. presence stochastic outcomes, finding descendants better values longer
implies existence policy reaches descendants high probability. One may argue FF-Replan (Yoon, Fern, & Givan, 2007)a top performer recent probabilistic planning
benchmarksuses enforced hill-climbing call FF. However, enforced hill-climbing
process used determinized problem, FF-Replan use form hill climbing
directly stochastic problem. fact, FF-Replan consider outcome probabilities
all.
One problem consider generalizing enforced hill-climbing stochastic domains
solution deterministic problem typically concise, sequential plan. contrast, solution
stochastic problem policy (action choice) possibly reached states. essential
motivation hill-climbing avoid storing exponential information search, even
explicit solution stochastic problem cannot directly stored respecting motivation.
reason, limit consideration online setting, solution problem
local policy around current state. local policy committed executed
local region exited, planner new online problem solve (possibly retaining
information previous solution). approach generalizes directly construction
offline policies situations space store policies available. Note that, contrast,
deterministic enforced hill-climbing easily implemented offline solution technique.
propose novel tool stochastic planning generalizing enforced hill-climbing goalbased stochastic domains. Rather seeking sequence actions deterministically leading
better state, method uses finite-horizon MDP analysis around current state seek policy
expects improve heuristic value current state. Critical process direct
incorporation probabilistic model heuristic function finding desired policy.
Therefore, finite-horizon analysis, heuristic function integrated MDP problem
order represent temporary, greedy goal improving current heuristic value.
integration done building novel heuristic-based MDP state new exit
action available terminates execution cost equal heuristic estimate state,
action costs removed1 . heuristic-based MDP, finite-horizon policies restricted
requirement horizon one, exit action must selected (but also selected
horizons). heuristic-based MDP, cost policy state expected
value heuristic upon exit (or horizon) executed s.
Thus, find desired local policy using value iteration heuristic-based MDP around
current state, deepening horizon, policy found cost improving heuristic
estimate current state. restriction selecting exit action horizon one corresponds
initializing value iteration provided heuristic function. policy found,
1. motivation removal action costs heuristic-based MDP discussed Section 3.2.

816

fiS TOCHASTIC E NFORCED H ILL -C LIMBING

method executes policy exiting action indicated (or horizon used computing
policy).
resulting method, stochastic enforced hill-climbing (SEH), simply generalizes depth-k
breadth-first search state improved heuristic value (from DEH) k-horizon value iteration computation seeking policy expects improvement heuristic value. Note although
stochastic enforced hill-climbing explicit statespace technique, suitable use astronomically large statespaces heuristic used informative enough limit effective size
horizon k needed find expected heuristic improvement. empirical results work
demonstrate behavior successfully.
1.1 Applicability Limitations
Stochastic enforced hill-climbing (SEH) applied heuristic function. However,
applicability (and likewise limitations) SEH greatly depends characteristics
heuristic function. SEH appropriate goal-oriented problem given strong enough heuristic
function, demonstrate empirically SEH generally outperforms greedy following
heuristic variety heuristics variety domains, even presence probabilistically interesting features (Little & Thiebaux, 2007) deadends. SEH rely upon heuristic
function identification dead-ends appropriate handling probabilistically interesting features require non-local analysisSEH simply provides local search often correct
flaws heuristic function. SEH thus intended possible improvement stochastic
solution methods construct cost-to-go (cost) function follow greedily using
constructed cost function search heuristic. Many methods constructing value/cost functions
proposed evaluated literature, potentially improved
goal-based domains using SEH place greedy following (Sutton, 1988; Fahlman & Lebiere,
1990; Bertsekas, 1995; Gordon, 1995; Mahadevan & Maggioni, 2007; Sanner & Boutilier, 2009)2 .
prove correctness SEH Section 3.4 showing deadend-free domains, SEH
finds goal probability one (i.e. SEH get stuck local optima).
SEH search technique leverages heuristic estimate distance go, must
emphasized that, unlike many search techniques, SEH makes promises
optimality solution path found. SEH greedy, local technique promise
repeatedly find policy reduces heuristic value, possible. such,
SEH inappropriate technique use optimal solutions required.
Stochastic enforced hill-climbing ineffective presence huge plateaus valleys
heuristic functions, due extreme resource consumption finding desired local policies.
Heuristic functions huge plateaus result methods failed find useful information problem state regions. SEH inappropriate tool solving
stochastic planning problemother tools needed construct useful heuristic function
manages deadends avoids huge plateaus. weakness mirrors weakness enforced hillclimbing deterministic domains. SEH also fail find goals avoidable dead-ends
present recognized early enough heuristic. fact, effective dead-end detection
central goal heuristic design greedy technique applied heuristic.
2. applicability SEH, cost function must non-negative must identify goals assigning zero state
goal state; however, general value/cost functions normalized satisfy requirements.

817

fiW U , K ALYANAM , & G IVAN

insight usefulness SEH gained comparison recent determinizing replanners. mentioned above, one way exploit deterministic planning techniques
DEH stochastic problems determinize planning problem use deterministic planner select action sequence. Executing action sequence problem guaranteed
reach goal due determinization approximation, replanning needed augment
technique. paper, call stochastic planners use technique determinizing replanners. Determinizing replanners using determinization (called outcomes) retains
possible state transitions shown reach goal probability one absence
dead-end states.
contrast determinizing replanners, SEH point relies determinization
problem, instead analyzes increasing-size local probabilistic approximations problem.
SEH conducts full probabilistic analysis within horizon, seeking objective reducing
provided heuristic, using value iteration. way, SEH leverages probabilistic parameters
ignored determinizing replanners, well provided heuristic function,
based upon substantial probabilistic analysis. result, SEH successfully handles probabilistic
problem aspects cause major problems determinizing replanners. However, point,
theoretical results characterizing gains determinizing replanners. Instead,
extensive empirical evaluation showing advantages FF-Replan (Yoon et al., 2007)
RFF (Teichteil-Konigsbuch, Kuter, & Infantes, 2010) (two determinizing replanners), well
substantial gains compared greedy following heuristic (which also uses transition
probability parameters).
1.2 Evaluation
test SEH broad range domains first three international probabilistic planning
competitions (as well probabilistically interesting domains Little & Thiebaux, 2007),
using two different methods generate heuristic functions. First, test SEH heuristic function based ideas successful re-planner FF-Replan (Yoon et al., 2007).
new controlled-randomness FF (CR-FF) heuristic deterministic FF heuristic (Hoffmann
& Nebel, 2001) computed simple determinization probabilistic problem makes
available deterministic transition wherever probabilistic transition possible. note
FF-Replan use (or any) heuristic function stochastic problem. Instead, FFReplan relies FF construct plan deterministic problem, calls FF turn use
deterministic enforced hill-climbing exactly heuristic. Here, consider performance
heuristic directly stochastic problem, comparing greedy heuristic-following SEHbased search around heuristic. latter method using SEH constitutes novel method
combining determinization (that removes probabilistic parameters) probabilistic reasoning.
experiments show new method substantially outperforms FF-Replan across broad
evaluation.
also performed second evaluation technique heuristic functions learned
domain-specific experience relational feature-learning method presented work
Wu Givan (2007, 2010). heuristic functions already shown give good
performance used construct simple greedy policy, improved SEH.
SEH technique seen perform well domain-by-domain analysis across
broad set competition planning domains, full domain-by-domain results available
818

fiS TOCHASTIC E NFORCED H ILL -C LIMBING

online appendix. However, compress summarize extensive per-problem results,
divided evaluation domains experimenter-defined categories aggregated performance measurement within problem category. categories single domains,
generally, multiple closely related domains may aggregated within single category.
example, multiple domains competitions variants blocks world,
problems domains aggregated B LOCKSWORLD category.
order fairly compare SEH FF-based planners (such RFF, described TeichteilKonigsbuch et al., 2010, FF-Replan) exploit blocksworld-targeted planning heuristics
added goal deletion goal agenda, provided heuristics extensions SEH.
resulting planner called SEH+ , described detail Section 3.6. results show SEH+
performs nearly identically SEH non-blocksworld categories using CR-FF heuristic.
employ extensions comparing SEH CR-FF heuristic planners.
Using experimenter-defined categories, able show SEH exploits heuristic
functions effectively greedy following heuristic. SEH statistically significantly
outperforms greedy following thirteen seventeen categories using CR-FF heuristics
losing one category. SEH also outperforms greedy following six seven categories using learned heuristics. (In cases, categories showed similar performance
compared planners.)
show SEH+ , using CR-FF heuristics, outperforms FF-Replan ten
fifteen categories, similar performance two categories, losing three categories.
aggregate results show SEH+ (using CR-FF heuristics) particularly strong performance advantage FF-Replan probabilistically interesting categories (Little & Thiebaux,
2007).
Finally, compare performance SEH+ RFF-BG (Teichteil-Konigsbuch
et al., 2010), one winner fully-observable track third international probabilistic planning competition. SEH+ outperforms RFF-BG twelve fifteen categories, similar
performance one category, losing two categories.
summary, empirical work demonstrates SEH provides novel automatic technique
improving heuristic function using limited searches, simply applying SEH
reasonable heuristic functions produces state-of-the-art planner.

2. Technical Background: Markov Decision Processes
give brief review Markov decision processes (MDPs) specialized goal-region objectives.
detail MDPs, see work Bertsekas (1995), Puterman (2005), Sutton Barto
(1998).
2.1 Goal-Oriented Markov Decision Processes
Markov decision process (MDP) tuple (S, A, C, T, sinit ). Here, finite state space
containing initial state sinit , selects non-empty finite available action set A(s) state
S. action-cost function C assigns non-negative real action-cost state-action-state
triple (s, a, ) action enabled state s, i.e., A(s). transition probability
function maps state-action pairs (s, a) probability distributions S, P(S),
A(s).
819

fiW U , K ALYANAM , & G IVAN

represent goal, include zero-cost absorbing state , i.e., C(, a, s) =
0 (, a, ) = 1 A(). Goal-oriented MDPs MDPs
subset G statespace, containing , that: (1) C(g, a, ) zero whenever g G
one otherwise, (2) (g, a, ) one g G A(g). set G thus
taken define action-cost function C, well constrain transition probabilities .
(stochastic) policy MDP : N P(A) specifies distribution actions
state finite horizon. cost-to-go function J (s, k) gives expected cumulative
cost k steps execution starting state selecting actions according () state
encountered. horizon k, least one (deterministic) optimal policy (, k)

J (s, k), abbreviated J (s, k), greater J (s, k) every state s,
policy . following Q function evaluates action using provided cost-to-go function
J estimate value action applied,
X
Q(s, a, J) =
(s, a, )[C(s, a, ) + J(s )].


Recursive Bellman equations use Q() describe J J follows:
J (s, k) = E [Q(s, (s, k), J (, k 1))]
J (s, k) = min Q(s, a, J (, k 1)),
aA(s)

taking expectation random choice made possibly stochastic policy (s, k).
cases, zero step cost-to-go function zero everywhere, J (s, 0) = J (s, 0) = 0
s. Value iteration computes J (s, k) k increasing order starting zero. Note
policy cost function depend k, may drop k argument list.
Also using Q(), select action greedily relative cost function. policy
Greedy(J) selects, state horizon k, uniformly randomly selected action
argminaA(s) Q(s, a, J(, k 1)).
goal-based MDP problems directly specified above, may also specified
exponentially compactly using planning languages PPDDL (Younes, Littman, Weissman, & Asmuth, 2005), used experiments. technique avoids converting
entire PPDDL problem explicitly form, resource reasons, instead constructs
sequence smaller problems explicit MDP form modeling heuristic flaws.
dead-end state state every policy zero probability reaching goal
horizon. say policy reaches region states probability one following policy
horizon k probability entering region point converges one k goes
infinity. say dead-ends unavoidable problem whenever policy sinit
reaches goal region probability one. (We say domain unavoidable dead-ends
problem domain unavoidable dead-ends.) note greedy techniques
hill-climbing expected perform poorly domains dead-end states attractive
heuristic values. Application SEH thus leaves responsibility detecting avoiding deadend states design heuristic function.
heuristic h : R may provided, intended estimate cost function J large
horizons, h(s) = 0 G, h(s) > 0 otherwise. heuristic may indicate dead-end
states returning large positive value V assume selected experimenter
exceed expected steps goal state reach goal. experiments,
820

fiS TOCHASTIC E NFORCED H ILL -C LIMBING

add trivial, incomplete dead-end detection (described Section 5.2) heuristic function
evaluate.
note domains evaluated paper contain unavoidable deadends,
may policy success ratio one. choice large value used recognized
dead-end states effects trade-off optimizing success ratio optimizing expected cost
incurred goal successful.
2.2 Determinizing Stochastic Planning Problems
stochastic planners heuristic computation techniques, including used experiments, rely computing deterministic approximations stochastic problems. One planner,
all-outcomes FF-Replan (Yoon et al., 2007), determinizes stochastic planning problem
invokes deterministic planner FF (Hoffmann & Nebel, 2001) determinized problem.
determinization used FF-Replan constructed creating new deterministic action
possible outcome stochastic action ignoring probability outcome happening. effectively allows planner control randomness executing actions, making
determinization kind relaxation problem. Section 5.2, define domainindependent heuristic function, controlled-randomness FF heuristic (CR-FF), deterministic FF heuristic (Hoffmann & Nebel, 2001) computed all-outcomes FF-Replan determinization probabilistic problem3 . variety relaxations previously combined
variety deterministic heuristics order apply deterministic planning techniques stochastic problems (Bonet & Geffner, 2005). generally, deterministic relaxations provide general
technique transferring techniques deterministic planning use solution stochastic
problems.

3. Stochastic Enforced Hill-Climbing
Deterministic enforced hill-climbing (DEH) (Hoffmann & Nebel, 2001) searches successor
state strictly better heuristic value returns path current state successor.
path action sequence guarantees reaching desired successor. illustrate
behavior DEH compared greedy policy using example Figure 1. stochastic
environment, may single better descendant reached probability one,
since actions may multiple stochastic outcomes. simply use breadth-first search
DEH find single better descendant ignore possible outcomes, might end
selecting action low probability actually leading state better heuristic value,
illustrated Figure 2. shown figure, algorithm, stochastic enforced hill-climbing
(SEH), accurately analyzes probabilistic dynamics problem improving heuristic
value.
section, give details SEH. note DEH, local breadth-first search
gives local policy state region surrounding current state deterministic environment.
value following policy heuristic value improved descendant found
breadth-first search. SEH, implement ideas stochastic setting.
3. deterministic FF heuristic, described work Hoffmann Nebel (2001), FF planner version 2.3
available http://www.loria.fr/hoffmanj/ff.html, efficiently computes greedy plan length problem relaxation
state facts never deleted. plan found relaxed problem referred relaxed plan
problem.

821

fiW U , K ALYANAM , & G IVAN

h=7

h=7

h=5

h=5

h=7
h=8

h=0

h=7

h=8

h=8

h=0

h=6
h=8

h=6

h = 10

h = 10

(a) Behavior greedy policy.

(b) Behavior DEH.

Figure 1: Comparison behavior DEH greedy policy local optimum
encountered. solid black circle represents current state, shaded circle represents
goal state (with heuristic value zero). (a) greedy policy keeps selecting actions indicated
wide arrow cannot reach goal state. hand, DEH uses breadth-first search
finds goal state two steps away current state, shown (b).

h=7
h=5
h=7
h=8

h=7

p =0.2
p =0.8

h=6

h=5

h=2

h = 10

p =0.2

h=7

h=0

p =0.8
h=8

(a) Behavior DEH stochastic environments.

h=6

h=2

h=0

h = 10

(b) Behavior SEH stochastic environments.

Figure 2: Comparison behavior SEH DEH stochastic example. assume
DEH first determinizes problem, creating one deterministic action possible stochastic
outcome. solid black circle represents current state, shaded circle represents
goal state (with heuristic value zero). (a) DEH looks one step ahead selects action drawn
double lines, one outcomes leads state h = 2, better current
state. However, action choice higher probability going state h = 10
one h = 2. (b) SEH first decides policy better value 5
horizon MDP includes states reachable current state one step. SEH
extends horizon two states considered. selects actions indicated
wide arrows lead goal state.

822

fiS TOCHASTIC E NFORCED H ILL -C LIMBING

Online Planning using Local Planner
1. Repeat
2.
current state
3.
local Find-Local-Policy(s,h)
4.
Follow local selected
5. goal reached
Table 1: Pseudo-code online planning framework. policy local may non-stationary,
case local planner also returns initial horizon execution policy termination line 4 also happen reaching specified horizon.

present SEH two steps. First, present simple general framework online planning repeatedly calls local planner selects policy around current state. Second,
present local planner based enforced hill-climbing idea. online planning
framework instantiated local planner, resulting algorithm SEH. combination
two steps constitute central algorithmic contribution paper. Finally, present
analytical properties algorithm.
3.1 Simple Online Planning Framework
familiar direct approach online planning call planner current state
planner select action. action executed environment, resulting new current
state. process repeated.
Here, present simple generalization approach allows planner select
one action call, action executed. idea planner makes
plan local context surrounding current state, plan executed local
context exited. local context exited, new current state process
repeated.
formally, augment action space new terminate action (called ), indicating planned-for local context exited. define local policy around state
partial mapping states augmented action space defined every
state reachable policy4 . online planner built repeatedly seeking
executing local policy around current state using planning subroutine. local policy
executed terminate action called (which effect state), point
new local policy must sought. ideas reflected pseudo-code shown Table 1.
note notion local context discussion informal precise
notion given use terminate action. local policy executed selects
terminate action. Find-Local-Policy routine free use method decide state
assigned terminate action. Previously published envelope methods (Dean, Kaelbling,
Kirman, & Nicholson, 1995) provide one way address issue, termination
assigned every state outside envelope states. However, framework general
envelope methods, allows local policies selected based upon pre-existing
4. local policy returned non-stationary finite horizon, must select terminate action
final stage, reachable states.

823

fiW U , K ALYANAM , & G IVAN

envelopes states (though always, post-planning, interpret set reachable states
envelope). general intuition selecting action current states may involve
analysis sufficient select actions many surrounding states, framework allows
Find-Local-Policy routine return policy specifying action selections.
Also, note online planning framework includes recent re-planners FFReplan (Yoon et al., 2007) RFF (Teichteil-Konigsbuch et al., 2010). However, replanning
current plan failed (e.g. determinization used generate naive)
quite different character SEH, constructs plans improve heuristic value,
replans time plan terminates. Thus, SEH uses heuristic function define subgoals
plan original goal incrementally.
remains present local planner combine online planning framework
define stochastic enforced hill climbing. local planner analyzes MDP problem around
current state, heuristic function integrated problem embody subgoal
improving heuristic value current state. describe simple integration
heuristic function problem next, discuss local planner based integration.
3.2 Heuristic-Based Markov Decision Processes
method relies finite horizon analyses transformed MDP problem, increasing horizons. transform MDP problem novel heuristic achievement transform analysis
order represent goal finding executing policy expects improve initial
(current) states heuristic value.
heuristic achievement transform straightforward, applies goal-oriented
MDP problem. First, action costs removed problem. Second, terminate action
assigned action cost h(s) transitions deterministically absorbing state .
policy executed, selection action state result replanning, discussed
online planning framework presented. actions thought heuristic
achievement actions, allowing immediate achievement value promised heuristic
function.
Analyzing MDP transformed heuristic achievement transform finite horizon
around s0 represents problem finding policy improving heuristic value s0
without regard cost achieving improvement heuristic. Allowing heuristic
achievement action selected point state reflects greedy nature goal:
planner forced look improvement found, long policy
initial state expects see improvement.
Formally, given MDP = (S, A, C, T, s0 ) non-negative heuristic function h : R,
heuristic achievement transform h, written Mh , given (S, , C , , s0 ),
, C , follows. Let s, s1 , s2 arbitrary states S. define (s)
A(s) {a }, take C (s1 , a, s2 ) = 0 (s1 , a, s2 ) = (s1 , a, s2 ) A(s1 ).
Finally, define (s, , ) = 1 C (s, , ) = h(s).
transformed MDP zero-cost policies states, immediate use. However, policies required select final action (at horizon one)
represent policies seeking get regions low heuristic value, whatever cost.
increasing-horizon search policies corresponds roughly breadth-first search
improved heuristic value deterministic enforced hill-climbing. Formally, define class
824

fiS TOCHASTIC E NFORCED H ILL -C LIMBING

heuristic-achievement policies H class policies (s, k) satisfy (s, 1) = s.
define Jh (s, k) value minH J (s, k) heuristic transform MDP h h
policy achieves value. note that, due zeroing non-terminal action costs,
Jh (s, k) represents expected heuristic value achieved next execution ,
required horizon k before. Formally, define random variable state
h first executes trajectory s, Jh (s, k) = E[h(s )].
rough motivation setting action costs zero analysis heuristic-based
MDP actions considered method remediate flawed heuristic.
cumulative action cost required reach state improved heuristic value measure
magnitude flaw heuristic. Here, remove cost analysis order
directly express subgoal reaching state lower heuristic value. Including action costs
might, example, lead preferring cheap paths higher heuristic values (i.e., states worse
s0 ) expensive paths lower heuristic values found. basic motivation
enforced hill climbing strongly seek improved heuristic values. Instead diluting
subgoal adding action costs, methods seek shortest path heuristic improvement
analyzing heuristic-based MDP iteratively deepened finite horizon, discussed
next subsection. approach reasonable settings action
cost, finite-horizon value iteration stochastic-setting analogue uniform cost search.
settings varying action cost, future work needed adapt SEH usefully consider
cost without excessively diluting focus improving heuristic.
3.2.1 H EURISTIC ACHIEVEMENT VALUE TERATION
Following formalism value iteration Section 2.1, compute Jh (s, k) heuristic
achievement value iteration follows:
Jh (s, 1) = h(s),
Jh (s, k) = min Q(s, a, Jh (, k 1)) k 2.
aA (s)

non-stationary policy achieving cost-to-go given Jh (, k) also computed using
following definition:
h (s, 1) = ,
h (s, k) = argminaA (s) Q(s, a, Jh (, k 1)) k 2.
Note Q() computed heuristic-achievement transformed MDP Mh equations.
technical reasons arise zero-cost loops present, require tie breaking
argmin h (s, k) favors action selected h (s, k 1) whenever one options.
prevent selection looping actions shorter, direct routes value.
3.3 Local Planner
consider method stochastic enforced hill-climbing uses online planning framework, presented Table 1, together local policy selection method solves
heuristic-achievement MDP (exactly, approximately, heuristically). Here, describe one
straightforward method local policy selection defining SEH-find-local-policy using finitehorizon value iteration. method generalizes breadth-first search used deterministic
825

fiW U , K ALYANAM , & G IVAN

enforced hill-climbing, seeks expected heuristic improvement rather deterministic
path improved heuristic value. sophisticated heuristic methods finite-horizon
value iteration considered implementation presented finds local MDP problems intractable. analytical results Section 3.4 apply method exactly solves
heuristic-achievement MDP, method presented Table 2; experimental results
conducted using implementation Table 2 well.
present pseudo-code SEH-Find-Local-Policy Table 2. heuristic function h respects
goals h(s) = 0 iff G. algorithm assumes non-negative heuristic function h : R
respects goals, input. SEH-Find-Local-Policy(s0 ,h) returns policy h horizon k.
policy computed states horizons needed order execute h s0 using
horizon k policy terminates.
Thus, lines 5 11 Table 2 , heuristic-achievement value iteration conducted increasing horizons around s0 , seeking policy improving h(s0 ). Note given horizon k + 1,
states reachable within k steps need included value iteration.
3.3.1 E ARLY ERMINATION
primary termination condition repeated local policy construction discovery policy
improving heuristic estimate initial state. discussed Proposition 1,
domains without deadends, SEH-Find-Local-Policy always find policy improving h(s0 ),
given sufficient resources.
However, badly flawed heuristic functions large enough horizons analyzed
SEH-Find-Local-Policy may unacceptably large given resource constraints. Moreover, domains unavoidable deadends, may horizon, however large, policy improving
heuristic initial state. reasons, practice, algorithm stops enlarging
horizon heuristic-based MDP analysis user-specified resource limits exceeded.
horizon-limited analysis heuristic-transform MDP construction yield
desired results inexpensively, biased random walk used seek new initial state. example, consider problem provided heuristic labels states reachable k steps
cost-to-go estimates similar, forming large plateau. analysis large
plateau exceeds resources available, biased random walk indicated, lack useful heuristic
guidance.
So, horizon k found Jh (s0 , k) < h(s0 ), system executes h s0
horizon k terminate action selected. resource limit exceeded without
finding horizon, system executes biased random walk length , terminating
action imposed states reachable biased random walk h(s) < h(s0 ).
additional biased random walk allows method retain beneficial properties
random exploration domains heuristic flaws large MDP analysis. resource
consumption threshold random walk triggered viewed parameter controlling
blend random walk MDP-based search used overcoming heuristic flaws.
currently principled way analyzing tradeoff resource consumption
cost switching biased random walk, determining switching. Instead,
use domain-independent resource limits described Section 5.1, determined
experimentation.
826

fiS TOCHASTIC E NFORCED H ILL -C LIMBING

SEH-Find-Local-Policy(s0 ,h)
//
s0 current state.
//
h : {} R heuristic function, extended h() = 0.
//
assume global variable Mh heuristic-achievement
transform original problem h.
//
seek policy problem Mh achieving cost less h(s0 ).
1. k = 1
2. Repeat
3.
k =k+1
4.
// Compute Jh (s0 , k) Mh using value iteration
5.
Jh (, 1) = h(), h (, 1) = , n = 1
6.
Repeat
7.
n=n+1
8.
reachable s0 Mh using k n steps
9.
Jh (s, n) = minaA (s) Q(s, a, Jh (, n 1))
10.
h (s, n) = argminaA (s) Q(s, a, Jh (, n 1))
11.
n = k
12. Jh (s0 , k) < h(s0 ) resource consumption exceeds user-set limits
13. Jh (s0 , k) < h(s0 )
14.

15.
Return h horizon k
16.
else
17.
// Return -step biased random walk policy
18.
// Note: implementations compute lazily online
19.
n = 1
20.
state
21.
h(s) < h(s0 )
22.

23.
(s, n) selects probability one
24.
else
25.
(s, n) selects action A(s) probability
26.

P

eQ(s,a,h)
ai A(s) (e

Q(s,ai ,h) )

Return horizon

Table 2: Pseudo-code local planner used implement stochastic enforced hill-climbing.

827

fiW U , K ALYANAM , & G IVAN

Horizon-limited analysis heuristic-transform MDP may also terminate without finding
horizon k Jh (s0 , k) < h(s0 ) entire reachable statespace explored,
presence deadends. may happen without exceeding available resources,
case fall back fixed number iterations standard VI original MDP model
(including action costs without heuristic transform) reachable states.
3.4 Analytical Properties Stochastic Enforced Hill-Climbing
deterministic settings, given sufficient resources dead-ends, enforced hill-climbing
guarantee finding deterministic path improved heuristic value (if nothing else, goal state
suffice). Given finite state space, guarantee implies guarantee repeated enforced
hill-climbing find goal.
situation subtle stochastic settings. problem dead-ends, every
state optimal policy reaches goal probability one. follows problems,
h assigning zero every goal state, every state real value > 0, horizon
k Jh (s, k) < . (Recall Jh analyzes heuristic transform MDP wherein action costs
dropped except h() must realized horizon one.) SEH-Find-Local-Policy(s,h)
considers k turn Jh (s, k) < h(s) have:

Proposition 1. Given non-goal state s, dead-ends, non-negative heuristic function
h : R respecting goals, sufficient resources, routine SEH-Find-Localpolicy(s,h) returns policy h horizon k expected return Jh (s, k) strictly
less h(s).
However, unlike deterministic setting, policy found routine SEH-Find-Local-Policy
expects improvement heuristic value. particular executions policy
current state may result degraded heuristic value.
Here, prove even stochastic settings, spite possibility poor results
one iteration, SEH reach goal region probability one, absence dead-end states
sufficient resources. practice, provision sufficient resources serious hurdle,
must addressed providing base heuristic modest-sized flaws.

Theorem 1. dead-end free domains, unbounded memory resources, SEH reaches goal region probability one.
Proof. Let x0 , x1 , x2 , . . . , xm , . . . random variables representing sequence
states assigned line 2 Table 1 execute SEH planning problem,
x0 initial state sinit . algorithm achieves x G ,
thus terminates, take xj+1 = xj j . (Note result xj G implies
xj+1 G, G goal region states.)
show arbitrary > 0 probability xm goal region
h(sinit )
least 1
, real value > 0 defined below. expression goes one
828

fiS TOCHASTIC E NFORCED H ILL -C LIMBING

goes infinity, conclude SEH reaches goal region
probability one.
Proposition 1, non-goal state s, absent dead-ends sufficient
resources, one iteration SEH guaranteed return policy finite horizon
ks value Jh (s, ks ) improving h(s). Let = h(s) Jh (s, ks ) > 0 value
improvement horizon ks . finitely many non-goal
states, exists = minsSG > 0 improvement h(s) Jh (s, ks )
least . Consider arbitrary xi
/ G. Noting Jh (xi , kxi ) =
E[h(xi+1 )] due zero action costs Mh , follows immediately E[h(xi )
h(xi+1 )|xi
/ G] , G goal region states. Using xi G implies
xi+1 G h(xi ) = h(xi+1 ) = 0, write
E[h(xi ) h(xi+1 )]
=E[h(xi ) h(xi+1 )|xi
/ G]Qi
+ E[h(xi ) h(xi+1 )|xi G](1 Qi )

(1)

Qi , > 0,
defining Qj probability xj
/ G.
Now, lower-bound expected heuristic improvement E[h(x0 ) h(xm )] calls SEH-Find-Local-Policy, > 0. decompose expected
improvement calls SEH-Find-Local-Policy sum expected improvements individual calls. Then, lower-bounding sum using smallest
term, get
E[h(x0 ) h(xm )]
=


m1
X

i=0
m1
X

E[h(xi ) h(xi+1 )]
(2)
Qi (from Inequality 1)

i=0

mQm ,
Qm non-increasing, since xm1 G implies xm G.
Next, combine lower bound natural upper bound h(sinit ), since h
assumed non-negative (so E[h(x0 ) h(xm )] h(sinit )) x0 = sinit . Thus,
h(sinit ) Qm m.
h(s

)

init , converging zero
Therefore probability Qm xm
/ G
large SEH reaches goal probability one.

theorem assumes absence dead-ends, problems dead-ends covered theorem well dead-ends avoidable identified heuristic.
Specifically, may require heuristic function assigns state
policy reach goal state probability one. case, problem
converted form required theorem simply removing states assigned
consideration (either pre-processing local MDP construction).
829

fiW U , K ALYANAM , & G IVAN

3.5 Variants Extensions SEH
SEH based finite-horizon analysis MDP transformed heuristic-achievement transform around current state s0 . particular heuristic-achievement transform describe
course option incorporating heuristic local search around s0 .
already considered number related alternatives arriving choice describe,
options considered future research. One notable restriction transform
removal action costs, discussed Section 3.2. important method
retain actual heuristic value analysis trade large, small, positive
negative changes heuristic value according probabilities arising. reason,
heuristic transform abstract away value simply assign rewards 1
0 according whether state improves h(s0 ). choice remove action costs local
expansion lead poor performance domains flawed heuristics interacting badly
high variations action costs. subject future research method.
Also, MDP models describe paper limited obvious ways.
limitations include state space discrete finite, problem setting lacks discounting,
objective goal-oriented. yet implement extension relax limitations,
leave consideration issues arise future work. note would appear
method fundamentally goal-oriented, given goal repeatedly reducing heuristic value
current state. However, possible contemplate infinite-horizon discounted non-goaloriented variants seek policies maintain current heuristic estimate.
3.6 Incorporating FF Goal-Ordering Techniques SEH
planner FF contains heuristic elements inspired ordering issues arise blocksworld
problems (Hoffmann & Nebel, 2001). heuristic elements improve performance blocksworld problems significantly. assist fair comparison SEH FF-Replan,
implemented two heuristic elements, namely goal agenda added goal deletion, variant
SEH call SEH+ .
implementation SEH+ follows. stochastic planning problem first determinized using outcomes determinization described Section 2.2. goal-agenda technique FF invoked determinized problem extract sequence temporary goals
G1 , . . . , Gm , Gi set goal facts Gm original problem goal. SEH
stochastic version added goal deletion, described next subsection, invoked repeatedly compute sequence states s0 , . . . , sm , s0 initial state > 0 si
defined state reached invoking SEH state si1 goal Gi (thus satisfying Gi ).
Added goal deletion idea pruning state search space avoiding repetitive addition
deletion goal fact along searched paths. FF, search state s, goal fact
achieved action arriving s, deleted action relaxed plan found s,
expanded (Hoffmann & Nebel, 2001).
stochastic adaptation added goal deletion, define set facts added
state transition (s, a, ) facts true represent set difference
s. Then, set added goal facts transition added facts also true
current temporary goal Gi , i.e., (s s) Gi . prune state transition (s, a, ) whenever
relaxed plan computed current temporary goal Gi contains action deletes
added goal facts. transition (s, a, ) pruned modifying Bellman update
830

fiS TOCHASTIC E NFORCED H ILL -C LIMBING

state contributes dead-end state value (V ) Q-value s, weighted
transition probability (instead contributing cost-to-go ). formally, define
modified Q-function using added goal deletion, Qagd (s, a, J) follows:
(
1, f (s s) Gi deleted action relaxed plan(s ,Gi )5

I(s ) =
0, otherwise
X
Qagd (s, a, J) =
(s, a, )[I(s )V + (1 I(s ))J(s )]


Qagd () replaces Q() definition cost-to-go function Jh () Section 3.2. Also,
reachability line 8 Table 2 use pruned transitions.
problems, subsequent deletion newly added goals unavoidable valid plan.
Added goal deletion prunes routes leading goal region problems even though
actual deadend present. Hence, incomplete technique discussed work
Hoffmann Nebel (2001). FF falls back best-first search DEH able find valid
plan due pruning. Similarly, unable find improved policy, SEH falls back either
value iteration biased random walk described Section 3.3.
Preliminary exploration incorporating stochastic variants FFs helpful action pruning
(Hoffmann & Nebel, 2001) SEH improve performance, much like effect added
goal deletion domains except blocksworld6 . result, report helpfulaction-pruning methods here.

4. Related Work
section discuss planning techniques close work one dimensions.
4.1 Fast-Foward (FF) Planner Deterministic Enforced Hill-Climbing
introduction deterministic enforced hill-climbing (DEH) relation technique,
please see Section 3. Here, additionally note several lines work directly
extend FF planner allow planning numeric state-variables (Hoffmann, 2003) planning uncertainty (Hoffmann & Brafman, 2006, 2005; Domshlak & Hoffmann, 2007). Although
techniques involve significant changes computation relaxed-plan heuristic
possible addition use belief states handle uncertainty, enforced hill-climbing still
primary search technique used lines work. note although work Domshlak Hoffmann actions probabilistic outcome handled, planner (Probabilistic-FF)
designed probabilistic planning observability, whereas planner designed
probabilistic planning full observability.
4.2 Envelope-Based Planning Techniques
Stochastic enforced hill-climbing dynamically constructs local MDPs find local policy leading
heuristically better state regions. concept forming local MDPs, envelopes, using
5. relaxed plan(s ,Gi ) computes relaxed plan states Gi defined work Hoffmann
Nebel (2001) using all-outcomes problem determinization defined Section 2.2.
6. explored ideas based defining helpfulness action expectation helpfulness
deterministic outcomes.

831

fiW U , K ALYANAM , & G IVAN

facilitate probabilistic planning used previous research work Bonet
Geffner (2006), Dean et al. (1995), briefly review here.
envelope-based methods work Dean et al. (1995) Gardiol Kaelbling (2003)
start partial policy restricted area problem (the envelope), iteratively improves solution quality extending envelope recomputing partial policy.
typical assumption implementing method planner initial trajectory
starting state goal, generated stochastic planner, use initial envelope.
Another line work, including RTDP (Barto, Bradtke, & Singh, 1995), LAO* (Hansen &
Zilberstein, 2001), LDFS (Bonet & Geffner, 2006), starts envelope containing
initial state, iteratively expands envelope expanding states. States expanded
according state values dynamic programming methods used backup state values
newly added states, convergence criterion reached. Stochastic enforced hill-climbing
viewed repeatedly deploying envelope method goal, time, improving
heuristic estimate distance-to-go. good h function, invocations result trivial
one-step envelopes. However, local optima plateaus encountered, envelope may
need grow locate stochastically reachable set exits.
referenced previous search methods constructed envelopes seeking high
quality policy goal rather far limited relatively inexpensive goal basin
escape. results derive online greedy exploitation heuristic rather
expensive offline computation converged values proving overall (near) optimality. LDFS,
example, compute/check values least states reachable optimal policy (even
given J input) possibly vastly many others well computation.
previous methods able exploit properties (such admissibility)
heuristic function guarantee avoiding state expansions regions state space. Clearly,
SEH exploits heuristic function way avoid expanding regions statespace.
However, point conducted theoretical analysis regions guaranteed unexpanded particular kinds heuristic, analyses may quite difficult.
4.3 Policy Rollout
technique policy rollout (Tesauro & Galperin, 1996; Bertsekas & Tsitsiklis, 1996) uses
provided base policy make online decisions. technique follows policy Greedy(Vf ),
Vf computed online sampling simulations policy .
computation optimal heuristic-transform policy h SEH similarities policy
rollout: case, online decisions made local probabilistic analysis leverages provided information manage longer-range aspects local choice. SEH, heuristic function
provided while, policy rollout, base policy provided. view, policy rollout local
analysis assumption non-local execution use base policy , whereas SEH
local analysis assumption non-local execution achieve base heuristic
cost estimate h.
fact, goal-oriented setting, provided heuristic function h stochastic (a simple generalization describe paper), equal sampled-simulation evaluation
V policy , SEH executes policy policy rollout, assuming uniform
action costs sufficient sampling correctly order action choices. claim follows h = V always action yield expected improvement h one step,
832

fiS TOCHASTIC E NFORCED H ILL -C LIMBING

goal-oriented setting. need uniform action costs claim may relaxed
variant SEH developed retains action costs heuristic transform.
policy rollout, horizon-one greedy use sampled heuristic needed, main
substance SEH enable repair use heuristic functions flaws cannot
repaired horizon one. Thus central differences techniques reflected
ability SEH leverage arbitrary heuristic functions repair flaws functions larger
horizons.
Policy rollout provides elegant guarantee online policy selected improves base
policy, given sufficient sampling. result follows intuitively computed policy
policy-iteration improvement base policy. Unfortunately, similar guarantee known
apply SEH arbitrary heuristic function. However, policy rollout cannot used improve
arbitrary heuristic function either.
4.4 Local Search Optimization
Stochastic enforced hill-climbing regarded one many local-search techniques designed
improve greedy one-step lookahead, naive form local search optimization.
briefly discuss connections method simulated annealing, one large family related
local search techniques. detail, please see work Aarts Lenstra (1997).
Simulated annealing (Kirkpatrick et al., 1983; Cerny, 1985) allows selection actions
inferior expected outcome probability monotone action q-value. probability
inferior action selected often starts high decreases time according cooling schedule. ability select inferior actions leads non-zero probability escaping local
optima. However, method systematically search policy so. contrast,
stochastic enforced hill-climbing analyzes heuristic-based MDP increasing horizons systematically search policies give improved expected value (hence leaving local extrema).
substantial preliminary experiments, could find successful parameter settings control
simulated annealing effective application online action selection goal-directed stochastic
planning. knowledge, simulated annealing otherwise tested direct forwardsearch action selection planning, although variants applied success
planning-as-search settings (Selman, Kautz, & Cohen, 1993; Kautz & Selman, 1992; Gerevini &
Serina, 2003) planning via Boolean satisfiability search.

5. Setup Empirical Evaluation
Here, describe parameters used evaluating method, heuristics test
method on, problem categories tests conducted, random variables
aggregated evaluation, issues arising interpreting results statistical significance.
run experiments Intel Xeon 2.8GHz machines 533 MHz bus speed 512KB
cache.
5.1 Implementation Details
horizon increase new states reachable, implementation SEH simply switches
explicit statespace method solve MDP formed reachable states. specifically,
833

fiW U , K ALYANAM , & G IVAN

increase k line 3 Table 2 lead new reachable states line 8, trigger
value iteration states reachable s0 .
Throughout experiments, thresholds used terminate local planning line 12 Table 2
set 1.5 105 states one minute. set biased random walk length ten. work
makes assumption heuristic functions used assign large values easily recognized deadends, hill-climbing works poorly presence dead-end attractor states. enforce
requirement simple dead-end detection front-end heuristic function
(described next Section 5.2 heuristic) assigning value 1.0 105 recognized
dead-end states.
denote implementation running heuristic h SEH(h).
5.2 Heuristics Evaluated
describe two different types heuristic functions used evaluation associated
dead-end detection mechanisms.
5.2.1 C ONTROLLED -R ANDOMNESS FF H EURISTIC
use evaluations, define domain-independent heuristic function, controlledrandomness FF heuristic (CR-FF). define CR-FF state FF distance-to-goal
estimate (Hoffmann & Nebel, 2001) computed all-outcomes determinization described
Section 2.2. denote resulting heuristic function F . computing CR-FF heuristic,
use reachability analysis built FF planner detection deadends.
5.2.2 L EARNED H EURISTICS
also test stochastic enforced hill-climbing automatically generated heuristic functions
work Wu Givan (2010), perform state-of-the-art used
construct greedy policy. shift heuristic functions fit non-negative range requirement h discussed previously. learned heuristic functions currently available
seven test categories, tested categories.
note heuristics learned discounted setting without action costs
direct fit distance-to-go formalization adopted here. still able get
significant improvements applying technique. denote heuristics L. states
valid action choice available labeled deadends applying SEH learned
heuristics.
5.3 Goals Evaluation
primary empirical goal show stochastic enforced hill-climbing generally improves
significantly upon greedy following heuristic (using policy Greedy(h) described
technical background above). show true heuristics defined
Section 5.2. show empirically applicability limitation SEH discussed Section 1.1,
different types problems including probabilistically interesting ones (Little & Thiebaux, 2007).
secondary goal evaluation show base heuristics resulting performance strong comparison deterministic replanners FF-Replan (Yoon et al., 2007)
RFF (Teichteil-Konigsbuch et al., 2010). FF-Replan RFF use Fast-Forward (FF)
834

fiS TOCHASTIC E NFORCED H ILL -C LIMBING

base planner, RFF uses most-probable-outcome determinization contrast all-outcomes
determinization used FF-Replan. primary difference RFF FF-Replan
executing plan, RFF grows policy trees minimize probability
replan, FF-Replan not.
5.4 Adapting IPPC Domains Experiments
conduct empirical evaluation using problems first three international probabilistic planning competitions (IPPCs) well twelve probabilistically interesting problems
work Little Thiebaux (2007). omit particular problems domains
particular comparisons several practical reasons, detailed online appendix.
enforced hill-climbing nature goal-oriented technique SEH formulated
goal-oriented setting, ignore reward structure (including action goal rewards)
evaluated problems assume uniform action cost one problems,
transforming reward-oriented problem description goal-oriented one.
provide detailed per-problem results online appendix planner evaluated
work. However, support main conclusions, limit presentation aggregations
comparing pairs planners sets related problems. purpose, define seventeen
problem categories aggregate within problem category. categories single
domains, generally, multiple closely related domains may aggregated within single category. example, blocksworld category aggregates blocksworld problems three
competitions, even though action definitions exactly every problem.
paired comparisons, aggregated results problems labeled constructed
probabilistically interesting IPPC3 organizers work Little Thiebaux
(2007) combined category PI PROBLEMS.
Table 3, list evaluated categories (including combined category PI PROBLEMS),
well planning competitions literature problems category from.
evaluated problems category identified online appendix.
reward-oriented YSADMIN domain IPPC3 stochastic longest-path problem
best performance required avoiding goal continue accumulating reward long
possible (Bryce & Buffet, 2008). (Note contrary organizers report, domains goal
condition servers rather servers down.) goal-oriented adaptation removes
longest-path aspect domain, converting domain goal get
servers up.
B LOCKSWORLD problems IPPC2 contain flawed definitions may lead block
stacking top itself. Nevertheless, goal problems well defined achievable
using valid actions, hence problems included B LOCKSWORLD category.
discovered five rectangle-tireworld problems (p11 p15 IPPC3 2T IREWORLD) apparent bugno requirement remain alive included goal condition. domain design provides powerful teleport action non-alive agents intended
increase branching factor (Buffet, 2011). However, lacking requirement alive goal,
domain easily solved deliberately becoming non-alive teleporting goal.
modified problems require predicate alive goal region. merged
modified rectangle-tireworld problems triangle-tireworld problems IPPC3
835

fiW U , K ALYANAM , & G IVAN

Category

Problem Source(s)

B LOCKSWORLD

IPPC1, IPPC2, IPPC3

B OXWORLD

IPPC1, IPPC3

B USFARE

Little Thiebaux (2007)

RIVE

IPPC2

E LEVATOR

IPPC2

E XPLODING B LOCKSWORLD

IPPC1, IPPC2, IPPC3

F ILEWORLD

IPPC1

P ITCHCATCH

IPPC2

R ANDOM

IPPC2

R IVER

Little Thiebaux (2007)

CHEDULE

IPPC2, IPPC3

EARCH R ESCUE

IPPC3

YSADMIN

IPPC3

YSTEMATIC - TIRE

Triangle-tireworld (IPPC3 2-Tireworld P1 P10, Little Thiebaux (2007)),
Rectangle-tireworld (IPPC3 2-Tireworld P11 P15) bug fixed

IREWORLD

IPPC1, IPPC2

OWERS H ANOI

IPPC1

Z ENOTRAVEL

IPPC1, IPPC2

PI PROBLEMS

B USFARE, RIVE, E XPLODING B LOCKSWORLD
P ITCHCATCH, R IVER, CHEDULE, YSTEMATIC - TIRE, IREWORLD

Table 3: List categories planning competitions literature problems
category taken.

836

fiS TOCHASTIC E NFORCED H ILL -C LIMBING

work Little Thiebaux (2007) category YSTEMATIC - TIRE, problems
systematically constructed emphasize PI features.
5.5 Aggregating Performance Measurements
experiments, designed repeatable aggregate measurements sample
many times order evaluate statistical significance. define random variables representing aggregate measurements describe sampling process, well method
evaluating statistical significance.
5.5.1 EFINING AMPLING AGGREGATE -M EASUREMENT R ANDOM VARIABLES
pair compared planners, define four random variables representing aggregate performance comparisons problems category. random variable based upon
sampling process runs planner five times problems category, aggregates
per-problem result computing mean. use five-trial runs reduce incidence lowsuccess planners failing generate plan length comparison. mean value five-trial run
sample value respective random variable.
First, per-problem success ratio (SR) fraction five runs succeed
problem. success ratio random variable category planner mean SR
across problems category.
Second, per-problem successful plan length (SLen) mean plan length successful
runs among five runs. order compare two planners plan length, define perproblem ratio jointly successful plan lengths (JSLEN-RATIO) two compared planners
follows. planners positive SR among five trials problem, JSLEN-RATIO
ratio SLen values two planners; otherwise, JSLEN-RATIO undefined
problem. use ratio lengths emphasize small plan length differences short solutions
long solutions, decrease sensitivity granularity action definitions.
mean JSLEN-RATIO random variable category pair planners
geometric mean JSLEN-RATIO across problems category JSLEN-RATIO
well defined. manner ensure two planners compared exactly set
problems. Note that, unlike SR, JSLEN-RATIO depends pair compared planners,
rather measurement single planner; ratio successful plan length
jointly solved problems two planners.
Similarly, per-problem ratio jointly successful runtimes (JSTIME-RATIO) defined
manner used comparing plan lengths. mean JSTIME-RATIO computed
geometric mean well-defined per-problem JSTIME-RATIO values.
JSLEN-RATIO JSTIME-RATIO ratios two measurements, use geometric mean aggregate per-problem results generate sample value, whereas use arithmetic
mean SR variables. Note geometric mean desired property planners tied overall (so geometric mean one), mean insensitive planner
given denominator ratio.
Thus, draw single sample four aggregate random variables (SR planner,
JSLEN-RATIO, JSTIME-RATIO) comparing two planners, run two planners
problem five times, computing per-problem values four variables, take (arith837

fiW U , K ALYANAM , & G IVAN

metic geometric) means per-problem variables get one sample aggregate variable. process used repeatedly draw many samples needed get significant results.
use plan-length cutoff 2000 attempt. attempt given time limit 30
minutes.
5.5.2 IGNIFICANCE P ERFORMANCE IFFERENCES B ETWEEN P LANNERS
general goal order pairs planners overall performance category problem.
this, must trade success rate plan length. take position significant
advantage success rate primary goal, plan length used determine preference
among planners success rate differences found significant.
determine significance three performance measurements (SR, JSLENRATIO, JSTIME-RATIO) using t-tests, ascribing significance results p-value
less 0.05. exact hypothesis tested form t-test used depends performance
measurement, follows:
1. SR use paired one-sided t-test hypothesis difference true means
larger 0.02.
2. JSLEN-RATIO use one-sample one-sided t-test hypothesis true geometric mean JSLEN-RATIO exceeds 1.05 (log true mean JSLEN-RATIO exceeds
log(1.05)).
3. JSTIME-RATIO use one-sample one-sided t-test hypothesis true
geometric mean JSTIME-RATIO exceeds 1.05 (log true mean JSTIME-RATIO
exceeds log(1.05)).
stop sampling performance variables achieved one following criteria, representing SR winner determined SR appears tied:
1. Thirty samples drawn p-value SR difference 0.05 0.5.
2. Sixty samples drawn p-value SR difference 0.05 0.1.
3. One hundred fifty samples drawn.
experiments present next, stopping rule leads 30 samples drawn
unless otherwise mentioned. Upon stopping, conclude ranking planners (naming
winner) either SR difference JSLEN-RATIO p-value 0.05, significant
SR differences used first determine winner. neither measure significant upon
stopping, deem experiment inconclusive.
Combining categories evaluations, aggregate results across multiple categories problem, e.g., combined category PI PROBLEMS. cases, effectively
defined one larger category, techniques defining performance measurements determining statistical significance Section 5.5. However, actually re-run
planners combined-category measurements. Instead, re-use planner runs used
single-category experiments. Rather use stopping rule described, compute
maximum number runs available combined categories use many samples
838

fiS TOCHASTIC E NFORCED H ILL -C LIMBING

combined-category performance measurements. avoid double counting problem results,
treat combined categories separately analyzing results counting wins losses.

6. Empirical Results
present performance evaluation stochastic enforced hill-climbing (SEH) section.
experiments underlying results presented involve 169,850 planner runs 17 categories.
6.1 Summary Comparison
results Table 4 show that, CR-FF heuristic, SEH goal-ordering addedgoal-deletion enhancements (SEH+ (F )) improves significantly baseline SEH technique
(SEH(F )) category B LOCKSWORLD, show significant changes aggregated
performance non-blocksworld problems7 . remainder experiments involving CRFF, evaluate SEH+ (F ), noting comparison planners (FF-Replan RFF)
benefit goal-ordering added-goal-deletion enhancements base planner, FFplan.
results present next SEH+ (F ) show:
SEH+ (F ) significantly outperforms Greedy(F ) 13 categories, outperformed
Greedy(F ) CHEDULE. three categories comparison inconclusive (B USFARE, R IVER IREWORLD). See Table 5 details.
FF-Replan inapplicable two categories (IPPC3 EARCH - -R ESCUE IPPC3
YSADMIN). SEH+ (F ) significantly outperforms FF-Replan 10 categories, outperformed FF-Replan three categories (E XPLODING B LOCKSWORLD, P ITCHCATCH,
Z ENOTRAVEL). two categories comparison inconclusive (F ILE WORLD R IVER ). SEH+ (F ) also significantly outperforms FF-Replan combined
category PI PROBLEMS, although winner varied aggregated categories. See
Table 6 details.
RFF-BG inapplicable two categories (B USFARE IPPC1 F ILEWORLD). SEH+ (F )
significantly outperforms RFF-BG 12 categories, outperformed RFF-BG two
categories (E XPLODING B LOCKSWORLD YSTEMATIC - TIRE). one category
comparison inconclusive (S YSADMIN). SEH+ (F ) also significantly outperforms RFF-BG combined category PI PROBLEMS, although winner varied
aggregated categories. See Table 7 details.
learned heuristic work Wu Givan (2010) computed
subset domains, hence seven categories applicable evaluation using
learned heuristic (see online appendix details). results present next SEH
learned heuristic, SEH(L), show:
SEH(L) significantly outperforms Greedy(L) six categories. one category
(T IREWORLD) comparison inconclusive. See Table 8 details.
7. show p-values rounded two decimal places. example, show p=0.00 value p rounded two
decimal places 0.

839

fiW U , K ALYANAM , & G IVAN

SR
SR
SEH+ (F ) SEH(F )

Category

JSLENRATIO
(SEH/
SEH+ )

JSTIMERATIO
(SEH/
SEH+ )

SR
Difference
Significant?
(p-value)

JSLENRATIO
Significant?
(p-value)

Winner

B LOCKSWORLD

0.93

0.72

1.58

2.85

YES

(p=0.00)

YES

(p=0.00)

SEH+ (F )

N - BLOCKSWORLD

0.69

0.69

1.01

0.97



(p=1.00)



(p=1.00)

Inconclusive

Table 4: Aggregated comparison SEH+ (F ) SEH(F ).

SEH(L) significantly outperforms FF-Replan five categories, outperformed FFReplan two categories (E XPLODING B LOCKSWORLD Z ENOTRAVEL). See Table 9
details.
6.2 Discussion
discuss results comparisons pairs planners, including SEH versus greedy
heuristic-following, SEH versus FF-Replan, SEH versus RFF-BG.
6.2.1 SEH/SEH+ V ERSUS G REEDY
primary evaluation goal show stochastic enforced hill-climbing generally improves
significantly upon greedy following heuristic (using policy Greedy(h) described
technical background above). demonstrated evaluating SEH two different
heuristics Tables 5 8, SEH(h) significantly outperforms Greedy(h) nineteen
twenty-four heuristic/category pairs, losing CHEDULE SEH+ (F ) Greedy(F ).
discuss category Greedy outperforms SEH techniques significantly.
CHEDULE, multiple classes network packets different arrival rates. Packets deadlines, packet served deadline, agent encounters classdependent risk death well delay packet cleaned up. reach goal
serving packet every class, agent must minimize dropping-related risk dying
waiting arrival low-arrival-rate class. all-outcomes determinization underlying
CR-FF heuristic gives deterministic domain definition dying optional (never chosen)
unlikely packet arrivals happen choice, leading optimistic heuristic value.
using optimistic heuristic value, basic local goal SEH, improve
current state heuristic, leads building large local MDPs analysis. presence
dead-ends (death, above), even arbitrarily large local MDPs may able achieve local
improvement, CHEDULE, SEH+ typically hit resource limit MDP size
every action step.
contrast, greedy local decision making well suited packet scheduling. Many well known
packet scheduling policies (e.g. earliest deadline first static priority work Liu &
Layland, 1973) make greedy local decisions practically quite effective. experiments,
Greedy policy applied CR-FF benefits locally seeking avoid incidental delays
dropped-packet cleanup: even though heuristic sees risk-of-dying cost dropping, still
recognizes delay cleaning lost dropped packets. Thus, Greedy(F ) class-insensitive
840

fiS TOCHASTIC E NFORCED H ILL -C LIMBING

JSLENSR
RATIO
SR
SEH+ (F ) Greedy(F ) (Greedy/
SEH+ )

Category

JSTIMERATIO
(Greedy/
SEH+ )

SR
Difference
Significant?
(p-value)

JSLENRATIO
Significant?
(p-value)

Winner

B LOCKSWORLD

0.93

0.35

1.40

0.63

YES

(p=0.00)

YES

(p=0.00)

SEH+ (F )

B OXWORLD

0.99

0.05

1.18

1.12

YES

(p=0.00)

YES

(p=0.00)

SEH+ (F )

B USFARE

1.00

0.99

0.85

0.86



(p=0.97)



(p=0.21)

Inconclusive

RIVE

0.69

0.35

1.60

1.41

YES

(p=0.00)

YES

(p=0.00)

SEH+ (F )

E LEVATOR

1.00

0.40

1.82

1.81

YES

(p=0.00)

YES

(p=0.00)

SEH+ (F )

E XPLODING
B LOCKSWORLD

0.44

0.18

1.01

0.63

YES

(p=0.00)



(p=0.93)

SEH+ (F )

F ILEWORLD

1.00

0.21

1.03

0.24

YES

(p=0.00)



(p=1.00)

SEH+ (F )

P ITCHCATCH

0.45

0.00





YES

(p=0.00)

R ANDOM

0.99

0.94

1.76

0.59

YES

(p=0.00)

YES

(p=0.00)

SEH+ (F )

R IVER

0.66

0.67

0.97

0.98



(p=0.60)



(p=0.75)

Inconclusive

CHEDULE

0.54

0.60

1.18

0.32

YES

(p=0.00)

YES

(p=0.01)

Greedy(F )

EARCH
R ESCUE

1.00

1.00

1.23

1.08



(p=1.00)

YES

(p=0.00)

SEH+ (F )

YSADMIN

0.27

0.27

1.21

1.23



(p=1.00)

YES

(p=0.00)

SEH+ (F )

YSTEMATIC
- TIRE

0.29

0.21

1.03

0.72

YES

(p=0.00)



(p=0.86)

SEH+ (F )

IREWORLD

0.91

0.90

0.96

0.79



(p=0.93)



(p=0.74)

Inconclusive

OWERS
H ANOI

0.53

0.00





YES

(p=0.00)

0.90

0.20

1.31

0.74

YES

(p=0.00)



Z ENOTRAVEL




YES

(p=0.00)

SEH+ (F )

SEH+ (F )
SEH+ (F )

Table 5: Aggregated comparison SEH+ (F ) Greedy(F ). R IVER domain evaluation required extending sampling 60 samples per experimental protocol described Section 5.5.2. values p-values JSLEN-RATIO JSTIME-RATIO P ITCHCATCH
OWERS H ANOI available due zero success ratio Greedy(F ) categories.

841

fiW U , K ALYANAM , & G IVAN

JSLENSR
SR
RATIO
SEH+ (F ) FF-Replan (FFR/
SEH+ (F ))

Category

JSTIMERATIO
(FFR/
SEH+ (F ))

SR
Difference
Significant?
(p-value)

JSLENRATIO
Significant?
(p-value)

Winner

B LOCKSWORLD

0.93

0.87

1.33

1.17

YES

(p=0.00)

YES

(p=0.00)

SEH+ (F )

B OXWORLD

0.99

0.88

3.93

1.57

YES

(p=0.00)

YES

(p=0.00)

SEH+ (F )

B USFARE

1.00

0.01

0.00

0.00

YES

(p=0.00)

RIVE

0.69

0.54

1.26

2.42

YES

(p=0.00)

YES

(p=0.00)

SEH+ (F )

E LEVATOR

1.00

0.93

0.95

0.93

YES

(p=0.00)



(p=0.36)

SEH+ (F )

E XPLODING
B LOCKSWORLD

0.44

0.44

0.85

0.56



(p=0.96)

YES

(p=0.00)

FF-Replan

F ILEWORLD

1.00

1.00

0.97

0.57



(p=1.00)



(p=1.00)

Inconclusive

P ITCHCATCH

0.45

0.51

2.78

0.21

YES

(p=0.00)

YES

(p=0.00)

FF-Replan

R ANDOM

0.99

0.96

1.37

0.19

YES

(p=0.00)

YES

(p=0.00)

SEH+ (F )

R IVER

0.66

0.65

0.94

0.93



(p=0.60)



(p=0.33)

Inconclusive

CHEDULE

0.54

0.48

1.04

0.10

YES

(p=0.00)



(p=0.59)

SEH+ (F )

YSTEMATIC
- TIRE

0.29

0.07

0.36

0.38

YES

(p=0.00)

YES

(p=0.00)

SEH+ (F )

IREWORLD

0.91

0.69

0.69

0.57

YES

(p=0.00)

YES

(p=0.00)

SEH+ (F )

OWERS
H ANOI

0.59

0.50

0.64

0.06

YES

(p=0.00)

YES

(p=0.00)

SEH+ (F )

Z ENOTRAVEL

0.90

1.00

0.70

0.10

YES

(p=0.00)

YES

(p=0.00)

FF-Replan

PI
P ROBLEMS

0.55

0.45

1.02

0.54

YES

(p=0.00)



(p=1.00)

SEH+ (F )





SEH+ (F )

Table 6: Aggregated comparison SEH+ (F ) FF-Replan (FFR). R ANDOM R IVER
domains required extending sampling 60 samples OWERS H ANOI domain required
extending sampling 150 samples per experimental protocol described Section 5.5.2.
p-value JSLEN-RATIO B USFARE available extremely low success rate
FFR leads one sample JSLEN gathered 30 attempts, yielding estimated
variance.

842

fiS TOCHASTIC E NFORCED H ILL -C LIMBING

SR
SR
SEH+ (F ) RFF-BG

Category

JSLENRATIO
(RFF-BG/
SEH+ (F ))

JSTIMERATIO
(RFF-BG/
SEH+ (F ))

SR
Difference
Significant?
(p-value)

JSLENRATIO
Significant?
(p-value)

Winner

B LOCKSWORLD

0.93

0.77

0.79

0.22

YES

(p=0.00)

YES

(p=0.00)

SEH+ (F )

B OXWORLD

0.99

0.89

1.03

3.70

YES

(p=0.00)



(p=1.00)

SEH+ (F )

RIVE

0.69

0.61

1.07

1.24

YES

(p=0.00)



(p=0.08)

SEH+ (F )

E LEVATOR

1.00

1.00

1.27

0.15



(p=1.00)

YES

(p=0.00)

SEH+ (F )

E XPLODING
B LOCKSWORLD

0.44

0.43

0.84

0.56



(p=0.92)

YES

(p=0.00)

RFF-BG

P ITCHCATCH

0.45

0.00





YES

(p=0.00)

R ANDOM

0.99

0.74

1.26

0.56

YES

(p=0.00)

YES

(p=0.00)

SEH+ (F )

R IVER

0.66

0.51

0.77

0.21

YES

(p=0.00)

YES

(p=0.00)

SEH+ (F )

CHEDULE

0.54

0.43

1.06

0.08

YES

(p=0.00)



(p=0.40)

SEH+ (F )

EARCH
R ESCUE

1.00

0.01

2.99

0.86

YES

(p=0.00)

YES

(p=0.00)

SEH+ (F )

YSADMIN

0.27

0.27

1.10

9.31



(p=1.00)



(p=0.05)

Inconclusive

YSTEMATIC
- TIRE

0.29

0.81

1.22

4.49

YES

(p=0.00)

YES

(p=0.00)

RFF-BG

IREWORLD

0.91

0.71

0.68

0.21

YES

(p=0.00)

YES

(p=0.00)

SEH+ (F )

OWERS
H ANOI

0.58

0.48

0.64

0.01

YES

(p=0.03)

YES

(p=0.00)

SEH+ (F )

Z ENOTRAVEL

0.90

0.02

1.20

0.04

YES

(p=0.00)



(p=0.27)

SEH+ (F )

PI
P ROBLEMS

0.55

0.51

0.91

0.50

YES

(p=0.00)

YES

(p=0.00)

SEH+ (F )





SEH+ (F )

Table 7: Aggregated comparison SEH+ (F ) RFF-BG. R IVER OWERS
H ANOI domains required extending sampling 60 samples per experimental protocol described Section 5.5.2. values p-values JSLEN-RATIO JSTIME-RATIO P ITCH CATCH available due zero success ratio RFF-BG category.

843

fiW U , K ALYANAM , & G IVAN

SR
SEH(L)

Category

JSLENSR
RATIO
Greedy(L) (Greedy/
SEH)

JSTIMERATIO
(Greedy/
SEH)

SR
Difference
Significant?
(p-value)

JSLENRATIO
Significant?
(p-value)

Winner

B LOCKSWORLD

1.00

1.00

7.00

3.69



(p=1.00)

YES

(p=0.00)

SEH(L)

B OXWORLD

0.89

0.89

5.00

0.55



(p=1.00)

YES

(p=0.00)

SEH(L)

E XPLODING
B LOCKSWORLD

0.10

0.02

1.09

1.00

YES

(p=0.00)



(p=0.31)

SEH(L)

YSTEMATIC
- TIRE

0.34

0.14

0.75

0.39

YES

(p=0.00)

YES

(p=0.00)

SEH(L)

IREWORLD

0.90

0.89

1.05

1.05



(p=0.92)



(p=0.60)

Inconclusive

OWERS
H ANOI

0.60

0.00





YES

(p=0.00)

0.58

0.03

13.25

5.66

YES

(p=0.00)



Z ENOTRAVEL


YES

(p=0.00)

SEH(L)
SEH(L)

Table 8: Aggregated comparison SEH(L) Greedy(L). values JSLEN-RATIO
JSTIME-RATIO p-value JSLEN-RATIO OWERS H ANOI available due
zero success ratio Greedy(L) category.

SR
SEH(L)

Category

JSLENSR
RATIO
FF-Replan (FFR/
SEH(L))

JSTIMERATIO
(FFR/
SEH(L))

SR
Difference
Significant?
(p-value)

JSLENRATIO
Significant?
(p-value)

Winner

B LOCKSWORLD

1.00

0.83

0.99

2.06

YES

(p=0.00)



(p=1.00)

SEH(L)

B OXWORLD

0.89

0.88

3.61

0.54



(p=0.97)

YES

(p=0.00)

SEH(L)

E XPLODING
B LOCKSWORLD

0.10

0.46

0.71

0.73

YES

(p=0.00)

YES

(p=0.00)

FF-Replan

YSTEMATIC
- TIRE

0.34

0.10

0.28

0.18

YES

(p=0.00)

YES

(p=0.00)

SEH(L)

IREWORLD

0.90

0.70

0.66

0.51

YES

(p=0.00)

YES

(p=0.00)

SEH(L)

OWERS
H ANOI

0.60

0.42

0.64

4.76

YES

(p=0.00)

YES

(p=0.00)

SEH(L)

0.58

1.00

0.58

0.03

YES

(p=0.00)

YES

(p=0.00)

FF-Replan



Z ENOTRAVEL

Table 9: Aggregated comparison SEH(L) FF-Replan (FFR).

844

fiS TOCHASTIC E NFORCED H ILL -C LIMBING

policy greedily seeks avoid dropping, similar earliest deadline first. problems
SEH encounters evaluation CHEDULE suggest future work automatically recognizing
domains large MDP construction proving futile automatically reducing MDP size
limits adapt performance towards behavior greedy policy. note across tested
benchmark domains heuristics, one domain/heuristic combination
phenomenon arose practice.
6.2.2 SEH/SEH+ V ERSUS FF-R EPLAN



RFF-BG

also demonstrated performance improvement SEH+ (F ) best performing planners first three international probabilistic planning competitions, outperforming FF-Replan
ten fifteen categories losing three (E XPLODING B LOCKSWORLD, P ITCHCATCH,
Z ENOTRAVEL), outperforming RFF-BG 12 15 categories losing E XPLODING
B LOCKSWORLD YSTEMATIC - TIRE. Additionally, SEH(L) outperforms FF-Replan five
seven categories losing E XPLODING B LOCKSWORLD Z ENOTRAVEL. section
discuss categories SEH+ (F ) SEH(L) lose FF-Replan RFF-BG.
Z ENOTRAVEL logistics domain people transported cities via airplanes
load/unload/fly action non-zero probability effect. result, takes
uncertain number attempts complete task. domains probabilistic effect choice change change, all-outcome determinization leads
safe determinized plan FF-Replanone replanning needed reach goal.
domains, including Z ENOTRAVEL, all-outcomes determinization provide effective
way employ deterministic enforced hill-climbing problem. note though though,
determinization still ignores probabilities action outcomes, lead bad
choices domains (not Z ENOTRAVEL). deterministic stochastic enforced
hill-climbing must climb large basins Z ENOTRAVEL, substantial overhead stochastic backup computations basin expansion leads least constant factor advantage deterministic expansion. extension SEH might address problem successfully future
research would detect domains stochastic choice change non-change,
handle domains emphasis determinization.
E XPLODING B LOCKSWORLD variant blocks world two new predicates detonated destroyed. block detonate once, put-down, probability,
destroying object placed upon. state resulting action depicted Figure 3 delete-relaxed path goal, actual path, state dead-end attractor
delete-relaxation heuristics CR-FF. FF-Replan RFF-BG never select action
path goal including action. SEH+ (F ) weak dead-end detection used experiments select dead action shown, resulting poor performance
situation arises. would possible use all-outcomes determinization improved
dead-end detector conjunction SEH+ (F ) order avoid selecting actions.
dead-end detection would carefully implemented managed control run-time
costs incurred SEH relies critically able expand sufficiently large local MDP regions
online action selection.
P ITCHCATCH, unavoidable dead-end states (used domain designers simulate cost penalties). However, CR-FF heuristic, based all-outcomes determinization, assigns optimistic values correspond assumed avoidance dead-end states.
845

fiW U , K ALYANAM , & G IVAN

Current
State

b3

b5

b4

b1

b2

b5

b3

b2

b4

Goal State

Path
Destroyed Table

Pick table b3

b3

b5

b4

b1

b2

Destroyed Table

Figure 3: illustration critical action choice SEH+ (F ) E XPLODING B LOCKSWORLD
problem (IPPC2 P1). middle state actual path goal delete-relaxed path
goal. Due table exploded, block placed onto table, resulting
middle state dead-end state. middle state dead-end attractive heuristic
value without regard whether blocks shown remaining explosive charge not,
state feature shown.
result, local search SEH+ (F ) unable find expected improvement CR-FF values,
falls back biased random walk domain. domain suggests, domains SEH+ (F ) performs weakly, work needed managing domains
unavoidable deadend states.
two categories SEH(L) loses FF-Replan (E XPLODING B LOCKSWORLD
Z ENOTRAVEL) also categories SEH+ (F ) loses FF-Replan. Greedily following
learned heuristics two categories leads lower success ratio greedily following CRFF, suggesting significant flaws learned heuristics CR-FF. Although SEH able
give least five-fold improvement greedy following, success ratio two categories, improvement large enough SEH(L) match performance SEH+ (F )
FF-Replan, based relaxed-plan heuristic FF.
SEH+ loses RFF YSTEMATIC - TIRE due weak performance Triangle Tireworld problems. Triangle Tireworld provides map connected locations arranged single
safe path source destination, exponentially many shorter unsafe paths8 .
Determinizing heuristics detect risk unsafe paths greedy following
heuristics lead planners (such SEH+ ) take unsafe paths, lowering success rate.
results show SEH+ often repair flawed heuristic, Triangle Tireworld domain heuristic attracts SEH+ apparent improvements actually dead-ends.
contrast, RFF designed increase robustness determinized plans high probability failure. RFF continue planning avoid failure rather relying replanning
failure. initial determinized plan high probability failure (relative RFFs
8. safe path drawn following two sides triangular map, many unsafe paths interior
triangle. Safety domain represented presence spare tires repair flat tire 50%
chance occurring every step.

846

fiS TOCHASTIC E NFORCED H ILL -C LIMBING

JSLENRATIO
(FFR/
SEH+ )

JSTIMERATIO
(FFR/
SEH+ )

SR
Difference
Significant?
(p-value)

JSLENRATIO
Significant?
(p-value)

SR
SEH+ (F )

SR
FFReplan

B LOCKSWORLD

0.70

0.37

0.72

0.88

YES

(p=0.00)

YES

(p=0.00)

SEH+ (F )

B OXWORLD

0.67

0.34

5.02

0.98

YES

(p=0.00)

YES

(p=0.00)

SEH+ (F )

Category

Winner

Table 10: Aggregated comparison SEH+ (F ) FF-Replan scaled-up problems.

Category

SR
SEH+ (F )

SR
RFFBG

JSLENRATIO
(RFFBG/
SEH+ )

JSTIMERATIO
(RFFBG/
SEH+ )

SR
Difference
Significant?
(p-value)

B LOCKSWORLD

0.70

0.33

0.46

0.14

YES

(p=0.00)

B OXWORLD

0.67

0.00

0.88

10.81

YES

(p=0.00)

JSLENRATIO
Significant?
(p-value)

YES

(p=0.00)


Winner

SEH+ (F )
SEH+ (F )

Table 11: Aggregated comparison SEH+ (F ) RFF-BG scaled-up problems.

threshold), RFF extends plan execution often detect need use longer,
safe route.
6.2.3 P ERFORMANCE L ARGE P ROBLEMS
order demonstrate advantages SEH emphasized problem size grows,
present aggregated performance SEH+ (F ) additional large-sized problems generated using generators provided first IPPC. scaling experiments computationally
expensive, run two domains widely evaluated planning literature: B LOCKSWORLD B OXWORLD (which stochastic version logistics).
B LOCKSWORLD, generated 15 problems 25- 30-block problems. B OXWORLD,
generated 15 problems size 20 cities 20 boxes. (Only one problem across three
competitions reached size B OXWORLD, problem unsolved competition
winner, RFF.) aggregated results FF-Replan RFF-BG presented Tables 10
11. experiments scaled-up problems consumed 3,265 hours CPU time
show SEH+ (F ) successfully completed majority attempts FF-Replan RFF
succeeded substantially less often9 .
Note although FF heuristic good B OXWORLD logistics domains,
failure all-outcomes determinization take account probabilities action outcomes
quite damaging FFR B OXWORLD, leading planner often select action hoping
9. statistical protocol requires 30 samples random variable averaging performance 5 solution attempts,
planner problem. 45 problems 3 planners, yields 30*5*45*3=20,250 solution attempts,
taking approximately 10 CPU minutes large problems.

847

fiW U , K ALYANAM , & G IVAN

low-probability error outcome. note RFF uses most-probable-outcome determinization
suffer issues FFR boxworld. Given high accuracy
FF heuristic boxworld, believe ideas RFF likely re-implemented and/or
tuned achieve better scalability boxworld problems. leave possibility direction
future work understanding scalability RFF.

7. Summary
proposed evaluated stochastic enforced hill-climbing, novel generalization
deterministic enforced hill-climbing method used planner FF (Hoffmann & Nebel, 2001).
Generalizing deterministic search descendant strictly better current state
heuristic value, analyze heuristic-based MDP around local optimum plateau reached
increasing horizons seek policy expects exit MDP better valued state.
demonstrated approach provides substantial improvement greedy hill-climbing
heuristics created using two different styles heuristic definition. also demonstrated
one resulting planner substantial improvement FF-Replan (Yoon et al., 2007)
RFF (Teichteil-Konigsbuch et al., 2010) experiments.
find runtime stochastic enforced hill-climbing concern domains.
One reason long runtime number size local optima basins plateaus may
large. Currently, long runtime managed primarily reducing biased random walk
resource consumption exceeds user-set thresholds. possible future research direction regarding
issue prune search space automatically state action pruning.

Acknowledgments
material based upon work supported part National Science Foundation, United
States Grant No. 0905372 National Science Council, Republic China (98-2811M-001-149 99-2811-M-001-067).

References
Aarts, E., & Lenstra, J. (Eds.). (1997). Local Search Combinatorial Optimization. John Wiley &
Sons, Inc.
Barto, A. G., Bradtke, S. J., & Singh, S. P. (1995). Learning act using real-time dynamic programming. Artificial Intelligence, 72, 81138.
Bertsekas, D. P. (1995). Dynamic Programming Optimal Control. Athena Scientific.
Bertsekas, D. P., & Tsitsiklis, J. N. (1996). Neuro-Dynamic Programming. Athena Scientific.
Bonet, B., & Geffner, H. (2005). mGPT: probabilistic planner based heuristic search. Journal
Artificial Intelligence Research, 24, 933944.
Bonet, B., & Geffner, H. (2006). Learning depth-first search: unified approach heuristic search
deterministic non-deterministic settings, application MDPs. Proceedings
Sixteenth International Conference Automated Planning Scheduling, pp. 142
151.
848

fiS TOCHASTIC E NFORCED H ILL -C LIMBING

Bryce, D., & Buffet, O. (2008). International planning competition uncertainty part: Benchmarks
results.. http://ippc-2008.loria.fr/wiki/images/0/03/Results.pdf.
Buffet, O. (2011) Personal communication.
Cerny, V. (1985). Thermodynamical approach traveling salesman problem: efficient simulation algorithm. J. Optim. Theory Appl., 45, 4151.
Dean, T., Kaelbling, L. P., Kirman, J., & Nicholson, A. (1995). Planning time constraints
stochastic domains. Artificial Intelligence, 76, 3574.
Domshlak, C., & Hoffmann, J. (2007). Probabilistic planning via heuristic forward search
weighted model counting. Journal Artificial Intelligence Research, 30, 565620.
Fahlman, S., & Lebiere, C. (1990). cascade-correlation learning architecture. Advances
Neural Information Processing Systems 2, pp. 524 532.
Gardiol, N. H., & Kaelbling, L. P. (2003). Envelope-based planning relational MDPs. Proceedings Seventeenth Annual Conference Advances Neural Information Processing
Systems.
Gerevini, A., & Serina, I. (2003). Planning propositional CSP: Walksat local search
techniques action graphs. Constraints, 8(4), 389413.
Gordon, G. (1995). Stable function approximation dynamic programming. Proceedings
Twelfth International Conference Machine Learning, pp. 261268.
Hansen, E., & Zilberstein, S. (2001). LAO*: heuristic search algorithm finds solutions
loops. Artificial Intelligence, 129, 3562.
Hoffmann, J. (2003). Metric-FF planning system: Translating ignoring delete lists numeric
state variables. Journal Artificial Intelligence Research, 20, 291341.
Hoffmann, J., & Brafman, R. (2005). Contingent planning via heuristic forward search implicit
belief states. Proceedings 15th International Conference Automated Planning
Scheduling.
Hoffmann, J., & Brafman, R. (2006). Conformant planning via heuristic forward search: new
approach. Artificial Intelligence, 170(6-7), 507 541.
Hoffmann, J. (2005). ignoring delete lists works: Local search topology planning benchmarks. Journal Artificial Intelligence Research, 24, 685758.
Hoffmann, J., & Nebel, B. (2001). FF planning system: Fast plan generation heuristic
search. Journal Artificial Intelligence Research, 14, 253302.
Kautz, H., & Selman, B. (1992). Planning satisfiability. Proceedings Tenth European
Conference Artificial Intelligence (ECAI92).
Kirkpatrick, S., Gelatt, Jr, C., & Vecchi, M. (1983). Optimization simulated annealing. Science,
220, 671680.
Little, I., & Thiebaux, S. (2007). Probabilistic planning vs replanning. Workshop International
Planning Competition: Past, Present Future (ICAPS).
Liu, C., & Layland, J. (1973). Scheduling algorithms multiprogramming hard-real-time
environment. Journal Association Computing Machinery, 20, 4661.
849

fiW U , K ALYANAM , & G IVAN

Mahadevan, S., & Maggioni, M. (2007). Proto-value functions: Laplacian framework learning representation control Markov decision processes. Journal Machine Learning
Research, 8, 21692231.
Nilsson, N. (1980). Principles Artificial Intelligence. Tioga Publishing, Palo Alto, CA.
Puterman, M. L. (2005). Markov Decision Processes: Discrete Stochastic Dynamic Programming.
John Wiley & Sons, Inc.
Sanner, S., & Boutilier, C. (2009). Practical solution techniques first-order MDPs. Artificial
Intelligence, 173(5-6), 748788.
Selman, B., Kautz, H., & Cohen, B. (1993). Local search strategies satisfiability testing.
DIMACS Series Discrete Mathematics Theoretical Computer Science, pp. 521532.
Sutton, R. S. (1988). Learning predict methods temporal differences. Machine Learning,
3, 944.
Sutton, R. S., & Barto, A. G. (1998). Reinforcement Learning: Introduction. MIT Press.
Teichteil-Konigsbuch, F., Kuter, U., & Infantes, G. (2010). Incremental plan aggregation generating policies MDPs. Proceedings Ninth International Conference Autonomous
Agents Multiagent Systems (AAMAS 2010), pp. 12311238.
Tesauro, G., & Galperin, G. (1996). On-line policy improvement using Monte-Carlo search.
NIPS.
Wu, J., & Givan, R. (2007). Discovering relational domain features probabilistic planning.
Proceedings Seventeenth International Conference Automated Planning
Scheduling, pp. 344351.
Wu, J., & Givan, R. (2010). Automatic induction Bellman-Error features probabilistic planning. Journal Artificial Intelligence Research, 38, 687755.
Yoon, S., Fern, A., & Givan, R. (2007). FF-Replan: baseline probabilistic planning. Proceedings Seventeenth International Conference Automated Planning Scheduling, pp. 352358.
Younes, H., Littman, M., Weissman, D., & Asmuth, J. (2005). first probabilistic track
international planning competition. Journal Artificial Intelligence Research, 24, 851887.

850

fiJournal Artificial Intelligence Research 42 (2011) 309-352

Submitted 02/11; published 11/11

Relevant Explanation Bayesian Networks
Changhe Yuan

cyuan@cse.msstate.edu

Department Computer Science Engineering
Mississippi State University
Mississippi State, MS 39762

Heejin Lim

hlim@ai.kaist.ac.kr

Department Computer Science
Korea Advanced Institute Science Technology
Daejeon, South Korea 305-701

Tsai-Ching Lu

tlu@hrl.com

HRL Laboratories LLC
Malibu, CA 90265

Abstract
major inference task Bayesian networks explaining variables observed particular states using set target variables. Existing methods solving
problem often generate explanations either simple (underspecified)
complex (overspecified). paper, introduce method called Relevant Explanation (MRE) finds partial instantiation target variables maximizes
generalized Bayes factor (GBF) best explanation given evidence. study
shows GBF several theoretical properties enable MRE automatically identify relevant target variables forming explanation. particular, conditional
Bayes factor (CBF), defined GBF new explanation conditioned existing
explanation, provides soft measure degree relevance variables new
explanation explaining evidence given existing explanation. result, MRE
able automatically prune less relevant variables explanation. also show
CBF able capture well explaining-away phenomenon often represented
Bayesian networks. Moreover, define two dominance relations candidate
solutions use relations generalize MRE find set top explanations
diverse representative. Case studies several benchmark diagnostic Bayesian
networks show MRE often able find explanatory hypotheses
precise also concise.

1. Introduction
One essential quality human experts ability explain reasoning
people. comparison, computer expert systems still lack capability regard.
Early medical decision-support systems MYCIN (Buchanan & Shortliffe, 1984)
shown empirically comparable even better diagnostic accuracies domain
experts. However, physicians still reluctant use systems daily clinical
settings. One major reason expert systems lack capability clearly explain
advice; physicians uncomfortable following piece advice
fully understand (Teach & Shortliffe, 1981). capability explanation thus critical
success decision-support system.
c
2011
AI Access Foundation. rights reserved.

fiYuan, Lim, & Lu

Bayesian networks (Pearl, 1988) offer compact intuitive graphical representations
uncertain relations among random variables domain become basis
many probabilistic expert systems (Heckerman, Mamdani, & Wellman, 1995b). Bayesian
networks provide principled approaches finding explanations given evidence, e.g.,
belief updating, Maximum Posteriori assignment (MAP), Probable Explanation
(MPE) (Pearl, 1988). However, methods may generate explanations either
simple (underspecified) complex (overspecified). Take medical diagnostic system
example. system may contain dozens even hundreds potentially dependent
diseases target variables. Target variables defined variables diagnostic
explanatory interest. Belief updating finds singleton explanations ignoring
compound effect multiple diseases. MAP MPE consider effect finding
full configuration target variables, explanations often contain many
variables. Although patient may one disease, almost never
diseases one time long delay treatments long.
desirable find explanations contain relevant diseases. diseases
excluded medical tests treatments.
paper, introduce method called Relevant Explanation (MRE)
finds partial instantiation target variables maximizes generalized Bayes
factor (GBF) best explanation given evidence. study shows GBF
several theoretical properties enable MRE automatically identify relevant
target variables forming explanation. particular, conditional Bayes factor (CBF),
defined GBF new explanation conditioned existing explanation, provides
soft measure degree relevance variables new explanation explaining
evidence given existing explanation. result, MRE able automatically prune
less relevant variables explanation. also show CBF able capture well
explaining-away phenomenon often represented Bayesian networks. Moreover,
define two dominance relations candidate solutions use relations
generalize MRE find set top explanations diverse representative.
case studies show MRE performed well explanation tasks set benchmark
Bayesian networks.
remainder paper structured follows. Section 2 provides brief overview
literature explanation, including scientific explanation, explanation artificial
intelligence, relation causation explanation. Section 3 provides
introduction explanation Bayesian networks, especially methods explaining evidence. Section 4 introduces formulation Relevant Explanation discusses
theoretical properties. section also discusses generalize MRE find set
top explanations. Section 5 presents case studies MRE set benchmark
Bayesian networks. Finally, Section 6 concludes paper.

2. Explanation
Explanation topic full debate; fact, commonly accepted definition
explanation yet. section provides brief overview major developments
explanation philosophy science artificial intelligence. brief discussion
relation causation explanation also included.
310

fiMost Relevant Explanation Bayesian Networks

2.1 Scientific Explanation
Explanation focal subject philosophy science long time. goal
explanation simply describe world is, develop fundamental
scientific understanding world (Woodward, 2003) answer questions
happen? field hence named scientific explanation.
One earliest model scientific explanation Deductive-Nomological (D-N)
model (Hempel & Oppenheim, 1948). According D-N model, scientific explanation
consists explanandum, phenomenon explained, explanation (or
explanans), facts used explain explanandum. explanation successfully
explain explanandum explanation true, explanation logically entails
explanandum.
However, every phenomenon expressed terms deterministic logic rules.
Many phenomena inherently uncertain. Hempel (1965) modified D-N model
introduced inductive-statistical (I-S) model. I-S model similar D-N model
except assumes probability logic rule capturing uncertainty
linking initial conditions phenomenon explained.
D-N I-S models limitation allowing inclusion irrelevant
facts explanation, facts affect correctness rules (Suermondt, 1992). address shortcoming, Salmon (1970) introduced statisticalrelevance (S-R) model. S-R model requires explanation consist
facts statistically relevant explanandum. fact statistically relevant
explaining explanandum posterior probability fact observing
explanandum different prior probability. intuition behind S-R model
statistically irrelevant facts, even though may high probabilities,
constitute good explanation.
Salmon (1984) introduced Causal-Mechanical (C-M) model explanation take
account causation. basic idea behind C-M model process explanation involves fitting explanandum causal structure domain tracing
causes may lead explanandum.
many approaches well. Ketcher (1989) believes scientific explanation provide unified account natural phenomena world. Van
Fraassen (1980) believes explanation favor explanandum, i.e., explanation either increases probability explanandum decreases probability
nearest competitor explanandum. Several mathematical theories explanatory
power also proposed Jeffreys (1935), Good (1977), Gardenfors (1988).
2.2 Explanation Artificial Intelligence
comparison scientific explanation, researchers area artificial intelligence
taken much broader view explanation. Early development decision-support systems made clear decision-support systems intended replace human
experts, rather provide advice second opinion experts
better performance. necessary decision-support systems capability
explain conclusions made conclusions appropriate
domain experts understand possibly follow advice (Dannenberg, Shapiro,
311

fiYuan, Lim, & Lu

& Fries, 1979). decision-support system, presentation help users understanding conclusions system regarded explanation (Suermondt, 1992).
example, explanation trace reasoning process system reaching
conclusions (Suermondt, 1992), canned textual explanation abstract reasoning
process (Bleich, 1972), verbal translation inference rules (Buchanan & Shortliffe,
1984), visual display certain elements system helps user understand
results (Lacave, Luque, & Diez, 2007).
Nevertheless, important form explanation artificial intelligence forming explanatory hypotheses observed facts, often called abductive inference (Peirce,
1948). Many issues need consideration abductive inference. One issue define
explain. every observation needs explanation. According Pierce (1948), common trigger abductive inference surprising fact observed, is, newly
observed information conflict already known currently believed.
words, requires explanation something causes someones cognitive dissonance explanandum rest belief (Gardenfors, 1988). also
argued observations serve part explanation (Chajewska & Halpern,
1997; Nielsen, Pellet, & Elisseeff, 2008). Suppose observe grass wet,
rained. need explain rained. fact rained actually
excellent explanation grass wet (Nielsen et al., 2008). Therefore,
potential distinction explanandum, i.e., observations explained,
observations. Deciding explanandum may nontrivial task.
explanandum decided, task reduces finding explanatory hypothesis
explanandum. issue define good explanation is. good explanation able provide sort cognitive relief, is, explanation
decrease surprise value caused observation explanandum. Intuitively,
value explanation degree explanation decreases surprise
value. Many different criteria used existing explanation methods, including
weight evidence (Good, 1985), probability (Pearl, 1988), explanatory power (Gardenfors,
1988), likelihood evidence (de Campos, Gamez, & Moral, 2001), causal information
flow (Nielsen et al., 2008). One goal paper study compare properties
measures.
Moreover, quality explanation also highly goal-dependent. resulting
explanations may vary level specificity scope depending objectives
explanation task (Leake, 1995). example, explaining symptoms patient,
doctor either find explanation constitutes diagnosis, i.e., explaining
diseases patient may have, provide explanation risk factors may
caused symptoms. Defining goal explanation task thus important.
general overview explanation artificial intelligence. Section 3,
provide detailed review one particular topic area: explanation
Bayesian networks.
2.3 Causation Explanation
agreed upon causation plays important role explanation helps generate
intuitive explanations (Chajewska & Halpern, 1997; Halpern & Pearl, 2005; Nielsen et al.,
312

fiMost Relevant Explanation Bayesian Networks

2008). However, considerable disagreement among researchers whether explanations causal distinction causal non-causal explanations
is. believe completely subsuming explanation causation typically
broader view explanation. following arguments belief
explanation tasks require causal meanings.
First all, explanation much broader meaning AI. explanation tasks
AI require causal meanings. example, verbal visual explanations often
used decision-support systems illustrate concepts, knowledge, reasoning processes;
seem causal meanings. insisted explanations
causal, explanation tasks may disallowed.
Furthermore, many domains clear understandings causal relations
yet established. statistical relevance information. relevance information insufficient fully capture causal relations. Again, explanation may
disallowed altogether domains insist explanations
causal.
Moreover, situation complicated fact still considerable
disagreement definition causation. Causal claims also vary drastically
extent explanatorily deep enough (Woodward, 2003). some,
sufficient causal explanation say rock broke window. others,
merely descriptive statement; necessary resort deeper Newtonian mechanics
explain rock broke window.
Finally, legitimate why-questions causal require causal explanations.
example, difference explanation belief explanation
fact (Chajewska & Halpern, 1997). someone tells rained last night
ask why, may give explanation grass wet. Another example
variety physical explanations geometrical rather causal
explain phenomena using structure spacetime rather using forces energy
transfer (Nerlich, 1979).
goal paper take tall task settling debate
relation causation explanation. methods propose paper
aimed general enough applicable causal non-causal
settings.

3. Explanation Bayesian Networks
Bayesian network directed acyclic graph (DAG) nodes denote random/chance variables, arcs lack denote qualitative relations among
variables. dependence relations variables quantified
conditional probability distributions, one variable conditioned parents. Figure 1(b) shows example Bayesian network. Bayesian network essentially encodes
joint probability distribution random variables domain serve
probabilistic expert system answer various queries domain.
Unlike many machine learning methods mostly predictive methods, Bayesian
network used prediction explanation deep representation
domain. Explanation tasks Bayesian networks classified three categories;
313

fiYuan, Lim, & Lu

explanation reasoning, explanation model, explanation evidence (Lacave &
Diez, 2002). goal explanation reasoning Bayesian networks explain
reasoning process used produce results credibility results
established. reasoning Bayesian networks follows normative approach,
explanation reasoning difficult explanation methods try imitate
human reasoning (Druzdzel, 1996; Lacave & Diez, 2002). goal explanation model
present knowledge encoded Bayesian network easily understandable forms
visual aids experts users examine even update knowledge.
example, graphical modeling tools GeNIe (Druzdzel, 1999), Elvira (Lacave
et al., 2007), SamIam (AR Group, UCLA, 2010) functionalities visualizing
strength probabilistic relations variables domain. goal
explanation evidence explain observed variables particular
states using variables domain. focus explanation evidence
research. Next review major methods explaining evidence Bayesian
networks discuss limitations.
3.1 Explanation Evidence
Numerous methods developed explain evidence Bayesian networks.
methods make simplifying assumptions focus singleton explanations.
example, often assumed fault variables mutually exclusive collectively
exhaustive, conditional independence evidence given hypothesis (Heckerman, Breese, & Rommelse, 1995a; Jensen & Liang, 1994; Kalagnanam & Henrion, 1988).
However, singleton explanations may underspecified unable fully explain
given evidence evidence compound effect multiple causes.
domain multiple dependent target variables, multivariate explanations
often appropriate explaining given evidence. Maximum Posteriori assignment (MAP) finds complete instantiation set target variables maximizes
joint posterior probability given partial evidence variables. Probable
Explanation (MPE) (Pearl, 1988) similar MAP except MPE defines target
variables unobserved variables. common drawback methods
often produce hypotheses overspecified may contain irrelevant variables
explaining given evidence.
Everyday explanations necessarily partial explanations (Leake, 1995). difficult
also unnecessary account potential factors may related
occurrence event; desirable find relevant contributing factors. Various
pruning techniques used avoid overly complex explanations. methods
grouped two categories: pre-pruning post-pruning. Pre-pruning methods
use context-specific independence relations represented Bayesian networks prune
irrelevant variables (Pearl, 1988; Shimony, 1993; van der Gaag & Wessels, 1993, 1995)
applying methods MAP generate explanations. example, Shimony (1993)
defines explanation probable independence-based assignment complete
consistent respect evidence nodes. Roughly speaking, explanation
truth assignment variables relevant evidence nodes. ancestors
evidence nodes relevant. ancestor given node irrelevant independent
314

fiMost Relevant Explanation Bayesian Networks

node given values ancestors. However, independence relations
strict unable prune marginally loosely relevant target variables.
contrast, post-pruning methods first generate explanations using methods
MAP MPE prune variables important. example method
proposed de Campos et al. (2001). method first finds K probable explanations (K-MPE) given evidence, K user-specified parameter,
simplify explanations removing unimportant variables one time. variable
regarded unimportant removal reduce likelihood explanation.
pointed Shimonys partial explanations necessarily concise (Chajewska & Halpern, 1997). explanation must include assignment nodes
least one path variable root, since relevant node, least one
parents must relevant. method de Campos et al. prune conditionally
independent variables well. limitations methods addressed using
thresholding method allow pruning marginally relevant variables (Shimony, 1996;
de Campos et al., 2001). However, modified methods involve manual setting
tunable parameters, rather arbitrary subject human errors.
Several methods use likelihood evidence measure explanatory power
explanation (Gardenfors, 1988). Chajewska Halpern (1997) extend approach
use value pair <likelihood, prior probability> order explanations,
forcing users make decisions clear order two explanations. Since
likelihood measure allows comparing explanations contain different numbers
variables, potentially find concise explanations. practice methods
often fail prune irrelevant variables, adding variables typically
affect likelihood.
Henrion Druzdzel (1991) assume system set pre-defined explanation
scenarios organized tree; use scenario highest posterior probability
explanation. method also allows comparing explanations different numbers
variables requires explanation scenarios specified advance.
Flores et al. (2005) propose automatically create explanation tree greedily
branching informative variable step maintaining probability
branch tree certain threshold. pointed Flores et al.s
approach adds variables order informative remaining target
variables, informative explanandum (Nielsen et al., 2008).
results paper provide evidence drawback well. Moreover, criterion
use choose best explanation probability explanation given
evidence, makes ranking explanations extremely sensitive user-specified
threshold bounding probabilities branches. Nielsen et al. developed another
method uses causal information flow (Ay & Polani, 2008) select variables
expand explanation tree. However, inherits drawback explanation tree-based
methods essence greedy search methods; even though identify important
individual variables, may fail recognize compound effect multiple variables.
Furthermore, method also tunable parameters may subject human errors.
Finally, since explanation explanation tree contain full branch starting
root, explanations may still contain redundant variables.
315

fiYuan, Lim, & Lu

Input

B





C

Output B

(0.016)
Output

Input

C (0.15)

Output C

Output

Output

B (0.1)
Total Output

(0.1)

(a)

(b)

Figure 1: (a) electric circuit (b) corresponding diagnostic Bayesian network
3.2 Explanation Two Benchmark Models
section uses couple examples illustrate methods reviewed
last section work practice.
3.2.1 Circuit
first consider electric circuit Figure 1(a) (Poole & Provan, 1991). Gates A, B, C,
defective closed. prior probabilities gates defective
0.016, 0.1, 0.15, 0.1 respectively. also assume connections
gates may fail small probabilities. circuit modeled diagnostic
Bayesian network shown Figure 1(b). Nodes A, B, C, correspond gates
circuit two states each: defective ok. others input output
nodes two states well: current noCurr. probabilities
output nodes A, B, C, state current given parent nodes
parameterized follows.
P (Output B = current|B = def ective, Input = current) = 0.99;
P (Output = current|A = def ective, Input = current) = 0.999;
P (Output C = current|C = def ective, Output B = current) = 0.985;
P (Output = current|D = def ective, Output B = current) = 0.995.
Otherwise parent state current, output nodes state
noCurr probability 1.0. Finally, conditional probability table Total Output
noisy-or gate (Pearl, 1988), means parent node state current
causes Total Output state current independently parents.
parent node state current, probability Total Output
state current 0.0. individual effect parent nodes Total Output
parameterized follows.
P (T otal Output = current|Output = current) = 0.9;
316

fiMost Relevant Explanation Bayesian Networks

P (T otal Output = current|Output C = current) = 0.99;
P (T otal Output = current|Output = current) = 0.995.
Suppose observe electric current flows circuit, means
nodes Input otal Output state current. Nodes A, B, C,
logical choices target variables model. task find best explanatory
hypothesis explain observation electric current circuit. Domain knowledge
suggests three basic scenarios likely lead observation: (1)
defective; (2) B C defective; (3) B defective.
Given observation electric current, posterior probabilities A, B, C,
defective 0.391, 0.649, 0.446, 0.301 respectively. Therefore, explanation
(B) best single-fault explanation, B means B defective. However,
B alone fully explain evidence; C involved. Actually,
restrict defective states, (D) best singleton explanation
probability 0.699, clearly useful explanation evidence.
MAP finds (A, B, C, D) best explanation. Given B C defective,
arguable okay irrelevant explaining evidence. MAP
intrinsic capability indicate part explanation important. Since
MPE assumes unobserved variables target variables, explanation
even redundancy.
pre-pruning techniques unable prune target variable model context-specific independence target variables given evidence. method simplifying K-MPE solutions requires intermediate output nodes
included explanatory variables. Since typically necessary consider
target variables, adapt method slightly simplify top K MAP solutions
instead, refer K-MAP simplification method hereafter. best explanation found method (B, D). good explanation, although argue
later (B, C) better explanation.
methods based likelihood evidence overfit choose (A, B, C, D)
best explanation, probability evidence given target
variables defective almost 1.0.
explanation tree methods find (A) best explanation. (A) good
explanation, (B, C) better explanation argue later.
3.2.2 Vacation
Consider another example (Shimony, 1993). Mr. Smith considering taking strenuous
hiking trips. decision go hiking depends health status. healthy,
go hiking; otherwise, would rather stay home. Mr. Smith subject different
risks dying depending health status spends vacation.
relations variables best represented using Bayesian network Figure 2.
conditional probabilities model parameterized follows:
P (healthy) = 0.8;
P (home|healthy) = 0.8;
P (home|healthy) = 0.1;
317

fiYuan, Lim, & Lu

Healthy
Vacation
location

Alive

Figure 2: Bayesian network vacation problem.

P (alive|healthy, V acation location = ) = 0.99;
P (alive|healthy, home) = 0.9;
P (alive|healthy, hiking) = 0.1,
* means value matter. totally 100 similar hiking
trails Mr. Smith choose from. model 100 hiking trips either different
states variable Vacation location, one state named hiking. case
hiking trails modeled different states, conditional probability given health
status distributed evenly across states. Shimony (1993) showed modeling
choice one-state vs. multi-state significantly affects best explanation MAP. Given
Mr. Smith alive vacation, best explanation target variable
set {Healthy, V acation location} changes (healthy, hiking) one-state model
(healthy, home) multi-state model. rather undesirable
explanation totally change simply model refined.
examine methods affected modeling choice.
explanation tree method finds (hiking) explanation one-state model
(healthy, home) multi-state model. explanations seem counterintuitive.
causal explanation tree K-MAP simplification methods find (healthy)
explanation two models.
Mr. Smith died afterwards? interesting explanation task
outcome surprising given low prior probability dying problem. MAPs explanation changed (healthy, hiking) one-state model (healthy, home)
multi-state model. explanation tree method finds (hiking) one-state model
(home) multi-state model, perplexing explanations. causal explanation tree method finds (healthy, hiking) one-state model (healthy, trip)
multi-state model; K-MAP simplification method. causal explanation tree K-MAP simplification methods quite robust face refinement
model; explanations also seem plausible. However, since 100 hiking trips
identical multi-state model, hiking trip plugged explanation.
means 100 equally good explanations. debatable whether specific
hiking trip necessary detail needs included.
318

fiMost Relevant Explanation Bayesian Networks

results show existing explanation methods Bayesian networks
often generate explanations either underspecified overspecified. fail find
right explanations contain relevant target variables.

4. Relevant Explanation Bayesian Networks
Users want accurate explanations want burdened unnecessary details.
Bayesian network real-world domain may contain many target variables, typically target variables relevant explaining given evidence.
goal research develop explanation method able automatically
identify relevant target variables forming explanation.
first state several basic assumptions behind research. First, explanation
typically depends agents epistemic state (Gardenfors, 1988). assume
knowledge encoded Bayesian network constitutes complete epistemic state
explainer. Second, assume explanandum specified observed states
set evidence variables explanation task. Third, assume Bayesian
network annotated set target variables clearly defined. setting,
able focus important issue evaluate select best
explanation. believe, however, proposed methodologies easily generalized
general settings.
4.1 Good Explanation?
consider good explanation two basic properties: precise concise.
Precise means explanation decrease surprise value explanandum
much possible. Many concepts used refer property,
including confirmative (Carnap, 1948), sufficient (Khan, Poupart, & Black, 2009),
relevant (Shimony, 1993). also regard high explanatory power (Gardenfors, 1988)
referring preciseness explanation. Concise means explanation
contain relevant variables explaining evidence. similar another
concept called minimal (Khan et al., 2009).
attempts capture preciseness conciseness single concept,
including consistent (Pearl, 1988) coherent (Ng & Mooney, 1990). Pearl (1988) argues
explanation needs internally consistent, taking sets facts
likely true given evidence may produce reasonable results. However,
putting consistent facts together necessarily lead either preciseness conciseness. example, two perfectly correlated facts consistent, necessarily
relevant explaining evidence, adding explanation likely leads
redundancy. Ng Mooney (1990) define coherence metric measures well
explanation ties various observations together. definition also seems likely
lead simple explanations. However, definition based Horn-clause axioms
cannot generalized probabilistic systems easily.
addition, explanation method Bayesian networks able capture
explaining-away phenomenon often represented Bayesian networks. explaining-away
phenomenon refers situation effect multiple causes, observing
effect one causes reduces likelihood presence causes.
319

fiYuan, Lim, & Lu

explaining-away phenomenon represented using collider structure (Pearl,
1988), i.e., V structure single node multiple parents. desirable capture
phenomenon order find explanations precise concise.
4.2 Definition Explanation Evidence
note definition explanation full instantiation target variables
used MAP MPE quite restrictive. fundamentally limits capability
methods find concise explanations. approach define explanation follows.
Definition 1 Given set target variables Bayesian network partial evidence
e remaining variables, explanation evidence joint instantiation x
non-empty subset X target variables, i.e., X M.
definition allows explanation partial instantiation target variables. Therefore, provides explanation method freedom choose target
variables include.
One key difference definition many existing methods
existing definitions often built-in relevance measure optimized,
definition treats partial instantiation target variables explanation.
believe deciding relevance measure separate issue defining explanation.
separation two issues allows us compare quality different
explanations also generalize method find multiple top explanations.
Note disallow disjunctives definition. agree Halpern
Pearl (2005) allowing disjunctive explanations causes technical philosophical problems. example explaining-away situation, effect may multiple
potential causes. Let number causes n. causes good explanation itself. allow disjunctives causes, totally 2n disjunctives.
really difficult consider disjunctives. Philosophically, one causes
present, disjunctive includes cause part true well. unclear
disjunctive choose explanation. Besides, disjunctive multiple
causes seems equivalent claiming cause potential explanation. Separating
causes individual explanations allows comparing explanations. unclear
benefits allow disjunctives.
4.3 Relevance Measures
need relevance measure evaluate quality explanation. measure
able evaluate explanatory power explanation also favor
concise explanations relevant variables included explanation.
Since dealing probabilistic expert systems, measure based
probabilistic relations explanation explanandum (Chajewska &
Halpern, 1997). also desirable probabilistic relation summarized
single number (Suermondt, 1992). Next discuss several popular relevance measures
order motivate choice.
One commonly used measure probability explanation given evidence,
used MAP MPE find likely configuration set target variables.
320

fiMost Relevant Explanation Bayesian Networks

relying posterior probability, however, explanation may contain independent
marginally relevant events high probability. Methods use probability
relevance measure intrinsic capability prune less relevant facts.
may argue variables selected target variables explanation
first place. requires important task selecting relevant variables
rest shoulders users. explanation method effective,
perform user task extracting essential knowledge simple
possible (Druzdzel, 1996). Moreover, shown earlier probability measure
quite sensitive modeling choices; simply refining model dramatically change
best explanation.
Another commonly used measure likelihood evidence variations.
likelihood measure undesirable property called irrelevant conjunction (Chajewska &
Halpern, 1997; Rosenkrantz, 1994), is, adding irrelevant fact valid explanation
change likelihood. property limits capability method based
measure find concise explanations. Another common drawback probability
likelihood measures focus measuring preciseness explanation;
intrinsic mechanism achieve conciseness explanation. measure
achieve preciseness conciseness time highly desirable.
According Salmon (1984), order construct satisfactory statistical explanation,
necessary factor prior posterior probabilities either explanandum
explanation. explanation result comparison prior
posterior probabilities. comparative view explanation generates set possibilities.
One form comparison difference prior posterior probabilities.
However, inappropriate relevance measure according Good (1985). Consider
increase probability 1/2 3/4, 3/4 1. cases difference
probabilities 1/4, degree relevance entirely different.
Another possibility belief update ratio, define follows.
Definition 2 Assuming P (x) 6= 0, belief update ratio x given e, r(x; e), defined

P (x|e)
.
(1)
r(x; e)
P (x)
trivial mathematical derivation shows following also true.
r(x; e) =

P (e|x)
.
P (e)

(2)

Therefore, belief update ratio equivalent ratio posterior prior
probabilities explanandum given explanation. clear ratios
proportional likelihood measure P (e|x) constant. therefore share
drawbacks likelihood measure.
Suermondt (1992) uses cross entropy prior posterior probability
distributions target variable measure influence evidence variable
target variable. Cross entropy assigns large penalty incorrect statements certainty
near-certainty. However, measure used select influential evidence
variables, select specific states target variables explanation. Furthermore,
321

fiYuan, Lim, & Lu

pointed cross-entropy ideal measure symmetric;
necessary keep track distribution represents origin comparison
times.
1935 paper (Jeffreys, 1935) book Theory Probability (Jeffreys, 1961),
measure called Bayes factor proposed quantifying evidence favor scientific
theory. Bayes factor ratio likelihoods hypothesis alternative
hypothesis. alternative hypothesis also simple statistical hypothesis, measure
simply likelihood ratio. cases either hypothesis unknown parameters,
Bayes factor still form likelihood ratio, likelihoods obtained
integrating parameter space (Kass & Raftery, 1995). logarithm
Bayes factor defined weight evidence independently Good (1950)
Minsky Selfridge (1961). Similar cross-entropy, Bayes factor (or weight
evidence) also assigns large values probabilities close certainty. drawback
Bayes factor, however, difficult use measure compare two
hypotheses (Suermondt, 1992); necessary pairwise comparisons multiple
hypotheses.
4.4 Generalized Bayes Factor
slight modification, generalize Bayes factor compare multiple hypotheses. define generalized Bayes factor (GBF) following.
Definition 3 generalized Bayes factor (GBF) explanation x given evidence
e defined
P (e|x)
,
(3)
GBF (x; e)
P (e|x)
x denotes set alternative hypotheses x.
one hypothesis x X contains single binary variable. Otherwise,
x catches alternative hypotheses x. catch-all form Bayes factor
previously introduced Fitelson (2001). next sections, show GBF
several desirable theoretical properties enable automatically identify
relevant variables finding explanation. properties possessed
simple form Bayes factor prompt us give GBF new name emphasize
importance.
Note really need compute P (e|x) directly calculating GBF (x; e).
trivial mathematical derivation shows
P (x|e)(1 P (x))
.
(4)
GBF (x; e) =
P (x)(1 P (x|e))
Therefore, GBF longer measure comparing different hypotheses, simply
measure compares posterior prior probabilities single hypothesis. GBF
hence able overcome drawback Bayes factor pairwise comparisons
multiple hypotheses.
Using x definition GBF catch alternative hypotheses enables GBF
capture property call symmetry explanatory power. Consider two complementary simple hypotheses H H following two distinct cases. first case,
322

fiMost Relevant Explanation Bayesian Networks

P (H) increases 0.7 0.8. increase goes hand hand decrease P (H)
0.3 0.2. second case, P (H) increases 0.2 0.3, also goes hand
hand decrease P (H) 0.8 0.7. two cases completely symmetric
other, indicates two Hs amount explanatory
power. GBF assigns score H cases. many relevance measures
probability likelihood measure assign totally different scores.
Besides Equation 4, GBF expressed forms, one following.
P (x|e)/P (x|e)
.
(5)
GBF (x; e)
P (x)/P (x)
Essentially, GBF equal ratio posterior odds ratio x given e
prior odds ratio x (Good, 1985). Therefore, GBF measures degree change
odds ratio explanation.
GBF also calculated ratio belief update ratios x
alternative explanations x given e, i.e.,
GBF (x; e) =

P (x|e)/P (x)
.
P (x|e)/P (x)

(6)

multiple pieces evidence, GBF also calculated using chain
rule similar joint probability distribution multiple variables. first define
conditional Bayes factor follows.
Definition 4 conditional Bayes factor (CBF) explanation given evidence e
conditioned explanation x defined
GBF (y; e|x)

P (e|y, x)
.
P (e|y, x)

(7)

Then, easy show following chain rule calculating GBF
explanation given set evidence true.
GBF (x; e1 , e2 , ..., en ) = GBF (x; e1 )

n


GBF (x; ei |e1 , e2 , ..., ei1 ).

(8)

i=2

chain rule especially useful multiple pieces evidence obtained
incrementally.
4.4.1 Handling Extreme Values
GBF assigns much weight probabilities ranges close 0 1. weighting
consistent decision-theoretic interpretation subjective probability 0
1 (Suermondt, 1992). belief probability event equal 1 means
one absolutely sure event occur. One probably would bet anything, including
life, occurrence event. rather strong statement. Therefore,
increase probability less one one decrease non-zero zero
extremely significant, matter small change is.
323

fiYuan, Lim, & Lu















fffi


















Figure 3: GBF function prior probability given fixed increase
posterior probability prior. different curves correspond different
probability increases. example, +0.01 means difference
posterior prior probabilities 0.01.

following several special cases computing GBF face extreme probabilities.
P (x) = 0.0, P (x|e) must equal zero well, yields ratio
two zeros. commonly done, define ratio two zeros zero. Intuitively,
impossible explanation never useful explaining evidence.
P (x) = 1.0 P (x|e) = 1.0, ratio two zeros. Since
explanation true matter evidence is, useful explaining
evidence either. case actually used counterexample using probability
relevance measure, fact explanation high posterior probability
may simply due high prior probability.
P (x) < 1.0 P (x|e) = 1.0, GBF score equal infinity. fact
explanation initially uncertainty becomes certainly true observing evidence
warrants explanation large GBF score.
4.4.2 Monotonicity GBF
study monotonicity GBF regard two relevance measures.
first measure difference posterior prior probabilities. commonly
believed amount difference probability ranges close zero one
much significant ranges. prominent measure able capture
belief K-L divergence (Kullback & Leibler, 1951). measure explanatory
power also capture belief ranking explanations. Figure 3 shows plot
GBF prior probability difference posterior prior
probabilities fixed. example, +0.01 means difference posterior
324

fiMost Relevant Explanation Bayesian Networks






fi


ff























Figure 4: GBF function prior probability belief update ratio
fixed. different curves correspond different belief update ratios.

prior probabilities 0.01. figure clearly shows GBF assigns much higher scores
probability changes close zero one.
also study monotonicity GBF regard another measure, belief
update ratio defined Equation 1. Recall belief update ratio proportional
likelihood measure constant. likelihood measure, typically together
penalty term complexity model, popular metric used model selection. AIC
BIC (Schwartz, 1979) prominent examples. Next show GBF provides
discriminant power belief update ratio (hence, also likelihood measure
ratio posterior prior probabilities evidence). following
theorem. proofs theorems corollaries paper found
appendix.
Theorem 1 explanation x fixed belief update ratio r(x; e) greater 1.0,
GBF (x; e) monotonically increasing prior probability P (x) increases.
Figure 4 plots GBF function prior probability fixing belief update
ratio. different curves correspond different belief update ratios. GBF automatically
takes account relative magnitude probabilities measuring quality
explanation. prior probability explanation increases, ratio probability increase becomes significant. Therefore, explanations cannot
distinguished likelihood measure ranked using GBF. Since lower-dimensional
explanations typically higher probabilities, GBF intrinsic capability penalize complex explanations. value pair <likelihood, prior probability> used
Chajewska Halpern (1997) able produce partial orderings among explanations. sense, GBF addresses limitation integrating two values
single value produce complete ordering among explanations. Users
burden define complete ordering anymore.
325

fiYuan, Lim, & Lu

4.4.3 Achieving Conciseness Explanation
section discusses several theoretical properties GBF. key property GBF
able weigh relative importance multiple variables include
relevant variables explaining given evidence. following theorem.
Theorem 2 Let conditional Bayes factor (CBF) explanation given explanation x
less equal inverse belief update ratio alternative explanations
x, i.e.,
1
GBF (y; e|x)
,
(9)
r(x; e)

GBF (x, y; e) GBF (x; e).

(10)

conditional independence relations Bayesian networks provide hard measure relevance explanation regard another explanation x; answer
either yes no. contrast, GBF (y; e|x) able provide soft measure relevance explaining e given x. GBF also encodes decision boundary, inverse
belief update ratio alternative explanations x given e. ratio used decide
important remaining variables order included explanation.
1
, important enough included. Otherwise,
GBF (y; e|x) greater r(x;e)
excluded explanation. Simply dependent enough variable
included explanation.
Theorem 2 several intuitive desirable corollaries. first corollary states that,
explanation x belief update ratio greater 1.0, adding independent
variable explanation decrease GBF score.
Corollary 1 Let x explanation r(x; e) > 1.0, X, E, state
,
GBF (x, y; e) < GBF (x; e).
(11)

Therefore, adding irrelevant variable dilute explanatory power existing
explanation. GBF able automatically prune variables explanation.
Note focus explanations belief update ratio greater 1.0.
explanation whose probability change even decreases given evidence
seem able relieve cognitive dissonance explanandum
rest beliefs. According Chajewska Halpern (1997), fact potential
explanation equally less likely posteriori priori cause suspicion.
philosophical literature, also often required posterior probability
explanandum least greater unconditional probability, learning
explanation increases probability explanandum (Gardenfors, 1988; Carnap,
1948).
Corollary 1 requires variable independent X E.
assumption rather strong. following corollary shows result holds
conditionally independent E given x.
326

fiMost Relevant Explanation Bayesian Networks

Corollary 2 Let x explanation r(x; e) > 1.0, E|x, state
,
GBF (x, y; e) < GBF (x; e).
(12)

Corollary 2 general result Corollary 1 captures intuition
conditionally independent variables add additional information explanation explaining evidence. Note properties relative existing explanation.
possible variable independent evidence given one explanation, becomes dependent evidence given another explanation. Therefore, selecting variables
one one greedily guarantee find explanation highest GBF.
results relaxed accommodate cases posterior
probability given e smaller prior conditioned x, i.e.,
Corollary 3 Let x explanation r(x; e) > 1.0, state variable
P (y|x, e) < P (y|x),
GBF (x, y; e) < GBF (x; e).

(13)

intuitive result; state variable whose posterior probability decreases
given evidence part explanation evidence.
applied GBF rank candidate explanations circuit example introduced
Section 3. following shows partial ranking explanations highest
GBF scores.
GBF (B, C; e) > GBF (B, C, A; e), GBF (B, C, D; e) > GBF (B, C, A, D; e)
(B, C) highest GBF score also concise
explanations, indicates variables relevant explaining
evidence (B, C) observed. results indicate GBF intrinsic
capability penalize higher-dimensional explanations prune less relevant variables,
match theoretical properties well.
4.5 Relevant Explanation
theoretical properties presented previous section show GBF plausible
relevance measure explanatory power explanation. particular, show
GBF able automatically identify relevant target variables finding
explanation. hence propose method called Relevant Explanation (MRE)
relies GBF finding explanations given evidence Bayesian networks.
Definition 5 Let set target variables, e partial evidence
remaining variables Bayesian network. Relevant Explanation problem
finding explanation x e maximum generalized Bayes factor score
GBF (x; e), i.e.,
RE(M; e) arg maxx,XM GBF (x; e) .
(14)
327

fiYuan, Lim, & Lu

Although MRE general enough applied probabilistic distribution model,
MREs properties make especially suitable Bayesian networks. Bayesian networks
invented model conditional independence relations random variables
domain obtain concise representation domain also
efficient algorithms reasoning relations variables. concise
representation Bayesian network also beneficial MRE following ways.
First, MRE utilize conditional independence relations modeled Bayesian
network find explanations efficiently. example, Corollaries 1 2 used
prune independent conditionally independent target variables
partial instantiations target variables need considered search
solution. independence relations identified graphical structure
Bayesian network may significantly improve efficiency search
explanation.
Second, similar chain rule Bayesian networks, chain rule GBF Equation 7 also simplified using conditional independence relations. computing GBF (x; ei |e1 , e2 , ..., ei1 ), may need condition subset evidence
(e1 , e2 , ..., ei1 ). Conditioning fewer evidence variables allows reasoning algorithms
involve smaller part Bayesian network computing GBF score (Lin & Druzdzel,
1998). One extreme case that, evidence variables independent given
explanation, GBF explanation given evidence simply product
individual GBFs given individual piece evidence.
GBF (x; e1 , e2 , ..., en ) =

n


GBF (x; ei ).

(15)

i=1

Finally, MRE able capture well unique explaining-away phenomenon
often represented Bayesian networks. Wellman Henrion (1993) characterized explaining away negative influence two parents induced observation
child Bayesian network. Let B predecessors C graphical model
G. C observed equal c. Let x denote assignment Cs predecessors,
denote assignment Bs predecessors. negative influence B
conditioned C = c means
P (B|A, c, x, y) P (B|c, x, y) P (B|A, c, x, y).

(16)

MRE captures explaining-away phenomenon well CBF. CBF provides measure relevant new variables explaining evidence conditioned
existing explanation. explaining-away situation, one causes already present
explanation, causes typically receive high CBFs. fact, CBF
capture Equation 16 equivalent way shown following theorem.
Theorem 3 Let B predecessors C Bayesian network. C observed
equal c. Let x denote assignment Cs predecessors, denote
assignment Bs predecessors,
P (B|A, c, x, y) P (B|c, x, y) P (B|A, c, x, y)
GBF (B; c|A, x, y) GBF (B; c|x, y) GBF (B; c|A, x, y) .
328

(17)
(18)

fiMost Relevant Explanation Bayesian Networks

Bayes factor
<1
1 3
3 10
10 30
30 100
>100

Strength evidence
Negative
Barely worth mentioning
Substantial
Strong
strong
Decisive

Table 1: Bayes factor.

consider circuit example, (B, C) (A) good explanations
evidence themselves; GBF scores (B, C) (A) given e
42.62 39.44 respectively. Jeffreys (1961) recommends using Table 1 guidance
determining significance Bayes factor value. use table judge GBFs,
(B, C) (A) strong explanations. However, (B, C) already
observed, GBF (A; e|B, C) equal 1.03, barely worth mentioning.
results indicate GBF able capture explaining-away phenomenon
circuit example.
4.6 K-MRE
many decision making problems, decision makers typically would like multiple competing
options choose from. Outputting best solution hence best practice.
especially true multiple top solutions almost equally good.
case, want know solution best, also much better
solutions. difference first second best solutions
large, gives decision makers confidence quality best solution. Moreover,
finding multiple top solutions used sensitivity analysis method provide insight
sensitive best explanations changes model parameters.
naive approach finding top K MRE solutions select explanations
highest GBF scores. However, strategy may find explanations supersets
top explanations. consider circuit example. Table 2 lists
explanations highest GBF scores. Simply relying scores produce
following rather similar top four explanations: (B, C), (A, B, C), (B, C, D),
(A, B, C, D). explanations essentially cover basic scenario
B C defective. search list finding
two basic scenarios: defective, B defective.
often critical achieve diversity goal find multiple solutions.
example, argued diversity important recommender systems (Smyth & McClave, 2001). rather similar set recommendations give users useful set
alternatives choose from. believe holds finding explanations.
order find set top explanations diverse representative, define
two dominance relations among candidate solutions MRE. first relation strong
dominance.
329

fiYuan, Lim, & Lu

Explanations
(B, C)
(A, B, C)
(B, C, D)
(A, B, C, D)
(A)
(A, B)
(A, C)
(B, D)

GBF
42.62
42.15
39.93
39.56
39.44
36.98
35.99
35.88

Table 2: explanations highest GBF scores Circuit network. explanations boldface top minimal explanations.

Definition 6 explanation x strongly dominates another explanation
x GBF (x) GBF (y).
x strongly dominates y, x clearly better explanation y,
higher equal explanatory score also concise. need include
x top explanation set. second relation weak dominance.
Definition 7 explanation x weakly dominates another explanation
x GBF (x) > GBF (y).
case, x larger GBF score y, concise. possible
include let decision maker decide whether prefers
conciseness higher score. However, believe need include x,
higher GBF score indicates extra variables X important
explaining given evidence.
Based two kinds dominance relations, define concept minimal.
Definition 8 explanation minimal neither strongly weakly dominated
explanation.
new K-MRE approach defined minimal explanations
included top set. circuit network, since (A, B, C), (B, C, D),
(A, B, C, D) strongly dominated (B, C), need consider (B, C)
among them. Similarly, (A, B) (A, C) strongly dominated (A), (A)
included top set. Finally, get set top explanations shown boldface
Table 2. clearly diverse representative original set contains
dominated explanations.
dominance relations defined restricted GBF; also applicable
relevance measures. example, potentially help methods based
likelihood measure find concise explanations.
330

fiMost Relevant Explanation Bayesian Networks

5. Case Studies
tested MRE explanation tasks set benchmark Bayesian networks
literature, including Circuit (Poole & Provan, 1991), Vacation (Shimony, 1993), Academe
(Flores et al., 2005), Asia (Lauritzen & Spiegelhalter, 1988), Circuit2 (Darwiche, 2009).
networks annotated variables classified three categories:
target, observation, auxiliary. target node, also named fault, usually represents
diagnostic interest (e.g., health status engine). observation node usually
represents symptom (e.g., observing excessive smoking engine exhaust), built-in
error message (e.g., status power supply), test (e.g., measuring voltage
battery). node neither target observation classified auxiliary node.
compared K-MRE several existing explanation methods, including K-MAP
(Pearl, 1988), explanation tree (ET) (Flores et al., 2005), causal explanation tree (CET)
(Nielsen et al., 2008), K-MAP simplification (K-SIMP) (de Campos et al., 2001). Several methods tunable parameters. explanation tree (ET) method two
parameters controlling growth explanation tree. One parameter threshold
value deciding whether target variable significant enough used expand
branch explanation tree; variable used average mutual information target variable unused target variables conditioned current
branch larger equal threshold. parameter threshold value
probability branch explanation tree. branch expanded
probability branch less threshold. set two parameters
0.05 0 respectively. branch explanation tree marked posterior
probability.
causal explanation tree (CET) method one parameter, lower-bound
threshold causal information flow variable evidence conditioned
current branch. causal information flow larger equal threshold,
variable used expand branch further. set threshold 0.01.
branch causal explanation tree marked using log ratio posterior prior
probabilities evidence given branch.
K-MAP simplification (K-SIMP) method also threshold value bounds
reduction likelihood evidence simplifying explanation. deleting
variable reduces likelihood explanation within factor bounded
threshold, simplification allowed. set threshold value 0.05. keep
track explanations highest likelihood values simplification.
parameters methods set allow much expansion simplification possible. even so, ET CET methods may fail find significant
variable create even root explanation tree. happens, force
two methods generate least root node ignoring thresholds.
5.1 Circuit
circuit network introduced Section 3, Table 3 lists top explanations found
K-MRE, K-MAP, K-SIMP. set K 3 throughout case studies. Figure 5
shows explanation trees found ET CET methods.
331

fiYuan, Lim, & Lu

Circuit
K-MRE

K-MAP

K-SIMP

Explanations
(B, C)
(A)
(B, D)
(A, B, C, D)
(A, B, C, D)
(A, B, C, D)
(B, D)
(B, C)
(A)

Scores
42.62
39.45
35.88
0.0128
0.0099
0.0082
0.9818
0.9683
0.9014

Table 3: Top explanations found K-MRE, K-MAP, K-SIMP Circuit network
given observation electric current. Note scores methods
following different meanings: GBF MRE, probability MAP,
likelihood evidence K-SIMP.

K-MRE able find intuitive explanations Circuit network. (B, C)
better explanation (A) (B, D), larger posterior probability two explanations (the posterior probabilities 0.394, 0.391,
0.266 respectively), prior probabilities explanations 0.015, 0.016,
0.01 respectively.
explanations found K-MAP mostly consistent K-MRE found,
although K-MAP solutions supersets K-MRE solutions. surprising
MAP find complete assignments target variables. MAP ability
indicate parts explanations important, believe
fundamental drawback MAP. Users burdened task identifying
important parts explanations.
K-SIMP method first finds top K MAP solutions simplifies
deleting variables reduce likelihood evidence much, any. set
top solutions found K-SIMP K-MRE. results indicate
simplification method helped prune less relevant target variables Circuit
network. However, K-SIMPs ranking explanations different. (B, D) best
explanation. number variables explanation also considered ranking
criterion explanations (de Campos et al., 2001), (A) becomes best
explanation.
ET method selects node root explanation tree. important
whether closed significantly affects likelihood evidence. However, ET method selects variable second important variable,
lead good explanation. Moreover, easy way extract top explanations explanation tree. ET method relies probability ranking
explanations. seems consider partial paths solutions.
example, (A) higher probability (A) clearly good explanation.
consider full paths root leaves, (A) best explanation.
332

fiMost Relevant Explanation Bayesian Networks




ok
0.609

def



0.391

def
0.262

ok
-0.692

def

C

4.610
ok

def

0.347

1.391

(a)

ok
-1.913

(b)

Figure 5: (a) Explanation tree (b) causal explanation tree Circuit network
given observation electric current.

Although (A, D) probability slightly smaller (A), good
explanation all. Moreover, using probability rank explanations inevitably makes
threshold value bounding probabilities branches significant effect
ranking, believe fundamental flaw ET method.
CET method also selects node root explanation tree. However,
selects C second important variable, lead good explanation either. Since branches causal explanation tree marked log ratio
posterior prior probabilities evidence, makes sense consider
partial branches explanations. top two explanations according CET method
(A) (A, C), (A, C) clearly good explanation.
explanation tree methods failed find either (B, C) (B, D) top
explanation. main reason greedy search methods. may good
identifying individual variables important, often fail identify
compound effect multiple variables. Even though variable B may large
effect A, forms excellent explanations together C D. explanation tree
methods failed find variable pairs consider one variable time.
5.2 Vacation
Two versions vacation network introduced Section 3. One version models
possible hiking trips one state named hiking, version models
100 hiking trips separate identical states. networks, first consider
scenario Mr. Smith alive vacation. Table 4 shows top explanations
K-MRE, K-MAP, K-SIMP, Figure 6 shows explanation trees ET
CET methods.
333

fiYuan, Lim, & Lu

Vacation
K-MRE
K-MAP

K-SIMP

One-state model
Explanations
Scores
(healthy)
1.3378
(home)
1.0078
(healthy, hiking) 0.6336
(healthy, home)
0.1584
(healthy, home) 0.1440
(healthy)
0.9900
(home)
0.9450

Multi-state model
Explanations
Scores
(healthy)
1.3378
(any trip)
1.0034
(healthy, home)
0.1440
(healthy, home)
0.0792
(healthy, trip) 0.0071
(healthy)
0.9900
(home)
0.9300

Table 4: Top explanations found K-MRE, K-MAP, K-SIMP two Vacation
networks given Mr. Smith alive vacation.

K-MRE found two top explanations model explanations
GBFs less equal 1.0. (healthy) best explanation models.
fact, explanation score models. Vacation location treated
K-MRE irrelevant probability staying alive regardless
Mr. Smith decides spend vacation. Although second best explanation changed
(home) (any tip), note explanations GBF scores close 1.0
barely worth mentioning according Table 1. Actually best explanations also
GBFs slightly 1.0 interesting explanations either. reason
Mr. Smiths alive vacation surprising event; real
need explaining observation.
K-MAP extremely sensitive modeling choice. best explanation change (healthy, hiking) (healthy, home), also highest probability
decreased significantly 0.6336 0.1440. (healthy, home) ranked third onestate model, became best explanation multi-state model.
Although K-SIMP method started simplifying top three explanations
K-MAP, ended two explanations models. simplification method resulted duplicate solutions. Otherwise, simplification method
quite robust face modeling choice; (healthy) best explanation
models.
ET method produced similar trees models. However, selects Vacation
location important variable. counterintuitive Vacation location
even affect probability Mr. Smith alive healthy. result
indicates mutual information target variables good indicator
relevance explaining evidence. Also, unclear explanations
extract tree. rely probability selecting full branches,
select (hiking) one-state model (healthy, home) multi-state model.
Neither good explanation Mr. Smiths alive vacation.
causal explanation tree method also robust face modeling choice.
selects Healthy important variable. also finds (healthy) best
explanation models.
334

fiMost Relevant Explanation Bayesian Networks

Healthy
Vacation location


-0.345

home
hiking
0.322

0.075

Vacation location
0.678

Healthy


home hiking

yes

-0.063

0.169

0.153

yes

(a) ET one-state model

-3.233

(b) CET one-state model
Healthy

Vacation location


-0.345

home
trip
0.237


0.153

Vacation location

0.008

Healthy

0.075

home trip

yes

-0.063

0.084

(c) ET multi-state model

yes

-3.233

(d) CET multi-state model

Figure 6: Explanation trees (ET) causal explanation trees (CET) Vacation
networks give Mr. Smith alive vacation.

Next consider scenario Mr. Smith died vacation. Table 5
Figure 7 show explanations found various methods observation.
MRE finds (healthy, hiking) best explanation one-state model
(healthy) multi-state model. rather intuitive result. one-state
model, hiking likely event significantly increases chance Mr. Smiths death
unhealthy. multi-state model, however, hiking trails modeled
individual states, rather low prior posterior probabilities. result, MRE considered individual hiking trips unimportant details excluded
best explanation. may argue individual hiking trip
effect hiking state one-state model. However, reasoning ignores prior
probabilities explanations essentially supports use likelihood measure
335

fiYuan, Lim, & Lu

Vacation
K-MRE
K-MAP

K-SIMP

One-state model
Explanations
Scores
(healthy, hiking)
36.00
(healthy, hiking)
(healthy, home)
(healthy, hiking)
(healthy, hiking)
(healthy)
(hiking)

0.0360
0.0160
0.0064
0.9000
0.2600
0.0624

Multi-state model
Explanations
Scores
(healthy)
26.0000
(home)
1.2310
(healthy, home)
0.0160
(healthy, home)
0.0008
(healthy, trip)
0.0004
(healthy, trip)
0.9000
(healthy)
0.2600
(home)
0.0700

Table 5: Top explanations found K-MRE, K-MAP, K-SIMP two Vacation
networks given Mr. Smith died vacation.

select explanations. already discussed earlier, likelihood measure
significant drawbacks.
K-MAP shown sensitive modeling choice. best explanation
changed (healthy, hiking) one-state model (healthy, home) multistate model. (healthy, home) good explanation staying home reduces
likelihood Mr. Smiths death vacation.
K-SIMP method selects (healthy, hiking) one-state model (healthy,
trip) multi-state model. Therefore, 100 best explanations exactly
score according method.
ET method creates simple trees root models. However,
variable chosen method counterintuitive. Vacation location
important variable explaining Mr. Smiths death.
CET method made good choice selecting Healthy important variable. Similar K-SIMP, CET also included detailed vacation locations part
explanations, 100 best explanations score.
5.3 Academe
Figure 8 shows Academe network introduced Flores et al. (2005) discuss
explanation tree method. prior probability distributions four target variables
Theory, Practice, Extra, OtherFactors parameterized follows.
P (T heory) < good, average, bad > = < 0.4, 0.3, 0.3 >;
P (P ractice) < good, average, bad > = < 0.6, 0.25, 0.15 >;
P (Extra) < yes, > = < 0.3, 0.7 >;
P (OtherF actors) < plus, minus > = < 0.8, 0.2 >;
conditional probabilities MarkTP, GlobalMark, FinalMark given parents parameterized follows.
P (M arkT P = pass|T heory = bad P ractice = bad) = 0.0;
336

fiMost Relevant Explanation Bayesian Networks

Healthy

2.115

home hiking

home hiking
0.293

0.737

0.707

(a) ET one-state model

-2.585

Vacation location

Vacation location

yes

3.907

(b) CET one-state model
Healthy

2.115
Vacation location

Vacation location

0.737

0.007

(c) ET multi-state model

-2.585

home trip

home trip
0.280

yes

3.907

(d) CET multi-state model

Figure 7: Explanation trees (ET) causal explanation trees (CET) Vacation
networks given Mr. Smith died vacation.

P (M arkT P = pass|T heory = good, P ractice = good) = 1.0;
P (M arkT P = pass|T heory = good, P ractice = average) = 0.85;
P (M arkT P = pass|T heory = average, P ractice = good) = 0.9;
P (M arkT P = pass|T heory = average, P ractice = average) = 0.2;
P (GlobalM ark = pass|M arkT P = pass, Extra = ) = 1.0;
P (GlobalM ark = pass|M arkT P = f ail, Extra = yes) = 0.25;
P (GlobalM ark = pass|M arkT P = f ail, Extra = no) = 0.0;
P (F inalM ark = pass|GlobalM ark = pass, OtherF actors = plus) = 1.0;
P (F inalM ark = pass|GlobalM ark = pass, OtherF actors = minus) = 0.7;
337

fiYuan, Lim, & Lu

Practice

Theory

Extra

MarkTP

OtherFactors

GlobalMark

FinalMark

Figure 8: Academe network.
Academe
K-MRE

K-MAP

K-SIMP

Explanations
(bad theory)
(bad practice, extra)
(good theory, bad practice, minus otherF actors)
(bad theory, good practice, extra, plus otherF actors)
(bad theory, average practice, extra, plus otherF actors)
(average theory, bad practice, extra, plus otherF actors)
(bad theory, extra)
(average theory, bad practice)

Scores
3.0205
2.2986
2.0209
0.0958
0.0399
0.0399
0.9600
0.7260

Table 6: Top explanations found K-MRE, K-MAP, K-SIMP Academe network given FinalMark fail.

P (F inalM ark = pass|GlobalM ark = f ail, OtherF actors = plus) = 0.05;
P (F inalM ark = pass|GlobalM ark = f ail, OtherF actors = minus) = 0.0.
consider problem finding explanations observation FinalMark
fail using target variable set {T heory, P ractice, Extra, OtherF actors}. Table 6
Figure 9 show explanations found various methods observation.
K-MRE selects (bad theory) best explanation failing final grade.
good explanations contain bad theory part, (bad theory) dominates
explanations. (bad practice) good explanation, combination
bad practice extra preparation turns better explanation.
top three explanations found K-MAP probabilities smaller 0.1.
general, highly domain-dependent probabilities mean good explanations
mean bad explanations. comparison, GBFs likelihood evidence
consistent across different domains. Note claiming top
explanations ranked probability necessarily bad; believe probability may
good measure explanatory power explanation.
K-SIMP method selects (bad theory, extra) best explanation. explanation good explanation itself. However, really explanation highest
338

fiMost Relevant Explanation Bayesian Networks

Theory
good
-1.135
Practice
average
-1.360

good

average
-0.242
Practice
good
average
-1.728

bad

bad

0.911

bad

Practice
OtherFactors

-2.984

good
0.423
Theory

average
0.295

plus
-1.848
Extra

0.030

0.054

good average

0.339

0.039

0.613

0.911

plus
minus
-2.433

minus

0.282

Theory

good average bad

OtherFactors

0.911

bad

0.115

bad

yes

0.141

-2.151

(a)

Extra

-0.257

-1.736

-0.380

yes
-2.736

-2.321

(b)

Figure 9: (a) Explanation tree (b) causal explanation tree Academe network
FinalMark fail.

likelihood. example, likelihood failing grade given (bad theory, bad practice,
extra, minus otherF actors) equal 1.0, K-SIMP limited top solutions
found K-MAP. Also, method ended two explanations,
top two MAP solutions simplified explanation.
ET method incorrectly selects Practice important variable; Theory
higher impact final mark according model. Again, ET
method measures importance target variable using mutual information
target variables, evidence variable. Recall made bad choices
Academe Vacation networks well.
CET method made sensible choice selecting Theory important
variable. three equally good explanations according method: (bad theory),
(average theory, bad practice), (good theory, bad practice). reason
method cannot distinguish explanations marks branches using log
ratio posterior prior probabilities evidence, proportional
likelihood measure.
5.4 Asia
Asia network first introduced Lauritzen Spiegelhalter (1988) used
Nielsen et al. (2008) discuss CET method. probabilities network
parameterized follows.
P (V isitT oAsia = yes) = 0.01;
P (Smoking = yes) = 0.5;
P (T uberculosis = yes|V isitT oAsia = yes) = 0.05;
339

fiYuan, Lim, & Lu

VisitToAsia

Tuberculosis

Lung_Cancer

Smoking

Dyspnea

Bronchitis

TborCa

X_Ray

Figure 10: Asia network.
P (T uberculosis = yes|V isitT oAsia = no) = 0.01;
P (LungCancer = yes|Smoking = yes) = 0.1;
P (LungCancer = yes|Smoking = no) = 0.01;
P (Bronchitis = yes|Smoking = yes) = 0.6;
P (Bronchitis = yes|Smoking = no) = 0.3;
P (T borCa = yes|T uberculois = yes LungCancer = yes) = 1.0;
P (T borCa = yes|T uberculois = no, LungCancer = no) = 0.0;
P (Dyspnea = yes|T borCa = yes, Bronchitis = yes) = 0.9;
P (Dyspnea = yes|T borCa = yes, Bronchitis = no) = 0.7;
P (Dyspnea = yes|T borCa = no, Bronchitis = yes) = 0.8;
P (Dyspnea = yes|T borCa = no, Bronchitis = no) = 0.1;
P (X ray = abnormal|T borCa = yes) = 0.98;
P (X ray = abnormal|T borCa = no) = 0.05;
consider two different observations Asia network: Dyspnea present, X-ray
abnormal. Table 7 Figure 11 show explanations found various methods
two observations using target variable set {Bronchitis, LungCancer, uberculosis}.
interesting K-MRE obtained quite intuitive concise top explanations
observations: (Bronchitis), (LungCancer), (T uberculosis). use disease name
Bronchitis denote presence disease negation Bronchitis
denote absence disease. ranking explanations, however, different. first observation, (Bronchitis) better explanation Dyspnea
(T uberculosis) (LungCancer) conditional probabilities show presence Bronchitis larger effect Dyspnea. second observation, Tuberculosis
LungCancer ancestors X-ray, Bronchitis direct effect X-ray
receives small GBF. reason (Bronchitis)s GBF still greater 1.0
Bronchitis increases likelihood Smoking, turn increases likelihood
abnormal X-ray.
K-MAP identified Bronchitis part best explanation first observation,
included Bronchitis LungCancer part best explanation
second observation, even though Bronchitis direct contributor abnormal
340

fiMost Relevant Explanation Bayesian Networks

Asia
K-MRE

K-MAP

K-SIMP

K-MRE

K-MAP

K-SIMP

Explanations

Scores

Dyspnea present
(Bronchitis)
(LungCancer)
(T uberculosis)
(LungCancer, uberculosis, Bronchitis)
(LungCancer, uberculosis, Bronchitis)
(LungCancer, uberculosis, Bronchitis)
(LungCancer, Bronchitis)
(Bronchitis)
(T uberculosis)
Abnormal X-ray
(LungCancer)
(T uberculosis)
(Bronchitis)
(LungCancer, uberculosis, Bronchitis)
(LungCancer, uberculosis, Bronchitis)
(LungCancer, uberculosis, Bronchitis)
(LungCancer)
(T uberculosis)

6.1391
1.9678
1.8276
0.3313
0.0521
0.0521
0.9000
0.8080
0.4323
16.4231
9.6886
1.2535
0.0305
0.0261
0.0228
0.9800
0.1012

Table 7: Top explanations found K-MRE, K-MAP, K-SIMP Asia network
given two different observations.

X-ray. second best explanation first observation claims none diseases
present, clearly good explanation.
K-SIMP method found quite perplexing explanations observations. best
explanation (LungCancer, Bronchitis) first observation (LungCancer)
second observation. reason K-SIMP find good explanations
network K-SIMP restricted solutions found K-MAP. method
still able find (Bronchitis) second best explanation first observation,
missed altogether second observation.
ET method able find important variables explaining observations, fell short recognizing importance Tuberculosis explaining
second observation. expanded LungCancer explaining first observation.
CET method able find intuitive explanations. best explanations
(Bronchitis) Dyspnea (LungCancer) abnormal X-ray. However, one drawback
explanation tree tree structure requires explanation start
root. example, one explanations explaining Dyspnea (Bronchitis, LungCancer, uberculosis). arguable (T uberculosis) good explanation
explaining Dyspnea; really necessary include Bronchitis LungCancer
part explanation. believe another common drawback two
explanation tree methods caused tree representation use.
341

fiYuan, Lim, & Lu

Bronchitis

-1.650

yes

Bronchitis

0.887

LungCancer


0.166

yes

LungCancer

0.834

yes


-2.037

yes

0.683

Tuberculosis



yes

0.128

0.038

0.683

(a) ET Dyspnea


-2.124

(b) CET Dyspnea
LungCancer

yes

LungCancer
yes
0.489

3.151


-0.886
Tuberculosis



yes

0.511

(c) ET abnormal X-ray

3.151


-1.141

(d) CET abnormal X-ray

Figure 11: Explanation trees (ET) causal explanation trees (CET) found Asia
network given two different observations.

5.5 Circuit2
Model-based diagnosis application abductive inference Horn-clause logic theories (Peirce, 1948; de Kleer & Williams, 1987), tries find minimal set assumptions that, together background knowledge, logically entail observations need
explanation. However, methods model-based diagnosis developed based logic
theories. Entailment either true false logic systems. methods cannot
easily generalized probabilistic expert systems Bayesian networks. contrast,
342

fiMost Relevant Explanation Bayesian Networks



B

1

2

C



B

OK_1

OK_2

OK_3


C



3
E

E

(a)

(b)

Figure 12: (a) digital circuit Darwiche (2009) (b) corresponding Bayesian
network.

Circuit Figure 12
K-MRE
K-MAP

K-SIMP

Explanations
(OK3 )
(OK1 , OK2 )
(OK1 , OK2 , OK3 )
(OK1 , OK2 , OK3 )
(OK1 , OK2 , OK3 )
(OK3 )
(OK1 , OK2 )

Scores
4.0000
2.0000
0.1250
0.1250
0.1250
1.0000
1.0000

Table 8: Top explanations found K-MRE, K-MAP, K-SIMP Circuit2 network
given output observed low.

MRE easily applied model-based diagnostic systems faulty behaviors
components also specified.
consider digital circuit Figure 12(a) used Darwiche (2009) discuss
methods model-based diagnosis. Gates 1 2 inverters, gate 3
gate. prior probability gates abnormal 0.5. inverter
abnormal, outputs low input low, outputs high probability 0.5
input high. gate abnormal, always outputs low. digital
circuit modeled Bayesian network Figure 12(b). consider case
output E observed low. two kernel model-based diagnoses (OK1 , OK2 )
(OK3 ). Table 8 Figure 13 show explanations found various methods
observation using target variable set {OK1 , OK2 , OK3 }.
K-MRE able find two kernel diagnoses top two explanations,
(OK3 ) receives higher GBF (OK1 , OK2 ). higher GBF score due
(OK3 )s higher prior posterior probabilities (OK1 , OK2 ). comparison,
methods model-based diagnosis typically treat two explanations equally good.
343

fiYuan, Lim, & Lu

OK_2

yes
0.600
OK_3

0.400


yes
0.400
OK_1

0.200

OK_2

0.200



yes

-0.322

0.263

0.200

(a)

yes

(b)

Figure 13: (a) Explanation tree (b) causal explanation tree Circuit2 network
given output observed low.

K-MAP able single two kernel diagnoses. fact, many MAP solutions
posterior probability, including explanation gates
defective.
K-SIMP method found two explanations K-MRE. Therefore, simplification method helped simplifying explanations network. However, K-SIMP
able rank two explanations either.
two explanation tree methods completely misfired network. unclear
make sense explanation tree ET method Figure 13(a). causal
explanation tree Figure 13(b) expanded variable OK 2 failed find
kernel diagnoses. Again, explanation tree methods greedy search
methods cannot recognize compound effect multiple variables.
5.6 Summary Case Studies
case studies show K-MRE able identify relevant target variables
find concise intuitive explanations methods. GBF seems
plausible measure explanatory power achieve preciseness conciseness
explanations time. Another advantage GBF use Table 1
general guidance determining significance explanations found K-MRE.
contrast, probability seems good measure explanatory power. Methods
344

fiMost Relevant Explanation Bayesian Networks

based probability, K-MAP, quite sensitive modeling choices; also
lack capability indicate important parts explanations. K-MAP
simplification method shown often able simplify solutions K-MAP
get concise explanations. fundamental drawback restricted
solutions found K-MAP may able find best explanations. Also,
may reduce multiple top MAP solutions explanation. ET method
uses mutual information target variables criterion select target
variables explain evidence. criterion shown effective. Also,
using probability rank explanations makes ET method sensitive
user-specified threshold value bounding probabilities branches. CET
method good identifying individual target variables important, often
fails recognize significant compound effect multiple variables.
CET method, well ET method, based greedy search considers
one variable time. Another common drawback explanation tree methods
tree representation fundamentally limits capability methods find concise
explanations.

6. Concluding Remarks
paper, introduced Relevant Explanation (MRE) method finding
explanations given evidence Bayesian networks. study shows MRE
several desirable theoretical properties enable MRE automatically identify
relevant target variables find explanation evidence. MRE also able
capture unique explaining-away phenomenon often represented Bayesian networks.
defined two dominance relations among MRE solutions used develop
K-MRE method find set top MRE solutions diverse representative.
results case studies set benchmark Bayesian networks agree quite well
theoretical understandings MRE. Another contribution research
also made clear properties drawbacks several existing relevance measures
explanation methods.

Acknowledgments
research supported National Science Foundation grants IIS-0842480, IIS0953723, EPS-0903787. Part research previously presented DX07 (Yuan & Lu, 2007), AAAI-08 (Yuan & Lu, 2008), UAI-09 (Yuan, Liu, Lu, & Lim, 2009),
ExaCt-09 (Yuan, 2009). thank editors anonymous reviewers
constructive comments.

Appendix A. Proofs
following proofs theorems corollaries.
345

fiYuan, Lim, & Lu

A.1 Proof Theorem 1
Proof: likelihood measure expressed
P (e|x) =

P (x|e)P (e)
= r(x; e)P (e).
P (x)

Therefore, fixed likelihood P (e|x) indicates belief update ratio r(x; e) remains
constant prior posterior probabilities may vary. Furthermore, GBF
expressed follows.
GBF (x; e) = 1 +

r(x; e) 1
.
1 r(x; e)P (x)

Therefore, GBF monotonically non-decreasing fixed belief update ratio r(x; e)
greater equal 1.0 prior posterior probabilities increase.
2
A.2 Proof Theorem 2
Proof:
GBF (x, y; e) =
=
=

P (x, y|e)(1 P (x, y))
P (x, y)(1 P (x, y|e))
P (x|e)P (y|x, e)(1 P (y|x)P (x))
P (x)P (y|x)(1 P (y|x, e)P (x|e))
1
P (x|e) 1 P (x) + P (y|x) 1
P (x) 1 P (x|e) +

1
P (y|x,e)

1

equation less equal GBF (x; e)



1
P (y|x) 1
1
P (y|x,e) 1



P (y|x, e)(1 P (y|x))
P (y|x)(1 P (y|x, e))



CBF (y; e|x)

1 P (x)
1 P (x|e)
P (x)
P (x|e)
1
.
r(x; e)
2

A.3 Proof Corollary 1
Proof: corollary follows Theorem 2. present another way prove it.
GBF (x, y; e) =
=
=

P (x, y|e)(1 P (x, y))
P (x, y)(1 P (x, y|e))
P (x|e)P (y)(1 P (y)P (x))
P (x)P (y)(1 P (y)P (x|e))
P (x|e)(1 P (y)P (x))
.
P (x)(1 P (y)P (x|e))
346

fiMost Relevant Explanation Bayesian Networks

P (x|e) > P (x),
GBF (x, y; e) =
=
<

=

P (x|e)(1 P (y)P (x))
P (x)(1 P (y)P (x|e))
P (x|e)(1 P (x) + (1 P (y))P (x))
P (x)(1 P (x|e) + (1 P (y))P (x|e))
P (x|e)(1 P (x) + (1 P (y))P (x))
P (x)(1 P (x|e) + (1 P (y))P (x))
P (x|e)(1 P (x))
P (x)(1 P (x|e))
GBF (x; e) .
2

A.4 Proof Corollary 2
Proof: corollary proved similar way Corollary 1.
GBF (x, y; e) =
=
=
=

P (x, y|e)(1 P (x, y))
P (x, y)(1 P (x, y|e))
P (x|e)P (y|x, e)(1 P (y|x)P (x))
P (x)P (y|x)(1 P (y|x, e)P (x|e))
P (x|e)P (y|x)(1 P (y|x)P (x))
P (x)P (y|x)(1 P (y|x)P (x|e))
P (x|e)(1 P (y|x)P (x))
.
P (x)(1 P (y|x)P (x|e))

P (x|e) > P (x),
GBF (x, y; e) =
=
<

=

P (x|e)(1 P (y|x)P (x))
P (x)(1 P (y|x)P (x|e))
P (x|e)(1 P (x) + (1 p(y|x))P (x))
P (x)(1 P (x|e) + (1 p(y|x))P (x|e))
P (x|e)(1 P (x) + (1 p(y|x))P (x))
P (x)(1 P (x|e) + (1 p(y|x))P (x))
P (x|e)(1 P (x))
P (x)(1 P (x|e))
GBF (x; e) .
2

A.5 Proof Corollary 3
Proof:
GBF (x, y; e) =

P (x|e)P (y|x, e)(1 P (y|x)P (x))
P (x, y|e)(1 P (x, y))
=
.
P (x, y)(1 P (x, y|e))
P (x)P (y|x)(1 P (y|x, e)P (x|e))
347

fiYuan, Lim, & Lu

P (y|x, e) P (y|x),
GBF (x, y; e)

P (x|e)(1 P (y|x)P (x))
P (x|e)P (y|x)(1 P (y|x)P (x))
=
.
P (x)P (y|x)(1 P (y|x)P (x|e))
P (x)(1 P (y|x)P (x|e))

P (x|e) > P (x),
GBF (x, y; e) =
=
<

=

P (x|e)(1 P (y|x)P (x))
P (x)(1 P (y|x)P (x|e))
P (x|e)(1 P (x) + (1 p(y|x))P (x))
P (x)(1 P (x|e) + (1 p(y|x))P (x|e))
P (x|e)(1 P (x) + (1 p(y|x))P (x))
P (x)(1 P (x|e) + (1 p(y|x))P (x))
P (x|e)(1 P (x))
P (x)(1 P (x|e))
GBF (x; e) .
2

A.6 Proof Theorem 3
Proof:

C observed, following equality.
P (B|A, x, y) = P (B|x, y) = P (B|A, x, y) = P (B|y).

(19)

Therefore,
P (B|A, c, x, y) P (B|c, x, y) P (B|A, c, x, y)


1 P (B|A, c, x, y) 1 P (B|c, x, y) 1 P (B|A, c, x, y)
P (B|A,c,x,y)
1P (B|A,c,x,y)




P (B|A,c,x,y) 1P (B|A,x,y)
1P (B|A,c,x,y) P (B|A,x,y)







P (B|c,x,y)
1P (B|c,x,y)



P (B|A,c,x,y)
1P (B|A,c,x,y)

P (B|c,x,y) 1P (B|x,y)
1P (B|c,x,y) P (B|x,y)



P (B|A,c,x,y) 1P (B|A,x,y)
1P (B|A,c,x,y) P (B|A,x,y)

GBF (B; c|A, x, y) GBF (B; c|x, y) GBF (B; c|A, x, y)

.
2

References
AR Group, UCLA (2010). Samiam: Sensitivity analysis, modeling, inference more..
http://reasoning.cs.ucla.edu/samiam/index.php.
Ay, N., & Polani, D. (2008). Information flows causal networks. Advances Complex
Systems (ACS), 11 (01), 1741.
Bleich, H. L. (1972). Computer-based consultation: Electrolyte acid-base disorders.
American Journal Medicine, 53 (3), 285 291.
348

fiMost Relevant Explanation Bayesian Networks

Buchanan, B., & Shortliffe, E. (Eds.). (1984). Rule-Based Expert Systems: MYCIN Experiments Stanford Heuristic Programming Project. Addison-Wesley, Reading,
MA.
Carnap, R. (1948). Logical Foundations Probability. 2nd ed. University Chicago Press,
Chicago, IL.
Chajewska, U., & Halpern, J. Y. (1997). Defining explanation probabilistic systems.
Proceedings Thirteenth Annual Conference Uncertainty Artificial Intelligence (UAI97), pp. 6271, San Francisco, CA. Morgan Kaufmann Publishers.
Dannenberg, A., Shapiro, A., & Fries, J. (1979). Enhancement clinical predictive ability
computer consultation. Methods Inf Med, 18 (1), 1014.
Darwiche, P. A. (2009). Modeling Reasoning Bayesian Networks (1st edition).
Cambridge University Press, New York, NY, USA.
de Campos, L. M., Gamez, J. A., & Moral, S. (2001). Simplifying explanations Bayesian
belief networks. International Journal Uncertainty, Fuzziness Knowledge-Based
Systems, 9 (4), 461489.
de Kleer, J., & Williams, B. C. (1987). Diagnosing multiple faults. Artificial Intelligence,
32 (1), 97130.
Druzdzel, M. J. (1996). Explanation probabilistic systems: feasible? work?.
Proceedings Fifth International Workshop Intelligent Information Systems
(WIS-96), pp. 1224, Deblin, Poland.
Druzdzel, M. J. (1999). GeNIe: development environment graphical decision-analytic
models. Proceedings 1999 Annual Symposium American Medical
Informatics Association (AMIA1999), p. 1206, Washington, D.C.
Fitelson, B. (2001). Studies Bayesian Confirmation Theory. Ph.D. thesis, University
Wisconsin, Madison, Philosophy Department.
Flores, J., Gamez, J. A., & Moral, S. (2005). Abductive inference Bayesian networks:
finding partition explanation space. Eighth European Conference Symbolic Quantitative Approaches Reasoning Uncertainty, ECSQARU05, pp.
6375. Springer Verlag.
Gardenfors, P. (1988). Knowledge Flux: Modeling Dynamics Epistemic States.
MIT Press.
Good, I. J. (1950). Probability Weighing Evidence. Griffin, London.
Good, I. J. (1977). Explicativity: mathematical theory explanation statistical
applications. Proceedings Explicativity: Mathematical Theory Explanation
Statistical Applications, Series A. Vol. 354, No. 1678, pp. 303330.
Good, I. J. (1985). Weight evidence: brief survey. Bayesian Statistics, 2, 249270.
349

fiYuan, Lim, & Lu

Halpern, J. Y., & Pearl, J. (2005). Causes Explanations: Structural-Model Approach.
Part II: Explanations. British Journal Philosophy Science, 56 (4), 889
911.
Heckerman, D., Breese, J., & Rommelse, K. (1995a). Decision-theoretic troubleshooting.
Communications ACM, 38, 4957.
Heckerman, D., Mamdani, E. H., & Wellman, M. P. (1995b). Real-world applications
Bayesian networks - introduction. Commun. ACM, 38 (3), 2426.
Hempel, C. G. (1965). Aspects Scientific Explanation Essays Philosophy
Science. Free Press, New York, NY.
Hempel, C. G., & Oppenheim, P. (1948). Studies logic explanation. Bobbs-Merrill,
Indianapolis, IN.
Henrion, M., & Druzdzel, M. J. (1991). Qualitative propagation scenario-based schemes
explaining probabilistic reasoning. Bonissone, P., Henrion, M., Kanal, L., &
Lemmer, J. (Eds.), Uncertainty Artificial Intelligence 6, pp. 1732. Elsevier Science
Publishing Company, Inc., New York, N. Y.
Jeffreys, H. (1935). Contribution discussion Fisher. Journal Royal Statistical
Society, 98, 7072.
Jeffreys, H. (1961). Theory Probability. Oxford University Press.
Jensen, F. V., & Liang, J. (1994). drHugin: system value information Bayesian
networks. Proceedings 1994 Conference Information Processing Management Uncertainty Knowledge-Based Systems, pp. 178183.
Kalagnanam, J., & Henrion, M. (1988). comparison decision analysis expert rules
sequential diagnosis. Proceedings 4th Annual Conference Uncertainty
Artificial Intelligence (UAI-88), pp. 253270, New York, NY. Elsevier Science.
Kass, R. E., & Raftery, A. E. (1995). Bayes factors. Journal American Statistical
Association, pp. 773795.
Khan, O. Z., Poupart, P., & Black, J. P. (2009). Minimal sufficient explanations factored
markov decision processes. Proceedings Nineteenth International Conference
Automated Planning Scheduling, pp. 194200.
Kitcher, P., & Salmon, W. (1989). Explanatory unification causal structure
world, pp. 410505. University Minnesota Press, Minneapolis, MN.
Kullback, S., & Leibler, R. (1951). information sufficiency. Annals Mathematical
Statistics, 22(1), 7986.
Lacave, C., & Diez, F. (2002). review explanation methods Bayesian networks.
Knowledge Engineering Review, 17, 107127.
350

fiMost Relevant Explanation Bayesian Networks

Lacave, C., Luque, M., & Diez, F. (2007). Explanation Bayesian networks influence
diagrams elvira. IEEE Transactions Systems, Man, Cybernetics, Part B:
Cybernetics, 37 (4), 952 965.
Lauritzen, S. L., & Spiegelhalter, D. J. (1988). Local computations probabilities
graphical structures application expert systems. Journal Royal
Statistical Society, Series B (Methodological), 50 (2), 157224.
Leake, D. B. (1995). Abduction, experience, goals: model everyday abductive
explanation. Journal Experimental Theoretical Artificial Intelligence, 7,
407428.
Lin, Y., & Druzdzel, M. J. (1998). Relevance-based sequential evidence processing
Bayesian networks. Proceedings Uncertain Reasoning Artificial Intelligence
track Eleventh International Florida Artificial Intelligence Research Symposium
(FLAIRS98), pp. 446450, Menlo Park, CA. AAAI Press/The MIT Press.
Minsky, M., & Selfridge, O. (1961). Learning random nets. Addison-Wesley, Butterworth,
London.
Nerlich, G. (1979). Time direction conditionship. Australasian Journal
Philosoph, 57 (1), 314.
Ng, H. T., & Mooney, R. J. (1990). role coherence abductive explanation.
Proceedings Eighth National Conference Artificial Intelligence (AAAI-90),
pp. 337342, Boston, MA.
Nielsen, U., Pellet, J.-P., & Elisseeff, A. (2008). Explanation trees causal Bayesian
networks. Proceedings 24th Annual Conference Uncertainty Artificial
Intelligence (UAI-08), pp. 427434.
Pearl, J. (1988). Probabilistic Reasoning Intelligent Systems: Networks Plausible
Inference. Morgan Kaufmann Publishers, Inc., San Mateo, CA.
Peirce, C. (1948). Philosophy Peirce: Selected Writings, chap. Abduction induction. Harcourt, Brace Company, New York.
Poole, D., & Provan, G. M. (1991). likely diagnosis?. Bonissone, P.,
Henrion, M., Kanal, L., & Lemmer, J. (Eds.), Uncertainty Artificial Intelligence 6,
pp. 89105. Elsevier Science Publishing Company, Inc., New York, N. Y.
Rosenkrantz, R. D. (1994). Bayesian confirmation: Paradise regained. British Journal
Philosophy Science, 45(2), 467476.
Salmon, W. (1970). Statistical explanation, pp. 2987. University Pittsburgh Press,
Pittsburgh, PA.
Salmon, W. (1984). Explanation Causal Structure World. Princeton University Press, Princeton, NJ.
351

fiYuan, Lim, & Lu

Schwartz, G. (1979). Estimating dimensions model. Ann. Stat., 6, 461464.
Shimony, S. (1993). role relevance explanation I: Irrelevance statistical independence. International Journal Approximate Reasoning, 8 (4), 281324.
Shimony, S. (1996). role relevance explanation II: Disjunctive assignments
approximate independence. International Journal Approximate Reasoning, 14 (1),
2554.
Smyth, B., & McClave, P. (2001). Similarity vs. diversity. Proceedings International
Conference Case-based Reasoning (ICCBR-01), pp. 347361.
Suermondt, H. (1992). Explanation Bayesian Belief Networks. Ph.D. thesis, Stanford
University, Palo Alto, California.
Teach, R. L., & Shortliffe, E. H. (1981). analysis physician attitudes regarding
computer-based clinical consultation systems. Computers biomedical research,
international journal, 14 (6), 542558.
van der Gaag, L., & Wessels, M. (1993). Selective evidence gathering diagnostic belief
networks. AISB Quarterly, pp. 2334.
van der Gaag, L., & Wessels, M. (1995). Efficient multiple-disorder diagnosis strategic
focusing, pp. 187204. UCL Press, London.
van Fraassen, B. (1980). Scientific Image. Oxford University Press, Oxford.
Wellman, M., & Henrion, M. (1993). Explaining explaining away. IEEE Transactions
Pattern Analysis Machine Intelligence, 15, 287291.
Woodward, J. (2003). Scientific explanation. Zalta, E. N. (Ed.), Stanford Encyclopedia Philosophy (Winter 2003 Edition).
Yuan, C. (2009). properties Relevant Explanation. Proceedings 21st
International Joint Conference Artificial Intelligence ExaCt Workshop (ExaCt-09),
pp. 118126, Pasadena, CA.
Yuan, C., Liu, X., Lu, T.-C., & Lim, H. (2009). Relevant Explanation: Properties,
algorithms, evaluations. Proceedings 25th Conference Uncertainty
Artificial Intelligence (UAI-09), pp. 631638, Montreal, Canada.
Yuan, C., & Lu, T.-C. (2007). Finding explanations Bayesian networks. Proceedings
18th International Workshop Principles Diagnosis (DX-07), pp. 414419.
Yuan, C., & Lu, T.-C. (2008). general framework generating multivariate explanations
Bayesian networks. Proceedings Twenty-Third National Conference
Artificial Intelligence (AAAI-08), pp. 11191124.

352

fiJournal Artificial Intelligence Research 42 (2011) 5590

Submitted 04/11; published 09/11

APP: Scalable Multi-Agent Path Planning Algorithm
Tractability Completeness Guarantees
Ko-Hsin Cindy Wang
Adi Botea

C INDY.WANG @ RSISE . ANU . EDU . AU
DI .B OTEA @ NICTA . COM . AU

NICTA & Australian National University,
Canberra, Australia

Abstract
Multi-agent path planning challenging problem numerous real-life applications. Running centralized search A* combined state space units complete
cost-optimal, scales poorly, state space size exponential number mobile units.
Traditional decentralized approaches, FAR W HCA *, faster scalable,
based problem decomposition. However, methods incomplete provide guarantees respect running time solution quality. necessarily able tell
reasonable time whether would succeed finding solution given instance.
introduce APP, tractable algorithm multi-agent path planning undirected graphs.
present basic version several extensions. low-polynomial worst-case upper
bounds running time, memory requirements, length solutions. Even though
algorithmic versions incomplete general case, provides formal guarantees
problems solve. version, discuss algorithms completeness respect
clearly defined subclasses instances.
Experiments run realistic game grid maps. APP solved 99.86% mobile units,
1822% better percentage FAR W HCA *. APP marked 98.82%
units provably solvable first stage plan computation. Parts APPs computation
re-used across instances map. Speed-wise, APP competitive significantly
faster W HCA *, depending whether APP performs computations scratch.
data APP re-use preprocessed offline readily available, APP slower
fast FAR algorithm factor 2.18 average. APPs solutions average 20%
longer FARs solutions 731% longer W HCA *s solutions.

1. Introduction
Path planning important many real-life problems, including robotics, military operations, disaster rescue, logistics, commercial games. Single-agent path planning, size state
space bounded size map, tackled search algorithm A* (Hart,
Nilsson, & Raphael, 1968). However, many units moving simultaneously inside
shared space, problem becomes much harder. centralized search initial state goal
state difficult problem even inside fully known, two-dimensional environment represented
weighted graph, one node occupied exactly one unit time. Assuming
units size, unit moves synchronously adjacent unoccupied node one
time step, problems state space grows exponentially number mobile units. Existing
hardness results shown NP-complete decide solution k moves exists (Ratner & Warmuth, 1986), optimize solution makespan (Surynek, 2010b). version
problem one robot movable obstacles several nodes, either robot
c
2011
AI Access Foundation. rights reserved.

fiWANG & B OTEA

obstacle move adjacent vacant node per step, also NP-complete (Papadimitriou,
Raghavan, Sudan, & Tamaki, 1994). Yet another version problem, determining solution exists moving two-dimensional rectangles different sizes inside box, shown
PSPACE-hard, even without requiring optimality (Hopcroft, Schwartz, & Sharir, 1984). Despite completeness solution optimality guarantees, centralized A* search little practical
value multi-agent path planning problem, intractable even relatively small maps
collections mobile units.
Scalability larger problems achieved decentralized approaches, decompose
global search series smaller searches significantly reduce computation. However,
existing decentralized methods FAR (Wang & Botea, 2008) W HCA * (Silver, 2006)
incomplete, provide formal criteria distinguish problem instances
successfully solved instances. Further, guarantees given respect running
time quality computed solutions.
work present algorithm combines strengths worlds: working well
practice featuring theoretical tractability partial completeness guarantees. introduce
APP, tractable multi-agent path planning algorithm undirected graphs. problem instance, APP systematically identifies set units, contain units instance,
guaranteed solved within low-polynomial time. sake clarity distinguish
basic version extended versions APP. APP provides formal guarantees
problems solve. Basic APP algorithm complete class problems, called
LIDABLE, define Section 3. Extended versions algorithm enlarge completeness range, discussed Section 7, improve solution length, discussed Section 8.
also evaluate version attempts solve units, provably solvable ones.
Given problem graph nodes n mobile units, APPs worst case performance
running time O(m2 n2 ), even smaller (e.g., O(max(mn2 , m2 log m))), depending
assumptions input instance. worst-case memory requirements within O(m2 n)
even O(mn). upper bound solution length, measured total number moves,
order O(m2 n2 ) even O(mn2 ). See Section 6 detailed discussion.
APP keeps running costs low eliminating need replanning. path (u)
unit u computed beginning. replanning required runtime. blank travel
idea, inspired way blank moves around sliding tile puzzles, center
u
algorithm. unit u progress current location liu next location li+1
path
u
(u) blank located (i.e., li+1 empty). Intuitively, next location currently
occupied another unit, APP tries bring blank along alternate path, outlined bold
u
u
li+1
without passing liu . possible, blank
Figure 1, connects li1
u
brought li+1 shifting units along alternate path, blank travels sliding tile
puzzle. ability bring blank next location key guarantee units progress. Formal
details provided Section 5.
performed detailed experiments, evaluating different versions APP comparing
APP fast incomplete methods FAR W HCA * grid maps. results
presented Section 9. benchmark data (Wang & Botea, 2008) consist 100 2000 mobile
units uniformly randomly generated 10 game maps, 10 scenario instances per number
units map. conclude extended APP significantly better success ratio
scalability state-of-the-art incomplete decentralized algorithms. particular, APP solves
higher percentage units even crowded instances. Despite APPs incompleteness
56

fiM APP : CALABLE ULTI -AGENT PATH P LANNING



b

u

l


u

c

b
c

Figure 1: left, unit u blocked a. blank found location l along alternate
path, marked bold contour. right: sliding b along
u . sake clarity simplicity,
alternate path, blank brought li+1
illustrate examples four-connected grid world.

general case, algorithm marks 98.82% units provably solvable first stage
plan computation. attempting solve units, provably solvable ones, APP
succeeds 99.86% units. comparison, FAR solved 81.87% units. W HCA * solved
77.84% (with diagonal moves allowed) 80.87% (with diagonal moves) units. Even
challenging instances 2,000 mobile units maps, 92% 99.7% mobile units test
data fall within APPs completeness range (i.e., provably solvable). terms percentage fully solved instances, version APP attempts solve units,
provably solvable, successful 84.5% instances. significantly better
FAR (70.6%), W HCA * diagonal moves (58.3%), W HCA * diagonals (71.25%).
Parts APPs computation re-used across instances map. instances
solved algorithms, APP competitive speed significantly faster W HCA *, depending whether APP performs computations scratch. re-usable data
available, APP slower fast FAR algorithm factor 2.18 average. APPs
solutions reported average 20% longer FARs solutions 731% longer
W HCA *s solutions.
Parts work reported shorter conference papers follows. theoretical
description Basic APP, experiments, provided earlier paper (Wang & Botea,
2009). brief overview APP extensions brief summary initial results topic
two-page paper (Wang & Botea, 2010). New material added current paper includes detailed
algorithmic description enhancements Basic APP formal proofs algorithms
properties. also provide comprehensive empirical analysis enhanced APP, several
additional experiments.
rest paper structured follows. Next briefly overview related work. Then,
state problem definition Section 3. Sections 46 focus Basic APP. Sections 7
8 cover enhancements Basic APP algorithm, extending completeness range (Section 7),
57

fiWANG & B OTEA

improving quality plans also running time (Section 8). empirical evaluation
topic Section 9. last part contains conclusions future work ideas.

2. Related Work
Finding shortest path connects single pair start-target points known, finite map
optimally solved A* algorithm (Hart et al., 1968). extension path planning
multiple simultaneously moving units, distinct start target positions, introduces potential
collisions due physical constraint one location occupied one unit
time. Units interact share information units path planning, making
problem complex.
multi-agent path planning, centralized A* performs single global search combined
state space L1 L2 Ln n units, Li set possible locations unit i.
Centralized A* plans paths units simultaneously, finding joint plan containing units
actions (waits well moves). retains optimality completeness guarantees A*,
prohibitively large state space O(mn ) states, n units graph nodes. Moreover,
search nodes generated unpromising, taking units farther goal (Standley,
2010). poses strong limiting factor problems centralized A* solve practice.
hand, purely decentralized method, Local Repair A* (L RA *) (Stout, 1996) first
plans units path independently A*. Then, execution, L RA * replans additional
independent A* searches every time collision occurs. good case, L RA * significantly
reduce computations O(mn). However, also generate cycles units, unable
prevent bottlenecks. problems discussed Silver (2005), Bulitko, Sturtevant, Lu,
Yau (2007), Pottinger (1999), Zelinsky (1992). cases, L RA * exhibits significant
increase running time may terminate. Therefore, straightforward extensions
single-agent A* outlined strong limitations practice.
Traditionally, multi-agent path planning took centralised decentralised approach (Latombe,
1991; Choset et al., 2005). centralized approach plans globally, sharing information centrally,
using potential field (Barraquand, Langlois, & Latombe, 1991). contrast, decentralized approach decomposes problem series smaller subproblems, typically first computing units paths individually, ignoring units, handling interactions online.
Examples robotics include computing velocity profiles avoid collisions units (Kant
& Zucker, 1986), pre-assigning priorities process robots one one (Erdmann & LozanoPerez, 1986). Recent algorithms also use combination two approaches. instance,
Biased Cost Pathfinding (BCP) technique (Geramifard, Chubak, & Bulitko, 2006) generalised
notion centralized planning central decision maker resolves collision points paths
pre-computed independently per unit, replanning colliding units around highestpriority unit. avoid excessively long (or even potentially unbounded) conflict resolutions, limit
planning time set. BCP returns paths fewest collisions within time. algorithm
shown work well small-scale gridworld scenarios, complete optimal
general case. Standleys (2010) algorithm, hand, improved standard centralized
search whilst preserving optimality completeness. new state space representation incorporates next move assignments every unit state, decomposes timestep
advancing units advancing units one one fixed ordering. Thus branching factor
reduced 9n 9, increasing depth search factor n. technique gen58

fiM APP : CALABLE ULTI -AGENT PATH P LANNING

erates 9nt state nodes perfect heuristic (t number timesteps
optimal solution). practice, operator decomposition technique (OD) still often intractable,
producing lower exponential search space standard joint search space. Recognising
much cheaper perform several independent searches one global search, Standley also
decoupled planning non-interfering subgroups units independence detection (ID).
group solved centrally optimality overall solution still guaranteed.
fully developed hybrid algorithm, OD+ID, uses operator decomposition improve centralized planning non-independent subproblems. Nonetheless, optimality requirement costly
practice. Planning time still dominated largest subgroup units. number
units increases, less likely independent paths unavoidably overlap,
subgroups expected increase size too. Standleys (2010) experiments showed incomplete algorithm HCA* (Silver, 2005) actually solved instances. Furthermore,
relatively small problems compared experiments (Wang & Botea, 2008, 2010),
least 2 orders magnitude fewer agents (between 260 units), much smaller maps, 1 2
orders magnitude fewer tiles (approximately 819 tiles).
Therefore, methods tackling larger problems take decentralized approach, usually suboptimal nature. general, giving optimality reduces computation significantly. Decentralized path planning often much faster, scales much larger problems, yields
suboptimal solutions provides completeness guarantees. Recent work grid maps include
W HCA * (Silver, 2006), uses 3-dimensional temporal-spatial reservation table performs
series windowed forward searches unit, based true distance heuristic obtained
initial backward A* search target. FAR algorithm (Wang & Botea, 2008),
units follow flow annotation map planning moving, repairing plans locally using
heuristic procedures break deadlocks. flow related ideas include Jansen Sturtevants
(2008) direction map sharing information units directions travel, later units
follow movement earlier ones, improved coherence leading reduced collisions.
Methods scale instances number units well beyond capabilities
centralized search. However, mentioned earlier, methods known formal characterizations running time, memory requirements, quality solutions worst
case. lack ability answer reasonable bounded time whether given problem would
successfully solved, always important case incomplete algorithms.
practice, traditional approaches multi-agent pathfinding serious drawbacks,
inherent trade-off scalability, optimality completeness. Recently, body work
begun bridge gap two, addressing completeness tractability issues
hand hand, bounded suboptimal approach. Ryan (2008) introduced complete method
combines multi-agent path planning hierarchical planning search graphs specific substructures stacks, halls, cliques rings. example, stack narrow corridor
one entrance, placed one end stack. Many maps, including game maps
used experiments, seem allow efficient decomposition stacks, halls, cliques
rings. B IBOX (Surynek, 2009b) solves problems least 2 unoccupied vertices biconnected graph. worst case, number steps cubic number nodes. B IBOX
later extended work 1 unoccupied vertex necessary (Surynek, 2009a).
densely populated problems algorithm designed for, Surynek (2010a) expressed
B IBOX target computer game scenarios, normally lot fewer units
locations map. B IBOX suited multi-robot scenarios automatic packages
59

fiWANG & B OTEA

inside warehouse (Surynek, 2010c). Bibox- (Surynek, 2009a), requires 1 unoccupied
node, shown run significantly faster significantly shorter solutions Kornhauser,
Miller, Spirakiss (1984) algorithm related pebble coordination game. performed
quick evaluation B IBOX using code obtained author. found that, graphs
order magnitude smaller game maps, B IBOX exhibits fast-growing runtime (e.g.,
10 minutes graph 2500 locations) long solutions, millions moves.
Part explanation B IBOX builds instances crowded. understanding,
B IBOX designed solve crowded instances, necessarily efficiently solve instances
significantly fewer units locations.

3. Problem Statement
instance characterized graph representation map, non-empty collection
mobile units U . Units homogeneous speed size. unit u U associated starttarget pair (su , tu ). units distinct starting target positions. objective navigate
units start positions targets avoiding fixed mobile obstacles. state
contains positions units given time. work assumes undirected weighted graphs
unit occupies exactly one node time, move unoccupied neighbour
node. time discretized one units move synchronously time step.
Travelling along edge depend interfere rest problem, except
two nodes connected edge.
Several methods exist abstract problem map search graph, including navigation
meshes (Tozour, 2002), visibility points (Rabin, 2000), quadtrees (Samet, 1988). However,
graph abstraction generates nodes, visibility graph, may render multi-agent
pathfinding problem unsolvable, even though works single agent case. hand,
search graph obtained imposing regular grid contains nodes, covering locations
traversable space, offers path options avoid collisions units. Hence,
grid maps, besides popular easy implement, suitable multi-agent
problems. clarity practicality, focus grid maps examples experiments.
Nonetheless, conditions algorithmic definitions APP, introduce next
sections, specific regular grid maps. illustrated examples, assume
straight moves four cardinal directions performed (4 connected grid). Restricting
movements 8 directions (cardinal + diagonals) 4 cardinal directions negative impact
completeness. Since standard practice allow diagonal move equivalent (but
longer) two-move path exists, every solution allows diagonal moves, solution
cardinal moves. Therefore, problem diagonal moves reduced problem
straight moves, price possibly taking longer paths. Introducing diagonal moves could
reduce path length, potential drawback blocking units often straight
moves crowded maps. Whether enough clearance make diagonal move depends
two adjacent nodes (i.e., two tiles sharing common corner grid), since
physically impossible squeeze two units.

4. LIDABLE Class Instances
introduce subclass instances Basic APP shown complete.

60

fiM APP : CALABLE ULTI -AGENT PATH P LANNING


i+1

u

(u)
i-1

u lu (denoted 1
Figure 2: example alternate path, , connecting locations li1
i+1
+ 1 picture) belong precomputed path (u) unit u.

Definition 1 (S LIDABLE unit LIDABLE instance). mobile unit u LIDABLE iff path
u
u
(u) = (l0u , l1u , . . . , l|(u)|
) nodes exists, l0u = su , l|(u)|
= tu , following
conditions met:
u , lu , lu (u), except
1. Alternate connectivity. three consecutive locations li1
i+1
last triple ending tu , i.e. 0 < < |(u)| 1, alternate path ui exists
u lu go lu . See Figure 2 example.
li1
i+1


2. Initial blank. initial state, l1u blank (i.e. unoccupied).
3. Target isolation. target interferes -paths units. formally,
following hold tu :
(a) (v U \ {u}) : tu
/ (v);
(b) (v U, {1, . . . , |(v)| 1}) : tu
/ vi .
instance belongs class LIDABLE iff units u U LIDABLE.
three conditions verified polynomial time. verification includes attempting
compute paths unit. Since state space A* explore linear
m, A* search time polynomial m. checks blank location first step,
passing targets, trivial. process checks LIDABLE conditions
serves important additional purpose. time checks succeed instance known
belong LIDABLE, completed search needed solve instance.
remaining part algorithm simply tell units wait, move forward,
move backwards along already computed paths.
Notice three conditions restricted grid maps only. work standard
assumption one graph node occupied one unit time, moving along
edge neither depends interferes parts graph except two nodes ends
edge.
61

fiWANG & B OTEA

Algorithm 1 Overview APP.
1: u U
2:
compute (u) (as needed) su tu
3:
LIDABLE conditions hold
4:
mark u LIDABLE
5: initialize set LIDABLE units {optional: make units active, discussed text}
6: 6=
7:
progression step
8:
repositioning step needed

5. Basic APP
present basic version APP algorithm, complete LIDABLE class
problems. main feature Basic APP (and extensions presented Sections 7 8)
deadlock-free cycle-free, due total ordering active units. Units lower priority
interfere ability higher priority units advance.
illustrated Algorithm 1, problem instance, APP starts computing path (u)
unit u target (goal), constructing caching alternate paths along way. Note
paths alternate paths need satisfy conditions Definition 1. loop
lines 14 succeeds units, APP tell instance hand belongs LIDABLE,
APP complete.
subset units marked LIDABLE, APP guaranteed solve them.
equivalent solving smaller instance LIDABLE. Optionally, APP attempt
solve remaining units well, adding set active units giving lower
priority LIDABLE units. important stress that, remaining part paper,
implicit assumption APP attempts solve provably solvable units, unless
explicitly state opposite. experiments section, however, discuss options.
set LIDABLE units partitioned subset solved units already reached
targets, subset active units. Initially, units active. LIDABLE class,
becoming solved, units interfere rest problem (as ensured target
isolation condition). shown later, Basic APP solved units never become active again,
considered remaining part solving process.
Definition 2. advancing condition active unit u satisfied iff current position, pos(u),
belongs path (u) next location path blank.
Definition 3. state well positioned iff active units advancing condition satisfied.
Lines 68 Algorithm 1 describe series two-step iterations. progression step advances
active units towards targets. shown later, progression step brings least one active
unit target, shrinking active set ensuring algorithm terminates, reaching
state units solved. progression could result breaking advancing condition
one active units, remain. objective repositioning step ensure
active unit advancing condition satisfied starting next progression step. Note
repositioning step necessary every progression step except last.
62

fiM APP : CALABLE ULTI -AGENT PATH P LANNING


b

b





b

b





b


b



b
ii

b
iii

b
iv

v

Figure 3: Example APP works.

5.1 Example
simple example APP works illustrated Figure 3. two units, b.
APP uses total ordering active units progression step (Section 5.3). Here,
higher priority b. targets b drawn stars. Figure 3 (i), b progress
towards targets, becomes blocked b. (ii), blank brought front sliding
b ai (outlined bold); side effect, b pushed path. end current
progression step (iii), reaches target. repositioning step (iv), since already solved,
moves ignored. Repositioning undoes bs moves b back path blank
front it. bs advancing condition restored therefore global state example
well positioned. next progression step (v), b reaches target. algorithm terminates.
5.2 Path Computation
problem instance, compute path (u) individually. paths (u) fixed
throughout solving process. ensure paths satisfy alternate connectivity condition
(Definition 1), modify standard A* algorithm follows. expanding node x0 ,
neighbour x00 added open list alternate path x00 x, parent
x0 . process compute path (u) family alternate paths simultaneously.
give neighbour x00 node x0 chance added open list, node x0 might
expanded three times, per possible parent x. Therefore, O(m) node expansions
required A* search find path, number locations map.
Equivalently, computing path could also seen standard A* search extended space
pairs neighbouring nodes (at four nodes created extended space original
node).
Since alternate paths depend triple locations, unit, re-use information planning paths units problem. means alternate path
set three adjacent tiles map computed per problem instance,
cached later use. Given location l grid map, eight locations could
path two moves away four-connect grid. shown Figure 4a, eight locations
form diamond shape around l. four locations straight line l
63

fiWANG & B OTEA

1
8

1
2

l

7
6

8
3

7

4



2

l

ii

6

3

4

5

5



b

Figure 4: (a) eight locations two moves away l. (b) Two two-move paths l location
2 go ii.

(locations 1, 3, 5, 7), precompute alternate path avoids in-between location
targets. four locations (labeled 2, 4, 6, 8), need compute (at most) two
alternate paths. example, two possible paths l 2 two moves long:
ii (Figure 4b). need one alternate path avoid intermediate location,
ii. summary, precompute 12 paths l. locations map,
need 12m
2 = 6m alternate paths (only one computation triple, since alternate
path connects two endpoints ways).
possible optimization reuse alternate paths across LIDABLE instances map.
Alternate paths overlap targets new instance need re-computed. discuss
option experiments section.
5.3 Progression
Algorithm 2 shows progression step pseudocode. iteration outer loop, active
units attempt progress one move towards targets. processed order (line 2).
unit v processed unit w, say v higher priority write v < w. ordering
fixed inside progression step, may change one progression step another. actual
ordering affects neither correctness completeness method, may impact
speed solution length. ordering units chosen heuristically, e.g. giving higher
priority units closer target. Thus, units could get target quickly,
solved way remaining units problem.
ensure lower priority units harm ability higher priority units progress,
introduce notion private zone. see Algorithm 2 unit cannot cause
moves occupy private zone higher-priority unit.1 Given unit u, let pos(u)
u
current position, let int((u)) = {l1u , . . . , l|(u)|1
} interior precomputed path
(u). shown Algorithm 2, unit u might get pushed precomputed path, case
pos(u)
/ (u).
u , lu } pos(u) = lu int((u)).
Definition 4. private zone, (u), unit u (u) = {li1


Otherwise, (u) = {pos(u)}. words, private zone includes current location

1. move caused unit u either move u along (u) path, move different unit w,
pushed around u side effect blank travel.

64

fiM APP : CALABLE ULTI -AGENT PATH P LANNING

Algorithm 2 Progression step.
1: changes occur
2:
u order
3:
pos(u)
/ (u)
4:
nothing {u pushed track result blank travel}
u current progression step
5:
else u already visited li+1
6:
nothing
u , belongs private zone higher priority unit, i.e.
7:
else next location, li+1
u
v < u : li+1 (v)
u released v}
8:
nothing {wait li+1
u blank
9:
else li+1
u
10:
move u li+1
u
11:
else bring blank li+1
u
12:
bring blank li+1
u
13:
move u li+1
14:
else
15:
nothing

unit. addition, unit pre-computed path start position, location
behind unit belongs private zone well.
Lines 315 Algorithm 2 show processing u, active unit hand. u pushed
precomputed path, action taken (lines 34). Lines 5 6 cover situation
unit u pushed around (via blank travel) higher-priority units back location (u)
already visited current progression step. case, u doesnt attempt travel
previously traversed portion path, ensuring bounds total travelled distance
u
introduced later hold. u path next location li+1
currently blocked higheru available, u
priority unit v, action taken (lines 78). Otherwise, next location li+1
u
moves (lines 910). Finally, li+1 occupied smaller-priority unit, attempt made
u
first bring blank li+1
u move (lines 1113). u moves new
u
u target location u.
location li+1 (lines 10 13), test performed check li+1
case, u marked solved removing adding S, set solved
units.
u
Bringing blank li+1
(lines 11 12) illustrated Figure 1. discuss
process detail. location l ui sought following properties: (1) l blank,
u (inclusive) along u belongs private zone higher(2) none locations l li+1

u
priority unit, (3) l closest (along ui ) li+1
property. location l
u
found, test line 11 succeeds. actual travel blank l li+1
along ui
(line 12) identical movement tiles sliding-tile puzzle. Figure 1 shows example
u
blank traveling. intuition behind seeking blank along ui that, often, li1
u lu test line 11
remains blank time interval u advances li1

performed. guaranteed always hold case active unit highest priority,
call master unit.
Let us introduce characterize behaviour master unit formally. beginning progression step, one master unit u selected. unit highest priority among
65

fiWANG & B OTEA

units active beginning progression step. status master unit
preserved entire progression step, even u becomes solved. beginning
next progression step, new master unit selected among remaining active units.
Lemma 5. master unit u always bring blank front, needs one.
u , belongs private zone, (u), unit
Proof. Since us previous location, li1
u .
move private zone highest priority unit, u guaranteed always find blank li1
u lu belong private zone higher priority
Moreover, location along ui li1
i+1
unit since units higher priority. Note also ui free physical obstacles
u lu .
construction. must possible blank travel li1
i+1

Lemma 6. master unit u never pushed -path.
Proof. u pushed (u) blank travelling performed another unit, contradicts u
highest priority unit.
Theorem 7. long master unit u solved, guaranteed advance along (u)
iteration outer (while) loop Algorithm 2. end current progression
step, least u reached target.
Proof. Using previous two lemmas, easy check u never enters nothing line
Algorithm 2. Similar Lemma 6, u never pushed cannot revisit previous location. Also,
since u highest priority, next location cannot held private zone another unit.
Hence, us progress target guaranteed.
following result useful ensure progression step always terminates, either
state units solved state remaining active units stuck.
Theorem 8. Algorithm 2 generates cycles (i.e., repetitions global state).
Proof. show proof contradiction. Assume cycles. Consider cycle
active unit u cycle highest priority. Since unit cycle dominates u,
means movements u cannot part blank travel triggered higher priority unit.
Therefore, movements u result either line 10 line 13. is, us moves
along path (u). Since (u) contains cycles, u cannot run cycle.
5.4 Repositioning
end progression step, remaining active units (if left)
advancing condition broken. Recall happens unit u either pos(u)
/ (u) u
placed precomputed path next location path blank. repositioning
step ensures well positioned state reached (i.e., active units advancing condition
satisfied) starting next progression step.
simple computationally efficient method perform repositioning undo block
recent moves performed preceding progression step. Undoing move means carrying
reverse move. Solved units affected. remaining active units, undo
moves, reverse global order, well positioned state encountered. call strategy
reverse repositioning. example provided Section 5.1.
66

fiM APP : CALABLE ULTI -AGENT PATH P LANNING

Proposition 9. reverse repositioning strategy used line 7 Algorithm 1 (when needed),
progression steps start well positioned state.
Proof. lemma proven induction iteration number j Algorithm 1. Since
initial state well positioned (this follows easily Definitions 1 3), proof j = 1
trivial. Assume repositioning step performed starting iteration j + 1.
worst case, reverse repositioning undoes moves remaining active units (but
moves units become solved), back original positions beginning j-th
progression step. words, reach state similar state s0 beginning
previous progression step, except units targets s. Since s0 well
positioned (according induction step), follows easily well positioned too.

6. Worst-case Best-case Analysis
give bounds runtime, memory usage, solution length APP algorithm
problem LIDABLE n units map traversable tiles. examine worst case
scenario case, also discuss best-case scenario end.
introduce additional parameter, , measure maximal length alternate paths .
worst case, grows linearly m. However, many practical situations, small constant,
since ends path close other. analysis discusses scenarios.
Theorem 10. Algorithm 1 worst-case running time O(max(n2 m, m2 log m))
constant, O(n2 m2 ) grows linearly m.
Proof. outlined Section 5.2, single-agent A* search consistent heuristic 2 expands
O(m) nodes. Hence, assuming open list implemented priority queue, A* search
takes O(m log m) time. Note that, graphs edges cost, log factor
could principle eliminated using breadth-first search find optimal path. Grid maps
cardinal moves fit category. However, simplicity, assume log
factor present.
Hence, worst case, searches -paths take O(nm log m) time n units.
A* searches take O(m2 log m) time.
single progression step, outlined Algorithm 2, suppose blank travel required n
units, every move along way except first last moves. Since length paths
bounded length alternate paths bounded , total number moves
progression step O(nm), running time Algorithm 2.
Clearly, complexity repositioning step cannot exceed complexity previous
progression step. Hence complexity iteration Algorithm 1 (lines 57) O(nm).
number iterations n, since size reduces least one iteration.
APP takes O(max(nm log m, m2 log m, n2 m)) time run, O(max(n2 m, m2 log m))
constant O(n2 m2 ) grows linearly m.
Theorem 11. maximum memory required execute APP O(nm) constant,
O(nm2 ) grows linearly m.
2. well known Manhattan heuristic, used implementation, consistent. proof
easy, direct result 1) definition consistency 2) way Manhattan distance computed (by
pretending obstacles map).

67

fiWANG & B OTEA

Proof. Caching possible paths entire problem described Section 5.2 takes O(m)
memory. A* searches paths performed one time. search, stored
cache, memory used open closed lists released. A* working memory
takes O(m) space, storing paths takes O(nm) space. Overall, path computation
across units requires O(nm + m) space.
Then, lines 57 Algorithm 1, memory required store stack moves performed
one progression step, used repositioning. shown proof Theorem 10,
number moves progression step within O(nm). So, overall maximum memory
required execute program O(nm), O(nm) constant O(nm2 )
grows linearly m.
Theorem 12. total distance travelled units O(n2 m) constant,
O(n2 m2 ) grows linearly m.
Proof. shown previously, number moves progression step within O(nm).
number moves repositioning step strictly smaller number moves previous
progression step. n progression steps (followed repositioning steps). Hence,
total travelled distance within O(n2 m).
Corollary 13. Storing global solution takes O(n2 m) memory constant, O(n2 m2 )
grows linearly m.
discuss best case scenario. APP computes optimal solutions number moves
paths optimal units reach targets without blank traveling (i.e., units
travel along paths ). obvious example paths disjoint. case,
solutions makespan optimal too. well preserving optimality best case, search
effort APP also smaller spent centralised A* search, n single-agent
m!
O(m) searches, compared searching combined state space n units, (mn)!
states.

7. Extending Completeness Range
extend APPs completeness beyond class LIDABLE, evaluated impact
three LIDABLE conditions preliminary experiment. ran Basic APP data
set also used main experiments (the data set main experiments described
Section 9). preliminary experiment, switched one LIDABLE condition time
counted many units satisfy remaining two conditions. larger increase number
solvable units suggests relaxing definition condition hand could provide
significant increase completeness range.
initial experimental evaluation indicates Basic APP three LIDABLE conditions solves 70.57% units (basic case). alternate connectivity requirement switched off,
87.06% units satisfy remaining two conditions. Switching target isolation makes 85.05%
units satisfy remaining two conditions. However, ignoring blank availability condition
small impact, increasing percentage slightly, 70.57% basic case 70.73%.
results suggest alternate connectivity target isolation conditions restrictive blank availability condition. Thus, focus relaxing two conditions.
68

fiM APP : CALABLE ULTI -AGENT PATH P LANNING

target isolation, extension allows unit plan path targets,
still guarantee clearly identified set units reach targets. topic
Section 7.1. extend alternate connectivity, developed technique allows paths
planned regions alternate paths, tunnels. blank travelling operation
tunnel-crossing unit uses blank positions ahead unit, along remaining
pre-computed path, describe detail Section 7.2. empirical analysis
features provided Section 9.
7.1 Relaxing Target Isolation Condition
several targets close other, target isolation condition, forbidding paths
pass targets, make targets behave virtual wall, disconnecting two areas
map. result, Basic APP report many units non-S LIDABLE.
extension introduce allows unit u plan path target another unit v,
subsequently v never assigned higher priority u. specifically, partial ordering
defined, u v iff target v belongs -path u
path along us
u 2
ui ). Every
-path. Written formally, u v iff tv (u), (u) = ((u) ki=1
time mention refer transitive closure. show section that, paths
planned way (possibly empty) relation creates cycles type u u,
instance solved slight modification Basic APP.
Units plan paths foreign target choice.
achieve strategy, A* searches assign high cost graph search edges adjacent
foreign target. desirable outcome reducing interactions caused target
isolation relaxation. particular, way original LIDABLE units compute paths
preserved, foreign targets crossed cases. words, instances LIDABLE
characterized empty relation.
Definition 14. instance belongs class I-S LIDABLE iff every unit u exists path (u)
satisfying alternate connectivity initial blank condition definition LIDABLE
(Definition 1). Furthermore, cycles allowed relation.
Assume moment (possibly empty) relation without cycles available. Aspects
related obtaining one discussed later section.
Definition 15. solving I-S LIDABLE instances, extended algorithm, APP, two
small modifications original algorithm:
1. total ordering < inside progression step stays consistent : u v u < v.
2. u v, v cannot marked solved (i.e. moved S) unless u already
marked solved.
extra conditions hand, ensure even unit x arrives target tx
units clear tx -paths, units get past x performing normal blank
travel. Following that, x undo moves back tx repositioning step, Basic APP.
prove APP terminates, first prove following two lemmas hold highest
priority unit, u, progression step:
69

fiWANG & B OTEA

Lemma 16. unit visit target u, tu , current progression step.
Proof. Since u master unit, follows u < v active unit v. According
point 1 Definition 15, follows u v. Relation cycles, means v u.
Therefore, applying definition , follows tu
/ (v). completes proof,
APP movements performed along paths.
Since repositioning step undo moves made previous progression step, units
revisit locations visited progression step. So, following direct result
Lemma 16:
Corollary 17. unit visit tu repositioning step follows.
Corollary 18. u solved, cannot interfere rest problem.
Theorem 19. APP terminates.
Proof. Showing least highest priority unit u reaches target given progression step
virtually identical proof Lemma 7. Corollary 18 guarantees that, solving u,
interfere rest problem. Hence, number active units strictly decreases
progression step, algorithm eventually terminates.
Let us get back question provide cycle-free relation. Testing whether
units plan paths way cycle introduced might end expensive.
unit u cant possibly avoid targets, might choose crossing
target v crossing target w. One option might lead cycle whereas might
avoid cycles. Therefore, systematic search might required seek cycle-free relation .
Rather searching systematically, APP takes cheaper, greedy approach.
cycles, mark number units I-S LIDABLE. selected way
units remain cycle-free (we call I-S LIDABLE units). I-S LIDABLE units
guaranteed solved.
result greedy approach, APP complete class I-S LIDABLE. Still,
complete superset LIDABLE able identify many units (often all)
provably solved.
Finally, wrap discussion extension concluding upper bounds
APP, given Section 6, still apply APP. proof identical make
worst-case assumptions before: master unit gets solved progression step,
every move along units path requires blank travel. Moreover, note additional step
path pre-computation topologically sorting partial order, , linear priority order <,
done cheaply time linear number units (Tarjan, 1976).
7.2 Relaxing Alternate Connectivity Condition
show Section 9, previous extension target isolation significantly improves
APPs success ratio (i.e., percentage solvable units). Yet, significant room
improvement. particular, maps single-width tunnels still showed bottleneck terms
success ratio. Tunnels make alternate connectivity condition connecting two ends
consecutive triple locations without going middle harder even impossible
70

fiM APP : CALABLE ULTI -AGENT PATH P LANNING

satisfy. single-width tunnel bridges two otherwise disjoint regions, shown Figure 5,
versions APP presented far fail find path two regions, alternate
connectivity broken triples inside tunnel.

Figure 5: example units targets side, way
cross single-width bridge. Units drawn circles, corresponding targets
squares shade.

section introduce buffer zone extension, solution relaxing alternate
connectivity condition. allows many paths, corresponding many units, cross singlewidth tunnel. intuition simple. Often, plenty blank positions ahead unit, along
remaining locations precomputed -path corresponding paths along it.
tunnel-crossing operation essentially generalisation blank travelling, blank position
sought path ahead, instead alternate path current location triple.
Definition 20. precomputed path (u) crosses tunnels, define following:
buffer zone, ((u)), portion (u) target end
last tunnel (at theSj-th move (u)), together corresponding alternate paths:
((u)) =
{liu } ui .
i{j+2,...,ku 1}

dynamic counter, ((u)), keeps track many positions buffer zone blank.
counter initialized beginning appropriate value, incremented
decremented necessary later on.
threshold ((u)) set length(t) + 2, longest tunnel crossed
unit u. threshold acts minimal value ((u)) guarantees u cross
tunnels safely.

71

fiWANG & B OTEA

unit u attempts cross tunnel, push units lower priorities closest blank
locations buffer zone, u exits tunnel. tunnel-crossing operation
possible, enough blanks available buffer zone. analyse new extended
algorithm detail, introduce extended class AC LIDABLE, whose definition includes
units meeting new buffer zone extension.
Definition 21. relaxing alternate connectivity condition, allow (u) go one
single-width tunnels iff enough blanks us buffer zone, least ((u)) blank
locations ((u)) initial state, i.e., ((u)) ((u)). before, alternate paths still
needed locations outside tunnels.
Definition 22. unit u U belongs extended class, call AC LIDABLE, iff
path (u) meeting initial blank target isolation conditions given definition
LIDABLE (Definition 1), relaxed alternate connectivity condition (Definition 21 above).
AC APP modified Basic APP following two ways integrate buffer
zone technique relaxing alternate connectivity condition. Firstly, repositioning step cannot
finish counter () value threshold (). words, need ensure
enough blanks available buffer zone progression step begins. following
new advancing condition, updated Definition 2 adding extra, aforementioned condition.
Definition 23. advancing condition active, tunnel-crossing unit u satisfied iff current
position belongs path (u) next location path blank (as given Definition 2),
also ((u)) ((u)).
Secondly, need preserve one Basic APPs main features, units lower priority
never block units higher priority, ensuring APP run cycles deadlocks.
Hence, unit u lower priority v cannot cause moves bring ((v))
threshold (i.e., ((v)) ((v)) 1). Recall move caused u either move
u along (u) path (checked lines 7-8 Algorithm 4), move different unit
w, pushed around u side effect blank travel (checked lines 7-11
Algorithm 3). Thus buffer zone u acts generalised private zone, u holds least
((u)) locations accessible units lower priorities.
extensions AC APP maintain following properties Basic APP.
Lemma 24. long master unit u solved, guaranteed advance along (u)
iteration outer (while) loop Algorithm 4. end current progression
step, least u reached target.
Proof. result follows directly proof Lemma 7. parts new
Algorithm 4 compared Algorithm 2 (the progression step Basic APP) check
lines 7-8 modified blank travelling operation (lines 13-15). Since u highest priority
current progression step, cause moves affecting buffer zone every unit,
unit move buffer zone u would bring number blanks
threshold, i.e. ((u)) < ((u)). Hence u guaranteed enough blanks cross
tunnel (u).
proof Lemma 25 similar Lemma 8 Section 5.3.
72

fiM APP : CALABLE ULTI -AGENT PATH P LANNING

u )
Algorithm 3 AC APP canBringBlank( unit u, location li+1
1: u outside tunnels
2:
look nearest blank b along ui
3: else u inside tunnel
4:
look nearest blank b ((u))
5: b found
6:
return false
u } {segment along u ((u)) above}
7: location l {b, . . . , li+1

8:
v < u : l (v) {check causing another unit move private zone
higher priority unit, v}
9:
return false
10:
else v < u : l ((v)) & ((v)) ((v)) {check causing another unit
move buffer zone higher priority unit, v}
11:
return false
12: return true

Algorithm 4 AC APP Progression step.
1: changes occur
2:
u order
3:
pos(u)
/ (u)
4:
nothing
u
5:
else v < u : li+1
(v)
6:
nothing
u
7:
else v < u : li+1
((v)) & ((v)) ((v)) {check moving
buffer zone higher priority unit}
8:
nothing {wait v blanks buffer zone}
u current progression step
9:
else u already visited li+1
10:
nothing
u blank
11:
else li+1
u
12:
move u li+1
u ) {Algorithm 3}
13:
else canBringBlank( u, li+1
u
14:
bring blank li+1
u
15:
move u li+1
16:
else
17:
nothing

Lemma 25. Algorithm 4 generates cycles (i.e., repetitions global state).
Theorem 26. AC APP terminates.
Proof. follows Lemmas 24 25 number active units strictly decreases
successive iterations Algorithm 4. Hence, algorithm AC APP eventually terminates.
Since shown algorithm AC APP guaranteed solve class AC LID completeness result shown follows directly.

ABLE ,

73

fiWANG & B OTEA

Corollary 27. AC APP complete class AC LIDABLE.
AC APP extension preserves upper bounds running time, memory usage, solution length given Section 6. Here, introduce max denote maximal length tunnels
units cross. worst case analysis, units initiate blank travelling every move along
way, involves tunnels. So, depending whether max , maximal length
paths, longer, AC APP runs O(n2 mmax ) O(n2 m) time. Since parameters
often constant practice, grow worst linear m, running time O(n2 m) O(n2 m2 ),
before. bounds total travel distance global solution follow directly. Lastly,
virtually additional memory required storing buffer zones, except one counter one
threshold variable, per unit.
7.3 Combining Target Isolation Alternate Connectivity Relaxations
show two extensions LIDABLE class combined.
Definition 28. instance belongs extended class, I+AC LIDABLE, iff every unit u
exists path (u) meeting initial blank condition given Definition 1, relaxed
alternate connectivity condition Definition 22. Furthermore, (possibly empty) relation
introduced result target isolation relaxation cycle-free, Definition 14.
obtain extended algorithm, I+AC APP, combining APP (Definition 15)
AC APP (Algorithms 3 4).
Theorem 29. I+AC APP terminates.
Proof. proof Lemma 24, show least highest priority unit u reaches
target progression step, follows. Definition 21, u guaranteed enough blanks
clear single-width tunnels along path. Definitions 14 15 guarantee that,
outside tunnels, u always bring blank needed, stated Lemma 5. Furthermore,
progression step generates cycles. proved cases Lemmas 25 8.
also know solved unit u interfere rest problem,
results Lemmas 16 18, Corollary 17. Note tricky cases units
targets inside single-width tunnels excluded extended class I+AC LIDABLE,
zero buffer capacity according defined Definition 20.
Since iteration algorithm solves least one unit, I+AC APP terminates.

8. Improving Solution Length
mentioned before, avoid replanning, units pushed off-track blank travelling units
undo moves get back -paths immediate repositioning step.
observed that, practice, reverse repositioning strategy (defined Section 5.4) introduce
many unnecessary moves, increase solution length, increase running time, may
hurt visual quality solutions.
Recall that, standard reverse repositioning step, new moves added solution
built. moves undo, reverse order, moves active units (i.e., solved
yet) made previous progression step. process continues well positioned state
74

fiM APP : CALABLE ULTI -AGENT PATH P LANNING

u

(v)

u

(v)

v

v

(u)

(u)

Figure 6: Two examples global checking well positioned state.

reached, means active units advancing condition satisfied (i.e., every
active unit -path blank front).
undo move, well-positioned check performed globally. words, Basic
APP checks advancing condition active units, unit affected
recent undo move. global checking guarantees eventually reach well-positioned state,
proved Proposition 9, but, mentioned earlier, often create many unnecessary moves.
provide two simple examples Figure 6, illustrate one case global checking
useful, one case global checking strong condition, adding unnecessary moves.
First, consider two units, u v, undoing one move global moves stack places u
back path, blank front. Assume us current position way vs
future undo moves, shown left Figure 6. Therefore, even us advancing condition
satisfied, u needs additional undo moves, make room undo moves units, v,
order reach globally well positioned state. case, global checking useful. second
example, imagine u vs moves recent progression step independent
other, possibly even two map areas far away other. simple case shown
right Figure 6. recent progression, vs last move (when v derailed) followed
sequence us moves. final move u pushed track, whereas preceding
moves along us -path, (u). Reverse repositioning would undo moves reverse global
order, means undoing us moves undoing vs last move. However, one undo
move u one undo move v sufficient restore units well positioned state.
illustrated, global checking advancing condition could strong, whereas
local checking could insufficient. solution introduce section,
called repositioning counting, finds middle ground two extremes, improves
number moves still maintains guarantee reaching well-positioned state. Intuitively,
undo moves unit u stop soon (a) us advancing condition satisfied, (b)
current position cannot possibly interfere future undo moves units, (c) unit
performing repositioning possibly stop blank position front u us -path,
75

fiWANG & B OTEA

(d) u doesnt stop initial second location another active unit v. initial second
location unit v position ahead v beginning recent progression step.
fourth condition ensures units blank front end, worst case
revert back initial position beginning recent progression step.3
Definition 30. location l path, keep counter, c(l), that:
beginning progression step, counter c(l) reset 0, l empty, 1,
l occupied.
Every time l visited progression step, c(l) incremented.
Every time unit leaves l result undo move repositioning step, c(l)
decremented.
Following directly definition c(l) given above, formulate following two
results c(l) repositioning time:
Lemma 31. c(l) = 0, unit pass l remaining part current
repositioning step.
Lemma 32. given active unit u, current position pos(u), c(pos(u)) = 1,
progression moves location pos(u) already undone. words,
unit remainder repositioning step pass pos(u).
introduce new enhancement APP, aimed eliminating many useless undo
moves repositioning steps.
Definition 33. enhanced algorithm, R C APP, uses repositioning counting strategy
line 7 Algorithm 1. means active unit u stops undoing moves current
repositioning step, soon meets following conditions:
(a) advancing condition u satisfied according Definition 2, plus extension Definition 23.
(b) us current location, pos(u), c(pos(u)) = 1
u , c(lu ) = 0
(c) location front u, li+1
i+1

(d) current location initial second location another active unit.
Theorem 34. repositioning steps R C APP end well-positioned state.
3. Condition d) ignored without invalidating algorithms ability make progress towards goal state. Even
units could possibly end state without blank front, guaranteed least one unit (i.e.,
one finishes repositioning first) blank front. guarantees least one unit
solved next progression step.

76

fiM APP : CALABLE ULTI -AGENT PATH P LANNING

Proof. Recall moves made progression step kept totally ordered list.
prove directly repositioning counting, undoing subset moves, reaches wellpositioned state. Since counter c(l) incremented decremented according Definition 30,
unit u satisfying three conditions Definition 33 restored advancing condition.
Furthermore, combined results Lemmas 31 32 guarantee units later
get us way, u way units repositioning moves.

Theorem 34, applying R C repositioning steps extended algorithm I+AC APP
negative impact completeness.

9. Experimental Results
section present empirical evaluation APP algorithm. first point
impact newly added feature. put I+AC+R C enhanced APP test
comparison existing state-of-the-art decoupled, incomplete methods. Specifically,
benchmarks FAR (Wang & Botea, 2008), extended version Silvers (2005) W HCA *
algorithm Sturtevant Buro (2006), called W HCA *(w,a), applies abstraction
expensive initial backward A* searches. APP, algorithms tested rather
large problems, terms map size number units. aware programs
scale well FAR W HCA *. strengths two methods potential ability
find solution quickly, weakness cannot tell whether would able
solve given instance.
implemented APP scratch integrated Hierarchical Open Graph4 (HOG)
framework. source code extended W HCA * algorithm, W HCA *(w, a) (Sturtevant &
Buro, 2006), extra features spatial abstraction diagonal moves (but without priority
system unit replanning), obtained Nathan Sturtevant. FAR algorithm
implementation used previous experiments (Wang & Botea, 2008).
Experiments run data set randomly generated instances used previously published work (Wang & Botea, 2008). input grid maps5 10 largest game Baldurs Gate6 , range 13765 51586 traversable tiles size, listed Table 1.
game maps quite challenging, containing different configurations obstacles forming different
shapes rooms, corridors, narrow tunnels. test map 100 2000 mobile units
increments 100. 10-minute timeout per instance set. W HCA *(w, a) experiments,
set window size, w, 8, use first level abstraction (a = 1). seems
good parameter setting work Sturtevant Buro (2006), experiments comparing
W HCA *(20,1) show W HCA *(8,1) work better data set. Abstraction allows W HCA *
build heuristic graph smaller actual graph movement takes
place. FAR, units make reservations k = 2 steps ahead, recommended setting.
experiments run 2.8 GHz Intel Core 2 Duo iMac 2GB RAM.
77

fiWANG & B OTEA

Basic MAPP

Number SLIDABLE

2000

700
414
400
500
300
204
602
411
603
307

1500
1000
500
0
0

500
1000
1500
Total number agents

2000

TI MAPP
414
400
204
500
411
300
700
602
603
307

1500
1000
500
0

AC MAPP
2000

0

Number AC-SLIDABLE

Number TI-SLIDABLE

2000

500
1000
1500
Total number agents

2000

700
500
300
400
414
204
602
411
603
307

1500
1000
500
0
0

500
1000
1500
Total number agents

2000

TI + AC MAPP
Number TI+AC-SLIDABLE

2000

700
300
500
414
400
602
204
603
411
307

1500
1000
500
0
0

500
1000
1500
Total number agents

2000

Figure 7: MAPPs widened completeness range relaxation: graph line represents
number units solved problem instances map. Here, provably solvable
units counted.

78

fiM APP : CALABLE ULTI -AGENT PATH P LANNING

FAR

Number agents solved

2000

414
204
400
411
700
500
300
602
603
307

1500

1000

500

0

0

500
1000
1500
Total number agents

2000

WHCA* diagonals

Number agents solved

2000

400
204
414
411
700
500
300
603
602
307

1500
1000
500
0
0

500
1000
1500
Total number agents

2000

WHCA* diagonals

Number agents solved

2000

204
414
400
411
700
500
300
603
602
307

1500
1000
500
0
0

500
1000
1500
Total number agents

2000

Figure 8: success ratios (averaged 10 trials) FAR, W HCA *(8,1), without
diagonals, set problem instances. timeout set 10 minutes per
instance 3 incomplete algorithms.
79

fiWANG & B OTEA

Map ID
AR0700SR
AR0500SR
AR0300SR
AR0400SR
AR0602SR
AR0414SR
AR0204SR
AR0307SR
AR0411SR
AR0603SR

Short ID
700
500
300
400
602
414
204
307
411
603

# nodes
51586
29160
26950
24945
23314
22841
15899
14901
14098
13765

Table 1: 10 maps descending order, terms number nodes.

9.1 Scalability Percentage Solved Units
compare FAR, W HCA *(8,1) four versions APP: Basic APP original LID ABLE definitions; APP , version target isolation relaxation switched on; AC
APP, based relaxing alternate connectivity condition; +AC APP, relaxing
target isolation condition, alternate connectivity condition. measure success ratio,
defined percentage solved units. Note repositioning counting (R C)
considered section, since impact success ratio, designed
improve solution length.
APP versions used section attempt solve units provably solvable
(i.e., units marked LIDABLE, LIDABLE, AC LIDABLE, I+AC LIDABLE respectively).
reason want evaluate many units fall subclasses practice.
next section show data obtained version APP attempts solve units.
Figure 7 summarizes success ratio data version APP algorithm
maps. closer curve top diagonal line (being total number units), better
success ratio map. Basic APP exhibits mixed behaviour, greater success ratio
six maps. four challenging maps (602, 411, 603, 307), success ratio gets often
50% number mobile units increases. maps common feature containing
long narrow corridors even single-width tunnels, connecting wider, open regions
map. Thus surprising that, mentioned Section 7, alternate path target isolation
conditions identified greatest causes failing find LIDABLE path.
Relaxing target isolation condition (T APP) significantly improves success ratio
maps. good success ratio (93% higher) achieved 7 maps across entire
range number mobile units. 3 maps contain high proportion narrow
corridors, also single-width tunnels.
Relaxing alternate connectivity well (T +AC APP) yields excellent success ratio
unit numbers maps. example, scenarios 2000 units,
4. http://webdocs.cs.ualberta.ca/nathanst/hog.html
5. experimental maps viewed online, at: http://users.cecs.anu.edu.au/cwang/gamemaps
6. http://www.bioware.com/games/baldurs_gate/

80

fiM APP : CALABLE ULTI -AGENT PATH P LANNING

challenging according Figures 7 8, smallest success ratio 92% (map 307) largest
one 99.7%. scenarios fewer mobile units, I+AC APP even better success ratios.
Next compare success ratio I+AC APP (bottom plot Figure 7) FAR
(top plot Figure 8) W HCA *(8,1) (middle bottom Figure 8, without diagonals,
respectively). Extended APP clear winner terms scalability. FAR W HCA * suffer
number units increased. incomplete algorithms often time even scenarios
significantly fewer units 2000. 2000 units, FAR solves 17.5% units,
W HCA * solves 16.7% (no diagonal moves) 12.3% (with diagonal moves)
units. entire data set, I+AC APP solved 98.82% units, FAR solved
81.87% units, 77.84% 80.87% solved W HCA * without diagonal moves
allowed, respectively.
9.2 Scalability Attempting Solve Units
previous section, compare FAR, W HCA * APP. I+AC APP version
used attempts solve units, provably solvable ones (attempt-all feature).
mentioned earlier, achieved marking units active beginning. Active units
partitioned three categories: i) provably solvable units reach target; ii)
units reached target; iii) units reached target location,
still active units still cross location. total ordering <
active units must respect conditions units category i) higher priority units
category ii), higher priority units category iii).
attempt-all feature turned on, I+AC APPs percentage solved units increases
98.82% (Section 9.1) 99.86%.
Next focus number solved instances. instance considered solved iff
units solved. APP successful 84.5% instances. significantly better FAR
(70.6%), W HCA * diagonal moves (58.3%), W HCA * diagonals (71.25%).
attempt-all feature massive impact percentage fully solved instances, improving 34% 84.5%. might seem counter-intuitive attempt-all feature
small impact percentage solved units great impact percentage solved instances. explanation following. APP fails instance,
small percentage units remain unsolved. Often, one two
unsolved units failed instance. Managing solve remaining units well
attempt-all feature result whole instance changing label failed solved, even
though change overall percentage solved units small.
remaining sections use attempt-all feature well. reason increases
number solved instances therefore obtain larger set data analyse.
9.3 Total Travel Distance
Factors may impact length plans lengths initial paths, extra movements caused blank travel repositioning. experiments, length precomputed
paths virtually negative impact travel distance. Even APPs paths
satisfy additional constraints, avoiding targets possible, similar
length normal unconstrained shortest paths, 1.4% longer average.
81

fiWANG & B OTEA

RC-Improved Travel Distance (Map 400)
800000

MAPP total
RC MAPP total
MAPP Pre-Computed Pi
MAPP undos
RC MAPP undos

Distance (moves)

700000
600000
500000
400000
300000
200000
100000
0
0

2

4

6 8 10 12 14 16 18 20
Number agents (100s)

Figure 9: typical case improved distances R C APP normal APP. Note precomputed -paths affected R C enhancement.

section, first evaluate improvement repositioning counting (R C)
standard reverse repositioning. compare total distance travelled R C APP
FAR W HCA *.
9.3.1 R EDUCING U NDO OVES
identified excessive undoing moves repositioning bottleneck Basic APP. Figure 9 shows benefits repositioning counting (R C), enhancement described Section 8. figure compares total travelled distance, well number undo moves,
R C+T I+AC APP (shown R C APP short) I+AC APP (M APP short) average case. shown, repositioning counting turns quite effective, eliminating many
unnecessary undo moves (that help reach globally restored state). Averaged
entire data set, R C APP 59.7% shorter undo distance APP standard reverse
repositioning, results reducing total travelled distance 30.4% average.
9.3.2 C OMPARING OTAL ISTANCE FAR W HCA *(8,1)
evaluate solution length attempt-all R C+T I+AC APP compared FAR
W HCA *(8,1). plot total travel distance averaged subset input instances
algorithms considered fully solve.
Figures 10 11 show average results maps. APP, show length
precomputed paths, number undo (repositioning) moves, total travelled distance.
According performance criterion, set maps roughly partitioned three subsets.
good case, map 307, APP performs better W HCA *(8,1) without diagonals
terms total travel distance, even comparable FAR. average case, APPs travel
82

fiM APP : CALABLE ULTI -AGENT PATH P LANNING

Total Travel Distance: Good Case (307)
90000

WHCA*(8,1) noD
FAR
MAPP Total
WHCA*(8,1)
MAPP Pi
MAPP Undos

70000
60000
50000

250000
Distance

80000

Distance

Total Distance Travelled: Average Case (411)
300000

40000
30000

200000

WHCA* noD
MAPP Total
FAR
WHCA*(8,1)
MAPP Pi
MAPP Undos

150000
100000

20000

50000

10000
0
100

200

300

400 500 600
Number agents

700

800

0
900

200

Total Distance Travelled (603)
160000

Distance

140000
120000
100000

WHCA* noD
MAPP Total
WHCA*
FAR
MAPP Pi
MAPP Undos

250000

80000
60000

200000

MAPP Total
WHCA* noD
FAR
MAPP Pi
WHCA*
MAPP Undos

150000
100000

40000

50000

20000
0
100

600 800 1000 1200 1400 1600
Number agents

Total Distance Travelled (602)
300000

Distance

180000

400

200

300

400 500 600 700
Number agents

800

0
900

200

400

600
800
1000
Number agents

1200

Figure 10: Distance travelled plotted averaged instances fully solved algorithms.

distance roughly comparable W HCA * without diagonals. Maps 603, 411, 602 belong
category. Finally, harder case, APPs total distance increases faster rate
others, direct result increasingly larger number undo moves. harder cases
include maps 204, 414, 700, 400, 300, 500. Upon inspection, cases typically involve
high number turns corners. APPs case, results high degree path overlapping,
units keep close edge rounding corner, obtain shorter -paths.
summarise overall results, APPs travel distance ranges 18.5% shorter W HCA *
without diagonal moves, 132% longer, 7% longer average. Compared
version W HCA * diagonal moves enabled, APPs total distance 31% longer average,
varying 5.8% shorter 154% longer. Compared FAR, APPs solutions range
4.8% shorter 153% longer, 20% longer average.
closer look results reveals that, even repositioning counting use, APP
still make unnecessary undo moves. useless undo move counts double final solution
length, since undo matched new forward move next progression step.
Improving solution length promising direction future work.
9.4 Running Time Analysis
case travel distance analysis, meaningful runtime comparison, also restrict
analysis subset instances completed algorithms (FAR, W HCA * versions,
83

fiWANG & B OTEA

Total Travel Distance: Harder Case (700)
300000

Distance

250000
200000

MAPP Total
WHCA*(8,1) noD
FAR
MAPP Pi
WHCA*
MAPP Undos

150000

Total Distance Travelled (300)
400000
350000
300000
Distance

350000

250000
200000
150000

100000

100000

50000

50000

0
200

400

0
600 800 1000 1200 1400
Number agents

MAPP Total
WHCA* noD
FAR
MAPP Pi
WHCA*
MAPP Undos

200

MAPP Total
WHCA* noD
FAR
MAPP Pi
WHCA*
MAPP Undos

250000
200000

MAPP Total
WHCA*(8,1) noD
FAR
MAPP Pi
WHCA*(8,1)
MAPP Undos

150000
100000
50000
0

200 400 600 800 1000 1200 1400 1600 1800 2000
Number agents

200 400 600 800 1000 1200 1400 1600 1800 2000
Number agents

Total Distance Travelled (414)
300000

Distance

250000
200000

MAPP Total
WHCA* noD
FAR
MAPP Pi
WHCA*
MAPP Undos

150000

Total Distance Travelled (500)
300000
250000
Distance

350000

200000

MAPP Total
WHCA* noD
FAR
MAPP Pi
WHCA*
MAPP Undos

150000
100000

100000

50000

50000
0

600 800 1000 1200 1400
Number agents

Total Travel Distance (204)
300000

Distance

Distance

Total Distance Travelled (400)
500000
450000
400000
350000
300000
250000
200000
150000
100000
50000
0

400

0
200 400 600 800 1000 1200 1400 1600 1800 2000
Number agents

200

400

600 800 1000 1200 1400
Number agents

Figure 11: Distance travelled continued: remaining six maps.

I+AC+R C APP attempt-all feature turned on). show overall summary data,
Tables 2 3, charts 10 maps, Figures 12 13.
implementation APP builds scratch required paths, including -paths.
However, -paths re-used instances map. -paths
contain target current instance might recomputed. small percentage
-paths, since number targets typically much smaller map size.
evidence strongly supports taking -path computations offline map pre-processing step
improve APPs running time. Hence, distinguish case APP performs
computations scratch, case alternate paths (i.e., paths) already
available (e.g., previous instances map hand, result preprocessing). Note
84

fiM APP : CALABLE ULTI -AGENT PATH P LANNING

Time ratio:
Average
Min
Max

vs FAR
10.14
2.90
60.46

vs W HCA *
0.96
0.08
4.57

vs W HCA *+d
0.93
0.11
4.92

Table 2: APPs runtime divided runtime FAR, W HCA *, W HCA *+d. table,
assume APP performs computations, including alternate-path search,
scratch.

Time ratio:
Average
Min
Max

vs FAR
2.18
0.56
7.00

vs W HCA *
0.21
0.01
0.99

vs W HCA *+d
0.19
0.01
0.70

Table 3: APPs runtime divided runtime FAR, W HCA *, W HCA *+d. table,
time compute alternate paths omitted, could re-used instances
map.

FAR W HCA *, computation depends every units start target locations,
therefore cannot easily taken map pre-processing step (since storing entire search trees
take much memory practical).
Table 2 shows that, APP performs computations scratch, comparable
speed W HCA *, actually slightly faster average. However, version APP
10 times slower FAR average. paths already available, APPs speed
improves significantly, -path computation expensive part APP. seen
Table 3, APPs speed ratio vs FAR reduces 2.18. APP also becomes 4.85.2 times faster
W HCA *(with without diagonals) average.
Figure 12 shows detailed runtime data 8 10 maps. Even computation scratch, APP faster W HCA *+d (i.e., diagonal moves enabled). also
often faster, least comparable, W HCA * without diagonals. APP offline preprocessing reasonably close FAR, even though FAR consistently faster least comparable
APP. remaining two maps, represent difficult cases APP, presented
Figure 13. map 700 especially, largest data set, also significantly larger
rest (almost 24 times larger), APP significantly higher total time, shown top
right Figure 13.
break APPs total running time (shown bottom Figure 13 map 700)
consistently shows search time dominates. Furthermore, node expansions, node
expansions generally several times greater node expansions, resulting majority
path computation time spent searching -paths.
85

fiWANG & B OTEA

Total Running Times (411)
400

WHCA*(8,1) noD
WHCA*(8,1)
MAPP total
MAPP preprocessing
FAR

300
250

120
100
Time (s)

350

Time (s)

Total Running Times (307)
140

200
150

80
60
40

100

20

50
0

WHCA*(8,1) noD
WHCA*(8,1)
MAPP total
MAPP preprocessing
FAR

200

400

0
100

600 800 1000 1200 1400 1600
Number agents

200

400

900

300

100
700

800

0
900

200 400 600 800 1000 1200 1400 1600 1800 2000
Number agents
Total Running Times (602)
400

WHCA*(8,1) noD
WHCA*(8,1)
MAPP total
MAPP preprocessing
FAR

350
300
Time (s)

Time (s)

400

800

200

WHCA*(8,1)
WHCA*(8,1) noD
MAPP total
MAPP preprocessing
FAR

500

700

WHCA*(8,1)
MAPP total
WHCA*(8,1) noD
MAPP preprocessing
FAR

500

Total Running Times (414)
600

400 500 600
Number agents

Total Running Times (204)
600

Time (s)

Time (s)

Total Running Times (603)
500
WHCA*(8,1) noD
450
WHCA*(8,1)
MAPP total
400
350 MAPP preprocessing
FAR
300
250
200
150
100
50
0
100 200 300 400 500 600
Number agents

300

300
200

250
200
150
100

100
0

50
0
200 400 600 800 1000 1200 1400 1600 1800 2000
Number agents
Total Running Times (300)

300

400
350
300
Time (s)

Time (s)

200
150
100

600
800
Number agents

1000

1200

MAPP total
WHCA*(8,1) noD
WHCA*(8,1)
MAPP preprocessing
FAR

250
200
150
100

50
0

400

Total Running Times (400)
450

WHCA*(8,1) noD
WHCA*(8,1)
MAPP total
MAPP preprocessing
FAR

250

200

50
200

400

600
800 1000
Number agents

1200

0
1400

200 400 600 800 1000 1200 1400 1600 1800 2000
Number agents

Figure 12: Runtime data averaged fully completed instances algorithms. Map IDs
displayed shorthand brackets. APP preprocessing stands version
computes alternate paths.

86

fiM APP : CALABLE ULTI -AGENT PATH P LANNING

Total Running Times (500)
140

Time (s)

120
100

Total Running Times: Worst Case (700)
350

WHCA*(8,1)
MAPP total
WHCA*(8,1) noD
MAPP preprocessing
FAR

MAPP total
WHCA*(8,1)
WHCA*(8,1) noD
250 MAPP preprocessing
FAR
200
300

Time (s)

160

80
60

150

40

100

20

50

0
200

400

600
800 1000
Number agents

1200

0
1400

200

400

600
800 1000
Number agents

1200

1400

MAPP Times Breakdown (700)
350

Total Runtime
Total Search
Omega Search
Repositioning

300

Time (s)

250
200
150
100
50
0
200

400

600
800 1000
Number agents

1200

1400

Figure 13: Top: hard cases I+AC+R C APPs total runtime. Bottom: time breakdown, showing -path computation takes majority APPs search time.

10. Conclusion
Traditional multi-agent path planning methods trade optimality, completeness, scalability. centralised method typically preserves optimality (theoretical) completeness,
decentralised method achieve significantly greater scalability efficiency. hand,
approaches shortcomings. former faces exponentially growing state space
number units. latter gives optimality offers guarantees respect completeness, running time solution length. new approach, aimed bridging missing links,
identifies classes multi-agent path planning problems solved polynomial time.
also introduced algorithm, APP, solve problems classes, low polynomial upper
bounds time, space solution length.
performed detailed empirical evaluation APP. extended APPs completeness
range reaches 92%99.7%, even challenging scenarios 2000 mobile units.
completeness range even better scenarios fewer units. data set, APP significantly better percentage solved units (98.82% provably solvable, 99.86% attempt-all
mode) FAR (81.87%) W HCA * (77.84% 80.87%, without diagonal moves).
attempt-all version APP solves 1326% instances benchmark algorithms.
87

fiWANG & B OTEA

instances solved algorithms, APP significantly faster variants W HCA *,
slower fast FAR algorithm factor 2.18 average, alternate
paths needed instance readily available. performing computations scratch,
APPs speed comparable W HCA *. APPs solutions reported average 20% longer
FARs solutions 731% longer W HCA *s solutions. However, unlike algorithms
FAR W HCA *, APP offer partial completeness guarantees low-polynomial bounds
runtime, memory solution length. Thus, APP combines strengths two traditional
approaches, providing formal completeness upper-bound guarantees, well scalable
efficient practice.
findings presented open avenues future research large-scale multi-agent
pathfinding. long term, APP part algorithm portfolio, since cheaply
detect guaranteed solve instance. Thus worthwhile investigate tractable
classes, subclasses FAR complete. APP improved run faster,
compute better solutions, cover instances. Solution quality measured
total travel distance, also terms makespan (i.e., total duration actions run
parallel) total number actions (including move wait actions). far, worked
relaxing two original LIDABLE conditions: target isolation alternate connectivity. Future
work could address initial blank condition. Moreover, initially non-S LIDABLE units
problem could become LIDABLE later on, LIDABLE units getting solved.
Extending APP instances units heterogeneous size speed another promising
direction.

Acknowledgments
NICTA funded Australian Governments Department Communications, Information
Technology, Arts Australian Research Council Backing Australias Ability
ICT Research Centre Excellence programs.
Many thanks Nathan Sturtevant providing HOG framework, help
understanding program. Thanks also Philip Kilby, Jussi Rintanen, Nick Hay
many helpful comments. thank anonymous reviewers valuable feedback.

References
Barraquand, J., Langlois, B., & Latombe, J.-C. (1991). Numerical potential field techniques
robot path planning. International Conference Advanced Robotics (ICAR), Vol. 2, pp.
10121017.
Bulitko, V., Sturtevant, N., Lu, J., & Yau, T. (2007). Graph Abstraction Real-time Heuristic
Search. Journal Artificial Intelligence Research (JAIR), 30, 51100.
Choset, H., Lynch, K., Hutchinson, S., Kantor, G., Burgard, W., Kavaraki, L., & Thrun, S. (2005).
Principles Robot Motion: Theory, Algorithms, Implementation. MIT Press.
Erdmann, M., & Lozano-Perez, T. (1986). Multiple Moving Objects. IEEE International
Conference Robotics Automation (ICRA), pp. 14191424.
Geramifard, A., Chubak, P., & Bulitko, V. (2006). Biased Cost Pathfinding. Artificial Intelligence
Interactive Digital Entertainment conference (AIIDE), pp. 112114.
88

fiM APP : CALABLE ULTI -AGENT PATH P LANNING

Hart, P., Nilsson, N., & Raphael, B. (1968). Formal Basis Heuristic Determination
Minimum Cost Paths. IEEE Transactions Systems Science Cybernetics, 4(2), 100
107.
Hopcroft, J. E., Schwartz, J. T., & Sharir, M. (1984). complexity motion planning
multiple independent objects: PSPACE-hardness warehousemans problem. International Journal Robotics Research (IJRR), 3(4), 7688.
Jansen, R., & Sturtevant, N. (2008). New Approach Cooperative Pathfinding. International
Conference Autonomous Agents Multiagent Systems (AAMAS), pp. 14011404.
Kant, K., & Zucker, S. W. (1986). Toward Efficient Trajectory Planning: Path-Velocity Decomposition. International Journal Robotics Research (IJRR), 5(3), 7289.
Kornhauser, D., Miller, G., & Spirakis, P. (1984). Coordinating pebble motion graphs, diameter permutation groups, applications. Proceedings 25th Annual Symposium
Foundations Computer Science (FOCS), pp. 241250.
Latombe, J.-C. (1991). Robot Motion Planning. Kluwer Academic Publishers.
Papadimitriou, C., Raghavan, P., Sudan, M., & Tamaki, H. (1994). Motion planning graph.
35th Annual Symposium Foundations Computer Science, pp. 511520.
Pottinger, D. (1999). Coordinated Unit Movement. http://www.gamasutra.com/view/
feature/3313/coordinated_unit_movement.php.
Rabin, S. (2000). A* Speed Optimizations. Deloura, M. (Ed.), Game Programming Gems, pp.
272287. Charles River Media.
Ratner, D., & Warmuth, M. (1986). Finding shortest solution N N extension 15puzzle intractable. Proceedings AAAI National Conference Artificial Intelligence
(AAAI-86), pp. 168172.
Ryan, M. R. K. (2008). Exploiting Subgraph Structure Multi-Robot Path Planning. Journal
Artificial Intelligence Research (JAIR), 31, 497542.
Samet, H. (1988). Overview Quadtrees, Octrees, Related Hierarchical Data Structures.
NATO ASI Series, Vol. F40.
Silver, D. (2005). Cooperative Pathfinding. Artificial Intelligence Interactive Digital Entertainment conference (AIIDE), pp. 117122.
Silver, D. (2006). Cooperative pathfinding. AI Programming Wisdom, 3, 99111.
Standley, T. (2010). Finding Optimal Solutions Cooperative Pathfinding Problems. Proceedings Twenty-Fourth AAAI Conference Artificial Intelligence (AAAI-10), pp. 173178.
Stout, B. (1996). Smart Moves: Intelligent Pathfinding. Game Developer Magazine.
Sturtevant, N. R., & Buro, M. (2006). Improving collaborative pathfinding using map abstraction..
Artificial Intelligence Interactive Digital Entertainment (AIIDE), pp. 8085.
Surynek, P. (2009a). Application Pebble Motion Graphs Abstract Multi-robot Path Planning. Proceedings 21st International Conference Tools Artificial Intelligence
(ICTAI), pp. 151158.
Surynek, P. (2009b). novel approach path planning multiple robots bi-connected graphs.
IEEE International Conference Robotics Automation (ICRA), pp. 36133619.
89

fiWANG & B OTEA

Surynek, P. (2010a) personal communication.
Surynek, P. (2010b). Optimization Variant Multi-Robot Path Planning Intractable.
Proceedings 24th AAAI Conference Artificial Intelligence (AAAI-10), pp. 1261
1263.
Surynek, P. (2010c). Multi-robot Path Planning, pp. 267290. InTech - Open Access Publisher.
Tarjan, R. E. (1976). Edge-disjoint spanning trees depth-first search. Acta Informatica, 6(2),
171185.
Tozour, P. (2002). Building Near-Optimal Navigation Mesh. Rabin, S. (Ed.), AI Game Programming Wisdom, pp. 171185. Charles River Media.
Wang, K.-H. C., & Botea, A. (2008). Fast Memory-Efficient Multi-Agent Pathfinding. Proceedings International Conference Automated Planning Scheduling (ICAPS),
pp. 380387.
Wang, K.-H. C., & Botea, A. (2009). Tractable Multi-Agent Path Planning Grid Maps. Proceedings International Joint Conference Artificial Intelligence (IJCAI), pp. 1870
1875.
Wang, K.-H. C., & Botea, A. (2010). Scalable Multi-Agent Pathfinding Grid Maps
Tractability Completeness Guarantees. Proceedings European Conference
Artificial Intelligence (ECAI), pp. 977978.
Zelinsky, A. (1992). mobile robot navigation exploration algorithm. IEEE Transactions
Robotics Automation, 8(6), 707717.

90

fiJournal Artificial Intelligence Research 42 (2011) 917-943

Submitted 03/11; published 12/11

Interpolable Formulas Equilibrium Logic
Answer Set Programming
Dov Gabbay

dov.gabbay@kcl.ac.uk

Bar Ilan University Israel, Kings College London
University Luxembourg.

David Pearce

david.pearce@upm.es

AI Dept, Universidad Politecnica de Madrid, Spain.

Agustn Valverde

valverde@ctima.uma.es

Dept Applied Mathematics, Universidad de Malaga, Spain.

Abstract
Interpolation important property classical many non-classical logics
shown interesting applications computer science AI. study
Interpolation Property non-monotonic system equilibrium logic, establishing weaker stronger forms interpolation depending precise interpretation
inference relation. results also yield form interpolation ground logic
programs answer sets semantics. disjunctive logic programs also study
property uniform interpolation closely related concept variable forgetting. first-order version equilibrium logic analogous Interpolation properties
whenever collection equilibrium models (first-order) definable. Since
case so-called safe programs theories, applies usual situations arise
practical answer set programming.

1. Introduction
interpolation property important much discussed topic logical systems,
classical non-classical (Gabbay & Maksimova, 2005). importance computer
science also becoming recognised nowadays. interpolation property applied
various areas computer science, example software specification (Diaconescu,
Goguen, & Stefaneas, 1993; Bicarregui, Dimitrakos, Gabbay, & Maibaum, 2001),
construction formal ontologies (Kontchakov, Wolter, & Zakharyaschev, 2008)
model checking related subareas (McMillan, 2005). first two areas interpolation
important metatheoretical property, particular may provide basis modular composition decomposition theories; instance, Kontchakov et al. (2008)
plays key role study modular decomposition ontologies.
cases, interpolants play role special formulas applied automated deduction (McMillan, 2005).
date interpolation received much less attention systems non-monotonic
reasoning logic programming, despite importance AI computer science.
note study interpolation property system nonmonotonic reasoning
known equilibrium logic (Pearce, 2006). Since turn regarded logical
foundation stable model reasoning answer set programming (ASP), results
transfer immediately sphere ASP. shall focus mainly interpolation
c
2011
AI Access Foundation. rights reserved.

fiGabbay, Pearce, & Valverde

metatheoretical property primary interest establishing property certain
cases interest. Although Section 8 consider case interpolant (actually
uniform interpolant) explicitly constructed, mainly concerned pure
existence theorems. Discussion complexity issues well possible applications
interpolation property ASP left future work. However, seems likely that,
case studies involving formal ontologies (Konev, Walther, & Wolter, 2009), interpolation
may useful property applications ASP knowledge representation. previous
paper (Pearce & Valverde, 2012), interpolation Beth properties underlying,
monotonic logic ASP used characterise strong kinds intertheory relations.
capture weaker kinds intertheory relations may important able rely
interpolation holding extended, non-monotonic logic. plan explore avenue
future.
introduce property interpolation, let us start notation terminology. Let us assume syntax first-order logic formulas denoted lower case
Greek letters predicates lower case Latin letters.
Let monotonic inference relation suppose . interpolant
(, ) formula
&

(1)

contains predicate constant symbols belong . logic L
inference relation L said interpolation property interpolant exists
every pair formulas (, ) L . well-known, classical logic well
many non-classical logics possess interpolation.
Suppose deal non-monotonic logical system inference relation |.
express idea formula interpolant generally suffice simply
replace | (1). One problem that, since | non-monotonic, general
transitive. Instead, following idea Gabbay Maksimova (2005), modify
condition (1) proceed two-stage fashion. make use fact nonmonotonic consequence defined terms minimal models monotonic
logical system, say consequence relation | appropriately captured means
minimal models logic L consequence relation |=L . suppose | .
interpolant (, ) look formula
| & |=L

(2)

predicate constant symbols occur . Since |
defined via subclass minimal L-models, already assume |=L |. Moreover
assume L well-behaved sublogic sense L-equivalent
formulas |-consequences L-consequences |-consequences
|-consequences (so e.g. (2) derive | ). non-monotonic
reasoning last two properties known left right absorption, respectively.
Given conditions, follows (2) formula language
L-equivalent also interpolant (, ). Likewise interpolant
(, ) |=L | interpolant (, ).
Now, find interpolant (, ) satisfying (2), prove one always exists,
proceed follows. look L-formula say, precisely L-defines
918

fiInterpolable Formulas Equilibrium Logic Answer Set Programming

minimal models . Since | follows |=L . Now, L interpolation
property defined earlier, apply theorem obtain infer existence
L-interpolant sense (1) ( , ). Hence (2) follows.
Notice two-stage procedure relies three key features: (i) identify
suitable monotonic sublogic L |, (ii) formulas minimal models L-definable,
(iii) L interpolation property. conditions prima facie independent. shall see, may (i) (iii) lack (ii). situation respect
equilibrium logic follows. propositional case three conditions met,
establish interpolation property general case. situation quantified
equilibrium logic complicated. general case, lack condition (ii).
precisely, appropriate monotonic sublogic L logic interpolation
property, equilibrium models formula need first-order definable L.
procedure outlined yield interpolants cases. However recent results generalised concept (first-order) stable model imply interesting
classes interpolable formulas: shall consider detail one class, safe
formulas. particular, safe formula | , exists interpolant
(2) holds. classes interpolable formulas so-called tight formulas,
formulas possessing finite, complete set called loops.
Safety, tightness loop formulas studied length answer set programming (ASP). implications results ASP summarised follows.
case (finite) ground programs interpolation property holds. first-order
non-ground case, interpolation holds finite, safe programs without function symbols,
hence practically finite programs currently admitted answer set solvers. Moreover,
since safety defined arbitrary formulas function-free language, class
safe formulas sense goes beyond class expressions normally admitted ASP,
even auxiliary concepts like weight constraints aggregates included.

2. Logical Preliminaries
work standard propositional predicate languages, latter may
general case contain constant function symbols. Propositional languages based
set V propositional variables, formulas built-up usual way using
logical constants , , , , standing respectively conjunction, disjunction, implication
negation. propositional formula, denote V () set propositional
variables appearing .
first-order language L = hC, F, P consists set constants C, function symbols
F predicate symbols P ; function symbol f F predicate symbol p P
assigned arity. Moreover, assume fixed countably infinite set variables,
symbols , , , , , , auxiliary parentheses (, ). Atoms, terms
formulas constructed usual; closed formulas, sentences,
variable bound quantifier. (first-order) formula, L() denotes
language associated , i.e. set constants, function predicate symbols occuring
it.
make use following notation terminology. Boldface x stands tuple
variables, x = (x1 , . . . , xn ), (x) = (x1 , . . . , xn ) formula whose free variables
919

fiGabbay, Pearce, & Valverde

x1 ,. . . , xn , x = x1 . . . xn . ti terms, = (t1 , . . . , tn ) denotes vector
terms. theory set sentences. Variable-free terms, atoms, formulas, theories
also called ground.
usual symbols |=, possibly subscripts, used denote logical
inference consequence relations, respectively. logic L said monotonic
inference relation L satisfies monotonicity property:
L & L
distinguish non-monotonic monotonic inference relations, use | symbolise
former. cases non-monotonic logic understood terms inference
relation extends suitable monotonic logic. extension well-behaved
say monotonic logic forms deductive base 1 (Pearce, 2006) it.
made precise follows.
Definition 1 Let | nonmonotonic inference relation. say logic L
monotonic inference relation L deductive base | iff (i) L |; (ii) 1 L 2
1 2 ; (iii) | L , | .
L denotes ordinary logical equivalence L, denotes non-monotonic equivalence, i.e. 1 2 means 1 2 non-monotonic consequences.
Furthermore, say deductive base strong satisfies additional condition:
1 6L 2

exists 1 6 2 .

terms nonmonotonic consequence operations, (ii) (iii) correspond conditions
known left absorption right absorption respectively (Makinson, 1994).
2.1 Interpolation
turn interpolation property.
Definition 2 logic L inference relation L said interpolation property
whenever
L
exists sentence (the interpolant)
L & L
predicate, function constant symbols contained ,
i.e. L() L() L(). case propositional logic, requirement V ()
V () V ().
explained introduction, non-monotonic logics consider two forms
interpolation, one weaker one stronger. stronger form makes use underlying
monotonic logic.
1. close concept fully absorbing inferential frame used Dietrich (1994).

920

fiInterpolable Formulas Equilibrium Logic Answer Set Programming

Definition 3 Suppose | . (|, L ) interpolant (, ) formula
| & L

(3)

L deductive base | contains predicate, function constant
symbols belong . non-monotonic logic inference relation |
said (|, ) interpolation property suitable deductive base logic L
(|, L ) interpolant exists every pair formulas (, ) | .
requirement L form deductive base ensures desirable properties
interpolation met.
Proposition 1 Let (|, L ) interpolant (, ).
(a) L , (|, L ) interpolant (, ).
(b) L , L , (|, L )
interpolant ( , ).
property deductive base also guarantees (|, L ) relation transitive
sense (3) holds , , , also | . last property necessarily
hold second, weaker form interpolation call (|, |) interpolation.
Definition 4 Suppose | . (|, |) interpolant (, ) formula
| & |

(4)

contains predicate, function constant symbols belong .
case propositional logic, requirement V () V () V ().
Analogous previous case, say non-monotonic logic inference relation | (|, |) interpolation property (|, |) interpolant exists every pair
formulas (, ) | . Notice (|, ) stronger form interpolation
logic (|, ) interpolation must also (|, |) interpolation,
consequence deductive base requirement (first clause).
Evidently properties expressed Proposition 1 directly applicable
second form interpolation refer underlying base logic. Nevertheless
important feature interpolation properties shall establish
formulate prove analogous properties even (|, |) interpolation.
also consider restricted variants interpolation property holds
certain types formulas, words, interpolant (, ) given
| whenever belong specific syntactic classes. cases refer
interpolable formulas. Later shall consider kinds restrictions, belongs
specific class alternatively does.
2.2 Review Logic Here-and-There
Equilibrium logic based nonclassical logic here-and-there, denote
HT propositional case. quantified first-order case denote logic
QHT, subscripts/superscripts denote specific variants.
921

fiGabbay, Pearce, & Valverde

propositional quantified cases logic based axioms rules
intuitionistic logic captured usual Kripke semantics intuitionistic logic (van
Dalen, 1997). However additional axioms HT QHT mean use
simple kinds Kripke structures. first-order case regard structures
sets atoms built arbitrary non-empty domains D; denote At(D, F, P ) set
atomic sentences hD, F, P (if = C, obtain set atomic sentence
language L = hC, F, P i);2 denote (D, F ) set ground terms hD, F, P i.
L = hC, F, P L = hC , F , P i, write L L C C , F F P P .
L-interpretation set mean subset At(D, F, P ). classical Lstructure regarded tuple = h(D, I), L-interpretation
: (C D, F ) D, called assignment, verifies I(d) =
recursively defined.3 = (C, F ) = id, known Herbrand structure.
hand, here-and-there L-structure static domains, QHTs (L)-structure,
tuple = h(D, I), h , h(D, I), h h(D, I), classical L-structures
h .
Thus think here-and-there structure similar first-order classical
model, two parts, components, h correspond two different points
worlds, there, sense Kripke semantics intuitionistic logic,
worlds ordered h t. world w {h, t} one verifies set atoms w
expanded language domain D. call model static, since, contrast
say intuitionistic logic, domain serves worlds. Since h < t, whatever
verified h remains true t. satisfaction relation defined reflect
two different components, write I, w |= denote true respect
w component. Although need define satisfaction relation L = hC, P i,
recursive definition forces us consider formulas hC D, F, P i. particular,
p(t1 , . . . , tn ) At(C D, F, P ) I, w |= p(t1 , . . . , tn ) iff p(I(t1 ), . . . , I(tn )) w
every t1 , . . . , tn (C D, F ). |= extended recursively follows4 :
I, w |= iff I, w |= I, w |= .
I, w |= iff I, w |= I, w |= .
I, |= iff I, 6|= I, |= .
I, h |= iff I, |= I, h 6|= I, h |= .
I, w |= iff I, 6|= .
I, |= x(x) iff I, |= (d) D.
I, h |= x(x) iff I, |= x(x) I, h |= (d) D.
I, w |= x(x) iff I, w |= (d) D.
2. think objects additional constants; approach allow us use simplified
notation objects distinguished names.
3. is, every C, I(a) every f F arity n, mapping f : Dn defined;
recursive definition given I(f (t1 , . . . , tn )) = f (I(t1 ), . . . , I(tn )).
4. following corresponds usual Kripke semantics intuitionistic logic given assumptions
two worlds h single domain D,

922

fiInterpolable Formulas Equilibrium Logic Answer Set Programming

Truth sentence model defined follows: |= iff I, w |=
w {h, t}. sentence valid true models, denoted |= . sentence
consequence set sentences , denoted |= , every model model .
resulting logic called Quantified Here-and-There Logic static domains (Lifschitz, Pearce, & Valverde, 2007) denoted QHTs . terms satisfiability validity
logic equivalent logic introduced Pearce Valverde (2005).
complete axiomatisation QHTs obtained follows (Lifschitz et al., 2007).
take axioms rules first-order intuitionistic logic add axiom Hosoi
( ( ))

(5)

determines 2-element here-and-there models propositional case, together
axiom:
x((x) x(x)).
.
also consider equality predicate, =6 P , interpreted following condition
every w {h, t}
.
I, w |= t1 = t2 iff I(t1 ) = I(t2 ).
obtain complete axiomatisation, need add axiom decidible equality
.
.
xy(x = x =
6 y).
denote resulting logic QHTs= (Lifschitz et al., 2007) inference relation
. compactness strong form completeness established |=
.
context logic programs, following assumptions often play role. case
classical QHTs= models, say parameter names assumption (PNA)
applies case I|T (C,F ) surjective, i.e. unnamed individuals D; unique
names assumption (UNA) applies case I|T (C,F ) injective; case PNA
UNA apply, standard names assumption (SNA) applies, i.e. I|T (C,F ) bijection.
usual first order logic, satisfiability validity independent signature.
= h(D, I), h , L -structure L L, denote I|L restriction
sublanguage L:
I|L = h(D, I|L ), h |L , |L
Proposition 2 Suppose L L, theory L L -model .
M|L L-model .
Proposition 3 Suppose L L L. valid (resp. satisfiable)
QHTs= (L) valid (resp. satisfiable) QHTs= (L ).
proposition allows us omit reference signature logic
denoted simply QHTs= .
simplify notation also symbolise QHTs= structure = h(D, I), h ,
hU, H, i, U = (D, I) universe, H, respectively sets atoms
h , . case propositional HT logic, Kripke structures regarded pairs
hH, set atoms obvious way. (strongly) complete axiomatisation HT
obtained intuitionistic logic adding Hosoi axiom (5).
923

fiGabbay, Pearce, & Valverde

2.3 Interpolation Logic Here-and-There
important useful property HT fact strongest propositional
intermediate logic (i.e. strengthening intuitionistic logic) properly contained
classical logic. Moreover turn properly contains intermediate logics.
addition HT one precisely seven superintuitionistic propositional logics possessing
interpolation property (Maksimova, 1977; Gabbay & Maksimova, 2005).
languages without function symbols Ono showed interpolation holds
logic QHTs quantified here-and-there constant domains (Ono, 1983).5 addition,
Maksimova (1997, 1998) showed adding pure equality axioms, e.g. decidible equality axiom, superintuitionistic logic preserves interpolation property (Gabbay &
Maksimova, 2005). conclude therefore
Proposition 4 logic QHTs= possesses interpolation property.
Note strong completeness theorem QHTs= work equivalently
|=.
make observation interpolation continues hold languages include function symbols. established using following property.
Proposition 5 every formula , possible build formula , ,
atoms one following types:
.
x = C,
.
f (x1 , . . . xn ) = f F (where every xi variables),
p(t1 , . . . , tm ) (where every xi variables).
Theorem 1 Let L language containing function symbols. QHTs= (L)
interpolation property.
Proof sketch: Let us assume ; previous proposition, assume,
without loss generality, function symbols atoms type
.
f (x1 , . . . xn ) = y. Now, consider language L obtained L replacing every
function symbol f fresh predicate symbol, Pf , Arity(Pf ) = 1 + Arity(f ).
Let formulas L build respectivelly, replacing every atom
.
f (x1 , . . . xn ) = Pf (x1 , . . . xn , y). Trivially, and, interpolation property
QHTs= (L ), exists interpolant : , . replace
.
predicates Pf (t1 , . . . , tn , tn+1 ) atoms f (t1 , . . . tn ) = tn+1 obtain interpolant
initial pair formulas.
5. Onos axiomatisation QHTs uses constant domains axiom x((x) ) (x(x) ), well
alternative axioms propositional here-and-there, viz. p (p (q q)) (p q) (q p) (p
q). However, axioms given equivalent Onos.

924

fiInterpolable Formulas Equilibrium Logic Answer Set Programming

2.4 Equilibrium Logic
Equilibrium logic non-monotonic logic based certain kinds minimal models
QHTs= HT. give definition QHTs= ; propositional version easily
obtained it.
Definition 5 Among quantified here-and-there structures define order E follows:
h(D, I), h , E h(D , J), J h , J



= , = J, = J , h J h .

subset relation holds strictly, write .
Definition 6 (Equilibrium model) Let theory = h(D, I), h , model
.
1. said total h = .
2. said equilibrium model (or short, say: equilibrium)
minimal E among models , total.
words, equilibrium models total models smaller non-total
model. Evidently total QHTs= model theory equivalently regarded
classical first order model ; follows make tacit use equivalence.
propositional case, equilibrium models defined way,
ordering propositional HT models. usual way formula theory said
consistent QHTs= model additionally say coherent
equilibrium model.
following definition give preliminary notion equilibrium entailment,
agrees standard versions equilibrium logic (Pearce, 2006).
Definition 7 relation |, called equilibrium entailment, defined follows. Let
set formulas.
1. non-empty coherent (has equilibrium models), | every equilibrium model model QHTs= (respectively HT).
2. either empty equilibrium models, | .
Notice unless need distinguish propositional first-order reasoning use
symbols |, |= either version.
words may help explain concept equilibrium entailment. First,
define basic notion entailment truth every intended (equilibrium) model.
nonmonotonic reasoning common approach sometimes called skeptical
cautious notion entailment inference; counterpart brave reasoning defined
via truth intended model. Since equilibrium logic intended provide logical
foundation answer set semantics logic programs, cautious variant entailment
natural one choose: standard consequence relation associated answer
sets given truth answer sets program. Note however ASP
programming paradigm answer set may correspond particular solution
problem modelled therefore interest right.
925

fiGabbay, Pearce, & Valverde

Secondly, useful nonmonotonic consequence entailment relation
non-trivially defined consistent theories. shall see below, however,
theories possess equilibrium models. cases natural use monotonic consequence entailment relation. particular propositional case HT maximal
logic property logically equivalent theories equilibrium models.
Evidently situation 2 also handles correctly cases empty inconsistent.
Despite qualifications, remains ambiguity concept equilibrium
entailment need settle. Suppose L L, theory L
sentence L (i.e. L = L()). understand expression | ?
Evidently, fix language advance, say language L , simply
consider equilibrium models L . represents knowledge base logic
program, instance, may also take view L() appropriate signature
work with. case, query fully interpreted contains
terms theory language L().
language L theory whose language contained L, let EML ()
collection equilibrium models QHTs= (L). consider following two
variants entailment.
Definition 8 (Equilibrium entailment) Assume theory L, non-empty
equilibrium models, then:
(i) Let us write |cw |= EML (), L = LL():
(ii) let us write |ow |= EML () L() ,

general EML () L denotes collection expansions elements EML ()
models L L , i.e. vocabulary L \ L interpreted arbitrarily.
(iii) either empty equilibrium models, |cw iff |ow iff .
simple example illustrate difference |cw |ow . Let
L-sentence let q(x) predicate L. Let constant L let L
language L {q}. first method |cw (q(a) q(a)). fact
stronger entailment |cw q(a). reason form equilibrium
models L , q(a) false effect taking minimal models.
hand, expand equilibrium models QHTs= (L) QHTs= (L ), new
predicate q receives arbitrary interpretation QHTs= (L ). Since logic 3-valued
obtain |ow q(a) q(a).
standard, monotonic logics, difference two forms entailment. Definition 8 replace everywhere equilibrium model simply model (in
QHTs= ), variants (i) (ii) give result.
context logic programming deductive databases orthodox view
reasoning based closed world assumption (CWA). Accordingly ground atomic
query like q(a)?, predicate q belong language program
database, would simply assigned value false. also case first kind
equilibrium entailment use label |cw since variant appears closer
closed world form reasoning. hand, may legitimate cases
want apply CWA unknown values assigned atom
expressed theory language. second form entailment, |ow ,
926

fiInterpolable Formulas Equilibrium Logic Answer Set Programming

nearer open world reasoning, may appropriate. present purposes, however,
suffices cw ow thought merely mnemonic labels.
thorough analysis closed world versus open world reasoning context would
lead us consider assumptions UNA SNA outside scope paper.
However, observed logic programming use CWA lead
certain apparent anomalies. Notably occurs programs unsafe (see Section
5 below), following, formulated traditional notation logic programs:6
q(x, y) : p(x, y).
p(x, x).
Given restrictions SNA Herbrand models, query
? q(a, z).
yields answer z cannot satisfied models single domain
element a, query
? q(a, b).
satisfiable, given new constant b. logic programming, restrictions
usually assumed, different solutions problem proposed (Gelder, Ross,
& Schlipf, 1991; Kunen, 1987; Maher, 1988). would like point
equilibrium logic generally speaking kind program theory create
special difficulties. Neither query
? q(a, z).
understood zq(a, z), query
? q(a, b).
true equilibrium models. particular, equilibrium model whose domain
singleton element, even q(a, b) need true; evidently general case UNA
instance apply. hand answer set programming, UNA often
assumed, also typically assumed programs safe. safety condition
program excluded variables appearing head rule appear
positive body makes answer sets sensitive set constants appearing
language used grounding program. paper,
application interpolation ASP concerned, restrict attention safe programs
theories complying generalised form safety (Section 5 below).

3. Interpolation Propositional Equilibrium Logic
section deal interpolation propositional equilibrium logic. clear
semantic construction propositional equilibrium logic HT deductive base.
base actually maximal.
Proposition 6 HT strong maximal deductive base (propositional) equilibrium
entailment.
first property precisely strong equivalence theorem Lifschitz, Pearce
Valverde (2001). Maximality follows fact logic strictly stronger
HT would contain classical logic easily seen deductive base,
e.g. violating condition (ii) Definition 1. have:
6. grateful anonymous referee raising point example.

927

fiGabbay, Pearce, & Valverde

Lemma 1 Let coherent HT-formula EM () set equilibrium models.
formula HT v() defines EM () sense EM ()
|= .
Proof. Suppose coherent. let
M1 = hT1 , T1 i, M2 = hT2 , T2 i, . . . , Mn = hTn , Tn
enumeration equilibrium models. show define EM (). Suppose
Ti , ki elements denote Ai1 , . . . , Aij , . . . , Aiki . Let Ti complement
Ti ; list members Aik1 +1 , . . . Ail . . . , Ai|v()| . Set
=

^
j=1,...,ki

Aij (

_

Ail ),

l=ki+1 ,...,|v()|

=

_



i=1,...,n

claim |= = Mi = 1, . . . , n, i.e. models
precisely M1 , . . . , Mn . verify claim, note Mi |= Mi |= .
Conversely, suppose |= . semantics HT clear |= iff
|= |= , particular |= implies |= = 1, . . . , n. However,
defines complete theory whose models total. follows |= ,
= Mi . establishes claim.

Although shall demonstrate interpolation (|, |) form relation |cw , actually establish stronger result. One consequence
concerned |ow entailment (|, ) form interpolation actually holds.
Proposition 7 (|, |-Interpolation) Let , formulas set v = v() v()
v = v() \ v() suppose B1 , . . . Bn enumeration v . |cw ,
formula v() v() v(), | , B1 . . . Bn |= . Hence
particular |cw .
Proof. Let , v, v statement proposition, suppose |cw .
holds equilibrium models language v. Case (i): suppose
coherent form set equilibrium models, EMv ().
equilibrium construction easy see model EMv ()
atom Bi false, = 1, n. Construct formulas formula exactly
proof Lemma 1. consider formula (B1 . . . Bn ) . Clearly formula
defines set equilibrium models HT(v). Consequently, (B1 . . .Bn ) |=
(B1 . . . Bn ) . apply interpolation theorem HT
infer formula (B1 . . . Bn ) ,
v() v( ) v() hence v() v() v(). Since HT deductive base,
conclude
| & B1 . . . Bn .
Now, since v() v() v(), Bi 6 v() = 1, n. follows HT(v()), Bi
false every equilibrium model . model satisfies (B1 . . . Bn ).7
Since also satisfies , |cw .
7. Notice case adding sentence (B1 . . . Bn ) change set equilibrium
models.

928

fiInterpolable Formulas Equilibrium Logic Answer Set Programming

Case (ii). equilibrium models hypothesis .
case simply choose interpolant (, ).

Corollary 1 (|, -Interpolation) Let , formulas |cw v()
v(). formula v() v() v() |cw .
Proof. Immediate Proposition 7 fact v() \ v() = .



Proposition 8 (|, -Interpolation) Let , formulas set v = v() v()
v = v() \ v(). |ow , formula v() v() v(), | ,
.
Proof. Let , v, v statement proposition suppose |ow .
holds expansions elements EMv() () language v. Case (i): suppose
coherent consider EMv() ().
construct formulas formula exactly proof Lemma 1.
consider defines set EMv() (). holds expansions models
v. Hence |= therefore apply interpolation
theorem HT infer formula ,
v() v( ) v() hence v() v() v(). Since |ow HT deductive
base conclude
|ow & .
Case (ii). equilibrium models, choose interpolant (, ).



4. Interpolation Quantified Equilibrium Logic
turn first-order logic. Given inferences form | , key element
proofs Propositions 7 8 existence formula defines collection
EMv() () equilibrium models. propositional case seen existence
established. first-order case, hand, need
exist. words, EML() () need first-order definable arbitrary .
fact hard show. Ferraris et al. (2007) pointed out, general form
answer set programming first-order formulas allowed, fortiori quantified
equilibrium logic, property transitive closure expressible. Yet property
definable classical first-order logic therefore also cannot defined QHTs= .
usual way say collection K QHTs= (L) models (QHTs= ) definable
L-sentence, , K |= . easy see whenever
class EML() () first-order definable QHTs= obtain first-order analogs
Propositions 7 8. method proof essentially before.
completeness outline main steps case (|, |)-interpolation.
Proposition 9 (|, |-Interpolation) Let , formulas collection equilibrium models QHTs= - definable. Set L = L() L() L = L() \ L(). Let
{pi : = 1, n} (finite, possibly empty) set predicates L suppose
929

fiGabbay, Pearce, & Valverde

pi arity ki . |cw , formula L() L() L(), | ,

^

xpi (x) |=
i=1,n

Hence particular |cw .
Proof. Assume hypotheses. holds equilibrium models language
L. treat case coherent non-empty collection equilibrium
models, EML() (). assumption collection definable QHTs= (L())-sentence,
, say. consider equilibrium models expanded language L, i.e.
collection EML (). equilibrium construction claim EML () |= xpi (x),
= 1, n. Since working first-order semantics, let us rehearse
briefly argument this. true would model hU, T, EML (),
predicate symbol pi L tuple elements domain hU, T, i,
hU, T, |= pi (a), ie pi (a) . However, since refer relation
pi , structure hU, H, H = \ pi (a) must Valso model , contradicting
hU, T, equilibrium.
EML () |= i=1,n xpi (x) since defines
V
EML() () clearly i=1,n xpi (x) defines EML ().
V
proceed propositional case. i=1,n xpi (x) ,
^
xpi (x) .

i=1,n

interpolation
theorem QHTs= formula L() L() L(),
V
i=1,n xpi (x) . Consequently also
^
xpi (x)
| &
i=1,n

token propositional case, infer |cw .

case (|, )-interpolation |ow analogous state main property
without proof.
Proposition 10 (|, -Interpolation) Let , formulas collection
equilibrium models QHTs= - definable. |ow , formula
L() L() L(), | .

5. Illustration: Interpolation Safe Formulas
restrictive definability assumption? often met practice? Actually
mainstream answer set programming, whose language equilibrium logic captures extends (see next section), non-definable classes answers sets play significant role.
reason query answering existing solvers rely grounders instantiate
parts program computing intended models solutions. grounding
process essentially eliminates variables reduces original program propositional
form. practical cases, then, collection stable equilibrium models
definable.
930

fiInterpolable Formulas Equilibrium Logic Answer Set Programming

computational approach work general, syntactic restrictions need
imposed admissible programs theories. common form restriction called
safety. standard types logic programs based rules one regards rule safe
every variable appearing rules head also appears body. complex
formulas admitted equilibrium logic general approach answer sets (Ferraris
et al., 2007; Ferraris, 2008), new concepts safety need devised. Proposals suitable
safety concepts made Lee, Lifschitz Palla (2008b) general first-order formulas
Bria, Faber Leone (2008) restricted syntactic class. recently
Cabalar, Pearce Valverde (2009) generalised approaches suggested
safety concept arbitrary function-free formulas equilibrium logic. Since new
concept safety defines quite broad class interpolable formulas, let us review
main features. following section mention kinds interpolable
formulas may arise answer set programming.
5.1 General Concept Safety
remainder section assume languages function-free. usual
sentence said prenex form following shape, n 0:
Q 1 x1 . . . Q n xn
Qi quantifier-free. sentence said universal
prenex form quantifiers universal. universal theory set universal
sentences. safety concept defined prenex formulas provide normal form
QHTs= (Pearce & Valverde, 2005).
first introduce concept called semi-safety. main property semi-safety formulas equilibrium models refer objects language. Note
remainder section use fact negation treated
defined operator, , consider additional semantic clauses
negation.
Definition 9 (Semi-safety) quantifier free formula semi-safe nonsemi-safe variable; is, NSS() = , NSS operator recursively defined
follows:
atom, NSS() set variables ;
NSS(1 2 ) = NSS(1 ) NSS(2 );
NSS(1 2 ) = NSS(1 ) NSS(2 );
NSS(1 2 ) = NSS(2 ) r RV(1 ),
operator RV computes restricted variables follows:
atomic , equality two variables RV() = ; otherwise,
RV() set variables occurring ;
RV() = ;
931

fiGabbay, Pearce, & Valverde

RV(1 2 ) = RV(1 ) RV(2 );
RV(1 2 ) = RV(1 ) RV(2 );
RV(1 2 ) = .
definition semi-safe formulas introduced Cabalar, Pearce Valverde (2009)
generalises former definition Lee, Lifschitz Palla (2008b). short, variable x semi-safe every occurrence inside subformula that,
either x RV() x semi-safe .
examples semi-safe formulas are, instance:
p(x) (q(x) r(x))
p(x) q r(x)

(6)

Note (6), x restricted p(x) q consequent r(x) semi-safe
thus formula itself. contrary, following formulas semi-safe:
p(x) q r(x)
p(x) r(x) q(x)
following results set previously referred property semi-safe formulas:
equilibrium models include objects language.
Proposition 11 (Cabalar et al., 2009)
function free, semi-safe, h(D, I), T, |= , h(D, I), |C , |= .
Theorem 2 (Cabalar et al., 2009) function free, semi-safe, h(D, I), T,
equilibrium model , |C = .
equilibrium models semi-safe formulas refer objects language,
however model could equilibrium depending considered domain.
guarantee independence domain, need additional property semisafety. Specifically, need analyse whether unnamed elements could modify
interpretation formula. that, use assignments Kleenes threevalued logic; three-valued interpretation : {0, 1/2, 1}, extended evaluate
arbitrary formulas () follows:
( ) = min((), ())
( ) = max((), ())

() = 0
( ) = max(1 (), ())

every variable x, going use Kleenes interpretations x , defined follows:
x () = 0 x occurs atom x () = 1/2 otherwise. Intuitively, x () fixes
atoms containing variable x 0 (falsity) leaving rest undefined
evaluates using Kleenes three-valued operators, nothing else exploiting
defined values 1 (true) 0 (false) much possible.
occurrence variable x Qx weakly-restricted occurs subformula
that:
932

fiInterpolable Formulas Equilibrium Logic Answer Set Programming

Q = , positive8 x () = 1
Q = , negative x () = 0
Q = , positive x () = 0
Q = , negative x () = 1
cases, say makes ocurrence weakly restricted . property
added semi-safety condition complete definition safety.
Definition 10 semi-safe sentence said safe positive occurrences
universally quantified variables, negative occurrences existentially quantified
variables weakly restricted.
instance, formula = x(q(x) (r p(x))) safe: occurrence x
p(x) negative, whereas occurrence q(x) inside positive subformula, itself,
x weakly-restricted, since x () = 0 ( 1/2 0) = 1. Another example safe
formula x((p(x) q(x)) r).
Proposition 12 (Cabalar et al., 2009) function free, safe, prenex formula,
then: h(D, I), T, equilibrium model equilibrium model
GrC () (the grounding C).
5.2 Interpolation
basis Proposition 12 could already establish interpolation theorems safe
formulas prenex form, essentially replacing formulas ground versions
working propositional logic. However, also apply Propositions 9 10 directly
noting property shown Cabalar et al. (2009) safe prenex formulas definable
classes equilibrium models.
Theorem 3 (interpolation safe formulas)
Safe formulas prenex form
QHTs= -definable classes equilibrium models. Therefore formulas (|, |)-interpolation |cw inference holds Proposition 9 (|, )-interpolation holds |ow
inference Proposition 10.

6. Interpolation Answer Set Semantics
Answer set programming (ASP) become established form declarative, logic-based
programming basic ideas well-known. textbook treatment reader
referred Barals book (2003). also well-known, origins ASP lie
stable model answer set semantics logic programs introduced Gelfond Lifschitz (1988, 1990, 1991). semantics made use fixpoint condition involving certain
reduct operator. Subsequent extensions concept cover general kinds rules
8. Recall subexpression formula said positive number implications
contain subexpression antecedent even, negative odd. also consider
defined .

933

fiGabbay, Pearce, & Valverde

also relied reduct operator similar sort. original definitions, reader
referred various papers cited.
correspondence answer set semantics equilibrium logic also wellestablished discussed many publications, beginning Pearce (1997),
first showed answer sets disjunctive programs regarded equilibrium
models (Lifschitz et al., 2001, 2007; Ferraris et al., 2007; Pearce & Valverde, 2005, 2006,
2008). purposes suffice recall two important syntactic classes
programs main features correspondence equilibrium logic.
one extreme ground, disjunctive logic programs; treat without
strong negation, answer sets simply collections atoms. programs consist
sets ground rules form
K1 . . . Kk L1 , . . . Lm , notLm+1 , . . . , notLn

(7)

Li Kj atoms. translation syntax programs HT
propositional formulas trivial one, viz. (7) corresponds HT sentence
L1 . . . Lm Lm+1 . . . Ln K1 . . . Kk

(8)

translation correspondence answer sets equilibrium
models ground disjunctive programs also direct one:
Proposition 13 Let disjunctive logic program. hT, equilibrium model
answer set .
first shown Pearce (1997) basic equivalence later shown hold
general classes programs Pearce, P. de Guzman Valverde (2000).
also common treat non-ground rules form (7) variables may appear.
variables thought universally quantified, corresponding translation logical formula would simply universal closure formula (8).
extreme, Ferraris, Lee Lifschitz (2007) provided new definition
stable model arbitrary first-order formulas. case property stable
model defined syntactically via second-order condition resembles parallel circumscription. However also showed new notion stable model equivalent
equilibrium model defined first-order languages. sequel paper,
Lee, Lifschitz Palla (2008a) applied new definition made following refinements. stable models formula defined Ferraris et al. (2007) were,
answer sets formula Herbrand models formula stable
sense Ferraris et al. Using new terminology, follows general stable
models equilibrium models coincide, answer sets equivalent SNA-QHT
models equilibrium models.
two extremes many syntactically different kinds programs
considered several variations concept answer set proposed.
However main varieties display similar correspondence equilibrium logic.
merely necessary cases restrict attention specific kinds equilibrium models, e.g. Herbrand models, UNA-models SNA-models. important notice also
correspondence extends many additional constructs introduced
934

fiInterpolable Formulas Equilibrium Logic Answer Set Programming

ASP, cardinality weight constraints even general forms aggregates (Lee
& Meng, 2009). accommodated equilibrium logic translation
logical formulas.
ASP main emphasis finding answer sets answer
set solvers compute. Less attention placed implementing non-monotonic inference
relation query answering mechanism. However standard, skeptical concept
inference entailment associated answer set semantics. notion entailment
consequence programs answer set semantics query Q entailed
program Q true answer sets (Balduccini, Gelfond, & Nogueira, 2000).
Let us denote entailment consequence relation |AS . Evidently atoms true
answer set belong it. Conjunctions disjunctions handled
obvious way (Lifschitz, Tang, & Turner, 1999; Balduccini et al., 2000). Sometimes,
queries form a, logical notation a, explicitly dealt (Balduccini
et al., 2000). However seems keeping semantics regard formula
form true answer set true. Another way
express would say answer set satisfies violate
constraint { }, understanding constraint violation Lifschitz, Tang Turner (1999).9
way would say |AS answer set contains A. Similarly,
interpretation queries containing quantifiers answer set semantics also conform
equilibrium logic, taking account specific restrictions, Herbrand
models, might imposed.
therefore transfer interpolation properties equilibrium logic answer set
semantics ASP. remains consider whether |AS best identified closed
world version inference, |cw , open world version, |ow . Again, since ASP
solvers generally implement inference engines, difference largely theoretical one. traditional logic programming, however, query belong
language program usually answered false. also seems quite natural ASP
context that, given program query Q, one consider stable models
language L() L(Q) even proper extension language .10
general |cw seems natural choice answer set inference. hand,
contexts answer set semantics used open world setting, example
setting hybrid knowledge bases (Rosati, 2005) non-monotonic rules combined
ontologies formalised description logics. systems semantics terms
equilibrium logic provided de Bruijn, Pearce, Polleres Valverde (2007).
entailment relation style |ow might sometimes appropriate.
general answer set semantics defined coherent programs theories.
these, identifying |AS |cw , apply Proposition 9 directly:
Corollary 2 coherent formulas , (|, |)-interpolation form Proposition 9
holds entailment |AS answer set semantics.
9. logical terms constraint would written .
10. Notice Proposition 12 program consists safe formulas, atomic query q(a) automatically
false belong language program (even q does), simply grounding
program constants sufficient generate answer sets.

935

fiGabbay, Pearce, & Valverde

7. Application Interpolation
Interpolation property applied various areas computer science, notably
software specification (Bicarregui et al., 2001) construction formal ontologies (Lutz & Wolter, 2010). areas relevant modularity issues.
discuss simple application related concept described Lutz Wolter
adapt case nonmonotonic logic programs.
One way compare two theories via nonmonotonic consequence relations.
two theories produce answers given query language, call inseparable; term used mathematical logic also study formal ontologies (Lutz
& Wolter, 2010).
Let us say therefore 1 2 L-inseparable V () L,
1 | 2 | .
Proposition 14 Let 1 2 L-inseparable theories V (1 ) = V (2 ) = V ,
say. L L V L L, 1 2 L -inseparable.
Proof. Assume 1 2 L-inseparable L extension L
V L L. Suppose 1 | , V () = L . Suppose L \ V = {B1 , . . . Bn }.
Proposition 7 interpolant (1 , ) |= B1 . . .Bn . Since
1 | V () L, L-inseparability 2 | . right absorption therefore
2 | B1 . . . Bn . However clear B1 , . . . Bn false equilibrium
models 2 , 2 | . Repeating argument 1 2 interchanged shows
theories L -inseparable.

proof similar argument given Lutz Wolter (2010) Theorem 7 paper, applied TBoxes description logics. property described
called robustness signature extensions. Notice however that, since |
general transitive cannot immediately infer 2 | | also 2 | .
highlights added strength using explicitly set {B1 , . . . Bn } property
HT forms deductive basis |.
study modularity logical relations programs ASP,
common compare sets answer sets rather consequence classes. However
turns notion inseparability close concept already
studied ASP. Two theories programs said projectively equivalent
projections answer sets onto common sublanguage agree (Eiter, Tompits,
& Woltran, 2005). Formally, let 1 , 2 theories L signature L
V (1 ) V (2 ). 1 2 said projectively equivalent relative L
E(1 )L = E(2 )L , class models K, KL = {ML : K}.
Proposition 15 Let 1 , 2 theories L signature L V (1 ) V (2 ).
1 2 projectively equivalent relative L L-inseparable.
words two concepts agree whenever L common sublanguage 1 , 2 .
main advantage L-inseparability seems natural one use
want consider signatures extend language either program theory.
936

fiInterpolable Formulas Equilibrium Logic Answer Set Programming

8. Uniform Interpolation Forgetting
stronger form interpolation known uniform interpolation also important certain
applications computer science (Konev et al., 2009). usual, given , ,
interested interpolants
&

(9)

contains predicate constant symbols belong .
difference said uniform interpolant (9) holds
signature . logic said uniform interpolation property
uniform interpolants exist , .
classical propositional logic, uniform interpolation holds, however fails first
order classical logic many non-classical logics. may hold certain restrictions
placed theory language formulated query language
containing . example shown hold description logics (Kontchakov
et al., 2008) syntactic restrictions apply. Even ASP turns form
uniform interpolation holds restricted query language, essentially one allows
instance retrieval. show using known results ASP
concept forgetting (Eiter & Wang, 2008) quite closely related interpolation.
Variable forgetting, studied Eiter Wang (2008), concerned following
problem. Given disjunctive logic program certain atom occurring , construct
new program, denoted forget(, a), contain whose answer
sets respects close possible . precise notion
closeness reader referred paper Eiter Wang, however consequences
evident shortly. Eiter Wang define forget(, a) (as generic term), show
programs exist whenever coherent, provide different algorithms compute
programs.
Given coherent , results forget(, a), forgetting may
different always answer set equivalent. Moreover purposes satisfy
following key property, coherent, a, b distinct atoms usual |
denotes nonmonotonic consequence,
| b



forget(, a) | b.

(10)

showing indeed answer sets forget(, a) closely related.
establish version uniform interpolation case disjunctive programs
simple, atomic queries, need show always find = forget(, a)
| . examine first algorithm Eiter Wang computing
forget(, a); also simplest three algorithms presented. Let coherent
program rules form (7) write formulas form (8) let atom
. method constructing = forget(, a) follows.
1. Compute equilibrium models E().
2. Let E result removing E().
3. Remove E model non-minimal form E (= {A1 , . . . , }, say).
937

fiGabbay, Pearce, & Valverde

4. Construct program whose answer sets precisely {A1 , . . . , } follows:
Ai , set = {Ai : Ai }, Ai = V () \ Ai .
Set = 1 . . . .
verify desired property. Let L simple query language composed
conjunctions literals.
Proposition 16 equilibrium logic (or answer set programming) uniform interpolation
holds (coherent) disjunctive programs queries L(V ()).
Proof. prove claim shall show following. Let coherent disjunctive
program let L = L(V ) V V (). program
V ( ) = V L,
| ( | & | )
begin, let | . Let X = {a1 , . . . , } = V () \ V .
choose result forgetting X , defined Eiter Wang (2008)
follows:
forget(, X) := forget(forget(forget(, a1 ), a2 ), . . . , ),
shown order atoms X matter. know
(10) atom V = 1, n,
| forget(, ai ) | a,

(11)

| forget(, X) | a.

(12)

therefore
Let forget(, X) determined algorithm 1 Eiter Wang (2008) described
above. easy see (11) semantics | (12) continues hold
replaced negated atom b therefore also conjunction literals since
conjunction entailed element holds every equilibrium model.11 remains
show | . Again, suffice show entailment one member
sequence forget(, ai ) since order irrelevant wlog choose first element
forget(, a1 ) show | forget(, a1 ). compute programs 1 , . . . ,
algorithm. need check | = 1, n, i.e.
E(), |= {Ai : Ai }.
Consider E() = hT, i. distinguish two cases. (i) Ai .
|= Ai . follows |= Ai Ai
|= {Ai : Ai }. Case (ii) Ai 6 . Ai incomparable.
particular cannot Ai minimality property Ai obtained step 3.
Hence Ai 6= . Choose Ai . |= , 6|= hence 6|= Ai .
Consequently, , |= Ai |= {Ai : Ai }. follows
i, | construction | , establishes proposition.
11. Eiter Wang (2008) point out, atom b true answer set forget(, a),
must also true answer set , showing (12) holds literals.

938

fiInterpolable Formulas Equilibrium Logic Answer Set Programming

8.1 Extending Query Language
establish uniform interpolation ASP using method forgetting, defined
Eiter Wang (2008), seems clear cannot extend non-trivial way
expressive power query language L. Since method forgetting removes
non-minimal sets E() (once removed), atom b might true
equilibrium model equilibrium model forget(, a). Hence might
disjunction, say b, derivable forget(, a). Likewise,
consider programs variables first-order setting, cannot general extend L
include existential queries.
hand, property uniform interpolation certainly holds L(V )
even without condition V V (). Suppose | V () \ V () 6= ,
say V () \ V () = {b1 , . . . , bk }. b1 , . . . , bk false equilibrium models .
Trivially, b V () regard result forgetting b .
repeat proof Proposition 16, setting X = {V () \ V } {V \ V ()}.
relevant properties continue hold.
interesting open question whether extend theory language include
general kinds program rules allowing negation head. Accommodating kinds formulas would constitute important generalisation since
amount normal form equilibrium logic. However, answer sets programs
satisfy minimality property holds answer sets disjunctive programs,
clear definition forgetting would need appropriately modified -
task attempt here.

9. Literature Related Work
interpolation theorem classical logic due Craig (1957); extended intutionistic logic Schutte (1962). Maksimova (1977) characterised super-intuitionistic
propositional logics possessing interpolation. modern, comprehensive treatment interpolation modal intuitionistic logics found monograph Gabbay
Maksimova (2005).
non-monotonic logics, interpolation received little attention. notable exception
article (Amir, 2002) establishing interpolation properties circumscription
default logic. well-known relation answer sets disjunctive programs
extensions corresponding default theories, also derives form interpolation
ASP. regard answer set semantics, approach Amir quite different
ours. Since founded analysis default logic, uses classical logic underlying
base. Amirs version interpolation form (3) L classical logic;
requirement L form well-behaved sublogic |, e.g. deductive base. Amir
remarks, one cannot deduce general property (4) | . However L classical
logic one cannot even deduce | (3). generally, counterpart
Proposition 1 case. Another difference respect approach
Amir discuss nature | relation ASP detail, particular
understand | case contains atoms present program . fact,
interpret |AS Section 6 above, easy refute (|, L )-interpolation L
classical logic. Let program B q query B C. clearly
939

fiGabbay, Pearce, & Valverde

|AS q, formula vocabulary B would classically entail C.
interpretation answer set inference atoms program
regarded false, (|, L )-interpolation would refuted.

10. Conclusions
discussed two kinds interpolation properties non-monotonic inference relations shown properties hold turn two different inference relations
associate propositional equilibrium logic. case use fact
collection equilibrium models definable logic HT here-and-there
logic possesses usual form interpolation. One forms inference studied
seems many cases appropriate concept associate answer set programming, although general ASP systems tailored query answering deduction.
Using results Eiter Wang (2008) variable forgetting ASP, could also show
property uniform interpolation holds disjunctive programs restricted
query language.
also discussed interpolation property first-order equilibrium logic based
quantified version QHT logic here-and-there, obtaining analogous results
propositional case whenever collection equilibrium models definable.
positive results transfer answer set programming assumption usually made
ASP systems programs safe therefore definable collections answer sets.
saw, notion safety quite generally defined theories limited
normal disjunctive programs.

Acknowledgments
David Pearce partially supported MEC projects TIN2009-14562-C05-02 CSD200700022. Agustn Valverde partially supported MEC project TIN2009-14562-C05-01,
Junta de Andalucia projects P09-FQM-05233 TIC-115. authors grateful
anonymous referees helpful comments.

References
Amir, E. (2002). Interpolation theorems nonmonotonic reasoning systems.. Proceedings NMR02, pp. 4150.
Balduccini, M., Gelfond, M., & Nogueira, M. (2000). A-prolog tool declarative
programming. Proc. SEKE 2000).
Baral, C. (2003). Knowledge Representation, Reasoning Declarative Problem Solving.
Cambridge University Press.
Bicarregui, J., Dimitrakos, T., Gabbay, D. M., & Maibaum, T. S. E. (2001). Interpolation
practical formal development. Logic Journal IGPL, 9 (2).
Bria, A., Faber, W., & Leone, N. (2008). Normal form nested programs. Holldobler, S.,
Lutz, C., & Wansing, H. (Eds.), Proc. JELIA08, Vol. 5293 LNCS, pp. 7688.
Springer.
940

fiInterpolable Formulas Equilibrium Logic Answer Set Programming

Cabalar, P., Pearce, D., & Valverde, A. (2009). revised concept safety general answer
set programs. Erdem, E., Lin, F., & Schaub, T. (Eds.), Proc. LPNMR09, Vol.
5753 LNCS, pp. 5870. Springer.
Craig, W. (1957). Linear reasoning. new form herbrand-gentzen theorem.. J. Symb.
Logic, 22, 250268.
de Bruijn, J., Pearce, D., Polleres, A., & Valverde, A. (2007). Quantified equilibrium logic
hybrid rules. Marchiori, M., Pan, J. Z., & de Sainte Marie, C. (Eds.), Proc.
RR07, Vol. 4524 LNCS, pp. 5872. Springer.
Diaconescu, R., Goguen, J., & Stefaneas, P. (1993). Logical support modularisation.
Logical Environments, pp. 83130. Cambridge University Press.
Dietrich, J. (1994). Deductive bases nonmonononic inference operations. Ntz report,
University Leipzig.
Eiter, T., Tompits, H., & Woltran, S. (2005). solution correspondences answer-set
programming.. Kaelbling, L. P., & Saffiotti, A. (Eds.), Proc. IJCAI05, pp.
97102. Professional Book Center.
Eiter, T., & Wang, K. (2008). Semantic forgetting answer set programming. Artificial
Intelligence, 172 (14), 16441672.
Ferraris, P. (2008). Logic programs propositional connectives aggregates. CoRR,
abs/0812.1462.
Ferraris, P., Lee, J., & Lifschitz, V. (2007). new perspective stable models. Veloso,
M. M. (Ed.), Proc. IJCAI07, pp. 372379.
Gabbay, D. M., & Maksimova, L. (2005). Interpolation Definability: Modal Intuitionistic Logic. Oxford University Press, USA.
Gelder, A. V., Ross, K. A., & Schlipf, J. S. (1991). well-founded semantics general
logic programs. Journal ACM, 38 (3), 620650.
Gelfond, M., & Lifschitz, V. (1988). stable model semantics logic programming.
Kowalski, R. A., & Bowen, K. (Eds.), Proc. ICLP88, pp. 10701080. MIT
Press.
Gelfond, M., & Lifschitz, V. (1990). Logic programs classical negation. Warren,
David H.D.; Szerdei, P. (Ed.), Proc. ICLP90, pp. 579597. MIT Press.
Gelfond, M., & Lifschitz, V. (1991). Classical negation logic programs disjunctive
databases. New Generation Computing, 9, 365385.
Konev, B., Walther, D., & Wolter, F. (2009). Forgetting uniform interpolation largescale description logic terminologies. Boutilier, C. (Ed.), Proc. IJCAI09, pp.
830835.
Kontchakov, R., Wolter, F., & Zakharyaschev, M. (2008). tell difference
dl-lite ontologies?. Brewka, G., & Lang, J. (Eds.), Principles Knowledge
Representation Reasoning: Proc. KR08, pp. 285295. AAAI Press.
Kunen, K. (1987). Negation logic programming. Journal Logic Programming, 4 (4),
289308.
941

fiGabbay, Pearce, & Valverde

Lee, J., Lifschitz, V., & Palla, R. (2008a). reductive semantics counting choice
answer set programming. Fox, D., & Gomes, C. P. (Eds.), Proc. AAAI08, pp.
472479. AAAI Press.
Lee, J., Lifschitz, V., & Palla, R. (2008b). Safe formulas general theory stable
models (preliminary report). de la Banda, M. G., & Pontelli, E. (Eds.), Proc.
ICLP08, Vol. 5366 LNCS, pp. 672676. Springer.
Lee, J., & Meng, Y. (2009). reductive semantics aggregates answer set programming. Erdem, E., Lin, F., & Schaub, T. (Eds.), Proc. LPNMR09, Vol. 5753
LNCS, pp. 182195. Springer.
Lifschitz, V., Pearce, D., & Valverde, A. (2001). Strongly equivalent logic programs. ACM
Transactions Computational Logic, 2 (4), 526541.
Lifschitz, V., Pearce, D., & Valverde, A. (2007). characterization strong equivalence
logic programs variables. Baral, C., Brewka, G., & Schlipf, J. S. (Eds.),
Proc. LPNMR07, Vol. 4483 LNCS, pp. 188200. Springer.
Lifschitz, V., Tang, L. R., & Turner, H. (1999). Nested expressions logic programs. Annals
Mathematics Artificial Intelligence, 25 (34), 369389.
Lutz, C., & Wolter, F. (2010). Deciding inseparability conservative extensions
description logic el. Journal Symbolic Computation, 45 (2), 194228.
Maher, M. J. (1988). Equivalences logic programs. Foundations Deductive Databases
Logic Programming., pp. 627658. Morgan Kaufmann.
Makinson, D. (1994). General patterns nonmonotonic reasoning, pp. 35110. Oxford
University Press, Inc.
Maksimova, L. (1997). Interpolation superintuitionistic predicate logics equality.
Algebra Logic, 36, 543561.
Maksimova, L. (1998). Interpolation superintuitionistic modal predicate logics
equality. M.Kracht, de Rijke, M., Wansing, H., & Zakharyaschev, M. (Eds.), Advances Modal Logic, Vol. I, pp. 133141. CSLI Publications.
Maksimova, L. (1977). Craigs interpolation theorem amalgamable varieties. Doklady
Akademii Nauk SSSR, 237 (6), 12811284.
McMillan, K. L. (2005). Applications craig interpolants model checking. Halbwachs,
N., & Zuck, L. D. (Eds.), Proc. TACAS05, Vol. 3440 LNCS, pp. 112. Springer.
Ono, H. (1983). Model extension theorem craigs interpolation theorem intermediate
predicate logics. Reports Mathematical Logic, 15, 4158.
Pearce, D. (1997). new logical characterization stable models answer sets. Dix,
J., Pereira, L. M., & Przymusinski, T. C. (Eds.), Proc. NMELP96, Vol. 1216
LNCS, pp. 5770. Springer.
Pearce, D. (2006). Equilibrium logic. Annals Mathematics Artificial Intelligence,
47 (1-2), 341.
Pearce, D., de Guzman, I. P., & Valverde, A. (2000). Computing equilibrium models using
signed formulas. Proc. CL2000, Vol. 1861 LNCS, pp. 688703. Springer.
942

fiInterpolable Formulas Equilibrium Logic Answer Set Programming

Pearce, D., & Valverde, A. (2005). first order nonmonotonic extension constructive
logic. Studia Logica, 80 (2-3), 321346.
Pearce, D., & Valverde, A. (2006). Quantified equilibrium logic. Technical report, Universidad Rey Juan Carlos. (http://www.matap.uma.es/investigacion/tr/ma06_02.
pdf).
Pearce, D., & Valverde, A. (2008). Quantified equilibrium logic foundations answer
set programs. de la Banda, M. G., & Pontelli, E. (Eds.), Proc. ICLP08, Vol.
5366 LNCS, pp. 546560. Springer.
Pearce, D., & Valverde, A. (2012). Synonymous theories knowledge representations
answer set programming. Journal Computer System Sciences, 78, 86104.
Rosati, R. (2005). Semantic computational advantages safe integration ontologies rules. Fages, F., & Soliman, S. (Eds.), Proc. PPSWR05, Vol. 3703
LNCS, pp. 5064. Springer.
Schutte, K. (1962). Der interpolationsatz der intuitionistischen pradikatenlogik.. Math.
Ann., 148, 192200.
van Dalen, D. (1997). Logic Structure (3th edition). Springer.

943

fiJournal Artificial Intelligence Research 42 (2011) 181-209

Submitted 5/11; published 10/11

Topological Value Iteration Algorithms
Peng Dai

DAIPENG @ CS . WASHINGTON . EDU

Google Inc.
1600 Amphitheatre Pkwy
Mountain View, CA 94043
USA

Mausam
Daniel S. Weld

MAUSAM @ CS . WASHINGTON . EDU
WELD @ CS . WASHINGTON . EDU

Department Computer Science Engineering
University Washington
Seattle, WA 98195
USA

Judy Goldsmith

GOLDSMIT @ CS . UKY. EDU

Department Computer Science
University Kentucky
Lexington, KY 40508
USA

Abstract
Value iteration powerful yet inefficient algorithm Markov decision processes (MDPs)
puts majority effort backing entire state space, turns
unnecessary many cases. order overcome problem, many approaches
proposed. Among them, ILAO* variants RTDP state-of-the-art ones. methods
use reachability analysis heuristic search avoid unnecessary backups. However, none
approaches build graphical structure state transitions pre-processing step
use structural information systematically decompose problem, whereby generating
intelligent backup sequence state space. paper, present two optimal MDP algorithms. first algorithm, topological value iteration (TVI), detects structure MDPs
backs states based topological sequences. (1) divides MDP strongly-connected
components (SCCs), (2) solves components sequentially. TVI outperforms VI
state-of-the-art algorithms vastly MDP multiple, close-to-equal-sized SCCs. second algorithm, focused topological value iteration (FTVI), extension TVI. FTVI restricts
attention connected components relevant solving MDP. Specifically, uses
small amount heuristic search eliminate provably sub-optimal actions; pruning allows
FTVI find smaller connected components, thus running faster. demonstrate FTVI outperforms TVI order magnitude, averaged across several domains. Surprisingly, FTVI
also significantly outperforms popular heuristically-informed MDP algorithms ILAO*,
LRTDP, BRTDP Bayesian-RTDP many domains, sometimes much two orders
magnitude. Finally, characterize type domains FTVI excels suggesting way
informed choice solver.

1. Introduction
Markov Decision Processes (MDPs) (Bellman, 1957) powerful widely-adopted formulation modeling autonomous decision making uncertainty. instance, NASA researchers
c
2011
AI Access Foundation. rights reserved.

fiDAI , AUSAM , W ELD , & G OLDSMITH

use MDPs model next-generation Mars rover planning problems (Bresina, Dearden, Meuleau,
Ramkrishnan, Smith, & Washington, 2002; Feng & Zilberstein, 2004; Mausam, Benazera, Brafman,
Meuleau, & Hansen, 2005; Meuleau, Benazera, Brafman, Hansen, & Mausam, 2009). MDPs
also used formulate military operations planning (Aberdeen, Thiebaux, & Zhang, 2004)
coordinated multi-agent planning (Musliner, Carciofini, Goldman, E. H. Durfee, & Boddy, 2007),
etc.
Classical dynamic programming algorithms, value iteration (VI), solve MDP optimally iteratively updating value every state fixed order, one state per iteration.
inefficient, since overlooks graphical structure problem, provide
vast information state dependencies.
past decade researchers developed heuristic search algorithms use reachability information heuristic functions avoid unnecessary backups. approaches,
improved LAO* (ILAO*) (Hansen & Zilberstein, 2001), LRTDP (Bonet & Geffner, 2003b),
HDP (Bonet & Geffner, 2003a), BRTDP (McMahan, Likhachev, & Gordon, 2005) Bayesian
RTDP (Sanner, Goetschalckx, Driessens, & Shani, 2009), frequently outperform value iteration.
problems, however, heuristic search algorithms offer little benefit difficult predict excel. raises important, open question, attributes problems
problem domains make best suited heuristic search algorithms?
paper present two algorithms solve MDPs optimally speed convergence value iteration: topological value iteration (TVI) (Dai & Goldsmith, 2007) focused
topological value iteration (FTVI) (Dai, Mausam, & Weld, 2009b). TVI makes use graphical
structure MDP. performs Bellman backups intelligent order performing
additional topological analysis MDP state space. TVI first divides MDP strongly connected components (SCCs) solves component sequentially topological order. Experimental results demonstrate significant performance gains VI and, surprisingly, heuristic search algorithms (despite TVI using reachability information itself) specific kind
domain one multiple, close-to-equal-sized SCCs.
TVI general, independent assumptions start state find
optimal value function entire state space. However, many benchmark problems cannot
broken roughly equal-sized SCCs, leaving TVIs performance better (or often worse, due
overhead generating SCCs) MDP algorithms. instance, many domains (e.g.,
Blocksworld) reversible actions. Problems domains states
connected reversible actions end one (large) SCC, thus, eliminating benefit
TVI.
FTVI addresses weaknesses TVI. first performs phase heuristic search eliminates provably sub-optimal actions found search. builds informative
graphical structure based remaining actions. find short phase heuristic
search often able eliminate many actions leading MDP structure amenable
efficient, topology-based solutions.
evaluate FTVI across several benchmark domains find FTVI outperforms TVI
significant margins. Surprisingly, also find FTVI outperforms state-of-the-art heuristic
search algorithms domains. unexpected, since common wisdom dictates
heuristic-guided search much faster all-state dynamic programming. better understand
big improvement, study convergence speed algorithms problem features.
discover two important features problems hard heuristic search algorithms: smaller
182

fiT OPOLOGICAL VALUE TERATION LGORITHMS

number goal states long search distance goal. features commonly found
many domains, e.g., Mountain car (Wingate & Seppi, 2005) Drive (Bonet, 2006). show that,
domains, FTVI outperforms heuristic search convergence speed order magnitude
average, sometimes even two orders magnitude.
Comparing previous conference versions (Dai & Goldsmith, 2007; Dai et al., 2009b),
paper makes several significant improvements: (1) add convergence test module
search phase FTVI. module, FTVI works good best heuristic search algorithms
domains used significantly outperformed. (2) perform extensive empirical study
TVI (Figures 2 3 new) FTVI (Figure 5 new, added Blocksworld
domain). (3) describe TVI FTVI consistent way improve pesudo-codes. (4)
add convergence proof TVI (Theorem 2).
outline rest paper follows: Section 2 formally defines MDPs, reviews
algorithms solve MDPs. Section 3 describes topological value iteration algorithm,
compares empirically algorithms special MDP domain. Section 4 introduces
focused topological value iteration algorithm provides thorough empirical evaluation.
present related work Section 5 conclude Section 6.

2. Background
provide overview Markov decision process (MDP) dynamic programming algorithms
solve MDP.
2.1 Markov Decision Processes Planning
AI researchers typically use MDPs formulate fully-observable probabilistic planning problems.
MDP defined five-tuple hS, A, Ap, T, Ci,
finite set discrete states.
finite set applicable actions.
Ap : P(A) applicability function. Ap(s) denotes set actions
applied state s. P(A) power set set actions.
: [0, 1] transition function describing effect action execution.
C : R+ cost executing action state.
agent executes actions discrete time steps. step, system one distinct
state S. agent execute action set applicable actions Ap(s) A, incurring cost C(s, a). action takes system new state s0 stochastically, probability
Ta (s0 |s).
horizon MDP number steps costs accumulated. concentrate
special set MDPs called stochastic shortest path (SSP) problems. Despite simplicity, SSP
general MDP representation. infinite-horizon, discounted-reward MDP easily converted SSP problem (Bertsekas & Tsitsiklis, 1996). horizon MDP indefinite,
i.e., finite unbounded, costs accumulated discounting. two
components SSP:
183

fiDAI , AUSAM , W ELD , & G OLDSMITH

s0 initial state.
G set sink goal states. Reaching one g G terminates execution.
cost execution sum costs along path s0 first goal state
encountered.
assume full observability, i.e., executing action transitioning stochastically
next state governed , agent full knowledge state. policy, : A,
MDP mapping state space action space, indicating action execute
state. solve MDP need find optimal policy ( : A), probabilistic
execution plan reaches goal state minimum expected cost. evaluate policy
value function, set values satisfy following equation:
V (s) = C(s, (s)) +

X

T(s) (s0 |s)V (s0 ).

(1)

s0

optimal policy must satisfy following system Bellman equations:
V (s) = 0 G, else
"
V (s) =

min

#
X

C(s, a) +

aAp(s)

Ta (s0 |s)V (s0 ) .

(2)

s0

corresponding optimal policy extracted value function:
"
#
X
(s) = argminaAp(s) C(s, a) +
Ta (s0 |s)V (s0 ) , G.

(3)

s0

Given implicit optimal policy form optimal value function V (), Q-value
state-action pair (s, a) defined value state s, immediate action performed,
followed afterwards. concretely,
X
Q (s, a) = C(s, a) +
Ta (s0 |s)V (s0 ).
(4)
s0

Therefore, optimal value function expressed by:
V (s) = minaAp(s) Q (s, a).
2.2 Dynamic Programming
optimal MDP algorithms based dynamic programming, whose utility first proved
simple yet powerful algorithm named value iteration (Bellman, 1957). Value iteration first
initializes value function arbitrarily, example zero. Then, values updated iteratively
using operator called Bellman backup (Line 7 Algorithm 1) create successively better
approximations state per iteration. define Bellman residual state
absolute difference state value Bellman backup. Value iteration stops
value function converges. implementation, typically signaled Bellman error,
184

fiT OPOLOGICAL VALUE TERATION LGORITHMS

Algorithm 1 (Gauss-Seidel) Value Iteration
1: Input: MDP = hS, A, Ap, T, Ci, : threshold value
2: initialize V arbitrarily
3: true
4:
Bellman error 0
5:
state
6:
oldV V (s)


P
7:
V (s) minaAp(s) C(s, a) + s0 Ta (s0 |s)V (s0 )
8:
Bellman residual(s) |V (s) oldV |
9:
Bellman error max(Bellman error, Bellman residual(s))
10:
Bellman error <
11:
return V
largest Bellman residual states, becomes less pre-defined threshold, . call
Bellman backup contraction operation (Bertsekas, 2001), every state, Bellman residual
never increase iteration number.
Value iteration converges optimal value function time polynomial |S| (Littman, Dean,
& Kaelbling, 1995; Bonet, 2007), yet practice usually inefficient, since blindly performs
backups state space iteratively, often introducing many unnecessary backups.
2.2.1 H EURISTIC EARCH
improve efficiency dynamic programming, researchers explored various ideas
traditional heuristic-guided search, consistently demonstrated usefulness MDPs
(Barto, Bradtke, & Singh, 1995; Hansen & Zilberstein, 2001; Bonet & Geffner, 2003b, 2006;
McMahan et al., 2005; Smith & Simmons, 2006; Sanner et al., 2009). basic idea heuristic search consider action necessary, leads conservative backup
strategy. strategy helps save lot unnecessary backups.
define heuristic function h : R+ , h(s) estimate V (s). heuristic
function h admissible never over-estimates value state,
h(s) V (s), S.

(5)

also interchangeably write admissible heuristic function Vl , emphasize Vl (s)
lower bound V (s).
Definition greedy policy best policy one-step lookahead given current value
function, V :
"
#
X
(s) = argminaAp(s) C(s, a) +
Ta (s0 |s)V (s0 ) , G.
(6)
s0

policy graph, G = (V, E), MDP set states policy directed,
connected graph vertices V S, s0 V, S, V iff reachable
s0 policy . Furthermore, s, s0 V, hs, s0 E (the edges policy graph) iff
T(s) (s0 |s) > 0.
185

fiDAI , AUSAM , W ELD , & G OLDSMITH

Heuristic search algorithms two main features: (1) search limited states
reachable initial state. Given heuristic value, heuristic search algorithm generates
running greedy policy, well policy graph. algorithm performs series heuristic
searches, states greedy policy graph converge. search typically starts
initial state, successor states explored best-first manner. Visited states values
backed search. (2) Since heuristic search algorithms fewer backups value
iteration, require special care guarantee final optimality. values state space
initialized admissible heuristic function. Note value iteration also take advantage
initial heuristic values informative starting point, require heuristics
admissible guarantee optimality.
Different heuristic search algorithms use different search strategies therefore perform Bellman backups different orders.
AO* algorithm (Nilson, 1980) solves acyclic MDPs, applicable general MDPs.
LAO* (Hansen & Zilberstein, 2001) extension AO* algorithm handle MDPs
loops. Improved LAO* (ILAO*) (Hansen & Zilberstein, 2001) efficient variant LAO*.
iteratively performs complete searches discover running greedy policy graph. detail,
greedy policy graph contains initial state s0 search starts. New states added
graph means expansions frontier state depth-first manner,
states added. state expansion, one greedy actions chosen, actions
successor states added graph. States expanded yet contain successors
called frontier states. Later, states greedy policy graph backed postorder visited. search iteration performs |S| backups, practice
number typically much smaller. ILAO* terminates states current greedy policy
graph Bellman residual less given .
Real-time dynamic programming (RTDP) (Barto et al., 1995) another popular algorithm
MDPs. interleaves dynamic programming search plan execution trials. execution
trial path originates s0 ends goal state bounded-step cutoff.
execution step simulates result one-step plan execution. agent greedily picks action
current state s, mimics state transition new current state s0 , chosen stochastically
based transition probabilities action, i.e., s0 Ta (s0 |s). Dynamic programming
happens states backed immediately visited. RTDP good finding
good sub-optimal policy relatively quickly. However, order RTDP converge, states
optimal policy backed sufficiently, convergence usually slow. overcome
slow convergence problem RTDP, researchers later proposed several heuristic search variants
algorithm.
Bonet Geffner (2003b) introduced smart labeling technique RTDP extension named
labeled RTDP (LRTDP). label state solved every state reachable applying
greedy policy either goal state, solved, Bellman residual greater
threshold . States labeled solved longer get backed future search. Labeling
helps speed convergence avoids many unnecessary backups states already
converged. execution trial, LRTDP tries label every unsolved state reverse order
visit. label state s, LRTDP initiates DFS s0 checks states reachable
greedy policy rooted solved, back up, otherwise. LRTDP terminates
states current policy graph solved. Bonet Geffner also applied labeling technique
another algorithm called HDP (Bonet & Geffner, 2003a). HDP uses Tarjans algorithm find
186

fiT OPOLOGICAL VALUE TERATION LGORITHMS

strongly connected component MDP help label solved states implicitly control
order states backed search trial.
McMahan et al. (2005) proposed another extension named bounded RTDP (BRTDP),
uses lower bound heuristic value function Vl , also upper bound Vu . BRTDP
two key differences original RTDP algorithm. First, BRTDP backs state
s, updates lower bound upper bound. Second, choosing next state s0 ,
difference two bounds, Vu (s0 ) Vl (s0 ), also taken consideration. concretely,
s0 Ta (s0 |s)[Vu (s0 ) Vl (s0 )], focuses search states less likely converged.
One feature BRTDP adaptive trial termination criterion, helpful practice.
Smith Simmons (2006) introduced similar algorithm named focused RTDP (FRTDP).
define occupancy intuitive measure expected number times state visited
execution termination. Therefore occupancy state indicates relevance policy. Similar
BRTDP, FRTDP also keeps two bounds state. FRTDP uses product states occupancy
difference bounds picking next state. Also, FRTDP assumes discounted cost
setting, immediately applicable SSP problems.
Recently Sanner et al. (2009) described another advanced RTDP variant named Bayesian RTDP,
also uses two value bounds. basic motivation Bayesian RTDP anytime performance sub-optimal policies important, finding optimal policy timeconsuming. especially true sub-optimal policy performs close optimal one,
much faster generate. key assumption true value function state s, V (s),
uniformly distributed interval [Vl (s), Vu (s)]. Therefore, probability density function
1
V (s) 1v[Vl (s),Vu (s)] [ Vu (s)V
], E[V (s)] = 21 [Vl (s) + Vu (s)]. evaluate important
l (s)
pick state s0 next state, refers notion value perfect information (VPI),
intuitively tells expected Q-value difference current state-action pair, Q(s, a),
without knowledge V (s0 ). choose s0 , Bayesian RTDP uses metric combines
BRTDP metric VPI value.
2.3 Limitation Previous Solvers
Value iteration backs states iteratively based fixed order. Heuristic search backs
states dynamic, informed order, implied visited search. state
backed pre-order (when first visited, e.g., variants RTDP), post-order (when
searches back track, e.g., ILAO*). None algorithms use MDPs graphical structure,
intrinsic property governs complexity solving problem (Littman et al., 1995), way
decide order states solved.
Consider PhD program Finance department. Figure 1 shows MDP describes
progress PhD student. simplicity reasons, omit action nodes, transition
probabilities, cost functions. goal state set singleton G = {g}, indicates
student gets PhD degree. directed edge two states means head state one
successor state tail state least one action. initial state, s0 , describes status
entry-level student. first pass qualifying exam, consists finding
supervisor passing exam. passing exam one choose work different
supervisor (back state s0 figure). State s1 indicates student found supervisor.
works proposal, consists written document oral exam.
187

fiDAI , AUSAM , W ELD , & G OLDSMITH

s0

s1

s3

s2

s4

g

s4
Figure 1: simple MDP example. action nodes, transition probabilities, cost functions
omitted. goal state set singleton G = {g}. directed edge two states means
head state one successor state tail state action.

pass two consecutive quarters; otherwise back state s2 . passing proposal,
state s4 , needs defend thesis, passing reaches goal state g.
Observing MDP, find optimal order back states s4 , s2 s3 , till
converge, followed s0 s1 . reason value s4 depend
values non-goal states. Similarly, values s2 s3 depend values
either s0 s1 . Value iteration well heuristic search algorithms take advantage
graphical structure apply backup order, contain intelligent subroutine
discovers graphical structure, use information dynamic programming step.
intuition new approaches discover intrinsic complexity solving MDP
studying graphical structure, later contributes intelligent backup order.

3. Topological Value Iteration
describe topological value iteration (TVI) algorithm (Dai & Goldsmith, 2007).
First observe value state depends values successors. example,
suppose state s2 successor state s1 action (Ta (s2 |s1 ) > 0). Bellman equations
V (s1 ) dependent V (s2 ). case, define state s1 causally depends state s2 . Note
causal dependence relationship transitive. find causally dependent states
implicitly building reachability graph GR MDP. set vertices GR equals set
states reachable s0 . directed edge vertex s1 s2 means exists
least action Ap(s1 ), Ta (s2 |s1 ) > 0. causal relationship transitive,
directed path state s1 sk GR means s1 causally dependent sk , V (s1 ) depends
V (sk ). Also note two vertices causally dependent other, call mutual
causal dependence.
Due causal dependence, usually efficient back s2 ahead s1 .
observation, following theorem.
Theorem 1 Optimal Backup Order (Bertsekas, 2001): MDP acyclic, exists
optimal backup order. applying optimal order, optimal value function found
state needing one backup.
theorem easy prove and, furthermore, optimal backup order topological order
vertices GR . However, general, MDPs contain cycles common one state
mutually causally depend another.
two states mutually causally dependent, best order back unclear.
hand, neither state causally dependent other, order backup matter.
Finally, one state causally dependent (and vice versa), better order
188

fiT OPOLOGICAL VALUE TERATION LGORITHMS

backups state causally dependent updated later. apply idea
group together states mutually causally dependent make meta-state. make
new directed graph GM directed edge two meta-states X exists
exists two states s1 s2 action Ap(s1 ) s1 X , s2
Ta (s2 |s1 ) > 0. clear GM acyclic, otherwise states cycle mutually
causally dependent, construction rule belong meta-state.
case, back states GM topological order. Theorem 1, state
requires one meta-backup. called meta-backup since meta-state may contain multiple
states. perform meta-backup, apply dynamic programming algorithm, value
iteration, states belonging corresponding meta-state.
pseudo-code TVI shown Algorithm 2. first apply Kosarajus algorithm (Cormen,
Leiserson, Rivest, & Stein, 2001) find set strongly connected components (SCCs, metastates) causality graph GR , topological order. (id[s] indicates topological order
SCC state belongs to.) based fact reversing edges GR ,
resulting graph, G0R , strongly connected components original. using
that, get SCCs forward traversal find ordering vertices, followed
traversal reverse graph order generated first traversal. Kosarajus algorithm
efficient, time complexity linear number states. state space large,
running algorithm leads unavoidable yet acceptable overhead. many cases overhead
well compensated computational gain. use value iteration solve SCC C (as
meta-backup) topological order.
Algorithm 2 Topological Value Iteration
1: Input: MDP = hS, A, Ap, T, Ci, : threshold value
2: SCC(M )
3: 1 cpntnum
4:
0 set states id[s] =
5:
0 hS 0 , A, Ap, T, Ci
6:
VI(M 0 , )
7:

Function SCC(M )
construct GR
10: construct graph G0R reverses head tail vertices every edge GR
11: {call Kosarajus algorithm (Cormen et al., 2001). inputs GR G0R outputs cpntnum,
total number SCCs, id : [1, cpntnum], id SCC state belongs to,
topological order.}
12: return (cpntnum, id)
8:

9:

3.1 Convergence
Bellman operator contraction operation (Bertsekas, 2001), have:
Theorem 2 Topological Value Iteration guaranteed converge value function Bellman error greater .
189

fiDAI , AUSAM , W ELD , & G OLDSMITH

Proof first prove TVI guaranteed terminate finite time. Since MDP contains
finite number states, contains finite number connected components. solving
components, TVI uses value iteration. value iteration guaranteed converge
finite time (given finite ), TVI, essentially finite number value iterations, terminates
finite time.
prove TVI guaranteed converge optimal value function Bellman error
. prove induction.
First, MDP contains one SCC, TVI coincides VI, optimal algorithm.
contraction property Bellman backups, VI converges, Bellman error state
space .
Now, consider case MDP contains multiple SCCs. point, TVI working
one component C. know optimal value every state C, V (s), depends
optimal values states descendants s. also know descendant s0
must belong either C, component C 0 topologically later C. means
either value computed VI batch (s0 C), state s0 already converged
(s0 C 0 ). latter case, value convex combination states error . Inside
maximization operation Bellman equation affine combination values total
weight 1, leads overall convex combination error . Therefore,
VI finishes solving C, value must converge Bellman residual . Also note
values states belong component earlier C depend
states component C. result, component C converges, Bellman residual states
components remain unchanged thus . Combining results conclude
TVI terminates, Bellman residuals states . means Bellman
error state space .
high-level perspective, TVI decomposes MDP sub-problems finds
value state space batch manner, component component. component converged, states safely treated sink states, values depend values
states belonging later components.
3.2 Implementation
made two optimizations implementing TVI. first one uninformed reachability analysis. TVI depend initial state information. However, given information,
TVI able mark reachable components later ignore unreachable ones dynamic
programming step. reachable state space found depth-first search starting s0 ,
overhead linear |S| |A|. extremely useful small portion
state space reachable (e.g., domains International Planning Competition 2006,
see Bonet, 2006).
second optimization use heuristic values Vl () starting point. used hmin
(Bonet & Geffner, 2003b), admissible heuristic:
hmin (s) = 0 G, else


hmin (s) =
min C(s, a) + mins0 :Ta (s0 |s)>0 hmin (s0 ) .
aAp(s)

(7)

implement it, first construct new deterministic problem. action successor
pair original MDP, add new problem deterministic action cost
190

fiT OPOLOGICAL VALUE TERATION LGORITHMS

same, deterministic successor. solve new problem single, backward,
breadth-first search set goal states. Values deterministic problem hmin .
3.3 Experiments
address following questions experiments: (1) TVI compare VI
heuristic search algorithms MDPs contain multiple SCCs? (2) favorable
problem features TVI?
compared TVI several optimal algorithms, including VI (Bellman, 1957), ILAO*
(Hansen & Zilberstein, 2001), LRTDP (Bonet & Geffner, 2003b), BRTDP (McMahan et al., 2005),
Bayesian RTDP (Sanner et al., 2009) (BaRTDP), HDP (Bonet & Geffner, 2003a)1 . used
fully optimized C code ILAO* provided Eric A. Hansen additionally implemented
rest algorithms framework. performed experiments 2.5GHz
Dual-Core AMD Opteron(tm) Processor 2GB memory. Recall BRTDP BaRTDP use
upper bounds. used upper bounds described Section 4.2. used = 2 106
= 10 BRTDP BaRTDP.2 BaRTDP, used probabilistic termination condition
Algorithm 3 Sanner et al. (2009). 3
compared algorithms running time, time algorithm starts solving problem generating policy Bellman error (= 106 ). terminated algorithm find policy within five minutes. Note performance
measures anytime performance (the original motivation BaRTDP) space consumption, main motivation TVI decrease convergence time. expect TVI
steep anytime performance curve, postpones backing initial state till starts
working SCC initial state belongs to. Space, hand, less interesting
in-memory MDPs algorithms requires MDP model stored main memory dynamic programming apply. Therefore, share space limit. work
overcoming space limitation, see, example work Dai et al. (2008, 2009a).
tested algorithms set artificially-generated layered MDPs. MDP
state size |S|, partition state space evenly number nl layers, labeled integers
1, . . . , nl . allow states higher numbered layers successors states lower numbered layers, vice versa, state limited set allowable successor states,
named succ(s). layered MDP parameterized two variables: number actions
per state, na , maximum number successor states per action, ns . generating
transition function state-action pair (s, a), draw integer k uniformly [1, ns ].
k distinct successors uniformly sampled succ(s) random transition probabilities.
pick one state layer nl goal state. One property layered MDP contains
least nl connected components.
1. Notice comparison somewhat unfair TVI, since heuristic search algorithms may expand portions
state space, sub-optimality proved. Still, make comparison understand practical
benefits TVI v.s. known optimal MDP algorithms
2. termination threshold BRTDP (it terminates vu (s0 ) Vl (s0 ) < ). indicates stopping
condition heuristic search trial. detailed discussions two parameters, please refer work
McMahanet al. (2005). carefully tuned parameters.
3. termination condition may result sub-optimal policies, reported times BaRTDP paper
lower bounds. Note BaRTDP mainly aims improving anytime performance RTDP, orthogonal
convergence time. report convergence speed thorough investigation purposes.

191

fiRunning time (seconds)

DAI , AUSAM , W ELD , & G OLDSMITH

100

VI
ILAO*
LRTDP

10

TVI
BRTDP

1
1

10
100
Number layers

1000

BaRTDP

Figure 2: Running times algorithms different number layers nl random layered MDPs
|S| = 50000, na = 10, ns = 10. Note two coordinates log-scaled.
nl > 10 TVI outperforms VI, also state-of-the-art heuristic search algorithms.

several planning domains lead multi-layered MDPs. example game
Bejeweled, game difficulty levels: level least one layer. consider chess
variant without pawn promotions, played stochastic opponent. set pieces
could appear board together leads least one strongly connected component.
know multi-layered standard MDP benchmarks. Therefore, compare, section,
artificial problems study TVIs performance across controlled parameters, nl |S|.
Next section contains comprehensive experiments benchmark problems.
generated problems different parameter configurations ran algorithms
set problems. running times, process converged within cut-off, reported
Figures 2 3. element table represents median convergence time running
10 MDPs configuration.4 Note varying |S|, nl , na , ns yields many MDP
configurations. tried combinations representative ones reported. found HDP
much slower algorithms, include performance.
first experiment, fixed |S| 50,000 varied nl 1 1,000. Observing
Figure 2 first find that, one layer, performance TVI slightly worse
VI, MDP probably contains SCC contains majority state space,
defeats benefit TVI. TVI consistently outperforms VI nl > 1. nl 10,
TVI equals beats ILAO*, fastest heuristic search algorithm set problems.
nl > 10, TVI outperforms algorithms cases visible margin. Also note that,
number layers increases running times algorithms decrease.
4. picked median instead mean avoid unexpected hard problem, takes long time solve,
thereby dominating performance.

192

fiRunning time (seconds)

OPOLOGICAL VALUE TERATION LGORITHMS

162.31

60
50
40
30
20
10
0

VI
ILAO*
LRTDP
TVI
BRTDP
0

50000
State space size

100000

BaRTDP

Figure 3: Running times algorithms different state space size |S| fixed nl = 100, na = 10,
ns = 10. TVI outperforms VI, also state-of-the-art heuristic search algorithms.
relative performance TVI improves |S| increases.

MDPs become structured, therefore simpler solve. running time TVI decreases
second fastest LRTDP. LRTDP slow nl = 1 running time drops
dramatically nl increases 1 20. TVI spends nearly constant time generating
topological order SCCs, fast convergence mainly due fact VI much
efficient solving many small (and roughly equal-sized) problems large problem whose size
sum small ones. experiment shows TVI good solving MDPs
many SCCs.
second experiment, fixed nl 100 varied |S| 10,000 100,000.
find that, state space 10,000 TVI outperforms VI, BRTDP BaRTDP, slightly
underperforms ILAO* LRTDP. However, problem size grows TVI soon takes lead.
outperforms algorithms state space 20,000 larger. state space
grows 100,000, TVI solves problem 6 times fast VI, 4 times fast ILAO*, 2 times
fast LRTDP, 21 times fast BRTDP, 3 times fast BaRTDP. experiment shows
TVI even efficient problem space larger.

4. Focused Topological Value Iteration
Topological value iteration improves performance value iteration significantly
MDP many equal-sized strongly connected components. However, also observe many
MDPs evenly distributed connected components. due following reason:
state many actions, sub-optimal. sub-optimal actions, although
part optimal policy, may lead connectivity lot states. example, domains
like Blocksworld reversible actions. Due actions states mutually causally
193

fiDAI , AUSAM , W ELD , & G OLDSMITH

s4

a7

a5
C13 a6

s1

a3
s5

s3

C11
1

a4

C1

s2
C12

a12 s7

C21

a2

a9
a8

a11
a10
s6
C22

C2

Figure 4: graphical representation MDP set strongly connected components (before
knowledge sub-optimal actions). Arcs represent probabilistic transitions, e.g.,
a7 two probabilistic successors s5 s7 .

dependent. result, states connected reversible actions end forming large connected
component, making TVI slow.
hand, heuristic search powerful solution technique, successfully concentrates computation, form backups, states transitions likely
part optimal policy. However, heuristic search uses backup strategy problems,
thus missing potential savings knowing graphical structure information.
knew existence action optimal policy, could eliminate rest
actions outgoing state, thus breaking connectivity. course, information never
available. However, little help heuristic search, eliminate sub-optimal actions
problem leading reduced connectivity hopefully, smaller sizes strongly connected
components.
Figure 4 shows graphical representation part one simple MDP 7 states
12 actions. figure, successors probabilistic actions connected arc.
simplicity, transition probabilities Ta , costs C(s, a), initial state goal states omitted. Using
TVI, divide MDP two SCCs C1 C2 . However, suppose given
additional information a5 a12 sub-optimal. Based remaining actions, C1 C2
sub-divided three two smaller components respectively (as shown figure).
Dynamic programming greatly benefit new graphical structure, since solving smaller
components much easier large one.
4.1 FTVI Algorithm
key insight novel algorithm break big components smaller parts, removing actions proven suboptimal current problem hand. exploits
knowledge current initial state goal, TVI mostly ignores. call new
algorithm focused topological value iteration (FTVI) (Dai et al., 2009b). pseudo-code shown
Algorithm 3.
core, FTVI makes use action elimination theorem, states:
194

fiT OPOLOGICAL VALUE TERATION LGORITHMS

Theorem 3 Action Elimination (Bertsekas, 2001): lower bound Q (s, a) greater
upper bound V (s) action cannot optimal action state s.
gives us template eliminate actions, except need compute lower bound
Q upper bound V . FTVI keeps two bounds V simultaneously: lower
bound Vl () upper bound Vu (). Vl () initialized via admissible heuristic. note
two properties Vl : (1) Ql (s, a) computed one-step lookahead given current lower bound
value Vl () (Line 30, Algorithm 3) lower bound Q (s, a), (2) V values remain
lower bounds throughout algorithm execution process, initialized admissible
heuristic. So, lets us easily compute lower bound Q , also improves backups
performed.
Similar properties hold Vu , upper bound V , i.e., initialize Vu upper bound
perform backups based Vu successive value estimate remains upper bound.
later implementation section lists exact procedure compute lower upper bounds
domain-independent manner. note employ action elimination use lower
upper bounds, domain informative, domain-dependent bounds available,
easily plugged FTVI.
FTVI contains two sequential steps. first step, call search step, FTVI
performs small number heuristic searches similar ILAO*, i.e., backs state
per iteration. makes searches FTVI fast, still useful enough eliminate sub-optimal
actions. two main differences common heuristic search search phase FTVI.
First, backup, update upper bound manner lower bound.
reminiscent backups BRTDP (McMahan et al., 2005). Second, also check eliminate
sub-optimal actions using action elimination (Lines 3032).
second step, computation step, FTVI generates directed graph GSR
manner TVI generates GR , based remaining actions. concretely, directed
edge vertex s1 s2 exists uneliminated action Ta (s2 |s1 ) > 0.
easy see graph GSR generated always sub-graph GR . FTVI finds
connected components GSR , topological order, solves component sequentially
topological order.
state following theorem FTVI.
Theorem 4 FTVI guaranteed converge optimal value function.
correctness theorem based two facts: (1) action elimination preserves soundness,
(2) TVI optimal planning algorithm (Theorem 2).
4.2 Implementation
several interesting questions answer implementation. calculate initial
upper lower bounds? many search iterations need perform search step?
possible FTVI converges search step? still remains large component
even action elimination?
used lower bound Vl TVI (see Section 3.2). upper bound, started
simple upper bound:
195

fiDAI , AUSAM , W ELD , & G OLDSMITH

Algorithm 3 Focused Topological Value Iteration
1: Input: MDP hS, A, Ap, T, Ci, x: number search iterations batch, y: lower bound

2:
3:
4:
5:
6:
7:
8:
9:
10:
11:
12:
13:
14:
15:
16:
17:
18:
19:
20:
21:
22:
23:
24:
25:
26:
27:
28:
29:
30:
31:
32:
33:
34:
35:

percentage change initial state value new batch search iterations, : threshold
value
{step 1: search}
true
old value Vl (s0 )
iter 1 x
Bellman error 0
every state
mark every state unvisited
s0
Search(s)
Bellman error < {The value function converges}
return Vl
old value/Vl (s0 ) > (100 y)%
break
{step 2: computation}
hS, A, Ap, T, Ci
TVI(M , ) {by applying backup operator action elimination}
Function Search(s)

/ G
mark visited
argmina Q(s, a)
every unvisited successor s0 action
Search(s0 )
Bellman error max(Bellman error, Back up(s))

Function Back up(s)
action
P
Q(s, a) C(s, a) + s0 Ta0 (s0 |s)Vl (s0 )
Ql (s, a) > Vu (s)
eliminate Ap(s)
oldVl Vl (s)
Vl (s) minaAp(s) Q(s, a)
P
Vu (s) minaAp(s) [C(s, a) + s0 Ta0 (s0 |s)Vu (s0 )]
36: return |Vl (s) oldVl |

Vu (s) = 0 G, else Vu (s) = .

(8)

initialization gives us global yet loose upper bound. improve tightness,
performed backward best-first search set goal states. States visited Vu values
updated Algorithm 3, Line 35. iteratively get tighter tighter bounds
backward searches performed.
time spent search significant impact FTVI. search iterations
might eliminate enough sub-optimal actions. However, many search iterations turn
196

fiT OPOLOGICAL VALUE TERATION LGORITHMS

50
40
30

20
10
0
1

10
100
1000
Heuristic search trial #

10000

Running time (seconds)

Running time (seconds)

FTVI heuristic search algorithm trade advantage FTVI. control experiment varying total number heuristic search trials two problems. Figure 5 shows
performance Wet-floor problem matches hypothesis perfectly. Drive problem,
number search trials affect convergence speed much, many search
trials turn harmful.
15
10
5
0
1

10
100
1000
Heuristic search trial #

10000

Figure 5: Running times FTVI different number initial search trials (left) Wet-floor problem
(right) Drive problem. trials sometimes less helpful eliminating enough
sup-optimal actions, many trials harmful.

Considering tradeoff, let algorithm automatically determine number search
iterations. FTVI incrementally performs batch x search iterations. batch, computes
amount change Vl (s0 ) value. change greater y%, new batch search
performed. Otherwise, search phase considered complete. implementation, use
x = 100, = 3.
interesting case occurs optimal value found search step. Although
FTVI performs limited number search iterations, possible problem optimally solved
within search step. helpful keep track optimality information search step,
FTVI potentially skip unnecessary search iterations entire computation step.
this, need maintain Bellman error current search iteration, terminate
FTVI error smaller threshold (Lines 1112). experiment, find simple
optimization extremely helpful promoting performance FTVI.
Sometimes cases GSR still contains large connected components.
caused two reasons (1) optimal policy indeed large components, (2) connectivity caused many suboptimal actions successfully eliminated search. try decompose large components, let FTVI perform additional intra-component heuristic
searches. intra-component heuristic search takes place inside particular component.
purpose find new, sub-optimal actions, might help decompose component. Given
component C GSR , define SourceC set states none incoming transitions states C. words, states SourceC incoming bridge states
C rest MDP. intra-component heuristic search C originates state SourceC .
search branch terminates state outside C encountered.
experiments compared performance FTVI without additional
intra-component search problems four domains, namely Wet-floor (Bonet & Geffner, 2006),
197

fiDAI , AUSAM , W ELD , & G OLDSMITH

Single-arm pendulum (Wingate & Seppi, 2005), Drive, Elevator (Bonet, 2006). results
show additional intra-component search provided limited gains Wet-floor problems,
helped decrease size largest components approximately 50% average,
sped convergence 10% best. However, intra-component search turned harmful
domains, provide new graphical information (no smaller components
generated). contrary, search introduced lot unnecessary overhead.
used version perform additional intra-component search throughout rest
experiments.
4.3 Experiments
address following two questions experiments: (1) FTVI compare
algorithms broad range domain problems? (2) specific kind domains
FTVI preferred heuristic search?
implemented FTVI framework Section 3.3, used cut-off time
5 minutes algorithm per problem. investigate helpfulness action elimination,
also implemented VI variant applies action elimination backups. used
threshold value = 106 , ran BRTDP BaRTDP upper bound FTVI.
4.3.1 R ELATIVE PEED FTVI
Problem
MCar100
MCar300
MCar700
SAP100
SAP300
SAP500
WF200
WF400
DAP10
DAP20
Drive
Drive
Drive
Elevator (IPPC p13)
Elevator (IPPC p15)
Tireworld (IPPC p5)
Tireworld (IPPC p6)
Blocksworld (IPPC p4)
Blocksworld (IPPC p5)

VI
1.40
26.12
278.16
2.30
42.61
174.71
19.95
105.79
0.77
21.41
2.00
20.58
236.91
33.88
47.88
17.69
14.19

VI (w/ a.e.)
0.74
13.40
124.34
1.06
19.90
77.99
13.71
98.97
0.67
17.62
1.39
14.20
133.80
16.46
23.04
17.69
14.19

ILAO*
1.91
11.91
101.65
1.81
32.40
131.17
11.22
73.88
1.01
32.68
1.60
96.09
227.53
27.35
0.00
0.00
0.02
0.00

LRTDP
1.23
229.70
2.58
51.45
0.69
273.37
0.14
0.16
0.26
0.11

BRTDP
2.81
117.23
216.01
9.39
22.08
97.73
3.04
144.12
7.85
163.91
0.01
0.01
1.93
0.66

BaRTDP
63.55 (*)
180.64 (*)
262.92 (*)
111.59 (*)
1.99 (*)
103.87 (*)
222.33 (*)
4.17 (*)
4.17 (*)
3.94 (*)
0.03
0.04
-

TVI
0.68
23.22
233.98
2.37
44.2
20.58
100.78
0.75
21.95
1.23
13.03
74.70
58.46
14.59
2.26
48.81
54.35
54.34

FTVI
0.22
2.35
13.06
0.17
2.96
9.56
8.81
74.24
0.59
17.49
1.07
10.63
41.93
54.11
12.11
0.00
0.00
0.02
0.00

Table 1: Total running times different algorithms problems various domains. FTVI outperforms
algorithms vast margins. (Fastest times bolded. - Time means algorithm
failed solve problem within 5 minutes. *s mean algorithm terminated suboptimal solutions.)

198

fiT OPOLOGICAL VALUE TERATION LGORITHMS

Problem
MCar100
MCar300
MCar700
SAP100
SAP300
SAP500
WF200
WF400
DAP10
DAP20
Drive
Drive
Drive
Elevator (IPPC p13)
Elevator (IPPC p15)
Tireworld (IPPC p5)
Tireworld (IPPC p6)
Blocksworld (IPPC p4)
Blocksworld (IPPC p5)

Reachable |S|
10,000
90,000
490,000
10,000
90,000
250,000
40,000
160,000
10,000
160,000
4,563
29,403
75,840
539,136
539,136
671,687
724,933
103,121
103,121

TVI
BC size
ime
7,799
0.68
71,751
23.22
390,191 233.98
9,999
2.37
89,999
44.2
39,999
20.58
159,999 100.78
9,454
0.75
150,489
21.95
4,560
1.23
29,400
13.03
75,840
74.70
1,053
58.46
1,053
14.59
23
2.26
618,448
48.81
103,104
54.35
103,204
54.34

BC size
1
1
1
n/a
n/a
n/a
15,039
141,671
n/a
n/a
4,560
29,400
75,840
1,053
1,053
n/a
n/a
n/a
n/a

FTVI
Tsearch
0.20
2.22
12.29
0.17
2.96
9.56
3.30
14.27
0.59
17.49
0.11
0.15
0.18
0.01
0.01
0.00
0.00
0.02
0.00

Tgen
0.01
0.13
0.76
n/a
n/a
n/a
0.12
0.36
n/a
n/a
0.02
0.15
0.40
1.73
1.60
n/a
n/a
n/a
n/a

ime
0.22
2.35
13.06
0.17
2.96
9.56
8.81
74.24
0.59
17.49
1.07
10.63
41.93
54.11
12.11
0.00
0.00
0.02
0.00

Table 2: Detailed performance statistics TVI FTVI. (BC size means size biggest connected
component. n/a means FTVI converged search step skipped computation step.
running times seconds. Tsearch represents time used search step, Tgen
time spent generating graphical structure. Fastest times bolded. - Time means
algorithm failed solve problem within 5 minutes.)

evaluated various algorithms problems eight domains Mountain Car, Single
Double Arm Pendulum (Wingate & Seppi, 2005), Wet-floor (Bonet & Geffner, 2006)5 ,
four domains International Planning Competition 2006 Drive, Elevators, TireWorld
Blocksworld. mountain car problem usually many source states.6 chose source state
initial state, averaged statistics per problem. Table 1 lists running times
various algorithms. FTVI, additionally report (in Table 2) time used searches
(Tsearch ), time spent generating graphical structure (Tgen ), problem solved
search phase, leftover time spent solving SCCs. also compared
size biggest component (BC size) generated TVI FTVI.
Overall find FTVI outperforms five algorithms domains.
FTVI outperforms TVI domains. Notice MCar problems, FTVI establishes
favorable graphical structures (strongly connected components size one) search step.7
graphical structure makes second step FTVI trivial. TVI solve much bigger
components, runs much slower. Drive domain, even find informed
graphical structure, advanced backup action elimination enables FTVI converge faster.
5. Note used probability wet cells, p = 0.5.
6. source state state incoming transitions.
7. allow FTVI perform computation step opposed stop search step problem solved,
find similar structures Tireworld Blocksworld problems.

199

fiDAI , AUSAM , W ELD , & G OLDSMITH

FTVI outperforms heuristic search algorithms significantly domains MCar, SAP
Drive. faster ILAO* order magnitude. shows extreme effectiveness
FTVIs decomposing problem small sub-problems using advanced graphical information
solving sub-problems sequentially. three RTDP algorithms competitive
algorithms domains, fail return solution cutoff time many
problems. FTVI shows limited speedup heuristic search domains Wet-floor, DAP,
Elevator. FTVI par ILAO*, vastly outperforms TVI Tireworld Blocksworld
domains, converges within search step. convergence speed value iteration typically
slow, backs states iteratively fixed order. Adding action elimination Bellman backups
increases convergence speed VI two times, especially Mountain Car, Single Arm
Pendulum, Elevator domains, convergence speed usually least one magnitude slower
FTVI.
4.3.2 FACTORS ETERMINING P ERFORMANCE
shown FTVI faster heuristic search algorithms many domains, relative
speedup domain-dependent. find domain features particularly beneficial
FTVI worse heuristic search algorithms? evaluation performed control experiments
varying domains across different features study effect planning time various
algorithms.
make initial prediction three features.
1. number goals domain: number goal states small, search may take
long time discovers path goal. Therefore, many sub-optimal policies might
evaluated heuristic search algorithm.
2. Search depth initial state goal state: depth lower bound length
execution trial also size policy graph. greater depth implies
search steps per iteration, might make evaluating policy time-consuming.
3. Heuristic informativeness: performance heuristic search algorithm depends lot
quality initial heuristic function. expect win FTVI increase
heuristic less informed.
Number Goals. far know, suitable domain specify
total number goal states arbitrarily, used artificial domain. domain
state two applicable actions, action two random successors. tested
algorithms domains two sizes, 10,000 (Figure 6(left)) 50,000 (Figure 6(right)).
problem size, fixed shortest goal distance varied number goal states, |G|.
concretely, generating state transitions, performed BFS initial state,
randomly picked goal states search depth. |G| value, generated 10 problems,
reported median running time four algorithms (LRTDP BaRTDP slow
domain). observe algorithms take time solve problem smaller number
goal states larger number. However, beyond point (|G| > 20 experiments),
running times become stable. FTVI runs marginally slower |G| small, suggesting
performance less dependent number goal states. BRTDP second best
handling small goal sets, runs nearly fast FTVI goal set large. Even though
200

fi1.4
1.2
1
0.8
0.6
0.4
0.2
0

ILAO*

Running time (seconds)

Running time (seconds)

OPOLOGICAL VALUE TERATION LGORITHMS

TVI
FTVI
BRTDP

0

20
40
60
80
Number goal states

100

7
6
5
4
3
2
1
0

ILAO*
TVI
FTVI
BRTDP

0

20

40
60
80
Number goal states

100

Figure 6: Running times algorithms different number goal states problem size (left) |S| =
10, 000 (right) |S| = 50, 000 random MDPs. FTVI TVI slow least significantly
number goal states small.

TVI runs slowest among four algorithms, performance shows less severe dependence
number goal states. runs almost fast ILAO* goal set size 1. contrast,
ILAO* runs twice fast TVI goal set size greater 20.
Search Depth. experiment, studied search depth goal initial
state influences performance various algorithms. chose Mountain car problem
Single-arm pendulum problem. randomly picked 100 initial states state space8
measured shallowest search depth, or, shortest distance, d, goal state. running times
Figure 7 ordered d. BaRTDP terminate optimal policy many instances,
performance shown. BRTDP biggest variance performance included
clarity purposes.
see, FTVI fastest algorithm suite experiments. converges
quickly initial states (usually around one two seconds Mcar300, less 10 seconds SAP300). TVIs performance unaffected search depth, expected, since
variant value iteration search component. MCar300 problem,
find strong evidence running time algorithm depends search depth. FTVI runs
order magnitude faster TVI, ILAO*, BRTDP two orders magnitude faster
LRTDP. SAP300 problems, running times algorithms except TVI increase
search depth increases. LRTDP runs fast relatively small, slows considerably
unable solve many problems becomes larger. ILAO*s convergence speed varies
bit distance small. increases, running time also increases. BRTDPs performance (not included) close ILAO* small, becomes slower performs
similar LRTDP large. problem, heuristic search algorithms unanimously suffer
significantly increase search depth, running times increase least two
orders magnitude small large values. hand, FTVI slows one
order magnitude, makes converge one order magnitude faster ILAO*, one two
orders magnitude faster BRTDP TVI, two orders magnitude faster LRTDP
large depths.
8. Note problems well-defined initial states. picked initial states arbitrarily S.

201

fiDAI , AUSAM , W ELD , & G OLDSMITH

1000

TVI

100

FTVI

10
1
0.1

0

200

0.01

0.001

Running time (seconds)

Running time (seconds)

1000

FTVI

10
1
0

100

200

Running time (seconds)

Running time (seconds)

FTVI

1
0.1

0

200

0.01
Shortest goal distance

1000

TVI

100

0.01

LRTDP

10

0.001

Shortest goal distance

1000

0.1

ILAO*

100

LRTDP

10

FTVI

1
0.1
0.01

Shortest goal distance

ILAO*

100

0

100

200

Shortest goal distance

Figure 7: Running times algorithms different shortest distance goal (top) mountain car
300 300 (MCar300), (bottom) single-arm pendulum 300 300 (SAP300) problems, (left) comparison FTVI TVI, (right) comparison FTVI heuristic search algorithms. Heuristic search algorithms slow massively (note log scale) search depth large.

Heuristic Quality. Finally studied effect heuristic informativeness algorithms. conducted two sets experiments, based two sets consistent heuristics. found
BRTDP slower algorithms problems BaRTDP comparable (about 50%
slower LRTDP) Wet100 problem, include running times.
first experiment, pre-computed optimal value function problem using value iteration,
used fraction optimal value initial heuristic. Given fraction f (0, 1],
calculated h(s) = f V (s). Figure 8 plots running times different algorithms f
three problems. Note f = 1 means initial heuristic already optimal, problem trivial
algorithms, TVI overhead building topological structure. FTVI, however,
able detect convergence search step circumvent overhead, fast. LRTDP
slow Wet100 problem, running times problem omitted figure.
figure shows f increases (i.e. heuristic becomes informative) running times
algorithms decrease almost linearly. true even TVI, heuristic-guided
algorithm, takes less time, probably initial values affect number iterations
required convergence.
thoroughly study influence heuristics, conducted second set experiments.
experiment, used fractional Vl value initial heuristic. Recall Vl lower
bound V computed value deterministic problem. calculated initial heuristic
202

fiILAO*
LRTDP

0.5

TVI
FTVI

0
0

0.5
f

1

3
2.5
2
1.5
1
0.5
0

ILAO*
LRTDP
TVI
FTVI
0

0.5
f

1

5
4
3

ILAO*

2

TVI

1

FTVI

0
0

0.5
f

1

Running time (seconds)

1

Running time (seconds)

1.5

Running time (seconds)

Running time (seconds)

Running time (seconds)

Running time (seconds)

OPOLOGICAL VALUE TERATION LGORITHMS

8
6
ILAO*

4

LRTDP

2

TVI

0

FTVI
0

0.5
f

1

3
2.5
2
1.5
1
0.5
0

ILAO*
LRTDP
TVI
FTVI
0

0.5
f

1

5
4
3

ILAO*

2

TVI

1

FTVI

0
0

0.5
f

1

Figure 8: Running times algorithms different initial heuristic (top) mountain car 100 100
(MCar100), (middle) single-arm pendulum 100100 (SAP100), (bottom) wet-floor 100100
(WF100)
problems.
sensitive
P
P algorithms equally
P
P heuristic informativeness. (left) f
= sS h(s)/ sS V (s) (right) f = sS h(s)/ sS Vl (s).

h(s) = f Vl (s). included algorithms show similar smooth decrease running time
f increases. BRTDP, however, shows strong dependence heuristics Wet100 problem.
running time decreases sharply 96.91 seconds 0.54 seconds 99.81 seconds
6.21 seconds f = 0.02 f = 1 two experiments. Stable changes two
experiments suggests following algorithms except BRTDP. (1) algorithm particularly
vulnerable less informed heuristic function; (2) extremely informative heuristics (when f
close 1) necessarily lead extra fast convergence. result in-line results
deterministic domains (Helmert & Roger, 2008).
203

fiDAI , AUSAM , W ELD , & G OLDSMITH

4.3.3 ISCUSSION
experiments, learn FTVI vastly better domains whose problems small
number goal states long search depth initial state goal (such MCar, SAP
Drive). convergence control module FTVI helps successfully matching performance FTVI fastest heuristic search algorithm. addition, FTVI displays limited
advantage heuristic search two intermediate cases problem (1) many goal
states long search depth (Elevator), (2) short depth fewer goal states (DAP). conclusion, FTVI algorithm choice whenever problem either small number goal states
long search depth.

5. Related Work
Besides TVI several researchers proposed decomposing MDP sub-problems
combining solutions final policy, e.g., work Hauskrecht et al. (1998) Parr
(1998). However, approaches typically assume additional structure problem,
either known hierarchies, known decomposition weakly coupled sub-MDPs, etc., whereas
FTVI assumes additional structure.
BRTDP (McMahan et al., 2005), Bayesian RTDP (Sanner et al., 2009) Focused RTDP
(Smith & Simmons, 2006) (FRTDP) also keep upper bound value function. However,
algorithms use upper bound purely judge close state convergence, comparing
difference upper lower bound values. example, BRTDP tries make
searches focus states whose two bounds larger differences, intuitively, states whose
values less converged. Unlike FTVI, three algorithms perform action elimination,
use connected component information solve MDP. performance BRTDP
(and similarly Bayesian RTDP) highly dependent quality heuristics. Furthermore,
FRTDP works discounted setting, thus immediately applicable stochastic
shortest path problems.
HDP similar TVI sense uses Tarjans algorithm (slightly different
Kosarajus algorithm) find strongly connected components greedy graph. computes
SCCs multiple times dynamically depth-first searches HDP tries label
solved states. find topological order SCCs decompose problem
use topological order sequentially solve SCC.
Prioritized sweeping (Moore & Atkeson, 1993) extensions, focussed dynamic programming (Ferguson & Stentz, 2004) improved prioritized sweeping (McMahan & Gordon, 2005),
order backups intelligently help priority queue. state queue prioritized
based potential improvement value backup state. Dai Hansen (2007)
demonstrate algorithms large overhead maintaining priority queue
outperformed simple backward search algorithm, implicitly prioritizes backups without
priority queue. Moreover, prioritized sweeping improved prioritized sweeping find optimal
value entire state space MDP, use initial state information. Focussed
dynamic programming, however, able make use initial state information,
optimal algorithm. three algorithms massively outperformed LAO* variant (Dai &
Hansen, 2007).
MDP large solved optimally, another thread work solves MDPs approximately. typical way use deterministic relaxations MDP and/or basis
204

fiT OPOLOGICAL VALUE TERATION LGORITHMS

functions (Guestrin, Koller, Parr, & Venkataraman, 2003; Poupart, Boutilier, Patrascu, & Schuurmans, 2002; Patrascu, Poupart, Schuurmans, Boutilier, & Guestrin, 2002; Yoon, Fern, & Givan,
2007; Kolobov, Mausam, & Weld, 2009, 2010a, 2010b). techniques algorithms
orthogonal ones FTVI, interesting future direction approximate FTVI
applying basis functions.
MDP maintains logical representation, another type algorithm aggregates groups
states MDP features, represents factored MDP using algebraic Boolean decision diagrams (ADDs BDDs) solves factored MDP using ADD BDD operations;
SPUDD (Hoey, St-Aubin, Hu, & Boutilier, 1999), sLAO* (Feng & Hansen, 2002), sRTDP (Feng,
Hansen, & Zilberstein, 2003) examples. factored representation exponentially simpler flat MDP, computation efficiency problem-dependent. idea algorithms orthogonal (F)TVI. Exploring ways combining ideas (F)TVI
compact logical representation achieve performance improvements remains future work.
Action elimination originally proposed Bertsekas (2001). proved
helpful RTDP factored MDP setting (Kuter & Hu, 2007), cost action
depends state variables. Action elimination also useful temporal planning
(Mausam & Weld, 2008). extended combo-elimination, rule prune irrelevant
action combinations setting multiple actions executed time.
idea finding topological order strongly connected components MDP
extended solving partially-observable MDPs (POMDPs). POMDP problem typically
much harder MDP problem since decision agent partial information
current state (Littman et al., 1995). topological order-based planner (POT) (Dibangoye, Shani,
Chaib-draa, & Mouaddib, 2009) uses topological order information underlying MDPs
help solve POMDP problem faster. believe idea extended help solve even harder
problems, decentralized POMDP (Bernstein, Givan, Immerman, & Zilberstein, 2002),
future.

6. Conclusions
work makes several contributions. First, present two new optimal algorithms solve
MDPs, topological value iteration (TVI) focused topological value iteration (FTVI). TVI studies
graphical structure MDP breaking strongly connected components solves
MDP based topological order components. FTVI extends topological value iteration
algorithm focusing construction strongly connected components transitions likely
belong optimal policy. FTVI using small amount heuristic search eliminate
provably suboptimal actions. contrast TVI, care goal-state information,
FTVI removes transitions determines irrelevant optimal policy reaching
goal. sense, FTVI builds much informative topological structure TVI.
Second, show empirically TVI outperforms VI state-of-the-art algorithms
MDP contains many strongly connected components. find TVI advantageous problems multiple equal-sized components.
Third, show empirically FTVI outperforms TVI VI large number domains,
usually order magnitude. performance due success informed
graphical structure, since sizes connected components found FTVI vastly smaller
constructed TVIs.
205

fiDAI , AUSAM , W ELD , & G OLDSMITH

Fourth, find surprisingly many domains FTVI massively outperforms popular heuristic search algorithms convergence speed, ILAO*, LRTDP, BRTDP BaRTDP.
analyzing performance algorithms different problems, find smaller number goal states long search depth goal two key features problems especially
hard heuristic search handle. results show FTVI outperforms heuristic search
domains order magnitude.
Finally, by-product also compare ILAO*, LRTDP, BRTDP BaRTDP (four popular,
state-of-the-art heuristic search algorithms) find strength algorithm usually
domain-specific. Generally, ILAO* faster convergence algorithms. BRTDP
BaRTDP slow domains probably due fact vulnerable problems lack informed upper bounds.

Acknowledgments
work conducted Peng Dai student University Washington. work
supported Office Naval Research grant N00014-06-1-0147, National Science Foundation
IIS-1016465, ITR-0325063 WRF / TJ Cable Professorship. thank Eric A. Hansen
sharing code ILAO*, anonymous reviewers excellent suggestions improving
manuscript.

References
Aberdeen, D., Thiebaux, S., & Zhang, L. (2004). Decision-Theoretic Military Operations Planning. Proc. 14th International Conference Automated Planning Scheduling
(ICAPS-04), pp. 402412.
Barto, A., Bradtke, S., & Singh, S. (1995). Learning act using real-time dynamic programming.
Artificial Intelligence J., 72, 81138.
Bellman, R. (1957). Dynamic Programming. Princeton University Press, Princeton, NJ.
Bernstein, D. S., Givan, R., Immerman, N., & Zilberstein, S. (2002). Complexity Decentralized Control Markov Decision Processes. Mathematics Opererations Research, 27(4),
819840.
Bertsekas, D. P. (2000-2001). Dynamic Programming Optimal Control, Vol. 2. Athena Scientific.
Bertsekas, D. P., & Tsitsiklis, J. N. (1996). Neuro-Dynamic Programming. Athena Scientific,
Belmont, MA.
Bonet, B., & Geffner, H. (2003a). Faster Heuristic Search Algorithms Planning Uncertainty
Full Feedback. Proc. 18th International Joint Conf. Artificial Intelligence (IJCAI03), pp. 12331238. Morgan Kaufmann.
Bonet, B., & Geffner, H. (2003b). Labeled RTDP: Improving Convergence Real-time Dynamic Programming. Proc. 13th International Conference Automated Planning
Scheduling (ICAPS-03), pp. 1221.
206

fiT OPOLOGICAL VALUE TERATION LGORITHMS

Bonet, B. (2006). Non-Deterministic Planning Track 2006 International Planning Competition.. http://www.ldc.usb.ve/bonet/ipc5/.
Bonet, B. (2007). Speed Convergence Value Iteration Stochastic Shortest-Path
Problems. Mathematics Operations Research, 32(2), 365373.
Bonet, B., & Geffner, H. (2006). Learning Depth-First Search: Unified Approach Heuristic
Search Deterministic Non-deterministic Settings, Applications MDPs. Proc.
16th International Conference Automated Planning Scheduling (ICAPS-06), pp.
142151.
Bresina, J. L., Dearden, R., Meuleau, N., Ramkrishnan, S., Smith, D. E., & Washington, R. (2002).
Planning Continuous Time Resource Uncertainty: Challenge AI. Proc.
18th Conf. Uncertainty AI (UAI-02), pp. 7784.
Cormen, T. H., Leiserson, C. E., Rivest, R. L., & Stein, C. (2001). Introduction Algorithms,
Second Edition. MIT Press.
Dai, P., & Goldsmith, J. (2007). Topological Value Iteration Algorithm Markov Decision Processes. Proc. IJCAI, pp. 18601865.
Dai, P., & Hansen, E. A. (2007). Prioritizing Bellman Backups Without Priority Queue. Proc.
17th International Conference Automated Planning Scheduling (ICAPS-07), pp.
113119.
Dai, P., Mausam, & Weld, D. S. (2008). Partitioned External-Memory Value Iteration. AAAI, pp.
898904.
Dai, P., Mausam, & Weld, D. S. (2009a). Domain-Independent, Automatic Partitioning Probabilistic Planning. IJCAI, pp. 16771683.
Dai, P., Mausam, & Weld, D. S. (2009b). Focused Topological Value Iteration. Proc. ICAPS,
pp. 8289.
Dibangoye, J. S., Shani, G., Chaib-draa, B., & Mouaddib, A.-I. (2009). Topological Order Planner
POMDPs. Proc. IJCAI, pp. 16841689.
Feng, Z., & Hansen, E. A. (2002). Symbolic Heuristic Search Factored Markov Decision Processes. Proc. 17th National Conference Artificial Intelligence (AAAI-05).
Feng, Z., Hansen, E. A., & Zilberstein, S. (2003). Symbolic Generalization On-line Planning.
Proc. 19th Conference Uncertainty Artificial Intelligence (UAI-03), pp. 209216.
Feng, Z., & Zilberstein, S. (2004). Region-Based Incremental Pruning POMDPs. Proc.
UAI, pp. 146153.
Ferguson, D., & Stentz, A. (2004). Focussed Dynamic Programming: Extensive Comparative Results. Tech. rep. CMU-RI-TR-04-13, Carnegie Mellon University, Pittsburgh, PA.
Guestrin, C., Koller, D., Parr, R., & Venkataraman, S. (2003). Efficient Solution Algorithms
Factored MDPs. J. Artificial Intelligence Research, 19, 399468.
207

fiDAI , AUSAM , W ELD , & G OLDSMITH

Hansen, E. A., & Zilberstein, S. (2001). LAO*: heuristic search algorithm finds solutions
loops. Artificial Intelligence J., 129, 3562.
Hauskrecht, M., Meuleau, N., Kaelbling, L. P., Dean, T., & Boutilier, C. (1998). Hierarchical
Solution Markov Decision Processes using Macro-actions. Proc. UAI, pp. 220229.
Helmert, M., & Roger, G. (2008). Good Almost Perfect?. Proc. AAAI, pp. 944949.
Hoey, J., St-Aubin, R., Hu, A., & Boutilier, C. (1999). SPUDD: Stochastic Planning using Decision
Diagrams. Proc. 15th Conference Uncertainty Artificial Intelligence (UAI-95),
pp. 279288.
Kolobov, A., Mausam, & Weld, D. S. (2009). ReTrASE: Intergating Paradigms Approximate
Probabilistic Planning. Proc. IJCAI, pp. 17461753.
Kolobov, A., Mausam, & Weld, D. S. (2010a). Classical Planning MDP Heuristics: Little
Help Generalization. Proc. ICAPS, pp. 97104.
Kolobov, A., Mausam, & Weld, D. S. (2010b). SixthSense: Fast Reliable Recognition Dead
Ends MDPs. Proc. AAAI.
Kuter, U., & Hu, J. (2007). Computing Using Lower Upper Bounds Action Elimination
MDP Planning. SARA, pp. 243257.
Littman, M. L., Dean, T., & Kaelbling, L. P. (1995). Complexity Solving Markov Decision
Problems. Proc. 11th Annual Conference Uncertainty Artificial Intelligence
(UAI-95), pp. 394402 Montreal, Quebec, Canada.
Mausam, Benazera, E., Brafman, R. I., Meuleau, N., & Hansen, E. A. (2005). Planning
Continuous Resources Stochastic Domains. Proc. IJCAI, pp. 12441251.
Mausam, & Weld, D. S. (2008). Planning Durative Actions Stochastic Domains. J.
Artificial Intelligence Research (JAIR), 31, 3382.
McMahan, H. B., & Gordon, G. J. (2005). Fast Exact Planning Markov Decision Processes.
Proc. 15th International Conference Automated Planning Scheduling (ICAPS05).
McMahan, H. B., Likhachev, M., & Gordon, G. J. (2005). Bounded real-time dynamic programming: RTDP monotone upper bounds performance guarantees. Proceedings
22nd international conference Machine learning (ICML-05), pp. 569576.
Meuleau, N., Benazera, E., Brafman, R. I., Hansen, E. A., & Mausam (2009). Heuristic Search
Approach Planning Continuous Resources Stochastic Domains. J. Artificial
Intellegence Research (JAIR), 34, 2759.
Moore, A., & Atkeson, C. (1993). Prioritized Sweeping: Reinforcement Learning Less Data
Less Real Time. Machine Learning, 13, 103130.
208

fiT OPOLOGICAL VALUE TERATION LGORITHMS

Musliner, D. J., Carciofini, J., Goldman, R. P., E. H. Durfee, J. W., & Boddy, M. S. (2007). Flexibly
Integrating Deliberation Execution Decision-Theoretic Agents. ICAPS Workshop
Planning Plan-Execution Real-World Systems.
Nilson, N. J. (1980). Principles Artificial Intelligence. Tioga Publishing Company, Palo Alto,
Ca.
Parr, R. (1998). Flexible Decomposition Algorithms Weakly Coupled Markov Decision Problems. Proc. UAI, pp. 422430.
Patrascu, R., Poupart, P., Schuurmans, D., Boutilier, C., & Guestrin, C. (2002). Greedy Linear
Value-Approximation Factored Markov Decision Processes. Proc. 17th National
Conference Artificial Intelligence (AAAI-02), pp. 285291.
Poupart, P., Boutilier, C., Patrascu, R., & Schuurmans, D. (2002). Piecewise Linear Value Function
Approximation Factored MDPs. Proc. 18th National Conference Artificial
Intelligence (AAAI-02), pp. 292299.
Sanner, S., Goetschalckx, R., Driessens, K., & Shani, G. (2009). Bayesian Real-Time Dynamic
Programming. Proc. IJCAI, pp. 17841789.
Smith, T., & Simmons, R. G. (2006). Focused Real-Time Dynamic Programming MDPs:
Squeezing Heuristic. Proc. 21th National Conference Artificial
Intelligence (AAAI-06).
Wingate, D., & Seppi, K. D. (2005). Prioritization Methods Accelerating MDP Solvers. J.
Machine Learning Research, 6, 851881.
Yoon, S., Fern, A., & Givan, R. (2007). FF-Replan: Baseline Probabilistic Planning. Proc.
17th International Conference Automated Planning Scheduling (ICAPS-07), pp.
352359.

209

fiJournal Artificial Intelligence Research 42 (2011) 427-486

Submitted 1/11; published 11/11

Adaptive Submodularity: Theory Applications Active Learning
Stochastic Optimization
Daniel Golovin

DGOLOVIN @ CALTECH . EDU

California Institute Technology
Pasadena, CA 91125, USA

Andreas Krause

KRAUSEA @ ETHZ . CH

Swiss Federal Institute Technology
8092 Zurich, Switzerland

Abstract
Many problems artificial intelligence require adaptively making sequence decisions
uncertain outcomes partial observability. Solving stochastic optimization problems
fundamental notoriously difficult challenge. paper, introduce concept
adaptive submodularity, generalizing submodular set functions adaptive policies. prove
problem satisfies property, simple adaptive greedy algorithm guaranteed
competitive optimal policy. addition providing performance guarantees
stochastic maximization coverage, adaptive submodularity exploited drastically speed
greedy algorithm using lazy evaluations. illustrate usefulness concept
giving several examples adaptive submodular objectives arising diverse AI applications
including management sensing resources, viral marketing active learning. Proving adaptive
submodularity problems allows us recover existing results applications
special cases, improve approximation guarantees handle natural generalizations.

1. Introduction
many problems arising artificial intelligence one needs adaptively make sequence decisions, taking account observations outcomes past decisions. Often outcomes
uncertain, one may know probability distribution them. Finding optimal policies
decision making partially observable stochastic optimization problems notoriously intractable (see, e.g. Littman, Goldsmith, & Mundhenk, 1998). fundamental challenge identify
classes planning problems simple solutions obtain (near-) optimal performance.
paper, introduce concept adaptive submodularity, prove partially
observable stochastic optimization problem satisfies property, simple adaptive greedy algorithm guaranteed obtain near-optimal solutions. fact, reasonable complexity-theoretic
assumptions, polynomial time algorithm able obtain better solutions general. Adaptive
submodularity generalizes classical notion submodularity1 , successfully used
develop approximation algorithms variety non-adaptive optimization problems. Submodularity, informally, intuitive notion diminishing returns, states adding element
small set helps adding element larger (super-) set. celebrated result
work Nemhauser, Wolsey, Fisher (1978) guarantees submodular functions,
simple greedy algorithm, adds element maximally increases objective value,
1. extensive treatment submodularity, see books Fujishige (2005) Schrijver (2003).

c
2011
AI Access Foundation. rights reserved.

fiG OLOVIN & K RAUSE

selects near-optimal set k elements. Similarly, guaranteed find set near-minimal
cost achieves desired quota utility (Wolsey, 1982), using near-minimum average time
(Streeter & Golovin, 2008). Besides guaranteeing theoretical performance bounds, submodularity allows us speed algorithms without loss solution quality using lazy evaluations (Minoux, 1978), often leading performance improvements several orders magnitude (Leskovec,
Krause, Guestrin, Faloutsos, VanBriesen, & Glance, 2007). Submodularity shown
useful variety problems artificial intelligence (Krause & Guestrin, 2009a).
challenge generalizing submodularity adaptive planning action taken
step depends information obtained previous steps feasible solutions
policies (decision trees conditional plans) instead subsets. propose natural generalization diminishing returns property adaptive problems, reduces classical
characterization submodular set functions deterministic distributions. show
results Nemhauser et al. (1978), Wolsey (1982), Streeter Golovin (2008), Minoux (1978)
generalize adaptive setting. Hence, demonstrate adaptive submodular optimization
problems enjoy theoretical practical benefits similar classical, nonadaptive submodular problems. demonstrate usefulness generality concept showing
captures known results stochastic optimization active learning special cases, admits
tighter performance bounds, leads natural generalizations allows us solve new problems
performance guarantees known.
first example, consider problem deploying (or controlling) collection sensors
monitor spatial phenomenon. sensor cover region depending sensing range.
Suppose would like find best subset k locations place sensors. application,
intuitively, adding sensor helps placed sensors far helps less
already placed many sensors. formalize diminishing returns property using notion
submodularity total area covered sensors submodular function defined
sets locations. Krause Guestrin (2007) show many realistic utility functions
sensor placement (such improvement prediction accuracy w.r.t. probabilistic model)
submodular well. consider following stochastic variant: Instead deploying fixed
set sensors, deploy one sensor time. certain probability, deployed sensors fail,
goal maximize area covered functioning sensors. Thus, deploying
next sensor, need take account sensors deployed past failed.
problem studied Asadpour, Nazerzadeh, Saberi (2008) case
sensor fails independently random. paper, show coverage objective
adaptive submodular, use concept handle much general settings (where, e.g., rather
all-or-nothing failures different types sensor failures varying severity). also
consider related problem goal place minimum number sensors achieve
maximum possible sensor coverage (i.e., coverage obtained deploying sensors everywhere),
generally goal may achieve fixed percentage maximum possible sensor
coverage. first goal, problem equivalent one studied Goemans Vondrak
(2006), generalizes problem studied Liu, Parthasarathy, Ranganathan, Yang (2008).
maximum coverage version, adaptive submodularity allows us recover generalize
previous results.
another example, consider viral marketing problem, given social network,
want influence many people possible network buy product.
giving product free subset people, hope convince friends
428

fiA DAPTIVE UBMODULARITY: HEORY PPLICATIONS

buy product well. Formally, graph, edge e labeled number
0 pe 1. influence subset nodes graph, influenced node,
neighbors get randomly influenced according probability annotated edge connecting
nodes. process repeats node gets influenced. Kempe, Kleinberg,
Tardos (2003) show set function quantifies expected number nodes influenced
submodular. natural stochastic variant problem pick node, get see
nodes influenced, adaptively pick next node based observations
on. show large class adaptive influence maximization problems satisfies adaptive
submodularity.
third application active learning, given unlabeled data set,
would like adaptively pick small set examples whose labels imply labels.
problem arises automated diagnosis, hypotheses state system (e.g.,
illness patient has), would like perform tests identify correct hypothesis.
domains want pick examples / tests shrink remaining version space (the set consistent
hypotheses) quickly possible. Here, show reduction version space probability
mass adaptive submodular, use observation prove adaptive greedy algorithm
near-optimal querying policy, recovering generalizing results Kosaraju, Przytycka,
Borgstrom (1999) Dasgupta (2004). results active learning automated diagnosis
also related recent results Guillory Bilmes (2010, 2011) study generalizations
submodular set cover interactive setting. contrast approach however, Guillory
Bilmes analyze worst-case costs, use rather different technical definitions proof techniques.
summarize main contributions below, provide technical summary Table 1.
high level, main contributions are:
consider particular class partially observable adaptive stochastic optimization problems, prove hard approximate general.
introduce concept adaptive submodularity, prove problem instance satisfies property, simple adaptive greedy policy performs near-optimally, adaptive
stochastic maximization coverage, also natural min-sum objective.
show adaptive submodularity exploited allowing use accelerated
adaptive greedy algorithm using lazy evaluations, obtain data-dependent
bounds optimum.
illustrate adaptive submodularity several realistic problems, including Stochastic Maximum Coverage, Stochastic Submodular Coverage, Adaptive Viral Marketing, Active
Learning. applications, adaptive submodularity allows us recover known results
prove natural generalizations.
1.1 Organization
article organized follows. 2 (page 430) set notation formally define relevant adaptive optimization problems general objective functions. readers convenience,
also provided reference table important symbols page 480. 3 (page 433) review classical notion submodularity introduce novel adaptive submodularity property.

429

fiG OLOVIN & K RAUSE

Name
A.S. Maximization

New Results
Tight (1 1/e)-approx. A.M.S. objectives

A.S. Min Cost Coverage

Tight logarithmic approx. A.M.S. objectives

A.S. Min Sum Cover

Tight 4-approx. A.M.S. objectives

Data Dependent Bounds

Generalization A.M.S. functions

Accelerated Greedy
Stochastic Submodular
Maximization
Stochastic Set Cover

Generalization lazy evaluations adaptive setting
Generalization previous (1 1/e)-approx.
arbitrary peritem set distributions, item costs
Generalization previous (ln(n) + 1)-approx.
arbitrary per-item set distributions, item costs
Adaptive analog previous (1 1/e)-approx. nonadaptive viral marketing, general reward
functions; tight logarithmic approx. adaptive min
cost cover version
Improved approx. factor generalized binary search
approximate versions without item costs
(|E|1 )-approximation hardness A.S. Maximization, Min Cost Coverage, Min-Sum Cover, f
adaptive submodular.

Adaptive Viral
Marketing

Active Learning
Hardness absence
Adapt. Submodularity

Location
5.1,
page 438
5.2,
page 440
5.3,
page 443
5.1,
page 438
4, page 436
6, page 445
7, page 446
8, page 448

9, page 454
12,
page 464

Table 1: Summary theoretical results. A.S. shorthand adaptive stochastic, A.M.S.
shorthand adaptive monotone submodular.
4 (page 436) introduce adaptive greedy policy, well accelerated variant. 5
(page 438) discuss theoretical guarantees adaptive greedy policy enjoys applied
problems adaptive submodular objectives. Sections 6 9 provide examples
apply adaptive submodular framework various applications, namely Stochastic Submodular
Maximization (6, page 445), Stochastic Submodular Coverage (7, page 446), Adaptive Viral Marketing (8, page 448), Active Learning (9, page 454). 10 (page 459) report empirical
results two sensor selection problems. 11 (page 462) discuss adaptivity gap
problems consider, 12 (page 464) prove hardness results indicating problems
adaptive submodular extremely inapproximable reasonable complexity
assumptions. review related work 13 (page 465) provide concluding remarks 14
(page 467). Appendix (page 468) gives details incorporate item costs includes
proofs omitted main text.

2. Adaptive Stochastic Optimization
start introducing notation defining general class adaptive optimization problems
address paper. sake clarity, illustrate notation using sensor
placement application mentioned 1. give examples applications 6, 7, 8, 9.
430

fiA DAPTIVE UBMODULARITY: HEORY PPLICATIONS

2.1 Items Realizations
Let E finite set items (e.g., sensor locations). item e E particular (initially
unknown) state set possible states (describing whether sensor placed location e
would malfunction not). represent item states using function : E O, called
realization (of states items ground set). Thus, say (e) state e
realization . use denote random realization. take Bayesian approach
assume known prior probability distribution p () := P [ = ] realizations (e.g.,
modeling sensors fail independently failure probability), compute posterior
distributions2 . consider problems sequentially pick item e E, get see
state (e), pick next item, get see state, (e.g., place sensor, see whether
fails, on). pick, observations far represented partial realization
, function subset E (i.e., set items already picked) states
(e.g., encodes placed sensors failed). notational convenience,
sometimes represent relation, E equals {(e, o) : (e) = o}. use
notation dom() = {e : o.(e, o) } refer domain (i.e., set items observed
). partial realization consistent realization equal everywhere
domain . case write . 0 consistent ,
dom() dom( 0 ), say subrealization 0 . Equivalently, subrealization 0
if, viewed relations, 0 .
Partial realizations similar notion belief states Partially Observable Markov
Decision Problems (POMDPs), encode effect actions taken (items selected)
observations made, determine posterior belief state world (i.e., state
items e yet selected, p ( | ) := P [ = | ]).
2.2 Policies
encode adaptive strategy picking items policy , function set
partial realizations E, specifying item pick next particular set observations
(e.g., chooses next sensor location given placed sensors far, whether
failed not). also allow randomized policies functions set partial realizations
distributions E, though emphasis primarily deterministic policies.
domain , policy terminates (stops picking items) upon observation . use dom()
denote domain . Technically, require dom() closed subrealizations.
is, 0 dom() subrealization 0 dom(). use notation
E(, ) refer set items selected realization . deterministic policy
associated decision tree natural way (see Fig. 1 illustration). Here,
adopt policy-centric view admits concise notation, though find decision tree view
valuable conceptually.
Since partial realizations similar POMDP belief states, definition policies similar
notion policies POMDPs, usually defined functions belief states
actions. discuss relationship stochastic optimization problems
considered paper POMDPs Section 13.
2. situations, may exact knowledge prior p (). Obtaining algorithms robust
incorrect priors remains interesting source open problems. briefly discuss robustness guarantees
algorithm 4 page 437.

431

fiG OLOVIN & K RAUSE

Figure 1: Illustration policy , corresponding decision tree representation, decision
tree representation [2] , level 2 truncation (as defined 5.1).

2.3 Adaptive Stochastic Maximization, Coverage, Min-Sum Coverage
wish maximize, subject constraints, utility function f : 2E OE R0
depends items pick state item (e.g., modeling total area
covered working sensors). Based notation, expected utility policy
favg () := E [f (E(, ), )] expectation taken respect p (). goal
Adaptive Stochastic Maximization problem find policy
arg max favg () subject |E(, )| k ,

(2.1)



k budget many items picked (e.g., would like adaptively choose k
sensor locations working sensors provide much information possible expectation).
Alternatively, specify quota Q utility would like obtain, try find
cheapest policy achieving quota (e.g., would like achieve certain amount information,
cheaply possible expectation). Formally, define average cost cavg () policy
expected number items picks, cavg () := E [|E(, )|]. goal find
arg min cavg () f (E(, ), ) Q ,

(2.2)



i.e., policy minimizes expected number items picked possible
realizations, least utility Q achieved. call Problem 2.2 Adaptive Stochastic Minimum
Cost Cover problem. also consider problem want minimize worst-case
cost cwc () := max |E(, )|. worst-case cost cwc () cost incurred adversarially
chosen realizations, equivalently depth deepest leaf , decision tree associated
.
Yet another important variant minimize average time required policy obtain
utility. Formally, let u(, t) expected utility obtained steps3 , let Q =
E [f (E, )] maximum
possible expected utility, define min-sum cost c ()
P
policy c () := t=0 (Q u(, t)). define Adaptive Stochastic Min-Sum Cover
problem search
arg min c () .
(2.3)


3. formal definition u(, t), see A.5 page 478.

432

fiA DAPTIVE UBMODULARITY: HEORY PPLICATIONS

P Unfortunately, show 12, even linear functions f , i.e., f (A, ) =
eA we, simply sum weights (depending realization ), Problems (2.1), (2.2),
(2.3) hard approximate reasonable complexity theoretic assumptions. Despite
hardness general problems, following sections identify conditions
sufficient allow us approximately solve them.
2.4 Incorporating Item Costs
Instead quantifying cost set E(, ) number elements |E(, )|, also
consider
case item e E cost c(e), cost set E c(S) =
P
c(e).
consider variants Problems (2.1), (2.2), (2.3) |E(, )|
eS
replaced c(E(, )). clarity presentation, focus unit cost case, i.e., c(e) = 1
e, explain results generalize non-uniform case Appendix.

3. Adaptive Submodularity
first review classical notion submodular set functions, introduce novel notion
adaptive submodularity.
3.1 Background Submodularity
Let us first consider special case p () deterministic or, equivalently, |O| = 1
(e.g., sensor placement applications, sensors never fail). case, realization
known decision maker advance, thus benefit adaptive selection. Given
realization , Problem (2.1) equivalent finding set E
arg max f (A, ) |A| k.

(3.1)

AE

interesting classes utility functions f , NP-hard optimization problem. However, many practical problems, mentioned 1, f (A) = f (A, ) satisfies submodularity. set function f : 2E R called submodular if, whenever B E e E \ B
holds
f (A {e}) f (A) f (B {e}) f (B),
(3.2)
i.e., adding e smaller set increases f least much adding e superset B.
Furthermore, f called monotone, if, whenever B holds f (A) f (B) (e.g., adding
sensor never reduce amount information obtained). celebrated result Nemhauser
et al. (1978) states monotone submodular functions f () = 0, simple greedy algorithm starts empty set, A0 = chooses
Ai+1 = Ai {arg max f (Ai {e})}

(3.3)

eE\Ai

guarantees f (Ak ) (1 1/e) max|A|k f (A). Thus, greedy set Ak obtains least (1
1/e) fraction optimal value achievable using k elements. Furthermore, Feige (1998) shows
result tight P 6= NP; assumption polynomial time algorithm strictly
better greedy algorithm, i.e., achieve (1 1/e + )-approximation constant > 0,
even special case Maximum k-Cover f (A) cardinality union sets
433

fiG OLOVIN & K RAUSE

indexed A. Similarly, Wolsey (1982) shows greedy algorithm also near-optimally
solves deterministic case Problem (2.2), called Minimum Submodular Cover problem:
arg min |A| f (A) Q.

(3.4)

AE

Pick first set A` constructed greedy algorithm f (A` ) Q. Then, integervalued submodular functions, ` |A |(1 + log maxe f (e)), i.e., greedy set
logarithmic factor larger smallest set achieving quota Q. special case Set Cover,
f (A) cardinality union sets indexed A, result matches lower bound
Feige (1998): Unless NP DTIME(nO(log log n) ), Set Cover hard approximate factor
better (1 ) ln Q, Q number elements covered.
let us relax assumption p () deterministic. case, may still want
find non-adaptive solution (i.e., constant policy always picks set independently
) maximizing favg (A ). f pointwise submodular, i.e., f (A, ) submodular
fixed , function f (A) = favg (A ) submodular, since nonnegative linear combinations
submodular functions remain submodular. Thus, greedy algorithm allows us find nearoptimal non-adaptive policy. is, sensor placement example, willing commit
locations finding whether sensors fail not, greedy algorithm provide
good solution non-adaptive problem.
However, practice, may interested obtaining non-constant policy ,
adaptively chooses items based previous observations (e.g., takes account sensors
working placing next sensor). many settings, selecting items adaptively offers huge
advantages, analogous advantage binary search sequential (linear) search4 . Thus,
question whether natural extension submodularity policies. following,
develop notion adaptive submodularity.
3.2 Adaptive Monotonicity Submodularity
key challenge find appropriate generalizations monotonicity diminishing
returns condition (3.2). begin considering special case p () deterministic, policies non-adaptive. case policy simply specifies sequence items (e1 , e2 , . . . , er ) selects order. Monotonicity context
characterized property marginal benefit selecting item always nonnegative, meaning sequences (e1 , e2 , . . . , er ), items e 1 r holds
f ({ej : j i} {e}) f ({ej : j i}) 0. Similarly, submodularity viewed
property selecting item later never increases marginal benefit, meaning
sequences (e1 , e2 , . . . , er ), items e, r, f ({ej : j i} {e}) f ({ej : j i})
f ({ej : j r} {e}) f ({ej : j r}).
take views monotonicity submodularity defining adaptive analogues,
using appropriate generalization marginal benefit. moving general adaptive
setting, challenge items states random revealed upon selection.
natural approach thus condition observations (i.e., partial realizations selected items),
take expectation respect items consider selecting. Hence, define
4. provide wellknown example active learning illustrates phenomenon crisply 9; see Fig. 4
page 454. consider general question magnitude potential benefits adaptivity 11 page 462
.

434

fiA DAPTIVE UBMODULARITY: HEORY PPLICATIONS

adaptive monotonicity submodularity properties terms conditional expected marginal
benefit item.
Definition 3.1 (Conditional Expected Marginal Benefit). Given partial realization
item e, conditional expected marginal benefit e conditioned observed , denoted
(e | ),
fi


fi
fi
(e | ) := E f (dom() {e} , ) f (dom(), ) fi
(3.5)
expectation computed respect p ( | ) = P [ = | ]. Similarly,
conditional expected marginal benefit policy
fi


fi
fi
( | ) := E f (dom() E(, ), ) f (dom(), ) fi .
(3.6)
sensor placement example, (e | ) quantifies expected amount additional area covered placing sensor location e, expectation posterior distribution p(e) (o) :=
P [(e) = | ] whether sensor fail not, taking account area covered placed working sensors encoded . Note benefit accrued upon
observing (and hence selected items dom()) E [f (dom(), ) | ],
benefit term subtracted Eq. (3.5) Eq. (3.6). Similarly, expected total
benefit obtained observing selecting e E [f (dom() {e} , ) | ].
corresponding benefit running observing slightly complex. realization
, final cumulative benefit f (dom() E(, ), ). Taking expectation
respect p ( | ) subtracting benefit already obtained dom() yields
conditional expected marginal benefit .
ready introduce generalizations monotonicity submodularity
adaptive setting:
Definition 3.2 (Adaptive Monotonicity). function f : 2E OE R0 adaptive monotone
respect distribution p () conditional expected marginal benefit item nonnegative,
i.e., P [ ] > 0 e E
(e | ) 0.

(3.7)

Definition 3.3 (Adaptive Submodularity). function f : 2E OE R0 adaptive submodular
respect distribution p () conditional expected marginal benefit fixed item
increase items selected states observed. Formally, f adaptive
submodular w.r.t. p () 0 subrealization 0 (i.e., 0 ),
e E \ dom( 0 ),

(e | ) e | 0 .
(3.8)
decision tree perspective, condition (e | ) (e | 0 ) amounts saying
decision tree , node v selects item e, compare expected
marginal benefit e selected v expected marginal benefit e would obtained
selected ancestor v , latter must smaller former. Note
comparing two expected marginal benefits, difference set
435

fiG OLOVIN & K RAUSE

items previously selected (i.e., dom() vs. dom( 0 )) distribution realizations (i.e.,
p ( | ) vs. p ( | 0 )). also worth emphasizing adaptive submodularity defined relative
distribution p () realizations; possible f adaptive submodular respect
one distribution, respect another.
give concrete examples adaptive monotone adaptive submodular functions
arise applications introduced 1 6, 7, 8, 9. Appendix, explain
notion adaptive submodularity extended handle non-uniform costs (since, e.g.,
cost placing sensor easily accessible location may smaller location
hard get to).
3.3 Properties Adaptive Submodular Functions
seen adaptive monotonicity adaptive submodularity enjoy similar closure properties monotone submodular functions. particular, w1 , . . . , wm P
0 f1 , . . . , fm
adaptive monotone submodular w.r.t. distribution p (), f (A, ) =
i=1 wi fi (A, ) adaptive monotone submodular w.r.t. p (). Similarly, fixed constant c 0 adaptive monotone
submodular function f , function g(E, ) = min(f (E, ), c) adaptive monotone submodular. Thus, adaptive monotone submodularity preserved nonnegative linear combinations
truncation. Adaptive monotone submodularity also preserved restriction,
f : 2E OE R0 adaptive monotone submodular w.r.t. p (), e E, function g : 2E\{e} OE R0 defined g(A, ) := f (A, ) E \ {e} also
adaptive submodular w.r.t. p (). Finally, f : 2E OE R0 adaptive monotone submodular
w.r.t. p () partial realization conditional function g(A, ) := f (Adom(), )
adaptive monotone submodular w.r.t. p ( | ) := P [ = | ].
3.4 Problem Characteristics Suggest Adaptive Submodularity?
Adaptive submodularity diminishing returns property policies. Speaking informally,
applied situations objective function optimized feature synergies benefits items conditioned observations. cases, primary objective might
property, suitably chosen proxy does, case active learning
persistent noise (Golovin, Krause, & Ray, 2010; Bellala & Scott, 2010). give example applications 6 9. also worth mentioning adaptive submodularity directly
applicable. extreme example synergistic effects items conditioned observations
class treasure hunting instances used prove Theorem 12.1 page 464, (binary) state certain groups items encode treasures location complex manner. Another
problem feature adaptive submodularity directly address possibility items
selection alter underlying realization , case problem optimizing policies
general POMDPs.

4. Adaptive Greedy Policy
classical non-adaptive greedy algorithm (3.3) natural generalization adaptive setting. greedy policy greedy tries, iteration, myopically increase expected objective
value, given current observations. is, suppose f : 2E OE R0 objective,
partial realization indicating states items selected far. greedy policy

436

fiA DAPTIVE UBMODULARITY: HEORY PPLICATIONS

select item e maximizing expected increase value, conditioned observed states
items already selected (i.e., conditioned ). is, select e maximize
conditional expected marginal benefit (e | ) defined Eq. (3.5). Pseudocode adaptive
greedy algorithm given Algorithm 1. difference classic, non-adaptive greedy
algorithm studied Nemhauser et al. (1978), Line 6, observation (e ) selected
item e obtained. Note algorithms section presented Adaptive Stochastic
Maximization. coverage objectives, simply keep selecting items prescribed greedy
achieving quota objective value (for min-cost objective) selected
every item (for min-sum objective).
4.1 Incorporating Item Costs
adaptive greedy algorithm naturally modified handle non-uniform item costs replacing selection rule
(e | )
e arg max
.
c(e)
e
following, focus uniform cost case (c 1), defer analysis costs
Appendix.
4.2 Approximate Greedy Selection
applications, finding item maximizing (e | ) may computationally intractable,
best find -approximation best greedy selection. means find
e0

1
e0 | max (e | ) .
e
call policy always selects item -approximate greedy policy.

1
2
3
4
5
6

Input: Budget k; ground set E; distribution p (); function f .
Output: Set E size k
begin
; ;
= 1 k
foreach e E \ compute (e | ) = E [f (A {e} , ) f (A, ) | ] ;
Select e arg maxe (e | );
Set {e };
Observe (e ); Set {(e , (e ))};
end
Algorithm 1: adaptive greedy algorithm, implements greedy policy.

4.3 Robustness & Approximate Greedy Selection
show, -approximate greedy policies performance guarantees several problems.
fact performance guarantees greedy policies robust approximate greedy
selection suggests particular robustness guarantee incorrect priors p (). Specifically,
incorrect prior p0 evaluate (e | ) err multiplicative factor
437

fiG OLOVIN & K RAUSE

, compute greedy policy respect p0 actually implementing
-approximate greedy policy (with respect true prior), hence obtain corresponding
guarantees. example, sufficient condition erring multiplicative factor
exists c 1 1 = d/c c p () p0 () p () ,
p true prior.
4.4 Lazy Evaluations Accelerated Adaptive Greedy Algorithm
definition adaptive submodularity allows us implement accelerated version
adaptive greedy algorithm using lazy evaluations marginal benefits originally suggested
non-adaptive case Minoux (1978). idea follows. Suppose run greedy
fixed realization , select items e1 , e2 , . . . , ek . Let := {(ej , (ej ) : j i)}
partial realizations observed run greedy . adaptive greedy algorithm computes
(e | ) e E 0 < k, unless e dom( ). Naively, algorithm thus needs
compute (|E|k) marginal benefits (which expensive compute). key insight
7 (e | ) nonincreasing e E, adaptive submodularity
objective. Hence, deciding item select ei know (e0 | j ) (e | )
items e0 e j < i, may conclude (e0 | ) (e | ) hence eliminate
need compute (e0 | ). accelerated version adaptive greedy algorithm exploits
observation principled manner, computing (e | ) items e decreasing order
upper bounds known them, finds item whose value least great upper
bounds items. Pseudocode version adaptive greedy algorithm given
Algorithm 2.
non-adaptive setting, use lazy evaluations shown significantly reduce
running times practice (Leskovec et al., 2007). evaluated naive accelerated implementations adaptive greedy algorithm two sensor selection problems, obtained speedup
factors range roughly 4 40 problems. See 10 page 459 details.

5. Guarantees Greedy Policy
section show objective function adaptive submodular respect
probabilistic model environment operate, greedy policy inherits precisely performance guarantees greedy algorithm classic (non-adaptive) submodular
maximization submodular coverage problems, Maximum k-Cover Minimum Set
Cover, well min-sum submodular coverage problems, Min-Sum Set Cover. fact,
show holds true generally: approximate greedy policies inherit precisely
performance guarantees approximate greedy algorithms classic problems.
guarantees suggest adaptive submodularity appropriate generalization submodularity
policies. section focus unit cost case (i.e., every item cost).
Appendix provide proofs omitted section, show results extend
non-uniform item costs greedily maximize expected benefit/cost ratio.
5.1 Maximum Coverage Objective
section consider maximum coverage objective, goal select k items
adaptively maximize expected value. task maximizing expected value subject

438

fiA DAPTIVE UBMODULARITY: HEORY PPLICATIONS

Input: Budget k; ground set E; distribution p (); function f .
Output: Set E size k
begin
; ; Priority Queue Q EMPTY QUEUE;
1
2
foreach e E Q. insert(e, +);
3
= 1 k
4
max ; emax NULL;
5
max < Q. maxPriority( )
6
e Q. pop( );
7
(e | ) = E [f (A {e} , ) f (A, ) | ];
8
Q. insert(e, );
9
max <
10
max ; emax e;
11
{emax }; Q. remove(emax );
12
Observe (emax ); Set {(emax , (emax ))};
end
Algorithm 2: accelerated version adaptive greedy algorithm. Here, Q. insert(e, )
inserts e priority , Q. pop( ) removes returns item greatest priority,
Q. maxPriority( ) returns maximum priority elements Q, Q. remove(e)
deletes e Q.
complex constraints, matroid constraints intersections matroid constraints,
considered work Golovin Krause (2011). stating result, require
following definition.
Definition 5.1 (Policy Truncation). policy , define level-k-truncation [k]
policy obtained running terminates selects k items, terminating.
Formally, dom([k] ) = { dom() : || < k}, [k] () = () dom([k] ).
following result, generalizes classic result work Nemhauser et al.
(1978) greedy algorithm achieves (1 1/e)-approximation problem maximizing
monotone submodular functions cardinality constraint. setting ` = k = 1
Theorem 5.2, see greedy policy selects k items adaptively obtains least (11/e)
value optimal policy selects k items adaptively, measured respect favg .
proof see Theorem A.10 Appendix A.3, generalizes Theorem 5.2 nonuniform item costs.
Theorem 5.2. Fix 1. f adaptive monotone adaptive submodular respect
distribution p (), -approximate greedy policy, policies positive
integers ` k,



favg ([`] ) > 1 e`/k favg ([k]
).

particular, ` = k implies -approximate greedy policy achieves 1 e1/
approximation expected reward best policy, terminated running
equal number steps.
greedy rule implemented small absolute error rather small relative
error, i.e., (e0 | ) maxe (e | ) , argument similar used prove Theorem 5.2
439

fiG OLOVIN & K RAUSE

shows




) `.
favg ([`] ) 1 e`/k favg ([k]

important, since small absolute error always achieved (with high probability) whenever f evaluated efficiently, sampling p ( | ) efficient. case, approximate
N

1 X
(e | )
f (dom() {e} , ) f (dom(), ) ,
N
i=1

sampled i.i.d. p ( | ).
5.1.1 DATA EPENDENT B OUNDS
maximum coverage objective, adaptive submodular functions another attractive feature:
allow us obtain data dependent bounds optimum, manner similar bounds
non-adaptive case (Minoux, 1978). Consider non-adaptive problem maximizing
monotone submodular function f : 2A R0 subject constraint |A| k. Let
optimal solution, fix E.
X
f (A ) f (A) + max
(f (A {e}) f (A))
(5.1)
B:|B|k

eB

P
setting B = f (A ) f (A B) f (A) + eBP
(f (A {e}) f (A)). Note
unlike original objective, easily compute maxB:|B|k eB (f (A {e}) f (A))
computing (e) := f (A {e}) f (A) e, summing k largest values. Hence
quickly compute upper bound distance optimal value, f (A ) f (A).
practice, data-dependent bounds much tighter problem-independent performance guarantees Nemhauser et al. (1978) greedy algorithm (Leskovec et al., 2007).
note bounds hold set A, sets selected greedy algorithm.
data dependent bounds following analogue adaptive monotone submodular
functions. See Appendix A.2 proof.
Lemma 5.3 (The Adaptive Data Dependent Bound). Suppose made observations
selecting dom(). Let policy |E( , )| k . adaptive
monotone submodular f
X
( | )
max
(e | ) .
(5.2)
AE,|A|k

eA

Thus, running policy , efficiently compute bound additional benefit
optimal solution could obtain beyond reward . computing
conditional expected marginal benefits elements e, summing k largest them. Note
bounds computed fly running greedy algorithm, similar
manner discussed Leskovec et al. (2007) non-adaptive setting.
5.2 Min Cost Cover Objective
Another natural objective minimize number items selected ensuring sufficient
level value obtained. leads Adaptive Stochastic Minimum Cost Coverage problem
described 2, namely arg min cavg () f (E(, ), ) Q . Recall
440

fiA DAPTIVE UBMODULARITY: HEORY PPLICATIONS

cavg () expected cost , unit cost case equals expected number items
selected , i.e., cavg () := E [|E(, )|]. objective adaptive monotone submodular,
adaptive version Minimum Submodular Cover problem (described line (3.4)
3.1). Recall greedy algorithm known give (ln(Q) + 1)-approximation Minimum
Submodular Cover assuming coverage function integer-valued addition monotone
submodular (Wolsey, 1982). Adaptive Stochastic Minimum Cost Coverage also related
(Noisy) Interactive Submodular Set Cover problem studied Guillory Bilmes (2010, 2011),
considers worst-case setting (i.e., distribution states; instead states
realized adversarial manner). Similar results active learning proved Kosaraju
et al. (1999) Dasgupta (2004), discuss detail 9.
assume throughout section exists quality threshold Q f (E, ) = Q
, E , f (S, ) Q. Note that, discussed Section 3,
replace f (S, ) new function g(S, ) = min(f (S, ), Q0 ) constant Q0 , g
adaptive submodular f is. Thus, f (E, ) varies across realizations, instead use
greedy algorithm function truncated threshold Q0 min f (E, ) achievable
realizations.
contrast Adaptive Stochastic Maximization, coverage problem additional subtleties
arise. particular, enough policy achieves value Q true realization; order
terminate, also requires proof fact. Formally, require covers f :
Definition 5.4 (Coverage). Let = (, ) partial realization encoding states observed
execution realization . Given f : 2E OE R, say policy covers
respect f f (dom(), 0 ) = f (E, 0 ) 0 . say covers f covers
every realization respect f .
Coverage defined way upon terminating, might know realization
true one, guaranteed achieved maximum reward every possible case
(i.e., every realization consistent observations). obtain results average
worst-case cost objectives.
5.2.1 INIMIZING AVERAGE C OST
presenting approximation guarantee Adaptive Stochastic Minimum Cost Coverage, introduce special class instances, called selfcertifying instances. make
distinction greedy policy stronger performance guarantees selfcertifying instances, instances arise naturally applications. example, Stochastic Submodular
Cover Stochastic Set Cover instances 7, Adaptive Viral Marketing instances 8,
Pool-Based Active Learning instances 9 selfcertifying.
Definition 5.5 (SelfCertifying Instances). instance Adaptive Stochastic Minimum Cost Coverage selfcertifying whenever policy achieves maximum possible value true
realization immediately proof fact. Formally, instance (f, p ()) selfcertifying
, 0 , 0 , f (dom(), ) = f (E, )
f (dom(), 0 ) = f (E, 0 ).
One class selfcertifying instances commonly arise f (A, ) depends
state items A, uniform maximum amount reward
obtained across realizations. Formally, following observation.
441

fiG OLOVIN & K RAUSE

Proposition 5.6. Fix instance (f, p ()). exists Q f (E, ) = Q
exists g : 2EO R0 f (A, ) = g ({(e, (e)) : e A}) ,
(f, p ()) selfcertifying.
Proof. Fix , 0 , 0 . Assuming existence g treating
relation, f (dom(), ) = g() = f (dom(), 0 ). Hence f (dom(), ) = Q = f (E, )
f (dom(), 0 ) = Q = f (E, 0 ).
results minimum cost coverage, also need stronger monotonicity condition:
Definition 5.7 (Strong Adaptive Monotonicity). function f : 2E OE R strongly adaptive
monotone respect p () if, informally selecting items never hurts respect
expected reward. Formally, , e
/ dom(), possible outcomes
P [(e) = | ] > 0, require
E [f (dom(), ) | ] E [f (dom() {e} , ) | , (e) = o] .

(5.3)

Strong adaptive monotonicity implies adaptive monotonicity, latter means selecting
items never hurts expectation, i.e.,
E [f (dom(), ) | ] E [f (dom() {e} , ) | ] .
state main result average case cost cavg ():
Theorem 5.8. Suppose f : 2E OE R0 adaptive submodular strongly adaptive monotone respect p () exists Q f (E, ) = Q . Let value
f (S, ) > Q implies f (S, ) = Q . Let = min p () mini optimal policy minimizing expected number
mum probability realization. Let avg
items selected guarantee every realization covered. Let -approximate greedy policy.
general


Q

cavg () cavg (avg ) ln
+1

selfcertifying instances
cavg ()


cavg (avg
)




ln

Q





+1 .

Note range(f ) Z, = 1 valid choice, general selfcertifying
) (ln(Q/) + 1) c

instances cavg () cavg (avg
avg () cavg (avg ) (ln(Q) + 1),
respectively.
5.2.2 INIMIZING W ORST-C ASE C OST
worst-case cost cwc () := max |E(, )|, strong adaptive monotonicity required;
adaptive monotonicity suffices. obtain following result.
Theorem 5.9. Suppose f : 2E OE R0 adaptive monotone adaptive submodular
respect p (), let value f (S, ) > f (E, ) implies f (S, ) = f (E, )

. Let = min p () minimum probability realization. Let wc
442

fiA DAPTIVE UBMODULARITY: HEORY PPLICATIONS

optimal policy minimizing worst-case number queries guarantee every realization
covered. Let -approximate greedy policy. Finally, let Q := E [f (E, )] maximum
possible expected reward.


Q

+1 .
cwc () cwc (wc ) ln

proofs Theorems 5.8 5.9 given Appendix A.4.
Thus, even though adaptive submodularity defined w.r.t. particular distribution, perhaps
surprisingly, adaptive greedy algorithm competitive even case adversarially chosen
realizations, policy optimized minimize worst-case cost. Theorem 5.9 therefore
suggests strong prior, obtain strongest guarantees choose
distribution uniform possible (i.e., maximizes ) still guaranteeing adaptive
submodularity.
5.2.3 ISCUSSION
Note approximation factor selfcertifying instances Theorem 5.8 reduces
(ln(Q) + 1)-approximation guarantee greedy algorithm Set Cover instances Q
elements, case deterministic distribution p (). Moreover, deterministic distribution p () distinction average-case worst-case cost. Hence, immediate corollary result Feige (1998) mentioned 3 every constant > 0
polynomial time (1 ) ln (Q/) approximation algorithm selfcertifying instances
Adaptive Stochastic Min Cost Cover, either cavg () cwc () objective, unless
NP DTIME(nO(log log n) ). remains open determine whether Adaptive Stochastic
Min Cost Cover worst-case cost objective admits ln (Q/) + 1 approximation self
certifying instances via polynomial time algorithm, particular whether greedy policy approximation guarantee. However, Lemma A.14 show Feiges result
also implies (1 ) ln (Q/) polynomial time approximation algorithm general
(non self-certifying) instances Adaptive Stochastic Min Cost Cover either objective, unless
NP DTIME(nO(log log n) ). sense, three results comprising Theorem 5.8
Theorem 5.9 best-possible reasonable complexity-theoretic assumptions. show
Section 9, result average-case cost greedy policies selfcertifying instances
also matches (up constant factors) results hardness approximating optimal policy
special case active learning, also known Optimal Decision Tree problem.
5.3 Min-Sum Cover Objective
Yet another natural objective min-sum objective, unrealized reward x incurs
cost x time step, goal minimize total cost incurred.
5.3.1 BACKGROUND N - ADAPTIVE -S UM C P ROBLEM
non-adaptive setting, perhaps simplest form coverage problem objective
Min-Sum Set Cover problem (Feige, Lovasz, & Tetali, 2004) input set system
(U, S), output permutation sets hS1 , S2 , . . . , Sm i, goal minimize sum
element coverage times, coverage time u index first set contains
(e.g., j u Sj u
/ Si < j). problem generalizations
443

fiG OLOVIN & K RAUSE

min-sum objective useful modeling processing costs certain applications, example
ordering diagnostic tests identify disease cheaply (Kaplan, Kushilevitz, & Mansour, 2005),
ordering multiple filters applied database records processing query (Munagala,
Babu, Motwani, Widom, & Thomas, 2005), ordering multiple heuristics run boolean
satisfiability instances means solve faster practice (Streeter & Golovin, 2008).
particularly expressive generalization min-sum set cover studied names MinSum Submodular Cover (Streeter & Golovin, 2008) L1 -Submodular Set Cover (Golovin, Gupta,
Kumar, & Tangwongsan, 2008). former paper extends greedy algorithm natural online
variant problem, latter studies parameterized family Lp -Submodular Set Cover
problems objective analogous minimizing Lp norm coverage times
Min-Sum Set Cover instances. Min-Sum Submodular Cover problem, monotone
submodular function f : 2E R0 defining reward obtained collection elements5 .
integral cost c(e) element, output sequence elements
= he1 , e2 , . . . , en i. R0 , define set elements sequence within
budget t:




X
[t] := ei :
c(ej ) .


ji

cost wish minimize
c () :=


X


f (E) f ([t] ) .

(5.4)

t=0

Feige et al. (2004) proved Min-Sum Set cover, greedy algorithm achieves 4-approximation
minimum cost, also optimal sense polynomial time algorithm
achieve (4 )-approximation, > 0, unless P = NP. Interestingly, greedy algorithm also achieves 4-approximation general Min-Sum Submodular Cover problem
well (Streeter & Golovin, 2008; Golovin et al., 2008).
5.3.2 DAPTIVE TOCHASTIC -S UM C P ROBLEM
article, extend result Streeter Golovin (2008) Golovin et al. (2008)
adaptive version Min-Sum Submodular Cover. claritys sake consider unit-cost
case (i.e., c(e) = 1 e); show extend adaptive submodularity handle general
costs Appendix. adaptive version problem, [t] plays role [t] , favg
plays role f . goal find policy minimizing
c () :=


X
t=0


X
X

E [f (E, )] favg ([t] ) =
p ()
f (E, ) f (E([t] , ), ) .


(5.5)

t=0

call problem Adaptive Stochastic Min-Sum Cover problem. key difference
objective minimum cost cover objective here, cost step
fractional extent covered true realization, whereas minimum cost cover
objective charged full step completely covered true realization
5. encode Min-Sum Set Cover instance (U, S), let E := f (A) := | eA e|, e E subset
elements U .

444

fiA DAPTIVE UBMODULARITY: HEORY PPLICATIONS

(according Definition 5.4). prove following result Adaptive Stochastic Min-Sum
Cover problem arbitrary item costs Appendix A.5.
Theorem 5.10. Fix 1. f adaptive monotone adaptive submodular respect
distribution p (), -approximate greedy policy respect item costs,
policy, c () 4 c ( ).

6. Application: Stochastic Submodular Maximization
first application, consider sensor placement problem introduced 1. Suppose
would like monitor spatial phenomenon temperature building. discretize
environment set E locations. would like pick subset E k locations
informative, use set function f(A) quantify informativeness placement
A. Krause Guestrin (2007) show many natural objective functions (such reduction
predictive uncertainty measured terms Shannon entropy conditionally independent
observations) monotone submodular.
consider problem, informativeness sensor unknown deployment (e.g., deploying cameras surveillance, location objects associated
occlusions may known advance, varying amounts noise may reduce sensing
range). model extension assigning state (e) possible location, indicating extent sensor placed location e working. quantify value
set sensor deployments realization indicating extent various sensors
working, first define (e, o) e E O, represents placement
sensor location e state o. suppose function f : 2EO R0
quantifies informativeness set sensor deployments arbitrary states. (Note f
set function taking set (sensor deployment, state) pairs input.) utility f (A, ) placing
sensors locations realization
f (A, ) := f({(e, (e)) : e A}).
aim adaptively place k sensors maximize expected utility. Q
assume sensor
failures location independent other, i.e., P [ = ] = eE P [(e) = (e)] ,
P [(e) = o] probability sensor placed location e state o. Asadpour
et al. (2008) studied special case problem, sensors either fail completely (in
case contribute value all) work perfectly, name Stochastic Submodular Maximization. proved adaptive greedy algorithm obtains (1 1/e) approximation
optimal adaptive policy, provided f monotone submodular. extend result multiple
types failures showing f (A, ) adaptive submodular respect distribution p ()
invoking Theorem 5.2. Fig. 2 illustrates instance Stochastic Submodular Maximization f (A, ) cardinality union sets index parameterized .
Q
Theorem 6.1. Fix prior P [ = ] = eE P [(e) = (e)] integer k, let
objective function f : 2EO R0 monotone submodular. Let -approximate
greedy policy attempting maximize f , let policy. positive integers `,



favg ([`] ) 1 e`/k favg ([k]
).

).
particular, greedy policy (i.e., = 1) ` = k, favg ([k] ) 1 1e favg ([k]
445

fiG OLOVIN & K RAUSE

Proof. prove Theorem 6.1 first proving f adaptive monotone adaptive submodular
model, applying Theorem 5.2. Adaptive monotonicity readily proved observing
f (, ) monotone . Moving adaptive submodularity, fix , 0
0 e
/ dom( 0 ). aim show (e | 0 ) (e | ). Intuitively, clear,
(e | 0 ) expected marginal benefit adding e larger base set case
(e | ), namely dom( 0 ) compared dom(), realizations independent. prove
rigorously, define coupled distribution pairs realizations
0 0
Q
(e0 ) = 0 (e0 ) e0
/ dom( 0 ). Formally, (, 0 ) = eE\dom() P [(e) = (e)]
0
0
0
, , (e ) = 0 (e0 ) e0
/ dom( 0 ); otherwise (, 0 ) = 0. (Note
0
0
0
(, 0 ) > 0 implies (e0 ) = 0 (e0 )
since
P e 0dom() as0 well,
P ,0 ,
0
0
.) Also note p ( | ) =
0 (, ) p ( | ) =
(, ). Calculating
(e | 0 ) (e | ) using , see (, 0 ) support ,


f (dom( 0 ) {e} , 0 ) f (dom( 0 ), 0 ) = f( 0 (e, 0 (e)) ) f( 0 ))
f( {(e, (e))}) f())
= f (dom() {e} , ) f (dom(), )
submodularity f. Hence
P
0
0
0
0
0
(e | 0 ) =
(,0 ) (, ) (f (dom( ) {e} , ) f (dom( ), ))
P
0
= (e | )

(,0 ) (, ) (f (dom() {e} , ) f (dom(), ))
completes proof.

7. Application: Stochastic Submodular Coverage
Suppose instead wishing adaptively place k unreliable sensors maximize utility
information obtained, discussed 6, quota utility wish adaptively place
minimum number unreliable sensors achieve quota. amounts minimum-cost
coverage version Stochastic Submodular Maximization problem introduced 6,
call Stochastic Submodular Coverage.
6, Stochastic Submodular Coverage problem suppose function
f : 2EO R0 quantifies utility set sensors
arbitrary states. Also,
Q
states sensor independent, P [ = ] = eE P [(e) = (e)]. goal
obtain
quota Q utility
n
minimum cost. Thus, define objective f (A, ) :=

min Q, f ({(e, (e)) : e A}) , want find policy covering every realization minimizing cavg () := E [|E(, )|]. additionally assume quota always obtained
using sufficiently many sensor placements; formally, amounts f (E, ) = Q .
obtain following result, whose proof defer end section.
Q
Theorem 7.1. Fix prior independent sensor states P [ = ] = eE P [(e) = (e)],
EO R0 monotone submodular function. Fix Q R0 f (A, ) :=
let
f :2

min Q, f({(e, (e)) : e A}) satisfies f (E, ) = Q . Let value
f (S, ) > Q implies f (S, ) = Q . Finally, let -approximate greedy
446

fiA DAPTIVE UBMODULARITY: HEORY PPLICATIONS

Figure 2: Illustration part Stochastic Set Cover instance. Shown supports two
distributions sets, indexed items e (marked blue) e0 (yellow).

policy maximizing f , let policy.


Q

cavg () cavg ( ) ln
+1 .

7.1 Special Case: Stochastic Set Coverage Problem
Stochastic Submodular Coverage problem generalization Stochastic Set Coverage
problem (Goemans & Vondrak, 2006). Stochastic Set Coverage underlying submodular objective f number elements covered input set system. words,
ground set U n elements covered, items E item e associated
distribution subsets U . item selected, set sampled distribution,
illustrated Fig. 2. problem adaptively select items elements U covered
sampled sets, minimizing expected number items selected. Like us, Goemans
Vondrak also assume subsets sampled independently item, every element
U covered every realization, f (E, ) = |U | .
Goemans Vondrak primarily investigated adaptivity gap (quantifying much adaptive
policies outperform non-adaptive policies) Stochastic Set Coverage, variants
items repeatedly selected not, prove adaptivity gaps (log n) former case,
(n) O(n2 ) latter. also provide n-approximation algorithm.
recently, Liu et al. (2008) considered special case Stochastic Set Coverage item
may one two states. motivated streaming database problem,
collection queries sharing common filters must evaluated stream element.
transform problem Stochastic Set Coverage instance (filter, query) pairs
covered filter evaluations; pairs covered filter depends (binary) outcome
evaluating stream element. resulting instances satisfy assumption every
element U covered every realization. study, among algorithms, adaptive
greedy algorithm specialized thisQsetting, show subsets areP
sampled independently
item, P [ = ] = e P [(e) = (e)], Hn := nx=1 x1 approximation.
(Recall ln(n) Hn ln(n) + 1 n 1.) Moreover, Liu et al. report empirically
outperforms number algorithms experiments.
447

fiG OLOVIN & K RAUSE

adaptive submodularity framework allows us recover Liu et al.s result, generalize
richer item distributions subsets U , corollary Theorem 7.1. Specifically,
obtain (ln(n)+1)-approximation Stochastic Set Coverage problem, n := |U |,
matches approximation ratio greedy algorithm classical Set Cover Stochastic Set
Coverage generalizes. Like Liu et al.s result, result tight NP * DTIME(nO(log log n) ),
since matches Feiges lower bound (1 ) ln n approximability Set Cover
assumption (Feige, 1998).
model Stochastic Set Coverage problem letting (e) U indicate random
set
sampled
es distribution. Since sampled sets independent P [ = ] =
Q
P
[(e)
=
(e)]. E let f (A, ) := | eA (e)| number elements U
e
covered sets sampled items A. previous work mentioned above, assume
f (E, ) = n . Therefore may set Q = n. Since range f includes integers,
may set = 1. Applying Theorem 7.1 yields following result.
Corollary 7.2. adaptive greedy algorithm achieves (ln(n) + 1)-approximation Stochastic
Set Coverage, n := |U | size ground set.
provide proof Theorem 7.1.
Proof Theorem 7.1: ultimately prove Theorem 7.1 applying bound Theorem 5.8 selfcertifying instances. proof mostly consists justifying final step.

Without
n loss
generality may assume f truncated Q, otherwise may use g(S) =
min Q, f(S) lieu f. removes need truncate f . Since established adaptive
submodularity f proof Theorem 6.1, assumption f (E, ) = Q , apply
Theorem 5.8 need show f strongly adaptive monotone, instances
consideration selfcertifying.
begin showing strong adaptive monotonicity f . Fix partial realization , item
e
/ dom() state o. Let 0 = {(e, o)}. treating 0 subsets E O,
using monotonicity f, obtain


E [f (dom(), ) | ] = f() f( 0 ) E f (dom( 0 ), ) | 0 ,
equivalent strong adaptive monotonicity condition.
Next prove instances selfcertifying. Consider , 0 consistent
.
f (dom(), ) = f() = f (dom(), 0 ).
Since f (E, ) = f (E, 0 ) = Q assumption, follows f (dom(), ) = f (E, ) iff
f (dom(), 0 ) = f (E, 0 ), instance selfcertifying.
shown f p () satisfy assumptions Theorem 5.8 selfcertifying
instance. Hence may apply obtain claimed approximation guarantee.

8. Application: Adaptive Viral Marketing
next application, consider following scenario. Suppose would like generate demand genuinely novel product. Potential customers realize valuable new
product them, conventional advertisements failing convince try it.
448

fiA DAPTIVE UBMODULARITY: HEORY PPLICATIONS

Figure 3: Illustration Adaptive Viral Marketing problem. Left: underlying social network.
Middle: people influenced observations obtained one person selected.

case, may try spur demand offering special promotional deal select people,
hope demand builds virally, propagating social network people recommend
product friends associates. Supposing know something structure
social networks people inhabit, ideas, innovation, new product adoption diffuse
them, begs question: initial set people offer promotional
deal, order spur maximum demand product?
This, broadly, viral marketing problem. problem arises context spreading technological, cultural, intellectual innovations, broadly construed. interest unified
terminology follow Kempe et al. (2003) talk spreading influence social network, say people active adopted idea innovation question,
inactive otherwise, influences b convinces b adopt idea innovation question.
many ways model diffusion dynamics governing spread influence
social network. consider basic well-studied model, independent cascade model,
described detail below. model Kempe et al. (2003) obtain interesting result;
show eventual spread influence f (i.e., ultimate number customers demand
product) monotone submodular function seed set people initially selected. This,
conjunction results Nemhauser et al. (1978) implies greedy algorithm obtains
least 1 1e value best feasible seed set size k, i.e., arg maxS:|S|k f (S),
interpret k budget promotional campaign. Though Kempe et al. consider
maximum coverage version viral marketing problem, result conjunction
Wolsey (1982) also implies greedy algorithm obtain quota Q value cost
ln(Q) + 1 times cost optimal set arg minS {c(S) : f (S) Q} f takes
integral values.
8.1 Adaptive Viral Marketing
viral marketing problem natural adaptive analog. Instead selecting fixed set
people advance, may select person offer promotion to, make observations
449

fiG OLOVIN & K RAUSE

resulting spread demand product, repeat. See Fig. 3 illustration. 8.2,
use idea adaptive submodularity obtain results analogous Kempe et al.(2003)
adaptive setting. Specifically, show greedy policy obtains least 1 1e
value best policy. Moreover, extend result achieving guarantee
case reward simply number influenced people, also (nonnegative)
monotone submodular function set people influenced. 8.3 consider minimum
cost cover objective, show greedy policy obtains logarithmic approximation it.
knowledge, approximation results adaptive variant viral marketing problem
known.
8.1.1 NDEPENDENT C ASCADE ODEL
model, social network directed graph G = (V, A) vertex V
person, edge (u, v) associated binary random variable Xuv indicating u
influence v. is, Xuv = 1 u influence v influenced, Xuv = 0
otherwise. random variables Xuv independent, known means puv := E [Xuv ].
call edge (u, v) Xuv = 1 live edge edge Xuv = 0 dead edge.
node u activated, edges Xuv neighbor v u sampled, v activated (u, v)
live. Influence spread us neighbors neighbors, on, according
process. active, nodes remain active throughout process, however Kempe et al.
(2003) show assumption without loss generality, removed.
8.1.2 F EEDBACK ODEL
Adaptive Viral Marketing problem independent cascades model, items correspond people activate offering promotional deal. define states
(u) depends information obtain result activating u. Given nature
diffusion process, activating u wide-ranging effects, state (u)
state social network whole u particular. Specifically, model
(u) function u : {0, 1, ?}, u ((u, v)) = 0 means activating u revealed (u, v) dead, u ((u, v)) = 1 means activating u revealed (u, v) live,
u ((u, v)) = ? means activating u revealed status (u, v) (i.e., value
Xuv ). require realization consistent complete. Consistency means edge
declared live dead two states. is, u, v V A,
(u (a), v (a))
/ {(0, 1), (1, 0)}. Completeness means status edge revealed
activation. is, exists u V u (a) {0, 1}. consistent
complete realization thus encodes Xuv edge (u, v). Let A() denote live edges
encoded . several candidates edge sets allowed observe
activating node u. consider call Full-Adoption Feedback Model: activating u get see status (live dead) edges exiting v, nodes v reachable
u via live edges (i.e., reachable u (V, A()), true realization. illustrate
full-adoption feedback model Fig. 3.
8.1.3 BJECTIVE F UNCTION
simplest case, reward influencing set U V nodes f(U ) := |U |. Kempe et al.
(2003) obtain 1 1e -approximation slightly general case node u
450

fiA DAPTIVE UBMODULARITY: HEORY PPLICATIONS

P
weight wu indicating importance, reward f(U ) := uU wu . generalize
result further, include arbitrary nonnegative monotone submodular reward functions f.
allows us, example, encode value associated diversity set nodes influenced, notion better achieve 20% market penetration five different (equally
important) demographic segments 100% market penetration one 0% others.

8.2 Guarantees Maximum Coverage Objective
ready formally state result maximum coverage objective.

Theorem 8.1. greedy policy greedy obtains least 1 1e value best policy
Adaptive Viral Marketing problem arbitrary monotone submodular reward functions,
independent cascade full-adoption feedback models discussed above. is, (S, )
set activated nodes seed set activated nodes realization,
f : 2V R0 arbitrary monotone submodular function indicating reward influencing
set, objective function f (S, ) := f((S, )), policies k N



1
greedy
favg ([k] ) 1
favg ([k] ).
e

).
generally, -approximate greedy policy ` N, favg ([`] ) 1 e`/k favg ([k]
Proof. Adaptive monotonicity follows immediately fact f (, ) monotonic
. thus suffices prove f adaptive submodular respect probability distribution
realizations p (), invoke Theorem 5.2 complete proof.
say observed edge (u, v) know status, i.e., live dead.
Fix , 0 0 v
/ dom( 0 ). must show (v | 0 ) (v | ).
prove rigorously, define coupled distribution pairs realizations
0 0 . Note given feedback model, realization function random variables {Xuw : (u, w) A} indicating status edge. conciseness use notation
X = {Xuw : (u, w) A}. define implicitly terms joint distribution X X0 ,
= (X) 0 = 0 (X0 ) realizations induced two distinct sets random
edge statuses, respectively. Hence ((X), (X0 )) = (X, X0 ). Next, let us say partial realization observes edge e w dom() revealed status live dead.
edges (u, w) observed , random variable Xuw deterministically set status observed
0 deterministically set
. Similarly, edges (u, w) observed 0 , random variable Xuw
status observed 0 . Note since 0 , state edges observed
0 . (X, X0 ) support() properties. Additionally,
construct status edges unobserved 0 X
0 edges (u, w), else (X, X0 ) = 0.
X0 , meaning Xuw = Xuw
constraints leave us following degrees freedom: may select Xuw
(u, w) unobserved . select independently, E [Xuw ] = puw
prior p (). Hence (X, X0 ) satisfying constraints,

1Xuw
uw
(X, X0 ) =
pX
,
uw (1 puw )
(u,w) unobserved

451

fiG OLOVIN & K RAUSE

otherwise (X, X0 ) = 0. Note p ( | ) =
next claim (, 0 ) support()

P

0

(, 0 ) p (0 | 0 ) =

0
(, ).

P

f (dom( 0 ) {v} , 0 ) f (dom( 0 ), 0 ) f (dom() {v} , ) f (dom(), ). (8.1)
Recall f (S, ) := f((S, )), (S, ) set activated nodes seed set
activated nodes realization. Let B = (dom(), ) C = (dom() {v} , )
denote active nodes selecting v dom() realizations , similarly
define B 0 C 0 respect 0 0 . Let := C \ B, D0 := C 0 \ B 0 . Eq. (8.1)
equivalent f(B 0 D0 ) f(B 0 ) f(B D) f(B). submodularity f, suffices
show B B 0 D0 prove inequality, do.
start proving B B 0 . Fix w B. exists path u dom()
w (V, A()). Moreover, every edge path live also observed live,
definition feedback model. Since (, 0 ) support(), implies every edge
path also live 0 , edges observed must status
0 . follows path u w (V, A(0 )). Since u clearly also dom( 0 ),
conclude w B 0 , hence B B 0 .
Next show D0 D. Fix w D0 suppose way contradiction w
/ D.
Hence exists path P v w (V, A(0 )) path exists (V, A()).
edges P live 0 , least one must dead . Let (u, u0 ) edge
P . status edge differs 0 , (, 0 ) support(), must
(u, u0 ) observed 0 observed . observed 0 , feedback
model must u active dom( 0 ) selected, i.e., u B 0 . However, implies
nodes reachable u via edges P also active dom( 0 ) selected, since
edges P live. Hence nodes, including w, B 0 . Since D0 B 0 disjoint,
implies w
/ D0 , contradiction.
proved Eq. (8.1), proceed use show (v | 0 ) (v | ) 6.
P
0
0
0
0
0
(v | 0 ) =
(,0 ) (, ) (f (dom( ) {v} , ) f (dom( ), ))
P
0
= (v | )

(,0 ) (, ) (f (dom() {v} , ) f (dom(), ))
completes proof.
8.2.1 C OMPARISON TOCHASTIC UBMODULAR AXIMIZATION
worth contrasting Adaptive Viral Marketing problem Stochastic Submodular Maximization problem 6. latter problem, think items random independently distributed sets. Adaptive Viral Marketing contrast, random sets (of nodes
influenced fixed node selected) depend random status ofthe edges, hence may
correlated them. Nevertheless, obtain 1 1e approximation factor
problems.

8.3 Minimum Cost Cover Objective
may also wish adaptively run campaign certain level market penetration
achieved, e.g., certain number people adopted product. formalize
452

fiA DAPTIVE UBMODULARITY: HEORY PPLICATIONS

goal using minimum cost cover objective. objective, instance Adaptive
Stochastic Minimum Cost Cover, given quota Q f(V ) (quantifying desired
level market penetration) must adaptively select nodes activate set active
nodes satisfies f(S) Q. obtain following result.
Theorem 8.2. Fix monotone submodular function f : 2V R0 indicating thenreward influo
encing set, quota Q f(V ). Suppose objective f (S, ) := min Q, f((S, )) ,
(S, ) set activated nodes seed set activated nodes
realization. Let value f(S) > Q implies f(S)
Qfor
S. -approximate greedy policy average costs ln Q
+ 1 times
average cost best policy obtaining Q reward Adaptive Viral Marketing problem independent
model full-adoption feedback described above. is,
cascade

Q
cavg () ln + 1 cavg ( ) covers every realization.
Proof. prove Theorem 8.2 recourse Theorem 5.8. already established f
adaptive submodular, proof Theorem 8.1. remains show f strongly adaptive
monotone, instances selfcertifying, Q equal corresponding terms
statement Theorem 5.8.
start strong adaptive monotonicity. Fix , e
/ dom(), O. must show
E [f (dom(), ) | ] E [f (dom() {e} , ) | , (e) = o] .

(8.2)

Let V + () denote active nodes selecting dom() observing . definition
full adoption feedback model, V + () consists precisely nodes v exists path Puv u dom() v via exclusively live edges. edges whose status observe consist edges exiting nodes V + (). follows every path
u V + () v V \ V + () contains least one edge observed
dead. Hence, every , set nodes activated selecting dom() same. Therefore E [f (dom(), ) | ] = f(V + ()). Similarly, define 0 := {(e, o)},
E [f (dom() {e} , ) | , (e) = o] = f(V + ( 0 )). Note activated, nodes never
become inactive. Hence, 0 implies V + () V + ( 0 ). Since f monotone assumption,
means f(V + ()) f(V + ( 0 )) implies Eq. (8.2) strong adaptive monotonicity.
Next establish
thatothese instances selfcertifying. Note every
n
f (V, ) = min Q, f(V ) = Q. earlier remarks, know f (dom(), ) =
f(V + ()) every . Hence , 0 consistent , f (dom(), ) =
f (dom(), 0 ) f (dom(), ) = Q f (dom(), 0 ) = Q, proves
instance selfcertifying.
Finally show Q equal corresponding terms statement Theorem 5.8.
noted earlier, f (V, ) = Q . n
defined

valueosuch f(S) > Q implies
n
f(S) Q S. Since range(f ) = min Q, f(S) : V , follows cannot
f (S, ) (Q , Q) , satisfies requirements corresponding term
Theorem 5.8. Hence may apply Theorem 5.8 selfcertifying instance Q
obtain claimed result.

453

fiG OLOVIN & K RAUSE

9. Application: Automated Diagnosis Active Learning
important problem AI automated diagnosis. example, suppose different hypotheses state patient, run medical tests rule inconsistent hypotheses.
goal adaptively choose tests infer state patient quickly possible.
similar problem arises active learning. Obtaining labeled data train classifier typically
expensive, often involves asking expert. active learning (c.f., Cohn, Gharamani, & Jordan,
1996; McCallum & Nigam, 1998), key idea labels informative others:
labeling unlabeled examples imply labels many unlabeled examples, thus
cost obtaining labels expert avoided. standard, assume
given set hypotheses H, set unlabeled data points X x X
independently drawn distribution D. Let L set possible labels. Classical
learning theory yields probably approximately correct (PAC) bounds, bounding number n
examples drawn i.i.d. needed output hypothesis h expected error
probability least 1 , fixed , > 0. is, h target hypothesis (with
zero error), error(h) := PxD [h(x) 6= h (x)] error h, require P [error(h) ]
1 . latter probability taken respect D(X); learned hypothesis h thus
error(h) depend it. key challenge active learning avoid bias: actively selected examples
longer i.i.d., thus sample complexity bounds passive learning longer apply. one
careful, active learning may require samples passive learning achieve
generalization error. One natural approach active learning guaranteed perform least
well passive learning pool-based active learning (McCallum & Nigam, 1998): idea
draw n unlabeled examples i.i.d. However, instead obtaining labels, labels adaptively
requested labels unlabeled examples implied obtained labels.
obtained n labeled examples drawn i.i.d., classical PAC bounds still apply. key question
request labels pool infer remaining labels quickly possible.
case binary labels (or test outcomes) L = {1, 1}, various authors considered
greedy policies generalize binary search (Garey & Graham, 1974; Loveland, 1985; Arkin,
Meijer, Mitchell, Rappaport, & Skiena, 1993; Kosaraju et al., 1999; Dasgupta, 2004; Guillory &
Bilmes, 2009; Nowak, 2009). simplest these, called generalized binary search (GBS)
splitting algorithm, works follows. Define version space V set hypotheses consistent observed labels (here assumefiP
fino label noise). worst-case setting,
fi
fi
GBS selects query x X minimizes
hV h(x) . Bayesian setting assume
given prior pHfi hypotheses; case GBS selects query x X minimizes
fiare
fiP
fi
hV pH (h) h(x) . Intuitively policies myopically attempt shrink measure version space (i.e., cardinality probability mass) quickly possible. former provides
O(log |H|)-approximation worst-case number queries (Arkin et al., 1993),
latter provides O(log minh 1pH (h) )-approximation expected number queries (Kosaraju
et al., 1999; Dasgupta, 2004) natural generalization GBS obtains guarantees
larger set labels (Guillory& Bilmes, 2009). Kosaraju
et al. also prove running GBS
0
2
modified prior pH (h) max pH (h), 1/|H| log |H| sufficient obtain O(log |H|)approximation.
Viewed perspective previous sections, shrinking version space amounts
covering false hypotheses stochastic sets (i.e., queries), query x covers hypotheses disagree target hypothesis h x. is, x covers {h : h(x) 6= h (x)}. 8,

454

fiA DAPTIVE UBMODULARITY: HEORY PPLICATIONS

Figure 4: Illustration Active Learning problem, simple special case one-dimensional
data binary threshold hypotheses H = {h : R}, h (x) = 1 x
0 otherwise.

sets may correlated complex ways determined set possible hypotheses.
show, reduction version space mass adaptive submodular, allows us obtain
new analysis GBS using adaptive submodularity, arguably amenable extensions
generalizations previous analyses. new analysis allows us improve



1
previous best bound approximation factor GBS (Dasgupta, 2004) 4 ln minh pH (h)


ln minh 1pH (h) + 1. also show apply GBS modified prior distribution,
approximation factor improved O(ln |H|). result matches lower bound (ln |H|)
Chakaravarthy, Pandit, Roy, Awasthi, Mohania (2007) constant factors.
Theorem 9.1. Bayesian setting aprior pH ona finite
set hypotheses H,
generalized binary search algorithm makes OPT ln minh 1pH (h) + 1 queries expectation
identify hypothesis drawn pH , OPT minimum expected number queries
made policy.
minh pH (h) sufficiently small, running algorithm modified prior

p0H (h) max pH (h), 1/|H|2 improves approximation factor O(ln |H|).
devote better part remainder section proof Theorem 9.1,
several components. first address important special case uniform prior hypotheses,
i.e., pH (h) = 1/|H| h H, reduce case general prior uniform
prior. wish appeal Theorem 5.8, convert problem Adaptive Stochastic
Min Cost Cover problem.
9.1 Reduction Adaptive Stochastic Min Cost Cover
Define realization h hypothesis h H. ground set E = X, outcomes
binary; define = {1, 1} instead using {0, 1} consistent earlier exposition.
h H set h h, meaning h (x) = h(x) x X. define objective
function, first need notation. Given observed labels X O, let V () denote
version space, i.e., set hypotheses h(x) = (x) x dom(). See Fig. 4
illustration active
Plearning problem case indicator hypotheses. set
hypotheses V , let pH (V ) := hV pH (h) denote total prior probability. Finally, let (S, h) =
{(x, h(x)) : x S} function domain agrees h S. define objective
455

fiG OLOVIN & K RAUSE

function
f (S, h ) := 1 pH (V ((S, h))) = pH




h0 : x S, h0 (x) 6= h(x)

use p (h ) = pH (h) = 1/|H| h. Let optimal policy Adaptive Stochastic
Min Cost Cover instance. Note exact correspondence policies
original problem finding target hypothesis problem covering true realization;
h identified target hypothesis version space reduced {h }
occurs h covered. Hence cavg ( ) = OPT. Note assumed
uniform prior hypotheses, f (X, h ) = 1 1/|H| h. Furthermore, instances
selfcertifying.
Lemma 9.2. instances described selfcertifying arbitrary priors pH .
Proof. Intuitively, theses instances selfcertifying cover h policy must identify
h . formally, instances selfcertifying h h ,
f (dom(), h ) = f (X, h ) implies V () = {h}. turn means h
realization consistent , trivially implies realization 0 also
f (dom(), 0 ) = f (X, 0 ); hence instance selfcertifying.
9.2 Uniform Prior
next prove instances generated adaptive submodular strongly adaptive monotone
uniform prior.
Lemma 9.3. instances described above, f strongly adaptive monotone adaptive submodular respect uniform prior pH .
Proof. Demonstrating strong adaptive monotonicity uniform prior amounts proving
adding labels cannot grow version space, clear model. is, query x
eliminates subset hypotheses, queries performed, subset hypotheses
eliminated x cannot grow. Moving adaptive submodularity, consider expected marginal
contribution x two partial realizations , 0 subrealization 0 (i.e.,
0 ), x
/ dom( 0 ). Let [x/o] partial realization domain dom() {x}
agrees domain, maps x o. O, let ao := pH (V ([x/o])), bo :=
pH (V ( 0 [x/o])). Since hypothesis eliminated version space cannot later appear
version space, ao bo o. Next, note expected reduction version space mass
(and hence expected marginal contribution) due selecting x given partial realization
P
P
X o0 6=o ao0
X
o6=o0 ao ao0
P
(x | ) =
ao P [(x) 6= | ] =
ao
= P
.
(9.1)
o0 ao0
o0 ao0

oO

corresponding quantity 0 bo substituted ao Eq. (9.1), O. prove
adaptive submodularity must show (x | ) (x | 0 ) soit suffices show


P
P
P
/zo 0 ~z ~c [0, 1]O : co > 0 , (~z ) :=
o6=o0 zo zo0 / ( o0 zo0 )
functional form expression (x | ) Eq. (9.1). /zo 0
implies growing version space manner cannot decrease expected
456

fiA DAPTIVE UBMODULARITY: HEORY PPLICATIONS

marginal benefit query x, hence shrinking manner cannot increase expected
marginal benefit x. indeed case /zo 0 o. specifically, holds

P
P
2

b6=a zb +
(b,c):b6=c,b6=a,c6=a zb zc
=
0,
P
za
( b zb )2
derived elementary calculus.
Hence apply Theorem 5.8 selfcertifying instance maximum reward threshold Q = 11/|H|, minimum gap = 1/|H|, obtain upper bound OPT (ln (|H| 1) + 1)
number queries made generalized binary search algorithm (which corresponds exactly greedy policy Adaptive Stochastic Min Cost Cover) assumption
uniform prior H.
9.3 Arbitrary Priors
consider general priors H. construct Adaptive Stochastic Min Cost Cover instance
before, change objective function
f (S, h ) := 1 pH (V ((S, h))) + pH (h).

(9.2)

First note instances remain selfcertifying. proof Lemma 9.2 goes completely unchanged modification f . proceed show adaptive submodularity strong
adaptive monotonicity.
Lemma 9.4. objective function f described Eq. (9.2) strongly adaptive monotone
adaptive submodular respect arbitrary priors pH .
Proof. modified objective still adaptive submodular, (S, h ) 7 pH (h) clearly so,
adaptive submodularity defined via linear inequalities preserved taking
nonnegative linear combinations. Note f (X, h ) = 1 h .
Showing f strongly adaptive monotone requires slightly work before. Fix , x
/
dom(), O. must show
E [f (dom(), ) | ] E [f (dom() {x} , ) | , (x) = o] .

(9.3)

Plugging definition f , inequality wish prove may simplified
E [pH () | ] E [pH () | [x/o]] pH (V ()) pH (V ([x/o])).

(9.4)

random realization hypothesis, pH (h ) = pH (h) h. Let Velim :=
V () V ([x/o]) set hypotheses eliminated version space observation
h(x) = o. Rewriting Eq. (9.4), get
X
hV ()

pH (h)2

pH (V ())

X
hV ([x/o])

pH (h)2
pH (Velim ).
pH (V ([x/o]))

457

(9.5)

fiG OLOVIN & K RAUSE

Let LHS9.5 denote left hand side Eq. (9.5). prove Eq. (9.5) follows.
P
2
LHS9.5
[since pH (V ([x/o])) pH (V ())]
hVelim pH (h) /pH (V ())
P

hVelim pH (h) pH (V ())/pH (V ()) [since h V () pH (h) pH (V ())]
= pH (Velim )
conclude f adaptive submodular strongly adaptive monotone.
Hence apply Theorem 5.8 selfcertifying instance maximum reward threshold Q = 1, minimum gap = 1/ minh pH (h). result obtain upper bound
OPT (ln (1/ minh pH (h)) + 1) number queries made generalized binary search
arbitrary priors, completing proof Theorem 9.1.
9.4 Improving Approximation Factor Highly Nonuniform Priors
improve O(log |H|)-approximation event minh pH (h) extremely small
using observation Kosaraju et al. (1999), call policy progressive ifit eliminates least
one hypothesis version space
Let p0H (h) = max pH (h), 1/|H|2 /Z
query.
P
0
modified prior, Z := h0 max pH (h ), 1/|H|2 normalizing
Pconstant. Let
c(, h) cost (i.e., # queries) target h. cavg (, p) :=
h c(, h)p(h)
expected cost prior p. show cavg (, p0H ) good approximation cavg (, pH ). Call h rare pH (h) < 1/|H|2 , common otherwise. First, note


P
0
2 1 + 1/|H|, p0 (h) |H| p (h), h. Hence ,
h0 max pH (h ), 1/|H|
H
|H|+1 H
|H|
cavg (, pH ). Next, show cavg (, p0H ) cavg (, pH ) + 1. Consider
cavg (, p0H ) |H|+1
P
quantity cavg (, p0H ) cavg (, pH ) = h c(, h) (p0H (h) pH (h)). positive contributions
must come rare hypotheses. However, total probability mass p0H
1/|H|, since progressive
c(, h) |H| h, hence difference costs


1
one. Let := ln minh p0 (h) + 1 ln |H|2 + |H| + 1 approximation factor generalH

ized binary search run p0H . Let policy generalized binary search, let
optimal policy prior pH .

|H| + 1
|H| + 1
|H| + 1
cavg (, p0H )
cavg ( , p0H )
cavg ( , pH ) + 1 .
|H|
|H|
|H|


algebra, derive cavg (, pH ) cavg ( , pH ) + 1 ln 2e|H|2 . Thus
general prior simple modification GBS yields O(log |H|)-approximation.
cavg (, pH )

9.5 Extensions Arbitrary Costs, Multiple Classes, Approximate Greedy Policies
result easily generalizes handle setting multiple classes / test outcomes (i.e., |O| 2),
-approximate greedy policies, lose factor approximation factor.
describe Appendix, generalize adaptive submodularity incorporate costs items,
allows us extend result handle query costs well. therefore recover
extensions Guillory
Bilmes
(2009), improving approximation factor GBS


1
item costs ln minh pH (h) + 1. Guillory Bilmes also showed extend technique
458

fiA DAPTIVE UBMODULARITY: HEORY PPLICATIONS



x c(x)
-approximation costs using
Kosaraju et al. (1999) obtain log |H| max
minx c(x)
greedy policy, may combined tighter analysis well give similar result
improved leading constant. Recently, Gupta, Krishnaswamy, Nagarajan, Ravi (2010)
showed simultaneously remove dependence costs probabilities
approximation ratio. Specifically, within context studying adaptive travelling salesman
problem investigated Optimal Decision Tree problem, equivalent active
learning problem consider here. Using clever, complex algorithm adaptive greedy,
achieve (log |H|)-approximation case non-uniform costs general priors.
9.6 Extensions Active Learning Noisy Observations
Theorem 9.1 extensions mentioned far noise free case, i.e., result query x
observes h (x), h target hypothesis. Many practical problems may noisy observations. Nowak (2009) considered case outcomes binary, i.e., = {1, 1},
query may asked multiple times, instance query noise independent. case gives performance guarantees generalized binary search.
setting may appropriate noise due measurement error, applications noise
persistent, i.e., query x asked several times, observation always same. Recently,
Golovin et al. (2010) Bellala Scott (2010) used adaptive submodularity framework obtain first algorithms provable (logarithmic) approximation guarantees active
learning persistent noise.

10. Experiments
Greedy algorithms often straightforward develop implement, explains popular use practical applications, Bayesian experimental design Active Learning,
discussed 9 (also see excellent introduction Nowak, 2009) Adaptive Stochastic Set
Cover, e.g., filter design streaming databases discussed 7. Besides allowing us prove
approximation guarantees algorithms, adaptive submodularity provides following immediate practical benefits:
1. ability use lazy evaluations speed execution.
2. ability generate data-dependent bounds optimal value.
section, empirically evaluate benefits within sensor selection application,
setting similar one described Deshpande, Guestrin, Madden, Hellerstein, Hong (2004).
application, deployed network V wireless sensors, e.g., monitor temperature
building traffic road network. Since sensors battery constrained, must adaptively
select k sensors, then, given sensor readings, predict, e.g., temperature remaining
locations. prediction possible since temperature measurements typically correlated
across space. Here, consider case sensors fail report measurements due
hardware failures, environmental conditions interference.
10.1 Sensor Selection Problem Unreliable Sensors
formally, imagine every location v V associated random variable Xv describing
temperature location, joint probability distribution p (xV ) := P [XV = xV ]
models correlation temperature values. Here, XV = [X1 , . . . , Xn ] random
459

fiG OLOVIN & K RAUSE

vector temperature values. follow Deshpande et al. (2004) assume joint
distribution sensors multivariate Gaussian. sensor v make noisy observation Yv =
Xv + v , v zero mean Gaussian noise known variance 2 . measurements
YA = yA obtained subset locations, conditional distribution p (xV | yA ) :=
P [XV = xV | YA = yA ] allows predictions unobserved locations, e.g., predicting E[XV |
YA = yA ] (which minimizes mean squared error). Furthermore, conditional distribution
quantifies uncertainty prediction: Intuitively, would like select sensors minimize
predictive uncertainty. One way quantify predictive uncertainty use remaining
Shannon entropy
H (XV | YA = yA ) := E [ log2 (p (XV | yA ))] .
would like adaptively select k sensors, maximize expected reduction Shannon entropy (c.f., Sebastiani & Wynn, 2000; Krause & Guestrin, 2009b). However, practice, sensors
often unreliable, might fail report measurements. assume selecting sensor, find whether failed deciding sensor select next. suppose
sensor associated probability pfail (v) failure, case reading reported,
sensor failures independent ambient temperature v. Thus
instance Stochastic Maximization problem E := V , := {working, failed},


f (A, ) := H (XV ) H XV | y{v : (v)=working} .
(10.1)
multivariate normal distributions, entropy given
fi
fi
1
1
fi
fi
H (XV | YA = yA ) = ln(2e)n fiV AA + 2
AV fi ,
2
sets B, AB denotes covariance (matrix) random vectors XA XB .
Note predictive covariance depend actual observations yA , set
chosen locations. Thus,
H (XV | YA = yA ) = H (XV | YA ) ,
usual, H (XV | YA ) = E [H (XV | YA = yA )]. Krause Guestrin (2005) show,
function
g(A) := (XV ; YA ) = H (XV ) H (XV | YA )
(10.2)
monotone submodular, whenever observations YV conditionally independent given XV .
insight allows us apply result 6 show objective f defined Eq. (10.1)
adaptive monotone submodular, using f(S) := g({v : (v, working) S}) E O.
10.1.1 DATA E XPERIMENTAL ETUP
first data set consists temperature measurements network 46 sensors deployed
Intel Research Berkeley, sampled 30 second intervals 5 consecutive days (starting
Feb. 28th , 2004). define objective function respect empirical covariance estimated
data.
also use data traffic sensors deployed along highway I-880 South California.
use traffic speed data working days 6 11 one month, 357
sensors. goal predict speed 357 road segments. estimate empirical
covariance matrix.
460

fiA DAPTIVE UBMODULARITY: HEORY PPLICATIONS

10.1.2 B ENEFITS L AZY E VALUATION
data sets, run adaptive greedy algorithm, using naive implementation (Algorithm 1) accelerated version using lazy evaluations (Algorithm 2). vary probability
sensor failure, evaluate execution time number evaluations function g
(defined Eq. (10.2)) algorithm makes. Figures 5(a) 5(b) plot execution time given
50% sensor failure rate, computer 2.26 GHz dual core processor 4 GB RAM.
applications, function evaluations bottleneck computation, number
serves machine-independent proxy running time. Figures 5(c) 5(d) show
performance ratio terms proxy. temperature data set, lazy evaluations speed
computation factor roughly 3.5 7, depending failure probability.
larger traffic data set, obtain speedup factors 30 38. find benefit
lazy evaluations increases problem size failure probability. dependence
problem size must ultimately explained terms structural properties instances,
also benefit nonadaptive accelerated greedy algorithm. dependence failure probability
simpler explanation. Note applications, accelerated greedy algorithm selects v, fails, need make additional function evaluations select
next sensor. Contrast naive greedy algorithm, makes function evaluation
sensor selected far.
10.1.3 B ENEFITS DATA EPENDENT B OUND
adaptive submodularity allows us prove worst-case performance guarantees adaptive greedy algorithm, many practical applications expected bounds quite
loose. sensor selection application, use data dependent bounds Lemma 5.3
compute upper bound avg max favg ([k] ) described below, compare performance guarantee Theorem 5.2. accelerated greedy algorithm, use upper bounds
marginal benefits stored priority queue instead recomputing marginal benefits,
thus expect somewhat looser bounds. find application, bounds tighter
worst case bounds. also find lazy data dependent bounds almost tight
eager bounds using eagerly recomputed marginal benefits (e | ) latest greatest , though former slightly higher variance. Figures 5(e) 5(f) show performance
greedy algorithm well three bounds optimal value.
Two subtleties arise using data-dependent bounds bound max favg ([k] ).


P
|
first Lemma 5.3 tells us [k]
maxAE,|A|k
eA (e | ), whereas
would like bound difference
h optimal reward algorithms current
expected

reward, conditioned seeing , i.e., E f (E([k] , ), ) f (dom(), ) | . However,
applications f strongly adaptive monotone, strong adaptive monotonicity implies

h





E f (E([k]
, ), ) f (dom(), ) | [k]
| .
(10.3)


Hence, let OPT() := max E f (E([k] , ), ) | , Lemma 5.3 implies
OPT() E [f (dom(), ) | ] +

461

max
AE,|A|k

X
eA

(e | ) .

(10.4)

fiG OLOVIN & K RAUSE

second subtlety obtain sequence bounds Eq. (10.4). consider
(random) sequence partial realizations observed adaptive greedy algorithm, = 0
1 k ,P
obtain k + 1 bounds 0 , . . . , k , := E [f (dom( ), ) | ] +
maxAE,|A|k
eA (e | ). Taking expectation , note , i,
favg ([k] ) E [OPT( )] E [i ] .
Therefore 0 k , random variable whose expectation upper bound
optimal expected reward policy. point may tempted use minimum
these, i.e., min := mini {i } ultimate bound. However, collection random variables
X0 , . . . , Xk E [Xi ] not, general, satisfy mini {Xi } .
possible case, independent sensor failures, use concentration inequalities bound
mini {i } mini {E [i ]} high probability, thus add appropriate term obtain true
upper bound min , take different approach; simply use average bound avg :=
1 Pk
i=0 . course, depending application, particular bound (chosen independently
k+1
sequence 0 , 1 , . . . , k ) may superior. example, g modular, 0 best,
whereas g exhibits strong diminishing returns, bounds larger values may
significantly tighter.

11. Adaptivity Gap
important question adaptive optimization much better adaptive policies perform
compared non-adaptive policies. quantified adaptivity gap,
worst-case ratio, problem instances, performance optimal adaptive policy
optimal non-adaptive solution. Asadpour et al. (2008) show Stochastic Submodular
Maximization problem independent failures (as considered 6), expected value
optimal non-adaptive policy constant factor 1 1/e worse expected value
optimal adaptive policy. currently lower bounds adaptivity
gap general Adaptive Stochastic Maximization problem (2.1), show even
case adaptive submodular functions, min-cost cover min-sum cover versions large
adaptivity gaps, thus large benefit using adaptive algorithms. cases,
adaptivity gap defined worst-case ratio expected cost optimal non-adaptive
policy divided expected cost optimal adaptive policy. Adaptive Stochastic
Minimum Cost Coverage problem (2.2), Goemans Vondrak (2006) show special case
Stochastic Set Coverage without multiplicities adaptivity gap (|E|). exhibit
adaptive stochastic optimization instance adaptivity gap (|E|/ log |E|) Adaptive
Stochastic Min-Sum Cover problem (2.3), also happens adaptivity gap
Adaptive Stochastic Minimum Cost Coverage.
Theorem 11.1. Even adaptive submodular functions, adaptivity gap Adaptive Stochastic
Min-Sum Cover (n/ log n), n = |E|.
Proof. Suppose E = {1, . . . , n}. Consider active learning problem hypotheses
h : E {1, 1} threshold functions, i.e., h(e) = 1 e ` h(e) = 1 e < `
threshold `. uniform distribution thresholds ` {1, . . . , n + 1}.
order identify correct hypothesis threshold `, policy must observe least one
` 1 ` (and 1 < ` n). Let optimal non-adaptive policy
462

fiA DAPTIVE UBMODULARITY: HEORY PPLICATIONS

Time Standard Accelerated Adaptive Greedy

0.45
0.4

Time Standard Accelerated Adaptive Greedy

40
35

Adaptive Greedy

0.35

Adaptive Greedy

30

0.3

25

0.25
20

0.2
15

0.15

Accelerated Adaptive Greedy
10

0.1

5

0.05
0

0

5

10

15

20

25

30

35

40

45

0

50

Accelerated Adaptive Greedy
0

50

100

150

200

250

300

350

(a) Temperature Data: Execution time (sec)
naive vs accelerated implementations adaptive greedy vs. budget k number sensors
selected, pfail (v) = 0.5 v, plotted
standard errors.

(b) Traffic Data: Execution time (sec)
naive vs accelerated implementations adaptive greedy vs. budget k number sensors selected, pfail (v) = 0.5 v,
plotted standard errors.

8

45

Redu ction Function Evaluations vs. Pr[failure]

7
6
5
4

Reduction Function Evaluations vs . Pr [failur e]

40

90%
80%
70%
60%
50%
40%
30%
20%
10%

75%

35

50%
25%

30
25
20
15

3

10

2

5

1
0

10

20

30

40

0
0

50

100

200

300

400

(c) Temperature Data: ratio function evaluations made naive vs accelerated implementations adaptive greedy vs. budget k
number sensors selected, various failure
rates. Averaged 100 runs.

(d) Traffic Data: ratio function evaluations
made naive vs accelerated implementations
adaptive greedy vs. budget k number
sensors selected, various failure rates. Averaged 10 runs.

Reward Adaptive Greedy, DataDependent Bounds

Reward Adaptive Greedy, DataDependent Bounds

100

150

90

Standard Bound
Lazy Adaptive Bound
Adaptive Bound

Standard Bound
Lazy Adaptive Bound
Adaptive Bound

80
70

100

60
50
40
50

30

Adaptive Greedy

Adaptive Greedy
20
10
0

0

5

10

15

20

25

30

35

40

45

0

50

(e) Temperature Data: Rewards & bounds
optimal value pfail (v) = 0.5 v vs.
budget k number sensors selected, plotted
standard errors.

0

50

100

150

200

250

300

350

400

(f) Traffic Data: Rewards & bounds optimal value pfail (v) = 0.5 v vs.
budget k number sensors selected, plotted
standard errors.

Figure 5: Experimental results.
463

fiG OLOVIN & K RAUSE

problem. Note represented permutation E, observing element
multiple times increase cost providing benefit observing once,
element must eventually selected guarantee coverage. min-sum cover objective,
consider playing n/4 time steps. P [` observed n/4 steps] = n/4(n + 1). Likewise
P [` 1 observed n/4 steps] = n/4(n + 1). Since least one events must occur
identify correct hypothesis, union bound
P [ identifies correct hypothesis n/4 steps]



n
2(n + 1)



1/2.

Thus lower bound expected cost n/8, since n/4 time steps cost least
1/2 incurred. Thus, min-cost min-sum cover objectives cost optimal
non-adaptive policy (n).
example adaptive policy, implement natural binary search strategy,
guaranteed identify correct hypothesis O(log n) steps, thus incurring cost O(log n),
proving adaptivity gap (n/ log n).

12. Hardness Approximation
paper, developed notion adaptive submodularity, characterizes
certain adaptive stochastic optimization problems well-behaved sense simple greedy
policy obtains constant factor logarithmic factor approximation best policy.
contrast, also show without adaptive submodularity, adaptive stochastic optimization problems (2.1), (2.2), (2.3) extremely inapproximable, even (pointwise)
modular objective functions (i.e., , f : 2E OE R modular/linear
first argument): cannot hope achieve O(|E|1 ) approximation ratio problems, unless polynomial hierarchy collapses P2 .
Theorem 12.1. (possibly non-constant) 1, polynomial time algorithm Adaptive
Stochastic Maximization budget k items approximate reward optimal policy
budget k items within multiplicative factor O(|E|1 /) > 0, unless
PH = P2 . holds even pointwise modular f .
provide proof Theorem 12.1 Appendix A.7. Note setting = 1,
obtain O(|E|1 ) hardness Adaptive Stochastic Maximization. turns instance
distribution construct proof Theorem 12.1 optimal policy covers every realization
(i.e., always finds treasure) using budget k = O(|E|/2 ) items. Hence PH 6= P2
randomized polynomial time algorithm wishing cover instance must budget
= (|E|1 ) times larger optimal policy, order ensure ratio rewards,
(|E|1 /), equals one. yields following corollary.
Corollary 12.2. polynomial time algorithm Adaptive Stochastic Min Cost Coverage
approximate cost optimal policy within multiplicative factor O(|E|1 )
> 0, unless PH = P2 . holds even pointwise modular f .
Furthermore, since instance distribution construct optimal policy covers every
realization using budget k, c ( ) k. Moreover, since shown
complexity theoretic assumptions, polynomial time randomized policy budget k
464

fiA DAPTIVE UBMODULARITY: HEORY PPLICATIONS

achieves o(/|E|1 ) (unit) value obtained optimal policy budget k,
follows c () = (k). Since require = (|E|1 ) cover set realizations
constituting, e.g., half probability mass, obtain following corollary.
Corollary 12.3. polynomial time algorithm Adaptive Stochastic Min-Sum Cover approximate cost optimal policy within multiplicative factor O(|E|1 ) > 0,
unless PH = P2 . holds even pointwise modular f .

13. Related Work
large literature adaptive optimization partial observability relates adaptive submodularity, broadly organized several different categories. Here,
review relevant related work already discussed elsewhere manuscript.
13.1 Adaptive Versions Classic Non-adaptive Optimization Problems
Many approaches consider stochastic generalizations specific classic non-adaptive optimization
problems, Set Cover (Goemans & Vondrak, 2006; Liu et al., 2008), Knapsack (Dean, Goemans, & Vondrak, 2008, 2005) Traveling Salesman (Gupta et al., 2010). contrast,
paper goal introduce general problem structure adaptive submodularity unifies
number adaptive optimization problems. similar classic notion submodularity unifies various optimization problems Set Cover, Facility Location, nonadaptive
Bayesian Experimental Design, etc.
13.2 Competitive Online Optimization
Another active area research sequential optimization study competitive online algorithms. particularly relevant example Online Set Cover (Alon, Awerbuch, Azar, Buchbinder,
& Naor, 2009), known set system, arbitrary sequence elements presented
algorithm, algorithm must irrevocably select sets purchase times
purchased sets cover elements appeared far. Alon et al. (2009) obtain
polylogarithmic approximation problem, via online primaldual framework
profitably applied many problems. Buchbinder Naor (2009) provide detailed
treatment framework. Note competitive analysis focuses worstcase scenarios.
contrast, assume probabilistic information world optimize average case.
13.3 (Noisy) Interactive Submodular Set Cover
Recent work Guillory Bilmes (2010, 2011) considers class adaptive optimization problems family monotone submodular objectives {fh : h H}. problem, one must
cover monotone submodular objective fh depends (initially unknown) target hypothesis h H, adaptively issuing queries getting responses. Unlike traditional pool-based
active learning, query may generate response set valid responses depending
target hypothesis. reward calculated evaluating fh set (query, response) pairs
observed, goal obtain threshold Q objective value minimum total query cost,
queries may nonuniform costs. noisy variant problem (Guillory & Bilmes,
2011), set (query, response) pairs observed need consistent hypothesis H,
465

fiG OLOVIN & K RAUSE

goal obtain Q value hypotheses close consistent
observations. variants, Guillory Bilmes consider worst-case policy cost, provide greedy algorithms optimizing clever hybrid objective functions. prove approximation
guarantee ln(Q|H|) + 1 integer valued objective functions {fh }hH noisefree case,
similar logarithmic approximation guarantees noisy case.
similar spirit work, several significant differences two.
Guillory Bilmes focus worst-case policy cost, focus mainly average-case policy
cost. structure adaptive submodularity depends prior p (), whereas
dependence Interactive Submodular Set Cover. dependence turn allows us obtain
results, Theorem 5.8 selfcertifying instances, whose approximation guarantee
depend number realizations way guarantees Interactive Submodular Set
Cover depend |H|. Guillory Bilmes prove, latter dependence fundamental
reasonable complexity-theoretic assumptions6 . interesting open problem within adaptive
submodularity framework highlighted work Interactive Submodular Set Cover
identify useful instance-specific properties sufficient improve upon worst-case
approximation guarantee Theorem 5.9.
13.4 Greedy Frameworks Adaptive Optimization
paper perhaps closest spirit work one Stochastic Depletion problems
Chan Farias (2009), also identify general class adaptive optimization problems
near-optimally solved using greedy algorithms (which setting give factor
2 approximation). However, similarity mainly conceptual level: problems
approaches, well example applications considered, quite different.
13.5 Stochastic Optimization Recourse
class adaptive optimization problems studied extensively operations research (since Dantzig,
1955) area stochastic optimization recourse. Here, optimization problem,
Set Cover, Steiner Tree Facility Location, presented multiple stages. stage,
information revealed, costs actions increase. key difference problems studied
paper problems, information gets revealed independently actions taken
algorithm. general efficient, sampling based (approximate) reductions multi-stage
optimization deterministic setting (see, e.g., Gupta, Pal, Ravi, & Sinha, 2005).
13.6 Bayesian Global Optimization
Adaptive Stochastic Optimization also related problem Bayesian Global Optimization
(c.f., Brochu, Cora, & de Freitas, 2009, recent survey area). Bayesian Global Optimization, goal adaptively select inputs order maximize unknown function
expensive evaluate (and possibly evaluated using noisy observations). common approach successful many applications (c.f., Lizotte, Wang, Bowling, & Schuurmans,
2007, recent application machine learning), assume prior distribution, Gaus6. reduce Set Cover use result Feige (1998), requires assumption NP *
DTIME(nO(log log n) ), suffices assume P 6= NP using Set Cover approximation hardness result
Raz Safra (1997) instead.

466

fiA DAPTIVE UBMODULARITY: HEORY PPLICATIONS

sian process, unknown objective function. Several criteria selecting inputs
developed, Expected Improvement (Jones, Schonlau, & Welch, 1998) criterion. However, recently performance guarantees obtained no-regret setting (Grunewalder,
Audibert, Opper, & Shawe-Taylor, 2010; Srinivas, Krause, Kakade, & Seeger, 2010),
aware approximation guarantees Bayesian Global Optimization.
13.7 Probabilistic Planning
problem decision making partial observability also extensively studied
stochastic optimal control. particular, Partially Observable Markov Decision Processes (POMDPs,
Smallwood & Sondik, 1973) general framework captures many adaptive optimization
problems partial observability. Unfortunately, solving POMDPs PSPACE hard (Papadimitriou & Tsitsiklis, 1987), thus typically heuristic algorithms approximation guarantees
applied (Pineau, Gordon, & Thrun, 2006; Ross, Pineau, Paquet, & Chaib-draa, 2008).
special instances POMDPs related Multi-armed Bandit problems, (near-)optimal policies
found. include (optimal) Gittins-index policy classic Multi-armed Bandit problem (Gittins & Jones, 1979) approximate policies Multi-armed Bandit problem
metric switching costs (Guha & Munagala, 2009) special cases Restless Bandit problem (Guha, Munagala, & Shi, 2009). problems considered paper formalized
POMDPs, albeit exponentially large state space (where world state represents selected
items state/outcome item). Thus results interpreted widening class
partially observable planning problems efficiently approximately solved.
13.8 Previous Work Authors & Subsequent Developments
manuscript extended version paper appeared Conference Learning
Theory (COLT; Golovin & Krause, 2010). recently, Golovin Krause (2011) proved performance guarantees greedy policy problem maximizing expected value
policy constraints complex simply selecting k items. include matroid constraints, policy select independent sets items greedy policy
obtains 1/2approximation adaptive monotone submodular objectives, generally
p-independence system constraints, greedy policy obtains 1/(p + 1)approximation.
Golovin et al. (2010) and, shortly thereafter, Bellala Scott (2010), used adaptive submodularity framework obtain first algorithms provable (logarithmic) approximation guarantees
difficult fundamental problem active learning persistent noise. Finally, Golovin,
Krause, Gardner, Converse, Morey (2011) used adaptive submodularity context
dynamic conservation planning, obtain competitiveness guarantees ecological reserve
design problem.

14. Conclusions
Planning partial observability central notoriously difficult problem artificial intelligence. paper, identified novel, general class adaptive optimization problems
uncertainty amenable efficient, greedy (approximate) solution. particular, introduced concept adaptive submodularity, generalizing submodular set functions adaptive
policies. generalization based natural adaptive analog diminishing returns prop-

467

fiG OLOVIN & K RAUSE

erty well understood set functions. special case deterministic distributions, adaptive
submodularity reduces classical notion submodular set functions. proved several
guarantees carried non-adaptive greedy algorithm submodular set functions generalize
natural adaptive greedy algorithm case adaptive submodular functions, constrained
maximization certain natural coverage problems minimum cost minimum sum
objectives. also showed adaptive greedy algorithm accelerated using lazy evaluations, one compute data-dependent bounds optimal solution. illustrated
usefulness concept giving several examples adaptive submodular objectives arising
diverse AI applications including sensor placement, viral marketing, automated diagnosis
pool-based active learning. Proving adaptive submodularity problems allowed us recover existing results applications special cases lead natural generalizations.
experiments real data indicate adaptive submodularity provide practical benefits,
significant speed ups tighter data-dependent bounds. believe results provide
interesting step direction exploiting structure solve complex stochastic optimization
planning problems partial observability.
Acknowledgments
extended abstract work appeared COLT 2010 (Golovin & Krause, 2010). wish
thank anonymous referees helpful suggestions. research partially supported
ONR grant N00014-09-1-1044, NSF grant CNS-0932392, NSF grant IIS-0953413, DARPA MSEE
grant FA8650-11-1-7156, gift Microsoft Corporation, Okawa Foundation Research Grant,
Caltech Center Mathematics Information.

Appendix A. Additional Proofs Incorporating Item Costs
appendix provide proofs omitted main text. results 5,
first explaining results generalize case items costs,
proving generalizations incorporate item costs.
A.1 Incorporating Costs: Preliminaries
section provide preliminaries required define analyze versions problems non-uniform item costs. suppose item
P e E cost c(e), cost
set E given modular function c(S) = eS c(e). define generalizations
problems (2.1), (2.2), (2.3) A.3, A.4, A.5, respectively.
results respect greedy policy greedy -approximate greedy policies.
costs, greedy policy selects item maximizing (e | ) /c(e), current
partial realization.
Definition A.1 (Approximate Greedy Policy Costs). policy -approximate greedy
policy exists e E (e | ) > 0,



(e | )
1
(e0 | )
() e :

max
,
c(e)
e0
c(e0 )
terminates upon observing (e | ) 0 e E. is, approximate greedy policy always obtains least (1/) maximum possible ratio condi468

fiA DAPTIVE UBMODULARITY: HEORY PPLICATIONS

tional expected marginal benefit cost, terminates benefit obtained
expectation. greedy policy 1-approximate greedy policy.
convenient imagine policy executing time, policy selects
item e, starts run e, finishes running e c(e) units time. next generalize
definition policy truncation. Actually require three generalizations,
equivalent unit cost case.
Definition A.2 (Strict Policy Truncation). strict level truncation policy , denoted
[t] , obtained running time units, unselecting items whose runs finn

P
ished time t. Formally, [t] domain dom() : c(()) + edom() c(e) ,
agrees everywhere domain.
Definition A.3 (Lax Policy Truncation). lax level truncation policy , denoted [t] ,
obtained running time units, selecting items running time t. Formally, [t]

n
P
c(e)
<

, agrees everywhere domain.
domain dom() :
edom()
Definition A.4 (Policy Truncation Costs). level-t-truncation policy , denoted
[t] , randomized policy obtained running time units, item e
running 0 < c(e) time time t, selecting e independently probability /c(e). Formally, [t] randomized policy agrees everywhere domain, dom([t] )
dom([t] ) dom([t] ) certainty, includes dom([t] ) \ dom([t] )


P
domain independently probability edom() c(e) /c(()).
proofs follow, need notion conditional expected cost policy,
well alternate characterization adaptive monotonicity, based notion policy concatenation. prove equivalence two adaptive monotonicity conditions Lemma A.8.
Definition A.5 (Conditional Policy Cost). conditional policy cost conditioned , denoted c ( | ), expected cost items selects p ( | ). is, c ( | ) :=
E [c(E(, )) | ].
Definition A.6 (Policy Concatenation). Given two policies 1 2 define 1 @2 policy
obtained running 1 completion, running policy 2 fresh start, ignoring
information gathered7 running 1 .
Definition A.7 (Adaptive Monotonicity (Alternate Version)). function f : 2E OE R0
adaptive monotone respect distribution p () policies 0 , holds
favg () favg ( 0 @), favg () := E [f (E(, ), )] defined w.r.t. p ().
Lemma A.8 (Adaptive Monotonicity Equivalence). Fix function f : 2E OE R0 .
(e | ) 0 P [ ] > 0 e E policies 0 ,
favg () favg ( 0 @).
7. Technically, realization policy 2 selects item 1 previously selected, 1 @2 cannot
written function set partial realizations E, i.e., policy. amended allowing
partial realizations multisets elements E O, that, e.g., e played twice (e, (e)) appears
twice . However, interest readability avoid cumbersome multiset formalism, abuse
notation slightly calling 1 @2 policy. issue arises whenever run policy run another
fresh start.

469

fiG OLOVIN & K RAUSE

Proof. Fix policies 0 . begin proving favg ( 0 @) = favg (@ 0 ). Fix note
E( 0 @, ) = E( 0 , ) E(, ) = E(@ 0 , ). Hence




favg ( 0 @) = E f (E( 0 @, ), ) = E f (E(@ 0 , ), ) = favg (@ 0 ).
Therefore favg () favg ( 0 @) holds favg () favg (@ 0 ).
first prove forward direction. Suppose (e | ) 0 e E. Note
expression favg (@ 0 ) favg () written conical
P combination (nonnegative) (e0| )
0
terms, i.e., 0, favg (@ ) favg () = ,e (,e) (e | ). Hence favg (@ )
favg () 0 favg () favg (@ 0 ) = favg ( 0 @).
next prove backward direction, contrapositive form. Suppose (e | ) < 0
P [ ] > 0 e E. Let e1 , . . . , er items dom() define policies
0 follows. = 1, 2, . . . , r, 0 select ei observe (ei ). either policy
observes (ei ) 6= (ei ) immediately terminates, otherwise continues. succeeds selecting
dom() terminates. 0 succeeds selecting dom() selects e
terminates. claim favg (@ 0 ) favg () < 0. Note E(@ 0 , ) = E(, ) unless ,
E(@ 0 , ) = E(, ) {e} also E(, ) = dom(). Hence


favg (@ 0 ) favg () = E f (E(@ 0 , ), ) f (E(, ), )


= E f (E(@ 0 , ), ) f (E(, ), ) | P [ ]
= E [f (dom() {e} , ) f (dom(), ) | ] P [ ]
= (e | ) P [ ]
last term negative, P [ ] > 0 (e | ) < 0 assumption. Therefore favg () >
favg (@ 0 ) = favg ( 0 @), completes proof.
A.2 Adaptive Data Dependent Bounds Costs
adaptive data dependent bound following generalization costs.
Lemma A.9 (The Adaptive Data Dependent Bound Costs). Suppose made observations selecting dom(). Let policy. adaptive monotone submodular
f : 2E OE R0


(e | )


( | ) Z c ( | ) max
(A.1)
e
c(e)

P
P
| ) e E, 0 w 1 .
w
(e
|
)
:
c(e)w

c
(
Z = maxw
e
e
e
eE
e
Proof. Order items dom() arbitrarily, consider policy e dom()
order selects e, terminating (e) 6= (e) proceeding otherwise, and, succeed
selecting dom() without terminating (which occurs iff ), proceeds run
fresh start, forgetting observations . construction expected marginal
benefit running portion conditioned equals ( | ). e E, let
w(e) = P [e E(, ) | ] probability e selected running , conditioned
. Whenever e E \ dom() selected , current partial realization
0 contains subrealization; hence adaptive submodularity implies (e | 0 ) (e | ).
470

fiA DAPTIVE UBMODULARITY: HEORY PPLICATIONS

follows total contribution e ( | ) upperPbounded w(e) (e | ). Summing
e E \ dom(), get bound ( | )
eE\dom() w(e)(e | ). Next, note

w(e)c(e) cost c ( | ). Hence must case
P e E \ dom() contributes

eE\dom() w(e)c(e)
P c ( | ). Obviously, w(e) [0, 1] e, since w(e) probability.

Hence ( | ) eE\dom() w(e)(e | ) Z setting = w(e) feasible
linear program Z optimal value.
show Z c ( | ) maxe ((e | ) /c(e)), consider feasible solution w linear
program defining Z. attains objective value




X
X
(e | ) X
(e | )
(e | )
(e | )
c(e)
c ( | ) max

c(e) max
eE
eE
c(e)
c(e)
c(e)
eE
eE
eE
P
since eE c(e) c ( | ) feasibility w.
simple greedy algorithm used compute Z; provide pseudocode Algorithm 3. correctness algorithm readily discerned upon rewriting linear
program using variables xe = c(e)we obtain
(
)
X
X

Z = max
xe ((e | ) /c(e)) :
xe c ( | ) e E, 0 xe c(e) .
x

eE

e

Intuitively, clear optimize x shift
variables highest
Pmass towards

(e | ) /c(e) ratio. Clearly, optimal solution e xe = c ( | ). Moreover, optimal solution, (e | ) /c(e) > (e0 | ) /c(e0 ) implies xe = c(e) xe0 = 0, since otherwise
would possible shift mass xe0 xe obtain increase objective value.
(e | ) /c(e) values distinct distinct items, unique solution satisfying
constraints, Algorithm 3 compute. Otherwise, imagine perturbing (e | )
independent random quantities e drawn uniformly [0, ] make distinct. changes
optimum value
Pby |E|, vanishes let tend towards zero. Hence solution satisfying e xe = c ( | ) (e | ) /c(e) > (e0 | ) /c(e0 ) implies xe = c(e)
xe0 = 0 optimal. Since Algorithm 3 outputs value solution, correct.
A.3 Max-Cover Objective
item costs, Adaptive Stochastic Maximization problem becomes one finding
arg max favg ([k] )

(A.2)



k budget cost selected items, define favg () randomized policy
favg () := E [f (E(, ), )] before, expectation internal randomness determines E(, ) . prove following generalization
Theorem 5.2.
Theorem A.10. Fix 1 item costs c : E N. f adaptive monotone adaptive
submodular respect distribution p (), -approximate greedy policy,
policies positive integers ` k



favg ([`] ) > 1 e`/k favg ([k]
).
471

fiG OLOVIN & K RAUSE

Input: Groundset E; Partial realization ; Costs c : E N; Budget C = c ( | );
Conditional expected marginal benefits (e | ) e E.
Output: Z = P

P

maxw
eE (e | ) :
e c(e)we c ( | ) e E, 0 1
begin
(e2 | )
(en | )
1 | )
Sort E (e | ) /c(e), (e
c(e1 ) c(e2 ) . . . c(en ) ;
Set w 0; 0; 0; z 0; e NULL;
< C
+ 1; e ei ;
min {1, C a};
+ c(e)we ; z z + (e | );
Output z;
end
Algorithm 3: Algorithm compute data dependent bound Z Lemma A.9.
Proof. proof goes along lines performance analysis greedy algorithm
maximizing submodular function subject cardinality constraint Nemhauser et al. (1978).
extension analysis -approximate greedy algorithms, analogous
nonadaptive case, shown Goundan Schulz (2007). brevity, assume
. i, 0 < `
without loss generality = [`] = [k]

favg ( ) favg ([i] @ ) favg ([i] ) + k favg ([i+1] ) favg ([i] ) .
(A.3)
first inequality due adaptive monotonicity f Lemma A.8, may
infer favg (2 ) favg (1 @2 ) 1 2 . second inequalitymay obtained corol
lary Lemma A.9 follows. Fix partial realization form (e, (e)) : e E([i] , )
. Consider ( | ), equals expected marginal benefit portion
[i] @ conditioned . Lemma A.9 allows us bound
E [( | )] E [c ( | )] max ((e | ) /c(e)) ,
e

expectations taken internal randomness , any. Note since
0 0 know , E [c(E( , ))] k, expectation
form [k]
taken internal randomness . Hence E [c ( | )] k . follows
E [( | )] k maxe ((e | ) /c(e)). definition -approximate greedy policy,
obtains least (1/) maxe ((e | ) /c(e)) E [( | )] /k expected marginal benefit per
unit cost step immediately following observation . Next take appropriate convex combination previous inequality
different values . Let
random partial

realization distributed p () := P = | . = (e, (e)) : e E([i] , )



1
(e | )
favg ([i+1] ) favg ([i] ) E
max
e
c(e)



E [( | )]
E
k
favg ([i] @ ) favg ([i] )
=
k
472

fiA DAPTIVE UBMODULARITY: HEORY PPLICATIONS

simple rearrangement terms yields second inequality (A.3).
define := favg ( ) favg ([i] ), (A.3) implies k(i i+1 ),


1
1 `
infer i+1 1 k
hence ` 1 k
0 < e`/k 0 ,
x
last inequality used fact 1 x < e x > 0. Thus favg ( ) favg ([`] ) <

e`/k favg ( ) favg ([0] ) e`/k favg ( ) favg () > (1 e`/k )favg ( ).

A.4 Min-Cost-Cover Objective
section, provide arbitrary item cost generalizations Theorem 5.8 Theorem 5.9.
item costs Adaptive Stochastic Minimum Cost Cover problem becomes one finding,
quota utility Q,
arg min cavg () f (E(, ), ) Q ,

(A.4)



cavg () := E [c(E(, ))]. Without loss generality, may take truncated version f ,
namely (A, ) 7 min {Q, f (A, )}, rephrase Problem (A.4) finding
arg min cavg () covers .

(A.5)



Hereby, recall covers E [f (E(, ), )] = f (E, ), expectation
internal randomness . consider Problem (A.5) remainder. also consider
worst-case variant problem, replace expected cost cavg () objective
worst-case cost cwc () := max c(E(, )).
definition coverage (Definition 5.4 5.2 page 441) requires modification handle item costs. Note, however, coverage all-or-nothing sense covering realization
probability less one count covering it. corollary items
whose runs finished help coverage, whereas currently running items not. simple
example, consider case E = {e}, c(e) = 2, f (A, ) = |A|, policy selects
e terminates. [1] randomized policy probability 12 ,
empty policy probability 12 , E [f (E(, ), )] = 12 < 1 = f (E, ) . Hence, even
though half time [1] covers realizations, counted covering any.
begin approximation guarantee average-case policy cost arbitrary item
costs.
Theorem A.11. Suppose f : 2E OE R0 adaptive submodular strongly adaptive
monotone respect p () exists Q f (E, ) = Q . Let
value f (S, ) > Q implies f (S, ) = Q . Let = min p ()
optimal policy minimizing expected
minimum probability realization. Let avg
number items selected guarantee every realization covered. Let -approximate
greedy policy respect item costs. general


Q

cavg () cavg (avg ) ln
+1


473

fiG OLOVIN & K RAUSE

selfcertifying instances


Q

+1 .
cavg () cavg (avg
) ln

Note range(f ) Z, = 1 valid choice, general selfcertifying ) (ln(Q/) + 1) c

stances cavg () cavg (avg
avg () cavg (avg ) (ln(Q) + 1),
respectively.
Proof. Consider running -approximate greedy policy completion, i.e., covers true
realization. starts v0 := E [f (, )] 0 reward expectation, terminates Q
reward. Along way go sequence partial realizations specifying current
observations, 0 1 ` , dom( ) \ dom( i1 ) consists precisely ith
item selected . call sequence trace = () . realization x R0 ,
define (, x) partial realization seen achieved x reward expectation
. Formally,
(, x) arg max {| dom()| : (), E [f (dom(), ) | ] < x} .

(A.6)

Note (, x) exists x (v0 , Q], exists unique since two elements
trace equally large domains. Also note strong adaptive monotonicity f ,
function 7 E [f (dom( ), ) | ] must nondecreasing trace 0 , 1 , . . . , ` .
overall strategy bound expected cost cavg () bounding price pays
per unit expected reward gained runs,
integrating
run. Note Lemma A.9
| /c | . -approximate greedy
tells us maxe ((e | ) /c(e)) avg
avg
policy obtains least 1/ rate. Hence may bound price, denote ,




() c avg
| / avg
| .
(A.7)
Rather try bound expected price progresses time, bound expected
price progresses expected reward obtains, measured E [f (dom(),
) | ]
| (, x) Q x
current partial realization. next claim avg
x. Note E [f (dom( (, x)), ) | (, x)] < x definition (, x),
, ), ) = Q since covers every realization. Since Q maximum possible
f (E(avg
avg

| (, x) < Q x generate violation strong adaptive monoreward, avg
, 0 ), selecting dom( (, x))
tonicity fixing 0 (, x), selecting E(avg

| (, x) Q x, infer
reduce expected reward. Thus avg


| (, x)
| (, x)
c avg
c avg

( (, x))
.
(A.8)
| (, x)
Qx
avg
Next, take expectation . Let (x) := E [( (, x))]. Let x1 , . . . , xr possible
values (, x). {{ : xi } : = 1, 2, . . . , r} partitions set realizations,
r
X
X





E c avg
| (, x)
=
P [ xi ]
p ( | xi ) c avg
|
i=1

=

X

(A.9)



p () c


avg
|



(A.10)



= cavg (avg
)

474

(A.11)

fiA DAPTIVE UBMODULARITY: HEORY PPLICATIONS

follows
(x)

)
cavg (avg
.
Qx

(A.12)

Let cavg (, Q0 ) denote expected cost obtain expected reward Q0 . bound cavg (, Q0 )



Z Q0
Z Q0
cavg ( )
Q
cavg (, Q0 ) =
(x)dx
dx = cavg ( ) ln
.
(A.13)
Qx
Q Q0
x=0
x=0
use slightly different analyses general instances selfcertifying instances.
begin general instances. these, set Q0 = Q use refined argument
bound cost getting remaining expected reward. Fix dom() 0 .
say covers 0 covers 0 time observes . definition , 0
covered Q E [f (dom(), ) | ] . Hence last item selects, say
upon observing , must increase conditional expected value E [f (dom(), ) | ]
Q Q. Eq. (A.8), follows x [Q , Q],


| (, x)
| (, x)
c avg
c avg

( (, x))
.
| (, x)

avg
)/ x [Q
before, may take expectation obtain (x) cavg (avg
, Q]. fact together Eq. (A.13) yield

cavg () cavg (, Q) = cavg (, Q ) +

RQ
x=Q

cavg ( ) ln (Q/) +

E [(x)] dx

RQ
x=Q

cavg ( )
dx


= cavg ( ) (ln (Q/) + 1)
completes proof general instances.
selfcertifying instances use similar argument. instances set Q0 = Q ,
argue last item selects must increase conditional expected value
Q Q. suppose currently observes , achieved conditional value Q,
i.e., E [f (dom(), ) | ] < Q. uncovered. Since instance self
certifying, every f (dom(), ) < f (E, ) = Q. definition ,
f (dom(), ) Q , implies E [f (dom(), ) | ]
Q . Reasoning analogously general instances, may derive (x)
R
)/ x [Q , Q]. Computing c () = c (, Q0 ) + Q
cavg (avg
avg
avg
x=Q0 E [(x)] dx
gives us claimed approximation ratio selfcertifying instances, completes
proof.
Next consider worst-case cost. generalize Theorem 5.9 incorporating arbitrary item
costs.
Theorem A.12. Suppose f : 2E OE R0 adaptive monotone adaptive submodular
respect p (), let value f (S, ) > f (E, ) implies f (S, ) = f (E, )

. Let = min p () minimum probability realization. Let wc
optimal policy minimizing worst-case cost cwc () guaranteeing every realization
475

fiG OLOVIN & K RAUSE

covered. Let -approximate greedy policy respect item costs. Finally, let
Q := E [f (E, )] maximum possible expected reward.


Q

+1 .
cwc () cwc (wc ) ln

), let ` = k ln (Q/),
Proof. Let -approximate greedy policy. Let k = cwc (wc
apply Theorem A.10 parameters yield





`/k


favg ([`] ) > 1 e
favg (wc ) = 1
favg (wc
).
(A.14)
Q
covers every realization assumption, f ( ) = E [f (E, )] = Q, rearranging
Since wc
avg wc
terms Eq. (A.14) yields Q favg ([`] ) < . Since favg ([`] ) favg ([`] ) adaptive
monotonicity f , follows Q favg ([`] ) < . definition ,
covered [`] Q favg ([`] ) . Thus Q favg ([`] ) < implies Q favg ([`] ) =
0, meaning [`] covers every realization.
next claim [`] worst-case cost ` + k. sufficient show
final item executed [`] cost k realization. prove, follows
covers every realization cost
facts -approximate greedy policy wc
k. data dependent bound, Lemma A.9 page 470, guarantees


| )
| )
(e | )
(wc
(wc
max


.
(A.15)
| )
e
c(e)
c (wc
k
| ). Supposing
Suppose dom(). would like say maxe (e | ) (wc
| ) /k, hence
true, item e cost c(e) > k must (e | ) /c(e) < (wc
cannot selected -approximate greedy policy upon observing Eq. (A.15), thus
final item executed [`] cost k realization. next show
| ). Towards end, note Lemma A.13 implies
maxe (e | ) (wc

max (e | ) E [f (E, ) | ] E [f (dom(), ) | ] .
e

(A.16)

| ) suffices show
prove maxe (e | ) (wc

E [f (E, ) | ] E [f (E(wc
, ) dom(), ) | ] .

(A.17)

Proving Eq. (A.17) quite straightforward f strongly adaptive monotone. Given f
adaptive monotone, requires additional effort. fix E let nonadaptive policy selects items arbitrary order. Let P := { : dom() = A}.
P obtain
Apply Lemma A.13 0 = @wc

E [f (E(wc
, ) A, ) | ] E [f (E, ) | ] .

(A.18)

P
, ) A, ) | ] = f ( @ ) f ( ) =
Note P P [ ] E [f (E(wc
avg
avg wc
wc
P
E [f (E, )]. Since know E [f (E, )] = P P [ ] E [f (E, ) | ], averaging
argument together Eq. (A.18) implies P

E [f (E(wc
, ) A, ) | ] = E [f (E, ) | ] .

476

(A.19)

fiA DAPTIVE UBMODULARITY: HEORY PPLICATIONS

Since arbitrary partial realization dom() = A, E arbitrary,
fix dom() let = dom(). settings, Eq. (A.19) implies Eq. (A.17),
| ), thus -approximate greedy policy never select
thus maxe (e | ) (wc
). Hence c (
item cost exceeding k, k = cwc (wc
wc [`] ) cwc ([`] ) k,
cwc ([`] ) ` + k. completes proof.
Lemma A.13. Fix adaptive monotone submodular objective f . policy
dom()
E [f (E(, ), ) | ] E [f (E, ) | ] .
Proof. Augment new policy 0 follows. Run completion, let 0 partial
realization consisting states observed. 0 , proceed select
remaining items E order. Otherwise, * 0 terminate.


E [f (E(, ), ) | ] E f (E( 0 , ), ) | = E [f (E, ) | ] (A.20)
inequality repeated application adaptive monotonicity f , equality
construction.
5.2 described result Feige (1998) implies polynomial time
(1 ) ln (Q/) approximation algorithm selfcertifying instances Adaptive Stochastic Min
Cost Cover, unless NP DTIME(nO(log log n) ). show related result general instances.
Lemma A.14. every constant > 0, (1 ) ln (Q/) polynomial time approximation algorithm general instances Adaptive Stochastic Min Cost Cover, either average
case objective cavg () worst-case objective cwc (), unless NP DTIME(nO(log log n) ).
Proof. offer reduction Set Cover problem. Fix Set Cover instance ground
set U sets {S1 , S2 , . . . , Sm } 2U unit-cost sets. Fix Q, 1/
Q
Q/ positive integers,
= |U |. Let E := {S1 , S2 , . . . , Sm }, set cost
item one. Partition U 1/ disjoint, equally sized subsets U1 , U2 , . . . , U1/ . Construct
realization Ui . Let set states = {NULL}. Hence (e) = NULL
e, knowledge true realization revealed selecting items. use
uniform distribution realizations, i.e., p (i ) = i. Finally, objective f (C, ) :=
| SC (S Ui )|, i.e., number elements Ui cover sets C. Since |O| = 1,
every realization consistent every possible partial realization . Hence ,
E [f (dom(), ) | ] = f(dom()), f(C) = | SC S| objective function
original set cover instance. Since f submodular, f adaptive submodular. Likewise, since
f monotone, |O| = 1, f strongly adaptive monotone. Now, cover realization,
must obtain maximum possible value realizations, means selecting collection
sets C SC = U . Conversely, C SC = U clearly covers f .
Hence instance Adaptive Stochastic Min Cost Cover, either average case objective
cavg () worst-case objective cwc (), equivalent original Set Cover instance. Therefore,
result Feige (1998) implies polynomial time algorithm obtaining
(1 ) ln |U | = (1 ) ln (Q/) approximation Adaptive Stochastic Min Cost Cover unless
NP DTIME(nO(log log n) ).

477

fiG OLOVIN & K RAUSE

A.5 Min-Sum Objective
section prove Theorem 5.10, appears page 445, case items
arbitrary costs. proof resembles analogous proof Streeter Golovin (2007)
non-adaptive min-sum submodular cover problem, and, like proof, ultimately derives
extremely elegant performance analysis greedy algorithm min-sum set cover due Feige
et al. (2004).
objective function c () generalized arbitrary cost items uses strict truncation8 [t]
place [t] unit-cost definition:
c () :=


X


X
X

E [f (E, )] favg ([t] ) =
p ()
f (E, ) f (E([t] , ), ) .

t=0



t=0

(A.21)
prove -approximate greedy policy achieves 4-approximation minsum objective, i.e., c () 4 c ( ) policies . so, require following
lemma.
Lemma A.15. Fix -approximate greedy policy
adaptive monotone submodular
function f let si := favg ([i+1] ) favg ([i] ) . policy nonnegative integers
)f
k, favg ([k]
avg ([i] ) + k si .
) f (

Proof. Fix , , i, k. adaptive monotonicity favg ([k]
avg [i] @[k] ). next aim
prove

favg ([i] @[k]
) favg ([i] ) + k si
(A.22)

sufficient complete proof. Towards end,
fix partial realization


| , equals expected
form (e, (e)) : e E([i] , ) . Consider [k]
portion

marginal benefit [k]
[i] @[k] conditioned . Lemma A.9 allows us
bound


h

h

(e | )


E [k] |
E c [k] | max
,
e
c(e)

expectations
h taken
internal randomness , any. Note
, )) k, expectation taken internal
, E c(E([k]
h

h

. Hence E c |
|
randomness [k]
k . follows E [k]

[k]
k maxe ((e | ) /c(e)). definition -approximate greedy policy, obtains least
h


(1/) max ((e | ) /c(e)) E [k]
| /k
(A.23)
e

expected marginal benefit per unit cost step immediately following observation . Next
take appropriate convex combination previous inequality different
values .

Let random partial realization distributed (e, (e)) : e E([i] , ) . taking
8. See Definition A.2 page 469.

478

fiA DAPTIVE UBMODULARITY: HEORY PPLICATIONS

Figure 6: illustration inequality

R

x=0 h(x)dx



P

i0 xi (yi

yi+1 ).

expectation Eq. (A.23) yields

h
|
) f (
E [k]
favg ([i] @[k]
avg [i] )


favg ([i+1] ) favg ([i] ) E
=
.
k
k

(A.24)


Multiplying Eq. (A.24) k, substituting si = favg ([i+1] ) favg ([i] ) , conclude
)f (
ksi favg ([i] @[k]
avg [i] ) immediately yields Eq. (A.22) concludes proof.
Using Lemma A.15, together geometric argument developed Feige et al. (2004),
prove Theorem 5.10.
Proof Theorem 5.10: Let Q := E [f (E, )] maximum possible expected reward,
expectation
greedy policy. Define Ri :=
taken w.r.t. p (). Let
-approximate
Pi
Q favg [i] define Pi := Q favg [i] . Let xi := 2s
,
let yi := R2i , let h(x) :=



). claim f
Q favg ([x]
avg [i] favg [i] Pi Ri . clearly holds [i]
empty policy, otherwise always select item contributes zero marginal benefit,
namely item already played previously. Hence -approximate greedy
policy

never select items negative expected marginal benefit, favg [i] favg [i] .




Lemma A.15, favg [x
favg [i] + xi si . Therefore
i]
Pi
Ri
h(xi ) Q favg ([i] ) xi si = Pi

= yi
(A.25)
2
2




similar reasons favg [i] favg [i] , favg [i1] favg [i] ,
sequence hy1 , y2 , . . .i non-increasing. adaptive monotonicity adaptive submodular ) >
ity f imply h(x) non-increasing. Informally, otherwise, favg ([x]

favg ([x+1]
) x, optimal policy must sacrificing immediate rewards time x
exchange greater returns later, shown strategy optimal,
adaptive
submodularity
cannot hold. Eq. (A.25) monotonicity h 7 yi imply
R
P
h(x)dx

x
(yi yi+1 ) (see Figure 6). left hand side lower bound c ( ),

i0
x=0
1 P
1
si = (Ri Ri+1 ) right hand side simplifies 4
i0 Pi = 4 c (), proving

c () 4 c ( ).
479

fiG OLOVIN & K RAUSE

A.6 Symbol Table
E, e E
O,


,

p
p( | )

E(, )
(e | )
( | )
[e/o]
k
[k]
[k]
[k]
@ 0
f
favg
c
cavg
cwc
c
c ( | )

Q

1P

Ground set items, individual item.
States item may in, outcomes selecting item, individual
state/outcome.
realization, i.e., function items states.
partial realization, typically encoding current set observations;
E partial mapping items states.
random realization random partial realization, respectively.
consistency relation: means (e) = (e) e dom().
probability distribution realizations.
conditional distribution realizations: p( | ) := P [ = | ].
policy, maps partial realizations items.
set items selected run realization .
conditional expected marginal benefit e conditioned :
(e | ) := E [f (dom() {e} , ) f (dom(), ) | ].
conditional expected marginal benefit policy conditioned :
( | ) := E [f (dom() E(, ), ) f (dom(), ) | ].
Shorthand {(e, o)}.
Budget cost selected item sets.
truncated policy. See Definition 5.1 page 439 (unit costs) Definition A.4
page 469.
strictly truncated policy. See Definition A.2 page 469.
laxly truncated policy. See Definition A.3 page 469.
Policies 0 concatenated together. See Definition A.6 page 469.
objective function, type f : 2E OE R0 unless stated otherwise.
Average benefit: favg () := E [f (E(, ), )].
P
Item costs c : E N. Extended sets via c(S) := eS c(e).
Average cost policy: cavg () := E [c(E(, ))].
Worst-case cost policy: cwc () := max c(E(, )).

P
Min-sum cost policy: c () :=
t=0 E [f (E, )] favg ([t] ) .
Conditional average policy cost: c ( | ) := E [c(E(, )) | ].
Approximation factor greedy optimization -approximate greedy policy.
Benefit quota. Often Q = E [f (E, )].
Coverage gap: = sup { 0 : f (S, ) > Q 0 implies f (S, ) Q S, }.
indicator proposition P , equals one P true zero P false.
Table 2: Important symbols notations used article

480

fiA DAPTIVE UBMODULARITY: HEORY PPLICATIONS

A.7 Proof Approximation Hardness Absence Adaptive Submodularity
provide proof Theorem 12.1 whose statement appears page 464 12.
Proof Theorem 12.1: construct hard instance based following intuition. make
algorithm go treasure hunting. set locations {0, 1, , . . . , 1}, treasure
one locations, algorithm gets unit reward finds it, zero reward otherwise.
maps, consisting cluster bits, purporting indicate
treasure is, map stored (weak) secret-sharing way, querying bits
map reveals nothing says treasure is. Moreover, one maps
fake, puzzle indicating map correct one indicating treasures location.
Formally, fake map one probabilistically independent location treasure,
conditioned puzzle.
instance three types items, E = ET ] EM ] EP , |ET | = encodes
treasure is, |EM | = ms encodes maps, |EP | = n3 encodes puzzle,
m, t, n specified below. outcomes binary, = {0, 1}, identify
items bit indices. Accordingly say (e) value bit e. e EM EP ,
P [(e) = 1] = .5 independently. conditional distribution (ET ) given (EM EP )
deterministic specified below. objective function f linear, defined follows:
f (A, ) = |{e ET : (e) = 1}|.
` suitWe describe puzzle, compute i(P ) := (perm(P ) mod p) Pmod 2Q
able random matrix P , suitable prime p integer `, perm(P ) = Sn ni=1 Pi(i)
permanent P . exploit Theorem 1.9 Feige Lund (1997) show
exist constants , > 0 randomized polynomial time algorithm compute
(perm(P ) mod p) mod 2` correctly probability 2` (1+1/n ), P drawn uniformly

random {0, 1, 2, . . . , p 1}nn , p prime superpolynomial n, ` p 12 ,
PH = = P2 . encode puzzle, fix prime p [2n2 , 2n1 ] use n3 bits
(EP ) sample P = P () (nearly) uniformly
random {0, 1, 2, . . . , p 1}nn follows.
P
matrix P Znn , let rep(P ) := ij Pij p(i1)n+(j1) define base p representation
P . Note rep() one-to-one n n matrices entries Zp , define inverse
3
rep1 (). encoding
P () kinterprets bits (EP ) integer x [2n ], computes = x
j
2
3
2
2
mod (pn ). x 2n /pn pn , P = rep1 (y). Otherwise, P zero matrix.
2

3

2

latter event occurs probability pn /2n 2n , case simply suppose
2
algorithm consideration finds treasure gets unit reward. adds 2n
expected reward. let us assume
U P drawn uniformly random.
Next consider maps. Partition EM =
i=1 Mi maps Mi , consisting
items. map Mi , partition items s/ log2 groups log2 bits each, bits
group encode log2 bit binary string. Let vi {0, 1, . . . , 1} XOR
s/ log2 binary strings, interpreted integer (using fixed encoding). say Mi points
vi location treasure. priori, vi uniformly distributed {0, ..., 1}.
particular realization (EP EM ), define v() := vi(P ()) . set v() location
treasure realization , i.e., label ET = {e0 , e1 , . . . , et1 } ensure (ej ) = 1
j = vi(P ()) , (e) = 0 e ET . Note random variable v = v() distributed
uniformly random {0, 1, . . . , 1}. Note still holds condition realizations
481

fiG OLOVIN & K RAUSE

set s/ log2 1 items map, case still least one group whose
bits remain completely unobserved.
consider optimal policy budget k = n3 + + 1 items pick. Clearly,
reward 1. However, given budget k, computationally unconstrained policy
exhaustively sample EP , solve puzzle (i.e., compute i(P )), read correct map (i.e., exhaustively sample Mi(P ) ), decode map (i.e., compute v = vi(P ) ), get treasure (i.e., pick ev )
thereby obtaining reward one.
give upper bound expected reward R randomized polynomial time
algorithm budget k items, assuming P2 6= PH. Fix small constant > 0, set
= n3 = = n1/ . suppose give realizations (EM ) free. also replace
budget k items budget k specifically map items EM additional
budget k specifically treasure locations ET . Obviously, help it.
noted, selects less s/ log2 bits map Mi(P ) indicated P , distribution
vi(P ) conditioned realizations still uniform. course, knowledge vi 6= i(P )
useless getting reward. Hence try k log2 (t)/s = o(k) maps attempt
find Mi(P ) . Note randomized algorithm given random P drawn
{0, 1, 2, . . . , p 1}nn always outputs set integers size P [i(P ) S] q,
use construct randomized algorithm that, given P , outputs integer x
P [i(P ) = x] q/, simply running first algorithm selecting random item S.
find Mi(P ) , distribution treasures location uniform given knowledge.
Hence budget k treasure locations earn expected reward k/t. Armed
observations Theorem 1.9 work Feige Lund (1997) complexity
2
theoretic assumptions, infer E [R] o(k) 2` (1 + 1/n ) + k/t + 2n . Since = n3
= = n1/ = (1) = 1 ` = log2 k = n3 + + 1 = 2n3 + 1,
E [R]

k
(1 + o(1)) = 2n31/ (1 + o(1)).


Next note |E| = + ms + n3 = n3+1/ (1 + o(1)). Straightforward algebra shows
order ensure E [R] = o(/|E|1 ), suffices choose /6. Thus, complexity
theoretic assumptions, polynomial time randomized algorithm budget k achieves
o(/|E|1 ) value obtained optimal policy budget k, approximation
ratio (|E|1 /).

References
Alon, N., Awerbuch, B., Azar, Y., Buchbinder, N., & Naor, J. S. (2009). online set cover
problem. SIAM Journal Computing, 39, 361370.
Arkin, E. M., Meijer, H., Mitchell, J. S. B., Rappaport, D., & Skiena, S. S. (1993). Decision trees
geometric models. Proceedings Symposium Computational Geometry, pp. 369378,
New York, NY, USA. ACM.
Asadpour, A., Nazerzadeh, H., & Saberi, A. (2008). Stochastic submodular maximization. WINE
08: Proceedings 4th International Workshop Internet Network Economics, pp.
477489, Berlin, Heidelberg. Springer-Verlag.
Bellala, G., & Scott, C. (2010). Modified group generalized binary search near-optimal performance guarantees. Tech. rep., University Michigan.
482

fiA DAPTIVE UBMODULARITY: HEORY PPLICATIONS

Brochu, E., Cora, M., & de Freitas, N. (2009). tutorial Bayesian optimization expensive cost
functions, application active user modeling hierarchical reinforcement learning.
Tech. rep. TR-2009-23, Department Computer Science, University British Columbia.
Buchbinder, N., & Naor, J. S. (2009). design competitive online algorithms via primaldual
approach. Foundations Trends Theoretical Computer Science, 3, 93263.
Chakaravarthy, V. T., Pandit, V., Roy, S., Awasthi, P., & Mohania, M. (2007). Decision trees
entity identification: Approximation algorithms hardness results. Proceedings
ACM-SIGMOD Symposium Principles Database Systems.
Chan, C. W., & Farias, V. F. (2009). Stochastic depletion problems: Effective myopic policies
class dynamic optimization problems. Mathematics Operations Research, 34(2), 333
350.
Cohn, D. A., Gharamani, Z., & Jordan, M. I. (1996). Active learning statistical models. Journal
Artificial Intelligence Research (JAIR), 4, 129145.
Dantzig, G. B. (1955). Linear programming uncertainty. Management Science, 1, 197206.
Dasgupta, S. (2004). Analysis greedy active learning strategy. NIPS: Advances Neural
Information Processing Systems 17, pp. 337344. MIT Press.
Dean, B., Goemans, M., & Vondrak, J. (2005). Adaptivity approximation stochastic packing
problems. Proceedings 16th ACM-SIAM Symposium Discrete Algorithms,, pp.
395404.
Dean, B., Goemans, M., & Vondrak, J. (2008). Approximating stochastic knapsack problem:
benefit adaptivity. Mathematics Operations Research, 33, 945964.
Deshpande, A., Guestrin, C., Madden, S., Hellerstein, J., & Hong, W. (2004). Model-driven data
acquisition sensor networks. Proceedings International Conference Large
Data Bases (VLDB), pp. 588599.
Feige, U. (1998). threshold ln n approximating set cover. Journal ACM, 45(4), 634
652.
Feige, U., Lovasz, L., & Tetali, P. (2004). Approximating min sum set cover. Algorithmica, 40(4),
219234.
Feige, U., & Lund, C. (1997). hardness computing permanent random matrices.
Computational Complexity, 6(2), 101132.
Fujishige, S. (2005). Submodular functions optimization (2nd edition)., Vol. 58. Annals
Discrete Mathematics, North Holland, Amsterdam.
Garey, M. R., & Graham, R. L. (1974). Performance bounds splitting algorithm binary
testing. Acta Informatica, 3, 347355.
Gittins, J. C., & Jones, D. M. (1979). dynamic allocation index discounted multiarmed
bandit problem. Biometrika, 66(3), 561565.
Goemans, M. X., & Vondrak, J. (2006). Stochastic covering adaptivity. Proceedings 7th
International Latin American Symposium Theoretical Informatics, pp. 532543.

483

fiG OLOVIN & K RAUSE

Golovin, D., Gupta, A., Kumar, A., & Tangwongsan, K. (2008). All-norms all-Lp -norms
approximation algorithms. Hariharan, R., Mukund, M., & Vinay, V. (Eds.), IARCS Annual Conference Foundations Software Technology Theoretical Computer Science
(FSTTCS 2008), Dagstuhl, Germany. Schloss Dagstuhl - Leibniz-Zentrum fuer Informatik,
Germany.
Golovin, D., & Krause, A. (2010). Adaptive submodularity: new approach active learning
stochastic optimization. 23rd Annual Conference Learning Theory, pp. 333345.
Golovin, D., & Krause, A. (2011). Adaptive submodular optimization matroid constraints.
CoRR, abs/1101.4450.
Golovin, D., Krause, A., Gardner, B., Converse, S. J., & Morey, S. (2011). Dynamic resource
allocation conservation planning. AAAI 11: Proceedings TwentyFifth AAAI
Conference Artificial Intelligence, pp. 13311336. AAAI Press.
Golovin, D., Krause, A., & Ray, D. (2010). Near-optimal Bayesian active learning noisy
observations. NIPS: Advances Neural Information Processing Systems 23, pp. 766774.
Goundan, P. R., & Schulz, A. S. (2007). Revisiting greedy approach submodular set function
maximization. Tech. rep., Massachusetts Institute Technology.
Grunewalder, S., Audibert, J.-Y., Opper, M., & Shawe-Taylor, J. (2010). Regret bounds Gaussian
process bandit problems. Proceedings 13th International Conference Artificial
Intelligence Statistics.
Guha, S., & Munagala, K. (2009). Multi-armed bandits metric switching costs. Proceedings
International Colloquium Automata, Languages Programming (ICALP).
Guha, S., Munagala, K., & Shi, P. (2009). Approximation algorithms restless bandit problems.
Tech. rep. 0711.3861v5, arXiv.
Guillory, A., & Bilmes, J. (2009). Average-case active learning costs. 20th International
Conference Algorithmic Learning Theory, University Porto, Portugal.
Guillory, A., & Bilmes, J. (2010). Interactive submodular set cover. Proceedings International Conference Machine Learning (ICML), No. UWEETR-2010-0001, Haifa, Israel.
Guillory, A., & Bilmes, J. A. (2011). Simultaneous learning covering adversarial noise.
International Conference Machine Learning (ICML), Bellevue, Washington.
Gupta, A., Krishnaswamy, R., Nagarajan, V., & Ravi, R. (2010). Approximation algorithms
optimal decision trees adaptive TSP problems. Proceedings International Colloquium Automata, Languages Programming (ICALP), Vol. 6198 Lecture Notes
Computer Science, pp. 690701. Springer.
Gupta, A., Pal, M., Ravi, R., & Sinha, A. (2005). Wednesday? Approximation algorithms multistage stochastic optimization. Proceedings 8th International Workshop Approximation Algorithms Combinatorial Optimization Problems (APPROX).
Jones, D. R., Schonlau, M., & Welch, W. J. (1998). Efficient global optimization expensive
black-box functions. Journal Global Optimization, 13, 455492.
Kaplan, H., Kushilevitz, E., & Mansour, Y. (2005). Learning attribute costs. Proceedings
37th ACM Symposium Theory Computing, pp. 356365.
484

fiA DAPTIVE UBMODULARITY: HEORY PPLICATIONS

Kempe, D., Kleinberg, J., & Tardos, E. (2003). Maximizing spread influence social
network. KDD 03: Proceedings ninth ACM SIGKDD international conference
Knowledge discovery data mining, pp. 137146, New York, NY, USA. ACM.
Kosaraju, S. R., Przytycka, T. M., & Borgstrom, R. S. (1999). optimal split tree problem.
Proceedings 6th International Workshop Algorithms Data Structures, pp.
157168, London, UK. Springer-Verlag.
Krause, A., & Guestrin, C. (2005). Near-optimal nonmyopic value information graphical
models. Proceedings Uncertainty Artificial Intelligence (UAI).
Krause, A., & Guestrin, C. (2007). Near-optimal observation selection using submodular functions.
Conference Artificial Intelligence (AAAI) Nectar track, pp. 16501654.
Krause, A., & Guestrin, C. (2009a). Intelligent information gathering submodular function
optimization. Tutorial International Joint Conference Artificial Intelligence.
Krause, A., & Guestrin, C. (2009b). Optimal value information graphical models. Journal
Artificial Intelligence Research (JAIR), 35, 557591.
Leskovec, J., Krause, A., Guestrin, C., Faloutsos, C., VanBriesen, J., & Glance, N. (2007). Costeffective outbreak detection networks. KDD 07: Proceedings 13th ACM SIGKDD
international conference Knowledge discovery data mining, pp. 420429, New York,
NY, USA. ACM.
Littman, M., Goldsmith, J., & Mundhenk, M. (1998). computational complexity probabilistic
planning. Journal Artificial Intelligence Research, 9, 136.
Liu, Z., Parthasarathy, S., Ranganathan, A., & Yang, H. (2008). Near-optimal algorithms shared
filter evaluation data stream systems. SIGMOD 08: Proceedings 2008 ACM
SIGMOD international conference Management data, pp. 133146, New York, NY,
USA. ACM.
Lizotte, D., Wang, T., Bowling, M., & Schuurmans, D. (2007). Automatic gait optimization
Gaussian process regression. Proceedings Twentieth International Joint Conference
Artificial Intelligence (IJCAI), pp. 944949.
Loveland, D. W. (1985). Performance bounds binary testing arbitrary weights. Acta Informatica, 22(1), 101114.
McCallum, A., & Nigam, K. (1998). Employing EM pool-based active learning text classification. Proceedings International Conference Machine Learning (ICML), pp.
350358.
Minoux, M. (1978). Accelerated greedy algorithms maximizing submodular set functions.
Proceedings 8th IFIP Conference Optimization Techniques, pp. 234243. Springer.
Munagala, K., Babu, S., Motwani, R., Widom, J., & Thomas, E. (2005). pipelined set cover
problem. Proceedings Intl. Conf. Database Theory, pp. 8398.
Nemhauser, G. L., Wolsey, L. A., & Fisher, M. L. (1978). analysis approximations maximizing submodular set functions - I. Mathematical Programming, 14(1), 265294.
Nowak, R. (2009). Noisy generalized binary search. NIPS: Advances Neural Information
Processing Systems 22, pp. 13661374.
485

fiG OLOVIN & K RAUSE

Papadimitriou, C. H., & Tsitsiklis, J. N. (1987). complexity Markov decision processses.
Mathematics Operations Research, 12(3), 441450.
Pineau, J., Gordon, G., & Thrun, S. (2006). Anytime point-based approximations large
POMDPs. Journal Artificial Intelligence Research (JAIR), 27, 335380.
Raz, R., & Safra, S. (1997). sub-constant errorprobability lowdegree test, subconstant
error-probability PCP characterization NP. STOC 97: Proceedings twenty-ninth
annual ACM Symposium Theory Computing, pp. 475484, New York, NY, USA. ACM.
Ross, S., Pineau, J., Paquet, S., & Chaib-draa, B. (2008). Online planning algorithms POMDPs.
Journal Artificial Intelligence Research, 32, 663704.
Schrijver, A. (2003). Combinatorial optimization : polyhedra efficiency. Volume B, Part IV,
Chapters 39-49. Springer.
Sebastiani, P., & Wynn, H. P. (2000). Maximum entropy sampling optimal Bayesian experimental design. Journal Royal Statistical Society, Series B, 62(1), 145157.
Smallwood, R., & Sondik, E. (1973). optimal control partially observable Markov decision
processes finite horizon. Operations Research, 21, 10711088.
Srinivas, N., Krause, A., Kakade, S., & Seeger, M. (2010). Gaussian process optimization
bandit setting: regret experimental design. Proceedings International Conference Machine Learning (ICML).
Streeter, M., & Golovin, D. (2007). online algorithm maximizing submodular functions.
Tech. rep. CMU-CS-07-171, Carnegie Mellon University.
Streeter, M., & Golovin, D. (2008). online algorithm maximizing submodular functions.
NIPS: Advances Neural Information Processing Systems 21, pp. 15771584.
Wolsey, L. A. (1982). analysis greedy algorithm submodular set covering problem.
Combinatorica, 2(4), 385393.

486

fiJournal Artificial Intelligence Research 42 (2011) 275-308

Submitted 05/11; published 11/11

Revisiting Centrality-as-Relevance:
Support Sets Similarity Geometric Proximity
Ricardo Ribeiro

ricardo.ribeiro@inesc-id.pt

Instituto Universitario de Lisboa (ISCTE-IUL)
Av. das Forcas Armadas, 1649-026 Lisboa, Portugal
L2F - INESC ID Lisboa
Rua Alves Redol, 9, 1000-029 Lisboa, Portugal

David Martins de Matos

david.matos@inesc-id.pt

Instituto Superior Tecnico, Universidade Tecnica de Lisboa
Av. Rovisco Pais, 1049-001 Lisboa, Portugal
L2F - INESC ID Lisboa
Rua Alves Redol, 9, 1000-029 Lisboa, Portugal

Abstract
automatic summarization, centrality-as-relevance means important
content information source, collection information sources, corresponds
central passages, considering representation notion makes sense
(graph, spatial, etc.). assess main paradigms, introduce new centrality-based
relevance model automatic summarization relies use support sets
better estimate relevant content. Geometric proximity used compute semantic
relatedness. Centrality (relevance) determined considering whole input source
(and local information), taking account existence minor topics
lateral subjects information sources summarized. method consists
creating, passage input source, support set consisting
semantically related passages. Then, determination relevant content
achieved selecting passages occur largest number support sets.
model produces extractive summaries generic, language- domainindependent. Thorough automatic evaluation shows method achieves state-of-theart performance, written text, automatically transcribed speech summarization,
including compared considerably complex approaches.

1. Introduction
summary conveys end user relevant content one information
sources, concise comprehensible manner. Several difficulties arise addressing
problem, one utmost importance assess significant content. Usually, approaches vary complexity processing text speech. text summarization, up-to-date systems make use complex information, syntactic (Vanderwende,
Suzuki, Brockett, & Nenkova, 2007), semantic (Tucker & Sparck Jones, 2005), discourse
information (Harabagiu & Lacatusu, 2005; Uzeda, Pardo, & Nunes, 2010), either assess
relevance reduce length output, common approaches speech summarization
try cope speech-related issues using speech-specific information (for example,
prosodic features, Maskey & Hirschberg, 2005, recognition confidence scores, Zechner
& Waibel, 2000) improving intelligibility output automatic speech
c
2011
AI Access Foundation. rights reserved.

fiRibeiro & de Matos

recognition system (by using related information, Ribeiro & de Matos, 2008a). fact,
spoken language summarization often considered much harder task text summarization (McKeown, Hirschberg, Galley, & Maskey, 2005; Furui, 2007): problems like speech
recognition errors, disfluencies, accurate identification sentence boundaries
increase difficulty determining salient information, also constrain
applicability text summarization techniques speech summarization (although
presence planned speech, partly happens broadcast news domain, portability feasible, Christensen, Gotoh, Kolluru, & Renals, 2003). Nonetheless, shallow
text summarization approaches Latent Semantic Analysis (LSA) (Landauer, Foltz,
& Laham, 1998; Gong & Liu, 2001) Maximal Marginal Relevance (MMR) (Carbonell
& Goldstein, 1998) seem achieve performances comparable ones using specific
speech-related features (Penn & Zhu, 2008).
Following determination relevant content, summary must composed
presented user. identified content consists passages found input
source glued together form summary, summary usually designated
extract; hand, important content devised series concepts
fused smaller set used generate new, concise, informative text, presence abstract. extraction concept-to-text
generation, especially text summarization, text-to-text generation methods, rely
text rewritingparaphrasing, sentence compression major representative, becoming up-to-date subject (Cohn & Lapata, 2009). Given hardness
abstraction, bulk work area consists extractive summarization.
common family approaches identification relevant content
centrality family. methods base detection salient passages
identification central passages input source(s). One main representatives family centroid-based summarization. Centroid-based methods build
idea pseudo-passage represents central topic input source (the centroid )
selecting passages (x) included summary ones close centroid. Pioneer work (on multi-document summarization) Radev, Hatzivassiloglou,
McKeown (1999) Radev, Jing, Budzikowska (2000) creates clusters documents
representing document tf-idf vector; centroid cluster also defined
tf-idf vector, coordinates corresponding weighted average tf-idf
values documents cluster; finally, sentences contain words centroids presumably best representatives topic cluster, thus
best candidates belonging summary.
centrality(x) = similarity(x, centroid)

(1)

Another approach centrality estimation compare candidate passage every
passage (y) select ones higher scores (the ones closer every
passage). One simple way represent passages vectors using
weighting scheme like aforementioned tf-idf ; then, passage similarity assessed
using, instance, cosine, assigning passage centrality score defined
Eq. 2.
1 X
centrality(x) =
similarity(x, y)
(2)
N
276

fiRevisiting Centrality-as-Relevance

scores used create sentence ranking: sentences highest scores
selected create summary.
major problem relevance paradigm taking account entire
input source manner, either estimate centroids average distances input source
passages, may selecting extracts central input source are, however,
relevant ones. cognitive terms, information reduction techniques
summarization process quite close discourse understanding process (EndresNiggemeyer, 1998), which, certain level, works applying rules help uncovering
macrostructure discourse. One rules, deletion, used eliminate
understanding process propositions relevant interpretation
subsequent ones. means common find, input sources
summarized, lateral issues considerations relevant devise salient
information (discourse structure-based summarization based relevance nuclear
text segments, Marcu, 2000; Uzeda et al., 2010), may affect centrality-based
summarization methods inducing inadequate centroids decreasing scores
suitable sentences.
argued previous work (Gong & Liu, 2001; Steyvers & Griffiths, 2007), also
assume input sources mixtures topics, propose address aspect using
input source guidance. associating passage input source
support set consisting semantically related passages input
source, groups related passages uncovered, one constituting latent topic (the
union supports sets whose intersection empty). creation support
sets, semantic relatedness assessed geometric proximity. Moreover, similar work
usually explores different weighting schemes address specific issues task
research (Orasan, Pekar, & Hasler, 2004; Murray & Renals, 2007; Ribeiro & de Matos,
2008b), explore different geometric distances similarity measures, analyzing
performance context (the impact different metrics theoretical empirical
perspectives clustering setting shown Aggarwal, Hinneburg, & Keim, 2001).
build summary, select sentences occur largest number support sets
hence, central sentences, without problem affects previous centrality-based
summarization.
method produces generic, language- domain-independent summaries, low
computational requirements. test approach speech text data. empirical evaluation model text data, used experimental setup previously used
published work (Mihalcea & Tarau, 2005; Antiqueira, Oliveira Jr., da Fontoura Costa, &
Nunes, 2009), enabled informative comparison existing approaches.
concerns speech experiments, also used corpus collected previous work (Ribeiro
& de Matos, 2008a), well published results. allowed us compare model
state-of-the-art work.
rest document structured follows: Section 2, analyze representative models centrality-as-relevance approachespassage-to-centroid similarity-based
centrality pair-wise passage similarity-based centrality; Section 3 describes support
sets-based relevance model; evaluation model presented Section 4,
compare performance centrality-as-relevance models discuss
achieved results; final remarks conclude document.
277

fiRibeiro & de Matos

2. Centrality-as-Relevance
two main approaches centrality-based summarization: passage-to-centroid
similarity pair-wise passage similarity.
2.1 Passage-to-Centroid Similarity-based Centrality
centroid-based summarization, passage centrality defined similarity
passage pseudo-passage that, considering geometrical representation input
source, center space defined passages input source, centroid.
work multi-document summarization Radev et al. (1999, 2000) Radev, Jing,
Stys, Tam (2004) work developed Lin Hovy (2000) examples
approach.
Radev et al. present centroid-based multi-document summarizer (MEAD)
input cluster documents. Associated cluster documents centroid.
Documents represented vectors tf-idf weights centroid cluster
consists vector coordinates weighted averages tf-idf values
documents cluster, pre-defined threshold. Thus, centroid cluster
documents is, case, pseudo-document composed terms statistically
relevant. Given cluster documents segmented sentences , {s1 , s2 , . . . , sN },
centroid C, compression rate, summarization done selecting appropriate
number (according compression rate) sentences highest scores assigned
linear function (Eq. 3) following features: centroid value (Ci ), position value
(Pi ), first-sentence overlap value (Fi ).
score(si ) = wc Ci + wp Pi + wf Fi ,

1iN

(3)

P
centroid value, defined Ci = tsi Ct,i , establishes sentences closer
centroid (the ones contain terms centroid) higher scores. Position value (Pi ) scores sentences according position encompassing document.
Finally, first-sentence overlap value (Fi ) scores sentences according similarity
first sentence document.
Lin Hovy (2000) designate centroid topic signature define set
related terms: , {topic, < (t1 , w1 ), . . . , (tT , wT ) >}, ti represents term related
topic topic wi associated weight represents degree correlation
ti topic. Topic signatures computed corpus documents, previously
classified relevant non-relevant given topic, using log-likelihood-ratio-based
quantity 2log(). quantity, due asymptotic relation 2 distribution
well adequacy log-likelihood-ratio sparse data, used rank terms
define signature, select cut-off value establish number
terms signature. Summarization carried ranking sentences according
topic signature score selecting top ranked ones. topic signature score
(tss) computed similar manner MEADs centroid value: given input source
, {p1 , p2 , . . . , pN }, pi , ht1 , . . . , tM i, relevant passages ones
words topic (Eq. 4).
278

fiRevisiting Centrality-as-Relevance

tss(pi ) =


X

wj , wj weight tj defined topic signature

(4)

j=1

2.2 Pair-wise Passage Similarity-based Centrality
pair-wise passage similarity-based summarization, passage centrality defined
similarity passage every passage. work presented Erkan
Radev (2004), well work developed Mihalcea Tarau (2005), examples
approach.
Erkan Radev (2004) propose three graph-based approaches pair-wise passage
similarity-based summarization similar performance: degree centrality, LexRank,
continuous LexRank. Degree centrality based degree vertex. Pair-wise sentence similarity used build graph representation input source: vertices
sentences edges connect vertices corresponding sentences similar
given threshold. Sentences similar large number sentences considered
central (relevant) ones. Degree centrality similar model propose. However, model propose, introduce concept support set allow use
different threshold sentence. improves representation sentence,
leading creation better summaries.
LexRank, based Googles PageRank (Brin & Page, 1998), builds degree centrality
(degree) making centrality sentence influenced similar sentences,
adjacent ones graph representation (Eq. 5).
X centralityScore(t)
degree(t)

centralityScore(s) =

(5)

tadj[s]

ranking model similar PageRank except concerns similarity (adjacency)
graph, that, case, undirected (Eq. 6, damping factor N number
sentences).
X centrality(t)

centrality(s) =
+ (1 d)
(6)
N
degree(t)
tadj[s]

Continuous LexRank weighted version LexRank (it uses Eq. 7 instead Eq. 5).
centralityScore(s) =

X

sim(s, t)
centralityScore(t)
uadj[t] sim(u, t)

P
tadj[s]

(7)

Mihalcea Tarau (2005), addition Googles PageRank, also explore HITS
algorithm (Kleinberg, 1999) perform graph-based extractive text summarization: again,
documents represented networks sentences networks used globally
determine importance sentence. happens models proposed
Erkan Radev, sentences vertices (V ) edges (w) vertices established
passage similarity. TextRank (Mihalcea & Tarau, 2004)how model based
PageRank designated main contributionformalization similar Continuous
LexRank (see Eq. 8), although Mihalcea Tarau also explore directed graphs
279

fiRibeiro & de Matos

representation text12 . summarization, best results obtained using
backward directed graph: orientation edges vertex representing sentence
vertices representing previous sentences input source.
X
w(Vt , Vs )
P
extRank(Vs ) = (1 d) +
extRank(Vt )
(8)
Vu Out[Vt ] w(Vt , Vu )
Vt In[Vs ]

Passage similarity based content overlap3 defined Eq. 9. Given two sets
P , p1 , p2 , ..., pn Q , q1 , q2 , ..., qn , corresponding passage, similarity consists
cardinality intersection sum logarithms cardinality
set.
|{t : P Q}|
w(VP , VQ ) = sim(P, Q) =
(9)
log(|P |) + log(|Q|)
similar graph-based approach described Antiqueira et al. (2009). work
uses complex networks perform extractive text summarization. Documents also
represented networks, sentences nodes connections
nodes established sentences sharing common meaningful nouns.
2.3 Beyond Automatic Summarization
Apart summarization, considering PageRank HITS stem area
Information Retrieval, centrality-based methods similar ones previously described
successfully applied re-rank sets documents returned retrieval methods.
Kurland Lee (2005, 2010) present set graph-based algorithms, named influx,
similar model, reorder previously retrieved collection documents (C).
method starts defining k -nearest-neighbor (k NN) graph initial collection
based generation links defined Eq. 10 (KL, Kullback-Leibler divergence; LE,
maximum-likelihood estimate; , smoothing-parameter Dirichlet-smoothed version
p(); s, documents).
fifi



fifi []
LE
(s)
,
exp

KL
p
()
p
()
(10)
pKL,
fi
fi



Centrality determined defined Eq. 11. Edges weighted (weight given
pKL,
(s)) (weight 1). Edges corresponding generation probabilities k

highest ones considered.
X
centralityScore(d) ,
wt(o d)
(11)
oC

1. Language Independent Algorithm Single Multiple Document Summarization (Mihalcea
& Tarau, 2005), weighted PageRank equation minor difference one TextRank:
Bringing Order Texts (Mihalcea & Tarau, 2004). latter presents correct equation.
2. Although LexRank TextRank based PageRank, different equations used
formalization. equation used TextRank formalization PageRank original publication, however PageRank authors observe PageRanks form probability distribution Web
pages, sum Web pages PageRanks one. indicates need normalization
factor observed LexRank formalization currently assumed correct PageRank
formalization.
3. metric proposed Mihalcea Tarau (2004) unresolved issue: denominator 0
comparing two equal sentences length one (something happen processing speech
transcriptions). Instead, Jaccard similarity coefficient (1901) could used.

280

fiRevisiting Centrality-as-Relevance

also recursive versions centrality model, similar PageRank/LexRank Continuous LexRank.

3. Support Sets Geometric Proximity
work, hypothesize input sources summarized comprehend different
topics (lateral issues beyond main topic), model idea defining support set,
based semantic relatedness, every passage input source. Semantic relatedness
estimated within geometric framework, explore several distance metrics
compute proximity. relevant content determined computing
central passages given collection support sets. proposed model estimates
salient passages input source, based exclusively information drawn
used input source.
3.1 Model
leading concept model concept support set: first step method
assess relevant content create support set passage input source
computing similarity passage remaining ones, selecting
closest passages belong support set. relevant passages ones
occur largest number support sets.
Given segmented information source , p1 , p2 , ..., pN , support sets Si associated
passage pi defined indicated Eq. 12 (sim() similarity function,
threshold).
Si , {s : sim(s, pi ) > 6= pi }
(12)
relevant segments given selecting passages satisfy Eq. 13.
fi
fi
arg max fi{Si : Si }fi

(13)

sn
i=1 Si

major difference previous centrality models main reason introduce
support sets allowing different thresholds set (i ), let centrality
influenced latent topics emerge groups related passages.
degenerate case equal, fall degree centrality model proposed
Erkan Radev (2004). using, instance, nave approach dynamic
thresholds (i ) set limiting cardinality support sets (a k NN approach), centrality changed support set semantically related passages
passage. graph theory perspective, means underlying representation undirected, support set interpreted passages recommended
passage associated support set. contrasts LexRank models,
based undirected graphs. hand, models proposed Mihalcea Tarau (2005) closer work sense explore directed
graphs, although simple way (graphs directed forward backward).
Nonetheless, semantic relatedness (content overlap) centrality assessment (performed
graph ranking algorithms HITS PageRank) quite different proposal.
concerns work Kurland Lee (2005, 2010), considering k NN
281

fiRibeiro & de Matos

approach definition support set size, similar ideias, although
addressing automatic summarization, neighborhood definition strategy different ours: Kurland Lee base neighborhood definition generation probabilities
(Eq. 10), explore geometric proximity. Nevertheless, perspective
model, k NN approach support set definition possible strategy (others
used): model seen generalization k NN NN approaches, since
propose use differentiated thresholds (i ) support set (Eq. 12).
3.2 Semantic Space
represent input source term passages matrix A, matrix element
aij = f (ti , pj ) function relates occurrences term ti within passage
pj (T number different terms; N number passages).



a1,1 . . . a1,N

= ...
aT,1 . . . aT,N

(14)

concerns definition weighting function f (ti , pj ), several term weighting
schemes explored literaturefor analysis impact different
weighting schemes either text speech summarization see work Orasan et al.
(2004), Murray Renals (2007) Ribeiro de Matos (2008b), respectively. Since
exact nature weighting function, although relevant, central work,
opted normalized frequency simplicity, defined Eq. 15, ni,j number
occurrences term ti passage pj .
ni,j
f (ti , pj ) = tfi = P
k nk,j

(15)

Nevertheless, line work Sahlgren (2006) shows several tasks
concerning term semantic relatedness, one effective weighting schemes small
contexts binary term weighting scheme (Eq. 16), alongside raw dampened counts,
is, weighting schemes, based frequency, use global weights (note
also small contexts, words frequency 1, normalized
similar binary weighting scheme).
(
1 ti pj
f (ti , pj ) =
(16)
0 ti
/ pj
3.3 Semantic Relatedness
indicated Sahlgren (2006), meanings-are-locations metaphor completely vacuous without similarity-is-proximity metaphor. sense, explore prevalent
distance measures found literature, based general Minkowski distance (Eq. 17).
distminkowski (x, y) =

n
X
i=1

282

|xi yi |N

1

N

(17)

fiRevisiting Centrality-as-Relevance

Semantic relatedness computed using Manhattan distance (N = 1, Eq. 19),
Euclidean distance (N = 2, Eq. 20), Chebyshev distance (N , Eq. 21),
fractional distance metrics (we experimented N = 0.1, N = 0.5, N = 0.75,
N = 1.(3). Note that, 0 < N < 1, Eq. 17 represent metric, since
triangle inequality hold (Koosis, 1998, page 70). case, common use
variation defined Eq. 18.
distN (x, y) =

n
X

|xi yi |N , 0 < N < 1

(18)

i=1

Moreover, also experiment general Minkowski equation, using tuple dimension N .
n
X
distmanhattan (x, y) =
|xi yi |
(19)
i=1

v
u n
uX
(xi yi )2
disteuclidean (x, y) =

(20)

i=1

distchebyshev (x, y) = lim

N

n
X

|xi yi |N

i=1

1

N

= max (|xi yi |)


(21)

cosine similarity (Eq. 22), since one used similarity metrics, especially
using spatial metaphors computing semantic relatedness, also part
experiments.
Pn
x yi
xy
simcos (x, y) =
(22)
= qP i=1qP
n
n
kxkkyk
2
2
x

i=1
i=1
Grounding semantic relatedness geometric proximity enables solid analysis
various similarity metrics. instance, using Euclidean distance (Eq. 20), differences tuple coordinate values less 1 make passages closer, values
greater 1 make passages distant; Chebyshevs distance (Eq. 21) takes
account one coordinate: one greatest difference two passages; and,
Manhattan distance (Eq. 19) considers coordinates evenly. cosine similarity
(Eq. 22), tuples representing passages vectors angle form establishes
relatedness. contrast, Mihalcea Tarau (2005) Antiqueira et al. (2009) define
passage similarity content overlap. Figure 1 (N ranges 0.1, almost imperceptible graphical representation, N , square) shows unit circle
affected several geometric distances (Manhattan, N = 1, Euclidean, N = 2,
highlighted).
Although geometric proximity enables solid analysis effects using specific
metric, mainly relies lexical overlap. metrics could used, although costs
terms required resources would increase. Examples corpus-based vector space
models semantics (Turney & Pantel, 2010), like LSA (Landauer et al., 1998), Hyperspace
Analogue Language (Lund, Burgess, & Atchley, 1995), Random Indexing (Kanerva,
Kristoferson, & Holst, 2000; Kanerva & Sahlgren, 2001), similarity metrics based
knowledge-rich semantic resources, WordNet (Fellbaum, 1998).
283

fiRibeiro & de Matos

1

0.75

0.5

0.25

-1

-0.75

-0.5

-0.25

0

0.25

0.5

0.75

1

-0.25

-0.5

-0.75

-1

Figure 1: Unit circles using various fractional distance metrics (N equals 0.1, 0.5, 0.75,
1.(3)), Manhattan distance (N = 1), Euclidean distance (N = 2),
Chebyshevs distance (N ).

3.4 Threshold Estimation
previously mentioned, simple approach threshold estimation define fixed
cardinality support sets, k NN approach. means thresholds, although
unknown, different support set.
simple heuristic allows automatically set per passage thresholds select
members support set passages distance passage associated
support set construction smaller average distance. next sections,
explore several heuristics inspired nature problem used
possibly better approaches threshold estimation. However, subject merits
study.
3.4.1 Heuristics Based Distance Progression Analysis
One possible approach analyze progression distance values
passage remaining ones creation respective support set. type
heuristics uses sorted permutation, di1 di2 diN 1 , distances
passages, sk , passage pi (corresponding support set construction),
dik = dist(sk , pi ), 1 k N 1, N number passages.
284

fiRevisiting Centrality-as-Relevance

explore three approaches: standard deviation-based approach, given
Eq. 23, parameter controls width interval around average distance
relation standard deviation; approach based diminishing differences
consecutive distances, dik+2 dik+1 < dik+1 dik , 1 k N 3, = dik+2 ,
k largest one 1jk+1 j : dij+2 dij+1 < dij+1 dij ; and, approach based
average difference consecutive distances,

dik+1 dik

PN 2

<

l=1

(dil+1 dil )
,1
N 2
P

= dik+1 , k largest one 1jk j : dij+1 dij <
= ,
v
u
N
1
1
u 1 NX
1 X
=
dk , =
(dik )2
N 1
N 1
k=1

k N 2,

N 2

l=1 (dl+1 dl )

N 2

.

(23)

k=1

3.4.2 Heuristics Based Passage Order
estimation specific thresholds aims defining support sets containing
important passages passage analysis. sense, set heuristics
explore structure input source partition candidate passages
support set two subsets: ones closer passage associated support set
construction, ones appart.
heuristics use permutation, di1 , di2 , , diN 1 , distances passages, sk ,
passage, pi , related support set construction, dik = dist(sk , pi ), 1
k N 1, corresponding order occurrence passages sk input source.
Algorithm 1 describes generic procedure.
3.4.3 Heuristics Based Weighted Graph Creation Techniques
several ways define weighted graph, given dataset. main ideia
similar nodes must connected edge large weight. set heuristics,
explore two weight functions (Zhu, 2005) (Eqs. 24 25) considering returned
value given threshold, , passage sk belongs support set passage pi ,
dik = dist(sk , pi ).
exp((dik

tanh((dik

min (dij ))2 /2 ) >

1jN 1

N 1

1 X
dj )) + 1 /2 >
N 1

(24)

(25)

j=1

3.5 Integrating Additional Information
argued Wan, Yang, Xiao (2007) Ribeiro de Matos (2008a), use
additional related information helps build better understanding given subject, thus
improving summarization performance. Wan et al. propose graph-based ranking model
uses several documents given topic summarize single one them. Ribeiro
de Matos, using LSA framework, present method combines input source
285

fiRibeiro & de Matos

Input: Two values r1 r2 , representative subset, set passages
sk corresponding distances dik passage associated support set
construction
Output: support set passage analysis
R1 , R2 ;
k 1 N 1
|r1 dik | < |r2 dik |
r1 (r1 + dik )/2;
R1 R1 {sik };
else
r2 (r2 + dik )/2;
R2 R2 {sik };
end
end
l arg min1kN 1 (dik );
sl R1
return R1 ;
else
return R2 ;
end

Algorithm 1: Generic passage order-based heuristic.

consisting spoken document, related textual background information, cope
difficulties speech-to-text summarization.
model propose may easily expanded integrate additional information.
using information source , p1 , p2 , ..., pN source additional relevant
information B, may redefine Eq. 12 shown Eq. 26 integrate additional
information.
Si , {s B : sim(s, pi ) > 6= pi }

(26)

Matrix (from Eq. 14) redefined indicated Eq. 27, aidk represents
j
weight term ti , 1 (T number terms), passage pdk , 1 k (D
j

number documents used additional information) dk1 dkj dks , document
dk ; ainl , 1 l s, elements associated input source summarized.


a1d1 ... a1d1s
1
...
A=
d11 ... d1s

...

a1dD ... a1dD

1

... dD ... dD

1

a1n1 ... a1ns
n1 ... ns





(27)

Given new definition support set common representation additional
information, relevant content still assessed using Eq. 13.
line thought applied extend model multi-document summarization.
286

fiRevisiting Centrality-as-Relevance

4. Evaluation
Summary evaluation research subject itself. Several evaluation models put
forward last decade: beyond long-established precision recall (mostly useful
evaluating extractive summarization using also extractive summaries models), literature filled metrics (some automatic, others manual) like Relative utility (Radev
et al., 2000; Radev & Tam, 2003), SummACCY (Hori, Hori, & Furui, 2003), ROUGE (Lin,
2004), VERT (de Oliveira, Torrens, Cidral, Schossland, & Bittencourt, 2008), Pyramid method (Nenkova, Passonneau, & McKeown, 2007). comprehensive analysis
evaluation field see work Nenkova (2006) Nenkova et al. (2007).
Despite number approaches summary evaluation, widely used metric
still ROUGE one use study. chose ROUGE owing
wide adoption, also one data sets used evaluation
used published studies, allowing us easily compare performance model
known systems.
P
P
S{Reference Summaries}
gramN countmatch (gramN )
P
ROUGE-N = P
(28)
S{Reference Summaries}
gramN count(gramN )
Namely, use ROUGE-1 score, known correlate well human judgment (Lin,
2004). ROUGE-N defined Eq. 28. Moreover, estimate confidence intervals using
non-parametric bootstrap 1000 resamplings (Mooney & Duval, 1993).
Since proposing generic summarization model, conducted experiments
text speech data.
4.1 Experiment 1: Text
section, describe experiments performed analyze corresponding results
using input source written text.
4.1.1 Data
used corpus, known TeMario, consists 100 newspaper articles Brazilian Portuguese (Pardo & Rino, 2003). Although model general language-independent,
corpus used several published studies, allowing us perform informed comparison results. articles corpus cover several domains, world,
politics, foreign affairs. 100 newspaper articles, reference
human-produced summary. text tokenized punctuation removed, maintaining
sentence boundary information. Table 1 sumarizes properties data set.
4.1.2 Evaluation Setup
compare performance model input affected speech-related
phenomena, use previously published state-of-the-art results text summarization.
However, since information available kind preprocessing
previous studies, could guarantee fair comparison results previous
ones, without definition adequate methodology comparisons.
following systems evaluated using TeMario dataset:
287

fiRibeiro & de Matos

#Words

#Sentences

Average

Minimum

Maximum

News Story (NS)
NS Sentence
Summary (S)
Sentence

608
21
192
21

421
1
120
1

1315
100
345
87

News Story
Summary

29
9

12
5

68
18

Table 1: Corpus characterization.
set graph-based summarizers presented Mihalcea Tarau (2005), namely
PageRank Backward, HITSA Backward HITSH Forward;
SuPor-v2 (Leite, Rino, Pardo, & Nunes, 2007), classifier-based system uses
features like occurrence proper nouns, lexical chaining, ontology;
two modified versions Mihalceas PageRank Undirected, called TextRank + Thesaurus TextRank + Stem + StopwordsRem(oval) presented Leite et al. (2007);
and,
several complex networks summarizers proposed Antiqueira et al. (2009).
Considering preprocessing step applied corpus observed differences
published results, found important evaluate systems
conditions. Thus, implemented following centrality models:
Uniform Influx (corresponds non-recursive, unweighted version model),
proposed Kurland Lee (2005, 2010) re-ranking document retrieval (we
experimented several k graph definition, sames used support set cardinality kNN strategy, 10, 20, 50, 100, 200, 500, 1000, 2000, 5000,
10000, present best results);
PageRank, proposed Mihalcea Tarau (2004, 2005) Erkan Radev
(2004) (passage similarity metrics differ Mihalcea Tarau also explore directed
graphs);
Degree centrality proposed Erkan Radev (2004) (we experimented
several thresholds , ranging 0.01 0.09, show best results); and,
Baseline, ranking defined order sentences news
article, relevance decreasing begining end.
Table 2 discriminates PageRank-based models. PageRank directed forward
graph performs consistently worse (Mihalcea & Tarau, 2005) undirected
directed backward graphs, included trials. Degree Continuous
LexRank bound performance LexRank model, ones use
288

fiRevisiting Centrality-as-Relevance

Proposed model

Generic designation

Similarity metric

Continuous LexRank
TextRank Undirected
TextRank Backward

PageRank Undirected
PageRank Undirected
PageRank Backward

Cosine
Content overlap
Content overlap

Table 2: Models based PageRank.
evaluation. Moreover, assess influence similarity metrics graphbased centrality models, tested best-performing metric model, Manhattan
distance, PageRank model. Additionally, given models proposed Erkan
Radev (2004) use idf, present results (clearly identified) using weighting
schemes: using using idf.
Concerning summary size, number words generated summaries directly
depends number words reference abstracts, consisted compressing
input sources 25-30% original size.
4.1.3 Results
Table 3 illustrates comparison previously proposed models model.
table, model identified boldface distance name, conditions
used particular instance. Every time best performance achieved instance
using supports sets whose cardinality specified absolute terms (15), also present
best performance using support sets whose cardinality specified relative terms
(10%90% input source). fractional metrics, also present value N
Eq. 17, N 1, Eq. 18, 0 < N < 1. automatically set thresholds,
identify heuristic produced best results using following notation: H0 means
heuristic based average distance; H1 means heuristics based analysis
distances progression, H1.1 corresponding one based standard
deviation, H1.2 corresponding one based diminishing differences
consecutive distances, H1.3 corresponding one based average difference
consecutive distances; H2 means heuristics based passage order, H2.1 using
r1 minimum distance, r2 average distances, H2.2 using r1
minimum distance, r2 maximum distance, H2.3, using r1 distance
first passage r2 distance second passage, according required
permutation defined Section 3.4.2; H3 means heuristics based weighted graph creation
techniques, H3.1 based Eq. 24, H3.2 based Eq. 25.
best overall results obtained support sets-based centrality model using
Fractional, N = 1.(3) using idf, Manhattan distance. next
best-performing variants model Cosine, Minkowski (N defined dimension
semantic space), Euclidean, over-performing TextRank Undirected
Uniform Influx model. best PageRank variant, using backward directed graph
cosine similarity idf, achieved performance similar Cosine (SSC = 4,
idf ) Minkowski (SSC = 2) variants model. TextRank Undirected, Uniform
Influx, Continuous LexRank (idf ) obtained performances similar Euclidean (SSC
289

fiRibeiro & de Matos

Systems

ROUGE-1

Confidence Interval

Fractional (N = 1.(3), idf, H1.3)
Manhattan (SSC = 2)
Manhattan (10%)
Manhattan (idf, H2.1)
Cosine (idf, SSC = 4)
PageRank Backward Cosine (idf )
Minkowski (SSC = 2)
Minkowski (H2.1)
Cosine (idf, H0)
Manhattan (H1.2)
Euclidean (idf, SSC = 5)
TextRank Undirected
Uniform Influx (10%NN, = 10000)
Cosine (90%)
Continuous LexRank (idf )
Fractional (N = 1.(3), H1.3)
Fractional (N = 1.(3), SSC = 1)
PageRank Backward Cosine
Degree ( = 0.02, idf )
TextRank Backward
Minkowski (10%)
Euclidean (H2.3)
Cosine (H1.3)
Fractional (N = 1.(3), 80%)
Chebyshev (H1.2)
PageRank Backward Manhattan
Euclidean (10%)
Chebyshev (SSC = 2)
Chebyshev (10%)
Continuous LexRank
PageRank Undirected Manhattan

0.442
0.442
0.440
0.439
0.439
0.439
0.439
0.437
0.437
0.437
0.436
0.436
0.436
0.436
0.436
0.435
0.435
0.435
0.435
0.434
0.434
0.434
0.432
0.432
0.432
0.432
0.431
0.429
0.429
0.428
0.428

[0.430,
[0.430,
[0.429,
[0.428,
[0.428,
[0.427,
[0.427,
[0.426,
[0.425,
[0.425,
[0.424,
[0.424,
[0.422,
[0.423,
[0.424,
[0.422,
[0.423,
[0.423,
[0.423,
[0.423,
[0.422,
[0.422,
[0.420,
[0.420,
[0.419,
[0.419,
[0.418,
[0.417,
[0.417,
[0.415,
[0.415,

0.455]
0.454]
0.453]
0.451]
0.451]
0.451]
0.452]
0.450]
0.449]
0.450]
0.448]
0.448]
0.449]
0.448]
0.448]
0.447]
0.448]
0.447]
0.447]
0.446]
0.447]
0.448]
0.444]
0.445]
0.444]
0.442]
0.444]
0.442]
0.442]
0.441]
0.440]

Baseline

0.427

[0.415, 0.440]

Fractional (N = 0.1, H1.1)
Degree ( = 0.06)
Fractional (N = 0.5, H1.1)
Fractional (N = 0.75, H1.1)
Fractional (N = 0.75, 10%)
Fractional (N = 0.1, 90%)
Fractional (N = 0.5, 90%)

0.427
0.426
0.422
0.421
0.417
0.417
0.413

[0.414,
[0.414,
[0.409,
[0.410,
[0.404,
[0.405,
[0.403,

0.439]
0.439]
0.434]
0.433]
0.429]
0.429]
0.425]

Table 3: ROUGE-1 scores text experiment (SSC stands Support Set Cardinality).

290

fiRevisiting Centrality-as-Relevance

= 5, idf ) Cosine (90%) variants. Notice although exhaustively analyzing
effects term weighting, use idf clearly benefits metrics: see, instance,
Cosine Fractional N = 1.(3) variants model, PageRank variants based
cosine similarity, Degree. relevant note model, low
computational requirements, achieves results comparable graph-based state-of-the-art
systems (Ceylan, Mihalcea, Ozertem, Lloret, & Palomar, 2010; Antiqueira et al., 2009).
Notice although estimated confidence intervals overlap, performance
Manhattan SCC=2 variant significantly better, using directional Wilcoxon signed
rank test continuity correction, ones TextRank Undirected, (W = 2584,
p < 0.05), Uniform Influx (W = 2740, p < 0.05), also Continuous LexRank (W =
2381.5, p < 0.1).4 variants model perform baseline
Fractional variants N < 1. Fractional distances N < 1, seen
effect metric unit circle (Figure 1), increase distance passages,
negatively influencing construction support sets and, consequently estimation
relevant content.
Concerning automatically set per passage thresholds, possible observe
best overall performance achieved metric, Fractional N = 1.(3), idf, using
heuristic based average difference consecutive distances. Cosine,
Manhattan, Euclidean, Minkowski variants, heuristic based average distance
(Cosine) heuristics based passage order achieved results comparable best
performing kNN approaches. Chebyshev Fractional (with N < 1) variants best
results obtained using heuristics based analysis progression
distances.
Figure 2 shows improvements baseline previous best-performing
system. possible perceive greatest performance jumps introduced
Euclidean (10%) Euclidean (H2.3), Minkowski (SSC=2), best-performing Manhattan, instances support sets-based relevance model. Additionally, important
notice improvement CN-Voting baseline (computed conditions CN-Voting) 1%, performance worse poorest TextRank
version improvement baseline 1.6%. concerns linguistic knowledge-based systems (SuPor-2 enriched versions TextRank Undirected),
cannot make informed assessment performance since cannot substantiate
used baseline, taken work Mihalcea Tarau (2005). Nonetheless, using
baseline, clear linguistic information improves performance extractive
summarizers beyond achieved model: improvements baseline
range 9% 17.5%. Notice however, would possible enrich model
linguistic information, manner TextRank.
Regarding effect similarity metric PageRank-based systems, possible observe PageRank Undirected based Content Overlap (TextRank Undirected)
better performance similarity based geometric metriceither Manhattan Cosine (Continuous LexRank). However, happen considering results obtained several variants PageRank Backward. Although use
Content Overlap, fact, leads better performance using Manhattan-based
4. Statistical tests computed using R (R Development Core Team, 2009).

291

fiRibeiro & de Matos

PageRank Undirected Manhattan
Continuous LexRank
Chebyshev (10%)
Chebyshev (SSC = 2)
Euclidean (10%)
PageRank Backward Manhattan
Chebyshev (H1.2)
Fractional (N=1.(3), 80%)
Cosine (H1.3)
Euclidean (H2.3)
Minkowski (10%)
TextRank Backward
Degree (! = 0.02, idf)
PageRank Backward Cosine
Fractional (N = 1.(3), SSC = 1)
Fractional (N = 1.(3), H1.3)
Continuous LexRank (idf)
Cosine (90%)
Uniform Influx (10%NN, =10000)
TextRank Undirected
Euclidean (SSC = 5, idf)
Manhattan (H1.2)
Cosine (idf, H0)
Minkowski (H2.1)
Minkowski (SSC = 2)
PageRank Backward Cosine (idf)
Cosine (SSC = 4, idf)
Manhattan (idf, H2.1)
Manhattan (10%)
Manhattan (SSC = 2)
Fractional (N = 1.(3), idf, H1.3)
0.00% 0.50% 1.00% 1.50% 2.00% 2.50% 3.00% 3.50% 4.00%
Improvement previous system

Improvement baseline

Figure 2: Analysis increase performance model.

similarity metric, use cosine similarity results performance comparable
one using Content Overlap metric. Manhattan-based similarity metric
defined Eq. 29.

simmanhattan (x, y) =

1
1 + distmanhattan (x, y)

(29)

4.2 Experiment 2: Speech
section, describe experiments performed analyze corresponding results
using input source automatically transcribed speech.
292

fiRevisiting Centrality-as-Relevance

4.2.1 Data
evaluate ideas speech processing setting, used data Ribeiro
de Matos (2008a): automatic transcriptions 15 broadcast news stories European
Portuguese, part news program. Subject areas include society, politics, sports,
among others. Table 4 details corpus composition. news story,
human-produced reference summary, abstract. average word recognition
error rate 19.5% automatic sentence segmentation attained slot error rate (SER,
commonly used evaluate kind task) 90.2%. possible observe Table 4,
important distinguish notion sentence written text
sentence-like unit (SU) speech data. Note, particular, difference average
number words per sentence summary versus average number words per SU
news story. According Liu, Shriberg, Stolcke, Hillard, Ostendorf, Harper (2006),
concept SU different concept sentence written text, since, although
semantically complete, SUs smaller sentence. corroborated fact
possible find news stories SUs length 1 (this corpus 8 SUs length
1). Beyond definition SU, note SER 90.2% high value: currently,
automatic punctuation module responsible delimiting SUs achieves SER 62.2%,
using prosodic information (Batista, Moniz, Trancoso, Meinedo, Mata, & Mamede, 2010).

#Words

#SUs
#Setences

Average

Minimum

Maximum

News Story (NS)
NS SU
Summary (S)
Sentence

287
11
33
20

74
1
9
8

512
91
72
33

News Story
Summary

27
2

6
1

51
4

Table 4: Corpus characterization.

4.2.2 Evaluation Setup
Regarding speech summarization, even considering difficulties concerning applicability text summarization methods spoken documents, shallow approaches like LSA
MMR seem achieve performances comparable ones using specific speech-related
features (Penn & Zhu, 2008), especially unsupervised approaches. Given implemented
models, experiment compare support sets relevance model following
systems:
LSA baseline.
following graph-based methods: Uniform Influx (Kurland & Lee, 2005, 2010),
Continuous LexRank Degree centrality (Erkan & Radev, 2004), TextRank (Mihalcea & Tarau, 2004, 2005).
293

fiRibeiro & de Matos

method proposed Ribeiro de Matos (2008a), explores use
additional related information, less prone speech-related errors (e.g. online
newspapers), improve speech summarization (Mixed-Source).
Two human summarizers (extractive) using source automatic speech transcriptions news stories (Human Extractive).
analyzing results, important examine human performance. One
relevant issues assessed level agreement two human
summarizers: accomplished using kappa coefficient (Carletta, 1996),
obtained value 0.425, considered fair moderate/good agreement (Landis
& Kosh, 1977; Fleiss, 1981). Concerning selected sentences, Figure 3 shows human
summarizer H2 consistently selected first n sentences, H1 choices
also noticeable preference first sentences news story.

1
Sentence position

2
3
H1

4

H2
5
Remaining sentences
0

5

10

15

20

Number times selected

Figure 3: Human sentence selection patterns.
able perform good assessment automatic models, conducted two
experiments: first one, number SUs extracted compose automatic
summaries defined accordance number sentences reference human
abstracts (which consisted compressing input source 10% original
size); second experiment, number extracted SUs automatic summaries
determined size shortest corresponding human extractive summary. Notice
Mixed-Source human summaries experiments.
4.2.3 Results
Table 5 shows ROUGE-1 scores obtained, speech experiments. table,
possible find one instance models, since sometimes bestperforming variant using summary size size abstracts different
one using summary size size human extracts.
294

fiRevisiting Centrality-as-Relevance

Systems

Using Summary Size Reference
Human Abstracts Shortest Human Extracts

Human Extractive 1
Human Extractive 2
Cosine (idf, H2.3)
PageRank Backward Cosine
TextRank Backward
PageRank Backward Cosine (idf )
First Sentences
PageRank Backward Manhattan
Chebyshev (H2.3)
Chebyshev (10%)
Cosine (H2.3)
Minkowski (H2.3)
Cosine (40%)
Euclidean (H2.3)
Mixed-Source
Cosine (idf, 40%)
Minkowski (40%)
Fractional (N = 1.(3), idf, H2.3)
Manhattan (H3.1)
Fractional (N = 1.(3), SSC=4)
Cosine (80%)
Fractional (N = 1.(3), H3.2)
Degree ( = 0.06)
Fractional (N = 1.(3), 20%)
Manhattan (10%)
Euclidean (20%)
Euclidean (10%)
Euclidean (SSC=3)
Fractional (N = 1.(3), 10%)
Fractional (N = 1.(3), SSC=3)
TextRank Undirected
Degree ( = 0.03, idf )
Uniform Influx (10%NN, = 500)

0.544
0.514
0.477
0.473
0.470
0.467
0.462
0.462
0.458
0.443
0.410
0.407
0.404
0.401
0.392
0.389
0.381
0.380
0.373
0.371
0.365
0.361
0.351
0.347
0.346
0.344
0.337
0.336
0.336
0.333
0.332
0.328
0.314

LSA Baseline

0.308 [0.239, 0.407]

0.338 [0.260, 0.432]

Continuous LexRank (idf )
Fractional (N = 0.1, 90%)
Continuous LexRank
PageRank Undirected Manhattan
Fractional (N = 0.5, 90%)
Fractional (N = 0.75, 90%)

0.303
0.301
0.279
0.234
0.224
0.208

0.362
0.368
0.335
0.328
0.284
0.235

[0.452,
[0.392,
[0.374,
[0.363,
[0.360,
[0.360,
[0.360,
[0.355,
[0.351,
[0.329,
[0.306,
[0.316,
[0.306,
[0.310,
[0.340,
[0.287,
[0.288,
[0.274,
[0.276,
[0.279,
[0.290,
[0.268,
[0.247,
[0.280,
[0.246,
[0.277,
[0.262,
[0.262,
[0.263,
[0.256,
[0.242,
[0.232,
[0.211,

[0.215,
[0.191,
[0.212,
[0.163,
[0.133,
[0.149,

0.640]
0.637]
0.580]
0.583]
0.580]
0.571]
0.572]
0.577]
0.571]
0.576]
0.520]
0.509]
0.512]
0.504]
0.452]
0.500]
0.495]
0.496]
0.494]
0.483]
0.458]
0.469]
0.463]
0.432]
0.478]
0.418]
0.432]
0.430]
0.429]
0.442]
0.423]
0.428]
0.427]

0.402]
0.438]
0.343]
0.295]
0.336]
0.281]

0.544
0.514
0.505
0.510
0.505
0.516
0.514
0.514
0.506
0.483
0.446
0.449
0.440
0.440
0.392
0.464
0.435
0.451
0.431
0.402
0.443
0.431
0.383
0.374
0.412
0.371
0.404
0.405
0.405
0.407
0.361
0.369
0.382

[0.455,
[0.402,
[0.405,
[0.399,
[0.391,
[0.393,
[0.390,
[0.392,
[0.388,
[0.356,
[0.329,
[0.349,
[0.344,
[0.341,
[0.339,
[0.355,
[0.325,
[0.354,
[0.343,
[0.303,
[0.345,
[0.316,
[0.276,
[0.292,
[0.311,
[0.288,
[0.296,
[0.300,
[0.305,
[0.308,
[0.262,
[0.260,
[0.258,

[0.263,
[0.252,
[0.246,
[0.240,
[0.176,
[0.165,

0.650]
0.652]
0.619]
0.628]
0.625]
0.646]
0.637]
0.648]
0.618]
0.615]
0.562]
0.571]
0.547]
0.547]
0.449]
0.577]
0.554]
0.556]
0.533]
0.526]
0.555]
0.563]
0.499]
0.467]
0.532]
0.474]
0.524]
0.519]
0.529]
0.530]
0.464]
0.476]
0.511]

0.471]
0.498]
0.441]
0.432]
0.412]
0.302]

Table 5: ROUGE-1 scores, 95% confidence intervals computed using bootstrap statistics, speech experiment (SSC stands Support Set Cardinality; sorted
using scores human abstracts).

295

fiRibeiro & de Matos

first observation concerns particular aspect corpus: seen, especially
experiment using reference size size shortest human extracts, Human 2 First Sentences summarizers attained ROUGE-1 scores (this
happen experiment using abstracts size only, due fact First Sentences
summaries shorter, adapted experiment required size, ones Human
2, changed). fact, summaries equal, shows consistent
bias indicating relevant sentences tend occur beginning news
stories. bias, although surprising, since corpus composed broadcast news
stories, also common seen previous work (Ribeiro & de Matos,
2007; Lin, Yeh, & Chen, 2010). Second, interesting notice performance
PageRank-based models: text observable trend concerning directionality graph, LexRank versions performed baseline, speech
backward versions achieved good performance (the four undirected versions performed around baseline, LexRank obtaining results LSA baseline,
exception experiment using extracts size idf ). models perspective,
considering performance backward versions text speech, use
backward directionality seems main reason good performance speech,
input sources consist transcriptions broadcast news stories news program.
fact, mentioned before, kind input source usually short (cf. Table 4)
main information given opening news story. suggests directionality introduces position information model, relevant specific types
input source (this also discussed Mihalcea & Tarau, 2005). Moreover, note
Continuous LexRank performance close LSA Baseline, implies
model quite susceptible referred bias, noisy input, both. Taking
consideration model based pair-wise passage similarity one
best-performing support sets-based instance Cosine, similarity metric used
LexRank, seems model able account structure input sources data set. fact, Degree centrality, also based cosine similarity
performed better PageRank Undirected models. Influx model performed close
Degree centrality, far best performing approaches, which, case, suggests
method generating graph, generation probabilities, affected
noisy input, especially considering small contexts like passages. Approaches based
generation probabilities seem adequate larger contexts, documents (Kurland
& Lee, 2005, 2010; Erkan, 2006a). Erkan (2006b) mentions results query-based summarization using generation probabilities worse ones obtained LexRank
generic summarization.
Concerning overall results, performance varies according size summaries. using abstracts size, best-performing instance Cosine idf
using heuristic based passage order; using reference extracts size,
best performance achieved backward PageRank model, followed Chebyshev variant also using heuristic based passage order Cosine variant.
variants achieved better results TextRank Backward. Given success
heuristic H2.3 experiments, seems heuristic may also introducing
position information model. Although achieving best performance
experiment using extracts size, significant difference best sup296

fiRevisiting Centrality-as-Relevance

port sets-based relevance model instance, Chebyshev variant using heuristic based
passage order, ones achieved human summarizers: applying directional
Wilcoxon signed rank test continuity correction, test values using shortest human extracts size W = 53, p = 0.5. means state-of-the-art performance
experiment using abstracts size, comparable human (results similar First
Sentence, similar Human Extractive 2) using shortest human extracts
size. fact, Chebyshev (10%), avoid influence possible position information,
also significantly different Human Extractive 2 (W = 11, p = 0.2092). Cosine
idf using H2.3 better performance statistical significance Degree
= 0.06 (W = 53.5, p < 0.005 using abstracts size; W = 54, p < 0.005
using shortest human extracts size), TextRank Undirected (W = 92.5, p < 0.05
using abstracts size; W = 96, p < 0.05 using shortest human extracts
size), Uniform Influx (W = 60, p < 0.01 using abstracts size; W = 51,
p < 0.06 using shortest human extracts size), using statistical test.
obtained results, speech transcriptions written text, suggest model
robust, able detect relevant content without specific information
found performing well presence noisy input. Moreover, cosine
similarity seems good metric use proposed model, performing among
top ranking variants, written spoken language.
Fractional variants N < 1 were, again, worst performing approaches (we
include values automatically set per passage thresholds Table 5, since
worse simple kNN approach) effect similarity assessment
boosts influence recognition errors. hand, Chebyshev seems
imune influence: single use maximal difference dimensions
makes less prone noise (recognition errors). happens variant using
generic Minkowski distance N equal number dimensions semantic
space.
Figures 4 5 shows performance variation introduced different approaches.
Notice that, speech experiments, performance increments magnitude higher
compared ones written text. Overall, Chebyshev variant support
sets-based relevance model introduces highest relative gains, close 10% experiment using abstracts size, close 5% experiment using extracts size.
experiment using extracts size, TextRank Undirected also achieves relative gains
near 10% previous best-performing system, LSA baseline. Similar relative
improvements introduced human summarizers experiment using abstracts size. expected, increasing size summaries increases coverage
human abstracts (bottom Figure 5).
Further, comparing model complex (not centrality-based), state-of-the-art
models like one presented Lin et al. (2010) suggests least similar performance
attained: relative performance increment model LexRank 57.4%
39.8% (both speech experiments), whereas relative gain best variant model
proposed Lin et al. LexRank 39.6%. Note taken
indicative, since accurate comparison possible data sets differ, Lin et al.
explicit variant LexRank used, address statistical significance.
297

fiRibeiro & de Matos

Summary Size Determined Human Abstracts
Continuous LexRank (idf)
LSA Baseline
Uniform Influx (10%NN, =500)
Degree (! = 0.03, idf)
TextRank Undirected
Fractional (N=1.(3), SSC=3)
Fractional (N=1.(3), 10%)
Euclidean (SSC=3)
Euclidean (10%)
Euclidean (20%)
Manhattan (10%)
Fractional (N=1.(3), 20%)
Degree (! = 0.06)
Fractional (N=1.(3), H3.2)
Cosine (80%)
Fractional (N=1.(3), SSC=4)
Manhattan (H3.1)
Fractional (N=1.(3), idf, H2.3)
Minkowski (40%)
Cosine (idf, 40%)
Mixed-Source
Euclidean (H2.3)
Cosine (40%)
Minkowski (H2.3)
Cosine (H2.3)
Chebyshev (10%)
Chebyshev (H2.3)
PageRank Backward Manhattan
First Sentences
PageRank Backward Cosine (idf)
TextRank Backward
PageRank Backward Cosine
Cosine (idf, H2.3)
Human Extractive 2
Human Extractive 1
-10%

0%

10%

20%

Improvement previous system

30%

40%

50%

60%

70%

80%

Improvement baseline

Figure 4: Analysis increase performance model (Experiment using
abstracts size).

4.3 Influence Size Support Sets Assessment Relevance
propose method determining optimum size support sets. Nonetheless, analyze influence support set size assessment relevant
content, text speech.
Figure 6 depicts behavior model variants performance baseline written text, Figure 7 illustrates variants conditions
298

fiRevisiting Centrality-as-Relevance

Summary Size Determined Shortest Human Extracts
TextRank Undirected
Continuous LexRank (idf)
Degree (! = 0.03, idf)
Euclidean (20%)
Fractional (N=1.(3), 20%)
Uniform Influx (10%NN, =500)
Degree (! = 0.06)
Mixed-Source
Fractional (N=1.(3), SSC=4)
Euclidean (10%)
Fractional (N=1.(3), 10%)
Euclidean (SSC=3)
Fractional (N=1.(3), SSC=3)
Manhattan (10%)
Fractional (N=1.(3), H3.2)
Manhattan (H3.1)
Minkowski (40%)
Euclidean (H2.3)
Cosine (40%)
Cosine (80%)
Cosine (H2.3)
Minkowski (H2.3)
Fractional (N=1.(3), idf, H2.3)
Cosine (idf, 40%)
Chebyshev (10%)
TextRank Backward
Cosine (idf, H2.3)
Chebyshev (H2.3)
PageRank Backward Cosine
PageRank Backward Manhattan
First Sentences
Human Extractive 2
PageRank Backward Cosine (idf)
Human Extractive 1
-10%

0%

10%

20%

Improvement previous system

30%

40%

50%

60%

70%

80%

Improvement baseline

Figure 5: Analysis increase performance model (Experiment using
abstracts size).

automatic speech transcriptions (in case, error bars omitted clarity). analyze general performance variants, considering support set size number
passages input source 10% increments. Given average size input source,
written text (Table 1), speech transcriptions (Table 4), absolute cardinalities
(SSC) ranging 1 5 passages broadly cover possible sizes interval 0-10%.
first observation concerns fact varying cardinality support sets
input sources consist written text smooth effect performance.
allows analysis generic tendencies. contrast, processing automatic
299

fiRibeiro & de Matos

Cosine

Manhattan (N=1)

Fractional (N=1.(3))

90%

80%

70%

60%

50%

40%

90%

80%

70%

60%

50%

40%

30%

20%

10%

SSC=5

SSC=3

SSC=4

SSC=2

0.39

SSC=1

0.4

0.39

30%

0.41

0.4

20%

0.42

0.41

10%

0.43

0.42

SSC=5

0.43

SSC=3

0.44

SSC=4

0.45

0.44

SSC=2

0.46

0.45

SSC=1

0.46

Euclidean (N=2)

70%

80%

90%

80%

90%

60%

50%

70%

Minkowski (variable N)

40%

90%

80%

70%

60%

50%

40%

30%

20%

10%

SSC=5

SSC=4

SSC=3

SSC=2

0.39

SSC=1

0.4

0.39

30%

0.41

0.4

20%

0.42

0.41

10%

0.43

0.42

SSC=5

0.43

SSC=4

0.44

SSC=3

0.45

0.44

SSC=2

0.46

0.45

SSC=1

0.46

Chebyshev (N!!)

60%

50%

40%

90%

80%

70%

60%

50%

40%

30%

20%

10%

SSC=5

SSC=4

SSC=3

SSC=2

0.39

SSC=1

0.4

0.39

30%

0.41

0.4

20%

0.42

0.41

10%

0.43

0.42

SSC=5

0.43

SSC=4

0.44

SSC=3

0.45

0.44

SSC=2

0.46

0.45

SSC=1

0.46

Figure 6: Analysis impact cardinality support sets text summarization. axes ROUGE-1 scores X axes support sets cardinalities
(absolute relative length input source, terms passages).

speech transcriptions, possible perceive several irregularities. irregularities
two different causes: intrinsic characteristics speech transcriptions
recognition errors, sentence boundary detection errors, type discourse; or,
specificities data setin particular, global size corpus specific
news story structure. However, considering performance metrics text
speech, irregularities seem mainly caused intrinsic properties speech
transcriptions specific structure news story.
300

fiRevisiting Centrality-as-Relevance

90%

80%

60%

50%

40%

70%
70%

80%

90%

70%

80%

90%

60%

50%

40%

30%

60%

50%

40%

30%

20%

90%

80%

70%

60%

50%

40%

30%

20%

10%

SSC=5

SSC=4

0.2

SSC=3

0.2

SSC=2

0.3
0.25
SSC=1

0.3
0.25

10%

0.4
0.35

SSC=5

0.4
0.35

SSC=4

0.5
0.45

SSC=3

0.5
0.45

SSC=2

Chebyshev (N!!)

SSC=1

Minkowski (variable N)

20%

90%

80%

70%

60%

50%

40%

30%

20%

10%

SSC=5

SSC=4

0.2

SSC=3

0.2

SSC=2

0.3
0.25
SSC=1

0.3
0.25

10%

0.4
0.35

SSC=5

0.4
0.35

SSC=4

0.5
0.45

SSC=3

0.5
0.45

SSC=2

Euclidean (N=2)

SSC=1

Fractional (N=1.(3))

30%

90%

80%

70%

60%

50%

40%

30%

20%

10%

SSC=5

SSC=3

0.2

SSC=4

0.2

SSC=2

0.25
SSC=1

0.3

0.25

20%

0.35

0.3

10%

0.35

SSC=5

0.4

SSC=3

0.45

0.4

SSC=4

0.45

SSC=2

Manhattan (N=1)
0.5

SSC=1

Cosine
0.5

Figure 7: Analysis impact cardinality support sets speech-to-text
summarization. axes ROUGE-1 scores X axes support sets cardinalities (absolute relative length input source terms passages).
Lines square marks correspond experiment using summary size
size human abstracts; lines circle marks correspond experiment
using summary size size shortest human extracts. Horizontal lines
correspond baselines.

301

fiRibeiro & de Matos

Concerning performance itself, written text, best performances achieved using
low cardinalities (absolute cardinalities 2 3 passages, 10% passages
input source). Moreover, increase size support sets leads decay
results (except using cosine similarity). processing automatic speech
transcriptions, difficult find clear definition best results achieved.
Considering absolute cardinalities, exception Manhattan distance, every
variant peak using support sets 4 passages. However, possible
extend line thought relative sizes due previously referred irregularities.
Nonetheless, higher cardinalities (70%90%) lead worse results, expected given
nature model (again exception using cosine similarity).
addition, note increasing size summaries improves distinction
baseline (summaries based size shortest human extracts longer
ones based size human abstracts). means model robust
needs regarding summary size, continuing select good content even larger summaries.

5. Conclusions
number up-to-date examples work automatic summarization using centralitybased relevance models significant (Garg, Favre, Reidhammer, & Hakkani-Tur, 2009;
Antiqueira et al., 2009; Ceylan et al., 2010; Wan, Li, & Xiao, 2010). work,
assessed main approaches centrality-as-relevance paradigm, introduced
new centrality-based relevance model automatic summarization. model uses support
sets better characterize information sources summarized, leading better
estimation relevant content. fact, assume input sources comprehend
several topics uncovered associating passage support set composed
semantically related passages. Building ideas Ruge (1992), [...]
model semantic space relative position two terms determines semantic
similarity better fits imagination human intuition [about] semantic similarity [...],
semantic relatedness computed geometric proximity. explore several metrics
analyze impact proposed model well (to certain extent) related
work. Centrality (relevance) determined taking account whole input source,
local information, using support sets-based representation. Moreover,
although formally analyzed, notice proposed model low computational
requirements.
conducted thorough automatic evaluation, experimenting model written text transcribed speech summarization. obtained results suggest
model robust, able detect relevant content without specific information
found performing well presence noisy input,
automatic speech transcriptions. However, must taken consideration
use ROUGE summary evaluation, although generalized, allowing easily compare
results replicate experiments, ideal scenario, consequently, results
corroborated perceptual evaluation. outcome performed trials show
proposed model achieves state-of-the-art performance text speech summarization, including compared considerably complex approaches. Nonetheless,
identified limitations. First, although grounding semantic similarity geometric
302

fiRevisiting Centrality-as-Relevance

proximity, current experiments rely mainly lexical overlap. maintaining
semantic approach, use complex methods (Turney & Pantel, 2010) may improve assessment semantic similarity. Second, address specific procedure
estimating optimum thresholds, leaving future research. Nonetheless, explored
several heuristics achieved top ranking performance. Moreover, carried
document analysis provides clues adequate dimension support
sets, analytical analysis performed.

Acknowledgments
would like thank anonymous reviewers insightful comments. work
supported FCT (INESC-ID multiannual funding) PIDDAC Program
funds.

References
Aggarwal, C. C., Hinneburg, A., & Keim, D. A. (2001). Surprising Behavior
Distance Metrics High Dimensional Space. den Bussche, J. V., & Vianu, V.
(Eds.), Database Theory ICDT 2001, 8th International Conference London, UK,
January 46, 2001 Proceedings, Vol. 1973 Lecture Notes Computer Science, pp.
420434. Springer.
Antiqueira, L., Oliveira Jr., O. N., da Fontoura Costa, L., & Nunes, M. G. V. (2009).
complex network approach text summarization. Information Sciences, 179 (5),
584599.
Batista, F., Moniz, H., Trancoso, I., Meinedo, H., Mata, A. I., & Mamede, N. J. (2010).
Extending punctuation module European Portuguese. Proceedings
11th Annual Conference International Speech Communication Association (INTERSPEECH 2010), pp. 15091512. ISCA.
Brin, S., & Page, L. (1998). anatomy large-scale hypertextual Web search engine.
Computer Networks ISDN Systems, 30, 107117.
Carbonell, J., & Goldstein, J. (1998). Use MMR, Diversity-Based Reranking
Reordering Documents Producing Summaries. SIGIR 1998: Proceedings
21st Annual International ACM SIGIR Conference Research Development
Information Retrieval, pp. 335336. ACM.
Carletta, J. (1996). Assessing agreement classification tasks: kappa statistic. Computational Linguistics, 22 (2), 249254.
Ceylan, H., Mihalcea, R., Ozertem, U., Lloret, E., & Palomar, M. (2010). Quantifying
Limits Success Extractive Summarization Systems Across Domains. Human
Language Technologies: 2010 Annual Conference North American Chapter
ACL, pp. 903911. Association Computational Linguistics.
Christensen, H., Gotoh, Y., Kolluru, B., & Renals, S. (2003). Extractive Text Summarisation Techniques Portable Broadcast News?. Proceedings IEEE Work303

fiRibeiro & de Matos

shop Automatic Speech Recognition Understanding (ASRU 03), pp. 489494.
IEEE.
Cohn, T., & Lapata, M. (2009). Sentence Compression Tree Transduction. Journal
Artificial Intelligence Research, 34, 637674.
de Oliveira, P. C. F., Torrens, E. W., Cidral, A., Schossland, S., & Bittencourt, E. (2008).
Evaluating Summaries Automatically system proposal. Proceedings Sixth
International Language Resources Evaluation (LREC08), pp. 474479. ELRA.
Endres-Niggemeyer, B. (1998). Summarizing Information. Springer.
Erkan, G. (2006a). Language Model-Based Document Clustering Using Random Walks.
Proceedings Human Language Technology Conference North American
Chapter ACL, pp. 479486. Association Computational Linguistics.
Erkan, G. (2006b). Using Biased Random Walks Focused Summarization. Proceedings
Document Understanding Conference.
Erkan, G., & Radev, D. R. (2004). LexRank: Graph-based Centrality Salience Text
Summarization. Journal Artificial Intelligence Research, 22, 457479.
Fellbaum, C. (Ed.). (1998). WordNet: Electronic Lexical Database. MIT Press.
Fleiss, J. L. (1981). Statistical methods rates proportions (2nd edition). John Wiley.
Furui, S. (2007). Recent Advances Automatic Speech Summarization. Proceedings
8th Conference Recherche dInformation Assistee par Ordinateur (RIAO).
Centre des Hautes Etudes Internationales dInformatique Documentaire.
Garg, N., Favre, B., Reidhammer, K., & Hakkani-Tur, D. (2009). ClusterRank: Graph
Based Method Meeting Summarization. Proceedings 10th Annual Conference International Speech Communication Association (INTERSPEECH 2009),
pp. 14991502. ISCA.
Gong, Y., & Liu, X. (2001). Generic Text Summarization Using Relevance Measure Latent Semantic Analysis. SIGIR 2001: Proceedings 24st Annual International
ACM SIGIR Conference Research Development Information Retrieval, pp.
1925. ACM.
Harabagiu, S., & Lacatusu, F. (2005). Topic Themes Multi-Document Summarization.
SIGIR 2005: Proceedings 28th Annual International ACM SIGIR Conference
Research Development Information Retrieval, pp. 202209. ACM.
Hori, C., Hori, T., & Furui, S. (2003). Evaluation Method Automatic Speech Summarization. Proceedings 8th EUROSPEECH - INTERSPEECH 2003, pp.
28252828. ISCA.
Jaccard, P. (1901). Etude comparative de la distribution florale dans une portion des Alpes
et des Jura. Bulletin del la Societe Vaudoise des Sciences Naturelles, 37, 547579.
Kanerva, P., Kristoferson, J., & Holst, A. (2000). Random Indexing text samples
Latent Semantic Analysis. Gleitman, L. R., & Joshi, A. K. (Eds.), Proceedings
22nd annual conference Cognitive Science Society, p. 1036. Psychology
Press.
304

fiRevisiting Centrality-as-Relevance

Kanerva, P., & Sahlgren, M. (2001). Foundations real-world intelligence, chap.
words understanding, pp. 294311. No. 26. Center Study Language
Information.
Kleinberg, J. M. (1999). Authoritative Sources Hyperlinked Environment. Journal
ACM, 46 (5), 604632.
Koosis, P. (1998). Introduction Hp Spaces. Cambridge Universisty Press.
Kurland, O., & Lee, L. (2005). PageRank without Hyperlinks: Structural Re-Ranking using
Links Induced Language Models. SIGIR 2005: Proceedings 28th Annual
International ACM SIGIR Conference Research Development Information
Retrieval, pp. 306313. ACM.
Kurland, O., & Lee, L. (2010). PageRank without Hyperlinks: Structural Reranking using
Links Induced Language Models. ACM Transactions Information Systems,
28 (4), 138.
Landauer, T. K., Foltz, P. W., & Laham, D. (1998). Introduction Latent Semantic
Analysis. Discourse Processes, 25 (2), 259284.
Landis, J. R., & Kosh, G. G. (1977). Measurement Observer Agreement Categorical Data. Biometrics, 33, 159174.
Leite, D. S., Rino, L. H. M., Pardo, T. A. S., & Nunes, M. G. V. (2007). Extractive Automatic Summarization: linguitic knowledge make difference?. Proceedings Second Workshop TextGraphs: Graph-based Algorithms Natural
Language Processing, pp. 1724. Association Computational Linguistics.
Lin, C.-Y. (2004). ROUGE: Package Automatic Evaluation Summaries. Moens,
M.-F., & Szpakowicz, S. (Eds.), Text Summarization Branches Out: Proceedings
ACL-04 Workshop, pp. 7481. Association Computational Linguistics.
Lin, C.-Y., & Hovy, E. (2000). Automated Acquisition Topic Signatures Text
Summarization. Coling 2000: 18th International Conference Computational
Linguistics, Vol. 1, pp. 495501. Association Computational Linguistics.
Lin, S.-H., Yeh, Y.-M., & Chen, B. (2010). Extractive Speech Summarization
View Decision Theory. Proceedings 11th Annual Conference
International Speech Communication Association (INTERSPEECH 2010), pp. 1684
1687. ISCA.
Liu, Y., Shriberg, E., Stolcke, A., Hillard, D., Ostendorf, M., & Harper, M. (2006). Enriching Speech Recognition Automatic Detection Sentence Boundaries
Disfluencies. IEEE Transactions Speech Audio Processing, 14 (5), 15261540.
Lund, K., Burgess, C., & Atchley, R. A. (1995). Semantic associative priming highdimensional semantic space. Moore, J. D., & Lehman, J. F. (Eds.), Proceedings
17th annual conference Cognitive Science Society, pp. 660665. Psychology
Press.
Marcu, D. (2000). Theory Practice Discourse Parsing Summarization.
MIT Press.
305

fiRibeiro & de Matos

Maskey, S. R., & Hirschberg, J. (2005). Comparing Lexical, Acoustic/Prosodic, Strucural
Discourse Features Speech Summarization. Proceedings 9th EUROSPEECH - INTERSPEECH 2005.
McKeown, K. R., Hirschberg, J., Galley, M., & Maskey, S. R. (2005). Text Speech
Summarization. 2005 IEEE International Conference Acoustics, Speech,
Signal Processing. Proceedings, Vol. V, pp. 9971000. IEEE.
Mihalcea, R., & Tarau, P. (2004). TextRank: Bringing Order Texts. Proceedings
2004 Conference Empirical Methods Natural Language Processing, pp.
404411. Association Computational Linguistics.
Mihalcea, R., & Tarau, P. (2005). Language Independent Algorithm Single
Multiple Document Summarization. Proceedings Second International Joint
Conference Natural Language Processing: Companion Volume Proceedings
Conference including Posters/Demos Tutorial Abstracts, pp. 1924. Asian Federation Natural Language Processing.
Mooney, C. Z., & Duval, R. D. (1993). Bootstrapping : nonparametric approach statistical inference. Sage Publications.
Murray, G., & Renals, S. (2007). Term-Weighting Summarization Multi-Party Spoken
Dialogues. Popescu-Belis, A., Renals, S., & Bourlard, H. (Eds.), Machine Learning
Multimodal Interaction IV, Vol. 4892 Lecture Notes Computer Science, pp.
155166. Springer.
Nenkova, A. (2006). Summarization Evaluation Text Speech: Issues Approaches.
Proceedings INTERSPEECH 2006 - ICSLP, pp. 15271530. ISCA.
Nenkova, A., Passonneau, R., & McKeown, K. (2007). pyramid method: incorporating
human content selection variation summarization evaluation. ACM Transactions
Speech Language Processing, 4 (2).
Orasan, C., Pekar, V., & Hasler, L. (2004). comparison summarisation methods based
term specificity estimation. Proceedings Fourth International Language
Resources Evaluation (LREC04), pp. 10371041. ELRA.
Pardo, T. A. S., & Rino, L. H. M. (2003). TeMario: corpus automatic text summarization. Tech. rep. NILC-TR-03-09, Nucleo Interinstitucional de Lingustica Computacional (NILC), Sao Carlos, Brazil.
Penn, G., & Zhu, X. (2008). Critical Reassessment Evaluation Baselines Speech
Summarization. Proceeding ACL-08: HLT, pp. 470478. Association Computational Linguistics.
R Development Core Team (2009). R: Language Environment Statistical Computing. R Foundation Statistical Computing, Vienna, Austria. ISBN 3-900051-07-0.
Radev, D. R., Hatzivassiloglou, V., & McKeown, K. R. (1999). Description CIDR
System Used TDT-2. Proceedings DARPA Broadcast News Workshop.
Radev, D. R., Jing, H., & Budzikowska, M. (2000). Centroid-based summarization multiple documents: sentence extraction, utility-based evaluation, user studies.
306

fiRevisiting Centrality-as-Relevance

NAACL-ANLP 2000 Workshop: Automatic Summarization, pp. 2130. Association
Computational Linguistics.
Radev, D. R., Jing, H., Stys, M., & Tam, D. (2004). Centroid-based summarization
multiple documents. Information Processing Management, 40, 919938.
Radev, D. R., & Tam, D. (2003). Summarization Evaluation using Relative Utility.
Proceedings 12th international conference Information Knowledge Management, pp. 508511. ACM.
Ribeiro, R., & de Matos, D. M. (2007). Extractive Summarization Broadcast News: Comparing Strategies European Portuguese. Matousek, V., & Mautner, P. (Eds.),
Text, Speech Dialogue 10th International Conference, TSD 2007, Pilsen, Czech
Republic, September 3-7, 2007. Proceedings, Vol. 4629 Lecture Notes Computer
Science (Subseries LNAI), pp. 115122. Springer.
Ribeiro, R., & de Matos, D. M. (2008a). Mixed-Source Multi-Document Speech-to-Text
Summarization. Coling 2008: Proceedings 2nd workshop Multi-source
Multilingual Information Extraction Summarization, pp. 3340. Coling 2008 Organizing Committee.
Ribeiro, R., & de Matos, D. M. (2008b). Using Prior Knowledge Assess Relevance
Speech Summarization. 2008 IEEE Workshop Spoken Language Technology,
pp. 169172. IEEE.
Ruge, G. (1992). Experiments linguistically-based term associations. Information Processing Management, 28 (3), 317332.
Sahlgren, M. (2006). Word-Space Model: Using distributional analysis represent syntagmatic paradigmatic relations words high-dimensional vector spaces.
Ph.D. thesis, Stockholm University.
Steyvers, M., & Griffiths, T. (2007). Handbook Latent Semantic Analysis, chap. Probabilistic Topic Models, pp. 427448. Lawrence Erlbaum Associates.
Tucker, R. I., & Sparck Jones, K. (2005). shallow deep: experiment automatic summarising. Tech. rep. 632, University Cambridge Computer Laboratory.
Turney, P. D., & Pantel, P. (2010). Frequency Meaning: Vector Space Models
Semantics. Journal Artificial Intelligence Research, 37, 141188.
Uzeda, V. R., Pardo, T. A. S., & Nunes, M. G. V. (2010). comprehensive comparative
evaluation RST-based summarization methods. ACM Transactions Speech
Language Processing, 6 (4), 120.
Vanderwende, L., Suzuki, H., Brockett, C., & Nenkova, A. (2007). Beyond SumBasic:
Task-focused summarization lexical expansion. Information Processing Management, 43, 16061618.
Wan, X., Li, H., & Xiao, J. (2010). EUSUM: Extracting Easy-to-Understand English Summaries Non-Native Readers. SIGIR 2010: Proceedings 33th Annual International ACM SIGIR Conference Research Development Information
Retrieval, pp. 491498. ACM.
307

fiRibeiro & de Matos

Wan, X., Yang, J., & Xiao, J. (2007). CollabSum: Exploiting Multiple Document Clustering
Collaborative Single Document Summarizations. SIGIR 2007: Proceedings
30th Annual International ACM SIGIR Conference Research Development
Information Retrieval, pp. 143150. ACM.
Zechner, K., & Waibel, A. (2000). Minimizing Word Error Rate Textual Summaries
Spoken Language. Proceedings 1st conference North American chapter
ACL, pp. 186193. Morgan Kaufmann.
Zhu, X. (2005). Semi-Supervised Learning Graphs. Ph.D. thesis, Language Technologies
Institute, School Computer Science, Carnegie Mellon University.

308

fiJournal Artificial Intelligence Research 42 (2011) 91-124

Submitted 5/11; published 10/11

Scheduling Bipartite Tournaments
Minimize Total Travel Distance
Richard Hoshino
Ken-ichi Kawarabayashi

richard.hoshino@gmail.com
k keniti@nii.ac.jp

National Institute Informatics,
2-1-2 Hitotsubashi, Chiyoda-ku, Tokyo 101-8430, Japan

Abstract
many professional sports leagues, teams opposing leagues/conferences compete
one another, playing inter-league games. example bipartite tournament. paper, consider problem reducing total travel distance
bipartite tournaments, analyzing inter-league scheduling perspective discrete optimization. research natural applications sports scheduling, especially
leagues National Basketball Association (NBA) teams must travel
long distances across North America play games, thus consuming much time,
money, greenhouse gas emissions.
introduce Bipartite Traveling Tournament Problem (BTTP), inter-league
variant well-studied Traveling Tournament Problem. prove 2n-team
BTTP NP-complete, small values n, distance-optimal inter-league schedule
generated algorithm based minimum-weight 4-cycle-covers. apply
theoretical results 12-team Nippon Professional Baseball (NPB) league Japan,
producing provably-optimal schedule requiring 42950 kilometres total team travel,
16% reduction compared actual distance traveled teams 2010
NPB season. also develop nearly-optimal inter-league tournament 30-team
NBA league, 3.8% higher trivial theoretical lower bound.

1. Introduction
Consider tournament involving two teams X , n players. bipartite
tournament, players team X compete players team , goal
determining superior team. Labeling players {x1 , x2 , . . . , xn } {y1 , y2 , . . . , yn },
represent match ordered pair (xi , yj ), indices i, j {1, 2, . . . , n}.
Davis Cup example bipartite tournament, country fields
tennis squad consisting two singles players doubles team. five matches
played two countries, doubles teams squaring Day 2, sandwiched
singles matches (x1 , y1 ), (x2 , y2 ) Day 1, (x1 , y2 ), (x2 , y1 ) Day 3.
Another example biennial Ryder Cup championship, United States
Europe field teams consisting top twelve male golfers. competition culminates
twelve head-to-head matches last day, ith ranked golfer United
States facing ith ranked golfer Europe.
single round-robin (SRR) bipartite tournament, player X competes
every player once, everyone playing one match time slot.
produces tournament n2 matches spread n time slots. double roundc
2011
AI Access Foundation. rights reserved.

fiHoshino & Kawarabayashi

robin (DRR) bipartite tournament, pair plays twice, thus producing tournament
2n2 matches spread 2n time slots. SRR bipartite tournaments common
tennis ping-pong, DRR bipartite tournaments used chess, xi plays
yj twice, one game white one game black. aforementioned
Ryder Cup example partial bipartite tournament, player X plays
proper subset players .
much research conducted theory bipartite tournaments
(Kendall, Knust, Ribeiro, & Urrutia, 2010), previous papers dealt feasibility
fairness, specifically constructing balanced tournament designs minimizing carryover effects (Easton, Nemhauser, & Trick, 2004) ensure competitive balance
players team.
replacing words team player league team, respectively,
view X two n-team sports leagues, bipartite tournament
X represents inter-league play. example, Major League Baseball (MLB) holds
four weeks inter-league games season, every American League team playing 18
games half-dozen teams National League. MLB inter-league play
example partial bipartite tournament, some/many scheduled games
based historical rivalry geographic proximity.
light, consider problem minimizing total travel distance bipartite
tournaments. chess tennis, issue travel irrelevant tournament matches
take place venue. However, case inter-league play professional
baseball, teams must travel long distances play games across North America,
finding schedule reduces total travel distance important, economic
environmental reasons.
answer question creating distance-optimal inter-league schedule, introduce variant Traveling Tournament Problem (TTP), every pair teams
plays twice, one game teams home stadium. output optimal schedule minimizes sum total distances traveled teams move city
city, subject several natural constraints ensure balance fairness. Unlike
TTP models double round-robin intra-league tournament, variant, Bipartite Traveling Tournament Problem (BTTP), seeks best possible double round-robin
inter-league tournament.
Since introduction (Easton, Nemhauser, & Trick, 2001), TTP emerged
popular area study within operations research community (Kendall et al., 2010)
due incredible complexity, challenging benchmark problems remain unsolved.
Research TTP led development powerful techniques integer programming, constraint programming, well advanced heuristics simulated annealing (Anagnostopoulos, Michel, Hentenryck, & Vergados, 2006) hill-climbing (Lim,
Rodrigues, & Zhang, 2006). importantly, TTP direct applications scheduling optimization, aid professional sports leagues make regular season
schedules efficient, saving time money, well reducing greenhouse gas emissions.
purpose paper consider problem creating distance-optimal interleague tournaments, thus connecting techniques methods sports scheduling
theory bipartite tournaments, producing new directions research scheduling op92

fiScheduling Bipartite Tournaments Minimize Total Travel Distance

timization. Optimizing inter-league tournaments natural next step field sports
scheduling, especially since introduction inter-league play professional sports.
example, Major League Baseball, inter-league play began 1997, six decades
first proposed. Japan, Nippon Professional Baseball (NPB) league formed
1950, yet NPB inter-league play commence 2005.
authors motivated analyze Japanese NPB schedule, due puzzling
inefficiencies regular season schedule believed could improved. developed multi-round generalization TTP (Hoshino & Kawarabayashi, 2011c) based
Dijkstras shortest path algorithm create distance-optimal intra-league schedule
reduced total travel distance 60000 kilometres compared 2010 NPB
schedule. elaborated intricacies intra-league scheduling journal
paper (Hoshino & Kawarabayashi, 2011d). Inspired success analyzing intra-league
scheduling, asked whether techniques methods could extended inter-league
play, wondering whether 2010 NPB schedule requiring 51134 kilometres total team
travel could minimized optimality. answered question presenting Bipartite Traveling Tournament Problem (Hoshino & Kawarabayashi, 2011b), providing
rigorous analysis BTTP NPB distance matrix, producing provably-optimal interleague schedule requiring 42950 kilometres total team travel (Hoshino & Kawarabayashi,
2011a).
purpose paper expand upon two inter-league conference papers
provide thorough discussion BTTP properties. present rigorous proof
lemma omitted due space constraints (Hoshino & Kawarabayashi, 2011b),
key proving NP-completeness BTTP. also present application BTTP
beyond Japanese baseball, considering problem optimizing inter-league scheduling
30-team National Basketball Association (NBA) North America. briefly
alluded NBA inter-league problem (Hoshino & Kawarabayashi, 2011b), able
provide full analysis paper.
Section 2, formally define BTTP discuss uniform non-uniform schedules.
Section 3, prove BTTP 2n teams NP-complete obtaining reduction
3-SAT, well-known NP-complete problem boolean satisfiability (Garey & Johnson, 1979). Despite computational intractability general n, present simple yet
powerful heuristic involving minimum-weight 4-cycle-covers apply 12-team
NPB league Japan, well 30-team NBA.
Section 4, solve BTTP NPB, producing optimal schedule whose total
travel distance 42950 kilometres 16% less 51134 kilometres traveled
teams five weeks inter-league play 2010 season. Section 5, produce
nearly-optimal solution BTTP NBA, developing bipartite tournament schedule
whose total travel distance 537791 miles 3.8% higher trivial theoretical
lower bound. Section 6, conclude paper several open problems present
directions future research.

2. Definitions
Let 2n teams, n teams league. Let X two leagues,
X = {x1 , x2 , . . . , xn } = {y1 , y2 , . . . , yn }. Let 2n 2n distance matrix,
93

fiHoshino & Kawarabayashi

entry Dp,q distance home stadiums teams p q. definition,
Dp,q = Dq,p p, q X , diagonal entries Dp,p zero. Similar original
TTP, require compact double round-robin bipartite tournament schedule satisfying
following conditions:
(a) at-most-three: team may home stand road trip lasting three
games.
(b) no-repeat: team cannot play opponent two consecutive games.
(c) each-venue: 1 i, j n, teams xi yj play twice, others
home venue.

x1
x2
x3
y1
y2
y3

1
y1
y2
y3
x1
x2
x3

2
y2
y3
y1
x3
x1
x2

3
y3
y1
y2
x2
x3
x1

4
y1
y2
y3
x1
x2
x3

5
y2
y3
y1
x3
x1
x2

6
y3
y1
y2
x2
x3
x1

x1
x2
x3
y1
y2
y3

1
y3
y1
y2
x2
x3
x1

2
y2
y3
y1
x3
x1
x2

3
y1
y2
y3
x1
x2
x3

4
y3
y1
y2
x2
x3
x1

5
y1
y2
y3
x1
x2
x3

6
y2
y3
y1
x3
x1
x2

Table 1: Two feasible inter-league tournaments n = 3.
illustrate, Table 1 provides two feasible tournaments satisfying conditions case n = 3. table, schedules subsequently
presented, home games marked bold.
Following convention TTP, whenever team scheduled road trip
consisting multiple away games, team doesnt return home city rather
proceeds directly next away venue. Furthermore, assume every team begins
tournament home, returns home playing last away game. example,
Table 1, team x1 would travel distance Dx1 ,y1 + Dy1 ,y2 + Dy2 ,y3 + Dy3 ,x1 playing
schedule left distance Dx1 ,y3 + Dy3 ,y2 + Dy2 ,x1 + Dx1 ,y1 + Dy1 ,x1
playing schedule right. desired solution BTTP tournament schedule
minimizes total distance traveled 2n teams subject given conditions.
Define trip pair consecutive games occurring city, i.e.,
situation team doesnt play location time slots + 1,
therefore travel one venue another. Table 1, schedule left
24 total trips, schedule right 32 trips. One may conjecture
total distance schedule S1 lower total distance schedule S2 iff S1 fewer
trips S2 .
see actually case, let teams x1 , x3 , y1 , y2 located
(0, 0) let x2 y3 located (1, 0). schedule left total
distance 16 schedule right total distance 12. minimizing trips
correlate minimizing total travel distance; former trivial problem,
latter extremely difficult, even case n = 3.
six teams x1 , x2 , x3 , y1 , y2 , y3 located Cartesian plane
distance-optimal solution occurs via schedule 27 trips, although majority
cases, distance-optimal schedule consists 24 trips, fewest number possible.
94

fiScheduling Bipartite Tournaments Minimize Total Travel Distance

inspires several interesting open problems present conclusion
paper. provide example 27 trips, locate six teams x1 = (8, 0), x2 = (9, 0),
x3 = (0, 4), y1 = (6, 1), y2 = (0, 7), y3 = (3, 5). computer search proves
minimal distance






18 + 16 5 + 16 2 + 3 13 + 5 10 + 2 130 + 61 133.646,
equality iff inter-league schedule one two appearing Table 2. Note
27-trip distance-optimal schedules mirror image other.
x1
x2
x3
y1
y2
y3

1
y1
y2
y3
x1
x2
x3

2
y2
y3
y1
x3
x1
x2

3
y3
y1
y2
x2
x3
x1

4
y1
y2
y3
x1
x2
x3

5
y2
y3
y1
x3
x1
x2

6
y3
y1
y2
x2
x3
x1

x1
x2
x3
y1
y2
y3

1
y3
y1
y2
x2
x3
x1

2
y2
y3
y1
x3
x1
x2

3
y1
y2
y3
x1
x2
x3

4
y3
y1
y2
x2
x3
x1

5
y2
y3
y1
x3
x1
x2

6
y1
y2
y3
x1
x2
x3

Table 2: 27-trip distance-optimal schedules special selection 6 points.
Let BTTP* restriction BTTP set tournament schedules
given time slot, teams league either play home, play road.
example, left schedule Table 1 feasible solution BTTP BTTP*. say
schedules uniform. uniformity constraint significantly reduces
number potential tournaments, allows us quickly generate approximate solution
BTTP algorithm based minimum-weight 4-cycle-covers.
prove BTTP BTTP* NP-complete obtaining reduction
3-SAT, well-known NP-complete problem deciding whether boolean formula
conjunctive normal form three literals per clause admits satisfying assignment
(Garey & Johnson, 1979).

3. Theoretical Results
establish reduction, first express BTTP decision form:
INSTANCE:
(a) 2n teams, n teams belong league X n teams belong league .
(b) 2n 2n distance matrix whose entries distances pair
teams X .
(c) integer 0.
QUESTION: exist double round-robin bipartite tournament which:
(a) at-most-three, no-repeat, each-venue conditions satisfied.
(b) sum distances traveled 2n teams .
95

fiHoshino & Kawarabayashi

Similarly, express BTTP* decision form, adding uniformity constraint (i.e., given time slot, team plays home iff every team league
also plays home). reduce two problems 3-SAT.
Let = C1 C2 . . . Cm conjunction clauses three literals
variables {u1 , u2 , . . . , ul }. S, define sets XS YS representing teams
leagues X . set |XS | + |YS | vertices, describe polynomialtime algorithm constructs complete graph assigns edge weights produce
distance matrix DS . prove existence integer = (m)
solutions BTTP BTTP* total travel distance iff satisfiable.
establish desired polynomial-time reductions.
assume literals ui ui occur equally often 1 l.
see why, assume without loss ui occurs less frequently ui . repeated addition
tautological clause (ui ui+1 ui+1 ), affect satisfiability S,
ensure number occurrences ui matches ui .
Let r(i) denote number occurrences ui S. Figure 1, present gadget
variable ui , vertices ui,r ui,r correspond respectively r th
occurrence ui ui S, vertex ai,r adjacent ui,r1 ui,r , vertex bi,r
adjacent ui,r ui,r . (Note: ui,0 := ui,r(i) i.)

Figure 1: Gadget 3-SAT reduction.
gadget used establish NP-completeness deciding whether undirected graph contains given number vertex-disjoint s-t paths specified length (Itai,
Perl, & Shiloach, 1982) prove original TTP NP-complete (Thielen &
Westphal, 2010).
l gadgets, one ui , = 1, 2, . . . , l. define gadget graph GS .
create vertices cj dj 1 j m, one pair clause S. Join cj dj .
connect cj vertex ui,r iff clause Cj contains r th occurrence ui S. Similarly,
connect cj vertex ui,r iff clause Cj contains r th occurrence ui S.
illustrate, let = C1 C2 C3 C4 C5 C6 C7 C8 , C1 = (u1 u2 u3 ),
C2 = (u1 u2 u3 ), C3 = (u1 u2 u4 ), C4 = (u2 u3 u4 ), C5 = (u1 u3 u4 ),
C6 = (u1 u2 u4 ), C7 = (u2 u3 u4 ), C8 = (u1 u3 u4 ). definition,
instance 3-SAT. gadget graph GS given Figure 2.
Since literal occurs often negation, clause three literals,
number clauses must even. Hence, = 2k integer k 1.
instance S, define set XS 18k vertices corresponding teams league
X. define another set YS , 3 vertices (labelled p, q, r), place
96

fiScheduling Bipartite Tournaments Minimize Total Travel Distance

Figure 2: gadget graph GS instance S.
6k teams three vertices. create 36k-team league, 18k teams
X . weight edge correspond distance
teams located vertices. Using gadget graph GS , define edge
weights way satisfiable iff solutions BTTP BTTP* total
distance = (k) = 96k2 (2900k2 + 375k + 11). establish desired
polynomial-time reductions 3-SAT.
first define XS . Let C = {c1 , c2 , . . . , c2k } = {d1 , d2 , . . . , d2k },
set vertices corresponding gadget graph GS . Let U set 6k
vertices form ui,r ui,r appear GS , let B respectively set
vertices form ai,r bi,r appear GS . Finally, present two additional
sets, E = {e1 , e2 , . . . , ek } F = {f1 , f2 , . . . , fk }, matched vertices
U cycle cover.
define XS = B C E F U . Hence, |XS | = |A| + |B| + |C| + |D| + |E| +
|F | + |U | = 3k + 3k + 2k + 2k + k + k + 6k = 18k.
defined XS , define edge weights connecting pair vertices
XS , thus producing complete graph 18k vertices. weight edge
function k. readability, express weight function z,
z := 20k + 1. edge complete graph, assign weight set
{z 2 , z 2 + z, 2z 2 1} follows:
(1) weight z 2 given every edge appears gadget graph GS , 6k2
edges U E, k edges connecting ei fi (for 1 k).
(2) weight z 2 + z given 6k2 edges U F , 6k edges connecting
B common neighbour U , 6k edges connecting U
common neighbour C.
(3) weight 2z 2 1 given every edge.
create inter-league tournament 36k total teams. First, assign
18k teams league X 18k vertices graph XS , distance
97

fiHoshino & Kawarabayashi

home venues two teams edge weight corresponding two vertices
complete graph.
Let YS = {p, q, r}. define 18k teams league follows: place 6k teams
point p, 6k teams point q, 6k teams point r.
Therefore, |XS YS | = 18k + 3. extend complete graph 18k vertices
include three additional vertices. assign edge weight connecting pair
inter-league vertices, read matrix given Table 3.
aA
bB
cC
dD
eE
f F
uU

p YS
z2
z2
2
2z 1
z2
2
2z 1
z2
2
z +z

q YS
z2 + z
2z 2 1
z2
2
2z 1
z2 + z
z2
2
z + 2z

r YS
2z 2 1
z2 + z
z2 + z
z2
z2
2z 2 1
z 2 + 2z

Table 3: Weights edges connecting XS YS .
example, edge ci p given weight 2z 2 1, = 1, 2, . . . , 2k.
repeat process 7 3 = 21 pairs connecting vertex XS =
B C E F U vertex YS = {p, q, r}.
Finally, let weights edges pq, pr, qr 2z 2 1. result,
created complete graph vertex set XS YS , assigned weight
edge. Moreover, weight edge appears set {z 2 , z 2 + z, z 2 + 2z, 2z 2 1},
z = 20k + 1. versions TTP require teams located points
satisfying Triangle Inequality, chosen weights inter-league variant
BTTP ensure Triangle Inequality holds triplet points XS YS .
partition 18k vertices XS groups cardinality three
attach {p, q, r} = YS produce union cycles length 4.
formally, define following:
Definition 1. YS , y-rooted 4-cycle-cover union cycles length
4, every cycle contains y, cycle contains vertex YS \{y}, every
vertex XS appears exactly one cycle.

Figure 3: p-rooted 4-cycle-cover 18 vertices set XS .
98

fiScheduling Bipartite Tournaments Minimize Total Travel Distance

illustrate, Figure 3 gives p-rooted 4-cycle-cover |XS | = 18. definition
motivated tournament construction, show total travel distance
minimized creating uniform schedule team takes maximum number
three-game road trips play 18k away games. case 6k teams YS
located vertex p, 6k three-game road trips correspond 6k 4-cycles
minimum weight p-rooted 4-cycle-cover. example, p-u1,1 -c5 -d5 -p appears one
6k cycles, team YS located vertex p play three consecutive road games
tournament teams XS located u1,1 , c5 , d5 .
total distance traveled team YS bounded sum
edge weights minimum weight y-rooted 4-cycle-cover.
Definition 2. define three special types cycles may appear p-rooted 4-cyclecover.
(1) (p, a, u, b, p)-cycle 4-cycle vertices p, a, u, b order, p YS ,
A, u U , b B, au ub edges gadget graph GS .
(2) (p, u, c, d, p)-cycle 4-cycle vertices p, u, c, order, p YS ,
u U , c C, D, uc cd edges gadget graph GS .
(3) (p, u, e, f, p)-cycle 4-cycle vertices p, u, e, f order, p YS ,
u U , e E, f F , e f index (i.e., ei fi
1 k.)
example, instance whose gadget graph illustrated Figure 2, p-a1,2 u1,1 -b1,1 -p (p, a, u, b, p)-cycle, p-a1,2 -u1,1 -b4,2 -p not. Similarly, p-u4,3 -c8 -d8 -p
(p, u, c, d, p)-cycle, p-u4,3 -c7 -d7 -p not.
Following convention TTP (Easton, Nemhauser, & Trick, 2002), define
ILBt individual lower bound team t. value represents minimum
possible distance traveled team order complete games
constraints BTTP, independent teams schedules. definition,
team located YS , value ILBt minimum weight y-rooted
4-cycle-cover.
Similarly, define league lower bound LLBT minimum possible distance
traveled teams league , tournament lower bound LB
minimum possible distance traveled teams leagues. note following
trivial inequalities:

LLBX

LB LLBX + LLBY
X
X

ILBt , LLBY
ILBt .
tX

tY

definition, solution BTTP tournament schedule whose total travel distance
LB.
definitions need complete proof NP-completeness
BTTP BTTP*. create inter-league tournament 18k teams
XS 18k teams YS (with one-third teams vertex YS ),
99

fiHoshino & Kawarabayashi

show exists distance-optimal uniform tournament total distance
(k) = 96k2 (2900k2 + 375k + 11) iff satisfiable. establish polynomialtime reduction 3-SAT, since transformations construction clearly
polynomial.
desired result follow next four lemmas. lemma, let KS
complete graph 18k + 3 vertices XS YS , edge weights described
construction. interested reader, proofs three lemmas appear
Appendix A.
Lemma 1. following statements equivalent:
(i) = C1 C2 . . . C2k satisfiable.
(ii) exists p-rooted 4-cycle-cover KS exactly 3k (p, a, u, b, p)-cycles, 2k
(p, u, c, d, p)-cycles, k (p, u, e, f, p)-cycles.
Lemma 2. following statements equivalent:
(i) p-rooted 4-cycle-cover KS exactly 3k (p, a, u, b, p)-cycles, 2k (p, u, c, d, p)cycles, k (p, u, e, f, p)-cycles.
(ii) p-rooted 4-cycle-cover KS total edge weight k(24z 2 + 3z).
Lemma 3. Let ILBy minimum total edge weight y-rooted 4-cycle-cover KS .


= p
k(24z 2 + 3z)
ILBy =
k(24z 2 + 20z)
= q

k(24z 2 + 19z)
= r

Let us illustrate three lemmas specific example. Let = C1 C2 C3
C4 C5 C6 C7 C8 instance 3-SAT whose gadget graph GS presented
Figure 2. Recall defined C1 = (u1 u2 u3 ), C2 = (u1 u2 u3 ), C3 = (u1 u2 u4 ),
C4 = (u2 u3 u4 ), C5 = (u1 u3 u4 ), C6 = (u1 u2 u4 ), C7 = (u2 u3 u4 ),
C8 = (u1 u3 u4 ).
Suppose satisfiable, i.e., function : {u1 , u2 , u3 , u4 } {TRUE, FALSE}
clause Ci evaluates TRUE 1 8. symmetry, may
assume without loss (u4 ) TRUE. clauses C6 , C7 , C8 , see
1 3, (ui ) must TRUE FALSE. former, clause C2 FALSE,
latter, clause C1 FALSE. Therefore, satisfiable.
Since satisfiable, Lemma 1, exist p-rooted 4-cycle-cover
KS 12 (p, a, u, b, p)-cycles, 8 (p, u, c, d, p)-cycles, 4 (p, u, e, f, p)-cycles.
Lemma 2 Lemma 3, minimum weight p-rooted 4-cycle-cover KS strictly
larger 4(24z 2 + 3z).
show (non-satisfiable) instance cannot yield graph KS forming
distance-optimal inter-league tournament, satisfiable instance indeed does.
defined special 4-cycles rooted p (e.g. (p, a, u, b, p)-cycles), similarly define 4-cycles rooted q r. Lemma 3, lower bound ILBq occurs
q-rooted 4-cycle-cover consists 3k (q, u, b, a, q)-cycles, 2k (q, c, d, u, q)-cycles, k
100

fiScheduling Bipartite Tournaments Minimize Total Travel Distance

(q, f, u, e, q)-cycles, total edge weight 3k(4z 2 + 4z) + 2k(4z 2 + 3z) + k(4z 2 + 2z) =
k(24z 2 + 20z). lower bound ILBr occurs r-rooted 4-cycle-cover consists 3k
(r, b, a, u, r)-cycles, 2k (r, d, u, c, r)-cycles, k (r, e, f, u, r)-cycles, total edge weight
3k(4z 2 + 4z) + 2k(4z 2 + 2z) + k(4z 2 + 3z) = k(24z 2 + 19z). apply information
following lemma constructing distance-optimal bipartite tournament.
Lemma 4. satisfiable, exists uniform
schedule (i.e., solution
P
BTTP well BTTP*) whose total travel distance
ILBt = k2 (696z 2 + 408z 48) =
2
2
96k (2900k + 375k + 11).
Proof. Lemma 1, satisfiable, exists p-rooted 4-cycle-cover KS
exactly 3k (p, a, u, b, p)-cycles, 2k (p, u, c, d, p)-cycles, k (p, u, e, f, p)-cycles. Consider
p-rooted 4-cycle-cover. relabel teams XS follows:
First let {x0 , x1 , x2 }, {x3 , x4 , x5 }, . . . , {x9k3 , x9k2 , x9k1 } vertices 3k
(p, a, u, b, p)-cycles, x3i A, x3i+1 U , x3i+2 B 0 3k 1.
let {x9k , x9k+1 , x9k+2 }, {x9k+3 , x9k+4 , x9k+5 }, . . . , {x15k3 , x15k2 , x15k1 }
vertices 2k (p, u, c, d, p)-cycles, x3i U , x3i+1 C, x3i+2
3k 5k 1.
Finally, let {x15k , x15k+1 , x15k+2 }, {x15k+3 , x15k+4 , x15k+5 }, . . . , {x18k3 , x18k2 , x18k1 }
vertices k (p, u, e, f, p)-cycles, x3i U , x3i+1 E, x3i+2 F
5k 6k 1.
explain proof clearly, use relabeling teams XS , letting vertex xi 0 18k 1. also relabel teams YS ,
{p0 , p1 , . . . , p6k1 } teams p, {q0 , q1 , . . . , q6k1 } teams q,
{r0 , r1 , . . . , r6k1 } teams r.
Since every team plays two games 18k teams league,
tournament 36k time slots. build double round-robin bipartite tournament
teams league play home games slots (i.e., schedule
uniform.) Specifically, team XS play three consecutive home games followed
three consecutive road games repeat pattern 6k times. Similarly, team
YS play three consecutive road games followed three consecutive home games
repeat pattern end tournament. Given way constructed
edge weights, natural way construct distance-optimal tournament,
team takes trips possible.
Lemma 3, determined value ILBv v YS = P Q R.
ILBpi = k(24z 2 + 3z), ILBqi = k(24z 2 + 20z), ILBri = k(24z 2 + 19z),
0 6k 1. Therefore, LLBYS 6k2 (24z 2 + 3z) + 6k2 (24z 2 + 20z) + 6k2 (24z 2 + 19z) =
6k2 (72z 2 + 42z).
determine value ILBt XS = B C E F U . Every
team XS plays road game 18k teams YS , 6k teams located
points p, q, r. Team must make least 6k
3 = 2k trips p, q, r, since
maximum length road trip three games. Therefore, ILBt 2k(Dt,p +Dt,q +Dt,r ),
Dt,v distance XS YS choices y. Note equality
occur, specifically road trips team scheduled efficient way,
trip consisting three consecutive games three teams located
point.
101

fiHoshino & Kawarabayashi

Table 3, determine ILBt = 2k(Dt,p + Dt,q + Dt,r ) = 4k(4z 2 + z 1)
B C E. Similarly, ILBt = 4k(4z 2 1) F , ILBt = 4k(3z 2 + 5z)
U . Thus,
LLBXS
4k(4z 2 + z 1)(|A| + |B| + |C| + |E|) + 4k(4z 2 1)(|D| + |F |) + 4k(3z 2 + 5z)(|U |)

= 4k(4z 2 + z 1)(3k + 3k + 2k + k) + 4k(4z 2 1)(2k + k) + 4k(3z 2 + 5z)(6k)

= 36k2 (4z 2 + z 1) + 12k2 (4z 2 1) + 24k2 (3z 2 + 5z)

= k2 (264z 2 + 156z 48).

P
Therefore, LB LLBXS + LLBYS
ILBt = k2 (264z 2 + 156z 48) + 6k2 (72z 2 +
2
2
42z) = k (696z + 408z 48). complete proof, suffices construct tournament
teams
distance matches individual lower bound.
P total travel
prove LB =
ILBt = k2 (696z 2 + 408z 48).
0 6k 1 0 j 6k 1, determine opponent teams pi , qi ,
ri time slots 6j + 1, 6j + 2, 6j + 3, 6j + 4, 6j + 5, 6j + 6. Table 4, provide
schedule games slots 6j + 1, 6j + 2, 6j + 3, teams XS play home
teams YS play road. table, function f (i, j) always reduced
modulo 18k, x18k+z := xz 0 z 18k 1.
Game
pi
qi
ri

6j + 1
x3(i+j)+0
x3(i+j)+1
x3(i+j)+2

6j + 2
x3(i+j)+1
x3(i+j)+2
x3(i+j)+0

6j + 3
x3(i+j)+2
x3(i+j)+0
x3(i+j)+1

Game
pi
qi
ri

6j + 1
x3(i+j)+0
x3(i+j)+2
x3(i+j)+1

6j + 2
x3(i+j)+1
x3(i+j)+0
x3(i+j)+2

6j + 3
x3(i+j)+2
x3(i+j)+1
x3(i+j)+0

Table 4: left table lists schedule matches j satisfy + j
{0, 1, . . . , 5k 1} (mod 6k), right table lists schedule j
satisfy + j {5k, 5k + 1, . . . , 6k 1} (mod 6k).
Fix i. construction, team pi , qi , ri play {x0 , x1 , . . . , x18k1 }
road exactly once. fix j. time slot 6j + k (with 1 k 3), team XS
appears exactly once, playing unique opponent YS . teams schedule corresponds
rooted 4-cycle-cover. labeling scheme, 4-cycle-cover team pi consists
3k (p, a, u, b, p)-cycles, 2k (p, u, c, d, p)-cycles k (p, u, e, f, p)-cycles. Similarly,
4-cycle-cover team qi consists 3k (q, u, b, a, q)-cycles, 2k (q, c, d, u, q)-cycles,
k (q, f, u, e, q)-cycles. Finally, 4-cycle-cover team ri consists 3k (r, b, a, u, r)cycles, 2k (r, d, u, c, r)-cycles, k (r, e, f, u, r)-cycles. Therefore, team YS plays
6k road trips total travel distance equal minimum weight
4-cycle-cover rooted vertex, definition equal teams individual
lower bound. Thus, constructed schedule LLBYS = 6k2 (72z 2 + 42z).
construct half schedule, teams YS play home
teams XS play road. much simpler construction. example,
one way build half schedule match triplet teams XS (e.g.
{x0 , x1 , x2 }) triplet teams vertex YS (e.g. {p0 , p1 , p2 }),
three consecutive slots games two triplets home venues
102

fiScheduling Bipartite Tournaments Minimize Total Travel Distance

teams league YS . Repeating process, ensure 6k triplets
XS play 6k triplets YS via three-game road trips. Thus, schedule satisfies
LLBXS = k2 (264z 2 + 156z 48).
required putting schedules together ensure no-repeat rule,
simple matter given flexibility constructing half
tournament schedule.
Therefore, completed
bipartite tournament
Pour proof. 2If satisfiable,
2
teams XS YS LB = ILBt = k (696z +408z48). Recalling z = 20k+1,
conclude LB = 96k2 (2900k2 + 375k + 11).
illustrate preceding proof, Table 5 gives distance-optimal schedule case
k = 1, 18 teams league. present schedule teams YS since
immediately derive schedule teams XS table. always,
home games marked bold.
Game
p0
q0
r0
p1
q1
r1
..
.
p5
q5
r5

1
x0
x1
x2
x3
x4
x5
..
.
x15
x17
x16

2
x1
x2
x0
x4
x5
x3
..
.
x16
x15
x17

3
x2
x0
x1
x5
x3
x4
..
.
x17
x16
x15

4
x0
x6
x12
x1
x7
x13
..
.
x5
x11
x17

5
x2
x8
x14
x0
x6
x12
..
.
x4
x10
x16

6
x1
x7
x13
x2
x8
x14
..
.
x3
x9
x15

7
x3
x4
x5
x6
x7
x8
..
.
x0
x1
x2

8
x4
x5
x3
x7
x8
x6
..
.
x1
x2
x0

9
x5
x3
x4
x8
x6
x7
..
.
x2
x0
x1

10
x3
x9
x15
x4
x10
x16
..
.
x1
x7
x13

11
x5
x11
x17
x3
x9
x15
..
.
x2
x8
x14

12
x4
x10
x16
x5
x11
x17
..
.
x0
x6
x12

...
...
...
...
...
...
...
..
.
...
...
...

...
...
...
...
...
...
...
..
.
...
...
...

31
x15
x17
x16
x0
x1
x2
..
.
x12
x13
x14

32
x16
x15
x17
x1
x2
x0
..
.
x13
x14
x12

33
x17
x16
x15
x12
x0
x1
..
.
x14
x12
x13

34
x9
x15
x3
x10
x16
x4
..
.
x7
x13
x1

35
x11
x17
x5
x9
x15
x3
..
.
x8
x14
x2

36
x10
x16
x4
x11
x17
x5
..
.
x6
x12
x0

Table 5: distance-optimal inter-league tournament 18 teams league.
provided lemmas, prove main theorem paper.
Theorem 1. BTTP BTTP* NP-complete.
Proof. Let instance 3-SAT 2k clauses, create sets XS YS , edge
weights described construction. Consider inter-league tournament
18k teams XS 18k teams YS (with one-third teams vertex
YS ).
Lemma 4, satisfiable, exists uniform double round-robin bipartite
tournament total distance 96k2 (2900k2 + 375k + 11). definition,
tournament feasible solution BTTP BTTP*. prove converse.
Let (k) = 96k2 (2900k2 + 375k + 11). Consider inter-league tournament P

36k teams total travel distance (k). Lemma 4, (k) =
ILBt .
Hence, every team XS YS must travel shortest possible distance ILBt play
games. Lemma 3, implies every team located p YS must travel
distance ILBp = k(24z 2 + 3z).
Lemma 2, team p YS travels distance k(24z 2 + 3z), graph KS
must contain exactly 3k (p, a, u, b, p)-cycles, 2k (p, u, c, d, p)-cycles, k (p, u, e, f, p)-cycles.
Lemma 1, occurs iff satisfiable.
Therefore, constructed double round-robin bipartite tournament KS 36k
teams distance matrix DS solutions BTTP BTTP* total
103

fiHoshino & Kawarabayashi

distance (k) iff instance 2k clauses satisfiable. establishes desired
polynomial-time reduction 3-SAT, proving NP-hardness BTTP BTTP*.
Finally, note problems clearly NP, since distance traveled
teams calculated polynomial time. Therefore, conclude BTTP BTTP*
NP-complete.
illustrate difference BTTP BTTP*, provide concrete illustration case n = 3. Let teams X = {x1 , x2 , x3 } = {y1 , y2 , y3 }.
Figure 4, teams located Cartesian plane, x1 x2 represent
point, y1 y2 represent point, non-negative distances a, b, c satisfy
Pythagorean equation a2 + b2 = c2 .

Figure 4: Illustration BTTP case n = 3.

straightforward show ILBx1 = ILBx2 = ILBx3 = + b + c, ILBy1 =
ILBy2 = 4a ILBy3 = 2a + 2c. Hence, LB LLBX + LLBY (3a + 3b + 3c) + (10a +
2c) = 13a + 3b + 5c.
order LB = 13a + 3b + 5c, teams X must play three-game
road stand consecutive games y1 y2 , teams must
play three-game road stand consecutive games x1 x2 . One quickly
show scenario impossible, nearly-best schedule achieved
making either y1 y2 take extra trip, adding 2a total distance. Hence,
solution BTTP must distance least 15a + 3b + 5c.
BTTP*, LB 16a + 4b + 4c since LLBX = 4a + 4b + 2c LLBY =
12a + 2c uniform schedule. problems, justify optimality presenting
feasible tournament satisfying stated tournament lower bounds. presented
Table 6.
Team
x1
x2
x3
y1
y2
y3

1
y1
y2
y3
x1
x2
x3

2
y2
y3
y1
x3
x1
x2

3
y3
y1
y2
x2
x3
x1

4
y1
y2
y3
x1
x2
x3

5
y2
y3
y1
x3
x1
x2

6
y3
y1
y2
x2
x3
x1

Team
x1
x2
x3
y1
y2
y3

1
y1
y2
y3
x1
x2
x3

2
y3
y1
y2
x2
x3
x1

3
y2
y3
y1
x3
x1
x2

4
y1
y2
y3
x1
x2
x3

5
y3
y1
y2
x2
x3
x1

6
y2
y3
y1
x3
x1
x2

Table 6: Solutions BTTP* BTTP, total distance 16a+4b+4c 15a+3b+5c,
respectively.

104

fiScheduling Bipartite Tournaments Minimize Total Travel Distance

example, solution BTTP requires 25 trips, one trip solution
BTTP*, yet tournament lower bound reduced + b c > 0. see
concluding section, many examples solution n = 3 BTTP
requires 24 trips.
illustrate example case n = 6, consider 12-team league six
teams X . Place three points A, B, C equally spaced around unit circle,
4ABC equilateral. Place {x1 , x2 } A, {x3 , x4 } B, {x5 , x6 } C.
place {y1 , y2 , . . . , y6 } centre circle. best lower bound ILByj = 6
occurs yj plays two-game road trips {x1 , x2 }, {x3 , x4 }, {x5 , x6 } pairs rather

three-game road trips {x1 , x2 , x3 } {x4 , x5 , x6 }, total distance
4 + 2 3 > 6. clearly best lower bound ILBxi = 4 occurs xi plays three-game
road trips teams , making two trips centre circle.
Table 7 provides distance-optimal schedule uniform, thus proving
simple example, solution BTTP BTTP*. However, note
unlike proof Theorem 1, 12-team scenario, best schedule requires 102 total
trips, six fewest possible number total trips.
x1
x2
x3
x4
x5
x6
y1
y2
y3
y4
y5
y6

1
y1
y2
y3
y4
y5
y6
x1
x2
x3
x4
x5
x6

2
y2
y1
y4
y3
y6
y5
x2
x1
x4
x3
x6
x5

3
y1
y2
y3
y4
y5
y6
x1
x2
x3
x4
x5
x6

4
y2
y3
y1
y5
y6
y4
x3
x1
x2
x6
x4
x5

5
y3
y1
y2
y6
y4
y5
x2
x3
x1
x5
x6
x4

6
y4
y3
y6
y5
y2
y1
x6
x5
x2
x1
x4
x3

7
y3
y4
y5
y6
y1
y2
x5
x6
x1
x2
x3
x4

8
y4
y5
y6
y1
y2
y3
x4
x5
x6
x1
x2
x3

9
y5
y6
y4
y2
y3
y1
x6
x4
x5
x3
x1
x2

10
y6
y4
y5
y3
y1
y2
x5
x6
x4
x2
x3
x1

11
y5
y6
y1
y2
y3
y4
x3
x4
x5
x6
x1
x2

12
y6
y5
y2
y1
y4
y3
x4
x3
x6
x5
x2
x1

Table 7: Solution BTTP BTTP* scenario n = 6.
provided simple illustrations n = 3 n = 6, analyze BTTP two
professional sports leagues, namely Nippon Professional Baseball league (with n = 6)
National Basketball Association (with n = 15).

4. Japanese Baseball
Nippon Professional Baseball (NPB) Japans largest professional sports league.
NPB, teams split two leagues six teams, team playing 120 intraleague 24 inter-league games regular season. intra-league problem
analyzed recently authors (Hoshino & Kawarabayashi, 2011c), developed
multi-round generalization TTP based Dijkstras shortest path algorithm
applied produce distance-optimal schedule reducing total travel distance
60000 kilometres (a 25% reduction) compared 2010 NPB intra-league schedule
(Hoshino & Kawarabayashi, 2011d). Given Japan small island country, 60000
kilometre reduction represents significant amount.
105

fiHoshino & Kawarabayashi

consider inter-league problem, six teams NPB Pacific
League play four games six teams NPB Central League, one
two-game set played home Pacific League team, two-game set
played home Central League team. inter-league games take place
five-week stretch mid-May mid-June, intra-league games occurring
period. Thus, NPB inter-league scheduling problem precisely BTTP,
case n = 6.

Figure 5: Location 12 teams NPB.
locations teams home stadium marked Figure 5. readability,
label team follows: Pacific League teams p1 (Fukuoka), p2 (Orix), p3
(Saitama), p4 (Chiba), p5 (Tohoku), p6 (Hokkaido), Central League teams c1
(Hiroshima), c2 (Hanshin), c3 (Chunichi), c4 (Yokohama), c5 (Yomiuri), c6 (Yakult).
actual 12 12 NPB distance matrix provided Appendix B.
solve BTTP NPB, producing inter-league schedule requiring 42950
kilometres total travel, representing 16% reduction compared 51134 kilometres
traveled teams 2010 inter-league schedule (Hoshino & Kawarabayashi,
2011a). accomplish this, present two powerful reduction heuristics. motivate
heuristics, first require several key definitions.
X , let St set possible schedules played team
satisfying at-most-three each-venue constraints. Let St possible schedule
team t. , list opponents six road sets, ignore home
sets, since determine total distance traveled team road sets.
give example, feasible schedule x1 Sx1 case n = 6:
x1

1
y1

2
y6

3


4


5
y3

6
y5

7
y4

8


9


10


11
y2

12


following team schedule x1 , represents home set played x1
unique opponent . Note x1 satisfies at-most-three each-venue constraints.
Let = (x1 , x2 , . . . , xn , y1 , y2 , . . . , yn ), St X . Since
road sets X correspond home sets vice-versa, suffices list time
slots opponents n road sets , since uniquely determine
full schedule 2n sets every team X , thus producing inter-league tournament
106

fiScheduling Bipartite Tournaments Minimize Total Travel Distance

schedule . note feasible solution BTTP iff team plays unique
opponent every time slot, team schedule violates no-repeat constraint.
section, frequently refer team schedules tournament schedules .
context clear whether schedule individual team X ,
2n teams X .
before, define ILBt individual lower bound team t, minimum possible
distance traveled team order complete 2n sets.
St , let d(t ) integer d(t )+ILBt equals total distance
traveled team playing schedule . definition, d(t ) 0.
= (x1 , . . . , xn , y1 , . . . , yn ), define
X
d() =
d(t ).
tXY

P

Since
ILBt fixed, optimal solution BTTP schedule d()
minimized. motivation function d().
subset St St , define lower bound function
B(St ) = min d(t ).
St

St = St , B(St ) = 0 definition ILBt . subset St , define |St |
cardinality.
example, consider n = 6 instance Table 7, located six teams
league X two teams assigned vertex equilateral triangle.
mentioned end Section 3, ILBy1 = 6, equality occurring iff y1 plays
two-set road trips {x1 , x2 }, {x3 , x4 }, {x5 , x6 }. let Sy1 restriction
Sy1 subset schedules y1 starts three consecutive roadsets
teams x1 , x2 , x3
.
schedule must total distance 4+ 2 3, implying

B(Sy1 ) = 4 + 2 3 ILBy1 = 2 3 2 > 0.
n multiple 3, define team set R3t subset schedules
St n road sets occur n3 blocks three (i.e., team takes n3 three-set road
trips). example, Table 5 (which n = 18), every team plays schedule R3t .
Finally, define global constraint fixes subset matches, St
subset schedules St consistent global constraint.
example, simple constraint forces y2 play x1 home time slot
3, Sx1 would consist team schedules slot 3 road set y2 .
much complex global constraint (e.g. number fixed matches
large), |St | significantly less |St |.
illustrate concept, consider n = 6 instance global constraint
y1 starts three consecutive road sets teams x1 , x2 , x3 (in
order). One show 34 valid home-road patterns Sy1 , including
RRR-HHH-RRR-HHH RRR-H-R-HH-R-HH-R-H. home-road pattern,
3! = 6 ways assign {x4 , x5 , x6 } last three road sets. Thus, |Sy1 | = 343! = 204,
significantly less |Sy1 | shown equal 616 6! = 443520.
simple notion global constraints inspires first result, powerful reduction
heuristic drastically cuts computation time.
107

fiHoshino & Kawarabayashi

Proposition 1. Let fixed positive integer. global constraint , define
X ,
(
)
X



Zt = St : d(t ) + B(St )
B(Su ) .
uXY

= (x1 , . . . , xn , y1 , . . . , yn ) feasible tournament schedule consistent
d() , X , team ts schedule appears Zt .
Proof. Consider tournament schedules consistent . d() ,

prove. assume
. Letting
P schedule satisfies
P d()
P nothing
),
), d() =
d(
)

B(S
Q =
B(S
u
u
u
uXY
uXY
uXY
Q.
Zt , Zt St implying d(t ) B(St ). suppose exists
v X v
/ Zv . Since v consistent , v Sv d(v ) >


+ B(Sv ) Q B(Sv ). contradiction,
X
d() = d(v ) +
d(u )
uXY,u6=v

> (M + B(Sv ) Q) +
= (M +

B(Sv )

X

B(Su )

uXY,u6=v

Q) + (Q B(Sv )) = M.

Hence, = (x1 , . . . , xn , y1 , . . . , yn ) feasible tournament schedule consistent
d() , Zt X .

Proposition 1 shows perform reduction prior propagation, may
applicable problems. apply proposition, reduce BTTP k
scenarios scenario six home sets four Pacific League teams
pre-determined. Expressing scenarios global constraints 1 , 2 , . . . , k ,
fixes 24 72 total matches.
every , determine Zcj Central League teams setting low
threshold , show |Zcj | considerably smaller |Scj |, thus reducing
search space amount quickly analyzed. there, run simple
six-loop generates 6-tuples (c1 , c2 , c3 , c4 , c5 , c6 ) appear feasible
schedule d() . Proposition 1, cj Zcj 1 j 6. list
possible 6-tuples, quickly find optimal schedule corresponds
solution BTTP.
present result works case n = 6, two teams one
league located quite far 10 teams, forcing distance-optimal schedule
particular structure.
Proposition 2. Let fixed positive integer, define St = {t St : d(t ) }.
x
Suppose exist two teams xi , xj X = {x1 , x2 , . . . , x6 } Sxi R3xi , Sxj R3 j ,

team yk , every schedule Syk property yk plays road
sets xi xj two consecutive time slots. = (x1 , . . . , x6 , y1 , . . . , y6 )
feasible tournament schedule d() St , team schedules
108

fiScheduling Bipartite Tournaments Minimize Total Travel Distance

xi xj home-road pattern HH-RRR-HH-RRR-HH; moreover, teams
six home slots must following structure permutation (a, b, c, d, e, f )
{1, 2, 3, 4, 5, 6}:
xi
xj

1
ya
yb

2
yb
ya

3



4



5



6
yc
yd

7
yd
yc

8



9



10



11
ye
yf

12
yf
ye

Proof. first note xi xj structure, satisfy given
x
conditions since xi R3xi , xj R3 j , every team yk plays road sets xi
xj two consecutive time slots. example, yd plays road sets xj slot 6
xi slot 7. prove xi xj must structure.
team xt X time slot [1, 12], define O(xt , s) opponent
team xt set s. define O(xt , s) xt playing home; sets xt
plays road, O(xt , s) undefined.
Since xi Sxi Sxi R3xi , four possible cases consider:
(1) xi plays set 1 home, sets 2 4 road.
(2) xi plays sets 1 2 home, sets 3 5 road.
(3) xi plays sets 1 3 home, sets 4 6 road.
(4) xi plays sets 1 3 road, set 4 home.
examine cases one one. each, suppose exists feasible schedule
satisfying given conditions. finish case (2).
(1), let O(xi , 1) = ya . O(xj , 2) = ya , since ya must play road sets xi
x
xj consecutive time slots. Since xj R3 j xj plays home set 2, xj must
also play home set 1. Thus, O(xj , 1) = yb yb , forces O(xi , 2) = yb .
contradiction xi plays set 2 road.
(3), let O(xi , 1) = ya , O(xi , 2) = yb , O(xi , 3) = yc . O(xj , 2) = ya
O(xj , 4) = yc . Either O(xj , 1) = yb O(xj , 3) = yb . either case, violate at-mostx
three constraint condition xj R3 j .
(4), team xi starts three-set road trip. order satisfy at-most-three
constraint, xi must pattern RRR-HHH-RRR-HHH. reduces case
(3), read schedule backwards, letting O(xi , 12) = ya , O(xi , 11) = yb ,
O(xi , 10) = yc , applying argument previous paragraph.
(2), let O(xi , 1) = ya O(xi , 2) = yb . O(xj , 2) = ya O(xj , 1) = yb .
O(xj , 3) = yc yc , O(xi , 4) = yc , forcing xi play single road set slot 3.
Thus, xj must play road set 3, therefore also sets 4 5. Hence,
xi xj start two home sets followed three road sets. Since case
remaining, symmetry xi xj must end two home sets preceded three road
sets. Thus, two teams must pattern HH-RRR-HH-RRR-HH.
order yk play road sets xi xj two consecutive time
slots, must O(xi , 6) = O(xj , 7), O(xi , 7) = O(xj , 6), O(xi , 11) = O(xj , 12),
O(xi , 12) = O(xj , 11). completes proof.
109

fiHoshino & Kawarabayashi

use Proposition 2 solve BTTP, since teams p5 p6 located quite far
ten teams (see Figure 5). heuristic isolating two teams finding
common structure significantly reduces search space enables us solve BTTP
12-team NPB hours rather weeks.
applying results, require weeks computation time multiple
processors. two heuristics, BTTP solved less ten hours
single laptop. code written Maple compiled using Maplesoft 13 using
single Toshiba laptop Windows single 2.10 GHz processor 2.75 GB
RAM.
Table 8 presents inter-league tournament schedule solution BTTP
d() = (0 + 4 + 0 + 0 + 1 + 1) + (51 + 9 + 31 + 58 + 19 + 13) = 187.
p1
p2
p3
p4
p5
p6
c1
c2
c3
c4
c5
c6

1
c3
c5
c4
c2
c1
c6
p5
p4
p1
p3
p2
p6

2
c5
c3
c2
c4
c6
c1
p6
p3
p2
p4
p1
p5

3
c1
c2
c6
c5
c4
c3
p1
p2
p6
p5
p4
p3

4
c3
c1
c5
c4
c6
c2
p2
p6
p1
p4
p3
p5

5
c2
c3
c4
c6
c5
c1
p6
p1
p2
p3
p5
p4

6
c1
c6
c3
c5
c2
c4
p1
p5
p3
p6
p4
p2

7
c6
c1
c5
c3
c4
c2
p2
p6
p4
p5
p3
p1

8
c2
c4
c1
c6
c3
c5
p3
p1
p5
p2
p6
p4

9
c4
c5
c3
c1
c2
c6
p4
p5
p3
p1
p2
p6

10
c5
c6
c2
c3
c1
c4
p5
p3
p4
p6
p1
p2

11
c6
c4
c1
c2
c5
c3
p3
p4
p6
p2
p5
p1

12
c4
c2
c6
c1
c3
c5
p4
p2
p5
p1
p6
p3

Table 8: Solution BTTP total distance 42950 km.
Table 8, see seven twelve teams satisfy R3t , namely c1
six Pacific League teams. However, every Central League team schedule
plays road sets p5 p6 consecutive time slots. explains d(cj )
small.
P
claim optimal solution, total distance d() + ILBt = 187 +
42763 = 42950. prove this, set = 187. Define St = {t St : d(t ) },
determine Sp5 R3p5 Sp6 R3p6 .
Define Tci Sci subset schedules ci play road sets
p5 p6 two consecutive time slots. this, show B(Tc3 ) = 153,
B(Tcj ) > = 187 j {1, 2, 4, 5, 6}. claim satisfies d() 187,
cj
/ Tcj 1 j 6.
suffices prove claim j = 3. 144 schedules Tc3 ,
belong set R3c3 . example, one schedule c3
c3

1
p

2
p2

3
p1

4
p6

5
p

6
p

7
p

8
p3

9
p4

10
p5

11
p

12
p

Suppose exists tournament schedule d() 187 c3 Tc3 .
nine possible home-road patterns p5 R3p5 (e.g. HHH-RRR-H-RRR-HH H-RRRHHH-RRR-HH), gives rise 6! = 720 possible orderings six home
110

fiScheduling Bipartite Tournaments Minimize Total Travel Distance

sets. Thus, 9 720 = 6480 ways select time slots opponents
six home sets p5 . Similarly, 6480 ways p6 . simple Maplesoft
procedure shows 140 64802 possible pairs (p5 , p6 ) consistent
least one c3 Tc3 .
140 cases, define global constraints 1 , 2 , . . . , 140 , obtained
fixing twelve home sets {p5 , p6 }. k , define j {1, 2, 4, 5, 6}
set Zcj = {cj Scjk : d(cj ) B(Tc3 ) = 34}. run six-loop compute
possible 6-tuples (c1 , c2 , . . . , c6 ) satisfying given conditions c3 Tc3
cj Zcj j 6= 3. Within twenty minutes, Maplesoft solves 140 cases returns
feasible 6-tuples appear schedule d() 187.
Therefore, , cj must play road sets p5 p6 consecutive time slots.
Thus, teams p5 p6 satisfy conditions Proposition 2. Hence, home-road pattern
p5 p6 must HH-RRR-HH-RRR-HH.
Without loss, assume p5 plays home set c1 within first six time slots;
otherwise read schedule backwards symmetry. Thus, 6!2 = 360
ways assign opponents six home sets p5 . Proposition 2, 360
arrangements uniquely determines six home sets p6 .
short calculation shows order d() = 187, teams p1 p3 must also
play six road sets two blocks three. words, p1 R3p1 p3 R3p3 .
mentioned earlier, 9 6! possible ways select six home sets p1
p3 .
Thus, 360 (9 6!) (9 6!) ways select 24 home sets played
teams {p1 , p3 , p5 , p6 }. eliminate scenarios pi pj play
ck time slot. possibilities remain, create global
constraint apply Proposition 1.
Let {1 , 2 , . . . , k } complete set global constraints derived
process, fixes 24 72 matches, corresponding home sets
{p1 , p3 , p5 , p6 }. reduction heuristic Proposition 1 allows us quickly verify
existence feasible tournament schedules consistent d() .
explain procedure, let us illustrate inter-league schedule Table 8. Let
constraint fixes 24 home sets teams p1 , p3 , p5 , p6 table.
Sc5 , defined subset schedules Sc5 consistent , consists team
schedules c5 c5 plays road sets p1 slot 2, p3 slot 7, p5 slot 11,
p6 slot 12.
find 11 schedules c5 Sc5 d(c5 ) consistent
. Furthermore, d(c5 ) {19, 41, 46, 48}, implying B(Sc5 ) = 19. Similarly,
calculate values B(Scj ).
P
P
find 6j=1 B(Spj ) = 0 6j=1 B(Scj ) = 51 + 9 + 31 + 58 + 19 + 13 = 181,
implying Zc5 = {c5 Sc5 : d(c5 ) 187 + 19 181 = 25}. Hence, Zc5 reduces
two schedules d(c5 ) = 19, including team schedule c5 Table 8.
Proposition 1, schedule consistent satisfying d() must
property Zt team t. Since |Zcj | small, calculation extremely
fast. course, |Zcj | = 0, schedule exist.
algorithm, based Propositions 1 2, runs 34716 seconds Maplesoft (just
10 hours). Maplesoft generates zero inter-league schedules d() < 187 14
111

fiHoshino & Kawarabayashi

inter-league schedules d() = 187, including schedule given Table 8. Since
made assumption p5 plays home set c1 within first six time slots,
actually twice many distance-optimal schedules reading schedule
backwards.
28 distance-optimal schedules , find (d(p1 ), d(p2 ), . . . , d(p6 )) =
(0, 4, 0, 0, 1, 1) (d(c1 ), d(c2 ), . . . , d(c6 )) = (51, 9, 31, 58, 19, 13).
Therefore, proven Table 8 optimal inter-league schedule NPB,
reducing total travel distance 8184 kilometres, 16.0%, compared 2010 NPB
schedule.

5. American Basketball
National Basketball Association (NBA) one worlds lucrative sports
leagues, four billion dollars annual revenue, average franchise value
400 million dollars. 15 teams Western Conference 15 teams
Eastern Conference. Every NBA team plays 82 regular-season games, 30
inter-league (with one home game one away game 15 teams
conference.) geographic location team provided Figure 6.

Figure 6: Map NBAs 15 Western Conference teams 15 Eastern Conference
teams.
Given NBA teams play inter-league games, consider BTTP league,
attempt find distance-optimal inter-league tournament. theoretical
problem, assume inter-league games take place consecutive stretch
regular season, done currently Japanese NPB. also enforce
constraints BTTP, including team home stand road trip lasting
3 games. note strict conditions part NBA scheduling requirement, evidenced San Antonio Spurs playing 6 consecutive home games followed
immediately 8 consecutive road games 2009-10 regular season. Furthermore,
require inter-league schedule compact, i.e., team play one
game time slot. course, compactness condition part typical NBA
schedule, one team might play five games time another team played two.
112

fiScheduling Bipartite Tournaments Minimize Total Travel Distance

determine 30 30 NBA distance matrix online website1 lists
flight distance (in statute miles) pair major cities North America.
matrix found Appendix B.
Unlike 12-team NPB could solve BTTP, appears highly unlikely
solve problem 30-team NBA. Nonetheless, generate
inter-league
P
tournament whose total distance close trivial lower bound
ILBt , grouping
leagues fifteen teams five triplets travel distance team
extremely close ILBt , minimum weight t-rooted 4-cycle-cover. this,
construct uniform tournament, i.e., feasible solution BTTP*, Western
Conference team alternates playing three away games followed three home games.
Given geographic location 30 teams, easy show teams ILBt
occurs playing fifteen away games five groups three. note
always case; give concrete example, consider variant scenario presented
end Section 3. Let points X, Y, Z equally spaced around unit circle,
4XY Z equilateral. Place {e1 , e2 } X, {e3 , e4 } , {e5 , e6 } Z. place
{w, e7 , e8 , . . . , e15 } centre circle. best lower bound ILBw = 6
occurs w plays two-game road trips {e1 , . . . , e6 } pairs rather
threegame road trips like {e1 , e2 , e3 } {e4 , e5 , e6 }, total distance 4 + 2 3 > 6.
However, NBA distance matrix, teams ILBt occurs team five
road trips, trip team plays three opponents located close other.
Thus, team wi , exists permutation lower bound
ILBwi attained playing away games fifteen Eastern Conference teams
order e(1) , e(2) , . . . , e(15) . Note permutation, total distance traveled
wi
ILBwi =

5
X
{Dwi ,e(3j2) + De(3j2) ,e(3j1) + De(3j1) ,c(3j) + De(3j) ,wi }.
j=1

five triplets {{e(3j2) , e(3j1) , e(3j) } : j = 1, 2, . . . , 5} permuted 5! ways
without changing total distance. Also, within triplet, change order
first third element retaining total. Thus, compute ILBwi
15!
simple enumeration 5!2
5 cases, done minutes using Maplesoft.
P
this, calculate P
ILBt team t, giving LLBW tW ILBt = 251795. Similarly,
LLBE tE ILBt = 266137, LB LLBW + LLBE 517932.
nearly every case, bounds ILBwi ILBei attained selecting road
trips indicated Figure 7, corresponding minimum-weight triangle packing
league. example, minimum-weight triangle packing, every Eastern Conference team makes one trip northwest, play Portland, Golden State,
Sacramento order. Similarly, every Western Conference team makes one trip
southeast, play Atlanta, Orlando, Miami order. note natural
connection minimum-weight triangle packings minimum-weight 4-cycle-covers,
remarking former generates approximation latter.
Re-label fifteen Western Conference teams five triplets occur side-by-side (i.e.,
w1 Portland, w2 Golden State, w3 Sacramento), similarly re-label Eastern
1. http://www.savvy-discounts.com/discount-travel/JavaAirportCalc.html

113

fiHoshino & Kawarabayashi

Figure 7: minimum-weight triangle packing 30 NBA teams.

Conference teams. Similar construction Table 5, build tournament
5 5 = 25 pairs inter-league triplets, team one triplet plays three
teams triplet three consecutive time slots (e.g., e1 plays {w1 , w2 , w3 }, e2
plays {w2 , w3 , w1 } e3 plays {w3 , w1 , w2 }.) construction produces schedule
Eastern Conference teams travel 286683 miles Western Conference teams travel
258443 miles, total 545126 miles.
improve bound slightly noting away teams forced
travel according triplets given Figure 7. Specifically, suppose considering
road trips Eastern Conference. Let triplets {{e(3j2) , e(3j1) , e(3j) } : j =
1, 2, . . . , 5}, permutation . triplet {e(3j2) , e(3j1) , e(3j) } travels west
three-game road trips {w1 , w2 , w3 }, {w4 , w5 , w6 }, . . . , {w13 , w14 , w15 }. Ex15!
amining 5!2
5 non-equivalent possibilities , show best permutation
= (1, 6, 12, 2, 8, 13, 3, 7, 11, 4, 10, 14, 5, 9, 15), teams {e1 , e6 , e12 } play
first three games road {w1 , w2 , w3 }, teams {e2 , e8 , e13 } play
first three games road {w4 , w5 , w6 }, on. optimal
schedule, Eastern Conference teams travel total 280294 miles. Similarly, best
possible case, Western Conference teams travel total 257497 miles.
this, produce Table 9, uniform inter-league tournament total P
distance
280294 + 257497 = 537791 miles, 3.8% trivial lower bound
ILBt .
labeling 30 teams (e.g. PT = Portland Trailblazers, MB = Milwaukee Bucks)
given Appendix B.
P
certain trivial lower bound
ILBt cannot achieved
either BTTP BTTP*, conjecture 3.8% figure reduced using
sophisticated techniques. close get? leave challenge
interested reader.
Problem 1. Determine better (best?) bounds BTTP BTTP*, 30 30 NBA
distance matrix.
114

fiScheduling Bipartite Tournaments Minimize Total Travel Distance

PT
GW
SK
LC

PS
UJ
DN
OT
SS
DM
HR
MT
MG
NH

1
MB
TR
NK
IP
WW
BC
OM
CC
AH
CU
DP
PS
CB
NN
MH

2
IP
CC
NN
CU
CB
NK
MH
DP
OM
MB
TR
WW
PS
BC
AH

3
CU
DP
BC
MB
PS
NN
AH
TR
MH
IP
CC
CB
WW
NK
OM

4
MB
CC
CB
NN
TR
MH
DP
OM
IP
BC
WW
AH
PS
CU
NK

5
CB
MB
CC
MH
NN
TR
PS
DP
WW
IP
BC
NK
OM
AH
CU

PT
GW
SK
LC

PS
UJ
DN
OT
SS
DM
HR
MT
MG
NH

16
BC
WW
IP
NK
CU
AH
MB
CO
TR
NN
MH
OM
CC
DP
PS

17
IP
BC
WW
AH
NK
CU
CC
MB
MH
TR
NN
PS
CO
OM
DP

18
WW
IP
BC
CU
AH
NK
CO
CC
NN
MH
TR
DP
MB
PS
OM

19
NK
PS
AH
NN
MB
MH
CC
CO
DP
BC
WW
IP
CU
OM
TR

20
NN
WW
OM
BC
CU
AH
DP
PS
TR
NK
CO
MB
IP
MH
CC

6
CC
CB
MB
TR
MH
NN
OM
PS
BC
WW
IP
CU
DP
NK
AH

21
BC
CO
MH
NK
IP
OM
TR
WW
CC
NN
PS
CU
MB
AH
DP

7
AH
MB
TR
OM
NK
CC
PS
IP
WW
MH
CU
BC
NN
DP
CB

22
DP
PS
OM
IP
BC
WW
CU
AH
MB
CC
CO
MH
NK
TR
NN

8
OM
IP
CC
MH
NN
DP
WW
CU
CB
AH
MB
NK
BC
TR
PS

9
MH
CU
DP
AH
BC
TR
CB
MB
PS
OM
IP
NN
NK
CC
WW

10
CU
NK
AH
CC
MB
CB
TR
MH
DP
PS
OM
WW
NN
IP
BC

11
AH
CU
NK
CB
CC
MB
NN
TR
OM
DP
PS
BC
MH
WW
IP

23
OM
DP
PS
WW
IP
BC
NK
CU
CO
MB
CC
NN
AH
MH
TR

24
PS
OM
DP
BC
WW
IP
AH
NK
CC
CO
MB
TR
CU
NN
MH

25
TR
NN
WW
DP
OM
PS
CU
BC
MB
CC
NK
AH
MH
CO
IP

26
CC
NK
CO
TR
MH
WW
IP
NN
CU
DP
BC
OM
AH
PS
MB

12
NK
AH
CU
MB
CB
CC
MH
NN
PS
OM
DP
IP
TR
BC
WW

27
DP
BC
PS
CC
AH
CO
MB
NK
IP
TR
NN
MH
OM
WW
CU

13
WW
MH
MB
CB
TR
IP
BC
OM
NK
PS
AH
DP
CC
CU
NN

28
TR
NN
MH
DP
PS
OM
BC
IP
CU
NK
AH
CO
WW
MB
CC

14
CB
OM
IP
PS
CC
CU
NK
AH
NN
WW
MH
TR
DP
MB
BC

15
PS
AH
CU
WW
DP
MB
NN
MH
BC
CB
OM
CC
TR
IP
NK

29
MH
TR
NN
OM
DP
PS
WW
BC
AH
CU
NK
CC
IP
CO
MB

30
NN
MH
TR
PS
OM
DP
IP
WW
NK
AH
CU
MB
BC
CC
CO

Table 9: close-to-optimal solution NBA BTTP*.

6. Conclusion
paper, introduced Bipartite Traveling Tournament Problem applied
two professional sports leagues Japan North America, illustrating richness
complexity bipartite tournament scheduling.
Section 4, introduced two heuristics enabled us solve BTTP n = 6
NPB. Proposition 2 applicable certain 12-team configurations satisfying
specific geometric property, note Proposition 1 general technique
applied scheduling problems. method reduction prior propagation
breaks complex problem large number scenarios, sets scenario
global constraint reduce search space. confident Proposition 1
applied complicated problems sports scheduling.
Section 5, determined algorithm produced approximate solution
BTTP n = 15 NBA. finding minimum-weight rooted 4-cycle-covers, determined trivial lower bound BTTP, method creating uniform schedule
based minimum-weight triangle packing generated close-to-optimal feasible solution. NBA inter-league problem, process produced optimality gap
3.8%. hopeful ideas abstracted refined further, leading
powerful tools tackle even harder problem instances.
115

fiHoshino & Kawarabayashi

Perhaps sports leagues BTTP applicable, professional hockey football. also expand analysis model tripartite
multipartite tournament scheduling, league divided three conferences. specific example newly-created Super 15 Rugby League, consisting
five teams South Africa, Australia, New Zealand. addition intra-country
games, team plays four games (two home two away) teams
two countries. would interesting see whether determine
distance-optimal tripartite tournament schedule using methods developed paper.
conclude motivating several interesting questions, including dealing
geometric probability extremal combinatorics, leave open problems
interested reader.
solution non-uniform BTTP required 10 hours computations. Furthermore,
able solve BTTP applying Proposition 2, whose requirements would
hold randomly-selected 12 12 distance matrix. result, require
sophisticated technique improves upon two heuristics, perhaps using methods
constraint programming integer programming, hybrid CP/IP. wonder
exists general algorithm would solve BTTP given distance matrix,
small values n n = 6, n = 7, n = 8. pose open problem.
Problem 2. Develop computational procedure (or algorithm) routinely solve
BTTP BTTP* instances n 6.
end Section 3, presented simple example (see Figure 4) illustrate
difference BTTP BTTP* case n = 3. located six points
form two sets Pythagorean triangles, showed solutions two problems
total distance 15a + 3b + 5c 16a + 4b + 4c, respectively. (a, b, c) = (3, 4, 5),
tournament lower bounds 82 84, respectively. words, relaxing
uniformity requirement, reduce optimal travel distance 84 82,
improvement 2.38%. Using elementary calculus, show particular
choice six points, percentage reduction function 2.39%, equality iff
5+3 5
b
. However, selected different set six points, could achieve better
=
8
percentage reduction? motivates following question:
Problem 3. Consider six points X = {x1 , x2 , x3 } = {y1 , y2 , y3 } Cartesian
plane. Let tournament lower bounds BTTP* BTTP, respectively.
Determine smallest constant c c possible selections six
points X .
One may conjecture order minimize tournament lower bound, must
minimize total number trips taken 2n teams. saw Table 6,
conjecture false n = 3, located six points solution BTTP*
requires 24 trips, solution BTTP requires 25 trips. However, numerous
examples (e.g. scenario Table 7) 2n points located
solution BTTP* matches BTTP. motivates following question: given
random selection 2n points, probability solutions BTTP*
BTTP identical?
116

fiScheduling Bipartite Tournaments Minimize Total Travel Distance

illustrate, consider case n = 3. quickly show exist 60 29 =
30720 feasible inter-league tournaments, 60 23 = 480 uniform. run
simulation Maplesoft, scenario, randomly select six points (x, y)
Cartesian plane, calculate 15 1 column vector pairwise distances, apply
set feasible inter-league tournaments determine distance-optimal schedule.
run simulation 100000 times, scenario, note number trips taken
optimal solution. results appear Table 10.
Trips
Scenarios

24
55800

25
33077

26
10967

27
43

28
0

29
0

Table 10: Results simulation: number trips distance-optimal tournament.
note sum total 100000, 113 scenarios ended
tie (e.g. two tournaments, one 24 trips another 26 trips,
equal total distance rounding two decimal places.)
expected, majority scenarios, six points X property
distance-optimal bipartite tournament involved 24 trips, team played three
consecutive road games. Without much difficulty, one show (Hoshino & Kawarabayashi,
2011a) forces home game slots uniform, i.e., teams league
must play home games time, team X plays three consecutive
home games followed three consecutive road games, vice-versa. Therefore, 55.8%
randomly-selected scenarios, solution BTTP* identical solution
BTTP.
simulation motivates interesting question geometric probability. Given
2n points X chosen random, probability tournament
lower bound achieved schedule consisting trips? formally define
question present open problem reader.
Problem 4. Let 2n points X = {x1 , x2 , . . . , xn } = {y1 , y2 , . . . , yn } randomly
selected Cartesian plane. Let number trips taken distance-optimal
solution BTTP, teams located X . Determine value Pn (t)
t, Pn (t) represents probability distance-optimal tournament involves
2n teams taking exactly trips.
case n = 3, appears Pn (t) = 0 23 28.
trivial show must least 24 trips, formal proof
cannot exist selection six points X plane solution BTTP
27 trips. could prove n, number total trips
distance-optimal solution bounded function f (n), would enable
us solve BTTP without enumerate feasible schedules, i.e., small fraction
would suffice. result would certainly aid solving BTTP larger n, full
enumeration feasible tournament schedules computationally laborious.
motivates final problem.
Problem 5. Consider 2n-team bipartite tournament, teams located X =
{x1 , x2 , . . . , xn } = {y1 , y2 , . . . , yn }. n, determine smallest integer f (n)
117

fiHoshino & Kawarabayashi

solution BTTP involves teams taking f (n) trips, regardless
2n teams located.

Acknowledgments
research partially supported Japan Society Promotion Science
(Grant-in-Aid Scientific Research), C & C Foundation, Kayamori Foundation,
Inoue Research Award Young Scientists.

Appendix A.
provide proof three lemmas (from Section 3), beginning Lemma 1.
Proof. First, prove (i) (ii).
satisfiable, exists function valid truth assignment, i.e.,
function (ui ) {TRUE, FALSE} 1 l ensures
clause Cj evaluates TRUE 1 j 2k. , build p-rooted 4-cycle-cover
KS exactly 3k (p, a, u, b, p)-cycles, 2k (p, u, c, d, p)-cycles, k (p, u, e, f, p)-cycles.
first identify 3k (p, a, u, b, p)-cycles. 1 l, (ui ) FALSE,
select 4-cycles form p-ai,r -ui,r -bi,r -p, r = 1, 2, . . . , r(i).
(ui ) TRUE, select 4-cycles form p-ai,r+1 -ui,r -bi,r -p, r (where
ai,r(i)+1 = ai,1 ). Repeating construction i, produce 3k (p, a, u, b, p)-cycles,
covering 6k vertices B, well 3k vertices U .
consider clause Cj . Since valid truth assignment, least one
three literals Cj evaluates TRUE. words, must exist index
ui Cj (ui ) TRUE, ui Cj (ui ) FALSE.
former case, ui Cj (ui ) TRUE, exists index r
ui,r -cj edge gadget graph GS . p-ui,r -cj -dj -p (p, u, c, d, p)-cycle.
Note ui,r previously selected (p, a, u, b, p)-cycle since (ui ) TRUE
(and vertices ui,1 , ui,2 , . . . , ui,r(i) covered earlier.)
latter case, ui Cj (ui ) FALSE, exists index r
ui,r -cj edge gadget graph GS . p-ui,r -cj -dj -p (p, u, c, d, p)-cycle.
Note ui,r previously selected (p, a, u, b, p)-cycle since (ui ) FALSE
(and vertices ui,1 , ui,2 , . . . , ui,r(i) covered earlier.)
Repeating construction j, produce 2k (p, u, c, d, p)-cycles, covering 4k
vertices C D. Note u U chosen twice since vertex U adjacent
one vertex C. Thus, 2k cycles cover set 6k vertices XS , completely
disjoint 9k vertices covered previously-constructed 3k (p, a, u, b, p)-cycles.
result, left 3k vertices XS still covered, specifically k vertices
U , E, F . vertices trivially partitioned k (p, u, e, f, p)-cycles
ensuring ej fj belong cycle 1 j k. process
complete, p-rooted 4-cycle-cover KS contain exactly 3k (p, a, u, b, p)-cycles, 2k
(p, u, c, d, p)-cycles, k (p, u, e, f, p)-cycles.
established first direction, prove (ii) (i).
118

fiScheduling Bipartite Tournaments Minimize Total Travel Distance

Consider p-rooted 4-cycle-cover KS containing exactly 3k (p, a, u, b, p)-cycles, 2k
(p, u, c, d, p)-cycles, k (p, u, e, f, p)-cycles. prove exists function
satisfying truth assignment S, (ui ) {TRUE, FALSE} 1 l.
Define a-b path path three vertices whose endpoints ai,j bi,k ,
indices i, j, k. Consider problem maximizing number vertex-disjoint a-b
paths ith gadget. One quickly see maximum packing a-b paths occurs
iff r(i) paths chosen one following trivial ways:
(a) Taking paths form ai,r , ui,r , bi,r r = 1, 2, . . . , r(i).
(b) Taking paths form ai,r+1 , ui,r , bi,r r = 1, 2, . . . , r(i).
ai,r(i)+1 = ai,1 .)

(Note:

order us cover vertices B, gadget must select a-b
paths either vertically (a) diagonally (b). Thus, p-rooted 4-cycle-cover containing
3k (p, a, u, b, p)-cycles, one following scenarios must hold true ith gadget:
(1) r = 1, 2, . . . , r(i), vertex ui,r appears (p, a, u, b, p)-cycle,
vertex ui,r appears (p, a, u, b, p)-cycle.
(2) r = 1, 2, . . . , r(i), vertex ui,r appears (p, a, u, b, p)-cycle,
vertex ui,r appears (p, a, u, b, p)-cycle.
given p-rooted 4-cycle-cover KS , define (ui ) = FALSE scenario
(1) define (ui ) = TRUE scenario (2). claim desired function .
prove this, consider 2k (p, u, c, d, p)-cycles 4-cycle-cover. 1 j
2k, (p, u, c, d, p)-cycle containing cj also contains vertex U . vertex
either ui,r ui,r , indices r.
former case, ui,r cj appear (p, u, c, d, p)-cycle, implying ui,r cj edge gadget graph GS , ui literal clause Cj . Since ui,r appears
(p, u, c, d, p)-cycle therefore (p, a, u, b, p)-cycle, implies scenario
(2) above. Since (ui ) = TRUE ui Cj , clause Cj evaluates TRUE.
latter case, ui,r cj appear (p, u, c, d, p)-cycle, implying ui,r -cj
edge gadget graph GS , ui literal clause Cj . Since ui,r appears
(p, u, c, d, p)-cycle therefore (p, a, u, b, p)-cycle, implies scenario
(1) above. Since (ui ) = FALSE ui Cj , clause Cj evaluates TRUE.
Since Cj evaluates TRUE 1 j 2k, implies valid truth
assignment. conclude = C1 C2 . . . C2k satisfiable.
prove Lemma 2.
Proof. First, prove (i) (ii).

(p, a, u, b, p)-cycle, edges au ub appear gadget graph GS . Therefore,
edge weights au ub z 2 . Table 3, see (p, a, u, b, p)-cycle
edge weight z 2 + z 2 + z 2 + z 2 = 4z 2 . Similarly, (p, u, c, d, p)-cycle edge weight
(z 2 +z)+z 2 +z 2 +z 2 = 4z 2 +z, (p, u, e, f, p)-cycle edge weight (z 2 +z)+z 2 +z 2 +z 2 =
4z 2 + z.
119

fiHoshino & Kawarabayashi

p-rooted 4-cycle-cover KS exactly 3k (p, a, u, b, p)-cycles, 2k (p, u, c, d, p)cycles, k (p, u, e, f, p)-cycles, total edge weight exactly 3k(4z 2 ) + 2k(4z 2 +
z) + k(4z 2 + z) = k(24z 2 + 3z).
established first direction, prove (ii) (i).
Let R p-rooted 4-cycle-cover KS union r cycles, total edge
weight k(24z 2 + 3z). Since 18k vertices XS covered exactly one cycle
R, number edges R |XS | + r = 18k + r. Since cycle length greater
4, r 18k
3 = 6k. suppose r 6k + 1. least 24k + 1 edges
R, weight least z 2 given construction complete graph KS .
Hence, total edge weight R least (24k +1)z 2 = 24kz 2 +z 2 = 24kz 2 +z(20k +1) >
24kz 2 + 3zk = k(24z 2 + 3z), contradiction.
follows r = 6k, R must union 6k cycles length 4. Recall
weight edge appears set {z 2 , z 2 + z, z 2 + 2z, 2z 2 1}. Suppose
one 24k edges weight 2z 2 1. total edge weight R least
(24k1)z 2 +(2z 2 1) = 24kz 2 +z 2 1 = 24kz 2 +z(20k+1)1 > 24kz 2 +3zk = k(24z 2 +3z),
contradiction. Hence, edges R must weight z 2 , z 2 + z, z 2 + 2z.
Table 3, see edges p-c p-e appear 4-cycle-cover R, since
edges p C E weight 2z 2 1. follows must exist 2k 4-cycles
form p-?-ci -?-p k 4-cycles form p-?-ei -?-p, 2k + k = 3k
4-cycles containing unique element C E. blank space (denoted question
mark) filled vertex D, F , U , weights edges ca, cb, ea,
eb 2z 2 1 A, b B, c C, e E.

Since edge p-u weight z 2 + z, vertex u U chosen appear one
3k 4-cycles, adds edge weight z 2 + z, producing 4-cycle weight least
4z 2 + z. vertices u U chosen replace blank spaces, cycles
must form p-dj -ci -dk -p p-fj -ei -fk -p, lead addition
least one edge weight 2z 2 1 (since cannot simultaneously = j, = k,
j 6= k). follows 2k + k = 3k 4-cycles containing vertices C E must
weight least 4z 2 + z, thus contributing least k(12z 2 + 3z) total distance
p-rooted 4-cycle-cover R.
Since given 4-cycle-cover R weight k(24z 2 + 3z), implies rest
3k 4-cycles must weight exactly 4z 2 , 2k cycles form
p-?-ci -?-p k cycles form p-?-ei -?-p, total edge weight must exactly 4z 2 + z
ensure total edge weight R exceed k(24z 2 + 3z). implies
two scenarios, cannot replace two blank spaces two distinct vertices
U , would create cycle weight 4z 2 + 2z. follows R must 2k
(p, u, c, d, p)-cycles k (p, u, e, f, p)-cycles.
left 3k vertices A, B, U form remaining 3k
4-cycles. order total edge weight R exceed k(24z 2 + 3z) = 3k(4z 2 + z) +
12kz 2 , remaining 12k edges must weight z 2 . Since edge p-u weight
z 2 + z u U , 3k remaining vertices U must appear unique 4-cycle,
none adjacent root vertex p. follows remaining 3k 4-cycles R must
(p, a, u, b, p)-cycles.
120

fiScheduling Bipartite Tournaments Minimize Total Travel Distance

prove Lemma 3.

Proof. proof Lemma 2, see ILBp = k(24z 2 + 3z), handles
case = p. consider case = q.
Let R q-rooted 4-cycle-cover KS union r cycles. Suppose
contrary exists R total edge weight less k(24z 2 + 20z).
derive contradiction.
Since 18k vertices XS covered exactly one cycle R, number
edges R |XS |+r = 18k+r. previous proof, r 6k. r 6k+1, total
edge weight R least (24k + 1)z 2 = 24kz 2 + z 2 = 24kz 2 + z(20k + 1) > k(24z 2 + 20z),
contradiction.
Hence, r = 6k, R must union 6k cycles length 4. suppose
one 24k edges weight 2z 2 1. total edge weight R least
(24k 1)z 2 + (2z 2 1) = 24kz 2 + z 2 1 = 24kz 2 + z(20k + 1) 1 > k(24z 2 + 20z), another
contradiction.
Therefore, edges q-b q-d appear 4-cycle-cover R, since edges
p B weight 2z 2 1. follows must exist 3k 4-cycles form
q-?-bi -?-q 2k 4-cycles form q-?-di -?-q. blank space (denoted question
mark) filled vertex E F since weights edges be, bf , de, df
2z 2 1 b B, D, e E, f F .
follows k remaining 4-cycles must include k + k = 2k vertices
E F . 4-cycles contains three elements E F (e.g. cycle q-ei -fj ek -q cycle q-ei -ej -fk -q), creates least one edge weight 2z 2 1,
contradiction. Thus, must exactly two vertices E F 4-cycles.
Moreover, since weights edges ae, af , ce, cf 2z 2 1 A, c C,
follows final vertex remaining k 4-cycles must element U , thus
producing 4-cycle q-ui,r -ej -fk -q q-fi -uj,r -fk . Table 3, see every
valid cycle edge weight 4z 2 + 2z.
Hence, must k 4-cycles cycle cover R, containing 2k vertices E F
k vertices U , contributing total weight k(4z 2 + 2z). 3k 4-cycles
form q-?-bi -?-q, vertex C appear, otherwise would edge weight
2z 2 1. Similarly, 2k 4-cycles form q-?-di -?-q, vertex appear.
Thus, 3k 4-cycles containing bi , two vertices must selected
U . Table 3, see every 4-cycle edge weight 4z 2 + 4z.
2k 4-cycles containing di , two vertices must selected C U .
Also Table 3, see every 4-cycle edge weight 4z 2 + 3z.
Therefore, q-rooted 4-cycle-cover KS total edge weight k(4z 2 + 2z) +
3k(4z 2 + 4z) + 2k(4z 2 + 3z) = k(24z 2 + 20z), establishing desired contradiction.
conclude ILBq = k(24z 2 + 20z).
proof r-rooted 4-cycle-cover identical. apply mapping
{a, b, c, d, e, f, u} {b, a, e, f, c, d, u} vertices preceding paragraphs reach
conclusion. case, ILBr = k(4z 2 +3z)+3k(4z 2 +4z)+2k(4z 2 +2z) =
k(24z 2 + 19z).
121

fiHoshino & Kawarabayashi

Appendix B.
provide 12 12 distance matrix NPB league (from Section 4),
30 30 distance matrix NBA (from Section 5).
mentioned Section 4, Pacific League teams p1 (Fukuoka), p2 (Orix), p3
(Saitama), p4 (Chiba), p5 (Tohoku), p6 (Hokkaido), Central League teams c1
(Hiroshima), c2 (Hanshin), c3 (Chunichi), c4 (Yokohama), c5 (Yomiuri), c6 (Yakult).
Table 11, provide Dci ,cj Dpi ,pj < j since case > j equivalent
symmetry.
Team
c1
c2
c3
c4
c5
c6
p1
p2
p3
p4
p5
p6

c1
0

c2
323
0

c3
488
195
0

c4
808
515
334
0

c5
827
534
353
37
0

c6
829
536
355
35
7
0

p1
258
577
742
916
926
923
0

p2
341
27
213
533
552
554
595
0

p3
870
577
396
63
51
48
958
595
0

p4
857
564
383
58
37
39
934
582
86
0

p5
895
654
511
364
331
333
1100
670
374
361
0

p6
1288
1099
984
886
896
893
1466
1115
928
904
580
0

Table 11: Distance Matrix Japanese NPB League.
calculate entry distance matrix, determined teams travel
one stadium another, taking account actual mode(s) transportation.
example, distance Dc2 ,c5 = 534 found adding travel distance
component trip Hanshins home stadium Yomiuris home stadium, namely
15 km bus ride Koshien Stadium Shin-Osaka Station, 515 km bullet-train
ride Tokyo Station, followed 4 km bus ride Tokyo Dome.
rigorous approach simply calculating flight distance airports Osaka
Tokyo. Noting teams travel airplane, bullet train, bus, repeat
analysis 12
2 = 66 pairs cities produce matrix Table 11.
Finally, provide 30 30 distance matrix NBA, well labeling
30 teams Table 9. fifteen teams Western Conference, namely
Portland Trailblazers (PT), Golden State Warriors (GW), Sacramento Kings (SK),
Los Angeles Clippers (LC), Los Angeles Lakers (LL), Phoenix Suns (PS), Utah Jazz (UJ),
Denver Nuggets (DN), Oklahoma Thunder (OT), San Antonio Spurs (SS), Dallas Mavericks
(DM), Houston Rockets (HR), Minnesota Timberwolves (MT), Memphis Grizzlies (MG),
New Orleans Hornets (NH).
fifteen teams Eastern Conference, namely Milwaukee Bucks (MB),
Chicago Bulls (CU), Indiana Pacers (IP), Detroit Pistons (DP), Toronto Raptors (TR),
Cleveland Cavaliers (CC), Boston Celtics (BC), New York Knicks (NK), New Jersey Nets
(NN), Philadelphia Sixers (PS), Washington Wizards (WW), Charlotte Bobcats (CB), Atlanta Hawks (AH), Orlando Magic (OM), Miami Heat (MH). Note two teams
(Chicago Bulls Charlotte Bobcats) initials, thus represented former CU latter CB avoid ambiguity.
122

fiScheduling Bipartite Tournaments Minimize Total Travel Distance

Team
PT
GW
SK
LC

PS
UJ
DN
OT
SS
DM
HR
MT
MG
NH

PT
0

GW
536
0

SK
473
75
0

LC
824
333
368
0


824
333
368
0
0

PS
997
636
637
365
365
0

UJ
620
580
524
582
582
501
0

DN
969
931
884
837
837
582
375
0

OT
1462
1353
1320
1169
1169
820
852
493
0

SS
1691
1455
1441
1192
1192
831
1072
785
402
0

DM
1602
1445
1420
1227
1227
866
985
645
178
244
0

HR
1799
1605
1586
1358
1358
994
1178
853
391
187
215
0

MT
1403
1555
1494
1514
1514
1258
976
683
686
1084
843
1023
0

MG
1826
1770
1733
1594
1594
1244
1242
867
425
617
417
462
692
0

NH
2020
1875
1850
1645
1645
1281
1408
1052
559
486
430
300
1027
345
0

Table 12: Distance Matrix NBA Western Conference (intra-league).
Team
MB
CU
IP
DP
TR
CC
BC
NK
NN
PS
WW
CB
AH
OM
MH

MB
0

CU
66
0

IP
235
175
0

DP
248
249
249
0

TR
414
430
433
190
0

CC
323
310
257
90
191
0

BC
847
853
805
605
439
553
0

NK
734
728
655
486
361
418
184
0

NN
714
708
634
466
343
398
198
20
0

PS
680
667
578
434
342
357
276
93
80
0

WW
602
580
468
372
341
284
407
225
209
133
0

CB
642
591
422
502
582
425
718
534
522
442
317
0

AH
661
599
427
602
731
548
933
749
735
657
526
224
0

OM
1047
985
811
950
1036
877
1101
926
919
844
742
456
392
0

MH
1244
1183
1009
1143
1220
1068
1243
1077
1074
1002
911
643
589
198
0

Table 13: Distance Matrix NBA Eastern Conference (intra-league).
Team
MB
CU
IP
DP
TR
CC
BC
NK
NN
PS
WW
CB
AH
OM
MH

PT
1690
1711
1848
1934
2064
2014
2497
2415
2395
2368
2291
2247
2140
2491
2661

GW
1806
1807
1903
2052
2214
2117
2651
2535
2515
2472
2372
2251
2097
2397
2540

SK
1750
1753
1855
1998
2157
2064
2594
2482
2461
2419
2320
2209
2060
2367
2514

LC
1730
1718
1786
1967
2143
2022
2572
2437
2417
2365
2252
2092
1917
2181
2307


1730
1718
1786
1967
2143
2022
2572
2437
2417
2365
2252
2092
1917
2181
2307

PS
1439
1418
1466
1665
1848
1711
2265
2120
2100
2403
1926
1747
1562
1817
1942

UJ
1227
1230
1333
1474
1634
1540
2072
1958
1937
1895
1799
1700
1565
1897
2058

DN
894
886
973
1135
1307
1194
1739
1612
1592
1544
1441
1327
1190
1526
1692

OT
726
683
678
908
1098
934
1482
1324
1305
1242
1118
926
749
1049
1206

SS
1082
1028
973
1220
1406
1224
1739
1564
1547
1474
1342
1080
861
1023
1126

DM
840
787
745
990
1177
1001
1532
1362
1344
1275
1147
912
710
955
1094

HR
973
915
834
1083
1264
1077
1575
1397
1380
1306
1173
899
680
839
950

MT
292
330
495
531
667
612
1106
1012
992
965
894
917
894
1286
1483

MG
550
485
376
624
801
614
1123
950
932
861
731
503
327
668
849

NH
893
827
699
935
1097
906
1349
1166
1151
1074
942
642
419
540
665

Table 14: Distance Matrix two NBA Conferences (inter-league).

readability, 30 30 distance matrix broken 15 15 matrices, providing
intra-league inter-league distances. remark Los Angeles Clippers
Los Angeles Lakers play games arena, explains distance
zero. entry Tables 12 14 expressed miles, unlike NPB distance
matrix expressed kilometres.
123

fiHoshino & Kawarabayashi

References
Anagnostopoulos, A., Michel, L., Hentenryck, P. V., & Vergados, Y. (2006). simulated
annealing approach traveling tournament problem. Journal Scheduling, 9,
177193.
Easton, K., Nemhauser, G., & Trick, M. (2001). traveling tournament problem: description benchmarks. Proceedings 7th International Conference Principles
Practice Constraint Programming, 580584.
Easton, K., Nemhauser, G., & Trick, M. (2002). Solving travelling tournament problem:
combined integer programming constraint programming approach. Proceedings 4th International Conference Practice Theory Automated
Timetabling, 319330.
Easton, K., Nemhauser, G., & Trick, M. (2004). Sports scheduling. Leung, J. T. (Ed.),
Handbook Scheduling, chap. 52, pp. 119. CRC Press.
Garey, M., & Johnson, D. (1979). Computers Intractability: guide theory
NP-completeness. W.H. Freeman, New York.
Hoshino, R., & Kawarabayashi, K. (2011a). distance-optimal inter-league schedule
Japanese pro baseball. Proceedings ICAPS 2011 Workshop Constraint
Satisfaction Techniques Planning Scheduling Problems (COPLAS), 7178.
Hoshino, R., & Kawarabayashi, K. (2011b). inter-league extension traveling
tournament problem application sports scheduling. Proceedings 25th
AAAI Conference Artificial Intelligence, appear.
Hoshino, R., & Kawarabayashi, K. (2011c). multi-round balanced traveling tournament
problem. Proceedings 21st International Conference Automated Planning
Scheduling (ICAPS), 106113.
Hoshino, R., & Kawarabayashi, K. (2011d). multi-round generalization traveling
tournament problem application Japanese baseball. European Journal
Operational Research, doi: 10.1016/j.ejor.2011.06.014.
Itai, A., Perl, Y., & Shiloach, Y. (1982). complexity finding maximum disjoint paths
length constraints. Networks, 12, 278286.
Kendall, G., Knust, S., Ribeiro, C., & Urrutia, S. (2010). Scheduling sports: annotated
bibliography. Computers Operations Research, 37, 119.
Lim, A., Rodrigues, B., & Zhang, X. (2006). simulated annealing hill-climbing
algorithm traveling tournament problem. European Journal Operational
Research, 174, 14591478.
Thielen, C., & Westphal, S. (2010). Complexity traveling tournament problem.
Theoretical Computer Science, 412, 345351.

124

fiJournal Artificial Intelligence Research 42 (2011) 31-53

Submitted 4/11; published 9/11

Link Partial Meet, Kernel,
Infra Contraction Application Horn Logic
Richard Booth

richard.booth@uni.lu

Universite du Luxembourg
Luxembourg

Thomas Meyer

tommie.meyer@meraka.org.za

Centre Artificial Intelligence Research
University KwaZulu-Natal CSIR Meraka Institute
South Africa

Ivan Varzinczak

ivan.varzinczak@meraka.org.za

Centre Artificial Intelligence Research
University KwaZulu-Natal CSIR Meraka Institute
South Africa

Renata Wassermann

renata@ime.usp.br

Universidade de Sao Paulo
Brazil

Abstract
Standard belief change assumes underlying logic containing full classical propositional logic. However, good reasons considering belief change less expressive
logics well. paper build recent investigations Delgrande contraction
Horn logic. show standard basic form contraction, partial meet,
strong Horn case. result stands contrast Delgrandes conjecture
orderly maxichoice appropriate form contraction Horn logic. define
appropriate notion basic contraction Horn case, influenced convexity
property holding full propositional logic refer infra contraction.
main contribution work result shows construction method
Horn contraction belief sets based infra remainder sets corresponds exactly
Hanssons classical kernel contraction belief sets, restricted Horn logic.
result obtained via detour contraction belief bases. prove kernel
contraction belief bases produces precisely results belief base version
infra contraction. use belief bases obtain result provides evidence
conjecture Horn belief change best viewed hybrid version belief set change
belief base change. One consequences link base contraction
provision representation result Horn contraction belief sets version
Core-retainment postulate features.

1. Introduction
seminal paper, Delgrande (2008) shed light theoretical underpinnings
belief change weakening usual assumption belief change community, namely
underlying logical formalism least strong (full) classical propositional logic (Gardenfors, 1988). Delgrande investigated contraction functions belief
sets (sets sentences closed logical consequence) restricted Horn formuc
2011
AI Access Foundation. rights reserved.

fiBooth, Meyer, Varzinczak, & Wassermann

las (1951). Delgrandes main contributions essentially threefold. Firstly, showed
move Horn logic leads two different types contraction functions, referred
entailment-based contraction (e-contraction) inconsistency-based contraction (icontraction), coincide full propositional case. Secondly, showed Horn
contraction belief sets satisfy controversial Recovery postulate, exhibits
characteristics usually associated contraction belief bases (arbitrary sets sentences). finally, Delgrande made tentative conjecture version
Horn contraction usually referred orderly maxichoice contraction appropriate
method contraction Horn theories.
Delgrandes partial meet constructions appropriate choices contraction
Horn logic, show constitute appropriate forms Horn contraction. Moreover, referred above, although Horn contraction defined Horn belief
sets, related ways contraction belief bases, aspect yet
explored properly literature.
paper continue investigation contraction Horn logic, address
issues mentioned above, well others. Focusing Delgrandes entailmentbased contraction, start providing fine-grained construction belief set
contraction refer paper infra contraction. bring
picture construction method contraction first introduced Hansson (1994), known
kernel contraction. Although kernel contraction usually associated belief base
contraction, applied belief sets well. main contribution result
shows infra contraction corresponds exactly Hanssons kernel contraction belief
sets, restricted Horn logic. order prove this, first take close look
contraction belief bases, defining base version infra contraction proving
construction equivalent kernel contraction Horn belief bases. Since Horn belief
sets closed classical logical consequence, seen hybrid
belief sets belief bases. justifies use belief bases obtain results belief
set Horn contraction.
Horn logic found extensive use Artificial Intelligence, particular logic programming, truth maintenance systems, deductive databases. explains, part,
interest belief change Horn logic. (Despite interest Horn formulas,
worth noting work consider logic programming explicitly
use negation failure all.) Another reason focusing topic
application debugging repairing ontologies description logics (Baader, Calvanese,
McGuinness, Nardi, & Patel-Schneider, 2007). particular, Horn logic seen
backbone EL family description logics (Baader, Brandt, & Lutz, 2005),
therefore proper understanding belief change Horn logic important finding
solutions similar problems expressible EL family.
remainder present paper organized follows: logical preliminaries (Section 2), give background belief set contraction (Section 3) belief
base contraction (Section 4) necessary core section paper (Section 5).
prove kernel contraction infra contraction equivalent level
belief bases. enables us prove kernel contraction infra contraction
equivalent Horn belief set level well. led provide characterization infra contraction Horn belief sets version Core-retainment
32

fiPartial Meet, Kernel, Infra Contraction Horn Logic

postulate (Hansson, 1994) bases features. provides even evidence
hybrid aspect Horn belief change. results stated entailment-based
contraction (e-contraction). Section 6, discuss related work, also mention
similar results Delgrandes i-contraction another relevant type Horn contraction,
namely Booth et als (2009) package contraction. conclude summary contributions well discussion future directions investigation. Proofs new
results found Appendix A.

2. Preliminaries
work finitely generated propositional language set propositional atoms P,
together distinguished atom > (true), standard model-theoretic
semantics. Atoms denoted p, q, . . ., possibly subscripts. formulas
language denoted , , . . . recursively defined follows:
::= p | > | |
connectives (, , , . . . ) special atom (false) defined terms
usual way. LP denote set formulas language.
Classical logical consequence logical equivalence denoted |= respectively. X LP , set sentences logically entailed X denoted Cn(X).
belief set logically closed set, i.e., belief set K, K = Cn(K). usually denote
belief sets K, possibly decorated primes. P(X) denotes power set (set subsets) X. displaying belief sets sometimes follow convention displaying
one representative equivalence class modulo logical equivalence, dropping
representative tautologies. example, LP generated two atoms p
q, set Cn({p}) represented {p, p q, p q}.
Horn clause sentence form p1 p2 . . . pn q n 0, pi , q P
1 n (recall pi q may one > well). n = 0 write
q instead q. Horn formula conjunction Horn clauses. Horn set set
Horn formulas.
Given propositional language LP , Horn language LH generated LP simply
set Horn formulas occurring LP . Horn logic obtained LH
semantics propositional logic obtained LP , restricted Horn formulas.
Hence, |=, , related notions defined relative logic
working in. use |=PL CnPL (.) denote classical entailment consequence
propositional logic. Horn logic, define CnHL (.) follows: CnHL (X) =def CnPL (X)
LH X LH . define |=HL follows: X LH LH , X |=

HL
X |=PL .
consequence operator CnHL (.) Tarskian consequence operator sense
satisfies following properties Horn sets X, X 0 :
X CnHL (X)

(Inclusion)

CnHL (X) = CnHL (CnHL (X))

(Idempotency)

X X 0 , CnHL (X) CnHL (X 0 )

(Monotonicity)
33

fiBooth, Meyer, Varzinczak, & Wassermann

Horn belief set, usually denoted H (possibly primes), Horn set closed
operator CnHL (.), i.e., H = CnHL (H). shall dispense subscripts
whenever context makes clear logic dealing with.
AI tradition, given set formulas underlying logical language called
knowledge base, simply set beliefs. Belief change deals situations
agent modify beliefs world, usually due new previously unknown
incoming information, also represented formulas language. Common operations
interest belief change expansion (Gardenfors, 1988) agents current beliefs X
given formula (usually denoted X + ), basic idea add regardless
consequences, revision (Gardenfors, 1988) current beliefs (denoted
X ? ), intuition incorporate current beliefs way
ensuring consistency resulting theory time. Perhaps basic
operation belief change contraction (Alchourron, Gardenfors, & Makinson,
1985; Gardenfors, 1988), intended represent situations agent
give current stock beliefs (denoted X ). Indeed revision operation
defined terms contraction simple expansion via Levi identity (Levi,
1977). Therefore, contraction focus present paper follows shall
investigate detail. Throughout Sections 3 4 assume work language
full propositional logic LP .

3. Belief Set Contraction
commence discussion belief set contraction, aim describe
contraction knowledge level (Gardenfors, 1988), i.e., independently beliefs
represented syntactically. Thus, contraction defined belief sets.
Definition 1 (Belief Set Contraction) belief set contraction belief set K
function LP P(LP ).
principle categorical matching (Gardenfors & Rott, 1995) contraction
belief set sentence expected yield new belief set.
One standard approaches constructing belief contraction operators based
notion remainder set set K respect formula : maximal subset
K entailing (Alchourron et al., 1985). define belief sets,
known literature basic principle applied belief bases well
(we shall recall Section 4).
Definition 2 (Remainder Sets) Given belief set K formula LP , X K

X K;
X 6|= ;
every X 0 X X 0 K, X 0 |= .

call elements K remainder sets K respect .
34

fiPartial Meet, Kernel, Infra Contraction Horn Logic

easy verify K = |= (Gardenfors, 1988).
Since unique method choosing possibly different remainder sets,
presupposition existence suitable selection function so:
Definition 3 (Selection Functions) selection function set K (partial)
function P(P(LP )) P(P(LP ))
(K) = {K} K = ;
(K) K otherwise.

Selection functions provide mechanism identifying remainder sets judged
appropriate. resulting contraction obtained taking intersection
chosen remainder sets.
Definition 4 (Partial Meet Contraction) selection function
, belief set conT
traction operator generated defined K =def (K) partial meet
contraction.
Two subclasses belief set partial meet deserve special mention:
Definition 5 (Maxichoice Full Meet) Given selection function , maxichoice contraction (K) always singleton set. full meet contraction (K) = K whenever K 6= .
worth mentioning belief set full meet contraction unique, belief set
maxichoice contraction usually not.
Kernel contraction introduced Hansson (1994) generalization safe contraction (Alchourron & Makinson, 1985). Instead looking maximal subsets implying
given formula, kernel operations based minimal subsets imply it.
Definition 6 (Kernel) belief set K, X K
X K;
X |= ;
every X 0 X 0 X, X 0 6|= .

K called kernel set K respect elements K called
-kernels belief set K.
result kernel contraction obtained removing least one element
every (non-empty) -kernel K, using incision function.
Definition 7 (Incision Functions) incision function set K function
set kernel sets K P(LP )
35

fiBooth, Meyer, Varzinczak, & Wassermann

(K
)



(K
);

=
6 X K
, X (K ) 6= .

Given belief set K incision function K, ideally would want kernel
contraction K generated defined as:
K =def K \ (K )

(1)

turns belief set K, contraction operator (1) respect
principle categorical matching. because, belief set input, kernel
contraction (1) necessarily produce belief set result: K
general closed logical consequence, shown following example.
Example 1 Let K = Cn({p q, q r}) assume want contract p r
K. K
(p r) = {{p r}, {p q, q r}, {p q, p q r}}.
incision function defined (K (p r)) = {p r, p q, p q r},
applying operator (1) gives us K 0 K 0 |= p q r, obviously
pq r
/ K 0.
course, possible ensure one obtains belief set closing result
obtained operator logical consequence.
Definition 8 (Belief Set Kernel Contraction) Given belief set K incision
function K, belief set contraction operator K generated defined
K =def Cn(K ) belief set kernel contraction.
shall see Section 4 belief set kernel contraction closely related version
belief base contraction referred saturated base kernel contraction (Hansson, 1999).
Belief set contraction defined terms partial meet contraction corresponds exactly
perhaps best-known approach belief change: so-called AGM approach (Alchourron et al., 1985). AGM requires (basic) belief set contraction characterized
following set postulates:
(K 1) K = Cn(K )

(Closure)

(K 2) K K

(Inclusion)

(K 3)
/ K, K = K

(Vacuity)

(K 4) 6|= ,
/ K

(Success)

(K 5) , K = K

(Extensionality)

(K 6) K, Cn((K ) {}) = K
36

(Recovery)

fiPartial Meet, Kernel, Infra Contraction Horn Logic

Full AGM contraction involves two extended postulates addition basic postulates
given above. shall elaborate detail intuition postulates.
refer reader book Gardenfors (1988) handbook Hansson (1999).
Alchourron et al. (1985) shown postulates characterize belief set partial
meet contraction exactly, shown following result:
Theorem 1 (Alchourron et al., 1985) Every belief set partial meet contraction satisfies Postulates (K 1)(K 6). Conversely, every belief set contraction satisfies
Postulates (K 1)(K 6) belief set partial meet contraction.
Hansson (1994) shown Postulates (K 1)(K 6) also characterize kernel
contraction belief sets:
Theorem 2 (Hansson, 1994) Every belief set kernel contraction satisfies Postulates
(K 1)(K 6). Conversely, every belief set contraction satisfies Postulates (K 1)
(K 6) belief set kernel contraction.
conclude section important new observation whose usefulness become apparent Section 5.
Theorem 3 (Convexity) Let K belief set, let mc (belief set) maxichoice contraction, let fm denote (belief set) full meet contraction. every LP every
belief set X K fm X K mc , (belief set) partial meet
contraction pm K pm = X .
result shows every belief set results obtained full meet
contraction maxichoice contraction also obtained partial meet
contraction. So, possible define version belief set contraction based sets.
Definition 9 (Infra Remainder Sets) Given formula LP ,
belief sets K
0
0
00
K , K K K K ( K) K 0 K 00 .
refer elements K infra remainder sets K respect .
easy see K = |= . Note definition set infra
remainder sets belief set K required belief sets themselves.
remainder sets respect formula also infra remainder sets respect
, intersection set remainder sets respect . Indeed,
intersection set infra remainder sets respect also infra remainder
set respect . set infra remainder sets respect contains belief
sets remainder set respect intersection remainder
sets respect . explains infra contraction defined
intersection infra remainder sets (cf. Definition 4).
Definition 10 (Infra Contraction) Let K belief set. infra selection function
K (partial) function P(P(LP )) P(LP ) (K ) = K whenever
K = , (K ) K otherwise. belief set contraction operator belief
set infra contraction K = (K ).
37

fiBooth, Meyer, Varzinczak, & Wassermann

sense, then, infra contraction closer maxichoice contraction partial meet
contraction, since chooses single element set infra remainder sets, much
like maxichoice contraction chooses single element set remainder sets.
One immediate consequence Theorem 3 Definition 10 following:
Corollary 1 Infra contraction partial meet contraction coincide belief sets.

4. Belief Base Contraction
turn attention belief base contraction, agents beliefs represented
(usually finite) set sentences necessarily closed logical consequence, also
known base. usually denote bases B, possibly decorated primes.
Definition 11 (Belief Base Contraction) base contraction base B function LP P(LP ).
Intuitively idea that, fixed belief base B, contraction formula B
produces new base B .
Given construction methods belief set contraction already discussed Section 3,
two obvious ways define belief base contraction consider partial meet contraction kernel contraction bases. present cases.
definitions required partial meet base case analogous given
belief set case Section 3. readers convenience, state explicitly here:
Definition 12 (Base Remainder Sets) Given base B formula , X B

X B;
X 6|= ;
every X 0 X X 0 B, X 0 |= .

call elements B base remainder sets B respect .
Similarly belief set case, easy verify B = |= .
Definition 13 (Selection Functions) selection function base B (partial)
function P(P(LP )) P(P(LP ))
(B) = {B} B = ;
(B) B otherwise.

Definition 14 (Base Partial Meet Contraction) selection function
, belief
base contraction operator generated defined B =def (B)
base partial meet contraction.
38

fiPartial Meet, Kernel, Infra Contraction Horn Logic

Definition 15 (Base Maxichoice Full Meet) Given selection function ,
base maxichoice contraction (B) always singleton set. base
full meet contraction (B) = B whenever B 6= .
belief set case, checked belief base full meet contraction unique,
base maxichoice contraction usually not.
Hansson (1992) showed belief base partial meet contraction characterized
following postulates:
(B 1) 6|= , B 6|=

(Success)

(B 2) B B

(Inclusion)

(B 3) B 0 |= B 0 |= B 0 B, B = B (Uniformity)
(B 4) (B \ (B )), B 0
(B ) B 0 B B 0 6|= , B 0 {} |=

(Relevance)

Again, shall elaborate detail intuition postulates.
refer reader handbook Hansson (1999).
Theorem 4 (Hansson, 1992) Every base partial meet contraction operator satisfies Postulates (B 1)(B 4). Conversely, every base contraction satisfies (B 1)(B 4)
base partial meet contraction.
One question arises whether following belief base version convexity
principle Theorem 3 holds:
(Base Convexity) belief base B, let mc base maxichoice contraction,
let fm denote base full meet contraction. every set X B fm
X B mc , base partial meet contraction pm B pm = X.
belief set case, principle simply states every set results
obtained base full meet contraction base maxichoice contraction
obtained belief base partial meet contraction. following example shows
hold.
Example 2 Let B = {p q, q r, pq r, pr q} consider contraction p r.
easily verified base maxichoice gives either B (p r) = B 0 = {p q, p r q}
B(p r) = B 00 = {q r, pq r, pr q}. Therefore result obtained
base partial meet contraction provided base full meet contraction:
B (p r) = B 000 = {p r q}. observe even though case
B 000 X B 00 X = {p q r, p r q}, X equal B 0 , B 00 , B 000 .
shall come back issue end section.
give definitions kernel contraction belief base case. Again,
analogous given belief set case previous section, readers
convenience state explicitly here.
39

fiBooth, Meyer, Varzinczak, & Wassermann

Definition 16 (Base Kernels) belief base B formula , X B

X B;
X |= ;
every X 0 X 0 X, X 0 6|= .

B called kernel set B respect , elements B called
-kernels B.
result base kernel contraction obtained removing least one element
every (non-empty) -kernel B, using incision function.
Definition 17 (Incision Functions Bases) incision function base B
function set kernel sets B P(LP )

(B
) (B
);
=
6 X B
, X (B ) 6= .

refer incision function minimal every , every incision
function 0 , (B
) 0 (B
).
(unique) maximum incision function defined
follows: every , (B
) = (B ).
worthy mention minimal incision functions always exist.
Definition 18 (Base Kernel Contraction) Given incision function base B,
base kernel contraction B generated defined as: B = B \ (B ).
Base kernel contraction characterized postulates base partial meet
contraction, except Relevance replaced Core-retainment postulate below:
(B 5) (B \ (B )),
B 0 B B 0 6|= B 0 {} |=

(Core-retainment)

Theorem 5 (Hansson, 1994) Every base kernel contraction satisfies Postulates (B 1)
(B 3) (B 5). Conversely, every base contraction satisfies Postulates (B 1)
(B 3) (B 5) base kernel contraction.
Clearly, Core-retainment slightly weaker Relevance. indeed, thus follows
base partial meet contractions base kernel contractions, following
example Hansson (1999) shows, base kernel contractions base partial
meet contractions.
Example 3 Let B = {p, p q, p q}. B (p q) = {{p, p q}, {p q, p q}}.
incision function B (B (p q)) = {p q, p q},
B (p q) = {p}. hand, B(p q) = {{p, p q}, {p q}},
follows base partial meet contraction B (p q) yields either {p, p q}, {p q},
{p, p q} {p q} = , none equal B (p q) = {p}.
40

fiPartial Meet, Kernel, Infra Contraction Horn Logic

briefly pointed Definition 8, definition kernel contraction belief
sets closely related version belief base contraction Hansson (1999) refers
saturated base kernel contraction:
Definition 19 (Saturated Base Kernel Contraction) Given belief base B
incision function B, base contraction B generated defined
B =def B Cn(B ) saturated base kernel contraction.
easily shown (Hansson, 1994) set B definition saturated base
kernel contraction belief set, two notions coincide.
Observation 1 belief set K incision function K, saturated base
kernel contraction belief set kernel contraction identical.
saturated base kernel contractions general base partial meet contractions (Hansson, 1999, p. 91), distinction disappears considering belief sets only:
Theorem 6 (Hansson, 1994) Let K belief set. belief set contraction saturated base kernel contraction belief set partial meet contraction.
result Observation 1 Theorem 6 immediately following corollary:
Corollary 2 Let K belief set. belief set contraction belief set kernel contraction belief set partial meet contraction.
Thanks Theorem 3 (Convexity) extend Corollary 2 show kernel contraction, partial meet contraction, infra contraction coincide belief sets.
Corollary 3 Let K belief set. belief set contraction belief set kernel contraction belief set partial meet contraction belief set
infra contraction.
far considered remainder sets bases kernel sets bases, infra
remainder sets bases (cf. end Section 3). conclude section discussion
commencing definition base infra remainder sets.
Definition 20 (Base Infra Remainder Sets) Given formula
, bases B B 0 ,

0
00
B B B B ( B) B 0 B 00 . refer
elements B base infra remainder sets B respect .
Observe definition base infra remainder sets infra remainder
sets, differing deals belief bases belief sets. Note particular
elements required belief sets themselves. Base infra remainder sets
used define form base contraction way similar definition
(belief set) infra contraction (cf. Definition 10).
41

fiBooth, Meyer, Varzinczak, & Wassermann

Definition 21 (Base Infra Contraction) base infra selection function (partial)
function P(P(LP )) P(LP ) (B ) = B whenever B = ,
(B ) B otherwise. belief base contraction operator generated
defined B =def (B ) base infra contraction.
natural question ask base infra contraction compares base partial meet
contraction base kernel contraction. following result, plays central role
paper, shows base infra contraction corresponds exactly base kernel contraction.
Theorem 7 base contraction belief base B belief base kernel contraction B
base infra contraction B.
Example 3 know base kernel contraction general base partial
meet contraction: every base partial meet contraction also base kernel contraction,
converse hold. Theorem 7 following result thus follows.
Observation 2 Base infra contraction general base partial meet contraction.
Theorem 7 number interesting consequences well. philosophical
note, provides evidence contention kernel contraction approach
appropriate partial meet approach. mentioned earlier, well-known
kernel contraction partial meet contraction coincide belief sets, differ belief
bases (kernel contraction general partial meet contraction case).
importance Theorem 7 shows new seemingly different approach
contraction (infra contraction) identical kernel contraction belief sets
belief bases, different partial meet contraction belief bases, thereby tilting
scales evidence towards kernel contraction. shall see next section, Theorem 7
also instrumental lifting result level Horn belief sets.

5. Horn Belief Set Contraction
previous sections recalled several results belief change literature
stated new ones, connecting different constructions sets rationality postulates.
important note although examples literature assume
underlying logic contains classical propositional logic, results usually valid
broader set languages. discussed different contexts Hansson
Wassermann (2002), Flouris et al. (2006), Ribeiro Wassermann (2009a, 2009b, 2010),
Varzinczak (2008, 2010), Wassermann (2011), among others. belief bases,
shown Hansson Wassermann (2002) order keep representation theorems
partial meet kernel contraction, logic needs compact monotonic.
means results transfer directly Horn logics. However, belief sets
representation theorems demand restrictions logic. shown Flouris et
al. (2006), contraction operation satisfying basic AGM postulates exists
logic decomposable.
Definition 22 (Flouris et al., 2006) logic called decomposable
sets formulas X, X 0 , Cn() Cn(X 0 ) Cn(X), exists set formulas
X 00 Cn(X 00 ) Cn(X) Cn(X) = Cn(X 0 X 00 ).
42

fiPartial Meet, Kernel, Infra Contraction Horn Logic

shown Ribeiro (2010) Horn logic decomposable. Therefore, new
constructions sets postulates needed deal contraction Horn belief sets.
Delgrande (2008) investigated two distinct classes contraction functions Horn
belief sets: entailment-based contraction (e-contraction), removing unwanted consequence; inconsistency-based contraction (i-contraction), removing formulas leading
inconsistency; Booth et al. (2009) subsequently extended work Delgrande
providing fine-grained versions constructions. focus paper
e-contraction, although Delgrande, well Booth et al., also consider i-contraction.
Recall use H, sometimes decorated primes, denote Horn belief set.
Definition 23 (e-Contraction) e-contraction Horn belief set H function
LH P(LH ).
Delgrandes method construction e-contraction terms partial meet contraction. definitions remainder sets (Definition 2), selection functions (Definition 3),
partial meet contraction (Definition 4), well maxichoice full meet contraction (Definition 5) carry e-contraction, set K case replaced
Horn belief set H, refer e-remainder sets (denoted ), e-selection
functions, partial meet e-contraction, maxichoice e-contraction full meet e-contraction
respectively (we leave reference term Horn, since room
ambiguity here). full propositional case, easy verify e-remainder
sets also Horn belief sets, partial meet e-contractions (and therefore
maxichoice e-contractions, well full meet e-contraction) produce Horn belief sets.
Although Delgrande defines discusses partial meet e-contraction, argues
maxichoice e-contraction appropriate approach e-contraction. precise,
version maxichoice e-contraction Delgrande advocates actually restricted version maxichoice e-contraction refer orderly maxichoice e-contraction. (This
Horn case maxichoice contraction operators satisfying AGM postulates, including supplementary ones). Whereas (ordinary) maxichoice e-contraction
constructed setting, every LH , H equal element H, orderly
maxichoice e-contraction systematicSin nature. Associated every orderly maxichoice e-contraction linear order LH (H), union e-remainder sets
H respect sentencesS LH . Intuitively, higher linear order,
plausible element LH (H) intended be. orderly maxichoice
e-contraction generated obtained follows: every LH , K
selected plausible e-remainder set H respect (the one
highest order ).
argue although partial meet e-contractions appropriate choices
e-contraction, make set appropriate e-contractions. words,
Delgrandes approach complete. argument appropriate e-contractions
partial meet e-contraction based observation convexity result full
propositional logic Theorem 3 hold Horn logic.
Example 4 Let H = CnHL ({p q, q r}). e-contraction p r H, maxi1 = Cn ({p q}) H 2 = Cn ({q r, p r q}), whereas full
choice yields either Hmc
HL
HL
mc
43

fiBooth, Meyer, Varzinczak, & Wassermann

meet yields Hf = CnHL ({p r q}). three partial meet e-contractions.
consider Horn belief set H 0 = CnHL ({p q r, p r q}). clear
2 , partial meet e-contraction yielding H 0 .
Hf H 0 Hmc
order rectify situation, propose e-contraction extended
include cases H 0 above. argument follows: Since full meet e-contraction
deemed appropriate, stands reason belief set H 0 bigger
also seen appropriate, provided H 0 contain irrelevant additions.
since H 0 contained maxichoice e-contraction, H 0 cannot contain irrelevant
additions. all, maxichoice Horn e-contraction contains relevant additions,
since appropriate form contraction. Hence H 0 also appropriate result
e-contraction.
summary, every Horn belief set full meet maxichoice e-contraction
ought seen appropriate candidate e-contraction. captured
definition below.
Definition 24 (Infra e-Remainder Sets) Horn
belief sets H H 0 , H 0 H e

H 00 ( ) H 0 H 00 . refer
elements H e infra e-remainder sets H respect .
case full propositional logic (cf. Definition 9), e-remainder sets also infra
e-remainder sets, intersection set e-remainder sets. Similarly,
intersection set infra e-remainder sets also infra e-remainder set,
set infra e-remainder sets contains Horn belief sets e-remainder set
intersection e-remainder sets. full propositional case, explains
e-contraction defined intersection infra e-remainder sets (cf. Definition 4).
Definition 25 (Horn e-Contraction) Let H Horn belief set LH Horn
formula. infra e-selection function (partial) function P(P(LH )) P(LH )

(H e ) = H whenever H e = ;
(H e ) H e otherwise.

e-contraction infra e-contraction H = (H e ).
results kernel contraction, partial meet contraction infra contraction
compare base case (kernel contraction infra contraction identical,
general partial meet contraction) invite question whether similar results
hold Horn belief sets. provide answer this, need suitable version
kernel contraction Horn belief sets.
Definition 26 (Horn kernel e-contraction) Given Horn belief set H incision function H, Horn kernel e-contraction H, abbreviated kernel econtraction H, defined H e =def CnHL (H ), belief base
kernel contraction obtained .
44

fiPartial Meet, Kernel, Infra Contraction Horn Logic

turns infra e-contraction kernel e-contraction coincide, following
result shows.
Theorem 8 e-contraction Horn belief set H infra e-contraction H
kernel e-contraction H.
Theorem 8 Example 4 follows partial meet e-contraction
restrictive kernel e-contraction. comes Horn belief sets, therefore
exactly pattern belief bases: kernel contraction infra contraction
coincide, strictly permissive partial meet contraction. Contrast
case belief sets full propositional logic infra contraction, partial
meet contraction kernel contraction coincide.
One conclusion drawn restriction Horn case produces
curious hybrid belief sets belief bases full propositional logic. one
hand, Horn contraction deals sets logically closed. hand,
results Horn logic obtained terms construction methods close obtained
belief base contraction.
Either way, new results belief base contraction prove quite useful
investigation contraction Horn belief sets. conclude section providing
representation result Horn contraction inspired new results belief base
contraction paper.
Theorem 9 Every infra e-contraction satisfies (K 1), (K 2), (K 4), (K 5)
Core-retainment. Conversely, every e-contraction satisfies (K 1), (K 2), (K 4),
(K 5), Core-retainment infra e-contraction.
result inspired Theorem 7 shows base kernel base infra
contraction coincide. Given Core-retainment used characterizing base kernel
contraction, Theorem 7 shows link Core-retainment base infra
contraction, raises question whether link Core-retainment
infra e-contraction. answer, seen Theorem 9, yes. result provides
evidence hybrid nature contraction Horn belief sets. case
connection base contraction strengthened.

6. Related Work
knowledge, first formal proposal taking non-maximal remainder sets
contraction following AGM principles made Restall Slaney (1995).
construction appears context different ours: use four-valued logic
show dropping Recovery postulate, obtain representation result
partial-meet non-maximal remainders. Note restriction
remainder sets containing minimal core, made infra remainders, result
postulate associated kind minimal change.
work revision Horn formulas (Eiter & Gottlob, 1992;
Liberatore, 2000; Langlois, Sloan, Szorenyi, & Turan, 2008), recently attention
paid contraction Horn logic. Apart work Delgrande (2008)
45

fiBooth, Meyer, Varzinczak, & Wassermann

discussed, recent work obtaining semantic characterisation
Horn contraction using system spheres Fotinopoulos Papadopoulos (2009),
via epistemic entrenchment Zhuang Pagnucco (2010).
Billington et al. (1999) considered revision contraction defeasible logic
quite different Horn logic many respects, nevertheless rule-like flavour
similarity Horn logic.
present paper extension work Booth et al. (2009)
show infra e-contraction captured precisely six AGM postulates belief set
contraction, except Recovery replaced following (weaker) postulate (H e 6)
together Failure postulate:
(H e 6) H \ (H ),
exists X (He ) X H X 6|= , X {} |=
(H e 7) |= , H e = H

(Failure)

Theorem 10 (Booth et al., 2009) Every infra e-contraction operator satisfies Postulates (K 1)(K 5), (H e 6) (H e 7). Conversely, every e-contraction
satisfies (K 1)(K 5), (H e 6) (H e 7) infra e-contraction.
Postulate (H e 6) bears resemblance Relevance postulate base contraction states sentences removed H -contraction must
removed reason: adding brings back . Postulate (H e 7) simply
states contracting tautology leaves initial belief set unchanged.
worth noting (H e 6) somewhat unusual postulate refers
directly construction method intended characterize, i.e., e-remainder sets.
provided elegant characterization infra e-contraction taking
detour base contraction. Firstly, replaced (H e 6) Core-retainment
postulate used characterization base kernel contraction. turns
Vacuity postulate (K 3) Failure postulate (H e 7) follow
Core-retainment Inclusion postulate (K 2), obtained
characterization infra e-contraction.
addition e-contraction, Delgrande also investigated version Horn contraction
refers inconsistency-based contraction (or i-contraction) purpose
modify agents Horn belief set way avoid inconsistency sentence
provided input. is, i-contraction (H ) {} 6|=
.
HL
addition e- i-contraction, Booth et al. (2009) considered package contraction (or p-contraction), version contraction studied Fuhrmann Hansson (1994)
classical case (i.e., logics containing full propositional logic). Given set
formulas X, goal make sure none sentences X result obtained p-contraction. full propositional logic similar contracting
disjunction sentences X. Horn logic, full disjunction,
package contraction interesting. Although seems new results presented
paper applied i-contraction p-contraction, still
verified detail.
46

fiPartial Meet, Kernel, Infra Contraction Horn Logic

Recent work Delgrande Wassermann (2010) draws inspiration semantic
representation remainder sets. classical AGM approach, remainder set
obtained semantically adding models belief set H counter-model
formula contraction. Horn clauses, construction necessarily lead
sets correspond remainder sets. because, known Horn logic, given
two models m1 , m2 Horn belief set H, model m1 u m2 also model H,
m1 u m2 denotes model atoms true precisely atoms
true m1 m2 . illustrate this, consider following example:
Example 5 (Delgrande & Wassermann, 2010) Let P = {p, q, r} let Horn belief set H = CnHL (p q). Consider candidates H (p q). three e-remainder
sets, given Horn closures p (r q), q (r p), (p q) (q p) (r
p) (r q). infra e-remainder set contains closure (r p) (r q).
Example 5, unique model set {p, q, r} countermodel p q. add
models H close u result represents Horn belief set,
obtain set models formula p, cannot e-remainder set,
e-remainder set (CnHL (p (r q))) containing it. means approach
based e-remainder sets cannot contraction operators behaviour
classical ones.
Delgrande Wassermann propose mimic semantic construction classical
remainders: weak-remainder H formed intersecting H maximal
consistent Horn theory containing . Equivalently, weak-remainders semantically characterized taking closure intersection models H together
single counter-model . Representation results contraction based weakremainders provided.
Concerning connection partial meet contraction kernel contraction
bases, Falappa et al. (2006) shown construct partial meet contraction
kernel contraction, always possible, construct kernel contraction
partial meet contraction, possible. results generalized
apply base infra contraction base kernel contraction. is,
possible construct base infra contraction every base kernel contraction, well
base kernel contraction every base infra contraction.

7. Concluding Remarks
bringing Hanssons kernel contraction picture, made meaningful contributions investigation contraction Horn logic. main contributions
present paper follows: (i) result shows infra contraction kernel
contraction belief base case coincide; (ii) Lifting previous results Horn
belief sets show infra contraction kernel contraction Horn belief sets coincide.
investigation base contraction also allowed us improve rather unsatisfactory representation result proved Booth et al. infra contraction, relies
postulate referring directly construction method intended characterize.
obtained elegant representation result replacing postulate introduced
47

fiBooth, Meyer, Varzinczak, & Wassermann

Booth et al. well-known Core-retainment postulate, usually associated
base contraction. presence Core-retainment enforces hybrid
nature Horn belief change, lying somewhere belief set change base change.
seen kernel e-contraction infra e-contraction general
partial meet e-contraction. also evidence even forms Horn contraction may sufficient obtain meaningful answers. Consider, example,
Horn belief set example CnHL ({p q, q r}) encountered Example 4. view basic
Horn clauses (clauses exactly one atom head body) representative
arcs graph, style old inheritance networks, case made
regarding three arcs p q, q r, p r, basic information used
generate belief set. one possible desirable outcome contraction p r
CnHL (q r). However, seen Example 4, outcome supported
infra e-contraction (and therefore kernel e-contraction either). Ideally, truly
comprehensive e-contraction approach Horn logic would able account
cases well.
focus basic Horn contraction. future work plan investigate
Horn contraction full AGM contraction, obtained adding extended postulates.
Another interesting question investigation whether Theorem 9 generalized logics, notably extensions (full) propositional logic.
Finally, mentioned earlier, one reasons focusing topic
application debugging repairing ontologies description logics. particular,
Horn logic seen backbone EL family description logics (Baader et al.,
2005), therefore proper understanding belief change Horn logic important
finding solutions similar problems expressible EL family. currently
investigating possibilities.

Acknowledgments
paper extends work Booth, Meyer Varzinczak appeared IJCAI (Booth
et al., 2009), work Booth, Meyer, Varzinczak Wassermann appeared
NMR (Booth et al., 2010a) ECAI (Booth et al., 2010b).
authors grateful anonymous referees constructive useful
remarks, helped improving quality presentation work. would also
like thank Eduardo Ferme provided important hints connection infra
kernel contraction.
work Richard Booth supported FNR INTER project Dynamics
Argumentation. work Thomas Meyer Ivan Varzinczak supported
National Research Foundation Grant number 65152. work Renata Wassermann supported CNPq, Brazilian National Research Council, grants
304043/2010-9 471666/2010-6.

Appendix A. Proofs Main Theorems
proofs Lemma A.1 Theorem 3 need model-theoretic notions.
denote W set valuations LP [] set models , i.e., set
48

fiPartial Meet, Kernel, Infra Contraction Horn Logic

valuations satisfy . set sentences X, denote [X] set models
X, i.e., set valuations satisfy sentences X. V W, let
h(V ) = { LP | V []}.
results Lemma A.1 well-known model-theoretic descriptions full
meet, partial meet, maxichoice contraction, first presented Katsuno & Mendelzon (1991). results, stated below, stated directly Katsuno & Mendelzon,
follow easy consequences Theorem 3.3.
Lemma A.1 (Katsuno & Mendelzon, 1991) Let K belief set.
1. Let fm (belief set) full meet contraction. every LP , K fm =
Th([K] []);
2. Let mc (belief set) maxichoice contraction. every LP , w []
K mc = Th([K] {w});
3. Given LP , let V [] V 6= . (belief set) partial meet
contraction pm every LP , K pm = Th([K] V ).
Theorem 3 (Convexity) Let K belief set, let mc (belief set) maxichoice contraction, let fm denote (belief set) full meet contraction. every LP , let X
belief set (K fm ) X K mc . (belief set) partial meet
contraction pm every LP , K pm = X .
Proof:
cases |=
/ K hold easily, suppose 6|= K. Now, pick
belief set X K fm X K mc . Points (1) (2) Lemma A.1
means w [] [K] {w} [X ] K [].
follows [X ] = [K] [V ] V []. Point (3) Lemma A.1
follows partial meet contraction pm that, every LP ,
K pm = X = h([K] V ).
[qed]
Lemma A.2 (Falappa et al., 2006) Every base kernel contraction defined minimal
incision function base maxichoice contraction.
Lemma A.3 base kernel contraction defined maximal incision function
full meet base contraction.
Proof:


need prove B \ (B
) = (B). |= B 6|= result follows
immediately. suppose
6|= B |= . left-to-right direction, suppose

B
/ (B
), assume base remainder set B
respect , say X,
/ X.S must case contained
-kernel B. (B ): contradiction. right-to-left
direction, suppose
every base remainder set BSwith respect , assume


/ B \ (B
). Since B follows (B ). is,
-kernel B. least one minimal incision function (B ).
49

fiBooth, Meyer, Varzinczak, & Wassermann

Now, Lemma A.2 follows base remainder set B respect ,
say , = B \ (B
).
/ , contradicts supposition
every base remainder set B respect .
[qed]
Theorem 7 base contraction belief base B belief base kernel contraction B
base infra contraction B.
Proof:
part, let base kernel contraction B, let incision function
B generates , pick LP . |= B 6|=T result holds easily,
suppose 6|= B |= . remains
shown (B) B B 0

0
B B. Observe firstly

Tthat B \ (B ) B \(B ) = B . Lemma A.3
0
follows directly (B) B. Next, pick minimal incision function
0 (B
) (B
) ( 0 clearly exists). B = B \ (B ) B \ 0 (B )
Lemma A.2 follows B \ 0 (B ) = B 0 B 0 B.
part, let base infra contraction B. construct incision
function base kernel contraction generates exactly . Pick LP
suppose 6|= B |= (for remaining cases result easily holds). Let
(B ) = B \(B ). Since
B B B = B \(B ). First need
show

(B


)

(B
). so, observe
since B B , follows

(B) B . Therefore B \ (B ) B \ (B).
Lemma A.3

construction (B ) = B \ (B ) B \ (B) = (B ).
remains shown every B , (B ) 6= .
Pick B
, assume (B ) = . must
case B . |= therefore B |= , contradiction.
[qed]
Theorem 8 e-contraction Horn belief set H infra e-contraction H
kernel e-contraction H.
Proof:
Consider belief base B formula . Theorem 7 follows set base
infra remainder sets B respect (i.e., set B ) equal set results
obtained base kernel contraction B , call KCB . let B
set Horn formulas closed Horn consequence (a Horn belief set) Horn
formula. elements KCB necessarily closed Horn consequence,
close them, obtain exactly set results obtained kernel e-contraction
contracting B (by definition kernel e-contraction). Let us refer
latter set CnHL (KCB ), i.e., CnHL (KCB ) = {CnHL (X) | X KCB }. Also, elements
B closed Horn consequence, close resulting
set (refer set CnHL (B )) contains exactly infra e-remainder sets B
respect , i.e., CnHL (B ) = B e . see why, observe since B closed
Horn consequence, (base) remainder sets B respect (i.e., elements
B) also closed Horn consequence. theT
elements B sets (not
necessarily closed Horn consequence) (B) element B.
Therefore elements CnHL (B ) elements B closed
Horn consequence, i.e., CnHL (B ) = B e claimed. since B = KCB ,
also case CnHL (B ) = CnHL (KCB ), therefore CnHL (KCB ) = B e . [qed]
50

fiPartial Meet, Kernel, Infra Contraction Horn Logic

Theorem 9 Every infra e-contraction satisfies (K 1), (K 2), (K 4), (K 5)
Core-retainment. Conversely, every e-contraction satisfies (K 1), (K 2), (K 4),
(K 5), Core-retainment infra e-contraction.
Proof:
Let H Horn belief set, let infra e-contraction. H = H,
(K 1), (K 2), (K 4), (K 5) Core-retainment trivially satisfied. Suppose
H 6= H. H = X X H e . Then, definition, H
Horn belief set, hence H = CnHL (H ) (Postulate (K 1)). Moreover,
X 0 X X 0 . Since X 0 H, also follows X H,
H H (Postulate (K 2)). (K 4) also satisfied definition H e
monotonicity classical logic. (K 5) follows straightforwardly fact
working Horn belief sets. Finally, Core-retainment, suppose H

/ H . assume H 0 {} 6|=
every H 0 H H 0 6|=
.
HL
HL
0
0
particular then, every H , H {}T6|=HL . follows H 0
every H 0 , therefore (He ).
H , contradicts supposition.
Conversely, let H Horn belief set let e-contraction satisfies
Postulate (K 1), (K 2), (K 4), (K 5), Core-retainment. need show
every LH , H H e . Observe firstly satisfies (K 3). see why, note
Core-retainment follows
/ H H \ (H ) = , therefore
H H . (K 2) follows H = H .

/ H follows directly (K 3) H H e . |=
follows directly
HL
(K 2) Core-retainment H = H, therefore H H e .
So, suppose H 6|=
. show H
H e , need show
HL
H Horn belief set (from Postulate (K 1)) (He ) H H 0
H 0 . Observe firstly that, since H H (by Postulate (K 2))
0
0

/ H (by (K 4)),
H H H . Finally,
assume (He )
/ H . Core-retainment follows
00
00
H H H 6|=
H 00 {} |=
. follows
HL
HL
Horn belief set X H 00 X X 6|=HL
X {} |=HL .
X ,

/ X, contradicts assumption (He ). therefore
follows (H) H .
[qed]

References
Alchourron, C., Gardenfors, P., & Makinson, D. (1985). logic theory change:
Partial meet contraction revision functions. Journal Symbolic Logic, 50, 510
530.
Alchourron, C., & Makinson, D. (1985). logic theory change: safe contraction.
Studia Logica, 44, 405422.
Baader, F., Brandt, S., & Lutz, C. (2005). Pushing EL envelope. Kaelbling, L., & Saffiotti, A. (Eds.), Proceedings 19th International Joint Conference Artificial
Intelligence (IJCAI), pp. 364369. Morgan Kaufmann Publishers.
51

fiBooth, Meyer, Varzinczak, & Wassermann

Baader, F., Calvanese, D., McGuinness, D., Nardi, D., & Patel-Schneider, P. (Eds.). (2007).
Description Logic Handbook: Theory, Implementation Applications (2 edition). Cambridge University Press.
Billington, D., Antoniou, G., Governatori, G., & Maher, M. (1999). Revising nonmonotonic
theories: case defeasible logic. Proceedings 23rd Annual German
Conference Artificial Intelligence, No. 1701 LNAI, pp. 101112. Springer-Verlag.
Booth, R., Meyer, T., & Varzinczak, I. (2009). Next steps propositional Horn contraction. Boutilier, C. (Ed.), Proceedings 21st International Joint Conference
Artificial Intelligence (IJCAI), pp. 702707. AAAI Press.
Booth, R., Meyer, T., Varzinczak, I., & Wassermann, R. (2010a). contraction core Horn
belief change: Preliminary report. 13th International Workshop Nonmonotonic
Reasoning (NMR).
Booth, R., Meyer, T., Varzinczak, I., & Wassermann, R. (2010b). Horn belief change:
contraction core. Proceedings 19th European Conference Artificial
Intelligence (ECAI), pp. 10651066.
Delgrande, J. (2008). Horn clause belief change: Contraction functions. Lang, J., &
Brewka, G. (Eds.), Proceedings 11th International Conference Principles
Knowledge Representation Reasoning (KR), pp. 156165. AAAI Press/MIT
Press.
Delgrande, J., & Wassermann, R. (2010). Horn clause contraction functions: Belief set
belief base approaches. Proceedings 12th International Conference
Principles Knowledge Representation Reasoning (KR). AAAI Press.
Eiter, T., & Gottlob, G. (1992). complexity propositional knowledge base revision,
updates, counterfactuals. Artificial Intelligence, 57 (23), 227270.
Falappa, M., Ferme, E., & Kern-Isberner, G. (2006). logic theory change: Relations incision selection functions. Brewka, G., Coradeschi, S., Perini,
A., & Traverso, P. (Eds.), Proceedings 17th European Conference Artificial
Intelligence (ECAI), pp. 402406. IOS Press.
Flouris, G., Plexousakis, D., & Antoniou, G. (2006). generalizing AGM postulates.
Proceedings 3rd Starting AI Researchers Symposium, pp. 132143.
Fotinopoulos, A., & Papadopoulos, V. (2009). Semantics Horn contraction. 7th
PanHellenic Logic Symposium, pp. 4247.
Fuhrmann, A., & Hansson, S. (1994). survey multiple contractions. Journal Logic,
Language Information, 3, 3976.
Gardenfors, P. (1988). Knowledge Flux: Modeling Dynamics Epistemic States.
MIT Press.
Gardenfors, P., & Rott, H. (1995). Belief revision. Handbook Logic Artificial
Intelligence Logic Programming, Vol. 4, pp. 35132. Clarendon Press.
Hansson, S. (1992). dyadic representation belief. Belief Revision, Vol. 29 Cambridge Tracts Theoretical Computer Science, pp. 89121. Cambridge University
Press.
52

fiPartial Meet, Kernel, Infra Contraction Horn Logic

Hansson, S. (1994). Kernel contraction. Journal Symbolic Logic, 59 (3), 845859.
Hansson, S. (1999). Textbook Belief Dynamics: Theory Change Database Updating.
Kluwer Academic Publishers.
Hansson, S., & Wassermann, R. (2002). Local change. Studia Logica, 70 (1), 4976.
Horn, A. (1951). sentences true direct unions algebras. Journal
Symbolic Logic, 16, 1421.
Katsuno, H., & Mendelzon, A. (1991). Propositional knowledge base revision minimal
change. Artificial Intelligence, 3 (52), 263294.
Langlois, M., Sloan, R., Szorenyi, B., & Turan, G. (2008). Horn complements: Towards
Horn-to-Horn belief revision. Fox, D., & Gomes, C. (Eds.), Proceedings 23rd
National Conference Artificial Intelligence (AAAI), pp. 466471. AAAI Press.
Levi, I. (1977). Subjunctives, dispositions chances. Synthese, 34, 423455.
Liberatore, P. (2000). framework belief update. Proceedings 7th European
Conference Logics Artificial Intelligence (JELIA), pp. 361375.
Restall, G., & Slaney, J. (1995). Realistic belief revision. Proceedings Second World
Conference Foundations Artificial Intelligence (WOCFAI), pp. 367378.
Ribeiro, M. (2010). Belief Revision Description Logics Non-Classical Logics.
Ph.D. thesis, University Sao Paulo.
Ribeiro, M., & Wassermann, R. (2009a). AGM revision description logics. Workshop
Automated Reasoning Context Ontology Evolution (ARCOE).
Ribeiro, M., & Wassermann, R. (2009b). Base revision ontology debugging. Journal
Logic Computation, 19 (5), 721743.
Ribeiro, M., & Wassermann, R. (2010). AGM revision description logics.
Workshop Automated Reasoning Context Ontology Evolution (ARCOE).
Varzinczak, I. (2008). Action theory contraction minimal change. Lang, J., &
Brewka, G. (Eds.), Proceedings 11th International Conference Principles
Knowledge Representation Reasoning (KR), pp. 651661. AAAI Press/MIT
Press.
Varzinczak, I. (2010). action theory change. Journal Artificial Intelligence Research,
37, 189246.
Wassermann, R. (2011). AGM non-classical logics. Journal Philosophical Logic,
40 (1), 124.
Zhuang, Z., & Pagnucco, M. (2010). Horn contraction via epistemic entrenchment.
Janhunen, T., & Niemela, I. (Eds.), Proceedings 12th European Conference
Logics Artificial Intelligence (JELIA), No. 6341 LNCS, pp. 339351. SpringerVerlag.

53

fi
